Artificial Intelligence 76 ( 1995) 89-123 Artificial Intelligence Approximate planning * Matthew L. Ginsberg * Clh!L., 1269 University of Oregon, Eugene, OR 97403-1269, USA Received April 1993; revised March 1994 Abstract This paper makes two linked contributions. First, we argue that planning systems, instead of being correct (every plan returned achieves the goal) and complete (all such plans are returned), should be approximately correct and complete, in that most plans returned achieve the goal and that most such plans are returned. The first contribution we make is to formalize this notion. Our second aim is to demonstrate the practical importance of these ideas. We argue that the cached plans used by case-based planners are best thought of as approximate as opposed to exact, and also show that we can use our approach to plan for subgoals gr and g2 separately and to combine the plans generated to produce a plan for the conjoined goal go A gz. The computational benefits of working with subgoals separately have long been recognized, but attempts to do so using correct and complete planners have failed. 1. Introduction When we talk about a plan for achieving a goal, we typically mean not one plan but a turkey I will sweet to wish from my stated goal of many. As an example, involves stuffing and roasting take between now and when potatoes and pumpkin pie, buying a bottle of wine, calling them happy holidays, turkey preparation. that my plan for preparing that these are the only actions I may also plan on making if I say on Thanksgiving it, I hardly mean the turkey and other actions even further removed family members is done. In fact, my plan “stuff the turkey and then roast it” might be represented something like this: [ . . . stuff . . . roast . . .] (1) * Supported by the Air Force Office of Scientific Research under contract 92-0693 and by ARPA/Rome Labs under contracts F30602-91-C-0036 and F30602-93-C-00031. * E-mail: ginsberg@cs.uoregon.edu. 0004-3702/95/@9.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00077-8 90 M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 A B C D Fig. 1. Get A on B on C without building a four-block tower. where the ellipses denote currently undetermined action sequences that I might inter- sperse into the above plan. If I need to roast the turkey immediately after stuffing it, I might write that as [ . . . stuff roast. . .] (2) where the second set of ellipses has been dropped. There are, of course, many instances of ( 1) that are unsatisfactory. Perhaps I run the turkey through a paper shredder before beginning preparation, or unstuff it after stuffing it, or garnish it liberally with peanut butter before serving. In what sense can we say that ( 1) is our plan when so many things can go wrong? The conventional approach to this problem is to deal not with plans such as that appearing in ( 1) , but with far more specific plans such as [stuff yams telephone roast eat] (3) where there are guaranteed to be no extraneous actions that might interfere with our achieving our goal. But from a practical point of view, the plan (3) is nearly worthless, since it is almost inconceivable that I execute it exactly as written. There are many other examples of this phenomenon. If we intend to construct plans by retrieving them from a library of known solutions to similar problems (so-called case-based planning [ 14]), it is important that the plans in the library include some measure of flexibility. After all, it is unlikely that the new situation in which we find ourselves will be an exact match for the situation in which the plan was constructed. Our ability to plan for conjunctive goals rests on similar ideas. When possible, it is important that we plan for conjuncts separately and then merge the results; this appears to require that the solutions to the individual conjuncts be plan schemas such as ( 1). Planning for conjuncts separately enables us to take computational advantage of the benevolence of our environment as reflected in the frame assumption-we can typically achieve one subgoal and then not worry about it while we work on other things. Another example of a conjunctive planning problem appears in Fig. 1. The goal is to get A on B and B on C, but there is a restriction to the effect that one cannot build a four-block tower. For a human planner, the problem is easy. We realize that the general plan for getting B onto C is simply to move it there, and similarly for getting A on B. When we combine these two plans, however, we encounter a problem-the action of moving A to B will fail. We therefore modify the plan for getting B onto C, adding the additional action of moving C to the table. ML. Ginsberg/Artificial Intelligence 76 (1995) 89-123 91 I presented this problem to the authors of two generative planning systems-Minton (PRODIGY [ 171) and Wilkins ( SIPE [ 211) . Both reported (personal communication) that the problem would pose no significant difficulties for them and that they could solve it by adding an additional precondition to the action move(x, y) to the effect that y had to be either on the table or on a block z that was on the table. 1 The problem with this approach is that it doubles the branching factor for all plan- ning problems. This will lead to prohibitive computational difficulties as the problems involved get larger; imagine having to move a block prior to constructing a 13-block tower in a domain that prohibits 1Cblock ones. As an example of the immediacy of these difficulties, Penberthy and Weld’s UCPOP system [ 181 proved incapable of solving the four-block version of the problem in Fig. 1 without the inclusion of domain-specific control information. * Worse still is the fact that the branching factor is being increased on all problems, not just those that involve tall towers. Imagine, for example, that we can only put a blue block on a red one if the red block is on the table. The branching factor will still be doubled even if we are working in a domain without blue blocks! 3 Explicit control rules provide potential ways around these particular difficulties, but their use is problematic. What control rule are we to use if the previous domain includes painting actions, so that the colors of blocks can change? What control rule would allow us to efficiently solve the problem in Fig. 1 if the constraint were changed so that only jive-block towers were prohibited? Related problems appear in plan debugging. If a human planner discovers a bug in one portion of a plan to achieve a complex goal, the typical response is to restrict the impact of the bug to a small portion of the analysis and to then plan around the problem. That we can make modifications that address the bug without destroying the effect of the original plan depends on our commonsense ability to construct and manipulate plans that, while not holding universally, do hold in general. like ( I)-plans My intention in this paper is to develop a formalization of the ideas that are implicit in the plan ( 1)) and to then describe the use of these constructs in conjunctive planning. Please bear with me while we work through the mathematics, since there are a variety of fundamentally new ideas that we need to formalize. ( 1) We first need to describe plans that can have new actions added to them in arbitrary ways but that can still include the immediacy requirements of a plan such as (2). This is our goal in the next section, where we also present a variety of mathematical results about these new plans that will be needed later. (2) We next need to define conditions under which a plan approximately achieves a goal. The basic idea here is that a plan P is approximately correct if most instances of P that could actually be executed do indeed achieve the goal. We 1 Wilkins made the alternative suggestion of creating two move operators. This is equivalent in practice, however; doubling the branching factor by introducing a second move operator is equivalent to doubling it by introducing a disjunction into the precondition. *Will Harvey, personal communication. The problem is not one of time, but of space; UCPOP reported that it had exhausted its available memory while working on this problem. s This is assuming that we treat color as a precondition and not as a filter. We would need to do this if there were actions available that changed blocks’ colors. 92 M.L. Ginsberg/Art$icial Intelligence 76 (1995) 89-123 formalize this in Section 3 by introducing the idea of an exception to a plan and formalizing conditions under which plans hold sufficiently frequently that we are prepared to treat them as approximately correct. (3) The problem of building a planner around these ideas is discussed in Sections 4 and 5. Section 4 discusses the theoretical issues involved in the construction of the planner, showing that it is indeed possible to plan for conjuncts separately using our ideas. Section 5 discusses a preliminary implementation of our work. (4) Concluding remarks are contained in Section 6, and proofs have been deferred to an appendix. Let me end this introduction with something of a disclaimer. I do not mean to imply that existing implemented systems are incapable of manipulating expressions such as ( 1) . Tate’s O-Plan system, for example [ 2,201, appears to use ideas such as these rou- tinely. But planners that behave in this fashion have thus far lacked formal foundation, and correcting that is my intention here. In providing a solid formal foundation for nonlinear planning, McAllester and Rosenblitt’s paper [ 161 was both a step forward and a step back; although it formalized many ideas that had previously eluded precise description, it omitted many of the procedural tricks that make implemented planners effective. As a result, formally well-grounded planners such as that described by Pen- berthy and Weld [ 181 typically exhibit performance far worse than that of the informal systems that preceded them. My hope here is to shed some formal light on the ideas that have proven so effective in practice. 2. Plans I will adopt the view that a plan is a partially ordered collection of actions, where an action is a functional expression such as move( a, b) : Definition 2.1. An action is either a variable or a functional expression, where the arguments to the function may themselves include variables. A ground action is an action that contains no variables. By an action such as move( a, ?) we will mean the action of moving a to the location ? where ? will presumably be determined by other considerations. We cannot now simply define a plan to be a partially ordered sequence of actions, since we need to be able to distinguish between ( 1) and (2). In some cases, we will want the action a to precede b immediately, while in others, there may be many actions interspersed between the two. We handle this as follows: Definition 2.2. A plan is a triple (A, <, *) where A is a finite collection of actions and < is a partial order on A; by a Q b for actions a, b E A we mean that a must precede b. * is another binary relation on A with * c <, so that whenever u * b, a < b as well. We will assume that * and < also satisfy the following conditions: (1) Ifc*aandc<b,thenu<b. (2) If b * c and a < c, then a < b. M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 93 We will take a * b to mean that b is a successor of a for which no intermediate actions are permitted. Note that the definition refers to A as a collection instead of as a set; this is to allow the same action to appear multiple times in the partial order. To understand the additional conditions, suppose that a is an immediate successor of c, so that c * a. Now if b is some other successor of c, then a must precede b as well. The second condition is the dual of the first. In practice, plans are bounded by initial and terminal actions. We model this by requiring that plans contain dummy initial and terminal actions denoted by di and d, respectively: Definition 2.3. A plan (A, <, *) will be said to be bounded if di E A and d, E A with di < a and d, > a for all a E A. We will assume throughout this paper that all plans are bounded. The general turkey-roasting plan ( 1) corresponds to the partial order di < stuff < roast < d, while the plan that roasts the turkey immediately after stuffing it corresponds to di < stuff * roast < dr. The second inequality has been made an instance of *. Before proceeding, let me spend a moment discussing the difference between *, our annotation for the links in a partially-ordered plan, and the causal annotations introduced by McAllester and Rosenblitt [ 161. McAllester and Rosenblitt’s links serve more a bookkeeping function than anything else; the information they contain (which action is intended to achieve which precon- dition) could be recovered, if need be, from the plan being constructed. Recording the information on the arcs serves the computational purpose of making the plans more efficient to work with. Our * annotation is different. Annotating an arc with * makes the associated plan a semantically different object, in the sense that we have added a new constraint to the set of linearizations of the given plan. Note also that our language is fundamentally more flexible than McAllester and Rosenblitt’s-we allow the addition of arbitrary new actions to plans, while they do not. This is important, since it enables us to work with the flexible plan ( 1) instead of the far more restrictive (3). Lemma2.4. Zf(A,<,*) (1) Ifa*bundu*c, (2) Ifa*cundb*c, isuplun, then b=c. thenu=b. thenforunyu,b,cEA: An action can have at most one immediate predecessor or successor. Suppose now that we have some plan (A, <, *). If there is a chain 94 M.L. Ginsberg/Art@ial Intelligence 76 (1995) 89-123 c = co * s . . * cn = a and c 6 b, then b must either be one of the CL’S or it must follow a; there is no other “room” between c and a. The following lemmas capture this, where we have written Z for the transitive closure of *: Lemma25 Let (A,<,*) (1) Ifc<bandcJCa, (2) Ifb<candaZc, beaplan. Thenforanya,b,cEA: theneithercZbora<b. theneitherbicorb<a. Lemma2.6. then a 13; c. Let(A,<,*) beaplan.Thenforanya,b,cEA,ifa;i;banda<c<b, It is also straightforward to define conditions under which two plans are equivalent or one is an instance of the other: Definition 2.7. Two plans Pt and P2 will be called equivalent if they are identical up to variable renaming. Definition 2.8. A plan (AI, <I, *I) is a binding list (+ and a l-l mapping i : A2 + A1 with the following properties: is an instance of another plan (AZ, <2,*2) if there (1) For each a E AZ, i(a) = al,. In other words, the mapping i maps a to an action (2) that is the same as that constructed by applying the bindings in u to a. i( 62) C 61. Every ordering constraint on the second plan appears in the first as well. (3) i(*2) G *I. An example will probably help. If the stuff and roast actions accept an argument but the eat action doesn’t, [ . . . stuff (turkey) roast (turkey) . . . eat] is an instance of I . . . stuff (?) roast(?) . . .]. The plan (4) corresponds to the partial order di < stuff (turkey) * roast(turkey) < eat * d, while (5) corresponds to di < stuff (?) *roast(?) < dt. The required injection is now given by X, stuff(turkey), i(x) = if x = di or x = d,, if x = stuff(?), roast( turkey), if x = roast (?>, (4) (5) (6) (7) M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 95 and the binding list (T binds ? to turkey. It is clear that for each action x, i(x) = &. The image of f in (7) under i is the partial order di < stuff (turkey) < roast( turkey) < d, and is clearly included in the partial order of (6) ; the image of * under i contains the single pair stuff(turkey)*roast(turkey) and is once again contained in the * of (6). Proposition 2.9. The instance relation of Definition 2.8 is a partial order. We will write Pt S P2 to denote the fact that a plan PI is an instance of another plan p2. We have been careful in our definitions not to restrict the number of new actions that can be inserted between any two actions of the plan itself. When it comes time to actually execute the plan, however, we will need to select a specific action sequence. Definition 2.10. A plan P = (A, 6, *) will be called linear if the following conditions hold: ( 1) Every action in A is ground. (2) 3 =<. A linear plan that is an instance of a plan P will be called a linearization of P. In other words, a linearization of a plan replaces all of the variables with object constants and selects an ordering of the actions involved that can be derived solely from the immediacy conditions of *. This latter condition implies that no additional actions can be added to the plan. As an example, the linear plan (3) corresponds to the partial order di * stuff * yams * telephone * roast * eat * d,. There is no way to add another action to this ordering without having it either precede di, follow dt, or violate the conditions of Definition 2.2. Lemma 2.11. If P = (A, <, *) is a linear plan, then 6 is a total order. Proposition 2.12. PI C P2 if and only if the set of linearizations of PI is a subset of the set of linearizations of P2. Given the above result, it makes sense to think of a plan in terms of its linearizations; each linearization is a way in which we might actually go about executing the actions in the plan. Definition 2.13. A plan set is a set of linear plans. 96 M.L. Ginsberg/Art@cial Intelligence 76 (1995) 89-123 3. Approximate correctness Given now that there will almost inevitably be mistakes we can make, in the sense that there are linearizations of a given plan that do not actually achieve our intended result, how can we formalize the idea that the plan in ( 1) is correct “in general”? The solution we will use is an extension of an idea I proposed in 1991 [lo]. As an example, suppose that I am trying to get block A onto block B in the blocks world. A is clear, but C is currently on top of B and a wide variety of other blocks are scattered around the table. Here is my plan for achieving the goal: [move(C, ?) move(A, B)]. (8) I plan to move C out of the way, and then move A onto B. I’ve assumed just for the moment that no additional actions can be added; our interest here involves the variable ? that appears in (8). Note that there is one location to which we should not move the block currently on top of B-if we relocate it to A, B will become clear but A no longer will be. Given this, in what sense is (8) a solution to our problem? It is a solution in that there are many places to which we can move C, and the one that doesn’t work is in some sense pathological - most locations do work. What we need to do is to capture the way in which the set of exceptions is small relative to the set of possibilities. From a formal point of view, the exception involves a specific binding for the vari- able ?. This leads us to the following: Definition 3.1. Given a binding list u and a plan P = (A, <, *), the result of applying (+ to P is defined to be that plan where the actions in A have had the binding list applied to them but the plan is otherwise unchanged. This plan will be denoted PI,. We can, for example, bind ? to A in (8) to obtain [move(C,A) move(A, B)]. The following result is obvious: Lemma 3.2. Given a plan P and binding list a, PI, 2 P. 0 We are now in a position to describe conditions under which one set of plans is “small” relative to another. We need to be careful, however, since plans generally have infinitely many linearizations and we can’t simply say that Q is small relative to P if Q has many fewer linearizations than P does. Instead, we will say that Q is small relative to P if Q = P(, but Q # P. The motivation behind this definition is that there are generally many ways to bind any particular variable and Q is committed to a specific choice. In the following definition, we will say that Q is of measure 0 in P instead of simply saying that Q is small relative to P. The term is borrowed from real analysis, and we use M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 91 it because the formal definition of smallness has many of the same properties as does the analytic definition on which it is modelled. (The finite union of small sets is small, for example.) The 0 means that the ratio of the size of Q to that of P is approximately 0; we will also say that Q is “of measure 1” in P if this ratio is approximately 1, so that Q and P are comparably sized. Definition 3.3. A plan Q will be said to be of measure 0 in a plan P if Q # P but Q = PI, for some binding list cr. A plan or plan set Q will also be said to be of measure 0 in a plan or plan set P if either of the following conditions is satisfied: ( 1) Q is the finite union of sets of measure 0 in P. (2) There exist plan sets R and S with Q G R and both R and S - P of measure 0 in S. The requirement that Q # P ensures that the binding list CT is not trivial. The second condition in the definition handles cases where Q is a subset of a set of measure 0 in P (take S = P), or where, for example, one specific linearization has been removed from P. Adding that linearization back to P should not impact the question of whether Q is of measure 0 in P (take S to be the union of P and the missing linearization). As an example, the plan [ . . . move(a, b) . . .] is of measure 0 in the plan [ . . . move( a, ?) . . .] since the variable ? has been bound to a constant in (9). But the plan [ . . . move( a, b) ] (9) (10) (11) is not of measure 0 in the plan (9), since the difference between the two plans is not the binding of a variable but the fact that the action move(a, b) is the final action in ( 11) (i.e., an immediate predecessor of the plan’s terminal action) but not in (9). For similar reasons, a plan where two actions al and a2 are sequential is not of measure 0 in the plan where the actions are unordered. Since (9) is of measure 0 in the plan set (10) and ( 11) is an instance (i.e., a subset) of (9)) ( 11) is of measure 0 in ( 10) as well. Finally, (9) is also of measure 0 in the plan set given by removing [ . . . move(a, c) . . .] (12) from ( 10). After all, if binding ? to b reduces us to a set that is small relative to the set of all possible bindings, removing a single one of those possible bindings in advance shouldn’t change this conclusion. The second condition in Definition 3.3 allows us to continue to measure the size of a plan set relative to (10) even after ( 12) has been removed. 98 M.L. Ginsberg/Artijicial Intelligence 76 (1995) 89-123 What about adding new actions to a plan? If we add variable actions, the result will in general not be of measure 0 in the original plan; we are only committing to doing “something” and most of the linearizations of the original plan include additional actions of one form or another in any event. But if we add a specific action, the story is different: Proposition 3.4. Let P be a plan, and P’ an instance of P with i the associated injection from A to A’. Then if there is any action in A’ - i(A) that is not a variable, P’ is of measure 0 in P. Definition 3.5. A plan set Q will be said to be of measure 1 in P if P -Q is of measure 0 in P. Two plans sets will be called approximately equal if each is of measure 1 in the other. Lemma 3.6. Q is of measure 0 in P if any of the following conditions holds: (1) Q is empty. (2) Q is a subset of a set of measure 0 in P. (3) Q is of measure 0 in a subset of P. (4) Q is of measure 0 in a superset S of P with P of measure 1 in S. Lemma 3.7. Q is of measure 0 in P if and only if Q is of measure 0 in P U Q. Proposition 3.8. Approximate equality is an equivalence relation. We also have the following: Proposition 3.9. Let P # 0 be a plan set. Then provided that our language includes infinitely many object and action constants, there is no plan set that is both of measure 0 and of measure 1 in P. It is this result that gives teeth to the ideas we are proposing; if there were a plan of both measure 0 and measure 1 in P, we would be able to return as “generally correct” plans that in fact failed for large fractions of their linearizations. The requirement that there be infinitely many constants is a necessary one. If, for example, there were only 37 places to which an object could be moved, we could use the fact that each specific choice is of measure 0 in the overall plan to conclude that the union of all of them was-thereby violating Proposition 3.9. Similarly, if the set of actions we could take were circumscribed in some way, we could use Proposition 3.4 to find a counterexample to the above proposition. Finally, we present some technical results that we will need later. We begin by recalling the usual definition of convergence for a sequence Si of sets: Definition 3.10. Let Si be a sequence of (plan) sets. Then we will say that the Si converge to a set S if for any X, there is some index m(x) such that for i > m(x), x E Si if and only if x E S. M. L. Ginsberg/Artificial Intelligence 76 (1995) 89-l 23 99 Lemma 3.11. Suppose we have a sequence Pi of plan sets, where Pi+1 is of measure 0 in Pi for each i. Then the Pi converge to the empty set. Every infinite descending chain where each element is of measure 0 in the previous one converges to the empty set. It is not the case that there is no infinite descending chain of plan sets, each of measure 0 in the previous one. For any function constant f, we can get such a chain by considering [move(x,?)] 3 [move(x, f(?>>] 3 [move(x, f(f(?)>>l 3 -... Lemma 3.12. Suppose S is of measure 1 in T and of measure 0 in U. Then T is of measure 0 in U. Suppose that we denote by A 8 B the symmetric difference of A and B, so that AeB=(A-B)U(B-A). We now have: Proposition 3.13. Suppose that there is some set D that is of measure 1 in A 8 B and of measure 0 in A. Then A and B are approximately equal. 4. Planning Having introduced these notions, we need to use them to construct a planner. Before doing so, however, let me be clear about the problem that I am hoping to address. Our focus here is on planning itself, as opposed to reasoning about action or simulation. In other words, we will assume that the semantics of actions are somehow provided to us; somewhat more specifically, we assume that given a linear plan L and a goal g, we have some way to tell whether or not g holds after L is executed. From a formal point of view, we will assume that given a goal g, we can take L(g) to be the set of all linear plans that achieve g. The analysis we are about to present is independent of the specific semantics of action underlying the function L. In the examples, of course, we will need to rely on a specific semantics of action. For the blocks world, this semantics is presumably intuitive and corresponds to the usual STRIPS description. The only difference between our interpretation and the conventional one is that we need some way to interpret actions that are attempted even though their preconditions are not satisfied; we will take the view that such actions simply have no effect on the domain in question. We now make the following definition: Definition 4.1. A planning system P accepts as input a goal g and a plan set P. It returns a plan set P(g, P) c P that is approximately equal to L(g) 17 P. In some cases, we will assume that the goal is fixed, writing Pg for the corresponding function that accepts the plan set P only. 100 M.L. Ginsberg/ArtiJCcial intelligence 76 (1995) 89-123 The plan set P can be used to focus the planner’s attention on plans of a particular form. The condition that P(g, P) be of measure 1 in L(g) II P means that almost all- but not necessarily all-of the planner. In more picturesque terms, the planner is “approximately complete”. the plans in P that would achieve g are actually returned by The condition that L(g) n P be of measure 1 in P(g, P) means that almost all the plans returned by the planner achieve the goal; in other words, the planner is approximately correct. In a situation like this, where L(g) is of measure 1 in a plan set P, we will often say that P “generally achieves” g. In the remainder of this section, we will begin by discussing planning systems in general, describing implementation concerns that are likely to arise in their construction. There are then two technical issues that we will address. First, we will show that a planning system can be used to produce answers to planning queries that actually are correct and complete, at least in the limit. More precisely, we will show how a planning system can be used to construct a sequence of answers that converges on the actual set L(g). Second, we will show how a planning system can respond to a conjunctive goal gl A g2 by invoking itself only on the subgoals gi and g2 separately and then combining the results. More precisely, we will show how Ps,,,sz can be constructed from Pg, and Pg2. We begin by discussing Ps itself. On an intuitive level, the way Pg works is as follows: Given the goal g, we find the actions a that might succeed in establishing g. If the preconditions to these actions are in general satisfied (perhaps because these preconditions hold in the initial situation), we can take P(G) to be the union of plan sets of the form [... a . ..I for each action a achieving g. (13) If the preconditions of a are not in general satisfied, we can invoke P recursively on each precondition, merge the results to obtain plans that enable a, and then append a to the end of such plans. The result ( 13) is in fact a special case of this observation; if the preconditions to a are known to hold in the initial state [ 1, these preconditions also hold in a plan set that is approximately equal to [. . .] (the set of all plans). The expression ( 13) is simply the result of appending a to the end of such plans. We will see in what follows that we are often interested not only in P,, which constructs plans for achieving g, but also in Pig, which tells us which elements of a particular plan set _fuil to achieve g. This has obvious analogs in existing planners: (1) (2) (3) In a system like TWEAK-[ 11, the exceptions involve finding what Chapman calls clobberers. New actions that make the plan work after all are called white knights. McAllester and Rosenblitt [ 161 describe potential flaws in a plan (where one action might overturn the consequences of another) as threats. Overcoming the threats involves adding new actions to the plan that ensure that the consequences of the action hold after all. Finally, we will discuss in Section 5 the use of a declarative system to construct Pg and Pyg. M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 101 I Fig. 2. The Sussman anomaly. Before turning to technical issues, let us look at an example in a bit more detail. The problem we will consider is the well-known Sussman anomaly [ 191, shown in Fig. 2. The goal is to get A on B and B on C. At this point, we consider the subgoals separately. The first of these involves simply getting B on C. This is generally achieved by the Plan [ . . . move(B, C) . . .]. (14) Although there are instances of (14) that do not succeed in getting B on C, there are only a finite number of ways for this to happen-something must be put on B or on C, or B has to be moved away from C at the end of the plan. Each of these exceptions is of measure 0 in ( 14), which is why the plan ( 14) generally achieves on( B, C). Furthermore, move( B, C) in its add list, and the preconditions to this action hold in the initial situation. This implies that the plan set of ( 14) is approximately equal to the set of all plans for getting B onto C and we can take is the only action with on( B, C) P(on(B,C), [. ..I) = [.. . move(B,C) . . .]. (13 The two conditions of approximate equality are satisfied: Most plans that achieve the goal are instances of the above plan (in fact, they all are), and the exceptions are a set of measure 0 in (15). To continue the analysis, we compute P(lon(B,C), [. . . move(B,C) . . .I) in order to determine which elements of ( 15) are exceptions to the plan. There are two ways in which such exceptions might arise: One of the preconditions to the move action might fail to hold, or something might clobber the fact that B is on C after the action is executed. The action move(B,C) has two preconditions, that B be clear and that C be. B is clear in the initial situation, and the most general plan that clobbers this fact is [ . . . move(?, B) . . .]. It follows that the plan (14) will fail for the instance 1 . . . move(?, B) . . . move(B,C) . . .]. (16) 102 M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 to get B on C, but ( 16) is one general There are still more specific plans that do manage failure possibility. that the failed action of moving B to C simply has no effect on the locations of the blocks.) Another way for (14) that once we move something onto B, we are assuming to fail is given by (Recall [ . . . move(?, C) . . _ move( B, C) . . .] (17) where something is moved onto the top of C. The only remaining possibility is where B is not on C at the end of the plan because it is moved away. Combining this with (16) and ( 17), we see that we can take P(Ton(B,C),[... move(B,C) . ..I) =et Ue;?Ue3 to be the union of the following three sets of exceptions: el= I... move(?, B) . . . move( B,C) e2 = [. . . move(?,C) . . . move(B,C) es= [... move(B,C) . . . move(B,?) . . .], . . .], . . .]. Each of these sets is of measure 0 in ( 15), as is their union. If we wish, we can continue the process, computing P(on(B,C),el UezUes) (18) to find those elements of the exception we will see shortly, a sequence constructed the set of all plans that achieve The second goal on( A, B) is more complicated, the goal of getting B on C. set that achieve in this fashion will eventually the goal after all, and so on. As converge on but only slightly so. It is generally achieved by [ . . . move(C,?) . . . move(A, B) . . .]. (19) Once again, there are only finitely many ways for (19) be chosen poorly in the previous case. (In keeping with Proposition an infinite number of distinct complete for ? could actions could be added as that there are locations on the table to which C could be moved.) The (A and B are bad choices), or additional 3.9, we are assuming to fail - the binding list of exceptions is as follows: f, = [... move(?l,C) . . . move(C,?) . . . move(A,B) . . .] f2 = [... move(?l,?) _. . move(C,?) . . . move(A, B) . . .] f3 = [... move(C,?) . . . move(?l,A) . . . move(A, B) . . .] f4 = [. . . [move(?l, B) & move(C,?)] fs = [... move(C,?) fs = [... move(C,A) f7 =[**. move(C,B) . . . move(A,B) . . . move(A,B) . . .] . . .]. . . . move(A, B) . . . move(A,?l) . . .] . . . move(A, B) . . .] (20) In f4, we have extended our notation actions a and b without there being an ordering constraint between them. somewhat, writing a & b for the plan of taking M.L. Ginsberg/Artijcial Intelligence 76 (1995) 89-123 103 In less formal terms, the plan ( 19) can fail for the following reasons: ( 1) The attempt to move C out of the way can fail. This may happen because something has been moved on top of C ( fr ) or because something has already been moved to C’s intended destination (f~). (2) Something may be moved onto A (f3 or f6) or onto B (f4 or f7). We get two exceptions in each case here depending on whether the block moved into the way is C (fe and f7) or not (f~ and fd). (3) A may be moved off of B after it is put there (fs). Because all of the exceptions are of measure 0 in ( 19), ( 19) itself is a satisfactory choice for P(on(A, B), [. . .I). We also take P(lon(A,B), [. . . move(C,?) . . . move(A,B) . . .I) =Uft. We needed to be careful when constructing the above exceptions to take f3 as indi- cated instead of the more obvious choice fi = [. . . [move(?l,A) & move(C,?)] . . . move(A, B) . . .] (21) where we have allowed the action of moving something onto A to occur in parallel with the action of moving C out of the way. The reason is that if the action of moving ?I it won’t onto A is to interfere with the rest of the plan, this action must succeed-and unless C is moved out of the way first. Put more formally, the subset of f; that actually achieves on(A, B) includes a component that is approximately equal to [ . . . move(?l,A) . . . move(C,?) . . . move(A,B) . . .] (22) and is therefore not of measure 0 in f$. Again, recall that our semantics of failed actions is that they have no effect at all. Since A is not clear in Fig. 2, the first action of (22) fails and (22) effectively reduces to ( 19). From a computational point of view, it may be more attractive to work with f$ than to work with the more accurate f3 appearing in (20). The reason is that fi is already of measure 0 in the original plan ( 19), and it is simpler than f3 and therefore presumably easier to generate. It is obviously easier to stop as soon as a set of measure 0 in the original plan is encountered than to complete the analysis to obtain f3 instead of fi. This is exactly what commonsense planners should do-when we plan for one of a set of conjuncts, we only worry about what might go wrong until we feel confident in dismissing it. In our running example, we know that something will go wrong with the plan of moving A to B if we move an additional block onto A. The need for this extra action ensures that we are looking at a set of measure 0 in our overall plan, so we don’t think about it further. More specifically, we don’t bother to draw the conclusion that we can only move something onto A after C is cleared off the top of it. It is to remain in keeping with this approach that we may wish to work with fi instead of f3. The general version of this construction is similar. At each odd-numbered step (in- cluding the first), we look for plans that achieve the goal but that we have not yet identified. At even-numbered steps, we look for exceptions to the plans found thus far: 104 M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 Definition 4.2. Given a planning system P and a goal g, the planning sequence gener- ated by P for g is given by Pi-l(g) UP(g,P -Pi-l(g)), Pi(g) = Pi-l(g) -P(7g~Pi-l(g))9 if i is odd, if i is even. (23) The sequence is initialized by PO(g) = 0. Some notation will make this definition easier to work with. If we write ZJ for the symmetric difference between Pi and Pi-l, it suffices to describe only how Di is computed at each step. We know that Di has to be added to Pi at odd steps and removed at even steps. Now (23) becomes: P(g,P -Pi-l(g)), vi(g> = P(7g9Pi-l(g))9 if i is odd, if i is even. (24) Further simplification is often possible as well. If i is even, for example, we can evaluate (24) recursively to get (25) If we know that we caught all of the exceptions at the (i - 2) nd step, we will know that P( Tg, Pi-T(g)) = 8 and we can replace (25) with the simpler Di(S) =P(7gv~i-1(8)). (26) In a similar way, if we know that Di-1 (g) includes all the plans that achieve g at an odd step, we can conclude Di(g> = P(g, Di-1 (g) 1. (27) In both (26) and (27), the purpose of each step is to correct possible incorrectness in the previous step; possible incompleteness in the previous step is not an issue. We are now in a position to achieve the first of our two technical goals in this section: Theorem 4.3. Given a planning system P and a goal g, the planning sequence gener- ated by P for g converges to L(g). This result shows us how to construct a planner that is correct and complete from one that is approximately correct and approximately complete. Our remaining goal is that of showing how to combine the planner’s results for gl and for g2 to obtain a plan for gl A g2. Resumably, the semantics underlying L is such that a plan achieves the conjunctive goal gl A g2 if and only if it achieves both gl and g2, so that ml A g2) = Ug1) f-l L(g). M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 105 The following result is now obvious: Lemma 4.4. Suppose that PI achieves a goal gl and that P2 achieves g2. Then PI f~ P2 achieves gl A g2. 0 The problem, of course, is that PI f~ P2 may well be empty linear plans that achieve that the plans generally achieve achieves on( B, C) and that ( 19) generally achieves on( A, B) to conclude solution if PI and P2 are specific to require only their goals, we could use the fact that ( 14) generally that a general the goals. If we could weaken to the Sussman anomaly the above lemma is [ . . . move(B,C) & [move(C,?) . . . move(A,B)] . . .]. (28) involves This plan three actions-moving B to C, moving C out of the way, and moving A to B. C must be moved before A is put on B, but there are no other ordering to the Sussman anomaly, since constraints it allows the action of moving C out of the way. Here is the general problem: the action of moving B to C to precede involved. Unfortunately, this is not a solution Proposition 4.5. There exist plans PI, P2, Ql and Q2 with Qi of measure 0 in Pi but Ql fl Q2 of measure 1 in PI n P2. The Sussman anomaly isn’t quite this bad; the correct plan [.._ move(C,?)... move(B,C)... move(A,B) . ..I is neither of measure 0 nor of measure 1 in (28). (28) would generally were of measure 0, (28) would some of the time and fails in others; then the original goal of getting A on B and B on C; if it the goal. In fact, it succeeds If it were of measure 1 in (28), fail to achieve it depends only on how we order the actions. in general achieve The tower-construction problem of Fig. 1 is an example where Proposition 4.5 does hold. The plan [ . . . move( B,C) . ..I gets B on C, and [ . * . move(A, B) . . .] generally gets A on B. Nevertheless in the plan for constructing the tower is of measure 0 [ . . . move(A, B) & move( B,C) . ..I because we must proposition, sets for these plans. take the additional the Pi are the plans for achieving action of moving C to the table. In terms of the the subgoals, and the Qi are the exception We cannot necessarily merge specific plans for achieving the individual Nor, as Proposition 4.5 tells us, can we necessarily find a plan for the conjunctive conjuncts. goal 106 h4.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 by merging plans for generally achieving consequence an immediate of Theorem 4.3: the conjuncts. But we do have the following, Corollary 4.6. Given a planning system P and goals gl and g2, denote by Pi(g) planning sequence generated by P for g. Then the sequence the Pi(gl) n Pi(g2) (29) converges to L(gl A gz), the plan for achieving the conjunction of gl and gz. 0 This result is evidence the limit in (29) will not be viable that we are on the right track, although we need to do a bit in practice. More precisely, we need of Definition better-taking a way to compute Pg,,,gz that we can guarantee 4.1, To see how to do this, let us look at the Sussman anomaly to satisfy the requirements the first two terms in the planning in a bit more detail. sequences for We already know how to construct the subgoals; they are Pt(on(A,B)) = [... move(C,?)... move(A,B) . ..I. Pz(on(AW) =PI(MA,B)) -(J.fi, Pi(on(B,C)) = [. . . move(B,C) . . .], P2(on(B,C)) = Pt(on(B,C)) -Uei, where the ei and fi are given by ( 18) and (20) respectively. Let US denote the conjoined first element of this sequence sequence is given by in (29) by simply Pi. It now follows that the P, = [... move(B,C) & [move(C,?) , . . move(A,B)] . . .]. (30) The second element of the sequence either ( 18) or (20). We can compute involves removing these by combining, from Pt for example, the exceptions the plan in et = [... move(?l, B) . . . move(B,C) . . .] which is one of the three sets removed from Pt (on(B, C)), with [. . . move(C,?) . . . move(A,B) . . .] (31) (32) is the original Pt (on( A, B)). which and Pt (on( A, B)), which The result of this particular merge (We have standardized apart the variables in et is why the ? in (18) has been replaced with ?l in (31).) is the following set of three plans: [ . . . [move(?l, B) . . . move(B,C)] & [move(C,?) . . . move(A,B)] . . .], (33) 1 . . . move(C,?) . . . move(A,B) . . . move(B,C) . . .], [ . . . move(C, B) . . . [move(B,C) &move(A,B)] . ..I. (34) (35) The first of the above plans is the “obvious” merge where the two separate plans are to A and the first the variable ?I In the second, in parallel. simply executed is bound M.L. Ginsberg/Arti$cial Intelligence 76 (1995) 89-123 107 in et is identified with the second action action resulting action sequence The third plan is similar, with ? being bound Each of the three plans fails to achieve is accumulated in Pt (on( A, B) ). The ordering on the from the orderings on et and on Pt (on( A, B) ) . to B and ?l bound to C. new (and currently unidentified) before B is moved onto C. And finally, C itself is moved onto B in (35). the subgoal of getting B onto C. In (33), a block is moved onto B. In (34)) A is moved onto B (34) It is only that is of interest it involves an additional the variable ?. As we have already remarked, is of measure 0 in the set of exceptions because is of measure 0 because tells us that if we move A it binds to B before moving B to C, we will not achieve our overall goal because B will be occupied when we try to move it. to us. The plan (33) action, and (35) (34) We can continue in this fashion, accumulating all of the exceptions (30). In addition to (34)) the only plan not of measure 0 in the set of all exceptions to the overall plan is [ . . . move(B,C) . . . move(C,?) , . . move(A, B) . . .] is part of the result of merging PI (on( B, C) ) and ft ; this tells us that if we which move B to C too early, our plan for getting C out of the way en route to moving A will fail. We can conclude from all this that a generally valid plan for solving the Sussman anomaly is given by removing from the plan (30) the union of the two plans [ . . . move(C,?)... [... move(B,C)... move(A,B)... move(B,C) move(C,?)... move(A,B) . ..I. . ..I. The result is equivalent to the plan [. . . move(C,?) . . . move(B,C) . . . move(A,B) . . .] (34) which is indeed the usual solution to the original problem. Here is the result dealing with the general situation: Theorem 4.7. Suppose the plan sequences Pi converging we can always$nd 0 in Pin Qj. For any such i and j, Pi n Qj will be approximately that we have a conjunctive goal gl A g2 and a set P. Construct f~ P. Now an i and a j such that both Pi 8 Pi+, and Qj 8 Qj+l are of measure equal to L( gl Ag2) n P. to L(gl ) n P and Qi converging to L(g2) In our analysis of the Sussman anomaly, we actually terminated the construction of the than the points sanctioned by the above result. the for example, reflects some lookahead on our part; consider, plans for the subgoals somewhat earlier This early termination fact that the exception et = [... move(?, B) . . . move( B, C) . . .] to the plan for getting B on C, when combined with the plan [ . . . move(C,?) . . . move(A,B) . . .] (37) (38) 108 M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 A B C D Fig. 3. Get A on B on C without building a four-block tower. for getting A onto B, led to the exception [ . . . move(C,?) . . . move(A,B) . . . move(B,C) . . .] (39) to the general plan of moving B onto C in combination with (38). It turns out, however, that one set of measure 0 in el that actually achieves on( B, C) is [ . . . move(A,B) . . . move(B,C) . . .]. (40) The reason for this is that the initial action of moving A to B will fail (C is still in the way), so B will wind up on C after all. Now (39) is an instance of (40) and therefore might not be an exception to the general plan of getting B onto C. The recognition exception A to B to succeed indeed be blocked. getting B on C, but that binding ? to A in [. . . move( ?, B) . . . move( B, C) . . .] is an to the overall plan is subtle. Roughly speaking, we need the action of moving so moving B to C will to the plan for (in order to achieve In terms of Theorem 4.7, (40) the other subgoal), isn’t an exception [ . . . move(C,?) . . . move(A,B) . . . move(B,C) . . .] (41) and that’s what matters. Once we have identified (41) as an exception of Theorem 4.7 are satisfied and we can construct is an exception, to the original plan, the overall plan (36) with confidence. let us consider As a final example, the conditions problem once again. The in Fig. 3; recall that the goal is to get A on B and B on C without the tower-construction is repeated problem ever building a four-block sequence The planning tower. for getting B on C begins with PI = [... move( B, C) . . .] and exceptions given by el=[... move(?,B) . . . move(B,C) . . .], e2=[... move(?, C) . . . move( B,C) . . .], e3=[... move(B,C) . . . move(B,?) . . .], e4=[... move(?,?l) . . . move(C,?) . . . move(B,C) . . .]. (42) (43) M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 109 The final exception above involves situations where B cannot be moved four-block (43) be generated In practice, however, tower is involved. the exception than is to C because a to is less likely e;= [... move(C,?) . . . move(B,C) . . .]. (44) that putting B on C can never violate We realize constraint unless we first move C somewhere. We will temporarily work with e: instead of e4, just as we in (20) in the Sussman indicated anomaly. the possibility of working with fi in (21) the four-block instead offs In a similar way, the planning sequence for getting A on B begins with Q, = [... move( A, B) . . .] and exceptions f,=[... move(?,A) . . . move(A, B) . . .], fz=[... move(?, B) . . . move(A, B) . . .], f3=[... move(A, B) . . . move(A,?) . . .], fi=[... move(B,?) . . . move(A,B) . . .]. When we combine this sequence with the previous one, we get Pl nQl = [... move(A,B) &move(B,C) . . .] and the exceptions include g1=[... move(A,B) . . . move(B,C) . . .] gz=[... move(B,C) . . . move(A, B) . . .] together with sets of measure 0 with respect to these. But g1 ug2= L... move(A, B) & move( B, C) . . .] (45) (46) (47) (48) since both possible orderings can’t put A on B first because we will then be unable on C first because cannot be added. this might (and are eliminated. From a commonsense in fact does) make a three-block point of view, we to get B to C, and can’t put B tower to which A There are two ways in which the analysis can be extended. The exceptions (47) and (48) are the result of intersections with (42) and (46), so one of these two sets must be analyzed to work on this first, to leading further. Since fi is an approximation, it seems natural f,=[... move(?,A) . . . move(A, B) . . .], f2=[... move(?, B) . . . move(A,B) f3=[... move(A, B) . . . move(A,?) . . .], . . .], 110 M.L. Ginsberg/Art$cial Intelligence 76 (1995) 89-123 f4=[... move(B,C) . . . move(A,B) . . .], fs=[... move(?,?l) . . . move(B,?) . . . move(A,B) . . .]. (49) (50) (50) indicates that one way to make B the top block in a three-block is to move ? to ?l and then B to ?. This (45), however, so we need not worry about is still enough finding exceptions to (49), tower, and finding exceptions is of measure 0 in our prospective to to invalidate our original plan. We now have to choose finding a way to move B to C without creating a finding a way to move A to B before it4 The problem continues to (42), line The final stack solution be (49), which between three-block moving B to C. Let us suppose that we choose wrongly, so that we now have to look for instances of [ . . . move(?, B) . . . move( B, C) . . .] for which B actually ends up on C after all. Here is the most general solution: [. . move(?, B) . . . move(‘?,?l) . . . move(B,C) . . .]. (51) Unfortunately, to A and now this doesn’t help us with our original difficulty, since we need to bind ? [ . . . move(A, B) . . . move(A,?l) . . .] (52) is known to be an exception that fails to get A onto B. So we turn our attention to (49) ; if we begin by moving C, then we will in fact be able to move A to B after all. So we can achieve on(A, B) using the plan 1 . . . move(C,?) . . . move(B,C) . . . move(A, B) . . .]. (53) this still might not work, since moving C (potentially in getting B to C as indicated Unfortunately, three-block (44) plan appropriate goal of getting A on B and B on C. stack) may cause a problem for achieving (43), allowing us to conclude this subgoal. But now we finally replace that (53) does indeed generally achieve to the top of a in the original (44) with the more the The analysis would be very different if we were to work with a more conventional the fact that we cannot build a four-block planner. There, adding a new precondition either y must be on the table, or it must be on a block that is on the table. to the move operator, saying tower would be encoded by that in order to move x to y, Now when we try to move B to C, we will naturally generate the plan of first moving C to the table (since C being on the table is one possible way to achieve the disjunctive to solve the problem but the plan itself precondition). has been constructed to an identified bug in the simple plan of putting B on C and then A on B. This plan can then be extended instead of in response blindly In our approach, (53). A plan the problem to overcome and needed, and not as part of a general attempt is identified the four-block difficulty to get B onto C. in (46)) which is later refined is generated only when into (49) it is 4 As in the Sussman anomaly, we actually need to be a bit more careful but the details are not of interest. M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 111 is another difference in the treatments of this example as well. Consider a planner There conventional to move A to B. When to be modified, much work crucial for achieving to avoid replanning this subgoal that proceeds by first planning to move B to C, and then planning the ensuing backtrack will discard is lost in our simple example, but in more complex problems the difficulty is found and the plan for getting B onto C has the plan for getting A onto B. Not it may be for the goal of getting A onto B. After all, the existing plan is the correct one. The approach that we have described behaves in this fashion. The successive refine- ments to the plan for getting A onto B, beginning with the basic plan [ . . . move( A, B) . . .] and eventually culminating in [. . . move(C,?) . . . move(B,C) . . . move(A,B) . . .] plan (54). to use the fundamental in our approach, since we proceed by gradually all continue discarded are suggested by the merging computations subgoals. with the basic plans of moving B to C and A to B, and then debugging leads methods. In fact, work is in some sense never refining plan sets in ways that among interactions the tower is built up by starting the result. This than that associated with conventional to a much more focussed the plan for constructing and by corresponding In our framework, search process 5. Implementation considerations In order to actually build a planning of plan sets, including there are three separate problems the manipulation Second, we need to describe the first place. And finally, we need to discuss like Theorem 4.7; there are several simple more effective in practice. with these issues in this order. (Witness system based on the ideas that we have described, that need to be addressed. First, we need to discuss operation of plan intersection. the underlying the construction of a system that can produce the plan sets in results ideas that can make this result substantially details surrounding implementation the footnote in the previous section.) We will deal 5. I. Plan intersection and manipulating plan sets there that more Plan intersection a variety of authors; described possibility language that the actions is obtained. As a result, focus in Section 2. is more restricted is often known as plan merging and has already been discussed by typical is the treatment of Foulser et al. [ 41. The construction than is related to ours, although not identical. Foulser et al. allow for the two plans be merged at once, but their plan description they assume than ours. In keeping with conventional in a plan are sequential; no others can be interspersed as new information interests, they do not draw the distinction between < and * that was our 112 M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 Nevertheless, the ideas introduced by Foulser and his coauthors [4] can be used to implement our somewhat more general notion of plan intersection. The method used continues to be that of treating sequences of actions (actions related by Z in our notation) as atomic units, and then merging larger structures made up of these units. The details are not of any great theoretical interest and the interested reader is referred to the code itself. 5 One thing that does bear mention is that the result of intersecting two plans may be a plan set that cannot be represented as a single plan; witness the construction of (33), (34) and (35) from the intersection of (3 1) and (32). The implementation obviously needs to cater to this possibility. Manipulating general plan sets is a bit more interesting. This is quite a difficult problem but is made simpler in practice by the recognition that the plan sets under consideration are generally of the form D,-D2UD3-D4UD~-..~ (55) where the Di are the symmetric differences of successive ‘Pi and are in general fairly simply represented. The evaluation here is intended to be from left to right, so that (55) is in fact (((D,-D2)uD3)-D4)uD5-.... The implementation is constructed in just this way, representing any particular plan set as an alternating sum such as (55). Taking the union or intersection of these alternating sums is tedious but not terribly difficult. Of course, the manipulations involved are fundamentally dependent on the plan in- tersection operation that we described earlier. Existing planners work with global data structures, gradually accumulating actions into an overall plan. This makes their plans somewhat brittle, since they will need to discard a great deal of existing work when a portion of the plan changes. A system such as we have described plans for subgoals separately but must frequently merge the plans involved in order to understand possible subgoal interactions. The upshot of this is that the speed of a planner built on our ideas will be crucially dependent on the speed of the underlying mechanism for plan merging; as Foulser et al. point out, plan merging can be exponentially expensive. They also point out, however, that this exponential expense appears not to be incurred in practice because the plans being merged consist of small numbers of linear segments. This matches our experience. Finally, since specific plan segments tend to appear many times in the analysis, the overall computation can be speeded substantially by caching the results of the merging computation in some way. 6 ’ The code described in this section is part of the MVL obtained by anonymous ftp from t.uoregon.edu. theorem proving system [ 5,9,11], which can be. 6 More effective still appears to be to cache the results of the plan instance computation. M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 113 5.2. Constructing plan sets Given an implementation that manipulates plan sets, from where are we to obtain these sets in the first place? There are three sources: ( 1) Information about the initial situation (corresponding to the plan [ ] ) can be encoded in this fashion. Thus in the tower-construction example, we know that on(C, D) is generally achieved by the universal plan set [. . .]. is definitely achieved by the plan [ 1. It follows that on(C, D) (2) Information about actions occurring (although perhaps not succeeding) is en- coded similarly. For any action a, the statement “a has just occurred” is true for [... a]. What this says is that a occurs at the end of any sequence of theplan actions that does indeed end in a. (3) Finally, there are operations that transform plan sets into new plan sets. We have already seen one of these in the form of intersection; another corresponds to the frame axiom in our setting. Definition 5.1. There exists a frame operator F that accepts as input two plan sets and returns another plan set. The operator is defined so that if a particular goal or fluent g is inserted into the database by those plans in the set P+ and deleted from the database by those plans in P-, then L(g) = F(P+, P-). Somewhat less formally, the goal is achieved by plans in F( P+, P- ) and not achieved by plans outside this set. Note that the equality in the definition is exact, not approximate. As an example, we would expect to have F’([ 1,0> = [...I. (56) What this tells us is that if a fluent is true in the initial situation, and we know of no reason for it to be false in other situations, we can expect it to be true at all times. Here is another example: F([... a],0> = [... a . ..I. If an action a succeeds in achieving a goal and no other actions delete that goal, then we can use the frame axiom to conclude that the goal continues to hold after additional actions occur. Here is a slightly more interesting example. Suppose that some goal is added to the database by the plan [. . . a] but deleted by [. . . b] . What should 3( [. . . a], [. . . b] ) be? The result should be [... a . ..I-[... b...]U[... b... a...] (57) since if both actions a and b occur, the goal will be true only if a occurs after b does. This fits neatly into the implementation details already discussed; the plan set (57) is conveniently written as an alternating sum. 114 M.L. Ginsberg/Art$icial Intelligence 76 (1995) 89-123 It is because of examples such as this one that the operator 3 find a unary 3’ such that plan sets. We cannot is defined on pairs of 3(P, Q> = 3’(P) - 3'(Q) because, as we see from (57), the plan sets P and Q interact in the construction of 3(P,Q). The reason is important indicate only which actions actually the frame operator is because a planning database will typ- the domain there will be no explicit description of the set of plans that achieve a given that add g to the these plans, we have to find the plans the plan set in its and then use the frame operator 3 to actually construct add and delete ically description; goal g. In order to construct database, entirety. Working with actions that delete g allows us to compute P-,g similarly. fluents from In all of the examples we have encountered, Q and Q’ are as well, then 3( P, Q) is approximately should be if our ideas are to be usefully incorporated axiom; notion of when one set of plans it also serves to provide is small relative to another. if P and P’ are approximately equal and equal to 3( P’, Q’). This is as it that use the frame into systems loose confirmation of the utility of our measure-theoretic The function 3 has a variety of analogs in earlier work. We have already to the frame axiom; since on its clear connection plans where facts are added or deleted from the database and returns when and others have called it is also the analog the modal truth criterion [ 11. those facts hold generally, it is accepts remarked the about about in our setting of what Chapman information information isomorphic to the set of functions The collection of all plan sets is a lattice under the subset relation; more formally, set of plan sets is naturally plans into the two-point if p E P and P(p) = f otherwise. The set 2’ inherits a lattice structure structure on 2, and [ 51. A function modal operator [ 71 because the existing notion of modality modal operator be viewed modally. the from the set S of linear set 2 = {t, f}. For a particular plan set P and plan p, P(p) = t from the lattice to embed 2’ in a bilattice is referred to as a relationship between such functions and community, is indeed a and 3 [ 6 3 that the frame operator can [ 151 in the philosophical in this setting. I also suggest elsewhere that maps bilattice elements it is not hard to extend to new bilattice elements there is a natural this structure The point of this embedding setting. We can use the declarative mechanisms in a bilattice framework purpose planner but can instead All we need do is provide a declarative description of action. is that it allows us to treat 3 as a semantic object that exist in the bilattice the plan sets in question; we do not need to construct a special- theorem prover 19,111. resort to a general multivalued to manipulate The first axiom in this declarative description needs frame the statement “g has just been achieved”. is true for plans sets that terminate with an action that adds g; “g has just to capture a STRIPS-like axiom as in Definition 5.1. To do this, consider This sentence been removed” formalize is true for plan sets that terminate To triggers(g) g has just been deleted. Using this, we to mean in actions deleting g. reify g and add a predicate triggers; that g has just been added and triggers(lg) we wiii to mean take that the frame modality 3, we can now write M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 115 F[triggers(g),triggers(lg)] 3 holds(g). This allows us to use the information sets for which g holds). in F to find plan sets that achieve g (i.e., plan The rest of the axiomatization defines the extent of triggers: adds(a,p) Asucceeds >triggers(p), deletes( a,p) A succeeds(a) > triggers( lp), occurs(u) A precs( a, 1) A precs-ok( I) 3 succeeds(u), holds(p) A precs-ok(l) > precs-ok( [PI/] ), precs-ok( [ I). (58) (59) (60) (61) (62) the remaining (58) and (59) and succeed Axioms to the database, succeed-they of preconditions an empty and (62) are lists of preconditions if they occur and all of their preconditions tell us that successful actions add and delete facts as appropriate under which actions are satisfied. A list if the first one is and all the rest are; the ground case is that in (61) is always satisfied. The bracketed expressions and should not be confused with plans. list of preconditions axioms describe is satisfied situations Finally, we need to identify situations is assigned init occurs(u) [ ] where set instead say that init would be somewhat initial situation by writing, the plan set [. . . a] and succeeds( init) that sets up the initial in the initial situation and has no preconditions, in which actions occur, so that the sentence the plan (We could but that the is assigned information situation. about is a dummy action occurs less compact.) We can now add specific that for example, adds(init, on(C, 0)) to say that C is on D in the initial situation. for planning purposes, of action There are other advantages to exploiting this approach allows us to use a declarative description the bilattice machinery a noise) since procedural one. We can add actions effect (boiling water comes balloon causing on the values of other fluents declarative needed the declarative with hierarchical framework language, planners. and continues to mind), have effects without duration instead of a that require some variable amount of time to take a to be computed based in the same overall the machinery into the ideas typically associated [ 121, we can also introduce defaults [3,13]. All of this work remains to use this framework (like popping in our setting to provide that need for planning. As discussed elsewhere [ 81, or have ramifications thereby capturing 5.3. Status The current implementation is a good-but not perfect-match constructs The examples of Section 4 make some specific control assumptions that we have discussed. Plans and plan sets are both implemented for the theoretical as described. the nature about 116 M.L. Ginsberg/ArtiJcial Intelligence 76 (1995) 89-123 of the search, and these control decisions are not yet supported by the implementation. (In a bilattice setting, they appear to be restrictions to planning of more general control heuristics, and we are attempting to implement these general control notions as opposed to specializations of them.) Rather than invoke Theorem 4.7 directly, the planner works by determining at each point whether a particular line of reasoning will have a significant impact on its overall answer. In other words, it decides whether or not its answer would change on a set of measure 0 relative to the current value. This is in keeping with the analysis of Section 4, where we curtailed some portion of the analysis as soon as we could tell that the answer didn’t matter. Theorem 4.7 guarantees that there always will be a point at which things are clearly irrelevant; the implementation is often able to terminate its reasoning before the conditions of the theorem are satisfied. Most of the time used by the planner is spent in reasoning of just this sort, deciding whether a particular line of reasoning might impact the plan being generated. 6. Conclusion My overall aim in this paper has been to describe a single idea: that planners should manipulate not specialized plans that are guaranteed to achieve their goals, but more general plans that can only be expected to. We have presented a formalization of this idea of “expecting” a plan to achieve a goal in terms of the plan failing for a set of measure 0 in the set of its possible executions. Building a planner around this idea introduces additional possibilities that existing planners lack; most important among these is that it is possible to combine approximate plans for each of two subgoals to obtain an approximate plan for their conjunction. The main technical result of the paper is Theorem 4.7, which confirms this observation. An examination of the tower-construction problem indicates that such a planner will have advantages over a conventional one in that it will debug plans constructed using independence assumptions as opposed to catering to all possible plan interactions at the outset. Finally, we discussed briefly an implementation of our ideas that exploits the fact that plan sets can be viewed as elements of a bilattice. As mentioned in the introduction, some existing planners such as O-Plan appear to make informal use of the ideas that we have discussed, but we know of no planner that explicitly conforms to the notions we have presented. A preliminary implementation of such a planner has been built using the bilattice-based theorem prover MVL [ 113, but many implementation issues remain to be addressed. Dealing with these is the topic of ongoing research. Acknowledgement I would like to thank David Etherington, Nir Friedman, Will Harvey, Jim Hendler, David McAllester, Drew McDermott, Steve Minton, Dan Weld, David Wilkins, two M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 117 anonymous reviewers and the members of the PRINCPIA and GIRL research groups for many useful discussions regarding these ideas. Appendix A. Proofs Lemma2.4. rf(A,<,*) (1) Ifa*banda*c, (2) Zfa*candb*c, isaplan, thenb=c. thena=b. thenforanya,b,cEA: Proof. If a * b and a * c, then a * b and a < c, so that b < c. Since a * c and a < b, c < b as well; thus b = c. The second claim is similar. 0 Lemma25 Let (A,<,*) (1) Ifc<bandc?a, (2) IfbGcandaZc, Thenforanya,b,cEA: beaplan. theneithercTbora<b. theneitherbTcorb<a. Proof. Suppose that c < b and c T a but not c T b. We prove that a 6 b by induction on the length of the chain c = CO * . . . * c, = a. If n = 0, then c = a and since c < b, we have a 6 b. For the inductive case, suppose that the lemma holds for chains of length n - 1. Then in the above example, since c * cl and c < b, we must have cl < b. Since cl T a as well, we can apply the inductive hypothesis to conclude a 6 b. 0 Lemma2.6. then a Z c. Let (A,<,*) beaplan. Thenforanya,b,cEA, ifa*banda<c<b, Proof. Suppose we have a = a0 * . . . * a, = 6. For each ai in the chain, if ai- < c, we can conclude that ai < c. Thus if aj < c for each j, we eventually conclude b < c, so that b = c. It follows that c actually appears somewhere in the above chain, so that a ?; c. 0 Proposition 2.9. The instance relation of Definition 2.8 is a partial order. Proof. That the relation is reflexive and transitive is clear; to see that it is antisymmetric, if (~1 is the binding list associated with showing that p1 is an instance of p2 and ~72 is the binding list showing that p2 is an instance of ~1, then for any action a in ~1, we must have alv,la2 = a, so that the actions differ only in the names of the variables. 0 Lemma 2.11. If P = (A, <, *) is a linear plan, then < is a total order. 118 M.L. Ginsberg/Artficial Intelligence 76 (1995) 89-123 Proof. Suppose 6 = % , there must be bi and c; such that that we have a < b and a < c with b and c unordered. Then since a * bo * . . . * 6, = b a * CO * . . . * c, = c. in the other, then we will have b < c or the sequences differ, is a single point bi-1 with bi_1 * bi and bi_1 * ci but bi f ci, in conflict with If either of the above sequences c < b, so suppose otherwise. Now if i is the first point at which there Lemma 2.4. Cl is contained Proposition 2.12. 9 C P2 if and only if the set of linearizations of PI is a subset of the set of linearizations of P2. Proof. One direction because C is transitive. is easy: if PI C P2, every instance of PI is an instance of P2 list u and injection i that embeds P2 in L. If we modify For the other direction, that every of P2 = (AZ, <2, *2). Specifically, suppose linearization consider to a total order and the actions to unique Skolem constants. Since the variables linearization has been extended binding there must be a binding change list CT’ and injection to show that i preserves < and *. If we had a * b in P2 without the Skolem constants back to the variables they represent i : A2 4 AI that injects the actions of PI = (Al, <I, rl) is a the linear plan L in which 61 in Al have been made ground by of P2, (+ to this is a linearization in Al, we get a binding in A2 into Al. It remains only an extra action between a and b in the linear plan L to construct linearization of PI but not of P2, so it follows that * is preserved. the corresponding relation holding in PI, we could add that was a a plan suppose To see that < is preserved, that a < b in P2 but not in PI. Now it follows that in PI, where a $ b, if a F c or c _* a, we must not have c < b to a by * . We to satisfy Definition 2.2 if we add (in PI ) that b < c for all such points; that P2 this is a Thus whenever a < b in 4, a ,< b in PI as well. < is preserved by i, from the lemmas either. Thus b is unordered can continue suppose that we call the resulting plan P,‘. It is clear that P,’ has linearizations lacks, since a > b in PI but a f b in P2. But since P,’ is an instance of 4, contradiction. and the proof is complete. to all the points related in PI with respect 0 Proposition 3.4. Let P be a plan, and P’ an instance of P with i the associated injection from A to A’. Then if there is any action in A’ - i(A) that is not a variable, P’ is of measure 0 in P. that is identical in Proof. Let P” be a plan A’ - i(A) has been replaced with a new variable. Now it is clear that P” is an instance of P, and that P’ is of measure 0 in P” (since the new variable). Thus P’ is of measure 0 in P. to P’ but where some nonvariable it binds action 0 M.L. Cinsberg/Ar#cial Intelligence 76 (199.5) 89-123 119 Lemma 3.6. Q is of measure 0 in P if any of the following conditions holds: (1) Q is empty. (2) Q is a subset of a set of measure 0 in P. (3) Q is of measure 0 in a subset of P. (4) Q is of measure 0 in a superset S of P with P of measure 1 in S. Proof. ( 1) The empty set is the finite union of no sets, each of which is of measure 0 in P. (2) Take R to be the given set of measure 0 in P, and S = P. (3) Take R = Q and S to be the given subset of P. Now S - P = 0. (4) Take R = Q and S as given; since P is of measure 1 in S, S - P is of measure 0 in S. Cl Lemma 3.7. Q is of measure 0 in P if and only if Q is of measure 0 in P U Q. if it is of Proof. Since P C P U Q, it is clear since measure 0 in P. For the converse, Q is of measure 0 in S, we must have S - P of measure 0 in S as well. Thus Q is of measure 0 in P. that Q is of measure 0 in the union take R = Q and S = P U Q in the definition; 0 Proposition 3.8. Approximate equality is an equivalence relation. Proof. That approximate show that it is transitive. To see this, suppose is approximately measure 1 in X is similar. is reflexive and symmetric is clear; we need only equal to Y and Y to Z. We will show that X is of measure 1 in Z; that Z is of that X is approximately equality equal We need to show that Z - X is of measure 0 in Z. but we know that z-XC(Z-Y)U(Y-X). (A.1) The first term here is of measure 0 in Z because Y is of measure 1 in Z. The second term is of measure 0 in Y; since Z is of measure 1 in Y, it follows term is of measure 0 in Z as well. Thus the union is of measure 0 in Z and X is 0 of measure 1 in Z. that the second in (A.l) Proposition 3.9. Let P # 8 be a plan set. Then provided that our language includes infinitely many object and action constants, there is no plan set that is both of measure 0 and of measure 1 in P. Proof. The proof of this result Proposition 3.3 of [lo]. is essentially unchanged from that of the analogous If there were a subset Q of a plan set P that was both of measure 0 and of measure 1 in P, then we could repeatedly apply the secondary clauses of Definition 3.3 to construct a finite collection of plan sets Qi and a plan set S = Ui Qi such that each Qi = SI, for some nontrivial Ui. 120 M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 loss of generality We can suppose without general case is no harder. For Sj an arbitrary Skolem constant a linearization Qi = SICi only if (pi binds ? to Sj, it follows various Sj. Since be the union of finitely many Qi. a single variable ?; the let Sj be to Sj. Since Sj will be an instance of that each Qi can contain at most one of the there are an infinite number of Skolem constants available, S cannot of S in which ? has been bound in our language, that S contains 0 Lemma 3.11. Suppose we have a sequence Pi of plan sets, where Pi+1 is of measure 0 in Pi for each i. Then the Pi converge to the empty set. linear plan that appears loss of generality these assumptions, Pi must have been constructed Proof. Let P be an arbitrary consider only the subsequence without and only if it is of measure 0 in the union Pi U Pi+, ; we can also assume is a minimal such set such that Pi+1 is of measure 0 in Pi. Given in infinitely many of the Pi, and of the Pi’s whose elements contain P. We can assume that each Pi contains Pt+l, since Pi+1 is of measure 0 in Pi if that each Pt a subexpression with a variable move( x, ?) ) or by introducing in the plan. Since contain at most n subexpressions where every element contains P will be n*. This is in conflict with the assumption P appears from Pi+1 by either replacing ) with replacing move(x, block-on(?) to replace an object constant or variable it will length of a chain that if the eventual plan P contains n object or action constants in infinitely many Pi, and the proof is complete. (for example, a new variable as well, it follows that the maximum 0 Lemma 3.12. Suppose S is of measure 1 in T and of measure 0 in U. Then T is of measure 0 in U. Proof. We show instead that T is of measure 0 in T U U, which is equivalent. We know that T - S is of measure 0 in T, thus of measure 0 in T U U. S is also of measure 0 in TUU,soTc(T-S)USisofmeasureOinTUUaswell. 0 Proposition 3.13. Suppose that there is some set D that is of measure 1 in A 8 B and of measure 0 in A. Then A and B are approximately equal. Proof. SupposethatA-B=FandB-A=E,sothatA8B=EUF.NowifDisof measure 1 in E U F and of measure 0 in A, we know that E U F must be of measure 0 in A. Thus F is of measure 0 in A and B is of measure 1 in A. But we also have that since E U F is of measure 0 in A, it is of measure 0 in A U E U F = B U ‘F. Thus F is of measure 0 in B U F, and F is of measure 0 in B. In other words, B is of measure 1 in B U F. Since E is also of measure 0 in B U F, it follows that E is of measure 0 in B and A is of measure 1 in B. Thus A and B are approximately equal. 0 Theorem 4.3. Given a planning system P and a goal g, the planning sequence generated by P for g converges to L(g). M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 121 Proof. We begin by showing that the sequence converges, and then argue that it con- verges to L(g). To see that it converges, it suffices to show that the symmetric differences between successive elements of the planning sequence converge to the empty set. But at each step of the construction we will have (for example) Q(g) = P(% R-1 (g) ) for i even. Now we know that L( Tg) fl Pi-1 (g) is of measure 1 in Dii, but since Pi-t (g) = Pi-z(g) U Di_1, we GUI conclude that But we also know that [ L( lg) nPi_2(g) ] is of measure 0 in 24_2, since the i-2nd step was supposed to remove all plans that failed to achieve g. Similarly, [ L( -g) fl Di- 11 is of measure 0 in Di_ 1, since the i - 1 st step was supposed to add only plans that did achieve g. It follows that ]L(lg) nPi-2(g)] U [L(3) nQ-11 is of measure 0 in Di-1 U Vi-27 and thus by Lemma 3.12 that ‘Di is of measure 0 in Vi-1 U Di-2. This result holds for odd i as well by virtue of a similar argument. NOW suppose that we construct a new sequence Si, where Si = D2i U Dzi+t . We can apply Lemma 3.11 to conclude that the &‘i converge to 8, from which it follows that the Di do as well. Thus the planning sequence converges. The argument that it converges to L(g) is similar; at each step in the construction, we remove a set of measure 1 in the remaining error. Thus the sequence of symmetric differences between Pi(g) and L(g) also converges to 0, and the proof is complete. q Proposition 4.5. There exist plans Pi, 4, Ql and Q2 with Qi of measure 0 in Pi but Ql n Q2 of measure 1 in PI rl P2. Proof. An example follows the statement of the proposition in the main text. q Theorem 4.7. Suppose that we have a conjunctive goal gl A g2 and a set P. Construct the plan sequences Pi converging to L(gl) n P and Qt converging to L(g2) fl P. Now we can always$nd an i and a j such that both Pi 8 Pi+, and Qj 8 Qj+l are of measure 0 in Pi nQj. For any such i and j, Pi nQj will be approximately equal to L(gl Ag2) n P. Proof. The proof rests on the following proposition: Proposition A.l. Let f( PI, . . . , P,) be a function on plan sets that distributes with respect to set-theoretic union and such that f ( PI, . . . , P,, ) & Pi for each i. Now suppose that for each i, we have a sequence 122 M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 that converges to Pi and such that if we take Au = Ptj 8 Pij+l, each Atj is of measure 1 $I 8: in Pi@Ptj. Thenprovided ( 1) There is u collection of indices fi such that Aiji is of measure 0 in f ( Ptji) for f(P,,...,P,,) each i, and (2) For any such set of indices, f (Pi) and f ( Piji) are approximately equal. Proof. We prove the result for n = 1 only; the general case is no harder. Suppose, then, that f(P) is a function on plan sets that distributes with respect to set-theoretic union and such that f(P) G P. Suppose also that we have a sequence Pi that converges to P and such if we take Aj = Pj 0 Pj+l, each Aj is of measure 1 in # 8, we must show that: P 8 Pi. Then provided f(P) ( 1) There is an index j such that Aj is of measure 0 in f (Pi), and (2) For any such index, f(P) and f (Pj) are approximately equal. TO see this, fix i and say that P = (Pi - A) U B, SO that P U A = Pi U B. Now f(P) uf(A)=f(P) ‘Jf(B) since f distributes with respect to U. It follows that f(P) ef(Pi) C f(A) U f(B) C AUB=PBPi Since f(P) and therefore that At is of measure 1 in f(P) 8 f (Pi). # 8 and the At’s are converging to 0, it follows that there is some fixed j such that Aj is of measure 0 in f(P). But now we can apply Proposition 3.13 to conclude that f(P) and f (Pj) are approximately equal. Since f(P) and f (Pj) are approximately equal, Aj must be of measure 0 in f (Pj), and the first part of the proposition is proved. The second part of the proposition is proved as well; if Aj is of measure 0 in f (Pj), we know it is of measure 1 in f(P) 8 f (Pi), so f (Pi) and f(P) must be approximately equal. 0 To prove the original theorem, we can now simply take f = 13; the conditions on the A’s are guaranteed by the approximate validity of the fashion in which the planning sequences for the subgoals are constructed. Cl References [I] D. Chapman, Planning for conjunctive goals, Art% Intel 32 (1987) 333-377. [2] K. Currie and A. Tate, O-Plan: the open planning architecture, Artif: Intell. 52 (1991) 49-86. [ 31 J.J. Finger, Exploiting constraints in design synthesis, Ph.D. Thesis, Stanford University, Stanford, CA (1987). (41 D.E. Foulser, M. Li and Q. Yang, Theory and algorithms for plan merging, Arrif: Inrell. 57 (1992) 143-181. [ 51 M.L. Ginsberg, Multivalued Infell. 4 (1988) 265-316. logics: a uniform approach to reasoning in artificial intelligence, Comput. M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 123 [6] M.L. Ginsberg, Formalizing action, Tech. Report, Stanford University, Stanford, CA (1989). [7] M.L. Ginsberg, Bilattices and modal operators, J. Logic Comput. 1 (1990) 41-69. [8] M.L. Ginsberg, Computational considerations in reasoning about action, in: Proceedings Second International Conference on Principles of Knowledge Representation and Reasoning, Boston, MA (1991). [ 91 M.L. Ginsberg, The MVL theorem proving system, SIGART Bull. 2( 3) ( 1991) 57-60. [lo] M.L. Ginsberg, Negative subgoals with free variables, J. Logic Programming 11 (1991) 271-293. [ 1 l] M.L. Ginsberg, User’s guide to the MVL system, Tech. Report, University of Oregon, Eugene, OR (1993). [ 121 M.L. Ginsberg and H.W. Holbrook, What defaults can do that hierarchies can’t, in: Proceedings 1992 Nonmonotonic Reasoning Workshop Plymouth, VT (1992) [ 131 M.L. Ginsberg and D.E. Smith, Reasoning about action I: a possible worlds approach, Artif Intell. 35 (1988) 165-195. [ 141 K.J. Hammond, Explaining and repairing plans that fail, Arti$ Intell. 45 (1990) 173-228. [ 151 S.A. Kripke, Semantical considerations on modal logic, in: L. Linsky, ed., Reference and Modality (Oxford University Press, London, 1971) 63-72. [ 161 D. McAllester and D. Rosenblitt, Systematic nonlinear planning, in: Proceedings AAAI-91, Anaheim, CA (1991). [ 171 S. Minton, J.G. Carbonell, C.A. Knoblock, D.R. Kuokka, 0. Etzioni and Y. Gil, Explanation-based learning: a problem solving perspective, ArtijI Intell. 40 ( 1989) 63-l 18. [ 181 J.S. Penberthy and D.S. Weld, UCPOP: a sound, complete partial order planner for ADL, in: Proceedings Third International Conference on Principles of Knowledge Representation and Reasoning Boston, MA (1992) 103-113. [ 191 G.J. Sussman, A Computational Model of Skill Acquisition (American Elsevier, New York, 1975). [ 201 A. Tate, Project planning using a hierarchic non-linear planner, Tech. Report 25, Department of Artificial Intelligence, University of Edinburgh ( 1976). [21] D.E. Wilkins, Practical Planning: Extending the Classical AI Planning Paradigm (Morgan Kaufmann, San Mateo, CA, 1988). 