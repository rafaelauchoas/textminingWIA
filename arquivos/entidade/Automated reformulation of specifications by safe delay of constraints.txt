Artificial Intelligence 170 (2006) 779–801www.elsevier.com/locate/artintAutomated reformulation of specifications bysafe delay of constraints ✩Marco Cadoli, Toni Mancini ∗Dipartimento di Informatica e Sistemistica, Università di Roma “La Sapienza”, Via Salaria 113, I-00198 Roma, ItalyReceived 14 September 2004; received in revised form 25 January 2006; accepted 25 January 2006AbstractIn this paper we propose a form of reasoning on specifications of combinatorial problems, with the goal of reformulating themso that they are more efficiently solvable. The reformulation technique highlights constraints that can be safely “delayed”, andsolved afterwards. Our main contribution is the characterization (with soundness proof) of safe-delay constraints with respectto a criterion on the specification, thus obtaining a mechanism for the automated reformulation of specifications applicable to agreat variety of problems, e.g., graph coloring, bin-packing, and job-shop scheduling. This is an advancement with respect to theforms of reasoning done by state-of-the-art-systems, which typically just detect linearity of specifications. Another contributionis an experimentation on the effectiveness of the proposed technique using six different solvers, which reveals promising timesavings.© 2006 Elsevier B.V. All rights reserved.Keywords: Modelling; Reformulation; Second-order logic; Propositional satisfiability; Constraint satisfaction problems1. IntroductionCurrent state-of-the-art languages and systems for constraint modelling and programming (e.g., AMPL [22],OPL [48], XPRESSMP,1 GAMS [9], DLV [31], SMODELS [39], ESRA [21], PS [18] and NP-SPEC [8]) exhibit a strongseparation between a problem specification (e.g., Graph 3-coloring) and its instance (e.g., a graph), usually adopting atwo-level architecture for finding solutions: the specification is firstly instantiated (or grounded) against the instance,and then an appropriate solver is invoked (cf. Fig. 1). Such a separation leads to several advantages: obviously declar-ativeness increases, and the solver is completely decoupled from the specification. Ideally, the programmer can focusonly on the combinatorial aspects of the problem specification, without committing a priori to a specific solver. In✩ This paper is an extended and revised version of [M. Cadoli, T. Mancini, Automated reformulation of specifications by safe delay of constraints,in: Proceedings of the Ninth International Conference on the Principles of Knowledge Representation and Reasoning (KR 2004), Whistler, BC,Canada, AAAI Press/The MIT Press 2004, pp. 388–398].* Corresponding author.E-mail addresses: cadoli@dis.uniroma1.it (M. Cadoli), tmancini@dis.uniroma1.it (T. Mancini).1 Cf. http://www.dashoptimization.com.0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.01.008780M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801Fig. 1. Two-level architecture of current problem solving systems.fact, some systems, e.g., AMPL, are able to translate—at the request of the user—a specification in various formats,suitable for different solvers, e.g., among the others, CPLEX, MINOS,2 LANCELOT.3Nonetheless, many existing techniques proposed in the literature for optimizing the solution of constraint satisfac-tion problems apply after the commitment to the instance: notable examples are, e.g., symmetry detection and breaking(cf., e.g., [4,16,37]), the development of techniques for imposing various local consistency notions and of heuristicsduring search (cf., e.g., [17]), the development of algorithms that deal with dependent variables, e.g., those added toSAT instances during the clausification of non-CNF formulae [27], and with the so-called “equivalence clauses” [32].However, in many cases, properties that are amenable to be optimized derive from the problem structure, ratherthan the particular instance considered. Optimization techniques that act on the problem structure have been proposed.They include the addition of implied constraints (cf., e.g., [47]), the deletion or abstraction of some of the constraints(cf., e.g., [28]), the use of redundant models, i.e., multiple viewpoints synchronized by channelling constraints, inorder to increase constraint propagation [12,20,29].Our research follows the latter approach, with the aim of systematize the process of finding useful reformulationsby performing a symbolic reasoning on the specification. In general, for many properties, symbolic reasoning can bemore natural and effective than making such “structural” aspects emerge after instantiation, when the structure of theproblem has been hidden.An example of system that performs a sort of reasoning on the specification is OPL, which is able to automaticallychoose the most appropriate solver for a problem. However, the kind of reasoning offered is very primitive: OPL onlychecks (syntactically) whether a specification is linear, in this case invoking a linear—typically more efficient—solver,otherwise a general constraint programming one.Conversely, our research aims to the following long-term goal: the automated reformulation of a declarative con-straint problem specification, into a form that is more efficiently evaluable by the solver at hand. The ultimate goal is tohandle all properties suitable for optimization that derive from the problem structure at the specification level, leavingat the subsequent instance level the handling of the remaining ones, i.e., those that truly depend on the instance. Infact, it is worthwhile to note that focusing on the specification does not rule out the possibility of additionally applyingexisting optimization techniques at the instance level.The approach we follow is similar, in a sense, to the one used in the database research community for attackingthe query optimization problem in relational databases. A query planner, whose task is to reformulate the query posedby the user in order to improve the efficiency of the evaluation, takes into account the query and the database schemaonly, not its current content, i.e., the instance (cf., e.g., [1]).In general, reformulating a constraint problem specification is a difficult task: a specification is essentially a formulain second-order logic, and it is well known that the equivalence problem is undecidable already in the first-order case[3]. For this reason, research must focus on controlled and restricted forms of reformulation.Moreover, the effectiveness of a particular reformulation technique is expected to depend both on the problem andon the solver, even if it is possible, in principle, to find reformulations that are good for all solvers (or for solversof a certain class, e.g., linear, or SAT-based ones). To this end, in related work (cf. Section 6), we present differentreformulation strategies that have been proposed in order to speed-up the process of solving a constraint problem.2 Cf. http://www.sbsi-sol-optimize.com/.3 Cf. http://www.cse.clrc.ac.uk/nag/lancelot/lancelot.shtml.M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801781Fig. 2. Delaying the disjointness constraint in 3-coloring. (a) 1st stage: covering and good coloring; (b) 2nd stage: disjointness.(a)(b)In this paper, we propose a technique that allows us to select constraints in a problem specification that can beignored in a first step (regardless of the instance), and efficiently reinforced once a solution of the simplified problemhas been found. We call such constraints safe-delay. Moreover, we experimentally show how reformulating problemspecifications by safe-delay improves performances of different (but not all) solvers. On one hand, this gives evidencethat problem reformulation can be effective in many cases, and on the other, it confirms the intuition that a singlereformulation technique may have positive effects for some classes of solvers, but negative ones for others, and thata portfolio of different and complementary reformulation strategies has to be considered, in general (cf. Section 6 forrelated work).The NP-complete graph k-coloring problem offers a simple example of a safe-delay constraint. The problemamounts to find an assignment of nodes to k colors such that:• Each node has at least one color (covering);• Each node has at most one color (disjointness);• Adjacent nodes have different colors (good coloring).For each instance of the problem, if we obtain a solution neglecting the disjointness constraint, we can alwayschoose for each node one of its colors in an arbitrary way at a later stage (cf. Fig. 2). It is interesting to note that thedeletion of the disjointness constraints in graph k-coloring has been already proposed as an ad-hoc technique in [46](cf. also [42]), and implemented in, e.g., the standard DIMACS formulation in SAT of k-coloring.Of course not all constraints are safe-delay: as an example, both the covering and the good coloring constraints arenot. Intuitively, identifying the set of constraints of a specification which are safe-delay may lead to several advantages:• The instantiation phase (cf. Fig. 1) will typically be faster, since safe-delay constraints are not taken into account.As an example, let’s assume we want to use (after instantiation) a SAT solver for the solution of k-coloring ona graph with n nodes and e edges. The SAT instance encoding the k-coloring instance—in the obvious way, cf.,e.g., [25]—has n · k propositional variables, and a number of clauses which is n, n · k · (k − 1)/2, and e · k forcovering, disjointness, and good coloring, respectively. If we delay disjointness, n · k · (k − 1)/2 clauses need notto be generated.• Solving the simplified problem, i.e., the one without disjointness, might be easier than the original formulation forsome classes of solvers, since removing constraints makes the set of solutions larger. For each instance it holdsthat:{solutions of original problem} ⊆ {solutions of simplified problem}.In our experiments, using six different solvers, including SAT, integer linear programming, and constraint pro-gramming ones, we obtained fairly consistent (in some cases, more than one order of magnitude) speed-ups forhard instances of various problems, e.g., graph coloring and job-shop scheduling. On top of that, we implicitlyobtain several good solutions. Results of the experimentation are given in Section 5.• Ad hoc efficient methods for solving delayed constraints may exist. As an example, for k-coloring, the problemof choosing only one color for the nodes with more than one color is O(n).The architecture we propose is illustrated in Fig. 3 and can be applied to any system which separates the instancefrom the specification. It is in some sense similar to the well-known divide and conquer technique, cf., e.g., [14], but782M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801Fig. 3. Reformulation architecture.rather than dividing the instance, we divide the constraints. In general, the first stage will be more computationallyexpensive than the second one, which, in our proposal, will always be doable in polynomial time.The goal of this paper is to understand in which cases a constraint is safe-delay. Our main contribution is thecharacterization of safe-delay constraints with respect to a semantic criterion on the specification. This allows usto obtain a mechanism for the automated reformulation of a specification that can be applied to a great variety ofproblems, including the so-called functional ones, i.e., those in which the search space is a (total) function from afinite domain to a finite codomain.The outline of the paper is as follows: after recalling some preliminaries in Section 2, we present our reformulationtechnique in Section 3, and a discussion on the adopted methodology in Section 4. Afterwards, experimentation on theeffectiveness of the approach is described in Section 5, on both benchmark and randomly generated instances, usingSAT and state-of-the-art linear and constraint programming solvers. Finally, conclusions, future and related work arepresented in Section 6.2. PreliminariesThe style used for the specification of a combinatorial problem varies a lot among different languages for constraintprogramming. In this paper, rather than considering procedural encodings such as those obtained using libraries (in,e.g., C++ or PROLOG), we focus on highly declarative languages. Again, the syntax varies a lot among such languages:AMPL, OPL, XPRESSMP and GAMS allow the representation of constraints by using algebraic expressions, while DLV,SMODELS, and NP-SPEC are rule-based languages. Anyway, from an abstract point of view, all such languages areextensions of existential second-order logic (ESO) over finite databases, where the existential second-order quantifiersand the first-order formula represent, respectively, the guess and check phases of the constraint modelling paradigm.In particular, in all such languages it is possible to embed ESO queries, and the other way around is also possible, aslong as only finite domains are considered.To this end, in this paper we use ESO for the specification of problems, mainly because of its simplicity andbecause it allows to represent all search problems in the complexity class NP [19,40]. In particular, as we showin the remainder of this section, ESO can be considered as the formal basis for virtually all available languages forconstraint modelling. Intuitively, the relationship between ESO and real modelling languages is similar to that holdingbetween Turing machines or assembler, and high-level programming languages. We claim that studying the simplifiedscenario is a mandatory starting point for more complex investigations, and that our results can serve as a basis forreformulating specifications written in higher-level languages. In Section 4 we discuss further our choice, showinghow our reformulation technique can be easily lifted in order to deal with problem specifications written in other andricher languages, e.g., AMPL.Coherently with all state-of-the-art systems, we represent an instance of a problem by means of a relational data-base. All constants appearing in a database are uninterpreted, i.e., they don’t have a specific meaning.M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801783An ESO specification describing a search problem π is a formula.= ∃ (cid:5)S φ( (cid:5)S, (cid:5)R),ψπ(1)where (cid:5)R = {R1, . . . , Rk} is the input relational schema (i.e., a fixed set of relations of given arities denoting the schemafor all input instances for π ), and φ is a closed first-order formula on the relational vocabulary (cid:5)S ∪ (cid:5)R ∪ {=} (“=” isalways interpreted as identity), with no function symbols.An instance I of the problem is given as a relational database over the schema (cid:5)R, i.e., as an extension for allrelations in (cid:5)R. Predicates (of given arities) in the set (cid:5)S = {S1, . . . , Sn} are called guessed, and their possible extensions(with tuples on the domain given by constants occurring in I plus those occurring in φ, i.e., the so called Herbranduniverse) encode points in the search space for problem π on instance I.Formula ψπ correctly encodes problem π if, for every input instance I, a bijective mapping exists between solu-tions to π(I) and extensions of predicates in (cid:5)S which verify φ( (cid:5)S, I). More formally, the following must hold:For each instance I: Σ is a solution to π(I) ⇐⇒ {Σ, I} |= φ.It is worthwhile to note that, when a specification is instantiated against an input database, a constraint satisfactionproblem (in the sense of [17]) is obtained.Example 1. (Graph 3-Coloring [26, Prob. GT4]) In this NP-complete decision problem the input is a graph, and thequestion is whether it is possible to give each of its nodes one out of three colors (red, green, and blue), in such a waythat adjacent nodes (not including self-loops) are never colored the same way. The question can be easily specified asan ESO formula ψ over a binary relation edge:∃RGB ∀X R(X) ∨ G(X) ∨ B(X) ∧∀X R(X) → ¬G(X) ∧∀X R(X) → ¬B(X) ∧∀X B(X) → ¬G(X) ∧∀XY X (cid:13)= Y ∧ R(X) ∧ R(Y ) → ¬edge(X, Y ) ∧∀XY X (cid:13)= Y ∧ G(X) ∧ G(Y ) → ¬edge(X, Y ) ∧∀XY X (cid:13)= Y ∧ B(X) ∧ B(Y ) → ¬edge(X, Y ),(2)(3)(4)(5)(6)(7)(8)where clauses (2), (3–5), and (6–8) represent the covering, disjointness, and good coloring constraints, respectively.Referring to the graph in Fig. 2, the Herbrand universe is the set {a, b, c, d, e}, the input database has only one relation,i.e., edge, which has five tuples (one for each edge).In what follows, the set of tuples from the Herbrand universe taken by guessed predicates will be called theirextension and denoted with ext(). By referring to the previous example, formula ψ is satisfied, e.g., for ext(R) = {d},ext(G) = {a, e}, ext(B) = {b, c} (cf. Fig. 2(b)). The symbol ext() will be used also for any first-order formula with onefree variable. An interpretation will be sometimes denoted as the aggregate of several extensions.Finally, we observe that in this paper we consider basic ESO. Nonetheless, it is known (cf., e.g., [35]) that muchsyntactic sugar can be added to ESO in order to handle types, functions, bounded integers and arithmetics, withoutaltering its expressing power. In Section 3.3 we give some examples of the enriched language.3. ReformulationIn this section we show sufficient conditions for constraints of a specification to be safe-delay. We refer to thearchitecture of Fig. 3, with some general assumptions:Assumption 1. As shown in Fig. 2, the output of the first stage of computation may—implicitly—contain severalsolutions. As an example, node c can be assigned to either green or blue, and node e to either red or green. In thesecond stage we do not want to compute all of them, but just to arbitrarily select one. In other words, we focus onsearch problems, with no objective function to be optimized.784M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801(a)(b)(c)Fig. 4. (a) A solution of the first (a) and second (b) stage of a graph 3-coloring instance. (c) An alternative view showing how the extension for Rshrinks when moving from the first (dashed area) to the second stage.Assumption 2. The second stage of computation can only shrink the extension of a guessed predicate. Fig. 4 representsa solution of the first (a) and second (b) stage on the graph 3-coloring instance in Fig. 2. Fig. 4(c) gives further evidenceabout how the extension for predicate R shrinks when moving from the first (ext(R∗)) to the second stage (ext(R))(ext(B) and ext(G) are unchanged).This assumption is coherent with the way most algorithms for constraint satisfaction operate: each variable hasan associated finite domain, from which values are progressively eliminated, until a satisfying assignment is found.Nonetheless, in Section 3.4 we give examples of problem specifications which are amenable to safe-delay, althoughwith a second stage of different nature.Identification of safe-delay constraints requires reasoning on the whole specification, taking into account relationsbetween guessed and database predicates. For the sake of simplicity, in Section 3.1 we will initially focus our attentionon a single monadic guessed predicate, trying to figure out which constraints concerning it can be delayed. Afterwards,in Section 3.2 we extend our results to sets of monadic guessed predicates, then, in Section 3.3, to binary predicates.3.1. Single monadic predicateWe refer to the 3-coloring specification of Example 1, focusing on one of the guessed predicates, R, and trying tofind an intuitive explanation for the fact that clauses (3–4) can be delayed. We immediately note that clauses in thespecification can be partitioned into three subsets: NOR, NEGR, and POSR with—respectively—no, only negative,and only positive occurrences of R.Neither NOR nor NEGR clauses can be violated by shrinking the extension of R. Such constraints will be calledsafe-forget for R, because if we decide to process (and satisfy) them in the first stage, they can be safely ignored in thesecond one (which, by Assumption 2 above, can only shrink the extension for R). We note that this is just a possibility,and we are not obliged to do that: as an example, clauses (3–4) will not be evaluated in the first stage.Although in general POSR clauses are not safe-forget—because shrinking the extension of R can violate them—we now show that clause (2) is safe-forget. In fact, if we equivalently rewrite clauses (2) and (3–4), respectively, asfollows:R(X) → ¬B(X) ∧ ¬G(X),∀X ¬B(X) ∧ ¬G(X) → R(X)∀X(cid:14)(2)(cid:14)(3–4)we note that clause (2)(cid:14) sets a lower bound for the extension of R, and clauses (3–4)(cid:14) set an upper bound for it; both thelower and the upper bound are ext(¬B(X) ∧ ¬G(X)). If we use—in the first stage—clauses (2, 5–8) for computingext(R∗) (in place of ext(R)), then—in the second stage—we can safely define ext(R) as ext(R∗) ∩ ext(¬B(X) ∧¬G(X)), and no constraint will be violated (cf. Fig. 4). The next theorem (all proofs are delayed to Appendix A)shows that is not by chance that the antecedent of (2)(cid:14) is semantically related to the consequence of (3–4)(cid:14).Theorem 1. Let ψ be an ESO formula of the form:∃S1, . . . , Sh, S Ξ ∧ ∀X α(X) → S(X) ∧ ∀X S(X) → β(X),in which S is one of the (all monadic) guessed predicates, Ξ is a conjunction of clauses, both α and β are arbitraryformulae in which S does not occur and X is the only free variable, and such that the following hypotheses hold:M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801785Fig. 5. Extensions with and without Hyp 2.Hyp 1: S either does not occur or occurs negatively in Ξ ;Hyp 2: |= ∀X α(X) → β(X).Let now ψ s be:∃S1, . . . , Sh, S∗∗ ∧ ∀X α(X) → S∗Ξ(X),where S∗ is a new monadic predicate symbol, and Ξ ∗ is Ξ with all occurrences of S replaced by S∗, and let ψ d be:∀X S(X) ↔ S∗(X) ∧ β(X).For every input instance I, and every extension M∗ for predicates (S1, . . . , Sh, S∗) such that (M ∗, I) |= ψ s , it holdsthat:(cid:2)(cid:2)M∗ − ext(S∪ ext(S), Iwhere ext(S) is the extension of S as defined by M∗ and ψ d .|= ψ∗(cid:3))(cid:3)A comment on the relevance of the above theorem is in order. Referring to Fig. 3, ψ is the specification, I is theinstance, ψ s is the “simplified specification”, and ∀X S(X) → β(X) is the “delayed constraint” (belonging to NEGS ).Solving ψ s against I produces—if the instance is satisfiable—a list of extensions M ∗ (the “output”). Evaluating ψ dagainst M ∗ corresponds to the “PostProcessing” phase in the second stage. The structure of the delayed constraintψ d clearly reflects Assumption 2 above, i.e., that extensions for guessed predicates can only be shrunk in the secondstage. Moreover, since the last stage amounts to the evaluation of a first-order formula against a fixed database, it canbe done in logarithmic space (cf., e.g., [1]), thus in polynomial time.In other words, Theorem 1 says that, for each satisfiable instance I of the simplified specification ψ s , each solutionM ∗ of ψ s can be translated, via ψ d , to a solution of the original specification ψ; we can also say that Ξ ∧ ∀X α(X) →S(X) is safe-forget, and ∀X S(X) → β(X) is safe-delay.Referring to the specification of Example 1, the distinguished guessed predicate is R, Ξ is the conjunction ofclauses (5–8), and α(X) and β(X) are both ¬B(X) ∧ ¬G(X), cf. clauses (3–4)(cid:14). Fig. 4 represents possible extensionsof the red predicate in the first (R∗) and second (R) stages, for the instance of Fig. 2, and Fig. 5 (left) gives furtherevidence that, if Hyp 2 holds, the constraint ∀X α(X) → S(X) can never be violated in the second stage.We are guaranteed that the two-stage process preserves at least one solution of ψ by the following theorem.Theorem 2. Let I, ψ, ψ s and ψ d as in Theorem 1. For every instance I, if ψ is satisfiable, ψ s and ψ d are satisfiable.To substantiate the reasonableness of the two hypotheses of Theorem 1, we play the devil’s advocate and considerthe following example.Example 2. (Graph 3-Coloring with red self-loops (Example 1 continued)) In this problem, which is a variation ofthe one in Example 1, the input is the same as for graph 3-Coloring, and the question is whether it is possible to finda coloring of the graph with the additional constraint that all self-loops insist on red nodes.A specification for this problem can be easily derived from that of Example 1 by adding the following constraint:∀X edge(X, X) → R(X).(9)786M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801Fig. 6. An instance of the graph 3-coloring with red self-loops problem along with a solution of the first stage, obtained by delaying only thedisjointness constraints.We immediately notice that now clauses (3–4) are not safe-delay: intuitively, after the first stage, nodes may be redeither because of (2) or because of (9), and (3–4) are not enough to set the correct color for a node. Now, if—on topof (5–8)—Ξ contains also the constraint (9), Hyp 1 is clearly not satisfied. Analogously, if (9) is used to build α(X),then α(X) becomes edge(X, X) ∨ (¬B(X) ∧ ¬G(X)), and Hyp 2 is not satisfied. Fig. 5, right, gives further evidencethat the constraint ∀X α(X) → S(X) can be violated if ext(S) is computed using ψ d and ext(α) is not a subset ofext(β). An instance of the graph 3-coloring with red self-loops problem is given in Fig. 6, along with a solution of thefirst stage, in the case Ξ contains also the constraint (9). It can be observed that constraints (3–4) are not enough toset the correct color for node e.Summing up, a constraint with a positive occurrence of the distinguished guessed predicate S can be safely forgot-ten (after being evaluated in the first stage) only if there is a safe-delay constraint which justifies it.Some further comments about Theorem 1 are in order. As it can be observed (cf. Appendix A), the theorem proofdoes not formally require Ξ to be a conjunction of clauses; actually, it can be any formula such that, from any structureM such that M |= Ξ , by shrinking ext(S) and keeping everything else fixed we obtain another model of Ξ . As anexample, Ξ may contain the conjunct ∃X S(X) → γ (X) (with γ (X) a first-order formula in which S does not occur).Secondly, although Hyp 2 calls for a tautology check—which is not decidable in general—we will see in what followsthat many specifications satisfy it by design.3.2. Set of monadic predicatesTheorem 1 states that we can delay some constraints of a specification ψ, by focusing on one of its monadicguessed predicates, hence obtaining a new specification ψ s , and a set of delayed constraints ψ d . Of course, the sametheorem can be further applied to the specification ψ s , by focusing on a different guessed predicate, in order to obtaina new simplified specification (ψ s)s and new delayed constraints (ψ s)d . Since, by Theorem 2, satisfiability of suchformulae is preserved, it is afterwards possible to translate, via (ψ s)d , each solution of (ψ s)s to a solution of ψ s , andthen, via ψ d , to a solution of ψ.The procedure REFORMULATE in Fig. 7 deals with the general case of a set of guessed predicates: if the inputspecification ψ is satisfiable, it returns a simplified specification ψ s and a list of delayed constraints ψ d . AlgorithmSOLVEBYDELAYING gets any solution of ψ s and translates it, via the evaluation of formulae in the list ψ d —withLIFO policy—to a solution of ψ.As an example, by evaluating the procedure REFORMULATE on the specification of Example 1, by focusing on theguessed predicates in the order R, G, B, we obtain as output the following simplified specification ψ s , that omits alldisjointness constraints (i.e., clauses (3–5)):∃R∗∗GB ∀X R∗∗(X) ∨ G(X) ∨ B(X) ∧∗∗(Y ) → ¬edge(X, Y ) ∧(X) ∧ R∀XY X (cid:13)= Y ∧ R∗∗(Y ) → ¬edge(X, Y ) ∧(X) ∧ G∀XY X (cid:13)= Y ∧ G∀XY X (cid:13)= Y ∧ B(X) ∧ B(Y ) → ¬edge(X, Y ),and the following list ψ d of delayed constraints:∗∀X R(X) ↔ R(X) ∧ ¬G(X) ∧ ¬B(X);∗(X) ∧ ¬B(X).∀X G(X) ↔ G(10)(11)M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801787Algorithm SOLVEBYDELAYINGInput:Output: a solution of (cid:17)D, Φ(cid:18), if satisfiable, ‘unsatisfiable’ otherwise;a specification Φ, a database D;begin(cid:17)Φs , Φd (cid:18) = REFORMULATE(Φ);if ((cid:17)Φs , D(cid:18) is satisfiable) thenbeginlet M be a solution of (cid:17)Φs , D(cid:18);while (Φd is not empty) dobeginConstraint d = Φd .pop();M = M∪ solution of d; // cf. Theorem 1end;return M;end;else return ‘unsatisfiable’;end;Procedure REFORMULATEInput:a specification Φ;Output: the pair (cid:17)Φs , Φd (cid:18), where Φs is a simplified specification, and Φda stack of delayed constraints;beginStack Φd = the empty stack;Φs = Φ;for each monadic guessed pred. S in Φs dobeginpartition constraints in Φs according to Thm 1, in:(cid:17)Ξ ; ∀X α(X) → S(X); ∀X S(X) → β(X)(cid:18);if the previous step is possible with ∀X β(X) (cid:13)= TRUE thenbeginΦd .push(‘∀X S(X) ↔ S∗(X) ∧ β(X)’);Φs = Ξ ∗ ∧ ∀X α(X) → S∗(X);end;end;return (cid:17)Φs , Φd (cid:18);end;Fig. 7. Algorithm for safe-delay in case of a set of monadic predicates.It is worth noting that the check that ∀X β(X) is not a tautology prevents the (useless) delayed constraint ∀X B(X) ↔B∗(X) to be pushed in ψ d .From any solution of ψ s , a solution of ψ is obtained by reconstructing first of all the extension for G by for-mula (11), and then the extension for R by formula (10) (synthesized, respectively, in the second and first iterationof the algorithm). Since each delayed constraint is first-order, the whole second stage is doable in logarithmic space(thus in polynomial time) in the size of the instance.We also observe that the procedure REFORMULATE is intrinsically non-deterministic, because of the partition thatmust be applied to the constraints.3.3. Binary predicatesIn this subsection we show how our reformulation technique can be extended in order to deal with specificationswith binary (and, in general, n-ary) guessed predicates. This can be formally done by unfolding non-monadic guessedpredicates into monadic ones, exploiting the finiteness of the Herbrand domain.To illustrate the point, we consider the specification of the k-coloring problem using a binary predicate Col—thefirst argument being the node and the second the color, which is as follows (the input schema in this case is given by788M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801(cid:5)R = {node(·), color(·), edge(·, ·)} encoding the set of nodes, colors, and the graph edges, respectively, and constraintsforce Col to be correctly typed, and to satisfy conditions for covering, disjointness, and good coloring):∃Col ∀XY Col(X, Y ) → node(X) ∧ color(Y ) ∧∀X ∃Y node(X) → Col(X, Y ) ∧∀XY Z Col(X, Y ) ∧ Col(X, Z) → Y = Z ∧∀XY Z X (cid:13)= Y ∧ Col(X, Z) ∧ Col(Y, Z) → ¬edge(X, Y ).Since the number of colors is finite, it is always possible to unfold the above constraints with respect to the secondargument of Col. As an example, if k = 3, we replace the binary predicate Col with three monadic guessed predicatesCol1, Col2, Col3, one for each value of the second argument (i.e., the color), with the meaning that, if tuple (cid:17)n, c(cid:18)belongs to Col, then (cid:17)n(cid:18) belongs to Colc. Constraints of the specification must be unfolded accordingly. The outputof the unfolding process for k = 3—up to an appropriate renaming of Col1, Col2, Col3 into R, G, B—-is exactly thespecification of Example 1.The above considerations imply that we can use the architecture of Fig. 3 for a large class of specifications, in-cluding the so called functional specifications, i.e., those in which the search space is a (total) function from a finitedomain to a finite codomain. A safe-delay functional specification is an ESO formula of the form∃P Ξ ∧ ∀X ∃Y P (X, Y ) ∧ ∀XY Z P (X, Y ) ∧ P (X, Z) → Y = Z,where Ξ is a conjunction of clauses in which P either does not occur or occurs negatively. In particular, the dis-jointness constraints are safe-delay, while the covering and the remaining ones, i.e., Ξ , are safe-forget. Formally,soundness of the architecture on safe-delay functional formulae is guaranteed by Theorem 1.Safe-delay functional specifications are quite common; apart from graph coloring, notable examples are Job-shopscheduling and Bin packing, that we consider next.Example 3. (Job-shop scheduling [26, Prob. SS18]) In the Job-shop scheduling problem we have sets (sorts) J forjobs, K for tasks, and P for processors. Jobs are ordered collections of tasks and each task has an integer-valuedlength (encoded in binary relation L) and the processor that is requested in order to perform it (in binary relationProc). Each processor can perform a task at the time, and tasks belonging to the same job must be performed in theirorder. Finally, there is a global deadline D that has to be met by all jobs.An ESO specification for this problem is as follows. For simplicity, we assume that relation Aft contains all pairsof tasks (cid:17)k(cid:14), k(cid:14)(cid:14)(cid:18) of the same job such that k(cid:14) comes after k(cid:14)(cid:14) in the given order (i.e., it encodes the transitive closure),and that relation Time encodes all time points until deadline D (thus it contains exactly D tuples). Moreover, weassume that predicate “(cid:2)” and function “+” are correctly defined on constants in Time. It is worth noting that theseassumptions do not add any expressive power to the ESO formalism, and can be encoded in ESO with standardtechniques.∃S ∀k, t S(k, t) → K(k) ∧ T (t) ∧(cid:14)(cid:14) ∧(cid:14)(cid:14)(cid:14)(cid:14)(cid:14) = t) → t, j ) ∧ Job(k(cid:14)(cid:14), j ) ∧(cid:14)(cid:14)(cid:14)(cid:14), t) ∧ S(k, t) ∧) ∧ S(k(cid:14) ∧(cid:14) + l(cid:14)∀k ∃t S(k, t) ∧(cid:14)(cid:14)(cid:14)∀k, t(cid:14)∀kS(k, t(cid:14)(cid:14)(cid:14), t(cid:14)(cid:14)k, j, t, l, t, k(cid:14)(cid:14) ∧ Aft(k(cid:14) (cid:13)= k(cid:14)(cid:14)) → tL(k, l(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)∀k, k) ∧ S(k, t(cid:14)(cid:14) Job(k(cid:14)(cid:14)(cid:14), k(cid:14)(cid:14) (cid:2) t(cid:14)(cid:14)(cid:14), l, l, p) ∧ Proc(k(cid:14)(cid:14)) ∧ S(k(cid:14)(cid:14) → t, t(cid:14) (cid:2) t, t(cid:14)(cid:14)(cid:14)(cid:14)Proc(k(cid:14)(cid:14), p, t(cid:14)(cid:14) (cid:13)= k, p) ∧ k(cid:14)(cid:14)(cid:14)(cid:14)) →(cid:14) (cid:3) t, t) ∧ (tL(k(cid:4)(t, l(cid:14) (cid:2) t) ∧ S(k(cid:14)(cid:14) (cid:2) t(cid:14)(cid:14)(cid:14)(cid:14) + l∀k, t, l T (k) ∧ S(k, t) ∧ L(k, l) → Time(t + l).(cid:14)(cid:14) → t(cid:14)(cid:14) + l(cid:5))∧(cid:14)(cid:14) ∧ L(k(cid:14)(cid:14)) ∧, l(12)(13)(14)(15)(16)(17)M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801789Constraints (12–14) force a solution to contain a tuple (cid:17)k, t(cid:18) (t being a time point) for every task k, hence to encode anassignment of exactly a starting time to every task (in particular, (14) assigns at most one starting time to each task).Moreover, constraint (15) forces tasks that belong to the same job to be executed in their order without overlapping,while (16) avoids a processor to perform more than one task at each time point. Finally, (17) forces the scheduling toterminate before deadline D.It is worth noting that additional syntactic sugar may be added to ESO in order to better deal with schedulingproblems. As an example, constructs like those commonly found in richer modelling languages for such problems(cf., e.g., the part of OPL concerning scheduling) can be made available. However, such enhancements are out of thescope of this paper, and will not be taken into account. (cid:2)As an example, Fig. 8(a) and (b) show, respectively, an instance and a possible solution of the Job-shop schedulingproblem. The instance consists of 3 jobs (J1, J2, and J3) of, respectively, 4, 3, and 5 tasks each. The order in whichtasks belonging to the same job have to be performed is given by the letter in parentheses (a, b, c, d, e). Tasks have tobe executed on 3 processors, P1, P2, and P3, which are denoted by different borderlines. Hence, the processor neededto perform a given task is given by the task borderline.To reformulate the Job-shop scheduling problem, after unfolding the specification in such a way to have onemonadic guessed predicate St for each time point t, we focus on a time point t and partition clauses in the specificationin which St does not occur, occurs positively, or negatively, in order to build Ξ , α(k), and β(k). The output of thisphase is as follows:• α(k)• β(k).=.=(cid:6)(cid:6)t(cid:13)=tt(cid:13)=t¬St (k) (obtained by unfolding (13));¬St (k) (obtained by unfolding (14)).α and β above clearly satisfy Hyp 2 of Theorem 1. Moreover, according to the algorithm in Fig. 7, by iterativelyfocusing on all predicates St , we can delay all such (unfolded) constraints. It is worth noting that the unfolding ofguessed predicates is needed only to formally characterize the reformulation with respect to Theorem 1, and must notbe performed in practice.Intuitively, the constraint we delay, i.e. (14), forces each task to have at most one starting time: thus, by delayingit, we allow a task to have multiple starting times, i.e., the task does not overlap with any other task at any of its starttimes. Again, in the second stage, we can arbitrarily choose one of them. We observe that a similar approach has beenused in [15] for an optimized ad-hoc translation of this problem into SAT, where propositional variables represent theencoding of earliest starting times and latest ending times for all tasks, rather than their exact scheduled times. As anexample, Fig. 8(c) shows a solution of the first stage of the reformulated problem for the instance in Fig. 8(a), whichsubsumes the solution in Fig. 8(b).Example 4. (Bin packing [26, Prob. SR1]) In the Bin packing problem (cf. also [36]), we are asked to pack a set Iof items, each one having a given size, into a set B of bins, each one having a given capacity. Under the assumptionthat input instances are given as extensions for relations I , S, B, and C, where I encodes the set of items, B the setof bins, S the size of items (a tuple (cid:17)i, s(cid:18) for each item i), and C the capacity of bins (a tuple (cid:17)b, c(cid:18) for each bin b), anESO specification for this problem is as follows:∃P ∀i, b P (i, b) → I (i) ∧ B(b) ∧∀i ∃b I (i) → P (i, b) ∧P (i, b) ∧ P (i, b∀i, b, b(cid:2)(cid:7)∀b, c C(b, c) → sum(cid:14)(cid:14)) → b = b(cid:14)s | P (i, b) ∧ S(i, s)(cid:3) c(18)(19)(20)(21)(cid:8)(cid:3)where, to simplify notations, we assume bounded integers to encode the size of items and capacity of bins, and theexistence of a function sum that returns the sum of elements that belong to the set given as argument. We remind thatbounded integers and arithmetic operations over them do not add expressive power to ESO.In the above specification, a solution is a total mapping P from items to bins. Constraints force the mapping to be,respectively, over the right relations (18), total (19), mono-valued (20), and satisfying the capacity constraint for everybin (21).790M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801(a)(b)(c)Fig. 8. (a) An instance of the Job-shop scheduling problem, consisting in 3 jobs of, respectively, 4, 3, and 5 tasks each, to be executed on 3processors. (b) A possible solution of the whole problem for the instance in (a). (c) A solution of the first stage of the reformulated problem, thatsubsumes that in (b). Shades indicate multiple good starting times for tasks.In particular, by unfolding the guessed predicate P to |I | monadic predicates Pi , one for every item i, and, coher-ently, the whole specification, the constraints that can be delayed are the unfolding of (20), that force an item to bepacked in exactly one bin. Thus, by iteratively applying Theorem 1 by focusing on all unfolded guessed predicates,we intuitively allow an item to be assigned to several bins. In the second stage, we can arbitrarily choose one bin toobtain a solution of the original problem.Other problems that can be reformulated by safe-delay exist. Some examples are Schur’s Lemma (www.csplib.org,Prob. 15) and Ramsey problem (www.csplib.org, Prob. 17). A short discussion on how these reformulations can beaddressed is given in [7].As showed in the previous examples, it is worth noting that arithmetic constraints do not interfere with our refor-mulation technique. As an instance, in the last example, the “(cid:3)” predicate leads to clauses that remain satisfied if theextension of the selected guessed predicate is shrunk, while keeping everything else fixed.3.4. Non-shrink second stagesAs specified at the beginning of Section 3, in this paper we have focused on second stages in which the extensionof the selected guessed predicate can only be shrunk, while those for the other ones remain fixed.Actually, there are other specifications which are amenable to be reformulated by safe-delay, although with adifferent kind of second stages. As an example, we show a specification for the Golomb ruler problem.Example 5. (Golomb ruler (www.csplib.org, Prob. 6)) In this problem, we are asked to put m marks M1, . . . , Mm ondifferent points on a ruler of length l in such a way that:M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801791(1) Mark i is put on the left (i.e., before) mark j if and only if i < j , and(2) The m(m − 1)/2 distances among pairs of distinct marks are all different.By assuming that input instances are given as extensions for unary relations M (encoding the set of marks) and P(encoding the l points on the ruler), and that the function “+” and the predicate “<” are correctly defined on tuples inM and on those in P , a specification for this problem is as follows:(cid:14)(cid:14)∃G ∀m, i G(m, i) → M(m) ∧ P (i) ∧∀m ∃i M(m) → P (m, i) ∧(cid:14)G(m, i) ∧ G(m, i∀m, i, i(cid:14)∀m, m(cid:14)∀m, m) → i = i(cid:14)(cid:14)G(m, i) ∧ G(m, j, j, n, n, i, i(cid:14)(cid:14)G(m, i) ∧ G(m(cid:14) ∧ n < nm < m(cid:14) − i) (cid:13)= (j, i, i, i(i(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)) ∧ G(n, j ) ∧ G(n) ∧, j, i(cid:14) ∧ (m < n ∨ (m = n ∧ m(cid:14)< n(cid:14) − j ).(cid:14) ∧) ∧ m < m(cid:14) → i < i(cid:14))) →(cid:14) ∧(22)(23)(24)(25)(26)A solution is thus an extension for the guessed predicate G which is a mapping (22–24) assigning a point in theruler to every mark, such that the order of marks is respected (25) and distances between two different marks are alldifferent (26).Here, the constraint that can be delayed is (25), which forces the ascending ordering among marks. By neglectingit, we extend the set of solutions of the original problem with all their permutations. In the second stage, the correctordering among marks can be enforced in polynomial time.By unfolding the binary guessed predicate G, we obtain |M| monadic predicates Gm, one for each mark m. Oncea solution of the simplified specification has been computed, by focusing on all of them, in order to reinforce them(m − 1)/2 unfolded constraints derived from (25), we possibly have to exchange tuples among pairs of predicatesGm and Gm(cid:14) , for all m (cid:13)= m(cid:14), and not to shrink the extensions of single guessed predicates. Hence, Theorem 1 doesnot apply. Furthermore, a modification of some of the other constraints may be needed to ensure the correctness of thereformulation. In particular, in constraint (26) differences must be replaced by their absolute values.As for the effectiveness of such a reformulation, it can be objected that the constraints delayed actually break thepermutation symmetry, and removing them is likely to be not a good choice. However, even if this is likely to betrue for CP solvers, like those based on backtracking, it is not obvious for others, e.g., SAT ones. In [7] we showhow delaying such constraints significantly drops down the instantiation time needed by the NP-SPEC SAT compiler,without major variations in the solving times of the best SAT solver (ZCHAFF).Another class of problems that are amenable to be reformulated by safe-delay is an important subclass of per-mutation problems, that includes, e.g., Hamiltonian path (HP), Permutation flow-shop, and Tiling. Some preliminaryresults on how these problems can be reformulated appear in [34]. As an example, HP can be reformulated by lookingfor (small) cliques in the graph, and viewing them as single nodes. If we find an HP of the reduced graph, we can, inpolynomial time, obtain a valid solution of the original problem, since cliques can be traversed in any order.We are currently investigating the formal aspects of such a generalization, and for which class of solvers this kindof reformulations are effective in practice.4. Methodological discussionIn this section we make a discussion on the methodology we adopted in this work, in particular the use of ESO asa modelling language, and the choice of the solvers for the experimentation.As already claimed in Section 1, and as the previous examples show, using ESO for specifying problems wipesout many aspects of state-of-the-art languages which are somehow difficult to take into account (e.g., numbers,arithmetics, constructs for functions, etc.), thus simplifying the task of finding criteria for reformulating problemspecifications. However, it must be observed that ESO, even if somewhat limited, is not too far away from the mod-elling languages provided by some commercial systems.792M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801A good example of such a language is AMPL [22], which admits only linear constraints: in this case, the reformu-lation technique described in Theorem 1 can often be straightforwardly applied; as an instance, a specification of thek-coloring problem in such a language is as follows:param n_nodes;param n_colors integer, > 0;set NODES := 1..n_nodes;set EDGES within NODES cross NODES;set COLORS := 1..n_colors;# Coloring of nodes as a 2-ary predicatevar Coloring {NODES,COLORS} binary;s.t. CoveringAndDisjointness {x in NODES}:# nodes have exactly one colorsum {c in COLORS} Coloring[x,c] = 1;s.t. GoodColoring {(x,y) in EDGES, c in COLORS}:# nodes linked by an edge have diff. colorsColoring[x,c] + Coloring[y,c] <= 1;The reformulated specification can be obtained by simply replacing the “CoveringAndDisjointness” constraint withthe following one:s.t. Covering {x in NODES}sum {c in COLORS} Coloring[x,c] >= 1;thus leading exactly to the reformulated specification of Example 1.As for languages that admit non-linear constraints, e.g., OPL, it is possible to write a different specification usinginteger variables for the colors and inequality of colors between adjacent nodes. In this case it is not possible toseparate the disjointness constraint from the other ones, since it is implicit in the definition of the domains. Of course,study of safe-delay constraints is relevant also for such languages, because we can always specify in OPL problemssuch as the one of Example 5, which has such constraints, or we may want to write a linear specification for a givenproblem, in order to use a linear solver, more efficient in many cases (cf. Section 5).For what concerns the experimentation, it must be observed that a specification written in ESO naturally leadsto a translation into a SAT instance. For this reason, we have chosen to use, among others, SAT solvers for theexperimentation of the proposed technique. Moreover we considered also the impressive improving in performancesrecently shown by state-of-the art SAT solvers.As already claimed in Section 1, the effectiveness of a reformulation technique is expected to strongly depend onthe particular solver used. To this end, we solved the same set of instances with SAT solvers of very different nature(cf. Section 5). Finally, since it is well-known that state-of-the-art linear and constraint programming systems mayperform better than SAT on some problems, we repeated the experimentation by using commercial systems CPLEX(linear) and SOLVER (non-linear), invoked by OPLSTUDIO.45. Experimental resultsWe made an experimentation of our reformulation technique on 3-coloring (randomly generated instances), k-coloring (benchmark instances from the DIMACS repository5), and job-shop scheduling (benchmark instances fromOR library6), using both SAT-based solvers (and the NP-SPEC SAT compiler [8] for the instantiation stage), and theconstraint and linear programming system OPL [48], obviously using it as a pure modelling language, and omittingsearch procedures.4 Cf. http://www.ilog.com.5 Cf. ftp://dimacs.rutgers.edu/pub/challenge.6 Cf. http://www.ms.ic.ac.uk/info.html.M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801793Table 1Experimental results for 3-coloring on random instances with 500 nodes (100 instances for each fixed number of edges). Solving times (in seconds,with timeout of 1 hour) are relative to each set of 100 instancesUnd.edgese/n ZCHAFF(cid:9)No delay(cid:9)Delay % sav.WALKSAT(cid:9)No delay(cid:9)Delay % sav.BG-WALKSAT(cid:9)(cid:9)No delayDelay % sav.SATZ(cid:9)No delay(cid:9)Delay % sav.5006007008009001000110012001300140015000.262.00.132.40.222.80.23.20.183.60.164.04.411.254.8 80537.811497.695.260.45.618.776.00.000.260.920.22 −69.232.2245.450.128.4850.000.19.330.1422.2218.1848.7756.250.0712.07 −7.29 119.7086843.41 −7.83 129.353.77 134.501441.2459.771.04 145.3224.1 −28.40 147.680.601.827.588.5816.5242.82105.50112.05115.80119.93125.2534.552.4318.053.6310.619.928.0410.959.1719.8848.6212.2011.86 119.4713.37 129.7513.90 138.3717.47 145.5315.19 152.821.853.008.609.8217.8742.97105.47113.78117.58124.68128.9710.1723.978.9717.437210.9613.2810.357208.1910.14 14408.311.62 18787.411.72 11825.4412.31 16686.21700.1415.0295.0914.3331.5615.617.175.0829.5043.3710804.02 −49.837240.53 −0.4514403.530.0321603.45 −14.9925.818772.8126.4112279.1922.25544.3517.6978.2714.6126.95As for the SAT-based experimentation, we used four solvers of very different nature: the DPLL-based completesystems ZCHAFF [38] and SATZ [33], and the local-search based incomplete solvers WALKSAT [45] and BG-WALKSAT[51] (the last one being guided by “backbones”). We solved all instances both with and without delaying constraints.As for OPL, we wrote both a linear and a non-linear specification for the above problems, and applied our reformulationtechnique to the linear one (cf. Section 4). All solvers have been used with their default parameters, without anyheuristic or tuning that would possibly alter their performances. This is coherent with the declarative approach weadopted in this paper.Experiments were executed on an Intel 2.4 GHz Xeon bi-processor computer. The size of instances was chosen sothat our machine is able to solve (most of) them in more than a few seconds, and less than one hour. In this way, bothinstantiation and post-processing, i.e., evaluation of delayed constraints, times are negligible, and comparison can bedone only on the solving time.In what follows, we refer to the saving percentage, defined as the ratio:(time_no_delay − time_delay)/time_no_delay3-coloring. We solved the problem on 1500 randomly generated graph instances with 500 nodes each. The numberof edges varies, and covers the phase transition region [11]: the ratio (# of directed edges/# of nodes) varies between2.0 and 6.0. In particular, we considered sets of 100 instances for each fixed number of edges, and solved each set bothwith and without delaying disjointness constraints (timeout was set at 1 hour). Table 1 shows overall solving times foreach set of instances, for all the SAT solvers under consideration.As it can be observed, the saving percentage depends both on the edges/nodes ratio, and on the solver. However,we have consistent time savings for many classes of instances. In particular, ZCHAFF seems not to be positivelyaffected by safe-delay, and, for some classes of instances, e.g., those with 1500 edges, it seems to be negativelyaffected (−28.40%). On the other hand, both local-search based SAT solvers, i.e., WALKSAT and BG-WALKSAT showa consistent improvement with our reformulation technique, saving between 13% and 17% for hard instances. Thisbehavior is consistent with the observation that enlarging the set of solutions can be profitable for this kind of solvers,and will be discussed at the end of this section, since it has been observed in all our experiments. Even if these areincomplete solvers, they have been always able to find a solution for satisfiable instances, except for the class ofinput graphs with 1100 edges: in this case, they found a solution on the 40% (WALKSAT) and 50% (BG-WALKSAT)of positive instances. Delaying disjointness constraints does not alter this percentage in a significant way. Also SATZbenefits from safe-delay, with savings between 22% and 26% for hard instances, even if underconstrained instances(e.g., those with 700 edges) highlight poorer performances (−49.83%).It is worth noting, from the experiments described above, that the effectiveness of the reformulation may dependalso on some instance-dependent parameters like, e.g., the edges/nodes ratio. However, this does exclude that someclasses of solvers often benefit from the technique. In particular, it is interesting to note that the best technology, i.e.,local search, is always improved.794M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801For what concerns CPLEX instead, experimental results do not highlight significant variations in performances,since, in many cases, for the same set of 1500 instances, either both solving times were negligible, or a timeoutoccurred both with and without disjointness constraints. Finally, by solving the linear specification with SOLVER weobserved the following mixed evidence: (i) About 15% of the instances were not solved, regardless of safe-delay;(ii) Another 15% of the instances were successfully solved with the original specification, but performing safe-delayon them prevented the system from terminate within the time limit; (iii) As for the remaining instances, averagesavings in time were often appreciable.k-coloring. We solved the k-coloring problem on several benchmark instances of various classes of the DIMACSrepository, with k close to the optimum, in order to have non-trivial instances, both positive and negative.Results of our SAT-based experiments are shown in Table 2. As it can be observed, also here the effectiveness ofthe reformulation technique varies among the different solvers. In particular, ZCHAFF benefits by safe-delay on severalinstances, both positive and negative, but not on all of them. On the other hand, for local search solvers WALKSATand BG-WALKSAT, delaying disjointness constraints always (except for very few cases) speeds-up the computation(usually by 20–30%). The same happens when using SATZ with even higher savings, even if this solver timeouts forseveral instances.As for OPL instead, we have mixed evidence, since it is not the case that the linear specification (solved usingCPLEX) is always more efficient than the non-linear one (solved using SOLVER), or vice versa. Indeed, the linear spec-ification, when solved with CPLEX, often, but not always, benefits from safe-delay. Table 3 shows results obtainedon graphs of various classes of the benchmark set. Differently from Table 2, in this case, due to the higher numberof instances solved, we opted for showing aggregate results, grouping together instances of the same class. In partic-Table 2Solving times (seconds) for k-coloring (SAT solvers)InstanceColors Sol-ZCHAFFWALKSATBG-WALKSATSATZvable?No delay Delay % sav.No delay Delay % sav. No delay Delay % sav. No delay Delay % sav.10anna11anna10david11david8DSJC125.510DSJC250.55DSJC500.15le450_5a5le450_5b5le450_5c9le450_5c5le450_5d9miles50020miles50030mulsol.i.231mulsol.i.230mulsol.i.331mulsol.i.330mulsol.i.431mulsol.i.430mulsol.i.531mulsol.i.55myciel56myciel59queen8_810queen9_9queen11_11 13queen14_14 1712queen8_12NYNYNNNYYYYYNYNYNYNYNYNYYYYYY24.870.0115.150.141.42–11.1417.2327.770.0211.200.0980.190.01–0.01–0.01–0.01–0.0139.6115.020.000.0113.9313.040.000.190.254.04>98.5452.6986.091.5594.720.9195.101.360.000.0283.841.811.20 −1233.3331.9754.550.000.01––0.000.01––0.000.01––0.000.01––0.000.01413.99 1714.26 <−314.080.000.01−53.501397.23 2144.76––−55.95863.14114.14 −543.041.78 −1269.23–553.4617.750.130.0111.835.716.4840.000.050.0814.334.785.5825.000.070.05–mem mem–mem mem–mem mem9.234.915.4217.305.106.17*13.338.6710.00*0.001.201.204.318.158.526.248.519.0831.250.360.5320.7528.83 22.8544.312.3621.1229.20 23.0341.112.4819.7829.40 23.5840.912.3819.9126.70 21.3845.322.5312.501.160.000.0224.523.9510.958.22* 7.31*15.1335.799.718.27 11.82 −42.9411.084.685.274.631.330.025.234.254.224.034.06.20.060.14.665.520.050.07mem memmem memmem mem5.51 4.97*6.15*5.489.65 9.23*1.351.478.408.427.389.700.460.6330.18 24.162.804.2131.47 24.383.054.6030.93 24.812.764.9828.48 22.632.885.421.151.330.010.014.135.258.43* 7.61*14.47 11.634.5733.3315.4125.00–––9.9710.844.327.950.2023.9226.3219.9333.6022.5133.7019.7744.4820.5446.7713.750.0021.279.6819.599.08 −22.755.255.717.406.03–0.29–0.63–––0.09–0.08––158.67 145.3377.1696.8393.33104.6220.0222.45––5.206.00––3.768.36––2.675.10––2.705.04––2.735.08––2.745.1439.2552.890.040.100.220.2745.5156.91205.66 175.62943.30 708.920.250.35–68.97–87.30––8.4120.3110.7910.82–13.33–55.02–47.65–46.43–46.26–46.6925.7960.0018.5220.0314.6124.8628.57(‘–’ means that the solver did not terminate in one hour, while ‘mem’ that an out-of-memory error occurred. A ‘*’ means that the local search solverdid not find a solution.)M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801795Table 3Aggregate results (sum of solving times in seconds) for k-coloring (CPLEX)ClassLeighton(le graphs)Random(DSJC graphs)Reg. alloc.(fpsol, mulsol, zeroin graphs)SGB book(anna, david, huck, jean graphs)SGB milesSGB gamesSGB queenMycielskyAllInstancesSolvableNumberYNTotalYNTotalYNTotalYNTotalYNTotalYNTotalYNTotalYNTotalYNTotal369145911044832511211415527372461CPLEXNo delay4776.52110.644887.1619.225026.085045.3012423.8522.7912446.642.161.914.07138.242.98141.220.970.971.9411806.538.9311815.467.086.0813.1629174.575180.3834354.95Delay6660.0740.426700.4918.154112.104130.2511179.6414.2411193.882.271.713.98197.232.07199.300.881.051.936319.209.336328.534.975.5710.5424382.414186.4928568.90Saving−1883.5570.22−1813.331.07913.98915.051244.218.551252.76−0.110.200.09−58.990.91−58.080.09−0.080.015487.33−0.405486.932.110.512.624792.16993.895786.05Saving %−39.43%63.47%−37.10%5.57%18.18%18.14%10.01%37.52%10.07%−5.09%10.47%2.21%−42.67%30.54%−41.13%9.28%−8.25%0.52%46.48%−4.48%46.44%29.80%8.39%19.91%16.43%19.19%16.84%ular, for each class, we write the number of instances solved, and the time needed by CPLEX for both positive andnegative ones, with and without safe-delay (instances that couldn’t be solved in one hour by both specifications havebeen removed). It can be observed that the reformulated specification is more efficient, on the average, especially onnegative instances. Actually, safe-delay is really deleterious in only two cases: positive instances of “Leighton” and“SGB miles” classes.Job shop scheduling. We considered 40 benchmark instances known as LA01, . . . , LA40, with the number of tasksranging between 50 and 225, number of jobs between 10 and 15, and number of processors ranging between 5 and 15.However, in order to make our solvers (especially the SAT ones) able to deal with such large instances, we reduced(and rounded) all task lengths and the global deadline by a factor of 20 (original lengths were up to 100). In this way,we obtained instances that are good approximations of the original ones, but with much smaller time horizons, hencefewer propositional variables need to be generated.SAT solving times are listed in Table 4 for different values for the deadline. Again, we have a mixed evidence forwhat concerns ZCHAFF, which benefits from safe-delay on many but not all instances, while savings in time are alwayspositive when using local search solvers WALKSAT and BG-WALKSAT (even when they are not able to find a solutionfor positive instances, delaying constraints makes them terminate earlier). As for SATZ, savings in performances areoften very high, even if this solver is able to solve only a small portion of the instance set. Interestingly, the blow-down in the number of clauses due to safe-delay, in some cases makes the solver able to handle some large instances(cf. Table 4, e.g., instance LA06 with deadline 50), preventing the system from running out of memory (even if, inmany cases, the out-of-memory error changes to a timeout).796M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801Table 4Solving times (seconds) for job shop schedulingInstance Proc Tasks Jobs Dead-lineSol-vable?ZCHAFFWALKSATBG-WALKSATSATZNo delay Delay % sav.No delay Delay % sav. No delay Delay % sav. No delay Delay % sav.la01la01la02la02la03la03la04la04la05la05la06la06la07la07la08la08la09la09la10la10la16la16la17la17la18la18la19la19la20la20la22la22la23la23la24la24la25la25la29la29la36la36la38la38la39la39la40la4055555555555555555555101010101010101010101010101010101010101015151515151515155050505050505050505075757575757575757575100100100100100100100100100100150150150150150150150150200200225225225225225225225225101010101010101010101515151515151515151510101010101010101010151515151515151520201515151515151515333432333132293028294650435042434650465047483940414242434445485050534648485050756265587561625975NYNYNYNYNYNYNYNYNYNYNYNYNYNYNYNYNYNYNYNYNYNYNYNY0.690.131.752.342.771.921.114.051.330.29–0.44–1.27–0.85 −23.191.24 −853.858.001.6154.271.0724.192.1083.850.314.501.0630.122.830.9925.560.57 −96.55–1.89 −329.55–22.83–30.83––––0.98–262.44 181.53––0.315.76––2.2315.44155.2641.5890.71151.6487.6618.715.423.7231.374.19 −13.863.686.3133.284.215.753.2743.1333.8733.0950.04120.68 154.67 −28.1711.755.3333.3213.91––47.19619.5– 934.79 >48.0742.86– 1028.5610.70138.15 123.37– 1083.31 >39.823.52356.56 344.02438.27 510.21 −16.4169.26705.09 216.74– 1387.73 >22.9036.84– 527.86 >70.67– 844.58 >53.08– <−35.361329.741193.76 1773.00 −48.52787.54 918.24 −16.6027.98989.98 712.96−8.871154.18 1256.546.0420.86–1173.041238.0478239.83 31.13 21.8440.77* 31.42* 22.9436.63 28.63 21.8437.37* 28.80* 22.9332.78 25.37 22.6232.85* 25.53* 22.2733.22 26.10 21.4233.25* 26.22* 21.1528.92 22.83 21.0426.42 18.40 30.3578.10 62.92 19.4477.32 60.20* 22.1478.35 62.21 20.5978.62* 60.78* 22.6877.02 60.72 21.1676.83* 62.02* 19.2886.58 67.20 22.3985.73* 65.40* 23.7280.80 64.86 19.7280.10* 61.90* 22.7269.33 51.73 25.3869.87* 51.55* 26.2257.03 44.46 22.0357.82* 44.20* 23.5562.30 47.53 23.7063.72* 47.50* 25.4563.28 47.17 25.4764.83* 48.53* 25.1466.52 50.68 23.8068.87* 50.60* 26.52––––––––––––––––––mem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem mem39.55 31.21 21.0740.72* 31.95* 21.5337.95 29.92 21.1738.23* 29.10* 23.8932.92 25.11 23.7032.67* 26.31* 19.4433.48 26.06 22.1534.47* 26.02* 24.5229.25 23.10 21.0327.73* 19.46 29.8179.98 63.00 21.2378.77* 60.37* 23.3680.10 62.55 21.9178.08* 59.40* 23.9376.18 60.17 21.0277.25* 61.07* 20.9586.57 67.15 22.4383.65* 63.30 24.3381.42 63.07 22.5480.97* 61.05* 24.6067.47 51.11 24.2370.70* 51.53* 27.1156.23 43.78 22.1458.80* 43.71* 25.6561.12 45.48 25.5862.17* 46.85* 24.6447.4 25.9063.9763.52* 47.58* 25.0966.22 49.53 25.2067.47* 49.40* 26.78––––––––––––––––––mem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem memmem mem–––––––––––––154.49–––––1.76 98.86––––904.38 189.44 79.05699.77 295.12 57.83––0.890.58 34.83mem–mem4.87 100.00––mem––––––memmem 3108.10 100.00–mem––mem––mem––mem––––––––––––––––– 3524.02 >2.11–––––mem–mem–mem–mem–mem–mem–mem–mem–mem–mem–mem–mem–mem–mem–mem–mem–mem–memmemmemmemmemmemmemmemmemmemmemmemmemmemmemmemmemmemmemmemmem(‘–’ means that the solver did not terminate in one hour, while ‘mem’ that an out-of-memory error occurred. A ‘*’ means that the local search solverdid not find a solution.)For what concerns the experiments in OPL instead, both CPLEX and SOLVER (run on the linear specification), seemnot to be much affected by delaying constraints (or even affected negatively), and anyway are typically slower thanSAT. For this reason, detailed results are omitted.Summing up, we solved several thousands of instances. On the average, delaying constraints seems to be usefulwhen using a SAT solver. In particular, local search solvers like WALKSAT and BG-WALKSAT almost always benefitM. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801797from the reformulation. The same happens when using SATZ. As for ZCHAFF, we have mixed evidence, since insome cases it seems not to be affected by safe-delay (cf., e.g., results in Table 1), or affected negatively, while inothers it benefits from the reformulation (cf., e.g., Tables 2 and 4). The behavior of SAT solvers can be explained byconsidering the two phenomena that safe-delay produces: (i) The reduction of the number of clauses, and (ii) Theenlargement of the set of solutions. The latter phenomenon is particularly beneficial when dealing with local search,as already observed in, e.g., [41,43] where symmetry-breaking (a technique that reduces the solution density) has beenexperimentally proven to be an obstacle for these algorithms. Of course, also the reduced number of clauses in generalhelps the solver. Nonetheless, it is worth noting that clauses derived from disjointness constraints are short, and thisintuitively explains why the most efficient complete solver, ZCHAFF, that has powerful algorithms to efficiently dealwith short clauses (with respect to SATZ), not always benefits from safe-delay.As far as CPLEX and SOLVER are concerned, we have mixed evidence. First of all, as already observed, it is notalways the case that the linear specification solved with CPLEX is always faster than the non-linear one solved withSOLVER, or vice versa. However, in those cases in which CPLEX is faster, delaying constraints often speeds-up thecomputation. This is consistent with the observation that, from a theoretical point of view, finding a partitioningis much harder than finding a covering, and in practice this often holds also in presence of additional constraints.Moreover, as for the beneficial behavior highlighted on negative instances, deeper analyses on the number of iterationsand branches show that (i) More iterations are needed, on the average, by the simplex algorithm when invoked on thespecification with no delay, and (ii) The number of branches is often unaffected when performing safe-delay. Inparticular, the latter issue suggests that each branch-and-bound subproblem is often solved more efficiently on thespecification with safe-delay. Unfortunately, since CPLEX is not an open-source system, it is hard to analyze andexplain its behavior in greater detail.Finally, as for SOLVER when invoked on the linear specification, we observed that safe-delay has often (but notalways) a negative effect, and this behavior is in line with the common observation, cf., e.g., the literature aboutsymmetry-breaking and the addition of implied constraints, that restricting the set of solutions and adding tighterconstraints helps when dealing with solvers based on backtracking, since this can significantly increase the amount ofpropagation, and consequently leads to a better pruning of the search space.6. Conclusions, related and future workIn this paper we have shown a simple reformulation architecture and proven its soundness for a large class ofproblems. The reformulation allows to delay the solution of some constraints, which often results in faster solving. Inthis way, we have shown that reasoning on a specification can be very effective, at least on some classes of solvers.Although Theorem 1 calls for a tautology checking (cf. Hyp 2), we have shown different specifications for whichthis test is immediate. Furthermore, we believe that, in practice, an automated theorem prover (ATP) can be used toreason on specifications, thus making it possible to automatically perform the task of choosing constraints to delay.Actually, in another paper [6] we have shown that state-of-the-art ATPs usually perform very well in similar tasks(i.e., detecting and breaking symmetries and detecting functional dependencies on problem specifications).Related work. Several researchers addressed the issue of reformulation of a problem after the instantiation phase:as an example, in [50] it is shown how to translate an instantiated CSP into its Boolean form, which is useful forfinding different reformulations, while in [13] the proposed approach is to generate a conjunctive decomposition ofan instantiated CSP, by localizing independent subproblems. Furthermore, in [24], the system CGRASS is presented,allowing for the automated breaking of symmetries and the generation of useful implied constraints in a CSP. Finally,in [23] it is shown that abstracting problems by simplifying constraints is useful for finding more efficient reformula-tions of the original problem; the abstraction may require backtracking for finding solutions of the original problem.In our work, we focus on reformulation of the specification, i.e., regardless of the instance, and, differently from othertechniques, the approach is backtracking-free: once the first stage is completed, a solution will surely be found byevaluating the delayed constraints.Other papers investigate the best way to encode an instance of a problem into a format adequate for a specific solver.As an example, many different ways for encoding graph coloring or permutation problems into SAT have been figuredout, cf., e.g., [25,49]. In particular, the idea of looking for “multivalued” functions has been already implemented inad-hoc techniques for encoding various problems into SAT, like Graph coloring [42,46] and Job shop scheduling [15].Conversely, in our work we take a specification-oriented approach, giving a formal justification of why some of the798M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801constraints can be safely delayed, and presenting sufficient conditions that can be effectively used in order to isolatesuch constraints.Finally, we point out that a logic-based approach has also been successfully adopted in the ‘80s to study the queryoptimization problem for relational DBs. Analogously to our approach, the query optimization problem has beenattacked relying on the query (i.e., the specification) only, without considering the database (i.e., the instance), andit was firstly studied in a formal way using first-order logic (cf., e.g., [2,10,30,44]). In a later stage, the theoreticalframework has been translated into rules for the automated rewriting of queries expressed in real world languages andsystems.Since the effectiveness of a particular reformulation technique is expected to depend both on the problem and onthe solver (even if this does not rule out, in principle, the possibility to find reformulations that are good for all solvers,or for solvers of a certain class), our research investigates the reformulation problem in different and complementarydirections: in particular, in related work, we study how to detect symmetries [35] and functional dependencies [5]among predicates in specifications, and how specifications can be rewritten by exploiting these properties: symmetriescan be broken by appropriate symmetry-breaking constraints added to the problem specification, and dependenciescan be exploited by automatically synthesizing suitable search strategies. Experimental analysis shows how theseapproaches are effective in practice, for different classes of solvers. We have also shown [6] how automatic tools, suchas first-order theorem provers and finite model finders can be exploited, in practical circumstances, to make this kindof reasoning by computer.Future work. In this paper we have focused on a form of reformulation which partitions the first-order part of aspecification. This basic idea can be generalized, as an example by evaluating in both stages of the computation aconstraint (e.g., (9)), or to allow non-shrink second stages (cf., e.g., the specification for the Golomb ruler problemin Example 5), in order to allow reformulation for a larger class of specifications. Even more generally, the sec-ond stage may amount to the evaluation of a second-order formula. In the future, we plan—with a more extensiveexperimentation—to check whether such generalizations are effective in practice.Another important issue is to understand the relationships between delaying constraints and other techniques, e.g.,symmetry breaking. In fact, it is not always the case that delaying constraints, and so making the set of solutions larger,improves the solving process. Adding, e.g., symmetry-breaking or implied constraints are well known techniques thatmay reach the same goal with the opposite strategy, i.e., reducing the set of solutions. Currently, it is not completelyclear in which cases removing constraints results in better performances with respect to adding more constraints to thespecification itself, even if it seems that an important role is played by the nature of constraints we remove or add, e.g.,by their amenability to propagation in the search tree, together with the nature of the solver used, e.g., backtracking,linear, or based on local search. As for the latter class of solvers, it is known that enlarging the set of solutions cansignificantly speed-up performances (cf., e.g., [41,43]). Our experiments on WALKSAT and BG-WALKSAT confirm thisthesis.Finally, it is our goal to rephrase the theoretical results into rules for automatically reformulating problem specifi-cations given in more complex languages, e.g. AMPL and OPL, which have higher-level built-in constructs.AcknowledgementsThis research has been supported by MIUR (Italian Ministry for Instruction, University, and Research) underthe FIRB project ASTRO (Automazione dell’Ingegneria del Software basata su Conoscenza), and under the COFINproject “Design and development of a software system for the specification and efficient solution of combinatorialproblems, based on a high-level language, and techniques for intensional reasoning and local search”. The authors aregrateful to Carlo Mannino and Stefano Smriglio for useful discussions about CPLEX, and to the anonymous reviewersfor their comments and suggestions.Appendix A. Proofs of resultsProof of Theorem 1. Let I be an instance, M ∗ be a list of extensions for (S1, . . . , Sh, S∗) such that (M ∗, I) |= ψ s ,and ext(S) be an extension for S such that (M ∗, ext(S), I) |= ψ d .From the definition of ψ d , it follows that:(cid:2)(cid:3)∗M, ext(S), I|= ∀X S(X) → S∗(X),799(A.1)(A.2)M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801and so, since clauses in Ξ ∗ contain at most negative occurrences of S∗, that:(cid:3)∗, ext(S), I|= Ξ.(cid:2)M(cid:2)M(cid:2)M∗(cid:2)M∗Furthermore, from the definition of ψ s it follows that:(cid:3)∗, I|= ∀X α(X) → S∗(X),and from Hyp 2 that:∗(M, I) |= ∀X α(X) → S∗(X) ∧ β(X).This implies, by the definition of ψ d , that:(cid:3), ext(S), I|= ∀X α(X) → S(X).Moreover, by the same definition, it is also true that:(cid:3), ext(S), I|= ∀X S(X) → β(X).(A.3)From (A.1–A.3), and from the observation that S∗ does not occur in any of the right parts of them, the thesis fol-lows. (cid:2)Proof of Theorem 2. Let I be an input instance, and M be a list of extensions for (S1, . . . , Sh, S) such that (M, I) |=ψ . Let S∗ be defined in such a way that ext(S∗) = ext(S).Since solutions for ψ are also solutions for ψ s , and since ext(S∗) = ext(S), it follows that ((M − ext(S)) ∪ ext(S∗))is a solution of ψ s .As for ψ d , we observe that since M (which is a solution for the whole specification ψ) is also a solution for oneof its constraints, namely ∀X S(X) → β(X) (the delayed constraint), then, from ext(S∗) = ext(S), and in particularfrom the fact that ∀X S(X) → S∗(X) holds, it follows that (M, ext(S∗)) |= ∀X S(X) → S∗(X) ∧ β(X).Conversely, from ext(S∗) = ext(S), and in particular from the fact that ∀X S∗(X) → S(X) holds, it follows that(M, ext(S∗)) |= ∀X S∗(X) ∧ β(X) → S(X).Hence, the thesis follows. (cid:2)References[1] S. Abiteboul, R. Hull, V. Vianu, Foundations of Databases, Addison Wesley Publishing Company, Reading, MA, 1995.[2] A.V. Aho, Y. Sagiv, J.D. Ullman, Equivalences among relational expressions, SIAM Journal on Computing 2 (8) (1979) 218–246.[3] E. Börger, E. Gräedel, Y. Gurevich, The Classical Decision Problem, Perspectives in Mathematical Logic, Springer, Berlin, 1997.[4] C.A. Brown, L. Finkelstein, P.W. Purdom, Backtrack searching in the presence of symmetry, in: T. Mora (Ed.), Proceedings of the SixthInternational Conference on Applied Algebra, Algebraic Algorithms and Error Correcting Codes, Rome, Italy, in: Lecture Notes in ComputerScience, vol. 357, Springer, Berlin, 1988, pp. 99–110.[5] M. Cadoli, T. Mancini, Exploiting functional dependencies in declarative problem specifications, in: Proceedings of the Ninth EuropeanConference on Logics in Artificial Intelligence (JELIA 2004), Lisbon, Portugal, in: Lecture Notes in Artificial Intelligence, vol. 3229, Springer,Berlin, 2004.[6] M. Cadoli, T. Mancini, Using a theorem prover for reasoning on constraint problems, in: Proceedings of the Ninth Conference of the ItalianAssociation for Artificial Intelligence (AI*IA 2005), Milano, Italy, in: Lecture Notes in Artificial Intelligence, vol. 3673, Springer, Berlin,2005, pp. 38–49.[7] M. Cadoli, T. Mancini, F. Patrizi, SAT as an effective solving technology for constraint problems, in: Proceedings of the Twentieth ConvegnoItaliano di Logica Computazionale (CILC 2005), Roma, Italy, 2005.[8] M. Cadoli, A. Schaerf, Compiling problem specifications into SAT, Artificial Intelligence 162 (2005) 89–120.[9] E. Castillo, A.J. Conejo, P. Pedregal, R. García, N. Alguacil, Building and Solving Mathematical Programming Models in Engineering andScience, John Wiley & Sons, 2001.[10] A.K. Chandra, P.M. Merlin, Optimal implementation of conjunctive queries in relational databases, in: Proceedings of the Ninth ACM Sym-posium on Theory of Computing (STOC’77), Boulder, CO, ACM Press, 1977, pp. 77–90.[11] P. Cheeseman, B. Kanefski, W.M. Taylor, Where the really hard problem are, in: Proceedings of the Twelfth International Joint Conferenceon Artificial Intelligence (IJCAI’91), Sydney, Australia, Morgan Kaufmann, Los Altos, CA, 1991, pp. 163–169.[12] B.M.W. Cheng, K.M.F. Choi, J.H.-M. Lee, J.C.K. Wu, Increasing constraint propagation by redundant modeling: an experience report, Con-straints 4 (2) (1999) 167–192.[13] B.Y. Choueiry, G. Noubir, On the computation of local interchangeability in discrete constraint satisfaction problems, in: Proceedings of theFifteenth National Conference on Artificial Intelligence (AAAI’98), Madison, WI, AAAI Press/The MIT Press, 1998, pp. 326–333.800M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801[14] T.H. Cormen, C.E. Leiserson, R.L. Rivest, Introduction to Algorithms, The MIT Press, 1990.[15] J.M. Crawford, A.B. Baker, Experimental results on the application of satisfiability algorithms to scheduling problems, in: Proceedings of theTwelfth National Conference on Artificial Intelligence (AAAI’94), Seattle, WA, AAAI Press/The MIT Press, 1994, pp. 1092–1097.[16] J.M. Crawford, M.L. Ginsberg, E.M. Luks, A. Roy, Symmetry-breaking predicates for search problems, in: Proceedings of the Fifth Interna-tional Conference on the Principles of Knowledge Representation and Reasoning (KR’96), Cambridge, MA, Morgan Kaufmann, Los Altos,CA, 1996, pp. 148–159.[17] R. Dechter, Constraint networks (survey), in: Encyclopedia of Artificial Intelligence, second ed., John Wiley & Sons, 1992, pp. 276–285.[18] D. East, M. Truszczy`nski, Predicate-calculus based logics for modeling and solving search problems ACM Transactions on ComputationalLogic, 2004, submitted for publication.[19] R. Fagin, Generalized first-order spectra and polynomial-time recognizable sets, in: R.M. Karp (Ed.), Complexity of Computation, AmericanMathematical Society, Providence, RI, 1974, pp. 43–74.[20] P. Flener, Towards relational modelling of combinatorial optimisation problems, in: C. Bessière (Ed.), Proceedings of the International Work-shop on Modelling and Solving Problems with Constraints, in conjunction with the Seventeenth International Joint Conference on ArtificialIntelligence (IJCAI 2001), Seattle, WA, 2001.[21] P. Flener, J. Pearson, M. Ågren, Introducing ESRA, a relational language for modelling combinatorial problems, in: Proceedings of the Eigh-teenth IEEE Symposium on Logic in Computer Science (LICS 2004), Uppsala, Sweden, Springer, Berlin, 2003, pp. 214–232.[22] R. Fourer, D.M. Gay, B.W. Kernigham, AMPL: A Modeling Language for Mathematical Programming, International Thomson Publishing,1993.[23] E.C. Freuder, D. Sabin, Interchangeability supports abstraction and reformulation for multi-dimensional constraint satisfaction, in: Pro-ceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI’97), Providence, RI, AAAI Press/The MIT Press, 1997,pp. 191–196.[24] A. Frisch, I. Miguel, T. Walsh, CGRASS: A system for transforming constraint satisfaction problems, in: Proceedings of the Joint Workshop ofthe ERCIM Working Group on Constraints and the CologNet area on Constraint and Logic Programming on Constraint Solving and ConstraintLogic Programming (ERCIM 2002), Cork, Ireland, in: Lecture Notes in Artificial Intelligence, vol. 2627, Springer, Berlin, 2002, pp. 15–30.[25] A.M. Frisch, T.J. Peugniez, Solving non-boolean satisfiability problems with stochastic local search, in: Proceedings of the SeventeenthInternational Joint Conference on Artificial Intelligence (IJCAI 2001), Seattle, WA, Morgan Kaufmann, Los Altos, CA, 2001, pp. 282–290.[26] M.R. Garey, D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-Completeness, W.H. Freeman and Company, SanFrancisco, CA, 1979.[27] E. Giunchiglia, R. Sebastiani, Applying the Davis–Putnam procedure to non-clausal formulas, in: Proceedings of the Sixth Conference ofthe Italian Association for Artificial Intelligence (AI*IA’99), Bologna, Italy, in: Lecture Notes in Artificial Intelligence, vol. 1792, Springer,Berlin, 2000, pp. 84–94.[28] F. Giunchiglia, T. Walsh, A theory of abstraction, Artificial Intelligence 57 (1992) 323–389.[29] T. Hnich, T. Walsh, Why Channel? Multiple viewpoints for branching heuristics, in: Proceedings of the Second International Workshop onModelling and Reformulating CSPs: Towards Systematisation and Automation, in conjunction with the Ninth International Conference onPrinciples and Practice of Constraint Programming (CP 2003), Kinsale, Ireland, 2003.[30] A. Klug, On conjunctive queries containing inequalities, Journal of the ACM 1 (35) (1988) 146–160.[31] N. Leone, G. Pfeifer, W. Faber, T. Eiter, G. Gottlob, S. Perri, F. Scarcello, The DLV System for knowledge representation and reasoning, in:ACM Transactions on Computational Logic, submitted for publication.[32] C.M. Li, Integrating equivalency reasoning into Davis–Putnam procedure, in: Proceedings of the Seventeenth National Conference on ArtificialIntelligence (AAAI 2000), Austin, TX, AAAI Press/The MIT Press, 2000, pp. 291–296.[33] C.M. Li, Anbulagan, Heuristics based on unit propagation for satisfiability problems, in: Proceedings of the Fifteenth International JointConference on Artificial Intelligence (IJCAI’97), Nagoya, Japan, Morgan Kaufmann, Los Altos, CA, 1997, pp. 366–371.[34] T. Mancini, Reformulation techniques for a class of permutation problems, in: Proceedings of the Ninth International Conference on Principlesand Practice of Constraint Programming (CP 2003), Kinsale, Ireland, in: Lecture Notes in Computer Science, vol. 2833, Springer, Berlin, 2003,p. 984.[35] T. Mancini, M. Cadoli, Detecting and breaking symmetries by reasoning on problem specifications, in: Proceedings of the Sixth InternationalSymposium on Abstraction, Reformulation and Approximation (SARA 2005), Airth Castle, Scotland, UK, in: Lecture Notes in ArtificialIntelligence, vol. 3607, Springer, Berlin, 2005, pp. 165–181.[36] S. Martello, P. Toth, Knapsack Problems: Algorithms and Computer Implementation, John Wiley & Sons, 1990.[37] B.D. McKay, Nauty user’s guide (version 2.2). Available at http://cs.anu.edu.au/~bdm/nauty/nug.pdf, 2003.[38] M.W. Moskewicz, C.F. Madigan, Y. Zhao, L. Zhang, S. Malik, Chaff: Engineering an Efficient SAT Solver, in: Proceedings of the ThirtyEighth Conference on Design Automation (DAC 2001), Las Vegas, NV, ACM Press, 2001, pp. 530–535.[39] I. Niemelä, Logic programs with stable model semantics as a constraint programming paradigm, Annals of Mathematics and Artificial Intel-ligence 25 (3,4) (1999) 241–273.[40] C.H. Papadimitriou, Computational Complexity, Addison Wesley Publishing Company, Reading, MA, 1994.[41] S.D. Prestwich, Supersymmetric modeling for local search, in: Proceedings of the Second International Workshop on Symmetry in Con-straint Satisfaction Problems, in conjunction with the Eighth International Conference on Principles and Practice of Constraint Programming(CP 2002), Ithaca, NY, 2002.[42] S.D. Prestwich, Local search on SAT-encoded colouring problems, in: Proceedings of the Sixth International Conference on Theory andApplications of Satisfiability Testing (SAT 2003), Santa Margherita Ligure, Genova, Italy, in: Lecture Notes in Computer Science, vol. 2919,Springer, Berlin, 2004, pp. 105–119.M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801801[43] S.D. Prestwich, A. Roli, Symmetry breaking and local search spaces, in: R. Barták, M. Milano (Eds.), Proceedings of the Second InternationalConference on Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems (CPAIOR 2005),Prague, CZ, in: Lecture Notes in Computer Science, vol. 3524, Springer, Berlin, 2005, pp. 273–287.[44] Y. Sagiv, M. Yannakakis, Equivalence among relational expressions with the union and difference operations, Journal of the ACM 4 (27)(1980) 633–655.[45] B. Selman, H.A. Kautz, B. Cohen, Local search strategies for satisfiability testing, in: M. Trick, D.S. Johnson (Eds.), Proceedings of theSecond DIMACS Challenge on Cliques, Coloring, and Satisfiability, Providence, RI, 1993.[46] B. Selman, H. Levesque, D. Mitchell, A new method for solving hard satisfiability instances, in: Proceedings of the Tenth National Conferenceon Artificial Intelligence (AAAI’92), San Jose, CA, AAAI Press/The MIT Press, 1992.[47] B.M. Smith, K. Stergiou, T. Walsh, Using auxiliary variables and implied constraints to model non-binary problems, in: Proceedings of theSeventeenth National Conference on Artificial Intelligence (AAAI 2000), Austin, TX, AAAI Press/The MIT Press, 2000, pp. 182–187.[48] P. Van Hentenryck, The OPL Optimization Programming Language, The MIT Press, 1999.[49] T. Walsh, Permutation problems and channelling constraints, in: R. Nieuwenhuis, A. Voronkov (Eds.), Proceedings of the Eighth InternationalConference on Logic for Programming and Automated Reasoning (LPAR 2001), Havana, Cuba, in: Lecture Notes in Computer Science,vol. 2250, Springer, Berlin, 2001, pp. 377–391.[50] R. Weigel, C. Bliek, On reformulation of constraint satisfaction problems, in: Proceedings of the Thirteenth European Conference on ArtificialIntelligence (ECAI’98), Brighton, UK, John Wiley & Sons, 1998, pp. 254–258.[51] W. Zhang, A. Rangan, M. Looks, Backbone guided local search for maximum satisfiability, in: Proceedings of the Eighteenth InternationalJoint Conference on Artificial Intelligence (IJCAI 2003), Acapulco, Mexico, Morgan Kaufmann, Los Altos, CA, 2003, pp. 1179–1186.