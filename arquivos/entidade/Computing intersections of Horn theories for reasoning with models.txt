Artificial Intelligence 110 (1999) 57–101Computing intersections of Horn theories forreasoning with models IThomas Eiter a;(cid:3), Toshihide Ibaraki b;1, Kazuhisa Makino c;2a Institut und Ludwig Wittgenstein Labor für Informationssysteme, Knowledge-Based Systems Group,Technische Universität Wien, Treitlstrasse 3, A-1040 Wien, Austriab Department of Applied Mathematics and Physics, Graduate School of Informatics, Kyoto University,Kyoto 606, Japanc Department of Systems and Human Science, Graduate School of Engineering Science, Osaka University,Toyonaka, Osaka 560, JapanReceived 6 April 1998AbstractModel-based reasoning has been proposed as an alternative form of representing and accessinglogical knowledge bases. In this approach, a knowledge base is represented by a set of characteristicmodels. In this paper, we consider computational issues when combining logical knowledge bases,which are represented by their characteristic models; in particular, we study taking their logicalintersection. We present low-order polynomial time algorithms or prove intractability for the majorcomputation problems in the context of knowledge bases which are Horn theories. In particular,we show that a model of the intersection (cid:6) of Horn theories (cid:6)1; : : : ; (cid:6)l, represented by theircharacteristic models, can be found in linear time, and that some characteristic model of (cid:6) canbe found in polynomial time. Moreover, we present an algorithm which enumerates all the modelsof (cid:6) with polynomial delay. The analogous problem for the characteristic models is proved to beintractable, even if the possible exponential size of the output is taken into account. Furthermore,we show that approximate computation of the set of characteristic models is difficult as well.Nonetheless, we show that deduction from (cid:6) is possible for a large class of queries in polynomialtime, while abduction turns out to be intractable. We also consider a generalization of Horn theories,and prove negative results for the basic questions, indicating that an extension of the positive resultsbeyond Horn theories is not immediate. (cid:211) 1999 Elsevier Science B.V. All rights reserved.I An abstract of this paper containing some of the results appeared in: Proc. National Conference on ArtificialIntelligence (AAAI-98), Madison, WI, July 26–30, 1998, pp. 292–297.(cid:3)Corresponding author. Email: eiter@kr.tuwien.ac.at.1 Email: ibaraki@kuamp.kyoto-u.ac.jp.2 Email: makino@sys.es.osaka-u.ac.jp.0004-3702/99/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 9 9 ) 0 0 0 2 1 - 11999 Elsevier Science B.V. All rights reserved.58T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101Keywords: Automated reasoning; Model-based reasoning; Characteristic models; Algorithms and complexity;Knowledge representation1. IntroductionLogical languages are widely used as a basis for representing knowledge in advancedknowledge based systems (cf. [17]). The investigation of adequate languages, at thesyntactical as well as the semantical level, is an ongoing quest for improving onthe capabilities of current systems. In this approach, knowledge has been traditionallyrepresented by means of logical formulas, which are stored in a knowledge base KB;intuitively, such a KB is meant to capture the knowledge about a certain domain andstate of affairs, which is often called the “world”. The knowledge may be accessed byposing queries to KB, which are typically expressed by logical formulas (cid:11). The query (cid:11)is then answered by deduction or some other inference method from KB; i.e., it is testedwhether KB entails the query (cid:11) (KB ‘ (cid:11)). One of the main disadvantages of this approachis that deciding whether KB ‘ (cid:11) holds is intractable in already plain settings; e.g., in thepropositional context, it is a well-known co-NP-complete problem.More recently, model-based reasoning has been proposed as an alternative form ofrepresenting and accessing a logical knowledge base, cf. [13,24–26,29,30]. It can be seenas an approach towards Levesque’s notion of “vivid” reasoning [31], which asks for amore straight representation of a knowledge base, from which common-sense reasoning iseasier and more suitable than from the traditional one. In model-based reasoning, KB isrepresented by a subset S of its models, which are commonly called characteristic models,rather than by a set of formulas. Reasoning from KB becomes then as easy as to test,given a query (cid:11), whether (cid:11) is true in all models of S. For suitable (cid:11), this can be decidedefficiently. Moreover, it has also been shown that abduction from a KB represented byits characteristic models is polynomial [24,25,29], while this problem is intractable underformula representation [15,38].This time speed up comes at the price of space; indeed, the formula-based and themodel-based approach are orthogonal, in the sense that while a KB may have smallrepresentation in one formalism, it has an exponentially larger representation in the other.The intertranslatability of the two approaches, in particular for Horn theories, has beenaddressed in [24–27,29]. A number of techniques for efficient model-based representationof various fragments of propositional logic have been devised, cf. [25,29,30]. However,little attention has been paid so far on the important issue of how in this representationdifferent knowledge bases KB1; : : : ; KBl can be combined into a single KB.Main problems studiedThe semantical issue of combining knowledge bases, as well as closely related issues,have been studied in the recent literature, see, e.g., [1,2,7,18,23,33,36,39,41]. We do notintend to discuss the same issue here; rather, we are interested in tools and algorithms atthe operational level, which are needed for the implementation of a suitable semantics.In this context, a principal operation is taking the logical intersection of knowledgeT. Eiter et al. / Artificial Intelligence 110 (1999) 57–10159Sbases KB1; : : : ; KBl, i.e., the resulting knowledge base KB should have the models whichare common to all KBi ’s. While this operation is easily accomplished under formula-based representation (just take KB VDi KBi ), this task appears to be much morecomplicated under model-based representation. In fact, it is a priori not clear, how fromthe characteristic models of the individual KBi ’s the characteristic models of KB canbe efficiently constructed, and what computational cost is intrinsic to this problem. Forexample, even an efficient algorithm for simply deciding the consistency of KB is unclear.In this paper, we address this issue and study the problems of computing characteristicas well as arbitrary models of the logical intersection (cid:6) D (cid:6)1 \ (cid:1) (cid:1) (cid:1) \ (cid:6)l of propositionaltheories (cid:6)i . Here, we assume that a theory is a set of models. We focus on those (cid:6)i ’s whichare Horn theories; such theories are frequently encountered in the context of knowledgerepresentation, and their study in model-based reasoning received the main attention in[13,20,24–27], and was further discussed in [29]. In particular, we consider the followingmain problems in the context of model computation. Given the sets of characteristic modelsM1; : : : ; Ml representing Horn theories (cid:6)1; : : : ; (cid:6)l ,(cid:15) compute some arbitrary model of the theory (cid:6) D(cid:15) compute some arbitrary characteristic model of (cid:6) (Problem CMODEL);(cid:15) compute all models of the theory (cid:6) (Problem ALL-MODELS); and(cid:15) compute all characteristic models of (cid:6) (Problem ALL-CMODELS).Further problems on models, such as model checking [8,32], i.e., the recognition ofTliD1 (cid:6)i (Problem MODEL);models in (cid:6) and characteristic models, will be considered as well.Notice that Problem MODEL contains the consistency problem of (cid:6) as a subproblem;if we have an efficient algorithm for MODEL, then we can use it for an efficient checkwhether (cid:6) is consistent, i.e., whether (cid:6) 6D ; holds. Note that by the results of [14] (seealso [21]), Problem MODEL and the consistency check can be solved in linear time underformula representation.Obviously, Problem MODEL is not harder than Problem CMODEL, since any procedurefor the latter can be used for solving the former problem. However, it remains to seewhether the computation of an arbitrary model can be done more efficiently than acharacteristic model.Problem ALL-MODELS generalizes the first problem. Ideally, the generation of modelsis done one at a time, so that we can stop any time when no further models are desired.Such a procedure is valuable in case-based reasoning, for example, if one tries to find a“model” of the reality which fits a given description, or provides a good approximation forit. More generally, such an enumeration procedure can serve as a general purpose methodfor restricting the search space from the set of all models f0; 1gn to models of a knowledgebase (cid:6), if particular models of (cid:6) are computed.Problem ALL-CMODELS requests the complete output of (cid:6) in terms of its characteristicmodels. In ALL-MODELS, we might be satisfied if some models are initially produced fastand then the enumeration slows down; this can be useful if we want to find some “good”model within limited time. On the other hand, in ALL-CMODELS, quick generation of afew characteristic models is less important than a good overall behavior.From the results in [24], it easily follows that the output size of Problem ALL-MODELSmay be exponential in the input size (i.e., the number of characteristic models), even ifl D 1. Hence, a polynomial time algorithm for this problem is impossible, and the notion60T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101of efficient computation has to be reconsidered. A proposal in this vein is an algorithmwhich enumerates the models with polynomial delay [22], i.e., the next model is alwaysoutput in time polynomial in the input size, and the algorithm stops in polynomial time afterthe last output. Any such algorithm runs in polynomial total time [22], i.e., polynomial inthe combined size of input and output; if no polynomial total time algorithm exists, then aproblem may be considered as intractable.As discussed above, the model-based paradigm has been proposed to speed up on-linereasoning. It is therefore important to know, how reasoning from the logical intersection oftheories can be accomplished. In the seminal paper [24], deduction and abduction from aHorn theory, represented by its characteristic models, have been considered, and both wereshown to be tractable. We thus consider these two modes of reasoning on the intersection(cid:6) of Horn theories (cid:6)1, . . . , (cid:6)l represented by their characteristic models. The main issueshere are whether similar benign results as in [24,25] can be obtained, and in particularhow a suitable reasoning procedure, given the characteristic models of (cid:6)1; : : : ; (cid:6)l and thequery, should proceed.Main resultsWe have addressed all the problems from above, and found answers to all of them. Someof the results, e.g., that deduction from an intersection can be done fast, and the hardnessof computing all characteristic models, are rather unexpected. Briefly, the main results ofthis paper can be summarized as follows.(cid:15) Problems MODEL and CMODEL are both solvable in polynomial time. In fact, weshow that the least (i.e., unique minimal) model of (cid:6) is computable in time linear inthe input size, and hence Problem MODEL is solvable in linear time. As shown in [14],the least model of a Horn theory given by a Horn formula can be found in linear time;hence, we obtain that under both formula- and model-based representation, computingsome model of (cid:6), and in particular the least model of (cid:6), is possible in linear time. Asa consequence, under both representations also the consistency problem, i.e., decidingwhether (cid:6) 6D ;, can be solved in linear time.(cid:15) Problem ALL-MODELS can be solved with polynomial delay; we have developed arespective enumeration algorithm which produces one model at a time. Also this resultparallels a polynomial time result under formula-based representation. In fact, themodels of a Horn theory (and thus of (cid:6)) given by a Horn formula, can be enumeratedwith polynomial delay; see, e.g., [12] for such a procedure. The delay of our algorithmis of the same order as the best one in the formula case [12].(cid:15) We show that Problem ALL-CMODELS has no polynomial time algorithm. We provethis by describing a family of instances In to ALL-CMODELS, where n is the numberof atoms, such that the output of ALL-CMODELS has 2n models, while these instanceshave l D 2, and (cid:6)1 and (cid:6)2 have 2n characteristic models (Proposition 5.1). Thus,ALL-CMODELS may have exponential output in its input size, and is clearly notpolynomially solvable. This improves the result [20, Theorem 6], which states that,in our terminology, ALL-CMODELS for l D 2 cannot be solved in polynomial timeunless P D NP.T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10161(cid:15) Problem ALL-CMODELS has no polynomial total time algorithm, unless P D NP.This is a somewhat negative result, since it means that merging Horn knowledge basesunder model-based representation is a complex task in general. In fact, we establishthis for l D 2, i.e., even the intersection of two Horn theories is hard to compute. Wederive this result from the following associated decision problem, which is provedNP-complete: Given the characteristic models of (cid:6)1; : : : ; (cid:6)l and a subset S of thecharacteristic models of(cid:6) Dl\iD1(cid:6)i ;decide whether some characteristic model exists in (cid:6) n S.(cid:15) Since computing the set of characteristic models C(cid:3).(cid:6)/ is hard, we also considerthe issue of efficient approximations. However, we show that also the natural notionof sound and complete approximation of C(cid:3).(cid:6)/ is hard to compute. More precisely,we prove that any approximation N (cid:18) f0; 1gn of C(cid:3).(cid:6)/, which contains at least apolynomial fraction of C(cid:3).(cid:6)/ and is only polynomially larger than C(cid:3).(cid:6)/, is hardto compute. This is a rather strong result, since it shows that even if we want onlyto compute a significantly large part of C(cid:3).(cid:6)/, and allow (not too much) junk in theoutput, we face an intractable problem. To our knowledge, such a type of result isnovel in the area of model-based reasoning, and our proof technique may be appliedto obtain similar results for a wide range of similar problems.Furthermore, we prove similar results for computing the maximal models of (cid:6),which constitute a non-polynomial fraction of C(cid:3).(cid:6)/. This shows that both somenatural quantitative (in terms of numbers of models) and qualitative (semanticallydescribed) approximations of C(cid:3).(cid:6)/ are hard to compute, and reinforces the viewthat computing C(cid:3).(cid:6)/ is really difficult.(cid:15) Despite the fact that the number of characteristic models of the intersection (cid:6) ofHorn theories (cid:6)1; : : : ; (cid:6)l may be exponential, we show that it is possible to answerdeductive queries (cid:11) to (cid:6) in polynomial time. In particular, for any query (cid:11) givenjC(cid:3).(cid:6)i /j/ time,by a CNF formula, deciding whether (cid:6) jD (cid:11) is possible in O.mnwhere m is the number of clauses in (cid:11), n is the number of atoms, and jC(cid:3).(cid:6)i/j thenumber of characteristic models in (cid:6)i ; if (cid:11) is a single clause or a positive formula,then deciding (cid:6) jD (cid:11) is possible in linear time. These results are promising, sincethey show that under taking intersections of Horn theories, the benign property ofmodel-based reasoning is preserved that any CNF query posed to a Horn theory canbe answered in polynomial time [24,25].P(cid:15) On the other hand, abduction from the intersection (cid:6) of Horn theories (cid:6)1; : : : ; (cid:6)l isintractable, even if l is fixed to 2. We prove that deciding whether a query letter q hasan explanation from (cid:6) and a set of assumptions A is NP-complete.This result tells us that not all benign properties of characteristic models are preservedwhen we consider intersections of theories. In fact, this indicates that the tractabilityresult for abduction from a single Horn theory (cid:6)1 is not very robust, and thatadvantage of particular properties is taken in that case, which is no longer possibleif two theories (cid:6)1 and (cid:6)2 are combined (see Section 6.2 for further discussion).62T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101Usage and significance of the resultsOur results give a rather complete picture of the computational properties of usingthe model-based reasoning approach when different Horn knowledge bases KB1; : : : ; KBnare combined by taking their logical intersection. Since this is undoubtedly a principaloperation, our algorithms and results are significant for any reasoning system which adoptsthe model-based approach and incorporates this operation, embedded into a sophisticatedcombination semantics. Our algorithms are described at a detailed level, and can be easilyimplemented. Moreover, several algorithms run in linear time (and thus of optimal order),and others are of low-polynomial degree; improvements to linear time (if feasible) seem torequire much more effort and sophisticated methods.Furthermore, the algorithms, together with the complexity results, give us more insightinto the potential trade-off between off-line compilation and on-line reasoning. Forexample, by our results, for ad-hoc on-line deductive reasoning from an intersection (cid:6),using a direct inference method from (cid:6)1; : : : ; (cid:6)l is more advisable than computing firstthe characteristic models of (cid:6), and then applying a polynomial algorithm on them (e.g.,the one of [25]). Even in case of repetitive queries, a direct method may be more beneficialif (cid:6) has many characteristic models (of course, on the other hand, if (cid:6) is small whilethe sets of characteristic models of (cid:6)1; : : : ; (cid:6)l are huge, we may be better off withC(cid:3).(cid:6)/).Another aspect is dynamic combination of knowledge bases. For example, supposethere is pool of knowledge bases KB1; : : : ; KBl; for answering a query, at run-time asubcollection of KBi1 ; KBi2 ; : : : ; KBik of relevant knowledge bases is selected which haveto be combined. The different relevant subcollections might vary, and if there are many, wewould have to store a number of characteristic sets. In the worst case, their number mayexponential in l. Even for a small pool size l and under the assumption that only a fewknowledge bases are relevant for a query, we might need quite some storage. For example,if l D 10 and at most three KBi ’s are relevant to a query, then we need to store(cid:18)(cid:19)(cid:18)(cid:19)102C103D 45 C 120 D 165characteristic sets; if the number of relevant KBi ’s is increased to four, we need 275characteristic sets. Thus, in such a scenario, a direct reasoning strategy which employsour deduction algorithms is preferable.This becomes even more evident, if we take updates and changes to the knowledgebases into account; an update to a single knowledge base KBi requires to recompile thecharacteristic subsets of the subcollection to which KBi belongs; in the above example,their number is(cid:18)(cid:19)(cid:18)91D 9 C 36 D 45(cid:19)92C(respectively, 129) for subcollections of size at most three (respectively, at most four).Of course, a mixed strategy is viable in which for some subcollections the (small)characteristic sets are prestored and for others direct methods are applied.For abductive queries, we have a picture similar to deduction yet different. Here, anycurrent method for answering abductive queries from a set of CNF Horn formulas requiresT. Eiter et al. / Artificial Intelligence 110 (1999) 57–10163exponential time; however, while computing the characteristic models requires exponentialspace in general, abductive queries can be solved in polynomial space. Observe also that anobliterative reasoning approach, in which characteristic models are enumerated and deletedfor avoiding space problems, is not profitable, since it is intractable to tell when the lastcharacteristic model has been found.Extension of this workCharacteristic models have been generalized to non-Horn theories in [29], by makinguse of monotone theory [6], a characterization of Boolean functions introduced incomputational learning. The approach in [29] is promising, since many advantages of Horntheories carry over to non-Horn theories. In this direction, we further investigate extendedHorn theories, which contains both Horn and reverse Horn theories, i.e., theories whichbecome Horn by negating all elementary propositions.It appears that for extended Horn theories, both finding some model and findingsome characteristic model are intractable. As a consequence, polynomial total timealgorithms for finding all models and all characteristic models, respectively, are unlikelyto exist. Moreover, this means that both deduction and abduction of atomic queries froman intersection of theories, given by their characteristic models, is intractable in thiscase. These results indicate that from the computational side, a generalization of thecharacteristic models approach for intersections of theories is not immediately feasible,in the sense that both the off-line compilation and the on-line reasoning by direct methodsare expensive in general.Structure of the paperThe remainder of this paper is organized as follows. In the next section, we recall somebasic concepts and introduce notation. In Section 3, we consider Problem MODEL andmodel checking, i.e., recognition of a model from an intersection. We then address inSection 4 the Problem CMODEL, as well as characteristic model checking. After that, westudy in Section 5 the Problems ALL-MODELS and ALL-CMODELS, where we show thatthe output of ALL-CMODELS can be exponential in its input. In Section 6, we considerdeduction and abduction from the intersection of Horn theories. Section 7 addresses apossible generalization of our results to extended Horn theories. The final Section 8discusses further aspects and concludes the paper.In order not to distract from the flow of reading, longer proofs and technical details ofproofs have been moved to Appendix A.2. PreliminariesWe assume a standard propositional language with atoms x1; x2; : : : ; xn, where each xitakes either value 1 (true) or 0 (false). Negated atoms are denoted by xi . A literal ‘ is anatom or its negation.A model v is a vector in f0; 1gn, whose ith component is denoted by vi . For modelsv and w, we denote by v 6 w the usual componentwise ordering, i.e., vi 6 wi for all64T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101Fig. 1. Space of all models for n D 4 and theories (cid:6)1, (cid:6)2.i D 1; 2; : : : ; n, where 0 6 1; v < w means v 6D w and v 6 w. As usual, v > w is thereverse ordering. For any set B (cid:18) f1; : : : ; ng, we denote by xB the model v such that vi D 1,if i 2 B and vi D 0, if i =2 B, for all i D 1; : : : ; n.A theory is any set (cid:6) (cid:18) f0; 1gn of models; its cardinality is denoted by j(cid:6)j. Bymin.(cid:6)/ and max.(cid:6)/ we denote the sets of minimal and maximal models in (cid:6) under<, respectively, where v 2 (cid:6) is a maximal (respectively, minimal) model in (cid:6), if there isno w 2 (cid:6) such that w > v (respectively, w < v).A propositional clause C D ‘1 _ (cid:1) (cid:1) (cid:1) _ ‘k is Horn, if at most one literal ‘i is positive,and a CNF is Horn, if it contains only Horn clauses. A theory (cid:6) is Horn, if there existsa Horn CNF representing it. We shall denote by b(cid:6) the set of clauses from a Horn CNFrepresenting (cid:6). 3Horn theories (cid:6) have a well-known model-theoretic characterization (see, e.g., [34],and [13] for a proof in the propositional case). Denote by v ^ w componentwise ANDof vectors v; w 2 f0; 1gn; e.g., .0101/ ^ .1001/ D .0001/. Furthermore, denote by Cl^.S/the closure of S (cid:18) f0; 1gn under ^. Then, (cid:6) is Horn, if and only if (cid:6) D Cl^.(cid:6)/. Notethat as a consequence, any Horn theory (cid:6) 6D ; has the least (i.e., unique minimal) modelv Dw2S w, where S (cid:18) f0; 1gn,for the componentwise AND of all vectors in S; in particular, for empty S, by definitionw2(cid:6) w, i.e., min.(cid:6)/ D fvg. Here, we use the notationVV^w D .11 : : :1/:w2SSimilarly, v _ w denotes componentwise OR of vectors; e.g., .0101/ _ .1001/ D .1101/.For example, consider (cid:6)1 D f.0101/; .1001/; .1000/g and (cid:6)2 D f.0101/; .1001/;.1000/; .0001/; .0000/g (see Fig. 1). Then, for v D .0101/ and w D .1000/, we havev; w 2 (cid:6)1, while v ^ w D .0000/ =2 (cid:6)1; hence (cid:6)1 is not Horn. On the other hand,Cl^.(cid:6)2/ D (cid:6)2, and thus (cid:6)2 is Horn. In fact, it can be represented by the Horn CNFx3 ^ .x1 _ x2/ ^ .x2 _ x4/; hence, b(cid:6) D fx3, x1 _ x2; x2 _ x4g.For any Horn theory (cid:6), a model v 2 (cid:6) is called characteristic [24] (or extreme [13]), ifv =2 Cl^.(cid:6) nfvg/. The set of all characteristic models of (cid:6), which we call the characteristicset of (cid:6), is denoted by C(cid:3).(cid:6)/. Note that every Horn theory (cid:6) has the unique characteristic3 Observe that b(cid:6) is not uniquely defined; we use this as a conversion of a set of models into an equivalentformula, which is needed in some contexts.T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10165set C(cid:3).(cid:6)/ and that max.(cid:6)/ (cid:18) C(cid:3).(cid:6)/. In the above example, .0101/ 2 C(cid:3).(cid:6)2/, while.0000/ =2 C(cid:3).(cid:6)2/; it holds that C(cid:3).(cid:6)2/ D (cid:6)1. We remark that the characteristic set ofa Horn theory without negative clauses has been studied in the context of relationaldatabases, where it is known as the generating set [3]; see [28] for a discussion.Throughout this paper, we suppose that sets of vectors S (cid:18) f0; 1gn are represented in thestandard way, i.e., each model v 2 f0; 1gn is stored as a sequence v1v2 (cid:1) (cid:1) (cid:1) vn of 0’s and 1’s.However, our algorithms can be adapted for other forms of storage, e.g., a model tree givenby a binary decision tree, as well.3. Finding and recognizing a modelIn this section, we consider the problem of finding some model of the logical intersectionof Horn theories which are represented by their characteristic models. More formally, thisproblem is specified as follows:Problem MODELInput: Sets of characteristic models Mi D C(cid:3).(cid:6)i/ of Horn theories (cid:6)i (cid:18) f0; 1gn; i D1; 2; : : : ; l.Output: A model v in (cid:6) DTliD1 (cid:6)i if (cid:6) 6D ;; otherwise, “No”.The main result of this section is that such a model, and in fact the least model of(cid:6), is computable in linear time. Moreover, we obtain that model checking for (cid:6), i.e.,recognizing the members of (cid:6), is also possible in linear time.We start with the following lemma, which is useful for our purposes:Lemma 3.1. Let (cid:6)i (cid:18) f0; 1gn, i D 1; 2; : : : ; l, be Horn theories, and let (cid:6) DThen any v 2 (cid:6) satisfiesl_(cid:18) ^(cid:19)v >w:iD1w2C(cid:3).(cid:6)i /TliD1 (cid:6)i .(3.1)Proof. First note thatw Dv D^^w D (cid:1) (cid:1) (cid:1) Dw2Q1w2Q2^w2Qlwholds for some Qi (cid:18) C(cid:3).(cid:6)i /, i D 1; 2; : : : ; l, by the definitions of v and C(cid:3).(cid:6)i /. Then wehave v >w2C(cid:3).(cid:6)i / w for all i, and hence (3.1). 2VBased on this lemma, we can find a model of (cid:6) as follows. Clearly, (cid:6) has no model,if some (cid:6)i is empty; if not, then consider the least models v.1/; : : : ; v.l/ of (cid:6)1; : : : ; (cid:6)l ,respectively. If they all coincide, then v D v.1/ is a model of (cid:6), which is output. Otherwise,exploiting Lemma 3.1, we look at the least upper bound of v.1/; : : : ; v.l/ as a new candidateu for a model; in fact, any v 2 (cid:6) must satisfy u 6 v. Since v must be generated fromcharacteristic models in each (cid:6)i , we can discard all characteristic models from eachC(cid:3).(cid:6)i/ which for sure do not contribute in this process. Since the resulting theories are66T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101still Horn, we can iterate and build a chain C: u.1/ < u.2/ < (cid:1) (cid:1) (cid:1) < u.k/ such that either u.k/is found to be a model of (cid:6), or (cid:6) D ; is detected.The formal description of this algorithm is as follows.Algorithm GEN-MODELInput: Characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn; i D 1; : : : ; l.Output: A model v 2 (cid:6) DTliD1 (cid:6)i , if (cid:6) 6D ;; otherwise, “No”.Step 0. for each i D 1; 2; : : : ; l do Qi VD Mi ;Step 1. if Qi D ; for some i then output “No” and halt;Step 2. ifVVw Dw2Q1then output v DVw D (cid:1) (cid:1) (cid:1) Dw2Q2Vw2Qlww2Q1w and halt;Step 3. u VDVWliD1.w2Qiw/;for each i D 1; : : : ; l do Qi VD fw 2 Qi j w > ug;goto Step 1.Example 3.1. Let M1 D C(cid:3).(cid:6)1/ D f.0110/, .0011/, .1010/g and M2 D C(cid:3).(cid:6)2/ Df.1110/, .0111/, .0011/g. The corresponding Horn theories are, under formula-basedrepresentation, b(cid:6)1 D fx1 _ x2; x1 _ x4, x2 _ x4, x3g and b(cid:6)2 D fx1 _ x4, x1 _ x2, x3g.VD .0010/; hence, v D .0010/ is output.Note that (cid:6) D f.0110/, .0010/; .0011/g (as obvious from b(cid:6) D fx1, x2 _ x4, x3g); thus,the output of v D .0010/ is correct.In Step 2, we haveD .0010/ andw2Q1w2Q2VAn analysis of the run time of the above algorithm gives us the following result (seeAppendix A for its proof).Theorem 3.2. Problem MODEL can be solved using Algorithm GEN-MODEL inO.n2jMi j/ time.PliD1As an immediate corollary to this result, the consistency of the intersection (cid:6) of HornjMi j/ time. We do not state this result attheories (cid:6)1; : : : ; (cid:6)l is decidable in O.n2this point, since as will show below, the problem can be solved faster.PliD1VRecall that since Horn theories are closed under intersection, any Horn theory (cid:6) has thew2(cid:6) w. In fact, from the underlying idea of Algorithm GEN-MODEL, it isleast modelnot hard to see that it actually finds this particular model of (cid:6).Example 3.2. Let us reconsider Example 3.1. There, Algorithm GEN-MODEL outputsthe vector .0010/, which is the least model of (cid:6) D f.0110/; .0010/; .0011/g.Corollary 3.3. Given the characteristic sets C(cid:3).(cid:6)i/ of Horn theories (cid:6)i (cid:18) f0; 1gn,i D 1; : : : ; l, Algorithm GEN-MODEL finds the least model v of (cid:6) DinO.n2jMi j/ time if (cid:6) 6D ;, and outputs “No” if (cid:6) D ;.TliD1 (cid:6)iPliD1T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10167Fig. 2. Data structure for set Q1 D f.0101/; .0110/g used in MODEL+.Using sophisticated data structures, it is possible to improve the running time of Algo-jMi j/; i.e., to linear time in the input size. Basically, therithm GEN-MODEL to O.nmethod is to use lists for cross-references and counters to avoid the examination of the samebit of the input more than a few (constant many) times. We describe this more in detail; theuse of similar data structures may be beneficial for speeding up other reasoning algorithms.PliD1VThe operations we need to perform are:(a) to computew2Qiholds for all w 2 Qi ), and u VDWliD1.Vw2Qiw/ andw (i.e., to compute the set of components k such that wk D 1(b) to update Qi by removing some models from Qi .Recall that the vector u monotonically increases in the execution of Algorithm GEN-MODEL, and observe that the sets Qi monotonically decrease.For operation (a), we use counters #Qi;1, #Qi;2; : : : ; #Qi;n so that #Qi;k tells howmany models in Qi have value 1 in component k; i.e., #Qi;k D jfw 2 Qi j wk D 1gj.In order to find out the counters with a certain value quickly, we prepare bucketsBiT0U; BiT1U; : : : ; Bi TmU, where m D jQi j, for each i so that component k (i.e., the counter#Qi;k via a reference) is in bucket Bi T#Qi;kU. Moreover, we use a counter #Qi that tellsthe number jQi j of vectors in Qi .For operation (b), we keep lists Li;k of references to all the models w 2 Qi such thatwk D 0, and we establish a pointer from each component k with wk D 0 to w in list Li;k .Fig. 2 shows the data structure for Q1 D f.0101/; .0110/g.We furthermore prepare a bucket B such that i 2 B holds if and only if Bi T#QiU 6D ;.The algorithm, described in detail below, first scans the input and builds the datastructures. After that, it proceeds in a manner similar to GEN-MODEL, and processesthe sets of models.Algorithm. GEN-MODEL+Input: Characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn; i D 1; 2; : : : ; l.Output: A model v 2 (cid:6) .DliD1 (cid:6)i / if (cid:6) 6D ;; otherwise, “No”.TStep 0. for each i D 1; 2; : : : ; l do Qi VD Mi ;u VD .0; 0; : : : ; 0/ 2 f0; 1gn;Scan the input to set up the initial counters and buckets described above;Step 1. if #Qi D 0 holds for some i then output “No” and halt;Step 2. if B D ; then output v VD u and haltelse begin Select an arbitrary i 2 B;68T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101for each k in BiT#QiU do begin(* all models in Qi have “1” at component k *)uk VD 1;for each h D 1; 2; : : : ; l do begin(* update the buckets and lists related to Qh *)Remove k from BhT#Qh;kU;while there is a model w in Lh;k do begin(* eliminate a w 2 Qh with wk D 0 *)#Qh VD #Qh (cid:0) 1;for each j D 1; 2; : : : ; n doif wj D 0 then Remove w from Lh;j ;elsif j is in BhT#Qh;j U then begin(* wj D 1, and update #Qh;j and BhT(cid:1)U *)#Qh;j VD #Qh;j (cid:0) 1;Move j from BhT#Qh;j C 1U to BhT#Qh;j Uendfelsifgendfwhilegendfforgendfforg;B VD ;;for each h D 1; 2; : : : ; l do (* update a bucket B *)if BhT#QhU 6D ; then B VD B [ fhg;goto Step 1;endfifg.Initially, the algorithm sets u to the smallest possible model. If all Qi are non-empty,but B is empty (i.e., no (cid:6)i has a component k in which all the models have value 1), then.0; : : : ; 0/ is a model of each (cid:6)i , which is output. Otherwise, if some i 2 B exists then allmodels in Qi (and thus in (cid:6)i ) have value 1 at some component k. If (cid:6) is nonempty, thenevery model in (cid:6) must have value 1 at this component. Thus, in the candidate model u thecomponent uk is set to 1, and all sets Qj and the data structures are updated accordinglyby removing all the models w with wk D 0. If some Qi becomes empty, then (cid:6) D ; isdetected; otherwise, the process is continued. To speed up, all selectable components k forQi are processed at once.We omit an example for this algorithm, as it should be clear how it proceeds. The nextresult establishes that Algorithm GEN-MODEL+ has the desired property.Theorem 3.4. Algorithm GEN-MODEL+ solves Problem MODEL in O.ntime, i.e., in linear time.PliD1jMi j/Similarly to Algorithm GEN-MODEL, we notice the following corollary.Corollary 3.5. Given the characteristic sets C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn, i DTl1; 2; : : : ; l, deciding consistency and computing the least model of (cid:6) DiD1 (cid:6)i is possibleusing Algorithm GEN-MODEL+ in O.njMij/ time, i.e., in linear time.PliD1T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10169Yet another corollary is that the membership problem for (cid:6); i.e., model checking of vin (cid:6), can be done efficiently.Corollary 3.6. Given the characteristic sets C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn, i DTl1; : : : ; l, and some v 2 f0; 1gn, deciding whether v 2 (cid:6) DiD1 (cid:6)i is possible by usingAlgorithm GEN-MODEL+ in O.njMi j/ time, i.e., in linear time.PliD1lC1Proof. Indeed, v 2 (cid:6) holds if and only ifiD1 (cid:6)i 6D ;, where (cid:6)lC1 D fvg. SinceC(cid:3).(cid:6)lC1/ D fvg, we can use Algorithm GEN-MODEL+ to solve the problem inPlO.niD1jMij/ time (Corollary 3.5). 2jMij C 1// D O.njMij/ D O.n.PliD1lC1iD1PT4. Finding and recognizing a characteristic modelIn this section, we consider the problem of finding some characteristic model of thelogical intersection (cid:6) of Horn theories, as well as the problem of recognizing whether amodel is a characteristic model of (cid:6).The former problem is a first step towards an algorithm for computing all characteristicmodels; if this problem is hard, then computing all characteristic models is hard as well.The latter problem is relevant to the question of a computational upper bound to thegeneration of additional characteristic models; if the recognition problem is easy, anenumeration procedure may take advantage of this fact and rule out possible candidatesin low-order polynomial time. The main findings are that both computing and recognizinga characteristic model is possible in polynomial time.4.1. Finding some characteristic modelWe first consider the computation of some characteristic model, which is the followingproblem:Problem CMODELInput: Sets of characteristic models Mi D C(cid:3).(cid:6)i/ of Horn theories (cid:6)i (cid:18) f0; 1gn; i DTliD1 (cid:6)i if (cid:6) 6D ;; otherwise, “No”.Output: A characteristic model v in (cid:6) D1; 2; : : : ; l.TFor solving this problem, we proceed as follows. We construct the least model u ofi (cid:6)i as a candidate in C(cid:3).(cid:6)/; this is possible using Algorithm GEN-MODEL or its(cid:6) Dimproved version. Then, two cases arise:(i) u 2 C(cid:3).(cid:6)/; in this case, we can output u and stop.(ii) u =2 C(cid:3).(cid:6)/; here, u can be replaced by a new larger candidate model u0 > u suchthat u0 2 (cid:6) (which must exist), and the process is repeated for the new candidatemodel u0.Since any chain of models C: u D u.1/ < u.2/ < (cid:1) (cid:1) (cid:1) < u.k/ is bounded, this algorithmeventually finds some characteristic model (as any maximal model is characteristic) andhalts.70T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101A straightforward implementation of this algorithm uses a test for u 2 C(cid:3).(cid:6)/ (e.g.,Algorithm CHECK-CMODEL to be described in Section 4.2), and in case u =2 C(cid:3).(cid:6)/ amethod for selecting a proper model u0 as described above. However, a variant of thisstrategy gives us a faster algorithm. Rather than testing u 2 C(cid:3).(cid:6)/, we consider a stronger(sufficient but not necessary) condition, such that in case the test fails we can proceed likein case (ii), and the selection of a model u0 therein can be done fast. The stronger conditionis given in the following lemma. Let Qi D fv > u j v 2 Mi g and Pij D fw 2 Qi j wj D 1g.Lemma 4.1. Let (cid:6) and Pij be defined as above. Then u 2 C(cid:3).(cid:6)/ holds, if the followingcondition holds for all j :uj D 0 H)l\iD1Cl^.Pij / D ;:(4.1)(Note that the converse does not hold in general.) On the other hand, if (4.1) is violatedfor some j , then any model v 2 Cl^.Pij / is a model of (cid:6) with v > u. Although thisdoes not immediately imply that u is not a characteristic model of (cid:6), it says that somecharacteristic model w such that w > v must exist. Therefore we can proceed as in case(ii) and safely select u0 D v, replace each Mi by the set fw > u0 j w 2 Pij g, and continuewith the new candidate model u0. The following example illustrates this algorithm.Example 4.1. Let again M1 D C(cid:3).(cid:6)1/ D f.0110/; .0011/; .1010/g and M2 D C(cid:3).(cid:6)2/ Df.1110/; .0111/; .0011/g.The least model of (cid:6) D (cid:6)1 \ (cid:6)2 is u D u.1/ D .0010/. Thus, we have Q.1/1D M1 andQ.1/2D M2. For j D 2, we have P .1/12(cid:0)(cid:0)P .1/.0110/ 2 Cl^22\ Cl^P .1/12(cid:1)D f.0110/g and P .1/22(cid:1)D f.1110/; .0111/g; hence,violates (4.1). Thus, we set u.2/ D .0110/ and continue; we set M .2/and M .2/2Consequently, for each j , P .2/1jv D u.2/ is output.VD f.0110/gD ; and Q.2/D f.1110/; .0111/g.2is empty, which means that condition (4.1) is true; hence,VD f.1110/; .0111/g. Then, we obtain Q.2/11Note that C(cid:3).(cid:6)/ D f.0110/, .0011/g; thus, the output v D .0110/ is correct.An implementation of this method is straightforward, but rather time consuming. Wecan save on time by exploiting the following observation: If some j with uj D 0 satisfies(4.1), then we never have to check if (4.1) holds for this j later again. Indeed, this meansthat there exists no w0 2 (cid:6) such that w0 > u and w0jFormally, our algorithm can be written as follows.D 1.Algorithm GEN-CMODELInput: Characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn; i D 1; 2; : : : ; l.TOutput: A model v 2 C(cid:3).(cid:6)/, where (cid:6) DliD1 (cid:6)i , if (cid:6) 6D ;; otherwise, “No”.Step 1. Find the least model u in (cid:6);if no such u exists then output “No”T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10171else for each i D 1; 2; : : : ; l doQi VD fw 2 Mi j w > ug;Step 2. for each j D 1; 2; : : : ; n doif uj D 0 then beginfor each i D 1; 2; : : : ; l doifPij VD fw 2 Qi j wj D 1g;TliD1 Cl^.Pij / 6D ; then beginFind a model w0 inu VD w0;for each i D 1; 2; : : : ; l doTliD1 Cl^.Pij /;Qi VD fw 2 Pij j w > ug;end;end;Step 3. Output the model v VD u.Observe that, in this algorithm, the sets Pij are characteristic sets of Horn theoriesTliD1 Cl^.Pij / 6D ;” and finding a model ofCl^.Pij /. Thus, testing the condition “TliD1 Cl^.Pij / in Step 3 resorts to an instance of Problem MODEL which we haveconsidered in the previous section, and can be solved in polynomial time.An analysis of the running time of Algorithm GEN-CMODEL yields then the followingresult.Theorem 4.2. Problem CMODEL can be solved using Algorithm GEN-CMODEL inO.n2jMi j/ time.PliD1Similar as in the case of Algorithm GEN-MODEL, also Algorithm GEN-CMODELoutputs some particular model of (cid:6). In fact, we can easily see that it outputs a maximalmodel of (cid:6). Recall that max.(cid:6)/ (cid:18) C(cid:3).(cid:6)/ holds, while in general not every characteristicmodel is maximal. We thus obtain the following side result.Corollary 4.3. Given the characteristic sets C(cid:3).(cid:6)i/ of Horn theories (cid:6)i , i D 1; : : : ; l,GEN-CMODEL finds a maximal model v in (cid:6) DjMij/ time if(cid:6) 6D ;, and outputs “No” if (cid:6) D ;.TliD1 (cid:6)i in O.n2PliD1Corollaries 3.5 and 4.3 show that the least (i.e., unique smallest) model and somemaximal model in (cid:6) can be computed in polynomial time. We come back to the latterresult when we will consider abductive reasoning from an intersection.We remark at this point that finding a maximum model in (cid:6), i.e., a model which hasthe largest number of components set to 1, rather than a maximal model in the problemstatement of Corollary 4.3 is intractable unless PDNP; this was shown in [20]. Observethat finding a maximum model of an arbitrary Horn theory (cid:6) is also intractable if the inputis a Horn formula b(cid:6) representing (cid:6), while this can be easily done in O.njMi j/ time(i.e., in linear time), if the input is C(cid:3).(cid:6)/.PliD172T. Eiter et al. / Artificial Intelligence 110 (1999) 57–1014.2. Recognizing a characteristic modelThe factthat we can compute some characteristic model of the intersection (cid:6)efficiently does not automatically mean that we can recognize any characteristic modelfast; nonetheless, this task can be solved in polynomial time.The key for obtaining this result is the following lemma.Lemma 4.4. Let (cid:6) be a Horn theory and v be a model in (cid:6). Then v =2 C(cid:3).(cid:6)/ holds ifand only ifv 6D .11 (cid:1) (cid:1) (cid:1) 1/ and v Dwhere (cid:6)v D fw 2 (cid:6) j w > vg.^w;w2min.(cid:6)v /VProof. The if-part is obvious. For the only-if-part, let v =2 C(cid:3).(cid:6)/. Then v Dw.w,w2min.(cid:6)v / w >Clearly,then a component j exists such that uj D 0 for some u 2 (cid:6)v and wj D 1 for allw 2 min.(cid:6)v/. However, this contradicts that some w 2 min.(cid:6)v/ satisfies w 6 u. 2w.D v/ as min.(cid:6)v/ (cid:18) (cid:6)v. Ifw2min.(cid:6)v / w >w2(cid:6)vw2(cid:6)vw2(cid:6)vVVVVExploiting this lemma, we constructthe following algorithm for recognizing acharacteristic model, in which the set S is used to construct the above min.(cid:6)v/. Sincew 2 min.(cid:6)v/ satisfies wj D 1 for some j with vj D 0, such a S is constructed by collectingw.j / for all j with vj D 0, where w.j / is the least model in the set fw 2 (cid:6)v j wj D 1g.Algorithm CHECK-CMODELInput: Characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn, i D 1; : : : ; l, and amodel v 2 (cid:6) DTliD1 (cid:6)i .Output: “Yes”, if v 2 C(cid:3).(cid:6)/, otherwise, “No”.Step 0. if v D .11 : : : 1/ then output “Yes” and haltelse S VD ;.Step 1. for each j with vj D 0 do beginfor each i D 1; 2; : : : ; l doifPij VD fw 2 Mi j w > v; wj D 1g;TliD1 Cl^.Pij / 6D ; then beginTlw.j / := the least model iniD1 Cl^.Pij /;S VD S [ fw.j /g;end;end;Step 2. if v DVw.j/2S w.j / then output “No”else output “Yes”.T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10173Example 4.2. Let us consider again the above M1 D C(cid:3).(cid:6)1/ D f.0110/; .0011/; .1010/gand M2 D C(cid:3).(cid:6)2/ D f.1110/; .0111/; .0011/g, and suppose v D .0110/.Then, in Step 0 of CHECK-CMODEL, S VD ;; in Step 1, j takes values 1 and 4.For j D 1, we obtain P11 VD ; and P21 VD f.1110/g, hence Cl^.P11/ \ Cl^.P21/ D ;,and S is unchanged. For j D 4, we have P14 D ; again and P24 D f.0111/g; henceS D ; is not changed. In Step 2, the check v Dw.j/2S w.j / yields false (recall thatVw2S w D .11 : : :1/ holds for S D ;); hence the output is “Yes”. Note that v D .0110/Vis indeed a characteristic model of (cid:6), as we have seen in Example 4.1.Similarly to Algorithm GEN-CMODEL, the sets Pij are the characteristic sets of HornTliD1 Cl^.Pij / 6D ; and finding the leastTliD1 Cl^.Pij / in Step 3 can be done in polynomial time by using GEN-theories Cl^.Pij /. Thus testing the conditionmodel ofCMODEL.An analysis of the running time of Algorithm CHECK-CMODEL yields then thefollowing result.Theorem 4.5. Given the characteristic sets C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn,iD1 (cid:6)i , checking if v 2 C(cid:3).(cid:6)/ is possible ini D 1; : : : ; l, and a model v 2 (cid:6) DO.n2jMi j/ time by using Algorithm CHECK-CMODEL.TlPliD1Recall that the Algorithm GEN-CMODEL from above outputs a maximal model(Corollary 4.3). We remark that by using the Algorithm CHECK-CMODEL as asubroutine, we can modify GEN-CMODEL such that it computes a characteristic model inpolynomial time which is not necessarily a maximal model of the theory (cid:6). This can bedone by using CHECK-CMODEL for testing whether u =2 C(cid:3).(cid:6)/ in the method describedin the beginning of Section 4.1. However, the resulting algorithm has higher running timethan GEN-CMODEL.5. Computing all characteristic models and all modelsWe now turn to the issue of generating all characteristic models and all models of atheory (cid:6), where (cid:6) is the intersection of Horn theories (cid:6)1; : : : ; (cid:6)l . Let us first considercomputing all characteristic models.5.1. Computing the characteristic set of the intersectionIt is known (and easy to show) that for a Horn theory (cid:6), the number j(cid:6)j of its modelsmay be exponential in jC(cid:3).(cid:6)/j. Thus the output size of Problem ALL-MODELS may beexponential in the input size. For Problem ALL-CMODELS, we derive an analogous result.Proposition 5.1. For every n > 1, there exist Horn theories (cid:6)1 and (cid:6)2 such thatjC(cid:3).(cid:6)1/j D jC(cid:3).(cid:6)2/j D 2n and jC(cid:3).(cid:6)/j D 2n, where (cid:6) D (cid:6)1 \ (cid:6)2.74T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101Proof. Fix n, and define two sets of vectors S1; S2; (cid:18) f0; 1g4n as follows. Let Vi DS3iD0 Vi D f1; : : : ; 4ng; observe thatfi (cid:1) n C j j j D 1; : : : ng, for i D 0; : : : ; 3 and V DV0 contains the first n components, V1 the next n components etc.Then,S1 DS2 D(cid:9)(cid:8)xV n.V2[fj;3nCj g/; xV n.V2[fnCj;3nCj g/ j 1 6 j 6 n;(cid:9)(cid:8)xV n.V3[fj;2nCj g/; xV n.V3[fnCj;2nCj g/ j 1 6 j 6 n:Notice that in S1, every vector has the penultimate block of n bits set to 0. The other blocksare set to 1, and some bit j in the last block together with the same bit j in either the firstor second block, is switched to 0. The set S2 is similar to S1, but the penultimate and lastblocks are exchanged.For n D 2, for example, we haveS1 D f.01110001/; .11010001/; .10110010/; .11100010/g;S2 D f.01110100/; .11010100/; .10111000/; .11101000/g:Observe that jS1j D jS2j D 2n. Since S1 D max.S1/ and S2 D max.S2/, there are Horntheories (cid:6)1 and (cid:6)2 such that C(cid:3).(cid:6)1/ D S1 and C(cid:3).(cid:6)2/ D S2.Since all models xB in C(cid:3).(cid:6)1/ (respectively, C(cid:3).(cid:6)2/) satisfy B \ V2 D ; (respectively,B \ V3 D ;), all models xB 2 (cid:6) satisfyB (cid:18) V0 [ V1;i.e., the last 2n bits of a model in (cid:6) are always 0.DefineS D fxB j B (cid:18) V0 [ V1; such that j 2 B if and only if n C j =2 B; 1 6 j 6 ng:For n D 2, we haveS D f.00110000/; .10010000/; .01100000/; .11000000/g:Observe that jSj D 2n holds. It can be shown thatS D C(cid:3).(cid:6)/holds (see Appendix A), which proves the result. 2(5.1)(5.2)Let us now state the problem of computing all the characteristic models of an intersectionmore formally.Problem ALL-CMODELSInput: Sets of characteristic models Mi D C(cid:3).(cid:6)i/ of Horn theories (cid:6)i (cid:18) f0; 1gn; i DTliD1 (cid:6)i .Output: All characteristic models v in (cid:6) D1; 2; : : : ; l.The previous proposition tells us that the output size of this problem can be exponentialin its input size. Therefore, a polynomial time algorithm in the input size is impossible.This improves the previous result [20, Theorem 6], which states the ALL-CMODELS forT. Eiter et al. / Artificial Intelligence 110 (1999) 57–10175l D 2 is not solvable in polynomial time unless P D NP; by Proposition 5.1, this is trueregardless of whether P D NP holds.However, we still might hope that ALL-CMODELS has a polynomial total timealgorithm. However, this hope does not come true, as the following related problem isintractable.Problem ADD-CMODELInput: Characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn, i D 1; 2; : : : ; l, anda set S (cid:18) C(cid:3).(cid:6)/, where (cid:6) DQuestion: C(cid:3).(cid:6)/ n S 6D ;?TliD1 (cid:6)i .Theorem 5.2. Problem ADD-CMODEL is NP-complete. This holds even if l is fixed to 2.Proof. For every candidate model v 2 f0; 1; gn, we can apply Theorem 4.5 to check thecondition v 2 C(cid:3).(cid:6)/ n S in polynomial time. Thus ADD-CMODEL is in NP.VWe prove NP-hardness by a reduction from the satisfiability problem (SAT) [19]. Givenma CNF formula (cid:8) DiD1 Ci on n atoms x1; : : : ; xn, we define polynomially computablesets M1, M2 and S of vectors in f0; 1gnC2m, such that M1 D C(cid:3).(cid:6)1/, M2 D C(cid:3).(cid:6)2/ andS (cid:18) C(cid:3).(cid:6)1 \ (cid:6)2/. Moreover, S D C(cid:3).(cid:6)1 \ (cid:6)2/ holds if and only if (cid:8) is unsatisfiable.Without loss of generality, we make the following assumptions:(i) all literals in L D fxi; xi j 1 6 i 6 ng appear in (cid:8), but no literal appears in allclauses; and(ii) (cid:8) does not become a tautology by fixing the truth values of any two atoms xi andxj .It is easy to see that these restrictions on (cid:8) do not affect the NP-completeness of SAT.Define V D VL [ V1 [ V2, whereVL D f1; 2; : : : ; n; 1; 2; : : : ; ng;V1 D fn C 1; n C 2; : : : ; n C mg;V2 D fn C m C 1; n C m C 2; : : : ; n C 2mg:Intuitively, the elements in VL correspond to the literals in L, and the elements n C j inV1 and n C m C j in V2 correspond to clause Cj in (cid:8). Now we define the instance of ourproblem as follows:C(cid:3).(cid:6)1/ D T1;1 [ T1;2;where(cid:8)x.V1nfnCj g/[.VLnfqg/ j n C j 2 V1; q 2 Cj(cid:8)x.VLnfk;kg/[V2 j k 2 VL(cid:9)IT1;1 DT1;2 DC(cid:3).(cid:6)2/ D T2;1 [ T2;2;(cid:9);(5.3)(5.4)whereT2;1 DT2;2 D(cid:8)x.V2nfnCmCj g/[.VLnfqg/ j n C m C j 2 V2; q 2 Cj(cid:9)(cid:8)x.VLnfk;kg/[V1 j k 2 VLI(cid:9);76T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101S D S1 [ S2;where(cid:9)(cid:8)xVLnfk;kg j k 2 VL;(cid:8)xVLnfk;k;qg j k; q 2 VL with q 6D k; k(cid:9);S1 DS2 D(5.5)(5.6)(5.7)where q 2 Cj denotes that the literal corresponding to q appears in clause Cj (e.g., for aC1 D .x1 _ x3 _ x4/, we write 1; 3; 4 2 C1), and k D k.Each vector in S is generated by the intersection of one vector in T1;1 and one vector inT1;2 (respectively, one vector in T2;1 and one vector in T2;2).Observe that all vectors in T1;1 have value 0 at the components in V2, while all vectors inT2;1 have value 0 at the components in V1; in fact, the vectors in T1;1 and T2;1 are similar,with the roles of V1 and V2 interchanged. Intuitively, every vector in T1;1 represents thechoice of a literal q 2 Cj , which is represented by switching the component of n C j inthe block of 1’s for V1 and the component of q in the block of VL to 0. By selectingvectors v.1/; : : : ; v.m/ in T1;1, one for each clause, we obtain a collection of literals suchmthat satisfying all these literals makes (cid:8) true; note that the intersection v DiD1 v.i/ ofall these vectors is a vector in (cid:6)1 which has 0 at all components in V1 [ V2. Similarly, byselecting corresponding vectors u.1/; : : : ; u.m/ in T2;1, the same v can also be generated asmintersection v DiD1 u.i/ in (cid:6)2. Thus this v belongs to (cid:6)1 \ (cid:6)2. If v corresponds to aselection which does not select both a literal and its opposite, then v cannot be generatedas the intersection of any set of vectors in S, since each such intersection has 0 at bothk and k for some component k. This means that a characteristic vector of (cid:6)1 \ (cid:6)2 existswhich is not contained in S. An arbitrary selection of literals might include opposite literalsq and q; such illegal selections have 0 at components k; k for at least one k, and thecorresponding vector v can be generated in S. Summarizing, there exists an additionalcharacteristic model of (cid:6) which is not contained in S if and only if there exists a legalchoice of literals in all clauses of (cid:8) which satisfies the formula.The details of the proof can be found in Appendix A. 2VVThe result may be intuitively explained by the fact that a characteristic model is a specialmodel, which must satisfy some intersection condition. While it is feasible to check thiscondition for a given model, it is difficult to find a model which satisfies this conditionand additional constraints. There is an exponential number of candidates, and we have noefficient method at hand by which this candidate space can be substantially reduced.Corollary 5.3. Given the characteristic sets Mi D C(cid:3).(cid:6)i/ of Horn theories (cid:6)i (cid:18)f0; 1gn; i D 1; 2; : : : ; l, and a set S (cid:18) C(cid:3).(cid:6)/, where (cid:6) DliD1 (cid:6)i , deciding whetherS D C(cid:3).(cid:6)/ is co-NP-complete.TExploiting Theorem 5.2, we obtain the next theorem.Theorem 5.4. There is no polynomial total time algorithm for Problem ALL-CMODELS,unless PDNP.T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10177Proof. Towards a contradiction, assume that there is an algorithm A for ALL-CMODELSwith polynomial running time p.I; O/, where I is the input length and O the output length.We then solve ADD-CMODEL using A as follows. Execute A until either (i) it halts or (ii)time p.I; jSj/ is reached. In case (i), output “Yes” if A outputs some vector in C(cid:3).(cid:6)/ n S;otherwise, “No”. In case (ii), output “Yes”, since it implies C(cid:3).(cid:6)/ n S 6D ;. Hence,ADD-CMODEL is solvable in time polynomial in I and jSj, which contradicts Theorem 5.2unless P D NP. 2Observe that this result strengthens the result [20, Theorem 6] in another way, by statingthat no polynomial algorithm exists even if we relativize the run time by taking a possibleexponential output size into account. Practically speaking, this means that computing allcharacteristic models of an intersection of Horn theories is a hard problem.5.2. Approximation of the characteristic setIn the previous subsection, we have shown that computing the characteristic set of theintersection (cid:6) of Horn theories (cid:6)1; : : : ; (cid:6)l is intractable. As with other hard problems inthe context of reasoning (cf. [10,37]), it is thus natural to ask whether we can compute asuitable approximation of C(cid:3).(cid:6)/ in polynomial total time.Towards this goal, we first have to agree on what a suitable approximation of C(cid:3).(cid:6)/is. Recall that C(cid:3).(cid:6)/ is the unique smallest set S (cid:18) (cid:6) of models such that (cid:6) D Cl^.S/holds. A reasonable requirement is that an approximation M of C(cid:3).(cid:6)/ should only containmodels in (cid:6) (i.e., M (cid:18) (cid:6)). This assures Cl^.M/ (cid:18) (cid:6); in a sense, this is soundness of therepresentation. On the other hand, it would also be desirable that (cid:6) (cid:18) Cl^.M/ holds; i.e.,M is complete with respect to (cid:6). 4Let us call any set of models M which is sound and complete with respect to (cid:6)(i.e., C(cid:3).(cid:6)/ (cid:18) M (cid:18) (cid:6) holds) a conservative approximation of C(cid:3).(cid:6)/. Observe thatM D C(cid:3).(cid:6)/ and M D (cid:6) are the best and weakest conservative approximations of C(cid:3).(cid:6)/,respectively. A conservative approximation might be seen as a non-optimal compactrepresentation of (cid:6), which is, however, sound and complete for the purpose of reasoningfrom (cid:6).It is now natural to ask whether finding a reasonably sized conservative approximationM of C(cid:3).(cid:6)/ is tractable, i.e., possible in output polynomial time. Clearly, an M whose sizeis exponential in the size of C(cid:3).(cid:6)/ would not be acceptable, and thus we limit our attentionto those M whose sizes are polynomial in the size of C(cid:3).(cid:6)/. The next result, however, tellsus that finding any arbitrary such conservative approximation is also intractable.Theorem 5.5. Let p.(cid:1)/ be any polynomial. 5 Then, given the characteristic sets Mi DC(cid:3).(cid:6)i/ of Horn theories (cid:6)i (cid:18) f0; 1gn, i D 1; 2; : : : ; l, there is no polynomial totaltime algorithm for computing a conservative approximation M for C(cid:3).(cid:6)/, where (cid:6) DTiD1 (cid:6)i , such that jMj 6 p.jC(cid:3).(cid:6)/j/, unless P D NP. This holds even if l is fixed to 2.l4 Note that here soundness and completeness are understood with respect to representation of (cid:6) . If it werewith respect to query answering from (cid:6) , then the notions must be reversed.5 Here, and in the rest of this paper, we assume as usual that polynomials are monotone increasing.78T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101Proof. Assume such a polynomial total time algorithm A exists for this problem. Then,an output-polynomial total algorithm for Problem ALL-CMODELS exists, since we canfirst apply A, and then remove from its output M all models v such that v =2 C(cid:3).(cid:6)/in polynomial time (Theorem 4.5) in the size of C(cid:3).(cid:6)/; observe that the size of theintermediate result M is bounded by the polynomial p.jC(cid:3).(cid:6)/j/. By Theorem 5.4, ALL-CMODELS has no polynomial total time algorithm unless P D NP, from which the resultfollows. 2This result shows that for gaining tractability, we have to give up on conservativeapproximations. Thus, either soundness or completeness of the approximation (or both)has to be abandoned. It seems natural, however, to retain soundness, since completenessmay be dispensable for answering certain queries to a knowledge base (see Section 6.1 forfurther discussion).In giving up completeness, we have to decide which part of C(cid:3).(cid:6)/ should be omitted, inorder to be able to use the result of the approximation. This is not straightforward, however,and depends on the intended use of the knowledge base. We do not embark on this generalissue here, but point out that there are some principal limitations to such an approach.Our next result shows that any approximation of C(cid:3).(cid:6)/, regardless of being sound ornot, which returns a polynomial-size fraction of C(cid:3).(cid:6)/ and is polynomially bounded injC(cid:3).(cid:6)/j, is intractable, i.e., there is no polynomial total algorithm for its computation.Theorem 5.6. Let p.(cid:1)/ and q.(cid:1)/ be any polynomials. Then, there is no polynomial totaltime algorithm A for computing, given the characteristic sets Mi D C(cid:3).(cid:6)i / of Horntheories (cid:6)i (cid:18) f0; 1gn, i D 1; 2; : : : ; l, a set of models N (cid:18) f0; 1gn such that.i/ jC(cid:3).(cid:6)/j 6 q.jN \ C(cid:3).(cid:6)/j/ and.ii/ jNj 6 p.jC(cid:3).(cid:6)/j/, unless P D NP.This holds even if l is fixed to 2.As a consequence, there is no polynomial total time algorithm for computing half of thecharacteristic set, say, or any constant fraction of it. Thus, since a quantitative approxima-tion of C(cid:3).(cid:6)/ is infeasible, we would have to consider qualitative approximations, i.e.,meaningful semantical portions of C(cid:3).(cid:6)/ which are sufficient for certain purposes.An example of such a portion would be the maximal models max.(cid:6)/ of an intersection(cid:6). Recall that max.(cid:6)/ is included in C(cid:3).(cid:6)/, and as easily seen, this set may beexponentially smaller than C(cid:3).(cid:6)/, and thus the above results do not apply. Moreover,it is easily seen that max.(cid:6)/ is sound and complete with respect to answering negativedeductive queries (cid:11) to (cid:6), i.e., deciding whether (cid:6) jD (cid:11), where (cid:11) D C1 ^ (cid:1) (cid:1) (cid:1) ^ Cm_ (cid:1) (cid:1) (cid:1) _ xik (for reasoning from (cid:6), seeis a conjunction of negative clauses Ci D xi1Section 6). As we know from Corollary 4.3, computing one maximal model of (cid:6) Di (cid:6)iis possible in polynomial time. However, from the proof of Proposition 5.1, it follows thatexponentially many maximal models may exist. Thus, all we can expect in this regard is apolynomial total time algorithm.TUnfortunately, it turns out that there is no such algorithm, and also approximation ofmax.(cid:6)/ is hard. By a slight adaptation of the proof of Theorem 5.2, we obtain that findingan additional maximal model is NP-hard. Moreover, it follows from Corollary 3.6 andT. Eiter et al. / Artificial Intelligence 110 (1999) 57–10179Lemma 4.1 (cf. also Lemma 6.1 below) that recognizing a maximal model is polynomial.Thus, by analogous arguments as in the proofs in the previous subsections, we obtain thefollowing result.Theorem 5.7. Given the characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn,i D 1; : : : ; l,(i) it is co-NP-complete to decide whether max.(cid:6)/ D S holds, where (cid:6) DTliD1 (cid:6)iand S is a given set of maximal models of (cid:6),(ii) there is no polynomial total time algorithm for computing max.(cid:6)/, unless P D NP,(iii) there is no polynomial total time algorithm for computing a polynomial approxi-mation of max.(cid:6)/, unless P D NP.Here, “polynomial approximation” in (iii) is understood in the setting of Theorem 5.6.There is no reason for raising one’s hands in desperation about all these negativeresults. After all, one of the ideas behind characteristic models was off-line compilationfor efficient on-line reasoning. For such off-line compilation, we may be willing to pay ahigh computational price. The results from above just tell us that in the case of intersectionof knowledge bases, we indeed have to pay that price. However, this does not mean thatwe should abandon the search for reasonable and good algorithms for compilation. In therest of this section, we present an algorithm for enumerating all arbitrary models of (cid:6)with polynomial delay; this algorithm may be used as a basis for an algorithm computingC(cid:3).(cid:6)/ in some contexts.5.3. Computing all models of the intersectionLet us now consider the problem of computing all models of the intersection. The formalstatement of this problem is as follows:Problem ALL-MODELSInput: Sets of characteristic models Mi D C(cid:3).(cid:6)i/ of Horn theories (cid:6)i (cid:18) f0; 1gn, i D1; 2; : : : ; l.Output: All models v in (cid:6) DTliD1 (cid:6)i .It turns out that this problem is easier than the related Problem ALL-CMODELS, as weshall present a polynomial delay algorithm for it. Informally, this algorithm first finds aTlmodel in (cid:6) and then, for the next step, systematically shrinks the theory (cid:6) DiD1 (cid:6)i toa subset (cid:6) 0, such that no model in (cid:6) 0 has been output so far and finding a model in (cid:6) 0 isefficiently possible.The enumeration part of the algorithm is based on dynamic lexicographic enumeration[12], which improves on a previous technique in [40], and was used for efficientenumeration of the models of a Horn theory represented by a Horn formula. The ideais to restrict (cid:6) to a subset (cid:6) 0 of models different from the models v.1/, v.2/; : : : ; v.k/ D vwhich have been output in the previous steps, and to select from (cid:6) 0 a model w which hasthe largest common prefix with v. By clever bookkeeping of the previous prefixes, it ispossible to find such a model in (cid:6) 0 (so (cid:6) 6D ;) quite efficiently.The bookkeeping is done by maintaining a binary vector mark 2 f0; 1gn, where the valueof marki indicates whether the search for the models w 2 (cid:6) with common prefix up to80T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101i (cid:0) 1 (i.e., vj D wj for 1 6 j < i and vi 6D wi ) has already been successfully attempted(marki D 1) or not (marki D 0); after the output of the first model v.1/, mark is initializedto the zero vector .00 : : :0/.The algorithm, ALL-MODELS, uses a subroutine PART-MODEL, which has thefollowing specification:Procedure PART-MODEL.(cid:6)1; (cid:6)2; : : : ; (cid:6)lI b1; b2; : : : ; br /Input: Characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn, i D 1; 2; : : : ; l, anda list b1; b2; : : : ; br , r 6 n, of values bi 2 f0; 1g, 1 6 i 6 r.TliD1 (cid:6)i such that wi D bi holds for all i D 1; 2; : : : ; r, if anyOutput: A model w 2 (cid:6) Dsuch model exists; “No”, otherwise.By means of this procedure, it is possible to check whether a partial vector (given byb1; : : : ; br ) can be completed to a model in (cid:6), and such a model is returned if it is the case.Observe that this procedure can be implemented as described in the proof of Lemma 6.1,and that it returns the least model among all possible outputs.The main algorithm is then as follows.Algorithm ALL-MODELSInput: Characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn, i D 1; 2; : : : ; l.Output: All models v 2 (cid:6) DTliD1 (cid:6)i , if (cid:6) 6D ;; otherwise, “No”.Step 1. call GEN-MODEL to find some model v 2 (cid:6);if the answer is “No”, then output “No” and haltelse beginoutput v;mark VD .00 : : :0/; i VD nend;Step 2. if marki D 0 then begincall PART-MODEL((cid:6)1; : : : ; (cid:6)lI v1; : : : ; vi(cid:0)1; 1 (cid:0) vi );if a model w is returned then beginoutput w;set v VD w; marki VD 1;for j D i C 1 to n domarkj VD 0;i VD n C 1endend;Step 3. if i D 1 then haltelse begini VD i (cid:0) 1goto Step 2.end.T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10181(The algorithm can be reformulated to be slightly more efficient; we use this morereadable version for the sake of simplicity). We illustrate the algorithm on the followingexample.Example 5.1. Let us consider againM1 D C(cid:3).(cid:6)1/ D f.0110/; .0011/; .1010/gandM2 D C(cid:3).(cid:6)2/ D f.1110/; .0111/; .0011/g:In Step 1, the call to GEN-MODEL returns the least model of (cid:6), which is v D .0010/;this model is output and mark is initialized to .0000/ and i VD 4.In Step 2, PART-MODEL is called for the list 0; 0; 1; 1 of bi values (we omit (cid:6)1; : : : ; (cid:6)l ,which may be accessed as global variables). The model .0011/ is returned, which is outputand assigned to v; mark is updated to .0001/ and i is set to 5 and decreased to 4 in Step 3,where the computation returns to Step 2.In Step 3, i is decreased to 3, and in the next iteration of Step 2, PART-MODEL iscalled for the bi values 0,0,0. The answer is “No”, and hence i is decreased to 2 inStep 3. Subsequently, in Step 2, PART-MODEL is called for the bi values 0,1. The modelw D .0110/ is returned, which is output; v VD .0110/, mark VD .0100/, and i VD 5.In the next 2 iterations, PART-MODEL is called for the bi values 0,1,1,1 and 0,1,0,respectively, for which “No” is returned; after decreasing i to 1, PART-MODEL is calledagain for a single bi value 1, which also returns “No”. Hence, in Step 3, i D 1 is true, andthe algorithm stops.Thus, the models output are: (0010), (0110), and (0011), which are precisely the modelsin (cid:6).The analysis of the time complexity of Algorithm ALL-MODELS gives us the nextresult.Theorem 5.8. Algorithm ALL-MODELS is a polynomial delay algorithm for ProblemALL-MODELS, where the delay is!jMij;On2lXiD1i.e., the number of atoms times the input length.By combining Algorithms ALL-MODELS and CHECK-CMODEL, we obtain analgorithm for enumerating all characteristic models of (cid:6), which is, however, not apolynomial delay algorithm. Nonetheless, by using Algorithm ALL-MODELS, we restrictthe search space from all vectors in f0; 1gn to the models in (cid:6); if (cid:6) is small, or its sizeis polynomial in the size of C(cid:3).(cid:6)/, then this algorithm runs in polynomial total time. Thealgorithm may by particularly attractive if the size of the input I D M1; : : : ; Ml (cid:18) f0; 1gnis small in the number n; observe that if I is exponential in n, computing all models aswell as all characteristic models is possible in time polynomial in the input size by a bruteforce search. 82T. Eiter et al. / Artificial Intelligence 110 (1999) 57–1016. Reasoning from the intersectionIn this section, we turn our attention to reasoning from the intersection (cid:6) of Horntheories (cid:6)1; : : : ; (cid:6)l . In particular, we first consider answering of a deductive query (cid:11) posedto (cid:6), and then abduction in the setting where for a propositional letter q, an explanationon the basis of a set A of assumptions and the theory (cid:6) should be found.6.1. DeductionOne of the striking advantages of model-based reasoning is that large classes of queriesto a knowledge base can be evaluated efficiently. It has been shown in [24] that deductionof an arbitrary CNF formula (cid:11) from a Horn theory (cid:6) is polynomial, if (cid:6) is representedby its characteristic models C(cid:3).(cid:6)/. To evaluate the deduction (cid:6) jD (cid:11), it is sufficient tocheck whether (cid:6) jD C holds for each clause C in (cid:11); this problem can be solved bychecking whether some Horn strengthening C0 of C, i.e., a Horn clause C0 obtainedfrom C by removing all but one positive literal, is true in all characteristic models. Asshown in [24,25], (cid:6) jD (cid:11) is decidable in O.jC(cid:3).(cid:6)/j (cid:1) j(cid:11)j2/ time, where j(cid:11)j is the lengthof (cid:11).Following this paradigm, an arbitrary query (cid:11) posed to the intersection (cid:6) of Horntheories (cid:6)1; : : : ; (cid:6)l can be answered in the following way:(i) Compute C(cid:3).(cid:6)/;(ii) Apply any (fast) algorithm for deciding (cid:6) jD (cid:11) from C(cid:3).(cid:6)/.Example 6.1. Reconsider the theories b(cid:6)1 D fx1 _ x2; x1 _ x4, x2 _ x4, x3g and b(cid:6)2 Dfx1 _ x4, x1 _ x2, x3g from Example 3.1, whose characteristic sets are C(cid:3).(cid:6)1/ Df.0110/; .0011/; .1010/g and C(cid:3).(cid:6)2/ D f.1110/; .0111/; .0011/g, respectively. Supposewe want to know whether (cid:6) jD x1 _ x4 _ x3, where (cid:6) D (cid:6)1 \ (cid:6)2; observe that thequery (cid:11) is not Horn. After computing C(cid:3).(cid:6)/ D f.0110/, .0011/g, we check whetherC(cid:3).(cid:6)/ jD x1 _ x3 or C(cid:3).(cid:6)/ jD x4 _ x3 holds, where x1 _ x3 and x4 _ x3 are the Hornstrengthenings of (cid:11). However, both clauses evaluate to false on .0110/ and hence (cid:6) 6jD (cid:11)is concluded. Indeed, observe that from b(cid:6) D fx1, x2 _ x4, x3g, the query (cid:11) is not derivable.On the other hand, (cid:6) jD x1 _ x2 holds, since x1 is false in all models of C(cid:3).(cid:6)/.This approach may be infeasible, however, since the computation of C(cid:3).(cid:6)/ may needexponential time by the results of the previous section. Nonetheless, it is possible toevaluate (cid:6) jD (cid:11) efficiently, by a method which bypasses the computation of C(cid:3).(cid:6)/. Thereason is that the test (cid:6) jD C for a single clause C can be reduced to a consistency test,which is efficiently solvable. This is a consequence of the next lemma. Let, for any formula(cid:30), models.(cid:30)/ denote the set of its models.Lemma 6.1. Given the characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn,i D 1; 2; : : : ; l, and literals ‘1; : : : ; ‘a, deciding whether (cid:1) D models.‘1 ^ (cid:1) (cid:1) (cid:1) ^ ‘a/ \TliD1 (cid:6)i 6D ; holds and finding the least model of (cid:1) (if it exists) are possible inPliD1O.njMij/ time (i.e., in linear time).T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10183Proof. We can obtain an algorithm as desired by a slight adaptation of the AlgorithmGEN-MODEL+, which fixes the values of components of models according to ‘1; : : : ; ‘a.Suppose that ‘j D xij , j D 1; : : : ; h, and ‘j D xij , for j D h C 1; : : : ; k, and that noopposite literals are among ‘1, . . . , ‘a (otherwise, (cid:1) D ;). Modify GEN-MODEL+ asfollows.Let w 2 f0; 1gn be the vector which has value 1 at the components ij , for all j D 1; : : : ; h^ (cid:1) (cid:1) (cid:1) ^ xih, and set N VD fij jand value 0 at all others; i.e., w is the least model of xi1h C 1 6 j 6 ag. Then,(cid:15) replace in Step 0 the assignment “Qi VD Mi ” by “Qi VD fv 2 Mi j v > wg”, and theassignment “u VD .0; 0; : : : ; 0/” by “u VD w”;(cid:15) replace in Step 2 the assignment “uk VD 1” by the conditional statement “if k 2 Nthen output “No” and halt else uk VD 1”.Along the argument in the proof of Theorem 3.4, it can be shown that the modifiedalgorithm correctly outputs a model (in fact, the least model) of (cid:1), if one exists, and “No”otherwise; observe that the search through the space of models is restricted from the set^ (cid:1) (cid:1) (cid:1) ^ xih , and that the search is stopped as soon it isf0; 1gn to the set of all models of xi1Tl^ (cid:1) (cid:1) (cid:1) ^ xih/ \recognized that the least model in models.xi1iD1 (cid:6)i must have value 1 atsome component j such that xj occurs among ‘hC1; : : : ; ‘a.It is easy to see that by the above modifications, the order of the run time is not affectedjMij/. This proves the lemma. 2and remains to be O.nPliD1Theorem 6.2. Given the characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn,i D 1; 2; : : : ; l, and a clause C D ‘1 _ (cid:1) (cid:1) (cid:1) _ ‘a, deciding whether (cid:6) jD C holds is possiblein O.njMij/ time, i.e., in linear time.PliD1Proof. Clearly, (cid:6) jD C if and only if (cid:6) \ models.:C/ D ; holds. Since :C is equivalentto ‘1 ^ (cid:1) (cid:1) (cid:1) ^ ‘a, where ‘i denotes the complement of literal ‘i , the result immediatelyfollows from Lemma 6.1. 2Corollary 6.3. Given the characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn,i D 1; 2; : : : ; l, and a CNF formula (cid:11), (cid:6) jD (cid:11) can be checked in O.nmjMij/ time,where m is the number of clauses in (cid:11).PliD1Proof. Since (cid:6) jD (cid:11) holds if and only if (cid:6) jD C for every clause C in (cid:11), this follows fromTheorem 6.2. 2For a particular important class of formulas, we obtain the following result. Recall that aformula (cid:30) (not necessarily in CNF) is positive, if each atoms occurs therein under an evennumber of negations; in particular, every negation-free formula is positive.Theorem 6.4. Given the characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn,i D 1; 2; : : : ; l, and a positive formula (cid:11), (cid:6) jD (cid:11) can be checked in O.njMij C j(cid:11)j/time (i.e., in linear time), where j(cid:11)j denotes the length of (cid:11).PliD1Proof. Since (cid:30) is positive, it holds for any theory (cid:6) that (cid:6) jD (cid:11) holds if and only if v jD (cid:11)holds for all v 2 min.(cid:6)/ (see, e.g., [29, Section 3]).84T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101Since (cid:6) is Horn, it has the unique minimal model u (provided (cid:6) 6D ;), which can bejMij/ time (Corollary 3.5). Moreover, checking v jD (cid:11) is possibleconstructed in O.nin time O.n C j(cid:11)j/. Hence, the result follows. 2PliD16.2. AbductionAbduction [35] is a principal mode of reasoning which is heavily used in our dailylife reasoning. Informally, abduction is the task of finding an explanation for certainobservations, based on some background theory describing the relationships betweencauses and effects. There is a growing literature on this subject, which has been recognizedas an important principle of common-sense reasoning (see, e.g., [5]) and has many furtherapplications (see, e.g., references in [15]).More formally, abduction can be defined as follows, where we recall that b(cid:6) transformsa Horn theory (cid:6) into an equivalent set of Horn clauses.Definition 6.1. Let (cid:6) be a theory, A be a subset of the atoms of (cid:6), and q be an atom.Then, a subset E of literals on atoms from A is an explanation for q from (cid:6) and A, if(i) b(cid:6) [ E is consistent, and b(cid:6) [ E jD q. 6Usually, one is interested in minimal explanations, i.e., explanations E which do notcontain any other explanation properly.Example 6.2. Consider a theoryb(cid:6) D(cid:8)x1 _ x4; x4 _ x3; x1 _ x2(cid:9):Suppose we want to explain q D x2 from A D fx1; x4g. Then, we find that E D fx1g is anexplanation. Indeed, b(cid:6) [ fx1g is consistent, and b(cid:6) [ fx1g jD x2. Moreover, E is minimal.On the other hand, E0 D fx1; x4g is an alternative, non-minimal explanation of x2.One of the main obstacles for an implementation of abduction is its intrinsic computa-tional cost. Under formula-based representation, finding an abductive explanation is NP-complete in the Horn case [38], and is 6p2 -complete for general propositional theories [15],which is the prototypical complexity of many nonmonotonic reasoning problems.However, as shown in [24,25], finding an explanation is polynomial in the Horn caseif (cid:6) is represented by its characteristic models. This was a quite an encouraging result,since it shows that both deduction and abduction from a Horn theory can be done inpolynomial time. Since Theorem 6.4 in the previous subsection states that deduction fromthe intersection (cid:6) of Horn theories (cid:6)1; : : : ; (cid:6)l can be done in polynomial time, it wouldbe advantageous if a similar result can be obtained for abduction.However, it turns out that the desired generalization of the positive result in [25] is notapparent.6 Observe that in some texts, explanations must be sets of positive literals. As with Horn theories, it is known(cf. [29]) that an explanation exists only if an explanation containing merely positive literals exists; in fact, allminimal explanations are of this form.T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10185Theorem 6.5. Given the characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn,i D 1; : : : ; l, an assumption set A (cid:18) fx1; : : : ; xng, and an atom q from x1; : : : ; xn, decidingTlwhether q has an explanation from (cid:6) DiD1 (cid:6)i and A is NP-complete.Proof. The problem is in NP, since we can guess an explanation E and check inpolynomial time whether b(cid:6) [ E is consistent (Lemma 6.1) and whether b(cid:6) [ E jD q, bytesting the equivalent condition (cid:6) jD E (cid:27) q (Theorem 6.2).The NP-hardness part is shown by a modification of the reduction used in the proof ofTheorem 5.2. There, we have constructed from a CNF formula (cid:8) the characteristic setsC(cid:3).(cid:6)1/ D T1;1 [ T1;2 and C(cid:3).(cid:6)2/ D T2;1 [ T2;2 of Horn theories (cid:6)1 and (cid:6)2, respectively,along with a subset S of the characteristic set of (cid:6) D (cid:6)1 \(cid:6)2, such that some characteristicmodel v 2 C(cid:3).(cid:6)/ n S exists if and only if (cid:8) is satisfiable.We modify the construction as follows. Introduce a new component (i.e., atom) “0”, andset this component to 0 for all vectors in T1;2 and T2;2, and to 1 for all vectors in T1;1and T2;1; denote the resulting sets by T 0i;2, fori D 1; 2.i;j , for i; j D 1; 2, and let C(cid:3).(cid:6) 0Observe that any vector resulting from the intersection of a set of vectors in T 0i;1 hasvalue 1 at component 0, while any vector resulting from an intersection which involvesi;2, has value 0 at this component. Moreover, since all vectors in C(cid:3).(cid:6) 0some vector in T 0i /are incomparable, T 0i ), fori;1i D 1; 2. Following the argument in the proof of Theorem 5.2, it can be seen that eachmodel in (cid:6) 0 D (cid:6) 01i;2 is indeed the characteristic set of a Horn theory (D (cid:6) 02 has the form xB for some B (cid:18) VL [ f0g, and that each modeli / D T 0\ (cid:6) 0[ T 0[ T 0i;1v.k/ D xVLnfk;kgbelongs to (cid:6) 0, where k 2 VL; notice that v.k/ has component 0 set to 0.Let q be the propositional atom corresponding to the newly introduced component 0,and let A be the propositional atoms corresponding to all other components (alternatively,we could also set A D VL). Intuitively, if we want to explain q, then we must find a modelv in (cid:6) with the following properties: (i) v has value 1 at the component 0; and (ii) if wefix the values of the literals in A to those in v, then it is not possible to switch component0 to 0 and still have a model of (cid:6). Since the above v.k/ has components k, k and 0 all setto 0, such a v must correspond to a choice of literals whose satisfaction makes (cid:8) true.In Appendix A, we give a more detailed proof that q has an explanation from (cid:6) and Aif and only if (cid:8) is satisfiable. The theorem follows from this. 2This result shows that the tractability result for abduction in [24] is not very robust.The intuitive reason for the positive result in [24] is that if an explanation exists, thensome explanation can be easily found from the maximal models of (cid:6), which are includedin C(cid:3).(cid:6)/. However, in the case where (cid:6) is an intersection of theories, max.(cid:6)/ isnot explicitly given, and an exponential number of maximal models may exist. Whilecomputing some maximal model is tractable (Corollary 4.3), the computation of a maximalmodel which gives rise to an explanation E is NP-hard.As the abduction from an intersection is intractable, it might be suspected that astrategy of computing C(cid:3).(cid:6)/ and then running the polynomial algorithm of [24] is useful.Although this may not always be the case, since C(cid:3).(cid:6)/ requires exponential space in86T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101general (and thus its computation takes exponential time), the evaluation of an abductivequery is always possible in polynomial space and exponential time, and in some cases evenin polynomial time. An example is the following special case, which follows immediatelyfrom Theorem 6.2 by simple exhaustive search.Theorem 6.6. Given the characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn,i D 1; : : : ; l, an assumption set A (cid:18) fx1; : : : ; xng, and an atom q from x1; : : : ; xn, findingTlan explanation for q from (cid:6) DiD1 (cid:6)i and A is possible in polynomial time, if the sizejMij/ time (i.e., in linear time), ifof A is O.log n/. Moreover, it is possible in O.njAj 6 k holds for some constant k.PliD1The conclusion we can draw is that we have to look into particular query profiles(frequent or not, tractable or not, etc), and then decide which strategy to follow on thebasis of the results of this inquiry. Observe that even if space is not an issue, answeringpolynomially solvable abductive queries may take much longer (even exponentially longer)if we first compile C(cid:3).(cid:6)/ off-line than under on-line evaluation from (cid:6)1; : : : ; (cid:6)l .7. Non-Horn theoriesIn this section, we consider a possible generalization of our results to non-Horn theories.In particular, we consider a class of extended Horn theories, which includes Horn theoriesand a close variant thereof. We shall show that for this particular class, the main problemsconsidered in the previous sections are all intractable.7.1. Generalized characteristic modelsWe first review monotone theory of Boolean functions introduced in [6], and then recallthe definition of characteristic models for arbitrary classes C of Boolean functions.Given a model b 2 f0; 1gn, we define a partial order 6b over f0; 1gn by that v 6b wholds if and only if v (cid:8) b 6 w (cid:8) b holds, where (cid:8) denotes the XOR operation (i.e.,componentwise addition modulo 2; e.g., .1100/ (cid:8) .0110/ D .1010/). v 6b w can alsobe written as w >b v, and v <b w (respectively, v >b w) denotes v 6D w and v 6b w(respectively, v >b w). In other words, if bi D 0, then the order on the ith componentis normal, i.e., 0 <bi 1; on the other hand, if bi D 1, the order is reversed, i.e., 1 <bi 0. Themonotone extension of a model z 2 f0; 1gn with respect to b is defined by(cid:9);(cid:8)v 2 f0; 1gn j v >b zMb.z/ Dand the monotone extension of a theory (cid:6) (cid:18) f0; 1gn with respect to b is defined by[Mb.(cid:6)/ DMb.z/:z2(cid:6)The set of minimal models of (cid:6) with respect to b is defined byminb.(cid:6)/ D fz j z 2 (cid:6) and no v 2 (cid:6) satisfies v <b zg:T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10187Observe that min.(cid:6)/ D min.00:::0/.(cid:6)/ and max.(cid:6)/ D min.11:::1/.(cid:6)/, respectively. Mb.(cid:6)/can be rewritten as[Mb.(cid:6)/ DMb.z/:(7.1)(7.2)z2minb.(cid:6)/This is because Mb.v/ (cid:18) Mb.w/ holds for all pairs of v and w such that v >b w.It is easy to show the following properties:(cid:6) (cid:18) Mb.(cid:6)/;b =2 (cid:6) , b =2 Mb.(cid:6)/;(7.3)for all b 2 f0; 1gn. Furthermore, Mb is monotonic in (cid:6), distributes over unions (cid:6)1 [ (cid:6)2,and satisfiesMb.(cid:6)1 \ (cid:6)2/ (cid:18) Mb.(cid:6)1/ \ Mb.(cid:6)2/:Hence, by using (7.3) and (7.2), we obtain\\Mb.(cid:6)/ (cid:18) (cid:6) (cid:18)Mb.(cid:6)/ (cid:18)b =2(cid:6)b2f0;1gnConsequently, (cid:6) is characterized as follows.Proposition 7.1.\(cid:6) Db2f0;1gnMb.(cid:6)/ D\b =2(cid:6)Mb.(cid:6)/:\b =2(cid:6)Mb.(cid:6)/:(7.4)In the right hand side of (7.4), not all models b =2 (cid:6) may be necessary to represent (cid:6),Mb.(cid:6)/ may hold for some B (cid:18) f0; 1gn n (cid:6). This leads to the followingTb2Bi.e., (cid:6) Ddefinition.TDefinition 7.1 (Bshouty [6]). A set of models B is called a basis for a theory (cid:6), ifMb.(cid:6)/ holds. Furthermore, B is called a basis for a class of theories C, if it(cid:6) Dis a basis for all the theories in C.b2BClearly, f0; 1gn and f0; 1gn n (cid:6) are bases for any theory (cid:6), and f0; 1gn is a basis for anyclass of theories C. It is known that for the class of Horn theories CH ,BH D fb j k b k> n (cid:0) 1g;PniD1 xi .is a basis [29], where kxk D(7.5)Call a theory (cid:6) reverse Horn [29], if by negating all atoms xi , the resulting theoryis Horn; i.e., (cid:6) is reverse Horn, if and only if (cid:6) is closed under union of models (i.e.,v; w 2 (cid:6) implies v _ w 2 (cid:6). It is easy to see thatBRH D fb j kbk 6 1gis a basis of the class of reverse Horn theories CRH.(7.6)88T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101Monotone theory and the concept of basis has been used to define characteristic modelsof arbitrary theories as follows.Definition 7.2 (Khardon and Roth [29]). Let C be a class of theories, and let B be a basisfor C. For a theory (cid:6) 2 C, we define the set of characteristic models (cid:0) B .(cid:6)/ with respectto B as follows:(cid:0) B .(cid:6)/ D(7.7)minb.(cid:6)/:[b2BThis definition can be regarded as a generalization of that for Horn theories, sinceC(cid:3).(cid:6)/ D (cid:0) BH .(cid:6)/(7.8)holds for all Horn theories (cid:6) [29]. Note that max.(cid:6)/, which is a subset of C(cid:3).(cid:6)/, can berepresented bymax.(cid:6)/ D min.11:::1/.(cid:6)/:Any other model v in C(cid:3).(cid:6)/ is minimal with respect to some b with kbk D n (cid:0) 1.7.2. Extended Horn theoriesAs a generalization of the class of Horn theories (see (7.5)) and reverse Horn theories(see (7.6)), let us define BEH (cid:18) f0; 1gn by(cid:8)(cid:9):BEH Db 2 f0; 1gn j kbk > n (cid:0) 1orkbk 6 1(7.9)A theory (cid:6) (cid:18) f0; 1gn is called extended Horn if BEH is a basis for (cid:6), and let CEH denotethe class of extended Horn theories. Clearly, any Horn theory as well as reverse Horn theoryis always extended Horn.In the remainder of this section, we consider the Problems MODEL, CMODEL, ALL-MODELS, and ALL-CMODELS (see Sections 3–5) for CEH in place of CH . That is, the inputsets Mi , i D 1; 2; : : : ; l; are the sets of characteristic models of extended Horn theories(cid:6)1; : : : ; (cid:6)l .Since the class CEH is a natural extension of Horn theories which has a small basis,we could expect that the positive results from the previous sections carry over to it.Unfortunately, this is not the case. Already Problem MODEL, which is solvable in lineartime for CH , is intractable.Theorem 7.2. Problem MODEL for class CEH is NP-hard, even if l is fixed to 2.Proof. We reduce the following NP-complete problem [19] to our problem.Problem EXACT-HITTING-SETInput: A collection S D fS1; S2; : : : ; Smg of subsets of a finite set S D f1; 2; : : : ; rg.Question: Does S have an exact hitting set, i.e., a subset H (cid:18) S such that jH \ Si j D 1for all i?T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10189Without loss of generality, we may assume that jSi j D 3 holds for all i [19]. Setn D 2m C r and let V D f1; : : : ; ng. Define Q1; Q2 (cid:18) f0; 1gn by(cid:8)xV nfmCk;mCl;mCrCig j k; l 2 Si; k 6D l(cid:9)(cid:8)fi;mChg j h 2 SiIxQ1 DQ2 D(cid:9);the models in Q1 and Q2 can be illustrated as follows.Let (cid:6)1 D Cl^.Q1/ and (cid:6)2 D Cl_.Q2/, where Cl_.Q/ denotes the union closure of Q(dual to the intersection closure). Obviously, (cid:6)1; (cid:6)2 2 CEH, because (cid:6)1 and (cid:6)2 are Hornand reverse Horn theories, respectively.Informally, a model in Q1 corresponds to the exclusion of the elements k and l from Sifor forming a hitting set H , while a model in Q2 corresponds to the inclusion of h 2 Si inthe hitting set H . Note that the first m components of the intersection of some models inQ1 are always 1, and similarly the last m components of the union of some models in Q2are always 0. Hence, any model v 2 (cid:6)1 \ (cid:6)2 must correspond to the choice of exactly oneelement from each set Si , i D 1; : : : ; m.To prove the result, we show (see Appendix A) that(i) the set of characteristic models of (cid:6)i , with respect to class CEH (i.e., Mi D(cid:0) BEH .(cid:6)i/) can be obtained from Qi (and thus, from S) in time polynomial in nand jQi j, for i D 1; 2; and(ii) (cid:6)1 \ (cid:6)2 6D ; if and only if S has an exact hitting set. 2Corollary 7.3. For the class CEH, Problem CMODEL is NP-hard, and there exist nopolynomial total time algorithms for Problems ALL-MODELS and ALL-CMODELS,unless PDNP.Proof. NP-hardness of CMODEL is immediate from Theorem 7.2. The latter part can beshown by applying an argument similar to the proof of Theorem 5.4. 2Corollary 7.4. For the class CEH, both answering a deductive query (cid:11) and finding anabductive explanation is co-NP-hard, even if (cid:11) is an atom and the set of assumptions A isempty, respectively.From the view of formula-based representation, we find that these intractability resultsare not surprising. Any CNF formula (cid:8) can be rewritten to a conjunction (cid:8) D (cid:8)1 ^ (cid:8)2of a Horn CNF (cid:8)1 and a reverse Horn CNF (cid:8)2, respectively: (cid:8)1 is obtained by replacing90T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101negative literals xi in (cid:8) by positive literals yi and adding clauses xi _ yi, and (cid:8)2 containsall clauses xi _ yi , where the yi are new variables. An interesting question is whetherthere exists a class of formulas that extends Horn CNFs, for which some problems withintersection are intractable under model-based representation, but tractable under formula-based representation. This is left for further study.8. ConclusionIn this paper, we have considered the problem of taking the intersection (cid:6) Di (cid:6)i ofHorn theories (cid:6)i , which are represented by their characteristic models. We found bothpositive and negative results.TOn the positive side, we have shown that deciding consistency and computing somemodel or characteristic model of (cid:6) are polynomial, and that deductive queries (cid:11)in CNF to (cid:6) can be answered in polynomial time. More precisely, we presentedalgorithms which solve model finding, model checking and inference (cid:6) jD C for ajMij/ time, i.e., in time linear in the input size. For characteristicclause C in O.nmodel computation, characteristic model checking, and enumerating all models, we havePljMij/ time, or in the last case, have thisdescribed algorithms which work in O.n2iD1upper bound on the delay between subsequent outputs.PliD1On the negative side, we have shown that computing all characteristic models of (cid:6)is hard, even if the number of models is taken into account. In technical terms, we haveshown that there is no polynomial total time algorithm for computing all characteristicmodels unless P D NP. The intrinsic difficulty of this problem is further unveiled by ourresults that also computing an approximation of the set of characteristic models is a hardproblem, both for general quantitative notion (a polynomially-sized fraction or superset)and a qualitative notion in terms of the maximal models of a theory. Moreover, we haveshown that abductive reasoning from an intersection (cid:6) is intractable; this contrasts with theresult in [24], which shows that abductive reasoning from the given characteristic modelsof (cid:6) is polynomial.As we have discussed, all these results shed further light on the suitability andcomputational aspects of the model-based reasoning approach. They tell us that on-line reasoning versus off-line compilation for reasoning from an intersection has to bedeliberated, and off-line computation and on-line usage for reasoning may not pay off(e.g., for deductive reasoning). For more insight, we need a study of the typical structureof knowledge bases and query profiles, which we lack to date.Further issues remain for research. One direction is an extension of our results to otherclasses of theories. As we have shown, for extended Horn theories, all the main problemswhich we have considered for Horn theories become intractable. This indicates that thecharacteristic models approach is not immediately advantageous from the computationalside when combining knowledge bases. An investigation which classes of theories besidesHorn theories are benign for combination remains to be done.Another issue concerns a possible combination of the model-based and formula-basedapproach, in order to have complementary representations of a knowledge base which aresuitable for different purposes. It may appear that in such a context, some of the aboveT. Eiter et al. / Artificial Intelligence 110 (1999) 57–10191difficult problems, e.g., computing the characteristic set, is easier. In fact recognizingthe characteristic models of (cid:6) is not known to be co-NP-complete, and maybe evenpolynomial, if the input theories (cid:6)1; : : : ; (cid:6)l are represented both by their characteristicmodels and sets of Horn clauses.Finally, we comment here that Problem MODEL is somewhat related to the extensionproblem for double Horn functions [16], where the extension problem is to establish aBoolean function f that is consistent with a given partially defined Boolean function(pdBf) .T ; F / (i.e., f .v/ D 1 (respectively, 0) holds for all v 2 T (respectively, v 2 F ))[4,11], and a double Horn extension f is a natural restriction of Horn function. Thisrelationship comes from the similarity between two efficient algorithms for solving theextension problem and problem MODEL. However, no deep semantical relation is known.Further operations in combining theories (cid:6)i may be needed; e.g., taking the unioni (cid:6)i . Notice that (cid:6) is not necessarily Horn, even if all (cid:6)i are Horn. Such a theory(cid:6) Dmay be approximated by Horn theories, as described in [9,20,25,26].SAcknowledgementThe authors are grateful to the anonymous referees for their comments on this paper,pointing out corrections and providing helpful suggestions for improvements; the lastparagraph of Section 7.2 is due to such a comment. This work was partially supportedby the Austrian Science Fund Project N Z29-INF.The authors gratefully acknowledge the partial support of the Scientific Grant in Aidby the Ministry of Education, Science and Culture of Japan. Part of this research wasconducted while the first author visited Kyoto University in 1995 and 1998, by the supportof the Scientific Grant in Aid by the Ministry of Education, Science and Culture of Japan(Grant 06044112).Appendix A. ProofsTheorem 3.2. Problem MODEL can be solved using Algorithm GEN-MODEL inO.n2jMi j/ time.PliD1Proof. We first prove that Algorithm GEN-MODEL is correct. Let Q.j /in Step 1 of the j th iteration, and let(cid:18) ^l_(cid:19)iu.j / DwiD1w2Q.j/idenote the set Qidenote the model u obtained in Step 3 of the j th iteration. Consider the first iteration. If^^^w Dw D (cid:1) (cid:1) (cid:1) Dw;w2Q.1/1w2Q.1/2w2Q.1/l92T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101then obviously v DVw2Q.1/1w is in (cid:6). Otherwise, we claim thatv 2l\iD1(cid:1)(cid:0)Q.1/iCl^if and only ifv 2(cid:1)(cid:0)Q.2/i:Cl^l\iD1(A.1)(cid:18) Q.1/holds for all i. For the converse direction, note thati/ satisfies v > u.1/ by Lemma 3.1. This means that v can beThe if-part holds since Q.2/iD1 Cl^.Q.1/any model v 2represented by^^Tliiv Dw Dw D (cid:1) (cid:1) (cid:1) Dw2Q01w2Q02^w2Q0lwfor some Q0i(cid:18) fw 2 Q.1/Now (A.1) implies that, if Q.2/ij w > u.1/g D Q.2/iD ; holds for some i, theni. This proves the only-if-part.(cid:6) Dl\iD1(cid:1)(cid:0)Q.1/iCl^D ;Iiotherwise, in order to find a model v 2 (cid:6), we only check if there is a model v 2TiD1 Cl^.Q.2/l/, that is, the problem can be solved by returning to Step 1.We now iterate the loop of Steps 1–3 for j D 1; 2; : : : : We claim that the iteration finitelyterminates. To prove this, we show that u.j / < u.j C1/ always holds if Algorithm GEN-MODEL does not halt in the .j C 1/st iteration; as a consequence, it halts after at mostn C 1 iterations.Since the sets Q.j /are monotone nonincreasing with respect to j , u.j / 6 u.j C1/ alwaysholds. Let us assume that u.j / D u.j C1/ holds for some j . Then, by the definition of Q.j C1/,iiu.j / 6w 6 u.j C1/(A.2)^w2Q.jC1/iholds for all i. Therefore, u.j / D u.j C1/ implies^^u.j / Dw Dw D (cid:1) (cid:1) (cid:1) D^w;w2Q.jC1/1w2Q.jC1/2w2Q.jC1/land hence GEN-MODEL halts in Step 2 of the .j C 1/st iteration. This proves our claim.Finally, since each iteration can be obviously carried out in!(cid:12)(cid:12)On(cid:12)(cid:12)Q.j /ilXiD1D OnlXiD1jMij!time, Algorithm GEN-MODEL requires O.n2PliD1jMi j/ time in total. 2Corollary 3.3. Given the characteristic sets C(cid:3).(cid:6)i/ of Horn theories (cid:6)i (cid:18) f0; 1gn,i D 1; : : : ; l, Algorithm GEN-MODEL finds the least model v of (cid:6) DinO.n2jMi j/ time if (cid:6) 6D ;, and outputs “No” if (cid:6) D ;.TliD1 (cid:6)iPliD1 T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10193Proof. Define Q.j /as in the proof of Theorem 3.2. Let us assume that Algorithm GEN-MODEL outputs some model v(cid:3) in Step 2 of the kth iteration. Then, by extending (A.1) toj D 1; 2; : : : ; k (cid:0) 1, we haveil\(cid:1)(cid:0)Q.1/iCl^v 2.D (cid:6)/ , v 2(cid:1)(cid:0)Q.2/iCl^l\iD1, (cid:1) (cid:1) (cid:1) , v 2(cid:0)Q.k/i(cid:1):Cl^l\iD1(A.3)iD1TlThus (cid:6) Dminimal model iniD1 Cl^.Q.k/TliiD1 Cl^.Q.k/i/ holds. It follows from the definition of v(cid:3) that v(cid:3) is the unique/, and thus the least model of (cid:6). 2Theorem 3.4. Algorithm GEN-MODEL+ solves Problem MODEL in O.ntime, i.e., in linear time.PliD1jMi j/Vw2MiProof. Algorithm GEN-MODEL+ is similar to GEN-MODEL. Its correctness comes fromthe following observation. By Lemma 3.1, if u 2 (cid:6), then u >w holds for alli D 1; 2; : : : ; l. This implies that if all models w in an Mi satisfy wk D 1 for some k, thenuk D 1 must hold. Hence, to compute a model u 2 (cid:6), we first initialize u D .00 : : :0/, and,for each component k satisfying the above argument, update uk VD 1 and remove all modelsw with wk D 0 from all Mi until either (i) no new k exists or (ii) Mi D ; holds for some i.In case of (i), the current u satisfies u 2 (cid:6); otherwise, no u 2 (cid:6) exists. This, combinedwith the fact that buckets and counters are maintained properly, shows the correctness ofGEN-MODEL+.PliD1For the time complexity, observe that Step 0 (setting up the data structure) can be donejMij/ time, since each bit of the input can be incorporated into the structuresin O.nin constant time. The number of iterations of Steps 1 and 2 is at most n, since the numbersof 1 in v strictly increases at each iteration. Thus in total, Step 1 and the maintenance ofjMij/ time, respectively. Furthermore, the n iterations ofB in Step 2 require O.njMij/ time. This isStep 2 (other than the maintenance of B), can be executed in O.nbecause each component j of any model w is referred only once, each pointer from as wellas to a list Lh;j is immediately removed after the first reference, and each removal of anentry to Lh;j induces only a constant number of counter maintenance steps. Consequently,the overall running time of GEN-MODEL+ is O.nPliD1PliD1jMij/. 2PliD1Theorem 4.2. Problem CMODEL can be solved using Algorithm GEN-CMODEL inO.n2jMi j/ time.PliD1Proof. To establish the correctness of GEN-CMODEL, it remains from the discussion atthe beginning of this section to verify Lemma 4.1.VProof of Lemma 4.1. We assume that (4.1) holds and u =2 C(cid:3).(cid:6)/, and derive acontradiction. Then, there exists a model u0 2 (cid:6) such that u0 > u (since u =2 C(cid:3).(cid:6)/ impliesu02S u0 holds for some S (cid:18) C(cid:3).(cid:6)/, and hence any model u0 in S satisfiesthat u DTu0 > u). Consequently, u0 2liD1 Cl^.Pij / must hold for every component j such thatu0D 1 and uj D 0. Since (4.1) is true for u, holds for all j with uj D 0, we then canj94T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101conclude that there is no such u0; it follows u 2 C(cid:3).(cid:6)/, which is a contradiction. Thisproves the lemma. 2PliD1PliD1It remains to prove the bound on the time complexity. Step 1 can be done injMij/ time by using Algorithm GEN-MODEL+ (Corollary 3.5). In Step 2,O.nfor each j , both constructing Pij and updating Qi for all i can obviously be done inTliD1 Cl^.Pij / 6D ; andO.nPoutput of some w0 2ljMi j/iD1jMi j/ time. In total,time. Thus,PlO.n2iD1TliD1 Cl^.Pij / (if it is not empty) can be done in O.njMij/ time. Similarly to Step 1, checking whetherthe entire Step 2 can be executed in O.n2jMi j/ time is required. 2PliD1Theorem 4.5. Given the characteristic sets C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn,iD1 (cid:6)i , checking if v 2 C(cid:3).(cid:6)/ is possible ini D 1; : : : ; l, and a model v 2 (cid:6) DO.n2jMi j/ time by using Algorithm CHECK-CMODEL.TlPliD1Proof. Note that all models w.j / 2 S in Algorithm CHECK-CMODEL satisfy w.j / > v.Thus, by Lemma 4.4, showingS (cid:19) min.(cid:6)v/(A.4)proves the correctness of CHECK-CMODEL. For every u 2 min.(cid:6)v/,there is acomponent j such that uj D 1 and vj D 0. For such a j , let Qi VD fw 2 Mi j w > v; wj DTTll1g, i D 1; 2; : : : ; l. Then u 2iD1 Cl^.Qi / is Horn theory, itiD1 Cl^.Qi / holds. Sincehas the unique minimal model w.j /. However, u 2 min.(cid:6)v/ implies u D w.j /, and hence(A.4) follows.PliD1For the time complexity of CHECK-CMODEL, Step 0 is possible in constant time. ThePljMij/ time, and the if-statement also iniD1jMi j/jMij/ time. Hence, Algorithm CHECK-CMODELinner for-loop in Step 2 is feasible in O.njO.njtime. Step 3 can be done in O.njPlruns in O.n2jiD1jMi j/ by virtue of Corollary 3.5. Hence, Step 2 is possible in O.n2jjMij/ time. 2PliD1PliD1Proposition 5.1. For every n > 1, there exist Horn theories (cid:6)1 and (cid:6)2 such thatjC(cid:3).(cid:6)1/j D jC(cid:3).(cid:6)2/j D 2n and jC(cid:3).(cid:6)/j D 2n, where (cid:6) D (cid:6)1 \ (cid:6)2.Proof (continued). It remains to show that S D C(cid:3).(cid:6)/ (5.2) holds. We first showS D max.(cid:6)/.(cid:18) C(cid:3).(cid:6)//:(A.5)It is easy to see that S (cid:18) (cid:6). Assume that there is a model xB 2 (cid:6) such that B (cid:18) V1 [ V2and j; n C j 2 B for some j 2 V1. Then, by j; n C j 2 B and xB 2 (cid:6)1, we have 3n C j 2 B.However, this is a contradiction to (5.1). Hencefj; n C j g 6(cid:18) B(A.6)holds, which implies the maximality of all models in S, i.e., (A.5). For a non-maximalmodel xB 2 (cid:6) n S, we can verify from (5.1) and (A.6) thatT. Eiter et al. / Artificial Intelligence 110 (1999) 57–101v D^xBxB 2S: xB >vholds; i.e., v =2 C(cid:3).(cid:6)/. This proves our claim (5.2). 295(A.7)Theorem 5.2. Problem ADD-CMODEL is NP-complete. This holds even if l is fixed to 2.Proof (continued). Clearly, all models in C(cid:3).(cid:6)i / are maximal; hence, there exist Horntheories (cid:6)i with the defined characteristic models.To show that the reduction is appropriate, we will first prove the following containments:S (cid:18) (cid:6)B (cid:18) VL holds for all xB 2 (cid:6)S1 (cid:18) max.(cid:6)/.(cid:18) C(cid:3).(cid:6)//S2 (cid:18) C(cid:3).(cid:6)/(cid:3)S (cid:18) C.(cid:6)/:(A.8)(A.9)(A.10)(A.11)(A.12)This shows that (5.3), (5.4) and (5.5) in fact give a legal instance of our problem.(A.8): ConsiderxB D xVLnfk;k;qg.2 S/;where q D k or k is also allowed. By the assumption on (cid:8), every literal q appears in someclause Cj . Thusx.V1nfnCj g/[.VLnfqg/ 2 C(cid:3).(cid:6)1/holds for some j . This, combined with x.VLnfk;kg/[V2 2 C(cid:3).(cid:6)1/, impliesxB D x.V1nfnCj g/[.VLnfqg/ ^ x.VLnfk;kg/[V2 2 (cid:6)1:Similarly, we can show xB 2 (cid:6)2. Hence (A.8) holds.(A.9): Since any xB1 2 (cid:6)1 satisfies either V2 (cid:18) B1 or V2 \ B1 D ;, and no xB2 2 (cid:6)2satisfies V2 (cid:18) B2, we have V2 \ B D ; for all xB 2 (cid:6). Symmetrically, V1 \ B D ; holdsfor all xB 2 (cid:6). Hence (A.9) holds for all xB 2 (cid:6).(A.10): LetxB D xVLnfk;kg.2 S1/:If xB =2 max.(cid:6)/, then, by (A.8) and (A.9), some models in(cid:9)(cid:8)xVL; xVLnfkg; xVLnfkg^are in (cid:6). Since no xB1 2 C(cid:3).(cid:6)1/ satisfies B1 (cid:19) VL, we have xVL =2 (cid:6). Furthermore,xVLnfqg 2 (cid:6)1 for q D k or k is possible only ifxVLnfqg Dx.V1nfnCj g/[.VLnfqg/(A.13)nCj 2V1holds. However, this is impossible by the assumption on (cid:8) that no literal q in L appears inall clauses Cj .96T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101(A.11): For every v D xVLnfk;k;qg 2 S2, there is exactly one w D xVLnfk;kg 2 S such thatw > v. Thus, if v can be represented as the intersection of models in C(cid:3).(cid:6)/, then at leastone of the models in(cid:8)xVLnfk;qg; xVLnfk;qg; xVLnfqg(cid:9)is contained in C(cid:3).(cid:6)/ n S. However, we will show below (in the proof of (c) ) (b)) that, ifsuch a model exists in (cid:6), then (cid:8) becomes > by fixing appropriate two atoms in (cid:8), whichcontradicts the assumption (ii) on (cid:8). Therefore, (A.11) holds.(A.12): Immediate from (A.10) and (A.11). 2Clearly C(cid:3).(cid:6)1/, C(cid:3).(cid:6)2/ and S can be constructed in polynomial time from (cid:8). Hence,to complete the proof, it remains to show that (a) C(cid:3).(cid:6)/ n S 6D ; holds if and only if (b) (cid:8)is satisfiable.It is easy to show that any model u with u 6 w for some w 2 S is in Cl^.S/. Thus, (a) isequivalent to the existence of a model xB 2 (cid:6) such that xB 66 w holds for all w 2 S. As aconsequence, (a) is also equivalent to (c) the existence of a model xB 2 (cid:6) satisfying eitherk 2 B or k 2 B (or both) for all k 2 VL. To prove the equivalence of (a) and (b), we showthe equivalence of conditions (b) and (c).(c) ) (b): By xB 2 (cid:6)1 and (A.9), xB can be represented by^xB Dx.V1nfnCj g/[.VLnfqj g/;nCj 2V1where each qj 2 Cj satisfies qj 2 VL n B. Since at least one of k; k is contained in B, wecan conclude that (cid:8) is satisfiable; a model v such that (cid:8).v/ D 1 can be constructed byfixing vk D 1 if k 2 VL n B, 0 if k 2 VL n B, and 0 or 1 arbitrarily if k; k =2 VL n B.(b) ) (c): For a model v with (cid:8).v/ D 1, letVL n B D fk j vk D 1g [ fk j vk D 0g:This means that, for each Cj , there is a component qj 2 Cj \ .VL n B/. Furthermore, since^^xB DDx.V1nfnCj g/[.VLnfqj g/.2 (cid:6)1/nCj 2V1^qj 2Cj \.VLnB/^nCmCj 2V2qj 2Cj \.VLnB/x.V2nfnCmCj g/[.VLnfqj g/ .2 (cid:6)2/holds, we have a model xB 2 (cid:6)1 \ (cid:6)2 .D (cid:6)/. This completes the proof. 2Theorem 5.6. Let p.(cid:1)/ and q.(cid:1)/ be any polynomials. Then, there is no polynomial totaltime algorithm A for computing, given the characteristic sets Mi D C(cid:3).(cid:6)i / of Horntheories (cid:6)i (cid:18) f0; 1gn, i D 1; 2; : : : ; l, a set of models N (cid:18) f0; 1gn such that .i/ jC(cid:3).(cid:6)/j 6q.jN \ C(cid:3).(cid:6)/j/ and .ii/ jNj 6 p.jC(cid:3).(cid:6)/j/, unless P D NP. This holds even if l is fixedto 2.Proof. We prove this result by an extension to the proof Theorem 5.2 and applying anargument similar as in the proof of Theorem 5.4.T. Eiter et al. / Artificial Intelligence 110 (1999) 57–10197Recall that we have shown in Theorem 5.2 that Problem ADD-CMODEL is NP-hard. Inthe proof, we have described the construction of characteristic sets C(cid:3).(cid:6)1/, C(cid:3).(cid:6)2/ and aset of models S (cid:18) C(cid:3).(cid:6)/, where (cid:6) D (cid:6)1 \ (cid:6)2, from a restricted CNF formula (cid:8) such thatS 6D C(cid:3).(cid:6)/ holds if and and only if (cid:8) is satisfiable. The restrictions on (cid:8) were: (i) everyliteral in L appears in (cid:8), but no literal appears in all clauses; and (ii) (cid:8) does not becomea tautology by fixing the truth value of any two atoms xi and xj .Without loss of generality, we may replace (i) by the stronger condition .i0/: for eachatom xi , the clause xi _ xi occurs in (cid:8), and require in addition: (iii) if (cid:8) is satisfiable,then it has exponentially many models in the size j(cid:8)j of (cid:8). Condition (iii) can be easilyachieved by adding to (cid:8) sufficiently many clauses yi _ yi , where the yi are fresh atoms.For a formula (cid:8) satisfying .i0/, (ii) and (iii), it follows from the construction that thecharacteristic models v 2 C(cid:3).(cid:6)/ n S correspond 1–1 to the models of (cid:8). Hence, it followsthat (cid:8) is satisfiable, if and only if C(cid:3).(cid:6)/ is exponential in j(cid:8)j, and that (cid:8) is unsatisfiable,if and only if S D C(cid:3).(cid:6)/, which is polynomial in j(cid:8)j.Suppose then an algorithm A as hypothesized exists, whose running time is boundedby a polynomial r.I; O/, where I and O are the input and output length, respectively.We use A to solve Problem ADD-CMODEL in polynomial time as follows. We run A on(cid:6)1; : : : ; (cid:6)l for at most r.I; q.p.jSj/// many steps; this is the maximum running time ifC(cid:3).(cid:6)/ D S holds. Since jC(cid:3).(cid:6)/ n Sj is exponential in jSj if S 6D C(cid:3).(cid:6)/, it follows thatS D C(cid:3).(cid:6)/, if A halts within this time, and that S 6D C(cid:3).(cid:6)/, if A does not. Consequently,Problem ADD-CMODEL can be decided in polynomial time, which implies P D NP; theresult follows. 2Theorem 5.8. Algorithm ALL-MODELS is a polynomial delay algorithm for ProblemPljMij/, i.e., the number of atoms times theALL-MODELS, where the delay is O.n2iD1input length.Proof. The correctness of Algorithm ALL-MODELS follows from that fact that it is aninstance of the general enumeration scheme described in [12]; we omit the details.PliD1For the time complexity, we note that by Corollary 3.3, Algorithm GEN-MODEL+jMi j/. Furthermore, until the first successfulfinds a model of (cid:6) within time O.ncall of PART-MODEL and between two successful calls of PART-MODEL, at most n (cid:0) 1failing calls of PART-MODEL may occur; since Lemma 6.1 implies that the run time ofPljMij/, it follows that the delay between consecutive outputsPART-MODEL is O.niD1PljMij/. Finally, at most n (cid:0) 1 failing calls of PART-MODEL mayis bounded by O.n2iD1jMij/ after theoccur until the algorithm halts, and hence it stops within time O.n2last output.PliD1Consequently, ALL-MODELS outputs the models in (cid:6) with O.n2jMij/ de-PliD1lay. 2Theorem 6.5. Given the characteristic sets Mi D C(cid:3).(cid:6)i / of Horn theories (cid:6)i (cid:18) f0; 1gn,i D 1; : : : ; l, an assumption set A (cid:18) fx1; : : : ; xng, and an atom q from x1; : : : ; xn, decidingTlwhether q has an explanation from (cid:6) DiD1 (cid:6)i and A is NP-complete.98T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101Proof (continued). We claim that q has an explanation from (cid:6) and A if and only if (cid:8) issatisfiable.Prior to the proof of the claim, we observe the following useful lemma.Lemma A.1. A letter q has an explanation from a Horn theory (cid:6) and assumptions A, ifand only if there exists a model v in (cid:6) such that v jD q and (cid:6) jD E (cid:27) q, where E is theset (seen as conjunction) of all literals ‘ over A such that v jD ‘.Proof. The if direction is trivial; for the only-if direction, suppose E0 is an explanation.Then, there exists a model v in (cid:6) such that v jD E0 ^ q. Let E as described; then, sinceE0 (cid:18) E and b(cid:6) [ E0 jD q, we have b(cid:6) [ E jD q, and thus (cid:6) jD E (cid:27) q. 2To prove the only-if direction of the claim, suppose an explanation E exists. We mayassume that E has the form as in Lemma A.1 for some model v 2 (cid:6) 0. Then, sincecomponent 0 of v has value 1, v must be the intersection of vectors from T 01;1. Moreover,this intersection must correspond to the choice of a literal from each clause, such that notwo opposite literals are selected, i.e., v D xB such that B \ fk; kg 6D ;, for all k 2 VL. For,otherwise for some modelv.k/ D xVLnfk;kg 2 (cid:6);0we would have that w D v ^ v.k/ would satisfy w jD E but w 6jD q, which contradictsthat E is an explanation. (From v, we obtain a model of formula (cid:8) as in the proof ofTheorem 5.2.)For the if-direction, suppose (cid:8) is satisfiable. Then, from any model of (cid:8), we constructsimilar as in the proof of Theorem 5.2 a model v in (cid:6) 0 which is the intersection of modelsfrom T1;1 and has no two components k; k set to 0, for any k 2 VL; observe that v has value1 at component 0. Let E be as in Lemma A.1; then, E is an explanation for q. Indeed, anymodel w 2 (cid:6) which has value 0 at component 0, i.e., w jD :q, must have value 0 at somecomponents k; k where k 2 VL. It follows that w jD :E, and hence clearly (cid:6) jD E (cid:27) q.Thus, by Lemma A.1, E is an explanation of q. This proves the claim and the result. 2Theorem 7.2. Problem MODEL for class CEH is NP-hard, even if l is fixed to 2.Proof (continued). (i): Let us consider M1. By (7.7), we haveM1 D (cid:0) BH .(cid:6)1/ [ (cid:0) BRH .(cid:6)1/:Since max.Q1/ D Q1 and (cid:6)1 D Cl^.Q1/, we have C(cid:3).(cid:6)1/ D Q1. Thus, by (7.8) we have(cid:0) BH .(cid:6)1/ D Q1.Concerning (cid:0) BRH .(cid:6)1/, letz Dw and z.b/ D^w2Q1^ww2Q1: w>bfor any b with kbk D 1. Then, since z 6b v (respectively, z.b/ 6b v) holds for all v 2 (cid:6)1with vj D 0 (respectively, vj D 1), where j denotes an index such that bj D 1, it followsthat min.00:::0/.(cid:6)1/ D z and minb.(cid:6)1/ (cid:18) fz; zbg. This implies that also (cid:0) BRH .(cid:6)1/ isT. Eiter et al. / Artificial Intelligence 110 (1999) 57–10199computable from Q1 in polynomial time. Consequently, M1 is computable from Q1 inpolynomial time. The set M2 can be obtained in a similar manner; this proves (i).(ii): Any model v 2 (cid:6)1 \ (cid:6)2 must satisfyvj D 1;vj D 0;for all j D 1; 2; : : : ; m;for all j D m C r C 1; m C r C 2; : : : ; m C r C m:To prove the only-if-part of (ii), assume that some model v 2 (cid:6)1 \ (cid:6)2 exists. Then,(A.14)(A.15)^_v Dw Dww2Q01w2Q02(cid:18) Q2 . We show that H D fh j xfi;mChg 2(cid:18) Q1 and Q02g .(cid:18) S/ forms an exact hitting set of S. By (A.14), for each i D 1; 2; : : : ; m there is anholds for some nonempty sets Q01Q02h such that xfi;mChg 2 Q0jH \ Si j > 12. This means that H satisfiesfor all i. Furthermore, by (A.15), there are for each i elements k and l such thatxV nfmCk;mCl;mCnCig 2 Q01;which implies k; l =2 H . Thus we havejH \ Si j 6 1for all i. By (A.16) and (A.17), we conclude that H is an exact hitting set of S.For the if-direction, assume that H is an exact hitting set of S. Then define(cid:9)(cid:8)xV nfmCki ;mCli ;mCrCig j fki; lig D Si n H; i D 1; 2; : : : ; m(cid:9)(cid:8)xfi;mChi g j fhig D Si \ H; i D 1; 2; : : : ; m:DD0Q1Q02We can see thatand the theorem. 2w2Q01VWw Dw2Q02w .D v/ holds and hence v 2 (cid:6)1 \ (cid:6)2; this proves (ii)(A.16)(A.17)References[1] C. Baral, S. Kraus, J. Minker, Combining multiple knowledge bases, IEEE Trans. Knowledge and DataEngineering 3 (2) (1991) 208–220.[2] C. Baral, S. Kraus, J. Minker, V.S. Subrahmanian, Combining knowledge bases consisting of first ordertheories, in: M. Ras, Z.W. Zemankova (Eds.), Proc. 6th International Symposium on Methodologies forIntelligent Systems (ISMIS-91), Lecture Notes in Artificial Intelligence, Vol. 542, Springer, Berlin, 1991,pp. 92–101.[3] C. Beeri, M. Down, R. Fagin, R. Statman, On the structure of armstrong relations for functionaldependencies, J. ACM 31 (1) (1984) 30–46.[4] E. Boros, T. Ibaraki, K. Makino, Error-free and best-fit extensions of partially defined Boolean functions,Inform. and Comput. 140 (1998) 254–283.[5] G. Brewka, J. Dix, K. Konolige, Nonmonotonic reasoning—an overview, CSLI Lecture Notes 73, CSLIPublications, Stanford University, 1997.[6] N.H. Bshouty, Exact learning Boolean functions via the monotone theory, Inform. and Comput. 123 (1995)146–153.100T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101[7] R. Burke, K.J. Hammond, Combining databases and knowledge bases for assisted browsing, in: Proc. AAAISpring Symposium on Information Gathering, 1995.[8] M. Cadoli, The complexity of model checking for circumscriptive formulae, Inform. Process. Lett. 44 (1992)113–118.[9] M. Cadoli, Semantical and computational aspects of Horn approximations, in: Proc. IJCAI-93, Chambéry,France, 1993, pp. 39–44.[10] M. Cadoli, M. Schaerf, Tractable reasoning via approximation, Artificial Intelligence 74 (2) (1995) 249–310.[11] Y. Crama, P. Hammer, T. Ibaraki, Cause-effect relationships and partially defined Boolean functions, Ann.Oper. Res. 16 (1988) 299–326.[12] R. Dechter, A. Itai, Finding all solutions if you can find one, Technical Report ICS-TR-92-61, University ofCalifornia at Riverside, September 1992.[13] R. Dechter, J. Pearl, Structure identification in relational data, Artificial Intelligence 58 (1992) 237–270.[14] W. Dowling, J.H. Gallier, Linear-time algorithms for testing the satisfiability of propositional Horn theories,J. Logic Programming 3 (1984) 267–284.[15] T. Eiter, G. Gottlob, The complexity of logic-based abduction, J. ACM 42 (1) (1995) 3–42.[16] T. Eiter, T. Ibaraki, K. Makino, Double Horn functions, Inform. and Comput. 144 (1998) 155–190.[17] D. Gabbay, C. Hogger, J. Robinson (Eds.), Handbook of Logic in Artificial Intelligence and LogicProgramming, Clarendon Press, Oxford, 1993.[18] P. Gärdenfors, Knowledge in Flux, Bradford Books/MIT Press, Cambridge, MA, 1988.[19] M. Garey, D.S. Johnson, Computers and Intractability—A Guide to the Theory of NP-Completeness, W.H.Freeman, New York, 1979.[20] G. Gogic, C. Papadimitriou, M. Sideri, Incremental recompilation of knowledge, J. Artificial IntelligenceRes. 8 (1998) 23–37.[21] A. Itai, J.A. Makowsky, Unification as a complexity measure for logic programming, J. Logic Programming4 (1987) 105–117.[22] D.S. Johnson, M. Yannakakis, C.H. Papadimitriou, On generating all maximal independent sets, Inform.Process. Lett. 27 (1988) 119–123.[23] H. Katsuno, A.O. Mendelzon, Propositional knowledge base revision and minimal change, ArtificialIntelligence 52 (1991) 253–294.[24] H. Kautz, M. Kearns, B. Selman, Reasoning with characteristic models, in: Proc. AAAI-93, Washington,DC, 1993.[25] H. Kautz, M. Kearns, B. Selman, Horn approximations of empirical data, Artificial Intelligence 74 (1995)129–245.[26] D. Kavvadias, C. Papadimitriou, M. Sideri, On Horn envelopes and hypergraph transversals, in: W. Ng(Ed.), Proc. 4th International Symposium on Algorithms and Computation (ISAAC-93), Lecture Notes inComputer Science, Vol. 762, Springer, Berlin, 1993, pp. 399–405.[27] R. Khardon, Translating between Horn representations and their characteristic models, J. ArtificialIntelligence Res. 3 (1995) 349–372.[28] R. Khardon, H. Mannila, D. Roth, Reasoning with examples: propositional formulae and databasedependencies, Acta Informatica, to appear.[29] R. Khardon, D. Roth, Reasoning with models, Artificial Intelligence 87 (1–2) (1996) 187–213.[30] R. Khardon, D. Roth, Defaults and relevance in model-based reasoning, Artificial Intelligence 97 (1–2)(1997) 169–193.[31] H. Levesque, Making believers out of computers, Artificial Intelligence 30 (1986) 81–108.[32] P. Liberatore, M. Schaerf, The complexity of model checking for belief revision and update, in: Proc. AAAI-96, Portland, OR, 1996, pp. 556–561.[33] P. Liberatore, M. Schaerf, Arbitration (or how to merge knowledge bases), IEEE Trans. Knowledge and DataEngineering 10 (1) (1998) 76–90.[34] J. McKinsey, The decision problem for some classes of sentences without quantifiers, J. Symbolic Logic 8(1943) 61–76.[35] C.S. Peirce, Abduction and induction, in: J. Buchler (Ed.), Philosophical Writings of Ch.S. Peirce, Dover,New York, 1955, Chapter 11.[36] P.Z. Revesz, On the semantics of theory change: arbitration between old and new information, in: Proc.ACM Symposium on Principles of Database Systems (PODS-93), 1993, pp. 71–79.T. Eiter et al. / Artificial Intelligence 110 (1999) 57–101101[37] D. Roth, On the hardness of approximate reasoning, Artificial Intelligence 82 (1–2) (1996) 273–302.[38] B. Selman, H.J. Levesque, Abductive and default reasoning: A computational core, in: Proc. AAAI-90,Boston, MA, 1990, pp. 343–348.[39] V. Subrahmanian, Amalgamating knowledge bases, ACM Trans. Database Syst. 19 (2) (1994) 291–331.[40] L. Valiant, The complexity of enumeration and reliability problems, SIAM J. Comput. 8 (1979) 410–421.[41] M. Winslett, Updating Logical Databases, Cambridge Univ. Press, Cambridge, 1990.