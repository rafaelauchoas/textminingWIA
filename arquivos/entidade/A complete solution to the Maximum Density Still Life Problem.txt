Artificial Intelligence 184–185 (2012) 1–16Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA complete solution to the Maximum Density Still Life Problem ✩Geoffrey Chu, Peter J. Stuckey∗NICTA Victoria Laboratory, Department of Computing and Information Systems, University of Melbourne, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 17 August 2011Received in revised form 8 November 2011Accepted 8 February 2012Available online 10 February 2012Keywords:Combinatorial optimizationSearchConstraint programmingDynamic programming1. IntroductionThe Maximum Density Still Life Problem (CSPLib prob032) is to find the maximum numberof live cells that can fit in an n × n region of an infinite board, so that the board is stableunder the rules of Conway’s Game of Life. It is considered a very difficult problem andhas a raw search space of O (2n2). Previous state of the art methods could only solveup to n = 20. We give a powerful reformulation of the problem into one of minimizing“wastage” instead of maximizing the number of live cells. This reformulation allows usto compute very strong upper bounds on the number of live cells, which dramaticallyreduces the search space. It also gives us significant insights into the nature of the problem.By combining these insights with several powerful techniques: remodeling, lazy clausegeneration, bounded dynamic programming, relaxations, and custom search, we are ableto solve the Maximum Density Still Life Problem for all n. This is possible because theMaximum Density Still Life Problem is in fact well behaved mathematically for sufficientlylarge n (around n > 200) and if such very large instances can be solved, then there existways to construct provably optimal solutions for all n from a finite set of base solutions.Thus we show that the Maximum Density Still Life Problem has a closed form solution anddoes not require exponential time to solve.© 2012 Elsevier B.V. All rights reserved.The Game of Life was invented by John Horton Conway and is played on an infinite board made up of square cells. Thegame takes place through discrete time steps. Each cell c in the board is either alive or dead during each time period. Thelive/dead state of cell c at time t + 1, denoted as state(c, t + 1), can be obtained from the number l of live neighbors of c attime t and from state(c, t) as follows:state(c, t + 1) =⎧⎪⎪⎪⎨⎪⎪⎪⎩l < 2 dead [Death by isolation]l = 2 state(c, t) [Stable condition]l = 3 alive [Birth condition]l > 3 dead [Death by overcrowding]The board is said to be a still life at time t if it is stable under these rules, i.e., it is identical at t + 1. For example, anempty board is a still life. Given a finite n × n region where all cells outside must be dead, the Maximum Density Still LifeProblem is to compute the maximum density of live cells that can appear in the n × n region in a still life, or equivalently,the maximum number of live cells that can appear in the n × n region.✩This paper includes and significantly extends the earlier work (Chu et al., 2009) [1].* Corresponding author.E-mail address: peter.stuckey@nicta.com.au (P.J. Stuckey).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2012.02.0012G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–16The raw search space of the Still Life Problem has size O (2n2) and it is extremely difficult even for small values of n.Previous search methods using integer programming (IP) [2] and constraint programming (CP) [3] could only solve upto n = 9, while a CP/IP hybrid method with symmetry breaking [3] could solve up to n = 15. An attempt using bucketelimination [4] reduced the time complexity to O (n223n) but increased the space complexity to O (n22n). This methodcould solve up to n = 14 before it ran out of memory. A subsequent improvement that combined bucket elimination withsearch [5] used less memory and was able to solve up to n = 20.In this paper, we combine some mathematical insights into the Still Life Problem with several powerful search techniquesto completely solve the problem for all n. This is possible because the Still Life Problem becomes well behaved mathemat-ically for sufficiently large n (around n > 200). The overall solution plan has four parts: (1) use complete search with amodel that propagates strongly to solve the problem for all “small” n (n (cid:2) 50), (2) use bounded dynamic programming ona relaxation of the problem to prove a closed form upper bound on live cells for all medium and large n (n > 50), (3) use acustom search to look for special form solutions to prove lower bounds on live cells for medium n (around 50 < n (cid:2) 200),(4) look for special form periodic solutions that can be tiled to construct arbitrarily large solutions to prove lower boundson live cells for large n (around n > 200). The lower and upper bounds proved in parts 2, 3 and 4 coincide, thus they are theoptimums for those n. Each of these parts require some mathematical insights into the problem as well as the appropriateapplication of search techniques. We give a brief overview of them here.Part 1. In Section 2 we give a new insightful proof that the maximum density of live cells in the infinite case (n = ∞)2 . The proof is based on counting “wastage”. Wastage is calculated by looking at each 3 × 3 pattern and seeing howis 1much space we have “wasted” by not fitting in enough live cells into the local area. This proof allows us to reformulatethe Maximum Density Still Life Problem into one of minimizing wastage rather than maximizing the number of live cells.The new model gives very tight lower bounds on wastage that dramatically increases the pruning strength of the model. InSection 3 we show how this model, coupled with a simple lookahead, allows a Lazy Clause Generation [6] solver to solvethe problem up to around n = 50 using complete search.Part 2. In Section 4, we conjecture that for sufficiently large n, all wastage which is forced to occur by the still life con-straints are forced by only the constraints near the edge of the n × n region. That is, only the boundary conditions causesuboptimality compared to the optimal density of 12 in the infinite case. If this conjecture holds, then it is possible to geta very good or optimal lower bound on the wastage (and thus upper bound on live cells) simply by relaxing the Still LifeProblem onto its boundary and solving it, i.e., ignore all constraints other than then those within the first k rows of theedge of the n × n region for some small k. This relaxed problem has the interesting property that the pathwidth of itsconstraint graph is O (k) instead of the O (n) of the original. There exist various techniques for solving such low pathwidthproblems which can reduce the complexity from O (2nk) to only O (n22k), e.g., caching [7], nogood learning [6,8], dynamicprogramming [9], variable elimination [4]. In Section 5 we show how to use bounded dynamic programming [10] to solvethe boundary relaxation. For fixed and small k, these relaxed problems can be solved in O (n) time. Furthermore, due to thetranslational symmetry in the problem, we can solve the boundary relaxation for all n using induction by examining a finitenumber of base cases. Thus we can derive a closed form expression which gives a very tight upper bound on the numberof live cells.Part 3. In Section 6, we conjecture that for sufficiently large n, there always exist optimal solutions of the following form:wastage only exists at the four 4 × 4 corners of the board, or in the one row beyond the edge of the board. Based on thisconjecture, we search for these special form solutions using a variant of limited discrepancy search with dynamic relaxationsas a lookahead. Such a search can find optimal solutions for up to n = 200 or so. We know that the solution is optimal ifthe number of live cells in the solution coincides with the upper bound on live cells proved in part 2.Part 4. The Still Life Problem becomes mathematically well behaved for sufficiently large n. This raises the possibility thatoptimal solutions can be constructed in a systematic way. In Section 7 we find optimal solutions for n ∼ 200 which areperiodic, and which satisfy certain other constraints. If such solutions are found, then they can be tiled indefinitely toproduce arbitrarily large, provably optimal solutions.We conclude the paper in Section 8.2. Wastage reformulationThe maximum density of live cells in a still life on an infinite board is known to be 12 [11]. However, this proof is quitecomplex and only applies to the infinite case. In this section we provide a much simpler proof that can easily be extendedto the finite case and gives much better insight into the possible sub-patterns that can occur in an optimal solution.Theorem 1. The maximum density of live cells in a still life on an infinite board is 12 .Proof. Consider any configuration of the board which is a still life. We show that the density of live cells in this configura-tion is (cid:2) 12 . We initially assign 2 tokens to each cell in the board. We will show below that there exists a way to redistributeG. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–163Table 1Possible patterns around dead cells, showing where they donate their tokens and anywastage.Table 2Contributions to the tokens of a live cell from its Southneighbor.these tokens such that: (1) each live cell ends up with (cid:3) 4 tokens, and (2) each token either remains at the original cell towhich it was assigned, or is redistributed to one of the 4 orthogonal neighbors. If such a redistribution exists, then in anyn × n region of the infinite board, if L is the number of live cells, then: 2(n2 + 4n) (cid:3) 4L. This is because at most 2(n2 + 4n)tokens could have ended up in the n × n region after redistribution, and each live cell must have (cid:3) 4 of them. Rearranging,we get L/n2 (cid:2) 12 and the2result follows.+ 2/n, where the LHS is the density of live cells. As n approaches infinity, the RHS approaches 1We now describe a redistribution of tokens satisfying the above two properties, i.e., (1) each live cell ends up with (cid:3) 4tokens, and (2) each token either remains at the original cell or is redistributed to one of the 4 neighbors. The redistributionoccurs in two phases. In the first phase, the tokens of a dead cell are redistributed only to its orthogonal neighboring livecells, i.e. those that share an edge with the dead cell. Table 1 shows all possible patterns of orthogonal neighbors (up tosymmetries) around a dead cell. Live cells are marked with a black dot, dead cells are unmarked, and cells whose state isirrelevant for our purposes are marked with a “?”. Each pattern indicates the beneficiaries, i.e., the North, East, South orWest neighbors that receive 1 token from the center dead cell, as well as a number indicating the “wastage”, which we willdiscuss later.As can be seen from Table 1, a dead cell gives 1 token to each of its live orthogonal neighbors if it has (cid:2) 2 live orthogonalneighbors, 1 token to the two opposing live orthogonal neighbors if it has 3, and gives no tokens if it has 0 or 4 orthogonalneighbors. Given this set of redistribution rules, it is sufficient to examine the 3 bordering cells on each side of a live cell todetermine how many tokens are obtained from the orthogonal neighbor on that side. For example, the token obtained bythe central live cell from its South neighbor is illustrated in Table 2.The tokens obtained by a live cell can therefore be computed by simply adding up the tokens obtained from its fourorthogonal neighbors. Since each live cell starts off with 2 tokens, it must receive at least 2 extra tokens to end up with(cid:3) 4 tokens. Let us look at all possible patterns around a live cell and see where the cell will receive tokens from. Table 3shows all possible neighborhoods of a live cell (up to symmetries). For each pattern, it shows the benefactors, i.e., the North,East, South or West neighbors that give 1 token to the live cell, as well as a number indicating the “wastage”, which wewill discuss later. As can be seen from the table, after the first redistribution phase, almost every live cell already has therequired 4 tokens. The only exceptions are the live cells at the center of the last pattern in Table 3, which only received 1extra token and so currently has 3 tokens.In the second phase of redistribution, we fix up these remaining cases. Note that due to the still life constraints, the lasttwo patterns in Table 3 always occur together in unique pairs such that the last pattern is one cell down from the secondlast. To see this, suppose somewhere, the second last pattern occurs. The bottom middle live cell in the second last patternalready has three live neighbors. The still life constraints says that it cannot have more than 3 live neighbors, thus the nextrow from the bottom of the second last pattern has to be three dead cells, which then forms the last pattern one cell downas claimed. Similarly, suppose somewhere, the last pattern occurs. The top middle live cell in the last pattern already hasthree live neighbors. The still life constraints says that it cannot have more than 3 live neighbors, thus the next row fromthe top of the last pattern has to be three dead cells, which then forms the second last pattern one cell up as claimed.Also, note that the second last pattern has one extra unneeded token since it received 3 from its neighbors in the firstredistribution phase. Thus, in the second phase of redistribution, for each live cell at the center of the second last pattern,we take 1 of the 2 original tokens it had and redistribute it to the live cell at the bottom middle of the pattern, which mustbe the center live cell of a last pattern. After this, all live cells have (cid:3) 4 tokens, and each token either remained where it4G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–16Table 3Possible patterns around a live cell showing token benefactors and any wastage.was originally, or was redistributed to one of the orthogonal neighbors. Thus this redistribution has the two properties weclaimed and our proof is complete. (cid:2)The above proof is not only much simpler than that of [11], it also provides us with good insight into how to computeuseful bounds for the case where the board is finite. In particular, it tells us which 3 × 3 patterns are optimal and whichare suboptimal with respect to maximizing the number of live cells. Let us define wastage as follows. For a dead cell, letthe wastage of the cell be the number of tokens which was not given to any of the adjacent live cells during redistribution(shown in Table 1). For a live cell, let the wastage of the cell be the number of excess tokens above 4 it has after redistri-bution (shown in Table 3). Every live cell must end up with (cid:3) 4 tokens after redistribution. Thus every 4 tokens which arenot used to satisfy the (cid:3) 4 token requirement for some live cell reduces the number of live cell in the region by 1. In otherwords, the 3 × 3 patterns which have 0 wastage are precisely the ones which are packing in live cells optimally, whereasthe ones with > 0 wastage precisely the ones which are suboptimal and should be avoided.Since the number of live cells and the wastage is inversely related, we can reformulate the objective function in theMaximum Density Still Life Problem as follows. For each cell c, let P (c) be the 3 × 3 pattern around that cell. Note that if cis on the edge of the n × n region, the dead cells beyond the edge are also included in this pattern. Let q(P ) be the wastagefor each 3 × 3 pattern as listed in Tables 1 and 3. Define w(c) for each cell c as follows. If c is within the n × n region, thenw(c) = q(P (c)). If c is in the row immediately beyond the n × n region and shares an edge with it (there are 4n such cells),then w(c) = 1 if the cell in the n × n region with which it shares an edge is dead, and w(c) = 0 otherwise. For all other c,let w(c) = 0. Let W =w(c) over all cells.(cid:6)Theorem 2. Wastage and live cells are related bylive_cells = n22+ n − W4(1)Proof. We adapt the proof for the infinite board to a finite n × n region. Let us assign 2 tokens to each cell within the n × nregion, 1 token to each of the 4n cell in the row immediately beyond the edge of the n × n region, and 0 tokens to allcells beyond. In the first redistribution phase, for each dead cell within the n × n region, we redistribute its token amongits live orthogonal neighbors exactly as we did before. For each dead cell in the row immediately beyond the n × n region,we redistribute its 1 token to the cell in the n × n region with which it shares an edge if it is a live cell and do nothingotherwise.Once again, the still life constraints force the last two 3 × 3 patterns listed in Table 3 to occur in unique pairs. Note thatit is impossible for them to exist on the boundary so that one is in the n × n region and the other not, as that violates thestill life constraints. In the second phase of the redistribution, for each live cell at the center of the second last pattern, wetake 1 of the 2 original tokens it had and redistribute it to the live cell at the bottom middle of the pattern, which must bethe center live cell of a last pattern.After this, all live cells have (cid:3) 4 tokens. The undistributed tokens of a dead cell in the n × n region is exactly given bythe wastage count shown in Table 1. The excess tokens (above 4) of a live cell in the n × n region is exactly given by theG. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–165wastage count shown in Table 3. The undistributed tokens of a dead cell in the row just beyond the n × n region is 1 ifthe cell in the n × n region with which it shares an edge is dead, and 0 otherwise. As can be seen, these wastage numberscorrespond exactly with w(c) as defined above. Now, 4 times the number of live cells will be equal to the total number oftokens minus the total wastage. Hence we end up with Eq. (1). (cid:2)We can trivially derive some upper bounds on the number of live cells using this equation. Clearly W (cid:3) 0 and, thus, wehave: live cells (cid:2) (cid:5) n2+ n(cid:6). Also, by the still life constraints, there cannot be three consecutive live cells along the edge of2the n × n region. Hence, there is always at least 1 wastage per 3 cells along the edge and we can improve the bound to: livecells (cid:2) (cid:5) n23 n(cid:6)(cid:6). While this bound is very close to the optimal value for small n, it differs from the true optimum2by O (n) and will diverge from the optimum for large n.+ n − (cid:5) 13. Solving small n with complete searchThe power of a branch and bound algorithm is hugely dependent on how strong a bound we can prove on the objectiveat each node in the search tree. The stronger the bound we can prove, the earlier we can prune off failed subtrees. Thenaive Still Life model based on counting the number of live cells is very weak, because the upper bound on the number oflive cells that propagation can prove is usually very weak and search generally does not fail until the board is at least halffilled.Remodeling the Still Life Problem in terms of minimizing wastage instead of maximizing live cells allows us to propagatemuch stronger bounds on the objective, as it is easy to tell how much space has already been wasted in the parts ofthe board that are labeled. Let sl_waste be a width 10 table which specifies the wastage value of each 3 × 3 patternsatisfying the still life constraints. For example, the entries corresponding to the first and second patterns in Table 3 wouldbe (0, 1, 0, 0, 1, 0, 0, 1, 0, 0) and (0, 1, 0, 0, 1, 0, 1, 0, 0, 1). A single table constraint using sl_waste will be sufficient toenforce the still life constraints and set the value of the wastage variable. We propose the following simple MiniZinc [12]model:int: n; % instance parameterarray [0..n+1,0..n+1] of var 0..1: x; % cell live/dead statusarray [0..n+1,0..n+1] of var 0..2: w; % cell wastagevar 0..2*n*n+4*n: total_wastage;var 0..n*n: live_cells;% still life and wastage constraints in n by n regionconstraint forall (i,j in 1..n) (table(sl_waste, [x[i-1,j-1], x[i,j-1], x[i+1,j-1], x[i-1,j],x[i,j], x[i+1,j], x[i-1,j+1], x[i,j+1], x[i+1,j+1], w[i,j]]));% boundary conditionsconstraint forall (i in 0..n+1) (x[i,0] = 0 /\ x[0,i] = 0 /\ x[i,n+1] = 0 /\ x[n+1,i] = 0);constraint forall (i in 1..n-2) (sum (j in i..i+2) (x[1,j]) <= 2 /\sum (j in i..i+2) (x[n,j]) <= 2 /\sum (j in i..i+2) (x[j,1]) <= 2 /\sum (j in i..i+2) (x[j,n]) <= 2);% wastage constraints for boundaryconstraint forall (i in 1..n) (w[i,0] = 1 - x[i,1]);constraint forall (i in 1..n) (w[0,i] = 1 - x[1,i]);constraint forall (i in 1..n) (w[i,n+1] = 1 - x[i,n]);constraint forall (i in 1..n) (w[n+1,i] = 1 - x[n,i]);% objective functionconstraint total_wastage = sum (i,j in 0..n+1) (w[i,j]);constraint live_cells = (2*n*n+4*n - total_wastage)/4;solve maximize live_cells;6G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–16Table 4Optimum number of live cells in the Maximum Density Still Life Problem found by complete search and the time in seconds to find and prove them.n21222324252627282930Opt.232253276302326353379407437467Time7.082.45.135.40.4116.398.948.876.6240.8n31323334353637383940Opt.497531563598633668706744782824Time121.386.954.22.0155.2165.1161.2193.0312.217.6n41424344454647484950Opt.864907949993103910851132118112291280Time89.225 696402.3103.3218.4403.2200.265.3456.9585.1This basic model is capable of counting the wastage in the labeled parts of the board and using it to enforce an upperbound on the number of live cells. However, it is also important to get a good lower bound on the wastage that must occurin the parts of the board which are not yet labeled. The simplest bound we can get is that there must be at least 1 wastageper 3 cells along any unlabeled edge. We can implement this by adding a few lines and modifying the constraint on totalwastage:% wastage per 3 edge cells along edge iarray [1..4,1..n/3] of var 1..3: ew;constraint forall (i in 1..n/3) (ew[1,i] = sum (j in 3*i-2..3*i) (w[0,j]) /\ew[2,i] = sum (j in 3*i-2..3*i) (w[j,0]) /\ew[3,i] = sum (j in 3*i-2..3*i) (w[n+1,j]) /\ew[4,i] = sum (j in 3*i-2..3*i) (w[j,n+1]));constraint total_wastage = sum (i,j in 1..n) (w[i,j]) +sum (i in 1..4, j in 1.. n/3) (ew[i,j]) +sum (i in n/3*3+1..n) (w[0,i] + w[i,0] + w[n+1,i] + w[i,n+1]);In this modified model, the wastage of groups of three consecutive edge cells are summed together into variablesew[i,j] before being added to the objective. Since each ew[i,j] variable has a lower bound of 1, this facilitates the“at least 1 wastage per 3 edge cells” lookahead rule. However, this model is still a bit too weak for the bigger instances, andwe use a more advanced lookahead based on relaxations. We defer detailed discussion of this to Section 4.The search strategy is also important. We use a labeling strategy where we label from the boundary of the board inwards.We first label the first 3 rows of each edge and each 8 × 8 corner. Thereafter, we label one row in at a time in concentricsquares. The reason for this labeling strategy will become much clearer in view of the insights discussed in Section 4.Basically, most wastage that is forced to occur by the constraints occurs along the boundary of the n × n region, and thuslabeling those cells first increases the bound on the objective the quickest, allowing us to detect suboptimal assignmentsearlier.Finally, we must note that a certain feature of the solver we used is critical for solving this problem effectively. Onemajor problem with any search strategy for the Still Life Problem is that it is possible to make a “mistake” in labeling thatmakes the subtree unsatisfiable, but propagation may not be able to notice this until many decision levels later. A normalconstraint programming solver will take an exponential amount of nodes to backtrack to this mistake and fix it. The solverwe use however, is the Lazy Clause Generation [6] solver Chuffed, which supports conflict analysis and backjumping. ThusChuffed can analyze conflicts and immediately backjump to the mistake and fix it without having to waste an exponentialamount of time searching in the failed subtree. If the conflict analysis is turned off so that Chuffed behaves as a normalCP solver, then the optimal solution cannot be found for any 21 < n (cid:2) 30 within a 1 hour timeout (we did not try larger nwhere this presumably continues to hold).In Table 4, we show the results for 21 (cid:2) n (cid:2) 50 (n (cid:2) 20 have previously been solved). Clearly, we are already able tosolve instances which are much larger than the previous state of the art methods. Optimal solutions for n = 21 and n = 22are shown in Fig. 1. We can solve instances somewhat larger than n = 50 using complete search, but the run time growsvery quickly. Instead, we use better methods to tackle larger n in the next few sections.4. Upper bounds for large nTo solve the problem for larger n, we need more mathematical insight into the problem. We make the followingconjecture:G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–167Fig. 1. Optimal solutions for n = 21 and n = 22.Conjecture 1. For sufficiently large n, all “forced” wastage occurring in an optimal solution is caused by the still life constraints withink rows from the edge of the n × n region, where k is some small, fixed constant. (cid:2)By “forced” wastage, we mean wastage that is unavoidable due to the constraints of the problem, as opposed to “un-forced” wastage that may occur simply because we picked a suboptimal labeling of the board. In the later sections of thispaper, we will prove experimentally that Conjecture 1 does indeed hold, but this requires solving the Still Life Problemfor all n. For now, we treat it as a conjecture. Conjecture 1 is inspired by the following two facts. Firstly, in the optimalsolutions for n (cid:2) 20 that were found by previous methods, it was often the case that wastage only appeared in the cornersor within the first 3 rows from the edge. Secondly, we already know that there exist wastage free labellings in the infinitecase, thus there is nothing inherent in the still life constraints which force wastage. Instead, it would appear that it is theboundary conditions in the finite case which is forcing the extra wastage to occur.If the conjecture holds, then it should be possible to relax the Still Life Problem onto just the boundary variables (vari-ables within k rows of the edge) and still derive the same wastage lower bound. This has the advantage that: (1) such arelaxed problem has far fewer variables (O (nk) instead of O (n2)) and thus a much smaller search space, (2) such a relaxedproblem has low pathwidth (O (k) instead of O (n)) and there exist various techniques that can take advantage of this toreduce the search space even further to O (n22k), e.g., caching, nogood learning, dynamic programming, variable elimination.It is well known that any lower bound we prove for the objective function in the relaxed problem is also a valid lowerbound for the original problem. However, this bound may or may not be the optimal bound for the original problem. Ifwe relaxed the problem too much, then the bound we derive from the relaxed problem will be weaker than the optimalbound for the original problem. Now, if Conjecture 1 holds, then there should exist some small k such that the bound fromrelaxing the problem onto a width k boundary should still be optimal for the original problem. We need to find this k.The complexity of solving the relaxation is O (n22k), so choosing k too large will make the problem intractable. Wewish to find the smallest k such that the relaxation is sufficient to prove the optimal bounds for the original problem. Weperformed a series of experiments to try to guess what this minimal k is. We define the edge still life problem edge(n, k)in MiniZinc as follows:int: n, k; % instance parametersarray [0..n+1,0..k+1] of var 0..1: x; % cell live/dead statusarray [1..n,0..k] of var 0..2: w; % cell wastage% still life and wastage constraints in n by k regionconstraint forall (i in 1..n, j in 1..k) (table(wastage, [x[i-1,j-1], x[i,j-1], x[i+1,j-1], x[i-1,j],x[i,j], x[i+1,j], x[i-1,j+1], x[i,j+1], x[i+1,j+1], w[i,j]]));% boundary conditionsconstraint forall (i in 0..n+1) (x[i,0] = 0);constraint forall (i in 1..n-2) ( sum (j in i..i+2)(x[1,j]) <= 2);% wastage constraints for boundaryconstraint forall (i in 1..n) (w[i,0] = 1 - x[i,1]);% objective functionsolve minimize sum (i in 1..n, j in 0..k) (w[i,j]);8G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–16Table 5Ratio of wastage to edge cells in an optimal edge for different edge width, and number of patterns that appear in the first three rows.k1–23–1112(cid:2) 13r(k) (exact)r(k) (decimal)CastlesBlocks1/34/117/1910/270.3330.3640.3680.37001231111Fig. 2. Optimal edge patterns for a width 2 and width 3 boundary relaxation. Wastage is highlighted with a star.Let m(n, k) be the minimum wastage for problem edge(n, k). For each k, we calculate the edge wastage ratio r(k) as:r(k) = limn→∞ m(n, k)/n. These limits exist and can be calculated using a combination of dynamic programming and math-ematical induction in a finite amount of time. This is because the optimal edge patterns all become periodic for sufficientlylarge n for any k. We discuss this in more detail below. See Table 5 for the values of r(k) and Fig. 2 for a sample of optimaledge patterns.First, we note that r(1) = r(2) = 1/3 = 0.333 gives us the trivial edge wastage bound discussed in Section 2. The optimaledge pattern for k = 2 is unique and periodic and is shown in Fig. 2(a). However, this optimal width 2 edge cannot beextended to a width 3 edge without introducing additional wastage. For a width 3 edge, r(3) = 4/11 = 0.364 and theoptimal edge pattern is once again unique and periodic and is shown in Fig. 2(b). We will refer to the pattern shown in thefirst 8 columns of Fig. 2(b) the “castle” pattern and the next 3 columns of Fig. 2(b) the “block” pattern. The castle patternhas length 8 with 3 wastage and the block pattern has length 3 with 1 wastage. As k increases, r(k) continues to increaseslightly. At k = 13, we have r(13) = 10/27 = 0.370. The optimal edge is no longer unique or periodic, however, all of themare identical within the first 3 rows up to translational symmetry, and are composed of three castle patterns followed by ablock pattern, which gives 3 ∗ 3 + 1 = 10 wastage per 3 ∗ 8 + 3 = 27 cells. All of the optimal edge patterns only have wastagein the row beyond the edge, which is an interesting fact to note. Beyond, k = 13, the value of r(k) plateaus, and we stoppedour experimentation at k = 20. We show later in Section 7 that there exist arbitrarily thick edge patterns which achieveexactly an edge wastage ratio of r(13) = 10/27. So in fact, r(k) = 10/27 for all k (cid:3) 13.What the edge wastage ratio results show is that the still life constraints up to a depth of 13 are capable of forcingwastage to occur. We should not relax these constraints away, as that will degrade the bound that we can prove using therelaxed problem. Thus we need to look at an edge relaxation of at least width 13. However, the fact that r(k) plateaus afterk = 13 also suggests that width 13 is sufficient, i.e. the still life constraints beyond a depth of 13 can have no effect onforcing edge wastage, and we can relax them away without changing the bound. This turns out to be correct, as our resultslater show.5. Solving the boundary relaxationWe wish to solve a relaxed form of the Still Life Problem where we only consider a width 13 boundary. The techniquewe choose to use is bounded dynamic programming [10]. We discuss the choice of this technique and show how it can beapplied. First of all, it is necessary to choose one of the methods that can exploit the low pathwidth of the relaxed problem.Of these, dynamic programming is by far the easiest to implement. However, we use a variant of dynamic programmingcalled bounded dynamic programming [10]. For some kinds of dynamic programs, instead of calculating the exact value forevery subproblem, it is actually sufficient to prove a bound on the value of many of the subproblems.Example 1. Consider the recursion:(cid:7)a(n − 1) + 1, b(n − 1) + 2a(n) = min(cid:7)a(n − 1) + 3, b(n − 1) + 1b(n) = min(cid:8)(cid:8)Suppose we want to calculate the value of a(n). Suppose we have already calculated that a(n − 1) = 6. Now, we need tofind some information on b(n − 1). However, we note that one of the terms in the min: a(n − 1) + 1 = 7, is already known,therefore if it is known that b(n − 1) (cid:3) 5, then its exact value is irrelevant as far as the value of a(n) is concerned. We onlywant to know: is b(n − 1) (cid:3) 5, or if it is < 5, then what is its exact value? Thus we only wish to answer a bounded queryon the value of b(n − 1), where we do not care what its exact value is if it is above or below a certain range.On certain types of problems, bounded dynamic programming can be exponentially faster than normal dynamic pro-gramming, as there are a lot of subproblems whose exact values are irrelevant and all we need to do is to prove a certainG. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–169bound on their value. Proving a weak bound is often exponentially faster than finding the exact value. In the case of the StillLife Problem, there are many, many ways to label the cells, and most of them lead to large amounts of wastage. Therefore,we often just need to prove that a subproblem is sufficiently bad (has at least a certain amount of wastage), rather thancalculate exactly how bad it is. Bounded dynamic programming is a rigorous way to do this.We illustrate how dynamic programming can be applied with a simplified example. Consider a more constrained versionof edge(n, k) where we have additional boundary conditions which fix the first 2 and last 2 columns. We denote thisproblem by edge(n, k, s1, s2, e1, e2) where the model has the additional lines:% instance parametersint: s1, s2, e1, e2;% additional boundary conditionsconstraint s1 = sum (i in 0..k-1) (x[1,i] * 2^i);constraint s2 = sum (i in 0..k-1) (x[2,i] * 2^i);constraint e1 = sum (i in 0..k-1) (x[n,i] * 2^i);constraint e2 = sum (i in 0..k-1) (x[n-1,i] * 2^i);As can be seen, we are denoting the value of a column of k cells by a single number in {0, . . . , 2k − 1}, where thevalue of the cells are being interpreted as the binary digits of this number. We define the Boolean function s(a, b, c) wherea, b, c ∈ {0, . . . , 2k − 1} as true if three consecutive columns labeled as a, b, and c in that order do not violate the still lifeconstraints, and false otherwise. We define the integer function w(a, b, c) where a, b, c ∈ {0, . . . , 2k − 1} as the wastage inthe central column b if three consecutive columns are labeled as a, b, and c in that order.Let m(n, k, s1, s2, e1, e2) be the minimum wastage for problem edge(n, k, s1, s2, e1, e2). Then the following recursive for-mulas hold: ∀n (cid:3) 3, s1, s2, e1, e2 ∈ {0, . . . , 2k − 1},(cid:7)m(n − 1, k, s1, s2, e2, e3) + w(e1, e2, e3)m(n, k, s1, s2, e1, e2) = min(cid:7)(cid:9)(cid:9) e3 ∈0, . . . , 2k − 1(cid:8)(cid:8), s(e1, e2, e3).Let’s consider why. Firstly, consider any solution of edge(n, k, s1, s2, e1, e2). We must have fixed the (n − 3)th column tosomething. Let it be denoted by e3. To satisfy the still life constraints, we must have s(e1, e2, e3) be true. For each suchsolution, w(e1, e2, e3) gives us the wastage in the n − 2th column. If we project this solution onto the first n − 1 columns,then we clearly have a solution for edge(n − 1, k, s1, s2, e2, e3). Hence the minimum wastage among all such solutions ism(n − 1, k, s1, s2, e2, e3) + w(e1, e2, e3). Taking the minimum of these over all possible e3 gives m(n, k, s1, s2, e1, e2), andhence the recursive formula.Such a set of recursive formulas can be solved using dynamic programming in O (n). We can use precalculated values ofm(n, k, s1, s2, e1, e2) as a wastage lookahead in the complete search method described in Section 3. Given a partially fillededge where the last two columns are given by s1 and s2, we can look up mini, j m(n, k, s1, s2, i, j) to get a lower bound onthe wastage in the remaining cells of the edge. This will give a bound of approximately 10/27 wastage per remaining edgecell instead of the trivial 1/3 wastage per remaining edge cell we had before. Although the difference is small, it is quitecrucial for solving the larger n with complete search.Now, it turns out that for any k, for sufficiently large n, the values of m(n, k, s1, s2, e1, e2) become periodic. This isformalized by the following theorem.Theorem 3. If for some constants M, p, q, we have: ∀s1, s2, e1, e2, m(M + p, k, s1, s2, e1, e2) = m(M, k, s1, s2, e1, e2) + q, then∀n (cid:3) M, ∀s1, s2, e1, e2, m(n + p, k, s1, s2, e1, e2) = m(n, k, s1, s2, e1, e2) + q. That is, once n (cid:3) M, the values of m simply increase byq every p cells.Proof. The proof is by induction. The base case of n = M is true by assumption. Suppose it is true for n = t. Considern = t + 1. We have:m(t + 1 + p, k, s1, s2, e1, e2)(cid:7)m(t + p, k, s1, s2, e2, e3) + w(e1, e2, e3)(cid:7)m(t, k, s1, s2, e2, e3) + w(e1, e2, e3)= min= q + min= q + m(t + 1, k, s1, s2, e1, e2)(cid:2)(cid:9)(cid:9) e3 ∈(cid:9)(cid:9) e3 ∈(cid:7)(cid:7)0, . . . , 2k − 1(cid:8)0, . . . , 2k − 1(cid:8)(cid:8), s(e1, e2, e3)(cid:8), s(e1, e2, e3)Theorem 3 tells us that if we ever reach an n where the m values become periodic, then it remains periodic forall larger n. This always happens due to the translational symmetry in the Still Life Problem. For k = 13, the valuestypically become periodic by the time we reach n = 200. Once this happens, we can derive closed form equations form(n, k, s1, s2, e1, e2) for all larger n. Thus, we can calculate the values of m(n, k, s1, s2, e1, e2) for all n using a constantnumber of mathematical operations.10G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–16Fig. 3. Boundary relaxation for calculating wastage lower bounds.Table 6Lower bounds on wastage and corresponding upper bounds on live cells as calculated by bounded dynamic programming on a problem relaxation. Instanceswhere the bound on the relaxed problem differed from the original problem are indicated with an asterisk.n2021222324252627282930313233Waste lb.Live ub.4036424340464448514853555356210232253276∗302326∗353379∗407437466497530563n3435363738394041424344454647Waste lb.Live ub.5659626064676468687173727678598632668706∗744782824864907949993103910851132n4849505152535455565758596061Waste lb.Live ub.768080808584878988919292979611811229128013311382143614901545160216581717177618351897We now describe the full relaxed problem which we use to derive our bounds. We begin with the basic model describedin Section 3. We relax the problem in two steps. In the first step, we eliminate the depth 14+ cells to leave a width 13boundary. That is, for each x[i, j] where 13 < i, j (cid:2) n − 13, we eliminate x[i, j] from the problem by existentially quantifyingit in every constraint in which it appears. Existential quantification of a variable in a constraint weakens the constraint, sothis is a valid relaxation. In the second step, we cut a “slit” in this width 13 boundary in order to reduce the pathwidthfurther. The “slit” goes from the 1st to 13th columns between the 13th and 14th row. For each constraint c which includesvariables from both sides of the slit, i.e., both variables with i (cid:2) 13 and variables with i (cid:3) 14, 1 (cid:2) j (cid:2) 13, we create twocopies of c. In one copy, we existentially quantify all variables below the slit. In the other, we existentially quantify allvariables above the slit. Once again, this is a valid relaxation. The resulting relaxed problem is shown graphically in Fig. 3.The reason for the first part of the relaxation is to get rid of the variables and constraints which we conjecture areirrelevant for forcing the lower bound. The reason for the second part of the relaxation is to lower the pathwidth so thatthe problem becomes tractable. Recall that the complexity of solving a problem with pathwidth w is O (2w ). Without the“slit”, the pathwidth of the relaxed problem is around 5 ∗ 13 = 65, which is too high to be solved. With the slit, this dropsto around 3 ∗ 13 = 39, which is solvable.Once these relaxation are performed, we can simplify the objective function of the resulting relaxed problem. Considerw[i, j] where 14 < i, j (cid:2) n − 14. These variables occur in exactly one table constraint (involving the 3 × 3 pattern centeredat that coordinate), and as a positive term in the objective function. For such w[i, j] variables, since all 9 of the x[i, j]variables in the corresponding table constraint has been existentially quantified, w[i, j] is free to take any value allowed bythe table constraint. In particular, in any optimal solution, it would be set to its lower bound of 0. Thus we can simplifythe objective function of the relaxed problem by removing all such w[i, j] terms. Similarly, if two out of three columns ofthe x[i, j] in a 3 × 3 pattern are existentially quantified, then w[i, j] can always be set to 0. So we can also remove x[i, j]where i = 14 or n − 13 and 14 < j (cid:2) n − 14, or where j = 14 or n − 13 and 14 < i (cid:2) n − 14. The resulting problem is of thesame form as the simplified problem we showed above (except it has corners and multiple edges). It is easy to see that thesame kind of recursive formulation into a dynamic program is possible. Thus the relaxed problem can be completely solvedfor all n using bounded dynamic programming very efficiently.Table 6 shows the wastage lower bounds and the corresponding live cell upper bounds we derive for 21 (cid:2) n (cid:2) 56. Wenote several things. Firstly, all the bounds calculated by bounded dynamic programming on the relaxed problem are con-G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–1611wastage (cid:2)⎧⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎩(cid:5)40/27 ∗ n + 5(cid:6), n ≡ 5, 13, 21, 24, 32, 35, 40, 43, 48, 51(cid:5)40/27 ∗ n + 6(cid:6), n ≡ 0, 2, 7, 8, 10, 14, 15, 16, 18, 22, 23, 26,mod 54(cid:5)40/27 ∗ n + 7(cid:6), n ≡ 1, 3, 4, 9, 11, 12, 17, 19, 20, 25, 27, 28,29, 30, 34, 37, 38, 42, 45, 46, 50, 53mod 54(cid:5)40/27 ∗ n + 8(cid:6), n ≡ 6, 3331, 36, 39, 41, 44, 47, 49, 52mod 54mod 54Fig. 4. Closed form equations for the wastage lower bound for n (cid:2) 61.⎧⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎩livecells (cid:3)(cid:5)n2/2 + 17/27 ∗ n − 2(cid:6) n ≡ 0, 1, 3, 8, 9, 11, 16, 17, 19, 25, 27,31, 33, 39, 41, 47, 49mod 54(cid:5)n2/2 + 17/27 ∗ n − 1(cid:6) n ≡ 2, 4, 5, 6, 7, 10, 12, 13, 14, 15, 18,20, 21, 22, 23, 24, 26, 28, 29, 30,32, 34, 35, 36, 37, 38, 40, 42, 43,44, 45, 46, 48, 50, 51, 52, 53mod 54Fig. 5. Closed form equations for the live cell upper bound for n (cid:2) 61.Fig. 6. The two best ways to fill a corner (up to symmetry). Wastage is highlighted with a star. Note that there are two units of wastage in the cell in the4th column and 4th row in the second pattern.sistent with the optimal live cell values calculated by complete search in Section 3. Secondly, the bounds on the relaxedproblem are often the optimal bounds for the original problem (the only exceptions being n = 24, 26, 28, 38). This is consis-tent with Conjecture 1, which stated that for sufficiently large n, the relaxed problem should have the same bound as theoriginal. It would appear that the “sufficiently large n” in the conjecture is n > 38. Of course, to fully prove Conjecture 1,we must prove it for all n > 38. We do this in Section 7.For n (cid:3) 61, the wastage lower bounds becomes periodic and is given by the equations in Fig. 4. The corresponding livecell upper bound is given by the equations in Fig. 5. We shall see in the next two sections that these live cell upper boundsare in fact achievable, so the equations in Fig. 5 actually give us the optimal number of live cells for n (cid:3) 61.6. Lower bounds for large nLower bounds on live cells can be proved by finding actual solutions to the problem. If the number of live cells in thesolution found coincides with the upper bound proved in Section 5, then we know that it is an optimal solution and wehave solved the problem for that n. However, finding optimal solutions is very hard, because the default search space of theStill Life Problem is extremely large. The model given in Section 3 was good enough for us to solve up to around n = 50using complete search. However, to go beyond that size, we need something that reduces our search space much further.We make the following conjecture:Conjecture 2. For sufficiently large n, there always exist optimal solutions of the following form: wastage only exists at the four 4 × 4corners of the board, or in the one row beyond the edge of the board. (cid:2)Conjecture 2 is supported by the experiments described in Section 4. We reasoned that for sufficiently large n, the edgesshould follow one of the optimal edge patterns, and we know that none of them have any wastage other than in the onerow beyond the edge of the board. Similarly, there are only two ways to label a corner with minimum wastage (see Fig. 6)and both of them only have wastage within the 4 × 4 corners. And finally, the center of the board should be wastage free,because by Conjecture 1, the constraints in the center of the board do not force any wastage, and any wastage there wouldsimply make the solution suboptimal.Assuming that Conjecture 2 holds, we can look only for solutions of this special form. Note that searching only forsolutions of this special form gives an incomplete search on the Still Life Problem. However, incomplete search is perfectlysufficient for proving lower bounds on the number of live cells, since the solution itself is the proof. To solve for all n, wemust be able to find an optimal solution for every single n. We use two further techniques to reduce the search space:(1) dynamic relaxations as lookahead, and (2) a customized limited discrepancy search.In Section 4, we described how we can perform a relaxation onto the boundary of the board in order to derive a lowerbound on the wastage. We can do the same thing during search. Our search strategy is to label the board 8 rows at a time12G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–16Fig. 7. Dynamic relaxation lookahead for still life search.from top to bottom. Conjecture 1 tells us that for sufficiently large n, wastage is only forced by the boundary constraints.In a subproblem however, the boundary also includes the values of the cells we have labeled. If we relax the subproblemonto the boundary of the unlabeled region, we should be able to derive a very strong lower bound on the wastage in theunlabeled region of the board. Thus, at each search node, we relax the remaining problem onto: the unlabeled parts of thewidth 13 boundary, and the 8 unlabeled rows below the last row we labeled (see Fig. 7).We note several things. Firstly, the set of variables involved in the relaxation is different at each search depth. Secondly,the boundary conditions of the relaxation are different even for two nodes at the same search depth if their cells in the lasttwo rows are labeled differently. Thus each of these relaxed subproblems are different and have to be solved separately toderive the wastage lower bound. Now, as before, we can solve each of these in O (n) using dynamic programming. However,we can do better by noting that the relaxed problem at any node is very similar to the relaxed problem at its parent node,differing only by one column of 8 variables. By appropriately caching the solutions to the relaxed subproblem at the parentnode, we can solve the relaxed problem at each node in O (1). The cost is still non-trivial, however, the wastage lowerbounds derived by these relaxations are very strong and provide a large amount of pruning, so it is well worth it.One might wonder why we use a different search order than that described in Section 3, where we label the board fromoutside in rather than from top to bottom. This is because the relaxation lookahead already tells us how much wastage therehas to be in the unlabeled parts of the boundary, thus it is unnecessary to actually label it to force the wastage lower boundup. It is better not to label the boundary yet, as there are exponentially many ways to do it, but most of them are probablybad. It is better to fix the variables which are close to those variables already fixed so that we can detect inconsistenciesearlier, hence the top to bottom strategy.We also use the relaxation lookahead as a branching heuristic. When faced with the choice of labeling the next columnof 8 variables as any one of the 256 possible values, our relaxation lookahead is able to tell us how much the wastage lowerbound will increase by, given each of those choices. We order the choices according to how low the wastage lower boundgiven by the lookahead is. This is far superior to a naive, greedy branching heuristic which orders the choices based on thewastage in only the labeled part of the board, as it is often the case that greedily minimizing wastage locally will causemuch more wastage further on. Our lookahead is capable of seeing the wastage caused further on and will not pick suchlocally optimal but globally suboptimal choices.We use a modified version of limited discrepancy search [13]. Firstly, rather than defining a discrepancy as any choicewhich is not the first choice given by the branching heuristic, we define it as the amount that the wastage lower boundgiven by the relaxation lookahead would increase by if we made this decision. This means that there can be ties, i.e.multiple choices which are all equally good according to the lookahead. In such cases, we randomly tie-break betweenthem. Secondly, we add randomized restarts to the search. At randomized points in time, the search will backtrack by arandom number of rows. This is important, because despite our lookahead, there still exist vast subtrees where no optimalsolutions can be found, and a complete search will take an exponential number of nodes to backtrack out of them. Thecombination of random restarts, plus random tie-breaking between equally good choices, is very effective. Using thesetechniques, we are able to find optimal solutions to instances as large as n = 200 in several hours on average. An optimalsolution for n = 100 is shown in Fig. 8.7. Constructing optimal solutions for arbitrarily large nThrough our experimentation and analysis, it became clear that the Still Life Problem is actually fairly well behaved forsufficiently large n. We have the following properties: (1) the wastage lower bound is periodic in n, (2) there exist optimalperiodic edge patterns which achieve this wastage lower bound, (3) it is “easy” to fill in the center of the board without anywastage. Combining these facts together, it seems possible that with a bit of work, we can construct closed form optimalsolutions for arbitrarily large n.G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–1613Fig. 8. Optimal solution for n = 100.In Section 5, we already worked out wastage lower bounds for all n. If we can construct solutions that achieve thesewastage lower bounds for all n, then we are done. This can be done by solving instances of the Still Life Problem underadditional periodic constraints, so that parts of the solution can be tiled indefinitely to produce arbitrarily large optimalsolutions (see Fig. 9). The initial solution is broken up by two horizontal and two vertical cuts into: 4 corner pieces, 4 edgepieces, and 1 center piece. The edge pieces and center pieces must satisfy periodic constraints so that they can be tiled andstill satisfy the still life constraints. Furthermore, there are strong restrictions on the amount of wastage that can occur inthese tiled pieces. We know that for sufficiently large n, the wastage lower bounds from Section 4 has a wastage to edgecell ratio of exactly 10/27. Thus to hit this lower bound, our 4 periodic edge pieces must have precisely this wastage ratio.Also, the periodic center piece must be completely wastage free.Now, for the periodic edge pieces to have precisely a wastage to edge cell ratio of 10/27, their period must be a multipleof 27. Unfortunately, if the center piece is 27 × 27, then it is impossible for it to be wastage free, since it has an odd(cid:11)number of cells. Thus the minimum period we can use is 2 ∗ 27 = 54. The aim then is to solve an instance with n = nunder additional period 54 constraints and wastage constraints on the edge and center pieces. If an optimal solution can be(cid:11) + k ∗ 54 for any k ∈ N. Clearly, to solve for all n, this hasfound, then it can be tiled to create optimal solutions for n = nhad to be around 150 or higher before theto be done for each value of nStill Life Problem became sufficiently well behaved that the periodic version was solvable. So we had to solve 54 instancesof size 150+, one for each modulus class mod 54, under the additional periodic constraints and wastage constraints.mod 54, so there are 54 cases. We found that n(cid:11)(cid:11)Rather than directly solving such problems from scratch, we decided to utilize the solutions that we had already found,and try to extend them into periodic solutions by splicing in a periodic section. We first take an optimal solution for(cid:11) − 54. We cut it into two pieces vertically at some point. We then move the two pieces apart by 54 cells and try ton = nfill up the gap with a periodic 54 section which satisfies the additional wastage constraints. This periodic 54 section willend up being two of the periodic edge pieces. Secondly, we take this new solution and cut it horizontally at some point.We then move the two pieces apart by 54 cells and do the same again. This new section will end up being the other twoperiodic edge pieces plus the center piece. Now we end up with an optimal solution for n = nwhich satisfies the periodicconstraints and the wastage constraints. Here is a MiniZinc model for the first step. The second step is analogous.(cid:11)int: n; % instance parameter% four columns covering the splice point from sol of n = n’ - 54array [1..4,1..n] of 0..1: s;array [1..54,0..n+1] of var 0..1: x; % cell live/dead status% still life and wastage constraints in 54 by n region14G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–16Fig. 9. A periodic optimal solution where the center sections can be tiled indefinitely to produce optimal solutions for n = 100 + k ∗ 54.constraint forall (i in 2..53, j in 1..n) (table(sl_waste, [x[i-1,j-1], x[i,j-1], x[i+1,j-1], x[i-1,j],x[i,j], x[i+1,j], x[i-1,j+1], x[i,j+1], x[i+1,j+1], 0]));% boundary conditionsconstraint forall (i in 0..n+1) (x[i,0] = 0 /\ x[i,n+1] = 0);constraint forall (i in 1..52) (sum (j in i..i+2) (x[j,1]) <= 2 /\sum (j in i..i+2) (x[j,n]) <= 2);constraint forall (i in 1..n) (x[1,i] = s[3,i] /\ x[2,i] = s[4,i] /\x[n-1,i] = s[1,i] /\ x[n,i] = s[2,i]);% wastage constraints for boundaryconstraint sum (i in 1..54) (x[i,1]) = 34;constraint sum (i in 1..54) (x[i,n]) = 34;solve maximize satisfy;This splicing does not always succeed as the constraints are very, very strong. Whether it is satisfiable or not dependson the initial solution and the point at which we make the cut. In particular, the cuts must be made at a point whereboth edges have already transitioned into the optimal edge pattern of 3 castles per 1 block periodic pattern. If we couldnot solve a particular instance after a reasonable time, we tried a different cut point or tried it using a different solution of(cid:11) − 54. The success rate was around 80%, so most of them succeeded on the first try. After approximately 3000 hoursn = nof computation, we were able to find periodic solutions for all 54 cases, and thus the Still Life Problem was solved for alllarge n. The Still Life shown in Fig. 9 is one such periodic solution where the center sections can be tiled indefinitely toproduce optimal solutions for n = 100 + k ∗ 54.These results prove Conjecture 1, Conjecture 2, and closes off the Maximum Density Still Life Problem for all n. Werestate our results for clarity:G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–1615Table 7Maximum number of live cells in an n × n still life for n (cid:3) 60.n123456789101112131415Live cells0468161828364354647690104119n161718192021222324252627282930Live cells136152171190210232253276302326353379407437467n313233343536373839404142434445Live cells4975315635986336687067447828248649079499931039n464748495051525354555657585960Live cells108511321181122912801331138214361490154516021658171717761835Theorem 4. For n > 39, all “forced” wastage is caused by the still life constraints within 13 rows from the edge of the n × n region.Theorem 5. For n > 50, there always exist optimal solutions of the following form: wastage only exists at the four 4 × 4 corners of theboard, or in the one row beyond the edge of the board.Theorem 6. For n (cid:2) 60, the maximum number of live cells that can appear in an n × n still life is given in Table 7. For n (cid:3) 61, themaximum number of live cells that can appear in an n × n still life is given by:(cid:10)n2/2 + 17/27 ∗ n − 2(cid:10)n2/2 + 17/27 ∗ n − 1(cid:11)(cid:11)n ≡ 0, 1, 3, 8, 9, 11, 16, 17, 19, 25, 27,31, 33, 39, 41, 47, 49mod 54n ≡ 2, 4, 5, 6, 7, 10, 12, 13, 14, 15, 18,20, 21, 22, 23, 24, 26, 28, 29, 30,32, 34, 35, 36, 37, 38, 40, 42, 43,44, 45, 46, 48, 50, 51, 52, 53mod 548. ConclusionWe have solved the Maximum Density Still Life Problem for all n by combining mathematical insights into the prob-lem with appropriate applications of remodeling, lazy clause generation, bounded dynamic programming, relaxations, andcustom search. The complete solution consists of four parts: (1) complete search which can solve n (cid:2) 50, (2) bounded dy-namic programming with relaxation to prove optimal live cell upper bounds for n > 50, (3) incomplete search for specialform solutions which can prove optimal live cell lower bounds for 50 < n (cid:2) 200, (4) incomplete search to find optimalperiodic solutions which can be tiled to construct arbitrarily large solutions that prove the optimal live cell lower boundsfor n > 200. The optimal values for all n are given in Theorem 6. Optimal solutions for small and medium n and periodicoptimal solutions for large n can be found at www.csse.unimelb.edu.au/~pjs/still-life/. The total time takento completely solve the Maximum Density Still Life Problem for all n was approximately 3000 hours.AcknowledgementsNICTA is funded by the Australian Government as represented by the Department of Broadband, Communications andthe Digital Economy and the Australian Research Council through the ICT Centre of Excellence program.References[1] G. Chu, P. Stuckey, M. Garcia de la Banda, Using relaxations maximum density still life, in: I. Gent (Ed.), Proceedings of the 15th International Confer-ence on Principles and Practice of Constraint Programming, in: LNCS, vol. 5732, Springer-Verlag, 2009, pp. 258–273.[2] R. Bosch, Integer programming and Conway’s game of life, SIAM Review 41 (3) (1999) 596–604.[3] R. Bosch, M. Trick, Constraint programming and hybrid formulations for three life designs, Annals OR 130 (1–4) (2004) 41–56.[4] J. Larrosa, R. Dechter, Boosting search with variable elimination in constraint optimization and constraint satisfaction problems, Constraints 8 (3) (2003)303–326.[5] J. Larrosa, E. Morancho, D. Niso, On the practical use of variable elimination in constraint optimization problems: ‘Still-life’ as a case study, Journal ofArtificial Intelligence Research 23 (2005) 421–440.[6] O. Ohrimenko, P. Stuckey, M. Codish, Propagation via lazy clause generation, Constraints 14 (3) (2009) 357–391.[7] B.M. Smith, Caching search states in permutation problems, in: P. van Beek (Ed.), Proceedings of the 11th International Conference on Principles andPractice of Constraint Programming, in: Lecture Notes in Computer Science, vol. 3709, Springer, 2005, pp. 637–651.16G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–16[8] T. Feydy, P.J. Stuckey, Lazy clause generation reengineered, in: I.P. Gent (Ed.), Proceedings of the 15th International Conference on Principles andPractice of Constraint Programming, in: Lecture Notes in Computer Science, vol. 5732, Springer, 2009, pp. 352–366.[9] R. Bellman, Dynamic Programming, Princeton University Press, 1957.[10] J. Puchinger, P. Stuckey, Automating branch-and-bound for dynamic programs, in: R. Glück, O. de Moor (Eds.), Proceedings of the ACM SIGPLAN 2008Workshop on Partial Evaluation and Program Manipulation (PEPM ’08), ACM, 2008, pp. 81–89.[11] N. Elkies, The still-life density problem and its generalizations, Voronoi’s Impact on Modern Science: Book I (1998) 228–253, arXiv:math/9905194v1.[12] N. Nethercote, P. Stuckey, R. Becket, S. Brand, G. Duck, G. Tack, Minizinc: Towards a standard CP modelling language, in: C. Bessiere (Ed.), Proceedingsof the 13th International Conference on Principles and Practice of Constraint Programming, in: LNCS, vol. 4741, Springer-Verlag, 2007, pp. 529–543.[13] W.D. Harvey, M.L. Ginsberg, Limited discrepancy search, in: Proceedings of the 14th International Joint Conference on Artificial Intelligence, MorganKaufmann, 1995, pp. 607–615.