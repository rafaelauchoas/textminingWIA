Artificial Intelligence 174 (2010) 20–50Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSolving coalitional resource gamesPaul E. Dunne b, Sarit Kraus a,c,∗, Efrat Manisterski a, Michael Wooldridge ba Department of Computer Science, Bar-Ilan University, Ramat Gan, 52900, Israelb Department of Computer Science, University of Liverpool, Liverpool L69 7ZF, UKc Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20742, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 10 April 2008Received in revised form 18 September2009Accepted 22 September 2009Available online 25 September 2009Keywords:Coalitional gamesNTU gamesSolution conceptsThe coreBargainingAlgorithmsComplexity1. IntroductionCoalitional Resource Games (crgs) are a form of Non-Transferable Utility (ntu) game, whichprovide a natural formal framework for modelling scenarios in which agents must poolscarce resources in order to achieve mutually satisfying sets of goals. Although a numberof computational questions surrounding crgs have been studied, there has to date beenno attempt to develop solution concepts for crgs, or techniques for constructing solutions.In this paper, we rectify this omission. Following a review of the crg framework and adiscussion of related work, we formalise notions of coalition structures and the core forcrgs, and investigate the complexity of questions such as determining nonemptiness of thecore. We show that, while such questions are in general computationally hard, it is possibleto check the stability of a coalition structure in time exponential in the number of goalsin the system, but polynomial in the number of agents and resources. As a consequence,checking stability is feasible for systems with small or bounded numbers of goals. Wethen consider constructive approaches to generating coalition structures. We present anegotiation protocol for crgs, give an associated negotiation strategy, and prove that thisstrategy forms a subgame perfect equilibrium. We then show that coalition structuresproduced by the protocol satisfy several desirable properties: Pareto optimality, dummyplayer, and pseudo-symmetry.© 2009 Elsevier B.V. All rights reserved.There is currently much interest in the possibility of delegating complex tasks to semi-autonomous software agents[34,37]. A highly desirable requirement for such domains is that the agents should be able to reach agreements with one-another on matters of common interest. For example, in order to accomplish the goals that they have been delegated, agentsmay need to share a scarce resource, work together to achieve a common goal, or come to a common understanding abouta disputed domain of discourse. This requirement has motivated work in automated negotiation [22,28], online auctions [11]and computational social choice theory [15].In this paper, our interest lies in domains with the following characteristics:We desire some goal to be achieved, and delegate the goal to an agent, along with some bundle of resources, which may be expendedby the agent in order to accomplish the goal. Accomplishing the goal may require resources not possessed by the agent, promptingthe need for cooperation. A group of agents will thus pool resources to accomplish a set of goals to the satisfaction of all contributors.Our primary aim is for the agent to satisfy our goal, and to this end, if it is necessary to expend all the resources we endow it with,* Corresponding author.E-mail addresses: ped@csc.liv.ac.uk (P.E. Dunne), sarit@macs.biu.ac.il (S. Kraus), mjw@csc.liv.ac.uk (M. Wooldridge).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.09.005P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5021then this is acceptable. However, if there are multiple ways of satisfying the goal, we desire that the agent should minimize resourceusage.The formal model we use to capture such scenarios is a refinement of the Coalitional Resource Games (crgs) framework,which was introduced in [39]. In a crg, each agent has a set of goals, and is endowed with some quantity of resources;each goal requires a specified quantity of each resource in order to accomplish it. The main change to the basic crg modelthat we make here is to introduce the idea of preferring outcomes that minimize resource consumption. To capture thesepreferences, we introduce costs: the cost to an agent of a particular scenario is simply the sum of the resource quantities itcontributes in this scenario.Many important real world scenarios seem to fit within this model. Consider agents that support arranging carpoolschemes.1The idea in a carpool scheme is to encourage people who live and work close to each other to share cars to and from work, ratherthan each driving their own car. We model car pooling in our framework as follows. A possible goal of an agent is arrangingtransportation for all necessary days and times. An agent may have more than one possible goal when the transportation can beon different possible days (e.g., a worker might visit the main office on either Monday or Wednesday). The resources are places incars for specific days, origin, destination, and time. An agent would prefer that another agent provides a ride, if possible, even if heis available on that day and has the car, since this will save his resources.One characteristic of our domains is that utility is non-transferable. In cooperative games with transferable utility, thevalue of a coalition is simply a real number, corresponding to payoff that can be divided amongst coalition members in anyway they see fit [25, p. 257]. In such games, utility is transferable because it can be transferred between coalition members.Most existing work in multi-agent negotiation and resource allocation assumes transferable utility [22,28]. The rationalefor our choice is that there are domains in which utility is non transferable, which is why non-transferable utility games(ntu games) have been studied in the literature [25, p. 268]. As an example with respect to our domain, when scientistscollaborate on a joint paper, the resources they contribute include their experience and expertise. Such resources are noteasy to value or trade explicitly, and the utility that one scientist gets from publishing a paper cannot usually be transferredto those that he or she cooperated with. (We elaborate on this issue in more detail in Section 3.)We emphasise that the scenarios we consider typically require cooperation: it is not in general the case that an agentcan achieve its goals in isolation, and will need to cooperate with others in order to do so. The possible outcomes of thesecooperative games are structures in which coalitions commit to achieve certain goals, and in which members of a coalitioneach commit to contribute some part of their resource endowment. Presented with a number of different possible outcomes,we want an agent to choose one that achieves its delegated goal while minimizing the cost to itself (i.e., minimizes thequantity of resources that it contributes). Given that we are in the realm of cooperative games, a number of issues thussuggest themselves for consideration [29]: Which coalitions will form? And how will these coalitions choose an outcomefrom those that are available to them, given the different preferences that agents have over outcomes?With respect to the former question, we formalise the core for our domain, and investigate the complexity of severalquestions surrounding the core. We show that it is co-np-complete to check whether a particular outcome is in the coreof a game, while it is co-np-hard to check whether the core is non-empty, or to check whether the core is non-emptyand contains a non-trivial outcome. However, as we will see, the core may be empty even with quite strong constraints ongames, and this motivates us to consider other types of outcomes.Our second contribution is to consider a constructive, bargaining-based approach to coalition structure generation.We present a negotiation protocol for the domain, and investigate its properties. Using backward induction, we derivestrategies that are in subgame perfect equilibrium, and prove that outcomes generated will, on average, satisfy three de-sirable properties: pseudo-symmetry, dummy player, and Pareto optimality. Although n-agent bargaining for ntu gameshas been considered in the game theory literature [16], there has been little work on this in computer science/ai (seee.g., [7]).A comment on notation and proofs. The remainder of the paper makes use of much notation, and for the reader’s conve-nience, we summarise the main notations used in Appendix A. In addition, in the interests of readability, we omit all longerproofs from the main text, presenting them instead in Appendix B.1 This is not a frivolous example: car pooling is a major activity, heavily promoted by some national governments as a means of reducing road traffic(and hence pollution, etc.). See, for example:http://www.carpoolworld.com/.Carpools have already been the subject of study using coalitional games, although from a somewhat different (more abstract) perspective than the presentpaper [24].22P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–502. Background and related workIf we are to build computer programs that can cooperate with each other, then it is natural to ask what models havebeen previously developed to model cooperative scenarios. Game theory is a valuable source of models for multi-agentsystems in general, and cooperative game theory in particular studies cooperation, addressing itself to such problems as whowill cooperate with who (i.e., which coalitions will form), and how such coalitions will share the benefits of cooperation.Within cooperative game theory, perhaps the simplest, best-known, and most widely studied model of cooperative gamesis the coalitional game with transferable utility [25, p. 257]. Such a game is a structure (cid:3)Ag, ν(cid:4) with Ag being a set of players,and ν : 2Ag → R being the characteristic function of the game, which assigns a real valued utility, or payoff, to every possiblecoalition. The intuition is that ν(C) is the value that coalition C could earn, should they choose to cooperate with one-another. Notice that how a characteristic function is obtained or defined for any given scenario is not considered: suchconcerns are not considered at this abstract level of modelling. Given such structures, cooperative game theory attempts toanswer such questions as which coalitions might be formed by rational agents, and how the payoff received by a coalitionmight be “reasonably” divided between the members of that coalition. With respect to the former question, concepts suchas imputations, the core, stable sets, the kernel, and the nucleolus have been formulated [25]. These concepts representprogressively richer attempts to formalise when a coalition is stable (in the sense that there would be no incentive for arational agent to do other than remain a member of the coalition).A number of authors have taken ideas from cooperative game theory and attempted to apply them in multiagent systems.Sandholm et al. identify three key issues that have been addressed [29, pp. 210–211]:• Coalition structure generation: The partitioning of a group of agents into coalitions, where the overall partition is acoalition structure.• Solving the optimization problem of each coalition: Solving the “joint problem” of a coalition, i.e., finding the best way tomaximize the utility of the coalition itself.• Dividing the value of the solution for each coalition: Deciding “who gets what” in the final payoff of the game. With respectto this issue, concepts such as the Shapley value [25, p. 289] have been developed, which attempt to answer thequestion of how much an agent should receive based on an analysis of how much that agent contributes to a coalition.With respect to coalition formation, the main approach considered in both the coalitional game literature and the multi-agent systems literature is to consider the core [25, p. 257]. The core of a coalitional game is the set of possible outcomes(i.e., distributions of coalitional value to members of a coalition) to which no sub-coalition could possibly object, in thesense of being able to obtain an outcome for themselves that was strictly preferred by all sub-coalition members. The factthat the core is non-empty is a necessary (but not sufficient) condition for coalition formation: if the core is empty, thenthe coalition will not form because some coalition has an incentive to work on their own.With respect to distributing coalitional value, the Shapley value provides the best-known solution [25, p. 291]. The Shapleyvalue states that an agent should get the average amount that it contributes to coalitions, considering all possible coalitions,which may be formed in any possible order. The Shapley value is particularly compelling because it is the unique solutionto a set of axioms that characterise “fair” distributions of payoff to members of a coalition.If we are interested in computational applications of coalitional games, it is of course important to know how hard it isto compute solution concepts such as the core and Shapley value. Since these problems involve quantifying over coalitions,it appears at first sight that they must be computationally very costly. However, this in fact depends upon the representationused for the game in the input to the decision problem. The naive representation of a coalitional game (explicitly listing thevalue of every coalition) is of size exponential in the number of agents, and, for example, checking core non-emptiness canbe done in time polynomial in the size of this representation. However, it is generally accepted that such a representationis not of practical interest, and so much effort has been focussed around the complexity of computing solution concepts forcompact or succinct representations of games.A number of compact representations have been investigated. Deng and Papadimitriou, in perhaps the first detailed studyof the complexity of cooperative games, considered a representation based on weighted graphs [12]. The idea was to havea graph (cid:3)Ag, E ⊆ Ag × Ag(cid:4) with weights w i, j for every edge (i, j) ∈ E in the graph. To compute the value ν(C) of a coalitionin such a representation, we simply take the sum of weights of all edges in the graph induced by coalition C :(cid:2)ν(C) =w i, j.(i, j)∈E & {i, j}⊆CThe representation is compact because we only need to represent O (|Ag|2) weights w i, j in the input. However, checkingcore non-emptiness is np-complete with such a representation, although computing the Shapley value can be done inpolynomial time.Other succinct representations for coalitional games have been considered in the literature. For example, Ieong andShoham developed marginal contribution nets, a rule-based formalism for representing coalitional games [20], which gener-alises the induced sub-graph representation of Deng and Papadimitriou. They showed that while computing some solutionconcepts (e.g., the core) was hard with this representation, others — notably the Shapley value — were computationallyP.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5023easy. Conitzer and Sandholm considered the complexity of computing solutions based on a representation of superadditivegames [9]. Elkind et al., building on results of Deng and Papadimitriou, investigated the complexity of solution conceptsin weighted voting games [14]: here, computing the Shapley value is hard, while checking core-non-emptiness is easy.Bachrach and Rosenschein considered several other models for coalitional games, and the complexity of solution conceptson these games [2,3].Another approach to coalition formation that has received much attention in the literature is that of forming coalitionstructures so as to maximize the social welfare of the system, that is, maximizing the sum of the values of the individualcoalitions. Formally, given a coalitional game (cid:3)Ag, ν(cid:4), the optimal coalition structure CSis given as follows:∗∗ = argCSmaxCS∈ partitions of AgV (CS)whereV (CS) =(cid:2)C∈CSν(C).is computa-There will of course be exponentially many possible coalition structures, and so the problem of finding CS(i.e., partitions oftionally complex. Sandholm and colleagues developed algorithms to find optimal coalition structures CSagents) with worst case guarantees (that is, within some given ratio bound k of optimal) [29]. They showed that finding theoptimal coalition structure is np-hard [29, pp. 224–225]. They were able to show that for a ratio bound k = a (where a isthe number of agents) their algorithm required searching 2a−1 nodes, and that in a precise sense, this is the best that couldbe expected of such an algorithm. They also went on to establish how more extensive search might be used to lower thebound k. In earlier work, Shehory and Kraus developed algorithms for coalition structure formation in which agents weremodelled as having different capabilities, and were assumed to benevolently desire some overall task to be accomplished,where this task had some complex (plan-like) structure [31–33].∗∗In coalitional games with transferable utility, the payoff or utility obtained by a coalition may be arbitrarily dividedbetween coalition members. Thus side payments are possible between agents, which facilitates some outcomes that wouldnot otherwise be feasible (see, e.g., [13]). However, such transferable utility is not a realistic assumption in many domains,and coalitional games with non-transferable utility (more commonly referred to simply as ntu games), model such scenarios.Formally, an ntu game can be understood as a structure (cid:3)Ag, Ω, (cid:8)1, . . . , (cid:8)n, ν(cid:4) where Ag is a set of players, Ω is a set ofoutcomes, (cid:8)i⊆ Ω × Ω is a binary preference relation over Ω for player i ∈ Ag, and ν : 2Ag → 2Ω is the characteristic functionof the game, with the intended interpretation that ν(C) are all the outcomes that C ⊆ Ag could cooperate to achieve. ntugames generalise coalitional games with transferable utility: we can understand ν(C) as being the set of distributions ofpayoff that C can obtain to members of C .While the core has the same interpretation in ntu games as in tu games, it is less obvious how the Shapley valuemight be interpreted for ntu games. Hart and Mas-Colell propose a negotiation protocol for ntu games, and show that theprotocol leads to outcomes which closely correspond to the Shapley value in the transferable utility case [16].2 However,several quite significant restrictions are placed on the ntu games considered in [16]: in particular, the set of outcomes isinfinite and continuous. It is not clear how these solutions might be applied to finite, discrete ntu games. Vidal-Puga reportsimilar work, giving a similar bargaining protocol which leads to outcomes that correspond to the Owen value, an analogueof the Shapley value [36]. Bloch and Diamantoudi present a bargaining protocol for a class of ntu games called hedonicgames [5]. In a hedonic game, we do not start with a characteristic function, but simply a preference ordering, one for everyagent, over every coalition; in other words, an agent wants to join a coalition “for the pleasure of their company” (whencethe term “hedonic”). They show that under certain circumstances, using this protocol leads to outcomes in the core of thegame.Two closely related types of ntu game were introduced specifically to model goal-oriented multi-agent domains, i.e.,domains in which agents have goals to achieve. In a qualitative coalitional game (qcg), every agent has some set of goals,and desires to accomplish at least one of these, but is indifferent between its goals [38]. Each coalition is assumed tohave a set of choices, each choice representing a set of goals that would be accomplished were the coalition to make thecorresponding choice; coalitions then form to achieve mutually satisfying sets of goals. Such games are termed “qualitative”because there is no numeric measure of utility in such games: agents are simply satisfied or not. Coalitional resource games(crgs), the model underpinning the work of the present paper, were introduced in [39]. The idea in crgs was to considersituations in which the choices available to a coalition derive from the resources available to the coalition: each agent isendowed with a collection of resources, and different goals require different amounts of each resource to achieve them.Note that as considered in [39], crgs retain the qualitative nature of qcgs: an agent’s aim is simply to ensure that one ifits goals is achieved. The present paper is motivated in part by one obvious aspect of resource-based situations that wasnot considered in [39]: namely, the very obvious desire to minimize resource usage. While resource bounds were consideredin [39], no consideration was given to preferring solutions that minimize resource usage. So, while we base our work on themodel of crgs presented in [39], this model is extended with a natural notion of preference, to capture this very natural2 The Hart and Mas-Colell protocol was influential in determining the bargaining protocol of the present paper. Although there are several differences, asfollows. Once the order of agents is chosen, our protocol is deterministic; in addition we allow the agents to give counter offers.24P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50requirement. By introducing preferences, we also allow for solution concepts that could not be framed in the setting of [39]:for example, the notion of stability as embodied in the core.3. Coalitional Resource Games (CRGs)crgs contain a non-empty, finite set Ag = {a1, . . . , an} of agents. A coalition, typically denoted by C , is simply a set ofagents, i.e., a subset of Ag. The grand coalition is the set of all agents, Ag. Each agent i ∈ Ag is assumed to have associatedwith it a (finite) set G i of goals, drawn from a set of overall possible goals G. The intended interpretation is that themembers of G i represent all the different ways that agent i’s goals might be satisfied. That is, agent i would be happy ifany member of G i were achieved — but we are not concerned with preferences over individual goals. Thus, at this levelof modelling, i is indifferent among the members of G i : it will be satisfied if at least one member of G i is achieved, andunsatisfied otherwise. Note that cases where more than one of an agent’s goals are satisfied are not an issue — an agent’saim will simply be to ensure that at least one of its goals is achieved, and there is no sense of an agent i attempting tosatisfy as many members of G i as possible.In order to bring about their goals, agents must expend resources. We assume a (fixed, finite, non-empty) set of resources,R, and assume that each agent is endowed with a (possibly zero) natural number quantity of each resource. We denote theamount of resource r ∈ R that agent i ∈ Ag is endowed with by en(i, r), thus en(i, r) ∈ N. Different goals may requiredifferent quantities of each resource for their achievement. We denote the amount of resource r required to achieve goal gby req(g, r); again, we assume that req(g, r) ∈ N.Collecting these components together, we get coalitional resource games (crgs). A crg Γ is an (n + 5)-tuple:Γ = (cid:3)Ag, G, R, G 1, . . . , Gn, en, req(cid:4)where:• Ag = {a1, . . . , an} is a set of agents;• G = {g1, . . . , gm} is a set of possible goals;• R = {r1, . . . , rt} is a set of resources;• for each i ∈ Ag, G i ⊆ G is a set of goals, the intended interpretation being that any of the goals in G i would satisfy i —• en : Ag × R → N is an endowment function, with the intended interpretation that if en(i, r) = k, then agent i ∈ Ag isbut i is indifferent between the members of G i ;endowed with quantity k ∈ N of resource r ∈ R; and• req : G × R → N is a requirement function, with the intended interpretation that if req(g, r) = k, then to achieve goalg ∈ G, it is necessary to expend quantity k ∈ N of resource r ∈ R.We will assume that no goal in G is “trivially” attainable, i.e., every goal requires a non-zero expenditure of at least oneresource. This assumption seems reasonable, since goals requiring no resources can be eliminated without altering thestrategic structure of a game (since every agent can achieve such a goal, then these goals have no effect on the formationor otherwise of specific coalitions). Formally, we assume that∀g ∈ G, ∃r ∈ R such that req(g, r) > 0.We extend the endowment function en to coalitions via the function en : 2Ag × R → N.en(C, r) =(cid:2)en(i, r).i∈CSimilarly, we extend the req function to sets of goals via the function req : 2G × R → N.req(G(cid:11), r) =(cid:2)req(g, r).g∈G(cid:11)(cid:11)) to denote the total cost of resources that are required to satisfy the set ofWith a little abuse of notation, we use req(Ggoals G:(cid:11)req(G(cid:11)) =A set of goals G(cid:11)(cid:2)r∈R(cid:11)req(G(cid:11), r).satisfies agent i if G(cid:11) ∩ G i (cid:13)= ∅; we say that G(cid:11)satisfies coalition C ⊆ Ag if it satisfies every member of C .(cid:11)A set of goals Gis feasible for coalition C if that coalition is endowed with sufficient resources to achieve all the goals(cid:11). Notice that monotonically increasing coalitions have monotonically increasing feasible goal sets. That is, if C ⊆ C,. In the terminology of [38], crgs are thus inherently coalition monotonic.is feasible for C then Gis feasible for Cin Gthen if G(cid:11)(cid:11)(cid:11)We define a function sf : 2Ag → 2G to return the set of goal sets that both satisfy and are feasible for a given coalition.sf (C) = {G(cid:11) ⊆ G: G(cid:11)is feasible for and satisfies C}.P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5025Table 1Endowments, feasible goal sets, and satisfying feasible goal sets for coalitions in Example 1.en(C x, r1)en(C x, r2)f eas(C x)sf (C x)C000∅∅C120∅∅C201∅∅C321{g2}∅C412∅∅C532{{g1}, {g2}}{g1}C613∅∅C733{{g1}, {g2}}∅We say a coalition C are successful if sf (C) (cid:13)= ∅: thus, if C are successful, then C are endowed with the resources to bringabout some goal set Gwill satisfy every member of C .such that G(cid:11)(cid:11)(cid:11)) the set of agents that would have their goals satisfied by G(cid:11):Given a set of goals G(cid:11)succ(G) = {i: i ∈ Ag & G, we denote by succ(G(cid:11) ∩ G i (cid:13)= ∅}.(cid:11)Consider the following example.Example 1. Consider the following crg, which we refer to as Γ1. We have three agents, Ag = {a1, a2, a3}, with two possiblegoals, G = {g1, g2}, and two resources R = {r1, r2}. The goal sets for each agent are as follows:G 1 = {g1}G 2 = {g2}G 3 = {g1, g2}.The endowment function en is defined as follows:en(a1, r1) = 2en(a2, r1) = 0en(a3, r1) = 1en(a1, r2) = 0en(a2, r2) = 1en(a3, r2) = 2.And the requirement function as follows:req(g1, r1) = 3req(g2, r1) = 2req(g1, r2) = 2req(g2, r2) = 1.There are eight possible coalitions in the game, as follows:C0 = ∅C4 = {a1}C1 = {a3}C5 = {a1, a3}C2 = {a2}C6 = {a1, a2}C3 = {a2, a3}C7 = {a1, a2, a3}.The endowments for these coalitions are summarised in Table 1, together with the feasible goal sets for each coalition, andthe goal sets that are both feasible for and satisfy each coalition.Thus far, our presentation of crgs has faithfully followed that of [39]. At this point, we will start to introduce some newconcepts and notations.3.1. Contribution vectorsThe first new concept we introduce captures the idea of an agent contributing a certain specified amount of each resourceto a coalition. Formally, a resource vector is an |R|-tuple of natural numbers, indexed by elements of R: a resource vectorwill indicate the amount of each resource contributed by a specific agent. If C ⊆ Ag, then we say a C -contribution vector is a|C|-tuple of resource vectors, with members indexed by elements of C ; each component of a C -contribution vector definesthe contribution of a specific member of C .We denote contribution vectors by ξ , ξ (cid:11), etc., and we write ξi to denote the member of ξ indexed by i, i.e., ξi is thevector defining agent i’s contribution to ξ . We let ξi,r denote the amount of resource r ∈ R contributed by agent i ∈ Agaccording to contribution vector ξ . We will not allow agents to contribute more of a resource than they are endowed with,and for this reason, we require that a contribution vector ξ for coalition C must satisfy the following natural feasibilityrequirement:∀i ∈ C, ∀r ∈ R: ξi,r (cid:2) en(i, r).Although we do not do so in this paper, it is of course possible to think of a contribution vector ξ as an |Ag| × |R| matrixof natural numbers, with the value ξ [i, r] being the amount of resource r contributed by agent i.Now, as stated earlier, one of the key aims of the present paper is to consider situations in which an agent has multipleoptions for achieving one of its goals, but these different options have different resource consumption requirements: theaim should be to minimize resource requirements. To capture the idea of resource consumption, we define the total cost ofa contribution vector ξ for agent i ∈ C to be the sum of its individual resource contributions. These costs will shortly be26P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50used to define preference relations, with the basic idea being that an agent prefers to minimize costs. This additive modelof costs is of course relatively simple, and other models of costs and preferences are possible, but it is an useful startingpoint for our analysis. Formally, we denote the cost to agent i ∈ Ag of contribution vector ξ by ci(ξ ):ci(ξ ) =(cid:2)ξi,r.r∈R3.2. Cooperation structuresCoalitional games with transferable utility model cooperation at a very high level of abstraction. In particular, they donot indicate what coalitions will do – they simply indicate the value that the coalition may earn. This information providesthe basis upon which the agent can make a decision about whether it is rational to work with one coalition or another.In crgs, the picture is a little more complex. When an agent is deciding whether to work within a coalition, it needs toknow what goals the coalition will work on, and what the expected resource contribution will be. Only then can it beginto consider how desirable this outcome is, and compare it to other possibilities. We thus introduce cooperation structures,which represent this information. Formally, a cooperation structure is a triple:λ = (cid:3)C, Gwhere C ⊆ Ag, Gthat the coalition is endowed with sufficient resources to achieve the goals it commits to:, ξ (cid:4)(cid:11) ⊆ G, and ξ is a C -contribution vector, such that these components must satisfy the feasibility constraint(cid:11)(cid:2)i∈C∀r ∈ R,ξi,r (cid:3) req(G(cid:11), r).The intended interpretation of a cooperation structure λ = (cid:3)C, G(cid:11), ξ (cid:4) is thus that C will cooperate to achieve goal set G(cid:11),and that each agent i ∈ C will contribute resources ξi towards this joint effort.If λ is a cooperation structure, then we denote by Cλ, Gλ, and ξλ the coalition, goal set, and contribution vector of λ,respectively. With a slight abuse of notation, we lift the cost function ci(· · ·) from contribution vectors to cooperationstructures, writing ci(λ) as shorthand for ci(ξλ). With another abuse of notation, let succ(λ) denote the set of agents thatwould have their goals satisfied by λ, so succ(λ) is a shorthand for succ(Gλ).3.3. PreferencesWe now define, for every agent i ∈ Ag, a preference relation (cid:8)i over cooperation structures containing i. This relationcaptures the idea that an agent’s primary objective is to satisfy one of its goals; its secondary aim is to minimize costs.Thus, an agent prefers all cooperation structures in which it has one of its goals achieved over all those in which it doesnot; within the set of cooperation structures in which it has a goal achieved, it prefers to minimize its costs; and similarlyfor the set of cooperation structures in which it does not get any goal achieved.Formally, for all cooperation structures λ1, λ2 containing agent i, we define (cid:8)i so that λ1 (cid:8)i λ2 iff one of the followingconditions is satisfied:1. i /∈ succ(λ1) and i /∈ succ(λ2) and ci(λ1) < ci(λ2).2. i ∈ succ(λ1) and i /∈ succ(λ2).3. i ∈ succ(λ1) and i ∈ succ(λ2) and ci(λ1) < ci(λ2).The non-strict preference relation (cid:15)i then has the obvious interpretation.Now, cooperation structures are superadditive, in the sense that they can be “merged” with no loss of utility to anyof the participants. To make this idea precise, we define a disjoint union operator on cooperation structures, as follows.Suppose cooperation structures λ1 = (cid:3)C1, G 1, ξ 1(cid:4) and λ2 = (cid:3)C2, G 2, ξ 2(cid:4) are such that C1 ∩ C2 = ∅ (i.e., they have no agentsin common). Then we denote by λ1 (cid:16) λ2 the cooperation structure λ3 = (cid:3)C3, G 3, ξ 3(cid:4) whereby:• C3 = C1 ∪ C2;• G 3 = G 1 ∪ G 2;• for all k ∈ {1, 2}, ∀i ∈ Ck, ∀r ∈ R: ξ 3i,r= ξ ki,r .The disjoint union operator (cid:16) on cooperation structures then has the following property:Proposition 1. Let λ1 and λ2 be cooperation structures from some crg Γ , containing disjoint sets of agents, and let λ3 = λ1 (cid:16) λ2.Then for all k ∈ {1, 2}, ∀i ∈ Ck, λ3 (cid:15)i λk.Proof. Suppose not. Then either (i) some agent i had its goal achieved in the respective component cooperation structure(either λ1 or λ2) but not in λ3 – but this cannot be the case by construction; or else (ii) some agent i ∈ Cλ3 contributes morein λ3 than it did in the respective component cooperation structure – which again cannot be the case by construction. (cid:2)P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5027It is convenient to define preference relations in another way, based on a model of utility. The idea is that the preferencerelations induced by these utility functions will correspond to the preference relations as defined above. It is important tounderstand that we view utility simply as a numeric way of capturing preferences — and in particular, the fact that we haveutility does not mean that utility is transferable. Defining the preference relation via numeric utilities makes it possible forus to use numeric optimization techniques — in particular, integer linear programs — to compute solutions associated withpreferences. However, utility here is solely a convenient numerical representation of preference; it does not form a “commoncurrency” with which agents can compensate each other, and individual utility values cannot be compared between agents.We return to this point below.To define the utility functions ui(· · ·) for each agent i, we proceed as follows. First, we define V to be the maximalpossible cost needed for satisfying one goal for each agent:(cid:3)V =(cid:2)i∈Ag(cid:2)r∈Rmaxg∈G i(cid:4)req(g, r).Then, for λ = (cid:3)C, G(cid:11), ξ (cid:4), we define the functions ui(· · ·) as follows:(cid:5)ui(λ) =V − ci(λ)−ci(λ)if i ∈ succ(λ)otherwise.Now, given a coalitional resource game Γ and cooperation structures λ1, λ2, suppose we defined λ1 (cid:15)i λ2 iff ui(λ1) (cid:3) ui(λ2),with the strict preference relation (cid:8)i defined in the obvious way. It should be immediately clear from construction that thepreference relations defined in this way directly correspond to the preference relations as defined earlier.Given that we have just introduced a model of utility, it is natural to ask whether in fact our setting can be viewed as atu game. The answer is no. To see why, consider the following scenario. We have:Ag = {a1, a2}G = {g1, g2}R = {r1, r2}G 1 = {g1}req(g1, r1) = req(g2, r1) = 1req(g1, r2) = req(g2, r2) = 0en(a1, r1) = 1en(a1, r2) = 0G 2 = {g2}en(a2, r1) = 0 anden(a2, r2) = 1000.Notice that resource r2 plays no part in whether or not either agent’s goal can be achieved. Now, there is only one way foragent a1 to achieve its goal: he must use his total resource endowment in order to achieve g1. However, if this happens,then a2 must be unsatisfied; the only way agent a2 can be satisfied is for agent a1 to contribute his entire endowment tothe achievement of g2 — which of course would leave a1 unsatisfied. But this latter situation would be the worst outcomefrom the point of view of agent a1. Recall that what an agent values above everything else is the achievement of his goal:every outcome that achieves his goal is preferred over every outcome where he does not. In this scenario, there is no side-payment possible to a1 that could induce him to transfer his endowment of r1 to a2, because the only way a1 can achievehis goal is by using his endowment to this end, and achieving his goal is what matters the most to agent a1. Resources andresource consumption are a secondary concern: goal achievement is the primary concern.We can express this example informally, and perhaps somewhat morbidly, by the following rather tongue-in-cheek sce-nario. Suppose you and I are in a plane that is about to crash. You have a parachute, but unfortunately I do not. We eachhave a goal of staying alive, but if you give up your parachute to me — thereby allowing me to achieve my goal of stayingalive — then you will be unable to achieve your goal of staying alive. Is utility transferable here? Surely not: there is noutility I could transfer to you that would compensate you for not being able to achieve your goal!3.4. Coalition structuresRecall from Section 2 that in coalitional games with transferable payoff, a coalition structure is simply a partition of allthe agents in the system. Intuitively, each element in the partition represents a set of agents who will work together. Inthis highly abstract setting, there is thus no indication of what each coalition will actually do, or how they will cooperate.The coalition structure generation problem for such domains involves finding a partition that maximizes the sum of allindividual coalition values. In our domain, coalition structures are somewhat more complex. They are not simply partitionsof the agent population: they must indicate what goals each coalition will work to achieve, and what resources each memberof the coalition will contribute. Thus, for our domain, a coalition structure, σ , is a set of cooperation structuresσ = {λ1, . . . , λk}28P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50such that {Cλ1 , . . . , Cλk} is a partition of Ag. If σ is a coalition structure then we denote by λσ ,i the cooperation structure inσ of which i is a member. We let σ0 denote the “null” coalition structure, in which the grand coalition does nothing, andno agent makes any contribution.Intuitively, then, a coalition structure is the outcome of a crg. It specifies, for every agent in the game, what coalitionthat agent belongs to, what that agent will contribute to its coalition, and what goals will be achieved by the coalition. Ofcourse, not all coalition structures will be equal: an agent may prefer one over another. This leads us to consider the notionof stability.4. Stable coalition structures: The coreAs we discussed in Section 2, the core is perhaps the best-known and most widely studied solution concept in coalitionalgames [25, p. 258]. The core is the set of outcomes of a game, feasible for the grand coalition, such that no coalition couldachieve an outcome that they all strictly prefer. In this way, the core captures the key idea of coalitional stability: if thecore is non-empty, then this means there is no rational incentive for any sub-coalition to defect. Note that the core in thesetting of crgs must be formulated with respect to coalition structures: an agent needs to know what goals are expected tobe achieved and what it is expected to contribute in order to be able to make a judgement about the value of a coalitionstructure.Formally, a cooperation structure λ is said to block a coalition structure σ if∀i ∈ Cλ: λ (cid:8)i λσ ,i.A coalition structure σ is stable if it is not blocked by any cooperation structure. The core of a crg is its set of stablecoalition structures.Let us establish some properties of stable coalition structures.Proposition 2. The core is closed under disjoint union. More precisely, if σ is in the core and {λ1, λ2} ⊆ σ (λ1 (cid:13)= λ2), then the coalitionstructure {λ1 (cid:16) λ2} ∪ (σ \ {λ1, λ2}) is in the core.Proof. Suppose σ = {λ1, λ2, λ3, . . . , λk} is in the core. Let σ ∗ = {λ1 (cid:16) λ2, λ3, . . . , λk}, and suppose that σ ∗is blocked bysome cooperation structure λ. But then λ would also block σ , since from Proposition 1, for every agent i ∈ C , the coalitionstructure σ ∗isexactly as good as σ . This cannot be the case, however, since σ is in the core. Hence no such λ exists, and hence σ ∗is inthe core as required. (cid:2)is at least as good (and possibly better) than σ , and for every agent i ∈ Ag \ C , the coalition structure σ ∗Proposition 3. Suppose σ = {λ1, . . . , λk} is in the core of Γ . Then the core of Γ contains a coalition structure σ ∗grand coalition cooperation structure, i.e., such that σ ∗ = {λ∗} and Cλ∗ = Ag.containing a single,Proof. From Proposition 2: take a coalition structure in the core, and simply keep taking the disjoint union of cooperationstructures until we obtain a grand coalition cooperation structure. (cid:2)Notice that by this proposition, when we are looking for stable coalition structures, we can restrict our attention tolooking at cooperation structures containing the grand coalition.We will say a stable coalition structure is atomic if none of its component cooperation structures can be decomposed(w.r.t. disjoint union), such that the resulting coalition structure is stable. Formally, let σ = {λ1, . . . , λk} be a coalitionstructure in the core of some crg Γ . Then we say σ is atomic iff for all 1 (cid:2) i (cid:2) k, it is not the case that there exist disjoint,} ∪ (σ \ {λi}) is in the core. The following is now(cid:16) λ2non-empty cooperation structures λ1immediate:i such that λi = λ1i and {λ1i , λ2i , λ2iiProposition 4. If the core of Γ is non-empty, then the core contains an atomic coalition structure.Proposition 5. Unsatisfied agents incur no cost in any stable coalition structure. More formally, if coalition structure σ is stable, andi ∈ Ag is such that i /∈ succ(λσ ,i), then ci(λσ ,i) = 0.Proof. Agent i can always choose the singleton cooperation structure in which it contributes nothing and achieves no goals:such a cooperation structure would block any coalition structure in which i was unsatisfied but incurred some cost. (cid:2)Proposition 6. Suppose coalition structure σ is in the core, and let C be the set of agents that are unsatisfied in σ . Then for all Csf (C(cid:11)) = ∅.(cid:11) ⊆ C ,Proof. Suppose not: then ∃Cwhere ξ represents the entire endowment of every member of Cachieved even if it cost them their entire endowment rather than not get their goals achieved at all. (cid:2), would block σ , since C(cid:11)) (cid:13)= ∅. So suppose G(cid:11) ⊆ C such that sf (C(cid:11)). Then the cooperation structure (cid:3)C(cid:11), ξ (cid:4),would prefer to get their goals(cid:11) ∈ sf (C(cid:11), G(cid:11)(cid:11)P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5029Proposition 7. The following statements are equivalent:1. No coalition is successful in Γ .2. The core of Γ contains a coalition structure in which no agent expends any resources and no agent is satisfied.Proof.• (1) ⇒ (2): Suppose that (1) but not (2). Then the core contains a cooperation structure in which either (i) some agentsexpend some resources or (ii) some agent is satisfied. For case (i), it follows from (1), that at least one of the agentsexpending some resource must have its goal unsatisfied; but then this contradicts Proposition 5. For case (ii), supposesome agent – call it i – is satisfied. Note that i alone cannot achieve its goal, from (1), so some other agents, call themC , must contribute resources which lead to the achievement of one of i’s goal. Some member of C must be unsatisfied,otherwise C ∪ {i} would be a successful coalition, which they cannot be from (1). Again from Proposition 5 we have acontradiction.• (2) ⇒ (1): Follows immediately from Proposition 6. (cid:2)A obvious question is whether there are natural conditions on crgs that would ensure that the core is always non-empty;of these conditions, perhaps the most obvious is that of requiring agents to have at most one goal. But even in this case thecore can be empty, as the following example illustrates.Example 2. Consider the following crg. We have four agents, Ag = {a1, a2, a3, a4}, with four possible goals, G ={g1, g2, g3, g4}, and three resources R = {r1, r2, r3}. The goal sets for each agent are as follows.G 1 = {g1}G 2 = {g2}G 3 = {g3}G 4 = {g4}.The requirement function req is as defined in the following table:req(· · ·)g1g2g3g4r14444r20110r31002The endowment function en is as defined in the following table:en(· · ·)a1a2a3a4r18884r21002r30110We consider whether any possible coalition could be in the core:1. σ0 is not in the core, since no agent would have goals achieved by this coalition structure; and yet there are successfulcoalitions, which would block σ0, since they would rather have their goals achieved than otherwise.2. The grand coalition, and coalitions {a1, a4}, {a1, a2, a3}, {a1, a2, a4}, {a1, a3, a4}, {a2, a3}, {a2, a4}, {a3, a4}, {a1}, {a2}, {a3},and {a4} are unsuccessful. This is because, for each of these coalitions, there exists some resource such that the totalamount of this resource required to satisfy the goals of all coalition members is larger than the total endowment of thisresource.3. Consider coalition {a1, a2}. In order to satisfy both agents’ goals, 8 units of the resource r1 are required. Therefore oneof these agents must contribute at least 4 units of resource r1. Given this we consider the two following cases:(a) Agent a1 contributes at least 4 units of resource r1. In this case the coalition can be blocked by the cooperationstructure (cid:3){a1, a3}, {g1, g3}, ξ (cid:4), where the values of the contribution vector ξ (that are different from 0) are: ξ1,2 = 1,ξ3,1 = 8, ξ3,3 = 1. This is because the cost to a1 is smaller and a3 is satisfied.(b) Agent a2 contributes at least 4 units of resource r1. The coalition can be blocked by the cooperation structure(cid:3){a2, a3, a4}, {g2, g3, g4}, ξ (cid:4), where the values of the contribution vector ξ (that are different from 0) are: ξ2,3 = 1,ξ3,1 = 8, ξ3,3 = 1, ξ4,2 = 2 and ξ4,1 = 4. This is because the cost to a2 is smaller and a3 and a4 are satisfied.4. Coalition {a1, a3} is not stable from similar considerations to the ones we specified for coalition {a1, a2} (notice thatagents a2 and a3 are symmetric, in the sense that they have goals which would require the same amount of eachresource in order to satisfy them, and they have identical endowments).5. Consider coalition {a2, a3, a4}. In order to satisfy all agents goals, 12 units of resource r1 are required. As agent a4 hasonly 4 units of resource r1, a2 or a3 must contribute at least 4 units of resource r1. Given this we consider the twofollowing cases:30P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50(a) Agent a2 contributes at least 4 units of resource r1. In this case the coalition can be blocked by the cooperationstructure (cid:3){a1, a2}, {g1, g2}, ξ (cid:4), where the values of the contribution vector ξ (that are different from 0) are: ξ1,1 = 8,ξ1,2 = 1, ξ2,3 = 1. This is because the cost to a2 is smaller and a1 is satisfied.(b) Agent a3 contributes at least 4 units of resource r1. In this case the coalition can be blocked by the cooperationstructure (cid:3){a1, a3}, {g1, g3}, ξ (cid:4), where the values of the contribution vector ξ (that are different from 0) are: ξ1,1 = 8,ξ1,2 = 1, ξ3,3 = 1. This is because the cost to a3 is smaller and a1 is satisfied.Thus no coalition structure is stable, and so the core is empty.4.1. Complexity of stability checkingIt is natural to ask how hard it is to check whether a given coalition structure is in the core, or more generally, whetherthe core is non-empty. We have the following results:Proposition 8. Given a crg Γ and coalition structure σ over Γ , the problem of checking whether σ is in the core of Γ is co-np-complete.Proof. We work with the complement of the problem, i.e., the problem of checking, for any Γ and σ , whether σ isunstable. For membership of np, simply guess a cooperation structure λ and check that λ blocks σ : the size of λ is clearlyonly polynomial in the size of Γ , and verifying that λ blocks σ can easily be done in polynomial time. For np hardness,we reduce the problem of checking whether the grand coalition in a given crg is successful. This problem, named grandcoalition success, was proved to be np-complete in [39]. LetΓ = (cid:3)Ag, G, R, G 1, . . . , Gn, en, req(cid:4)∗(g, r) = req(g, r), and for each new resource ri , we fix reqbe the input instance of this problem. We create an instance Γ ∗, σ ∗= G i .∗contains all members of R, and in addition, for each agent i ∈ Ag, we create a resource ri . For each goal g ∈ G, andR∗(g, ri) = 1. Then for all r ∈ R, we fixresource r ∈ R, we fix req∗(i, r) = en(i, r), while for all new resources ri , we fix en(i, r j) = |G| if i = j and 0 otherwise. Notice that this constructionenhas the property that (i) the only coalition in Γ ∗which can be successful is the grand coalition; (ii) the grand coalitioncan succeed in Γ ∗contains the grand coalition cooperationstructure in which no goals are achieved, and no agent incurs any cost. The only cooperation structures that would beare those in which every agent is successful. We conclude that the grand coalition is successful in Γ iff σ ∗block σ ∗is notis successful iff the grand coalition is successful in Γ ∗in the core iff some coalition in Γ ∗iff they can succeed in Γ . Finally, we define σ ∗ = {σ0}, i.e., σ ∗as follows. First we set Ag∗ = G, and G∗ = Ag, G. (cid:2)∗iNow, consider the more general problem of checking, for any given Γ , whether the core of Γ is non-empty. This amountsto checking the following property:∃σ ∗: σ ∗is in the core of Γi.e., checking whether:∃σ ∗: ∀C ⊆ Ag, ∀λC :(cid:6) (cid:7)(cid:8)(λσ ∗,i (cid:15)i λC ).i∈CWe can prove:Proposition 9. Checking whether the core of a crg is non-empty is np-hard.Proof. See Appendix B. (cid:2)Now, simply knowing that the core is non-empty may in fact not be very useful, for the following reason. Suppose nocoalition is successful; that is, there is no set of agents that could pool their resources to achieve a mutually satisfactory setof goals. Proposition 7 tells us that in such cases, the core will contain a cooperation structure in which the grand coalitiondo nothing: i.e., they achieve no goals and expend no resources. In other words, the fact that the core is non-empty doesnot mean it contains “meaningful” coalition structures; it could be that it contains “empty” coalition structures. In regularcoalitional games, such a situation would occur if no coalition could obtain non-zero utility; this is not generally consideredas an outcome. So, let us say that the core is strongly non-empty if it is non-empty, and does not contain the trivial coalitionstructure σ0. Similarly, we say the core of a game is weak if it contains σ0. With respect to these notions, first notice thatthe reduction employed in the proof of Proposition 8 immediately gives us the following:Proposition 10. Checking whether the core of a crg is weak is co-np-complete.P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50311. If ∃i /∈ succ(λσ ,i ) such that ci (λσ ,i ) > 0 return {(cid:3){i}, ∅, ξ0(cid:4)}.2. For each G2.1. Set C2.2. Check whether there exists a preferred contribution vector ξ for C and G(cid:11)) & (i /∈ succ(λσ ,i ) or ci (λσ ,i ) > 0)}.(cid:11)(cid:11) = {i: i ∈ succ(Gin 2G :(cid:3)C(cid:11), G3. Return “σ is stable”.(cid:11), ξ (cid:4).(cid:11)given σ (Proposition 12), and if so, then returnFig. 1. Algorithm for finding a cooperation structure (if one exists) that blocks σ .If we get a “no” answer to this question. then there are two possibilities. Either the core is non-empty and does notcontain σ0, or else the core is empty. So, the question of whether or not the core is strongly non-empty is distinct fromknowing whether the core is weak. We have the following:Proposition 11. Checking whether the core of a crg is strongly non-empty is np-hard.Proof. See Appendix B. (cid:2)4.2. Positive resultsHaving established a series of negative results, which imply that checking stability is going to be hard in general, itis obvious to ask whether there are any positive results relating to stability checking. We show that, given a coalitionstructure σ , it is possible to check whether σ is stable in time exponential in the number of goals, but polynomial in thenumber of agents and resources. Since in many real world situations, the number of goals is relatively small and may evenbe bounded by a constant, the actual complexity of determining whether a given coalition structure is in the core may inmany cases be considered polynomial in the size of the input.Our result is constructive, in that we present an algorithm for checking stability with the desired properties. The keystep in the algorithm is given by the following result. Suppose we are given a crg Γ , a coalition structure σ over Γ , a setin Γ : we are asked whether there is a feasible resource vector ξ such that theof agents C in Γ and a set of goals G(cid:11), ξ (cid:4) blocks σ ; if such a ξ exists, then we are asked to report it, otherwise we should announcecooperation structure (cid:3)C, G(cid:11), ξ (cid:4) to be a cooperation structure, it must be that ξ carries enough resources tothat no such ξ exists (notice that for (cid:3)C, Gachieve the goals G, and in addition, C must be endowed with sufficient of these resources). Let us call this problem thatof computing a preferred contribution vector. We have:(cid:11)(cid:11)Proposition 12. The problem of computing a preferred contribution vector can be solved in polynomial time.Proof. The proof is given in detail in Appendix B; here we give an overview. The idea is to build a flow network corre-sponding to the desired situation, such that if a maximum flow with certain properties exists in this flow network, thenwe can “read off” the contribution vector ξ from this flow network. A flow network can be understood as a directed graphwith a source node s and a sink node t; edges in the graph are associated with a capacity, indicating how much flow cantravel along the edge. The classic question associated with flow networks is to compute the maximum flow from source sto sink t. The overall structure of the construction is illustrated in Fig. 2: the capacity xi for edge (s, ai) for each agent i isthe maximum cost that agent ai could incur in a preferred cooperation structure and still prefer it over σ ; the capacity ξi, jon edge (ai, r j) for agent ai and resource r j indicates the endowment of agent ai with resource r j ; and the capacity yi onedges (ri, t) indicate the total amount of resource ri required for goal set G. We then ask whether there is an integer flowof at least y1 + y2 + · · · + yt . If the answer is yes, then the actual flow on edges (ai, ri) gives the preferred contributionvector.(cid:11)The size of the flow network is polynomial in the size of the inputs, and computing the maximum flow can be done intime polynomial in the size of the network (e.g., using the Edmonds–Karp version of the Ford–Fulkerson algorithm). (cid:2)Given an algorithm for computing a preferred contribution vector, the overall algorithm for checking whether a coalitionstructure σ is stable is given in Fig. 1. We can explain the algorithm as follows:• First, in line (1), we check to see whether any agent is left unsatisfied while incurring some cost: if so, then thisimmediately gives us a blocking structure by Proposition 5.• Line (2) tries to build a blocking cooperation structure. It does this by considering each possible set of goals Gin turn,achieved through some resource contribution.and trying to see whether there is some coalition C that would prefer GIf there is such a coalition, then it must contain either agents that incur some cost in both σ and G(who might benefitfrom reducing costs) or else agents that do not have their goal achieved in σ , but do get their goal achieved in G(whowould benefit from getting their goal achieved) — line (2a). At line (2b), we have a candidate goal set Gand a relevantcoalition C , so we check to see whether there exists a preferred contribution vector; if such a vector ξ exists, then wereturn it, otherwise, we continue to the next goal set.(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)32P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50• If we have considered all goal sets, then we indicate failure, i.e., that σ is stable.Fig. 2. Overall structure of the flow network construction for Proposition 12.Now, the key properties of the algorithm are stated in the following proposition.Proposition 13. The algorithm in Fig. 1 is correct: if it returns “σ is stable”, then σ is indeed stable, while if it returns a cooperation(cid:11), ξ (cid:4), then this cooperation structure blocks σ . Moreover, the algorithm terminates, and runs in time exponential in thestructure (cid:3)Cnumber of goals but polynomial in the number of agents and resources.(cid:11), GProof. See Appendix B. (cid:2)To illustrate the algorithm, consider the following example.Example 3. Consider the following crg. We have three agents, Ag = {a1, a2, a3}, with three possible goals, G = {g1, g2, g3},and four resources R = {r1, r2, r3, r4}. The goal sets for each agent are as follows:G 1 = {g1}G 2 = {g2, g1}G 3 = {g1, g3}.The requirement function req is defined as follows:req(· · ·)g1g2g3r1400r2302r31433r4030The endowment function en is defined as follows:en(· · ·)a1a2a3r1400r2330r30311r4003Consider σ = {(cid:3)Ag, {g1}, ξ (cid:4)} whereξ1,r1ξ2,r1ξ3,r1= 4= 0= 0ξ1,r2ξ2,r2ξ3,r2= 3= 0= 0ξ1,r3ξ2,r3ξ3,r3= 0= 3= 11ξ1,r4ξ2,r4ξ3,r4= 0= 0= 0.P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5033The set of the goals includes seven nonempty sets: {g1, g2, g3}, {g1, g2}, {g2, g3}, {g1, g3}, {g1}, {g2} and {g3}. The algorithm(cid:11) = {a2, a3} is the coalitionconsiders goal sets {g1, g2, g3} and {g1, g2} without succeeding, and then considers {g2, g3}. Cof agents that would have their goals satisfied by {g2, g3} and do not obtain their maximum utility from σ , and we check= 2,to see whether a preferred contribution vector exists; in this case it does, and the non-zero contributions are ξ2,r2= 3. The algorithm returns the cooperation structure (cid:3){a2, a3}, {g2, g3}, ξ (cid:4) and terminates. Note that weξ3,r3illustrate the construction of the preferred contribution vector for this example in the proof of Proposition 12.= 6 and ξ3,r35. Fair coalition structures through bargainingIn the previous section, we investigated one type of solution for crgs, in which the main concern was to check whethera particular coalition structure was stable against defections. This assumes that a particular coalition structure has beenfound, but of course does not address the issue of where such a structure comes from. In this section, we address theissue of the method by which a group of agents can find a coalition structure. Our approach is to present a negotiationprotocol for finding coalition structures. Although negotiation protocols have long been the object of study in multi-agentsystems research (see e.g., [22,28] for well-known examples), little research in computer science/ai has addressed n-agentntu bargaining (see Section 2).We are looking for a protocol such that it will be possible to compute in reasonable time the strategies that are inequilibrium and that the resulted coalitions will satisfy some desirable properties.5.1. A negotiation protocol for coalition formationWe now present and analyze a negotiation protocol by means of which the agents within a crg can agree upon acoalition structure to implement: the resulting coalition structure, while not necessarily maximizing overall social welfare,will nonetheless exhibit a number of desirable properties. The protocol is described in Algorithm 1:Algorithm 1 Negotiation protocol for crg bargaining.(cid:11)(cid:11)1, . . . , an(cid:4) of Ag.Choose an ordering (cid:3)a{Negotiation stage starts}t := 0repeat(cid:11), ξ (cid:4) with C = {a(cid:11)t , a(cid:11)(cid:11)t+1, . . . , an}accept := truet := t + 1;(cid:11)t proposes a cooperation structure, λt (t) = (cid:3)C, Ga:= tirepeatiif a:= i + 1(cid:11)i rejects λt (t) thenaccept := false(cid:11)t forms the singleton coalition {aaelse{aelse(cid:11)i makes a counteroffer}{a(cid:11)i proposes λt (i), a proposal that must satisfy{i.e., The proposal made by around t.}end if(cid:11)i accepts the offer} aa(cid:11)t} in the final coalition structure.(cid:11)i accepts the offer and λt (i) is set to λt (i − 1).(cid:9)i−1j=t(cid:11)i cannot decrease the utility that an agent a[u j (λt (i)) (cid:2) u j (λt ( j))](cid:11)j , preceding a(cid:11)i in the ordering obtains from its earlier proposal λ j (t) inuntil (not accept) or (i = n)until (t = n) or (accept)The coalition structure consists of λt (n) and the singleton cooperation structures for each a(cid:11)i , 0 (cid:3) i < t.The intuition behind this protocol is that it balances the power given to the proposers and the responders:• The responders can reject the offer, in which case the proposer gets nothing from negotiation. Thus, the proposer mustprovide them with “beneficial” offers — if it makes them a poor offer, they can reject it, forcing the proposer to leavenegotiation, and forego the benefits of cooperation.• However, the proposer has the power to choose which offer to make: between all of the beneficial offers that it couldmake, it can choose its most preferred one.This protocol is a modification of the protocol proposed by Hart and Mas-Colell [16]. The modifications were motivated bytwo goals. Our first goal was to design a deterministic protocol. This makes it easier to compute the equilibrium strategies.In Hart and Mas-Colell’s protocol if a proposal is rejected then with probability ρ the proposer continues to be active andcontinues to participate in the negotiation process and with probability 1 − ρ the proposer drops out of the negotiation and34P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50gets a final payoff of 0. In our protocol, the proposer of a rejected proposal always drops out of the negotiation. Furthermore,in the Hart and Mas-Colell protocol, the proposer is chosen at random out of the active set at the beginning of each roundof the negotiation, while in our protocol the order of the agents is determined before the beginning of the negotiation. Thus,once the order of agents is chosen, our protocol is deterministic.Our second goal was to direct the agents to a Pareto optimal solution. The Hart and Mas-Colell protocol directs theagents to almost Pareto optimal solutions, but with the changes above, even this weaker property was not true anymore.Thus, while in the Mas-Colell protocol the responder can either accept or reject the offer, in our protocol we allow theresponders to improve upon previous proposed cooperation structures, given that the other agents will not suffer from suchan improvement.There are, however, a number of questions to be dealt with in order to fully analyze the approach described in Algo-(cid:11)t determine the exact form of the cooperation structure, λt(t), that it willrithm 1. For example: How does the agent, a(cid:11)i (for i > t) determine their responses to the current proposal and the form thatpropose in round t? How do the agents acounterproposals, λt(i) should take? And so on. Recalling that each agent is seeking to realise one of its desired goals andmaximize its utility in the light of other agents having similar aims, we shall see that such issues can be considered byformulating a system of inequalities, solutions to which not only respect the constraints set by the negotiation protocoljust described but also provide a means for establishing important equilibrium properties of the strategies defined fromthese solutions. Before considering the form and properties of these systems of inequalities, we first review the concept of“strategic equilibrium” to be used.5.2. Subgame perfect equilibriumIn the following we use the concepts of Nash equilibrium and subgame perfect equilibrium in order to analyze negotia-tion strategies. These are standard concepts in game theory, and we will not give a detailed presentation: see, e.g., [25].A strategy for an agent is simply a function from the history of negotiation to the choices available to that agent inthe current state of negotiation. Thus, a strategy is simply a rule telling the agent how to negotiate. A strategy profile is asequence of strategies, one for each agent.Now, Nash equilibrium is the most commonly used solution concept in game theory [25, p. 14]. This notion defines astable state of a game, but does not attempt to examine the process by which this state is reached.Definition 1 (Nash equilibrium). A strategy profile ( f 1, f 2, . . . , fn) is a Nash equilibrium if each agent i does not have adifferent strategy yielding an outcome that it prefers to that generated when it chooses f i , given that the other playersfollow their profile strategies.This means that if all agents use the strategies specified in the strategy profile of the Nash equilibrium, then no agent ismotivated to deviate and use another strategy. However, the use of the Nash equilibrium is not an effective way to analyzethe outcomes of our negotiation model, since it evaluates the desirability of a strategy only from the viewpoint of theagents only at the start of negotiation. In view of the fact that in our negotiation model agents know the history until theirmove, there may be some point in the negotiation where one or more agents prefer to diverge from their Nash equilibriumstrategies. That is, Nash equilibrium strategies may be in equilibrium only in the first step of the negotiation, but may beunstable in subsequent stages. Furthermore, there can be many (even infinitely many), Nash equilibria.Motivated by these arguments, we use the concept of subgame perfect equilibrium [25, p. 97], which is a stronger concept,and will be used in order to analyze the negotiation.Definition 2 (Subgame perfect equilibrium). A strategy profile is a subgame perfect equilibrium if the strategy profile inducedin every subgame is Nash equilibrium of that subgame.This means that in any step of the negotiation process, no matter what the history is, no agent is motivated to deviate(cid:11)n of the agents is fixed, weand use another strategy other than that defined in the strategy profile. Once the order acan compute the strategies that are in subgame perfect equilibrium using backward induction [25, p. 99].(cid:11)1, . . . , aHaving reviewed the formulation of equilibrium we can now return to the questions raised following the description ofthe negotiation protocol in Algorithm 1, i.e., the methods by which agents decide the form of cooperation structures putforward in the course of negotiation.5.3. Determining proposals by integer linear programming(cid:11)1, a(cid:11)(cid:11)2, . . . , anSuppose, having fixed an ordering (cid:3)a(cid:4) of the agents, negotiation has reached round t and it is the turn of(cid:11)i (where t (cid:2) i (cid:2) n) to contribute, i.e., to formulate the cooperation structure λt(t) (for t = i) or to make a counter-agent aproposal λt(i) or to reject. We denote by ui({i}) the maximal utility agent i ∈ Ag can obtain from its singleton cooperationstructure, i.e., ui({i}) = max{ui(λ) | λ = (cid:3){i}, G(cid:11)i obtains from its proposal at round t, so that u(i, t) = ui(λt(i)). Agent(cid:11)i is seeking to maximize this utility, but does not have complete freedom (within the protocol defined by Algorithm 1)(cid:11), ξ (cid:4)}.We denote by u(i, t) the utility that an agent aaP.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5035(cid:11)simply to propose a structure which is solely in its own interest: to do so, when i = t, might lead to agents aj rejecting itsproposal outright ( j > i); and, when i > t, the protocol described in Algorithm 1 does not allow λt(i) to reduce the utilityaccording to λt( j) of the agents that are ordered before it (i.e., for t (cid:2) j < i).The constraints governing the form that proposed cooperation structures can take may be described by considering asystem of inequalities (over three disjoint sets of variables) in which the integer values assigned to these variables in anysolution exactly describe the agents (C ), realized goals (G) and contributions (ξ ) featuring in a cooperation structure.(cid:11)Thus we have the following variables featuring in the system describing those proposals, λt(i), that could be made by ain round t:(cid:10)Y = { yl: for each gl ∈ G}(cid:10)(cid:11)S =t, aa(cid:10)(cid:11)t, aas j: for each a(cid:10)x jr : for each aX =∈∈(cid:11)j(cid:11)j(cid:11)(cid:11)(cid:11)(cid:11)t+1, . . . , an(cid:11)(cid:11)t+1, . . . , an(cid:11)and r ∈ R(cid:11).Informally these play the following roles:(cid:11)i• The variable yl ∈ Y will take the value 1 if the corresponding goal gl is among those realized in G(cid:11)of the cooperationstructure, λt(i) achieving utility u(i, t) proposed by a(cid:11)i in round t; otherwise yl = 0.• The variable s j ∈ S will take the value 1 if (at least) one of the goals for the agent a(cid:11)j∈ {a(cid:11)(cid:11)t, . . . , an} is realized in thecooperation structure, λt(i) achieving utility u(i, t) proposed by a• The variable x jr describes the amount of resource r ∈ R contributed by a(cid:11)i in round t; otherwise s j = 0.(cid:11)j within the cooperation structure, λt(i) achiev-ing utility u(i, t) proposed by a(cid:11)i in round t; x jr is an integer value with 0 (cid:2) x jr (cid:2) en(a(cid:11)j, r).We recall that(cid:3)(cid:2)V =maxg∈G ii∈Ag(cid:4)req(g, r)(cid:2)r∈Ris the maximum possible cost that needs to be expended in order for every agent to be able to achieve at least one of its(cid:11)goals. Given that ai ’s viewpoint) is that whichwould maximize u(i, t), i.e., solves(cid:11)i seeks to maximize its own utility in round t, the optimal proposal (from amaximize si V −(cid:2)xir.r∈R(1)(cid:11)As we have already noted, however, the protocol described in Algorithm 1, does not allow ai total latitude in constructingits proposal: the maximization problem specified in Eq. (1) must be solved subject to a number of constraints, captured interms of the following six groups of inequalities.yl (cid:3) s j ∀t (cid:2) j (cid:2) n.(2)Eq. (2) will be satisfied by instantiations of (cid:3)Y , S, X(cid:4) for which s j = 1 only if some goal acceptable to arealized in the cooperation structure λt(i) proposed by a(cid:3)C, Gone of its goals realized.(cid:11)j is amongst thosein round t, i.e., in proposing a cooperation structure, λt(i) =(cid:11)j benefits by having∈ C ) in achieving the utility u(i, t) only if, in return, a(cid:11)i can rely on the assistance of a(cid:11), ξ (cid:4), a(cid:11)j (a(cid:11)j(cid:11)is j V −x jr (cid:3) u( j, t) ∀t (cid:2) j (cid:2) i − 1.(3)Eq. (3) represents the constraint specified in the protocol described in Algorithm 1 that any proposal λt(i) by aall of those agents preceding aobtain, i.e., aHence the left-hand side of (3) describes the utility, u j(λt(i)), that a(cid:11)ai in round t; the right-hand side of (3) defines the utility that ain round t, i.e., λt( j).(cid:11)i must provide(cid:11)} — with at least the utility each can alreadyt+1, . . . , a(cid:11)j in round t may achieve u( j, t) by virtue of the cooperation structure λt( j) proposed earlier in the round.(cid:11)j accrues from the cooperation structure proposed by(cid:11)j obtains from its (earlier) proposed cooperation structure(cid:11)i in round t — the agents {a(cid:11)i−1(cid:11)t, aui({i})u(i, t + 1) otherwise.i = t(4)(cid:12)si V −(cid:2)r∈Rxir (cid:3)Whereas (3) is concerned with conditions imposed on λt(i) arising from the expectations of agents other than ain {aalways achieve the utility afforded by forming a singleton coalition, if a(cid:11)i , i.e., those(cid:11)i can(cid:11)i is the first agent to make a proposal in round t (so}, (4) sets constraints on utility obtainable by airrespective of the actions of agents. Noting that a(cid:11)t, . . . , a(cid:11)i−1(cid:11)i(cid:2)gl∈G j(cid:2)r∈R36P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50(cid:11)i forming a singleton coalition: the i = t case on the RHS of (4) captures this constraint. Alternatively, if a(cid:11)that i = t), any cooperation structure, λt(i) proposed must (in ai as could be achieved(cid:11)by ai is not thefirst agent to bid in round t (i (cid:13)= t), then (noting that i > t in this case), it is certainly the case that any proposal λt(i) madeby a(cid:11)i that could be realized in a later round of negotiation, i.e., the value u(i, t + 1).(cid:11)i ’s own interests) be as beneficial to a(cid:11)i must obtain at least the utility for as j V −x jr (cid:3) u( j, t + 1) ∀i + 1 (cid:2) j (cid:2) n.(5)(cid:2)r∈RThe conditions captured in (5) indicate that the utility gained by a(cid:11)i in round(cid:11)j would be able to make in a later(cid:11)j would either reject the proposal λt(i) or make a counterproposal obtaining utility at least(cid:11)j (i < j (cid:2) n) from any proposal, λt(i) made by a(cid:11)j could realise from the proposal that at, should be at least as great as that which around: were this not the case, au( j, t + 1) for itself in a later round:0 (cid:2) x jr (cid:2) en( j, r) ∀t (cid:2) j (cid:2) n, r ∈ R(cid:2)yl req(l, r) ∀r ∈ R.x jr (cid:3)(cid:2)t(cid:3) j(cid:3)ngl∈G(6)(7)The constraints specified in (6), (7) ensure the cooperation structure λt(i) is feasible (regardless of whether any agent(cid:11)(cid:11)j and resource r ∈ R, the proposal made by aadopts it). For each agent aj to expend at most its endowment of theresource r (6); and, (7) admits only cooperation structures λt(i) = (cid:3)C, G(so thatyl = 1) has sufficient of each resource provided in ξ ((cid:11)i allows a(cid:11), ξ (cid:4) for which each goal gl included in G(cid:13)nj=t x jr ) to meet its requirement req(gl, r).(cid:11)We denote by LP(i, t) the space of instantiations π of (cid:3)Y , S, X(cid:4) ∈ Z|G|+| X|+n−t+1 for which• π ∈ LP(i, t) maximizes u(i, t), as described in (1).• π ∈ LP(i, t) satisfies each of the inequalities specified in (2)–(7).We refer to such instantiations subsequently as solutions of LP(i, t). We note that LP(i, t) may be empty (no cooperation(cid:11)i in round t that satisfies the conditions imposed by the inequalities (2)–(7)), or LP(i, t)structure λt(i) can be proposed by a(cid:11)may have several solutions.3 In this latter case it is unimportant which solution of LP(i, t) is chosen by ai in round t: given(cid:11)i will achieve the same utility — u(i, t) — for each.the formulation of (1)–(7), a(cid:11), ξ (cid:4) so that:Given a solution of LP(i, t), let λt(i) = (cid:3)C, G},(cid:11)(cid:11)t, . . . , an• C = {a• G• ξ j = (cid:3)x j1, . . . , x j|R|(cid:4), t (cid:2) j (cid:2) n.(cid:11) = {gl: gl ∈ G j and yl = 1}, andWe observe that from the instantiation of (cid:3)Y , S, X(cid:4) defining a solution of LP(i, t) the exact form of the cooperation structure(cid:11), ξ (cid:4), theλt(i) is easily determined. Thus from a solution of LP(i, t) and its associated cooperation structure λt(i) = (cid:3)C, Gutility an agent i obtains from its proposed cooperation structure at round t is u(i, t) = si V −(cid:13)r∈R xir .We wish to use the protocol of Algorithm 1 together with the system of inequalities (1)–(7) to determine λt(n) thecooperation structure agreed when protocol described in Algorithm 1 ends. Specifically, we wish to treat the maximizationof (1) subject to the inequalities (2)–(7) as an integer linear program. One problem is, however, apparent with these condi-tions. The values V , en(a, r), and req(g, r) are already known as part of the crg instantiation and we wish to find solutions(values for (cid:3)Y , S, X(cid:4)) of LP(i, t). The problem is that the solutions of LP(i, t) are given in terms of solutions of L( j, t) wheret (cid:2) j < i so we need to determine the correct values for u( j, t) to use in Eqs. (3), (4) and (5). In other words, we cannotfind the value of u(i, t) until we have calculated the value of each u( j, t) for t (cid:2) j < i.Assume that the current round is t and it is the turn of agent a(cid:11)i to propose a cooperation structure. The value of u( j, t)to be used in finding a solution of LP(i, t) for each agent j preceding i according to the predefined order, i.e., those for(cid:11)which t (cid:2) j (cid:2) i − 1, can be calculated easily from the proposal agent aji−1 has already made. That is, u( j, t) is determined(cid:11)j at round t and does not require obtaining solutions of LP( j, t): suchby the cooperation structure that was proposed by awill already have been found and these values can be substituted for use in (3).In order to compute the value u( j, t + 1), for i (cid:2) j (cid:2) n, to be used in finding a solution of LP(i, t), however, will require(cid:11))(cid:11) (cid:2) j (cid:2) n, i.e., solutions of LP(i, t) are specified in terms of solutions of LP( j, t(cid:11) > t and ∀t(cid:11)) ∀tcomputing the values of u( j, t(cid:11) (cid:2) j (cid:2) n.(cid:11) > t and tfor every tWe resolve this difficulty as follows: to compute the required values the agent uses a backward induction starting fromcomputing u(n, n) by finding a solution of LP(n, n) which will lead to un({n}). Then the agent computes u(n − 1, n − 1) and(cid:11) > t the agent computesu(n, n − 1) by finding solutions of LP(n − 1, n − 1) and LP(n, n − 1). In general, given a round t3 Although, only a finite number of solutions are possible, since there are a finite number of possible cooperation structures.P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5037(cid:11)) by finding a solution of LP( j, t(cid:11)) for j = tu( j, ttill(cid:11) (cid:2) k (cid:2) j − 1 and(cid:11)) are already been calculated for tj = n). Note that when the agent calculates u( j, t(cid:11) + 1 (cid:2) k (cid:2) n. It is easy to see, by backward induction, that LP(t, t) willthe values of u(k, talways have a solution, i.e., LP(t, t) computed in that way is always non-empty. These processes are formally presented inthe following proposition.(cid:11)) according to the agents predefined order (i.e., it starts solving u( j, t(cid:11) + 1) are already computed for t(cid:11)) the values of u(k, t(cid:11)Proposition 14. Given an order of the agents (aFor any round 1 (cid:2) t < n,(cid:11)1, . . . , a(cid:11)n), a(cid:11)j∈ Ag, the following strategies are in subgame perfect equilibrium:• Agent a• Agent a(cid:11)t offers λt(t).(cid:11)j , t < j (cid:2) n in its turn at round t will do:Given the cooperation structures λt(l) that have already been proposed by aof LP( j, t) will be computed as described above. If LP( j, t) has no feasible solution, aOtherwise if λt( j) = λt( j − 1) then a(cid:11)j will accept, otherwise it will propose λt( j).(cid:11)l , t (cid:2) l < j, a(cid:11)j will compute u(l, t). Then, a solution(cid:11)j will “reject” the offer.Proof. The proof is by backward induction on the negotiation step (t), and for each step by backward induction accordingto the agent order.}) and it cannot do better. Note that there may be severalFor t = n: a solution of LP(n, n) will yield a(cid:11)(cid:11)n a utility of un({an(cid:11)solutions to LP(n, n), but they will all yield the same utility to an.(cid:11)n rejects aFor t = n − 1 and j = n: If a(cid:11)n−1 makes would yield a(cid:11)(cid:11)n obtain a utility of u(n, n) = un({a})n−1’s offer, the current round would end and a(cid:11)in the next round (t = n). So, if the offer a}), then an cannot gain by deviating. This(cid:11)(cid:11)is stated in constraint (4) on solutions of LP(n, n − 1). In addition, suppose the utility for an−1 from the offer an−1 made(cid:11)earlier in the round is u(n − 1, n − 1). According to the protocol an−1 at least that utility.This is stated in constraint (3) on solutions of LP(n, n − 1). Finally, the proposed offer must be feasible which is stated in(cid:11)constraints (6) and (7) on solutions of LP(n, n − 1). Among all these possible offers, an should choose a cooperation structurethat yields it the highest utility; this is stated by the target function (1). Thus, if there is a solution of LP(n, n − 1), if the(cid:11)offer associated with this solution is the same as the offer made by an should accept; if it is not the same itshould make the offer associated with this as in both cases it cannot improve by deviating. If such a solution does not exist,(cid:11)n should reject the offer and will get u(n, n) = un({aa(cid:11)n can only make offers that yield a(cid:11)n at least un({a(cid:11)n−1 then a(cid:11)n(cid:11)n(cid:11)n}).(cid:11)n−1 is making an offer to a}). So, a(cid:11)n−1’s utility from the proposal it makes should be at least not worse than un−1({a(cid:11)n−1(cid:11)n−1 is forced to leave the negotiation and,}).(cid:11)n. If a(cid:11)n rejects the offer, aFor t = n−1 and j = n−1: athereby, obtains un−1({aThis is valid according to constraint (4).(cid:11)n−1If the offer a(cid:11)n−1 makes yields a(cid:11)n at least un,n = un({a(cid:11)n cannot gain by deviating. This is stated in(cid:11)constraint (5) on solutions of LP(n − 1, n − 1). In order for it to be accepted by an, LP(n, n − 1) must contain a solution. Inparticular, these must satisfy constraint (4) on solutions of LP(n, n − 1) which is the same as constraint (5) on solutions ofLP(n − 1, n − 1): while LP(n, n − 1) may have several solutions, all will be associated with the same u(n, n − 1). The feasibility(cid:11)of the proposal is ensured by (6) and (7) on solutions of LP(n − 1, n − 1). Again among all these possible agreements an−1(cid:11)considers the best to itself (either, accept the proposed offer if it is the same as the one an−1 commuted or proposes thisagreement) and thus does not have an incentive to deviate.}), then, again, a(cid:11)nof LP(n, k + 1).Inductive step. Suppose the specified strategies are in subgame perfect equilibrium for t > k (cid:3) n. We will show it for t = k.(cid:11)n will obtain u(n, k + 1) which is associated with solutionsFirst we will consider j = n. From the induction hypothesis aAccording to constraint (4) on solutions of LP(n, k), a(cid:11)n it will obtain at least this amount, so if a solution to LP(n, k) existsthere is no incentive to wait to round k + 1. Similarly to the base case the other constraints are necessary for following theprotocol and making sure the proposed cooperation structure is feasible.(cid:11)Assuming the induction hypothesis is correct for k < m < j (cid:2) n, consider j = m − 1. From the inductive hypothesis, if aj ’soffer will be rejected, it will obtain u( j, k + 1) associated with solutions of LP( j, k + 1) in the next time period. According to(cid:11)constraint (5) on solutions of LP( j, k) aj will obtain at least this amount in the proposed cooperation structure. According to(cid:11)the induction hypothesis, aj will also receive at least this utility in the proposals made in the rest of the round given thatj < l (cid:2) n. To ensure there will be such a solution, by a similar argument to that used inthere will be a solution of LP(l, k),the base case, it must satisfy the constraint (4). In addition, to meet the protocol conditions and find a feasible cooperationstructure, LP( j, k) includes the constraints (3), (6) and (7).Finally, consider j = k. Given the induction hypothesis the reasoning is similar to the base case, where t = n − 1 andj = n − 1, and a(cid:11)j does not have any incentive to deviate. (cid:2)If the agents follow the subgame perfect equilibrium strategies, there will be only one round of the negotiation. The(cid:11)2 will make a counter offer trying to improve its own utility, while(cid:11)n, which will try to improve(cid:11)1 the same utility as in the original offer, and so on, until the turn of the last agent, a(cid:11)1 will make an offer; the second agent, afirst agent, agiving a38P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50its own utility while giving the others at least as much as they got in the offer of abe implemented will consist of the cooperation structure λ1(n) that will be offered by the last agent in the first round.(cid:11)n−1. The cooperation structure that will5.4. Desirable propertiesAn obvious question is what outcomes the protocol will lead to, assuming rational action on the part of participantagents; in particular, it would be highly desirable to have a protocol so that, assuming rational play, a “good” outcome willresult; so first, we need to consider what we mean by “good” in this context.First, it seems essential that no agent can lose by participating. We capture this in the notion of individual rationality.Proposition 15 (Individual rationality). Given a sequence (a(cid:11)1, . . . , a(cid:11)n), ui(λ1(n)) (cid:3) ui({i}).Proof. The claim is clear for acooperation structure au1({1}).(cid:11)1, since according to constraint (4) on solutions of LP(1, 1) its utility associated with the}). According to constraint (3) on solutions of LP(n, 1), u1(λ1(n)) (cid:3)(cid:11)1 proposes is at least u1({a(cid:11)1Consider any of the other agents, a(cid:11)j , 1 < j (cid:2) n. From constraint (4) on solutions of LP( j, j), u( j, j) (cid:3) u j({ j}). It is easy toshow by backward induction, using constraint (5) that u( j, t) for 1 (cid:2) t < j are also at least u j({ j}). (cid:2)An additional important property is Pareto Optimality of the outcome. This property ensures that it is not possible toimprove the outcome of one agent without decreasing the outcome of the others. In particular, in our case the cooperationstructure that is formed if the agents follow their subgame perfect equilibrium strategies is “efficient” in the sense that thereis no other cooperation structures in which at least one agent will obtain a higher utility without the others obtaining lowerutility. Note that this property addresses the outcome, not the strategies. It is possible that stable strategies (i.e., strategiesthat are in equilibrium) may yield non Pareto Optimal outcomes (e.g., the Nash equilibrium strategies in the Prisoner’sDilemma game). We formally prove this property in the next proposition.Proposition 16 (Pareto Optimality). Given a sequence (aui(λ1(n)) > ui(λ) and for a j ∈ Ag, j (cid:13)= i, u j(λ1(n) (cid:3) u j(λ).(cid:11)1, . . . , a(cid:11)n), there is no λ = (cid:3)Ag, G(cid:11), ξ (cid:11)(cid:4) such that there exists ai ∈ Ag such thatProof. The proposition is clear from the maximization expression of each LP(i, 1), 1 (cid:2) i (cid:2) n and constraint (3) on solutionsof LP(i, 1), 1 (cid:2) i (cid:2) n. Intuitively, each agent tries to maximize its own utility, given the utilities of agents preceding him. (cid:2)A common criticism of Pareto Optimality is that it may lead to unjust outcomes. In particular there may be ParetoOptimal outcomes where one of the players obtains a very large utility, while the others do not obtain any utility. However,defining a fair distribution of utility is not easy. The example of one player obtaining all the utility may be considered fairif this agent is the only one that contributed to the creation of this utility. However, such a distribution might be regardedas unfair if all agents contributed equally.Thus, first, we would like to characterize agents that do not contribute anything to the joint utility of a coalition. Wewill refer to such an agent as a dummy agent.4 We will require that in a “fair” cooperation structure a dummy agent willnot obtain any utility. In order to define the notion of a dummy agent we first recall what it means for a coalition to besuccessful: A coalition C ⊆ N is successful iff sf (C) (cid:13)= ∅. Intuitively, in a successful coalition at least one goal of each agentcan be satisfied.Definition 3 (Dummy agents). Agent i ∈ Ag is a dummy iff for all C ⊆ N, C ∪ {i} is not successful.It follows that if i ∈ Ag is a dummy agent then ui({i}) = 0. Furthermore, adding a dummy agent cannot increase the maximalsum of the utilities a group of agents could obtain without it. Given this definition, the “dummy agent” property will statethat a dummy agent should not obtain any utility from the coalition structure. In order to show that a cooperation structurethat the agents agree upon if they follow their subgame perfect equilibrium strategies in our proposed protocol satisfies thedummy agent property, we will first prove some properties of the resulting structure.Proposition 17. Suppose we are given a sequence (asuch that for any ai ∈ C , ui(λ1(n)) > 0. Then C is a successful coalition.(cid:11)1, . . . , a(cid:11)n), and the associated agreement is λ1(n). Let C ⊆ Ag be the set of agentsProof. From constraint (2) and Proposition 15 an agent a j that at least one of its goals is satisfied will not contributeany resources, i.e., xlr = 0 and its utility will be zero. So, for each agent in C at least one of its goals are satisfied and inconstraints (6) and (7), for only j ∈ C x jr > 0. Thus C is successful. (cid:2)4 We borrow this name from the definition of the Shapley value [25, p. 292].P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5039We now prove the dummy player property holds in our framework.Proposition 18 (Dummy agents). Suppose we are given a sequence (adummy agent then ui(λ1(n)) = 0.(cid:11)1, . . . , a(cid:11)n), and the associated agreement is λ1(n). Then if ai is aProof. Let C ⊆ Ag be the set of agents such that for any a j ∈ C , u j(λ1(n)) > 0. From Proposition 17 C is successful and thusaccording to the definition of the Dummy agent property, ai /∈ C . (cid:2)Another notion of fairness is that similar agents will obtain the same utilities when taking part in the same cooperationstructure. Similarity is defined in the next definition, in the sense of being able to replace one agent by the other in acooperation structure, without changing the utility obtained by all agents.Definition 4 (Interchangeable agents). Agents i, j ∈ Ag are said to be interchangeable iff:1. ui({i}) = u j({ j});2. for any set of agents C ⊆ Ag, where i, j ∈ C and for any λ = (cid:3)C, G(cid:11), ξ (cid:4) there exists λ(cid:11) = (cid:3)C, G(cid:11)(cid:11), ξ (cid:11)(cid:4) such that:3. Suppose λ = (cid:3)C, G(cid:11), ξ (cid:4) such that i /∈ C and j /∈ C . Then, for any λi = (cid:3)C ∪ {i}, G i, ξ i(cid:4) there is λ j = (cid:3)C ∪ { j}, G j, ξ j(cid:4) s.t.(i) ui(λ) = u j(λ(cid:11)), and u j(λ) = ui(λ(cid:11));(ii) For any l ∈ C , l (cid:13)= i, l (cid:13)= j ul(λ(cid:11)) = ul(λ).(i) ui(λi) = u j(λ j); and(ii) for any l ∈ C ul(λi) = ul(λ j).It seems fair that the expected utility of two interchangeable agents from the coalition structure formed is the same.Unfortunately, not each scenario of the protocol leads to a cooperation structure that satisfies such a symmetry property,because the order of the agents can make a significant difference. However, if we look at expected utility, this property issatisfied. Given a sequence of agents ς = {a1 (n) be the associated agreed cooperation structure. We can thendefine the expected utility EUi of agent i:(cid:11)(cid:11)1, . . . , an}, let λς(cid:2)EUi =ς =(a(cid:11)1,...,a(cid:11)n)a(cid:11)i∈Ag,a(cid:11)i(cid:13)=a(cid:11)j(cid:14)(cid:15)λς1 (n).1n! uiProposition 19 (Pseudo symmetry). If i, j ∈ Ag are interchangeable then E U i = E U j .(cid:11)h(cid:11)n and a(cid:11)1, . . . , a(cid:11)(cid:11)= a(cid:13)= ai andProof. Consider a(cid:13)= a j , then a1(n) the agreements reached when the agents follows the subgame perfectaequilibrium strategies of Theorem 14 associated with the first ordering of the agents and the second ordering respectively.1(n)) and for any h (cid:13)= i and h (cid:13)= j, uh(λ1(n)) =h . Denote by λ1(n) and λ(cid:11)1(n)) and u j(λ1(n)) = ui(λ(cid:11)= ai and for any 1 (cid:2) h (cid:2) n if a(cid:11)(cid:11)= a j and al(cid:11)(cid:11)(cid:11)n where ak(cid:11)(cid:11)= a j , ak(cid:11)= ai , al(cid:11)(cid:11)1, . . . , a(cid:11)h(cid:11)hWe show by induction on n that ui(λ1(n)) = u j(λ(cid:11)1(n)):uh(λ(cid:11)(cid:11)(cid:11)1(cid:11)(cid:11)= a2, and a2(cid:11)1, a= a1.(cid:11)2.• Base case: for n = 2 there are only two possible orders a(cid:11)1= a1, and a= a2 and a(cid:11)2(cid:11)1 which is a solution of LP(1, 1) with respect to aLet λ1(1) be the agreement proposed by aAccording to (2) of the definition of the interchangeable agents (Definition 4) there is a cooperation structure λ(cid:11)where u1(λ1(1)) = u2(λ(cid:11)Since according to (1) of Definition 4 u1({a1}) = u2({a2}) λ(cid:11)1(1) respectively.and aSimilarly we can show that u1(λ1(2)) = u2(λ(cid:11)1(1) is a solution to LP(1, 1) associated with a1(1)) and u2(λ1(1)) = u1(λ(cid:11)1 will offer λ1(1) and λ(cid:11)1(2)) and u2(λ1(2)) = u1(λ(cid:11)1(2)).1(1)).(cid:11)(cid:11)1, a(cid:11)(cid:11)(cid:13)= a j .(cid:13)= ai , a• Inductive case: Suppose the claim is true for n = m and we will show for n = m + 1.(cid:11)1(cid:11)Consider first the case where a1From the induction hypothesis we have that u j(λ2(m + 1)) = ui(λ(cid:11)h (cid:13)= i and h (cid:13)= j uh(λ2(m + 1)) = uh(λ(cid:11)(cid:11)1. According to the specifications of solutions in LP(1, 1) it yields all the other agents atLet λ1(1) be the offer made by a(cid:11)}) (constraint (6)), and maximizes its utility given these constraints.1 at least its u1({aleast u(l, 2) (constraint (5)), to aFrom (2) of Definition 4 there exists λ(cid:11)such that all the agents except i and j gets the same utility as in λ1(1) and(cid:11)(cid:11)ui(λ1(1)) = u j(λ(cid:11)) and u j(λ1(1)) = u j(λ(cid:11)). It is easy to see that λ(cid:11)(cid:11)(cid:11)1, . . . , anorder.5 In a similar way it can be shown that for any λ1(h) associated with the a1(h) associated1(h)) and u j(λ1(h)) =with the aui(λ(cid:11)n that yields the same utility to all agents but ai and a j and ui(λ1(h)) = u j(λ(cid:11)can be associated with LP(1, 1) for the a(cid:11)2(m + 1)), u j(λ2(m + 1)) = ui(λ(cid:11)1(h)). In particular this is true for h = m + 1.2(m + 1)) and for everyn there is a λ(cid:11)2(m + 1)).(cid:11)(cid:11)1, . . . , a(cid:11)1, . . . , a(cid:11)1(cid:11)(cid:11)(cid:11)(cid:11)2. Thus, a(cid:11)11(1)5 Note that there can be more than one such λ(cid:11); however all yield the same utilities to all agents.40P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50(cid:11)1(cid:11)= ai and al= a j and a= ai . Consider first λh(h) for h (cid:3) l. It is clear that sinceConsider the case where athe orders of the agents in both sequences starting in h are the same it will be associated with the same utilities asthat associated with λ(cid:11)(cid:11)Suppose alany h (cid:13)= i and h (cid:13)= j uh(λl(l)) = ul(λ(cid:11)Given this it can be shown that for any h (cid:13)= i, h (cid:13)= j uh(λ2(m + 1)) = uh(λ(cid:11)The proof now continues as in the previous case.l(l) in which u j(λl(l)) = ui(λ(cid:11)= ai .2(m + 1)) and u j(λ2(m + 1)) = ui(λ(cid:11)= a j made an offer λl(l). According to (3) of Definition 4 there is λ(cid:11)l(l)). It is easy to see that λ(cid:11)(cid:11)(cid:11)l(l) will be offered by all(l)) and for2(m + 1)).h(h).(cid:11)(cid:11)= a j and al(cid:11)(cid:11)1Given the claim that we proved above and the definition of E U , we can conclude that E U i = E U j . (cid:2)5.5. Time complexity of finding equilibrium strategies(cid:11) (cid:2) j (cid:2) n, finding a cooperation structure inNext we prove that given the integer program problem LP( j, t(cid:11)) (Eqs. (2)–(7)) and maximizes the objective functionwhich the agents’ utilities satisfy the constraints on solutions of LP( j, t(Eq. (1)) is exponential only in the number of goals. Since each agent when its turn arrives to respond to an offer andit needs to determine its strategy (reject the proposal or to offer a cooperation structure) has to solve only a polynomialnumber of such problems, computing the subgame perfect equilibrium strategy is exponential only in the number of thegoals. As mentioned before in many real world situations, the number of goals is relatively small and can be bounded bya small constant number. Thus the complexity of computing the subgame perfect equilibrium strategy can be consideredtractable.(cid:11)), 1 (cid:2) t(cid:11) (cid:2) n, tProposition 20 (Time complexity). Given the integer program problem LP( j, t(if any exists) that satisfies the constraints on solutions of LP( j, texponential only in the number of goals.(cid:11) (cid:2) j (cid:2) n, finding a cooperation structure(cid:11)) (Eqs. (2)–(7)) and maximizes the objective function (Eq. (1)) is(cid:11)), 1 (cid:2) t(cid:11) (cid:2) n, tProof. See Appendix B. (cid:2)5.6. Bargaining solutions and the coreThe two types of solution considered in this paper — bargaining solutions and the core — can be understood as repre-senting two camps of game theory researchers, namely noncooperative and cooperative. The most fundamental differencebetween them is the type of deviation that the two frameworks require their solution concepts to be immune to. It isinteresting to ask whether the gap between these two approaches can be closed. In particular, in our context, this meansasking whether the coalition structure that is obtained when the agents follow their equilibrium strategies in the negotiationprotocol is in the core.Some previous work has studied the relation of noncooperative models and the core (e.g., [8,27]). However, most previouswork focuses on tu-games. Works on ntu coalition games includes [17,23,30]. In [18,19], partition games with externalitiesare studied. Since our utility function is just a mechanism for expressing the preferences of agents over coalitions, ourgames have many similarities to hedonic games, where each player’s preferences only depend on the coalition they belongto. However, unlike hedonic games, in our model preferences also depend on the goals that a coalition satisfies, and theresources they need must contribute (i.e., not just with respect to coalitions, but with respect to cooperation structures).It turns out the relationships between the core and the outcomes of negotiation can be understood by considering therelationships between them in hedonic games.We begin by modifying the definition of top-coalition of hedonic games [4], and define the concept of a top-cooperationstructure in a crg.Definition 5 (Top-cooperation structure). A cooperation structure λ = (cid:3)C, Gi ∈ C and any cooperation structure λ(cid:11) = (cid:3)C(cid:11)(cid:11), ξ (cid:11)(cid:4) such that i ∈ C(cid:11), G(cid:11)and λ(cid:11) (cid:13)= λ, ui(λ) > ui(λ(cid:11)).(cid:11), ξ (cid:4) is a top-cooperation structure if for every agentThe key point about top-cooperation structures is this: every participant in a top-cooperation structure strictly prefers thiscooperation structure over all others that it could be involved with. Thus top-cooperation structures imply a certain kind ofuniformity for the preference relations of members of the top-cooperation structure. We can show:Proposition 21. If a top cooperation structure λ = (cid:3)C, G(cid:11), ξ (cid:4) exists in a crg Γ , then:1. λ contains the grand coalition (i.e., C = Ag).2. λ is the only top-cooperation structure in Γ .3. The core of Γ is non-empty, and contains a single coalition structure σ ∗ = {λ}.P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5041(cid:11)(cid:11) (cid:13)= ∅. Now consider the cooperation structure λ(cid:11)(cid:11) = (cid:3)Ccontribute nothing and achieve no goals). Take λ(cid:11)(cid:11)(cid:11) = λ (cid:16) λ(cid:11)(cid:11)(cid:11)(cid:11) = Ag \ C .Proof. For item (1), suppose for sake of contradiction that λ is a top-cooperation structure but that C (cid:13)= Ag. Let C(cid:11)(cid:11), ∅, ξ (cid:11)(cid:11)(cid:4) in which ξ (cid:11)(cid:11)(cid:11)(cid:11)Since C (cid:13)= Ag then C= 0 for all i ∈ Cand r ∈ Ri,r(cid:11)(cid:11)is feasible, since λ is feasible(i.e., the agents Cintroduces no additional goals. By Proposition 1, for all i ∈ C , we have ui(λ(cid:11)(cid:11)(cid:11)) (cid:3) ui(λ). But then λ cannot be a top-and λ(cid:11)(cid:11)(cid:11)cooperation structure, giving a contradiction. For item (2), suppose for sake of contradiction that there exists more than onebe one such top-cooperation structure (λ (cid:13)= λ(cid:11)top-cooperation structure in Γ , and let λ(cid:11)). From item (1), we know that bothwill contain the grand coalition. Since λ is a top-cooperation structure, then for all i ∈ Ag, we have ui(λ) > ui(λ(cid:11)).λ and λ(cid:11)is also a top-cooperation structure, then for all i ∈ Ag, we have ui(λ(cid:11)) > ui(λ), giving a contradiction. ForBut since λ(cid:11)item (3), to see that the core is non-empty, simply note that no cooperation structure λ(cid:11)can block σ ∗ = {λ} since λ containsthe grand coalition, and every member of Ag strictly prefers λ over any other cooperation structure of which it could bea member. To see that σ ∗ = {λ} is the unique member of the core, observe again that every member of λ (i.e., the grandcoalition) strictly prefers λ over any other cooperation structure of which it could be a part, and so λ will block any othercoalition structure σ (cid:11). Clearly λ(cid:11)(cid:11)(cid:11). (cid:2)Notice that this implies a kind of efficiency with respect to the core as a solution concept: if there is a top-coalitionstructure, then this will be in the core. Of course, the notion of a top-cooperation structure is a strong one, and this begsthe question of whether top-cooperation structures ever exist. The answer is yes, as the following example illustrates:Example 4. We define a crg with two agents, each of which shares a common goal, and each of which needs to contributeits entire endowment in order to have the goal accomplished. Formally, let Ag = {a1, a2}, let G = G 1 = G 2 = {g}, let R ={r1, r2}, and define req(g, r1) = 1, req(g, r2) = 1, en(a1, r1) = 1, en(a1, r2) = 0, en(a2, r1) = 0, and en(a2, r2) = 1. Let λ == 1. It is straightforward to see that λ is a top-cooperation(cid:3){a1, a2}, {g}, ξ (cid:4) in which ξa1,r1structure: the only other feasible cooperation structures achieve no goals, and both agents would strictly prefer λ over these.= 0, and ξa2,r2= 1, ξa1,r2= 0, ξa2,r1However, as the following example illustrates, there are of course crgs that have no top-cooperation structure:Example 5. We define a crg with two agents, each of which has one goal, which can only be accomplished by the otheragent contributing its resources. The agents collectively can accomplish both goals, but each would prefer the other toaccomplish its goal while making no contribution of its own. Formally, let Ag = {a1, a2}, let G = {g1, g2}, let G i = {gi},let R = {r1, r2}, and define req(g1, r1) = 0, req(g1, r2) = 1, req(g2, r1) = 1, req(g2, r2) = 0, en(a1, r1) = 1, en(a1, r2) = 0,en(a2, r1) = 0, and en(a2, r2) = 1. There are only four feasible cooperation structures, none of which is a top-cooperation= 0,structure. For example, consider the cooperation structure λ = (cid:3){a1, a2}, {g1, g2}, ξ (cid:4) in which ξa1,r1= 1. It is easy to see that both agents would prefer to contribute nothing and allow the other agent to accomplishand ξa2,r2their goal.= 1, ξa1,r2= 0, ξa2,r1Now, where top-cooperation structures exist, the core and bargaining solutions coincide:Proposition 22. For every crg that has a top-cooperation structure, the outcome of the negotiation process in which agents followtheir subgame perfect equilibrium strategies will be the top-cooperation structure, and thus the outcome of negotiation will be in thecore.This result is quite intuitive: according to the subgame perfect equilibrium strategies, when making the first proposal, the(cid:11)1 tries to maximise its own utility while ensuring that other agents do at least as wellfirst agent in the negotiation order a(cid:11)as they would do had bargaining proceeded to the stage where they were in the position of making a proposal. Agent a1will thus propose the top-cooperation structure, and since no agent can improve on this, the proposal will be accepted.Another obvious question is whether any element of the core can be reached by picking an appropriate negotiation orderof the agents. In general, this is not true. Furthermore, there are crgs in which for any order of the agents the resultingcoalition structure is not in the core. The following example illustrates this.Example 6. Consider the following crg. We have four agents, Ag = {a1, a2, a3, a2}. Intuitively, every pair of agents and eachtriple can form a successful cooperation structure. A single agent is not successful. Each coalition is associated with adifferent goal. For the set of goals we have:G = {g12, g23, g13, g14, g24, g34, g12,3, g13,2, g23,1, g12,4, g14,2, g24,1, g13,4, g14,3, g34,1, g2,34, g34,2, g24,3}.(The naming convention for goals will become clear below.) For every goal and every agent such that its index appears inthe goal name, there is a resource such that its superscript index is the agent’s index. For example, for goal g12 we haveresources r112 and r212, while for goal g12,3 we also have resource r3The goal sets for each agent are the goals in which its index appears, for exampleG 1 = {g12, g13, g14, g12,3, g13,2, g23,1, g12,4, g14,2, g24,1, g13,4, g14,3, g34,1}.12,3.42P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50According to the endowment function en each agent has 3 units of the resource in which its index appears as the super-script, e.g., agent a1 has 3 units of the resource r112.The requirement function is as follows. A goal with two indexes, gi j , requires 2 units for each resource with the same12. A goal with three indexes12,3, 1 of r112,3 and 3i j,l. For example, g12,3 requires 1 unit of r1i j . For example, g12 requires 2 units of r1i j and 2 for ri j,l, 1 unit for ri j,l and 3 units for rl12 and 2 units of r2jjindexes, i.e., 2 units of rigi j,l requires 1 unit of riof r312,3.The core of this crg consists of any two cooperation structures of two agents satisfying the associated goal and eachagent contributes its relevant required resource. For example, σ = {λ1, λ2} is in the core where(cid:16)(cid:16)λ1 ={a1, a2}, {g12}, ξ 1λ2 ={a3, a4}, {g34}, ξ 2(cid:17)(cid:17)where according to ξ 1, a1 contributes 2 units of r112 and a2 contributes 2 units of r212 andwhere according to ξ 2, a3 contributes 2 units of r3structures merging such two coalitions are also in the core.34 and a4 contributes 2 units of r434. In addition the grand cooperationWe now demonstrate that for any order of the agents the result of the negotiation will not be in the core. For ex-ample, suppose that the order is a1, a2, a3, a4. We have λ4(4) = {a4} and λ3(3) = (cid:3){a3, a4}, {g34}, ξ 34(cid:4) where according34. Furthermore, λ2(2) = (cid:3){a2, a3, a4}, {g34,2}, ξ 22(cid:4)to ξ 34, a3 contributes 2 units of r3where according to ξ 22, a3 contributes 1 unit of r334,2 and a2 contributes 3 units of r234,2. Finally,λ1(1) = (cid:3){a1, a2, a3, a4}, {g34,2}, ξ 22(cid:4) where ξ 22 is as above and a1 is not successful. It is easy to see that λ1(1) is not in thecore since a1 and a2 can block it. Similar observations can be made to any other order.34 and a4 contributes 2 units of r434,2, a4 contributes r4An obvious question is whether there are other cases in which the result of negotiation is always in the core. As wasshown in other papers that study the relationships between the core and the negotiation outcome in ntu games [23] thesubgame perfect equilibria of such games strongly depends on the order in which players move. Therefore, these papershave to rely on some mechanism for making players symmetric. We will follow this direction, and define a stronger notionof equilibrium that does not depend on the order of the agents: we adapt the notion of order independent equilibria [23]to crgs.oies were introduced in [23] as a way of linking cooperative and non-cooperative games. The starting point was theobservation that in a bargaining setting such as our that of [16] (or indeed our bargaining protocol), the outcome availableto a player depends crucially on the order in which players are able to make proposals: each different order defines adifferent game, and so an equlibrium for one order will not necessarily be an equilibrium for another order. oies wereintroduced to capture the idea of an equilibrium across all possible orders of players. Intuitively, an oie was defined to bea collection of strategies that forms a subgame perfect equilibrium for every possible ordering of agents, and also, producesan outcome that is independent of the ordering. It was then proved that, if a strategy profile forms an oie, then the outcomewas guaranteed to be in the core [23, Proposition A].We adapt the concept of oie for our setting. We first assume that a strategy specifies the action the agent will take atany decision point for any possible order of players (and not only for a given order as we discussed above). Given this, wedefine:Definition 6 (oie). A profile of extended strategies is an order independent equilibrium (oie) of the negotiation protocol if:1. the strategy profile is a subgame perfect equilibrium; and2. the offers an agent will make and accept according to its strategy in all subgames in which the sets of active agents arethe same (regardless of the order) are the same.Now, according to oie in the first round a given agent will make the same offer and will accept the same offers regardlessof the order of the agents. Even though in our model time is not costly we will assume that if an agent can get the sameutility for two coalition structures it will prefer the one formed at an earlier time. Thus, we can assume that the negotiationwill end at the first round since if the negotiation ends at time t then the disjoint union of the singleton cooperationstructures of the first t − 1 agents and the members of the coalition structures that was form in time t can be achieved inthe first round.Proposition 23. The outcome of negotiation if the agents follow OIE is in the core.(cid:11)n with negotiation ending at the first round withProof. For contradiction, assume that the order of the agents was a(cid:11), ξ (cid:4) that blocks σ . Now,a coalition structure σ , but that σ is not in the core. Thus there is a cooperation structure λ = (cid:3)C, Gconsider a different order of the agents where the members of C are placed at the end of the order. In that order, if the(cid:11)1, . . . , aP.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5043negotiation does not terminate until the round in which only the members of C remain, there will be at least one agentsuch that its utility from the coalition structure that will form will be at least that obtained from λ. Otherwise λ couldbe formed. This agent will not accept σ in the first round, since it could obtain a higher utility if negotiation continued.However, since the agents follow OIE it would not accept σ in the first round also when the agents are ordered accordingto the original order a(cid:11)n; a contradiction. (cid:2)(cid:11)1, . . . , aNote that Proposition 23 does not require that there is a top-cooperation structure. Also note that the converse ofProposition 23 does not hold. That is, there are core outcomes that cannot be reached by any OIE. In [23] it was enoughto require that for every subgame of the game the core is not empty. This is not enough for crgs, as demonstrated byExample 6.6. ConclusionsCoalitional resource games provide a natural model of scenarios in which groups of agents cooperate by pooling resourcesto achieve mutually satisfying sets of goals. In this paper, we have considered two types of solutions for such games: stablesolutions, in which each agent contributes some resources to the achievement of some goal set, and no coalition has anyincentive to deviate from the solution; and bargaining solutions, which satisfy the desirable properties of Pareto Optimality,dummy player, and pseudo-symmetry.Several issues suggest themselves for future work. First, it would be interesting to look at more sophisticated models ofresources and resource consumption. For example, [6] considers processes that have some duration, and that have differentresource usage requirements at different stages. Interesting issues arise, for example, when one considers combining suchprocesses. We might think of different goals being achieved by different processes, and then imagine scheduling suchprocesses in such a way as to satisfy agents while staying within stated resource bounds. This also leads us to considertemporal extensions to the present framework, as temporal extensions to qualitative coalitional games were consideredin [1]. Finally, of course, other bargaining approaches might be considered: for example there is work in the ntu bargainingliterature on bargaining protocols that lead to stable coalition structures (i.e., coalition structures in the core). It would beinteresting to consider whether such bargaining protocols might be developed for the present framework.AcknowledgementsWe are extremely grateful to the referees for their detailed and encouraging comments. This research was supported bya Royal Society travel grant, by the epsrc under project GR/T10657/01 (“Market Based Control of Complex ComputationalSystems”), by the U.S. Army Research Laboratory and the U.S. Army Research Office under grant number W911NF-08-1-0144,by NSF grant 0705587 and ISF #1357/07.Appendix A. Notational conventions(cid:11)(cid:11)(cid:11)Agreq, etc., etc., etc.GRG ienThe set of agents (a.k.a. players). Members of the set are typically denoted i, j, and subsets of Ag (coalitions) aredenoted by C, CThe set of overall possible goals; members are typically denoted by g, gThe set of resources, members denoted r, rThe goals of agent i ∈ Ag (G i ⊆ G).The endowment function of a crg: en : Ag × R → N. Thus en(i, r) defines how much of resource r agent i isendowed with.The requirement function of a crg: req : G × R → N. Thus req(g, r) denotes the amount of resource r required toachieve goal g.A coalitional resource game: Γ = (cid:3)Ag, G, R, G 1, . . . , Gn, en, req(cid:4).Γen(C, R) The total amount of resource r that coalition C ⊆ Ag are endowed with.req(Gsf (C)ξThe set of goals sets that are both feasible for and would satisfy C . If sf (C) (cid:13)= ∅ then we say that C are successful.A contribution vector: a C -tuple of resource vectors, the idea being that a contribution vector for C defines forevery member i of C how much of every resource i contributes. The notation ξi,r denotes how much of resourcer is contributed by agent i. A feasible contribution vector is one where every agent contributes no more than itsendowment of any given resource. We let ci(ξ ) denote the total cost of is contribution in ξ .A cooperation structure λ = (cid:3)C, Ggoals Gthe coalition, goal set, and contribution vector components of λ, and ci(λ) is shorthand for ci(ξλ).The total amount of all resources required to achieve goal set G(cid:11), ξ (cid:4) has the intended meaning that coalition C ⊆ Ag will work together to achieve(cid:11) ⊆ G, with the contribution of each agent being as defined in contribution vector ξ . Cλ, Gλ and ξλ denote(cid:11), r) The total amount of resource r required to achieve goal set G(cid:11) ⊆ G.λ(cid:11)(cid:11))req(G(cid:11)) The agents that get a goal achieved through Gsucc(G(cid:8)i(cid:11).; succ(λ) is a shorthand for succ(Gλ).Preference relation for i over cooperation structures: i prefers all cooperation structures in which it achieves itsgoals over all those in which it does not, and prefers to minimize its resource contribution.The utility i obtains from cooperation structure λ (will always be positive it i gets its goal achieved through λ).ui(λ)44P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50Table 2Resource requirements and endowments for the reduction in Proposition 9.req(· · ·)g0g1g2g3g4g5en(· · ·)aia1a2σr0r1400000040000002002r202zk00002z00r3r4003000003000300030r500003zk03z00r602k00kk200r7kk02k0002k0r800kk02k002kr900kk2k0002kr10kk2k00002k0r112k000kk200A coalition structure: a set of cooperation structures, such that the sets of agents in these cooperation structuresrepresent a partition of Ag. σ0 denotes the grand coalition achieves no goals and contributes no resources, andλσ ,i denotes the cooperation structure in σ of which i is a member.Appendix B. ProofsWe here present proofs that were omitted from the main text in the interests of readability.Proposition 9. Checking whether the core of a crg is non-empty is np-hard.Proof. We reduce from sat [26, p. 171]. An instance of sat is given by a propositional logic formula Φ over z Booleanvariables x1, . . . , xz, the aim being to answer “yes” if there is some valuation to the variables under which the formulais satisfied. Without loss of generality, we assume that z > 1 and Φ is presented in Conjunctive Normal Form (cnf), i.e.,a conjunction of k clauses:Φ =k(cid:18)i=1ψiwhere ψi is a disjunction of literals. We create an instance of the core non-emptiness problem as follows:• Possible Goals: For each literal (cid:13) occurring in Ψ we create a goal g(cid:13). We also create six additional goals, g0, . . . , g5.• Agents: For each clause ψi , we create an agent aψi , and in addition create two further agents a1 and a2. Let Agψ denotethe set of agents corresponding to clauses.• Goal sets for agents: For each agent ai ∈ Agψ , define the goal set Gai to be all the goals corresponding to literals in= {g(cid:13)1 , . . . , g(cid:13) y , g0, g5}. For agent a1 we defineψi , together with goals g0 and g5; thus if ψi = (cid:13)1 ∨ · · · ∨ (cid:13) y then GaiGa1= {g1, g2}, while for a2 we define Ga2• Resources: For each propositional variable x, we create a resource rx. We then create twelve additional resources, r0 to= {g3, g4}.r11.• Requirements: For each goal g corresponding to a variable, and resource rx, we define the quantity of rx required for gas follows:(cid:12)req(g, rx) =if g = gx or g = g¬xk0 otherwise.Requirements for {g0, g1, g2, g3, g4, g5} are given in Table 2. (Recall that z is the number of Boolean variables in thesat input formula, while k is the number of clauses.)• Endowments: For each agent ai corresponding to a clause ψi , and for each resource rx corresponding to a variable x,define the endowment function so that en(ai, r) = 1. For resources r0, . . . , r11, endowments are defined in Table 2.We prove that the core of ΓΦ is non-empty if and only if Φ is satisfiable.(⇒) Assume Φ is not satisfiable. We prove this implies the core is empty. First, observe that in this case we can in effecttreat the clause agents as a single agent, since the clause agents alone do not form a successful coalition — they canonly be satisfied by satisfying either g0 or g5.So, consider the possible cases:1. Observe that σ0 is not in the core, since no agent would have goals achieved by this coalition structure; and yet thereare successful coalitions, which would block σ0, since they would rather have their goals achieved than otherwise.P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50452. Consider the grand coalition. The grand coalition is unsuccessful. For suppose the contrary is true, and note thefollowing property:Consider any pair of distinct goals P = {gi, g j} from {g0, g1, g2, g3, g4, g5} then P can be achieved by the grandcoalition {Agψ , a1, a2} if and only if P is one of {{g0, g1}, {g2, g3}, {g4, g5}}; in all other cases there is someresource ri , 6 (cid:2) i (cid:2) 11 requiring > 2k to be expended, and the total endowment of the grand coalition, for anyresource ri , 6 (cid:2) i (cid:2) 11, is exactly 2k.(cid:11)Since Agψ cannot achieve the literal goals (from unsatisfiability) one of {g0, g5} must be in Gone of {g1, g2} is in Gwe have a contradiction, so the grand coalition is unsuccessful; and for a2 to be satisfied one of {g3, g4} must be in G(cid:11)(cid:11); for a1 to be satisfied. From the property we just stated,3. Consider coalition Agψ∪ {a1} achieving goals {g0, g1} at cost 4k + 4 to a1 (contributing its entire endowment of{r0, r7, r10}) and cost 2z + 4 to each clause agent (contributing its entire endowment of {r2, r6, r11}). This cooperationstructure would block the coalition structure in (1). The corresponding coalition structure would involve a2 beingunsuccessful.4. Consider coalition {a1, a2} achieving goals {g2, g3} at cost 4k + 3 to each agent: a1 contributes its endowment of{r4, r7, r10} while a2 contributes its endowment of {r3, r8, r9}. This cooperation structure would block the coalitionstructure in (3), since the cost to a1 is smaller and a2 is satisfied. The corresponding coalition structure would involveAgψ being unsuccessful.5. Consider coalition Agψ∪ {a2}. This coalition could achieve goals {g4, g5} at cost 4k + 2 to a2 (contributing its en-dowment of {r1, r8, r9}) and 3z + 4 to each clause agent, each of which commit their endowment of {r5, r6, r11}. Thiswould block the coalition structure in (4), since a2 would incur a lower cost while the clause agents would get theirgoals achieved. The corresponding coalition structure would involve a1 being unsuccessful.6. Finally, notice that the coalition structure in (3) would block the coalition structure in (5), since in the coalitionstructure in (3), Agψ would incur lower cost than in (5), while agent a1 would have a goal satisfied.In sum, if Φ is unsatisfiable, then every coalition structure in ΓΦ is blocked, and so the core of ΓΦ is empty.(⇐) Assume Φ is satisfiable. The reader may verify that the coalition Agψ of clause agents is successful in this case, at acost to each clause agent of at most z. In this case, the core of ΓΦ will contain a coalition structure in which:• clause agents Agψ achieve a set of goals corresponding to a valuation for Φ; and• agents a1 and a2 cooperate to achieve goals g2 and g3, at cost 4k + 3 to each.To see that such a coalition structure is stable, observe that the clause agents cannot achieve their goals any morecheaply; they will not cooperate with a1 or a2 since to do so would incur much greater cost, and so the only way thata1 and a2 can achieve their goals would be to work together. (cid:2)Proposition 11. Checking whether the core of a crg is strongly non-empty is np-hard.Proof. We reduce from sat [26, p. 171]. An instance of sat is given by a propositional logic formula Φ, the aim beingto answer “yes” if there is some valuation to the Boolean variables x1, . . . , x y that satisfies the formula. Without loss ofgenerality, we assume that Φ is presented in Conjunctive Normal Form (cnf), i.e., a conjunction of k clauses:Φ =k(cid:18)i=1ψiwhere ψi is a disjunction of literals. We create an instance of the core non-emptiness problem as follows.• For each literal (cid:13) occurring in Ψ we create a goal g(cid:13).• For each clause ψi , we create an agent aψi , and define G i to be the set of goals corresponding to the literals that occur}. Intuitively, each clause agent wants one of itsin ψi . That is, if ψi = (cid:13)1 ∨ · · · ∨ (cid:13)k, then we define G i = {g(cid:13)1 , . . . , g(cid:13)kliterals to be satisfied.• For each propositional variable x, we create a resource rx.• For each goal g and resource rx, we define the quantity of rx required for g as follows:(cid:12)req(g, rx) =if g = gx or g = g¬xk0 otherwise.• For each agent ai define its endowment function so that for all resources r, we have en(ai, r) = 1.We prove that the core of ΓΦ is strongly non-empty if and only if Φ is satisfiable:(⇒) Assume the core of ΓΦ is strongly non-empty, so the core contains some coalition structure in which some agentsexpend some resources and achieve some goals. It is immediate by construction that this coalition structure must46P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50involve the grand coalition being successful; since the requirement of any resource rx for any goal g(¬)x is k (i.e., thenumber of agents in the system) and each agent has exactly 1 unit of resource rx, to satisfy any agent’s goal wouldrequire the cooperation of the grand coalition, and moreover it would only be possible to satisfy either gx or g¬x,not both. So, if any agent was unsatisfied in the coalition structure in the strongly non-empty core, it would object,by doing nothing and achieving non of its goals. Finally, observe that if the core is strongly non-empty, then we canstraightforwardly extract a valuation for Φ from any coalition structure in the core: the goals achieved will tell us whichvariables to make true in a satisfying assignment, and the consistency of the valuation follows from the argumentsabove.(⇐) Assume Φ is satisfiable, and let ζ ⊆ {x1, . . . , x y} be a satisfying valuation. Construct a coalition structure σ ∗ =(cid:11)(cid:11), ξ (cid:4)} from ζ as follows: C is the grand coalition; in ξ every agent contributes all its resources; and define G{(cid:3)C, Gby:(cid:11) = {gx: x ∈ ζ } ∪ {g¬x: x /∈ ζ }.GWe claim σ ∗is in the core of ΓΦ . First, observe that every agent is satisfied in this coalition structure: every clauseagent has one of its goals satisfied since every clause in Φ must be satisfied by the valuation ζ . So, suppose for sakeof contradiction that σ ∗is not in the core. Then there must be an objection to it. Since every agent has their goalsatisfied, the only objection could be from some coalition that could have their goals satisfied at reduced cost. But byconstruction, every goal set corresponding to a satisfying assignment would have equal cost, (every agent would haveto contribute their entire endowment) which gives a contradiction. So σ ∗is in the core, and hence the core is stronglynon-empty. (cid:2)Proposition 12. The problem of computing a preferred contribution vector can be solved in polynomial time.(cid:11)(cid:11), the algorithm’s target is to find a contribution vector ξ thatProof. Given a set of goals Gblocks σ , if it exists. The overall algorithm for this is given in Fig. 4. The algorithm makes use of flow network construction,as follows.and a corresponding coalition CFirst, some notation. Given a set of goals G(cid:13)(cid:11)) to denote the set of resources that are required for this set of(cid:11)) = {r: r ∈ R, ∃g ∈ G s.t. req(g, r) > 0}. We use en(i) to denote the overall quantity of resources that the agent iswe use res(G(cid:11)goals, res(Gendowed with, en(i) =r∈R en(i, r).Now, we use max c(i) to denote the agent’s maximum cost in ξ in a way that (cid:3)C(cid:11)(cid:11)given Gci(ξ ) (cid:2) max c(i). In order to determine the value of max c(i) we consider the two following cases:the only cooperation structures λ = (cid:3)Cand C(cid:11), ξ (cid:4) can still block σ . In other words,(cid:11)(cid:11), ξ (cid:4) that are candidates for blocking σ are those in which ∀i ∈ C,(cid:11), G(cid:11), G1. The agent would have its goals satisfied by σ . Since the agent would have its goals satisfied both in λ and σ , the agent’scost in λ must be strictly less than in σ . Therefore max c(i) = ci(λσ ,i) − 1.2. The agent would not have its goals satisfied by σ . Since the agent would have its goals satisfied in λ but not in σ , theagent’s cost in λ can be even equal the total amount of resource that agent i ∈ Ag is endowed with, max c(i) = en(i).This is because an agent prefers all those cooperation structures which would result in one of its goals being satisfiedover all those where it is not.We thus define:(cid:12)max c(i) =ci(λσ ,i) − 1 i ∈ succ(λσ ,i)en(i)otherwise.In order to find such ξ that ∀i ∈ C(cid:11), ci(ξ ) (cid:2) max c(i) and ∀r ∈ R,network as described bellow.Given a set of goals G(cid:11) ∈ 2G and its corresponding set of agents C(cid:13)i∈C (cid:11) ξi,r (cid:3) req(G(cid:11), r), the algorithm constructs a flow(cid:11), we construct the corresponding network G f = (V , E)as follows:1. Set of vertices: V = {V A ∪ V R ∪ {s, t}} where V A represents all agents in C(cid:11)). In addition we let the source s and sink t to be two additional new vertices.res(G(cid:11)and V R corresponds to the resources in2. Set of edges: a directed edge connects between s and each vertex in V A and between each vertex in V R and t. Inaddition a directed edge connect between v i ∈ V A and v j ∈ V R if en(i, r j) > 0.(cid:10)E =(s, v i) | v i ∈ V A(v j, t) | v j ∈ V R(v i, v j) | v i ∈ V A, v j ∈ V R , en(i, r j) > 0(cid:11)(cid:10)∪(cid:11)(cid:10)∪(cid:11).3. Capacity function: for all v i ∈ V A we set c(s, v i) = max c(i). For all v j ∈ V R we set c(v j, t) = req(Gthat connects between v i ∈ V A and v j ∈ V R we set c(v i, v j) = en(i, r j).(cid:11), r j). For each edgeIntuitively:P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5047Fig. 3. The corresponding flow network G f for G(cid:11) = {g1, g2}.1. Build the corresponding flow-network G f .2. Find the maximum flow | f | in G f .3. If | f | < req(G4. For all agents i and resources r j such that (v i , v j ) ∈ E, set ξi,r j(cid:11)) then announce “no preferred contribution vector exists” and quit.= f (v i , v j ), and for all other agents iand resources r j set ξi,r j= 0.Fig. 4. Algorithm for computing a preferred contribution vector, if such exists (Proposition 12).• The flow on edges from the source s to agents will indicate an agents total contribution to the resource vector; thecapacity constraints ensure that the contribution is one that would be strictly preferred by the agent.• The capacity constraints on edge from an agent to a resource correspond to the endowment of the resource that theagent has — the flow on the edge indicates how much of the resource the agent contributes.• The flow on edges from resources to the sink node indicate how much of that resource is contributed overall (which isthe same as the total requirement for that resource).(cid:11)): if the answer is “yes”, then we canNow, we ask whether there is an integer-valued flow in G with value | f (G)| = req(G“read off ” ξ from the flow that we construct. The only problem is that maximum flow algorithm may return non-integeramounts. However the Integrality theorem shows that in case the capacity function takes only integer values if we useFord–Fulkerson method the maximum flow has the property that | f | is an integer and for all edges the value of f (u, v)is an integer [10]. Thus we can find whether such a ξ exists by running the Edmonds–Karp version of Ford–Fulkersonmethod [10]. (cid:2)Example 7. (Continuation of Example 3.) Fig. 3 shows the flow network built for {g2, g3}. The values of the maximum floware specified in the brackets. Since the value of the maximum flow (| f | = 11) equals req(G(cid:11)), σ can be blocked.Proposition 13. The algorithm in Fig. 1 is correct: if it returns “σ is stable”, then σ is indeed stable, while if it returns a cooperation(cid:11), ξ (cid:4), then this cooperation structure indeed blocks σ . Moreover, the algorithm terminates, and runs in time exponentialstructure (cid:3)Cin the number of goals in but polynomial in the number of agents and resources.(cid:11), GProof. Given a coalition structure σ , the algorithm first checks that unsuccessful agents in σ have 0 cost, i.e., that if i ∈ Agis such that i /∈ succ(λσ ,i), then ci(λσ ,i) = 0. If not, from Proposition 5, σ is not stable and the algorithm terminates.(cid:11)in 2G , whether there exists a coalition structure λ = (cid:3)C(cid:11), G(cid:11), ξ (cid:11)(cid:4) thatNext, the algorithm checks for each set of goals Gsatisfies all goals in Gand blocks the coalition structure σ .(cid:11)First note that the following agents cannot belong to the coalition C(cid:11)in the cooperation structure λ that blocks σ :1. Agents that would not have their goals satisfied by G(cid:11). Since these agents are not satisfied, ui(λ) (cid:2) 0. Thus these agentsdo not improve their utility from λ over σ .2. Agents that would have their goals satisfied by σ and have 0 cost, i.e., i ∈ succ(λσ ,i) & ci(λσ ,i) = 0. Since these agentsobtain their maximum utility from σ (U i(λσ ,i) = V ), there is no way these agents could improve their utility, and couldhence not form part of any blocking structure.Given this, we define C(cid:11)to be the set of agents that includes all agents in A g that can belong to the cooperativestructure λ that blocks σ (the agents that do not satisfy 1 and 2 above),(cid:10)(cid:14)(cid:11) =Ci: i ∈ succ(G(cid:11)) &i /∈ succ(λσ ,i) or ci(λσ ,i) > 0(cid:15)(cid:11).(B.1)48P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50In fact, it is sufficient to check only for C(cid:11)if a contribution vector ξ exists such that λ = (cid:3)C(cid:11), G(cid:11), ξ (cid:4) blocks σ : there is noneed to check for each subset of C(cid:11), as established in the following lemma. (cid:2)Lemma 1. If ∃C(cid:11)(cid:11) ⊆ C(cid:11)and a contribution vector ξ such that λ(cid:11) = (cid:3)C(cid:11)(cid:11), G(cid:11), ξ (cid:4) blocks σ , then C(cid:11)can block σ .(cid:11)(cid:11) ⊆ C(cid:11)and a contribution vector ξ such that λ(cid:11) = (cid:3)C(cid:11)(cid:11), G(cid:11), ξ (cid:4) blocks σ . We define the followingProof. Given a coalition Ccontribution vector ξ (cid:11):(cid:12)ci(ξ(cid:11)) =ci(ξ )0(cid:11)(cid:11)if i ∈ Cotherwise.(cid:11), G(cid:11), ξ (cid:11)(cid:4). Since λ(cid:11)Let λ(cid:11)(cid:11) = (cid:3)CV > ui(λσ ,i) (the agent’s utility from σ is lower than V , since we do not include agents that satisfy condition 2 in CConsequently (cid:3)C, ui(λ(cid:11)(cid:11)) = ui(λ(cid:11)) > ui(λσ ,i). Moreover, for each i /∈ Cblocks σ , for each i ∈ C(cid:11), ξ (cid:11)(cid:4) blocks σ . (cid:2), ui(λ(cid:11)(cid:11)) =(cid:11)).(cid:11), G(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)Finally, consider the running time of the algorithm. The complexity of step 2 is exponential in the number of goals, simply because it goes through all members of 2G . However, the complexity of the internal step is polynomialin G(Proposition 12). Therefore the total complexity of the algorithm is exponential in the number of goals, but polynomial inthe number of agents and resources.Proposition 20. Given the integer program problem LP( j, tthat satisfy the constraints on solutions of LP( j, tthe number of goals.(cid:11) (cid:2) j (cid:2) n, finding the cooperation structure (if one exists)(cid:11)) (Eqs. (2)–(7)) and maximizes the objective function (Eq. (1)) is exponential only in(cid:11)), 1 (cid:2) t(cid:11) (cid:2) n, t(cid:11) (cid:2) k (cid:2) j − 1 and the values of u(k, t(cid:11)) (Eqs. (1)–(7)) we assume that all the utilities values of the right sideProof. Given the integer program problem LP( j, t(cid:11)) the values of u(k, t(cid:11)) areof the constraints are already computed. This is because that when the agent calculates LP( j, t(cid:11) + 1 (cid:2) k (cid:2) n. Given this in(cid:11) + 1) are already computed for talready been calculated for torder to prove the above proposition we develop an algorithm that is similar to the algorithm we developed for checkingwhether σ can be blocked (the algorithm described in Fig. 1 in Section 4.2). Our algorithm goes through the power set of(cid:11)(cid:11), ξ (cid:11)(cid:4) (if exists) that(cid:11)= (cid:3){a}, Ggoals 2G . For each set of goals Gt, . . . , an(cid:11)satisfies the constraints of LP( j, tj ’s utility. After theand maximizes a(cid:11) ∈ 2G , it returns the cooperation structure (of all these(cid:11)j ’s utility. This cooperation structure maximizes the objective function of(cid:11)) (Eq. (1)). If no cooperation structure exists the algorithm returns that no feasible solution exists (in which case thealgorithm computes such a cooperation structure (if exists) for each Gcomputed cooperation structure) that maximizes aLP( j, tagent rejects the offer – see Proposition 14).(cid:11) ∈ 2G , the algorithm finds a cooperation structure λ(cid:11)G(cid:11)(cid:11)) (given in Eqs. (2)–(7)), satisfies all the goals in GIn the description of the algorithm we use the following definition: Given an integer program LP( j, twe use λp(k) to denote the cooperation structure that determines the minimum utility that a(cid:11)tcooperation structure that aIn order to determine λp(k) we consider the following cases:(the utility that is specified in the right side of the constraints of LP( j, t(cid:11)j proposes at round tshould be equal to or higher than the utility that a(cid:11))). Namely the utility that a(cid:11)(cid:11)(cid:11)) and an agent ak(cid:11)(cid:11)j can propose to ak at round(cid:11)k obtains from the(cid:11)k obtains from λp(k).1. If k < j, λp(k) is the cooperation structure that a2. If k > j or k = j and j (cid:13)= t3. If k = j and j = t(cid:11)(cid:11), λp(k) is the cooperation structure that a(cid:11)k proposes at round t(cid:11)., λp(k) is the singleton cooperation structure (that includes only agent a(cid:11)k proposes at round t(cid:11) + 1 computed by LP(k, t(cid:11) + 1).(cid:11)k) and maximizes the utilityof agent a(cid:11)k.(cid:11)(cid:11)k can obtain from any cooperation structure that satisfies only goals in G(cid:11)(cid:11) (cid:3) k (cid:3) n, which is not satisfied by Gbut is satisfied by λp(k), no cooperationk, tFirst note that if there exists an agent a(cid:11)can satisfy the constraints given in Eqs. (2)–(7). This is because the maximumstructure that satisfied only the goals in Gutility that acannot be greater than 0 while(cid:11)k’s utility from λp(k) is greater than 0. Therefore the algorithm can ignores Gaand continues to consider the next sets(cid:11)of goals in 2G . Thus we consider Gand λp(k).or is not satisfied both by Gin which each agent is either satisfied by G} the algorithm’s targetGiven such a set of goals Gis to find a contribution vector ξ (if exists) that satisfies constraints (Eqs. (2)–(7)), satisfies all goals in Gand maximizes(cid:11)(cid:11)c(k) (similar to the way we define max c(i) in Section 4.2) to denote agent aaj utility. For that purpose we use maxkmaximum cost in ξ in a way that constraints specified in Eqs. (2)–(7) are still satisfied. In other words the only cooperationstructures λ = (cid:3){a}, Gc(k). In orderto determine the value of max(cid:11), ξ (cid:4) that can satisfy constraints (Eqs. (2)–(7)) are those in which ∀k, ck(ξ ) (cid:2) max(cid:11), the integer program problem LP( j, tc(k) we consider the following cases:(cid:11)), and the coalition {a(cid:11)(cid:11)t(cid:11) , . . . , an(cid:11)(cid:11)t(cid:11) , . . . , an(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)(1) a(cid:11)k would have at least one of its goal satisfied by λp(k). Since the agent would have its goals satisfied both by Gλp(k), the agent’s cost in ξ must be less than or equal to its cost in λp(k). Therefore maxc(k) = ck(λp(k)).(cid:11)(cid:11)andP.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5049f min = null, G min = null.(cid:11)in 2G :(cid:11)k /∈ succ(G1.2. For each G(cid:11)(cid:11)) and a2.1. If ∃ak2.2. Build the corresponding flow-network G f .2.3. Find the minimum cost flow in G f .2.4. If f exists and one of the following conditions are satisfied:∈ succ(λp (k)) go to 2.(1) f min = null.(2) a(cid:11)(cid:11)j is not satisfied by G min.(cid:11)j is satisfied by G(cid:11)j is satisfied by G(3) aset f min = f , G min = Gf min = null return no feasible solution exists otherwise set ξk,rl(cid:11)(cid:11)t(cid:11) , . . . , anbut aand by G min and cost of f}, G min, ξ (cid:4)..(cid:11)(cid:11)3. If(cid:3){ais smaller than cost of f min,= f min(vk, vl), ∀(vk, vl) ∈ E and ξk,rl= 0, ∀(vk, vl) /∈ E, returnFig. 5. Algorithm for finding a ξ (if one exists) that satisfies constraints (2)–(7) on solutions of LP( j, t(Eq. (1)).(cid:11)) and maximizes the objective function of LP( j, t(cid:11))(2) a(3) a(cid:11)(cid:11)but not in λp(k), a(cid:11)k would has its goals(cid:11)k is endowed with,c(k) = en(k). This is because an agent prefers all those cooperation structures which would result in one of its(cid:11)k would not have its goals satisfied by λp(k) and would have its goals satisfied by Gsatisfied in Gmaxgoals being satisfied over all those where it is not.(cid:11)k would not has its goals satisfied both by λp(k) and Gequal to 0, max(cid:11)k’s cost in ξ can be even equal the total amount of resource that a. Since the agent is not satisfied, agent’s cost in ξ should bec(k) = 0.. Since a(cid:11)(cid:11)(cid:11)Consequently, we obtain:(cid:11)maxc(k) =⎧⎨⎩ck(λp(k)) k ∈ succ(Gk ∈ succ(Gen(k)k /∈ succ(G0(cid:11)) and k ∈ succ(λp(k))(cid:11)) and k /∈ succ(λp(k))(cid:11)) and k /∈ succ(λp(k)).Given an integer program LP( j, tsatisfies all goals in Gproblem.6 For that purpose the algorithm constructs the corresponding network G f = (V , E, c, b, ζ ) as follows:(cid:11)(cid:11) ,...,an(cid:11)k∈{at} ξk,r (cid:3) req(G(cid:11), r)) and maximizes a(cid:11)(∀r ∈ R,(cid:11)(cid:11) ∈ 2G , in order to find such ξ that ∀ak(cid:11)(cid:11)c(k),t, . . . , an(cid:11)j ’s utility, the algorithm solves a min cost flow}, ck(ξ ) (cid:2) max∈ {a(cid:11)(cid:11)) a set of goals G(cid:13)1. Set of vertices: V = {V A ∪ V R ∪{s, t}} where V A represents all agents in {ain res(G(cid:11)). In addition we let the source s and sink t to be two additional new vertices.(cid:11)(cid:11)t(cid:11) , . . . , an} and V R corresponds to the resources2. Set of edges: a directed edge connects between s and each vertex in V A and between each vertex in V R and t. Inaddition a directed edge connect between vk ∈ V A and vl ∈ V R if en(k, rl) > 0:(cid:10)E =(s, vk): vk ∈ V a ∪ (vl, t): vl ∈ V R ∪ (vk, vl): vk ∈ V a, vl ∈ V R , en(k, rl) > 0(cid:11)3. Capacities: for all vk ∈ V A we set c(s, vk) = maxc(k). For all vl ∈ V R we set c(vl, t) = req(Gconnects between vk ∈ V A and vl ∈ V R we set c(vk, vl) = en(k, rl).(cid:11).(cid:11), r j). For each edge that(cid:11)j ) and vl ∈ V R we set ζ (v j, vl) = 1. The4. Costs: For each edge that connects between v j (the vertex that presents agent arest of edges have no cost.5. Balances: we set b(s) = req(G(cid:11)), b(t) = −req(G(cid:11)) and 0 to the rest vertices.The following lemma follows immediately from the construction.(cid:11) ∈ 2G , there exists ξ that satisfies the constraints (2)–(7),Lemma 2. Given the integer program problem LP( j, t(cid:11)j ’s cost in ξ is equal to r, c j(ξ ) = r if and only if there exists a feasible flow in G f (that satisfies bothsatisfies all goals in Gand acapacity and balance constraints) with cost r. Moreover the amount of a resource rl ∈ R contributed by agent k, (ξk,rl ) corresponds tothe value of f (vk, vl) in the corresponding flow network G f .(cid:11)) and a set of goals G(cid:11)Given this we can find ξ (if exists) that maximizes agent aand satisfies the constraints(cid:11)) (Eqs. (2)–(7)) by running an algorithm for finding the minimum cost flow on G f . The integralityon solutions of LP( j, ttheorem for min cost flow shows that in case of flow network with costs has capacities and balances integer valued anda feasible flow in the network exists, then there is a minimum cost feasible flow which is integer valued. Furthermore,(cid:11)j utility, satisfies all goals in G(cid:11)6 Let G = (V , E, c, b, ζ ) be a directed graph defined by a set of vertices V , and a set of directed edges E. Each edge (v, u) ∈ E has a capacity c(v, u) ∈ Rand a cost ζ (v, u) ∈ R. In addition each vertex v ∈ V has a balance b(v) ∈ R. The min cost flow problem is to find a flow function f : V × V → R of(v,u)∈E ζ (v, u) f (v, u)) which satisfies the supply/demand constraints (for each vertex v ∈ V , b(v) =minimum cost (the cost of the flow is defined by(cid:13)(cid:13)(u,v)∈E f (u, v) − sum(v,u)∈E f (v, u)) and the capacity constraints (for all (v, u) ∈ E, f (v, u) (cid:3) c(v, u)) [35].50P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–50Klein’s algorithm finds such a feasible flow [21] (see [10, pp. 643–698] for a detailed discussion of related algorithms). Ouralgorithm is shown in detail in Fig. 5.The complexity of the algorithm is exponential only in the number of goals in G(cid:11). This is because the complexity of step 2, simply because it goes through all the 2G ’s subsets. However, the complexity ofis exponential in the number of goals in Gthe internal steps 2.1–2.4 is polynomial, as the problem of finding the minimum cost flow with integral data can be solvedin polynomial time [35]. Therefore the total complexity of the algorithm is only exponential in the number of goals butpolynomial in the number of agents and in number of resources. (cid:2)(cid:11)References[1] T. Ågotnes, W. van der Hoek, M. Wooldridge, Temporal qualitative coalitional games, in: Proceedings of the Fifth International Joint Conference onAutonomous Agents and Multiagent Systems (AAMAS-2006), Hakodate, Japan, 2006.[2] Y. Bachrach, J.S. Rosenschein, Computing the Banzhaf power index in network flow games, in: Proceedings of the Sixth International Joint Conferenceon Autonomous Agents and Multiagent Systems (AAMAS-2007), Honolulu, Hawaii, 2007, pp. 335–341.[3] Y. Bachrach, J.S. Rosenschein, Coalitional skill games, in: Proceedings of the Seventh International Joint Conference on Autonomous Agents and Multia-gent Systems (AAMAS-2008), Honolulu, Hawaii, 2008.[4] S. Banerjee, H. Konishi, T. Sonmez, Core in a simple coalition formation game, Social Choice and Welfare 18 (2001) 135–153.[5] F. Bloch, E. Diamantoudi, Noncooperative formation of coalitions in hedonic games, Unpublished working paper, 2005.[6] A. Chakrabarti, L. de Alfaro, T.A. Henzinger, M. Stoelinga, Resource interfaces, in: Proceedings of the Third International Conference on EmbeddedSoftware (EMSOFT), in: LNCS, vol. 2855, Springer-Verlag, Berlin, 2003, pp. 117–133.[7] G. Chalkiadakis, E. Markakis, C. Boutilier, Coalition formation under uncertainty: Bargaining equilibria and the Bayesian core stability concept, in:Proceedings of the Sixth International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-2007), Honolulu, Hawaii, 2007.[8] K. Chatterjee, B. Dutta, D. Ray, K. Sengupta, A noncooperative theory of coalitional bargaining, The Review of Economic Studies 60 (2) (1993) 463–477.[9] V. Conitzer, T. Sandholm, Complexity of constructing solutions in the core based on synergies among coalitions, Artificial Intelligence 170 (2006)607–619.[10] T.H. Cormen, C.E. Leiserson, R.L. Rivest, Introduction to Algorithms, The MIT Press, Cambridge, MA, 1990.[11] P. Cramton, Y. Shoham, R. Steinberg (Eds.), Combinatorial Auctions, The MIT Press, Cambridge, MA, 2006.[12] X. Deng, C.H. Papadimitriou, On the complexity of cooperative solution concepts, Mathematics of Operations Research 19 (2) (1994) 257–266.[13] P.E. Dunne, M. Wooldridge, M. Laurence, The complexity of contract negotiation, Artificial Intelligence 164 (1–2) (2005) 23–46.[14] E. Elkind, L. Goldberg, P. Goldberg, M. Wooldridge, Computational complexity of weighted threshold games, in: Proceedings of the Twenty-Second AAAIConference on Artificial Intelligence (AAAI-2007), Vancouver, British Columbia, Canada, 2007.[15] U. Endriss, J. Lang (Eds.), Proceedings of the First International Workshop on Computational Social Choice Theory 2006 (COMSOC-2006), Amsterdam,The Netherlands, December 2006.[16] S. Hart, A. Mas-Colell, Bargaining value, Econometrica 64 (2) (1996) 357–380.[17] M. Horniacek, Negotiation, preferences over agreements, and the core, International Journal of Game Theory 37 (2) (2008) 235–249.[18] C.Y. Huang, T. Sj ˝ostr ˝om, Consistent solutions for cooperative games with externalities, Games and Economic Behavior 43 (2003) 196–213.[19] C.Y. Huang, T. Sj ˝ostr ˝om, Implementation of the recursive core for partition function form games, Journal of Mathematical Economics 42 (2003) 771–793.[20] S. Ieong, Y. Shoham, Marginal contribution nets: A compact representation scheme for coalitional games, in: Proceedings of the Sixth ACM Conferenceon Electronic Commerce (EC’05), Vancouver, Canada, 2005.[21] M. Klein, A primal method for minimum cost flows with application to the assignment and transportation problem, Management Science 14 (1967)205–220.[22] S. Kraus, Strategic Negotiation in Multiagent Environments, The MIT Press, Cambridge, MA, 2001.[23] Benny Moldovanu, Eyal Winter, Order independent equilibria, Games and Economic Behavior 9 (1995) 21–34.[24] M. Naor, On fairness in the carpool problem, Journal of Algorithms 55 (2005) 93–98.[25] M.J. Osborne, A. Rubinstein, A Course in Game Theory, The MIT Press, Cambridge, MA, 1994.[26] C.H. Papadimitriou, Computational Complexity, Addison–Wesley, Reading, MA, 1994.[27] M. Perry, P.J. Reny, A noncooperative view of coalition formation and the core, Econometrica 62 (4) (1994) 795–817.[28] J.S. Rosenschein, G. Zlotkin, Rules of Encounter: Designing Conventions for Automated Negotiation among Computers, The MIT Press, Cambridge, MA,1994.[29] T. Sandholm, K. Larson, M. Andersson, O. Shehory, F. Tohmé, Coalition structure generation with worst case guarantees, Artificial Intelligence 111 (1–2)(1999) 209–238.[30] R. Serrano, R. Vohra, Non-cooperative implementation of the core, Journal Social Choice and Welfare 14 (4) (1997) 513–525.[31] O. Shehory, S. Kraus, Coalition formation among autonomous agents: Strategies and complexity, in: C. Castelfranchi, J.-P. Müller (Eds.), From Reactionto Cognition — Fifth European Workshop on Modelling Autonomous Agents in a Multi-Agent World, MAAMAW-93, in: LNAI, vol. 957, Springer-Verlag,Berlin, 1995, pp. 56–72.[32] O. Shehory, S. Kraus, Task allocation via coalition formation among autonomous agents, in: Proceedings of the Fourteenth International Joint Conferenceon Artificial Intelligence (IJCAI-95), Montréal, Québec, Canada, August 1995, pp. 655–661.[33] O. Shehory, S. Kraus, Methods for task allocation via agent coalition formation, Artificial Intelligence 101 (1–2) (1998) 165–200.[34] Y. Shoham, K. Leyton-Brown, Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations, Cambridge University Press, Cambridge, 2008.[35] P.T. Sokkalingam, R.K. Ahuja, J.B. Orlin, New polynomial-time cycle-canceling algorithms for minimum-cost flows, Networks 36 (1) (2000) 53–63.[36] J.J. Vidal-Puga, A bargaining approach to the consistent value for NTU games with coalition structure, Unpublished working paper, 2003.[37] M. Wooldridge, An Introduction to Multiagent Systems, John Wiley & Sons, New York, 2002.[38] M. Wooldridge, P.E. Dunne, On the computational complexity of qualitative coalitional games, Artificial Intelligence 158 (1) (2004) 27–73.[39] M. Wooldridge, P.E. Dunne, On the computational complexity of coalitional resource games, Artificial Intelligence 170 (10) (2006) 853–871.