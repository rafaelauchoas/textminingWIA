Artificial Intelligence 174 (2010) 551–569Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOptimal query complexity bounds for finding graphsSung-Soon Choi a,1, Jeong Han Kim a,b,∗,2a Department of Mathematics, Yonsei University, Seoul, 120-749, Republic of Koreab National Institute for Mathematical Sciences, Daejeon, 305-340, Republic of Koreaa r t i c l ei n f oa b s t r a c tWe consider the problem of finding an unknown graph by using queries with an additiveproperty. This problem was partially motivated by DNA shotgun sequencing and linkagediscovery problems of artificial intelligence.Given a graph, an additive query asks the number of edges in a set of vertices whilea cross-additive query asks the number of edges crossing between two disjoint sets ofvertices. The queries ask the sum of weights for weighted graphs.For a graph G with n vertices and at most m edges, we prove that there exists an algorithmto find the edges of G using O( m log n2log(m+1) ) queries of both types for all m. The bound is bestpossible up to a constant factor. For a weighted graph with a mild condition on weights, itlog m ) queries are enough provided m (cid:2) (log n)α for a sufficiently largeis shown that O( m log nconstant α, which is best possible up to a constant factor if m (cid:3) n2−ε for any constantε > 0.This settles, in particular, a conjecture of Grebinski [V. Grebinski, On the power of additivecombinatorial search model, in: Proceedings of the 4th Annual International Conferenceon Computing and Combinatorics (COCOON 1998), Taipei, Taiwan, 1998, pp. 194–203] forfinding an unweighted graph using additive queries. We also consider the problem offinding the Fourier coefficients of a certain class of pseudo-Boolean functions as well asa similar coin weighing problem.m© 2010 Elsevier B.V. All rights reserved.Article history:Received 6 August 2008Received in revised form 12 February 2010Accepted 13 February 2010Available online 21 February 2010Keywords:Combinatorial searchCombinatorial group testingGraph findingCoin weighingFourier coefficientPseudo-Boolean functionLittlewood–Offord theorem1. Introduction1.1. Graph finding problemThe problem of finding a graph is stated as follows. Suppose that a graph G has n vertices and at most m edges and thatthe edges of G are unknown. We may consider two types of queries, additive queries and cross-additive queries. An additivequery asks the number of edges in a set of vertices while a cross-additive query asks the number of edges crossing betweentwo disjoint sets of vertices. The problem is to find the edges of G by using as few queries as possible.Additive queries have been motivated by a main process in shotgun sequencing [6,20]. Shotgun sequencing is a methodto determine the whole genome sequence in an organism’s DNA. In shotgun sequencing, it is required to order decoded* Corresponding author at: National Institute for Mathematical Sciences, Daejeon, 305-340, Republic of Korea.E-mail addresses: ss.choi@yonsei.ac.kr (S.-S. Choi), jehkim@nims.re.kr (J.H. Kim).1 This research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry ofEducation, Science and Technology (CRI, No. 2008-0054850).2 This work was partially supported by Yonsei University Research Funds 2006-1-0078 and 2007-1-0025, and by the second stage of the Brain Korea 21Project in 2007, and by the Korea Research Foundation Grant funded by the Korean Government (MOEHRD) (KRF-2006-312-C00455).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.02.003552S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569fragments (called contigs) of the genome sequence. Given a set of contigs, a method called the multiplex PCR method [39]tells how many pairs of the contigs are adjacent in the original sequence. Thus, the task of ordering contigs is reduced tothe problem of finding an unknown graph, which is a Hamiltonian cycle or path, by using additive queries. See e.g., [20].Cross-additive queries have been motivated by the problem of finding the Fourier coefficients for a certain class ofpseudo-Boolean functions. A pseudo-Boolean function is a real-valued function defined on the set of binary sequences. It isk-bounded if it can be expressed as a sum of subfunctions each of which depends on at most k input bits. For example,given a 2-SAT formula, the number of clauses an assignment satisfies is a 2-bounded pseudo-Boolean function. In molecularbiology and biophysics, k-bounded functions have been used to study the evolution of a population of organisms in anenvironment [25]. Specifically, k-bounded functions with small k have received attention in modeling living systems [26]and real biological objects [17]. In evolutionary computation, k-bounded functions have been also used as a benchmark forcomparing heuristic algorithms [18,32,33,38]. Cross-additive queries are used to find the Fourier coefficients of 2-boundedfunctions. More generally, cross-additive queries for k-bounded hypergraphs can be used to find the Fourier coefficients ofk-bounded functions, where k-bounded hypergraphs are hypergraphs whose hyperedges are of size at most k.An algorithm to find an unknown graph is called non-adaptive if each query in the algorithm is independent of theanswers for the previous queries. Otherwise, it is called adaptive. Non-adaptive algorithms are preferable to adaptive onesparticularly when the number of required queries is fairly large and parallel computation is available. There have beena number of papers addressing the problem of finding a graph using additive queries. When the (unknown) graph is aHamiltonian cycle on n vertices, Grebinski and Kucherov [20] presented an adaptive algorithm using O(n) additive queries,which is the best possible up to a constant factor. Later, Grebinski and Kucherov [21] provided an extensive work for severaltypes of graphs. In particular, for graphs with maximum degree bounded by d, they proved the existence of a non-adaptivealgorithm using O(dn) additive queries. When the graph is k-degenerate, the existence of a non-adaptive algorithm usingO(kn) additive queries was shown by Grebinski [19].The fully general case that the graph has n vertices and at most m edges has been a matter of primary concern. It hasbeen conjectured by Grebinski [19] that there exists an algorithm to find the unknown graph using O(m) additive queriesprovided that m = Ω(n). The conjecture has not been settled for a decade. For general m, an adaptive algorithm usingO(m log n) additive queries by Angluin and Chen [4] is the best known to date. In fact, their algorithm uses less powerfulqueries called membership queries, which ask the oracle only about the existence of an edge in a set of vertices. (There havealso been a number of papers addressing the problem of finding a graph using membership queries [2,3,5–7].) Recently,Reyzin and Srivastava [34] presented a simpler adaptive algorithm using O(m log n) additive queries. In this paper, we provethe conjecture of Grebinski in a stronger form, namely the existence of a non-adaptive algorithm using O( m log n2queries. This bound is best possible and better than O(m) if log n2m(cid:3) log m, in particular, m > n2log(m+1) ) additivelog n .mWe shall focus on bounds for the number of required cross-additive queries. Note that cross-additive queries are lessstrong than additive queries since a cross-additive query for the disjoint sets S, T of vertices can be answered by the threeadditive queries for S ∪ T , S, and T . It can be easily shown that the converse is not true: For example, for a graph withexactly one edge, Ω(log n) cross-additive queries are required to verify that it has only one edge while one additive queryis enough to verify the same. In the rest of this paper, we state results with respect to cross-additive queries. The samestatements hold for additive queries after simple modifications if necessary.In this paper, we consider two versions of the graph finding problem. The first one isProblem 1 (Unweighted graphs).Input:Output:an unweighted graph G for which the only information given is that– G has the vertex set {1, . . . , n} and at most m edgesthe edges of GFor the query complexity of the problem, we have the following.Theorem 1.1. There is a non-adaptive algorithm that solves Problem 1 using O( m log n2mlog(m+1) ) cross-additive queries.The second is a generalized one for weighted graphs with a moderate condition on weights of edges.Problem 2 (Weighted graphs).Input:Output:a weighted graph G for which the only information given is that– G has the vertex set {1, . . . , n} and at most m edges– the weights of edges of G are between nthe edges of G−a and nb in absolute valueS.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569553For weighted graphs, a cross-additive query asks the sum of weights of the edges crossing between two disjoint sets ofvertices. We obtain bounds for the number of cross-additive queries required to solve the problem.Theorem 1.2. For any fixed constants a, b > 0, there are a constant α > 0 and a non-adaptive algorithm that solves Problem 2 usingO( m log nlog m ) cross-additive queries provided m (cid:2) (log n)α .This extends the result of the conference version [13] that gives the bound when m is at least a constant power of n.3Concerning the condition on weights, a remark is provided in Section 7.Notice that we focused only on query complexity of algorithms. The presented algorithms are not computationally ef-ficient and we do not try to optimize them in time complexity. In terms of query complexity, the bounds in the abovetheorems are optimal up to a constant factor for all or almost all m by the information-theoretic lower bounds. For un-weighted graphs, the bound is optimal for all m. For weighted graphs, the bound is optimal if m (cid:3) n2−ε for any constantε > 0. We do not know yet that the bound is optimal for m in the other range, and we conjecture that it is so up to aconstant factor. Theorem 1.2 implies the existence of an algorithm that finds the weights of all edges with the same querybound. This is because, once all edges are discovered, the weights of edges can be found by using at most m additionalqueries (one for each edge). It is not difficult to show that the algorithm is optimal by an information-theoretic lowerbound argument.1.2. Related problemsRelated to the graph finding problem, we consider the coin weighing problem and the problem of finding the Fouriercoefficients of a 2-bounded function.The problem of finding a graph can be regarded as an extension of the coin weighing problem. In the coin weighingproblem, we are given n coins among which there are some counterfeits. All the authentic coins have the same weight andthe weight is known. Authentic and counterfeit coins are indistinguishable from each other except that their weights aredifferent. Given a group of coins, the scale tells the sum of weights of the coins. The problem is to find the counterfeitsusing the scale as few times as possible. There are a few papers addressing the case where the weights of counterfeits areidentical [1,29,37]. When the weight of each counterfeit is a positive integer and the total weight of counterfeits is boundedabove by m, Lindström [28] constructed a non-adaptive algorithm to find the counterfeits with O(m log n) weighings. Underthe same condition, Grebinski and Kucherov [21] proved the existence of a non-adaptive algorithm with an optimal numberlog m ) weighings provided that m (cid:3) n1−ε for anyof weighings up to a constant factor. In particular, the algorithm uses O( m log nconstant ε > 0. In this paper, we show that the bound holds even for the general case that the weight of each counterfeitis nearly arbitrary provided that the number of counterfeits is at most m. The formal definition of the problem concernedis as follows.Problem 3 (Coin weighing).Input:Output:coins for which the only information given is that– the total number of coins is n, and there are at most m counterfeits among them– all the authentic coins have the same weight and the weight is known– the weight difference between each counterfeit and an authentic coin is between nthe set of counterfeit coins−a and nbFor this problem, we haveTheorem 1.3. For any fixed constants a, b > 0, there is a non-adaptive algorithm that solves Problem 3 with O( m log nlog (m+1) ) weighings.There have been many studies of the problem of finding the Fourier coefficients of a k-bounded pseudo-Boolean functionf : {0, 1}n → R where k is a constant. Kargupta and Park [24] presented a deterministic adaptive algorithm that uses O(nk)function evaluations. Later, Heckendorn and Wright [22] proposed a randomized adaptive algorithm. For the k-boundedfunctions with O(n) non-zero Fourier coefficients generated from a random model, they analyzed the algorithm to showthat, with negligible error probability, it finds the Fourier coefficients in O(n2 log n) function evaluations on average. Byanalyzing the algorithm of Heckendorn and Wright, Choi, Jung, and Moon [12] proved that, for a k-bounded function withm non-zero Fourier coefficients, O(γ (n, m)m log n) function evaluations are enough with negligible error probability, where1γ (n, m) is between n2 and n depending on m. Recently, Choi, Jung, and Kim [11] provided a randomized adaptive algorithmto find the Fourier coefficients with high probability in O(m log n) function evaluations.3 While this paper was in the review process, we learned that for additive queries, Bshouty and Mazzawi [8] improved our result to get the bound forarbitrary m.554S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569Table 1Summary of results.nmrange of mconditionon weightsCoin weighing# of coinsupper bound on# of counterfeits1 (cid:3) m (cid:3) n# of verticesupper bound on# of edges(cid:2)n21 (cid:3) m (cid:3)(cid:3)−a and nbbetween n(weight differences)N/Aquery complexityoptimalityO( m log nlog (m+1) )for m (cid:3) n1−εO( m log n2for all mlog(m+1) )mUnweighted graphsWeighted graphsFourier coefficients# of verticesupper bound on# of edges(log n)α (cid:3) m (cid:3)(cid:3)(cid:2)n2−a and nbbetween nin absolute value(edge weights)O( m log nlog m )for m (cid:3) n2−ε# of input variablesupper bound on# of non-zerocoefficients(log n)α (cid:3) m (cid:3)(cid:2)+ n + 1n2between nin absolute value(non-zero coefficients)−a and nb(cid:3)O( m log nlog m )for all mFor the problem of finding weights as well, all above bounds are optimal for all m.In this paper, we consider the problem for 2-bounded functions with a mild condition on Fourier coefficients as follows.Problem 4 (Fourier coefficients).Input:Output:is a 2-bounded pseudo-Boolean function defined on {0, 1}na function f for which the only information given is that– f– f has at most m non-zero Fourier coefficients– the non-zero Fourier coefficients of f are between nthe Fourier coefficients of f−a and nb in absolute valueAs we will see, the problem of finding the Fourier coefficients of a 2-bounded function is reduced to a combination ofthe coin weighing problem and the graph finding problem using cross-additive queries. We have the following corollaryfrom Theorems 1.2 and 1.3. An algorithm is called k-round if the sequence of queries (q1, . . . , q(cid:6)) used by the algorithmcan be divided into k parts (q1 , . . . , q(cid:6)1 ), (q(cid:6)1+1, . . . , q(cid:6)2 ), . . . , (q(cid:6)k−1+1, . . . , q(cid:6) ) so that each part is non-adaptive given theprevious parts. A non-adaptive algorithm is a one-round algorithm. The k-round algorithms with smaller k are preferable asthey can be executed using k sets of parallel computations.Corollary 1.4. For any fixed constants a, b > 0, there are a constant α > 0 and a 4-round algorithm that solves Problem 4 in O( m log nlog m )function evaluations provided m (cid:2) (log n)α .For the 2-bounded functions described in the corollary, the algorithm improves the bound of Choi, Jung, and Kim [11]by a factor of log m and it is deterministic and fairly non-adaptive. There have been many papers addressing the problem offinding the Fourier coefficients of Boolean functions [9,23,31]. We, however, think that the problem is not closely related toour problem as it is believed that there are not many non-trivial 2-bounded Boolean functions.As for the theorems for the graph finding problem, we may show the optimality up to a constant factor for the abovetwo theorems by information-theoretic lower bound arguments. Theorem 1.3 is optimal if m (cid:3) n1−ε for any constant ε > 0.However, for the problem of finding weights of coins, it implies the existence of an algorithm with optimal query complexityfor all m. By the same argument, Corollary 1.4 is optimal for all m in the specified range.Table 1 summarizes our results.1.3. OrganizationTo prove our results, we use an inequality describing the anti-concentration property of a sum of independent randomvariables. It is a generalized Littlewood–Offord theorem [14,30] and easily follows from the previous generalizations in-cluding ones in [15,16,27,35,36]. We describe the theorem in the next section. In Section 3, we prove Theorem 1.3 (coinweighing) using probabilistic methods. The proof is relatively easy to follow and it would be a good illustration of how thegeneralized Littlewood–Offord theorem is used. We prove Theorem 1.1 (unweighted graphs) in Section 4 and Theorem 1.2(weighted graphs) in Section 5. In Section 6, Corollary 1.4 is proved by showing how the problem of finding the Fourier co-efficients of a 2-bounded pseudo-Boolean function is reduced to the graph finding problem and the coin weighing problem.Concluding remarks will follow in the last section.2. Anti-concentration inequalityRandom variables of a certain type are highly concentrated near their means with high probability. There are a fewinequalities describing the concentration property. An example is the Chernoff bound [10], which shows that the sum ofS.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569555i.i.d. random variables is highly concentrated near its mean. On the other hand, the Littlewood–Offord theorem [14,30]describes the anti-concentration property of the sum of independent random variables. It gives an upper bound for theprobability that the sum of independent random variables having two different values is in an interval. There are severalgeneralizations of the theorem including those in [15,16,27,35,36]. We are going to use the following form, which can befound in [27]. It is actually not hard to derive it using the original Littlewood–Offord theorem.Theorem 2.1 (Generalized Littlewood–Offord theorem). Let a1, . . . , an, b1, . . . , bn and s > 0 be real numbers such that bi − ai (cid:2) s for1 (cid:3) i (cid:3) n and let X1, . . . , Xn be independent random variables. Suppose that there is p with 0 < p < 1 such that Pr[ Xi (cid:3) ai] (cid:2) p andPr[ Xi (cid:2) bi] (cid:2) p for all 1 (cid:3) i (cid:3) n. Then, for any real number r,(cid:6)(cid:4)Prr (cid:3)n(cid:5)i=1Xi (cid:3) r + s(cid:3) 2.6√pn.A version we will frequently use isCorollary 2.2. Let ρ be a positive integer and s be a positive real number. Let X1, . . . , Xn be independent random variables at least(cid:7)t Xi ’s of which satisfy Pr[ Xi = 0] (cid:2) p and Pr[| Xi| (cid:2) s] (cid:2) p for some p with 0 < p < 1. Then, the probability thatni=1 Xi is in aninterval of length ρs is at most 3.7ρ√pt.Proof. Without loss of generality, it may be assumed that Pr[ Xi = 0] (cid:2) p and Pr[| Xi| (cid:2) s] (cid:2) p for i = 1, . . . , t. This impliesthat Pr[ Xi = 0] (cid:2) p2 for i = 1, . . . , t. Since Xi ’s are independent, by Theo-(cid:3) 3.7√rem 2.1, the probability that.pt(cid:7)i=1 Xi conditioned on Xi ’s with i > t is in an interval of length s is at most 2.6n(cid:7)i=1 Xi is in an interval of length s and the corollary follows by union bound. (cid:2)n2 and, either Pr[ Xi (cid:2) s] (cid:2) p2 or Pr[ Xi (cid:3) −s] (cid:2) pThus, so is the probability that√2√pt3. Coin weighing problemIn this section, we prove Theorem 1.3. As the weight of an authentic coin is known in the coin weighing problem, wemay assume that the weight of an authentic coin is 0 and the weight of each counterfeit is non-zero (possibly negative).An instance of the coin weighing problem may be regarded as an n-dimensional vector whose coordinates are given by theweights of coins. For an instance x = (xi)ni=1, let sp(x) denote the support set of x, that is, the set of counterfeit coins in x.Similarly, a query can be regarded as a binary vector and a sequence of (cid:6) queries as an (cid:6) × n binary matrix.The basic idea for the proof of Theorem 1.3 is as follows. A sequence of queries, or a binary matrix M, separates a pairof instances x, y if a query in the sequence yields different answers for the two instances, i.e., Mx (cid:7)= M y. A sequence ofqueries separates a set of instances if it separates every pair of instances in the set with distinct supports. In a non-adaptivealgorithm, its sequence of queries must separate the set of all instances. If there were only finitely many possible instances,such a sequence might be enough as the given instance can be identified by checking all possible instances. Since thereare uncountably many instances, we consider a set of discretized instances: Let I be the set of all instances x = (xi) such−(a+3). We prove the existence of a sequence S of queries separating I by more than mthat xi is a multiple of nna+3 , i.e.,na+3 for the binary matrix M induced by S and x, y ∈ I with distinct supports. We will write MS (x) for(cid:8)Mx − M y(cid:8)∞ > mMx when we need to specify the sequence S.Lemma 3.1. There exists a sequence S of (cid:6) queries with (cid:6) = O( m log nlog (m+1) ) such that(cid:8)(cid:8)(cid:8)MS (x) − MS ( y)(cid:8)∞ >mna+3for all x, y ∈ I with sp(x) (cid:7)= sp( y).Once such a sequence S of queries is found, the following holds.Lemma 3.2. Suppose that x is a given instance. Then,(i) there exists y ∈ I such that sp(x) = sp( y) and(cid:8)(cid:8)(cid:8)MS (x) − MS ( y)(cid:8)(cid:3) m2na+3;∞(ii) for all z ∈ I with (cid:8)MS (x) − MS (z)(cid:8)∞ (cid:3) m2na+3 , sp(z) = sp(x).556S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569Proof. Let yi be the closest multiple of nand sp( y) = sp(x) as |xi| (cid:2) n−a if xi (cid:7)= 0. The inequality in (i) follows from the fact that−(a+3) to xi with ties broken by preferring the smaller one. Then, y belongs to I(cid:8)(cid:8)(cid:8)MS (x) − MS ( y)(cid:8)(cid:3)∞n(cid:5)i=1|xi − yi| (cid:3) m2na+3.For (ii), if (cid:8)MS (z) − MS (x)(cid:8)∞ (cid:3) mna+3 , sp(z) must be sp( y), which is sp(x). (cid:2)m2na+3 , (cid:8)MS (z) − MS ( y)(cid:8)∞ (cid:3) mna+3 by triangle inequality. Since S separates I by more thanLemmas 3.1 and 3.2 give Theorem 1.3 by the following algorithm.Algorithm// x is an unknown instance.compute MS (x);1for each z ∈ I2345return sp( y);if (cid:8)MS (x) − MS (z)(cid:8)∞ (cid:3) my ← z and break;2na+3 ,Now, we prove Lemma 3.1. Let D be the set of differences of instances in I with distinct supports, i.e., the set of vectorsx − y for all x, y ∈ I with sp(x) (cid:7)= sp( y). Since MS (·) is linear for a fixed sequence S, Lemma 3.1 is equivalent to saying thatthere exists a sequence S of (cid:6) queries such that (cid:8)MS (x)(cid:8)∞ > mna+3 for all x ∈ D. A probabilistic method is used to provethe following lemma, which immediately implies Lemma 3.1. In the following, a uniform random query means a uniformrandom binary vector sampled from {0, 1}n.Lemma 3.3. There exists a constant c > 0 such that(cid:9)PrThere is x in D such that(cid:8)(cid:8)(cid:8)MS (x)(cid:8)(cid:3) mna+3∞(cid:10)= o(1)for a sequence S of (cid:6) = cm log nlog (m+1) independent uniform random queries.Notice that for all x ∈ D, there is i such that |xi| (cid:2) n−a since x is the difference of a pair of instances with distinct−a, thesupports. For a uniform random query q, since flipping the ith bit of q changes the answer χq(x) by at least n−(cid:6). On the otherprobability of |χq(x)| < 1is at most 1/2. Thus, the probability of (cid:8)MS (x)(cid:8)∞ (cid:3) mna+3 < 12na2naO(m log n). If m is bounded from above, then we may take largehand, the size |D| of D is at most−(cid:6) is notenough c so that 2enough to use the union bound as the size of D is larger than 2(cid:6) unless m is bounded from above. However, if thereare many, say t, i’s such that |xi| (cid:2) m) by the generalized Littlewood–Offord theorem presented in Section 2. Observing this, we have the following lemma. Hereafter, “P (m) holds for sufficientlylarge m” means that there is a constant m0 > 0 such that P (m) holds for all m (cid:2) m0.−(cid:6)|D| = o(1). We may now assume that m is sufficiently large. It turns out that the bound 2na+3 , then the probability of |χq(x)| (cid:3) mna+3(cid:3)(4na+b+3)i = eis O( 1√tis at most 2(cid:2)ni2mi=1(cid:7)Lemma 3.4. For sufficiently large m, the following holds: Suppose that x ∈ D has at leastmna+3 in absolute value and q is a uniform random query. Then,(cid:9)Pr(cid:11)(cid:11)(cid:11) (cid:3) m(cid:11)χq(x)na+3(cid:10)(cid:3) m−0.4.mlog(m+1) coordinates larger than or equal toProof. Let Xi ’s be random variables such that Xi = xi if qi = 1 and Xi = 0 otherwise. Then, the lemma immediately follows(cid:7)log (m+1) i’s, | Xi| (cid:2)by the generalized Littlewood–Offord theorem as χq(x) =ni=1 Xi , Xi ’s are independent, and, for at leastna+3 with probability 1m2 while it is 0 with probability 12 . (cid:2)mLet D1 be the set of all x ∈ D with less thanmlog (m+1) coordinates larger than or equal to mna+3 in absolute value andD2 = D \ D1. Lemma 3.4 implies(cid:9)PrThere is x in D2 such that(cid:10)(cid:8)(cid:8)(cid:8)MS (x)(cid:8)(cid:3) mna+3∞(cid:3) |D|m−0.4(cid:6) = o(1)(1)for a large enough constant c in (cid:6) = cm log nthan mna+3 in absolute value with 0. Letlog (m+1) . For x ∈ D1, let ˜x be the vector obtained by replacing the coordinates in x less˜D1 be the set of all such ˜x. Notice that ˜x ∈ ˜D1 has at least one coordinate whoseS.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569557−a. The same argument mentioned above gives Pr[(cid:8)MS (˜x)(cid:8)∞ < 1−(cid:6) and the union bound2na ] (cid:3) 2absolute value is at least nyields(cid:9)PrThere is ˜x in ˜D1 such that(cid:8)(cid:8)(cid:8)MS (˜x)(cid:8)∞ <(cid:10)12na(cid:3) | ˜D1|2−(cid:6) (cid:3) 2−(cid:6)(cid:12)m(cid:5)log (m+1)(cid:13)(cid:13)(cid:12)n(cid:2)i=1i(cid:3)4na+b+3i = o(1)for a large enough constant c in (cid:6). Since(cid:8)(cid:8)(cid:8)(cid:8)MS (˜x)(cid:8)(cid:8)(cid:8)MS (x)(cid:8)−(cid:2)(cid:8)(cid:8)(cid:8)(cid:8)MS (x − ˜x)∞∞(cid:8)(cid:8)(cid:8)(cid:8)MS (˜x)∞(cid:2)∞− 2m2na+3and mna+3na+3 < 1+ 2m2(cid:9)2na , we havePrThere is x in D1 such that(cid:10)(cid:8)(cid:8)(cid:8)MS (x)(cid:8)(cid:3) mna+3∞(cid:9)(cid:3) PrThere is ˜x in ˜D1 such that(cid:8)(cid:8)(cid:8)MS (˜x)(cid:8)∞(cid:3) mna+3+ 2m2na+3(cid:10)= o(1).(2)Lemma 3.3 follows by (1) and (2).4. Finding graphsIn this section, we prove Theorem 1.1. Unlike the coin weighing problem, the number of all possible instances is finite asgraphs are unweighted. Thus, a desired algorithm is immediately obtained by a sequence of cross-additive queries separatingevery pair of all possible graphs. To be more precise, let G be the set of all graphs on the vertex set [n] = {1, . . . , n} havingat most m edges. For a graph G ∈ G and a sequence S of (cid:6) cross-additive queries, MS (G) is the (cid:6)-dimensional vectorconsisting of the answers of the (cid:6) queries for G. The following implies Theorem 1.1.Lemma 4.1. There exists a sequence S of (cid:6) cross-additive queries such that (cid:6) = O( m log n2mlog(m+1) ) and(cid:8)(cid:8)(cid:8)MS (G) − MS (H)(cid:8)∞ > 0for all distinct G, H ∈ G.We now prove Lemma 4.1. For two graphs G, H ∈ G, define the difference graph G − H to be the graph of which vertexset is [n] and edge set is (E(G) \ E(H)) ∪ (E(H) \ E(G)). Edges in E(G) \ E(H) have weight 1 and edges in E(H) \ E(G) haveweight −1. Let D be the set of difference graphs G − H for distinct G, H ∈ G. As the answer of a query for a differencegraph G − H ∈ D is the answer for G minus the answer for H ,MS (G − H) = MS (G) − MS (H)for any sequence S of queries. Thus, Lemma 4.1 is equivalent to saying that there exists a sequence S of O( m log(n2/m)log(m+1) )queries such that (cid:8)MS (G)(cid:8)∞ > 0 for all G ∈ D. A random query (S, T ) means a cross-additive query for a pair of randomsets of vertices S, T such that each vertex independently belongs to S, T , and none of S and T , each with probability 13 sothat S ∩ T = ∅. We prove the following to obtain Lemma 4.1.Lemma 4.2. There exists a constant c > 0 such that(cid:14)There is G in D such thatPr(cid:8)(cid:8)(cid:8)MS (G)(cid:8)(cid:15)= 0∞= o(1)for a sequence S of (cid:6) = cm log(n2/m)log(m+1)independent random queries.Let μS,T (G) be the answer of a cross-additive query (S, T ) for a graph G. For G ∈ D, since G is the difference graph oftwo distinct graphs, G has at least one edge. By this fact, we have the following.Lemma 4.3. For G ∈ D and a random query (S, T ),(cid:15)(cid:14)μS,T (G) = 0Pr(cid:3) 89.558S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569Proof. Take an edge e = {x, y} in G. We consider (S, T ) conditioned on ˜S = S ∩ ([n] \ {x, y}) and ˜T = T ∩ ([n] \ {x, y}). Inother words, all vertices except x and y are determined to be in S, T , or none of them. We show that μS,T (G) (cid:7)= 0 when(S, T ) is one of ( ˜S, ˜T ), ( ˜S ∪ {x}, ˜T ), ( ˜S, ˜T ∪ { y}), and ( ˜S ∪ {x}, ˜T ∪ { y}), each of which occurs with probability 1/9.The sum of weights of edges crossing between ˜S ∪ {x} and ˜T is that of edges crossing between ˜S and ˜T plus that ofedges crossing between {x} and ˜T . Similarly, the sum of weights of edges crossing between ˜S and ˜T ∪ { y} is that of edgescrossing between ˜S and ˜T plus that of edges crossing between ˜S and { y}. Thus, letting w G (e) be the weight of e,μ ˜S∪{x}, ˜T ∪{ y}(G) = w G (e) + μ ˜S∪{x}, ˜T (G) + μ ˜S, ˜T ∪{ y}(G) − μ ˜S, ˜T (G).If the last three terms are all 0, then μ ˜S∪{x}, ˜T ∪{ y}(G) = w G (e) (cid:7)= 0. (cid:2)(cid:7)(cid:3)(cid:2)(n2)2i = eiThus, the probability of (cid:8)MS (G)(cid:8)∞ = 0 is at most ( 8O(m log (n2/m)), wemay take large enough c in (cid:6) = cm log(n2/m)so that (8/9)(cid:6)|D| = o(1) if m is bounded above. It may now be assumed that mlog(m+1)is sufficiently large. The bound (8/9)(cid:6) is not enough to use the union bound as the size of D is larger than (9/8)(cid:6) unlessm is bounded above. Notice that, for a random query (S, T ), μS,T (G) is a sum of weights of edges in G chosen randomly. Ifthe edges were chosen independently, one might hope to prove Lemma 4.2 by dividing D into two classes according to thenumber of edges as in the coin weighing problem. However, there is a dependency among edges in general and the graphswith many edges are further divided into subclasses to handle the dependency.9 )(cid:6). As the size of D is at most2mi=1Precisely, we divide D into four classes D1, D2, D3, and D4. The class D1 consists of graphs in D that have only few(log (m+1))2 edges. The class D2 consists of graphs in D that have many vertices of high degree. Toedges, namely, less thanbe precise, let δ = 0.1 and define U (G) for a graph G ∈ D to be the set of vertices of degree at least mδ in G. The class D2is the set of graphs G in D with the size of U (G) being mδ or more. Define W (G) = [n] \ U (G). The class D3 is the set ofgraphs G in D \ (D1 ∪ D2) such that there are at least2(log (m+1))2 edges crossing between U (G) and W (G). The class D4 ismD \ (D1 ∪ D2 ∪ D3). It turns out that, for G ∈ D2 or D4 and a random query (S, T ), Pr[μS,T (G) = 0] is polynomially smallin m. On the other hand, it is not true for some graphs in D3 (e.g., the graphs G such that the size of U (G) is a constantindependent of n and there is no edge with both ends in W (G)). Instead of focusing on a single query, we consider queriescollectively for graphs in D3. Except for a negligible probability, there is a constant portion of the (cid:6) random queries for eachgraph in D3 that give polynomially small bounds in m as shown below.mWe consider four cases G ∈ Di , i = 1, . . . , 4, and show that(cid:14)PrThere is G in Di such that(cid:8)(cid:8)(cid:8)MS (G)(cid:8)(cid:15)= 0∞= o(1)for a large enough constant c in (cid:6).Case 1. G ∈ D1.As the number of graphs in D1 is at mostby Lemma 4.3.Case 2. G ∈ D2.Clearly, there are at most(cid:7)2mi=1(cid:3)(cid:2)(n2)2i = ei(cid:7)(cid:12)m(log(m+1))2i=1(cid:13)(cid:3)(cid:2)(n2)2i = eiO( m log(n2/m)log(m+1) ), the desired inequality immediately followsfollowing lemma. The proof is based on two applications of the generalized Littlewood–Offord theorem.O(m log (n2/m)) graphs in D2. Thus, the desired inequality is obtained by theLemma 4.4. For sufficiently large m, the following holds: Suppose that G is a graph in D2 and (S, T ) is a random query. Then,(cid:14)μS,T (G) = 0Pr(cid:15)(cid:3) m−0.01δ.Proof. As |U (G)| (cid:2) mδ , we may choose a subset Q of U (G) with |Q | = (cid:12)m0.1δ(cid:13). Denote by H the spanning subgraph ofG consisting of the edges in G except those with both ends in Q . (A spanning subgraph is a subgraph containing all thevertices of the original graph.) The lemma follows by showing that(cid:14)(cid:11)(cid:11)(cid:11)μS,T (H)(cid:11) (cid:3) m0.2δPr(cid:15)−0.01δ(cid:3) mfor a random query (S, T ). This is because there are at mostimplies |μS,T (H)| (cid:3) m0.2δ .Given a pair of disjoint sets ( A, B) of vertices in ¯Q := [n] \ Q , we say a vertex v in Q is bad for ( A, B) if the sum ofweights of edges crossing between A and v is less than m0.2δ in absolute value, that is, |μ A,v (H)| < m0.2δ . (We simply write(cid:3)(cid:2)|Q |2(cid:3) m0.2δ edges with both ends in Q so that μS,T (G) = 0S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569559μ A,v (H) for μ A,{v}(H).) A pair ( A, B) is called bad if there is a bad vertex in Q for ( A, B). It is good otherwise. Letting( ˜S, ˜T ) = (S ∩ ¯Q , T ∩ ¯Q ), we have(cid:14)(cid:11)(cid:11)(cid:11)μS,T (H)(cid:11) (cid:3) m0.2δPr(cid:15)=(cid:15)(cid:14)( ˜S, ˜T )Pr(cid:14)(cid:11)(cid:11)(cid:11)μS,T (H)(cid:11) (cid:3) m0.2δPr(cid:11)(cid:15)(cid:11)( ˜S, ˜T ).(cid:5)( ˜S, ˜T )The right hand side may be upper bounded by(cid:15)(cid:5)(cid:14)( ˜S, ˜T ) is badPr+(cid:14)Pr(cid:15)( ˜S, ˜T )(cid:14)(cid:11)(cid:11)(cid:11)μS,T (H)(cid:11) (cid:3) m0.2δ(cid:11)(cid:15)(cid:11)( ˜S, ˜T ).Pr( ˜S, ˜T ) goodThus, it is enough to show that each of the above two terms is polynomially small in m, say mFor a vertex v ∈ Q , μ ˜S,v (H) is a sum of weights of edges {v, u} with u ∈ ¯Q chosen independently and with probability 13 .As v is adjacent to at least mδ − |Q | (cid:2) mδ2 vertices in ¯Q , the generalized Littlewood–Offord theorem gives−0.04δ .(cid:14)Pr(cid:15)v is bad for ( ˜S, ˜T )= Pr(cid:14)(cid:11)(cid:11)(cid:11)μ ˜S,v (H)(cid:11) < m0.2δ(cid:15)(cid:3) m−0.2δ.Thus,(cid:14)( ˜S, ˜T ) is badPr(cid:15)(cid:3) |Q | · m−0.2δ (cid:3) m−0.1δ.Now, we show that, given the event that ( ˜S, ˜T ) is good, the probability of |μS,T (H)| (cid:3) m0.2δ is polynomially small in m.To this end, we consider the condition that ( ˜S, ˜T ) is fixed to be a good pair. Since there is no edge of H with both endsin Q , μS,T (H) is decomposed intoμS,T (H) = μS∩Q , ˜T (H) + μ ˜S,T ∩Q (H) + μ ˜S, ˜T (H).For a vertex v in Q , let Y v be a random variable such that Y v = μv, ˜T (H) if v ∈ S, Y v = μ ˜S,v (H) if v ∈ T , and Y v = 0otherwise. Then, μS∩Q , ˜T (H) + μ ˜S,T ∩Q (H) =v∈Q Y v and(cid:7)μS,T (H) =Y v + μ ˜S, ˜T (H).(cid:5)v∈Q(cid:7)Since there is no bad vertex of Q for ( ˜S, ˜T ), |Y v | (cid:2) m0.2δ if v ∈ T , which occurs with probability 1Y v = 0 if v /∈ S ∪ T , which also occurs with probability 1probability that |v∈Q Y v + μ ˜S, ˜T (H)| (cid:3) m0.2δ is at most many good pair ( ˜S, ˜T ),(cid:14)(cid:11)(cid:11)(cid:11)μS,T (H)(cid:11) (cid:3) m0.2δ3 . On the other hand,3 . Since Y v ’s are independent and the size of Q is (cid:12)m0.1δ(cid:13), the−0.04δ by the generalized Littlewood–Offord theorem. That is, for(cid:11)(cid:15)(cid:11)( ˜S, ˜T )−0.04δ.(cid:3) mPr(cid:2)Case 3. G ∈ D3.As mentioned above, a bound better than a constant may not be obtained for a random query for some graphs in D3.Taking this into account, we use a conditioning argument for the random queries in a collective sense to prove the desiredinequality. We start with the following lemma.Lemma 4.5. For sufficiently large m, the following holds: Suppose that G is a graph in D3. Then, there is a pair of disjoint sets of vertices( A, B) such that(i) 0 < | A| (cid:3) 2m2δ and |B| = (cid:12)mδ(cid:13),(ii) for each v ∈ B, there is u ∈ A that is adjacent to v, and(iii) for all u ∈ B and v ∈ [n] \ A, u and v are not adjacent.mProof. We prove the lemma by constructing the desired pair ( A, B). As G ∈ D3, the number of edges crossing between U (G)2(log (m+1))2 )/mδ (cid:2)2(log (m+1))2 . Since each vertex in W (G) is of degree less than mδ , there are at least (and W (G) is at leastm8δ vertices in W (G) that are adjacent to at least one vertex in U (G). Thus, we may iteratively choose (cid:12)mδ(cid:13) such verticesthat are not adjacent to each other. This is possible as vertices in W (G) are of degree less than mδ and m8δ/(1 + mδ) (cid:2) mδ .The set B consists of these vertices.The set A consists of vertices in U (G) and vertices in W (G) \ B that are adjacent to a vertex in B. Since G /∈ D2 andthere are at most |B|mδ vertices in W (G) \ B described above, | A| (cid:3) |U (G)| + |B|mδ (cid:3) 2m2δ . Hence the properties (i)–(iii)follow. (cid:2)m560S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569LetFor each graph G in D3, we choose a pair of disjoint sets of vertices ( A, B) satisfying the properties in Lemma 4.5and denote by H(G) the bipartite subgraph of G on A ∪ B consisting of all edges in G between them. Recall that S isthe sequence of random queries (S, T ). Once all vertices in ¯B := V (G) \ B are determined to be in S, T or none of themfor the random queries (S, T ), MS (G[ ¯B]) is determined, where G[ ¯B] is the induced subgraph of G on ¯B. Also, MS (G) =MS (H(G)) + MS (G[ ¯B]).˜S be the sequence of restricted random queries ( ˜S, ˜T ) on ¯B. Then we may write M ˜S (G[ ¯B]) for MS (G[ ¯B]) asMS (G[ ¯B]) depends only on ˜S. The quantity (cid:8)MS (H(G)) + M ˜S (G[ ¯B])(cid:8)∞ turns out to be zero with small enough proba-˜S. For the set H of all possible bipartite graphs H , say on A ∪ B, satisfying (i) and (ii) in Lemma 4.5, webility for most ofdivide the event {∃G ∈ D3 such that (cid:8)MS (G)(cid:8)∞ = 0} into events F H := {∃G ∈ D3 with H(G) = H such that (cid:8)MS (G)(cid:8)∞ = 0},H ∈ H. Observe that(cid:14)∃G ∈ D3 such thatPr(cid:8)(cid:8)(cid:8)MS (G)(cid:8)Pr[F H ].(cid:9) (cid:16)= Pr= 0(cid:5)F H(cid:3)(cid:10)(cid:15)∞(cid:7)H∈HH∈H˜S Pr[ ˜S] Pr[F H | ˜S], and will show that Pr[F H | ˜S] is small enough for mostTo estimate Pr[F H ], we further consider Pr[F H ] =of˜S.For a given graph H ∈ H on A ∪ B and the restricted random query ( ˜S, ˜T ) on ¯B, a vertex v ∈ B is called bad, if the sumof weights of edges between v and ˜S ∩ A is 0, i.e., μv, ˜S∩ A(H) = 0. The restricted random query ( ˜S, ˜T ) is bad if more than|B| vertices of B are bad for ( ˜S, ˜T ). The sequence ˜S = ( ˜S i, ˜T i)(cid:6)i=1 is called bad if the number of bad queries ( ˜S i, ˜T i) is more34than 9(cid:6)10 . The sequence is good if it is not bad. Observe thatPr[F H ] (cid:3) Pr[ ˜S bad] + Pr[F H and ˜S good] = Pr[ ˜S bad] +Pr[ ˜S] Pr[F H | ˜S].(cid:5)(3)We first show that Pr[ ˜S bad] is small enough.˜S goodLemma 4.6. For a given H ∈ H on A ∪ B, there is a constant β < 1 such that Pr[ ˜S bad] (cid:3) β(cid:6).Proof. We first show that a vertex v ∈ B is bad with probability at most 2/3. For each vertex v ∈ B, take u ∈ A that isadjacent to v in H . Assuming ˜S i ∩ A \ {u} is determined, there are three possibilities for u, u ∈ ˜S i , u ∈ ˜T i or u /∈ ˜S i ∪ ˜T i . Ifμv, ˜S i ∩ A\{u}(H) (cid:7)= 0, then v is not bad provided u /∈ ˜S i ∪ ˜T i , which occurs with probability 1/3. If μv, ˜S i ∩ A\{u}(H) = 0, thenu ∈ ˜S i implies that |μv, ˜S i ∩ A(H)| = 1. As u ∈ ˜S i with probability 1/3, v ∈ B is bad with probability at most 2/3.Therefore, the expected number of bad vertices in B is at most 23|B| and hence the probability that more than 3|B|/4vertices in B is bad is at most 8/9 by Markov’s inequality. This implies that the expected number of bad queries ( ˜S i, ˜T i)in ˜S is less than or equal to 8(cid:6)/9. Since ( ˜S i, ˜T i) are i.i.d., Chernoff’s large deviation inequality yields Pr[ ˜S bad] (cid:3) β(cid:6), for aconstant β < 1. (cid:2)For an upper bound of the second part of (3), observe that(cid:11)(cid:11) ˜S(cid:14)(cid:8)(cid:8)MS (H) + M ˜SPr[F H | ˜S] (cid:3)G[ ¯B]= 0(cid:3)(cid:8)(cid:8)(cid:5)Pr(cid:2)∞(cid:15).(4)G:H(G)=HWe show thatLemma 4.7. For sufficiently large m, the following holds: Suppose that ˜S is a good sequence of restricted random queries ( ˜S i, ˜T i) on ¯B.Then,(cid:14)(cid:8)(cid:8)MS (H) + M ˜SPr(cid:2)(cid:3)(cid:8)(cid:8)G[ ¯B]= 0∞(cid:15)(cid:11)(cid:11) ˜S(cid:3) m−δ(cid:6)/30.Proof. Without loss of generality, it may be assumed that ( ˜S i, ˜T i) is good for 1 (cid:3) i (cid:3) (cid:6)/10. For each i in the range, we may|B|4 good vertices in B. (Of course, it actually means (cid:12)|B|/4(cid:13).) Under the condition that ( ˜S i, ˜T i) is givenchoose a set B i ofand all the vertices in B \ B i have been determined to be in S i , T i , or none of them for the fully extended query (S i, T i),the event that a vertex v ∈ B i belongs to T i (or none of S i and T i , resp.), which occurs with probability 1/3, changes thesum of weights of edges crossing between S i and T i by at least 1 (or does not change the sum, resp.) independently ofthe other vertices in B i . Thus, the generalized Littlewood–Offord theorem yields that the sum of weights of edges crossingbetween S i and T i is a fixed number with probability at most |B i|−0.4. Since |B i| = |B|10 , areindependent,(cid:2) m0.9δ and (S i, T i), 1 (cid:3) i (cid:3) (cid:6)4(cid:14)(cid:8)(cid:8)MS (H) + M ˜SPr(cid:2)(cid:3)(cid:8)(cid:8)G[ ¯B]= 0∞(cid:15)(cid:11)(cid:11) ˜S(cid:3) m−δ(cid:6)/30.(cid:2)S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569561Since there are at mostO(m log (n2/m)) graphs in D3, the above lemma and (4) imply thatPr[F H | ˜S] (cid:3) exp(cid:2)m log(cid:2)n2/m(cid:3)(cid:3)+ O(cid:2)(cid:3) exp−m log(cid:3)(cid:3)(cid:2)n2/m,(cid:13)(cid:3)(cid:2)(n2)2i = ei(cid:7)2mi=1(cid:12)− δ(cid:6) log m30for large enough c in (cid:6) = cm log(n2/m)log(m+1). With this inequality and Lemma 4.6, (3) givesPr[F H ] (cid:3) β(cid:6)/2,and we finally have(cid:14)∃G ∈ D3 such thatPr(cid:8)(cid:8)(cid:8)MS (G)(cid:8)= 0∞(cid:5)(cid:15)(cid:3)Pr[F H ] (cid:3) |H|β(cid:6)/2.H∈HAs the number of edges in a graph in H is at most 2m3δ and the number of possible edge weights (including 0) is atmost 3, we have|H| (cid:3) 32m3δ(cid:12)(cid:18)n(cid:17)mδ(cid:13) (cid:12)2m2δ (cid:13)(cid:5)(cid:13)(cid:12)nii=1−(cid:6)/4(cid:3) βand the desired inequality follows.Case 4. G ∈ D4.For graphs G ∈ D4, we need two lemmas for the desired bound. The following is based on the fact that there are manyedges with both ends in W (G) while each vertex in W (G) has a bounded degree.Lemma 4.8. For sufficiently large m, the following holds: Suppose that G is a graph in D4. Then, G has an induced matching consistingof (cid:12)mδ(cid:13) edges.(cid:2)|U (G)|Proof. As G /∈ D1 ∪ D2 ∪ D3, there are at leastm2(log (m+1))2edges crossing between U (G) and W (G) (as G /∈ D3). Since the size of U (G) is less than mδ (as G /∈ D2), there are at4(log (m+1))2 edges with both ends in W (G) formostsufficiently large m. Considering edges with both ends in W (G) only, iteratively take an edge e and delete e and all edgesthat share a vertex with e. Since each vertex in W (G) has a degree less than mδ , we are able to take at least(log (m+1))2 edges in G (as G /∈ D1) and there are less than2 edges with both ends in U (G). Thus, there are at least(cid:3) m2δmm(cid:3)2(cid:12)m4(log (m + 1))2(cid:13)(cid:19)(cid:2)2mδ + 1(cid:3)(cid:2) mδedges. The first (cid:12)mδ(cid:13) such edges constitute an induced matching as desired. (cid:2)Since there are at most(cid:7)2mi=1(cid:3)(cid:2)(n2)2i = eiO(m log (n2/m)) different graphs in D4, the following lemma yields the desiredbound. To prove the lemma, the above lemma and the generalized Littlewood–Offord theorem are used.Lemma 4.9. For sufficiently large m, the following holds: Suppose that G is a graph in D4 and (S, T ) is a random query. Then,(cid:14)μS,T (G) = 0Pr(cid:15)(cid:3) m−0.4δ.Proof. According to Lemma 4.8, G has an induced matching consisting of (cid:12)mδ(cid:13) edges. Let B be the set of the verticesin the induced matching. We consider a random query (S, T ) conditioned on ˜S := S ∩ ¯B, ˜T := T ∩ ¯B, where ¯B := [n] \ B.Let e1, . . . , e(cid:12)mδ(cid:13) be the (cid:12)mδ(cid:13) edges in the induced matching. For each edge ei = {ui, v i}, let Xi be the random variablerepresenting the contribution of ui and v i to the value μS,T (G) so thatμS,T (G) =(cid:12)mδ (cid:13)(cid:5)i=1Xi + μ ˜S, ˜T (G).This is possible since ei ’s are the only edges of G with both ends in B and they are pairwise disjoint. It is now possible to(G) + w G (ei)use the same argument used in Lemma 4.3. For each i, Xi may be 0, μui , ˜T (G), μ ˜S,v ieach with probability 1/9, corresponding to the events {ui, v i /∈ S ∪ T }, {ui ∈ S, v i /∈ S ∪ T }, {ui /∈ S ∪ T , v i ∈ T }, and {ui ∈ S,v i ∈ T }, respectively. Since |w G (ei)| = 1, at least one of the last three values is 1/3 or more in absolute value. In particular,Xi = 0, | Xi| (cid:2) 1/3 each with probability at least 1/9. By the generalized Littlewood–Offord theorem, the probability that(cid:7)(cid:12)mδ (cid:13)(G) or μui , ˜T (G) + μ ˜S,v i−0.4δ and hence so is the probability that μS,T (G) = 0. (cid:2)i=1 Xi + μ ˜S, ˜T (G) is a fixed number is at most m562S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–5695. Finding weighted graphsIn this section, we prove Theorem 1.2. As in the coin weighing problem, we consider a set of discretized graphs toextend the idea for unweighted graphs to weighted ones. Precisely, let G be the set of all possible graphs considered in−a and nb in absolute value.Theorem 1.2, i.e., the set of graphs on [n] having at most m edges whose weights are between n−(a+6). A sequence S of queries separates a set of graphs ifLet I be the set of graphs in G with weights in multiples of nit separates every pair of graphs in the set with different sets of edges. We prove the existence of a sequence of queriesseparating I by more than mna+6 . As in the previous section, MS (G) denotes the vector whose coordinates are given by theanswers of a sequence S of queries for a graph G.Lemma 5.1. There exists a sequence S of (cid:6) cross-additive queries such that (cid:6) = O( m log nlog m ) and(cid:8)(cid:8)(cid:8)MS (G) − MS (H)(cid:8)∞ >mna+6for all G, H ∈ I with E(G) (cid:7)= E(H).Given such a sequence S, the following holds. We omit the proof as it is essentially the same as that of Lemma 3.2.Lemma 5.2. Suppose that G is a graph in G.(i) There exists H ∈ I such that E(G) = E(H) and(cid:8)(cid:8)(cid:8)MS (G) − MS (H)(cid:8)(cid:3) m2na+6.∞(ii) For all I ∈ I with (cid:8)MS (G) − MS (I)(cid:8)∞ (cid:3) m2na+6 , E(I) = E(G).Lemmas 5.1 and 5.2 imply Theorem 1.2 by the following algorithm: Given an unknown graph G in G, compute MS (G)2na+6 . The set of edges in H is the one that we are looking for. In thisand find H ∈ I such that (cid:8)MS (G) − MS (H)(cid:8)∞ (cid:3) malgorithm, O( m log nlog m ) queries are required only in computing MS (G) and they are non-adaptive.In the rest of this section, we prove Lemma 5.1. For two graphs G, H ∈ I, define the difference graph G − H to be theweighted graph of which vertex set is [n] and edge set consists of those edges e with w G (e) − w H (e) (cid:7)= 0. Here, we use theconvention that w G (e) = 0 if e is not an edge of a weighted graph G. The weight of an edge e in G − H is w G (e) − w H (e).Let D be the set of difference graphs G − H for G, H ∈ I with E(G) (cid:7)= E(H). Then, the following lemma implies Lemma 5.1.As in the previous section, a random query (S, T ) means a cross-additive query for a pair of random sets of vertices S, Tsuch that each vertex independently belongs to S, T , and none of S and T , each with probability 13 so that S ∩ T = ∅.Lemma 5.3 (Main lemma). There exists a constant c > 0 such thatPrThere is G in D such that(cid:8)(cid:8)(cid:8)MS (G)(cid:8)(cid:3) mna+6∞(cid:10)= o(1)for a sequence S of (cid:6) = cm log nlog m independent random queries.Notice that there may be edges of very small weight, e.g.,1na+6 , in absolute value. For that reason, it seems hard to proveLemma 5.3 by dividing the graphs in D regardless of weights of edges as in the proof for unweighted graphs. We divide Dinto four classes D1, D2, D3, and D4 based on weights of edges. For the division of cases, we need to classify edges intoin absolute value. An edge isthree types according to their weights. An edge is called heavy if its weight is at leastcalled light if its weight is less than mna+6 in absolute value. An edge that is neither heavy nor light is called middleweight. Theclass D1 consists of graphs in D that have only few heavy edges, namely, less than mlog m heavy edges. The class D2 consistsof graphs in D that have many vertices incident with many heavy or middleweight edges. To be precise, let δ = 0.1 anddefine U (G) for a weighted graph G to be the set of the vertices that are incident with at least mδ heavy or middleweightedges. The class D2 is the set of graphs G in D with the size of U (G) being mδ or more. Define W (G) = [n] \ U (G). Theclass D3 is the set of graphs G in D \ (D1 ∪ D2) such that there are at least2 log m heavy edges crossing between U (G) andW (G). The class D4 is D \ (D1 ∪ D2 ∪ D3). We consider four cases G ∈ Di , i = 1, . . . , 4, and show that18mnamPrThere is G in Di such that(cid:8)(cid:8)(cid:8)MS (G)(cid:8)(cid:3) mna+6∞(cid:10)= o(1)provided m (cid:2) (log n)α for a large constant α. The condition for the range of m is only used to derive the result for thesecond case, G ∈ D2 (see Lemma 5.4).(cid:9)(cid:9)Case 1. G ∈ D1.S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569563For G ∈ D1, let ˜G be the graph obtained by removing the middleweight and light edges from G. Let4na , S separates D1 by more than m˜D1 denote the setof such graphs ˜G. It turns out that if S separates ˜D1 by at leastna+6 . We first derive−a in absolute value as G is aan inequality fordifference graph of two graphs in I with different sets of edges. Thus, every H ∈ ˜D1 has such an edge and Pr[|μS,T (H)| <˜D1 is at most4na ] for a random query (S, T ) is at most 8/9 by the same argument used in Lemma 4.3. As the size of1(cid:7)(cid:12) mlog mi=1˜D1. Notice that for G ∈ D1, there is an edge in G of weight at least n(cid:3)(cid:2)(n2)(4na+b+6)i = eiO( m log nlog m )1(cid:13)(cid:9)PrThere is H in ˜D1 such that, the union bound yields(cid:10)(cid:8)(cid:8)(cid:8)MS (H)(cid:8)∞ <14na(cid:3) | ˜D1|(cid:13)(cid:6)(cid:12)89= o(1)(5)for a large enough constant c in (cid:6) = cm log nlog m .Since G − ˜G consists of at most 2m − 1 middleweight or light edges,(cid:8)(cid:8)(cid:8)(cid:8)MS (G − ˜G)(cid:8)(cid:8)(cid:8)(cid:8)MS ( ˜G)(cid:8)(cid:8)(cid:8)MS (G)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)MS ( ˜G)−(cid:2)(cid:2)∞∞∞− 2m − 18mna.∞4na and (5) imply(cid:8)(cid:8)(cid:8)MS (G)(cid:8)(cid:10)(cid:3) mna+6∞The fact that mna+6(cid:9)+ 2m−18mna < 1PrThere is G in D1 such that(cid:9)(cid:3) PrThere is ˜G in ˜D1 such thatCase 2. G ∈ D2.(cid:8)(cid:8)(cid:8)MS ( ˜G)(cid:8)(cid:3) mna+6∞+ 2m − 18mna(cid:10)= o(1).The proof for D2 is analogous to that of the second case for unweighted graphs. Let us first show that there is a set ofvertices incident with many edges of weights in some range while the weights of edges in the set are properly bounded.Lemma 5.4. For some constants α > 0 and m0 > 0, the following holds provided m (cid:2) m0 and m (cid:2) (log n)α : Suppose that G is a graphin D2. Then, for s = mna+6 , there exist Q ⊆ [n] and i (cid:2) 0 such that(i) the size of Q is (cid:12)m0.1δ(cid:13),(ii) each edge with both ends in Q has a weight less than 2i+1s in absolute value, and(iii) each vertex in Q is incident with at least m0.8δ edges with weights in [2i s, 2i+1s) in absolute value.Proof. An edge in G is called type i if the absolute value of its weight is in [2i s, 2i+1s). For each vertex v of G, denotedi(v) to be the number of edges of type i containing v. Notice that a vertex v ∈ U (G) is contained in at least mδ edgeswith weights s = mna+6 or more in absolute value and all weights of edges are at most 2nb in absolute value. Let t be thet−1i=0 di(v) (cid:2) mδ and t = O(log n). Hence, we choose a large enough α > 0 sominimum integer such that 2t s > 2nb. Then,that there is an integer i with 0 (cid:3) i (cid:3) t − 1 such that di(v) (cid:2) m0.8δ if m (cid:2) (log n)α . We decompose U (G) into U 0, . . . , U t−1so that v ∈ U i for the largest i with di(v) (cid:2) m0.8δ . As the size of U (G) is at least mδ , there is i such that the size of U i is atleast m0.95δ . Notice that all vertices in U i satisfy the property (iii).(cid:7)To construct the desired vertex set Q , we iteratively take a vertex u in U i and delete u and all vertices in U i that areadjacent to u by an edge of type j for some j > i. Then, each time at most (t − i − 1)m0.8δ + 1 (cid:3) m0.85δ vertices in U i are tobe deleted and hence we are able to take (cid:12)m0.1δ(cid:13) vertices in U i , which is the property (i). The property (ii) follows by theconstruction. (cid:2)Clearly, there are at mostfollowing lemma as (cid:6) = cm log n(cid:7)(cid:2)(cid:3)(n2)(4na+b+6)i = ei2mi=1O(m log n) graphs in D2. The desired bound for D2 is obtained by thelog m . The proof uses Lemma 5.4 and is essentially the same as that of Lemma 4.4.Lemma 5.5. For some constants α > 0 and m0 > 0, the following holds provided m (cid:2) m0 and m (cid:2) (log n)α : Suppose that G is a graphin D2 and (S, T ) is a random query. Then,(cid:11)(cid:11)(cid:11) (cid:3) m(cid:11)μS,T (G)na+6−0.01δ.(cid:3) mPr(cid:10)(cid:9)564S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569Proof. For G ∈ D2, we choose Q and i satisfying the properties in Lemma 5.4. Denote by H the spanning subgraph of Gconsisting of the edges in G except those with both ends in Q . By (i) and (ii) of Lemma 5.4, the sum of weights of edgeswith both ends in Q is at most(cid:11)(cid:11)(cid:11)μS,T (H)(cid:11) (cid:3)(cid:3)(cid:2)|Q |2i+1s (cid:3) 2i sm0.2δ in absolute value. Thus, |μS,T (G)| (cid:3) mna+6(cid:11)(cid:11)(cid:11) (cid:3) s + 2i sm0.2δ (cid:3) 2i+1sm0.2δ(cid:11)μS,T (G − H)(cid:11)(cid:11)(cid:11) +(cid:11)μS,T (G)= s implies2as i (cid:2) 0. To obtain the inequality, it is enough to show(cid:14)(cid:11)(cid:11)(cid:11)μS,T (H)(cid:11) (cid:3) 2i+1sm0.2δ−0.01δ.(cid:3) mPr(cid:15)For a pair of disjoint sets ( A, B) of vertices in ¯Q := [n] \ Q , we say a vertex v ∈ Q is bad for ( A, B) if the sum ofweights of edges in H crossing between A and v is less than 2i+1sm0.2δ in absolute value, that is, |μ A,v (H)| < 2i+1sm0.2δ .A pair ( A, B) is called bad if there is a bad vertex in Q for ( A, B). It is good otherwise. Letting ( ˜S, ˜T ) = (S ∩ ¯Q , T ∩ ¯Q ),Pr[|μS,T (H)| (cid:3) 2i+1sm0.2δ] is upper bounded by(cid:15)(cid:14)( ˜S, ˜T ) is badPr(cid:14)(cid:11)(cid:11)(cid:11)μS,T (H)(cid:11) (cid:3) 2i+1sm0.2δ(cid:15)(cid:14)( ˜S, ˜T )Pr(cid:11)(cid:15)(cid:11)( ˜S, ˜T ).(cid:5)Pr+( ˜S, ˜T ) goodThus, it is enough to show that each of the above two terms is polynomially small in m, say mFor a vertex v ∈ Q , μ ˜S,v (H) is a sum of weights of edges {v, u} with u ∈ ¯Q chosen independently and with probability 13 .edges {v, u} with |w H (uv)| (cid:2) 2i s, the generalized Littlewood–Offord theorem givesAs there are at least m0.8δ − |Q | (cid:2) m0.8δ2−0.04δ .(cid:14)Pr(cid:15)v is bad for ( ˜S, ˜T )= Pr(cid:14)(cid:11)(cid:11)(cid:11)μ ˜S,v (H)(cid:11) < 2i+1sm0.2δ(cid:15)(cid:3) m−0.15δ.Thus, the union bound yields(cid:14)(cid:15)There is a bad vertex in Q for ( ˜S, ˜T )Pr−0.05δ.(cid:3) |Q | · m−0.15δ (cid:3) mNow, we show that, given the condition that ( ˜S, ˜T ) is a fixed pair without a bad vertex in Q , the probability of|μS,T (H)| (cid:3) 2i+1sm0.2δ is polynomially small in m. Since there is no edge of H with both ends in Q , μS,T (H) is μ ˜S, ˜T (H)plus a sum of contributions Y v of v over v ∈ Q such that Y v is μv, ˜T (H), μ ˜S,v (H), and 0 when v belongs to S, T , and noneof them, respectively. The contribution Y v changes at least |μ ˜S,v (H)| (cid:2) 2i+1sm0.2δ according to v ∈ T or v /∈ S ∪ T , each of3 . As Y v ’s are independent for fixed ( ˜S, ˜T ) and the size of Q is (cid:12)m0.1δ(cid:13), the probability ofwhich occurs with probability 1−0.04δ by the generalized Littlewood–Offord theorem. That is, for any good pair ( ˜S, ˜T ),|μS,T (H)| (cid:3) 2i+1sm0.2δ is at most m(cid:14)(cid:11)(cid:11)(cid:11)(cid:15)(cid:11)μS,T (H)(cid:11)( ˜S, ˜T )(cid:11) (cid:3) 2i+1sm0.2δ−0.04δ.(cid:3) mPr(cid:2)Case 3. G ∈ D3.The proof is analogous to that of the third case for unweighted graphs. We start with the following lemma similar toLemma 4.5.Lemma 5.6. For sufficiently large m, the following holds: Suppose that G is a graph in D3. Then, there is a pair of disjoint sets of vertices( A, B) such that(i) 0 < | A| (cid:3) 2m2δ and |B| = (cid:12)mδ(cid:13),(ii) for each v ∈ B, there is u ∈ A that is adjacent to v by a heavy edge, and(iii) for all u ∈ B and v ∈ [n] \ A, u and v are joined only by a light edge.m2 log m . Since each vertex in W (G) is incident to less than mδ heavy edges, there are ( mProof. We construct the desired pair ( A, B). As G ∈ D3, the number of heavy edges crossing between U (G) and W (G) is2 log m )/mδ (cid:2) m8δ vertices inat leastW (G) that are adjacent to at least one vertex in U (G) by a heavy edge in G. Thus, we may iteratively choose (cid:12)mδ(cid:13) suchvertices that are not adjacent to each other by heavy or middleweight edges, as vertices in W (G) are incident to at mostmδ heavy or middleweight edges and m8δ/(1 + mδ) (cid:2) mδ . The set B consists of these vertices.The set A consists of vertices in U (G) and vertices in W (G) \ B that are adjacent to a vertex in B by a heavy ormiddleweight edge. Since G /∈ D2 and there are at most |B|mδ vertices in W (G) \ B described above, | A| (cid:3) |U (G)| + |B|mδ (cid:3)2m2δ . Hence the properties (i)–(iii) follow. (cid:2)For each graph G in D3, we choose a pair of disjoint sets of vertices ( A, B) satisfying the properties in Lemma 5.6and H(G) denotes the bipartite subgraph of G on A ∪ B consisting of all edges in G between them. Recall that S is thesequence of random queries (S, T ). Once all vertices in ¯B := V (G) \ B are determined to be in S, T or none of them forS.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569565the random queries (S, T ), MS (G[ ¯B]) is determined, where G[ ¯B] is the induced subgraph of G on ¯B. It is expected that(cid:8)MS (H(G)) + MS (G[ ¯B])(cid:8)∞ plays a major role in (cid:8)MS (G)(cid:8)∞. This is so since(cid:8)(cid:8)(cid:8)MS (G)(cid:8)(cid:2)∞(cid:8)(cid:8)MS(cid:2)(cid:3)H(G)+ MS(cid:8)(cid:8)MS(cid:2)(cid:3)H(G)(cid:2)+ MS(cid:2)(cid:2)(cid:3)(cid:8)(cid:8)G[ ¯B](cid:3)(cid:8)(cid:8)G[ ¯B]∞∞− mna+6− 110na+2(cid:12)|B|24(cid:13)+ |B|n.(6)Let˜S be the sequence of restricted random queries ( ˜S, ˜T ) on ¯B. Then MS (G[ ¯B]) is M ˜S (G[ ¯B]) as MS (G[ ¯B]) dependsonly on ˜S. The quantity (cid:8)MS (H(G)) + M ˜S (G[ ¯B])(cid:8)∞ turns out to be large, namely at leastna+6 , except fora small enough probability for most of ˜S. For the set H of all possible weighted bipartite graphs H , say on A ∪ B, satisfying(i) and (ii) in Lemma 5.6, we divide the event {∃G ∈ D3 such that (cid:8)MS (G)(cid:8)∞ (cid:3) m} into events F H := {∃G ∈ D3 withna+6H(G) = H such that (cid:8)MS (G)(cid:8)∞ (cid:3) mna+6(cid:8)(cid:8)(cid:8)MS (G)(cid:8)}, H ∈ H. Then,8mna > 1∃G ∈ D3 such thatPr[F H ].(cid:9) (cid:16)= Pr10na+2+ m(cid:5)F HPr(cid:3)(cid:10)(cid:9)(cid:10)1(cid:3) mna+6∞(cid:7)H∈HH∈H(cid:5)To bound Pr[F H ], we further consider Pr[F H ] =of˜S.For a given graph H ∈ H on A ∪ B and the restricted random query ( ˜S, ˜T ) on ¯B, a vertex v ∈ B is called bad, if the sum16mna . The restricted random query ( ˜S, ˜T )i=1 is called bad if the number of bad queriesof weights of edges crossing between v and ˜S ∩ A is negligible, i.e., |μv, ˜S∩ A(H)| < 1is bad if more than 34( ˜S i, ˜T i) is more than 9(cid:6)|B| vertices of B are bad for it. The sequence ˜S = ( ˜S i, ˜T i)(cid:6)10 . The sequence is good if it is not bad. We have˜S Pr[ ˜S] Pr[F H | ˜S], and will show that Pr[F H | ˜S] is small enough for mostPr[F H ] (cid:3) Pr[ ˜S bad] + Pr[F H and ˜S good] = Pr[ ˜S bad] +Pr[ ˜S] Pr[F H | ˜S].(7)Let us first show that Pr[ ˜S bad] is small enough.˜S goodLemma 5.7. For a given H ∈ H on A ∪ B, there is a constant β < 1 such that Pr[ ˜S bad] (cid:3) β(cid:6).Proof. For a vertex v ∈ B,(cid:9)(cid:11)(cid:11)(cid:11) <(cid:11)μv, ˜S∩ A(H)Pr[v is bad] = Pr(cid:10)(cid:3) 23116mna8mna according to u ∈ ˜S or not.as v is adjacent to a vertex u ∈ A by a heavy edge and so |μv, ˜S∩ A(H)| changes by at least|B| and hence the probability that more than 3|B|/4 verticesThus, the expected number of bad vertices in B is at most 23in B is bad is at most 8/9 by Markov’s inequality. This implies that the expected number of bad queries ( ˜S i, ˜T i) in ˜S isless than or equal to 8(cid:6)/9. Since ( ˜S i, ˜T i) are i.i.d., Chernoff’s large deviation inequality yields Pr[ ˜S bad] (cid:3) β(cid:6) for a constantβ < 1. (cid:2)1To bound the second part of (7), notice that (6) andPr[F H | ˜S] (cid:3)(cid:5)(cid:9)PrG:H(G)=H(cid:8)(cid:8)MS (H) + M ˜S(cid:2)(cid:3)(cid:8)(cid:8)G[ ¯B]We show18mna > 110na+2(cid:11)(cid:11)(cid:11) ˜S(cid:3) 1na+6 imply+ m(cid:10).(8)∞8mnaLemma 5.8. For sufficiently large m, the following holds: Suppose that ˜S is a good sequence of restricted random queries ( ˜S i, ˜T i) on ¯B.Then,(cid:9)Pr(cid:8)(cid:8)MS (H) + M ˜S(cid:2)(cid:3)(cid:8)(cid:8)G[ ¯B]∞(cid:11)(cid:11)(cid:11) ˜S(cid:3) 18mna(cid:10)(cid:3) m−δ(cid:6)/30.Proof. Suppose that ( ˜S i, ˜T i) is good and consider the fully extended random query (S i, T i). Then, there are at least (cid:12) |B|m0.9δ good vertices in B and for a good vertex v ∈ B, the answer of the query (S i, T i) changes by at leaston whether v ∈ T or v /∈ S ∪ T , each of which occurs with probability 116mna depending3 , independently of the other vertices in B. Thus, the(cid:13) (cid:2)41566S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569answer of (S i, T i) is at mosttheorem. Since at least (cid:6)/10 ( ˜S i, ˜T i)’s are good and (S i, T i)’s are independent, the lemma follows. (cid:2)in absolute value with probability m18mna−0.4δ or less by the generalized Littlewood–OffordSince there are eO(m log n) graphs in D3, the above lemma and (8) imply that(cid:13)Pr[F H | ˜S] (cid:3) exp+ O(m log n)(cid:3) exp(−m log n),(cid:12)− δ(cid:6) log m30for large enough c in (cid:6) = cm log nwe finally havelog m . With this inequality and Lemma 5.7, (7) gives Pr[F H ] (cid:3) β(cid:6)/2 for sufficiently large n and(cid:9)Pr∃G ∈ D3 such that(cid:8)(cid:8)(cid:8)MS (G)(cid:8)(cid:3) mna+6∞(cid:10)(cid:3)(cid:5)H∈HPr[F H ] (cid:3) |H|β(cid:6)/2.Since, for the graphs in H, the number of edges is at most 2m3δ and the number of possible edge weights (including 0) isat most 4nb+a+6, we have|H| (cid:3)(cid:2)4nb+a+6(cid:3)2m3δ(cid:12)nmδ(cid:13) 2m2δ(cid:5)(cid:13)(cid:12)nii=1−(cid:6)/4(cid:3) βand the desired inequality follows.Case 4. G ∈ D4.The proof is analogous to that of the fourth case for unweighted graphs. Let us first show that for G ∈ D4, there is amatching of a number of heavy edges if we do not consider the light edges in G.Lemma 5.9. For sufficiently large m, the following holds: Suppose that G is a graph in D4. Then, G has (cid:12)mδ(cid:13) pairwise disjoint heavyedges (regarding edges as sets of two vertices) such that any other edge joining two vertices in the heavy edges is light.Proof. Notice that, as G /∈ D1 ∪ D2 ∪ D3, there are at least4 log m heavy edges with both ends in W (G) and each vertex inW (G) is incident with less than mδ heavy or middleweight edges. Thus, we are able to iteratively choose a heavy edge eand delete e and all the heavy and middleweight edges sharing a vertex with e at leastm(cid:12)m4 log m(cid:13)(cid:2)/2mδ + 1(cid:3)(cid:2) mδtimes. The first (cid:12)mδ(cid:13) edges chosen are the desired edges. (cid:2)Since there are eO(m log n) graphs in D4, the following lemma yields the desired bound.Lemma 5.10. For sufficiently large m, the following holds: Suppose that G is a graph in D4 and (S, T ) is a random query. Then,(cid:9)Pr(cid:11)(cid:11)(cid:11) (cid:3) m(cid:11)μS,T (G)na+6(cid:10)(cid:3) m−0.4δ.Proof. According to Lemma 5.9, we may take (cid:12)mδ(cid:13) pairwise disjoint heavy edges e1, . . . , e(cid:12)mδ (cid:13) of G such that any otheredge joining two vertices contained in the heavy edges is light. Let B be the set of the vertices contained in the heavyedges. Define H to be the spanning subgraph of G consisting of the edges in G except for the light edges with both endsin B. Since the graph G − H has only the light edges with both ends in B and |B| = 2(cid:12)mδ(cid:13),(cid:11)(cid:11)(cid:11) (cid:3)(cid:11)μS,T (G − H)(cid:13)(cid:12)2mδ2mna+6and so |μS,T (G)| (cid:3) m(cid:11)(cid:11)(cid:11)μS,T (H)(cid:11) (cid:3)na+6 implies(cid:11)(cid:11)(cid:11) +(cid:11)μS,T (G)(cid:11)(cid:11)(cid:11) (cid:3)(cid:11)μS,T (G − H)(cid:12)(cid:12)2mδ2(cid:13)(cid:13)+ 1mna+6<18mna.To obtain the inequality, it is enough to show thatS.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569567(cid:9)Pr(cid:11)(cid:11)(cid:11) <(cid:11)μS,T (H)(cid:10)18mna(cid:3) m−0.4δ.We consider a random query (S, T ) conditioned on ˜S := S ∩ ¯B, ˜T := T ∩ ¯B, where ¯B := [n] \ B. That is, all vertices in ¯Bhave been determined to be in S, T , or none of them. For each heavy edge ei = {ui, v i} in B, let Xi be the random variablerepresenting the contribution of ui and v i to the value μS,T (H) so thatμS,T (H) =(cid:12)mδ (cid:13)(cid:5)i=1Xi + μ ˜S, ˜T (H).(H) or μui , ˜T (H) + μ ˜S,v iThis is possible since ei ’s are the only edges of H with both ends in B and they are pairwise disjoint. For each i, Xi may be 0,(H) + w G (ei) each with probability 1/9, corresponding to the events {ui, v i /∈ S ∪ T },μui , ˜T (H), μ ˜S,v i{ui ∈ S, v i /∈ S ∪ T }, {ui /∈ S ∪ T , v i ∈ T } and {ui ∈ S, v i ∈ T }, respectively. Since ei is heavy, i.e., |w G (ei)| (cid:2) 18mna , at least oneof the last three values is24mna each with probability at leasti=1 Xi + μ ˜S, ˜T (H) is in a fixed interval of length24mna or more in absolute value. In particular, Xi = 0, | Xi| (cid:2) 11/9. By the generalized Littlewood–Offord theorem, the probability that4mna is at most m−0.4δ and hence so is the probability that |μS,T (H)| < 18mna . (cid:2)(cid:7)(cid:12)mδ (cid:13)116. Finding Fourier coefficientsThe Walsh transform is a Fourier transform for the space of pseudo-Boolean functions in which a pseudo-Boolean func-tion is represented as a linear combination of basis functions called Walsh functions [40]. For each subset S of [n], the Walshfunction corresponding to S, ψS : {0, 1}n → R, is defined as(cid:7)ψS (x) = (−1)i∈S xifor x ∈ {0, 1}n. If we define an inner product of two pseudo-Boolean functions f and g as(cid:18) f , g(cid:19) =(cid:5)x∈{0,1}nf (x)g(x)2n,the set of Walsh functions, {ψS | S ⊆ [n]}, becomes an orthonormal basis of the space of pseudo-Boolean functions. Hence,a pseudo-Boolean function f can be represented asf =(cid:5)S⊆[n](cid:20)f (S)ψS ,where (cid:20)f (S) = (cid:18) f , ψS (cid:19) is called the Fourier coefficient corresponding to S.Now, we prove Corollary 1.4. Suppose that fis a 2-bounded function satisfying the condition in Corollary 1.4. Then, theFourier coefficients (cid:20)f (S) of f corresponding to S with |S| (cid:2) 3 are 0. Decompose f as follows:f = (cid:20)f (∅) + f 1 + f 2,where(cid:5)f 1 =S⊆[n]: |S|=1(cid:20)f (S)ψSandf 2 =(cid:5)(cid:20)f (S)ψS .S⊆[n]: |S|=2To find the Fourier coefficients ofcoefficient (cid:20)f (∅).f , we separately find the Fourier coefficients off 2 and f 1 and then find the FourierFirst, define G f as the weighted graph such that (i) V (G f ) = [n], (ii) for each pair e of vertices, e ∈ E(G f ) if and only if(cid:20)f (e) (cid:7)= 0, and (iii) w G f (e) = (cid:20)f (e) for all e ∈ E(G f ). Since the weights of edges of G f are precisely the Fourier coefficients off 2, consider the problem of finding the weighted graph G f . For a cross-additive query (S, T ), we haveμS,T (G f ) =(cid:5)e=uv: u∈S,v∈T(cid:20)f (e) = f (0n) − f (1S ) − f (1T ) + f (1S∪T )4,where 0n is the vector consisting of n zeros and 1 A for a subset A ⊆ [n] represents the vector consisting of 1 in the coor-dinates in A and 0 in the rest. This means that any cross-additive query for G f can be answered by 4 function evaluationsof f . Since f has at most m non-zero Fourier coefficients, G f has at most m edges. Hence, by Theorem 1.2, there exists alog m ) function evaluations. For each edge in G f , its weight can benon-adaptive algorithm to find the edges of G ffound by one cross-additive query. Thus, all the weights of edges in G f can be found in O(m) function evaluations in ain O( m log n568S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569non-adaptive way. Overall, there exists a 2-round algorithm to find the weights of edges in G f , consequently, the Fouriercoefficients of f 2 in O( m log nlog m ) function evaluations.Let x f be the n-dimensional vector whose ith element is the Fourier coefficient (cid:20)f ({i}). That is, the elements of x f areprecisely the Fourier coefficients of f 1. For q ∈ {0, 1}n, the following holds:χq(x f ) = ( f (0n) − f 2(0n)) − ( f (q) − f 2(q))2.If we regard x f as the vector representing the weights of n coins, this equation means that any coin weighing for x f canbe simulated by a constant number of function evaluations of f and f 2. Since f 2 is known by the algorithm for finding G fand the value of f (0n) is evaluated by the algorithm, only one function evaluation of f , i.e.,f (q), is required to know thevalue of χq(x f ). The function f 1 has at most m non-zero Fourier coefficients and so |sp(x f )| (cid:3) m. Hence, the non-adaptivelog m ) function evaluations. The value of each non-algorithm in Theorem 1.3 identifies the non-zero elements of x fzero element of x f can be found by one coin weighing, i.e., one function evaluation of f . Thus, all the values of non-zeroelements of x f can be found in O(m) function evaluations in a non-adaptive way. Overall, there exists a 2-round algorithmto find x f , consequently, the Fourier coefficients of f 1 in O( m log nin O( m log nlog m ) function evaluations.Once we obtain f 2 and f 1, we get the value of (cid:20)f (∅) by (cid:20)f (∅) = f (0n) − f 2(0n) − f 1(0n). This can be done withoutadditional function evaluations of f , since the value of f (0n) is evaluated by the algorithm for finding G f . Combining thetwo algorithms for finding G f and x f along with this final step, we obtain an algorithm to find the Fourier coefficients off using O( m log nlog m ) function evaluations. Since each of the two algorithms is a 2-round algorithm, the combined algorithm isa 4-round algorithm, which proves Corollary 1.4.7. Concluding remarksIn this paper, we proved the existence of optimal algorithms for the graph finding problem and two related problems.Our results for weighted graphs are based on the condition that the weights of edges in absolute value (or correspondingones for the other problems) are bounded above by a polynomial in n and below by an inverse polynomial in n. The essentialpart of the condition used in our proofs is that the ratio between the minimum and maximum is polynomially boundedabove in n. The polynomial ratio is best possible to derive the optimal bounds in our proofs and as yet we have no ideahow to obtain optimal bounds for more general conditions.For finding weighted graphs, we obtained the results under the condition that m is at least a (large) constant power oflog n. Getting the results for smaller m is still open for cross-additive queries and so is for the problem of finding Fouriercoefficients. (For additive queries, see [8] that appeared in the review process of this paper.) Also, although the proposedalgorithms are optimal, finding an explicit construction of optimal algorithms is still an open problem and, we think, animportant research direction. Another important issue in practical applications is the time complexity of the algorithms. Inthis paper, we focused only on the query complexity and did not try to optimize the time complexity. It would be worthtrying to find an optimal algorithm with a reasonable time complexity.A natural extension of the graph finding problem is the hypergraph finding problem, especially when the hypergraphis k-uniform for k = 3, 4, . . . . An algorithm for the problem would be useful to find the Fourier coefficients of certaink-bounded pseudo-Boolean functions as described in Section 6.References[1] M. Aigner, Combinatorial Search, Wiley, New York, 1988.[2] N. Alon, V. Asodi, Learning a hidden subgraph, SIAM Journal on Discrete Mathematics 18 (4) (2005) 697–712.[3] N. Alon, R. Beigel, S. Kasif, S. Rudich, B. Sudakov, Learning a hidden matching, SIAM Journal on Computing 33 (2) (2004) 487–501.[4] D. Angluin, J. Chen, Learning a hidden graph using O(log n) queries per edge, in: Proceedings of the 17th Annual Conference on Learning Theory (COLT2004), Banff, Canada, 2004, pp. 210–223.[5] D. Angluin, J. Chen, Learning a hidden hypergraph, Journal of Machine Learning Research 7 (2006) 2215–2236.[6] R. Beigel, N. Alon, M.S. Apaydin, L. Fortnow, S. Kasif, An optimal procedure for gap closing in whole genome shotgun sequencing, in: Proceedings ofthe Fifth Annual International Conference on Computational Molecular Biology (RECOMB 2001), Montreal, Canada, 2001, pp. 22–30.[7] M. Bouvel, V. Grebinski, G. Kucherov, Combinatorial search on graphs motivated by bioinformatics applications: A brief survey, in: Proceedings of the31st International Workshop on Graph-Theoretic Concepts in Computer Science (WG 2005), Metz, France, 2005, pp. 16–27.[8] N.H. Bshouty, H. Mazzawi, Reconstructing weighted graphs with minimal query complexity, in: Proceedings of the 20th International Conference onAlgorithmic Learning Theory (ALT 2009), Porto, Portugal, 2009, pp. 97–109.[9] N.H. Bshouty, C. Tamon, On the Fourier spectrum of monotone functions, Journal of the ACM 43 (4) (1996) 747–770.[10] H. Chernoff, A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations, Annals of Mathematical Statistics 23 (1952)493–509.[11] S.S. Choi, K. Jung, J.H. Kim, Almost tight upper bound for finding Fourier coefficients of k-bounded pseudo-Boolean functions, in: Proceedings of the21st Annual Conference on Learning Theory (COLT 2008), Helsinki, Finland, 2008, pp. 123–134.[12] S.S. Choi, K. Jung, B.R. Moon, Lower and upper bounds for linkage discovery, IEEE Trans. on Evolutionary Computation 13 (2) (2009) 201–216.[13] S.S. Choi, J.H. Kim, Optimal query complexity bounds for finding graphs, in: Proceedings of the 40th ACM Symposium on Theory of Computing (STOC2008), Victoria, Canada, 2008, pp. 749–758.[14] P. Erd ˝os, On a lemma of Littlewood and Offord, Bulletin of the American Mathematical Society 51 (1945) 898–902.S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569569[15] C.G. Esseen, On the Kolmogorov–Rogozin inequality for the concentration function, Z. Wahrscheinlichkeitstheorie Verw. Geb. 5 (1966) 210–216.[16] C.G. Esseen, On the concentration function of a sum of independent random variables, Z. Wahrscheinlichkeitstheorie Verw. Geb. 9 (1968) 290–308.[17] W. Fontana, P. Stadler, E. Bornberg-Bauer, T. Griesmacher, I. Hofacker, M. Tacker, P. Tarazona, E. Weinberger, P. Schuster, RNA folding and combinatorylandscapes, Physical Review E 47 (3) (1993) 2083–2099.[18] D.E. Goldberg, Genetic Algorithms in Search, Optimization, and Machine Learning, Addison–Wesley, Reading, Massachusetts, 1989.[19] V. Grebinski, On the power of additive combinatorial search model, in: Proceedings of the 4th Annual International Conference on Computing andCombinatorics (COCOON 1998), Taipei, Taiwan, 1998, pp. 194–203.[20] V. Grebinski, G. Kucherov, Reconstructing a Hamiltonian cycle by querying the graph: Application to DNA physical mapping, Discrete Applied Mathe-matics 88 (1998) 147–165.[21] V. Grebinski, G. Kucherov, Optimal reconstruction of graphs under the additive model, Algorithmica 28 (2000) 104–124.[22] R.B. Heckendorn, A.H. Wright, Efficient linkage discovery by limited probing, Evolutionary Computation 12 (4) (2004) 517–545.[23] J. Jackson, An efficient membership-query algorithm for learning DNF with respect to the uniform distribution, Journal of Computer and SystemSciences 55 (3) (1997) 42–65.[24] H. Kargupta, B. Park, Gene expression and fast construction of distributed evolutionary representation, Evolutionary Computation 9 (1) (2001) 1–32.[25] S.A. Kauffman, Adaptation on rugged fitness landscapes, in: D. Stein (Ed.), Lectures in the Sciences of Complexity, Addison–Wesley, Redwood City,1989, pp. 527–618.[26] S.A. Kauffman, The Origins of Order: Self-Organization and Selection in Evolution, Oxford University Press, New York, 1993.[27] L. Le Cam, On the distribution of sums of independent random variables, in: J. Neyman, L. Le Cam (Eds.), Bernoulli, Bayes, Laplace: AnniversaryVolume, Proceedings of an International Research Seminar, Statistical Laboratory, University of California, Berkeley, 1963, Springer-Verlag, New York,1965, pp. 179–202.[28] B. Lindström, On B2-sequences of vectors, Journal of Number Theory 4 (1972) 261–265.[29] B. Lindström, Determining subsets by unramified experiments, in: J.N. Srivastava (Ed.), A Survey of Statistical Designs and Linear Models, North-Holland,Amsterdam, 1975, pp. 407–418.[30] J.E. Littlewood, A.C. Offord, On the number of real roots of a random algebraic equation. III, Mat. Sbornik 12 (1943) 277–285.[31] Y. Mansour, Learning Boolean functions via the Fourier transform, in: V. Roychowdhury, K.Y. Siu, A. Orlitsky (Eds.), Theoretical Advances in NeuralComputation and Learning, Kluwer Academic, Dordrecht, 1994, pp. 391–424.[32] H. Mühlenbein, T. Mahnig, FDA– A scalable evolutionary algorithm for the optimization of additively decomposed functions, Evolutionary Computa-tion 7 (1) (1999) 45–68.[33] M. Pelikan, D.E. Goldberg, E. Cantú-Paz, Linkage problem, distribution estimation, and Bayesian networks, Evolutionary Computation 8 (3) (2000)311–340.[34] L. Reyzin, N. Srivastava, Learning and verifying graphs using queries with a focus on edge counting, in: Proceedings of the 18th International Conferenceon Algorithmic Learning Theory (ALT 2007), Sendai, Japan, 2007, pp. 285–297.[35] B.A. Rogozin, An estimate for concentration functions, Theory of Probability and Its Applications 6 (1) (1961) 94–97.[36] B.A. Rogozin, On the increase of dispersion of sums of independent random variables, Theory of Probability and Its Applications 6 (1) (1961) 97–99.[37] H.S. Shapiro, S. Söderberg, A combinatory detection problem, American Mathematical Monthly 70 (1963) 1066–1070.[38] M.J. Streeter, Upper bounds on the time and space complexity of optimizing additively separable functions, in: Proceedings of the Genetic and Evolu-tionary Computation Conference (GECCO 2004), Seattle, USA, 2004, pp. 186–197.[39] H. Tettelin, D. Radune, S. Kasif, H. Khouri, S.L. Salzberg, Optimized multiplex PCR: Efficiently closing a whole-genome shotgun sequencing project,Genomics 62 (1999) 500–507.[40] J.L. Walsh, A closed set of orthogonal functions, American Journal of Mathematics 55 (1923) 5–24.