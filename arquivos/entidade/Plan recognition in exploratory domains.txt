Artificial Intelligence 176 (2012) 2270–2290Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPlan recognition in exploratory domainsYa’akov Gal a,b,∗, Swapna Reddy b, Stuart M. Shieber b, Andee Rubin c, Barbara J. Grosz ba Department of Information Systems Engineering, Ben-Gurion University of the Negev, Israelb School of Engineering and Applied Sciences, Harvard University, USAc TERC, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 1 March 2010Received in revised form 8 August 2011Accepted 11 September 2011Available online 3 October 2011Keywords:Plan recognitionUser modelingThis paper describes a challenging plan recognition problem that arises in environmentsin which agents engage widely in exploratory behavior, and presents new algorithmsfor effective plan recognition in such settings. In exploratory domains, agents’ actionsmap onto logs of behavior that include switching between activities, extraneous actions,and mistakes. Flexible pedagogical software, such as the application considered in thispaper for statistics education, is a paradigmatic example of such domains, but many othersettings exhibit similar characteristics. The paper establishes the task of plan recognitionin exploratory domains to be NP-hard and compares several approaches for recognizingplans in these domains, including new heuristic methods that vary the extent to whichthey employ backtracking, as well as a reduction to constraint-satisfaction problems. Thealgorithms were empirically evaluated on people’s interaction with flexible, open-endedstatistics education software used in schools. Data was collected from adults using thesoftware in a lab setting as well as middle school students using the software in theclassroom. The constraint satisfaction approaches were complete, but were an order ofmagnitude slower than the heuristic approaches. In addition, the heuristic approaches wereable to perform within 4% of the constraint satisfaction approaches on student data fromthe classroom, which reflects the intended user population of the software. These resultsdemonstrate that the heuristic approaches offer a good balance between performanceand computation time when recognizing people’s activities in the pedagogical domain ofinterest.© 2011 Published by Elsevier B.V.1. IntroductionIn this paper we report on the development and evaluation of algorithms for recognizing users’ plans in domains inwhich users engage in exploratory and error-prone behaviors. The challenges presented by these domains were madeevident by our work with students using open-ended computer software for learning statistics, but they arise in human–computer interaction more broadly.Indeed, developing technology is changing rote and monolithic interaction styles between computers and their users tomore flexible types of interactions that allow users to explore and interleave between different activities. Examples of theseflexible systems include interactive drawing tools [44], Integrated Development Environments (IDEs), collaborative writingassistants [4], computer games, and educational software [51].To be effective partners, these systems need to recognize the activities their users are carrying out and to use thatinformation to provide support in a way that guides users’ interactions effectively. For example, an intelligent drawing tool* Corresponding author at: School of Engineering and Applied Sciences, Harvard University, USA.E-mail address: gal@eecs.harvard.edu (Y. Gal).0004-3702/$ – see front matter © 2011 Published by Elsevier B.V.doi:10.1016/j.artint.2011.09.002Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–22902271may infer that several objects on the canvas are all representatives of the same class. When the user modifies an attributein one of the forms, the system will identify and duplicate this change in the other objects in the class. Another benefit ofrecognizing users’ activities in software is to provide assessments of user performance. Such capabilities in educational andpedagogical systems could increase teachers’ abilities to identify those students who are having difficulty.Classical approaches to plan recognition have assumed a goal-oriented agent whose activities are consistent with therecognizers’ knowledge base and who forms a single encompassing plan. In contrast, flexible systems allow users to followmultiple plans, interleave actions from different plans, and perform redundant actions; they also tolerate user mistakes.Thus, inferring users’ plans in these systems gives rise to a more complex sort of plan recognition problem.This paper presents several new algorithms for keyhole plan recognition in exploratory domains.1 The algorithms arepost-hoc, in that they infer plans from complete interaction sequences, rather than after each observed action, as in on-linerecognition [13]. The algorithms we present vary in completeness (that is, whether plans are guaranteed to be found) andcomputational complexity. We investigate the trade-off between completeness and complexity empirically, by comparingthe performance of different plan recognition algorithms on real-world data.Our empirical analysis uses an educational software system for statistics education. Educational software is increasinglydesigned to be open-ended and flexible in order to support the types of exploratory activities that facilitate students’learning experience. This gives students the resources to explore concepts in new ways, but their interactions may be erraticor unfocused, making it challenging to recognize plans. During the chaos of a lab session, it is impossible for teachers totrack each student’s progress. As a result it is difficult to adapt their teaching to their students’ work. Educational softwarethus provides an important domain for plan recognition. A well structured post-hoc representation of the plans behindstudents’ activities would enable teachers to make better pedagogical decisions in the classroom.The research we report used a commercial system called TinkerPlots, used world-wide to teach students in grades 4through 8 about statistics and mathematics [34]. Using TinkerPlots, students build stochastic models and generate pseudo-random samples to analyze the underlying probability distributions. Our study used four different problems for whichstudents interacted with TinkerPlots to model hypothetical situations and to determine the probability of events.Students’ interactions with TinkerPlots are complex. They may pursue multiple plans and interleave actions from differentplans. They may be confused about the appropriate plan to take, and they may make mistakes. These behaviors create achallenging domain for plan recognition algorithms. Any number of extraneous actions may be interleaved among thosethat are a part of a successful plan. In addition, actions that are crucial to successful plans may occur in almost any order.All of the algorithms presented in the paper compose (possibly non-contiguous) interaction sequences from users’ in-teractions into a series of interdependent tasks and sub-tasks. They infer students’ plans by comparing their interactionsequence to ideal solutions, or recipes, that were specified by domain experts. At the end of this process, the algorithmsoutput a hierarchical plan that explains the student’s strategy during the session. The algorithms separate those actions thatcontribute to solving the problem from extraneous actions and mistakes.This paper integrates and extends initial reports of past studies [23,43] and makes several contributions. First, it formallydefines the task of plan recognition in exploratory domains and provides a proof of its NP-completeness. Second, it presentsnew greedy and complete algorithms for solving the plan recognition problem in these domains, providing a formal com-plexity analysis of these algorithms and comparing them to existing methods. Third, it is the first work to evaluate planrecognition algorithms on real-world data in the domain of flexible pedagogical software.We compared two algorithmic approaches for recognizing users’ interactions. One of the approaches employed incom-plete greedy algorithms to attempt to build plans from the bottom-up. The complexity of one of these algorithms ispolynomial in the size of the interaction sequence, while the complexity of the other algorithm is exponential (in theworst case) in the size of this sequence. The second approach converts the recognition process to a Constraint SatisfactionProblem (CSP) using one of two methods. One of these methods builds a complete plan to recognize the entire interactionsequence. The other method works piecemeal in a way that uses subsets of the activity sequence to eliminate infeasibleplans before attempting to recognize the entire sequence. This second method was suggested by Quilici et al. [42] but firsttested empirically here. In contrast to the greedy approach, the constraint satisfaction approach is complete, in the sensethat if all of the recipes for solving a given TinkerPlots problem exist, and the student solved the problem, the algorithmis guaranteed to find the plan that explains the student’s interaction. The complexity of both of the complete methods isexponential in the size of both the interaction sequence and the data set containing ideal solutions.We conducted a number of empirical studies to evaluate the ability of these algorithms to recognize the plans used tosolve TinkerPlots problems. The studies involved two types of settings: adults using TinkerPlots in a lab setting, and middleschool students using TinkerPlots in a classroom setting. The results confirmed that the complete algorithms were able torecognize all plans when the relevant recipes for the TinkerPlots problems existed, and students were able to solve theproblems. However, there was a systematic difference between these two empirical settings and their effect on the planrecognition algorithms. For adult data, the complete methods outperformed the heuristic approaches by 25%. For studentdata, which reflects the intended user population of TinkerPlots, this difference was just 4%. In addition, the heuristicapproaches were (on average) an order of magnitude faster than the complete approaches for both data sets. We show1 We use the term “keyhole plan recognition,” coined by Cohen et al. [17], to refer to the fact that the acting agent is not signalling its plan to theobserver.2272Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–2290that the determinant for run-time is the size of the interaction sequence for the heuristic approaches, and the size of theplan database for the complete approaches. Lastly, the interaction sequences obtained from middle school students weresignificantly longer than those of adults, and in general, students’ interactions corresponded to complete solutions less oftenthan adults.These results show that the heuristic algorithms we devised provide a good balance between performance and time inthe pedagogical software domain we considered. More generally, they demonstrate the feasibility of using Artificial Intelli-gence techniques to support the analysis of users’ interaction with flexible, open-ended software. Although our study usesone type of software, the techniques presented here are general and can be used to support the analysis of users’ inter-actions for different types of exploratory systems. Our techniques are of value to software designers and researchers whowish to understand the way people learn and use computer software, as well as to teachers.After describing related work (Section 1.1), we introduce the TinkerPlots software (Section 2), highlighting the propertiesthat characterize an exploratory domain. In Section 3, we describe the formal tools for representing plans in exploratorydomains and the abstract problem of recognizing plans relative to idealized recipes for achieving domain goals. We then(Section 4) draw an analogy between this plan recognition problem and grammar recognition, showing that the problem isequivalent to context-free recognition under a variant interpretation of such grammars. The analogy allows a simple proofof the NP-completeness of plan recognition in exploratory domains. We present a variety of plan recognition algorithmsfor this problem in Section 5, and evaluate their performance empirically on data obtained from users’ interactions withTinkerPlots in Section 6, demonstrating the practicality of the best of our algorithms in both coverage and speed.1.1. Related workPlan recognition is a cornerstone problem of AI and a necessary component of many applications such as software helpsystems [7,37], story understanding [16,50], and natural language dialogue [14,29]. Early approaches have assumed a goal-oriented agent whose activities were consistent with its knowledge base, and which formed a single encompassing plan [33,36]. A notable exception is Pollack [39] that allowed for agents to have ill-formed plans about achieving certain goals,and Brown and Burton [12] that allowed for agents’ knowledge to be possibly incorrect. We refer the reader to Carberry[15] for a detailed account of these approaches and focus this section on more recent works which capture some of theendemic qualities of exploratory domains, namely extraneous actions or mistakes, interleaving of activities, and free orderamong plan constituents.We first detail approaches that considered temporal relationships among actions that make up agents’ plans. Weida andLitman [49] proposed a method for recognizing plans that explicitly included ordering constraints in the plan library andsuggested various criteria for matching plans to action sequences, assuming that each action is directed at completing oneof the plans in the library. Avrahami-Zilberbrand and Kaminka [3] encoded relationships between action parameters in plansusing tree structures and provided methods for plan recognition that traverse the tree in a manner that is temporally consis-tent with the observations. Another approach to handling temporal relationships in plans derives from the analogy betweenplan recognition and grammar recognition [46,25]. Immediate-Dominance/Linear-Precedence (ID/LP) grammars [24] describelanguages that allowed for linear precedence and free word ordering over rule constituents. Algorithms for parsing ID/LPgrammars, which are analogous to recognizing plans, can at times provide exponential savings as compared to consideringevery possible order configuration of the rule constituents [45,5]. Pynadath and Wellman [41] developed a probabilisticgrammar for modeling agents’ plans that also included their beliefs about the environment. These techniques did not allowfor interleaving plans. All reordering among plan constituents in these above works was restricted to local permutationamong the constituent actions of sub-plans.Goldman et al. [28] proposed a probabilistic model of plan recognition that recognized interleaving actions and output adisjunction of plans—rather than a single hierarchy—to explain an action sequence. It also accounted for missing observations(e.g., not seeing an expected action in a candidate plan makes another candidate plan more likely). The algorithm wasgenerative, that is, with each observation, a pending set of possible hypotheses were generated that were subsequentlymatched against future observations. Geib and Goldman [26] have augmented this work to allow to recognize multipleinstances of the same plan, in addition to interleaving actions. This work provides a bottom-up algorithm that maintainsa distribution over the set of possible explanations matching users’ observations, while not assuming that agent’s top-levelgoal is known. Our work is distinct from this approach in several ways. First, the settings studied by Geib and Goldmando not account for agents’ extraneous actions, an endemic property of the exploratory domain we consider in this paper.Second, the probabilistic approach used by Geib and Goldman is complete when considering full observation sequences,with a worst-case complexity that is exponential in the size of the grammar. We provide heuristic algorithms that may beexponentially more efficient than complete approaches. Our algorithms are parameter-free, designed for ecologically realisticsettings (such as classrooms) in which tuning or learning parameters is difficult because of the effort involved in obtaininglarge amounts of training data. Third, we show the efficacy of our approach on real-world data obtained from students andadults using pedagogical software, whereas Geib and Goldman use synthetic data.Several works have used probabilistic reasoning to recognize students’ goals when interacting with pedagogical software.Conati et al. [18] used Bayesian networks to model students’ interactions with an intelligent tutor, using probabilistic infer-ence to recognize interleaving actions. Albrecht et al. [1] suggested a probabilistic approach to infer players’ goals as well astheir future actions from observation sequences. They used Dynamic Bayesian Networks to compute a posterior distributionY. Gal et al. / Artificial Intelligence 176 (2012) 2270–22902273Fig. 1. Two sampler models for rain.over possible goals given players’ actions in the game. They are able to capture agents’ mistakes, but infer the likelihoodof a single goal or action, rather than recognizing a hierarchical plan representing the entire action sequence. Quilici et al.[42] proposed an algorithm for implementing plan recognition as a constraint satisfaction problem but do not evaluate it onreal data. We augment this work in several ways. First, by implementing this algorithm on ecologically realistic data, thatof adults and middle school students using pedagogical software. Second, by describing alternative, heuristic approaches tocomplete algorithms in exploratory domains that provide a balance between completeness and time, and comparing theefficacy of these algorithms to the complete, CSP approach.Lastly, we will mention work in the intelligent tutoring systems community that has been applied to models of students’learning of mathematics and physics [19,8,2,47]. In these domains the tutor is an active participant in the student’s learningprocess and ambiguities or uncertainties about the students’ plan of action are resolved by querying the student. By contrast,the TinkerPlots style of educational software allows students to “learn by doing” in an exploratory open-ended mannerwithout explicit guidance by a software tutor. Our approach addresses a different problem, that of non-intrusive recognitionof students’ activities given their complete interaction histories with the software. Past work on recognition of users’ goalswith computer systems has focused on fixed, strongly constrained settings such as UNIX command line syntax [9], orapplications such as medical diagnosis and email notifications in which users tend to adopt the same goals many times [6,31,35]. In educational domains, goals are constantly evolving to reflect new concepts, and it may be difficult to collectstudent-specific training data for each type of goal.2. The TinkerPlots domainTinkerPlots is an educational software system used world-wide to teach students in grades 4 through 8 about statisticsand mathematics [34]. It provides students with a toolkit to actively model stochastic events, and to create and investigatea large number of statistical models [30]. As such, it is an extremely flexible application, allowing for data to be modeled,generated, and analyzed in many ways using an open-ended interface.To demonstrate our approach towards recognizing activities in TinkerPlots we will use the following running example,called rain.rain: The probability of rain on any given day is 75%. Use TinkerPlots to compute the probability that it will rain on each of the nextfour consecutive days.This problem is a simple example drawn from a set of problems posed to students using TinkerPlots in schools and tosubjects during our data collection procedure.Two of the several possible approaches towards modeling this problem in TinkerPlots are shown in Fig. 1. One uses thesame stochastic device multiple times, while the other uses multiple stochastic devices. Fig. 1(a) shows a sampler objectcontaining a single “spinner” device. Devices are added to sampler objects to model distributions. There are several typesof devices; spinner devices recall the distribution formed by spinning a dial. The spinner device in the left-hand modelcontains two possible events, “rain” and “sun”. The likelihood of “rain” is three times that of “sun”, as determined by thesurface area of these events within the spinner. Each draw of this sampler will sample the weather for a given day. Thenumber of draws is set to four, making the sampler a stochastic model of the weather on four consecutive days.2274Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–2290Fig. 2. Generating and analyzing data for the rain problem.Another possible approach to modeling the rain distribution is presented in Fig. 1(b), which shows a sampler with fourspinner devices. Each of these devices is a stochastic model of the weather on a given day, and the sampler, set to a singledraw, draws once from each device. In both of these approaches, the sampler, along with the contained devices, is a modelof the joint probability distribution over the weather for four consecutive days.When a sampler is run, it generates data that is sampled according to the distribution defined by the parameters of itsmodel. Fig. 2(a) shows a table object holding a portion of the sample generated by either of the sampler models in Fig. 1.Each line in the table represents a single repetition of the sampler, consisting of a “sun” or “rain” value for each of fourdays. Fig. 2(b) shows the end-result of a process in which this data is plotted onto a histogram for the purpose of inferringthe likelihood of four consecutive days of rain. There are many other approaches for modeling the rain distribution andorganizing the resulting data, which we do not show here.As students interact with TinkerPlots through its engaging direct manipulation interface, they create and modify devices,sample stochastic events, graph the results, modify and retry aspects, in a fluid manner in which all kinds of objects canbe manipulated in different orders, and with false starts and retries adding complexity to the exhibited behaviors. TheTinkerPlots system is metered to log all the primitive direct manipulation actions of the user.These logs constitute the trace of the observable behavior of the user. Our goal is to explain the log in terms of theproblem-solving goal that the user was engaged in, such as solving the rain problem.3. Methods and representationIn this section we introduce representations and algorithms towards describing TinkerPlots activities in a formal way.3.1. Actions, recipes and plansThe nomenclature in this paper follows the foundational planning terminology grounded in philosophy [11,10,20]. Themost fundamental components we define are called basic actions, which are atomic, and cannot be decomposed. Complexactions describe higher-level, more abstract activities that can be decomposed into sub-actions, which can be basic actionsor complex actions themselves. To emphasize the distinction between basic and complex actions, we notate complex actionsusing an underline notation.A recipe [40] for a complex action characterizes the sequences of actions that result in successful completion of theaction. The recipe for a complex action C is a set of sub-actions S and constraints R such that performing the sub-actionsunder the constraints constitutes completing the complex action. We do not allow recursively defined recipes; i.e., a recipefor the complex action C may not hereditarily include C in sub-action list S.The set of restrictions R constrains how sub-actions may be completed by expressing relationships over the parameters ofthe sub-actions that must hold. Restrictions may take the form of any Boolean relation over sub-actions’ parameters, whichincludes mathematical equations and inequalities. A common type of restriction uses inequalities and the pos (position)parameter of various actions to limit the order in which these actions must occur. In the absence of ordering restrictions,a recipe is completely free-ordered. Other restrictions may enforce a relationship between object identifiers in several Tin-kerPlots actions, requiring, for example, that two actions share the same is parameter to represent constraints that areimposed on the same sampler object s. To complete complex action C according to a recipe, all sub-actions in S must becompleted without violating any restrictions in R.We notate a recipe for complex action C with sub-actions {s1, . . . , sn} and restrictions R asC → s(cid:4)1, . . . , s(cid:4)n where RY. Gal et al. / Artificial Intelligence 176 (2012) 2270–22902275. . .AS[is = 11, pos = 5]ADS[is = 11, id = 2, td = spinner, pos = 6]ALE[is = 11, id = 2, ie = 1, le = a, pos = 7]ALE[is = 11, id = 2, ie = 2, le = b, pos = 8]AS[is = 9, pos = 9]CEL[is = 11, id = 2, ie = 1, le = rain, pos = 10]CEL[is = 11, id = 2, ie = 2, le = sun, pos = 11]CPD[is = 11, id = 2, ss = 1 : 3, pos = 12]ADS[is = 11, id = 3, td = mixer, pos = 13]. . .Fig. 3. A snippet of an action sequence taken from a user’s interaction with TinkerPlots.Basic actionsADS = Add Device to SamplerALE = Add Labelled EventAS = Add SamplerCEL = Change Event LabelCPD = Change Probability in DeviceCSA = Create Sampler with Event AComplex actionsAED = Add Event to DeviceCCD = Create Correct DeviceParametersid = Device IDie = Event IDis = Sampler IDle = Event Labeltd = Device Typess = Subsection Sizepos = Temporal PositionFig. 4. Action and parameter abbreviation key.(cid:4)where si is the name of the sub-action si (with optional subscripts to uniquely identify sub-actions with the same name).The restrictions R use the notation A[p] to refer to the value of a parameter p of some sub-action with name A. (In casemultiple sub-actions have the same name, the subscripts are used to disambiguate.) Standard conventions are used to notatemultiple inequalities (for example, a ≺ b ≺ c).2A recipe library [11] contains the complete set of recipes for all of the complex actions of the domain. Each complexaction type may have multiple recipes in the library providing alternatives for its completion.3A plan is a hierarchical construction of basic and complex actions used to complete a complex action called the rootaction. The plan for completing a root action C is a tree of parametrized actions rooted at C such that each complex actionis decomposed into sub-actions according to some recipe in the database.3.2. Representation of TinkerPlots activitiesThe nature of the questions (such as rain) for teaching statistical skills in TinkerPlots typically will require students toplan a series of activities to derive answers. Students interact with TinkerPlots through a series of operations that create,modify, or delete objects such as samplers, plots, and tables. Basic actions in TinkerPlots refer to rudimentary operationsthat can be carried out by a single keystroke or mouse action. It is these instances of basic actions that are logged as thesystem is used. Examples of basic actions in TinkerPlots include creating a new sampler, generating a random sample, ordeleting a plot. Complex actions in TinkerPlots are activities such as adding a spinner with six equally weighted events to asampler, fitting sampler data to a plot, or solving the rain problem. We impute complex actions to users of the software inour analysis of users’ actions as pursuing plans.Users’ interactions with TinkerPlots are recorded as finite, chronological sequences of basic actions that are performedby the users. It is these action sequences that constitute the input to the plan recognition algorithm. Fig. 3 shows a portionof an action sequence for creating the stochastic component (called a “device”) in the sampler of Fig. 1(a).4 For example,the action ADS[is = 11, id = 2, td = spinner, pos = 6] (Add Device to Sampler) refers to the action of adding a device withan identifier id = 2 and type td = spinner to a sampler with an identifier is = 11. The pos parameter specifies the temporalposition of the action within an action sequence; in this case ADS is the sixth action performed by the user. Fig. 4 providesa key to abbreviations for all actions (in upper-case script) and parameters (in lower-case script) used throughout the paper.In the TinkerPlots domain, a recipe captures an ideal sequence of actions for performing a particular activity. We repre-sent each basic or complex action type in TinkerPlots as a unique name (such as ADS for the basic action Add Device toSampler, or CCD for the complex action Create Correct Device); they are parametrized to describe features of the objectsto which an instance of the action refers. We notate an action with its parameters by placing the parameter values, keyed2 Our representations of recipes and restrictions are similar to classical planning formalisms such as Hierarchical Task Networks [27], but do not allowfor recursion.3 Other works have used the term “plan library” to refer to complete plan hierarchies from an agent’s root goal down to the basic level actions; see forexample Nau et al. [38]. We use the term “recipe library” to refer to a set of recipes.4 This sampler was used to generate the data in Fig. 2.2276Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–2290CCD → ADS, AED1, AED2, CPDwhereADS[pos] ≺ AED1[pos] ≺ AED2[pos] ≺ CPD[pos]ADS[is] = AED1[is] = AED2[is] = CPD[is]ADS[id] = AED1[id] = AED2[id] = CPD[id]CPD[ss] = (3 : 1)Fig. 5. A recipe for the CCD (Create Correct Device) complex action.AED → ALE, CELwhereALE[pos] ≺ CEL[pos]ALE[is] = CEL[is]ALE[id] = CEL[id]ALE[ie] = CEL[ie]Fig. 6. A recipe for the AED (Add Element to Device) complex action.Fig. 7. A possible plan for the CCD complex action.to the parameter names, in brackets after the name. For example, the set of sub-actions for one of the possible recipesfor solving rain includes creating a sampler that models the weather on four consecutive days, running the sampler, andplotting the results on a graph. Examples of such samplers are shown in Figs. 1(a) and 1(b). An example of a graph is shownin Fig. 2(b).Fig. 5 shows a recipe for the complex action CCD, which creates the sampler shown in Fig. 1(a). It includes two basicsub-actions, ADS and CPD, as well as two complex AED (Add Event to Device) actions. This recipe also contains severalrestrictions. The first, an ordering restriction, mandates that a device must be added to a sampler (action ADS) before anyevents are added to that device (action AED), which in turn must occur before the probability of those events is changed(action CPD). The second and third restrictions require that sampler and device identifiers are consistent across theseactions, and the fourth restriction requires that the surface area of events be resized to a 3 : 1 ratio.The purpose of giving TinkerPlots problems to students is to test their ability to construct appropriate, applicable modelsfor solving the problem. We treat recipes as idealized descriptions of the use of TinkerPlots to solve problems by construct-ing a plan for achieving the complex root action for solving the problem. For example, a plan for the complex action CCDis shown in Fig. 7. Here, each complex AED action is decomposed into sub-actions ALE and CEL using the recipe shownin Fig. 6. The plan was inferred from the student’s actions in the sequence shown in Fig. 3, and results in the creation of aspinner device, such as the one shown in Fig. 1(a) for solving the rain problem.The flexible nature of TinkerPlots supports exploratory and open-ended use of the software in several ways. First,students may perform extraneous activities that do not play a salient part in the solution to the problem. For exam-ple, the action AS[is = 9, pos = 9] in the student’s action sequence of Fig. 3 plays no role in the student’s plan in Fig. 7.Second, students may interleave the sub-actions of different complex actions. For example, in the plan of Fig. 7, theALE[is = 11, id = 2, ie = 2, le = b, pos = 8] action in position 8 (a sub-action of the complex action AED[is = 11, id = 2, ie = 2,le = sun, pos = 11], temporally occurs among the actions ALE[is = 11, id = 2, ie = 1, le = a, pos = 7] and CEL[is = 11, id = 2],ie = 1, le = rain, pos = 10 in positions 7 and 10 (sub-actions of the complex action AED[is = 11, id = 2, pos = 10]). Lastly, stu-dents may make mistakes when solving problems or only succeed in solving part of the problem. The combination of thesedifferent properties make it challenging to recognize the plans underlying students’ interactions with TinkerPlots, as weargue formally in the next section.Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–229022774. Grammars and complexityThe general problem of recognizing whether a sequence of basic actions embeds a plan that accords with the recipes inthe database includes satisfying an arbitrary set of constraints. This problem is at least as complex as constraint satisfactionfor the constraint language, which can be NP-hard or worse depending on the particular of the constraint language. Buteven without the solving of restrictions, the plan recognition problem is NP-complete. Geib and Goldman [26] show that arelated plan recognition problem—involving interleaving and ordering restrictions but not extraneous actions—is NP-hard viaa simple reduction from three-dimensional matching to a grammar formalism they call plan tree grammars. The extensionto our context, in which extraneous actions in the log are allowed, is straightforward.In this section, we review and extend the Geib and Goldman proof to derive a complexity result for plan recognition inexploratory domains. For simplicity, we use a simpler formal characterization than the plan tree grammars used by Geib andGoldman. We define a grammar formalism that, like plan tree grammars, allows interleaving, but unlike plan tree grammars,has no temporal ordering restrictions. This allows us to greatly simplify the description of the formalism. For concreteness,we call the formalism simple plan grammars.A simple plan grammar is structured exactly like a context-free grammar, with a set of terminal and nonterminal symbolsincluding a specified start symbol, plus a set of productions rewriting a nonterminal symbol to a sequence of terminals andnonterminals. As with other grammatical characterizations of planning, the nonterminal symbols correspond to complexactions and the terminal symbols to basic actions. Under this analogy, a recipe corresponds to a grammatical production,a plan to a parse tree, and an action sequence to a string to be parsed. Reconstructing a plan from an action sequencerelative to a recipe library would then correspond to parsing a string relative to a grammar [48].Although simple plan grammars are structured identically to context-free grammars, the language of a simple plangrammar is defined differently from the corresponding context-free grammar, so as to manifest interleaving and extrane-ous actions. (Indeed, one can think of a simple plan grammar as an alternate interpretation of the context-free grammarnotation.)The language of a simple plan grammar is defined in two steps. First, we define the base language of a simple plangrammar to be the language of the corresponding context-free grammar. The language of a simple plan grammar is then theset of all strings containing a subsequence that is a permutation of a string in the base language.This simple definition captures exactly the reordering, interleaving, and extraneous action aspects of the plan recognitionproblem, while abstracting away from temporal ordering and other constraints. The reordering and interleaving is capturedby the fact that all permutations of the base language strings are in the language of the grammar. The extraneous actionsare captured by including supersequences in the language as well, the extra symbols constituting the extraneous actions.What is not captured by simple plan grammars is the ordering restrictions. It is the ordering restrictions that greatlycomplicates the definition of plan tree grammars. As we will show, the ordering restrictions are not needed to carry throughthe NP-hardness proof, and therefore the simpler formalism is sufficient for showing that the plan recognition setting weare considering is NP-hard.By way of example, consider the following productions:S → M M MM → a b cM → d e fM → g h i(1)If we take these to be the productions of a context-free grammar, the grammar recognizes several strings, including thestrings abcdefghi and abcabcabc. However, when viewed as a simple plan grammar, it recognizes all supersequences ofpermutations of these strings, including the strings themselves, but also strings like adgbehcfi or ihgfedcba or aaaabcdefghiaa.It is easy to show that the problem of string recognition for simple plan grammars is NP-complete. We extend the proofof Geib and Goldman [26], which uses a reduction from the NP-complete problem 3-Dimensional Matching:3-Dimensional Matching (3DM): Given three identically sized disjoint sets W = {w 1, . . . , wq}, X = {x1, . . . , xq} and Y =(cid:4) ⊆ M of size q such that{ y1, . . . , yq}, and a set M ⊆ W × X × Y , does there exist a matching consisting of a subset Mno two elements of Magree on any coordinate (that is, all elements of W , X , and Y appear exactly once in M).(cid:4)(cid:4)This problem was shown to be NP-complete by Karp [32].We reduce an instance of 3DM to a simple plan grammar as follows. Given an instance of 3DM, we construct a simpleplan grammar with two nonterminals S (the start symbol) and M, and terminal symbols W ∪ X ∪ Y . The productions of thegrammar include one for each element (cid:8)w, x, y(cid:9) of M:M → w x yand a production generating q instances of nonterminal M:q times(cid:2) (cid:3)(cid:4) (cid:5)M · · · MS →(2)(3)2278Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–2290Note that the base language of the grammar, that is, the language of the productions when viewed as a context-freegrammar, comprises strings all of length 3q. Thus, if a string in the language includes all of the elements of W , X , and Y ,each must occur exactly once.In addition, we construct the string s = w 1 · · · wqx1 · · · xq y1 · · · yq containing each of the elements of W , X , and Y exactlyonce. We ask whether the string s is admitted by the constructed grammar.By way of example, the simple plan grammar (1) is exactly the one generated by this construction for the 3DM problemin which W = {a, d, g}, X = {b, e, h}, and Y = {c, f , i} and where M = {(cid:8)a, b, c(cid:9), (cid:8)d, e, f (cid:9), (cid:8)g, h, i(cid:9)}. The constructed string torecognize would be adgbehcfi.The construction has the property that s is admitted by the constructed simple plan grammar if and only if the corre-sponding 3DM instance has a solution. (In the example, the constructed string adgbehcfi is in the language of the simpleplan grammar because its permutation abcdefghi is in the base language.) The argument is straightforward, and essentiallythat of Geib and Goldman [26], with variation only for the lack of ordering restrictions and the issue of extraneous items.If there is a solution to the 3DM problem, then there is a subset Mof M that covers all and only the 3q elements ofW ∪ X ∪ Y . By construction, then, there is a string in the base language that includes all of these elements as well. Theconstructed string s is a permutation of that string, hence is in the language of the simple plan grammar.(cid:4)If the string s is in the language of the simple plan grammar, then there is a context-free derivation for some permutationof some subset of the elements of s. Because all strings in the base language are of length 3q, which is the length of s itself,the base language string must be an improper subset, that is, have exactly the elements of s. But in that case, a solution ofthe 3DM problem can be read off of the context-free derivation of the base language string. The particular M-productionsused in that derivation correspond to the Msubset.(cid:4)This proof differs from that of Geib and Goldman [26] in a few ways. First, we do not incorporate ordering constraintsin the rule M → w x y to require w ≺ x and x ≺ y as they do. These constraints are not necessary, because by constructionthe string to be recognized obeys such constraints directly. The same is true of the proof by Geib and Goldman [26]; theordering constraints are superfluous there too. By observing the superfluity of ordering restrictions for the proof, we allowa simpler grammar setup.Second, our definition of the language of a simple plan grammar incorporates all supersequences of base language strings,corresponding to allowing extraneous actions in logs in the plan recognition problem. The original proof was modified tohold even in this context by forcing all base language strings to include exactly 3q elements, the same as the constructedstring to be recognized, so the issue of supersequences becomes irrelevant. Although the simple plan grammar constructeddoes admit strings longer than 3q, they are irrelevant to the argument, as the string to be parsed is of length 3q. Forcingthe string to be of length at least 3q is the role of the S production, which has no analog in the Geib and Goldman proof.Along similar lines, nothing in the constructed grammar enforces the condition that the elements of M chosen aredistinct (that is, that no M-production is reused), and no such constraint on the grammar is necessary. If such duplicationwere to occur, the string generated would have repeated elements as well, but in that case, the derivation will never admitthe string to be recognized, which by construction has no repeated elements.We can conclude, then, that simple plan grammar recognition is NP-hard. The problem is also clearly in NP, as theconstructed grammar is polynomial in the size of the 3DM instance, and the context-free derivation for the base languagepermutation of s serves as a polynomially-sized witness for the recognition problem. Checking that the witness is for apermutation of s is trivially done in polynomial time.Thus, plan recognition in our model, in which recipes can be interleaved and extraneous actions can be observed, isNP-hard as well. Indeed, this holds whether or not extraneous actions can be observed; they were not made use of in theproof. Similarly, no use was made of recursion in the grammar, so a restriction to non-recursive recipes does not reduce thecomplexity. Finally, no use of ordering restrictions was made in the proof; satisfying such restrictions makes the recognitionproblem only more complex.Given the computational complexity of this plan recognition problem, the question arises as to whether it can be solvedin practice for problems of the scope that confront us in real-world cases. We turn to heuristic plan recognition algorithmsand their performance in the next section.5. Plan recognition algorithmsIn this section we present several plan recognition algorithms that are able to handle the interleaving and extraneousactions that are endemic to exploratory domains such as TinkerPlots. All of these approaches make use of a structurecalled a plan tree for representing and reasoning about recipes in the database, essentially a search tree for capturing theset of possible plans consistent with the recipe database. A plan tree has two types of nodes: and nodes, whose childrenrepresent actions that must be carried out to complete a recipe, and or nodes, whose children represent a choice of recipesfor completing an action. The root, action C , is an OR node. For each recipe for C , a child and node is added to the root andlabeled with the sub-actions of that recipe. The children of this and node are the plan trees of each sub-action. A branchterminates when a basic action is reached, as a basic action has no recipe by definition.A partial plan tree for the CCD action is shown in Fig. 8. The and nodes contain set brackets, while or nodes do not.Triangles denote unfinished subtrees which were omitted for expository convenience. The plan for creating the spinnerY. Gal et al. / Artificial Intelligence 176 (2012) 2270–22902279Fig. 8. A partial plan tree for the CCD complex action.t ← 0P 0 ← Xfor R C ∈ SortRecipes(R) do1: procedure BuildPlan(R, X )2:3:4:5:6:7:8:9:10:11:Pt+1, OL ← Pt(MC , OL) ← FindMatch(R C , OL)while MC is not null doAdd C to Pt+1 positioned after last a ∈ MCfor all a ∈ MC doCreate a branch from C in Pt+1 to a in PtRemove a from Pt+1(cid:10) R: a recipe list, X: an action sequence(cid:10) Pt : list of actions at stage t(cid:10) R C : a recipe for action C(cid:10) OL: an open list(cid:10) MC : a match(cid:10) a: an action12:13:(MC , OL) = FindMatch(R C , OL, null)t ← t + 1Fig. 9. Bottom-up plan recognition method.object shown in Fig. 1(a) can be found by selecting the leftmost child at each or node. This resulting plan mirrors the planshown in Fig. 7.5.1. Greedy algorithmsWe present two greedy algorithms for inferring users’ plans. Informally speaking, the algorithms work bottom-up, start-ing with the user log, and iteratively replacing a set of actions that match the sub-actions of a given recipe by the complexaction the recipe implements so as to form a new action list.A brute-force approach would involve non-deterministically finding all ways in which a complex action might be imple-mented in the action list. For example, the recipe library for the rain problem includes ten recipes and six complex actions.The different recipes for the rain problem can form 167,076 possible plans without considering different orderings betweenactions.5 If we consider all possible orderings within recipes, we get that there are 2,109,182,681,760 possible plans forthe rain problem. Naively considering each of these possibilities is infeasible.6 The heuristic approaches presented in thissection make various assumptions about exploratory domains that serve to significantly reduce their complexity as com-pared to the brute-force method. However, they are incomplete, in the sense that users may construct valid plans that thealgorithms fail to infer.At each step t, the algorithms incrementally build a plan by maintaining an ordered sequence of actions, denoted P t . Theaction sequence P 0, representing the “ground level” of the user’s plan, is denoted as X. During each step, the algorithmsattempt to replace subsets of actions from P t with the complex actions they represent. Each of the complex actions in P t isa partial plan that explains some activity in the user’s interaction.Because our recipe formalization does not allow for recursion, we can define an ordering over all complex actions in theplan library that reflects their depth. Specifically, if B is a constituent sub-action for complex action A, then all recipes forB must appear before the recipes for A in the ordering. The heuristic algorithms consider recipes according to this order.Both greedy algorithms are based on a function BuildPlan shown in Fig. 9 for constructing users’ plans bottom-up.BuildPlan takes two inputs: An action sequence X, and a recipe library, R. The method calls SortRecipes to topologicallysort R by depth from lowest to highest.For each recipe R C for complex action C , the action list P t+1 and an open list OL are initialized with the actions in P t .The algorithm repeatedly tries to find a match for R C in the open list by calling the function FindMatch(R C , OL), whichreturns a tuple (MC , OL), representing the actions MC in the match and a modified open list. (The two methods we shall5 For example, there are 16 possible ways to complete the CCD action, because there are two possible recipes in our recipe library for each of the fourMS actions.6 While it is theoretically possible to use string matching to align recipes to the action sequences, a naive approach would need to consider a prohibitivenumber of possible orderings. The complete approaches (the CSP algorithms) that we describe in the next session essentially perform this matching moreefficiently.2280Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–2290Fig. 10. Progression of BuildPlan over three steps.soon present for FindMatch modify the open list in different ways.) If a match exists, BuildPlan removes the actions in MCfrom P t+1 and replaces them with the complex action C , placed where the latest action in the match occurred. (In addition,it marks the actions in MC in P t to be the children of action C in P t+1.) Actions are removed from P t only when a matchis found, according to the criteria defined in the method FindMatch. (We will provide two possible types of criteria in thealgorithms below.) Once no more matches for R C can be found, the algorithm moves on to the next recipe, until all therecipes have been considered.Fig. 10 shows several stages of the BuildPlan procedure. Edges are shown between complex actions in each step andtheir constituent actions in the previous step. The first stage, titled P 0, contains only basic user actions. During the secondstage, titled P 1, two pairs of non-contiguous basic ALE and CEL actions are found to be matches for two complex AEDactions. This is an example of interleaving actions, because in P 0, the ALE constituent of the second AED action is positionedbetween the ALE and CEL constituents of the first AED action. In the third stage, a match for the CCD action is found,whose sub-actions consist of the first ADS action, both complex AED actions, and the CPD action. Fig. 10 defines a structurethat is similar to the ideal plan for the CCD action shown in Fig. 7, except that it explicitly indicates the interleavingaction sequences for the two AED actions, as well as includes redundant actions that were not part of the plan (e.g.,AS[is = 9, pos = 8]).BuildPlan is a greedy approach because it does not backtrack. After it chooses a match C for a given recipe R C , itreplaces the actions in P t+1 with complex action C without looking ahead to future stages. As a result, the algorithm mayfail to find a match for a recipe because a necessary sub-action was committed to another match at an earlier stage. Thecomplexity of the BuildPlan algorithm is dominated by the complexity of the FindMatch algorithm, call it CFM, discussedin the next section. Let |R| and |X| be the number of recipes in R and the number of actions in the action sequence X,respectively. Then, BuildPlan calls FindMatch at most |X| times per recipe, yielding an overall complexity of O (|R| · |X| · CFM)for BuildPlan.5.1.1. Matching algorithmsWe present two possible matching algorithms for implementing the FindMatch(R C , OL) process. Both of these make useof the Extends function, a Boolean function that takes as input an action a P , a partial match MC , and recipe R C . It returnstrue if a P can be added to MC , such that (1) a P corresponds to one of the constituent sub-actions of R C and is not alreadyin MC and (2) the addition of a P to MC will not violate any of the recipe constraints in R C . For example, the basic actionADS[is = 11, id = 2, td = spinner, pos = 6] in the action sequence of Fig. 3 extends the recipe for CCD shown in Fig. 5 giventhat MC = ∅.The Boolean function Fulfills(MC , R C ) returns true if MC is a complete match for the recipe R C . We then say that MCfulfills R C . Note that MC can include both basic and complex actions. For example, the actionsADS[is = 11, id = 2, td = spinner, pos = 6]AED[is = 11, id = 2, td = spinner, pos = 10]AED[is = 11, id = 2, td = spinner, pos = 11]CPD[is = 11, id = 2, pos = 12]fulfill the recipe for CCD shown in Fig. 5.Both of the matching algorithms choose actions that extend MC in any order that is allowed by the restrictions ofrecipe R C . In particular, the actions in OL may be non-contiguous; this allows the algorithms to capture interleaving plans.However, the two methods differ in the way they update the action list OL as they build a match.The first algorithm, NoBktrk(R C , OL), shown in Fig. 11, is an extension of an earlier algorithm proposed by Gal et al. [23].It receives as input R C , a recipe for some complex action C and an open list OL, which is initially equivalent to the actionY. Gal et al. / Artificial Intelligence 176 (2012) 2270–22902281MC ← nullfor a P ∈ OL do1: procedure NoBktrk(R C , OL)2:3:4:5:6:Add a P to MCRemove a P from OLif Extends(a P , MC , R C ) then(cid:10) R C : a recipe, OL: an open list(cid:10) a P : an action(cid:10) MC : a partial match7:8:9:10:11:12:if Fulfills(MC , R C ) thenreturn (MC , OL)else if MC is null thenreturn (null, OL)elseclear MC and goto line 2Fig. 11. Algorithm for finding a match without backtracking.6:7:8:9:10:11:12:13:14:15:1: procedure SomeBktrk(R C , OL)return SomeBktrkRec(R C , OL, null)2:3: procedure SomeBktrkRec(R C , OL, MC )4:5:if Fulfills(MC , R C ) thenreturn (MC , OL)(cid:4) ← OLOLfor a P ∈ OL do(cid:4)remove a P from OLif Extends(a P , MC , R C ) then(cid:10) R C : a recipe, OL: open list(cid:10) MC : a partial match(cid:10) a P : an actionAdd a P to MC(MC , OL) = FindMatch(R C , OLif Fulfills(MC , R C ) thenreturn (MC , OL)remove a P from MC(cid:4), MC )return (null, OL)Fig. 12. Algorithm for finding a match with depth-first search.CSA → AS, ADS, ALEwhereAS[pos] ≺ ADS[pos] ≺ ALE[pos]AS[is] = ADS[is] = ALE[is]ADS[id] = ALE[id]ALE[le] = ’A’Fig. 13. A recipe for the CSA (Create Sampler with event “A”) complex action.set in P t+1. NoBktrk removes actions, one by one, from the open list and places them into a partial match, MC . Onceremoved from the open list, these actions will not be reconsidered until a new recipe is provided at step t + 2.7The algorithm is quadratic in the size of the action sequence |X|. To see this, consider that in the worst case, it takes acomplete pass over the action list, which is bounded by the size of the action sequence, to fulfill a recipe. Because recipesin TinkerPlots are non-recursive, the number of times a recipe can be fulfilled is also bounded by the size of the actionsequence. Therefore, the complexity of NoBktrk is O (|X|2).The second algorithm for finding a match, called SomeBktrk (Fig. 12), performs a complete depth-first search given arecipe R C and an open list OL. It defines a sub-function that extends a partial match MC with a single action, and makesa recursive call to the sub-function. In contrast to the NoBktrk algorithm, it is complete given a recipe R C and an openlist OL; that is, it is guaranteed to find a match for R C if one exists in OL. However, SomeBktrk cannot guarantee that aplan is found, because BuildPlan itself is greedy. Due to BuildPlan’s lack of forward-checking or backtracking across timesteps, SomeBktrk may assign an action to a match during an early step and permanently remove that sub-action from theopen list. SomeBktrk may later be unable to fulfill a crucial recipe requiring the same sub-action because a match no longerexists in the open list.As an example of the way these two algorithms differ, consider a recipe for a complex action CSA (Create Sampler withEvent A) for creating a sampler with one device and a single event labeled “A”, shown in Fig. 13. Recall that both NoBktrkand SomeBktrk algorithms extend the current partial match by choosing actions in any order from the interaction sequencethat meets the recipe constraints. Given the action sequence shown in Fig. 3, the SomeBktrk algorithm, which is completegiven the recipe for CSA and the action sequence, will find the following match, which includes a sampler with identifieris = 11 and device with identifier id = 2.7 We hypothesized that actions that occur late in the interaction process are more salient than actions that occur earlier. However, in practice, traversingthe open list in reverse order and increasing order of the pos parameter yielded the same results.2282Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–2290AS[is = 11, pos = 5]ADS[is = 11, id = 2, td = spinner, pos = 6]ALE[is = 11, id = 2, ie = 1, le = ‘A’, pos = 7]However, the NoBktrk may decide to add the following actions to the partial match MC :ADS[is = 11, id = 3, td = mixer, pos = 13]AS[is = 11, pos = 5]The NoBktrk algorithm will now try to find an ALE[is = 11, id = 3, le = ‘A’] action which relates to a device with identifierid = 3, which does not exist in the interaction sequence. Therefore, it will remove the actions in the partial match fromconsideration. As a result, it will fail to find the AS[is = 11, pos = 5] action in future calls, and will not be able to fulfill therecipe.To compute the complexity of SomeBktrk, let S be the maximum number of sub-actions in any recipe. A first-depth(cid:4)recursive call can be made at most |X| times. Within each of these recursive calls, at most |X| − 1 actions can remain in OL.So, at most |X| − 1 second-depth recursive calls can be made for each first-depth recursive call, yielding an overall maximumof |X|(|X| − 1) second-depth recursive calls. After S − 1 recursive calls of increasing depth have been made, a match must becompleted or backtracking must occur. Within each lowest-depth recursive call, there can be at most |X| − (S − 1) actionsleft to consider. So, a worst-case complexity of SomeBktrk is O (|X|!S! ).5.2. Complete algorithmsIn this section we present two plan recognition algorithms that are complete. Both algorithms work by converting theplan recognition problem into one or more constraint satisfaction problems and using standard techniques for their solution.The conversion makes use of the Expand function, shown in Fig. 15, to convert plans to flat representations containingsolely basic actions, called expanded recipes. Note that like their conventional counterparts, expanded recipes also includeconstraints defined over their set of actions. The first complete algorithm performs the conversion naively, while the seconduse a cascade of conversions to significantly reduce the size of expanded plans.Expand(T A ) takes as input a plan tree T A for complex action A and returns a set of expanded recipes for A. Each andnode represents a possible recipe for its parent node, a complex action. For each and node, Expand recursively generatesall expanded recipes for each sub-action of the recipe. This algorithms alternates between two sub-procedures, DirectSumand Union. Given a recipe, the DirectSum procedure computes all possible replacements of complex sub-actions with basicactions. Each time a complex action is replaced, DirectSum ensures that all restrictions involving the complex action arepropagated to its sub-actions. For example, consider a single recipe R A with sub-actions B, C, and D:A → B, C, Dwith restrictions:B ≺ DC ≺ DSuppose also that recursive calls of Expand have found the expanded recipes for B to be {E, F} and the expanded recipesfor C to be {G, H} and {I, J}. In this case, DirectSum will return the following expanded recipes for A:{E, G, H, D}, {E, I, J, D}, {F, G, H, D}, {F, I, J, D}with each recipe including either the restriction E ≺ D or F ≺ D in place of the B ≺ D restriction, and including either therestriction G ≺ D and H ≺ D, or I ≺ D and J ≺ D in place of the C ≺ D restriction. Lastly, the Union sub-procedure takesthe union over the expanded recipes generated for each recipe of A.An expanded recipe is a series of basic actions (with associated restrictions) that the user may perform to realize apotential plan. To create an expanded recipe, a path is traversed through the plan tree, beginning at the root and endingwith basic actions at the leaves. This path provides a trace of the plan corresponding to the expanded recipe. For example,one expanded recipe can be achieved by traversing the plan tree in Fig. 8 and choosing the leftmost recipe at each or node.Notice that the path taken matches the plan in Fig. 7. In this expanded recipe, each complex AED action and its restrictionsare replaced with two basic actions, ALE and CEL, and corresponding restrictions, as shown in Fig. 14.The complexity of Expand is costly in the worst case. Let S be the maximum number of complex sub-actions for eachrecipe, N be the maximum number of recipes for a single complex action, and C be the number of distinct complex actions.A plan tree has depth of at most C + 1, as we do not allow for recursive recipes. At the lowest depth of the plan tree, allactions are basic and do not have recipes. At the second lowest depth, complex actions have at most N expanded recipes,as none of the N recipes contain any complex sub-actions. At the third lowest depth, each recipe for a complex action mayY. Gal et al. / Artificial Intelligence 176 (2012) 2270–22902283CCD → ADS, ALE1, CEL1, ALE2, CEL2, CPDwhereADS ≺ ALE1, ALE2 ≺ CPDCEL1, CEL2 ≺ CPDADS[is] = ALE1[is] = CEL1[is] = ALE2[is] = CEL2[is] = CPD[is]ADS[id] = ALE1[id] = CEL1[id] = ALE2[id] = CEL2[id] = CPD[id]Fig. 14. Expanded version of CCD recipe.1: procedure Expand(T C )ERs[C ] ← ∅2:for all r j , a child of C do3:4:5:6:ERs[r j ] ← ∅for all ai , a child of r j doERs[r j ] ← DirectSum(Expand(Tai ), ERs[r j ])(cid:10) T C : the plan tree for action C(cid:10) ERs[C ]: the expanded recipes for C(cid:10) r j : a recipe(cid:10) ai : an action7:8:9:ERs[a] ← Union(ERs[a], ERs[r j ])if ERs[a] = ∅ thenERs[a] ← {a}10:return ERs[a]Fig. 15. Algorithm for generating expanded recipes.1: procedure ConvertToCSP(EA = (S, R), X)complex action A, X: an action sequence2:3:4:5:6:7:for all s ∈ S doAddVariableAndDomain(s, X)for all r ∈ R doAddRestrictionConstraint(r)for all s ∈ S doAddRedundancyConstraint(s)(cid:10) E A : an expanded recipe S and restrictions R for(cid:10) S: a set of sub-actions(cid:10) R: a set of restrictionsFig. 16. Converting an expanded recipe and action sequence to a CSP.contain at most S complex sub-actions, and each sub-action may have at most N recipes. The DirectSum procedure thencreates at most N S expanded recipes per recipe. The Union procedure collects the expanded recipes resulting from eachrecipe for that action, resulting in a maximum of N(N)S , or N S+1, recipes. At the fourth lowest depth, each complex actioncan again have at most N recipes with at most S complex sub-actions in each. Each of these S sub-actions can contain atmost N(N)S expanded recipes. So, the DirectSum and Union procedures create at most N(N(N)S )S , or N S 2+S+1, expandedrecipes per recipe. Continuing this reasoning, the top-level action can have at most Nrecipes, yielding an overallcomplexity of N O (S C ).C−1i=0 S i(cid:6)5.2.1. Constraint satisfaction algorithmsIn this section we explain how to combine an expanded recipe and action sequence to create a constraint satisfactionproblem (CSP). A solution to the resulting CSP is the plan representing the users’ activities. Formally, a CSP is a triple( X, Dom, C), where X = {x1, . . . , xn} is a finite set of variables with respective domains Dom = {D1, . . . , Dn}, each a set ofpossible values for the corresponding variable, D i = {v i}, and a set of constraints C = {c1, . . . , cm} that limit the1, . . . , v ivalues that can be assigned to any set of variables.kThe algorithm ConvertToCSP, shown in Fig. 16, receives as input an expanded recipe E A and an action sequence X andreturns a CSP. If a solution exists for this CSP, a subset of the actions in X realize the expanded recipe E A . We first showhow to create variables in the CSP, and we use as a reference Fig. 17, which provides a graphical representation of theCSP resulting from the action sequence of Fig. 3 and the expanded recipe of Fig. 14. We used a graphical layout suggestedby Dechter [21]. Note that parameters belonging to actions are not pictured unless they participate in some constraint.Let S = {s1, . . . , sn} and R be the set of sub-actions and restrictions in the expanded recipe, respectively. Each action inS becomes a unique variable in the CSP by calling the subroutine AddVariableAndDomain(s, X). Based on the expandedrecipe, six variables are added at this time: ADS, ALE1, CEL1, ALE2, CEL2, and CPD. These variables appear, outlined, inthe graph of Fig. 17. Each variable’s domain is then derived from the actions in the action sequence. For each occurrenceof action s in the action sequence, a value is added to the domain of s in the CSP. The right-hand box of Fig. 17 gives theresulting domain for each variable based on the action sequence.Lastly, we add restrictions to our CSP. For each restriction r in R over actions (s1, . . . , sm) in S, a constraint over thecorresponding CSP variables is added to the CSP using the AddRestrictionConstraint(r) subroutine. At this point, all re-strictions listed in Fig. 14 are added, including CPD[ss] = (3 : 1). Directed edges in the figure represent temporal constraintsbetween two variables. Undirected edges represent other parametric constraints. The edge from ADS to ALE1 expresses theconstraint ADS ≺ ALE1 as well as the constraint ADS[is, id] = ALE1[is, id].2284Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–2290Fig. 17. CSP resulting from an action sequence and an expanded recipe.1: procedure CSPbrute(T C , X)E ← Expand(T C )2:for all e ∈ E do3:4:5:6:7:8:C ← ConvertToCSP(e, X)solution ← Solve(C)if solution (cid:14)= ∅ thenreturn solutionreturn ∅(cid:10) T C : the plan tree for action C , X: an action sequence(cid:10) E: a set of expanded recipes(cid:10) C: a CSPFig. 18. Brute-force algorithm.T C ← CreateRecipeTree(C, R)Perform a bottom-up traversal of T C .for each OR node representing action A do1: procedure CSPprune(C , R, X)2:3:4:5:6:Cache solution[ A] ← CSPbrute(T A , X)if A has not been cached then(cid:10) R: a recipe library, X: an action sequence(cid:10) T C : the plan tree for action C7:8:9:if solution[ A] = ∅ thenPrune parent of A from T Areturn solution[C]Fig. 19. Bottom-up algorithm.For variables corresponding to the same action, additional redundancy constraints are added using the AddRedundan-cyConstraint subroutine. These constraints ensure that such variables are assigned distinct values, as these variables sharethe same domain. An example is the constraint connecting the ALE1 and ALE2 variables, which requires that these variableassignments have distinct pos parameters.5.2.2. Brute-force algorithmA solution for a CSP provides a match between an expanded recipe and an action sequence. In this section we presenttwo algorithms that use CSPs to output a plan from an action sequined X for a desired complex action C given a set ofrecipes R.The first algorithm, shown in Fig. 18, takes a brute-force approach, calling Expand to generate each expanded recipefor C , converting it to a CSP and solving the CSP. This algorithm returns the first solution found to the CSP or ∅ if nosolution is found.The complexity of CSPbrute can be analyzed in terms of the FindMatch2 and Expand procedures. Recall that callingExpand results in at most N O (S C ) expanded recipes, where N is the maximum number of recipes for a single complexaction. In the worst case, all expanded recipes are considered, and for each expanded recipe a CSP solver must be run. Thecomplexity of this CSP solver can be bounded by the complexity of a complete backtracking search, which we have seen tobe|X|!S! . So, an overall worst-case complexity of CSPbrute is N O (S C ) O (|X|!S! ).5.2.3. Pruning algorithmThe second algorithm, shown in Fig. 19, takes a more sophisticated approach and traverses the plan tree from thebottom-up. At each or node, the algorithm determines whether the user completed the corresponding sub-action by eithercalling CSPbrute or referring to the cached result of an earlier CSPbrute call. If the user failed to complete that sub-action,the algorithm prunes the relevant recipe, the parent of the current node, from the tree, as the user cannot complete a recipewithout completing each sub-action in that recipe. By eliminating branches from the plan tree for the desired complexaction C , this pruning process narrows the search space of possible expanded recipes for root action C . This algorithm wassuggested by Quilici et al. [42].The CSPprune method calls the CSPbrute algorithm once per distinct complex sub-action. Let C again represent thenumber of distinct complex sub-actions in our recipe list. Then, the worst-case complexity of the pruning method isN O (S C ) O ( C|X|!S! ). The worst case occurs when the user has completed each of the C complex actions, causing no poten-Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–22902285Table 1Number of possible plans per problem, maximal number of complex actions per recipe (S), maximal number of recipes for a singlecomplex action (N), maximal number of distinct complex actions (C).rosarainearringsseatbelts# possible plansO (26)O (217)O (211)O (212)S4444N2224C13666tial expanded recipes to be eliminated. However, we hypothesized that users would be likely to solve TinkerPlots problemsjust once, and therefore some complex actions within the plan trees would not be matched in the action sequence.6. EvaluationThe plan recognition problem inherent in domains such as TinkerPlots, where agents are engaged in exploratory behaviorwith false starts in addition to successful plan construction, leads, as we have shown, to an NP-complete computation. Thealgorithms presented in the previous section, both incomplete and complete, were intended to allow solution of real-worldproblems in practice, despite the complexity issue inherent in the problem. To determine their real-world performance, wecollected actual logs of TinkerPlots usage on standard pedagogical problems, and compared the algorithms’ coverage andperformance. The results show that the best of the algorithms has excellent coverage and practical performance.6.1. Experimental designWe collected interaction sequences of people’s interaction with TinkerPlots in two different settings. The first settingincluded 12 adults with a wide variety of educational backgrounds, ranging from some high school to some post-graduateeducation. The second setting included 12 eighth grade students in a middle school in Cambridge MA.8 Each adult subjectreceived an identical 30-minute tutorial about TinkerPlots and was then asked to complete four problems in succession;these problems are detailed in Appendix A. Students were given a slightly longer 45 minute demonstration of the softwareand were asked to solve two of the four problems. User logs and videos of the users’ screens were recorded for all usersessions. TinkerPlots is equipped with a logging facility that records the basic actions that make up users’ action sequences.To evaluate the various plan recognition algorithms, we manually traced the videos of their interaction with TinkerPlots. Wenoted whether each problem was solved, and we constructed the (possibly multiple) plans used to solve the problem. Wedefine a recognition algorithm to be “correct” if the plans that it outputs exactly corresponds to the plans constructed fromthe videos, or if it fails to output a plan when the student did not successfully complete the problem as determined by anexpert.9 If a user has solved a problem in several different ways, a recognition algorithm is deemed correct if it recognizesany of these solutions.We created a set of recipes to the TinkerPlots problems in our study to serve as input to the plan recognition algorithms.Our purpose in this study was to evaluate algorithms for matching these ideal solutions with the appropriate basic levelactions in users’ interaction sequences. Therefore, the recipes we manually constructed were created prior to the collectionof and were not informed by the data of people’s interactions with TinkerPlots. Rather, they represented what we perceiveda priori to be a broad range of possible solutions for TinkerPlots problems. Ultimately, our database contained recipessufficient to explain all but three user interactions. The lack of inclusion of these recipes is discussed in Section 6.2.2. Therecipe library used to run the recognition algorithms on each problem consisted of those recipes that were constructed forthe problem. This corresponds to knowing which TinkerPlots problem students are trying to solve. This assumption is logicalin the context of pedagogical software.106.2. Results and discussionWe compared the performance of the four recognition algorithms presented, called the NoBktrk, SomeBktrk, CSPbrute,and CSPprune techniques.11 We analyzed the user logs corresponding to the problems outlined in Appendix A. Table 1 listsfeatures for each problem that affect the complexity analysis of Section 5.1.1.The analyzed user logs ranged in length from 14 to 80 actions. The average length of an interaction sequence for prob-lems collected from adult subjects was 35 actions. Adults solved the assigned problems 70% of the time. In contrast, the8 Appropriate IRB approval was obtained for both settings, and parental consent was obtained for the data collected from the eighth graders.9 The domain expert was a researcher of educational technology who has worked with TinkerPlots for several years. For each action sequence, the expertwas shown a movie of the desktop of the user, as well as the plan outputted by the algorithm.10 Dropping this assumption corresponds to running our algorithms using a recipe data base that contains the complete set of recipes for all problems.This may affect correctness for the greedy algorithms, but not for the complete algorithms.11 We used the python-constraint package created by Gustavo Niemeyer and available at http://labix.org/python-constraint to implement our constraintsatisfaction algorithms.2286Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–2290Table 2Accuracy of recognition algorithms by percentage. Parenthesized numbers are the number of logs.DataProblemAlgorithmNoBktrkSomeBktrkCSPbruteCSPpruneAdults + StudentsAdultsrosarainseat beltsearringsOverall(23)(16)(12)(11)(62)78%88%42%91%76%(18)(14)(5)(10)(47)87%88%67%100%85%(20)(14)(8)(11)(53)100%100%75%100%95%(23)(16)(9)(11)(59)100%100%75%100%95%(23)(16)(9)(11)(59)Fig. 20. Performance for data obtained from students (left) and adults (right).average length of an interaction sequence for problems collected from students was 68 actions. Students solved the as-signed problems 60% of the time. Also, people engaged in exploratory behavior using the software. For example, there wereon average 15 exogenous actions in each problem that was obtained from adults.Table 2 shows the accuracy of the recognition algorithms on data collected for students and adults. As shown by thetable, the heuristic algorithms NoBktrk and SomeBktrk were correct for 47 of 62 (76%) and 53 of 62 (85%) interactions, re-spectively. The heuristic algorithms were outperformed by both CSPbruteForce and CSPprune algorithms, which performedcorrectly for 59 of 62 (95%) interactions. The incorrect inferences in all algorithms were false negatives, that is, the algo-rithms were unable to find solutions existing within the interaction sequence. All of the solutions outputted by all of thealgorithms matched the expert’s opinion regarding the activities used by the students.The constraint satisfaction algorithms are guaranteed to find users’ plans if they exist, provided that the relevant recipesare contained in the recipe database. Each of the three incorrect inferences of these algorithms can be traced to recipesmissing from the database. In addition to incorrect inferences due to missing recipes, the incomplete approaches sufferedfrom prematurely committing to a match without being able to backtrack. An example of the latter case occurred frequentlywithin the seat belts problem (see Appendix A). This problem required the user to construct a conditional distributionrepresenting the fact that people wearing seat belts are less likely to be hurt in an accident. Some users created a samplerwith the wrong distribution parameters and proceeded to correct these parameter settings. The incomplete approachestended to match sub-recipes for creating a sampler with actions corresponding to the wrong parameters. Consequently,they failed to find matches for the sampler construction recipe. In contrast, the CSP algorithms were able to backtrack andpick the right match for the expanded sampler construction recipe.6.2.1. Performance of algorithms on ecologically realistic dataThere was a significant difference in the performance of the heuristic algorithm on data that was obtained from adultsand the data that was obtained from middle school students. Fig. 20 shows the average accuracy of the plan recognitionalgorithms on student data (left, 19 instances) and adult data (right, 20 instances) from two problems, rosa and rain.12 Thefigure details the performance of these algorithms when correctly identifying successful solutions (true positives), correctlyidentifying failed solutions (true negatives), and incorrectly identifying failed solutions (false negatives).As shown in Fig. 20, both of the heuristic algorithms were always able to recognize unsolved problems (true negatives).There were 6 such cases for adult data and 12 cases for student data. More generally, for student data the accuracy ofboth heuristic algorithms averaged 96%, just 4% lower than the accuracy of the complete CSP algorithms for this data.However, for adult data, the average accuracy of the heuristic algorithms was 75%, significantly lower than that the averageaccuracy of the CSP algorithms. This is also apparent from Table 3, which compares the precision and recall measures ofthe different approaches on student and adult data. All of the algorithms achieved perfect precision, because there were no12 We performed analysis on these two problems for which we have both student and adult data.Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–22902287Table 3Precision (left) and recall (right) measures for student and adult data.DataStudentAdultAlgorithmNoBktrk(1, 0.86)(1, 0.57)SomeBktrk(1, 0.86)(1, 0.71)CSP(1, 1)(1, 1)false positive classifications, as we described above. The complete CSP algorithms both achieved perfect recall because theydid not incur false negatives. For the heuristic approaches, both NoBktrk and SomeBktrk algorithms achieved lower recallmeasures than the CSP approaches for both student and adult data. However, the average recall measure achieved by theheuristic approaches for student data was significantly higher than the average recall they achieved for adult data.To explain the effect of the type of the setting on the various plan recognition algorithms, we compared the numberof times in which students and adults were able to solve the problems that were assigned to them. As shown in Fig. 20students were able to solve TinkerPlots problems less often than adults (for students, 12 data instances represented failuresout of a total of 19 instances; for adults, 6 data instances represented failures out of a total of 20 instances). We attributethis to the fact that students were more likely to engage in exploratory behavior or to make mistakes while using Tinker-Plots, as is attested by their longer interaction sequences. Thus, one explanation for the success of the heuristic algorithmswhen analyzing student data is that there were more true negative classifications for student data, and these were alwaysrecognizable by our recognition algorithms.However, the performance of the heuristic algorithms on student data cannot be attributed solely to the fact that therewere more true negative classifications for student data. Both of the heuristic algorithms also achieved higher accuracy ratesfor students than for adults on data instances representing true positives. As shown by Fig. 20, for student data, the heuristicalgorithms were able to recognize 6 out of 7 true positive instances (average accuracy 85%), but were only able to recognize8 and 10 out of 14 true positive instances (average accuracy 65%) for adult data. Thus, both NoBktrk and SomeBktrkalgorithms were better at recognizing successful and unsuccessful plans for students than for adults. These results provideadditional support for the applicability of these algorithms, showing that they are particularly suitable for data that wasobtained in an ecologically realistic fashion, rather than a lab setting.6.2.2. Limitations of approachesA significant hurdle to accurate recognition is the difficulty of expressing certain types of user strategies as recipes. Aspreviously mentioned, both the greedy and constraint satisfaction algorithms were susceptible to the fact that the recipedatabase failed to capture all of the possible ways in which people solved problems. Because we do not allow recipes tobe defined recursively, our recipes can only specify that a fixed, rather than variable, number of actions occur. In the rainproblem, for instance, there are several possible samplers that model the probability of rain as 75%. A natural solution isone (as in Fig. 1(a)) in which there are unique events for “rain” and “sun”, causing “rain” to be weighted as three timesmore likely than “sun”. In actuality, any proportional number of “rain” and “sun” events would suffice, as long as “rain” isthree times more likely than “sun”. This limitation prevented our library from succinctly expressing the infinite number ofpermissible strategies—three of which were used by students—for the seat belts problem.Although there were no false-positive classifications in our experimental sessions, they can happen in theory. One reasonfor this is that the recipe language cannot express actions that must not occur. For example, the rosa problem requires theuser to create a device with four events labeled R, O, S, and A. If a fifth event were added, the sampler would no longer becorrect. However, all of our recognition algorithms would incorrectly match the actions corresponding to the four previousvalues with the recipe for creating a sampler.It is possible to construct plans using recipes that cannot happen in practice because they are disallowed by the software.For example, two interleaved actions may add and delete each other’s preconditions.Finally, we note that our recipes are not designed to describe approximately correct user approaches. For example, oneproblem required users to add two identically labeled events to a device, without specifying what that label must be. Oneuser failed to complete this task according to the recipe database because he or she used event labels “pierced" and (sic)“piecred”. Despite this oversight, a teacher would likely consider this strategy a successful one. However, our algorithmswere unable to distinguish this mistake from other, more conceptual mistakes. One way to overcome such difficulties is tosearch for the “closest” plan for explaining users’ TinkerPlots activities in terms of recipes, rather than searching for onlycomplete and correct plans. This can be done by using flexible CSP solvers, which search for solutions that minimize thenumber of violated constraints.6.2.3. Performance considerationsIn this section we compare the performance incurred in practice by the four recognition algorithms we have presented(measured as run-time on a commodity computer). By working to recognize interleaving plans in user logs containing incor-rect strategies and up to 80 actions, we test whether the worst-case exponential complexity presents a significant barrierto real-world plan recognition. In Table 4 we present run-times for each of our four algorithms organized by increasingtheoretical computational complexity. These results are averaged over all action sequences for each problem.2288Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–2290Table 4Average runtime (in seconds) of recognition algorithms,Problemrosarainseat beltsearringsOverallAlgorithmNoBktrk0.150.350.020.010.133.340.540.341.821.54Table 5Average number of CSPs and variables for constraint satisfaction algorithms.Problemrosarainseat beltsearringsOverallCSPbruteCSPs1993003472922490Variables1829232123SomeBktrkCSPbruteCSPprune0.11131.546.076.9236.75CSPpruneCSPs141412981761570.0921.888.423.998.02Variables49111410As shown in the table, the average run-time of the heuristic approaches, which employed limited or no backtracking,was significantly faster than that of the complete approaches. Within the complete approaches, the pruning algorithmwas significantly faster than the brute-force algorithm. This is because there were “dead-ends” in the recipe tree that thepruning algorithm was able to exploit. As can be seen in the table, CSPprune outperformed the CSPbruteForce algorithm,and in reasonable time, despite having greater worst-case complexity. However, in cases where the pruning approach failsto eliminate branches from the plan-trees, it may turn out to be slower than the brute-force approach. For example, asshown in the table, for the seat belts problem, the CSPbruteForce algorithm was faster than the CSPprune algorithms.To examine the relationship between runtime and student interaction length, we measured the correlation betweenthese variables for each algorithm. The heuristic algorithms NoBktrk and SomeBktrk showed positive correlations betweenruntime and interaction length of .752 and .508, respectively. The CSPbruteForce algorithm showed a negative correlation of−.333, while CSPprune showed a very weak, positive correlation of .050. Also, as shown in Table 4, the complete approacheswere significantly slower when running on rain than when running on the other problem. The number of possible plansfor rain, as shown in Table 1, was significantly higher than the number of possible plans for the other problems.These results support our complexity findings that the bottleneck of the incomplete algorithms is the size of the user’sinteraction log, while the bottleneck of the complete algorithms is the complexity of the recipe library. These results alsodemonstrate the applicability of our algorithms to be used in actual classrooms. As shown in Table 1, the number of possibleplans for some TinkerPlots problems is very large. Despite this fact, the almost-perfect record of the heuristic approach, andthe short runtime of the complete approaches on these instances speaks well for their overall performance.Lastly, to further compare the performance of our constraint satisfaction algorithms, Table 5 presents two additionalstatistics: the average number of CSPs built per log and the average number of variables contained in each CSP. CSPpruneoutperforms CSPbruteForce in each category, building fewer and smaller CSPs, on average.7. Future work and conclusionThis paper investigated a class of plan recognition problems for domains in which agents engage widely in exploratorybehavior. We showed that constraint satisfaction algorithms are a viable and practical approach for plan recognition in onesuch domain, that of an educational software application. These algorithms were able to correctly capture users’ plans inreal-world logs of users’ sessions in reasonable time despite the theoretical worst-case behavior and the flexible nature ofthe software. The algorithms compared favorably to faster but greedier approaches.This work is a first step towards a pedagogical agent that is truly collaborative, in the sense that it provides usefulmachine-generated support to teachers and students. For teachers, this support consists of information about students’ per-formance both during and after class. For example, presenting teachers with a visualization of students’ plans will conveywhether and how students solved a particular problem more quickly than would be possible if they had to analyze snap-shots. Teachers can also benefit from the fact that our algorithms capture false starts and incorrect solutions, alerting themto mistakes and misconceptions by the students. Existing systems for assessing students’ performance with pedagogical soft-ware work in highly constrained settings, and report simple statistics, such as the number of correct answers solved [22].Our work extends such systems to exploratory domains, in which students’ performance can be explained in part by infer-ring their plans. In a recent user study we conducted with teachers using TinkerPlots in the classroom, teachers favored theplan-based presentation to other types of visualizations, such as seeing selected snapshots of the students’ work.Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–22902289We are currently extending these results in two ways. First, we are developing methods for presenting plan recognitionoutput to teachers in order to provide them with a broad and organized view of students’ activities. Second, we are evalu-ating the ability of the algorithms to generalize to a different pedagogical software system for teaching chemistry to collegestudents [51].This work raises several new opportunities for involving the use of plan recognition algorithms as a basis for buildingintelligent tutors that will augment existing software tools for mathematics education. These collaborative tutors will providemachine-generated support that decides when and how to intervene with students based on teachers’ feedback to the plansinferred by the system. They will contribute to the thoughtful analysis of probabilistic models by students and increasedability of teachers to identify those students who would benefit from teacher advice. Together these abilities should lead toimprovements in both teaching and learning.AcknowledgementsThis work was supported by NSF grant number REC-0632544. We are indebted to Craig Miller for developing the Tinker-Plots logging facility. Thanks very much to the anonymous reviewers for their helpful comments. Thanks to Elif Yamangil forassisting with the development of the greedy algorithm, and to Cliff Konold for helpful discussions. A special thanks goes toOfra Amir for reading and commenting on previous drafts of this work.Appendix A. Experimental problemsWe detail the four TinkerPlots questions posed to subjects and considered in our empirical evaluation of the algorithms.rosa:rain:Jessica has 4 letters printed on cards: R, O, S, and A. After mixing them up, she blindly picks the 4 letters one ata time and arranges them in line in the order she chose them. Build a TinkerPlots model and use it to help youestimate the probability of Jessica spelling the word ROSA.There is a 75% chance of rain for each of the next 4 days. Build a TinkerPlots model and use it to help you estimatethe probability of getting rain on all 4 days.seat-belts:If you get into an accident, you are much less likely to be injured if you are wearing your seat belt. Build aTinkerPlots model for people that1. are either wearing seat belts or not,2. then are either injured in accident or not injured in an accident.Design your factory so that the people wearing seat belts are less likely to get injured than those not wearingthem. In your model, what is the probability of people being injured in an accident? What is the probability ofbeing injured in an accident when you are wearing a seat-belt?earrings: Build a TinkerPlots factory that1. makes people that are girls or boys,2. then either pierces their ears or not.According to your model, what is the probability that1. a boy has a pierced ear?2. a girl has a pierced ear?According to your model, approximately what fraction of people you meet on the street will have pierced ears?References[1] D.W. Albrecht, I. Zukerman, A.E. Nicholson, Bayesian models for keyhole plan recognition in an adventure game, User Modeling and User-AdaptedInteraction 8 (1) (1998) 5–47.[2] J.R. Anderson, A.T. Corbett, K.R. Koedinger, R. Pelletier, Cognitive tutors: Lessons learned, The Journal of Learning Sciences 4 (2) (1995) 167–207.[3] D. Avrahami-Zilberbrand, G.A. Kaminka, Fast and complete symbolic plan recognition, in: Proceedings of the International Joint Conference on ArtificialIntelligence, vol. 14, 2005.[4] T. Babaian, B.J. Grosz, S.M. Shieber, A writer’s collaborative assistant, in: Intelligent User Interfaces Conference, 2002, pp. 7–14.[5] G.E. Barton, On the complexity of ID/LP parsing, Computational Linguistics (ISSN 0891-2017) 11 (4) (1985) 205–218.[6] M. Bauer, Acquisition of user preferences for plan recognition, in: Proceedings of the Fifth International Conference on User Modeling, 1996, pp. 105–112.[7] M. Bauer, S. Biundo, D. Dengler, J. Koehler, G. Paul, A logic-based tool for intelligent help systems, in: Proc. 13th International Joint Conference onArtificial Intelligence (IJCAI), 1993.[8] J.E. Beck, B.P. Woolf, Using a learning agent with a student model, in: Proc. of 4th International Conference on Intelligent Tutors, 1998.[9] N. Blaylock, J. Allen, Recognizing instantiated goals using statistical methods, in: Workshop on Modeling Others from Observations, 2005, pp. 79–86.[10] M.E. Bratman, Intention, Plans, and Practical Reason, Harvard University Press, Cambridge, MA, 1987.[11] M.E. Bratman, D.J. Israel, M.E. Pollack, Plans and resource-bounded practical reasoning, Computational Intelligence 4 (3) (1988) 349–355.[12] J.S. Brown, R.R. Burton, Diagnostic models for procedural bugs in basic mathematical skills, Cognitive Science 2 (2) (1978) 155–192.[13] H.H. Bui, A general model for online probabilistic plan recognition, in: Proc. 18th International Joint Conference on Artificial Intelligence (IJCAI), 2003.[14] S. Carberry, Plan Recognition in Natural Language Dialogue, MIT Press, 1990.[15] S. Carberry, Techniques for plan recognition, User Modeling and User-Adapted Interaction 11 (1) (2001) 31–48.[16] E. Charniak, R.P. Goldman, A Bayesian model of plan recognition, Artificial Intelligence 64 (1) (1993) 53–79.2290Y. Gal et al. / Artificial Intelligence 176 (2012) 2270–2290[17] P.R. Cohen, C.R. Perrault, J.F. Allen, Beyond question-answering, in: W. Lehnert, M. Ringle (Eds.), Strategies for Natural Language Processing, 1981,pp. 245–274.[18] C. Conati, A. Gertner, K. VanLehn, Using Bayesian networks to manage uncertainty in student modeling, Journal of User Modeling and User-AdaptedInteraction 12 (4) (2002) 371–417.[19] A. Corbett, M. McLaughlin, K.C. Scarpinatto, Modeling student knowledge: Cognitive tutors in high school and college, User Modeling and User-AdaptedInteraction 10 (2000) 81–108.[20] D. Davidson, Intending Essays on Actions and Events, Clarendon Press, 1980, pp. 83–102.[21] R. Dechter, Constraint Processing, Morgan Kaufmann, 2003.[22] M. Feng, N. Heffernan, K. Koedinger, Addressing the assessment challenge with an online system that tutors as it assesses, User Modeling and User-Adapted Interaction (ISSN 0924-1868) 19 (3) (2009) 243–266.[23] Y. Gal, E. Yamangil, A. Rubin, S.M. Shieber, B.J. Grosz, Towards collaborative intelligent tutors: Automated recognition of users’ strategies, in: Proceedingsof Ninth International Conference on Intelligent Tutoring Systems (ITS), Montreal, Quebec, 2008.[24] G. Gazdar, Generalized Phrase Structure Grammar, Harvard Univ. Press, 1985.[25] C.W. Geib, M. Steedman, On natural language processing and plan recognition, in: Proceedings of the 20th International Joint Conference on ArtificialIntelligence (IJCAI), Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2007, pp. 1612–1617.[26] C.W. Geib, R.P. Goldman, A probabilistic plan recognition algorithm based on plan tree grammars, Artificial Intelligence 173 (11) (2009) 1101–1132.[27] M. Ghallab, D.S. Nau, P. Traverso, Automated Planning: Theory and Practice, Morgan Kaufmann Publishers, 2004.[28] R.P. Goldman, C.W. Geib, C.A. Miller, A new model of plan recognition, in: Proc. 15th Conference on Uncertainty in Artificial Intelligence (UAI), 1999.[29] B.J. Grosz, C.L. Sidner, Plans for discourse, Intentions in Communication (1990) 417–444.[30] J.K. Hammerman, A. Rubin, Strategies for managing statistical complexity with new software tools, Statistics Education Research Journal 3 (2) (2004)17–41.[31] E. Horvitz, Principles of mixed-initiative user interfaces, in: Proc. of ACM SIGCHI Conference on Human Factors in Computing Systems, 1999.[32] R.M. Karp, Reducibility among combinatorial problems, in: R.E. Miller, J.W. Thatcher (Eds.), Complexity of Computer Computations, Springer, New York,1972, pp. 85–103.[33] H.A. Kautz, A formal theory of plan recognition, PhD thesis, University of Rochester, 1987.[34] C. Konold, C. Miller, TinkerPlots Dynamic Data Exploration 1.0, Key Curriculum Press, 2004, http://www.keypress.com/x5715.xml.[35] N. Lesh, Adaptive goal recognition, in: Proceedings of the 15th International Joint Conference on Artificial Intelligence, 1997, pp. 1208–1214.[36] K.E. Lochbaum, A collaborative planning model of intentional structure, Computational Linguistics 4 (1998) 525–572.[37] J. Mayfield, Controlling inference in plan recognition, User Modeling and User-Adapted Interaction 2 (1) (1992) 55–82.[38] D.S. Nau, S.J.J. Smith, K. Erol, et al. Control strategies in HTN planning: Theory versus practice, in: Proceedings of the National Conference on ArtificialIntelligence, 1998, pp. 1127–1133.[39] M.E. Pollack, Some requirements for a model of the plan inference process in conversation, in: Communication Failure in Dialogue and Discourse:Detection and Repair Processes, 1987.[40] M.E. Pollack, Plans as complex mental attitudes, Intentions in communication, 1990.[41] D.V. Pynadath, M.P. Wellman, Probabilistic state-dependent grammars for plan recognition, in: Proceedings of the 16th Conference on Uncertainty inArtificial Intelligence, 2000, pp. 507–514.[42] A. Quilici, Q. Yang, S. Woods, Applying plan recognition algorithms to program understanding, Automated Software Engineering 5 (3) (1998) 347–372.[43] S. Reddy, Y. Gal, S.M. Shieber, Recognition of users’ activities using constraint satisfaction, in: Proceedings of the First and Seventeenth InternationalConference on User Modeling, Adaptation and Personalization, 2009.[44] K. Ryall, J. Marks, S.M. Shieber, An interactive constraint-based system for drawing graphs, in: Proceedings of the 10th Annual Symposium on UserInterface Software and Technology (UIST), 1997.[45] S.M. Shieber, Direct parsing of ID/LP grammars, Linguistics and Philosophy 7 (2) (1984) 135–154.[46] C.L. Sidner, Plan parsing for intended response recognition in discourse, Computational Intelligence 1 (1) (1985) 1–10.[47] K. VanLehn, C. Lynch, K. Schulze, J.A. Shapiro, R.H. Shelby, L. Taylor, D.J. Treacy, A. Weinstein, M.C. Wintersgill, The Andes physics tutoring system:Lessons learned, International Journal of Artificial Intelligence and Education 15 (3) (2005).[48] M.B. Vilain, Getting serious about parsing plans: A grammatical analysis of plan recognition, in: AAAI, 1990, pp. 190–197.[49] R. Weida, D. Litman, Terminological reasoning with constraint networks and an application to plan recognition, in: Proc. of the 3rd Int. Conf. on thePrinciples of Knowledge Representation and Reasoning (KR-92), Citeseer, 1992, pp. 282–293.[50] R. Wilensky, Why John married Mary: Understanding stories involving recurring goals, Cognitive Science 2 (3) (1978) 235–266.[51] D.J. Yaron, M. Karabinos, A. Borek, B. McLaren, K.L. Evans, G. Leinhardt, Tracking and supporting learning in open-ended activities involving a virtuallab simulation, in: The 238th American Chemical Society National Meeting, Washington, DC, 2009.