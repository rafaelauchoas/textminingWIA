ELSEVIER Artificial Intelligence 72 ( 1995) 217-304 Artificial Intelligence On information invariants in robotics * Bruce Randall Donald* Computer Science Department, Cornell University, 4130 Vpson Hall, Ithaca. NY 14853-7.501, USA Received September 1992; revised April 1994 Abstract We consider the problem of determining the information requirements to perform robot tasks, invariants. This paper represents our attempt to characterize a using the concept of information family of complicated and subtle issues concerned with measuring robot task complexity. We also provide a first approximation to a purely operational theory that addresses a narrow but interesting special case. We discuss several measures for the information complexity of a task: (a) How much internal state should the robot retain? (b) How many cooperating agents are required, and how much communication between them is necessary? the in order to record state or sensory information to perform a task? (d) How much environment information is provided by sensors? and (e) How much computation is required by the robot? in order to compare the We consider how one might develop a kind of “calculus” on (a)-(e) power of sensor systems analytically. To this end, we attempt to develop a notion of information invariants. We develop a theory whereby one sensor can be “reduced” to another (much in the spirit of computation-theoretic among collaborating autonomous agents. reductions), by adding, deleting, and reallocating (a)-(e) (c) How can the robot change (side-effect) *This paper describes research done in the Robotics and Vision Laboratory at Cornell University. Support for research is provided our robotics IRI-9000532, the Air Force Office of Sponsored Research, Bell laboratories. IRI-9201699, in part by the National Science Foundation under grants No. IRI-8802390, and by a Presidential Young Investigator the Mathematical Sciences award to Bruce Donald, and in part by and AT&T Institute, Intel Corporation, * E-mail: brd@cs.comell.edu. 0004-3702/95/$09.50 SSDIOOO4-3702(94)00024-U @ 1995 Elsevier Science B.V. All rights reserved 218 B.R. Donald/Artificial Intelligence 72 (1995) 217-304 Part I-State, communication, and side-effects 1. Introduction In this paper we investigate the information requirements for robot tasks. Our work to the takes as its inspiration robotics community can be found the information in 1989 [ 241, although in the theoretical literature invariants that Erdmann rigorous examples of information invariants from as far back as 1978 (see, for example, introduced ’ 11,351). Part I of this paper develops the basic concepts and tools behind information invariants in plain language. Therein, we develop a number of motivating examples. provide a fairly detailed analysis. sensors and computation. This analysis will call for some machinery whose complexity is best deferred until In Part II, we In particular, we admit more sophisticated models of that time. A central has been robot’s actions to determine what to acquire theme to previous work (see the survey article information that information is needed by a particular [ 111 for a detailed review) is required to solve it. Key questions concern: to solve a task, and to direct a (1) (2) (3) (4) robot to accomplish a particular What information How may the robot acquire such information? What properties of the world have a great effect on the fragility of a robot plan/program? What are the capabilities environments) (in a given environment of a given robot or class of task? ? that (say) is encoded In addition is not dynamic. robots, contribute towards simplifying into both the environment These questions can be difficult. Structured environments, such as those found around the robot’s task because a great amount implicitly, and the robot’s (and their effects) are difficult to measure. We wish to the mechanics are quasi- in the assumption how much in the assumptions, we may ask the converse: how much infor- strategies to reduce com- the possible outcomes of little or no industrial of information is encoded, often control program. These encodings encoded the information quantify static, or that the environment information mation must the control system or planner compute? Successful manipulation often exploit properties of the (external) physical world (e.g., compliance) uncertainty putation, in which an action by dint of physical computation; expensive. Since during execution we may witness very little “computation” of “algorithm”, in obtaining meaningful that a theory of information in the sense to apply upper and lower bounds on the true task complexity. We hope the sensitivity of plans such strategies may require these strategies may be computationally laws. Executing in contrast, planning or simulating and hence gain information. Often, such strategies exploit mechanical from computer science have been difficult of the task circumscribes can be used to measure the mechanics to determining techniques traditional invariants ’ Erdmann introduced the notion of measuring task complexity somewhat complicated; the interested reader is referred to [ 24 1. in bit-seconds; the example is important but B.R. Donald/Artificial Melligence 72 (I 995) 217-304 219 to particular possible. assumptions about the world, and to minimize those assumptions where in from robotics invariants represents to perform information a paradigm the intrinsic Increasingly, less relevant the scientific tasks or sensors for characterizing the world. From researchers doubt of plan construction culture. This change seems relevance the external environment. algorithms. Unfortunately, the world and incrementally that the robot, on booting, We would like to develop a notion of information of robotics operations. We may view information this measure it remains a useful tool. Its apparent diminished to online algorithms. assume a strictly offline paradigm. For example, sensors, invariants to some measure of information. The idea is that the task-if you required in computational geometry, a successful input sizes and upper and lower bounds in robotics, in embedded systems shift that we may in the offline model, we reads a geometric model of the world from to plan. As an alternative, we would also like to consider online builds data structures ‘Qpically, online agents are not to have an a priori world model when the task begins. Instead, as time evolves, forces the agent to move, sense, and (perhaps) build data structures tasks, and the complexity as a mapping this measure characterizes will, a measure of complexity. For example, measure has been developed for characterizing for geometric although reflects a change from ofline reasonably might assume a disk and proceeds paradigms where the robot investigates that in some sense represent assumed the task effectively to represent the complexity model?’ often appear secondary, working their capabilities, online our work to the recent but intense agents. In particular, we discuss what kind of data structures the environment. We also discuss through a system of spatially it is profitable systems. However, is given an u priori world two robots. We discuss formal models of in Part I link robots, TOMMY and LILY, which may be viewed as online and how they are programmed. We also consider for situated autonomous robots can build to represent of state sensorimotor directions. In particular, online paradigm. The chief lacuna is a principled strategies gap in Part II, where we provide a theory of situated framework Our theory intrinsic hardness or difficulty. serve as “lower bounds” developed agents and in certain crucial in the of devices for analyzing online to fill this systems. We attempt sensor systems. We argue that this certain kinds of important questions about sensors. invariants. When a measure of to a measure of could invariants then in the same way that lower bounds have been the online viewpoint, offline questions for a known environment, separated agents. to explore online paradigms sensing has never been carefully considered or modeled the situated automata of [ 11. The examples In Part I of this paper, we describe theory of sensori-computational of state, and the distribution If these notions are truly is natural is intended information then in the armamentarium to reveal a system’s in online paradigms it leads naturally the externalization for autonomous such as “what if not artificial. can be found, to be extended the framework for answering foregrounding in computer in robotics, We believe information invariants intrinsic, science. remains interest robots, these In our quest for a measure of the intrinsic information are inspired by Erdmann’s monograph on sensor design interesting (in motion planning the complexity-theoretic lower bounds [ 9,30,43,45] (see, e.g., questions requirements of a task, we [ 251. Also, we note that many for sense) have been obtained see, e.g., 14, ; for upper bounds 220 U.K. Donuld/Art~ficirrl Intelligence 72 (1995) 217-304 The goals outlined here are ambitious that are “faithful” attack on perceptual to it [46]. His theory has developed a theory of synthetic automata which explore the is set in a framework where sensors are logical predicates. Perhaps our theory could be attack on a similar problem. This work was inspired by the [ 141 and [32] has developed the kinds of assumptions its environment. He also gives source- to the work research on 6, 121). Rosenschein world and build data structures logical viewed as a geometric theoretical by the experimental a semantics a sensori-computational to-source discussed here in Section 1, for a detailed bibliographic the geometric systems program makes about In addition essay on previous theory of planning under uncertainty, begun by Donald and Jennings that models and quantifies and Rus [33]. Horswill on sensori-computational studies of Jennings transformations for sensory equivalence “circuits”. see, e.g., [ 111 or [ 131. and we have only taken a small step towards for our inquiry, but we are far from invariants, information provides the setting above provide literature l-3) to raise issues concerning them. This paper is intended 4-9) we describe one particular some practical and theoretical motivations (Sections In part II (Sections theory contains a notion of sensor equivalence, and tools, and take a first stab at a theory. Part I of for our them. The questions answering survey some relevant this paper approach. theory. This reductions intended “reductions” in the four questions and the role of calibration the semantics of sensor systems precisely; formal, and contains a number of claims and lemmata. This formalism is used to explore some the semantics of properties of what we call situated our “reductions”. The results of Section 8 are then used in Section 9 to derive algebraic algorithms together with a notion of that may be performed between sensors. Part II contains an example which is the potential of a such a theory. We make an analogy between our interested especially complexity” above will find a discussion of “installation in Section 5 below. Section 8 discusses and the reductions used in complexity sensor systems. We also examine for reducing one sensor and very operational as such this section is mathematically theory. Readers in comparing to illustrate to another. sensors I. I. Research contributions and applications the “power” of such systems. The examples crisp analytical comparisons. We present look very different. Part I of this paper attempts similar to demonstrate Robot builders make claims about robot performance these claims and compare the systems. In and resource consumption. think that (or even I really for similar (or sensor systems) tasks may is that two robot programs it is hard to verify issue general, the key identical) how very different systems can accomplish to compare that they permit as to demonstrate theorems about systems. The analyses theory, which our on geometric making our comparisons. Our algorithms it computational; we give effective the standard of crispness and physical information represents relatively tradeoffs to which we aspire: that we believe can be proved in Part I are illuminating a systematic attempt reasoning. Finally, we try to operationalize tasks. We also discuss why it is hard in in Part I are distinguished so these examples these are the kinds of for sensorimotor but ad hoc. In Part II, we present based our analysis by for computing to make such comparisons theoretical) procedures precise. (albeit are exact and combinatorially B.R. Donald/Artijicial Intelligence 72 (1995) 217-304 221 (that the components sensori-computational is, build one sensor using to quantify when we can “efficiently” complexity”. Our measure of information too much stuff”. The last phrase is analogous compare embedded that attempts <I systems. To do so, We wish to rigorously build we define a “reduction” one sensor system out of another of another). Hence, we write A 61 B when we can build system A out of system B to “without adding much without “adding both information is relutivized components of B, and to to the information in measuring some tricky problems the bandwidth of A. This relativization in the theory to oracles sensor complexity. of computation. Hence, we write A <I B if we can build a sensorimotor that system of B, plus “a little rewiring”. A and B are modeled simulates A, using the components their internal components. However, our as circuits, with wires (data-paths) connecting in that systems differ from computation-theoretic sensori-computational their spatial configuration-i.e., as important as their connectivity. of the sensori-computational circumvents In this sense, our “components” location of each component-is (CT) “circuits”, are analogous complexity complexity the spatial the restrict resources resources instead, we can constrain We develop some formal concepts the range of admissible permutations. the analysis. Permutation models in building another sensor. Intuitively, such as the active and passive compo- (e.g., infra-red emitters and detectors). Geometric codesignation I.e., we do not allow at the same formalizes our notion they must be reconnected further relocation; such as on a robot, or at a goal. Output communication to facilitate permissible ways to reallocate and reuse resources it captures the notion of repositioning nents of sensor systems constraints arbitrary location”, of “a little bit of rewiring”. When using “wires”, or data-paths. usually need to add a communication mechanism components. Like CT reductions, A 6, B defines an “efficient” sors that takes B to A. However, we can give a generic algorithm reductions are widely useful or whether demonstrate on algorithmic so that the strength of our transformations is open; however we try to the potential usefulness both through examples and through general claims tractability. We also give a “hierarchy” of reductions, ordered on power, can be quantified. resources, we will the now spatially separate on sen- our can exist for CT.) 2 Whether (whereas no such algorithm there exist better reductions If we separate previously resources are permuted, to be “installed such reductions for synthesizing transformation to connect colocated (2) (3) is more powerful?” two sensori-computational systems A and B, we can ask for application of these ideas: (in the sense of A <I B, above). the following potential Given We foresee ( 1) (Comparison). “which (Transformation). We can also ask: “Can B be transformed (Design). Suppose we are given a specification The bag of parts consists of boxes and wires. Each box is a sensori-computational component pose and (ii) hook components decide, can we “embed” of A? The algorithms its inputs. The “wires” have different bandwidths, that computes a function of (i) together. Then, our algorithms location or and they can the also for A, and a “bag of parts” for B. of B so as to satisfy the specification (“black box”) the boxes its spatial into A?” * For example: no algorithm exists to decide the existence of a linear-space (or log-space, polynomial time, Turing-computable, etc.) reduction between two CT problems. 222 B.R. Donald/Artijicial Intelligence 72 (1995) 217-304 (4) using the bag of parts B?” reduction). Consider application 3, above. Suppose (that is, how the boxes should be placed in the world, and give the “embedding” how they should be wired together). Hence, we can ask: “Can the specification of A be implemented (Universal to the specification an “embedding” Since this reduction the components of A relative over the configuration the job of the components that in addition for A, we are given an encoding of A as a bag of parts, and that A <I B. the “power” of is relativized both to A and to B, it measures of A, we can ask, “can the components in B. By universally quantifying that specification. Suppose to the components of B always do to implement of A?’ further Our paper represents that our formalism does not currently consider. We discuss and acknowledge in Section 12.1. a first stab at these problems, and there are a number of issues these issues 2. Examples 2.1. A following task 2.1.1. A method of inquiry follow to information issues related the other. Now, many two autonomous mobile To introduce our ideas we consider a task involving in the setting of a single agent. We wish, however, robots. invariants to relate our to the results of Blum and Kozen (in Section 2.2 below), who consider mul- resources among of a task are made explicit. That is, the In science, often one learns a lot about the structure of an algorithmic problem is One robot must can be investigated discussion tiple agents. Second, one of our ideas is that, by spatially distributing collaborating by asking, “How can this task be performed by a team of robots?” one may highlight information for this is, so far, largely anecdotal. the evidence computer by parallelizing useful that a similar methodology it; we would eventually the information characteristics In robotics, in robotics. structure. to argue agents, like following distance. A robot running Here is a simple preview of how we will proceed. We first note that it is possible to a nearby moving object, write a servo loop by which a mobile robot can track (follow) a constant so as to maintain for range calculations, using sonar sensing this program will follow a nearby object. nominal to track. If we wish to In particular, it will not “prefer” any particular kind of object local infra- program a task where one robot follows another, we may consider adding them to transmit and receive messages. the robots, enabling red communication This kind of communication allows one robot to lead and the other to follow. It provides an experimental the concept of information in which to investigate and servoing invariants. between setting 2.1.2. Details of the following task We now discuss the task of following robots, such as those described in some more detail. Consider in [ 441. The robots we have in mind are the two autonomous robots [44], but the details of their construction are not important. mobile Cornell mobile B.R. Donald/Artificial Intelligence 72 (1995) 217-304 223 robot TOMMY. Note (mounted top to bottom on the cylindrical enclosure) the I. The Cornell mobile Fig. ring of sonars, the IR Modems, and the bump sensors. LILY is very similar. The robots can move about by controlling motors attached autonomous Each robot has an onboard processor and equipped with a ring of 12 simple Polaroid ultrasonic for control and programming. to wheels. The robots are sonar sensors. We wish to consider a task in which one robot called LILY must follow another robot loop using only sonar readings and to write such a control called TOMMY. position/force It is possible control alone. We now augment the robots described in [44] as follows. in our lab.) We equip each robot with 12 infra-red modems/sensors, the robots terizes in a ring about the robot body (see Fig. 1) . Each modem consists of an emitter- arrayed like detector pair. When (e.g., TVs). s Experiments with our initial de- the remote control sign bandwidth we could expect was roughly 2400 baud-feet. That is, at a distance of 1 foot between LILY and TOMMY, we each modem essentially that the communication for home appliances (This description or receiving, [5] seemed transmitting to indicate functions charac- ’ The IR modems can time-slice between collision detection and communication; moreover, nearby modems (on the same robot) can “stagger” their broadcasts so as not to interfere with each other. 224 H.K. l~onuld/Aitifi~;~ctl IrLtelli~ence 72 (199.5) 217-304 Tommy Lily Fig. 2. The “radar screens” of TOMMY and LILY. TOMMY (7’) is approaching I*, while LILY (L) follows at speed W. a wall (on his right) at speed could expect drops to 1200 baud, and so forth. to communicate at 2400 baud; at 2 feet, the reliable communication rate We pause for a moment to note that this simple, experimentally-determined quantity is our first example of an information invariant. i is mounted so as to be at a fixed angle from the front of the robot it is at a fixed angle 8i from the direction of forward motion, which is Now, modem base, and hence to be 0. defined Now, suppose that TOMMY is traveling at a commanded each modem panel the angle 8i, and the speed U. That is, he transmits speed of u (note u need not a the i on TOMMY transmits identifier be positive). For the task of following, unique (e.g., triple: 4 (id, B;, U). following In this task, LILY transmits ‘Tommy), that when the robots are in communication means sonars and IRS), can construct a virtual “radar screen” it notes other robots, their position the same information, with a different each can “detect” id of course. This (using In effect each robot like those used by air traffic controllers, on which and heading, as well as obstacles and features of the position the heading, and the name of the other robot.5 ‘The identifier is necessary for applications involving more than two robots. Also, using the id a robot can other robots’ broadcasts is noisy, but since an adequate disambiguate s This data [ 44 I, the IRS only add information since the IR processing from its own IR broadcast (e.g., reflections off white walls). servo loop for following can be constructed to the task. The IR information does not measurably using sonars alone slow down the robot, is distributed and is not done by the Scheme controller. B.R. Donald/Artificial Intelligence 72 (199s) 217-304 225 I i I I Tommy Tommy Fig. 3. The statespace “radar screen” of TOMMY is partitioned to indicate the control for LILY. (For the task of following, we could partition LILY's screen instead, but this is clearer for exposition). On the left is LILY’s direction control; and the regions are F (follow), C (correct), and I (intercept). The commanded motion direction is shown as an arrow. On the right is LILY’s speed control, with wt being very slow, wq fast, and wt < ~2 < ws < ~4. This control partition is conditioned on TOMMY'S speed u. The screen to realize the environment. important simply a local reconstruction at each iteration through Now, robotics employs (see Fig. 2) is in local coordinates that although Fig. 2 “looks” of sensor data. Moreover, like a pair of maps, for each robot.6 It is in fact, each is these “local maps” are updated the servo loop, and so little retained state is necessary. [37] space7 the notion of configuration In our case, the configuration is the set of all configurations. and velocities of the robot. After some reflection, to describe control algorithms. The conjigurution of one of our robots is its position and head- space is the space IR2 x S’. A related notion and planning ing. Configuration space of one robot space of configurations that Fig. 2 is a geometric depiction of a state space for the robot task of following actually a representation on where The points where one robot together into regions where the same action a feedback control spaces of the robots). Depending action. (servo) action may be grouped the state space in Fig. 2 is the it may be seen (it is is required. This is a common way of synthesizing the robots are in Fig. 2, each must class. Essentially, we partition of the mutual configuration take a different control to form an equivalence is state space, which loop. See Fig. 3. (parameterized) the same takes thought, is, very The point the answer is that in this analysis, we may ask, “What state must retain?‘, After some Fig. 2 may be drawn again state must be retained between need some Fig. 2. (We do not address whatever state TOMMY would need to figure out “where lead’, only how he should modify his control so as not to lose LILY.) One consequence of this kind of “stateless” loop iterations, because information the robot LILY in is, no in an iteration we only in to the “radar screens” iteration. That and draw the information is broken, or one robot is that if communication local state to process since at each from new sensor the sensor following readings servo little, 6 In the language of [ 141, the sonar sensors, plus the IR communication, represent concrete sensors, out of which the virtual sensors shown in Fig. 2 can be constructed. The construction essentially involves adding the IR information above to the servo loop for following using sonar given in [44). The details are not particularly important to this discussion. ’ See [361 for a good introduction. 226 B.K. Donuld/Artificiul Inrelhgence 72 (1995) 217-304 L, T Fig. 4. Following around a wall. The shorter path /, is quicker by Ar than p’, but it cannot be executed without more communication or state. (no the other, is stateless information) to base a strategy then the robots have no provision from from is obscured to reacquire contact. They can certainly go into the past on which a search mode, but this mode that it is not based on retained state (data) built up from before, before the break in contact. In short, at one time-step, LILY and TOMMY wake up and look at their radar screens. Based on what they see, they act. If one cannot see the other, perhaps it can begin a search or broadcast a cry feature of statelessness, or reactivity. Let us call a situation for help. This is an essential in which the robots maintain the control loop. If they break communication communication it breaks the control in the sense presenting loop. Now, suppose in trajectory p), that TOMMY has to go around a wall, as in Fig. 4. Suppose TOMMY it the wall (as the robots may be broken. Since the following is broken to write a general such has a geometric model of the wall is not hard for TOMMY to calculate shown LILY is “stateless” task will fail, unless LILY can reacquire TOMMY. It is difficult “search and reacquire” procedure, and it would certainly delay the task. For this reason, we may prefer TOMMY to predict when line-of-sight (from a map or through that if he takes a quick reconstruction). turn around that the line of sight between above, when communication communication as described Then such trajectories would be broken, and enough, the following hence allow assume may reasonably that follows the trajectory time as p’ ‘. It might also be reasonable to follow p*, Hence, in this example, to prefer a trajectory as p’ will allow like p’ the robots task to proceed. However, slowly (Fig. 4). When executed to maintain and there is a cost: for example, we than p. Now, let p* denote so it takes the same to assume that if TOMMY slowed down enough communication, the same path as p, but slowed-down that taking p’ will take At longer the quantity At is a measure of the “cost” of maintaining the robots could also maintain communication. communication. It is a kind of invariant. But we can be more precise. the control to preserve In particular, TOMMY has more choices at which LILY servos following distance9 containing “tighten up”-that (heel, d’) essentially LILY will servo the robots permit loop. The distance to TOMMY is controlled by a constant, which we will call the to LILY, d. Hence, TOMMY, could transmit an additional message the a new following distance d’. The meaning of this message would be is, to tell LILY to servo at a closer distance. Note that the message LILY. In this case, new servo to follow TOMMY at the closer distance d’, which will successfully to navigate p while maintaining encodes a plan D-a loop-for contact. is the time-resealed trajectory from ,j 1 I9 I. ’ So, p* ‘) For an explicit use of this constant in an actual servo loop, see, for example, [ 44 ] B.R. Donald/Artificial Intelligence 72 (1995) 217-304 227 is that we could allow LILY to retain an encoding of the trajectory p. This encoding some state, and allow could be via (p), LILY. In this case, after losing contact loop, until TOMMY is by transmitting the message (or plan) p open Another possibility TOMMY to broadcast points on the path, or a control program-essentially, TOMMY transmits with TOMMY, LILY will reacquired. In both a plan-a motion plan-for the path follow Since LILY already stores some value for d (see However, detail. for the plan the storage these cases, we must allow LILY to retain enough [ 441) , we need merely state to store d or p. that. on the replace (or path) p could be significant, depending imagine Finally, we could a scenario where LILY retains some amount of state to “track” TOMMY. For example, by observing TOMMY’s trajectory before (one in communication, filter). Based on these I will not to see that it requires some amount of over time the break could, extrapolations, detail this method here, but, it is not too difficult state for LILY to do this computation; LILY could seek TOMMY in the region of highest expectation. to extrapolate [23] or a kalman for example, use forward projections let us call this amount s. it may be possible future positions is a tradeoff between execution state and internal one would There or (p)), a conjecture like program p or D, we denote measure required the number of via points on p times to encode a single point). (storage to prove about its information for p or s). What time (At), communication (transmitting is this relationship? Here (d’) is For a path or a control Ipj could their bit-complexity (the number of bits this relationship. complexity by Ipi. For example, Idea 2.1. There bit-seconds. In particular, is an information invariant c for the task of following, whose units are where t,,, to, and t, are the execution times for the three strategies above. Eq. (1) should be interpreted as a lower bound-like that Erdmann’s invariant such as ( 1) quantifies information invariants the Heisenberg are also It in bit-seconds. An principle. the tradeoff between speed, communication, to prove such crisp results we must and geometry (see Appendix F. 1) , Moreover, yield results using “order” notation first make a number of the methods .) or big-theta (0( is no coincidence information and storage. Currently, assumptions we describe below 0 ( .) ) instead of strict equality. One example of provable about dynamics typically [ 8,19,20]. dynamics. We give some details developed “trade-offs” “trade-offs” between a performance measure work (and also a performance measure. similar information [ 11, below) (e.g., This work is concerned with provable planning information in flavor invariants algorithms is given in the kinodynamic literature for robots with in Appendix F. 1. Here we note that Xavier, in [ 21,491, and Xavier obtain speed. Their methods appear to require strategy). One might view our in the absence of to Eq. ( 1). Both Erdmann and execution the “cost” of a control information invariants as investigating In this case, we cannot directly measure absolute information 228 B.R. Donald/Artificial Intelligence 72 (I 995) 2 I7-304 complexity sensori-computational Appendix El in bit-seconds. Instead, we develop a way to relativize system to another, in order to quantify (or reduce) one their (relative) power. See for more details on information invariants with performance measures. To summarize: the ambition of this work is to define the notions in Idea 2.1 so that in order they can be measured directly. Previous work [21,25,49] measure to obtain a common not to use this crutch, we first define a set of transformations systems. Second, we propose understanding these transformations the information preserve. currency for information has required a performance In order invariance. on sensori-computational invariants in terms of what 2.2. The power of the compass In 1978, Blum and Kozen wrote a ground-breaking is devoted to a discussion [ 1,351. This section compass [ 11, and we interpret and information invariants. paper on maze-searching automata their results of their paper, On the power of the robots in the context of autonomous mobile In 1990, we posed the following question together with Jim Jennings: perceptual of mobile the physical these objects reconstruction (e.g., human-specified) categories. For example, in these terms by imagining (e.g., a wall sensor) and their “parameters” Question 2.2 ( [ 151). “Let us consider a rational robot pro- gramming. There is a task we wish the mobile robot to perform, and the task is specified these in terms of external like wall, door, hallway, or Professor Hopcroft. The task terms might be “concepts” the robot has virtual sensors which can may be specified recognize (e.g., length, orien- tation, etc.). Now, of course robot is not equipped with such sensors, but is armed with certain concrete physical sensors, plus the power to retain history instead the virtual and to compute. The task-level programming sensors as a tree of computation, and state retention. A particular kind of state consists of geometric short, we imagine actuators, which can move and interrogate notes by making geometric constructions be synthesized?” in constructions; to physical sensors and taking the world its sensors while these on “scratch paper”. But what should trees runs on the robot? How may these computation robot as an automaton, connected through in which the vertices are control and sensing actions, computation, in terms of the concrete robot capabilities. We imagine lies in implementing be? What program this implementation constructions the mobile problem Let us consider this question of state, namely, what should the answer In robotics, is frequently scratch paper? is reactive, and should not build any representations), should build a geometric model of the entire environment). such as [ 391 require a worst-case II of the environment). between 0 and O(n)? Can one do better? the robot record on its the robot the robot In particular, even schemes linear amount of storage (in the geometric complexity either “nothing” or “a map” (i.e., (namely, Is there a sufficient representation that is Blum and Kozen provide precise answers cal, situated automata. This section didactically to these questions in the setting of theoreti- adopts the rhetorical “we” to compactly B.R. Donald/Art&in1 Intelligence 72 (1995) 217-304 229 interpret into Question 2.2 above. their results. While these results are theoretical, we believe they provide insight We define a maze to be a finite, two-dimensional in the maze may, in addition (DFA) to an adjacent unobstructed automaton each move an automaton and it may revisit squares. Hence, the “exploration” task However, note that in this entire section can search a maze if eventually that many modern mobile square obstructed transitions, to its automaton checkerboard. A finite transit on in the N, S, E, or W direction. We say it will visit each square. It need not halt, analog of to perform. robots are programmed is the theoretical there is no control or sensing uncertainty. this kind of “searching” We can consider augmenting an automaton with a single counter; using it can record state. then we obtain the power of a Turing machine). lo (Two counters would not be an interesting enhancement, this counter because We say two (or more) automata search a maze together as follows. The automata could be effected using global land on the same square, each in lock-step. This synchronization clocks. When two automata move synchronously, control, or with synchronized its internal transmits state to the other. equipping is uniquely Finally, we may externalize and distribute the state. Instead of a counter, we may it can drop and pick up. Each to a square, It an automaton with pebbles, which identifiable consider pebble an automaton may then drop or pick up any pebbles. senses what pebbles are on the square, plus what pebbles in the maze. On moving to any automaton it is carrying. Hence, a pure automaton simple physical two automata models the “beacons” robot-like is a theoretical model of a “reactive”, robot controllers local communication often used by mobile (as opposed to the robot’s the single counter models a limited crea- are based on DFAs). The exchange of agents. between autonomous robots, or, more generally, state) internal form of state the tape of a Turing machine. We believe is a fundamental robots the environ- of the task in compare to structure (see, e.g., [ 131) or the mechanics paradigm. How do these techniques between collaborating mobile In manipulation, the ability than to side-effect the environment tasks. Finally, It is much more restrictive communication question. the actions of the robot [ 401) seems a fundamental (Many to perform ture. state between The pebbles model the ability in order (storage). that quantifying information-theoretic ment through (see, e.g., power? We call automata with these extra features enhanced, and we will assume that au- tomata are not enhanced unless noted. Given these assumptions, Blum and Kozen demon- strate the following that a single automaton cannot search all mazes. ” Next they prove the following: they note a result of Budach results. First, ‘a A counter is like a register. A DFA with a counter can keep a count in the register, increment or decrement it, and test for zero. A single counter DFA (introduced by Fischer [28] in 1966) can be viewed as a special kind of push-down (stack) automaton (PDA) that has only one stack symbol (except for a top of the stack marker). This means we should not expect a single-counter machine to be more powerful than a PDA, which, in turn, is considerably weaker than a Turing machine (see, e.g., 131, Chapter 51). The proof that a two- counter DFA can simulate a Turing machine was first given by Papert and McNaughton in 1961 [41] but shorter proofs are now given in many textbooks, for example, see [ 31, Theorem 7.91. ‘I See [ 11 for references. 230 B.R. Donuld/ArtificiuI Intelligence 72 (1995) 217-304 ( 1) There are two (unenhanced) (2) There is a two-pebble (3) There is a one-counter These results are crisp information (a perfect) map of the maze, automata that together can search all mazes. automaton automaton that can search all mazes. that can search all mazes. invariants. that would be linear build they term the nai’ve linear-space building mobile those space geometric data structure on their “scratch paper”. But (3) to search mazes-that a lag-space is logarithmic precise answer It is clear that a Turing machine could in the size of the maze. This algorithm. This is the theoretical analog of most map- that build “topological” maps still build a linear- is that is a is, using only an amount of storage the maze can be searched. I2 This of the world, robots-even that there algorithm implies in the complexity to part of our Question 2.2. also demonstrate (1-3) However, points interesting the sense of information) is equivalent (in the environment invariants. information (1) = of beacons and com- to collaborating with to (3) suggests an equiv- state, and [ l] with a excellent example of between communication, co-agent. The equivalence of (1) and (2) this case) and a tradeoff (in general) the environment. Hence we may credit the equivalence (2) demonstrates munication. Hence side-effecting an autonomous alence side-effecting information invariance. (in 2.2. I. The power of randomization Erdmann’s Ph.D. Thesis is an investigation permitting algorithms-by the performance initial conditions finite automaton (the environment), to that of randomized [ 241. The idea is similar of the power of randomization bounds on expected performance. strategies robot to randomly perturb to randomly choose among actions, one may enhance robots, and derive probabilistic not be lost in the context of the information points out, one select among eventually visit any particular maze square is one. Randomization mazes randomized) for the search increases These observations in robotic the its own internal state, or and capabilities of ‘s This lesson should invariants above. For example, as Erdmann it to randomly that such an automaton will also helps in finite 3D to time can search any maze directions. The probability finite automata have in searching 3D mazes), although to unbounded in a 2D unbounded maze, the automaton will eventually visit any particular maze square with probability (see Section 2.2.2 for more on the problems (the mazes we have considered automata can be even extended are finite). However, mazes although about randomizing that deterministic the unobstructed if we permit the expected (as opposed somewhat. comer (in a lexicographic It suffices t2 Here is the idea. First, 1 I 1 show how to write a program whereby an ““enhanced DFA can traverse boundary of any single connected component of obstacle squares. Now, suppose the southwesternmost can then be systematically !‘min of this comer, We now machine, and we measure and the algorithm I3 While the power of randomization Erdmann was able to lift these results continuous the DFA could “remember” order) of the obstacle. Next, [ I ] show how all the free space the y-coordinate for a DFA with a single counter for maze exploration, In particular, one challenge was to consider consumes 0( log n) bits of storage. For details, see [ 1 1. to record as possible) in the environment has long been known in the context of algorithms using a Turing then !trntn < n, If there arc n free squares to the robotics domain. the bit-complexity. this algorithm (as efficiently state spaces (as opposed to graphs). simulating searched. imagine the B.R. Donald/Artijicial intelligence 72 (1995) 217-304 231 to visit time the probability it is infinite. in 3D that any given “cube” will be visited drops from one things are worse: In 3D, however, the expected one, unbounded mazes, to about 0.37. 2.2.2. What does a compass give you? Thus we have given precise examples of information for tasks (or for it may be less clear what for a sensor would be. Again, Blum and Kozen provide a or “exploration”). However, invariants task, namely, one the information fundamental searching, invariants insight. We motivate their result with the following as Question 2.3. Suppose we have two mobile in Section 2.1. Suppose we put a flux-gate magnetic compass on LILY (but described not on TOMMY). How much more “powerful” has LILY become? What tasks can LILY now perform robots, TOMMY and LILY, configured that TOMMY cannot? Now, any robot engineer knows compasses to Question 2.3 is a precise, provable answer. Happily, is relatively accurate, I4 [ l] provide some insight: are useful. But what we want in answer the compass in the case where Consider an automaton it can (of any kind) tell N,S,E,W since the neighboring N,S,E,W squares a compass, interrogate can then accurately move one square By contrast, consider an automaton in a maze. Such an automaton apart. That is, on landing on a square, to find out which are unobstructed, effectively has it can and it in any unobstructed compass direction. has no compass; on landing on a vertex, in a graph (that need not be a maze). Such an there are some number g 2 0 of to “free” other vertices, and the automaton must choose one. Hence, as Blum and Kozen point out, “Mazes and regular planar graphs appear similar on the sugace, but in fact difSer substantially. The primary difference is that an it can distinguish N,S,E, M! A compass can provide automaton in a maze has a compass: the automaton with valuable information, as shown by the second of our results” [ 11. Recall point to ( 1) , no two together can search all finite planar cubic graphs (in a cubic graph, all vertices automata have degree g = 3). They then prove that no three automata suffice. Later, Kozen showed that four automata do not suffice assumption but restrict our cubic graphs that no finite set of finite automata can search all such finite 3D mazes 131. [ 1,351 provide a lower bound ( 1) in Section 2.2. Blum and Kozen show, that in contrast, if we relax the planarity to be 3D mazes, [ 351. Moreover, to the question, it is known Hence, compass provide?’ We close by mentioning is a large literature on randomized randomization the capability can improve information “What that in the flavor of Section 2.2.1, does a there for graphs. As in Section 2.2.1, of the search automata. and performance search algorithms automaton edges leading I4 In considering closely allied with Erdmann’s work on developing how a very accurate “minimal” sensors 1251. sensor can aid a robot in accomplishing a task, this methodology is 232 B.R. Donuld/Artijiciul Intelligence 72 (1995) 217-304 3. Discussion: measuring information We have described the basic tools and concepts behind connection illustrated by example how such invariants information conceptual tradeoffs arose naturally planning are traded-off. We noted that Erdmann’s in kinodynamic and robustness complexity, between However, without a performance can be analyzed invariants situations, information invariants. We and derived. We made a In previous work, and tradeoffs. in which performance measures, to control uncertainty) (in the sense of resistance invariants are of this ilk [24]. it is more difficult (cost) measure, to develop in- to peform information (side-effect) complexity of a robotic (a) space considerations complexity are fundamentally invariants. We believe measures of infomzation include: between collaborating them is necessary? and (c) How can the robot change in order to record state or sensory formation different from performance measures. Our interest here is in the former; we will not discuss performance measures again until Appendix El. Here are some measures of the task: (a) How much internal state should the robot information retain? (b) How many cooperating agents are required, and how much communication between ronment of these categories IR communication beacons. With regard the mobile sign spectrum. For example, builders” and model-based has considered of robot “hands” kinematics of the assembly to (c), the most easily ever, “external” parking police do on tires), or assembling of lower “entropy” of external state, which we explore the envi- a task? Examples local robots, and (c) dropable to (a), we note that, of course, memory chips are cheap, but in seem to fall at the ends of the de- reactive systems use (almost) no state, while “map [ 431 the number the interference control. With regard consists of coded IR beacons; how- (as side-effects could be as exotic as chalking notes on the environment into a configuration is an important an invariant complexity measure analogous robot design space, most investigations task, and assumes global synchronous approaches use a very large (linear) imagined physical realization to perform an assembly a collection of objects for computer memory, task. This quantifies (and hence, greater autonomous mobile amount. Natarajan to (b), namely information). Calibration in Part II. required (near) form (b) In Part I, we exploited automata-theoretic for tasks, we did touch on how information results that trade-off to explore and external state. While Part I concentrates on informa- for sensors can be the In particular, we reviewed a precise way to measure invariants invariants that a compass gives an autonomous mobile (a)-(c) proves sufficient to quantify robot. Somewhat surprisingly, a compass the information internal state, communication, tion invariants integrated information trading-off supplies. the measures into the discussion. invariant illustrates sensors. That The compass for more general information is provided by sensors ? While didactically satisfying, we must introduce discussion to include task: of a robotic Part II we explore develop a kind of “calculus” two additional the kind of result that we would is, we could add a fourth measure, the examples we presented some more machinery like to prove (d) How much are perhaps in order to extend our important measures of the information complexity is required of the robot? In (d), and (e) How much computation these issues in some detail. In particular, we describe how one might the power of in order to compare on measures (a)-(e) B.R. Donald/Ar@icial Intelligence 72 (1995) 217-304 233 systems analytically. system can be “reduced” To this end, we develop a theory whereby one sensori- in the spirit of computation- among collaborating (a)-(e) to another by adding, deleting, and reallocating (much sensor computational theoretic autonomous reductions), agents. Part II-Sensors and computation 4. Sensors elements, implemented the vertices are controllers Intuitively, we can imagine a sensor system being computational in which devices, and state elements. Such a system is called a virtd sensor, outputs are computed two sensor systems E and H, we would sensors provide. sense we shall soon make precise) of superficially like to be able to determine whether they deliver “equivalent” information, like to be able to write an “equation” as a tree of sensori- and sensors, computing sensor by [ 141. In a virtual from the outputs of other sensors in the same device. Given the (in a similar sensor systems. We would the two systems are “equivalent” in the sense that that is, whether E 2 H. More generally, we would like like to be able to quantify suppose E and H are different “implementations” the information In particular, E2’H+a (2) represent to “add” the box could specify what box q we need some new sensing, or some computation where we can rigorously E. For example, existing sensory and stored data. In Part II we discuss some methods for achieving goals. To illustrate our techniques, we describe the beacon, or lighthouse their information in Part I; it is our goal here to quantify we will allow concepts will be defined precisely sensor, a sensori-computational as follows: to H to make sensor on these [25], and the sensors and to the compass discussed In the beginning, intuition. The following the output of a the relation g, and the operator +. We begin two sensors, sensor. We then develop methods informal definitions, which suffice for building invariants. These sensors bear some relation the radial sensor to compare in Section 8: the term simulate, this relationship precisely. resource, Definition 4.1 (Znfomzal) . I5 For two sensor systems S and Q we say Q simulates S if the output of Q is the same as the output of 5. In this case we write S Z Q. The operator + in Eq. (2) is what we would “something” later see that 2 is an equivalence relation. represents like to call a resource “adding” something (later, to H. Informally, this in Section 4.2.1). We will Here is a preview of the formalism we will develop. We view sensor systems as “circuits”. We model computational components these circuits as graphs. Vertices correspond sensori- (what we will call “resources” below). Edges to different of the system I5 This definition is formalized in Section 8. I. 234 B.R. Donuld/Arti$cial intelligence 72 (1995) 217-304 through which information of to different spatial allocation of the “resources”. We also permit that we consider graph immersions as well as passes. Different embeddings to be colocuted. This requires Immersions are like embeddings, the concepts above are easily formalized. For example, but they need not be injective. the operation to “data-paths” correspond these graphs correspond resources graph embeddings. this model, Under + turns out to be like taking idea One key involves system when we change all immersions?‘. Our goal will be to determine what classes of immersions information. asking: “What its immersion?” this idea through an example. is added information Sections 4.1-7 explore in a sensor is preserved under preserve lost) (or the union of two graphs. information and “What 4. I. The radial sensor sensors In [25] Erdmann demonstrates We begin with a didactic example. for from task specifications. The sensors have the property of being required to examine sensor, called the radial sensor, which is the output of one of his examples. in which the robot must synthesizing “optimal” or “minimal” for the control system a particular The radial sensor arises by considering manipulation achieve a goal despite uncertainty. the task. For our purposes, that they convey exactly the information it is sufficient in the sense to perform a method strategies a small robot system specified by (x, h)). Thus, to the robot. The robot can only command The radial sensor works as follows. Consider in the plane. Suppose is at x E IR2, and at some heading h E S’. Both these state variables are (relative to the a velocity Vet, is global direction h + A0. the angle 0,. which is the angle between h and the ray between to the goal. I6 in the robot’s indeed, loop there is a goal region G which is a small disc in the plane. See Fig. 5. The robot some configuration unknown local coordinate and the robot would move The radial sensor returns x and the goal. The robot need only command ug, to reduce This example easily generalizes control Erdmann proves) that provably attains To summarize: its distance is uncertainty It is plausible relative motions it would command that this sensor the goal. in relative direction Ae, which is, the “aim” of ~~0) see is necessary and sufficient the radial sensor returns there [ 25,381. to write a feedback to the case where that encodes 19, of the goal G-relative that the radial sensor does not reveal the configuration We will not describe possible physical [25] for a discussion. the relative heading to the robot’s current heading h. See Fig. 5. We emphasize this. of the radial sensor, but see (x, h) of the robot beyond implementations information system (that (and I7 I6 In the language of ( I4 1, the perceptual equivalence classes for this sensor are the rays emanating at n. I7 Erdmann emphasizes the special cases where the robot always knows its heading, or, where the robot’s heading is always fixed (say, due North, so that h is always identically zero) In these cases, the radial sensor returns the @hai heading to the goal. This special case arises in the domain of manipulation with a robot arm, which, of course, is why it is natural for Erdmann’s theory. The radial sensor we present is iust slightly generalized for the mobile robot domain. B.R. Donald/Artificial Intelligence 72 (1995) 217-304 235 h Fig. 5. The radial sensor E, showing heading h and relative goal direction 8,. 4.2. Lighthouses, beacons, ships, and airplanes another is to compare sensor. Our goal this a sensor system since as described, We now describe sensor using information We call “agents”. We motivate denote L and R (see Fig. 6). L will be the “lighthouse” the “ship”. The robots informally to the radial invariants. See Fig. 6. We call this a lighthouse sensor system. separated it involves robots, which we and R will be system, we will In introducing to describe sensori-computational this sensor as follows. Consider (beacon) the lighthouse introduce machinery live in the plane. two physically two mobile this sensor resources. 4.2.1. Resources Now, to analyze the information tion of the sensor system, and, in particular, we must be careful (a)-(e) be careful following kinds of resources: (Section 3) are consumed invariants, we must be careful about the implementa- to count how resources the same way that one must the for an algorithm. Let us catalog and allocated-much in performing a complexity analysis l Emitters. On L, there are two lights which we call physical emitters. There unidirectional green light shines along a ray that is anchored is a green light l!$ that rotates at a constant angular velocity. That is, the at L. The ray sweeps (at its origin) (white?) (green?) (time) : Virtual ~enmr: : Construct orientation ; and the beacons. 8en801 out of time, (define (/ (* 2 *pi* (orientation) (time-beacons white? green?)).. h , , I , , , , ‘R Concrete sensors / I , I virtual sensors , / I I , I , , , , , I g a w N / , , / , , 1.\ ,,’ physical emitters 0 I I , , , , { L Fig. 6. The “beacon” sensor H, which is based on the same principle employed by lighthouses. sensor about L. The green light can only be seen by points on that ray. Second, white light q that flashes whenever light is (rotates) there is an omnidirectional the green pointing due North. That is, the white light can be seen from all directions. that detects when a white Concrete sensors. On R, there is a photo-electric light illuminates R. Another sensor detects green light. There is also a clock on R. Computation. There is a computer on R that we can program in Scheme, following [44]. The concrete functions (as in [ 441). The functions are of type UNIT ---f BOOL, and return #t when light is sensed and #f otherwise. The clock is available as the in small units. We can measure the time measured function (time), which returns techniques. Fur- the time and space requirements using standard of a computation consumed by counting thermore, we may quantify the number of calls to (white?), and the number of bits returned. the amount of sensor information sensors above are interfaced to Scheme via library and (green?) and (time> (green?), (white?) Now, here is how lighthouses work. See Fig. 6. The “ship” R times the period the time t between a white flash and angle between North the ship is the “angle” 0 of the robot-the be computed as 0 = 2m/t,. it measures (Assuming t,,. between white flashes. Then the next green flash. Clearly and the ray from L to R-can moving slowly, relative Virtual (orientation) fied as a computation (TO), and (iii) does some computation sensors. We can immediately implement to f,,.). shown this as a virtual below. The orientation sensor sensor [ 141 called is speci- retains some local state the time that (i) calls concrete sensors, (ii) (*, /, etc.). It is easy to measure B.R. Donald/Art$cial Intelligence 72 (1995) 217-304 231 and space requirements certain virtual sensors of the “circuit” to compute orientation. We detail this implementation that computes 6’. Hence, we can implement below: the following virtual sensors “on” the resources above, we can implement Given R. 18 ; Virtual sensor: ; ; construct orientation and the beacons. (define (/ (orientation) (* 2 *pi* sensor out of time, (time-beacons white? white? white?))) green?)) (time-beacons time between beacons and event2 event1 ; ; 19 are type UNIT --) BOOL.% (define (time-beacons event1 event2) (sleep-until (let eventl) (time))) ((TO (sleep-until (time) (- event2) TO))) : utility ; sleep-until in scheme48 [44]. waits until thunk returns #t, and then returns. (sleep-until fdefine thunk) . ...) including at sea using l Resources R does not have. Let us contrast our exemplar to a real ship navigating to the location of L. True North robot ship R with an enhanced version R’ that corresponds light- house sensors. We should not confuse R with a real ship. A real ship R’ has a a point which R’ will as- features, map, on which are located a priori sume corresponds is indicated on the map. R’ computes 0 as above (see Fig. 6), and draws a ray on the map, anchored at L, that is 6’ degrees to possessing has a compass. an accurate We observe communication unenhunced sources. that it is on that ray. In addition of L, a real ship often could approximate like radios. to (b) in Section 3. Our it has none of these re- roughly is not a real ship, and compass. Real ships also have communication In the robotics domain, orientation from North. R’ now knows a map, and knowing the map coordinates robot R, however, odometry resources compare devices Modern aircraft navigate using two sensors similar to the radial and lighthouse An Automatic Direction Finder (ADF) is a radial sensor. An ADF sensors. is simply a needle ‘s We must make some assumptions the clock and the processor are very fast relative I9 Objects of type UNIT - BOOL are called boolean rhunk.~. to the green light (and the ship). to prove this real-time program is correct. For example, we must assume 238 B.R. Donald/Artificial Intelligence 72 (1995) 217-304 you; coordinates radio transmitter, to a ground is a lighthouse of a green and white sensor. The VOR ground light arrangement. The radio receiver it, and then tells you the radial direction in relative airplane coordinates. You do not that points need to know where you are or which way you are headed. You simply make the needle the airplane. So it is a radial sensor, and you track into point straight ahead, by turning the goal. A VOR (VHF Omnirunge) transmitter has the equivalent plane decodes coordinates. Then, look at it, and turn the plane VOR uses a clock, just like in the lighthouse. The “green emitter” 30 Hz, and the white “North” decodes the difference, do not use light, but they broadcast in the in global if you actually want to fly to the VOR you have to have a compass, to fly in the same direction as your radio indicates. The in the VOR rotates at in the plane to give a direction. VORs range instead of the visual range. the source be straight ahead of is in local sensor you need a compass. The radial sensor light flashes 30 times a second. The receiver To follow a radial sensor you only need to follow a lighthouse like in the lighthouse from the transmitter, in the Megahertz example, to make just and the lighthouse sensor is in global coordinates. fewer instruments, The ADF requires but pilots tend to use the VOR. Why? Because that way you can look up your position on a chart, which is often what you care about (one VOR gives you a line; two give you your location). But if you just want to get somewhere, all you need is the ADF. 2o 5. Reduction of sensors 5. I. Comparing the power of sensors Let us call the radial sensor E and the (unenhanced) transform similar: both have components are, of course, superficially locations. Both sensors measure angles. Of course, cannot the information E, without consuming more resources. These sensors deliver in that neither delivers strictly more information to be able to compare two sensors even when We wish than the other. delivered by H into the information at two spatially lighthouse system H. The sensors separated they measure different angles. We of specification incomparable information, they deliver incomparable information. To do this, we introduce a mechanism compare E nor H delivers strictly more information, induced by our reduction. called reduction, which allows us to the power of two sensor systems such as E and H. Hence, even though neither they are comparable under a partial order 5.2. Sensor reduction The analytic goal of sensor reduction is to be able to write “equations” The operational goal is to build one sensor out of another, and to measure like Eq. (2). the “power” 2” There are some other reasons for using VORs, such as the fact that VORs are VHF while ADFs are LF/MF, so ADF reception gets blocked by thunderstorms while VOR reception does fine. On the other hand, VORs require line-of sight, whereas ADFs will work over the horizon. B.R. DonakVArtijicial Intelligence 72 (1995) 217-304 239 L := G Fig. 7. Reduction using a compass hR. for the resources we add. To illustrate of the construction by a careful accounting sensor E from sensor concept, we give two ways of constructing that R is located at x E R* and has heading h E St. However, R Section 4.1, we assume (x, h) . Before cannot sense these state variables and it does not know its configuration we begin we stress the following: our goal is to change sensor H (by adding resources) so as to simulate the angle t?,, which sensor E. We have accomplished this task when R knows in Figs. 5, 7, and 8. If. First, following is shown the 5.2.1. A reduction by adding a compass We sketch a way to construct sensor E from H. This way is easy since it involves adding a powerful function S from sensors we denote ~1, ~2, and sg (see Fig. 7): resource, namely a compass, to H. We will model to sensors. The reduction contains the following this reduction as a steps , which (st ) We place the beacon L at the goal G. 240 B.R. I)o,zctll/Artificiul Intellipvm 72 (I 995) 217-304 (S2) CS) sensor called a compass*’ We add a concrete heading h. The devices on R compute 0 using then compute 8, = rr - Ir - 19. (See Fig. 7). The reduction also adds a small amount of computation to R. The compass senses the the function (orientation) above, and this by defining two subtractions). We handle Specifically, we define a sensor hi takes the output value of 0 from specified compute on R. We will continue plus a small amount of computation. (orientation) in Step ss. IZR could be implemented the value 0, given 12 and 8. The subscript R of hR denotes to refer call hR a “compass” even though to be a device that (i) computes In this reduction all the changes are made to R; L remains the compass to include (but only a constant amount- this computation. the heading h, (ii) as an input, and (iii) outputs 8, as to by a compass plus a small “circuit” that it is installed it is really a compass the same. Now, recall the Eq. (2). Intuitively, we can substitute hR for the box q in this equation, and define , ~3 above. + operator to encode how hR is added to H, as specified in Steps ~1,. 5.2.2. Reduction using permutation and communication The reduction in Section 5.2. I requires adding new resources involves resources redistributing next reduction we consider involves Surprisingly, for permutation distributed may be viewed as a way of arranging to add information, a redistribution two new concepts. The first is permutation, (the compass hR). The and it in a sensor system, without consuming new resources. of resources can add information to the system. it is necessary for the sensor system In order to be spatially (as, for example, H is; see Fig. 6). When permutation in a configuration resource is communication. It measures resources primitives of the form COMM(L communication it gains information, of lower entropy. (b) in Section 3. We con- + R, info), which indicates only makes sense in info to R. Like permutation, sensor system. That The second concept sider adding communication that L sends message a spatially distributed can communicate complexity tination. External data-paths have a different permutation ing” internal data-paths. To analyze a system collaborating of autonomous to the system. can change “for free” the information (alone) is, because spatially colocated components in our model, only “external” data-paths add information Internal data-paths have the same (spatial) (spatial) source and des- source and destination. Hence, complexity of a system by “externaliz- like H, we view it as a system composed resources. The agents L and R, each of which has certain primitive COMM(.) cation by counting the only kind of communication abbreviate henceforth it by cOMM(irzfo). above we view as shared between L and R. We measure communi- the number of agents and the bits required info. This is we will consider here (i.e., L ---) R), and so we will to transmit *I In using the term “compass” we make no commitment the “compass” as sensing magnetic implemented any fixed direction senses the projection of a perfect position sensor using odometry or dead-reckoning, In particular, tields). plus some for our purposes. and need not be “true North”. technology to a particular is an orientation (such in principle be initial calibration. Moreover, “North” N can be In the language of I38 I, the compass for implementation that could sensor :I* E R2 x S’ onto S’. B.R. Donald/Artificial Intelligence 72 (1995) 217-304 241 N := h R physical emitters comm (0 L := G ; Virtual *ensor: i construct orientation ; and the beacons. sensor out of time, (define (orionte.ion) (1 (* 2 *pi* (time-beacons white? green?) ) 10 = &I Fig. 8. Reduction using permutation and communication Given contains these concepts, we can sketch another the following steps, which we denote ~1, ~2, and so forth. reduction y. See Fig. 8. The reduction (~1) As before, we place L at the goal G. (~2) We move the physical emitters t from L to R (i.e., we mount them on the for the emitters “North” robot). heading. That is, the white (to R) North, which is defined sensors the concrete should be installed light flashes when the green in the direction of R’s the local light passes to be the robot’s heading, h. (green?), (white?), and (time) from R to (~3) We move L. (~4) We move the virtual sensor this program will run on L. (orientation) coded above to L. That is, now See Fig. 8. Given ( ~1, . . . ,~4), by calling the value of the angle Br shown now compute knows 8,, R does not. We solve this problem by allowing L to communicate 6, to R using the COMM(.) primitive described above: (orientation), the procedure L can in the figure. However, although L now the value (~5) L communicates the value of Or to R using the primitive COMM(6,). Note that the permutation steps (~2,. . , y4) the sensors and emitters. We do not view require no new resources. They merely of the sensor the relocation the virtual to L”. Instead, we view sensor as “moving the computer as a computational circuit; we move that circuit to L. require permuting virtual (orientation) 242 B.R. Donald/Artificial Intelligence 72 (I 995) 217-304 is describing how the various physical calibrations. Since these calibrations resources should constrain the them arbitrary, is some spatial relationship to leaving the various resources, as opposed to the system. A calibration 5.3. Installation notes Crucial to installing a sensor since among be lined up. We call these alignments spatial relationships they effectively add information that is locked time. Even when it does change, system, calibration For example, by eliminating thereby eradicating can displace installation for describing concrete, let us consider H in the two reductions that uncertainty an invariant introduces the system can measure the initial calibration may still add information into place at the outset. This relationship may (or may not) change over to the to the initial setting. Hence, for the lifetime of the system. at installation, we perform a kind of calibration, for the duration of the calibration. Hence, calibration relative distances (at best) that persists uncertainty the task of dealing with sensor uncertainty or layout phase. The purpose of this section these calibrations, which we call installation notes. To make the calibrations necessary s (Section 5.2.1) and 1 (Section 5.2.2). ** is to introduce from the execution phase to the formal means this more to permute and install sensor system The installation Note II (Step sl) and Note 12 (Step YI ). The installation It, I2, and so forth. notes are numbered notes for Steps SI and YI are identical. When installing L at G, we must make sure that L and G line up perfectly; otherwise, the angle measured will not be exactly Br. Note 13. When installing the physical emitters on L, we must make sure that “North” for the emitters line up perfectly with true North. Compare Note 15, below. Note Z4 (Step ~2). When installing the compass, we must make sure that it lines up perfectly with the heading of the robot. Note 15 (Step ~2). We want the white through R’s heading h. Hence, when make sure heading h. that “relative North” installing for the emitters light to flash when the physical the green light passes emitters on R, we must the robot’s line up perfectly with 5.3.1. Calibration complexity It is difficult to precisely measure note the following. First, the calibrations of information freedom 13, 14, and 15 are equivalent (IDOF) to the system: each installation installation calibrations. systems, each of which has configuration the information gained in calibration. However, we in 13, I,, and 1s each add an equivalent amount of two 1 degree of space S’. Hence we say that requires calibration let us consider calibrations Ii and I2 above. This installation requires a careful of two 2DOF systems. To calibrate H so that at Z_. is located at the point G the radial Now calibration clearly adds information. More precisely, note that we have so far considered sensor E at a fixed goal G in the plane. Let us denote this particular More generally, for a point y in the plane, we make the dependence E),; thus we obtain a family of sensors {E,,} parameterized installation explicit by writing by y E R*. by EC;. ** This section devolves to a suggestion of Mike Erdmann [ 221, for which we are very grateful B.R. Donald/Artijicial Infelligence 72 (199.5) 217-304 243 Similarly, the case G # y; however let us denote by HY the sensor system H installed to do at least this much work in installing H. In other words, merely so that L is located at the point y. Now, our goal is to approximate one particular EG using some EZ?. Clearly, we could consider in specifying EG we specify G, and so this is given. That is, it is no more work to locate H at G than to locate E at G, information it is the only way to implement EG. Hence, we should be and the latter is unavoidable; in order allowed to specify is a sense to some y E lR2. This argument read all their to specify specify EG. When we will drop it. that certain algorithms must at least Ii and 12 are necessary In this case, we say that the calibrations E cannot be specified without calibrating the sensor E. That is, the calibration (the subscript G in this case) the problem of approximating to calibrate a 2DOF system the calibration parameter task, it is necessary to install Hc is understood, is necessary the sensor to G-there to saying is similar in which required input. to Definition 5.1 (Informal). Consider equivalent necessary installation to specify S, we say that S dominates Q in calibration complexity. the calibrations calibrations, and when two sensor systems S and Q. When S and Q require to install Q are required sor system communication, ing discussion systems Now In Section 5.2.1 we described a reduction using a compass from H. In Section 5.2.2 we described a reduction using permutation obtaining a different new sensor system (Section 5.3), we conclude that yields a new sen- and the preced- that E dominates both of these new sensor from H. From the time of calibration) may be much earlier state in calibration it is clear complexity. that calibration a measure of the external state Quantifying external (e.g., We developed section, precisely of time in this analysis found virtual sensor (orientation). the relatively it surprising that is tricky, since the time at which is a source of information. We view calibration (see resource (c), Section 3) required as for the task. is allocated the resource than the time of the task execution. in this the special role in time). We in the it is worth noting complexity sophisticated to deal with this problem. Finally, that calibration perspective of calibration (in time would appear so crucial not only here, but also and execution may be distant 5.4. Comments on power The reduction in Section 5.2.1 requires adding an orientation implemented permuting resources since L must now communicate using a compass or odometry). The reduction and emitters). 19~ to R. of H described the permutation Let H* denote (sensors in Steps (~2,. It also requires in H’, L has not been assigned any particular Thus, R does not. By installing H* so that L is assigned called H&. Now, recall the orientation in the language of Eq. (2), we have sketched how sensor hi for R, described sensor (which may be in Section 5.2.2 requires adding communication, . . , ~4) in Section 5.2.2. location, and while L knows 8,, the location G, we obtain a sensor in Section 5.2.1. Thus, 244 B.R. Donuld/Artijicial Intelligence 72 (I 995) 217-304 EG g HG + hR, EG = HE + COMM( 8,) (3) systems. Eq. (3) holds for all G. The operator + denotes “combining” the two sensor sub- If this sounds somewhat operational, we will give a more analytic discussion the semantics in Section 6 and a formal definition in Section 8, where we describe below of our sensor model in detail. 5.4.1. Output communication The term COMM(~,) in Eq. (3) says that we permit the permuted system HE to route removed subsystem 8, from one subsystem of Hc to another, spatially the information (these subsystems happen desired output of the sensor EG. Hence the term COMM(&) (L + R) of this information within this construction. to be L and R in our case). First, note that 8, is exactly the rerouting the permuted sensor system Hz. Let us generalize denotes an internal that ranges over all possible values that a sensor Definition 5.2. Let b be a variable system can compute. We call b the output of the system. Let lK( 6) be the number of values b can take on, and define logR( b) to be both the size of b and the output size of the sensor. The output size is an upper bound on the bit-complexity of b. For example, [ 1, q] , then lK( b) = q, and log lK( b) = log q. if b takes on integer values In our example, 8, is the output of EG; the quantity is the output size of EG. over a data-path e. We will assume Now, suppose loss of generality, we take the that the information the information. Thus we to communicate unit of time to be the interval of the occasion can take the size of the output b to be the bandwidth of e. repeatedly; without b is communicated is communicated the information in the range loglK(B,) To return to our example, it is clear that we can make the permuted sensor system Hg re-routing oper- specification of EG if we merely add one internal log lK(r9,). In this case, we say we have added output communication satisfy the information ation of bandwidth to the permuted sensor system. 23 More precisely, let S be a sensor system with output 6. Let Q be another sensor the plane. Let COW(b) be a log IK( b) . Then, adding output on sensor systems: transformation system. We imagine Q as a “circuit” embedded in (say) “sensor system” with one data-path e, that has bandwidth communication Q H Q + COMM(b). The bounded-bandwidth transformation to Q can be viewed as the following can be composed with permutation data-path e can be spliced The transformation is parameterized by (the bandwidth of) S. into Q anywhere. We note that this (in either order) : Q H Q* /I Q H Q + COMM(b) H - Q* + COMM(b) II (Q + COMM(b))*. z To borrow a UNIX metaphor, is, it can copy information between subsystems, but it cannot request arbitrary this transformation allows the system to do an internal rep, but not RPC-that remote evaluations. B.R. Donald/Art@cial Intelligence 72 (1995) 217-304 245 We give a fully formal, graph-theoretic model of this transformation in Section 8.7.2. 6. A hierarchy of sensors above The examples illustrate a general principle. This principle to the notion of reduction in the theory of computation. We would like our notion of reduction reductions. Consider to the work done by computation-theoretic to do work analogous two sensor systems S and Q. Recall 4.1) and calibration complexity from Section 5.3.1. the definitions of simulation (Definition is analogous Definition 6.1. We define the internal (resp. external) bandwidth of a sensor system S edge in S. The output size to be the greatest bandwidth of any internal of S is given by Definition to be the 5.2. We define and the output size of S. We call greater of the internal bandwidth, a sensor system monotonic if its internal and external bandwidths are bounded above by its output size. (resp. external) the maximum bandwidth mb(S) external bandwidth, Definition 6.2. We write S 6 Q when (1) Q simulates S (S g Q), (2) S dominates Q in calibration (3) mb(Q) is bounded above by mb(S). complexity, and Calibration information establishing idea. Calibration and analysis of calibration exploits external this external (from calibration) complexity state. Definition 6.2 allows us to order systems on how the yields. We will complete state later, in Sections 8.7.4 and A.l. complexity measures how much information we add it. Installing a sensor system may require of the system. In two components codesignate by the spatial relation. More generally, frame in the two sensor systems S and Q, we typically relative configuration-again, much formalization Here is the basic to a sensor system when we install and calibrate physically this case we say the two components we may have to establish a relation between a component world. Most generally, when we compare must spatial relation. When all these relations are (in)equalities is simple. When all the relations are semi-algebraic system algebraically codesignated. in a of configuration, we say the is (s.a.), we say the system some spatial relation between them in some appropriate install and calibrate and a reference Now, let Q* denote a permutation of sensor system Q, as described in Section 5.2.2. (For a formal definition, see Definition 8.6.) Definition 6.3. We write S <* Q if there exists some permutation Q* of sensor system Q such that S 6 Q*. Recall the meaning of com(in.o) from Sections 5.2.2 and 5.4.1. Finally, that logK(b) = (4) 246 B.K. Doncrld/Arfi’cict/ Intelligence 72 (1995) 217-304 Definition 6.4. Given mb(S). We say S is &‘iciently reducible to Q if two sensor systems S and Q, choose b such s <* Q + COMM(/)). In this case we write S <I Q. For monotonic sensor systems, it suffices Appendix B) . This special case motivates where we add “output communication” to take b to be the output of S (see side of (4), the construction on the right-hand to the sensor system Q (Section 5.4.1) We now recap a couple of crisp results using reductions: Claim 6.5. (a) EC < HG + hR, and (b) EC < HT; + COMM(6,). the discussion Proof. Recall (a), we use the reduction obtained by the reduction using permutation that employs a compass (Section 5.2. I ) . The proof of (b) 0 (Section 5.2.2). and communication complexity. To obtain is from Section 5.3.1 on calibration Now, recall Eq. (3). The relation EG. ‘? HG + h R, which derives from the compass since adding a new the in Section 5.2.1, does not imply efficient sensor hR is too powerful in Section 5.2.2: reducibility. However, by reduction concrete reduction to imply efficient reducibility, Proposition 6.6. Erdmann’s sensor system H, that is E <I H. radial sensor E is eficiently reducible to the lighthouse Proof. Recall EC. From this, and Claim 6.5(b), we conclude from Eq. (3) that EG Z Hz + COMM(~,), that E <I H. 0 and that 6, is the output of 7. Information invariants The relation <t defines a hierarchy of sensors. Compare [ 141, who propose a geometric program on their perceptual equivalence complexity of their information lattice of for the analysis and synthesis of sensors based classes. The relation <I orders sensor systems on the invariants. 24 the perceptual to develop a geometric account of information ‘4 It is possible For more on this connection, with a different represents “Permutations” are viewed as a kind of information-preserving or “automorphisms” a knowledge (essentially) flavor. Appendix D deals with invariance by pursuing in Section 8 is also geometric the direction of [ 141, but the geometry of lattices, where an element of the lattice immersions of sensor systems. the sensor functionality invariance. that preserve and. hence, a model of information of the function space of immersions transformation, see Appendix D. The account we give state. In Section 8 we examine different B.R. Donald/Art@cial Intelligence 72 (1995) 217-304 247 At this point example. Here Eq. (3). Since g is an equivalence it would be useful is the basic to review the particular information invariants in our idea. The invariants may be analyzed by first examining relation, we obtain the peculiar equation Now, what exactly does Eq. (5) mean? We understand that at present, this equation result. To do so, we must idea of how we is not yet formal. Our goal is to understand give a formal account of the colocation of resources. Here is a general will proceed: Recall this intriguing information that hi denotes between normally unapposed in Section 5.4.1 and Definition to define an information invariant described to a sensor system. Recalling equivalence relating sensors, communication, 6.4, where we the compass, invariant: a compass to permutation plus output communication. This idea is tantalizing because categories: and resource permu- is critically the transformation added output communication at first glance, we would appear to obtain the following is equivalent it seems it yields an information tation. The conditioned Output communication however, communication a global compass. 25 In Section 8.8, we address model tion can be modeled as a quotient map, and in Section 8.8 we discuss to information that this invariant rerouted by the output communication. local and global coordinates; the output can simulate the generality of Eq. (5). There we constraints. This coloca- its relationship invariant on the type of information the colocation of resources as geometric codesignation is not present before and communication step, then no amount of permutation permits us to transform between if some form of orientation is valid. However, invariance. it appears sensing (at L) being (5) 8. On the semantics of situated sensor systems In this section, we formalize our model of sensor systems. We give formal definitions sensor systems and “adding” and by “combining” the term “sensor system” to mean “sensori-computational of the reductions using permutation, resources. Below, we use system” where it is mellifluous. 8.1. Situated sensor systems We formalize our model of sensor systems using a concept similar to the communi- cation graph from distributed systems [ 271. Definition 8.1. A labelled graph G is a directed graph ( y E) with vertices V and edges E, together with a labelling that assigns a label to each vertex and edge. Where there is no ambiguity, we denote function by e. the labelling function ” In the language of [ 141, communication alence classes (PECs) of E (the rays described and permutation permit us to map between the perceptual equiv- in Section 4.1) and the PECs of H. 248 B.R. Donnld/Artijicial Intelligence 72 (199.5) 217-304 Definition 8.2. A sensor system S vertex is labelled with a component. Each edge is labelled with a connection. by a labelled graph is represented (V , E). Each In Section 4.2.1 we defined components and connections operationally. We now give a formal definition. Components functions describe Simulation and connections the behavior of both components are defined by their simulation functions. and connections. Consider a component (i) to know its inputs and need inputs and s outputs, each of which space of the component. A simulation a,.: R’ x C -+ R’. Now we connect (ii) e(u) associated with vertex U. To simulate a component, we has r Suppose a component its configuration. lies in some space R. Let C be the configuration is a map26 for a component function e(v) the system, but that the components together. Assume structure as fl, above that all the com- the components that r and s are fixed ponents have the same input-output throughout func- tions). We model an edge e between vertices u and u by its label, e(e) = b, and by a (i, j) . log R( b) is the bandwidth of the edge (Section 5.4.1) and the pair of integers, j) specifies index we attach e ( 1 6 i < r and 1 < j 6 s). to which of the I outputs of t(u) themselves may perform different for a moment (i.e., (resp., s inputs of e(u)) i (resp. Now, a simulation restrict will usually for bandwidth, function for this edge e is taken to be a function the edge functions to be the identify function fl, : R -+ R. We (but they also check i.e., that the transmitted data has size no greater than log K( b) ) . We also define a resource called is where the output of the sensor exactly one vertex with this label, called sensor system for the output device the output value of the sensor system. radial sensor E, lighthouse we locate the output vertex on the “ship” at R. function Ru is the identity A simulation the “output device”. Each sensor system must have the output vertex. The output vertex of the function function, but the output value of this device defines in Section 4 (the sensor H*), is measured. The simulation In the examples introduced lighthouse sensor system H, and the permuted for an entire sensor system U, then, such as a,, and edge simulation all the component simulation functions functions simulates is a collection functions of such as in the correct the edge simulation and simulates routing the convention the data between that two components them using can communicate without an connection when they are spatially colocated. When all these component are semi-algebraic, is also (see Section 9). These concepts will be used to implement our notions 3) and “universal then the sensor simulation for a sensor system 1.1, application function Sz, (Section simulation a, component a,. The function configuration, functions. We adopt (explicit) and edge functions semi-algebraic of a “specification” reductions” (Appendix A.4). Definition 8.3. Consider value of U at a particular configuration a sensor system 2.4 with simulation function ~ZU. The output is the value flu computes for that configuration. *’ Components that records Alternatively, S can be absorbed as a factor subspace that retain state can be modeled by a function a,, : R’ x C x S + R’ x S, where S is a store the state. For example, a state element with k bits of state would be modeled with S = (0, I}k. in the configuration space of the component. B.R. Donald/Artijicial Intelligence 72 (1995) 217-304 249 Hence the output value of U is a function of U’s configuration. The notions output value and ourput 5.2) are related as follows. The output of U is a variable that ranges over all possible output values of U. Given another sensor system V, we say the output of U is the same as the output of V when QU and flv are identical. (Definition (in principle) this model, we can simulate trees of embedded sensorimotor It is Under also possible to simulate more general graphs and systems with state, but in this case the value at the output vertex may vary over time (even for a fixed config- uration). the in [ 341; (a) synchronous to trees, which suffice to model our examples. 27 In for now we restrict our attention to consider one clock-tick; however, generalizations general our discussion are possible In this case we need some explicit notion of time and blocking arrival of data at a component. Such extensions behavior of the system the time-varying are considered computation. is restricted to consider to model [ 341. Let us relate these new definitions are given by the resources described in that they carry information; ponents data-paths that will be sent along that path. Connections mon connection For example, recall Eq. (3): is specified using the permuted recall to the examples from Part I. Examples of com- are like in Section 4.2.1. Connections label represents the information a connection’s the coIviM(in.o) sensor system H* introduced carry data between components. One com- in Section 5.4.1. in Section 5.4. Next, primitive defined EG g HG + hR, EG 2 H& + COMM(t?,). Consider the sensor system specified by the bottom right-hand side of Eq. (3) : H; + COMM(#,). (3) (*) In the graph representation of (*), the edge from the virtual (orientation) sensor at G to the output device at R, is labelled “f&“. Now, for each vertex v in V, we assume there is a configuration space C,. A point in a possible configuration this space C, represents have configurations lighthouse the ship moves). Others are installed at fixed configurations. that change during of the component. Some components the operation of the system (for example, sensor system, all components mounted on the ship change configuration in the as the emitters For example, m the lighthouse example, are installed at a specific position (L) and orientation (the Id. q white light for these emitters the same configuration To summarize: flashes when the green light points North). So, the configuration is lR* x S’. For convenience, let us assume that all components space C have space C, and so C = C,, (for all v E V). is a primitive device that computes a component its inputs and (ii) its configuration z E C. Each component is installed a function of (i) at a vertex 27 Note the sensor system Hz. + COMM(&) in Eq. (3) is effectively a tree, and not a graph, even though there is data flow both from R to L and L to R. This is because the output vertex u,, on R does not feed back into the system. 250 B.R. Donaid/Art$ciul Intelligence 72 (I 995) 217-304 in a configuration is the configuration graph with d vertices, whose edges are the connections is immersed described of communication z above. The graph can be of a component actuators. An actuator is a component whose output forces the configuration of the graph to change or evolve through a dynamics equation. If the configuration of the entire graph is z = (~1,. . from the actuator component space. See [ 17,341 for more discussion of actuators. , zd) E Cd, then the dynamics equation models a mapping e( ~1)‘s output at z to the tangent space TzCd to the configuration of its vertex. More generally, components the configuration space Cd, and , i, Now, we give Definition 8.4. A situated (or immersed) sensor system S is a sensor system S = ( r! E) , together with an immersion the conjigurution configuration qf the component is no ambiguity, we also call 4(u) If u E V, then we call 4(o) 4 : V ---) C of the vertices. of the vertex U. When l( 1:). there the A situated sensor system is modeled by an immersed graph. If the map 4 in Defini- In need not be injective. then we call 4 an embedding. Immersions tion 8.4 is injective, particular, in order to colocate vertices, In Definition 8.4, the immersion that we do not specify indicating vertices are outside immersion 4: V + C by 4-l C. We denote it is necessary q5 may be a partial the spatial configuration for immersions (as opposed to be non-injective. function, to total) of those components whose the domain of a (partial) the domain of the immersion. We denote its image by im 4. Example 8.5. HG is a situated sensor system of the same sensor system H, and so HG = ( H, fi* ) . (H, @). HT; is a different immersion @* This example illustrates a general concept: permutation of a situated sensor system corresponds to the choice of a different immersion with the same domain. Formally: Definition 8.6. Let S = (S, c,h) be a situated sensor system. A permutation a situated $* -‘C of +* are the same. 28 s* of S is such that the domain 4-l C of $J and the domain sensor system (S, 4*) Furthermore, for technical vertex has the “output device” reasons, we also permit a permutation label. See Section C.2. to change which We can now formalize Definition 4.1 to say precisely what it means for two partially situated sensor systems to be equivalent: (Formulized). Given Definition 4.1 two sensor systems S and Q, we say Q simulates S if the output of Q is the same as the output of S. In this case we write S 2 Q. More generally, suppose we write 2x Technically, there are two kinds of permutation. Definition 8.6 is called verfex permutation; in Ap- pendix A.2.1 we discuss a more general model called graph permutation. Vertex permutation suffices for all examples in this paper, but our results go through for graph permutation as well. B.R. Donald/Art@zial Intelligence 72 (1995) 2I7-304 (S,dJ) = (U,$> 251 (6) for two situated total. Now, suppose components simulates (S, 4) sensor systems. Eq. (6) that 4 and @ are partial, is clearly well-defined when 4 and # are of leaving unspecified is taken (6) the configurations to mean that (U,#> e(o) of S and g(u) of U. Then Eq. of u and u. for any configuration For Definition 4.1, in the case where (say) 4 is p$ial, we operationalize Eq. (6) is, we define ex 4 about all extensions 4 of 4. That it as a statement by rewriting to be the set of all extensions of 4. Then, we write: V$ E ex 4, Eq. (6) holds” (with bars placed over the immersions). We treat $ similarly, with an inner universal quantifier, although codesignation allow us to make the choice of extension $ of ti depend on the extension 6 that is bound by the outer quantifier. For example, Definition 4.1 becomes, “for all configurations x E C of U, for y E DS (x) of U, Eq. (6) holds”. Here Ds( x) is a set in C that varies all configurations constraints. Definition 4.1 can be with X; the function Ds( in Section 9. generalized (Sections 8.3 and 85.1) vertices; see Eq. (34) the codesignation constraints .) models to any number of “unbound” Definition 4.1 uses a strong notion of simulation (in which the outputs of the sensor the same equilib- requires systems must be identical). A weaker notion, which merely rium behavior, in Section 12. is introduced 8.2. Pointed sensor systems configuration Go E C. This corresponds Suppose we wish to consider a sensor system S = (Y!E), where one component for u E V is in a particular the partial function Cp with domain {u} and range {Go}. We may abbreviate system the notation we use in Section 5.3.1 and after. Of course, for this notation the information above about U, we must specify did that in Section 5.3.1 when we wrote down e(u) via the situated is to capture all the preimage2g of GO under 4, but we (S, 4) by writing So,,, to distinguish it from the unsituated system S. This to immersion “ . . let us denote by HG the sensor system H installed with L = G”. We now explain the notation used in Example 8.5. First, we formalize our discussion of SdO, above: Definition 8.7. A pointed where e!~ : V + C is an immersion the base point. An extension of a partial pointed immersion (5, G) where $ is an extension of 4. 3o ($, G) of the vertices of S, and G E im& G is called is any total pointed immersion immersion of a sensor system S = (YE) is a pair (4, G) Definition 8.8. A pointed sensor system is a triple (S, 4, G) where (S, 4) sensor system and (4, G) is a situated 8.7) of S. We abbreviate is a pointed (Definition immersion (S,+,G) by SC. 29 More precisely: we must write down that the preimage of Go under the immersion 4 contains L:. 3o (4. G) is called weakly pointed if 4 is partial and G is not necessarily contained in im 4. 252 B.R. Donald/Artijicial Intelligence 72 (1995) 217-304 Hence, HG in Example 8.5 is a pointed sensor system. Next, Definition 8.9. A pointed permutation system (S, 4*, G), where +* is a permutation of 4. of a sensor system (S, 4) is a pointed sensor Hence, HT; in Example 8.5 is a pointed permutation of the pointed sensor system HG. of of S o, then SG is a pointed permutation is a pointed permutation if Sz In general, SC. 8.3. Codesignation: basic concepts If we view the configurations Convention are “bound”. Here is another view: 4.1 gives a “default” of components then for determining which variables are “free” and which in a sensory system as “variables”, The partial immersion specifies which variables are specialized in the domain of the immersion. Their configurations (constants). to be constants. These to the domain for vertices outside The configuration correspond are not yet specialized, variables and hence are free. are the vertices bound variables of the immersion We now have two concepts to define and investigate. First, we show how to specify variables. After that, we must find a systems which contain some constant configuration (see [ 71) . Two vertices r and u codesignate way to make two free variables codesignate r and u codesignate under 4 when 4(r) = 4(u) under an immersion . More generally, different two 4 and $ when 4(v) = $(u). We now proceed with these immersions tasks. Recall our example of a pointed sensor system So, from Section 8.2 above. Recall So,, = (S, 4, Go), and S = (YE). The domain of #J is the single vertex v E V. Now, to continue, e(r), and that r # v so that r$ does not specify how to immerse r. Consider a different sensor system U, with at least like this: one vertex u. We wish to consider “combining” U and S by saying something that r E V is the vertex of component suppose Immerse S with vertex v at GO. Now, vertex r of S will be somewhere, but we want to immerse U so that u is at R also. say, R; Hence, we don’t care where R is, save that we wish the immersions under r and u. To do to colocate of S and U. We call this a this, we make r and u codesignate codesignation constraint after [ 71. Here is how we may say this more precisely: sensor Let So, denote Immerse $. Thus $ the rest of S in any consistent manner, and denote system S immersed with vertex v at Go (as above). this immersion by to {v} is is the extension of $ so that the restriction $jrll) of $ to 4. Now, let R E C be the configuration of r under 3, i.e., R = q(r). identical Denote by @ the (partial) of U to R. Note that Go is a “constant” that R depends on which extension immersion of U defined as follows. @ sends vertex u in the sense and R is a “free variable”, ;f; of 4 we choose, whereas Go does not. In Eqs. (2)-( 5)) we abbreviated this construction as follows: B.R. Donald/Artificial Intelligence 72 (1995) 217-304 SC0 + UR 253 (7) which not sufficient preimage is short for (S, 4) + (U, 9) with 4 and Cc, defined as above. Note that (7) is unless we also note that the to specify the desired (partial) immersion (under the immersion 4) of GO contains vertex u of S, and that q(r) = R= ccl(u). (*) a codesignation represents in Section 8.5.1. We must also specify (*) below variable. The notation explained in Eq. (3). in (7) constraint; we will define such constraints formally and R is a free is used in the body of the paper, for example, that GO is a constant It remains for us to define precisely the + operator we just used, and we do so in Definitions 8.1 O-8.12 below. 8.4. Combining sensor systems The + operator is defined on two graphs as a way of taking their union. Specifically: Definition 8.10. Consider combination B + 6’ of 0 and g’ as follows: two graphs Q = (YE) and G’ = (V’, E’). We define the G+G’=(VuV’,EuE’). We may define + on sensor systems graphs. We may define + on two immersed graphs whenever patible. An immersion q5 of G and an immersion the two immersions generally, on q!-’ C II $-’ C (for partial functions). Given Definition 8.10, we have: for are com- t+Q of Q’ are said to be compatible when or more total immersions) agree on the intersection V rl V’ (for 8.2) by lifting the immersions the definition (Definition Claim 8.11. The operator + defined in Definition 8.10 is associative and commutative. Proof. Definitional. 0 8.5. The general case Let (S, 4) and (U, $) be two situated sensor systems. Let V denote S and u the vertices of u. Our notation above (So, I.‘&, Ho, hR, etc.) the image of each partial In these cases it suffices immersion to abbreviate the vertices of is effective when is a singleton, e.g., 4(V) = {G} and 9(U) = {R}. SC = (S, 4) and UR = (U, $1, (if any) of the configurations G and R is constant and which (if and to specify which any) is free. We now generalize (S, 4) and (U,$) Suppose $(U) (which need not be singletons, this notation have compatible in general) for more complicated partial immersions. partial represent immersions. Now, 4(V) and the “constant” configuration 254 B.R. Donuld/Ar@ficial intelligence 72 (I 995) 217-304 (analogous bindings of vertices tion constraints. All the codesignation this form: each was a pair (u, u) E V x U. A codesignation is true: with the immersions to the singleton G above). We now consider codesigna- constraints we have seen so far in Section 8 have is compatible 4 and rC, if one of the following constraint ( 1) u is not in the domain +-‘C (2) u is not in the domain $-‘C of 4; of IJ; (3) 4(u) =Q(u). This definition is not quite general enough; we must also be able to specify two components means that that two vertices not codesignate, (a) that of S must be # G(u). The general definition is complicated and is given in two vertices of U (resp. V) codesignate-this colocated. for example, that 4(u) Definition 8.14 below. (b) we must also be able to specify However, putting off the formal definitions are to be held constant. The codesignation for a moment, we can see what a combined the immersions $ and 4 specify which component specify which constraints sensor system really is. In summary: configurations components are to be co-located. Definition 8.12. Let (S, 4) and (U, I++) be two situated sensor systems with compatible partial immersions. The combined sensor system (8) is specified by (8), and $. We say the combination are compatible. together with a set of codesignation constraints (8) is defined when the partial compatible with 4 4 and @ immersions then this vertex remains Now, consider u, resp. If U, = u, where u, f u,, we must naturally combined must say which). 3’ We adopt one default convention For more on output vertices, see Appendices C. 1 -C.2. two sensor systems S and U. Both have output vertices, say, u, and the output vertex of S + U. In the case specify which is the unique output vertex of the new, it to be either u, or uO (we in Section 8.7.3. sensor system. By convention we will declare for this choice Definition 8.12 specializes to the particular cases such as Eq. (3) we have considered, constraints. To illustrate by appropriate these choices, we give an example below, in Section 8.6. The operator + is associative and commutative (see Claim 8.11 and Appendix C). and codesignation choice of partial immersions 8.5. I. Codesignation constraints Throughout this section, we let (S, $) and (U, @) be two situated sensor systems with compatible partial immersions 4: V -+ C and $ : U + C. Definition 8.13. Define the partial immersion 4 + Cc, as follows: is not a severe ” This Appendix C.2. restriction when we are considering permutations like (S + U)* of S + 2.4. See B.R. Donald/Artificial Intelligence 72 (1995) 217-304 255 4+g:-+c, 4(X)> #(x), if x E V, ifnE U. XH i We say the map 4++ is defined when the partial immersions q5 and (I, are compatible. Definition 8.14. A codesignation constraint is a pair (x, y) E (V U U)*. Definition 8.15. We say a codesignation immersions 4 and @ if one of the following (1) x is not in thedomain (++$)-‘C (2) yisnotinthedomain(~++)-‘Cof(4+@); (3) (4+9)(x) =(9+@)(Y)* is true: of (d+$); constraint (x, y) is compatible with the partial Noncodesignation constraints are modeled symmetrically A codesignation 4 + $ that extends 4 + Ijl, constraint (x, y) indicates that we require to codesignation constraints. that for any total immersion (4+9>(x) =(4+@)(y) (*I holds. A noncodesignation Definitions employ 8.14-8.15 the machinery constraint requires inequality (instead of equality) handle a single constraint. For sets of constraints, these definitions. of Appendix A, which generalizes in (*) . to you have 8.6. Example: the basic idea As an example, let us interpret Eq. (3). We give it again: EG 2 HG + hR, EG % Hc + COMM(8,). (3) Recall EG and HG are situated sensor systems. EG is the radial sensor located at G E IL&*. HG is the lighthouse sensor with the emitters located at G and oriented (cid:144)I IZI Northward. When H is situated at G as above the position R of the ship, unspecified calibrated sensor system hR is co-located in (7)) in Eq. (3)) once the preimages the immersion towards North. Eq. (3) of the combined is partial, to obtain HG, the immersion in HG. hR denotes leaving installed at R, (top) holds for any ship’s position R so long as the to (7). As of G and R are specified, the right-hand the immersion) side of Eq. (3) the compass at R. Compare (under sensor system becomes clear. Now, HE defines a new immersion The immersion with exactly one edge e. e is an edge with (orientation) from HG). depends on R but Eq. (3) holds for any R. COMM(~,) defines a graph the virtual sensor two to the ship (the output vertex) at R. Thus, e is an edge between of H (by “new” we mean different label e(e) = Or, from 2.56 B.K. Doncdd/Artificiul Intelligence 72 (1995) 217-304 vertices of H* (or H;) but note that e is not part of the graph H* (nor HE); e is only present in the combination HG + COMM( 8,). Finally, by convention, Eq. (3) (by sentence below Eq. (3) that it holds for any G. This is equivalent VG” before Eq. (3). This effectively both on the left- and right-hand side of Eq. (3) itself) only holds for G. But, we specify in the the symbols “frees” G. The appearance of G as a subscript to placing indicates a codesignation constraint. 8.7. Example (continued) : a ,formal treatment 8.7.1. The top of Eq. (3 ) We now rewrite Eq. (3) using we do not explicitly be generalized lR2 x 9. by taking consider orientation the general notation of Section 8.5. In this example can space of components. However, the configurations G and R to lie in the configuration the discussion Let 4 be a partial immersion of E. Let I& be a partial immersion of E that installs it at G, so that EG = (E, 4~). Let Ic, be a partial immersion of H. Let I& be a partial immersion of H that installs the emitters i at G, so that NC; = (H, (clc). We will define codesignation constraints so that all the concrete and virtual sensors are installed on the ship (i.e., at R). = q . Let ~‘1 and v2 be the vertices of H such that C(vt) = q , and e(s) Let ~1,. sors described (orientation). , Uk be the vertices of H corresponding in Section 4.2.1. In particular, ut to the concrete and virtual sen- sensor is the vertex of the virtual Let uO be the output vertex of H. Let p be a partial immersion of the compass h. Let w be the vertex of the compass in h. Then we can rewrite the top of Eq. (3) as: (E,+G) g (H,$G) + (k,p) together with the codesignation constraints” (~~i~~;~)l<,~k~{fC’1~~2~~~~,~~1~~~~1~~~}. (3-top) (9) 87.2. The bottom of Eq. (3): Now, H* denotes a different immersion the partial codesignation constraints precisely define what COMM(.) means. that installs the sensor system COMM(.) immersion of H. Call this immersion @*. Let I++; denote the concrete and virtual sensors at G. We will define so that the emitters are installed on the ship. We must now We can be sure of getting the semantics of COMM(.) correct by treating system in its own right (albeit, a small one). Now, COMM(&) defines it as a sensor the graph with 32 A careful analysis will show that, while it is necessary that the rotating emitter q be located at G, the omnidirectional m can be anywhere. Hence the codesignation constraint (~‘1, ~‘2) is unnecessary. However, by removing it, we are left with the problem of synchronizing q and q . Either we must add communication, or else calibrate the emitters and give )F/ a clock. These issues complicate the example and so we will not deal with them further. B.R. Donald/Artificial Intelligence 72 (1995) 217-304 251 vertices 33 {ut , u,} and a single edge e = (~1, u,) with l(e) = 8,. We observe transformation and Definition 6.4) on sensor systems whereby we add output communication the following: implies that the (Section 5.4.1 The “head” vertex uO of the edge e = ( UI of the sensor system COMM(~,). , u,), is defined to be the output vertex Our model of communication bly not possible without include should COMM(.) the bottom half of Eq. (3) may be written: Hence is fairly abstract. External some form of buffering by either this buffer to be more realistic about modeling is proba- the sender or the receiver. internal state. communication (‘%d’G) = (H,&$) +COMM(h) together with the codesignation constraints {(~l,~i)}l<i~kU{(~I~~2)}. (3-bot) (10) Hence the bottom codesignation top codesignation not appear (since output vertex is not constrained Thus the codesignation constraints (9) for (3-top), constraints it is associated with the compass). Second, for (3-bot) from the (10) in that in the bottom constraints, w does the are different in the bottom equation, (orientation). to be colocated with the virtual sensor constraint (~1, u,) disappears. 8.7.3. Bandwidth and output vertices We have defined COMM(.) as a graph with a single edge e. The argument the bandwidth of e. Thus, for example, cow(b) label is b. This specifies b; if b requires k = logR( b) bits to encode (parameter) specifies that the edge is a data-path then k is the b to COMM(b) determines a graph with one edge e whose that can carry bandwidth of e. Now recall the discussion information (Section systems vertex of both H* and COMM(&), and so it unambiguously of the combined 8.5). Here, to choose output vertices on how sensor (Section 8.7.2, Eq. (3-bot)) we have u0 as the output the output vertex in combined remains system H* + COMM( 6,). More generally, we adopt the following Convention 8.16. Let S be a sensor output vertex of the combined of coMM(.). system. Unless otherwise the sensor system S + COMM( .) to be the output vertex u, stated, we take For more on bandwidth, see Appendix B; for more on output vertices under permu- tation, see Appendices C.1 -C.2. 8.7.4. Calibration complexity and codesignation The size of the set (9) or ( 10) (number of codesignation of calibration complexity (see Section 5.3.1). However, constraints) is one measure this should be only part of the 33 In this example, the vertices of COMM(,) are also vertices of H*; but more generally the vertex sets can be disjoint. 258 B.R. Donuld/Artij?cial Intelligence 72 (1995) 217-304 alone, constraints, is not a good that the number of codesignation in the place of several colocated components is that one sensor system (say H, for argument) could have a single component in another sensor system measure. One reason measure, that functions (say, V). For example, we could build a sensor V as follows: consider in H. Break up the emitter q into all its tiny wires, power supply, filaments, actuator, etc. All these components must then be colocated. This would result for V than for H and codesignation calibration complexity. Instead, something some additional of calibration useful property: in the same time it takes to read the input). constraints or installation complexity we should compare “size” using in order to measure calibration like order (Big-Oh 0( .) ) notation. This is the basic idea we use, but there are that we defer to Appendix A. 1. There we propose a measure retains, however, one that is more reasonable. This measure it (in fact, like “size” above, it can be computed the emitter q rotating in more high measure of subtleties complexity it is easy to compute thus, a spuriously 87.5. Noncodesignation constraints and parametric codesignation constraints To complete our model for this example, we must also introduce noncodesignation so that G # R; this is necessary constraints sensor E has two vertices, vertex” of E (this is the vertex located at G in Fig. 5). The noncodesignation for both (3-top) the radial to and tl, where to is the output vertex, and tl is the “central constraints to work. Suppose for our sensors and (3-bot) are {(4~4)~(GJ~h)). (11) The former require the codesignation constraint is a constraint on H (and H*). The latter is a constraint on E. Finally, we (tcl,4l) (12) Eq. ( 12) is called a parametric codesignation -- 4G, $G, and *; of #'G, $G, and q+; resp., we have @G(u,> = $f'G(t,) = fi;cucd. are discussed Parametric codesignation that for all extensions in Appendix A.3. it ensures - constraints constraint; further - - to explain most facets of our theory This completes our detailed discussion of the sensor systems in Eq. (3). The example in a simple setting. Let us sketch how two arbitrary points G and {tl, to} and the desired is designed to make R in G. We begin with the two pointed and (~1, UI} resp. (So, +G is total and I+!& is partial.) These functions permutation ~4: are: immersions +G and $o, with domains this analysis computationally effective. We choose tl f” UI 1,’ , G R R G G R @G *G *lz We want our analysis the ones we chose. To do this, we in effect wish to universally quantify over R and G and to be true for any R and G (with R # G) and not just B.R. Donald/Art#cial Intelligence 72 (199.5) 217-304 259 treat these configurations the quantification machinery our first use of Eq. (3)) we wrote as variables. To do this carefully and computationally from Section 9. Here, we give the basic requires idea. Now, after “Eq. (3) holds for all G.” as follows: the G subscripts: This sentence effectively adds “VG” to the front of Eq. (3), and hence to Eqs. (3-top) and 4 replace $G by $ and fiz by @‘. (See Section 10 for more details). by the task, this notation because our constructions explicit. As we is to treat all the sensor constraints and (3-bot) . We call this freeing G. To obtain (3-bot) remove of E. Similarly, We have chosen and the task is specified by G. The notation shall see below, perhaps unsituated, systems above. This may be done using this effect, we rewrite Eqs. (3-top) that is, replace 4~ by any immersion yet respecting the tools developed the cleanest way to model this example in the sequel (Sections 8.8-10). leaves this parameterization all the (non)codesignation are parameterized as initially 8.8. Generality and codesignation Consider a sensor system S with d vertices V, immersed via a map 4: V -+ C. The space of this sensor system can be viewed as Cd, since any immersion 4 configuration can be represented (u, U) for u, u E V. This specifies a new immersion of S in a quotient Cd/(u N u) of Cd in which the images of u and u are identified. This quotient construction can be used to analyze information in certain cases. We give an example below. in 34 Cd. Consider a codesignation equivalence as a point constraint In Section 7, we discussed how general Eqs. (3) and (5) are. We can now address that the top and bottom of Eq. (3) have different that equivalence only holds under the appropriate specifies such an iden- that each codesignation constraint is a relation to a “projective this question more precisely by noting constraints. This means codesignation spatial (Recall identifications. tification.) Hence, Eq. (5) space. It is analogous holds for projective example, by identifying exist projective that do not hold in R3. In our case, it seems that by investigating quotient the generality of information generally, sensor systems. all nonzero points on a line through in RF’* (for example, relations one may measure the origin invariants information-preserving transformations real projective relationships invariant” (e.g., reductions recall relation that that, for space R3 to a single point. There in projective geometry) the structure of these and, more invariants, on and immersions) space but not for affine space. To see this analogy, space lRJF* is obtained as a quotient of real Euclidean that holds only on a quotient of configuration in geometry: an invariant It is interesting from to note that the geometric structure of noncodesignation constraints is different can be viewed as follows. Let 7~ : Cd --t Cd-’ be the projection of Cd onto Cd-‘. This to Cd / (u N 0). Hence since Cd-’ map models given above. The quotient construction the quotient construction the quotient construction is isomorphic r models the identification of u and u. 7r then induces a new immersion 6 = r(d): 34 This just says that the function space Cv is isomorphic to Cd. 260 U.K. Donuld/Artijiciul Infrlligence 72 (1995) 217-304 cj =T(4) E C/(u - r:). One the other hand, noncodesignation let us assume requirement. To see this, d vertices of V. We then consider an immersion 1: to different values. Define noncodesignation must have an immersion constraint insists that we avoid are essentially a kind of genericity constraints that u and u are the first and second of the to be “generic” when it sends u and the that is, we the embedded diagonal, j z E C}. Then the diagonal A = {(z, z) E C* 4’ E (C’ ~ A) x C”-‘. (14) Combining sensor. ( 13) and ( 14) gives the general form for the configuration space of the 8.9. More general codesignation relations 8.9. I. The semantics of codesignation constraints The codesignation constraints we have encountered so far model the necessary equality of images of vertices under immersions. For example, 4(u) =@(u) for (some particular) u E U and t! t V: lJ d, C. V c (15) ( 16) Let us call this simple kind of codesignation constraints in ( IS), equality codesigna- tion constraints. More generally, we could consider and I/J(O) are colinear” or “4(u) of codesignation model such a relation as follows: consider a triple (u, u, @) where @ is a semi-algebraic predicate on C x C. So far, in considering predicates we have used have been diagonals:” relations of the form “The three points z, 4(u), is within distance d of r/~(u)“, etc. This other kind relations. We could could be called general codesignation equality codesignation constraints, constraints all the #(X,)7) iff x=v. ( 17) This choice figurations (Eq. ( 17)) explicitly encodes can be specified using colocation lighthouse sensor H it is necessary the assumption that all working sensor con- (or noncolocation) . For example, for the for the green and white lights q to be colocated. m Q For a noncodesignation constraint. WC complement the diagonal. B.R. Donald/Artificial Intelligence 72 (1995) 217-304 261 the sensor only works when the ship R is not at G. These statements give ge- specify to function properly. Hence, equality that the only geomet- the assumption is the colocation of components. Obviously Similarly, ometric constraints on the sensor semantics: what (non)colocations codesignation ric characteristic this is not true for all sensors, but it is true for the sensors we have considered paper. We call such sensors simple, and they are worth a definition (Definition below. must occur for the sensor such as Eq. ( 17) encode that affects sensor semantics the (non) codesignation in this 8.17) constraints constraints In this paper, we primarily discuss simple sensor systems, and only relations more generally, require general codesignation that must hold for the sensors to it may be true that there to function in Sec- of such extensions. However, we feel our to handle at least restricted algebraic codes- predicates relations would the “forbidden for a moment semi-algebraic constraints, More generally, we could, in principle, configurations-or, (in)equality than the ramifications (and should) be extended hold between component exist relationships other properly. tions 8-9 do we consider framework could ignation. To see how this would go, assume for general codesignation be (geometrically) diagonal” would generalize some polynomial codesignation identified via an algebraic map (a polynomial can be complicated; seen. and immersions inequalities, however, relations. The effect of general codesignation as follows. First, for a noncodesignation relations, we would construct a quotient whereby points to an arbitrary variety Y in Cd; Y would be characterized by 4 E Y would be forbidden. For general in Cd would be equation). The geometry of such spaces from a theoretical point of view, a line of attack can be We can summarize this discussion with a definition that captures the kind of sensor systems this paper addresses: that can be specified using only a finite number of semi-algebraic (and noncodesignation) that can be specified using only a finite number of is called simple. A sensor predicates is called algebraically constraints constraints (and noncodesignation) codesignation Definition 8.17. A sensor system equality system in its general codesignation codesignated. Since ( 17) is algebraically codesignated, nated. We consider only simple sensor systems in Section 9 apply to all algebraically codesignated systems. all simple systems are algebraic codesig- l-7. However, the algorithms in Sections 8.9.2. The semantics of permutation The semantics of permutations ignation. We now discuss our semantics, Section 9. but also is intimately bound up in the semantics of codes- the connection. The results of this section not only clarify in result, which we describe to a computational later lead The meaning of a permutation (see Definition 8.6) is clear for a totally situated sensor (i.e., a sensor system with a total immersion). Recall from Section 8.8 that we immersion 4 and its permutation 4* as elements of the configuration system can view an 4* 8.6 still 262 B.K. Donald/Artijiciai Intelligence 72 (199.5) 217-304 to choose 37 a permutation space 36 Cd. Now, suppose, possible 40 E C”, we build a sequence of such choices, {&,+i &+t = 4:. This defines a map for a moment, that for every 4* satisfying Definition 8.6. Imagine immersion + E Cd it is that for each , .} c Cd, where ,&, 43,. Cd + Cd 4 Cd --_) ... 40 H 41 H $2 k “. (18) Hence, a permutation sensori-computational space. configuration can be viewed as a way of “permuting” system, or, it may be viewed as a kind of automorphism the components of a of sensor Now, suppose we now allow 4 to be a partial immersion. Then by a permutation of 4 we mean a different partial applies). immersion with the same domain (Definition Permutations of a partial immersion have a structure in that each can be characterized geometrically that is related via regions to codesignation in Cd. Consider immersion 4. Given 4 we can define the set of extensions of 4: constraints, a partial which is a region ex4* of Cd, with this property: in Cd. A permutation &‘C = +* -‘c. #* of 4 corresponds to selecting a new region ( 19) classes” if we could it would be convenient Now, “equivalence different classes of immersions. A partial and permutation we need the following: like in Cd. That way we could view 4 and +* as the “generators” of in Cd, to a region in Cd. To take this view, to choice of a different then corresponds the regions corresponds and ex$* function region treat ex+ Proposition 8.18. Let 4* be a permutation unless 4 = 4’. of 4. Then ex q5 and ex c$* are disjoint, Proof. Let $ E ex 4 n ex +*. Since $ is an extension of both 4 and 4’) we have 74@% = 4 $l@*-l~ = +*. But @J* is a permutation (Definition of 4, which 8.6). Since 4* -’ C = &‘C, implies that $ and 4* have the same domain therefore r#~ = 4’. 0 Let 2( $) denote all permutations under ex do not intersect. The map ex also has a surjection-like of 4. Essentially, Proposition 8.18 tells us that the the images of distinct property property: ----t {R e g ions in Cd} has an injection-like map ex: S(4) permutations which we characterize as follows: ” We defer the necessity of quotienting C” and removing diagonals, until Section 10. 37 The choice will not, in general, be unique. B.R. Donald/Artificial Inrelligence 72 (199.5) 217-304 263 Claim 8.19. Let q5, Q : V + C where q5 is partial and $ permutation 4’ of 4 such that Cc, is an extension of +*. is total. Then there exists a Proof. Take 4* = @l+lc. 0 Proposition 8.20. Fix a partial {Regions in Cd} cover Cd, that is, ex4* = Cd. U 4’E-U4) immersion 4. The images of ex : Z(4) -+ Proof. Immediate from Claim 8.19. 0 We can summarize this as follows: we have viewed permutation self- as a bijective self-map of the disjoint as a bijective map of ,Z( 4). “equivalence” It is equivalent classes to view permutation (for all permutations claims: 4* of 4) in C d. This viewpoint is justified by the following two Proposition 8.21. The map P@ : Cd --f -z(4) cc, H 4’ s.t. * E ex I#J* is well-dejined. (20) that p&(e) Proof. Observe every $ E Cd, by Propositions 8.18. we see from Proposition 0 = I+$,~ for 8.19 and 8.20. That p4 (qb) is uniquely defined by (20), ( see Claim 8.19). The map p4 is defined Now, suppose the domain 4-‘C of 4 contains any permutation 4* of #J by the k images under 4. T hat is, we can represent any such permutation in Ck defines a permutation any point 4*. represent $-‘C Conversely, k vertices, 1 6 k < d. We can (~1,. . . , ZJ.) of the vertices of in Ck. 4’ by a point Lemma 8.22. The following properties hold: 38 (1) S(d) N Ck. (2) The map p4 is a projection and we can give it in C-coordinates as: P4 : Cd + c” (zl,...,zk,. . ..zd) +-+ (zl,...,zk). (21) 3X We use N to denote isomorphism. 264 B.K. Donuld/Art@iciul htellipnce 72 (1995) 217-304 (3) (4) (5) Let +* be a permutation and ex 4” = p4-‘4*. The map pb is a quotient map. P/p(f) z Ck. of q5. Then ex +* c Cd is a cylinder over qb* E Ck, Proof. Definitional. 0 Finally, we note that our discussion systems can be specialized same base point). ex 4 and ex 4* have these additional properties is a pointed permutation If 4* to pointed sensor systems and pointed permutation of permutation for partially sensor (with the of $J with point G, then the classes immersed (see Definition 8.7) : 39 GEim$= n im?, G t im+* = 0 im$*. (22) ?&2x d, $*+2x I$* immersed Thus for (partially) systems, we have a handle on permutation, and now is, (see Sec- a different in terms of permutation. class of C”. For most of this paper we examine a special case, where the are non- the sensor systems sensor system H* we know more precisely what the difference between tion 5.3.1) equivalence sensor systems are partially empty). A powerful generalization can be unsituated. This will allow us to understand precisely as a permutation in Section 10, where the unsituated is, the domains of the immersions (that is given (e.g.) HG and H; of the (unsituated) to choosing corresponds Permutation system H. situated 8. IO. The semantics of reductions Recall the definition of efJiciently reducible (Definition 6.4). To explore we first turn transitive. to the question of whether or not the relation <* this notion, 6.3 is in Definition Consider three sensor systems, l4, V, and W, and their permutations:40 Sensor sysrem Vertices Immersion Permutation 1 Permutation 2 u V W U={u,,,u I,... } U=(U.cr) v = {L.,,,I’,, .} v= (VP) v*= (V,P’) W={wo,w ,,._. } W=(Wy) W’=(W,y’) w+=(w,y’). (23) If <* if U <* is transitive, I/ and V <* W, then this property holds. From Definitions 5.1) when (Definition in calibration here on the less obvious aspects of transitivity. 41 To simplify deal with codesignation noncodesignation then U <* W. We explore 6.3 and 6.4 we can see that dominance and so we will concentrate is transitive, the discussion we only for but the argument generalizes mutatis mutandis constraints. constraints, complexity w For pointed sensor systems, the surjection-like properties (Propositions 8.19 and 8.20) only hold for the class of pointed 4” Other permutations 31 See Sections 8.7.4. and A. I for more on computational are possible, only a couple are shown. calibration complexity. the same base point). immersions (with B.R. Donald/Artijicial Intelligence 72 (1995) 217-304 265 8. IO. I. Weak transitivity First, let us observe that <* always obeys a property that is like “weaker”. We now elaborate. Suppose U <* V. Then some permutation definition of 6). So, we have lP = (V, p*) of V such 6.3), that Lf < V* (see Definition (Definition transitivity, but there exists 6.2 for the (U,a) 6 (u,P*). (24) Now, suppose (V, /3* ) <* W. Then there exists a permutation W* = ( W, y* ) such that (v,P*) 6 (w,r*). (25) From Eqs. (24) and (25)) and the definition of < (Definitions 5.1, 6.3) we have (zA,o) 6 (W,r*), (26) and therefore U <* W. This property we call weak transitivity. 8.10.2. Strong transitivity for simple sensor systems Simple sensor systems (Definition are chosen to obey their codesignation If <* is transitive: 8.17) obey strong transitivity, so long as all per- constraints. Suppose U, V, and W are then, if U <* V and V <* W, then U <* W. In other mutations all simple. words: Suppose U <* Y and V Q* W. Then U and W* = ( W, y* ) of W such that there exist permutations V* = (V, p* ) of (U,o) < (v?P*) and (V,P) 6 (WPY’). (24) (27) (Compare (27) with (25) ) . Then if <* is transitive, then there exists another permutation W+ = (W, rf) of W, such that (U,a) < (W,r+). (28) transitivity to “compose” is a much stricter condition the immersions Strong we be able immersion y+. This may not, in general, be possible. However, sensor systems, the system in which only equality codesignation (Definition In order for strong 8.17). transitivity than weak transitivity. It requires /I*, /3, and y* to somehow construct it is possible constraints are employed to hold, we must make sure that both the permutations the codesignation constraints /3 and /3* for V and V* respect is because we cannot expect any permutation are faulty configurations codesignation constraints of sensor configuration for V’s semantics. This of W to simulate U if either p or p* /?* of V valid if p* respects the to restricting p* to the valid regions space Cd, as in Sections 8.9.2 and 10. We call a permutation of V. We call an immersion for V. This corresponds that the for simple to specify 266 B.R. Doncrld/Art~ficinl /nfe/liCqence 72 (1995) 217-304 V” = (V, p* ) of V valid if its immersion p* is valid. In this case we also say that the sensor system V* is valid. Lemma 8.23. The relation <* (Definition systems (Dejinition 8.17). 6.3) is transitive for valid simple sensor Proof. Assume hold as above. We construct an immersion y’ so that (28) holds. there exist valid permutations a, p, p”, and y* so that (24) and (27) The picture we have is as follows: ULC V 0 P’ 11. Y* Y' Ti (29) Consider Fig. 9. Certain vertices (for example ~‘0 and ~1) are colocated. Codesignation the converse but colocation, implies immersion we must simulate reproduce all codesignation colocation suffices colocation is evidence to ensure that affects sensor semantics the new for codesignation. all colocations, constraints accurately is not necessarily because true. In constructing that way we will be sure a new to in the new immersion. Because (only) for simple sensor systems preserves immersion the sensor semantics. (Definition 8.17), this In short, We want to construct y’ as follows (see Fig. 9): y’:w-c w/ H P*(c,) iPp(r:,) =y*(~.,). The general This construction form of the set of colocations that y’ must simulate, is y*(W) n p(V). is general, and can be expressed as follows. Let .f : Y*-‘(Y*(w) np(v)) wi --i C w P*(PP’cr*(U). The map f is almost the map we want. When we define y+( w;) = z. If p-’ have a choice Since f( wi) is finite, we can enumerate all possible candidates be the correct one. Cl of yi . In this case we know c V is not a singleton in the construction (y* (w;)) set {z}, the image of f is a one-point (see Fig. then we lo), that rf( Wi) E f( w,). for y+; one of them will We note thal our proof tation W+. However, we can give a procedure It is possible candidates applying the results of the next section for the permutation y’. there exists a permu- is not constructive: we only prove for enumerating the finite number of to check which is the correct one, by We do not believe sensors. This is because (Section 9). that the relation <* holds for arbitrary algebraically the algebraic constraints may be incompatible. codesignated It would be of B.R. Donald/Artificial Intelligence 72 (1995) 217-304 267 vo w2 = (W,Y’), {uo, Ul,. .), V Fig. 9. The = and W+ V = {u~,o~, sensor situated (W, y’) .} and W = {w~~,wl,. = 4~). for Lemma systems U = (U(Y), V = 8.23. The vertices .}, rap. Not all vertices arc shown. y+(wz) (Y/3), V’ = of U, V, and W (V,p*), W* are U = = p*(un) = a(ul) and Y+(W) = P*(Q) P(W) = Y*(W) and P(W) = Y*(wz). to find a restricted class that is larger than equality codesignation, for which interest transitivity holds. 8.10.3. A hierarchy of reductions We now use our study of <*‘s even when <* , 42 Now transitivity is transitive, that A <I B and B <I C. Then it appears (namely, COMM(A)), and that to reduce B to C we could extra wire COMM(B), and therefore, two extra wires. That is, it could be that A cannot to understand it appears the reduction 61 (Defini- that 61 is not. To see this, that to reduce A to B we require require in the worst case, to reduce A to C we reduce to C with fewer tion 6.4). suppose one “extra wire” (another) could require 42 I would like to thank Ronitt Rubinfeld for contributing key insights to this discussion of k-wire reductions. 268 RR Donald/Artijicial lntelli~ence 72 (1995) 217-304 (y* (w,) ) is not a singleton Fig. 10. The case where 0-l p(on) = p(ot ) = y* (~1). Now, we note this difference permutations (~‘0, ~‘1 ) is not a codesignation cannot be semantic (i.e.. to be valid with respect are chosen constraint that ~‘0 and ~11 colocate under (in this case, it is {un, L.I } C V). In this example, j3 but not under fl*. However, that both for V. In other words, since we assume the sensor constraints function), to the codesignation it cannot affect for V in this example. than two extra wires. We have yet to find a non-artificial but it appears that < 1 is not transitive to indicate example of this lower bound (even for simple sensor systems). Let us summarize. The reduction 61 (Definition 6.4) It does not appear to be transitive. The reduction <* (Definition 6.3) is a “O-wire” reduction. It (Lemma 8.23). We could analogously define a 2- is transitive wire, or more generally, any k-wire reduction <k by modifying Eq. (4) in Definition 6.4 to for simple sensor systems is a “l-wire” reduction. s<* Q+k.COMM(b), (4’) where k . COMM( b) denotes COMM( b) + . + COMM( 6): Since ( <*) = (GO), this suggests a hierarchy of reductions, indexed by k. In general, we have the following: Definition 8.24. We say a relation >- is transitive when x + y and y + z always implies B.R. Donald/Artificial Intelligence 72 (1995) 217-304 269 x > z. To distinguish transitivity when necessary. 43 this from graded transitivity (below), we call this elementary We say a map 3: N --+ 2”‘, with F(i) = (+i), is a graded relation on X x X, when each >i is a relation on X x X. We also write F as {+i}icw. We say transitivity property holds: for every x, y, z E X, if x +i y and y +j z, then x +i+j z. that 3 has graded is graded transitive) (or if the following Clearly, the k-wire reductions {<i}ieN form a graded relation. Corollary 8.25. (a) The O-wire reduction <O (called <* in Definition 6.3) is elementary transitive for simple sensor systems. (b) The k-wire reductions sensor systems. (<i}iew are graded transitive (Definition 8.24) for simple Proof. Definition To complete property4 (a) is definitional 6.4, and that the + operator from Lemma 8.23. To see (b), we use Lemma 8.23, and recall (Claim 8.11). lemma, given by the “distributive” and commutative is associative the argument, we also need a technical of Proposition C.3. 0 We call the k-wire reductions {&}iE~ a hierarchy of reductions. We say such a hierarchy relation (i.e., any graded relation on X2) collapses if it is isomorphic to an elementary (i.e., to a single subset of X2). Corollary 8.26. The hierarchy of k-wire reductions collapses if 61 is elementary transitive (on simple sensor systems). (k > 0) on simple sensor systems the hierarchy, it suffices to show that X < 1 Proof. Suppose X <k 2 (k > 1) . To collapse 2. (This and associative, and by the “distributive” Now, construct k sensor systems, s = Z* +~-COMM( from Lemma 8.23, by observing follows that the + operator property of Proposition C.3). k) . Hence each of the i “extra wires” in x has bandwidth (for 1 =i,..., Sections 5.4.1, 8.7.3 and Definition 6.1; to see that this yields sufficient bandwidth, So, there exist k simple sensor systems 6, I$, . . . , Yk with 1,2,. Definition 6.2(3)). ti <I 2. Recall more wires ( <* ) = (<a), 2. x<r than Z resp., such that X 60 & <i Y&l 61 . . . <I (GO) c bx), where logK( bx) = mb( X) log K( 6x) (see see . . , k that then (<<I ) . If <I and <* are transitive, and observe that 0 is commutative For monotonic take bx to be the output of X (see Section 6). Corollary 8.26 is stated for simple sensor systems, but it holds for the more simple). general algebraic systems (in which case each K is algebraic but not necessarily sensor systems, we can simply 43 Elementary transitivity is the sense used in Lemma 8.23. u See Appendix C. 270 B.R. Donuld/Ar/if&l htelligence 72 (1995) 217-304 8.10.4. A partial order on simple sensor systems In this section, all sensor systems are assumed to be simple. Definition 8.27. We write U Go V if there exists some integer k such that U <k V. As a reduction, Go3 corresponds It is easy to see that <, to adding an arbitrary amount of global, point-to- for simple sensor is elementary transitive point communication. systems. of the system sensor system, In a multi-agent (i.e., number of by that components) i . U to denote “i size. For example, given a sensor system U, we can use the notation copies” of U. Now, even if for another sensor system V we have U <I V, it is unlikely that we will have i . U <I i I/, for all i E W. However, it is easy to see the following to grow, and to consider reductions parameterized it makes sense the “size” to allow Claim 8.28. If U <k V, then jbr any i, j t N, i. U <, j V. the number of components, The family {i . U}iEw is just one example of such a system; we could imagine other number of agents, or number of sensors examples where varies with i. Our emphasis has changed slightly from the preceding. Before, we asked, what k E N suffices such that U <k V? Now, we ask to find that k as a function of the size of U and V. Now, we might deem it unfair to add arbitrary communication instead consider adding only a polynomial U and I/ are data and q is a fixed polynomial. n to be the total number of components). sufficient communication to reduce U to V. q(n) amount of communication. to the system. Let us In Definition 8.29, take is the amount of n is the size of U and V (e.g., (a function of n), Definition 8.29. Let U and V be sensor systems. We write U <p V if there exists some fixed polynomial function q(n) of the size n of U and V, such that U GyCnI 1/ for all sizes n. So, the assertion “U <p V” is a statement about a family of sensor systems. It says that is in the size of U and V. In particular, note that if U <p V, then for any to V by permuting V and adding an amount of communication that U reduces polynomial i, j E N, i. U <p j V. However, we can say something stronger: Lemma 8.30 (Completeness U&V. of polynomial communication). U <p V iJ and only iJ Proof. “If” is trivial; we show the “only if” direction. then global point-to-point data-paths. Hence would be superfluous true that U &,,z) and would not add power to the system. can be implemented communication it is always If U and V have at most YZ vertices, new by adding 0(n2) V. Any additional communication 0 B.R. Donald/Artijicial Intelligence 72 (199.5) 217-304 271 It follows that <p is elementary transitive on simple sensor systems. Therefore it is a partial order on simple sensor systems. 9. Computational properties for deciding the relations <* and <I. This section In this section, we give a computational model of simulation 4.1)) and discuss an algorithm relies heavily on the results of Section 8. Readers unfamiliar with algebraic decision procedures may in Appendix A, where we review some basic facts about wish in terms of clarity. For example, semi-algebraic pointed constraints; the machinery of this section enables us to dispense with them in an elegant matter. are a somewhat awkward way to specify codesignation sets, This section also yields benefits the review immersions (Definition to consult 9.1. Algebraic sensor systems in this section are algebraic and use the theory of real closed fields. fields, we can quantify over real variables, but theory of real closed The algorithms In the first-order not over functions. This might seem to imply of sensor systems, since these immersions have a finite domain, configuration We now proceed to use this fact. immersion each space Cd. Therefore we can quantify over them in our algebraic that we cannot quantify over immersions are functions. However, since our immersions function can be represented as a point in a theory. Definition 9.1. We say a function is semi-algebraic when its graph is semi-algebraic. Consider valid immersion number of vertices in U. Now, a situated sensor system that is semi-algebraic (U, #), and for the moment assume that 4 is a and total. Let us define the size d of M to be the Definition 9.2. A simulation ring. We call the value flu (4) E R of fiu on a sensor configuration value or output value at 4. for U is a map Ru : Cd + R, where R is a 4 to be the sensor function & compute functions Simulation the value of the sensor given a configuration of the to determine what value the 4, Definition 9.2 also to in the context (Section 1.1, application 3). See Sections 8.1 and A.2 for more on simulation sensor. The idea is that we can apply a simulation sensor will return-what the sensor will compute formalizes our notion of a “specification” of design functions. in configuration for a sensor system, alluded function Example 9.3. Recall tion R,q for H computes (orientation) possible sensor (“equivalent” means the “lighthouse” sensor system H (Fig. 6). A simulation the value of 8. We imagine fin works by simulating (see Section 4.2.1). Other, equivalent, they compute the same value simulations for 0). For example: func- the are also let 272 B.R. Donald/Artijicial Intelligence 72 (1995) 217-304 E h) l&l2 x S’ be the configuration of the ship R. Let (L, 00) E R2 x S’ be the con- (x, figuration of the “lighthouse”. Then 0 = 00 + tan-’ (X - L) We note that this simulation is not algebraic). See Example 9.7, below. function (because arctangent is not algebraic Now, if the configuration space C is algebraic, then so is the function immersion 4 of 24 with algebraic coordinates can be represented in C”. So 4 is algebraic exactly when it can be represented space Cd. as an as such an Hence, every algebraic point algebraic point. Now, let ‘IT be a predicate on C” in the theory of real closed fields. Then g(4) is either true or false, and we can decide it by applying T to 4. Next, suppose we now permit 4 to be partial. We call a partial to its domain +-‘C function 4 semi- is ex 4 c Cd is also semi-algebraic. We then is semi-algebraic. If 4 its restriction +j4-lc then the set of its extensions algebraic when semi-algebraic, observe 3 of 4, ‘F(q) holds” namely that the expression denoting “for all extensions (resp., there exists an extension) is also semi-algebraic quantify over the configurations we can also “guess” permutations over permutations (0 E {‘v’, 3)). To quantify over all extensions 4 of #, we simply of the vertices outside the domain of 4. By Section 8.9.2 quantify to existentially is, it is possible and hence to decide sentences of the form4” of +-that which means, “there exists a permutation holds”. That is, $*, ‘IT(F) 34* E X(4), V4* E ex4*: T(+*). - 4* of 4, such that for any extension 4* of - (30) To guess a permutation inside the domain of 4. of $ we existentially quantify over the configurations of vertices Example 9.4. Let C be an algebraic vertices, V = { ~‘1, ~2, u?}. Now, we can encode any algebraic algebraically, $(c;) space. Let V be a set of three function Cc, : V + C semi- e.g., by a set of three ordered pairs { (01, zt ), (02, z2), (03, zs)}, where of 1,4 by the name Let us call such an s.a. representation = zi, (i = 1,2,3). configuration dzI,z2>Z3): dZl,Z2,Z3) = {$: v ---f C / ti(u,) = z,, (i = 1,2,3)}. Now, consider a partial immersion $J : V + C with domain {ut }, such that $(ut ) = G, where G is algebraic. We can encode 4 as 322323 : (~tG,z2,23). 45 We call the existential quantification reals is like guessing a witness to make the predicate true. “guessing” , since deciding a predicate in the existential theory of the B.R. Donald/Artijicial Intelligence 72 (1995) 217-304 213 We can also encode the extensions and permutations of 4 semi-algebraically. Specif- ically, we can encode any permutation @ of 4 by a single point zi (the image of UI ) ; we can encode any extension p images of uz and us, respectively). of @* by a pair (~2, zs) (the Thus, we can rewrite (30) as 321 vz2 vz3 : T(cr(Zl,Z2,Z3)). (31) If C has dimension r,, then the formula (31) is a Tarski sentence in 3r, variables. We summarize: Proposition 9.5. If 4 : V -+ C is a semi-algebraic and the set S( 4) (4’s extensions) (q5 s p ermutations) partial function, then the set ex 4 are also semi-algebraic. To guess a valid permutation, (Definition 8.10.2) we restrict constraints, codesignation the (algebraic) within (We are simply using algebraic decision procedures Any s.a. codesignation be represented relation choice of permutation constraints by an s.a. set D c R’. to the region ex 4*, is discussed for an algebraically as described to make the configurations to lie in Sections 8.9.2 and 10. these choices effective.) codesignated sensor system can structure of the region D, especially in The in Sections 8.9.2 and 10. We must restrict our to D. To guess a valid permutation, we modify - 3q5* E Z(4), V4* E Dnexg5* - : T(q3*). (30) to be: (32) Definition 9.6. We call a sensor system U algebraic (Definition simulation 8.17)) has an algebraic configuration function Sz, (Definition 9.2). if it is algebraically space C, and a semi-algebraic codesignated algebraic Example 9.7. Recall Example 9.3, above. The simulation is not algebraic. However, we can define a (semi-)algebraic encodes the sensor H’s function we give now is adequate and is adequate, to another orientation function KIH in Example 9.3 that simulation in the sense that we can use it to compare function sensor. The algebraic simulation the same information, the relation <*. to decide function an algebraic version of a~, we use a simple [ 181) . Let 4 be a configuration where 6 =fi~(4) to L. Szk encodes trick from calculus (also of sensor system (see Example 9.3), and the same information see, for example To construct used in kinematics; H (Fig. 6). Define a&($) q E 4 denotes which quadrant R is in relative as a~, but it is semi-algebraic. We will not prove ah = (tan(8/2),q), is algebraic Then we have sin0 = (1 - u2)/(1 + u2) and cos0 = 2u/(l but here is a brief argument. Substitute u = + u2), and function. By clearing denominators we obtain an is an s.a. set in the graph of fib is function function. See is a rational [ 181 for details. Essentially with the graph of the non-algebraic map 0~. The correspondence tan(8/2). our simulation algebraic correspondence given by 8 c--) u. 274 B.R. lhnuld/Art~jiciul lnrelligence 72 (I 995) 217-304 9.2. Computing the reductions <* and <I Now, suppose we have two algebraic whether U <* V. If l4 = (ZA, a) and V = (V,p), exists a permutation /3* such that sensor systems U and V. We wish to decide there then we wish to decide whether (2J.a) 6 cv,p*, (Here in Section 9.2 the relation 6 is used as in Definition 6.2). That is, we wish to decide the following (assume that cy and j? are partial): ($?* t Z(p),VZE exu,Vj?* t exp*) : ill =Cl~(p*). (33) Eq. (33) does not incorporate the codesignation constraints. algebraically algebraic codesignated, their codesignation constraints may be represented sets Du, Dy, and Dvu(E) in C”. So (33) becomes: Since Li and V are as semi- (3p* E (Z(p) n Dv),E t (exan Du),\Jp” E (ex/3* n Dvu(Z))) : (34) &/J(Z) = .Il,(p*). Note that V’s codesignation an s.a. function of Cu. This technicality specifying codesignation, and is explained is necessary further in Section A.3. constraints depend on Cr: that is, the s.a. set Dvu(cU) to allow for sufficient generality is in (34) functions to compute for the codesignation algorithm below (Theorem A.l) we can decide (1~ and 0 V. Let Y, be the dimension Using Grigoryev’s (We use (AS) in the following the time bound). Let no be the size of the time. of C. Let nn be the size simulation of the s.a. predicates In (34), the outer existential quantifier binds some number k < d vertices of V that are in the domain of 4. The inner universal quantifier binds the remaining d -k vertices of V. The middle universal quantifier binds up to d vertices of U. Hence, we see there are at most r = 2r,d variables, and there are LZ = 2 alternations. Let us treat the maximum degree 6 (34) as a constant. The predicate has size m = 2(no + no). Therefore we can decide in time constraints Du, Dv, and Dv~. Definition 9.8. Consider an algebraic d the size of U. We call the size IZ~~ of a sensor simulation complexity. We call the size ?‘@ of the codesignation complexity. We call U small (no + no) = do”‘. sensor system U, with d vertices. Recall we call the simulation for U the codesignation function 0~ constraints if n R and 80 are only polynomiahy large in d, i.e., Now, let us assume (see Definition 6.2) Then we see the following that it is possible in a time that much faster than (35) to compute dominance in calibration complexity (see Section A.1 for how). 9.9. There is an algorithm Lemma algebraic sensor systems. It runs in time polynomial for deciding the relation <* (Definition 6.3) for in the simulation and codes&nation B.R. Donald/Artificial Intelligence 72 (1995) 217-304 215 exponential (nn + no), and sub-doubly complexity That is, if the system has size d the time complexity in the size of the sensor systems. is: (no + nD)(rcd)““‘, where rc is the dimension of the configuration space for a single component. Corollary 9.10. For small46 to decide algorithm the relation <* in time sensor systems (Dejnition 9.8) of size d, there is an d(r,d)““’ (37) Corollary 9.11. For algebraic decided sensor systems, in the same time bounds as in Lemma 9.9 and Corollary 9.10. the relation <1 (Definition 6.4) can be for partial “commute” for guessing (the * operation) as the “distributive” immersions. This is formalized immersions and combination (Section 8.4). We first observe (the + operation) b), as in Definition 6.4. Recall the definition Proof. Consider deciding S <* Q+coMM( that permuta- of compatibility for compatible tion partial in Propo- sition C.3. We have already shown how to guess a permutation Q* of Q. Our arguments can be generalized mutatis mutandis above (Definition sensor systems. Since to compute (two vertices, one edge) with only a con- sensor system COm(b) stant number of codesignation (at most 2), we may guess how to combine constraints it with a permutation Q* of Q within and Corollary 9.10. To complete Appendix A.2) on how to simulate a permuted the proof we require a technical 0 the combination is a constant-sized in Lemma 9.9 in (given 8.10) of two algebraic time bounds given and permutations sensor system. property47 extensions the same argument shown 10. Unsituated permutation In Section 9 we examined a special case, where U and V are partially situated the domains of 4 and + are non-empty). We now give a powerful generalization the sensor systems can be unsituated. Using give an “abstract” version of permutation systems with codesignation different arrangement turn, corresponds Permutation (that is, in which the ideas in Sections 8.9.2 and 9, we can sensor constraints defines a in in the space of all immersions. Each cell in the arrangement, constraints. Each set of codesignation that is applicable corresponds to a region to partially immersed to selecting a different constraints. Since this corresponds family of immersions, while respect- to choosing a different region of in Cd. ing the codesignation Cd, the picture of abstract permutation model of situated permutations U has d vertices, is really not that different from the computational discussed two of which are u and u. When in Section 9. Suppose a simple sensor system constraint there is a codesignation 46 Recall all small systems are algebraic. 47 See Appendix C. 276 B.R. Donald/Artijicwl Intelligence 72 (1995) 2 I7-304 induces a quotient quotient map 7r: Cd + Cd/( u N 0) “identifies” for u and u, we write that the relation u N u must hold. This relation structure on Cd, and the corresponding as a the two vertices 14 and u. Similarly, we can model a non-codesignation “diagonal” A C C” that must be avoided. Abstract permutation of U can be viewed as follows. Let Du = (C” - A) /( II N II). DU is the quotient of (Cd - A) under 7~ For a partial constraints, we view permutation I++* to be chosen compatibly with the codesignation as a bijective self-map of the disjoint equivalence immersion constraint classes Thus, structure we define in general, the group structure for the permutation must respect for codesignation; the “diagonal” A, precisely. correspondingly, we call such permutations (38) the quotient valid. Below, Now, an unsituated with an empty domain. equivalence class {Du}. to defining unsituated permutation. immersion $0 sensor system 24 could be modeled using a partial In this case ex $0 = C” and Eq. (38) specializes to the single In this “singular” case, we can take several different approaches (i) We may define (i) is not very useful. We choose a different definition. For unsituated permutation, we redefine X(&J) and ex ~/JO in the special case where tiu has an empty domain. that sL-,* = @u. Although consistent with situated permutation, (i) .X(&) ’ such diagonals class ex @;. As { Aij};,,i=1,,,,, d. So, in that cell. Hence in situated permutation, is, let (XI,. . ,x,1) be a point (ii) When U is simple, we may define in Cd, and define as a bijective in Cd of complexity 0(d2”‘c ), ex @ E .X(@c) is a cell in the arrangement, . . I xd) 1 Xi = x.;}. Define permutation generated by all .X(&J) to be the set of colocations of vertices the ijth diagonal Aii = in self-map of the cells is an of U. That {(XI,. the arrangement arrangement and I++$ E exJ/o* is a witness point equivalence viewed as a self-map of the cells {ex I& } or (equivalently) witnesses as initially the sensor systems constraints. This may be done by ( 1) “algebraically” (ii) above, constraints, constraints. The methods choose unsituated permutations In our examples, each of Section 9 can be extended to guess colocate. 48 All our computational in Section 9 can be shown to hold for unsituated permutation by a simple extension of the arguments above. to guess unsituated permutations. corresponds (including of the can be as a self-map of the is to treat all specifying the domain of each immersion be empty, to a choice of which vertices our bounds) fi$ is a representative permutation all the codesignation (3) using the cleanest way to model our main examples (i.e., each unsituated permutation) all the (non)codesignation the codesignation {+:}. Perhaps yet respecting that respect unsituated, unsituated results letting (2) 10. I. Example of unsituated permutation Unsituated permutation is quite powerful. Consider deciding Eq. (34) ple, we only consider vertex permutation of simple sensor systems). (in this exam- In particular, we ” The codesignation relation u - r. the quotient map r. the non-codesignation relation A. and definition (ii) of unsituated permutation, can all be extended to algebraic sensor systems using the methods of Section 9. B.R. Donald/ArtQicial Intelligence 72 (1995) 217-304 211 want to see that (33) makes sense for unsituated permutation, when we replace p by pa, LY by LYO, etc., to obtain: (3P; E (-WO) n w, W E (exa0 n Du), v’Po* E (exPo* n &xAKI>)) - : %lGa = &A@>. (34’) to first choosing (34), we are restricted im- fixing a number of vertices of S. Next, we can permute U to to the choice of p* ) . This process gets the (this corresponds right, but at the cost of generality; we would know that for any “topologi- p* such that (34) holds. the same vertex choice of (Y, we can choose a permutation equivalent” means, “with sensor systems, “topologically the partial With situated permutation mersion a, and thereby be “near” these vertices colocations tally equivalent” For simple colocations”. Unsituated permutation (34’) allows us to do precisely what we want. In place of immersion class ex& of immersions an equivalence (Y for S, we begin with a witness point LYO E C”. ac represents all of which colocate the same vertices as (~0, in (34’) chooses an unsituated permutation & of U. PO* should be colocated, but not where. Now, given class ex QO of immersions, a partial an equivalence ‘~0. So, era says which vertices the outer existential quantifier represents same vertices of U as /3; does. The other, disjoint equivalence of Cd; each equivalence classes is _Z( pa) codesignation U, we install which vertices of S to colocate; colocated; construction Most specifically, given the configuration in the configuration of U relative z constraint DS ( .) then enforces them in the same “place”. More specifically: space Cd of U. This region constraints of L4, all of which colocate the classes, are also subsets class colocates different vertices of U, and the set of all such (= Z( p,*) ) . Choice of & selects which vertices of U to colocate. The the outputs of S and (~0 (given as data) determines the choice of /?o determines which vertices of U are of Ds( -) determines which vertices of U and S are colocated. a of S, Ds in turn defines a region Ds(cyO) the necessary coplacements that, when measuring to (S, G). 11. Application and experiments We now describe an application of the theory in this paper, presented but we describe it here to give some feeling [ 171 relies heavily on the results and methods (f) How much informztion task mechanics work is still preliminary, of our theory. The paper Donald et al. [ 171 quantify provided by the task mechanics? The theme of exploiting previous work. 49 One could define “exploiting as: taking advantage of the mechanical and physical laws that govern how objects move and change. Currently, for robot manipulation in our framework a new resource: in the geometry task mechanics” the mechanics are embedded in [ 171. This for the potential introduced here. is encoded or in is important 49 For example, see the discussion of [25,26,40] in Part I. 278 B.R. Donuld/Artifcial Intelligence 72 (1995) 217-304 Fig. I I. (a) the “two-finger” pushing task versus (b) the two robot pushing task. The goal is to push the block B in a straight line. of the system. with resources invariants of new issues; see [ 171 for details. In [ 171, we developed (a)-(e) (f) such is quite challenging. We close with an example. This example opens up a host in the style of the preceding. Developing from the abstract, that explicitly information invariants trade-off variations translation). Fig. 11 (a) depicts a two-finger planar pushing The two fingers ft and f2 are rigidly connected; line (pure they could be the fingers of a parallel-jaw gripper. One complication task. The goal is to push the box B in for a straight involves example, in the slip of the box on the table. This phenomenon the micro-mechanical the results of a one-fingered is very hard to model, and hence (COF) push; we will only obtain a straight lies on the line of pushing. However, with a two-fingered push, the box will translate in a straight the fingers. The nice thing about this is that the COF can move somewhat and the fingers can keep pushing, since we strategy the COF lies in some region C (see Fig. 11 (a) ), instead of on a line. only need ensure Second, it loop on our PUMA: again. For example, in Sense if the COF moves outside C, then the fingers can move sideways line trajectory when the center of friction line so long as the COF lies between the point 0 in Fig. II(a). lf r = 0, push forward the following control [ 171 we implement torque r about it is difficult the reaction to capture to predict in B.R. Donald/Artijicial Intelligence 72 (1995) 217-304 279 (do-forever (let ((7 (cond (measure-torque>>> (push T) T) ((zero? ( (negative? ((positive? T) 9)) (move +a) > -2))))) (move Fig. 12. Protocol Pl (for a two-fingered gripper). the control direction From jj. If r < 0 move the$ngers the mechanics perspective in P; else move the fingers in -2. it might appear we are done. However, the analogous pushing to overstate how critically control. Now, consider by an autonomous mobile in Section 2.1 of Part I. Each robot has a ring of one-bit contact In addition, measure of applied the robot, and the contact sensors. robot with only local communication, the applied power, force by observing the servo-loop See Fig. 12. it is difficult and task in Fig. 11 (b). Each finger is replaced configured as described sensors. that we can compute a the position and velocity of loop (Fig. 12) relies on global communication by examining it is clear (“bump”) in [44], (move linked, suggest strategy its applied the pushing in 9, move in *A, etc.). Since there are five qualitative in Fig. 11 (b) approximate these data to the other. The robots Now, we ask, how can the system the following. Each robot can compute and to compliantly the communication (Fig. 12), above? We observe and contact mode, and communicate perform a control rigidly Our experiments surface normal, in Part I allows orientation, transmit the power being applied (where the local surface normal of the box. Next, a robot could communicate this strategy: have to transmit communication it is possible this task robustly, strategy force together must the robots are not in f?. the box’s described identity, a robot might it is in contact with the box, the contact “bearing” to the motors, and ring), the message “Do the robots may choices on how to implement are aided by the ability to sense to it. The IR-Modem mechanism information: these strategies align of the following and speed. In addition here are several kinds of information indeed to convince oneself task: whether is on the bumper to specify and it is difficult for the pushing the contact like “Wait” and “Acknowledged”. . . .” or else “I am about that some particular to do this strategy: communication each robot’s . . .” Finally, implement primitives sufficient a move to com- scheme is optimal, or indeed, even necessary. it is clear state, and the compliant that the surface normal computation In [ 171, we analyze information invariants for manipulation presented here. For example, some internal or as temporary calibration. Communication in Fig. 1 l(b). accomplish required? protocols, tasks for cooperating mobile robots that can push large, heavy objects. One task is shown the robots task? How many messages and what information introduced here to compare and contrast pushing two manipulation tasks using the formalism requires external state the task to is In [ 171 we use the methods and to answer these questions. First, we precisely describe align can be viewed as consuming So we ask: what communication is necessary between appears fundamental to performing the (2-robot) pushing While perform munication 280 B.R. Donuld/Art~fic-iul Inlelligmc~e 72 (I 995) 217-304 n a 0 I- X b) The robot motions 4 The box motion Fig. 13. The task is to rotate the box by a specified angular amount. Here we illustrate the box being rotated by three cooperating autonomous agents. (a) The motion of the box viewed relative motion of the pushing robots, viewed the direction of the applied forces. From [ 17 ] in a system of coordinates in world coordinates. fixed on the box. The arrows (b) The illustrate the other in Fig. 13. More specifically, we ask: Can all explicit local and the agents be removed from a family of pushing protocols in Fig. 1 1 (b), global communication ,for these tasks?so Donald et al. [ 171 answer using the general methods between introduced here for analyzing information invariants. in the affirmative-a surprising result-by 11.1. Using circuits and reductions to analyze information invariants pro- large boxes. The the mass of a In [ 171, we develop and analyze synchronous and asynchronous manipulation times [26,40] than can push robot, although that are heavier the robots have also pushed couches to move the box by itself (specifically, the mass, and 8 x 3 robot diameters (perhaps in size). We build on the team of cooperating mobile several robots robot diameters wide, and one to two times for a small tocols boxes are typically single two to four ground-breaking work of Mason and Erdmann and others on planar sensorless in several ways. First, manipulation. Our work differs from previous work on pushing the robots and boxes are on a similar dynamic and spatial scale. Second, a single robot is not always strong enough its “strength” depends lever arm). Third, we do not assume the robots are globally coordinated on the effective (More precisely, we first develop protocols based on the assumption and controlled. local communication via a series of source-to-source assume neither of the friction distribution motor experiments experiments the “pushers” least two robot pushers and (ii) really “force-appliers” on the protocols). Fourth, our protocols that the robot has a geometric model of the box, nor that the first moment sensori- (the regards there are at (i) than the box, the robots are strategies have the flavor of [ 331). Finally, constraints. is possible, and then we subsequently transformations the robots are less massive friction. in a system with significant to infer the pushing In our case, because as moving kinematic the robot combines literature generally that communication and manipulation the necessary (the COF) information is known. Instead, remove that “’ This question was first posed as an open problem in a I992 draft of this paper. B.R. Donald/Artificial Intelligence 72 (199.5) 217-304 281 of manipulation Of course, our protocols tasks on spatially distributed and control. Next, in distributing rely on a number of assumptions strategy, first we start with a perfectly invariants developed here, to reveal these assumptions structure of the task. We believe our theory has implications teams of cooperating in order to work. We use the and expose theory of information for the the information robots. parallelization synchronous To develop a parallel manipulation protocol with global coordination it among cooperating, spatially separated agents, we relax it to an MPMD 51 protocol with local communication and partial synchrony. Finally, we remove all explicit communication. are asynchronous, each robot. Ultimately, the task dynamics, on our protocols. Because content of this implicit communication theory of information The manipulation The final protocols runs on through confers a certain degree of synchrony the information it is both difficult and important and synchronization, the robots must be viewed as communicating same program implicitly and this implicit communication “uniform”, or SPMD51 -the to analyze we believe that using our and essentially is justified. invariants transformations in [ 171 are first modeled as circuits, using the formalism on these protocols are then are modeled using three In particular, to an under <I. IR communication in this paper. For the task in Fig. 11 b, [ 171 consider transformations The circuit protocols in Section 8. Source-to-source described as circuit transformations. things we have learned. We can determine developed represented the reductions pushing protocols PI, P2, and P3, and their interreducibility an MPMD pushing protocol P2 with explicit we transform SPMD protocol P3 with no explicit communication. asynchronous is then analyzed as an instance of reducing several of a task by (i) parallelizing with communication “through can be sensed by another and protocol P3 makes use of an encoding Our approach of quantifying the world dynamics as a set of mechanically viewing paths”. This permits certain kinds of defacto communication robots. In “through takes place when a robot changes it and (ii) attempting the world” the world” complexity (through robot. For example, protocol P2 uses explicit communication in the task mechanics of the same information. involves “registers” and “data- between spatially separated in the task mechanics the information implemented This transformation the latter to the former, using <I. There are structure a lot about the information to replace explicit communication the task dynamics). Communication the environment and that change approach three protocols Rl, R2, and R3, for a reorientation [ 171, we also consider task is viewed as (see Fig. 13). A transformational a series of reductions. The final protocol R3 has several advantages the initial protocols Rl and R2. Using protocol R3, two robots (instead of three) suffice to rotate the box. The protocol the (including in R3 it is no longer same termination necessary such a model to have an a priori geometric model of the box-whereas runs on both robots. More interesting, in that the same program these protocols for the robots to developing is “uniform” is required predicate) (SPMD) over for Rl and R2. In terms of program development, spondence between developing these protocols, coordinated manipulation synchrony, and communication, shown in Fig. 14. We believe that a methodology we have a corre- for protocols is emerging, based on the tools described 51 SPMD (MPMD) = Single (Multiple) Program, Multiple Data. 282 B.R. Dmald/Ar!ijicial Inklligence 72 (1995) 217-304 Pushing task Reorientation task PI P2 P3 RI R2 R3 global coordination and control IR communication, local synchrony, MPMD partial uniform no explicit communication (SPMD), asynchronous, Fig. 14. Summary of parallel manipulation protocols from 1 17 1. here. This methodology (e.g., PI or Rl) with global coordination distributed strategy helps (P3 or R3) for the same task: transform an offline, synchronous manipulation strategy and control, into an online, asynchronous, Developing parallel manipulation protocols [ 171 separated agents. Synchronize and coordi- [ 33,471 manipulation (e.g., parallel-jaw protocol fingers, or (1) (2) (3) (4) (5) of several “agents” [ 261 or near-sensorless the protocol over spatially Start with a sensorless requiring global coordination fingers of a dexterous hand). Distribute nate control using explicit Define virtual sensors 52 for the quantities Step (2) measures. Implement Transform structures. Implement the shared data structures as “mechanical local communication. between registers”. (6) Our circuits model the protocols each virtual sensor using concrete sensors on mechanical observables. the communication two agents L and R into shared data in principle, mations between computed. Therefore, automatically. We believe tion protocols. We have implemented protocols using TOMMY manipulation See [ 171 for a full discussion. steps. By the results of Section 9, these reductions in the steps above. Our reductions model the transfor- can be effectively [ 17 ] could be synthesized that our methods are useful for developing parallel manipula- distributed, SPMD them robust and efficient. and tested our asynchronous, and LILY, the transformations and found in 12. Conclusions In this paper we suggested a theory of information the work of [ 11; first, we consider and computation. Our results generalize tailed yet abstract models of physical autonomous mobile third, we develop a generalizations and variations on compasses and orientation generalized devices. As such, perhaps our work could be called On the generalized power of generalized compasses. theory of the “power” of such sensori-computational sensors fairly de- robots; second, we consider sensors; and stratified that includes invariance 52 We use the term Section 4.2.1 for examples of virtual and concrete sensors. in the sense of 1 14 1: others, particularly Henderson have used similar concepts. See B.R. Donald/Art@cial Intelligence 72 (1995) 217-304 283 invariants in which is required to quantify to assumptions that information of robot systems, that are engineered that the equivalencies can serve as a framework their power, and to reduce state, external state, computation, to measure their fragility into the control system or the environ- information that information from which, we hope, such goals may be obtained. There are several that can be derived between communication, in determin- and sensors, can prove valuable to solve a task, and how to direct a robot’s actions to solve it. Our paper proposes a beachhead on information things We think the capabilities with respect ment. We believe internal ing what to acquire invariance we have learned. First, we were surprised by how important become sor be simulated by a simpler system with a clock (resp. communication)? sensors are ubiquitous in modern aircraft navigation In “DMEs” each other, and measure differences GPS, which was approved principles. (compare Section 4.2.1) . to apart. also operates on timing in timing pulses in July, 1993 for use in airplanes, station and the plane their distance insight can be gained by asking How can this sen- in invariant analysis. Much time and communication (distance measuring to estimate Time-based equipment) a ground systems talk reasoning. Finally, we try to operationalize and resource consumption. the systems. One reason In to the system. can add a great deal of information Robot builders make claims to verify it is hard robot performance about these claims and compare to quantify pre-calibration the “use” of external In general, is calibration: order complexity. Our theory represents a systematic attempt on geometric making our comparisons. Our algorithms (Definition it computational; we give effective Our reduction <I and physical (albeit are exact and combinatorially 6.4) attempts (that state, we suggested a theory of calibration to make such comparisons based our analysis by for computing theoretical) procedures precise. to quantify when we can “efficiently” of too complexity information circumvents to “without adding much is, build one sensor using is relativized both to the information the components build one sensor out of another another). Hence, we write A <I B when we can build A out of B without “adding much stuff”. The last is analogous Our measure of information ity of the sensori-computational relativization Appendix B). In this sense, our “components” of computation. Hence, we write A <I B if we can build a sensor using with wires computational spatial configuration-i.e., their connectivity. complexity”. complex- of A. This (see in the theory that simulates A, of B, plus “a little rewiring”. A and B are modeled as circuits, components. However, our sensori- in that their as sensor complexity to oracles systems differ from computation-theoretic components tricky problems in measuring are analogous location of each component-is of B, and to the bandwidth (CT) “circuits”, the components as important (data-paths) the spatial connecting internal some their Permutation models sensor. Codesignation ing another permutations. Output communication Like CT reductions, A <I B defines an “efficient” B to A. However, we give a generic algorithm the permissible ways to reallocate and reuse resources further in build- the range of admissible formalizes our notion of “a little bit of rewiring”. that takes (whereas on sensors our reductions for synthesizing transformation constraints restrict 284 B.H. I~onuld/Art~~fic~iclI lntelligencr 72 (1995) 217-304 there exist better reductions in our laboratory we are using <I to design manipulation can exist for CT”’ ). Whether such reductions (e.g., our “k-wire” reductions no such algorithm whether open; however for multiple mobile so that the strength of our transformations discussion more on relativized are widely useful or is in Section 8.10.3) [ 171 robots. We also give a “hierarchy” of reductions, ordered on power, can be quantified. See Appendix A.4 for a as per Section 1.1. See Appendices B and C.3 for of “universal complexity. information reduction” protocols Our work raises a number of questions. For example, can robots “externalize”, (suppose the dynamics. A juggling robot probably “bad” parts are reoriented record state in the world? The answer depends not only on the environment, upon be possible However, moving to investigate these issues further tasks and at least partially dynamic in both an experimental it is certainly possible during quasi-static manipulation cannot. On a conveyor belt, so that they may be removed towards multi-agent this question and theoretical in [ 17 1. tasks, we are attempting setting. We discuss or but also it may later). by a single agent. In By analogy with CT reductions, we may define an equivalence relation =k, such that A =k B when A <k B and B <k A. We may also ask, does a given class of sensori- computational to which any member of the class may be reduced? Note that the relation =k holds between any two complete circuits. systems contain “complete” circuits, are possible. Weaker forms of sensori-computational equivalence If we define the state of the system and behavior of U as it evolves let us the equilibrium of a sensor system Z4 to be a pair (z, b) where z is the configuration h is the output value at z, we can examine in state space. Recall Definition 4.1; let us call this strong simulation. By analogy, say that a system U weakly simulates another system V when U and V have identical, limit sets in state space. 54 If we replace strong simulation forward-attracting (2 results go through all of our structural in Definition mutatis mutandis. The computational limit sets and their properties this, if we can derive the properties of limit sets “by hand” then in principle, reductions using weak simulation instead of strong simulation compact 4.1) with weak simulation, (Z) can also be calculated by hand. results also go through, (a difficult problem in general). Failing if we can compute Finally, can we record “programs” state? Is there a “universal” manipulation perform a robot which could experiments. the correct strategy infer to accomplish the correct manipulation in the world in the same way we may externalize circuit which can read these programs a task? Such a mechanism might action by performing sensorimotor and lead to 12. I. Future research This paper represents a first stab at several difficult problems, and there are a number some of of issues that our formalism does not currently consider. We now acknowledge these issues here. s3 For example: no algorithm exists to decide the existence of a linear-space (or log-space, polynomial time, Turing-computable, etc.) reduction between two CT problems. 54 1 am grateful to Dan Koditschek, who has suggested this formalism in his papers. B.R. Donald/ArtQicial Intelligence 72 (1995) 217-304 285 reasons problem, one system to transform sensor system absolute sensor complexity-and it does not permit a “simplest” some of these limitations. We discuss for this. The first is that there are inherent into another. However, is “simpler” or “better” or “cheaper”. these problems good notions of “better” or “simpler”. The moreover, judge which system measurement There are several comparing to obtaining to get around deep-in plicit performance measure. We discussed in Section 2.1.2. In Section El, we argue to apply kinodynamic analysis mance measures framework-but algorithms Our theory allows us to compare members of a certain class of sensor systems, and, it does not permit one to for a given In particular, to be identified. on limitations represent structural barriers in part, theory are quite Appendix B at some length. Second, such comparisons would require an ex- time) allow us that external perfor- and “better” and “cheaper” could be used with our such as “simpler” we don’t know what exactly these measures are. It appears that efficient these measures will have to take advantage of their structure. performance measures, we have argued that it is very hard to the “power”of sensorimotor such measures as speed (or execution that such performance measures is no doubt these problems-which [21,49]. There is designed, tools tell us which are more powerful for exploiting Instead of investigating even measure or compare we developed theory of computation but it does theory, as in CT, we can define equivalence and given performance measures performance But in CT, “faster” does not necessarily mean “simpler” to CT reductions. Execution are analogous complexity. Finally, as in CT, notions of “simplicity” reduction or performance. of systems up to these of algorithms-although (e.g., asymptotic transformations then discuss (i.e., which can compute more). or reductions systems. To address this problem, as an analogy the are more “simple”, In our that we consider “fair”, in CT, the to choose from. in any sense. Our reductions to computational to notions of either transformations. Now, are orthogonal complexity) we can also compare our reductions. To make our stance clear, consider (CT). CT does not tell us which algorithms there are many different measures time or speed is analogous However, the notion of performance measures opens up a host of practical issues. 55 in a table could engineer, confronted by a some to measure is ineffective, may choose some simple scheme of looking up the “cost” of components strategy the problem to solve of the system rather (for example, measuring Certainly be used in conjunction with our system. An instrumentation problem where one measurement other property components pressure of a fixed volume of gas). This approach although measurement cost of transducers, and inferring effects in future work. another (for example, the effect on the measurement strain gauges). These than reconfigure from its value, noise properties of transducers in positioning than rather the temperature the is not envisaged by our theorems, distinct the example, one observable and common mode issues should be considered noise of measuring the power of two given strategies could be compared. Furthermore, strategies have costs other than those considered here-for the sensori-computational There is much to be done. Our model of reduction should be attempted. In addition to measuring the information is very operational complexity and others of commu- 55 I would like to thank the anonymous referees for suggesting these issues and the wording to describe them. 286 R.R. I)onclld/Arl~~tic.icll Intelligence 72 (I 995) 217-304 to quantify to measure it may be valuable the “size” of a resource permutation, nication, it may make sense sources are moved. All these ideas remain this problem by investigating preserving (a)-(e) it would be valuable across heterogeneous the distance messages must be sent. Similarly, or how far re- to be explored. Finally, we have approached that is, the kind of information- invariance, the resources that can be derived among systems containing variance, that is, that would apply (Section 3). An alternative would be to look at information to have a truly uniform measure of information resource categories. equivalencies information In the appendices we present a number of important extensions, and attempt to address some of the issues raised in this section. Acknowledgments Jim Jennings, to light without and Greg Whelan; Sundar Narasimhan, their help and experiments. This paper could never have been written without discussions and help from Jim Jennings, Mike Erdmann, Dexter Kozen, Jeff Koechling, Tomas Lozano-Perez, Daniela to all of them for their generosity Rus, Pat Xavier, and Jonathan Rees. I am very grateful with their time and ideas. The robots and experimental devices described herein were in our lab by Jim Jennings, Russell Brown, Jonathan Rees, Craig Becker, Mark built these ideas could never Battisti, Kevin Newman, Dave Manzanares, to have come I would thank Mike Erdmann, Jonathan Rees, John Canny, Ronitt Rubinfeld, Seth Hutchinson, and suggestions illustration for this paper and I am very grateful Koechling, Mike Erdmann, to me how lighthouses, ADFs, and VORs work. This paper was improved by incorporating suggestions made at the Workshop on Computational at like to thank Phil the University Agre, Stan Rosenschein, Yves Lesperance, Brian Smith, Ian Horswill, and all members I would also like to thank of the workshop, the anonymous I am grateful to Phil Agre who carefully edited the in Fig. 1. Debbie Lee Smith and Amy Briggs drew the rest of the figures to Jeff and suggestions. referees for their comments and suggestions. Theories of Interaction and Agency, organized of Chicago by Phil Agre and Tim Converse. on drafts of this paper. Thanks for their help. I am grateful suggestions on presentation. this paper and made many to Loretta Pompilio for their comments and Randy Brost and Amy Briggs for explaining for providing for drawing furthermore comments invaluable invaluable to them I would like Appendix A. Algebraic decision procedures The algorithms for an introduction of [ 21, or discussions we reduce our computational in Section 9 are algebraic and use the theory of real closed fie1ds;s6 the classic paper In Section 9, [ 481; in books such as [ 18, Chapters to algebraic decision procedures the truth of a Tarski formula see, for example I-41 and [lo]. to deciding problem sh Also called “Tarski’s Language” or the “first-order language of algebra and geometry”. One common mathematical term is “the first-order theory of real closed fields”. B.R. Donald/Artificial Intelligence 72 (I 995) 217-304 287 algorithms the language can of semi-algebraic the algebraic called defined by polynomial algebraic numbers. A Tarski formula universally equalities then decide such a sentence. Tarski’s language sets. Such sets are real semi-algebraic and inequalities, where the polynomial coefficients that quantifies existentially is a logical sentence is also varieties are or over each of the real variables. A typical Tarski formula might be: (Vx3y3zV’w) : xy* - 16w4 < 0 V~XW2+X7+78w<O A z4 + 5w3 + 4x2y* - y + 7.x = 0. More generally, we can think of a Tarski sentence as (01x1 02x2 ... 0~): Q(xI,...,x,) RI 0 CIS:!(XI,...,X,) R2 0 (A.1) C.4.2) among is a relation is one of V or A. 57 Each $1,. . . , s, is a polynomial . . , C,, are logical where each Oi is a quantifier, each Rj is a real relation, and Cl,. connectives. A quantifier Oi is either V or 3, and it quantifies over a real variable xi. real values, and is one of <, >, or =. A logical A real relation in lR[xi, . . . ,x,1, and connective in r variables. We call the set Y c Iw’ defined by (A.l) or (A.2) so (A.2) a semi-algebraic if it can be if the only real relation we in a form like (A.2). The set Y is called algebraic written (=) . The boolean characteristic require set is equality such as Y is defined as a set Y c R’ is called semi-algebraic function T( .) of a semi-algebraic set, and, conversely, is a sentence T(x,, . . . ,x,) USI(X~,...,X,) RI 0 CISZ(XI,...,X~) R2 0 (A.3) Cm-1 s,,,(xI,. . . txr) R, 0. T( .) is called a semi-algebraic predicate. Hence, (A.2) can be written (01x1 02x2 ‘. . Or&) : T(Xl,. . .1 x,1. Let CD be an s.a. predicate. Let x denote (xl,. (0x1, denote the sentence 3x : (T,(x) . . . , Ox,.). If 7l’r is an s.a. predicate A G(x)) as follows: . . , x,), and for a quantifier 0, let Ox for the s.a. set Y, we will abbreviate 3x E Y: @(x). this convention Given (A.4), formula Vx : (Ty( x) a G(x) ) is therefore equivalent a little manipulation shows to (A.4) that as a consequence, the V’x E Y: @p(x). 57 So < and > can be built out of these. 288 B.R. Donuld/Art@cial Intelligence 72 (I 995) 217-304 Let S be the total degree bound number of polynomials m the size of the Tarski sentence cate T( .) in (A.3). Observe however, of terms in (A.2)) we would employ as well. for the polynomials si , . , s,, in (A.2). We call the (A.2) and of the s.a. predi- that to calculate a bound 0( arm) on the number the degree bound 6 and the number of variables r Now, it is remarkable that one can decide such sentences although Tarski’s original algorithm improved by a chain of researchers how to decide the first-order in time 2 *“‘“” and space 2 o(n’) In Section 9, we use this result: in complete generality: this bound has been since then. For example, Ben-Or et al. [2] showed theory of real closed fields with a purely algebraic algorithm [48] was non-elementary,58 1291). Sentences in time doubly-exponential Theorem A.1 (Grigoryev decided specifically, where a < r is the number of quantifier alternations can be decided in the theory of real closed fields can be only in the number of quanti$er alternations. More the truth of a Tar-ski sentence for m polynomials of degree < 6 in r variables, in the prenex form of the formula, in time Proof. See [29 J. 0 A.l. Application: computational calibration complexity (A.5) complexity does not change with the immersion, the calibration than the issues of immersion complexity Recall the discussion in Section 8.7.4. We wish to develop an algorithm because the relation <* between sensor systems. Comparing nitions 5.1, 6.2) of two sensor systems seems easier the calibration simulation, respects long as the immersion calibration computing complexity that specify a sensor system. One measure, of course, constraints codesignation constraints, are also important. Using measure codesignated the codesignation is to measure the complexity of algebraic sensor systems (Definition relations such as those encountered 8.17). constraints. The essential the complexity Now, to decide the relation <*, we must be able to decide dominance for deciding (Defi- and so idea behind of the codesignation is the number of but other measures, the algebraic methods from Section A, we can develop tools to such as the degree and the quantification, in algebraically 5.1). We propose of the codesignation the complexity of the codesignation varieties that the algebraic (see Definition by the complexity complexity complexity measure of the semi-algebraic do this is to count algebraic codesignation complexity measure measure of the sensor’s calibration such as (A.5), the number, degree, quantification, constraints. This gives numbers to measure calibration constraints. constraints by comparing codesignations in calibration installation and In general, one may the complexity specify. One way to of the semi- for m, 6, a, and r for an algebraic and dimension for example. Eq. (A.5) can then be used as a complexity. These bounds can then be compared 5R Tarski developed this algorithm around 1920, but it was not published until later. B.R. Donald/Artijicial Intelligence 72 (1995) 217-304 289 big-Oh (O(e) ) notation) complexity. The comparison (using calibration to read the input, and the time required the algebraic simulation. to determine which sensor dominates can be done in essentially is very small compared terms of in the same time it takes the time for to (35), in our theory of a sensor system, that system Some of the complexity to map then though an abstract definition space, and this approach, obtained. We believe (see Eq. (38)), eliminate so forth). However, of measuring not yield a computational it mirrors much of modern geometry, that it would be possible instead of constructing some of the technical baggage required it appears that this approach would the complexity of the underlying theory of calibration configuration complexity. into a particular to proceed from a decision of the underlying results independent through configuration space. One may ask whether to the results space it as a quotient of set differences. This would and the question hence it would leave unanswered space-and to start with an a priori configuration non-codesignation (codesignation, is essential A.2. Application: simulation functions Recall the discussion in Section 8. We now discuss of simulation functions simulation systems is important that simulation this might be accomplished. functions work on permuted for components, and edges, and sensor It their encodings. sensor systems. Here is how functions A.2.1. Vertex versus graph permutations We now consider two orthogonal kinds of permutation. and a(e) never change. The first model l(u) 8.6. In this model, in Definition and wires with them. That is, the vertices move suffices follow. Vertex permutation in Sections 8.1 and 9 suffices edge labels and is given components as they move, the edges paper, and the machinery and <I. the vertices can move, and they drag the and in this the reductions <* (under permutation), for all reductions to compute In both models, the vertex and is called vertex permutation, We can also consider connectivity changes. An edge permutation with vertices V and edges E. Start with any bijection permutation, An edge permutation an alternate model, called edge permutation, where the edge can be modeled as follows. Consider a graph (+: V2 ---f V2. We call (T an edge the restriction map ~1s : E + cr( E) on the edge set E. says nothing about the immersion of a graph. it induces since That independently. We can also compose followed by an edge permutation. the models. We define a graph permutation In a graph permutation, is, vertices may move, but in addition, to be a vertex the vertices and the edge the different models, consider a sensor system 24 has one edge permutation the edges move connectivity may change. To illustrate U with three vertices {ui , ~2, ug} with labels e( ui) = Bi (i = 1,2,3). e = (~1, ~2) of bandwidth of the system, and e is a data-path. A vertex permutation U* of U would move vertices (and and ~2, (and edge connectivity. the spatially, but in U*, e would still connect UI the So, for example, an edge permutation CT(U) could be a graph with therefore therefore, BI and B2). An edge permutation CT of U would change to &. So, the Bi are the components k that connects Bi the components) 290 B.R. Donuld/Arr~jificiul Intelligence 72 (I 995) 217-304 of U is and (+ is an u2 to u3 (and hence B2 to Bs). But in a(U) no one edge a(e) = (~'2, Q), connecting edge would connect ui and ~2. Finally, consider a graph permutation U* of U. Suppose U* = (T( U*), that is, U* is the vertex permutation U* followed by the edge permutation u above. U* has the same edge connectivity immersed as in U*. To summarize: let (U, 4) be a situated sensor system. A graph permutation in U*, the vertices are as a(U). However, given by U* = (U, q ) where fl = (4’) CT), $* is a vertex permutation, edge permutation. So, vertex permutation preserves permits arbitrary the edges around. Edge permutation It cannot add new edges, nor can it change move edges). permutation required) discussed Section A.4). Here, we will content ourselves with answering permit graph permutation, permutation suffices for all the examples [ 171. Graph permutation (particularly in in Section 1 .l give us a more powerful reduction? rewiring the graph topology whereas edge permutation can existing their bandwidth. Although vertex (and for some of the applications (4) universal in this paper, graph permutation is also required (3) design and is useful (using if we does it change our complexity bounds? and (ii) does graph two questions: reduction-see (i) We first turn to question (i). Fortunately, we can extend our computational this scheme, we can compute all our reductions to graph permutation without difficulty. To do this, we model a graph permutation sensor system U as a vertex permutation Using time bounds given in place of vertex permutation mutandis. graph permutation throughout. Our other lemmas also go through mutatis in Lemma 9.9 and Corollary 9.10, permitting of U, followed by an edge permutation (<*, <I, etc.) within results of a of U. the same We now elaborate. An adjacency matrix for a sensor system with d vertices is a d x d integer entries. binary matrix. An adjacency matrix with bandwidth has non-negative An entry of b in row u, column u specifies a (directed) between59 vertices L: and u. Given an edge permutation adjacency matrix, and the edge simulation be constructed in our sensor system as part of its configuration. Hence, system may have different “wiring diagrams” (different such “configurations” demonstrate their algebraicity. and the resulting “configuration functions edge of bandwidth (T, we can construct a new (such as s2, in Section 8.1) can logK(b) in different configurations, edges). We now consider the this space”. In particular, we wish to from the adjacency matrix. Now, we may view the edges (data-paths) Consider a sensor system U with d vertices V, and O(d2) edges E. When we permit of this system can be specified by a pair (4, (T), graph permutation, a configuration where 4: V -+ C is an immersion space Cd. What about u? u is a As we have discussed, 4 lives member of the permutation group on d2 elements. u can be modeled as a d2 x d2 binary matrix called a permutation matrix. Every permutation matrix has a single 1 in each row the space and column, the other entries being zero. Let Z;2 denote 8.4) of U, and u is an edge permutation. the field Z/2. Then, in the configuration (Definition 59 This representation is not hard to extend to components with multiple inputs and outputs, using an rd x sd matrix. B.R. Donald/Art$icial Intelligence 72 (1995) 217-304 291 of permutation matrices Each element is an orthogonal matrix, with determinant fl. is o( &, d2), the orthogonal group of d2 x d2 binary matrices. Every “rewiring” of U using only existing edges O( Zz, d2). So, to model vertex permutation configuration to add one extra wire reductions edge simulation functions (output communication), from adjacency matrices is s.a. I+ E is encoded by a permutation plus rewiring, we extend our usual sensor this model (for k-wire of or several extra wires (Section 8.10.3) ). The space O( &, d2) is algebraic, and the computation space from Cd to Cd x O(Z2, d2). It is not hard to extend it is to compute Now, how expensive the reductions <* and 61 using graph per- space (which has mutation? Perhaps surprisingly, dimension the same complexity bounds given d4 + r,d in Lemma 9.9 and Corollary 9.10 (so long as r and s are constants). This is because 6o even with this extended configuration instead of r,d), we still obtain (see Eqs. (35-37)) n(d4+rcd)o”’ is still n(‘Cd)O”‘. We now address question (ii): does graph permutation give us a more powerful reduction? In answer we show the following: Lemma A.2 (The clone permutation, sor system. lemma). Graph permutation preceded by a linear time and linear space can be simulated using vertex of the sen- transformation system simulates Proof. Given a sensor system U we “clone” all its vertices, and attach the edges to the clones. The cloned is colocated with remain associated with original vertices. We can move an edge its clone. Components (which independently of are clones). Any graph permutation the cloned system. of IA can be simulated by a vertex permutation the original when each vertex connected, by moving of the components it originally its vertices More specifically: given a graph G = (YE) with labelling function new graph G’ = (V’, E’) with labelling be an injective map from V into a universe of vertices 61 V, such that cl(V) lift cl to V2 and then restrict then cl(e) = (cl(u),cl(u)). it to E to obtain cl : E ---f cl(V)* as follows: Edge labels are defined as foIlows: C’(cZ(e)) =l(ef. function L”. Let the cloning f?, we construct a function cl : V-+ V f~ V = 8. We If e = (u, u), Finally we define V’ = V U cl(V) and E’ = cl(E) . We define e’(u) the labelling returns function the “identity” e’ on V’ as follows, C’(u) = l(u) when u E V. Otherwise, component, which can be simulated as the identity function.62 Suppose U has d = [VI vertices and /El edges. This transformation adds only d vertices and can be computed in time and space O(d + [El). 0 is absorbed by the 0( I ) in the second exponent. ho Another way to see this is as follows: even if we try each of the (d*) ! edge permutations, ( d2) ! factor h1 See Section C.1. ‘*The proof can be strengthened (explicit) connection when vertices have no associated components, the encoding without adding additional physical can communicate without an if cloned that is, L?‘(u) = 0 for L: Q V. This version has the appeal of changing that colocated. Therefore as follows, Recall they are spatially two components the proof goes through even this additional resources. 292 B.R. Donald/Arri’citrl Intclligrrm 72 (I 995) 217-304 Let us denote by cl(U) clone Lemma A.2. Now consider any k-wire reduction & linear-space the of U described transformation (Section 8.10.3). We see that: in Corollary A.3. Let k E W. Suppose V <k U (using graph permutation). that for two sensor systems U and V, we have Then V <k cl(U) (using only vertex permutation). Class edge permutation In practice, we wish to impose some restrictions on edge and graph permutation. in the system, suppose we have a sensor in addition where both SOURCE system U containing robots L and R. The sensori-computational and two cooperating systems for L and R to bandwidth, have a and DESTINATION For example, communicating mobile are modeled as circuits. The data-paths type, of the form SOURCE--,DESTINATION, E {L, R}. When permuting only edges of the same two classes, L + R. In constructing U*, we may use an internal edge (of sufficient bandwidth) to connect sufficient bandwidth) edge permutation, we permute unchanged to permute into internal edges L 4 L and R + R, and external edges L + R and the complexity bounds and the lemmas of Section A.2. I. edges within a class. Class edge permutation the edges of U to obtain U*, it makes sense two components where SOURCE=DESTINATION. type. More generally, we may segregate External edges Hence, (of in class leaves can be used when SOURCE the edge types # DESTINATION. any In this example, maintaining exactly two physical locations can be done using simple codesignation constraints. More generally, we take SOURCE, DESTINATION E C. A.3. Application: parametric codesignation constraints Recall Eq. (34)) in which we formulated cision procedure. We now discuss notation and hypotheses of Section 9.2. some the sensor reduction problem as an s.a. de- the technical details of this equation, using In order to allow for sufficient generality, we must permit V’s codesignation constraints that (U,(Y) denotes to depend on U’s configuration Cy. That is, the s.a. set Dvu(Z) Cy. Recall given sensor system V can simulate constraint DVU (Cy) that depends on (Y. That is we are interested that sensor system U is at configuration Z, we are interested but only when V’s configuration the sensor system U installed (U,Z), is an s.a. function of at configuration Z. Now, in whether or not - p* satisfies some in the question: “Does (V, p*) simulate (U, Z), given that p* lies in Dvu (Z) ?” 63 For example, consider the reduction the ship’s configuration things) “coordinate” of Cu. The parametric codesignation the corresponding “Can H simulate E?” only makes sense given G and (ii) constraints the ships (that are invariant with (Y) ensure ship in the lighthouse in Proposition 6.6. Here U specifies (among other (x, h) in the radial sensor E. We think of (x, h) as one is used to ensure that sensor H is also placed at (x, h) . The question constraint D”(Z) that (i) H and E are both installed at in H and E are in the same configuration. (i). whereas parametric Static codesignation codesignation ” In particular, we do not cnrc what happens when p* @ Dvu(Y), B.R. Donald/Artificial Intelligence 72 (1995) 217-304 293 (resp. ~,q,~) be the projection constraints rE,x ship’s configuration. semi-algebraic DH could be implemented functions. Then as (that vary with E) ensure (ii). This could be implemented of E’s (resp. H’s) configuration So, in particular, 7r,sX(Z) = (x, h). These projections codesignation (this aspect of) the parametric as follows: that returns let the are clearly constraint p E DH(~) _ (rH,x(p) = ‘W,x(z.)) . (A.61 The fact that we have an equality constraint and H are simple sensor systems (Definition sensors systems), DH could specify a more complicated (=) 8.17). in Eq. (A.6) In general the fact that E reflects (for arbitrary algebraic s.a. relation between ZC and /I. (see Eq. (34) ) Formally, parametric codesignation constraints as DH (A.6) and Dvu can be modeled as parametric S.U. sets (see [ 61) : set D (1~) is defined Definition A.4 ( Canny). A parametrically-de$ned as follows. D(a) is an s.a. set which is a function of some argument CY. Hence there is an implicitly defined s.a. predicate To( z, (w) which is true iff z E D(a). Now, let Y be an s.a. set with predicate Tr. So, when we write D(a) C Y we mean Vz To( z, cu) + %y (z ) , which gives us an s.a. predicate @o (cr) which is true of those values of LY such that D(a) semi-algebraic c Y. A.4. Application: universal reductions We can now use the tools from Sections A.2-A.3 to develop an algorithm for “uni- requires graph reduction” versal permutation (application (see Appendix A.2.1) . 4 of Section 1.1) . Universal reduction function 0~ that computes a function of (a) for U, and a function 0~ for V. The bag Let U and V be sensor systems. Suppose we are given a specification as usual, is encoded as a simulation “bag of parts” for V. The specification, as described in Section 8.1. We are also given a simulation of parts consists of boxes and wires. Each box is a sensori-computational (“block box”) inputs. The “wires” have different bandwidths, Recall we are given a simulation fi, function and 0~ are encoded; immerse the components also give the immersion how they should be wired together). Hence, we can ask, can the specification implemented its together. e(u) and a simulation functions Qu (above) decide, can we of U? The algorithms in the world, and of U be its spatial and they can hook the boxes of V so as to satisfy (that see Section 8.1) . Then, our algorithms is, how the boxes should be placed this is how the global simulation function &, for each component for each edge e (indeed, location or pose and (b) the bag of parts V? the specification component using Now, suppose that in addition that U <1 V. Since of U as a bag of parts, and an immersion further the “power” of the components quantifying do the job of the components over the configuration this reduction of U?” to the specification to implement for U, we are given an encoding Suppose is relativized both to U and to V, it measures in V. By universally of U, we can ask, “can the components of V always to the components that specification. of U relative 294 B.R. Donuld/Artijiciul Intelligence 72 (1995) 217-304 More specifically: let LY be a configuration of the sensori-computational the set of all graph permutations Let l4* = (U, cu*) be a graph permutation denote .X((u) x 0(&, well as its wiring connectivity. By Sections 8.9.2 and A.2.1, zY( a) is s.a. d2). Thus (Y* E Z~*((Y), and (Y* encodes of LY, so, if U has d vertices, the spatial of (U, cu) (Section A.2.1). Let then C*(a) = immersion of 2.4 as Similarly, let ,L3 be a configuration of V. Hence, we can decide the Tarski sentence (KY* t X*(&u), 1p* E DVU(a*) n X*(p)) : (u,a*) <I (v,p*), (A.7) system U. .P((Y) holds, we say where DVU( .) Eq. (A.7) ~ersal reduction algebraically. With time complexity of deciding is a parametric s.a. codesignation constraint that 24 universally reduces to V, (or (Section A.3). When is a uni- reductions that there from L4 to V). Hence, is possible to compute universal the notation and hypotheses as above throughout Appendix A, the (A.7) is given by Eq. (AS), which becomes (ms)o(‘.)*‘+’ = (no fw) O( r,d+dJ) ‘-I (A.81 Eq. (A.8) is still (no + no)(rcd) ““‘. Hence we have that Corollary A.5 Universal bounds given in Eqs. (35)-(37). reductions (Eq. (A.7)) can be computed in the same time Appendix B. Relativized information complexity Let us specialize Definition 6.4 to monotonic sensor systems: Definition 6.4 (Monotonic). Consider b be the output of sensor S. We say S is eficiently two monotonic sensor systems S and Q, and let reducible to Q if (4) S <* Q + COMM(b). In this case we write S <I Q. For the sensors we have considered, their complexity could essentially be characterized this definition looks at a visual the size log IK( b) of the output b. We now generalize is as follows. There are sensor systems whose complexity using motivation characterized by the number of bits of output. 64 For example: consider a “grandmother” sensor. Such a sensor visual field contains interpretation which discusses different perspective, process field)-i.e., if the if it doesn’t. Now, one view of the sensor [ 141, reduction and identification a somewhat that views sensors as model matchers. So, imagine a computational that G is in the data (the visual field itself). The sensor and #f is that of information given V (the visual in the probability P( G 1 V) of G (grandmother) field and outputs one bit, returning #t slightly. Our cannot be well- However, consider a grandmother the probability that calculates information). hierarchies of sensor (compare problem ‘+I This discussion devolves to a suggestion of Sundar Narasimhan [42], for which we are very grateful. B.R. Donald/Artificial Intelligence 72 (1995) 217-304 295 to see a grandmother the former case is something prefers is a process TIGER (when given a fuzzy picture specific only to detecting grandmothers, while as the model that best explains the latter the current data. The latter this sensor might output that computes over model classes. For example, that is best explained as a tiger). 6s In short, one may view a sensor system as storing prior distributions. These distribu- the stored distributions informa- In principle, state. To quantify it toward a fixed set of model classes. the absolute or internal tions bias may be viewed either as calibration tion complexity model classes stored in the prior distribution of a sensor system, we need to measure complexity of of the sensor. This could be very difficult. to measure a quantity called the maximum bandwidth of a sensor and external edge over all internal is the maximum the information this quantity Instead, we propose Intuitively, system. bandwidths (data-paths). That is: Definition 6.1 (First part). We define sensor system S to be the greatest bandwidth of any internal S. The output size of S is given by Definition 5.2. We define mb(S) size of S. the internal (resp. external) bandwidth of a (resp. external) edge in the maximum bandwidth and the output to be the greater of the internal bandwidth, external bandwidth, is an upper bound on the relative complexity of the components intrinsic output complexity (Sections 8 and 12)). We The maximum bandwidth (relativized explore to the information this notion briefly below. Maximum bandwidth is a measure of information ponents of the system. For example, component mother). The only data-path component small, in the system the absolute that outputs one bit when it recognizes is a measure of internal information complexity only relative to the sensori-computational complexity. The bandwidth com- that we had a sensor system with a single (say, a grand- the single is a complicated model in the system has bandwidth one bit, because is very powerful. So, even though the maximum bandwidth imagine information complexity may be large. So, some sensors are black boxes. We call a sensor system a black box if it is encoded as a single component. The only measure of bandwidth we have for a black box is its output size. For example, Erdmann’s a black box plus output communication. radial sensor E (Section 4.1) is essentially More generally, we call a sensor system monotonic if its internal and external band- widths are bounded above by its output size. So, black box sensors are trivially mono- tonic. All the sensor systems in our forthcoming work in this paper are monotonic. But some of the systems [ 171 are not. In light of this discussion, we now give a generalized definition of the reduction < 1, using relativized information First, let S be a monotonic complexity. sensor system with output b as in Definition 6.4. In this case, we define COMM(~) to be COm(b). 65 Now one may ask why prefer one model over another and there can be many answers. Minimum Description Length, or MDL. This theory attempts to minimize L(M) + L( D 1 M) where L(M) the length of model and L( D 1 M) is the length of the data given that the model is minimal. [42] advocates is 296 B.R. Dnnald/Artijicial Intelligence 72 (199.5) 217-304 More generally, for (possibly) in general COMM(zk) where k is the relative (k) (Definition S as an upper bound on k. Finally, we generalize Definition 6.4 to nonmonotonic systems as follows: is difficult, but we will treat the maximum bandwidth nonmonotonic let COMM(S) sensors, we will intrinsic output complexity of S. Measuring be this 6.1) of sensor Definition 6.4 (Generalized). ejficiently reducible to Q if S <* Q +coMM(S). In this case we write S <I Q. Consider two sensor systems S and Q. We say S is (B.1) Appendix C. Distributive properties In this appendix, we prove some technical properties about the permutation of partial the “distributive prop- (i.e., without output to include the definition of compatibility immersions. These properties erties”. First, we consider vertices, as in Definition permutation for partial and we call them and combination are algebraic, “pure” permutation in Sections C.l-C.2 we generalize of output vertices. Recall and combination (Section 8.4). 8.12). Then, immersions Definition C.l. Let 4 and tj be compatible partial immersions. We say the permutations 4* and @* are compatible permutations of 4 and fi, if fl and 9’ are also compatible. We would like to show that for immersions, commute. immersions 4 and +, if 4* and I,?’ are compatible and permutation combination That is: for two compatible partial then permutations, 4* +I)* = (4+#)*‘? In answer, we can now show the following: Claim C.2. Consider compatible permutations 4* and $*. Then two compatible partial immersions 4 and 1+9, together with two (1) 4* ++* G -z’(4+qj. (2) Let y* E 2(4 + fl,). Then there exists 4* E S(4), @* E _I$($), such that y* = 4’ + **. Proof. (2) First, let y* be a permutation of 4+fi. Then 4* is a permutation of 4 and fl* is a permutation of @, and 4* + +* = y*. Let 4* = y*14-lc and r+%* = y*l+-lc. ( 1) Conversely, suppose 4* and r,V are compatible permutations that since the domains of 4 and 4* (resp., Cc, and @* ) are identical, we observe the domains of 4’ + J+F and 4 + Cc, are identical. Hence, 4* + t,b* is a permutation 4+4. of 4 and t++. Then therefore of 0 B.R. Donald/Artijicial Intelligence 72 (1995) 217-304 297 Next, we ask, for sensor systems, do combination and permutation commute? That is: for two sensor systems S and U, is it true that s* +?A* = (S +2/f)* whenever + is defined (see Definition 8.12) ? In answer, we show the following: Proposition C.3. Consider sions are compatible, so that S + U is dejined. Then, two sensor systems S and U as above. Assume their immer- ( 1) Let S’ and U* be compatible permutations of S and U. Then S* + U* is a permutation of S + U. (2) Let (S+U) * be a permutation of S+U. Then there exist compatible permutations S’ and U* of S and U resp. such that S* + U* = (S + U) *. Proof. Let S = (S,qb), U = (U,+>, S* = (S,4*) Claim C.2. 0 and U* = (U,JI*), and apply C. I. Combination of output vertices Recall the definition of combination in Section 8.5. There, we considered systems S and U. Both have output vertices, say, u, and u, resp. When we combine two sensor systems S and U to form S + 2.4, we must specify of the new, combined in a consistent manner commutative. two sensor the the unique output vertex system. We now show how to choose output vertices and operation + remains sensor so that the combination associative First, we view each sensor system as a pointed graph-a graph with one distinguished the output vertex. 66 We define + on two pointed graphs in such a manner let (Cl, UI ) be a pointed graph with vertex called as to produce a new pointed graph. For example output vertex ~1. Let (G2, ~42) be another pointed graph. Then (Gl,ul) + (G2vu2) = (GI +G2,w +u2), 8.12). The output vertex UI + 142 is where Gl + G2 denotes combination let V be the universe of all possible vertices. So, for any graph Gi defined as follows: with vertices and edges (F, Ei), we have L$ c V. We insist that V have a total-order +. Define u1 +u2 =min+(ul,uz). (Definition It is easy to see that under this definition, the operation + on pointed graphs is both associative and commutative. C.2. Output permutation Recall Definition 8.6. There, we also permitted a permutation ’ has the “output device” label. This kind of permutation is not required to change which vertex for the monotonic 66 We must be careful not to confuse a pointed graph with a pointed sensor system (Definition 8.8) 298 B. R. Donald/Artificial Intelligence 72 (I 995) 217-304 sensor systems theory, and it is used explicitly (Appendix B) considered in [ 171. We formalize in this paper, but it is needed for the general called output permutation is to choose a new distinguished vertex. For example, point ua, we could choose a new distinguished (Section C. 1) . for vertex ui. this notion here. on pointed graphs We define an operation The effect of this operation a graph G with distinguished We represent this operation by (G,no) ++ (G,uI). We call (G, ~1) an output permutation of (G, ~a). Now, following Appendix A.2.1, let us call our existing notion of permutation (Defi- nition 8.6) by the name vertex permutation It is possible to compose output permutations (to distinguish it from output permutation). and vertex permutations. We adopt to include both output permutations and Convention C.4. We use the term permutation vertex permutations. Similarly, we will use the operator * for any permutation. This convention is necessary to make combination and permutation commute in gen- era1 C.3. Discussion .) = (S + COMM( (the * operation) that S’ + COMM( commute. So, for example, In Appendices B and C, we have made sure that combination in any order. Second we have ensured and associative. Third, and (the + operation) for any sensor system S, have permutation and ensured operation + is combination (see gener- commutative alized Definition 6.4) we have given enough bandwidth so that it still works when we switch it (e) around using permutation. Hence, the sensor as the sensor system Q system is that of the permuted largest flow in S. in an arbitrary way, plus one extra data-path whose bandwidth in Definition 6.2, for the reduction <r .) ) *, i.e., we can do the permutation the single edge e in COMM(.) (B.l) may be implemented that the combination (Q + COMM( S) )* in 3. Appendix D. On alternate geometric models of information invariants We have presented a geometric model of information John Canny and Jim Jennings information model is somewhat different for suggesting invariants, using the language and concepts developed in flavor from that of Section 8. to that I provide an “abstract” example of I am grateful invariants. in [ 141. The resulting Here is a alternate geometric model for an example of information invariance. Let IA equivalence of perceptual classes, as in [ 14, 5.11. A simple control [ 161 on U. Now consider and the sensing map, as in [ 14,5.2]. Let U and V be two arrangements of perceptual be an arrangement strategy may be modeled the lattice of perceptual equivalence varying equivalence there is an information invariant for U and V as a subgraph of the RR-graph classes formed by fixing the task environment in the lattice. Then classes B.R. Donald/Artificial Intelligence 72 (1995) 217-304 299 they have a common when Note that by construction, This example is simple; other kinds of information coarsening 67 W, together with a control strategy on W. this control strategy agrees on the overlap of U and V. it remains this geometric model invariants. to develop and exploit for Appendix E. A non-geometric formulation of information invariants in which like a “logical” There are several places where we have exploited the geometric in constructing problems measure geometric quantities). that each component It is of some interest our framework. First, our sensors are geometrical Second, the configuration is physically placed and oriented to derive an “abstract” of a sensor in physical space. version of our framework structure of robotics (in that they in is geometrical, geometry framework. plays no role. ‘* Such a framework would be something It is not hard to formulate our approach in a geometry-free manner. First one would say that the “value” or the “output” of a sensor is simply a value in some set. Next, one would replace space C of a component by any set of the form the configuration C = {z 1 z is a location}. (E.1) and In constraints codesignation constructions, constraints now reduce to Chapman’s to have no structure whatsoever. All the definitions, C can be taken proofs of Section 8 then go through mutatis mutandis: there is no geometry anywhere. particular, our (formerly geometric) codesignation (propositional) [ 71. It is now worth asking, what are the implications for Section 9? It is easy to extend function Ktu for a sensor system 24: one obtains a set set. At this point we to derive the algorithms of Section 9. Hence In particular, we structure. that other in the abstract the definition map flu lose the algebraic properties we exploited our algorithms do not obtain when we remove lose our main computational deductive mechanisms might be used, case. (non-geometric) the geometric result, Lemma 9.10. It seems plausible, however, : Cd --+ R where C is as in (E.l ), and R is an arbitrary to obtain similar of a simulation instead, results Appendix F. Provable information invariants with performance measures El. Kinodynamics and tradeoffs It is possible to develop provable have performance measures. Consider once again above in Section 2.1. That these invariants 201 should come as no surprise, since the execution information in the special case where we invariants discussed [ 8,19, is taken (Eq. ( 1)) are related to kinodynamics time for a control strategy the information invariants 67 A coarsening of U and V is a partition W such that both U and V are finer than W. 68 I am grateful to Stan Rosenschein for encouraging me to develop this generalization. 300 B.R. Donnld/Art$ciul Inrellipm 72 (1995) 217-304 tradeoffs introduced complexity, executor complexity, the tradeoffs between planning a new algorithmic mechanism for measuring Essentially, Xavier considers how closely trajectory and how much “safety” es-in as “cost”. In [ 491, Pat Xavier kinodynamic quantify (clearance). optimal-time to execute “equicomplexity” For a fixed “complexity” the planner, of the phase space for the dynamical obtains a kinodynamic of the form (see [ 211 for a brief description). These techniques were used to and “safety” an required solution with an uncertain control system. Xavier obtained in the ET-ES plane. These curves may be interpreted as follows. time of r (which may be equivalently viewed as (i) the running density the discretization the robot), Xavier’s planner family of approximations solution which satisfies a one-parameter (ET) one can approximate the sense of headway-is of the planner, or (iii) the space requirements system representing the approximate curves (ii) CF.]) (El) invariant invariants r. Hence represents information conditioned is a fruitful is a function as well, and, on complexity such theorems about the dynamics and geometry, an infor- where fr mation if we view the “following distance” d as being similar to the clearance parameter es, such kinodynamic methods appear attractive. We believe they that these methods could be used to prove require specific assumptions in principle. Pursuing Kinodynamic find provable, 491). However, it makes controls, not sensing, theory of Lozano-Perez compared with reachability. manipulation kinodynamics emphasize performance, and one may even [ 21, therein this line of attack. First, in the same way that in the citizen of a bias towards sensorless control. Second, the results tradeoffs are one source of information for information [ 261; in kinodynamics, relies on a measure of cost (in a bit dissatisfying the senior partner, much like ( 1) ; while they are quite general it is a consequence of model-based In [ 381, this is a consequence this case, time), and hence rigorous characterizations invariants, questions line of future research. [ 111)) recognizability et al. [ 381 (see is a second-class not competence. is something about (e.g., there Glossary of symbols 69 Section/ Page Definition Figure Appendix (equation) IR s’ real numbers unit circle P? I” trajectories S 9 Q Q simulates S 2.1 2 2.1.2 2.1.2 4. I 222 222 222 233,244,25 I + E G combination of sensor systems 8. IO 253.244 the radial sensor the goal configuration 4.1 4.1 234 234 4.1 8.10 (3),(6) (3) 5 5 “For some symbols, the first page reference points to the beginning of the (sub)section explaining or containing that symbol. B.R. Donald/Artificial Intelligence 72 (1995) 217-304 301 SeCtid Appendix Page Definition Figure (equation) R x, x h Or N H L B (white?) (green?) (time) ship ship’s position ship’s heading angle between h and the goal direction direction of North tbe lighthouse (beacon) sensor lighthouse R’s beating from L rotating green light flashing white light l-bit white light sensor l-bit green light sensor clock (orientation) orientation sensor hR PI generalized compass (installed on R) sensed position COMM( .) communication primitive COMM(L -+ R, info) communicate info from L to R 4.1 4.1 4.1 4.1 4.2.1 4.2.1 4.2.1 4.2.1 4.2.1 4.2.1 4.2. I 4.2.1 4.2.1 4.2.1 5.2.1 5.2.1 5.2.1 5.2.1 234 234 234 234 235,236 235,236 235,236 235,236 235,236 235,236 235,236 235,236 235,236 235,236 239 239 239 239 COMM(Br) XQ,... h K(b) mb( S) COMM(h) COMM(S) EG &i * datapath labeled Br sensor systems output of a sensor S 5.2.1, 8.1.2 239, 256,244 5.2.1 239 5.4.1, 8.1 244, 247.245 5.2, 8.3, 6.4 number of values b can take on 5.4.1, 6 244,245 maximum bandwidth of S datapath with bandwidth log iK( b) datapnth with bandwidth mb( S) radial sensor installed at G lighthouse sensor installed at G (vertex) permutation petmutation of H permutation of HG simulation and domination O-wire reduction l-wire (“efficient”) reduction k-wire reduction reduction using global communication 6, B 8.7.2 B 5.3.1 5.3.1 5.3.1 3 3 6.2 6.3 6.4 8.10.3 8.10.4 reduction using polynomial communication 8.10.4 a graph with vertices V and edges E number of vertices in V sensor systems immersions labelling function configuration space situated sensor system permutation of an immersion permutation of a sensor system pointed immersion pointed sensor system pointed permutation 8.1 9.2 8.2 8.1 8.1 8.1 8.1 8.1 8.1 a.7 8.7 8.7 245.294ff 256,245,268 294,296 242.25 1,244 242,244,25 1 242.250.244 244 244 245,265 245,264,268 245 261 27Off 270ff 241 214,214 247,267,268 247,250 247,250 247 247,250 247,250 247.250 251 251 251 5.2 6.1 6.4 8.8 8.8 8.6 6.2 6.3 6.4 8.21 8.29 8.1 a.2 8.4 8.4 8.6 8.6 8.6 a.1 8.7 8.7 5 5 5 5 6 6 6 6 6 6 6 6 6 6 7 (3) (4) 14).(4’) (B.1) (3) (3) (3) (3) (3) (24)-(28) (4). (4’) (35) 9, 10 302 B.R. Donuld/Arti’cial Intelligence 72 (1995) 217-304 Section/ Page Appendix Definition Figure (equation) 8.8. IO 259, 275 (14),(38) 9.1, A 27 I, 286,287 extension of a partial immersion 8.3 extension of a permutation output vertex diagonal S.U. predicate extensions of 6 (vertex) permutations of 4 graph permutations of 4 image of C$ simulation function quantifier sa. codesignation constraints dimension of C degree bound simulation complexity XI. codesignation complexity 9.1 8.5 8.9.2 8.9.2 A.4 X.9.2 9.1 9.1 9.2 9.2 9.2 9.2 92 edge petmutntion A.2.1 graph permutation of U, (U, 4) A.2. I group of orthogonal matrices clone function A.2.1 A.2.1 252 271 253 261,263 26 1,263 293 261,264 271,241,274 9.2 211,287 274,274 274,214 274,274 274,214 274,214 289 289 289 9.8 9.8 289,291 A.2 (A.3) (20) (20) (A.7) (22) (34) (A.3) (34) (35) (35) (35) (35) References [ 1 ] M. Blum and D. Kozen On the power of the compass (or, why mazes are easier to search than graphs), in: Proceedings [ 21 M. Ben-Or, D. Kozen and J. Reif, The complexity of elementary 19th Symposium on Foundations of Computer Science, Ann Arbor, Ml ( 1978) 132- 142. algebra and geometry, J. Camp. Syst. Sci. 32 (1986) 251-264. [ 31 M. Blum and W. Sakoda On the capability 17th Symposium on Foundations of Computer Science of finite automata in 2 and 3 dimensional ( 1977) 147- 161. space, in: Proceedings [ 41 A. Briggs, An efficient algorithm for one-step compliant motion planning with uncertainty, Algorithmica 8 (2) (1992) IS] R.G. Brown, Forthcoming 195-208. Ph.D. Thesis, Computer Science Department, Cornell University, Ithaca, NY, USA. [ 6 1 J. Canny, On computability of fine motion plans, in: IEEE International Conference on Robotics and Automation, Scottsdale, AZ ( 1989). [7] D. Chapman, Planning ]S] J. Canny, B. Donald, for conjunctive goals, Artif Intell. 32 (3) J. Reif and P. Xavier, On the complexity Symposium on rhe Foundations of Computer Science, White Plains, NY ( 1988) 306-316. (1987) 333-378. of kinodynamic planning, in: 29th 19 1 J. Canny and J. Reif, New lower bound techniques for robot motion planning problems, 28th Annuul IEEE Symposium on Foundations ] 10 ] D. Cox, J. Little and D. O’Shea, in Computer Science, Los Angeles, CA ( 1987). Ideals, Varieties, and Afgorifhnts, Undergraduate Texts in Mathematics ( Springer-Verlag. New York, 199 I ). I1 1 B.R. Donald, Robot motion planning, 121 B.R. Donald, The complexity of planar compliant motion planning with uncertainty, Algorithmicu IEEE Trans. Rob. Autom. 8 (2) (1992). 5 (3) (1990) 353-382. ) 131 B.R. Donald, Error and ( Springer-Verlag, New York, 1989). 1 141 B.R. Donald and J. Jennings, Constructive Autonom. Syst. (9) ( I ) ( 1992) 41-74. detection recovery in robotics, Lecture Notes in Computer Science 336 recognizability for task-directed robot programming, .I. Rob. B.R. Donald/Artificial Intelligence 72 (1995) 217-304 303 [ 151 B.R. Donald and J. Jennings, Constructive recognizability for task-directed robot programming, in: Proceedings IEEE International Conference on Robotics and Automation, Nice, France ( 1992). [ 161 B.R. Donald J. Jennings, Sensor and classes, equivalence Sacramento, CA ( 199 1) . in: Proceedings interpretation using perceptual International Conference on Robotics and Automation, task-directed planning and IEEE [ 171 B.R. Donald, J. Jennings and D. Rns, Information for distributed manipulation, and J.-C. Latombe, eds., The First Workshop on the Algorithmic Foundations of Robotics Boston, MA, 1994). A revised version of: B.R. Donald, of information Robotics Research (ISSR), Hidden Valley, PA ( 1993). in: R. Wilson (A.K. Peters, and D. Rns, Towards a theory in: International Symposium on J. Jennings robots, autonomous mobile for cooperating invariants invariants [ 18 I B.R. Donald, D. Kapnr and J. Mnndy, Symbolic and Numerical Computation for Arttficial Intelligence (Academic Press, London, 1992). 1191 B.R. Donald planning, (1989). and P. Xavier, A provably good approximation algorithm for optimal-time trajectory in: Proceedings IEEE International Conference on Robotics and Automation, Scottsdale, AZ [20] B.R. Donald and F! Xavier, Provably good approximation for Cartesian robots and open chain manipulators, Geometry, (Berkeley, CA 1990). planning in: Proceedings 6th ACM Symposium on Computational for optimal kinodynamic algorithms [ 211 B.R. Donald and P Xavier, Time-safety planning IEEE International Conference on Robotics and Automation, Sacramento, CA ( 199 1). trade-offs and a bang-bang for kinodynamic algorithm in: Proceedings [22] M. Erdmann, Personal Communication [23] M. Erdmann, Using backprojections (1986). ( 1992). for fine motion planning with uncertainty, Int. I. Rob. Rex 5 ( I ) [ 241 M. Erdmann, On probabilistic strategies for robot tasks, Ph.D. Thesis, MIT-AI-TR 1155, Department of EECS, MIT AI Lab, Cambridge, MA ( 1989). 1251 M. Erdmann, Towards Carnegie-Mellon School of Computer Science, Pittsburgh, PA ( 199 1) task-level planning: action-based sensor design, Tech. Report, CMU-CS-92-116, 1261 M. Erdmann and M. Mason, An exploration of sensorless manipulation, in: IEEE International Conference on Robotics and Automation, San Francisco, CA ( 1986). 1271 M. Fischer, N. Lynch and M. Merritt, Easy impossibility proofs for distributed concensus problems, Distrib. Comput. 1 ( 1986) 26-39. [28] PC. Fischer, Turing machines with restricted memory access, [29] D.Y. Grigoryev, Complexity of deciding Tarski algebra, J. Symb. Comput. 5 ( 1) (1988) 65-108. 130 1 J.E. Hopcroft, and M. Shark, On of motion planning Inf Control 9 (4) the complexity J.T. Schwartz (1966) 364-379. for multiple Int. I. Rob. Res. 3 (4) independent (1984) 76-88. objects; PSPACE-hardness of the “Warehouseman’s Problem”, [ 3 I] J.E. Hopcroft and J. Ullman Introduction to Automata Theory, Languages, and Computation (Addison- Wesley, Reading, MA, 1979). [ 321 I. Horswill, Analysis of adaptation [ 33 ] J. Jennings and D. Rns, Active model acquisition and environment, Artif: Infell. 73 ( 1995) (to appear). for near-sensorless manipulation with mobile robots, International for Development (IASTED) in: International Association Conference on Robotics and Manufacturing, Oxford, England of Science and Technology ( 1993). [ 341 J. Jennings, Sensor interpretation and task-directed planning for autonomous agents, Ph.D. Thesis, Computer Science Department, Cornell University, Ithaca, NY ( 1994) [35] D. Kozen, Automata and planar graphs, fundamentals of computing Proceedings Conference on Algebraic, Arithmetic, and Categorical Methods ( Akademie Verlag, Berlin, 1979). [ 361 J.-C. Latombe, Robot Motion Planning [ 371 T. Lozano-P&ez, 108-120. (Klnwer, New York, 199 I ). space approach, Spatial planning: a configuration theory, in: L. Bndach, ed., in Computation Theory IEEE Trans. Comput. 32 ( 1983) 1381 T. Lozano-Perez, M.T. Mason and R.H. Taylor, Automatic synthesis of fine-motion strategies for robots, Int. I. Rob. Res. 3 (1) (1984). (391 V.J. LnmeIsky and A.A. Stepanov, Path-planning strategies for a point mobile automaton moving amidst unknown obstacles of arbitrary shape, Algorithmica 2 ( 1987) 403-430. 304 B.R. Donald/ArtQicial Intelligence 72 (I 995) 217-304 I40 I M.T. Mason, Mechanics and planning of manipulator pushing operations, I41 1 M. Minsky, Recursive unsolvability of Post’s problem of ‘Tag’ and other topics lnt. J. Rob. Rex 5 (3) ( 1986). in the theory of Turing machines, Ann. of Math. 74 (3) ) 42) S. Narasimhan, Personal Communication I43 1 B.K. Natarajan, On planning assemblies, IL ( 1988) 299-308. Geometry, Urbana, ( 1961) 437-455. ( 1993). in: Proceedings fin&h Annual Symposium on Computational 1441 J. Rees and B.R. Donald, Program mobile robots Conference on Robotics and Auromation, Nice, France in scheme, ( 1992). 145 1 J. Reif, Complexity of the mover’s problem and generalizations, of Computer Science ( 1979); also Symposium on Foundations Sharir, eds., Planning, Geometry and Complexity of Robot Motion 267-281. in: Proceedings IEEE International in: Proceedings IEEE in: J. Schwartz, and M. (Ablex, Norwood, NJ, 1987) Ch. I I, J. Hopcroft 20th Annual ( 46 ] S.J. Rosenschein, Synthesizing information-tracking automata from environment descriptions, Teleos Research, Tech. Report No. 2 (1989). [ 47 1 D. Rus, Fine motion planning for dexterous manipulation, Ph.D. Thesis, Tech. Report CU-CS-TR 92. 1323, Computer Science Department, Cornell University, Ithaca, NY ( 1992). I48 1 A. Tarski, A Decision Method for Elementary Algebra and Geometry (University of California Press, Berkeley, CA, 2nd ed., I95 I ). ) 49 1 PG. Xavier, Provably-good approximation algorithms for optimal kinodynamic Tech. Report CU-CS-TR 92-1279, Computer Science Department, Cornell University, robot plans, Ph.D. Thesis, Ithaca, NY ( 1992) 