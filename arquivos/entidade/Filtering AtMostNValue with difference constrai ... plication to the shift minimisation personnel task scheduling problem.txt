Artificial Intelligence 212 (2014) 116–133Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFiltering AtMostNValue with difference constraints:Application to the shift minimisation personnel taskscheduling problem ✩Jean-Guillaume Fages a,∗, Tanguy Lapègue ba École des Mines de Nantes, LINA (UMR CNRS 6241), LUNAM Université, 4 rue Alfred Kastler, La Chantrerie, BP20722,44307 Nantes Cedex 3, Franceb École des Mines de Nantes, IRCCyN (UMR CNRS 6597), LUNAM Université, 4 rue Alfred Kastler, La Chantrerie, BP20722,44307 Nantes Cedex 3, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 3 February 2014Received in revised form 31 March 2014Accepted 4 April 2014Available online 12 April 2014Keywords:Constraint-ProgrammingGlobal constraintsAtMostNValueShift Minimisation Personnel TaskScheduling ProblemThe problem of minimising the number of distinct values among a set of variables subjectto difference constraints occurs in many real-life contexts. This is the case of the ShiftMinimisation Personnel Task Scheduling Problem, introduced by Krishnamoorthy et al.,which is used as a case study all along this paper. Constraint-Programming enables toformulate this problem easily, through several AllDifferent constraints and a singleAtMostNValue constraint. However, the independence of these constraints results ina poor lower bounding, hence a difficulty to prove optimality. This paper introducesa formalism to describe a family of propagators for AtMostNValue.In particular,we provide simple but significant improvement of the state-of-the-art AtMostNValuepropagator of Bessière et al., to filter the conjunction of an AtMostNValue constraintand disequalities. In addition, we provide an original search strategy which relies onconstraint reification. Extensive experiments show that our contribution significantlyimproves a straightforward model, so that it competes with the best known approachesfrom Operational Research.© 2014 Elsevier B.V. All rights reserved.1. IntroductionThe problem of minimising the number of distinct values among a set of variables subject to difference constraints occursin many real-life contexts, where an assignment of resources to tasks has to be optimised. For instance, in transports, crewshave to be assigned to trips [42]. In schools, classes have to be assigned to rooms [12]. In airports, maintenance tasks haveto be assigned to ground crew employees [16,17]. In some factories, fixed jobs have to be assigned to machines [23,24,38].In a more theoretical context, one may need to colour a graph, such that adjacent vertices have distinct colours and notevery colour can be taken by every node [28,30]. In order to illustrate our contribution, we consider the Shift MinimisationPersonnel Task Scheduling Problem (SMPTSP) [36]. This problem belongs to the set of personnel scheduling problems [19,57]. It arises when a set of tasks, fixed in time, have to be assigned to a set of shifts so that overlapping tasks are not✩This paper is an invited revision of a paper first published at the 19th International Conference on Principles and Practice of Constraint Programming(CP 2013) where it was recognized as the best student paper.* Corresponding author.E-mail addresses: jean-guillaume.fages@mines-nantes.fr (J.-G. Fages), tanguy.lapegue@mines-nantes.fr (T. Lapègue).http://dx.doi.org/10.1016/j.artint.2014.04.0010004-3702/© 2014 Elsevier B.V. All rights reserved.J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133117assigned to the same shift. Each shift is associated with a given subset of assignable tasks. The objective is to minimisethe number of used shifts. This problem typically occurs as the second step of decomposition methods which handle thecreation of shifts in a first step. With this kind of methods, side constraints related to personnel roster design are consideredin the first step only, whence the simplicity of the SMPTSP formulation. Nonetheless, current exact approaches relying onMixed Integer Programming (MIP) fail to solve large scale instances [36,43]. This is the main motivation for investigating aConstraint-Programming (CP) approach.CP is a programming paradigm which belongs to the wide field of Artificial Intelligence (AI). It is a declarative languagewhich enables to model both satisfaction and optimisation problems through variables, domains, and constraints [52]. Eachvariable is associated with a domain representing its possible values. The constraints are defined over variables to modelthe properties which must hold. Therefore, a solution is an assignment of values to variables which satisfies every constraintof the model. From a technical point of view, a constraint is equipped with at least one propagator which filters infeasiblevalues from variable domains. Each time a variable domain is reduced, the propagators associated with this variable arescheduled for further filtering. This leads to series of filtering steps, called propagation [54]. A propagator is monotonic [55]when the smaller the domains before filtering, the smaller the domains after filtering, under the inclusion. Furthermore,it is idempotent [55] if applying its filtering algorithm twice in a row leads to no further inference. Overall, the solvingprocess relies on a backtrack algorithm which alternates filtering steps to make inference and branching decisions to performhypothesis.The core idea of CP is to design independent constraints that can be combined through shared variables, in order tomodel constrained problems. However, in case of optimisation problem, such independent constraints often lead to a poorbounding of the objective function compared to a MIP approach. This restrains the deployment of CP into industrial appli-cations [39]. Therefore, it is often more interesting to design global constraints [4]. These constraints are able to considera larger part of the problem, hence their filtering impact is increased. For instance, the AllDifferent global constraintis the conjunction over a clique of binary difference constraints, and it has been proved highly relevant within CP solvers[50]. However, developing effective global constraints is often difficult, and it also tends to make CP solver maintenancemore expensive, which is one of the greatest concerns of the CP community [47]. Consequently, from a practical pointof view, one would rather adapt existing constraints than to implement brand new ones, in order to capitalise over pre-vious work. In this paper we investigate the interest of considering difference constraints when filtering the well knownAtMostNValue constraint [3,7,48]. We introduce a new propagator whose implementation is based on the state-of-the-artAtMostNValue propagator [7]. Furthermore, we provide a bold search strategy which relies on constraint reification toattempt strong search space reduction. A wide range of experiments shows that our contribution significantly improves theCP model, so that it competes with the most recent SMPTSP dedicated approaches.The remainder of the paper is organised as follows: Section 2 is devoted to the description of the SMPTSP, in Section 3we show how the straightforward CP model of the SMPTSP can be improved with a new propagator. Then, a branchingscheme suited to solve the SMPTSP is presented in Section 4. Our approach is validated by an extensive experimental studyin Section 5, followed by our conclusions.2. Description of the SMPTSPThis section first introduces the notations that are used in the paper. Then, some simple complexity results are mentionedto give insight over our case study. Finally, it provides the state-of-the-art mathematical formulation of the problem.2.1. NotationsIn the following, T and S respectively refer to the set of tasks and shifts. Note that a shift may be seen as a workerwith specific skills and potentially a working time window [36]. Given a task t ∈ T , we refer to the set of shifts that canbe assigned to t as St ⊆ S. Therefore, the SMPTSP consists of assigning to each task t ∈ T , a shift s ∈ St , with a minimumtotal number of shifts, and such that overlapping tasks have different shifts. As tasks are fixed in time, finding all maximalsets of overlapping tasks, referred to as C is polynomial [29]. It amounts to finding the set of maximal cliques in an intervalgraph. The size of the largest clique, referred to as LB(cid:5)=, provides a trivial lower bound on the required number of shifts.Fig. 1 introduces the running example of the paper. The input instance data is displayed in Fig. 1a. It includes a set of5 tasks T = {t1, .., t5} and a set of 5 shifts S = {s1, .., s5}. Each task, represented by a rectangle, is associated with a setof compatible shifts, e.g. St1= {s2, s3, s4}. Starting and ending time of tasks give C = {K1, K2, K3} with K1 = {t1, t2, t3},K2 = {t1, t3, t4}, K3 = {t4, t5}. Therefore, LB(cid:5)= = 3. An optimal solution involving shifts {s1, s2, s3} is given in Fig. 1b. Thisexample will be used all along the article to illustrate our points.2.2. ComplexityThe SMPTSP is similar to many problems such as the Fixed Job Scheduling Problem [23,24], the Interval SchedulingProblem [34,35], the Class-Room Assignment Problem [12], the Graph Colouring Problem [28] and the List Colouring Prob-lem [18]. Therefore, many complexity results of the literature are relevant to our case study. For instance, when shifts are118J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133Fig. 1. A basic example with 5 shifts and 5 tasks.identical (∀t ∈ T , St = S), the SMPTSP can be seen as a Graph Colouring Problem,1 where vertices correspond to tasks,shifts correspond to colours and two vertices are connected whenever their corresponding tasks overlap in time. While thisproblem is NP-hard in general, it is polynomial for interval graphs, which is our case because the graph is generated froma set of time intervals (each task is associated with a fixed time interval) [25]. Nevertheless, the SMPTSP generally involvesrestrictions over allowed shift-task assignments, i.e., shifts are not identical. The previously mentioned colouring problemhas to be changed so that not every colour can be taken by every vertex. Instead, each vertex is associated with a subset offeasible colours. This problem is known as the List Colouring Problem [18], and it is NP-hard, even for interval graphs [25].Therefore, the complexity of the SMPTSP stems from shift heterogeneity.2.3. Mathematical formulationThe SMPTSP may be stated in Mathematical Programming by using binary variables xt,s and ys, which respectivelyspecify if the task t is assigned to the shift s and if the shift s is used. Based on these variables, the number of used shifts isgiven by (1) and the assignment of tasks to compatible shifts is ensured by (2). The purpose of the constraint (3) is twofold:First, it prevents shifts to be assigned to overlapping tasks. Second, it ensures that shifts assigned to at least one task arecounted as used. We refer to this model as MIP model:minimisesubject to:(cid:2)s∈S(cid:2)s∈St(cid:2)ysxt,s = 1,∀t ∈ Txt,s ≤ ys, ∀s ∈ S, ∀K ∈ Ct∈Kxt,s ∈ {0, 1},ys ∈ {0, 1},∀t ∈ T , ∀s ∈ St∀s ∈ S3. A CP model based on the AtMostNValue constraint(1)(2)(3)(4)(5)This section first introduces a straightforward CP formulation of the SMPTSP. Next, it recalls the former AtMostNValuepropagator our approach is based on, and provides a new formalism to define propagators of the same family. Then, itintroduces a new propagator which filters AtMostNValue while considering a set of difference constraints. We show howto improve and diversify its impact on variables. Finally, we discuss the case of dynamic difference constraints and providesome implementation guidelines.3.1. A straightforward CP formulationThe SMPTSP can be formulated within CP with a set of |T | integer variables X and one objective variable z. X representstask-shift assignments: More precisely, if we note d(x) the domain of a variable x ∈ X , then d(xi) = { j} means that task tiis assigned to shift s j and d(z) gives the number of shifts assigned to at least one task. We refer to this model as CP model:minimisesubject to:z(cid:3)AllDifferent{xi | i ∈ K}(cid:4), ∀K ∈ CAtMostNValue(X , z)(6)(7)(8)1 We recall that the Graph Colouring Problem consists of assigning a minimum number of colours to vertices of a graph, such that adjacent vertices havedistinct colours.J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133},initial domains: d(xi) = { j ∈ Sti(cid:6)(cid:5)LB(cid:5)=, |S|d(z) =∀xi ∈ X119(9)(10)The expressive language offered by CP enables to model the problem through two global constraints. In (7), AllDif-ferent constraints [50] are used to forbid the assignment of overlapping tasks to the same shift. In (8), the AtMost-NValue constraint [7] is used to restrict the number of shifts that are involved in the schedule. Then, variable initialdomain definitions are given by (9) and (10). Trivial lower and upper bounds for z are respectively the maximum numberof overlapping tasks (LB(cid:5)=, the number of variables in the largest AllDifferent constraint) and the number of availableshifts.From a sementical point of view, constraints (7) are equivalent to one single SomeDifferent constraint. This constrainthas been introduced in [51] to model a set of disequalities, in order to solve a workforce management problem [2]. Apropagator establishing the Generalised Arc Consistency (GAC) on SomeDifferent has been introduced in [51]. Since itsworst case runtime complexity is O (n3βn), with β ≈ 3.5, Richter et al. suggests various modifications to improve its runtimeon their industrial benchmarks [2,51]. Nevertheless, their study shows that their algorithm is not suited to instances whosedisequalities are numerous and form a graph which consists of few big connected components. This is unfortunately the caseof SMPTSP instances, for which the graph of overlapping tasks is presumably connected. Furthermore, as AllDifferentconstraints are detected in polynomial time, then CP model already has a good propagation of disequalities. Therefore, wedo not use SomeDifferent in CP model.To get a higher level of abstraction, we now consider the SMPTSP as the problem of assigning a minimum number ofvalues to variables, which are subject to some difference constraints.3.2. State-of-the-art filtering of the AtMostNValueconstraintThe AtMostNValue constraint belongs to the Number of Distinct Values constraint family [3]. It has been introducedin [48] to specify music programs but the first filtering algorithm was provided in [3]. Then, the AtMostNValue constrainthas been widely investigated in [7], where the authors proved that enforcing the GAC on AtMostNValue is NP-hard, andprovide various filtering algorithms. According to this study, the greedy propagator they introduced provides a good tradeoffbetween filtering and runtime. Thus, we use it as the reference propagator for filtering the AtMostNValue constraint.Before describing this propagator we need to recall a few definitions:Definition 1. The intersection graph of a set of variables X , GI (X ) = (V , EI ), is defined by a vertex set V where eachvariable xi ∈ X is associated with a vertex i ∈ V , and an edge set EI representing domain intersections: For any (i, j) ∈ V 2,there is an edge (i, j) ∈ EI if and only if d(xi) ∩ d(x j) (cid:5)= ∅.Definition 2. An independent set in a graph G = (V , E) is a subset, A ⊆ V , of disjoint vertices, i.e., for any (i, j) ∈ A2 suchthat i (cid:5)= j, (i, j) /∈ E.Definition 3. A maximum independent set in a graph G is an independent set whose cardinality is maximum. The indepen-dence number of a graph G, noted α(G), is the cardinality of a maximum independent set in G. The set of all independentsets in a graph G, is referred to as IS(G).The filtering algorithm proposed in [7] stems from the search of a maximum independent set in GI (X ). Since thisproblem is NP-hard [27], it actually computes an independent set A in GI (X ), in a greedy way, by selecting nodes ofminimum degree first [31]. This heuristic is referred to as MD. Then, the propagator filters according to the following rules:– R1: z ← max(z, | A|)– R2: | A| = z ⇒ ∀i ∈ V , d(xi) ← d(xi) ∩(cid:7)a∈ A d(xa)Where z and z respectively refer to the lower bound and the upper bound of the variable z. R1 states that the cardinalityof A is a valid lower bound for z. R2 states that whenever the cardinality of the independent set A is equal to the upperbound of z, then variables in X have to take their values among the subset of values induced by A. Indeed, variablesassociated with an independent set of an intersection graph take different values, by definition. Thus, using a value outsideof this subset of values would lead to use at least | A| + 1 values, which is a contradiction.Regarding the time complexity of these filtering rules, R1 clearly runs in constant time whereas R2 requires a finerstudy. Let the number of variables and the number of values be respectively referred to as n = |X | and l = |S|. We assumethat the intersection, as well as the union, of two variable domains can be computed in O (log(l)) worst case time witha∈ A d(xa) requires at most n domain unions. As it does not depend on i, itbit vector operations. The computation ofcan be computed once and for all in O (n log(l)) worst case time. Then, n domain intersections are performed. Thus, R2 ispropagated in O (n log(l)) worst case time.(cid:7)120J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133Fig. 2. Applying AMNV(cid:13)GI |MD|R1,2(cid:14) to our example when d(z) = {1}.Overall, the greedy propagator of AtMostNValue takes a graph G as input, calls a function F to compute independentsets in G and then filters variable domains with a set of rules R. Therefore, we introduce the notation AMNV(cid:13)G|F |R(cid:14) to de-fine such a family of propagators. Consequently, the greedy propagator introduced in [7] is referred to as AMNV(cid:13)GI |MD|R1,2(cid:14).In the following, we suggest improvement for G, F and R, leading to a new propagator which filters AtMostNValue anda set of difference constraints.To illustrate the state-of-the-art propagator, we now apply it to our running example in Fig. 2, with d(z) = {1}. Thisstate might occur during the resolution. Because of variable domain definitions, the intersection graph corresponding toour example, is a complete graph. Thus, MD selects only one node, x3 for instance. Next, R1 states that the number ofvalues is at least one, which provides no information because d(z) = {1}. Then, R2 states that values 2, 4 and 5 must beremoved from the domain of the variables (Fig. 2a). Consequently, the edges (x1, x5) and (x5, x4) have to be removed inorder to obtain the new intersection graph. Based on this new graph, if we assume that x1 and x5 are then used as a newindependent set (Fig. 2b) then R1 states that the number of values is at least two, leading to fail.3.3. Embedding difference constraints into AtMostNValueAs the SMPTSP only considers two kinds of constraints (AtMostNValue and AllDifferent), filtering their conjunc-tion may be very profitable. For that purpose, this section introduces an implied propagator, in the form AMNV(cid:13)G|F |R(cid:14),which considers difference constraints. This work stems from the very simple observation that, if a disequality states thattwo variables xi and x j of X must take different values, then for every solution, there is no edge between vertex i andvertex j in GI (X ). However, such an edge might exist during search. If so, then it would presumably lower the propagationstrength, because the more edges in GI (X ), the smaller independent sets in GI (X ). Hence, we should remove those edgesas soon as possible. Consequently, we introduce the constrained intersection graph (Definition 4), to be used instead of theintersection graph of variables.Definition 4. Given a set of variables X and a set of difference constraints D, the constrained intersection graph, GCI (X , D) =(V , ECI ), of X and D is defined by a vertex set V where each variable xi ∈ X is associated with a vertex i ∈ V , and anedge set ECI representing possible classes of equivalence: For any (i, j) ∈ V 2, there is an edge (i, j) ∈ ECI if and only ifd(xi) ∩ d(x j) (cid:5)= ∅ and neq(xi, x j) /∈ D.In this paper, we consider a single set of variables X and a single set of difference constraints D, thus, for the sake ofclarity GCI (X , D) and GI (X ) will be respectively noted GCI and GI . GCI can be computed by removing from GI anyedge which is associated with a disequality. It is worth noticing that GCI ⊆ GI .Proposition 1. IS(GI ) ⊆ IS(GCI ), hence α(GI ) ≤ α(GCI ).Proof. Let AI be an independent set in GI . Since GCI and GI are based on the same variable set, they share the samevertex set, so AI is also a subset of vertices of GCI . Since vertices of AI are pairwise disjoint in GI (by assumption) andsince all edges of GCI also belong to GI , then vertices of AI are also pairwise disjoint in GCI . Consequently, AI is an inde-pendent set in GCI . Thus, all independent sets in GI are independent sets in GCI , so maxI∈IS(GI ) |I| ≤ maxIc ∈IS(GCI ) |Ic|,hence α(GI ) ≤ α(GCI ). (cid:2)Note that a maximum independent set in GI , is not necessarily maximal in GCI . For instance, one may consider anon-empty set of variables with identical domains and with a difference constraint over each pair of distinct variables. ThenGI is a complete graph, whereas there are no edges, but loops, in GCI . Consequently, α(GI ) = 1 whereas α(GCI ) = |V |. Itis worth noticing that in our context, the bigger the independent set, the higher the chance to filter variable domains. Thus,using GCI is presumably better than using GI to filter AtMostNValue when difference constraints figure in the model(Proposition 2).To illustrate the interest of GCI , we now use it on our example, with d(z) = {1, 2, 3}, in Fig. 3. Because of differenceconstraints, GCI is sparser than GI (Fig. 3a). Thus, MD is now able to compute a larger independent set, leading to find aJ.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133121Fig. 3. Use of AMNV(cid:13)GCI |MD|R1,2(cid:14) on our example.better lower bound for z. For instance, if we consider the independent set {x1, x2, x3} (Fig. 3b), then R1 and R2 respectivelystate that the number of values is at least three and that the value 5 can be removed from the variable domains.Following [15], a propagator A is stronger than a propagator B if and only if, in any propagation, any value filtered by Bis also filtered by A. Furthermore, A is strictly stronger than B if and only if A is stronger than B and there exists at leastone problem instance for which a value is filtered by A and not by B, during a propagation step.Proposition 2. Given an oracle O which computes all maximum independent sets of any graph, then AMNV(cid:13)GCI |O|R1,2(cid:14) is strictlystronger than AMNV(cid:13)GI |O|R1,2(cid:14).Proof. First of all, since O is able to compute all maximum independent sets of any graph, then the lower bound given by R1in GCI is equal to α(GCI ) whereas the lower bound given by R1 in GI is equal to α(GI ). Since α(GI ) ≤ α(GCI ) (Propo-sition 1), then AMNV(cid:13)GCI |O|R1(cid:14) is stronger than AMNV(cid:13)GI |O|R1(cid:14). Second, since O is able to compute all maximum inde-pendent sets of any graph, and since IS(GI ) ⊆ IS(GCI ) (Proposition 1), then values filtered by AMNV(cid:13)GI |O|R2(cid:14) are alsofiltered by AMNV(cid:13)GCI |O|R2(cid:14). Consequently, AMNV(cid:13)GCI |O|R2(cid:14) is stronger than AMNV(cid:13)GI |O|R2(cid:14). Examples given onFigs. 2and 3 illustrate a case where α(GCI ) > α(GI ). Therefore AMNV(cid:13)GCI |O|R1,2(cid:14) is strictly stronger than AMNV(cid:13)GI |O|R1,2(cid:14). (cid:2)Proposition 3. Given an independent set A in GCI such that | A| = z, any solution of the conjunction of AtMostNValue and Dsatisfies the following formula: ∀i ∈ V \ A, ∃a ∈ Ai s.t. xi = xa, where Ai denotes {a ∈ A | (i, a) ∈ ECI }.Proof. Given an independent set A in GCI such that | A| = z. Let’s assume that there exists a solution S to the conjunctionof AtMostNValue and D such that there exists a vertex i ∈ V \ A for which ∀a ∈ Ai, xi (cid:5)= xa. Thus, S is solution of theconjunction of AtMostNValue and D ∪ {neq(xi, xa) | a ∈ Ai}. Consequently, A ∪ {i} is a valid independent set in GCI . ThenR1 states that z ← | A ∪ {i}|, i.e., z ← z + 1 which is not possible. Consequently, such a solution S does not exist, henceProposition 3 holds. (cid:2)From a filtering perspective, Proposition 3 leads to consider the following rule:– R3: | A| = z ⇒ ∀i ∈ V \ A(cid:8)(cid:7)d(xi )←d(xi )∩Ai ={a} ⇒ d(xa)←d(xa)∩d(xi )d(xa)a∈ AiThis rule is actually a refined variant of R2. While this change is quite simple, it may have a significant impact inpractice, especially on large scale problems were, for any i ∈ V \ A, | Ai| is presumably small compared to | A|. Note theparticular case that occurs when, for some node i ∈ V \ A, Ai = {a} enables to learn the valid equality xi = xa. This way, itis possible to filter the domain of the variable xa of the independent set as well. From a theoretical point of view R3 isalso stronger than R2 (Proposition 4). However, such filtering comes at a price. As it depends on i,d(xa) must becomputed for every i ∈ V \ A. This raises the worst case time complexity of R3 to O (n2 log(l)).To illustrate this rule, we now apply it on our example, with d(z) = {1, 2, 3}, in Fig. 4. If we consider the independentset {x1, x3, x4}, then R1 deduces that d(z) = {3} but R2 cannot filter X domains (Fig. 4a), because the set of values inducedby the independent set is {1, 2, 3, 4, 5}. However, R3 (Fig. 4b) enables to filter the value 5, which is not included in d(x1) ∪d(x3) = {1, 2, 3, 4}, from the domain of x5. It also removes values 1 and 2, which do not figure in d(x4) = {3, 4, 5}, from thedomain of x2. Finally, it learns the valid equality x2 = x4, which allows to remove values 4 and 5 from the domain of x4.a∈ Ai(cid:7)Proposition 4. Given a deterministic heuristic H which computes an independent set A in GCI , then AMNV(cid:13)GCI |H|R3(cid:14) is strictlystronger than AMNV(cid:13)GCI |H|R2(cid:14).Proof. Since AMNV(cid:13)GCI |H|R3(cid:14) and AMNV(cid:13)GCI |H|R2(cid:14) use the same deterministic heuristic H in the same graph GCI , thenthey filter with the same independent set A. Since, for any node i ∈ V , Ai = {a ∈ A | (i, a) ∈ ECI }, then Ai ⊆ A. Consequently,any value filtered by R2 is also filtered by R3. The example given on Fig. 4 illustrates a case where AMNV(cid:13)GCI |H|R3(cid:14)filtrates more than AMNV(cid:13)GCI |H|R2(cid:14). Therefore, AMNV(cid:13)GCI |H|R3(cid:14) is strictly stronger than AMNV(cid:13)GCI |H|R2(cid:14). (cid:2)122J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133Fig. 4. AMNV(cid:13)G CI |MD|R1,2(cid:14) versus AMNV(cid:13)G CI |MD|R1,3(cid:14), on our example.3.4. Diversifying filteringCP frameworks traditionally perform a fix point over constraints at each branching node [54]. This implies that our modelmay compute thousands of independent sets during the search process. Thus, it is advised to use a greedy algorithm, suchas MD, to filter the AtMostNValue constraint [7]. This heuristic is efficient but it lacks diversification for both its boundand the resulting filtering, which depend on the computed independent set. If we assume ties (of equal degree vertices) arebroken in a lexicographic way, then MD is deterministic. This may lead to unfortunate results when the considered graphdoes not suit this heuristic.Proposition 5. Given two functions F1 and F2 which compute a set of independent sets in GCI , respectively noted A1 and A2.If F1 and F2 are such that, for any A1 induced by F1 and for any A2 induced by F2, maxI2∈A2\A1|I1|, thenAMNV(cid:13)GCI |F1|R1,3(cid:14) is strictly stronger than AMNV(cid:13)GCI |F2|R1,3(cid:14).|I2| < maxI1∈A1|I1||I2| ≤ maxI1∈A1|I2| < maxI1∈A1|I1|, hence AMNV(cid:13)GCI |F1|R1(cid:14) isProof. First, maxI2∈A2\A1implies that maxI2∈A2stronger than AMNV(cid:13)GCI |F2|R1(cid:14). Second, let’s now assume that a value is removed from a domain of a variable in Xby AMNV(cid:13)GCI |F2|R3(cid:14). If this filtering occurs while considering an independent set of A1 ∩ A2, then the same filteringis performed by AMNV(cid:13)GCI |F1|R1,3(cid:14). Else, this filtering occurs when considering an independent set I2 of A2 \ A1. Anecessary condition so that R3 triggers filtering is that, |I2| = z. As |I2| < maxI1∈A1|I1|, then the problem is actually infea-sible, which is captured by AMNV(cid:13)GCI |F1|R1(cid:14). Thus, AMNV(cid:13)GCI |F1|R1,3(cid:14) is stronger than AMNV(cid:13)GCI |F2|R1,3(cid:14). Let F1 = MDand F2 = FV respectively denote the minimum degree heuristic and a (bad) heuristic which selects only the first vertex.We assume ties are broken in a lexicographic way, i.e., in case of a complete graph, both heuristics output the same sin-gleton independent set, hence both approaches are equivalent. If the graph is not complete, then there exists at least avertex pair (u, v) ∈ GCI with no edge, hence any independent set computed by MD will have at least two vertices. Thus,AMNV(cid:13)GCI |MD|R1,3(cid:14) is strictly stronger than AMNV(cid:13)GCI |FV|R1,3(cid:14). Therefore, if F1 and F2 are such that, for any A1 inducedby F1 and for any A2 induced by F2, maxI2∈A2\A1|I1|, then AMNV(cid:13)GCI |F1|R1,3(cid:14) is strictly stronger than|I2| < maxI1∈A1AMNV(cid:13)GCI |F2|R1,3(cid:14). (cid:2)As suggested in [3,7], and highlighted by Proposition 5, it may be interesting to obtain several independent sets to applyfiltering rules over a greater set of variables. In particular, if all maximal independent sets were known, R1,3 could thenbe used optimally, i.e., all values that could be filtered by R1,3 would actually be filtered. One way to find all maximalindependent sets is to adapt the algorithm of Bron–Kerbosch, an exact algorithm which computes all maximal cliques inan undirected graph [10]. However, as the underlying problem is NP-hard, performing the Bron–Kerbosch algorithm at eachpropagation would presumably be very time consuming. On our large data, it turned out that the improved filtering providedby this algorithm is not worth the overhead. Therefore, we suggest to keep the philosophy of MD and to get diversificationthrough a fast algorithm. The simplest way would be to randomly break ties of MD. However, this does not bring enoughdiversification to improve results. Thus, we introduce the Rk algorithm (Algorithm 1).The Rk heuristic performs k iterations, each one computes an independent set randomly. Each independent set is com-puted by successively selecting a node randomly and removing it along with its neighbours, until all nodes are removed. Itthus provides a set of k independent sets, each one being maximal under inclusion. However, these independent sets are notnecessarily all distincts (random node selections might lead to same results). As it relies on randomness, such propagator isneither idempotent nor monotonic. From a theoretical point of view, this approach presents several interesting properties.First, it offers control over its runtime complexity and its expected quality. Second, computing independent sets randomlytends to impact variable domains homogeneously. Note that, when k → ∞, then the method tends to enumerate and filterwith all maximum independent sets, which is optimal with the given filtering rules. However, from a practical point of view,one has to bound the number of iterations in order to get a reasonable runtime. We suggest to keep k between 20 and100 as a default setting, which seems to perform better than MD, on average, without introducing a significant overhead.Regarding the probability distribution of Rk, two options may be considered: A uniform distribution or a weighted distri-bution where small-degree vertices are more likely to be selected. The second option may be seen as a random adaptationof MD. Based on practical experiments, and because MD offers a good approximation ratio [31], we recommend to use auniform-distribution Rk together with MD.J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133123Algorithm 1 Rk algorithm to compute independent sets.Require:G CI , the constrained intersection graph of which independent sets have to be computedk, the number of iterations (and thus the number of independent sets to compute)count ← count − 1G ← GCI .copy() // Copies the constrained intersection graphA ← ∅ // Creates an independent set A, initially emptywhile (G (cid:5)= ∅) do1: A ← ∅ // Creates a set of independent sets, initially empty2: count ← k3: while (count ≥ 0) do4:5:6:7:8:9:10:11:12:13: end while14: return A // returns a set of independent sets in GCIend whileA ← A ∪ { A} // adds the independent set A to Ax ← randomNode(G) // Randomly selects a node x in GA ← A ∪ {x}// Adds x to the independent set AG ← G \ { y | (x, y) ∈ G} // Removes x’s neighbours from G (including x itself)3.5. The case of dynamic difference constraintsOur approach focuses on the SMPTSP which considers a set of tasks that are already fixed in time. Thus, differenceconstraints are given as input through a set of AllDifferent constraints. However, one may be interested in filteringAtMostNValue when difference constraints appear dynamically during the search. Let us consider a generalisation of theSMPTSP for which tasks are no longer fixed in time but have a time window instead. In such problem, disequalities implic-itly appear as time variable domain reductions induce task overlaps. It is worth noticing that in this situation, differenceconstraints would no longer be well propagated because of the absence of AllDifferent constraints in the model. For-tunately, the AtMostNValue propagator can help to get back a global view of the problem and thus a powerful filteringthanks to Proposition 6.Proposition 6. If A is an independent set in GCI , let X A denote {xi ∈ X | i ∈ A}, then the constraint AllDifferent(X A) holds.Proof. By definition of a constrained intersection graph, an independent set represents variables that are either alreadydifferent or constrained to be. (cid:2)From Proposition 6, we derive a new filtering rule for AtMostNValue which calls a filtering algorithm of AllDif-ferent over variables corresponding to the independent set A it has computed:– R4: AllDifferent({xi ∈ X | i ∈ A})Note that this rule can either directly call a filtering algorithm of AllDifferent over the appropriate subset of vari-ables or post dynamically an AllDifferent constraint into the solver. The first option is the simplest one, but cannotfilter incrementally, so a bound-consistent (BC) filtering algorithm of AllDifferent, such as the one presented in [44],would presumably be more relevant than the GAC one [50]. Note that the subset of variables to be different is lost right afterfiltering and the next propagation may involve a worse independent set. Instead, the second option can involve incrementalGAC AllDifferent constraints which would remain in the current search branch. However, since each independent setcan post an AllDifferent constraint, it has the drawback of leading to a potential explosion over the number of suchconstraints. Thus, one needs to set up a constraint pool to manage those constraints, by retaining only the most interestingconstraints and removing dominated ones. One can see a parallel with Cut pools of MIP solvers [1]. For solver maintenancesimplicity purposes, we recommend the first option.Note that R4 is only relevant when disequalities arise during search. It is useless in the case of the SMPTSP, because allmaximal AllDifferent constraints are already preprocessed in polynomial time. Overall, R4 can be seen as a dynamicgeneralisation of a common good practice, which consists in reformulating a set of disequalities into AllDifferentconstraints during preprocessing [30].3.6. ImplementationSo far, we have seen that it was possible to tune the original greedy AtMostNValue propagator. We now suggest asimple and generic pseudocode (Algorithm 2).The constrained intersection graph is stored as a backtrackable structure which is updated at the beginning of thefiltering algorithm, i.e., after potentially many domain modifications. This turns out to be much faster than updating GCIincrementally after every domain modification or rebuilding it entirely from scratch. Once the graph has been updated, the124J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133Algorithm 2 AMNV(cid:13)GCI |F |R(cid:14) – filtering algorithm.Require:z, an integer variableX , a set of variablesD, a set of difference constraintsG CI = (V , ECI ), a backtrackable graphF , a function that computes a set of independent sets in a given graphR, a set of filtering rulesend ifECI ← ECI ∪ {(i, j)}end forG CI ← (V , ECI )if (d(xi ) ∩ d(x j ) (cid:5)= ∅ ∧ neq(xi , x j ) /∈ D) then// graph generationV ← [1, |X |]ECI ← ∅for ((i, j) ∈ V 2) do1: if (first call of the propagator) then2:3:4:5:6:7:8:9:10:11: else12:13:14:15:16:17:18: end if19: A ← F (G CI ) // computes a set A of independent sets20: for ( A ∈ A) do21:22: end forif (d(xi ) ∩ d(x j ) = ∅ ∨ neq(xi , x j ) ∈ D) thenfilter(X , z, GCI , A, R) // rule-based filtering// graph lazy updatefor ((i, j) ∈ ECI ) doECI ← ECI \{(i, j)}end forend ifpropagator computes a set of independent sets with a function F . For each independent set, the propagator filters the lowerbound of z and filters X with a set of rules R.It is worth noticing that no assumption is made on the set of difference constraints D which can thus grow during theresolution process. For instance, D can be modified by the user or other constraints. Note also that, as long as domain unionand intersection operations are defined, no assumption is made about the kind of variables in X . This means Algorithm 2can be used to filter the AtMostNVector constraint [13], a variant of AtMostNValue which holds on continuous vectorvariables instead of integer variables. Indeed, continuous domains are represented by floating intervals, hence union andintersection operations are straightforward. Overall, one can see that this propagator is both flexible and easy to implementand maintain.4. Designing a search heuristic for the SMPTSPThis section describes the search process that is used within our CP approach. It embeds some cost-based reasonings(bottom–up optimisation strategy and tailored value selection), domain reduction reasonings (heuristic symmetry breakingand variable selection) and finally a bit of learning (throught last-conflict [41]).4.1. Optimisation strategyThe classical optimisation strategy of a CP solver consists of enumerating improving solutions. If the search completes,the last solution found is proved to be optimal. This process is known as the top–down approach. However, the filteringof AMNV(cid:13)G|F|R(cid:14) is related to the lower bounding of the problem. Therefore, the lower the objective upper bound, thestronger the filtering. Hence, we naturally employed a bottom–up minimisation strategy. It tries to compute a solutioninvolving k values, where k is initialised to the root lower bound of z and incremented by one each time the solver provesunsatisfiability. Thus, the first solution found is optimal. This is done by simply branching on the objective variable andassigning it its current lower bound.The search heuristic that is used over X is the following: The variable associated with the smallest domain is selectedfirst [32], and then fixed to the first value in its domain that is already assigned to another variable. If no such value exists,then the variable is fixed to its lower bound. Thus, the value selection naturally tends to use few different values. Thisbranching scheme is reinforced by the last-conflict heuristic [41] which aims at identifying critical variables.4.2. When search tries its luckIn [21], we employed a two-step search strategy that first finds a subset of z allowed values and then assign a valueto every decision variable x ∈ X . The first step requires to associate every shift s j ∈ S with a new binary variable y j ∈ Yto tell whether or not the value j must be assigned to a variable in X . However, this approach makes the model heavierbecause of additional variables and channelling constraints. Moreover, branching on Y first might not be appropriate forJ.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133125Fig. 5. Impact of breif , which reifies the constraint maximum(X ) = z.every instance. If so, compelling the search to follow this scheme may decrease performances. Therefore, while keeping thegeneral idea of a two-step search strategy, we now suggest a lighter and more flexible branching scheme.It is worth noticing that if shifts were all equivalent, i.e., if values of assignment variables were all interchangeable, thenthe problem would be polynomial to solve. From a modelling perspective, we could force to use any arbitrary set of zvalues. More precisely, we could use the first z values. Assuming that values are consecutive and start at one, we couldadd the constraint maximum(X ) = z. This symmetry breaking constraint [26] may dramatically reduce the search space.Unfortunately, values are generally not interchangeable, so we cannot post such a hard constraint directly. Nevertheless, itmay occur in some instances that values are nearly interchangeable, in the sense that finding a valid subset of values tobe used is a minor issue compared to finding a valid variable-value assignment. In other words, if zdenotes the optimumvalue, then the problem admits a solution for numerous value subsets of size z. For this reason, we introduce a binaryvariable breif to reify [5] the above symmetry breaking constraint. The search heuristic first fixes breif to 1 in order topropagate this constraint and reduce the search space [20]. In case no solution exists, a backtrack fixes it to 0 and turns theconstraint into its opposite i.e., maximum(X ) (cid:5)= z, so that the approach remains exact. This is a full reification. However, thefiltering of the right branch will be weak, so a half-reification [22] of the constraint maximum(X ) = z would be sufficientto reproduce our approach. Note that the initial set of shifts may be randomly shuffled to handle the case where it isordered in a specific way. One can see this search trick as a way to perform symmetry breaking from search. However, asthe model is unlikely to contain such symmetries, it is rather a heuristic gamble. More precisely, there aredifferentvalue sets of the size of the optimal value. Let K be the number of different value sets that belong to at least one optimal∗} to belong to an optimal solution is thereforesolution. We have 0 ≤ K ≤P (breif = 1) = K(cid:3)|S|. The probability of the value set {1, 2, ..., z(cid:3)|S|z∗(cid:3)|S|z∗(cid:4) .(cid:4)(cid:4)∗∗To illustrate the use of breif we now apply it on our running example, with d(z) = {3} (the optimum) in Fig. 5. Forthe sake of clarity, the shift set of the example has not been shuffled, hence a value i ∈ [1, 5] corresponds to the shift si .However, in practice, we randomly shuffle the initial shift set to reduce bias, so values 1, 2 and 3 might refer to shifts s2,is set to 1, the constraint maximum(X ) = z leads to remove values 4 and 5 from Xs4 and s5 for instance. When breifdomains. This is a lucky guess, because optimal solutions use the value sets {1, 2, 3} and {1, 3, 4}, i.e., K = 2. Therefore, theconstraint maximum(X ) = z has a probability to hold on optimal solutions of(cid:4) = 0.2. This illustrates why it has to be∗z2(cid:3)53reified.5. Experimental studyIn order to evaluate the interest of our contribution, we perform extensive tests. First, Section 5.1 introduces and mo-tivates a new benchmark data set for the SMPTSP. Next, in Section 5.2, we focus on the objective lower bound quality atroot node. Section 5.3 highlights the potential benefit of strengthening and diversifying the filtering. Section 5.4 investigatesthe interest of adding the reification of a symmetry breaking constraint. Section 5.5 focuses on the scalability issue, i.e., itevaluates the ability of our approach to compute tight bounds, even on large instances. Finally, in Section 5.6 we compareour approach to the best known results on the state-of-the-art SMPTSP instances.Our algorithms have been implemented in JAVA, we have used Choco 3-1-1 [14] to implement CP model and Cplex 12.4with default settings to implement MIP model. Note that we have used the automatic tunning tool of Cplex to get the bestsetting, which turned out to be the default one. All our implementations are available online at [40]. In the following werespectively note zand zr the optimal objective and the objective lower bound at root node. Finally, a CP model using apropagator AMNV(cid:13)G|F|R(cid:14), is noted ↓AMNV(cid:13)G|F|R(cid:14) when used within a top–down minimisation strategy and ↑AMNV(cid:13)G|F|R(cid:14)when used within a bottom–up minimisation strategy.∗5.1. A new set of challenging SMPTSP instancesVery recently, Smet et al. have shown in [56] that the 137 instances provided by Krishnamoorthy and Ernst in [37] admita feasible solution with an objective value equal to LB(cid:5)=. Since worker skills are taken into account in [37], this result issomehow surprising: One may expect that considering worker skills would have an impact on the optimum, but actually, it126J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133Fig. 6. Comparison of instance input and output characteristics.Fig. 7. Homogeneity of shifts (measured with quartiles) depending on instances, sorted by increasing number of tasks. dH: normalised Hamming distance.only makes it harder to find a feasible solution. Consequently, these instances do not provide much challenge regarding tothe search of interesting lower bounds. Therefore, we propose a new set of challenging instances whose maximal numberof overlapping tasks does not provide a good lower bound.In order to generate this new benchmark we use a dedicated procedure based on some of the empirical results presentedin [37] and [56]. First of all, it is specified in [37] that the average tightness, defined as the sum of processing times over thesum of shift lengths should be close to 90% in order to obtain challenging instances. Another hardness analysis [56] showsthat the smaller the average task processing time, the more difficult instances are to solve. Based on these two conclusions,we designed a dedicated procedure able to generate a new set of challenging instances. The procedure which is given indetails in [40] generates randomly a set of tasks ranging from 15 minutes to 2 hours. We consider random skills and sixdifferent time windows to generate shifts. The first three aim at splitting a working day into 8 hours time intervals, which isvery common in personnel scheduling [57]. The other three are obtained from the previous ones by introducing an offset totheir starting time, so that each task is entirely contained in at least one time interval. Based on this simple procedure, weprovide 100 new instances with a number of tasks ranging from 70 to 1600 and a number of available shifts ranging from60 to 950. These instances along with our generator are available online [40]. In the following, we refer to the instances ofKrishnamoorthy et al. as Data_137, and our generated instances as Data_100. In order to apprehend the differences betweenData_137 and Data_100, we now provide some comparisons between those two data sets.|S||T | and z|T | on every instance (represented as a mark) in Fig. 6. Both |S| and |T | areis known (or at least well approximated) after resolution. This enables to highlight both input andinput data, whereas zoutput characteristics of these instances. As can be seen, the two instance sets form two disjoint clusters. It is interestingto notice that instances of the same data set can then be split into sub-clusters, revealing some patterns in their generator.The main difference between the two data sets is related to z|T | , which has an average value of 39% and 83%, respectively|S||T | is 2.2 times bigger in Data_100 than in Data_137. Thus, Data_100for Data_100 and Data_137. Regarding input data only,instances have on average more available shifts per task than Data_137, but they use a significantly smaller percentageof these shifts in optimal solutions. Therefore, finding a shift set which corresponds to an optimal solution may be moredifficult.As a first step, we show the ratios∗∗∗As a second step, we investigate the homogeneity of shifts. In order to evaluate this characteristic, we use a normalisedHamming distance: Given an instance i, the distance dH(s1, s2) between two shifts s1 and s2 is equal to the number of tasksthat belong to one and only one of the shifts, divided by the total number of tasks within i. To measure the homogeneity ofshifts we compute this distance for every pair of shifts in all instances. The analysis of these data relies then on the use ofquartiles. As illustrated in Fig. 7, it turned out that the median distance between shifts is on average relatively similar fromData_137 (44.5%) to Data_100 (46.6%). However, the first and third quartiles of this distance are on average quite differentfrom one data set to another: Many shifts in Data_100 are either very similar or quite different, whereas shifts in Data_137are always a bit different. This difference of homogeneity mainly comes from the use of 8 hours shifts within Data_100:J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133127Fig. 8. Ratio|ECI ||EI | of all instances, sorted by increasing number of tasks.Fig. 9. Impact of GCI on zr . Instances are sorted by increasing value of LB(cid:5)=.Shifts that belong to the same time interval are relatively close whereas shifts that belong to different time intervals arecompletely different.5.2. Impact of GCI on root nodeBasically, using GCI instead of GI aims at reducing the number of edges to obtain larger independent sets, hence a|ECI |better filtering. As a first step to measure the interest of GCI , we evaluate the ratio|EI | . On Data_137, this ratio rangesbetween 35% and 85% with a mean value of 65%. On Data_ 100, the trend is different since the minimum and the maximumratio are respectively 67% and 75%, with a mean value of 71%. Note also that this ratio tends to increase on Data_137,whereas it is constant on Data_100. These differences surely come from the strengthened structure of Data_100 comparedto Data_137. Overall, GCI has significantly less edges than GI . (See Fig. 8.)We then compare the value of the root lower bound, zr , obtained with AMNV(cid:13)GCI |MD|R1(cid:14) and AMNV(cid:13)GI |MD|R1(cid:14), onboth data sets. LB(cid:5)= is used as a baseline comparison. Results are reported on Fig. 9. The horizontal axis represents instances,sorted by increasing value of LB(cid:5)=. On both data sets, using AMNV(cid:13)GCI |MD|R1(cid:14) instead of AMNV(cid:13)GI |MD|R1(cid:14) dramaticallyimproves the value of zr . On Data_137, the use of GCI allows to get a relative gap between LB(cid:5)= and zr of about 6%. As LB(cid:5)=. On Data_100, the use of GCI allows to getis always equal to zvalues of zr that are more than twice LB(cid:5)=. On both data sets, our approach scales much better than the classical one whichis not able to increase zr whatever the size of the instance. More precisely the lower bound given by AMNV(cid:13)GI |MD|R1(cid:14)turns around 1 (respectively 6), which corresponds to the different time windows on Data_137 (respectively Data_100).Actually, this is not really surprising since AMNV(cid:13)GI |MD|R1(cid:14) is blind to AllDifferent constraints, which represent a bigpart of the problem. Using GCI instead of GI makes these AllDifferent constraints visible to AtMostNValue, hencethe increased of zr .on Data_137, this means that zr is already very close to z∗∗5.3. Managing the tradeoff between filtering and runtimeAs explained in Section 3.4, using the algorithm Rk is a simple and effective way to obtain diversification in filtering.The parameter k enables to manage the tradeoff between expected filtering power and runtime. Since Rk is suggested asa complement to MD, it must be seen as an improvement opportunity. Back to our case, many values of k, together withvarious filtering rules have been tested, within a time limit of 5 minutes. Within these experiments, the search heuristicdoes not branch on breif , which will be evaluated in the next section.128J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133Fig. 10. Number of optima proved depending on k for several filtering configurations, with a time limit of 5 minutes.Impact of AMNVback-propagationIn order to evaluate the influence of the back-propagation of AMNV on performances, we compare the number of optimaproved by CP model with filtering rules R1, R1,2 and R1,3 (Fig. 10). R1,2 introduces a slight overhead compared to R1 only,without providing much more domain reductions. Thus, R1 is generally more efficient than R1,2 on Data_137. Instead, R3has a strong impact on Data_137: It enables to solve 26 more instances within the time limit. Note that a minimum numberof iterations is required before R3 brings a significant improvement. However, results are more qualified on Data_100.Overall, R3 is worth the overhead. Thus, the interest of Rk not only lies in finding larger independent sets (R1), but also indiversifying the filtering (R3).Interestingly, the best setting for k changes quite a lot from one data set to another, hence using an automatic algorithmconfiguration program [33] seems relevant to get the best results. About Data_137, a few dozens of iterations enable toenhance performances, with a best value for k around 120. On the contrary, hundreds and even thousands of iterationsare required to solve Data_100 instances. In particular, performing 5000 iterations on Data_100 is still much better thanperforming none. This means that the benefit of Rk is absolutely worth the induced overhead. The optimal setting seemsto be around 2000. Note that within 5 minutes, the best configuration of CP model is able to solve around 80% of Data_137,compared to only half of Data_100.Impact of AllDifferentpropagationIn this section, we investigate the interest of R4. As explained in Section 3.5, this rule is not relevant to the SMPTSP,because all maximal AllDifferent constraints are already known. Nevertheless, it may be worthwhile when disequalitiesappear dynamically. To get insight into the behaviour of R4, while preserving the SMPTSP as an illustration, we remove allthe AllDifferent constraints of CP model and replace them by cliques of binary disequalities (suffixed with a). Thisenables to measure the filtering ability stemming from R4, which only makes sense if maximal AllDifferent constraintsare not in the original model.∗Thus, the semantic of the problem remains the same while the global view of the AllDifferent constraints is lost.Note that, we no longer use LB(cid:5)= as an initial lower bound, because it corresponds to the size of the largest AllDifferentconstraint. Given this new model, we compare the number of optima respectively proved by ↑AMNV(cid:13)GCI |MD,Rk|R1,3(cid:14)∗and↑AMNV(cid:13)GCI |MD,Rk|R1,3,4(cid:14)∗, for different values of k, after a resolution of 5 minutes (Fig. 11). As justified in Section 3.5,R4 calls the AllDifferent BC filtering algorithm on every independent set.As a baseline comparison, we also display the results of ↑AMNV(cid:13)GCI |MD,Rk|R1,3(cid:14), which includes AllDifferentconstraints.2 Therefore, Fig. 11 enables to evaluate the role of R4 when AllDifferent constraints are not given, but alsoto compare the good propagation of AllDifferent constraints with the naive propagation of binary disequalities.Two main observations can be made on Data_137 results. First, the good propagation of AllDifferent constraintsonly makes a difference once the AMNV filtering is strong enough, i.e., when k > 0. For instance, with k = 120, it enablesto find 118 optima, whereas ↑AMNV(cid:13)GCI |MD,Rk|R1,3(cid:14)∗respectively solve 101 and 99instances to optimality. Second, R4 has a low impact on results. A slight improvement can be noticed for small k values,but this trend reverses when k increases. This means R4 is unfortunately not able to get back the good tradeoff betweenfiltering and runtime of the original model, which has AllDifferent constraints in it.and ↑AMNV(cid:13)GCI |MD,Rk|R1,3,4(cid:14)∗Surprisingly, with k < 1000, R4 leads to even better results than the original model on Data_100. It provides a bettertradeoff between filtering and runtime. However, increasing k even more introduces a strong overhead. Interestingly, itcan be seen that ↑AMNV(cid:13)GCI |MD, Rk|R1,3(cid:14) and ↑AMNV(cid:13)GCI |MD, Rk|R1,3(cid:14)∗lead to very similar results. This means thatachieving a high level of consistency over AllDifferent constraints or simply propagating binary disequalities does not2 The default implementation of AllDifferent in Choco 3-1-1 performs an ad hoc compromise between BC and GAC, in order to provide a goodtradeoff between filtering and runtime.J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133129Fig. 11. Impact of R4 on the number of optima proved, depending on k. Note that LB(cid:5)= is no longer used as an initial lower bound for z.Fig. 12. Number of optima proved by ↑AMNV(cid:13)GCI |MD, Rk|R1,3(cid:14) within a 5 minutes time limit, for various k settings, with and without breif .really matter on this data set. The difficulty of such instances mainly stems in the lower bounding of the problem. Perhapsthe AMNV propagation must be improved before AllDifferent constraint propagations play a key role.5.4. Impact of branching on breifWe now evaluate the interest of branching on breif (Fig. 12), as suggested in Section 4. This binary variable reifies theconstraint maximum(X ) = z, which breaks symmetries arising from the case where all shifts are equivalent. We mentionthat no instance satisfies such an assumption. Hence, branching on breif is a totally heuristic choice, aiming at reducing thesearch space. Results show that breif is very well suited to Data_137. It enables to solve 136 instances in less than 5 minutes(with k = 20). This may come from the z|S| ratio and the homogeneous repartition of task-shift compatibilities: Any setof zshifts is very likely to cover all tasks. Nevertheless, it is worth mentioning that, on this data set, no two shifts areidentical. Unfortunately, breif does not help solving Data_100 instances, which have more structure in the design of shifts,to the contrary. We observe a slight performance loss. Note that the possibility to use constraint reification within search isa powerful feature of CP.∗∗5.5. Scalability studyWe now evaluate the ability of our approach to provide good bounds even on large scale instances. For that, we evaluatethe relative gap (z–z)/z depending on the running model. Both MIP model and CP model are run with a time limit of6 minutes. Default values for z and z are respectively 0 and |S|, i.e., LB(cid:5)= is not used. Therefore, a run which times outwithout computing any bound leads to a relative gap of 100%. In order to get tight bounds, CP model is first run 3 minutesin a bottom–up approach to compute a good lower bound and then, if no optimum has been found, 3 other minutes in atop–down mode to get a good upper bound. Given the size of the instances, finding a feasible solution may be difficult. Asthe AtMostNValue propagation relies on lower bounding, we can expect a strong propagation during the bottom–up step.This is no longer expectable in a top–down approach, for which the faster propagation the better. Therefore, the filteringof ↓AMNV(cid:13)GCI |MD,Rk|R1,3(cid:14) is lightened by setting k to 0. Furthermore, as enforcing maximum(X ) = z removes feasiblesolutions, breif is set to 0 as well.130J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133Fig. 13. Relative gap between z and z depending on the running model, on Data_137 and Data_100, after a 6 minutes resolution. Instances are sorted byincreasing number of tasks.Fig. 13 gives general trends regarding the ability to scale of MIP model and CP model. It shows that MIP model fails tosolve about half of instances on both data sets: It is not able to provide either lower bounds or upper bounds (100% gap).On Data_137, there are 12 instances for which it is able to compute a lower bound, but no upper bound (70%–95% gap).This indicates that embedding the linear relaxation of the problem within a global constraint is not promising at all onthese large scale instances. Regarding this scalability issue, the top–down and bottom–up CP approaches perform very well.The relative gap is on average 0.1% and 1.4%, with a maximum of 2.9% and 5.7%, for respectively Data_137 and Data_100.Thus, the relative gap does not increase much with the instance size. Consequently, using ↑AMNV(cid:13)GCI |MD,Rk|R1,3(cid:14) and↓AMNV(cid:13)GCI |MD|R1,3(cid:14) leads to finding tight bounds for z, even on large instances. This makes CP model a more reliableapproach than MIP model to bound the objective in a short time.5.6. A competitive approachIn order to estimate the quality of our approach, we now compare it to the state-of-the-art SMPTSP approaches, on in-stances of the literature (Data_137). The first two SMPTSP approaches were given by Krishnamoorthy et al., who introducedboth MIP model and a dedicated metaheuristic [36]. Next, Smet et al. provided a metaheuristic based on a local branchingimprovement heuristic [56]. Finally, and very recently, Lin and Ying proposed a three-phase exact approach [43]: The firstphase builds an initial solution with a constructive heuristic, the second one improves it with an iterated greedy algorithm,and the third one solves MIP model, initialized with the best solution found.We compare the performances of CP model with existing approaches. This comparison is based on their ability to reachan optimal solution in a short time. For CP model, we used ↑AMNV(cid:13)GCI |MD,R40|R1,3(cid:14), the best configuration on Data_137.Regarding the results of [43], it occurs that their last phase times out on instances for which the input solution (computedin phases one and two) is optimal. Presumably, they were not aware that LB(cid:5)= is optimal on Data_137, which was firstpointed out by Smet et al. Therefore, to have a fair evaluation of their method, we consider that it stops whenever one ofthe three phases has found an optimal solution. This slightly shorten the running time of [43].As illustrated in Fig. 14, both CP model and [56] dominate other approaches. They are comparable in the sense that theyboth find all optimal solutions within the given time limit. Nevertheless, [56] focuses on finding good solutions and its onlylower bounding procedure is LB(cid:5)=. Therefore, this approach is not able to prove optimality in general, whereas CP model isable to provide optimality certificates. We point out that the results of CP model are better than those presented in [21].This comes from slight code refactoring along with the use of breif (see Section 4).As the SMPTSP often occurs as a subproblem of a more general method, it seems critical to provide a good lower boundin a short time. To evaluate the capacity of ↑AMNV(cid:13)GCI |MD,Rk|R1,3(cid:14) to provide quickly a good value of z, we compare zrand its required runtime with those of the lower bounding procedure given in [36]. This procedure is based on a Lagrangianrelaxation, therefore, we refer to its lower bound as zL. For a full resolution, ↑AMNV(cid:13)GCI |MD,R40|R1,3(cid:14) gives the bestresults on Data_137. However, if the purpose is to design an effective lower bounding procedure, it may be interesting touse a much higher value of k, which may reduce the gap to optimality with a small overhead. Consequently, we compare zLr when obtained with k = 40with zr for two different settings of k: 40 and 1000. To ease the reading, zr will be noted z40when obtained with k = 1000. To have a fair comparison, we do not use LB(cid:5)= in our model, since it gives theand z1000optimal value on the state-of-the-art instances.rJ.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133131Fig. 14. Cumulated number of optima found, depending on runtime, on Data_137.Fig. 15. Relative gap between z and zbecause it is equal to zon every instance.∗∗depending on the running model, on Data_137 instances, sorted by increasing task number. z1000ris not displayedFig. 16. Runtime (in seconds) to compute z, depending on the running model.rr and z1000are much closer to zAs illustrated in Fig. 15, z40and z40r(2.26%) is also betteris on average more than ten times closer to zthan the one of zL (10.17%). Finally, as illustrated by Fig. 16, the runtime of z40are much smaller than the onerof zL: The average runtime of z40turns around half a second compared to more than one hundred seconds for zL. Noterthat the average runtime of z1000is less than twice as big as the one of z40, which highlights the interest of increasing krwhen searching a good lower bound. On the whole, the root node provided by ↑AMNV(cid:13)GCI |MD,Rk|R1,3(cid:14) is very close tothe optimum, and it can be computed quickly, even on large scale instances.than zL. Moreover, the empirical worst-case gap of z40rthan zL. More precisely, z1000is always equal to zand z1000r∗rr∗∗6. ConclusionsIn this paper, we have introduced a CP approach to solve the SMPTSP, along with a new set of challenging instances. Thismodel outperforms previous exact approaches on state-of-the-art benchmarks. Furthermore, it provides very good lower andupper bounds, even on large instances, in a short time. Thus, the CP approach competes with both exact and metaheuristicstate-of-the-art approaches.Furthermore, we have provided the notation AMNV(cid:13)G|F |R(cid:14), to describe a family of AtMostNValue propagators. In par-ticular, we introduced a new propagator, AMNV(cid:13)GCI |MD,Rk|R1,3(cid:14), to filter the conjunction of an AtMostNValue constraint132J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133and disequalities. This propagator keeps close to the existing AtMostNValue propagator because it is fast to propagate, butalso to capitalise over previous work in order to reduce implementation and maintenance issues. AMNV(cid:13)GCI |MD,Rk|R1,3(cid:14)relies on a more appropriate graph structure (GCI ), as well as refined filtering rules (R3), and a simple way to diversifyfiltering (Rk), in order to improve the overall approach. Moreover, this propagator gives control over the tradeoff betweenfiltering and runtime. As it is simple to implement, effective and relevant for many applications, we believe that this prop-agator would benefit the CP community.Nevertheless, the maximum independent set is not a tight relaxation for AtMostNValue, and there are several leadsto achieve a stronger filtering. One of these is the Lovász number [45], a real number introduced in Graph Theory asan upper bound over the Shannon capacity of a graph. Lovász’s sandwich theorem indicates that the Lovász number ofGCI provides a valid lower bound over the number of distinct values to be taken by X , which is greater or equal to themaximum independent set relaxation. This number can be approximated with Semi Definite Programming (SDP) solvers(e.g. [8,11]), which are unfortunately not yet fast enough to allow an integration into a global constraint. Therefore, futureimprovement in SDP may have a positive impact on CP applications related to the SMPTSP. Another research perspectivewould be to investigate the application of this propagator in the context of dynamic difference constraints, which occurs inmany disjunctive scheduling problems.Finally, we introduced an original way to enhance search by introducing and reifying a global constraint. The successof this dedicated and naive attempt draw new perspectives regarding search heuristics. We believe this concept may begeneralised toward new black-box search strategies [9,46,49], based on global constraint reification. This may reduce theneed of designing dedicated search procedures [53], which still restricts the diffusion of CP. Past work on both symmetrybreaking [26] and global constraint learning [6] may be a good lead.AcknowledgementsThe authors thank the anonymous referees as well as Samuel Burer, Xavier Lorca, Thierry Petit, Damien Prot and CharlesPrud’Homme for their useful comments. This work has been funded by the regional council of Pays de la Loire and theCNRS.References[1] G. Andreello, A. Caprara, M. Fischetti, Embedding {0, 1/2}-cuts in a branch-and-cut framework: a computational study, INFORMS J. Comput. 19 (2)(2007) 229–238.[2] S. Asaf, H. Eran, Y. Richter, D.P. Connors, D.L. Gresh, J. Ortega, M.J. Mcinnis, Applying constraint programming to identification and assignment of serviceprofessionals, in: CP, in: Lecture Notes in Computer Science, vol. 6308, Springer, 2010, pp. 24–37.[3] N. Beldiceanu, Pruning for the minimum constraint family and for the number of distinct values constraint family, in: CP, in: Lecture Notes in ComputerScience, vol. 2239, Springer, 2001, pp. 211–224.[4] N. Beldiceanu, M. Carlsson, S. Demassey, T. Petit, Global constraint catalogue: past, present and future, Constraints 12 (1) (2007) 21–62.[5] N. Beldiceanu, M. Carlsson, P. Flener, J. Pearson, On the reification of global constraints, Constraints 18 (1) (2013) 1–6.[6] N. Beldiceanu, H. Simonis, A constraint seeker: finding and ranking global constraints from examples, in: CP, in: Lecture Notes in Computer Science,vol. 6876, Springer, 2011, pp. 12–26.[7] C. Bessière, E. Hebrard, B. Hnich, Z. Kiziltan, T. Walsh, Filtering algorithms for the NValue constraint, Constraints 11 (4) (2006) 271–293.[8] B. Borchers, Csdp, a c library for semidefinite programming, Optim. Methods Softw. 11 (1–4) (1999) 613–623.[9] F. Boussemart, F. Hemery, C. Lecoutre, L. Sais, Boosting systematic search by weighting constraints, in: European Conference on Artificial Intelligence,2004, pp. 146–150.[10] Bron, Coen, Kerbosch, Joep, Algorithm 457: finding all cliques of an undirected graph, Commun. ACM 16 (9) (1973) 575–577.[11] S. Burer, R.D.C. Monteiro, A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization, Math. Program. 95 (2)(2003) 329–357.[12] M.W. Carter, C.A. Tovey, When is the classroom assignment problem hard? Oper. Res. 40 (1) (1992) 28–39.[13] G. Chabert, L. Jaulin, X. Lorca, A constraint on the number of distinct vectors with application to localization, in: CP, in: Lecture Notes in ComputerScience, vol. 5732, Springer, 2009, pp. 196–210.[14] CHOCO Team, Choco: an open source Java constraint programming library, Tech. Rep., Ecole des Mines de Nantes, 2010, http://www.emn.fr/z-info/choco-solver/.[15] R. Debruyne, C. Bessière, Some practicable filtering techniques for the constraint satisfaction problem, in: Proceedings of the 15th International JointConference on Artificial Intelligence, IJCAI’97, Morgan Kaufmann Publishers Inc., 1997, pp. 412–417.[16] M.C. Dijkstra, L.G. Kroon, M. Salomon, J.A.E.E. Van Nunen, L.N. van Wassenhove, Planning the size and organization of KLM’s aircraft maintenancepersonnel, Interfaces 24 (6) (1994) 47–58.[17] D. Dowling, M. Krishnamoorthy, H. Mackenzie, D. Sier, Staff rostering at a large international airport, Ann. Oper. Res. 72 (1997) 125–147.[18] P. Erd ˝os, A. Rubin, H. Taylor, Choosability in graphs, in: Proceedings of the West Coast Conference on Combinatorics, Graph Theory and Computing, in:Congres., vol. 26, 1979, pp. 125–157.[19] A.T. Ernst, H. Jiang, M. Krishnamoorthy, D. Sier, Staff scheduling and rostering: a review of applications, methods and models, Eur. J. Oper. Res. 153 (1)(2004) 3–27.[20] F. Fages, On the use of constraint reification within search, 2013, personal communication.[21] J.G. Fages, T. Lapègue, Filtering atmostnvalue with difference constraints: application to the shift minimisation personnel task scheduling problem, in:CP, in: Lecture Notes in Computer Science, vol. 8124, Springer, 2013, pp. 63–79.[22] T. Feydy, Z. Somogyi, P.J. Stuckey, Half reification and flattening, in: CP, in: Lecture Notes in Computer Science, vol. 6876, Springer, 2011, pp. 286–301.[23] M. Fischetti, S. Martello, P. Toth, The fixed job schedule problem with spread-time constraints, Oper. Res. 35 (6) (1987) 849–858.[24] M. Fischetti, S. Martello, P. Toth, The fixed job schedule problem with working-time constraints, Oper. Res. 37 (3) (1989) 395–403.[25] B. Flavia, D. Guillermo, M. Javier, Exploring the complexity boundary between coloring and list-coloring, Electron. Notes Discrete Math. 25 (2006)41–47.J.-G. Fages, T. Lapègue / Artificial Intelligence 212 (2014) 116–133133[26] P. Flener, J. Pearson, M. Sellmann, P.V. Hentenryck, M. Ågren, Dynamic structural symmetry breaking for constraint satisfaction problems, Constraints14 (4) (2009) 506–538.[27] M.R. Garey, D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-Completeness, W.H. Freeman, 1979.[28] M.C. Golumbic, Algorithmic Graph Theory and Perfect Graphs, 2nd edn, Ann. Discrete Math., vol. 57, Elsevier, 2004.[29] M. Gondran, M. Minoux, S. Vajda, Graphs and Algorithms, John Wiley & Sons, Inc., New York, NY, USA, 1984.[30] S. Gualandi, F. Malucelli, Exact solution of graph coloring problems via constraint programming and column generation, INFORMS J. Comput. 24 (2012)81–100.[31] M.M. Halldórsson, J. Radhakrishnan, Greed is good: approximating independent sets in sparse and bounded-degree graphs, Algorithmica 18 (1) (1997)145–163.[32] R.M. Haralick, G.L. Elliott, Increasing tree search efficiency for constraint satisfaction problems, in: Proceedings of the 6th International Joint Conferenceon Artificial Intelligence, IJCAI’79, vol. 1, Morgan Kaufmann Publishers Inc., 1979, pp. 356–364.[33] S. Kadioglu, Y. Malitsky, M. Sellmann, K. Tierney, Isac – instance-specific algorithm configuration, in: ECAI, in: Frontiers in Artificial Intelligence andApplications, vol. 215, IOS Press, 2010, pp. 751–756.[34] A.W.J. Kolen, J.K. Lenstra, C.H. Papadimitriou, F.C.R. Spieksma, Interval scheduling: a survey, Nav. Res. Logist. 54 (2007) 530–543.[35] M.Y. Kovalyov, C.T. Ng, T.C.E. Cheng, Fixed interval scheduling: models, applications, computational complexity and algorithms, Eur. J. Oper. Res. 178(2007) 331–342.[36] M. Krishnamoorthy, A. Ernst, D. Baatar, Algorithms for large scale shift minimisation personnel task scheduling problems, Eur. J. Oper. Res. 219 (2012)34–48.[37] M. Krishnamoorthy, A. Ernst, The personnel task scheduling problem, in: X. Yang, K. Teo, L. Caccetta (Eds.), Optimization Methods and Applications, in:Applied Optimization, vol. 52, Springer, US, 2001, pp. 343–368.[38] L.G. Kroon, M. Salomon, L.N.V. Wassenhove, Exact and approximation algorithms for the tactical fixed interval scheduling problem, Oper. Res. 45 (4)(1997).[39] C. Kuip, Public remark at workshop “CP solvers: modeling, applications, integration, and standartization”, in: 19th International Conference on Princi-ples and Practice of Constraint Programming, 2013.[40] T. Lapègue, J.G. Fages, D. Prot, O. Bellenguez-Morineau, Personnel task scheduling problem library, https://sites.google.com/site/ptsplib/smptsp/home,2013.[41] C. Lecoutre, L. Sais, S. Tabary, V. Vidal, Reasoning from last conflict(s) in constraint programming, Artif. Intell. 173 (18) (2009) 1592–1614.[42] R. Leone, P. Festa, E. Marchitto, A bus driver scheduling problem: a new mathematical model and a GRASP approximate solution, J. Heuristics 17 (4)(2010) 441–466.[43] S.W. Lin, K.C. Ying, Minimizing shifts for personnel task scheduling problems: a three-phase algorithm, Eur. J. Oper. Res. (2014).[44] A. López-Ortiz, C.G. Quimper, J. Tromp, P. van Beek, A fast and simple algorithm for bounds consistency of the alldifferent constraint, in: IJCAI, MorganKaufmann, 2003, pp. 245–250.[45] L. Lovász, On the Shannon capacity of a graph, IEEE Trans. Inf. Theory 25 (1) (1979) 1–7.[46] L. Michel, P. Van Hentenryck, Activity-based search for black-box constraint programming solvers, in: CPAIOR, 2012, pp. 228–243.[47] J.N. Monette, P. Flener, J. Pearson, Towards solver-independent propagators, in: CP, in: Lecture Notes in Computer Science, vol. 7514, Springer, 2012,pp. 544–560.[48] F. Pachet, P. Roy, Automatic generation of music programs, in: CP, 1999, pp. 331–345.[49] P. Refalo, Impact-based search strategies for constraint programming, in: Principles and Practice of Constraint Programming, 2004, pp. 557–571.[50] J.C. Régin, A filtering algorithm for constraints of difference in CSPs, in: National Conference on Artificial Intelligence, AAAI, 1994, pp. 362–367.[51] Y. Richter, A. Freund, Y. Naveh, Generalizing alldifferent: the somedifferent constraint, in: CP, in: Lecture Notes in Computer Science, vol. 4204, Springer,2006, pp. 468–483.[52] F. Rossi, P. van Beek, T. Walsh (Eds.), Handbook of Constraint Programming, Elsevier, 2006.[53] T. Schrijvers, G. Tack, P. Wuille, H. Samulowitz, P.J. Stuckey, Search combinators,in: Principles and Practice of Constraint Programming, 2011,pp. 774–788.[54] C. Schulte, P.J. Stuckey, Efficient constraint propagation engines, ACM Trans. Program. Lang. Syst. 31 (1) (2008).[55] C. Schulte, G. Tack, Weakly monotonic propagators, in: Principles and Practice of Constraint Programming, 2009, pp. 723–730.[56] P. Smet, T. Wauters, M. Mihaylow, G. Vanden Berghe, The shift minimisation personnel task scheduling problem: a new hybrid approach and compu-tational insights, Technical Report, University of North Carolina, 2013.[57] J. Van den Bergh, J. Beliën, P. De Bruecker, E. Demeulemeester, L. De Boeck, Personnel scheduling: a literature review, Eur. J. Oper. Res. 226 (3) (2013)367–385.