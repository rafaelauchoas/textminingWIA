Artificial Intelligence 196 (2013) 106–142Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAutomatic behavior composition synthesisGiuseppe De Giacomo a, Fabio Patrizi a, Sebastian Sardiña b,∗a Dipartimento di Informatica e Sistemistica, Sapienza Università di Roma, Rome, Italyb School of Computer Science and IT, RMIT University, Melbourne, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 9 February 2011Received in revised form 28 November 2012Accepted 13 December 2012Available online 2 January 2013Keywords:Knowledge representation and reasoningIntelligent agentsReasoning about actions and changeAutomated planningSynthesis of reactive systemsThe behavior composition problem amounts to realizing a virtual desired module (e.g.,a surveillance agent system) by suitably coordinating (and re-purposing) the execution of aset of available modules (e.g., a video camera, vacuum cleaner, a robot, etc.). In particular,we investigate techniques to synthesize a controller implementing a fully controllable tar-get behavior by suitably coordinating available partially controllable behaviors that are toexecute within a shared, fully observable, but partially predictable (i.e., non-deterministic),environment. Both behaviors and environment are represented as arbitrary finite state tran-sition systems. The technique we propose is directly based on the idea that the controllerjob is to coordinate the concurrent execution of the available behaviors so as to “mimic”the target behavior. To this end, we exploit a variant of the formal notion of simulationto formally capture the notion of “mimicking”, and we show that the technique proposedis sound and complete, optimal with respect to computational complexity, and robust fordifferent kind of system failures. In addition, we demonstrate that the technique is wellsuited for highly efficient implementation based on synthesis by model checking technolo-gies, by relating the problem to that of finding a winning strategy in a special safety gameand explaining how to actually solve it using an existing verification tool.© 2013 Elsevier B.V. All rights reserved.1. IntroductionIn this paper, we provide a thorough investigation—from theory to implementation—of the behavior composition prob-lem, that is, the problem of how to realize an abstract desired target behavior module by reusing and re-purposing a setof accessible modules implementing certain concrete behaviors. More concretely, we are interested in synthesizing a sort ofcontroller that coordinates the available existing behaviors in order to replicate a given desired target behavior [30,79,80].Generally speaking, a behavior stands for the logic of any artifact that is able to operate in the environment, such as devices,agents, software or hardware components, or workflows. For example, consider a painting blocks world scenario in whichblocks are painted and processed by different robotic arms; different behaviors stand for different types of arms (e.g., a grip-per, a painting arm, a cleaner arm, etc.), all acting in the same environment. The aim is to realize a desired (intelligent)virtual painting system by suitably “combining” the available arms.Behavior composition is of particular interest in agents and multi-agent settings. A (desired) intelligent system maybe built, for example, from a variety of existing different modules operating (that is, performing actions) on a commonenvironment and whose logic is only partially known. These modules may, in turn, be other agents themselves. A set ofRoboCup players with different capabilities can be put together to form an (abstract) more sophisticated “team” player. Sim-ilarly, a BDI (Belief–Desire–Intention) agent may implement a desired deterministic plan (which was probably obtained via* Corresponding author.E-mail addresses: degiacomo@dis.uniroma1.it (G. De Giacomo), patrizi@dis.uniroma1.it (F. Patrizi), sebastian.sardina@rmit.edu.au (S. Sardiña).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.12.001G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142107planning or agent communication) by appealing to the set of available user pre-defined non-deterministic plans [36,75]. Inrobot ecologies and ambient intelligence, advanced functionalities, such as a home surveillance agent, are achieved throughthe composition of many simple robotic devices, such as a vacuum cleaner, a lamp, or a video camera [76,17].Our work is really a form of process synthesis as studied in Computer Science [70,1,89,51]. However, while most litera-ture on synthesis concentrates on synthesizing a process satisfying a certain specification from scratch, behavior compositionfocuses on synthesizing a process (the controller) starting from available components [54]. This idea of composing andreusing components has been strongly put forward by Service Oriented Computing, under the name of “service com-position” [2,42,63,86]. Indeed, service composition aims at composing complex services by orchestrating (i.e., controllingand coordinating) services that are already at disposal. When service composition takes into account the behavior of thecomponent service, as in [20,84,16] for instance, it becomes intimately related to what we call here “behavior composi-tion”.When we look at behavior composition from an Artificial Intelligence perspective, the issue of actual controllability ofthe available behaviors becomes prominent. While one can instruct a behavior module to carry out an action, the actualoutcome of the action may not always be foreseen a priori, though it can possibly be observed after execution. Our workhere is based on revisiting a certain stream of work in service composition [13–15], called “Roman Model” in [42,86], butkeeping the need of dealing with partial controllability central. In particular, we consider the problem of synthesizing a fullycontrollable target behavior from a library of available partially controllable behaviors that are to execute within a shared,fully observable, but partially predictable environment [30,79].Technically, we abstract behaviors and the environment as finite state transition systems. More precisely, each availablemodule is represented as a non-deterministic transition system (to model partial controllability); the target behavior isrepresented as a deterministic transition system (to model full controllability); and the environment is represented as anon-deterministic transition system (to model partial predictability). The environment’s states are fully accessible by theother transition systems. Working with finite state transition systems allows us to leverage on research in Verification andSynthesis in Computer Science [69,87,50,3,23].Once we settle for a formal specification of the problem of concern, we develop a novel sound and complete, and optimalw.r.t. worst-case computational complexity technique to generate so-called compositions. The technique is directly based onthe idea that a composition amounts to a controller that coordinates the concurrent execution of the available modulesso as to “mimic” the desired target behavior. We capture “mimicking” through the formal notion of simulation [60,41].Obviously, we need to consider that available behaviors as well as the environment are only partially controllable (i.e.,non-deterministic), and therefore a special variant of the classical notion of simulation ought to be devised.The proposed technique has several interesting features:• The technique is sound and complete, in a very strong sense: it allows to synthesize a sort of meta-controller, calledcontroller generator, that represents all possible compositions. While the set of possible compositions is infinite (in factuncountable) in general, the controller generator is unique.• The technique gives us a very precise characterization of the sources of complexity in the problem: it allows for comput-ing the controller generator (i.e., an implicit representation of all compositions) in time exponential only in the numberof available behaviors, but not in the number of their states. Observe that checking the existence of a composition isknown to be EXPTIME-hard even for deterministic available behaviors running in a stateless environment [61].• Due to its “universality”, the controller generator can be used to generate a sort of lazy composition on-the-fly, possiblyadapting reactively based on runtime feedback.In particular, we shall argue that the composition solutions obtained are robust to behavior failures in two ways. First,they can handle (a) temporary behavior unavailability as well as (b) unexpected behavior/environment evolution in atotally reactive and on-the-fly manner—that is, without any extra effort or “re-planning” required to continue the realiza-tion of the target behavior—if at all possible, by the very nature of the composition generator. Second, the compositionsolutions can be parsimoniously refined when a module (c) becomes permanently unavailable, or (d) unexpectedly re-sumes operation.We complement the proposed technique by showing how it can be implemented by making use of model checkingtechnology applied to some special game structures developed in the context of Synthesis in Computer Science [3,47,40,69,27]. To that end, we show how to polynomially encode behavior compositions into safety games of a specific form, in whicheach strategy for winning the game corresponds to a composition (Section 5). With that reduction at hand, one is then ableto use available tools such as tlv [71] in order to actually compute the controller generator by symbolic model checking(Section 6).Most results presented in this paper appeared at an earlier stage in [30,79,15,80,26]. Here we revise, extend, and combinethem into a uniform and in-depth investigation which includes all the technical details and extended examples, so as toprovide a fully-comprehensive and clear analysis of the problem and of our solution approach. In particular the technicalcontributions include:• a notion of composition in the presence of partially controllable behaviors;108G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142• a simulation-based technique working with partially controllable behaviors, which produces “universal” solutions, i.e.,ones from which all possible solutions can be generated;• repair procedures to incrementally refine and adapt an existing solution to various unexpected types of failures;• an alternative, equivalent, solution technique based on safety games well suited for model checking based technology;and a proof-of-concept implementation of the latter in the tlv system.The rest of the paper is organized as follows. In Section 2 we spell out our framework for behavior composition. In Sec-tion 3, we provide our technique based on simulation for synthesizing compositions, and we detail the notion of controllergenerator. In Section 4, we show how the approach can deal with behavior failures. Then, in Section 5, we turn to synthesisby model checking, and show how one can compute the controller generator through safety games. Based on the results ofthe previous sections, we show in Section 6 how to implement behavior composition in practice using existing platformsfor synthesis by model checking such as tlv [71]. (The full tlv code for our running example is reported in Appendix A.) Wediscuss related work in various areas of Artificial Intelligence and Computer Science in Section 7, and draw conclusions inSection 8.2. The frameworkIn this section, we formally define the problem of concern, by developing an abstract framework based on finite statetransition systems.Environment. We assume to have a shared fully observable environment which provides an abstract account of action pre-conditions and effects, and can be regarded as a means of communication among behaviors (defined below). As, in general,we have incomplete information about preconditions and effects (akin to an action theory), the environment can, in general,be non-deterministic.Formally, an environment is a tuple E = (cid:3)A, E, e0, ρ(cid:4), where:• A is a finite set of shared actions;• E is the finite set of environment states;• e0 ∈ E is the environment initial state;• ρ ⊆ E × A × E is the environment transition relation among states.When referring to environment transitions, we equivalently use notations (cid:3)e, a, eperforming action a in state e may lead the environment to successor state e.(cid:7)(cid:7)(cid:4) ∈ ρ or ea−→ e(cid:7)(in E ), both denoting thatObserve that this notion of environment shares a lot of similarities with so-called “transition systems” in action lan-guages [34]; indeed, that formalism might well be used to compactly represent the environment, in our setting.Behaviors. A behavior abstracts the program of some agent (or, more in general, the logic of a device/module), in terms of(internal) states, actions and transitions. Behaviors are not intended to execute on their own but, rather, to operate withinan environment (and, through this, possibly interact with other behaviors). Hence, they are equipped with the ability totest, when needed, conditions (or guards) on environment states.Formally, a behavior over an environment E is a tuple B = (cid:3)B, b0, G, F , (cid:3)(cid:4), where:• B is the finite set of behavior states;• b0 ∈ B is the behavior initial state;• G is a set of guards over E , that is, boolean functions g : E (cid:9)→ {(cid:10), ⊥};• F ⊆ B is the set of behavior final states;• (cid:3) ⊆ B × G × A × B is the behavior transition relation.(cid:7)(cid:4) ∈ (cid:3) denotes that:(cid:7)We freely interchange notations (cid:3)b, g, a, b(i) action a can be executed by B in state b when the environment is in a state e such that g(e) = (cid:10); and (ii) the execution. Notice that a behavior’s evolution depends on the environment it is definedmay lead the behavior to successor state bover, as action executability depends on guard satisfaction.in B. A “guarded” transition (cid:3)b, g, a, b(cid:7)(cid:4) ∈ (cid:3), and b(cid:7)g,a−→ bIntuitively, behavior states model agent’s decision points: when the behavior is in a given state, the agent selects theaction to be executed next among those executable1 at that state. Executing the selected action, besides other effects,leads the behavior to a successor state, where a new set of actions become executable, and a new iteration starts. Finalstates are those where the behavior can be safely stopped (e.g., final states of a mechanic arm might correspond to safeconfigurations).1 Subject to environment’s current state.G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142109Fig. 1. The painting arms system S = (cid:3)B1, B2, B3, E(cid:4) and the target arm BT .e ∈ E, respectively, for which two transitions bWe say that a behavior B over environment E is deterministic if no behavior and environment states exist, say b ∈ B andg2,a−→ bClearly, given a deterministic behavior’s and an environment’s states, and an executable action, the next behavior state isalways predictable. In other words, deterministic behaviors are fully controllable by appropriate action selections. In general,however, behaviors are non-deterministic, that is, the state resulting from an action execution is unpredictable, and, thus,so are the actions that will be available in such a state. In other words, non-deterministic behaviors are only partiallycontrollable.and g1(e) = g2(e) = (cid:10).exist such that bg1,a−→ b(cid:7) (cid:12)= band b(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)System and target behavior. As said above, behaviors operate within an environment (the one they are defined over) andcan, through this, interact with each other. The notion of system introduced below allows for identifying a set of interactingbehaviors over the same environment.A system is a tuple S = (cid:3)B1, . . . , Bn, E(cid:4), where E is an environment and B1, . . . , Bn are pre-defined, possibly non-deterministic, available behaviors over E . We stress that available behaviors are given and cannot be modified, though theycan, of course, be (partially) controlled through action execution. The behaviors of a system model the only available im-plementations one can actually use to execute actions. Importantly, a behavior cannot be instructed to execute actionsregardless of its (and environment’s) current state, but needs to be in a state where the desired action is actually exe-cutable; external controllers must, of course, take these constraints into account when coordinating a set of behaviors.Finally, we define the so-called target behavior BT as a deterministic behavior over E , which represents the fully control-lable desired behavior to be obtained. Roughly speaking, the challenge we deal with here is to bring about the “virtual” (i.e.,non-readily available) target behavior by properly “composing” the execution of available behaviors. Observe that the targetis meant to be deterministic, as it is assumed that the desired system is fully known.Example 1. In the painting arms scenario depicted in Fig. 1, the overall aim of the system is to process blocks. Only oneblock at a time can be processed: it can be cleaned or painted, but needs first to be prepared. After preparation, cleaningand painting can be performed when water and paint, stored in two different tanks, are (respectively) available. Both tankscan be charged simultaneously by pushing a button. Blocks can also be cleaned, but only in particular circumstances (i.e.,environment in state e3, see below).The non-deterministic environment E provides a description of the dynamic domain that the behaviors interact with.Nodes and edges represent states and transitions, respectively; each edge label represents the action that triggers the tran-sition; and the initial state has an incoming edge without source. For instance, as said, blocks can be painted or cleanedonly after they have been prepared: so, from e1, a state where either action paint or clean is enabled (either e2 or e3) canonly be reached by first executing prepare. Though not graphically represented, the environment accounts for tank states,e.g.: in e1 and e2 the water tank is not empty, while it is in e3 and e4. Action clean can also be performed in e3, eventhough the water tank is empty, as in this state a cleaning tool not relying on water becomes available.BT describes the (deterministic) behavior of a desired (target) arm-agent module. Observe that state t2 captures a deci-sion point: cleaning a block is optional, as the selection of the next transition is demanded to the executor, which makes110G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142Fig. 2. Enacted arm B3.its decisions according to internal policies—e.g., ensuring first that the block is dirty. Also, notice that BT is “conservative”,in that it always recharges the tanks after processing a block, so as to guarantee that clean will be executable, if needed.The desired arm BT does not exist in reality. Nonetheless, there are three different actual arms available: B1(states a1, a2), a cleaning-disposing arm able to clean and dispose blocks; B2 (states b1, . . . , b4), capable of preparing,cleaning, and painting blocks; and B3 (states c1, c2), a paint arm that can also prepare blocks for processing. All three armsare able to press the charge button (to refill the tanks). Notice that arm B2 behaves non-deterministically when it comes topainting a block. This non-determinism captures modeler’s incomplete information about B2’s internal logic. Observe alsothat arm B1 requires the environment to be in e1 or e2, in order to perform clean, as it needs water to actually execute theaction.In this example, all behavior states are assumed final, thus imposing no restrictions on when the execution can bestopped.Next, we derive the notions of behavior and system enactment, which are abstract structures needed to formally statethe composition problem and characterize its solutions.Enacted behaviors. Behaviors and the environment mutually affect their executions. Such a “combined” evolution is for-mally described by enacted behaviors. Given a behavior B = (cid:3)B, b0, G, F , (cid:3)(cid:4) over an environment E = (cid:3)A, E, e0, ρ(cid:4), theenacted behavior of B on E is a tuple TB = (cid:3)S, A, s0, Q , δ(cid:4), where:• S = B × E is the (finite) set of TB’s states, where for each state s = (cid:3)b, e(cid:4) ∈ S, we denoteb as beh(s) and e as env(s);• A is the same set of actions as in E ;• s0 ∈ S is the initial state of TB, such that beh(s0) = b0 and env(s0) = e0;• δ ⊆ S × A × S is the enacted transition relation, where (cid:3)s, a, s(cid:7)(cid:4) ∈ δ or, equivalently, sin TB, if and only if:a−→ s(cid:7)– env(s)– beh(s)a−→ env(sg,a−→ beh(s(cid:7)) in E , that is, action a is actually executable in E ;(cid:7)) in B, with g(env(s)) = (cid:10) for some g ∈ G, that is, action a can be performed by B from its statebeh(s) when the environment state env(s) satisfies the guard which labels the respective transition.• Q = {s ∈ S | beh(s) ∈ F } is the set of the enacted behavior’s final states.Technically, TB is the synchronous product of the behavior and the environment, and represents all possible executionsobtained from running behavior B once guards are evaluated and actions are performed in E . Observe that the enactedbehavior non-determinism stems from both environment’s and behavior’s. Moreover, notice that action executability for abehavior is subject to: (i) its own state; (ii) guard evaluation in current environment state; and (iii) the environment stateitself. In particular, even though a transition labeled with action a and outgoing from current behavior (B) state exists,if, given current environment state e, no transition outgoing from e is labeled with a, then B cannot execute a—as ifits precondition were not satisfied. In the following, when no ambiguity arises, we simplify the notation by denoting theenacted counterpart of a behavior Bi simply as Ti , instead of TBi .Example 2. The enacted behavior T3 depicted in Fig. 2 describes the evolution of arm B3 if it were to act alone in theenvironment. Observe that there exist some joint states that cannot be reached by B3 alone. For instance, (cid:3)c1, e4(cid:4) can onlybe reached by executing action dispose which is not available in B3.Enacted system behavior. The enacted system behavior formally captures the concurrent, interleaved, execution of all avail-able behaviors on the environment of a system. Let S = (cid:3)B1, . . . , Bn, E(cid:4) be a system, where E = (cid:3)A, E, e0, ρ(cid:4) and Bi =(cid:3)B i, bi0, G i, F i, (cid:3)i(cid:4) (i = 1, . . . , n). The enacted system behavior of S is a tuple TS = (cid:3)SS , A, {1, . . . , n}, sS0, Q S , δS (cid:4), where:• SS = B1 × · · · × Bn × E is the finite set of TS states; given sS = (cid:3)b1, . . . , bn, e(cid:4), we denote bi as behi(sS ) (i = 1, . . . , n)and e as env(sS );• sS0 ∈ SS is the initial state of TS , such that behi(sS0) = bi0 (i = 1, . . . , n) and env(sS0) = e0;• Q S = {sS ∈ SS | ∀i ∈ {1, . . . , n} behi(sS ) ∈ F i} is the set of TS final states;G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142111• δS ⊆ SS × A × {1, . . . , n} × SS is TS ’s transition relation, where (cid:3)sS , a, k, s(cid:7)S (cid:4) ∈ δS or, equivalently, sSa,k−→ s(cid:7)S in TS , ifand only if:– env(sS )(cid:7)S ) in E ;a−→ env(sg,a−→ behk(s– behk(sS )– behi(sS ) = behi(s(cid:7)S ) in Bk, with g(env(sS )) = (cid:10), for some g ∈ Gk;(cid:7)S ), for i ∈ {1, . . . , n} \ {k}.The enacted system behavior TS is technically the synchronous product of: (i) the environment, and (ii) the asynchronousproduct of the available behaviors. Except for the presence of index k in transitions, which identifies the behavior thatperforms the labeling action, it is formally analogous to an enacted behavior.Controller. We are now ready to introduce the main component of our framework: the controller, which models an entityable to instruct available behaviors to execute actions, as well as to activate, stop, and resume their execution. We assumethe controller has full observability on both available behaviors and the environment, that is, it can keep track, at runtime,of their current states. Although other choices are possible, full observability is quite natural in this context, since availablebehaviors and environment are already suitable abstractions of actual modules: if details have to be hidden, this can bedone directly within the exposed abstract behaviors, by resorting to non-determinism.In order to formally define controllers, we start with the notions of traces and histories. Let TB = (cid:3)S, A, s0, Q , δ(cid:4) be anenacted behavior of some (available or target) behavior B over environment E . A trace for TB is a possibly infinite sequenceτ = s0 a1−→ s1 a2with a state) h = s0 a1are also histories, function |·| is also defined over them; if τ is an infinite trace, we let |τ | = ∞.−→ s(cid:6) of a trace. We denote h’s last state s(cid:6) by last(h), and its length (cid:6) by |h|. As finite traces−→ · · · , such that (i) s0 = s0; and (ii) s j a j+1j (cid:2) 0. A history is just a finite prefix (ending−→ s j+1 in TB, for all−→ · · · a(cid:6)Traces and histories extend immediately to enacted system behaviors, by adding index k. System traces have the form−→ · · · a(cid:6),k(cid:6)−→ s1 a2,k2−→ s(cid:6). Functions |·| and last are extended in the obvious−→ · · · , and system histories have the form s0 a1,k1s0 a1,k1way.Now, consider a system S = (cid:3)B1, . . . , Bn, E(cid:4) and its enacted behavior TS . Let H be the set of all TS histories. A controllerfor S is a possibly partial function P : H × A (cid:9)→ {1, . . . , n}.2 Intuitively, P (h, a) identifies the available behavior, i.e., BP (h,a),to delegate action a to, after S has evolved as described by enacted system behavior history h.The behavior composition problem. Roughly speaking, the problem we deal with is that of synthesizing, for a given system S,a controller that realizes a desired target behavior, that is, a controller able to coordinate the available modules in the systemso that the resulting behavior is, in fact, analogous to the target. In order to formalize this notion, we first need to definetrace realizations. Let S = (cid:3)B1, . . . , Bn, E(cid:4) be a system, BT a target behavior, and P a controller for S. Furthermore, let τ bean enacted target behavior trace (i.e., a trace of TT ) of the form τ = s0 a1−→ · · · . We define the set of enacted systemhistories induced by controller P on trace τ , as the set Hτ ,P =−→ s1 a2τ ,P , where:(cid:6)(cid:2)0H(cid:6)(cid:2)• H0= {sS0};τ ,P• H j+1τ ,P is the set of all ( j + 1)-length histories ha j+1,k j+1−→ sj+1Ssuch that:– h ∈ H j– env(s– k j+1 = P (h, a j+1), that is, at history h, action a j+1 in trace τ is delegated to available behavior Bτ ,P ;j+1S ) = env(s j+1);k j+1 ;– last(h)−→ s j+1 in TS , that is, behavior Bk j+1 can actually execute action a j+1.a j+1,k j+1Informally, Hτ ,P ⊆ H represents the set of all possible enacted system histories that ensue when controller P processes thetarget trace τ . Notice that the evolution of the environment in the histories in Hτ ,P ought to respect the evolution of theenvironment encoded in trace τ . Also note that because the evolution of the environment is independent of which behaviorexecutes an action, if the target can cause the environment to evolve from one state to another when performing an action,then such same action in an available behavior will also be able to cause the same evolution of the environment.Then, we say that P realizes enacted target trace τ (recall τ = s0 a1−→ s1 a2−→ · · ·) if:1. for all TS histories h ∈ Hτ ,P : if |h| < |τ |, then P (h, a|τ | ∈ Q T (i.e., beh(s2. if τ is finite and s|h|+1) = k and last(h)|τ |) is final for BT ), then all |τ |-length histories h ∈ H|τ |(cid:7)S in TS for some s(cid:7)S ;τ ,P are such that last(h) ∈ Q S .a|h|+1,k−→ s2 The kind of general synthesis we focus on here is that under the general assumption of perfect recall [32]: all what has been “seen” so far can be usedto take a decision. As part of the technical contributions of this paper, we shall demonstrate later that finite controllers will however be sufficient for ourcomposition framework.112G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142Fig. 3. Two finite state controllers.Informally, saying that a controller realizes a target behavior trace means that: given a (possibly infinite) sequence of actionscompliant with the target behavior, and a possible environment evolution resulting from the execution of such actionsequence, the controller selects at each step of execution a behavior able to actually execute the action requested at thatstep, no matter how behaviors—which are non-deterministic—selected earlier evolved.In addition, if the target trace finishes at a final state (for the enacted target behavior), then the whole system is broughtto a legal terminating state, too. In other words, the controller is always able to delegate the actions so as to mimic thetarget behavior.Because a deterministic behavior itself can be seen as a specification of a set of traces, we say that a controller P realizesa target behavior BT if and only if it realizes all traces of TT . This can be informally rephrased as the ability to delegate, stepby step, all target behavior’s action sequences, no matter how the environment and the available behaviors evolve.Observe that the controller can observe the current states of the available behaviors as well as that of the environment(in fact, it can observe the whole system history up to the current state), in order to decide which behavior to select next.This makes these controllers akin to an advanced form of conditional plans and, in fact, the problem itself is related toplanning [39], being both synthesis tasks. Here, though, we are not planning for choosing the next action, but for whoshall execute the next action, whatever such action happens to be at runtime. Formally, the problem that we deal with is asfollows:Given a system S = (cid:3)B1, . . . , Bn, E(cid:4) and a deterministic target behavior BT over E , synthesize a controller P that real-izes BT .All controllers that are a solution to this problem are called compositions (of BT on E ).Example 3. Even though compositions are, in general, functions of system histories (and actions), there are cases wherethey depend only on the history’s last k ((cid:2) 0) states. In such cases, they can be represented as finite state machines. InFig. 3, for instance, two finite state controllers P 1 and P 2 are depicted. An edge outgoing from a state s and labeled with apair c : (cid:3)a, k(cid:4) means that when the controller is in state s and action a is requested, a is delegated to behavior Bk, providedcondition c holds (omitted conditions are assumed true). The main difference between P 1 and P 2 is in the arm used forpainting: P 1 uses B2, while P 2 uses B3. In addition, P 1 recharges the tanks using behavior B1 when behavior B2 is in b1,whereas it uses behavior B2 when B2 is in state b1. Controller P 2, on the other hand, always uses B3 to recharge the tanks.For an example of trace realization, consider trace τ = (cid:3)t1, e1(cid:4) prepare−→ (cid:3)t2, e2(cid:4) clean−→ (cid:3)t3, e3(cid:4) paint−→ (cid:3)t4, e3(cid:4) of the enacted targetbehavior TT depicted in Fig. 4(a) (the graphical patterns of states are not relevant here). The set Hτ ,P 1 of enacted systemhistories induced by P 1 on τ , for the enacted system behavior TS of Fig. 4(b), contains exactly the following traces:h1 = (cid:3)a1, b1, c1, e1(cid:4);h2 = (cid:3)a1, b1, c1, e1(cid:4) prepare,2−→ (cid:3)a1, b2, c1, e2(cid:4);h3 = (cid:3)a1, b1, c1, e1(cid:4) prepare,2−→ (cid:3)a1, b2, c1, e2(cid:4) clean,1−→ (cid:3)a2, b2, c1, e3(cid:4);h4 = h3h5 = h3paint,2−→ (cid:3)a2, b1, c1, e3(cid:4);paint,2−→ (cid:3)a2, b3, c1, e3(cid:4).Observe that even though action paint may lead the environment to either state e2 or state e3, the traces in Hτ ,P 1account for the latter outcome only. This is due to the fact that Hτ ,P 1 only contains histories encoding the same environmentevolution as target trace τ (and where delegations are performed as dictated by controller P 1). The case in which theenvironment moves to state e2 is accounted for by another target trace, say τ (cid:7), which matches τ except for the last state,where last(τ (cid:7)) = (cid:3)t4, e2(cid:4). Notice however that in order for P 1 to be a composition, τ (cid:7)must be realized as well. As foravailable behaviors, instead, all of their possible evolutions are accounted for in set Hτ ,P 1 . For instance, h4 and h5 representG. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142113Fig. 4. The largest ND-simulation relation (cid:15) between the enacted target TT and (a fragment of) the enacted system TS . A state in TS ND-simulatesthose in TT that share its texture, e.g., (cid:3)(cid:3)a1, b3, c1(cid:4), e2(cid:4) (cid:15) (cid:3)t4, e2(cid:4). Observe that state (cid:3)(cid:3)a1, b1, c1(cid:4), e1(cid:4) is the only one with two textures—plain black andwhite—and hence ND-simulates both (cid:3)t1, e1(cid:4) and (cid:3)t5, e1(cid:4), and that state (cid:3)(cid:3)a1, b1, c1(cid:4), e3(cid:4) ND-simulates no state.similar runs except for the fact that behavior B2 evolves differently after executing the paint action (either to b1 in h4 or tob3 in h5).It can be easily seen that P 1 does realize trace τ , as well as all of the other traces of TT , thus being a composition of BTon E . On the contrary, P 2 does not amount to a composition of BT . To see that, consider again the target trace τ . It turnsout that set Hτ ,P 2 contains the history(cid:3)a1, b1, c1, e1(cid:4) prepare,2−→ (cid:3)a1, b2, c1, e2(cid:4) clean,1−→ (cid:3)a2, b2, c1, e3(cid:4),and that no transition (cid:3)a2, b2, c1, e3(cid:4) paint,3−→ s(cid:7)S exists in TS for any s(cid:7)S . Hence, P 2 does not realize τ and is not a composition.This concludes the formal statement of the behavior composition problem. The framework just presented stands for whatcan be considered the “core” framework, i.e., a basic setting that incorporates all distinguishing features of the problem.However, we stress that extensions and generalization can be defined so as to obtain non-trivial variants, which can beadopted to model and solve similar problems from domains that satisfy different assumptions (see Section 8 for a discussionon this).3. Composition via simulationNext, we present our approach to composition synthesis. This is originally inspired by [15], where a restricted versionof the composition problem was addressed, in the context of services, by taking the standard notion of simulation rela-tion [60,41] as a formal tool for solution characterization. Here, the shared environment and the (devilish) non-determinismof both the available behaviors and the environment significantly sophisticate that framework, calling for a new formal set-ting, the one presented here, where the usual notion of simulation relation is no longer enough to fully characterize the setof solutions and, hence, to guide the solution process.Intuitively, we say that a transition system S1 simulates another transition system S2, if S1 is able to “match”, step bystep, all of S2 moves during execution. More precisely, imagine to execute S2 starting from its initial state. At each step ofexecution, S2 performs a transition among those allowed in its (current) state. If, for all possible ways of executing S 2, S1can, at each step, choose a transition that “matches” (according to some criteria, e.g., label equivalence) the one executedby S2 then S1 simulates S2. We stress that S1 decisions are required to be made in an “online” fashion, as S 2 evolves. Inother words, it is not the case that S1 knows in advance which transitions S2 will execute in the future.Such an intuition is formalized in the following definition, where both non-determinism and the shared environment aretaken into account.114G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142Algorithm 1: NDS(TT , TS )—Largest ND-simulation.1 R := S T × SS \ {(cid:3)sT , sS (cid:4) | env(sT ) (cid:12)= env(sS ) ∨ (sT ∈ Q T ∧ sS /∈ Q S )};2 repeat3R := (R \ C), where C is the set of (cid:3)sT , sS (cid:4) ∈ R such that there exists an action a ∈ A and for each k there exists a transition sTsuch that either:a−→ s(cid:7)T in TT(a) there is no transition sSa,k−→ s(cid:7)S in TS such that env(s(cid:7)T ) = env(s(b) there exists a transition sSa,k−→ s(cid:7)S in TS such that env(s(cid:7)T ) = env(s(cid:7)S ); or(cid:7)S )(cid:7)T , s(cid:7)S (cid:4) /∈ R.but (cid:3)s4 until (C = ∅);5 return R;Let S = (cid:3)B1, . . . , Bn, E(cid:4) be a system, BT a target behavior over E , and TS = (cid:3)SS , A, {1, . . . , n}, sS0, Q S , δS (cid:4) and TT =(cid:3)S T , A, sT 0, Q T , δT (cid:4) the enacted system and enacted target behaviors corresponding to S and BT on E , respectively. AnND-simulation relation of TT by TS is a relation R ⊆ S T × SS , such that (cid:3)sT , sS (cid:4) ∈ R implies:1. env(sT ) = env(sS );2. if sT ∈ Q T , then sS ∈ Q S ;3. for all a ∈ A, there exists a k ∈ {1, . . . , n}—also referred to as a witness of (cid:3)sT , sS (cid:4) ∈ R for action a—such that for alltransitions sTa−→ s(cid:7)T in TT :a,k−→ s(a) there exists a transition sSa,k−→ s(cid:7)S in TS with env(s(b) for all transitions sS(cid:7)S in TS with env(s(cid:7)S ) = env(s(cid:7)T );(cid:7)S ) = env(s(cid:7)T ), it is the case that (cid:3)s(cid:7)T , s(cid:7)S (cid:4) ∈ R.In words, if a pair of enacted states is in the ND-simulation (relation), then: (i) its states share the same environmentcomponent; (ii) if the target behavior is in a final state, so is the system; and (iii) for all actions the (enacted) targetbehavior can execute, there exists a witness behavior Bk that can execute the same action while guaranteeing, regardless ofnon-determinism, preservation of the ND-simulation relation for successor target and system states.We say that a state sT ∈ S T is ND-simulated by a state sS ∈ SS (or sS ND-simulates sT ), denoted sT (cid:15) sS , if there existsan ND-simulation relation R of TT by TS such that (cid:3)sT , sS (cid:4) ∈ R. Observe that this is a co-inductive definition. As a result,the relation (cid:15) is itself an ND-simulation relation, in fact the largest one, in the sense that all ND-simulations are containedin (cid:15).Given TT and TS , relation (cid:15) can be computed by Algorithm 1 (NDS). Roughly speaking, the algorithm works by iter-atively removing those tuples for which the requirements of the ND-simulation definition do not apply, until a fixpointis reached. It is straightforward to prove that the algorithm reaches a fixpoint in a finite number of steps and computesthe largest ND-simulation, by comparing the algorithm with the definition of ND-simulation relation and observing that notuple is ever added to the candidate set R, and that C ⊆ R.Example 4. Fig. 4 shows a fragment of the largest ND-simulation relation for our painting blocks world example. In par-ticular, Fig. 4(a) shows the enacted target behavior of BT and Fig. 4(b) depicts a fragment of the system enacted behavior.States in Fig. 4(b) contain, in the bottom half, the environment component, and, in the top half, a compact representation ofavailable service (current) states: the first component of the integer string represents the subscript of the state that B1 is in,the second refers to B2, and so on. For instance, the node labeled with (cid:3)211, e4(cid:4) represents the system state (cid:3)(cid:3)a2, b1, c1(cid:4), e4(cid:4).Matching graphical patterns between TT and TS states mean that such states are in ND-simulation. For example,(cid:3)(cid:3)a1, b3, c2(cid:4), e2(cid:4) of TS ND-simulates (cid:3)t2, e2(cid:4) of TT ; this implies that (i) every conceivable action taken in (cid:3)t2, e2(cid:4) can bereplicated by some behavior (possibly a different one for each action) when the system is in (cid:3)(cid:3)a1, b3, c2(cid:4), e2(cid:4) and, moreover,that (ii) this property propagates to the resulting successor states.Observe that, clearly, a TT state can be simulated by several TS ’s, as is the case for, e.g., (cid:3)t4, e2(cid:4), which is simulatedby both (cid:3)(cid:3)a1, b1, c1(cid:4), e2(cid:4) and (cid:3)(cid:3)a1, b3, c1(cid:4), e2(cid:4). Also the converse may happen: (cid:3)(cid:3)a1, b1, c1(cid:4), e1(cid:4) in TS ND-simulates TT state(cid:3)t1, e1(cid:4) as well as (cid:3)t5, e1(cid:4).The relevance of the ND-simulation relation to the composition problem addressed here is twofold. Firstly, as will beshown next, computing the largest ND-simulation relation between a target enacted behavior and a system enacted behavioris essentially equivalent to checking whether there exists a composition for the target behavior that “uses” the behaviorsavailable in the system. Secondly, this “simulation-based” approach overcomes the main obstacles that previous solutiontechniques (e.g., [13]) encountered, as it enables the construction of flexible solutions that can take runtime information intoaccount, at no additional (worst-case) cost.Our first main result states that checking the existence of a composition can be reduced to checking whether the enactedtarget behavior’s initial state is ND-simulated by the enacted system behavior’s initial state, which corresponds to checkingwhether there exists an ND-simulation relation that includes the initial states of both.G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142115Theorem 1. Let S = (cid:3)B1, . . . , Bn, E(cid:4) be a system and BT a target behavior over E . Moreover, let TT = (cid:3)S T , A, sT 0, Q T , δT (cid:4) andTS = (cid:3)SS , A, {1, . . . , n}, sS0, Q S , δS (cid:4) be the enacted target behavior and the enacted system behavior for BT and S, respectively.Then, a composition controller P of target BT on system S exists if and only if sT 0 (cid:15) sS0.Proof. (If Part) . First, we define P . To this end, let h = s0Sa−→ s(cid:6)+1exists a TT history hT = s0Ts(cid:6)Tk ∈ {1, . . . , n} such that for all transitions s(cid:6)TTin TT (i.e., action a is BT -executable in s(cid:6)a−→ s(cid:6)+1T:a1−→ · · ·a(cid:6)−→ s(cid:6)−→ · · · a(cid:6),k(cid:6)a1,k1−→ s(cid:6)T (i.e., a history matching the actions of h) such that s(cid:6)(cid:15) s(cid:6)S ∈ H be a TS history and a ∈ A an action. If thereS , and a transitionT ), then we define P (h, a) ∈ ωa, where ωa is the set of all indexesT• there exists a transition s(cid:6)Sa,k−→ s(cid:6)+1• for all transitions s(cid:6)SSa,k−→ s(cid:6)+1Sin TS with env(s(cid:6)+1in TS with env(s(cid:6)+1S )=env(s(cid:6)+1TS ) = env(s(cid:6)+1), s(cid:6)+1TT);(cid:15) s(cid:6)+1S .(cid:15) s(cid:6)Because s(cid:6)TP (h, a) undefined.S , we know that ωa (cid:12)= ∅. In all other cases, namely, when hT does not exist or a is not BT -executable,Next, we prove that P is indeed a composition, that is, we show that every TT trace is realized by P . To this end, weconsider any TT trace τ = s0Ta1−→ s1Ta2−→ · · · (s0T= sT 0) and prove the following claim first:(†) for every TS history h = s0S(cid:2)Since Hτ ,P =H(cid:6)(cid:6)(cid:2)0τ ,P , we prove (†) by induction on (cid:6) as follows:−→ · · · a(cid:6),k(cid:6)a1,k1−→ s(cid:6)S ∈ Hτ ,P , with 0 (cid:3) (cid:6) < |τ |, it is the case that s(cid:6)T(cid:15) s(cid:6)S .= {sS0}. Clearly, sT 0 (cid:15) sS0 and (†) holds trivially.a(cid:6)+1,k(cid:6)+1• Let H0τ ,P• Take h(cid:6)+1 = s0S) = env(s(cid:6)+1env(s(cid:6)+1was defined above, it follows that s(cid:6)+1T(cid:15) s(cid:6)+1S .T−→ s(cid:6)S−→ · · · a(cid:6),k(cid:6)a1,k1τ ,P , where s0S ) and P (h(cid:6), a(cid:6)+1) = k(cid:6)+1. By the induction hypothesis, we know that s(cid:6)S = sS0. By the definition of H(cid:6)+1S ∈ H(cid:6)+1−→ s(cid:6)+1τ ,P , s(cid:6)S(cid:15) s(cid:6)−→ s(cid:6)+1in TS ,S . Then, by the way PSa(cid:6)+1,k(cid:6)+1TNext, take any h ∈ Hτ ,P such that |h| < |τ |. Because of the way each Hiτ ,P is constructed, h ought to be of the form(cid:15) s(cid:6)−→ · · · a(cid:6),k(cid:6)a1,k1−→ s(cid:6)S , that is, h has to match all actions in τ . From (†) above, we have that s(cid:6)Th = s0Sof ND-simulation, the fact that a(cid:6)+1 is BT -executable in s(cid:6)s(cid:6)SS . Then, by definitionT , and the way P is defined above, there exists a transitionS , where k = P (h, a(cid:6)+1) and k ∈ {1, . . . , n}. In addition, if τ is finite, then for every h ∈ H|τ |τ ,P we have, due to (†)|τ |∈ Q T (i.e., TT is final in enacted state sT ), then last(h) ∈ Q S .a(cid:6)+1,k−→ s(cid:6)+1above, that sThen, P realizes τ and P is a composition.(cid:15) last(h), which in turns implies that if s(Only-If Part) . Let P be a controller for S that is a composition of BT on E . From P , we build a relation R ⊆ S T × SSthat is an ND-simulation such that (cid:3)sT 0, sS0(cid:4) ∈ R. The definition of R is as follows: (cid:3)sT , sS (cid:4) ∈ R if and only if there exists aTT trace τ = s0Ta2−→ · · · and an (induced) TS history h ∈ Hτ ,P such that sT = s|h|T and sS = last(h).Next, we show that R is an ND-simulation relation (page 114). Consider then a pair (cid:3)sT , sS (cid:4) ∈ R. By R’s definition, therea1−→ s1T|τ |T|τ |Texists a TT trace of the form τ = s0T−→ · · · a(cid:6)a1−→ sT · · · and an (cid:6)-length TS history (induced by τ and P ) h ∈ H(cid:6)such thatˆτ ,Ph = s0S−→ · · · a(cid:6),k(cid:6)a1,k1−→ sS .First, due to the way set H(cid:6)τ ,P is constructed, env(sT ) = env(sS ) holds, as only system histories matching the evolutionof the environment as in trace τ are considered. Second, because P is a composition, P realizes τ as well as its |h|-lengthtrace prefix τ ||h|. It follows then that if last(τ ||h|) = sT ∈ Q T , then sS ∈ Q S .is BT -executable in sT , that is, there exists sTis, h can be induced by P when realizing trace τ ∗a,ka−→ ska ∈ {1, . . . , n} such that P (h, a) = ka and sSIt remains to prove that the third requirement of ND-simulation holds. To that end, consider an action a ∈ A thatτ ∗,P , that. Since P is a composition, it realizes trace τ ∗and hence there exitsa−→ s(cid:7)∗T in TT . Because theS in TS . Next consider any transition sT(cid:7)(cid:7)(cid:7)T ) = env(sS )S with env(s(cid:7)T is a legal trace of TT and history(cid:7)S ) holds, that is, requirement 3(b) of the ND-simulation definitionevolution of the environment is independent of that of the behaviors, there must exist sSand hence condition 3(a) of ND-simulation definition applies. Moreover, τ (cid:7) = τ |(cid:6)his satisfied, with ka = P (h, a) being indeed a witness of sT (cid:15) sS for action a. (cid:2)T in BT . Take now trace τ ∗ = τ |(cid:6)τ (cid:7),P . Hence, by definition of R above, R(s∗T . Clearly, h ∈ H(cid:6)S ∈ H(cid:6)+1a,ka−→ sa,ka−→ sa−→ sa−→ sa−→ s(cid:7)T , s∗(cid:7)Theorem 1 provides a straightforward method for checking the existence of a composition, namely: (i) compute thelargest ND-simulation relation between TT and TS , and (ii) check whether (cid:3)sT 0, sS0(cid:4) is in such a relation.116G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142As for computational complexity considerations, observe that algorithm NDS described above computes the largest ND-simulation relation (cid:15) between TT and TS in polynomial time, with respect to the size of TT and TS . Since the number ofstates in TS is exponential in the number of available behaviors B1, . . . , Bn, we get that the largest ND-simulation relation(cid:15) can be computed in exponential time in the number of available behaviors. Hence, as formally stated in the next theorem,this technique is a notable improvement with respect to the ones based on reduction to PDL [30,79], which are exponentialalso in the number of states of both the behaviors and the environment.3 Considering that the composition problem isEXPTIME-hard [61], the upper bound we get is indeed tight, that is, roughly speaking, this is the best we can hope for.Theorem 2. Checking for the existence of compositions by computing the largest ND-simulation relation (cid:15) can be done in polynomialtime in the number of states of the available behaviors, of the environment, and of the target behavior, and in exponential time in thenumber of available behaviors.Once the ND-simulation relation is computed, the problem of “synthesizing” a controller that is a composition arises.Next, we show how, from the largest ND-simulation relation, we can build a finite state program, i.e., a controller generator,that returns, at each step, the set of all available behaviors capable of performing the requested action, while guaranteeingthe possibility of delegating to available services all (target-compliant) requests that can be issued in the future.Formally, let S = (cid:3)B1, . . . , Bn, E(cid:4) be a system, BT a target behavior over E , and TS = (cid:3)SS , A, {1, . . . , n}, sS0, Q S , δS (cid:4) andTT = (cid:3)S T , A, sT 0, Q T , δT (cid:4) the enacted system behavior and the enacted target behavior corresponding, respectively, to Sand BT . The controller generator (CG) of S for BT is a tuple CG = (cid:3)Σ, A, {1, . . . , n}, ∂, ω(cid:4), where:1. Σ = {(cid:3)sT , sS (cid:4) ∈ S T × SS | sT (cid:15) sS } is the set of CG states, formed by all pairs of TT and TS state belonging to the largestND-simulation relation; given σ = (cid:3)sT , sS (cid:4) we denote sT by comT (σ ) and sS by comS (σ ).2. A is the finite set of shared actions.3. {1, . . . , n} is the finite set of available behavior indexes.4. ∂ ⊆ Σ × A × {1, . . . , n} × Σ is the transition relation, where (cid:3)σ , a, k, σ (cid:7)(cid:4) ∈ ∂ , or σ a,k−→ σ (cid:7)in CG, if and only if:• there exists a transition comT (σ )• there exists a transition comS (σ )• for all σ (cid:7)(cid:7) ∈ S T × SS such that comS (σ )a−→ comT (σ (cid:7)) in TT ;a,k−→ comS (σ (cid:7)) in TS ;5. ω : Σ × A (cid:9)→ 2{1,...,n}ω(σ , a) =(cid:3)kis the output function defined as(cid:5)(cid:4)(cid:4) ∃σ (cid:7) ∈ Σ s.t. σ a,k−→ σ (cid:7)is in CG.a−→ comT (σ (cid:7)(cid:7)) in TT , and env(comT (σ (cid:7)(cid:7))) =env(comS (σ (cid:7)(cid:7))), it is the case that (cid:3)comT (σ (cid:7)(cid:7)), comS (σ (cid:7)(cid:7))(cid:4) ∈ Σ (i.e., k is a witness of comT (σ ) (cid:15) comS (σ ) for action a).a,k−→ comS (σ (cid:7)(cid:7)) in TS , comT (σ )Roughly speaking, the CG is a finite state transducer that, given an action a (compliant with the target behavior), outputs,through function ω, the set of all available behaviors that can perform a next, according to the largest ND-simulationrelation (cid:15). Observe that computing the CG from relation (cid:15) is easy, as it involves checking local conditions only. In fact, onecould directly compute the CG by enriching relation (cid:15), during computation, with information about actions, indices, andtransitions.By Theorem 1, if there exists a composition of BT , then sT 0 (cid:15) sS0 and CG does include state σ0 = (cid:3)sT 0, sS0(cid:4). In sucha case, we can build actual controllers, called generated controllers, that are compositions of BT , by picking up, at eachstep, one available behavior among those returned by output function ω. Notice that full-observability of available behaviorstates is a crucial assumption here, as both ω and ∂ depend on the current states of both the environment and all systembehaviors, which, due to non-determinism, cannot be known with certainty, i.e., can be reconstructed, by just looking at theaction history. As a result, after each action execution, in order to obtain ω’s output, the new states of the system and ofthe environment need to be known. Of course, more complex scenarios where available behavior states are only partiallyobservable can be considered, though this is out of the scope of this paper.Formally, controllers that are compositions can be generated from the CG as follows.4 Firstly, in analogy with behavior andsystem traces, we define CG traces and histories: a trace for CG is a possibly infinite sequence σ 0 a1,k1−→ · · ·, such thateach transition σ j a j+1,k j+1−→ σ j+1 is in CG, for all j (cid:2) 05; consequently, a history for CG is a finite prefix of a trace. Functions−→ σ 1 a2,k2last and | · | over CG histories are defined as usual. For technical convenience, given a CG trace τCG = σ 0 a1,k1−→ · · ·, wea2,k2define the corresponding projected system trace as the sequence projS (τCG) = comS (σ 0)−→ · · ·, intuitivelyobtained from τCG by taking only the system component of each state. Clearly, by definition of CG, if σ 0 = (cid:3)sT 0, sS0(cid:4) thena1,k1−→ comS (σ 1)−→ σ 1 a2,k23 Though in light of the result in here, a better complexity analysis involving the specific PDL satisfiability procedures could be carried out.4 We stress that as a composition exists if and only if σ0 = (cid:3)sT 0, sS0(cid:4) ∈ Σ (Theorem 1), constructing a composition makes sense only if this conditionholds.5 Observe that we do not require σ 0 = (cid:3)sT 0, sS0(cid:4) .= σ0 as, in general, the CG does not include σ0.G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142117projS (τCG) is a legal TS trace. Also, from τCG we define the corresponding projected target trace projT (τCG) = comT (σ 0)a2−→ · · · that can be easily proven to be a legal TT trace if σ 0 = (cid:3)sT 0, sS0(cid:4). Similarly, we can derive from each CGcomT (σ 1)history hCG a projected system history and a projected target history, which are, respectively, a TT history and a TS history, ifσ 0 = (cid:3)sT 0, sS0(cid:4).a1−→Next, let HCG be the set of all CG histories, and consider a selection functionCGP : HCG × A (cid:9)→ {1, . . . , n}such that CGP(hCG, a) ∈ ω(last(hCG), a), for all hCG ∈ HCG and a ∈ A, if ω(last(hCG), a) is non-empty, while it is left uncon-strained if ω(last(hCG), a) is empty.Finally, assuming that CG includes σ0 = (cid:3)sT 0, sS0(cid:4), for each CG history hCG = σ 0 a1,k1−→ · · · a(cid:6),k(cid:6)−→ σ (cid:6) such that σ 0 = σ0,consider the corresponding projected system history:(cid:6)(cid:6)(cid:7) a1,k1−→ · · · a(cid:6),k(cid:6)−→ comSσ (cid:6)(cid:7).projS (hCG) = comSσ 0For a given selection function CGP, a generated controller is any function P CGP : H × A (cid:9)→ {1, . . . , n} such that for every TShistory h ∈ H and action a ∈ A, if h = projS (hCG) for some CG history hCG, then P CGP(h, a) = CGP(hCG, a).The following results relate CGs to compositions and show that, given a CG containing σ0, one getsall and only controllersthat are compositions by considering all possible resolutions of the non-determinism of function CGP. Notably, while eachspecific composition may be an infinite state program, the controller generator, which in fact includes them all, is alwaysfinite.Theorem 3. Let S, BT , TS and TT be as above, and let CG = (cid:3)Σ, A, {1, . . . , n}, ∂, ω(cid:4) be the controller generator of S for BT . Ifσ0 = (cid:3)sT 0, sS0(cid:4) ∈Σ , then:1. every generated controller obtained from CG as shown above is a composition of BT on E ;2. every controller that is a composition of BT on E can be obtained from CG as shown above.Proof. To prove the first claim, we show that for every target trace τ ∈ HT and controller P CGP defined as above, thereexists a controller P , defined as in the (If Part) of Theorem 1, such that Hτ ,P = Hτ ,P CGP . Since P is proven to realize τ , bylooking at the definition of trace realization, this is enough to prove that P CGP realizes τ as well.τ ,P CGPLet H(cid:6)⊆ Hτ ,P⊆ Hτ ,P CGP be the set of system histories h = s0Sbe the analogous set for τ and P . We prove, by induction, the existence of P (defined as in the (If Part) of Theorem 1) suchthat H(cid:6)S induced by τ and P CGP. Also, let H(cid:6)−→ s(cid:6)(cid:2)τ ,P , for every (cid:6) (cid:2) 0. Since, for every controller C , Hτ ,C == H(cid:6)(cid:6)(cid:2)0τ ,Pτ ,P CGPτ ,C , we get that Hτ ,P CGPH(cid:6)= {sS0}. By induction hypothesis, assume= Hτ ,P .−→ · · · a(cid:6),k(cid:6)a1,k1H(cid:6)For the base case ((cid:6) = 0), no matter how P is defined, H0−→ · · · a(cid:6),k(cid:6)a1,k1τ ,P , and consider a system history h = s0S−→ · · · a j ,k ja1,k1= H(cid:6)τ ,P CGP−→ s(cid:6)τ ,P CGP= H0τ ,PS ∈ H(cid:6)τ ,P CGP−→ sjS . In particular k(cid:6) = P CGP(h|(cid:6)−1, a(cid:6)) is defined, and there-1, . . . , (cid:6), we have ki = P CGP(h|i−1, ai), where h| j = s0S−→ · · · a(cid:6)−1,k(cid:6)−1fore, by P CGP definition, there exists a CG history ˜hCG = (cid:3)˜s0S (cid:4) such that projS (˜hCG) = h|(cid:6)−1.T , s0In principle, ˜hCG can be any, as long as projS (˜hCG) = h|(cid:6)−1. In particular, it could be unrelated to τ . But because ˜hCG is aS and therefore env(˜sihistory for CG, it is such that (cid:3)˜siS ). In turn, h beingT ) (i = 0, . . . , (cid:6) − 1). Finally, BT being deterministicT ) = env(siS ) = env(siinduced by τ , env(siT ). So, we conclude that projT (˜hCG) = τ |(cid:6)−1. Based on this and the fact= sT 0, we get beh(˜siand having ˜s0= s0TTthat projS (˜hCG) = h|(cid:6)−1, we also have that ˜hCG is unique, for fixed h.T , siT ), and hence env(˜siT ) = beh(siS (cid:4) ∈Σ (i = 0, . . . , (cid:6) − 1), hence ˜si(cid:15) siS ) = env(si−→ (cid:3)˜s(cid:6)−1T ) = env(siS (cid:4) a1,k1, s(cid:6)−1TTBy definition of induced history, given h, k(cid:6) = P CGP(h|(cid:6)−1, a(cid:6)) = CGPCGP(˜hCG, a(cid:6)) ∈ ω((cid:3)s(cid:6)−1. Because h is an induced history, for i =S (cid:4) a1,k1−→ · · · a(cid:6),k(cid:6)−→ (cid:3)s(cid:6)T , s(cid:6)T , s0, s(cid:6)−1S (cid:4), a(cid:6)). So, observing theTS (cid:4) is a CG history, in particular,definition of CG and ω, it is easily seen that the sequence hCG = (cid:3)s0such that projS (hCG) = h and projT (hCG) = τ |(cid:6).ST , s(cid:6)(cid:4) ∈ Σ —and that a(cid:6)+1 is BT -executable in s(cid:6)Next, we prove that all possible extensions of h, obtained by realizing action a(cid:6)+1 in τ (if any), according to P CGP , arealso possible under P , and vice versa. In other words, we prove that H(cid:6)+1τ ,P . Two cases are possible: either (i)τ = τ |(cid:6) (i.e., τ is finite); or (ii) not. In case (i), we trivially obtain H(cid:6)+1S —T (this trivially comes from a(cid:6)+1 position in τ ). In addition, hC G isas (cid:3)s(cid:6)proved, above, a CG history such that projS (hCG) = h. Therefore, by definition of generated controller, P CGP(h, a(cid:6)+1) = k(cid:6)+1 ∈ω((cid:3)s(cid:6)T , s(cid:6)On the other hand, consider the construction of P in the (If Part) of Theorem 1. Given h, τ |(cid:6) matches (by construc-S (as proven above). So, P (h, a(cid:6)+1) ∈ ωa(cid:6)+1 (cid:12)= ∅. But then,tion) all actions in h, and is such that s(cid:6)TS (cid:4), a(cid:6)+1) = ωa(cid:6)+1 , no matter which index P CGP returns, P can choose the same index, say k(cid:6)+1,observing that ω((cid:3)s(cid:6)T , s(cid:6)from ωa(cid:6)+1 so that k(cid:6)+1 = P CGP(h, a(cid:6)+1) = P (h, a(cid:6)+1). Clearly, given h, a(cid:6)+1 and k(cid:6)+1, every possible system history of the= ∅. For case (ii), observe that s(cid:6)T= last(τ |(cid:6)) (cid:15) last(h) = s(cid:6)S (cid:4), a(cid:6)+1) (cid:12)= ∅.τ ,P CGP= H(cid:6)+1τ ,P= H(cid:6)+1(cid:15) s(cid:6)τ ,P CGP118G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142a(cid:6)+1,k(cid:6)+1−→ s(cid:6)+1 is such that ˆh ∈ H(cid:6)+1form ˆh = hH(cid:6)+1τ ,PWe prove the second part by showing that for all TT traces, all decisions made by P along an arbitrary history inducedτ ,P if and only if ˆh ∈ H(cid:6)+1τ ,P CGP. Since h is arbitrarily chosen, we ultimately get= H(cid:6)+1τ ,P CGP.a1−→ s1Tby τ and P are compliant with the definition of generated controller.−→ s(cid:6)a2−→ · · · be a TT trace, and h = s0S−→ · · · a(cid:6),k(cid:6)a1,k1S (cid:4) a1,k1Let τ = s0T−→ · · · a(cid:6),k(cid:6)S ∈ Hτ ,P a generic history induced by τ and P . SinceP is a composition, by (Only-If Part) of Theorem 1, we get that ki = P (h|i, ai+1) is a witness of siS for ai+1, forS (cid:4) is a CG-history. Indeed, by definition of ω, for every a that is BT -i = 0, . . . , (cid:6) − 1. Then, hCG = (cid:3)s0T , s(cid:6)executable in sT , ω((cid:3)sT , sS (cid:4), a) contains all (and only) the witnesses of sT (cid:15) sS for a. So, this will be true, in particular, forω((cid:3)siT , siSince every prefix of a history is a history itself, and (cid:6) being arbitrary, the argument above proves that for every prefixof h, say h| j ( j = 0, . . . , (cid:6) − 1), there exists an hCG prefix hCG| j , which is a CG-history, such that projS (hCG| j) = h| j . But then,S (cid:4), a j+1), we get that P CGP can behave in the same wayP CGP(h| j, a j+1) = CGP(hCG| j) ∈ ω((cid:3)sjT , sas P , along h, by properly picking, at every step, an element from the set returned by ω. Since (cid:6) was arbitrarily chosen, thisresult extends to all histories h ∈ Hτ ,P . (cid:2)S (cid:4), a j+1). As k j ∈ ω((cid:3)sS (cid:4), ai+1).−→ (cid:3)s(cid:6)T , s0jT , s(cid:15) siTjjWe close this section by observing that compositions can be generated just-in-time, based on both the CG and ob-servability of behavior and environment states. Intuitively, the CG is analogous to a sort of “meta-plan” or a statefulnon-deterministic “complete universal plan”, which keeps all the existing plans at its disposal and selects the one to followfor next action, possibly with contingent decisions.6Example 5. The CG can decide how to delegate actions, as requests from target arm BT come in. For instance, if a cleanaction is requested after a block has been prepared, the CG knows it ought to delegate such a request to arm B A , so asto stay within the ND-simulation relation. While physically possible, delegating clean to arm BB would bring the enactedsystem into state (cid:3)(cid:3)a1, b1, c1(cid:4), e3(cid:4) which is known not to be in ND-simulation with the (enacted) target.4. On behavior failuresIn discussing the behavior composition problem, we have, so far, assumed implicitly that all (available) componentmodules are fully reliable, i.e., that they are always available, and behave “correctly”, relative to their specification. However,there are many situations and domains in which full reliability of components might not be an adequate assumption. Forexample, in multi-agent complex and highly dynamic domains, one can rely neither on total availability nor on reliabilityof the existing modules, which may stop being available due to a variety of reasons, e.g.: devices may break down, agentsmay decide to stop cooperating, communication with agents may drop, exogenous events may change the state of theenvironment, and many others; also, behaviors may possibly re-appear into the system at some later stage, thus creatingnew “composition opportunities” for the controller.Generally speaking, behavior and environment specifications can be seen as contracts, and failures, such as those de-scribed above, can be interpreted as “breaches” of such contracts. In this section, we identify some classes of failures andpropose respective procedures to “repair” the controller under execution when the failure occurred. Specifically, we identifyfive core ways of breaking contracts7:(a) A behavior temporarily freezes, that is, it stops responding and remains still, then eventually resumes in the same stateit was in. As a result, while frozen, the controller cannot delegate actions to it.(b) A behavior unexpectedly and arbitrarily (i.e., without respecting its transition relation) changes its current state. Thecontroller can in principle keep delegating actions to it, but it must take into account the behavior’s new state.(c) The environment unexpectedly and arbitrarily (i.e., without respecting its transition relation) changes its current state.The controller has to take into account that this affects both the target and the available behaviors.(d) A behavior dies, that is, it becomes permanently unavailable. The controller has to completely stop delegating actions toit.(e) A behavior that was assumed dead unexpectedly resumes operation starting in a certain state. The controller can exploitthis opportunity by delegating actions to the resumed behavior, again.Previous composition techniques (e.g., [14,30,79]) do not address these cases, as they assume that controllers always dealwith fully reliable modules. Consequently, upon any of the above failures, we are only left with the (default) option of6 As stated, we defined controllers to be as general as possible. Note that since traces are unbounded in nature, it is not immediate that finite controllerare enough. Indeed, the notion of simulation includes a local condition on states as well as a transition condition that captures how states evolve over time.7 Obviously, we assume an infrastructure that is able to distinguish between these failures.G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142119“re-planning” from scratch for a whole new controller, if any. What we shall prove in this section is that the simulation-based technique presented in Section 3 is intrinsically robust, in the sense of being able to deal with unexpected failures bysuitably refining the solution at hand, either on-the-fly (for cases (a), (b), and (c)), or parsimoniously (for cases (d) and (e)),thus avoiding full re-planning.4.1. Reactive adaptabilityWe start by showing that Theorem 3 provides us with a sound and complete technique for dealing with failure cases (a),(b) and (c), without requiring any re-planning step. As a matter of fact, once we have the controller generator, actualcompositions can be generated “just-in-time”, as (target compliant) actions are requested. In other words, one can delaythe choice performed by the selection function CGP until run-time, when contingent information, such as actual behavioravailability, can be taken into account. This ability provides the executor with great flexibility, as, in a sense, it can “switch”compositions online, as needed. A controller generated in this manner is referred to as a just-in-time (JIT) generated controller,and is denoted as CGPjit. Below, we discuss the effectiveness of JIT generated controllers in cases (a), (b) and (c).Freezing of behaviors. A JIT generated controller CGPjit fully addresses temporary behavior freezing, i.e., failure case (a).Indeed, if a behavior is temporarily frozen, the CGPjit simply stops delegating actions to it, and continues with any otherpossible choice.8 Obviously, if no other choices are possible, the CGPjit is left with no other option than waiting for thefrozen behavior to come back.State change of behaviors and environment.JIT generated controllers also address unexpected changes in the internal stateof behaviors and/or of the environment, that is, failure cases (b) and (c).9 To understand this, let us denote by TS (zS ) thevariant of the enacted system behavior whose initial state is zS instead of sS0. Similarly, let us denote by TT (zT ) the enactedtarget behavior whose initial state is zT instead of sT 0. Next, suppose that the state of the enacted system behavior changes,unexpectedly, to state ˆsS , due to a change of the state of a behavior (or a set of behaviors) and/or of the environment. Then,if sT is the state of the target when the failure happened, one should recompute the composition with the system startingin ˆsS and the target starting from ˆsT , where ˆsT is just sT with its environment state replaced by the one in ˆsS (note ˆsT = sTfor failures of type (b)). Observe, though, that ND-simulation relations are independent from the initial states of both thetarget and the system enacted behaviors. Therefore, the largest ND-simulation relation between TT (ˆsT ) and TS (ˆsS ) is, infact, relation (cid:15), that we already computed. This implies that we can still use the very same controller generator CG (andthe same just-in-time generated controller CGPjit as well), with the guarantee that all compositions of the system variantfor the target variant, if any, are still captured by the CG (and CGPjit too). Put it all together, we only need to check whetherˆsT (cid:15) ˆsS , and, if so, continue to use CGPjit (now from 0-length CG history h0CG= (cid:3)ˆsT , ˆsS (cid:4)).Example 6. Upon an unexpected change in the system, in the environment or any available behavior, the CG can react/adaptto the change immediately. For instance, referring to Fig. 4, suppose the target is in state t3, the environment in state e3,and the available behaviors B1, B2, and B3, are in their states a2, b2, and c1, respectively. That is, TT is in (cid:3)t3, e3(cid:4), and TSis in (cid:3)(cid:3)a2, b2, c1(cid:4), e3(cid:4). Suppose that, unexpectedly, the environment happens to change to state e2—someone has rechargedthe water tank. All that is needed in this case is to check whether the new states of TT and TS , namely (cid:3)t3, e2(cid:4) and(cid:3)(cid:3)a2, b2, c1(cid:4), e2(cid:4), respectively, are still related according to relation (cid:15). Since they are, the CG continues the realization of thetarget from such (new) enacted states.Computing reactive compositions on-the-fly. Observe that a JIT generated controller CGPjit can be computed on-the-fly bystoring only the ND-simulation relation (cid:15). In fact, at each point, the only information required for the next choice isω(σ , a), where σ ∈ Σ (recall Σ = (cid:15)) is formed by the current state of the enacted target behavior and that of the enactedsystem behavior. Now, in order to compute ω(σ , a) we only need to know (cid:15).4.2. Parsimonious refinementAs seen above, failure cases (a), (b), and (c), do not need any particular effort to be dealt with. However, when consider-ing cases (d) and (e), things change significantly: a simple reactive approach is no longer sufficient, and more complexrefinement techniques are required. Concretely, suppose that the current composition that is being executed—from anND-simulation relation—becomes suddenly invalid, due to a disruption in the available system (e.g., a behavior becomesunavailable). While the current ND-simulation relation behind the composition is no longer sound, it may not be necessaryto recompute the new ND-simulation relation (and a corresponding composition, if any) “from scratch”. As a matter of fact,we shall show here that the ND-simulation at hand can be refined in an intelligent manner, so as to re-use previous compu-tation effort. Technically, using the current ND-simulation relation and the nature of the disruption, one can identify upper8 If more information is at hand, the CGPjit may use it to choose in an informed way, though this is out of the scope of this paper.9 Although hardly as meaningful as the ones above, unforeseen changes in the target state can be accounted for in a similar way.120G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142Algorithm 2: NDSP(TT , TS , Rinit, Rsure).1 R := Rinit \ Rsure;2 R := R \ {(cid:3)sT , sS (cid:4) | (env(sT ) (cid:12)= env(sS )) ∨ (sT ∈ Q T ∧ sS /∈ Q S )};3 repeat4R := (R \ C), where C is the set of (cid:3)sT , sS (cid:4) ∈ R such that there exists an action a ∈ A such that for each k there is a transition sTTT such that either:(a) there is no transition sS(cid:7)S in TS such that env(sa,k−→ s(cid:7)T ) = env(sa−→ s(cid:7)T in(b) there exists a transition sSbut (cid:3)s(cid:7)T , s(cid:7)S (cid:4) /∈ R ∪ Rsure.a,k−→ s(cid:7)S in TS such that env(s(cid:7)S ); or(cid:7)S )(cid:7)T ) = env(s5 until (C = ∅);6 return R ∪ Rsure;and lower bounds for the new ND-simulation relation that needs to be computed due to the disruption. The upper boundwill rule out tuples that are known not to be in the new ND-simulation, whereas the lower bound will provide those tuplesthat ought to be in such relation.To that end, we define a new algorithm, namely Algorithm 2 (NDSP), that instead of computing the largest ND-simulationrelation from scratch (as done by Algorithm 1), it does so by leveraging on known lower (Rinit) and upper (Rsure) bounds.More specifically, the algorithm—a (generalized) parametric version of Algorithm 1—computes the largest ND-simulationrelation between TT and TS that is contained in the initial relation Rinit ⊆ S T × SS and assuming that such resultingrelation contains relation Rsure ⊆ S T × SS . Of course, not every upper and lower bounds are reasonable. We will presentbelow a set of results that tells us how to use such algorithm in order to refine or adapt an existing (ND-simulation) relationat hand. As one can observe, the NDSP algorithm works the same way as algorithm NDS, except that: (i) instead of startingfrom S T × SS , it takes the initial set Rinit as input; and (ii) neglects all pairs contained in Rsure for removal, as they areassumed to be (surely) included in the ND-simulation relation that is being computed. As expected, when Rinit = S T × SSand Rsure = ∅, algorithm NDSP behaves exactly as NDS does. Indeed, this is a special case of the next result, which identifiessufficient conditions on the new parameters to guarantee that the outputs of NDSP and NDS match.Lemma 4. Consider a system S = {B1, . . . , Bn, E} and a target behavior BT , and let TS and TT be their respective enacted behaviors.If Rsure ⊆ NDS(TT , TS ) ⊆ Rinit, then NDSP(TT , TS , Rinit, Rsure) = NDS(TT , TS ).1 and RiProof. Let Riiteration. Similarly, define Ciiterations (clearly, n2 (cid:3) n1).2 be the sets representing R in algorithms NDS and NDSP, respectively, after the i-th repeat-loop2. Moreover, assume that NDSP and NDS require n2 and n1, respectively, repeat-loop1 and CiFirst, let us prove, by induction on i, that Ri2∪ Rsure ⊆ Ri1, with r < n1. Let π = (cid:3)sT , sS (cid:4) ∈ Rr+1Suppose now that Rr2ever expanded along iterations, it is the case that π /∈ Rsure (otherwise π ∈ NDS(TT , TS ) and π ∈ Rr+1Rr+111. Because π /∈ Rr+11. It is obvious that R0), and thus π ∈ Rr+12, and π ∈ Rr∪ Rsure ⊆ R0∪ Rsure ⊆ Rr, π ∈ Rr211. This means that there exists an action ˆa ∈ A such that for each k there is a transition sTis, π ∈ Creither (a) or (b) of step 3 of NDS holds. If case (a) holds, then also π ∈ Crthere exists a tuple π (cid:7)k /∈ Rrkaction ˆa and tuple π (cid:7)step 3 hold then π ∈ Cr(a) or (b) of NDSNDSP(Tt, TS , Rinit, Rsure) ⊆ NDS(Tt, TS ).k do indeed satisfy the requirement of the step 4 of NDSP. Hence, π ∈ Cr2 and, consequently, π /∈ Rr+1S in TS , but π (cid:7)(cid:7)(cid:7)S (cid:4) such that sSˆa,k−→ s(cid:7)T , s= (cid:3)s2(cid:7)2112. Since neither Ri∪ Rsure, but π /∈ Rr+11 (observe Rinit ⊆ S T × SS ).1 nor Ri2 are, as NDS(TT , TS ) ⊆, π was deleted at the r-th loop iteration of NDS, that(cid:7)T in TT such that2 trivially holds. If case (b) applies for some k, then1. By induction hypothesis, π (cid:7)∪ Rsure. Thus,22. We conclude that if eitherand. Contradiction. Therefore, Rr+1∪ Rsure ⊆ Rr+1k /∈ Rrˆa−→ s21Next, we prove that NDS(TT , TS ) ⊆ NDSP(TT , TS , Rinit, Rsure). To that end, we shall prove, by induction on i, thatNDS(TT , TS ) ⊆ Ri∪ Rsure. Since NDS(TT , TS ) ⊆ Rinit, NDS(TT , TS ) ⊆ R0∪ Rsure. Next, suppose that NDS(TT , TS ) ⊆ Rr∪222Rsure, for some r < n2, and let π = (cid:3)sT , sS (cid:4) ∈ NDS(TT , TS ) but π /∈ Rr+1∪ Rsure,∪ Rsure. By induction hypothesis, π ∈ Rr2and π was therefore removed from R2 in the r-th iteration of the NDSP algorithm. This means that there exists an ac-ˆa−→ s(cid:7)tion ˆa ∈ A such that for each k there is a transition sTT in TS such that either (a) or (b) of the fourth step inNDSP holds. In particular, if case (b) applies for some k, then there exists a tuple π (cid:7)(cid:7)(cid:7)S in TS ,= (cid:3)sS (cid:4) such that sSkbut π (cid:7)k /∈ Rn11 . However, since π ∈ NDS(TT , TS ),k /∈ Rn1π ∈ Rn1tuples, π is a candidate to be re-moved from set Rn11 , i.e., π ∈ Cn1∪ Rsure andNDS(TT , TS ) ⊆ NDSP(Tt, TS , Rinit, Rsure) follows. (cid:2)k /∈ NDS(TT , TS ) and thus π (cid:7)k /∈ Rr1 . But, by using the same action ˆa, together with the corresponding π (cid:7)1 . Then, algorithm NDS requires more than n1, a contradiction. Hence, π ∈ Rr∪ Rsure. By the induction hypothesis, π (cid:7)ˆa,k−→ s(cid:7)T , s1222Next, we introduce convenient notations to shrink and expand systems and ND-simulation relations. Given a systemS = (cid:3)B1, . . . , Bn, E(cid:4) and a set of behavior indexes W ⊆ {1, . . . , n}, we denote by S(W ) the system derived from S byG. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142121keeping only the behaviors Bi such that i ∈ W (note S = S({1, . . . , n})). Also, for an enacted target behavior TT over E , wedenote by (cid:15)W the largest ND-simulation relation of TT by TS(W ). Finally, given a further set of indexes U ⊆ {1, . . . , n} suchthat W ∩ U = ∅, we denote by (cid:15)W ⊗ U the relation obtained from (cid:15)W , by (trivially) putting back into the system all Bisuch that i ∈ U . Formally, this latter operation can be defined as follows (without loss of generality, assume W = {1, . . . , (cid:6)}and U = {(cid:6) + 1, . . . , m}):(cid:15)W ⊗ U =(cid:3)(cid:7)(cid:4)(cid:4)(cid:4) s(cid:3)sT , sfor i ∈ {(cid:6) + 1, . . . , m}(cid:5).(cid:7) = (cid:3)b1, . . . , b(cid:6), b(cid:6)+1, . . . , bm, e(cid:4) such that (cid:3)sT , (cid:3)b1, . . . , b(cid:6), e(cid:4)(cid:4) ∈ (cid:15)W and bi is a state of Bi,Intuitively, adding a set of behaviors to a system can only extend, and never reduce, the capabilities of the system. Indeed,the additional behaviors do not constrain in any way those already present, while, in general, make the system able toexecute more actions. In particular, if a system can simulate a target behavior (on some environment), we expect it to havethe same ability, and possibly more, after introducing additional behaviors. The next result proves this intuition, i.e., thatwhen “putting back” a set of behaviors U into system S(W ), by extending (cid:15)W as shown above, we are guaranteed toobtain an ND-simulation relation for the (expanded) system S(W ∪ U ), though not necessarily the largest one.Lemma 5. Given a system S = {B1, . . . , Bn, E}, a target behavior BT and its respective enacted behavior TT over E , let W , U ⊆{1, . . . , n} be such that W ∩ U = ∅. The following hold:• (cid:15)W ⊗ U ⊆ (cid:15)W ∪U ;• (cid:15)W ⊗ U is an ND-simulation relation of TT by TS(W ∪U ).(cid:7)(cid:4)(cid:4) ∈ (cid:15)W ⊗ U . Due to the definition of operation ⊗, it is the case that (cid:3)t, e(cid:4)(cid:15)W (cid:3)b1, . . . , b(cid:6), eProof. Without loss of generality, consider W = {1, . . . , (cid:6)}, and U = {(cid:6) + 1, . . . , m}. Suppose that (cid:3)(cid:3)t, e(cid:4), (cid:3)b1, . . . , b(cid:6), b(cid:6)+1, . . . ,(cid:7)(cid:7)(cid:4). This means that e = ebm, eand that for each a ∈ A, there exists index ka ∈ W satisfying the requirements of the ND-simulation relation definition forsystem S(W ). Then, (cid:3)t, e(cid:4) (cid:15)W ∪U (cid:3)b1, . . . , b(cid:6), b(cid:6)+1, . . . , bm, e, and for every a ∈ A, the same index ka wouldalso satisfy the requirements of the ND-simulation definition for system S(W ∪ U )—the new behaviors are not used andthey cannot either remove or inhibit other behaviors capabilities. This shows that (cid:15)W ⊗ U is an ND-simulation relation ofTT by TS(W ∪U ) and, hence, (cid:15)W ⊗ U ⊆ (cid:15)W ∪U , as (cid:15)W ∪U is the largest ND-simulation relation of TT by TS(W ∪U ). (cid:2)(cid:7)(cid:4). Indeed, e = e(cid:7)As it turns out, adding new behaviors has a minimal impact on the ND-simulation relation, that can be recomputedthrough simple projection operations. Unfortunately, this is not the case when behaviors become unavailable. As discussedbelow, this has, in general, a disruptive impact on the ND-simulation relation, which, in order to be recomputed, requiresmore than just local changes. To see this, let F ⊆ W be the set of indexes of those behaviors that become permanentlyunavailable, and denote by (cid:15)W|F the relation obtained from (cid:15)W by projecting out, that is dropping, the terms/argumentscorresponding to (failed) behaviors Bi such that i ∈ F . In general, the so-obtained relation just contains (possibly properly)the new largest ND-simulation after failure. Specifically, we have:Lemma 6. For S and TT as above, let W , F ⊆ {1, . . . , n} be such that F ⊆ W . The following holds:• (cid:15)(W \F ) ⊆ (cid:15)W|F ;• (cid:15)W|F may not be an ND-simulation relation of TT by TS(W \F ).Proof. By Lemma 5, (cid:15)(W \F ) ⊗ F ⊆ (cid:15)(W \F )∪F , that is, (cid:15)(W \F ) ⊗ F ⊆ (cid:15)W . By projecting out F on both relations, we get(cid:15)(W \F ) ⊗ F |F ⊆ (cid:15)W|F . Then, since (cid:15) ⊗ X| X = (cid:15) for any (cid:15) and X , (cid:15)(W \F ) ⊆ (cid:15)W|F follows.It is immediate to find cases where the containment is proper, and hence the second part follows. (cid:2)Notice that even though (cid:15)W is the largest ND-simulation relation when all behaviors in W are active, the projectedrelation (cid:15)W |F is not necessarily even an ND-simulation relation for the (contracted) system S(W \ F ).In light of these results, we next show how to deal with failure cases (d) and (e).Permanent unavailability. When a behavior becomes permanently unavailable (cf. case (d)), one cannot wait for it to resume.Instead, one can either continue to executing the composition (controller) and just “hope for the best”, i.e., that the failedbehavior will not be actually required (because, e.g., some actions occurring in the target behavior are not executed atruntime), or one can “refine” the current composition so as to continue guaranteeing the full realization of the targetbehavior.Assume that, at some point, while a composition built from an ND-simulation relation is executing, a set of availablebehaviors become unavailable. Clearly, the current composition is no longer sound (as some required behaviors might be un-available), the ND-simulation relation is no longer useful, and one is required to recompute a new one (and a corresponding122G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142Fig. 5. An ND-simulation relation between enacted target behavior TT and enacted system TS({1,3}).composition) in order to keep executing the target behavior. Of course, the new ND-simulation relation can always be com-puted “from scratch”, by considering only the set of currently available behaviors. However, from the computational pointof view this might not be the best solution, as it does not take advantage of what has been previously computed. In thefollowing, we propose a different approach, based on the above results, that aims at minimizing the required computationaleffort by refining, rather than recomputing, the ND-simulation relation at hand.Lemma 6 essentially says that, when some behaviors become unavailable, in order to compute the new ND-simulationrelation, it is enough to execute the NDSP algorithm by instantiating Rinit with the relation obtained by projecting out thefailed components from the current ND-simulation relation. This yields, in general, substantially less algorithm iterationsthan NDS. Indeed, as behaviors become unavailable, the effort to obtain the new largest ND-simulation relation is systematicand incremental, in that no tuples that were previously discarded are considered again. This, along with Lemma 4 leads tothe followingTheorem 7. Consider S, BT and TT as above. Let W ⊆ {1, . . . , n} contain the indexes of the behaviors currently working in S and letF ⊆ W contain the indexes of the behaviors that, at a given point, become permanently unavailable. Then, for every relation β suchthat β ⊆ (cid:15)(W \F ), the following holds:(cid:15)(W \F ) = NDSP(TT , TS(W \F ), (cid:15)W |F , β).Proof. Direct consequence of Lemmas 4 and 6. (cid:2)Example 7. Suppose that arm BT (Fig. 1) is being successfully realized by means of controller P 1 (Fig. 3). Assume thatarm B2 breaks down in state b3, just after painting a block. With B2 out, controller P 1 cannot guarantee BT realizationanymore—yet, interestingly, this can now be done by controller P 2 on the new (unexpected) sub-system. To handle sucha failure case, first, behavior B2 is projected out from the ND-simulation relation (cid:15){1,2,3}, thus getting (cid:15){1,2,3}|{2}; then,the new largest ND-simulation relation is computed with NDSP starting from relation (cid:15){1,2,3}|{2}, thus obtaining (cid:15){1,3}—from which a new CG and a corresponding composition can be derived. The result is shown in Fig. 5, where the enactedtarget behavior is the same as in Fig. 4(b), reported here for convenience. Like in Example 4, matching filling patternsindividuate pairs in the ND-simulation relation. Observe that tuple (cid:3)(cid:3)t3, e3(cid:4), (cid:3)(cid:3)a2, c1(cid:4), e3(cid:4)(cid:4) belongs to relation (cid:15){1,2,3}|{2}, butis filtered out by the NDSP algorithm (the original tuple (cid:3)(cid:3)t3, e3(cid:4), (cid:3)(cid:3)a2, b2, c1(cid:4), e3(cid:4)(cid:4) ∈ (cid:15){1,2,3} relied on B2 for maintainingthe ND-simulation).Resumed behaviors. Consider now the situation where the operating behaviors are those with indexes in W , and others,supposed to be permanently unavailable, become unexpectedly available (cf. case (e)). Let U be the set of indexes of suchbehaviors, with U ∩ W = ∅. As already observed, this never reduces the capabilities of the whole system but could enhanceit with more choices, or, differently said, after behaviors in U become available again, the system can still realize at leastthe same executions as before. However, if one wants to exploit the further capabilities brought by the resumed behaviors,the new largest ND-simulation relation (cid:15)(W ∪U ) must be computed. In doing so, one can leverage on the fact that (cid:15)(W ∪U )contains relation (cid:15)W ⊗ U (cf. Lemma 5) and completely neglect, for potential filtering, tuples in (cid:15)W ⊗ U . That is, such tuplescan be provided in input to the NDSP algorithm as the “sure set”.G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142123Theorem 8. Consider S, BT and TT as above. Let W ⊆ {1, . . . , n} contain the indexes of the behaviors currently working in S, andU ⊆ {1, . . . , n}, with W ∩ U = ∅, the indexes of those that were assumed permanently unavailable but have unexpectedly resumed.Then, for every set α such that (cid:15)(W ∪U )⊆ α, the following holds:(cid:15)(W ∪U ) = NDSP(TT , TS(W ∪U ), α, (cid:15)W ⊗ U ).Proof. Consequence of Lemmas 4 and 5. (cid:2)As it turns out, this requires, in general, less iterations than those required for computing the ND-simulation relationfrom scratch, as tuples considered by NDS are not processed by NDSP. Observe that even if new behaviors not appearing in{1, . . . , n} are included in U , the thesis of Lemma 5 still holds. Therefore, if the system is enriched with new behaviors, onecan use the largest ND-simulation relation previously computed, in order to save computational efforts, when computingthe new ND-simulation relation.Reusing previously computed ND-simulations. Theorems 7 and 8 essentially show that, by using algorithm NDSP, when a be-havior resumes or becomes unavailable and a new ND-simulation relation needs to be re-computed, one can take advantageof the ND-simulation relation previously computed. In fact, such theorems can be combined so as to reuse not only the lastND-simulation relation computed, but all those computed in the past (assuming they have been stored).To see this, let W ⊆ 2, such that {1, . . . , n} ∈ W , be a set of sets of behavior indices, and assume that the largestND-simulation relation for each set in W has been already computed and stored. For W /∈ W , in order to compute the(largest) ND-simulation relation (cid:15)W , one can first define the following sets:{1,...,n}} (cid:15)W (cid:7) |(W (cid:7)\W );} (cid:15)W (cid:7) ⊗ (W \ W(cid:7));(cid:8)¯α =¯β ={W (cid:7)∈(cid:3)WW(cid:2){W (cid:7)∈(cid:4)WWW and (cid:5)W(cid:3)=W(cid:4)WW(cid:5)WW(cid:3)=Wwhere (cid:4)WW stand for the set of tightest supersets and subsets, respectively, of W in W , namely:(cid:7) ∈ W(cid:7) ∈ W(cid:7) ∧ ∀V ∈ W.W ⊆ V → V (cid:12)⊂ W(cid:7) (cid:12)⊂ V(cid:7) ⊆ W ∧ ∀V ∈ W.V ⊆ W → W(cid:4)(cid:4) W ⊆ W(cid:4)(cid:4) W;(cid:5)(cid:5).(cid:7)(cid:7)Then, by applying Theorems 7 and 8, (cid:15)W can be computed as follows:(cid:15)W = NDSP(TT , TS(W ), ¯α, ¯β).Clearly, by using NDSP(TT , TS (W ), ¯α, ¯β) to compute (cid:15)W , the computations already carried out are maximally reused todevise other ND-simulation relations, as ¯α and ¯β are the tightest sets one can obtain starting from the ND-simulationrelations for sets in W . Of course, once computed (cid:15)W , CGPjit can be immediately computed on-the-fly, as before.We close this section by noting that the kind of failures considered can be seen as core classes of breach-of-contract, withrespect to the specification. Other forms of failures are clearly conceivable [88,64,55], which assume additional informationat hand—e.g., a module may announce unavailability duration and/or the state (or possible states) it will join back—and thatcan be exploited for failure reaction, thus opening interesting research directions. However, covering a wider range of failurecases is out of the scope of the present paper, and we limit our attention only to the classes presented above.5. Simulation and safety gamesIn previous sections, we have shown that the behavior composition problem can be reduced to the problem of finding anND-simulation relation between two transition systems that, together, describe the original problem instance. Moreover, wehave discussed optimization approaches to obtain computational benefits, when computing a new ND-simulation relation inresponse to different type of failures. In the rest of the paper, we adopt a more pragmatic perspective, and focus on findingeffective ways for actually computing an ND-simulation relation. Concretely, we will demonstrate how controller generatorscan be synthesized by applying model checking techniques.We begin by laying down the theoretical bases for actually solving the behavior composition problem, and show thatan ND-simulation relation can be constructed by resorting to infinite games. In particular, we argue that constructing anND-simulation relation is equivalent to building a winning strategy in a safety game (cf. [5,6,69]).10 The main motivationbehind the use of game structures is the availability of software tools, such as tlv [71], Lily [44], Anzu [45], and Mocha [4],which provide (i) effective procedures for strategy computation; and (ii) convenient languages for representing the probleminstance in a modular and high-level manner. In fact, the next section explains in detail how to solve behavior compositionproblem instances using the tlv system.10 Safety games are those where some condition—the invariant property—needs to always be maintained, in our case: TS is always able to “locally” (i.e.,state-by-state) mimic TT .124G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–1425.1. Safety-game structuresWe consider the notion of game structure proposed in [69], specialize it to safety games (see, e.g., [5]), and adapt liter-ature results [5,6] to solve the resulting problem. Roughly speaking, a safety-game structure represents a game played bytwo players, system and controller,11 where, at each turn, the former moves and the latter replies. Moves are subject toconstraints (i.e., only some moves/replies are allowed in a given game state). Intuitively, the controller ’s objective is toalways be able to reply to system ’s moves so as to satisfy a given (goal) property, while the system tries to avoid this.Throughout the rest of the paper, we assume to deal with infinite-play (though finite state) games, possibly obtainedby introducing fake loops, as customary, e.g., in ltl verification. Infinite plays are assumed for technical convenience only,so as to handle all plays—finite or infinite—in a uniform way. This assumption, however, does not limit the power of gamestructures (for technical details about plays, see below).A safety-game structure ((cid:2)-GS, for short) is a tuple G = (cid:3)V, X , Y, Θ, ρs, ρc, (cid:2)ϕ(cid:4), where:• V = {v 1, . . . , vn} is the finite set of state variables, which range over finite domains V 1, . . . , V n, respectively. Set V ispartitioned into sets X = {v 1, . . . , vm} (the system variables) and Y = {vm+1, . . . , vn} (the controller variables). A valuationof variables in V is a total function val : V −→i=1 V i such that val(v i) ∈ V i , for each i ∈ {1, . . . , n}. For convenience,we represent valuations as vectors (cid:24)s = (cid:3)s1, . . . , sn(cid:4) ∈ V , where V = V 1 × · · · × V n and si = val(v i), for each i ∈ {1, . . . , n}.Consequently, (sub)valuations of variables in X (resp. Y ) are represented by vectors (cid:24)x ∈ X ((cid:24)y ∈ Y ), with X = V 1 × · · · ×V m (Y = V m+1 × · · · × V n). A game state is a valuation (cid:24)s = (cid:3)s1, . . . , sn(cid:4) ∈ V , and its sub-vectors (cid:24)x = (cid:3)s1, . . . , sm(cid:4) ∈ X and(cid:24)y = (cid:3)sm+1, . . . , sn(cid:4) ∈ Y are the corresponding system and controller states, respectively. By a slight abuse of notation,we shall also write (cid:24)s = (cid:3)(cid:24)x, (cid:24)y(cid:4).(cid:2)n• Θ is a formula representing the initial states of the game. Technically, it is a boolean combination of expressions of theform (v i = si), where v i ∈ V , for some i ∈ {1, . . . , n}, and si ∈ V i . Each of such expressions is an assignment constraint,satisfied by state (cid:24)s = (cid:3)s1, . . . , sn(cid:4) if val(v i) = si . In general, not all variables in V are required to occur in Θ . Given agame state (cid:3)(cid:24)x, (cid:24)y(cid:4) ∈ V , we write (cid:3)(cid:24)x, (cid:24)y(cid:4) |(cid:25) Θ if (cid:3)(cid:24)x, (cid:24)y(cid:4) satisfies, in the obvious way, the boolean combination of assignmentconstraints specified by Θ .• ρs ⊆ X × Y × X is the system transition relation, which relates each game state to its possible successor system states.• ρc ⊆ X × Y × X × Y is the controller transition relation, relating each game state together with one its successor systemstates (i.e., move), to possible successor controller states.• (cid:2)ϕ is the goal formula, representing the invariant property to be guaranteed, where ϕ has the same form as Θ above.The above definition is completed by enforcing the infinite-play game assumption, informally stated above, by requiring thatfor each game state (cid:3)(cid:24)x, (cid:24)y(cid:4) ∈ V :• there exists an (cid:24)x(cid:7)• for all (cid:24)x(cid:7) ∈ X such that ρs((cid:24)x, (cid:24)y, (cid:24)x(cid:7)); and(cid:7)), there exists a (cid:24)ysuch that ρs((cid:24)x, (cid:24)y, (cid:24)x(cid:7) ∈ Y such that ρc((cid:24)x, (cid:24)y, (cid:24)x(cid:7), (cid:24)y(cid:7)).In the rest of the paper, when no ambiguity arises, we will use “game structure” or simply “game” to refer to a safety-game(cid:7)structure. The idea behind game structures is that, with the game in some state (cid:24)s = (cid:3)(cid:24)x, (cid:24)y(cid:4), the system moves, by choosing (cid:24)x(cid:7), (cid:24)y(cid:7)). Each pair of system move andsuch that ρs((cid:24)x, (cid:24)y, (cid:24)x(cid:7)(cid:4). Note that the controller is allowed(cid:7) = (cid:3)(cid:24)xsubsequent controller reply defines a game transition from (cid:24)s = (cid:3)(cid:24)x, (cid:24)y(cid:4) to state (cid:24)s(cid:7)to observe the system move before replying, as witnessed by the presence of (cid:24)xsuch that ρc((cid:24)x, (cid:24)y, (cid:24)x(cid:7), (cid:24)yin ρc((cid:24)x, (cid:24)y, (cid:24)x(cid:7)), and the controller then replies, by choosing (cid:24)y(cid:7), (cid:24)y(cid:7)).(cid:7)(cid:7), (cid:24)y(cid:7), (cid:24)y(cid:7)(cid:4) is a successor of a state (cid:3)(cid:24)x, (cid:24)y(cid:4) iff ρs((cid:24)x, (cid:24)y, (cid:24)xWith the formal notion of games at hand, let us next define the corresponding dynamics and the notion of winning in a(cid:7)). A game play starting from stategame. A game state (cid:3)(cid:24)x(cid:3)(cid:24)x0, (cid:24)y0(cid:4) ∈ V is an infinite sequence of states η = (cid:3)(cid:24)x0, (cid:24)y0(cid:4)(cid:3)(cid:24)x1, (cid:24)y1(cid:4) · · · such that for each j (cid:2) 0, (cid:3)(cid:24)x j+1, (cid:24)y j+1(cid:4) is a successor of(cid:3)(cid:24)x j, (cid:24)y j(cid:4). Clearly, by the infinite-play assumption, every game always admits at least a play. Intuitively, plays capture (infinite)sequences of game states obtained by alternating system moves and controller replies. A play is said to be winning (for thecontroller ) if it satisfies the winning condition (cid:2)ϕ, that is, (cid:3)(cid:24)xi, (cid:24)yi(cid:4) |(cid:25) ϕ, for all i (cid:2) 0. The intuition is that the play remainswithin a set of safe states, i.e., which satisfy the invariant property.(cid:7)) and ρc((cid:24)x, (cid:24)y, (cid:24)x(cid:7), f ((cid:3)(cid:24)x0, (cid:24)y0(cid:4), (cid:24)x1 · · · (cid:24)xn(cid:24)xA (controller ) strategy is a partial(cid:7)),(cid:7))) holds. A play η = (cid:3)(cid:24)x0, (cid:24)y0(cid:4)(cid:3)(cid:24)x1, (cid:24)y1(cid:4) · · · is compliant with a strategy f: ( X × Y ) × Xfor every (finite) sequence ofgame states λ : (cid:3)(cid:24)x0, (cid:24)y0(cid:4) · · · (cid:3)(cid:24)xn, (cid:24)yn(cid:4) and for every system state (cid:24)xit is the case thatρc((cid:24)xn, (cid:24)yn, (cid:24)xif (cid:24)y(cid:6) = f ((cid:3)(cid:24)x0, (cid:24)y0(cid:4),(cid:24)x1 · · · (cid:24)x(cid:6)), for all (cid:6) > 0, that is, intuitively, all controller replies in the play match those the strategy prescribes. A strategy fis winning from a state (cid:24)s if all plays starting from (cid:24)s and compliant with f are winning. A strategy fis winning for a gameG if fis winning from all of G’s initial states. We say that a game is winning (for the controller ) if there exists a winningstrategy for it, and that a game state is winning if there exists a winning strategy from that state. The winning set of a gameG is the set of all winning states of that game.+ (cid:9)→ Y such that(cid:7) ∈ X such that ρs((cid:24)xn, (cid:24)yn, (cid:24)xfunction f11 To avoid confusion with our previous notation, we adopt a notation different from that of [69], in which the players are the environment (our system)and the system (our controller).G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142125Algorithm 3: WIN—Computes a safety-game structure’s winning set.:= {(cid:3)(cid:24)x, (cid:24)y(cid:4) ∈ V | (cid:3)(cid:24)x, (cid:24)y(cid:4) |(cid:25) ϕ};(cid:7)1 W2 repeat3W := W(cid:7)(cid:7);:= W ∩ π (W ) ;(cid:7));W45 until (W = W6 return W ;// current candidate set// compute next candidate setIntuitively, a game is winning if the controller can control the game evolution, through a winning strategy that affectsonly Y variables, so as to guarantee that the winning condition ϕ holds along all game plays, no matter how the systemmoves happen to be. In order to prove that a game is winning, one thus needs to prove the existence of a winning strategy,which is clearly equivalent to showing that the set of game’s initial states is a subset of the winning set.Next, we show how one can compute the winning set of a given safety-game structure G = (cid:3)V, X , Y, Θ, ρs, ρc, (cid:2)ϕ(cid:4). Thekey ingredient is the following operator π : 2V −→ 2V (see [5]):(cid:3).=(cid:6)(cid:7)(cid:6)(cid:7)(cid:5)(cid:7)(cid:3)(cid:24)x, (cid:24)y(cid:4) ∈ V | ∀ (cid:24)xπ (P ), (cid:24)yIntuitively, given a set of game states P ⊆ V , π (P ) denotes the set of P ’s controllable predecessors, that is, the set of all gamestates from which the controller can force the play to reach a state in P , no matter how the system happens to move. Usingthis operator, Algorithm 3 [5] can be applied to compute the set of all G’s winning states, as proven below.→ ∃ (cid:24)y(cid:7)(cid:24)x, (cid:24)y, (cid:24)x(cid:7)(cid:24)x, (cid:24)y, (cid:24)x(cid:7)(cid:4) ∈ P(cid:7)∧ (cid:3)(cid:24)x.ρc.ρs, (cid:24)y.(cid:7)(cid:7)(cid:7)The algorithm essentially computes a fixpoint, starting from the set of all game states that satisfy the goal formula ϕ.(the next “candidate” set) contains all those game states that satisfy ϕ, and from which theAfter the first iteration, Wcontroller has a strategy to force, in one step, the game to a state that satisfies ϕ. The process is then iterated, by refiningthe current candidate set W , ruling out all those states that are not controllable predecessors of W . At the end of then-th iteration, W contains all those game states from which the controller has a strategy to make the game traverse nstates satisfying ϕ, independently of system moves. When a fixpoint is reached, n can be replaced by ∞. Termination of thealgorithm is evident, as no new states are ever added to W . The following theorem, which shows that the obtained set isindeed the winning set, rephrases previous results from [5] and [6] within our game framework.Theorem 9. Let G = (cid:3)V, X , Y, Θ, ρs, ρc, (cid:2)ϕ(cid:4) be a safety-game structure as above, and let W be obtained by running Algorithm 3on G. Given a game state (cid:3)(cid:24)x0, (cid:24)y0(cid:4) ∈ V , there exists a winning strategy from (cid:3)(cid:24)x0, (cid:24)y0(cid:4) if and only if (cid:3)(cid:24)x0, (cid:24)y0(cid:4) ∈ W .Proof. (If Part) When the algorithm returns, it is the case that WW ∩ π (W ) and therefore W ⊆ π (W ). Hence, by definition of π (W ), the following holds:(cid:7) = W . Being W(cid:7) = W ∩ π (W ), we have that W =∀(cid:3)(cid:24)x, (cid:24)y(cid:4) ∈ W ,(cid:7)) = {(cid:24)ywhere Φ((cid:24)x, (cid:24)y, (cid:24)x(cid:7)has just played (cid:24)x(cid:6)∀(cid:24)x(cid:7) ∈ X.ρs(cid:7) | ρc((cid:24)x, (cid:24)y, (cid:24)xfrom game state (cid:3)(cid:24)x, (cid:24)y(cid:4).(cid:7)(cid:24)x, (cid:24)y, (cid:24)x(cid:7), (cid:24)y(cid:7)) ∧ (cid:3)(cid:24)x(cid:7)(cid:6)→ Φ(cid:7), (cid:24)y(cid:7)(cid:7)(cid:24)x, (cid:24)y, (cid:24)x(cid:12)= ∅,(1)(cid:7)(cid:4) ∈ W } represents, informally, the set of all “good” moves when the systemUsing set Φ, we consider next any strategy f ((cid:3)(cid:24)x, (cid:24)y(cid:4), λ) satisfying the following constraint (here (cid:6) (cid:2) 1):(cid:6)(cid:3)(cid:24)x0, (cid:24)y0(cid:4), (cid:24)x1 · · · (cid:24)x(cid:6)(cid:7)f∈ Φ((cid:24)x(cid:6)−1, (cid:24)y(cid:6)−1, (cid:24)x(cid:6)), whenever Φ((cid:24)x(cid:6)−1, (cid:24)y(cid:6)−1, (cid:24)x(cid:6)) (cid:12)= ∅,where (cid:24)y(cid:6)−1 = f ((cid:3)(cid:24)x0, (cid:24)y0(cid:4), (cid:24)x1 · · · (cid:24)x(cid:6)−1), when (cid:6) > 1 (when (cid:6) = 1, (cid:24)y(cid:6)−1 = (cid:24)y0).Next, let us prove that strategy fis indeed a winning strategy from the initial game state. To that end, all we have todo is to show that for any game play η = (cid:3)(cid:24)x0, (cid:24)y0(cid:4)(cid:3)(cid:24)x1, (cid:24)y1(cid:4) · · · from game state (cid:3)(cid:24)x0, (cid:24)y0(cid:4) and compliant with strategy f , it isthe case that (cid:3)(cid:24)xi, (cid:24)yi(cid:4) ∈ W , for all i (cid:2) 0. Observe that for any game state (cid:3)(cid:24)x, (cid:24)y(cid:4) ∈ W , it is the case that (cid:3)(cid:24)x, (cid:24)y(cid:4) |(cid:25) ϕ. This isbecause the algorithm starts exactly with the game states that satisfy ϕ (line 1) and only removes states from the candidateset (line 4). So, let us prove that (cid:3)(cid:24)xi, (cid:24)yi(cid:4) ∈ W , for all i (cid:2) 0, by induction on the index i. The base case when i = 0 is trivial,as (cid:3)(cid:24)x0, (cid:24)y0(cid:4) ∈ W holds by assumption.Next, suppose that for (cid:3)(cid:24)xi, (cid:24)yi(cid:4) ∈ W ,for some k (cid:2) 0. Because η is a game play,it is the casethat ρs((cid:24)xk, (cid:24)yk, (cid:24)xk+1). Also, by the induction hypothesis, (cid:3)(cid:24)xk, (cid:24)yk(cid:4) ∈ W . Therefore, by applying Eq. (1), we have thatΦ((cid:24)xk, (cid:24)yk, (cid:24)xk+1) (cid:12)= ∅. From this—together with the fact that (cid:24)yk = f ((cid:3)(cid:24)x0, (cid:24)y0(cid:4), (cid:24)x1 · · · (cid:24)xk) when k > 0, as play η is compliantwith f —it follows that f ((cid:3)(cid:24)x0, (cid:24)y0(cid:4), (cid:24)x1 · · · (cid:24)xk+1) = (cid:24)yk+1 ∈ Φ((cid:24)xk, (cid:24)yk, (cid:24)xk+1), and by definition of set Φ, (cid:3)(cid:24)xk+1, (cid:24)yk+1(cid:4) ∈ W follows.(Only-If Part) Let W i be the version of W at i-th iteration (at line 5), where 1 (cid:3) i (cid:3) N, assuming the algorithm ter-minates in N iterations and hence it returns W N . We show, by induction on index i, that for any game state (cid:3)(cid:24)x, (cid:24)y(cid:4), if(cid:3)(cid:24)x, (cid:24)y(cid:4) /∈ W i , and hence (cid:3)(cid:24)x, (cid:24)y(cid:4) /∈ W N , then the system can always force from state (cid:3)(cid:24)x, (cid:24)y(cid:4) to reach, in at most i steps, a state(cid:3)(cid:24)x(cid:7), (cid:24)yFor the base case, suppose that (cid:3)(cid:24)x, (cid:24)y(cid:4) /∈ W 1. Due to lines 1 and 3 of Algorithm 3, set W 1 is exactly those and onlythose states that satisfy ϕ, that is, (cid:3)(cid:24)x, (cid:24)y(cid:4) (cid:12)|(cid:25) ϕ, and the claim follows trivially. Now, assume the claim holds for all i (cid:3) k andconsider a game state (cid:3)(cid:24)x, (cid:24)y(cid:4) /∈ W k+1. If (cid:3)(cid:24)x, (cid:24)y(cid:4) /∈ W k, then the game state was removed at some previous iteration j (cid:3) k, andby the induction hypothesis, the system can force all plays to violate the goal in at most k (and hence k + 1) steps. So,(cid:7)(cid:4) such that (cid:3)(cid:24)x(cid:7)(cid:4) (cid:12)|(cid:25) ϕ.i (cid:3) k,for all(cid:7), (cid:24)y126G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142(cid:7), (cid:24)ysuppose on the other hand that (cid:3)(cid:24)x, (cid:24)y(cid:4) ∈ W k, that is, the game state was removed at the k + 1 iteration (in line 4). From line 4in the algorithm, we know that W k+1 = W k ∩ π (W k). Since (cid:3)(cid:24)x, (cid:24)y(cid:4) ∈ W k but (cid:3)(cid:24)x, (cid:24)y(cid:4) /∈ W k+1, it follows that (cid:3)(cid:24)x, (cid:24)y(cid:4) /∈ π (W k).(cid:7) ∈ Y with(cid:7) ∈ X , with ρs((cid:24)x, (cid:24)y, (cid:24)xBy definition of π , there the system has a move (cid:24)x(cid:7)(cid:4) /∈ W k. By the induction hypothesis, the system can always force from game stateρc((cid:24)x, (cid:24)y, (cid:24)x(cid:7), (cid:24)y(cid:3)(cid:24)xfrom the initial state (cid:3)(cid:24)x, (cid:24)y(cid:4), the system isalways able to force violating ϕ in at most k + 1 steps.(cid:7)(cid:7)(cid:4) to reach, in at most k steps, a state that violates ϕ. Thus, by playing (cid:24)x(cid:7)), such that for all controller replies (cid:24)y(cid:7)), it is the case that (cid:3)(cid:24)xNow, suppose that there exits a winning strategy f from state (cid:3)(cid:24)x0, (cid:24)y0(cid:4), but on the contrary, that (cid:3)(cid:24)x0, (cid:24)y0(cid:4) /∈ W , or whatis the same, that (cid:3)(cid:24)x0, (cid:24)y0(cid:4) /∈ W N . By our reasoning above, the system can always force the game to violate ϕ in at mostN steps. This implies that there exits a game play η = (cid:3)(cid:24)x0, (cid:24)y0(cid:4)(cid:3)(cid:24)x1, (cid:24)y1(cid:4) · · · (i.e., starting from (cid:3)(cid:24)x0, (cid:24)y0(cid:4)) and compliant with fsuch that for some i < N, (cid:3)(cid:24)x1, (cid:24)y1(cid:4) (cid:12)|(cid:25) ϕ applies. Hence,f would not be a winning strategy from (cid:3)(cid:24)x0, (cid:24)y0(cid:4), a contradiction isreached, and it follows then that (cid:3)(cid:24)x0, (cid:24)y0(cid:4) ∈ W must apply. (cid:2)(cid:7), (cid:24)yImportantly, once the winning set is computed, it can be used to define a winning strategy [5,6]. To see this, assume(cid:7) ∈ X (such that(cid:7), (cid:24)y(cid:7))).(cid:7)(cid:4) ∈ W (and ρc((cid:24)xn, (cid:24)yn, (cid:24)x(cid:7)(cid:4), informally meaning that it canthat η = (cid:3)(cid:24)x0, (cid:24)y0(cid:4) . . . (cid:3)(cid:24)xn, (cid:24)yn(cid:4) is the prefix of a play executed up to some point. For each next system move (cid:24)x(cid:7)ρs((cid:24)xn, (cid:24)yn, (cid:24)xIndeed, such a condition guarantees that the controller has a winning strategy from (cid:3)(cid:24)xforce the (future extension of the) play to maintain ϕ.(cid:7))), one can define f ((cid:3)(cid:24)x0, (cid:24)y0(cid:4), (cid:24)x1 . . . (cid:24)xn(cid:24)xsuch that (cid:3)(cid:24)x(cid:7), (cid:24)y, by taking any reply (cid:24)y(cid:7)) = (cid:24)y(cid:7), (cid:24)y(cid:7)5.2. From composition to safety gamesNext, we show how the behavior composition problem can be reduced in practice to the problem of synthesizing a win-ning strategy in a safety-game structure. In order to do so, we need to identify which place each component of a compositionproblem—target behavior, available behaviors, environment, and composition controller—occupies in the game represen-tation, that is, players controller and system need to be defined for the particular setting. Generally speaking, whencomposing behaviors, a controller can be seen as a strategy, i.e., a function of system histories that returns decisions, so,from this perspective, it seems very natural to represent the composition as the (synthesized strategy for) controller player,and all other components combined together as the system player.Let S = (cid:3)B1, . . . , Bn, E(cid:4) be a system and BT a target behavior over E , where Bi = (cid:3)B i, bi0, G i, F i, (cid:3)i(cid:4), for i = 1, . . . , n, T ,and E = (cid:3)A, E, e0, ρ(cid:4). We derive a safety-game structure G(cid:3)S,BT (cid:4) = (cid:3)V, X , Y, Θ, ρs, ρc, (cid:2)ϕ(cid:4) that captures the relationshipbetween the target behavior and the system, as follows:1. V = {b1, . . . , bn, e, bT , a, ind}, where:• bi ranges over B i , for each i ∈ {1, . . . , n, T };• e ranges over E;• a ranges over A ∪ {(cid:19)};• ind ranges over {1, . . . , n} ∪ {(cid:19)}.Here, V = B1 × · · · × Bn × E × B T × (A ∪ {(cid:19)}) × {1, . . . , n, (cid:19)} is the set of all possible valuations.2. X = {b1, . . . , bn, e, bT , a} is the set of player system variables, and X = B 1 × · · · × Bn × E × B T × (A ∪ {(cid:19)}) represents theset of all possible valuations.3. Y = {ind} is the (singleton) set of player controller variables, and Y = {1, . . . , n, (cid:19)} represents the set of all possible(cid:7), b(cid:7)T , a(cid:7)(cid:4)(cid:4) ∈ ρs iff a(cid:7) ∈ {(cid:19)} ∪ {ˆa | e(cid:7)ˆa−→ e(cid:7)(cid:7)in E, b(cid:7)T(cid:7)gT ,ˆa−→valuations.4. Θ = (ind = (cid:19)) ∧ (a = (cid:19)) ∧(cid:9)i∈{1,...,n,T } bi = bi0 ∧ e = e0;5. ρs ⊆ X × Y × X is such that (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), ind, (cid:3)b(cid:7)n, e(cid:7)) = (cid:10)} and one of the following three cases applies:(cid:7)1, . . . , b= bi0, for each i ∈ {1, . . . , n, T }, and e(cid:7) = e0;(cid:7)T (e(cid:7)(cid:7)T in BT , gb(a) ind = (cid:19) and b(b) ind (cid:12)= (cid:19) and(cid:7)ii. there exists a transition bTgT ,a−→ b(cid:7)T in BT such that gT (e) = (cid:10);gind,a−→ b(cid:7)ind in Bind such that gind(e) = (cid:10);(cid:7)i , for all i ∈ {1, . . . , n} \ {ind};a−→ e(cid:7)in E ; orii. there exists a transition bindiii. bi = biv. there exists a transition e(cid:7) = e and b(c) ind (cid:12)= (cid:19), e(cid:7)ii. there is no transition bTii. there is no transition bindiii. there is no transition e6. (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), ind, (cid:3)b(cid:7)1, . . . , bgT ,a−→ b(cid:7)(cid:7)T in BT such that gT (e) = (cid:10);gind,a−→ b(cid:7)ind in Bind such that gind(e) = (cid:10); or(cid:7)(cid:7)in E .(cid:7)(cid:7), bT , a(cid:7)(cid:4) ∈ ρc iff inda−→ e(cid:7)n, e(cid:7)(cid:4), ind(cid:7) (cid:12)= (cid:19).= bi , for each i ∈ {1, . . . , n, T }, and at least one of the following conditions applies:G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–1421277. Formula ϕ is defined depending on current system, target, and environment state, current requested action and currentbehavior selection12:(cid:10)ϕ(b1, . . . , bn, e, bT , a, ind).=validReq →(cid:12)(cid:10)¬faili∧finalT→(cid:12)finali,n(cid:11)i=1n(cid:11)i=1(cid:13)where• validReq• faili• finali.=.= ind = i ∧(cid:13).=b∈F igT (e) = (cid:10);(cid:3)bT ,gT ,a,b(cid:9)(cid:7)(cid:4)∈(cid:3)TT(cid:7)(cid:3)bi ,gi ,a,bi(cid:4)∈(cid:3)i(bi = b), for each i ∈ {1, . . . , n, T }.gi(e) = ⊥, for each i ∈ {1, . . . , n};Intuitively, the system player represents all possible evolutions of S generated by legal executions of BT , which areindeed the only evolutions relevant to our problem. Each complete valuation of variables in V captures the current stateof the system (variables b1, . . . , bn, and e), that of the target behavior (variable bT ), the action to be performed next(variable a), and the available behavior selected to perform the action (variable ind). For technical convenience, a specialvalue (cid:19) is used for both the action request and the delegation, to represent a request for “no action” (a = (cid:19)) and the initialdistinguished states of the game (ind = (cid:19)).As for the evolution of the game, the player system’s transition relation ρs accounts for the synchronous evolution of thesystem and the target behavior. Condition 5(a) states that initial game states—those where ind = (cid:19)—evolve to states encod-ing S’s and BT ’s initial states. Condition 5(b) encodes the evolution of system S when the controller has performed a validaction delegation. Basically, the new state of player system encodes the correct evolution of the target (condition 5(b)i),the selected available behavior (condition 5(b)ii), the non-selected behaviors (condition 5(b)iii), and the environment (con-dition 5(b)iv). Condition 5(c), on the other hand, accounts for the cases in which there is no valid behavior delegationpossible, either because the current action being requested is not target-compatible (condition 5(c)i), cannot be handled byany available behavior (condition 5(c)ii), or is not allowed in the environment (condition 5(c)iii). In these cases, all behaviorsand the environment are forced to stay still. Note that condition 5(c) accounts for the case of an “empty” action request,that is, when a = (cid:19). Finally, the next requested action acan either be (cid:19)—denoting no request—or one that conforms withthe target behavior logic. Observe that in a certain game state, transition function ρs may allow several different systemplayer’s moves, thus reflecting the non-determinism coming from the available behaviors, the environment, as well as fromtarget action requests.(cid:7)The rules for controller player’s moves are simpler, as such player is allowed to arbitrarily assign any available behaviorindex in any of its moves (condition 6).To fully comply with our definition of safety-game structures given in Section 5.1, we need to show that G(cid:3)S,BT (cid:4) sat-isfies the infinite-play assumption. For legibility, from now on, when (cid:24)xi = (cid:3)b1i, . . . , bni, ei, bT i, ai(cid:4) is a system player statein G(cid:3)S,BT (cid:4), we will use comT ((cid:24)xi) = (cid:3)bT i, ei(cid:4) and comS ((cid:24)xi) = (cid:3)b1i, . . . , bni, ei(cid:4) to project the enacted target and the enactedsystem states encoded in (cid:24)xi , respectively, and a((cid:24)xi) = ai to project the action request encoded in (cid:24)xi . A game state is of theform (cid:3)(cid:24)x, y(cid:4).Lemma 10. Let G(cid:3)S,BT (cid:4) be the safety-game structure derived for a behavior composition problem, as above. Then, for each game state(cid:7)(cid:3)(cid:24)x, y(cid:4), there exists (cid:24)x(cid:7)(cid:7)), and for each such (cid:24)xsuch that ρc((cid:24)x, y, (cid:24)xsuch that ρs((cid:24)x, y, (cid:24)xthere exists y(cid:7), y(cid:7)).(cid:7)Proof. If cases 5(a) and 5(b) do not account for any system player’s move, then case 5(c) will apply and ρs((cid:24)x, y, (cid:24)x(cid:7)with (cid:24)x(cid:7)(cid:7)). Moreover, for every (cid:24)x, y and (cid:24)xmatching (cid:24)x except, possibly, for a((cid:24)x(cid:7)) holds, for any y(cid:7)) will hold(cid:7) ∈ {1, . . . , n}. (cid:2)(cid:7), y, ρc((cid:24)x, y, (cid:24)xOnce proven that G(cid:3)S,BT (cid:4) is a legal safety-game structure, we show a useful property of (certain) successor game states.In words, the following lemma says that a successor game state captures a legal evolution of the enacted target behavior TTand the enacted system TS . In addition, provided the successor game state encodes an actual action request, such requestconforms with the enacted target behavior.Lemma 11. Let G(cid:3)S,BT (cid:4) be the safety-game structure derived for a behavior composition problem, as above. Let (cid:3)(cid:24)x, y(cid:4) be a (non-a((cid:24)x)−→ sT in TT , for some sS ∈ SSinitial) game state of G(cid:3)S,BT (cid:4) such that there exist transitions comS ((cid:24)x)and sT ∈ S T . Then, (cid:3)(cid:24)xa((cid:24)x), y−→ sS in TS and comT ((cid:24)x)(cid:7)(cid:4) is a successor state of (cid:3)(cid:24)x, y(cid:4) iff(cid:7), y(cid:7) (cid:12)= (cid:19);• y• comT ((cid:24)x)• comS ((cid:24)x)a((cid:24)x)−→ comT ((cid:24)xa((cid:24)x), y−→ comS ((cid:24)x(cid:7)) in TT (and, since BT is deterministic, comT ((cid:24)x(cid:7)) in TS ; and(cid:7)) = sT );12 We assume an empty set of conjuncts is equal to ⊥.128G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142• if a((cid:24)x(cid:7)) (cid:12)= (cid:19), then there exists s(cid:7)T(cid:7))∈ S T such that comT ((cid:24)x(cid:7))−→ sa((cid:24)x(cid:7)T in TT .Proof. All three claims follow directly from G(cid:3)S,BT (cid:4)’s ρs definition (see condition 5). Observe that since the system andtarget both have transitions, conditions 5(a) and 5(c) may not apply. The first claim follows from conditions 5(b)i and 5(b)iv.The second one is a consequence of conditions 5(b)ii, 5(b)iii and 5(b)iv. Finally, the third claim follows from the constraintimposed on a((cid:24)x(cid:7)). (cid:2)Finally, consider the goal formula ϕ. As for the first disjunct, it is trivially satisfied by the initial state only. Concerningthe second one, it is better understood by looking at subformulae faili and finali . The former holds if behavior Bi is selected(i.e., ind = i), but cannot execute the requested action a, that is, each transition outgoing from its current state bi for actiona has its guard not satisfied by the current environment state e. The latter holds if the target behavior is in a final state, butnot all available behaviors are. The target fails (failT ) if it requests an action incompatible with its specification. Essentially, ϕrequires that the controller player makes an adequate decisions: it never selects a behavior that may not be able to executethe current requested action.Once the game structure is built, the problem we deal with is that of synthesizing a (winning) strategy for the controllerplayer that guarantees ϕ to hold along all possible plays starting from the initial state. We shall demonstrate next that thiscorresponds to synthesizing a composition. More specifically, in Theorem 14, we will show that by computing G(cid:3)S,BT (cid:4)’swinning set, one is able to construct the controller generator.We start by exploring the relationship between G(cid:3)S,BT (cid:4)’s maximal winning set and the largest ND-simulation relation.Theorem 12. Let S = (cid:3)B1, . . . , Bn, E(cid:4) be a system and BT a target behavior over E . Let G(cid:3)S,BT (cid:4) = (cid:3)V, X , Y, Θ, ρs, ρc, (cid:2)ϕ(cid:4) be a (cid:2)-GS derived as above from S and BT , and let W ⊆ V be the maximal set of controller winning states for G(cid:3)S,BT (cid:4). Then, for all bi ∈ B i ,with i ∈ {1, . . . , n}, e ∈ E and a ∈ A ∪ {(cid:19)}:(cid:14)(cid:3)b1, . . . , bn, e, bT , a(cid:4), ind(cid:15)∈ W , for some ind ∈ {1, . . . , n}if and only if(cid:3)bT , e(cid:4) (cid:15) (cid:3)b1, . . . , bn, e(cid:4).Proof. (Only-If Part) Assume that (cid:3)(cid:24)x0, y0(cid:4) = (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), ind(cid:4) ∈ W , for some ind ∈ {1, . . . , n}. Hence, there exists awinning strategy f from (cid:3)(cid:24)x0, y0(cid:4). Using such a strategy, we define a relation R ⊆ S T × SS as follows:(cid:3)sT , sS (cid:4) ∈ R iffthere exists a game play η = (cid:3)(cid:24)x0, y0(cid:4)(cid:3)(cid:24)x1, y1(cid:4) · · · compliant with f such thatcomT ((cid:24)x(cid:6)) = sT and comS ((cid:24)x(cid:6)) = sS , for some (cid:6) (cid:2) 1.Clearly, η = (cid:3)(cid:24)x0, y0(cid:4)(cid:3)(cid:24)x, f ((cid:3)(cid:24)x0, y0(cid:4), (cid:24)x)(cid:4)(cid:3)(cid:24)x, f ((cid:3)(cid:24)x0, y0(cid:4), (cid:24)x(cid:24)x)(cid:4) · · · where (cid:24)x = (cid:3)b1, . . . , bn, e, bT , (cid:19)(cid:4) is an f -compliant play. Since,comT ((cid:24)x) = comT ((cid:24)x0) = (cid:3)bT , e(cid:4) and comS ((cid:24)x) = comS ((cid:24)x0) = (cid:3)b1, . . . , bn, e(cid:4), we get that (cid:3)(cid:3)bT , e(cid:4), (cid:3)b1, . . . , bn, e(cid:4)(cid:4)∈ R.→So, let us prove that R is indeed an ND-simulation of TT by TS , that is, we are to prove the three requirements of ND-simulations (see page 114). To that end, assume (cid:3)sT , sS (cid:4) ∈ R. By definition of R, env(sT ) = env(sS ) holds, so requirement 1holds.k) = (cid:19) or a((cid:24)xSince (cid:3)sT , sS (cid:4) ∈ R, there exists a game play η = (cid:3)(cid:24)x0, y0(cid:4)(cid:3)(cid:24)x1, y1(cid:4) · · · compliant with f such that comT ((cid:24)xk) = sT and(cid:9)ni=1 finali),comS ((cid:24)xk) = sS , for some k (cid:2) 1. Because fwhich yields requirement 2: if the target is in a final state in (cid:24)xk, so are all available behaviors.is a winning strategy, (cid:3)(cid:24)xk, yk(cid:4) |(cid:25) ϕ. Hence, (cid:3)(cid:24)xk, yk(cid:4) |(cid:25) (finalT(cid:7)= yi , for all i ∈ {0, . . . , k − 1}, and comT ((cid:24)xk) = comT ((cid:24)x(cid:7)a−→ s(cid:7)0, yk) = sT and comS ((cid:24)xk) = comS ((cid:24)xk) is a legal target transition in comT ((cid:24)x(cid:7)a−→ s(cid:7)T in TT . First, from condition 5(b)Finally, for the third requirement of ND-simulations, consider a transitions sT(cid:7)(cid:7)(cid:7)in G(cid:3)S,BT (cid:4)’s definition, it follows that there exists an f -compliant game play η(cid:7) = (cid:3)(cid:24)x= (cid:24)xi and(cid:4)(cid:3)(cid:24)x(cid:4) · · · such that (cid:24)x1, y0i(cid:7)(cid:7)k) = sS —play η(cid:7)is exactly like ηyi(cid:7)up to game state (cid:3)(cid:24)xk, yk(cid:4), except that (cid:24)xk may (possibly) encode a different requested action. Due to the rules of ρs, either(cid:7)(cid:7)a((cid:24)xk). In the former case, the third ND-simulation constraint follows(cid:7)(cid:7)trivially. So, suppose that a((cid:24)xT in TT .k) = a(cid:7) ∈ A and that sTDue to conditions 5(b)iv and 5(b)i in G(cid:3)S,BT (cid:4)’s definition, we can assume that η(cid:7)(cid:4) |(cid:25) validReq),k) is a valid target request (and hence, (cid:3)(cid:24)x(cid:7). So, from conditions 7, 5(b)ii, 5(b)iii and 5(b)iv in G(cid:3)S,BT (cid:4)’s definition, comS ((cid:24)xk)is such that comT ((cid:24)xk+1) = sis winning, and η(cid:7)f(cid:7)a((cid:24)xk), y(cid:7)(cid:7)with f , (cid:3)(cid:24)xk−→ comS ((cid:24)xk+1)k, yfollows, and requirement 3(a) of ND-simulations applies (again, it is trivially true that env(comS ((cid:24)xk+1)) = env(comT ((cid:24)xk+1))).(cid:7)(cid:7)S in TS with env(sT ). Again, since every possible evolution of the enacted system isFinally, consider any sS(cid:7)(cid:7)accounted by some successor game states (Lemma 11), we can assume that η(cid:7)is such that comS ((cid:24)xk+1) = sS . Thus, by R’s(cid:7)definition (see any such η(cid:7)S ) and condition 3(b) of ND-simulation follows.(If Part) Assume (cid:3)bT , e(cid:4) (cid:15) (cid:3)b1, . . . , bn, e(cid:4) and let ω(·,·) be the output function of the controller generator of S for BTis one such η(cid:7)(cid:7)kis still compliant with f ), it follows that R(s(cid:7)T —thereis compliant(cid:7)(cid:7)S ) = env(s(cid:7). Since a((cid:24)x(cid:4) |(cid:25) ¬fail y(cid:7)a−→ s(cid:7)k, y(cid:7)T , s(cid:7)1(cid:7)k(cid:7)k(cid:7)(see page 116).Let (cid:24)x0 = (cid:3)b1, . . . , bn, e, bT , a(cid:4). We define y0 = ω((cid:3)(cid:3)bT , e(cid:4), (cid:3)b1, . . . , bn, e(cid:4)(cid:4), a), if a ∈ A is a legal action for the target torequest at state bT when the environment is in state e; otherwise y0 can take any arbitrary value in {1, . . . , n}. It isimportant to note that, in the former case, ω((cid:3)(cid:3)bT , e(cid:4), (cid:3)b1, . . . , bn, e(cid:4)(cid:4), a) (cid:12)= ∅ and hence y0 ∈ {1, . . . , n}. This is because sinceG. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142129comS ((cid:24)x0) can mimic any possible move of comT ((cid:24)x0), including the target compatible action a, there must exist σ (cid:7) ∈ Σ suchthat (cid:3)comT ((cid:24)x0), comS ((cid:24)x0)(cid:4) a((cid:24)x0),i−→ σ (cid:7)in CG, for some i ∈ {1, . . . , n}. Note that (cid:3)comT ((cid:24)x0), comS ((cid:24)x0)(cid:4) ∈Σ is a state in CG, ascomT ((cid:24)x0) (cid:15) comS ((cid:24)x0).To prove that (cid:3) (cid:24)x0, y0(cid:4) ∈ W , we show that there is a strategy f (·,·) that is winning from game state (cid:3) (cid:24)x0, y0(cid:4). Considerthen any strategy f (·,·) such that for all sequences (cid:24)x1 · · · (cid:24)xk, with k (cid:2) 1, it is the case that f ((cid:3)(cid:24)x0, y0(cid:4), (cid:24)x1 · · · (cid:24)xk) ∈ {1, . . . , n}and(cid:6)(cid:3)(cid:24)x0, y0(cid:4), (cid:24)x1 · · · (cid:24)xk(cid:7)f(cid:6)(cid:7)(cid:3)comT ((cid:24)xk), comS ((cid:24)xk)(cid:4), a((cid:24)xk),∈ ωwhenever a((cid:24)xk) (cid:12)= (cid:19), comT ((cid:24)xk) (cid:15) comS ((cid:24)xk), and ρs((cid:24)xk−1, yk−1, (cid:24)xk) hold true. Informally, we pick any strategy that alwaysselects a behavior compatible with the controller generator output function whenever the enacted system state simulatesthe enacted target state in the last move (cid:24)xk of the system player and there is a proper action request. In all other cases, thestrategy can pick any behavior arbitrarily (but never (cid:19)).First, we argue that fis well-defined and indeed a valid strategy in G(cid:3)S,BT (cid:4). It never selects (cid:19) and hence adheresto G(cid:3)S,BT (cid:4)’s condition 6. Moreover, whenever a((cid:24)xk) (cid:12)= (cid:19), comT ((cid:24)xk) (cid:15) comS ((cid:24)xk), and ρs((cid:24)xk−1, yk−1, (cid:24)xk) apply, we can followthe same reasoning we did above for y0 to conclude that ω((cid:3)comT ((cid:24)xk), comS ((cid:24)xk)(cid:4), a((cid:24)xk)) (cid:12)= ∅. We just need to note thatbecause a((cid:24)xk) (cid:12)= (cid:19) and ρs((cid:24)xk−1, yk−1, (cid:24)xk), then a((cid:24)xk) ought to stand for an action that is legal for the target at comT ((cid:24)xk)(condition 5(b) and third claim in Lemma 11).So, let us next prove that for any f -compliant game play η = (cid:3)(cid:24)x0, y0(cid:4)(cid:3)(cid:24)x1, y1(cid:4) · · ·, it is the case that comT ((cid:24)xi) (cid:15) comS ((cid:24)xi)(i.e., (cid:3)bT i, ei(cid:4) (cid:15) (cid:3)b1i, . . . , bni, ei(cid:4)), for all i (cid:2) 0. The base case when i = 0 is trivial by definition of (cid:24)x0 and the assumption.Consider now game state (cid:3)(cid:24)xk+1, yk+1(cid:4), for some k (cid:2) 0. By induction hypothesis, comT ((cid:24)xk) (cid:15) comS ((cid:24)xk) applies. Because ηis a game play, one of the three cases of condition 5 in G(cid:3)S,BT (cid:4)’s definition must apply for each transition. First of all,because yi ∈ {1, . . . , n} for every i (cid:2) 0, condition 5(a) never applies. Now, if a((cid:24)xk) is not a legal target transition (includinga((cid:24)xk) = (cid:19)), then case 5(c) ought to apply, comT ((cid:24)xk+1) = comT ((cid:24)xk) and comS ((cid:24)xk+1) = comS ((cid:24)xk) hold, and comT ((cid:24)xk+1) (cid:15)comS ((cid:24)xk+1) follows directly.Assume next that a((cid:24)xk) does stand for a legal action transition in the target at game state (cid:24)xk, that is, (cid:3)(cid:24)xk, yk(cid:4) |(cid:25) validReq.If k = 0, then by definition of f for the first move, y0 ∈ ω((cid:3)comT ((cid:24)x0), comS ((cid:24)x0)(cid:4), a((cid:24)x0)). If k (cid:2) 1, then because comT ((cid:24)xk) (cid:15)comS ((cid:24)xk) (by induction hypothesis), a((cid:24)xk) (cid:12)= (cid:19) (by assumption), and ρs((cid:24)xk−1, yk−1, (cid:24)xk) (η is a game play), we know bydefinition of f that yk ∈ ω((cid:3)comT ((cid:24)xk), comS ((cid:24)xk)(cid:4), a((cid:24)xk)). So, yk ∈ ω((cid:3)comT ((cid:24)xk), comS ((cid:24)xk)(cid:4), a((cid:24)xk)), for all k (cid:2) 0, which impliesthat yk ∈ {1, . . . , n}, as we proved above that fBy definition of CG’s output function, (cid:3)comT ((cid:24)xk), comS ((cid:24)xk)(cid:4) a((cid:24)xk), yk−→ (cid:3)sis indeed a well-defined strategy for G(cid:3)S,BT (cid:4).(cid:7)T , sa((cid:24)xk), yk−→ s(cid:7)S (cid:4) in CG, for some s(cid:7)T and comS ((cid:24)xk)a((cid:24)xk)−→ s(cid:7)S . Due to Lemma 11, we conclude that:(cid:7)T∈ S T and sS ∈ S(cid:7)S . By CG’stransition relation ϑ , this means that comT ((cid:24)xk)comS ((cid:24)xk)comT ((cid:24)x)a((cid:24)xk), yk−→ comS ((cid:24)xk+1);a((cid:24)x)−→ comT ((cid:24)xk+1).(2)(3)(cid:7)TFrom (2) and the third condition in CG’s transition relation, it follows that (cid:3)s(cid:15) comS ((cid:24)xk+1). Due to the first requirement of ND-simulations, env(s(cid:7)T , comS ((cid:24)xk+1)(cid:4) ∈ Σ is a state in CG, and(cid:7)(cid:7)T ) = env(comS ((cid:24)xk+1)) applies. What is more,thus sT(cid:7)T ) = env(comT ((cid:24)xk+1)), since env(comS ((cid:24)xk+1)) = env(comT ((cid:24)xk+1)). This, together with (3) and the fact that the targetenv(sbehavior BT is deterministic, implies that s= comT ((cid:24)xk+1), and as a result, comT ((cid:24)xk+1) (cid:15) comS ((cid:24)xk+1) follows.So, we have proven that for any f -compliant game play η = (cid:3)(cid:24)x0, y0(cid:4)(cid:3)(cid:24)x1, y1(cid:4) · · ·,it is the case that comT ((cid:24)xi) (cid:15)i (cid:2) 1. Consider next any game state (cid:3)(cid:24)x(cid:6), y(cid:6)(cid:4) in η, with (cid:6) (cid:2) 0, and let us prove that (cid:3)(cid:24)x(cid:6), y(cid:6)(cid:4) |(cid:25) ϕ.comS ((cid:24)xi), for allFrom comT ((cid:24)x(cid:6)) (cid:15) comS ((cid:24)x(cid:6)) and requirement 2 of ND-simulations, we conclude that (cid:3)(cid:24)x(cid:6), y(cid:6)(cid:4) |(cid:25) finalT→ finali , for eachi ∈ {1, . . . , n}. Now, if a((cid:24)x(cid:6)) is not a legal transition for the target at game state (cid:24)x(cid:6) (including (cid:19)), then (cid:3)(cid:24)x(cid:6), y(cid:6)(cid:4) |(cid:25) ¬validReqfollows. Otherwise, a((cid:24)x(cid:6)) ∈ A is a target compatible action, then, by the way we defined f above, we know thaty(cid:6) ∈ ω((cid:3)comT ((cid:24)x(cid:6)), comS ((cid:24)x(cid:6))(cid:4), a((cid:24)x(cid:6))); observe comT ((cid:24)x(cid:6)) (cid:15) comS ((cid:24)x(cid:6)) and (cid:3)(cid:24)x(cid:6), y(cid:6)(cid:4) is part of a legal play respecting ρs. Thismeans that there exists a transition (cid:3)comT ((cid:24)x(cid:6)), comS ((cid:24)x(cid:6))(cid:4) a((cid:24)x(cid:6)), y(cid:6)−→ σ (cid:7)in controller generator CG, for some σ (cid:7) ∈ Σ . By CG’s(cid:7)transition relation definition, there exists a transition comS ((cid:24)x(cid:6))S in TS , which—by the notion of enacted system—implies that behavior B y(cid:6) can make a transition on action a((cid:24)x(cid:6)) and (cid:3)(cid:24)x(cid:6), y(cid:6)(cid:4) |(cid:25) ¬fail y(cid:6) follows. Finally, (cid:3)(cid:24)x(cid:6), y(cid:6)(cid:4) |(cid:25) ¬failitrivially, for all i ∈ {1, . . . , n} \ { y(cid:6)}.a((cid:24)x(cid:6)), y(cid:6)−→ sis a winning from game state (cid:3)(cid:24)x0, y0(cid:4) = (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), ω((cid:3)(cid:3)bT , e(cid:4),Putting it all together, the strategy f(cid:3)b1, . . . , bn, e(cid:4)(cid:4), a)(cid:4), and (cid:3)(cid:24)x0, y0(cid:4) ∈ W . (cid:2)While Theorem 12 only talks about non-initial states, it can be easily further extended to the unique initial state.Theorem 13. Let W ⊆ V be the maximal set of winning states for (cid:2)-GS G(cid:3)S,BT (cid:4), as above, and let (cid:3)(cid:24)x0, y0(cid:4) be the initial state of thegame, that is, (cid:3)(cid:24)x0, y0(cid:4) |(cid:25) Θ . Then, (cid:3)(cid:24)x0, y0(cid:4) ∈ W iff (cid:3)bT 0, e0(cid:4) (cid:15) (cid:3)b10, . . . , bn0, e0(cid:4).130G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142Proof. This follows from the fact that, due to case 5(a) in G(cid:3)S,BT (cid:4) definition, each successor of the initial gameis, (cid:3)(cid:24)x, y(cid:4) is a game successor of (cid:3)(cid:24)x0, y0(cid:4) iffstate represents the initial state ofcomS ((cid:24)x) = (cid:3)b10, . . . , bn0, e0(cid:4) and comT ((cid:24)x) = (cid:3)bT 0, e0(cid:4). So, if (cid:3)bT 0, e0(cid:4) (cid:15) (cid:3)b10, . . . , bn0, e0(cid:4), then by Theorem 12, for each such(initial) system move (cid:24)x, there exists a controller move ind such that (cid:3)(cid:24)x, ind(cid:4) ∈ W is a winning state, and as a result,(cid:3)(cid:24)x0, y0(cid:4) ∈ W , too. Conversely, (cid:3)(cid:24)x0, y0(cid:4) can only be winning if for every system move (cid:24)x from (cid:3)(cid:24)x0, y0(cid:4), there exists a con-troller move ind such that the successor state (cid:3)(cid:24)x, ind(cid:4) of the initial state is winning, which by Theorem 12, implies that(cid:3)bT 0, e0(cid:4) (cid:15) (cid:3)b10, . . . , bn0, e0(cid:4). (cid:2)the composition problem. ThatAs a straightforward consequence of this result and Theorem 1, we have that (cid:2)-GS G(cid:3)S,BT (cid:4) is winning if and only ifthere exists a composition of the target in the system.In addition to this, the following result holds, which gives us an actual procedure to build a controller generator and,hence, all possible compositions.Theorem 14. Let S = (cid:3)B1, . . . , Bn, E(cid:4) be a system and BT a target behavior over E . Let G(cid:3)S,BT (cid:4) = (cid:3)V, X , Y, Θ, ρs, ρc, (cid:2)ϕ(cid:4) bethe (cid:2)-GS derived as above, and assume that (cid:3)(cid:3)b10, . . . , bn0, e0, bT 0, (cid:19)(cid:4), (cid:19)(cid:4) ∈ W , where W is the maximal set of winning states. Let(cid:16)CG = (cid:3) (cid:17)Σ, A, {1, . . . , n},(cid:17)∂, (cid:17)ω(cid:4), where:• (cid:17)Σ = {(cid:3)(cid:3)bT , e(cid:4), (cid:3)b1, . . . , bn, e(cid:4)(cid:4) | (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), ind(cid:4) ∈ W }.• (cid:17)∂ ⊆ (cid:17)Σ × A × {1, . . . , n} × (cid:17)Σ is such that (cid:3)σ , a, k, σ (cid:7)(cid:4) ∈ (cid:17)∂ , where σ = (cid:3)(cid:3)bT , e(cid:4), (cid:3)b1, . . . , bn, e(cid:4)(cid:4) and σ (cid:7) = (cid:3)(cid:3)b(cid:7)T , e(cid:7)(cid:4),(cid:7)n(cid:4), e(cid:7)1, . . . , b(cid:7)(cid:4), if and only if(cid:3)b– (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), k(cid:4) ∈ W ;– (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), k(cid:4) |(cid:25) validReq; and(cid:7), b(cid:7)– ρs((cid:3)b1, . . . , bn, e, bT , a(cid:4), k, (cid:3)bn, e• (cid:17)ω(σ , a) = {k | ∃ σ (cid:7) ∈ (cid:17)Σ s.t. σ a,k−→ σ (cid:7)is in (cid:16)CG}.(cid:7)1, . . . , b(cid:7)T , a(cid:7)(cid:4)), for some a(cid:7) ∈ A ∪ {(cid:19)}.Then, (cid:16)CG = CG, that is, (cid:16)CG is the controller generator of S for BT .Proof. Consider the definition of controller generator CG in Section 3; page 116. We need to show that Σ = (cid:17)Σ , (cid:17)∂ = ∂ , and(cid:17)ω = ω.By definition of (cid:17)Σ , (cid:3)(cid:3)bT , e(cid:4), (cid:3)b1, . . . , bn, e(cid:4)(cid:4) ∈ (cid:17)Σ iff (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), ind(cid:4) ∈ W , for some a and ind. Thus, by The-orem 12, (cid:3)(cid:3)bT , e(cid:4), (cid:3)b1, . . . , bn, e(cid:4)(cid:4) ∈ (cid:17)Σ iff (cid:3)bT , e(cid:4) (cid:15) (cid:3)b1, . . . , bn, e(cid:4). This, together with the definition of Σ in CG and thefact that if sT (cid:15) sS then env(sT ) = env(sS ), implies that (cid:3)(cid:3)bT , e(cid:4), (cid:3)b1, . . . , bn, e(cid:4)(cid:4) ∈ (cid:17)Σ iff (cid:3)(cid:3)bT , e(cid:4), (cid:3)b1, . . . , bn, e(cid:4)(cid:4) ∈ Σ . Hence,Σ = (cid:17)Σ .Let us prove next that (cid:17)∂ = ∂ . Suppose that (cid:3)σ , a, k, σ (cid:7)(cid:4) ∈ (cid:17)∂ . Then, (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), k, (cid:3)b(cid:7)(cid:4)(cid:4) ∈ ρs.Because a, k (cid:12)= (cid:19) due to the definition of (cid:17)∂ , case 5(a) (page 126) of G(cid:3)S,BT (cid:4) does not apply. Moreover, a is a target andenvironment compatible action, due to (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), k(cid:4) |(cid:25) validReq, that can be legally performed by behavior Bk,due to (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), k(cid:4) |(cid:25) ¬failk (as (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), k(cid:4) ∈ W ). Thus, case 5(c) of G(cid:3)S,BT (cid:4) cannot apply either.(cid:7)1, . . . , b(cid:7)T , a(cid:7)n, e(cid:7), bSo, case 5(b) of G(cid:3)S,BT (cid:4) must apply. Then, comT (σ )a,k−→ comS (σ (cid:7)) in TS . Let us next(cid:7)(cid:7)(cid:7)(cid:4) in TS . Due to(cid:7)(cid:7)S = (cid:3)bprove the third requirement for ∂ in CG. To that end, consider any transition comS (σ )n, e(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:4) where(cid:7), bT , (cid:19)(cid:4), kLemma 11, game state (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), k(cid:4) ought to have a successor state of the form (cid:3)(cid:3)b1, . . . , b(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:4) ∈ W .(cid:7)(cid:7)(cid:4), k(cid:7), b(cid:7)(cid:7) (cid:12)= (cid:19). Moreover, since (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), k(cid:4) ∈ W , there is at least one such ksuch that (cid:3)(cid:3)b1, . . . , bT , ak(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:4)(cid:4) ∈ Σ(cid:7)(cid:7)(cid:7)(cid:7)Then, by Theorem 12, (cid:3)bn, e1, . . . , bT , en, eT , efollows. Then, (cid:3)σ , a, k, σ (cid:7)(cid:4) ∈∂ follows and (cid:17)∂ ⊆ ∂ .a−→ comT (σ (cid:7)) in TT and comS (σ )a,k−→ s(cid:7)(cid:4) applies and therefore, by definition of Σ in CG, (cid:3)(cid:3)b(cid:7)(cid:7)1, . . . , b(cid:7)(cid:7)n, e(cid:7)(cid:7)n, e(cid:7)(cid:4), (cid:3)bNow, let us prove that ∂ ⊆ (cid:17)∂ . Assume (cid:3)σ , a, k, σ (cid:7)(cid:4) ∈∂ . We want to prove (cid:3)σ , a, k, σ (cid:7)(cid:4) ∈ (cid:17)∂ . To that end, we show that:(cid:7)(cid:7)1, . . . , b(cid:7)(cid:4) (cid:15) (cid:3)b(cid:7)(cid:7)1. (cid:3)(cid:24)x, k(cid:4) = (cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), k(cid:4) ∈ W ; and(cid:7), b2. ρs((cid:3)b1, . . . , bn, e, bT , a(cid:4), k, (cid:3)b(cid:7)1, . . . , b(cid:7)n, e(cid:7)T , (cid:19)(cid:4)).(cid:7)∗, k∗, b∗n, e∗(cid:4), k∗T , a∗1, . . . , b∗) in TS and comT (σ )T .) Again, since (cid:3)σ , a, k, σ (cid:7)(cid:4) ∈ ∂ , the third requirement in the definition of ∂ implies that (cid:3)comT ((cid:24)xTo prove the first claim, take a successor (cid:3)(cid:24)xa−→ comT (σ (cid:7)) in TT and comS (σ )a,k−→ comS ((cid:24)x∗(cid:4) of (cid:3)(cid:24)x, k(cid:4) in G(cid:3)S,BT (cid:4). Because (cid:3)σ , a, k, σ (cid:7)(cid:4) ∈ ∂ ,∗(cid:4) = (cid:3)(cid:3)ba,k−→ comS (σ (cid:7)) in TS . Thus, Lemma 11 applies and we conclude thatcomT (σ )∗) in TT . (Note that because the target behavior is deterministiccomS (σ )∗∗)(cid:4) ∈ Σ= bbT∗(cid:4) ∈ W .and therefore comT ((cid:24)x∗(cid:4) is still a successor game state of (cid:3)(cid:24)x, k(cid:4) by requirement 6 (page 126) of G(cid:3)S,BT (cid:4)Note that for such particular kdefinition. Informally, at game state (cid:3)(cid:24)x, k(cid:4), the controller can force the game to a winning state no matter the system plays∗. So, to prove that (cid:3)(cid:24)x, k(cid:4) ∈ W , it remains to be shown that (cid:3)(cid:24)x, k(cid:4) |(cid:25) ϕ, that is, game state (cid:3)(cid:24)x, k(cid:4) itself sat-its next move (cid:24)x(cid:7)k in Bk such that g(e) = (cid:10), and thereforeisfies the winning condition. Since comS (σ )∗). By applying Theorem 12, there exists one such k, (cid:3)(cid:24)xa,k−→ comS (σ (cid:7)) in TS , then bk∗ ∈ {1, . . . , n} such that (cid:3)(cid:24)x∗), comS ((cid:24)x∗, k∗) (cid:15) comS ((cid:24)x∗a−→ comT ((cid:24)xg,a−→ b∗, kG. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142131(cid:3)(cid:24)x, k(cid:4) |(cid:25) ¬failk. (Note that (cid:3)(cid:24)x, k(cid:4) |(cid:25) ¬faili trivially for all i (cid:12)= k.) Next, because σ ∈ Σ , comT (σ ) (cid:15) comS (σ ). Then, if bT is finalin BT , so are all bi in Bi . Hence, (cid:3)(cid:24)x, k(cid:4) |(cid:25) ¬finalT(cid:7)n, e(cid:7)T , (cid:19)(cid:4)) follows due to Lemma 11 and the fact that (cid:19) is always a legalPutting it all together, we have just shown that (cid:17)∂ = ∂ , that is, the transition relation for (cid:16)CG is exactly that of the controllerFinally, ρs((cid:3)b1, . . . , bn, e, bT , a(cid:4), k, (cid:3)b(cid:9)ni=1 finali .generator. As an immediate consequence of this, we obtain ω = (cid:17)ω, as their definitions coincide. Hence, CG = (cid:16)CG. (cid:2)action in the game.(cid:7)1, . . . , b→(cid:7), bThe above theorems show how one can exploit tools from reactive system synthesis for computing all compositions of agiven target behavior. In details, starting from S = (cid:3)B1, . . . , Bn, E(cid:4) and BT , one can build the corresponding game structureG(cid:3)S,BT (cid:4), then compute the winning set W , and, if it contains G(cid:3)S,BT (cid:4)’s initial state, use W to generate the controllergenerator. In fact, this last step is not really needed. It is not hard to see that given a system state (cid:3)b1, . . . , bn, e, bT , a(cid:4)(including action a ∈ A to be executed next), a behavior selection ind is “good” (i.e, the selected behavior can actuallyexecute the action and the whole system can still ND-simulate the target behavior) if and only if W contains a tuple(cid:3)(cid:3)b1, . . . , bn, e, bT , a(cid:4), ind(cid:4). Consequently, at each step, based on (current) target behavior state bT , available behaviors’ statesb1, . . . , bn, environment state e, and requested action a, one can select a tuple from W , extract its ind component, and useit to select the next behavior.Finally, note that the time complexity of Algorithm 3 is polynomial in |V |, the size of the input (cid:2)-GS state space. Since,in our encoding, |V | is polynomial in |B 1|, . . . , |Bn|, |B T |, |E|, and |A|, and exponential in n, we get the following result:Theorem 15. Let S = (cid:3)B1, . . . , Bn, E(cid:4) be a system and BT a target behavior over E . Checking the existence of compositions by reduc-tion to safety games can be done in polynomial time w.r.t. |B 1|, . . . ,| Bn|, |B T |, |E|, and |A|, and exponential time in n.Such a result says that computing a composition using safety games has the same computational complexity as comput-ing the ND-simulation relation for solving behavior composition problems (cf. Theorem 2). Since the composition problemis EXPTIME-hard [61], the technique based on safety games is actually optimal with respect to worst-case time complex-ity.6. Implementing behavior composition in TLVWith the behavior composition problem formally reduced to that of synthesizing a winning strategy in a special safety-game, one can appeal to existing implemented systems that are capable of searching for winning strategies in gamestructures, such as tlv [71], Anzu [45], Lily [44], and Mocha [4]. We note that, even though not all of these tools of-fer efficient, or more appropriately optimized, solution techniques, there are currently promising efforts in this direction (cf.,e.g., [44]), so we may likely expect formal synthesis technology to become available as an effective alternative in the future—similarly to model checking [23]. In that sense, in this section we explain in detail how a proof-of-concept implementationof what was presented in the previous section can be readily obtained. Although we shall focus on tlv, all basic conceptsdiscussed here remain valid for all other tools.tlv (Temporal Logic Verifier) is a (generic) software for verification and synthesis of ltl specifications, which exploitsBinary Decision Diagrams (BDDs) for symbolic state manipulation, in order to contain state explosion. Generally speaking,tlv takes two inputs: (i) a synthesis procedure; and (ii) an ltl specification, encoded in smv language [59], to be processedby the input procedure. In particular, for (i), we consider a specific procedure for dealing with safety games and refer to theso-obtained system as tlv (cid:2).13 Essentially, tlv (cid:2)takes as input an ltl specification encoding a (cid:2)-GS and derives from thegame’s maximal winning set, if non-empty, a structure representing the controller generator, as shown in Theorem 14. Werefer to [71] for further details on tlv and the input language smv, here introducing some essentials only.Our approach consists in: (i) building, as described in Section 5.2, the (cid:2)-GS corresponding to a given behavior composi-tion problem; (ii) deriving the smv encoding for the obtained (cid:2)-GS; and (iii) executing the encoding in tlv (cid:2), to both checkwhether the composition problem is solvable and, if so, compute the controller generator. Next, we detail (ii) .In the smv encoding, every aspect of a (cid:2)-GS, e.g., the available behaviors or the controller, is modeled as a so-called“module”. Fig. 6 shows the basic blocks of the encoding for our painting world running example (see Fig. 1; page109).Modules, e.g., ArmSys, can be built from submodules, by declaring these in the VAR section, which is what we actually doin our construction. When doing so, according to the smv semantics, the execution of the composite module correspondsto the synchronous execution of its submodules. Asynchronicity can be emulated by allowing a module to loop at eachstate via a no-op transition. This is indeed what we do so as to accommodate the asynchronous execution of the availablebehaviors (see definition of enacted system in Section 2): each submodule that represents an available behavior is forced toloop at each step when not “selected”, by means of auxiliary no-op action none.Module Main, consisting of submodules sys and contr, wraps all the other modules, and represents the whole gamestructure. In particular, module sys captures the system player, by encoding the enacted system behavior (asys) togetherwith the enacted target behavior (client), i.e., informally, the external uncontrollable system. Module contr, on the other13 This specific procedure for safety games was originally coded by Amir Pnueli.132G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142Fig. 6. A tlv sample fragment encoding.hand, encodes the constraints on the controller player in the game structure, that is, the module to be synthesized. Finally,variable good encodes the goal invariant property to be respected, which states that a game state (including both playerstates) is “good” if and only if either both players are at their dummy initial states or the external system—the systemplayer—has not been brought into a failure state. The external system may reach a failure state, for instance, if an availablebehavior is requested an action it cannot perform in its current state, or if the target behavior is in a final state but someavailable behavior is not.Modules sys and contr are meant to evolve synchronously, the former choosing the next requested action to be per-formed and the latter selecting the available behavior for its execution. Consequently, the requested action (sys.req)is passed as an input argument to the contr module, and the chosen available behavior is passed as an input to thesys module. Notice that instead of merely returning just the index of the available behavior meant to execute the cur-rently requested action (as in the game structure previously defined), the contr module outputs one action per availablebehavior—e.g., a2op denotes the action assigned to behavior arm a2, using the distinguished action constant none to statethat no action is requested. This approach enables the encoding of settings where more than one behavior may executeat the same time, like in [79]. We refer to this encoding as it introduces no additional difficulty while being clearly moregeneral.Next, we detail the submodules representing the two players of the game structure. As for contr, which is an instance ofController, the transition relation defined by the constraints in the INIT and TRANS sections encodes an unconstrainedcontroller, which assigns, at each step, one action to each available behavior, by assigning values to the state variables a1op,a2op, and a3op. The synthesis goal is to restrict such a relation so as to obtain a winning strategy. In particular, the constraintsenforced on the controller player’s state are as follows. According to the INIT section, in its initial state (where variableinitial holds true) the controller must instruct every behavior to initialize itself by performing the dummy action start(all behaviors initialize simultaneously). As for non-initial states, the TRANS section defines the following constraints: (i) noinitialization action can be assigned to any behavior; (ii) the current action request must match at least one of the behaviorG. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142133actions; (iii) a behavior can be instructed to execute an action only if that action is the one currently requested; and (iv) atmost one behavior can be instructed to act at a time.Concerning module sys, which is an instance of System, it essentially captures, as said above, all the aspects of thesystem player. Precisely, sys is the synchronous product of the enacted available system (submodule asys) and the clientissuing the action requests (submodule client). On the one hand, submodule asys accounts for the available behaviorsrunning in the environment, according to both the currently requested action (variable req) and the controller assignmentto variables a1op, a2op, and a3op; on the other hand, submodule client provides, at every game state, the requestedaction (variable req), which is, of course, required to be compliant with the target behavior. Observe that client requestsaction none (last rule) only when no other legal action can be requested anymore. Since the execution of none yields nochange in the current game state, it turns out that once executed, none remains the only action available to the target,from that point on.Distinguished abbreviations are used to define, in the DEFINE section, initial, final, and failure states. In particular, theenacted system behavior (ArmSys) fails (failure) when any of the available behaviors does, an available behavior failingwhen instructed to perform an action it cannot execute, depending on its and the environment’s current state. Avoidingsuch situations, by properly constraining sys’s transition relation, is exactly the synthesis procedure’s aim. Clearly, the onlyway to achieve this is by suitably assigning sys’s controllable input variables a1op, a2op, and a3op, that is, ultimately, bysuitably “crafting” the contr module (while respecting its constraints). Finally, the whole enacted system does not respectthe final-state condition (failfinal) when the client is in a state where it may legally terminate its execution but theavailable system does not.We encoded our running example for tlv (cid:2), and run it to compute the corresponding winning set, along with thecontroller generator. The result obtained was an automaton with 16 states and 21 transitions, from where controllers canbe easily extracted. We report three sample states of the automaton:State 3sys.asys.env.state = e2,sys.asys.a2.state = b2,sys.client.target.state = t2,contr.a1op = none, contr.a2op = paint, contr.a3op = none,sys.asys.a1.state = a1,sys.asys.a3.state = c1,sys.client.req = paint,State 15sys.asys.env.state = e2,sys.asys.a2.state = b3,sys.client.target.state = t4,contr.a1op = dispose, contr.a2op = none, contr.a3op = none,sys.asys.a1.state = a1,sys.asys.a3.state = c1,sys.client.req = dispose,State 16sys.asys.env.state = e2,sys.asys.a2.state = b1,sys.client.target.state = t4,contr.a1op = dispose, contr.a2op = none, contr.a3op = none,sys.asys.a1.state = a1,sys.asys.a3.state = c1,sys.client.req = dispose,In state 3, for instance, the environment is in state e2, the available arms are in states a1, b2, and c1, the target behavioris in state t2, the action requested next is paint, and the controller has selected arm B2 for carrying out the action. States15 and 16 are the possible successor states that the game can be in, depending on how the non-deterministic transition inbehavior B2 turns out.The complete tlv specification for our example can be found in Appendix A.We close by noting that the implementation discussed in this section is only concerned with the synthesis of the con-troller generator (see Section 3), and as a result is not meant to deal with the run-time adaptation techniques developed inSection 4 for dealing with failures. Indeed such techniques are expected to be part of a “smart” composition executor whichwill execute and adapt controller generators at run-time.7. Related workThe framework developed in this paper can be seen as a core account for behavior composition, and can be extendedin a number of directions. In [79], a distributed version of the problem is presented, where instead of a central entitythat embodies the controller, a set of local controllers, one per available behavior, are meant to jointly realize the targetbehavior, by exploiting an underlying, shared communication channel. Another extension involves realizing not one butseveral target behaviors concurrently, using the same available system [77]. Composition under partial observability wasalso explored by De Giacomo [24], whereas composition with data exchange was investigated by Berardi et al. [12] inthe context of web-services. Finally, [78,28] propose two frameworks (and corresponding techniques) for composing agenthigh-level programs. The techniques for all these extensions vary, from PDL satisfiability [79,12] to LTL/ATL synthesis [24,77,28], to computation of specific fix-points [78]. Also, a direct search-based technique for the core composition account134G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142was recently proposed by Stroeder and Pagnucco [85], which could turn out to be promising when it comes to applyingheuristics.The composition technique we proposed here is related to synthesis of reactive systems from LTL temporal specifica-tions [70,69,47], which is proven 2EXPTIME-complete, in general [70]. In our particular case, however, we can restrict to aclass of specifications, namely GR(1), for which the problem is EXPTIME-complete [69]. Though a subclass of full LTL, GR(1)type formulas are expressive enough to deal with many, if not most, realistic applications. They, for instance, have beenused to support advanced forms of path planning in robots [49,48,11,33]. Notably, a work that is inspired by our behaviorcomposition is that of Lusting and Vardi [54], where the problem of synthesizing LTL specifications by coordinating givenmodules from an existing library is studied (and proven 2EXPTIME-complete). In turn, De Giacomo and Felli [25] showedhow to solve the behavior composition problem by ATL model checking. ATL (Alternating-time Temporal Logic) [3] is a logicespecially aimed for reasoning about multi-player games, where players can form coalitions to satisfy certain formulae. Theresult is important in that it gives access to some of the state-of-the-art model checking techniques and tools, such as mc-mas,14 that have been recently developed within the agent community. Since the behavior composition task can be seen aswinning a special kind of game (see Section 5), it would be interesting to explore whether the heuristic-based techniquesdeveloped in the context of General-Game Playing [35] can be applied for “playing” composition games that are either toodifficult to solve at the outset or directly unsolvable.Our work directly relates to several others (e.g., [38,19,13,31,12,15,37,73]) on Service Oriented Computing (SOC) [2].Indeed, available behaviors, ultimately transition systems, can be seen as the conceptual model for conversational, or stateful,(web) services. By taking this perspective, many results presented here become applicable, almost off-the-shelf, in the SOCarea. One line of research that is quite related to ours is that reported in [65,66,68,16] which exploits techniques forconditional planning for temporally extended goals. Starting from a set of conversational available services, specified inbpel4ws (Business Process Execution Language for Web Services), and a goal specified as a branching temporal formulae (inthe language EaGLe, a suitable extension of CTL [22]), conditional planning techniques are exploited to find an interleavedexecution of available services, so as to satisfy the desired goal. Roughly speaking, a goal represents a main, finite, desiredpath of states, plus some secondary paths to be followed when “exceptions” (i.e., deviation from the main path) arise.This technique, actually implemented in the system astro15 based on the Model Based Planner (mbp3) [21], exploits ModelChecking technology (ultimately, BDDs) to control the state space explosion. Two main features differentiate such work fromours. Firstly, our goals are actually new services (behaviors), rather than desired executions, which, once realized, can beexecuted as any other one. What is more, the behaviors we synthesize are really intended to interact with some executor,instead of executing on their own, like plans do. So, from a high-level perspective, we aim at extending the set of servicesoffered by a given system, whereas the work above focuses more on serving particular requests by taking advantage of theexisting system. A research line on services that adopts the same approach as ours is that in [8–10]. Like ours, these worksrely on techniques borrowed from controller synthesis, though the approach therein is more theoretical. In contrast, wefully take advantage of such results for practical reasons, by (i) exploiting controller synthesis techniques to build flexiblesolutions, and (ii) by showing how to use the actual existing technology, based on a symbolic approach, for effective solutionconstruction.In the series of works [57,58,83], the Situation Calculus logical framework is adopted as a theoretical framework forcomposing semantic Web services (specified in the OWL-S process ontology [56]). Available and goal services are modeledas (complex) Golog programs, and the objective is to find a terminating execution of the available services that correspondsto an execution of the goal service. Based on the same Situation Calculus semantics, Sirin et al. [82] exploits HierarchicalTask Networks (HTN) to model available (OWL-S) services, and then uses an HTN planner [62] to build a plan representingan actual, finite, execution of a desired target service. All such works share the idea of achieving a desired goal—beingit a state or a situation—by executing a terminating plan or program. Our approach is different, and, in a sense, moregeneral, essentially due to two major differences: first, we consider realization of infinite target behavior executions; second,a solution to our composition problem is required to realize all possible behavior service executions, rather than just one.Behavior composition is also related to several forms of automated planning in AI, in particular, to planning for tem-porally extended goals (as mentioned above in the context of services), which investigates techniques for building finite orinfinite plans that satisfy linear- or branching-time specifications [7,67,46]. Indeed, our problem requires an advanced con-ditional plan (with loops) that always guarantees all possible target requests to be served, which is, ultimately, a (temporal)invariant property. More specifically, the solutions obtained via the simulation technique developed in this work are akinto the so-called universal plans [81], i.e., plans representing every possible solution. A further recent work about planning,where temporal fairness constraints are explicitly stated so as to capture long-term effects of action executions is [29]. Weconjecture that some of the concepts there can be exploited in our context to make the notion of behaviors to be composedmore sophisticated.Composing behaviors can also be linked to (multi-)agent systems in natural ways. For instance, a Belief–Desire-Intentionagent operates on the coordinated execution of pre-defined non-deterministic plans—the available behaviors—in order toachieve its goals [75,36]. One could then imagine composing such available plans so as to bring about another non-available14 http://www-lai.doc.ic.ac.uk/mcmas/.15 http://astroproject.org.G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142135plan—the target behavior—that represents all the goals of the agent. Similarly, composing behaviors can be seen as realizinga “team-oriented” behavior (e.g., a RoboCup sophisticated abstract “team” player), represented by the target behavior, fromthe behavior of single agents (e.g., a set of actual RoboCup robotic players with different capabilities), represented by thevarious available behaviors. Of course, the core composition framework as presented here lacks, so far, convenient featuresfor programming team agent systems [72,43], such as roles, holons, communication channels, etc.Finally, behavior composition, as studied in this paper, is tightly related to the problem of integrating simple function-alities to implement advanced (intelligent) behaviors in the context of robot ecologies [76,18,17]. The idea of leveragingon the capabilities of many simple robotic devices (e.g., vacuum cleaners, blinds, cameras, robot arms, etc.) in order toachieve complex tasks has attracted much attention lately given the marked tendency toward the embedding of intelli-gent, networked robotic devices in our homes and offices. While very close in “spirit”, the work done in robot ecologiesso far focuses on differs aspects. Most of the work in “composing” functionalities within an ecology of robots is de-voted to the generation of adequate ways of connecting existing functionalities via so-called configurations in order tobe able to carry a particular task, such as making the output of a video camera the input of a moving robot lackingvisual capabilities. Instead of dealing explicitly with such connectivity issues (except for the interaction with the en-vironment), our work focuses on how each component needs to be actually operated in order to achieve the targetprocess. Also, the integration of functionalities is either done fully by hand (e.g., [76,18]) or semi-automatically throughhand-tailored planning techniques (e.g., [52,53]) in the style of HTN planning. In the latter case, one is meant to de-fine standard “recipes” to describe ways to combine functionalities for specific purposes. Our approach is more of afirst-principles one, no domain information is available on how available behaviors can or should be combined. Moreimportantly, while we took a high-level perspective on agents and shared devices, and focused on the synthesis prob-lem only, the aforementioned work on robot ecologies deals better with many other practical aspects of concern when itcomes to implementing the solution. For instance, how to design such devices so that they can easily interoperate amongthemselves, as we assume here, and how such interoperability is actually realized, via an appropriate middleware [17].In fact, we expect a fruitful cross-fertilization between the theoretical studies on automated synthesis of agents, as theone in the present paper, and practical work on experimenting device integration in robot ecologies and ambient intelli-gence.8. ConclusionsIn this paper, we have carried out a deep investigation on the behavior composition problem, that is, the problemof realizing a desired, but non-available, target behavior by reusing and re-purposing accessible modules (devices, agents,plans, etc.), which are the only behaviors actually available. In particular, we have proposed a technique, based on the notionof simulation, for building a controller that coordinates the concurrent executions of the available behaviors so as to “mimic”the target behavior. What is more, we showed that such technique can be directly related to building a winning strategyfor a safety game, which opens the door for relying on symbolic model checking technology. Because of this, the resultsfrom Sections 3 and 5 can be easily linked. While Theorem 1 connects the existence of a composition controller with thatof certain simulation relation, Theorem 12 connects the latter with the existence of a winning strategy, thus closing theloop from compositions to winning strategies in a safety game. Similarly, Theorem 14 (which is a surplus of Theorem 12)can be seen as the counterpart of simulation-based Theorem 3 (which is a surplus of Theorem 1) for safety games. Finally,Theorems 2 and 15 describe the complexity of the problem in terms of finding an adequate simulation relation or a winningset for a safety game, respectively, without overhead for the latter.This work lays the basis for several further developments, some of which have already been mentioned in the relatedwork section. We would like to close the paper by briefly discussing two of them that still require further study. Thefirst one concerns the possibility of interchanging actions. More precisely, in this work we have implicitly assumed thattwo actions are equivalent if and only if they are named the same way, and hence, they are exactly the same action.Clearly, there are situations requiring a more flexible model, for instance when the domain includes actions with differentnames that execute, in fact, the same task; or where some actions specialize some other, more abstract, ones. For exam-ple, actions paint-red and paint-blue may stand for specializations (or implementations) of the more abstract, and maybenot even directly available, action paint. Both concrete actions, when abstracting from other details, may be consideredequivalent in terms of the effect of having an object painted. One natural way to generalize the composition frameworkdeveloped in this paper is to assume the existence of an underlying compatibility relation (cid:27) ⊆ A × A among actions: ifa (cid:27) ˆa (i.e., action ˆa is compatible with action a), then an execution of action a can be satisfied by the actual executionof action ˆa. With a domain compatibility relation at hand, one can then generalize the notion of ND-simulation from Sec-tion 3 to account for the fact that whenever an action a is requested by the target (e.g., paint), a compatible action ˆa,i.e., a (cid:27) ˆa, can be carried out by some available behavior (e.g., paint-red). We expect all results presented here to stillhold in such a generalized case, though further work is needed in order to formalize this intuition. While above we donot make any assumption on relation (cid:27), in practice it may be natural to assume that it satisfies certain properties. Forinstance, a reflexive compatibility relation captures the fact that every action can be always replaced by itself; a par-tial order captures a hierarchy of actions, where a general action a can be replaced by a more specific one, but not viceversa; and finally an equivalence relation can be used to assert that some actions carry out the very same task (relative136G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142to some features of interest). A further study of which properties of relation (cid:27) in specific applications is certainly ofinterest.The second direction for further study stems from the observation that, when no compositions exist, it may be of interestto approximate “solutions”. That is, if a composition does not exist, one may be interested in understanding which part ofthe target cannot be realized and which can. Some compelling contribution in this direction can be found in the areaof supervisory control of deterministic discrete event systems [74]. In particular, there is a foundational result of greatinterest: given a specification of the allowed behavior in terms of a language, i.e., a possibly infinite set of runs that aredeemed as “allowed”, it is always possible to find a single maximal subset of such runs that can be obtained by controllinga given system, the so called “supremal controllable sublanguage” [90]. It would be quite interesting to understand if,at least in certain cases, an analogous property holds for behavior composition as well. The question then is what an“optimal” controller amounts to. Besides some domain-independent criteria (e.g., number of transitions realized), allowingthe specification of additional domain information could help define what such best controllers are, such as quantifyingall or some non-deterministic transitions and specifying preferences over target actions or available behaviors. Initial stepstoward “optimization” versions of the composition problem studied in this article have been recently proposed by Yadav andSardina [91,92], who developed a (quantitative) decision-theoretic composition framework as well as a qualitative accountfor “approximate” composition.AcknowledgementsThe authors would like to thank the anonymous reviewers for their suggestions and comments that helped improve thepaper. This research was partially supported by the Australian Research Council (grants DP1094627 and DP120100332), theEU FP7-ICT Project ACSI (grant no. 257593), as well as two mobility awards (Australian Academy of Science “Scientific Visitto Europe” and RMIT Visiting Researcher’s awards).Appendix A. TLV implementation for the painting block exampleWe list here the smv code that completes the one presented in Fig. 6. As for module main, we refer the reader to Fig. 6,where the full encoding is reported. Concerning the code for module Environment, it is as follows:MODULE Environment(act) -- EnvironmentVARst: {ini,e1,e2,e3,e4};INITst = iniTRANScasest = ini & act = start : next(st) = e1;act = none : next(st) = st;st = e1 & act = recharge : next(st) = e1;st = e1 & act = prepare : next(st) = e2;st = e2 & act in {paint,recharge} : next(st) = e2;st = e2 & act = dispose : next(st) = e1;st = e2 & act = clean : next(st) in {e2,e3}; -- nondet!st = e3 & act in {paint,clean}: next(st) = e3;st = e3 & act = dispose : next(st) = e4;st = e3 & act = recharge : next(st) = e2;st = e4 & act = prepare : next(st) = e3;st = e4 & act = recharge : next(st) = e1;TRUE : FALSE; -- no other transitions possible!esacDEFINEinitial := st = ini;Observe that the environment has one dummy state ini and one dummy action start, which, when executed in theinitial state, makes the environment move to state e1. Every line in the TRANS section encodes a transition, that is, it definesthe next state of the module (next(st)) given the environment’s current state (st) and the action being performed, whichis an input parameter (variable act).We next list the code corresponding to the three available arms B1, B2, and B3. Their encoding is similar to that ofthe environment, though with some differences. Firstly, as the dynamics of each behavior—captured in the module’s TRANSsection—depends on both the action being performed by the behavior itself and the current environment state, both theaction and the environment state appear as inputs (variables act and env) in each behavior module. As for the TRANSsection, similarly to the environment’s, each of its entries within the case body captures a behavior transition. In particular,observe that every behavior may be instructed to execute the dummy action none (second entry in TRANS), i.e., a no-opaction that yields no state change in the module. Through this mechanism we implement the asynchronous execution ofavailable behavior modules, as explained in Section 6. Secondly, to account for guards, the transitions occurring in a behaviormodule may contain (boolean) formulae involving the current state of the environment. For example, the fourth transitionin the ArmA module states that the next state of the behavior is a2, provided: the current state is a1, the behavior isG. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142137executing action clean, and the environment is in either state e1 or e2. Finally, each behavior defines its initial, final, andfailure conditions. In particular, behavior failure is accounted for by introducing the distinguished absorbing state failed,that the module reaches whenever no transition rule applies for the current action and environment state input, i.e., whenthe behavior cannot legally execute the requested action.MODULE ArmA(act, env)VARst: {ini,failed,a1,a2};INITst = iniTRANScasest = ini & act = start :next(st) = a1;act = none : next(st) = st;st = a1 & act in {dispose,recharge} :next(st) = a1;st = a1 & act=clean & env in {e1,e2}:next(st) = a2;st = a2 & act = recharge :next(st) = a2;st = a2 & act = dispose :next(st) = a1;TRUE : next(st) = failed;esacDEFINEinitial := st = ini;final:= st = a1;fail := state = failed;MODULE ArmB(act, env)VARst: {ini,failed,b1,b2,b3,b4};INITst = iniTRANScasest = ini & act = start :next(st) = b1;act = none : next(st) = st;st = b1 & act = prepare :next(st) = b2;st = b2 & act = clean :next(st) = b1;st = b2 & act = paint :next(st) in {b1,b3};st = b3 & act = recharge :next(st) = b1;st = b3 & act = prepare :next(st) = b4;st = b4 & act = clean :next(st) = b3;TRUE : next(st) = failed;esacDEFINEinitial := st = ini;final:= st = b1;fail := state = failed;MODULE ArmC(act, env)VARst: {ini,failed,c1,c2};INITst = iniTRANScasest = ini & act = start : next(st) = c1;act = none : next(st) = st;st = c1 & act = recharge : next(st) = c2;st = c2 & act = prepare : next(st) = c2;st = c2 & act = paint : next(st) = c1;TRUE : next(st) = failed; -- failed!esacDEFINEinitial := st = ini;final:= st = c1;fail := state = failed;The target specification is even simpler, as the target may not include any non-deterministic transition:MODULE Target(env, req)VARstate: {ini,t1,t2,t3,t4,t5};INITstate = ini & req = startTRANScasestate = ini & req = startreq = nonestate = t1 & req = preparestate = t2 & req = paintstate = t2 & req = cleanstate = t3 & req = paintstate = t4 & req = disposestate = t5 & req = recharge: next(state) = t1;: next(state) = state;: next(state) = t2;: next(state) = t4;: next(state) = t3;: next(state) = t4;: next(state) = t5;: next(state) = t1;esacDEFINEinitial:= state = ini;final:= state = t1;138G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142Using the target, we can then specify the client, which is meant to issue the request actions according, of course, to thetarget behavior:MODULE Client(env)VARtarget : Target(env, req);req: {start,none,prepare,clean,paint,dispose,recharge};INITreq = startTRANScasenext(tst) = t1 : next(req) = prepare;next(tst) = t2 : next(req) in {paint,clean} ;next(tst) = t3 : next(req) = paint;next(tst) = t4 : next(req) = dispose;next(tst) = t5 : next(req) = recharge;TRUE : next(req) = none;esacDEFINEinitial:= target.initial;tst := target.state;final:= target.final;When the full specification is run against the tlv (cid:2) system, the following output is obtained:TLV version 4.18.4...Resources used: user time: 0.11 sBDD nodes allocated: 125962max amount of BDD nodes allocated: 125962Bytes allocated: 2228288...Automaton StatesState 1sys.availsys.env.state = start_st,sys.availsys.a2.state = start_st,sys.client.target.state = start_st,contr.a1op = start_op, contr.a2op = start_op, contr.a3op = start_op,sys.availsys.a1.state = start_st,sys.availsys.a3.state = start_st,sys.client.req = start_op,State 2sys.availsys.env.state = e1,sys.availsys.a2.state = b1,sys.client.target.state = t1,contr.a1op = none, contr.a2op = prepare, contr.a3op = none,sys.availsys.a1.state = a1,sys.availsys.a3.state = c1,sys.client.req = prepare,State 3sys.availsys.env.state = e2,sys.availsys.a2.state = b2,sys.client.target.state = t2,contr.a1op = none, contr.a2op = paint, contr.a3op = none,sys.availsys.a1.state = a1,sys.availsys.a3.state = c1,sys.client.req = paint,State 4sys.availsys.env.state = e2,sys.availsys.a2.state = b2,sys.client.target.state = t2,contr.a1op = clean, contr.a2op = none, contr.a3op = none,sys.availsys.a1.state = a1,sys.availsys.a3.state = c1,sys.client.req = clean,State 5sys.availsys.env.state = e2,sys.availsys.a2.state = b2,sys.client.target.state = t3,contr.a1op = none, contr.a2op = paint, contr.a3op = none,sys.availsys.a1.state = a2,sys.availsys.a3.state = c1,sys.client.req = paint,State 6sys.availsys.env.state = e3,sys.availsys.a2.state = b2,sys.client.target.state = t3,contr.a1op = none, contr.a2op = paint, contr.a3op = none,sys.availsys.a1.state = a2,sys.availsys.a3.state = c1,sys.client.req = paint,State 7sys.availsys.env.state = e3,sys.availsys.a2.state = b3,sys.client.target.state = t4,contr.a1op = dispose, contr.a2op = none, contr.a3op = none,sys.availsys.a1.state = a2,sys.availsys.a3.state = c1,sys.client.req = dispose,G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142139State 8sys.availsys.env.state = e3,sys.availsys.a2.state = b1,sys.client.target.state = t4,contr.a1op = dispose, contr.a2op = none, contr.a3op = none,sys.availsys.a1.state = a2,sys.availsys.a3.state = c1,sys.client.req = dispose,State 9sys.availsys.env.state = e4,sys.availsys.a2.state = b1,sys.client.target.state = t5,contr.a1op = recharge, contr.a2op = none, contr.a3op = none,sys.availsys.a1.state = a1,sys.availsys.a3.state = c1,sys.client.req = recharge,State 10sys.availsys.env.state = e4,sys.availsys.a2.state = b3,sys.client.target.state = t5,contr.a1op = none, contr.a2op = recharge, contr.a3op = none,sys.availsys.a1.state = a1,sys.availsys.a3.state = c1,sys.client.req = recharge,State 11sys.availsys.env.state = e2,sys.availsys.a2.state = b3,sys.client.target.state = t4,contr.a1op = dispose, contr.a2op = none, contr.a3op = none,sys.availsys.a1.state = a2,sys.availsys.a3.state = c1,sys.client.req = dispose,State 12sys.availsys.env.state = e2,sys.availsys.a2.state = b1,sys.client.target.state = t4,contr.a1op = dispose, contr.a2op = none, contr.a3op = none,sys.availsys.a1.state = a2,sys.availsys.a3.state = c1,sys.client.req = dispose,State 13sys.availsys.env.state = e1,sys.availsys.a2.state = b1,sys.client.target.state = t5,contr.a1op = recharge, contr.a2op = none, contr.a3op = none,sys.availsys.a1.state = a1,sys.availsys.a3.state = c1,sys.client.req = recharge,State 14sys.availsys.env.state = e1,sys.availsys.a2.state = b3,sys.client.target.state = t5,contr.a1op = none,sys.availsys.a1.state = a1,sys.availsys.a3.state = c1,sys.client.req = recharge,contr.a2op = recharge, contr.a3op = none,State 15sys.availsys.env.state = e2,sys.availsys.a2.state = b3,sys.client.target.state = t4,contr.a1op = dispose, contr.a2op = none, contr.a3op = none,sys.availsys.a1.state = a1,sys.availsys.a3.state = c1,sys.client.req = dispose,State 16sys.availsys.env.state = e2,sys.availsys.a2.state = b1,sys.client.target.state = t4,contr.a1op = dispose, contr.a2op = none, contr.a3op = none,sys.availsys.a1.state = a1,sys.availsys.a3.state = c1,sys.client.req = dispose,Automaton TransitionsFrom 1 to 2From 2 to 3 4From 3 to 15 16From 4 to 5 6From 5 to 11 12From 6 to 7 8From 7 to 10From 8 to 9From 9 to 2From 10 to 2From 11 to 14From 12 to 13From 13 to 2From 14 to 2From 15 to 14From 16 to 13Automaton has 16 states, and 21 transitionsThe output states that an automaton with 16 states and 21 transition was successfully synthesized. Observe thatthe automaton encodes and accounts for the constraints of both the whole system and the client running the target,140G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142as well as the controller performing the composition. In fact, the obtained result can be regarded as a representationof the controller generator for the painting blocks example. States can be read as follows: an assignment to variablessys.availsys.env.state, sys.availsys.a1.state, sys.availsys.a2.state, sys.availsys.a3.state,and sys.client.target.state, forms the current state of the enacted system; an assignment to sys.client.reqrepresents the action currently requested; and an assignment to contr.a1op, contr.a2op, and contr.a3op, repre-sents a possible action delegations to available behaviors for fulfilling the current request.We close by mentioning that, by running the example on a 2011 mid-priced laptop, we get a solution in less than half asecond.References[1] M. Abadi, L. Lamport, P. Wolper, Realizable and unrealizable specifications of reactive systems, in: Proceedings of the International Colloquium onAutomata, Languages and Programming (ICALP), 1989, pp. 1–17.[2] G. Alonso, F. Casati, H. Kuno, V. Machiraju, Web Services. Concepts, Architectures and Applications, Springer, 2004.[3] R. Alur, T.A. Henzinger, O. Kupferman, Alternating-time temporal logic, Journal of the ACM 49 (5) (2002) 672–713.[4] R. Alur, T.A. Henzinger, F.Y.C. Mang, S. Qadeer, S.K. Rajamani, S. Tasiran, MOCHA: Modularity in model checking, in: Proceedings of the InternationalConference Computer Aided Verification (CAV), 1998, pp. 521–525.[5] E. Asarin, O. Maler, A. Pnueli, Symbolic controller synthesis for discrete and timed systems, in: P. Antsaklis, W. Kohn, A. Nerode, S. Sastry (Eds.), HybridSystems II, in: LNCS, vol. 999, Springer, 1995, pp. 1–20.[6] E. Asarin, O. Maler, A. Pnueli, J. Sifakis, Controller synthesis for timed automata, in: IFAC Symposium on System Structure and Control, Elsevier SciencePublishers Ltd., 1998, pp. 469–474.[7] F. Bacchus, F. Kabanza, Planning for temporally extended goals, Annals of Mathematics and Artificial Intelligence 22 (1–2) (1998) 5–27.[8] P. Balbiani, F. Cheikh, G. Feuillade, Composition of interactive web services based on controller synthesis, in: Proceedings of the IEEE Congress onServices (SERVICES), 2008, pp. 521–528.[9] P. Balbiani, F. Cheikh, G. Feuillade, Algorithms and complexity of automata synthesis by asynchronous orchestration with applications to web servicescomposition, Electronic Notes in Theoretical Computer Science (ENTCS) 229 (3) (2009) 3–18.[10] P. Balbiani, F. Cheikh, G. Feuillade, Controller/orchestrator synthesis via filtration, Electronic Notes in Theoretical Computer Science (ENTCS) 262 (2010)33–48.[11] C. Belta, A. Bicchi, M. Egerstedt, E. Frazzoli, E. Klavins, G.J. Pappas, Symbolic planning and control of robot motion: State of the art and grand challenges,IEEE Robotics and Automation Magazine 14 (1) (March 2007) 61–70.[12] D. Berardi, D. Calvanese, G. De Giacomo, R. Hull, M. Mecella, Automatic composition of transition-based semantic web services with messaging, in:Proceedings of the International Conference on Very Large Databases (VLDB), 2005, pp. 613–624.[13] D. Berardi, D. Calvanese, G. De Giacomo, M. Lenzerini, M. Mecella, Automatic composition of e-services that export their behavior, in: Proceedings ofthe International Joint Conference on Service Oriented Computing (ICSOC), 2003, pp. 43–58.[14] D. Berardi, D. Calvanese, G. De Giacomo, M. Lenzerini, M. Mecella, Automatic service composition based on behavioural descriptions, InternationalJournal of Cooperative Information Systems 14 (4) (2005) 333–376.[15] D. Berardi, F. Cheikh, G. De Giacomo, F. Patrizi, Automatic service composition via simulation, International Journal of Foundations of Computer Sci-ence 19 (2) (2008) 429–451.[16] P. Bertoli, M. Pistore, P. Traverso, Automated composition of web services via planning in asynchronous domains, Artificial Intelligence Journal 174 (3–4)(2010) 316–361.[17] M. Bordignon, J. Rashid, M. Broxvall, A. Saffiotti, Seamless integration of robots and tiny embedded devices in a PEIS-ecology, in: Proceedings of theIEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2007, pp. 3101–3106.[18] M. Broxvall, M. Gritti, A. Saffiotti, B.-S. Seo, Y.-J. Cho, PEIS ecology: Integrating robots into smart environments, in: Proceedings of the IEEE InternationalConference on Robotics and Automation (ICRA), 2006, pp. 212–218.[19] T. Bultan, X. Fu, R. Hull, J. Su, Conversation specification: a new approach to design and analysis of e-service composition, in: Proceedings of theInternational Conference on World Wide Web (WWW), 2003, pp. 403–410.[20] D. Calvanese, G. De Giacomo, M. Lenzerini, M. Mecella, F. Patrizi, Automatic service composition and synthesis: The roman model, IEEE Data EngineeringBulletin 31 (3) (2008) 18–22.[21] A. Cimatti, M. Pistore, M. Roveri, P. Traverso, Weak, strong, and strong cyclic planning via symbolic model checking, Artificial Intelligence Jour-nal 147 (1–2) (2003) 35–84.[22] E. Clarke, E. Emerson, Design and synthesis of synchronization skeletons using branching time temporal logic, in: D. Kozen (Ed.), Logics of Programs,in: LNCS, vol. 131, Springer, Berlin/Heidelberg, 1982, pp. 52–71 (Chapter 5).[23] E.M. Clarke, O. Grumberg, D. Peled, Model Checking, The MIT Press, 1999.[24] G. De Giacomo, R. De Masellis, F. Patrizi, Composition of partially observable services exporting their behaviour, in: Proceedings of the InternationalConference on Automated Planning and Scheduling (ICAPS), 2009, pp. 90–97.[25] G. De Giacomo, P. Felli, Agent composition synthesis based on ATL, in: Proceedings of Autonomous Agents and Multi-Agent Systems (AAMAS), 2010,pp. 499–506.[26] G. De Giacomo, F. Patrizi, Automated composition of nondeterministic stateful services, in: Web Services and Formal Methods, 6th International Work-shop, Revised Selected Papers, WS-FM 2009, Bologna, Italy, September 4–5, 2009, in: LNCS, vol. 6194, Springer, 2010, pp. 147–160.[27] G. De Giacomo, F. Patrizi, P. Felli, S. Sardina, Two-player game structures for generalized planning and agent composition, in: Proceedings of theNational Conference on Artificial Intelligence (AAAI), 2010, pp. 297–302.[28] G. De Giacomo, F. Patrizi, S. Sardina, Agent programming via planning programs, in: Proceedings of Autonomous Agents and Multi-Agent Systems(AAMAS), May 2010, pp. 491–498.[29] G. De Giacomo, F. Patrizi, S. Sardina, Generalized planning with loops under strong fairness constraints, in: Proceedings of Principles of KnowledgeRepresentation and Reasoning (KR), 2010, pp. 351–361.[30] G. De Giacomo, S. Sardina, Automatic synthesis of new behaviors from a library of available behaviors, in: Proceedings of the International JointConference on Artificial Intelligence (IJCAI), 2007, pp. 1866–1871.[31] A. Deutsch, L. Sui, V. Vianu, Specification and verification of data-driven web applications, Journal of Computer and System Sciences 73 (3) (2007)442–474.[32] R. Fagin, J.Y. Halpern, Y. Moses, M.Y. Vardi, Reasoning About Knowledge, The MIT Press, Cambridge, Massachusetts, 1995.[33] G.E. Fainekos, A. Girard, H. Kress-Gazit, G.J. Pappas, Temporal logic motion planning for dynamic robots, Automatica 45 (2) (2009) 343–352.[34] M. Gelfond, V. Lifschitz, Action languages, Electronic Transactions of AI (ETAI) 2 (1998) 193–210.G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142141[35] M. Genesereth, N. Love, General game playing: Overview of the AAAI competition, AI Magazine 26 (2005) 62–72.[36] M.P. Georgeff, A.L. Lansky, Reactive reasoning and planning, in: Proceedings of the National Conference on Artificial Intelligence (AAAI), 1987, pp. 677–682.[37] C.E. Gerede, R. Hull, O.H. Ibarra, J. Su, Automated composition of e-services: Lookaheads, in: Proceedings of the International Joint Conference onService Oriented Computing (ICSOC), 2004, pp. 252–262.[38] C.E. Gerede, O.H. Ibarra, B. Ravikumar, J. Su, Online and minimum-cost ad hoc delegation in e-service composition, in: Proceedings of the IEEE Inter-national Conference on Services Computing (SCC), 2005, pp. 103–112.[39] M. Ghallab, D. Nau, P. Traverso, Automated Planning: Theory and Practice, Morgan Kauffman, 2004.[40] A. Harding, M. Ryan, P.-Y. Schobbens, A new algorithm for strategy synthesis in LTL games, in: Proceedings of Tools and Algorithms for the Constructionand Analysis of Systems (TACAS), 2005, pp. 477–492.[41] M.R. Henzinger, T.A. Henzinger, P.W. Kopke, Computing simulations on finite and infinite graphs, in: Proceedings of the Annual Symposium on Foun-dations of Computer Science (FOCS), 1995, pp. 453–462.[42] R. Hull, Web services composition: A story of models, automata, and logics, in: Proceedings of the IEEE International Conference on Services Computing(SCC), 2005, pp. 18–19.[43] B. Jarvis, D. Jarvis, L. Jain, Teams in multi-agent systems, in: Z. Shi, K. Shimohara, D. Feng (Eds.), Intelligent Information Processing III, in: IFIP Interna-tional Federation for Information Processing, vol. 228, Springer, 2007, pp. 1–10 (Chapter 1).[44] B. Jobstmann, R. Bloem, Optimizations for LTL synthesis, in: Proceedings of the Formal Methods in Computer Aided Design (FMCAD), IEEE ComputerSociety Press, 2006, pp. 117–124.[45] B. Jobstmann, S. Galler, M. Weiglhofer, R. Bloem, Anzu: A tool for property synthesis, in: Proceedings of the International Conference Computer AidedVerification (CAV), 2007, pp. 258–262.[46] F. Kabanza, S. Thiébaux, Search control in planning for temporally extended goals, in: Proceedings of the International Conference on AutomatedPlanning and Scheduling (ICAPS), 2005, pp. 130–139.[47] Y. Kesten, N. Piterman, A. Pnueli, Bridging the gap between fair simulation and trace inclusion, Information and Computation 200 (July 2005) 35–61.[48] H. Kress-Gazit, G.E. Fainekos, G.J. Pappas, Where’s Waldo? Sensor-based temporal logic motion planning, in: Proceedings of the IEEE InternationalConference on Robotics and Automation (ICRA), 2007, pp. 3116–3121.[49] H. Kress-Gazit, G.E. Fainekos, G.J. Pappas, Temporal-logic-based reactive mission and motion planning, IEEE Transactions on Robotics 25 (6) (2009)1370–1381.[50] O. Kupferman, M.Y. Vardi, Module checking, in: Proceedings of the International Conference Computer Aided Verification (CAV), 1996, pp. 75–86.[51] O. Kupferman, M.Y. Vardi, Church’s problem revisited, The Bulletin of Symbolic Logic 5 (2) (1999) 245–263.[52] R. Lundh, L. Karlsson, A. Saffiotti, Plan-based configuration of an ecology of robots, in: Proceedings of the IEEE International Conference on Roboticsand Automation (ICRA), 2007, pp. 64–70.[53] R. Lundh, L. Karlsson, A. Saffiotti, Automatic configuration of multi-robot systems: Planning for multiple steps, in: Proceedings of the European Confer-ence in Artificial Intelligence (ECAI), 2008, pp. 616–620.[54] Y. Lustig, M.Y. Vardi, Synthesis from component libraries, in: Proceedings of the International Conference on Foundations of Software Science andComputational Structures (FOSSACS), in: LNCS, vol. 5504, Springer, 2009, pp. 395–409.[55] O. Marin, M. Bertier, P. Sens, DARX – a framework for the fault tolerant support of agent software, in: Proceedings of the IEEE International Symposiumon Software Reliability Engineering (ISSRE), 2003, pp. 406–418.[56] D.L. Martin, M.H. Burstein, D.V. McDermott, S.A. McIlraith, M. Paolucci, K.P. Sycara, D.L. McGuinness, E. Sirin, N. Srinivasan, Bringing semantics to webservices with OWL-S, in: Proceedings of the International Conference on World Wide Web (WWW), 2007, pp. 243–277.[57] S.A. McIlraith, T.C. Son, Adapting golog for composition of semantic web services, in: Proceedings of Principles of Knowledge Representation andReasoning (KR), 2002, pp. 482–496.[58] S.A. McIlraith, T.C. Son, H. Zeng, Semantic web services, IEEE Intelligent Systems 16 (2) (2001) 46–53.[59] K.L. McMillan, Symbolic Model Checking, Kluwer Academic Publishers, Norwell, MA, USA, 1993.[60] R. Milner, An algebraic definition of simulation between programs, in: Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),1971, pp. 481–489.[61] A. Muscholl, I. Walukiewicz, A lower bound on web services composition, Logical Methods in Computer Science 4 (2) (2008).[62] D.S. Nau, T.-C. Au, O. Ilghami, U. Kuter, J.W. Murdock, D. Wu, F. Yaman, SHOP2: An HTN planning system, Journal of Artificial Intelligence Research 20(2003) 379–404.[63] M.P. Papazoglou, P. Traverso, S. Dustdar, F. Leymann, Service-oriented computing: State of the art and research challenges, IEEE Computer 40 (11)(2007) 38–45.[64] O. Pettersson, Execution monitoring in robotics: A survey, Robotics and Autonomous Systems 53 (2) (2005) 73–88.[65] M. Pistore, F. Barbon, P. Bertoli, D. Shaparau, P. Traverso, Planning and monitoring web service composition, in: Proceedings of the Artificial Intelligence:Methodology, Systems, and Applications (AIMSA), in: LNCS, vol. 3192, Springer, 2004, pp. 106–115.[66] M. Pistore, A. Marconi, P. Bertoli, P. Traverso, Automated composition of web services by planning at the knowledge level, in: Proceedings of theInternational Joint Conference on Artificial Intelligence (IJCAI), 2005, pp. 1252–1259.[67] M. Pistore, P. Traverso, Planning as model checking for extended goals in non-deterministic domains, in: Proceedings of the International Joint Confer-ence on Artificial Intelligence (IJCAI), 2001, pp. 479–486.[68] M. Pistore, P. Traverso, P. Bertoli, A. Marconi, Automated synthesis of composite BPEL4WS web services, in: Proceedings of the IEEE InternationalConference on Web Services (ICWS), 2005, pp. 293–301.[69] N. Piterman, A. Pnueli, Y. Sa’ar, Synthesis of Reactive (1) Designs, in: Proceedings of the International Conference on Verification, Model Checking, andAbstract Interpretation (VMCAI), 2006, pp. 364–380.[70] A. Pnueli, R. Rosner, On the synthesis of a reactive module, in: Proceedings of the ACM SIGPLAN–SIGACT Symposium on Principles of ProgrammingLanguages (POPL), 1989, pp. 179–190.[71] A. Pnueli, E. Shahar, A platform for combining deductive with algorithmic verification, in: Proceedings of the International Conference Computer AidedVerification (CAV), 1996, pp. 184–195.[72] D.V. Pynadath, M. Tambe, N. Chauvat, L. Cavedon, Toward team-oriented programming, in: Proceedings of the International Workshop on Agent Theo-ries, Architectures, and Languages (ATAL), Springer, 2000, pp. 233–247.[73] R. Ragab Hassen, L. Nourine, F. Toumani, Protocol-based web service composition, in: Proceedings of the International Joint Conference on ServiceOriented Computing (ICSOC), in: LNCS, vol. 5364, Springer, 2008, pp. 38–53 (Chapter 7).[74] P.J. Ramadge, W.M. Wonham, Supervisory control of a class of discrete event processes, SIAM Journal on Control and Optimization 25 (1987) 206–230.[75] A.S. Rao, AgentSpeak(L): BDI agents speak out in a logical computable language, in: Proceedings of the Seventh European Workshop on ModellingAutonomous Agents in a Multi-Agent World (Agents Breaking Away), in: LNCS, vol. 1038, Springer, 1996, pp. 42–55.[76] A. Saffiotti, M. Broxvall, PEIS ecologies: Ambient intelligence meets autonomous robotics, in: Proceedings of the International Conference on SmartObjects and Ambient Intelligence, 2005, pp. 275–280.142G. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142[77] S. Sardina, G. De Giacomo, Realizing multiple autonomous agents through scheduling of shared devices, in: Proceedings of the International Conferenceon Automated Planning and Scheduling (ICAPS), 2008, pp. 304–312.[78] S. Sardina, G. De Giacomo, Composition of ConGolog programs, in: Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),2009, pp. 904–910.[79] S. Sardina, F. Patrizi, G. De Giacomo, Automatic synthesis of a global behavior from multiple distributed behaviors, in: Proceedings of the NationalConference on Artificial Intelligence (AAAI), 2007, pp. 1063–1069.[80] S. Sardina, F. Patrizi, G. De Giacomo, Behavior composition in the presence of failure, in: Proceedings of Principles of Knowledge Representation andReasoning (KR), 2008, pp. 640–650.[81] M.J. Schoppers, Universal plans for reactive robots in unpredictable environments, in: Proceedings of the International Joint Conference on ArtificialIntelligence (IJCAI), 1987, pp. 1039–1046.[82] E. Sirin, B. Parsia, D. Wu, J. Hendler, D. Nau, HTN planning for web service composition using SHOP2, Journal of Web Semantics: Science, Services andAgents on the World Wide Web 1 (4) (October 2004) 377–396.[83] S. Sohrabi, N. Prokoshyna, S.A. McIlraith, Web service composition via generic procedures and customizing user preferences, in: Proceedings of theInternational Semantic Web Conference (ISWC), 2006, pp. 597–611.[84] S. Sohrabi, N. Prokoshyna, S.A. Mcilraith, Web service composition via the customization of golog programs with user preferences, in: A.T. Borgida,V.K. Chaudhri, P. Giorgini, E.S. Yu (Eds.), Conceptual Modeling: Foundations and Applications, Springer, 2009, pp. 319–334 (Chapter Web and Services).[85] T. Stroeder, M. Pagnucco, Realising deterministic behaviour from multiple non-deterministic behaviours, in: Proceedings of the International JointConference on Artificial Intelligence (IJCAI), 2009, pp. 936–941.[86] J. Su (Ed.), IEEE Data Engineering Bulletin 31 (September 2008).[87] L. Tan, R. Cleaveland, Simulation revisited, in: Proceedings of Tools and Algorithms for the Construction and Analysis of Systems (TACAS), 2001, pp. 480–495.[88] A. Tripathi, R. Miller, Exception handling in agent-oriented systems, in: A. Romanovsky, C. Dony, J. Knudsen, A. Tripathi (Eds.), Advances in ExceptionHandling Techniques, in: LNCS, vol. 2022, Springer, 2001, pp. 128–146.[89] M.Y. Vardi, An automata-theoretic approach to fair realizability and synthesis, in: Proceedings of the International Conference Computer Aided Verifi-cation (CAV), 1995, pp. 267–278.[90] W. Wonham, P. Ramadge, On the supremal controllable sub-language of a given language, SIAM Journal on Control and Optimization 25 (3) (1987)637–659.[91] N. Yadav, S. Sardina, Decision theoretic behavior composition, in: Yolum Tumer, Stone Sonenberg (Eds.), Proceedings of Autonomous Agents and Multi-Agent Systems (AAMAS), 2011, pp. 575–582.[92] N. Yadav, S. Sardina, Qualitative approximate behavior composition, in: Proceedings of the European Conference on Logics in Artificial Intelligence(JELIA), in: LNCS, vol. 7519, Springer, 2012, pp. 450–462.