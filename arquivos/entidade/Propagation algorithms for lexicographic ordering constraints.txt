Artificial Intelligence 170 (2006) 803–834www.elsevier.com/locate/artintPropagation algorithms for lexicographic ordering constraintsAlan M. Frisch a,∗, Brahim Hnich b, Zeynep Kiziltan c, Ian Miguel d, Toby Walsh ea Department of Computer Science, University of York, UKb Faculty of Computer Science, Izmir University of Economics, Turkeyc DEIS, University of Bologna, Italyd School of Computer Science, University of St Andrews, UKe National ICT Australia and Department of CS & E, UNSW, AustraliaReceived 12 April 2005; received in revised form 24 March 2006; accepted 27 March 2006AbstractFinite-domain constraint programming has been used with great success to tackle a wide variety of combinatorial problems inindustry and academia. To apply finite-domain constraint programming to a problem, it is modelled by a set of constraints on a setof decision variables. A common modelling pattern is the use of matrices of decision variables. The rows and/or columns of thesematrices are often symmetric, leading to redundancy in a systematic search for solutions. An effective method of breaking thissymmetry is to constrain the assignments of the affected rows and columns to be ordered lexicographically. This paper develops anincremental propagation algorithm, GACLexLeq, that establishes generalised arc consistency on this constraint in O(n) operations,where n is the length of the vectors. Furthermore, this paper shows that decomposing GACLexLeq into primitive constraintsavailable in current finite-domain constraint toolkits reduces the strength or increases the cost of constraint propagation. Alsopresented are extensions and modifications to the algorithm to handle strict lexicographic ordering, detection of entailment, andvectors of unequal length. Experimental results on a number of domains demonstrate the value of GACLexLeq.© 2006 Elsevier B.V. All rights reserved.Keywords: Artificial intelligence; Constraints; Constraint programming; Constraint propagation; Lexicographic ordering; Symmetry; Symmetrybreaking; Generalized arc consistency; Matrix models1. IntroductionConstraints are a natural means of knowledge representation. For instance: the maths class must be timetabledbetween 9 and 11am on Monday; the helicopter can carry up to four passengers; the sum of the variables must equal100. This generality underpins the success with which finite-domain constraint programming has been applied to awide variety of disciplines [27]. To apply finite-domain constraint programming to a given domain, a problem mustfirst be characterised or modelled by a set of constraints on a set of decision variables, which its solutions must satisfy.A common pattern arising in the modelling process is the use of matrices of decision variables, so-called matrixmodels [9]. For example, it is simple to represent many types of functions and relations in this way [15].* Corresponding author.E-mail addresses: frisch@cs.york.ac.uk (A.M. Frisch), brahim.hnich@ieu.edu.tr (B. Hnich), zkiziltan@deis.unibo.it (Z. Kiziltan),ianm@dcs.st-and.ac.uk (I. Miguel), tw@cse.unsw.edu.au (T. Walsh).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.03.002804A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834Concomitant with the selection of a matrix model is the possibility that the rows and/or columns of the matrixare symmetric. Consider, for instance, a matrix model of a constraint problem that requires finding a relation R onA × B where A and B are n-element and m-element sets of interchangeable objects respectively. The matrix, M, hasn columns and m rows to represent the elements of A and B. Each decision variable Ma,b can be assigned either 1 or0 to indicate whether (cid:3)a, b(cid:4) ∈ A × B is in R. Symmetry has been introduced because the matrix, whose columns androws are indexed by A and B, distinguishes the position of the elements of the sets, whereas A and B did not. Givena (non-)solution to this problem instance, a (non-)solution can be obtained by permuting columns of assignmentsand/or permuting rows of assignments. This is known as row and column symmetry [8]. Since similar behaviour canbe found in multidimensional matrices of decision variables it is known more generally as index symmetry. As is welldocumented, symmetry can lead to a great deal of redundancy in systematic search [8].As reviewed in Section 2.5 of this paper, lexicographic ordering constraints have been shown to be an effectivemethod of breaking index symmetry. This paper describes a constraint propagation algorithm, GACLexLeq, that en-forces this constraint. Given a lexicographic ordering constraint c, the propagation algorithm removes values from thedomains of the constrained variables that cannot be part of any solution to c. This paper also shows that GACLexLeqestablishes a property called generalised arc consistency,—that is it removes all infeasible values—while only re-quiring a number of operations linear in the number of variables constrained. The GACLexLeq algorithm is alsoincremental; if the domain of a variable is reduced the algorithm can re-establish generalised arc consistency withoutworking from scratch.Although the examples and experiments in the paper employ the lexicographic ordering constraint to break indexsymmetry, we note that lexicographic ordering can be used to break any symmetry that operates on the variables ofan instance. The lex-leader method [5] breaks all symmetry by identifying a representative among the elements of theequivalence class of symmetries of an instance and adding a lexicographic ordering constraint for each other elementof the equivalence class to ensure that only the representative is allowed.The paper is organised as follows. Section 2 introduces the necessary background while Section 3 describes a num-ber of applications used to evaluate our approach. Section 4 presents a propagation algorithm for the lexicographicordering constraint. Then Section 5 discusses the complexity of the algorithm, and proves that the algorithm is soundand complete. Section 6 extends the algorithm to propagate a strict ordering constraint, to detect entailment, and tohandle vectors of different lengths. Alternative approaches to propagating the lexicographic ordering constraint arediscussed in Section 7. Section 8 demonstrates that decomposing a chain of lexicographic ordering constraints intolexicographic ordering constraints between adjacent or all pairs of vectors hinders constraint propagation. Computa-tional results are presented in Section 9. Finally, we conclude and outline some future directions in Section 10.2. BackgroundAn instance of the finite-domain constraint satisfaction problem (CSP) consists of:• a finite set of variables X ;• for each variable X ∈ X , a finite set D(X) of values (its domain); and• a finite set C of constraints on the variables, where each constraint c(X1, . . . , Xn) ∈ C is defined over the variablesX1, . . . , Xn by a subset of D(X1) × · · · × D(Xn) giving the set of allowed combinations of values. That is, c isan n-ary relation.A variable assignment maps every variable in a given instance of CSP to a member of its domain. A variableassignment A is said to satisfy a constraint c(X1, . . . , Xn) if and only if (cid:3)A(X1), . . . , A(Xn)(cid:4) is in the relation denotedby c. A solution to an instance of CSP is a variable assignment that satisfies all the constraints. An instance is said to besatisfiable if it has a solution; otherwise it is unsatisfiable. Typically, we are interested in finding one or all solutions,or an optimal solution given some objective function. In the presence of an objective function, a CSP instance is aninstance of the constraint optimisation problem.To impose total ordering constraints on variables and vectors of variables there must be an underlying total orderingon domains. If the domain of interest is not totally ordered, a total order can be imposed. And now, since domainsare always finite, every domain is isomorphic to a finite set of integers. So we shall simplify the presentation byconsidering all domains to be finite sets of integers.A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834805The minimum element in the domain of variable X is min(X), and the maximum is max(X). Throughout, vars(c)is used to denote the set of variables constrained by constraint c.If a variable X has a singleton domain {v} we say that v is assigned to X, or simply that X is assigned. If two.= X(cid:6)). If v is.= X(cid:6), otherwise we write ¬(Xvariables X and X(cid:6) are assigned the same value, then we write Xassigned to X and v(cid:6) is assigned to X(cid:6) and v < v(cid:6) then we write X (cid:2) X(cid:6).A constraint c is entailed if all assignments of values to vars(c) satisfy c. If a constraint can be shown to be entailedthen running the (potentially expensive) propagation algorithm can be avoided. Similarly, a constraint c is disentailedwhen all assignments of values to vars(c) violate c. Observe that if a constraint in a CSP instance can be shown to bedisentailed then the instance has no solution.2.1. Generalised arc consistencyThis paper focuses on solving the CSP by searching for a solution in a space of assignments to subsets of thevariables. Solution methods of this type use propagation algorithms that make inferences based on the domains ofthe constrained variables and the assignments that satisfy the constraint. These inferences are typically recordedas reductions in variable domains, where the elements removed cannot form part of any assignment satisfying theconstraint, and therefore any solution. At each node in the search, constraint propagation algorithms are used toestablish a local consistency property. A common example is generalised arc consistency (see [19]).Definition 1 (Generalised arc consistency). A constraint c is generalised arc consistent (or GAC), written GAC(c), ifand only if for every X ∈ vars(c) and every v ∈ D(X), there is at least one assignment to vars(c) that assigns v to Xand satisfies c. Values for variables other than X participating in such assignments are known as the support for theassignment of v to X.Generalised arc consistency is established on a constraint c by removing elements from the domains of variablesin vars(c) until the GAC property holds. For binary constraints, GAC is equivalent to arc consistency (AC, see [18]).2.2. Vectors and lexicographic orderingA one-dimensional matrix, or vector, is an ordered list of elements. We denote a vector of n variables as(cid:7)X = (cid:3)X0, . . . , Xn−1(cid:4), while we denote a vector of n integers as (cid:7)x = (cid:3)x0, . . . , xn−1(cid:4). In either case, a sub-vectorfrom index a to index b inclusive is denoted by the subscript a..b, such as: (cid:7)xa..b. We define min((cid:3)X0, . . . , Xn−1(cid:4))to be (cid:3)min(X0), . . . , min(Xn−1)(cid:4) and, similarly, max((cid:3)X0, . . . , Xn−1(cid:4)) to be (cid:3)max(X0), . . . , max(Xn−1)(cid:4). We de-fine (cid:3)x0, . . . , xn−1(cid:4) ∈ (cid:3)X0, . . . , Xn−1(cid:4) to be true if and only if xi ∈ D(Xi) for all i ∈ [0, n − 1]. Finally, we define(cid:3)X0, . . . , Xn−1(cid:4) .= (cid:3)Y0, . . . , Yn−1(cid:4) to be true if and only if Xi.= Yi for all i ∈ [1, n).A vector of distinct variables is displayed by a vector of the domains of the corresponding variables. For in-stance, (cid:7)X = (cid:3){1, 3, 4}, {1, 2, 3, 4, 5}, {1, 2}(cid:4) denotes the vector of three distinct variables, whose domains are {1, 3, 4},{1, 2, 3, 4, 5}, and {1, 2}, respectively.Lexicographic ordering is a total ordering on vectors and is used, for instance, to order the words in a dictionary.Lexicographic ordering is defined on equal-sized vectors as follows.Definition 2. Strict lexicographic ordering (cid:7)x <lex (cid:7)y between two length n vectors of integers (cid:7)x and (cid:7)y holds if and onlyif for some k ∈ [0, n) it is the case that (cid:7)x0..k−1 = (cid:7)y0..k−1 and xk < yk.This ordering can be weakened to include equality.Definition 3. Two equal-length vectors of integers (cid:7)x and (cid:7)y are lexicographically ordered (cid:7)x (cid:2)lex (cid:7)y if and only if(cid:7)x <lex (cid:7)y or (cid:7)x = (cid:7)y.Given two equal-length vectors of variables (cid:7)X and (cid:7)Y , we write a lexicographic ordering constraint as (cid:7)X (cid:2)lex(cid:7)Y and(cid:7)Y . These constraints are satisfied by an assignment if the vectorsa strict lexicographic ordering constraint as (cid:7)X <lex(cid:7)x and (cid:7)y assigned to (cid:7)X and (cid:7)Y are ordered according to Definitions 3 and 2, respectively.806A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–8342.3. Variable symmetryVarious types of symmetries arise in instances of the CSP. All of the symmetries considered in this paper arevariable symmetries. A variable symmetry for an instance I of the CSP is a bijection σ on the variables of I such thatany total variable assignment A is a solution to I if and only if A · σ (the functional composition of A and σ ) is. Thishas the obvious consequence that the identity function is a variable symmetry. It also means that every variable X hasthe same domain as σ (X); otherwise, not every assignment would be mapped to an assignment.As is the usual practice, we consider a set of symmetries on a problem instance, and the set always forms a group.This means that the inverse of a symmetry is also a symmetry and so is the composition of two symmetries. Sucha set of symmetries is called a symmetry group. Two assignments, A and A(cid:6), are said to be symmetric if, for somesymmetry σ in the symmetry group, A · σ = A(cid:6). A symmetry group partitions the set of total assignments for a CSPinstance into equivalence classes, called symmetry classes, where the members of each equivalence class are pairwisesymmetric. Notice that either all members of a symmetry class are solutions or none are.Symmetry in a CSP instance introduces symmetry in its search space of partial assignments. The subtrees rooted attwo symmetric partial assignments are symmetric to each other1 and the solutions, if any, in one subtree are symmetricto those in the other subtree. Since the two symmetric subtrees contain symmetric solutions, there is no need to searchboth; any solutions found in one can be transformed into the solutions of the other simply by applying the relevantsymmetry to it. It is important to note that a search space can contain symmetric subtrees that contain no solutions.Thus, even in cases where an instance has no solutions or where we are searching for only a single solution, subtreesthat are symmetric to each other can be encountered.The search of a space of partial assignments can be sped up by employing some method that avoids searchingsome or all parts of the space that are symmetric with parts that are searched. Such a method is often referred to assymmetry breaking. Symmetry is often broken “statically” by transforming a problem instance into one that has fewersymmetries. This is achieved by adding to the instance a constraint, called a symmetry-breaking constraint, that is trueof some, but not all, symmetric assignments [22]. For example, consider a CSP instance with the variable symmetrythat swaps X and Y . Adding the constraint X (cid:2) Y to the instance breaks the symmetry—that is, the resulting instancedoes not have the symmetry. We often talk of a set of symmetry-breaking constraints, which can be considered as theconstraint consisting of the conjunction of all the members of the set.We say that a symmetry-breaking constraint c is consistent for a CSP instance with a symmetry group if c issatisfied by at least one assignment in every symmetry class. The constraint c is complete if it is satisfied by at mostone assignment in every symmetry class.Crawford et al. [5] showed a method for generating a set of lexicographic ordering constraints that are consis-tent and complete for breaking any group of variable symmetries. It starts with an enumeration (cid:7)X of the variablesin the instance. The set of symmetry-breaking constraints contains one constraint of the form (cid:3)X0, . . . , Xn−1(cid:4) (cid:2)lex(cid:3)σ (X0), . . . , σ (Xn−1)(cid:4) for each symmetry σ in the group. Since this set of constraints is often too large to use inpractice, what is often used is a subset and/or simplification of these constraints, which gives a consistent, thoughincomplete, set of symmetry-breaking constraints. For this reason, lexicographic ordering constraints are widely usedfor breaking variable symmetries.2.4. Matrix models and index symmetryA matrix model is the formulation of a CSP with one or more matrices of decision variables [9]. Matrix models area natural way to represent problems that involve finding a function or relation. For example, in the warehouse locationproblem (prob034 in CSPLib [13]), we need to find a function from stores to warehouses that determines whichwarehouse supplies each store. As a second example, in the steel mill slab design problem (prob038 in CSPLib), weneed to find a function from orders to slabs that determines which slab is used to satisfy each order. Other examplesare encountered later in this paper. Matrix models have been long used in integer linear programming [23], and arecommonly used in constraint programming. Of the first 38 problems in CSPLib, at least 33 have matrix models, mostof them already published and proved successful [9].1 For the purposes of this paper precise definitions of symmetric partial assignments and symmetric search trees are not necessary.A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834807Matrices can be of any number of dimensions; the examples used in this paper have two or three dimensions. If amatrix X of variables has n dimensions, we denote each of its elements by Xi1,...,in . In a two-dimensional matrix werefer to the first dimension as the columns of the matrix and the second dimension as the rows. In general, the valuesthat are used to index the matrix can be drawn from any finite set. Without loss of generality, we shall assume that adimension that has n index values uses {0, . . . , n − 1} as its index values.Many matrix models have variable symmetries among the variables of the matrix (matrices). A common pattern ofsymmetry is that the rows and/or columns of an assignment to a 2D matrix can be swapped without affecting whetheror not the assignment is a solution [9]. These are called row symmetry or column symmetry; the general term is indexsymmetry.Definition 4. Let I be a CSP instance containing a two-dimensional matrix X of variables. A column symmetry for Iis a variable symmetry, σ , for I such that for some bijection ρ on the column indices of X,• σ (Xi,j ) = Xρ(i),j , for every variable Xi,j in matrix X, and• σ (Y ) = Y for every variable not in matrix X.A row symmetry is the same as a column symmetry except that it operates on the second index of the matrix ratherthan on the first.Thus, for a particular index i of a matrix, every index symmetry σ on i corresponds to a unique bijection ρi on thevalues of index i. We therefore identify an index symmetry by ρ and the index on which it operates.Again, we are interested only in groups of index symmetries and, particularly, groups of two kinds. If every bijec-tion on the values of an index is an index symmetry, then we say that the index has total symmetry. If the first (resp.second) index of a 2D matrix has total symmetry, we say that the matrix has total column symmetry (resp. total rowsymmetry). We also say that all the columns (resp. rows) of the matrix are interchangeable.In many matrix models only a subset of the rows or columns are interchangeable. Let I be non-singleton, non-empty subset of the values of index i of a matrix. Let S be the set containing every bijection ρ on the values of indexi such that ρ(v) = v for every v /∈ I . If every member of S is an index symmetry for i then we say that the matrix haspartial index symmetry. If the first (resp. second) index of a 2D matrix has partial symmetry, we say that the matrixhas partial column symmetry (resp. partial row symmetry). We also say that all the columns (resp. rows) in I of thematrix are interchangeable.There is one final case to consider: an index may have partial index symmetry on multiple subsets of its values. Forexample, a CSP instance may have a 2D matrix for which rows 1, 2 and 3 are interchangeable and rows 5, 6 and 7 areinterchangeable. This can occur on any or all of the indices.Section 3 of this paper gives several examples of CSPs that have index symmetry.An n × m matrix with total row and total column symmetry has n!m! symmetries. Consequently, it can be verycostly to visit all the symmetric branches in a tree search. The next subsection explains how to break many of thesesymmetries.2.5. Lexicographic ordering constraints for breaking index symmetryThe application of lexicographic ordering constraints considered by this paper is to breaking symmetries in CSPinstances that have matrices with index symmetry. This section summarises the major results from Flener et al. [8]and Shlyakhter [25] on breaking index symmetries with lexicographic ordering constraints.If a matrix in a CSP instance has total column (resp. row) symmetry, then the symmetry can be broken completelyby a symmetry-breaking constraint that imposes a total ordering on the rows (resp. columns). The total ordering usedhere is the lexicographic ordering. In particular, we constrain the columns (resp. rows) to be non-decreasing as thevalue of the index increases. One way to achieve this, which is used in the experiments presented in this paper, is byimposing a constraint between adjacent columns (resp. rows). If X is an n by m matrix of decision variables, then webreak column symmetry by imposing the constraints(cid:3)Xi,0, . . . , Xi,m(cid:4) (cid:2)lex (cid:3)Xi+1,0, . . . , Xi+1,m(cid:4)(i ∈ [0, n − 2])808A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834and we break row symmetry by imposing the constraints(cid:3)X0,j , . . . , Xn,j (cid:4) (cid:2)lex (cid:3)X0,j +1, . . . , Xn,j +1(cid:4)(j ∈ [0, m − 2]).Though these lexicographic ordering constraints are consistent and complete for total row or total column symmetryindividually, they are not complete for a matrix that has both kinds of symmetry. They are, however, consistent andhave been shown to be effective at removing many symmetries from the search spaces of many problems. Care mustbe taken in specifying these constraints; if, the column constraints take Xi,0 to be the most significant position in eachcolumn and the row constraints take Xn,j to be the most significant position in each row, then the conjunction of theconstraints is an inconsistent symmetry-breaking constraint.If a matrix has only partial column (resp. partial row) symmetry then the symmetry can be broken by constrainingthe interchangeable columns (resp. rows) to be in lexicographically non-decreasing order. This can be achieved ina manner similar to that described above. The method also extends to matrices that have partial or total columnsymmetry together with partial or total row symmetry. Finally, if the columns and/or rows of a matrix have multiplepartial symmetries than each can be broken in the manner just described.Though it will not arise in this paper, lexicographic ordering constraints can be used in a similar manner to breaksymmetry in multi-dimensional matrices that have partial or total index symmetry on any number of its dimensions.3. ApplicationsThis section presents matrix models for three combinatorial problems in which lexicographic ordering constraintscan be used to break index symmetry. These models are used in the experiments presented in Section 9.3.1. Progressive party problemThe progressive party problem arises in the context of organising the social programme for a yachting rally(prob013 in www.csplib.org). Given a set of boats, each with a number of crew members and a capacity in termsof the number of guests it can accommodate, the problem is to designate a minimal subset of the boats as hosts andschedule the remaining boats to visit the hosts for a number of half-hour periods. All members of a particular guestcrew remain together, and the crew of host boats remain on board their own boat. A guest boat cannot revisit a hostand guest crews cannot meet more than once.A simplified version of this problem, also studied by Smith et al. [24], removes the objective function, pre-designating the host boats and asking for only the schedule to be found. We study this version of the problem here.Let Periods be the set of time periods, Guests the set of guest boats and Hosts the set of host boats. Each host boatk has a capacity ck (after taking its own crew into consideration), and each guest boat j has a crew size sj . Smith etal.’s matrix model of this problem is given in Fig. 1. It comprises two matrices, H indexed by Periods × Guests andB indexed by Periods × Guests × Hosts. If Hi,j = k, or equivalently Bi,j,k = 1, then in period i, guest j visits hostk. Although B is redundant given H , it allows the capacity constraints to be specified concisely.Constraint (1) ensures that every pair of guest crews meet at most once. Note that the constraint sub-expression= Hi,j2 is reified to a 1 or a 0 value, depending on whether or not it is satisfied. Hence, the summation counts theHi,j1number of periods in which guest crews j1 and j2 are assigned the same host value. Constraint (2) disallows a guestcrew from revisiting a host boat over the course of the schedule. Here, for the sake of presentation, the periods areconsidered to be the integers 0, . . . , p − 1. Constraint (3) ensures that the capacity of each host boat is never exceeded.Finally, Constraint (4) is a channelling constraint [3], which maintains consistency between the H and B matrices.The time periods are interchangeable, hence there is total symmetry on the first index of H and the first indexof B.2 Guests with equal crew size are interchangeable, which means that there is partial symmetry on the secondindex of H and the second index of B. Finally, hosts with equal capacity are interchangeable, hence there is partialsymmetry on the third index of B.2 Observe that this is the same symmetry in both matrices and therefore cannot be broken independently in the two matrices. This issue ariseselsewhere, but for concision we do not re-address it.A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834809Given:Periods, Guests, Hosts,matrix ck indexed by k ∈ Hosts,matrix sj indexed by j ∈ GuestsDecision Variables:matrix Hi,j with domain Hosts indexed by i ∈ Periods, j ∈ Guests,matrix Bi,j,k with domain {0, 1} indexed by i ∈ Periods, j ∈ Guests, k ∈ Hostsi∈Periods(Hi,j1Constraints:(cid:2)= Hi,j2 ) (cid:2) 1(1)(2) all-different((cid:3)H0,j , H1,j , . . . , Hp−1,j (cid:4)) (j ∈ Guests)(3)(4) Hi,j = k ↔ Bi,j,k = 1j ∈Guests sj ∗ Bi,j,k (cid:2) ck(cid:2)(j1, j2 ∈ Guests, j1 < j2)(i ∈ Periods, k ∈ Hosts)(i ∈ Periods, j ∈ Guests, k ∈ Hosts)Fig. 1. Matrix model of the progressive party problem from [24].Given:T emplates, Variations, s,matrix dj indexed by j ∈ VariationsDecision Variables:matrix Runi with domain {0, . . . , max(dj )} indexed by i ∈ T emplates,matrix Ti,j with domain {0, . . . , s} indexed by i ∈ T emplates, j ∈ VariationsConstraints:(cid:2)(1)(cid:2)(2)j ∈Variations Ti,j = s(i ∈ T emplates)i∈T emplates Runi ∗ Ti,j (cid:3) dj (j ∈ Variations)Objective:minimize(cid:2)i∈T emplates RuniFig. 2. Matrix model of the template design problem from [21].3.2. Template design problemThe template design problem (prob002 in CSPLib) involves configuring a set of printing templates with designvariations that need to be printed to meet specified demand. Given is a set of variations of a design, with a commonshape and size and such that the number of required “pressings” of each variation is known. The problem is to designa set of templates, with a common capacity to which each must be filled, by assigning zero or more instances of avariation to each template. A design should be chosen that minimises the total number of “runs” of the templatesrequired to satisfy the number of pressings required for each variation. As an example, the variations might be forcartons for different flavours of cat food, such as fish or chicken, where ten thousand fish cartons and twenty thousandchicken cartons need to be printed. The problem would then be to design a set of templates by assigning a number offish and/or chicken designs to each template such that a minimal number of runs of the templates is required to printall thirty thousand cartons.Proll and Smith address this problem by fixing the number of templates and minimising the total number of press-ings [21]. We will adopt their model herein. Let T emplates be the fixed-size set of templates, each with capacity s,to which variations are to be assigned. Let Variations be the set of variations. Each variation, j , is described by ademand dj that specifies the minimum number of pressings required. Proll and Smith’s model is given in Fig. 2. Itcomprises two matrices, Run indexed by T emplates, and T indexed by T emplates × Variations. If Runi = j , thentemplate i is printed j times, where j ranges between 0 and the maximum number of pressings required by any singlevariation. Similarly, if Ti,j = k then template i is assigned k instances of variation j , where 0 (cid:2) k (cid:2) s.810A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834Given:v, b, r, k, λLet:B = {0, . . . , b − 1} and V = {0, . . . , v − 1}Decision Variables:matrix Xi,j with domain {0, 1} indexed by i ∈ B, j ∈ VConstraints:(cid:2)(1)(cid:2)(2)(cid:2)(3)i∈B Xi,j = rj ∈V Xi,j = ki∈B Xi,j1∗ Xi,j2(j ∈ V)(i ∈ B)= λ (j1, j2 ∈ V, j1 < j2)Fig. 3. Matrix model of the BIBD problem from [20].Constraint (1) ensures that every template has all its s slots occupied, and constraint (2) specifies that the totalproduction of each variation is at least its demand. The objective is then to minimise the total number of pressings.In this model all the templates are interchangeable, hence Run has total symmetry on its index and T has totalsymmetry on its first index. Variations of equal demand are interchangeable, hence there is total symmetry on thesecond index of T .3.3. Balanced incomplete block design problemThe balanced incomplete block design (BIBD) problem is a standard combinatorial problem from design theory [4]with applications in experimental design and cryptography (prob028 in CSPLib). Given the tuple of natural numbers(cid:3)v, b, r, k, λ(cid:4), the problem is to arrange v distinct objects into b blocks such that each block contains exactly k distinctobjects, each object occurs in exactly r different blocks, and every two distinct objects occur together in exactly λblocks.Meseguer and Torras’ model [20], which we adopt in this paper, is given in Fig. 3. It comprises one matrix, X,indexed by B × V, where B = {0, . . . , b − 1} is the set of blocks and V = {0, . . . , v − 1} is the set of objects. Xi,j = 1 ifand only if block i contains object j . Constraints (1) and (2) ensure, respectively, that each object appears in r blocksand that each block contains k objects. Constraint (3) is a scalar product constraint that requires every pair of objectsto meet in exactly λ blocks. Since both the objects and the blocks are interchangeable, the matrix X has total row andtotal column symmetry.4. A propagation algorithmWe present a propagation algorithm for the lexicographic ordering constraint that either detects the disentailmentof (cid:7)X (cid:2)lex(cid:7)Y or prunes inconsistent values to establish GAC on (cid:7)X (cid:2)lex(cid:7)Y .In order to simplify the presentation, here and throughout the entire paper we consider only the case where (cid:7)X and(cid:7)Y are variable-distinct in the following sense:Definition 5. A pair of vectors is variable-distinct if each contains only CSP variables, each contains no repeatedvariables, and there are no variables common to both vectors.Note that the majority of applications, such as those described in the previous section, involve ordering variable-distinct vectors. Kiziltan [17] gives an algorithm similar to that presented here, but which caters for the cases wherevariables are repeated. In the presence of repeated variables, the algorithms given herein can be used by the followingsimple expedient. Consider a constraint c with two occurrences of variable X. We can replace c with c(cid:6) ∧ (X = X(cid:6)),where X(cid:6) has the same domain as X and c(cid:6) results from replacing one occurrence of X in c with X(cid:6). This stepcan be repeated to remove all repeated occurrences of a single variable. This approach preserves soundness, but notcompleteness.The key to the algorithm is that there are two significant indices within (cid:7)X and (cid:7)Y . The index α is the least index atwhich (cid:7)X and (cid:7)Y are not ground and equal. If there is no such index α is n. The index β is the least index in [α, n) suchA.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834811that (cid:7)Xβ..n−1 >lexregions of (cid:7)X and (cid:7)Y within indices [α, β).(cid:7)Yβ..n−1 is entailed. If there is no such index, β is n + 1. The algorithm only needs to consider the4.1. A worked exampleWe now illustrate the GACLexLeq algorithm by considering its operation on the lexicographic ordering constraint(cid:7)X (cid:2)lex(cid:7)Y , where (cid:7)X and (cid:7)Y are variable-distinct and have the domains:(cid:7)X =(cid:7)Y =(cid:4){1, 3, 4}, {1, 2, 3, 4, 5}, {1, 2}, {3, 4, 5}(cid:4){0, 1, 2, 3, 4}, {0, 1}, {0, 1, 2}(cid:3){1}, {2},(cid:3){1}, {2}, {0, 1, 2},{1},{2},The program variables alpha and beta are used to record the values α and β. When the domains of (cid:7)X and (cid:7)Y arereduced alpha and beta may no longer contain the values α and β so the algorithm needs to update these programvariables.We traverse the vectors once in order to initialise alpha and beta. Starting from index 0, we move first to index.= Y1. We stop at 2 and set alpha = 2 = α as Y2 is not assigned.1 and then to index 2 because X0(cid:3){1}, {2},(cid:3){1}, {2}, {0, 1, 2},alpha ↑(cid:7)X =(cid:7)Y ={2},.= Y0 and X1{1, 3, 4}, {1, 2, 3, 4, 5}, {1, 2}, {3, 4, 5}{0, 1, 2, 3, 4}, {0, 1}, {0, 1, 2}{1},(cid:4)(cid:4)We initialise beta by traversing the vectors starting from alpha. At index 2 min(X2) = max(Y2), thereforeX2 (cid:3) Y2 is entailed. Hence, β may equal 2, but this can only be determined by examining the variables with greaterindices. At index 3, min(X3) = max(Y3). This neither precludes nor confirms β = 2. At index 4, it is possible tosatisfy X4 (cid:2) Y4. Hence, we have determined β (cid:11)= 2. At index 5 min(X5) = max(Y5), therefore X5 (cid:3) Y5 is entailed.Similarly, β may equal 5, but this can only be determined by examining the variables with greater indices. At index 6,min(X6) > max(Y6), so X6 > Y6 is entailed. Hence, (cid:7)X5..6 >lex(cid:7)Y5..6 is entailed, and therefore β = 5, to which betais initialised.(cid:3)(cid:7)X ={1}, {2},(cid:3)(cid:7)Y ={1}, {2}, {0, 1, 2},alpha ↑{1, 3, 4}, {1, 2, 3, 4, 5},{0, 1, 2, 3, 4},{1, 2},{0, 1},↑ beta(cid:4){3, 4, 5}(cid:4){0, 1, 2}{2},{1},The algorithm restricts domain pruning to the index alpha. As values are removed from the domains of thevariables, the value of alpha monotonically increases and the value of beta monotonically decreases. The constraintis disentailed if the values of alpha and beta become equal.Consider the vectors again. As the vectors are assigned and equal at the indices less than alpha, there is nosupport for any value in D(Yalpha) that is less than min(Xalpha). We therefore remove 0 and 1 from D(Yalpha) andincrement alpha to 3 = α:(cid:3){1}, {2}, {2}, {1, 3, 4}, {1, 2, 3, 4, 5}, {1, 2},(cid:3){0, 1, 2, 3, 4}, {0, 1},{1}, {2}, {2},↑ betaSimilarly, there is no support for any value in D(Xalpha) greater than max(Yalpha). We therefore remove 3 and 4from D(Xalpha) and increment alpha to 4 = α:(cid:4){3, 4, 5}(cid:4){0, 1, 2}{1},alpha ↑(cid:7)X =(cid:7)Y =(cid:7)X =(cid:7)Y =(cid:3){1}, {2}, {2}, {1}, {1, 2, 3, 4, 5}, {1, 2},(cid:3){1}, {2}, {2}, {1}, {0, 1, 2, 3, 4}, {0, 1},alpha ↑ ↑ beta(cid:4)(cid:4){3, 4, 5}{0, 1, 2}Since alpha = beta − 1, there is no support for any value in D(Xalpha) greater than or equal to max(Yalpha).Similarly, there is no support for any value in D(Yalpha) less than or equal to min(Xalpha). We must thereforeestablish arc consistency on Xalpha < Yalpha. Doing so removes 4 and 5 from D(Xalpha), and also 0 and 1 fromD(Yalpha):(cid:7)X =(cid:7)Y =(cid:3){1}, {2}, {2}, {1}, {1, 2, 3},(cid:3){1}, {2}, {2}, {1}, {2, 3, 4},{3, 4, 5}{0, 1, 2}(cid:4)(cid:4){1, 2},{0, 1},alpha ↑ ↑ beta812A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834The constraint (cid:7)X (cid:2)lex(cid:7)Y is now GAC.4.2. Theoretical backgroundThis section formally defines α and β and presents two theorems that show their significance in propagating theconstraint (cid:7)X (cid:2)lex(cid:7)Y .Definition 6. Given two length n variable-distinct vectors, (cid:7)X and (cid:7)Y , α is the least index in [0, n) such that ¬(Xαor, if no such index exists, n..= Yα)Definition 7. Given two length n variable-distinct vectors, (cid:7)X and (cid:7)Y , β is the least index in [α, n) such that∃k ∈ [β, n) .(cid:5)(cid:6)min(Xk) > max(Yk) ∧ min( (cid:7)Xβ..k−1) = max( (cid:7)Yβ..k−1)or, if no such index exists, n + 1.The relative values of α and β provide important information about the constraint (cid:7)X (cid:2)lex(cid:7)Y . By definition, β cannotbe strictly less than α. The following two theorems in turn address the cases when α = β and when α < β. The firsttheorem states that if α = β then the constraint is disentailed.Theorem 1. Let (cid:7)X and (cid:7)Y be a pair of length n variable-distinct vectors. α = β if and only if (cid:7)X (cid:2)lex(cid:7)Y is disentailed.(⇐) If (cid:7)X (cid:2)lex.= (cid:7)Y0..α−1, and by Definition 7 (cid:7)Xβ..n−1 >lexProof. (⇒) By Definition 6, (cid:7)X0..α−1there is no assignment that can satisfy (cid:7)X (cid:2)lex(cid:7)Y is disentailed then (cid:7)X >lex(cid:7)Y .(cid:7)Y is entailed. From the definition of strict lexicographic ordering theremust be an index i such that min(Xi) > max(Yi). Let j be the least such index. If j = 0 then, by Definitions 6 and.= (cid:7)Y0..j −1 then from7, α = j = β. Otherwise observe that min(Xh) (cid:2) max(Xh) for all h ∈ [0, j − 1]. If (cid:7)X0..j −1.= Yg). ThenDefinition 6 α = j and from Definition 7 β = j . Otherwise, let g < j be the least index such that ¬(Xgfrom Definition 6 g = α and from Definition 7 g = β. (cid:2)(cid:7)Yβ..n−1 is entailed. Since β = αThe second theorem states that if β > α then the constraint is GAC if and only if α = n or all values at index αhave support.Theorem 2. Let (cid:7)X and (cid:7)Y be a pair of length n variable-distinct vectors such that β > α. GAC( (cid:7)X (cid:2)lexif either(cid:7)Y ) if and only1. β = α + 1 and AC(Xα < Yα), or2. β > α + 1 and AC(Xα (cid:2) Yα).Proof. (⇒) Assume (cid:7)X (cid:2)lex(cid:7)Y is GAC but either Xα < Yα is not AC when β = α + 1 or Xα (cid:2) Yα is not AC whenβ > α + 1. Then either there exists no value in D(Yα) greater than (or equal to) a value a in D(Xα), or there exists novalue in D(Xα) less than (or equal to) a value b in D(Yα). Since the variables are all assigned and pairwise equal atindices less than α, a or b lacks support from all the variables in the vectors. This contradicts that (cid:7)X (cid:2)lex(cid:7)Y is GAC.(⇐) All variables with indices less than α are assigned and pairwise equal. Therefore, the assignment Xα (cid:2) Yαprovides support for all values at indices greater than α. Hence, given β = α + 1 and AC(Xα < Yα) the constraintis GAC. Similarly, if β > α + 1 and AC(Xα (cid:2) Yα) then Xα (cid:2) Yα supports all values at indices greater than α. It.= Yα. If β = n + 1, then by definition min(Xi) (cid:2) max(Yi) for allremains to consider the assignments that set Xαi ∈ [α, n) and the constraint is GAC. Otherwise, from the definition of β, min(Xi) (cid:2) max(Yi) for all i ∈ [α, β) and.= Yα is supported by the combination of Xβ−1 (cid:2) Yβ−1¬(Xβ−1and (cid:7)Xα+1..β−2.= Yβ−1). Since (cid:7)X and (cid:7)Y are variable-distinct, Xα.= (cid:7)Yα+1..β−2. Hence, the constraint is GAC. (cid:2)A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834813Algorithm GACLexLeq.= Yalpha) do alpha := alpha + 1if (min(Xi ) = max(Yi )) then if (beta = −1) then beta := ielse beta := −1i := i + 1alpha := 0while (alpha < n ∧ Xalphaif (alpha = n) then beta := n + 1, returni := alphabeta := −1while (i (cid:11)= n ∧ min(Xi ) (cid:2) max(Yi )) doEstablishGACA1A2A3A4A5A6A6.1A6.2A6.3A7A8A9A10ReEstablishGAC(i in [0, n)) Triggered when min(Xi ) or max(Yi ) changesA11A12A12.1A12.2A13A13.1A13.2if (i = alpha ∧ i + 1 = beta) then EstablishAC(Xi < Yi )if (i = alpha ∧ i + 1 < beta) thenEstablishAC(Xi (cid:2) Yi ).= Yi ) then UpdateAlphaif (Xiif (i = n) then beta := n + 1else if (beta = −1) then beta := iif (alpha = beta) then disentailedReEstablishGAC(alpha)if (alpha < i < beta) thenUpdateBeta(i − 1)if ((i = beta − 1 ∧ min(Xi ) = max(Yi )) ∨ min(Xi ) > max(Yi )) thenUpdateAlphaA14A15A16A17A18alpha := alpha + 1if (alpha = n) then returnif (alpha = beta) then disentailedif (¬(Xalphaelse UpdateAlpha.= Yalpha)) then ReEstablishGAC(alpha)UpdateBeta(i in [0, n))A19A20A21A21.1A22beta := i + 1if (alpha = beta) then disentailedif (min(Xi ) < max(Yi )) thenelse UpdateBeta(i − 1)if (i = alpha) then EstablishAC(Xi < Yi )Fig. 4. Constituent procedures of the GACLexLeq algorithm.4.3. Algorithm GACLexLeqBased on Theorems 1 and 2, we have designed an efficient linear-time propagation algorithm, GACLexLeq, which(cid:7)Y . It(cid:7)Y or prunes only inconsistent values so as to establish GAC on (cid:7)X (cid:2)lexeither detects the disentailment of (cid:7)X (cid:2)lexis presented in Fig. 4.Throughout the paper, we assume that our propagation algorithms are used in a certain manner, which is commonin the practice of constraint programming. If we are searching for a solution to a set of constraints that contains aconstraint of the form (cid:7)X (cid:2)leq(cid:7)Y , then the constraint will be imposed with a call to EstablishGAC. In searchingdown any path of the search space ReEstablishGAC is called whenever the domain of a variable in (cid:7)X or (cid:7)Y isreduced in a certain manner. As many domain reductions do not destroy the GAC property, our algorithms specify theconditions under which ReEstablishGAC is triggered. Finally, we assume that the solver detects when the domainof a variable has been reduced to the empty set and interrupts the execution of the propagation algorithm and signalsdisentailment. Thus our algorithms do not test for empty domains. When other conditions lead our algorithms detectthat the constraint is disentailed, the algorithms signal this and return. We assume that the propagation algorithms arenever called with a constraint for which disentailment has been detected.814A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834Let us discuss GACLexLeq, beginning with EstablishGAC. Throughout the paper we refer to lines A1–A9 asthe “initialisation step” since these lines initialise the program variables alpha and beta to α and β, as defined inDefinitions 6 and 7. Following the initialisation step ReEstablishGAC is called (line A10) to establish generalisedarc consistency.Line A2 traverses (cid:7)X and (cid:7)Y , starting at index 0, until either it reaches the end of the vectors (all pairs of variablesare assigned and equal), or it finds an index where the pair of variables are not assigned and equal. In the first case,(cid:7)Y is entailed. In the second case, alpha is set to the smallest index wherethe algorithm returns (line A3) as (cid:7)X (cid:2)lexthe pair of variables are not assigned and equal. The vectors are traversed at line A6, starting at index alpha, untileither the end of the vectors is reached (none of the pairs of variables have min(Xi) > max(Yi)), or an index i wheremin(Xi) > max(Yi) is found. In the first case, beta is set to n + 1 (line A7). In the second case, beta is guaranteedto be at most i (line A8). If, however, there exists an h ∈ [0, i − 1] such that min( (cid:7)Xh..i−1) = max( (cid:7)Yh..i−1), then betacan be revised to the least such h (line A6.1).If alpha = beta then disentailment is detected and EstablishGAC terminates, signalling that this is the case(line A9). Otherwise, it is sufficient to call ReEstablishGAC with index alpha (line A10) to establish generalisedarc consistency, as we will show.We now consider ReEstablishGAC itself. Apart from the call made by EstablishGAC, this procedure istriggered whenever the lower bound of one of the variables in (cid:7)X, or the upper bound of one of the variables in (cid:7)Y , ismodified. The justification for this is that lexicographic ordering is a monotonic constraint. If a value of Xi has anysupport then it is supported by the maximum value of Yi ; likewise, if a value of Yi has any support then it is supportedby the minimum value of Xi . Hence new support needs to be sought only if one of these bounds is changed.ReEstablishGAC consists of three mutually-exclusive branches, which we describe in turn. Line A11 estab-lishes AC on Xi < Yi , in accordance with Theorem 2. Again, because of monotonicity, this is a simple step. First, acheck is made to ensure that the upper bound of Xi is supported by the upper bound of Yi . If not, the upper bound ofXi is revised accordingly. Similarly, the lower bound of Yi is compared against the lower bound of Xi and revised ifnecessary.Lines A12–12.2 cater for the case when alpha and beta are not adjacent. Again exploiting monotonicity, lineA12.1 establishes AC on Xi (cid:2) Yi , in accordance with Theorem 2. If, following this step, Xi and Yi are assigned andequal, alpha no longer reflects α and is updated via UpdateAlpha. In lines A14 and A18 of UpdateAlpha thevectors are traversed until α is reached. If α = n the procedure returns (line A15) because GAC has been established.If α = β, disentailment is signalled (line A16) in accordance with Theorem 1. Otherwise, ReEstablishGAC iscalled (line A17).Finally, lines A13–A13.2 deal with a call to ReEstablishGAC with an index between alpha and beta. Inthis case, it may be the case that beta does not reflect β and must be updated. The condition for updating beta isderived from Definition 7: at i either min(Xi) > max(Yi), or i is beta − 1 and min(Xi) = max(Yi). The programvariable beta is updated by calling UpdateBeta(i − 1). In lines A19 and A22, the vectors are traversed until β isreached. Again, if α = β, disentailment is signalled (line A20) in accordance with Theorem 1. Otherwise, line A21.1establishes AC on Xi (cid:2) Yi if α is adjacent to β.5. Theoretical propertiesWe begin by analysing the worst-case time complexity of GACLexLeq, before establishing its soundness andcompleteness.5.1. Time complexityThis section considers the time complexity of using GACLexLeq to establish or re-establish GAC as well as thetotal time complexity of establishing and then repeatedly re-establishing GAC in moving down a single branch in asearch space.The GACLexLeq algorithm updates the domains of variables by establishing arc-consistency on constraints ofthe form X (cid:2) Y and X < Y , both of which modify the domains only by tightening their bounds. Depending on howdomains are implemented, the time taken to perform this tightening operation could be constant, a function of thecardinality of the domain, or even a function of the structure of the domain. In order to abstract away from this issue,A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834815we shall measure the run time of our algorithms by a pair of functions (cid:3)f1, f2(cid:4), where f1 gives the total number ofoperations performed (counting domain bounds modification as a single operation) and f2 gives the total number ofdomain bounds modifications. We also assume that min(X) and max(X) can be computed in constant time. Thus, thecost of establishing AC on X (cid:2) Y or X < Y is (cid:3)O(1), 0(cid:4) if the constraint is AC, and (cid:3)O(1), 1(cid:4) if it is not.Our approach to the complexity analysis is first (in Lemma 2) to characterise the amount of computation performedas a function of Mαβ , the total number of times that alpha and beta are modified, and then obtain the complexityresult by establishing that Mαβ is bounded by the vector length plus one.Lemma 1. Every execution of UpdateAlpha increments alpha and every execution of UpdateBeta de-creases beta. During the execution of ReEstablishGAC the value of alpha never decreases and the valueof beta never increases.Proof. Each execution of UpdateAlpha increments alpha on Line A14 and modifies alpha nowhere else. Eachexecution of UpdateBeta assigns a value to beta on line A19 and is modified nowhere else. Let us confirm thatline A19 decreases beta. On the initial call to UpdateBeta (line 13.2) the value passed is no greater than beta − 2and on subsequent calls (line A22) i is decremented. Hence, immediately before line A19 is executed, i + 1 is strictlyless than beta. An execution of ReEstablishGAC never modifies alpha or beta other than through calls toUpdateAlpha and UpdateBeta; hence it never decreases alpha or increases beta. (cid:2)Lemma 2. Given a pair of equal-length variable-distinct vectors, the time complexity of ReEstablishGAC is(cid:3)O(Mαβ ), O(Mαβ )(cid:4), where Mαβ is the total number of times that the alpha or beta variables are modified duringthe execution.Proof. With any execution e of ReEstablishGAC we can associate a string, se, of the symbols “r”, “a” and “b” thatindicates the sequence of invocations of ReEstablishGAC, UpdateAlpha and UpdateBeta, respectively, thattake place during execution e. It is useful to observe, from the structure of the algorithm, that the set of all such stringsis r(a∗|a+r)b∗. Consider an arbitrary execution e of ReEstablishGAC. We start the proof by first showing thatfor execution e Mαβ = (cid:7)(|se|). From Lemma 1 we know that each execution of UpdateAlpha increments alphaand each execution of UpdateBeta decreases beta. Each execution of ReEstablishGAC, except the first, ispreceded by an execution of UpdateAlpha, whose execution incremented alpha. Therefore Mαβ = (cid:7)(|se|). Ob-serving that each of ReEstablishGAC, UpdateAlpha and UpdateBeta perform O(1) total operations, weconclude that the total number of operations performed during execution e is O(Mαβ ). Observing ReEstablish-GAC, UpdateAlpha and UpdateBeta perform at most one domain bounds modification, we conclude that thetotal number of such modifications performed during execution e is O(Mαβ ). (cid:2)Theorem 3. Given a pair of length n variable-distinct vectors the time complexity of both ReEstablishGAC andEstablishGAC is (cid:3)O(n), O(n)(cid:4).Proof. First consider ReEstablishGAC. Observe that when ReEstablishGAC is called on line A10, alphais at least 0 and beta is at most n + 1. From Lemma 1 it follows that this is true for any subsequent call toReEstablishGAC, be it from line A17 or from outside the algorithm. Observe that the value of alpha neverexceeds that of beta. From Lemma 1 and these observations, it follows that, for any execution of ReEstab-lishGAC, Mαβ (cid:2) n + 1. Therefore, it follows from Lemma 2 that the complexity of both ReEstablishGAC andEstablishGAC is (cid:3)O(n), O(n)(cid:4).Now consider EstablishGAC. Observe that the complexity of the initialisation step (lines A1 through A9)is (cid:3)O(n), 0(cid:4). Adding this to the execution time of ReEstablishGAC (line A10) gives a total complexity of(cid:3)O(n), O(n)(cid:4). (cid:2)As explained at the beginning of Section 4.3, if we are searching for a solution to a set of constraints that contains(cid:7)Y , then the constraint will be imposed with a call to EstablishGAC and down anya constraint of the form (cid:7)X (cid:2)lexbranch of a search space a call will be made to ReEstablishGAC every time a lower bound of some Xi is increased,or a upper bound of some Yi is decreased. Direct application of Theorem 3 would tell us that if such a sequence has816A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834k + 1 calls then its total execution time is (cid:3)O(kn), O(kn)(cid:4). However, because the algorithms are incremental, the actualexecution time is much less.Theorem 4. Given a pair of equal-length variable-distinct vectors, the time complexity of executing EstablishGACfollowed by a sequence of k executions of ReEstablishGAC is (cid:3)O(n + k), O(n + k)(cid:4).Proof. From Lemma 1 and the arguments put forward in the previous proof, we know that over the entire sequenceof operations Mαβ will not exceed n + 1. Hence, by Lemma 2, the number of operations performed related to movesof alpha and beta is O(n). But each of the k executions in the sequence will perform at least a constant numberof operations, even if alpha and beta are not moved; this takes O(k) total operations. Thus the total number ofoperations executed in the sequence is O(n + k). By a similar argument, the number of domain bounds modificationsperformed in the sequence of executions is also O(n + k). (cid:2)5.2. Soundness and completenessWe now turn our attention to the soundness and completeness of GACLexLeq. By soundness of a propagationalgorithm we mean that the algorithm only removes domain elements that participate in no satisfying assignment tothe constrained variables and signals disentailment only if the constraint is disentailed. By completeness we meanthat the algorithm signals disentailment if the constraint is disentailed, otherwise it removes all domain elements thatparticipate in no satisfying assignment. We begin with the initialisation part of EstablishGAC.Lemma 3. Let (cid:7)X and (cid:7)Y be a pair of length n variable-distinct vectors. The initialisation step of EstablishGAC on(cid:7)Y is disentailed if and only if this is(cid:7)X and (cid:7)Y sets alpha and beta to α and β respectively. It signals that (cid:7)X (cid:2)lexthe case.Proof. Line A2 of EstablishGAC traverses (cid:7)X and (cid:7)Y , starting at index 0, until either it reaches the end of the vectors(all pairs of variables are assigned and equal), or it finds an index where the pair of variables are not assigned and(cid:7)Y ) holds and the algorithm returns with alpha and beta set as per Definitions 6equal. In the first case, GAC( (cid:7)X (cid:2)lexand 7 (line A3). In the second case, alpha is set to the smallest index where the pair of variables are not assignedand equal, as per Definition 6. The vectors are traversed at line A6, starting at index alpha, until either the end of thevectors is reached (none of the pairs of variables have min(Xi) > max(Yi)), or an index i where min(Xi) > max(Yi)is found. In the first case, beta is set to n + 1 (line A7) as per Definition 7. In the second case, beta is guaranteedto be at most i (line A8). If, however, there exists an h ∈ [0, i − 1] such that min( (cid:7)Xh..i−1) = max( (cid:7)Yh..i−1), then beta(cid:7)Y is disentailed bycan be revised to the least such h (line A6.1), as per Definition 7. If alpha = beta then (cid:7)X (cid:2)lexTheorem 1 and thus EstablishGAC terminates signalling that this is the case (line A9). (cid:2)Having established that alpha and beta are correctly initialised via lines A1 to A9 of EstablishGAC, weshow that these two variables are correctly updated by UpdateAlpha and UpdateBeta respectively. Note thatthese two procedures may trigger pruning. We also show that such pruning is sound and complete.Lemma 4. Let (cid:7)X and (cid:7)Y be a pair of length n variable-distinct vectors, alpha < α and beta (cid:3) β. UpdateAlpha is(cid:7)Y is not disentailed, UpdateAlpha terminatessound. If α < β or beta = β, UpdateAlpha is complete. If (cid:7)X (cid:2)lexwith α = alpha.Proof. Induction on k = n − α.Base case: k = 0, hence α = n. By definition, (cid:7)Xalpha..α−1.= (cid:7)Yalpha..α−1. At line A14, alpha is incremented.If alpha is now equal to α, updateAlpha terminates at line A15, which is complete. Otherwise, since α = n,β = n + 1, so the condition of line A16 cannot be met. Similarly, the condition of line A17 cannot be met. There-fore, UpdateAlpha is called recursively at line A18. This process repeats until alpha = n, and UpdateAlphaterminates correctly.Inductive case: We assume that the theorem is true for 0 (cid:2) k < j . We prove that it is true for k = j , equivalently.= (cid:7)Yalpha..α−1 by definition. As above, alpha is updated until it is set correctlywhen α = n − j . Again, (cid:7)Xalpha..α−1A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834817to α at line A14. The condition of line A15 cannot be met, by assumption. If alpha = beta, which is possible onlyif beta = β, disentailment is signalled at line A16. This is sound and required for completeness. Since alpha = α,the condition of line A17 is met, and ReEstablishGAC(alpha) is called. Consider first the case where α = β − 1.From Theorem 2, establishing AC on Xalpha < Yalpha is sound and required for completeness. Since the conditionof line A16 was not met, and alpha = α, the condition of line A11 is met only if beta = β, which is the secondcompleteness condition. AC is established at line A11, and the algorithm terminates as required. Consider now thecase where α < β −1. From Theorem 2, establishing AC on Xalpha (cid:2) Yalpha is sound and required for completeness.Since alpha = α, and β (cid:2) beta, the condition of line A12 is met. AC is established at line A12.1 as required. If.= Yalpha, then UpdateAlpha is called with k < j (since α is now a greater index). This isthis results in Xalphasound and complete by the induction assumption. Since alpha = i the third branch cannot be entered. (cid:2)Lemma 5. Let (cid:7)X and (cid:7)Y be a pair of length n variable-distinct vectors, 0 (cid:2) alpha (cid:2) α, and for all h in [β,i + 1], min(Xh) (cid:3) max(Xh). In addition, assume that α < β and β − 1 (cid:2) i < n, or α = β and alpha −1 (cid:2) i < n.UpdateBeta(i) is sound and complete. Furthermore, if (cid:7)X (cid:2)lex(cid:7)Y is not disentailed, UpdateBeta(i) terminateswith β = beta.Proof. We divide the proof into three cases.Case 1: α = β. From Theorem 1, it is sound to signal disentailment and completeness requires that disentailmentis signalled. We assume that the initial call to UpdateBeta is with i > α. An initial call with i (cid:2) α is a simple sub-case, as will become clear. By assumption, at every index h in [β, i + 1], min(Xh) (cid:3) max(Yh). Hence, the conditionof line A21 cannot be met, and UpdateBeta is called recursively until β = beta. By assumption alpha (cid:2) α.If α = alpha, then the condition of line A20 is met, and disentailment is signalled as required. If alpha < α,.= (cid:7)Y alpha..α−1. At this point, thethe recursion continues until alpha − 1 since, by Definition 6, (cid:7)Xalpha..α−1condition of line A20 is met, and disentailment is signalled as required.Case 2: α = β − 1. From Theorem 2, it is sound to establish AC(Xα < Yα) and completeness requires that AC isestablished. As above, UpdateBeta traverses the vectors until the condition of either line A20 or line A21 is met.However, the condition of line A20 cannot be met: by assumption, alpha (cid:2) α < β and, by Definition 7, min(Xβ−1)< max(Yβ−1). By assumption, at every index h in [β, i + 1] min(Xh) (cid:3) max(Yh). Hence, the recursion will end wheni reaches α = β − 1. At this point the conditions of lines A21 and A21.1 are met and AC is established as required. Ifthis does not cause disentailment, the algorithm returns with beta = β.Case 3: α < β − 1. Similarly to above, beta is updated to β, at which point the condition of line A21 is met.Clearly, however, the condition of line A21.1 cannot be met and the algorithm terminates correctly. (cid:2)In the context of a constraint solver, where it is intended that GACLexLeq is used, there is no guarantee thatReEstablishGAC will be invoked immediately following every individual change to the vectors of variables thatit constrains. Hence, we must show that ReEstablishGAC is sound and complete following a number of suchchanges. We also show that both EstablishGAC and ReEstablishGAC ensure that alpha and beta are setcorrectly upon termination. This, in turn, ensures that successive applications of ReEstablishGAC following asequence of changes remains sound and complete.Theorem 5. Let (cid:7)X and (cid:7)Y be a pair of length n variable-distinct vectors such that GAC( (cid:7)X (cid:2)lex(cid:7)Y ), and letalpha = α (cid:11)= β = beta. Let domain reductions be made to some variables in (cid:7)X and (cid:7)Y , whose indices form theset I. Let P be the process of executing, in any order, ReEstablishGAC(i) for each i ∈ I that meets the triggerconditions. P is sound and complete. If (cid:7)X (cid:2)lex(cid:7)Y is not disentailed, P terminates with α = alpha and β = beta.Proof. Soundness: The algorithm prunes values directly at lines A11 and A12.1, and as a result of invoking Up-dateAlpha and UpdateBeta at lines A12.2 and A13.2. We consider each case in turn. The condition of lineA11 is met if 1) alpha = α and beta = β, in which case the propagation performed is sound from Theorem 2, or2) α = β and alpha = α or beta = α. Here, propagation will result in an empty domain and disentailment willbe signalled, which is sound from Theorem 1. If alpha < α, the propagation at line A12.1 will have no effect andUpdateAlpha is invoked. If alpha = α, the propagation at line A12.1 is sound from Theorem 2. If this results818A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834.= Yi , UpdateAlpha is invoked. In either case, the soundness conditions for UpdateAlpha are met by as-in Xisumption. If the conditions of lines A13 and A13.1 are met, then UpdateBeta(i − 1) is invoked. The soundnessconditions for UpdateBeta are met by assumption.Completeness: We divide completeness into three cases, according to the relative values of α and β.Case 1: α < β − 1. From Theorem 2, it suffices to show that AC(Xα (cid:2) Yα) is established. If α remains equal toalpha, then there are three possibilities: (a) Xα and Yα are unchanged and AC(Xα (cid:2) Yα) holds as it did before thesequence of domain reductions. (b) Domain reductions at α have not affected the lower bound of Xα or the upperbound of Yα. From monotonicity AC(Xα (cid:2) Yα) still holds. (c) The lower bound of Xα and/or the upper bound of Yαhas been revised, in which case α ∈ I and the propagation is performed at line A12.1 as required. If alpha < α thenthe domain of Xalpha and/or Yalpha has been reduced to a single value. Since AC(Xalpha (cid:2) Yalpha) held beforethe sequence of domain reductions, this means that the lower bound of Xalpha and/or the upper bound of Yalpha hasbeen reduced. Hence, UpdateAlpha is invoked at line A12.2, which is complete from Lemma 4.Case 2: α = β − 1. If α = n, no propagation is necessary. Otherwise it suffices to show that AC(Xα < Yα) isestablished from Theorem 2. If α remains equal to alpha, then there are two possibilities: (a) beta = β. If eitherXα and Yα are unchanged, or domain reductions at α have affected neither the lower bound of Xα nor the upperbound of Yα, from monotonicity, AC(Xα < Yα) holds as it did before the sequence of domain reductions. If thelower bound of Xα and/or the upper bound of Yα has been revised then α ∈ I and AC(Xα < Yα) is established atline A11 as required. (b) β < beta. For some index j ∈ [β, beta), the lower bound of Xj or the upper bound ofYj has been revised such that for all h in [β, j ], min(Xh) (cid:3) max(Xh). Hence, j ∈ I and, UpdateBeta(j − 1) iscalled at line A13.2. It is complete from Lemma 5. If alpha < α then, as above, alpha is updated to α. If, at thispoint, beta = β, then AC is established at line A11 as required. If beta > β, then UpdateBeta is called with itscompleteness conditions met, as above.Case 3: α = β. From Theorem 1, completeness requires that disentailment is signalled. By assumption, it is not thecase that both alpha = α and beta = β. By similar arguments to the above, either UpdateAlpha is invoked andis complete by Lemma 4, or UpdateBeta is invoked and is complete by Lemma 5.Accuracy of α and β on termination (assuming (cid:7)X (cid:2)lex(cid:7)Y is not disentailed): If alpha < α then, as argued above,the domain of Xalpha and/or Yalpha has been reduced to a single value. Hence, UpdateAlpha is invoked at lineA12.2, which terminates with α = alpha from Lemma 4. If β < beta then, as also argued above, for some index j ,where β (cid:2) j < beta, the lower bound of Xj or the upper bound of Yj has been revised such that for all h in [β, j ]min(Xh) (cid:3) max(Xh). Hence, j ∈ I and, UpdateBeta(j − 1) is called at line A13.2. From Lemma 5 it terminateswith beta = β. (cid:2)Theorem 6. Let (cid:7)X and (cid:7)Y be a pair of length n variable-distinct vectors. EstablishGAC on (cid:7)X and (cid:7)Y is sound andcomplete. If (cid:7)X (cid:2)lex(cid:7)Y is not disentailed, EstablishGAC terminates with α = alpha and β = beta.Proof. From Lemma 3, after line A9 of EstablishGAC has been executed, alpha and beta are set to α and β.If disentailment has not already been detected, line A10 invokes ReEstablishGAC(alpha). From Theorem 2, ifGAC( (cid:7)X (cid:2)lex(cid:7)Y ) then ReEstablishGAC(alpha) has no effect, which is complete. Otherwise, either AC(Xalpha (cid:2)Xbeta) or AC(Xalpha < Xbeta) does not hold. If alpha is adjacent to beta, AC(Xalpha < Xbeta) is establishedat line A11, which is sound and complete. If alpha and beta are not adjacent, AC(Xalpha (cid:2) Xbeta) is established.= Yalpha, UpdateAlpha is called at line A12.2. From Lemma 4, UpdateAlpha isat line A12.1. If now Xalphasound, complete, and if (cid:7)X (cid:2)lex(cid:7)Y is not disentailed, it terminates with α = alpha and β = beta. (cid:2)6. Extensions6.1. Strict lexicographic ordering constraintWith very little effort, GACLexLeq can be adapted to obtain a propagation algorithm, GACLexLess, whicheither detects the disentailment of (cid:7)X <lex(cid:7)Y .The reason the two algorithms are so similar is that as soon as β takes a value other than n + 1, GACLexLeq enforcesstrict lexicographic ordering on the vectors.(cid:7)Y or prunes only inconsistent values so as to establish GAC on (cid:7)X <lexA.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834819Before showing how we modify GACLexLeq, we give the necessary theoretical background. We define the index(cid:7)Yβ..n−1α between two vectors (cid:7)X and (cid:7)Y as in Definition 6. However, β is now the least index such that (cid:7)Xβ..n−1 <lexis disentailed, or n if no such index exists.Definition 8. Given two length n variable-distinct vectors, (cid:7)X and (cid:7)Y , β is the least index in [α, n) such that(cid:5)∃k ∈ [β, n) .(cid:5)min(Xk) > max(Yk) ∧ min( (cid:7)Xβ..k−1) = max( (cid:7)Yβ..k−1)∨ min( (cid:7)Xβ..n−1) = max( (cid:7)Yβ..n−1)(cid:6)(cid:6)or, if no such index exists, n.We again make use of α and β to detect disentailment as well as prune inconsistent values.Theorem 7. Let (cid:7)X and (cid:7)Y be a pair of length n variable-distinct vectors. β = α if and only if (cid:7)X <lex(cid:7)Y is disentailed.Proof. (⇒) Identical to the proof of Theorem 1.(⇐) If (cid:7)X <lex(cid:7)Y is disentailed then (cid:7)X (cid:3)lexsubstituting Definition 8 for Definition 7. Otherwise just (cid:7)X (cid:3)lex∀i ∈ [0, n) min(Xi) (cid:3) max(Yi). Hence, from Definition 6, α is the least index such that ¬(XαDefinition 8, β = α. (cid:2)(cid:7)Y is entailed, the proof follows as for Theorem 1,(cid:7)Y is entailed. Since the vectors are variable-distinct,.= Yα). Thus, from(cid:7)Y is entailed. If (cid:7)X >lexThe conditions for GAC to hold are also similar:Theorem 8. Given a pair of length n variable-distinct vectors, (cid:7)X and (cid:7)Y , if β > α then GAC( (cid:7)X <lexeither of the following conditions holds:(cid:7)Y ) if and only if1. β = α + 1 and AC(Xα < Yα), or2. β > α + 1 and AC(Xα (cid:2) Yα).Proof. (⇒) Similar to the proof of Theorem 2.(⇐) Since (cid:7)X0..α−1.= (cid:7)Y0..α−1, the assignment Xα (cid:2) Yα supports all values in the domains of (cid:7)Xα+1..n−1 and(cid:7)Yα+1..n−1. Hence, given β = α + 1 and AC(Xα < Yα), the constraint is GAC. Similarly, if β > α + 1 andAC(Xα (cid:2) Yα) then Xα (cid:2) Yα supports all values in the domains of (cid:7)Xα+1..n−1 and (cid:7)Yα+1..n−1. It remains to consider.= Yβ−1) and min(Xi) (cid:2) max(Yi) for allXα.= Yα supports and is supported by the combination of Xβ−1 (cid:2) Yβ−1i ∈ [α, β). Since (cid:7)X and (cid:7)Y are variable-distinct, Xαand (cid:7)Xα−1..β−2.= Yα. Irrespective of whether β = n, from the definition of β, ¬(Xβ−1.= (cid:7)Yα−1..β−2. Hence, the constraint is GAC. (cid:2)We now consider the simple modifications to GACLexLeq necessary to obtain the propagation algorithmGACLexLess, which is presented in Fig. 5. First, the initialisation step of EstablishGAC (i.e. lines B1–B8)must reflect the new definition of β. From Definition 8 and Theorem 7, the constraint is disentailed if α = n. LineB3 deals with this case. A further change to the initialisation step is at line B7. Line A7 of GACLexLeq has beenremoved so that beta is assigned to n correctly if there is no index from which the tail of the vectors is guaranteed tobe ordered lexicographically equal or decreasing. The second modification is to UpdateAlpha, as indicated in thefigure. Again, if alpha reaches n the constraint is disentailed. No other modifications are necessary.6.2. EntailmentEven though GACLexLeq is a sound and complete propagation algorithm, it does not detect entailment. Thissection extends the GACLexLeq algorithm to a new algorithm, GACLexLeqEntailed, that can detect entailment.Mimicking the treatment of disentailment, when entailment is detected the algorithm signals this and returns. Once aconstraint is entailed it remains GAC even if the domains of the constrained variables are later reduced; hence there isno need ever to re-establish GAC.It is not hard to show when (cid:7)X (cid:2)lex(cid:7)Y is entailed.820A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834Algorithm GACLexLess.= Yalpha) do alpha := alpha + 1alpha := 0while (alpha < n ∧ Xalphaif (alpha = n) then disentailedi := alphabeta := −1while (i (cid:11)= n ∧ min(Xi ) (cid:2) max(Yi )) doEstablishGACB1B2(cid:4)(cid:4) B3B4B5B6B6.1B6.2B6.3if (min(Xi ) = max(Yi )) then if (beta = −1) then beta := ielse beta := −1i := i + 1if (beta = −1) then beta := iif (alpha = beta) then disentailedReEstablishGAC(alpha)(cid:4)(cid:4) B7B8B9ReEstablishGAC(i in [0, n)) Triggered when min(Xi ) or max(Yi ) changesIdentical to GACLexLeqUpdateAlphaB14(cid:4)(cid:4) B15B16B17B18alpha := alpha + 1if (alpha = n) then disentailedif (alpha = beta) then disentailedif (¬(Xalphaelse UpdateAlpha.= Yalpha)) then ReEstablishGAC(alpha)UpdateBeta(i in [0, n))Identical to GACLexLeqFig. 5. Constituent procedures of the GACLexLess algorithm. Modifications from GACLexLeq are indicated by ‘(cid:4)(cid:4)’.Theorem 9. Given a pair of length n variable-distinct vectors, (cid:7)X and (cid:7)Y , (cid:7)X (cid:2)lexmax( (cid:7)X) (cid:2)lex min( (cid:7)Y ).(cid:7)Y is entailed if and only ifProof. (⇒) Since (cid:7)X (cid:2)lexmax( (cid:7)Y ).(cid:7)Y is entailed, any combination of assignments satisfies (cid:7)X (cid:2)lex(cid:7)Y . Hence, min( (cid:7)X) (cid:2)lex(⇐) Any (cid:7)x ∈ (cid:7)X is lexicographically less than or equal to any (cid:7)y ∈ (cid:7)Y . Hence, (cid:7)X (cid:2)lex(cid:7)Y is entailed. (cid:2)To exploit this fact, we introduce γ , which is the least index in [α, n) such that (cid:7)Xγ ..n−1 (cid:2)lex(cid:7)Yγ ..n−1 is entailed, orn if no such index exists.Definition 9. Given a pair of length n variable-distinct vectors, (cid:7)X and (cid:7)Y , γ is the least index in [α, n) such that∨ max( (cid:7)Xγ ..n−1) = min( (cid:7)Yγ ..n−1)(cid:6)(cid:5)max(Xk) < min(Yk) ∧ max( (cid:7)Xγ ..k−1) = min( (cid:7)Yγ ..k−1)∃k ∈ [γ , n) .or, if no such index exists, n.Theorem 10. Given a pair of length n variable-distinct vectors, (cid:7)X and (cid:7)Y , (cid:7)X (cid:2)lex(cid:7)Y is entailed if and only if γ = α.Proof. (⇒) If (cid:7)X (cid:2)lex(cid:7)Y is entailed, then, from the definition of lexicographic ordering and the fact that the vectorsare variable distinct, either a) there exists an index i such that max(Xi) < min(Yi) and max( (cid:7)X0..i−1) = min( (cid:7)Y0..i−1)or b) max( (cid:7)X0..n−1) = min( (cid:7)Y0..n−1). First, consider a). Let k be the least index such that the variables are not assignedand equal. By Definition 6, α = k. Clearly, k lies in [0, i]. From the first part of Definition 9, γ = k. Now consider b).If the vectors are assigned and equal, then α = n = γ by Definitions 6 and 9. Otherwise, let k be defined as above.From the second part of Definition 9, γ = k.(⇐) By Definition 6, (cid:7)X0..α−1 = (cid:7)Y0..α−1 is entailed, and by Definition 9 (cid:7)Xα..n−1 (cid:2)lex(cid:7)Yα..n−1 is entailed. Hence,(cid:7)X (cid:2)lex(cid:7)Y is entailed. (cid:2)A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834821We now consider the modifications necessary to GACLexLeq to obtain GACLexLeqEntailed, which is pre-sented in Fig. 6. Clearly, if alpha reaches n, then the constraint is entailed. This case is dealt with by lines C3 andC21. Otherwise, entailment is detected by considering γ . We introduce the program variable gamma to keep track ofγ (line C10) and initialise it (lines C11–C12) in much the same way as beta.Two further procedures are required to maintain gamma correctly. First, γ may change following an update tomax(Xi) or min(Yi), which are the opposite conditions to those that trigger ReEstablishGAC. Hence, Check-Entailment is triggered by these events (line C19), which calls the UpdateGamma procedure if necessary.UpdateGamma works similarly to the other two Update procedures, signalling entailment if alpha and gammameet (line C28).Algorithm GACLexLeqEntailed.= Yalpha) do alpha := alpha + 1if (min(Xi ) = max(Yi )) then if (beta = −1) then beta := ielse beta := −1i := i + 1alpha := 0while (alpha < n ∧ Xalphaif (alpha = n) then entailedi := alphabeta := −1while (i (cid:11)= n ∧ min(Xi ) (cid:2) max(Yi )) doEstablishGACC1C2(cid:4)(cid:4) C3C4C5C6C6.1C6.2C6.3C7C8C9(cid:4)(cid:4) C10(cid:4)(cid:4) C11(cid:4)(cid:4) C11.1(cid:4)(cid:4) C11.2(cid:4)(cid:4) C11.3(cid:4)(cid:4) C11.4(cid:4)(cid:4) C12(cid:4)(cid:4) C13C14ReEstablishGAC(i in [0, n)) Triggered when min(Xi ) or max(Yi ) changesIdentical to GACLexLeqCheckEntailment(i in [0, n)) Triggered when max(Xi ) or min(Yi ) changesif (i = n) then beta := n + 1else if (beta = −1) then beta := iif (alpha = beta) then disentailedgamma := −1,while (i (cid:11)= n ∧ max(Xi ) (cid:3) min(Yi )) doif (max(Xi ) = min(Yi )) thenif (gamma = −1) then gamma := iif (alpha = gamma) then entailedReEstablishGAC(alpha)else gamma := −1i := i + 1if (gamma = −1) then gamma := ii := alpha(cid:4)(cid:4)(cid:4)(cid:4) C19if ((i = gamma − 1 ∧ max(Xi ) = min(Yi )) ∨ max(Xi ) < min(Yi )) then UpdateGamma(i − 1)UpdateAlphaC20(cid:4)(cid:4) C21C22C23C24alpha := alpha + 1if (alpha = n) then entailedif (alpha = beta) then disentailedif (¬(Xalphaelse UpdateAlpha.= Yalpha)) then ReEstablishGAC(alpha)UpdateBeta(i in [0, n))Identical to GACLexLeq(cid:4)(cid:4)(cid:4)(cid:4) C28(cid:4)(cid:4) C29(cid:4)(cid:4) C30UpdateGamma(i in [0, n))if (i + 1 = alpha) then entailedif (max(Xi ) > min(Yi )) then gamma := i + 1else if (max(Xi ) = min(Yi )) then UpdateGamma(i − 1)Fig. 6. Constituent procedures of the GACLexLeqEntailed algorithm. Modifications from GACLexLeq are indicated by ‘(cid:4)(cid:4)’.822A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834Section 5.1 analyzed the complexity of GACLexLeq by considering the modifications of alpha and beta. Asthe same arguments can be made about the modifications of gamma, the results given in Theorems 3 and 4 apply toGACLexLeqEntailed as well.6.3. Vectors of different lengthThis section considers vectors of different length. Since two vectors of different length can never be equal, we onlyconsider imposing a strict lexicographic ordering constraint.Considering vectors of equal length, Definition 2 defined strict lexicographic ordering between two vectors ofintegers and Theorem 8 stated the necessary conditions for GAC on a strict lexicographic ordering constraint on a pairof vectors of variables. It is, however, straightforward to generalise the definition and the theorem for two vectors ofany, not necessarily equal, length.Definition 10. Strict lexicographic ordering (cid:7)x <lex (cid:7)y between two vectors of integers (cid:7)x = (cid:3)x0, x1, . . . , xm−1(cid:4) and(cid:7)y = (cid:3)y0, y1, . . . , yn−1(cid:4) holds if and only if either of the following conditions hold:1. m < n ∧ (cid:7)x (cid:2)lex (cid:7)y0..m−1, or2. m (cid:3) n ∧ (cid:7)x0..n−1 <lex (cid:7)y.In other words, we truncate to the length of the shortest vector and then compare. Either (cid:7)x is shorter than (cid:7)y and thefirst m elements of the vectors are lexicographically ordered, or (cid:7)x is at least as long as (cid:7)y and the first n elementsare strict lexicographically ordered. An example is (cid:3)0, 1, 2, 1, 5(cid:4) <lex (cid:3)0, 1, 2, 3, 4(cid:4) <lex (cid:3)0, 1, 2, 3, 4, 5, 5, 5(cid:4) <lex(cid:3)0, 1, 2, 4, 3(cid:4).Based on this general definition, GAC on (cid:7)X <lex(cid:7)Y is either GAC on a lexicographic ordering constraint or GACon a strict lexicographic ordering constraint.Proposition 1. Given a pair of variable-distinct vectors, (cid:7)X of length m and (cid:7)Y of length n, (cid:7)X <lexonly if either of the following conditions hold:(cid:7)Y is GAC if and1. m < n and GAC( (cid:7)X (cid:2)lex2. m (cid:3) n and GAC( (cid:7)X0..n−1 <lex(cid:7)Y0..m−1), or(cid:7)Y ).We can now easily generalise the propagation algorithm GACLexLess based on this theorem. If m < n then we(cid:7)Y0..m−1. If m (cid:3) n then we justjust consider the first m variables of (cid:7)Y and use GACLexLeq to enforce GAC on (cid:7)X (cid:2)lexconsider the first n variables of (cid:7)X and use GACLexLess to enforce GAC on (cid:7)X0..n−1 <lex(cid:7)Y ).7. Alternative approachesVarious alternative methods exist for enforcing the lexicographic ordering constraint, ranging from enforcing acollection of simpler constraints to alternative propagation algorithms. This section summarises and discusses thesealternative approaches.7.1. Arithmetic constraintsTo ensure that (cid:7)X (cid:2)lex(cid:7)Y , we can post the following arithmetic inequality constraint between the vectors (cid:7)X and (cid:7)Ywhose variables range over any subset of {0, . . . , d − 1}:d n−1 ∗ X0 + d n−2 ∗ X1 + · · · + d 0 ∗ Xn−1 (cid:2) d n−1 ∗ Y0 + d n−2 ∗ Y1 + · · · + d 0 ∗ Yn−1This is equivalent to converting two vectors into numbers and posting an ordering on the numbers. In order to enforce(cid:7)Y , we post the strict inequality constraint:strict lexicographic ordering (cid:7)X <lexd n−1 ∗ X0 + d n−2 ∗ X1 + · · · + d 0 ∗ Xn−1 < d n−1 ∗ Y0 + d n−2 ∗ Y1 + · · · + d 0 ∗ Yn−1A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834823These two arithmetic constraints are logically equivalent to the corresponding lexicographic ordering constraint.Since these constraints are monotonic—any unsupported domain values are the greatest ones in (cid:7)X or the least onesin (cid:7)Y —many constraint toolkits establish GAC on these constraints. Unfortunately, when n and d become large, d n−1will be much more than the word size of the computer and establishing GAC will be expensive. Hence, this method isonly feasible when the vectors and domain sizes are small.Inspired by [10], Warwick Harvey has suggested an alternative arithmetic constraint [14]. To ensure (cid:7)X (cid:2)lex(cid:7)Y , heposts the following logically equivalent constraint:(cid:5)X0 < Y0 +(cid:5)X1 < Y1 +(cid:5). . . + (Xn−1 < Yn−1 + 1) . . .(cid:6)(cid:6)(cid:6)1 =A constraint of the form (Xi < Yi + B) is reified into a 0/1 variable and it is interpreted as Xi < (Yi + B). Strictordering is achieved by posting:(cid:5)X0 < Y0 +1 =(cid:5). . . + (Xn−1 < Yn−1 + 0) . . .(cid:5)X1 < Y1 +.= Yn−1 in case the vectors are assigned and equal until the last index. Many toolkits that support(cid:6)(cid:6)(cid:6)which disallows Xn−1reification maintain GAC on these constraints.Henceforth, we shall refer to Harvey’s reification approach by his name and to the purely arithmetic constraintabove simply as the “arithmetic constraint”.7.2. Logical decompositionsThe first decomposition, which we call the ∧ decomposition, is a conjunction of n − 1 constraints:X0 (cid:2) Y0 ∧X0 = Y0 → X1 (cid:2) Y1 ∧X0 = Y0 ∧ X1 = Y1 → X2 (cid:2) Y2 ∧...X0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xn−2 = Yn−2 → Xn−1 (cid:2) Yn−1That is, we enforce that the most significant bits of the vectors are ordered, and if the most significant bits are equal thenthe rest of the vectors are lexicographically ordered. In order to decompose the strict lexicographic ordering constraint(cid:7)X <lex(cid:7)Y , we only need to change the last conjunction to X0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xn−2 = Yn−2 → Xn−1 < Yn−1.The second decomposition, which we call ∨ decomposition, is a disjunction of n − 1 constraints:X0 < Y0 ∨X0 = Y0 ∧ X1 < Y1 ∨X0 = Y0 ∧ X1 = Y1 ∧ X2 < Y2 ∨...X0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xn−2 = Yn−2 ∧ Xn−1 (cid:2) Yn−1That is, we enforce that either the most significant bits of the vectors are strictly ordered or the most significant bits areequal and the rest of the vectors are lexicographically ordered. For strict lexicographic ordering, it suffices to changethe last disjunction to X0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xn−2 = Yn−2 ∧ Xn−1 < Yn−1.Constraints with logical connectives are imposed in the following manner.• C1 ∧ C2: Both C1 and C2 are imposed.• C1 ∨ C2: If one of C1 or C2 becomes disentailed, the other constraint is imposed. If C1 or C2 becomes entailedthen C1 ∨ C2 becomes entailed.• C1 → C2: If C1 becomes entailed then C2 is imposed. If C2 becomes disentailed then ¬C1 is imposed. If C1becomes disentailed or C2 becomes entailed, then C1 → C2 becomes entailed.824A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834• ¬C1: If C1 becomes entailed then ¬C1 becomes disentailed. If C1 becomes disentailed then ¬C1 becomesentailed.We consider a propagation algorithm for these decompositions that treat the logical connectives in this manner andestablish AC on a binary constraint whenever it is imposed. We now show that these algorithms are guaranteed toestablish GAC and that each of the algorithms can prune values that the other cannot.Theorem 11. For both (cid:7)X (cid:2)lex(cid:7)Y the ∧ decomposition and the ∨ decomposition are sound but notcomplete. Moreover, on each of these constraints, the two decomposition algorithms are incomparable in that one canprune values that the other cannot, and vice-versa.(cid:7)Y and (cid:7)X <lex(cid:7)Y ) but the proof also works for ( (cid:7)X <lexProof. We only consider ( (cid:7)X (cid:2)lex(cid:7)Y is GAC. Thusevery value has a support. The vectors (cid:7)x and (cid:7)y supporting a value are lexicographically ordered ((cid:7)x (cid:2)lex (cid:7)y). By De-finition 3, either (cid:7)x = (cid:7)y or there is an index k in [0, n) such that xk < yk and (cid:7)x0..k−1 = (cid:7)y0..k−1. In either case, allthe constraints posted in either of the decompositions are satisfied. That is, every binary constraint imposed in thedecompositions is AC. Hence, the ∧ decomposition and the ∨ decomposition are sound for ( (cid:7)X (cid:2)lex(cid:7)Y ). Suppose that (cid:7)X (cid:2)lexConsider (cid:7)X = (cid:3){0, 1}, {1}(cid:4) and (cid:7)Y = (cid:3){0, 1}, {0}(cid:4) where (cid:7)X (cid:2)lex(cid:7)Y is not GAC. The ∧ decomposition imposes both ofX0 (cid:2) Y0 and X0 = Y0 → X1 (cid:2) Y1. We have AC(X0 (cid:2) Y0). Since X1 (cid:2) Y1 is disentailed, X0 (cid:11)= Y0 is imposed. We haveAC(X0 (cid:11)= Y0) so no pruning is possible. The ∨ decomposition, however, imposes X0 < Y0 because X0 = Y0 ∧ X1 (cid:2) Y1is disentailed. This removes 1 from D(X0) and 0 from D(Y0).Now consider (cid:7)X = (cid:3){0, 1, 2}, {0, 1}(cid:4) and (cid:7)Y = (cid:3){0, 1}, {0, 1}(cid:4) where (cid:7)X (cid:2)lex(cid:7)Y is not GAC. The ∧ decompositionremoves 2 from D(X0) by AC(X0 (cid:2) Y0). The ∨ decomposition, however, leaves the vectors unchanged since neitherX0 < Y0 nor X0 = Y0 ∧ X1 (cid:2) Y1 is disentailed.(cid:7)Y ).Since each decomposition prunes a value not pruned by the other, neither is complete. (cid:2)Together, the two decompositions behave similarly to the propagation algorithm of the lexicographic orderingconstraint: they either prove that (cid:7)X (cid:2)lex(cid:7)Y ). However, this requires posting(cid:7)Y is disentailed or establish GAC( (cid:7)X (cid:2)lexand propagating many constraints, and is likely to be inefficient. Our experimental results in Section 9.1 confirm thisexpectation.Theorem 12. Given a pair of length n variable-distinct vectors, (cid:7)X and (cid:7)Y , the ∧ and ∨ decomposition of (cid:7)X (cid:2)lextogether either prove that (cid:7)X (cid:2)lex(cid:7)Y is disentailed, or establish GAC( (cid:7)X (cid:2)lex(cid:7)Y ).(cid:7)YProof. Consider the ∧ decomposition. If α = β then either min(Xα) > max(Yα), or there exists an index k in (α, n)such that min(Xk) > max(Yk) and min( (cid:7)Xα..k−1) = max( (cid:7)Yα..k−1). In the first case, the constraint X0 = Y0 ∧ X1 = Y1 ∧· · · ∧ Xα−1 = Yα−1 → Xα (cid:2) Yα is disentailed. In the second case, the constraint X0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xk−1 =.= (cid:7)Yα..k−1 due to the constraint X0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xi−1 =Yk−1 → Xk (cid:2) Yk is disentailed because (cid:7)Xα..k−1Yi−1 → Xi (cid:2) Yi . In any case, (cid:7)X (cid:2)lex(cid:7)Y is disentailed. This is correct by Theorem 1. If, however, α < β then theconstraint X0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xα−1 = Yα−1 → Xα (cid:2) Yα makes sure that AC(Xα (cid:2) Yα). Now consider the ∨decomposition. If β = α then all the disjuncts of the decomposition are disentailed, so (cid:7)X (cid:2)lex(cid:7)Y is disentailed. This iscorrect by Theorem 1. If β = α + 1 then each disjunct except X0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xα−1 = Yα−1 ∧ Xα < Yα isdisentailed. This makes sure that AC(Xα < Yα). Given β > α, we have either• β = α + 1 and AC(Xα < Yα), or• β > α + 1 and AC(Xα (cid:2) Yα).By Theorem 2, we have GAC( (cid:7)X (cid:2)lex(cid:7)Y ). (cid:2)Theorem 13. Given a pair of length n variable-distinct vectors, (cid:7)X and (cid:7)Y , the ∧ and ∨ decomposition of (cid:7)X <lextogether either prove that (cid:7)X <lex(cid:7)Y is disentailed, or establish GAC( (cid:7)X <lex(cid:7)Y ).(cid:7)YA.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834825Proof. We only need to consider two cases, β = n and β < n ∧ min( (cid:7)Xβ..n−1) = max( (cid:7)Yβ..n−1); the remaining cases arecovered by the proof of Theorem 12. Assume β = n. Consider the ∧ decomposition. We either have α + 1 = β = n orα + 1 < β = n. In the first case, the constraint X0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xn−2 = Yn−2 → Xn−1 < Yn−1, which is thelast constraint of the conjunction, makes sure that AC(Xα < Yα). In the second case, the constraint X0 = Y0 ∧ X1 =Y1 ∧ · · · ∧ Xα−1 = Yα−1 → Xα (cid:2) Yα makes sure that AC(Xα (cid:2) Yα).Now assume β < n ∧ min( (cid:7)Xβ..n−1) = max( (cid:7)Yβ..n−1). Consider the ∧ decomposition. If α = β the constraint X0 =.= (cid:7)Yi dueY0 ∧ X1 = Y1 ∧ · · · ∧ Xn−2 = Yn−2 → Xn−1 < Yn−1 is disentailed because for all i ∈ [α, n − 1) we get (cid:7)Xito the constraint X0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xi−1 = Yi−1 → Xi (cid:2) Yi . Hence, (cid:7)X (cid:2)lex(cid:7)Y is disentailed. This is correctby Theorem 1. If, however, α < β then the constraint X0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xα−1 = Yα−1 → Xα (cid:2) Yα makessure that AC(Xα (cid:2) Yα). Now consider the ∨ decomposition. If β = α then all the disjuncts of the decomposition(cid:7)Y is disentailed. This is correct by Theorem 1. If β = α + 1 then each of the disjuncts butare disentailed, so (cid:7)X (cid:2)lexX0 = Y0 ∧ X1 = Y1 ∧ · · · ∧ Xα−1 = Yα−1 ∧ Xα < Yα is disentailed. This makes sure that AC(Xα < Yα).Given β > α, whether β = n or β < n, we have either1. β = α + 1 and AC(Xα < Yα), or2. β > α + 1 and AC(Xα (cid:2) Yα).By Theorem 8, we have GAC( (cid:7)X <lex(cid:7)Y ). (cid:2)7.3. Alternative propagation algorithmsThe ECLiPSe constraint solver [29] provides a global constraint, called lexico_le, for lexicographic orderingof two vectors. The manual [6] does not reveal what propagation is performed by this constraint. Our tests show that it(cid:7)Y leavesis not complete: if (cid:7)X = (cid:3){0, 1}, {0, 1}, {1}(cid:4) and (cid:7)Y = (cid:3){0, 1}, {0}, {0}(cid:4) then executing lexico_le on (cid:7)X (cid:2)lex(cid:7)Y is not GAC. Our tests also show that lexico_le can prune valuesthe vectors unchanged, even though (cid:7)X (cid:2)lexthat are not pruned by each of the decompositions discussed in Section 7.2. For instance, if (cid:7)X = (cid:3){0, 1}, {1}(cid:4) and (cid:7)Y =(cid:7)Y gives (cid:7)X = (cid:3){0}, {1}(cid:4) and (cid:7)Y = (cid:3){1}, {0}(cid:4) but the ∧ decomposition(cid:3){0, 1}, {0}(cid:4) then executing lexico_le on (cid:7)X (cid:2)lexleaves the vectors unchanged. Likewise, if (cid:7)X = (cid:3){0, 1, 2}, {0, 1}(cid:4) and (cid:7)Y = (cid:3){0, 1}, {0, 1}(cid:4) then executing lexico_le(cid:7)Y gives (cid:7)X = (cid:3){0, 1}, {0, 1}(cid:4) and (cid:7)Y = (cid:3){0, 1}, {0.1}(cid:4) but the ∨ decomposition leaves the vectors unchanged.on (cid:7)X (cid:2)lexWe have found no examples where either of the decompositions prunes values not pruned by lexico_le.Subsequent to the first publication of our GACLexLeq algorithm [10], Carlsson and Beldiceanu developed acomplete propagation algorithm for the lexicographic ordering constraint using a finite automaton [2]. The algorithmmaintains generalised arc consistency or detects (dis)entailment, and runs in linear time for posting plus amortisedconstant time per propagation event. Their algorithm records the position of α, but has no counterpart of our betavariable.7.4. Encoding GACLexLeqAn alternative way of propagating a global constraint is to post a set of constraints that “simulate” the special-purpose propagation algorithm. The success of such an approach was demonstrated in [11] by showing that arcconsistency on the CSP representation of the stable marriage problem gives reduced domains that are equivalentto the GS-lists produced by the Extended Gale–Shapley algorithm. Inspired by [10], Gent et al. have developed anencoding of the lexicographic ordering constraint [12].The encoding introduces a new vector (cid:7)α of 0/1 variables indexed from −1 to n − 1. The intended meaning of (cid:7)α isthat: if αi = 1 then (cid:7)X0..i = (cid:7)Y0..i , if αi+1 = 0 but αi = 1 then Xi+1 < Yi+1. They post the following constraints:α−1 = 1αi = 0 → αi+1 = 0αi = 1 → Xi = Yiαi = 1 ∧ αi+1 = 0 → Xi+1 < Yi+1αi = 1 → Xi+1 (cid:2) Yi+1(i ∈ [0, n − 2])(i ∈ [0, n − 1])(i ∈ [−1, n − 2])(i ∈ [−1, n − 2])826A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834For strict lexicographic ordering, it suffices to add αn−1 = 0.The advantage of using this encoding is that it obviates the need implement a special-purpose propagation algo-rithm, instead relying on existing and more general propagation algorithms. On the other hand, as our experimentalresults in Section 9 show, the introduction of extra variables and constraints may be less efficient.8. Multiple vectorsChains of lexicographic ordering constraints often arise in practice, such as when posting lexicographic orderingconstraints on the rows or columns of a matrix of decision variables. We can treat such a chain as a single globalordering constraint over the whole matrix. Alternatively, we can decompose it into lexicographic ordering constraintsbetween adjacent rows/columns or between all pairs of rows/columns. This section demonstrates that such decompo-sitions hinder constraint propagation.As this section considers sequences of vectors, it is useful to subscript the individual vectors, such as in the vectorsequence (cid:7)X0, . . . , (cid:7)Xn−1. Notice that the vector accent in (cid:7)Xi indicates that we are referring to vector i in a sequence ofvectors, as opposed to Xi , which refers to element i in vector X.Theorem 14. Let (cid:7)X0, . . . , (cid:7)Xn−1 be variable-distinct vectors. Then GAC( (cid:7)Xi (cid:2)leximply GAC( (cid:7)Xi (cid:2)lex(cid:7)Xj ) for all i, j ∈ [0, n) such that i < j .(cid:7)Xi+1) for all i ∈ [0, n − 1) does not(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)Proof. Consider the following three vectors:(cid:4)(cid:4)(cid:4)(cid:7)X0 ={0, 1}{1},{0, 1},(cid:7)X1 ={0, 1}, {0, 1}, {0, 1}(cid:7)X2 ={0},{0, 1},{0, 1}Observe that (cid:7)X0 (cid:2)lex(cid:7)X1 and (cid:7)X1 (cid:2)lexin which the initial element of (cid:7)X0 is assigned 1. (cid:2)(cid:7)X2 are each GAC. But (cid:7)X0 (cid:2)lex(cid:7)X2 is not GAC as the constraint has no solutionTheorem 15. Let (cid:7)X0, . . . , (cid:7)Xn−1 be variable-distinct vectors. Then GAC( (cid:7)Xi <leximply GAC( (cid:7)Xi <lex(cid:7)Xj ) for all i, j ∈ [0, n) such that i < j .(cid:7)Xi+1) for all i ∈ [0, n − 1) does notProof. This is shown by the example in the proof of Theorem 14. (cid:2)Theorem 16. Let (cid:7)X0, . . . , (cid:7)Xn−1 be variable-distinct vectors. Then GAC( (cid:7)Xi (cid:2)lexi < j does not imply GAC( (cid:7)X0 (cid:2)lex(cid:7)X1 (cid:2)lex · · · (cid:2)lex(cid:7)Xn−1).(cid:7)Xj ) for all i, j ∈ [0, n) such thatProof. Consider the following three vectors:(cid:4)(cid:7)X0 =(cid:7)X1 =(cid:7)X2 =Observe that (cid:7)X0 (cid:2)lexconstraint has no solution in which the initial element of (cid:7)X0 is assigned 1. (cid:2){0, 1}, {0, 1}, {1}, {0, 1}(cid:4){1}{0, 1}, {0, 1}, {0},(cid:4){0}{0, 1}, {0, 1}, {0},(cid:7)X2 and (cid:7)X1 (cid:2)lex(cid:7)X1, (cid:7)X0 (cid:2)lex(cid:7)X2 are each GAC. But (X0 (cid:2)lex(cid:7)X1 (cid:2)lex X2) is not GAC as theThe proof of Theorem 16 shows that the theorem holds even if attention is restricted to 0/1 variables, demonstratingthe incorrectness of a previous claim [10] to the contrary.Theorem 17. Let (cid:7)X0, . . . , (cid:7)Xn−1 be variable-distinct vectors. Then GAC( (cid:7)Xi <lexi < j does not imply GAC( (cid:7)X0 <lex(cid:7)X1 <lex · · · <lex(cid:7)Xn−1).(cid:7)Xj ) for all i, j ∈ [0, n) such thatProof. This is shown by the example in the proof of Theorem 16. (cid:2)A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834827Subsequent to [10], Carlsson and Beldiceanu [1] introduced a propagation algorithm, called lex_chain, that canestablish GAC on a constraint of the form ( (cid:7)X0 (cid:2)lex(cid:7)Xn−1). Every time the constraint is propagated,(cid:7)X1 (cid:2)lex · · · (cid:2)lexfeasible upper and lower bounds are computed for each vector in the chain and then the vectors are pruned with respectto these bounds. Given m vectors, each of length n, the algorithm maintains generalised arc-consistency or detects(dis)entailment, and performs O(nm) operations.9. Experimental resultsWe implemented our algorithms in C++ using ILOG Solver 5.3 [16] and performed experiments to compare themwith the alternatives presented in Section 7 and the lex_chain algorithm mentioned in Section 8. We experimentedon the three matrix models given in Section 3, adding lexicographic ordering constraints to break the partial and totalindex symmetry.The results of the experiments are shown in tables where a “−” means no result is obtained in 1 hour. The numberof fails gives the number of incorrect decisions at choice points in the search tree. The best result of each entry in atable is typeset in bold. Lexicographic ordering on the rows is enforced via technique Tech, then we write Tech R.Similarly, we write Tech C if Tech is used to constrain the columns to be lexicographically ordered, and Tech RC ifTech is used to constrain both dimensions. In theory, posting lexicographic ordering constraints between every pair ofrows (similarly for columns) leads to more pruning than posting between adjacent rows (see Section 8). However, wedid not observe any benefit in practice. Therefore, we just posted lexicographic ordering constraints between adjacentrows. The experiments were conducted using ILOG Solver 5.3 on a 1 Ghz Pentium III processor with 256 Mb RAMunder Windows XP. We propagate the arithmetic constraint via IloScalProd, which maintains GAC on it. Weeither look for one solution or the optimal solution in optimisation problems.9.1. Comparison with alternative approachesWe designed some experiments to test two goals. First, does our propagation algorithm(s) do more inference inpractice than the ∧ and ∨ decompositions? Similarly, is the algorithm more efficient in practice than these decompo-sitions? Second, how does our algorithm compare with the alternatives that also maintain GAC, that is the arithmeticconstraint, the combined logical decompositions, and Gent et al.’s encoding?We do not experiment with lexico_le, since it is exclusive to ECLiPSe. Recall, however, that we have shownin Section 7.3 that lexico_le does not maintain GAC. Furthermore, we do not experiment with Carlsson andBeldiceanu’s pairwise propagation algorithm since it is exclusive to SICStus prolog. As noted in Section 7.3, however,this algorithm has been shown to behave very similarly to our own.We now consider each of the three problem domains in turn.Progressive party problem. We use the matrix model introduced in Section 3. The H matrix in this model haspartial row and total column symmetry, which we break by posting lexicographic ordering constraints using either ourpropagation algorithm GACLexLess or the various alternative approaches. Due to the problem constraints, no pair ofrows/columns can be equal. Given a set of interchangeable guests {gi, gi+1, . . . , gj }, therefore, we can break the partialrow symmetry of H by constraining the corresponding rows, (cid:7)Ri, (cid:7)Ri+1, . . . , (cid:7)Rj , to be strictly lexicographically orderedas follows: (cid:7)Rj <lex(cid:7)Ri . As for the column symmetry of H , we constrain the columns, (cid:7)C0, (cid:7)C1, . . . , (cid:7)Cp−1,corresponding to the p time periods to be strictly lexicographically ordered as follows: (cid:7)Cp−1 <lex(cid:7)C1.We consider several instances of the progressive party problem, drawn from the data in CSPLib. We randomlyselect 13 host boats in such a way that the total spare capacity of the host boats is sufficient to accommodate all theguests. The data is presented in Table 1. The last column gives the percentage of the total capacity used, which is ameasure of constrainedness [28].(cid:7)Cp−2 · · · <lex(cid:7)Ri+1 · · · <lexWe branch on the variables of the H matrix. As in [24], we give priority to the largest crews, so the guest boatsare ordered in descending order of their size. Also, when assigning a host to a guest, we first try a value that is mostlikely to succeed. We therefore order the host boats in descending order of their spare capacity. In terms of variableordering, we use the smallest-domain first heuristic.828A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834Table 1Instance specification for the progressive party problemInstance #123456789Host boats2-12, 14, 163-14, 163-12, 14, 15, 163-12, 14, 16, 253-12, 14, 16, 233-12, 15, 16, 251, 3-12, 14, 163-12, 16, 25, 263-12, 14, 16, 30Total host spare capacityTotal guest size%capacity1021001011019910010010098929091929091929290.90.90.90.91.91.91.92.92.92Table 2Performance of different propagation algorithms on the progressive party problem. All times are given in secondsInst.#123456789*GACLexLess RCFailsTime4464452,3804594438,48178233,849211,0750.860.982.170.860.986.141.1316.79117.25∧ RCFails–4453,651–443604–773213,568Time–1.413.00–1.121.36–1.31150.33∨ RCFailsTime––––––––––––––––––∧∨ RCTime1.111.252.951.151.188.101.5021.62156.84Gent et al.TimeHarveyTime0.981.112.470.981.166.621.2118.40130.270.921.042.440.950.986.821.2217.93131.11Table 2 summarises the results of the experiments. Note that all the problem instances are solved for 6 time periods.One exception is the last instance, indicated by a “*”, as none of the approaches could solve this instance within anhour time limit for 6 time periods. We therefore report results for 5 time periods for this instance of the problem.In this set of experiments, clearly GACLexLess is superior to the ∨ decomposition: none of the instances couldbe solved within an hour by the ∨ decomposition. However, it is difficult to judge which of GACLexLess and the ∧decomposition is superior. GACLexLess solves instances 1, 4 and 7 very quickly, but the ∧ decomposition fails toreturn an answer in one hour. Also, instances 3 and 9 are solved with fewer failures by GACLexLess. On the otherhand, the ∧ decomposition is superior to GACLexLess for instances 6 and 8. No difference in the size of the search(cid:7)Y does not establishtree is observed for instances 2 and 5. Note that even though the ∧ decomposition of (cid:7)X <lexGAC, enforcing the ∧ decomposition at every choice point may lead to a smaller search tree than maintaining GACat every choice point because a dynamic variable ordering is employed.We now turn our attention to the alternatives that maintain GAC. Note that posting the arithmetic constraint is notfeasible for this problem, as the largest coefficient necessary is 1328, which is greater than 231, the maximum integersize allowed in Solver 5.3. In all cases, the tree explored is identical, hence we focus on run-time. Versus the combined∧∨ decomposition, GACLexLess is clearly more efficient, especially for the more difficult instances. Compared withGent et al.’s encoding and Harvey’s arithmetic constraint, GACLexLess holds a small but consistent advantage thatscales with the difficulty of the instance. In all cases, this advantage is due to the fact that GACLexLess encapsulateslexicographic ordering in a single compact constraint. The alternatives incur the overhead of several constraints and/orseveral additional variables (note that the reification performed in Harvey’s arithmetic constraint makes use of hiddenBoolean variables).Template design problem. We use the model of [21], which adds symmetry-breaking constraints and implied con-straints to the matrix model introduced in Section 3. The T matrix has partial row and partial column symmetry. Againwe break the partial row symmetry by posting lexicographic ordering constraints. Given a set of interchangeable vari-ations {vi, vi+1, . . . , vj }, we can break the partial row symmetry of T by insisting that the rows corresponding toA.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834829such variations, (cid:7)Ri, (cid:7)Ri+1, . . . , (cid:7)Rj , are lexicographically ordered as follows: (cid:7)Ri (cid:2)lexamong interchangeable templates are broken by the constraints(i ∈ [0, t − 1))Runi (cid:2) Runi+1(cid:7)Ri+1 · · · (cid:2)lex(cid:7)Rj . The symmetriesWe post the additional constraints proposed in [21]. In presenting these constraints we consider T emplates be[0, t), Variations to be [0, v), and Surplus to be s ·j ∈Variations dj . To ease the presentation ofthese constraints we assume that the variations are ordered by non-decreasing demand; that is, if i < j then di (cid:2) dj .The additional constraints arei∈T emplates Runi −(cid:2)(cid:2)T0,j < T0,j +1 → T1,j > T1,j +1(cid:7)(cid:7)Runi ∗ Ti,j (cid:2)Runi ∗ Ti,j +1(j ∈ [0, v − 1), dj = dj +1)(j ∈ [0, v − 1), dj < dj +1)i∈T emplates(cid:7)i∈T emplatesRuni ∗ Ti,j − dj (cid:2) Surplus(j ∈ Variations)i∈T emplates(cid:7)(cid:8) (cid:7)(cid:9)Runi ∗ Ti,j − dj(cid:2) Surplus(k ∈ [1, v − 1))(1)(2)(3)(4)0(cid:2)j (cid:2)ki∈T emplatesThe constraints in (1) break symmetries among variations with equal demand when t = 2, and (2) are what they call“pseudo-symmetry” breaking constraints. The constraints of (3) and (4) are implied constraints that provide an upperbound on the cost function. Proll and Smith [21] also post some implied constraints on the Run variables, but we omitthese as they can be shown to be propagation redundant.We also use the static variable ordering proposed by Proll and Smith [21]: we first label the variables of T , andthen the variables of Run. The T matrix is labelled row by row starting with variation 0, and each row is labeled inorder starting with template 0. The Run variables are labelled in order starting with Run0.Our experiments are conducted on an instance of the template design problem known as the herbs problem [21],where labels for a variety of herbs are to be printed on templates. The data for this instance are shown in Table 3.As in [21], we first specify that the over-production of any variation can be at most 10%. With this constraint, thereis no solution with 2 templates, and this is trivially proven by all the approaches and GACLexLeq in 36 fails, 0.1seconds. Removing this restriction makes the problem very difficult. A solution with cost 89 is found in 109,683 failsand around 23 seconds by GACLexLeq, the ∧ decomposition and the arithmetic constraint, but all of them fail toprove optimality within an hour. Changing the labeling heuristic by assigning the Run variables before the T variableshelps to find and prove a solution for 2 templates with cost 87, but does not help to find a solution for 3 templateswithin an hour even with the restricted over-production of 10%.An alternative way of solving the problem is to allow 10% over- and under-production. We therefore relax theconstraint that for all variations the minimum amount produced meets its demand. According to [21], this meets theproblem owner’s specification. The results of tackling the problem in this way for t = 2, 3, 4, 5 templates are shownin Table 4.We observe in Table 4 that, as the number of templates increase, the search effort and time required to find asolution and prove optimality dramatically increase for the ∧ and ∨ decompositions. On the other hand, GACLexLeqfinds and proves solutions very quickly with much less effort. In particular, the 4 and 5 template problems can only besolved by GACLexLeq. On the approaches that maintain GAC we focus on run time since the search trees exploredare identical. In these cases, there is very little difference in time taken. This is because the vectors constrained arerelatively short, with each variable having a relatively small domain size. Hence, the advantage of having a singlecompact constraint is not visible.Table 3The data for the herbs problem in [21]Slots per template Number of variations Demand (in thousands)423060, 60, 70, 70, 70, 70 ,70, 70, 70, 80, 80,80, 80, 90, 90, 90, 90, 90, 90, 100, 100,100, 100, 150, 230, 230, 230, 230, 280, 280830A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834Table 4Performance of different propagation algorithms on the herbs problem with 10% over- and under-production. All times are given in seconds∨ RGACLexLeq R∧ RGoalt∧∨ RTimeArth RTimeGent et al.TimeHarveyTimeFailsTimeFailsTimeFailsTime2345findprovefindprovefindprovefindprove22495526704770.020.020.020.020.020.020.020.02224918,34118,341––––0.020.027.677.67––––224918,84218,842––––0.020.029.309.30––––0.080.080.080.080.080.080.080.080.080.080.080.080.080.080.080.080.020.020.020.020.020.020.020.020.020.020.020.020.020.020.020.02Fig. 7. BIBD: GACLexLeq/GACLexLess vs ∧, ∨, ∧∨ decompositions in terms of fails.Balanced incomplete block design problem. We use the matrix model, introduced in Section 3. Due to the con-straints on the rows, no pair of rows in X can be equal unless r = λ. To break the row symmetry, we enforce thatthe rows (cid:7)R0, (cid:7)R1, . . . , (cid:7)Rv−1 of X corresponding to the v elements are strictly lexicographically ordered as follows:(cid:7)R0. As for the column symmetry, we enforce that the columns (cid:7)C0, (cid:7)C1, . . . , (cid:7)Cb−1 of X cor-(cid:7)Rv−1 <lex(cid:7)C0. We post theresponding to the b subsets of V are lexicographically ordered as follows: (cid:7)Cb−1 (cid:2)lexlexicographic ordering constraints either by using GACLexLess and GACLexLeq, or the corresponding alternativeapproaches.(cid:7)Rv−2 · · · <lex(cid:7)Cb−2 · · · (cid:2)lexLarge benchmark instances were selected with which to experiment (as in [4]). For the labelling heuristic, weadopted a static variable ordering, instantiating the matrix X along its rows from top to bottom and exploring thedomain of each variable in ascending order. Figs. 7–9 (note the logarithmic scale) summarise our results. Again, webegin by comparing our propagation algorithm with the ∧ and ∨ decompositions individually. Given our choice ofvariable ordering, our algorithm explores the same search tree as the ∧ decomposition on all but two of the instances,where it explores a slightly smaller tree. The ∨ decomposition, however, can solve only the first 3 instances withinan hour limit, with many more failures. In terms of run time, however, we observe a substantial gain in efficiencyby using our algorithms in preference to the other approaches. Even though the ∧ decomposition and our algorithmsexplore the same search tree, the efficiency of our algorithms dramatically reduces the run times.We now turn our attention to the alternatives that maintain GAC. Note that these instances require the orderingof relatively long vectors, hence posting the arithmetic constraint is not feasible. The combined ∧∨ decompositionperforms better than the ∧ decomposition alone, but is still significantly less efficient than GACLexLeq. We observein Fig. 9 that the instances are solved quicker using our algorithm (note the logarithmic scale), though the differenceis not as much as the difference between the algorithms and the ∧ decomposition in Fig. 8. In comparison with Gentet al.’s encoding and Harvey’s arithmetic constraint, GACLexLeq maintains a small but consistent advantage.To summarise the three sets of experiments in this section, GACLexLeq provides an efficient and lightweightmeans of enforcing lexicographic ordering, which provides a consistent improvement over the alternatives when usedA.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834831Fig. 8. BIBD: GACLexLeq/GACLexLess vs ∧, ∨, ∧∨ decompositions in terms of run times.Fig. 9. BIBD: GACLexLeq/GACLexLess vs Gent et al.’s encoding and Harvey’s arithmetic constraint in terms of run times.with a fixed search strategy. We observed that a weaker propagation algorithm combined with a dynamic variableordering can sometimes perform better, but this is unsurprising: choosing the ‘right’ variable to assign next is wellknown to be crucial in reducing search. On this occasion the dynamic variable was led by chance to a better selectiondue to weaker propagation.The alternatives that do maintain GAC have the disadvantage of requiring the introduction of auxiliary variablesand constraints. To illustrate this point, consider Figs. 10 and 11, which present the total numbers of variables andmemory used for GACLexLeq, Gent et al.’s encoding and Harvey’s decomposition on the BIBD problem.9.2. Comparison with lex_chainAs Theorem 16 shows, the lex_chain algorithm of [1] can do more pruning than lexicographic ordering con-straints between adjacent pairs of vectors. We performed a further set of experiments to determine the value of thisadditional pruning in practice. We focus on the BIBD problem as the most challenging domain considered herein.Table 5 summarises the results of solving BIBDs using SICStus Prolog constraint solver 3.10.1 [26]. Note that weused different instances from those in the previous experiments, since the earlier instances proved to take too longto solve in SICStus. We constrained the columns and rows to be lexicographically ordered non-decreasing or non-increasing, and assigned the variables in the matrix from top to bottom exploring the domains in ascending order.The lexicographic ordering constraints are posted using lex_chain. This constraint is either posted once for all thesymmetric rows/columns, or between each adjacent symmetric rows/columns.In all the cases, we observed no benefits of combining a chain of lexicographic ordering constraints. By posting theconstraints between the adjacent rows/columns, we obtain the same search trees and very similar run times as posting832A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834Fig. 10. BIBD: GACLexLeq/GACLexLess vs Gent et al.’s encoding and Harvey’s arithmetic constraint in terms of number of variables.Fig. 11. BIBD: GACLexLeq/GACLexLess vs Gent et al.’s encoding and Harvey’s arithmetic constraint in terms of memory usage.Table 5BIBD: lex_chain((cid:3)X0, . . . , Xm−1(cid:4)) vs lex_chain((cid:3)Xi , Xi+1(cid:4)) for all i ∈ [0, m − 1) with row-wise labelingv, b, r, k, λNo symmetrybreakingBacktracks<lex R (cid:2)lex Clex_chain(cid:3)X0, . . . , Xm−1(cid:4)Backtracks6,20,10,3,47,21,9,3,36,30,15,3,67,28,12,3,49,24,8,3,26,40,20,3,87,35,15,3,57,42,18,3,65,2011,488540,03923,160––9,429,4475,975,823841302172161,472449326460(cid:3)Xi , Xi+1(cid:4)Backtracks841302172161,472449326460>lex R (cid:3)lex Clex_chain(cid:3)X0, . . . , Xm−1(cid:4)Backtracks7067292161837951,576395756(cid:3)Xi , Xi+1(cid:4)Backtracks7067292161837951,576395756only one constraint on the rows/columns. This result is in agreement with our previous experiments, comparing postinglexicographic ordering constraints between adjacent rows/columns of a matrix, and between all pairs of rows/columns[10], where the latter is an approximation of lex_chain.10. ConclusionThis paper introduced new algorithms for propagating lexicographic ordering constraints on two vectors of decisionvariables. Such constraints are useful for breaking row and column symmetries in matrix models. We demonstratedthat decomposing such constraints often carries a penalty either in the amount or the cost of constraint propagation.A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834833We have therefore developed efficient propagation algorithms that either ensure that such constraints are GAC ordetect disentailment. These algorithms require only O(n) operations where each vector contains n variables and canexecute as sequence of k updates in O(n + k) operations. Experimental results on a number of domains demonstratethe value of these new algorithms.A number of interesting questions remain. First, are there other total orderings of vectors that we can post to breakrow and column symmetry? For example, can we use the Gray code ordering? Second, how do we design labelingstrategies to work in synergy with symmetry breaking constraints like this? Third, are these global constraints usefulin multi-criteria optimization problems where the objective function consists of features that are ranked [7]?AcknowledgementsWe thank Chris Jefferson for many useful discussions. Ian Miguel is supported by a UK Royal Academy of Engi-neering/EPSRC Research Fellowship. Brahim Hnich received support from Science Foundation Ireland under GrantNo. 00/PI.1/C075. The majority of this work was done while Brahim Hnich and Zeynep Kiziltan were at UppsalaUniversity, and Ian Miguel was at the University of York.References[1] M. Carlsson, N. Beldiceanu, Arc-consistency for a chain of lexicographic ordering constraints, Technical Report T2002-18, Swedish Instituteof Computer Science, 2002.[2] M. Carlsson, N. Beldiceanu, Revisiting the lexicographic ordering constraint, Technical Report T2002-17, Swedish Institute of ComputerScience, 2002.[3] B.M.W. Cheng, K.M.F. Choi, J.H.M. Lee, J.C.K. Wu, Increasing constraint propagation by redundant modeling: An experience report, Con-straints 4 (1999) 167–192.[4] C.H. Colbourn, J.H. Dinitz, The CRC Handbook of Combinatorial Designs, CRC Press, 1996.[5] J. Crawford, G. Luks, M. Ginsberg, A. Roy, Symmetry breaking predicates for search problems, in: Proceedings of the 5th InternationalConference on Knowledge Representation and Reasoning (KR ’96), 1996, pp. 148–159.[6] P. Brisset, H. El Sakkout, T. Frühwirth, C. Gervet, W. Harvey, M. Meier, S. Novello, T. Le Provost, J. Schimpf, K. Shen, M.G. Wallace,ECLiPSe Constraint Library Manual Release 5.6, 2003.[7] M. Ehrgott, X. Gandibleux, A survey and annotated bibliography of multiobjective combinatorial optimization, OR Spektrum 22 (2000)425–460.[8] P. Flener, A.M. Frisch, B. Hnich, Z. Kiziltan, I. Miguel, J. Pearson, T. Walsh, Breaking row and column symmetry in matrix models, in:P. van Hentenryck (Ed.), Proceedings of the 8th International Conference on Principles and Practice of Constraint programming (CP-02), in:Lecture Notes in Computer Science, vol. 2470, Springer, 2002, pp. 462–476.[9] P. Flener, A.M. Frisch, B. Hnich, Z. Kiziltan, I. Miguel, T. Walsh, Matrix modelling: Exploiting common patterns in constraint programming,in: Proceedings of the International Workshop on Reformulating Constraint Satisfaction Problems, 2002, pp. 27–41.[10] A.M. Frisch, B. Hnich, Z. Kiziltan, I. Miguel, T. Walsh, Global constraints for lexicographic orderings, in: P. van Hentenryck (Ed.), Pro-ceedings of the 8th International Conference on Principles and Practice of Constraint Programming (CP-02), in: Lecture Notes in ComputerScience, vol. 2470, Springer, 2002, pp. 93–108.[11] I.P. Gent, R.W. Irving, D. Manlove, P. Prosser, B.M. Smith, A constraint programming approach to the stable marriage problem, in: T. Walsh(Ed.), Proceedings of the 7th International Conference on Principles and Practice of Constraint Programming (CP-01), in: Lecture Notes inComputer Science, vol. 2239, Springer, 2001, pp. 462–476.[12] I.P. Gent, P. Prosser, B.M. Smith, A 0/1 encoding of the gaclex constraint for pairs of vectors, in: Notes of the ECAI-02 Workshop W9Modelling and Solving Problems with Constraints, 2002.[13] I.P. Gent, T. Walsh, CSPLib: A benchmark library for constraints, Technical Report APES-09-1999, 1999.[14] W. Harvey, Personal e-mail communication, 2002.[15] B. Hnich, Function variables for constraint programming, PhD thesis, Department of Information Science, Uppsala University, 2003.[16] ILOG S.A., ILOG Solver 5.3 Reference and User Manual, 2002.[17] Z. Kiziltan, Symmetry breaking ordering constraints, PhD thesis, Uppsala University, 2004.[18] A.K. Mackworth, Consistency in networks of relations, Artificial Intelligence 8 (1977) 99–118.[19] A.K. Mackworth. On reading sketch maps, in: Proceedings of the 5th International Joint Conference on Artificial Intelligence, 1977, pp. 598–606.[20] P. Meseguer, C. Torras, Solving strategies for highly symmetric CSPs, in: T. Dean (Ed.), Proceedings of the 16th International Joint Conferenceon Artificial Intelligence (IJCAI-99), Morgan Kaufmann, 1999, pp. 400–405.[21] L. Proll, B.M. Smith, Integer linear programming and constraint programming approaches to a template design problem, INFORMS Journalon Computing 10 (3) (1998) 265–275.[22] J.F. Puget, On the satisfiability of symmetrical constrained satisfaction problems, in: H.J. Komorowski, Z.W. Ras (Eds.), Proceedings of the 7thInternational Symposium on Methodologies for Intelligent Systems (ISMIS-93), in: Lecture Notes in Computer Science, vol. 689, Springer,1993, pp. 350–361.834A.M. Frisch et al. / Artificial Intelligence 170 (2006) 803–834[23] A. Schrijver, Theory of Linear Integer Programming, John Wiley and Sons, 1986.[24] B.M. Smith, S.C. Brailsford, P.M. Hubbard, H.P. Williams, The progressive party problem: Integer linear programming and constraint pro-gramming compared, Constraints 1 (1996) 119–138.[25] I. Shlyakhter, Generating effective symmetry-breaking predicates for search problems, Electronic Notes in Discrete Mathematics 9 (2001).[26] Swedish Institute of Computer Science, SICStus Prolog User’s Manual, Release 3.10.1, April 2003.[27] M. Wallace, Practical applications of constraint programming, Constraints 1 (1/2) (1996) 139–168.[28] J.P. Walser, Integer Optimization by Local Search—A Domain-Independent Approach, Lecture Notes in Artificial Intelligence, vol. 1637,Springer, 1999.[29] M.G. Wallace, S. Novello, J. Schimpf, ECLiPSe: A platform for constraint logic programming, ICL Systems Journal 12 (1) (1997) 159–200.