Artificial Intelligence 175 (2011) 1655–1671Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintVoting almost maximizes social welfare despite limited communication ✩Ioannis Caragiannis a, Ariel D. Procaccia b,∗a Research Academic Computer Technology Institute & Department of Computer Engineering and Informatics, University of Patras, Greeceb School of Engineering and Applied Sciences, Harvard University, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 7 December 2010Received in revised form 14 March 2011Accepted 23 March 2011Available online 5 April 2011Keywords:Computational social choiceIn cooperative multiagent systems an alternative that maximizes the social welfare—the sumof utilities—can only be selected if each agent reports its full utility function. This may beinfeasible in environments where communication is restricted. Employing a voting rule tochoose an alternative greatly reduces the communication burden, but leads to a possiblegap between the social welfare of the optimal alternative and the social welfare of theone that is ultimately elected. Procaccia and Rosenschein (2006) [13] have introduced theconcept of distortion to quantify this gap.In this paper, we present the notion of embeddings into voting rules: functions that receivean agent’s utility function and return the agent’s vote. We establish that very low distortioncan be obtained using randomized embeddings, especially when the number of agents islarge compared to the number of alternatives. We investigate our ideas in the contextof three prominent voting rules with low communication costs: Plurality, Approval, andVeto. Our results arguably provide a compelling reason for employing voting in cooperativemultiagent systems.© 2011 Elsevier B.V. All rights reserved.1. IntroductionA major challenge that arises in the design and implementation of multiagent systems is the aggregation of the pref-erences of the agents. Voting theory provides a neat solution by giving extremely well-studied methods of preferenceaggregation. In recent years the theoretical aspects of computational voting have been enthusiastically investigated, es-pecially within the AI community (see, e.g., [15, Chapter 1] and the many references therein). Moreover, voting has beenapplied for preference aggregation in areas as diverse as Planning, Scheduling, Recommender Systems, Collaborative Filtering,Information Extraction, and Computational Linguistics (see, e.g., [7,12,16]).While the appeal of voting in the context of heterogeneous, competitive multiagent systems is apparent, some multiagentsystems are centrally designed and fully cooperative (e.g., systems for planning and scheduling, recommender systems, collab-orative filtering, and so on). We believe that, to date, the benefit of employing voting in such domains was unclear. Indeed,agents are normally assumed to compute a utility for every possible alternative. If the agents are cooperative then they cansimply communicate their utilities for the different alternatives, and subsequently select an alternative that maximizes thesocial welfare, i.e., the sum of utilities.However, accurately conveying an agent’s utility function for each alternative may be very costly in terms of commu-nication. This could prove to be a serious obstacle in domains where communication is restricted. Communication maybe limited by the physical properties of the system (e.g., slow or error-prone transmitters, systems with low energy con-✩A preliminary version of the paper appeared in the Proceedings of AAAI’10.* Corresponding author.E-mail addresses: caragian@ceid.upatras.gr (I. Caragiannis), arielpro@seas.harvard.edu (A.D. Procaccia).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.03.0051656I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–1671sumption requirements, etc.) or the representation of the full utility functions may require a huge amount of information.Blumrosen et al. [1] outline additional persuasive reasons why communication should be restricted in multiagent settings.Fortunately, some prominent voting rules—functions that select an alternative given the preferences of the agents—imposea very small communication burden [5], and are moreover resistant to errors in communication [14].For example, consider the paradigmatic cooperative multiagent system domain: scanning an area on Mars with multiplerovers (which are known to have limited communication capabilities). Suppose the rovers must select or update their jointplan (this may happen very often), and there are one million alternatives. Moreover, suppose each rover computes a utilityfor each alternative on a scale of one to one million (this is, in fact, a very coarse scale). A rover would need to communicate106 · log(106) ≈ 20 · 106 bits in order to report its utility function. In contrast, under the Plurality voting rule, where eachagent votes for a single alternative and the alternative with most votes wins, a rover only needs to transmit twenty bits. Eventhough current applications may involve a small number of rovers, the research in wireless communication systems alreadyenvisages large-scale applications (e.g., for environment monitoring, disaster relief, battlefield operations and surveillance)with many ultra-small, possibly mobile, wireless devices such as sensors or mini-robots that cooperate towards a commongoal. Such devices are expected to be fully autonomous, a property that calls for low energy consumption and, consequently,for low communication requirements. The Harvard Micro Air Vehicles Project1 provides a concrete example of such a system.In this paper we shall argue that, in some cooperative multiagent systems, exact maximization of the social welfare canbe replaced by very simple voting rules (given an extra ingredient that we present below). The benefit is a huge reductionin the communication burden, whereas the cost, a deterioration in the social welfare of the outcome, will be shown to bealmost negligible in some settings. This arguably provides a pivotal reason for employing voting in cooperative multiagentsystems, and in AI in general.1.1. Our approachThe degree to which the social welfare of the outcome can decrease when voting is used is captured by the notionof distortion, introduced by Procaccia and Rosenschein [13]. They focus on voting rules that receive as input a ranking ofthe alternatives, and, crucially, assume that each agent reports a ranking such that the alternative that is ranked in thekth place has the kth highest utility. Under this assumption, they define the distortion of a voting rule to be the worst-caseratio between the maximum social welfare over all the alternatives, and the social welfare of the winner of the election; theworst-case is taken over all the possible utility functions of the agents. After proving some impossibility results, Procacciaand Rosenschein further restrict the structure of the utility functions. Even under this additional (very strong) assumption,they show that the distortion of most prominent voting rules is linear in the number of alternatives. The approach ofProcaccia and Rosenschein is descriptive: they propose to use the notion of distortion as a criterion in the comparison ofdifferent voting rules.Our main conceptual contribution is the consideration of embeddings into voting rules. An embedding is a set of instruc-tions that inform each agent how to vote, based only on the agent’s own utility function, that is, without any communicationor coordination between different agents. More accurately, an embedding into a specific voting rule is a function from utilityfunctions to votes that are valid under the voting rule. For instance, consider the simple Plurality rule described above. Givena utility function, an embedding into Plurality returns the alternative that the agent votes for. Procaccia and Rosenscheinimplicitly use one specific embedding, but many different embeddings exist. In this sense, our approach is algorithmic: wewish to design embeddings in a way that minimizes the distortion.We redefine the notion of distortion to take embeddings into account. The distortion of an embedding into a voting rule isstill the worst-case ratio between the maximum social welfare and the social welfare of the winner, but now the winnerdepends both on the voting rule and on the embedding, that is, on the way the utilities of the agents are translated intovotes. The worst-case is taken over all possible utilities; we do not make any assumption regarding the utilities, except thatthey are normalized.We take the idea of embeddings into voting rules one step further by allowing randomized embeddings. A randomizedembedding randomly chooses the agent’s vote, according to some probability distribution. The distortion is defined similarly,by taking into account the expected social welfare of the winner of the election. As we shall see, randomization gives usgreat power and flexibility, and ultimately provides us with the tools to design truly low-distortion embeddings.We wish to design low-distortion embeddings into voting rules with low communication complexity. Indeed, given thateach of our cooperative agents votes according to the instructions provided by the embedding (in a fully decentralized way),then an alternative with social welfare close to optimal may be elected in the face of restricted communication. We find theexistence of low-distortion embeddings rather striking, as the social welfare is a centralized concept.1.2. Our resultsWe study the distortion of embeddings into three voting rules: Plurality, Approval (each agent approves a subset ofalternatives), and Veto (each agent gives a “negative point” to one alternative). Plurality and Veto have the smallest com-1 http://robobees.seas.harvard.edu.I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–16711657munication burden among all prominent voting rules: only log m bits per agent, where m is the number of alternatives.Approval requires more communication, m bits per agent, but still less than other prominent voting rules.We first deal with the Plurality rule. We show that any deterministic embedding into Plurality has distortion Ω(m2),and also provide a matching upper bound. Our main result deals with randomized embeddings into Plurality: we show thatthe naïve embedding into Plurality, which selects an alternative with probability proportional to its utility, yields constantdistortion when n = Ω(m ln m), where n is the number of agents, and has extremely low distortion, specifically 1 + o(1), forlarger values of n.Next we investigate the Approval rule. We give a lower bound of Ω(m) for deterministic embeddings, and also presenta matching upper bound. Our randomized upper bounds for Approval follow directly from the upper bounds for Plurality,since any embedding into Plurality is also an embedding into Approval.These results apply to the case n (cid:2) m. Even though we have no positive theoretical results for the case n (cid:3) m, we presentexperimental results from the application of randomized embeddings into Plurality and Approval on random utility profiles;the results suggest that relatively low distortion can also be achieved in this case as well provided that the number ofagents is not very small.Finally, we consider the Veto rule. We show that any deterministic embedding into Veto has infinite distortion, and thesame is true for randomized embeddings if n < m − 1. We further show that low-distortion embeddings into Veto can beobtained, albeit using a large number of agents. Our related positive result is stated in a more general form and applies toany scoring protocol.2. Embeddings into PluralityWe denote by N = {1, . . . , n} the set of agents, and by A, | A| = m, the set of alternatives.We assume that the agents have normalized cardinal utilities over A. Specifically, let U = U ( A) be the set of utilityx∈ A u(x) = 1. Each agent i has a utility function u ∈ U . A utilityfunctions u over A such that for each x ∈ A, u(x) (cid:2) 0, andprofile is a vector of utility functions(cid:2)u = (cid:5)u1, . . . , un(cid:6) ∈ U n.The social welfare of an alternative x ∈ A with respect to u ∈ U n, denoted by sw(x, u), is the sum of the utilities of x for allagents:sw(x, u) =(cid:3)i∈Nui(x).In our formal presentation, a voting rule is defined as a function that selects a set of alternatives rather than a singlealternative. Such a function is formally known as a voting correspondence, hence the term voting rule is slightly abused. Wemust deal with sets of winners since our rules are based on notions of score, and there might be a tie with respect to themaximum score.Under the Plurality rule, each agent casts its vote in favor of a single alternative. The set of winners is the set of alterna-tives with a maximum number of votes.A deterministic embedding into Plurality is a function f : U → A. Informally, given an agent i ∈ N with a utility functionf (u) is the alternative which agent i votes for under the embedding f . Given a utility profile u ∈ U n and anu ∈ U ,embedding f , denote the (Plurality) score of x ∈ A bysc(x, f , u) =(cid:4)(cid:5)(cid:4)i ∈ N: f (ui) = x(cid:6)(cid:4)(cid:4),and denote the set of winners bywin( f , u) = argmaxx∈ Asc(x, f , u).Note that the argmax function returns a set of maximal alternatives.A randomized embedding randomly selects one of the alternatives, that is, it is a function f : U → (cid:3)( A), where (cid:3)( A) isthe space of probability distributions over A. Put another way, given u ∈ U ,f (u) is a random variable that takes the valuex∈ A p(x) = 1. With respect to a randomized embedding f , sc(x, f , u) is a random variablex ∈ A with probability p(x), i.e.,that takes values in {1, . . . , n}, and win( f , u) is a random variable that takes values in 2 A , the powerset of A. Less formally,given a randomized embedding f , a utility profile u, and S ⊆ A, we have some probability (possibly zero) of S being theset of winners when fis applied to u.(cid:2)As a measure of the quality of an embedding, we use the notion of distortion, introduced by Procaccia and Rosenschein[13], but adapt it to apply to general embeddings.1658I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–1671Definition 1 (Distortion).1. Let f : U → A be a deterministic embedding, u ∈ U n. The distortion of f at u isdist( f , u) = max y∈ A sw( y, u)minx∈win( f ,u) sw(x, u).2. Let f : U → (cid:3)( A) be a randomized embedding, u ∈ U n. The distortion of f at u isdist( f , u) =max y∈ A sw( y, u)E[minx∈win( f ,u) sw(x, u)].3. Let f be a deterministic or randomized embedding. The distortion of fisdist( f ) = maxu∈U ndist( f , u).Let us give an intuitive interpretation of this important definition. The distortion of a deterministic embedding is theworst-case ratio between the social welfare of the most popular alternative, and the social welfare of the least popularwinner, where the worst-case is with respect to all possible utility profiles. In other words, we are interested in the question:how small can the social welfare of one of the winners be, when compared to the alternative with maximum social welfare?Our focus on the social welfare of the “worst” winner is appropriate since the analysis is worst-case. Alternatively, it ispossible to think of voting rules that elect only one of the alternatives with maximum score, but in the worst-case the mostunpopular one is elected, that is, in the worst-case ties are broken in favor of alternatives with lower social welfare; this isthe interpretation of Procaccia and Rosenschein [13].The definition of distortion with respect to randomized embeddings is slightly more subtle. Here there is no definitewinner. However, given a utility profile u ∈ U , we can talk about the expected minimum social welfare among the winners,since the set of winners is simply a random variable that takes values in 2 A , hence minx∈win( f ,u) sw(x, u) is a randomvariable that takes values in the interval [0, n] and its expectation is well defined. The rest of the definition is identical tothe deterministic case.2.1. Deterministic embeddingsProcaccia and Rosenschein [13] consider a specific, naïve deterministic embedding into Plurality. Their embedding simplymaps a utility function u ∈ U to an alternative with maximum utility, that is,f (u) ∈ argmaxx∈ A u(x). They show that itsdistortion is m − 1 under a very restricted definition of distortion (called misrepresentation) that assumes a specific structureof utility functions.It is easy to see that the distortion of this naïve embedding, according to Definition 1, is at most m2. Indeed, let u ∈ U ,is the naïve embedding. By the Pigeonhole Principle, it must hold that sc(x, f , u) (cid:2) n/m.and let x ∈ win( f , u), where fNow, for each agent i ∈ N such that f (ui) = x, it must hold that ui(x) (cid:2) 1/m, since x has maximum utility and there mustexist an alternative with utility 1/m (again, by the Pigeonhole Principle). We deduce that sw(x, u) (cid:2) n/m2. On the otherhand, for any y ∈ A, sw( y, u) (cid:3) n. Therefore,dist( f ) = maxu∈U nmax y∈ A sw( y, u)minx∈win( f ,u) sw(x, u)(cid:3) nn/m2= m2.We wish to ask whether there is a clever deterministic embedding into Plurality that (asymptotically) beats the m2 upperbound given by the naïve one. Our first theorem answers this question in the negative.Theorem 2. Let | A| = m (cid:2) 3, |N| = n (cid:2) (cid:9) m+12Ω(m2).(cid:10), and let f : U → A be a deterministic embedding into Plurality. Then dist( f ) =Proof. Let f be a deterministic embedding into Plurality. For every pair of distinct alternatives x, y ∈ A, let uxy ∈ U suchthat uxy(x) = 1/2, uxy( y) = 1/2, and uxy(z) = 0 for every z ∈ A \ {x, y}. We claim that we can assume that f (uxy) ∈ {x, y},since otherwise the distortion is infinite. Indeed, if f (uxy) = z /∈ {x, y}, then consider a utility profiles u where ui ≡ uxy forall i ∈ N. Then win( f , u) = {z}, but sw(z, u) = 0, whereas, say, sw(x, u) = n/2 > 0.Let T be a tournament on A, that is, a complete asymmetric binary relation (see, e.g., [10]). For every two alternativesx, y ∈ A, we have that xT y (read: x dominates y) if f (uxy) = x, and yT x if f (uxy) = y. By our claim above, T is well defined., by the Pigeonhole Principle there must be an alternative thatSince the number of pairs of alternatives is(cid:8)(cid:7)m2= m(m−1)2other alternatives; without loss of generality this alternative is a ∈ A. Let A(cid:12)(cid:10) such that for all x ∈ A∗ ∈ U as follows: for every x ∈ A(cid:12), xT a. Further, let A(cid:12)(cid:12) = A \ ( A(cid:12)(cid:12)∗(x) = 1/| A(cid:12)(cid:12)|; for every x ∈ A \ A, u(cid:12) ∪ {a}) and notice that | A, ube a subset of(cid:12)(cid:12)| = (cid:14) m−1(cid:15). Define∗(x) = 0. Then without loss of(cid:12)(cid:12)2is dominated by at least m−12alternatives of size (cid:9) m−12a utility function ugenerality f (u∗) = b, with b ∈ A(cid:12)(cid:12), otherwise the distortion is infinite by the same reasoning as above.I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–16711659Now, we have | A(cid:12)| + 1)(cid:15). All the agents in the first(cid:12)| + 1 blocks of agents, each of size either (cid:9)n/(| Ablock, which is at least as large as any other, have the utility function u, thereis a block of agents with the utility function uax (hence they vote for x). Given this utility profile u, b must be among thewinners, that is, b ∈ win( f , u). We have that(therefore they vote for b). For each x ∈ A(cid:12)| + 1)(cid:10) or (cid:14)n/(| A∗(cid:12)sw(b, u) (cid:3)(cid:9)(cid:10)n(cid:9) m−1(cid:10) + 12·1(cid:14) m−12(cid:15)(cid:3) 8nm2,whereas(cid:11)(cid:9)sw(a, u) (cid:2)n −n(cid:9) m−1(cid:10) + 12(cid:10)(cid:12)· 12(cid:2) n6.The distortion is at least as large as the ratio between the maximum social welfare and the social welfare of a winner withrespect to the specific utility profile u, that is,∗)dist( f ) (cid:2) dist( f , u) (cid:2) sw(a, usw(b, u∗)(cid:8)(cid:7)m2.= Ω(cid:2)2.2. Randomized embeddingsTheorem 2 implies that the distortion of any deterministic embedding into Plurality is quite high. Can we do better usingrandomized embeddings? In general, the answer is definitely positive. However, we start our investigation of randomizedembeddings into Plurality with a negative result that holds when the number of agents is small.Theorem 3. Let |N| = n (cid:3) m = | A|. Then any randomized embedding f : U → (cid:3)( A) into Plurality has distortion Ω(m/n).Proof. Let f be an embedding into Plurality. Consider a utility function uexist xwith probability at most 1/m.∗ ∈ A such that f (u∗∗) = xun(x∗For i = 1, 2, . . . , n − 1, let ui ≡ u∗) = 1, un(x) = 0 for all x ∈ A \ {xNow, the probability that {xbe the utility function of agent i, and let the utility function of agent n be defined bym , sw(x, u) = n−1∗}. We have that sw(xm for any x ∈ A \ {x∗, u) = 1 + n−1∗}.∗∗} = win( f , u) is at most the probability that xreceives a vote from one of the agents1, 2, . . . , n − 1, i.e., at most (n − 1)/m. We conclude that the distortion of f at u is at least∗ ∈ U where u∗(x) = 1/m for all x ∈ A. There mustdist( f , u) =n−1m1 + n−1mm ) + (1 − n−1m ) · n−1m· (1 + n−1=m2(n − 1)+ 12,hence dist( f ) = Ω(m/n). (cid:2)We now turn to our presentation of low-distortion embeddings. It turns out that when the number of agents is at least aslarge as the number of alternatives, a huge reduction in the distortion can be achieved using randomized embeddings. If thenumber of agents is significantly larger, the distortion can be very close to one. Indeed, consider the following embedding.Embedding 1 (Naïve randomized embedding into Plurality). Given a utility function u ∈ U , select alternative x ∈ A with proba-bility u(x).The following powerful theorem is our main result.Theorem 4. Let |N| = n (cid:2) m = | A|, and denote Embedding 1 by f . Then:1. dist( f ) = O(m2m/n).2. dist( f ) = O(3. Let n (cid:2) 3 and (cid:4)(n, m) = 4m ).√(cid:13)m ln nn. If (cid:4)(n, m) < 1, then dist( f ) (cid:3)11−(cid:4)(n,m) .All three bounds on the distortion are required, since each has values of n and m where its guarantees are strongerthan the others. Asymptotically, the most powerful bound is the one given in Part 1: it guarantees that the distortion ofEmbedding 1 is already constant when n = Ω(m ln m), that is, when the number of agents is slightly larger than the numberof alternatives. This is very close to the necessary condition n = Ω(m) for obtaining constant distortion that is implied byTheorem 3. Part 1 yields a very weak result for the case n = m; in this case, we get by Part 2 that the distortion is O(m ).Finally, for large values of n we do not find it sufficient to show that the distortion is constant, we want to establish that it√1660I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–1671is almost one. This does not follow from Part 1 due to the constant hidden in the O notation. However, from Part 3 we getthat for, e.g., n (cid:2) m2, the distortion is 1 + o(1).We now prove the theorem. We will require several results regarding the sums of random variables.Lemma 5. Let X1, . . . , Xn be independent heterogeneous Bernoulli trials. Denote by μ the expectation of the random variable X =(cid:2)i Xi . Then (see, e.g., [11] for the different variations on the Chernoff bounds):1. (Jogdeo and Samuels [9]) Pr[ X < (cid:14)μ(cid:15)] < 1/2.2. (Lower tail Chernoff bound) For any δ ∈ [0, 1],(cid:8).−μδ2/23. (Upper tail Chernoff bound) For any δ (cid:2) 0,(cid:15)X (cid:3) (1 − δ)μ(cid:3) expPr(cid:7)(cid:14)(cid:14)(cid:15)X (cid:2) (1 + δ)μPr(cid:3)(cid:11)e1 + δ(cid:12)(1+δ)μ.4. For δ (cid:2) 2e − 1,(cid:14)(cid:15)X (cid:2) (1 + δ)μPr(cid:3) 2−(1+δ)μ.5. For δ < 2e − 1 we can use the simplified inequality(cid:14)(cid:15)X (cid:2) (1 + δ)μPr(cid:7)(cid:3) exp−μδ2/5(cid:8).(1)(2)(3)(4)Proof of Theorem 4. We prove the theorem’s three parts separately. Part 1 is the most straightforward, while Part 2 issimilar but slightly more involved, and the proof of Part 3 is quite different and significantly more complicated.is sw(x, u). Let xProof of Part 1. Let u ∈ U n be a utility profile. First notice that the expected Plurality score of x ∈ A under the embedding∗ ∈ argmaxx∈ A sw(x, u) be an alternative with maximum social welfare. We have thatx∈ A sw(x, u) = n;f∗, u) (cid:2) n/m (cid:2) 1. By Part 1 of Lemma 5, with probability at least 1/2 itby the assumption that n (cid:2) m, it follows that sw(xholds that sc(x∗, u)(cid:15).(cid:2)∗, f , u) (cid:2) (cid:14)sw(xConsider some alternative x ∈ A such thatsw(x, u) <∗, u)sw(x2e(4m)2m/n.(5)We apply the upper tail Chernoff bound (2) to the random variable sc(x, f , u) with expectation μ = sw(x, u) using (1 +δ)μ = (cid:14)sw(x∗, u)/2, we also have 1 + δ > e(4m)2m/n. Therefore,∗, u)(cid:15) > sw(x∗, u)(cid:15). By (5) and since (cid:14)sw(x(cid:11)(cid:14)sc(x, f , u) (cid:2)Pr(cid:16)(cid:7)sw∗x, u(cid:8)(cid:17)(cid:15)(cid:3)1(4m)2m/n(cid:12)(cid:14)sw(x∗,u)(cid:15)(cid:11)(cid:3)1(4m)2m/n(cid:12)sw(x∗,u)/2(cid:3) 14m,where the last inequality follows since sw(x∗, u) (cid:2) n/m.By the union bound, the probability that either sc(x∗, u)(cid:15), or some alternative x that satisfies (5) hasis at most 3/4. Therefore, with probability 1/4 all the winners have social welfare at least∗, f , u) < (cid:14)sw(xsc(x, f , u) (cid:2) (cid:14)sw(xsw(x∗, u)(cid:15),∗, u)/(2e(4m)2m/n). Hence∗, u)dist( f , u) (cid:3) sw(xsw(x∗,u)2e(4m)2m/n14·= 8e · (4m)2m/n.Since n (cid:2) m, we have that 42m/n (cid:3) 16. It follows that the distortion of fis as announced.∗Proof of Part 2. The proof is similar to Part 1. Given u ∈ U n, we once again denote by xsocial welfare, and we let L ⊂ A be the set of alternatives with social welfare smaller than sw(xthe alternative with maximum√∗, u)/(3em ), that is,(cid:18)L =x ∈ A: sw(x, u) <∗, u)sw(x√m3e(cid:19).If L = ∅ then the claim follows trivially, hence we can restrict our attention to three cases. In all three cases we demonstratethat with constant probability no alternative in L is among the winners, that is, with probability bounded away from zeroan alternative with social welfare at least sw(xm ) is elected, which directly yields the bound on the distortion.∗, u)/(3e√Case 1: sw(xprobability that sc(x√2/(3e∗, u) < 2 and |L| = 1. Since n (cid:2) m it also holds that sw(x∗, f , u) = 0 is at most 1/2. Let x be the element of L. Since sw(x∗, u) (cid:2) 1 and, hence, by Jogdeo and Samuels the∗, u) < 2, it also holds that sw(x, u) <√m ) and, by Markov’s inequality, we have that the probability that sc(x, f , u) (cid:2) 1 is at most 2/(3em ) < 1/4.I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–16711661Case 2: sw(xvotes for an alternative not in L. We have that∗, u) < 2 and |L| > 1. For each i ∈ N, let Xi be a random variable such that Xi = 1 if f (ui) /∈ L, that is, agent i(cid:3)Xi =(cid:3)x /∈Lsc(x, f , u).i∈N(cid:2)The sumx /∈L sc(x, f , u) has expectation at leastm − 2√3em· |L| > m − |L| + 1.By Jogdeo and Samuels (using the fact that the Xi are independent) with probability at least 1/2 it holds that(cid:2)x /∈L sc(x, f , u) (cid:2) m − |L| + 1. If so then by the Pigeonhole Principle there exists some alternative x0 ∈ A \ {L} which hassc(x0, f , u) (cid:2) 2.Now, consider some alternative x ∈ L. We apply Eq. (2) to the random variable sc(x, f , u) with expectation μ = sw(x, u)√√using (1 + δ)μ = 2. Since μ (cid:3) 2/(3em ), it holds that 1 + δ > 3em. We conclude that(cid:14)sc(x, f , u) (cid:2) 2Pr(cid:15)(cid:3)(cid:12)2(cid:11)1√3m= 19m.By the union bound the probability that some alternative in L is among the winners is at most (1/9m) · m + 1/2 = 11/18.∗, u)(cid:15) is at most 1/2. Next we considerCase 3: sw(xsome alternative x ∈ L. We apply (2) to the random variable sc(x, f , u) with expectation μ = sw(x, u) using∗, u) (cid:2) 2. By Jogdeo and Samuels, the probability that sc(x∗, f , u) < (cid:14)sw(x(1 + δ)μ =(cid:16)sw(cid:7)∗x(cid:8)(cid:17), u.Sinceμ <∗, u)sw(x√m3eit holds that 1 + δ > 2e∗, u)(cid:15)(cid:14)sw(x√m2e,(cid:3)√m. We conclude that(cid:12)(cid:14)sw(x∗,u)(cid:15)(cid:11)(cid:14)sc(x, f , u) (cid:2) 2Pr(cid:15)(cid:3)1√(cid:11)(cid:3)1√(cid:12)2= 14m.mSimilarly to Case 2, we apply the union bound and conclude that the probability that sc(x, f , u) (cid:2) sc(xm22∗, f , u) for somex ∈ L is at most (1/4m) · m + 1/2 = 3/4.Proof of Part 3. Given u ∈ U n we consider the alternative x√set of alternatives with social welfare at most sw(xthere exists x ∈ L such that sc(x, f , u) (cid:2) sc(xeither∗ ∈ A with the maximum social welfare. Denote by L ⊂ A thesw(x∗, u) ln n. We will show that the probability that2 +∗, f , u) is at most m/n. Specifically, we will establish that the probability that∗, u) − (5 )√√(cid:7)(cid:8), f , u∗xsc(cid:7)(cid:8), u∗x−(cid:3) sw(cid:7)2 sw(cid:8)x∗, uln n(cid:13)∗, f , u) with δ =(cid:20)(2 ln n)/(sw(x∗, u)). Since the expectation of∗x(cid:3) 1nNext we consider an alternative x ∈ L and the random variable sc(x, f , u). This variable has expectation μ < sw(x2 +sw(x∗, u) ln n. We apply the upper tail Chernoff bound with δ such that2 sw5 )−√√.√(∗, u) −or(cid:7)sc(x, f , u) (cid:2) sw∗x(cid:8), u−(cid:13)(cid:7)2 sw(cid:8)x∗, uln nfor some x ∈ L is at most m/n.sc(xWe first apply bound (1) to the random variable sc(x∗, f , u) is sw(x(cid:7)∗, u) we have that(cid:7)(cid:8)(cid:3) sw, f , u(cid:8)x∗, u(cid:14)scPr(cid:8), uln n∗x(cid:13)(cid:7)(cid:15)(cid:7)(1 + δ)μ = sw√(cid:13)(cid:8), u∗x−(cid:7)(cid:8)x∗, uln n.2 swClearly, δμ >5 sw(x∗, u) ln n. If δ (cid:2) 2e − 1, Eq. (3) yields(cid:13)(cid:14)sc(x, f , u) (cid:2) swPr(cid:7)∗x(cid:8), u−2 sw(cid:7)(cid:8)x∗, u(cid:15)ln n(cid:3) 2−(sw(x∗,u)−√2 sw(x∗,u) ln n ) (cid:3) 2−(16−4√2 ) ln n (cid:3) 1n1662I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–1671where the second inequality follows from the fact that sw(xn/m > 16 ln n.If δ < 2e − 1, Eq. (4) yields(cid:14)sc(x, f , u) (cid:2) swPr(cid:7)∗x(cid:8), u−(cid:13)(cid:7)2 sw(cid:8)x∗, uln n(cid:15)(cid:3) exp(cid:11)− (δμ)25μ(cid:12)(cid:11)< exp− sw(x∗, u) ln nμ(cid:12)(cid:3) 1n.∗, u) (cid:2) n/m and since the assumption (cid:4)(n, m) < 1 implies thatBy the union bound, we have that the probability that some of the undesired events happen is at most m/n (there are atmost m such events). Hence, with probability at least 1 − m/n some alternative x ∈ A \ L is the winner, and the expectedscore of the worst winner is at least(cid:7)(cid:7)sw∗x(cid:8), u√− (2 +√5 )sw(cid:13)(cid:8)ln n(cid:7)(cid:8)x∗, u(cid:21)(cid:11)(cid:12)1 − mn(cid:12)(cid:11)(cid:11)(cid:11)(cid:7)(cid:8), u∗x= sw(cid:7)(cid:2) sw∗x(cid:8), u(cid:7)(cid:2) sw∗x(cid:8), u(cid:7)(cid:2) sw∗x(cid:8), u√1 − (2 +√√5 )(cid:22)ln nsw(x∗, u)(cid:12)(cid:11)m ln n√1 − ((cid:11)(cid:11)1 −(cid:11)(cid:22)1 − 42 +5 )√√2 +m ln n5 + 14(cid:12)n(cid:12)(cid:22)1 −(cid:12)m ln nn(cid:7)∗x= sw(cid:8)(cid:7), un(cid:8)1 − (cid:4)(n, m).(cid:12)1 − mn(cid:22)(cid:12)m ln n16nThe second transition holds since n (cid:2) 3 together with (cid:4)(n, m) < 1 imply that(cid:22)(cid:22)(cid:3)mnm(cid:3)16n ln nm ln n16nand, furthermore, sw(xα, β ∈ [0, 1]. (cid:2)∗, u) (cid:2) n/m. The third transition follows from the inequality (1 − α)(1 − β) (cid:2) (1 − α − β) for anyOur final result regarding embeddings into Plurality asserts that the upper bound of O(m ) for the case of n = m, whichfollows from Part 2 of Theorem 4, is almost tight. This case is especially interesting since for slightly larger values of n thedistortion is constant.√Theorem 6. Let |N| = n = m = | A|, and denote Embedding 1 by f . Then dist( f ) = Ω((cid:13)mln m ).Proof. The main idea is the construction of a utility profile with “heavy” (high social welfare) alternatives and “light” (lowsocial welfare) alternatives; the heavy alternatives have social welfare and score of exactly two, whereas the light alterna-tives have low social welfare and expected score. However, since there are many light alternatives, with high probability atleast one such alternative has a score of two.Formally, let t, λ, and k be integers to be defined later. Consider an instance with N = N(cid:12) ∪ A(cid:12)(cid:12)| = λ (i.e., n = t + λ). Furthermore, let A = A(cid:12)(cid:12)|Nthat m = n, which implies that m = λ(k − 1). We construct a utility profile u ∈ U n as follows. Each x ∈ A1 with respect to the utility functions of exactly two agents in N1/k with respect to the utility functions of exactly two of the agents in N(cid:12)| = t and(cid:12)(cid:12)(cid:12)(cid:12)| = kλ/2 (i.e., m = t/2 + kλ/2). It also holdshas utility equal tohas utility(cid:12)(cid:12), sw(x, u) = 2. Each x ∈ A, sw(x, u) = 2/k., that is, for all x ∈ A(cid:12)(cid:12)(cid:12)| = t/2 and | A, where |N, where | A(cid:12) ∪ N(cid:12)(cid:12)(cid:12)(cid:12)(cid:12), hence for all x ∈ Ak2 . Moreover, the probability that sc(x, f , u) < 2k2 . Therefore (by an implicit applicationThe probability that an alternative x ∈ A(cid:12)(cid:12)given that a subset other alternatives in Aof the chain rule) the probability that no x ∈ A(cid:12)(cid:12)satisfies sc(x, f , u) < 2 is 1 − 1have score less than two is at most 1 − 1(cid:12)(cid:12)has score two is at most(cid:12)kλ/2(cid:11)1 − 1k2(cid:3) exp(cid:11)− λ2k(cid:12).Selecting λ = 2(cid:9)k ln k(cid:10), we have that the probability that no alternative in Athe distortion is at least(cid:12)(cid:12)has score two is at most 1/k. It follows that2· (1 − 1+ 2k )k(cid:2) k2.2 · 1kClearly m = O(k2 ln k) and, hence, the bound on the distortion follows. (cid:2)I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–167116633. Embeddings into ApprovalUnder the Approval rule, each agent approves a subset of the alternatives. Each approved alternative receives one point.The set of winners includes the alternatives with most points, summed over all the agents.We must reformulate some of our definitions in order to apply our notions to Approval voting. A deterministic embeddinginto Approval is a function f : U → 2 A , where 2 A is the powerset of alternatives. In words, an agent with a utility functionu approves each of the alternatives in f (u). The (Approval) score of an alternative is redefined to besc(x, f , u) =(cid:4)(cid:5)(cid:4)i ∈ N: x ∈ f (ui)(cid:6)(cid:4)(cid:4).A randomized embedding is a function f : U → (cid:3)(2 A). The rest of the definitions (in particular, the definition of distortion)are the same as before.3.1. Deterministic embeddingsIn Section 2 we have seen that no deterministic embedding into Plurality can achieve distortion better than Ω(m2) (The-orem 2). As it turns out, better results can be achieved with respect to Approval. Indeed, consider the following Embedding.Embedding 2 (Deterministic embedding into Approval). Given a utility function u, approve the subset of alternatives x ∈ A suchthat u(x) (cid:2) 1/m.The following straightforward result establishes that the distortion of this embedding is O(m).Theorem 7. Let |N| = n, | A| = m, and denote Embedding 2 by f . Then dist( f ) (cid:3) 2m − 1.Proof. Let u be a utility profile. Let x ∈ win( f , u) be a winning alternative, and let x∗the social welfare. Alternative xrespect to sc(x∗) < 1/m with respect to n − sc(x∗, f , u) agents. Hence,has ui(x∗ ∈ A be an alternative which maximizes∗, f , u) agents i, and has utility at most one with(cid:7)(cid:8), u∗xsw(cid:7)∗x< sc(cid:7)(cid:7)n − sc∗x+(cid:8)(cid:8), f , u· 1m(cid:12)(cid:7)(cid:8), f , u∗x· sc(cid:8), f , u(cid:11)1 − 1m(cid:12)+= nm(cid:11)2 − 1m(cid:3)· sc(x, f , u) (cid:3) (2m − 1) · sw(x, u).∗, f , u) (cid:3) sc(x, f , u)) and also has score at leastThe third transition holds since x is a winning alternative (and, hence, sc(xn/m (since, by the definition of the embedding, at least one alternative is approved by each agent). The last transitionfollows from the definition of the embedding, which implies that sc(x, f , u) (cid:3) m · sw(x, u). (cid:2)Unfortunately, it is impossible to design low-distortion deterministic embeddings into Approval. In fact, the followingtheorem asserts that the simple Embedding 2 is asymptotically optimal.Theorem 8. Let |N| = n (cid:2) 2, | A| = m (cid:2) 3, and let f : U → 2 A be a deterministic embedding into Approval. Then dist( f ) (cid:2) (m − 1)/2.Proof. Let f be a deterministic embedding into Approval. Consider the utility function u1 ∈ U where u1(a) = 0, u1(x) =∗ ∈ A \ {a}, otherwise1/(m − 1) for all x ∈ A \ {a}. We can assume that f (u1) does not approve a and approves at least one xwe get infinite distortion by considering the utility profile where ui ≡ u1 for all i ∈ N. Without loss of generality f (u1)approves b ∈ A \ {a}.Now, let u2 ∈ U be defined by u2(a) = 1, u2(x) = 0 for all x ∈ A \ {a} (in particular, u2(b) = 0). We define a utilityprofile u ∈ U n by setting ui ≡ u1 for (cid:9)n/2(cid:10) agents i, and ui ≡ u2 for (cid:14)n/2(cid:15) agents i. By the argument above it holds thatb ∈ win( f , u), but (using the assumption on the size of n and m) it holds thatdist( f , u) (cid:2) sw(b, u)sw(a, u)(cid:2) m − 12.We conclude that dist( f ) (cid:2) (m − 1)/2. (cid:2)1664I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–16713.2. Randomized embeddingsIn the context of deterministic embeddings, we have seen that there is a gap between the distortion of embeddings intoApproval and embeddings into Plurality. It turns out that there is also a huge gap with respect to randomized embeddings,when the number of agents is very small.Indeed, consider the randomized embedding finto Approval that, with probability 1/2, approves an alternative withmaximum utility, and with probability 1/2 approves all the alternatives. Further, assume that N = {1, 2}, and let u ∈ U 2.∗) (cid:2) ui(x) for all x ∈ A and all i ∈ N. Then clearly, for everyWithout loss of generality there exists x∗} with probability at least 1/4. Hence, the distortionx ∈ A, sw(x, u) (cid:3) 2 · sw(xof this embedding is at most eight, i.e., constant. This reasoning can easily be extended to obtain constant distortion withrespect to any constant n. Compare this result with Theorem 3.∗, u). Moreover, it holds that win( f , u) = {x∗ ∈ A such that u1(xHowever, as before, we are mostly interested in the case of a large number of agents. Crucially, every embedding intoPlurality can also be seen as an embedding into Approval, where for every utility function exactly one alternative is ap-proved. Hence, the powerful positive result regarding Embedding 1, namely Theorem 4, also holds with respect to Approval.It is natural to consider the following embedding into Approval.Embedding 3 (Naïve randomized embedding into Approval). Given a utility profile u ∈ U n, independently approve each alter-native x ∈ A with probability u(x).So, in contrast to Embedding 1 into Plurality, under Embedding 3 multiple alternatives can be approved. However, theexpected score of an alternative under both embeddings is identical. This implies (not directly) that Theorem 4, and eventhe lower bound given in Theorem 6, apply to Embedding 3 as well.It remains open whether there is a gap in the distortion of randomized embeddings into Plurality and randomized em-beddings into Approval when n (cid:2) m. Interestingly enough, the lower bound of Ω(m/ ln m ) for n = m (Theorem 6) alsoholds with respect to some natural embeddings into Approval which may approve multiple alternatives, such as Embed-ding 4 that is considered in the next section.(cid:20)4. Experimental resultsIn this section, we present experimental results concerning representative randomized embeddings into Plurality andApproval. Our aim is to shed some light on the enigmatic case in which the number of agents is smaller than the numberof alternatives. The main message from our experiments is that efficiency with respect to the distortion can be obtained byrandomized embeddings in this case as well. Recall that our positive result (Theorem 4) does not apply to this case.We remark that, since the definition of distortion involves all utility profiles with specific numbers of agents and alterna-tives as well as the expectation of the social welfare of the winning alternative, we should not expect its exact measurementin our experiments. Instead, we will approximate the distortion of embeddings by considering many utility profiles that areproduced according to carefully selected probability distributions, which can serve as strong adversaries for our embeddings,and by considering the execution of the embeddings many times on each utility profile. Our experimental setting also al-lows us to make interesting observations about the efficiency of embeddings on particular probability distributions of utilityprofiles; in this context, we will examine distortion measurements that deviate from the standard definition of distortion(see below) and are specific to particular probability distributions.In more detail, we consider utility profiles that are produced randomly according to a family of different probabilitydistributions. The probability distributions are defined as follows for values of parameter τ in [1, +∞).τ -biased probability distributions. A specific alternative x is identified. For each agent, we pick a random value in therange [0, 1] for each alternative. We multiply the value corresponding to the specific alternative x by τ . These values arethen normalized (so that their sum is unity) in order to compute the utility function of the agent over the alternatives.We use the term τ -biased utility profiles to refer to utility profiles that are produced randomly according to the τ -biasedprobability distribution. Such utility profiles have the following properties:• The expected social welfare of all alternatives except x is the same.• The expected social welfare of alternative x is τ times the expected social welfare of any other alternative.The rationale behind the selection of these probability distributions is that they can challenge our embeddings (byproducing utility profiles that are difficult to handle efficiently) and reveal empirical statements of some generality abouttheir distortion. Intuitively, the social welfare of an alternative will be concentrated around its expectation. In the extremecase of τ -biased profiles for high values of τ , most agents will also have a high utility for a particular alternative (i.e.,alternative x). This alternative probably has the highest social welfare and should be the winner in any low-distortionembedding. Indeed, our experimental results will verify this observation. On the other hand, in τ -biased utility profilesI. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–16711665for small values of τ , it may not be apparent that the alternative with the highest social welfare is the one that wouldbe selected by the voting rule; recall that the number of alternatives is large, the randomized embeddings make randomchoices and, furthermore, the number of agents is small. The ability of our embeddings to identify alternatives with highsocial welfare (for different values of τ ) will reflect their efficiency in terms of the distortion.In the experiments presented below we have run Embedding 1 into Plurality on τ -biased utility profiles. We have alsoconsidered the following embedding into Approval which tries to exploit the extra flexibility Approval provides by allowingeach agent to approve any number of alternatives.Embedding 4. For any agent, pick a value in [0, 1] uniformly at random and approve all alternatives (if any) that have utilityhigher than this value.We remark that Embedding 3 could be a natural embedding to consider here but, not surprisingly, the results obtainedare similar to those of Embedding 1. Our upper bound analysis (i.e., the statement and proof of Theorem 4) can be easilyseen to extend to Embedding 4 as well but it does not capture the case in which the number of agents is smaller than thenumber alternatives.In our experiments, the distortion at a utility profile is computed using Definition 1.2 as the average social welfare of thewinner after 1000 executions of the randomized embedding over the maximum social welfare among all alternatives in theparticular profile. Ties among different winning alternatives are broken in favor of the alternative with the minimum socialwelfare as Definition 1.2 suggests. The results from a representative set of experiments are depicted in Fig. 1. The four plotscontain results from the application of Embeddings 1 and 4 on τ -biased utility profiles (for values of τ that are powers of 2and lie between 1 and 128) with 64 or 128 alternatives and 8 or 16 agents. Here, we have used a distortion measure that isspecific to τ -biased utility profiles for a given value of τ and particular numbers of agents and alternatives. More precisely,for each point in the four plots of Fig. 1, the distortion value was computed as the maximum distortion in 1000 differentτ -biased utility profiles. This gives us a more refined measure of the efficiency of randomized embeddings as a function ofthe values of τ .The results provide information the theoretical analysis cannot provide unless it becomes very detailed and adapted tothe particular probability distributions. In all experiments we have performed with Embedding 1 for Plurality, the distortionis non-monotonic with respect to τ . There exists a particular value (or range of values) of τ for which the distortion ismaximized (see Fig. 1). The low-distortion values for high values of τ can be easily explained. According to the definitionof τ -biased utility profiles, many agents are expected to have a significantly higher utility for the particular alternative x.Consequently, Embedding 1 will translate such utilities into a vote for alternative x, and hence x is often selected. For smallvalues of τ , the social welfare of the alternatives is around the (same, more or less) expectation, and Embedding 1 computesa winner with social welfare that is not far from the maximum one. τ -biased utility profiles for intermediate values of τare the most difficult to handle. However, in all cases the distortion is relatively low.Interestingly, the experimental results indicate that the behavior of Embedding 4 on τ -biased utility profiles is different.Our observation for Embedding 1 for high values of τ applies to Embedding 4 as well. On the other hand, Embedding 4seems to have its highest distortion for small values of τ (unlike Embedding 1, which efficiently handles such utility pro-files). This is due to the fact that, by its definition, Embedding 4 cannot help an agent distinguish between alternatives thathave comparable utility since (unlike Embedding 1) it may translate the utility function of an agents to approvals for all suchalternatives. This effect almost vanishes as τ increases and, for most values of the parameter τ , Embedding 4 significantlyoutperforms Embedding 1, quickly reaching optimal distortion. This last phenomenon is more apparent when the numberof agents is large (compare Figs. 1(c) and 1(d) with Figs. 1(a) and 1(b), respectively) and implies that the extra flexibility ofEmbedding 4 is beneficial in this case.A summary of the results of our experiments with profiles with 64 or 128 alternatives and a number of agents that is apower of 2 between 2 and 64 or 128, respectively, is depicted in the two plots of Fig. 2. These results are similar in spirit toour upper bound statements (e.g., Theorem 4) in the sense that the distortion bounds are worst-case among utility profilesproduced according to different probability distributions. Each point in these plots represents the maximum distortionobserved in τ -biased profiles for all different values of τ that are powers of 2 with the particular number of agents andnumber of alternatives corresponding to the point. For example, the point of Fig. 2(b) that corresponds to the execution ofEmbedding 1 with 16 agents has a distortion value equal to the maximum (i.e., 4.73) among the eight distortion values forthis embedding in Fig. 1(d) (that is obtained for τ = 8). So, the distortion value at each point in the plots of Fig. 2 is themaximum distortion observed in 8000 different utility profiles. The remaining points have been produced by running thetwo embeddings in utility profiles with appropriate parameters.The results suggest a threshold behavior with respect to the relative performance of the two embeddings: Embedding 1outperforms Embedding 4 in profiles with small number of agents, whereas the opposite is true when the number of agentsis high. The transition takes place when the number of agents goes from 8 to 16 and pinpoints the threshold at which theextra flexibility that Approval provides (and Embedding 4 exploits) becomes beneficial. Alternatively, this transition in thebehavior of Embeddings 1 and 4 can be observed by examining the maximum distortion (over all values of τ ) of eachembedding in the four plots of Fig. 1 (and can be explained by the discussion on the behavior of Embedding 4 above).However, in general, the results indicate that, at least for the particular family of probability distributions of utility profiles,the distortion of both embeddings is O (m/n). This claim is supported by the 13 pairs of points depicted in Fig. 2 as well as1666I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–1671Fig. 1. Experiments in profiles with 64 or 128 alternatives and 8 or 16 agents. The distortion is a function of parameter τ which takes as values the powersof 2 from 1 to 128. Note that the scale of the x-axis is logarithmic.by other experiments on utility profiles with intermediate numbers of alternatives and agents that are not reported here.This bound matches asymptotically the theoretical lower bound of Theorem 3 and is superior to the theoretical upper boundof Theorem 4 (for n = m). The latter is to be expected since the lower bound construction used in the proof of Theorem 3is unlikely to be produced by the τ -biased probability distributions.5. Embeddings into VetoUnder the Veto rule, each agent vetoes a single (presumably least preferred) alternative. The set of winners includes allthe alternatives that are vetoed the least number of times. Equivalently, each agent awards one point to all the alternativesexcept one, and the alternatives with most points are the winners.The Veto rule can be interpreted as a scoring rule. Such a rule is defined by a vector of real numbers (α1, α2, . . . , αm)with α1 = 1 (cid:2) α2 (cid:2) · · · (cid:2) αm−1 (cid:2) αm = 0. Let L( A) denote the set of rankings over A. The vote of each agent is an elementof L( A). The number of points awarded by an agent to the alternative ranked in the kth position is αk. Veto then is thescoring rule defined by (1, . . . , 1, 0). Plurality is the scoring rule defined by (1, 0, . . . , 0).I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–16711667Fig. 2. Summary of experiments in profiles with 64 or 128 alternatives. The distortion is a function of the number of agents (which takes as values thepowers of 2 from 2 to the number of alternatives). Note that the scale in both axes is logarithmic.In this section we are mostly interested in the Veto rule, due to its low communication costs (log m bits per agent).However, one can think of other scoring rules with low communication costs, e.g., 2-approval defined by (1, 1, 0, . . . , 0) or2-antiapproval defined by (1, . . . , 1, 0, 0). Hence, we will formulate some of our results for scoring rules in general. Notethat a deterministic embedding into a scoring rule R is a function f : U → L( A), whereas a randomized embedding is afunction f : U → (cid:3)(L( A)).5.1. Deterministic embeddingsThe Plurality and Veto rules are closely related in the sense that agents must award an equal number of points toalmost all alternatives, and therefore cannot make a distinction in their votes between very desirable and very undesirablealternatives. However, this turns out to be a more acute problem under Veto, since agents cannot even single out one goodalternative. The following definition allows us to quantify this property.Definition 9. Let R be a scoring rule with score vector (α1, α2, . . . , αm) over m alternatives with 1 = α1 (cid:2) α2 (cid:2) · · · (cid:2) αm−1 (cid:2)αm = 0. The decisiveness dR of R is defined as dR = m −mi=1 αi .(cid:2)Observe that the decisiveness of a scoring rule lies between 1 (for Veto) to m − 1 (for Plurality). Procaccia and Rosen-schein [13] (implicitly) relate the distortion of the naïve deterministic embedding to decisiveness. The naïve deterministicembedding simply computes a non-increasing ordering of the alternatives with respect to their utilities, breaking ties amongthe alternatives according to a predefined rule (e.g., lexicographically).Theorem 10. (See Procaccia and Rosenschein [13].) The naïve deterministic embedding into a scoring rule R with decisiveness at mostm − 2 has infinite distortion.We can extend the above impossibility result to any deterministic embedding.Theorem 11. Let |N| = n (cid:2) 1 and | A| = m (cid:2) 3, and let f : U → A be a deterministic embedding into a scoring rule with α1 = α2.Then dist( f ) = ∞.Proof. Let a ∈ A and u be a utility profile such that for all i ∈ N, ui(a) = 1, and ui(x) = 0 for all x ∈ A \ {a}. Let f be anembedding into a scoring rule with α1 = α2 = 1. Let y ∈ A \ {a} that is ranked in one of the first two positions of theranking f (u). Then, y has a score of n and, hence, y ∈ win( f , u). Since sw(a, u) = n and sw( y, u) = 0, it follows that thedistortion of fis infinite. (cid:2)It follows that for all the scoring protocols that could be of interest due to their low communication requirements,deterministic embeddings have infinite distortion.1668I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–16715.2. Randomized embeddingsFirst, observe that if n < m − 1, then any randomized embedding into Veto has infinite distortion, for reasons similar to∗ ∈ A and 0 for the remainingthe deterministic case (Theorem 11). Indeed, consider n agents with utility 1 for alternative xm − 1 alternatives. At least one of these m − 1 alternatives is not vetoed, and hence it is included in the set of winners.However, for larger values of n it is possible to obtain positive results; we consider the following embedding into any scoringrule.Embedding 5 (Randomized embedding into scoring rules). Given a utility function u ∈ U , select an alternative x ∈ A withprobability u(x) to be ranked first; denote the selected alternative by x. Now, complete the ranking at positions 2, . . . , mby selecting a random permutation among the alternatives in A \ {x∗}.∗For Veto Embedding 5 reduces to the following scheme. As in the general embedding, select an alternative x ∈ A with. Now, the vetoed alternative f (u) is selected uniformly at ran-∗} is selected with probability 1/(m − 1)). Interestingly, for Plurality∗} (that is, each alternative in A \ {xprobability u(x), and denote the selected alternative by xdom from A \ {xEmbedding 5 reduces to Embedding 1.∗We have the following upper bound on the distortion of Embedding 5.Theorem 12. Let |N| = n (cid:2) m = | A|, n (cid:2) 3, and denote by f the Embedding 5 to a scoring rule R with decisiveness dR ∈ [1, m − 1].Furthermore, let(cid:22)(cid:4)(n, m) = 2m(m − 1)dRln nn.If (cid:4)(n, m) < 1, then dist( f ) (cid:3)11−(cid:4)(n,m) .The proof of this theorem is along similar lines to the proof of Part 3 of Theorem 4. The main difference is that, insteadof using Lemma 5 which applies to sums of Bernoulli trials, we now have to use a more general inequality due to Hoeffding[8] which applies to sums of independent heterogeneous random variables (taking values in the range [0, 1]). We note that,since this inequality is more general, it yields a weaker bound for Plurality than the one obtained in Part 3 of Theorem 4.Lemma 13. (See Hoeffding [8].) Let X1, . . . , Xn be independent heterogeneous random variables with Xi ∈ [0, 1]. Denote by μ theexpectation of the random variable X =(cid:2)i Xi . Then for any λ > 0,Pr[| X − μ| (cid:2) λ] (cid:3) exp(cid:11)(cid:12).− 2λ2nProof of Theorem 12. Let λ = 12by L the set of alternatives with social welfare less than sw(x∗n ln n. Given u ∈ U n, consider the alternative x∗, u) − 2λ m−1dR. We will show that the probability that eitherwith maximum social welfare and denote√(cid:7)(cid:8), f , u∗xsc(cid:14)(cid:7)sc∗x(cid:3) E(cid:8)(cid:15), f , u− λorsc(x, f , u) (cid:2) E(cid:7)(cid:14)sc∗x(cid:8)(cid:15)− λ, f , u√for some x ∈ L is at most m/n.Using the Hoeffding bound for the random variable sc(x(cid:7)(cid:14)scPr∗x(cid:8), f , u(cid:14)(cid:7)sc∗x(cid:3) E(cid:8)(cid:15), f , u(cid:15)(cid:14)(cid:4)(cid:4)sc(cid:3) Pr(cid:7)∗x− λ∗, f , u), we have(cid:14)sc− E(cid:8), f , u∗x(cid:7)(cid:8)(cid:15)(cid:4)(cid:4) (cid:2) λ, f , u(cid:15)(cid:3) exp(cid:12)(cid:11)− 2λ2n= 1√n.Now, observe that for any x ∈ A and i ∈ N, the score x receives from agent i when applying f on the utility profile ui isα1 = 1 with probability ui(x) and α j with probability 1−ui (x)m−1(cid:24)for j = 2, . . . , m. Hence,(cid:23)(cid:15)(cid:14)sc(x, f , u)E==(cid:3)i∈N(cid:3)(cid:11)i∈Nui(x) · 1 +m(cid:3)j=21 − ui(x)m − 1· α jui(x) +(cid:7)1 − ui(x)(cid:8) m − dR − 1m − 1(cid:12)= m − dR − 1m − 1n + dRm − 1sw(x, u).I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–16711669Therefore for every alternative x ∈ L it holds that(cid:14)(cid:7)sc∗xE(cid:8)(cid:15), f , un + dR− λ = m − dR − 1m − 1(cid:2) m − dR − 1n + dRm − 1(cid:14)(cid:15)sc(x, f , u)+ λ.= Em − 1m − 1(cid:7)(cid:8), u∗xsw− λsw(x, u) + λUsing this last observation and the Hoeffding bound for the random variable sc(x, f , u), we have(cid:14)(cid:3) Pr(cid:15)sc(x, f , u)∗x(cid:8)(cid:15)(cid:7)(cid:15)(cid:14)(cid:14)sc(x, f , u) (cid:2) EPr(cid:2) E(cid:14)(cid:14)sc(x, f , u)(cid:15)(cid:4)(cid:4) (cid:2) λ(cid:15)By the union bound the probability that some of the undesirable events happen is at most m/n. Hence, with probabilityn there is no x ∈ L among the winners. We conclude that the expected social welfare of the worst winner√√− λ(cid:15), f , uscsc(x, f , u) + λ(cid:14)(cid:4)(cid:4)sc(x, f , u) − E(cid:12)(cid:11)− 2λ2n(cid:3) Pr(cid:3) exp= 1√n.at least 1 − m/is at least(cid:11)(cid:7)sw∗x(cid:8), u− 2λ(m − 1)dR(cid:12)(cid:11)1 − m√n(cid:12)(cid:11)(cid:12)(cid:12)(cid:12)(cid:11)1 − m√n1 − m√n(cid:12)(cid:11)(cid:7)(cid:8), u∗x= sw√1 − (m − 1)n ln ndR · sw(x∗, u)ln n(cid:22)(cid:7)(cid:2) sw∗x(cid:8), u(cid:7)(cid:2) sw∗x(cid:8), u(cid:7)(cid:2) sw∗x(cid:8), u(cid:7)∗x= sw, u(cid:8)(cid:7)(cid:11)1 − m(m − 1)dR(cid:11)1 − m(m − 1)dR(cid:11)1 − 2m(m − 1)dR(cid:8)1 − (cid:4)(n, m).(cid:22)nln n(cid:12)2(cid:12)n(cid:22)ln nn∗, u) (cid:2) n/m, the third transition easilyThe first transition follows by substituting λ, the second transition holds since sw(xfollows by the condition on (cid:4)(n, m) using n (cid:2) 3, and the fourth transition follows from (1 − α)2 (cid:2) 1 − 2α. This concludesthe theorem’s proof. (cid:2)As corollaries, we have that if n/ ln n (cid:2) 16m2(m − 1)2, then the distortion of Embedding 5 into Veto is at most two. Inaddition, for instances with (cid:4)(n, m) = o(1), the distortion is at most 1 + o(1).When n is not much larger than m we can show an exponential lower bound on the distortion of Embedding 5 into Vetoby exploiting the relation to the well-known coupon collector problem (see, e.g., [11]). Indeed, consider an instance with n∗and 0 for all other alternatives. Then, our embedding into Veto shouldagents with utility 1 for a particular alternative x∗the one that will not get score 1 (i.e., the one that will be rankedselect equiprobably among all alternatives besides xwas ranked last in the preferences of some agent is thelast). Hence, the question of whether every alternative besides xsame as the question of whether all m − 1 coupons will be randomly selected after n trials. When n = (m − 1) ln(m − 1)/2the probability that this happens is exponentially low (i.e., O (exp(−n ))) and, therefore, the expected social welfare of√the alternative to be selected will be at most O (exp(−n )). More generally wehave the following theorem. Note that, in order to keep the exposition simple, we assume that f simply returns the vetoedalternative (as opposed to a ranking of all the alternatives).n )) and the distortion at least Ω(exp(√√∗Theorem 14. Let n = |N| (cid:2) | A| = m, and let f : U → (cid:3)( A) be a randomized embedding into Veto. Then dist( f ) = Ω(m/√n ).Proof. Let f be a randomized embedding into Veto. Let N = Nlater. We define a utility profile u ∈ U n as follows. For all i ∈ Nutility 1/m for each alternative. Let xthis utility profile, i.e., for all i ∈ N(cid:12)(cid:12)| = λ, with λ to be definedhave∗ ∈ A be the alternative that has the highest probability of being vetoed under f given(cid:12)(cid:12)and x ∈ A, ui(x) = 1/m, that is, all the agents in N(cid:12)| = n − λ and |N, where |N(cid:12) ∪ N(cid:12),(cid:12)(cid:12)(cid:14)Pr∗f (ui) = x(cid:15)(cid:14)(cid:2) Pr(cid:15)f (ui) = x.(6)1670I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–1671Furthermore, for all i ∈ Nsw(x, u) = (n − λ)/m for all x ∈ A \ {xwe have ui(x∗}.(cid:12)(cid:12)∗) = 1, ui(x) = 0 for all x ∈ A \ {x∗}. Note that sw(x∗, u) = λ + (n − λ)/m, whereas(cid:12)It follows from Eq. (6) that the probability that xis among the λ + 1 alternatives that are vetoed least by the agentsis at most (λ + 1)/m. Therefore with probability at least 1 − (λ + 1)/m there are λ + 1 alternatives that are vetoedas there are only λ such, and at least one of them is not vetoed by the agents in N(cid:12)(cid:12)in N∗at most as many times as xagents. We conclude that the distortion of fby N(cid:12)is at least∗dist( f , u) (cid:2)λ + n−λm ) + (1 − λ+1n ), we get that dist( f ) (cid:2) Ω(m/· (λ + n−λλ+1mmm ) · n−λ√mn ). (cid:2)=√Taking λ = Θ(λ + n−λmλ+1m· λ + n−λm.Theorem 14 provides a necessary condition n = Ω(m2) in order to obtain constant distortion into Veto, whereas Em-bedding 1 yields a constant upper bound when n = Θ(m ln m) with respect to Plurality and Approval. Hence, randomizedembeddings into Veto are provably less efficient even when the number of agents is larger than the number of alternatives.6. DiscussionIn this section we discuss a few prominent issues.6.1. On the interpretation of our resultsInterestingly, our technical results deal with embeddings into voting rules and are not directly related to communication,therefore the results may lend themselves to different interpretations.Procaccia and Rosenschein [13] motivate their work by arguing that in some systems voting must be used since utilitiescannot be calculated or cannot be compared, even though exact and comparable utilities conceivably exist. This situationis less common in systems that are populated entirely by computational agents (although bounded rationality may be anissue), and more common in systems that also involve humans. Procaccia and Rosenschein do assume that the agents rankthe alternatives according to decreasing utility, but this does not require calculating the exact utilities.In contrast, the randomized embeddings introduced in this paper require the computation of exact utilities. So, we aredealing with systems (that are presumably populated solely by computational agents) where one could potentially gatherexact utilities and select the best alternative. One possible interpretation of our results is that they can be used to improvethe performance of systems that, by design, are unnecessarily constrained to use voting when utilities could have beenreported, but this is not an approach we wish to advocate. We feel that our interpretation in terms of communicationreduction, as presented in the introduction, provides a robust motivation that ties in closely to the results.6.2. Relation to work on compact preferencesA significant body of work in AI is devoted to compactly representing preferences. A prominent example is the work onCP-nets [2], a graphical representation of preferences that employs conditional ceteris paribus (all else being equal) prefer-ence statements. This representation is often compact and admits efficient algorithms for different inference tasks. Anotherexample is a recently proposed representation of utility functions using weighted propositional formulas [17]. By consider-ing different restrictions on the syntax of formulas and the weights one can obtain different representation languages, eachcapturing a different class of utility functions.This line of work proposes to reduce communication and computation burdens by making arguably natural assumptionsregarding the utility functions. In contrast, in this paper we impose no restrictions on the utility functions (with the ex-ception of the extremely weak normalization assumption, see below); rather, we reduce communication by slightly relaxingthe optimality of the outcome.6.3. Generality of normalized utilitiesIt is easy to see that very strong lower bounds would hold without assuming that the utilities are normalized. Weargue though that this assumption is essentially without loss of generality. Indeed, the setting we have in mind (which isconsistent with our motivation and examples) is one where all agents have equal weight in deciding the social quality ofalternatives, and are merely trying to evaluate which alternative is best for the system. For example, we are precluding asituation where one agent has utility one for x and zero for the rest, and a second agent has utility 1/2 for x and zero forthe rest: if both believe that x is the only reasonable alternative, they would both give that alternative their entire “poolof points”. In other words, the only real assumption is that agents have equal weight; normalized utilities logically follow.Note that a similar assumption is typically made in social choice contexts concerning the fair division of a good amongagents with cardinal utilities over parts of the good (see, e.g., [3]); it is assumed that the sum of an agent’s utilities forevery partition of the good is one.I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–167116716.4. Future workOur notion of embeddings into voting rules is extremely decentralized, that is, the agents cast their votes independentlyaccording to the embedding. On the other extreme, if full coordination is allowed, the distortion would always be one, asthe agents would be able to find out which alternative maximizes social welfare and coordinate their votes in a way thatthis alternative is elected (assuming the voting rule is onto the set of alternatives). It would be interesting to investigate anotion of embedding that allows for partial communication between the agents.Our strongest positive results hold in settings where the number of agents is larger than the number of alternatives. Thisis indeed the case in many environments, notably in political elections. However, one can think of a variety of multiagentsettings where the number of alternatives is larger. Our experimental results shed some light to the distortion of randomizedembeddings into Plurality and Approval in this case. In future work, we would like to achieve a better understanding of theachievable distortion when n = o(m).The results in this paper mainly concern three voting rules: Plurality, Approval, and Veto. Certainly, low distortion canalso be achieved using randomized embeddings into any scoring protocol as Theorem 12 indicates. Among others, thisincludes k-approval and k-antiapproval voting rules, according to which each agent approves or vetoes k alternatives, re-spectively; these voting rules require O (k log m) bits to be communicated by each agent and meet the low communicationrequirement when k is small. Furthermore, it includes the Borda rule which, in our context, can be defined as follows: eachagent awards 1 − k−1m−1 points to the alternative ranked in the kth position. Extending this line of work to other prominentvoting that either have low communication requirements, such as Plurality with Runoff or Single Transferable Vote [5], orare based on pairwise comparisons, such as Copeland or Maximin, could prove challenging but rewarding.Finally, it is interesting to think about maximizing social welfare via methods that require minimal communicationand are not necessarily constrained by voting rules. This question is related to work in the theory of computer sciencecommunity on streaming algorithms (see, e.g., [4,6]).References[1] L. Blumrosen, N. Nisan, I. Segal, Auctions with severely bounded communication, Journal of Artificial Intelligence Research 28 (2007) 233–266.[2] C. Boutilier, R.I. Brafman, C. Domshlak, H.H. Hoos, D. Poole, CP-nets: A tool for representing and reasoning with conditional ceteris paribus preferencestatements, Journal of Artificial Intelligence Research 21 (2004) 135–191.[3] S.J. Brams, A.D. Taylor, Fair Division: From Cake-Cutting to Dispute Resolution, Cambridge University Press, 1996.[4] M. Charikar, K. Chen, M. Farach-Colton, Finding frequent items in data streams, Theoretical Computer Science 312 (2004) 3–15.[5] V. Conitzer, T. Sandholm, Communication complexity of common voting rules, in: Proceedings of the 6th ACM Conference on Electronic Commerce(EC), 2005, pp. 78–87.[6] G. Cormode, S. Muthukrishnan, An improved data stream summary: the count-min sketch and its applications, Journal of Algorithms 55 (2005) 58–75.[7] S. Ghosh, M. Mundhe, K. Hernandez, S. Sen, Voting for movies: The anatomy of a recommender system, in: Proceedings of the 3rd Annual Conferenceon Autonomous Agents (AGENTS), 1999, pp. 434–435.[8] W. Hoeffding, Probability inequalities for sums of bounded random variables, Journal of the American Statistical Association 58 (301) (1963) 13–30.[9] K. Jogdeo, S. Samuels, Monotone convergence of binomial probabilities and a generalization of Ramanujan’s equation, Annals of Mathematical Statis-tics 39 (1968) 1191–1195.[10] J.W. Moon, Topics on Tournaments, Holt, Reinhart and Winston, 1968.[11] R. Motwani, P. Raghavan, Randomized Algorithms, Cambridge University Press, 1995.[12] D. Pennock, E. Horvitz, L. Giles, Social choice theory and recommender systems: Analysis of the axiomatic foundations of collaborative filtering, in:Proceedings of the 17th AAAI Conference on Artificial Intelligence (AAAI), 2000, pp. 729–734.[13] A.D. Procaccia, J.S. Rosenschein, The distortion of cardinal preferences in voting, in: Proceedings of the 10th International Workshop on CooperativeInformation Agents (CIA), in: Lecture Notes in Computer Science (LNCS), vol. 4149, Springer, 2006, pp. 317–331.[14] A.D. Procaccia, J.S. Rosenschein, G.A. Kaminka, On the robustness of preference aggregation in noisy environments, in: Proceedings of the 6th Interna-tional Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), 2007, pp. 416–422.[15] Ariel D. Procaccia, Computational voting theory: Of the agents, by the agents, for the agents, PhD thesis, The Hebrew University of Jerusalem, 2008.[16] G. Sigletos, G. Paliouras, C. Spyropoulos, M. Hatzopoulos, Combining information extractions systems using voting and stacked generalization, Journalof Machine Learning Research 6 (2005) 1751–1782.[17] J. Uckelman, Y. Chevaleyre, U. Endriss, J. Lang, Representing utility functions via weighted goals, Mathematical Logic Quarterly 55 (4) (2009) 341–361.