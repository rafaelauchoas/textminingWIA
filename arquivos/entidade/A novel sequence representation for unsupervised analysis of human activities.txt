Artificial Intelligence 173 (2009) 1221–1244Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA novel sequence representation for unsupervised analysis of humanactivitiesRaffay Hamid∗, Siddhartha Maddi, Amos Johnson, Aaron Bobick, Irfan Essa, Charles IsbellCollege of Computing, Georgia Institute of Technology – Atlanta, GA, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 30 October 2007Received in revised form 12 March 2009Accepted 25 May 2009Available online 30 May 2009Keywords:Temporal reasoningScene analysisComputer visionFormalizing computational models for everyday human activities remains an open chal-lenge. Many previous approaches towards this end assume prior knowledge about thestructure of activities, using which explicitly defined models are learned in a completelysupervised manner. For a majority of everyday environments however, the structure of thein situ activities is generally not known a priori. In this paper we investigate knowledgerepresentations and manipulation techniques that facilitate learning of human activities ina minimally supervised manner. The key contribution of this work is the idea that globalstructural information of human activities can be encoded using a subset of their localevent subsequences, and that this encoding is sufficient for activity-class discovery andclassification.In particular, we investigate modeling activity sequences in terms of their constituentsubsequences that we call event n-grams. Exploiting this representation, we propose acomputational framework to automatically discover the various activity-classes taking placein an environment. We model these activity-classes as maximally similar activity-cliques ina completely connected graph of activities, and describe how to discover them efficiently.Moreover, we propose methods for finding characterizations of these discovered classesfrom a holistic as well as a by-parts perspective. Using such characterizations, we presenta method to classify a new activity to one of the discovered activity-classes, and to auto-matically detect whether it is anomalous with respect to the general characteristics of itsmembership class. Our results show the efficacy of our approach in a variety of everydayenvironments.© 2009 Elsevier B.V. All rights reserved.1. IntroductionConsider a household kitchen where different activities, such as making omelets, washing dishes, or eating cereal etc.,can take place. Each one of these activities can be performed in many different ways. To build systems that can be proactiveand assistive in such environments, it is not plausible to learn each and every one of the in situ activities in a completelysupervised manner. We are therefore interested in knowledge representations and manipulation techniques that allow com-putational systems to analyze human activities with minimal supervision.The importance of these systems that can learn our everyday activities can be motivated by the variety of applicationsthat they promise to offer. For instance, they have the potential to help us monitor peoples’ health as they age, as well asin fighting crime through improved surveillance. Their medical applications include identifying and evaluating crucial parts* Corresponding author.E-mail addresses: raffay@cc.gatech.edu (R. Hamid), maddis@cc.gatech.edu (S. Maddi), amos@cc.gatech.edu (A. Johnson), afb@cc.gatech.edu (A. Bobick),irfan@cc.gatech.edu (I. Essa), isbell@cc.gatech.edu (C. Isbell).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.05.0021222R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244Fig. 1. Illustration of an example event. A person shown washing some dishes in the sink of a kitchen.of surgical procedures, and providing surgeons with useful feedback. Similarly, they can help us improve our productivity inoffice environments by detecting important events around us to enhance our involvement in various tasks.One of the key challenges in building such perceptual systems is the big gap that exists between the low level sensoryinputs such as pixel values or microphone voltages, and higher level inferences such as what dish is being prepared in akitchen, or whether someone forgot to add salt in it etc. A natural way to bridge this gap is to have a set of intermediatecharacterizations that can appropriately channel the low-level perceptual information all the way to higher level inferencestage. The granularity at which these intermediate characterizations should be defined presents a trade-off between howexpressive the characterizations are, versus the robustness with which they can be detected through low-level sensory data.In the following, we define a set of such intermediate characterizations that we shall use throughout this paper.1.1. Elements of activity dynamicsOne way of looking at everyday environments is in terms of a set of perceptually detectable key-objects [22]. A key-objectmay be defined as:Key-object: An object present in an environment that provides functionalities that may be required for the execution ofactivities of interest in that environment.We assume that a list of key-objects for an environment is known a priori. An illustrative figure showing a list of key-objects in a kitchen environment is shown in Fig. 1. Various operations on the key-objects can be used to define a set ofperceptually detectable activity-descriptors. We call these descriptors Events which are defined as:Event: A particular interaction among a subset of key-objects over a finite duration of time.Fig. 1 shows an example event of a person washing utensils in a sink.Event vocabulary: The set of interesting events that can take place in an environment.An event vocabulary for a household kitchen may consist of events like person opens the fridge door, person turns the stoveon, person turns the faucet on, etc. We assume that such an event vocabulary is known a priori.Activity: A finite sequence of events.To illustrate the notion of activities in an everyday environment, an example activity of making scrambled eggs is describedbelow:Make Scrambled Eggs= Enter Kitchen → Turn Stove On → Get Eggs → Fry Eggs →Turn Stove Off → Leave KitchenWe assume that the start and end events of activities are known a priori, and that every activity must be finished beforeanother is started, i.e. the question of overlapping activities is not included in our problem domain.R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12441223Fig. 2. General framework. 1. Starting with a corpus of activities, we extract their contiguous subsequences using some activity representation. 2. Based onthe frequential information of these subsequences, we define a notion of activity similarity and use it to automatically discover different activity-classes. 3.We characterize the discovered classes both at holistic and by-parts levels. 4. We classify a test activity to one of the discovered classes, and compare it tothe previous members of its membership class in order to detect anomalies.1.2. Main hypothesisWe want to learn everyday human activities using some activity representation that does not require us to manuallyencode the structural information of these activities in a completely supervised manner. By structural information of anactivity, we mean the various events constituting that activity, and the temporal order in which these constituent eventsare arranged. Our approach to this challenge is based on our hypothesis that we can learn the global structure of activitiessimply by using their local event subsequences. In particular, our main hypothesis states:Hypothesis statement: “The structure of activities can be encoded using a subset of their contiguous event subsequences, and thisencoding is sufficient for activity discovery and recognition”.At the heart of our hypothesis is the question whether we can have an appropriately descriptive yet robustly detectableevent vocabulary to describe human activities in a variety of everyday environments. Such intermediate sets of charac-terizations have been previously shown to exist for representing various temporal processes including speech [32], textdocuments [36], and protein sequences [4].We posit that the key-objects in everyday environments pose a set of spatial and temporal constraints on the way wegenerally execute our activities in these environments [22]. For instance, one has to open a fridge before one can get milkout of it. Similarly, one must turn a stove on before one can use it to fry eggs, etc. We believe that these constraintscan be used to construct a set of robustly detectable events that can appropriately describe the various activities takingplace in an environment. These events can channel the low-level information detected from the sensors, in a manner thatfacilitates making useful higher-level inferences. This idea of learning activity structure by using statistics of their local eventsubsequences is essential to move us away from the traditional grammar driven approaches for activity modeling, and adopta more data-driven perspective.1.3. Key contributionsThe main contribution of this work is a data-driven perspective towards activity analysis. We view this approach towardsautomatic analysis of human activities in four principled ways:1. Representation of activities in terms of their local event subsequences2. Discovery of the various activity-classes in an environment3. Characterization of the discovered activity-classes, and4. Detection of activities that deviate from characteristics of discovered classes.A brief description of these main contributions follows. A block diagram illustrating the general overview of our proposedframework is given in Fig. 2.1.3.1. Activity representationWe propose a novel activity representation that considers activities in terms of their contiguous event subsequencesof some fixed length. In particular, we consider activities as histograms of their event n-grams, where an n-gram is acontiguous activity subsequence of length n.1.3.2. Activity-class discoveryExploiting our activity representation, we propose a computational framework to automatically discover the variousactivity-classes taking place in an environment. We model activity-classes as maximally similar activity-cliques in a com-pletely connected graph of activities, and show how to discover them efficiently.1.3.3. Activity-class characterizationFinding characterizations of the discovered activity-classes is imperative for online activity classification as well asanomaly detection. In this regard, we propose methods for finding concise characterizations of these discovered activity-classes, both from a holistic as well as a by-parts perspective. From a holistic view, we formalize the problem as finding1224R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244typical members of activity-classes that, to some measure, best represent all the members of the activity-class. On a by-partslevel, we consider this problem as that of finding recurrent event subsequences in the member activities of an activity-class.We call these recurrent event subsequences event motifs (formally defined in Section 7.1), and find them in a way such thatthey are maximally mutually exclusive amongst the various activity-classes.1.3.4. Activity classification & anomalous activity detectionUsing such characterizations, we present a method to classify a new activity instance to one of the discovered activity-classes, and to automatically detect if it is anomalous with respect to the general characteristics of its membership class.We also present an information theoretic method to explain the detected anomalies in a maximally informative manner.1.4. Document layoutThis paper is a detailed exposition and extension of some of our preliminary work in [15] and [16]. We start in Section 2by reviewing the previous work related to the problem at hand, pointing out how our approach is different from thepreviously proposed methods. We explain in Section 3 our proposed activity representation of event n-grams, and presentan empirical analysis of their discriminative power and sensitivity to sensor noise as a function of class overlap. Exploitingevent n-grams, in Section 4 we show how the notion of maximal cliques in edge-weighted activity-graphs can be usedto efficiently discover activity-classes in an unsupervised manner. In Section 5, we explain how these discovered activity-classes can be used for activity classification, anomalous activity detection as well as their explanation. Section 6 explains theexperimental results for our proposed framework. The characterization of the discovered activity-classes for the purposes ofonline activity classification and anomaly detection is presented in Section 7. Section 8 explains the results for our proposedframework for event motif discovery. The conclusions and future directions of this work are explained in Section 9.2. Related workThe problem of automatic human activity analysis has been studied in various contexts, including computational percep-tion [6], ubiquitous computing [11], as well as robotics [40]. Much has been written about activity decomposition and therole of knowledge in the perception of motion [5], where scientists have worked on understanding the psychological [43]as well as computational basis of how motion is perceived [44,46]. In the following we briefly review some of the previouswork done in the scope of perceptual scene analysis, comparing how our work differs from these previous approaches.2.1. Activity representationOne of the key problems in building perceptual systems is finding activity representations that are efficiently computable.Most of the previous approaches towards this end assume that the structure of activities being modeled is known a priori(see e.g. [7,20,24–26,38] and the references therein). However, such prior knowledge about activity structure is generally notat hand. These grammar driven modeling approaches are therefore limited to representing activities performed in relativelysmall-scale constrained environments, underscoring the motivation of our current work. Here we propose to treat activitiesas bags of event n-grams to extract their global structural information by using statistics of their local event subsequences.2.2. Activity-class discoveryDiscovering activity-classes using perceptual data has been explored in depth in the past. Our approach towards thisproblem is however novel in a few key aspects. The work in [13] and [31] for instance looks directly at perceptual signals todiscover coherent classes of behaviors. Our work on the other hand adds an intermediate abstraction layer of events uponwhich the discovery process takes place. Since events are semantically more meaningful than the direct sensory signals,the activity-classes discovered based on events would potentially be more coherent and easily interpretable. Since event-monograms, as used in [47] and [39], do not capture the temporal information of activities, we propose to use higher orderevent n-grams. While work in [29,42] has similar motivation of finding event patterns between activity sequences, ourframework goes beyond finding similarities between activities, and also addresses problems of class characterization as wellas anomaly detection.Unlike previous approaches, our framework models activity-classes as edge-weighted maximal cliques in a completelyconnected graph of some given activity-instances. Finding maximal cliques in edge-weighted graphs is a classic graph the-oretic problem [2,33]. In this paper we adopt the recently proposed approximate approach of iteratively finding dominantsets of maximally similar nodes in a graph (equivalent to finding maximal cliques) [30]. Besides providing an efficient ap-proximation to finding maximal cliques, the framework of dominant sets naturally provides a principled measure of thecohesiveness of a class as well as a measure of node participation in its membership class.2.3. Anomaly detectionMost of the previous attempts to tackle the problem of finding activities that are anomalous have focused on a recogni-tion based perspective towards the problem, where anomalous activities are explicitly modeled and learned in a supervisedR. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12441225Fig. 3. Illustration of n-grams. Transformation of an example activity from sequence of events to histogram of event n-grams. Here the value of n is shownto be equal to 3.manner [18,19]. For large-scale everyday environments however, anomalies are hard to completely define a priori. Ratherthan modeling anomalies themselves, in this work we propose to model the regular activity-classes and detect anomalousactivities based on their distance from learned models of regular behaviors in the environment. Previous works that havesimilarly taken a detection based perspective towards finding anomalies [8,31] have looked at it mostly from a generativeperspective, and have not attempted to explain why an activity being detected as anomalous is in fact an anomaly. In con-trast, our approach takes an instance-based view of activity-classes, and attempts to detect as well as explain in a maximallyinformative manner, why an activity is detected as an anomaly.2.4. Activity-class characterizationA concise characterization of discovered activity-classes is imperative, both from a representational as well as a dis-criminative perspective. This is particularly important in situations where the start and end of different activities is notexplicitly marked, and there is a need to perform online classification and anomaly detection. While previously proposedinstance-based approaches in this regard [23,39] focus on the representational aspects of the problem, they are not neces-sarily discriminative. Moreover, these approaches only consider activities at a global scale, not incorporating the more localinformation. To this end, we formalize this problem as finding predictably recurrent event motifs using variable memoryMarkov chains.Numerous solutions to the problem of discovering important recurrent motifs in the fields of Bioinformatics and StringAnalysis have been previously proposed (see e.g. [4,9,27] and the references therein). Work done in [45] and [34] presentstechniques for learning variable memory Markov chains from training data in an unsupervised manner. Here, we extendthe work done in [45] to handle data from multiple classes, finding motifs that are maximally mutually exclusive amongstactivity-classes. Instead of sequentially finding individual subsequences and masking them out from the sequences as pro-posed in [3], our scheme simultaneously finds all the subsequences in the data in one pass, allowing to find partiallyoverlapping subsequences.3. Activity representation – activities as bags of event n-gramsSince models of activity structure for relatively unconstrained environments are generally not available a priori [10],representations that can encode this structure with minimal supervision are needed. Considering an activity as a sequenceof discrete events,1 two important quantities emerge:1. Content – which events are constituting an activity, and2. Order – the temporal arrangement of the constituent events.We want to learn the content and order information of activities using an activity representation that does not requireus to manually encode this information in a completely supervised manner.Our view of an activity is similar to how researchers in Natural Language Processing have looked at documents, i.e.as vectors of their constituent words (see Vector Space Model (VSM) [36]). While approaches such as VSM capture thecontent of a sequence in an efficient way, they completely ignore its order. Since the word content alone in documentsoften implies causal structure, ignoring order information of words is usually not a significant challenge. Activities howeverare not fully defined by their event-content alone; rather, there are preferred or typical event-orderings [27]. Therefore amodel to capture event order in a more explicit manner is needed.To this end we consider activities in terms of histograms of event n-grams where an n-gram is a contiguous subsequenceof an activity. Each event n-gram is of a fixed size n. By sliding a window of length n over an activity, we can find all theevent n-grams contained in it. We can then represent that activity as counts of these extracted n-grams. For the illustrativeexample shown in Fig. 3, the value of n is set equal to 3.It is evident that higher values of n capture order information of events more precisely. However, as n increases, thedimensionality of the histogram space grows exponentially. For instance, given an event vocabulary of k events, n-gramswith n = 5 would span an activity space with k5 dimensions. For even moderate values of k, density estimation in such1 Recall that we have defined an activity as a finite sequence of discrete events.1226R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244Fig. 4. Illustration of Algorithm 1. We begin by constructing a complete tree of depth d. P and Q are selected from leaf-set S. Probabilities of VMMC-1are sampled from N (0, 1). VMMC-2 is constructed by perturbing probabilities of VMMC-1.Require: Symbol vocabulary k, modal depth d, number of topological operations I , and % node perturbation ηConstruct V1 as complete tree of depth d with leaf-set SRandomly construct P ⊆ S where (cid:5)P(cid:5) = (cid:5)S(cid:5)/2Construct Q ≡ S \ Pfor i = 1 to I doSample a member of Q. Detach it from its parent. Attach it to a randomly selected member of Q.end forSample edge probability of V1 from N (μ, 1) distributionConstruct V2 as an exact copy of V1Sample edge probability of η% nodes of V2 from N (μ, 1)Algorithm 1. Construct VMMC’s V1 and V2.a space can be challenging. This highlights the importance of selecting a reasonable value of n which sufficiently capturesevent dependence in an environment, and yet induces a space that can be estimated from reasonable amounts of data.3.1. Empirical analyses of n-grams using simulation dataRepresentations such as n-grams can be thought of as a means to extract different sequential features from an activ-ity sequence. It is essential to analyze how well can such a feature space discern between members of different classeswith respect to some ground-truth notion of class-overlap. Moreover, since for any sensor-based perceptual system, theobservations are always prone to sensor-noise, the efficacy of a representation is a function of how sensitive it is to sensor-noise. With this perspective at hand, we now present empirical analyses of n-grams in terms of their discriminative powerand noise sensitivity as a function of class-disjunction and noise perturbation. The analyses presented here are based onsimulated data, the details of which follow.Events in human activities depend on preceding events over variable durations [28]. To simulate this variable lengthevent dependence, we model activity-classes as variable memory Markov chains (VMMC) [45]. One way of encoding such aVMMC is by using a probabilistic tree [14], where each node represents any one of the members of the event vocabulary,while each edge represents the probability of traversing to its child from its parent. The topology of a tree encodes thevariable temporal dependence between different events. Given two identical trees, the sequences generated from themwould have same statistical properties. However, as we increasingly perturb their edge probabilities, the resulting sequencesgenerated would have increasingly different event statistics. Using this behavior to model the disjunction between thesequences of a pair of activity-classes, we first outline a novel algorithm regarding how to systematically control disjunctionbetween activity-classes.3.1.1. A novel method to systematically control class disjunctionWe begin by constructing a complete tree T with depth equal to d. Randomly selecting half of the leaf-nodes of T , weiteratively attach them to its remaining half. The VMMC for class-1 is completed by assigning edge-probabilities of T bysampling from a normal distribution with zero mean and unit variance (N (0, 1)). VMMC for class-2 is constructed by firstforming an exact copy of VMMC of class-1, followed by perturbing edge probabilities of top η% edge-paths of VMMC forclass-1. The algorithm is outlined in Algorithm 1, and figuratively illustrated in Fig. 4.3.1.2. Simulation dataFor a symbol vocabulary (cid:5)Σ(cid:5) = 5 and modal depth equal to 3, we generated 10 different topologies of VMMC’s. Foreach topology, we generated sequences for 2 classes with percent overlap decreasing from complete overlap to completeR. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12441227(a)(b)Fig. 5. (a) Discriminative prowess. Classification accuracy as a function of class-overlap. (b) Noise sensitivity. Classification for various representations relativeto their noise free performance.non-overlap with increments of 10%. For each of these 100 trials, we generated 75 sequences each of length 100 symbols,randomly selecting two-thirds for the training data and the rest for testing.3.1.3. Discriminability analysisFor data generated as described in Section 3.1.2, and using similarity metric defined later (Eq. (1)), the nearest neighborclassification results are given in Fig. 5(a). It is evident that for substantive class overlap, higher values of n seem to captureactivity structure more rigidly, entailing a more discriminative representation. However, since accurate density estimationfor higher value n-grams require exponentially greater amount of data, Vector Space Model seems to outperform 3- and5-grams in cases where the 2 classes are more disjunctive.3.1.4. Noise sensitivity analysisWe now analyze noise sensitivity of n-grams as a function of noise added as Insertion, Deletion, Transposition and Substi-tution of symbols. For data generated as described in Section 3.1.2, we cumulatively added all four types of noises with auniform prior on each, and noise likelihood ranging monotonically from 0 to 30%. Using noisy data, the classification resultsfor different representations relative to their noise free performance is given in Fig. 5(b). It is evident that representationsthat capture event order information more rigidly, are more sensitive to sensor noise. This underlines an inherent tradeoffbetween the ability of a representation to explicitly capture sequence-structure, and its robustness to sensor noise. It seemsthat tri-grams (n = 3) provide a reasonable balance between the two opposing factors. This is particularly true for relativelysmall class-overlap.4. Unsupervised activity-class discoveryWe want to use the activity representation of event n-grams to automatically discover the various categories of humanbehaviors taking place in an environment. We assume that members of an activity-class generally share a set of commonproperties that make them perceptually similar to each other, while making them different from members of other activity-classes. In order to discover such internally cohesive and externally disjunctive activity-classes, we first need to define somenotion of activity similarity based on which we could formalize a method for activity-class discovery.4.1. Activity similarity metricDue to the spatial and temporal constraints imposed by the key-objects in an environment, human activities tend tohave partially ordered sequences of events. Our desired notion of similarity between activities should consider this partiallyordered nature of activities, and we want to use the representation of event n-grams as a means to this end. In particular,our view of similarity between a pair of activity sequences consists of two factors:1. The structural differences, and2. The frequential differences.1228R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244Fig. 6. Illustration of activity-class discovery. Activity-instances are represented as a completed connected, edge-weighted activity graphs G. The edge-weightw p,q between nodes p and q is computed using Eq. (1). Maximal cliques of activity-nodes are iteratively found and removed from the activity-graph, untilthere remain no non-trivial maximal cliques. These maximal cliques correspond to activity-classes comprising of mutually similar activity instances.The structural differences relate to the distinct n-grams that occurred in either one of the activities in an activity-pair,but not in both. For such differences, the number of mutually exclusive n-grams is of fundamental interest. Similarly, if aparticular n-gram is present in both the sequences, the only discrimination that can be drawn between the sequence-pairis purely based on the frequency of the occurrence of that n-gram. This intuition can be formalized as follows.Let A and B denote two activities, and let their corresponding histograms of event n-grams be denoted by H A and H B .Let Y and Z be the sets of indices of n-grams with counts greater than zero in H A and H B respectively. Let αi denotedifferent n-grams, and f (αi | H A) and f (αi | H B ) denote the counts of αiin A and B respectively. We define similaritybetween two activities as:sim( A, B) = 1 − κ(cid:2)i∈Y , Z| f (αi | H A) − f (αi | H B )|f (αi | H A) + f (αi | H B )(1)where κ = 1/(|Y | + | Z |) is the normalizing factor, and | · | computes the cardinality of a set. While our proposed similaritymetric conforms to: (1) the property of Identity of indiscernibles, (2) is commutative, and (3) is positive semi-definite, itdoes not however follow the triangular inequality, making it a divergence rather than a true distance metric.4.2. Activity-class discoveryIt is argued that while facing a new piece of information, humans first classify it into an existing class [35], and thencompare it to the previous class members to understand how it varies in relation to the general characteristics of the mem-bership class [37]. Using this perspective as our motivation, we represent an activity space by a set of mutually disjunctiveclasses, and then detect a new activity as a regular or an anomalous member of its membership class.4.2.1. Activity-classes as maximal cliquesGiven K activity-instances, we consider this activity-set as an undirected edge-weighted graph with K nodes, each repre-senting a histogram of n-grams of one of the K activity-instances. The weight of an edge is the similarity between a pair ofnodes as defined in Eq. (1). We can now formalize the problem of discovering activity-classes as searching for edge-weightedmaximal cliques2 in the graph of K activity-instances [2]. We begin by finding the first maximal clique in the activity-graph,followed by removing that set of nodes from the graph, and iteratively repeating this process with the remaining set ofnodes, until there remain no maximal cliques in the graph. The leftover nodes after the removal of maximal cliques aredissimilar from most of the regular nodes, and are considered as being anomalous (see Fig. 6 for illustration).4.2.2. Maximal cliques using dominant setsAs combinatorially searching for maximal cliques in an edge-weighted undirected graph is computationally hard, numer-ous approximations to the solution of this problem have been proposed [33]. For our purposes, we adopt the approximateapproach of iteratively finding dominant sets of maximally similar nodes in a graph (equivalent to finding maximal cliques)as proposed in [30]. Besides providing an efficient approximation to finding maximal cliques, the framework of dominantsets provides a principled measure of cohesiveness of a class as well as a measure of node participation.Let the data to be clustered be represented by an undirected edge-weighted graph with no self-loops G = (V , E, ϑ)is the positive weight function. Thewhere V is the vertex set V = {1, 2, . . . , K }, E ⊆ V × V is the edge set, and ϑ : E → R+2 A subset of nodes is a clique if all its nodes are mutually adjacent; a maximal clique is not contained in any larger clique; a maximum clique has largestcardinality.R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12441229weight on the edges of the graph are represented by a corresponding K × K symmetric similarity matrix A = (ai j) definedas:sim(i, j)0if (i, j) ∈ Eotherwise(2)(cid:3)ai j =Here sim(i, j) is computed using our proposed notion of similarity as defined in Eq. (1). To quantize the cohesiveness ofa node in a cluster, we define its “average weighted degree”. Let S ⊆ V be a non-empty subset of vertices and i ∈ S, suchthat,Intuitively, ΦS (i, j) measures the similarity between nodes j and i, with respect to the average similarity between node iand its neighbors in S. Note that ΦS (i, j) can either be positive or negative.We now consider how weights are assigned to individual nodes. Let S ⊆ V be a non-empty subset of vertices and i ∈ S.awdegS (i) = 1(cid:5)S(cid:5)and(cid:2)ai jj∈SΦS (i, j) = ai j − awdegS (i)for j /∈ SThe weight of i with respect to S is given as:(cid:4)w S (i) =1(cid:5)if (cid:5)S(cid:5) = 1j∈S\{i} ΦS\{i}( j, i)w S\{i}( j) otherwiseMoreover, the total weight of S is defined asW (S) =(cid:2)w S (i)i∈S(3)(4)(5)(6)Intuitively, w S (i) gives a measure of the overall similarity between vertex i and the vertices of S \ {i} with respect to theoverall similarity among the vertices in S \ {i}. We are now in a position to define dominant sets. A non-empty sub-set ofvertices S ⊆ V such that W (T ) > 0 for any non-empty T ⊆ S, is said to be dominant iff:• w S(i) > 0, ∀i ∈ S, i.e. internal homogeneity,• w S∪{i}(i) < 0 ∀i /∈ S, i.e. external inhomogeneity.Effectively, we can state that the dominant set in an edge-weighted graph is equivalent to a cluster of vertices in that graph.Since solving Eq. (5) combinatorially is infeasible, we use a continuous optimization technique of replicator dynamics (fordetails, see [30]).5. Activity classification and anomaly explanation(cid:2)Given (cid:5)C(cid:5) discovered activity-classes, we are interested in finding if a new activity instance is regular or anomalous.Each member j of an activity-class c has some weight wc( j), that indicates the participation of j in c. We compute thesimilarity between a new activity-instance τ and the previous members of each class by defining a function Ac(τ ) as:Ac(τ ) =sim(τ , j)wc( j) ∀ j ∈ c(7)jHere wc( j) is the same as defined in Eq. (5). Ac represents the average weighted similarity between the new activity-instance τ and any one of the discovered classes c. The selected membership class cis found as∗c∗ = arg max∀cAc(τ )(8)Once the membership decision of a new test activity has been made, we now focus our attention on deciding whetherthe new class member is regular or anomalous. Intuitively speaking, we want to decide the normality of a new instancebased on its closeness to the previous members of its membership activity-class. This is done with respect to the averagecloseness between all the previous members of its membership class. Let the function Γ (τ ) be:Φc∗ ( j, τ )wc∗ ( j)j∈c∗(9)where Φ is defined by Eq. (4). We define a new class member τ as regular if Γ (τ ) is greater than a particular threshold.The threshold on Γ (τ ) is learned by mapping all the anomalous activity instances detected in the training activity-set totheir closest activity-class (using Eqs. (7) and (8)), and computing the value of Γ for both regular and anomalous activityinstances. We can now observe the variation in false acceptance rate and true positives as a function of the threshold Γ .This gives a “Receiver Operating Curve” (ROC). The area under ROC is indicative of the confidence in our detection metricΓ (τ ) [21]. Based on our tolerance for true and false positive rates, we can choose an appropriate threshold.(cid:2)Γ (τ ) =1230R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12445.1. Anomaly explanationExplanation of the detected anomalous activities is a function of characterization of the general properties of an activity-class. One way of characterizing these properties is to find the best representative or typical member of a class [23]. Thequestion of typicality is closely related to the similarity of a node to other members of a class. The problem has beenpreviously approached as finding the node with min-max distance from other nodes [12], or the node with maximum in-degree [17]. Such approaches however either assume the clusters to be well behaved, or take a very local view of a node’ssimilarity to its neighbors.5.2. Activity-class modelingFollowing [23], we propose the idea of typical nodes (mentioned as “authoritative sources” in [23]) and “similar to typical(STT)” nodes (mentioned as “hubs” in [23]). Typical and STT nodes exhibit a mutually reinforcing relationship – a good STTnode is one which is closer to a Typical node, while a Typical node is one closer to more STT nodes. Following [23], weassociate a non-negative Typicality weight xp and a non-negative STT weight y p to each node in the cluster where pdenotes the index of nodes in a cluster. Naturally, if p is closer to many nodes with large x values, it should receive a largey value. On the other hand if p is closer to nodes with large y values, it should receive large x value. We define two coupledprocesses to update weights xp and y p iteratively, i.e.(cid:2)(cid:2)xp ←yqand y p ←xq(10)q: (q,p)∈Eq: (q,p)∈E∗As we iterate the above two equations k times in the limit k → ∞, xp and y p converge to x. The node which hasthe largest component in the converged vector xwould correspond to the node which has the greatest Typical weight andcan be computed from the Eigen Analysis of the matrix A T Ahence is the best representative of the nodes of clusters. xis the principal eigenvector (thewhere A is the symmetric similarity matrix of all the nodes of the cluster. Essentially xone with greatest corresponding eigenvalue) of A T A, the largest component of which corresponds to the Typical Node ofthe cluster (for proof, see [23]).and y∗∗∗∗5.2.1. Explanatory featuresFor large scale surveillance systems, it is imperative to find the features that can be used to explain an anomalousactivity in a maximally-informative manner. We are interested in features of an activity-class that have minimum entropy,and occur frequently. The entropy of an n-gram indicates the variation in its observed frequency, which in turn indicatesthe confidence in the prediction of its frequency. The frequency of occurrence of an n-gram suggests its participation in anactivity-class. We want to analyze the extraneous and the pertinent features in an activity sequence that made it anomalouswith respect to the most explanatory features of the regular members of the membership activity-class. We now constructour approach mathematically (a figurative illustration is given in Fig. 7).Let αi denote a particular n-gram i for an activity, and c denote any of the (cid:5)C(cid:5) discovered activity-classes. If R de-notes the typical member of c as described in Section 5.2, and τ denotes a new activity-class member detected as beinganomalous, then we can define the difference between their counts for αi as:D(αi) = f R (αi) − fτ (αi)(11)where f (αi) denotes the count of an n-gram αi . Let us define the distribution of the probability of occurrence of αi in c as:P c(αi) =(cid:5)(cid:5)Mi=1k∈c fk(αi)(cid:5)k∈c fk(αi)(cid:2)(cid:3)j∈c(cid:2)Q (x) = ψ1 if f (αi) = x0 otherwiseHc(αi) =Q c(x) lnx∈χ ic(cid:8)(cid:9)Q c(x)where M represents all the non-zero n-grams in all the members of activity-class c. Let us define multi-set χ ic as:(cid:6)(cid:7)=χ icfk(αi) | k ∈ cWe can now define probability Q (x) of occurrence of a particular member x ∈ χ ic for αi in c as:where ψ is the normalization factor. Let us define Shannon’s Entropy of a tri-gram i for an activity-class c by Hc(αi) as:We can now define the notion of predictability, PRDc(αi), of the values of tri-gram αi of cluster c as:PRDc(αi) = 1 −(cid:5)Hc(αi)Mi=1 Hc(αi)(12)(13)(14)(15)(16)R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12441231Fig. 7. Five simulated activity sequences are shown to illustrate the different concepts introduced in Section 5.2.1. α1 has low value of P c , its entropy Hcis low and therefore its predictability is high. α4 has medium P c , its entropy Hc is also low and its predictability is high. Finally α8 has high P c , but itsentropy Hc is high which makes its predictability low. α1 could be useful in explaining the extraneous features in an anomalous activity, while α4 couldbe useful in explaining the features that were deficient in an anomaly.It is evident from this definition, that αi with high entropy Hc(αi) would have high variability, and therefore would havelow predictability.We define the explainability of an n-gram αi ∈ c that was frequently and consistently present in the regular activity-classas:c (αi) = PRDc(αi)P c(αi)ξ PIntuitively, ξ Pcindicates how much an αi is instrumental in representing a activity-class c.Similarly, we can define the explainability of αi ∈ c in terms of how consistently was it absent in representing c.(cid:8)c (αi) = PRDc(αi)ξ AP maxc(cid:9)(αi) − P c(αi)(17)(18)where P maxc(αi) is the maximum probability of occurrence of any αi in c.The first term in both Eqs. (17) and (18) indicates how consistent αi is in its frequency over the different members of aclass. The second term in Eqs. (17) and (18) dictates how representative and non-representative αi is for c respectively.Given an anomalous member of a activity-class, we can now find the features that were frequently and consistentlypresent in the regular members of the activity-class, but were deficient in the anomaly τ . To this end, we define thefunction Deficient(τ ) as:(cid:10)Deficient(τ ) = arg max(cid:11)ξ Pc (αi)Dc(αi)(cid:10)Extraneous(τ ) = arg min(cid:11)ξ Ac (αi)Dc(αi)αiαiSimilarly, we can find the most explanatory features that were consistently absent in the regular members of the member-ship activity-class but were extraneous in the anomaly. We define the function Extraneous(τ ) as:(19)(20)We can explain anomalies based on these features in two ways. Firstly, we can consider features that were deficient froman anomaly but were frequently and consistently present in the regular members. Secondly, we can consider features thatwere extraneous in the anomaly but were consistently absent from the regular members of the activity-class.6. Results: Class discovery, classification & anomaly explanationTo test the competence of our proposed framework, experiments on data-sets collected from three everyday environ-ments were performed. The explanation of the experimental setups and results obtained in these settings are presented inthe following.1232R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244Fig. 8. A schematic diagram of the camera setup at the loading dock area with overlapping fields of view.Fig. 9. Key frames of example events. The figure shows an delivery activity in a loading dock area. Only Camera 1 is being shown here. The key-objectswhose interactions define these events are shown in different colored blocks.6.1. Experimental setup – loading dock areaWe collected video data at the Loading Dock Area (LDA) of a retail bookstore. We installed two cameras with partiallyoverlapping fields of view. A schematic diagram with sample views from the two cameras is shown in Fig. 8. Different de-livery activities take place in this environment, and to get the reader better situated with the dynamics of this environment,some of the events from one of the collected activity are shown in Fig. 9. Daily activities from 9a.m. to 5p.m., 5 days a week,for over one month were recorded, during which we collected 195 activities. Of these, 150 were randomly selected as ourtraining set, while the remaining 45 were used as our testing set. We carefully identified 10 key-objects in the environment,whose various interactions constituted an event vocabulary of 61 events. Events of the 150 training activity instances weremanually annotated using our pre-defined event-vocabulary. For testing activities, we hand-tracked the key-objects and builtlow-level event detectors that used these object-tracks for semi-automatic event detection in test videos.6.2. Analysis of discovered activity-classes – loading dock areaOut of the 150 training activities, we discovered 7 activity-classes, with 106 activities as part of any one of the discoveredclasses, while 44 activities being different enough to be not included into any class. The visual representation for thesimilarity matrices of the original 150 activities and the re-arranged activities in 7 classes is shown in Fig. 10.Analysis of these discovered activity-classes reveals a strong structural similarity amongst the class members. For in-stance, the most cohesive of the discovered classes was the one where all the UPS deliveries were clustered. It must bepointed out that there was no explicit information about the company-labels of the delivery vehicles in our vocabulary.The reason we were able to discover all UPS deliveries as a cohesive activity-class is because the activity-structure inducedby a UPS delivery by the virtue of where the truck docks, how many packages are delivered, in what manner are theyR. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12441233Fig. 10. Each row represents similarity of an activity with the entire training date. White implies identical similarity. Black represents complete dissimilarity.Activities ordered after the red cross line in the clustered similarity matrix were dissimilar enough to be considered anomalous. (For interpretation of thereferences to color in this figure legend, the reader is referred to the web version of this article.)Table 1Description for the discovered classes in loading dock: A brief description of the various discovered classes in the Loading Dock Environment are given interms of the different distinguishing features.Class indexClass descriptionClass 1Class 2Class 3Class 4Class 5Class 6Class 7(cid:2)delivery-vehicles that picked up multiple packages using hand carts.UPSPickup trucks and vans that dropped off a few packages without needing a hand cart.Delivery trucks that dropped off multiple packages, with multiple people using hand-carts.A mixture of car, van, and truck delivery vehicles that dropped off one or two packages without needing a hand cart.Delivery-vehicles that picked up and dropped-off multiple packages using a motorized hand cart and multiple people.Van delivery-vehicles that dropped off one or two packages without needing a hand cart.Delivery trucks dropped off multiple packages using hand carts.delivered etc., is reflected in our similarity metric, and is picked up by the discovery algorithm. This anecdotal evidence isan indication that the perceptual bias introduced by us in terms of the event-vocabulary, is successfully manipulated at thehigher-level discovery algorithm. A brief description of the discovered activity-classes is given in Table 1.6.3. Experimental setup – residential house environmentTo test our proposed algorithms on the activities in a residential house environment, we deployed 16 strain gages atdifferent locations in a house, each with a unique identification code. These transducers register the time when the residentof the house walk over them. The data was collected daily for almost 5 months (151 days – each day being consideredas an individual activity). Whenever the person passed near a transducer at a particular location, it was considered asthe occurrence of a unique event. Thus our event vocabulary in this environment consists of 16 events. Fig. 11 shows aschematic top-view of this environment.6.4. Analysis of discovered activity-classes – residential houseOut of the 151 activities captured over a little more than 5 months, we found 5 activity-classes (maximal cliques), with131 activities as members of any one of the discovered class, and 20 activities being dissimilar enough not to be a part ofany non-trivial maximal clique. A brief description of the discovered activity-classes is given in Table 2.A closer analysis of these classes show the general behavior of the person depending on how long did the person spendin the house, what parts of the house did he spent most of his time at while he was inside, and what were the mostfrequent location-transitions that he made. These behaviors seem to correlate with other physical information not encodedin the data, such as what day of the week it was etc. This demonstrates that the proposed system can be very useful formonitoring the everyday activities of senile individuals to see if there are any anomalous patterns.6.5. Experimental setup – household kitchenOne of the main reasons of exploring this environment was to study how our framework performs when the events aredetected in a completely automatic manner using low-level pixel information. To this end, we deployed a top-down staticcamera in a household kitchen to record a user’s interactions with different key-objects known a priori. The user enacted 10activity-classes each constituting of 10 activity instances. The directions and recipes for preparing dishes of different classeswere taken from http://www.recipeland.com/. The floor-layout of the kitchen and the key-objects are shown in Fig. 12.1234R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244Fig. 11. A schematic diagram of the strain-gage setup in the house scenario. The red dots represents the positions of the strain gages. (For interpretation ofthe references to color in this figure legend, the reader is referred to the web version of this article.)Table 2Description for the discovered classes in residential house: A brief description of the various discovered classes in the Residential House Environment aregiven in terms of the different distinguishing features.Class indexClass descriptionClass 1Class 2Class 3Class 4Class 5Activities lasting for the entire length of days where the person’s trajectory spans the entire house space. Most of the time was spent inthe area around the Kitchen and the Dining Table.The person moves from kitchen to the stairway more often. Further more, as opposed to cluster 1, the person does not go from theOffice to the Sun Room area.The person spends more time in the areas of Den and the living-room. Moreover, he visits the Sun-room more often.The person spends most of the day in Kitchen and Dining Room. The duration for which she stays in the house is smaller for this class.The person moves from Dining Room to the Sun Room more often. The duration for which she stays in the house is significantly smallerthan any other activity-class.Fig. 12. A schematic diagram showing the kitchen floor layout, and the location of the considered key-objects.6.5.1. Automatic event detection in household kitchen environmentOne of the imperatives of exploring this environment was to see how our framework performs when the events aredetected completely automatically using the low-level pixel values. For this setup, we assume the proximity of person witha particular key-object to imply an interaction between the person and the object. Each interaction longer than a particularduration was registered as an event of person interacting with a certain key-object. For this work, we implemented apreviously proposed tracking framework [41]. For extracting the person from background image, we learned Gaussian MixtureModels for the chromatic contents of the background, used for computing the likelihood for the presence of the person inthe image space. Given such likelihoods, we used a particle filter framework to search through image space for computingthe maximum a posteriori position of the person. This MAP estimate in one frame is propagated to the next as the initialstate of the filter for next iteration. This process is figuratively illustrated in Fig. 13.R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12441235Fig. 13. Figurative illustration of person tracking: (1) The background image is divided into multiple regions, and a Gaussian mixture model for the chromaticcontent of each region is learned. (2) These background models are used to subtract the foreground from the background, and another set of Gaussianmixture models are learned for the chromatic content of the foreground. (3) During testing, the likelihood of a portion of the image belonging to foregroundis computed using the background and foreground appearance models. (4) A fixed number of most likely hypotheses (particles) are sampled from theprevious frame, and are re-distributed using a motion model. These hypotheses are weighted using foreground likelihood in test image, and used to inferposition of the person in current frame.Table 3Comparative performance for class discovery: The table shows the discovered number of activity-classes while using the n-gram representation for differentvalues of n.1-grams3-grams5-gramsAloo DamBabkaCerealFruit SaladOmeletRaitaChickenSetup TableGreen SaladWash DishesAverage% DiscoveryP55.5–60.0–––16.360.0–50.024.1R50.0–60.0–––100.060.0–50.032.0P50.055.557.1––17.944.450.040.044.435.9R60.050.040.0––70.040.050.020.040.037.0P54.537.533.333.3–33.341.645.437.525.034.1508090R60.030.030.340.0–70.050.050.030.020.038.06.6. Analysis of discovered activity-classes – household kitchenThe purposes of conducting this experiment was to explore how many of the original activity-classes that we know arepresent in our activity-corpus can n-grams extract for different values of n. For every class that our framework discovered,the final class-label is assigned based on the labels of the majority of the class-members. Moreover, any two classes withthe same class labels were merged. We ran the discovery algorithm for different values of thresholds, and the best obtainedresults are given in Table 3.As can be observed that as the value of n increases, the n-grams are able to capture the activity structure more explicitly,resulting in the recovery of more number of activity-classes. The quality of the recovered classes also increases with theincrease in the value of n.Note that this trend however cannot continue indefinitely. This is because with higher values of n the sparsity of thedata would increase to a point where the structural signature of activities present in the data might be lost. Therefore, thereis a need to first discover the predominant mode of temporal dependence of events in an environment, which could beused to set an optimal value of n. We leave the discovery of an optimal value of n as part of our future work.1236R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244(a)(b)(c)Fig. 14. Anomalous activities: (a) shows a delivery vehicle leaving the loading dock with its back door still open; (b) shows an unusual number of peopleunloading a delivery vehicle; (c) shows a person cleaning the loading dock floor.6.7. Detected anomalies – loading dock environmentWe now present a detailed explanation of how using the initially detected anomalous activities in the Loading Dock Area(see Section 6.2), we can learn a threshold for detecting new anomalous activity-class members, validate how intuitive arethese detected anomalies from a human view-point, and explain in what ways are the detected anomalies different fromthe regular members of their membership classes.6.7.1. Analysis of detected anomaliesAnalyzing the detected anomalous activities reveals that there are essentially two kinds of activities that are beingdetected as anomalous, (1) ones that are truly alarming, where someone must be notified, and (2) those that are simplyunusual delivery activities with respect to the other regular activities. Key-frames for three of the truly alarming anomalousactivities are shown in Fig. 14. Fig. 14(a) shows a truck driving out without closing it’s back door. Not shown in thekey-frame is the sequence of events where a loading-dock personnel runs after the delivery vehicle to tell the driver ofhis mistake. Fig. 14(b) shows a delivery activity where a relatively excessive number of people unload the delivery vehicle.Usually only one or two people unload a delivery vehicle, however as can be seen from Fig. 14(b), in this case there were fivepeople involved in the process of unloading. Finally, Fig. 14(c) shows the unusual even of a person cleaning the dock-floor.6.7.2. User study for detected anomaliesTo analyze how intuitive the detected anomalies are to humans, a user test involving 7 users was performed. First 8regular activities for a subject were selected so she could understand the notion of a regular activity in the environment.10 more activities were selected, 5 of which were labeled as regular by the system while the rest of the 5 were detected asanomalies. Each of the 7 users were shown these 10 activities and asked to label every one of them as a regular instance oran anomaly based on the regular activities previously shown. Each of the 10 activities were given labels based on what themajority agreed upon. 8 out of 10 activities labeled by the users, corresponded with the labels of the system. The probabilityof the system choosing the correct label 8 out of 10 times by chance is 4.4%.3 This highlights the interesting fact that theanomalies detected by the proposed system fairly match the natural intuition of human observers.6.8. Noise analysis of n-grams in loading dock environmentThe results presented thus far were generated using activities with hand-labeled events. However, using low-level visionsensors to detect these events will generate noise. This invites the question as to how well would the proposed systemperform over noisy data. In the following, the noise analysis to check the stability and robustness of the proposed frameworkis presented; allowing one to make some predictions about its performance on data using low-level vision.Given the discovered activity-classes and the learned detection threshold using the training set of 150 activity-instances,various types and amounts of noise to the 45 test sequences was added, and the following two tests were performed:1. Regular classification rate: Percent activities classified as regular members in the 45 ground truth test activities main-tain their correct activity-class and regular-membership labels in the face of noise.2. Anomaly detection rate: Percent of 45 ground truth test activities detected as anomalies still get detected as anomaliesin the face of noise.Different amounts of noise using four types of noise models, Insertion Noise, Deletion Noise, Substitution Noise and SwapNoise was synthetically generated. We generated one noisy event-symbol using a particular noise model, anywhere within3 Given that the probability of correctly choosing the true label by simply guessing is 0.5, the binomial probability states that chance of an 8/10 successis C 108 (0.5)8(0.5)2 ≈ .0439.R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12441237Fig. 15. Noise analysis – loading dock area: Each graph shows system-performance under synthetically generated noise using different generative noisemodels.Table 4Anomaly detection rate: The average detection rate of the system in the face of noise.Noise modelInsertion NoiseDeletion NoiseSwap NoiseSubstitution Noise% age correct100%99%97%100%a window of a time-period for each activity in the testing data set. For instance Insertion Noise of time period 10 wouldinsert one event-symbol between any two consecutive event-symbols, every 10 symbols. The classification performance ofthe proposed system under such noise model is shown in Fig. 15. The system performs robustly in the face of noise anddegrades gracefully as the amount of noise increases. Likewise, the anomaly detection capability of our system in the faceof synthetically generated noise is shown in Table 4. The reason for such high detection rate even with large amount ofsynthetic noise is that it is unlikely that an anomaly would transform into something regular when perturbed randomly.6.9. Automatic event detectionTo move one step closer towards using low-level vision, we wrote a feature-labeling software that a user uses only tolabel the various objects of interest in the scene such as the doors of the loading dock, the delivery vehicles and its doors,people, packages and carts. We assign each object a unique ID during labeling. The ID numbers and object locations arestored in an XML format on a per-frame basis. We also wrote event detectors that parsed the XML data files to computethe distances between these objects for the 45 test activities. Based on the locations and velocities of these objects, thedetectors performed automatic event detection.The horizontal line in Fig. 15 shows the Regular Classification Rate of our system over these automatically generated eventsequences, i.e. 70.8%. The results for Anomaly Detection Rate for the automatically generated event sequences is 90.48%.6.10. Anomalous activity explanationFig. 16 shows the explanation generated by the system for the three anomalous activities (shown in Fig. 14). The anomalyshown in Fig. 14(a) was classified to a activity-class where people frequently carry packages through the front door ofthe building. There was only one person in this anomaly who delivers the package through the side door. This is evi-dent by looking at the extraneous features of the anomaly (Fig. 16(b)) where the tri-gram Person Full Handed →Person Exits Side Door → Person Empty Handed captures this difference. The second tri-gram of Fig. 16(b),Person Full Handed → Person Exits Back Door → Person Full Handed shows the fact that there was an-other person who went out of the garage to tell the driver of the delivery vehicle that his back door was open.1238R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244Fig. 16. Anomaly explanation – explanations for anomalies in Fig. 14. The n-grams with less frequency than expected are shown in green, while those withfrequencies greater that their expected frequency are shown in orange. (For interpretation of the references to color in this figure legend, the reader isreferred to the web version of this article.)The membership activity-class of anomaly in Fig. 14(b) has people frequently carrying packages through the front doorof the building. In this anomaly, all of the workers go to the side door of the building. Moreover, majority of events in thisanomaly were related to carts that is not one of the general characteristic of its membership activity-class. This is shownin Fig. 16-d by tri-grams Person Enters Back Door of DV → Person Empty Handed → Person PushesCart from Back Door of DV, and Person Empty Handed → Person Pushes Cart from Back Door of DV→ Cart Empty. Similarly Fig. 16(e) and Fig. 16(f) explain how anomaly in Fig. 14(c) was different from its membershipactivity-class.7. Activity-class characterizationSo far, we have considered situations where the beginning and end of activities is explicitly known. However, thereare many scenarios where such demarcations are not so well-defined. For such situations, it is crucial to find concisecharacterizations of the discovered activity-classes that could be used for online activity classification and detection ofanomalous activities. We formalize this problem as finding predictably recurrent activity subsequences (called event motifs)using variable-memory Markov chains (VMMC). Note that our usage of (VMMC’s) in Section 3.1 to empirically analyze thecompetence of n-grams, was for purely generative purposes. However, here we describe a novel method to learn the VMMCmodel of an activity-class in a data-driven manner.7.1. Defining event motifsWe are interested in frequently occurring event subsequences that are useful in predicting future events in activities.Following [45], we assume that a class of activity sequences can be modeled as a variable-memory Markov chain (VMMC).We define an event-motif for an activity-class as one of the variable-memory elements of its VMMC. We cast the problem offinding the optimal length of the memory element of a VMMC as a function optimization problem and propose our objectivefunction in the following.7.2. Formulation of objective functionLet Y be the set of events, A be the set of activity-instances, and C be the set of discovered activity-classes. Let functionU (a) map an activity a ∈ A to its membership class c ∈ C . Let the set of activities belonging to a particular class c ∈ C bedefined as Ac = {a ∈ A: U (a) = c}. For a = ( y1, y2, . . . , yn) ∈ A where y1, y2, . . . , yn ∈ Y , let p(c|a) denote the probabilitythat activity a belongs to class c. Then,p(c | a) = p(a | c)p(c)p(a)∝n(cid:12)i=1p( yi | yi−1, yi−2, . . . , y1, c)(21)where we have assumed that all activities and classes are equally likely. We approximate Eq. (21) by a VMMC, Mc as:R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244n(cid:12)i=1p( yi | yi−1, . . . , y1, c) =n(cid:12)i=1p( yi | yi−1, . . . , yi−mi , c)1239(22)where mi (cid:2) i − 1 ∀i. For any 1 (cid:2) i (cid:2) n, the sequence ( yi−1, yi−2, . . . , yi−mi ) is called the context of yi in Mc [45], denotedby SMc ( yi). We want to find the sub-sequences which can efficiently characterize a particular class, while having minimalrepresentation in other classes. We therefore define our objective function as:Q(Mc | Ac) = γ − λwhereγ =(cid:12)a∈ Acp(c | a) and λ =(cid:2)(cid:12)c(cid:14)∈C\{c}a∈ Ac(cid:14)p(c(cid:14) | a)(23)(24)Intuitively, γ represents how well a set of event-motifs can characterize a class in terms of correctly classifying the activitiesbelonging to that class. On the other hand, λ denotes to what extent a set of motifs of a class represent activities belongingto other classes. It is clear that maximizing γ while minimizing λ would result in the optimization of Q(Mc | Ac). Notethat our motif finding algorithm leverages our activity-class discovery framework by using the availability of the discoveredactivity-classes to find the maximally mutually exclusive motifs.7.3. Objective function optimizationWe now explain how we optimize our proposed objective function. [45] describes a technique to compare differentVMMC models that balances the predictive power of a model with its complexity. Let s be a context in Mc , where s =yn−1, yn−2, . . . , y1, and yn−1, yn−2, . . . , y1 ∈ Y . Let us define the suffix of s as suffix(s) = yn−1, yn−1, . . . , y2. For each y ∈ Y ,(cid:14) ⊆ A where s precedes y, andlet N A(cid:14) ( y, s) be the number of occurrences of event y in activity-sequences contained in Alet N A(cid:14) (s) be the number of occurrences of s in activity-sequences in A. We define the function (cid:15) A(cid:14) (s) as(cid:14)(cid:15) A(cid:14) (s) =(cid:2)y∈YN(s, y) log(cid:13)(cid:14)ˆp( y | s)ˆp( y | suffix(s))(25)where ˆp( y | s) = N A(cid:14) (s, y)/N A(cid:14) (s) is the maximum likelihood estimator of p( y | s). Intuitively, (cid:15) A(cid:14) (s) represents the number, were encoded using s as a context, versus having suffix(s) as aof bits that would be saved if the events following s in Acontext. In other words, it represents how much better the model could predict the events following s by including the lastevent in s as part of context of these events.(cid:14)We now define the function Ψc(s) (bit gain of s) as(cid:2)Ψc(s) = (cid:15) Ac (s) −(cid:15) Ac(cid:14) (s)c(cid:14)∈C\{c}(26)Note that higher values of (cid:15) Ac (s) imply greater probability that an activity in Ac is assigned to c, given that s is used as amotif. In particular, higher the value of (cid:15) Ac (s), higher will be the value of γ . Similarly, higher the value of(cid:14) (s),higher the value of λ.c(cid:14)∈C\{c} (cid:15) Ac(cid:5)We include a sequence s as a context in the model Mc iffΨc(s) > K × log((cid:17))(27)where (cid:17) is the total length of all the activities in A, while K is a user defined parameter. The term K × log((cid:17)) representsadded complexity of the model Mc , by using s as opposed to suffix(s) as a context, which is shorter in length and occursat least as often as s. The higher the value of K the more parsimonious the model will be.Eq. (27) selects sequences that both appear regularly and have good classification and predictive power – and hence canbe thought of as event-motifs. Work in [34] shows how the motifs in a VMMC can be represented as a tree. Work donein [1] presents a linear time algorithm that constructs such a tree by first constructing a data structure called a Suffix Treeto represent all sub-sequences in the training data A, and then by pruning this tree to leave only the sequences representingmotifs in the VMMC for some activity-class. We follow this approach by using Eq. (27) as our pruning criterion.8. Results: Discovered event motifsWe now present the results of motifs we obtained using our method for the previously discovered activity-classes inLoading Dock and House environments.1240R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244Table 5Description for the discovered event motifs in Loading Dock: A brief description is given for the various discovered event motifs for the 7 discoveredactivity-classes in the Loading Dock environment.Class indexClass 1Class 2Class 3Class 4Class 5Class 6Class 7Class descriptionPerson places package into back door of delivery vehicle → Person enters into side door of building → Person is empty handed →Person exists from side door of building → Person is full handed → Person places package into back door of delivery vehicle.Cart is full → Person opens front door of building → Person pushes cart into front door of building → Cart is full → Person closesfront door of building → Person opens front door of building → Person exists from front door of building → Person is empty handed→ Person closes front door of building.DV drives in forward into LDA → Person opens left door of DV → Person exists from left door of DV → Person is empty handed →Person closes the left door of delivery vehicle.Person opens back door of DV → Person removes package from back door of DV → Person removes package from back door of DV →Person removes package from back door of DV → Person removes package from back door of DV → Person removes package from backdoor of DV.Person closes front door of building → Person removes package from cart → Person places package into back door of DV → Personremoves package from cart → Person places package into back door of DV → Person removes package from cart → Person placespackage into back door of DV.Person Removes Cart From Back Door of DV → Person Removes Package From Back Door of DV → Person Places Package Into Cart →Person Places Package Into Cart → Person Removes Package From Back Door of DV → Person Places Package Into Cart → PersonRemoves Package From Back Door of DV → Person Places Package Into Cart.Person closes back door of DV → Person opens left door of DV → Person enters left door of DV → Person is empty handed → Personcloses left door of DV.Table 6Description for the discovered event motifs in Residential House domain: A brief description is given for the various discovered event motifs for the 5discovered activity-classes in the Residential House Environment.Class indexClass 1Class 2Class 3Class 4Class 5Class descriptionAlarm → Kitchen entrance → Fridge → Sink → Garage door (inside).Stairway → Fridge → Sink → Cupboard → Sink.Stairway → Dining Table → Den → Living-room Door → Sun-room → Living-room door → Den.Den → Living-room door → Den → Kitchen Entrance → Stairway.Fridge → Dining Table → Kitchen Entrance → Fridge → Sink.8.1. Analysis of discovered event motifsThe highest big-gain event-motifs found for the 7 discovered activity-classes in the Loading Dock domain are given inTable 5. The discovered motifs of activity-classes seem to characterize these classes efficiently. Note that the discoveredmotifs for activity-classes where package delivery occurred, have events like Person Places Package In The Back Door OfDelivery Vehicle and Person Pushes Cart In The Front Door of Building → Cart is Full. On the other hand event-motifs foractivity-classes where package pick-up occurred, have events such as Person Removes Package From Back-Door Of DeliveryVehicle and Person Places Package Into Cart.The highest big-gain event-motifs found for the 5 discovered activity-classes in the House scenario are given Table 6. Themotifs for the House environment capture the position where the person spends most of her time, and the order in whichshe visits the different places.8.2. Subjective assessment of discovered motifsTo subjectively assess the interpretability of the motifs discovered by our proposed method, we performed an anecdotaluser test involving 7 participants. For each participant, 2 of the 7 discovered activity-classes were selected from the LoadingDock environment. Each participant was shown 6 example activities, 3 from each of the 2 selected activity-classes. Theparticipants were then shown 6 motifs, 3 for each of the 2 classes, and were asked to associate each motif to the class thatit best belonged to. Their answers agreed with our systems 83% of the time, i.e., on average a participant agreed with oursystem on 5 out of 6 motifs. The probability of obtaining this agreement by random guessing4 is only 0.093.9. Conclusions & future workThis paper explores the problem of learning to discover and recognize human activities in everyday environments. Tra-ditional approaches to this end assume that the structure of activities being modeled is known a priori. However, for a4 According to the binomial probability function the chance of randomly agreeing on 5 out of 6 motifs is C 65 (0.5)1(0.5)5.R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12441241majority of everyday environments, the structure of such activities is generally not available. The main contribution of thiswork is an investigation of knowledge representations and manipulation techniques that can facilitate learning of everydayhuman activities in a minimally supervised manner.We posit that if we choose to describe everyday activities in term of an appropriate set of events, then the structuralinformation of these activities can be encoded using their local event subsequences, and that this encoding is sufficient foractivity-class discovery and classification. With this perspective at hand, we particularly investigate representation of eventn-grams that characterize activities in terms of their fixed length event subsequences.Exploiting this representation, we propose a computational framework to discover the various activity-classes takingplace in an environment. We model these activity-classes as maximally similar activity-cliques in a completely connectedgraph of activities, and describe how to discover them efficiently. Moreover, we propose methods for finding concisecharacterizations of these discovered activity-classes, both from a holistic as well as a by-parts perspective. Using suchcharacterizations, we present an incremental method to classify a new activity instance to any one of the discovered activity-classes, and to automatically detect whether it is anomalous with respect to the general characteristics of its membershipclass. Our results show the efficacy of our framework in a variety of everyday environments, including a Loading Dock area,a Household Kitchen, and a Residential House environment.9.1. Main conclusionsIn the following we describe the main conclusions of our work.9.1.1. Learning global activity structure using local event statisticsThe key conclusion of this work is that if we describe everyday activities in terms of an appropriate set of events,the structural information of these activities can be uniquely encoded using statistics of their local event subsequences.At the heart of this idea of learning activity structure using event statistics is the question whether we can have suchan appropriately expressive yet robustly detectable event vocabulary to describe human activities in a variety of everydayenvironments. There exists an inherent tradeoff between the expressiveness of events and the robustness with which theycan be detected using low-level perceptual information. The way one strikes a balance between these two opposing factorswill impact the kinds of analysis we can perform on the activities taking place in an environment.9.1.2. Specificity versus sensitivity of sequential representationsAnother tradeoff we came across over the course of this work is between the specificity to which a representationcaptures the structure of a sequential process, and its sensitivity to sensor noise. While n-grams for smaller values of nonly encode activity structure up to a fixed temporal scale, and are therefore less exact and more lossy, they are at thesame time more robust to various perturbations brought about by the sensor noise. On the other hand n-grams with largervalues of n are able to capture sequence structure over longer temporal scale, therefore encoding the structural informationmore exactly. However, their greater specificity results in their higher sensitivity to sensor noise. We saw this trend in thesimulation experiments of Section 3.1.9.1.3. Behavior discovery using feature based view of activity-classesIn this work, we have taken on the problem of unsupervised discovery of human behaviors with a feature-based viewof activity-classes. This view posits that members of an activity-class generally share a set of common properties that makethem perceptually similar to each other. For instance, activities of frying omelets look similar to each other as they mostlyrequire events such as beating eggs followed by frying them. We believe that our representation of modeling activities asconjunctions of their sequential features supports a notion of their perceptual similarity that can be used for the unsu-pervised discovery and characterization of various human behaviors. We have shown that posing this question as a graphpartitioning problem by modeling activity-classes as maximal cliques of nodes in activity-graphs is a plausible way of solvingthis problem. Moreover, we showed that using the framework of Dominant Sets is an efficient means to this end.9.1.4. A detection based approach to finding anomalous behaviorsOne application of our proposed computational framework is automatically finding activities that are in some senseirregular or anomalous. As anomalies are rare occurrences with large variation amongst them, traditional approaches thatattempt to learn explicitly defined models of anomalies do not generalize well. In this work, we have approached theproblem of finding anomalous behaviors from a detection rather than a recognition based perspective. As the notion ofanomaly is closely related to what is meant by regular, we have modeled anomalies as activities that deviate from behaviorsperceived as regular in an environment. Using discovered activity-classes to learn the notion of regularity in an environment,we have tried to detect anomalies that deviate from regular behaviors.Our research findings demonstrate that since all deviations from regular behaviors are not necessarily interesting, takinga purely detection-based perspective towards finding anomalies can in fact be too general. One way of striking a balancebetween the brittleness of an exclusively recognition-based perspective and the generality of a purely detection-based viewtowards anomalies, is to learn certain domain specific constraints on what makes various irregularities truly alarming. Howthese constraints should be modeled and learned for different environments remains an open question.1242R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12449.2. Current limitations & future research directionsAt present, there are several limitations of our framework that might be used as avenues for future research. Some ofthese are given in the following.9.2.1. Incorporating temporal information of eventsIn everyday environments, any particular event may take variable time to finish. In a household kitchen for instance,the event of taking something out of the refrigerator may take longer or shorter time depending on how many items arebeing taken out. This duration over which an event takes place can be an important discriminating factor to distinguishamongst various activity-classes. Furthermore, the event duration can be an important indicator about whether the eventwas performed correctly or not. At present, we are not incorporating any information regarding the duration that the variousevents take to be executed. A potential future direction of our work might be to investigate the extent to which consideringsuch temporal information of events is useful for activity analysis.9.2.2. Automatic parsing of activities in a stream of detected eventsCurrently, our framework assumes that the start and end of each activity is know a priori. However, there are manyenvironments where such explicit demarcations of the start and end of activities are not available. One way of inferringthese demarcations is to use the occurrence of event motifs in the event stream that are maximally mutually exclusiveamongst the various activity-classes. We leave the exploration of such an approach to temporally segment activities fromevent streams as a part of our future work.9.2.3. Analyzing group activitiesCurrently, we are only focusing on activities where one agent performs one event at a time. However, there is a largeclass of activities where multiple agents simultaneously perform multiple events. An important question to explore in thefuture would be how can our proposed framework scale up to efficiently analyzing such simultaneous streams of events.9.3. Concluding remarks & discussionWe conclude with discussion regarding choice of an appropriate event vocabulary, and the general applicability of ourproposed framework.9.3.1. Choosing an appropriate event vocabularyThe choice of a particular set of events to describe the in situ activities determines how strictly or loosely defined thestructure of these activities is. In the following we enlist some of the criteria for selecting an event vocabulary suitable fora computational system such as ours.(1) Events in an event vocabulary should be of finite duration and temporally local, i.e. events should have a finite durationbetween their start and end points, and this range should in general be reasonably smaller than the duration of anentire activity.(2) Events should not be temporally overlapping. In other words, each event must end before another event starts. Insituations where multiple events are being simultaneously performed by different agents, there must exist a mappingbetween which event is being performed by which agent.(3) Events in an event vocabulary should not occur spuriously and there needs to be a strict correlation between the actionof an agent which causes the occurrence of a particular event.(4) Events should have temporal atomicity, i.e., if there are two events in a vocabulary that cannot happen without be-ing temporally adjacent to each other, then they should be merged to one, provided that the merged event can stillbe robustly detected. This condition supports a minimal sized event vocabulary, resulting in reduced computationalcomplexity.(5) An event vocabulary should be complete with respect to spanning the various occurrences of interest that can transpirein an environment.A key factor to consider while choosing event vocabulary for an environment is the inherent tradeoff that exists betweenhow well does a set of events capture the underlying structure of activities, versus how robustly these events can bedetected using some low-level perceptual information. There does not exist a set of hard and fast rule according to whichthe granularity of constituent events should be selected, however in general this choice should be made based on thedynamics of an environment, and the available sensor modalities.9.3.2. General applicability of the proposed frameworkThe usefulness of a computational framework for activity analysis depends on the general characteristics of variousactivities that take place in an environment. Everyday environments can have a wide range of activity dynamics. On oneend of this spectrum are the environments where activities with strict and well defined structure take place. Examples ofR. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12441243such environments include assembly lines on factory floors, missile installation sites, or runways of aircraft carriers, wherea very strict regimen is followed. For such environments, our proposed framework is overkill, and more grammar driven-approaches would work better. On the other end of this spectrum are the environments where activities show a very looselydefined structure. Examples of these include kindergarten playgrounds, scenarios of loitering at a subway station, or simplyhanging out in the living room. Since there is not enough repetitive activity-structure, our system would have difficultyin finding it. Somewhere between these two ends is the set of environments where the activity structure is neither toostrict, nor too loosely defined. Our proposed framework is geared towards this class of environments. Some of the generalcharacteristics of such environments are listed in the following:(1) Many different types of activities can take place in the environment, and the number of possible in situ activities is notnecessarily known a priori.(2) There exists enough variance amongst the instances of different types of activities so that it is not feasible to write anexplicit grammar-based model for the different activity classes.(3) Instances belonging to each type of activity require execution of multiple intermediate tasks (i.e., events) for theirsuccessful completion.(4) All instances belonging to the various activity types taking place in an environment can be described in terms of ashared set of events.(5) There exists a mostly common set of partially ordered constraints amongst the constituent events of any particular ac-tivity type. Constituent events of different activity types mostly adhere to sets of different partially ordered constraints.Some of the example environments that generally have the aforementioned properties include car repair shops, surgicaloperation theaters, or building construction sites.References[1] A. Apostolico, J. Bejerano, Optimal amnesic probabilistic automata, Journal of Computational Biology 7 (2000) 381–393.[2] J. Auguston, J. Miker, An analysis of some graph theoretical clustering techniques, Journal of the ACM 17 (4) (1970) 571–588.[3] T. Bailey, C. Elkan, Fitting a mixture model by expectation maximization to discover motifs in biopolymers, in: Proc. International Conference ofIntelligent Systems in Molecular Biology, 1994, pp. 28–36.[4] G. Bejerano, G. Yona, Modeling protein families using probabilistic suffix trees, in: Proc. of International Conference of Research in ComputationalMolecular Biology, 1999.[5] A. Bobick, Movement, activity and action: The role of knowledge in the perception of motion, in: Movement, Activity and Action: The Role of Knowledgein the Perception of Motion, Royal Society Workshop on Knowledge-based Vision in Man and Machine, 1997.[6] A.F. Bobick, S.S. Intille, J.W. Davis, F. Baird, C.S. Pinhanez, L.W. Campbell, Y.A. Ivanov, A. Schuette, A. Wilson, The kidsroom: A perceptually-basedinteractive and immersive story environment, in: Vismod, 1996.[7] M. Brand, N. Oliver, A. Pentland, Coupled hidden Markov models for complex action recognition, in: IEEE Conference of Computer Vision and PatternRecognition, 1997.[8] S. Calderara, R. Cucchiara, A. Prati, Detection of abnormal behaviors using a mixture of von Mises distributions, in: IEEE Int. Conf. on Advanced Videoand Signal Based Surveillance, 2007.[9] B. Chiu, E. Keogh, S. Lonardi, Probabilistic discovery of time series motifs, in: SIGKDD, 2003.[10] T. Choudhury, M. Philipose, D. Wyatt, J. Lester, Towards activity databases: Using sensors and statistical models to summarize people’s lives, in: IEEEData Engineering Bulletin, 2006.[11] A. Dey, R. Hamid, C. Beckmann, I. Li, D. Hsu, A cappella: Programming by demonstration of context-aware applications, in: SIGCHI, 2004, pp. 33–40.[12] R. Diestel, Graph Theory, Graduate Texts in Mathematics, Springer, 2000.[13] F. Duchne, C. Garbay, V. Rialle, Similarity measure for heterogeneous multivariate time-series, in: Proc. of the 12th European Signal Processing Confer-ence, 2004, pp. 7–10.[14] D. Gusfield, Algorithms on Strings, Trees, and Sequences: Computer Science and Computational Biology, first ed., Cambridge University Press, 1997.[15] R. Hamid, A. Johnson, S. Batta, A. Bobick, C. Isbell, G. Coleman, Detection and explanation of anomalous activities: Representing activities as bags ofevent n-grams, in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2005.[16] R. Hamid, S. Maddi, A. Johnson, A. Bobick, I. Essa, C. Isbell, Discovery and characterization of activities from event-streams, in: International Conferenceof UAI, 2005.[17] I. Heller, C. Tompkins, An extension of a theorem of Danzig’s, in: Linear Inequalities and Related Systems, Princeton University Press, 1956.[18] S. Hongeng, R. Nevatia, Multi-agent event recognition, in: Proc. of IEEE ICCV, 2001.[19] K. Ilgun, R. Kemmerer, P.A. Porras, State transition analysis: A rule-based intrusion detection approach, IEEE Transactions on Software Engineering 21(1995) 181–199.[20] Y. Ivanov, A. Bobick, Recognition of visual activities and interactions by stochastic parsing, IEEE PAMI 22 (8) (2000) 852–872.[21] A. Johnson, A. Bobick, Relationship between identification metrics: Expected confusion and area under a roc curve, in: IEEE CVPR, 2002.[22] D. Kirsh, The intelligent use of space, Artificial Intelligence 73 (1–2) (1995) 31–68.[23] J.M. Kleinberg, Authoritative sources in a hyperlinked environment, Journal of the ACM 46 (5) (1999) 604–632.[24] L. Liao, D.J. Patterson, D. Fox, H. Kautz, Learning and inferring transportation routines, Artificial Intelligence 171 (5–6) (2007) 311–331.[25] D. Minnen, I. Essa, T. Starner, Expectation grammars: Leveraging high-level expectations for activity recognition, in: IEEE Conference on CVPR, Madison,WI, 2003.[26] D. Moore, I. Essa, M. Hayes, Context management for human activity recognition, in: Proc. of Audio & Vision-based Person Authentication, 1999.[27] T. Oates, Peruse: An unsupervised algorithm for finding recurring patterns in time series, in: IEEE ICDM, Japan, 2002.[28] N. Oliver, E. Horvitz, A. Garg, Layered representations for human activity recognition, in: IEEE ICMI, 2002.[29] J. Patino, E. Corvee, F. Bremond, M. Thonnat, Management of large video recordings, in: AmI.d 2007 Ambient Intelligence Developments, 2007.[30] M. Pavan, M. Pelillo, A new graph-theoretic approach to clustering and segmentation, in: IEEE Conference of CVPR, 2003.[31] C. Piciarelli, G. Foresti, L. Snidaro, Trajectory clustering and its applications for video surveillance, in: Proc. of Advanced Video and Signal BasedSurveillance, 2005.1244R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244[32] Lawrence R. Rabiner, A tutorial on hidden Markov models and selected applications in speech recognition, in: Alex Weibel, Kay-Fu Lee (Eds.), Readingsin Speech Recognition, 1990, pp. 267–296.[33] V. Raghavan, C. Yu, A comparison of the stability characteristics of some graph theoretic clustering methods, IEEE Transactions on Pattern Analysis andMachine Intelligence 3 (1981) 393–402.[34] D. Ron, Y. Singer, N. Tishby, The power of amnesia: Learning probabilistic automata with variable memory length, Machine Learning 25 (1996) 117–149.[35] E. Rosch, C. Mervis, W. Gray, D. Johnson, P. Boyes-Braem, Basic objects in natural categories, Cognitive Psychology 8 (1976).[36] G. Salton, The SMART Retrieval System – Experiment in Automatic Document Processing, Prentice-Hall, Englewood Cliffs, New Jersey, 1971.[37] R. Schank, Dynamic Memory: A Theory of Reminding and Learning in Computers and People, Cambridge University Press, 1983.[38] Y. Shi, Y. Huang, D. Minen, A. Bobick, I. Essa, Propagation networks for recognizing partially ordered sequential action, in: Proceedings of IEEE Confer-ence on Computer Vision and Pattern Recognition, 2004.[39] C. Stauffer, W. Grimson, Learning patterns of activity using real-time tracking, IEEE Transactions on Pattern Analysis and Machine Intelligence 22 (8)(2000) 747–757.[40] G. Sukthankar, K. Sycara, Robust recognition of physical team behaviors using spatio-temporal models, in: Proceedings of the Fifth International JointConference on Autonomous Agents and Multiagent Systems, 2006, pp. 638–645.[41] J. Sullivan, A. Blake, M. Isard, J. MacCormick, Bayesian object localisation in images, IJCV 4 (2) (September 2001) 111–135.[42] A. Toshev, F. Brémond, M. Thonnat, An a priori-based method for frequent composite event discovery in videos, in: Proceedings of 2006 IEEE Interna-tional Conference on Computer Vision Systems, 2006.[43] P. Tse, J. Intriligator, J. Rivest, P. Cavanagh, Attention the subjective expansion of time, Perception and Psychophysics 66 (2004) 1171–1189.[44] S. Ullman, The Interpretation of Visual Motion, MIT Press, 1979.[45] M. Weinberger, J. Rissanen, M. Feder, A universal finite memory source, IEEE Trans. Inform. Theory IT-41 (48) (1995) 643–652.[46] A. Yuille, N. Grzywacz, A computational theory for the perception of coherent visual motion, Nature 333 (May 1988) 71–74.[47] H. Zhong, J. Shi, M. Visontai, Detecting unusual activity in video, in: Proc. of IEEE CVPR, 2004.