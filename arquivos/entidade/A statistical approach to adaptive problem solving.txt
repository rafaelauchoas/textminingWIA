ELSEVIER Artificial Intelligence 88 (1996) 101-142 Artificial Intelligence A statistical approach to adaptive problem solving Jonathan Gratch ‘**, Gerald DeJong b,l a Information Sciences Institute, University of Southern California, 4676 Admiral@ Way, Marina de1 Rey, CA 90292, USA h Beckman Institute, University of Illinois, 405 N. Mathews, Urbana, IL 61801, USA Received May 1994; revised February 1995 Abstract Domain independent general purpose problem solving techniques are desirable from the stand- points of software engineering and human computer interaction. They employ declarative and modular knowledge representations and present a constant homogeneous interface to the user, untainted by the peculiarities of the specific domain of interest. Unfortunately, this very insulation from domain details often precludes effective problem solving behavior. General approaches have proven successful in complex real-world situations only after a tedious cycle of manual experi- mentation and modification. Machine learning offers the prospect of automating this adaptation cycle, reducing the burden of domain specific tuning and reconciling the conflicting needs of generality and efficacy. A principal impediment to adaptive techniques is the utility problem: even if the acquired information is accurate and is helpful in isolated cases, it may degrade overall problem solving performance under difficult to predict circumstances. We develop a formal char- acterization of the utility problem and introduce COMPOSER, a statistically rigorous learning approach which avoids the utility problem. COMPOSER has been successfully applied to learning heuristics for planning and scheduling systems. This article includes theoretical results and an extensive empirical evaluation. The approach is shown to outperform significantly several other leading approaches to the utility problem. 1. Introduction There is a wide gulf between general approaches and flective solving. Practical success has come from custom [ 52,661, or other application systems specific techniques techniques * Corresponding ’ E-mail: dejong@cs.uiuc.edu. author. E-mail: gratch@isi.edu. approaches to problem like expert systems, reactive that require extensive human 0004-3702/96/$15.00 PII SOOO4-3702(96)0001 l-2 Copyright @ 1996 Elsevier Science B.V. All rights reserved. to complete. AI researchers have also developed domain independent algo- and constraint satisfaction algorithms. Unfortunately, show success, systems, while derived from a general it is usually only after extensive domain specific technique, bear more investment rithms such as nonlinear planning when general approaches adjustments. The resulting resemblance Adaptive problem tradeoff performance solvers to work well all about performance irrelevant problem to real-world on unseen or unlikely problems, fact, machine problem solving performance, adaptive problem solving learning to the custom approaches. solving in repetitive problem for the problems on other hypothetical is a potential means solving they actually for circumventing this generality/ situations. We want our problem solving. Pragmatically, a system’s overall performance may be enhanced. encounter problems. Worst-case behavior and we care not at is largely by sacrificing good behavior In to enhance Nonetheless, the capacity techniques have successfully demonstrated although in limited contexts [ 18,46,57,65]. in any general sense. is still far from realized The principal impediment to adaptive problem introduced to machine hypothesized adaptation actually automatically formance. Steve Minton refer to this difficulty of insuring performance discussed via search control heuristics progress on this issue understood, solving performance [ 15,40,48,53], and can fail to improve performance, in the context of improving called control under certain circumstances. the problem results solving is characterizing when an in improved problem solving per- to the term utility problem the average problem [ 531. Minton originally solving speed learning improvements rules. While there has been considerable the proposed methods are often ad hoc, poorly or worse, actually degrade problem Adaptivity can be an effective method for improving problem solving performance in through that to deduce a priori, as in the blocksworld domain where a block can never represented. On the other hand, the that real-world problems are often constrained experience. On one hand, the domain specification may implicitly embed constraints are difficult be atop itself, though distribution of tasks embeds many constraints For example, greater that can only be induced application may never contain from experience. towers of height in ways that only become obvious a particular blocksworld is not explicitly this constraint than three. Exploiting these regularities from characterizations can lead to clear performance of past problems. Most distributions improvements. Of course, look into the future to anticipate particular problems. However, the problem solver cannot exhibit it can generalize peculiarities intractable that may be exploited once detected. Conversely, even worst-case algorithms may perform well under certain distributions. For example, Goldberg suggests solved in 0( n2) time [ 221. that naturally occurring [ 5,561 or devising Recent work has focused on characterizing [3]. techniques it is available Research optimization [45] exploit construction [ 51, pp. 252-2851 the expected distribution these easy distributions information when that can exploit specific distribution satisfiability problems are frequently the fact of a problem better expected performance. solver with substantially of tasks can allow into self-organizing and dynamic that learning systems the In the next section, we provide a formal characterization decision problem theoretic solving performance terms. This introduces and casts in the notion of expected utility as a metric of through a space of the learning of the utility problem as a search J. Gratch, G. DeJong/Ar@cial Intelligence 88 (1996) 101-142 103 p&~!iEEJcy Fig. I. Learning transforms an initial problem solver into a new one. To accomplish this the learner must choose one of a set of possible transformations. several techniques transformations the COMPOSER algorithm, performs a probabilistic to ensure problem solving 3 describes problem. COMPOSER and incorporates describes an extensive evaluation of the approach for a domain compares average case analysis of the algorithm’s to be polynomial confidence favorably with existing approaches independent problem in the number of transformations a probabilistic for a problem solver with high expected utility. Section the utility approach space search through the efficiency of this process. Section 4 in the context of learning control rules that COMPOSER to avoiding the transformation solver. The experiments indicate complexity. COMPOSER’s to the utility problem. Section 5 provides an run time is shown in the statistical considered and required. Finally, we discuss some limitations and present conclusions. 2. A formal characterization of the utility problem algorithm learning Before a rigorous terize what the learning formal characterization makes precise and explicit should do, and it provides a structure and precise statements. can be constructed, we must explicitly charac- to achieve. In this section, we introduce a is attempting system of a general class of learning problem solvers. This formalism intuitive and often unstated notions of what a learning system for formal analysis, enabling us to make definitive Abstractly, a learning algorithm operates on an initial problem solver, transforming relative the effect of this change criterion and a pattern of tasks associated with the intended application. solver, where is assessed it to into a different problem some evaluation This is illustrated set of potential problem transformations To characterize utility [2] as a common argued for the merits of decision systems [ 41,64,67,7 1 ] and machine in Fig. 1 where a set of hypothesized transformations defines a solvers. The learning to adopt, where “good” outcomes, we use the decision the outcome of this decision framework for characterizing system must decide which hypothesized solver. theoretic notion of expected this decision problem. Doyle has is a new problem [ 131 and it has seen increasing theory as a standard for evaluating artificial acceptance, both in artificial intelligence intelligence at large learning in particular [ 30,35,45,69]. 2.1. Expected utility Decision theory relies on the observation can, under some natural assumptions, that preferences over different outcomes be characterized by a real-valued utility function. 104 J. Gratch. G. DeJoq/Art@cial Intelligence RR (1996) 101-142 Outcome A is preferred to outcome B iff the utility of A is greater than the utility of B. the same outcome. Even In an uncertain world, a decision may not always produce the next. The correct the best decision policy may do very well one time and poorly decision policy under uncertainty maximizes is characterized by a set of outcomes and a probability distribution over this set, and the expected utility of a decision of occurrence. is the utility of all possible outcomes weighted by their probability expected utility: a decision For learning, the characteristics solvers) problem (transformed preferences with a utility of choosing application a transformation are preferred. With decision of the intended application determine what outcomes these theory, we represent to be cast as the decision problem the learning expected utility. However, we require function, allowing that increases to obey the following two restrictions. probability as a random selection of tasks according Fixed distribution assumption. The pattern of tasks in the problem ment must be characterizable unknown) that there is some probability of occurrence associated with each task that is independent of the tasks already seen, and that this probability a common impose does not change with time. This is it does solving environ- to a fixed (but states over the domain of discourse. This restriction to a great many applications. However, that we discuss in Section 6. simplification that applies distribution limitations further set of preferences the expected utility hypothesis: from a problem solver and problem criterion must be expressed by a utility Expected utility assumption. The evaluation function. This is a function to a numeric value. The function must be chosen such that problem solver A is preferred over problem solver B if and only if the expected utility of A is greater than the expected utility of B. Decision for theory posits function must also be any consistent requires an efficient computable (or to problem to solve determine solver would the problem then be its average problem solving If the problem solver is semi-decidable, one could proceed by imposing a resource bound and assigning if the application could be the CPU cost to solve a problem it cannot be solved). This can be computed by actually attempting system. For example, function the time. The expected utility of a problem time for the given fixed problem distribution. some suitable utility value to the conclusion by the learning the utility that there exists such a utility [ 11, Ch. 71). The utility “I don’t know” and measuring function solver, [ 341). (see (see attributes. In many real-world It may not be immediately clear how to represent preferences in terms of a single situations, comparisons between actions are made on utility measure. In planning problems, we may care not only the basis of several performance about how fast a plan is created, but also about other attributes such as its execution cost to how to translate or robustness. A large literature [ 631). problems these “multi-attribute” the let PS denote a problem be be the utility of PS function and expected utility assumptions we can characterize value of a problem solver, D denote the probability in the decision into a single utility solver by its expected utility. Formally, for problem x E D, and U(PS,x) the set of possible problems With the fixed distribution in the domain, Pro(x) (see, for example, of occurrence expressible is devoted sciences J. Crutch, G. DeJong/Artifcial Intelligence 88 (1996) 101-142 105 on problem n. The expected utility of PS with respect to the distribution D, written ED [ U( PS) 1, is defined as: U(PS,x)PrD(x)dx (D continuous), u(ps,x)~D(x) (D discrete). 2.2. Composite transformations Next we must formalize the effects of learning. A learning algorithm maps some initial problem solver P&Id into a new problem solver PS,,. We ‘introduce the notion of a composite transformation to denote the structural changes performed to a problem solver in the course of learning. A composite transformation is whatever is required to transform P&d into P&~ and it may be built from several component structural changes. For example, the PRODIGY/EBL system [ 531 builds a composite transformation from a set of learned control rules. A given learning algorithm has the potential to produce a variety of composite transformations depending on the initial problem solver and the distribution of observed problems. This corresponds to the notion of a hypothesis space in classification learning and we characterize it as a set of possible composite transformations. Alternatively, this set can be thought of as the set of all problem solvers reachable by the learning algorithm. Note that this set will be quite large (possibly infinite) for any nontrivial learning approach. A composite transformation maps P&1,-J into some PS,,. The value of this composite transformation can be measured by the difference in expected utility between PS,,, and P&Id. This provides a metric for assessing the performance of a learning algorithm. 2.3. Optima&y versus improvement Expected utility defines a total preference ordering over a set of composite transforma- tions associated with a learning approach. The ideal learning algorithm would choose the composite transformation in this set with the highest expected utility. Such an algorithm can be considered optimal with respect to the set of entertained composite transforma- tions. One might consider optimality as part of the requirement for avoiding the utility problem-that is, a learning algorithm should not only avoid lowering expected utility, but it should avoid sub-optimal improvements as well. Unfortunately, optimality is an extremely expensive requirement. For many machine intractable to identify the optimal transfor- learning algorithms, it is computationally mation. For example Greiner shows the inherent difficulties when transformations are constructed from macro-operators [ 361. We have chosen, therefore, not to insist on optimality and instead we adopt a weaker requirement. In our analysis, when a learning algorithm adopts a composite transformation it must increase expected utility, but it need not be the optimal choice. In fact, just improving the problem solver may be beyond the capabilities of a learning algorithm. If all of the composite transformations lead to a decrease in expected utility, a 106 J. Gratch. G. DeJm~/Art~ficiul Intelligence 88 (1996) 101-142 learning algorithm solver unchanged. should ignore all of the transformations, and leave the initial problem 2.4. Unknown icformatiorl problem For a given learning problem there is some true but unknown expected utility asso- transformed problem solver: both the utility of a transformed system can only estimate by solving some randomly solvers. are typically unknown. A learning training examples. For example, a learning system might estimate ciated with each possible problem solver on any given problem, and the probability distribution over the space of this in- possible problems formation the through selected problems with the original value of a transformation and transformed improve the estimate, but it may still differ from the true expected utility due to sampling error. that a composite that a transfor- in fact it does not. Nevertheless, Unknown transformation mation in characterizing learning does not improve performance. Therefore, we adopt a probabilistic An algorithm which solves the utility problem may adopt composite negative expected utility as long as this event occurs with probability pre-specified information means a learning algorithm cannot guarantee the utility problem we would like to explicitly quantify transformations with less than some increases expected utility. There is always to increase expected utility when amount, which may be arbitrarily the number of examples would close to zero. the possibility is estimated requirement. the chance Increasing that 2.5. The utility problem (2) an initial problem A learning algorithm exhibits the utility problem when it lowers the expected utility of the initial problem solver. More precisely, given: ( 1) an application described by a utility to a fixed probability function, a set of problems, and access to problems drawn according distribution, (3) a confidence parameter, produces greater probability distribution. Under this definition, composite a learning algorithm to the fixed if an adaptive problem solver adopts some improve performance. We say # P&d and (b) with probability solver for this application, Hold, the utility problem whenever: it must, with high probability, exhibits solver PS,,, has lower expected utility than Hold, with respect I - 6, a learning this requirement. transformation, than 6, PS,,, if it satisfies transformed algorithm problem some (a) it solves the utility problem the utility problem, thus defined, Admittedly, solving is a weak requirement the utility problem on a is to is a measure of to solve trivial way does provide, however, algorithm. For example, one anything. What the requirement learning avoid learning confidence algorithm modifies a problem solver, while at the same time avoiding we may have confidence mance on problems drawn according this minimal would it is acceptable not to learn. While a general statement of these requirements the scope of this article, satisfied by our COMPOSER in whatever changes a learning algorithm may make. That is, if a learning the utility problem, that those modifications will improve problem solving perfor- Ideally, one restrictions on when is outside requirements to the same probability requirement with additional the subsequent system. like to strengthen section discusses some stronger distribution. J. Gratch, G. DeJong/Artificial Intelligence 88 (1996) 101-142 107 3. A solution to the utility problem The preceding framework not only defines the goal of a learning technique, it sug- system, which embodies to the utility problem. The effectiveness solution in terms of its expected utility, which can be estimated gests a natural can be judged level of confidence using statistical procedures. Beyond solving COMPOSER performance with high probability transformations before this basic solution can be realized tion outlines our strategies for addressing of the algorithm. of a transformation to an arbitrary the utility problem, our to improve of the domain and that must be resolved in an efficient and practical algorithm. This sec- these difficulties and ends with a presentation there are many difficulties are satisfied. However this basic solution, can be shown requirements that certain given 3.1. Incremental learning The most significant composite difficulty arises transformations. that can be exploited. In most there learning in how Frequently to efficiently is some techniques, investigate internal the vast set to structure a composite trans- (later we refer to atomic For example, SOAR constructs a new problem builds a learned control strategy transformations may share transformations consists of many individual atomic simply as transformations). chunks individual [46]. PRODIGY/EBL control rules components. [ 531. In such systems,composite of possible transformations formation modifications solver from from individual individual many given learning transformation transformations, an by making many local Instead of making a global decision among all possible composite system builds up a composite transformation This is analogous incremental decisions. The composability problem is the name we give to the problem of identifying an effective composite from multiple atomic to the planning problem. A planner does not transformations. the set of all complete plans. Rather it uses operators solve a goal by searching as to make learning operators. to to address solve a variety of goals, the particular for combination planning described solving can be viewed from this perspective, although operators can be flexibly combined In COMPOSER, we view atomic that it must be constructed In fact, most learning they are not generally Just as individual can be combined in such terms. transformations transformations inefficiencies. of problem incremental techniques individual progress. planning through atomic the acceptable independent measures 3.1.1. Operationality The composability criteria: problem constrains formation quality. A measure must ensure that locally beneficial into a beneficial local measures the other a measure, ily combined. Mitchell et al.‘s operationality hypothesis is to develop the quality of an atomic composite. One solution that assess to provide such a measure. in the final composite [ 141 are attempts transformations transformations that appear criteria local measures of atomic transformations trans- combine independent measures. These are of transformation transformation. With such and eas- independently [54] and Etzioni’s non-recursive Incidentally, these are both in- can be separately evaluated on sampled problems 108 J. Gratch, G. DeJong/Art$cial Intelligence 88 (1996) 101-142 dependent of the problem distribution of the transformations. as well, obviating the need for statistical validation independent measures are in general not possible. Atomic interact with each other in difficult as a source of difficulty transforma- to predict ways. Such interactions but have been over- in planning, in Section 4). hypoth- against detrimental (as illustrated and the non-recursive in learning, often with unfortunate independent measures consequences like operationality cannot provide even weak guarantees Unfortunately, tions potentially have long been recognized looked Simple syntactic esis, while useful heuristics, results. together consider is because illustration, trustworthy As an intuitive odor”. Another who is equally leaves”. Each rule alone may the problem of selecting a satisfactory improve our chance the rules there is one particularly served and is typically it. This they diminish evil dish, a large green blob of dough in a Xanthin sequence things that says “Don’t eat for interact. that smells of it may be this single that our two friends were warning us about, each in his own way. Each items whose only sin is to have in common with the horrible one. Furthermore, we must pay the waiter to allow us to sniff to leaf is. social situations we might be better off to of dishes at a Dim Sum restaurant. One seasoned patron advises “Avoid exude a faint hazelnut-like things prepared with Xanthin an enjoyable meal while Suppose hazelnut offensive entree rule avoids a single superficial the overhead of evaluating both rules: we must persuade each dish as it comes by and we must explain avoid Xanthin Depending simply to awkward forget both rules and risk a taste of the green doughy blob. Here, two rules avoid the same penalty. As there is no added benefit in point of fact, we have no idea what a Xanthin this dish but also eliminates other delicious leaves when, on our sensitivity in broken Cantonese leaf sauce. Indeed in eliminating it that we wish feature twice, the utility of the two together in isolation. A more subtle is sensitive the problem the first rule. to the context is not equivalent to the sum of their improvements interaction in which it is evaluated. A second rule that significantly change involves a rule that has an evaluation cost which alters cost of the average evaluation solving procedure may substantially To make this more formal, we focus on the problem of building a composite transfor- the control transformations are search control rules, as in PRODIGY/EBL mation where the atomic [ 531. Let utility be the negative of the time to solve a problem. Control duce the time to solve a problem by eliminating overhead: space to see if a portion of the search increases utility time saved minus evaluation However, since control rules the sum of the improvements search, but they introduce an evaluation rule’s preconditions must be matched at each node in the search rule a control cost. Thus, search evaluation criterion. rules is not time is a candidate interact, the improvement of the rules in isolation. if the benefits of less search exceed tree can be pruned. of multiple control for an independent this evaluation rules can re- In isolation, Let us quantify this. Consider the interaction between the control rules illustrated in Fig. 2. This shows a hypothetical searched by the initial problem under node 1. Suppose r and s are two heuristics respectively. is exhaustively that there are no solution nodes in sets R and S trimmed by r. 1 SI is similarly defined. When search space of fifteen nodes which 1 RI is the number of nodes to conclude that prune the nodes solver J. Crutch, G. DeJong/Art@cial Intelligence 88 (1996) 101-142 109 R-S = nodes saved only by r S-R = nodes saved only by s RnS = nodes saved by both rands M,. = Average match cost of r MS = Average match cost of s g = Average cost to expand a node Fig. 2. Example of interacting heuristics. r is checked six times used in isolation, at node 2 saving nodes 3-8 and at node 9 saving nodes 10-12. Heuristic eight times evaluation a node be g. twice: s is checked (i.e., 15 - ISI) and succeeds at node 1, saving nodes 9-15. Let the average cost of r be M,, the average cost of s be M,Y, and the average time to expand (i.e., 15 - [RI ) . It successfully applies Let U( X,p) be the utility of a problem solver using p. The interaction between are not additive: two rules on a problem the set of rules X on problem to which their utilities is the amount Residue=U({r,s},p) - [U({r},p> +U({s},p)] =~R-SI.M,-IRnS~.g. This residue measures the interaction if this value mations combine synergistically may prune sub-trees over which another control When using is negative, overlap utility in isolation interactions would seem benefit of atomic they avoid. The key point to preclude effective transformations. can potentially in the search combine between atomic rule tends to be expensive transformations. is positive. For example, one control The transfor- rule to evaluate. If the residue there maybe a large rules with positive to yield a strategy worse than neither. Such the is that two control for determining independent criteria the first rule, the average match cost of the second decreases. they engage interaction. For example, in a harmful 3.1.2. Incremental utility: a context sensitive measure While we cannot develop a general independent measure of atomic transformation quality, we can develop a context sensitive measure other atomic we can view a composite transformations transformation participating in the composite In particular, problem solvers: each with some expected utility. We adopt a context sensitive improves expected as a sequence of intermediate transformation. transformation that states how much a given atomic that accounts for the context of Ps~ld,PSl,PS2,...,PSnew, measure of utility if appended utility to an existing sequence of transformations. Let PS denote a problem solver and let PST = Apply(~, PS) denote solver incremental that results from applying an atomic utility of r to be the difference transformation between the problem the the expected utility of PS’ and r to PS. We define I IO J. Grtrtch. G. I~eJon~/ArtQicicd Intelligence 88 (I 996) 101-142 the expected utility of PS. 2 We denote conditional given problem change in expected utility provided by transformation incremental utility as AlJo(71PS), meaning the 7 over distribution D solver PS. We can state this formally as: or equivalently: [U(PS’,.r) - U(PS,x)lPrD(x)dx (D continuous), lU(PS’.x) - U(PS,x)]Pro(x) (D discrete). (2) The change in expected utility provided by a composite transformation is equivalent to the sum of the incremental utilities of each transformation: Our definition of incremental utility clarifies two important properties of transforma- on utility is dependent on the distribution D. tions. First the effect of a transformation Second, the effect is conditional the incremental the distribution incremental posite utility values. utility of a transformation will vary unpredictably or the problem indicates transformation without considering on the problem solver to which it is applied. In general, as we change either nature of identify a globally maximal com- explosive number of conditional that in general we cannot a potentially it is applied. The conditional to which solver utility 3.2. COMPOSER COMPOSER learning element ite transformation, utility. Additionally, we can show adopt a sequence of improving tence of such a sequence. requires it is guaranteed COMPOSER element with certain characteristics of training problems drawn randomly COMPOSER’s method for searching define on the method describe how the system achieves the constraints is a statistical approach that provides atomic transformations, that provably solves the utility problem. Given a (with pre-specified that, given sufficient if COMPOSER confidence) adopts a compos- to improve expected examples, COMPOSER will the exis- given transformations with high probability, as input a transformable (specified below), initial problem a utility solver, a learning and a source from the problem distribution. We next describe transformations. We then the set of composite Finally we transformations. function, for proposing atomic its statistical guarantee. ? In other learning algorithms incremental utility is simply referred to as utility. We feel the additional terminology helps to highlight the difference between the utility of a problem solver, which is of interest to the user, and the utility of a transformation which is only of interest to the learning algorithm. J. Gratch, G. DeJong/Art@cial Intelligence 88 (1996) 101-142 111 3.2. I. Overview Because they do not compose linearly, it is typically However, we want as great an improvement utility in conjunction with a greedy hill-climbing the set of possible composite transformations. solver and incrementally incremental solver that results utility. Each new transformation the previous from applying intractable to determine COMPOSER the best as possible. proce- its that is assessed transforma- from training utility incremental of problems. This hill-climbing transformations adopts begins interactions. One shortcoming is uses statistical methods according to estimate to the distribution the difficulty of negative to explore uses incremental sequence of transformations. COMPOSER dure search with the original problem are estimated with respect tion. COMPOSER examples drawn randomly approach successfully it cannot exploit positive to possess positive to the problem avoids interactions. Solutions, therefore, may be local optima. 3.2.2. Transformation generator COMPOSER requires a source of transformations for each step in the search. This is formalized into a set of candidate abstractly TG:PSxX+{q,... examples transformations. map the problem solver into some new, possibly SOAR can be viewed as a transformation training problem the single Etzioni’s STATIC system original problem as a function we call a transformation generator. This is a function , ok} that maps a problem solver and an optional set of training in the set should improved, problem solver. For example, takes the current problem solver and an impasse, and generates a set of chunks. that takes the solver and no training examples, and generates a set of control [ 141 can be seen as a transformation Each transformation that produced generator generator rules. 3.2.3. Statistical inference COMPOSER must estimate incremental utility from training stances for reasoning data and assess the about has favored worst-case These are quite useful to to be a function of a set of predefined parameters with unknown learning community techniques). theoretical (also called non-parametric statements but are too inefficient accuracy of these estimates. There are several philosophical these statistical issues. The computational statistical models make techniques provide a more practical alternative. is assumed Inference a popular parametric of prior knowledge We prefer frequentist the need for the specification insuring absolutely the probable performance to estimating alternative reduces about for most practical uses. Parametric In these, the distribution of utility values values. these unknown values from the data. Bayesian models are to worst-case models but they require of the alternative the specification transformations. on prior to avoid dependence so-called information, statistical models which have the efficiency of Bayesian approaches without information.3 When we must balance between efficiency, error does not exceed a bound and achieving and so have adopted reasonable of prior s There is controversy between Bayesians and frequentists as to which approach is more appropriate; in many cases it can be shown that Bayesian approaches with non-informative approaches. We do not take a stand on a Bayesian one without changing mapping of COMPOSER O-1 loss function issue. One might well contributions is to map the probability 6 becomes a bound on the expected to frequentist replace our frequentist model with of this work. The straightforward statement of Bq. (3) framework this interpretation, this the principal priors are equivalent loss of a decision. [ 2, p. 631. Under into a Bayesian theoretical into a I12 J. Gratch, G. DeJong/Art#cial Intelligence 88 (1996) 101-142 we err to the side of efficiency, as long there are good arguments are not exceeded when necessary. in practice. In Appendix A, we describe how to adjust that the error bounds this tradeoff COMPOSER must ensure that the overall error remains below some threshold S. Formally: To achieve (3) this, COMPOSER must account identifies a new transformation time for three sources of error. Each to adopt, it compares a set of estimates, one considered at that step. The first source of error is associated with COMPOSER for each transformation these estimates (there utility, even though somewhat step. Third, the error across all of these steps must be accounted it appears positive). Second, is some probability larger probability into a these individual of error for the overall decision of what to adopt at a given the final problem solver, PSnew, is produced as a result of several steps, and errors combine that a transformation has negative incremental for as well. We define the function Bound( 6, ITI ) , which specifies the acceptable error for a utility estimate as a function of the overall error, 6, and the size of the set of transformations, search: 4 T, at a given step in the hill-climbing Bound(6, ITI) avoids third sense, this definition the second and error of each individual into bound of 6. Given incremental issues. First we must determine Second we must decide how many accurate estimates. We can estimate incremental it remains utility of a transformation the utility problem by bounding incremental utility estimate) the first sense of error (the in such a way that as they combine the total acceptable the overall error remains below to construct a statistical procedure to the specified error bound. This that estimates two involves how estimates are generated training problems are needed from training problems. to attain sufficiently utility by randomly drawing problems according to the the resulting averaging incremental under consideration, utility the estimated solver, PS, a set of transformations, distribution D and, for each transformation from n utility values. Call =,,(~jPs) incremental and a training problems. Given a current problem problem X, COMPOSER must determine the current and each of the transformed problem solvers: Vr E T, U( PS’, x) - U( PS, x). Recall that, by the definition, behavior of the problem solver on the problem. Thus, given a set of m transformations, we can compute PS and then with PST’ PF problem solving attempts. The complexity of processing the problem with involves m + 1 tied to ,..., PFm. Processing each training example is measurable by observing utility values by solving the utility of a problem solver on a problem in utility between the necessary the difference an example is therefore incremental 4 This definition embodies a compromise between bounding statistical error and example efficiency which works well in practice. The rational behind the compromise is discussed in Appendix A, where we illustrate some other possible definitions. J. Cratch, G. DeJong/At@cial Intelligence 88 (1996) 101-142 113 A 5 -- 9 5 -- 9 -- ._ ------__m______ & Estimate 0 -. *. -. -. -. I 1 I __-- __-- 5 __-- I I __. --- I 10 I ---- 15 Training Examples --) Fig. 3. Sizing the confidence interval. We would like to take enough examples such that the confidence interval lies entirely above or below the axis. the complexity of each of the m + 1 problem solvers. We call this brute-force processing and it is the default method used by COMPOSER. We show in Appendix A that for many applications utility values. there are other more efficient methods the incremental for obtaining utility is estimated a sufficiently that incremental We can determine a suitable sample size by considering how the accuracy of estimates the number of examples used in the computation. Specifically, large sample size such that it can bound improves as we increase the COMPOSER must determine probability to be positive when in fact it is negative and vice versa. We would also prefer to use as few examples as possible. COMPOSER to determine how many examples are sufficient relies on a sequential statistical to make this inference fixed sample in advance, but is is not determined a function of the observations. Sequential procedures provide a test called a stopping rule that determines when sufficient examples have been taken. An important advantage of sequential to be significantly [23]. Sequential procedures differ from the more common is that the average number of examples in that the number of examples techniques technique required procedures less than that required by fixed sample the sample size using a stopping rule the stopping techniques. rule proposed by NGdas [60]. The is quite simple. Given a sample of values and a We determine behind tends level cr we can construct a confidence 1 - a. In other words, lies outside the confidence to shrink. 5 The stopping utility intuition confidence utility with probability incremental of the interval needed incremental 1 - (Y, that the transformation is positive for the interval (negative). tends utility, as illustrated interval containing the true incremental a that the true there is only probability interval. With more examples, the width rule determines how many examples are above or below zero to shrink to the point of being entirely in Fig. 3. At this point, we can state, with probability if the estimate incremental (negative) utility has positive After each example is processed the rule evaluates the Nhdas stopping to true. When transformation will speed up (slow down) PS if its estimated (negative) with confidence 1 - (Y. Examples are taken until rule is evaluated. Sampling this occurs we can state incremental that the utility the following terminates when given is positive equation holds: 5 The interval size is actually a random function of the data. It will tend to shrink with more examples, but not monotonically. It will grow, temporarily, if an outlying data point is encountered. 114 .I. Grutclt. G. De.lon~/Artijiciul Intelligence 88 (1996) 101-142 (4) where II is the number of examples erage improvement, ment, LY is the acceptable an initial sample size, and Q(cu> is a parametric between the true and the estimated incremental error S,‘( r/ PS) is the observed variance utility: taken so far, AU,,( TIPS) is the transformation’s in the estimate, 110 is a small in the transformation’s integer finite av- improve- indicating the discrepancy function that models Q( LY) := x such that Iy’ about statistical assumption the parametric The function Q(a) makes utility of this parametric model [38, p. 1921. This the true incremental is normally distributed of a random variable, about the true mean of the distribution. This theorem demonstrates incremental sonableness the Central Limit Theorem distribution distributed if the underlying mal for the purposes of estimating strictly holds only as the sample size tends to infinity, extensive experience problems has demonstrated small sample sizes (see is justified by an important states the average of these values will tend to be normally that even as nor- the Central Limit Theorem in real-world even with the effectiveness of this “normal approximation” expected utility. Although it can be accurately [ 39, Section 5.31). is non-normal, approximated distribution that the estimated utility. The rea- in statistics, that regardless of the theorem theorem The choice of minimum is in Appendix A. By default we use a sample size of fifteen which has worked size, 110, relates to the definition of Q(a) sample and discussed well in our empirical investigations. 3.2.4. The COMPOSER algorithm COMPOSER is illustrated its statistics and evaluates in Fig. 4. After each problem solving attempt, COMPOSER rule for each candidate transformation. the stopping If updates the stopping utility, COMPOSER invokes instead, stopping these are eliminated not affect candidates time a transformation higher rules are satisfied for one or more transformations with positive incremental the transformation with highest adopts the transformation generator to obtain a new set of candidate rules are satisfied for transformations with negative that eliminating from further consideration (note the current problem are unaffected). This cycle repeats until solver, so the statistics associated with is adopted than its predecessor, giving COMPOSER the training the expected utility of the resulting problem solver an anytime behavior [ 71. transformations. incremental incremental utility, and If utility, a candidate does the remaining set is exhausted. Each is 4. Utility problem in the PRODIGY problem solver This section describes one of two extensive evaluations we have performed with the search system. We describe an application of COMPOSER to learning COMPOSER .I. Gratch, G. DeJong/Art@cial Intelligence 88 (1996) 101-142 115 COMPOSER(PS,ld, TG( s), 8, examples, 4) 1. PS := P&d; T := TG(PS); n := 0; i := 0; cy := Bound(6, ITI); 2. While T # 0 and i < [examples1 do 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. /* Hill-climb Repeat as long as there is data and possible transformations */ /* Until enough data taken to identify next step */ n := n + 1; i := i + 1; step-taken ‘Jr E T: Get AUi(71PS) := FALSE; /* Observe incremental utility values for ith Problem */ signi$cunt := {Q- E T: n >, no and /* Collect all transformations that have reached statistical significance */ (S,2(~lPS))/[~u,(~lPS)12 < n/[Q<412} If 3 E signi@znt: E,, (~1 PS) > 0 Then /* Adopt T that most increases expected utility */ PS = Apply( x E significant: Vy E signr$cant [bU,(xlPS) T := TG( PS); n := 0; LY := Bound( S, ITI); step-taken > acl,(ylPS)],PS) := TRUE; Else T := T - {r E sign$icant: %?,(~lPs) transformations /* Discard < 0) that lower expected utility */ Until step-taken or T = 8 or i = Iexamples j ; Return PS Bound(S, ITI) := S/lTI, Q(a) := x where s,“( 1/&)e-0.5J2dy = a/2 Fig. 4. The COMPOSER algorithm. is described elsewhere [ 261. for the PRODIGY planning that has served as the basis for several system learning [ 531. PRODIGY the status of a benchmark for learning investigations systems. COMPOSER is a well studied [ 15,43, has for to the problem of learning heuristic control strategies control strategies planning system 531 and has attained also been successfully a NASA scheduling domain, which A main goal of this evaluation applied is to contrast COMPOSER’s approach with several including methods developed explicitly for addressing the utility problem, system as well as a more general other methods for the PRODIGY COMPOSER. We would like to compare than implementation minimizing the context of the PRODIGY problem solving system and each method use PRODIGY’s of learned to rather by is re-implemented within to (discussed below) as the source statistical the theoretical basis for these alternatives details. Therefore, we take pains to provide a fair comparison the systems. Each method the differences between transformations. is constrained explanation approach approach learning similar based 4.1. The application This available problem implementation is constructed within the PRODIGY 2.0 architecture which is from Carnegie Mellon University. PRODIGY solver based on the STRIPS planner is a general purpose means-ends [ 181 with a few enhancements. Plans are 116 J. Gmrch, G. DeJon~/ArtiJicicrl intelligence 88 (1996) 101-142 identified by depth-first decisions: search. Search proceeds by recursively applying four control ( I ) choosing a node to expand in the current search space (where a node contains a conjunction of goals, some of which may already be achieved), (2) choosing an unachieved goal at that node, (3) choosing an operator that possibly achieves (4) choosing a binding list for the operator. a default control method implements PRODIGY methods may be modified by the introduction rules are described rules. Control in Section 6.2. the goal, and for each of these decisions and these called control of heuristic knowledge 4.1. I. Problem distributions We evaluate COMPOSER’s domain was reported on three different domain problem of a robot moving boxes through AB-WORLD domain, designed BIN-WORLD in both PRODIGY/EBL construction domain was introduced to highlight deficiencies domain. ability to identify effective modifications theories. The STRIPS domain was reported interconnected It is a rooms with lockable doors. The to PRODIGY in [53]. in [ 161. It is a variant of the standard blocksworld in Minton’s PRODIGY/EBL approach. The in [ 301 and was designed and Etzioni’s STATIC approach. This domain to highlight deficiencies is a simple Problem distributions for the STRIPS domain and AB-WORLD generators 2.0. Following provided with PRODIGY the set of problems was biased by filtering out problems the problem in [53], too difficult or too easy; problems were excluded I CPU second or more than structed with methodology were judged control Problems deficiencies detailed description of the experiments in PRODIGY/EBL strategy required less for the BIN-WORLD were generated domain are con- the that if the default PRODIGY than 100 CPU seconds. to highlight in Appendix B. A more designed and STATIC. This is described appears in [ 241. in a distribution 4.1.2. Expected utility We follow the established PRODIGY methodology in CPU seconds time by the cumulative interpretation theoretic the decision solving (e.g. performance [ 16,531). Under this In function based on the time required is captured particular, we let the utility of the problem solver over a problem be the negative of the CPU time required translates into “improving” to solve the problem. Maximizing time required to solve a set of problems of the evaluation expected utility therefore to solve a problem. to solve a problem. of measuring as a utility the average criterion, problem 4.2. Transformation generator Minton introduced a technique for generating control strategy. The approach uses explanation struct atomic search control theory of the problem four control points. The search control rules are condition-action the way PRODIGY atomic modifications based learning rules based on traces of problem of the PRODIGY [ 12,541 (EBL) to con- solving behavior and a rules can be associated with any of the statements which alter the space of possible plans. solver. Sets of control explores J. Crutch, G. DeJong/Artifcial Inrelligence 88 (1996) 101-142 117 RULE-l: IF current-node is ?n current-goal at ?n is (CLEAR ?x) (NOT (HOLDING ?x)) is true at ?n THEN choose operator UNSTACK Fig. 5. An example of a control rule. PRODIGY/EBL generates rejection and selection control rules which are guaranteed sound in that they do not prune valid solutions from the search tree, 6 In particular, to acquire a rejection control rule, PRODIGY must show that a particular decision cannot even in principle lead to a successful outcome. PRODIGY performs a full tree search of all viable options. If no success node is encountered in this exhaustive search, PRODIGY re-expresses the conditions that describe the failure in a way that can be tested at the node itself. Under these conditions, there is no point in conducting the search since it is doomed to fail. The rejection rule prunes this decision for future searches. Likewise, a selection control rule can be acquired only if all ways but one of resolving the decision lead to failures. If resources are exhausted before a full search has been completed, then no rules can be learned from this portion of the tree. This is a limitation of the approach but fortunately, even in recursive domains, there are usually enough fully explored sub-trees to learn useful control rules. An example of an operator selection rule is shown in Fig. 5. Under the conditions of its antecedent, all operators except UNSTACK necessarily lead to failures. While control rules are sound, they may not increase the efficiency of planning. All control rules avoid search in the plan space, but they introduce the cost of matching their preconditions. A rule is harmful when the precondition evaluation cost exceeds the savings. Furthermore, control rules interact in subtle ways. Without a criterion for choosing among possible rule sets, the learning algorithm quickly degrades performance. Minton introduced a heuristic empirical procedure for addressing the utility problem in this context. This procedure attempts to account for the distributional nature of the incremental utility of individual control rules. Minton calls the overall approach of EBL learning and heuristic utility analysis PRODIGYIEBL. Unfortunately, while it performs quite well on some domains, PRODIGY/EBL has since been shown to have undesirable properties. Etzioni illustrated how seemingly innocuous changes to a domain theory result in degraded problem solving performance [ 151. We showed that this behavior is due to the utility procedure’s inability to correctly estimate distribution information and to handle the composability problem (see [ 291) . COMPOSER’s statistically sound utility estimation procedure corrects these problems and should result in a more effective learning algorithm. “The EBL unit used in PRODIGY/EBL can produce three control rule types: rejection, selection, and preference rules. Preference rules, in fact, can lead to incorrect action selection. Minton has noted that preference rules seem to be less effective. We have verified that PRODIGY/EBL actually produces strategies with higher utility if it is prevented from producing preference rules [29]. We disabled the learning of preference rules in this implementation because it enabled a more efficient means of gathering incremental utility data points (see Appendix A). II8 J. Gmtch, G. DeJon~/Artijiciul Intelligence 88 (1996) 101-142 For this evaluation, the EBL component of PRODIGY serves as the transformation analyzes a trace of each solution attempt and conjectures search control rules serves as an atomic rules. Each of these control generator. The EBL component new control current system, our actual use of this transformation usage all at once (as in lines 1 and 3 of the algorithm), to the set T after each problem (line 8 of the algorithm), to the new transformation strategy. To be more consistent with its use in the PRODIGY from its normal to be conjectured added is adopted are carried forward transformations their statistics are discarded. all previously conjectured set, though generator differs somewhat solving event. Whenever (Fig. 4). Rather a transformation in COMPOSER transformation to the transformations transformations are potentially than forcing 4.3. COMPOSER implementation details to construct an adaptive problem solver for the three applica- We used COMPOSER tions. We call the resulting PRODIGY with COMPOSER/PRODIGY. no control rules acts as the initial problem solver. Minton’s EBL learning element acts as solver the transformation with the empty set of control adding control takes the problem a PS,,, generator. Thus, COMPOSER/PRODIGY rules as P&d and produces rules with positive by incrementally implementation incremental utility. control extracts this, we modified procedure of using attempt. To accomplish allowed us to tailor COMPOSER Several properties of this application between adopted and candidate control utility data points. The implementation rules with an unobtrusive to achieve rules to more efficiently greater statistical efficiency. We exploited a property of control utility incremental gather incremental the trace values for all candidate the PRODIGY planner of a single solution rules are to distinguish utility and have been added those which have been shown into the control strategy of the PRODIGY planner. Candidate rules are those that have been proposed by the EBL technique, but not yet validated. When solving a problem, they would candidate rules are checked, are recorded, but the search paths are not actually eliminated. After a problem eliminate those search paths which is solved, would have been eliminated by candidate control these the savings which would be provided by the rule. This savings avoidable paths indicates is reported is compared with the recorded precondition match cost, and the difference as the incremental to identify rules. The time spent exploring cost and the search paths rule for that problem. ’ rules. Adopted control trace can be analyzed utility of the control their precondition to have positive the annotated incremental 4.4. Evaluation We evaluated COMPOSER/PRODIGY’s the utility problem: for addressing criteria performance against four other proposed ‘Appendix A describes how for some applications the Bou~zd function can be modified to improve the efficiency of utility analysis. For this implementation we used Eqs. (A.2) and (A.?) of the appendix to define a variant of the default Bound. As stated in Section A. I. I, this allows transformations to be added to T at any low variability of control rules, we used a minimum no = 3. time in the utility analysis. Due to the relatively J. Gratch, G. DeJong/Artificial Intelligence 88 (1996) 101-142 119 ( 1) the heuristic utility analysis of PRODIGY/EBL (2) (3) a hybrid of PRODIGY/EBL hypothesis of STATIC [ 141, and STATIC suggested by Etzioni the non-recursive [ 531, [ 141 to overcome limitations of the two systems, and (4) PALO [ 351, a statistical approach similar to COMPOSER but based on a more conservative statistical model. the experiments we review differences problem between solving these techniques. the evaluations the systems. All systems are implemented transformation the same and use For framework Before discussing we tried within generator. to minimize the PRODIGY 4.4.1. PRODIGYIEBL’s utility analysis This technique, developed by Minton rules are proposed, (the example problem for use in PRODIGY/EBL, strategy. The savings afforded by each rule is estimated transfor- adopts they are added from a and this value to the rule each time it applies. Match cost is measured directly from problem the from the current control strategy. The issue of are gathered as if there mations with a heuristic utility analysis. As control to the current control single example is credited traces and averaged across multiple savings, cumulative interactions among were no interactions. the rule is removed transformations If the cumulative cost exceeds is not addressed-estimates the rule was learned) training examples. from which 4.4.2. STATIC’s non-recursive STATIC utilizes a control of utility. The criterion is effective when “EBL [ 14, p. 61. The hypothesis that transformations if they are generated predicate A weaker constructed negative performance addressed. STATIC applies macro-operators For Etzioni, in a subgoal reading from non-recursive incremental the explanation hypothesis rule selection criterion based on Etzioni’s structural is grounded it is able in the non-recursive to curtail admits several search via non-recursive The strongest interpretations. explanations” interpretation is hypothesis. This states theory that have positive incremental utility, regardless of problem distribution, from non-recursive explanations of planning behavior (i.e., no is derived using another instantiation of the same predicate). is that a composite elements strategy will (admitting utility, but a set of non-recursive on average). The issue of interactions this criterion to control as well [ 47,681. improve expected utility if it is that some transformations will have improve is also not in between rules but the issue transformations transformations is important will of a control the PICKUP operator has no chance of leading another proposition with tree contains that executing proof suppose some blocksworld that the PICKUP operator should be pruned that matches alizing why PICKUP necessarily explanation includes a requirement some inferences by “CLEAR(B)“. rule from consideration is recursive to a solution if any proposition in its the same predicate name. For example, in rule stating in any future situation are constructed by gener- that the example’s through to a strong is recursive. According control of “CLEAR(A)” which is in turn supported This explanation the conditions of this one. The precise conditions problem. PRODIGY would acquire a rejection fails in this example. Now suppose 120 J. Gmtcch, G. DeJong/ArtiJicial Intelligence 88 (1996) 101-142 reading of the non-recursive the overall utility. hypothesis, the associated control rule could not improve reason for this success [ 1.51 .8 This claim of the non-recursive is cited as a principal on several domains. The non-recursive STATIC outperforms PRODIGY/EBL’s as the two algorithms to construct use different their respective control pothesis to evaluate ies are also employed the effectiveness plicating NONREC algorithm, the PRODIGY/EBL analysis with a syntactic criterion which only adopts non-recursive acts as a filter, only allowing PRODIGY/EBL that satisfy hy- is difficult rule generators. Different vocabular- rules, We wish to focus on the com- the hypothesis within empirical utility rules. This rules. All rules hypothesis, rule generator. To achieve a re-implementation framework. NONREC into the final problem solver. and therefore must remove of STATIC’s non-recursive replaces PRODIGY/EBL’s criterion are incorporated this goal we constructed to generate non-recursive factor of a different the non-recursive control 4.4.3. A composite algorithm that the strengths of STATIC and PRODIGY/EBL [ 141. He proposed a hybrid algorithm which embodies including a two layered utility criterion. The non-recursive can he combined several hypothesis acts to utility non-recursive control rules are subject Etzioni suggests into a single approach advancements as an initial filter, but the remaining analysis and may be later discarded. the NONREC-UA We implemented rules are proposed by PRODIGY/EBL’s basis of the non-recursive PRODIGY /EBL. algorithm learning module, to test this hybrid criterion. As control they are first filtered on the rules undergo utility analysis as in hypothesis. The remaining 4.4.4. PALO’s Chernoff bounds Greiner and Cohen have proposed an approach similar to COMPOSER’s [ 331. The approximately and evaluates that rule and probably technique stopping terminates in the transformation is based on Chernoff bounds. locally optimal transformations it incorporates learning when it has (with high probability) space. Our evaluation a criterion (PALO) by a statistical method. PALO differs approach also adopts a hill-climbing for when to stop in its learning. PALO identified a near-local maximum rule which focuses on the different stopping Chernoff bounds provide a much more conservative model of the discrepancy between the sample mean and true mean of a distribution. As a result, PALO provides stronger that if the user bounds on statistical error but at the cost of more examples. This means specifies an error level of 6, the true error level will never exceed 6, and may in fact be much PALO-RI uses a candidate learning begins. A candidate this approach. Like COMPOSER, set of rules. In this case, the size of the set is fixed before lower.9 Our PALO-RI algorithm evaluates is adopted when the following rule holds: stopping ‘Etzioni and Minton have subsequently suggested that some of the success of STATIC is due to the fact that its global analysis allows for more concise rules [ 17 1, ’ In addition to the conservative stopping rule, PALO adopts the conservative definition of Bound that follows from adopting Eqs. (A. I ) and (A.5). whereas COMPOSER adopts Eqs. (A. I ) and (A.3). J. Crutch, G. DeJong/Art@cial Intelligence 88 (1996) 101-142 121 n .KG,(T(PS) > A7 2nln J ( Tm,,( h + 1 )W 36 > where hU, ( TIPS) is the estimated size of the largest possible to the current transformation search), transformation: and & candidate sequence incremental utility of transformation set, h is the number of transformations (the number of steps taken 7, Tmax is the added in the hill-climbing is the size of the range of incremental utility values for a given A7 = max {AV,(rlPS)} - m,in{A0:(r\PS)} true value is strongly performance and minimum is typically unavailable is that its sample complexity A disadvantage of the technique utility values as tightly as possible without underestimating (as its depends on the maximum transformation). effected in advance improvement To use this method, one must be able to bound the that all by the setting of AT, a parameter whose of learning possible by a given the range of incremental true range. In the context of PRODIGY, one can set an upper bound by noting problems are restricted most a transformation for our purposes. Rather, we bound A7 by the maximum to solve problems from the training require knowledge provide is 100 seconds. This seemed too conservative time PRODIGY actually requires learning. Using a tighter bound would to help; to to be solvable within a resource bound of 100 CPU seconds-the could help (or hurt) set before of how much to the other learning some detailed knowledge that was not provided systems and thus seems unfair transformations are expected to PALO-RI. PALO-RI uses the same method as COMPOSER/PRODIGY to obtain the setting of the system’s various parameters incremental in the next utility statistics. We discuss section. sampling test that terminates One advantage of PALO not included in PALO-RI, if the incremental threshold. data when the best transformation to fall below a pre-specified tional recognized pend considerable in performance parameter corporates an indifference includes a detailed discussion of the tradeoffs to as indifleerence zone methods are referred (see Section 5). Methods which incorporate zone into a COMPOSER-like method is that it incorporates an addi- is utility of all transformations In contrast, COMPOSER may ex- leads to a negligible improvement this additional “don’t care” [ 11. Our more recent work in- [ 251. That paper also imposed by such approaches. 4.4.5. Experimental procedure We investigated the STRIPS domain from [ 531, the AB-WORLD domain produced harmful strategies, and the BIN-WORLD [ 301 which yielded detrimental for which PRODIGYIEBL from learning we The problem distributions were constructed provided with the PRODIGY criteria. Results are summarized results for both STATIC’s and PRODIGY/EBL’s in Fig. 6. In each domain, using the algorithms the random problem generator rule set was saved after architecture. The current control from [ 141 domain 122 .I. Grtrtclr. G DrJo,lS/Art~~fir,ictI lntelligrnce 88 (I 996) IO/-142 from training is the execution for the experiments times using distinct training examples. “’ The independent measure every twenty is the number of training examples and the dependent measure time in CPU seconds over 100 test problems drawn the same distribution. This process was repeated eight the same and to problem generator. All results reported are the average of these eight trials (rounded the nearest whole number). Fig. 6 shows the comparison graphs along with the number the 100 of rules for the 100 training examples, and the number of seconds required is set at test problems. COMPOSER IO% for the experimental whose optimal values are difficult given the information influenced by parameters to assess. We tried to assign values close to optimal require an error parameter 6 which runs. PALO-RI’s behavior learned by the algorithm, the number of seconds to generate solutions test sets constructed and PALO-RI to process is strongly available required from the evaluation, but this proved examples wcrc required; During tions within to reach quiescence many training harmful statistics on PALO-RI we only performed one instead of eight more. we terminated PALO-RI examples, whichever came first. that PALO-RI would not adopt any transforma- the 100 training examples. We tried to give the algorithm enough examples too large since To collect trials. Further- the first transformation was adopted or 10,000 too expensive. The problem the candidate rules were not discarded as quickly as in COMPOSER/PRODIGY. is twofold-first, set grew secondly, learning after to us. ” it was apparent The results illustrate exceeded interesting several the performance features. The implementation of all other approaches developed with in every domain. The COMPOSER learned fewer control beneficial control strategies. mations. domain. Therefore, than differences the results strategies yielded higher expected utility and were more succinct and STRIPS, COMPOSER/PRODIGY In AB-WORLD rules). In BIN-WORLD, In fact, it does not appear It should be stressed that any control that all algorithms USC the same transformation (containing identified the algorithm did not adopt any transfor- in this rule improves performance generator. rather to the utility problem represent differences in approaches in the vocabulary of transformations. We expected COMPOSER/PRODIGY to have higher learning times than PRODIGY/ EBL or NONREC due to its more rigorous Surprisingly, and COMPOSER/PRODIGY quickly discarded a control rule with high match cost which PRODIGY/EBL, NONREC, times were not much higher than the non-statistical learned more quickly on BIN-WORLD where it in their assessment of incremental utility. approaches the learning actually I” PRODIGY/EBL’s utility analysis requires an addttional settling phase after training. Each control strategy produced by PRODIGY/EBL and NONRECfUA received a settling phase of 20 problems following the methodology outlined in 15.3 1. ” C was fixed based on the size of the candidate list observed in practice. In the best case, a rule can save the entire cost of solving a problem, so for each domain, lambda for each rule was set at the maximum problem solving cost observed in practice. AR-WORLD: C = 30. A = 15: STRIPS: C = 20. A = 100; BIN-WORLD: C=S. A= 150. emTinoituloSegarevA)melborprepsdnocesUPC(eiTnoituloSegarevAeiTnoituloSegarevA       124 .I. G-arch, G. DeJong/Artijicid Intelligence 88 (1996) /O/-Id2 hypothesis difference cannot completely account to the fact that STATIC and rules. In our experiments, we in AB-WORLD. The non-recursive the remaining no learning for this difference. We attribute NONREC entertain constrained NONREC while in Etzioni’s experiments STATIC entertained This conjecture was recently somewhat different sets of control to use the rule vocabulary which was available to PRODIGY/EBL a somewhat different space of rules. supported by Minton and Etzioni Finally, although PALO-RI did not improve performance within the 100 training exam- the other approaches. This to converge is selected. Thus, the transforma- fact, the initial the large sample sizes required by PALO allow utility estimates to their true values before any transformation likely outperform to be selected it would [ 171. tend utility rules allowed PALO-RI first. (In to exceed COMPOSER/PRODIGY’s given extended examples.) In contrast, COMPOSER as- utility and the variance of utility values when determining has reached significance. This results in COMPOSER transformations more quickly. Unfortunately is very high, both in terms of examples and learning somewhat less beneficial strategies, recog- the cost of PALO’s time. it achieves much the higher incremental ples, if given sufficient examples is because closely tions with selection of better control performance sesses both when a transformation nizing performance While COMPOSER may identify faster convergence. in AB-WORLD incremental low variance improvement 5. Complexity results We now turn to an analysis of the COMPOSER algorithm. Given our emphasis on the aspects of the algorithm, our analysis will not consider worst-case behavior. practical for both sample results Rather, we provide average case complexity complexity, and run time complexity of the algorithm. We focus on the number of examples and the amount of work required the total steps taken, but this is domain complexity will depend on the number of hill-climbing specific. to perform a single step in the hill-climbing the number of examples to make a statistical search. Obviously, for the algorithm inference, required The number of examples taken at a hill-climbing to complexity factors, but these can be related amount of work at a step depends on the number of candidate step and we can specify of transformations. With such knowledge, the transformation to organize the exact function for a specific relationship a user of COMPOSER generator in meaningful ways. For example, step also depends on domain specific the at that transformations between work and the number can assess how best learning problem. 5.1. Properties of the Ncidas stopping rule The properties of COMPOSER inference. Therefore, we first consider Given some transformation many examples are sufficient tive) with probability 7, and an error level a, this stopping the characteristics follow from the properties of its method for statistical rule. rule determines how (nega- rule have been proven of the Nadas stopping utility of 7 is positive of this stopping to show that the incremental 1 - LY. The characteristics J. Crutch, G. DeJong/Artificial Intelligence 88 (1996) 101-142 12.5 in [ 601. The proofs are technical but we will restate the results and give an by Nadas intuitive explanation COMPOSER of why they hold. takes examples until the following inequality holds (Eq. (4) ) : taken so far, bu, is the transformation’s where n is the number of examples improvement, the acceptable sample size, and Q( cu) is the function estimated incremental utility: is the observed variance Si error in the estimate, no is a small finite in the transformation’s that models integer indicating the discrepancy between a minimum the true and improvement, average (Y is Q(a) = x such that For a given sequence of training examples time” is somewhat misleading number of examples, called the stopping term “stopping the temporal duration of the procedure. We retain with the statistical complexity time: E[ ST]. This is the average number of examples the results of Nadas we can derive time. literature.) The stopping rule is characterized of the stopping the following time in the sequential the stopping rule will be satisfied after some (The statistical as it refers to the number of examples, not literature. the term, however, to be consistent time, ST, is a random variable. The sample by the expected value of the stopping to make a decision. From for the expected stopping relationship required transfotmation. Theorem 1. Let ST be the stopping a given of the distribution associated with the transformation utility. Then: time associated with the Nddas stopping rule for Let a be the requested error level, o2 be the actual variance incremental and t_~ be the actual ( 1) For small 1 /a the expected stopping time is governed by the following relation- ship: E[ST] < -. a2 2 a% #u2’ (2) For large 1 /(Y the expected stopping time is governed by the following relation- ship: E[ST] z ln(l/a)$. This result states that the stopping time is determined which is under control of the user, and two fixed but unknown which are properties of the inference problem. The average stopping with a particular is bounded by a quadratic transformation constants, by the error level parameter, cr2 and P, time associated in I/LY (or to log of l/a for large I/a), the inverse of its mean. This makes the more difficult values. is to zero, the more difficult the default strategy. the more difficult it is to bound linearly with the variance of the transformation, the greater intuitive sense: the mean, the greater the variance in incremental its mean, and the closer the incremental it is to bound it is to show that the transformation and quadratically with the required confidence, utility utility than is better (worse) form equation time is derived by Nadas Proof. A non-closed in [60]. for the stopping The theorem follows from this proof and other results (see [ 24, Appendix B] ). Although the complete proof is too lengthy result like Theorem 1 should hold. The Central Limit Theorem states that the normalized incremental difference between utility will it is easy to compute a be (approximately) confidence statistics book shows (with a suitable mapping of notations) utility and the sample this observation the mean, given a sample of II observations. Any introductory the true incremental normally distributed. Using to include here, it is easy to provide intuition on why a interval around that: or in other words, with probability p, lies within The Nadas stopping interval rule is designed the interval AU,,&Q(cv) m I --a, the true incremental utility of a transformation, II, w h ere Si is the variance of our n samples. to take examples until the size of this confidence is twice the size of the unknown mean, p. Formally: Solving this relationship t’or II WC get the f’ollowing relationship: This shows that II is the number of examples that will produce a confidence of the appropriate the result of Theorem I. size. Or stated differently. II should be the stopping time, which It then remains to show how Q(cu) grows as a function of interval is bounded by a linear shows Q ( LY) < m can be obtained using Both derivations follows function x 1 /a. For large 1 /a, Q(a) the asymptotic expansion in [ 241. are given 2 from M&or~‘s inequality. More precisely, converges to about dm. of the standard normal distribution. I/LY. That Q( cy is this This 5.2. Sample complexit> The sample complexity (which inference takes some number of examples at each step of the hill-climbing is no way to bound search. As stated, there the number of steps COMPOSER will take as this is a function is equivalent is the number of examples to the largest stopping statistical to perform required time at a step). COMPOSER .I. Gratch, G. DeJong/Art@kd Intelligence 88 (1996) 101-142 127 the expected number of examples taken at each step in the hill-climbing space associated with an application. However we can transformation of the particular characterize search in terms of several parameters. Within a particular hill-climbing that LY is the allowable each transformation with negative be total error bound. The error (Y is related LY = S/jTI. incremental utility step there is some set of transformations statistical error associated with an incremental utility estimate in T. The value LY is a bound on the probability that a transformation T. Recall for is perceived as positive or vice versa. Let the value S to 6 by the Bound function and by default, consumes (2) some As validation to have negative proceeds within estimates computing ( 1) all transformations the step, COMPOSER for transformations are shown transformation with positive dynamically arise: discarded; adopted; or (3) examples the second, adopted the sample complexity, given that sufficient data has been provided make a decision: examples, training in T. One of three cases must utility and are and utility In the first case, the expected number of in T; in time of the that governs to the expected number of examples time of the transformations theorem describes to the maximum set is exhausted. for COMPOSER to the stopping the relationship The following transformation. is equivalent is equivalent is identified the training incremental incremental stopping Theorem 2. Let ST* be the number of examples consumed at a step in COMPOSER’s hill-climbing search under the default settings Eqs. (A. 1) and (A.3) ) , where S is the error bound and T is the set of transformations at that step, Then: ( 1) For small ITl/S the expected sample complexity is bounded by a polynomial in T and 116: (2) For large ]T\/S the expected sample complexity is governed by: where c is a constant whose value depends on the expected incremental utility and variance in incremental utility values for the transformations in T. Proof. This follows directly The constant c is the expected value of gF/,uT where i is the last transformation adopted/rejected 1 and the default definition of LY = S/IT]. that is from Theorem at a step. Thus, the expected number of examples required at a step grows at most quadratically in IT] and grows at most quadratically there will be an increase we increase polynomially the number of candidates. Similarly, as we require greater statistical confidence. in 1 /S. This means, all other things being equal, required at a step as the sample complexity will increase in the expected number of examples 0 12X J. Grurch. G. DeJon,q/ArtiJicrol intelligence 88 (1996) lOI-/ 5.3. Run time complex@ The expected run time of the algorithm depends on the number of examples used by to bound a single step. the algorithm in 7’ over each example, so the cost the algorithm and the cost to process each example which may not be possible in advance. Therefore, we provide results for the complexity of performing Under utility statistics, for gathering actually of processing is tied to the complexity of the problem solver. tries out each transformed problem solver the brute-force method incremental Theorem 3. Let R be an upper bound on the cost oj.solving a problem. Then: the expected run time complexity ( I ) For small jTl/S is: (2) For large /T//6 rhe expected run rune complexity is: O(R.iTi.ln (v)) Proof. Where (T(/6 is small, from Theorem 2 the number of samples required at a step is: Using each sample maximum large jTi/S. the default means for gathering jr\ + 1 times. Each solution incremental utility statistics attempt can cost at mosi R leading requires solving cost of R/T/ to process each example. The analogous argument holds to a for Therefore, expected cost of a hill-climbing step grows linearly in the required confidence, ically mations at that step, JTI. (cid:144)1 l/6, and at most cubically in R, at most quadrat- in the number of transfor- 5.4. Discussion Theorem I has some interesting consequence for the COMPOSER’s performance. the fewest examples. Theorem 1 states that the transformation it exhausts utility or when transformations with positive A step will terminate when COMPOSER cremental many that required fewest examples the one with the highest utility. Thus, COMPOSER This was observed is not necessarily ratio between the set of possible identifies a transformation with positive in- If there are utility, COMPOSER will adopt the one the the one with the highest incremental utility, but rather transformations. incremental requiring does not necessarily its variance and the square of its incremental steepest ascent hill climbing. perform A problem utility. COMPOSER in the comparison with PALO-RI. arises when all of the transformations does not terminate until some in T have near-zero incremental has been accepted transformation J. Gratch, G. DeJong/ArtQicial Intelligence 88 (1996) 101-142 129 the sample complexity utility of transformations increases dramatically. Although to zero, or all have been rejected. As the incremental that every however, transformation has near-zero utility, if this occurs, the algorithm may not be able to make a decision. Rather, the algorithm will simply exhaust all of its training examples with out it might make making any improvements sense to terminate search. We discuss the step early and proceed this possibility in expected utility. Under such circumstances step in the hill-climbing in Section 6. to a different it is unlikely tends 6. Limitations and future work COMPOSER provides a probabilistic solution that COMPOSER In this section we discuss in the problem reported elsewhere to realize its generality. its practicality implementations it is important strated other aging, that restrict tensions successful utility problem: utility of transformations, set of commitments large space of possible commitments to the approach. We first characterize limitations through results. We then consider organizing the search and gathering (see also [ 3 1 ] ) . solving applications [ 26,271. While to the utility problem and has demon- described herein, and in two these successes are encour- embodies many design commitments these limitations and possible ex- for that are necessary to three aspects of the some conditions and extensions the space of modifications, embodies statistics. COMPOSER estimating a particular for each of these aspects and thus can be seen as one point in a 6.1. Applicability conditions We can summarize three basic conditions that COMPOSER requires for satisfactory results. 6.1,1. A structured transformation space solver is constructed by composing some body of atomic mod- the space of possible composite modifications will be so large as genera- small into a sequence of search steps, with a relatively intractable. COMPOSER requires a transformation search this space A modified problem In general, ifications. to make exhaustive tor that structures factor. branching Clearly, COMPOSER’s performance is tied to the transformations is to be effective, COMPOSER that make up a strategy. Because of the nature of hill climbing, exists, that COMPOSER will find it. there must exist good methods there is no guarantee it is given. If for the control points even if a good strategy For our experiments, to its existing transformation a problem solver set of control one which adopts by the addition of a single as entertaining rules at a time. This some of the problems of hill climbing. However, COMPOSER would that allowed as many as ten or is transformed rules. One might two or three control transformations imagine not work effectively with rules to act as a unit. The cost of actually performing the transformation the new problem solver should also be small. Transformations such as rule control a single would ameliorate probably twenty control to generate I30 J. Grutch, G. .!kJm~/A,?t~cd lnrelligence 88 (1996) 101-142 a spatial changing would not be likely candidates reasoner for the COMPOSER approach. from a surface representation to a volume representation 6. I .2. Availability of representative training problems by a fixed problem distribution. provided with a sufficiently COMPOSER’s statistical approach assumes To estimate that the pattern of tasks can be represented this distribution, the algorithm must be large body of training problems. through a set of different violate or one that cycles sub-patterns, A task distribution the fixed distribution to the COMPOSER assumption. However these difficulties. With quickly shifting but cyclic patterns, that approach. Shifts in the shifts slowly over time presents a difficulty for distribution it may partially overcoming the extent of the suffice to average over the cycle. One might draw problems the systematic changes. Training on cycle and then randomize this randomized distribution will result in a problem solver that does not take advantage there are slow of the shifts, but will nonetheless or use steady shifts shifts [49]. other methods Tracking and taking advantage of predicted shifts is an important area of future research. in the distribution to periodically improve average performance. When the problem solver as the distribution take windows of training problems, there are approaches the problems throughout to destroy one can re-train incremental 61.3. Low problem solving cost utility is only feasible the strongest to improve. Extracting transformations This is perhaps use COMPOSER solver. One real-world domain lem of scheduling antennas COMPOSER’s modeling but we were forced ciency. Potential ways of relaxing discussed below. [ 261. This application communications training statistics by solving if problems can be solved with a sufficiently limitation of the technique. for example, an average case exponential to which COMPOSER has been applied between earth orbiting demonstrated the necessity of reducing It may not be feasible examples under various low cost. to time problem is the prob- satellites and ground based learning cost. this complexity reasonable in managing to maintain effi- solving are this reliance on tractable initial problem assumptions to make some additional helped dramatically innovations 6.2. Organizing search A key challenge is successfully navigating through posite modifications. COMPOSER’s search. In many ways, this restriction transformations, between all. In other ways, the restriction mations will be considered at each step. hill-climbing is too strong. When restriction attempts the vast space of possible com- to ensure efficient interactions there are strong COMPOSER may find poor local maxima, or no solution at is too weak. It says nothing about how many transfor- It is vital to focus the search on the most promising follows a generate and test paradigm. Performance tion as intelligent of intelligent generation lem solving first. COMPOSER can be improved by making genera- achieves some measure its EBL component. This carefully analyzes each prob- that as possible. PRODIGY’s and only propose sound learning component trace for search transformations inefficiencies alternatives through J. Gratch, G. DeJong/Art$cial Intelligence 88 (1996) 101-142 131 address observed deficiencies. Where applicable, heuristics hypothesis may also help filter out unpromising transformations. like Etzioni’s non-recursive Finally, we are investigating how to apply notions to help control the improvement from work on bounded the cost of identifying rationality good due to reasoning with the cost of transformations with a bias on is ensured by imposing identifies improvements. Currently, COMPOSER utility and the efficiency of search [ 13,411 and bandit problems [ 20,2 1,421 adaptations. These methods balance achieving those high incremental the exploration-the between pled method relates their incremental in this area see [ 25,28,32]. for characterizing the utility function actual search behavior of the algorithm arises from the interaction like to develop a more princi- transformations which directly utility and the cost to achieve an improvement. For some results and these biases. We would the value of investigating 4.3. Estimating incremental utility The search through the transformation transformations. utility. Typically utility of alternative the number of examples and must be estimated by applying the precise shape of the distribution the incremental butional nature of incremental even its general form are unavailable some statistical model. While grows only as the log of the required confidence, tical concern. Another chief limitation to the appropriateness an initial sample size parameter which may have to be adjusted Reliance on such parameters seems in substantially investigation Chernoff bounds. space relies on the ability to accurately estimate This is made difficult by the distri- and training data to to form these estimates this cost is a significant prac- tied this includes for a particular domain. statistical alternative like Chernoff bounds, which result is the area of future work and reducing is that the accuracy of estimates of the statistical model. In the case of COMPOSER, to be to use weak method statistical models, higher sample complexities. An important but the only obvious is unfortunate, of alternative rules which is ultimately lie between the Nadas technique stopping required inefficiency entity, even if two identical as an independent in how COMPOSER is that it treats each there is often a relationship gathers statistics though trans- between that would allow a more efficient use of information. As an extreme the algorithm the sample complexity only grows to develop utility of multiple One formation transformations example, will maintain by the log of the number of transformations. a single statistical model from which one can derive transformations. is an important the incremental taken by [45,69]. While not always possible, transformations twice the statistics necessary, although This area of future research. it may be possible to COMPOSER, is the approach are provided Sometimes it strategy process. For example, Several statistical methods can be applied estimation resulting that other transformations may be better than the default, quickly eliminated than the default control strategy. We investigate in [ 61. Similar strategies the efficiency of the to further if the a transformation is significantly worse than the default control strategy. However, given could be more rather to COMPOSER if they are compared with the most promising inference appear in [ 50,581. this and other extensions transformations for improving transformation the statistical is eliminated currently improve only 132 J. Grcitch, G. DeJon~/ArriJiciul lntellipvzce 88 (1996) 101-142 the distributional binary measures of incremental Heuristics and prior information like the operutionality criteria of Mitchell, Keller, and Kedar-Cabelli utility. Unfortunately, measures be seen as approximate measures have difficulty capturing we are investigating example, COMPOSER transformations to be based on fewer examples. application are also considered all information However, estimation. can replace or augment statistical estimates. Syntactic [ 541 can syntactic nature of incremental utility. Instead, the use of such measures as a bias on the estimation process. For confidence when thereby allowing estimates in the PRODIGY step steps. Currently COMPOSER discards on a different control strategy. step may be useful as a bias on later that many of the same control in subsequent satisfy certain syntactic measures of utility, across steps as each step is conditional issue, we observed in one hill-climbing could be modified from a previous rules considered less statistical In a related hill-climbing information to require gained 6.4. Gathering statistics The need for efficient search and estimation incremental incremental in some applications is a serious limitation, utility values. COMPOSER in the problem solving domains discussed utility statistics. The default method is limited to gather to obtain to solve problems with the original and intermediate expensive problems is feasible this dependence on problem solving overcome or mitigated. For example, article, we were able to take advantage of properties of the transformations examples more efficiently. to implement within resolved by identifying important arises from the fact that it can be quite requires solving to cases where it problem solvers. While it can be in this to process vocabularies may be easier the issue can be than others. Perhaps means is the possibility utility estimates on weaker and cheaper to obtain information. For example, Greiner and Jurisica [ 351 propose one method from a single solution transformations upper and lower bounds on the utility of the novel search paths. attempt by maintaining about Other authors have suggested [ 53,611) currently or by observing intractable problems by first learning (e.g. to estimate utility values. of basing some transformation framework In general, the COMPOSER information (e.g. that it may be possible hybrid statistical/analytic from simpler problems area of future work to gain useful for evaluating incremental [ 12,55,70] a teacher several An ) 7. Conclusion This article has argued that it is desirable, and possible, that automatically solving solving techniques Adaptive problem On the one hand, general purpose an application representation. On demands of individual after a tedious cycle of manual experimentation and satisfy is a means of reconciling to construct general problem adapt to the characteristics of a specific application. needs. techniques can ease much of the burden of developing and modular knowledge two seemingly contradictory the oft argued need for declarative the other hand, special purpose approaches are best suited applications. General approaches have proven successful, and modification. Adaptive to the only techniques J. Gratch, C. DeJong/Artifcial Intelligence 88 (19%) 101-142 133 promise to reduce the burden of this modification process and, thereby, take a step toward reconciling the conflicting needs of generality and efficiency. In this article we have developed a formal characterization of the utility problem which connects work on adaptive problem solving to the rich field of decision theory. This has been a fertile connection, giving rise to COMPOSER. COMPOSER is a statistically rigorous algorithm built upon the decision theoretic foundation. It transforms a general problem solving technique into one specialized for an application. COMPOSER is still a heuristic approach, but by casting it within a statistically sound framework we are able to articulate the assumptions which underly the technique and predict their consequences. Most importantly, since these assumptions are stated explicitly, they can be subjected to empirical investigations. A larger theme is that any learning algorithm must strike a balance between maximiz- ing performance yet doing so efficiently. COMPOSER embodies numerous commitments to achieve efficient learning performance. We have argued that effective learning is com- posed of essentially three basic and roughly independent problems. First, there is the problem of searching the space of possible composite modifications. Second, there is the issue of obtaining estimates of local properties of transformations across the pattern of task, in our case estimating incremental utility of atomic transformations. Finally, there is the issue of efficiently gathering the information to produce these estimates. By decomposing the problem in this way, it is possible to consider approaches like COM- POSER as not just a single algorithm, but as a collection of methods, each of which can be tested individually. It is our hope then that future research in this area will not proceed simply by the development of large techniques like COMPOSER or PRODIGY, but by the development of smaller, well understood, methods that may be combined in a variety of ways to produce a complete algorithm. Acknowledgements Many thanks are due to Steve Minton, who’s PRODIGY system inspired this work. Russ Greiner contributed greatly through many technical discussions. Adam Martinsek assisted us on numerous statistical issues. Thanks also to Marsha Brofka, Dan Oblinger, Oren Etzioni, and the anonymous reverers for critical comments on earlier versions of this work. This research was conducted primarily at the Beckman Institute at the University of Illiois with support by the National Science Foundation under grants NSF-IRI-87-19766 and NSF-IRI-92-09394. Appendix A. Implementation tradeoffs Our motivation in designing COMPOSER was not simply to provide a statistically sound learning technique, but to provide a practical tool. A chief drawback of COM- POSER’s statistical approach is that it can be expensive. This section discusses pragmatic issues and techniques for improving COMPOSER’s performance by tailoring it to the specific characteristics of an application. 134 J. Grarch. G. DeJong/Artificficrui Intellipxce RR (I 9%) 101-142 impediment The principal the computational aging COMPOSER’s consume to a particular application, we see three ways in which this expense can be mitigated: to the utility problem transformations. like to efficiently process each example and to to COMPOSER’s expense of identifying inferences. When applying COMPOSER is man- To maximize performance we would approach good few examples its statistical to perform ( 1) Tailoring of the Bound function. (2) Tailoring of the discrepancy modeling (3) Tailoring of methods describes This appendix for gathering the rationale behind function Q ( LY) . incremental utility statistics, the standard configuration alternative approaches. This tailoring allows to take advantage of any domain specific knowledge to improve POSER and describes signer ciency. of COM- the application de- effi- learning A.1. Tailoring Bowzd(G, ]TI 1 The Bound function defines the error such a way that the overall probability 8. Here we consider a more general definition of Bound the hill-climbing of error, the error at each step in the hill-climbing and the cumulative step from a set 7 of estimates, search. We will look at these sources estimate, the acceptable error in step i. /3; to denote level for each incremental of learning a worse problem that includes in utility estimate is less than solver the current step in for two sources search given that we are choosing a error over steps in the hill-climbing individually. We use LY to denote the error of each search: Bound( 6, i, (TI). To do this, one must account A. I. 1. Error in a .step On step i, we are investigating a set T of transformations. Given that the error of each of a joint event is cy, the expected is less than or equal [ 37, p. 3631.) That to the sum of probabilities total error for the step, /3,, is bounded below by LY the step error may be greater in the situation where every member of T has negative of the estimates and above by ITILY. (The upper bound follows from Bonferroni’s that the probability each event seen correct decision probability incremental the greater /I; is a function of the size of T. The true relationship depends on the covariance between the distribution utility data points associated with each transformation, though, inequality which states of than cx is most clearly utility. The incremental is there to have positive transformation. However, estimated the larger the number of transformations, cy that a given utility and be adopted. Typically, the probability that at least one of the estimates will be in error, meaning transformation will be incorrectly is generally unavailable. is to not adopt any this information of incremental for this step the precise the for choosing LY to achieve a step relationship between It is difficult, if not impossible, to characterize size of T and p;. We have considered error of PiI two methods Worst case: cy := Pj/\T\ (default), best case: cy := pi. (A.1) (A.2) J. Gratch. G. DeJong/Art@cial Intelligence 88 (1996) 101-142 135 In the worst case, error grows linearly in the size of the number of transformations, utility and is negatively incremental has negative for example when every transformation correlated. This situation will probably never arise in practice, however, it does provide a that the observed statistical error will not be higher than expected. The strong guarantee as the size of T best-case model, Eq. (A.2), assumes grows. We have performed can be reasonable is that the size of T does not have to be known generator in advance so we can allow the transformation the existing members. small (e.g., 30). The advantage of this assumption the error does not grow appreciably some empirical evaluations to add new transformations into T as we are evaluating that this assumption if T is relatively showing A.l.2. Error across steps Let pi denote the final problem result in a decrease a liberal policy. COMPOSER solver may still be a significant that it is worth one step backwards the chance of adopting a transformation with negative on the ith step. As the number of steps grows, so does the chance will actually utility, implement being worst-case approach step to at most 6 (i.e., Ci pi < 8). This guarantees requirement, but may require many more examples different ways to implement of possible in terms of the overall error parameter 8: incremental utility that at least one step in expected utility. However, even if some steps reduce improvement. By default, we allows an error of 8 at each step, the rational take several steps forward. The that COMPOSER will adopt any incorrect that COMPOSER the error than the former approach. There are the number for setting pi the worst-case approach depending on whether in advance. We have considered is to limit the probability steps is known three methods to quickly satisfies Liberal bound: pi := S (default), worst-case bound/limited steps: pi := t, worst-case bound/unlimited steps: pi := 7. 66 1279 (A.3) (A.4) (A.5) The default policy, Eq. (A.3), relies on the assumption that the magnitude of the utility of incorrect steps is comparable to the magnitude of the incremental if some steps reduce utility, solver. This assumption incremental utility of correct steps so that even tend to improve on the initial problem simulation sacrificed simply divide of steps is unbounded what the final number of steps, the total error sums to less than 6. Bq. (AS) this requirement. the final result will has held across several are useful when efficiency must be in advance, one can the number the error at each step must be such that no matter satisfies the error evenly over each of the k steps (Eq. (A.4) ) . When experiments. for rigor. When the number of steps can be limited two equations in advance, later The t2 Once a model implementor the application for the error across steps, chooses a model these should be unified for the error within a step and function into an overall I2 This equation was suggested to us by Russell Greiner and is the basis for his PALO algorithm (see [35 1) 136 J. Grutch. G. DeJon~/Arti~ciul Intelligence 88 (1996) 101-142 Pl d- Fig. A. 1. Probability distribution of the normalized difference between the sample mean and true mean of the is the value such that the probability of achieving a distance greater than this is original distribution. Q( n, a) less than or equal to a/2. Bound( 6, i, ITI) which combines for the ith step in the hill-climbing the two choices into an error level for each estimate search. A.2. Tailoring Q( cu) and no difference incremental incremental expected discrepancy the normalized the true the rzormalized difference, d, between is the difference divided by the observed variance The function Q(a) models utility and the esti- between a more utility. Here we consider is the average of a finite sample of n data utility observations. This sample will be roughly representative of the actual from the fixed distribution. However of data points as it is drawn randomly the true mean of the distribution. The Nadas the sample mean and the true in mated general definition, Q( n, a). The estimate incremental distribution the sample mean will only approximate stopping rule bounds mean. The normalized the sample mean. The expected normalized difference can be modeled by a probability that a particular normalized difference distribution function which shows the likelihood in Fig. A.1. The arises from a random sample. Such a distribution function difference. The bell shaped curve shows function Q( n, a), also called is the positive difference d such that the probability than this is less to cr/2. than or equal It is rarely possible situation. Fortunately, converges standard normal distribution). This property in statistics. This fact implies, under some weak conditions,” can be approximated (see is the motivation data points ensures an accurate approximation. We have investigated methods improves as the sample size increases. This large initial sample of two approximation (also called a is asserted by the Central Limit Theorem that function Q(n, cu) is illustrated each normalized th quantile of this distribution, a difference greater to know the precise distribution of differences for any distribution, for a given learning the distribution of differences to a normal distribution with zero mean and unit variance the quantile of a standard normal distribution the no parameter. Taking a sufficiently [ 39, Section 5.31). The approximation the likelihood of observing for defining Q(n, a) : as n increases, of observing satisfactorily the ((r/2) behind using I3 The distribution must have positive variance and hence finite mean J. &arch, G. DeJong/Artijicial Intelligence 88 (1996) 101-142 137 Standard normal: Q* (n, (Y) = x 00 x & e-“%‘zdy = z (default), such that J( > such that J n (n + 1)/21 + y2,rj(“f,,,2dy ercn,2jc1 = ;. 00 X (‘4.6) (A.7) T: Qt(n9aY> =x The first is COMPOSER’s default. It is based on the standard normal distribution model. The second is based on a model called the student t distribution. This second model is accurate when there is high variance in the sample, but it is more expensive to compute. For a given learning situation, the function Q( n, cu) and no should be chosen to best model the expected discrepancy in the given learning situation. If an exact model can be determined then an initial sample size is unnecessary. In general, higher variance in incremental utility values requires a greater no to ensure the approximation model is close. Smaller values for 6 require more precise modeling of the error and therefore a better approximation. Thus, the smaller the requested error level, the greater that no should be to ensure a close approximation to 6. If no is set too small, the likely result is a higher than requested statistical error. If no is too large, an excessive number of examples is required to perform statistical inference. The general experience in the statistical community is that the normal approximation becomes quite good after only a few initial samples. We recommend a value around fifteen. A.3. Gathering statistics The largest cost in using COMPOSER tends to be cost to obtain utility observations. Given a current problem solver PS and a set of transformations T, COMPOSER must obtain utility observations for each transformation over a large sample of problems. There are many techniques, however, that can significantly reduce this cost depending on the characteristic of the application. These techniques can reduce cost in two ways; first by reducing the number of utility values necessary to observe, and second, by reducing the cost of obtaining each utility value. A sampling technique known as blocking can reduce the number of utility values nec- essary to make statistical decisions [4,58]. As was shown in the theoretical analysis, the number of examples needed to make statistical inferences grows with the variance in the incremental utility values. Blocking works by minimizing this variance. To understand blocking, consider the problem of finding the highest yielding variety of wheat. Wheat yield is effected by factors other than the variety of wheat, which is the factor of interest. We will call these other influences the nuisance factors (e.g., the weather conditions in the year the crop was grown). Often these nuisance factors have the greatest influence, washing out the contribution of the factor of interest, and thus increasing the variance in the data. A standard solution, called randomized block design is to combine all data with identical values on their nuisance factors into a single block, and only consider the differences in the observations within the block when computing utility values. For the wheat example, a block corresponds to a plot of land in some location. Block design suggests having several plots of land in different wheat within each plot. One then only considers within a plot of land, and averages these differences locations, and planting every variety of in yield between varieties the difference across the different plots. of each problem are easy, others hard, and these dif- In COMPOSER, the nuisance factors are the specific characteristics small changes problems influences incremental applications is to block are dominant transformation is to compute to overwhelm transformations as transformations to the current problem inference. These problem in many of the intended the behavior of each possible from the task distribution-some from the utility of each transformation this procedure can lead to a significant utility values are then derived by subtracting the differences due to the choice of transformation. (the block) and observe Incremental in turn, for that block. When reduction drawn ferences are likely The solution we have adopted problem problem. default strategy problem the number of examples needed for statistical to dominate relatively transformed problem to blocking a different problem. it may not be possible benefit by problem. We take each on that the utility of the the in influences tend generally make solver, and therefore each solver will perform similarly on similar problems. The alternative utility where each utility value is derived from this strategy as is of limited to the effect of the transformations. the cost of obtaining utility data. The simple is to solve a given problem with each of the candidate prob- strategy we recommend lem solvers. The complexity of this brute-force processing is tied to the complexity of each of the ITI problem solvers. In some learning situations, brute-force processing may prove too expensive. For example. one or more of the candidate problem solvers may be requires explicit exper- intractable. Furthermore, imentation with alternative problem solvers. is is desirable solver. As gathering to learn passively, statistics to employ any information that could reduce the normal operations of the problem principal expense, In some situations, to repeatedly is intrusive-it In some learning solve the identical problem. Blocking There are also techniques the brute-force method if problem differences it may be necessary are small relative is COMPOSER’s the incremental it is important for reducing to perform situations, this cost. through The cost of obtaining utility observations can be dramatically reduced if there is a solving detailed cost model mations without actually could simply draw a random the effect of different this, it may be possible of different problem in PRODIGY. Sometimes Greiner and Jurisica does not conflict with COMPOSER’s transformations the problem transfor- that can efficiently derive the ramification of the proposed [36,68]). With such a model we (e.g. example and then use the model Such models are rarely available, but short of to determine training transformations. to extract the necessary to determine solver. Section 4 describes one such unobtrusive by solely observing it is only possible [35] propose one method statistics the effectiveness the normal operations of the current that worked in this way. that implementation information for using such partial information to extract partial assumptions and could be incorporated. Appendix B. BIN-WORLD domain The BIN-WORLD in both PRODIGY/EBL’s domain was introduced utility analysis in [30] to highlight some deficiencies and Etzioni’s non-recursive hypothesis. The J. Gratch, G. DeJang/Art$cial Intelligence 88 (1996) 101-142 139 is a robot assembly domain a set of components All the components in the bin are free of defects, be examined suitable as achieving (represented for a particular part are stored task where the goal is to construct a composite part from is true). in a bin. If all of the components the part may be assembled. Otherwise another bin must if a given bin is the state where part-assembled operator determines for acceptability. The INSPECT-BIN for assembly. The ASSEMBLE-COMPONENTS operator constructs the part. B.I. Domain theory ~~~ B.2. Problem distribution Effects: (add defect-free-components(x)) according each. Forty-nine A problem distribution two problem in a problem to the distribution. The experiment is defined by enumerating to each class. A set of problems a set of problem classes and assign- constructing is created by randomly ing probabilities is based on a uniform distri- problems that each class has an equal chance of classes. This means bution over solving attempt. The first class contains problems with fifty participating bins of two components bins contain a defective component. One bin contains no defects. The bins are ordered with the defect-free bin last. The second class is defect contains problems with two bins of two hundred components free. The other bin contains are ordered with the defective component The rational behind variance. PRODIGY/EBL utility of a bi-modal distribution example results learned control its utility estimates on a single example. Estimating from a single (or any distribution with high variance) utility of any of the true incremental last. The bins are ordered with the defect-free bin last. a defective component. The components is to construct a distribution with high this problem distribution in an inaccurate each. One bin representation bases rule. References for ranking means of normal populations R.E. Bechhofer, A single-sample multiple decision procedure with known variances, Ann. Mafh. Stat. 25 ( I ) ( 1954). J.O. Berger, StatisticaL Decision Theory and Bayesian Analysis (Springer, Berlin, 1980). A. Borgida and D.W. Etherington, Hierarchical in: knowledge bases and efficient disjunctive Proceedings First International Conference an Principles of Knowledge Representation and Reasoning, Toronto, Ont. ( 1989) 33-43. H. Bthinger, H. Martin and K.-H. Scriever, Nonparametric Seyuenticrf Selection Procedures (Birkhauser, Boston, 1980). P. Cheeseman, B. Kanefsky IJCAI-89, Sidney and W.M. Taylor, Where the really hard problems in: Proceedings reasoning, 1633169. (1989) are, 140 J. Gratch, G. DeJon~/Artifclal Intelligence 88 (1996) 101-142 16 1 S.A. Chien, J.M. Gratch and M.C. Burl, On the efficient allocation of resources in machine learning: a statistical approach, 171 T. Dean and M. Boddy, An analysis of time-dependent for hypothesis evaluation IEEE Trans. Pattern Anal. Mach. Intell. 17 ( 1995) 652-665. in: Proceedings AAAI-88, St. Paul, planning, MN (1988) 49-54. [ 81 T.L. Dean and MI? Wellman, Planning and Control (Morgan Kaufmann, San Mateo, CA, 1991). 19 ] R. Dechter, Constraint networks, in: S.C. Shapiro, ed., Encyclopedia of Art$cial Intelligence (Wiley, New York, 1992). [ 10 1 R. Dechter and J. Pearl, Network-based heuristics for constraint-satisfaction problems, Arf$ Intell. 34 (1987) l-38. 1 1 I I M.H. DeGroot, Optimal Statistical Decisions (McGraw-Hill, New York. 1970). I I2 I G.E DeJong and R.J. Mooney, Explanation-based learning: an alternative view, Mach. Learn. 1 ( 1986) 145-176. [ 13 I J. Doyle, Rationality and its roles in reasoning (extended version), in: Proceedings AAAI-90, Boston, MA (1990) 1093-I 100. I 14 1 0. Etzioni, A structural theory of search control, PhD thesis, Department of Computer Science, Carnegie- Mellon University, Pittsburgh, PA ( 1990). I IS I 0. Etzioni, Why Prodigy/EBL works, [ 16 1 0. Etzioni, STATIC a problem-space (1991) s33-540. in: Proceedings AAAI-90, Boston, MA ( 1990) 916-922. compiler in: Proceedings AAAI-9I. Anaheim, CA for PRODIGY, I 171 0. Etzioni and S. Minton, Why EBL produces overly-specific knowledge: in: Proceedings Ninth International Conference on Machine Learning, Aberdeen a critique of the PRODIGY ( 1992) approaches, 137-143. [ I8 ] R.E. Fikes and N.J. Nilsson, STRIPS: a new approach to the application of theorem proving to problem solving, Art$ Intell. 2 ( 197 I ) 189-208. [ 19 I M. Fisher, The Lagrangian relaxation method for solving integer programming problems, Manage. Sci. 27 (1981) l-18. 1201 P.W.L. Fong, A quantitative study of hypothesis selection. in: Proceedinp Twelfth International Conference on Machine Learning, Tahoe City, CA ( 1995) 226-234. [ 2 1 1 J.C. Gittins, Multi-Armed Bandit Allocation Indices (Wiley, New York, 1989). 1221 A. Goldberg, and CA. Brown, Average PW. Purdom time analysis of simplified Davis-Putnam Inform. Process. Lett. 15 ( 1982) 72-79. procedures, I 231 Z. Govindarajulu, 1241 J.M. Gratch, COMPOSER: UIUCDCS-R-93-1806, The Sequential Statistical Analysis (American Sciences Press, Columbus, OH, 198 1) solving, Tech. Rept. to adaptive problem a decision-theoretic approach Department of Computer Science, University of Illinois, Urbana, IL ( 1993). 1251 J. Gratch, On efficient approaches to the utility problem in adaptive problem solving, PhD thesis, Department of Computer Science, University of Illinois at Urbana-Campaign, Urbana, IL ( 199.5) [261 J. Gratch and S. Chien, Learning scheduling in: Proceedings Tenth International Conference on Machine Learning, Amherst, MA ( 1993). in: for the deep space network to improve schedule quality, search control knowledge search control knowledge I27 I J. Gratch, S, Chien and G. DeJong, Learning problem, Proceedings IJCA193 Schedulirq Workshop ( 1993). I281 J. Gratch, S. Chien and G. DeJong, Improving learning performance through rational resource allocation, in: Proceedings AAAI-94, Seattle, WA ( 1994). I29 1 J. Gntch and G. DeJong, A hybrid approach to guaranteed effective control strategies, in: Proceedings Eighth International Workshop on Machine Learning, Evanston, IL ( I99 I ) 1301 J. Gratch and G. DeJong, COMPOSER: solution in: Proceedings AAAI-92, San Jose, CA ( 1992) 235-240. and G. DeJong, A framework a probabilistic learning, 131 I J. Gntch of simplifications International Conference on Art$cial Intelligence Planning Systems, College Park, MD ( 1992) 78-87. learning and action, a principled IL 801, Department of Computer Science, University of Illinois, Urbana, and G. DeJong, Rational in: Proceediqs to balancing in learning approach learning: to plan, First 1321 J. Gntch to the utility problem in speed-up Tech. Rept. UIUCDCS-R-93-I (1993). 133 I R. Greiner and W.W. Cohen, Probabilistic hill-climbing, in: Proceedings Computational Learning Theory and “Natural” Learning Systems ( 1992). J. Gratch, G. DeJong/Artificial Intelligence 88 (1996) 101-142 141 [ 34 ] R. Greiner and C. Elkan, Measuring and improving ( 199 1) AAAI-91, Sidney the effectiveness of representations, in: Proceedings ] 35 ] R. Greiner and I. Jurisica, A statistical approach to solving the EBL utility problem, in: Proceedings AAAI-92, San Jose, CA ( 1992) 241-248. [ 361 R. Greiner and J. Likuski, Incotporating redundant learned rules: a preliminary formal analysis of EBL, in: Proceedings IJCAI-89, Detroit, MI ( 1989) 744-749. 1371 Y. Hochberg ( 38 ] R.V. Hogg and A.T. Craig, Introduction [ 39 ] R.V. Hogg and E.A. Tanis, Probability [ 40 ] L.B. Holder, Empirical and A.C. Tamhane, Multiple Comparison Procedures Statistics to Mathematical (Wiley, New York, 1987). (Macmillan, New York, 1978). Inference analysis of the general utility problem and Statistical (Macmillan, New York, 1983). in machine learning, in: Proceedings AAAI-92, San Jose, CA ( 1992) 249-2.54. I41 1 E.J. Horvitz, GE Cooper and D.E. Heckerman, Reflection and action under scarce resources: IJCAI-89, Detroit, MI ( 1989) 1121-l 127. study, in Embedded Systems (MIT Press, Cambridge, MA, 1993). principles and empirical 1421 L.P KaeIbIing, Learning [ 43 ] C. Knoblock, Learning hierarchies of abstraction in: Proceedings spaces, in: Proceedings Sixth international Conference theoretical on Machine Learning, Ithaca, NY ( 1989) 241-245. [ 441 R.E. Korf, Planning as search: a quantitative 145 ] P. Laird, Dynamic optimization, approach, A@ Intell. 33 ( 1987) 65-88. in: Proceedings Ninth International Conference on Machine Learning, Aberdeen ( 1992) 263-272. [ 461 J.E. Laird, P.S. Rosenbloom and A. Newell, llniversal Subgoaling and Chunking: The Automatic Generation and Learning of Goal Hierarchies (Kluwer Academic Publishers, Hingham, MA, 1986) I47 ] S. Letovsky, Operationality criteria for recursive predicates, in: Proceedings AAAI-90, Boston, MA ( 1990) 936-941. 1481 N.J. Lewins, Practical solution-caching for PROLOG: an explanation-based learning approach, PhD thesis, Department of Computer Science, University of Western Australia 1491 N. Littlestone 212-261. and M.K. Warmuth, The weighted majority algorithm, ( 1993). Inform. Compur. 108 ( 1994) ] SO] 0. Maron and A.W. Moore, Hoeffding races: accelerating model selection search for classification and function approximation, Los Altos, CA, 1994). in: Advances in Neural Ir#~rmation Processing Systems 6 (Morgan Kaufmann, ]5 I] K. Melhom, Data Structures and Algorithms 1521 DP Miller, R.S. Desai, E. Gat, R. Ivlev and J. Loch, Reactive navigation in: Proceedings AAAI-92, San Jose, CA ( 1992) 823-828. in: Learning Search Control Knowledge: An Explanation-BasedApproach I: Sorring and Searching I 531 S. Minton, experimental results, (Springer, Berlin, 1984). through rough terrain: (Kluwer Academic Publishers, Norwell, MA, 1988). ] S4] T.M. Mitchell, R. Keller and S. Kedar-Cabelli, Explanation-based generalization: a unifying view, Mach. Learn. 1 (1986) 47-80. [ S.51 T.M. Mitchell, S. Mahadevan Proceedings and L.I. Steinberg, LEAP IJCAI-8.5, Los Angeles, CA ( 1985) 573-580. a learning apprentice for VLSI design, in: [ 561 D. Mitchell, B. Selman and H. Levesque, Hard and easy distributions of SAT problems, in: Proceedings AAAI-92, San Jose, CA ( 1992) 459-465. 1571 T.M. Mitchell, R.E. Utgoff and R. Banerji, Learning by experimentation: acquiring and refining problem- J. Carbonell and T. Mitchell, eds.. Machine Learning: An Artificial solving heuristics, in: R. Michalski, Intelligence Approach (Morgan Kaufman, San Mateo, CA, 1983) ] 581 A.W. Moore and MS. Lee, Efficient algorithms for minimizing cross validation error, in: Proceedings Eleventh International Conference on Machine Learning, New Brunswick, NJ ( 1994). ] 591 J. Mostow, Mechanical transformation Department of Computer Science, CMU, Pittsburgh, PA ( I98 I ). task heuristics of into operational procedures, PhD thesis, 1601 A. Nadas, An extension of a theorem of Chow and Robbins on sequential confidence intervals for the mean, Ann. Math. Stat. 40 (1969) 667-671. from exercises, 16 I ] B.K. Natarajan, On learning in: Proceedings Second Annua/ Workshop on Computational Learning Theory, Santa Cruz, CA (1989) 72-87. [ 621 M.A. Perez and 0. Etzioni, DYNAMIC: a new rule for training problems in EBL, in: Proceedings Ninth International Conference on Machine Leurning, Aberdeen ( 1992) 367-372. 142 .I. G‘rc~lch. (;. DeJo,r,~/Ar/ifrl,ttr/ Ir~rell,~er/c~ XX (I 996) 101-142 I63 1 B. Roy, Problems and methods with multiple objective I64 1 S. Russell and E. Wefald. Principles of metareasoning. cm Principles c!f Knmvfrd~e Repr~se~r~trfion md Keasonin~, functtons. Mot/l. Pro~rd,rr~zin~ 1 (2) in: Prr~~erliqs First Toronto, Ont. ( 1989) 400-4 Internntioncd I I_ ( 197 I ). Confhrence 165 1 A.L. Samuel, Some studies 1661 M. Schoppers. Building in machine learning using the game of checkers. fBM J. 3 (3) ( 1959). plans to monitor and exploit open-loop and closed-loop dynamics, in: Prowedings I~irs~ /nfenwrtiotlt~/ ~‘mf~rence m Art&icd Inteilipnce PkmninR Systems, College Park. MD (1992) 204-213. 1671 U.M. Schwuttke and L. Ciasser. Real-time metareasoning with dynamic trade-off evaluation. in: Proceedin,q~ AAAI-92. San Jose. CA C 1992) 500-506. 1681 D. Subramanian and R. Feldman. The utility of EBL in recursive domain theories, in: Proceedings AAAI-90. Boston. MA ( 1990) 942-949. I69 I 0. Subramanian and S. Hunter. Measuring utility and the design of provably good EBL algorithms, in: PrweedinK.7 Nirlth /nrermr/kmtrl Ccmf~reru~e OH Mtrchine Lecuxin~, Aberdeen ( 1992) 426-435. Learning with Lecwnin,q. Evanston. 1 70 1 P. Tadepalli, Mtrchine 171 ) M.l? Wellman Pn~c~rrdi~~~s MD ( 1992) 236-242. Fir.rt inscrutable theories. IL ( I99 I ) 544-548. utility in: Procwdin~s Ei&th fnrernarioncd Wor,Wmp C),I representation for decision-theoretic planning, in: and J. Doyle. Modular /nfernotiomrl Cimferrwu OH Ar/ifi&rl htelliprwe Pkmnin~ S_~.wms. College Park. 