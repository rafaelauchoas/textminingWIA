Artificial Intelligence 217 (2014) 20–42Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComplexity of and algorithms for the manipulation of Borda, Nanson’s and Baldwin’s voting rules ✩Jessica Davies a, George Katsirelos b, Nina Narodytska a, Toby Walsh c,∗Lirong Xia da University of Toronto, Toronto, Canadab INRA, Toulouse, Francec NICTA and UNSW, Sydney, Australiad Rensselaer Polytechnic Institute, Troy, USA, a r t i c l e i n f oa b s t r a c tArticle history:Received 4 October 2011Received in revised form 12 July 2014Accepted 13 July 2014Available online 23 July 2014Keywords:Social choiceVoting methodsManipulationBorda votingNanson’s voting ruleBaldwin’s voting ruleWe investigate manipulation of the Borda voting rule, as well as two elimination style voting rules, Nanson’s and Baldwin’s voting rules, which are based on Borda voting. We argue that these rules have a number of desirable computational properties. For unweighted Borda voting, we prove that it is NP-hard for a coalition of two manipulators to compute a manipulation. This resolves a long-standing open problem in the computational complexity of manipulating common voting rules. We prove that manipulation of Baldwin’s and Nanson’s rules is computationally more difficult than manipulation of Borda, as it is NP-hard for a single manipulator to compute a manipulation. In addition, for Baldwin’s and Nanson’s rules with weighted votes, we prove that it is NP-hard for a coalition of manipulators to compute a manipulation with a small number of candidates.Because of these NP-hardness results, we compute manipulations using heuristic algorithms that attempt to minimise the number of manipulators. We propose several new heuristic methods. Experiments show that these methods significantly outperform the previously best known heuristic method for the Borda rule. Our results suggest that, whilst computing a manipulation of the Borda rule is NP-hard, computational complexity may provide only a weak barrier against manipulation in practice. In contrast to the Borda rule, our experiments with Baldwin’s and Nanson’s rules demonstrate that both of them are often more difficult to manipulate in practice. These results suggest that elimination style voting rules deserve further study.Crown Copyright © 2014 Published by Elsevier B.V. All rights reserved.1. IntroductionVoting is a simple mechanism to combine preferences in multi-agent systems. Results like those of Gibbard and Satterth-waite demonstrate that it may often pay for agents to manipulate an election by misreporting their preferences [24,34]. One appealing escape from manipulation is computational complexity [3]. Whilst a manipulation may exist, perhaps it is computationally too difficult to find? With a single manipulator, there is only a small set of voting rules that are known to This paper is an invited revision of the winner of the Outstanding Paper award at the Twenty-fifth AAAI Conference on Artificial Intelligence (AAAI-11). E-mail addresses: jdavies@cs.toronto.edu (J. Davies), gkatsi@gmail.com (G. Katsirelos), ninan@cs.toronto.edu (N. Narodytska), toby.walsh@nicta.com.au✩Parts of this paper also appear in [14].* Corresponding author.(T. Walsh), xial@cs.rpi.edu (L. Xia).http://dx.doi.org/10.1016/j.artint.2014.07.0050004-3702/Crown Copyright © 2014 Published by Elsevier B.V. All rights reserved.J. Davies et al. / Artificial Intelligence 217 (2014) 20–4221be NP-hard to manipulate with unweighted votes: the second order Copeland rule [13,3], single transferable vote (STV) [2]and ranked pairs [35,40]. With two or more manipulators, computing a manipulation is NP-hard for some other common voting rules [19,40,20,41]. One case that remains open is Borda voting. Xia, Conitzer, and Procaccia [41] observe that:“The exact complexity of the problem [computing a manipulation with unweighted votes] is now known with respect to almost all of the prominent voting rules, with the glaring exception of Borda”.Computing a manipulation of Borda is NP-hard when votes are weighted and we have a coalition of manipulators [12]. On the other hand, computing a manipulation of Borda is polynomial-time when votes are unweighted and there is just a single manipulator [3]. For a coalition of manipulators and unweighted votes, it has been conjectured that the problem is NP-hard [43]. Note that there exist other scoring rules besides Borda where computing a manipulation with unweighted votes has been show to be NP-hard [41]. One of the most important contributions of this paper is to close the question of the computational complexity of computing a coalitional manipulation for Borda with unweighted votes. We prove that computing a manipulation of Borda with just two manipulators is NP-hard. This result was proven independently in [7]. We will discuss the similarities and differences between the two proofs later in the paper.We also study two voting rules that are closely related to the Borda rule: Nanson’s and Baldwin’s rules. These are elimination style rules that use Borda scoring to eliminate candidates over a number of rounds. The two rules have been used in real elections in the University of Melbourne (between 1926 and 1982), the University of Adelaide (since 1968), and the State of Michigan (in the 1920s). There are several reasons we consider Nanson’s and Baldwin’s rules. Firstly, they have features that might appeal to the two opposing camps that support Borda and Condorcet. In particular, unlike the Borda rule itself, both Nanson’s and Baldwin’s rules are Condorcet consistent as they elect the candidate who beats all others in pairwise elections. Secondly, statistical analysis suggests that, whilst the Borda rule is often vulnerable to manipulation [10], Nanson’s rule is particularly resistant [22]. We might expect Baldwin to be similarly resistant. Thirdly, for any Condorcet consistent rule (and thus for Nanson’s and Baldwin’s rules), Brandt et al. [8] have shown that many types of control and manipulation problems have polynomial-time algorithms when votes are single-peaked. It is an interesting question then if such manipulation problems remain polynomial when we drop the domain restriction.Nanson’s and Baldwin’s rules are also interesting to study as they are elimination style rules, and elimination style rules are often computationally harder to manipulate than the base rule from which they are derived [2,15]. Elkind and Lipmaa have conjectured that computing a manipulation for the closure of many voting rules (where we successively use the rule to eliminate candidates) is NP-hard [16]. One of our contributions is to prove that computing a manipulation of Baldwin’s rule, which is the closure of Borda voting, is NP-hard with a single manipulator. We also prove that manipulation of Nanson’s rule is NP-hard, again with a single manipulator and unweighted votes. Finally, we consider the problem of computing a manipulation with weighted votes and a coalition of manipulators. We show that Baldwin’s and Nanson’s rules are NP-hard to manipulate in this setting with just three and four candidates respectively.Our theoretical results suggest that all three rules are computationally difficult to manipulate in the worst case. We also investigate whether these rules are resistant to manipulation in practice [37–39]. We propose several polynomial-time heuristic algorithms for the three voting rules that try to minimise the number of manipulators required to ensure a partic-ular result. Our experiments suggest that the Borda rule is often easy to manipulate in practice. The heuristics that we study are able to find an optimal manipulation in 99% of the cases. Interestingly, these heuristics were significantly less effective for Baldwin’s and Nanson’s rules. These empirical results, together with our theoretical results, provide further evidence for the recent claim that elimination style voting rules tend to be more computationally resistant to manipulation [15].The focus in this paper is on manipulation problems. It would, however, be interesting in the future to consider also control and bribery problems [4,17]. Control is somewhat different from manipulation since in control problems we change the structure of the election (number of candidates, number of voters, etc.). Bribery, on the other hand, is very close to manipulation since we only change the votes. Manipulation is also related to the possible winner problem [26] and to dealing with uncertainty when eliciting and aggregating preferences [36,32,33]. See [21] for a longer discussion on the connections between these problems.The rest of the paper is organised as follows. In Section 2 we provide background. Section 3 focuses on unweighted manipulation and Section 4 on the weighted case. Section 5 presents four heuristic algorithms that aim to find the minimum number of manipulators and Section 6 evaluates these algorithms experimentally. In Section 7 we present two interesting connections between unweighted coalitional manipulation of the Borda rule and two problems from discrete mathematics. We conclude in Section 8.2. BackgroundLet C = {c1, . . . , cm} be the set of m candidates (or alternatives). A linear order on C is a transitive, antisymmetric, and total relation on C. The set of all linear orders on C is denoted by L(C). An n-voter profile P on C consists of n linear orders on C. That is, P = (V 1, . . . , V n), where for every j ≤ n, V j ∈ L(C). The set of all n-profiles is denoted by Fn. A (deterministic) voting rule r is a function that maps any profile on C to a unique winning candidate, that is, r : F1 ∪ F2 ∪ . . . → C. When voters are weighted, we have a function w that associates each voter j with a fixed positive integer w( j). A voting rule treats weights as if we had w( j) identical copies of the voter j.22J. Davies et al. / Artificial Intelligence 217 (2014) 20–42Borda rule The Borda rule, proposed by Jean-Charles de Borda in 1770, is a positional scoring rule that gives a score of m − i to candidate a for each vote that puts candidate a in ith place. The candidate with the highest total Borda score wins. We write s(a, P ) for the total Borda score given to candidate a from the profile of votes P , and s(a) where P is obvious from the context. A score vector (cid:7)s1, . . . , sm(cid:8) indicates that the ith candidate receives the Borda score si . The Borda rule is used in parliamentary elections in Slovenia and, in modified form, in elections within the Pacific Island states of Kiribati and Nauru. The Borda rule or similar scoring rules are also used by many organisations and competitions including the Robocup autonomous robot soccer competition, the X.Org Foundation, the Eurovision song contest, and in the election of the Most Valuable Player in major league baseball. The Borda rule has many good features. For instance, it is monotone, as increasing the score for a candidate only helps them win. It never elects the Condorcet loser (a candidate that loses to all others in pairwise elections). However, it may fail to elect a Condorcet winner (a candidate that beats all others in pairwise elections) even if one exists.Nanson’s and Baldwin’s rules These rules are derived from the Borda rule. Nanson’s rule eliminates all candidates with less than the average Borda score [29]. This step is then repeated with the reduced set of candidates until there is a single candidate left. A closely related voting rule proposed by Baldwin successively eliminates one of the candidates with the lowest Borda score1 until one candidate remains [1]. The two rules are closely related. Indeed, they are sometimes confused in the literature. One of the most appealing properties of Nanson’s and Baldwin’s rules is that they are Condorcet consistent, i.e. they elect the Condorcet winner whenever one exists. This follows from the fact that the Borda score of the Condorcet winner is never below the average Borda score. Both rules satisfy several other desirable criteria, including the majority criterion, i.e., a candidate that is preferred by a majority of voters always wins, and the Condorcet loser criterion. There are also properties which distinguish them. For instance, Nanson’s rule satisfies reversal symmetry (i.e. if there is a unique winner under all tie breaking rules and all voters reverse their votes then the winner changes) but Baldwin’s rule does not. Finally, there are also desirable properties that neither rule satisfies like monotonicity.The manipulation problem We can now formally define the different manipulation problems we consider. The unweighted coalitional manipulation problem is defined as follows.Definition 1 (r-Coalitional-Manipulation). Given a tuple (P NM, p, M), where P NM is the non-manipulators’ profile, p is the candidate preferred by the manipulators, and M is the set of manipulators, does there exist a profile P M for the manipulators such that r(P NM ∪ P M ) = p? In other words, does there exist a profile P M for the manipulators such that candidate p wins an election under the voting rule r and the profile P NM ∪ P M ?We drop the word “coalitional” when there is a single manipulator. The weighted coalitional manipulation is defined similarly, where the weights of the voters (both non-manipulators and manipulators) are also given as inputs.Definition 2 (r-Weighted-Coalitional-Manipulation). Given a tuple (P NM, p, w, M), where P NM is the non-manipulators’ profile, p is the candidate preferred by the manipulators, w is the weighting function and M is the set of manipulators, does there exist a profile P M for the manipulators such that r(w, P NM ∪ P M ) = p? In words, does there exist a profile P Mfor the manipulators such that candidate p wins an election under the voting rule r and the profile P NM ∪ P M ?The corresponding optimisation versions of these problems seek to minimise |M|, the number of manipulators.As is common in much of the literature, we break ties in favour of the coalition of the manipulators. This tie-breaking rule was originally used in [3]; see [18] for a discussion of why this has become a “tradition”. We also assume that the manipulators have complete knowledge about the scores from the votes of the non-manipulators. Again, this has become the “tradition” within the literature from some of the earliest work. The argument often put forward for the assumption of complete information is that partial or probabilistic information about the votes of the non-manipulators would add to the computational complexity of computing a manipulation.Given a set of votes and n manipulators, it is in the best interest of all manipulators to place the preferred candidate, p, first for the Borda rule. Hence, p will have Borda score s(p) + n(m − 1). We define the gap of candidate i as g(i) =s(p) + n(m − 1) − s(i). For p to win under Borda voting, we need the manipulating votes to give to candidate i (where i (cid:9)= p) a total Borda score which is less than or equal to g(i). Note that if g(i) is negative for even one i, then p cannot win under Borda voting.In the proofs of this paper, we will often need to refer to pairs of votes of a particular form. We define the pair of votes W (u,v) = {u (cid:10) v (cid:10) Others, rev(Others) (cid:10) u (cid:10) v} where Others is a total order in which the candidates in C \ {u, v} are in a pre-defined lexicographic order, and rev(Others) is its reverse.1 If multiple candidates have the lowest score, then we use a tie-breaking mechanism to eliminate one of them.J. Davies et al. / Artificial Intelligence 217 (2014) 20–42233. Unweighted coalitional manipulationWe start by considering the computational complexity of manipulating Borda, Nanson’s and Baldwin’s rules with un-weighted votes. We prove that the coalitional manipulation problem is NP-complete under the Borda rule with two manipulators. This settles an open problem in computational social choice. We also show that Baldwin’s and Nanson’s rules are NP-complete to manipulate even with a single manipulator.3.1. Borda ruleIn this section we present one of our main results. We prove that computing a manipulation of the Borda rule is NP-hard for two manipulators. Our NP-hardness proof uses a reduction from a specialised permutation problem that is strongly NP-complete [42].Definition 3 (Permutation Sum). Given q integers X1 ≤ · · · ≤ Xq where σ and π of 1 to q such that σ (i) + π (i) = Xi ?(cid:2)qi=1 Xi = q(q + 1), do there exist two permutations We first give a technical lemma that shows we can construct votes for the non-manipulators with a given target sum.Lemma 1. Given integers X1 to Xm, we can construct, in time polynomial in Borda score of candidate ci is Xi + C for 1 ≤ i ≤ m, and for candidate cm+1 is y ≤ C , for some integer C ≥ 0.i=1 Xi , votes over m + 1 candidates such that the total m(cid:2)Proof. This proof uses the construction of McGarvey [28], which has been used elsewhere in the computational social choice literature [41,6]. We show how to increase the score of a candidate by 1 more than the other candidates except for the last candidate whose score increases by 1 less. For instance, suppose we wish to increase the score of candidate c1 by 1 more than candidates c2 to cm, and by 2 more than candidate cm+1. Consider the pair of votes W (c1,cm+1) defined in Section 2, and given below:c1 (cid:10) cm+1 (cid:10) c2 (cid:10) . . . (cid:10) cm−1 (cid:10) cmcm (cid:10) cm−1 (cid:10) . . . (cid:10) c2 (cid:10) c1 (cid:10) cm+1.The score of candidate c1 increases by m + 1, of candidates c2 to cm by m, and of candidate cm+1 by m − 1. By repeated construction of such votes, we can achieve the desired result. For example, we may construct Xi copies of W (ci ,cm+1) for all 1 ≤ i ≤ m.As the number of votes is linear in mi=1 Xi , the time is polynomial in the sum of the given integers. (cid:2)(cid:2)Theorem 1. Unweighted coalitional manipulation for the Borda rule is NP-complete with two manipulators.Proof. The problem is clearly in NP, since a set of manipulator votes that make the preferred candidate win is a polynomial witness that a manipulation exists.To show NP-hardness, we reduce from the Permutation Sum problem. Given an instance of Permutation Sum with qintegers, X1 to Xq, we assume, without loss of generality, that 2 ≤ Xi ≤ 2q for all i ∈ {1, . . . , q}. Given such an instance of Permutation Sum, we create a manipulation problem with m = q + 3 candidates p, a1 . . . , aq+2 where the preferred candidate of the two manipulators is p. By Lemma 1, we can construct an election in which the non-manipulators cast votes to give the score vector for (cid:7)p, a1, . . . aq+2(cid:8) of:(cid:3)C, 2(q + 2) − X1 + C, . . . , 2(q + 2) − Xq + C, 2(q + 2) + C, y(cid:4)for some C ≥ 0 and y ≤ C . We show next that two manipulators can make candidate p win such an election if and only if the Permutation Sum problem has a solution.(⇒) Suppose we have two permutations σ and π of 1 to n with σ (i) + π (i) = Xi . We construct two manipulating votes, in which the candidates get the following scores, respectively:(cid:3)q + 2, σ (1), . . . , σ (q), 0, q + 1(cid:3)q + 2, π (1), . . . , π (q), 0, q + 1(cid:4)(cid:4).Since σ (i) + π (i) = Xi , these give a total score vector:(cid:3)2(q + 2) + C, 2(q + 2) + C, . . . , 2(q + 2) + C, 2(q + 1) + y(cid:4).As y ≤ C and we tie-break in favour of the manipulators, candidate p wins.24J. Davies et al. / Artificial Intelligence 217 (2014) 20–42(⇐) Suppose we have a successful manipulation. To ensure candidate p beats candidate aq+1, both manipulators must put candidate p in first place. Similarly, both manipulators must put candidate aq+1 in last place, otherwise candidate aq+1will beat our preferred candidate. Hence the final score of candidate p is 2(q + 2) + C . The gap between the final score of candidate p and the current score of candidate ai (where 1 ≤ i ≤ q) is Xi . The sum of these gaps is q(q + 1). Therefore, if any candidate a1 to aq gets a score of q + 1 then candidate p will be beaten. Hence, the two scores of q + 1 have to go to the least dangerous candidate which is candidate aq+2.The votes of the manipulators are thus of the form:(cid:3)q + 2, σ (1), . . . , σ (q), 0, q + 1(cid:3)q + 2, π (1), . . . , π (q), 0, q + 1(cid:4)(cid:4)where σ and π are two permutations of 1 to q. To ensure candidate p beats candidate a j for j ∈ [1, q], we must have:2(q + 2) − X j + C + σ ( j) + π ( j) ≤ 2(q + 2) + C.Rearranging this gives:σ ( j) + π ( j) ≤ X j.(cid:2)qi=1 Xi = q(q + 1) and Since (cid:2)qi=1 σ (i) =σ ( j) + π ( j) = X j.(cid:2)qi=1 π (i) = q(q+1)2, there can be no slack in any of these inequalities. Hence,That is, we have a solution of the Permutation Sum problem. (cid:2)The result of Theorem 1 was proved independently by Betzler et al. [7] using a different reduction from the same problem. Their proof relies on the same basic idea as ours – constructing a set of non-manipulating votes such that the candidates have specific gaps. In contrast to our proof which needs Θ(m) non-manipulators and a single dummy candidate using the construction of Lemma 1, Betzler et al. use a more complicated construction which introduces Θ(m) dummy candidates but needs only three non-manipulating votes. It follows therefore that the problem of computing a manipulation is not fixed parameter tractable in the number of voters.3.2. Baldwin’s ruleOur next result is proved by reduction from the exact 3-cover (X3C) problem.Definition 4 (X3C). Given two sets V = {v 1, . . . , vq}, q = 3r, and S = {S1, . . . , St}, where t ≥ 2 and for all j ≤ t, |S j| = 3 and S j ⊆ V , does there exist a subset S (cid:15)of S such that each element in V is in exactly one of the 3-sets in S (cid:15)?Theorem 2. Unweighted manipulation for Baldwin’s rule is NP-complete with one manipulator.Proof. We give a reduction from X3C. Given an X3C instance V = {v 1, . . . , vq}, S = {S1, . . . , St}, we let the set of candidates be C = {p, d, b} ∪ V ∪ A, where p is the manipulator’s preferred candidate, A = {a1, . . . , at}, and d and b are additional candidates. Members of A correspond to the 3-sets in S. Let m = |C| = q + t + 3.The profile P contains two parts: P 1, which is used to control the changes in the score differences between candidates, after a set of candidates is removed, and P 2, which is used to balance the score differences between the candidates.We make the following observations about the pair of votes W (c1,c2), which were defined in Section 2. First, these two votes give the following scores to each candidates(c1): ms(c2): m − 2s(e): m − 1 for e ∈ OthersSecond, for any set of candidates C(cid:15) ⊆ C and any pair of candidates e1, e2 ∈ C \ C(cid:15),s(e1, W (c1,c2)|C\C(cid:15) ) − s(e2, W (c1,c2)|C\C(cid:15) ) = s(e1, W (c1,c2)) − s(e2, W (c1,c2)) +⎧⎨⎩if e1 = c2 and c1 ∈ C(cid:15)1−1 if e1 = c1 and c2 ∈ C(cid:15)0otherwise.(1)Here W (c1,c2)|C\C(cid:15) is the pair of votes obtained from W (c1,c2) by removing all candidates in C(cid:15). In words, the formula states that after C(cid:15)is removed, the score difference between e1 and e2 is increased by 1 if and only if e1 = c2 and c1 is removed; it is decreased by 1 if and only if e1 = c1 and c2 is removed; for any other cases, the score difference does not change. Additionally, for any e ∈ C \ {c1, c2}, s(c1, W (c1,c2)) − s(e, W (c1,c2)) = 1 and s(c2, W (c1,c2)) − s(e, W (c1,c2)) = −1.We next show how to use votes of the form W (c1,c2) to construct the first part of the profile P 1. We recall that m =|C| = q + t + 3. P 1 is composed of the following votes:J. Davies et al. / Artificial Intelligence 217 (2014) 20–4225• for each j ≤ t and each v i ∈ S j , there are 2m copies of W (v i ,a j );• for each i ≤ q, there are m copies of W (b,v i );• there are m(t + 6) copies of W (b,p).Let avg(P 1) be the average score of candidates in P 1. That is, avg(P 1) = s(d, P 1) = (m − 1)(6mt + mq + m(t + 6)). Define occ(i) to be the number of occurrences of the element v i in sets in S. The votes in P 1 give the scoress(v i, P 1): avg(P 1) + 2m · occ(i) − ms(a j, P 1): avg(P 1) − 6ms(p, P 1):s(b, P 1):s(d, P 1):avg(P 1) − m(t + 6)avg(P 1) + mq + m(t + 6)avg(P 1)It is not hard to verify that s(b, P 1) − s(p, P 1) ≥ mq, and for any cfollowing votes:(cid:15) ∈ V ∪ A, s(c(cid:15), P 1) − s(p, P 1) ≥ 2m. P 2 is composed of the • for each i ≤ q, there are s(v i, P 1) − s(p, P 1) − m = 2m · occ(i) + mt + 4m copies of W (d,v i );• for each j ≤ t, there are s(a j, P 1) − s(p, P 1) − 1 = mt − 1 copies of W (d,a j );• there are s(b, P 1) − s(p, P 1) − mq = 2m(t + 6) copies of W (d,b).Let avg(P 2) be the average score of candidates in P 2. That is, avg(P 2) = s(p, P 2) = (m − 1)(2m ·t(mt − 1) + 2m(t + 6)). The votes in P 2 give the scores:(cid:2)qi=1 occ(i) + mtq + 4mq +s(v i, P 2): avg(P 2) − (2m · occ(i) + mt + 4m)s(a j, P 2): avg(P 2) − (mt − 1)s(p, P 2):avg(P 2)avg(P 2) − 2m(t + 6)s(b, P 2):avg(P 2) + 2m ·s(d, P 2):(cid:2)qi=1 occ(i) + mtq + 4mq + t(mt − 1) + 2m(t + 6)Let P = P 1 ∪ P 2, avg(P ) = avg(P 1) + avg(P 2). The combined Borda scores are:s(v i, P ): avg(P ) − m(t + 5)s(a j, P ): avg(P ) − m(t + 6) + 1s(p, P ):s(b, P ):s(d, P ):avg(P ) − m(t + 6)avg(P ) + mq − m(t + 6)avg(P ) + qm(t + 5) + t(m(t + 6) − 1) + 2m(t + 6) − mqWe make the following observations about the Borda scores of the candidates in P .• For any i ≤ q, s(v i, P ) − s(p, P ) = m.• For any j ≤ t, s(a j, P ) − s(p, P ) = 1.• s(b, P ) − s(p, P ) = mq.Suppose the X3C instance has a solution S1, . . . , Sq/3 (this is without loss of generality since we can rename the sub-scripts of the 3-sets in the solution to {1, . . . , q/3}). Then, we let the manipulator vote as follows:p (cid:10) d (cid:10) aq/3+1 (cid:10) · · · (cid:10) at (cid:10) b (cid:10) V (cid:10) aq/3 (cid:10) · · · (cid:10) a1.In the following, we use Ck to denote the set of candidates that have not yet been eliminated after round k.The candidates with the lowest Borda score before the manipulator’s vote are p followed by all a j ’s, which all have 1 more, as explained above. With the manipulator’s vote, p overtakes all a j . Moreover, a1 has the lowest Borda score, which means that a1 is eliminated in the first round. We next show that for all j = 1, . . . , q/3, in round 4 j − 3, candidate a j is eliminated, and in round 4 j − 2, 4 j − 1, 4 j, S j are eliminated.Suppose this holds for all rounds before round 4 j − 2. In round 4 j − 3 candidate a j is eliminated. By Eq. (1), for all c(cid:15) ∈ C4 j−3 \ (S j ∪ {d, p}), we have(cid:9)(cid:15)(cid:8)c, P |C4 j−3(cid:8)scs(d, P |C4 j−3 ) − s(p, P |C4 j−3 ) = s(d, P |C4 j−4 ) − s(p, P |C4 j−4 ) − (mt − 1)− s(p, P |C4 j−3 ) = s− s(p, P |C4 j−4 ), P |C4 j−4(cid:9)(cid:15)and for any v ∈ S j , we haves(v, P |C4 j−3 ) − s(p, P |C4 j−3 ) = s(v, P |C4 j−4 ) − s(p, P |C4 j−4 ) − 2m26J. Davies et al. / Artificial Intelligence 217 (2014) 20–42Therefore, in round 4 j − 2, the difference between p and the candidates in S j is decreased by 2m, which covers their initial difference of m and also the difference in the manipulator’s vote (as this can be at most m − 2). Meanwhile, d is still leading by a large margin. Therefore, in rounds 4 j − 2, 4 j − 1, 4 j, the candidates in S j are eliminated (the order of elimination does not matter). Eliminating each v ∈ S j has three effects on score difference between p and other candidates:1. the score difference between all ak with v ∈ Sk and p is increased by 2m;2. the score difference between b and p is decreased by m;3. the score difference between d and p is decreased by the number of copies of W (d,v) in P .These do not affect the fact that candidates in S j are eliminated in rounds 4 j − 2, 4 j − 1, 4 j, and we also note that for all j < k ≤ q/3, the score difference between p and ak does not change. Therefore, in round 4 j + 1 candidate j + 1 is eliminated.Continuing, after the first 4q/3 rounds, all candidates v i are eliminated, each decreasing the score difference between band p by m for a total of mq. Hence b and p are tied for the lowest total Borda score in P (it is not hard to verify that other ak and d still have higher scores). Considering the manipulator’s vote, b is eliminated next. This decreases the difference between d and p by 3m(t + 6) (which is the cumulative effect of the third set of votes in P 1 and the third set of votes in P 2), and between aq/3+1, . . . , aq and p by m(t + 6) (by the third set of votes in P 1). It follows that in the next t − q/3rounds, all remaining candidates in A are eliminated. Finally, when only p and d remain, they are tied in P . But since the manipulator prefers p to d, p is the winner.Suppose the manipulator can cast a vote to make p the winner. We first note that, from the votes in P 1, as long as not all of the candidates in V , A and b are eliminated, the difference between the score of d and p is greater than m, so it cannot be covered by the vote of the manipulator. Hence, d must be eliminated after these other candidates, that is, in the last round. In the round when b is eliminated, the score of b can be no more than the score of p. We note that s(b, P ) − s(p, P ) = mq and the score difference can only be reduced by the manipulator ranking b below p, and by eliminating v 1, . . . , vq before b. However, ranking b below p reduces the score difference by no more than m − 1 and eliminating any single candidate in V reduces the difference by m. Therefore, before b drops out, all q candidates in V must have already dropped out. We note that for any v i ∈ V , s(v i, P ) − s(p, P ) = m, so the manipulator’s vote cannot cover this difference. Also the only other way to reduce this difference is by eliminating some a j with v i ∈ S j . Therefore, for each v i ∈ V , there exists at least one a j with v i ∈ S j that is removed before v i . For any such a j , no candidate v i ∈ S j can drop out before a j . Otherwise the difference between a j and p is increased by 2m, reaching 2m + 1. Therefore, before b drops out, this difference cannot be covered by the manipulator’s vote, which means that p drops out before a j . This is a contradiction since we assume that p drops out after b. On the other hand, no other candidate ak with S j ∩ Sk (cid:9)= ∅ can drop out before b, because when the candidates in the intersection of S j and Sk drop out, the difference between ak and p is increased by 2m and becomes positive. Finally, we note that after a j drops out, in the next three rounds the candidates in S j drop out. It follows that the set of candidates in A that drop out before the candidates in V that they cover corresponds to an exact cover of V . After all the candidates in V drop out, b drops out, followed by the rest of the candidates in A and then d, as above.Therefore, the unweighted manipulation problem under Baldwin’s rule is NP-complete with only a single manipula-tor. (cid:2)3.3. Nanson’s ruleWe reduce the exact 3-cover (X3C) problem to a manipulation problem under Nanson’s rule.Theorem 3. Unweighted manipulation for Nanson’s rule is NP-complete with one manipulator.Proof. The idea of the proof is similar to that of the proof of Theorem 2. We prove NP-completeness by reduction fromX3C with t ≥ 3q (this is without loss of generality because if t < q then we can add dummy S 1’s to S). Given an X3Cinstance V = {v 1, . . . , vq}, S = {S1, . . . , St}, we let the set of alternatives be C = {p, d, b1, b2} ∪ V ∪ A, where p is the manipulator’s preferred candidate, V = {v 1, . . . , vq}, A = {a1, . . . , at}, and d, b1, and b2 are auxiliary alternatives. Without loss of generality, both q and t are even, and t ≥ 3q. We will use the votes W (c1,c2) defined in Section 2 to construct the profile. For any C(cid:15) (cid:2) C, we make the following observations about W (c1,c2).(cid:8)c(cid:15)s, W (c1,c2)|C\C(cid:15)(cid:9)− |C \ C(cid:15)| + 1 =(cid:15) = c1 and c2 /∈ C(cid:15)(cid:15) = c2 and c1 /∈ C(cid:15)(2)⎧⎨⎩1if c−1 if c0otherwise.We note that |C \ C(cid:15)| − 1 is the average score of the alternatives in W (c1,c2)|C\C(cid:15) .Let m = q + t + 4. Again, the profile has two parts: P 1, which is used to control the score differences between the alternatives and the average score, and P 2, which is used to set the initial scores. P 1 consists of the following votes:• for every j ≤ t there are 7m/2 − q/3 copies of W (a j ,b1);J. Davies et al. / Artificial Intelligence 217 (2014) 20–4227• for every v i ∈ S j (there are three of them), there are m copies of W (v i ,a j );• for every i ≤ q, there are m copies of W (v i ,p);• there are mq copies of W (p,b1);• there are mq + t(7m/2 − q/3) copies of W (b1,b2).The second part of the profile, P 2, consists of the following votes, where occ(v i) is the number of times that v i is covered by the 3-sets in S:• for any i ≤ q, there are m · occ(v i) copies of W (d,v i ),Let P = P 1 ∪ P 2 and let avg(P ) = (m − 1)|P |/2. We make the following observations about P :(cid:2)q• s(p, P ) − avg(P ) = 0.• s(d, P ) − avg(P ) = m(• s(b1, P ) − avg(P ) = 0.• s(b2, P ) − avg(P ) = −(mq + t(7m/2 − q/3)).• For any j ≤ t, s(a j, P ) − avg(P ) = m/2 − q/3.• For any i ≤ q, s(v i, P ) − avg(P ) = m.i=1 occ(v i)) = 3mt.Suppose the X3C instance has a solution {S1, . . . , Sq/3} (this is without loss of generality since we can rename the subscripts of the 3-sets in the solution to {1, . . . , q/3}). Then, we let the manipulator vote as follows:p (cid:10) b1 (cid:10) b2 (cid:10) d (cid:10) aq/3+1 (cid:10) · · · (cid:10) at (cid:10) V (cid:10) aq/3 (cid:10) · · · (cid:10) a1.The manipulator’s vote does not change the score of any candidate with respect to the average by more than (m − 1)/2, therefore b2 will be eliminated in the first round. The difference between the score of candidate a j for 1 ≤ j ≤ q/3 and the average will be m/2 − q/3 − ((m − 1)/2 − j + 1). Since j ≤ q/3, this is seen to be less than or equal to −1/2, hence these candidates are also eliminated in the first round. No other candidates are eliminated in the first round: for all candidates in V , the manipulator’s vote is not enough to make their score less than the average, while all other candidates receive more than the average from the manipulator.Let C1 = C \ {a1, . . . , aq/3}. In the second round, by Eq. (2), for any v i ∈ V , s(v i, P |C1 ) − avg(P |C1 ) = 0. The reason is that each v i gets m(occ(i) − 1) points from the second part of P 1 because {S1, . . . , Sq/3} covers V , m points from the third part of P 1, and −m · occ(i) points from P 2. Counting in the manipulator’s vote and recalling that we assumed t ≥ 2q, we have that the scores of all candidates in V are below the average score. Moreover, because b2 was eliminated in the first round, the score of b1 is now below the average. Therefore, b1 and all the candidates in V are the only candidates eliminated in the second round.Let C2 = C \ ({b1, b2, a1, . . . , aq/3} ∪ V). In the beginning of the third round, because b1, b2, and all candidates in Vwere eliminated, we have that for each W (c1,c2) in P , at least one of c1 and c2 was eliminated. Therefore, the score of all remaining candidates is the same as the average score in P |C2 . Moreover, for the same reason, in any later round the score of all remaining candidates is the same as the average score in P (restricted to the remaining candidates). Therefore the manipulator’s vote becomes decisive. It follows that in each of the following rounds, the candidates ranked below the mid-position in the manipulator’s votes are eliminated. The final winner is the manipulator’s top-ranked candidate, which is p.Next, we show that if the manipulator can cast a vote to make p win, then there exists a solution to the X3C instance. In the first round b2 definitely drops out. This makes the score of b1 below the average score in the second round (from the mq + t(7m/2 − q/3) copies of W (b1,b2) in P 1), which means that b1 will definitely drop out in the second round. If any of the v i candidates remain in the third round, then the score of p will be strictly lower than the average score (from m copies of W (v i ,p) in P 1). Therefore, all alternatives in V must drop out in the first and second rounds. In fact, v i ’s can only drop out in the second round, and only when there exists j such that v i ∈ S j and the alternative a j drops out in the first round. Moreover, no more than q/3 alternatives in A can possibly drop out in the first round (since the only way for them to drop out is to be ranked among the bottom q/3 positions). Therefore, in order for p to survive the third round, the bottom q/3alternatives in the manipulator’s vote must be among A and they must correspond to an exact cover of V , which means that the X3C instance has a solution.Therefore, the unweighted manipulation problem under Nanson’s rule is NP-complete when there is only one manipula-tor. (cid:2)Our results about the complexity of manipulating Baldwin’s and Nanson’s rules significantly increase the size of the set of voting rules used in practice that are known to be NP-hard to manipulate with a single manipulator. They also contrast to Borda where computing a manipulation with a single manipulator can be done in polynomial time [3]. Adding elimination rounds to Borda to get Nanson’s or Baldwin’s rules increases the computational complexity of computing a manipulation with one manipulator from polynomial-time to NP-hard.28J. Davies et al. / Artificial Intelligence 217 (2014) 20–424. Weighted coalitional manipulationIn this section we show that weighted coalitional manipulation under Baldwin’s or Nanson’s rules is NP-complete. It has already been shown that the weighted coalitional manipulation problem for Borda is NP-hard for three or more candidates [12].4.1. Baldwin’s ruleSimilar to the case of Borda, we prove that the weighted coalitional manipulation problem for Baldwin’s rule is NP-hard for three or more candidates. Our result is proved by reduction from the Partition problem.Definition 5 (Partition). Given a set of integers A = {k1, . . . , kq} such that these numbers into two sets the elements in each of which sum to K ?(cid:2)qi=1 ki = 2K , does there exist a partition of A partition that witnesses the satisfiability of a Partition instance is called a perfect partition.Theorem 4. For Baldwin’s rule and weighted votes, the coalitional manipulation problem is NP-hard with three or more candidates.Proof. We reduce from the partition problem. We construct a coalitional manipulation problem with three candidates (a, b, and p) in which the manipulators want to make p win.We suppose the non-manipulators have voted as in the following table.weights11K5K14K2K − 15K5Kvotesa (cid:10) b (cid:10) pa (cid:10) p (cid:10) bb (cid:10) p (cid:10) ab (cid:10) a (cid:10) pp (cid:10) a (cid:10) bp (cid:10) b (cid:10) aAt this point the scores of the candidates ares(a): 39K − 1s(b): 48K − 2s(p): 39K .For each integer ki ∈ A, we have a member of the manipulating coalition with weight 3ki .Suppose there is a perfect partition. Let the manipulators corresponding to the integers in one half of the partition vote a (cid:10) p (cid:10) b, and the others vote p (cid:10) a (cid:10) b. The scores are now as follows: s(a) = 48K − 1, s(b) = 48K − 2, s(p) = 48K . Hence bwill be eliminated. In the next round, p wins as s(a) = 21K − 1 but s(p) = 27K . Thus the manipulators can make p win if a perfect partition exists.Conversely, suppose there is a manipulation in which p wins. Suppose a is eliminated in the first round. Then the scores in the second round from the non-manipulators are: s(b) = 27K − 1, and s(p) = 15K . The manipulators cannot now prevent b from winning. Hence b must be eliminated in the first round. If any manipulator puts b above last place, b will not be eliminated and will win. Thus all the votes of the manipulators are a (cid:10) p (cid:10) b or p (cid:10) a (cid:10) b. Consider the following partition of A constructed from any successful manipulation. In the first half of the partition, we put all integers associated with weighted votes of the manipulators of the form a (cid:10) p (cid:10) b. In the second half, we put all integers associated with weighted votes of the form p (cid:10) a (cid:10) b. Suppose the first half of the partition sums up to K − x and the second half sums up to K + x. Then we have scores: s(a) = 48K − 1 − 3x, s(b) = 48K − 2 and s(p) = 48K + 3x. If x ≥ 1 then a is eliminated. On the other hand, if x ≤ −1 then p is eliminated. Hence x = 0 and we have a perfect partition. For more than three candidates, we add “harmless” candidates that are in the last places of every vote of the non-manipulators. (cid:2)Note that Coleman and Teague in Theorem 13 of [11] provide an NP-hardness result for the weighted coalitional manipu-lation problem for voting rules like Baldwin’s that eliminate candidates one by one. Our result for Baldwin’s rule is different in two aspects. First, Coleman and Teague use a different tie-breaking rule. They break ties against the manipulator whilst, as is more common in the literature, we suppose ties are broken in their favour. The second difference is that Coleman and Teague do not specify a precise bound on the number of candidates, while we present a proof that weighted coalitional manipulation under Baldwin’s rule is NP-hard for just three candidates.J. Davies et al. / Artificial Intelligence 217 (2014) 20–42294.2. Nanson’s ruleWe show that the weighted coalitional manipulation problem under Nanson’s rule is NP-complete with four or more candidates. However, if there are at most three candidates, the computational complexity of computing a manipulation under Nanson’s rule is polynomial-time.Theorem 5. For Nanson’s rule and weighted votes, the coalitional manipulation problem is NP-complete with four or more candidates.Proof. We reduce from partition. For any partition instance, we construct a coalitional manipulation problem with four candidates (a, b, c, and p) where p is the candidate that the manipulators wish to win. We suppose the non-manipulators have voted as in the following table.weights2(2K + 1)2(2K + 1)2(2K + 1)2(2K + 1)2(K + 2)2(K + 2)111222votesb (cid:10) p (cid:10) c (cid:10) aa (cid:10) c (cid:10) b (cid:10) pc (cid:10) p (cid:10) b (cid:10) aa (cid:10) b (cid:10) c (cid:10) pp (cid:10) a (cid:10) b (cid:10) cc (cid:10) b (cid:10) p (cid:10) ap (cid:10) a (cid:10) b (cid:10) ca (cid:10) b (cid:10) c (cid:10) pa (cid:10) b (cid:10) p (cid:10) cc (cid:10) p (cid:10) a (cid:10) ba (cid:10) c (cid:10) p (cid:10) bb (cid:10) p (cid:10) a (cid:10) cThe total scores from non-manipulators are as follows: s(a) = 28K + 38, s(b) = 34K + 37, s(c) = 34K + 37 and s(p) =24K + 38. The average score is 30K + 37.5. For each integer ki , we have a member of the manipulating coalition with weight 2ki . Now, suppose there is a solution to the partition instance. Let the manipulators corresponding to the integers in one half of the partition vote p (cid:10) a (cid:10) b (cid:10) c, and let the others vote p (cid:10) a (cid:10) c (cid:10) b.The total scores are now as follows: s(a) = 36K + 38, s(b) = 36K + 37, s(c) = 36K + 37 and s(p) = 36K + 38. The average score is 36K + 37.5.The alternatives b and c are eliminated, and p wins in the second round. Thus the manipulators can make p win if a perfect partition exists.Conversely, suppose there is a successful manipulation. Clearly, we need to ensure that p is not eliminated in the first round. To ensure this, all manipulators must rank p first. Otherwise, the score of p would be less than the average score 36K + 37.5, so p would be eliminated. Next, we show that if b and c are not eliminated in the first round, p cannot win overall. We consider all possible sets of candidates besides b and c that could be eliminated in the first round. There are six cases.1. only a is eliminated in the first round. The scores from non-manipulators in the second round are as follows: s(b) =24K + 27, s(c) = 24K + 27, and s(p) = 12K + 21. The average score is 20K + 25. Even with the maximum possible score of 8K from the manipulators, p is eliminated. This contradicts the assumption that p wins.2. only b is eliminated in the first round. Note that if a is not ranked second in the votes of all manipulators, its score will be less than the average 36K + 37.5 and it will be eliminated. This contradicts our assumption that p and aare not eliminated in the first round. Hence, all manipulators have to cast votes that rank p first and a second. The votes of the manipulators in the second round will then be p (cid:10) a (cid:10) c, giving scores s(a) = 22K + 23, s(c) = 24K + 25, and s(p) = 26K + 27. The average score is 24K + 25. Hence, a is eliminated. In the next round, p is eliminated, as s(p) = 10K + 10, s(c) = 14K + 15, and the average score is 12K + 12.5. This contradicts the assumption that p wins.3. only c is eliminated in the first round. This case is symmetric to the second case.4. a and b are eliminated in the first round. In the second round, the scores from non-manipulators are s(c) = 14K + 15and s(p) = 6K + 10. The 4K points from the manipulators cannot now prevent p from being eliminated. This contradicts the assumption that p wins.5. a and c are eliminated in the first round. This is symmetric to the fourth case.6. a, b, and c are all eliminated in the first round. This case is impossible because if b and c are eliminated then a must get 8K points from the manipulators. Hence, a reaches the second round.Thus, the only way for p to win is if b and c are eliminated in the first round. For this to occur, the manipulators have to put p in first place, and a in second place. If b gets more than a score of 2K from the manipulators in the first round, then its total score will be greater then the average of 36K + 37.5 and it will not be eliminated in the first round. Similarly, 30J. Davies et al. / Artificial Intelligence 217 (2014) 20–42if c gets more than a score of 2K from the manipulators, then it will not eliminated in the first round. However, as both the first and second place in the manipulators votes are fixed, there is exactly 4K points to divide between them. Hence, they must divide the 4K points equally. Hence, there exists a solution to the partition instance. For more than four candidates, we add “harmless” candidates that are in last place in every vote of the non-manipulators. (cid:2)Clearly, there is a polynomial-time algorithm to compute a manipulation of Baldwin’s rule with two candidates (since this case degenerates to majority voting). For Nanson’s rule, on the other hand, there is a polynomial-time algorithm for up to three candidates.Theorem 6. For Nanson’s rule and weighted votes, the coalitional manipulation problem can be solved in polynomial time for up to three candidates.Proof. Consider an election with three candidates (a, b, and p) in which the manipulators want p to win. We prove that in a successful manipulation, either all manipulators vote p (cid:10) a (cid:10) b or they all vote p (cid:10) b (cid:10) a. If p does not win using one of these two votes, then p cannot win. Therefore we simply try out the two votes and compute if p wins in either case.Suppose the manipulators can make p win. We first note that there is no harm in raising p to the first position while keeping the other parts of their preferences the same. By doing so, we ensure that the score of p goes up and the scores of a and b go down. The only possible change in the elimination process is that now both a and b drop out in the first round, so that p still wins.Now, suppose that all manipulators rank p in their top positions. Let P M denote a profile for the manipulators that makes p win. Because Nanson’s rule never selects the Condorcet loser, it cannot be the case that both a majority of voters prefer a to p, and b to p. Without loss of generality, suppose that a majority of voters prefer p to a. We argue that if all manipulators vote p (cid:10) a (cid:10) b, then p still wins. For the sake of contradiction, suppose all manipulators vote p (cid:10) a (cid:10) b but p does not win. As the manipulators still rank p in their top positions, the score of p in the first round is the same as in P M . Therefore, p must enter (and lose) the second round. Hence, only a is eliminated in the first round, and in the second round a majority of voters prefer b to p. However, having the manipulators vote p (cid:10) a (cid:10) b only lowers b’s score in the first round, compared to the case where they vote P M . Hence, when the manipulators vote P M , b also enters the second round and then a majority of voters prefer b to p, which is a contradiction.Therefore, if the manipulators can make p win, then they can make p win by all voting p (cid:10) a (cid:10) b, or all voting p (cid:10) b (cid:10) a. (cid:2)The reason that the above algorithm does not work for manipulating Baldwin’s rule is that the algorithm requires that we can place p as the first choice in every manipulating vote. However, in a successful manipulation in the proof of Theorem 4, the manipulators are split between p (cid:10) a (cid:10) b and a (cid:10) p (cid:10) b, and switching the votes of the latter group into p (cid:10) a (cid:10) b spoils the manipulation.The results in this section suggest that Baldwin’s rule is arguably harder to manipulate because Nanson’s rule is poly-nomial to manipulate with three candidates, and requires at least four candidates to be NP-hard, but Baldwin’s is NP-hard already with three candidates. It follows that computing a manipulation is NP-hard for both rules when votes are un-weighted, the number of candidates is small, and there is uncertainty about how agents have voted in the form of a probability distribution [12]. Note that the coalitional manipulation problem for Borda with weighted votes is NP-hard for three or more candidates [12]. Thus, somewhat surprisingly, adding an elimination round to Borda, which gives us Nan-son’s rule, decreases the computational complexity of computing a manipulation with three manipulators from NP-hard to polynomial-time.5. Heuristic methodsNP-hardness only characterises the worst-case complexity of computing a manipulation. Given enough manipulators, we can easily make any candidate win. We consider next minimising the number of manipulators required. For example, Reverse is a simple heuristic method proposed to compute Borda manipulations [43]. The method constructs each manipu-lator’s vote in turn: preferred candidate p is put in first place, and the remaining candidates are put in reverse order of their current Borda scores. The method continues constructing manipulating votes until p wins. A long and intricate argument shows that Reverse constructs a manipulation which uses at most one more manipulator than is optimal.Example 1. Suppose we have four candidates, c1, c2, c3, p, and the two non-manipulators have cast votes: c3 (cid:10) c1 (cid:10) c2 (cid:10) pand c2 (cid:10) c3 (cid:10) c1 (cid:10) p. Then we have the score vector (cid:7)3, 4, 5, 0(cid:8). We use Reverse to construct a manipulation that makes candidate p win. Reverse first constructs the vote: p (cid:10) c1 (cid:10) c2 (cid:10) c3. The score vector is now (cid:7)5, 5, 5, 3(cid:8). Reverse next constructs the vote: p (cid:10) c1 (cid:10) c2 (cid:10) c3. (It will not matter how ties between 1, 2, and 3 are broken.) The score vector is now (cid:7)7, 6, 5, 6(cid:8). Finally, Reverse constructs the vote: p (cid:10) c3 (cid:10) c2 (cid:10) c1. The score vector is (cid:7)7, 7, 7, 9(cid:8). Hence, Reverse requires three manipulating votes to make candidate p win. As we will see later, this is one more vote than in the optimal solution.J. Davies et al. / Artificial Intelligence 217 (2014) 20–4231Following [43], we propose four new heuristic methods. The first two algorithms work with all three voting rules. However, the last two algorithms are designed specifically for the elimination style of Baldwin’s and Nanson’s rules. All algorithms attempt to construct a manipulation with a specific number of manipulators. Hence, in order to find the best possible number of manipulators using one of these algorithms, we run it for one manipulator, then two and so on until a manipulation is found. We refer to a manipulation with k manipulators as a k-manipulation.5.1. Manipulation matricesIn this section we prove some auxiliary results that are needed to develop our heuristic algorithms.We can view Reverse as greedily constructing a manipulation matrix. A manipulation matrix is an n by m matrix A, where n is the number of manipulators, m is the number of candidates, and A(i, j) = k if and only if the ith manipulator adds a score of k to candidate c j . The jth column of the matrix, A( j), is the set of scores received by candidate c j , and each of the n rows is a permutation of 0 to m − 1. We require that the sum of the jth column is less than or equal to g(c j), the maximum score candidate c j can receive without defeating p. Reverse constructs this matrix row by row.Our new methods break out of the straightjacket of constructing a manipulation matrix in row-wise order. To achieve this, we take advantage of an interesting result that relaxes the constraint that each row is a permutation of 0 to m − 1. This lets us construct a relaxed manipulation matrix. This is an n by m matrix that contains n copies of 0 to m − 1 in which the sum of the jth column is again less than or equal to g(c j). In a relaxed manipulation matrix, a row can repeat an integer provided other rows compensate by not having that integer at all.Theorem 7. Suppose there is an n by m relaxed manipulation matrix A. Then there is an n by m manipulation matrix B with the same column sums.Proof. The proof is by induction on n. In the base case, n = 1 and we just set B(1, j) = A(1, j) for all j ∈ {1, . . . , m}. In the inductive step, we assume the theorem holds for all relaxed manipulation matrices with n − 1 rows. Let h(i) be the sum of the ith column of A. We use a perfect matching in a suitable bipartite graph to construct the first row of B and then appeal to the induction hypothesis on an n − 1 by m relaxed manipulation matrix constructed by removing the values in the first row from A.We build a bipartite graph as follows. The first half of the bipartite graph consists of m vertices {V i}|m−1i=0 , while the j=1. Each vertex V i represents a score, i, that must appear in the first second half of the graph consists of m vertices {W j}|mrow of B. Each vertex W j represents the jth column of A.We add the edge (V i, W j) to this bipartite graph for each i ∈ [0, m − 1], j ∈ [1, m], and k ∈ [1, n] where A(k, j) = i. An edge (V i, W j) therefore means that score i can be taken from the jth column of A.Note that there can be multiple edges between any pair of vertices. By construction, the degree of each vertex is n.Suppose we take any U ⊆ {V i | i ∈ [0, m − 1]}. Recall first that the Hall condition [25] states that a perfect matching exists if and only if |V | ≤ |N(V )| for all sets of vertices V (where N(V ) is the neighbourhood of V ). Since the degree of each vertex is n, there are n|U | edges leaving U . For the same reason, each vertex in N(U ) can accommodate at most nincoming edges. Therefore n|U | ≤ n|N(U )|. Hence, the Hall condition holds and a perfect matching exists. Consider an edge (V i, W j) in such a perfect matching. We construct the first row of B by setting B(1, j) = i. As this is a matching, each i ∈ [0, m − 1] occurs once, and each column is used exactly one time. We now construct an n − 1 by m matrix from A by removing one element equal to B(1, j) from each column j. By construction, each value i ∈ [0, m − 1] occurs n − 1 times, and the column sums are now h( j) − B(1, j). Hence it is a relaxed manipulation matrix. We can therefore appeal to the induction hypothesis. This gives us an n by m manipulation matrix B with the same column sums as A. (cid:2)We can extract from this proof a polynomial-time method to convert a relaxed manipulation matrix into a manipulation matrix. Hence, it is enough to propose new heuristic methods that construct relaxed manipulation matrices. This is advan-tageous for greedy methods like those proposed here, as we have more flexibility in placing integers into good positions in a relaxed manipulation matrix.5.2. Largest FitOur first heuristic method, Largest Fit is inspired by bin packing and multiprocessor scheduling. Constructing an n by mrelaxed manipulation matrix is similar to packing nm objects into m bins with a constraint on the capacity of the different bins and an extra constraint on the number of items (n) that can be placed in each bin. The problem is also similar to scheduling nm unit length jobs with different memory requirements on n different processors with a constraint on the total memory footprint of the n different jobs running at every clock tick and schedule length fixed to m. Krause et al. [27] have proposed a simple heuristic for this problem that schedules the unassigned job with the largest memory requirement to the time step with the maximum remaining available memory that has less than n jobs assigned.Largest Fit works in a similar way to construct a relaxed manipulation matrix. It assigns the largest unallocated score to the largest gap. More precisely, it first assigns n instances of m − 1 to column p of the matrix (since it is best for the 32J. Davies et al. / Artificial Intelligence 217 (2014) 20–42manipulators to put p in first place in their votes). It then allocates the remaining (n − 1)m numbers in reverse order to the columns corresponding to the candidate with the currently smallest score who has not yet received n votes from the manipulators. Unlike Reverse, we do not necessarily fill the matrix in row-wise order.Example 2. Consider again Example 1. We start with the score vector (cid:7)3, 4, 5, 0(cid:8). One manipulator alone cannot increase the score of candidate p enough to beat c2 or c3. Therefore, we need at least two manipulators. Largest Fit first puts two 3s in column 4 of the relaxed manipulation matrix. This gives the score vector (cid:7)3, 4, 5, 6(cid:8). The next largest score is 2. Largest Fitputs this into column 1 as this has the larger gap. This gives the score vector (cid:7)5, 4, 5, 6(cid:8). The next largest score is again 2. Largest Fit puts this into column 2 giving the score vector (cid:7)5, 6, 5, 6(cid:8). The two next largest scores are 1. Largest Fit puts them in columns 1 and 3, giving the score vector (cid:7)6, 6, 6, 6(cid:8). Finally, the two remaining scores of 0 are put in columns 2and 3, so all columns contain two scores. This gives a relaxed manipulation matrix corresponding to the manipulating votes: p (cid:10) c2 (cid:10) c1 (cid:10) c3 and p (cid:10) c1 (cid:10) c3 (cid:10) c2. With these votes, p wins based on the tie-breaking rule. Unlike Reverse, Largest Fitconstructs an optimal manipulation with just two manipulators.As we show in Section 5.5, Largest Fit and Reverse, are, in fact, incomparable. There is an infinite family of problems on which Largest Fit finds an optimal manipulation but Reverse does not, and vice versa.5.3. Average FitOur second heuristic method, Average Fit takes into account both the size of the gap and the number of scores still to be added to each column. If two columns have the same gap, we want to choose the column that contains fewer scores. To achieve this, we look at the average score required to fill each gap: that is, the size of the gap divided by the number of scores still to be added to the column. Each manipulator gives their largest score, m − 1, to the preferred candidate p and then has to distribute their remaining scores among other candidates. Initially, a manipulator has m − 1 scores to distribute. We call all manipulator scores that have not been distributed so far “unassigned scores”. At each step, Average Fit selects a column and a score to distribute to that column. First, the column is chosen, by selecting the column for which the size of the remaining gap divided by the number of scores still to be added to the column is largest. We tie-break by choosing the column containing the fewest scores. Then, an unassigned score is chosen to distribute to that column. We choose the largest unassigned score that will fit into that column’s gap. If there is no unassigned score that will fit into the gap, then the largest unassigned score is chosen.Example 3. Consider again Examples 1 and 2. We start with the score vector (cid:7)3, 4, 5, 0(cid:8). This method computes, identically to Largest Fit, that two manipulators are needed. Like Largest Fit, Average Fit first puts two 3s in column 4 of the relaxed manipulation matrix. This gives the score vector (cid:7)3, 4, 5, 6(cid:8). The next largest score is 2. Average Fit puts this into column 1 as this has the largest average 3/2. This gives the score vector (cid:7)5, 4, 5, 6(cid:8). The next largest score is again 2. Average Fitputs this into column 2, which has average 2/2 = 1, giving the score vector (cid:7)5, 6, 5, 6(cid:8). The two next largest scores are 1. Average Fit puts the first 1 in column 1, which has average 1/1 and the next 1 in column 3 which has average 1/2. This gives the score vector (cid:7)6, 6, 6, 6(cid:8). Finally, the two remaining scores of 0 are put in columns 2 and 3, so all columns contain two scores. This is identical to the manipulation computed by Largest Fit, with votes p (cid:10) c2 (cid:10) c1 (cid:10) c3 and p (cid:10) c1 (cid:10) c3 (cid:10) c2.For an example on which Average Fit beats Largest Fit, see Theorem 9. For an example on which Largest Fit beats Average Fit, see Theorem 10.5.4. Eliminate and Reverse EliminateOur next methods are designed to take into account the elimination style nature of Baldwin’s and Nanson’s rules.The first method, which we call Eliminate, repeatedly constructs votes in which the desired candidate is put in first place, and the other candidates in the reverse of the current elimination order. Thus, the first candidate eliminated is put in last place, the second candidate eliminated is put in the penultimate place, and so on. For Nanson’s rule, we order candidates eliminated in the same round by their Borda score in that round. The intuition behind Eliminate is to move the desired candidate up the elimination order whilst keeping the rest of the order unchanged.Our final method, which we call RevEliminate, repeatedly construct votes in which the desired candidate is put in first place, and the other candidates in the current elimination order. For instance, the first candidate eliminated is put in second place. For Nanson’s rule, we order candidates eliminated in the same round by the inverse of their Borda score in that round. The intuition behind RevEliminate is to move the desired candidate up the elimination order, and to assign the largest Borda scores to the least dangerous candidates.It is easy to show that all methods will eventually compute a manipulation of Nanson’s or Baldwin’s rule in which the desired candidate wins.Example 4. We revisit Examples 1–3 and show the operation of Eliminate for Baldwin’s rule. The initial score vector is (cid:7)3, 4, 5, 0(cid:8), so p is eliminated in the first round. In the second round, the score vector is (cid:7)1, 2, 3(cid:8), so c1 gets eliminated, and J. Davies et al. / Artificial Intelligence 217 (2014) 20–4233in the last round c3 and c2 are in a tie with the score vector (cid:7)1, 1(cid:8). We assume the tie is broken in favour of c2, so it wins the election. Therefore, Eliminate will have the first manipulator vote p (cid:10) c2 (cid:10) c3 (cid:10) c1. With one manipulator, this gives the score vector (cid:7)3, 6, 6, 3(cid:8). With tie breaking in favour of p, c1 is eliminated in the first round, so the score vector in the second round is (cid:7)4, 3, 2(cid:8), so p is eliminated in the second round. This means that we need at least one more manipulator. By construction, Eliminate can only change the step in which p is eliminated. The other candidates are eliminated in the same order amongst themselves. Hence, the vote of the second manipulator is also p (cid:10) c2 (cid:10) c3 (cid:10) c1. The initial score vector is now (cid:7)3, 8, 7, 6(cid:8). The candidate c1 is again eliminated in the first round. In the second round, the score vector is (cid:7)5, 3, 4(cid:8). Therefore, c3 is eliminated. In the third round, c2 and p are tied with the score vector (cid:7)2, 2(cid:8). Since we break ties in favour of the preferred candidate, Eliminate has computed a manipulation with two manipulators. This is optimal.With RevEliminate, the first manipulator votes p (cid:10) c1 (cid:10) c3 (cid:10) c2. This gives the score vector (cid:7)5, 4, 6, 3(cid:8). Hence p is again eliminated in the first round. The score vector in the second round is (cid:7)3, 2, 4(cid:8). Hence c2 is eliminated. In the third round, The score vector in the second round is (cid:7)1, 2(cid:8). Hence c1 is eliminated and c3 wins. The vote of the second manipulator is therefore p (cid:10) c2 (cid:10) c1 (cid:10) c3. This gives the score vector (cid:7)6, 6, 6, 6(cid:8). We suppose tie breaking eliminates c3. The score vector in the second round is (cid:7)4, 4, 4(cid:8). We suppose tie breaking now eliminates c2. The score vector in the third round is (cid:7)2, 2(cid:8). Since we break ties in favour of p, RevEliminate has also computed an optimal manipulation.5.5. Theoretical propertiesFirst, we show that Largest Fit is incomparable to Reverse since there exists an infinite family of problems on which Largest Fit finds an optimal manipulation but Reverse does not, and vice versa.Theorem 8. For Borda voting, there exists an election for which Largest Fit finds an optimal 2-manipulation, but Reverse produces a 3-manipulation.Proof. We suppose there are just two non-manipulators with votes σ and σ (cid:15)σ = (cid:7)1, 2, . . . , m − 1, 0(cid:8) and let, and the preferred candidate p is cm. Let σ (cid:15) =(cid:10)m2+ 1,m2+ 2, ...,m2+ m2− 1, 1, 2, ...,(cid:11), 0.m2Thenσ + σ (cid:15) =(cid:10)(cid:12)(cid:13)(cid:12)+ 1,2 + m21 + m2(cid:13)(cid:12)+ 2, ...,m2− 1 + m2+ m2(cid:13)(cid:12)− 1,m2(cid:13)+ 1, ...,(cid:12)m − 1 + m2(cid:13)(cid:11), 0.2This gives m21 ≤ i ≤ m − 1. Before continuing, we rename the candidates so that s(cm, P ) = 0 and s(ci, P ) = m22 , or in other words, there exists a score m+ 2x for 1 ≤ x ≤ m2+ 2x − 1 for 1 ≤ x ≤ m− 1 and m2Recall that the preferred candidate is p = cm. The first vote generated by Reverse is v 1 = p (cid:10) c1 (cid:10) c2 (cid:10) · · · (cid:10) cm−1, after which s(ci, P ∪ {v 1}) = m+ m − 1 for all candidates ci (cid:9)= cm. This is larger than the score of the distinguished candidate 2s(p, P ∪ {v 1}) = m − 1. Therefore another manipulator is added. Without loss of generality, we suppose its vote is v 2 = cm (cid:10)+ (m − 1) + (m − i − 1) =c1 (cid:10) c2 (cid:10) · · · (cid:10) cm−1. The resulting scores of the competing candidates are s(ci, P ∪ {v 1, v 2}) = m2(5/2)m − 2 − i. So candidate c1 still has larger score than s(p, P ∪ {v 1, v 2}) = 2m − 2. Therefore, Reverse does not find a 2-manipulation. Note that, as Reverse never uses more than one additional manipulator than is optimal, it will successfully find a 3-manipulation.+ i for all 1 ≤ i ≤ m − 1.+ i for all Largest Fit will first give the highest scores, m − 1, from both manipulators to the preferred candidate. Then in each iteration, Largest Fit will place a score from the multi-set S2 = {0, . . . , m − 2} (cid:18) {0, . . . , m − 2} into the manipulation ma-trix B. The first m − 1 iterations of Largest Fit will place the kth largest score from S 2 into the kth column of matrix Bfor 1 ≤ k ≤ m − 1. Note that the kth largest score is m − 2 − (cid:19)(k − 1)/2(cid:20). Let Bm−1 be the tentative manipulation matrix at this point and write sum(Bm−1(i)) for the sum of the elements of its ith column. Then, the score of candidate ci under this partial manipulation is sum(Bm−1(i)) + s(ci, P ) = (m − 2 − (cid:19)(i − 1)/2(cid:20)) + m+ i for all i, hence sum(Bm−1(i)) + s(ci, P ) ≤2sum(Bm−1(i + 1)) + s(ci+1, P ) for all 1 ≤ i ≤ m − 2, and so the relative order of the candidates’ scores does not change. The − 2}. The next m − 1 iterations of Largest Fit will multi-set of scores available at this point is S(cid:15)2 into the kth column of matrix B for 1 ≤ k ≤ m − 1. So column i will receive the element place the kth largest score from S− 1 − (cid:21)(i − 1)/2(cid:22). Let B2(m−1) be the matrix when the loop terminates. The score of candidate ci under the manipulation m2B2(m−1) is sum(B2(m−1)(i)) + s(ci, P ) = (m − 2 − (cid:19)(i − 1)/2(cid:20)) + ( m− 1 − (cid:21)(i − 1)/2(cid:22)) = 2(m − 1) for all i, while 2the achievable score of candidate p is also 2(m − 1). Therefore, Largest Fit finds a 2-manipulation. Fig. 1 illustrates how the scores are placed in matrix B by Largest Fit, where the shaded area represents the scores s(ci, P ). (cid:2)− 1} (cid:18) {0, . . . , m2= {0, . . . , m2+ i) + ( m2(cid:15)2Unfortunately, Largest Fit does not share the guarantee of Reverse that in the worst case it requires one more manipu-lator than is optimal. In fact the number of extra manipulators used by Largest Fit is not bounded.34J. Davies et al. / Artificial Intelligence 217 (2014) 20–42Fig. 1. The 2-manipulation generated by Largest Fit for the election in Theorem 8.Theorem 9. For Borda voting, there exists an election with 4 candidates and 2k votes (k divisible by 36) on which both Reverse and Average Fit will find an optimal manipulation but Largest Fit requires at least k/9 − 3 additional manipulators.Proof. Consider a Borda election in which the scores of four candidates after the non-manipulators P vote are s(c1, P ) = 6k, s(c2, P ) = 4k, s(c3, P ) = 2k, s(p, P ) = 0. These scores can be achieved if all 2k votes are c1 (cid:10) c2 (cid:10) c3 (cid:10) p. Reverse will use 2kmanipulators, all voting p (cid:10) c3 (cid:10) c2 (cid:10) c1, to achieve a score of 6k for all candidates. This is the only optimal manipulation. To see that Average Fit will find the optimal manipulation, note that the initial gaps are 0, 2k, and 4k and the averages 0, 1, and 2 for candidates c1, c2 and c3, respectively. In the first step, Average Fit will assign a score of 2 to candidate c3 and will continue to do that as long as the average of candidate c3 is greater than that of candidate c2. To find when that happens, we let x be the number of iterations and solve 4k−2x= 1 ⇒ x = 2k. This means that Average Fit will give all 2k scores of 2 2k−xto candidate c3. Similarly, we see that it will give all scores of 1 to candidate c2 and only scores of 0 to candidate c1. This means that all manipulators will vote p (cid:10) c3 (cid:10) c2 (cid:10) c1, the only optimal manipulation.It remains to argue that Largest Fit requires more than 2k + k/9 − 4 manipulators. We exploit the fact that Largest Fitis monotonic, in the sense that if it finds a successful Borda manipulation with a given number of manipulators, it also succeeds with more. Additional manipulators only give Largest Fit more opportunity to increase the score of the preferred candidate over the other candidates. Assume for contradiction that we find a manipulation using n = 2k +k/9 −4 = 19k/9 −4manipulators. We will follow the execution of Largest Fit until a contradiction is obtained. By monotonicity, Largest Fitcannot use 2k + k/9 − 4 or fewer manipulators. Note that given our definition of n, since k is divisible by 4 and 9, n−kis an integer.Let B denote the relaxed manipulation matrix constructed by Largest Fit, and let B(i), i ∈ {1, . . . , m} denote its ith column. We write sum(B(i)) for the sum of the elements in B(i). First, the algorithm will place k 2’s in B(3), at which point sum(B(3)) = 2k + 2k = 4k = s(2, P ). Then it will begin to place 2’s in columns B(2) and B(3) evenly, until all remaining n − k 2’s have been placed into B. At this point, B(2) contains n−k2’s, and the number of 2’s that B(3) contains is k + n−k= k/2 + n/2 = k/2 + (19k/9 − 4)/2 = 14k/9 − 2 < 19k/9 − 4 = n. So at this point, neither B(3) nor B(2) is full yet (B(2) has fewer elements than B(3)). Both columns sum to 4k + 2( n−k2 ) = 46k/9 − 4 = 5k + k/9 − 4 < 6k. Therefore, the algorithm will start putting 1’s in both B(2) and B(3) evenly, until either their column sums reach 6k or B(3) gets filled. In fact, B(3) will be filled before its sum reaches 6k, since B(3) requires n−k2 more elements to be filled, but at this point, sum(B(2)) = sum(B(3)) = 46k/9 − 4 + n−k= 51k/9 − 6 = 5k + 2k/3 − 6 < 6k.Now, the algorithm will continue by putting k/3 + 6 1’s into B(2), at which point sum(B(2)) = 51k/9 − 6 + k/3 + 6 = 6k. Then the algorithm will start putting 1’s evenly in both B(1) and B(2), until either it runs out of 1’s or B(2) is filled. In fact, the 1’s will run out before B(2) is filled, since B(2) requires n − ( n−k+ k/3 + 6) = 2k/3 − 6 more elements, which is equal to the number of remaining 1’s, but these are spread between B(1) and B(2). So B(2) will get (2k/3 − 6)/2 =k/3 − 3 additional 1’s, for a total of sum(B(2)) = 4k + 2( n−k+ k/3 + 6 + k/3 − 3 = 19k/3 − 3 > 19k/3 − 12 = 3n. Since sum(B(2)) > 3n there is no manipulation using n = 19k/9 − 4 manipulators. Therefore, Largest Fit requires at least n + 1 = 2k + k/9 − 3 manipulators. (cid:2)2 ) + n−k+ n−k2222222Average Fit is also incomparable to Largest Fit. Like Reverse, Average Fit finds optimal manipulations on the elections in the proof of Theorem 9. However, there exist examples on which Largest Fit finds an optimal manipulation but Average Fitdoes not.J. Davies et al. / Artificial Intelligence 217 (2014) 20–4235Theorem 10. For Borda voting, there exist an election on which Largest Fit finds an optimal manipulation but Average Fit requires an additional vote.Proof. We failed to find a simple example but a computer search using randomly generated instances gave the following. Consider an election in which the manipulators wish candidate c8 to win, and 8 non-manipulators have voted as follows:#voters31112votec1 (cid:10) c2 (cid:10) c3 (cid:10) c4 (cid:10) c5 (cid:10) c6 (cid:10) c7 (cid:10) c8c1 (cid:10) c2 (cid:10) c3 (cid:10) c4 (cid:10) c5 (cid:10) c7 (cid:10) c6 (cid:10) c8c1 (cid:10) c2 (cid:10) c3 (cid:10) c6 (cid:10) c5 (cid:10) c4 (cid:10) c7 (cid:10) c8c7 (cid:10) c1 (cid:10) c6 (cid:10) c5 (cid:10) c4 (cid:10) c2 (cid:10) c3 (cid:10) c8c8 (cid:10) c7 (cid:10) c6 (cid:10) c5 (cid:10) c4 (cid:10) c3 (cid:10) c2 (cid:10) c1This gives the score vector for (cid:7)c1, . . . , c8(cid:8) of:(cid:7)41, 34, 30, 27, 27, 26, 25, 14(cid:8).On this problem, Largest Fit finds an optimal manipulation that makes the final candidate win but Average Fit requires an additional vote. The calculations are shown in Appendix A. (cid:2)So far we have not found any instances where Reverse performs better than Average Fit.Finally, we consider properties of heuristic algorithms with respect to Baldwin’s and Nanson’s rules. It appears that it is harder to find an approximately optimal manipulation for these rules than for the Borda rule. For all our heuristic methods, we can give examples where the heuristic computes a manipulation that uses several more manipulators than is optimal. The most interesting result is that although Reverse was shown to never require more than one extra manipulator than optimal under the Borda rule [43], the result does not transfer to Baldwin’s and Nanson’s rules. Indeed, even with a fixed number of candidates, Reverse can require an unbounded number of extra manipulators.Theorem 11. For Baldwin’s rule, there exists an election with 7 candidates and 42n votes (n even) where Reverse computes a manip-ulation with at least 10n more votes than is optimal.Proof. Consider an election over candidates a, b, c, d, e, f , and p where p is the preferred candidate of the manipulators. We define V (u,v) as the pair of votes: {u (cid:10) v (cid:10) Others (cid:10) p, rev(Others) (cid:10) u (cid:10) v (cid:10) p}, where Others is some fixed ordering of the other candidates and rev(Others) is its reverse. Note that these votes differ from the pair of votes W (u,v) defined in Section 2. The non-manipulators cast the following votes: 3n copies of V (a,b), V (b,c), V (c,d), V (d,e), and V (e, f ). In addition, there are 6n copies of the votes: p (cid:10) a (cid:10) Others and rev(Others) (cid:10) p (cid:10) a. After the non-manipulators have voted, s(a) = s( f ) = 138n, s(b) = s(c) = s(d) = s(e) = 141n, and s(p) = 42n.If 18n manipulators vote identically p (cid:10) a (cid:10) . . . (cid:10) f then p wins. The following table shows scores of all candidates in 6 rounds.s(a)228n189n150n111n72n30ns(b)213n174n135n96n54n−s(c)195n156n117n73n−−s(d)177n138n96n−−−s(e)s( f )s(p)138n159n117n −−−−−−−−−150n126n102n78n54n30nRound 1Round 2Round 3Round 4Round 5Round 6By the tie-breaking rule, p wins in the last round.This manipulation provides an upper bound on the size of an optimal manipulation for Baldwin’s rule.Reverse will put p in the first place, then a and fin some order, and then the remaining candidates. Without loss of generality, we suppose Reverse breaks ties by constructing the vote p (cid:10) a (cid:10) f (cid:10) b (cid:10) c (cid:10) d (cid:10) e. It alternates this vote with p (cid:10) a (cid:10) f (cid:10) e (cid:10) d (cid:10) c (cid:10) b. After n such manipulating votes have been constructed, the scores of candidates a to f are level at 142n + n/2, and p is at 48n. From then on, the manipulators put p in first place and alternate the order of the other candidates. Without loss of generality, we suppose Reverse breaks ties by constructing the vote p (cid:10) a (cid:10) b (cid:10) c (cid:10) d (cid:10) e (cid:10) f . It alternates this vote with p (cid:10) f (cid:10) e (cid:10) d (cid:10) c (cid:10) b (cid:10) a. At least 28n votes are therefore required in total for p to move out of last place. Hence, Reverse requires at least 10n extra manipulators compared to the optimum number for Baldwin’s. (cid:2)Theorem 12. For Nanson’s rule, there exists an election with four candidates and 110n votes where Reverse computes a manipulation with at least 4n more votes than is optimal.36J. Davies et al. / Artificial Intelligence 217 (2014) 20–42Table 1Percentage of elections drawn from the impartial culture model for which each heuristic found an optimal manipulation with Borda voting.m48163264128Total# Inst.27715893596659685962594232 502ReverseLargest FitAverage Fit94.2%85.5%76.8%71.1%66.8%65.3%74.9%92.9%87.7%81.9%80.7%80.0%79.9%83.0%100.0%99.3%98.6%98.5%98.4%98.0%98.7%Largest FitbeatsAverage Fit0.00%0.03%0.05%0.02%0.05%0.03%0.03%Proof. Consider an election over a, b, c, and p, where p is the preferred candidate of the manipulators. We use the votes W (u,v) defined in Section 2. Non-manipulators cast the following votes: 15n copies of W (a,c), W (b,c) and W (b,p), and 10ncopies of W (a,p). After the non-manipulators have voted, s(a) = 190n, s(b) = 195n, s(c) = 135n, and s(p) = 140n. The average score is 165n.If 21n manipulators vote identically p (cid:10) c (cid:10) a (cid:10) b then p wins. The following table shows scores of all candidates in two rounds.averages(a)Round 1Round 2196.5n65.5n211n65ns(b)195n−s(c)177n−s(p)203n66nHence, p wins in the last round.This manipulation provides an upper bound on the size of an optimal manipulation for Nanson’s rule.Reverse will construct the vote p (cid:10) c (cid:10) a (cid:10) b. After 5n such manipulating votes, the scores of a and b will become level.Reverse will then alternate between p (cid:10) c (cid:10) b (cid:10) a and p (cid:10) c (cid:10) a (cid:10) b. In total, Reverse will construct 25n such manipulating votes, 15n for p (cid:10) c (cid:10) a (cid:10) b and 10n for p (cid:10) c (cid:10) b (cid:10) a. At this point, p wins under Nanson’s rule as demonstrated in the following table.averages(a)s(b)s(c)Round 1Round 2202.5n135n205n135n185n205n135n −s(p)215n135nNote that p wins in the second round by our tie-breaking assumption. Hence, Reverse uses 4n extra manipulators compared to the optimum number for Nanson’s. (cid:2)These results demonstrate that, for Baldwin’s and Nanson’s rules, Reverse does not approximate the optimal number of manipulators by an additive constant (as it does for Borda).6. Experimental resultsTo test the performance of these heuristic methods in practice, we ran some experiments. Our experimental setup is based on that in [38]. We generated votes drawn either from the impartial culture model, or the Polya–Eggenberger urn model [5]. In the urn model, votes are placed in an urn and drawn at random. Votes are placed back into the urn along with b other votes of the same type. This captures varying degrees of social homogeneity. We set b = m! so that there is an approximately 50% chance that the second vote is the same as the first. In both models, we generated between 22 and 27votes for varying m.6.1. Borda ruleFirst we present our results for the Borda rule. Manipulation under the Borda rule can be easily modelled as a constraint satisfaction problem. We used this property to obtain optimal solutions for our instances. We tested 1000 instances at each problem size and determined if the returned manipulations are optimal, by modelling the problem of finding an optimal manipulation as a constraint satisfaction problem and solving it using the solver Gecode [23].The constraint solver found an optimal manipulation in 32 502 out of the 32 679 distinct impartial culture elections within the 1 hour time-out. Results are shown in Table 1. Both Largest Fit and Average Fit provide a significant improve-ment over Reverse, solving 83% and 99% of instances to optimality. Reverse solves fewer problems to optimality as the J. Davies et al. / Artificial Intelligence 217 (2014) 20–4237Table 2Percentage of elections drawn from an urn model for which each heuristic found an optimal manipulation with Borda voting.m48163264128Total# Inst.39295501550255325494557131 529ReverseLargest FitAverage Fit93.3%85.6%79.2%72.4%67.6%64.5%76.3%66.3%50.1%41.1%36.3%33.0%30.6%41.7%100.0%99.9%99.5%99.5%99.7%99.9%99.7%Largest FitbeatsAverage Fit0.00%0.00%0.02%0.00%0.00%0.00%0.00%Table 3Average number of manipulators required by each heuristic in elections drawn from an impartial culture model using the Borda rule.n48163264128Opt.9.306.337.087.868.629.29ReverseLargest FitAverage Fit9.366.487.318.158.959.639.376.457.268.068.829.499.306.347.107.888.639.31Table 4Average number of manipulators required by each heuristic in elections drawn from an urn model using the Borda rule.n48163264128Opt.42.2132.6734.0835.0636.7637.70ReverseLargest FitAverage Fit42.2832.8234.2935.3437.0938.0642.9433.7835.6836.9738.9239.9842.2132.6734.0935.0736.7737.71number of candidates increases, while Average Fit does not seem to suffer from this problem as much: Average Fit solved all of the four candidate instances and 98% of the 128 candidate ones. Table 3 shows the average number of manipulators used by each of the heuristics, compared to the average optimal number of manipulators. We also note that in every one of the 32 502 instances, if Reverse found a k vote manipulation either Average Fit did too, or Average Fit found a (k − 1)vote manipulation, i.e., Average Fit never found a worse solution than Reverse. Furthermore, Largest Fit used at most two more manipulators than the optimum.With the urn model, we were able to find an optimal manipulation for 31 529 out of the 31 530 elections within the 1 hour time-out. Tables 2 and 4 give results. Reverse solves about the same proportion of the urn instances as impartial culture instances, 76%. However, the performance of Largest Fit drops significantly. It is much worse than Reverse solving only 42% of instances to optimality. Furthermore, in contrast to the impartial culture elections where Largest Fit used at most two extra manipulators, here Largest Fit used up to 14 more manipulators than the optimum. The reason for such behaviour is that the non-manipulators’ profiles in urn instances are similar to the profiles in the proof of Theorem 9, where Largest Fit requires an unbounded number of additional manipulators. The good performance of Average Fit is maintained. It found an optimal manipulation on more than 99% of the instances. It never lost to Reverse and was only beaten by Largest Fit on one instance in our experiments.These results suggest that while Borda manipulation is NP-hard, in practice the simple heuristic algorithms that we pro-posed can compute optimal manipulations in the vast majority of cases. Thus, it appears that Borda elections are vulnerable to manipulation.6.2. Baldwin’s and Nanson’s rulesIt is much more difficult to model the unweighted coalitional manipulation problem under Baldwin’s and Nanson’s rules as a constraint satisfaction problem since the scores of the candidates in each vote change in each round. Hence, we partitioned our experiments into two parts: small problems where we can find an optimum solution in a brute-force manner and large problems that show how heuristic algorithms scale.Our first set of experiments used 3000 elections with five candidates and five non-manipulating voters. This is small enough to find the optimal number of manipulators using brute force search, and thus to determine how often a heuristic computes an optimal solution. We threw out the 20% or so of instances generated in which the preferred candidate has 38J. Davies et al. / Artificial Intelligence 217 (2014) 20–42Table 5Percentage of elections drawn from an impartial culture model with five candidates where the heuristic finds an optimal manipulation.RulesBaldwinNansonBordaReverse74.4%74.6%95.7%Largest FitAverage FitEliminateRevEliminate74.4%76.0%98.8%75.8%78.0%99.8%62.2%65.4%95.7%75.2%66.9%10.7%Table 6Percentage of elections drawn from an urn model with five candidates where the heuristic finds an optimal manipulation.RulesBaldwinNansonBordaReverseLargest FitAverage FitEliminateRevEliminate75.1%78.1%96.1%75.4%79.0%92.7%77.3%79.8%99.9%68.9%72.2%96.1%83.4%79.4%4.4%Table 7Average number of manipulators required by each heuristic in elections drawn from an impartial culture model using Baldwin’s rule.n48163264128ReverseLargest FitAverage FitEliminateRevEliminate2.252.994.315.938.5612.132.253.074.416.038.6512.242.253.014.406.148.8412.412.443.354.796.619.5413.372.213.064.676.8411.0216.06Table 8Average number of manipulators required by each heuristic in elections drawn from an impartial culture model using Nanson’s rule.n48163264128ReverseLargest FitAverage FitEliminateRevEliminate2.152.914.135.808.5112.072.172.964.275.888.5812.092.152.844.055.818.8213.002.253.054.446.188.9912.602.283.214.997.4612.0417.90Table 9Average number of manipulators required by each heuristic in elections drawn from an urn model using Baldwin’s rule.n48163264128ReverseLargest FitAverage FitEliminateRevEliminate3.265.9511.6421.7043.0982.193.235.9611.6621.7843.3781.823.245.9911.8722.3544.2483.623.356.3712.7424.6749.0795.373.145.8211.5222.4145.7091.80already won before the manipulators vote. Results are given in Tables 5–6. The tables demonstrate that heuristics that are very effective at finding an optimal manipulation for the Borda rule do not perform as well for Baldwin’s and Nanson’s rules. For example, AverageFit almost always finds an optimal manipulation of the Borda rule but can only find optimal solutions about three quarters of the time for Baldwin’s or Nanson’s rules. Note that Eliminate and RevEliminate are strictly speaking defined just for Nanson’s and Baldwin’s rules. With the Borda rule, we can simply use the same manipulating votes they construct with, say, Baldwin’s rule. These put the preferred candidate in first place so eventually must be successful in constructing a successful Borda manipulation.In our second set of experiments, we eschew computation of an optimal manipulation in order to use larger problems. This amplifies the differences between the different heuristic methods. Similarly to Section 6.1, we tested 1000 instances at each problem size, which gives 6000 instances in total.Tables 7–10 show the results for the average number of manipulators. The results show that, with Nanson’s and Baldwin’s rules, Reverse works slightly better overall compared to LargestFit and AverageFit, which themselves outperform the other two methods especially for problems with large number of candidates. This contrasts with the results on the Borda rule in the previous section, where LargestFit and AverageFit do much better than Reverse. In most cases AverageFit is less effective than LargestFit except urn elections with Nanson’s rule.These experimental results suggest that Baldwin’s and Nanson’s rules are harder to manipulate in practice than Borda. Heuristic methods that work well on the Borda rule are significantly less effective on these rules. Overall, Reverse, Largest-Fit, and AverageFit appear to offer the best performance, though no heuristic dominates.J. Davies et al. / Artificial Intelligence 217 (2014) 20–4239Table 10Average number of manipulators required by each heuristic in elections drawn from an urn model using Nanson’s rule.n48163264128ReverseLargest FitAverage FitEliminateRevEliminate3.205.9311.6222.3644.5687.183.195.9811.9322.7845.5087.553.205.9511.6422.5344.7786.763.286.1312.1624.0048.8197.023.226.0912.3724.3949.6999.43Fig. 2. Permutation matrix with restricted diagonals sums (PMRDS).7. Related problemsThere exists an interesting connection between the problem of finding a coalition of two manipulators for the Borda voting rule and two other problems in discrete mathematics: the problem of finding a permutation matrix with restricted diagonals sums (PMRDS) [9] and the problem of finding multi Skolem sequences [30]. We consider this connection for two reasons. First, future advances in these adjacent areas may give insights into new manipulation algorithms or into the complexity of manipulation. Second, this connection reveals an interesting open case for Borda manipulation – Nordh has conjectured that when the gaps g(i) of all candidates are distinct, then manipulation can be done in polynomial time [31].A permutation matrix is an n by n Boolean matrix which is obtained from an identity matrix by a permutation of its columns. Hence, a permutation matrix contains a single value 1 in each row and each column. Consider the 2n − 1diagonals of the matrix, numbering them from the top right to bottom left, and let di be the sum of the elements of the ith diagonal. Finding a permutation matrix such that its diagonal sums form a given sequence (d1, . . . , d2n−1) is the permutation matrix with restricted diagonals sums problem. This problem occurs in discrete tomography, where we need to construct a permutation matrix from its X-rays for each row, column, and diagonal. The X-ray values for each row and column are one, while the values for the diagonal are represented by the sequence (d1, . . . , d2n−1).We transform a Borda manipulation problem with m + 1 candidates and 2 manipulators such that i=1 g(i) = m(m − 1)to a PMRDS problem on an m by m matrix. Note that here we use m to denote the number of candidates excluding the preferred candidate. Note that such a manipulation problem is tight, i.e., all gaps will be matched exactly, and all candidates will have the same score after the manipulation. In parallel with the description of the transformation, we illustrate it with the following example with five candidates. Our preferred candidate is 4. Let (cid:7)4, 4, 6, 6, 0(cid:8) be a score vector, where our preferred candidate has 0 score, and (cid:7)4, 4, 2, 2(cid:8) be the corresponding gap vector. We label rows of a permutation matrix with scores given by the first manipulator, and columns of the permutation matrix with the reverse of the scores given by the second manipulator. We label each element of the matrix with the sum of its row and column labels. Fig. 2a shows the labelling for our example in gray.(cid:2)mNote that each element on a diagonal is labelled with the same value. Therefore, each diagonal labelled with value krepresents the gap of size k in the manipulation problem. Hence, the sum of the diagonal di labelled with k encodes the number of occurrences of gaps of size k. For example, d3 = 2 ensures that there are two gaps of size 2 and d5 = 2 ensures that there are two gaps of size 4. The remaining diagonal sums, di , i ∈ {1, 2, 4, 6, 7}, are fixed to zero.Consider a solution of PMRDS (Fig. 2b). Suppose the cell P (x, y) contains the value one. We conclude that the first manipulator gives the score x and the second gives the score m − y − 1 to a candidate with the gap x + (m − y − 1). In our example, cell P (0, 1) contains one, hence the first manipulator gives the score 0 and the second gives the score m − y − 1 = 4 − 1 − 1 = 2 to a candidate with the gap 2. By examining all cells with the value one, we obtain the complete votes of the manipulators, which in our example are (4 (cid:10) 1 (cid:10) 2 (cid:10) 0 (cid:10) 3) for the first manipulator and (4 (cid:10) 0 (cid:10) 3 (cid:10) 1 (cid:10) 2) for the second, to fill the gaps (cid:7)4, 4, 2, 2(cid:8). As the number of ones in each diagonal is equal to the number of occurrences of the corresponding gap, the constructed two manipulator votes make our candidate a winner. The total scores are (cid:7)8, 8, 8, 8, 8(cid:8).Finding a coalitional manipulation under the Borda rule using two manipulators is also connected to the problem of finding multi Skolem sequences used for the construction of Steiner triple system [30]. Given a multi-set of positive integers 40J. Davies et al. / Artificial Intelligence 217 (2014) 20–42Table 11Operation of Largest Fit when trying to find a manipulation with four manipulators. The first seven columns show the gaps of the candidates. In the final column, we use the notation x : y to indicate that Largest Fitassigns vote x to candidate y. The preferred candidate (c8, not shown in the table) gets 7 from all four manipulators, thus its score is 42. We omit the 0 scores.c1c211111111111111111111100008888888888444444111111000c3121212121277777733333311111100c415151515999995555222220000000c51515159999944444441111111110c616161010101010555555522222000000c71711111111116666662222222200000Vote6:76:66:56:45:35:75:65:54:44:24:34:73:43:63:53:22:32:42:62:71:11:21:31:5(cid:15)imH = {h1, . . . , hm} we need to decide whether there exists a partition P of the set {1, . . . , 2m} into pairs (pi, pso that H ≡ {pi − p| (pi, pulators with gaps G = {g(1), . . . , g(m)} such that (cid:2)(cid:15)i), i = 1, . . . , m, (cid:15)i) ∈ P }. There is a reduction from a manipulation problem with m + 1 candidates and 2 manip-i=1 g(i) = m(m − 1) to a special case of multi Skolem sequences with i=1 hi = m2 similar to the reduction from a scheduling problem in [30].2 The multi Skolem sequence instance that corre-sponds to a manipulation instance is defined by H = {2m − g(1) − 1, . . . , 2m − g(m) − 1}. If a manipulation is given by the votes σ , π , then the partitions (2m −σ (i), π (i) +1) satisfy 2m −σ (i) −π (i) −1 = 2m − g(i) −1. Conversely, suppose there ex-(cid:15)(cid:15)ists partition P of the set {1, . . . , 2m} into pairs (pi, pi) ∈ P , i = 1, . . . , m. Then the i, (pi, p− 1 = 2m −(2m − g(i) − 1) − 1 = g(i).votes are given by σ (i) = 2m − pi, π (i) = p(cid:15)i), i = 1, . . . , m, so that hi = pi − p(cid:15)− 1, which satisfy σ (i) +π (i) = 2m − pi + pi(cid:2)m(cid:15)i8. ConclusionsIn this paper we have investigated theoretically and empirically the computational complexity of manipulation problems for the Borda voting rule and two extensions of Borda voting, Baldwin’s and Nanson’s rules. We proved that it is NP-hard to compute a coalitional manipulation of the Borda rule with just two manipulators. This resolves a long-standing open question regarding the computational complexity of unweighted coalitional manipulation for common voting rules. We showed that two other rules, Baldwin’s and Nanson’s rules, which are derived from the Borda rule are also NP-hard to manipulate both with weighted and unweighted votes. Because of these NP-hardness results, we proposed several simple heuristic methods. We showed that they can compute optimal manipulations of the Borda rule in almost all the randomly generated elections. This suggests that the Borda rule is not resistant to manipulation in practice. In contrast, these heuristic algorithms did not perform as well in either Baldwin or Nanson elections, suggesting that these elimination style rules are more resistant to manipulation than the Borda rule.AcknowledgementsGeorge Katsirelos was partially supported by the ANR UNLOC project ANR 08-BLAN-0289-01. Nina Narodytska and Toby Walsh are supported by the Australian Department of Broadband, Communications and the Digital Economy, the Australian Research Council, and the Asian Office of Aerospace Research and Development (AOARD-104123). Toby Walsh is currently supported by the German Federal Ministry for Education and Research through the Alexander von Humboldt Foundation. Lirong Xia acknowledges an RPI startup fund, NSF Grant #1136996 to the Computing Research Association for the CIFellows Project, and Vincent Conitzer’s NSF CAREER 0953756 and IIS-0812113 for support.2 The reduction implicitly assumes that mi=1 hi = m2 as the author confirmed in a private communication.(cid:2)J. Davies et al. / Artificial Intelligence 217 (2014) 20–4241Table 12Operation of Average Fit when trying to find a manipulation with four manipulators. Since the algorithm works on averages, we show averages as fractions to convey both the actual gap, and the remaining number of votes.c11/41/41/41/41/41/41/41/41/41/41/41/41/41/41/41/41/41/41/41/4c28/48/48/48/48/48/48/48/48/48/48/48/48/48/45/35/35/35/33/21/1c312/412/412/412/412/412/412/47/37/37/37/37/37/34/24/21/11/11/11/11/1c415/415/415/415/49/39/39/39/39/35/25/25/21/11/11/11/11/11/11/11/1c515/415/415/49/49/39/39/39/34/24/24/24/24/24/24/24/21/11/11/11/1c616/416/410/310/310/310/35/25/25/25/25/21/11/11/11/11/11/11/11/11/1c717/411/311/311/311/36/26/26/26/26/22/12/12/12/12/12/12/10/00/00/0Vote6:76:66:56:45:75:65:35:54:44:74:64:43:33:23:33:52:72:22:2Appendix A. Proof of Theorem 10In Table 11, we show the operation of Largest Fit when trying to find a manipulation with four manipulators. This is eas-ily seen to be optimal because the maximum score of the preferred candidate that can be achieved with three manipulatorsis 35, which is not enough to defeat the 1st candidate. Based on these assignments, we find a perfect matching on the manipulation matrix (not shown), as described in Theorem 7. This gives the following votes for the manipulators:(cid:7)0, 4, 2, 3, 1, 5, 6, 7(cid:8)(cid:7)1, 0, 4, 2, 3, 6, 5, 7(cid:8)(cid:7)0, 1, 5, 4, 6, 3, 2, 7(cid:8)(cid:7)0, 3, 1, 6, 5, 2, 4, 7(cid:8)In Table 12, we show the operation of Average Fit. At this point, the algorithm has yet to place a 2, but all candidates have gap of at most 1, so it has failed to find a manipulation. (cid:2)References[1] J. Baldwin, The technique of the Nanson preferential majority system of election, Trans. Proc. R. Soc. Vic. 39 (1926) 42–52.[2] J. Bartholdi, J. Orlin, Single transferable vote resists strategic voting, Soc. Choice Welf. 8 (4) (1991) 341–354.[3] J. Bartholdi, C. Tovey, M. Trick, The computational difficulty of manipulating an election, Soc. Choice Welf. 6 (3) (1989) 227–241.[4] J. Bartholdi, C. Tovey, M. Trick, How hard is it to control an election? Math. Comput. Model. 16 (8–9) (1992) 27–40.[5] S. Berg, Paradox of voting under an urn model: the effect of homogeneity, Public Choice 47 (1985) 337–387.[6] N. Betzler, B. Dorn, Towards a dichotomy of finding possible winners in elections based on scoring rules, J. Comput. Syst. Sci. 76 (8) (2010) 812–836.[7] N. Betzler, R. Niedermeier, G. Woeginger, Unweighted coalitional manipulation under the Borda rule is NP-hard, in: Proceedings of the 22nd Interna-tional Joint Conference on Artificial Intelligence, IJCAI-11, 2011, pp. 55–60.[8] F. Brandt, M. Brill, E. Hemaspaandra, L. Hemaspaandra, Bypassing combinatorial protections: polynomial-time algorithms for single-peaked electorates, in: Proceedings of the 24th AAAI Conference on Artificial Intelligence, AAAI-10, 2010, pp. 715–722.[9] S. Brunetti, A. Del Lungo, P. Gritzmann, S. de Vries, On the reconstruction of binary and permutation matrices under (binary) tomographic constraints, [10] J. Chamberlin, An investigation into the relative manipulability of four voting systems, Behav. Sci. 30 (1985) 195–203.[11] T. Coleman, V. Teague, On the complexity of manipulating elections, in: Proceedings of the 13th Conference “Computing: The Australasian Theory Theor. Comput. Sci. 406 (1–2) (2008) 63–71.Symposium”, CATS2007, 2007, pp. 25–33.gan, 1951.Computational Social Choice, COMSOC-10, 2010.Artificial Intelligence, AAAI-2012, 2012.Computation, ISAAC 2005, 2005, pp. 206–215.[12] V. Conitzer, T. Sandholm, J. Lang, When are elections with few candidates hard to manipulate?, J. ACM 54 (3) (2007) 1–33.[13] A.H. Copeland, A ‘reasonable’ social welfare function. Notes from a seminar on applications of mathematics to the social sciences, University of Michi-[14] J. Davies, G. Katsirelos, N. Narodytska, T. Walsh, An empirical study of Borda manipulation, in: Proceedings of the 3rd International Workshop on [15] J. Davies, N. Narodytska, T. Walsh, Eliminating the weakest link: making manipulation intractable?, in: Proceedings of the 26th AAAI Conference on [16] E. Elkind, H. Lipmaa, Hybrid voting protocols and hardness of manipulation, in: Proceedings of 16th International Symposium on Algorithms and [17] P. Faliszewski, E. Hemaspaandra, L. Hemaspaandra, How hard is bribery in elections?, J. Artif. Intell. Res. 35 (1) (2009) 485–532.[18] P. Faliszewski, E. Hemaspaandra, L. Hemaspaandra, J. Rothe, A Richer understanding of the complexity of election systems, in: Fundamental Problems in Computing: Essays in Honor of Professor Daniel J. Rosenkrantz, 2009, pp. 375–406.42J. Davies et al. / Artificial Intelligence 217 (2014) 20–42[19] P. Faliszewski, E. Hemaspaandra, H. Schnoor, Copeland voting: ties matter, in: Proceedings of the 7th International Joint Conference on Autonomous [20] P. Faliszewski, E. Hemaspaandra, H. Schnoor, Manipulation of Copeland elections, in: Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems, AAMAS-08, 2008, pp. 983–990.Agents and Multiagent Systems, AAMAS-10, 2010, pp. 367–374.[21] P. Faliszewski, A. Procaccia, AI’s war on manipulation: are we winning?, AI Mag. 31 (4) (2010) 53–64.[22] P. Favardin, D. Lepelley, Some further results on the manipulability of social choice rules, Soc. Choice Welf. 26 (2006) 485–509.[23] Gecode Team, Gecode: generic constraint development environment, 2006.[24] A. Gibbard, Manipulation of voting schemes: a general result, Econometrica 41 (4) (1973) 587–601.[25] P. Hall, On representatives of subsets, J. Lond. Math. Soc. (1935) 26–30.[26] K. Konczak, J. Lang, Voting procedures with incomplete preferences, in: Proceedings of the IJCAI-2005 Workshop on Advances in Preference Handling, [27] K.L. Krause, V.Y. Shen, H.D. Schwetman, Analysis of several task-scheduling algorithms for a model of multiprogramming computer systems, J. ACM 2005.22 (4) (1975) 522–550.[28] D. McGarvey, A theorem on the construction of voting paradoxes, Econometrica 21 (4) (1953) 608–610.[29] E. Nanson, Methods of election, Trans. Proc. R. Soc. Vic. 19 (1882) 197–240.[30] G. Nordh, A note on the hardness of Skolem-type sequences, Discrete Appl. Math. 158 (8) (2010) 63–71.[31] G. Nordh, Personal communication, 2011.[32] M. Pini, F. Rossi, B. Venable, T. Walsh, Incompleteness and incomparability in preference aggregation, in: Proceedings of 20th International Joint Conference on Artificial Intelligence, IJCAI-2007, 2007, pp. 1464–1469.[33] M. Pini, F. Rossi, B. Venable, T. Walsh, Incompleteness and incomparability in preference aggregation, Artif. Intell. 175 (7–8) (2011) 1272–1289.[34] M.A. Satterthwaite, Strategy-proofness and Arrow’s conditions: existence and correspondence theorems for voting procedures and social welfare func-tions, J. Econ. Theory 10 (2) (1975) 187–217.[35] T.N. Tideman, Independence of clones as a criterion for voting rules, Soc. Choice Welf. 4 (1987) 185–206.[36] T. Walsh, Uncertainty in preference elicitation and aggregation, in: Proceedings of the 22nd AAAI Conference on Artificial Intelligence, AAAI-2007, 2007, pp. 3–8.[37] T. Walsh, Where are the really hard manipulation problems? The phase transition in manipulating the veto rule, in: Proceedings of the 21st Interna-tional Joint Conference on Artificial Intelligence, IJCAI-2009, 2009, pp. 324–329.[38] T. Walsh, An empirical study of the manipulability of single transferable voting, in: Proceedings of the 19th European Conference on Artificial Intelli-gence, ECAI-2010, 2010, pp. 257–262.[39] T. Walsh, Where are the really hard manipulation problems?, J. Artif. Intell. Res. 42 (2011) 1–29.[40] L. Xia, M. Zuckerman, A. Procaccia, V. Conitzer, J. Rosenschein, Complexity of unweighted coalitional manipulation under some common voting rules, in: Proceedings of the 21st International Joint Conference on Artificial Intelligence, IJCAI-2009, 2009, pp. 348–353.[41] L. Xia, V. Conitzer, A. Procaccia, A scheduling approach to coalitional manipulation, in: Proceedings of the 11th ACM Conference on Electronic Com-[42] W. Yu, H. Hoogeveen, J.K. Lenstra, Minimizing makespan in a two-machine flow shop with delays and unit-time operations is NP-hard, J. Sched. 7 (5) merce, EC-2010, 2010, pp. 275–284.(2004) 333–348.[43] M. Zuckerman, A. Procaccia, J. Rosenschein, Algorithms for the coalitional manipulation problem, Artif. Intell. 173 (2) (2009) 392–412.