Artificial Intelligence 132 (2001) 1–38Artificial nonmonotonic neural networksB. Boutsinas a,c,∗, M.N. Vrahatis b,ca Department of Computer Engineering and Informatics, University of Patras, GR-26500 Patras, Greeceb Department of Mathematics, University of Patras, GR-26500 Patras, Greecec University of Patras Artificial Intelligence Research Center (UPAIRC),University of Patras, GR-26500 Patras, GreeceReceived 30 August 1999; received in revised form 8 January 2001AbstractIn this paper, we introduce Artificial Nonmonotonic Neural Networks (ANNNs), a kind ofhybrid learning systems that are capable of nonmonotonic reasoning. Nonmonotonic reasoning playsan important role in the development of artificial intelligent systems that try to mimic commonsense reasoning, as exhibited by humans. On the other hand, a hybrid learning system providesan explanation capability to trained Neural Networks through acquiring symbolic knowledge of adomain, refining it using a set of classified examples along with Connectionist learning techniquesand, finally, extracting comprehensible symbolic information. Artificial Nonmonotonic NeuralNetworks acquire knowledge represented by a multiple inheritance scheme with exceptions, suchas nonmonotonic inheritance networks, and then can extract the refined knowledge in the samescheme. The key idea is to use a special cell operation during training in order to preserve thesymbolic meaning of the initial inheritance scheme. Methods for knowledge initialization, knowledgerefinement and knowledge extraction are introduced. We, also, prove that these methods addressperfectly the constraints imposed by nonmonotonicity. Finally, performance of ANNNs is comparedto other well-known hybrid systems, through extensive empirical tests.  2001 Elsevier Science B.V.All rights reserved.Keywords: Nonmonotonic reasoning; Neural networks; Hybrid systems; Inheritance networks; Unconstrainedoptimization; DNA sequence analysis* Corresponding author.E-mail address: vutsinas@ceid.upatras.gr (B. Boutsinas).0004-3702/01/$ – see front matter  2001 Elsevier Science B.V. All rights reserved.PII: S 0 0 0 4 - 3 7 0 2 ( 0 1 ) 0 0 1 2 6 - 62B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–381. Introduction1.1. Motivation and backgroundNonmonotonic reasoning plays an important role in the development of systems that tryto mimic common sense reasoning, as exhibited by humans. Human beings are constantlyforced to make decisions and reach conclusions in an ambiguous world. The knowledgethat can be acquired by observation is inherently incomplete and may contain conflictinginformation as well as exceptions to general rules. Many formalisms are proposed in theliterature that are capable of representing knowledge under a multiple inheritance schemewith exceptions (e.g., [3,6,9,19,26,48,50,54]). A nonmonotonic reasoner has to face thetwo general problems of knowledge-based systems, namely the strong dependency on thecorrectness of the domain knowledge and the lack of domain independent and effectivelearning algorithms. Due to the latter, the domain knowledge must be altered manually,whenever necessary. Moreover, a nonmonotonic reasoner, usually, has problems in dealingwith multiple extensions of a theory. In such situations, extensions are treated as cases ofambiguity. The way they are treated depends on whether a credulous or a skeptical viewis adopted [55]. Besides, no attempt is made to resolve possible conflicts (except for a fewcases, as in [52]).On the other hand, example-based systems, such as Artificial Neural Networks (ANNs),need a large set of training examples and they have a strong dependency on the featuresused to describe those examples. They also lack an explanation capability for the generatedoutputs and, consequently, for the decisions reached. Moreover, a longstanding problemin connectionist modelling is the representation of structured objects. Although someattempts have been made to address this problem (e.g., [47]), the proposed systems are notefficient [27]. On the contrary, an explanation capability and representation of structuredobjects can be easily provided by a knowledge-based system.Recently, significant attention has been paid to the development of hybrid systems thatare based on a neural-symbolic integration, aiming at exploring the advantages of eachconstituent paradigm. There were promising early attempts [11] toward the combination ofthe explanation capabilities and the powerful declarative knowledge representation of thesymbolic approach with the massive parallelism and the generalization capabilities of theconnectionist approach. Neural-symbolic hybrid systems use an Artificial Neural Networkas an example-based learning system and a symbolic knowledge representation scheme forthe domain knowledge. The most important contributions to this interesting field can befound in [1,8,10,12,18,22,29,30,42,56].Following McCarthy’s observation [37], most of the hybrid systems using neural net-works for inferential processing, are based on logic-based propositional knowledge repre-sentation schemes. Such logic-based formalisms may lack several important properties ofnonmonotonic reasoning [6], such as the very important property of stability (also calledcumulativity). This is generally true even for well known nonmonotonic formalisms suchas Reiter’s Default Logic [6]. Special extensions of Default Logic have been introduced inorder to tackle the stability problem, such as Cumulative Default Logic [4,34]. Moreover,it has been shown that many decision problems are intractable or even undecidable whenstated within the context of formal logic-based systems.B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–383On the other hand, symbolic-connectionist systems in a nonmonotonic domain areimportance to both theory and practice. Path-based such formalisms areof greatrepresentation schemes based on semantic networks. They introduce an alternativeapproach to nonmonotonic reasoning. They try to tackle algorithmic intractability and thecorrect treatment of incomplete or contradictory knowledge. Although there exists a lot ofcriticism about the semantics of semantic networks [64], it is accepted that they can beeffectively used as a representation and inference scheme in a nonmonotonic domain [54].Inheritance networks is such a path-based formalism with widespread use in nonmonotonicreasoning systems [55].Hybrid systems are usually based on logic-based knowledge representation schemesas far as the domain knowledge is concerned. The proposed, in this paper, ArtificialNonmonotonic Neural Networks (ANNNs) are hybrid systems that use inheritancenetworks, as a nonmonotonic multiple inheritance knowledge representation scheme forthe domain knowledge, and Artificial Neural Networks as a learning mechanism. Thelatter are supported by a proper training method, which suits perfectly our approach andis applied by changing selected weights at each epoch. ANNNs are not based on energyminimization, but on the spreading activation metaphor. The input cells of the connectionistpart are externally activated, based on known facts in the domain knowledge, and thespreading of this activation forces some output cells to be either activated or deactivated. Itis the activation of output cells that guides the reasoning process.1.2. Related workIn [23] a logic-based method is presented for inserting any propositional general logicprogram P into a three-layer feedforward Artificial Neural Network with binary thresholdneurons. It is proved that if the network is transformed into a recurrent network, byconnecting output units to corresponding input units, it always falls into a unique stablestate that corresponds to the unique stable model, namely the semantics, of P . Thepotential impact of this result is that a new massively parallel computational model forlogic programming is derived.The system presented in [56] (Knowledge-Based Artificial Neural Network) is capableof inserting “if-then” rules into a neural network, refining these rules using a backpropaga-tion based learning algorithm and extracting rules from the neural network. It is empiricallyshown that the system can not only revise the domain knowledge but also can efficientlylearn new rules from examples using the domain knowledge.Following the key idea in [23], the system in [12] (Connectionist Inductive Learningand Logic Programming System) integrates inductive learning from examples anddomain knowledge with deductive learning from Logic Programming. Propositional logicprograms can be inserted into a feedforward Artificial Neural Network with bipolar semi-linear threshold neurons. The network is trained using the standard backpropagationlearning algorithm and the revised logic program can be extracted.Moreover, it is shown [40–42] that the satisfiability problem in propositional logic canbe reduced to the problem of finding a global minima of an energy function of a symmetricnetwork. The consequence of this very important result is that symmetric neural networks4B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38can be applied in solving a lot of hard problems, such as optimization problems andconstraint satisfaction problems [16].There are also efforts in the direction of hybrid systems that use knowledge represen-tation schemes based on first-order logic. Unfortunately, such systems are still proposi-tional [24,25]. In [21], an automated reasoning system for first-order Horn clauses is pre-sented (Connectionist Horn Clause Logic), which is implemented in a feedforward neuralnetwork. In [24] an extension of the method in [23] is presented for inserting first-orderlogic programs into three-layer recurrent Artificial Neural Networks that correspond to anapproximation of the semantics of programs. Finally, in [43] an analogous result to [42] isshown, according to which a first-order resolution proof (although of a fixed predeterminedlength) can be also reduced to a global minimum of the energy function of a symmetricnetwork.The first result toward a hybrid symbolic-connectionist system in a nonmonotonicdomain is due to Pinkas. In [44], it is shown that the minimization problem of an energyfunction of a symmetric network can also be applied to propositional nonmonotonicreasoning (in fact, exceeding it [45]). As shown in [46], initial domain knowledge canbe represented by a logic-based scheme, the Penalty Logic. To every propositional formularepresenting domain knowledge (the assumption), a positive real number is assigned (thepenalty), in order to form a penalty logic well formed formula. This penalty has to be paidby any assignment that does not satisfy the assumption. An assignment is preferred overany other that pays a higher penalty. Assignments that pay the minimum penalty (preferredmodels) are preferred over any other. Pinkas showed that the minimization problem of anenergy function of a symmetric network can be reduced to the problem of finding preferredmodels for a given set of assumptions representing initial domain knowledge.In the rest of the paper, we first describe ANNNs. Then, we present a knowledgeinitialization, a knowledge refinement and a knowledge extraction method for ANNNs.Consequently, we test the performance of ANNNs against other well-known hybridsystems and, finally, we discuss some critical issues.2. Artificial Nonmonotonic Neural NetworksArtificial Nonmonotonic Neural Networks are neural-symbolic hybrid systems. Theypossess a domain knowledge that is used for the initialization of an Artificial NeuralNetwork. The latter is used as an example-based learning mechanism for the refinement ofthe initial knowledge through processing a set of classified examples. After the refinement,the acquired knowledge is extracted substituting the initial domain knowledge. At thisstate, a new cycle of knowledge initialization-refinement-extraction can start, whenever anew set of examples need to be considered (see Fig. 1).Domain knowledge is represented by a nonmonotonic multiple inheritance schemeallowing exceptions. More specifically, we use Nonmonotonic Inheritance Networks(NINs) that are based on semantic networks. There is a clash of intuitions [55] innonmonotonic inheritance networks concerning the treatment of nonmonotonicity (on-pathversus off-path preemption), the treatment of competing extensions (forms of skepticismversus forms of credulity) and the direction in which the represented inheritance is followedB. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–385Fig. 1. The cycle of knowledge initialization, refinement and extraction.(upward versus downward view of reasoning). Their performance is closely related tothese intuitions [51]. The reasoning process was proved to be NP-hard for on-path/off-path credulous downward reasoners as well as for on-path upward credulous reasoners.However, it is proved to have polynomial time complexity for skeptical reasoners.In NINs, knowledge is represented by attaching, to each node of a directed acyclic graph,a label that denotes an object, a class of objects or a property possessed by objects of thedomain of discourse and by establishing the desired relationships through the insertionof the proper directed edges. When we insert an edge that emanates from a node andis incident to another, we mean that the class of objects represented by the former nodeinherits some or all of the defining properties of the class represented by the latter. If aninheritance exception exists, this is indicated by an exception link. For example, the NINshown in the left part of Fig. 2 represents the facts that all Es are Ds (or are kinds of Ds,or are like Ds [3]), all Ds are Cs and so on. Moreover, a reasoning system can concludethat all Es are Cs because they are Ds. Finally, the exception link (indicated by a dottedline) represents that Ds are not Bs, although they are Cs.There are two main operations associated with NINs. The first operation consists inanswering whether an object possesses a particular property. The second consists in findingall the objects satisfying a particular set of properties. Developing efficient algorithmsfor these two operations is of great importance to many AI applications. Both of theseoperations can be reduced to computing the transitive relationships between the objects inthe nonmonotonic inheritance network.The objective of the knowledge initialization phase is to construct an Artificial NeuralNetwork that provides the same answers as the nonmonotonic inheritance network, as far asthe above operations are concerned. The knowledge initialization methodology we employis presented in the next section. After the knowledge initialization phase, the constructedArtificial Neural Network is trained using a set of classified examples, in order to refinethe initial knowledge. The refinement is achieved through changing the initial weights. The6B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38way we construct the Artificial Neural Network during the initialization phase imposessome constraints on the training method we can use. We propose a new training method,which suits perfectly our approach, satisfying the requirements. The method is presented inSection 4. Finally, the refined knowledge is extracted from the Artificial Neural Networkand it is represented by a nonmonotonic inheritance network, which replaces the initialone. The proposed knowledge extraction method is presented in Section 5.3. The knowledge initialization methodThe representation in the nonmonotonic inheritance network that corresponds to thedomain knowledge can be based on either directed acyclic graphs or on set descriptions.The knowledge initialization phase is formally defined as follows:Given: A directed acyclic graph G = (V , E = R ∪ POS ∪ NEG) where V is the setof nodes that represent objects of the domain of discourse and E is the set ofedges that represent relations between those objects. Set R consists of the edgesthat represent ordinary relations, set POS consists of the edges that representexceptional positive relations and set NEG consists of the edges that representexceptional negative relations. Finally, it is assumed that R ∩ POS ∩ NEG = ∅.or:(i) a set of relations R = {r | r = (cid:8)q, s(cid:9)}, with some type of semantics (e.g., ofthe “isa”, “ako” or “isl” [3] type), and(ii) a set of exceptions X = {(cid:8)q, {n1, . . . , nk}, {p1, . . . , pl}(cid:9)}, where q, n1, . . . , nk,p1, . . . , pl represent objects of the domain of discourse and any ni is inexceptional negative relation with q and any pi is in exceptional positiverelation with q.initialize an Artificial Neural Network, with:• a set of k ∈ N cells U = {u1, . . . , uk}, each one of which receives a networkbinary input and gives a network binary output. Moreover, each cell ui performsan operation S (to be described later) on its inputs;• a set of integer weights W = {wi,j | i, j (cid:1) k};• a proper activation function σ applied to the network outputs:(cid:1)σ (x) =1,−1,if x > 0;if x (cid:1) 0.(1)Cell input and activation are assumed to be discrete (see Section 4 for a justification).In the following, we use interchangeably the notion of a link in the inheritance networkand the notion of a weighted connection in the neural network. We first present theknowledge initialization method with respect to the main characteristics of common sensereasoning, namely nonmonotonicity, redundancy and ambiguity.B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–387Fig. 2. An ANN initialized using a NIN.3.1. Inserting symbolic knowledge with exceptionsExceptions in the inheritance of properties, from more general classes to more specificones, introduce nonmonotonicity in reasoning about the represented knowledge. Theexistence of more specific knowledge about an object of discourse may change previouslyvalid conclusions.Consider, for example, the nonmonotonic inheritance network shown in the left part ofFig. 2. An interpretation of the symbols could be the following: A stands for HOVER,B stands for FLY, C stands for BIRD, D stands for PENGUIN and E stands for MALEPENGUIN. The fact that an object of discourse is a bird leads to the conclusion that it flies.But the more specific fact that it is a penguin forces the conclusion that it does not fly.The initial nonmonotonic inheritance network can be transformed to an Artificial NeuralNetwork, as shown in the right part of Fig. 2. The equivalence between the ANN andthe initial NIN, as far as its intended meaning is concerned, requires simulation of theinheritance cancelling (exceptions) represented by the negative links. This can be achievedby attaching a negative weight to the connection of the Artificial Neural Network thatcorresponds to the negative link of the symbolic domain knowledge, as shown in the rightpart of Fig. 2. In this way, the activation of cell u4 or u5 (corresponding to the fact thatan object of discourse is a penguin or a male penguin) will prevent cells u2 and u1 fromgetting activated (corresponding to the conclusion that an object of discourse flies andhovers). The above are considered under a standard activation function and cell operation.3.2. Inserting symbolic knowledge with redundanciesSince our aim is to simulate common sense reasoning as closely as possible, it isimportant for a nonmonotonic reasoner to handle redundant information in a consistentmanner. Of course, as long as the reasoner’s knowledge about the world remains unchanged8B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38Fig. 3. A NIN supplemented with a redundant atomic statement.in time, this kind of information could be recognized and, subsequently, removed duringa preprocessing phase of the reasoner’s life cycle. However, if the reasoner’s knowledgeis continuously subjected to revisions, as it is often the case, it is always possible thatredundant, or even contradictory, information is introduced as a side effect of a revisionprocess. Redundant information is closely related to the stability (cumulativity) of thereasoner.Suppose thatthe reasoner, whose knowledge is represented by a nonmonotonicinheritance network, supports the conclusion isa(X, Y ). We say that the reasoner is stableif, after inserting into its knowledge base the (redundant) information that isa(X, Y ), itcontinues to support all the conclusions it supported before the insertion of this piece ofinformation.Consider, for example, the nonmonotonic inheritance network shown in the left partof Fig. 3, with the same interpretation of symbols as that of the previous example.Clearly, the redundant fact that a male penguin is a bird should not change any previousconclusion made without taking this redundant fact into consideration. This is satisfied bythe activation of the cells in the right part of Fig. 3.This kind of stability, is called atomic stability. It is obvious that an Artificial NeuralNetwork initialized with the proposed methodology supports atomic stability. Atomicstability is viewed [26] as an acceptability criterion for an inheritance reasoner.However, the other kind of stability, called generic stability, is not viewed as sucha criterion. In our opinion, both atomic and generic stability should be viewed asacceptability criteria for an inheritance reasoner [2,3].Consider, for example, the nonmonotonic inheritance network shown in the left part ofFig. 4, with the same interpretation of symbols as that of the previous example. Clearly,the redundant fact that a bird hovers should not change any previous conclusion that wasmade without taking this redundant fact into consideration. This is however not satisfiedby the activation of the cells in the right part of Fig. 4. Without the connection from cell u3B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–389Fig. 4. A NIN supplemented with a redundant generic statement.to cell u1, activation of cell u4 or u5 prevents activation of cells u2 and u1. However, this isno longer true in the presence of that connection. Therefore, an Artificial Neural Networkinitialized with the methodology proposed so far does not support generic stability.In order to overcome this serious problem, a more negative weight, say −2, could beattached to all the connections that correspond to the negative links. But, this techniquedoes not always offer a solution, since this negative weight could be absorbed in theactivation function of a standard type, if it is a function of the weighted sum of the inputsto a cell.To address this problem, we define a cell operation S as the computation of the maximumabsolute value of the inputs of the cell. Thus,∀ui, Si (in1, . . . , inm) := in1 (cid:16) in2 (cid:16) · · · (cid:16) inm,where (cid:16) is a binary operator defined as:x (cid:16) y =− ||x|−|y||+|x|+|y|2+ ||x|−|y||+|x|+|y|2+1,,,|x−ε+y| < 0;|x−ε+y| > 0 ∧ x, y > 0;if x−ε+yif x−ε+yotherwise.(2)(3)in1, . . . , inm are the inputs of cell ui and ∀uj that is connected to ui , inj is derived by thefunction(cid:1)inj =0,wj,i (cid:16) Sj ,if σ (Sj ) = −1;if σ (Sj ) = 1.(4)Intuitively, the cell operation S guarantees that the output of a cell is identical to its inputwith the maximum absolute value. In the case that there are more than one input of equalabsolute value, the output is identical to the negative one. This is achieved by subtractinga very small positive number ε from some of the inputs determining the resolution ofdistinguishing x and y.10B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38Therefore, (see Fig. 4) if w4,2 = −2 the output of cell u2 is −2, if u4 is activated.Eventually, the output of the cell u2 becomes the output of cell u1. Considering onlythe positive outputs as activating a cell, the Artificial Neural Network in Fig. 4 behavescorrectly satisfying the very important property of stability.3.3. Satisfying “inferential distance ordering”It is often the case that a negative link should be preempted by a more specific positiveone (or vice versa). Therefore, there is also an ordering of the exception links, eithernegative or positive, according to how specific is the class they refer to. The more specificthe referring class the higher the priority of the exception link. This ordering is referredto, in the literature, as the “inferential distance ordering” [54] and it is viewed as anacceptability criterion for nonmonotonic reasoning. It ensures that if there are any conflictsamong the exception links, they are resolved in favor of the exceptions that have a higherpriority, according to “inferential distance ordering”; that is, in favor of the exceptionsconcerning more specific classes.In order to properly initialize the Artificial Neural Network we have to preserve the“inferential distance ordering”. But, if all negative links were represented by the samenegative weight and all positive links by the same positive weight, we could not resolvethe conflict in favor of the more specific one. We overcome this problem by assigning toa negative or a positive weight a negative or a positive link respectively, with a magnituderelative to a topological ordering of the cells.According to a topological ordering, there is a function f : U → N that assigns an integerto each cell such that, if cell ui is an ancestor of cell uj (in the sense that there exists aconnection path from ui to uj ), then f (ui ) > f (uj ). We assign a weight to each exceptionlink, starting from the links having tail nodes with the lowest topological order. If there arelinks having tail nodes with the same topological ordering, we start from a negative link(s).To each negative link, a negative weight, equal to the topological order of its tail node, isassigned. To each positive link, a positive weight, equal to the topological order of the tailnode of the last examined negative link in the same path, is assigned. Exceptionally, to eachpositive link, in the case that its head node has a topological order lower than or equal tothe head node of the last examined negative link (or of all the last examined negative linkswith the same tail node), a positive weight equal to the topological order of its tail node isassigned.The above methodology, which is applied to the example of Fig. 5, is formally presentedby the Initialization Algorithm in Section 3.5. Intuitively, this methodology guarantees that,along a path, every combination of positive and negative exception links satisfies stabilityand inferential distance ordering (see Section 5.4 for a proof).3.4. Inserting symbolic knowledge with conflictsNonmonotonic multiple inheritance frequently introduces multiple extensions of atheory. We quote from [9]:“. . . an extension is a set of beliefs which are in some sense justified or reasonablein light of what is known about a world”.B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3811Fig. 5. Assigning negative or positive weights according to a topological ordering.These multiple extensions are due to conflicts in the represented knowledge. Usually, allcases of multiple inheritance are treated as cases of ambiguity, e.g., in [54], and there is noeffort to resolve the conflicts (an exception is [52]). The way in which multiple extensionsare treated depends on whether a credulous or a skeptical view is adopted [26].The proposed methodology, by definition, can not recognize multiple extensions andsupports a preference over the conclusions represented by paths containing connectionswith weights of maximum absolute value. Consider, for example, the nonmonotonicinheritance network shown in the left part of Fig. 6. An interpretation of the symbolscould be the following: A stands for PACIFIST, B stands for QUAKER, C stands forREPUBLICAN and D stands for NIXON. The activation of the cells in the right networkof Fig. 6, supports the conclusion that, definitely, Ds are not As, since they are Cs, althoughthe opposite conclusion is also supported, since As are Bs. This conclusion is due to theactivation of cell u3, that prevents u1 from activation. Generally, any path that contains aconnection with a maximum absolute value, due to the transfer of this value, is prevalentover any other. Therefore, if the weight is negative(positive) then a negative(positive)conclusion is derived.One of the main advantages of the Artificial Nonmonotonic Neural Networks is that,during the knowledge refinement phase, explained in a later section, the conflicts can beresolved in favor of the most probable ones, with respect to the training set.12B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38Fig. 6. Conflicted extensions.3.4.1. Inserting symbolic coupled knowledgeIn nonmonotonic reasoning, usually, objects are coupled with their immediate succes-sors. This means that an object is not allowed to possess a property that is not possessedby any of its immediate successors, since this object possesses a property strictly becauseit belongs to a particular class. Of course, in some kind of nonmonotonic reasoning, theskeptical reasoning for instance, an object can not be coupled with its immediate succes-sors.In the proposed methodology, neither coupling nor decoupling can be assured. Thisis because the conclusion is relied on the maximum absolute value of the connections.Consider, for example, the nonmonotonic inheritance network shown in the left part ofFig. 7. Clearly, neither Ds nor Es are As, due to the negative weights w3,2 and w5,3.A skeptical reasoner, on the contrary, supports the conclusions that Es are As and that Dsare not As, thus allowing the decoupling of Es from Ds.Of course, during the knowledge refinement phase, coupling or decoupling is preferredin favor of the most probable, with respect to the training set.3.5. The initialization algorithmAccording to the methodology presented in the above sections, the initializationalgorithm is as follows:Given: a direct acyclic graph: G(V , E = R ∪ POS ∪ NEG),or:a set of relations: R = {r | r = (cid:8)q, s(cid:9)}along with a set of exceptions: X = {(cid:8)q, {n1, . . . , nk}, {p1, . . . , pk}(cid:9)},initialize an Artificial Neural Network with:• a set of cells U = {u1, . . . , uk},• a set of weights W = {wi,j | i, j (cid:1) k},B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3813Fig. 7. Another example of conflicted extensions.executing the following algorithm:The initialization algorithm1. for each vi ∈ V (or for each distinct q that is referred to in R), define a cell ui ∈ U ,2. for each e = (i, j ) ∈ E (or for each r = (i, j ) ∈ R) define a connection from ui touj with wi,j = 1,3. for each n = (i, j ) ∈ NEG (or for each (cid:8)i, (j, . . .), (. . .)(cid:9) ∈ X), in ascendingtopological order of i, define a connection from ui to uj with wi,j = −(d × i)(where d is a positive integer that is used in order not to allow contiguousweights),4. for each p = (i, j ) ∈ POS (or for each (cid:8)i, (. . .), (j, . . .)(cid:9) ∈ X), in ascendingtopological order of i, define a connection from ui to uj with wi,j = +(d × i)(where d is as above), if for the most closed, in the same path, edge n = (x, y) ∈NEG of p, f (j ) (cid:2) f (y). Otherwise, define a connection from ui to uj withwi,j = +(d × x).4. A knowledge refinement methodKnowledge refinement is based on the training of the corresponding Artificial NeuralNetwork. At the same time, knowledge refinement aims to an effective knowledge extrac-tion. To this end, we need a training method that preserves the symbolic meaning of theinitialized Artificial Neural Network. In our case, this is accomplished both by restrictingthe weights to be set to selected ones and by using a fixed architecture. Notice that mosttraining algorithms are specialized to train a particular type of network architecture.14B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38In our case, the network is considered as a network of neurons with discrete states. Thus,consider a Discrete Multilayer Neural Network (DMNN) consisting of L layers, in whichthe first layer denotes the input, the last one (L) is the output and the intermediate layersare the hidden layers. It is assumed that the (l − 1)th layer has Nl−1 units. These unitsoperate according to the following equations:net lj=Nl−1(cid:6)i=1wl−1,lijyl−1i+ θ lj ,ylj= σ l(cid:7)(cid:8),net lj(5)j is the net input to the j th unit at the lth layer, wl−1,lwhere net lis the connection weightfrom the ith unit at the (l − 1)th layer to the j th unit at the lth layer, yli denotes the outputof the ith unit belonging to the lth layer, θ lj denotes the threshold of the j th unit at thelth layer, and σ is the activation function. We consider units where σ (netli) is a discreteactivation function. We especially focus on units with two output states, usually calledbinary or hard-limiting units [38], i.e.:(cid:9)ij(cid:8)(cid:7)net ljσ l=“true”,“false”,(cid:2) 0;if net ljif net lj < 0.(6)Although units with discrete activation function have been superseded to a large extent bythe computationally more powerful units with analog activation function, DMNNs are stillimportant in that they can handle many of the inherently binary tasks that neural networksare used for. Their internal representation is clearly interpretable, they are computationallysimpler to understand than networks with sigmoid units and provide a starting point forthe study of the neural network properties. Furthermore, when using hard-limiting unitswe can understand better the relationship between the size of the network and the trainingcomplexity [17]. In [13], it has been demonstrated that DMNNs with only one hidden layercan create any decision region that can be expressed as a finite union of polyhedral setswhen there is one unit in the input layer. Moreover, artificially created examples were given,where these networks create non convex and disjoint decision regions. Finally, discreteactivation functions facilitate neural network implementations in digital hardware and aremuch less costly to fabricate.The most common feed forward neural network (FNN) training algorithm, back-propagation (BP) [49], which makes use of the gradient descent, cannot be directly appliedto networks of units with discrete output states, since discrete activation functions (suchas hardlimiters) are non-differentiable. This also holds for various modifications of theBP method (see, e.g., [31,32]). However, various modifications of the gradient descentapproach have been presented in the literature [14,53,63]. In [15] an approximation togradient descent, the so-called pseudo-gradient training method, is proposed. This methoduses the gradient of a sigmoid as a heuristic hint instead of the true gradient. Experimentalresults validated the effectiveness of this approach.We derive and apply a new training method for DMNNs that makes use of thegradient approximation introduced in [15]. Our method exploits the imprecise informationregarding the error function and the approximated gradient, like the pseudo-gradientmethod does, but it has an improved convergence speed and has the potential to trainB. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3815DMNNs in situations where, according to our experiments, the pseudo-gradient methodfails to converge. For some comparative results of this method with BP see [33].4.1. Problem formulation and proposed solutionWe consider units with two discrete output states and use the convention f (or −f ) for“false” and t (or +t) for “true”, instead of the classical 0 and 1 (or −1, and +1). f , t arereal positive numbers and f < t. Real positive values prevent units from saturating, giveto the logic “false” some power of influence over the next layer of the DMNN and help thejustification of the approximated gradient value, which we employ.First, let us define the error for a discrete unit as follows:ej (t) = dj (t) − yLj (t),for j = 1, 2, . . . , NL,(7)where dj (t) is the desired response at the j th neuron of the output layer at the inputpattern t, yLj (t) is the output at the kth neuron of the output layer L. Notice that N refers tothe number of output cells that are semantically related to the input cells. More specifically,these output cells are only those that eventually can be activated by the input cells. Thus,we consider a subgraph of the initial inheritance network. For a fixed, finite set of input–output cases, the square error over the training set, which contains T representative cases,is:E =T(cid:6)t =1E(t) =T(cid:6)NL(cid:6)t =1j =1e2j (t).(8)The idea of the pseudo-gradient was first introduced in training discrete recurrent neuralnetworks [65,66] and was extended to DMNNs [15]. The method approximates the truegradient ∇E(w) of the error function E(w) with respect to the weights w, by introducingan analog set of values for the outputs of the hidden layer units and the output layer units.j in Eq. (5) can be written as:Thus, it is assumed that yl(cid:7)(cid:7)S(cid:8)(cid:8),ylj= (cid:10)σ lnet ljwhere, if S(·) is defined in [0, 1] then:“true”,“false”,otherwise if S(·) is defined in [−1, 1] thenif x (cid:2) 0.5;if x < 0.5,(cid:10)σ (x) =(cid:1)(cid:1)(cid:10)σ (x) =“true”,“false”,if x (cid:2) 0;if x < 0.Using the chain rule, the pseudo-gradient is computed by:(cid:11)∂E∂wl−1,lij= (cid:10)j yl−1δli,where the back-propagating error signal (cid:10)δ for the output layer is:(cid:7)netLj(cid:7)dj − SnetLj· s(cid:25)(cid:8),(cid:8)(cid:8)=(cid:10)δLj(cid:7)(9)(10)(11)(12)(13)16B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38and for the hidden layers (l ∈ [2, L − 1]) is:(cid:8)(cid:6)(cid:10)δlj= s(cid:25)(cid:7)net ljwl,l+1j n(cid:12)δl+1nn.(14)In these expressions s(cid:25)(net lj ) is the derivative of the analog activation function.By using real positive values for “true” and “false” we ensure that the pseudo-gradientwill not reduce to zero when the output is “false”. Notice also that we do not use σ (cid:25), whichis zero everywhere and nonexistent at zero. Instead, we use s(cid:25), which is always positive, so(cid:10)δlj gives an indication of the direction and magnitude of a step up or down as a function ofnet lj in the error surface E.However, as pointed out in [15], the value of the pseudo-gradient is not accurate enough,so gradient descent based training in DMNNs is considerably slow when compared to BPtraining in FNNs.In order to alleviate this problem, we propose an alternative to the pseudo-gradienttraining method procedure. The proposed training method is applied by changing selectedweights at each epoch, which is very useful in our approach. It is based on recentlyproposed unconstrained optimization methods [59–61].Next, we present the proposed training method. For simplicity, we index the se-lected weights in sequence: wi , i = 1, 2, . . . , n. Thus, in order to find a point w∗ =(w∗n), which minimizes the given error function:1, w∗2 , . . . , w∗E : D ⊂ Rn → R,(15)1, w02, . . . , w02, . . . , w0in a specific bounded domain D, we try to obtain a sequence of points {wk}, k = 0, 1, . . . ,which converges to w∗. So, using an arbitrary chosen starting vector of weights w0 =n) ∈ D, we subminimize E along the w1 direction. Now, if (cid:13)w1 is such a(w0subminimizer, then, of course, point ((cid:13)w1, w0n) possesses a smaller function value= (cid:13)w1. We repeat the above process to find a subminimizerthan point w0. Then, we set w11(cid:13)w2 along w2 direction with as starting vector of weights (w12, . . . , w0n). Thus, wecompute the point w13 with as starting vectorof weights (w1n) is formed. Now,after replacing the starting point w0 by w1, we can repeat the above process to computew2 and so on until the final estimated point w∗ is computed according to a predeterminedaccuracy. Notice that we use only one-dimensional subminimization techniques tominimize the error function. For more details on such techniques see [7,36,39,57,58].1, w02 and in the same way we compute the point w1n) and so on until point w1 = (w12, . . . , w02, . . . , w11, w11, w1With the above discussion in mind we provide below a high level description of ouralgorithm, where E indicates the error function, w0 = (w0n) the starting weights,h = (h1, . . . , hn) the starting stepsizes in each coordinate direction, MEP the maximumnumber of epochs required and δ, ε the predetermined desired accuracy.1, . . . , w0The training algorithm1. Input {E; w0; h; MEP; δ; ε}.2. Set k = −1.3. Set i = 0.B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38174. If k < MEP, replace k by k + 1 and go to the next step;otherwise, go to Step 12.5. Replace i by i + 1 and continue.6. Compute a subminimizer (cid:13)wi , within an accuracy δ, along the ith direction by applyingany one-dimensional subminimization iterative scheme.7. If (cid:13)wi is a subminimizer of E along the ith direction set wk+1= (cid:13)wi ;i= wki .otherwise set wk+18. If i < n, go to Step 5.9. If E(wk+1) (cid:1) E(wk), go to Step 3;otherwise set y0 = wk and continue.i10. Apply one step of a pseudo-gradient training method utilizing the starting value y0and take its output value ySUB.11. If E(wk+1) > E(ySUB), then set wk+1 = ySUB and return to Step 3.12. Output {wk; E(wk)}.Our experience is that in many cases, as well as for all the problems studied in [33,60,61], the application of the subprocedure at Step 10 is not necessary. We have placedit in our algorithm for the sake of completeness. For a proof of the convergence of thisalgorithm and related ones, see [59–61].5. The knowledge extraction methodOne of the main advantages of a hybrid system comes from the fact that the symbolic partis used to access the refined knowledge. Therefore, the knowledge extraction phase, wherethe refinement knowledge provided by the trained Artificial Neural Network is extractedin a comprehensible symbolic scheme, is of great importance to the reliability of a hybridsystem.The proposed knowledge extraction method of Artificial Nonmonotonic Neural Net-works heavily relies on reversing the initialization phase. The cells of the Artificial NeuralNetwork are, simply, transformed into nodes of the Nonmonotonic Inheritance Network.But the refinement of the initialized knowledge is actually represented by the changes inthe weights of the connections of the Artificial Neural Network. These changes actually re-alize the refinement of the initialized knowledge, resolving conflicts. The initial knowledgeof the inheritance network is changed due to insertions and deletions of exception links.As it is well known, there is not a unique trained set of weights w∗ that verifies thecorresponding error function. To ensure that the changes in the weights do not concernconnections that do not contribute in the knowledge refinement, we apply the trainingalgorithm to selected weights, as described in Section 5.3.5.1. Resolving conflictsIn resolving conflicts, a technique based on the identification of the extension that issupported by the set of classified examples used during the refinement phase is employed.Extensions are actually represented by paths of the inheritance network, and, hence,18B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38of the connectionist network. The identification of the prevalent extensions, after therefinement phase, is achieved by the identification of changes in the weights attached tothe connections.In the initialized connectionist network prevalent extensions are those represented bya path containing connections with weights of maximum absolute value. Since negativeweights support negations, a decrease of a weight gives a further precedence to a prevalentextension supporting negations. On the other hand, an increase in a weight, contributestoward the cancelling of a negative weight and therefore gives precedence to a prevalentextension supporting a positive result. An increase or a decrease in a weight, wi,j , is definedwith regard to its value before the refinement phase, w0i,j . When a prevalent extension isidentified by a change in a weight, the extracted inheritance network is modified in orderto support this extension. This is achieved by adding to the inheritance network a properexception link, positive or negative, depending on the result supported by the identifiedextension. The added exception link concerns the extension as a whole and, clearly, it doesnot concern the exception link whose corresponding connection has changed. Therefore,the added exception link is attached to the path that represents the extension.Consider, for example, the trained Artificial Neural Network of Fig. 8. Suppose thatthere is a decrease in the weight w3,2 = −6, (w0= −3), which identifies the extension3,2F → D → C → A as prevalent. Then, a negative exception link (F, A) is added thatsupports this prevalent extension. Notice that the added link does not affect the existednegative exception link (C, A), which has to remain. The added link, of course, has apriority over the existing one, according to the “inferential distance measure”.In order to add exception links properly, we need to identify the path that representsa certain extension. Since a prevalent extension is identified by a change in a weight ofa connection that represents an existing exception link, we assume that an extension isFig. 8. Adding exception links.B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3819represented by a path containing the tail and the head nodes of this exception link. Such apath is the F → D → C → A in Fig. 8, containing the tail node F and the head node A ofthe existing exception link (C, A).In general, if there exists a path from a node representing an input cell underconsideration to a node representing an output node under consideration and this pathcontains the changed weight, we add an exception link between these two nodes. Theexception link is positive (negative) if there is an increase (decrease) to a negative (positive)weight or a decrease (increase) to a positive (negative) weight.5.2. Preemption of exception linksIt may also be the case that an existing exception link should be preempted, because it isnot supported by the set of training examples. Such exception edges can be also identifiedby changes in weights of the corresponding connections.Consider, for example, the trained Artificial Neural Network of Fig. 9 that was initializedas shown in Fig. 5. Suppose that weight w6,4 is decreased. Therefore a positive exceptionlink (F, D) is added. Notice that the added link introduces a conflict. This conflict isresolved in the implementation level, where the existing exception link (F, D) is deleted(see the extraction algorithm in the next subsection).Fig. 9. Preempted exception links.20B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–385.3. The extraction algorithmTo attack all the above cases, during the refinement phase, the training method is appliedon selected weights. Mainly, these weights are the ones that correspond to exceptionlinks. Therefore, any change to a weight guarantees the prevalence or the validation ofan exception link. Meanwhile, when resolving conflicts, if there are extensions representedby paths without exceptions, then identification of the prevalent extension is not possible,because only the weights that correspond to exception links are considered. Actually, insuch a case the initialized connectionist network can not be trained.We handle this problem by allowing the addition of weights to the set of selected weightsthat correspond to ordinary links. These are the weights of the connections that are adjacentto those output cells that represent nodes without incoming exception links.Consider, for example, the trained Artificial Neural Network of Fig. 11. The trainingalgorithm allows the addition of the weight w563,561 to the set of selected ones, apart fromw560,559 and w561,560.The extraction algorithm, at first, transforms cells and connections to nodes and edges.Then, the algorithm adds proper negative or positive exception links, if a prevalentextension is identified. The extraction algorithm is presented below:Given:the trained connectionist network with:a set of cells U = {u1, . . . , uk}, a set of weights W = {wi,j | i, j (cid:1) k} along withthe initial set of weights W 0 = {w0i,j| i, j (cid:1) k} before the refinement phase,Revise the Inheritance Network with:• a set of nodes V ;• a set of edges that represent ordinary relations R;• a set of edges that represent exceptional positive relations POS;• a set of edges that represent exceptional negative relations NEG.Executing the following algorithm:The extraction algorithm1. for each cell ui ∈ U :construct a node vi ∈ V2. for each connection from ui to uj :if wi,j = 1 thenconstruct an edge e = (i, j ) ∈ Rif wi,j < 0 thenconstruct an edge e = (i, j ) ∈ NEGif wi,j > 0 thenconstruct an edge e = (i, j ) ∈ POS3. for each connection from ui to ujwhere |w0| (cid:28)= |wi,j |:i,jif a path h, t containing (i, j ) exists,where h is the node representing input under considerationand t is the node representing output under considerationB. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3821thenif w0i,j < wi,j thenadd (if it does not already exist)the exception link e = (h, t) ∈ POS.delete any existing exception link e = (h, t) ∈ NEG.elseif w0i,j > wi,j thenadd (if it does not already exist)the exception link e = (h, t) ∈ NEG.delete any existing exception link e = (h, t) ∈ POS.5.4. Soundness and completenessThe proposed methodology is sound and complete, as it is proved in the following. Ingeneral, we consider that:a system is sound if every output is valid,a system is complete if every valid output can be produced.The proof of soundness and completeness of ANNNs is actually reduced to the proof ofsoundness and completeness of initialization, revision and extraction phase separately.The completeness of the initialization phase is obvious and comes straightforward fromthe initialization algorithm in Section 3.5. Every inheritance network can be transformedto a neural network of the type described throughout Section 3. This is so, because there isa one to one correspondence between the sets of nodes V and edges E of the inheritancenetwork and the sets of cells U and connections W of the neural network respectively.Obviously, there is always a topological ordering of nodes in the inheritance network,therefore it is always possible to assign weights to the connections of the neural network.The soundness of the initialization phase guarantees the equivalence between theneural network and the intended meaning of the background knowledge. We considerthat equivalence is guaranteed if the neural network satisfies inheritance, stability andinferential distance ordering (described in detail in Section 3). We prove the soundnessof the initialization phase by cases. Lemmas 1 and 2 guarantee the satisfaction ofthe inheritance property. Satisfaction of the inferential distance metric and the stabilityproperty is guaranteed by Theorems 3 and 6. Notice that the conflict resolution property isguaranteed after the refinement phase, therefore all the following proofs refer to an intra-extension (intra-path) domain.Lemma 1. In a neural network constructed from an inheritance network without anyexceptions or only positive ones, using the algorithm in Section 3.5, a cell o ∈ U isactivated iff at least one cell j k ∈ U connected to o via a path of connections p = {wj 0,j 1,wj 1,j 2, . . . , wj n,o}, where j 0, . . . , j n ∈ U and wj 0,j 1, wj 1,j 2, . . . , wj n,o ∈ W , is alsoactivated.Proof. Suppose that cell j k, where 1 (cid:1) k (cid:1) n, is activated. Thus, from Eq. (2) we obtainSj k+1(. . . , inj k, . . .) = · · · (cid:16) inj k (cid:16) · · · and, since j k is activated, from Eq. (4) we obtain22B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38σ (Sj k) = 1 and inj k = wj k,j k+1 (cid:16) Sj k. Given that there exist only positive exceptions,wj k,j k+1 (cid:2) 1, Sj k+1 (cid:2) 1 and σ (Sj k+1) = 1. Similarly, σ (Sj k+2) = 1 and so on, until,finally, σ (So) = 1. ✷Lemma 2. In a neural network constructed from an inheritance network with at mostone negative exception in each of its paths and no positive ones, using the algorithm inSection 3.5, the activation of cell t ∈ U , which the exception link starts from, prevents fromactivation any other cell connected to the head h ∈ U of the exception link via a path ofconnections p = {wh,j 1, wj 1,j 2, . . .}, where j 1, j 2, . . . ∈ U and wh,j 1, wj 1,j 2, . . . ∈ W .Proof. Since cell t is activated and there exists only one negative exception, wt,h, St (· · ·) (cid:2)1 and σ (St ) = 1. Thus, from Eq. (2) we obtain Sh(. . . , int , . . .) = · · · (cid:16) int (cid:16) · · · andby means of Eq. (4) we have int = wt,h (cid:16) St . Because there exists only one negativeexception, wt,h < −1, since f (t) < f (h) and f (h) (cid:1) 1. Thus, int < −1, hence Sh < −1and σ (Sh) = −1. Similarly, by Lemma 1, for any j k included in p, σ (Sj k) = −1. ✷Theorem 3. In a neural network constructed from an inheritance network with at mosttwo exceptions wf t,f h, wst,sh in each of its paths p = {wj 0,j 1, wj 1,j 2, . . . , wj n,o}, wherej 0, . . . ,j n ∈ U and wj 0,j 1, wj 1,j 2, . . . ∈ W , the inferential distance metric and stabilityproperty are satisfied. The following cases exist:(1) Both of them are negative or positive. In this case the following sub cases aredistinguished:(a) exclusion: f (f t) < f (f h) (cid:1) f (st) < f (sh);(b) inclusion: f (f t) (cid:1) f (st) < f (sh) (cid:1) f (f h);(c) intersection: f (f t) (cid:1) f (st) < f (f h) < f (sh).(2) The first is positive and the other is negative. In this case the following sub cases aredistinguished:(a) exclusion: f (f t) < f (f h) (cid:1) f (st) < f (sh);(b) inclusion: f (f t) (cid:1) f (st) < f (sh) (cid:1) f (f h);(c) intersection: f (f t) (cid:1) f (st) < f (f h) < f (sh). This subcase, actually, introducesatomic stability.(3) The first is negative and the other is positive. In this case the following sub cases aredistinguished:(a) exclusion: f (f t) < f (f h) (cid:1) f (st) < f (sh);(b) inclusion: f (f t) (cid:1) f (st) < f (sh) (cid:1) f (f h);(c) intersection: f (f t) (cid:1) f (st) < f (f h) < f (sh). This subcase, actually, introducesgeneric stability.Proof. It is straightforward from Eqs. (2), (3) and (4) that for each of the abovesubcases, considering arbitrary input and output cells, the output cells are properlyactivated/deactivated so that the inferential distance metric and stability property aresatisfied. In the following, we prove this claim for one of the above subcases. The proofsfor the rest subcases are similar. Consider the case ((ii)(a)) above. Suppose that cell f t isactivated. Then, from Lemma 1, for every node f i for which f (f t) < f (f i) < f (sh),σ (Sf i) = 1 is implied. It is clear, from the fourth step of the initialization algorithm inB. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3823Section 3.5, that |wf t,f h| = |wst,sh|, wf t,f h > 0, wst,sh < 0. Therefore, for the outputcell sh, Ssh(insm, inst ) = insm (cid:16) inst , where sm is the immediate ancestor of sh. Then,insm = wsm,sh (cid:16) Ssm = wf t,f h. Also, inst = wst,sh (cid:16) Sst = wst,sh due to ε in Eq. (3).Therefore, Ssh = wst,sh, also due to ε in Eq. (3). Finally, σ (Ssh) = −1. ✷Definition 4. If m = (mt, mh), n = (nt, nh) are exception links, we define the dominantexception link as the link that has priority over the other, according to the inferentialdistance metric and the stability property with respect to Theorem 3. Formally, m isdominant on n, denoted as m (cid:29) n, ifsign(Snh) = sign(wm),f (mt) (cid:2) f (nt), f (mh) (cid:2) f (nh),if sign(wm) (cid:28)= sign(wn);if sign(wm) = sign(wn).(16)(cid:1)Lemma 5. The dominant operator, (cid:29), defines a relation D on the set of connections W .Relation D is reflexive and antisymmetric.Proof. Obviously, ∀m = (mt, mh) ∈ W, m (cid:29) m, since f (mt) = f (mt). Therefore D isreflexive. Obviously, ∀m = (mt, mh), n = (nt, nh) ∈ W , for which m (cid:29) n, n (cid:29) m, thenm ≡ n is implied. Therefore D is antisymmetric. ✷Theorem 6. The general case of a neural network constructed from any inheritancenetwork is reduced to the case of Theorem 3, where at most two exceptions in each of itspaths are allowed. This is accomplished by successively replacing the pairs of exceptions(m, n) by the dominant exception of them, starting from the pair with the lower topologicalorder for the tail of m. Under this constraint, we prove that D is also transitive and hencepermits successive substitutions.Proof. We prove that ∀l = (lt, lh), m = (mt, mh), n = (nt, nh) ∈ W , for which f (lt) >f (lh), f (mt) > f (mh), f (nt) > f (nh), f (lt) (cid:2) f (mt) (cid:2) f (lh) (cid:2) f (mh), f (mt) (cid:2)f (nt) (cid:2) f (mh) (cid:2) f (nh),if l (cid:29) m, m (cid:29) n then l (cid:29) n is implied. Hence, D istransitive. If sign(wl) = sign(wm) (both negative or positive), from Definition 4, f (lt) (cid:2)f (mt), f (lh) (cid:2) f (mh). If, also, sign(wm) = sign(wn) then sign(wl) = sign(wm) =sign(wn) and from Definition 4 f (mt) (cid:2) f (nt), f (mh) (cid:2) f (nh). So, f (lt) (cid:2) f (nt),f (lh) (cid:2) f (nh) and, from the second case of Definition 4, l (cid:29) n. Else, if sign(wm) (cid:28)=sign(wn) then, also, sign(wl) (cid:28)= sign(wn) and, since m (cid:29) n, sign(Snh) = sign(wm).Therefore, sign(Snh) = sign(wl) and, hence, from the first case of Definition 4, l (cid:29) n.Consider, now, the case where sign(wl) (cid:28)= sign(wm). If, also, sign(wm) (cid:28)= sign(wn) thensign(wl) = sign(wn). Since, by constraint, f (lt) (cid:2) f (nt), f (lh) (cid:2) f (nh) then, from thesecond case of Definition 4, l (cid:29) n. Finally, if sign(wm) = sign(wn) then sign(wl) (cid:28)=sign(wn). Since l (cid:29) m then sign(Smh) = sign(wl). Moreover, sign(Snh) is determined bysign(wm) and sign(Smh). But, since sign(Smh) = sign(wl) then sign(Snh) is determined bythe dominant of l and m, which is l. Therefore, sign(Snh) = sign(wl), and, from the firstcase of Definition 4, l (cid:29) n. ✷Completeness and soundness of the refinement phase is reduced to convergence of thetraining algorithm. For a proof of convergence of this algorithm as well as for some otherrelated results see [59–61].24B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38Completeness of the extraction phase is obvious and comes straightforward fromthe extraction algorithm in Section 5.3. The extraction algorithm guarantees that everyoutput cell o ∈ U can be reached by an input cell i ∈ U by atleast one pathp = {wi,j 1, wj 1,j 2, . . . , wj n,o}, where j 1, . . . , j n ∈ U and wi,j 1, . . . , wj n,o ∈ W , whichincludes a weight wp,q that belongs to the set of the selected weights. Therefore, everychange to a weight that belongs to the set of the selected weights, during the refinementphase, can be transformed to an addition of an exception link between the head and the tailof the path(s) which the changed weight is assigned to.Soundness of the extraction phase is, also, obvious. An increase in a negative weightor a decrease in a positive weight actually decreases the absolute value of the weight andhence gives precedence to any other conflicted path with a positive or negative weightrespectively. Similarly, a decrease in a negative weight or an increase in a positive weightgives precedence to the path that contains it.6. Experimental resultsIn order to test the effectiveness and efficiency of ANNNs, as a learning system, we needto refine some initial knowledge of a pure nonmonotonic domain. Instead of choosingsuch a scarcely mentioned in the literature domain, which would not be appropriate forcomparative results, we tested ANNNs in a problem that can be considered as being definedin a nonmonotonic domain, although in the literature, it is not treated as such. The problemis the extraction of classification rules from a dataset that can be considered, in the scopeof this work, as being reduced to the extraction of general patterns and their exceptions.Classification problem, in a monotonic domain, has been attacked using both symbolic andconnectionist techniques. There are also hybrid systems, as most of those mentioned in theintroduction, that have been evaluated using it.The key idea behind using ANNNs in the classification problem, under a pseudononmonotonic domain, is to consider some initial, arbitrarily chosen, classification rulesthat introduce conflicts and then to refine them by resolving these conflicts. Therefore,exceptions in the initial knowledge are, actually, artificially defined. The reader shouldbear in mind that ANNNs are capable of refining initial knowledge of a nonmonotonicdomain. To our knowledge, there exists no hybrid system, apart from Pinkas’s symmetricnetworks based on a translation of Penalty Logic, (which however heavily relies on userdefined penalties, which in turn require a kind of preprocessing of the conflicts), that can beused in classifying examples that belong to a nonmonotonic domain. Of course, a relationcan be established between Logic Programming and nonmonotonic reasoning throughdefault and autoepistemic logics, which is based on treating negation [35]. Thus, hybridsystems like those in [23] and [12] can be, also, used in a nonmonotonic domain. However,for practical problems, one should take into consideration that, in establishing a relationbetween Logic Programming and nonmonotonic reasoning, the default interpretation ofnegation is an NP-complete task. Therefore, heuristics as “negation as failure to prove”has to be adopted. Moreover, one should also take into consideration hurdles imposed bylogic-based formalisms, in general, such as the lack of the stability property, mentioned inthe introduction.B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3825In order to evaluate ANNNs, by obtaining comparative results with other hybridsystems, we transform a monotonic domain to an artificial nonmonotonic. It is actuallythis transformation that prevents ANNNs from outperforming alternative systems inclassification in a monotonic domain. The main problem is that ANNNs, inherently, treatnoise as exceptions and thus tend to overspecialize. Therefore, ANNNs are not so accuratein unseen examples, when applied to a monotonic domain. But, the obtained experimentalresults, as presented in what follows, are comparable to other hybrid systems and superiorto various well-known pure symbolic or connectionist systems.In the next subsection, we compare ANNNs with pure symbolic and connectionistsystems against the problem of classifying both real-world datasets and test datasets. Morespecifically, we evaluate ANNNs using a real-world dataset representing the customerbase of a big telecommunications company and two real-world datasets from the domainof Molecular Biology, especially that of DNA sequence analysis, namely the “promoterrecognition” and the “splice-junction determination” problems [62]. Notice that DNAsequence analysis problems are used as benchmarks for comparing the performance oflearning systems.6.1. Extracting customer profilesClassification rules can be extracted using supervised learning methods and can be usedto classify data into predefined classes, described by a set of concepts (attributes). In mostof the cases, independently of the adopted representation scheme, a set of classificationrules describes a class through defining a general pattern with exceptions. A subset ofthese rules defines the general pattern (e.g., “young loan applicants are of a high risk”),while the rest define the exceptions (e.g., “young loan applicants with high income are oflow risk”).Consider, for example the sample of rules shown in Fig. 10. These rules are constructedby the CN2 algorithm [5] and describe the behavior of the customer base of a bigtelecommunications company. 1 The conditions of the rules are certain attributes of thecustomer base and the predefined classes denote a profit related behavior. It is obvious thatthe last three rules define general patterns, while the first one is an exception to the last tworules.Therefore, if we represent general patterns as an initial knowledge using a nonmonotonicinheritance scheme, we can find their exceptions refining the initial knowledge with respectto database records as training examples. Initial knowledge is, usually, provided by experts.In the tests we performed for ANNNs evaluation, it is chosen randomly. If we consider thethree general patterns shown in Fig. 10 as initial knowledge, the initial inheritance networkshown in Fig. 11 is constructed.Consider the following interpretation 2 of the symbols:• A stands for BAD;• B stands for COMMON;• C stands for GOOD;1 For confidentiality reasons, the classes in the rules are not the same as the actual ones.2 For confidentiality reasons, attribute values are not the same as the actual ones.26B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38Fig. 10. A sample of a decision list.Fig. 11. An example.• D stands for EMPLOYEES OF GOVERNMENT COMPANIES;• E stands for RESIDENTS OF AEGEAN ISLANDS;• F stands for YOUNG PEOPLE;• G stands from YOUNG PEOPLE, EMPLOYEES OF GOVERNMENT COMPA-NIES, RESIDENTS OF AEGEAN ISLANDS.The above inheritance network, in turn, is used to initialize a connectionist network asshown in the same figure. The latter is trained, using relational data as training examples.Finally, refined rules are extracted in the form of a new inheritance network, as shownin Fig. 12. This refined inheritance network can now be used to infer that “EmployeesB. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3827Fig. 12. Resolving conflicts.of government companies and residents of Aegean Islands are common customers”. Thisholds because of the added positive exception link (G, B) and the negative exception link(G, C). The first supports the fact that Gs are Bs, while the previously conflicted extension(that Gs are not Bs because they are Cs) is removed due to the second.Notice that every such query, which is actually a combination of attribute values, shouldbe considered as exceptional and refined during training. Hence, combinations of attributevalues are considered as potential exceptions, determining a pseudo nonmonotonic domain.The initial weights of the previous example are shown in Fig. 11. During the refinementphase some of the initial weights are changed while trying to minimize the error function.The error function, given that there are three output cells and one input cell, takes thefollowing form:E =3(cid:6)i=1(cid:14)σ (NOUTi) − (2DOUTi − 1)(cid:15)2,Thus:E =(cid:14)(cid:7)(w560,559 (cid:16) S560) (cid:16) (w564,559 (cid:16) S564) − (2DOUT559 − 1)(cid:7)(w561,560 (cid:16) S561) (cid:16) (w562,560 (cid:16) S562) − (2DOUT560 − 1)+(cid:7)(w563,561 (cid:16) S561) − (2DOUT563 − 1)(cid:8)2+(cid:15).(17)(cid:8)2(cid:8)2A table with 30000 records is used as a training set. This table is the same as the one usedby the CN2 algorithm when the rules of Fig. 10 are extracted. 31 records of this table areof the form:“young_people, empl_gov_co, res_Aegean_Isl, bad ”which are encoded as:in565 = 1, DOUT561 = 0, DOUT560 = 0, DOUT559 = 1,129 records of them are encoded as:in565 = 1, DOUT561 = 0, DOUT560 = 1, DOUT559 = 0, and108 records of them are encoded as:in565 = 1, DOUT561 = 1, DOUT560 = 0, DOUT559 = 0.28B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38Table 1Instances of the trace of executionw0563,561111566−1−1−1w0561,560−561w0560,559−560−561−561−561−561−5662566−566−560−560−560−560E1280210412802144107210721112Some epochs of the refinement process are exhibited in Table 1. Theoretically, the weightw560,559 is changed properly in the interval [−ζ, ζ ], where ζ is a “big” positive integer. Weconsider ζ as the number assigned to the last cell in topological ordering plus one. Actually,weight w560,559 is changed taking values from the set {−566, . . ., +566}. Since there is notany minimization of the error function, the algorithm proceeds to changing other weights.Eventually, weight w563,561 is changed. A decrease minimizes the error function.Meanwhile, in this case, as possibly in the general case, all outputs are deactivated andthere is no conflict resolution at all. In such a case, we ignore the decrement of the errorfunction and we proceed while keeping the change in the weight. This is also the case,when more than one outputs are activated. According to our experience, and in view of allthe tests that we have made, the latter case has not been encountered.Then, weight w561,560 is changed. An increase in the weight minimizes the error functionwith respect to its initial value. More changes do not further minimize the error function,therefore the refinement phase finishes. The revised inheritance network is shown inFig. 12. There was an increase in weight w561,560 that identifies the extension G → E → Bas prevalent. Therefore a positive exception link (G, B) is added that supports this prevalentextension. Notice that the added link does not affect the existed negative exception link(B, A), which should be retained. Moreover, there was a decrease in weight w563,561.Therefore, a negative exception link (G, C) is also added.Notice that in the revised inheritance network a negative exception link (G, A) is notadded, in order to directly exclude the extension (G → D → A). Meanwhile, the positiveexception link (G, B) can be used to resolve the conflict, indirectly, through adopting askeptical view [26]. Alternatively, such conflicts can be resolved at the implementationlevel. Thus, if a positive exception link is added by the extraction algorithm then negativeexception links are also added to the rest of the output nodes.Initial knowledge, represented in the inheritance network shown in Fig. 11, consistsof general rules that refer to values of different attributes characterizing the training set(nodes D, E, F ), while the input node G represents a potential exception that refers toa combination of attribute values. If we consider all possible general rules, each for adifferent attribute value, that arbitrarily classify examples to all three classes (A, B andC), we can use ANNNs to refine this initial knowledge, thus resolving these artificialB. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3829Fig. 13. Test-set performance.conflicts. Obviously, we can then consider exceptions of these rules, each of them formedby a combination of values, taken from a pair of attributes, and we can try to resolve anyconflicts. We can repeatedly consider further exceptions (exceptions of larger depth), eachof them formed by a combination of values taken from a triple of attributes (as in Fig. 11)and so on. Thus, at the end, the obtained inheritance network represents classification rules,with resolved conflicts, and can be used in a classification process.We have compared ANNNs, in extraction of customer profiles, to symbolic andconnectionist techniques. We have chosen CN2, a well-known symbolic algorithm, and twogenuine connectionist learning techniques, namely the Self-Organized Map algorithm [28]and the Radial Basis Function networks. The overall classification accuracy of testedtechniques is shown in Fig. 13, using a set of 30000 patterns, chosen out of a set of 60000patterns. In each case we formed a training set choosing, randomly, 80% of the initial setand a test set from the remaining 20%.Using SOM, the best results was obtained when the number of neurons was in the range50 to 150. Within that range the classification performance was not strongly dependenton the number of neurons. The training set size should be large. For instance, for 10000training patterns, taken from the training set, the obtained performance was 36%. However,for 30000 training patterns and more (up to 50000 patterns that we tried) the classificationperformance was not varied significantly and it was about 46%. When the class informationis appended as input to the training patterns, the classification performance is improvedby about 2–4% (it becomes about 48% to 50%). The LVQ phase, with the supervisedrefinement of the class boundaries, further improves the classification results to 56–58%.Radial Basis Function (RBF) networks were also used, taking as centers the weightvectors of the neurons obtained after the SOM or LVQ. Then the RBF network trainingalgorithm learns locally the classification function, by accounting mostly the patterns thatfall near each training center [20]. However, practically, the numerical solution of theformulated equations for the RBF training becomes problematic, due to the large size ofthe problem. The currently achieved performance with the RBF networks is only 37%. Thepoor performance can be attributed to the large size of the training set that involves largematrices, which are mostly sparse.30B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38As far as the symbolic algorithm CN2 is concerned, it overcomes the low classificationperformance problem of connectionist techniques. Actually, the construction of rules isrelated to a predefined measure of classification performance (entropy). However, it suffersfrom a very bad time and space complexity.The example of the previous section, shown in Fig. 11, concerns a particular combinationof attribute values determining a potential exception that must be probably resolved. Thisexample is actually a subset of a complete solution provided by the other mentionedapproaches. The overall time complexity is dominated by the number of differentcombinations of the values of a subset of input attributes to be examined. This isZ =(cid:16)S(cid:6)(Si )(cid:6)(cid:14)i=2j =1|Ak1| × · · · × |Akj |(cid:17)(cid:15),(18)where S is the number of attributes and |Akn| is the number of different values thatcan be assigned to an attribute (a field). Therefore, the time complexity of the particularapplication of ANNNs to a classification problem is directly proportional to the number ofdifferent attributes and to the number of the different values of these attributes. On the otherhand, the number of attributes participating in a combination, that is the depth of exception,has an impact on the classification accuracy. Large depths tend to overspecialize.6.2. Analyzing DNA sequenceWe, also, evaluate ANNNs using the promoter recognition and the splice-junctiondetermination problem. Initial knowledge of each problem is the rule sets used in [12,56]. The initial knowledge for the promoter recognition problem is represented by theNIN shown in Fig. 14, where every sequence location is arbitrarily connected bothto a “promoter” output node and to a “no promoter” one. These output nodes areconnected via an exception link. The same approach is, also, adopted for the splice-junctiondetermination problem.We used cross-validation as the testing methodology. More specifically, for promoterrecognition we used leaving-one-out cross-validation in which the set of 106 examples ispermuted and divided into 106 sets with only one example in each set. In each evaluationphase, one set, which has never been seen during learning, is used for testing, whileFig. 14. The initial NIN for promoter recognition problem.B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3831Fig. 15. Test-set performance in promoter recognition.Fig. 16. Test-set performance in splice-junction determination.the examples of the remaining 105 sets are used for training. Hence, evaluation processrequires 106 training phases. Test-set performance in promoter recognition for ANNNs isshown in Fig. 15, where the number of not recognized positive and negative examples isdepicted.Test-set performance in splice-junction determination, using 10-fold cross-validation in1000 examples, chosen randomly out of the standard set of 3190 examples, is illustratedin Fig. 16. Test-set performance for ANNNs is compared to other empirical learningalgorithms and two methods (Stormo, O’Neill [56]) suggested by biologists. Notice thatwe replicate tests for these algorithms performed in [56].The overall classification accuracy of ANNNs, in promoter recognition and splice-junction determination, compared to other systems that learn strictly from examples, aswell as from examples and background knowledge, is shown in Fig. 17 and Fig. 18,respectively. Notice that we replicate tests for these algorithms performed also in [12].Performance of ANNNs, in promoter recognition, is tested using, apart from leaving-one-out, both 10-fold and 20-fold cross validation. Fig. 17 shows that the 10-foldmethodology exhibits the best results, while the 20-fold the worst. One hypothesis to32B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38Fig. 17. Classification accuracy in promoter recognition.Fig. 18. Classification accuracy in splice-junction determination.explain this result is that there is a trade off between the decrease of accuracy, due toinsufficient training examples (20-fold) or overspecialization (leaving-one-out), and theincrease of accuracy, due to an optimum training set (10-fold).We, also, evaluate the generalization ability of ANNNs in learning from small sets ofexamples. The testing methodology consists in splitting the initial set of 106 examplesof the promoter recognition problem into two subsets, one containing approximately 25%of the examples (26) and the other the remaining examples (80). The latter set is furtherB. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3833Fig. 19. Classification accuracy in learning from small sets.Fig. 20. Classification accuracy as a function of depth of exceptions.partitioned into sets of increasing size, with the smaller sets being subsets of the larger ones.In each evaluation phase, one of those subsets is used for training, while the set of the 26examples is always used for testing. The classification accuracy of ANNNs, in each phase,is depicted in Fig. 19 compared to other hybrid systems and backpropagation. Notice thatwe replicate tests performed in [12]. The same result holds, also, for the splice-junctiondetermination problem.Depth of exceptions has a straightforward impact on the classification accuracy ofANNNs (in the particular context of the pseudo nonmonotonic domain). On the other hand,depth of exceptions has a straightforward impact on the time complexity. Note that largedepths of exceptions are not desirable in such a pseudo nonmonotonic domain, since theyintroduce overspecialization. On the contrary, they are desirable in a pure nonmonotonicdomain, in order to capture exceptions.Also, notice that all the tests presented so far have been performed with depth equals to2 (combinations of two attributes). Of course, in a nonmonotonic domain, the larger thedepth the better the classification accuracy and the worse the time complexity. In Fig. 20,34B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38classification accuracy, for the promoter recognition problem, is depicted as a function ofdepth of exceptions, where approximately 25% of the examples (26) were used for testingand the remaining examples for training.7. Discussion, conclusion and further researchHybrid systems are typically used for refinement of the domain knowledge. After therefinement phase, the trained Artificial Neural Network, as part of the hybrid system, canbe used, as a reasoning system, in order to access the refined knowledge.In general, an Artificial Neural Network, by construction, supports access operationsof the ISA type queries, that is it infers about whether an object possesses a particularproperty or not. Notice that the complexity of ISA queries in an Artificial Neural Networkis comparable to the complexity of ISA queries in path-based networks, when using veryeffective compression techniques (see, for example, [2]). Of course, this is true if weconsider the enumeration of the activation function of unit cost. Moreover, an ArtificialNeural Network can support access operations concerning the recognition problem, that isit can find all the objects satisfying a particular set of properties. However, in that case suchoperations are not effective enough.The main advantages of hybrid systems come from using the symbolic part to accessthe refined knowledge. Apart from more effective access operations, the symbolic parthas also an explanation capability about the generated outputs. In such a utilization ofhybrid systems, the refined knowledge has to be extracted in order to feed back thedomain knowledge. Therefore, reliability of the extraction phase is a critical factor to theeffectiveness of hybrid systems.We have tried to use a proper initialization method, a proper training method anda proper extraction algorithm for ANNNs. We proved that they preserve the symbolicmeaning of the Initial Inheritance Network, so that we can effectively transform the trainedArtificial Neural Network into a comprehensible nonmonotonic inheritance network.Moreover, we evaluated ANNNs by applying them to the classification problem for apseudo nonmonotonic domain, where exceptions in the initial knowledge are artificiallydefined. We have followed this evaluating procedure in order to obtain comparative results,because, to our knowledge, there are no available benchmarks for pure nonmonotonicdomains. On the other hand, for a monotonic domain there are well known and widelyused benchmarks (e.g., see [56]). We empirically proved that, despite ANNNs beingcapable of refining initial knowledge of a nonmonotonic domain, their performance inthe classification problem is comparable to other hybrid monotone systems and better thanvarious well-known monotone pure symbolic or connectionist systems. Of course, none ofthe monotone systems, that ANNNs were compared to, can be used in classifying examplesthat belong to a nonmonotonic domain. The main problem, observed during experiments,is that ANNNs, inherently, treat noise as exceptions and thus tend to overspecialize.We are currently applying ANNNs to different data sets that can constitute a purenonmonotonic domain (incomplete data, data with drifting or evolving concepts, dataarriving over time, etc.). We, also, try to improve the performance of ANNNs in monotonicdomains that are reduced to pseudo nonmonotonic domains, as those used in the presentedB. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3835experimental tests. To this end, we try to identify any malfunctions in cases that biasedand noisy data exists, where ANNNs, in pseudo nonmonotonic domains, usually exhibit alower performance compared to other systems.In general, ANNNs, treating noise as exceptions, are very sensitive to noise in both thetraining and the domain knowledge, especially when ANNNs are applied to a monotonicdomain. This result is, also, obvious from the presented experiments. We propose to attackthis problem by properly selecting the training set, to be able to define as much desiredoutputs as possible. That is, training is forced to contain not only examples for resolvingextensions or deleting exceptions, but also examples that support the already representedknowledge. Moreover, although a continuous analogous refinement process may be morepowerful for tackling noise, however it does not satisfy the prerequisites imposed by theproposed approach. To this end, we intent to modify our approach so that continuousanalogous refinement processes could be applied instead.In conclusion, ANNNs are defined to be capable of refining initial knowledge of anonmonotonic domain. We applied ANNNs to a monotonic domain, reducing it to a pseudononmonotonic domain, namely the extraction of classification rules from large relationaldatabases. Notice that, since common monotonic knowledge representation schemes,such as production rules of traditional Expert Systems, are weaker than nonmonotonicinheritance networks, the domain knowledge of a hybrid system can be the domainknowledge of a traditional Expert System. In that case, the initialization-refinement-extraction cycle can be considered as a knowledge acquisition and inferring methodologyfor traditional Expert Systems, capable of justifying the produced conclusions.Finally, we are interested in examining the behavior of training methods that do notpreserve the symbolic meaning of the initialized Artificial Neural Network, such asthose that are not restricted to changing the weights, but can also add hidden layers andconnections. The semantics of NINs that are extracted from such trained Artificial NeuralNetwork is under research.AcknowledgementsWe wish to thank the anonymous referees for their constructive comments, suggestions,and invaluable criticisms which helped us to improve the paper. We also wish to thankDr. S. Papadimitriou and Mr. G. Petalas for their invaluable help during the tests as well asDr. P. Peppas for useful discussions.References[1] R. Andrews, J. Diederich, A.B. Tickle, Survey and critique of techniques for extracting rules from trainedartificial neural networks, Knowledge-Based Systems 8 (1995) 373–389.[2] B. Boutsinas, On managing nonmonotonic transitive relationships,in: Proc. 8th IEEE InternationalConference on Tools with Artificial Intelligence (ICTAI), Toulouse, France, 1996, pp. 374–382.[3] B. Boutsinas, Y.C. Stamatiou, G. Pavlides, Massively parallel support for nonmonotonic reasoning, in:J. Geller, H. Kitano, C. Suttner (Eds.), Parallel Processing for Artificial Intelligence, Elsevier Science,Amsterdam, 1997, pp. 41–67.36B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38[4] G. Brewka, Cumulative default logic: In defense of nonmonotonic inference rules, Artificial Intelli-gence 50 (2) (1991) 183–205.[5] P. Clark, T. Niblett, The CN2 induction algorithm, Machine Learning 3 (1989) 261–283.[6] J.P. Delgrande, T. Schaub, W. Ken Jackson, Alternative approaches to default logic, Artificial Intelligence 70(1994) 167–237.[7] J.E. Dennis Jr., R.B. Schnabel, Numerical Methods for Unconstrained Optimization and NonlinearEquations, Prentice-Hall, Englewood Cliffs, NJ, 1983.[8] D. Dubois, H. Prade, Possibilistic logic, preferential models, nonmonotonicity and related issues, in: Proc.IJCAI-91, Sydney, Australia, 1991, pp. 419–424.[9] D. Etherington, Formalizing nonmonotonic reasoning systems, Artificial Intelligence 31 (1987) 41–85.[10] L. Fu, Introduction to knowledge-based neural networks, Knowledge-Based Systems 8 (1995) 299–300.[11] S.I. Gallant, Connectionist expert systems, Comm. ACM 31 (1988) 152–169.[12] A.A. Garcez, G. Zaverucha, The connectionist inductive learning and logic programming system, Appl.Intelligence 11 (1999) 59–77.[13] G.J. Gibson, F.N. Cowan, On the decision regions of multi-layer perceptrons, Proc. IEEE 78 (1990) 1590–1594.[14] E.M. Gorwin, A.M. Logar, W.J.B. Oldham, An iterative method for training multilayer networks withthreshold functions, IEEE Trans. Neural Networks 5 (1994) 507–508.[15] R. Goodman, Z. Zeng, A learning algorithm for multi-layer perceptrons with hard-limiting threshold units,in: Proc. IEEE Neural Networks for Signal Processing, 1994, pp. 219–228.[16] H.W. Güsgen, S. Hölldobler, Connectionist inference systems, in: B. Fronhofer, G. Wrightson (Eds.),Parallelization in Inference Systems, Lecture Notes in Artificial Intelligence, Vol. 590, Springer, Berlin,1992, pp. 82–120.[17] S.E. Hampson, D.J. Volper, Representing and learning Boolean functions of multivalued features, IEEETrans. Systems Man Cybernet. 20 (1990) 67–80.[18] I. Hatzilygeroudis, J. Prentzas, Constructing modular hybrid knowledge bases for expert systems, Internat.J. Artificial Intelligence Tools 10 (1–2) (2001) 87–105.[19] I. Hatzilygeroudis, H. Reichgelt, Handling inheritance in a system integrating logic in objects, DataKnowledge Engineering 21 (1997) 253–280.[20] S. Haykin, Neural Networks, 2nd edn., Macmillan Publishing, 1999.[21] S. Hölldobler, F. Kurfess, CHCL—A connectionist inference system, in: B. Fronhöfer, G. Wrightson (Eds.),Parallelization in Inference Systems, Lecture Notes in Artificial Intelligence, Vol. 590, Springer, Berlin,1992, pp. 318–342.[22] S. Hölldobler, Automated inferencing and connectionist models, Post Ph.D. Thesis, Intellektik, Informatic,TH Darmstadt, 1993.[23] S. Hölldobler, Y. Kalinke, Towards a massively parallel computational model for logic programming, in:Proc. ECAI-94 Workshop on Combining Symbolic and Connectionist Processing, 1994, pp. 68–77.[24] S. Hölldobler, Y. Kalinke, H. Störr, Approximating the semantics of logic programs by recurrent neuralnetworks, Appl. Intelligence 11 (1999) 45–58.[25] S. Hölldobler, Challenge problems for the integration of logic and connectionist systems, Technical Report,WV-99-03, AI Institute, Dept. of Computer Science, Dresden University of Technology, 1999.[26] J. Horty, R. Thomason, D. Touretzky, A skeptical theory of inheritance in nonmonotonic semantic networks,Artificial Intelligence 42 (1990) 311–318.[27] Y. Kalinke, Using connectionist term representation for first-order deduction—A critical view, in: F. Maire,R. Hayward, J. Diederich (Eds.), Connectionist Systems for Knowledge Representation Deduction,Queensland Univ. of Tech., 1997.[28] T. Kohonen, Self-Organized Maps, Springer, Berlin, 1997.[29] R. Maclin, Learning from instruction and experience: Methods for incorporating procedural domain theoriesinto knowledge-based neural networks, Technical Report, UW CS-TR-95-1285, 1995.[30] R. Maclin, J.W. Shavlik, Refining domain theories expressed as finite-state automata,in: Proc. 8thInternational Machine Learning Workshop, San Mateo, CA, 1991.[31] G.D. Magoulas, M.N. Vrahatis, G.S. Androulakis, Effective backpropagation training with variable stepsize,Neural Networks 10 (1997) 69–82.B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–3837[32] G.D. Magoulas, M.N. Vrahatis, G.S. Androulakis, Increasing the convergence rate of the error backpropa-gation algorithm by learning rate adaptation methods, Neural Computation 11 (1999) 1769–1796.[33] G.D. Magoulas, M.N. Vrahatis, T.N. Grapsa, G.S. Androulakis, A training method for discrete multilayerneural networks, in: S.W. Ellacott, J.C. Mason, I.J. Anderson (Eds.), Mathematics of Neural Networks,Models, Algorithms and Applications, Kluwer Academic, Boston, 1997, pp. 250–254 (Chapter 42).[34] D. Makinson, General theory of cumulative inference, in: M. Reinfrank (Ed.), Proc. 2nd InternationalWorkshop on nonmonotonic Reasoning, Lecture Notes in Artificial Intelligence, Vol. 346, Springer, Berlin,1989, pp. 1–18.[35] V.W. Marek, M. Truszczy´nski, Nonmonotonic Logic, Springer, Berlin, 1993, pp. 141–187.[36] G.E. Manoussakis, M.N. Vrahatis, G.S. Androulakis, New unconstrained optimization methods based onone-dimensional rootfinding, in: D. Bainov, A. Dishliev (Eds.), Proc. 3rd International Colloquium onNumerical Analysis, Science Culture Technology Publishing, Oxford Graphic Printers, 1995, pp. 127–136.[37] J. McCarthy, Epistemological challenges for connectionism, Behavioural and Brain Sciences 11 (1988) 44.[38] W. McCullough, W.H. Pitts, A logical calculus of the ideas imminent in nervous activity, Bull. Math.Biophysics 5 (1943) 115–133.[39] J.M. Ortega, W.C. Rheinboldt, Iterative Solution of Nonlinear Equations in Several Variables, AcademicPress, New York, 1970.[40] G. Pinkas, The equivalence of connectionist energy minimization and propositional calculus satisfiability,Technical Report, WU CS 90-03, 1990.[41] G. Pinkas, Energy minimization and the satisfiability of propositional logic, in: D. Touretzky, J. Elman,T. Sejnowski, G. Hinton (Eds.), Proc. of the Connectionist Models School, Morgan Kaufmann, San Mateo,CA, 1990.[42] G. Pinkas, Symmetric neural networks and propositional logic satisfiability, Neural Computation 3 (1991)282–291.[43] G. Pinkas, Expressing first-order logic in symmetric connectionist networks, in: L.N. Kanal, C.B. Suttner(Eds.), Informal Proc. Internat. Workshop on Parallel Processing for AI, Sydney, Australia, 1991, pp. 155–160.[44] G. Pinkas, Propositional nonmonotonic reasoning and inconsistency in symmetric neural networks, in: Proc.IJCAI-91, Sydney, Australia, 1991, pp. 525–530.[45] G. Pinkas, Constructing syntactic proofs in symmetric networks, Advances in Neural InformationProcessing Systems IV (NIPS91) (1992) 217–224.[46] G. Pinkas, Reasoning, nonmonotonicity and learning in connectionist networks that capture propositionalknowledge, Artificial Intelligence 77 (1995) 203–247.[47] J. Pollack, Recursive distributed representations, Artificial Intelligence 46 (1990) 77–105.[48] R. Reiter, A logic for default reasoning, Artificial Intelligence 13 (1980) 81–132.[49] D.E. Rumelhart, G.E. Hinton, R.J. Williams, Learning internal representations by error propagation, in:D.E. Rumelhart, J.L. McClelland (Eds.), Parallel Distributed Processing: Explorations in the Microstructureof Cognition, Vol. 1, MIT Press, Cambridge, MA, 1986, pp. 318–363.[50] E. Sandewall, Nonmonotonic inference rules for multiple inheritance with exceptions, Proc. IEEE 74 (1986)1345–1353.[51] B. Selman, H.J. Levesque, The tractability of path-based inheritance, in: Proc. IJCAI-89, Detroit, MI, 1989.[52] L. Shastri, Default reasoning in semantic networks: A formalization of recognition and inheritance, ArtificialIntelligence 39 (1989) 283–355.[53] D.J. Tom, Training binary node feed forward neural networks by backpropagation of error, ElectronicsLetters 26 (1990) 1745–1746.[54] D. Touretzky, The Mathematics of Inheritance Systems, Morgan Kaufmann, Los Altos, CA, 1986.[55] D. Touretzky, J. Horty, R. Thomason, A clash of intuitions: The current state of nonmonotonic multipleinheritance systems, in: Proc. IJCAI-87, Milan, Italy, 1987, pp. 476–482.[56] G.G. Towell, J.W. Shavlik, Knowledge based artificial neural networks, Artificial Intelligence 40 (1994)119–165.[57] M.N. Vrahatis, Solving systems of nonlinear equations using the nonzero value of the topological degree,ACM Trans. Math. Software 14 (1988) 312–329.[58] M.N. Vrahatis, CHABIS: A mathematical software package for locating and evaluating roots of systems ofnonlinear equations, ACM Trans. Math. Software 14 (1988) 330–336.38B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38[59] M.N. Vrahatis, G.S. Androulakis, J.N. Lambrinos, G.D. Magoulas, A class of gradient unconstrainedminimization algorithms with adaptive stepsize, J. Comput. Appl. Math. 114 (2000) 367–386.[60] M.N. Vrahatis, G.S. Androulakis, G.E. Manoussakis, A new unconstrained optimization method forimprecise problems, in: D. Bainov, A. Dishliev (Eds.), Proc. 3rd International Colloquium on NumericalAnalysis, Science Culture Technology Publishing, Oxford Graphic Printers, 995, pp. 185–194.[61] M.N. Vrahatis, G.S. Androulakis, G.E. Manoussakis, A new unconstrained optimization method forimprecise function and gradient values, J. Math. Anal. Appl.197 (1996) 586–607.[62] J.D. Watson, N.H. Hopkins, J.W. Roberts, J.A. Steitz, A.M. Weiner, Molecular Biology of the Gene, Vol. 1,Benjamin Cummings, Menlo Park, CA, 1987.[63] B. Widrow, R. Winter, Neural nets for adaptive filtering and adaptive pattern recognition, IEEE Computer(March 1988) 25–39.[64] W. Woods, What’s in a link?: Foundations for semantic networks, in: R. Brachman, H. Levesque (Eds.),Readings in Knowledge Representation, Morgan Kaufmann, Los Altos, CA, 1985, pp. 217–241.[65] Z. Zeng, R. Goodman, P. Smyth, Learning finite state machines with self-clustering recurrent networks,Neural Comput. 5 (1993) 976–990.[66] Z. Zeng, R. Goodman, P. Smyth, Discrete recurrent neural networks for grammatical inference, IEEE Trans.Neural Networks 5 (1994) 320–330.