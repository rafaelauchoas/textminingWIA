Artificial Intelligence 173 (2009) 857–875Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintStrengths and synergies of evolved and designed controllers:A study within collective roboticsGianluca Baldassarre∗, Stefano NolfiLaboratory of Autonomous Robotics and Artificial Life, Istituto di Scienze e Tecnologie della Cognizione, Consiglio Nazionale delle Ricerche (LARAL-ISTC-CNR),Via San Martino della Battaglia 44, 00185 Roma, Italya r t i c l ei n f oa b s t r a c tThis paper analyses the strengths and weaknesses of self-organising approaches, such asevolutionary robotics, and direct design approaches, such as behaviour-based controllers,for the production of autonomous robots’ controllers, and shows how the two approachescan be usefully combined. In particular, the paper proposes a method for encoding evolvedneural-network based behaviours into motor schema-based controllers and then showshow these controllers can be modified and combined to produce robots capable of solvingnew tasks. The method has been validated in the context of a collective robotics scenarioin which a group of physically assembled simulated autonomous robots are requested toproduce different forms of coordinated behaviours (e.g., coordinated motion, walled-arenaexiting, and light pursuing).© 2009 Elsevier B.V. All rights reserved.Article history:Received 10 November 2006Received in revised form 19 December 2008Accepted 3 January 2009Available online 6 January 2009Keywords:Neural networksGenetic algorithmsSelf-organisationMotor schema-based controllersPotential fieldsModularityMulti-variable statistical regression1. IntroductionIn the field of autonomous robotics, approaches in which the controllers are designed by the experimenter, such asbehaviour-based robotics [2,3,10,13,18,22,27,28,31,32,51,52], and approaches in which some of the characteristics of the con-trollers are developed through automatic procedures, such as evolutionary robotics [8,39,41,42,44,47,48,53], are usually seenas two alternative methods based on partially contrasting principles. This paper proposes a method for combining thestrengths of automatic procedures and direct design methods. In particular it show how effective solutions discoveredthrough an evolutionary technique can be re-coded in motor schema-based controllers which can be later manipulated andcombined to produce new behaviours.To accomplish this goal, the research presented here compares evolved feed-forward neural-network controllers [16,36,39]with hand-coded motor schema-based controllers [1,2]. Artificial neural networks are a formalism widely used to encode robots’controllers in evolutionary robotics research [39]. Feed-forward neural networks are the simplest type of neural controllerin which the state of the motors is a function of only the current state of the sensors. Feed-forward neural controllershave been chosen because they were sufficient for the purposes of this study and because they could be easily comparedwith hand-coded motor schema-based controllers. Hand-coded motor-schema based controllers are a class of behaviour-based controllers [2,13] based on artificial potential fields which have been successfully used with both mobile robots [1] androbotic manipulators [30]. These types of controllers have been chosen because, as feed-forward neural controllers, theyinvolve a direct mapping between the activation of sensors and the commands issued to motors: this feature was expectedto ease the comparison of the two types of controllers. Here the mapping between the two classes of controllers will be* Corresponding author.E-mail addresses: gianluca.baldassarre@istc.cnr.it (G. Baldassarre), stefano.nolfi@istc.cnr.it (S. Nolfi).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.01.001858G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875obtained with suitable mathematical multi-variable functions. The form of these functions will be directly designed, whereasits parameters, depending on the specific goal in hand, will be either hand-tuned, or obtained through suitable regressions,or searched with evolutionary/design hybrid techniques.The test of models were conducted in the context of a collective robotics scenario [15,19,21,25,33,34] in which a “swarm”of assembled robots [37] is requested to display a variety of coordinated cooperative behaviours and in which each robothas access to only local sensory information.Beside highlighting the general strengths and weaknesses of the two approaches, the paper also shows how: (a) thesolutions encoded in evolved neural controllers (Section 2 illustrates the methods used for this evolution and Section 3illustrates the functioning of the evolved controllers) can be implemented in motor schema-based controllers (Section 4);(b) the obtained motor schema-based controllers can be manually manipulated to identify the key functioning features ofthe evolved solution (Section 5); (c) the obtained motor schema-based controllers can be modified to obtain new controllersable to produce new behaviours (Section 6); (d) different schema-based controllers obtained from the evolved ones can becombined to develop robots able to produce more complex behaviours (Section 7).2. The experimental set-up2.1. The robotThe research presented here was carried out within a research project, SWARM-BOTS, funded by the European Union (IST-FET Program; [20,37]). The goal of this project was to develop swarm-bots, that is groups of fully autonomous robots able tophysically connect and disconnect to form larger robotic systems. These systems can assume different physical shapes andact to solve problems that cannot be solved by single robots. This paper focuses on how a group of robots that are alreadyassembled can accomplish common tasks such as to coordinate the motion direction in a distributed fashion (that is withouta leader, cf. [8]). Other researches carried out within the project studied how robots can self-assemble and disassemble toaccomplish collective tasks [26,49].Each robot (Fig. 1; cf. [37]) has a cylindrical body with a diameter of 11.6 cm and consists of a mobile base (“chassis”), anda main body (“turret”). The chassis is endowed with two motors each controlling a track and a teethed wheel. A third motorallows the turret and the chassis to actively rotate with respect to each other. The turret is provided with two grippers, onerigid and one flexible, that allow the robots to self-assemble and grasp objects. Each robot is provided with a numberof different sensors [37], but only the traction sensor described below has been simulated and used in the experimentsreported in this paper.In order to carry out the experiments reported in the paper we built a simulator of the robot based on the SDK VortexTMtoolkit (Critical Mass Labs, Canada) which allows programming realistic simulations of dynamics and collisions of rigidbodies in 3D. Given the high computational costs of simulations, only few relevant characteristics of the sensors, actuatorsand body of the robot were simulated; moreover the size of the robots and the gravitational acceleration coefficient werereduced to have the possibility of increasing the simulation time step without having instabilities.Fig. 1. The robot that has been reproduced in the simulator used to carry out the experiments reported in the paper.G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875859Fig. 2. Four simulated robots linked up to form a linear swarm-bot. Each robot is made up by a chassis (parallelepiped) to whom two motorised cylindricalwheels and two small spherical wheels are attached (the two passive wheels have different colours, dark and light grey, to allow distinguishing the twopossible chassis’ fronts). The chassis is connected to a cylindrical turret. The black segment between the turrets of two robots represents a physical linkbetween them. The white line above each robot’s turret, which goes from the turret’s centre to a point on its perimeter, indicates the direction of tractionand, with its size, the intensity of traction.Fig. 3. Traction force detected by the robot traction sensor. The parallelepiped represents the chassis. The turret has not been drawn for clarity. The largeand small grey circles represent respectively the right motorised wheel and the front passive wheel. The thin arrow indicates the orientation of the chassis,the bold arrow indicates the vector of the traction force that the turret exerts on the chassis, and the dotted arrow indicates the angle of traction measuredclockwise from the back of the robot.The motor system of a simulated robot was modelled by four wheels connected to the chassis: two lateral motorisedwheels that modelled the external wheels of the real robot and two spherical passive wheels placed at the front and atthe back to stabilise the robot. The chassis was connected to the turret, modelled as a cylinder, through a motorised joint(Fig. 2). The turret was endowed with a gripper which was modelled by creating a physical joint between the robot andother robots when needed (this joint was either rigid – in which case it will be called rigid link in the following sections –or possessed a free hinge with a vertical pivot – in which case it will be called flexible link). The active and passive wheelshad a diameter of respectively 2.30 and 1.15 cm. The turret had a diameter of 5.8 cm and a height of 4.6 cm.During evolution, spherical collision models were used for all the wheels and for the chassis, as these speeded upcomputations (results equivalent to those reported below were obtained by testing the evolved controllers with the collisionmodels shown in Fig. 2). The gravitational acceleration coefficient was set at 9.8 cm/s2. This low value, that caused a lowfriction of the wheels on the ground, was compensated for by setting the maximum torque of the motors at a low value,70 dynes cm. The coefficient of friction, simulated by Vortex according to the Coulomb model, was set at 0.6. The desiredspeed of the wheels varied within ±5 rad/s. The desired speed applied to the turret-chassis motor was permanently setequal to the difference between the desired speed of the left wheel and right wheel times 0.26 (this setting implied that,when the chassis turned, the turret turned in the opposite direction so that its orientation did not change with respect tothe environment: this greatly helped the robots to turn their chassis when they were attached to other robots). The stateof the sensors and motors, and the differential equations used by Vortex to simulate the bodies’ dynamics, were updatedevery 100 ms.Each robot was provided with a traction sensor placed at the turret-chassis junction (Fig. 3). This sensor returned thedirection (angle with respect to the chassis’ orientation) and the intensity of the force of traction that the turret exertedon the chassis. Traction was caused by the movements of both the connected robots and the robot’s own chassis. Noticethat, by being rigidly assembled to other robots, the turret of a specific robot physically integrated the forces produced bythe other robots on it. As a consequence, the traction sensor measured the mismatch between the directions of motion ofthe robot and the direction of motion of the rest of the group, and hence furnished the robots an important communicationchannel based on implicit communication [42,50]. The intensity of the traction force measured the size of this mismatch. Tohave more realistic simulations, a 2D noise ranging within ±5% of the maximum value was added to the traction force seenas a 2D vector.Each robot was also endowed with four light sensors. These sensors were used to extend the controller in order tosolve light pursuing tasks (see Section 7). The sensors were positioned on the perimeter of the turret, and were simulatedby using a sampling procedure applied to a real sensor (cf. [36]; the sensors had a high sensitivity to the light gradient:their activation was maximum when close to the light, exponentially decreased with a decreasing distance, and achieved860G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875Fig. 4. Computation of the activation of the “virtual light sensors” on the basis of the activation of the light sensors. The four empty squares represent thelight sensors placed on the turret. The four empty circles represent the virtual light sensors located on the chassis. As an example, the dotted arrows departfrom the sensors that were used to compute the activation of the virtual sensor pointed by the heads of the arrows themselves.Fig. 5. The neural controller of each robot consisted of a two-layer neural network with five input neurons, encoding the direction and intensity of tractionplus a bias signal, and two output neurons, encoding the desired speed of the wheel motors.a value of zero at 400 cm). A noise ranging within ±5% of the maximum intensity was added to the sensors. Shadowswere simulated by computing geometrical projections of obstacles in the sensors’ fields. In order to provide the robot withinformation about the light with respect to the orientation of the chassis (this greatly eased control as the wheels wereconnected to the chassis), the activations of the light sensors were used to compute the activation of four “virtual lightsensors”. The activation of these sensors was computed on the basis of the weighted average of the activation of the twolight sensors closer to the considered virtual sensor, with weights proportional to the angular distance of the latter fromthem (Fig. 4).2.2. The neural controllerEach robot’s controller (Fig. 5) consisted of a neural network with five input neurons directly connected to two outputneurons. The first four input neurons encoded the traction direction on the basis of a cosine function and four different“preferred orientations”. In particular, the activation xi of the input neuron i was computed as follows:(cid:2)xi =cos(ta − tai)(cid:3)+ · tiwhere ta is the traction angle (measured clockwise from the robot chassis’ rear), tai is the preferred orientation of the inputneuron i (set to 0 rad, (1/2)π rad, π rad, and (3/2)π rad respectively for the first, second, third and fourth input neuron),cos(·) is the cosine function, [·]+is the identity function returning 0 for negative values, and ti is the traction intensitynormalised in [0, 1]. The last input neuron, x5, was a bias neuron always activated with one.The activation y j of each of the two output neurons was computed on the basis of the activation of the five inputneurons xi and a sigmoid transfer functions as follows:(cid:4)py j =(w ji · xi)y j = 1/i(cid:5)(cid:6)1 + exp(−py j)where py j is the activation potential of the output neuron j, and exp(·) is the exponential function. The activation of thetwo output neurons was used to set the desired speed of the two robot’s wheels by mapping it onto ±5 rad/s and wasused to set the desired speed of the turret-chassis motor according to the mechanism explained in Section 2.1.The architecture of the neural controller illustrated above was chosen by testing and comparing the performance andevolvability of various feed-forward different neural networks having a variable number of hidden units. Finally, a neuralnetwork with no hidden units was chosen as this had a performance comparable to that of the other neural networks buthad a higher evolvability (i.e. the genetic algorithm optimised its parameters in fewer generations).G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–8758612.3. The genetic algorithmThe connection weights of the neural controllers were evolved with a genetic algorithm [39]. Among the various availablelearning techniques a genetic algorithm was chosen because: (a) supervised-learning algorithms could not be used as thebehaviour of the single robots leading to efficient collective performance was not known a-priori (cf. [54]); (b) reinforcementlearning techniques were difficult to apply due to the high integration of the required collective behaviour and the complexdynamics of the group (cf. [35]); (c) unsupervised learning techniques, based only on self-organising principles (cf. [29]),could not be used as we wanted to have a criterion with which to guide the algorithm to develop specific desired behaviours(such as the fitness of genetic algorithms).The initial population of the genetic algorithm consisted of 100 randomly generated genotypes that encoded the con-nection weights of 100 corresponding neural controllers. Each connection weight was represented in the genotype by eightbits that were transformed into a number within ±10. Each genotype encoded the connection weights of four identicalneural controllers which were used to control a group of four robots linked up to form the swarm-bot shown in Fig. 2. Eachswarm-bot was tested five times (“epochs”), each lasting 150 time steps of 100 ms. The 20 best genotypes of each genera-tion were allowed to reproduce by generating five copies each, with 3% of their bits replaced by a new randomly selectedvalue. The evolutionary process lasted 100 generations. The evolution was replicated 30 times with different seeds of therandom number generator (as a consequence these evolutionary runs started with different random genotype populations).The swarm-bots were selected for the ability to move as fast and as straight as possible. More specifically, the fitness ofeach swarm-bot was computed by first measuring the Euclidean distance between the centre of mass of the swarm-bot atthe beginning and at the end of each one of the five epochs, and then by summing the resulting measures. To normalisethe value of the fitness to one, the total fitness of one swarm-bot over five epochs was divided by the maximum distancetravelled by a single robot moving straight at maximum speed for 750 (= 150 × 5) steps.3. The evolved controllerFig. 6 shows the average fitness and standard error of the best controllers of the 30 runs of the evolution, measuredover 100 epochs. All runs produced controllers that lead the robots to coordinate so as to allow the group to move fastand straight. The rest of the paper focuses on the controller corresponding to seed 30. The weights of this controller arereported in Table 1. This controller was selected as: (a) it had a high performance (its performance was not statisticallydifferent from the controller with the highest performance, corresponding to seed 20, t-test, p = 0.71); (b) it implied aforward movement of the robots (recall that the robots have two possible fronts of motion: using the forward front easedthe analyses); (c) it had a particularly regular shape (see Fig. 7) that eased the regression process and the analysis of thecontroller (see Sections 4 and 5).Fig. 6. Average fitness and standard error, measured over 100 tests, of the best controllers of the 30 runs of the evolution. The white bar corresponds tothe 30th controller, used throughout the paper.Table 1Weights of the neural-network controller emerged in the 30th evolutionary run. The rows indicate the weights corresponding to the two output units ofthe neural network whereas the columns indicate the weights corresponding to the input units (I1, I2, I3, and I4) having a particular preferential tractiondirection (traction from left, front, right and back), and a bias unit (Bias).Left motorRight motorI1Left−10.0008.1250I2Front−1.1718−1.4062I3Right7.5781−8.8281I4Back−5.0781−3.7500Bias6.48435.3906862G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875Fig. 7. The graphs show the commands that the controller corresponding to seed 30 issues to the robots’ left motor (a) and right motor (b) in correspondenceto a traction force having different angles and intensities. The vertical axis indicates the activation of the motor neurons which cause the robot’s speed andwhether its moves straight, turns left or turns right. The schematic little picture represents a chassis and should aid the “visualization” of the direction oftraction with respect to the chassis itself: the white little wheel of the schematic chassis represents the rear of the chassis and corresponds to an angle oftraction of 0measured clockwise.◦The functioning of the evolved controller at the individual and collective level is now briefly described (for more detailssee [7] and [8]). Direct observation of the collective behaviour of robots indicates that: (a) at the beginning of the test theystart to pull/push in different directions, (b) then they orient their chassis in the direction where the majority of the otherrobots are moving, and then (c) they move straight along the direction that emerges from the initial negotiation in finecoordination with the other robots. The absolute direction that emerges from the robots’ negotiation changes in differenttests depending on the initial orientation of the robots, but the robots always converge towards a single direction of motion(see [8], for data).In order to understand how the individual controller produced this behaviour, the activation of its two output unitscorresponding to traction forces having different angles and intensities was measured and plotted (Fig. 7). The analysis of), thethe resulting graphs reveals that the controller works as follows. When the traction comes from the front (about 180robot is oriented toward a direction that is close to the “mean” direction of motion of the other robots. In this situation◦)the robot moves straight. When the traction comes from the left hand side (about 90there is a significant mismatch between the orientation of the robot and the mean orientation of the other robots. In thiscondition the robot turns toward the direction of the traction force, by turning left when the traction comes from the lefthand side and by turning right when the traction comes from the right hand side. The speed of turning is proportional) the robot goes straight at maximumto the intensity of the traction force. When traction comes from the rear (about 0speed independently of the intensity of traction. This might be due to the fact that when the traction comes from the left(rear) represents theor the right hand side the robot has to respectively turn left or right, so the point corresponding to 0separation between the two different turning behaviours. Overall, the individual robot’s behaviour might be characterisedas a conformist tendency to follow the direction of motion of the rest of the group: indeed traction provides an indicationof the average direction of motion of the other robots. At the group level, this tendency rapidly leads the robots to select) or the right hand side (about 270◦◦◦◦G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875863the same direction of motion and to move in a coordinated fashion. Note that these individual and collective behaviourshave the features of a self-organising process [12,14] based on a positive feedback mechanism, likely also characterised by aphase transition phenomenon (see [4,55,56], for details).Notwithstanding this analysis revealed important features of the evolved solution, it did not allow us to fully clarify therole of other characteristics. In particular, it did not allow clarifying the functional role, if any, of the following characteristicsof the evolved controllers: (a) the tendency of the robots to persevere in their direction of motion when the traction comesfrom their rear (“stubbornness”; see Fig. 7); (b) the tendency of the robots to move forward at maximum speed with tractionforces coming from the front (see Fig. 7); (c) the left/right asymmetry of some evolved controllers having high fitness (thisimplied that the effects of traction forces coming from the left or the right and side were different in these controllers,data not shown). As we will see, the method described in Section 4 allowed us to better understand these features of theevolved controllers.4. Mapping evolved neural-controllers into motor schema-based controllersThis section describes how it is possible to re-code the sensory-motor mapping implemented by the evolved neural con-troller into a suitable motor schema-based controller encoded as a multi-variable equation. Motor-schema based controllers[1], initially developed by Khatib [30] in particular in relation to robotic manipulators, are a type of controllers used inbehaviour-based robotics [2,13] in which the control modules responsible for producing different elementary behaviours areexpressed as mathematical equations which generate artificial potential fields capable of guiding robots’ movements. Forexample, in the case of a robot engaged in a navigation task, if graphically visualised with a gradient graph the potentialfield generated by a motor schema-based controller might indicate: (a) the robot’s direction of motion in the various posi-tions in space, e.g. pointing away from obstacles and other robots, and pointing towards a navigation goal; (b) the robot’sspeed related to the distance to such objects. A key aspect of the motor schema-based approach is that it allows generatingbehaviours derived from various sources (e.g. various obstacles, resources, etc.) as a weighted sum of the different potentialfields. An application of this principle will be shown in Section 7.To recode the neural controller into a motor schema-based controller a strategy was followed which should be also ap-plicable to other problems which can be solved with feed-forward neural controllers. The strategy is based on the selectionof a suitable nonlinear mathematical function and the use of a statistical regression technique to estimate its parameterson the basis of data sampled from the input–output mapping of the original neural controller. The selection of the mathe-matical function is the most delicate passage of the procedure. Here this selection was performed by trying to satisfy thefollowing constraints: (a) the function should be mainly formed by summations and multiplications of Gaussian and sigmoidfunctions: this is an important point as these functions allow forming functional bases which on one side are suitable forstatistical regressions (e.g. due to their overall simplicity, symmetry or monotonicity), and on the other side allow buildinguniversal function approximators (see [17], and [40], for the sigmoid and Gaussian bases, respectively); (b) the capacity ofthe built function of approximating the function expressed by the controller of interest (this capacity can be measured bythe residual error of the regression); (c) the presence of parameters that allow manipulating with ease the aspects of in-terest of the behaviour exhibited by the controller (see Sections 5 and 6 for examples of this; in this respect, consider thathaving more parameters than the original controller – as it happened in the example shown here where the approximationfunction has 16 parameters vs. the 10 parameters corresponding to the weights of the original neural controller – mightallow rendering the various aspects of the controller independent between them and hence more easily modifiable). Thesecriteria should allow applying the procedure also to problems different from those reported here to the extent that theyhave a similar level of complexity. The estimation of the function parameters reported below was performed with a LeastMean Square nonlinear regression using the Nonlinear Regression Toolbox of MatlabTM.The parameters’ estimation was based on the input-output vector couples produced by the best evolved neural controllercorresponding to the 30th run of the evolutionary experiment (Table 1). These input-output vector couples were sampledby systematically varying the input pattern of the evolved network and by computing the corresponding output pattern.The input pattern was varied by sampling the angle and intensity of traction over 41 values each. This sampling processproduced two input-output data sets, one for the left motor and one for the right motor, each composed of 41 × 41 = 1681elements. These two data sets are graphically displayed in Fig. 7 and, partially, in Fig. 8a.As a first possible candidate function for the regression, we selected a Gaussian function with one independent variablecorresponding to the angle of traction, multiplied by a three-degree polynomial function with one independent variablecorresponding to the intensity of traction:wds = b7 +b3 exp(cid:7)(cid:7)(cid:8)(cid:8)− (ta − b1)2b2(cid:5)b4 ti + b5 ti2 + b6 ti3(cid:6)(1)where wds, the dependent variable of the function, is the wheel’s desired speed ranging over [−1, 1], ta is the traction angleranging over [0, 1], ti is the traction intensity ranging over [0, 1], b1–b7 are the parameters of the function which wereestimated separately for the left and right wheel. The values of the parameters obtained through the regression for the twowheels are shown in Table 2. The Mean Square Error of the regression for the left and right wheels was respectively 0.0035and 0.0030. The mapping performed by the function on the basis of the tuned parameters is shown in Fig. 8b (compare itwith Fig. 8a relative to the evolved controller).864G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875Fig. 8. The sensory-motor mapping performed by four different controllers: (a) the evolved neural controller; (b) the Gaussian controller; (c) the Sigmoidcontroller; (d) the Rounded Sigmoid controller. Each graph encodes the desired speed of the two motors ( y-axis) for traction forces with different directions(x-axis). Thick and thin lines encode the desired speed of respectively the left and right motor. The 11 curves in each graph correspond to desired speed oftraction with different intensities (from −1 to +1 in intervals of 0.2).G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875Table 2Parameters of the “Gaussian controller” (Eq. (1)) estimated with a Least Mean Square nonlinear regression.LeftRightb10.7230.291b20.0320.034b32.0082.023b40.9620.787b5−4.266−4.192b62.0332.191Table 3Parameters of the “Sigmoid controller” (Eq. (2)) estimated with a Least Mean Square nonlinear regression.LeftRightb10.1180.549b20.0300.025b30.4580.901b40.0220.030b50.6500.627b60.1070.122Table 4Rounded parameters of the “Sigmoid controller” (Eq. (2)) estimated with a Least Mean Square nonlinear regression.LeftRightb10.050.55b20.030.02b30.450.95b40.020.03b50.600.60b60.100.10b71.0991.092b71.001.00865b71.0131.011b81.0051.001b81.001.00Fig. 9. Average performance and standard error measured over 100 trials of robots provided with the evolved neural controller and the three equation-basedcontrollers described in the text.In order to improve the approximation, and to have parameters which allow an independent regulation of the controllers’“stubbornness” and asymmetry, a second function was designed. This was composed by the product of three Sigmoid func-tions, two depending on the traction angle and one depending on the traction intensity:wds = b8 +1(cid:5)(cid:5)− (ta−b1)1 + expb2(cid:6)(cid:6)1(cid:5)(cid:5)+ (ta−b3)1 + expb4(cid:6)(cid:6)−2 b7(cid:5)(cid:5)− (ti−b5)1 + expb6(cid:6)(cid:6)(2)By using this function the Mean Square Error of the regressions for the left and right motor were respectively 0.0004and 0.0007. The mapping performed by the function on the basis of the estimated parameters (see Table 3) is shown inFig. 8c.The estimated parameters of the “Sigmoid function controller” (Table 3) were rounded as reported in Table 4 in order tosimplify their manipulation and the interpretation of the effects of such manipulations on the robots’ behaviour illustratedin the next sections (the important parameters b1 and b3 were rounded in such a way that the “sides” of the two Sigmoidfunctions sensitive to the traction angle were all at a distance of 0.05 from either one of the two critical values of traction; b2 and b4, regulating the pendence of the same twoand 180force’s angle, 0 and 0.5, respectively corresponding to 0−2; the less sensitive parameters b5–b7, regulating the Sigmoid function dependent on tractionfunctions, were rounded to 10−1). Fig. 8d displays the mapping obtainedintensity, and b8, regulating the level of the overall function, were rounded to 10on the basis of the function resulting from these rounding.◦◦Fig. 9 compares the mean and standard error of the performance of the four controllers (i.e. respectively the neural-network controller, the “Gaussian controller”, the “Sigmoid controller”, and the “Rounded Sigmoid controller”) in 100 trialsof the coordinated motion task used to evolve the neural controller. The results show that the evolved neural controlleroutperforms the three equation-based controllers: the difference of performance between the former and each one of thelatters is statistically significant (t-test, p < 0.01 in all cases). This implies that small differences in the sensory-motor866G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875mapping (as mentioned above, the residual errors after the regressions were very low) play a significant role in robots’behaviour.As the Rounded Sigmoid controller had a performance higher than the Sigmoid controller and the Gaussian controller(even if not statistically significant: t-test, p > 0.1 in both statistical comparisons), and moreover, differently from the lattertwo, it had some parameters that allowed changing important aspects of the robots’ behaviour (see next section), it wasused in all experiments presented in the remaining sections of the paper. Section 7 will show the artificial potential fieldgenerated by this controller.5. Manipulating the motor schema-based controller to identify crucial aspects of the evolved controllerThis section describes the results of the manipulations of the Rounded Sigmoid controller developed in the previoussection which were carried out to understand the role played by the various aspects of the mathematical function that itimplements (see Fig. 7). This analysis focused on the aspects of the controller that the experiments described in Section 3suggested to be important with respect to the coordinated behaviour displayed by the whole swarm-bot, namely: con-formism/stubbornness with respect to traction from the rear, reaction to traction from the front, and symmetry/asymmetryof reaction to traction from the left and right hand side.The effects of the manipulation of the controller on the swarm-bot’s behaviour were measured in terms of the averagedistance covered by it in 100 trials (the same measure used in Section 4). The results are summarised in Fig. 10. Thehistogram bar “D” indicates the performance observed by the unmodified Rounded Sigmoid controller. The histogram barsA–E indicate the performance of controllers that have increasing levels (from left to right) of conformism to traction forcescoming from the rear. The level of conformism was regulated by setting the parameters b1 of the left wheel and b3 ofthe right wheel, that establish the reactivity of respectively the left and right motor to traction from the rear, to thecouples of values: {0.20, 0.80}, {0.15, 0.85}, {0.10, 0.90}, {0.05, 0.95}, and {0.00, 1.00} (the effects of these parameters onthe mathematical function implemented by the controller are indicated by the oblique arrows on the graphs reported underthe respective bars in the histogram of Fig. 10). The performance of controllers corresponding to bars A, B, C, and E isstatistically lower when compared to performance of the unchanged Sigmoid, bar D (t-test, p < 0.05 in all cases). Theincrease of performance from controller A to D indicates that increasing levels of conformism with respect to traction forcescoming from the rear improve the capacity of the robots to coordinate quickly: the reason is that the controllers react morereadily to mismatches with respect to the group’s motion. The low performance of controller E (the one with the highestFig. 10. Average performance and standard error over 100 tests of controllers obtained by manipulating the Rounded Sigmoid controller. The functionimplemented by each controller is visually rendered by a small graph vertically below the respective bar of the histogram (same scale and conventions ofFig. 8). The two couples of numbers under each bar indicate the parameters b1–b3 of the left wheel (first couple of numbers) and b1–b3 of the right wheel(second couple of numbers). The black bar (D) refers to the unchanged controller; dark grey bars (A, B, C, E) and light grey bars (F, G) refer to controllersused to study the effects of different levels of subbornness/conformism for traction forces coming from respectively the robots’ rear or front; white bars(H–K) refer to controllers used to study the effects of different levels of asymmetry. Arrows on the small graphs highlight relevant aspects of the functionsimplemented by the controllers (see text).G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875867◦conformism), can be explained by considering that in this case the left wheel erroneously slows down when the tractionorcomes from 350less (see oblique arrows on graph under bar E). These results suggest that our previous interpretations correctly attributeda central role to conformism and that stubbornness for traction forces coming from the rear does not play an importantfunctional role (as it was erroneously suggested in a previous work, [5], before conducting this analysis).or more and, similarly, the right wheel erroneously slows down when the traction comes from 10◦Tests F–G, compared with test D, analyse the effects of manipulations that increase the interval in which robots exhibita tendency to move forward at maximum speed for traction forces coming from the front (see the vertical arrows on thegraphs under the respective bars). These manipulations were performed by setting the parameter b3 of the left wheel and b1of the right wheel to the values {0.35, 0.65} for F and {0.25, 0.75} for G (note that in the case of D such parameters wereset at {0.45, 0.55}). The fact that performance of controller F does not statistically differ from the unchanged controller D(t-test, p = 0.96) indicates that the response to traction forces coming from the front is not as important as the lack ofconformist behaviour for traction forces coming from the rear. Performance is impaired only if such tendency is extendedto an excessively wide range of traction forces coming from the front, as in the case of controller G (its performance isstatistically lower than that of D, t-test, p < 0.05), likely because in this case the capability of the controller to suitablyrespond to traction forces coming from the left or from the right hand side is impaired.Tests H–K were conducted to analyse the effects of asymmetries between the reactions of left and right motors totractions coming respectively from the left and the right hand side of the robots. The controllers of tests H–J were obtainedby changing in various ways the parameter b1 and b3 of the two wheels, with respect to the control condition D, so asto obtain different types of asymmetries (see values directly in Fig. 10; the asymmetries of the controllers with respectto D are indicated by the vertical arrows on the respective lower diagrams). The performance of the three controllerswas not statistically different from the performance of the controller D (t-test, p = 0.92, p = 0.09, p = 0.11, respectively).This indicates that small asymmetries produce little effects on performance. Performance significantly deteriorates (butsurprisingly not so much) only with strong asymmetries such as that of test K: in this case the reactivity of the controllerto traction forces coming from the left hand side of the robot was eliminated altogether.Overall these results explain why the five best-performing neural controllers evolved with different random number-generator seeds (3, 12, 20, 22, and 30, see Fig. 6) vary significantly with respect to the reactivity to traction forces comingfrom the front and with respect to asymmetry, while they all have a high reactivity (conformism) to traction forces comingfrom the left or right hand side (especially near the rear), at least for one of the two motors (data not reported).6. Developing controllers that exhibit new behavioursThis section describes the results obtained by modifying the parameter of the Rounded Sigmoid controller in order todevelop swarm-bots that display new types of behaviours. In particular, these experiments exemplify how new behaviourscan be obtained either through direct modification of the parameters of the hand-coded controller or through an IteratedEvolutionary Computation (IEC) technique (see [46], for a review). The two examples used to illustrate this point, reportedin Sections 6.1 and 6.2, are both related to behaviours based on self-organising mechanisms guiding the whole system.In this respect, the results not only show how the hand-tuned controller might allow developing new potentially usefulbehaviours, but they also indicate that the technique proposed in this paper allows studying self-organising processes incollective robotic systems.IEC is an evolutionary technique in which the selection of the best individuals is not performed automatically, on the ba-sis of a formalised selection criterion, but rather by the experimenter, on the basis of the visual inspection of the behaviourexhibited by the robots. IEC methods have an important advantage with respect to automatic evolutionary procedures con-sisting in the fact that they do not require identifying a detailed “effective selection criterion” (i.e. a fitness function whichmaximises not only final effective solutions of the problems, but also approximate solutions in early stages of the evolution-ary process which represent necessary steps to build the final solutions, cf. [39]). Moreover, by exploiting human ability tojudge behaviours, IEC methods allow evolving behaviour on the basis of abstract selective criteria, such as “displaying inter-esting behaviours” or “display synchronised behaviours”, that are difficult to formalise [23]. On the side of the drawbacks,IEC techniques require the experimenter to evaluate the behaviour of all the produced controllers and so are extremely timeconsuming and in practise can be applied only to problems with limited search spaces, that is involving limited numbers offree parameters.6.1. Synchronised periodic behavioursIn a first experiment we tried to develop swarm-bots able to display synchronised periodic behaviours [45] relying onself-organising principles [4,14,55,56] by varying the evolved solution through an IEC technique. According to Strogatz [45],synchronised periodic behaviours rely on two specific self-organising mechanisms: (a) an intrinsic tendency of the elementscomposing the collective system to generate a periodic behaviour; (b) a tendency of the elements to slow down or toaccelerate the frequency of their periodic behaviour on the basis of phase mismatches. In this respect, we wanted to verifyif it was possible to obtain behaviours relying upon such mechanisms through a IEC procedure directly applied to theRounded Sigmoid controller. The experimental set-up used for this experiment involved 10 robots linked to form a linearstructure.868G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875Fig. 11. (a) Trajectories followed by ten robots assembled to form a linear swarm-bot during a test lasting 300 cycles, when guided by the Rounded Sigmoidcontroller modified through an IEC procedure. Each line corresponds to the trajectory followed by the barycentre of one robot. (b) Synchronisation of theperiodic circling behaviour displayed by the ten robots in the same test: the curves show the sine ( y-axis) of the chassis’ absolute orientation angle of theten robots in 300 time steps (x-axis).Table 5Parameters of the controller obtained with an Interactive Evolutionary Computation technique which lead the robot to exhibit a periodic synchronisedbehaviour at the group level.LeftRightb10.0380.535b20.0400.025b30.4620.924b40.0200.003b50.6180.607b60.0830.085b70.9750.992b80.5410.981The specific IEC technique used here was implemented by first defining the goal of the exercise in an intended genericform (cf. [23]), in our case “trying to obtain a periodic behaviour in a group of assembled robots”, and then by performingmultiple times the following three operations until the obtained behaviours were “satisfactory”: (a) varying the free param-eters of the neural controllers by clicking on a corresponding button of the graphic interface of the simulator; (b) observingthe behaviour displayed by the robots after the variation of the free parameters; (c) deciding whether to retain or discardthe behavioural variant so obtained by suitably clicking either one of two buttons of the graphic interface. The programintroduced the variations of the parameters by adding a random number, drawn with a uniform probability distributionover the interval [−0.05, 0.05], to each parameter of the controller and then by truncating their values, if needed, withinthe range [0.0, 1.0].By following this procedure, it was indeed possible to quickly obtain a new variation of the controller that, once em-bodied in the 10 robots, allowed them to produce a periodic behaviour and to quickly synchronise their movements. Fig. 11illustrates a typical behaviour obtained at the end of this procedure (notice how the individual robots start with differentrandomly assigned orientations). The analysis of the graphs, and the visual inspection of the robots’ behaviour, indicatesthat: (a) at the individual level the controller tends to produce periodic behaviour that consists in producing a circulartrajectory by turning counter-clockwise (Fig. 11a); (b) robots display a conformist tendency which leads each robot to turnwith a larger or smaller orientation variation depending on whether the perceived traction force comes from respectivelythe same or from the opposite direction with respect to the direction of turning: this implies that robots tend to acceler-ate or decelerate their circling behaviour on the basis of the mismatch between their phase and the phase of the rest ofthe group (Fig. 11b); (c) as a result of these accelerations and decelerations, robots rapidly converge into a stable state inwhich their motions are synchronised and in which the intensity of traction forces becomes close to null. Notice how thepoints (a) and (b) indicate that the synchronised periodic behaviour observed at the group level actually relies on the afore-mentioned self-organising mechanisms hypothesised by Strogatz [45] (for other examples and analyses of behaviours basedon self-organising principles, and relevant for collective robotics, see: [4,8,11,27,31,32,43,55,56]). Also notice how these re-sults indicate that the tendency of the robots to modify the frequency of their circling behaviour in order to “catch up” orto “wait for” the rest of the group relies upon the same conformist tendency that was used by evolved robots to displaycoordinated movements along a single direction.G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875869Fig. 12. (a) A swarm-bot deforms its structure and succeeds in exiting a walled arena with four narrow passages. (b) The traces left by a swarm-bot engagedin exiting the arena.The analysis of the parameters of the new controllers, reported in Table 5, suggests that the most important variationof the controller’s parameters with respect to their original values (cf. Table 4), consists in the variation of parameter b8associated with the average speed of the left wheel. This variation is responsible for the intrinsic tendency of the robots toproduce a circling behaviour. Indeed, even if all parameters, with the exception of parameter b8 associated with the averagespeed of the left wheel, were reset to the original values reported in Table 4, the robots still displayed the synchronisedperiodic behaviour.6.2. Coordinated behaviours allowing a swarm-bot to exit from an arenaIn a second experiment, we aimed at improving the swarm-bot’s capability of exiting an arena surrounded by walls andwith narrow ways out, by directly modifying the parameters of the Rounded Sigmoid controller. In this experiment theswarm-bot consisted of eight robots assembled through flexible links into a circular structure (Fig. 2; a “flexible link” wassimulated with two segments, each rigidly connected to a robot, connected between them through a passive hinge jointwith one degree of freedom pivoting on the vertical axis). The environment included four walls which formed a squarearena having four narrow passages located at the four corners. As the width of the passages was smaller than the diameterof the swarm-bot (when it had a regular circular shape), the swarm-bot had to appropriately deform its shape to effectivelyexit the arena (see Fig. 12a).As described in [6], swarm-bots provided with the evolved neural controller described in Sections 2 and 3 display anability to generalise their coordinated motion in situations in which they are connected through flexible links; moreover,they spontaneously exhibit a coordinated obstacle avoidance behaviour as a result of the traction forces produced by thecollisions between the robots’ turrets and obstacles. As a result of the combination of these abilities, plus the spontaneousdeformation of the swarm-bots’ shape caused by the robots’ collisions with walls, the evolved swarm-bot already displayeda good ability to solve the task described above (see Fig. 12b). The swarm-bot maintained these capabilities also when870G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875equipped with the Rounded Sigmoid controller. In particular, the swarm-bot provided with such controller managed to exitthe arena in 33.5% of cases when tested for 200 trials lasting 3000 cycles each.To modify the Rounded Sigmoid controller so as to enhance swarm-bot’s ability to exit from the arena we tried toincrease the level of stubbornness of the controller. The reason of this choice was the hypothesis that a higher level ofstubbornness would have reduced the tendency of the robots to avoid obstacles which in turn would have increased theswarm-bot tendency to deform its shape, as a result of the collision with obstacles, so as to conform its shape to thecharacteristic of the passage and exit the arena more easily.To verify this hypothesis, the test illustrated above was repeated with the Rounded Sigmoid controller where b1 of theleft wheel was set at 0.10 and b3 of the right wheel was set at 0.90. The result of the test confirmed the hypothesis: themodified controller outperformed the baseline controller by exiting the arena 52% of times versus the 33.5% of times of thebaseline (t-test, p < 0.01).This experiment shows how the hand-coded controller allows directly modifying its parameters so as to have a particulardesired behaviour at the group level. This can be done, as it usually happens for hand-coded controllers, because it issometimes possible to have a sufficiently accurate intuition about the causal relationship existing between the parametersof the controller, the behaviour of the single robots, and the behaviour of the whole group.7. Using the motor schema-based controller as a building block in behaviour-based controllersThe Rounded Sigmoid controller developed for coordinated motion tasks could also be used as a building block to designcontrollers capable of solving more complex tasks. To illustrate this more in detail, we considered an experimental set-upwhere a linear swarm-bot formed by four robots assembled to form a linear structure had to coordinate to move in spaceand search and approach a light target. In previous research this behaviour was evolved from scratch ([7]; given that swarm-bots as those used here exhibit spontaneous obstacle avoidance, as illustrated in Section 6, this work used this behaviourto tackle a light searching task in a maze). This section shows how the whole behaviour can be implemented by using amodular architecture formed by two motor schemas, each based on the Rounded Sigmoid controller, producing respectivelya coordinated motion behaviour and a coordinated light pursuing behaviour.The first motor schema, capable of performing coordinated motion, was implemented by using the unmodified RoundedSigmoid controller described in Section 4. The second motor schema, capable of performing coordinate light-pursuing, wasimplemented by using a copy of the same Rounded Sigmoid controller that took as input the direction and intensity of thelight (encoded as illustrated in Section 2.1) instead of the direction and intensity of the traction force. The reason why theRounded Sigmoid controller, suitable for producing a coordinated motion behaviour, could be re-used to produce a lightpursuing behaviour is that both behaviours represent a form of taxis, that is behaviours that drive the robots toward acertain direction on the horizontal plane.The arbitration between the two motor schemas of the controller was accomplished by averaging the output producedby them. This is a typical solution adopted for motor schema-based controllers (cf. [1,2]; note that other solutions havebeen proposed within the behaviour-based robotics literature, such as the hierarchical arbitration mechanism used in thepopular subsumption architecture, [13]). Interestingly, a sort of averaging arbitration mechanism also emerged in the neuralcontrollers evolved from scratch (cf. [7]).Visual inspection of the behaviour exhibited by robots provided with this modular controller indicates that when robotsdo not perceive the light, they display a smooth coordinated motion behaviour. As soon as robots start to detect the light,that is as soon as the distance between them and the light is below 400 cm and they are not shadowed by other robots,they starts moving toward the direction of the light. This motion generates traction forces that are detected by the otherrobots of the group (in particular by those in shadow) so that they turn accordingly and the whole group ends up movingtoward the light in a finely coordinated fashion.In order to quantify the performance of this behaviour, the new motor schema-based controller was tested with andwithout the light target, and the results obtained by robots provided with the double motor schema-based controller werecompared with those obtained with neural controllers evolved from scratch (data from [7]). As shown in Fig. 13, in bothtests the performance of the double motor schema-based controller is rather good but lower than the performance displayedby the evolved neural controller (t-tests, p < 0.01).To analyse the role of each of the two motor schema controllers and to understand how the average of their output couldproduce an effective behaviour, we plotted the potential gradient fields generated by the coordinated motion schema-basedcontroller alone (Fig. 14a), the coordinated light-pursuing schema-based controller alone (Fig. 14b), and by the combinationof the two schema-based controllers arbitrated by averaging their output patterns (Fig. 14c). As specified above, the twoschema-based controllers were implemented by using two Rounded Sigmoid controllers which respectively received asinput the direction and the intensity of traction and the direction and intensity of light.Concerning the coordinated motion controller Fig. 14a shows the motor reactions produced by the controller for tractionforces with different intensities and directions. Each arrow of the graph represents the controller reaction to a certainintensity and direction of traction. In particular, a certain intensity of traction is proportional to the closeness of the positionof the arrow to the centre of the graph, whereas the direction of traction is represented by direction going from the arrowposition to such centre. The length and the orientation of each arrow represent, respectively, the change of position and thechange of orientation of the robot that is produced by setting the desired speed of its two wheels (for 0.75 s) to the valuesG. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875871Fig. 13. Performance ( y-axis) of the evolved neural-network controller (light grey bars) and of the double motor schema-based controller (dark grey bars)in a coordinated motion test (“Movement”) and in a light approaching test (“Light”). Each histogram bar reports the average performance and the standarderror of the controllers obtained in 100 trials. The data relative to the evolved neural controllers are those produced by the experiments described in detailin [7].produced by the controller with the intensity and direction of traction corresponding to the arrow position. This analysisconfirms that, as indicated in Section 3, when traction comes from the robot’s front or rear, or when its intensity is low,the robot tends to move straight. On the contrary, when traction comes from either the robot’s left or right hand side, andthe intensity of the traction is significant, the robot tends to turn toward the direction of the traction (by consequently alsoreducing the extent of the displacement).In relation to the coordinated light-pursuing behaviour, Fig. 14b shows the reactions produced by the controller fordifferent sensory states corresponding to different orientations and distances of the light target. The distance (which wasvaried within the range of [0, 141] cm) of the light target is represented by the distance of the arrow position from thecentre of the north-wall side of the graph, whereas the direction of the light target is represented by the direction goingfrom the arrow position to such centre. Analogously to what done for the previous graph, the reaction of the controlleris indicated by the length and the orientation of the arrows. These represent, respectively, the change of position and thechange of orientation of the robot produced in 0.75 s by setting the desired speed of the two wheels to the value producedby the controller with a light position and distance corresponding to the arrow position. The graph show that a robot movesfast towards the light when this is located in front of it, whereas it turns toward the light when this is located on its left orright hand side.Finally, with regards to the overall controller, Fig. 14c shows the average of the output patterns produced by the twobehaviours for different direction and intensities of the traction (represented, as in the case of Fig. 14a, with respect to atraction coming from the centre of the graph) and different orientations and distances of the light target (imagined to bepositioned, as in the case of Fig. 14a, at the centre of the north side of the graph). The graph shows how the tendencyto navigate towards the light target and the tendency to align with the rest of the group are smoothly integrated in theresulting potential field. For example, in the outer portions of the graph, which correspond to a situation in which the robotis rather aligned with the rest of the group (signalled by a low traction intensity), the reaction of the robot mainly take intoaccount the direction of the light. Conversely, in the central part of the graph, which corresponds to situations in whichthere is a significant mismatch between the orientation of the robot and that of the rest of the group (signalled by a hightraction intensity), the robot mainly responds to the direction of traction. Interestingly, in situations in which there is apotential conflict between the direction of the light and the direction of the group’s motion (corresponding to top-centralpart of the graph) the potential field resulting from the average of the outputs of the two controllers does not lead to fixedpoint or limit-cycle behaviours which could prevent the accomplishment of the task (these are typical problems which canarise when different schema-based controllers are combined, [24]).To summarise, the results shown in this section demonstrate how evolved controllers can be exploited as templates fordesigning hand-coded controllers within the framework of the motor schema-based approach so as to solve new problemswithout the need to re-evolve solutions from scratch.8. The path to implementation in real robotsThe arguments presented in the paper rely on experiments carried out on simulated swarm-bots. The reason for usingsimulations in this work resided primarily in its peculiarly theoretical and methodological aims. In previous works, theevolved controller capable of performing coordinated motion was successfully tested in hardware in a wide variety ofconditions [9]. These tests demonstrated the robustness of the controller evolved in simulation by showing how it waspossible to transfer it to real robots with full success without the need of any modification. The strength of the coremechanisms underlying the coordinated motion controller presented here were also tested in other real robotic set-ups872G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875Fig. 14. Potential fields generated by different motor schemas built on the basis of the Rounded Sigmoid controller. (a) Motor schema able to produce groupcoordination behaviours. (b) Motor schema able to produce light approaching behaviours. (c) Controller formed by the two motor schemas shown in graphs“a” and “b” arbitrated by averaging their output patterns.that used them as “building-blocks” for evolving more complex behaviours (e.g., [48]). Finally, the flexibility of the reals-bot developed within the project SWARM-BOTS was also tested with hand-coded controllers (e.g., [26]). The work thatled to this wide spectrum of results (cf. the web site of the project for other references of works carried out with reals-bots: http://www.swarm-bots.org/) on one side indicated the importance of expanding the theoretical understanding ofG. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875873the evolved controllers through new methods of analysis (like those described here) and, on the other side, suggested tocarry out a close comparison of evolved controllers with hand-coded ones.9. Discussion and conclusionsAt the current state of the art, self-organising methods, such as those proposed within the evolutionary robotics litera-ture, and direct design methods, such as behaviour-based robotics, have both strengths and weaknesses. A major strengthof self-organising methods, as shown in this paper, is the ability to discover effective solutions that exploit properties of thesystem that can hardly be identified by a human designer. With this respect, the experiment described in Section 3 showshow evolving robots were able to discover a simple strategy that allows a group of physically assembled robots to produce avery efficient coordinate motion behaviour. Some fine details of the found solution were hard to identify. This was demon-strated by the fact that the hand-coded controllers, obtained by approximating the sensory-motor mapping produced byevolved neural controllers with a suitable statistical procedure, produced a performance lower than the performance of thelatter ones (see Sections 5 and 7), even if the residual error of the regression was very low (see Section 4). In general, thereason why self-organising methods such as those used by evolutionary robotics can generate solutions that are difficult toimagine for an human designer is that, through random variation and selection, they can discover and capitalise on usefulproperties emerging from the complex fine-grained interactions between the robots and their environment, including thesocial environment formed by other robots [23,38,39]. The main weakness of self-organising methods is that they do notguarantee that a given problem will be actually solved even if an effective solution exists. In fact, to be successful evolution-ary methods not only require that an effective solution of the problem exists, but also that a chain of intermediate adaptivesolutions, that represent crucial steps toward the final solution, can be discovered through progressive variations [39].The main strength of hand-coded controllers reside in the fact that, by being easier to understand from the point ofview of the experimenter and by usually presenting a strong modular organisation, they can be directly programmed,modified and combined to produce new controllers, or new variations of existing controllers, in an incremental fashion.Hence, in general, hand-coded controllers can be more easily scaled to increasing complex tasks. On the other side, themain weakness of hand-coded controllers resides in the difficulty of identifying the “micro rules” that should regulate thefine-grained interaction between the robot and the environment that can lead to the desired behaviour.This paper proposed a method for combining the strengths of self-organising methods and direct design methods. Inparticular it showed how effective solutions discovered through an evolutionary technique can be re-coded in equation-based controllers, such as motor schema-based controllers, that can be later manipulated and combined to produce newbehaviours. In this respect, as demonstrated in Section 4, equation-based controllers functionally analogous to evolved feed-forward neural controllers can be obtained by: (a) identifying a function which approximates the general characteristicsof the mapping performed by the evolved neural controller; (b) approximating the function parameters through nonlinearregression methods. The recoding of the neural controllers in equation-based controllers can produce a loss of performance.However, as we have shown, the process of recoding can favour the identification of crucial parameters that can be latervaried to analyse the characteristics of the evolved solution and to develop new controllers able to produce new forms ofbehaviour. With respect to the last point, Section 6 and 7 showed how it is possible to obtain new variations of evolvedbehaviours, and completely new behaviours, by varying the parameters of the equation-based controllers or by combiningdifferent equation-based controllers.The parameters of the equation-based controllers can be varied either manually (Section 6.2), after their functionalrole has been identified (Section 5), or through semi-automatic techniques based on interactive evolutionary computationalgorithms (Section 6.1). In the latter case the parameters are varied randomly but variations are retained or discarded onthe basis of their effects evaluated by visually inspecting the resulting behaviours. In both cases, the identification of fewcrucial parameters is essential to keep the search space within a reasonable size.Finally, as shown in Section 7, equation-based controllers which approximate evolved solutions can be fruitfully usedas building blocks and combined to solve problems that require different related abilities (e.g., coordinated motion andcoordinated light approaching).The proposed method should have, at least in principle, a general validity and could therefore be applied successfully todifferent robotic set-ups and to problems different from those studied in the present paper, at least in the cases in whichthe evolved neural controllers consist of feed-forward neural architectures.To the best of the authors knowledge, this paper presents the first work which explicitly combines evolutionary synthesisapproaches with human design or “guidance” (as done in IEC techniques) not only at the level of fine-grained solutions butalso at the level of the whole robot control architecture.AcknowledgementsThis research has been supported by the “SWARM-BOTS” and “SWARMANOID” projects funded by the Future and Emerg-ing Technologies program (IST-FET) of the European Commission under grants IST-2000-31010 and IST-022888, respectively.References[1] R.C. Arkin, Motor schema based mobile robot navigation, International Journal of Robotics Research 8 (1989) 92–112.874G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875[2] R.C. Arkin, Behaviour-Based Robotics, MIT Press, Cambridge, MA, 1998.[3] T. Balch, R.C. Arkin, Behavior-based formation control for multirobot teams, IEEE Transactions on Robotics and Automation 14 (6) (1998) 926–939.[4] G. Baldassarre, Self-organization as phase transition in decentralized groups of robots: A study based on Boltzmann entropy, in: M. Prokopenko (Ed.),Advances in Applied Self-Organizing Systems, Springer-Verlag, Berlin, 2008, pp. 127–146.[5] G. Baldassarre, S. Nolfi, D. Parisi, Evolution of collective behaviour in a group of physically linked robots, in: G. Raidl, A. Guillot, J.-A. Meyer (Eds.),Applications of Evolutionary Computing – Proceedings of the Second European Workshop on Evolutionary Robotics, Springer Verlag, Berlin, 2003,pp. 581–592.[6] G. Baldassarre, S. Nolfi, D. Parisi, Evolving mobile robots able to display collective behavior, Artificial Life 9 (2003) 255–267.[7] G. Baldassarre, D. Parisi, S. Nolfi, Coordination and behaviour integration in cooperating simulated robots, in: S. Schaal, A. Ijspeert, A. Billard, S. Vi-jayakumar, J. Hallam, J.-A. Meyer (Eds.), From Animals to Animats 8: Proceedings of the 8th International Conference on Simulation of AdaptiveBehavior, MIT Press, Cambridge, MA, 2004, pp. 385–394.[8] G. Baldassarre, D. Parisi, S. Nolfi, Distributed coordination of simulated robots based on self-organization, Artificial Life 12 (3) (2006) 289–311.[9] G. Baldassarre, V. Trianni, M. Bonani, F. Mondada, M. Dorigo, S. Nolfi, Self-organised coordinated motion in groups of physically connected robots, IEEETransactions in Systems, Man and Cybernetics – Part B Cybernetics 37 (1) (2007) 224–239.[10] T.D. Barfoot, C.M. Clark, Motion planning for formations of mobile robots, Journal of Robotics and Autonomous Systems 46 (2004) 65–78.[11] R. Beckers, O. Holland, J.-L. Deneubourg, From local actions to global tasks: Stigmergy and collective robotics, in: R.A. Brooks, P. Maes (Eds.), Proceedingsof the 4th International Workshop on the Synthesis and Simulation of Living Systems (ALife IV), MIT Press, Cambridge, MA, 1994, pp. 181–189.[12] E. Bonabeau, M. Dorigo, G. Theraulaz, Swarm Intelligence: From Natural to Artificial System, Oxford University Press, Oxford, 1999.[13] R.A. Brooks, A robust layered control system for a mobile robot, Journal of Robotics and Automation 2 (1986) 14–23.[14] S. Camazine, J.L. Deneubourg, N.R. Franks, J. Sneyd, G. Theraulaz, E. Bonabeau, Self-Organization in Biological Systems, Princeton University Press,Princeton, NJ, 2001.[15] Y.U. Cao, A.S. Fukunaga, A.B. Kahng, Cooperative mobile robotics: Antecedents and directions, Autonomous Robots 4 (1997) 1–23.[16] D. Cliff, I. Harvey, P. Husbands, Explorations in evolutionary robotics, Adaptive Behavior 2 (1993) 73–110.[17] G. Cybenko, Approximation by superposition of sigmoidal functions, Mathematics of Control, Signals, and Systems 2 (1989) 303–314.[18] J.P. Desai, J.P. Ostrowski, V. Kumar, Modeling and control of formations of nonholonomic mobile robots, IEEE Transactions on Robotics and Automa-tion 17 (6) (2001) 905–908.[19] M. Dorigo, E. Sahin, Swarm robotics – Special issue editorial, Autonomous Robots 17 (2–3) (2004) 111–113.[20] M. Dorigo, V. Trianni, E. Sahin, R. Groß, T.H. Labella, G. Baldassarre, S. Nolfi, J.-L. Deneubourg, F. Mondada, D. Floreano, L.M. Gambardella, Evolvingself-organizing behaviors for a swarm-bot, Autonomous Robots 17 (2–3) (2004) 223–245.[21] G. Dudek, M. Jenkin, E. Milios, A taxonomy of multirobot systems, in: T. Balch, L.E. Parker (Eds.), Robot Teams: From Diversity to Polymorphism,A K Peters Ltd., Wellesley, MA, 2002.[22] J. Fredslund, M.J. Mataric, A general algorithm for robot formations using local sensing and minimal communication, IEEE Transactions on Robotics andAutomation 18 (5) (2002) 837–846.[23] P. Funes, B. Orme, E. Bonabeau, Shaping collective behavior: An exploratory design approach, in: J. Pollack, M. Bedau, P. Husbands, T. Ikegami, R. Watson(Eds.), Artificial Life IX: Proceedings of the Ninth International Conference on the Simulation and Synthesis of Living Systems, MIT Press, Cambridge,MA, 2004, pp. 232–237.[24] S. Ge, Y. Cui, Dynamic motion planning for mobile robots using potential field method, Autonomous Robots 13 (2002) 207–222.[25] R. Grabowski, L.E. Navarro-Serment, P.K. Khosla, An army of small robots, Scientific American (November 2003) 42–47.[26] R. Groß, M. Bonani, F. Mondada, M. Dorigo, Autonomous self-assembly in mobile robotics, in: K. Murase, K. Sekiyama, N. Kubota, T. Naniwa, J. Sitte(Eds.), Proceedings of the Third International Symposium on Autonomous Minirobots for Research and Edutainment, Springer Verlag, Berlin, 2006,pp. 314–322.[27] O. Holland, C. Melhuish, Stigmergy, self-organization, and sorting in collective robotics, Artificial Life 5 (2) (1999) 173–202.[28] A.J. Ijspeert, A. Martinoli, A. Billard, L.M. Gambardella, Collaboration through the exploitation of local interactions in autonomous collective robotics:The stick pulling experiment, Autonomous Robots 11 (2001) 149–171.[29] J.A. Janet, R. Gutierrez, T.A. Chase, Mark W. White, J.C. Sutton, Autonomous mobile robot global self-localization using Kohonen and region-featureneural networks, Journal of Robotic Systems 14 (4) (1997) 263–282.[30] O. Khatib, Real-time obstacle avoidance for manipulators and mobile robots, The International Journal of Robotics Research 5 (1) (1986) 90–98.[31] M.J.B. Krieger, J.-B. Billeter, L. Keller, Ant-like task allocation and recruitment in cooperative robots, Nature 406 (2000) 992–995.[32] C.R. Kube, H. Zhang, Collective robotics: From social insects to robots, Adaptive Behavior 2 (2) (1993) 189–219.[33] R.C. Kube, E. Bonabeau, Cooperative transport by ants and robots, Robotics and Autonomous Systems 30 (1998) 85–101.[34] A. Martinoli, Swarm intelligence in autonomous collective robotics: From tools to the analysis and synthesis of distributed control strategies, Ph.D.dissertation. Computer Science Department, Lausanne, Ecole Polytechnique Fédérale de Lausanne, 1999.[35] M.J. Matari ´c, Reinforcement learning in the multi-robot domain, Autonomous Robots 4 (1) (1997) 73–83.[36] O. Miglino, H.H. Lund, S. Nolfi, Evolving mobile robots in simulated and real environments, Artificial Life 4 (1995) 417–434.[37] F. Mondada, G.C. Pettinaro, A. Guignard, I.V. Kwee, D. Floreano, J.-L. Deneubourg, S. Nolfi, L.M. Gambardella, M. Dorigo, SWARM-BOT: A new distributedrobotic concept, Autonomous Robots 17 (2–3) (2004) 193–221.[38] S. Nolfi, Behaviour as a complex adaptive system: On the role of self-organization in the development of individual and collective behaviour, Com-plexUs 2 (3–4) (2006) 195–203.[39] S. Nolfi, D. Floreano, Evolutionary Robotics: The Biology, Intelligence, and Technology of Self-Organizing Machines, MIT Press, Cambridge, MA, 2000.[40] J. Park, I. Sandberg, Universal approximation using radial-basis-function networks, Neural Computation 3 (1991) 246–257.[41] M. Quinn, L. Smith, G. Mayley, P. Husband, Evolving teamwork and role allocation with real robots, in: R.K. Standish, M.A. Bedau, H.A. Abbass (Eds.),Proceedings of the 8th International Conference on Artificial Life, MIT Press, Cambridge, MA, 2002, pp. 302–311.[42] M. Quinn, L. Smith, G. Mayley, P. Husbands, Evolving controllers for a homogeneous system of physical robots: Structured cooperation with minimalsensors, Philosophical Transactions of the Royal Society of London, Series A 361 (2003) 2321–2344.[43] C.W. Reynolds, Flocks, herds, and schools: A distributed behavioral model, Computer Graphics 21 (4) (1987) 25–34.[44] L. Spector, J. Klein, C. Perry, M. Feinstein, Emergence of collective behavior in evolving populations of flying agents, Genetic Programming and EvolvableMachines 6 (1) (2005) 111–125.[45] S. Strogatz, Sync: The Emerging Science of Spontaneous Order, Hyperion, New York, 2003.[46] H. Takagi, Interactive evolutionary computation: Fusion of the capabilities of EC optimization and human evaluation, Proceedings of the IEEE 89 (2001)1275–1296.[47] V. Trianni, C. Ampatzis, A.L. Christensen, E. Tuci, M. Dorigo, S. Nolfi, From solitary to collective behaviours: Decision making and cooperation, in:F. Almeida e Costa, M. Rocha Luis, E. Costa, I. Harvey, A. Coutinho (Eds.), Proceedings of the 9th European Conference on Artificial Life (ECAL 2007),Springer Verlag, Berlin, 2007, pp. 575–584.[48] V. Trianni, M. Dorigo, Self-organisation and communication in groups of simulated and physical robots, Biological Cybernetics 95 (2006) 213–231.G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875875[49] E. Tuci, R. Groß, V. Trianni, F. Mondada, M. Bonani, M. Dorigo, Cooperation through self-assembling in multi-robot systems, ACM Transactions onAutonomous and Adaptive Systems 1 (2) (2006) 115–150.[50] L. Tummolini, M. Mirolli, C. Castelfranchi, Stigmergic cues and their uses in coordination: An evolutionary approach, in: A.M. Uhrmacher, D. Weyns(Eds.), Agents, Simulations and Applications, Taylor & Fransis, London, in press.[51] P.K.C. Wang, Navigation strategies for multiple autonomous mobile robots moving in formation, Journal of Robotic Systems 8 (2) (1991) 177–195.[52] Z.D. Wang, E. Nakano, T. Takahashi, Solving function distribution and behavior design problem for cooperative object handling by multiple mobilerobots, IEEE Transactions on Systems, Man and Cybernetics – Part A 33 (5) (2003) 537–549.[53] C.R. Ward, F. Gobet, G. Kendall, Evolving collective behavior in an artificial ecology, Artificial Life 7 (1) (2001) 191–209.[54] Y. Yamashita, J. Tani, Emergence of functional hierarchy in a multiple timescale neural network model: A humanoid robot experiment, PLoS Computa-tional Biology 4 (11) (2008).[55] G. Baldassarre, D. Parisi, S. Nolfi, Measuring coordination as entropy decrease in groups of linked simulated robots, in: A. Minai, Y. Bar-Yam (Eds.),Proceedings of the Fifth International Conference on Complex Systems (ICCS2004), May 16–21 2004, Boston, MA, The New England Complex SystemsInstitute, Cambridge, MA, 2004, Published online at http://www.necsi.org/events/iccs/2004proceedings.html.[56] A.E. Turgut, C. Huepe, H. Çelikkanat, F. Gökçe, E. Sahin, Modeling phase transition in self-organised flocks, in: M. Dorigo, M. Birattari, C. Blum, M. Clerc,T. Stützle, A.F.T. Winfield (Eds.), Proceedings of the 6th International Conference on Ant Colony Optimization and Swarm Intelligence (ANTS 2008), in:LNCS, vol. 5217, Springer-Verlag, Berlin, 2008, pp. 108–119.