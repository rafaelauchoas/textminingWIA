ELSEVI ER Artificial Intelligence 96 (1997) 395-419 Artificial Intelligence Tail uncertainty analysis in complex systems Enrique Castillo * , Cristina Solares, Patricia G6mez Department of Applied Mathematics and Computational Sciences, Universiry of Cantabria, 39005 Santandes Spain Received March 1996; revised May 1997 Abstract The paper presents an efficient computational method for estimating the tails of a target vari- able Z which is related to other set of bounded variables X = (Xi,. . . , X,) by an increasing relation Z = h( XI, . . . , X,). To this aim, variables Xi, i = 1,. . . , n are sequentially (decreasing) is guaranteed to be in the tail simulated in such a manner that Z = h( xi, . . . , xi-i, Xi, . . . ,X,) of Z. The: method is shown to be very useful to perform an uncertainty analysis of Bayesian networks, when very large confidence intervals for the marginal/conditional probabilities are re- quired, as in reliability or risk analysis. The method is shown to behave best when all scores coincide and is illustrated with several examples, including two examples of application to real cases. A comparison with the fast probability integration method, the best known method to date for solving this problem, shows that it gives better approximations. @ 1997 Elsevier Science B.V. Keywords: IBounded variables; Fast probability integration method; Likelihood weighing; Monotonic transformation; Tail simulation; Uncertainty analysis 1. Introduction Consid.er the pressure tank in Fig. 1. It is a tank for storage of a pressurized fluid, is introduced with the help of a pump activated by an electric motor. The tank for periods of less than one the electric if a the it after the activation of relay, F; and relay which is known not to have problems minute. Therefore, a security mechanism, based on a time relay, F, interrupts current after 60 seconds. the pressure switch, E, which initiates current after the initiation the operation of the system; one relay, D, which supplies step and interrupts the current threshold value, The system also includes In addition, a pressure switch, A, also interrupts in the tank reaches a certain if the pump is working * Corresponding author. Email: castie@ccaix3.unican.es. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. HI sooo4-3702(97)00052-0 396 E. Castillo et al./Art$cial Intelligence 96 (1997) 395-419 Fig. 1. Pressure tank diagram. C, which starts the operation of the electrical circuit of the motor. Assume interested of failure of the pressure the probability in knowing tank. that we are As shown in Section 7.2, using the techniques of fault tree analysis, the probability of failure of the tank can be approximated by P(K=l)~:l+x2_xlx;!+X3X4+X3Xg+X3X6, (1) where xi,... , X.5 are the probabilities of failure of its components. When there are common causes of failure, fault trees become fault networks and then, to avoid replication of nodes. Bayesian Bayesian network models are more convenient networks are introduced in Section 2. With common causes of failure, the probability of failure of the tank can be approxi- mated by P(K = 1) M Xi +0.5X2 - 0.5xiX2 +X3X4 + 2.5X2X5 + 0.25X3X6. (2) The preceding models ( 1) and (2) assume that the values of the probabilities . .> are known constant values. Thus, once these probabilities are known one the probability of failure using expressions ( 1) or (2). analysis, in uncertainty these probabilities its associated density too. Thus, In some cases, as in reliability ables (not known with certainty), variable tervals. high confidence this paper we deal with a more general problem which consists of estimating of a random variable which is related to other basic variables by a monotone We assume to be random vari- are assumed and then the probability of failure becomes a random in- or risk analysis of nuclear power plants, very In the tail relation. is not that the cumulative distribution (cdf) of the target variable to obtain confidence are required, which of their tails. the estimation is needed intervals function function implies (x1,x2,. can calculate However, E. Castillo et al./Artifcial Intelligence 96 (1997) 395-419 397 directly available but determined Bayesian Networks the target variable to solve through the basic variables. Note that in the case of is a marginal or conditional probability. cumulative they are related as an approximation The usual procedure technique distribution a large sample and using the above problem is a very well known is based on Monte Carlo simula- technique which allows dealing to other random variables by a complex the to the exact one. The but in the tails, in the central part of the distribution, consists of simulating function tion. Monte Carlo simulation with random variables when relation. The common empirical method performs well when we are interested gives very poor approximations when the aim of the analysis as, for example, design only the engineer tudes magnitud.es, because has motivated and several papers dealing with the estimation of large percentiles example, (temperatures, winds, waves, earthquakes, they produce the estimation tails are important interested is only structural, of extreme value of small or large percentiles. However, and one has to deal with extreme percentiles. In fact, in the occurrences of either very large values of magni- etc.) or very low values of the same problems. This [ lo] or [ 41) (see, for supply or environmental the appearance is concentrated in Engineering in particular in general [ 14,191). theory (see Several simulation methods have been proposed as: stochastic for simulating [ 131, likelihood weighing simulation networks, random and stochastic simulation [ 71, stratified sampling samples in [ 171, hybrid [ 2,6]. Bayesian methods of logic sampling However! these methods have not been designed to solve the tail estimation problem. We note here that estimation of extreme percentiles the simulation method if we can control we present a method which allows simulating null proportion of rejections. This means belongs to the desired tail. things are completely different. is difficult from real samples but In this paper the tails of the target variable with a sample in the simulated that each data point A very good alternative to simulation It appeared in the field of structural been expanded by Hasofer and Lind is the fast probability reliability with Freudenthal [ 121, Rackwitz and Flessler integration [9] [ 1.51, and Breitung The main idea of the FPI method consists of approximating multidimensional by known variables. Thus, eliminating integrals, associated with standardized and independent multinomial the need to perform a numerical integration. The Fl?I method has shown to give precise results and has demonstrated (FPI) method. in 1956, and has [ 31. integrals random to be much for estimating extreme percentiles than Monte Carlo simulation techniques more efficient (see, for example, [ 11,181). Since the FPI is considered to be the best known method, to date, it will be used here for the sake of comparison with the proposed method. as follows. to understand The paper is structured are necessary scription of the proposed method, which is illustrated several cases of monotone obtained with the FPI method. An improvement lation procedures with equal scores, is illustrated method for its application tions of the proposed method In Section 2 we give some basic concepts which the rest of the paper. In Section 3 we give a detailed de- to functions. Estimates are compared with exact values and those of this method, obtained by using simu- in Section 5. In Section 6 we adapt the to Bayesian networks, and in Section 7 we present two applica- to real examples. Finally, Section 8 gives some conclusions. in Section 4 by its application 398 E. Castillo et al./Artijcial Intelligence 96 (1997) 395-419 2. Some required background In this section we introduce some basic concepts to be used later. 2.1. Bayesian networks Let X = {X1,X2,... , Xn} be a set of n discrete variables, , r-t}. A Bayesian network over X is a pair (D, P), where {O,l,... directed acyclic graph (DAG) over X and P = {PI (XI 1 TI ) , . . . , P,, (x, 1 rn)} of n conditional probabilities, node Xi. The joint probability in the set the graph D is a is a set one for each variable, where ZTi is the set of parents of density of X can be written as: taking values P(Xl,X:!,... ,&I = fpicxi I nTi). i=l If we denote Oijr = Pi(Xi =j 1 ni =T), j E (0,. . . , ri}, (4) instantiation of the parents of Xi. The joint probability density where T is any possible (3) can be considered Castillo, Gutierrez as a B-parametric family. and Hadi [ .5,6] have shown probabilities conditional with known values e. are polynomials the &parameters which are first degree monotone functions of the parameters. P( Xi = j 1 E = e), where E is a set of evidential that the marginal P( Xi = j), and nodes of that they are respectively and quotients of polynomials, in each parameter. This implies 2.2. A general simulation framework Next, we illustrate a general simulation scheme which is sustained by the following theorem (see [16], [8] or [l]). Theorem 1 (Rejection method). ability density pB( x). Suppose that h(x) Let X be a k-dimensional random vector with prob- can be represented in the form pB(x) = cg(x)Ps(x), (3 where c > 1, 0 < g(x) < 1, and Ps( x) is a probability density function (pdfi. Let U be a standani uniform U(0, 1) random variable and let Y be a random variable with independent of U. It follows that the conditional distribution of Y given that pdf Ps(y) U < g(Y) coincides with the distribution of X. leads to the rejection method which consists of the following This theorem 0 Step 1: Simulate Y using Ps (y). l Step 2: Draw a random uniform U(0, 1) number U. l Step 3: If U < g(Y) use Y as a random number from pB (x) ; otherwise, steps: repeat the process from Step 1. E. Castillo et al./Artijcial Intelligence 96 (1997) 395-419 399 Table 1 Sampling distribution, and generation and scoring methods associated with some of the four most important simulation methods: (AR: Acceptance-Rejection, US: Uniform sampling, LW: Likelihood weighing, and MS: Markov sampling) Method Sampling distribution Ps (xi) Generation ordering Score Etvidential node Non-evidential node PC& I nil l/Cd(Xi) S(Xi I Hi) ancestral mY ancestral P(Xi I ni)nij,,Pe(xj I nj) aY 1 or0 ny!, P(Xi I fli) l-I&EPe(ei 1 I Hi) AR us LW MS I’(& I nil J’o(xi) h(xi) &t-G) Q. (5) suggests the following modification of the rejection sampling method: Instead to g(Y) or cg( Y) (the score) to get a probability. This leads to a much higher efficiency is rejected. The price we need to pay is of rejecting a sample, we give it a probability proportional and at the: end we normalize process, because no sample of the simulation that we have to calculate and store the scores. is the sampling distribution Note that Ps (x) Of a special interest is the case in which the joint probability density and cg( x) = Pa (x) /Ps( x) is the score. (pdf) function f(x1,. conditional * * ,x,)isknownthroughaset{f(x~),f(xzIx~),...,f(x,Ix~,...,x,_~)}of as in the case of Bayesian networks. probabilities, In known simulation methods for Bayesian networks, be written as the product of the sampling distributions the sampling distribution of node Xi, then PS(X) = fiPS(Xi). i=l The real joint probability can be written as the sampling distribution can of the nodes. So, let Ps (xi) be i=l If some: of these factors coincide, they cancel in the score expression b(x) w=‘pso= ’ pB(xi 1 ri> II pS(xi) i=l Sampling algorithms for Bayesian networks consist of the following three compo- nents: ( 1) A sampling distribution, (2) An instantiation (3) A scoring method. generation method, and All the existing methods show differences the sampling distribution, in one of these three elements. Table 1 shows the generation method and the scoring methods associated with (6) (7) (8) 400 E. Castillo et al./Art#cial Intelligence 96 (1997) 395-419 four of the most important given in the Introduction), simulation methods where (see [ 6, Chapter 93, or the references PO(&) = 1 if xi = ei, 0 otherwise, Ci is the set of sons of Xi, Pe( ) means P( ) with all evidential nodes their corresponding of Xi and E is the set of evidential nodes. evidential values ei, card(Xi) is the cardinal instantiated to (number of elements) 3. The proposed method The main idea of the proposed methods consists of simulating only the tail of the target random variable Z related variable. Assume to a set X = {Xi, . . . , X”} of basic random variables by an increasing relation. , that is, we have a bounded that Z = h(X) (decreasing) Note that if h(X) is decreasing, we can work with -Z that 00 < ai < Xi < bi < 00. Then, h(a) < Z < h(b), lower and upper bounds of Z, respectively. instead of Z. Assume also are the and h(b) that is, h(a) We start by analyzing the right tail and then we give the required modifications for the left tail. 3.1. Right tail Our aim is to approximate the cdf in the tail 7 = {z 1 h(b) - E < z 6 h(b)} of Z, by simulating . . For any i, let us denote hi’ (xi-l, z, xi+’ ) the inverse of h(x) with respect the random variable , X,, ) restricted to Z > h(b) - E. (Xl, to xi, where we have denoted Xi = (Xt 7. e e 9 Xi) and xi = (Xi,. . ., X,). sequentially The proposed method in the following that we have already simulated variables X1 = nt , . . . , Xi-1 = Xi-t. Then simulates variables XI, . . . ,X, form. Assume we simulate Xi such that h(b) --E < h(xi_l,Xi,X’+‘) < h(xi_l,b’). (9) that once variables Xi-1 have been simulated, Note h(xi_l,b’). the new upper bound of Z is From (9) we get li(X’+‘) < Xi < Ui(X’+‘), and (10) (11) E. Castillo et al./Artij?cial Intelligence 96 (1997) 395-419 401 Since X’+ ’ have not been simulated yet, we must choose the largest possible interval which, taking into account the constraint ai < Xi < bi, is Li < Xi < Ui, where Li=max $+r[i(X’+l),ai] [ =max(h~:‘(xi_t,h(b) -e,bi+‘),ai) and Ui =min tn~Ui(X’+‘),b,] [ =min(hi’(Xi-l,h(xi-l,bi),ai+l),bi) (13) (14) (15) are the lower and upper bounds of Xi given Xi. Once Li and Ui are known, we can sequentially proportional Ps (Xi; xi__1 ) lead to different methods. to Ps( xi; Xi-l) simulate Xi, i = 1, . . . , n, with density in the region Li < Xi < Ui. Note that different choices of 3.2. Left tail Similarly, we can approximate the cdf in the left tail 7 = {z 1 h(a) < z < h(a) + .z} of 2, by simulating the random variable X restricted to Z 6 h(a) + E. The above discussion, expressions left tail with the following changes: l Expression (9) becomes and method for the right tail remain valid for the h(xi_*,a’) < h(xi_t,XivX’+‘) < h(U) +E, (16) because, once variables Xi-1 have been simulated, h(.Vi_,,U’). l Expression ( 11) becomes the new lower bound of Z is Zi(X’+‘) =hil(xi_l,h(Xi-l,Ui),X’+‘). l Expression (12) becomes Ui(X’+‘) =h[‘(xi-t,h(U) +&,Xi+‘). l Expression (14) becomes l Expression (15) becomes (17) (18) (19) 402 E. Castillo et al. /Artijicial Intelligence 96 (1997) 395-419 3.2.1. Simulation algorithm The proposed method can be summarized in the following algorithm: Algorithm 1. Input: l An increasing function defining the target variable: Z = h(X) l A set of n conditional probabilities Pa (Xi 1 Xi_ r ) . l Lower and upper bounds of the basic random variables X: a and b. l Sample size m and desired departure E from lower h(a) or upper bound h(b) of the target random variable Z. Output: l A sample of size m from the left tail ‘T = {z 1 h(a) < z < h(a) + c} or the right tail 7 = {z 1 h(b) - E < z < h(b)} of the target Z. Steps: l Step 1: Simulate sequentially Xi, i = 1,. . . , n in the interval Li < Xi 6 Ui, (21) using Ps (xi; Xi- 1) , that is, we simulate truncated variables, where xi, i = 1, . . . , n are the simulated values. l Step 2: Calculate the simulated sample value zj = h(x) and assign it the score Wj = ’ pS(Xi rI i=l PS(Xi;Xi-1) I Xi-11 ’ (22) l Step 3: Store the pair (zj, Wj) . l Step 4: Repeat steps 1 to 3 m times. l Step5 Sortthepairs l Step 6: Replace wj in the pairs (zj, Wj) , j = 1, . . . , m by i c’,, (zj,wj),j=l,...,mwithrespecttoZj. tail and by 1 - i CEj+, wk, for the right tail. ok, for the left 0 Step 7: The resulting Wj, j = 1,. . . , m are the simulated approximations pz (zj ) to FZ ( z.i > . Note that many choices are possible for PS (Xi; Xi-1 ) in Step 1. Two special cases are: ( 1) Likelihood weighing method: In this case the sampling distribution is ps(xi’ = Fxilx,_,(ui I xi-l) - F(xilx;_l)(Li I xi--l> pB(Xi I Xi-11 (23) and then the score (8) becomes: w= pB0 h(X) = II”,, hCxi I F) n”,, pS(Xi I Tii) =fi[Fx,lX._,CU, I Xi-l) -FXil?&_,(Li I Xi-l)]. (24) i=l E. Castillo et al./Artijicial Intelligence 96 (1997) 395-419 403 (2) Uniform sampling method: In this case the sampling distribution is PS(Xi) = - 1 Ui - Li and then the score (8) becomes: Pn(X) w=-= Ps(X> nL, pB(Xi I TTTi) = nk1 PS(ni I vi) ’ l-I i=l [(Vi - Li) eXp(Xi)l. (26) 4. Experimental design and performance of the method In this section we study the performance of the proposed method by its application several examples has been based on the following and the corresponding considerations: analysis. To this end, the experimental to design (1) (2) (3) (4) (5) (6) (7) Several examples with known associated cdf for 2 have been selected so that a comparison with the exact cdf FZ (z ) of the target variable 2 be possible. A set of simulation size m has been simulated and the corresponding To measure the quality of fit the following error statistics have been used: p_z (z ) has been calculated. runs have been performed. In each experiment, a sample of Ql =max 1 F(Zi) i -E(G) 1, and Q2 = {i $(F(zi) - P(Zi))2}1’2, Fl (27) (28) estimates appear in the tables. and fi( z) are the exact and the estimated cdf of Z, respectively. the mean and standard deviation of Qt and Q2, the experiments have where F(z) To estimate been replicated 1000 times. The corresponding Sample sizes m = 100, 200, 500 and 1000 have been selected. The results have been compared with end, intervals are also shown in all tables. Note that these estimates do not depend on the sample size. N’o comparison with the standard Monte Carlo method has been done, because the tails. In fact, a very large proportion of it is very inefficient sample values are out of the tail when this involves high percentiles. the mean error values associated with this method and the corresponding FPI values. To this the corresponding for simulating In the following subsections some of the conducted experiments are described. 4.1. Right tail of sums of uniforms In the case of sums h(X) = CL, Xi, and the functions Zi( Xi+‘) and ui( Xi+‘) in (11) and (12)become 404 E. Castillo et al./Art@cial Intelligence 96 (1997) 395-419 tail of the sum of four uniforms: Mean and standard deviation estimates of Qt and Q2 and values of the FPI method, for samples sizes of 100, 200, 500 and 1000 corresponding (3.1,4) or the cdf interval (0.9727,l) ( 1000 replications) Proposed method PPI method the to the HQ21 0.00298 0.00207 0.00137 0.00091 ELQII 0.0400 0.0400 0.0400 0.0400 E[Q21 0.0166 0.0166 0.0166 0.0166 ~%Q21 0.00462 0.00334 0.00208 0.00147 2 &, k=i+l Table 2 Right corresponding variable interval m 100 200 500 1000 &Qll 0.00703 0.00518 0.00329 0.00237 HQII 0.00316 0.00214 0.00139 0.0009 1 i-l /i(x’+‘) =-xxa+&k-E- k=l k=l ui(xi+‘) = ebk - 2 xk. k=i k=i+l Thus, from (14) and (15) we get Li=m~(~~k-~~k-E.&). Ui = bi. (30) kl k=l The exact cumulative distribution function of the sum of n uniforms is given by F(z) = J&-1Y - r=o ; 0 (z - r)‘, O<z<n, (31) where [z ] is the integer part of z. Table 2 shows the mean and standard deviation estimates of Ql and Q2 and the for IZ = 4 and samples sizes m of 100, 200, corresponding 500 and 1006, obtained by the likelihood weighing method. _ values of the FCPI method, 4.2. Right tail of products of uniforms In the case of products h(X) = ny=, Xi. If we assume Xi > 0, i = 1, , n, the functions Zi(X’+‘) and ui(X’+‘) in (11) and (12) become li(x’+‘) = n”,, bk - 8 <ni,-; xk) (Ha,, xk) ’ &(x’+‘) II”,i bk IX++1 ‘k * and are (see (14) and (15)) (32) (33) E. Castillo et al./Artifcial Intelligence 96 (1997) 395-419 405 Table 3 Right tail c’f the product of three uniforms: Mean and standard deviation estimates of Ql and Q2 and the corresponding to the variable for samples sizes of 100, 200,500 values of the FPI method, and 1000 corresponding (1000 replications) or the cdf interval (0.9984.1) interval (0.8.1) Proposed method FPI method &Q,l 0.000239 0.000178 0.000113 0.000080 100 200 500 1000 8Q11 0.000095 0.000067 0.000041 0.000030 &Q21 0.000141 0.000104 0.000064 0.000046 NQ21 0.00008 1 0.000057 0.000036 0.000026 WQII 0.00430 0.00430 0.00430 0.00430 n”,i bk - E (I-&: Xk) (nLi+, bk) ‘% > ’ Li=lEiX Ui = bi. WQ21 0.00171 0.00171 0.00171 0.00171 (34) (35) The exact cumulative distribution function of the product of n uniforms U(0, 1) is F(z)=z(C i! n--l (-logz)’ ), O<z<l. i=O Table 3 shows the mean and standard deviation corresponding 500 and 1000, obtained by the likelihood weighing method. values of the FPI method, the for n = 3 and samples sizes m of 100, 200, estimates of Ql and Q2 and 4.3. Right tail of sums of products of uniforms As a simple example we consider here the case h(X,,... ,~6)=~1+~2+~3(~4+~~+~6). and we assume which that Xi N U(O,p), implies bi = p, i = 1,. . . ,6. i = 1,. ..,6 and with p < i and E < 2p+3p2, (37) The li( Xi+‘> and Ui( X’+’ ) functions become in Table 5. the values become the functions in Table 4 and Li and Ui Fig. 2 :shows the exact and simulated tail (0.003,004) of the random variable Z = X1 + X2 -1 X3 (X4 + X5 + X6), when we assume and p = 0.002. distributed identically (i.i.d.) uniforms U(O,O.O02); that Xi, i = 1,. . . , n are independent implies E = 0.001, which 4.4. Left itail of products In the case of products of non-negative variables h(X) = nf=, Xi, and the functions Zi(X’+‘) and ui(X’+‘) in (17) and (18) become II”,i ak zi(Xz+l) = <nap,,, xkI. (38) 406 E. Castillo et al. /Artificial Intelligence 96 (1997) 395-419 Table 4 Lower Li ( ti‘+t ) and upper Ui ( Xi+* ) bounds for the sequential simulation of sums of products i 1 2 3 4 5 6 li(X’+‘) 2P+3P2-E-X~-X~(X~+X~+X~) 2P+3~-~-x,-X3(X4+X5+Xd 2p+3p2 --E--X, -xr x4+x5+% 2p+3p2--E--x, --q 13 x5 _ x 6 2pt3p2-s-x, 13 -xz - X4 - x6 2p+3,?--E--x, =3 -9 - x4 - x5 Ui(X’+‘) 2P+3P2-x2-x3(x4+x5+x6) P+3P2-X3(X4+X5+X6) 3p2 x,+x,+& - 3p X5 X6 - 2P - x6 P Table 5 Lower Li and upper Ui bounds for the sequential simulation of sums of products Li max(p - E, 0) max(2p-e-+1,0) max( 2 F+ 3 pz Z” 1 --x 2 +O) max( 2pf3p2 --E--X, -xx mad 2pt3p2--e--x,--q 13 - 2P, 0) -x4-P,O) x3 m=( 2pt3p2--e--x,-q 13 -x4-x5.0) 0.003 0.0032 0.0034 0.0036 0.0038 0.004 0.0042 Fig. 2. Exact and simulated tail (0.003,004) of z =X1 + X2 + X3(X4 +X5 +X6), ui(xi+‘) = n;, ak+& IIE: ‘k II&i+, ‘k Thus, Li and Ui become (see (14) ad (15)) , ai = ai, ui P P P P P P (39) (40) E. Castillo et al. /Artificial Intelligence 96 (I 997) 395-419 Table 6 Left corresponding the variable (0,0.9) uniform samoline methods) tail of the sum of four exponentials: Mean and standard deviation estimates of Ql and Q2 and sizes of 100, 200, 500 and 1000 corresponding (Likelihood weighing values of the FPI method, or the cdf interval ( 1000 replications) for samples (0.0.0135) interval 407 the to and m 100 200 500 1000 m 100 200 500 1000 &Q,l 0.00257 0.00186 0.00122 0.00086 filet1 0.00380 0.00275 0.00182 0.00130 Likelihood weighing Proposed method FPI method HQll 0.00106 0.00076 0.00050 0.00035 &Q21 0.00159 0.00113 0.00074 0.0005 1 XQ21 0.00095 0.00070 0.00046 0.00032 Uniform samulinn E[Qll 0.0376 0.0376 0.0376 0.0376 HQ21 0.0153 0.0153 0.0153 0.0153 Proposed method FFI method XQll 0.00171 0.00118 0.00076 0.00056 &Q21 0.00255 0.00179 0.00116 0.00083 *-rQzl 0.00166 0.00116 0.00076 0.00056 E[QII 0.0376 0.0376 0.0376 0.0376 WQzl 0.0153 0.0153 0.0153 0.0153 (41) 4.5. Left lail of sums of exponentials In the case of sum of four exponential E( 1) variables, Table 6 shows the mean and values of the FPI for samples sizes m of 100, 200, 500 and 1000 when the likelihood weighing estimates of Qt and Q2 and the corresponding sampling methods are used. Note that the first gives better results. standard deviation method, and the uniform 4.6. Analysis and discussion of experimental results From thle preceding ( 1) Percentiles analysis, we can conclude the following: low or high probabilities corresponding estimated with a sample of relatively to very (2) Thie quality of the approximation (3) The method seems to work well for any percentile (4) (see previous examples). the proposed method gave much better results than small size using the proposed method. improves substantially with the sample size m. are very closely In all conducted experiments, the FPI method. (5) The likelihood weighing method seems to give better results than the uniform sampling. (6) The proposed method deteriorates for increasing number of basic variables. 408 E. Castillo et al./Art@cial Intelligence 96 (1997) 395419 5. Improved methods if this number The no rejection method performs very well for small number of basic variables for this is that the number increases. The main reason but deteriorates and of feasible different if we design the associated simulating the ideal situation being all scores to be equal. Now we show how this optimal solution can be theoretically achieved. blows up with scores become very far apart. This problem can be solved to similar scores for all instantiations, the number of basic variables instantiations procedures leading If we choose p cx,j I s = pB(xi I xi-l)[G+l(Ui+l> -Gi+l(b+l)l Gi(Ui) - Gi(b) 9 pB(& = G,(U,) 1 xn-1) - G,(L,) ’ ps(xn’ where Gi(xi) is the cdf associated with the pdf gi(x) ‘pB(x I xi-1)[G+l(ui+l> -Gi+l(h+l)l, Li<X<Ui, i=l,...,n-1, gn(x) = pB(x 1 xn-11, Ln 6 x < un, (42) (43) the score becomes w = G1 (U1 ) - G1 (Ll ), which implies constant The method is illustrated with the two examples below. scores. is independent of the sample and 5.1. Sum of uniforms (left tail) Assume that we consider the random variable Z = cl1 Xi, where Xi, i = 1,. . . , n are the left 1) random variables. Assume also that we want to simulate i.i.d uniform U(0, tail of Z. In this case we can simulate with (42) to obtain: Li=ai=O, i-l Ui=min(E-Cx;,bi), k=l G,(x) =E - x1 -. e. - x+-l - x; L, < x 6 U,,, Gi(x) = 1 - (1 - xi_1 )‘-‘+’ e - Ckl xk and the score becomes w=Gl(U1) -G1(L1) =GI(E) -Gl(O) =8/n!. Thus, we simulate using the expressions: (44) (45) (46) (47) (48) E. Castillo et al./Artijicial Intelligence 96 (1997) 395-419 409 Table 7 Right tail of the sum of four uniforms: Mean and standard deviation estimates of Ql and Q2 and the corresponding values of the FPI method, for samples sizes of 100, 200, 500 and 1000 corresponding to the variable interval (3.1,4) or the cdf interval (0.9727.1) ( 1000 replications) (likelihood weighing and improved methods) m 100 200 500 1000 m 100 200 500 1000 &Q,l 0.00703 0.00518 0.00329 0.00237 &Q,l 0.00220 0.00156 0.00102 0.00072 Likelihood weighing Proposed method FPI method HQll 0.00316 0.00214 0.00139 0.0009 1 &Q21 0.00462 0.00334 0.00208 0.00147 >-rQzl 0.00298 0.00207 0.00137 0.00091 E[Qll 0.0400 0.0400 0.0400 0.0400 NQ21 0.0166 0.0166 0.0166 0.0166 Uniform sampling Proposed method FPI method @-rQll 0.00070 0.00049 0.00032 0.00022 B[Qzl 0.00103 0.0007 1 0.00046 0.00032 a-rQ21 0.00041 0.00029 0.00019 0.00013 E[Qll 0.0400 0.0400 0.0400 0.0400 i-l xi= (E--CXk)(l-pil’(n-i+l)), kl i=l,..., II, where pi are i.i.d. U(0, 1) random variables and we have assumed E < 1. 5.2. Sum of uniforms (right tail) Assume that we consider i.i.d uniform U(0, 1) random variables. Assume also that we want to simulate tail of 2. In this case the score becomes the random variable 2 = x1, Xi, where Xi, i = 1, . . . , n are the right w = En/n! and we simulate with the expressions: (50) i-1 Xi= (i---E-g*0 + [l- i-l (i-E-_C*~)]P~“fl-i+“. k=l i=l,...,n, (51) where pi are i.i.d. U( 0,l) random variables and we have assumed E < 1. Table 7 shows the mean and standard deviation values of the FFI method, corresponding 1000, together with a duplicate of the results has been done by the likelihood weighing method. A comparison of both methods shows that the improved method gives better results. in Table 2. In both cases the simulation for samples estimates of Qi and Q2 and the sizes m of 100, 200, 500 and WQ21 0.0166 0.0166 0.0166 0.0166 (49) 410 E. Castillo et al./Art@cial Intelligence 96 (1997) 395419 6. Adapting the method to uncertainty analysis in Bayesian networks The main problem of the proposed method consists of finding the n inverse functions hZY1(Xi-_l,Z,Xi+l), i= 1,. . . , n, since the functions can be extremely complex. Fortunately, the algebraic expressions associated with uncertainty analysis consists of polynomials analysis involved, which are first degree Networks variables inversion of the target function In the case of polynomial, or quotients of polynomials in each of them. This allows avoiding in Bayesian of the basic the for each variable. The idea is as follows. the algebraic expression for the unavailability h( x,) can be written as h(Xi-_l,Xj,Xi+l)=LY(Xi_~rXi+l) +XiP(Xi_lyXi+'), (52) andP(xi-1,x’+‘) are the coefficients of the first degree polynomial function in xi can be evaluated in two different points of xi, ai and bi, wherea(xi_t,xi+‘) function in Xi. This say, to get linear h(X~-l,U~,X'+l)=~(Xi_*,X"+l)+U~~(X~_~,X'+l), h(Xi_l,birXi+')=LY(Xi_l,Xi+l)+biP(Xi__l,Xi+l), from which we can write h(Xi_l,Xi,Xi+‘) = h(Xi_l,bi,Xi+‘)(Xi-Ui) +h(Xi-l,Ui,X’+‘)(bi-Xi) bi - Ui Thus, its inverse can be written as (53) (54) . (55) This means that we can write the inverse hEF1 (.) as a function of h( .). In other words, we do not need to calculate the inverse. Similarly, if we deal with rational functions, we have h(Xi_l,Xi,Xi+l) = CX(Xi-_lyXifl) +Xip(Xi__l,Xi+l) y(Xi-1,X’+‘) +XiS(Xi-1,X’+‘) ’ (57) If p or 6 are not null we can divide numerator and denominator (57) depends on three coefficients. Thus, we need to evaluate points to obtain an expression Note that this has many computational for the inverse, similar advantages to (56). since we need to implement only by it and we realize that in three different (57) functions h( .) instead of all possible inverses. 7. Examples In this section we show two examples of applications to probability risk assessment. This is one of the fields where the presented method fits very well, since tails play the most important role. E. Castillo et al./Artijicial Intelligence 96 (1997) 395-419 411 Fig. 3. Simplified standby system diagram. Table 8 Variables associated with different element types of failures Variable Physical meaning Variable Physical meaning ACA BlA BIB Cl G2 G3 G4 G5 G6 G7 G8 G9 Cl0 Cl1 Cl2 Cl3 Electric power failure Pump Bl fails to start Pump Bl fails after starting Collector does not receive water flow Valve V6 fails to open Valve V6 does not receive water flow Valve V5 fails to open Valve V5 does not receive water flow Valve V4 is closed Valve V4 does not receive water flow Pump Bl failure Pump Bl does not received water flow Valve V3 is closed Valve V3 does not receive water flow Valve V2 fails to open Valve V2 does not receive water flow Cl5 Ml 01 02 SISA TlA TlB VIA V2A V2B V3A V4A V5A V5B V6A V6B Valve Vl does not receive water flow Element out of service (maintenance) Valve V4 opened after maintenance Valve V3 opened after maintenance Logic signal failure Tank failure Ventilation tank failure Valve Vl is blocked Valve V2 mechanical failure Valve V2 is blocked Valve V3 is blocked Valve V4 is blocked Valve V5 mechanical failure Valve V5 is blocked Valve V6 mechanical failure Valve V6 is blocked 7.1. Example 1: Standby system The simplified shows the variables associated with all considered flow diagram of a typical standby system element Assume that the unavailability of the system is shown in Fig. 3. Table 8 types of failures. is the aim of the analysis. The operating policy (1) (2) (3) (4) is designed to supply water from tank Tl is as follows: The system The system must pump using Bl and open the motorized valves V2, V5 and V6. All valves are shown Pump Bl works for 10 minutes, making and the retention valve VRl, after opening water to tank Tl. system). is started and the manual valve V7 the (standby the test, the pump is checked once a month; during in Fig. 3 in their normal positions the motorized valve V2 returning the water to flow through to collector C 1. 412 E. Castillo et al./Artijcial Intelligence 96 (1997) 395-419 Fig. 4. Directed graph used modelize the system. correctly even valve V7 open. to pump is done every five The system The V3 is (5) (6) (7) (8) (9) (10) V4 are and we during the other contributions unavailability In each Pump the availability must work 24 hours power supply the pump which 24 hours an estimated assumed negligible. that the period, which are the system order to all motorized of 1 x 10p3. checked. To this is unavailable 7 hours. valves demand one accident. comes from failure probability A, signals of pump and valves come train A, has an unavailability of (12) avoid V5 and replication structure of are tested nodes, as x 10m4. a month. is usually graph in 4 and We are In system. (unavailabilities) and maintenance involved variables corresponding Bayesian confidence analyze we want in obtaining the logic policy failure on the interval the (SISA), with fault been modelized diagrams, means of the the probability failure of of the electric power of failure the system. probabilities (ACA) can be that the of failure the system be written Z = = 1) Iz(xI,x~,x~) = - LYXIX~X~, where xi, x2 and x3 are the probabilities ACA and Ml, respectively, failure probabilities Since Expression previous examples different ways: of the remaining (58) involves of no failure associated with variables SZSA, and LY is a constant, which is close to 1 and depends on the elements in the system. to this case, we can solve the uncertainty the product ~1~2x3, we can use the results of the in two analysis problem E. Castillo et al./Artijicial Intelligence 96 (1997) 395-419 413 ( 0.00125 O.Oc’126 0.00121 0.00128 0.00129 Fig. 5. Exact (continuous line), simulated and FPI (dotted line) tail of h(_q,xz,q) CY = 0.999 when Xi, i = 1,2,3 are uniforms U(O.9999,1). = 1 - QX~XQ~ for Exact anralysis. Expression (58) shows that the cdf of Z is FZ(Z)=P~~~[Z~Z]=P~~~[~-~X~X~X~~Z]=~-_~[(~-ZZ)/(Y], (59) where &r(u) is the cdf of U = ~1~2x3. If we assume that Xi, X;? and X3 are i.i.d. uniform U(p, 1) random variables, the cumulative distribution function of U in the region u < /I* is -ps + u + u1ogp + u(logP)2/2 Mu) = + u(logu/P2)2/2 (1 - P)3 - (u + ulog/3) log(u/& It is clear that Z takes values in the interval ( 1 - (Y, 1 - ap3). (60) described in Section 3, we simulate sequentially, X1, X2 and X3 Approxilmate analysis. Using in the intervals the techniques Li = p < Xj 6 cup3+e @2 I-I;:; (x,/P) = Ul, i = 1,2,3. (61) Fig. 5 shows the exact, the simulated and the FPI tail for ff = 0.999, p = 0.9999 and E = 0.00005. A sample size of n = 1000 has been used for the proposed method. Note that the IT1 method gives worse results than the proposed method. From IFig. 5, the 0.98 one-sided is (0,0.00125). confidence The corresponding the system is (0,0.001264). for the probability interval interval obtained using of failure of the FPI method 7.2. Example 2: Pressure tank Here we return to the pressure the failure the tank K is equal to the logical expression tree and the sets of failures tank example given in the introduction. Fig. 6 shows that produce system failure. Note that failure of 414 E. Castillo et al./Artificial Intelligence 96 (1997) 395-419 K . . . Tank . . . . . . . . , . . . Primary failure of time relay F. A . . . . . . . . . . . . . Primary failure of pressure switch A. E . . . . . . . . . . . . . Primary failure of swich E. D . . . . . . . . . . . . . Primary failure of relay D. C . . . . . , . . . . . Primary failure of relay C. B .._.......... Primary failure of tank B. ,. ),( Fig. 6. Tank failure. tree and logic equation of failure K=BvCv(AAE)v(AAD)v(AAF), where the symbols and are for and respectively. get =BACA(AAE)A(AAD)A(AAF) =BACA(AVB> A(Av6) A(AvP> =(BA~A/i)V(BACAEA~AF). (62) (62) (63) Eqs. (62) and (63) are the bases for deriving system. The variables in the set the set of rules for a deterministic expert V=(A,B,C,D,E,F,G,H,I,J,K), E. Castillo et al./Arti@ial Intelligence 96 (1997) 395-419 415 (4 (W Fig. 7. (a) Sets of chained rules and (b) influence diagram of the pressure tank example. where G, H, I, and J are intermediate Fig. 7(a) shows the set of chained failures, are assumed to be either rules as seen in uncertainty paradigms. true or false. Fig. 7(b) shows the directed acyclic graph for the pressure the: arrows where joint prob’ability distribution P(X) of all nodes can be written as the initial dependence indicate of the variables. From Fig. 7(b), tank system problem, the P(A)P(B)P(C)P(D)P(E)P(F) x P(G 1 D,F)P(H 1 E,G)P(Z 1 A,H)P(J 1 C,I)P(K 1 B,J), where P(A = 1) =x3, P(B = 1) = XI, P(C = 1) =x2, P(D = 1) =X5, P(E = 1) =x4 are the and P(F = 1) = x6, P(G associated probabilities with an “ANJI” gate. With this notation, 1 C,I)P(K is the probability the probability of failure becomes 1 D,F),P(H associated with “OR” gates and P(Z 1 A, H) I E,G),P(J 1 B,J) P(K = 1) =x1 +x2 - XIX2 + x3x4 - x1x3x4 - x2x3x4 +x1x2x3x4 + x3x5 - x1x3x5 - x2x3x5 +x1x2x3x5 - x3x4X5 +x1x3x4x5 + x2x3x4x5 - x1x2x3x4x5 + x3x6 - x1x3x6 - x2x3x6 + x1x2x3x6 - x3x4x6 + x1x3x4x6 + x2x3x4x6 - x1x2x3x4x6 - x3x5x6 +x1x3%x6 + x2x3x5x6 - x1x2x3x5x6 +x3x4x5x6 --x1x3x4x5x6 - x2x3x4x5x6 + x1x2x3x4x5x6. (64) the probability TO evaluate A, B, C, D, E and F and then, taking we get the approximation given in Expression ( 1) . into consideration only of K = 1 we assume very small probabilities of events terms up to second order Eq. ( 1) has been used to simulate the tail of P (K = 1) assuming A to F to be uniformly U( 0, 0.001) and independently tail approximations of the probability of failure of the pressure the random variables distributed. Fig. 8 shows the right tank (without common 416 E. Castillo et al. /ArtiQicial Intelligence 96 (1997) 395419 Fig. 8. Right tail approximations of the probability of failure of the pressure tank (without common cause analysis), obtained by the proposed (continuous line) and the FPI (dotted line) methods. cause analysis), methods. Note that though of a certain more reliable failure probability of the pressure other words, we can give unilateral pressure obtained by the proposed the difference for the tail. Since line) it is to be relevance than the FPI, we can make statements of the form “The probability of the In of the (continuous is small in terms of probability the proposed method has been shown line) and the FPI (dotted values, tank to be larger than 0.0019 is less than 0.0052”. for the failure probability confidence intervals tank. 7.2.1. Common cause of failure Now let us assume that there is a common cause of failure for all relays (C, D and them. Thus, the process can be modified as follows. to the new influence diagram where that, in this case, we have a multiply-connected F). So, we draw new edges linking Fig. 9 shows a Bayesian network which corresponds C, D and F have been graph. Assume probability function of all nodes can be written as linked. Note that the new nodes can also take values “true” or “false”. The joint P(X) =P(A)P(B)P(C 1 D)P(D)P(E)P(F ( C,D)P(G 1 D,F) x P(H 1 E,G)P(Z 1 A,H)P(J 1 C,Z)P(K I B,J). (65) The conditional probabilities are as before with the only differences being P(F = 1 1 C = 0, D = 0) = x5/4, P(F=lIC=O,D=1)=2x6, P(F= 11 c = i,D=o> =2x6, P(F = 1 1 c = l,D = 1) =4x6 P(C = 1 1 D = 0) = x2/2. P(C = 1 1 D = 1) = 3x2. This shows that the probability than when larger fails is larger then when it does not. they are not and the probability of failure of relay F when relays C and D fail are of failure of relay C when relay D Note that these probabilities bility of failure has been reduced approximately C = 0, D = 0) dominates imply a substantial improvement the term P( F = 1 I to X6/4), because in the expression P( F = 1) = Cc,d P( F = 1 1 C = c, D = of relay F (its proba- E. Castillo et al./Art@cial Intelligence 96 (1997) 395-419 417 Fig. 9. The Bayesian network for the pressure tank with common causes of failure. d) P (C =: c, D = d) due to the fact that the reliabilities of relays C and D are high. We shall see however that the common causes are close to compensate this effect. Using exact expression the symbolic propagation methods described by Castillo et al. [5] we get the of failure of the pressure for the probability tank: P( A;: = 1) =X1 + 0.5X2 - 0.5X1X2 + X3X4 - X1 X3X4 - 0.5X2X3X4 +0.5X1X2X3X4 + 2.5~2~5 - 2.5x,x2x5 +X3X5 - x1x3x5 - 3X2X3X5 + 3X1X2X3X5 - X3X4X5 + X1X3X4X5 +0.5X2X3X4X5 - 0.5X1X2X3X4X5 + 0.25x3&5 - 0.25x1x3&5 - 0.125x2x3&5 + 0.125x1x2x3x6 - 0.25x3x4&j + 0.25x,x3x4&j + 0.125x2x3x4x6 - 0.125x1x2x3x4&j - 0.25x3x5x6 +0.25x1x3x5x6 + 0.125x2x3x5x6 - 0.125x1x2x3x5&j + 0.25x3x4x5&5 - 0.25x1x3x4x5&5 - 0.125~2~3~4~5~6 + 0.125xtx2x3x4x5x6 (66) (2)) which has been used to simulate Taking now into consideration given in Expression the random variables A to F to be uniformly U(0, 0.001) and independently The methods the simulated in Section 3 have been used. Fig. 10 shows probabi1it.y of failure of the pressure method similar increased. only terms up to second order we get the approximation the tail of P( K = 1) assuming distributed. tails for the cause analysis), using the proposed tail is very the reliability of relay F has been (continuous to the previous tail (see Fig. 8)) even though line) and the FPI method line). The resulting tank (Common (dotted 8. Conclusions One eflicient computational algorithm for simulating is defined variable which function of a set of basic variables has been given. This method allows simulating tail directly, to the target this leads i.e., all the simulated points are guaranteed of the method. Several tail of a random in each variable the to belong tail; theoretical examples and two to a good performance the left (right) (decreasing) increasing invertible as an 418 E. Castillo et al./Artij?cial Intelligence 96 (1997) 395-419 Fig. 10. Simulated tails for the probability of failure of the pressure tank (Common cause analysis) using the proposed method (continuous line) and the FPI method (dotted line). to illustrate life examples have been given of the real exact cdf in the tail and the FPI method with the simulated cdf shows that the proposed if the simulation method is carefully selected for getting method performs well especially similar scores for all simulated in many fields of reliability risk or security assessments of complex systems. instantiations. The method has immediate applications the method. Some comparisons theory, as probability Acknowledgments We thank Iberdrola, and Dire&on the Leonardo Torres Quevedo Foundation General de Investigaci6n Cientifica Cantabria (project TIC96-0580), referees for partial support of this work. We also thank for their comments which allowed a substantial improvement of the paper. of the University of y Tecnica (DGICYT) the Editor and References [ 11 B. Arnold, E. Castillo and J.M. Sarabia, Conditionally specified distributions, in: Lecture Notes in Statistics, Vol. 73 (Springer, New York, 1992) 1-151. [2] R. Bouckaert, E. Castillo and J.M. Guti&rez, A modified simulation scheme for inference in Bayesian networks, Intemat. J. Approximate Reasoning (1995). [ 31 K. Breitung, Asymptotic approximations for multinormal integrals, J. Engineering Mechanics Division ASCE 100 (3) (1984) 357-366. [4] E. Castillo, Extreme Value Theory in Engineering (Academic Press, New York, 1988). [ 51 E. Castillo, J.M. Guti&rez and A.S. Hadi, Parametric structure of probabilities in Bayesian networks, in: Proceedings ECSQARU’95, Fribourg, Lecture Notes in Artificial Intelligence, Vol. 946 (Springer, New York, 1995) 89-98. [ 61 E. Castillo, J.M. Guti&rez and AS. Hadi, Expert Systems and Probabilistic Network Models (Springer, New York, 1997). [7] R.M. Chavez and G.F. Cooper, A randomized approximation algorithm for probabilistic inference on Bayesian belief networks, Networks 20 (1990) 661-685. [ 81 L. Devroye, Non-Uniform Random Variate Generations (Springer, New York, 1986). E. Castillo et al./Art&ial Intelligence 96 (1997) 395-419 419 [9] A.N. Freudenthal, [lo] J. Galambos, The Asymptotic Theory offitreme Order Statistics (Krieger, Malabar, FL, 1987). [ 111 FE. Haskin, B.D. Staple and C. Ding, Efficient uncertainty Safety and the probability of structural analyses using fast probability failure, Trans. AXE 121 (1956) 1337-1397. integration, Nuclear Engineering and Design (1996) 225-248. [ 121 A.M. Hasofer and N.C. Lind, Exact and invariant second moment code format, J. Engineering Mechanics Divis,ion ASCE 100 (1) (1974) 111-121. [ 131 J. Pe,ul, Evidential (198’7) 245-257. reasoning using stochastic simulation of causal models, Artificial Intelligence 32 [ 141 J. Pickands [ 151 R. Rackwitz and B. Fiessler, Structural III, Statistical inference using extreme order statistics, Ann. Statist. 75 (1) reliability under combined load sequences, ( 1975) 119-131. J. Comput. Strut. 9 (1971%) 489-484. [ 161 CRY. Rubinstein, Simulation and the Monte Carlo Method (John Wiley and Sons, New York, 1981). [ 171 R.D. Shachter networks, IntelOgence, Vol. 5 (North-Holland, Amsterdam, [ 181 B. Staple and FE. Haskin, Analysis of extreme on belief in: L.N. Kanal, M. Henrion, R.D. Shachter and J.F. Lemmer, eds., Uncertainry in Artificial top event frequency percentiles based on fast probability and M.A. Peot, Simulation to general probabilistic approaches inference 1990). integmtion, in: Proceedings PSAM-II, San Diego, CA (1994) 4619-4624. [ 191 I. Weissman, Estimation of parameters and large quantiles based on the k hugest observations, J. Amer. Statist. Assoc. 73 (364) (1978) 812-815. 