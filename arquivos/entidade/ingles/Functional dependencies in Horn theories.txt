Artificial Intelligence 108 (1999) 1–30Functional dependencies in Horn theoriesToshihide Ibaraki a;1, Alexander Kogan b;c;(cid:3), Kazuhisa Makino d;2a Department of Applied Mathematics and Physics, Graduate School of Informatics, Kyoto University, Kyoto,Japan 606b Department of Accounting and Information Systems, Faculty of Management, Rutgers University, Newark,NJ 07102, USAc RUTCOR, Rutgers University, 640 Bartholomew Road, Piscataway, NJ 08854-8003, USAd Department of Systems and Human Science, Graduate School of Engineering Science, Osaka University,Toyonaka, Osaka, JapanReceived 12 March 1997; received in revised form 29 July 1998AbstractThis paper studies functional dependencies in Horn theories, both when the theory is representedby its clausal form and when it is defined as the Horn envelope of a set of models. We providepolynomial algorithms for the recognition of whether a given functional dependency holds in a givenHorn theory, as well as polynomial algorithms for the generation of some representative sets offunctional dependencies. We show that some problems of inferring functional dependencies (e.g.,constructing an irredundant FD-cover) are computationally difficult. We also study the structure offunctional dependencies that hold in a Horn theory, showing that every such functional dependencyis in fact a single positive term Boolean function, and prove that for any Horn theory the set of itsminimal functional dependencies is quasi-acyclic. Finally, we consider the problem of condensinga Horn theory, prove that any Horn theory has a unique condensation, and develop an efficient(cid:211) 1999 Elsevier Science B.V. All rightspolynomial algorithm for condensing Horn theories.reserved.Keywords: Knowledge representation; Horn theory; Functional dependency; Condensation; Computationalcomplexity; Conjunctive normal form; Acyclic directed graph1. IntroductionRelational databases have been invented, studied and deployed as essential tools ofinformation storage and retrieval (see [10,33,34,42,43]). Functional dependencies have(cid:3)Corresponding author. Email: kogan@rutcor.rutgers.edu.1 Email: ibaraki@kuamp.kyoto-u.ac.jp.2 Email: makino@sys.es.osaka-u.ac.jp.0004-3702/99/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 9 8 ) 0 0 1 1 4 - 31999 Elsevier Science B.V. All rights reserved.2T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30been recognized to be one of the most important concepts in the relational databasetheory (see [1,14]). Functional dependencies state that the values of certain attributes ina relation are determined by the values of some other attributes. They are commonly usedin the logical database design to express integrity constraints, and thus to express domainknowledge. The problems of inferring functional dependencies from relations have beenstudied in [30,35]. Thorough theoretical studies of functional dependencies in relationaldatabases (see [12,14,15,28,39]) have established a close connection with Horn clauses.Horn clauses were introduced in formal logic (see [21,36]), and gained prominencein logic programming (see [13]) and artificial intelligence (see [9,11,24]). In artificialintelligence, the implementation of a knowledge base as a Horn theory is often preferred,since linear time complexity of solving Horn satisfiability problems (see [13,37]) providesthe benefits of computationally tractable reasoning, while Horn clauses have the expressivepower sufficient for many applications.A Horn theory is characterized by the condition that the intersection of any two models isagain a model. A theory can be viewed as the set of its models, and reasoning with modelshas been developed in recent AI studies (see [24,27,29]). In model-based representation, atheory is represented by a subset of its models, which are commonly called characteristicmodels [24,27,29]. From the database theory point of view, the set of models is infact a relation. This relation may have functional dependencies, which reveal importantstructural properties of the theory by describing the intrinsic determinants of values ofcertain attributes. Individual functional dependencies can provide valuable insights intohidden laws of the problem domain, and can be used by domain experts for evaluatingand verifying the theory. The inference of functional dependencies in a Horn theory canthus provide a means of its qualitative analysis, and can also be considered to be a form ofknowledge discovery.The knowledge of functional dependencies in a theory may allow to simplify thetheory by eliminating those variables whose values are determined by the values of othervariables. This “condensation” procedure will result in a theory which does not have anyfunctional dependencies, can have much fewer variables than the original theory, and canbe structurally simpler than the original theory. The computational expense of condensinga theory can be offset by the speedup of queries to the knowledge base, and thereforecondensation can provide significant computational benefits. Moreover, the condensedtheory can be viewed as the “core” of the original theory, and thus condensation can revealimportant structural information about the problem domain.Knowledge condensation represents a special type of knowledge preprocessing, whichattempts to spend some computational resources at the preliminary stage to transforma knowledge base in such a way that the transformed one can be used to reason andanswer queries with less computational effort. The computational expense of knowledgepreprocessing is quickly amortized over the large number of queries during routineoperations. A well developed type of knowledge preprocessing is known under the name ofknowledge compilation (see [25,40]), which constructs Horn upper and lower bounds of ageneral Boolean theory and attempts to use them for answering queries. For some queries,such attempts can be successful, providing fast answers which would be impossible toobtain using the original Boolean theory. If the Horn bounds do not provide an answer, thenthe original theory has to be used to answer queries. It is interesting to note that knowledgeT. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–303compilation attempts to reduce the size of the Horn upper bound by introducing additionalvariables in the theory (see [25]), while knowledge condensation aims to simplify theproblem by eliminating redundant variables from the theory.Another well developed type of knowledge preprocessing is knowledge compression(see [6,17–20]), which shortens the length of a Horn CNF without changing the Horntheory it represents. While knowledge compilation aims to reduce an intractable problemto a tractable one, knowledge compression, similarly to knowledge condensation, isdeveloped for Horn theories, and therefore simplifies a problem which is already tractable.Such simplifications are nevertheless very important, since Horn theories used in practicalapplications can have very long representations. This is typical in many applications wherepropositional Horn theories can be generated automatically, e.g., when first-order Horntheories are instantiated over finite but large domains. In these situations, the possiblesignificant size reductions provided by knowledge compression and condensation becomeessential. Both knowledge compression and condensation can be used together withknowledge compilation to simplify the Horn bounds it produces.This paper is devoted to the studies of functional dependencies in Horn theories. Itfocuses on characterizing the combinatorial structure of such functional dependencies, andon developing efficient polynomial algorithms for recognizing, inferring and using them.We consider the problems arising when a theory is represented by its Horn clausal form,as well as when it is defined as the Horn envelope (see [26]) of a set of models (i.e., it isrepresented by characteristic models).The results of this paper reveal new properties of Horn theories, and can be used tomake knowledge representation and reasoning computationally more efficient. We providepolynomial algorithms to recognize whether a given functional dependency holds in agiven Horn theory, as well as polynomial algorithms to generate some representativesets of functional dependencies. We show that some problems of inferring functionaldependencies (e.g., constructing an irredundant FD-cover) are computationally difficult.We also study the structure of functional dependencies that hold in a Horn theory, showthat every such functional dependency is in fact a single positive term Boolean function,and prove that for any Horn theory the set of its minimal functional dependencies is quasi-acyclic.Finally, we apply the obtained structural and algorithmic results about functionaldependencies in Horn theories to the problem of condensing a Horn theory. We provethat, in contrast with the case of general Boolean theories, any Horn theory has a uniquecondensation. We show that a Horn theory can be totally condensed using a very limitednumber of functional dependencies, and develop an efficient polynomial algorithm forcondensing Horn theories. The condensation of a Horn theory represented as the Hornenvelope of a set of models always reduces the size of the representation, and thereforeis computationally advantageous. The condensation of a Horn CNF may result (in theworst case) in a moderate polynomial increase in the length of the CNF. On the otherhand, examples show that the potential reduction in the length of the CNF resultingfrom condensation can be exponential. It makes sense at the preprocessing stage toattempt condensing a Horn CNF, since in the worst case (where the size increases) only apolynomial amount of computational effort is wasted, while in the case of success (wherethe size decreases) the computational benefits will be utilized continuously over the long4T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30run. Additionally, knowledge compression can be applied to the condensed theory, whichmay be easier to compress than the original one since it contains fewer variables and canhave simpler structure.2. Notation and basic conceptsPropositional variables taking the values in f0; 1g (meaning false and true, respectively,and assuming 0 < 1) will be denoted by lower case Latin letters (usually from the endof the alphabet), with x denoting the negation of x. Propositional variables and theirnegations will be called literals, with the variables themselves called positive literals andtheir negations called negative literals. Upper case Latin letters (usually from the end of thealphabet) will be used to denote sets of propositional variables, with the letter V reservedto denote the set of all variables (in most cases assumed to be fx1; x2; : : : ; xng). Booleanvectors (points, or models) in f0; 1gn will be denoted by lower case Greek letters, with(cid:11)TXU denoting the restriction of a point (cid:11) 2 f0; 1gn to the set of variables in X (cid:18) V . Wewill denote as (cid:11) 6 (cid:12) the condition that (cid:11)i 6 (cid:12)i for all i D 1; 2; : : : ; n, and as (cid:11) < (cid:12) thecondition that (cid:11) 6 (cid:12) and (cid:11) 6D (cid:12). We will say that (cid:11) and (cid:12) are comparable if either (cid:11) 6 (cid:12)or (cid:12) 6 (cid:11) holds.2.1. TheoriesA set of Boolean vectors (also called models) in f0; 1gn is called a theory (or a Booleanfunction f0; 1gn ! f0; 1g, identified with its set of true points, i.e., the points assigned thevalue 1), and it will usually be represented by an upper case Greek letter like (cid:6). We willdenote by (cid:6)TXU a theory (cid:6) restricted to the variables in X. The number of models of atheory (cid:6) will be denoted by j(cid:6)j.We shall call a disjunction of literals a clause, and in many cases will not distinguishbetween a clause and the set of literals it contains. A clause C is said to subsume a clauseC0 if C0 contains all the literals in C. It is well known that any theory can be representedas a conjunction of clauses called conjunctive normal form (CNF). In some cases, we willnot make a distinction between a CNF and the theory it represents. The length of a CNFF (i.e., the number of literals in it) will be denoted by jFj. A CNF is called irredundant ifthe removal of any clause from it results in a CNF that does not represent the same theory.A clause C is called an implicate of a theory (cid:6) if its set of models contains (cid:6), andthis will be denoted as (cid:6) jD C. Clearly, each clause of a CNF is an implicate of the theoryrepresented by the CNF. A clause C is called a prime implicate of a theory (cid:6) if (cid:6) jD Cand there is no distinct clause C0 such that (cid:6) jD C0 jD C (in other words, (cid:6) does not havea distinct implicate C0 that subsumes C). A CNF consisting only of prime implicates ofthe theory it represents is called prime.A clause containing a single literal is called a unit clause, while a clause containing twoliterals will be called quadratic. It can be seen easily that, for any non-empty theory (cid:6),if a unit clause is an implicate of (cid:6), then (i) it is a prime implicate of (cid:6), (ii) no otherprime implicate of (cid:6) involves the variable of this clause, and (iii) all the models of (cid:6) havethe same value in the variable of this clause. In other words, a unit implicate means thatT. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–305(cid:6) is degenerate in the variable of the unit clause, and without loss of generality we shallassume from now on that all theories considered in this paper do not have unit implicates.Clearly, if a theory has no unit implicate, then every quadratic implicate of such a theoryis prime.If an arbitrary theory is given by its set of models, all its unit implicates correspond tothe constant-zero or constant-one columns. If a Boolean theory is given by a CNF, it isNP-hard to check whether it has any unit implicates. This, however, will not present anyproblems in the context of this paper, since the discussion here will be focused on the Horntheories, and the discovery of unit implicates, if any, of a Horn CNF F can be accomplishedin O.jV jjFj/ time. 32.2. Functional dependenciesFor two subsets of variables X; Y (cid:18) V , an expression X ! Y , called a functionaldependency, means that the values of the variables in X determine the values of thevariables in Y . A functional dependency X ! Y is said to hold in a theory (cid:6) if, forany (cid:11); (cid:12) 2 (cid:6) such that (cid:11)TXU D (cid:12)TXU, it holds that (cid:11)TY U D (cid:12)TY U. Obviously, functionaldependencies are monotone with respect to set inclusion. More precisely, if a functionaldependency X ! Y holds in a theory (cid:6), then a functional dependency X0 ! Y 0 alsoholds in (cid:6) for any X0 (cid:19) X and any Y 0 (cid:18) Y .Since a functional dependency X ! Y holds in a theory (cid:6) if and only if the functionaldependency X ! y holds in (cid:6) for every y 2 Y , without loss of generality, we will restrictour attention to functional dependencies of type X ! y. A functional dependency X ! yin (cid:6) states that the variable y is a Boolean function of the variables in X (i.e., y D f .X/).Theorem 2.1. Given a theory (cid:6), one can check in O.jV jj(cid:6)j/ time whether a functionaldependency X ! y holds in (cid:6).Proof. To check whether X ! y holds in (cid:6), we construct a binary decision tree usingall the variables in X one by one for branching at the decision nodes. The root of the treecontains all the points in (cid:6). Each node of the tree contains the set of points in (cid:6) whichhave exactly the same values in the variables along the path from the root to the node. Thebranching stops when a node has no points, or when all the variables in X have alreadybeen used for branching. The functional dependency X ! y does not hold in (cid:6) if and onlyif there exists a leaf in the resulting tree which contains points in (cid:6) that have the oppositevalues in y. Since the number of leaves of the tree does not exceed 2j(cid:6)j, this can bechecked in O.j(cid:6)j/ time. Since the depth of the tree does not exceed jXj, the constructionof the tree can be done in O.jV jj(cid:6)j/ time, and therefore the total time needed to checkwhether X ! y holds in (cid:6) is O.jV jj(cid:6)j/. 2On the other hand, if a theory is represented by a CNF, the problem of checking whethera functional dependency holds in the theory becomes difficult.3 In the following we use the notation (cid:30) D O. / to denote that there exists a constant c such that (cid:30) 6 c .6T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30Theorem 2.2. Given a CNF F and a functional dependency X ! y, it is CoNP-completeto check whether this functional dependency holds in the theory represented by F .Proof. The problem is obviously in CoNP, since if the functional dependency X ! y doesnot hold in the theory represented by F , it can be demonstrated by two points (cid:11) and (cid:12) thatsatisfy F and (cid:11)TXU D (cid:12)TXU and (cid:11)TyU 6D (cid:12)TyU.We shall now show that this problem is hard by a reduction from the satisfiabilityproblem, which is known to be NP-complete. Given an arbitrary CNF F 0, in order to checkwhether it is satisfiable (i.e., whether F 0 has a model), we introduce two new variables x0and y0, and create a new CNF F D F 0 ^ .x0 _ y0/. We claim that the given CNF F 0 issatisfiable if and only if the dependency x0 ! y0 does not hold in the theory representedby F . Indeed, each model of F 0 corresponds to three models of F with the variables.x0; y0/ taking the values .0; 0/, .0; 1/, and .1; 1/, respectively. The first two combinationsshow that the dependency x0 ! y0 does not hold. On the other hand, if F 0 has no models,x0 ! y0 trivially holds. 2A functional dependency X ! y in (cid:6) is minimal if there is no X0 (cid:26) X such that thefunctional dependency X0 ! y holds in (cid:6). Because of monotonicity, it is essential toknow only the set of minimal functional dependencies in (cid:6), which will be denoted byM.(cid:6)/.We shall call functional dependencies with a single variable in the left-hand side simple.Since we consider theories without unit implicates, any simple functional dependency thatholds in a theory is minimal. Moreover, if a functional dependency x ! y holds in (cid:6), thenthe functional dependency y ! x must also hold in (cid:6), because a Boolean function of asingle variable, which is not a constant, can be either an identity (y D x), or its negation(y D x). This implies the following statements, in which we use simplified notations suchas xyZ ! w to mean fx; yg [ Z ! w.Lemma 2.3. If a simple functional dependency x ! y holds in a theory (cid:6), then(cid:15) the functional dependency y ! x must also hold in (cid:6),(cid:15) no minimal functional dependency in (cid:6) has the form xyZ ! w,(cid:15) xZ ! w is a minimal functional dependency in (cid:6) if and only if yZ ! w is a minimalfunctional dependency in (cid:6), and(cid:15) Z ! x is a minimal functional dependency in (cid:6) if and only if Z ! y is a minimalfunctional dependency in (cid:6).The statements of the lemma (except for the second one) require the assumption that (cid:6)does not have unit implicates. As was remarked above, if (cid:6) does have a unit implicate,say x or x, then the variable x is degenerate in the sense that all the models of (cid:6) havethe same value in x. In this case, for every variable y 2 V the functional dependencyy ! x obviously holds in (cid:6), and no other minimal functional dependency in (cid:6) involvesx. This implies that without loss of generality the study of functional dependencies can berestricted to theories without unit implicates.The proof of Theorem 2.2 shows that if a theory (cid:6) is represented by a CNF, then it isdifficult to check whether even a simple functional dependency holds in (cid:6).T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–307The fact that certain functional dependencies hold in a theory may imply that otherfunctional dependencies must also hold in the same theory. More precisely, a functionaldependency is said to be implied by a set of functional dependencies if it can be derivedfrom these dependencies by the repetitive application of the following Armstrong’s rulesof inference (see [1,33]):(1) inclusion rule: if X (cid:18) Y , then Y ! X;(2) augmentation rule: if X ! Y , then XZ ! Y for any set Z; and(3) transitivity rule: if X ! Y and Y ! Z, then X ! Z.The set of all the functional dependencies implied by the functional dependencies in a set Dwill be called the closure of D, and will be denoted by bD. For a theory (cid:6), a set of minimalfunctional dependencies D will be called an FD-cover of (cid:6) if its closure bD is the set of allthe functional dependencies that hold in (cid:6). An FD-cover of (cid:6) is called irredundant if noproper subset of it is an FD-cover of (cid:6). Clearly, for any (cid:6), the set M.(cid:6)/ is an FD-coverof (cid:6). However, it is possible that a subset of M.(cid:6)/ also provides an FD-cover of (cid:6).For a set of functional dependencies D, a theory (cid:6) is called an Armstrong relation forD if the set of all the functional dependencies that hold in (cid:6) coincides with the closure bD.The concept of Armstrong relations is very important in the theory of relational databases,and has been well studied (see [1,2,28,34]). It is known that, for any set of functionaldependencies D, there exists an Armstrong relation. However, such relation may not beBoolean. If we restrict the set of relations to theories in f0; 1gn, there are sets of functionaldependencies D for which there is no Armstrong relation. For example, let us considerD D fx ! y; yz ! wg. Since D does not contain y ! x, all the models of any Armstrongrelation of D should have the same value in y. Therefore, yz ! w implies that z ! w mustalso hold, and since it is not in D, this set of functional dependencies has no Armstrongrelation among general Boolean theories.2.3. CondensationIf a functional dependency X ! y holds in a theory (cid:6), then the value of y is redundantin every model of (cid:6) in the sense that y can be determined from X, i.e., by a Booleanfunction y D f .X/. It therefore may be beneficial to “reduce” (cid:6) by eliminating y andconsidering instead the theory (cid:6)TV n yU. If the description of the function f is preserved,then this reduction will not result in any loss of information. The reduced theory (cid:6)TV n yUis simpler to work with since it has fewer variables, and its structure is not complicatedin any way by this reduction. Moreover, this reduced theory will have fewer functionaldependencies than the original one, since, as can be seen easily, its set of functionaldependencies consists of those and only those dependencies that hold in (cid:6) and do notinvolve y.If the theory (cid:6)TV n yU still has some functional dependencies, then the reductionprocedure can be repeated. We shall call condensation the iterative application of thereduction procedure until the resulting theory has no functional dependencies. Theresulting theory (cid:6) c, which has no functional dependencies, will be called a condensationof (cid:6). Generally, a theory that does not have any functional dependencies will be calledcondensed.8T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30The condensation procedure does not specify which functional dependency to use forreducing a theory at each step, and if the theory has several functional dependencies, onewill be chosen arbitrarily. Therefore, the result of the condensation procedure is generallynon-deterministic, and a theory may be condensed into many different ones.The reduction procedure described above is similar to the normalization process whichis routinely used in the logical design of relational databases. The peculiarity of thenormalization process consists in the fact that the description of function f is preserved inthe form of a relation. In a knowledge-based system this function can be stored in otherways (i.e., as a clausal form, a formula, a decision tree, etc.). It may happen, however,that the structure of this function f is complicated. Then the task of preserving and usingthis functional description may be far from trivial. This complication, if it happens, mayoffset the benefits of reduction and may even impose some computational penalties. Thisproblem manifests itself in the practice of relational databases, where denormalization iscommonly used to speed up the database performance.2.4. Horn theoriesA clause is called Horn if it contains at most one positive literal. Clauses containingexactly one positive literal are called definite, while clauses containing no positive literalsare called negative. A CNF is called Horn if it contains only Horn clauses. A CNFcontaining only negative clauses will be called negative, while a CNF containing onlydefinite clauses will be called definite. A theory is called Horn if there exists a Horn CNFrepresenting it. It is known (see [17,18]) that every prime implicate of a Horn theory isHorn, and therefore any prime CNF of a Horn theory is Horn. The most important propertyof Horn CNFs is the linear time complexity of the satisfiability problem (see [13]), i.e.,the problem of checking whether the theory represented by the CNF contains at least onemodel. Based on this, for a given Horn CNF and any clause, it can be checked in linear timewhether this clause is an implicate of the CNF, and if yes, a prime implicate subsumingthis clause can be found easily.For two points (cid:11); (cid:12) 2 f0; 1gn, the point (cid:13) defined by (cid:13)i D (cid:11)i ^ (cid:12)i , i D 1; 2; : : : ; n, will becalled the intersection of (cid:11) and (cid:12) and denoted by (cid:11) \(cid:12). It is well known (see [11,36]) that atheory is Horn if and only if it is closed under intersection, i.e., (cid:11); (cid:12) 2 (cid:6) imply (cid:11) \ (cid:12) 2 (cid:6).This property leads to an alternative way of representing Horn theories, i.e., a Horn theorycan be represented by a subset of its models which has the property that all the other modelscan be obtained as intersections of some models in the subset. The smallest such subset iscalled the characteristic set [24,27,29]. For an arbitrary theory (cid:6), its intersection closureis called the Horn envelope of (cid:6) and is denoted by H .(cid:6)/ (see [26]). Clearly, H .(cid:6)/ is theminimum Horn superset of (cid:6); i.e., for any Horn theory (cid:6) 0 (cid:19) (cid:6), it holds that H .(cid:6)/ (cid:18) (cid:6) 0.In this paper, we shall consider a Horn theory (cid:6) (cid:18) f0; 1gn that is represented either by aHorn CNF or by a subset (cid:6) 0 of (cid:6) satisfying (cid:6) D H .(cid:6) 0/.WIt is natural to establish a correspondence between functional dependencies and Hornclauses by introducing for a functional dependency X ! y the definite Horn clausey _x2X x. This correspondence has been well studied (see [12,14,15,39]), and has beenshown to establish the following equivalence between a set of functional dependencies Dand its corresponding definite Horn CNF F : a functional dependency X ! y is impliedT. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–309Wby D if and only if the definite Horn clause y _x2X x is an implicate of F . Therefore, aset of functional dependencies can be naturally interpreted as a Horn CNF. In what followswe will occasionally make no distinction between a set of functional dependencies andthe corresponding definite Horn CNF. Since a Horn CNF represents a Horn theory (or aHorn Boolean function, see [17,18]), we shall call the Horn theory represented by the setof functional dependencies holding in a theory (cid:6) the associated Horn theory of (cid:6), andview M.(cid:6)/ as the set of all prime implicates of this associated Horn theory. This paper isdevoted to studying various properties of M.(cid:6)/ when (cid:6) itself is a Horn theory.2.5. ExamplesTo illustrate the concepts introduced in this section, let us consider a theory (cid:6), which isthe set of row vectors in the following matrix (cid:0) :0(cid:0) DB@1CA :x110y101z w000111In the following, we will sometimes write (cid:6) D (cid:0) if (cid:6) is the set of row vectors in thematrix (cid:0) . One can check that (cid:6) can be represented by the following CNF:.x _ w/.y _ z/.w _ y/.w _ z/.x _ y _ z/:Furthermore, using the decision tree construction described in the proof of Theorem 2.1, itcan be verified that the following set of functional dependencies is an FD-cover of (cid:6):D D fx ! w; w ! x; xy ! z; yz ! x; xz ! yg:The set of all minimal functional dependencies that hold in (cid:6) is then given by:[M.(cid:6)/ D Dfwy ! z; yz ! w; wz ! yg:The condensation of (cid:6) using the sequence of functional dependencies fx ! w; xy ! zg1 , while the condensation of (cid:6) using the sequence ofresults in the condensed theory (cid:6) cfunctional dependencies fw ! x; wz ! yg results in the condensed theory (cid:6) c2 :B@(cid:6) c1DCA ;B@(cid:6) c2D01x110y10101CA :z w000111In the condensation of (cid:6) cz D x _ y, while in the condensation of (cid:6) cexpressions: x D w, y D z _ w.1 the eliminated variables have the following expressions: w D x,2 the eliminated variables have the followingIt can be seen easily that the above theory (cid:6) is not Horn; its Horn envelope H .(cid:6)/ isshown in Fig. 1.The Horn theory H .(cid:6)/ can be represented by the following Horn CNF:.x _ y _ z/.y _ z _ w/.w _ y/.w _ z/:10T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30H .(cid:6)/ D0BBBBBBBBB@x1101000y10101001CCCCCCCCCAz w00011100000100;H .(cid:6)/c D0BBBBBBBBB@x1101000y10101001CCCCCCCCCA:z0110010Fig. 1. Horn envelope H .(cid:6)/ and its condensation.The set of all minimal functional dependencies that hold in H .(cid:6)/ coincides with the FD-cover of H .(cid:6)/ and consists of a single functional dependency:M.H .(cid:6)// D D D fyz ! wg:The theory H .(cid:6)/ has a unique condensation which is shown in Fig. 1. The eliminatedvariable has the following expression: w D yz. The condensed theory H .(cid:6)/c can berepresented by a CNF consisting of a single negative clause:x _ y _ z:3. Recognizing functional dependencies in Horn theoriesThe most basic problem about functional dependencies in Horn theories is therecognition problem, i.e., given a Horn theory (cid:6) and a functional dependency X ! y,check whether this functional dependency holds in (cid:6). It was remarked in Section 2.2 (seeTheorem 2.2) that in the case of general Boolean theories the computational complexity ofthe recognition problem depends on how the theory is represented.We will consider first the case in which a Horn theory is represented by a Horn CNF.Theorem 3.1. Given a Horn CNF F and a functional dependency X ! y, it canbe checked in O.jXjjFj/ time whether this functional dependency holds in the theoryrepresented by F .Proof. Let (cid:6) be the theory represented by F . The functional dependency X ! y does nothold in (cid:6) if and only if there exist (cid:11); (cid:12) 2 (cid:6) such that (cid:11)TXU D (cid:12)TXU and (cid:11)TyU 6D (cid:12)TyU. Letus introduce a new variable z0 for every z 2 V n .X [ y/, and let us denote by F 0 the CNFobtained from F by substituting y for y and z0 for z, for every z 2 V n .X [ y/. The CNFF 0 can be constructed in O.jXjjFj/ time by using an O.jXj/ time procedure for checkingwhether z 2 X. It can be seen easily that the functional dependency X ! y does not holdin (cid:6) if and only if the CNF F ^ F 0 is satisfiable, i.e., there exists a solution to the followingequation:F ^ F 0 D 1:(1)T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–3011The satisfiability problem (1) may not be Horn because of the substitution of y for y inF 0. It can, however, be solved in O.jFj/ time, since it is equivalent to the Horn satisfiabilityproblem obtained by substituting y D 1 in (1). Indeed, let F1 and F0 be the CNFs obtainedfrom (1) by substituting y D 1 and y D 0, respectively. Then (1) has a solution if and onlyif at least one of these two Horn satisfiability problems has a solution. One can easily seethat F1 can be obtained from F0 by substituting z VD z0 and z0 VD z for all z 2 V n .X [ y/.This means that F1 has a solution if and only if so does F0, which is also equivalent to thecondition that (1) has a solution. Thus, the linear time algorithm for the Horn satisfiabilityproblem (see [13]) can be employed to construct an O.jXjjFj/ time algorithm for checkingwhether a functional dependency holds in the theory represented by a Horn CNF. 2Corollary 3.2. Given a Horn CNF F and a functional dependency X ! y in the theoryrepresented by F , it can be checked in O.jXj2jFj/ time whether this functional dependencyis minimal.Proof. The procedure consists in removing variables from X one by one and checkingwhether the resulting functional dependency still holds. If the functional dependency is notminimal, a minimal one will be produced as a by-product of this procedure. 2Let us consider next the case in which we are given a set of models (cid:6). We would liketo check whether a given functional dependency holds in the Horn envelope H .(cid:6)/. Thefollowing lemma provides a structural characterization important for this situation. Let (cid:6) x0denote the set of all the models of (cid:6) that have the value 0 in x, i.e.,(cid:9):(cid:11) j (cid:11) 2 (cid:6); (cid:11)TxU D 0(2)D(cid:8)(cid:6) x0Similarly,(cid:6) x1D(cid:8)(cid:11) j (cid:11) 2 (cid:6); (cid:11)TxU D 1(cid:9):(3)Since we limit our attention to theories without unit implicates, both (cid:6) xempty for all variables x 2 V .0 and (cid:6) x1 are non-Lemma 3.3. A functional dependency X ! y holds in the Horn envelope H .(cid:6)/ of atheory (cid:6) if and only if there exists a subset X0 (cid:18) X such that the following two conditionshold:(1) all the points (cid:11) in (cid:6) y(2) for every point (cid:11) 2 (cid:6) y1 satisfy (cid:11)TX0U D .11 : : : 1/, and0 , there exists x 2 X0 such that (cid:11)TxU D 0.Proof. Let us denote by (cid:11)1 the point of H .(cid:6)/ obtained by the intersection of all the pointsin (cid:6) y1 . We will show below that the functional dependency X ! y does not hold in H .(cid:6)/if and only if there exists a point (cid:12)0 2 (cid:6) y0 such that (cid:11)1TXU 6 (cid:12)0TXU.The functional dependency X ! y does not hold in H .(cid:6)/ if and only if there exist(cid:11); (cid:12) 2 H .(cid:6)/ such that (cid:11)TXU D (cid:12)TXU and (cid:11)TyU 6D (cid:12)TyU. We can assume that (cid:11)TyU D 1 and(cid:12)TyU D 0. By the closure property of H .(cid:6)/, (cid:11) must have been obtained by the intersectionof some points in (cid:6) y1 , and therefore (cid:11)1 6 (cid:11). The point (cid:12) must have been obtained by12T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30the intersection of some points in (cid:6), with at least one point (cid:12)0 from (cid:6) yintersection. Obviously, (cid:12) 6 (cid:12)0. Then(cid:11)1TXU 6 (cid:11)TXU D (cid:12)TXU 6 (cid:12)0TXU:0 used in thisConversely, if (cid:11)1TXU 6 (cid:12)0TXU, then the point (cid:12) D (cid:11)1 \ (cid:12)0 satisfies (cid:12)TXU D (cid:11)1TXU and(cid:12)TyU D 0, while, obviously, (cid:11)1TyU D 1.Now there does not exist (cid:12)0 2 (cid:6) y0 such that (cid:11)1TXU 6 (cid:12)0TXU if and only if for every6D ;0 there exists a coordinate x 2 X such that (cid:12)TxU D 0 and (cid:11)1TxU D 1 (since (cid:6) y(cid:12) 2 (cid:6) yholds by the assumption that no unit clause exists in H .(cid:6)/).By construction, if (cid:11)1TxU D 1 then for every point (cid:11) 2 (cid:6) y1 we have (cid:11)TxU D 1. Finally, letX0 D fx 2 X j (cid:11)1TxU D 1g. Then it is easy to see that (cid:11)1TXU 6 (cid:12)0TXU holds if and only ifconditions (1) and (2) of the lemma hold. 20Corollary 3.4. A functional dependency X ! y is minimal in the Horn envelope H .(cid:6)/of a theory (cid:6) if and only if the following three conditions hold:(1) all the points (cid:11) in (cid:6) y(2) for every point (cid:11) 2 (cid:6) y(3) for every x 2 X, there exists a point (cid:11) 2 (cid:6) y1 satisfy (cid:11)TXU D .11 : : : 1/,0 , there exists x 2 X such that (cid:11)TxU D 0, and0 such that (cid:11)TxU D 0 and (cid:11)TX n xU D.11 : : : 1/.Proof. The first two conditions are the conditions of Lemma 3.3, and the third conditionstates that the removal of any variable from X results in a functional dependency thatviolates the second condition. 2Remark that in the case of a simple functional dependency we have X n x D ;, andtherefore condition (3) of the corollary trivially holds for simple functional dependencies.Since (cid:6) jD H .(cid:6)/, any functional dependency that holds in H .(cid:6)/ also holds in (cid:6). Onthe other hand, there may exist functional dependencies that hold in (cid:6) and do not hold inH .(cid:6)/. Interestingly, Corollary 3.4 implies that a minimal functional dependency in H .(cid:6)/is also a minimal functional dependency in (cid:6).As was noted in Section 2.2, one can check quickly whether a functional dependencyX ! y holds in a theory (cid:6), if all the models of (cid:6) are given. However, since the Hornenvelope H .(cid:6)/ may contain a number of models which is exponential in j(cid:6)j, this resultcannot be applied directly to recognizing whether X ! y holds in H .(cid:6)/. As a corollaryof the structural characterization in Lemma 3.3, we get the following result showing howto check fast whether X ! y holds in H .(cid:6)/.Theorem 3.5. Given a theory (cid:6) and a functional dependency X ! y, it can be checkedin O.jV jj(cid:6)j/ time whether this functional dependency holds in the Horn envelope H .(cid:6)/.Proof. Lemma 3.3 implies that the following linear time algorithm checks whether thedependency X ! y holds in H .(cid:6)/.(1) Split (cid:6) into (cid:6) y(2) Determine the maximum subset X0 (cid:18) X such that (cid:11)TX0U D .11 : : : 1/ for all (cid:11) 2 (cid:6) y1 .(3) For every (cid:12) 2 (cid:6) y0 , check whether there exists an x 2 X0 such that (cid:12)TxU D 0.0 and (cid:6) y1 .T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–3013The dependency X ! y does not hold in H .(cid:6)/ if and only if there exists a (cid:12) 2 (cid:6) ythat (cid:12)TX0U D .11 : : :1/. 20 suchCorollary 3.6. Given a theory (cid:6) and a functional dependency X ! y, it can be checkedin O.jV jj(cid:6)j/ time whether this functional dependency is minimal in the Horn envelopeH .(cid:6)/.Proof. Corollary 3.4 shows that checking the minimality consists in simply maintainingfor each x 2 X an indicator bit whose value is initialized at 0 and set to 1 whenever step (3)of the algorithm described in the proof of Theorem 3.5 encounters some (cid:12) 2 (cid:6) y0 such that(cid:12)TxU D 0 and (cid:12)TX n xU D .11 : : :1/. 2Interestingly, for a model representation, checking the minimality of a functionaldependency does not result in any discernible increase in the computing time as comparedwith checking whether the dependency holds. By contrast, Theorem 3.1 and Corollary 3.2suggest that the computing time for a CNF representation does increase, althoughmarginally.4. Structure of functional dependencies in Horn theoriesWe will analyze in this section structural properties of the set of minimal functionaldependencies that hold in an arbitrary Horn theory. We start this analysis by establishing aconnection between minimal functional dependencies in a Horn theory and certain primeimplicates of that theory.Theorem 4.1. A functional dependency X ! y holds and is minimal in a Horn theory (cid:6)if and only if all clauses y _ x, x 2 X, and the clause y _x2X x are prime implicates of(cid:6).WProof. Corollary 3.4 implies that a functional dependency X ! y is minimal in a Horntheory (cid:6) if and only if the following three conditions hold:(1) for every model (cid:11) 2 (cid:6) with (cid:11)TyU D 1, we have (cid:11)TXU D .11 : : : 1/;(2) for every model (cid:11) 2 (cid:6) with (cid:11)TyU D 0, there exists an x 2 X such that (cid:11)TxU D 0, and(3) for every x 2 X, there exists a model (cid:11) 2 (cid:6) such that (cid:11)TyU D 0, (cid:11)TxU D 0 and(cid:11)TX n xU D .11 : : : 1/.WLet us first discuss the “only if” part of the theorem. Condition (1) states that, for everyx 2 X, the clause y _ x is an implicate of (cid:6). Since we consider only theories without unitimplicates, every quadratic implicate is prime.Condition (2) states that the clause y _x2X x is an implicate of (cid:6), and condition (3)states that the removal of any literal x results in a clause which is not an implicate of (cid:6).x2X x is not an implicate of (cid:6), since otherwise y would be anFurthermore, the clausex2X.y _ x/), contradicting the assumption thatx2X x/ ^implicate of (cid:6) (implied by .(cid:6) has no unit implicate. Therefore, y _x2X x is prime.Let us now discuss the “if” part. The fact that the clause y _ x is an implicate of (cid:6) forx2X x is an implicate ofevery x 2 X implies condition (1). The fact that the clause y _VWWWW14T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30(cid:6) implies condition (2). The fact that for every x 2 X the clause y _implicate of (cid:6) implies condition (3). 2Wx02Xnx x0 is not anNote that this proof can be modified (using Lemma 3.3 instead of Corollary 3.4) to showthe following result.Theorem 4.2. A functional dependency X ! y holds in a Horn theory (cid:6) if and only if allclauses y _ x, x 2 X, and the clause y _x2X x are implicates of (cid:6).WNote that Theorems 4.1 and 4.2 provide a slightly different (from Theorem 3.1 andCorollary 3.2) way of checking whether a functional dependency X ! y holds (and isminimal) in the theory represented by a Horn CNF F . It consists in simply checking (e.g.,as described in [17,18]) whether y _x2X x and y _x, for all x 2 X, are (prime) implicatesof F .WCorollary 4.3. For a Horn theory (cid:6), the set of models of M.(cid:6)/ is a superset of (cid:6).Corollary 4.4. If a functional dependency X ! y is minimal in a Horn theory (cid:6), then,for every (cid:11) 2 (cid:6), we have (cid:11)TyU DVx2X (cid:11)TxU.This corollary states that minimal functional dependencies in Horn theories always takethe functional form of single positive term Boolean functions (i.e., y Dx2X x for someX), while minimal functional dependencies in general Boolean theories can be arbitraryBoolean functions without redundant 4 variables. To show the latter statement, for anyBoolean function without redundant variables f .X/, with jXj D n, we construct a theory(cid:6) with n C 1 variables fX; yg and 2n models obtained by adding to every (cid:11) 2 f0; 1gn the.n C 1/st coordinate y D f .(cid:11)/. One can easily see that X ! y is a minimal functionaldependency in (cid:6).VCorollary 4.5. A simple functional dependency x ! y holds in a Horn theory (cid:6) if andonly if the variables x and y are logically equivalent in (cid:6), i.e., (cid:11)TxU D (cid:11)TyU for all (cid:11) 2 (cid:6).Note that in the case of general Boolean theories without unit implicates, if x ! y holds,then either x and y are logically equivalent, or x and y are logically complementary, i.e.,(cid:11)TxU D (cid:11)TyU for all models (cid:11).To analyze the structure of functional dependencies in Horn theories, we shall associateto a set of of functional dependencies D a directed graph G.D/ whose set of vertices is theset of variables V , and an oriented arc x ! y is in G.D/ if and only if the set D contains afunctional dependency X ! y such that x 2 X. A similar construction was used in [38] inthe study of unique Horn satisfiability, and in [19] for the compression of Horn knowledgebases. The following statement establishes a fundamental structural property of the graphG.M.(cid:6)// of the set of all minimal functional dependencies in a Horn theory (cid:6).4 A variable is called redundant in a Boolean function if changing the value of only this variable never changesthe value of the function. It is well known that almost all Boolean functions do not have redundant variables.T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–3015Theorem 4.6. For a Horn theory (cid:6), the graph G.M.(cid:6)// has an oriented cycle involvingvariables x and y if and only if the simple functional dependencies x ! y and y ! x holdin (cid:6).Proof. Theorem 4.1 implies that if the arc x0 ! y0 is in G.M.(cid:6)//, then y0 _ x0 is a primeimplicate of (cid:6). Clearly, if y0 _ x0 and z0 _ y0 are implicates of (cid:6), then z0 _ x0 is also animplicate of (cid:6). Therefore, the existence of an oriented path from x to y in G.M.(cid:6)//implies that y _ x is a prime implicate of (cid:6). Similarly, the existence of an oriented pathfrom y to x implies that x _ y is a prime implicate of (cid:6). Then, by Theorem 4.1, bothx ! y and y ! x are minimal functional dependencies in (cid:6).Conversely, if simple functional dependencies x ! y and y ! x hold in (cid:6), then theyare minimal, and therefore G.M.(cid:6)// contains both arcs x ! y and y ! x. 2Theorem 4.6 and Lemma 2.3 imply the following corollary.Corollary 4.7. For a Horn theory (cid:6), every strongly connected component ofthegraph G.M.(cid:6)// is a complete directed graph, and any minimal non-simple functionaldependency in (cid:6) involves at most one variable from every strongly connected componentof G.M.(cid:6)//.Theorem 4.6 and Corollary 4.5 imply that all the cycles in G.M.(cid:6)// are due tothe presence of logically equivalent variables in (cid:6). Intuitively, a group of logicallyequivalent variables can be replaced by a single variable without losing any essentialinformation about a theory. This intuition was formalized in the procedure of 2-conden-sation introduced in [19] for the purpose of optimal compression of quasi-acyclic Hornknowledge bases. We call Horn theories without logically equivalent variables 2-con-densed.Given a Horn theory (cid:6), the procedure of 2-condensation constructs the 2-condensedHorn theory (cid:6) 2c by replacing each group of logically equivalent variables with a singlerepresentative. For a variable x 2 V , let us denote by r.x/ the representative of x in (cid:6) 2c.Note that if x and y are logically equivalent in (cid:6), then r.x/ D r.y/. Similarly, let r.X/denote the set of representatives of a set of variables X (cid:18) V . The following statement wasproven in [19].Proposition 4.8 (Hammer and Kogan [19]). A definite Horn clause y _implicate of a Horn theory (cid:6) if and only if either r.y/ _of the 2-condensed theory (cid:6) 2c, or X D fxg and x is logically equivalent to y in (cid:6).x2X x is a primex2X r.x/ is a prime implicateWWProposition 4.8 and Theorem 4.1 imply the following statement.Corollary 4.9. A functional dependency X ! y is minimal in a Horn theory (cid:6) if and onlyif either r.X/ ! r.y/ is a minimal functional dependency in the 2-condensed Horn theory(cid:6) 2c, or X D fxg and x is logically equivalent to y in (cid:6).This corollary shows that for most purposes itis sufficientto study functionaldependencies in 2-condensed Horn theories.16T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30If (cid:6) is represented by a Horn CNF F , then a prime Horn CNF representing (cid:6) 2c canbe constructed in O.jV jjFj C jFj2/ time (see [19]). The procedure consists in inferring allthe quadratic prime implicates of (cid:6), identifying groups of logically equivalent variables,reducing F to an equivalent prime CNF F 0, and replacing in F 0 equivalent variables fromthe same group with a single representative.If (cid:6) is represented by a set of models (cid:6) 0 such that H .(cid:6) 0/ D (cid:6), then any twovariables are logically equivalent in (cid:6) if and only if the corresponding columns in (cid:6) 0 areidentical. Therefore, removing all but one columns from every group of identical columnsin (cid:6) 0 results in (cid:6) 00 such that H .(cid:6) 00/ D (cid:6) 2c. This 2-condensation can be easily done inO.j(cid:6) 0jjV j/ by constructing a binary decision tree on the columns of (cid:6) 0, using each row of(cid:6) 0 one by one at the decision nodes, and then removing from (cid:6) 0 all but one column fromthe group of columns of every leaf in the resulting tree.The procedure of 2-condensation can be viewed as a restriction of the procedure ofcondensation introduced in Section 2.3, since 2-condensation is achieved if the procedureof condensation is applied using only simple functional dependencies. The condensationof Horn theories is discussed in detail in Section 6.Corollary 4.5 implies the following statement.Corollary 4.10. No simple functional dependency holds in a 2-condensed Horn theory.Theorem 4.6 and Corollary 4.10 imply the following important structural property offunctional dependencies in 2-condensed Horn theories.Theorem 4.11. For a 2-condensed Horn theory (cid:6) 2c, the graph G.M.(cid:6) 2c// contains nooriented cycles.The acyclicity of G.M.(cid:6) 2c// is a very important structural property of the Horn theoryrepresented by M.(cid:6) 2c/. Such Horn theories are called acyclic. They were studied in [19],where it was proven that any acyclic Horn theory has a unique irredundant and prime CNF.In view of the equivalence of sets of functional dependencies and definite Horn CNFs, thisresult together with Theorem 4.11 immediately imply the next theorem.Theorem 4.12. The set of functional dependencies holding in a 2-condensed Horn theoryhas a unique irredundant FD-cover.While the set of functional dependencies holding in a 2-condensed Horn theorycorresponds to an acyclic Horn theory, the set of functional dependencies holding ina general Horn theory corresponds to a quasi-acyclic Horn theory 5 (following theterminology of [19]). In this general case, the irredundant FD-cover will not be uniqueany more, but the results of [19] together with the presentation above show that all theirredundant FD-covers have essentially the same structure. An irredundant FD-cover of aHorn theory (cid:6) consists of the unique irredundant FD-cover of the 2-condensed theory (cid:6) 2c(with an arbitrary substitution of original variables for their representatives in (cid:6) c) and an5 A Horn theory is called quasi-acyclic if its 2-condensation is acyclic.T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–3017irredundant FD-cover of the set of simple functional dependencies in (cid:6). A minimum sizeirredundant FD-cover will be obtained when an irredundant FD-cover of the set of simplefunctional dependencies in (cid:6) is chosen to consist of dependencies forming a single simplecycle in each group of logically equivalent variables.5. Inferring functional dependencies in Horn theoriesIt follows from Corollary 4.9 that for the purpose of inferring functional dependenciesholding in a Horn theory, we can assume that the theory is 2-condensed. Although theirredundant FD-cover of any 2-condensed Horn theory is unique, this FD-cover can bevery large as compared with the length of the CNF representation of the theory.Theorem 5.1. For every n > 2, there exists a 2-condensed Horn theory of 2n C 1 vari-ables, which has the CNF representation of size O.n/ and the irredundant FD-cover ofsize 6 (cid:127).2n/.Proof. Consider the following Horn CNF:n^.xi _ x0/ ^n^.yi _ xi / ^x0 _n_!yi:iD1iD1iD1This CNF has 2n C 1 clauses and 5n C 1 literals. It can be checked that this is the uniqueirredundant prime CNF of the Horn theory it represents. It can also be checked that all itsquadratic prime implicates except .yi _ x0/, i D 1; 2; : : : ; n, are contained in this CNF,and the Horn theory is 2-condensed. One can verify that in addition to the quadraticprime implicates, the theory has 2n other prime implicates, each of which has the formWniD1 zi , with zi 2 fxi; yig. Then, by Theorem 4.1, the set of minimal functionalx0 _SniD1 zi !dependencies in this Horn theory consists of all the dependencies of the formx0, where zi 2 fxi; yig. Every dependency of this form is needed in the irredundant FD-cover, since it is not implied by other dependencies of this form. Therefore, the irredundantFD-cover consists of 2n minimal functional dependencies. 2A similar result can also be shown when a 2-condensed Horn theory is represented by aset of models.Theorem 5.2. For every n > 2, there exists a theory (cid:6) having size j(cid:6)j D O.n/ anddepending on 2n C 1 variables, such that its Horn envelope H .(cid:6)/ is a 2-condensed Horntheory whose irredundant FD-cover is of size (cid:127).2n/.Proof. Let us consider the following theory (cid:6) which has 2nC1 variables x1; x2; : : : ; x2nC1and 3n C 1 models. The variable x2nC1 has the value 1 only in the single model.1111 : : :11/. Among the remaining 3n models, there is a group of n models such that6 In the following we use the notation (cid:30) D (cid:127). / to denote that there exists a constant c such that (cid:30) > c . 18T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30in the ith model of this group the only variables that have the value 0 are x2i(cid:0)1 and x2i, inaddition to x2nC1. The remaining group of 2n models is such that in the ith model of thisgroup the only variable that has the value 1 is xi . Informally, (cid:6) can be given by(cid:6) D0BBBBBBBBBBBBBBBB@1 10 01 11 1::::::1 11 00 10 0::::::0 01 11 10 01 1::::::1 10 00 01 0::::::0 01 11 11 10 0::::::1 10 00 00 0::::::0 0(cid:1) (cid:1) (cid:1)(cid:1) (cid:1) (cid:1)(cid:1) (cid:1) (cid:1)(cid:1) (cid:1) (cid:1): : :(cid:1) (cid:1) (cid:1)(cid:1) (cid:1) (cid:1)(cid:1) (cid:1) (cid:1)(cid:1) (cid:1) (cid:1): : :(cid:1) (cid:1) (cid:1)1111:::0000:::11CCCCCCCCCCCCCCCCA1000:::0000:::0:Since all the columns of (cid:6) are distinct, its Horn envelope H .(cid:6)/ is 2-condensed. Bythe first statement of Lemma 3.3, no functional dependency holding in H .(cid:6)/ can havevariables x1; : : : ; x2n in the right-hand side, since for every i 6 2n there exists a model in(cid:6) in which the only variable that has the value 1 is xi .By the second statement of Lemma 3.3, any functional dependency holding in H .(cid:6)/(and therefore having x2nC1 in the right-hand side) should include in the left-hand sideeither x2i(cid:0)1 or x2i or both, since for every i 6 n there exists a model in (cid:6) in whichthe only variables that have the value 0 are x2i(cid:0)1, x2i, and x2nC1. Then, by the thirdstatement of Corollary 3.4, no minimal functional dependency holding in H .(cid:6)/ caninclude both x2i(cid:0)1 and x2i in the left-hand side. This implies that all the minimal functionalSniD1 yi ! x2nC1, where yi 2 fx2i(cid:0)1; x2ig.dependencies holding in H .(cid:6)/ are of the formEvery dependency of this form is needed in the irredundant FD-cover, since it is not impliedby other dependencies of this form. Therefore, the irredundant FD-cover consists of 2nminimal functional dependencies. 2Theorems 5.1 and 5.2 prove that the set of all minimal functional dependencies M.(cid:6)/of a Horn theory (cid:6) may be exponential in the length of the input, and hence cannot begenerated in polynomial time. It is therefore important to look for an alternative objectof smaller size that would capture some crucial information about M.(cid:6)/. An interestingaggregate description of this set is provided by generating for every variable y the set ofvariables F(cid:6) .y/ that take part in the minimal functional dependencies X ! y in (cid:6):F(cid:6) .y/ D fx 2 V j 9Z: xZ ! y 2 M.(cid:6)/g:(4)Clearly, the sets F(cid:6) .y/ provide a way of describing the graph G.M.(cid:6)// introduced inSection 4.We shall study below the computational complexity of generating F(cid:6) .y/ when a Horntheory is represented by a set of models and by a CNF. We first consider the Horn enveloperepresentation.T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–3019Theorem 5.3. Given a theory (cid:6), the set FH .(cid:6)/.y/ can be constructed in O.jV jj(cid:6)j2/ timefor every variable y 2 V .Proof. Let us define Xy (cid:18) V as the set of variables x such that all (cid:11) 2 (cid:6) y1 satisfy (cid:11)TxU D 1.By Corollary 3.4(1), we have FH .(cid:6)/.y/ (cid:18) Xy . Let us analyze now the requirementimposed by Corollary 3.4(2) and (3) on the points in (cid:6) yTXyU0contains a point with all 1’s, then FH .(cid:6)/.y/ is empty.TXyU. Note first that if (cid:6) y0Note that if X0 ! y is a functional dependency in H .(cid:6)/, then there exists X00 (cid:18) X0such that X00 ! y is a minimal functional dependency in H .(cid:6)/. Moreover, for any x 2 X0which has an (cid:11) 2 (cid:6) y0 such that (cid:11)TxU D 0 and (cid:11)TX0 n xU D .11 : : :1/, the set X00 must containthis x. It can then be shown that a variable x belongs to FH .(cid:6)/.y/ if and only if there existsan (cid:11) 2 (cid:6) y0 such that (cid:11)TxU D 0 and (cid:11)TXyU 6< (cid:12)TXyU for any other point (cid:12) in (cid:6) y0 . Indeed, ifsuch (cid:11) exists, then letX0 D Xy n fz 2 V j (cid:11)TzU D 0; z 6D xg:By Corollary 3.3, X0 ! y holds in H .(cid:6)/, and, as discussed above, every X00 (cid:18) X0, suchthat X00 ! y is a minimal functional dependency in H .(cid:6)/, must contain x. Conversely,let us assume by contradiction that for every (cid:11) 2 (cid:6) y0 such that (cid:11)TxU D 0, (cid:11)TXyU < (cid:13) TXyUholds for some point (cid:13) in (cid:6) y0 . Note that under this assumption, we can always find (cid:13) ’ssuch that (cid:13) TxU D 1. Indeed, if (cid:13) TxU D 0, then, by our assumption applied to (cid:13) , there mustexist (cid:13) 0 such that(cid:13) 0TXyU > (cid:13) TXyU > (cid:11)TXyU:Let us also assume that X (cid:18) Xy contains x, and X ! y is a minimal functional dependencyin H .(cid:6)/. Let (cid:11) 2 (cid:6) y0 be a point satisfying the requirement of Corollary 3.4(3). Byassumption, there must exist (cid:12) 2 (cid:6) y0 such that (cid:12)TXyU > (cid:11)TXyU and (cid:12)TxU D 1. Then this (cid:12)must violate the requirement of Corollary 3.4(2), contradicting the assumption that X ! yis a minimal functional dependency in H .(cid:6)/.Consequently, the set FH .(cid:6)/.y/ can be constructed by the following procedure:(1) Split (cid:6) into (cid:6) y(2) Determine the subset Xy of all x 2 V such that (cid:11)TxU D 1 for every (cid:11) 2 (cid:6) y1 .(3) Remove from (cid:6) y0TXyU every point (cid:11) such that (cid:11) < (cid:12) holds for some point (cid:12) in this0 and (cid:6) y1 .set; denote the resulting set byTXyU.(4) Place in FH .(cid:6)/.y/ every variable x 2 Xy such that there exists (cid:11) 2 c(cid:6) y0TXyU forc(cid:6) y0which (cid:11)TxU D 0.Steps (1), (2) and (4) of this algorithm have linear time complexity. Obviously, step (3)can be completed in O.jV jj(cid:6)j2/ time. 2Theorem 5.3 shows that the sets F(cid:6) .y/, and therefore the graph G.M.(cid:6)//, are easilyconstructible if a Horn theory (cid:6) is given by a set of models. We shall show next that thisproblem becomes computationally difficult if a Horn theory is represented by a Horn CNF.Problem: Horn-CNF-Aggregate-SetInstance: A Horn CNF F representing a Horn theory (cid:6), and two variables x and y.Question: Does x belong to F(cid:6) .y/?20T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30Theorem 5.4. The Horn-CNF-Aggregate-Set problem is NP-complete.Proof. One can easily see that the Horn-CNF-Aggregate-Set problem belongs to NP.Indeed, if a set X containing x is given, checking whether X ! y is a minimal functionaldependency in (cid:6) can be done in polynomial time, by Corollary 3.2.To show that the problem is NP-hard, we shall polynomially reduce the following NP-complete problem (see [32]) to our problem.Problem: Prime-Attribute-NameInstance: A definite Horn CNF F in variables x1; : : : ; xn.Question: Is there a negative prime implicate of F 0 D F ^ .WniD1 xi / containing x1?An instance of the Prime-Attribute-Name problem can be transformed to an instance ofthe Horn-CNF-Aggregate-Set problem in the following way. Let us consider the definiteHorn CNFF 00 D F ^y _n_iD1!xi^n^iD1. y _ xi/;where y is a new variable. We argue that the Horn-CNF-Aggregate-Set problem for theinput CNF F 00 representing a Horn theory (cid:6), and variables x1 and y, is equivalent tothe original instance of the Prime-Attribute-Name problem. Indeed, since F has no unitimplicates, each y _ xi is prime. Therefore, by Theorem 4.1, the variable x1 belongs toF(cid:6) .y/ if and only if (cid:6) has a prime implicate of the form y _ x1 _x2X x for someWx2X x is an implicate of F 00 if and only if the clauseX. Obviously, a clause y _ x1 _Wx1 _x2X x is a prime implicateWof F 00 if and only if the clause x1 _x2X x is a prime implicate of F 0. This establishesthe equivalence and completes the reduction. 2x2X x is an implicate of F 0. Therefore, a clause y _x1 _WWNote that the Horn-CNF-Aggregate-Set problem is closely related to the abductionproblem of determining whether a given variable occurs in a minimal explanation (see[41] and [28]).6. Condensation of Horn theoriesThe procedure of condensation introduced in Section 2.3 aims at simplifying a giventheory by eliminating variables that are functionally dependent on other variables. Inthe case of general Boolean theories the simplification provided by condensation maycome at a price. First of all, the functional dependencies used in condensation may havecomplicated structure which can make their storage and manipulation very expensivecomputationally. Second, the resulting condensed theory may depend on the choice offunctional dependencies to be used in condensation. We will show in this section that thecondensation of Horn theories does not present these problems.The computational feasibility and benefits of condensing Horn theories stem from thefact that functional dependencies in any Horn theory always have a very simple structure.Corollary 4.4 states that a minimal functional dependency X ! y is actually a single T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–3021positive term Boolean function: y Dstored and manipulated computationally.Vx2X x. This functional description can be easilySince a set of points closed under intersection will remain closed under intersection afterremoving any variables, a condensation of any Horn theory will be Horn. Therefore, theprocedure of condensation preserves the computationally advantageous Horn structure, andsimplifies the theory by removing the variables whose values are essentially superfluous.If a Horn theory is represented by a set of models, the representation of its condensationis obtained by removing the corresponding columns from the matrix, as was demonstratedin Section 2.5. As a result, for any theory (cid:6), its condensation using those functionaldependencies that hold in the Horn envelope H .(cid:6)/ will result in the condensed theory(cid:6) c such that H .(cid:6) c/ D H .(cid:6)/c.The condensation of a Horn theory represented by a Horn CNF is more involved. If aminimal functional dependency X ! y is used in condensation, thenx2X x has to besubstituted for y in all the clauses involving y. As a result, a Horn clause y _ C will bex2X x _ C, while a Horn clause y _ C will be transformedtransformed to the Horn clausex2X x _ C. This expression, however, is equivalent to theto the non-clausal expressionHorn CNF:WVV^^x _ C D.x _ C/:(5)x2Xx2XTherefore, the resulting CNF will remain Horn.WThe clausex2X x _ C may contain up to jXj (cid:0) 1 more literals than the original clausex2X.x _ C/ may have up to jXj times as many literals as they _ C, while the CNForiginal clause y _ C. This observation might hint that the length of a Horn CNF couldexplode in the condensation procedure.VLet us denote by Vi the set of variables of the Horn theory (cid:6)i produced at the ith stepof the condensation procedure.Lemma 6.1. For a Horn CNF F , the Horn theory (cid:6)i produced at the ith step of thecondensation procedure can be represented by a Horn CNF Fi whose length is limited byO.jVij2jFj/, and this bound is sharp.Proof. Note that every variable in V nVi can be expressed as a single positive term Booleanfunction of a subset of variables of Vi , since the superposition of positive terms is again apositive term:^^^if yi Dx;then z Dyi Dx2Xii2Ix:Si2I Xix2Therefore, instead of carrying out the condensation procedure step by step, we can achievethe same result if we first derive the expressions of all the variables of V n Vi through thevariables of Vi , and only then substitute all these expressions directly in the original CNFF and carry out the expansion (5) to obtain the Horn CNF Fi . Then one can see that thenumber of literals in each clause can increase by at most O.jVij/ and the number of clausescan increase at most by a factor of O.jVij/, resulting in the bound of the lemma.22T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30To demonstrate that the length of a CNF can actually increase proportionally to thesquare of the number of variables, consider for example the following Horn CNF:F Dn^iD1.x0 _ yi_ z0/ ^!n_iD1!zi _ z0^n^iD1.z0 _ zi/ ^n_iD1xi _ x0^.x0 _ xi/:n^iD1This CNF depends on 3nC2 variables, has 9nC2 literals, and can be seen to be irredundantSSnniD1 xi ! x0 are minimaliD1 zi ! z0 andand prime. It follows from Theorem 4.1 thatfunctional dependencies in the theory represented by F . Using these dependencies toeliminate the variables z0 and x0 by condensation results in the following Horn CNF:n^n^n_F c DiD1j D1kD1!xk _ yi_ zj:This CNF depends on 3n variables, and its length is n3 C 2n2. One can see that this CNFis the unique irredundant prime CNF of the Horn theory it represents. 2It follows from Lemma 6.1 that the condensation procedure can be implemented toproduce a Horn CNF of length at most O.jV j2jFj/. Although there is a possibility (inthe worst case) of a moderate polynomial increase in the length of a Horn CNF resultingfrom condensation, the next result proves that the potential reduction of the length of theCNF can be exponential.Theorem 6.2. For every n > 2, there exists a Horn theory of 2n variables, whose minimumCNF representation is of size (cid:127).2n/ but whose condensation has a CNF representation ofsize O.n/.PnProof. For a Boolean vector (cid:11) 2 f0; 1gn, let jj(cid:11)jj DiD1 (cid:11)i . Let us now consider thefollowing Horn CNF depending on 2n variables z, x1; : : : ; xn, and all y(cid:11), where (cid:11) 2 f0; 1gnand jj(cid:11)jj > 2:!^_F D(cid:11)2f0;1gnV jj(cid:11)jj>2^iV (cid:11)i D1^(cid:11)2f0;1gnV jj(cid:11)jj>2iV (cid:11)i D1xi _ y(cid:11)^!.y(cid:11)_ xi/^!xi _ z:n_iD1This CNF has n2n(cid:0)1 C 2n (cid:0) 2n clauses and 3n2n(cid:0)1 C 2n (cid:0) 3n literals. It can bechecked that F is irredundant and prime. Moreover, all the variables of the Horn theory (cid:6)represented by F are irredundant, and therefore the minimum CNF representation of (cid:6) isof size (cid:127).2n/.It follows from Theorem 4.1 that all minimal functional dependencies of the form[iV (cid:11)i D1xi ! y(cid:11);   T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–3023where (cid:11) 2 f0; 1gn with jj(cid:11)jj > 2, hold in (cid:6). The condensation of (cid:6) using these functionaldependencies results in the following Horn CNF:F c Dn_iD1xi _ z;which consists of a single clause having n C 1 literals. 2As was mentioned in Section 2.3 and demonstrated in Section 2.5, for general Booleantheories the result of the condensation procedure may depend on the order in whichfunctional dependencies are used. We will show next that the quasi-acyclicity of structureof functional dependencies in Horn theories makes the condensation procedure essentiallydeterministic.Simple functional dependencies, if hold at all in (cid:6), correspond to logically equivalentvariables (see Corollary 4.5). The order of elimination of these variables may affect onlywhich variable will be kept from each group of logically equivalent variables, and will notaffect the results of condensation using non-simple functional dependencies, as obviousfrom Lemma 2.3. We can therefore assume without loss of generality that the condensationprocedure uses simple functional dependencies first, i.e., the procedure of 2-condensationdescribed in Section 4 is finished first, and in what follows, (cid:6) is assumed to be 2-con-densed.Theorem 6.3. The condensation of a Horn theory (cid:6) does not depend on the order ofusage of functional dependencies, and the resulting theory (cid:6) c is unique up to the namesof representatives of logically equivalent variables of (cid:6).Proof. Let us consider the graph G.M.(cid:6)//. Every vertex of this graph which hasincoming arcs corresponds to a variable which appears as the right-hand side of some non-simple minimal functional dependencies. To show that the order of usage of functionaldependencies does not affect which variables are eliminated, it is sufficient to show thatif a variable x can be eliminated by condensation from (cid:6), then x can still be eliminatedby condensation from (cid:6) 0 obtained by eliminating another variable y. In other words, itis sufficient to show that if a variable x had an incoming arc before a minimal functionaldependency C ! y (where x 6D y) was used for condensation, then x would still have anincoming arc in the resulting graph of the reduced theory.Since the functional dependencies of the reduced theory are exactly those not involvingy, an incoming arc of x might disappear only if that arc was produced by the minimalfunctional dependencies of the form yC0 ! x. By Theorem 4.11, the graph G.M.(cid:6)//does not have oriented cycles, and therefore x =2 C. Then CC0 ! x is a nontrivialfunctional dependency which holds in (cid:6), and there exists a set C00 (cid:18) C [ C0 such thatC00 ! x is a minimal functional dependency holding in (cid:6). Since y =2 C00, this functionaldependency remains in the reduced theory, and x will have an incoming arc in the resultinggraph. 2The condensation of a Horn theory requires the knowledge of its functional dependen-cies. It was shown in Section 5 that the inference of all the minimal functional dependencies24T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30may be very expensive computationally, and even the construction of the graph G.M.(cid:6)//may be difficult if a Horn theory is represented by a Horn CNF. However, we show nowthat any Horn theory can be condensed in polynomial time.Let V c denote the variables remaining after the condensation procedure. It follows fromTheorem 6.3 that this set V c is uniquely defined.Theorem 6.4.(1) Given a theory (cid:6), the theory (cid:6) c such that H .(cid:6) c/ D H .(cid:6)/c, and the termsrepresenting all the variables in V n V c through the variables in V c, can beconstructed in O.jV j3j(cid:6)j/ time.(2) Given a Horn CNF F , a Horn CNF representing the condensation of the theoryrepresented by F , and the terms representing all the variables in V n V c throughthe variables in V c, can be constructed in O.jV j2jFj/ time.Proof. The underlying reason for this theorem is the fact that condensation can be carriedout using a very limited number of functional dependencies. More precisely, by the proofof Theorem 6.3, it is sufficient to construct a single minimal functional dependencyX ! y for every variable y to be eliminated. For every variable y 2 V such a minimalfunctional dependency can be easily found, if it exists at all. The procedure consists inchecking whether V n y ! y is a functional dependency, and if yes, then deriving aminimal functional dependency X ! y. It follows from Theorem 3.1 that, for the CNFrepresentation, this can be done for all the variables in O.jV j2jFj/ time. Theorem 3.5shows that, for the model representation, this will take O.jV j3j(cid:6)j/ time.The next step is to use the inferred functional dependencies to construct a subgraph G0of the graph G.M.(cid:6)//. Clearly, the variables V c that will remain after the condensationprocedure correspond to the vertices in G0 (and hence in G.M.(cid:6)//) that have no incomingarcs in G.M.(cid:6)//. Then we can start from V c, follow the arcs in G0, and superpose positiveterms to express every variable in V n V c as a single positive term Boolean function ofvariables in V c. Since the number of incoming arcs in every vertex cannot exceed jV j, theBoolean function in every vertex can be computed in O.jV cjjV j/ time, and all the verticesin the graph can be processed in O.jV j2jV cj/ time.For the model representation, the only remaining step is the elimination of columnscorresponding to the variables in V n V c. Since this can be done in linear time, and sinceO.jV j2jV cj/ 6 O.jV j3/, we have proven the bound of the first statement.For the CNF representation, we now have to substitute in F the functional expressionsfor all the variables in V n V c. Since every clause contains at most jV j literals, thesubstitution itself (without carrying out the expansion (5)) can be done in O.jV cjjFj/ time.Finally, the expansion (5) can be done in O.jV cj2jFj/ time, thus proving the bound of thesecond statement. 2It follows from Lemma 6.1 that the bound of Theorem 6.4(2) cannot be improved.While Theorem 6.3 states that the condensed theory is unique, the terms representing thevariables in V n V c may not be unique. Consider, for example, the following irredundantand prime Horn CNF:F D .x _ y _ z _ t/.t _ x/.t _ y/.t _ z/.u _ w _ t/.t _ u/.t _ w/:T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–3025Since uw ! t is a minimal functional dependency (see Theorem 4.1), the variable t canbe eliminated by condensation, which results in the following condensed CNF:F c D .x _ y _ z _ u/.x _ y _ z _ w/.u _ w _ x/.u _ w _ y/.u _ w _ z/:The eliminated variable t, however, can be expressed either as t D uw or as t D xyz. Thefirst term is shorter than the second one, and therefore is more efficient to use. It would beadvantageous to find the shortest possible terms for representing the variables in V n V c.Therefore, we shall study the computational complexity of the following two problems.Problem: Shortest-Term (CNF)Instance: A Horn CNF F , a variable x 2 V n V c, and a number k.Question: Can x be expressed through no more than k variables of V c?Problem: Shortest-Term (Models)Instance: A theory (cid:6) representing a Horn envelope H .(cid:6)/, a variable x 2 V n V c, and anumber k.Question: Can x be expressed through no more than k variables of V c?Clearly, both problems belong to NP, since if a term expressing y as a function of nomore than k variables in V c is given, one can easily check that all the variables in the termindeed belong to V c and the term corresponds to a functional dependency.We will show that both these problems are computationally difficult, using reductionsfrom the following well known NP-complete problem (see, e.g., [16]).Problem: Set-CoveringInstance: A 0–1 matrix A D .aij /l(cid:2)m and a number k.Question: Is there a 0–1 vector y D .y1; y2; : : : ; ym/ such thatinequalityAy > ePmj D1 yj 6 k and the(6)holds, where e is the l-dimensional all-one column vector?In the following, we can assume without loss of generality that the matrix A does nothave zero rows, and that no two columns of A are comparable, since the Set-Coveringproblem remains NP-complete under these conditions. Note that if no two columns of Aare comparable, then A does not contain all-zero or all-one columns, and it also does notcontain any identical columns.Theorem 6.5. The Shortest-Term .Models/ problem is NP-complete.Proof. Let us transform an arbitrary instance of the Set-Covering problem into an instanceof the Shortest-Term (Models) problem in the following way:0@ 1 1 : : : 1 1Jl(cid:2)m (cid:0) A Ol1A :(cid:6) DHere Ol is the l (cid:2) 1 zero matrix, and Jl(cid:2)m is the l (cid:2) m matrix whose elements are all 1’s.26T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30Let x be the variable corresponding to the last column of (cid:6). Since A does not havecomparable columns, it follows from Lemma 3.3(1) that all functional dependencies inH .(cid:6)/ have x in the right-hand side. Therefore, V c includes all the variables of (cid:6) exceptx. Lemma 3.3 (2) then implies that the left-hand side of every functional dependency of(cid:6) corresponds to a solution of (6), and vice versa every solution of (6) corresponds tothe left-hand side of a functional dependency of (cid:6). Therefore, H .(cid:6)/ has a functionaldependency with no more than k variables in the left-hand side if and only if the answer tothe Set-Covering problem is “yes”. 2Theorem 6.6. The Shortest-Term .CNF/ problem is NP-complete.Proof. We will use an instance of the Set-Covering problem to construct a Horn CNFdepending on l C m C 1 variables in the following way:l^l_m^^!F D_ x^.x _ yi/ ^.x _ zj / ^.yi _ zj /:yiiD1iD1j D1i;j V aij D1It can be checked that F is irredundant and prime, and it contains all the quadratic primeimplicates of the Horn theory (cid:6) it represents. In addition to the prime implicates in F , (cid:6)has prime implicates_ zj , j D 1; : : : ; m, and implicates of the formWliD1 yi___yizj _ x;i2Ij 2Jwhere I and J satisfy the condition that for every i 2 f1; : : : ; lg n I there exists a j 2 Jsuch that aij D 1.Since A does not have all-one columns, for every j 2 f1; : : : ; mg there exists ani 2 f1; : : : ; lg such that yi _ zj is not an implicate of (cid:6). Then it follows from Theorem 4.2that all functional dependencies in this Horn theory (cid:6) have x in the right-hand side, andare of the following form:[[yi [zj ! x;(7)i2Ij 2Jwhere I and J satisfy the condition that for every i 2 f1; : : : ; lg n I there exists a j 2 Jsuch that aij D 1. Thus, the set V c consists of l C m variables: yi, i D 1; 2; : : : ; l, and zj ,j D 1; 2; : : : ; m.Let us consider a functional dependency of the form (7). Since, without loss ofgenerality, A does not have zero rows, for every i 2 I there exists a j .i/ 2 f1; : : : ; mgsuch that yi _ zj .i/ is a prime implicate of (cid:6). Therefore, if a functional dependency (7)holds in (cid:6), then the functional dependency[Sj 2J [i2I j .i/zj ! xalso holds in (cid:6), and the cardinality of its right-hand side is(cid:12)(cid:12)(cid:12)(cid:12)J [[i2I(cid:12)(cid:12)(cid:12)(cid:12) 6 jJ j C jI j:j .i/ T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–3027Clearly, if I D ;, then there is a one-to-one correspondence between the sets J offunctional dependencies of the form (7) and the vectors y satisfying the inequality (6).Therefore, x can be expressed through no more than k variables of V c if and only if theanswer to the Set-Covering problem is “yes”. 27. Concluding remarksWe studied here functional dependencies in Horn theories, with the main emphasis oncomputational results and structural properties. We considered the representation of a Horntheory as a Horn CNF, and as the Horn envelope of a set of models. In both cases, one canrecognize in polynomial time whether a given functional dependency holds in a given Horntheory, while it is computationally difficult for a general CNF.We established a correspondence between minimal functional dependencies in a Horntheory and some prime implicates of the theory, and proved that the associated Horn theory(defined by all minimal functional dependencies) is a superset of the original Horn theory.It was also established that every functional dependency in a Horn theory has the functionalform of a single positive term, while a functional dependency in a general Boolean theorycan be an arbitrary Boolean function without redundant variables.We associated a directed graph with a set of functional dependencies, and proved thatsuch a graph associated with all minimal functional dependencies in a Horn theory is quasi-acyclic; i.e., all its cycles (if any) are created by the logically equivalent variables. It wasshown that this graph can be constructed in polynomial time if a Horn theory is representedas the Horn envelope of a set of models, while this construction becomes computationallydifficult if a theory is represented by a Horn CNF. We showed that the set of minimalfunctional dependencies (and even its minimum FD-cover) can be exponentially large ascompared with the size of both the CNF and the Horn envelope representations of a theory.We introduced the procedure of condensing a theory by eliminating those variablesthat are functionally dependent on other variables. In the case of general Booleantheories, the condensed theory may depend on the choice of functional dependenciesto be used in the condensation process, and the functional expressions of eliminatedvariables through the remaining variables may be too complicated to make condensationcomputationally advantageous. However, the condensation of a Horn theory is unique, andcan be constructed in polynomial time.In the research report version of this paper (see [22]) we develop further results aboutfunctional dependencies in Horn theories. We show how to recognize in polynomial timewhether a minimal functional dependency in a Horn theory belongs to all or only to someirredundant FD-covers of the theory, or does not belong at all to any irredundant FD-cover of the theory. We also consider the complexity of inferring all minimal functionaldependencies as a function of the size of the output, develop an incrementally polynomialalgorithm for inferring all minimal functional dependencies in a theory given as a HornCNF, and show that the existence of a polynomial total time algorithm for inferring allminimal functional dependencies in a theory given as the Horn envelope of a set of modelsis equivalent to the existence of a polynomial total time algorithm for the well knownproblem of dualizing a positive theory (see, e.g., [3]).28T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30The results presented in this paper can be extended in a straightforward way to a widerclass of so-called renamable Horn theories. A theory (cid:6) is called renamable Horn ifthe theory (cid:6) 0 resulting after substituting some variables in (cid:6) with their negations (i.e.,renaming some x’s as x’s) is Horn. If a renaming to make a theory Horn is known, thenthe theory can be transformed into a Horn form, and can be worked with as essentiallya Horn theory. It turns out that for some representations of a renamable Horn theorysuch renaming can be easily found. This is the case for the CNF representation: one canrecognize in polynomial time whether a given CNF can be renamed as Horn, and if yes,a renaming making it Horn can also be determined in polynomial time (see [8,31]). The“envelope-type” representation of a renamable Horn theory is not well defined in the sensethat the explicit knowledge of renaming is required to redefine the intersection closure. Ifall the models of a theory are given, then one can check in polynomial time if the theoryis renamable Horn. To see this, it is sufficient to use a given set of models for constructingin polynomial time (as described in [44]) a prime CNF representing this theory. One caneasily see that a theory is renamable Horn if and only if any of its prime CNFs can berenamed as a Horn CNF.It is obvious that if X ! y is a functional dependency in a theory (cid:6), then this functionaldependency will hold in any theory (cid:6) 0 obtained from (cid:6) by renaming some variables,i.e., no renaming changes the set of functional dependencies. However, the functionalform of the expression y D f .X/ will change in accordance with the renaming. In thecase of renamable Horn theories this functional form does not become significantly morecomplicated: it is either a single term or a single clause, which is not necessarily positiveany more.Renamable Horn CNFs and 2-CNFs (where each clause contains at most 2 literals)are well known classes of formulae for which the satisfiability problem can be solvedin polynomial time. These two classes turn out to be special cases of the class of so-calledq-Horn CNFs which were introduced and studied in [4,5,7]. It was shown that a q-HornCNF can be characterized by a special linear programming problem associated to the CNF,can therefore be recognized in polynomial time, and the q-Horn satisfiability problem canbe solved in polynomial time. In a forthcoming paper [23], we study q-Horn theoriesand show that functional dependencies in a q-Horn theory still have the form similar tofunctional dependencies in a renamable Horn theory, i.e., they are either a single term or asingle clause.AcknowledgementsThe authors extend their thanks for the partial support provided by the Office of NavalResearch (grant N00014-92-J1375). A part of this work was done during the secondauthor’s visit at Kyoto University, which was supported by a Scientific Grant in Aid by theMinistry of Education, Culture and Sports of Japan. The authors are grateful to ThomasEiter for his useful comments. The authors also express their gratitude to the anonymousreferees whose constructive comments helped significantly improve this paper.T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–3029References[1] W.W. Armstrong, Dependency structures of database relationships, in: Proceedings IFIP-74, North-Holland,Amsterdam, 1974, pp. 580–583.[2] C. Beeri, M. Dowd, R. Fagin, R. Statman, On the structure of Armstrong relations for functionaldependencies, J. ACM 31 (1) (1984) 30–46.[3] J.C. Bioch, T. Ibaraki, Complexity of identification and dualization of positive Boolean functions, Inform.and Comput. 123 (1995) 51–75.[4] E. Boros, Y. Crama, P.L. Hammer, Polynomial time inference of all valid implications for Horn and relatedformulae, Ann. Math. Artificial Intelligence 1 (1990) 21–32.[5] E. Boros, Y. Crama, P.L. Hammer, M. Saks, A complexity index for satisfiability problems, SIAM J. Comput.23 (1994) 45–49.[6] E. Boros, O. ˇCepek, A. Kogan, Horn minimization by iterative decomposition, Ann. Math. and ArtificialIntelligence 23 (3–4) (1998) 321–343.[7] E. Boros, P.L. Hammer, X. Sun, Recognition of q-Horn formulae in linear time, Discrete Appl. Math. 55(1994) 1–13.[8] V. Chandru, C.R. Coullard, P.L. Hammer, M. Montañez, X. Sun, On renamable Horn and generalized Hornfunctions, Ann. Math. Artificial Intelligence 1 (1990) 33–47.[9] C.L. Chang, R.C.T. Lee, Symbolic Logic and Mechanical Theorem Proving, Academic Press, New York,1973.[10] E.F. Codd, A relational model for large shared data banks, Comm. ACM 13 (1970) 377–387.[11] R. Dechter, J. Pearl, Structure identification in relational data, Artificial Intelligence 58 (1992) 237–270.[12] C. Delobel, R.G. Casey, Decomposition of a data base and the theory of Boolean switching functions, IBMJ. Res. Development 17 (1973) 374–386.[13] W.F. Dowling, J.H. Gallier, Linear time algorithms for testing the satisfiability of propositional Hornformulae, J. Logic Programming 3 (1984) 267–284.[14] R. Fagin, Functional dependencies in a relational database and propositional logic, IBM J. Res. Development21 (1977) 534–544.[15] R. Fagin, Horn clauses and database dependencies, J. ACM 29 (4) (1982) 952–985.[16] M.R. Garey, D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-Completeness,Freeman, San Francisco, CA, 1979.[17] P.L. Hammer, A. Kogan, Horn functions and their DNFs, Inform. Process. Lett. 44 (1992) 23–29.[18] P.L. Hammer, A. Kogan, Optimal compression of propositional Horn knowledge bases: Complexity andapproximation, Artificial Intelligence 64 (1993) 131–145.[19] P.L. Hammer, A. Kogan, Quasi-acyclic propositional Horn knowledge bases: Optimal compression, IEEETrans. Knowledge and Data Engineering 7 (1995) 751–762.[20] P.L. Hammer, A. Kogan, Essential and redundant rules in Horn knowledge bases, Decision Support Systems16 (2) (1996) 119–130.[21] A. Horn, On sentences which are true of direct unions of algebras, J. Symbolic Logic 16 (1951) 14–21.[22] T. Ibaraki, A. Kogan, K. Makino, Functional dependencies in Horn theories, RUTCOR Research ReportRRR 14–98, Rutgers University, New Brunswick, NJ, 1998.[23] T. Ibaraki, A. Kogan, K. Makino, Functional dependencies in q-Horn theories, Manuscript, 1998.[24] H. Kautz, M. Kearns, B. Selman, Horn approximations of empirical data, Artificial Intelligence 74 (1995)129–145.[25] H. Kautz, M. Kearns, B. Selman, Forming concepts for fast inference, in: Proc. AAAI-92, San Jose, CA,1992, pp. 786–793.[26] D. Kavvadias, C.H. Papadimitriou, M. Sideri, On Horn envelopes and hypergraph transversals, in: K.W. Nget al. (Eds.), Algorithms and Computation—ISAAC-93, Lecture Notes in Computer Science, Vol. 762,Springer, Berlin, 1993, pp. 399–405.[27] R. Khardon, Translating between Horn representations and their characteristic models, J. ArtificialIntelligence Res. 3 (1995) 349–372.[28] R. Khardon, H. Mannila, D. Roth, Reasoning with examples: Propositional formulae and databasedependencies, Acta Informatica (1998) to appear. (Preliminary version: Technical Report TR-15-95, AikenComputation Laboratory, Harvard University, Cambridge, MA, 1995.)30T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30[29] R. Khardon, D. Roth, Reasoning with models, Artificial Intelligence 87 (1996) 187–213.[30] J. Kivinen, H. Mannila, Approximate inference of functional dependencies from relations, Theoret. Comput.Sci. 149 (1995) 129–149.[31] H.R. Lewis, Renaming a set of clauses as a Horn set, J. ACM 25 (1978) 134–135.[32] C.L. Lucchesi, S.L. Osborn, Candidate keys for relations, J. Comput. System Sci. 17 (1978) 270–279.[33] D. Maier, The Theory of Relational Databases, Computer Science Press, Rockville, MD, 1983.[34] H. Mannila, K.-J. Räihä, Design of Relational Databases, Addison-Wesley, Wokingham, 1992.[35] H. Mannila, K.-J. Räihä, Algorithms for inferring functional dependencies, Data and Knowledge Engineer-ing 12 (1994) 83–99.[36] J.C.C. McKinsey, The decision problem for some classes of sentences without quantifiers, J. Symbolic Logic8 (3) (1943) 61–77.[37] M. Minoux, LTUR: A simplified linear-time unit resolution algorithm for Horn formulae and computerimplementation, Inform. Process. Lett. 29 (1988) 1–12.[38] M. Minoux, The unique Horn-Satisfiability problem and quadratic Boolean equations, Ann. Math. ArtificialIntelligence 6 (1992) 253–266.[39] Y. Sagiv, C. Delobel, D.S. Parker, R. Fagin, An equivalence between relational database dependencies and afragment of propositional logic, J. ACM 28 (3) (1981) 435–453.[40] B. Selman, H. Kautz, Knowledge compilation and theory approximation, J. ACM 43 (2) (1996) 193–224.[41] B. Selman, H.J. Levesque, Support set selection for abductive and default reasoning, Artificial Intelligence82 (1996) 259–272.[42] J.D. Ullman, Principles of Database and Knowledge-Base Systems, Vol. I: Classical Database Systems,Computer Science Press, New York, 1988.[43] J.D. Ullman, Principles of Database and Knowledge-Base Systems, Vol. II: The New Technologies,Computer Science Press, New York, 1989.[44] Yu.I. Zhuravlev, A. Kogan, Realization of Boolean functions with a small number of zeros by disjunctivenormal forms and related problems, Soviet Mathematics—Doklady 32 (3) (1985) 771–775.