ELSEVIER Artificial Intelligence 86 (1996) l-41 Artificial Intelligence Variable and value ordering heuristics for the job shop scheduling constraint satisfaction problem * Norman Sadehav*, Mark S. Fox b~l a School of Computer Science, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213-3891, USA ’ Department of Industrial Engineering, University of Toronto, 4 Taddle Creek Road, Toronto, Ont., Canada M5S IA4 Received April 1992; revised August 1995 Abstract Practical constraint satisfaction problems (CSPs) such as design of integrated circuits or scheduling generally entail large search spaces with hundreds or even thousands of variables, each with hundreds or thousands of possible values. Often, only a very tiny fraction of all these possible assignments participates in a satisfactory solution. This article discusses techniques that aim at reducing the effective size of the search space to be explored in order to find a satisfactory solution by judiciously selecting the order in which variables are instantiated and the sequence in which possible values are tried for each variable. In the CSP literature, these techniques are commonly referred to as variable and value ordering heuristics. Our investigation is conducted in the job shop scheduling domain. We show that, in contrast with problems studied earlier in the CSP literature, generic variable and value heuristics do not perform well in this domain. This is attributed to the difficulty of these heuristics to properly account for the tightness of constraints and/or the connectiviv of the constraint graphs induced by job shop scheduling CSPs. A new probabilistic framework is introduced that better captures these key aspects of the job shop scheduling search space. Empirical results show that variable and value ordering heuris- tics derived within this probabilistic framework often yield significant improvements in search efficiency and significant reductions in the search time required to obtain a satisfactory solution. The research reported in this article was the first one, along with the work of Keng and Yun ( 1989), to use the CSP problem solving paradigm to solve job shop scheduling problems. The suite of benchmark problems it introduced has been used since then by a number of other *This research was supported, in part, by the Advanced Research Projects Agency under contract #F30602- 88-C-0001 and Digital Equipment Corporation. from McDonnell Aircraft Company and #F30602-91-F-0016, and in part by grants * Corresponding I E-mail: msf@ie.utoronto.ca. author. E-mail: sadeh@cs.cmu.edu. 0004-3702/96/$15.00 SSDI0004-3702(95)00098-4 Copyright @ 1996 Elsevier Science B.V. All rights reserved. 2 N. Sudeh, M.S. Fh/Artijiicial Intelligence 86 (I 996) l-41 to evaluate alternative for the job shop scheduling CSP The article briefly researchers reviews some of these more recent efforts and shows that our variable and value ordering heuristics remain quite competitive. techniques 1. Introduction (e.g. ( CSPs) (e.g. [ 10,39,52] Practical constraint satisfaction problems such as design problems [ 3 1, 491) or scheduling problems ) generally entail large search spaces with hundreds or even thousands of variables, each with several hundred or thousand possible values. Often, only a very tiny fraction of all these possible assignments in amounts of search before one a satisfactory the such solution that aim at reducing effective in selecting in which possible values are tried which variables to as these techniques In the CSP literature, for each variable. variable and value ordering heuristics. Our investigation in the job shop scheduling domain solution, potentially can be found. This article discusses are commonly is conducted to be explored by judiciously size of the search space requiring prohibitive and the sequence are instantiated [ 2, 12,261. participates techniques the order referred Specifically, we study a class of job shop scheduling problems in which operations [ 11,39,42,44]. time windows factory scheduling problems, We refer to satisfaction problem or job shop CSP. in which some oper- scheduling have to be performed within non-relaxable this class of problems as the job shop constraint Examples of job shop CSPs include ations have to be performed within one or several shifts, spacecraft mission problems, in which time windows are determined by astronomical factory rescheduling have no control, to be rescheduled without disturbing a job shop CSP, the objective a schedule where each operation no resource adapted reduce to relaxable due dates events over which we in which a small set of operations need problems, the schedule of other operations, etc. When solving is to find as quickly as possible a feasible schedule, namely is performed within one of its legal time windows and in this paper have also been is to the sum of tardiness and inventory costs of a set of jobs to be processed subject job shop scheduling problems, where The techniques presented to solve just-in-time is oversubscribed. the objective [ 39,401. The job shop CSP can easily be shown of any procedure enforcing mechanisms worst-case complexity nential. At the time we started consistency to yield ported different CSPs determine such as those found important [ 6,9, 11,13, 17,23,29,37,5 increases this study, CSP techniques to be NP-complete to solve this problem [ 141. Accordingly, is expected that interleave the to be expo- search with ordering heuristics had been re- to a number of 11. One of the objectives of our study was to and variable/value in search efficiency when applied if similar results could be obtained on large-scale tightly connected problems in the job shop scheduling domain. In this article, we first review generic variable and value ordering heuristics that have to perform well on other classes of CSPs. We explain why these heuristics like job shop to perform as well on large-scale for In particular, we show that these heuristics been reported are unlikely scheduling. tightly connected CSPs fail to adequately account N. Sadeh, M.S. Fox/Artificial Intelligence 86 (1996) 1-41 3 operations). solving paradigm indicate that attempt to better account a probabilistic are defined framework, within which new variable the tightness of constraints and/or induced by the high connectivity for the interactions of the constraint graphs characteristic of job shop CSPs. 2 The second part of this paper and value ordering introduces heuristics interactions. Empirical results more specialized heuristics [ 201. Our study suggests ability of the probabilistic on the availability reliance of an operation on the availability between variables measures of resource contention between unscheduled that our new heuristics outperform both generic CSP heuristics as well as CSPs for resource- and time-constrained these more powerful heuristics lies in the to provide estimates of the reliance of a variable the in job shop scheduling, and measures of contention framework of one of its remaining recently developed that a key to defining (e.g., of a reservation) values (e.g., in job shop scheduling, for the allocation of incompatible for these values that the CSP problem While our work shows large-scale domains considered does scale up to that benchmark complex problems of this and probably in earlier CSP studies are not representative other classes of complex CSPs. We hope that this research will prompt others in the field to evaluate to revisit earlier studies and look for more challenging their techniques. such as the job shop CSP, it also suggests problems on which is organized in Section 7. Empirical The balance of this paper as follows. Section 2 provides a formal defi- the backtrack search procedure nition of the job shop scheduling CSP Section 3 details in Sec- used in our study. Generic variable and value ordering heuristics are reviewed tions 4 and 5 respectively. Section 6 describes new variable and value ordering heuristics based on a probabilistic model of the search space. The complexity of these heuristics our new heuristics with other is discussed heuristics discussed in this article was the first one, along with that of Keng and Yun [ 201, to use the CSP prob- lem solving paradigm to solve job shop scheduling problems. The suite of benchmark to problems it introduced evaluate alternative re- views some of these more recent efforts and shows that our variable and value ordering heuristics Section 9 provides a summary of the paper and further discusses then been used by a number of other researchers for the job shop scheduling CSl? Section 8 briefly in Section 8. The work reported in this paper are presented remain quite competitive. results comparing techniques has since of this study. the implications Earlier variations of the techniques presented in this paper are discussed in [ 11,38, 39,41-441. 2. The job shop constraint satisfaction problem The job shop CSP requires a set of jobs .I = {jt , . . . , j,,} on a set of physical 0’ = {O{,.. resources RES = {RI, scheduling . . . , R,}. Each job according . , Of,,} to be scheduled to a process routing that specifies a j, consists of a set of operations * Constraint graphs are graphical representations of binary CSPs (i.e. CSPs with binary constraints) each variable Other graphical is represented representations by a node, and binary constraints also exist for non-binary CSPs. are represented by arcs between in which two nodes. 4 N. Sadeh. M.S. Fkr/Art$ciui lntellrpwce 86 (I 996) I-41 j, j, 0: 0: 0: Fig. I. Examples of tree-like process routings. these operations partial ordering among shop CSPs with tree-like process routings. A tree-like process routing of precedence situation, especially paper to more general forms a tree (see Fig. 1). This job is one whose graph is by far the most common in this in factory scheduling. Extensions of the techniques presented types of process routings will be briefly discussed as well. (e.g. 0; BEFORE 0:). This study assumes constraints in this paper, each job In the job shop CSP studied (or deadline) j, has a release date rdr and ddl between which all its operations have to be performed. a due date Each operation Of has a fixed duration duj and a start time sd whose value has to be is initially constrained by selected. The domain of possible start times of each operation If necessary, the release and due dates of the job the unary constraints the set of admissible model allows for additional thereby defining one or several time windows within which start times of each operation, In order an operation has to be carried out (e.g. a specific shift in factory scheduling). to be successfully (e.g. a executed, each operation Of requires P,! different milling machine, a set of fixtures and a machinist) Rf, ( 1 < j < p(), for each of which there may be a pool of physical from which to choose, the operation belongs. that further restrict to which resources resources @, = { rijl , . t-i,,’ >, ‘J with ri,x l RES ( I 6 k < qi, ) ( e.g. several possible milling machines). More formally, the problem can be defined as follows: Vuriables A vector of variables (or aggregate variable) is associated with each operation, 0: ( 1 < 1 < ?I, I < i < nl), which consists of ( 1 ) the operation start time, stf, and (2) its resource requirements, Rf, ( 1 < ,i 6 pi ). N. Sadeh, M.S. Fox/Artijicial Intelligence 86 (1996) 1-41 5 In our search procedure, whose start time and resource instantiations resource assignments, associated with an operation, namely to as a reservation is referred each operation requirements is considered are simultaneously a single (aggregate) variable instantiated. A tuple of a start time and a set of specific for that operation. Constraints The non-unary ( 1) Precedence constraints of the problem are of two types: routings constraints defined by the process equalities of the type: s4 + duf 6 st$ (i.e. Of BEFORE 0;). translate into linear in- (2) Capacity constraints at a time translate that restrict into disjunctive the use of each resource to only one operation constraints of the form: (VpVq RL # R:9) V szf’ + du$ < sti V st$ + du$ < s$. These constraints simply express that, unless they use different resources, two operations 0: and Of cannot overlap. for any there are unary constraints restricting include non-relaxable Additionally, variables. These constraints dates, between which all operations allows times of an operation. As a result, will generally operation has to start. Time is assumed discrete, can only the set of possible values of individual and release due dates (or deadlines) in a job have to be scheduled. The model actually start start times of an operation time windows within which the start times and end times requirement Rfi has to be selected that further the domain of possible take integer values. Finally, each resource consist of one or several non-contiguous type of unary constraint the set of possible i.e. operation restricts from a set of resource alternatives .ni,. c RES. Objective In the job shop CSP studied in this paper, the objective solution as fast as possible. Notice that this objective the number of search states visited. deciding which search state to explore next. It also accounts Example is to come up with a feasible from simply minimizing is different for the time spent by the system resource requirement with a single possible value. Operation Fig. 2 depicts a simple job shop scheduling problem with four jobs J = {j, , j2, js , jd} each operation resources RES = {RI, Rz, R3, Rd}. In this example, start times that all operations have that all jobs are released at time 0 and None that will be discussed: release and due dates, operations can have different durations, for each of these requirements. and four physical has a single are the only variables. For the sake of simplicity, the same duration, namely have to be completed of these simplifying jobs usually have different several resource However number of heuristics discussed the merits of a in this paper. When appropriate, we will consider slight by time 15 (the minimum makespan of this problem).3 this example will often prove sufficient are required by the techniques and several alternatives it is assumed requirements, assumptions time units, to contrast simple, three 3 The makespan of a schedule is the length of the time interval that spans from the earliest operation start time to the latest operation end time [ 21. 6 N. Strdeh. M.S. Fox/Art~Jmczl lntellipnce 86 (I 996) l-41 j 1 i j 3 j 4 C, Pi capacity constraint ) precedence constraint Fig. 2. A simple job shop problem with four jobs. Each node is labeled by the operation the resource required by this operation. that it represents and to discuss issues that would not be immediately visible variations of this base problem otherwise. Notice operations duration, in this problem, resource R2 is expected that, (one from each job). Since all operations resource R2 is the only one to be required by four the same in the example have to be a small bottleneck.’ 3. The search procedure A general paradigm Variables or groups of variables [ 3,16,35,50]. stantiated. Each search state is created process goes on until either a complete is reached. A deadend violating one or several problem for solving CSPs relies on the use of depth-first backtrack search in- a new (or group of variables) to a new, more complete, partial solution. This state state is one whose partial solution cannot be completed without state, the procedure time a new variable that corresponds is obtained or until a deadend constraints. When (i.e. subproblems) are successively is instantiated, in a deadend solution ’ Informally, a bottleneck is a resource or group of resources whose utilization is expected to be close to or larger than its available capacity. N. Sadeh, M.S. Fox/Artificial Intelligence 86 (1996) I-41 7 has to undo one or several assignments (otherwise known able. the problem as backtracking. is infeasible). It results and try alternative ones, This process of undoing if there are any left is earlier assignments in lower search efficiency, and, hence, is undesir- In the worst case, exponential amounts of backtracking may be necessary to come up with a feasible solution can be improved by interleaving mechanisms (schedule). and variable/value enforcing l Consistency ordering heuristics: (checking) techniques: These In practice, search with the application the average complexity of the procedure enforcing of consistency space by eliminating [23]. This problem empty, a deadend formulation. l Variablelvalue local inconsistencies is done by inferring new constraints If, during this process, situation has been identified. that cannot participate techniques prune the search in a global solution to the current them the domain of a variable becomes and adding ordering heuristics: These heuristics are concerned with the order in to each variable. As discussed of this paper, these heuristics can have a great impact on search and values assigned which variables are instantiated in the remainder efficiency. In this study, we consider a depth-first search procedure that starts in a state where all still have to be scheduled and proceeds by scheduling operations one by one in which a a new search state is created is scheduled, enforcing procedure updates to account to schedule operations (Fig. 3). Each time an operation consistency operations operation eration all operations have been successfully is detected. backtrack). search state), The results In the latter case, If there are no decisions the problem reported is infeasible the set of possible reservations of unscheduled for the latest assignment. Next, the procedure determines which to that op- and which reservation (variable ordering) itself, until either (or deadend) (i.e. is back in the initial to undo one or several earlier decisions scheduled or until an inconsistency left to undo (i.e. the procedure to assign it needs calling and the procedure terminates. in this study were obtained using a simple chronological that systematically reservations goes back for that operation. to the most recently If no alternative goes back to the next most recently scheduled operation back- scheduled op- reservation and (value ordering). The procedure goes on, recursively tracking mechanism eration and tries alternative is left, so on. the procedure 1. If all operations have been scheduled 2. Apply 3. If a deadend enforcing procedure. then backtrack the consistency is detected then stop, else go on to 2. (i.e. select an alternative if there is one left and go back to 1, else stop and report that the problem else go on to step 4. is infeasible), the next operation 4. Select 5. Select a promising 6. Create a new search state by adding reservation to be scheduled for that operation (value ordering heuristic). the new reservation assignment to the (variable ordering heuristic). current partial schedule. Go back to 1. Fig. 3. Depth-first backtrack search procedure. N. Sudeh. M.S. t;ox/Artificiul Intelligence 86 (1996) l-41 Before propagation Downstream Propagation Upstream Propagation / ,--- LO,81 [3,111 [7,151 ) precedence constraint Fig. 4. Consistency with respect to precedence constraints. Consistency (I! enforcing in our procedure combines three types of computations: constraints: Consistency with respect is linear constraints is maintained using a longest path procedure operation. Essentially, as in PERT/CPM in each search state, a pair of earliest/latest are propagated downstream within are propagated upstream to that incre- possible start times [ 181, earliest start the job whereas latest start (Fig. 4). The complexity of this sim- In Consistency with respect to precedence precedence mentally updates, for each unscheduled time constraints time constraints ple propagation mechanism the absence of capacity constraints require the same resource), posability backtrack-free Forward consistency checks with respect to capacity constraints: Enforcing sistency with respect to capacity constraints nature of these constraints. Whenever a resource some time interval, a “forward checking” mechanism remaining possible and removes first proposed in which no two operations to guarantee decom- to guarantee con- is more difficult due to the disjunctive in the number of precedence (e.g. problems those reservations in [ 2 I ] (see Fig. 5 ) to an operation over the set of that same resource, as that would conflict with the new assignment, in each search state, it is sufficient i.e., if applied [ 391. reservations of other operations [ 17,291 checks can be shown the procedure is allocated constraints. requiring search [ 5,8], (2) N. Sadeh, M.S. Fox/Art$cial Intelligence 86 (1996) 1-41 9 Before propagation: [ 7 , 15 ] , 15 ] After propagation: [ 10 scheduled to start at time 6 --____ capacity constraint Fig. 5. Forward consistency checks with respect to capacity constraints. (3) Additional consistency checks with respect to capacity constraints: Additionally, our consistency enforcing mechanism checks that no two unscheduled operations intervals. An example of such a situation require overlapping resource/time the same resource, 0: in Fig. 6, where is illustrated start and Ofi, rely on the availability intervals. Whichever requiring time two operations of overlapping I I I 0versub;cribed interval I est : 1st: estl J 1st: eft: eft’ J lftr lft: time m m earliest possible reservation latest possible reservation time interval absolutely required by the operation, whatever its start time Fig. 6. Detecting situations where two unscheduled operations requiring the same resource are in conflict for operation 0; require time is selected this operation will always between operation 0: will always its earliest/latest (within its resource over the time interval start time window), that spans ([ Ist;k,eff]). Similarly, its latest start require that same resource between its latest start time and its earliest finish time time and its earliest finish lime (interval [Is<,eft:]). Interval [LY$,&] and [ Ls~,~ff~ J overlap. This represents a capacity constraint consistency mechanism. which enforces a higher forward checking while only resulting conflict. This additional than has been shown to often increase search efficiency, level of arc-consistency in minor computational [ 17,24,29], overheads [ 391. Because it is only possible to efficiently enforce partial consistency with respect to sometimes occur. In other words, the scheduling reach a search state, in which several unscheduled operations left, while ac- to each have some possible is actually to simultaneously reservations insufficient backtracking will for a resource appear capacity constraints, procedure will sometimes competing the total capacity available on the resource commodate with respect to precedence respect constraint violations. constraints), all these operations. Notice, however, is sufficient to precedence constraints backtracking that because consistency enforcement (with can only occur as the result of capacity to guarantee decomposability to efficiently guarantee backtrack-free it is impossible Because CSPs, variable actual complexity variable specialized heuristics job shop scheduling problems. and value ordering heuristics are generally of the search procedure. The next and value ordering heuristics developed critical search for job shop the in determining examine popular for generic CSPs as well as more to two sections and identify key weaknesses of these heuristics when applied 4. A look at some popular variable ordering heuristics A powerful way of reducing the average complexity search of backtrack is to ju- is that, by search will generally avoid building par- the chances first can also help state that is not later on. This reduces difficult variables is in a deadend in which variables are instantiated. The intuition select to complete first, backtrack that the frequency) the amount of backtracking when the order difficult variables it will not be able of backtracking. diciously instantiating tial solutions (i.e. reduce immediately difficult variables, detect. This reduces that cannot be completed. One can distinguish ( 1) Fixed variable ordering heuristics: A unique variable ordering the time the system wastes attempting detected by its consistency checking mechanism. Instantiating the system between the system moves to more constrained deadend states that are easier to two broad types of variable ordering heuristics: to complete partial solutions Indeed, by instantiating is determined prior to starting the search and used in each branch of the search tree. (2) Dynamic variable ordering heuristics: The ordering each search state in order to account in the search tree generally entail different variable orderings. in for earlier assignments. Different branches is dynamically revised N. Sadeh, MS. Fox/Artijicial Intelligence 86 (1996) 1-41 11 since require Clearly, less computation such as N-queens fixed variable orderings or on moderate-size CSPs seemed for which dynamic variable ordering heuristics they are determined once and for all. On the other hand, dynamic variable ordering heuristics are potentially more powerful because they can identify difficult variables within specific search states rather than for the overall search tree. While a number of early CSP studies performed to suggest on simple problems that that dynamic variable ordering heuristics might be too expensive, Purdom showed can be there are more difficult CSPs, expected to to achieve exponential the CSP come up with a solution literature search In each search state, DSR looks for the variable rearrangement to be instantiated with the smallest number of remaining values, and selects this variable it is worthwhile to determine whether next. DSR has often been used as a benchmark using a dynamic variable ordering heuristic the experiments belongs is justified, CSI? presented at the end of this paper clearly show that job shop scheduling for which a dynamic variable ordering for the job shop [37]. For these more difficult classes of problems, for a given class of problems. Not only do in the average amount of search required to the class of more difficult problems using a simple heuristic known that DSR is too weak a heuristic they also clearly [3,6,7,15,37]. recommends as dynamic generally indicate savings (DSR) The scheduling problem introduced in Fig. 2 helps understand the shortcomings this variable ordering heuristic. Fig. 7 depicts consistency enforcing procedure described in Section 3. this problem after application According left, while to schedule that, among to DSR, six operations appear to be equally good candidates the other four operations have ten possible (values) It is easy to see however resource R2 are the last operations to be in contention appear for resource R2 strongly to be sched- start (val- some are in these six “critical” operations, than others. Consider operations 0: and 0;. Both require three out of the in their jobs. In other words, the same that 0: and 0: are more start times. For like O:, which has also seven possible start times, competes only is the in its job (job js) . In other words, (resource R3), and uled first, namely Oi, Oi, Oi, O:, Oz, and Oi, as they each have seven possible times start times ues). fact more difficult resource R2, which is required by a total of four operations. Additionally, four operations requiring most of these operations time. This high contention difficult instance, an operation with one other operation first operation these two operations hence are expected DSR cannot account values of each variable, but fails available start resources are more likely than operations 0: and Oz. Unfortunately, the number of remaining It simply counts that these values remain the likelihood for highly contended for resource R2 at about suggests to schedule for these observations. for resource Rs, namely operation 0:. Additionally, than the other four operations with seven possible than those of other operations. are not in high contention to become unavailable times of operations is the last operation in job jl, while 0: for their resource later on. Clearly to be easier to schedule to estimate competing 0: In this example, the bottleneck of capacity constraints. Therefore, variables might actually perform better than DSR. Several such variable ordering heuristics have fixed variable ordering been proposed to the largest clique that identifies difficult constraints resource R:! also corresponds a variable ordering heuristic in the literature. These heuristics graph) as those with many in the constraint are generally (i.e. nodes incident of of the 12 N. Sudeh. M.S. Fm/Arti$cial Intelligence 86 (I 996) l-41 j 1 j 2 j 4 G PI capacity constraint + precedence constraint Fig. 7. The same job shop CSP after consistency instance, namely represents (0, 1,2,3,4,5,6}. all start [ 0.61 times between labeling. Start time labels are represented as intervals. For time 0 and time 6, as allowed by the time granularity, are added unless new constraints is the minimum width (MW) heuristic to the problem as it is solved. One such heuristics, [ 6, 131. MW orders the variables from heuristic last to first by selecting, at each stage, a rlode in the constraint graph which has a minimal degree 5 in the graph remaining after deleting all nodes that have already been selected [ 61. A variation of this heuristic known as the minimum degree (MD) heuristic [ 61. In simply first. There are the example depicted In general, scheduling problems are not also MW orderings like MD or MW do not provide very that simple, and fixed variable ordering heuristics good advice either. This is best illustrated by slightly modifying the scheduling problem depicted in Fig. 2, MD would select 0: in the initial constraint graph starting with this operation. ranks variables according to be scheduled to their degree in Fig. 2. the problem and introduce a fifth resource, say requiring RI or R3 in the original Suppose, for instance, that we change Rs. Suppose also that we allow any of the operations problem to use R5 as an alternative resource. We now have: 0 a;, = fin:, = .n;, = {R,, R5}, . 12;, = a;, = {R3, R5}. 5 The degree of a node is the number of constraints incident to that node N. Sadeh, M.S. Fox/Artificial Intelligence 86 (1996) l-41 Cl R capacity constraint ) preceaence constraint Fig. 8. A new resource Rs is added to the problem. Rl.5 stands for RI or Rg. R3.5 stands for R3 or Rg. that capacity constraints between operations belonging capacity constraints constraints (Fig. 8). Notice corresponding involving between 0: and O;, which would require if both operations use Rs. This constraint the two operations, which requires from The two cliques of capacity constraints by a larger clique of capacity constraints 0: job are subsumed by precedence constraint precede O:, constraint between to the additional now MW orderings and MD orderings fact the addition of R5 has significantly in the new clique, and to schedule actually constraint example of a variable ordering heuristic Another is the mux curdinality tightness variable to be instantiated, largest number of already as a fixed variation of DSR. to schedule tightness, namely to the inability the difficulty of satisfying instantiated variables the operations resulting is due (MC) easy and then at each stage picks to RI and R3 are now subsumed five operations: Oi, Oi, Of, O:, and to the same in that job. This is the case for the capacity that either 0: precede 0: or 0: is subsumed by the precedence that 0: always precede 02. Due of Rs, there are the introduction starting with some of these five operations. In loosened connected the capacity constraints participating by these constraints of these heuristics that these operations to account a specific constraint that does not account are even easier are for [ 11,301. for constraint search order which arbitrarily the first to the [ 6,241. This heuristic can also be viewed the variable connected selects than before. Failure of MW and MD to identify 14 N. Sadeh, M.S. Fr,x/Artijiciul Intelligence 86 (1996) l-41 Another weakness of generic variable ordering heuristics described from the fact that they treat all problem constraints types of constraints the effectiveness in the job shop CSP, consistency erature comes practical CSPs, different ing. This in turn impacts instance, that backtracking in Section 3. Consequently, how difficult constraints. This can be exploited only occurs as a result of capacity constraint violations, it is to find that operation a reservation the criticality of an operation should solely be a function of that does not violate any capacity to design more effective variable ordering heuristics. uniformly. entail different in the CSP lit- In many check- of different variable ordering heuristics. For ensure enforcing as explained levels of consistency can efficiently techniques is to a [20], though reflecting reservation is assigned (i.e. its its authors apparently its chance of satisfying the strength of their heuristic contention with other operations of DSR in which each operation (i.e. each value) the capacity constraints variable ordering heuristic by Keng and Yun that takes advantage of this observation failed to this observation. Keng and Yun suggested A specialized the one developed relate generalization a survivability measure for the allocation of its resource). chance of surviving to be scheduled next is the one with the smallest global survivability, The operation possible by the sum of the survivabilities as determined reservations. Experiments at the end of this paper, show that this heuristic presented performs better than all the generic heuristics described above. They also show that this heuristic (i.e. is quite expensive, ’ In scheduling problems with several hundred values) of all unscheduled operations or more, each with several hundred possible start times and several possible resources, can be obtained by focusing on one or a small number of cliques of tight capacity constraints, in these cliques. A heuristic and selecting than Keng and Yun’s based on this idea is described heuristic while achieving this heuristic may not be cost effective. More efficient heuristics the operation most likely to violate a constraint an even higher search efficiency. in Section 6. which runs faster as it requires operations. of each of its (remaining) all the remaining reservations inspecting 5. A look at some popular value ordering heuristics Another powerful way of reducing selecting search relies the average complexity of backtrack the order in which possible values are tried for each variable. least constraining values. A least to the overall in a large number of solutions compatible the system will least constraining is one that assigns in many solutions to participate values, to participate search state. By first trying value is one that is expected on judiciously A good value ordering heuristic constraining problem or, better, one expected with the current generally maximize and hence the number of values left to variables that still need to be instantiated, it it will avoid building partial solutions that cannot be completed. b Notice also that this heuristic may still identify operations with just a few remaining possible in fact the reservations as critical while other operations. This could be the case if operation 0; of possible times. caused by this operation, In fact, consistency since there is no capacity constraint enforcing start in the example is sufficient to ensure to it. incident of these operations may not be in contention with reservations those of any in Fig. 2 had only a small number that backtracking will never be N. Sadeh, M.S. Fox/Art@cial Intelligence 86 (1996) l-41 15 in which a given assign- to Attempting to exactly compute the number of global solutions (or value) participates would be futile as it would require finding all solutions Instead, Dechter and Pearl have developed an advised backtracking that relies on tree-like relaxations (ABT) to estimate relaxation of a CSP is one whose constraint graph of the original CSP It turns in which a value participates (i.e. variables) the number of solutions of the problem steps, where n is the number of variables in 0(nk2) in the number of possible values of a variable. The idea is that, to the original CSP, a good relaxation for the original CSP One way constraint C in should also be a good value relaxations is to associate with each (binary) that is close enough ment the problem. value ordering heuristic the goodness of a value. A tree-like is a tree that spans some or all the nodes out that, within such relaxations, can be efficiently CSP, and k the maximum if one can find a tree-like value to obtain the original constraint graph a weight w(C) (i.e. that satisfy the number of value pairs can then be obtained by looking network. for the relaxation tree-like computed tight equal to the satisfiability of that constraint relaxation the constraint). A tight tree-like in the resulting tree (MST) spanning for a minimum Even for a fixed variable ordering, this heuristic generally in the search requires tree. This amounts the computation typically relaxations elementary computations each of which these conditions, is generally not enough computations. Empirical for each of the n levels in each search state. This requires 0( n2) elementary that a fixed variable ordering results presented to efficiently it might even be necessary of a fixed MST computations, hence a total of 0(n3) 8 indicate shop scheduling problems. Under new tree-like weights of each constraint quite expensive particularly well on some classes of CSPs, tightly connected CSPs such as job shop scheduling, whether using minimum tree relaxations shop CSPs, relaxation below with an example. to n MST [ 481, in Section solve job to identify the can become to perform it does not seem to lend itself very well to spanning or not. Indeed, when dealing with tightly connected CSPs such as job that one canJind a tight tree-like relaxation, namely a tree-like to guide search. 7 This is illustrated for large CSPs. More generally, while ABT has been reported in each search state. The resulting computations that will provide sufficiently good advice in turn would require updating it is unlikely Consider constraint Pt in the scheduling problem depicted in Fig. 7. Pt is a precedence constraint between operation 0; and operation 0,. ’ The set of start time pairs (stt , sti) that satisfy constraint Pt is: {(0,3),(0,4),..., (0,9), (1,4), (1,5),. . ., (1,9),. . ., (69)). In order to identify to the cardinality computations weights are as follows: a tight tree-like relaxation, Pt is assigned a weight, w( Pt ), equal of that set, namely w( PI ) = 7 + 6 + 5 + 4 + 3 + 2 + 1 = 28. Similar the weights of other constraints. These to compute can be performed 7 The experiments reported in [9] seemed to indicate the advice provided by ABT was too expensive and too accurate. often relaxations with a relatively high density of solutions. ended up being more cost effective. However, the opposite. In these experiments, that Instead, advice provided by looser these results were obtained on rather small problems it appeared 16 N. Sudeh, M.S. Fox/Art$cral Intellipxce 86 (1996) I-41 j 1 j4 [0.91 13.121 C, p, capacity constraint ) precedence constraint Fig. 9. An MST relaxation of the scheduling problem. = LV(PS) =28, 0 w(P,) = w(&) = w(P4) 0 W(PJ) = w(Pg) = 55. 0 w(C,) = 38, w(C2) = 29, w(C1) = 38. 0 w(Cq) =43, . w(C,) = w(c6) = 38, w(c7, Fig. 9 shows an MST = w(c,o) = 38. = 29, w(cs) = 56, w(c9) of the scheduling includes initially contained is even more dramatic. Only 2 out of the 6 constraints to R2 have been preserved. This problem obtained using these relaxation IO out of the 16 constraints present weights. It appears that the MST relaxation in the cliques of capacity in the original CSI? The loss of information in the clique cor- constraints responding In general a resource required by M operations will result in a clique of (“;‘) capacity constraints. At most in any tree-like relaxation of the M - 1 of these capacity constraints can be preserved if the advice provided problem. Under that the system by ABT for job shop CSPs selects 0: in Fig. 9, to be instantiated ABT would recommend of the scheduling start time 4 to this operation. A careful examination that there is no feasible schedule with 0: these conditions, we should not be surprised is not very effective. Suppose the MST relaxation is not an accident. reveals however first. ’ Using for instance represented assigning problem * It should now be clear that this is a good choice, since this operation has only seven possible start times and requires resource Rz. the main bottleneck of the problem. N. Sadeh, MS. Fox/Artificial Intelligence 86 (1996) 1-41 17 starting at 4. If 0: were to start at time 4, the other three operations R2 would all have to be scheduled between operations has a duration of three time units, resource time 7 and time 15. Given that each of these impossible. this is clearly requiring [ 201. This heuristic are ranked according requirements Keng and Yun have developed a specialized value ordering heuristic that can deal more first estimates overall for each resource as a function of time. Based on these estimates, operation to prevent contention to how well they are expected effectively with cliques of capacity constraints contention reservations with the resource that Keng and Yun’s value ordering heuristic generally outperforms ABT. However heuristic does not attempt job so that Keng and Yun’s heuristic only accounts operation, but fails to account the same job. in Section 8 show their the same In other words, to the current to other operations within to other operations within reservations. room least constraining of other operations. Empirical for capacity constraints for capacity constraints too can be assigned to leave enough incident incident results they The next section describes counts for the high connectivity ing, and for the constraint ordering heuristics identified comings interactions are defined within above. of constraint graphs typically a probabilistic model of the search space that better ac- found in job shop schedul- induced by these graphs. New variable and value the short- this framework that attempt to remedy 6. New variable and value ordering heuristics 6.1. General considerations that affect solution for search to complete to conclude are heuristics that minimize Good variable that the problem is overconstrained). the current partial and value ordering heuristics and value ordering heuristics search for the time spent applying of the value ordering heuristic once a variable has been selected, values the time if one exists, or with the (i.e. either with a solution, time is infeasible, If the problem (except the the system has to try each one of its required answer is independent heuristic): remaining In general variable that are explored, search state, and the amount of time spent applying ordering heuristics precludes interactions time. Instead, our approach expected number of search states spent enforcing already been scheduled specific operations heuristics cannot be completed. the number of search states in each consistency these heuristics. Variable and value of these the expected search the that the time that have (i.e. the depth in the search tree) rather than a function of the to yield can also affect each other’s performance. The complexity is mainly a function of the number of operations the average amount of time spent enforcing to be explored. Assuming the design of heuristics that efJicientZy reduce that have been scheduled, that reduce search time as well. 1 that a critical variable namely one whose remaining possible values are expected possible values of other variables. Under a set of simplifying to cause backtracking, to conflict with the remaining assumptions, is one that is expected that directly minimize is in effect expected aims at developing this approach We postulate independence consistency that need heuristics 18 N. Sudeh. M.S. Fox/ArnjSciul Intelligence 86 (1996) I-41 and Elliott have shown that a variable ordering heuristic based on such a Haralick criticality measure will minimize in the search tree, and hence the total number of search states that need to be visited to come up with a solution [ 171. 9 We also postulate in many solutions compatible with the current search state. that a good value is one that is expected length of branches to participate the expected In the next subsection, we introduce a probabilistic model of the search space, which we will use to compute estimates of variable criticality and value goodness. 6.2. A probabilistic model of the search space to be involved framework A critical variable is one expected to a variable that values assigned criticality, we introduce a probabilistic a given value will be assigned (2) value) the chances and each other of value contention), (measures that cannot be prevented by the consistency conflicts constraint violations, to conflict with the resource that cannot be prevented by our consistency a critical operation requirements for (1) the chance in a conflict. To approximate variable that that accounts (or the reliance of a variable on a particular conflict with those conflicts that the only enforcing procedure are capacity are likely requirements taking enforcing procedure. Given to different variables into account only is one whose resource of other unscheduled operations. We consider an unscheduled to that operation. Because, a priori, more likely probability only one reservation, to be selected to be selected. Clearly, hence: a probabilistic model operation Of is assigned a subjective probability of(p) in which each remaining reservation/value p of there is no reason than another, each operation to be allocated is to believe is assigned an equal reservation in any given schedule, an operation will be assigned that one reservation CT;(p) = - 1 NBRf ’ is the number of remaining where NBRf This distribution mirrors our intuition does not heavily bility of anyone of these reservations operations with few remaining reservations. Using these subjective reservations rely on any one of its remaining reservations of Of in the current search state. that an operation with many possible reservations the proba- low. On the other hand, rely more heavily on each of their remaining reservations, is rather to be selected and hence reservation distributions, we can estimate the reliance of an operation 0: on the availability that the reservation We refer to this probability allocated of a resource Rk E RES at time r as the probability that resource at that time. as the individual demand of operation Of for resource Rk to this operation will require likely is equally to become unavailable. Under ‘) See 117, pp. 307-3 I2 1. At the end of their proof, variable value call the smnllest Success pmhabilifv one with the smallest number of remaining values. The authors exploit search rearrangement (under several other simplifying to create backtracking will minimize heuristic. When this last assumption assumptions made earlier length of each branch (or equivalently the expected this assumption, the variable most likely to create backtracking) assumption the variable with what that each they is the their dynamic that the variable most likely this result to motivate is omitted, Haralick and Elliott’s proof shows in their proof) choosing the authors make the unnecessary in the search tree. N. Sadeh, M.S. Fox/Artificial Intelligence 86 (1996) l-41 19 it Df (Rk, 7). Df (Rk, T) can simply be computed by adding the reservations p of operation Of: that require resource of all remaining at time r and denote probabilities Rk at time 7. By adding g:(p) the individual Rk, an aggregate demand profile, Ditg’( unscheduled demands of all unscheduled ) T , is obtained operations resource that measures contention between requiring operations Equivalently, for resource Rk as a function of time. if we were to assume a stochastic mechanism by randomly rent partial unscheduled the probability requires Rk at time r and Dgp’ (7) would be the expected number of reservations at time r (or the expected number of operations the cur- to each 0: based on its af distribution, Df( Rk, 7) would be that for Rk schedule operation that assigns operation Of a reservation that completes (value) that resource at that time). the stochastic mechanism a reservation (variable) (solution) assigning requiring Similar demand profiles are built by Keng and Yun’s heuristics [20]. Our variable and value ordering heuristics differ from those of Keng and Yun in the way they exploit to these demand profiles. build probabilistic The following techniques demand profiles, based on a predejined variable ordering [ 281. of these profiles for the example and Smith also proposed lo Earlier, Muscettola the construction introduced illustrates in Fig. 2. Consider operation 0: this operation has seven possible sistency, each with a probability ui(sti) times and hence az(s$> = l/10, st$ = 3,4,. = l/7 . . (12. in the initial search state depicted in Fig. 7. After enforcing con- (i.e. start times sti = 3,4, . . . ,9>, to be selected. Similarly, 0: has ten possible start reservations The individual adding the probabilities demand of operation 0: of all its possible for resource R2 at time t can be obtained by reservations starting between t and t - duf: D:Uht) = c u;(r). t < 5. computations the individual 0: (R2, t) = l/7 for the other the individual resource R2, as well as the aggregate demand for 3 < t < 4 and Di( R2, t) = 217 for 4 6 demands of these four operations over time. As expected, can be performed resource R2. Fig. 10 shows intervals over which 0: time demands of all four operations For instance, Similar may require for that resource obtained by requiring adding the two operations with only seven possible start times (namely 0: and 0:) have more compact (namely 0; individual the two operations with ten possible and Of). Notice also, that, because of the normalization the total (like all the is always equal to the duration of that operation. This total operations demand is simply spread differently over time, depending on the number of start times still available start times of the CT:< p) distributions, resource demand of an operation with only one possible to the operation. in this example) individual demands than Fig. 11 displays aggregate demands pated, resource R2 is the most contended for. for all four resources in the example. As antici- lo The work presented here was performed Keng and Yun’s interpretation of their demand profiles is not a probabilistic one. concurrently with Keng and Yun’s [ 11,41,421. Notice also that 20 N. Sadeh. M.S. Fo.r/Artijiciul Intellipwce 86 (1996) I-41 D:(z): Individual Demand of 0: for R2 ~~] , , &f> , , , 0123456789 10 11 12 13 14 15 D;(z): Individual Demand of 0: for R, time t/me D:(z): Individual Demand of 0: for R, ;zJ , , , , , &-y-y--~ 0123456789 IO 11 12 13 14 15 time D:(T): Individual Demand of 0: for R, 0123456789 10 11 12 13 14 15 time Dzy(z): Aggregate Demand for R, ii/ , , 5-h 0123456789 IO 11 12 13 14 75 time Fig. IO. Building KZ’S aggregate demand profile in the initial search state. In general, building aggregate demand profiles operation. Hence, requires looking at each remaining in each search state, the complexity reservation of each unscheduled of this procedure the number of remaining of remaining reservations another. Accordingly, more efficient by dynamically reservations sets of possible the aggregate demand profiles and adding in Section 8 were obtained observation. the computation updating shrink is O(Nk), where N is the number of unscheduled reservations of an unscheduled operation. of many operations do not change of demand profiles could potentially individual (i.e. subtracting demands of operations when their old individual demands using a procedure the new ones). Empirical that did not operations In practice, and k the sets from one search state to be made their from results presented of this take advantage N. Sadeh, M.S. Fox/Art@cial Intelligence 86 (1996) 1-41 21 II:?(T): Aggregate Demand for R 1 &-y-h , , , 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 time D:~(T): Aggregate Demand for R2 0123456789 10 11 12 13 14 15 time Diy(Q: Aggregate Demand for R, 0 1 2 3 4 5 6 7 8 9 10 11 12 13 15 14 time D:.(T): Aggregate Demand for R4 1.50 1.25 1 1.00 0.75 9.50 1 zpp 0 12 3 4 5 5 7 9 9 10 11 12 13 14 15 time Fig. 11. Aggregate demands in the initial search state for each of the four resources. 6.3. A variable ordering heuristic based on measures of resource contention The aggregate demand for a resource over a time interval for that resource/time operations between unscheduled terval with the highest demand/contention are most likely constraints nect operations contributing the operation with the highest contribution can be considered resource/time tion/variable most likely to be involved most on the availability to the demand to be violated interval is a measure of contention can be expected (specifically, interval. The resource/time in- to be the one where capacity that con- the capacity constraints for this resource/time to the demand for the most critical one. This interval). Accordingly, the most contended-for is the opera- that relies It is also the operation in a conflict. of the highly contended-for resource/time interval. 22 N. Sad& MS. Fox/Artijicul /ntrlligence X6 (1996) l-41 Several variations of this variable ordering heuristic have been The simplest and often most effective one inspects each resource’s aggregate demand profile using time intervals of duration equal to the average duration of the operations requiring interval with the highest demand that resource. The heuristic interval. This is the and the operation with the largest contribution variable ordering heuristic used in the empirical in Section 8. We refer to it as ORR (for “operation to this resource/time study reported then picks the resource/time reliance” heuristic). implemented. resource Fig. I I displays the demand profiles of RI. Rz, R1, and R4, the four resources in our time 8 and 11. This to the clique of tight capacity constraints for this peak is 0:. This is no coincidence: precisely that the operation with the largest contribution 0; competes example. The highest demand peak is the one on resource R2 between resource/time interval corresponds identified earlier. Fig. I2 indicates for the most contended demand start resource and belongs two times left after consistency intervals for: [7, 10[ and [ 8, 1 I[. Had our heuristic chosen 17, 101 instead of [8, I I I, it would have selected 0: in this as the operation example. that have only seven possible there are actually to be scheduled next. In fact, 0: and 0; appear equally critical in the demand profile of R2 that qualify as most contended checking. Notice that. in this example, to the group of six operations to the The ORR heuristic requires looking successively calendar, and if the scheduling in order at each resource, and each time interval. this requires 0( Hm) the most contended is H, to identify horizon interval on that resource’s If there are rn resources computations. elementary 6.4. A reservation ordering heuristic that attempts to minimize contention that overhead relaxations to minimize the computational In Section 4. we showed associated with ABT’s could become prohibitive on large job tree relaxations to to help due to the difficulty of tree-like for cliques of capacity constraints. We now describe a value ordering resource contention while relying on predetermined that attempts relaxations. The predetermined in the job selection of minimum spanning shop CSPs and is often unlikely properly account heuristic tree-like all unscheduled operation these operations. However, rather than simply counting relaxations, our value ordering heuristic also accounts for the probability to the relaxation solution is estimated using resource contention) for the ORR variable ordering heuristic. the cliques of capacity constraints the same demand profiles to be scheduled next) belongs, along with all precedence are comprised of some or the constraints between to these that a solution that a relaxations the current critical operation (or “survives” that are constructed the cliques qf capacib constraints. The probability the number of solutions tree-like to which (to the relaxation) operations satisfies satisjes (i.e. For job shop CSPs with tree-like process routings, constraints our value ordering heuristic by precedence constraints. Each candidate the number of solutions satisfy capacity constraints the tree-like is comprised of all the unscheduled connected to the current critical operation, along with these precedence reservation (for the critical operation) relaxation adopted by operations to the relaxation with which it is compatible (or “survive” resource contention). The reservation is ranked according that are expected to to compat- N. Sadeh, M.S. Fox/ArQ5cial Intelligence 86 (1996) I-41 23 ia , Dy; 0 0 1 2 3 4 5 6 7 9 9 IO 11 12 13 15 14 me D:(z): Individual Demand of 0: for R, 1 :;I , , &-y-~ , , , 0 1 2 3 4 5 5 7 9 9 10 11 12 13 15 14 time D;(z): Individual Demand of @ for R, D:(T): Individual Demand of 0: for R, jj gEJ , , ) , , M-y5 012345679 9 10 11 12 13 14 15 t/me D:(T): Individual Demand of 0; for R, 1 izj , -, er_+7 0 1 2 3 4 5 6 7 9 9 IO 11 12 13 14 15 time Fig. 12. ORR heuristic: the most critical operation is the one that relies most on the most contended re- source/time interval. ible with the largest number of such schedules heuristic. Below, we detail the approximations compute resource contention. that a reservation the probability is the one selected by our value ordering to used in our value ordering heuristic and a solution to the relaxation “survive” 6.4.1. Estimating the probability that a reservation survives contention Let Of be an unscheduled operation reservations. We refer to the probability of its remaining operation Of will not conflict with the resource survivability of reservation of reservation p (for Of) is approximated requirements p (for Of). It will be denoted and p = (~4 = t, Rf, = rflk, , Rf2 = rfzkz,. . .) one reservation p to that assigning as the of other operations surv~( p). The survivability by the product of the probability that each 24 N. Sadeh, M.S. Fox/Artificial lntelltgence 86 (1996) I-41 one of the resources (independence assumption) : required by that reservation will be available between t and t + dui .rurvj( p) = rI (,,E i ri,,, .r.iZi12’ -1 availf ( rijk, t, t + dui) . (1) where availf(rfjk, t, t + duf) stands for the probability that resource rfik will not be required by any other operation between this resource to 0: will not create backtracking). t and t + dui (or the probability that assigning Let rilk = R, E RES. The probability avuilf ( rijk, t, t + dui) that resource rlk = R,, the aggregate demand profile of resource R,, introduced also requires keeping will not ‘be required by any other operation between using value ordering heuristic (unscheduled) operations for R,, at time 7, which to the aggregate demand track of n,,(r), contributing competing operations t and t + duf can be approximated in Section 6.2. Our the number of the number of namely is also for R,, at time 7, denoted Dir( 7). At any time t < r < t + dui, there are by definition ?z,, (7) - I unscheduled operations competing with operation Of for resource R,,. The total demand of these other unsched- that each of these uled operations /z,‘( 7) - 1 other operations equally contributes that none of these operations for R,) at time r is Dif’( 7) - 0: ( R,, 7). Assuming requires R,, at time 7 is given by: to this demand, the probability D;y’(7) _ D;( R,7) ‘P(~‘-’ l- 11,’ (7) - 1 (2) It is tempting to approximate availf(rijk, t, t + dui), i.e. the probability that rfjk = R,, to Of between to Of on each one of the dui time intervals between I and t + dui. as the product of the probabilities that R,) I and t + duf. In is too pessimistic. this approximation will be available will be available general, with 0: have a duration over time interval time interval several contiguous the calendar of that resource average duration of the operations competing [ 7,~ + I[ without requiring equal It assumes to 1, i.e. that any of these operations it over time interval that the operations competing could require R, [r + 1 ,r + 2 [ or over require for R,, generally can be obtained by subdividing [T- - 1, T[. Instead, because operations competing time intervals, a better approximation into buckets of duration AVG(du), where AVG(du) for rfik = R,. uvailf(rfik, is the t, t + duf) is then approximated time buckets approximated as the probability that Of will be able to secure the (duf)/(AVG(du)) that it requires as: to fit on the resource’s calendar. Using Eq. (2), this can be uvuilf( R,, t, t + duf) AVG(D;yr(7) _ D;c RI,,7)) AVG(n,,(r)--l)x(d~)(AVG(du))-’ AVG(n,(7) - 1) where AVG( D::‘(T) - Di( R,,, T) ) and AVG(n,,(7) - 1) are respectively the average of D”,s:“‘( 7) - Df (R,, , 7) and the average of H,~ ( 7) - 1 over time interval [t, t + duf [ . N. Sadeh, M.S. Fox/Artificial intelligence 86 (1996) l-41 25 Reservation Survivabilities for 0: 1 . Q 1.00r Q m 2 t a 0.80. 0.60. 0.40. 0.20 - 0.00, 0 I 1 . 2 , 3 I 4 I 5 ~ 6 , 7 I 8 1 9 10 I I 11 12 start time Reservation Survivabilities for 0: 1.00 p a P m 0.80 ? e a 0.60 I iz] , , 11 1 !I 11 , , ( 0 1 2 3 4 5 6 7 8 9 10 1112 start time Reservation Survivabilities for 0: P 1.00 P (D 0.80 .s 0.60 r s 0.40 1 0.20 0.00 L 0 I 2 1 3 4 5 1 ! : T 6 7 9 9 r IO , I1 staff time 12 Fig. 13. Survivability measures current critical operation. for the reservations of operations in job j,, the job to which 0: belongs, the selected reservation survivabilities (the operation for the three operations to be scheduled in job js, the job in the initial search state). curves is easily interpreted by looking at Figs. 7 and 11. Fig. 13 depicts to which 0: belongs The shape of these survivability Consider operation 0:. Fig. 7 indicates for resource Rs, namely operation 0,. ’ Because operation 0: has a duration du: = 3 is St: = 6, operation 0: will and because if it is scheduled at s$ = 0, 1, 2, or 3. This is why the never conflict with operation 0: to 1. For start times s4 = 4,5 and 6 survivability in the probability that 0: only competes with one other operation the earliest possible start time of operation 0: of conflicting with a reservation of each of these start times increases, as indicated assigned is equal to 0: 26 N. Sudeh, M.S. Fox/Artificiul Intelligence 86 (1996) l-41 for resource R3 between the two operations fairly low (i.e. the conflicts Fig. 11 by the higher aggregate demand times where a conflict between such a conflict remains a small fraction of the reservations of these two operations conflict with each other), of start times s< = 4,s and 6 remain fairly close to 1 (though smaller survivabilities I ). Operations reservation operations time 6 and 9 (the only is possible). Since the probability of involve only two operations and only the than their curves of these two survivabilities can be interpreted using similar, 0; and 0: compete with more operations though slightly more complex arguments. are smaller. The shape of the survivability than 0:. Accordingly, 6.4.2. Estimating the probability thut a job schedule survives contention A good reservation p for a critical operation 0: is not just one that is likely to (locally) operations it requires. for the resources in the same job (job j,) so that they too have reservations It should also leave enough room to other that ranks the number of job that are likely to survive resource contention survive contention unscheduled are likely to survive resource contention. Accordingly, our value ordering heuristic each remaining (of the critical operation) reservation schedules compatible with this reservation (in short, the expected number of survivable job have already been scheduled, look at the relaxation the current (critical) operation. in the to that can be reached from constraints without visiting a scheduled comprised of all unscheduled operations operation via precedence rather than looking at the entire job, it is sufficient schedules). When some operations by estimating The following details the way in which our value ordering heuristic approximates the number of job schedules compatible with a given reservation that are expected to survive these details can safely jump resource contention. The reader who is not interested to Section 7 or 8. (for the critical operation) in In order to proceed, a few notations need to be introduced: (i.e. the operation selected to be scheduled next). that make up the relaxation used by our value that a scheduled constraints without visiting the unscheduled operations : the goodness of assigning p to O!, expressed as the expected number of reservations. from 0: via precedence Of: the current critical operation p: one of Of’s remaining RELAX: & 0’: the set of operations ordering heuristic. This set consists of 0: and can be reached operation. good!(p) survivable compf (p): signment of p to Of. sol E compf ( p) : a solution of p to of. p( 0: 1 sol) : the reservation that the probability by the product of the probabilities solutions the set of solutions to the relaxation. to the relaxation to the relaxation Assuming approximated survives contention, assigned that a solution sol survives to an operation 0: E RELAX; resource contention that each reservation p( 0: 1 sol) in solution sol. can be in sol the goodness of assigning p to Of is: goodfb) = c n surv~(p(0~ j sol)). (4) .so/ l compf ( p) 0;ERELAXj that are compatible with the as- that is compatible with the assignment N. Sadeh. MS. Fox/Artificial Intelligence 86 (19%) I-41 21 assumption is equivalent constraints in other jobs. Empirical to omitting results reported acceptable. Thanks the interactions induced by that in Section 8 suggest the to this assumption, in each search state are those is generally that need to be computed independence This precedence this independence only reservation of operations Expression that of other operations assumption survivabilities in RELAX: 2 0’. (4) can be rewritten in RELAX:: to separate the survivability of reservation p from goof.ff(p> =survf(p) x c rI surv:(p(o: 1 sol)). solEcomp](p) O~ERELAx~\{Of} This can be further rewritten as: go&p) = sun+(p) x compsurvf(p), (9 (6) where compsurvi(p) Of that are expected is the number of solutions compatible with the assignment of p to to survive contention: compsuruf 1 ( p) = rI su?-l&p(O~ 1 sol)). sol Ecompf(p) O:ERELAX;\{Of} Note that, in fact, cornpsurvf (p) is only a function of the start time sd allocated to 0; in reservation p an can therefore be written as corrzpsuw~ ( t) . times In tree-like process routings, t of Of in O(~lk) it is possible steps, where VI f nl is the number of operations to evaluate compsurvf ( t) for all the possible in procedure described is an adaptation of a procedure described is 0(vlk2) to 0( ilk) by taking advantage of the linearity of precedence tree-like CSPs. Here we have further is done using a dynamic programming start relaxation RELAX:, and k the maximum number of possible This technique procedure complexity the model was to allow for other temporal constraints the complexity should be possible constraints one, and use the resulting that are not on a critical path) of the algorithm would be 0( vlk2). For non-tree-like to remove a small number of precedence constraints reservations of an operation. in Appendix A. This in [ 91. The complexity of Dechter’s this If in [ 11, it reduced constraints. such as those described process plans, (e.g. precedence into a tree-like the process routing to transform for general relaxation earlier, to compute goodness measures. the critical operation is 0;. Since no operation has In the example discussed is only compatible with one solution the goodness measures computed using (6). Start time s$ = 6 been scheduled yet, the relaxation used by the heuristic consists of all three operations in job js. Fig. 14 displays namely a solution for instance is given by: in which sg = 3 and s$ = 0. Therefore, = 6). On the other hand, good@ start time s$ = 7 is compatible with three solutions one with sti = 3 and se = 0, one with s$ = 4 and st = 0, and one with sg = 4 and s( = 1. The of each of survivability these three solutions. to the relaxation, the goodness of this start time (s$ = 0) x surv~(s~ = 3) x surv;(s< time was obtained by adding the survivabilities to the relaxation, of this start = 6) = su$ Start solutions time s$ = 12 is the one compatible with the largest number of survivable this is the start time selected by the value ordering to the relaxation. Hence 28 N. Sadeh. MS. Fbx/Arti&ial Intelligence 86 (I 996) I-41 Reservation Goodness for 0: ii 6.00 - a .% 6.00- 7.00 - 5.00 - 4.00 - 3.00 - 2.00 - l.W- O.w, 0 , 1 , 2 , 3 , 4 ,F 5 f! 7 6 I 9 6 0 0 I I 10 11 start time 12 Fig. 14. Value goodness for 0: expressed us the number of’ compatible job schedules expected to survive resource contention. heuristic. By assigning ordering heuristics that were just described, schedule without backtracking. This problem backtracking by Keng and Yun’s heuristic. this start time to Oi, and iteratively using the variable and value the search procedure easily completes the is relatively easy, and is also solved without No heuristic is perfect. Although our value ordering heuristic reveals start time, a careful analysis st: = 1 1, is actually infeasible. Notice however scheduler does not need to try the second best value recommended is enough for the first value to work. for instance recommends the right that its second best choice, namely the it by the heuristic: that, in the absence of backtracking, In Appendix B, we describe a filtering mechanism used in our value ordering heuristic as the the ranking of reservations. We refer to the resulting heuristic refine to further FSS value ordering heuristic-FSS stands for “filtered survivable schedules”. 7. Overall complexity In each search state, of the look-ahead complexity the worst-case operations left to an operation O(max( Nk, Hm)), where N is the number of unscheduled search state, k the maximum number of reservations the scheduling horizon, and m the number of resources to be the dominant appears search states generated by the system uled), the overall complexity total number of operations sizes suggests approach. Clearly, when backtracking can be much higher, not often the case. is analysis in the current in that state, H in the system. In general 0( Nk) the number of (i.e. to be sched- the to be scheduled. Experimentation with problems of different of the of the procedure occurs, results presented factor. In the absence of backtracking that, in the absence of backtracking, is equal to the number of operations in Section 8 show that this is this is the true complexity the overall complexity where NOP denotes though empirical of the approach is O(NOpk), N. Sadeh, MS. Fox/Artificial Intelligence 86 (1996) 1-41 29 8. Empirical evaluation reports This section ordering heuristic rearrangement) value ordering veloped by Keng and Yun [ 201. (DSR) variable heuristic [ 91, and the combination the results of an experimental study comparing and FSS value ordering heuristic against the DSR (dynamic the ORR variable search [ 3,17,37], of variable and value ordering heuristics de- (advised backtracking) the ABT 8.1. Design of the test data A set of 60 scheduling and ten jobs of five operations job had a linear process routing specifying a sequence one of the five resources. This sequence was randomly generated for bottleneck order to further problems was randomly generated, each with five resources each (i.e. a total of 50 operations per problem). Each in which the job had to visit each for each job, except (in resources, which were each visited after a fixed number of operations resource contention). increase conditions: the distribution of job due dates and to cover different scheduling Two parameters were adjusted the number of major bottleneck rameter, RG, controlled bottleneck parameter, BK, controlled groups of ten problems were randomly generated, by considering of the range parameter and two different bottleneck parameter, which will be referred a function of the first two in order to 100% over the major part of each problem. the other parameters were allowed have been either a range pa- release dates, and a resources. Six three different values configurations. The value of a third to as the slack parameter, S, had to be adjusted as close for bottleneck If this parameter had been fixed while to change, a large proportion of the problems would trivial or infeasible. to keep demand resource(s) The three parameters were set as follows: this parameter l Range parameter (RG): - drawn controlled of the problem was estimated and S is the slack parameter, which in each problem. Due dates were randomly the release date and due date from a uniform distributions ( 1 +S) M U( 1 -RG, 1) , where U( a, b) represents a uniform probability distribution between a and 6, M is an estimate of the minimum makespan of the distribution is defined below as a function of problem, BK and RG. The minimum makespan as M = (n - 1 )dURb,,t + c21R, &R, where n is the number of jobs, m the number of (or one of them if there are several) resource resources, Rbr,,k the main bottleneck and & resource Ri. This denotes estimate was first suggested release dates were randomly drawn ( 1 + S) M U( 0, RG). Three values of the from a uniform distribution range parameter were used to generate problems: RG = 0.0, 0.1, and 0.2. Due to size of the scheduling problems considered here, larger values of RG the moderate is also in part due to the quickly to produce tend fact that, to keep from generating the value of the slack parameter, S, as RG becomes in [ 341. Similarly, of the form: the average duration of the operations infeasible problems, we increase less resource contention. This larger, as detailed below. requiring l Bottleneck parameter (BK): (BK = l), while in half of the problems, in the other half there was only one major there were two major bottlenecks bottleneck (BK = 2). 30 N. Sudeh. M.S. I;ox/Artijiciul Intelligence X6 (1996) l-41 l Slack parameter (S): two bottlenecks for problems with or jobs with different release dates and due dates, the time span of each problem was inflated to ( 1 +S) M so that most problems set to S = 0.1 x (BK - 1) + RG. While ensuring feasible, resources over the major this provided part of each problem. feasible. The slack parameter was empirically for close to 100% utilization of bottleneck that most problems remained remained Finally, operation durations were randomly drawn on whether an operation depending operations had durations non-bottleneck tion U(3, 11). On average, operations start times (i.e. values) the initial search state. operations had their durations randomly drawn from a uniform distribution from required a bottleneck two different distributions, resource or not. Bottleneck II( 8, 16) whereas randomly drawn from a uniform distribu- in these problems had slightly over 100 possible in enforcing procedure left after application of the consistency 8.2. Comparison with other heuristics Five combinations l DSR& ABT: of variable and value ordering heuristics were compared: the dynamic search rearrangement heuristic [3] combined with [9]. The version of ABT used the in relaxation as tree-like implemented value ordering heuristic it used the process routing advised backtracking these experiments was one based on the same predetermined FSS, namely This version of ABT was carefully search state (where ~1 is the number of operations k the maximum number of remaining checking). This was done using a procedure similar Notice that an implementation slow to be competitive. and required been 0( vtk*). It would have required computing the number of solutions identifying relaxation an MST to count in FSS. of ABT using MST relaxations would have been too to the one implemented constraint satisfiabilities in each search state. Additionally, the time to a general MST relaxation would have to which the current operation belonged. in each in O(vtk) and in the tree-like start times of an operation after consistency steps relaxation to run l DSR& FSS: the DSR heuristic combined with the filtered survivable schedules (FSS) value ordering heuristic (with @J = 2.5). l ORR& ABT the operation resource reliance (ORR) variable ordering heuristic together with the ABT value ordering heuristic. l ORRd FSS: the ORR and FSS heuristics l SMU: the variable and value ordering heuristics developed by Keng and Yun at the (with Cp = 2.5) advocated in this paper. Southern Methodist University [ 201. All combinations of variable and value ordering heuristics were run functions were shared (e.g. consistency in a modular enforcing module, functions were bypassed whenever possible in DSR&ABT). All functions were of demand profiles in which all common testbed backtracking module, etc.), and unnecessary (e.g. bypassing the construction implemented with equal care. On each problem, search was stopped The performance compared along of each combination three dimensions: if it required more than 500 search states. of variable and value ordering heuristics was N. Sadeh, M.S. Fox/Artificial Intelligence 86 (1996) I-41 31 (1) (2) (3) introduced framework interactions is not necessarily to search efficiency to be scheduled over the of heuristics with respect the ratio of the number of operations is doing a good job at focusing to 1. While a high search efficiency evaluation It tells us if a heuristic In the absence of backtracking, for each operation, and hence search efficiency synonymous with is search on In particular, we want in Section 6 is doing a for Search eficiency: total number of search states that were explored. only one search state is generated is equal a fast procedure, important. critical variables and promising values for these variables. to make sure that the probabilistic good job at capturing key constraint in generic CSP heuristics. This metric can tell us if this is indeed Number of experiments solved in less than 500 search states each. When a combi- nation of variable and value ordering heuristics cannot solve a given experiment in less to let the procedure reach a solution. At that point, amount of time. continue, Average CPU time (in seconds): time successfully schedule a problem. When a solution cannot be found 500 search states, this time is approximated 500 search states. All CPU running Knowledge Craft on with a more procedure results required to in less than to explore 5000/200 top of Allegro Common Lisp. Experimentation as it will not return a solution within any reasonable is the average CPU as the CPU time required times were obtained on a DECstation that are not well accounted the case. indicates (on the same platform). runs about 30 times faster in this language recent version of our system written thousands of search states it does not make sense than 500 search states, it typically needs that the in C++ indicate this to to solve that DSR in Table 1. They of 58%, and failed job shop scheduling results not only suggest are summarized realistic variable ordering heuristic. ” They also so far in the CSP literature are often too shallow for problems is generally problems. Combined with ART, not The sufficient this heuristic was only able to solve 29 problems out of 60 in less than 500 search states each. Even when combined with the FSS value ordering heuristic, DSR only achieved to solve 27 problems out of 60 in less than a search efficiency that job shop scheduling 500 search states. These requires a dynamic indicate that the variable ordering such heuristics proposed as job shop scheduling. After replacing DSR with ORR in combination with ART, search efficiency went up by 16% and 11 additional problems were solved in less than 500 search states each. The SMU heuristic achieved a higher efficiency of 72% and solved 43 problems out of 60 in less than 500 states. Even this heuristic had trouble solving many than ORR&ABT. ORR&FSS, problems. the variable and value ordering heuristics advocated in this paper, yielded an impressive 86% search efficiency, and solved 52 problems out of 60 in less than 500 search states. that it was able to solve, ORR&FSS never generated more Among than 78 search states and never to solve a problem. This heuristic combination speedups over all the other heuristics. it could hardly solve more problems took over 150 CPU seconds the 52 experiments also achieved important In fact, ‘I In [ 391, we also reported experiments number of critical operations critical operations heuristic quickly degrades as it becomes less dynamic. scheduled at once, namely comparing variations of our ORR heuristic less dynamic variations of ORR where that differed in the two or more of the variable ordering are selected at once. These experiments show that the performance 32 Table I Comparison parentheses N. Sudeh, MS. I;r,.r/Arri’ciul Intelligence 86 (1996) l-41 of five heuristics over six sets of ten job shop problems; standard deviations appear between Performance of fve heuristics DSR&ABT DSR&FSS ORR&ABT SMU ORR&FSS Search efficiency RG = 0.2 BK= I Nb. exp. solved CPU seconds Search efficiency RG = 0.2 BK=2 Nb. exp. solved CPU seconds Search efficiency RG = 0.1 BK= I KG = 0.1 BK=’ RG = 0.0 BK= I RG = 0.0 BK=2 Overall performance exp. Nb. CPU seconds solved Search efticiency exp. Nb. CPU seconds solved Search efficiency cxp. Nb. CPU seconds solved Search efficiency exp. Nb. CPU seconds solved Search efficiency exp. Nb. CPU seconds solved 0.72 (0.42) 8 524 (6955) 0.49 (0.40) 7 886.5 (819) 0.60 (0.44) 7 473.5 (486.5) 0.22 (0.27) 2 925 (460) 0.28 (0.38) 3 857 (411) 0.3 I (0.33) 3 679.5 (514) 0.44 (0.41) 29 724.5 (585.5) 0 R2 (0.38) X 380 (51.5) 0.73 (0.43) I 456.5 (489) 0.X2 (0.38) X 266 (249) 0.46 (0.46) 4 483 (324) 0.32 (0.38) 3 659 (379) 0.37 (0.43) 3 615 (420) 0.58 (0.45) 33 476.5 (411.5) 0.96 (0.06) IO 78.5 ( 10.5) 0.54 (0.39) 6 566.5 (591.5) 0.79 (0.36) 9 290 (416) 0.3 I (0.37) 4 918 (S75) 0.s3 (0.44) 6 X32 (817) 0.46 (0.40) 5 907 (830) 0.60 (0.41) 40 598,s (665.5) I .oo (0.00) IO I88 (14) 0.79 (0.38) 8 384.5 (379.5) 0.64 (0.46) 6 464.5 (390.5) 0.7 I (0.42) 7 355 (3Ol.S) 0.46 (0.46) 4 626 (399.5) 0.7s (0.41) 8 383.5 (415) 0.72 (0.41) 43 400 (356.5) 0.96 (0.07) IO 88.5 (13) 0.99 (0.02) IO 93 (7.5) 0.78 (0.36) 8 331.5 (503.5) 0.87 (0.29) 9 I84 (281) 0.73 (0.43) 7 47s (640.5) 0.82 (0.38) 8 300.5 (444) 0.86 (0.31) 52 245.5 (403.5) 8.3. Recent developments and additional results The benchmark problems used in this study have been made available to the research ftp account at CMU and have been widely community disseminated, in this area. A high point in the history of the benchmark was reached at the AAAI Spring Symposium held for the first time a common set of problems at large through an anonymous providing N. Sadeh, MS. Fox/Artificial Intelligence 86 (1996) I-4I 33 200 c II ::::< 50 -)- 100 200 300 400 Without Rough Demand PrOfibS -I- With Rough Demand Profiles Fig. 15. Scale-up experiments: of operations to be scheduled. CPU times are. on a DECstation 5000/200 running C++. versions with and without rough demand profiles. Problem sizes are the number at Stanford they were able to efficiently in March 1992, when three groups of researchers simultaneously announced approach developed by Johnston et al. within relies on a collection the context of the heuristics heuristics often violates one of initialization solve all 60 problems, using three different approaches: constraints for the same resource approach developed by Muscettola within the context of are imposed between subsets is [27]. Resource fails to find a feasible If the procedure from scratch, relying on the stochasticity of its Monte Carlo contention (1) (2) (3) solution. it restarts in which precedence to produce a different system. This approach contending via Monte Carlo simulation. A bottleneck partitioning his HSTS system, of operations approximated solution, simulation A trial-and-error SPIRE [ 191. The schedule produced by the initialization or more constraints. When heuristic the solution) a prespecified initialization The specific [27] has reported our 60 benchmark solve all 60 problems A procedure we developed gent backtracking mechanisms that “min-conflict” problems. This suggests number heuristics initialization should mainly be attributed [ 251. If “min-conflict” that attempts this is the case, it is passed on to a ‘mm-conflict” the solution to get rid of conflicts within (or “repair” fails to produce a feasible schedule within the for repair. techniques used in SPIRE have never been published. of repair cycles, a new schedule and, if necessary, passed on to “min-conflict” is generated by by itself can only solve about 24 out of to that the ability of this approach heuristics. that combines our ORR&FSS heuristics with intelli- to its initialization described our heuristics in [ 45,461. More recently, we reimplemented of demand profiles, using simpler “rough” demand profiles in C++. Most of the problems can be in 3 to 4 CPU seconds on a DECstation 5000/200. We were also able to further to solved speed up the computation identify areas of high contention over which the more detailed demand profiles described in Section 6 are then constructed. The rough demand profiles are obtained by evenly its earliest start time and spreading its latest finish time. Rough demand profiles can easily be updated from one search state to the next and can significantly of more detailed demand profiles over those areas of highest contention. Using the demand of each unscheduled reduce computation operation between time by focusing the construction these 34 N. Sudeh. MS. Fox/Art@cicll Intelligence 86 (1996) I-41 the CPU time required rough demand profiles, fell between 1.5 and 2.5 CPU seconds on a DECstation5000/200, heuristics for the job shop CSP also become more significant on larger problems, as illustrated up to several low backtracking. problems that these in comparison with more recent techniques proposed The speedups obtained using rough demand profiles in Fig. 15. Problems with thousand operations have been solved by the procedure with consistently to solve our 60 benchmark showing remain quite competitive [ 22,33,47]. 9. Summary and concluding remarks (e.g. events subject problem scheduling can be found to this problem to hard constraints in the factory scheduling situations where one needs of a number of rescheduling problems where activities need imposed by various astronomical as the job shop CSP. Examples of this formulation In this paper, we studied a variation of the job shop scheduling problem in which time windows. We operations have to be performed within one or several non-relaxable of the job refer domain when some shop scheduling include operations have to be performed within one or several shifts. Other examples to be scheduled within spacecraft mission [27]). This formulation time windows to revise is also representative imposed by other operations whose schedule we a schedule can be cannot or would rather not modify. More generally, used to model any scheduling problem with hard deadlines. The job shop CSP cannot be rules or similar solved with traditional integer programming one-pass number of binary vari- techniques have so far been overwhelmed in this type of problems for the limited to account ables required [ 321. Our work, which, along with that of Keng and Yun [20], was the first one to apply that this paradigm provides a promising approaches. Our approach enforcing mechanisms with a probabilistic to schedule next (variable ordering) ordering). (reservation scheduling consistency that combines to decide which operation to each operation to traditional search procedure look-ahead analysis by the combinatorial resource capacities to this class of problems, demonstrates relies on a depth-first backtrack the job shop CSP formulation such as priority dispatch and which reservation ‘* Traditional mixed the CSP problem solving paradigm [ 12,26,39]. scheduling scheduling techniques techniques alternative to assign proposed heuristics literature, in the CSP [20]. We showed both generic heuristics for the tightness of constraints and/or In the first part of the paper, we reviewed a number of popular variable and value that had ordering heuristics to perform particularly well on other CSPs as well as Keng and Yun’s been reported fail to adequately scheduling induced by the high account connectivity of the constraint graphs characteristic of job shop CSPs. In the second part a new probabilistic model of the search space that allows of this article, we introduced (i.e. an operation) on the availability of a value us to estimate for the (i.e. a reservation), for the assignment and the degree of contention (i.e. contention among uninstantiated among unscheduled that these heuristics often the reliance of a variable variables operations for the interactions of conflicting values ‘* See [ 41 for experiments applying priority dispatch rules to our set of 60 benchmark problems. N. Sadeh, MS. Fox/Art$cial Intelligence 86 (1996) l-41 35 of a resource over some allocation new variable and value ordering heuristics were defined: resource time interval). Based on this probabilistic model, reliance” that relies most on the most contended (ORR) variable ordering heuristic selects the resource/time interval, and schedules” expected i.e. job schedules to that (FSS) value ordering heuristic assigns to be compatible with the largest number of to survive resource that are expected (2) ( 1) The “operation operation the “filtered survivable operation survivable contention. the reservation job schedules, results show that this pair of heuristics can Experimental of job shop CSPs generic CSP heuristics results indicate search efficiency but also achieve and specialized that could not be efficiently .@cientfy solve a number (both solved by prior CSP heuristics heuristics developed by Keng and Yun). The in increases that the ORR and FSS heuristics not only yield significant important reductions in search time. The estimates of resource contention used in the ORR and FSS heuristics assumptions. More sophisticated independence implemented, which attempt on several have also been cies, some using more complex analytical models Carlo simulations these more sophisticated requirements. [ 431. The improvements versions do not seem to better account [ 41,42,44] While our ORR and FSS heuristics were developed are based versions of these heuristics for different dependen- others relying on Monte achieved by in search efficiency generally to justify their heavier computational as resource allocation problems. For instance, from this work go beyond Fundamental that were described in fact, any CSP with disequality from being assigned and contention and, abilistic measures of reliance resource problem, allocation constraints problems can be formulated problem often used to evaluate CSP techniques tion problem two variables preventing in which each queen/row learned In fact, the lessons that these values in the CSP constraints. for the chances to a variable but do not account often praised like DSR count with disequality ordering heuristics ordering heuristics not account structed. Variable ordering heuristics incident ordering heuristics The probabilistic model of the search space in which more sophisticated ing a framework can be defined. For value goodness FSS heuristics can base count for entire cliques of capacity constraints cliques. like ABT assume their decisions can be used for the job shop CSP, the prob- in any (i.e. these the N-queens as a resource alloca- is a resource. constraints since the same value), can be formulated is a task and each column the number of values like MW or MC count weaknesses as a solution remain available literature have been job shop scheduling of generic variable l3 and CSPs and value identified. Variable left to each variable but do is con- the number of constraints for the tightness of these constraints. Value relaxation. tree-like in this paper aims at provid- and of variable criticality our ORR and that ac- relaxations of these introduced approximations rather than tree-like this framework, on measures of resource contention that the CSP admits a tight instance, within !3 Constraints constraints further restricting admissible resource assignments [ 201. representing the ability of queens to attack each other along diagonals can be represented as 36 N. Sudeh, MS. Fox/Artij?ciul Intelligence X6 (1996) l-41 large-scale domains Finally, while our work shows that the CSP problem solving paradigm does scale up such as the job shop scheduling CSP, it also suggests to complex that benchmark problems considered of this and probably other classes of complex CSPs. We hope that this research will prompt problems on others which to evaluate in the field to revisit earlier studies and look for more challenging in earlier CSP studies are not representative their techniques. Appendix A. Counting the number of survivable schedules to 0: defined procedure in reservation job schedules that efficiently to the relaxation (or more generally a dynamic programming This appendix describes that are compatible with the assignment counts the number of survivable in Section 6.4 for the FSS value ordering heuris- of a reservation p to the current critical t is the start time of a the number of survivable solutions tic) operation Of. This number was referred allocated similar method developed by Dechter and Pearl for the ABT value ordering heuristic of Dechter and Pearl’s procedure [9] in the re- would have an 0( vlk2) complexity laxation used by the FSS value ordering heuristic, number of the procedure described here possible takes advantage to O(v/k). (where V[ is the number of operations [ 361). While a direct generalization p. The procedure presented t), where here and k the maximum in that relaxation), to as compsunt(( of the linearity of an operation this complexity of precedence is a variation reservations constraints to reduce (see also Fig. A.1 represents a prototypical tree-like process constraints nized with the current critical operation precedence critical operation 0: by a precedence operations by precedence constraints, constraint, between operations in the tree are those operations the grandchildren etc. routing, which has been reorga- as the root of the tree. The arrows represent routing. The children of the to 0: to these the operations directly connected that are directly connected in the process Fig. A. 1. A tree-like process precedence constraints. routing, organized with the current critical operation as its root. Arrows represent N. Sadeh. MS. Fox/Artificial Intelligence 86 (1996) l-41 31 All the computations presented to a single checking has already been performed. The notations in this appendix refer in search state, are those used which consistency in Section 6.4. A few extra notations need to be defined: . suw:,(r) = C&o with s$ = t. sur$(p), where G is the set of remaining reservations of Of, l CY~: the direct children of 0; that are after Of in the process routing. l ~3:: the direct children of 0; l A: the time granularity that are before 0; in the process routing. In Section 6.4, it was assumed of the problem. that A = 1 (i.e. that all start times and end times have to be integers). For the sake of clarity, in this appendix account explicitly the formulas presented In tree-like process routings, each operation 0: disjoint sets of operations, contains exactly one child of operation 0: and defines a subproblem that each correspond is the unique for A. link between otherwise to one of its children. Each of these sets that only interacts with the other subproblems via operation 0;. Accordingly: l For each Of E &,, we define BEFL j( t) as the number of survivable solutions to the subproblem defined by operation 0,: and its descendants that are compatible with the assignment of s$ = t to 0:. l For each 0: E af , we define AFTf k(t) as the number of survivable solutions to the subproblem with the assignment of s$ = t to Of. defined by operation 0: and its descendants that are compatible Given that operation Of is the only link between the subproblems defined by each one of its children, we have: compsurvi(t) = n BEF~,j(t) X n AFT:,,(t). .i@f kEaj that this formula also relies on an independence that a solution Notice the probability given by the product of the probabilities that solution BEFi,j(t) survives contention. is obtained by adding all the subproblem to the relaxation survives contention assumption made in Section 6.4: to be in assignments is assumed that each one of the reservation solutions compatible with the precedence constraint st$ + dufi < t: BEF;,j(t) = c ~wv,:.(~) x n BEF~,,JT) x ~AFT;,JT) rQt-du; PEP; e; Similarly for AFTi,,( t), we have: . 1 AFT;,,(t) = c w-v:(~) x T>t+duj a: lIEa: J We can speed up the computation of this recurrence using partial sums: 38 N. Sadeh. M.S. Fox/Artijicial Intelligence 86 (1996) I-41 BEF,!,i(t)=BEFf,,i(t- A) + survi(t -- dui) x n BEFjJt Ia: ~ du;) x n AFT;,,(t - du;) ytn; , I AFT;,,(t) =AFT;,,( t + A) + survi.(t+duj) x n BEFi,,,(t+duf) x ~AFT~,U(t+du~) i W$ ,&I; I The recurrence is initialized with: BEF:,,, (es4 - A) = 0, AFT:,,Jls$ + A) = 0 and uses the convention: I-I = 1. 0 In order to compute compsuw~( t) for all remaining Oi, the system starts by computing in the tree depicted at each the BEFi,,)(t) level in Fig. A. 1. The procedure all BEF:,,, (t) or all AFT:,,,(t) start times of the critical operation at the leaf operations then moves up in the tree by combining and AFT,;,,,(t) computed at the previous level. At each operation O:, in the tree, the procedure computes at most A BEF:,,, (t) expressions if 0; expressions, two multiplications is before O,$, its parent operation, or h AFT:,,(t) is the maximum number of possible start times of an operation). Each such computation involves the relaxation used by the FSS value ordering heuristic, computing be done for all the possible 0( v/k) steps where k is the maximum Hence in all compsurvf (t) can survL( t) = xpEG surv~,(p) requires however i4 number of reservations is also 0( zqk). the overall complexity of the procedure start times of all the operations if ~1 is the number of operations computations. Computing and one addition. Hence, in 0( v/A) elementary if 01, is after 0;. (where A left to an operation. in the relaxation Appendix B. Value ordering filter The following describes a filtering mechanism used to refine the ranking of reserva- tions in our FSS value ordering heuristic. I4 The real complexity This duration is assumed to be bounded by a constant. is actually O( vlkdu), where du 1s the duration of the longest operation in the relaxation. N. Sadeh, MS. Fox/Artijcial Intelligence 86 (1996) 1-41 39 For some reservations influence in (6) compared f32: p, compsurvf ( p) can become very large and have too much p1 and the following to survf(p). Consider two reservations . pl: compsurv~(p~) l p2: compsurvf(p2) = 1000 and suwf(p,) =0.5. = 200 and survf(p2) = 1.0. should recognize reservation pr, despite that reservation the fact that, according in this example, p2 is better to Rq. (6) goodi( pi) = 500 is it does not really matter whether equals 200 or 1000: in either case there will certainly be enough com- of the reported at the end of this paper, this solutions compatible with a Ideally, a good value ordering heuristic than larger than goodf((p2) = 200. Indeed, compsurvf (p) patible schedules. reservation problem was handled by filtering reservation p, compsurvf measures (p) . Instead of relying on Eq. (6), our value ordering heuristic the factor that really matters here is the survivability to the following revised formula: reservation goodness according the number of survivable itself (i.e. locally). In the experiments Instead, goodf ( p> = Sunti ( p) X MZN( P-l, compsurvi ( p) ) , (B-1) the minimum where MN denotes empirically that, on the average, each one of the zq - 1 other operations survivable adjusted. By using a filter of the form Wr-‘, reservations. function I5 and @ is a parameter of the system the heuristic attempts in the relaxation has CD that is to ensure References [II [21 [31 [41 [51 I61 171 [81 [91 1101 [Ill J.F. Allen, Maintaining knowledge about temporal intervals, Commun. ACM 26 (1983) 832-843. K.R. Baker, Inrroducfion to Sequencing and Scheduling (Wiley, New York, 1974). J.R. Bitner and E.M. Reingold, Backtrack programming techniques, Commun. ACM 18 ( 1975) 651-655. C-C. Cheng, Scheduling by precedence constraints posting, Ph.D. Thesis, Graduate School of Industrial Administration and the Robotics Institute, Carnegie Mellon University, Pittsburgh, PA ( 1995), E. Davis, Constraint propagation with interval labels, Artif: Intell. 32 (1987) 281-331. R. Dechter and I. Meiri, Experimental evaluation of preprocessing techniques in constraint satisfaction problems, in: Proceedings IJCAI-89, Detroit, MI ( 1989) 271-277. R. Dcchter and I. Meiri, Experimental evaluation of preprocessing algorithms for constraint satisfaction problems, Art$ Intell. 68 (1994) 21 l-241. R. Dechter, I. Meiri and J. Pearl, Temporal constraint networks, in: Proceedings First ln?ernational Conference on Principles of Knowledge Representation and Reasoning, Toronto, Ont. ( 1989). R. Dcchter and J. Pearl, Network-based heuristics for constraint satisfaction problems, Artif: Intell. 34 (1988) 1-38. M.S. Fox, Constraint-Directed Search: A Case Study of Job-Shop Schedufing (Morgan Kaufmann, Los Altos, CA, 1987). MS, Fox, N. Sadeh and C. Baykan, Constrained heuristic search, in: Proceedings IJCAI-89, Detroit, MI (1989) 309-315. l5 A more sophisticated way of filtering compsu~(p) would involve filtering the number of compatible reservations of each operation in the relaxation. This would ensure that each one of the operations in the relaxation has enough compatible reservations. In general, because the critical operation is also the one in the relaxation whose reservations are the least survivable, a single filter for all the other operations in the relaxation seems sufficient. 40 N. Sudeh, M.S. Fox/Art#ficicrl Intelligence 86 (1996) I-41 [ I2 I S. French, SequtvwinX New York, 1982). ccnd Scheduling: An Introdu&m to the Mufhemutics of the Job-Shop (Wiley, [ 13 1 E.C. Freuder, A sufficient condition 1 14 1 M.R. Garey and D.S. Johnson, Computers (Freeman, San Francisco, CA. 1979). for backtrack-free search, J. ACM 29 ( 1982) 24.-32. trnd Intruc~tubilitv: A Guide to the Theory c~~NP-Conlpleteness I 151 M.L. Ginsberg, M. Frank, M.P. Halpin and M.C. Torrance, Search on Artijicial puzzle, lessons learned from crossword Infelligence ( 1990) 210-215. in: Proreedings of thr Eighth Nationtrl Conjerewu ( I6 I SW. Golomb and L.D. Baumert. Backtrack programming, 1 171 R.M. Haralick and G.L. Elliott, Artif Intell. 14 (1980) 263-313. [ I8 1 L.A. Johnson and D.C. Montgomery. Increasing 0l~nifion.s J. ACM 12 ( 1965) S16-S24. tree search efficiency for constraint satisfaction problems, Ke.\eorclt in Production Plowing, Scheduling, cmd Imvntory Confrol (Wiley, New York, 1974). I I9 I M.D. Johnston and S. Minton, Analyzing a heuristic strategy for constraint satisfaction and scheduling, in: M. Fox and M. Zweben. eds.. Intelligent Schedulirl,q (Morgan Kaufmann, Los Altos, CA, 1994) 257-289, Chapter 9. 120 1 N. Keng and D.Y.Y. Yun, A planning/scheduling methodology for the constrained resource problem, in: Proceedings IJCAI-89. Detroit. MI ( 1989) 998-1003. / 2 I 1 C. Le Pape and S.F. Smith, Management of temporal constraints for factory scheduling, Tech. Kept., The Robotics Institute. Carnegie Mellon University, Pittsburgh. PA ( 1987): also in: Proceedings Working C‘orrferencr on Tmrporcd Aspects 111 fnformution .Systcms, Paris (North-Holland, Amsterdam, 1987). 122 I J. Liu and K. Sycara, Collective problem solving through coordination in a society of reactive agents, Tech. Rept. CMU-RI-TR-94-23, The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA (1994). I23 I A.K. Mackworth and E.C. Freuder. The complexIt) 01. some polynomial network consistency algorithms for constraint satisfaction problems. Art$ Intell. 25 ( 198.5) 6.5-74. j 24 1 J.J. McGregor, Relational consistency algorithms and their applications in finding subgraph and graph isomorphisms. Infi~rrrr. Sci. 19 ( 1979) 229-250. 12.51 S. Minton, M.D. Johnston, A.B. Philips and P. Laird. Minimizing conflicts: a heuristic repair method for constraint 1261 T.E. Morton, satisfaction and scheduling problems. Ar-hf. /tall. 58 ( 1992) 161~205. and D.W. Pentico, Heuristic, Scheduhng Systems. Wiley Series in Engineering and Technology Management (Wiley, New York, 1993). I27 1 N. Muscettola, HSTS: integrating planning and scheduling, in: M. Fox and M. Zweben, eds., intelligent (Morgan Kaufmann, Los Altos, CA, 1994) 169-212, Chapter 6. and S. Smith, A probabilistic framework for resource-constrained multi-agent planning, in: Proceedings AAAI-87, Seattle, WA ( 1987) IO63- 1066. I29 I B. Nadel, Tree search and arc consistency in constraint satisfaction algorithms. in: L. Kanal and V. Kumar, eds., Seclrcll in Artickl Intelligerlce (Springer, Berlin, l988), [ 301 B.A. Nadel, Theory-based search-order selection for constraint satisfaction problems, Tech. Rept. DCS- TR-I 83, Department of Computer Science. Laboratory for Computer Research, Rutgers University, New Brunswick. NJ ( 1986). 131 D. Navinchandra, Explorrrtion and Innowtion in L)esi,qIl (Springer, Berlin, 1990). I32 I33 I 34 13s G.L. Nemhauser and L.A. Wolsey. Integer und Combinatoritrl Optimization (Wiley, New York, 1988). W.P.M. Nuijten, Time and resource constrained scheduling, Ph.D. Thesis. Technische Universiteit Eindhoven, Eindhoven ( 1994 1. P.S. Ow. Focused scheduling in proportionate Howshops. Muncher. Sci. 31 ( 1985) 852-869. J. Pearl, Heuristics: Intelligent Secwh Srrcuqies ,/i)r- Computer Problem Solving (Addison-Wesley, Reading, MA, 1984). I 36 I J. Pearl, Probtrbilistk Recuorzing 111 Irztek,~rnt .Swcm.~: Networks of Pkusible frrference ( Morgan Kaufmann, Los Altos, CA, 1988). I37 I F!W. Purdom Jr, Search rearrangement backtracking and polynomial average time, Artif: fnrell. 21 ( 1983) 117-133. I38 I N. Sadeh, Look-ahead techniques for activity-based job-shop scheduling, Thesis Proposal ( 1989). I39 1 N. Sadeh, Look-ahead techniques for micro-opportunistic job shop scheduling, Ph.D. Thesis, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA ( 199 I ). Scheduliqq j 28 I N. Muscettola N. Sadeh, M.S. Fox/Artijcial Intelligence 86 (1996) 1-41 41 (401 N. Sadeh, Micro-opportunistic scheduling: the MICRO-BOSS factory scheduler, in: M.S. Fox and M. Zweben, eds., Intelligent Scheduling (Morgan Kaufmann, Los Altos, CA, 1994) 99-135, Chapter 4. ]41] N. Sadeh and M.S. Fox, Preference graphs, Tech. Rept. in temporal/capacity Computer Science Department, Carnegie Mellon University, Pittsburgh, PA ( 1988); propagation constraint CMU-CS-88-193, also: Robotics Institute Tech. Rept. CMU-RI-TR-89-2. [42] N. Sadeh and M.S. Fox, Focus of attention Conference on Space Telerobotics (1989). in an activity-based scheduler, in: Proceedings NASA [43] N. Sadeh and M.S. Fox, CORTES: an exploration into micro-opportunistic job-shop scheduling, in: Proceedings IJCAI-89, Detroit, MI ( 1989). (44 ] N. Sadeh, and M.S. Fox, Variable and value ordering heuristics for activity-based job-shop scheduling, in: Proceedings Fourth International Conference on Expert Systems in Production and Operations Management, Hilton Head Island, SC ( 1990) 134-144. [45] N. Sadeh, K. Sycara and Y. Xiong, Backtracking CMU-RI-TR-92-06, The Robotics for hard scheduling problems, Tech. Rept. Institute, Carnegie Mellon University, Pittsburgh, PA ( 1992); also: techniques Artif Infell. 76 (1995) 455-480 (improved version). [46] N. Sadeh, K. Sycara and Y. Xiong, Backtracking satisfaction earlier version of this paper also appeared as CMU Tech. Rept. CMU-RI-TR-92-06. problem, Artif: Intell. 76 (1995) 455-480; techniques for the job shop scheduling also: CMU Tech. Rept. CMU-RI-TR-94-31; constraint an [47] SF, Smith and C. Cheng, Slack-based AAAI-93, Washington, DC (1993). heuristics for constraint satisfaction scheduling, in: Proceedings [ 481 R.E. Tarjan, Minimum spanning Conference Series in Applied Mathematics trees, in: Data Structures and Network Algorithms, CBMS-NSF Regional 44 (SIAM, Philadelphia, PA, 1983) Chapter 6. [ 491 P Van Hentenryck, H. Simonis and M. Dincbas, Constraint satisfaction using constraint logic programming, Artif Intell. 58 ( 1992) 113-159. [SO] R.J. Walker, An enumerative technique for a class of combinatorial problems, in: R. Bellman and M. Hall, eds., Combinatorial Analysis, Proceedings Symposium on Applied Mathematics (American Mathematical Society, Providence, RI, 1960) 91-94, Chapter 7. [ 511 R. Zabih and D. McAllester, A rearrangement search strategy for determining propositional satisfiability, in: Proceedings AAAI-88, St. Paul, MN (1988) 155-160. [ 521 M. Zweben, B. Daun, E. Davis and M. Deale, Scheduling and rescheduling with iterative repair, in: MS. Fox and M. Zweben, eds., bzrelligent Scheduling (Morgan Kaufmann, Los Altos, CA, 1994) 241-255, Chapter 8. 