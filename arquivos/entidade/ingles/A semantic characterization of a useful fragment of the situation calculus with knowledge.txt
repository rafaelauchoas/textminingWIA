Artificial Intelligence 175 (2011) 142–164Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA semantic characterization of a useful fragment of the situation calculuswith knowledgeGerhard Lakemeyer a,∗, Hector J. Levesque ba Dept. of Computer Science, RWTH Aachen, 52056 Aachen, Germanyb Dept. of Computer Science, University of Toronto, Toronto, Ontario, Canada M5S 3A6a r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Knowledge representationReasoning about action1. IntroductionThe situation calculus, as proposed by McCarthy and Hayes, and developed over the lastis reconsidered. A new logical variant called ES isdecade by Reiter and co-workers,proposed that captures much of the expressive power of the original, but where certaintechnical results are much more easily proved. This is illustrated using two existingnon-trivial results: the determinacy of knowledge theorem of Reiter and the regressiontheorem, which reduces reasoning about the future to reasoning about the initial situation.Furthermore, we show the correctness of our approach by embedding ES in Reiter’ssituation calculus.© 2010 Elsevier B.V. All rights reserved.Among the many contributions of John McCarthy, the formalism of the situation calculus has proved to be an extremelyuseful tool for reasoning precisely about action and change. It was originally proposed in [29,30] as a dialect of first-orderlogic. A second-order refinement of the language, developed by Reiter and his colleagues [36], forms the theoretical andimplementation foundation for Golog [27], a language for the high-level control of robots and other agents (see, for example,[2,31]). Over the past decade, a number of extensions have been proposed to deal with issues such as time, natural actions,knowledge of agents, numerical uncertainty, or utilities (see [36] and the references therein).As a formalism, the situation calculus is based on axioms. In Reiter’s formulation, which is also our starting point, thesetake the form of so-called basic action theories. These consist of a number of foundational axioms, which define the space ofsituations, unique-name axioms for actions, axioms describing action preconditions and effects, and axioms about the initialsituation.What makes basic action theories particularly useful is the formulation of action effects in terms of successor state axioms,which not only provide a simple solution to the frame problem [35] but also allow the use of regression-based reasoning,which has been used in planning [8] and forms the core of every Golog interpreter, for example. Derivations using regressionare simple, clear, and computationally feasible.Since the situation calculus is defined axiomatically, no special semantics is needed. Tarskian models suffice, providedthey satisfy the foundational axioms. When the focus is on logical entailments, which is the case in the execution of Gologprograms, for example, this approach seems perfectly adequate.However, when we wish to consider theoretical questions about basic action theories that are not direct entailmentquestions, problems arise. For example, suppose we are doing an analysis of our system, and want to know, if wheneverTheory1 entails Formula1, is it also true that Theory2 entails Formula2? Here we can run into serious complications in an* Corresponding author.E-mail addresses: gerhard@cs.rwth-aachen.de (G. Lakemeyer), hector@cs.toronto.edu (H.J. Levesque).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.005G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164143Fig. 1. A simple robot.axiomatic setting unless there are ways to take derivations of Formula1 from Theory1 and convert them into derivations ofFormula2 from Theory2. Similar issues arise with consistency questions.For instance, consider the epistemic extension of the situation calculus, as introduced by Moore and later extended byScherl and Levesque [32,39]. If Know( A) entails (Know(B) ∨ Know(C)) in this theory, is it also true that Know( A) entailsKnow(B) or Know( A) entails Know(C)? For restricted A, B, C , the answer is yes, but the proof by Reiter requires a multi-page argument using considerable proof–theoretic machinery, including Craig’s Interpolation Lemma [37].One might wonder whether a semantic proof using Tarski structures would be any easier. The answer, in short, is no. Theproblem is that different Tarski structures can have different domains and considerable effort is required to standardize thedomains, identify the situations, and amalgamate multiple structures into a single structure that satisfies the foundationalaxioms. While certainly possible, the argument is again long and complicated.In contrast, in the epistemic logic KL [22], the semantic proof of the above determinacy of knowledge theorem is simple,clear and direct. One reason for this is the use of a semantic formulation involving possible worlds for knowledge [12,7].Typical of these formalisms, situations and possible worlds are not reified in the language itself. Beyond this, however,a major factor in the simplicity of proofs in KL (and its extension, OL) is the use of standard names, which allows a substi-tutional interpretation of the first-order quantifiers.1 While there have been philosophical arguments against substitutionalquantification [18], our experience has been that its technical simplicity has been of tremendous help in tackling issuessuch as quantifying-in [15], which are rarely addressed in other formalisms.Since KL only deals with static knowledge bases, an amalgamation of KL and the situation calculus was previously pro-posed [19]. However, this formalization kept situations reified, did not allow substitutional quantification, and the definitionof knowledge required second-order logic, all of which again complicated the proofs considerably, even semantic ones.In this paper, we propose a rather different amalgamation of KL and the situation calculus called ES. The idea is tokeep the simplicity of KL, and while dropping some of the expressiveness of the ordinary situation calculus, retain its mainbenefits, like successor state axioms to solve the frame problem and regression-based reasoning. In particular, we will use apossible-world semantics where situations are part of the semantics but do not appear as terms in the language. In order torepresent what is true in a situation after a number of actions have occurred, we use special modal operators. For example,we will have formulas like those of traditional dynamic logic [33,10], such as[forward] [forward] distance = 4to say that a robot is four units away from a wall after moving forward twice (see Fig. 1 for an illustration). In contrastto other modal approaches such as [3,11,5] but similar to [6], we also allow formulas of the form ∀a, x.([a](distance = x) ≡φ), where modalities contain (action) variables. This feature will be key in reconstructing Reiter’s basic action theories inour language. Moreover, unlike standard modal logics (including dynamic logics), we will be able to use a substitutionalinterpretation for first-order quantifiers. This is perhaps the main reason why we cannot afford situation terms as part ofour language. The epistemic situation calculus requires us to consider an uncountable number of initial situations (see [26]for a second-order foundational axiom that makes this explicit). In a language with only countably many situation terms,this would preclude a substitutional interpretation of quantifiers.Yielding much simpler proofs (like the determinacy of knowledge and the correctness of regression) still leaves open thequestion of the overall correctness of the approach. In other words, is ES really a faithful reconstruction of the situationcalculus? We will prove that it is by providing an embedding of ES in Reiter’s version of the situation calculus, showingthat the valid sentences of ES can be cast as entailments in Reiter’s original version (modulo some modest assumptions).This shows that ES is a notational variant for a fragment of the situation calculus that can be given a clean and work-able semantics. In addition, this result allows us to automatically transfer results obtained for ES to that fragment of thesituation calculus, which is expressive enough to formulate basic action theories, and more.The rest of the paper is organized as follows. In the next section we introduce the syntax and semantics of ES anddiscuss some of the properties of knowledge. In Section 3, we introduce the ES-version of Reiter’s basic action theories,1 Roughly speaking, this amounts to assuming at the outset that the domain of quantification is countably infinite and that there is a set of specialconstants called standard names uniquely denoting each element of the domain. A first-order universal sentence then ends up being true iff every instanceof the sentence, where a standard name substitutes for the variable, is true.144G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164followed by regression theorems for the non-epistemic and epistemic case. Section 5 provides the results on embedding ESin the situation calculus. We end the paper with a discussion of related work, only-knowing, and concluding remarks.2. The logic ESThe language is a second-order modal dialect with equality and sorts of type object and action. Before presenting theformal details, here are the main features:• Standard names: Unlike other languages (but similar to KL), the language includes (countably many) standard names forboth objects and actions. These can be thought of as special extra constants that satisfy the unique name assumptionand an infinitary version of domain closure. This allows first-order quantification to be understood substitutionally.Equality can also be given a simpler treatment: every ground term will have a coreferring standard name, and twoterms are considered equal if their coreferring standard names are identical.• Fluent and rigid functions and predicates: The language also contains both fluent and rigid predicate and function symbols.Fluents vary as the result of actions and have values that may be unknown, but rigids do not. These are present in theoriginal situation calculus, of course. For example, we might have a sentence like this in the situation calculus:Fragile(c) ∧ ¬ Broken(c, S0).Here we can see that the first predicate is rigid and the second one is fluent just by seeing if the last argument is asituation. In our case, we do not have situation terms, and so we will need to distinguish the two sorts of predicatessyntactically and semantically. Furthermore, for second-order quantification, we will need to distinguish rigid and fluentpredicate variables as well.2• Knowledge and truth: The language includes a modal operator Know for knowledge. This allows us to distinguish betweensentences that are true and sentences that are known (by some implicit agent). For example, we can model situationswhere a robot is close to a wall but does not yet know it. We can also model situations where a robot has false beliefsabout its world or how its world changes. The connection between knowledge and truth is made with sensing. Everyaction is assumed to have a binary sensing result and after performing the action, the agent learns that the action waspossible (as indicated by the Poss predicate) and whether the sensing result for the action was 1 or 0 (as indicated bythe SF predicate).2.1. The languageDefinition 1. The symbols of ES are taken from the following vocabulary:• first-order variables: x1, x2, . . . , y1, y2, . . . , a1, a2, . . . ;2, . . . ;• fluent second-order variables of arity k: P k• rigid second-order variables of arity k: Q k2, . . . ;• standard names: n1, n2, . . . for objects and actions;• fluent function symbols of arity k: f k1 , f k• rigid function symbols of arity k: gk1, gk• fluent predicate symbols of arity k: F k• rigid predicate symbols of arity k: Gk• connectives and other symbols: =, ∧, ¬, ∀, Know, (cid:2), round and square parentheses, period, comma.2 , . . . ; for example, distance;2, . . . ; for example, forward;2, . . . ; for example, Broken;1, F k2, . . . ; for example, BrotherOf ;1, Gk1, P k1, Q kWe assume that all action function symbols are rigid and that the fluent predicates include the special predicates Possand SF.Definition 2. The terms of the language are of sort action or object, and form the least set of expressions such that1. Every standard name and first-order variable is a term of the corresponding sort;2. If t1, . . . , tk are terms and h is a k-ary function symbol then h(t1, . . . , tk) is a term of the same sort as h.By a primitive term we mean one of the form h(n1, . . . , nk) where h is a (fluent or rigid) function symbol and all of theni are standard names.2 We follow Reiter in including both types of symbols. It is possible to live with just fluents, however, and treat rigids as fluents that happen not tochange.G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164145Definition 3. The well-formed formulas of the language form the least set such that1. If t1, . . . , tk are terms, and H is a k-ary predicate symbol then H(t1, . . . , tk) is an (atomic) formula;2. If t1, . . . , tk are terms, and V is a k-ary second-order variable, then V (t1, . . . , tk) is an (atomic) formula;3. If t1 and t2 are terms, then (t1 = t2) is a formula;4. If t is an action term and α is a formula, then [t]α is a formula;5. If α and β are formulas, v is a first-order variable, and V is a second-order variable, then the following are alsoformulas: (α ∧ β), ¬α, ∀v.α, ∀V .α, (cid:2)α, Know(α).We read [t]α as “α holds after action t”, and (cid:2)α as “α holds after any sequence of actions.” So, for example, here is asuccessor state axiom in this language (we follow the usual convention of having free variables universally quantified fromthe outside):(cid:2)(cid:2)[a] Broken(x) ≡(cid:2)(cid:3)a = drop(x) ∧ Fragile(x)(cid:2)Broken(x) ∧ a (cid:7)= repair(x)∨(cid:3)(cid:3)In English: after any sequence of actions, an object x will be broken after doing action a iff a is the dropping of x whenx is fragile or x was already broken and a is not the action of repairing it.As usual, we treat (α ∨ β), (α ⊃ β), (α ≡ β), ∃v.α, and ∃V .α as abbreviations. To ease notation, we leave the type ofvariables implicit. We reserve the symbol a to denote a variable of type action.We use αxn to mean formula α with all free occurrences of variable x replaced by name n. We call a formula withoutfree variables a sentence. By a primitive sentence we mean a formula of the form H(n1, . . . , nk) where H is a (fluent or rigid)predicate symbol and all of the ni are standard names.In the following, we will sometimes refer to special sorts of first-order formulas and use the following terminology:• a formula with no (cid:2) operators is called bounded;• a formula with no (cid:2) or [t] operators is called static;• a formula with no Know operators is called objective;• a formula with no fluent, (cid:2), or [t] operators outside the scope of a Know is called subjective;• a formula with no Know, (cid:2), [t], Poss, or SF is called a fluent formula.32.2. The semanticsThe main purpose of the semantics we are about to present is to be precise about how we handle fluents, which mayvary as the result of actions and whose values may be unknown. Intuitively, to determine whether or not a sentence αis true after a sequence of actions z has been performed, we need to specify two things: a world w and an epistemicstate e. We write e, w, z |(cid:10) α. A world determines truth values for the primitive sentences and coreferring standard namesfor the primitive terms after any sequence of actions. An epistemic state is defined by a set of worlds, as in possible-worldsemantics.More precisely, let N denote the set of all standard names and Z the set of all finite sequences of standard actionnames, including (cid:11) (cid:12), the empty sequence. Then• a world w ∈ W is any function from the primitive sentences and Z to {0, 1}, and from the primitive terms and Z to N(preserving sorts), and satisfying the rigidity constraint: if g is a rigid function or predicate symbol, then for all z andz(cid:14)];(cid:14)in Z , w[g(n1, . . . , nk), z] = w[g(n1, . . . , nk), z• an epistemic state e ⊆ W is any set of worlds.We extend the idea of coreferring standard names to arbitrary ground terms as follows. Given a term t without variables,a world w, and an action sequence z, we define |t|zw (read: the coreferring standard name for t given w and z) by:1. If t ∈ N , then |t|zw= w[h(n1, . . . , nk), z], where ni = |ti|z2. |h(t1, . . . , tk)|zw .w= t;So to find a coreferring standard name for h(t1, . . . , tk), we find coreferring names for the ti recursively, and then usethe function w on the resulting primitive term.3 In the situation calculus, these correspond to formulas that are uniform in some situation term.146G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164To interpret formulas with free variables, we proceed as follows. First-order variables are handled substitutionally usingthe standard names. To handle the quantification over second-order variables, we use second-order variable maps defined asfollows:The second-order primitives are formulas of the form V (n1, . . . , nk) where V is a (fluent or rigid) second-order variableand all of the ni are standard names. A variable map u is a function from worlds, second-order primitives, and Z to{0, 1}, satisfying the rigidity constraint: if Q is a rigid second-order variable, then for all w and win W , and all z and(cid:14)zin Z , u[w, Q (n1, . . . , nk), z] = u[w(cid:14), Q (n1, . . . , nk), z(cid:14)].(cid:14)Let u and u(cid:14)be variable maps, and let V be a (fluent or rigid) second-order variable; we write u(cid:14) ∼V u to mean that u(cid:14)and uagree except perhaps on the second-order primitives involving V .(cid:14) (cid:17)z w (read: w(cid:14)agrees withFinally, to interpret what is known after a sequence of actions has taken place, we define ww agree on the sensing throughout action sequence z) inductively by the following:1. w2. w(cid:14) (cid:17)(cid:11) (cid:12) w iff w(cid:14)(cid:14) (cid:17)z·n w iff w(cid:4)(cid:14)wSF(n), zand w agree on the value of every primitive rigid term and sentence;(cid:14) (cid:17)z w, w(cid:4)= wSF(n), z(cid:14)[Poss(n), z] = 1, and(cid:5)(cid:5).Note that (cid:17)z is not quite an equivalence relation because of the use of Poss here. As will become clearer, this is becausewe are insisting that the agent comes to believe that Poss was true after performing an action, even in those “non-legal”situations where the action was not possible in reality.4Putting all these together, here is the semantic definition of truth. Given a sentence α of ES, an epistemic state e ⊆ Wand a world w ∈ W , we define e, w |(cid:10) α (read: α is true at e and w) as e, w, (cid:11) (cid:12), u |(cid:10) α for any second-order variable map u,where for any z ∈ Z we have:1. e, w, z, u |(cid:10) H(t1, . . . , tk) iff w[H(n1, . . . , nk), z] = 1, where ni = |ti|zw ;2. e, w, z, u |(cid:10) V (t1, . . . , tk) iff u[w, V (n1, . . . , nk), z] = 1, where ni = |ti|z3. e, w, z, u |(cid:10) (t1 = t2) iff n1 and n2 are identical, where ni = |ti|z4. e, w, z, u |(cid:10) [t]α iff e, w, z · n, u |(cid:10) α, where n = |t|z5. e, w, z, u |(cid:10) (α ∧ β) iff e, w, z, u |(cid:10) α and e, w, z, u |(cid:10) β;6. e, w, z, u |(cid:10) ¬α iff e, w, z, u (cid:7)|(cid:10) α;7. e, w, z, u |(cid:10) ∀x.α iff e, w, z, u |(cid:10) αx8. e, w, z, u |(cid:10) ∀V .α iff e, w, z, u9. e, w, z, u |(cid:10) (cid:2)α iff e, w, z · z10. e, w, z, u |(cid:10) Know(α) iff e, w(cid:14) |(cid:10) α, for every u(cid:14), u |(cid:10) α, for every z(cid:14), z, u |(cid:10) α, for every w(cid:14) ∈ e such that w(cid:14) ∼V u;(cid:14) ∈ Z ;w ;w ;w ;(cid:14) (cid:17)z w.n, for every standard name n of the right sort;When α is objective (has no Know operators), we can leave out the e and write w |(cid:10) α. Similarly, when α is subjective,we can leave out the w and write e |(cid:10) α. When Σ is a set of sentences and α is a sentence, we write Σ |(cid:10) α (read:Σ logically entails α) to mean that for every e and w, if e, w |(cid:10) α(cid:14)for every α(cid:14) ∈ Σ , then e, w |(cid:10) α. Finally, we write |(cid:10) α(read: α is valid) to mean {} |(cid:10) α.2.3. KnowledgeAt this point we will not go into a detailed discussion of the properties of ES. Instead we will focus on knowledge as afirst example of how the semantics of ES allows us to prove properties with relative ease. A more complete picture of ESwill emerge later when we establish a formal connection with Reiter’s situation calculus.The interpretation of knowledge in ES is just a special case of possible-world semantics [17,12]. One minor featureworth noting is that we do not simply require truth in all elements of e, the given set of “possible worlds,” as in KL. Infact, e represents the initial state of knowledge, and as knowledge is acquired though action, some of those initial worldswill no longer be considered possible. This is reflected in the (cid:17)z relation. In a nutshell, we look for truth in all elements ofe that agree with the real world w in terms of sensing. It will then follow that after doing a sequence of actions, the agentwill know the correct values of the sensing results in the real world (and everything it can conclude from that).Regarding the more traditional logical properties of knowledge, it is not surprising that we obtain the usual propertiesof weak S5 or K45 [7]. Since we assume a fixed universe of discourse, the Barcan formula for knowledge (Property 4 of thefollowing theorem) and its existential version (Property 5) hold as well. Moreover, these properties hold after any numberof actions have been performed.4 An alternate account that would state that the agent learns the true value of Poss (analogous to SF) is a bit more cumbersome, but would allow (cid:17)z tobe a full equivalence relation.G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164147Theorem 1.1. |(cid:10) (cid:2)(Know(α) ∧ Know(α ⊃ β) ⊃ Know(β));2. |(cid:10) (cid:2)(Know(α) ⊃ Know(Know(α)));3. |(cid:10) (cid:2)(¬ Know(α) ⊃ Know(¬ Know(α)));4. |(cid:10) (cid:2)(∀x. Know(α) ⊃ Know(∀x.α));5. |(cid:10) (cid:2)(∃x. Know(α) ⊃ Know(∃x.α)).Proof.1. Let e, w, z |(cid:10) Know(α) ∧ Know(α ⊃ β). Then for all we, w(cid:14), z |(cid:10) β and, therefore, we have that e, w, z |(cid:10) Know(β).2. Let e, w, z |(cid:10) Know(α). Let w(cid:14)and w(cid:14)(cid:14) (cid:17)z w and, therefore, e, w(cid:14)(cid:14)relation, we have whave e, w(cid:14), z |(cid:10) Know(α) and, hence, e, w, z |(cid:10) Know(Know(α)).be worlds in e such that w3. Let e, w, z |(cid:10) ¬ Know(α). Thus for some wand w(cid:14)(cid:14) ∈ e. Clearly, e, w(cid:14)(cid:14), z |(cid:10) ¬ Know(α). Since w4. Let e, w, z |(cid:10) ∀x. Know(α). Hence for all r ∈ R, e, w, z |(cid:10) Know(αxof the right sort, e, w, z |(cid:10) αxn, from which e, w, z |(cid:10) Know(∀x.α) follows.(cid:14) (cid:17)z w, if w(cid:14) ∈ e then e, w(cid:14), z |(cid:10) α and e, w(cid:14), z |(cid:10) (α ⊃ β). Hence,(cid:14)(cid:14), z |(cid:10) α by assumption. As this is true for all w(cid:14) (cid:17)z w and w(cid:14)(cid:14) (cid:17)z w(cid:14). Since (cid:17)z is an equivalence, we(cid:14)(cid:14) ∈ e with w(cid:14)(cid:14) (cid:17)z w(cid:14)(cid:14), w(cid:14) (cid:17)z w, w(cid:14) ∈ e and e, w(cid:14), z (cid:7)|(cid:10) α. Let w(cid:14)(cid:14)be any world such that w(cid:14)(cid:14) (cid:17)z w(cid:14)(cid:14)(cid:14) (cid:17)z w, e, w, z |(cid:10) Know(¬ Know(α)) follows.r ) and thus for all w(cid:14) (cid:17)z w, if w(cid:14) ∈ e then for all n ∈ N5. Let e, w, z |(cid:10) ∃x. Know(α). Then e, w, z |(cid:10) Know(αxn) for some n ∈ N . By the definition of Know, it follows that e, w, z |(cid:10)Know(∃x.α). (cid:2)We remark that the converse of the Barcan formula (Property 4) holds as well. However, note that this is not the casefor Property 5: (cid:2)(Know(∃x.α) ⊃ ∃x. Know(α)) is not valid in general. Despite the fact that quantification is understoodsubstitutionally, knowing that someone satisfies α does not entail knowing who that individual is, just as it should be.Perhaps more interestingly, we can easily prove a generalized version of the determinacy of knowledge:Theorem 2. Suppose α is an objective sentence and β is an objective formula with one free variable x, such that |(cid:10) Know(α) ⊃∃x. Know(β). Then for some standard name n, |(cid:10) Know(α) ⊃ Know(β xn).Proof. Suppose not. Then for every n (of the right sort), Know(α) does not entail Know(β xα does not entail β xThen we have that e |(cid:10) Know(α) and for every standard name n, e |(cid:10) ¬ Know(β xthe fact that Know(α) entails ∃x. Know(β). (cid:2)n. So for every n, there is a world wn such that wn |(cid:10) (α ∧ ¬β xn), and so, by the lemma below,n). Now let e = {wn | n a standard name}.n), and so e |(cid:10) ∀x.¬ Know(β). This contradictsLemma 1. If α and β are objective, and |(cid:10) (α ⊃ β), then |(cid:10) (Know(α) ⊃ Know(β)).Proof. Suppose that some e |(cid:10) Know(α). Then for every w ∈ e, w |(cid:10) α. Then for every w ∈ e, w |(cid:10) β. Thus e |(cid:10) Know(β). (cid:2)This proof is exactly as it would be in KL. Again it is worth noting that the proof of this theorem in the ordinarysituation calculus (for the simpler case involving disjunction rather than existential quantification) is a multi-page argumentinvolving Craig’s Interpolation Lemma.3. Basic action theoriesLet us now consider the equivalent of basic action theories of the situation calculus. Since in our logic there is no explicitnotion of situations our basic action theories do not require foundational axioms like Reiter’s second-order induction axiomfor situations [36]. In fact, for this and the next section we will have no use for second-order logic at all and only considerthe first-order fragment of ES.Definition 4. Given a set of fluents F , a set Σ ⊆ ES of sentences is called a basic action theory over F iff Σ = Σuna ∪ Σ0 ∪Σpre ∪ Σpost ∪ Σsense where Σ mentions only fluents in F and1. Σuna is a set of unique names axioms for action functions;2. Σ0 is any set of fluent sentences;3. Σpre is a singleton sentence of the form (cid:2) Poss(a) ≡ π , where π is a fluent formula5;5 We assume that (cid:2) has lower syntactic precedence than the logical connectives, so that (cid:2) Poss(a) ≡ π stands for ∀a.(cid:2)(Poss(a) ≡ π ).148G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–1644. Σpost is a set of sentences of the form (cid:2)[a]F ((cid:19)v) ≡ γF or (cid:2)[a] f ((cid:19)v) = y ≡ γ f , one for each relational fluent F andfunctional fluent f , respectively, and where γF and γ f are fluent formulas6;5. Σsense is a sentence exactly parallel to the one for Poss of the form (cid:2)SF(a) ≡ ϕ, where ϕ is a fluent formula.The idea here is that Σ0 expresses what is true initially (in the initial situation), Σpre is one large precondition axiom,and Σpost is a set of successor state axioms, one per fluent, which incorporate the solution to the frame problem proposedby Reiter [35]. Here we follow the convention of [39] that every action returns a sensing result. Σsense then captures theoutcome of sensing actions. For actions like forward, which do not return any useful sensing information, SF can be definedto be vacuously true (see below for an example).7Since an agent’s beliefs may differ from what is true, we will, in general, need two basic action theories: Σ for whatis true in the world, including its dynamics, and Σ (cid:14)for what the agent believes to be true. Except for the unique namesassumption for actions, the two are allowed to differ arbitrarily and even contradict each other to allow for false beliefs.A state of affairs can then be characterized by sentences of the form Σ to denote what is actually true, Know(Σ (cid:14)) to denotewhat the agent believes to be true, and perhaps a set of sentences ¬ Know(φ) to capture some of the agent’s ignorance.8We will be interested in the what is entailed by such theories.As an example, imagine a robot that lives in a 1-dimensional world, and that can move towards or away from a fixedwall. The robot also has a sonar sensor that tells it when it gets close to the wall, say, less than 10 units away. See Fig. 1.So we might imagine three actions, forward and backward which move the robot one unit towards and away from the wall,and a sonar sensing action which tells the robot if it is close to the wall but has no effect on the world. For simplicity,we will simply assume that these three are standard names, that is, we do not need to stipulate unique names axioms forthese. We have a single fluent, distance, which gives the actual distance from the robot to the wall.9Let us consider informally how sensing relates knowledge to truth here. We start in some initial epistemic state e andworld w. Initially, before any actions have taken place, the action sequence z is (cid:11) (cid:12). We might suppose that w[distance, (cid:11) (cid:12)] =∗[distance, (cid:11) (cid:12)] = 13. Now suppose6 as in the diagram. If the robot does not know where it is, there may be a w∗[SF(sonar), (cid:11) (cid:12)] = 0. Inthe robot performs a sonar action. In this case, we would expect that w[SF(sonar), (cid:11) (cid:12)] = 1, but wother words, if the sonar is doing its job, in w it would tell us that the robot is close to the wall and in wit would tell∗ (cid:7)(cid:17)z w, since they disagree on the SFus that the robot is far from the wall. So if we now let z = (cid:11)sonar(cid:12), we see that w(cid:14)[SF(sonar), (cid:11) (cid:12)] = 1. Since the definition of Know uses (cid:17),value. In fact, for every wwhen we consider what is known after doing the sonar action, the robot will believe (correctly) that it is close to the wall:e, w, (cid:11)sonar(cid:12) |(cid:10) Know(distance < 10).(cid:14) (cid:17)z w, we will have that w∗ ∈ e where wsuch that w∗(cid:14)Let us now make all this precise. We begin our formalization by writing preconditions for the three actions:(cid:2) Poss(a) ≡a = forward ∧ distance > 0 ∨a = backward ∧ TRUE ∨a = sonar ∧ TRUE.In other words, while backward and sonar are always possible, forward is executable only when the robot is not already atthe wall. Next, we define the sensing results for the actions:(cid:2)SF(a) ≡a = forward ∧ TRUE ∨a = backward ∧ TRUE ∨a = sonar ∧ distance < 10.Since backward and forward are not expected to return any useful sensing information, SF is vacuously true for them, whileSF(sonar) says that the sonar returns 1 precisely when the distance to the wall is less than 10. Finally, we write a successorstate axiom for our only fluent:(cid:2)[a](distance = x) ≡a = forward ∧ distance = x + 1 ∨6 The [t] construct has higher precedence than the logical connectives. So (cid:2)[a]F ((cid:19)x) ≡ γF abbreviates ∀a.(cid:2)([a]F ((cid:19)x). ≡ γF ).7 In this paper we restrict ourselves to sensing truth values. See [39] for how to handle arbitrary values.8 When we use Σ as part of a sentence we mean the conjunction of all the finitely many sentences contained in Σ .9 Here and below, we use simple arithmetic involving <, +, and −, which can easily be defined in second-order terms with the standard names actingas natural numbers. We omit the details.G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164149a = backward ∧ distance = x − 1 ∨a (cid:7)= forward ∧ a (cid:7)= backward ∧ distance = x.In other words, the distance to the wall increases or decreases by 1 depending on whether backward or forward is executed,or it remains as before for all other actions.Now we are ready to consider some specifics having to do with what is true initially by defining an action theory. LetClose stand for the formula “distance < 10.” Let φ denote the conjunction of the sentences above. We assume that φ is trueand the robot knows it. We also assume the robot is located initially 6 units away from the wall, but that the robot has noidea where it is. So, we let Σ = {φ} ∪ {distance = 6} and Σ (cid:14) = {φ}. Then we get this:Example 1. The following are logical entailments ofΣ ∧ Know∧ ∀x.¬ Know(distance (cid:7)= x):(cid:3)(cid:2)(cid:14)Σ1. Close ∧ ¬ Know(Close) ∧ [forward]¬ Know(Close)the robot is close to the wall, but does not know it, and continues not to know it after moving forward;2. [sonar](Know(Close) ∧ [forward] Know(Close))after reading the sonar, the robot knows it is close, and continues to know it after moving forward;3. [sonar][backward]¬ Know(Close)after reading the sonar and then moving backward, the robot no longer knows that it is close to the wall;4. [backward][sonar] Know(Close)after moving backward and then reading the sonar, the robot knows that it is close to the wall;5. [sonar][forward][backward] Know(Close)after reading the sonar, moving forward, and then backward, the robot knows that it is still close to the wall;6. [sonar] Know([forward]Close)after reading the sonar, the robot knows that it will remain close after moving forward;7. ¬ Know([sonar] Know(Close))the robot does not know initially that it will know that it is close after reading the sonar;8. Know([sonar](Know(Close) ∨ Know(¬Close)))the robot does know initially that after reading the sonar, it will then know whether or not it is close to the wall;9. Know([sonar][backward]¬ Know(Close))the robot knows initially that it will not know that it is close after reading the sonar and moving backwards.Proof. The proofs of these are similar. Here we will only do item 3. Let z = (cid:11)sonar · backward(cid:12), and suppose that e, w |(cid:10)Σ ∧ Know(Σ (cid:14)) ∧ ∀x.¬ Know(distance (cid:7)= x); we must show that e, w, z |(cid:10) ¬ Know(Close). Because e |(cid:10) ∀x.¬ Know(distance (cid:7)= x),(cid:14) (cid:17)z w. However,there exists ww(cid:14)[distance, (cid:11) (cid:12)] = 9. Since 9 < 10, we also have that w(cid:14), z |(cid:10) ¬Close. Therefore, e, w, z |(cid:10) ¬ Know(Close). (cid:2)(cid:14)[distance, z] = 10. So there exists w(cid:14) ∈ e such that w(cid:14) ∈ e such that w(cid:14) (cid:17)(cid:11) (cid:12) w and w(cid:14) (cid:17)z w and w4. Projection by regressionThe examples of the previous section all involve projection as a fundamental reasoning task, that is, determining whatholds after a number of actions have occurred, as inΣ ∧ Know∧ ∀x.¬ Know(distance (cid:7)= x) |(cid:10) [sonar][backward]¬ Know(Close).(cid:3)(cid:2)(cid:14)ΣWhen we are not concerned with knowledge, things are somewhat simpler as we only need a single basic action theory asinΣ |(cid:10) [forward][backward]Close.For this simpler case, Reiter [36] showed how successor state axioms allow the use of regression to solve this reasoning taskfor certain α (which he called the regressable formulas) and which, roughly, correspond to bounded objective formulas in ES.The idea is to successively replace fluents in α by the right-hand side of their successor state axioms until the resultingsentence contains no more actions, at which point one need only check whether that sentence follows from the sentencesin the initial theory. Later Scherl and Levesque [39] extended these results to handle knowledge in the situation calculus. Inthis section we will show how these ideas carry over to ES, beginning with the non-epistemic fragment of the language.4.1. Regressing objective formulasHere we consider regression to determine entailments of the form Σ |(cid:10) α, where Σ is a basic action theory and αis any bounded objective sentence. To start with we assume, from now on, that all basic action theories and queries arerectified, that is, that each quantifier has a distinct variable. This is needed for regression to work properly and later for the150G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164translation of ES to the situation calculus.10 To simplify the formal details, we will define regression only for formulas inthe following normal form NF.Definition 5. A sentence α is in NF if it is rectified and every function symbol f in α occurs only in equality expressions ofthe form ( f (n1, . . . , nk) = n), where the ni and n here are either variables or standard names.It is easy to show that every sentence can be transformed into an equivalent one in NF and the transformation is linearin the size of the original sentence. For example, if b is a rigid constant and f a functional fluent, then the normal form ofF ( f (b)) is ∃x, y.(b = x) ∧ ( f (x) = y) ∧ F ( y). Note that, for any formula in NF, if a term t appears in [t] or as an argumentto a function or predicate, then t is either a variable or a standard name. In the following we will make use of sequenceswhich consist of action variables or action standard names. We will reserve the symbol r to denote such sequences. (Wecontinue to use z to denote the special case where all elements of the sequence are standard names.)In our account, any bounded, objective sentence α in NF is considered regressable. By the transformation above anybounded, objective sentence becomes regressable by first converting it into NF and then applying regression to the result.Definition 6. We define R[α], the regression of α wrt Σ , to be R[(cid:11) (cid:12), α], where for any sequence r consisting of actionvariables or standard names, R[r, α] is defined inductively on α by:1. R[r, ∀xα] = ∀xR[r, α];2. R[r, (α ∧ β)] = (R[r, α] ∧ R[r, β]);3. R[r, ¬α] = ¬R[r, α];4. R[r, [t]α] = R[r · t, α];5. R[r, Poss(t)] = R[r, π a];t6. R[r, SF(t)] = R[r, ϕa];t7. R[r, G(t1, . . . , tk)] = G(t1, . . . , tk) for rigid predicate G;8. R[r, F (t1, . . . , tk)] for fluent predicate F is defined inductively on r by:(a) R[(cid:11) (cid:12), F (t1, . . . , tk)] = F (t1, . . . , tk);v1(b) R[r · t, F (t1, . . . , tk)] = R[r, (γF )at1t9. R[r, (t1 = t2)] = (t1 = t2) if t1 and t2 do not mention functional fluents;10. R[r, ( f (n1, . . . , nk) = n)] for functional fluent fis defined inductively by:. . . vktk];(a) R[(cid:11) (cid:12), ( f (n1, . . . , nk) = n)] = ( f (n1, . . . , nk) = n);(b) R[r · t, ( f (n1, . . . , nk) = n)] = ∃ y.(γ f )atn1 . . . vkv1nk∧ ( y = n).Note that this definition uses the right-hand sides of the precondition, successor state, and sense condition axiomsfrom Σ .It is not hard to show that R always transforms a bounded objective formula into a fluent formula.Lemma 2. Let α be a bounded objective formula and r a sequence of action variables or standard names. Then there is a unique fluentformula φ such that R[r, α] = φ.Proof. The proof is simple but tedious and we will skip the details here. Perhaps the only interesting aspect is the structureof the proof itself, which is also used in other proofs of properties of regression below. First, the lemma is proved for staticformulas only. This is achieved by an induction on the length of r and a sub-induction on the length of α, counting the+ 1,number of logical operators and where occurrences of Poss(t) and SF(t) are counted as the length of π atrespectively. Note, in particular, that the induction is well-behaved because the formulas π , ϕ, γF , and γ f are themselvesfluent formulas, that is, they are static and mention neither Poss nor SF.+ 1 and ϕatHaving proved the lemma for static α, the case of bounded formulas is established by another simple induction on thenumber of [t]-operators in α. (cid:2)Using the semantics of ES, we will now reprove Reiter’s Regression Theorem, and show that it is possible to reducereasoning with formulas that contain [t] operators to reasoning with fluent formulas in the initial state.We begin by defining for any world w and basic action theory Σ another world wΣ which is like w except that itsatisfies the Σpre, Σsense, and Σpost sentences of Σ .Definition 7. Let w be a world, z ∈ Z , and Σ a basic action theory with fluents F . Then wΣ is a world satisfying thefollowing conditions:10 See also the proof of Lemma 6 below, where this is needed to establish the induction for ∀.G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–1641511. for h /∈ F (predicate or function), wΣ [h(n1, . . . , nk), z] = w[h(n1, . . . , nk), z];2. for predicate F ∈ F , wΣ [F (n1, . . . , nk), z] is defined inductively:(a) wΣ [F (n1, . . . , nk), (cid:11) (cid:12)] = w[F (n1, . . . , nk), (cid:11) (cid:12)];(b) wΣ [F (n1, . . . , nk), z · m] = 1 iff wΣ , z |(cid:10) (γF )amn1 . . . vkv1nk ;3. for function f ∈ F , wΣ [ f (n1, . . . , nk), z] is defined inductively:(a) wΣ [ f (n1, . . . , nk), (cid:11) (cid:12)] = w[ f (n1, . . . , nk), (cid:11) (cid:12)];(b) wΣ [ f (n1, . . . , nk), z · m] = n iff wΣ , z |(cid:10) (γ f )amynn1 . . . vkv1nk ;4. wΣ [Poss(n), z] = 1 iff wΣ , z |(cid:10) π an5. wΣ [SF(n), z] = 1 iff wΣ , z |(cid:10) ϕan.;Note that this again uses the π , γ , and ϕ formulas from Σ . Then we get the following simple lemmas11:Lemma 3. For any w, wΣ exists and is uniquely defined.Proof. wΣ clearly exists. The uniqueness follows from the fact that π and ϕ are fluent formulas and that for all fluentsin F , once their initial values are fixed, then the values after any number of actions are uniquely determined by Σpost. (cid:2)Lemma 4. If w |(cid:10) Σuna ∪ Σ0 then wΣ |(cid:10) Σ .Proof. Directly from the definition of wΣ , we have that wΣ |(cid:10) ∀a(cid:2) Poss(a) ≡ π , wΣ |(cid:10) ∀a(cid:2)SF(a) ≡ ϕ, wΣ |(cid:10) ∀a∀(cid:19)x(cid:2)[a]F ((cid:19)x)≡ γF , and wΣ |(cid:10) ∀a∀(cid:19)x∀ y(cid:2)[a] f ((cid:19)x) = y ≡ γ f . (cid:2)Lemma 5. If w |(cid:10) Σ then w = wΣ .Proof. If w |(cid:10) ∀a.(cid:2) Poss(a) ≡ π , w |(cid:10) ∀a(cid:2)SF(a) ≡ ϕ, w |(cid:10) ∀a∀(cid:19)x(cid:2)[a]F ((cid:19)x) ≡ γ f , and w |(cid:10) ∀a∀(cid:19)x∀ y(cid:2)[a] f ((cid:19)x) = y ≡ γ f , then wsatisfies the definition of wΣ . (cid:2)The following property of regression is used to prove the main lemma needed for the Regression Theorem. Given an denote r with all occurrences of variable x replaced by standardsequence of action variables or standard names r, let rxname n.Lemma 6. For any bounded objective formula α and sequence of action variables or standard names r, R[r, α]xn= R[rxn, αxn].Proof. The proof is long but simple and follows the structure of the proof of Lemma 2. Here we only consider static α andthree cases: fluent predicates, assuming that the lemma holds for |r| = k − 1, Poss and ∀, assuming in the sub-induction thatthe lemma holds for formulas of length m − 1.1. Let r = r(cid:14) · t. Then R[r, F ((cid:19)t)]xn= R[r(cid:14), γFn (def. of R) = R[r]xat(cid:19)u(cid:19)t(cid:14)xn , (γFat(cid:19)u(cid:19)t)xn] (by induction) = R[r(cid:14)xn , (γFatxn(cid:19)u(cid:19)txn)] (since x notin γF ) = R[(r2. R[r, Poss(t)]xnn, F ((cid:19)t)x(cid:14) · t)x].nn (definition of R) = R[rx= R[r, π a]xtπ does not mention x) = R[rx3. R[r, ∀ y.α]xn= (∀ y.R[r, α])xnn, Poss(t)xn= ∀ y.R[r, α]x].n, (π at )xn] (by induction, as π atis of length m − 1) = R[rxn, (π atxn)] (sincen (since x (cid:7)= y) = ∀ y.R[rxn, αxn] (by induction on |α|) = R[rxn, (∀ y.α)xn]. (cid:2)Lemma 7. Let α be any bounded, objective sentence in NF and z ∈ Z .Then w |(cid:10) R[z, α] iff wΣ , z |(cid:10) α.Proof. As before, the proof is rather straightforward and uses the same induction scheme as Lemma 2. Assuming the lemmaholds for z of length k − 1, we only consider two cases, atoms with functional fluents and ∀.1. Note that, by the definition of NF, ground atoms mentioning functional fluents have the form f (n1, . . . , nk) = n, wheren and ni are standard names. Then:wΣ , z · m |(cid:10) f (n1, . . . , nk) = n iff (by definition of wΣ ),wΣ , z |(cid:10) ∃ y.(γ f )a v1w |(cid:10) R[z, ∃ y.(γ f )a v1w |(cid:10) R[z · m, f (n1, . . . , nk) = n].∧ y = n iff (by induction),∧ y = n] iff (by definition of R),mn1 . . . vknkmn1 . . . vknk2. w |(cid:10) R[z, ∀x.α] iff w |(cid:10) ∀x.R[z, α] iff w |(cid:10) R[z, α]xn for all n of the right sort iff (by Lemma 6), w |(cid:10) R[z, αxn] for all niff (by sub-induction on |α|), wΣ , z |(cid:10) αxn for all n iff wΣ , z |(cid:10) ∀x.α. (cid:2)11 As we only consider first-order sentences here, the second-order variable map u is dropped everywhere.152G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164Theorem 3 (Objective regression). Let Σ = Σuna ∪ Σ0 ∪ Σpre ∪ Σpost ∪ Σsense be a basic action theory and let α be an objective,bounded sentence. Then R[α] is a fluent sentence and satisfiesΣ |(cid:10) α iff Σuna ∪ Σ0 |(cid:10) R[α].Proof. Suppose Σuna ∪ Σ0 |(cid:10) R[α]. We prove that Σ |(cid:10) α. Let w be any world such that w |(cid:10) Σ . Then, w |(cid:10) Σuna ∪ Σ0, andso w |(cid:10) R[α]. By Lemma 7, wΣ |(cid:10) α. By Lemma 5, wΣ = w, and so w |(cid:10) α.Conversely, suppose Σ |(cid:10) α. We prove that Σ0 |(cid:10) R[α]. Let w be any world such that w |(cid:10) Σuna ∪ Σ0. From Lemma 4,wΣ |(cid:10) Σ , and so wΣ |(cid:10) α. By Lemma 7, w |(cid:10) R[α]. (cid:2)Note that the conciseness of this proof depends crucially on the fact that Lemma 7 is proved by induction over sentences,which is possible only because quantification is interpreted substitutionally.4.2. Regressing knowledgeLet us now turn to the more general case of regression for bounded sentences which may refer to the agent’s knowledge.for what is true inAs we discussed in Section 3, this means that we need to consider two basic action theories Σ and Σ (cid:14)the world and for what the agent believes, respectively.The following theorem can be thought of as a successor-state axiom for knowledge, which will allow us to extendregression to formulas containing Know. Note that, in contrast to the successor state axioms for fluents, this is a theorem ofthe logic not a stipulation as part of a basic action theory:Theorem 4. |(cid:10) (cid:2)[a] Know(α) ≡SF(a) ∧ Know(Poss(a) ∧ SF(a) ⊃ [a]α) ∨¬SF(a) ∧ Know(Poss(a) ∧ ¬SF(a) ⊃ [a]α).Proof. For both directions of the equivalence we will only consider the case where ¬SF(n) holds for an arbitrary actionname n. The other case is completely analogous.(cid:14)[SF(n), z] = 0. Thus wTo prove the only-if direction, let e, w, z |(cid:10) [n] Know(αa¬SF(n). It suffices to show that e, w, z |(cid:10) Know(Poss(n) ∧ ¬SF(n) ⊃ [n]α(cid:14)). So suppose wand we, w(cid:14)[SF(n), z] = w[SF(n), z] and, hence, wfollows.(cid:14), z · n |(cid:10) α(cid:14)Conversely, let e, w, z |(cid:10) ¬SF(n) ∧ Know(Poss(n) ∧ ¬SF(n) ⊃ [n]α(cid:14)). We need to show that e, w, z |(cid:10) [n] Know(α(cid:14)), that is,(cid:14)[SF(n), z] = w[SF(n), z] = 0 by assumption., from which e, w, z |(cid:10) [n] Know(α(cid:14)) follows. (cid:2)(cid:14) (cid:17)z·n w and w(cid:14), z |(cid:10) Poss(n) ∧ ¬SF(n). Therefore, by assumption, e, we, w, z · n |(cid:10) Know(α(cid:14)). Let wHence e, wn . Suppose e, w, z |(cid:10)(cid:14)[Poss(n), z] = 1,(cid:14) (cid:17)z·n w. Since e, w, z |(cid:10) [n] Know(α(cid:14)) by assumption,n) for action name n. We write α(cid:14)(cid:14)[Poss(n), z] = 1 and w, from which e, w(cid:14) ∈ e. Then w(cid:14), z |(cid:10) [n]α(cid:14)(cid:14), z · n |(cid:10) α(cid:14)(cid:14) (cid:17)z w, w(cid:14) ∈ e, wfor αaWe consider this a successor state axiom for knowledge in the sense that it tells us for any action a what will be knownafter doing a in terms of what was true before. Like [39], it makes the simplifying assumption that all actions are known tothe agent. Unlike [39], it is formalized without a fluent for the knowledge accessibility relation, which would have requiredsituation terms in the language. In this case, knowledge after a depends on what was known before doing a about what thefuture would be like after doing a, contingent on the action being possible and the sensing information provided by a.12For example, if after doing sonar the robot knows it is close to the wall, then before doing sonar, the robot already knew aconditional: if the sonar returns a 1 on completion, then this indicates that the robot will be close to the wall.represents the beliefs of the agent. We allow Σ and Σ (cid:14)We are now ready to extend regression to deal with knowledge. Instead of being defined relative to a basic actiontheory Σ , the regression operator R will be defined relative to a pair of basic action theories (cid:11)Σ (cid:14), Σ(cid:12) where, as above,Σ (cid:14)to differ arbitrarily and indeed to contradict each other, so thatagents may have false beliefs about what the world is like, including its dynamics.13 The idea is to regress wrt Σ outsideof Know operators and wrt Σ (cid:14)inside. To be able to distinguish between these cases, R now carries the two basic actiontheories with it as extra arguments.Rules 1–10 of the new regression operator R are exactly as before (Definition 6) except for the extra arguments Σ (cid:14)and Σ . Then we add the following:11. R[Σ (cid:14), Σ, r, Know(α)] is defined inductively on r by:(a) R[Σ (cid:14), Σ, (cid:11) (cid:12), Know(α)] = Know(R[Σ (cid:14), Σ (cid:14), (cid:11) (cid:12), α]);(b) R[Σ (cid:14), Σ, r · t, Know(α)] = R[Σ (cid:14), Σ, r, βat], where β is the right-hand side of the equivalence in Theorem 4.12 Note that by this account, after performing an impossible action, the agent believes that the action was possible. This is perhaps undesirable, but thisanomaly arises only in non-legal situations.13 This is like [19] but in contrast to Scherl and Levesque [39], who can only handle true belief. While we allow for false beliefs, we continue to use theterms knowledge and belief interchangeably.G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164153For simplicity, we write R[α] instead of R[Σ (cid:14), Σ, (cid:11) (cid:12), α]. Next we extend Lemma 4 to knowledge, where eΣ = {wΣ |w ∈ e} for a given epistemic state e and basic action theory Σ :Lemma 8. If e |(cid:10) Know(Σuna ∪ Σ0) then eΣ |(cid:10) Know(Σ).Proof. Let e |(cid:10) Know(Σuna ∪ Σ0), that is, for all w, if w ∈ e then w |(cid:10) Σuna ∪ Σ0. We need to show that for all w, if w ∈ eΣthen w |(cid:10) Σ .Let w ∈ eΣ . By definition, there is a w(cid:14) ∈ e such that w = w(cid:14)Σ . Since w(cid:14) |(cid:10) Σuna ∪ Σ0, by Lemma 4, w(cid:14)Σ|(cid:10) Σ , that is,w |(cid:10) Σ . (cid:2)We now turn to the generalization of Lemma 7 for knowledge.Lemma 9. e, w |(cid:10) R[Σ (cid:14), Σ, z, α] iff eΣ (cid:14) , wΣ , z |(cid:10) α.Proof. The proof is by induction on z with a sub-induction on α.Let z = (cid:11) (cid:12). The proof for Poss, SF, fluent atoms, and the connectives ¬, ∧, and ∀ is exactly analogous to Lemma 7.For formulas Know(α) we have:eΣ (cid:14) |(cid:10) Know(α) ifffor all w ∈ eΣ (cid:14) , eΣ (cid:14) , w |(cid:10) α iff (by definition of eΣ (cid:14) ),for all w ∈ e, eΣ (cid:14) , wΣ (cid:14) |(cid:10) α iff (by induction),for all w ∈ e, e, w, |(cid:10) R[Σ (cid:14), Σ (cid:14), (cid:11) (cid:12), α] iffe |(cid:10) Know(R[Σ (cid:14), Σ (cid:14), (cid:11) (cid:12), α]) iff (by definition of R),e |(cid:10) R[Σ (cid:14), Σ, (cid:11) (cid:12), Know(α)].This concludes the base case z = (cid:11) (cid:12).Now consider the case of z · n, which again is proved by a sub-induction on α. The proof is exactly like the sub-inductionfor the base case except for Know, for which we have the following:eΣ (cid:14) , wΣ , z · n |(cid:10) Know(α) iff (by Theorem 4),eΣ (cid:14) , wΣ , z |(cid:10) βan (where the β is from Theorem 4)iff (by the main induction),e, w |(cid:10) R[Σ (cid:14), Σ, z, βane, w |(cid:10) R[Σ (cid:14), Σ, z · n, Know(α)],] iff (by definition of R),which completes the proof. (cid:2)Finally, here is the general regression theorem:Theorem 5 (Generalized regression). Let Σ and Σ (cid:14)sentence and satisfiesΣ ∧ Know|(cid:10) α iff Σuna ∪ Σ0 ∧ Know(cid:3)(cid:2)(cid:14)Σ(cid:2)Σuna ∪ Σ(cid:14)0(cid:3)|(cid:10) R[α].be basic action theories, and α be a bounded sentence. Then R[α] is a staticProof. To prove the only-if direction, let us suppose that Σ ∧ Know(Σ (cid:14)) |(cid:10) α and that e, w |(cid:10) Σuna ∪ Σ0 ∧ Know(Σuna ∪ Σ (cid:14)0).Thus w |(cid:10) Σuna ∪ Σ0 and, by Lemma 4, wΣ |(cid:10) Σ . Also, e |(cid:10) Know(Σuna ∪ Σ (cid:14)0) and thus, by Lemma 8, eΣ (cid:14) |(cid:10) Know(Σ (cid:14)).(Note that Σuna is the same for both Σ and Σ (cid:14).) Therefore, eΣ (cid:14) , wΣ |(cid:10) Σ ∧ Know(Σ (cid:14)). By assumption, eΣ (cid:14) , wΣ |(cid:10) α and, byLemma 9, e, w |(cid:10) R[α].Conversely, suppose Σuna ∪ Σ0 ∧ Know(Σuna ∪ Σ (cid:14)0) |(cid:10) R[α] and let e, w |(cid:10) Σ ∧ Know(Σ (cid:14)). Then w |(cid:10) Σuna ∪ Σ0 and0). Then, by assumption, e, w |(cid:10) R[α]. Then eΣ (cid:14) , wΣ |(cid:10) α by Lemma 9. By Lemma 5, wΣ = w and, sincee |(cid:10) Know(Σuna ∪ Σ (cid:14)e |(cid:10) Know(Σ (cid:14)), eΣ (cid:14) = e. Therefore, e, w |(cid:10) α. (cid:2)This theorem shows that determining what is true and what is known after any (bounded) number of actions haveoccurred can always be reduced to reasoning about what is true and known in the initial state.In order to deal with our robot example, we need to go a little beyond this as we may want to make assumptions aboutwhat the robot does not know as in(cid:2)(cid:3)Σ ∧ Know(cid:14)Σ∧ ∀x.¬ Know(distance (cid:7)= x) |(cid:10) [sonar][backward]¬ Know(Close).The following corollary shows that we can deal with such cases without any problems.154G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164Corollary 1. Let γ be a static sentence which mentions neither Poss nor SF. ThenΣ ∧ Know∧ γ |(cid:10) α iff Σuna ∪ Σ0 ∧ Know(cid:3)(cid:2)(cid:14)Σ(cid:2)(cid:3)Σuna ∪ Σ(cid:14)0∧ γ |(cid:10) R[α].Proof. The proof makes use of the fact that for any static formula γ , R[γ ] = γ . Σ ∧ Know(Σ (cid:14)) ∧ γ |(cid:10) α iff Σ ∧ Know(Σ (cid:14)) |(cid:10)γ ⊃ α iff Σ ∧ Know(Σ (cid:14)) |(cid:10) R[γ ⊃ α] (by the regression theorem) iff Σ ∧ Know(Σ (cid:14)) |(cid:10) γ ⊃ R[α] (because R leaves γ as is)iff Σ ∧ Know(Σ (cid:14)) |(cid:10) γ ⊃ R[α]. (cid:2)5. Mapping to the situation calculusHow do we know that the semantics of ES is correct? In this section, we argue that it is indeed correct by showing howformulas α in ES can be translated in a direct way to formulas α∗in the situation calculus as defined by Reiter. We assumethat this language has functional and relational fluents, functions and predicates that are not fluents, the distinguishedconstant S0, function do, binary predicate (cid:20) over situations, predicates Poss and SF, and a binary predicate K for knowledge.We take Knows(α, σ ) in the situation calculus as an abbreviation for the formula ∀s(K (s, σ ) ⊃ αnowis theresult of replacing by s in α every occurrence of now that is not within the scope of a further Knows.14), where αnowssPerhaps the most desirable and simplest outcome of a translation from ES to the situation calculus would be that|(cid:10) α iff Σ |(cid:10)FOL α∗,where |(cid:10) is validity in ES, Σ is the set of foundational axioms of the situation calculus, and |(cid:10)FOL is ordinary classicallogical consequence. Unfortunately, we do not get exactly this correspondence for a variety of reasons we will discussbelow. But we do get something close:|(cid:10) α iff Σ ∪ Υ |(cid:10)FOL α∗,where Υ is a set of five axioms that we will justify separately.Somewhat surprisingly, it turns out that the foundational axioms Σ are actually completely irrelevant as far as thefragment of the situation calculus as defined by our translation is concerned. In other words, we also obtain|(cid:10) α iff Υ |(cid:10)FOL α∗.Below, we will first prove this result and then show that only small modifications are needed to obtain a proof for thecase when foundational axioms are assumed as well. To establish these results it will be necessary to work with ordinaryTarski models of sentences of the situation calculus. As we argued in the beginning, this is difficult and painstaking, and isindeed one of the main reasons to prefer ES over the situation calculus. But here there is no alternative. So while the proofof the theorems is quite laborious, we remind the reader that this can be thought of as a final reckoning for a formalismthat is unworkable semantically.5.1. The translationBefore describing Υ , we present the translation from ES into the situation calculus.In the simplest case, theidea is that a formula like distance = 6, where distance is a fluent, will be mapped to the situation calculus formuladistance(S0) = 6, where we have restored the distinguished situation term S0 for the fluent. Similarly, the formula[forward]¬(distance = 6) will be mapped to ¬(distance(do(forward, S0)) = 6), and (cid:2)(distance > 0) will be mapped to(cid:14)) > 0). For knowledge, Know(distance > 0) will be mapped to Knows(distance(now) > 0, S 0) which∀s(cid:14)) > 0). So ES formulas can be thought of as “situation-suppressed” (inis an abbreviation for ∀smapping we will define restores the situation argument to the fluents, leaving thesituation-calculus terminology) and therigids unchanged.(cid:14), S0) ⊃ distance(s∗(cid:14) ⊃ distance(s(cid:14)(S0 (cid:20) s(cid:14)(K (sMore precisely, we have the following:Definition 8. Let α be any term or formula of ES without standard names. The expression α∗for any situation term σ , α[σ ] is defined inductively by:is defined as α[S0] where,1. v[σ ], where v is a first-order variable, is v;2. g(t1, . . . , tk)[σ ], where g is a rigid function, predicate, or second-order variable, is g(t1[σ ], . . . , tk[σ ]);f (t1, . . . , tk)[σ ], where f3.4. (t1 = t2)[σ ] is (t1[σ ] = t2[σ ]);5. ([t]α)[σ ] is α[do(t[σ ], σ )];6. (α ∧ β)[σ ] is (α[σ ] ∧ β[σ ]);is a fluent function, predicate, or second-order variable is f (t1[σ ], . . . , tk[σ ], σ );14 In some versions of the situation calculus, the argument to Knows is a formula α where situations are suppressed. In that case, αnowunderstood as restoring s as the situation argument.sshould beG. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–1641557. (¬α)[σ ] is ¬α[σ ];8. (∀v.α)[σ ] is ∀v.α[σ ];9. (∀V .α)[σ ] is ∀V .α[σ ];10. ((cid:2)α)[σ ] is ∀s11. Know(α)[σ ] is Knows(α[now], σ ).(cid:14)(σ (cid:20) s(cid:14) ⊃ α[s(cid:14)]);Note that the translation of (cid:2)α introduces quantification over situations, where the introduced variable s(cid:14)is assumed tobe one that does not appear in situation term σ .5.2. The axioms and the embedding theoremThe axioms we assume in Υ are the following:1. Domain of objects is countably infinite15;2. Domain of actions is countably infinite (as above);3. Equality is the identity relation16:∀x∀ y.(x = y) ≡ ∀Q(cid:2)(cid:3)Q (x) ≡ Q ( y)(cid:14).(s (cid:20) s;4. Less-than over situations: ∀s∀s(cid:14)) ≡ ∀P (· · · ⊃ P (s, s(cid:14))),where the ellipsis stands for the universal closure of(cid:4)(cid:5)P (s1, s1)P (s2, s3) ⊃ P5. The K predicate: ∀s(cid:4)∧(cid:2)(cid:3)(cid:5)s2, do(a, s3);(cid:14), s)),where the ellipsis stands for the universal closure of(cid:14), s) ≡ ∀P (· · · ⊃ P (s(cid:14)∀s.K (s(cid:4)(cid:4)(cid:4)(cid:5)K (s1, S0) ⊃ P (s1, S0)(cid:5)P (s1, s3) ∧ P (s2, s3) ⊃ P (s1, s2)P (s1, s2) ∧ Poss(a, s1) ∧ SF(a, s1) ≡ SF(a, s2) ⊃ P∧∧(cid:2)do(a, s1), do(a, s2)(cid:3)(cid:5).Axioms (1) and (2) talk about the cardinality of the set of objects and actions respectively: they are both countable and in-finite. The countability aspect is not very controversial. In the first-order case, every satisfiable set of sentences is satisfiablein a countable domain, and we do not expect users of the situation calculus to use second-order logic to defeat this. Notethat this does not rule out having theories that talk about real numbers or other continuous phenomena; it simply rulesout using second-order logic to force the interpretations of these theories to be uncountable. We can, however, imaginecontexts where finiteness might be desirable. In such cases, we can introduce a new predicate O and instead of assertingthat there are finitely many objects, assert that there are finitely many objects in O .As for axiom (3), it is hard imagining anyone taking the negation of this one seriously. The usual first-order axioma-tization of equality is often enough, but the intent is invariably for the equality symbol to be understood as the identityrelation, which this second-order axiom ensures.Axiom (4) uses second-order logic to define the (cid:20) relation as reachability using do. It does not say anything about S 0nor about situations that cannot be reached using do. As it turns out, we do not need to stipulate anything about them.(See the conclusion for more on this.)Finally axiom (5) is a second order definition of the K predicate in terms of the value it has at S 0. This is just anotherway of capturing the successor state axiom for K introduced by Scherl and Levesque [39], and the added machinery tomake Knows be a weak-S5 operator [14]. Other knowledge operators are possible in the situation calculus, but weak-S5 andits extensions (such as strong-S5) are the most often used.The last missing piece are the axioms asserting the countability of objects and actions. Here is one way of specifyingthese for objects:∃Q .∀xQ (x) ∧ Inf (Q ) ∧ Cnt(Q ) whereCnt(Q )def= ∀Q(cid:14)(cid:14) (cid:2) Q ∧ InfQ(cid:14)Q⊃ Q (cid:2) Q(cid:2)(cid:2)(cid:3)(cid:3)(cid:14)Inf (Q )def= ∃Q(cid:14).Q(cid:14) (cid:2) Q ∧ Q (cid:2) Q(cid:14)15 See the precise logical rendering of this below.16 It is not hard to show that this second-order definition entails all the usual properties like reflexivity and substitution of equals for equals.156G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164Q (cid:2) QQ (cid:2) Q(cid:2)(cid:14) def= ∃R.∀x(cid:2)(cid:14) def= ∀xQ (x) ⊃ Q(cid:14)(cid:3)(x)(cid:2)∧ ∃x(cid:14)(cid:3)(x)(cid:14)Q (x) ∧ ¬Q(cid:3)( y) ∧ R(x, y)(cid:14)Q (x) ⊃ ∃ y Q(cid:14)(cid:14)∧ ∀x, x, y.R(x, y) ∧ R(cid:3)(cid:2)(cid:14)x, y(cid:14)⊃ x = x.(cid:14)says that Q is a proper subset of QStarting from the bottom, Q (cid:2) Q;Q (cid:2) Qwhich is nosmaller than Q itself; Cnt(Q ) says that Q is countable if every infinite proper subset is no smaller than Q ; finally, the firstline says that the set of all objects is countably infinite (here x is assumed to be of type object). To assert the same foractions we simply add another axiom of the form; Inf (Q ) says that Q is infinite if it contains a proper subset Qis no smaller than Q , that is, there is a 1–1 mapping from Q to Qsays that the set Q(cid:14)(cid:14)(cid:14)∃Q .∀a Q (a) ∧ Inf (Q ) ∧ Cnt(Q ) where a is of type action.With all the axioms in place we can now state our first embedding theorem:Theorem 6. Let α be any sentence of ES without standard names. Thenα is valid iff Υ |(cid:10)FOL α∗.The long and arduous proof of the theorem is left to Appendix A. If nothing else, it provides further evidence thatordinary Tarski models of sentences of the situation calculus are cumbersome to work with.An interesting aspect of the theorem is that it requires few assumptions about the nature of situations. For example,Υ admits models where there are situations other than those reachable from S 0 or the situations which are K -accessiblefrom S0. In contrast, Reiter’s foundational axioms Σ , which we will present in a moment, rule out such non-standardmodels. In order to show that ES can be fully embedded in Reiter’s situation calculus, which requires the foundationalaxioms, we still need to show that the above theorem continues to hold if we add Σ as additional assumptions on theright-hand side of the theorem. Note that this is not immediately obvious as extra assumptions normally lead to moreentailments.To see why this is not the case here, let us first review the axioms Σ for the epistemic situation calculus from [36]:1. do(a1, s1) = do(a2, s2) ⊃ a1 = a2 ∧ s1 = s2;2. ∀Q .∀s.[Ini(s) ⊃ P (s)] ∧ ∀a, s.[Q (s) ⊃ Q (do(a, s))] ⊃ ∀s.Q (s), where Ini(s)3. s (cid:3) do(a, s4. ¬s (cid:3) S0;5. K (s(cid:14), s) ⊃ [Ini(s) ≡ Ini(s(cid:14)) ≡ s (cid:20) s(cid:14))].;(cid:14)def= ∀a∀s(cid:14).s (cid:7)= do(a, s(cid:14));(1) is a unique names axiom for situations; the second-order axiom (2) defines the set of all situations to be thosereachable from an initial situation (Ini(s)) by a sequence of actions; (3) defines (cid:3) as reachability (by a sequence of actions)between situations; (4) says that no situation precedes S0; (5) says that an initial situation is K -accessible only from anotherinitial situation. Note that Ini(S0) is a logical consequence of Σ .The intuitive reason why we can add these axioms to Theorem 6 without invalidating it is because they assert propertiesof situations which we cannot even express in ES, and hence they are not in the image of the translation. For example,since S0 is not part of the language, we simply cannot say that nothing precedes S 0. In other words, while we certainlyhave Σ ∪ Υ |(cid:10)FOL ∀s.¬s (cid:3) S0 and Υ (cid:7)|(cid:10)FOL ∀s.¬s (cid:3) S0, this does not matter for the theorem, as there is no α ∈ ES such thatα∗is equivalent to ∀s.¬s (cid:3) S0. Hence we obtain:Theorem 7. Let α be any sentence of ES without standard names. Thenα is valid iff Σ ∪ Υ |(cid:10)FOL α∗.The theorem establishes that ES is indeed a fragment of Reiter’s situation calculus. As ES itself seems to be much moreworkable, this then is perhaps the main significance of the theorem: any property which we obtain for ES automaticallyholds for the fragment of the original situation calculus given by our translation. And this fragment covers the main uses ofthe situation calculus, in particular, Reiter’s basic action theories [36], and those dealing with knowledge [39]. We saw anexample in Section 3. In [24] we also showed that ES is expressive enough to capture the action language Golog [27].What do we give up? As we have seen, the foundational axioms themselves cannot be expressed in ES. Another sentencewhich has no straightforward counterpart in is(cid:14)∃s∃s.S0 (cid:20) s ∧ S0 (cid:20) s(cid:14) ∧(cid:14)s (cid:7)= s∧ F (s) ≡ F(cid:2)(cid:3)(cid:2)(cid:3),(cid:14)swhich says that two distinct situations are reachable that agree on the truth value of F . It’s the equality between situationsthat presents a problem here. However, as we showed in [24], sentences like these can be expressed if we add to ES anexplicit encoding of action sequences. Indeed, with this trick we were able to come up with a backward translation fromthe situation calculus to ES, which covers the entire rooted situation calculus with knowledge. Here rooted means thatG. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164157quantification over situations is restricted to formulas of the form ∀s.σ (cid:20) s ⊃ α, where σ is a situation term. Note, inparticular, that the rooted situation calculus without knowledge is equivalent to Reiter’s original version (simply take σ tobe S0). So, with a little bit of extra effort, ES has almost the same expressive power as all of the situation calculus.6. Related workWhile the situation calculus has received a lot of attention in the reasoning about action community, there are, ofcourse, a number of alternative formalisms, including close relatives like the fluent calculus [13,40] and more distant cousinsdescribed in [16,9,38].The closest approaches to ours are perhaps those concerned with reasoning about action based on dynamic logic [10].For example, De Giacomo and Lenzerini [4] and later Demolombe et al. [6], whose work extends [3], show how to importReiter’s solution to the frame problem into dynamic logic. There are also epistemic extensions of dynamic logic such as [11]and [5]. In the language of [11], it is possible to express things like [forward][sonar] Know(Close) using an almost identicalsyntax and where Know also has a possible-world semantics. While most approaches remain propositional, there are somefirst-order treatments such as [5,6], which, like ES, are inspired by the desire to capture fragments of the situation calculusin modal logic.Although they do not consider epistemic notions, the work by [1] is relevant as it reconstructs a version of the situationcalculus in Hybrid Logic [1], a variant of modal logic which was inspired by the work on tense logic by Prior [34]. Ina sense, though, this work goes only part of the way as an explicit reference to situations within the logic is retained.To us this presents a disadvantage when moving to an epistemic extension. As we said in the beginning, the problem isthat the epistemic situation calculus requires us to consider uncountably many situations, which precludes a substitutionalinterpretation of quantification.7. Only knowing and actionsIn previous work, for example [21,22], we have used the concept of only-knowing as a way of capturing the idea thata sentence is not only believed by an agent, but all that is believed by the agent. This idea has a number of applications,including reconstructing some aspects of nonmonotonic reasoning [25].One application of only-knowing for our purposes is to provide a convenient way of specifying what is not known:instead of saying that an agent believes some sentences (such as a basic action theory) and also stipulating that she doesnot believe certain other sentences (as we did in the robot example in Section 3), it will be sufficient to say that the basicaction theory is all that the agent believes. It will then follow logically that certain other sentences are not believed. So forexample, in the robot example, instead of sayingThe following are logical entailments of(cid:14)(cid:3)(cid:2)Σ ∧ KnowΣ∧ ∀x.¬ Know(distance (cid:7)= x),where we had to say explicitly that the agent did not know anything about the distance to the wall, it will be sufficient tosayThe following are logical entailments of(cid:2)(cid:3)(cid:3)(cid:2)Σ ∧ OKnow(cid:14)Σ,where OKnow(Σ (cid:14)) will be how we say in the language that Σ (cid:14)we will then obtain as a property that(cid:14)(cid:2)(cid:3)|(cid:10) OKnowΣ⊃ ∀x.¬ Know(distance (cid:7)= x),is all that is known. Once this operator is properly defined,which then allows us to carry out the example. In fact, for any two fluent sentences φ and ψ such that (cid:7)|(cid:10) (φ ⊃ ψ), we willhave that |(cid:10) (OKnow(φ) ⊃ ¬ Know(ψ)).But how should this operator be generalized from our previous work on only-knowing in the static case? In an earlierversion of this paper [23], we proposed a definition that had some interesting properties, but some drawbacks as well. Wenow believe that the definition should be the following:• e, w, z, u |(cid:10) OKnow(α) iff for every w(cid:14), w(cid:14) ∈ e wziff e wz , w(cid:14), (cid:11) (cid:12), u |(cid:10) α,wheree wz is defined as(cid:6)w(cid:14)z(cid:4)w z is defined by w z(cid:7)(cid:7) wH((cid:19)n), z(cid:14) ∈ e and w(cid:4)(cid:5)(cid:14)= w(cid:8)(cid:14) (cid:17)z w,H((cid:19)n), z · zand(cid:5).(cid:14)158G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164This semantic characterization appears to be the correct generalization of only-knowing for a dynamic language like ES. Inaddition, it appears to have some very nice connections to the concept of the progression of basic action theories [20,28,41].One complication here is that rigid predicates (predicates whose truth values are unchanging and known) appear to presentproblems for this otherwise well-behaved definition. However, we leave this exploration for future research, and do notpursue the matter here.8. ConclusionsIn this paper, we have isolated a fragment of the situation calculus with knowledge (presented using a modal syntax) andshowed it to have a relatively simple model theoretic semantics based on possible worlds. We showed that this semanticsallowed clear and direct proofs of certain properties of interest. We also showed that it coincided with the use of thesituation calculus by Reiter provided we made five assumptions: there are countably infinitely many actions and objects,the = symbol denotes identity, the (cid:20) symbol denotes reachability using do, and knowledge satisfies the properties of aquantified weak S5. Given these assumptions, practitioners are then free to use either the modal syntax we have presentedhere or the original situation calculus syntax introduced by McCarthy and can expect to reap the same semantic rewards.The subset of the situation calculus studied here might be thought to owe more to the dialect studied by Ray Reiter andcoworkers [36] than to the less constrained dialect first envisioned by John McCarthy [29]. For example, we lean heavilyon the use of basic action theories and regression, as popularized by Reiter. However, this is not quite right. A carefulreading of the embedding theorem, which shows how a fragment of the classical situation calculus can be realized in ES,demonstrates quite clearly that we get an exact correspondence without requiring all the foundational axioms proposedby Reiter. These axioms (including the second-order induction axiom) were used by Reiter to constrain the space of allsituations to be a tree rooted at S0. In our embedding, we do not rule out “non-standard models” where, for example, S 0 isthe result of performing some action. We can get away with this heresy because, without situation terms in the language,such non-standard anomalies cannot be expressed! Thus, from the point of view of the situation calculus, we can leave thespace of situations unconstrained, just as McCarthy did, without jeopardizing the advantages of the Reiter account.So in the end, despite the modal syntax which is admittedly somewhat at odds with McCarthy’s aesthetic, the situationcalculus dialect presented here is in fact closer semantically to the vision first presented by McCarthy and subsequentlyfound to be so useful by so many.Appendix A. Proof of the Embedding TheoremMMWe need some notation for talking about classical Tarski structures and truth. Suppose we are given a Tarski structureM defined by a domain D and interpretations for the constant, function and predicate symbols of the situation calculuslanguage. We assume that D = Dsit ∪ Dact ∪ Dobj, where Dsit is the domain of situations, Dact is the domain of actions,and Dobj is the domain of objects. We use the following notation: if c is a constant symbol, then cis the element of DMdenoted by c; his the relation (subset of the Cartesian product) over D of the appropriate arity denoted by H .is the function from the Cartesian product over D of the appropriate arity to D denoted by h; and HLet μ be a mapping from ordinary variables to D and from second-order variables to relations over D. For any ordinaryvariable v and element d of D, μ{x/d} is the variable map just like μ except that x is mapped to d. Similarly, for anysecond-order variable P and relation Z over D of the right arity, μ{P /Z } is the variable map just like μ except that P ismapped to Z .More notation: For any term t, (cid:21)t(cid:21)Mμ is the element of D denoted by t in the classical sense, and M, μ |(cid:10) α means thatα is true in the classical sense for structure M, when the free variables are interpreted by μ. We will omit the μ whennothing depends on the variable map.Let M be a Tarski structure satisfying the axioms in Υ over the domain D = Dsit ∪ Dact ∪ Dobj. Let ι0 = SandDstrt = {ι0} ∪ {ds ∈ Dsit | M, μ{s/ds} |(cid:10) K (s, S0)}. Dstrt should be thought of as starting situations consisting of S0 andwhatever is K -accessible from S0. These play the role of the initial situations in Reiter’s situation calculus except that theymay have predecessors because we do not require Reiter’s foundational axioms. Let e be an epistemic state, and assumethat we are given three mappings ω ∈ [Dstrt → W ], θ ∈ [N → Dact ∪ Dobj], and π ∈ [Z × Dstrt → Dsit]. Suppose further thatthe following properties are satisfied:M01. θ is 1–1, onto, and sort preserving;2. ω is onto e (that is, e ⊆ the image of ω);3. for any rigid function symbol g,= θ(cid:2)(cid:3)θ(n1), . . . , θ(nk)(cid:4)ω(ι)Mg(cid:2)g(n1, . . . , nk), (cid:11) (cid:12)(cid:5)(cid:3);4. for any fluent function symbol f ,(cid:2)(cid:3)θ(n1), . . . , θ(nk), π (z, ι)(cid:2)(cid:4)ω(ι)= θf (n1, . . . , nk), z(cid:5)(cid:3);Mf5. for any rigid predicate symbol G,(cid:10) (cid:7)(cid:4)(cid:6)(cid:9)(cid:7) ω(ι)θ(n1), . . . , θ(nk)M =G(cid:5)G(n1, . . . , nk), (cid:11) (cid:12)(cid:8);= 1G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–1641596. for any fluent predicate symbol F (including Poss and SF),(cid:6)(cid:9)M =Fθ(n1), . . . , θ(nk), π (z, ι)F (n1, . . . , nk), z(cid:10) (cid:7)(cid:4)(cid:7) ω(ι)(cid:5)(cid:8);= 1M(θ(n), π (z, ι)) = π (z · n, ι);7. do8. =Mis identity;9. (cid:3)M= {(π (z, ι), π (z · z10. K(cid:14), ι))};M = {(π (z, ι(cid:14)), π (z, ι)) | ω(ι(cid:14)) ∈ e and ω(ι(cid:14)) (cid:17)z ω(ι)}.In what follows, we will consider expressions (terms or formulas) of ES whose free first-order variables appear in the listx1, . . . , xm. We will consider substituting these variables by standard names n1, . . . , nm of the right sort. For ease of reading,for any term or formula α, we write α+tomean μ{x1/θ(n1), . . . , xm/θ(nm), s/π (z, ι)}, where the variable s, the z ∈ Z and the ι ∈ Dstrt will be determined by context.Then we get the following:nm . In the situation calculus, for a variable map μ, we write μ+to mean αx1n1 . . .xmLemma 10. Let t be a term of ES without standard names whose free variables are among the x1, . . . , xm. Let ι ∈ Dstrt, z ∈ Z , andw = ω(ι). Then, given the properties above,(cid:2)(cid:7)(cid:7)t(cid:11)(cid:11)(cid:11)t[s](cid:11)+(cid:3).μ+ = θ(cid:7)(cid:7)zwProof. By induction on t.If t is the variable xi , then (cid:21)t[s](cid:21)μ+ = (cid:21)xi(cid:21)μ+ = θ(ni) = θ(|tIf t is of the form g(t1, . . . , tk) then we have the following:+|zw ).(cid:3)(cid:2)(cid:2)g(cid:3)(cid:11)(cid:11)μ+ =(cid:3)by definition of t[s](cid:11)(cid:11)(cid:11)t[s](cid:11)(cid:11)(cid:2)(cid:11)gμ+ = (by definition of denotation)t1[s], . . . , tk[s](cid:2)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)t1[s](cid:11)tk[s](cid:11)(cid:11)Mμ+ , . . . ,(cid:2)(cid:7)(cid:2)(cid:7)(cid:7)(cid:7)(cid:3)(cid:7)t(cid:7)t(cid:7)z(cid:7)z+, . . . , θkww(cid:2)(cid:7)(cid:7)(cid:7)(cid:7)(cid:3)(cid:7)t(cid:7)z(cid:7)z(cid:7)t+, (cid:11) (cid:12)w , . . . ,kw(cid:2)(cid:7)(cid:7)(cid:7)(cid:7)(cid:5)(cid:3)(cid:7)t(cid:7)z(cid:7)z(cid:7)t+w , . . . ,wkw(cid:7)(cid:2)(cid:7)(cid:3)(cid:7)z(cid:7)g(t1, . . . , tk)+w= (by Property 3)(cid:5)(cid:3)= (by induction)+1+1+1M(cid:2)μ+(cid:3)(cid:3)θ(cid:4), zwθθθggg(cid:3)(cid:2)(cid:4).= (by the rigidity constraint)= (by definition of coreference)If t is of the form f (t1, . . . , tk) then we have the following:f(cid:2)μ+ =(cid:11)(cid:11)(cid:3)(cid:11)t[s](cid:11)by definition of t[s](cid:3)(cid:11)(cid:11)(cid:2)(cid:11)(cid:11) fμ+ = (by definition of denotation)t1[s], . . . , tk[s], s(cid:2)(cid:11)(cid:11)(cid:11)(cid:11)(cid:3)(cid:11)t1[s](cid:11)(cid:11)tk[s](cid:11)M= (by induction)μ+ , π (z, ι)μ+ , . . . ,(cid:2)(cid:7)(cid:2)(cid:7)(cid:7)(cid:7)(cid:3)(cid:3)(cid:2)(cid:3)(cid:7)t(cid:7)t(cid:7)z(cid:7)z+, π (z, ι), . . . , θθkww(cid:2)(cid:7)(cid:7)(cid:7)(cid:7)(cid:5)(cid:3)(cid:3)(cid:4)(cid:7)t(cid:7)z(cid:7)z(cid:7)t+w , . . . ,wkw(cid:7)(cid:2)(cid:7)(cid:3)(cid:7)z(cid:7) f (t1, . . . , tk)+w= (by Property 4)+1+1M(cid:2), z(cid:2)θθ.ff= (by definition of coreference)Lemma 11. Let t be a term of ES without standard names whose free variables are among the x1, . . . , xm. Let ι ∈ Dstrt, z ∈ Z , andw = ω(ι). Then, given the properties above,(cid:3)(cid:2)(cid:11)(cid:2)(cid:11)dot[s], s(cid:3)(cid:11)(cid:11)μ+ = π(cid:7)(cid:7)t+(cid:7)(cid:7)zw , ι.z ·Proof. The proof is immediate from Property 7 and Lemma 10. (cid:2)Definition 9. For a given variable map μ let uμ be any ES variable map which satisfies the following:1. for any rigid second-order variable V and any w and z, let(cid:10)θ(n1), . . . , θ(nk)w, V (n1, . . . , nk), z= 1 iffuμ(cid:5)(cid:4)(cid:9)∈ μ(V );160G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–1642. for any fluent second-order variable V and any ι and z, let(cid:4)ω(ι), V (n1, . . . , nk), z(cid:5)uμ= 1 iff(cid:9)(cid:10)θ(n1), . . . , θ(nk), π (z, ι)∈ μ(V ).Note that uμ is not necessarily completely specified for fluent variables as there may be worlds in W which are notin the image of ω. Let us call a world which is in the image of ω an ω-world. For example, all worlds in e are ω-worldsbecause ω is assumed to be onto e (Property 2). Then we have the following:Lemma 12. Let w = ω(ι) and let u1 and u2 be variable maps which agree on all values where the first argument is an ω-world. Thenfor all basic sentences α,e, w, z, u1 |(cid:10) α iffe, w, z, u2 |(cid:10) α.Proof. The proof is by induction on the structure of α. All cases except second-order variables are immediate since w andall worlds in e are ω-worlds.Let e, w, z, u1 |(cid:10) ∀V .α. Then for all u(cid:14) ∼V u1 which agrees with u, if u(cid:14) ∼V u1 then e, w, z, uon V . Also, by definition, this uis a uwith u2 and therefore uwe obtain e, w, z, u2 |(cid:10) ∀V .α. The other direction is completely symmetric. (cid:2)on all values for ω-worlds. Thus, by induction, e, w, z, u(cid:14) |(cid:10) α. Now consider any u(cid:14)(cid:14)(cid:14) ∼V u2. Then there clearlyagrees with u1 on all other values and hence agrees(cid:14)(cid:14) ∼V u2,(cid:14)(cid:14) |(cid:10) α. Since this holds for all u(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)Lemma 13. e, w, z, uμ |(cid:10) ∀V .α iff for all relations Z over D (with arity and sorts given by V ), e, w, z, uμ{V / Z } |(cid:10) α.Proof. We only consider fluent variables V . (Rigids are a simpler special case.) For the only-if direction, suppose uμ{V / Z } isagrees with uμ{V / Z } on V and, by definition of ∼V , also agrees with uμ{V / Z }given. Then there is a uon all variables other than V on all ω-worlds. Hence uμ{V / Z } agrees with uon all ω-worlds and thus, by assumption andLemma 12, e, w, z, uμ{V / Z } |(cid:10) α.(cid:14) ∼V uμ such that u(cid:14)(cid:14)(cid:14) ∼V uμ. ConsiderConversely, let u(cid:6)(cid:9)θ(n1), . . . , θ(nk), π (z, i)Z =(cid:14)(cid:14) ∼V uμ, we obtain e, w, z, uμ |(cid:10) ∀V .α. (cid:2)agrees with uμ{V / Z } on all ω-worlds and hence e, w, z, u(cid:10) (cid:7)(cid:7) u(cid:14)(cid:4)ω(i), V (n1, . . . , nk), z(cid:5)Then uany u(cid:8)= 1 for all ι and z(cid:14) |(cid:10) α by assumption and Lemma 12. Since this holds for.Now we can put all the results together and prove the main lemma:Lemma 14. Let α be a basic formula of ES with no standard names and whose free variables are among the x1, . . . , xm. Then, giventhe properties above, for any variable map μ, any ES variable map uμ satisfying Definition 9, any situation variable s, any z ∈ Z , anyι ∈ Dstrt and w = ω(ι),e, w, z, uμ |(cid:10) α+iff M, μ+ |(cid:10) α[s].Proof. The proof is by induction on the structure of α. There are 12 cases:1. For a formula of the form F (t1, . . . , tk):+ke, w, z, uμ |(cid:10) F (t1, . . . , tk)++|zw[F (|tw , . . . , |tw ), z] = 1 iff (by Property 6)|z1++w ), . . . , θ(|t|z(cid:11)θ(|tw ), π (z, ι)(cid:12) ∈ F|z(cid:10)1k(cid:11)(cid:21)t1[s](cid:21)μ+ , . . . , (cid:21)tk[s](cid:21)μ+ , π (z, ι)M, μ+ |(cid:10) F (t1[s], . . . , tk[s], s).∈ FMMiff (by definition of satisfaction)iff (by Lemma 10)iff (by definition of satisfaction)2. For a formula of the form G(t1, . . . , tk):e, w, z, uμ |(cid:10) G(t1, . . . , tk)++w , . . . , |t|zw[G(|t1+|zw[G(|tw , . . . , |t1+(cid:11)θ(|tw ), . . . , θ(|t|z1(cid:11)(cid:21)t1[s](cid:21)μ+ , . . . , (cid:21)tk[s](cid:21)μ+ (cid:12) ∈ GM, μ+ |(cid:10) G(t1[s], . . . , tk[s], s).Miff (by definition of satisfaction)+w ), z] = 1 iff (by the rigidity constraint)|zk+w ), (cid:11) (cid:12)] = 1 iff (by Property 5)|zk+w )(cid:12) ∈ G|ziff (by Lemma 10)kMiff (by definition of satisfaction)3. For a formula of the form P (t1, . . . , tk):e, w, z, uμ |(cid:10) P (t1, . . . , tk)+w , . . . , |tuμ[w, P (|t|zw ), z] = 1 iff (by definition of uμ)|z++w ), π (z, ι)(cid:12) ∈ μ+[P ] iff (by Lemma 10)|zw ), . . . , θ(|t|z(cid:11)θ(|t1kiff (by definition of satisfaction)+k+1G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164161(cid:11)(cid:21)t1[s](cid:21)μ+ , . . . , (cid:21)tk[s](cid:21)μ+ , π (z, ι)(cid:12) ∈ μ+[P ] iff (by definition of satisfaction)M, μ+ |(cid:10) P (t1[s], . . . , tk[s], s).4. For a formula of the form Q (t1, . . . , tk):+1+kiff (by definition of satisfaction)e, w, z, uμ |(cid:10) Q (t1, . . . , tk)+w , . . . , |tuμ[w, Q (|t|zw ), z] = 1 iff (by definition of uμ)|z++w ), π (z, ι)(cid:12) ∈ μ+[Q ] iff (by Lemma 10)(cid:11)θ(|t|zw ), . . . , θ(|t|z1k(cid:11)(cid:21)t1[s](cid:21)μ+ , . . . , (cid:21)tk[s](cid:21)μ+ , π (z, ι)(cid:12) ∈ μ+[Q ] iff (by definition of satisfaction)M, μ+ |(cid:10) Q (t1[s], . . . , tk[s], s).5. For a formula of the form (t1 = t2):iff (by definition of satisfaction)e, w, z, uμ |(cid:10) (t1 = t2)+++= |t|z|z|tw iff (by Property 1)w21+w ) = θ(|t|zθ(|t1(cid:21)t1[s](cid:21)μ+ = (cid:21)t2[s](cid:21)μ+ iff (by definition of satisfaction and Property 8)M, μ+ |(cid:10) (t1[s] = t2[s]).|zw ) iff (by Lemma 10)+26. For a formula of the form [t]α:w , uμ |(cid:10) α++|ziff (by definition of satisfaction)iff (by induction)(cid:14)] iff+|ze, w, z, uμ |(cid:10) ([t]α)++|ze, w, z · |tM, μ+{s(cid:14)/π (z · |tw , ι)} |(cid:10) α[sw , ι), then M, μ+{sfor every τ ∈ Dsit, if τ = π (z · |tfor every τ ∈ Dsit, if τ = (cid:21) do(t[s], s)(cid:21)μ+ , then M, μ+{s(cid:14) = do(t[s], s) ⊃ α[sfor every τ ∈ Dsit, M, μ+{sM, μ+ |(cid:10) ∀s(cid:14)(sM, μ+ |(cid:10) α[do(t[s], s)] iffM, μ+ |(cid:10) ([t]α)[s].(cid:14) = do(t[s], s) ⊃ α[s(cid:14)/τ } |(cid:10) (s(cid:14)]) iff(cid:14)/τ } |(cid:10) α[s(cid:14)/τ } |(cid:10) α[s(cid:14)]) iff (by definition of satisfaction)(cid:14)] iff (by Lemma 11)(cid:14)] iff7. For a formula of the form (α ∧ β):e, w, z, uμ |(cid:10) (α ∧ β)+M, μ+ |(cid:10) (α ∧ β)[s].iff (by induction)8. For a formula of the form ¬α:e, w, z, uμ |(cid:10) ¬α+M, μ+ |(cid:10) ¬α[s].iff (by induction)9. For a formula of the form ∀v.α:iff (by definition of satisfaction)e, w, z, uμ |(cid:10) (∀v.α)+for all names n of the right sort, e, w, z, uμ |(cid:10) α+ vfor all names n of the right sort, M, μ+{v/θ(n)} |(cid:10) α[s] iff (by Property 1)for all d ∈ D of the right sort, M, μ+{v/d} |(cid:10) α[s] iff(by definition of satisfaction) M, μ+ |(cid:10) ∀v.α[s].n iff (by induction)10. For a formula of the form ∀V .α:e, w, z, uμ |(cid:10) (∀V .α)+for all relations Z over D, e, w, z, uμ{V / Z } |(cid:10) α+for all rel. Z over D, M, μ+{V /Z } |(cid:10) α[s] iff (by definition of satisfaction)M, μ+ |(cid:10) ∀V .α[s].iff (by Lemma 13)iff (by induction)11. For a formula of the form (cid:2)α:e, w, z, uμ |(cid:10) (cid:2)α+(cid:14), uμ |(cid:10) α+(cid:14) ∈ Z , e, w, z · zfor all z(cid:14)/π (z · z(cid:14) ∈ Z , M, μ+{sfor all zfor all τ ∈ Dsit, if there exists zfor all τ ∈ Dsit, M, μ+{s(by definition of satisfaction) M, μ+ |(cid:10) ∀siff (by definition of satisfaction)iff (by induction)(cid:14), ι)} |(cid:10) α[s(cid:14)] iff(cid:14) ∈ Z such that τ = π (z · z(cid:14)/τ )} |(cid:10) (s (cid:20) s(cid:14) ⊃ α[s(cid:14) ⊃ α[s(cid:14)(s (cid:20) s(cid:14)]) iff(cid:14)]).(cid:14), ι), then M, μ+{s(cid:14)/τ } |(cid:10) α[s(cid:14)] iff (by Property 9)12. For a formula of the form Know(α):(cid:14) ∈ e, if wiff (by definition of satisfaction)e, w, z, uμ |(cid:10) Know(α)+(cid:14) (cid:17)z w, then e, wfor all wfor all ω(ι(cid:14)) ∈ e, if ω(ι(cid:14)) (cid:17)z w, then e, ω(ι(cid:14)), z, uμ |(cid:10) α+for all ω(ι(cid:14)) ∈ e, if ω(ι(cid:14)) (cid:17)z w, then M, μ+{sfor all τ ∈ Dsit, if there exists ι(cid:14) ∈ Dstrt such that τ = π (z, ι(cid:14)) where ω(ι(cid:14)) ∈ e and ω(ι(cid:14)) (cid:17)z w,iff (by induction)(cid:14)] iff(cid:14)/π (z, ι(cid:14))} |(cid:10) α[s(cid:14), z, uμ |(cid:10) α+iff (by Property 2)then M, μ+{sfor all τ ∈ Dsit, M, μ+{s(cid:14)/τ } |(cid:10) α[s(cid:14)] iff (by Property 10)(cid:14), s) ⊃ α[s(cid:14)/τ } |(cid:10) (K (s(cid:14)]) iff (by definition of satisfaction)162G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164M, μ+ |(cid:10) ∀s(cid:14)(K (sM, μ+ |(cid:10) Knows(α[now], s) iffM, μ+ |(cid:10) Know(α)[s].(cid:14), s) ⊃ α[s(cid:14)]) iffThis completes the proof. (cid:2)With this lemma in place, we can now prove the correctness of the embedding of ES into the situation calculus:Theorem 6. Let α be any basic sentence of ES without standard names. Thenα is valid iff Υ |(cid:10)FOL α∗,Proof. First assume that α is not valid. Then there is an e, w 0 such that e, w 0 (cid:7)|(cid:10) α. Define a Tarski structure as follows:• The domain of M is D = Dobj ∪ Dact ∪ Dsit, where Dobj (resp. Dact) is the set of standard names of objects (resp.actions), and Dsit = Z times W ;• The fixed vocabulary of M is defined by:M– =MM– S0– do– (cid:3)M= {((z, w), (z · z– Kis the identity relation over D,= ((cid:11) (cid:12), w 0),(n, (z, w)) = (z · n, w),(cid:14), w))},M = {((z, w), (z, w 0)) | w ∈ e and w (cid:17)z w 0};(cid:7)(cid:7) w 0• for every fluent predicate symbol F (including Poss and SF),= 1• for every rigid predicate symbol G,(cid:5)G(n1, . . . , nk), (cid:11) (cid:12)(cid:11)n1, . . . , nk(cid:12)F (n1, . . . , nk), z(cid:11)n1, . . . , nk, (z, w)(cid:12)• for every rigid function symbol g,(cid:7)(cid:7) wM =M == 1(cid:8);G(cid:6)(cid:6)F(cid:4)(cid:5)(cid:4)(cid:8);gM(n1, . . . , nk) = w 0• for every fluent function symbol f ,(cid:4)= w(cid:2)(cid:3)n1, . . . , nk, (z, w)Mf(cid:5)g(n1, . . . , nk), z.(cid:4)(cid:5)g(n1, . . . , nk), (cid:11) (cid:12);These definitions ensure that M satisfies Υ . Next, define the mappings θ , π , and ω by letting θ(n) = n, and for anyinitial ι = ((cid:11) (cid:12), w), letting π (z, ι) = (z, w), and ω(ι) = w. This ensures that the properties needed for Lemma 14 are satisfied,and so M (cid:7)|(cid:10) α∗. Consequently, Υ (cid:7)|(cid:10)FOL α∗.Conversely, assume that Υ (cid:7)|(cid:10)FOL α∗. Thedomain D must be Dsit ∪ Dact ∪ Dobj, with Dstrt ⊆ Dsit as the set of starting situations, and with ι0 = S∈ Dstrt. SinceM |(cid:10) Υ , both Dobj and Dact are countably infinite, say Dobj = {δ1, δ2, . . .}, and Dact = {λ1, λ2, . . .}. We define the map-pings θ , π and ω by the following:. Then there is a Tarski structure M that satisfies Υ but such that M (cid:7)|(cid:10) α∗M0• θ maps the i-th standard name for objects to δi , and the i-th standard name for actions to λi ;• for any z ∈ Z and ι ∈ Dstrt, we define π (z, ι) by:π ((cid:11) (cid:12), ι) = ι,π (z · n, ι) = doM(cid:2)(cid:3)θ(n), π (z, ι);• for any ι ∈ Dstrt, we let ω(ι) be the world w defined by the following:(cid:4)(cid:5)(cid:4)(cid:4)(cid:4)wwwwG(n1, . . . , nk), z(cid:5)F (n1, . . . , nk), z(cid:5)g(n1, . . . , nk), zf (n1, . . . , nk), z(cid:5)= 1 iff= 1 iff(cid:2)−1= θ= θ−1g(cid:2)f∈ G(cid:9)(cid:10)M,θ(n1), . . . , θ(nk)(cid:10)(cid:9)θ(n1), . . . , θ(nk), π (z, ι)(cid:2)θ(n1), . . . , θ(nk)(cid:2)θ(n1), . . . , θ(nk), π (z, ι)(cid:3)(cid:3),MM(cid:3)(cid:3).∈ FM,For any ι ∈ Dstrt, ω(ι) obviously satisfies the rigidity constraint. Finally, we let• e = {ω(ι) | (ι, ι0) ∈ K• w 0 = ω(ι0).M};G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164163These definitions ensure that all of the properties needed for Lemma 14 are satisfied, and so e, w 0 (cid:7)|(cid:10) α. Consequently,α is not valid. (cid:2)Theorem 7. Let α be any sentence of ES without standard names. Thenα is valid iff Σ ∪ Υ |(cid:10)FOL α∗.Proof. The proof is almost the same as the previous one because we can re-use the same model constructions.Let us first assume that α is not valid. Then there is an e, w 0 such that e, w 0 (cid:7)|(cid:10) α. Now define a Tarski structure Mexactly as in the first part of the proof of Theorem 6. It is easy to see that Σ (as well as Υ ) is satisfied by M. In particular,the construction ensures that situations have unique names and that neither S 0 nor any situation K -accessible from S0has a predecessor, that is, these are truly initial situations. Furthermore, by construction, the situations reachable from theinitial situations are the only situations of the model so that the induction axiom for situations (Axiom 2) is also satisfied.The rest of the argument is exactly as in Theorem 6, from which Σ ∪ Υ (cid:7)|(cid:10)FOL α∗Conversely, assume that Σ ∪ Υ (cid:7)|(cid:10)FOL α∗. Then there is a Tarski structure M that satisfies Σ ∪ Υ but such that M (cid:7)|(cid:10) α∗.We define the mappings θ , π and ω as well as w 0 and e exactly as in Theorem 6. As before, all the properties of Lemma 14are satisfied and, hence, e, w 0 (cid:7)|(cid:10) α, which proves that α is not valid. (cid:2)follows.References[1] P. Blackburn, J. Kamps, M. Marx, Situation calculus as hybrid logic: first steps, in: P. Brazdil, A. Jorge (Eds.), Progress in Artificial Intelligence, in: LectureNotes in Artificial Intelligence, vol. 2258, Springer-Verlag, 2001, pp. 253–260.[2] W. Burgard, A.B. Cremers, D. Fox, D. Hähnel, G. Lakemeyer, D. Schulz, W. Steiner, S. Thrun, Experiences with an interactive museum tour-guide robot,Artificial Intelligence 114 (1–2) (2000).[3] M.A. Castilho, O. Gasquet, A. Herzig, Formalizing action and change in modal logic I. The frame problem, Journal of Logic and Computation 9 (5) (1999)701–735.[4] G. De Giacomo, M. Lenzerini, PDL-based framework for reasoning about actions, in: Proc. of AI*IA, in: Lecture Notes in Artificial Intelligence, vol. 992,1995, pp. 103–114.[5] R. Demolombe, Belief change: from situation calculus to modal logic, in: IJCAI Workshop on Nonmonotonic Reasoning, Action, and Change (NRAC’03),Acapulco, Mexico, 2003.[6] R. Demolombe, A. Herzig, I.J. Varzinczak, Regression in modal logic, Journal of Applied Non-Classical Logics 13 (2) (2003) 165–185.[7] R. Fagin, J. Halpern, Y. Moses, M. Vardi, Reasoning about Knowledge, MIT Press, Cambridge, 1995.[8] A. Finzi, F. Pirri, R. Reiter, Open world planning in the situation calculus, in: Proc. of the 7th Conference on Artificial Intelligence (AAAI-00), AAAI Press,2000, pp. 754–760.[9] Michael Gelfond, Vladimir Lifschitz, Representing action and change by logic programs, Journal of Logic Programming 17 (1993) 301–321.[10] D. Harel, Dynamic logic, in: D. Gabbay, F. Guenther (Eds.), Handbook of Philosophical Logic, vol. 2, D. Reidel Publishing Company, 1984, pp. 497–604.[11] A. Herzig, J. Lang, D. Longin, T. Polacsek, A logic for planning under partial observability, in: Proc. of the Seventeenth National Conference on ArtificialIntelligence (AAAI-00), AAAI Press, 2000, pp. 768–773.[12] J. Hintikka, Knowledge and Belief, Cornell University Press, Ithaca, 1962.[13] S. Hölldobler, J. Schneeberger, A new deductive approach to planning, New Generation Computing 8 (1990) 225–244.[14] G. Hughes, M. Cresswell, An Introduction to Modal Logic, Methuen and Co., London, 1968.[15] D. Kaplan, Quantifying-in, in: L. Linsky (Ed.), Reference and Modality, Oxford University Press, Oxford, 1971, pp. 112–144.[16] R. Kowalski, M. Sergot, A logic based calculus of events, New Generation Computing 4 (1986) 67–95.[17] S.A. Kripke, Semantical considerations on modal logic, Acta Philosophica Fennica 16 (1963) 83–94.[18] S.A. Kripke, Is there a problem with substitutional quantification?, in: G. Evans, J. McDowell (Eds.), Truth and Meaning, Clarendon Press, Oxford, 1976,pp. 325–419.[19] G. Lakemeyer, H.J. Levesque, AOL: a logic of acting, sensing, knowing, and only knowing, in: Proc. of the Sixth International Conference on Principlesof Knowledge Representation and Reasoning, Morgan Kaufmann, San Francisco, 1998, pp. 316–327.[20] G. Lakemeyer, H.J. Levesque, A semantical account of progression in the presence of defaults, in: Proc. of the 21st International Joint Conference onArtificial Intelligence (IJCAI-09), Pasadena, USA, 2009, pp. 842–847.[21] H.J. Levesque, All I Know: A Study in Autoepistemic Logic, Artificial Intelligence, vol. 42, North Holland, 1990, pp. 263–309.[22] H.J. Levesque, G. Lakemeyer, The Logic of Knowledge Bases, MIT Press, 2001.[23] G. Lakemeyer, H.J. Levesque, Situations si, situation terms no, in: Proc. of the Ninth Conference on Principles of Knowledge Representation and Rea-soning (KR2004), 2004.[24] G. Lakemeyer, H.J. Levesque, A useful fragment of the situation calculus, in: Proc. of the 19th International Joint Conference on Artificial Intelligence(IJCAI-05), 2005, pp. 490–496.[25] G. Lakemeyer, H.J. Levesque, Towards an axiom system for default logic, in: Proc. of the 21st National Conference on Artificial Intelligence (AAAI-06),2006.[26] H.J. Levesque, F. Pirri, R. Reiter, Foundations for the situation calculus, Linköping Electronic Articles in Computer and Information Science 3 (18) (1998).[27] H.J. Levesque, R. Reiter, Y. Lespérance, F. Lin, R.B. Scherl, Golog: a logic programming language for dynamic domains, Journal of Logic Programming 31(1997) 59–84.[28] F. Lin, R. Reiter, How to progress a database, Artificial Intelligence 92 (1997) 131–167.[29] J. McCarthy, Situations, actions and causal laws, Technical report, Stanford University, 1963. Also in: M. Minsky (Ed.), Semantic Information Processing,MIT Press, Cambridge, MA, 1968, pp. 410–417.[30] J. McCarthy, P.J. Hayes, Some philosophical problems from the standpoint of artificial intelligence, in: B. Meltzer, D. Mitchie, M. Swann (Eds.), MachineIntelligence, vol. 4, Edinburgh University Press, 1969, pp. 463–502.[31] S. McIlraith, T.C. Son, Adapting Golog for composition of semantic web services, in: Proc. of the Eighth International Conference on Principles ofKnowledge Representation and Reasoning, Morgan Kaufmann, San Francisco, 2002, pp. 482–493.[32] R.C. Moore, A formal theory of knowledge and action, in: J.R. Hobbs, R.C. Moore (Eds.), Formal Theories of the Commonsense World, Ablex, Norwood,NJ, 1985, pp. 319–358.164G. Lakemeyer, H.J. Levesque / Artificial Intelligence 175 (2011) 142–164[33] V.R. Pratt, Semantical considerations on Floyd–Hoare logic, in: Proc. 17th Annual IEEE Symposium on Foundations of Computer Science, IEEE ComputerSociety Press, 1976, pp. 109–121.[34] A. Prior, Past, Present and Future, Oxford University Press, 1967.[35] R. Reiter, The frame problem in the situation calculus: A simple solution (sometimes) and a completeness result for goal regression, in: V. Lifschitz(Ed.), Artificial Intelligence and Mathematical Theory of Computation, Academic Press, 1991, pp. 359–380.[36] R. Reiter, Knowledge in Action: Logical Foundations for Describing and Implementing Dynamical Systems, MIT Press, 2001.[37] R. Reiter, On knowledge-based programming with sensing in the situation calculus, ACM Transactions on Computational Logic (2001) 433–457.[38] Erik Sandewall, Features and Fluents. The Representation of Knowledge about Dynamical Systems, Oxford University Press, 1994.[39] R.B. Scherl, H.J. Levesque, Knowledge, action, and the frame problem, Artificial Intelligence 144 (1–2) (2003) 1–39.[40] Michael Thielscher, From situation calculus to fluent calculus: state update axioms as a solution to the inferential frame problem, Artificial Intelli-gence 111 (1–2) (1999) 277–299.[41] S. Vassos, H.J. Levesque, On the progression of situation calculus basic action theories: resolving a 10-year-old conjecture, in: Proc. of the 20th AAAIConference on Artificial Intelligence (AAAI-08), 2008.