Artificial Intelligence 85 (1996) 363-397 Artificial Intelligence The sensitivity of belief networks to imprecise probabilities: an experimental investigation Malcolm Pradhan a,b,*, Max Henrion a, Gregory Provan a, Brendan Del Favero a,c, Kurt Huang a*b a Institute for Decision Syslems Research, 4984 El Catnino Real, Suite 110, L.os Altos, CA 94022. USA h Section on Medical Informarics. Stanford University, Stanford, CA 94305, USA c Engineering-Economic Systems, Stanford University, Stanford, CA 94305, USA Received January 1995; revised October 1995 for reason- the numerical In this Abstract Bayesian belief networks are being increasingly used as a knowledge representation the practicality of obtaining for large-scale applications. need to create belief networks the probabilities affects diagnostic performance. We conducted for medical diagnosis of ( 1) varying (2) adding ing under uncertainty. Some researchers have questioned probabilities with sufficient precision work, we investigate how precise in the probabilities set of real-world belief networks the effects on diagnostic performance weights into numerical probabilities, (3) simplifying severe-to outside large amounts of noise significant that outside diseases degraded performance modestly. Overall, highly simple binary belief networks are a practical lead to only modest reductions from quatemary binary domains-absent the network. We found that even extreme differences and present, and (4) using effect of the simplification from quatemary domains imprecise to be by measuring how imprecision a series of experiments on a the mappings in liver and bile disease. We examined frequency to the numerical probabilities. from qualitative test cases mild, moderate, and that contain diseases in the probability mappings and in diagnostic performance. We found no to binary representation. We also found that even significantly, and that that these findings indicate suggest random noise for diseases and findings-absent, representations may often be adequate. These findings of robustness input probabilities may not impair diagnostic performance representation without requiring undue precision. Keywords: Probabilistic reasoning; Bayesian networks * Corresponding author. E-mail: pradhan@camis.stanford.edu 0004.3702/96/$15,00 PIISOOO4-3702(96)00002-l Copyright @ 1996 Published by Elsevier Science B.V. All rights reserved. 364 M. Prudhm r/ trl. /Artificiul Intelli~erwe 85 (1996) 363-397 1. The tradeoff between accuracy and cost or model is, by definition, from a human expert, Each knowledge representation is derived the representation When of the expert’s perception of reality. The question accurate-it whether is s@ficietzt!\. for which one that drives our research. is completely for the purposes the representation accurate a simplification it is a simplification of reality. even is not cannot be-but whether the model is the it is designed. This question a representation in choosing in representation The choice of a representation the accuracy with which the model represents is a balancing act. On the one hand, a richer representa- the real-world system. in inferences-for tion should improve Greater accuracy to be correct, example, that would be most effective. On the other hand, a and richer and for resources storage, and will require more effort to construct, verify, and maintain. The success of knowledge-based to find an effective systems depends critically on the knowledge engineer’s ability in a medical application, recommendations representation will require more computational tradeoff between accuracy and cost. that would be more likely lead to improved accuracy should diagnoses for inference treatment Experienced knowledge engineers generally develop useful intuitions about how to there is little theoretical or experimental complexity of alternative them. Of course. the exploration knowledge make such choices: however, available to guide computational topic of AI research. However, once we have chosen a particular such as rules, a nonmonotonic research available to guide or richness of the model Theoretical relationships important and performance, its performance the knowledge representation to affect is likely engineer between analysis role. of the generality, representations research currently and has been a major limitations, type of representation- is little in deciding how the complexity for a given application. of the experimental work must play an can be valuable here. But, due to the analytic complexity logic scheme, or Bayesian belief networks-there 1. I. Experiments on be&f networks efficient in interest techniques, representation In recent years, inference algorithms, there has been substantial growth in Bayesian belief net- 1321. There has been work on the develop- works (BNs) as a knowledge and ment of effective knowledge engineering increasing numbers of real-world applications of BNs [ 14,171. The primary goal of the work described here is to investigate how the precision of representation of BNs affects the quality of diagnosis based on the network. We view this research as a contribution an empirical and theoretical basis for guidelines towards the eventual goal of developing for knowledge engineers the level and complexity of representation that provides generated, to compare knowledge range of different characteristics-such internal nodes, or frequency of undirected cycles-we tradeoff between accuracy and cost. is based on a series of real-world BNs, rather than on the randomly research it is easy to generate BNs with a wide as ratio of arcs to nodes, ratio of source nodes to wanted to focus on BNs that have abstract knowledge bases (KBs) used in much of the experimental representations. Although to help them choose the most appropriate Our investigation M. Pradhan et al./Art@cial Intelligence 85 (1996) 363-397 365 the characteristics to be relevant The problem domain disorders (liver and bile diseases). of real application to other real application domains that we use in this study than artificially is medical diagnosis likely generated networks. for hepatobiliary domains. We believe such BNs are more from an early quasi-probabilistic [ 301 that uses a representation (CPCS) reference as frequency weights, specifying BNs case simulation (QMR) links, such as the relationship the experimental patient [25] and quick medical bases, causal We derived computer-based rived the Internist-l In these knowledge finding are quantified give rise to a finding or other variable, on a five-point qualitative our group developed a belief network independence and marginal probabilistic [ 231, even though some information in QMR-BN. reformulation, QMR-BN, demonstrated representation, with specific from the Internist-l independence to convert a method the chance of findings given diseases, noisy OR influences of diseases on findings, of QMR with the independence [40]. Empirical of diseases comparison comparable diagnostic performance (e.g. linkages between diseases) was not employed KB, named de- [24] expert systems. between disease and that one disease will scale. In previous work, to /QMR representation assumptions-conditional herent BN, mapping probabilities Our first task in the current work was to convert the CPCS knowledge base into a co- frequency weights into link probabilities, which are the conditional probabilities, but not caused by one of the diseases or other variable of each finding given each disease. We also had to assess additional to quantify leak that each finding, or other variable, will be present in the knowledge base, and prior the chance probabilities Bayesian to quantify representations the prevalence rate of each disease or predisposing in general, and BNs in particular, have been criticized by to from large numbers of numerical probabilities are estimated directly these probabilities they require factor. by domain experts, or some combination the fact that a conventional BN representation has a certain AI researchers because quantify uncertain data, or assessed as subjective probabilities of the two, there voracious appetite is no denying for such numbers. relationships. Whether The first question we examined is how precise such numbers need to be. The liter- that subjective are liable to consistent biases and imprecision. of subjective probabilities makes clear ature on the expert assessment probabilities achieve adequate diagnostic precision performance the reliability If it turns out that BNs, to require numerical probabilities with greater than experts can provide, BNs will be of little practical value. But, if a BN’s to probable errors, we can allay concerns about assessments. performance, turns out to be insensitive of subjective probability two experiments to examine We performed In each experiment, we assessed bilities. effect on diagnostic diagnosis averaged over a large number of diagnostic performance, measured First, we compared the standard, empirically into probabilities weights treats frequency weights as order-of-magnitude that strength. ignores differences between the numbers to two alternative mappings, the effect of the manipulations assigned as the probability the sensitivity of BNs to the expert proba- in terms of their to the correct test cases, for three different BNs. [ 151 from frequency that and the uniform mapping, links as having equal all probabilities, treating by the curvilinear mapping derived mapping Second, we added random noise to the probabilities ping. In this case, we added noise separately and the prior probabilities. By examining three types of probability, we were able to differentiate effect on diagnostic performance. to the link probabilities, derived from the standard map- leak probabilities, the effect of noise separately on each of these them in terms of their among In our third experiment, we examined is. the number of values each variable can the performance of networks severe} with simplified networks containing such as diseases and findings-that We compared mild. moderate, prcwnt}. Enriching the representation extra effort because more probabilities must be quantified. the computational performance effort required to discover whether In our fourth experiment. we examined from binary containing quaternary the effect of the domain size of variables, take. {absent, domains {absent, binary domains to quaternary domains entails much increases in diagnostic It also substantially the change for diagnosis. We examined the additional work is likely to be worthwhile. the effect of including outside diseases that the probability in the network-perhaps in the network being explicitly, for a finding the test cases. that are not explicit is diseases major benefit of BNs is that they represent uncertainty of a model. The leak probability due to incompleteness represents explicitly Because true explanation way, the BN supports our experiments, we extracted test cases that included diseases We were able scope of the diagnostic network. including uncertainty (or other variable) that the finding will be present for a reason that is not modeled a false positive or a disease or fault not modeled. that the In this For of the representation. from a large BN. We used some in the large network, but not always in the subnetworks. to test performance when there are diseases present leak events explicitly. we can infer the probability about scope and limitations is a cause not represented three smaller subnetworks that are not in the the BN represents in the model. of a finding reasoning explicitly in tested. A 1.2. Overvirrr knowledge to variations representations In Section 3, we describe how we converted The paper is organized as follows. In Section 2. we review previous work on the sensi- in the numbers and repre- the qualitative CPCS knowledge the noisy OR into the noisy MAX cause vari- In Section 4, we present our the selection of networks, generation of test cases, and 5, 6, and for each of the three and tivity of probabilistic sentation. base into a quantitative BN, and how we generalized relationship which we used to mode1 the influence of multiple ables on each effect variable using quaternary experimental the measures of diagnostic 7, we present experiments, tne domain size, respectively. We summarize our conclusions performance. designs, the probability mappings, results, and discussions in the probabilities, In the following the experimental three sections, random noise in Section 9. independent approach, including domains. changing 2. Previous research on belief network sensitivity Considering the degree of controversy about the relative merits of schemes for rea- soning under uncertainty. there have been relatively few previous studies comparing M. Pradhan et al./Artijicial Intelligence 85 (1996) 363-397 367 of alternative performance BNs with rule-based abilities, simplifications. We will conclude apparent variety of findings. schemes, effects on BNs of structural schemes. We will group these studies analysis of the sensitivity independence assumptions, of BNs this section by a discussion of into comparisons to numerical prob- and effects of other for the of the reasons 2.1. Comparison of probabilistic to rule-based and symbolic representations in the diagnosis of gastrointestinal the diagnostic accuracy of rule-based of rule-based or symbolic knowledge little or no significant difference pain [4], and acute abdominal Many comparisons bilistic BNs have found studies comparing found no statistical difference abdominal Chard et al. showed that an ad hoc qualitative model the diagnosis of chest pain, with uniform weights produced formulation version called QMR-BN [ 231. original in the diagnosis of gynaecological [ 401, demonstrated found pain due to gynaecological representations with proba- in performance. For example, schemes with independent Bayes [ 111, acute disease [42,43]. scheme can perform as well as a Bayesian [ 291, in rule ROC curves. As noted earlier, a re- into a belief network to the comparable diagnostic performance [ 31. O’Neil and Glowinski origin disorders of a large heuristic knowledge base, Internist-l/QMR that a Bayesian approach and a linear decision indistinguishable Heckerman and colleagues, with the Pathfinder project [ 141, found that a Bayesian Wise and Henrion better overall, according for lymph node pathology. However, system both had comparable diagnostic ability belief network model and rule-based human expert physician network performed had more parameters and was better tuned to the domain expert’s subjective assessments. of the performance factors, possi- among but that in other cases the differences were substantial, par- Indeed, some schemes could produce results of six different bilistic schemes were insignificant, ticularly with weak or conflicting that were qualitatively to a that the belief it to the human experts, perhaps because logic, and BN schemes. They found an experimental uncertainty, that, in some cases, the differences these circumstances. incorrect under [47] conducted for representing they found comparison evidence. including certainty schemes 2.2. Sensitivity of uncertain reasoning to numerical inputs Ng and Abramson [27] to the prior and conditional showed noise added medical pathology. A recent study for troubleshooting belief network probabilities, order-of-magnitude substantial robustness probabilities of diagnostic to accuracy in the domain of for a BN model [ 181 found in a simple that diagnostic performance an automobile was barely affected by substituting based on the kappa calculus [ 131. 2.3. Sensitivity of probabilistic reasoning to independence assumptions There have been several empirical independence of findings [7]. One might expect BN models conditional de Dombal studies of the effect of assumptions in the independence Bayes model about the introduced by to provide more accurate diagnoses 36X M. Prudhun er 01. /ArtiJk:itrl Intelligence 85 (1996) 363-397 independence Bayes models, assuming all findings are conditionally the disease state, because than on [ 12,281. The experimental abdominal pain, found a 4% increase for pairwise accounting no statistically have even found independence Bayes interactions significant tends among [ 121 showed empirically assumptions Fryback dependence dependencies dence assumptions analysis of QMR-BN due to inappropriate with many findings appropriate modeling of dependence assumption (typically can outperform the BN models can capture conditional evidence here is mixed. Seroussi in diagnostic accuracy using a Lancaster model. Todd and Stamper [ 391, in the domain of acute (from 63.7% to 67.7%) by found and some the two approaches difference between [42.43], independent dependencies [ 6,9]. to be better that a large model with many findings. He found to overweight positive evidence due that smaller models with appropriate larger models with inappropriate [ 23 1, we also found unrealistically of conditional independence inappropriate to ignoring in- the indepen- In our assumptions. large posterior probabilities in examples that of findings, 20 to 50 findings per case). These results suggest can significantly affect in large networks. 2.4. SinzpliJcation of be&f networks Several researchers have explored schemes to simplify BNs, and examined their effects [20] convert BNs to their equivalent to 0 the k smallest probabilities tables in computing that deletes technique [ 221 explored a complementary the clique tree. as measured by the Kullback-Leibler taking advantage of the smaller probability the network by setting Jensen and Andersen trees ’ and then simplify thereby on reasoning performance. clique in each clique, marginal probabilities. Kjaerulff from the least edges important that useful simplifications metric. Both studies found tional error. Sarkar with tree structure, [ 381 proposed methods in order to reduce computational for optimal approximation could be obtained with little addi- of a general BN complexity. simplification methods [ 36,371 developed methods Other researchers have used domain-dependent to study trade- the richness and size of BN models. Provan and temporal BN models for the medical to simplify improved as that diagnostic accuracy of acute abdominal pain. They found for computa- [2] and influence diagrams to the specifics of a problem, also supporting offs between diagnostic accuracy against colleagues management a function of network complexity, tional effort. a simplified Breese dynamically from a database tradeoffs between complexity could be optimal. Breese and Horvitz but that, with an appropriate penalty to construct belief networks and in response and accuracy. representation [ 1 ] describe approaches 2.5. Understanding results on sensitivities The findings of low sensitivities of diagnostic performance to errors in numerical inputs are consistent with the widely observed classification under uncertainty. Experimental robustness of simple for in extensive studies of com- linear models psychologists, ’ A clique is n fully connected graph, containing a set of directly dependent nodes. Any BN can be converted into a tree of cliques. M. Pradhan et al. /Artificial lnielligence 85 (1996) 363-397 369 plex, configural approximate human experts or features, is based on the inherent tion tasks can be formulated log-odds prior). judgments by human experts, have found that simple linear models with and even uniform weights often do as well, and sometimes even better than in domains where there are several noisy cues [ 51. These results apply so that even optimal performance is limited. The underlying robustness of linear models [ 451. Note that diagnostic Bayesian reasoning with conditional as a weighted linear sum of evidence weights (log-likelihoods plus explanation for a wide range of classifica- independence Von Winterfeld and Edwards [44] have shown that the optimal decisions and hence in a decision analysis are still less sensitive expected utility than are the posterior probabilities. They show that this robustness concavity of expected decision. Pierce loss as a function of probability [ 341 and Fishburn [ lo] have shown related results. to errors in input probabilities is due to the necessary in the region around an optimal the other hand, von Winterfeld can create arbitrarily structure and Edwards large losses [44] also showed in utility. We should about missing findings, missing diseases, or missing the qualitative structure of a model and so could substantially that errors in therefore be relationships, which affect On model concerned would change results. an accurate diagnosis. On the other hand, [47] suggest engine makes that if there is little or no evidence. little difference, because is strong, scheme will perform well. In either case, there will errors. The largest differences or small numerical if there The findings of Wise and Henrion evidence, and inference the quality of the representation no scheme can compute any reasonable consistent to representation be little sensitivity largest schemes, between sensitivities and evidence. Accordingly, moderate or conflicting systematically we vary the quantity of evidence situation. to errors in inputs, occur when described there is below, in the experiments to ensure coverage of the intermediate 3. Knowledge base conversion to belief network The BN that we used for our experimental analysis supports medical diagnosis for liver and bile (hepatobiliary) base, experimental the CPCS system, developed by Parker and Miller knowledge base extension of the Internist-l diseases. We derived the network [30] [ 251. from a rich knowledge in the mid-1980s as an to Internist-l the CPCS knowledge base, its relationship In this section, we describe and QMR, and how we mapped for identifying the qualitative methods tion 3.2 we describe how we mapped strength of relationships assessed prior probabilities derivable generalized to represent effect variable. in its original noisy OR, or noisy MAX, which the probabilistic variables, from and CPCS, their domains, and influences. the frequency weights, which express it into a BN representation, CPCS-BN. We describe In Sec- the probabilities. We also to conditional and leak probabilities, which were additional quantities not the that we use effects of multiple predecessor or causal variables on each form. In Section 3.3 we define and explain is the prototypical from CPCS in Internist-l influence 370 hf. Prudhur~ et d. /Art$cial lntelllgerm 85 (1996) 363-397 3.1. Internist-l, QMR, und CPCS The CPCS KB was developed as an experimental and computer aided instruction. The developers support patient simulation tasks required a KE3 with a much richer representation is restricted knowledge engineering tion based on their experience with the CPCS system. to the hepatobiliary medical domain because task too great to convert all of Internist-l extension of the Internist-l KB to felt that these than that of Internist-l. CPCS the the developers regarded to a richer representa- The CPCS KE3 has a multilevel and more recently QMR, contain only diseases and findings-a Internist-l, representation. and findings as well as predisposing prevalence diseases and findings. For example, consider a disease acute gastritis which blood suggestive of blood count. Internist-l the CPCS KB includes anemia (an IPS) between two-level that includes diseases that influence disease that mediate between involves loss: pale skin and low red blood cell In contrast, rates, and intermediate pathophysiological this disease and the two findings. the disease and the two findings. has direct links between loss and two tindings representation states (IPSs) to diseases (PFDs) factors Whereas Internist-l findings, CPCS uses quaternary variables, states. CPCS contains disease, disease represents frequency directed for diseases and for certain such as diseases and IPSs. Some findings are also represented with multiple and QMR use binary domains domains {absent, mild, moderate, severe} {absent, present} links between the variables of types predisposing to to IPS and findings. and IPS to findings. CPCS, like its predecessors, between the strength of the relationship (an integer between 0 and 5) that represents a graded degree of likelihood. cause and effect variables by a 3.2. Translation of the yuulitutive CPCS itlto (I belief network The original CPCS system wab developed as Lisp frames. To construct represented to Common Lisp, and then parsed and IPSs as four levels of severity IPS node were represented disease or IPS node were represented findings, CPCS contained these links into arcs in the BN. causal the BN we converted in FranzLisp. Diseases the frames in the CPCS-BN. Predisposing and IPSs were the original CPCS KB to create nodes. We represented diseases factors of a disease or and findings and symptoms of a to the for that node. In addition links between disease and IPS frames; we converted as that node’s predecessors, as the successors of CPCS In the conversion for consistency the domain knowledge of medical doctors associated with this project. Because interpretations to the BN representation, we checked to make numerous minor corrections using the original CPCS knowledge base was not designed with probabilistic in mind, we had to make node values consistent, were contained within a node. For example accumulation) was automatically scrotum}. Since edema may occur at more broken the node edema created as one node containing into two nodes: edema-legs and edema-scrotum. than one site simultaneously that only mutually to remove artifactual nodes, exclusive values to fluid legs, the node was (swelling the states {none, to confirm due and The resultant network has 448 nodes and over 900 arcs. Fig. 1 is a snapshot of part of in the the complexity of the CPCS-BN. Because that demonstrates inference the network M. Pradhan et aLlArtificial Intelligence 85 (1996) 363-397 371 Fig. 1. Approximately one quarter of the full 450-node CPCS-BN. is extremely complete CPCS-BN experiments, we used subsets of the full network comprising 42 nodes (2 diseases), nodes detail (4 diseases). These subsets are described (3 diseases) in Section 4. and we ran approximately time consuming, and 245 nodes 300,000 146 in more To complete probabilities, to specify the conversion leak probabilities, to CPCS-BN, we assessed three sets of probabilities: prior and link probabilities. We assessed over 560 probabilities the network fully, as described in the following subsections. 3.2.1. Assessment of the prior probabilities The prior probabilities of the predisposing factors in CPCS-BN were assessed by of disease nodes the predisposing the posterior probabilities in these experiments, we removed accuracy the prior probabilities physicians. However, because we are using as a measure of diagnostic factors and assessed play an important different disease rates (prior probabilities). travenous drug use will have a much higher rate of viral hepatitis compared population. The removal of predisposing CPCS network reduces that the prior probabilities to uncontrolled not subject factors often role in medical diagnosis by effectively defining subpopulations with For example, a population who has high in- to the general version of the this ensures for each network, and to probability mapping. of the diseases would be consistent variations due to noise or frequency it’s diagnostic power and medical factors from the experimental of the diseases. Predisposing realism, however 311 M. Pradhun et ~1. /Artificial Intellipnce X5 (I 996) 363-397 We derived disease prior prohabilities from the National Center for Health Statistics data, as had been done for the original QMR-BN. 3.2.2. Assessment of the leak probabilities by observing Experts assessed the leak probabilities of each node that are the node is the that a person could present with anemia not caused by acute gastritis or that required a leak, and deriving a probability each of the predecessors introduced anemia with predecessors acute gastritis and pregnancy, probability pregnancy. that the node could be true given (leak probabilities includes in Section 3.3.2). For example, in the network was absent then the leak for anemia the predecessors if a network represented formally The assessed factors (parents) must be modified. For example, as a new parent of the node anemia, condition the network. is a relatively leak probability of a node of that node; if a parent is added or removed, if we include is specific to the particular set of causal then the leak probability the condition peptic ulcer in our model the new in the leak probability will decrease because common cause of anemia and it is now explicitly modeled 3.2.3. Assessment of the link probabilities The original CPCS system contained to IPSs, and from causal diseases and IPSs to findings. The strengths of these links were indicated by an integer from 0 to 5 called a frequency weight. The frequency weight of a link was very roughly equivalent that the successor node would be present given the predecessor node is present. to the conditional from diseases probability links in [40]. We also tested the sensitivity of the performance of the CPCS-BN In constructing the CPCS-BN. WC converted the real interval into the integers by mapping used particular probability mapping used, as described represent only one-to-one The link probabilities these frequency weights (0. I 1, using the same mapping to probabilities as was to the in Section 5. relationships the nodes, e.g. between the effect of more than one disease on a between a disease and a finding. To combine finding, we use the devices of the noisy OR and the noisy MAX, which are described in the next section. 3.3. Modeling causal injuences The link probabilities described in the previous section model one-to-one relation- the effect of multiple diseases on a for probabilistic influence probability matrix. For binary variables, ships between diseases and findings. To combine single fied representations the full conditional quires a single parameter, from one variable tioners using belief networks have found represent by experts finding, we use the leaky, noisy OR, and the noisy MAX. These are simpli- than the leak noisy OR re- link and practi- to as judged the situation a large majority of actual applications in many domains. They represent that noisy OR relationships between binary variables to finding. Researchers the strength of each far fewer parameters e.g. from disease a link probability for diagnostic are sufficient to represent that require relationships to another, M. Pradhan et al. /Art@cial Intelligence 85 (1996) 363-397 313 Fig. 2. A noisy OR network they are causally that can cause a given the tendency of each other disease there are multiple diseases or faults and where test-outcome, in which servable disease does not affect finding. There are some situations causes, which can be represented minority. make that the noisy OR and noisy MAX seem the most appropriate probabilistic pretation. finding or ob- the presence of one their common and gating can occur among relations, but these are a small In the CPCS KB the presence of IPS nodes between diseases and findings inter- by other probabilistic in which synergies independent; to produce In the following discussion, we denote variables using upper-case letters and instantiations lower-case that a variable can take be x[ 01, x[ 1 I,. . .,x[n absent state. Any state, x[j] , where j > 0 means X is present. of variables using letters (e.g., x). Let the values - 11. The value x[O] denotes (e.g., X) (states) the the 3.3.1. Noisy OR The noisy OR is a model of probabilistic variable and a set of binary variables originally proposed by Pearl causal that represent [ 3 I] and independently influence between a binary effect its causes. This representation was by Peng and Reggia [ 33 1. Consider a variable X that has m predecessors Dt , . . . , D,. The noisy OR can be the the probability of each cause Di being [ 161. If these conditions hold, used when ( 1) each Di has a probability Link( Di, X) of being sufficient effect in the absence of all other causes, and (2) sufficient we can model as a belief network, as in Fig. 2. of the presence of other causes the noisy OR relationship is independent to produce in Fig. 2, let n(X) the noisy OR network variables { D1, . . . , Dm}. Let V, C Z7( X) be the subset of predecessors be the set of explicitly modeled For of predecessor X that are present and K C Z7( X) be the subset of predecessors of X that are absent. We assume of n(X) in which Di is present and all other D,i (j # i) are absent, or: is denoted 7~( X), and we define r(X) = Ui as a specific instantiation (thus, V, U & = I7( X) ) . An instantiation that all predecessors are instantiated of Z7( X) r(X) = Ui E {Di = di[ l] and Dj = dj[O] for all j # i}. Let Link( Dj, X) , on the arc from Di to X, represent the link probability, the probability that X is present given that Di is present and all other predecessors are absent: 374 M. Pradhun et (II. /Artijicul Inrellipmy 85 (1996) 363-397 Fig. 3. Explicit representation of the leak probability as u cause of x Link(D,,X) = P(X =.r[ I I / I-,). (1) Since the Dj E fl( X) are assumed to be causally independent, X is absent only when all Di fail to cause X to be present: P(X=x[O] / mcx,,= P(X=r]OJ /r,) n i:n,E\; (2) (3) = II i.fl,E\‘\ ( 1 ~ Lirzk( D,,X)). from which it follows that the complement is given by: P(x=.r[ I] / II(X)) = I ~- n (I -Link(D,.X)). , Il,E\‘, 3.3.2. Leaky-no& OR Like any model, a BN is an incomplete representation e~wtrs to represent predecessors that could cause are represented predecessor modeled (non-leak) has a corresponding that finding explicitly the missing variables that influence leak event that represents to be present, other than those predecessor variables in the model. Fig. 3 shows a finding X, with all of reality. We can use leak a finding. Each variable with events the possible that two explicit the set of explicitly variables, D1 and D?. and a leak event, Lx. Recall predecessors of X is 77(X) = (01, D2, , D,,,}. The probability that the leak event is the leak probability. The leak prob- ability for X, Leak(X), explicitly modeled predecessors is equal is present to the probability 77(X) are absent: that X is present when all its VI Leak(X)=P(Lx)=P(X=x[I] ID,=d,[O], i=l,2 ,..., rn). (4) Thus, we can model the leak event is that the link probability like any other explicit cause Di of X. The only that if Lx is from 7,~ to X is exactly 1. Note then X is present. Note also that for the leaky-noisy OR, the link probability the probability that X is present given that Di is present and all difference present, Link( D,, X) represents other predecessors including the leak rzode are absent. M. Pradhan et al./Art$cial Intelligence 85 (1996) 363-397 315 Link0 ebb Drn Link(D,,X) Fig. 4. A node X with predecessors DI, , D,,, and shadows SI, , S,. By incorporating a leak event into Eq. (3), we arrive at a formula for the leaky- noisy OR: P(X=x[l] 1 n(X)) = 1 - (1 -Leak(X)) n (1 -Link(oi,X)). (5) i:D,EVx 3.3.3. Noisy MAX The binary noisy OR is insufficient quaternary variables. for the CPCS-BN application, because we need In this section, we outline how the binary version to an nary version, termed of the noisy OR was first proposed by Henrion described here and in [35] the noisy MAX. [ 411 and in the formulation described [ 81. The generalization here and [ 161. The derivation follow Henrion’s work. Two related of the noisy OR to model is used In domains the in [ 81 independently. Also, the the context of learning models for OR gates, and or non-functional. in which case two values, that can be functional than take on more is insufficient. The noisy MAX generalization The generalization implementation from is different are described (or other such devices) and generalizations by Srinivas circuits such as medicine, binary generalization identical is virtually in [ 81 is described within formulation its application variables may of Srinivas to inference Consider a generalization is a the in CPCS-BN have states that are ordered by severity: absent, mild, moderate, of the noisy OR mode1 in which each variable domain the states are ordered. For example, state space in which (or nary) to the one described here, but was derived in Bayesian networks is not apparent. to accommodate can be generalized finite discrete variables and severe. In a noisy OR, each predecessor Di may be seen as having a shadow Si (Fig. 4). to the link probability. is present with probability its shadow equal If D; is present, Variable X is simply may be computed directly the standard, noiseless OR of the shadows. The probability of X from this fact. Similarly, for a noisy MAX, each predecessor 376 M. Pradhan et ~1. /ArtiJlciczl lntellipnce 85 (I 996) 363-397 3 2 1 0 Sl 0 1 2 3 s2 Fig. 5. A node X with predecessors 01, D? and shadow variables SI , J‘z having ordered states (0, 1.2.3). The shaded area represents to calculate PC X = XI 2 I 1 L)I , LIZ). the probabilities required has a shadow. The probability probabilities known. Hence, the value of X would be simply the name noisy MAX. and the probabilities distribution over each shadow S, is determined by its link of its predecessor Di. If the shadow predecessors were the maximum of the values of the shadows Si. We define S( X-1 to be the set of instantiations of the shadow variables (St = .Sl, . s,, = s,, ) such that max,,t, ,,,, ( 5, ) = k. We can use the noisy MAX to compute the conditional probability P(X=.u[kJ / D I...., D,,,)= c P(u’ D ,,.... D,,,) ,rESt A / =c I-I ,rES( A, 1=I ,. ,111 P(Sj = CTj / Di). (6) For example, consider ordered states (0. 1,2,3} to compute P( X = x[ 21 1 Dl, 02 ) we notice variable must be 2. In this case combinations This is shown graphically the case of two predecessors D1 and D2, both of which have shadow variables Sl and &. If we want state of any shadow all into account is 2. takes state taken by either variable of Sr and S2 in which in Fig. 5. the noisy MAX calculation that the maximum and corresponding the maximum 4. Experimental approach In this section. we describe the experimental experiments, which we will present the three networks we used in the experiments, how we analyzed how we generated the results, and we provide some sample results. in the following approach we used in each of the three three sections. Here, we describe the test cases, and 4.1. Subnetwork selectiorl Because CPCS-BN ence with available is large and multiply connected, infer- inference algorithms using the entire network. If we wish to compute it is impractical to perform M. Pradhan et al./Arr@cial Intelligence 85 (1996) 363-397 377 Fig. 6. Subnetwork containing the ancestors and descendants of the disease ascending-cholangitis. Table 1 Subnetworks MAX nodes Network BN2 BN3 BN4 Full CPCS used for experiments, including the number of probabilities specified after expansion of the noisy # nodes Max # parents # probabilities #I parameters 42 146 245 365 2 4 I 12 492 2420 77,988 90,813,182 412 1480 3180 6658 tool Netview We extracted of a small set of diseases, we can perform only the posterior probabilities only the subnetwork of the CPCS network the BN graphical the full CPCS-BN using to display selected subsets of nodes from a network editing ancestors and descendants in a large network. For example, that is relevant. We selected subnetworks inference using from the user and in Fig. 6, Netview displays only the immediate [ 351. Netview allows for simplicity of visualization of the selected node-ascending-cholangitis, from the full CPCS-BN respectively, named two, three, and four diseases. We devel- three subnetworks BN2, BN3, and BN4, containing, oped versions of BN2, BN3, and BN4 in both quaternary summarizes the number of nodes of each type in the three subnetworks with the full CPCS network. The table also shows the maximum number of parents a single node needed fully specify parameters for to and the number of noisy MAX in each network, the network the total number of conditional those conditional probabilities. (in the quaternary domain), and binary domains. Table 1 for the experiments, to fully specify in comparison in this case. probabilities required Fig. 7 shows BN2, and Fig. 8 shows BN3. 4.2. Test cases We needed test cases far more on the diagnostic performance the effects of the experimental manipulations than the small number of cases available from real patient data. Accordingly, we generated sample test cases directly from the BNs specified by the network themselves, findings according to the probabilities to estimate generating reliably 37x M. Prudhun PI (11. /ArriJwicll htelll~ence 85 (1996) 363-397 Fig. 7. The 42-node. two-disease subset of the full 450-node CPCS-EN. used as BN2 in our experiments M. Pradhan et al./Artifcial Intelligence 85 (I 996) 363-397 379 Fig. 8. The 146-node, three-disease subset of the full 450-node CPCS-BN, used as BN3 in our experiments. 380 hf. Prudhr rl ~1. /Artifcul lnreiligence 85 (1996) 363-397 logic sampling [ 161. We used the full CPCS network and the standard probability using mapping for generating the test cases. Since we wanted to investigate how the amount of evidence the experimental manipulations, we generated cases with varying numbers of findings. include values for all findings. To create harder The test cases, as initially generated, five cases cases with fewer findings, the order from each initial case, by revealing in which the findings as follows: and also for greater medical the findings realism, we created in five phases, approximating in a real medical consultation. We grouped into these five phases corresponding findings would be revealed stages in medical diagnosis, affects sensitivity to successive to Phase 1: History, including symptoms and findings volunteered by the patient-e.g., abdominal pain in the epigastrium. Phuse 2: Examination, including objective evidence observed by the physician-e.g., abdominal tenderness. Please 3: Inexpensive, Ptzusr 4: Expensive days. laboratory tests, whose results are returned in a few hours. tests, whose results are returned in tests, non-invasive laboratory Pime 5: Expenive, invasive through biopsies-e.g., the test cases with the following usually obtained We generated ( 1 ) First, we generated a set of disease combinations hepatocellular laboratory live steps: tests, including pathology inflammation findings, which are and/or necrosis. using levels, for each network the number of possible there are 4k possible combinations. ‘*absent” or “severe”. We generated combinations we restricted ourselves in the quater- the standard probability mapping. For a network with To to sever- to cases for dis- for the (us- (3,0), nary representation k diseases, each at four severity reduce ity levels representative eases chosen at random two-disease network, we generated cases with the following disease settings ing the ordinal representation 0, 1.2,3 (3.3). We used the same combination with a randomly In addition, we generated the subnetworks. As an example, (O,O), (0,3), to generate another set of cases coverage of the space. from outside selected disease from outside for severity of settings of these states the subnetwork set to level 3. combinations levels): (2 ) For each disease combination we computed tions over the findings at four severity the probability case. distributions the conditional levels. We used random sampling probability distribu- from to comprise each to generate sets of finding levels (, 3 ) For the cases to be used for binary networks, we reduced from four to two, classifying of each disease and finding beyond absent as present. the number of levels all levels of severity (4) We categorized the findings listed above. From each full four partial cases: Phase 1, including only Phase 1 findings; the live phases into case, we generated Phase 2, which adds Phase 2 findings to Phase 4. Each Phase 5 case is the full case including phases. to the Phase 1 findings; and so on, up from all five findings There are, in general, 5n phased cases generated number of basic and phased cases for each network. from II basic cases. Table 2 shows the M. Pradhan et al./Art@cial Intelligence 85 (1996) 363-397 381 Table 2 Number of cases used for experiments Network Basic cases Number of phases Total cases (by phase) BN2 BN3 BN4 Total 160 160 320 640 s s 5 5 800 800 1600 3200 I 0.9 - 0.8- 0.7- 0.6-r 0.5 - 0.4 - 0.3- 0.2 2 Prob(true dx) Nehvork 1 2 3 Phase 4 Fig. 9. The average probability of the true diagnosis as a function of the phase (amount of evidence) network. for each 4.3. Measures of diagnostic performance We quantify diagnostic performance as the probability assigned by each network true diagnosis, each probabilities the probability assigned averaged over to each disease when present-that the set of test cases. We analyze separately is, the true positive assigned to each disease when absent-that is, the false positive to the rate-and rate. Initially, we aggregate the results by phase so that we can see how performance to the true (true positive and true negative) as a function of the phase for each of the three assigned varies by phase. For example, Fig. 9 plots the average probability diagnosis networks. As expected, diagnostic performance is, the additional probability especially 0.22. But, with the entire set of evidence available becomes excellent, For statistical of the true diagnosis. Performance for BN3, where averaging 0.95 over the three networks. analysis of the results we compared the average posterior probability findings available improves consistently with phase-that in the later phases lead to a higher average posterior starts out relatively poorly for the true diagnosis for Phase 1, is in Phase 5, diagnostic performance networks the standard mapping to that of the “gold standard” network-the to perform better than the performance of the modified standard mapping. We expected test (a) the modified networks because 3x2 M. Prudhun et ul. /Artijiciul Intelligence 85 (I 996) 363-397 cases were sampled for the basis of the standard mappings [ 151. from the standard networks, and (b) there is experimental evidence 5. Experiment on sensitivity to mappings In our first experiment, we examined the effect of alternative mappings in Internist-l to those from the to the (similar in CPCS and QMR) those knowledge bases. used in the BN representation. denoted by integers from 0 to 5, expressing frequency weights used The frequency weights are qualitative link probabilities judgments, the degree of connection between each cause and effect (e.g. disease and IPS, or IPS and finding) provided by the clinical diagnosticians who created There are two reasons to vary the mappings. First. as we try to develop probabilistic of CPCS and QMR, we want to know which mapping gives best results. in the mapping. the network in the numerical reformulations Second, we want to understand how sensitive is to changes More generally, we wish to understand how sensitive BNs are to changes the standard mapping, probabilities. principal uniform mappings, standard mappings would degrade standard mapping, probabilistic assessed by a the curvilinear mapping and as we shall describe. Our hypothesis was that use of these non- to the the quality of diagnostic performance the best that the standard mapping would provide [ 15 ). to two extreme mappings, this experiment we compared of the frequency weights. since we believed author of QMR interpretation relative In 5.1. Design of mapping experiment We compared three different mappings from frequency weights to link probabilities, as follows: The standard mapping was obtained frequency weights and subjective probabilities from an experiment to assess the correspondence [ 151. For a set of disease-finding between pairs, Dr. R. Miller, a principal tional probability found a simple and consistent frequency weights ble 3, is the average probability This mapping was used terms [ 401. condi- of each finding given the presence of each disease. The experimenters author of QMR, assessed directly the numerical for the corresponding relationship between the assessed probabilities pairs. The standard mapping, as shown in this experiment and the in Ta- for each frequency weight. obtained in previous experiments reformulating QMR in probabilistic The curvilinear mapping provides an order-of-magnitude interpretation It interprets 4 and 5 are orders of magnitude 0 to 3 as the orders of magnitude 0.0001 for the complement probability-that frequencies quency weights. 0.1. Frequencies is, 0.9 and 0.99. The uniform mapping to the identical probability differences of evidence ignores all distinctions among frequencies, mapping of 0.5. We use it to demonstrate the effect of ignoring the strength of links entirely. With the uniform mapping among in the network depends only on the leak values. of the fre- to them all the the strength M. Pradhan et al. /Artificial Intelligence 85 (1996) 363-397 383 used to represent frequency weight from the original CPCS knowledge base as probabilities in 0 0.0025 0.0001 0.5 1 0.025 0.001 0.5 Frequency 2 0.2 0.01 0.5 3 0.5 0.1 0.5 4 0.8 0.9 0.5 5 0.985 0.99 0.5 Table 3 Mappings CPCS-BN Mapping standard curvilinear uniform Network B BN2 I 1- to probability on average diagnostic performance BN3 BN4 from frequency Meall Prob(tme dx) Mm% Fig. 10. The effect of alternative mappings for all phases for each network. 5.2. Results of mapping experiment Fig. 10 compares the three mappings averaged the standard mapping performs best, on the curvilinear mapping performs next best, and the uniform mapping performs for networks BN2 and BN3. For BN4 performance in terms of the diagnostic performance over all cases for each network. As expected, average; the worst. This pattern with standard performance with uniform mapping and curvilinear mapping indistinguishable. is significantly worse than the standard mapping. In all cases, is observed are almost the the three mappings with only We also compared sensitivity was different show that the standard mapping can perform worse than the uniform mapping, as in BN2 and BN3. to see if the in Fig. 11. These cases the best, but that the curvilinear mapping for cases with less evidence, as shown the Phase 1 findings, is consistently 5.3. Discussion of mapping experiment The finding standard mapping that the curvilinear and uniform mappings did worse on average is as expected. According to the experimental than the calibration by Hecker- Probttrue dx) Fig. I I. The cffcct of alternative mappings for Phase I findings only. BNZ BN3 Network BN4 from frequency to probability on average diagnostic performance the best probabilistic interpretation man and Miller, the standard mapping should provide of the frequency weights. is most in however, interesting, interpretation, of the decrement of the probabilities and uniform mappings. The curvilinear mapping, with its puts relatively much more weight on the larger fre- the importance I, 2 and 3. It reduces twenty. The uni- for is the modest magnitude the two very substantial modifications What performance obtained by provided by the curvilinear order-of-magnitude quency weights, 4 and 5, than the smaller weights, of the findings with link strengths 0, 1. and 2 by a factor of about form mapping, on the other hand. I to 5. Effectively, frequencies of the leak probability, which mapping the leaks and priors remain quantitative. Despite performance These results to changes or errors whether the link is of less importance. (probability indicate very substantial in the link probabilities. They suggest there exists a link between a disease and finding. The quantitative the average these substantial of true diagnosis 1 is reduced by only 0.05 from (0.87 to 0.82). robustness of diagnostic performance with respect is strength of it makes the strength of evidence of a finding a function is not affected by mapping. the uniform to a purely qualitative for links-although, changes, that what matters most ignores any differences the representation in link strengths In this sense, structure reduces totally 6. Experiment on sensitivity to noise In our second experiment, we examined how random noise hilities affects diagnostic performance. Numerical probabilities he estimated subject from a sample in the numerical proha- for belief networks may from empirical data or assessed by experts. In either case, the numbers are the data may be obtained of the application domain, or the expert to various sources of inaccuracy and bias. For example, that is not truly representative M. Pradhan et al./Art$cial Intelligence 85 (I 996) 363-397 385 may have non-representative process of expert assessment of probabilities have been the subject of extensive study [ 21,261. experience. Limited sample sizes lead to random error. The to a variety of inaccuracies which is subject The question we wish to address here is how far these sources of imprecision to matter. Accordingly, we add random noise these sources of imprecision. probability mappings second experiment, we compared types of probability types of probability. to see whether on only are likely to simulate In our first experiment, we examined effects of alternative to the original probabilities the links, but not the leak or prior probabilities. In the the effect of noise separately on each of the three for the three there are different levels of sensitivity A better understanding of sensitivity assessment-whether help guide the builder of belief networks into probability estimated empirically what levels of precision the input probabilities. A better understanding the knowledge and priors could help guide these three classes of probability. to errors or noise can in deciding how much effort it is worth putting are assessed directly by experts, or in numerical probability probabilities from collected patient case data. It could also help us understand in diagnosis we can expect given the inevitable of the relative sensitivity engineer in allocating in imprecision leaks, to links, effort in assessing 6.1. Design of noise experimenl to add noise to a probability the most obvious way is to add a random to the probability. This approach has two problems. First, a large additive than 1 or less than 0, and so needs to be to produce a probability Perhaps noise directly error is likely greater truncated. Second, an error of plus or minus 0.1 seems a lot more serious in a probability of 0.1, ranging 0.6. Link probabilities that are present or absent of 0.5, ranging effects in diagnosis from 0 to 0.2, than it does in a probability near 0 or 1 can have enormous from 0.4 to for findings (respectively). A more appealing approach that avoids these problems rather than the probability. This approach can be viewed as a version of Fechner’s psychophysics or brightness probability bound. The log-odds just-noticeable differences constant when measured on a logarithmic to have a symmetric this behavior. in which similar are approximately transformation More specifically, we transformed provides exactly each probability p into log-odds form, added normal noise with a standard deviation of (7 and transform back into probabilities. We define the log-odds is to add noise to the log-odds law of such as weight scale. Since effect near each has two bounds, 0 and 1, we wish transformation in quantities as: LO(P) = lW,(JP/( 1 - P) I. We add log-odds noise to the probability as follows: p’=Lo-‘[Lo(p) +e] where e =Normal(O,a). (8) We start with binary networks using and then add noise, generated with CT = 1 .O, u = 2.0, and c = 3.0. We generated 10 noisy networks independently the standard mapping with no noise for each link probability (U = 0), in the network, for independently 386 M. Prudhun et cd./Arfijiciul Intelligence 85 (1996) 363-397 0 1 2 3 Standard Deviation of Noise Added Fig. Il. Effects of noise BNZ network. in the link. leak, and prior probabilities on average diagnostic performance for the each CT. Similarly, we created noisy networks adding noise only to the leak probabilities, for each network. and only to the prior probabilities The total number of networks used in this experiment were 273. comprised of 3 levels of noise x 3 probability x 10 samples x 3 networks, plus leak, and priors) the original 3 standard networks without noise. For each of these networks, we ran the entire set of cases, requiring a total of 291,200 runs. As in the experiments in Section 5. we compared performance using the average probability to the true diagnoses. types (link, assigned 6.2. Results of noise experimerlt Fig. 12 plots the average performance-the probability assigned to the true diagnosis- Fig. 13 and Fig. 14 plot similar measurements the four levels of noise on the link, leak, and prior for the two-disease network against probabilities. and four-disease networks, BN3 and BN4. The results are similar for all three networks. We for each type see that, as expected, to noise of probability-link, on links than to noise on priors or leaks. The effect of noise on the leaks and priors is indistinguishable increasing noise consistently leak, and prior. Performance degrades performance is relatively more sensitive for networks BN3 and BN4. for the three-disease 6.3. Discussiorl of noise experiment of noise in the numerical probabilities the amount of degradation IS shows The introduction small when one considers expected. However, values of the the degree of noise. Fig. probability with noise as a function of the probability without noise for (T = 1.0 and CT = 3.0. Even for u = 1 .O, the noise generates a wide range of probabilities. For g = 3.0, the entire unit square. These graphs the 80% probability interval seems to cover nearly does degrade performance, and 90-percentile is surprisingly lo-percentile the as M. Pradhan ef al./Art$cial Intelligence 85 (1996) 363-397 387 Mean Prob(true dx) Type of Noise Added -Q- Link + + Leak Prior 0.6 0.5 0.4 0.3 0.2 0.1 0.0 1 0 I 1 I 2 I 3 Standard Deviation of Noise Added Fig. 13. Effects of noise BN3 network. in the link, leak, and prior probabilities on average diagnostic performance for the Mean Prob(tme dx) Type of Noise Added 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 I 0 I 1 I 2 I 3 Standard Deviation of Noise Added Fig. 14. Effects of noise BN4 network. in the link, leak, and prior probabilities on average diagnostic performance for the show that noise of u = 3.0 and greater can transform other probability. produce only modest degradations In spite of this tendency, in performance. any probability into almost any it appears these vast errors in the probabilities 6.4. Effects of noise on true positives and negatives Hitherto, our analysis has combined i.e., the probability of the disease the probabilities for cases in which assigned the disease to true positives is present-and (TP) - prob- 388 M. Pmdhun et rd. /Artijiciul intelligence 85 (I 996) 363-397 Probabtity with Noise Probability with Noise “‘5 0 015 Probability without Noise Probability without Noise (a (b) Fig. 15. Effect of adding noise: ( a) u = I, (b) tr = 3. True Negatives True Positives Meall Prob(true dx) Type of Noise Added 0 Link + t Leak Prior n 1 2 3 Standard Deviation of Noise Added Fig. 16. Effect of noise probabilities, in the link, averaged over BN2. BN3, and BN4. leak. and prior probabilities on the true positive and true negative (TN)-i.e.. the probability to true negatives assigned abilities in which the disease results by examining the average probability function of the noise similar for each of the three networks. Accordingly, averaged over the three networks. for cases is absent. We can obtain that help explain our the effects of noise on these two measures separately. Fig. 16 plots for TP and TN, as a leak, and prior probabilities. These results were for simplicity, Fig. 16 shows results to the true diagnosis level in the link, of no disease interesting separately assigned insights The first point to note is that, without noise, the average performance (TN) at 0.97 is substantially the system is more likely better than for true positives to miss a disease that is present for true negatives (TP) at 0.73. In other words, a than to falsely diagnose M. Pradhan et al. /Artijicial Intelligence 85 (1996) 363-397 389 that is not present. This tendency of diseases to the prior probabilities disease the prevalence according most of the test cases to contain one or more diseases diagnostic performance cases would have no diseases. in the test cases on interesting to underdiagnose is much larger should be expected because than would be expected generated on to the priors, more to provide more information on the diseases. Note that we deliberately cases, even though according significantly degrades performance let us look at the effect of noise Now probabilities effect on TN (a = 0.05). Conversely, noise in the leak probabilities detectable degrades TN. Finally, noise degrading performance performance disruption in the priors has a similar, slight, but significant, effect in on both TP and TN. At the highest noise setting, u = 3, the the of networks with leak noise and prior noise sharply decline because levels on TP and TN. Noise in the link for TP, but has no statistically detectable has no statistically (+ = 1 and u = 2, but link noise significantly effect on TP at noise to the probability is so extreme (Fig. 15). values levels Why should link noise and leak noise show these contrary effects on TP and TN? We in the the role of the link and leak probabilities these results by analyzing can explain diagnosis. For simplicity, -f, absent, strength of diagnostic let us consider f, or on the posterior odds of a single disease D. A standard measure of the ratio, also known as the evidence finding F, being present, the effect of a single is the log-likelihood evidence P ( f 1 d) , the probability Eq. (5): of the finding when the disease is present is expanded using P(f)d)=l-(l-Leak(F))(l-Link(D,F)) =Leak(F) +Link(D,F)(l -Leak(F)). (9) P( f 1 -d), probability, Leak(F) probabilities: the probability of the finding when the disease . We can now rewrite the likelihoods is absent, is the leak in terms of the link and leak EW(f, D> = log,,, Leuk( F) + Link( D, F) ( 1 - Leuk( F) ) Leuk( F) Notice ( 11) ), because Fig. 17 plots does not play a role in the negative evidence weight the leak probability if a finding is absent the evidence weights and the mean evidence weight with u = 2 noise then the leak must be off by definition. for positive and negative of the link probability, probability. weight It demonstrates for the finding. This effect arises from findings, as a function in the link the evidence the fact that the evidence weights are that, on the average, noise in the link decreases (10) (Eq. 390 M. Pradhan et trl./Arti$cial Intelligence 85 (1996) 363-397 Poslive evidence no noise Positive evidence with noise Lmk probability Fig. 17. Evidence weights probability. without noise and with u = 2 noise. Note that noise tends to decrease both positive and negative from a single positive and negative for a disease findings. finding as a function of the link for the evidence weight concave to reduce increases. Noise increase the true negative functions of the link probability. Accordingly, to the true positive, the probability assigned in the links, by reducing in the links will tend as noise strength of findings can only to true negative, but this effect is undetectable because the noise reducing performance the evidential the probability assigned rate is already high. The impact of noise on the positive evidence (Eq. ( 10) ) is bounded by the value of the leak. The smaller In contrast. the link probability the leak, the greater the negative evidence weight the possible effect on the positive evidence. (Eq. ( 11) ) can be significantly decreased if is close to 1.0, as is the case with sensitive findings. A related argument demonstrates the strength of evidence on the average. increase true positives is again not detectable. false positives and so degrades performance that noise in leak probabilities will tend to increase to noise for true negatives. The effect on in leaks also tends In consequence, 7. Experiment on sensitivity to domain size In our third experiment, we examined the effect of the richness of the representation by comparing networks using quaternary domains. with variables at four levels-absent, mild, moderate, and severe-with hypothesis was that the binary representation would degrade of the network amount of degradation. networks using binary domains-absent, representation. We wanted to the quaternary the diagnostic performance to quantify relative present. Our the M. Pradhan et al./Ar@cial Intelligence 85 (I 996) 363-397 391 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Mean Prob(true dx) Domain Size Binary Quarternary 0 Kl TweDisease Three-Disease Network Fig. 18. Binary versus quatemary comparison for two- and three-disease networks. Creating a quaternary network is significantly more work than a binary representation, It requires leak, and prior distribution; link, for each probability, in each distribution instead of one probability (fourth or second) that they add to unity. The computational is also significantly since it requires assessment of at least three times as many probabilities. probabilities remaining constraint networks that we could not perform quaternary of knowing it would allow knowledge base designers domain construction due to the excessive computation in diagnostic precision due to changing representation the change than binary networks. runs for the four-disease to be worthwhile and computation. the experimental size is likely greater in trading off between precision to make more informed decisions network In this case, it was such in the time required. The benefit the domain size is that about what in and effort effort for inference in quaternary three the the is determined by 7.1. Design of domain experiment We started with the quaternary representation them to binary and reduced cases to binary converted so that we could compare directly test cases for testing the posterior disease probabilities representations. for the two- and three-disease networks, the quaternary test the results, we also Similarly, we reduced In scoring the binary networks. from the quaternary to binary representation the results from quaternary and binary networks. 7.2. Results of domain experiment As shown in Fig. 18, we found no statistically significant difference between the diagnostic accuracies of the quaternary and binary networks. We also found no significant difference when we restricted our comparison to Phase 1 cases. 392 M. Prudhun et ~d./Arti’ciul Intelligence 85 (1996) 363-397 7.3. Discussion of domain experittzettt The complete absence of statistically detectable difference domains was unexpected. In general from the binary and quaternary consistent with the findings to changes or noise in the complexity of the representation no reason required least. for this domain and class of networks. to invest for the richer in the numerical probabilities the preceding two experiments. The low sensitivity to changes low sensitivity that there is of the links. These results suggest suggests in the extra work for knowledge engineering and for computation representation. A simple binary representation is sufficient-at in performance terms, between is the finding 8. Experiment on outside diseases the performance of subnetworks with two, three, and four diseases in the knowledge base. The effect of incomplete of diagnostic system will have to handle cases in which the true disease or fault knowledge but more seldom the network of the experimental twelve diseases is often discussed, the effect of diseases outside the entire network with in our description systems from examines the reliability performance. As we mentioned test cases Any real diagnostic is not explicitly modeled bases on studied. Our fourth experiment on diagnostic approach, we generated analyze and BN4, respectively). Half of the test cases in all the results diseases disease not in the subnetwork. Our goal was to see how having outside the network would affect performance. Obviously, identify a disease outside network which are actually by the findings’ be incorrectly positive. that are outside each subnetwork. the network. The question explained by invoking leak is a proxy leaks-a reported above to (BN2, BN3, include includes a the true disease being the system cannot correctly the inside caused by an outside disease will be correctly explained they will to a false for outside diseases-or whether leading the network a disease inside In other words, the true diagnosis is whether any findings 8.1. Desigtl qf outside discuses e.rperimettr As described from the entire twelve-disease from mapping without noise. the diseases outside in the section on test case generation, we generated cases using diseases in half the cases one or more diseases this analysis, we use the standard each subnetwork. including network, For 8.2. Results qf outside diseuses e,rperimenr Fig. 19 shows diagnostic performance to the true diagnosis, the subnet- negative or positive, work and for cases which do contain one or more diseases outside the network. These results are averaged over all five phases and three networks. The results are qualitatively similar for cases which contain no diseases outside for each network separately. as the probability separately assigned M. Pradhan et al. /Art$cial Intelligence 85 (1996) 363-397 393 g 9 2 2 a 5 2 Number of Diseases Outside the Network Fig. 19. Effect of diseases outside negatives. True Negative True Positive the network on the average probability assigned to true positives and true’ The results for the true negative cases show almost perfect performance, are no outside diseases. Performance of outside diseases. The results to 0.76, by the presence of outside diseases. is significantly reduced, for the true positives are slightly 0.97, if there to 0.92, by the presence from 0.73 improved, 8.3. Discussion of outside diseases experiment The findings for outside diseases accord with our expectations for both true negative in to false that lead findings-and two or more diseases have common to explain the true negative the findings. For this reason, we observe rate. invoked erroneously reduce how the outside diseases can improve and positive cases. For the true negative cases, outside diseases may cause findings the network-where positives, outside diseases rate, consider To understand an outside disease to a disease in the network. For a test case in which both inside and outside diseases are present, finding will be present, the outside disease the true which will then be interpreted as evidence in the network, positive and so cannot cases with outside diseases can only increase to true positives, as we observe. rate. An outside disease cannot reduce the prevalence of findings the true positive that is also linked for the inside disease, and so increase in the network. Accordingly, that can cause a finding that the common of any disease in the network the probability the probability the probability increases assigned reduce Although the outside diseases degrade the true negative rate and positive diseases rate, the latter effect is significantly is to degrade performance. larger, so that overall improve the true the effect of outside 394 M. Prudhun er ul./Artijiciul Intelligence 85 (1996) 363-397 9. Conclusions In this paper, we have examined the sensitivity of several belief networks on diag- to imprecision nostic performance Overall, we have found a surprising ities. Here we summarize limitations. in the representation level of robustness of the numerical probabilities. in the probabil- to imprecision their and discuss the key findings, explore their implications, Extreme changes in the probability mapping link probabilities to numerical curvilinear mapping, which ties, provided performance uniform mapping which further on average, although ited evidence (the Phase 1 cases). from the qualitative frequency weights had modest effects on the diagnostic performance. The interprets probabili- that was worse than the standard mapping on average. The as order-of-magnitude the frequencies ignores all differences in link strength degraded performance it performed better than the curvilinear mapping with lim- The addition of massive amounts of random noise to the link, leak, and prior proba- in the link for all three networks. Noise had the largest effect in reducing performance in diagnostic performance. Noise bilities produced only modest decrements probabilities in the leak and prior probabilities degraded with the level of noise for all three networks. had smaller effects, but performance consistently The surprisingly small effect of large amounts of random noise should be reassur- it is belief networks. It provides empirical IPSs, and their relationships, to obtain ing for those constructing much more important and diseases, level of precision. Experience able providing probabilities, acceptable. Knowledge improve acceptance of these techniques. although use of probability that high suggests than to quantify information, evidence identifying that findings, the relations with a high that domain experts are much more comfort- than they are providing quantitative the latter more should greatly elicitation methods can make are not necessary levels of precision these kinds of qualitative knowledge the correct qualitative The surprising for each variable, from the quaternary if it turns out to be general, of a quaternary BN, assuming noisy OR and noisy MAX influences. lack of detectable effect of simplifying to binary is also good news for the engineer. A binary BN requires, at most, one third of the number of If the the relative advantage of binary domains effort than for many representation BN knowledge probabilities network contains more complex increases larger ones. Our results suggest applications. influences, rapidly. Moreover, small domains representation may be adequate require much less computational that a binary to examine existence of causes the effect of one class of incompleteness In our fourth experiment, we report one of the few studies cally representation, with leaky, noisy ORs and MAXes, provides a representation of the potential knowledge base. We found the diseases were missing was degraded, However, to provide an estimate of the probability work. systemati- of the knowledge base. The belief net as leaks in the in which the network. that we did not address was the net- that, as we expected, performance even the effect was moderate. An important question that a disease was present outside on test cases inside that are not explicit (diseases or faults) for the diseases M. Pradhan et al./Artifcial Intelligence 85 (1996) 363-397 395 system is to lead to better decisions-more by accuracy of diagnosis, not by improved decisions. However, Ultimately cost-effective measured performance imprecision the decision. model of system being diagnosed we find that the quality of diagnosis the quality of decisions will be equally or more robust. the purpose of any diagnostic treatments of diseases, or repair to complex artifacts. In this paper, we have if it should not degrade in the to imprecision than is the quality of the decision. Therefore, where that the diagnosis, is more sensitive does not degrade accuracy to imprecision, we can be confident In general, diagnostic in the representation is robust and suggestive evidence, we for all BNs. First, note that that predictive like most existing influences. to noisy MAX to believe these networks, hitherto, that make extensive use of other the large majority of types of While we believe that these results provide intriguing application. There is reason that they should not be viewed as definitive should caution these results are for a diagnostic applications may show greater sensitivity. Second, large BNs, use noisy OR influences, In fact, in most diagnostic influences influence may show different sensitivities. are noisy OR links. But, BNs belief networks constructed or their generalization Clearly, there is a need for additional work to explore believe that further experimental work will also help to provide a deeper understanding profitable avenues for further experimentation. is essential, we expect these possibilities. While we analysis of some of the findings, and suggest that theoretical We are not the first to argue that the conclusions the imprecision representations where both the structural assumptions of diagnostic and other expert sys- in the numerical parameters. However, embody unexplicated of rationality, from structural it is often hard to separate the question of simplifications. In the context of a probabilis- to be clear about both structural simplifications, and the effects of numerical approximation, sources of error, in a way that is impossible such as and so differ- in heuristic of principles approximations tems may have low sensitivity in heuristic simplifications numerical tic belief network, independence entiate among representations Our results assumptions, these potential of uncertainty. lend support it is possible for the value of qualitative probability probabilistic schemes infinitesimal [ 19,461 and such as the QPNs have performed initial experimental some for machine diagnosis using a qualitative with a numerical BN. We found the numerical The findings we have presented here help to explain qualitative and infinitesimal and quantitative little difference representations. representations infinitesimal comparisons of the performance representation in diagnostic performance for cases with small fault priors the small differences between representations, [ 131. Indeed, we of a BN (the K calculus) between [ 181. the Acknowledgements This work was supported by NSF grant IRI 91-20330 Systems Research. We would commentary BN, and Lyn DuprC for her editorial help. like on earlier drafts, Dr. Blackford Middleton to thank Joseph Kahn to the Institute for providing for Decision feedback and for his help in developing CPCS- M. Prudhun et ul./Art[jiciul Intelligence 85 (1996) 363-397 References 1 1 1 J. Breese. Construction of belief and decision networks, Tech. Rept. 30, Rockwell International Science Center. Palo Alto, CA ( 199 1) 12 1 1. Breese and E. Horvitz, Ideal reformulation of belief networks, in: Proceedings Sixth Internationul Workshop on Uncertuinty in Al. Cambridge, MA ( 1990) 64-72. 13 1 D. Chard, Mathematical methods 14 1 D. Croft and R. Machol, Mathematical methods in medical diagnosis, Med. Decision Making 2 (2) ( 1991) 69-89. in medical diagnosis, Ann. Biomed. Eng. 2 ( 1987) 69-89. 1 S 1 R.M. Dawes and B. Corrigan. Linear models 16 1 ET. de Dombal. The diagnosis of acute abdominal pain with computer assistance: worldwide perspective, Psych. Bull. 81 ( 1974) 95-106. in decision-making, Ann. C/G. 45 ( 1991) 273-277. 17 1 ET. de Dombal, D.J. Leaper. J.R. Staniland. Al? McCann and J.C. Horrocks, Computer-aided diagnosis of acute abdominal pain, British Med. J. 2 ( 1972) 9- 13. ( 8 1 F.J. Diez, Parameter adjustment in Bayes networks: Ninth Anmtul Conttirence on Uncertuinry in Arr$iciul and R.S. Davies, Use of a bayesian 19) EH. Edwards noisy OR-gate. the generalized Intelligence, Washington, DC ( 1993) 99-105. diagnosis in the computer-assisted algorithm in: Proceedings of appendicitis, Sur,?. Gynecol. Obstet. 158 ( 1984) 2 19-222. 1 IO 1 P.C. Fishbum, A.H. Murphy and H.H. Isaac& Sensitivity of decisions to probability estimation errors: a re-examination, Oper. Rex 16 ( 1968) 254-267. 1 1 I 1 J. Fox, D. Barber and K.D. Bardhan. A quantitative Met/l. Inf>rrn. Med. 19 (1980) 210-21.5. comparison with rule-based diagnostic inference, [ IZ ) D.G. Fryback. Bayes‘ theorem and conditional nonindependence of data in medical diagnosis. Compur. Biomed. Rex. 11 ( 1978) 423-434. ( 13 I M. Goldszmidt and J. Pearl, Reasoning with qualitative probabilities can be tractable, in: Proceedings Eighth Conference on Uncertainty in Al. Stanford, CA ( 1992) 112-120. E.J. Horvitz and B.N. Nathwani, Toward normative ( 141 D.E. Heckerman, expert systems: Part 1. The Pathfinder project, Mer/t. Infi~rnt. Med. 31 ( 1992) 90-I OS. [ IS I D.E. Heckerman and R.A. Miller, Towards a better understanding of the INTERNIST- I knowledge base, in: Proceedings Medinfr,, Washington, DC (North-Holland. New York. 1986) 27-3 I. I 16 1 M. Henrion. Propagation of uncertainty by probabilistic logic sampling in Bayes’ networks, and L.N. Kanal, eds., Uncerfuin~ in Arti$ciuI Intelligence 2 (North-Holland, Amsterdam, in: J. Lemmer 1988) 149- 163. I I7 1 M. Henrion, J.S. Breese and E.J. HorvttL. Decision analysis and expert systems, AI Mugazine 12 (4) (1991) 64-91. ( 181 M. Henrion. A. Darwiche, M. Coldszmidt, G. Provan and 8. Del Favero. An experimental of infinitesimal Fifrll and numerical probabilities Internniionul Workshop on Principles of Diqnosis. for diagnostic reasoning, New Paltz, NY ( 1994) 13 I- 139. I 19 ] M. Henrion and M.J. Druzdzel, Qualitative and linguistic explanationsof networks, in: Proceedings Sixth Internutional Conference on Uncertainty probabilistic in belief in Al. Cambridge, MA ( 1990) reasoning I O-10. I20) F. Jensen and S.K. Andersen, Approximations in Bayesian belief universes for knowledge based systems, in: Proceedings Si.rth International Co@rence on Uncertainty in AI, Cambridge, MA ( 1990). 12 I I D. Kahneman, P. Slavic and A. Tversky. Judgntenr under Uncertainty: Heuristics and Biuses (Cambridge University Press, Cambridge, [22] U. Kjmrulff. Aspects of efficiency 1982). improvements in Bayesinn networks, Ph.D. Thesis, Department of Mathematics and Computer Science. Aalbog University, Aalborg 11.3 I B. Middleton, M. Shwe. D.E. Heckerman, M. Henrion, E.J. Horvitz, H. Lehmann ( 1993 ). and G.F. Cooper, of the INTERNIST- 1 /QMR knowledge base 11: Evaluation Probabilistic diagnosis using a reformulation of diagnostic performance, Meth. I24 1 R.A. Miller, FE. Masarie and J.D. Myers, Quick medical (QMR) for diagnostic assistance, Med. Conput. 3 ( 1986) 34-48. [ 1.5 I R.A. Miller. H.E.J. Pople and J.D. Myers, INTERNIST- I : An experimental computer-based diagnostic consultant for general internal medicine. Nen Englund J. Med. 307 ( 1982) 468-476. Inform. Med. 30 ( 199 1) 256-267. reference comparison in: Cl. Provan, ed., Proceedings M. Pradhan et ul./Artificial Intelligence 85 (1996) 363-397 391 [ 261 M.G. Morgan and M. Hemion, Uncertainty: A Guide to the Treatment of Uncertainty in Quantitative Policy and Risk Analysis (Cambridge University Press, New York, 1990). [ 27 1 K. Ng and B. Abramson, A sensitivity analysis of Pathfinder: a follow-up study, in: Proceedings Seventh International Conference on Uncertainty in AI, Los Angeles, CA ( 1991) 242-248. (281 M.J. Norusis and J.A. Jacquez, Diagnosis diagnosis, Comput. Biomed. Res. 8 (1975) I: symptom nonindependence 156-172. in mathematical models for ]29] J. O’Neil and R. Glowinski. The ARC and AURC cooperative group: computer-aided diagnosis of acute abdominal pain when taking into account interactions, Med. Inform. 2.5 ( 1990) 194-198. [ 301 R.C. Parker and R.A. Miller, Using causal knowledge as an extension of INTERNIST-l, Computer Applications in Medical Cure. Washington, DC (IEEE, New York, 1987) 473-480. to create simulated patient cases: the CPCS project in: W.W. Stead, ed., Proceedings Eleventh Annual Symposium on [ 3 11 J. Pearl, Fusion, propagation 132 1 J. Pearl, Probabilistic Reasoning in Intelligent Systems (Morgan Kaufmann, San Mateo, CA, 1988). [ 33 ] Y. Peng and J. Reggia, Plausibility of diagnostic hypotheses, in belief networks, Art6 Intell. 29 ( 1986) 241-288. in: Proceedings AAAI-86. Philadelphia. PA and structuring (1986) 140-145. 1341 D.A. Pierce and J.L. Folks, Sensitivity of Bayes procedures to the prior distribution, Oper. Rex 17 (1969) 344-350. 1351 M. Pradhan, G.M. Provan, B. Middleton large belief in: Proceedings Tenth International Conference on Uncertaint?, in AI, Seattle, WA ( 1994) and M. Hemion, Knowledge engineering for networks, 484-490. I 36 ] G. Provan, Tradeoffs in constructing and evaluating temporal influence diagrams, in: Proceedings Ninth Annual Conference on Uncertainty in Artificial Intelligence, Washington, DC ( 1993) 40-47. [ 37 1 G.M. Provan, Tradeoffs in knowledge-based construction of probabilistic models, IEEE Trans. Syst. Man Cyberrl. 24 ( 11) (1994) 287-294. tree-decomposable 138) S. Sarkar, Using structures to approximate belief networks, in: Proceedings Ninth Annual Conference on Uncertainty in Artificial Intelligence, Washington, DC ( 1993) 376-382. 1391 B. Seroussi, Computer-aided diagnosis of acute abdominal pain when taking into account interactions. Meth. Inform. Med. 25 (1986) 194-198. [40] M. Shwe, B. Middleton, D.E. Heckerman, M. Hemion. E.J. Horvitz, H. Lehmann and G.F. Cooper, of the INTERNIST- I /QMR knowledge base I: Probabilistic Probabilistic diagnosis using a reformulation model and inference algorithms, Meth. Inform. Med. 30 (1991) 241-255. [ 41 ] S. Srinivas, A generalization of the noisy-or model, in: Proceedings Ninth Annual Conference on Uncertainty in Artificial Intelligence, Washington. DC ( 1993) 208-2 15. 1421 B.S. Todd and R. Stamper, The formal design and evaluation of medical diagnostic programs, Tech. Rept., Technical Monograph PRG-109, Oxford University Computing Laboratory, Oxford (1993). 1431 B.S. Todd and R. Stamper, The relative accuracy of a variety of medical diagnostic programs, Meth. Inform. Med. 33 (1994) 402-416. 1441 D. von Winterfeldt and W. Edwards, Decision Analysis and Behavioural Research (Cambridge University Press, Cambridge, (45 1 H. Wainer, Estimating 1986). coefficients in linear models: it don’t make no nevermind, Psych. Bull. 83 ( 1976) 213-217. [46] M.P. Wellman, Graphical 1471 BP Wise and M. Henrion, A framework in qualitative probabilistic for comparing inference networks, Nemorks 20 ( 1990) 687-701. uncertain inference systems to probability. in: L.N. Kanal and J. Lemmer. eds., Uncertainty in Artificial Intelligence 4 (North-Holland, 1986) 169-184. Amsterdam, 