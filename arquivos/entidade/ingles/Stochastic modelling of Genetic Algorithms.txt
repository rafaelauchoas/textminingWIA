ELSEVIER Artificial Intelligence 82 (1996) 303-330 Artificial Intelligence Stochastic modelling of Genetic Algorithms David Reynolds*, Jagannathan Gomatam Department of Mathematics, Glasgow Caledonian University, Cowcaddens Road, Glasgow G4 OBA, UK Received July 1994 Abstract throughout distinctions replacement, for convergence, via Genetic Algorithms, which has practical This paper presents stochastic models for two classes of Genetic Algorithms. We present between classes of Genetic Algorithms which sample important in terms of their search dynamics. For both classes of with and without and analyse special cases of algorithm, we derive sufficient conditions Genetic Algorithm optimisation. We also derive a long-run measure of crossover bias for to the optimisation theoretical choice of crossover operators. For a class of Genetic Algorithms, we provide the algorithms underpinning increase. For degenerate an alternative accompanies excessive crossover rates. In formulating important definitions are introduced which capture in simple form the probabilistic properties of the genetic operators, which provides models which are independent that results, by proving search as mutation probabilities that degeneration class of Genetic Algorithms, we show of a class of empirically derived of solution encoding schemes. implications with respect cost-independent to randomised, the models, 1. Introduction reasons Genetic Algorithms to a wide variety of combinatorial including many that are NP-hard [3,10]. Theoretical (GAS) are a set of heuristic search algorithms which have optimisation been applied with success into problems, those who the and analyse deterministic mathematical models for GAS 12, lo], and formulate those who investigate the application of stochastic models based on the theory of Markov Chains [4, 5, 7-9, 15, 17, 181. In this paper we shall present a number of stochastic models for GAS. this success are divided mainly investigations two camps; into for * Corresponding author. E-mail: dre@gcal.ac.uk. 0004-3702196/$15.00 SSDI 0004-3702(94)00091-3 0 1996 Elsevier Science B.V. All rights reserved 304 D. Reynolds, .I. Gomatam I Artificial Intelligence 82 (1996) 303-330 We begin by giving a brief introduction to GAS in Section 2, making important of and there. properties [4,5,15,18], then proceed to the authors; the GA operators representation-independent of homogeneous Markov Chains the probabilistic to formulate In Section 3 we present a brief introduction from old ones by sampling with replacement, In Sections 4 and 5 we introduce new definitions large classes of GAS, those which create new populations of distinctions between and those which sample solutions to the solutions without replacement. to theory in [7] summarise current stochastic models for GAS [7-9, 171. The work reported in this paper we generalise and extend was previously unknown for the results reported these describing stochastic models for the two definitions classes of GAS mentioned. The models are to investigate various properties of GAS. We analyse special cases of optimisation via GAS, and show that, given certain choices of mutation and crossover rates, both GAS reduce to a search of the solutions where no role is played by the cost function, despite the that both GAS For of a selection operator. presence for the expected numbers of converge in one generation. We present bounds in the long run which is based optimal and other solutions within the population on the probability of creation of solutions under crossover, for the class of GAS which operate on the basis of sampling with replacement. Finally, we discuss the for further analysis of the models contained potential in this paper with respect to the long-run probability distribution of a generalised GA [7] and for obtaining their rates of convergence analysing these cases, we show this distribution. then used and use towards 2. Definitions of GAS . . , k}, and that for the formulation their behaviour. We stipulate and concepts which are necessary to describe The objective of this section is to formulate definitions for GAS, together with of various assumptions that our optimi- mathematical models sation problem has k > 0 candidate solutions, where k is an integer. We assume that we have assigned a bijective mapping from the set of solutions to the integers (1,. a well- defined cost (or fitness), J, which is restricted by 0 <A < CQ. Thus, to the set of fitness values f = solutions {fi7.. . , fk}. For the purposes of formulating the models, we merely assume to the [lo] each solution would be repre- solutions, e.g., thus, we sented in our analysis as the base 10 version of its binary representation; do not assume any particular encoding scheme for solutions. that we have assigned a natural in a binary string encoding a set of and developing s = {si , s2, . . . , sk} i s k) there corresponds to each solution labelling system corresponds i (1~ index there A GA mentioned for solving is characterised by possessing the following features finite and discrete maximisation [3, lo]: problems of the type (i) a scheme for encoding solutions to the optimisation problem to be solved (chromosomes); (ii) an evaluation function that rates each solution, assigning a positive cost, or fitness to each one: D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 305 (iii) an initialisation procedure candidate solutions; for generating an initial population of size N of (iv) a set of operators used to manipulate the genetic composition of the population between generations; (v) a set of parameter values, such as stopping-criteria, This algorithm, together with the genetic operators, has been implemented etc. in the recent there are many different to optimisation problems, the fitness evaluation/selection, representation the most common many different ways [6]. For example, schemes [6] for candidate solutions being binary strings of fixed length L. Also, in different ways mutation and crossover operators have all been implemented [7]. [6], including introduction Further, the order in which these operators are applied in order to generate new populations has also been varied [6]. However, we can divide into two classes the majority of from the current population and solutions by sampling solutions with replacement those which sample solutions then the genetic operators. A pseudo-code without is: description the genetic operators, and then implement those algorithms which form new populations for GAS which use sampling with replacement of a time-varying mutation operator of existing GAS; implementing replacement and GAIWI(N, begin s, f, fitness selection, mutation, crossover) Initialise with population of size N at generation REPEAT WHILE BEGIN ]Pop(t + l)] <N t = 0 Select (p 2 2) parent solutions with replacement from Pop(t) by fitness selection Carry out mutation of the copies of the selected parents Combine the mutant parents to form (c 3 1) child solutions by crossover Place the child solutions in the new population Pop(t + 1) END t:=t+l UNTIL stopping-criteria-reached end Here and in what follows, mutation and crossover are pre-defined operators. We shall consider fitness selection above and in what follows to be implemented roulette wheel selection the selected parent solutions for GA/WI, we shall by the common immediately after selection consider into the old population into Pop(t)), and that we subsequently operate on copies of the parents. For GAS which operate on the basis of sampling without replacement, a pseudo-code description to be replaced [lo]. Further, (i.e., is: GA/ WO(N s, f, fitness selection, mutation, crossover) begin 306 D. Reynolds, J. Gomatam ! Artijicial Intelligence 82 (1996) 303-330 Initialise with population of size N, N even, at generation REPEAT t = 0 Select N parent solutions with replacement from Pop(t) by fitness selection, to form population Pop’(t) to each solution Carry out mutation in Pop’(t) to form population Pop “( t ) Carry out croSSover pairwise between solutions in Pop”(t) to form N new child solutions, to form population Pop”‘(t) Set Pop(t + 1) := Pop”‘(t) t=t+l UNTIL stopping-criteria-reached end although in GA/W0 to note that both algorithms contain a sampling with replacement It is important fitness selection operator, and crossover operators are implemented on the basis of sampling from the current population without the latter tions. Note that we have not described choice of solution models we formulate will be independent of in GA applica- to the [6]. The two operators without replacement the above algorithms with respect to [9], GAS which contain replacement. According scheme, of which are more common there are many of representation. implementations the mutation representation 3. Current stochastic models We present a brief introduction the current approaches to [5,15,18] for further details. to discuss to Markov Chains. We then proceed to the stochastic modelling of GAS. The reader is referred 3.1. Homogeneous Markov Chain theory Definition 3.1. A stochastic process (i.e., a sequence of random variables over i.e., if time, X(t)) if it exhibits Markov dependence, is called a Markov process Pr[X(t) <x 1 X(t,) = x,, . . . , X(to) = x,] = Pr[X(t) s x 1 X(t,) = xn] = q&,x; t,) , (3.1) (3.2) (3.3) where t>t,>+-- > t,. A realisation of X(t) over time is called a Markov Chain. The Markov Chains we shall discuss in this paper are realisations of random variables defined over discrete state-spaces and discrete time. If a Markov process is said to be homoge- has parameters which do not vary over time, the process case, the probabilities of neous, otherwise, In the homogeneous inhomogeneous. D. Reynolds, .I. Gomatam I Artificial Intelligence 82 (1996) 303-330 307 transiting from state i to state j between on t, - t, and are defined to be time steps t, = m and t, = n depend only PI;“.“’ = Pr[X,=j]X,=i]. (3.4) A Markov Chain is said to be irreducible one time-step transition probability matrix i, 1 G i <S, s.t. Pii > 0, then the chain is said to be aperiodic. For irreducible and finite length Markov Chains, the following two theorems hold: aperiodic if the corresponding If the chain has all of its states is irreducible. 3.2 Theorem irreducible, n 3 N, the n-step transition probability matrix P” has no zero elements. [15, p. 471. Let P be the transition probability matrix of an finite Markov Chain. Then there exists an N s.t. for all aperiodic Theorem irreducible, S-state finite Markov Chain. Then 3.3 [15, p. 881. Let P be the transition probability matrix of an 9T ) L-1 9 n ?LilPl= (3.5) (3.6) (3.7) wherem=[rr,,rz,..., ~~s]withO<‘rr~<landm-[l,...,l],,,=l. The following theorem shows that irreducible at a geometric and aperiodic Markov Chains (i.e., possess geometric rate stationarity converge towards ergodicity , [ 151). Theorem 3.4 [15, p. 901. Let P be the transition matrix of an irreducible, aperiodic S-state Markov Chain. Let the limiting probabilities be defined as in (3.5). Then there exists constants c and r with c > 0 and 0 < r < 1 s.t. P. = r. + e(Y) I 11 11 ’ where ]ely)] < cm . When P>O, c= 1. Finally, the following theorem presents the stationary irreducible and aperiodic Markov Chain in terms of the corresponding probability matrix: distribution of an transition Theorem 3.5 [15, p. 921. Given the transition probability matrix P of an aperiodic and irreducible, there exists a unique probability vector ‘II = [7r1, n;, . . . , CTJ with TV - [l, . . . , l],,, = 1, and S-state finite Markov Chain, IlP=II=PlT, (3.8) 308 D. Reynolds, J. Gomatam I Art@cial Intelligence 82 (1996) 303-330 where II is a matrix where each row vector is identical to r. The probability vector w gives the stationary distribution of the process. Notice that (3.8) implies nP = n. In the rest of the paper, we shall refer (3.8) as the invariant equation. We proceed current approaches in the next subsection to the stochastic modelling of Genetic Algorithms. 3.2. General stochastic models for GAS to to discuss Most current models formulated to describe the probabilistic search carried out and the properties and that, and primitive it can be shown the genetic operators by GAS are mainly based on quite general matrix properties, are cast as of the binary string encoding scheme. Thus, irreducible for stochastic matrices, example, due to the properties of these matrices a stationary distribution holds for since these models generally consider certain classes of GA [7-9,171. However, i.e., the the action of the mentioned operators upon the states of the algorithm, populations, to it is quite difficult to obtain results regarding the optimisation problem [17]. Thus, the transition probability matrices of many current models are based in the large part upon the irreducibility and primitivity and this means that the models are not properties of certain genetic operators, that a particular formulated solution is created upon mutation, crossover, and other algorithm parameters. Thus, the corresponding to the search dynamics of the main stochastic model of [17] is on the basis of costs of solutions, can be extracted with respect algorithms. For example, the actual solutions little information the probability P=C*M*S (3.9) acting upon where P is the transition probability matrix of the underlying stochastic process of and C, M and S are irreducible matrices which corre- the Genetic Algorithm, states of the to the three genetic operators spond algorithm. The stochastic model contained an abstract generalisation, which also appears to be over-simplified [17], as is the main model of [9]. Note that in [8,17] a globally optimal GA is given as one which maintains (i.e., elitism [lo]). the currently optimal solution from generation the global optimality of this algorithm In [17] the conclusion trick”. We verify this conclusion explicitly depends essentially on this “algorithmic in this paper by carrying out the analyses of special cases mentioned previously. in [8] is essentially the population to generation is reached that 3.3. Explicit stochastic models for GAS In [7], a description binary encoded GA as a sequence of random vectors models, GAS, at least for those which implement sampling with replacement, is given of the application and analysis of modelling a [4,11]. Thus, using these it is shown in [7] that a stationary distribution exists for certain classes of the genetic operators on the basis of instances of GA/WI under a binary encoding i.e., D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 309 equations of modified [lo]. The stationary distribution of the GAS described in [7] is given in scheme transition probability matrices. terms of the characteristic the main work of [7] is concerned with the analysis of time-varying However, to both mutation probabilities within Genetic Algorithms, and does not generalise classes of Genetic Algorithm under discussion here. In this paper we present and by formulat- formalise their differing ing stochastic models search properties; in the the stationary dis- literature. The models are then used tribution of both of these GAS in certain cases, and to provide practical guidance for the parameterisation the distinction between algorithms GA/WI and GA/W0 for each algorithm which show explicitly these differing properties have not yet been discussed to present explicitly of such algorithms. 4. Stochastic model for GA/WI The objective of this section is to formulate a stochastic model for the first class of solutions of algorithms, GA/WI, purely on the basis of sampling with replacement from the current population and then operating on copies of the sampled solutions with the mentioned genetic operators. those which create new populations i.e., 4.1. K-solution, 1 -operator GAIWI(N, s) We present a stochastic model for GAIWI(N, s), i.e., with no fitness selection, mutation or crossover operators. We begin by formulating essential definitions. Definition 4.1. Let (Xi), represent GA/ WI at time t. Then (X, , X2, . . . , X,), represents in the population integer. the numbers of solution i within the population the numbers of all solutions at time t, where X, + X2 + * * * + X, = N and Xi is a positive Definition 4.2. Let Pl={X=(X x 1, 2, . ..> X,): X,+X,+..*+X,=N, Xi a positive integer} represent the set consisting of all valid states of algorithm GA/WI. Thus, since GA/WI samples solutions with immediate replacement on copies of is made between the genetic operators implements distinction states of ,!?‘I. Since the numbers of each solution within random variable, subject vectors. Essentially, to X, + X2 + . . . + X, = N. Therefore, (X, , X2, . . . , X,) E Slkl is a random vector [ll], the states of GA/WI are random to the analysis of the properties of GA/WI with respect the permutations of solutions within the population the population is a the collection the sampled solutions, and then no 310 D. Reynolds, J. Gomatam I Artijicial Intelligence 82 (1996) 303-330 heuristic search for optimisation probability distributions of the given random variables/vectors. reduces, in certain cases, to the analysis of the In order to formulate conver- gence results for GA/WI, we make the following definition of matrix multiplica- tion for general matrices which are indexed by vectors; transition probability matrices and corresponding Definition 4.3. Let A,, E R and BXy E 8 be ]Slkl] x IS’kll matrices, where X,Y E the real Slkl. Then we define as the ZJth element of the matrix product AB number c Am& = c AIDiBDJ VZ, J ESLk’ , DES[kl Is[kll i=l (4.1) where by summation over Di is meant the list of vectors formed under an arbitrary bijective mapping between {1,2, . . . , Is’~‘~} and S’kl. Thus D is a dummy vector in (4.1). Only the existence of the (arbitrary) mapping [19]. When successive matrix is important, multiplications the same it is assumed mapping and there are ]Stkl]! such mappings are carried out for such matrices, throughout. is used for indexing purposes the summation over that From this general definition, we make the following definition for premultipli- cation of an ]Stkll x ISLkll matrix by a 1 x 1~~~~1 column vector. Definition 4.4. Let qr E 3 and Bxy E ‘3 where B is an ]s’~]] x I,s’~‘J matrix and q is a 1 x ISfk’l column vector, where X,Y E S’kl. Then we define as the .Zth element of the matrix product qB the real number c qD& DES[kl I.s[kll = 2 i=l q@Dd VJ E SIkl 9 (4.2) where by summation over Di is meant the list of vectors formed under an arbitrary bijective mapping between {1,2, . . . , /,SLklj} and Slkl, as in Definition 4.3. the summation over indexing notation This notation, which enables us to ignore the particular mapping used and for the elements of the transition matrices which retain vector are to follow, is useful in terms of estimating marginal probability distributions from transition matrices 1151, as will become clear. It is usual when formulating stochastic models the existence of the bijective mappings in the previous definitions, and then use these to index the states of the described GA [7-91. However, to this then gives useful retain the identity of solutions within the states of GA/WI; information to both solutions and states. on the long run search properties of the GAS with respect in this paper we do not require this restriction, preferring for GAS to show A result is given in [7,17] concerning the number of states of a GA, in terms of D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 311 the chosen present representation scheme, the following general result. i.e., fixed length binary strings. We now Proposition 4.5. GAIWI with population size N, where the order population solution space of size IsI = k searches a state-space of size IS’kll, where in which the is stored is irrelevant (sampling with replacement GA), operating on a p’k’l = (“,‘” ; ‘) . Proof. A population configuration and only if X,+X,+...+X,=N (Xi, X,, . . . , X,) is a valid state of GA/WI if (4.3) (4.4) by definition of X E Stkl. Thus the total number of valid states is given by the total number of distinct solutions of this equation integers, which is a well-known problem from combinatorics, with solution as stated [19]. 0 in non-negative Therefore, the number of states of GA/WI is a function of the solution space and the population size alone, regardless of the chosen solution encoding scheme. and It will be shown is the number of states of each algorithm; GAS which contain operators GA/W0 which do not sample with replacement (i.e., GA/ WO-type algorithms) will be shown to have more states than those which do not contain such operators. that a fundamental between GA/WI difference later With the necessary definitions of the underlying (solutions) (states) of the following stochastic model in place, we now and random vectors the conditional probability distributions of these entities; for proceed to calculate GAIWI(N, i is sampled from population X = (X, , X,, . . . , X,) E Stkl is X,/N where 1 c i d k. the probability of Y = (Yi , Y,, _ . . , Y,) E Stkl instances of solutions Therefore, (1,. . . , k) at time t + 1 given X = (Xi, X,, . . . , X,) instances at time t is s), with random sampling of solutions, random variables the probability that solution Pr{(Y1, yZ, . . . , Yk)r+l 1 cxl? x2, . . . , xk>t> = PXY = Y,!Y,!. . N! . yk! (zL)“(~)“. . . (g’“, (4.5) This equation gives the conditional (Yi, Y2,. . . , Yk) at time of the random that the state-space of the Markov vector process defined by (4.5) is the same as the space defined in Definition 4.2, i.e., it consists of all distinct vectors (Xi, X,, . . . , X,) E Stk’. Each solution has a one- step conditional probability distribution given by [ll] t + 1. Note distribution probability whereX,YES ‘kl Substituting . 4.5 ( ) into (4.6) shows that the numbers of solution (4.6) 312 D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 i, 1 c i 6 k, within the population binomial distribution. investigated at time In [7] certain basic properties t, (Xi), is a random variable with a (4.5) are of the model for the case of binary representation schemes. 4.2. Incorporating fitness-based selection: GAIWI(N, s, f, roulette wheel) We consider the standard roulette-wheel-based . . . ) x/J E S@’ there corresponds solution has a strictly positive Since each (Xi ) x2, 5 > 0, 15 i =S k, if we select from the population at time t (with replacement) the basis of roulette-wheel i is sampled from population X E S’kl is fitnesses then we have that the probability a fitness vector, cost, or f= selection procedure fitness value, (fi, [3,10]. to i.e., . . . , fk) with on that solution X,f; so that (4.7) Pr~(Yl,Y~,....Y~)l+ll(~l,xZ....~xX)O=-j_~~~~ (4.8) N! where by rxi is meant the relative fitness of solution i conditional upon population X. Since the fitness of a solution is assumed fixed, we have again that this model first-order Markov process, over the states defined as defines a time-homogeneous This model is also discussed in [7] for the before byX=(X,,X,,. of solutions [lo]. In the next section, special case of binary string representation we discuss the problem of introducing the GA mutation and crossover operators into this model, in a form which leaves the model representation-independent. ..,X,)ES’~]. 4.3. Incorporating mutation and crossover: GAIWI(N, s, f, roulette wheel, mutation, crossover) Since our models are to be representation-independent, we make the following in simple form the stochastic properties of the genetic definitions, which capture operators mutation and crossover. Definition 4.6. Let r] be a row-stochastic mutation matrix, i transforms probability that solution to solution j under mutation, i.e., i.e., 77ij stores the &jij=l. j=l (4.9) For example, the fixed mutation probabilities p, c l/2, used in [6, lo], we have that for a binary representation with strings of fixed length L and using D. Reynolds, J. Gomatam I Artijkial Intelligence 82 (1996) 303-330 qij +yyl -pm)L-H(i,j) ) Tij = Tji > 0 313 (4.10) the Hamming distance between i and j [17]. To both incorporate [17], where H(i, j) represents encodings of solutions representation-independent, the probability fixed number of (ordered) operation. “minimal” crossover probability matrix is defined below. the binary string crossover and to remain we define a crossover probability matrix, which gives that a fixed number of (ordered) parent solutions will generate any the action of some crossover triples, etc. The is indexed by ordered pairs, child solutions under this matrix Thus, Definition 4.7. Let C, m, j > i, be a row-stochastic crossover probability matrix, i.e., m$lCij,m=l VlSiSjGk, (4.11) that stores the probability with which solutions i, j, will produce solution m under (1 s i c j s k, 1 =S m s k). Moreover, we define C, i > 0 the action of crossover and Cij,j > 0 (non-zero probability of parental retention). Note that the rows’of C are indexed by ordered pairs of parent solutions, the columns by single child solutions. An example is given in Appendix A of a crossover probability matrix for a that we in an ordered pair, which forces the string length is 2. Note binary string encoding of solutions, where force to be gathered the parent uniqueness of reference. solutions in place, to see that this definition as implemented it is now possible l-child crossover operation, this particular in, for is a 2-parent [14], i.e., 2-parent solutions will always generate only one child (which It was noticed that in fact it is quite possible to define With croSSover example, may be one of the parents). an X-parent Y-child crossover operation it should be pointed out that descriptions of crossover instances of an X-parent Y-child crossover operation, easily extended triples, must be distinct so that requirement production probabilities under crossover are not over/underestimated C matrix. Since our definition Chain model for GA/WI which uses this definition. As usual, the previous definitions apply to the given genetic operators scheme. in the literature are mere the C matrix can be i.e., the essential the solution within the is the simplest possible, we shall develop a Markov two regardless of solution encoding triples, etc., of both parents the pairs, [6], where X 2 2 and Y 2 1. Therefore, to is that and children; the probability With these definitions of mutation and crossover calculate (X1,X*, two parents between in terms of the unions and intersections of probabilistic events, that under (with replacement), the mutant and non-mutant to solution given X = fitness selection of the action of roulette-wheel then mutation of one parent and then crossover to produce solution i; this is clearly given by, in place, we now proceed is produced . . . ,Xk)EPl, 1 pi s k, i, 314 D. Reynolds, J. Gomatam I Artificial Intelligence 8.2 (1996) 303-330 = Pr U jfS n U j-;;‘b n U d,, n d, b;,i bEs dEs I i jES (where subscript “fs” refers to fitness selection) which has probability (4.12) (4.13) (4.14) where by pxi is meant i by GA/WI, conditional upon population X, where 1 s i s k. This gives the stochastic model as for GA/WI, with the given operators, the probability of generation of solution N! PXY = y,!y,!. . (4.15) where Y E S’kl. Note that the independence of parent selection gives (4.13) from (4.12). The row-stochasticity of P follows from that of the given pxi terms (which two definitions) and the properties of the multinomial follows by the previous distribution the stochastic model would be obtained [12]. With mutation of both parents, in a similar manner, for X, YE S’kl, (4.16) 4.4. Analysis of the models for GAIWI(N, s, f, roulette wheel, mutation, crossover) three results relating to present We proceed in this section to a stationary distribution; search which has important properties of GA/WI. The first result presents sufficient conditions for GA/WI converge GA/WI terisation approximation We first show the usefulness of the independence of the models by presenting theorem to the search to the second result presents a special case of for Genetic Algorithm parame- implications result presents a long-run of crossover. from solution encoding schemes (4.15). A convergence result for GA/ WI with respect to the implementation for (4.16) may be obtained similarly. and representation issues, and the the following for model third 4 ;,m_ . [I P’= 4 y D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 315 4.4.1. Parameter choice for convergence Theorem 4.8. GA I WI with 77 > 0, and C as defined, converges in limit towards a stationary probability distribution q where qx is strictly positive for all X E S’kl, i.e., Also, convergence takes place at least geometrically, P$i = qr + e$i for all states X, YE S’k’, where le$tl < rf . (4.17) i.e., there exists 0 s r < 1, s.t. (4.18) (4.19) Finally, q is independent of the initial choice of population X(O). Proof. Suppose we are given arbitrary states X, YE S’kl where we transit from X to Y in one in P given by (4.15). Then, time step according there are two possible cases; to the appropriate probability Case 1: X, = 0, some 1 <I s k. Then there exists at least one component Xj in is relative fitness rZj greater than zero, since the population X, with corresponding of fixed size N. Thus, p,I=r~j77ilr,iCj~I~.-.>0 p,I=r,j17i,r,jC~jr+...>0 (jsZ), (j>Z). Case 2: X,>O, 16Isk. Then pxI = ‘;17)11r&1,1 + . . . > 0 . (4.20) (4.21) Therefore, for arbitrary states X, Y E Slkl the entry in P consists of a product of strictly positive numbers, since I was also arbitrary, which implies that P is strictly positive. The result follows by application of Theorems 3.2 and 3.3. q Note that mutation is often implemented for binary-encoded GAS in such a way as to force n > 0, as mentioned previously 17,171. In the next section we show that removes bias it is possible towards solutions based on cost. in a way which completely to parameterise GA/WI 4.4.2. Special case Proposition 4.9. GA/WI has a random-search-type algorithm over the solution space as a special case, i.e., there exists at least one choice for C, s.t. the underlying stochastic process of GA I WI is a Markov Chain in which any given k - 1 solutions 316 D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 can be represented by independent and identically distributed random variables. Further, to stationarity immediately, the Markov Chain under in one generation. this choice of C converges i.e., Proof. Set Cbd,! =llkVl~b~d~k, lsttk. Then, pxi=llk Vlsisk, VXES[~’ by substitution in (4.14) so that N! 1 Pxy= y,ly2!.. .Yk! kN’ (4.22) (4.23) where Y E S’kl. Since process, if it exists, is unique, we can “guess” the stationary distribution of a homogeneous stochastic N! qx=x,!x2!...xk! 1 kN’ and check by substitution in (3.8) (4.24) c 4XPH = XES(kl and c 4x=1, XE.s[kl N! xEst”l x, !X,! ’ ’ .x,! =[ 1 kN Yl!Y2!. N! 1 . * Yk! 2 I = PXY (4.25) q,>o vx, (4.26) where X E Stkl. Thus the chosen q is indeed the stationary distribution of GA/WI with C = [l lk]. To show that the GA converges in one generation, we observe that (4.27) and so P is its own limiting matrix, by repeated substitution. To show that the random variables Xi, 1 d i s k, have the same marginal distributions, observe that each of these random variables has a marginal distribution at stationarity which is binomially distributed with probability parameter the unconditional l/k, i is given by probability of obtaining i.e., at stationarity, j of solution Pr[Xi=j]=(r)($)i(l-+)P-j, t=1,2,... (4.28) (by use of (4.6)) and this holds for all 1~ i s k. Notice that, since X1 + X2 + . . . + X, = N, VX E S’kl, only k - 1 of the given random variables are independent [ll], the proof. as claimed, and this completes 0 Again, an analogous result holds for model (4.16), for GA/WI with mutation the algorithm with the previous crossover operator of both parents. We describe D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 317 since search” implications for the parameterisation choice as “random the random variables Xi, 1 s i s k, are all identically distributed at ail times during the search (since the algorithm converges i.e., there is no selection bias towards any solution based on cost or immediately), this result In fact, there are other choices for C (and n) which provide otherwise. also; we sought only to prove an existence result for the special case. The above and solution encoding result has important schemes of Genetic Algorithms with respect of crossover. Essentially, GA/WI-type Genetic Algorithms which do not relate the probability to any of the properties of the given parents of child production under cro~over thus, are degenerate we strongly conjecture success of binary-encoded Genetic Algorithms depends to a certain extent on the properties of the binary encoding scheme. In practical terms, the binary encoding scheme for solutions to (multidimensional) In the next section, we extract information from the model (4.15) which also provides a measure of crossover bias with respect to the search for optimal solutions; reason for the observed to the choice of crossover operators. algorithms with respect to the implementation that a fundamental search algorithms. the degeneration of GA/WI-type automatically prevents random GAS 4.4.3. Long run approximation result We now present a general result for GA/WI, where mutation of only one is carried out (4.15). As before, analogous results exist for the case where (4.16). To proceed, we formulate prop- parent mutation of both parents definitions of certain parameters of GA/WI, which capture erties of these operators. is carried out fundamental Definition 4.10. Let 0, = min Cbd,, Vl s b s d G k, 16 t s k. Thus, 0, is the minimum component of the vector which is the tth column of C. Note that f3, may vary across columns of C (solutions). Definition 4.11. Let E, = max Cbd,* Vl s b d d s k, 1 s t d k. Thus, E, is the maximum component of the vector which is the tth column of C. Note that E, may also vary across columns of C (solutions). Definition 4.12. Let py be the long run expected numbers of solution population, distribution q where 1 s t G k. t in the the expected value of random variable X, within the stationary i.e., Definition 4.13. Let e be a matrix which rows store the population vectors in the same order in which they index P and q, so that e is of size I.Slkll x IsI. Then e, is a vector containing X, of solution t across the populations. With guarantee these definitions, we state and prove the following approximation for GA/ WI with mutation of one parent. 318 D. Reynolds, J. Gomatam / Artijicial Intelligence 8.2 (1996) 303-330 Theorem 4.14. For GAIWI, with mutation of one parent only (4.15) and with 77 > 0, the following holds: N8,s+Ne,. (4.29) Proof. By definition of multivariate distribution the expected [ 11,121, value of a random variable within a a, = ,& [ N! YI!“‘Y,!i=l I? (P .)‘T x1 Ix,S[kl, 1 (using the fact that q is a stationary distribution expected value of the multinomial distribution this gives (4.30) for P). By the formula for the p;=N c XE.s[~l (4.31) the parameters By substituting so that the result follows by simple substitution of the given 0, and E, into (4.31). from Proposition 4.9, we see that in these cases the bounds are exact, i.e., they return to; = N/k, as expected. Again, this justifies since in the long run the use of the term “random search” within that proposition, we expect equal numbers of all solutions within the population. Note that an analogous result holds for model (4.16). guarantee Therefore, algorithms can be used this long run approximation to analyse certain cases of crossover together with a given population size; it can be seen that the lower bound on pr increases in value as either the population size N becomes larger (for 19, > 0) or 0, increases, and the upper bound on y;” decreases as either size or E, decreases; neither of these facts is intuitively obvious the population from the definition of GA/WI-type in Section 2. Thus, these bounds the existence of crossover bias within GAS, since the bounds given highlight of the costs of solutions. The existence of this bias is of above are independent importance fundamental via GAS, since for a given problem k is generally very large and the costs f are not known optimisation lower cost the existence of crossover bias, for example beforehand; scheme and choice of crossover solutions operator), is generally undesirable. is that these bounds do not depend on any particular Another i.e., they may prove useful for the analysis of non-binary representation encoding is not immediately apparent (depending on the given encoding towards scheme, schemes, where [6,10]. for example important point the choice of crossover operator in terms of optimisation lower costs solutions towards Finally, we note that we are justified in calculating the expected values of the D. Reynolds, J. Gomatam I Artijicial Intelligence 82 (1996) 303-330 319 stationary Theorem 4.8). distribution, since, the stochastic process converges in limit (by 5. Explicit stochastic model for GA/WO(N, s, f, roulette wheel, mutation, crossover) We now proceed to vector-indexed matrix multiplication important the size of the state-space for convergence to formulate a stochastic model for GA/WO; we proceed at a the resultant model is of a slightly faster pace than for GA/WI, partly because simpler form than for the latter, and partly because some analogous concepts with respect etc. need not be made here, for results for GA/WO-type Genetic Algorithms with brevity. We present sufficient to respect in limit of these algorithms, and a special case analysis conditions which underpins rates in performance of the algorithm with respect to the discovery cause a degradation results which show of higher fitness solutions and GA/WI-type Genetic Algorithms; we the relationship that they possess show that GA/WI and GA/W0 differing search prop- the order in which erties); finally, we show that for algorithms such as GA/WO, the solutions are stored within the population affects the search fundamentally dynamics of the algorithm. transition probability matrices results observed experimentally, possess differing state-spaces, in that excessive mutation [6,10]. We also present between GA/WO- through which they search, important therefore differing (and 5.1. Definitions of GAI WO statesloperators In GA/WO, so that each each of the genetic operators acts upon the population to GA/WI) a new population. since is applied singly to specific locations, (as opposed produces operators, (mutation assume that the solutions are stored within the population the GA implemented GA/ WO; separately is a stochastic process which the mutation and crossover the population crossover pairwise) we merely in list-like fashion, as in in [6]. Thus, we introduce new definitions for the states of in effect for they are effected locations within In particular, to specific Definition 5.1. Let contained in the population of GA/W0 i = (iI, . . . , iN)r store the order in which the solutions are at time t, where 1 s i, s k, 16 m s N. Thus, every component of the GA/W0 state vectors is some solution (whereas every component of the GA/ WI state vectors counts some solution). Definition 5.2. Let S”N1 = {i = (iI, . . . , i,): 1 s i, s k, 1 =S m s N}. Thus, Sf’N1 is the set consisting of all valid populations of GA/WO. These definitions lead to: 320 D. Reynolds, J. Gomatam I Artijicial Intelligence 82 (1996) 303-330 Proposition 5.3. GA/ WO with population size N, operating on a solution space of size IsI = k searches a state-space of size ISf’N1j, where Proof. The total number of population number of distinct permutations of the population states of GA/W0 (5.1) is given by the total states of GA/WI, i.e., by (5.2) ISr(N]I = kN . x2,,, (’ ’ since, every state vector X E S Ikl of GA/ WI will have the bracketed distinct corresponding states; given in [l, p. 491. Cl permutations, which, within GA/WO, then the result (5.1) follows from a modification of the well-known term in (5.2) are all distinct result Thus, we present the following inequality between GA/WI and GA/WO: Theorem 5.4. Let ISCkll be given by (4.3), and ISf’N’J by (5.1). Then IS”NII > IS’kll for k>l and N>l. Proof. Observe that Nk > k + N - 1 for k,N > 1. Thus, k.2k. ..Nk>k(k+l)*..(k+N-1), so that IsdN11 =kN> k(k+ l)-$+N-l) = ,pq, which completes the proof. 0 (5.3) (5.4) Note larger optimisation, to nontrivial to be strictly that k > 1 corresponds the number of states of GA/W0 and N > 1 to a is shown nontrivial Genetic Algorithm. Thus, that of GA/ WI. This fact has been previously here some authors give the left-hand side of (5.4) as the ignored within the literature; size of the Genetic Algorithm state-space [17]; others give the right-hand side [7]. Here, we have shown which Genetic Algorithms possess which state-space, with the state-space of GA/ respect WO being strictly larger than that of GA/WI. to the implementation of the genetic operators; than As is evident from the definitions of GA/WI crossover probability matrix is insufficient the GA/W0 Therefore, we introduce: crossover operator (which produces and GA/WO, the single-child to describe the stochastic properties of two children from two parents). Definition 5.5. Let C,,,,, be a row-stochastic crossover probability matrix, i.e., D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 321 Ii Ii Cob,,, =l Vl~Lz~b~k, g=l h=g the action of crossover that stores under define Cij,ij > 0 (since whether or not two solutions are combined probabilistic the probability with which solutions a, b will produce solutions g, h for 1 s a =Z b G k, 1 s g <h c k. Moreover, we is the result of a test [6, lo]). Note that we force both the parent and child solutions in an ordered pair, which again forces uniqueness of reference. The 2-parent, 2-child crossover probability matrix has the following useful property. to be gathered Proposition 5.6. i g=l i C,,.,,=i h=g $ Cab,hg=l Vlsasbsk. h=l g=t Proof. Settingm=k-g+l, lsg<k, n=k-h+l, lch=sgck, gives g=l h=l = il gg ‘&,h =l Vlca<bsk, _ since the middle sum is merely a rearrangement 0 completes the proof. of the outer two sums, and this This then gives the following useful property: Proposition 5.7. fi g=l i h=g+l c,,,,, = i “cl c,,,,, Vl<a<bsk. g=l h=l Proof. Each sum the term excluding in the above is just the sums written in Proposition 5.6, and this completes the proof. 0 With these definitions and results in place, which describe in simple form the stochasticity of the GA/ WO croSSover operator, we formulate a definition which (since both use relates the selection operator of GA/WI to that of GA/W0 322 D. Reynolds, J. Gomatam I ArtiJicial Intelligence 82 (1996) 303-330 sampling with replacement transition matrix for the selection operator of GA/WO. selection operators). It is then used to formulate Definition 5.8. Let (Xi b)r store the numbers of solutions b within the population of GA/W0 at time t,‘i.e., Xi,,=de3m, ,..., md, m,,#m, Vlsy#zsd s.t. i,l = * . . = imd = b . a i Thus, (Xi,l, . . . , Xi,k) is a many-to-one mapping from the states of GA/W0 the states of GA/WI; within i = (iI, . . . , iN) of GA/W0 counting vector tion 4.2 can represent to i,, 1 s a s N, so that each (i1, . . . , iN) E SfIN1 has a unique (X,,r , . . . , Xi,k) but any given (Xi, X,, . . . , X,) E S’kl in Defini- the total occurrences of solutions it counts 0 x different (iI, . . . , iN) E TIN1 vectors [ 11. (5.5) 5.2. Stochastic model for GAIWO(N, s, f, roulette wheel, mutation, crossover) We present in this section a stochastic model for GA/WO; we begin by presenting a stochastic model for the selection operator. An important point to be j E S’lN1 which have the same counting vector Y E Slkl made is that populations from i E S”N1, because within the will have the same probability of production GA/W0 is fitness selection operator in which unimportant they are placed within j E Sf’N1 is important, by Definition 5.2, and so different due to the of j E S’lN1 thus have equal probability of occurrence, permutations sampling with replacement between solution b within population roulette-wheel the selection events, as in GA/WI). Therefore, (which implies independence the relative the order in which the solutions are selected their ordering within population i E S’lN1 is given by i); only the order fitness of operator (i.e., lsbck, so that Fij = Pr{(jl, j2, . . . , j,,,) 1 (iI, i,, . . . , iN)} = n r:f b=l k (5.6) (5.7) is the transition matrix for the selection operator of GA/WO, where i, j E SrLN1 and where X, Y E Slkl are the counting vectors for populations ly. i and j respective- The transition matrix for the GA/W0 mutation operator is of a simple form; D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 323 since mutation it also transforms population is carried out independently i to population, in list-like manner j, i,j E S”N1, to the population, N Mij = Pr{(jl, . . . , j,) I (il, . . . , iN)) = n Vidjd . (5.8) d=l The construction of the transition matrix for the croSSover operator of GA/W0 therefore we make a definition which relates crossover probabilities is non-trivial; to the C matrix; Definition 5.9. Let C,*,,,, be defined as c* ab,cd = C ab,cd, c p=“’ ab,dc, acb, a>b, a ~ b , c bn,dc, 1 a>b, csd, csd, c>d, c>d, cd g ives the appropriate value within C for crossover between arbitrarily c,*, i.e.y labelled ‘solutions. Since the crossover operator of GA/W0 transforms population j, i,jES’IN’ the crossover probabilities by the creation of solutions pairwise, the following equation to the child solutions placed within j E S”N1, i to population relates Pr{(j2d-I, hd) = t&f3 h, 1 (i2d-ly &d) = cay b)) = Pr{( j2d-1y j2d) = thy 8) 1 @2d-1? kd) = ca2 b)) ) (5.9) where 1 <d s N/2, the relevant above (5.9) is an ordered pair of solutions. Thus, we define: i.e., either ordering of the new pair of child solutions within locations of j is stipulated as equally likely, where each term in the Definition 5.10. Let f(x, y) be defined as Note that f is symmetric about x = y. Thus, with all necessary definitions in place, observe that Pr{(jZd-l? j2d) = k, h, 1 (i2d-ly &d) = CUT b)) = WabT gh n (j2d-1? hd> = k, h)l =f(g, h)C:b,,, 3 (5.10) where each term in brackets is an ordered pair. Thus, the general formula for the 324 D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 conditional probability of obtaining is ( j2d_1, jZd) from (i,,_, , i,,) under crossover Pr{(j2d-l 9 j2d) I Ci*d-1 7 i2d)l =ftj2d-l) j2d)Cr*,d_li2d,j2d_,i,, ) (5.11) 1 d d d N/2. Denoting operator, we thus have by Q the transition matrix for the given crossover = I1 VG2d-19 d=l j2d~cr*2_,~2d,j2d_lj,dl 3 (5.12) since the pair-wise crossover events are independent of one another. To complete the construction of Q, we state and prove the following: Proposition 5.11. Let Q be defined as in (5.12). Then Q is a row-stochastic matrix, i.e., Proof. Observe that c jcs'[Nl Q, = i i jl=l jz=l - - - 5 [ ?f Mj2d-17 i,,,C~d_l~2d,j2d_lj2dl] jN'l d=l j,=l j2=1 i jN_l=l i K~N-I~ jN)C~_liN,jN_ljN j,=l 3 (5.13) and so the general term is 5 j2d--l=l i &=l .f(j2d-1y j2d)CI*,,_,i,,,jzd_1iZd ZZ- : i_ _i 12d-1-1 12d-12d-l+l ‘2d-li2d)j2dj2d-1 k + c Ci2d_li2dTj2d-lj2d-l j2d-1’1 (via the properties of f(x, v) and assuming i,,_, d i,, without loss of generality, since the sum is overj components), where 1 s d d N/2. By Proposition 5.7, the first two sums are equal, and, added to the third sum, this gives D. Reynolds, J. Gomatam ! Artificia2 Intelligence 82 (1996) 303-330 325 by Definition 5.5. Since d was arbitrarily chosen, product of l’s, and so Q is indeed row-stochastic. (5.12) is shown to be a finite 0 that F is easily shown to be row-stochastic using the properties of the in a the overall and the above analysis for Q can be repeated it is also row-stochastic. Thus, to show that distribution, Note multinomial simpler form for M, stochastic model for GA/W0 is P,=(F.M.Q),= 2 C (KbMb,)Q, &S’INl bEs’[Nl ( vi> j E ‘IiN 7 (5.14) > to predict (i.e., (4.15) and (4.16)) and GA/W0 where F, M and Q are row-stochastic matrices defined in (5.7), (5.8) and (5.12), is used throughout. Thus, it can be seen and vector-indexed matrix multiplication that the transition matrices of GA/WI (i.e. (5.14)) differ; generally, is of higher order than the transition matrix of GA/W0 that of GA/WI. Since knowledge of the transition matrix of a stochastic process is the behaviour of that process at all time steps, given any sufficient [15], this initial probability of the corresponding Markov Chain implies the in a concise form. models Notice also that distinct orderings of the solutions with i E Sf’N1 are essentially transition probabilities differing states of GA/ WO, with corresponding within the (5.14); populations of GA/W0 that GA/W0 (4.15) and (4.16) and (5.14) capture the search dynamics of this algorithm. are quite distinct search algorithms; the solutions are stored within this distinction and GA/WI distribution determines the order in which differing thus, 5.3. Analysis of model of GAIWO(N, s, f, roulette wheel, mutation, crossover) In this section we present analyses of the model given in in the usual way is implemented also possesses a stationary distribution; we then show that, if two fundamental (5.14). We show that, if the mutation operator [6, 171 that GA/W0 each row of the mutation probability matrix is the discrete uniform distribution over GA/ WO converges the search conducted search. the set of solutions s = {si, s2, . . . , sk}, to cost-independent immediately then by 5.3.1. Parameter choice for convergence We proceed to present a similar result to that of Section 4.4.1, in that we derive towards a stationary in limit sufficient distribution. We first formulate definitions essential for GA/W0 to converge conditions to the method of proof: Definition 5.12. Let fmin = min{ fi, . . . , f,} > 0. 326 D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 Thus, fmin is equal to the cost of the solution(s) with lowest cost. Definition 5.13. Let f,,, = max{fr , . . . , fk} > 0. Thus, fm,, is equal to the cost of the solution(s) with largest cost. Definition 5.14. Let r)min = mini,j [nij]. Thus, nmin is the smallest entry in the mutation probability matrix. It is greater than zero when n > 0. Definition 5.15. Let Cmin = minisi [C,,,] > 0. Thus, Cmin is the smallest probability crossover operator. It is greater GA/W0 that a pair of parents is retained under the than zero by Definition 5.5. 5.16. GAIWO with 77 > 0, and C as defined, Theorem towards a stationary probability distribution, q’, where qj is strictly positive for all i, where i is a valid population state of the algorithm, converges i.e., (5.15) Also, convergence takes place at least geometrically, i.e., there exists 0 < r < 1 s.t. Pi’ = qj + eg’ , where le$‘l S rf . Finally, q’ is independent of the initial choice of population i(,,). Proof. Observe that Pij = (F . M + Q), 2 FiiMijQ jj Vi, j E StLN1 , (5.16) (5.17) (5.18) where vector-indexed multiplication Definitions 4.3 and 4.4. Now is carried out in the general sense of b=l so rxb afminl(Nfmax) that VlSbck fitness than all other solutions, and the denominator with maximum fitness; thus, and VXESlkl, h w ere at since the numerator of the given fraction least one component of i has value b, is smaller in is the cost of the population D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 327 Fii = fi b=l (since n > 0) Q,z- (+)“‘*>O VjE,YLN1 (5.19) (5.20) (5.21) (by definition of Q), which side of right-hand and aperiodic, irreducible (5.18) together the is strictly positive, Vi, j E S”N1. Since P is then the product given on imply that the result follows by use of Theorems 3.3 and 3.4. 5.3.2. Special case the following special case of GA/WO, we show In described shows that, in the case where GA/WI GA/W0 respect to the absence of bias towards cost; however, to parameterise that both algorithms in this paper contain similar degenerate cases; thus, the following result as in Proposition 4.9, and is parameterised that both algorithms have identical search properties with the choice of which operator is different. as below, Theorem GAIWO 5.17. Let 7 = [l/k],,,. is Then the resultant stationary distribution for qj=s C Q. aJ ’ jES”N’. tZES’[NJ Proof. By substitution of r] into (5.8), it follows that 1 Mij=s Vi,jES”N’. Thus, by substitution into (5.14), PO=+ Q, ViESrEN’, c .ES”N’ (5.22) (5.23) (5.24) Vi,j E Sf’N’ since F is row-stochastic. Substitution of (5.22) equation Q that into the invariant (3.8) with P given by (5.24) obtains the result, observing by definition of qj +e,>O V~EES”~‘. The corresponding because P in (5.24) has identical rows, as does P of Proposition 4.9. result for immediate convergence follows; essentially, 0 (5.25) this is Within a relaxed theoretical that GA/WI degenerates result framework of discussion, we see the surprising immediately search for “com- to “fitness-free” 328 D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 to plete” crossover regardless of mutation, and GA/ WO degenerates “fitness-free” search for “complete” mutation regardless of crossover. It is worthy of note that q above in (5.22) is discrete uniform (= [l/Z?] over S”N’) in the case where no crossover actually takes place (i.e., crossover parameter p, = 0 in [lo]), identity matrix I. Again, as for GA/WI, since Q in this case is the ]S’lN1 there may be other parameterizations for GA/W0 which produce cost-indepen- dent search; as in the case for the former, we sought to prove an existence result here. immediately 1 x /S”N’I (which measures crossover bias) The extension of the approximation guarantee is currently being for GA/WI, given in Section 4.4.3 to GA/WO-type developed by the authors, and will be reported it should be pointed out that the distributions given in the rows of the matrix defined by into this (5.14) are non-standard problem an element of intractability. probability distributions, in a future publication; and thus introduce algorithms 6. Conclusions and future directions In this paper we have described a number of models for GAS, which were then used to analyse the convergence properties of the given algorithms. We defined, in and crossover operators which terms of stochastic matrices, genetic mutation in such a way that captured the resultant their essential stochastic properties of solutions, yet yielded sufficient models were independent of the representation distinction between GAS conditions for convergence. We made an important in terms from populations which sample solutions with and without replacement of the size of the state-space of both algorithms. We presented, via definitions of stochastic models for the two classes of algorithm. We then genetic operators, analysed particular cases of genetic search, showing sufficient conditions for both classes for degeneracy guarantee indicates solutions. Future an approximation for optimisation via sampling with replacement GAS; this guarantee towards given the existence of bias within the GA crossover operator theoretical work will concentrate on the presentation search, and presented to randomised important than represents for both classes of algorithm. The extension stationary distributions of GAS with parameters other special case analyses, estimation of the first moments of the stationary distributions of GA/WI-type GAS to higher moments important estimation of these moments stationary distribution of the algorithms, and provides guidance with respect algorithm parameterisation, possible crossover probability matrices. Other important work concerns phenomenon as “premature [3,6, lo], together with the rate of convergence of Genetic Algorithms their stationary distributions investigated by the authors, and will be reported theoretical and practical work; the is significant, due to the multivariate nature of the to as shown in Sections 4.4.2 and 4.4.3. It may also be these moments using particular cost functions, mutation and the analysis of the of Genetic Algorithms” towards this is currently being in a future publication. These [18], by use of these models; convergence to estimate known of the those used in our the of D. Reynolds, J. Gomatam I Artijicial Intelligence 82 (1996) 303-330 329 tasks represent aspects of optimisation via Genetic Algorithms. important problems with respect to the theoretical and practical Acknowledgements Both authors would like to thank Dr. C.N.B. Martin, Clean Energy Systems, in this work. David National Engineering Laboratory, Glasgow for his interest Reynolds for financial support to Glasgow Caledonian University during this work. He would also like to express thanks to members of staff of the Department of Mathematics, Glasgow Caledonian University for encouragement. is grateful Appendix A. Example of crossover probability matrix, binary string encoding scheme of length 2 Example A.1 (Binary string uniform crossover [3,16]). This can be implemented by simultaneously moving along both parents and selecting a bit from either parent with probability in this case, for strings of length 2, the crossover probability matrix is given in Table A.l. l/2. Thus, Table A.1 Uniform crossover probability matrix for binary string (L = 2) GA 00 1 0.5 0.5 0.25 0 0.25 0 0 0 0 01 0 0.5 0 0.25 1 0.25 0.5 0 0 0 10 0 0 0.5 0.25 0 0.25 0 1 0.5 0 11 0 0 0 0.25 0 0.25 0.5 0 0.5 1 c ‘,,rn 00 00 00 01 00 10 0011 0101 01 10 01 11 10 10 10 11 1111 References [l] I. Anderson, A First Course in Combinatorial Mathematics (OUP, Oxford, 1985). [2] D.L. Battle and M.D. Vose, Isomorphisms of genetic algorithms, Artif. Intell. 60 (1993) 155-165. [3] D. Beasley, D.R. Bull and R.R. Martin, An overview of Genetic Algorithms: Part 2, research topics, Univ. Comput. 15 (1993) 170-181. [4] R.N. Bhattacharya and E.C. Waymire, Stochastic Processes with Applications (Wiley, New York, 1990). [5] E. Cinlar, Introduction to Stochastic Processes (Prentice-Hall, Englewood Cliffs, NJ, 1975). 330 D. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 [6] L. Davis, What is a Genetic Algorithm, in: L. Davis, ed., Handbook of Genetic Algorithms (Van Nostrand Reinhold, New York, 1991) Chapter 1. [7] T.E. Davis and J.C. Principe, A simulated annealing theory for the simple genetic algorithm, in: R.K. Belew and L.B. Booker, eds., Proceedings of the Fourth Conference on Genetic Algorithms, San Mateo, CA (Morgan Kaufmann, San Mateo, CA, 1991) 174-181. [8] A.E. Eiben, E.H.L. Aarts and K.M. Van Hee, Global convergence of genetic algorithms: a Markov chain analysis, in: H.P. Schwefel and R. Manner, eds., Parallel Problem Solving from Nature (Springer, Berlin, 1991) 4-12. like convergence [9] D.E. Goldberg, Finite Markov chain analysis of Genetic Algorithms, ed., Proceedings of the Second International Conference on Genetic Algorithms (Lawrence Erlbaum, Hillsdale, NJ, 1987) l-8. in: J.J. Grefenstette, [lo] D.E. Goldberg, Genetic Algorithms Wesley, Reading, MA, 1989). in Search, Optimisation and Machine Learning (Addison- [ll] A.F. Karr, Probability (Springer-Verlag, New York, 1993). [12] W. Mendenhall, D.D. Wackerly and R.L. Scheaffer, Mathematical Statistics with Applications (Wiley, New York, 1993). [13] H. Mint, Nonnegative Matrices (Wiley, New York, 1988). [14] D.J. Montana, Automated parameter ed., Handbook of Genetic Algorithms tuning for interpretation of synthetic images, in: L. Davis, (Van Nostrand Reinhold, New York, 1991). [15] U. Narayan Bhat, Elements of Applied Stochastic Processes (Wiley, New York, 2nd ed., 1984). and evaluation of an improved [16] J.C. Potts, T.D. Giddens and S.B. Yadav, The development Genetic Algorithm based on migration and artificial selection, IEEE Trans. Syst. Man Cybern. 24 (1) (1993) 73-86. [17] G. Rudolph, Convergence analysis of canonical Genetic Algorithms, IEEE Trans. Neural Net. 5 (1) (1994) 96-101. [18] E. Seneta, Non-negative Matrices and Markov Chains (Springer-Verlag, New York, 2nd ed., 1981). [19] J.H. van Lint and R.M. Wilson, A Course in Combinatorics (CUP, Cambridge, 1993). 