Artificial Intelligence 81 ( 1996) 17-29 Artificial Intelligence Generating hard satisfiability problems * Bart Selman a,*, David G. Mitchell b*l, Hector J. Levesque bv2 a AI Principles Research Department, AT&T Bell Laboratories, Murray Hill, NJ 07974, USA b Department of Computer Science, Vniversiry of Toronto, Toronto, Canada M5S IA4 Received May 1993; revised May 1995 Abstract We report results from large-scale experiments in satisfiability testing. As has been observed by others, testing the satisfiability of random formulas often appears surprisingly easy. Here we show that by using the right distribution of instances, and appropriate parameter values, it is possible to generate random formulas that are hard, that is, for which satisfiability testing is quite difficult. Our results provide a benchmark for the evaluation of satisfiability testing procedures. Keywords: Satisfiability; Random problems: Phase transitions; 4.3; Benchmarks; Empirical study 1. Introduction Many computational tasks of interest to AI, to the extent that they can be precisely characterized at all, can be shown to be NP-hard in their most general form. However, there is fundamental disagreement, at least within the AI community, about the impli- cations of this. It is claimed on the one hand that since the performance of algorithms designed to solve NP-hard tasks degrades rapidly with small increases in input size, something will need to be given up to obtain acceptable behavior. On the other hand, it is argued that this analysis is irrelevant to AI since it is based on worst-case scenarios, * An earlier version of this paper * Corresponding ’ Work carried out while visiting AT&T Bell Laboratories. author. Telephone: [ 291 was presented at AAAI-92. (908) 582-2221. E-mail: selman@research.att.com. E-mail: mitchell@ai.toronto.edu. 2 Fellow of the Canadian Institute for Advanced Research. Supported in part by a grant from the Natural Sciences and Engineering Research Council of Canada. E-mail: hector@ai.toronto.edu. 0004-3702/96/.$15.00 SSDIOOO4-3702(9.5)00045-3 @ 1996 Elsevier Science B.V. All rights reserved 18 B. Sehan et al./Art$cial Intelligence 81 (1996) 17-29 and that what is really needed is a better understanding “on average”. of how these procedures perform The first computational task shown to be NP-hard, by Cook [9], was propositional that makes tasks have been shown to be NP-hard by proving true according the formula for SAT. Unlike many other NP-hard or SAT: Given a formula of the propositional to its variables Subsequent satisfiability assignment interpretation. least as hard as SAT. Roughly, a task is NP-hard a good algorithm SAT is of special concern (i.e., given a collection of base facts 2, a sentence not satisfiable). Many other forms of reasoning, planning these usually fact that SAT is a fundamental is essential. in AI applications require much more than the propositional and image interpretation, to AI because of its direct relationship calculus, decide if there is an to the usual rules of they are at for it would entail tasks (see [ 171 for a catalogue) , to deductive reasoning if a good algorithm (Y may be deduced iff .Z U {TX} is including default reasoning, diagnosis, also make direct appeal to satisfiability. The fact that the calculus that work well task, and that developing SAT procedures simply highlights We might ask when it is reasonable and when we should settle for something always a result of strange encodings in answering on the expected difficulty of SAT (although time being, we must rely largely on empirical such questions tailored to use a sound and complete procedure for SAT, less. Do hard cases come up often, or are they for some specific purpose? One difficulty results It seems that, at least for the is that there appear to be few applicable analytical see below). results. A number of papers (some discussed below) have claimed that the difficulty of SAT on randomly generated problems result by Goldberg polynomial in practice, but at first blush worst cases. [20] suggests in that SAT can be readily time. This does not settle the question of how well the methods will work to AI than contrived solved “on average” to be more relevant it does appear is not so daunting. For example, an often-quoted of instances. the Goldberg The big problem assume a distribution [ 141 refuted choice of distribution. is easy, but that he had used a distribution with a preponderance is, from the space of all problem no hard cases. Nevertheless, is that to examine how well a procedure does on average one must Indeed, as we will discuss below, Franc0 and Paul1 of the It is not that Goldberg had a clever algorithm, or that the problem of easy instances. That in a way that produced almost that it was a direct consequence to appear purporting result by showing papers continue to empirically they sampled instances, efficacy of some new procedure, presenting propositional given using easy problems the danger of biasing (even data suggesting variables-can just that very large satisfiability be solved. How are we to evaluate the sample if unwittingly)? to suit the procedure but using this distribution problems-with (e.g., the demonstrate [22,241), or thousands of results, in question, or of simply these empirical In this paper, we present empirical results showing that random fiability can be generated particular SAT procedure, robustness of the procedures we develop, we will want to consider on a wide spectrum of examples. While in such a way that easy and hard sets of instances anyway) are predictable in advance. the easy cases we have found can be s01ved by their performance instances of satis- (for a the If we care about B. Selman et al./Artificial Intelligence 81 (1996) 17-29 19 Procedure DP Given a set of clauses 2 defined over a set of variables V: If 2 contains a unit clause C, assign to the variable men- the truth value which satisfies C, and return the result of calling DP on If .E is empty, return “satisfiable”. If _E contains an empty clause, return “unsatisfiable”. Unit-Clause Rule: tioned the simplified Splitting Rule: Select from V a variable u which has not been assigned a truth If this call formula. value. Assign returns “satisfiable”, set u to the opposite value, and return it a value, and call DP on the simplified then return “satisfiable”. Otherwise, the result of calling DP on the re-simplified formula. formula. Fig. 1. The DP procedure. almost any reasonable method, from the losers. Thus, our data is presented as challenging of SAT procedures for example). The SAT procedure we used for our tests is the Davis-Putnam (see Selman et al. [ 3 1,32,34], it is the hard cases ultimately that separate test material the winners for developers procedure, which we [ 16,351, case of resolution the most widely used general this was a good choice for two reasons: First, it is equivalent reasoning in AI; second, until recently, almost all empirical work on SAT testing has used that describe below. We believe to a particular method one or another refinement of this method, which facilitates comparison. We suspect our results on hard and easy areas generalize is an extension remain [29]. The primary observations This paper larger sample sizes (10,000 and arguments formulas per point, rather than 500), which eliminates most of the sampling error and so gives a clearer picture of the behaviors of interest. We have added data in Section 3 on the average cost than just one), truth assignments. We have also improved our and have data comparing formula models been extended or clarified, and some updated references have been added, especially to theoretical the median number of satisfying different the same, but we have used much (Section 4). Some discussions to all SAT procedures. to find all satisfying truth assignments of a previous random results. (rather report is organized as follows. In Section 2 we describe the Davis- in Section 3 we study its performance on one distribution of it produces computationally the fixed clause length model. We show that with the right choice of parameter In Section 4 we consider challenging SAT instances. in the testing procedures. We briefly review related work in Section the constant density model, and argue that it is not useful The rest of the paper and Putnam procedure formulas, values, a second distribution, evaluation of satisfiability 5, and summarize our results in Section 6. 2. The Davis-Putnam procedure One of the most widely used methods is the [ 121. Our procedure, which we refer to as DP, is the splitting for propositional satisfiability testing Davis-Putnam procedure 20 B. Selman et al./Art$cial Intelligence 81 (1996) 17-29 variant of the Davis-Putnam procedure as described in [ 111, but without the pure literal rule. (The pure literal rule is: if a literal p occurs in a formula, but its negation does not, then p can be immediately assigned the value true.) DP is sketched in Fig. 1. It takes as input a set of clauses _Z over a set of variables Y and returns either “satisfiable” or “unsatisfiable.” (A clause is a disjunction of literals. A set of clauses represents a conjunction of disjunctions, i.e., a formula in conjunctive normal form (CNF) .) DP performs a backtracking depth-first search in the space of all truth assignments, incrementally assigning truth values to variables and simplifying the formula. If no new variable can be assigned a value without producing an empty clause, it backtracks by changing a previously made variable assignment. In our implementation, variables are given an arbitrary ordering, and in the “splitting” step we choose the next variable according to this ordering, and set it first to true. The performance of simple backtracking is greatly improved by employing the unit clause rule: Whenever a clause containing a single literal arises, the variable occurring in that clause is immediately assigned the appropriate truth value. The formula is then simplified, which may lead to new unit clauses, and so on. This process of unit propagation can be executed in time linear in the total number of literals. 3. The fixed clause length model In this section, we study formulas generated using the fixed clause length model, which we call random K-SAT. There are three parameters: the number of variables N, the number of literals per clause K, and the number of clauses M. To keep the volume of data presented manageable and yet give a detailed picture, we limit our attention to formulas with K = 3, that is, random 3-SAT. (Some data on other values of K can be found in [ 26,28,33] .) For a given N and M, an instance of random 3-SAT is produced by randomly generating M clauses of length 3. Each clause is produced by randomly choosing three distinct variables from the set of N available, and negating each with probability 0.5. (Note that this method of generation allows duplicate clauses in a formula, so that strictly speaking such formulas are sequences of clauses, not sets. However, as N gets large, duplicates will become rare because we generally select only a linear number of clauses. Most analytical work on random K-SAT uses this same model. ) We now consider the performance of DP on such random formulas. Fig. 2 shows the total number of recursive calls by DP to find one satisfying assignment, or to determine that the formula is unsatisfiable. There are three curves, for formulas with 20,40, and 50 variables. Along the horizontal axis is the ratio of clauses to variables (i.e., the number of clauses normalized through division by the number of variables). Each data point gives the median number of calls for a random sample of 10,000 formulas. We use medians instead of means here because the means of the number of calls are heavily influenced by a very small number of extremely large values. Although they occur very rarely, these values are large enough to make the variance be as large as the mean. But our current interest is what the “bulk” of instances from the distribution are like, not the unusual or extreme cases. As the median is more robust in the presence of B. Sehnun et al. /Art$icial Intelligence 81 (1996) 17-29 21 20-variable 40-variable 50-variable formulas * -I- formulas -Sk formulas Number gfIJ calls 2500 2000 1500 1000 500 0 2 3 4 5 6 7 8 Ratio of clauses-to-variables Fig. 2. Median number of recursive DP calls for random 3-SAT formulas, as a function of the ratio of clauses to variables. such “outliers” [ 11, it appears to be a more informative statistic for current purposes. 3 In Fig. 2, we see the following pattern: For formulas that are either relatively short or relatively long, DP finishes quickly, but the formulas of medium length take much longer. Since formulas with few clauses are under-consrruined and have many satisfying assignments, an assignment is likely to be found early in the search. Formulas with very many clauses are over-constrained (and usually unsatisfiable), so contradictions are found easily, and a full search can be completed quickly. Finally, formulas in between are much harder because they have relatively few (if any) satisfying assignments, but the empty clause will only be generated after assigning values to many variables, resulting in a deep search tree. Similar under- and over-constrained areas have been found for random instances of other NP-complete problems [ 8,361. The curves in Fig. 2 are for all formulas of a given size, that is they are composites of satisfiable and unsatisfiable subsets. In Fig. 3 the median number of calls for 50-variable formulas is factored into satisfiable and unsatisfiable cases, showing that the two sets are quite different. The extremely rare unsatisfiable short formulas are very hard, whereas the rare long satisfiable formulas remain moderately difficult. Thus, the easy parts of the composite distribution appear to be a consequence of a relative abundance of short satisfiable formulas or long unsatisfiable ones. To understand the hard area in terms of the likelihood of satisfiability, we experimen- tally determined the probability that a random 50-variable instance is satisfiable (Fig. 3 A reasonable question to ask is how big a sample would be required to get a good estimate of the mean. Because of the potentially exponential nature of the problem, as we increase the sample size, we may continue to find ever larger (but ever rarer) samples that could place the mean anywhere [ 18,331. 22 B. Selman et al./ArrQicial Intelligence 81 (1996) 17-29 Number bfP calls 2000 0 2 4 3 5 Ratio of clauses-to-variables 6 7 8 Fig. 3. Median DP calls for 50-variable random 3-SAT as a function of the ratio of clauses to variables. Probability 1 0.8 0.6 0.4 0 2 4 3 5 Ratio of clauses-to-variables 6 7 8 Fig. 4. Probability of satisfiability of 50-variable formulas, as a function of the ratio of clauses to variables. the peak on our curve for number 4). There is a remarkable of recursive is about 0.5. The main empirical conclusion we draw from this is that the hardest area for satisjiability is near the point where 50% of the formulas are satisjiable. between the probability calls and the point where that a formula correspondence is satisfiable This “50%-satisfiable” point seems to occur at a fixed ratio of the number of clauses is about 4.3 times the number effect for small formulas, and the location gradually occurs at 4.55 for formulas with 20 variables; 4.36 to the number of variables: when the number of clauses of variables. There is a boundary decreases with N: the 50%-point for 50 variables; determined). We conjecture of variables. The peak hardness described point are confirmed by more detailed experiments for the 50-% satisfiable point. These observations [ 10,271. for 100 variables 4.31 and 4.3 for 150 variables (all empirically that this ratio approaches about 4.25 for very large numbers that we have just for DP exhibits the same behavior about the 50%-satisfiable the performance of DP can be improved by using clever variable While heuristics, ter the easy-hard-easy challenging (e.g., for [4,38] ), it seems unlikely pattern. The formulas selection that such heuristics will qualitatively al- to be the most in the hard area appear that they will be for the strategies we have tested, and we conjecture B. Selman et al./Artifcial Intelligence 81 (1996) 17-29 23 bfIJ Number 15000 calls 10000 5000 0 3.5 4 5 4.5 5.5 Ratio of clauses-to-variables 6.5 6 7 7.5 8 Fig. 5. Searching for all assignments. Median DP calls for 50-variable random 3-SAT as a function of the ratio of clauses to variables. every Larrabee Davis-Putnam (heuristic) method. This conjecture is supported by other workers, and Tsuji [ 271, who used a satisfiability procedure quite different for example the from procedure, but found the same hard and easy areas. The phenomenon we see in Fig. 4 is called a threshold phenomenon or a phase to to variables of around 4.3. For and the transition. Our results show a phase the almost all unsatisfiable more discussion phase transition we observe here for K-SAT, see [ 261. transition phase at a ratio of clauses on the relation between general phase from the almost all satisfiable phase transition phenomena the probability of satisfiability is that there is some specific In terms of what is known theoretically about The general case for K > 2 is a challenging the threshold conjecture random 3-SAT, to variables above which the probability of satisfiability it approaches 0. For the case of 2-SAT it has been shown is 1 [ 6,13,19]. recent progress there has been substantial transition. So far, it has been shown that as N gets large the probability of random 3-SAT is satisfiable approaches 0 whenever is less than 3.003 [ 151, and approaches 1 when this ratio is greater than 4.758 can be seen, our empirical than, the best theoretical bounds. for ratio of clauses approaches 1, and below which ratio open problem, although the theoretical bounds on the that an instance to variables [ 251. As results are in agreement with, though much more fine-grained true, and the threshold the ratio of clauses in narrowing insight To get some further into the search performed by DP, we now consider what happens when we let DP search the full space, i.e., we do not stop the procedure as soon as one assignment is found. Fig. 5 gives the total number of recursive calls. (Again, each data point gives the median value of a sample of 10,000 formulas.) We see that the size to variables. of the search space monotonically This is consistent with our expectation the longer and the deeper the search tree. We also it takes before DP will run into a contradiction, formulas, at least on average. see that the search tree is somewhat is found DP This can be intuitively tends relatively long branches assignments. The full search space for under-constrained for decreasing that the fewer clauses explained by the fact that when an assignment in order to satisfy all clauses, so it generates to assign many variables larger for satisfiable ratios of clauses in the formula for satisfying increases 24 B. Selman et al. /Artificial Intelligence 81 (1996) 17-29 le+06 10000 Number of solutions 1000 100 1 3 3.5 4 4.5 5 5.5 6 6.5 Ratio of clauses-to-variables Fig. 6. Median number of satisfying assignments for satisfiable 50-variable random 3-SAT formulas as a function of the ratio of clauses to variables. Note the logarithmic scale. formulas quickly becomes extremely large. For example, at a ratio of 3.3, we have over 200,000 recursive calls for satisfiable instances. Note however that such a large search space is not a problem when searching for a single assignment. Part of the reason for this is that there are many satisfying assignments for the under-constrained formulas. This is shown in Fig. 6. In this figure, we give the median number of satisfying assignments for satisfiable random 3-SAT formulas as a function of the ratio of clauses to variables. (Each data point is based on 10,000 instances.) For example, at a ratio of 3.3, the formulas have around 110,000 satisfying assignments. When searching for a single satisfying assignments, DP may be able to find one early on in the search. 4. The constant-density model We now examine formulas generated using the constant-density model. The model has three parameters: the number of variables N, and number of clauses M as before; but instead of a fixed clause length, clauses are generated by including a variable in a clause with some given probability P, and then negating it with probability 0.5. Large formulas generated this way very often have at least one empty clause and several unit clauses, so that they tend to be either trivially unsatisfiable, or easily shown satisfiable. Thus, the more interesting results are for the modified version in which empty and unit clauses are disallowed. This distribution we call random P-SAT. Analytic results by Franc0 and Paul1 [ 141 suggest that one probably cannot generate computationally challenging instances from this model, and our experiments confirm this prediction. In Fig. 7, we compare the number of recursive DP calls to solve instances of random P-SAT and random 3-SAT with the same number of variables. In this case, we have set the probability P to give an average clause length of 3. Although we see a slight easy-hard-easy pattern (previously noted by Hooker and Fedjki [23]), the hard area is not nearly as pronounced as that for random 3-SAT formulas of similar size, and in absolute terms the random P-SAT formulas are much easier. Note that we are using B. Selman et al./Artifcial Intelligence 81 (1996) 17-29 25 10000 t , / I 1 I , : 25-var. K-SAT +- . 50.~~. K-SAT t . 25-var. P-SAT B- 50-var. P-SAT x - DP calls 1000 : 100 10 2 3 Ratio 4 6 of clauses-to-variables 5 7 8 Fig. 7. Comparison of median DP calls for fixed-length (3-SAT) and constant-density formulas (average clause length 3). with 25 and 50 variables. Table 1 Number of DP calls at hardest point, for fixed-length (K-SAT) and constant-density (P-SAT) formulas, with 25, 50, and 75 variables. The numbers in brackets indicate the number of literals per clause (for the P-SAT model, this is the avenge number of literals per clause) Variables 25 50 7s K-SAT (3) 253 3,683 46,9 15 Formula distribution P-SAT (3) P-SAT (4) 33 68 111 53 157 392 a logarithmic represents much greater difficulty. scale for the number of DP calls, so the greater height of the 3-SAT curve the rate of growth in difficulty of the random 3-SAT formulas the median number of DP calls at the hardest point on the curve Further, Table 1 gives random 3-SAT and random P-SAT (For comparison, we also include here the numbers clause the two random is much higher. for formulas, as a function of the number of variables. for random P-SAT with expected in growth rate for the table clearly shows a large difference length of 4.) Again, It might be argued larger P-SAT formulas could be sufficiently challenging. formula models. that formulas, they are easy in comparison there Some data on larger formulas of this type can be found sized random K-SAT are difficult that as N results formulas. Moreover, a host of analytical gets large, almost all instances of this family of distributions will be easy to solve. Our experimental mode1 is not suitable (see below) strongly suggest in [ 24,281. While indeed results and the analytical results strongly suggest that the constant-density testing procedures. to comparably for evaluating satisfiability 26 B. Selman et al./Artifcial Intelligence 81 (1996) 17-29 5. Related work recently of random the satisfiability results. The main consisted mostly of analytic is a large body of literature on testing formulas, impetus for this that SAT might in fact be solvable, on average, using DP Franc0 and Paul1 [ 141 showed that Goldberg’s There which until research was early results by Goldberg efficiently variant of the positive constant-density model-and formulas were so easy to satisfy that an algorithm which simply tried randomly generated assignments would, with probability in a constant number of guesses. Further analytic of the distribution thus overly optimistic. Goldberg’s results for the constant-density model can be found in [5,30,37]. results were a direct consequence 1, find a satisfying assignment [ 201, which suggested approaching used-a instances, Franc0 and Paul1 [ 141 also investigated with a fixed clause length of 3, and suggested random that for any fixed ratio of clauses truth assignments, probability the ratio of clauses much about the expected its expected approaching to variables an hypothesis we have confirmed experimentally if DP is forced to variables, time will be exponential 1 as the number of variables approaches the performance of DP on random formulas that it might be more useful for generating here. They showed to find all satisfying in the number of variables, with infinity while keeping tell us this result does not directly fixed. Unfortunately, time to find a single assignment. [7] gives further A result of Chvatal and Szemeredi [ 2 11, they showed approaching that any resolution 1 on unsatisfiable insight. Extending a ground- requires ex- random 3-SAT formulas, strategy to variables is held constant. Random 3-SAT formulas approaching 1 whenever [ 251. So, given that DP corresponds the ratio of clauses to a particular resolution to variables it follows that the average time complexity on such formulas are is strategy is the ratio of clauses result by Haken time with probability breaking ponential when unsatisfiable with probability greater than 4.758 as mentioned exponential. above, to variables result applies to variables. Chvatal and Szemeredi’s (fixed) number of variables when varying in the number of variables n. Our results fixed. 4 They show that growth of the DP tree is an exponential This result may appear inconsistent with our claim that over-constrained formulas are pattern for formulas the number of clauses and thus to the case the ratio easy, but it is not. Our results show that there is an easy-hard-easy with a given the ratio of clauses where we increase both the number of variables and clauses, while keeping of clauses function ratios in the hard area grows much faster than in the easy (over-constrained) has been confirmed by recent results for a highly-optimized [ lo]. Experiments Crawford and Auton procedure difference consistently 50,000-clause formulas for area. This variant of DP developed by show that in the hard area, at a ratio of 4.3, their is with 2(“/57). This For example, our DP of lOOO-variable, 1290-clause to determine instances of 3-SAT, even though there are some 300-variable scales with 2(‘1/‘7), whereas at a ratio of 10, the scaling in growth rate has important practical consequences. solve. So, what we have called takes only several seconds that it cannot practically that the exponential the unsatisfiability the “easy area”, suggest is 4 To state this differently, consider Fig. 2. Chvatal and Szemeredi analyze the scaling behavior going in the vertical direction at a given fixed ratio of clauses to variables. B. Selman et al./Art$cial Intelligence 81 (1996) 17-29 21 definitely easy compared to the formulas in the hard area (around the 50%-point), and for lower values of n is often much too easy to be useful as test formulas. For formulas with larger numbers of variables, eventually the truly easy area will occur only at ever higher ratios of clauses to variables. Turning to under-constrained formulas, the behavior of DP can be at least partially explained by the fact that they tend to have many satisfying truth assignments-see Fig. ~--SO that the procedure almost always finds one early in the search. For ratios below 3,003, a simple heuristic algorithm finds satisfying assignments to random 3-SAT with high probability, in polynomial time [ 151. Other analytic results for random 3-SAT are reviewed in [ 3,5,25]. As we mentioned in Section 3, establishing theoretically the exact nature the satisfi- ability transition for random K-SAT, when K > 2, is a challenging open problem. The experimental data suggests that there may be a threshold for satisfiability, at about 4.25 clauses per variable in the case of 3-SAT. Threshold phenomena are common in some other types of combinatoric structures, such as random graphs [ 21. Not only are our experimental results consistent with the analytic results, they also provide a much more fine-grained picture of how 3-SAT behaves in practice. One reason for the limitations of analytic results is the complexity of the analyses required. Another is that they are asymptotic, i.e., they hold in the limit as the number of variables goes to infinity, so they do not necessarily tell us much about formulas that have only a modest number of variables (say, up to a few thousand) as encountered in practice. A valuable contribution was made by Cheeseman et al. [ 81, who explored the hardness of random instances of various NP-complete problems. They observed a similar easy- hard-easy pattern as a function of one or more problem parameters for instances of graph coloring and Hamiltonian circuit. They also give some preliminary results for satisfiability. But, they do not describe exactly how the formulas are generated, or fully specify their test procedure, and their findings are based on relatively small formulas (up to 25 variables). Possibly because of the preliminary nature of their investigation, they observe that they do not know how to generate hard SAT instances except via transformation of hard graph coloring problems, so their instance distribution is almost certainly somewhat different than random 3-SAT. 6. Conclusions There has been much debate in AI on the importance of worst-case complexity results, such as NP-hardness results. In particular, it has been suggested that satisfiability testing might be quite easy on average. We have carried out a detailed study of the average-case difficulty of SAT testing for random formulas. We confirmed previous observations that many instances are quite easy, but we also showed how hard instances can be generated. The fixed clause length model with roughly 4.3 times as many clauses as variables gives computationally challenging instances which have about a 0.5 probability of being satisfiable. Randomly generated formulas with many more or fewer clauses are quite easy. 28 B. Selman et al./Arttj?cial Intelligence 81 (1996) 17-29 Our data provide two important lessons. The first is that the constant-density model is inappropriate for evaluating satisfiability procedures, since it seems to be dominated by easy instances for all values of the parameters. The second is that it is not necessarily the case that generating larger formulas provides harder formulas. For example, our DP can solve lOOO-variable 3000-clause (under-constrained) and lOOO-variable 50000- clause (over-constrained) random 3-SAT instances in seconds. On the other hand, it cannot consistently solve random 3-SAT instances with 300 variables and 1290 clauses. Because random 3-SAT instances can be readily generated, those from the hard area can be very useful in the evaluation of satisfiability testing procedures, and algorithms for related tasks such as Boolean constraint satisfaction. We hope that our results will help prevent further inaccurate or misleading reports on the average-case performance of SAT procedures. Acknowledgements We thank James Crawford and Larry Auton for providing us with their very efficient tableau code, which we modified to obtain a fast implementation of DP. We thank Henry Kautz for many useful discussions and comments, and Fahiem Bacchus for helpful comments on an earlier draft. The second and third authors were funded in part by the Natural Sciences and Engineering Research Council of Canada, and the Institute for Robotics and Intelligent Systems. References [ I 1 R.J. Beckman and R.D. Cook, Outlier . . . . . . . . . s, Technometrics 25 (2) 121 B. Bollobas, Random Graphs (Academic Press, London, 1985). [ 3 1 A. Broder, A. Frieze and E. Upfal, On the satisfiability and maximum satisfiability of random 3-CNF formulas, in: Proceedings Fourth Annual ACM-SIAM Symposium on Discrete Algorithms (1993) 322- 330. (1983) 119-149. 14 1 M. Buro and H. Kleine-Burring, Report on a SAT competition, Technical Report #I 10, Department of Mathematics and Informatics, University of Paderbom, Germany ( 1992). [ 5 I M. Chao and J. France, Probabilistic analysis of a generalization of the unit-clause literal selection I61 I91 I71 181 heuristics for the k satistiability problem, Inform. Sci. 51 (1990) 23-42. V. Chvatai and B. Reed, Mick gets some (the odds are on his side), in: Proceedings FOCS-92 ( 1992) 620-627. V. Chvatal and E. Szemeredi, Many hard examples for resolution, J. ACM 35 (4) ( 1988) 759-208. P. Cheeseman, B. Kanefsky and W.M. Taylor, Where the really hard problems am, in; Proceedings IJCAI-91, Sydney, Australia (1991) 163-169. S.A. Cook, The complexity of theorem-proving procedures, in: Proceedings 3rd Annual ACM Symposium on the Theory of Computing , New York ( 1971) 151-158. J.M. Crawford and L.D. Auton, Experimental results on the cross-over point in satisfiability problems, in: Proceedings AAAI-93, Washington, DC ( 1993). M. Davis, G. Logemann and D. Loveland, A machine program for theorem-proving, Commun. ACM 5 ( 1962) 394-397. M. Davis and H. Putnam, A computing procedure for quantification theory, J. ACM 7 (1960) 201-215. 1121 [ 13 I W.F. de la Vega, On random ZSAT, Manuscript ( 1992). I I4 I J. Franc0 and M. Paull, Probabilistic analysis of the Davis Putnam procedure for solving the satistiability III I 1101 problem, Discrete Appl. Math. 5 (1983) 77-87. B. Sebnan et al./Artificial Intelligence 81 (1996) 17-29 29 [ I5 1 A. Frieze and S. Suen, Analysis of three simple heuristics on a random instance of k-SAT, Manuscript (1992). 1 I6 1 Z. Galil, On the complexity of regular resolution and the Davis-Putnam procedure, Theoret. Comput. Sci. 4 (1977) 23-46. 1 17 1 M.R. Carey and D.S. Johnson, Computers and Intracrability: A Guide to the Theory of NP-Cotnplereness (Freeman, New York, 1979). [ I8 1 I.P. Gent and T. Walsh, E!asy problems are sometimes hard, Artit Intell. 70 (1994) 335-345. [ 19 1 A. Goerdt, A threshold for unsatisfiability, Manuscript ( 1991). I20 1 A. Goldberg, On the complexity of the satisfiability problem, Courant Computer Science Report, No. 16, New York University, New York ( 1979). [ 21 1 A. Haken. The intractability of resolution, Theor. Comput. Sci. 39 ( 1985) 297-308. 122 I J.N. Hooker, Resolution vs. cutting plane solution of inference problems: some computational experience, Uper. Res. Len. 7 (1) ( 1988) i-7. I23 1 J.N. Hooker and C. Fedjki, Branch-and-cut solution of inference problems in propositional logic, Ann. Math. Arr$ Intell. 1 (1990) 123-139. 1241 AI? Kamath, N.K. Karmarker, KG. Ramakrishnan and M.G.C. Resende, Computational experience with an interior point algorithm on the satisliability problem, in: Proceedings Integer Programming and Combinatorial Optimization, Waterloo, Ont. ( 1990) 333-349. I 2.5 I A.P. Kamath, A. Motwani, R. Palem and P Spirakis, Tail bounds for occupancy and the satisfiability threshold conjecture, in: Proceedings FOCS-94 ( 1994). [ 26 I S. Kirkpatrick and B. Selman, Critical behavior in the satisfiability of random Boolean expressions, Science 264 (1994) 1297-1301. 127 1 T. Larrabee and Y. Tsuji, Evidence for a satisfiability threshold for random 3CNF formulas, in: Proceedings AAAI Spring Symposium on AI and NP-hard problems, Palo Alto, CA ( 1993). [ 28 I D.G. Mitchell and H.J. Levesque, Some pitfalls for experimenters with random SAT, Artif: Intell. 81 I I l-125 (this volume). 129 I D.G. Mitchell, B. Selman and H.J. Levesque, Hard and easy distributions of SAT problems, in: Proceedings AAAI-92, San Jose, CA (1992) 459-465. [ 30 I P Purdom, A survey of average time analyses of satisfiability algorithms, J. Inform. Process. 13 (4) (1990). 131 I B. Selman, Stochastic search and phase tmnsitions: Al meets physics, in: Proceedings IJCAI-95, Montreal, Que. ( 1995). 1321 B. Selman, H. Kautz and B. Cohen, Local search strategies for satisfiability testing, in: DIMACS Series in Discrete Marhemarics and Theoretical Computer Science (ACM Press, Providence, RI, 1996); preliminary version in: Proceedings AAAI-94, Seattle, WA (1994) 337-343. I 33 I B. Selman and S. Kirkpatrick, Critical behavior in the computational cost of satisfiability testing, Artif: Intell. 81 ( 1996) 273-295 (this volume). 134 I B. Selman, H.J. Levesque and D.G. Mitchell, GSAT: a new method for solving hard satisfiability problems, in: Proceedings AAAI-92. San Jose, CA ( 1992) 440-446. 135 I A. Vellino, The complexity of automated reasoning, Ph.D. Thesis, Department of Philosophy, University of Toronto, Toronto, Ont. ( 1989). I36 I C.P. Williams and T. Hogg, Using deep structure to locate hard problems, in: Proceedings AAAI-92, San Jose, CA (1992) 472-277. I37 I L.C. WU and C.Y. Tang, Solving the satisfiability problem by using randomized approach, Inform. Process. L.etr. 41 (1992) 187-190. I 38 I R. Zabih and D. McAllester, A rearrangement search strategy for determining propositional satisfiability, in: Proceedings AAAI-88, St. Paul, MN (1988) 155-160. 