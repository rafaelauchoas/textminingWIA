Artificial Intelligence 175 (2011) 2075–2098Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLearning heuristic functions for large state spacesShahab Jabbari Arfaee a, Sandra Zilles b,∗, Robert C. Holte aa University of Alberta, Department of Computing Science, Edmonton, Alberta, Canada T6G 2H8b University of Regina, Department of Computer Science, Regina, Saskatchewan, Canada S4S 0A2a r t i c l ei n f oa b s t r a c tArticle history:Received 19 September 2010Received in revised form 27 July 2011Accepted 1 August 2011Available online 5 August 2011Keywords:Heuristic searchPlanningLearning heuristics∗We investigate the use of machine learning to create effective heuristics for searchor heuristic-search planners such as FF. Our method aims toalgorithms such as IDAgenerate a sequence of heuristics from a given weak heuristic h0 and a set of unsolvedtraining instances using a bootstrapping procedure. The training instances that can besolved using h0 provide training examples for a learning algorithm that produces aheuristic h1 that is expected to be stronger than h0. If h0 is so weak that it cannot solveany of the given instances we use random walks backward from the goal state to createa sequence of successively more difficult training instances starting with ones that areguaranteed to be solvable by h0. The bootstrap process is then repeated using hi in lieu ofhi−1 until a sufficiently strong heuristic is produced. We test this method on the 24-sliding-tile puzzle, the 35-pancake puzzle, Rubik’s Cube, and the 20-blocks world. In every case∗to solve randomly generated problemour method produces a heuristic that allows IDAinstances quickly with solutions close to optimal.The total time for the bootstrap process to create strong heuristics for these large statespaces is on the order of days. To make the process effective when only a single probleminstance needs to be solved, we present a variation in which the bootstrap learning ofnew heuristics is interleaved with problem-solving using the initial heuristic and whateverheuristics have been learned so far. This substantially reduces the total time needed tosolve a single instance, while the solutions obtained are still close to optimal.© 2011 Elsevier B.V. All rights reserved.1. IntroductionModern heuristic search and planning systems require good heuristics. A popular approach to creating heuristics fora state space is abstraction: from the state space description one creates a description of an abstract state space that iseasier to search; exact distances in the abstract space give admissible estimates of distances in the original space [4,5,16,24,34,36]. One limitation of this approach is that it is often memory-intensive. This has led to the study of compressionschemes [3,7,42], disk-based methods [52], and distributed methods [8]. These methods extend the range of problems towhich abstraction is applicable, but since combinatorial problems grow in size exponentially it is easy to imagine problemsso large that, with the computers of the foreseeable future, even the best heuristics created by these systems will be tooweak to enable arbitrary instances to be solved reasonably quickly.A second limitation of abstraction is that it can only be applied to state spaces given in a suitable declarative form.There are situations in which there is no such state-space description, for example, if a planner is controlling a system orcomputer game, or when such a description would be vastly less efficient than a “hard-coded” one, or when the state spaceis described declaratively but in a different language than the abstraction system requires. We call such representations* Corresponding author.E-mail addresses: jabbaria@cs.ualberta.ca (S. Jabbari Arfaee), zilles@cs.uregina.ca (S. Zilles), rholte@ualberta.ca (R.C. Holte).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.08.0012076S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098opaque. With an opaque representation, a state space is defined by a successor function that can be called to compute astate’s children but cannot otherwise be reasoned about. By definition, abstraction cannot be applied to create heuristicswhen the state space is represented opaquely.An approach to the automatic creation of heuristics that sidesteps both of these limitations is to apply machine learningto a set of states whose distance-to-goal is known (the training set) to create a function that estimates distance-to-goalfor an arbitrary state, i.e., a heuristic function. This idea has been applied with great success to the 15-puzzle and otherstate spaces of similar size (see Ernandes and Gori [9] and Samadi, Felner, and Schaeffer [41]), but could not be appliedto larger spaces, e.g., the 24-puzzle, because of the excessive time it would take to create a sufficiently large training setcontaining a sufficiently broad range of possible distances to goal. To overcome this obstacle, Samadi et al. [41] reverted tothe abstraction approach: instead of learning a heuristic for the 24-puzzle directly they learned heuristics for two disjointabstractions of the 24-puzzle and combined them to get a heuristic for the 24-puzzle. This approach inherits the limitationsof abstraction mentioned above and, in addition, the crucial choices of which abstractions to use and how to combine themare made manually.Ernandes and Gori [9] proposed a different way of extending the machine learning approach to scale to arbitrarilylarge problems, but never implemented it. We call this approach “bootstrap learning of heuristic functions” (bootstrapping,for short). The contribution of the present paper is to validate their proposal by supplying the details required to makeautomatic bootstrapping practical and showing experimentally that it succeeds on state spaces that are at or beyond thelimit of today’s abstraction methods.Bootstrapping is an iterative procedure that uses learning to create a series of heuristic functions. Initially, this proce-dure requires a heuristic function h0 and a set of states we call the bootstrap instances. Unlike previous machine learningapproaches to creating heuristics, there are no solutions given for any instances, and h0 is not assumed to be strong enough[29]) is run with h0 in an attempt toto solve any of the given instances. A standard heuristic search algorithm (e.g., IDAsolve the bootstrap instances within a given time limit. The set of solved bootstrap instances, together with their solutionlengths (not necessarily optimal), is fed to a learning algorithm to create a new heuristic function h1 that is intended to bebetter than h0. After that, the previously unsolved bootstrap instances are used in the same way, using h1 as the heuristicinstead of h0. This procedure is repeated until all but a handful of the bootstrap instances have been solved or until asuccession of iterations fails to solve a large enough number of “new” bootstrap instances (ones that were not solved onprevious iterations).∗If the initial heuristic h0 is too weak to solve a sufficient number of the given bootstrap instances within the given timelimit we use a random walk method to automatically generate bootstrap instances at the “right” level of difficulty (easyenough to be solvable with h0, but hard enough to yield useful training data for improving h0).As in the earlier studies by Ernandes and Gori [9] and Samadi et al. [41], which may be seen as doing one step of thebootstrap process with a very strong initial heuristic, the learned heuristic might be inadmissible, i.e., it might sometimesis not guaranteed to find optimal solutions with the learned heuristic. Withoverestimate distances, and therefore IDAbootstrapping, the risk of excessive suboptimality of the generated solutions is much higher than with the one-step methodsbecause on each iteration the learning algorithm might be given solution lengths larger than optimal, biasing the learnedheuristic to even greater overestimation. The suboptimality of the solutions generated is hence an important performancemeasure in our experiments.∗We test our method experimentally on four problem domains that are at, or beyond, the limit of what current abstractionmethods can solve optimally—the 24-sliding-tile puzzle, the 35-pancake puzzle, Rubik’s Cube, and the 20-blocks world—ineach case starting with an initial heuristic so weak that the previous, one-step methods would fail because they would notbe able to generate an adequate training set in a reasonable amount of time. In all the domains, bootstrapping succeeds in∗to solve randomly generated problem instances quickly with solutions that are veryproducing a heuristic that allows IDAclose to optimal. On these domains our method systematically outperforms Weighted IDA[30] and BULB [15].∗The time it takes for our bootstrap method to complete its learning on these large state spaces is on the order of days.This is acceptable when the learned heuristic will be used to solve many instances, but a different approach is neededin order to solve a single instance quickly. For this we introduce a method that interleaves the bootstrapping process forcreating a succession of ever stronger heuristics with a process that uses the set of heuristics that are currently available(initially just h0) to try to solve the given instance. The total time required to solve a single instance using this methodis substantially less than the learning time for the bootstrap method, and the solutions it produces are of comparablesuboptimality. For example, with this method the total time to solve an instance of the 24-puzzle is just 14 minutes, onaverage, and the solution found is only 6.5% longer than optimal. When applied to the blocksworld instances used in theIPC2 planning competition, our interleaving method solves all the instances within the 30-minute time limit, and almost allare solved optimally.The remainder of the paper is organized as follows. Section 2 provides a full description of the Bootstrap and Ran-domWalk methods, which are experimentally evaluated in Section 3. The interleaving method for quickly solving singleinstances is described and evaluated in Section 4. Section 5 surveys previous work related to bootstrapping and Section 6closes the paper with a summary and conclusions.S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–209820772. The Bootstrap and RandomWalk algorithmsThis section describes the algorithmic approach and implementation of our method for learning heuristics. The input toour system consists of a state space, a fixed goal state g, a heuristic function h0, a set Ins of states to be used as bootstrapinstances, and a set of state features to be used for learning. We do not assume that h0 is sufficiently strong that any ofthe given bootstrap instances can be solved using it. In principle, h0 could be completely trivial (returning 0 for all states)but in practice it is useful to include weak but non-trivial heuristics among the features used for learning. If that is done itmakes sense to use their maximum as h0 in the absence of any stronger heuristic.In the first subsection, we focus on the bootstrap procedure, which incrementally updates the initial heuristic with thehelp of a set of bootstrap instances. This procedure requires h0 to be strong enough to solve several of the given instancesat least suboptimally in the given time limit. If it is not, a set of easier instances is needed to improve the initial heuristicto the point where the easiest bootstrap instances can be solved. This set of easier instances is generated by the randomwalk method described in the second subsection.2.1. The Bootstrap algorithmOur bootstrap procedure, Algorithm 1, proceeds in two stages. In the first stage, for every instance i in Ins, a heuristicsearch algorithm is run with start state i and the current heuristic hin (line 7). Every search is cut off after a limited periodof time (tmax). If i is solved within that time then the user-defined features of i, together with its solution length, are addedto the training set. In addition, features and solution lengths for all the states on the solution path for i are added to thetraining set (lines 8 and 9). This increases the size of the training set at no additional cost and balances the training set tocontain instances with long and short solutions.Algorithm 1for each instance i ∈ Ins doAdd (feature vector(s), distance(s, g, P i )) to TSend forremove i from InsNumSolved := NumSolved + 1if Heuristic Search(i, g, hin, tmax) succeeds thenfor each state s on i’s solution path P i do1: procedure Bootstrap(h0, hin, Ins): hout2: uses global variables tmax, t∞, insmin, g3: create an empty training set TS4: NumSolved := 05: while (NumSolved + size(Ins) (cid:2) insmin) && (tmax (cid:3) t∞) do6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23: end while24: return hinhlearn := learn a heuristic from TSDefine hin(x), for any state x, to be max(h0(x), hlearn(x))clear TSNumSolved := 0end forif (NumSolved (cid:2) insmin) thentmax := 2 × tmaxend ifend ifelseThe second stage examines the collected training data. If “enough” bootstrap instances have been solved then the heuris-tic hin is updated by a learning algorithm (line 17) and the training set is reset to be empty. If not “enough” bootstrapinstances have been solved, the time limit is increased without changing hin (line 21). Either way, as long as the currenttime limit (tmax) does not exceed a fixed upper bound (t∞), the bootstrap procedure is repeated on the remaining bootstrapinstances with the current heuristic hin. “Enough” bootstrap instances here means a number of instances above a fixedthreshold insmin (line 15). Variable NumSolved keeps track of the number of bootstrap instances solved in each iteration.It increases whenever a new instance is solved (line 12) and it will be set to zero for the next iteration (line 19). Theprocedure terminates if tmax exceeds t∞ or if the remaining set of bootstrap instances is too small.Notice (line 17) that each heuristic hin created by bootstrap is the maximum of the heuristic returned by the learningalgorithm using the current training set (hlearn) and h0. This is not an essential requirement of the bootstrap process butit is advisable when h0 is known to be an admissible heuristic since it can only make the heuristic more accurate. In allthe experiments reported below, this method was used. It is also possible to take the maximum over all previously learnedheuristics as well as hlearn and h0, or to add the previously learned heuristics to the set of features used for learning. Wedid not do either of these because of the considerable increase in computation time they would have caused.Table 1 shows each iteration of the bootstrap procedure on the 15-puzzle (defined in Section 3) when Ins contains 5000randomly generated solvable instances, insmin is 75, and tmax is 1 second. The definition of the initial heuristic h0, the2078S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098Table 1Bootstrap iterations for the 15-puzzle.IterationNumber solvedAverage optimal cost(solved instances)Average nodes generated(solved instances)Average suboptimality(test instances)0123986332651915646.1154.3758.5260.44517,295205,836353,997276,7921.2%2.8%5.5%8.3%learning method, and the features used for learning are the same as those for the 24-puzzle that are given in Section 3with h0below. The first row shows the result of the initial iteration. All 5000 instances in Ins were attempted but IDAwas only able to solve 986 of them in the time limit (column “Number solved”). The average optimal solution length forthe solved instances is shown in column “Average optimal cost”. The average number of nodes generated in solving theseinstances is shown in column “Average nodes generated”. The states along these 986 solution paths, together with theirdistances to the goal, form the training set to which a learning algorithm is applied to create a new heuristic, h1.1 Thesuboptimality of the heuristic learned on this iteration (h1), measured on an independent test set, is shown in column“Average suboptimality”.∗An attempt is then made using h1 to solve each of the 4014 instances that were not solved using h0. The next row(iteration 1) shows that 3326 of these were solved in the time limit. All the states along all these solution paths were usedto learn a new heuristic h2, which was then used in an attempt to solve each of the 688 instances that were not solvedon the first two iterations. The next row (iteration 2) shows that 519 of these were solved. The heuristic, h3, learned fromthese solution paths solved 156 of the 169 instances not solved to this point, and those solution paths provide the trainingdata to create a new heuristic, h4. The bootstrap process ends at this point because there are fewer than insmin unsolvedinstances, and h4 is returned as the final heuristic. In this example, there was no need for the bootstrap process to increasethe time limit tmax because each iteration solved insmin or more instances with the initial tmax value.There are no strong requirements on the set Ins of bootstrap instances—it may be any set representative of the instancesof interest to the user. However, for the bootstrap process to incrementally span the gap between the easiest and hardest ofthese instances, Ins must contain instances at intermediate levels of difficulty. At present this is simply an intuitive informalrequirement for which we have no proof of necessity.2.2. The RandomWalk algorithmIt can happen that the initial heuristic h0 is so weak that the heuristic search algorithm is unable to solve enoughinstances in Ins, using h0, to get a sufficiently large set of training data. For this case we need a procedure that generatesbootstrap instances that are (i) easier to solve than the instances the user provided but (ii) harder to solve than instancessolvable by simple breadth-first search in acceptable time (to guarantee a high enough quality of training data).This is accomplished using random walks backward from the goal2 of a suitably chosen length to generate instances.As described in Algorithm 2, we first test whether the initial heuristic is strong enough to solve a sufficient number (atleast insmin many) of the user-provided bootstrap instances (Ins) in the given time limit tmax (line 5). If so, the bootstrapprocedure can be started immediately (line 10). Otherwise, we perform random walks backward from the goal, up to depth“length”, and collect the final states as special bootstrap instances (RWIns). The bootstrap procedure is then run on thesespecial instances (line 7) to create a stronger heuristic. This process is repeated with increasingly longer random walks(line 8) until it produces a heuristic that is strong enough for bootstrapping to begin on the user-given instances or fails toproduce a heuristic with which sufficiently many instances in RWIns can be solved within time limit t∞.Algorithm 2 In a random walk we disallow the inverse of the previous move.1: procedure RandomWalk (h0, Ins, lengthIncrement): hout2: uses global variables tmax, t∞, insmin, g3: length := lengthIncrement4: hin := h05: while (hin is too weak to solve insmin many instances in Ins within time tmax) && (tmax (cid:3) t∞) do6:7:8:9: end while10: return Bootstrap(h0, hin, Ins)RWIns := 200 instances, each generated by applying “length” many random moves backward from ghin := Bootstrap(h0, hin, RWIns)length := length + lengthIncrement1 As explained above, h1, and all other heuristics created by Bootstrap, are defined, for any state x, as the maximum of h0(x) and hlearn(x), where hlearnis the heuristic created by the learning algorithm in the current iteration.2 For spaces with uninvertible operators, this requires a predecessor function, not just the successor function provided by an opaque representation.Hence the RandomWalk part of the process will not be applicable to certain opaque domains. Moreover, the RandomWalk procedure works only for singlegoal states, not for sets of goal states. Neither of these restrictions applies to the Bootstrap procedure itself, since there the search progresses in the forwarddirection.S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–20982079Table 2RandomWalk procedure applied to the 20-blocks world.Row12345678RWlength204060608080100120NumbersolvedAverageoptimal cost1971451157999951741398.9711.7613.9616.0516.0819.3720.4123.50Timelimit11122444The choice of “lengthIncrement” is an important consideration. If it is too large, the instances generated may be toodifficult for the current heuristic to solve and the process will fail. If it is too small, a considerable amount of time will bewasted applying the bootstrap process to instances that do not substantially improve the current heuristic. In our system,the lengthIncrement parameter was set automatically as follows.1. Run a breadth-first search backward from the goal state with a time limit given by the initial value of tmax. Let S bethe set of states thus visited.2. Repeat 5000 times: do a random walk backward from the goal (always disallowing the inverse of the previous move)until a state not in S is reached. Set lengthIncrement to be the floor of the average length of these 5000 random walks.The intuition motivating this definition of lengthIncrement is as follows. Initially, it generates problem instances that, onaverage, are just a little more difficult than can be solved using breadth-first search with a time limit of tmax. These are thusexpected to provide training examples that are solvable using h0 and cause a non-trivial heuristic function to be learned.On subsequent iterations, we imagine that most of the instances created by random walks whose length is the next largermultiple of lengthIncrement will be within a short breadth-first search of the instances that were solved on the previousiteration—in other words, just slightly more difficult, on average, than the previous instances. By being slightly more difficultthey are easy enough to be solved using the current heuristic but provide training instances that allow a better heuristic tobe learned.The RandomWalk approach is not guaranteed to succeed. It might fail to generate problems of a suitable level of difficulty(easy enough to be solvable using the current heuristic but hard enough to help produce a better heuristic).Table 2 illustrates the RandomWalk procedure on the 20-blocks world when Ins contains 5000 randomly generatedsolvable instances, insmin is 75, tmax is 1 second, and 200 random walk instances are generated (RWIns) for each distinctrandom walk length. The definition of this domain, the initial heuristic h0, the learning method, and the features usedfor learning are given in Section 3 below. Random walks are necessary in this domain because h0 is too weak to solvea sufficient number (insmin) of the bootstrap instances (Ins). The value of “lengthIncrement” was set automatically by ourmethod at 20.The first row shows the result of the initial iteration. 200 instances (RWIns) have been generated by random walks oflength 20 (column “RW length”) and passed to the bootstrap procedure along with h0. IDAusing h0 as the heuristic wasable to solve 197 of these instances (column “Number solved”) within the time limit (column “Time limit”, in seconds) sothere is just one iteration of the bootstrap process, which returns a new heuristic, h1. This heuristic is then used to attemptto solve the bootstrap instances in Ins. It is too weak to solve a sufficient number of them in the time limit so anotheriteration of the RandomWalk process is needed.∗The random walk length is increased by 20 (the value of lengthIncrement) and a set (RWIns) of 200 instances is gener-ated by random walks of length 40 and passed to the bootstrap procedure along with h1. 145 of them are solved in the firstbootstrap iteration and the bootstrap procedure returns a new heuristic, h2, since fewer than insmin unsolved RandomWalkinstances remain. This heuristic is used to attempt to solve the bootstrap instances (Ins). It is too weak to solve a sufficientnumber of them in the time limit so another iteration of the RandomWalk process is needed.The random walk length is increased by 20 and a set of 200 instances (RWIns) are generated by random walks oflength 60 and passed to the bootstrap procedure along with h2. The bootstrap process (row 3) is only able to solve 115of these instances using h2 in its first iteration. A new heuristic, h3, is learned from these but is not passed back tothe RandomWalk procedure because there are still more than insmin unsolved RandomWalk instances (RWIns). A seconditeration of the bootstrap procedure attempts to solve them with its new heuristic, h3, but fails to solve a sufficient number(insmin) and therefore doubles the time limit and attempts them again with h3. Row 4 shows that this iteration of thebootstrap procedure succeeds in solving 79 of them with the new time limit, and from these it learns a new heuristic,h4. Since there are now fewer than insmin unsolved RandomWalk instances, the bootstrap procedure returns h4 to theRandomWalk process. This heuristic is used in an attempt to solve the bootstrap instances (Ins). It is too weak to solve asufficient number of them in the time limit so another iteration of the RandomWalk process is needed.As the table shows, in total 6 iterations of the loop in the RandomWalk process were executed (6 distinct values of theRandomWalk length) and for each of these iterations either one or two bootstrap iterations were required to find a heuristic2080S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098Fig. 1. System overview.that could solve the random walk instances. The time limit had to be increased twice. The RandomWalk process endedbecause the heuristic, h8, created from the RandomWalk instances solved in the final row of the table, was able to solve asufficient number (insmin) of the bootstrap instances (Ins) that the bootstrap procedure could finally be started on the setof bootstrap instances (Ins) with h8 as its initial heuristic.Once the bootstrap process begins to operate on the bootstrap instances, the RandomWalk process will not be invokedagain. However, there is a role that it could play. If in some iteration the Bootstrap process fails to solve a sufficient numberof instances, instead of doubling its current time limit (line 21 of Algorithm 1) it could instead invoke the RandomWalkprocess to generate instances of the appropriate level of difficulty. Preliminary experiments with this idea succeeded onartificially contrived sets of bootstrap instances for the 15-puzzle and 17-pancake puzzle, but failed on Rubik’s Cube. Becauseof the latter we abandoned this idea and all the experiments reported in this paper are based on using RandomWalk onlyas an initial step, if needed, to create a heuristic strong enough to allow the bootstrap process to begin operating on thebootstrap instances.2.3. Summary: System overviewA summary of the overall system and its operation is depicted in Fig. 1. The key inputs from the user are an initialheuristic h0 and a set of bootstrap instances. The RandomWalk procedure tests whether h0 is strong enough to solve asufficiently large number of the bootstrap instances. If it is not, RandomWalk internally generates its own instances throughrandom walks of a length that it determines automatically. These instances are passed to the Bootstrap procedure, whichreturns a heuristic. This procedure repeats, with instances created by random walks of increasing lengths, until the currentheuristic is strong enough to solve a sufficiently large number of the bootstrap instances. At this point Bootstrap is invokedone last time, with the bootstrap instances. The final heuristic it creates on these instances is the heuristic that is output bythe system.3. Experiments with Bootstrap and RandomWalkExcept where explicitly stated otherwise, IDA∗was the search algorithm used.Domains. Because it is essential in this study to be able to determine the suboptimality of the solutions our methodproduces, we chose as testbeds domains in which optimal solution lengths can be computed in a reasonable amount oftime, either by existing heuristic search methods or by a hand-crafted optimal solver for the domain. The following domainsmet this criterion.3• (n2 − 1)-Sliding-tile puzzle [46] – The sliding-tile puzzle consists of n2 − 1 numbered tiles that can be moved in ann × n grid. A state is a vector of length n2 in which component k names what is located in the kth puzzle position(either a number 1, . . . , n2 − 1 for a tile or a symbol representing the blank). Every operator swaps the blank with a tileadjacent to it. The left part of Fig. 2 shows the goal state that we used for the 24-puzzle while the right part shows astate created from the goal state by applying two operators, namely swapping the blank with tile 1 and then swappingit with tile 6.The number of states reachable from any given state is (n2)!/2, cf. [1]. We report results on the 24-puzzle (n = 5), thelargest version of the puzzle that has been solved optimally by abstraction-based heuristic search methods [32]. Thisdomain has roughly 1025 reachable states.• n-Pancake puzzle [6] – In the n-pancake puzzle, a state is a permutation of n numbered tiles and has n − 1 successors,with the lth successor formed by reversing the order of the first l + 1 positions of the permutation (1 (cid:2) l (cid:2) n − 1).3 Experiments on smaller versions of some of these domains (the 15-puzzle, the 17- and 24-pancake puzzles, and the 15-blocks world) can be found ina previous publication [27].S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–20982081Fig. 2. The goal state for the 24-puzzle (left) and a state two moves from the goal (right).Fig. 3. The goal state for the 35-pancake puzzle (above) and a state one move from the goal (below).Fig. 4. The goal state for Rubik’s Cube (left) and a state one move from the goal (right) (modified from Zahavi et al. [51]).Fig. 5. The goal state for the 20-blocks world (left) and a state two moves from the goal (right).The upper part of Fig. 3 shows the goal state that we used in our experiments, while the lower part shows the 3rdsuccessor of the goal (the first four positions have been reversed).All n! permutations are reachable from any given state. We report results for n = 35 which contains more than 1040reachable states. The largest version of the puzzle that has been solved optimally by general-purpose abstraction-basedmethods is n = 19 [22].• Rubik’s Cube [31] – Rubik’s Cube is a 3 × 3 × 3 cube made up of 20 moveable 1 × 1 × 1 “cubies” with coloured stickerson each exposed face. Each face of the cube can be independently rotated 90 degrees clockwise or counterclockwise or180 degrees. The left part of Fig. 4 shows the goal state for Rubik’s Cube while the right part shows the state producedby rotating the right face 90 degrees counterclockwise.We used the standard encoding of the puzzle, including the standard operator pruning methods that reduce the branch-ing factor from 18 to approximately 13.34847 [31]. The number of states reachable from any given state is approximately4.3252 × 1019 [31]. Rubik’s Cube is at the limit of today’s general-purpose heuristic search methods for finding optimalsolutions.• n-Blocks world [45] – In the blocks world, each block can have at most one block on top of it and one block below it.A block with no block below it is said to be on the table. A block with no block above it is said to be clear. A moveconsists in moving a clear block to be on top of some other clear block or onto the table. We used n = 20 blocks in ourexperiments; the number of reachable states is more than 1020 [45]. The left side of Fig. 5 shows the goal state that weused; the right side of Fig. 5 shows the state produced from the goal state by moving block 20 to the table and thenmoving block 19 to the top of block 20.Learning algorithm and features. The learning algorithm used in all experiments was a neural network (NN) with oneoutput neuron representing distance-to-goal and three hidden units trained using standard backpropagation [40] and meansquared error (MSE).4 Training ended after 500 epochs or when MSE < 0.005.4 We do not consider the choice of the particular learning algorithm critical; we chose this neural network setting to be the same as previous work onlearning heuristics [9,41]. Using only three hidden units made sure that, for every domain we experimented with, the number of inputs was at least aslarge as the number of hidden units. We experimented with various error measures that penalize overestimation, but found none that yielded substantially2082S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098It is well known that the success of any machine learning application depends on having “good” features. The issue ofautomatically creating good features for learning search control knowledge has been studied, in the context of planning,by Yoon et al. [49]. In our experiments we did not carefully engineer the features used or exploit special properties of thedomain. Our intention was to show that the bootstrap learning approach is effective, even in the absence of carefully chosenfeatures and human insight into the domain. We did deliberately choose features that could be quickly calculated since theirvalues are all needed every time a heuristic value must be computed for a state.The input features for the NN are described separately for each domain below; most of them are values of weak heuristicsfor the respective problems.Initial heuristics. The initial heuristic h0 for each domain was defined as the maximum of the heuristics used as featuresfor the NN. In all the domains other than Rubik’s Cube, h0 was too weak for us to evaluate it on the test instances ina reasonable amount of time. After each iteration of our method, the new heuristic was defined as the maximum of theoutput of the NN and the initial heuristic. No domain-specific knowledge, such as geometric symmetry or duality [51] wasused to augment the heuristics in any of the experiments reported.One advantage that h0 has compared to the heuristics generated by bootstrapping is that it can be computed morequickly, since the maximum of a set of feature values can be evaluated faster than a neural network output with the samefeatures as input. For example, the computation of each neural network heuristic in our experiments was between 1.25(Rubik’s Cube) and 2.0 (24-puzzle) times slower than the computation of the corresponding h0 heuristics.Bootstrap instances. Ins consisted of either 500 or 5000 solvable instances generated uniformly at random except for Rubik’sCube where they were generated by random walks of various lengths between 1 and 25.Numeric parameters. In all experiments, insmin = 75, tmax = 1 second, t∞ = 512 seconds, and the size of the set RWIns was200.The tables below summarize the results on our test domains. All these results are based on a set of test instancesgenerated independently of the bootstrap instances, in contrast to Table 1, where some measurements were based on thebootstrap instances solved in the respective Bootstrap iteration. In the tables with Bootstrap results, the “Iteration” columnindicates which Bootstrap iteration is being described in each row. The “No. solved” and “Total unsolved“ columns show,respectively, the number of bootstrap instances solved in a particular iteration and the total number of bootstrap instancesthat are not yet solved at the end of that iteration.The “Avg. subopt.” column gives the average suboptimality of the solutions found for the test instances by the heuristicproduced at the end of an iteration, calculated as follows. We define the suboptimality for an instance as the cost of thesolution found for that instance divided by its optimal solution cost. We then compute the average over all the instances ofthe individual suboptimalities and subtract one. For example, Avg. subopt. = 7% means that, on average, the solution foundfor a test instance was 7% longer than its optimal solution.“Avg. nodes gen.” is the average number of nodes generated to solve the test instances using the heuristic produced at theend of an iteration. “Avg. solving time” is the average search time in seconds to solve the test instances. Unless specificallystated, no time limit was imposed when systems were solving the test instances. “Learning time” in the row for iteration iis the time used by our method to complete all iterations up to and including i, including all the RandomWalk processingrequired before iteration 0 could begin. The letters “s”, “m”, “h”, and “d” represent units of time—seconds, minutes, hours,and days, respectively.Each row in the “Other methods” tables gives the data for a non-bootstrapping system that we tried or found in the, givenliterature. The “h (Algorithm)” column indicates the heuristic used, with the search algorithm, if different from IDAin parentheses. The symbol #k indicates that the same heuristic is used in this row as in row k. The run-times taken fromthe literature are marked with an asterisk to indicate they may not be strictly comparable to ours. Some suboptimalities∗∗)(W-IDAfrom the literature are computed differently than ours; these too are marked with an asterisk. All weighted IDAand BULB results are for our own implementations of these algorithms, except for the BULB results on Rubik’s Cube, whichare from Furcy and König [15].∗The last Bootstrap iteration shown in the tables represents the last successful iteration of the Bootstrap process. If therewere fewer than insmin unsolved bootstrap instances remaining after that iteration (24-puzzle, 35-pancake puzzle, andRubik’s Cube and the 20-blocks world using 5000 bootstrap instances), the Bootstrap process terminated as soon as thatiteration was done and the “Bootstrap completion time” shown in each table, which measures the entire time required bythe Bootstrap process, is equal to the “Learning time” reported for the final iteration. However, if there were insmin or moreunsolved bootstrap instances remaining after the last iteration shown in a table (Rubik’s Cube and 20-blocks world, eachwith 500 bootstrap instances), another bootstrap iteration would have been attempted on those instances but Bootstrapterminated it without creating a new heuristic because tmax exceeded t∞. In such a case the “Bootstrap completion time”includes the time taken by the final, unsuccessful iteration. For example, the “Learning time” for iteration 1 in Table 9 showsbetter results than MSE. We also briefly experimented with linear regression instead of a neural network; the preliminary results were on a par with thoseof the neural net.S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–20982083Table 324-Puzzle, Bootstrap (500 bootstrap instances).Iteration0 (first)123 (final)No. solvedTotal unsolvedAvg. subopt.Avg. nodes gen.Avg. solving timeLearning time14198112128359261149215.1%5.9%5.6%5.7%121,691,641156,632,35270,062,61062,559,170153.34 s205.68 s89.03 s81.52 s1 h 38 m2 h 16 m3 h 57 m11 h 43 mBootstrap completion time = 11 hours and 43 minutesTable 424-Puzzle, Bootstrap (5000 bootstrap instances).Iteration0 (first)2468101214161820222426 (final)No. solvedTotal unsolvedAvg. subopt.Avg. nodes gen.Avg. solving timeLearning time41311684116263212112116141270156147791374587406038073521302925342188185015731057652393224124.7%4.9%4.8%5.0%5.1%5.7%6.2%6.4%6.4%7.2%7.7%7.3%7.9%8.1%1,798,903,6241,386,730,4911,051,748,928307,700,388555,085,735140,197,951164,616,540135,943,43435,101,91824,416,96718,566,78812,172,88910,493,6497,445,3352364.69 s1776.41 s1366.37 s403.09 s719.79 s182.82 s223.68 s175.11 s45.83 s31.47 s24.60 s16.13 s13.65 s9.65 s19 h23 h1 d 09 h1 d 17 h1 d 23 h2 d 04 h2 d 08 h2 d 12 h2 d 20 h3 d 03 h3 d 09 h3 d 12 h3 d 22 h4 d 21 hBootstrap completion time = 4 days and 21 hoursthat it takes 2 days to learn the final heuristic for Rubik’s Cube using 500 bootstrap instances, but the “Bootstrap completiontime” is reported as 2 days and 19 hours. The difference (19 hours) is the time required by an iteration after iteration 1,which failed to solve insmin new instances within the time limit of t∞.3.1. 24-PuzzleTables 3 and 4 show our results on the 50 standard 24-puzzle test instances first solved by Korf and Felner [32], whichhave an average optimal cost of 100.78. The input features for the NN were: Manhattan distance (MD), number of out-of-place tiles, position of the blank, and five heuristics, each of which is a 4-tile pattern database (PDB [5]). The total memoryused to hold the PDBs was about 50 megabytes. The time to build the pattern databases and generate bootstrap instances,which we call the pre-processing time, was about 2 minutes.The initial heuristic is sufficiently weak that nine RandomWalk iterations were necessary before bootstrapping itselfcould begin (ten iterations were required when there were only 500 bootstrap instances). Table 3 shows the results for allbootstrap iterations when it is given 500 bootstrap instances. Table 4 is analogous, but when 5000 bootstrap instances aregiven. In both cases, there is a very clear trend: search becomes faster in each successive iteration (see the “Avg. nodes gen.”and “Avg. solving time” columns) but suboptimality becomes worse. The increase in suboptimality is most likely caused bythe fact that the solutions for the training instances become increasingly suboptimal on successive iterations. Suboptimaltraining instances bias the system to learn new heuristics that overestimate to an even greater extent which, in turn, leadsto even more suboptimal solutions in subsequent iterations.There is clearly a rich set of time-suboptimality tradeoffs inherent in the bootstrap approach. In this paper we do notaddress the issue of how to choose among these options, we assume that a certain number of bootstrap instances aregiven and that the heuristic produced by the final bootstrap iteration is the system’s final output. There is also clearlyan interesting relationship between “Learning time” and “Solving time”: the heuristics created later in the process solveproblems faster on average. In Section 4 we present one approach to exploiting this relationship when there is only oneproblem instance to solve.There are two key differences between using 500 and 5000 bootstrap instances. The most obvious, and in some settingsby far the most important, is the total time required for the combined RandomWalk and Bootstrap process. Because afterevery iteration an attempt is made to solve every bootstrap instance, having 10 times as many bootstrap instances makesthe process roughly 10 times slower. The second difference is more subtle. The larger bootstrap set contains a larger numberof more difficult problems, and those drive the Bootstrap process through additional iterations (in this case seven additionaliterations), producing, in the end, faster search but worse suboptimality than when fewer bootstrap instances are used.Fig. 6 shows the distribution of suboptimality values for iterations 0, 13, 26 of the Bootstrap process with 5000 bootstrapinstances. A data point (x, y) on the plot means that for y% of the test instances the solution was at most x% suboptimal.2084S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098Fig. 6. 24-Puzzle, distribution of suboptimality values.Fig. 7. 24-Puzzle, distribution of solving times.We see that there is an across-the-board degradation of the suboptimalities from early to later iterations: the curve foriteration 26 is strictly below the curve for iteration 13 which, in turn, is strictly below the curve for iteration 0.Fig. 7 shows the distribution of solving times in an analogous manner; the x-axis measures solving time in seconds. Theleft plot is for the instances that are solved in 200 seconds or less and the right plot is for the remaining instances witha different scale on the x-axis. There are a few test instances that take extremely long to solve using the heuristic learnedon the first iteration, but by iteration 13 all the instances can be solved in under 2500 seconds. Using the final heuristic, allinstances are solved in under 72 seconds. We see that there is an across-the-board improvement in solving times: the plotfor iteration 0 is strictly below the plot for iteration 13 which, in turn, is strictly below the plot for iteration 26. The samegeneral trends for suboptimality and solving time were seen in all other test domains unless specifically noted otherwisebelow.Table 5 shows the results of other systems on the same test instances. Row 1 reports on W-IDAusing our initialheuristic (h0) multiplied by a weight (W) chosen so that Subopt is roughly equal to the Subopt value achieved by the finalbootstrap heuristic (Table 4, iteration 26). In Row 2, W is chosen so that Nodes gen. is roughly equal to the Nodes gen. valueachieved by the final bootstrap heuristic (Table 4, iteration 26). The results of analogous settings for BULB’s beam width (B)when h0 is used are shown in Rows 3 and 4. Bootstrap (Table 4, iteration 26) dominates in all cases, in the sense that if Wand BULB compare to Bootstrap in either one of the values (Subopt or Nodes gen.), then theand B are set so that W-IDAheuristic obtained in the final Bootstrap iteration (Table 4, iteration 26) is superior in the other value. Note however, that∗guarantees that the solution cost achieved is always within a factor of W of the optimal one—a guarantee that ourW-IDAlearned heuristics cannot provide. This has to be kept in mind for all subsequent comparisons of Bootstrap to W-IDA∗∗.Row 5 shows the results with the heuristic hsum, which is defined as the sum of the heuristic values among the NN’sinput features (h0 is the maximum of these values). Although hsum can, in general, be much greater than the actual distanceto goal, hsum might be quite an accurate heuristic when a moderate number of weak heuristics are used for NN features, asin our experiments. By comparing its performance with Bootstrap’s we can see the return on investment for learning howto combine the different heuristics as opposed to just giving them all equal weight as hsum does. As the results show, hsum,with our NN features for the 24-puzzle, performs very poorly in terms of suboptimality. It is superior to Bootstrap with 500instances (Table 3, iteration 3) and Bootstrap with 5000 instances (Table 4, iteration 26), in terms of both nodes generatedand solving time.∗S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–20982085Table 524-Puzzle, other methods.Row12345h (Algorithm)∗, W = 1.5)h0 (W-IDA∗, W = 2.6)h0 (W-IDAh0 (BULB, B = 20,000)h0 (BULB, B = 10,000)hsumResults from previous papers67891011∗Add 6-6-6-6#6 (DIDA)#6, Add 8-8-8#6, W = 1.4 (RBFS)PE-ANN, Add 11-11-2 (RBFS)#10, W = 1.2 (RBFS)Avg. subopt.Avg. nodes gen.Avg. solving time9.0%80.5%13.8%122.9%181.4%0%0%0%∗9.4%∗0.7%∗3.7%39,356,250,8967,579,34585,136,4757,624,139151,892360,892,479,67075,201,250, 61865,135,068,0051,400,431118,465,980582,46628,770.8 s5.5 s185.4 s13.4 s0.1 s∗47 h∗10 h?s1.0∗111.0∗s0.7∗sRows 6–8 show the results of state-of-the-art heuristic search methods for finding optimal solutions. Row 6 shows theresults using the maximum of disjoint 6-tile PDBs and their reflections across the main diagonal as a heuristic, due to Korfand Felner [32]. Row 7 shows the results for DIDA, obtained by Zahavi, Felner, Holte, and Schaeffer [50] using the sameheuristic. In Row 8 the heuristic used is the maximum of the heuristic from Row 6 and a partially created disjoint 8-tilePDB, see Felner and Adler [10] (solving time was not reported). The very large solving times required by these systemsshows that the 24-puzzle represents the limit for finding optimal solutions with today’s abstraction methods and memorysizes. Row 9, due to Samadi et al. [41], illustrates the benefits of allowing some amount of suboptimality. Here, RBFS [30] isused with the heuristic from Row 6 multiplied by 1.4. The number of nodes generated has plummeted. Although this resultis better, in terms of nodes generated and solving time, than Bootstrap (Table 4, iteration 26), it hinges upon having a verystrong heuristic since we have just noted that W-IDAwith our initial heuristic is badly outperformed by Bootstrap.∗∗Rows 10 and 11 in Table 5 show the PE-ANN results by Samadi et al. [41]. As discussed in the introduction, this is not adirect application of heuristic learning to the 24-puzzle because it was infeasible to generate an adequate training set for aone-step method. Critical choices for abstracting the 24-puzzle were made manually to obtain these results. Row 10 showsthat our automatic method is superior to PE-ANN used in this way by a factor of more than 20 in terms of nodes generated.The suboptimality values shown in Rows 10 and 11 are not directly comparable to those in Tables 3 and 4 because Samadiet al. defined average suboptimality differently, as the total length of the solutions found divided by the total length of theoptimal solutions. The suboptimality of Bootstrap with 5000 instances, calculated in this way, happens to be the same (toone decimal place) as in Table 4 (8.1%) and is inferior to PE-ANN’s. Row 11 shows that if PE-ANN’s learned heuristic issuitably weighted it can outperform Bootstrap in both nodes generated and suboptimality.To see how Bootstrap’s results would change if it were given a stronger initial heuristic, we reran the experiment withh0 being the state-of-the-art admissible heuristic, namely Korf and Felner’s maximum of disjoint 6-tile PDBs and theirreflections across the main diagonal [32]. We adjusted the features used by the neural network accordingly: instead of 8features, we now used 13, namely one for each of the four disjoint PDBs, one for each of the four reflected PDBs, one forthe sum of the first four PDB features, one for the sum of the four reflected PDB features, plus one each for ManhattanDistance, position of the blank, and number of tiles out of place. Note that increasing the number of features might increaseBootstrap’s completion time and its solving time.The use of a stronger h0 decreased Bootstrap’s completion time by more than 50% when 500 bootstrap instances wereused but increased it by about 25% when 5000 bootstrap instances were used. The suboptimality of the solutions foundusing the final Bootstrap heuristic were unaffected by the use of the stronger heuristic when 500 bootstrap instances wereused but increased from 8.1% to 11.2% when 5000 bootstrap instances were used. The most important consequence of usinga stronger h0 is a dramatic reduction of the number of nodes generated by the final heuristic Bootstrap produced. With 500bootstrap instances only 5,087,295 nodes are generated on average, a 12-fold reduction compared to Table 3, and with 5000bootstrap instances use of the stronger h0 produces more than a 6-fold reduction in nodes generated.∗and BULB with this strong h0. W-IDAWe also reran W-IDAis still outperformed by Bootstrap, but not as badly.W = 1.45 yields an average suboptimality similar to Bootstrap’s with 5000 instances and the strong h0, but generatesroughly 3 times as many nodes. W = 1.5 generates a similar number of nodes but has a higher suboptimality (16% onaverage, compared to 11.2%). BULB, using the strong heuristic, is more clearly outperformed by Bootstrap. When generatinga comparable number of nodes to Bootstrap with 5000 instances and the strong h0, BULB’s suboptimality is much higherthan Bootstrap’s (418.3% compared to 11.2%). B = 20,000 resulted in a suboptimality (13.3%) approaching Bootstrap’s, but atthe cost of generating 36 times more nodes on average.∗3.2. 35-Pancake puzzleFor the 35-pancake puzzle the input features for the NN were seven 5-token PDBs, a binary value indicating whether themiddle token is out of place, and the number of the largest out-of-place token. Optimal solution lengths were computed us-2086S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098Table 635-Pancake puzzle, Bootstrap (500 bootstrap instances).IterationNo. solvedTotal unsolvedAvg. subopt.Avg. nodes gen.Avg. solving timeLearning time0 (first)1234 (final)13477811007736628920810831Bootstrap completion time = 1 day and 2 hoursTable 735-Pancake puzzle, Bootstrap (5000 bootstrap instances).10.4%10.2%11.4%11.3%12.3%178,891,711181,324,430169,194,509191,333,354131,571,637217 s219 s202 s228 s158 s7 h9 h11 h16 h1 d 02 hIteration0 (first)24681012141618202224262830 (final)No. solvedTotal unsolvedAvg. subopt.Avg. nodes gen.Avg. solving timeLearning time10225812826521695150128250118102210170105170125489843944110363031982999273224562008176615751177814600279369.2%9.7%10.2%10.8%11.6%12.2%12.3%12.3%12.4%13.2%13.0%13.5%14.2%14.9%15.1%15.4%2,766,675,1351,591,749,582586,345,353295,187,243134,075,80265,290,47947,998,04045,571,41139,128,83938,126,20839,440,28436,423,26225,034,58026,089,59313,156,60914,506,4134168 s1923 s687 s345 s157 s102 s76 s71 s45 s43 s44 s52 s42 s43 s21 s21 s1 d 17 h2 d 07 h2 d 20 h3 d 08 h3 d 18 h4 d 04 h4 d 20 h5 d 15 h5 d 23 h6 d 05 h6 d 16 h7 d 00 h7 d 10 h7 d 23 h8 d 07 h8 d 11 hBootstrap completion time = 8 days and 11 hoursFig. 8. 35-Pancake puzzle, distribution of solving times.ing the highly accurate, hand-crafted “break” heuristic.5 50 randomly generated instances, with an average optimal solutioncost of 33.6, were used for testing. The pre-processing time to build pattern databases and bootstrap instances was about18 minutes while the memory used to hold the pattern databases was about 272 megabytes.The initial heuristic is so weak that seven RandomWalk iterations were necessary before bootstrapping itself could be-gin (9 iterations were required when there were only 500 bootstrap instances). Table 6 has rows for all bootstrap iterationswith 500 bootstrap instances and Table 7 has rows for selected iterations with 5000 bootstrap instances. In both cases,we see the same trends as in the 24-puzzle concerning suboptimality, solving time, and the influence of the number ofbootstrap instances.Fig. 8 shows the distribution of solving times for iterations 0, 15, and 30 of the Bootstrap process with 5000 bootstrapinstances. Like the corresponding figure for the 24-puzzle (Fig. 7) we see that there are some instances that take a very longtime to solve using the heuristic learned in the first iteration and that by the middle iteration there are no such problematic5 For details on “break”, see http://tomas.rokicki.com/pancake/ or Helmert [20].S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–20982087Table 835-Pancake puzzle, other methods.Row1234h (Algorithm), W = 9)∗h0 (W-IDAh0 (BULB, B = 20,000)h0 (BULB, B = 500)hsumAvg. subopt.108.9%405.4%2907.9%59.0%Avg. nodes gen.1,092,647,373426,578,146154,193,96671,081,642Avg. solving time857 s1360 s483 s69 sinstances: all instances are solved in 500 seconds or less. But unlike the 24-puzzle, here the speedup in solving the hardestinstances is accompanied by a slowdown in solving the easier instances: in the left side of Fig. 8 the plot for iteration 15 isbelow that for iteration 0. By the final iteration, there is an across-the-board improvement in solving time compared to thetwo other iterations shown.Because of its large size, no previous general-purpose search system with automatically created heuristics has been, BULB, and hsum. None of these methods wasapplied to this problem domain, so Table 8 includes results only for W-IDAand BULB Rows 1 and 3 show theable to achieve a “Nodes gen.” value similar to Bootstrap with 5000 instances. For W-IDAminimum number of nodes these two algorithms generated (we tried 15 values for W between 1.1 and 10, and 15 values forB between 2 and 20,000). As can be seen, W-IDAand BULB produce a very high degree of suboptimality when generating∗or BULB can compete with Bootstrap in terms of suboptimality wasthe fewest nodes. Looking for settings for which W-IDA∗with Bootstrap’s final heuristic (iteration 30 in Table 7) needed onnot successful. Allowing 10 times more time than IDA∗and BULB, is inferioreach test instance, W-IDAto Bootstrap (Table 7, iteration 30) in terms of both nodes generated and suboptimality.did not complete any instances at all. Row 4 shows that hsum, like W-IDA∗∗∗∗As we did for the 24-puzzle, to see the effect of giving Bootstrap a strong initial heuristic, we reran the experiments withh0 being the strongest general-purpose type of admissible heuristic that is known for the 35-pancake puzzle, the additiveheuristics defined by Yang et al. [48]. The particular h0 we used was a 5-5-5-5-5-5-5 additive PDB. The features used forlearning were the seven 5-pancake PDBs, their sum, and the same two non-PDB features used with the weak h0.The use of the stronger h0 did not affect Completion times for either 500 or 5000 bootstrap instances. For 500 bootstrapinstances, use of the stronger h0 decreased suboptimality (from 12.3% to 5.5%) and reduced the number of nodes generatedby almost a factor of 5. For 5000 bootstrap instances, the stronger h0 decreased suboptimality even more (from 15.4% to5.9%) but had little effect on the number of nodes generated.3.3. Rubik’s CubeFor Rubik’s Cube, the input features for the NN were the three PDBs used by Korf [31], namely, one PDB based on theeight corner cubies and two PDBs each based on six edge-cubies. 333 megabytes of memory is used for the PDBs and thepre-processing took about 16 minutes.Korf’s 10 standard Rubik’s Cube instances [31] were used for testing. The average optimal solution cost for these in-stances is 17.5. The initial heuristic was sufficient to begin the Bootstrap process directly, so no random walk iterationswere necessary.Tables 9 and 10 show the results for each bootstrap iteration when 500 and 5000 bootstrap instances are given. In eithercase, bootstrapping produces very substantial speedup over search using h0. For instance, using 500 bootstrap instancesproduces a heuristic that reduces the number of nodes generated by a factor of 43 compared to h0 while producing solutionsthat are only 4% longer than optimal. The trends across bootstrap iterations are the same as those observed in previousexperiments.The results of other systems are shown in Table 11. Rows 1 and 2 are when the initial heuristic (h0) is used with W-∗on the same set of test instances. Row 3 shows the results with hsum. As in the Pancake puzzle, Bootstrap (Table 10,IDAiteration 14) outperforms hsum in both suboptimality and nodes generated.Rows 4–6 show the results of state-of-the-art heuristic search methods for finding optimal solutions. Row 4 shows theresults using the initial heuristic (h0) [31]. Row 5 shows the results by Zahavi et al. [51] when dual lookups [11] for both6-edge PDBs were used in conjunction with the heuristic of Row 4. In Row 6 [51], the edge PDBs used in Row 5 areincreased from 6-edge to 7-edge and dual lookup is used. Bootstrap outperforms all of these optimal systems in terms ofnodes generated and solving time.For BULB, we compared our results to those of Furcy and König [15], which were obtained using h0. However, Furcyand König used a different set of test instances: they created 50 solvable instances by doing random walks of length 500backward from the goal state. This set of instances is currently unavailable, making it impossible to do a precise comparisonwith our method. With that in mind, an inspection of Furcy and König’s results shows that with an appropriate setting ofB, BULB’s performance in terms of nodes generated is similar to Bootstrap’s; the average number of nodes generated onFurcy and König’s 50 instances, using B = 50,000, was 189,876,775, compared to 192,012,863 for Bootstrap on Korf’s 10instances (see iteration 14 in Table 10). Because the optimal solution costs for Furcy and König’s instances are not known, acomparison of suboptimalities is not possible.2088S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098Table 9Rubik’s Cube, Bootstrap (500 bootstrap instances).Iteration0 (first)1 (final)No. solvedTotal unsolvedAvg. subopt.Avg. nodes gen.Avg. solving timeLearning time256762441782.8%4.0%67,264,270,2648,243,780,39178,998 s10,348 s5 m2 dBootstrap completion time = 2 days 19 hoursTable 10Rubik’s Cube, Bootstrap (5000 bootstrap instances).Iteration0 (first)1234567891011121314 (final)No. solvedTotal unsolvedAvg. subopt.Avg. nodes gen.Avg. solving timeLearning time2564355126821661491621667625685136218206192243620811955187317071558139612301154898813677459253613.4%4.6%5.8%9.7%12.6%16.0%21.8%20.1%21.8%22.9%22.9%25.3%24.7%27.5%29.3%69,527,536,5557,452,425,5443,314,096,4043,722,365,147974,287,428748,608,645599,503,676614,676,983465,772,443552,259,662518,980,590624,542,989422,066,562251,228,458192,012,86386,125 s10,477 s3976 s4444 s1119 s848 s823 s842 s626 s624 s577 s686 s464 s280 s208 s43 m10 h1 d 06 h2 d 16 h5 d 08 h7 d 05 h9 d 09 h11 d 07 h13 d 04 h16 d 14 h19 d 10 h23 d 20 h27 d 06 h30 d 02 h31 d 15 hBootstrap completion time = 31 days and 15 hoursTable 11Rubik’s Cube, other methods.Row123h (Algorithm)∗h0 (W-IDA∗h0 (W-IDAhsum, W = 1.9), W = 3.3)Results from previous papers456h0#4 with dual lookupmax{8, 7, 7} with dual lookup3.4. 20-Blocks worldAvg. subopt.Avg. nodes gen.Avg. solving time30.4%76.4%54.5%0%0%0%5,653,954,001217,463,103246,235,226360,892,479,670253,863,153,49354,979,821,5576632 s245 s256 s∗102,362 s∗91,295 s∗44,201 sWe used 9 input features for the NN: seven 2-block PDBs, the number of out of place blocks, and the number of stacks ofblocks. Optimal solutions were computed using the hand-crafted blocks world solver PERFECT [45]. We used 50 random testinstances in which the goal state has all the blocks in one stack. The average optimal solution length of the test instancesis 30.92. The total amount of memory required for this experiment was less than 3 kilobytes while the pre-processing tooka few seconds.The initial heuristic is so weak that six RandomWalk iterations were necessary before bootstrapping could begin (eightiterations for 500 bootstrap instances). Tables 12 and 13 show the bootstrap iterations for the 20-blocks world. The heuristicsused in the feature vector were so weak that solving the test instances using the early heuristics produced by Bootstrapwas infeasible; therefore, iteration 0 is not shown in Table 12 and iterations 0 through 2 are not shown in Table 13. Thecompletion time of Bootstrap using 500 bootstrap instances is much longer than the total time to learn the final heuristic(iteration 3 in Table 12) because “enough” instances were not solved in the last iteration of the Bootstrap and the processterminated due to tmax exceeding t∞. The trends in these results are the same as for the domains discussed previously.The results of BULB on the same set of test instances are shown in Table 14. For suboptimality, BULB could not competewith Bootstrap; we tried 15 values for B between 2 and 20,000. The best suboptimality achieved by BULB is shown inRow 1. It shows that even with much greater suboptimality, BULB is inferior to Bootstrap in terms of nodes generated andsolving time. BULB’s results when B is set so that BULB is approximately equal to Bootstrap (Table 13, iteration 13) in termsof nodes generated is shown in Row 2. Again Bootstrap dominates.with time limits 10 times larger than the solving time using Bootstrap’s final heuristic for each test instance∗failed to solve more than half the test instances (W was varied between 1.2 and 10). In the best case (W = 9) W-IDAsolved 24 of the test instances. An attempt to compare our results to hsum failed because the heuristics used in the feature∗W-IDAS. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–20982089Table 1220-Blocks world, Bootstrap (500 bootstrap instances).Iteration123 (final)No. solvedTotal unsolvedAvg. subopt.Avg. nodes gen.Avg. solving timeLearning time7595903382431671.8%2.4%3.8%13, 456,726,5198886,906,652615,908,78555,213 s35,692 s2763 s11 h1 d 02 h1 d 10 hBootstrap completion time = 2 daysTable 1320-Blocks world, Bootstrap (5000 bootstrap instances).Iteration345678910111213 (final)No. solvedTotal unsolvedAvg. subopt.Avg. nodes gen.Avg. solving timeLearning time275290450556162117508377988389278124912041148513231206698321223140512.2%3.2%3.5%4.0%4.1%5.4%6.5%8.0%8.7%8.9%9.6%12,771,331,0898,885,364,397941,847,444660,532,208789,515,580191,696,47622,413,31211,347,28217,443,3787,530,3295,523,98352,430 s35,636 s3828 s2734 s3240 s791 s93 s47 s72 s31 s23 s3 d 06 h4 d 04 h5 d 21 h7 d 03 h8 d 05 h9 d 05 h9 d 22 h10 d 18 h10 d 10 h10 d 20 h11 d 01 hBootstrap completion time =11 days and 1 hourTable 1420-Blocks world, other methods.Row12h (Algorithm)h0 (BULB, B = 20,000)h0 (BULB, B = 2400)Avg. subopt.Avg. nodes gen.Avg. solving time28.8%58.8%278,209,9805,809,7912482 s32 svector were so weak that even the sum of these values is still a weak heuristic for this domain. hsum failed to solve anyinstance given a time limit of one day per instance.4. Solving single instances quicklyThe preceding experiments demonstrate that bootstrap learning can help to speed up search dramatically with relativelylittle degradation in solution quality. An inherent and non-negligible expense is the time invested in learning the heuristicfunction. The Bootstrap completion times reported are on the order of days. Such a lengthy process would be warranted ifthe final heuristic was going to be used to solve numerous problem instances that were distributed in the same way as thebootstrap instances, since one would expect most of the new instances would be solved as quickly with the final heuristicas the bootstrap instances were, i.e., within the time limit used in the last iteration of the bootstrap process.However, many planning problems require just a single instance to be solved—a task for which our bootstrapping ap-proach may seem ill-suited because of the large total time required. In this section we investigate whether a variation ofour bootstrapping method can quickly solve a single instance of a given problem domain. Instead of minimizing solvingtime at the expense of requiring very large learning times, as in the previous sections, we are now looking for a balancein the learning and solving times so that the sum of the learning and solving times is made as small as can be. With thisgoal in mind, we present a method that involves interleaving the learning and solving processes. The method is fully au-tomatic once the ratio of solving time to learning time is specified. We present experimental results on the 24-puzzle, the35-pancake puzzle, Rubik’s Cube, the 20-blocks world and the IPC2 blocksworld instances. In all domains other than Rubik’sCube, interleaving bootstrap learning and problem-solving proves very effective at solving single instances.4.1. Method and implementationAn important factor influencing the total time for the bootstrap process in the previous experiments is the number ofbootstrap instances. For instance, Tables 3 and 4 show that increasing this number from 500 to 5000 increases the totaltime from 12 hours to 5 days for the 24-puzzle. In fact, a very large portion of the training time is spent on trying to solvebootstrap instances that are still too difficult for the current heuristic. This suggests that considerable time could be savedif we ran our system without any initial bootstrap instances given at the outset, just using random walks to create training∗instances at successive levels of difficulty until a heuristic was created with which the one and only target instance inscould be quickly solved. Following Algorithm 2, this procedure would basically work as follows, starting with h being theinitial heuristic.2090S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098∗If h is too weak to solve inswithin a time limit of tmax, generate a set RWIns of instances by random walks backwardfrom the goal. Improve h by applying the bootstrap procedure (Algorithm 1) to (h0, h, RWIns), where h0 = h. Repeat thiscan be solved using the current heuristicprocess, increasing the length of the random walks in each iteration, until insh within a time limit of tmax.∗∗The total time required by this procedure, including training time and solving time, would be the measure for evaluation.The obvious problem with this approach is the use of the parameter tmax, because the total time will strongly dependon the value of this parameter. If tmax is too low, we might need many iterations. If tmax is too high, we force the solver,when using too weak a heuristic, to spend the full amount of tmax in vain while it would be advantageous to invest more inlearning. Automatic adjustment of tmax involves the time-consuming process of attempting to solve a non-negligible numberof instances created by RandomWalk, and hence the naive method just described is expected to be infeasible.Avoiding tmax completely by fixing a training time and then trying to solve inswith the heuristic learned after the fixedamount of training is not any more promising. Here the training time is the critical parameter that cannot be set withoutprior knowledge.Our approach to an automated process that does not hinge critically on such parameters is to interleave learning andsolving as follows. We alternate between the execution of two threads, a learning thread and a solving thread. The learningthread runs the RandomWalk process in the manner just described to produce a sequence of stronger and stronger heuris-∗. Initially this thread usestics. The solving thread uses the heuristics generated by the RandomWalk process to solve insthe initial heuristic. When a new heuristic is produced, the solving thread is updated to take into account the existence ofa new, probably stronger, heuristic.There are many possible ways of updating the solving thread when a new heuristic becomes available; here we examinejust three.1. The simplest approach to updating the solving thread is to abort the current search and start a new search from scratchusing the new heuristic. We call this approach “Immediate Restart”.2. The second approach is to finish the current IDA∗∗that iteration ends without solving insiteration uses the new heuristic, h, and IDAit will have computed the IDA∗bound max(DB, h(ins∗iteration but using the new heuristic instead of the previous one. Ifbound, DB, to use on the next iteration. The next∗)). We call this approach “Heuristic Replacement”.3. The third approach is to subdivide the solving thread into a set of solving sub-threads, one for each heuristic that isknown. As soon as a new heuristic is learned in the learning thread, this approach starts an additional solving sub-. In this approach no thread is ever stopped completely untilthread, which uses the new heuristic to try to solve insinsis solved in one of the solving sub-threads. We call this approach “Independent Solvers”.6∗∗Regardless of the approach, the total time by which we evaluate the interleaved learning and solving process is the sum ofthe times used by both threads (including all the sub-threads) up to the point when insis solved in one sub-thread.∗∗or until ts seconds have elapsed. If insPseudocode for the interleaved learning and solving processes for the Immediate Restart and Heuristic Replacementapproaches is shown in Algorithm 3. We use a fixed ratio, ts : tl, of the time allocated to solving (ts) and the time allocatedto learning (tl).7 Line 3 calls “continue” with the Solver thread and a time limit ts. This executes the solver until it hasis not yet solved the loop (lines 4–10) is executed until it is. Line 5 callssolved ins“continue” with the RandomWalk procedure described above and a time limit tl. This resumes execution of the RandomWalkprocess at the point where it was previously suspended, runs it for time tl, suspends it, and returns whatever its currentheuristic is at the time of suspension. If the heuristic returned is new, the solving thread is updated, as described above, totake into account the new heuristic (line 7). Line 9 resumes the (updated) solving thread. The entire process stops when asolution for insis found.∗∗Algorithm 3, hin, ts , tl ): solutionh := continue(RandomWalk, tl)if (h is a new heuristic) then∗1: procedure Interleaving(ins2: Create a solving thread, Solver, using hin.3: solved := continue(Solver, ts)4: while (!solved) do5:6:7:8:9:10: end while11: return the solution from the solving threadend ifsolved := continue(Solver, ts)UPDATE(Solver, h)6 As opposed to the other two approaches, Independent Solvers has the advantage that it can easily be parallelized.7 Technically, not only is the ratio of solving time to learning time given, but also the actual time units. Using a “ratio” of 100:200 will in practice yielddifferent results than a “ratio” of 1:2. For simplicity, and since we always set ts = 1 second in our experiments, we still use the term “ratio” to refer to thesetting of ts and tl .S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–20982091Determining the best ratio ts : tl for each domain is beyond the scope of this paper; in the current system the ratio hasto be set manually. Generally, the weaker the initial heuristic the more the ratio should allocate time to the learning thread.We ran experiments with ratios of 1:1 to 1:10 and, if necessary, for larger values of tl; see Section 4.2 for details. Since theinitial heuristics in our experiments are always rather weak, we did not use ratios favouring the solving thread.Pseudocode for the interleaved learning and solving processes for the Independent Solvers approach is shown in Algo-rithm 4. It follows exactly the same general pattern as Algorithm 3, but there is a growing list of Solvers instead of justone Solver. When a new heuristic is learned a new solving sub-thread using this heuristic is added at the beginning of thelist. The procedure IndependentSolvers divides the available time for solving, ts, among the set of available solving threads—is solved in one of theexactly how this is done is described in the next paragraph. No thread is terminated until inssolving sub-threads.∗Algorithm 4, hin, ts, tl ): solutionh := continue(RandomWalk, tl)if (h is a new heuristic) then∗1: procedure Interleaving(ins2: Create a list, Solvers, containing just one solving sub-thread using hin.3: solved := IndependentSolvers(Solvers, ts)4: while (!solved) do5:6:7:8:9:10: end while11: return the solution from the independent solving sub-threadsend ifsolved := IndependentSolvers(Solvers, ts)add a solving sub-thread using h to the beginning of SolversFor the allocation of solving time among the various solving sub-threads, many strategies are possible. The one wereport here we call “Exponential”. When a new heuristic is learned, this strategy halves the time allocated to the solvingsub-threads using previous heuristics and allocates ts2 seconds to the sub-thread using the new heuristic. Thus the solvingsub-thread for the new heuristic gets half the total time available for solving on each round until another heuristic iscreated. The motivation for this strategy is that heuristics created later in the learning process are expected to be strongerthan those created at early stages, so the more recently created heuristics may be more likely to quickly solve the targetinstance. It therefore seems reasonable to invest more time in solvers using the heuristics learned in later iterations. Thereason not to suspend solving sub-threads with weak heuristics completely is that there is still a chance that they arecloser to finding a solution than the solving sub-thread using the most recently created heuristic. This may be (i) becausemore time has already been invested in the sub-threads using weaker heuristics or (ii) because a weaker heuristic mayoccasionally still behave better on one particular target instance than an overall stronger heuristic.Other strategies, such as Röger and Helmert’s alternation technique [39], are certainly possible.8Algorithm 5t := t/2S := ith sub-thread in Solversif i (cid:5)= |Solvers| then1: procedure IndependentSolvers (exponential) (Solvers, time): status2: t := time3: for i = 1 to |Solvers| do4:5:6:7:8:9:10:11: end for12: return falseend ifif continue(S, t) succeeds thenreturn trueend ifPseudocode for the Exponential time allocation strategy is shown in Algorithm 5. The time invested in the solving sub-thread using the best available heuristic (the first in the Solvers list) is twice as large as that invested in the sub-threadusing the second best heuristic, which again is a factor of two larger than the time for the next “weaker” sub-thread, andso on. The weakest two sub-threads will always be allocated the same amount of time, so that the total time spent on thesub-threads sums up to the time allocated to the solving thread overall.This strategy for allocating the total solving time into time budgets for the currently available heuristic solvers borrowsfrom the hyperbolic dove-tailing approach to interleaved search introduced by Kirkpatrick [28]. Kirkpatrick proved his ap-proach to be average-case optimal and worst-case optimal for a certain variation of the so-called cow path problem, whichwas first studied by Baeza-Yates, Culberson, and Rawlins [2]. However, this variation of the cow path problem does not8 Not reported here are the results of using a uniform strategy, which allocates the same amount of time to all solving sub-threads. We found itsperformance inferior to that of the “Exponential” strategy. See Jabbari Arfaee’s thesis [26] for details.2092S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098Table 15Solving a single instance of the 24-puzzle.RowRatio (ts : tl)Immediate restart1:11:21:5 (best)123Heuristic replacement45671:11:21:51:6 (best)Independent solvers (exponential)1:11:21:51:10 (best)891011minmaxmeanmedstdSubopt.5 m 30 s4 m 24 s4 m 04 s5 m 30 s4 m 16 s4 m 04 s3 m 58 s20 m 48 s15 m 36 s12 m 30 s11 m 31 s62 m 05 s47 m 04 s51 m 00 s61 m 54 s36 m 30 s37 m 32 s36 m 34 s44 m 54 s43 m 36 s42 m 42 s53 m 46 s18 m 49 s15 m 54 s15 m 24 s18 m 19 s15 m 06 s14 m 28 s14 m 05 s23 m 36 s18 m 03 s15 m 50 s15 m 48 s17 m 25 s14 m 18 s15 m 18 s17 m 03 s13 m 52 s14 m 08 s13 m 56 s21 m 54 s16 m 30 s14 m 30 s14 m 14 s8 m 45 s6 m 54 s7 m 58 s8 m 29 s5 m 48 s5 m 57 s5 m 48 s4 m 07 s4 m 15 s5 m 53 s6 m 55 s6.3%6.4%6.5%6.2%6.3%6.3%6.5%6.4%6.7%6.9%7.0%exactly model the search problem we are facing. Hence we do not have any formal guarantees on the efficiency of ourmethod.4.2. ExperimentsWe ran experiments comparing the three versions of our interleaving approach, with different ts : tl ratios, on the samedomains used in Section 3. The experimental settings for each domain, i.e., the features, and the neural network settingswere the same as those described in Section 3, and we used the same computer. The test instances used for each domain inSection 3 are here used as individual target instances for testing. We also report results on the IPC2 blocksworld instances,along with comparisons to state-of-the-art planners on those instances. In all our experiments, the parameter ts used inAlgorithm 4 was set to 1 second, while tl was varied from 1 to 10 seconds in steps of 1. Whenever the ratio 1:10 resultedin a lower mean total time than the ratios 1:1 to 1:9, we also tested the ratios 1:11, 1:12, etc. until the mean total timestarted increasing again. The ratio resulting in the lowest total time is marked in the tables below as the “best” ratio. Thetables only show the results for ratios 1:1, 1:2, 1:5, and the best ratio.4.2.1. 24-PuzzleTable 15 shows the results for our three interleaving strategies for the solvers. The “min”, “max”, “mean”, “med” and“std” columns, respectively, show the minimum, maximum, mean, median, and standard deviation, of the total times on the50 instances of the 24-puzzle that were used for this experiment. The “subopt.” column shows the average suboptimality ofthe solutions found, calculated in the same manner as in Section 3. The trends apparent in these results are:• The average suboptimality increases as the ts : tl ratio increases in favour of the learning thread. This can be explainedby the trends observed in Section 3. There we have seen that more bootstrap iterations result in larger suboptimality.Since more bootstrap iterations also result in stronger heuristics, the target instance is more likely to be solved first byone of the strongest heuristics created in the interleaving process. A solver using this stronger heuristic, though solvingthe target instance faster, provides a solution that has a higher cost than the solutions that solvers using the weakerheuristics would have eventually provided.• The mean and median values initially decrease with growing tl, i.e., when the ts : tl ratio favours the learning thread.It turns out that, on average, the heuristic that solves the target instance requires only a few seconds of solving time.Therefore, most of the solving time is spent on unsuccessful trials using other heuristics. Increasing the learning timemakes the system produce stronger heuristics faster. This in turn decreases the total solving time for most instances(mean and median decreases). However, the mean and median values eventually start to increase at some point. Thishappens for the following reason. As just noted, the heuristic that solves the target instance requires a few seconds ofsolving time. Since ts is one second, this means that the solving thread must be suspended and resumed a few times inorder for this heuristic to completely solve an instance. As tl increases this heuristic gets created sooner but the delaysbetween suspending and resuming the solving thread also get longer (they are length tl), and for a sufficiently large tlthe increase in the delays between solving episodes outweigh the advantage of creating the heuristic sooner.• The mean total times for the best ratio of all three strategies is similar (less than 10% difference).The mean total time spent on a target instance (including the learning time)—under 16 minutes (960 seconds)—issubstantially lower than the total time spent by our bootstrap system using a large set of bootstrap instances but no inter-leaving. According to Tables 3 and 4, the latter requires more than 11 hours when using 500 bootstrap instances and almost5 days when using 5000 bootstrap instances. Alternatively, to minimize learning time one could consider using the heuristicsS. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–20982093Table 16Solving a single instance of the 35-pancake puzzle.RowRatio (ts : tl)Immediate restart12341:11:21:51:6 (best)Heuristic replacement56781:11:21:51:8 (best)Independent solvers (exponential)1:11:21:51:9 (best)9101112minmaxmeanmed2 h 36 m2 h 07 m1 h 45 m1 h 37 m2 h 34 m2 h 06 m1 h 45 m1 h 39 m7 h 13 m5 h 24 m4 h 19 m1 h 50 m6 h 48 m5 h 18 m5 h 57 m4 h 29 m6 h 45 m5 h 15 m5 h 00 m4 h 54 m9 h 48 m7 h 28 m6 h 42 m7 h 01 m3 h 41 m2 h 54 m2 h 38 m2 h 07 m3 h 36 m2 h 50 m2 h 34 m2 h 29 m7 h 36 m5 h 45 m4 h 45 m3 h 23 m3 h 24 m2 h 39 m2 h 26 m2 h 07 m3 h 24 m2 h 39 m2 h 19 m2 h 14 m7 h 28 m5 h 32 m4 h 39 m3 h 28 mstd46 m40 m48 m33 m42 m38 m42 m42 m30 m24 m28 m50 mSubopt.7.5%8.0%8.2%8.3%7.6%8.0%8.2%8.1%7.8%8.0%8.3%8.9%created by the first bootstrap iteration. With 5000 bootstrap instances, this heuristic solves instances considerably slower, onaverage, than the interleaving methods (2364.9 seconds, or about 39 minutes—see iteration 0 in Table 4—compared to under16 minutes). The heuristic created on the first iteration of bootstrapping with 500 bootstrap instances solves instances fasterthan interleaving (153.34 seconds, or about 2.5 minutes—see iteration 0 in Table 3), but it takes 98 minutes to learn thisheuristic (see the “Learning time” column for iteration 0 in Table 3). Therefore, our method to solve a target instance hassubstantial speedup over the normal bootstrap method. Our method also fares well in comparison to the systems reported∗ (W = 1.5) and has a suboptimality superior to BULB (B = 20,000) and far superior to hsum.in Table 5. It dominates W-IDAIts total time (under 960 seconds) is less than that of any of the optimal methods. Its time is inferior to that of the weightedRBFS system reported in line 9 of Table 5 but its suboptimality is superior. Comparisons with the PE-ANN system in lines10 and 11 of Table 5 are not possible because the training times for that system are unknown.If Bootstrap is given a strong initial heuristic h0 (the maximum of disjoint 6-6-6-6 PDBs and their reflections), thetotal times are similar to those reported in Table 15, but the suboptimality reduces to roughly 4% for all the interleavingstrategies.4.2.2. 35-Pancake puzzleTable 16 provides detailed results for the 35-pancake puzzle. The trends observed in this experiment are similar to thoseobserved for the 24-puzzle except here the Independent Solvers strategy has mean and median times that are considerablyhigher than those of the other two strategies.The suboptimality of the heuristics produced by any of the interleaving strategies is superior to any of the suboptimalitiesreported for basic bootstrapping in Tables 6 and 7, and the mean total solving time for the interleaving strategies are lessthan half the time required to finish the first bootstrapping iteration with 500 bootstrap instances (7 hours—see Table 6). In∗ (W = 9), or BULB (B (cid:2) 20,000), than usingTable 8 we see that instances are solved much more quickly using hsum, W-IDAany of our interleaving methods, but with much greater suboptimality.If Bootstrap is given a strong initial heuristic h0 (a 5-5-5-5-5-5-5 additive PDB), the total times are slightly smaller thanin Table 16 and suboptimality decreases to around 4.5% for all the interleaving strategies.4.2.3. Rubik’s CubeTable 17 shows the experimental results for Rubik’s Cube. As for the 35-pancake puzzle, the Independent Solvers strategyhas mean and median times that are considerably higher than the other two strategies.The reason the suboptimality is the same for all variations tested is that in all cases, almost all the instances are solvedusing the third heuristic created by bootstrapping. This happens because h0 and the first two learned heuristics are veryweak, and too much time (25 hours) is needed to learn the fourth heuristic. This may also explain why the best ratio hereis smaller than for the other domains.Although interleaving is very much superior to the basic bootstrapping process when there is only a single Rubik’s Cubeinstance to solve, the best mean total time in Table 17 (10 hours and 54 minutes, or 39,240 seconds) is only 11% betterthan the time required to solve an average instance optimally using the best known heuristic for Rubik’s Cube (44,201seconds, see Row 6 of Table 11). However, all the interleaving strategies shown in Table 17 outperform simply using ourinitial heuristic to solve each instance, which requires 102,362 seconds (28 hours and 26 minutes) on average (see Row 4which, with W = 1.4, requires more time to solveof Table 11). Heuristic Replacement with a 1:5 ratio dominates W-IDAan instance (12 hours and 36 minutes on average) and produces a greater suboptimality (13.3% compared to 6.4%).∗2094S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098Table 17Solving a single instance of Rubik’s Cube.RowRatio (ts : tl)Immediate restart1:111:2 (best)21:53Heuristic replacement4561:11:21:5 (best)Independent solvers (exponential)1:171:2 (best)81:59minmaxmeanmedstdSubopt.0 h 41 m1 h 01 m2 h 01 m0 h 41 m1 h 01 m2 h 01 m1 h 22 m2 h 02 m4 h 03 m19 h 27 m19 h 48 m28 h 01 m18 h 43 m17 h 54 m19 h 41 m26 h 16 m29 h 54 m29 h 29 m13 h 29 m11 h 42 m13 h 08 m13 h 21 m11 h 18 m10 h 54 m15 h 36 m14 h 51 m17 h 23 m13 h 50 m11 h 18 m11 h 10 m13 h 28 m10 h 42 m9 h 16 m15 h 02 m13 h 04 m14 h 45 m4 h 54 m4 h 45 m7 h 02 m4 h 59 m4 h 45 m5 h 24 m6 h 34 m4 h 45 m4 h 30 m6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%Table 18Solving a single instance of the 20-blocks world.RowRatio (ts : tl)Immediate restart12341:11:21:51:9 (best)Heuristic replacement5671:11:21:5 (best)Independent solvers (exponential)1:11:21:5 (best)8910min17 m17 m10 m26 m17 m17 m10 m17 m17 m10 m4.2.4. 20-Blocks worldmaxmeanmedstdSubopt.25 h 38 m19 h 24 m15 h 58 m15 h 48 m25 h 35 m19 h 22 m15 h 55 m25 h 52 m19 h 44 m15 h 48 m5 h 18 m4 h 28 m4 h 15 m4 h 01 m5 h 00 m4 h 16 m4 h 06 m6 h 04 m4 h 52 m3 h 49 m1 h 22 m1 h 28 m1 h 24 m2 h 00 m1 h 23 m1 h 16 m1 h 22 m2 h 03 m1 h 52 m1 h 24 m7 h 28 m5 h 53 m5 h 15 m4 h 40 m7 h 17 m5 h 46 m5 h 12 m7 h 38 m5 h 58 m4 h 45 m1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%Table 18 shows the experimental results for the 20-blocks world. In each case the solutions were only 1.3% longer thanoptimal, on average, and at least 37 of the 50 instances were solved optimally. Unlike the previous domains, here theIndependent Solvers strategy slightly outperforms the others in terms of mean total time.In this experiment, our initial heuristic is so weak that it takes a few iterations of RandomWalk until the heuristicbecomes sufficiently strong that the solver using it can solve the instance in a reasonable amount of time. After this point,for a few iterations, the learned heuristics enable the instances to be solved more quickly without changing the solutionquality. For this reason, we observe a constant suboptimality of 1.3% for all different strategies.The speedup compared to the initial bootstrap method (which needed 2 days when using 500 bootstrap instances and11 days when using 5000 bootstrap instances) is again remarkable. In addition, the solution lengths are much closer tooptimal than before (cf. Tables 12 and 13 for Bootstrap results on the 20-blocks world).BULB with B (cid:2) 20,000 would solve a single instance faster than our method (see Table 14), but even for B = 20,000 thewe were unable to find a value of Wsuboptimality would be more than 20 times higher than that of Bootstrap. For W-IDAthat can solve all the test instances in a reasonable amount of time with a suboptimality close to our interleaving methodso we base our comparison on the instances solved using a 2-hour time limit per instance. Heuristic Replacement with aratio of 1:5 solved 27 of the 50 instances with this time limit and its solutions were just 2.4% suboptimal. With this timelimit W-IDA∗ (W = 4) also solved 27 instances but its suboptimality was 150%.∗4.2.5. IPC2 blocks world instancesWe further tested our interleaving technique on the 35 instances of blocks world domains of varying size used inTrack 1 of the IPC2 planning competition.9 This version of the blocks world has a “hand” that is used to pick up and putdown blocks, as opposed to the “handless” version we have used in the 20-blocks world experiments elsewhere in thispaper. Despite this difference we used the same features and initial heuristic here as in the previous experiments with the“handless” 20-blocks world.9 See http://www.cs.toronto.edu/aips2000/ for more details.S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–20982095Table 19IPC2 blocks world instances, results for interleaving using the exponential allocation strategy.InstanceOptimalRatio (1:1)Ratio (1:2)Ratio (1:5)TimeSubopt.TimeSubopt.TimeSubopt.9-09-19-210-010-110-211-011-111-212-012-113-013-114-014-115-015-116-116-217-0302826343234323032343442443836405254524822137358212314511702362313627134710013314.8%5%33195842318411021024517331047512717512584.8%5%65238474663799148616717624239311056032304.8%5%Table 19 shows the results on the hardest 20 instances of the IPC2 set. The first column names the instances, where x– yrefers to the yth instance that consists of x blocks. The other columns show the total time (in seconds) and suboptimalityachieved by our interleaving method using the exponential allocation strategy. In this table, empty “Time” entries indicatethat the total time was below 0.1 seconds and empty “Subopt.” entries indicate the instance was solved optimally. The 15instances with the fewest blocks (between 4 and 8) are not shown; all were solved optimally by our system in less than0.1 seconds. Table 19 shows that our interleaving method is capable of solving all the instances in less than 30 minutes (thetime limit for solving an instance in the IPC2 competition) while the solutions are almost always optimal, and those thatare not optimal are very close to optimal.The Fast Downward planner [19], with the setting10 that uses multi-heuristic best-first search11 and preferred operators,also solved all 35 of these blocks world instances. It took Fast Downward, on average, less than a second to solve eachinstance, and its solutions are 200% suboptimal.12 Our interleaving approach required much more time (about 138 seconds,on average) but found solutions that were only 0.3% suboptimal.The FF planner [23] solved 29 of the 35 instances in the time limit of 30 minutes. The solutions generated for the solvedinstances were 2.3% suboptimal and it took less than 6 seconds, on average, for FF to solve one of these 29 instances.These 29 instances were all solved optimally by our interleaving approach but in a greater amount of time (25 seconds) onaverage. Of course, our method was also able to solve the 6 problems in 30 minutes that FF could not.The best performing optimal planners from IPC5 such as Gamer and HSP13 solved 30 of the 35 instances within a timelimit of 30 minutes [21].14 Furthermore, the landmark cut heuristic [21], which is competitive with the state-of-the-artoptimal planners in overall performance, solved 28 of the 35 instances within the same time limit. Its average solving timeon these 28 instances was 76 seconds. Our interleaving approach also solved these 28 instances optimally, and did so inless than 19 second on average.∗FYoon, Fern, and Givan [49] report two sets of results on these blocks world instances. One set is for a method theypresent for learning a heuristic function to guide planning, the other is for a method they present for learning a decisionlist policy to guide planning. In both cases they learned from the solutions found by solving the easiest 15 instances (theones not shown in Table 19) with FF’s heuristic and then solved the remaining 20 instances with the learned heuristic/policyin conjunction with FF’s heuristic. Their methods are therefore “one step” methods, they are not methods aimed at solvingsingle instances quickly. The learning phase for the method that learned a heuristic took 600 seconds. They then took12.94 seconds, on average, to solve each of the 20 test instances (all 20 were solved within the 30-minute time limit). Thesolutions found had an average suboptimality of 120%.15 Our interleaving method solved the same instances in 242 seconds,10 This setting is referred to as “M + P” in Helmert’s paper [19].11 This search algorithm is a best-first search algorithm that alternates between expanding nodes from different open lists that are sorted based ondifferent heuristics [39]. Here, the casual graph heuristic [19] and FF’s relaxed plan heuristic [23] are used.12 All results for the planning systems discussed here are taken from the papers cited.13 See http://ipc.informatik.uni-freiburg.de/ for more details about the competition and the planners.14 Neither the solving time nor the instances solved is reported for these two planners.15 Fern et al. computed average suboptimality differently than we have defined it in this paper. They defined average suboptimality as the total lengthof the solutions found divided by the total length of the optimal solutions. In this paragraph, we use their method to compute the suboptimality of oursystems to allow a comparison to be made.2096S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098on average, with almost optimal solutions (the average suboptimality was 0.5%). Our single-instance method could thereforesolve approximately 3 problems from scratch in the same time that their method could perform learning once and solve3 problems. Their method for learning a decision list policy took less time to learn and solve a single instance than ourmethod (100.05 seconds, on average) but produced longer solutions (their average suboptimality was 17%).5. Related workBootstrap learning to iteratively improve an initially weak evaluation function for single-agent search is an idea due toRendell [37,38], who used it to enable unidirectional search to solve random instances of the 15-puzzle for the first time.Our method differs from Rendell’s in several key details, the most important being that Rendell assumed the user wouldprovide a set of bootstrap instances for each iteration, at least one of which was required to be solvable using the currentevaluation function. We, on the other hand, assume that the entire set of bootstrap instances is given at the outset, and ifthe initial system cannot solve any of them it generates its own instances.The only other study of bootstrap learning of heuristics is due to Humphrey, Bramanti-Gregor, and Davis [25]. Their SACHsystem learns a heuristic to solve a single instance, and the bootstrapping is done over successive failed attempts to solvethe instance. Impressive results were obtained on the fifteen most difficult standard 100 instances of the 15-puzzle. Onaverage these instances were solved by A* with only 724,032 nodes generated in total over all of SACH’s iterations, and thesolutions found were only 2% suboptimal.Hauptman et al. [17,18] use genetic programming [33] to iteratively improve an initial population of heuristic functions.The key difference between this and bootstrapping is that it creates new heuristics by mutating and recombining heuristicsin its current population rather than learning a new heuristic from solved instances. Training instances in their system(the analog of our bootstrap instances) are used only for evaluating the fitness of the newly created heuristics. The mainapplication to date has been to the standard 6 × 6 Rush Hour puzzle, which is sufficiently small (3.6 × 1010) that mostinstances can be solved quickly even without a heuristic, hence guaranteeing that the evaluation of fitness will succeedin distinguishing better heuristics from worse ones. The heuristic learned by their system reduced the number of nodesgenerated by an IDAvariant by a factor of 2.5 compared to search with no heuristic. The time required for learning andthe suboptimality of the solutions generated were not reported. They have also used FreeCell as testbed [17], but in thatapplication a policy was evolved to guide search, not a heuristic function.∗The online learning of heuristics as studied by Fink [13] is also related to bootstrapping. Fink proves his learning algo-rithm has certain desirable properties, but it has the practical shortcoming that it requires optimal solution lengths to beknown for all states that are generated during all of the searches.Thayer, Dionne, and Ruml [47] used online learning to update an initial heuristic function during a greedy best-firstsearch that aims at solving a specific instance of a search problem. They computed the error of the heuristic after each nodeis expanded by the search algorithm. The error is defined as the difference between the heuristic value of the state and thesum of the heuristic value of the child with the largest heuristic estimate and the cost of the action that generates the child.This error estimate is then used to update the heuristic function during search. Their experimental results showed that whensuch an update is used with the greedy best-first search, it can improve the performance of the initial heuristic in terms ofboth solution quality and solving time. For example, the heuristic created by this system improves over Manhattan Distancein the 15-puzzle by a factor of about 3 in terms of solution cost and by factor of about 2 in terms of time needed to solveeach problem instance. In their experiments, Thayer et al. included a system, “ANN-offline, which learns a heuristic in aone-step manner resembling the system of Ernandes and Gori [9]. This produced a heuristic that was much more accuratethan the heuristic learned by their online method but, interestingly, much poorer at guiding greedy best-first search. Asthey observe, this highlights the different requirements for heuristics that are used for pruning unpromising paths, which isthe focus of our paper, compared to heuristics that are used to determine the order in which paths are to be explored.Other systems for learning heuristics limit themselves to just one step of what could be a bootstrapping process [9,35,41,43,44,49]. Such systems typically assume the initial heuristic (h0) is sufficiently strong that arbitrary instances can be solvedwith it, and use learning to create a better heuristic, i.e., one that allows instances to be solved more quickly than with h0although perhaps with greater suboptimality. If our bootstrap method is given an initial heuristic as strong as these systemsrequire, it performs the same as they do, i.e., it performs only one iteration and produces an improved heuristic withoutintroducing much suboptimality. For example, on the 15-puzzle Samadi et al.’s one-step system [41] creates a heuristic thatallows solutions to random solvable instances to be found by RBFS after generating only 2241 nodes, on average, and thesolutions found are only 3.3% longer than optimal. Our system, if supplied with an initial heuristic comparable in strengthto Samadi et al.’s initial heuristic, terminates after one iteration with a heuristic that allows solutions to the same instancesto be found by RBFS after generating only 9402 nodes, and the solutions found are only 0.5% longer than optimal [27]. Ofcourse, our bootstrapping method has the advantage over these systems that it does not require a strong initial heuristic;it will succeed even if given an initial heuristic so weak that it cannot solve any of the bootstrap instances in a reasonableamount of time.Two previous systems have used random walks to generate successively more difficult instances to bootstrap the learningof search control knowledge in a form other than a heuristic function. Fern, Yoon, and Givan [12] used random walks inlearning policies to control a Markov Decision Process, and Finkelstein and Markovitch [14] used them in the context ofS. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–20982097learning macro-operators to augment a heuristic-guided hill-climbing search. In both cases the initial random walk lengthand the increment were user-specified.6. ConclusionsThis paper gives experimental evidence that machine learning can be used to create strong heuristics from very weakones through an automatic, incremental bootstrapping process augmented by a random walk method for generating succes-sively more difficult problem instances. Our system was tested on four problem domains that are at or beyond the limit ofcurrent abstraction methods and in each case it successfully created heuristics that enable IDAto solve randomly generatedtest instances quickly and almost optimally. The total time needed for this system to create these heuristics strongly dependson the number of bootstrap instances it is given. Using 500 bootstrap instances, heuristics are produced approximately 10times faster than using 5000 bootstrap instances. Search is slower with the heuristics produced using fewer bootstrap in-stances, but the solutions found are closer to optimal. This work significantly extends previous, one-step methods that failunless they are given a very strong heuristic to start with.∗The total time for the bootstrap process to create strong heuristics for these large state spaces is on the order of days.This is acceptable when the learning time can be amortized over a large number of test instances. To make heuristic learningeffective when only a single problem instance needs to be solved, we presented a variation in which the bootstrap learningof new heuristics is interleaved with problem-solving using the initial heuristic and whatever heuristics have been learnedso far. When tested on the same four domains, this method was shown to substantially reduce the total time needed tosolve a single instance while still producing solutions that are very close to optimal. When applied to the blocksworldinstances used in the IPC2 planning competition, our interleaving method solved all the instances within the 30-minutetime limit, and almost all were solved optimally.AcknowledgementsThanks to Neil Burch, Richard Valenzano, Mehdi Samadi, Fan Yang, Uzi Zahavi, and Ariel Felner for sharing their code,Jonathan Schaeffer for suggesting the ideas of heuristic replacement and immediate restart, reviewers for their insightfulcomments, the Alberta Ingenuity Centre for Machine Learning, and NSERC.References[1] Aaron F. Archer, A modern treatment of the 15-puzzle, American Mathematical Monthly 106 (1999) 793–799.[2] Ricardo A. Baeza-Yates, Joseph C. Culberson, Gregory J.E. Rawlins, Searching in the plane, Information and Computation 106 (2) (1993) 234–252.[3] Marcel Ball, Robert C. Holte, The compression power of symbolic pattern databases, in: Proceedings of the 18th International Conference on AutomatedPlanning and Scheduling (ICAPS 2008), 2008, pp. 2–11.[4] Blai Bonet, Héctor Geffner, Planning as heuristic search, Artificial Intelligence 129 (2001) 5–33.[5] Joseph C. Culberson, Jonathan Schaeffer, Searching with pattern databases, in: Proceedings of the Canadian Conference on Artificial Intelligence, in:LNAI, vol. 1081, Springer, 1996, pp. 402–416.[6] Harry Dweighter, Problem E2569, American Mathematical Monthly 82 (1975) 1010.[7] Stefan Edelkamp, Symbolic pattern databases in heuristic search planning, in: Proceedings of the 6th International Conference on Artificial IntelligencePlanning Systems (AIPS 2002), 2002, pp. 274–283.[8] Stefan Edelkamp, Shahid Jabbar, Peter Kissmann, Scaling search with pattern databases, in: Proceedings of the 5th International Workshop on ModelChecking and Artificial Intelligence (MoChArt), in: LNCS, vol. 5348, Springer, 2009, pp. 49–65.[9] Marco Ernandes, Marco Gori, Likely-admissible and sub-symbolic heuristics, in: Proceedings of the 16th European Conference on Artificial Intelligence(ECAI 2004), 2004, pp. 613–617.[10] Ariel Felner, Amir Adler, Solving the 24 puzzle with instance dependent pattern databases, in: Proceedings of the 6th International Symposium onAbstraction, Reformulation and Approximation (SARA 2005), in: LNCS, vol. 3607, Springer, 2005, pp. 248–260.[11] Ariel Felner, Uzi Zahavi, Jonathan Schaeffer, Robert C. Holte, Dual lookups in pattern databases, in: Proceedings of the 19th International Joint Confer-ence on Artificial Intelligence (IJCAI, 2005), pp. 103–108.[12] Alan Fern, Sungwook Yoon, and Robert Givan, Learning domain-specific control knowledge from random walks, in: Proceedings of the 14th Interna-tional Conference on Automated Planning and Scheduling (ICAPS 2004), 2004, pp. 191–199.[13] Michael Fink, Online learning of search heuristics, in: Proceedings of the 11th International Conference on Artificial Intelligence and Statistics (AISTATS2007), 2007, pp. 114–122.[14] Lev Finkelstein, Shaul Markovitch, A selective macro-learning algorithm and its application to the N × N sliding-tile puzzle, Journal of Artificial Intelli-gence Research 8 (1998) 223–263.[15] David Furcy, Sven König, Limited discrepancy beam search, in: Proceedings of the 19th International Joint Conference on Artificial Intelligence (IJCAI2005), 2005, pp. 125–131.[16] Patrik Haslum, Héctor Geffner, Admissible heuristics for optimal planning, in: Proceedings of the 5th International Conference on Artificial IntelligencePlanning Systems (AIPS 2000), 2000, pp. 140–149.[17] Ami Hauptman, Achiya Elyasaf, Moshe Sipper, Evolving hyper heuristic-based solvers for Rush Hour and FreeCell, in: Proceedings of the 3rd AnnualSymposium on Combinatorial Search (SoCS 2010), 2010, pp. 149–150.[18] Ami Hauptman, Achiya Elyasaf, Moshe Sipper, Assaf Karmon, GP-rush: using genetic programming to evolve solvers for the Rush Hour puzzle, in:Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation (GECCO 2009), ACM, New York, NY, USA, 2009, pp. 955–962.[19] Malte Helmert, The Fast Downward planning system, Journal of Artificial Intelligence Research 26 (2006) 191–246.[20] Malte Helmert, Landmark heuristics for the pancake problem, in: Proceedings of the 3rd Annual Symposium on Combinatorial Search (SoCS 2010),2010, pp. 109–110.[21] Malte Helmert, Carmel Domshlak, Landmarks, critical paths and abstractions: What’s the difference anyway? in: Proceedings of the 19th InternationalConference on Automated Planning and Scheduling (ICAPS 2009), 2009, pp. 162–169.2098S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098[22] Malte Helmert, Gabriele Röger, Relative-order abstractions for the pancake problem, in: Proceedings of the 19th European Conference on ArtificialIntelligence (ECAI 2010), 2010, pp. 745–750.[23] Jörg Hoffmann, Bernhard Nebel, The FF planning system: Fast plan generation through heuristic search, Journal of Artificial Intelligence Research 14(2001) 253–302.[24] Robert C. Holte, Jeffery Grajkowski, Brian Tanner, Hierarchical heuristic search revisited, in: Proceedings of the 6th International Symposium on Ab-straction, Reformulation and Approximation (SARA 2005), in: LNAI, vol. 3607, Springer, 2005, pp. 121–133.[25] Timothy Humphrey, Anna Bramanti-Gregor, Henry W. Davis, Learning while solving problems in single agent search: Preliminary results, in: Proceed-ings of the 4th Congress of the Italian Association for Artificial Intelligence (AI*IA 1995), in: LNCS, vol. 992, Springer, 1995, pp. 56–66.[26] Shahab Jabbari Arfaee, Bootstrap learning of heuristic functions, Master’s thesis, Computing Science Department, University of Alberta, 2010.[27] Shahab Jabbari Arfaee, Sandra Zilles, Robert C. Holte, Bootstrap learning of heuristic functions, in: Proceedings of the 3rd Annual Symposium onCombinatorial Search (SoCS 2010), 2010, pp. 52–60.[28] David G. Kirkpatrick, Hyperbolic dovetailing, in: Proceedings of the 17th Annual European Symposium on Algorithms (ESA 2009), in: LNCS, vol. 5757,Springer, 2009, pp. 516–527.[29] Richard E. Korf, Depth-first iterative-deepening: An optimal admissible tree search, Artificial Intelligence 27 (1) (1985) 97–109.[30] Richard E. Korf, Linear-space best-first search: Summary of results, in: Proceedings of the 10th AAAI Conference on Artificial Intelligence (AAAI 1992),1992, pp. 533–538.[31] Richard E. Korf, Finding optimal solutions to Rubik’s Cube using pattern databases, in: Proceedings of the 14th AAAI Conference on Artificial Intelligence(AAAI 1997), 1997, pp. 700–705.[32] Richard E. Korf, Ariel Felner, Disjoint pattern database heuristics, Artificial Intelligence 134 (2002) 9–22.[33] John R. Koza, Genetic Programming II: Automatic Discovery of Reusable Programs, MIT Press, Cambridge MA, May 1994.[34] Judea Pearl, Heuristics, Addison–Wesley, 1984.[35] Marek Petrik, Shlomo Zilberstein, Learning heuristic functions through approximate linear programming, in: Proceedings of the 18th InternationalConference on Automated Planning and Scheduling (ICAPS 2008), 2008, pp. 248–255.[36] Armand Prieditis, Machine discovery of effective admissible heuristics, Machine Learning 12 (1993) 117–141.[37] Larry A. Rendell, Details of an automatic evaluation function generator for state-space problems, Technical Report CS-78-38, Department of ComputerScience, University of Waterloo, 1978.[38] Larry A. Rendell, A new basis for state-space learning systems and a successful implementation, Artificial Intelligence 20 (1983) 369–392.[39] Gabriele Röger, Malte Helmert, The more, the merrier: Combining heuristic estimators for satisficing planning, in: Proceedings of the 20th InternationalConference on Automated Planning and Scheduling (ICAPS 2010), 2010, pp. 246–249.[40] David E. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams, Learning internal representations by error propagation, in: Parallel Distributed Processing:Explorations in the Microstructure of Cognition, MIT Press, Cambridge, MA, USA, 1986, pp. 318–362.[41] Mehdi Samadi, Ariel Felner, Jonathan Schaeffer, Learning from multiple heuristics, in: Proceedings of the 23rd AAAI Conference on Artificial Intelligence(AAAI 2008), 2008, pp. 357–362.[42] Mehdi Samadi, Maryam Siabani, Ariel Felner, Robert Holte, Compressing pattern databases with learning, in: Proceedings of the 18th European Confer-ence on Artificial Intelligence (ECAI 2008), 2008, pp. 495–499.[43] Sudeshna Sarkar, Partha P. Chakrabarti, Sujoy Ghose, Learning while solving problems in best first search, IEEE Transactions on Systems, Man, andCybernetics, Part A 28 (1998) 535–541.[44] Sudeshna Sarkar, Sujoy Ghose, Partha P. Chakrabarti, Learning for efficient search, Sadhana: Academy Proceedings in Engineering Sciences 2 (1996)291–315.[45] John Slaney, Sylvie Thiébaux, Blocks world revisited, Artificial Intelligence 125 (2001) 119–153.[46] Jerry Slocum, Dic Sonneveld, The 15 Puzzle, Slocum Puzzle Foundation, 2006.[47] Jordan Thayer, Austin Dionne, Wheeler Ruml, Learning inadmissible heuristics during search, in: Proceedings of the 21st International Conference onAutomated Planning and Scheduling (ICAPS 2011), 2011, pp. 250–257.[48] Fan Yang, Joseph Culberson, Robert Holte, Uzi Zahavi, Ariel Felner, A general theory of additive state space abstractions, Journal of Artificial IntelligenceResearch 32 (2008) 631–662.[49] Alan Fern Sungwook Yoon, Robert Givan, Learning control knowledge for forward search planning, Journal of Machine Learning Research 9 (2008)683–718.[50] Uzi Zahavi, Ariel Felner, Robert Holte, Jonathan Schaeffer, Dual search in permutation state spaces, in: Proceedings of the 21st AAAI Conference onArtificial Intelligence (AAAI 2006), 2006, pp. 1076–1081.[51] Uzi Zahavi, Ariel Felner, Robert C. Holte, Jonathan Schaeffer, Duality in permutation state spaces and the dual search algorithm, Artificial Intelli-gence 172 (4–5) (2008) 514–540.[52] Rong Zhou, Eric A. Hansen, External-memory pattern databases using structured duplicate detection, in: Proceedings of the 20th AAAI Conference onArtificial Intelligence (AAAI 2005), 2005, pp. 1398–1405.