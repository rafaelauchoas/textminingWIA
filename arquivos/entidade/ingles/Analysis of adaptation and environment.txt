Artificial Intelligence 73 (1995) l-30 Artificial Intelligence Analysis of adaptation and environment Ian Horswill * MIT Art$cial Intelligence Laboratory Received September 1992; revised September 1994 Abstract Designers often improve the performance of artificial agents by specializing them. We can to an make a rough, but useful distinction between specialization to a task and specialization to an environment can be difficult to understand: it may be unclear environment. Specialization the agent depends, or in what manner it depends on on what properties of the environment into a each individual property. In this paper, I discuss a method for analyzing specialization series of conditional optimizations: formal transformations which, given some constraint on the environment, map mechanisms to more efficient mechanisms with equivalent behavior. I apply the technique to the analysis of the vision and control systems of a working robot system in day to day use in our laboratory. The method is not intended as a general theory for automated synthesis of arbitrary specialized agents. Nonetheless, it can be used to perform posr-hoc analysis of agents so as to make explicit the environment properties required by the agent and the computational value of each property. This post-hoc analysis helps explain performance in normal environments and predict performance in novel environments. In addition, the transformations brought out in the analysis of one system can be reused in the synthesis of future systems. 1. Introduction Scientists and mathematicians seek general principles: for one reason or another explain a large class of phenomena. Engineers forced solve a wide range of problems, mechanisms problems. than to pay the price needed individual principles seek general mechanisms, to use highly specialized ones. When one needs it may be more desirable to design a set of specialized that each but are often to to build a single mechanism that can solve all * E-mail: ian@ai.mit.edu. 0004-3702/95/$09.50 SSDIOOO4-3702(94)00057-3 @ 1995 Elsevier Science B.V. All rights reserved Computer science, being a curious combination of engineering and generality for ever simpler more compact and mathematics, often at once. Theorists and program- abstract computing (e.g. the 2-counter Turing machine [ 331 or search language designers that are still Turing-equivalent pushes both extremes of specialization ming machines the lambda calculus of specialized machines mapping [ 171. Finally, compiler designers the general machines circuits with which [ lo,41 ] ). while computer architects search for the best collections the behavior of these general computing for automatically search for better methods to emulate into specialized machines [ 31. Specialization and to an environment to a task is no different to a task (e.g. navigation Throughout this paper, I will adopt the somewhat artificial distinction vs. car assembly) of an agent cialization forests versus highways). specialization of a normal computer program explicit definition of the task and consciously agent or program. Often structure of the task, with modules of the mechanism of the overall However, of her agent’s environment agent’s assumptions the agent. Such factors conspire between spe- (e.g. than the to a task. The designer usually has an in the design of the uses that definition the internal reflects structure of the mechanism to subproblems [ 71.) formal description of the behavior In addition, the represented within the agent. These (the exception being simple virtual worlds). its environment tacit knowledge may be spread diffusely to make specialized in the case of biological are often not explicitly it is rare for a designer to have a complete is not as clear agents difficult to understand. corresponding agents, see the internal throughout about (This task. The fundamental usefully described behavior when when specialized mechanisms the paper. the agent claim of this paper in terms of transformations is situated is that environmental specialization can be over possible agents that provably preserve type of environment. The issue of the scope of in some specific should be used in the first place is outside 2. Example to avoid obstacles by turning Fig. I shows an image of an office taken with a camera mounted on a robot. Suppose we want the robot left when there is more free space to the left and right when there is more free space to the right. To do this, the robot must to the problem determine which side of the image has more free space. This amounts of finding which regions of the floor are free and which have objects on top of them. loses information, The problem depth the structure of the scene information images or of additional without additional assumptions. the image projection process in particular, and so we cannot uniquely determine in the form of additional is difficult because information either the features the problem A common way of solving is to build a complete depth map of the scene and then project in the depth map into the floor plane. Those parts of the floor onto which no features are projected will be free space. A common way of features building depth maps is to use two cameras (usually edges) can be found the matching of the features, we can compute each feature’s shift due to parallax, and from in a stereo configuration. Distinctive in the two images and matched to one another. Given I. Horswill/Art$icial Intelligence 73 (1995) l-30 3 Fig. 1. (Left) Image of an office taken from the robot’s camera. The dots in the lower middle of the image in the rendering process. The structure are artifacts due to the quantization in the lower right-hand portion of in the top-left are (left to right) a doorway viewed from the image is a Hegged an oblique angle, a small trash can, and a file cabinet. The homogeneous left is the carpet. (Right) The pixels with significant office chair. The structures in the lower and middle texture. region -Lp__ situation m image Fig. 2. An observer views a cliff of a textureless sides of the cliff may produce a local variation is still no texture depth, or even the presence, of the cliff from stereo data. surface in the image above or below the discontinuity which would allow the observer (Left). Although variations in image brightness at the point of discontinuity in lighting of the two there (Right), to infer the that, the 3D positions of the features (see The stereo approach, while perfectly [ 41) . reasonable, does have undesirable properties. in the matching phase. It may also require is that the floor in this environment are marked from a distance, expensive, particularly and so has no features in which pixels with significant in white. The region corresponding It is computationally very high resolution data. A more important problem appears textureless map of the image gradients) black. The stereo process cannot make any depth measurements region of the image because can be remedied by interpolating compute depth. the depth of the floor directly, but because happens general case (see Fig. 2). there are no features a flat surface In that case, the stereo system to be true of floors in office environments. texture to match. Fig. 1 shows a (actually, significant to the floor intensity is uniformly in the most important there to be matched. The problem in the absence of texture from which to is working not because it is measuring assumption that is not true in the it is making a smoothness The assumption This brings out two important points. First truly general systems are extremely rare, the mechanisms we in advance and so claims of generality build have hidden assumptions. These can be particularly difficult should be considered carefully. Often to uncover 4 I. Horswill/Arfifcial Intelligence 73 (1995) I-30 Fig. 3. The carpet blob extracted there is more exposed carpet. from Fig. I using the coloring algorithm. Note that the blob is taller where choose are bad. Quite the contrary: test data that fit them. This is not to say that because we may unconsciously can lead to great im- implicit assumptions provements in performance. However, we as engineers need to make informed decisions about our use of specialization. We need to understand more clearly what assumptions our agents make about their environments, the particular environments and how often those assumptions in which they operate. those assumptions are true of 2. I. A more ejficient algorithm The stereo system worked on the scene obstacles had texture. We can make a different system much more efficient, by using these facts directly and by treating the floor as a useful feature of the environment rather than a problem in Fig. 1 because the floor was flat and the to solve the problem, one that is the lack of texture on to be overcome. Notice This blob is easily computed by region coloring: each image column, marking pixels until a textured pixel is found marked pixels will form floor in the corresponding exposed the amount of free space in that direction. that the floor forms a single, connected black blob at the bottom of Fig. 1. in Fig. 3. I will call this the carpet blob. The carpet blob is shown alone trace up in that column. The the blob. The height of the blob varies with the amount of direction, giving us a rough and ready measure of starting at the bottom of the screen, We can then solve our navigation problem simply by extracting in which the carpet blob is tallest. This technique capabilities tours of the AI lab at MIT. The navigation turning in the direction the low level navigation simple real time on a low-end personal computer. the Polly system the carpet blob and is the basis of [ 18,191, a mobile robot that gives in algorithm can easily be executed 2.2. Preliminary analysis of coloring algorithm Both mechanisms the stereo algorithm and the coloring (blob-based) algorithm that make assumptions about the structure of their environments. are specialized They I. HorswiWArtificial Intelligence 73 (1995) I-30 5 hold, but may perform properly when run in environments fail otherwise. Unfortunately, represented. Neither algorithm would have any mention of the flatness of the floor in its source code listing, except, perhaps, as a comment. are not explicitly their assumptions their assumptions in which it into the coloring We can understand algorithm by deriving The stereo system measures a depth map and projecting the exact distances that we use it consistently. it from the stereo algorithm free space directly by means of a series of transformations. by computing the floor plane. Since we are only concerned with determining which side has more free space, however, we do not need in any particular unit of measure. Any measure will do to know provided for the stereo system any function of the free space. It has been known system that computes a strictly at least since Euclid for points on that we can replace stereo computations with the a ground plane. This means, image plane heights of obstacles, provided rest on the floor and we have some way of labeling each pixel as being either obstacle or carpet. A general obstacle the detector might be more difficult so carpet in this environment we can substitute appearance-it for the obstacle detector. that image plane height roughly, to build has a very predictable is such a distance measure In fact, we can substitute stereo system. However, has no texture-and a texture detector than the original that obstacles increasing We can summarize l We can substitute this analysis with the following general principles: any monotonic measure of a quantity for a calibrated measure, provided l We can substitute height that all objects that the measure will only be used for comparisons. in the image plane rest on the floor and there for some other distance calculation, is some way of classifying provided pixels as being l We can substitute floor or object. a texture detector for a floor detector, provided that the floor is a general of the coloring from a possibly the specialization and the obstacles do have texture. concisely describe transformation textureless, These principles describes ficient one, along with the conditions The transformations novel environments, to use the blob-based have to abandon If there was some property other than texture which allowed carpet pixels classified, algorithm. Each to a more ef- it valid. in if we wanted in an environment with a textured carpet, we would but we would still be able to use the other two. to be easily then we could use that property as the basis of a new transformation. can be used to predict or reused algorithm the last transformation, in the design of new systems. For example, the performance of the coloring algorithm on the task and environment that make inefficient algorithm 3. Preview The main point of this paper is that we can usefully analyze specialized systems by deriving them from general systems using a chain of conditional Implicit in these claims is the promise that such an analysis optimizations. can be made and precise. However, the “analysis” least. Most of the rest of the paper way of making in the previous section was handwavy, is devoted to an extended example the analysis precise. This entails a great deal of formalism which formal to say the showing one is otherwise uninteresting. them entirely. The reader may want to skim the most formal sections or skip The paper should not be interpreted as arguing The notations used here, while quite serviceable, were chosen for any particular choice of notation. they were largely because to a more compact exposition given alternatives do exist (see Section 4). than the alternatives in the literature. Nonetheless. the Section 4 surveys analysis. The rest of the paper literature on environmental robot. The systems of the Polly to a detailed analysis of the navigational system was not cooked up to suit the needs of the formalism. Polly is a real, in day-to-day use at the MIT AI lab. Section 5 fleshes out and so on. Section 6 then fully formalizes transformation, the blob coloring for the purpose of analyzing is devoted navigation working, vision-based the notions of environment, these notions Polly’s changes and actions. Section 8 uses this extended level navigation the basis of state to encompass to analyze Polly’s high system. Section 9 then gives concluding system. Section 7 extends low level navigation the formalism algorithm, formalism remarks. robot 4. Related work Relatively science. mostly computational little attention has been devoted to environmental likely because it is only recently specialization that we have begun in computer to construct systems that are closely coupled to natural environments. In biology, a great deal of attention has been given to the specialization to their environments. Cybernetics, agents focused on agent/environment of specific, complex environments intelligence to artificial and robotics interactions, (see [ 29,30,34] ) . of complete intelligence, also on the properties [ 451. Ideas from these areas are now being applied the progenitor of artificial although not necessarily In perceptual psychology, Gibson proposed an “ecological” stressed the role of the environment that the structure of the environment through the environment perceptual apparatus of the organism via a process akin to resonance. that in forming an agent’s perceptions. Gibson argued in the energy flowing determines can be directly picked up by the theory of perception a set of invariants that these invariants and Marr [28] argued that in order to properly understand the operation of a perceptual the problem the theory defines input-output interpretations system), we must understand (or more generally, of any intelligent theov. behavior of the perceptual system it solves at the level of a conzpututional ’ The computational system, along with a set of constraints desired on the possible of a given input. The constraints were necessary because a single stimulus can usually be generated by an infinite number of possible situations. The virtue of a computational individual mechanism. A single computational many different mechanisms computational tation possible at all, not how to make it more efficient. Marr believed the details of an theory can be used to explain and unify it. To Marr, the role of the constraints within theories was to show how the structure of the environment made interpre- that the human is that it abstracts away from that instantiate theory ’ Marr’s actual story is more complicated than this. and used three levels of explanation, not two. See I28 I. 1. Horswill/Art$cial Intelligence 73 (I 995) I-30 7 visual system was a general mechanism of the environment could be specialized ronment. This work extends Marr’s ideas by using constraints at the implementation descriptions how a system to take advantage of useful, but unnecessary, properties of the envi- and so was relatively unconcerned with understanding to explain optimizations three-dimensional for constructing level. (see about to form [36-381). the dynamics and Kaelbling for synthesizing developed a method to be directly synthesized the basis of a programming to the state of the environment finite-state machines. Rosenschein Most formal models of environments use state-space descriptions of the environment, finite state machines used Their formalization allowed from descriptions of desired behavior of the behavior of the environment. The formalization was powerful to program a real robot. language used states logic [ 121 use a automata whose internal given a set of temporal usually to represent both agent and environment specialized mechanisms and a formalization enough Later, Rosenschein had provable correlations assertions geometric, but similar, approach [46] has specifically of the environment. Donald and Jennings for constructing of simulated proposed based on the types of mechanisms which can operate successfully within also used a finite state formalization three classes based on properties finite state machines by a genetic algorithm. Littman reinforcement in terms of the amount of local storage algorithm that still allowed an optimal control policy environments them. Wilson into [43] used grid worlds for a class of artificial agents created for to classify environments the complexity of RL agents the RL of the environment. He divided environments such as determinacy. Todd and Wilson they use and how far into the future algorithms. Littman parameterized by the minimal parameters looks. He then empirically [25] used FSM models classified environments the classification virtual sensors. to taxonomize to be learned. learning Wilson There is also an extensive literature on discrete-event dynamic systems (see [23] for a readable but which assume to the agents. introduction), which also model information that transition the environment as a finite state machine, is visible than state information) (rather Several researchers have discussed how time-extended patterns of interaction with the from a formal [ l] ) can be used to reduce (called “dynamics” by Agre environment burden on an agent. Lyons and Hendriks have discussed how to derive and exploit useful [ 271. They use a uniform dynamics temporal formalization to exploit logic, they are able to identify useful dynamics them. Hammond, Converse, and Grass discuss how new dynamics can be designed into an agent to improve based on process algebra. Using and design reactive behaviors the stability of the agent/environment of both agent and environment of the environment the computational specification system [ 161. 5. Analyzing specialized agents We will assume that we can reasonably separate the world into agent and environment. ‘Ihe world here need not mean the entire physical universe, only that portion of it which to our analysis. Let A denote some set of possible agents and E a set of is relevant system with some environments. Each agent/environment form a dynamic pair will 8 I. Horswill/Arti$ciul Intelligence 73 (1995) I-30 behavior. We will also assume some behaviors. We will write (ai, el ) E (~2, e2) to mean in ei equivalent over possible that the behavior of ai operating to the behavior of a2 in e2. We can then say that two agents are notion of equivalence if they are equivalent in all environments: is equivalent task-specific al = a2 iff Vet,ez.(ai,ei) = (u2,e2). We will call them conditionally they are equivalent in all environments equivalent given some environmental constraint C if satisfying C. We will write this al Z_C az. Thus UI fc a2 iff Vei,e2.C(ei) AC(e2) * (at,ei) = (u2,e2). Often, the designer has a particular behavior the only useful behavioral distinction = relation will divide working. Let the habitat HA of agent A be set of environments will often refer to environment constraints be described as a constraint or conjunction as habitat constraints, of constraints. the possible behaviors is whether into only that they want the agent to achieve. Then the agent “works” or not, and so the two classes, working and not in which it works. We since the habitat can 5. I. Specialization as optimization Suppose we want to understand ronment. Although also have a smaller habitat, and domain constraints C;, such that s might be more efficient an agent s that is somehow specialized to its envi- than some more general system g, it may s; i.e. H, C_ H,. If we can find a sequence of mechanisms then we have within the environments they will work in exactly of the habitat of g: that g GC,~...~~,, s. We can phrase this latter statement that sati& Cl, . . the same cases. This lets us express , C,,, g and s are behaviorally the habitat of s in terms in English as: equivalent- H,, 2 HgnCl I-I..-nC,,. Note that the left- and right-hand situations where S works but g does not. One of the constraints on the right-hand might also be overly strong. sides are not necessarily equal because there may be side in which g is gradually into to the derivations of equations. We will restrict -_c, s, can be seen as the transformed step si-1 I will call such a sequence of equivalences, to the case where each derivation s, a derivation of s from g, in analogy our attention result of applying given Ci (i.e. for which si = O;( s,_l) defined). Exhibiting are easier optimizations Oi, making these constraints If an environment to understand. It also places the computational some general optimizing transformation Oi that preserves equivalence such a derivation breaks s’s specialization and for which a -_c, Oi(a) whenever Oi(a) is that the constraints Ci in correspondence with their explicit. Teasing value of each constraint into smaller pieces apart helps predict the performance of the agent in novel environments. satisfies all the constraints, the agent will work. If it does not, then 1. Horswill/Art@cial Intelligence 73 (1995) l-30 9 we know which optimizations will fail, and consequently, which parts of the design to modify. In addition, if we can write a general lemma to the effect that a -ci @(a), then we can reuse Oi in the design of future systems. Such lemmas may be of greater interest than the actual agents that inspired them. Note that we can equally well perform a derivation of one subsystem of an agent from another possible subsystem. For that reason, I will often use the term “mechanism” to mean either an agent or one of its subsystems. 6. Analysis of simple perceptual systems In this section, we will perform a more detailed analysis of the coloring algorithm given in Section 2.1. To do this, we need to flesh out the notions of environment, behavior, and behavioral equivalence. Throughout the paper, we will use a state space formalization of the environment. In this section, we will only be concerned with the environment states themselves, not with the possible transitions between them. We will also ignore the internal state of the agent. In Section 7, we will add dynamics and internal state. Let W be the set of possible world states. We will model environments as subsets of W (we will consider other state spaces in Section 7.1). Thus & = 2w. Habitats, which we have defined as sets of environments, will then effectively just be (larger) regions of the state-space themselves. Habitat constraints, constraints over possible habitats, are then also effectively just subsets of W. Since we are ignoring dynamics and internal state, we will consider only those perceptual systems that give information about the instantaneous world state. Thus a perceptual system is a mechanism that has an identifiable output with an identifiable set of possible states S such that the state of the output is causally determined by the perceptual system computes a function from the state of the world. Effectively, W to S. We will call that function the information type that the perceptual system computes. We will say that two perceptual systems are behaviorally equivalent if they compute the same information type. An information type is finite if its range is finite. Note that information types should not be confused with the concept of information as inverse probability used in classical information theory (see [ 151). While the two are certainly compatible, classical information theory is concerned with measuring quantities of information, whereas our concern here is with distinguishing among different kinds of information. 6.1. Derivability and equivalence Often what is interesting about an information type is what other information types can be computed from it. We will say that one information type I’ : W --+ S’ is derivable from another, I : W + S, if there exists a derivation function f for which I’ = f o I. II (written ii = 12) if they are interderivable. and 12 are equivalent The range of an information type is irrelevant to derivability; We can arbitrarily rename the elements of its range without changing what can be derived from it. Thus what really matters is the partition PI it induces on the world states: P, = {A c W 1 x,y t A w I(x) = I(y)}. The elements of the partition are the maximal sets of world states that are indistinguish- able given only I. One can easily show that* Lemma 1. The following stutements are equivalent: ( I ) 11 and 12 are equivalent, (2) X is derivable from 11 iff it is derivable from 12, for all X. (3) The partitions PI, and PI: are identical. (4) 11 and 12 di$fer only by u bijection (a 1-I onto mapping). that is, interderivable. We will say that I and I’ are condition+ if for all w t C. Note that I =lv I and that It =c, 12 and f2 =cz 1s implies equivalent equivalent given C if their I (bv) = I’(w) ft =c,n~2 Is. Finally, we will say that two perceptual systems are behaviorally if they compute information identical given C (written types are conditionally type and conditionally the same information identical given C. I =c I’) 6.2. Unconditional equivalence transformations We will use a single box labeled with an information type I to represent is meant internal wholly within to represent structure the system. Thus a perceptual system that (somehow) computes a connection to the environment. When we want in the system, we will use single arrows the 1. The double arrow the to expose to represent connections the transformations f, g, represents . . to it. Finally, we will denote predicates with a “?‘, thus a system which first computes I and then applies denotes diagrams a system which outputs true when I (KJ) > T, and false otherwise. These inherit the associativity of function composition: and so a simple optimization, which we might call “folding” compiler optimization), computation: is the replacement in of a series of computations with a single (after constant-folding 2 SW ] I9 1 for El proof I. HorswiN/Artificial Intelligence 73 (199.5) I-30 II *I-f+ 00 z * f0I-. 0 One example of an optimizing transformation is what might be called “decalibration”. precise parameters Estimating sensor calibration. Often all that is done with this information empirical threshold. For example, we might estimate whether we should swerve around avoid collision. Generally, experimentally. any units, provided such as depth can be difficult and can require precise it to some to decide to it in it, or whether the designer arbitrarily In such situations, we can use any mechanism it is too late and we must brake chooses a threshold or determines that computes distance that we correct is to compare to an obstacle the threshold. the distance Lemma 2 (Decalibration) numbers) and any strictly increasing function f : I$ -+ JR, . For any information type I : W + Ii2 (IR is the set of real +j-yT+ c ++I>fo?li. Proof. By associativity, the right-hand side is equivalent to +&-ZK+ and for all x, f(x) > f(T) iff x > T, thus (> f(T)?) of = (> T?). (cid:144)! Decalibration allows a calibrated mechanism to be replaced with an uncalibrated mechanism, in certain cases. 6.3. Transformations over simple vision systems The coloring algorithm used image plane height to discriminate depth and a texture for the to find obstacles. In this section, we will derive sufficient conditions detector validity of these techniques. We will show that image plane height is a strictly increasing into function of object depth, provided its region of contact with the floor. We will also show that the floor is contained within frequencies below w and which are for floors whose surface markings have no spatial viewed in the region between objects and floor. The proof is not terribly (0, dw) can be used to discriminate interesting from a distance of at least d, any low pass filter with a passband in itself. The reader may wish to skip to Section 6.4. rests on the floor and its projection the object First, we need forward direction the forward the camera frames share their left/right for the camera- and body-centered the ground plane the b/w images are Z(R) to define our coordinate (z) is the axis of projection, systems, one camera-centered, in which and the other body-centered, (2) direction faces forward, but somewhat down, and so the camera- and body-centered (see Fig. 4). We will assume is the direction of motion axis, which we will call X. We will call the up/down lies at Y = 0. We will denote systems y and Y, respectively. We will assume the image with range set X by Z(X) the in which that axes that so and the color images are Z(W3). The projection camera-centered coordinates, process can be specified In the projection process maps a point (X, y, z ) in the world in either of these coordinate frames. I. Hor.~will/Ar/ifcial Infelligence 73 (1995) I-30 camera 1: Y optic axis 2 h I center of body coordinate system p, Ground plane Fig. 4. A camera viewing a ground plane. The X axis (not shown) comes out of the page and is shared by the camera and body coordinate is formed by X, Y and 2, the camera frame, by X, y and z. z is also the axis of projection, or optic axis, of the camera. h is the height of the camera and P is an arbitrary point on the ground plane. frames. The body coordinate frame (fX/z, to a point the body-centered A point P in the world will be projected J‘y/z) on the image plane, where f is the focal length of the lens. In is best expressed with vector algebra. coordinate system, projection to the image plane point ,f(P- h) z.(P-h)’ ‘= (These are 3D coordinates; image plane axes X and y, yielding the 2D coordinates the coordinates are obtained by projecting . p, y. p> ) (X it onto the 6.3.1. Salience functions and jigure/ground separation : W + I( {T, F}) system (“figure/ground”) that can compute FGo within FGo can be arbitrarily difficult Let 0 be a set of objects and FGo type that, for all world states, returns an image information “T” if they were imaged A perceptual the background. of chameleons to be recognized information constraint (a “salience constraint”). to find particular classes of objects in the biological world (see be the unique in which pixels are marked in that world state from one of the objects 0, otherwise “F”. 0 from the case where 0 is the set there are often specific cues that allow objects in specific contexts. We will call these cues salience functions. An to FGo given some functions ) and The use of such simple, easily computed [ 351 for a good introduction). is common both in AI (see its habitat can distinguish type is a salience function or snipers). Fortunately, if it is conditionally [ 11,20,42,44,47] equivalent (consider The coloring algorithm uses the texture detector as a salience function. We want to determine what salience constraint we will restrict ourselves detector examines small patch with to Fourier-based measures of texture. Effectively, is required for a given texture detector. For simplicity, a texture the projection of a a small patch of the image. We can approximate (X,y,z) H (fxlzo~.fYlzo) to the center of the surface patch. A sufficiently where ~0 is the distance can be treated as a plane with a some patch’s reflectance varies as a sinusoid with frequency vector 3. Then at a point (x’, y’) on the patch is given by: local coordinate system (x’, y’). Suppose small patch the its reflectance R I. Horswill/Art$icial Intelligence 73 (1995) I-30 13 Zero band Projected zero band Fig. 5. The effect of perspective projection on local frequency distributions. R(X’,y’) = t sin& +sitl$ +i. ( > If we view the patch: l from a unit distance, l through a lens of unit focal length, l from a direction normal l with the X axis aligned with the x’ axis, and l with even illumination of unit intensity to the patch, then the image intensity will simply be I(%Y) = N&Y). Now consider halving the focal length halves the size of the image. the effect of changing the viewing conditions. Doubling the distance or Z(x,y) =R($,g) = k sin&+sin& ( + i. Y 1 is still a sine wave grating, but its projected frequency is doubled. Rotating The image the patch by and angle 6 around factor of cos 13, producing the X axis shrinks the image along the Y axis by a a sine wave of frequency (w,, w,/cos 0) : I(x,y)=R(X,yCOS8)=~ Rotating about the Y shrinks frequency vector. sinX+sin- wx ( ycose WY > +;. the X axis. Rotating about the optic axis simply rotates the but with a frequency Thus a sine wave grating viewed from any position appears as a grating with identical and amplitude is linear, we can extend this to arbitrary possibly a rotation. Since the projection process power spectra: the power spectrum of the patch’s projection will be the power spectrum of the patch, rotated and stretched along each axis (see Fig. 5). Frequency bands of the patch are transformed regions of the frequency domain of its projection. vector modified by a scaling of its components into elliptical 14 I. Horswill/Artijiciul Intelligence 73 (1995) I-30 point of projection I”* /Y image plane r’ Ground plane -2 l P Fig. 6. Monotonicity of image plane height in body depth. Rays projected from the point of projection to points on the ground plane pass through successively higher points on the image plane as they move to more distant points on the ground plane. Bounds on the possible viewing conditions bands can be deformed. yield bounds on how much the frequency The background texture constmint that all surface patches of the background have surface markings whose power spectra are bounded below by w, that in view is all objects have surface markings with energy below w, and that no surface lit. We have that closer than d focal lengths, and that the scene is uniformly requires (BTC) Lemma 3. Any thresholded (0, dw) is a salience function given the background texture constraint. lineurfiltering of the image with u passband in the interval fronto-parallel from distance d, the band no patch of the background has energy Proof. By assumption, all objects do. By the reasoning above, when any patch, either object or background, viewed Thus a patch was imaged note that increasing the size of the projected any viewing orientation, object. Thus a thresholded in the band (0, w), but is (0, dw). in this band. But increase can only than d and iff it was imaged from an ellipse. Thus for any distance greater in (0, dw) iff its projection has energy a patch will have energy the distance or changing linear filter is a salience the viewing orientation function given BTC. (0, w) projects from an object to the band frequency 0 The corollary is conditionally constraint. to this is that any thresholded equivalent to a figure/ground 6.3.2. Depth recover) linear filter with passband system given the background in (0,dw) texture Depth can be measured in either a camera-centered coordinate system. We will call these “camera depth” and “body depth”, respectively. The camera depth of a point P is its distance to the image plane, z . (P - h). Body depth, on the other hand, is how far forward the robot can drive before it collides with the point, Z. P. We will concern ourselves with body depth. or a body-centered Consider a world of flat objects lying on a ground plane. Then both object points and ground plane points have zero Y coordinates. The points must be linear combinations of X and 2. Since both z and Z are perpendicular will make no contribution to X, the X component of the point either to camera depth or to body depth and we can restrict I. Hor.swill/Art@cial Intelligence 73 (1995) I-30 15 is simply to the one-dimensional our attention depth II, while We can see by inspection, depth and body depth are related by a linear mapping. More surprisingly, height can also be shown analytically. The image plane height of P is case, shown in Fig. 4, of a point P = nZ. Its body its camera depth z . (nZ - h) depends on camera placement. in n and so camera image plane function of body depth. This can be seen from Fig. 6. It that the camera depth is linear is a strictly increasing however, Y* f(nZ - h) z . (nZ - h) =y.(fnZ-fh) > nz.Z-z.h nff-S =- M-r for cr = fZ. obtain y, /3 = z . Z, y = z . h, and S = f h . y. Differentiating with respect to n, we a(@ - r) (np - S) PS-o,Y - p(na - r)* looks forward and P is in front of the agent, we have that n, /I, S > 0, = (np- y)2’ the camera When and ya < 0, so the derivative is strictly positive. (GPC) requires The ground plane constraint in G is its set of points of contact with G.3 Thus pyramids 0 resting on a ground plane G, and that for each o E 0, o is completely o’s projection their bases would satisfy GPC, we can use least y coordinate be the information Let Body-Depth, generated by one of the objects 0, or cc for pixels generated by the background. that the camera view a set of the objects in view and resting on resting on their points. Given as a measure of the depth of the closest object. type which gives the correct body depth for pixels the restriction, but not pyramids Lemma 4. Let R be a region of the image. Then minR oBody-Depth, equivalent increasing : FGo(x, y) for some to min{y function. is conditionally E R} given GPC, module a strictly (x,y) touching the floor) has minimal depth, otherwise it must be the case that some contact point Proof. Note that there can only be one minimal depth, but there can be many minimal- (an object depth object points. However, there would be an object point point whose ground plane projection was not a contact point, a contradiction. Let p be a contact point. We want to show that no object point can have a smaller minimal-depth is invariant with respect to changes projected y coordinate in the X coordinate, than p must have either a smaller Z coordinate or a smaller Y coordinate. The first would contradict p’s being a minimal-depth the ground plane. Thus p must have a minimal y projection. We have already shown that for contact points than p. Since the y coordinate to a lesser y coordinate the latter would place a point which projects the point below the y projection in body depth. point while increasing is strictly 0 A trivial corollary to this lemma is that the height of the lowest figure pixel in the direction corresponding in an to image column gives the distance the column. to the nearest object 3 Formalizing the notion of “touches” can be difficult (see for example [ 13, Chapter 81). but we will treat the notion as primitive, since the particular formalization is unimportant for our purposes. 16 I. Hor.swill/Artijicial Intelligence 73 (I 995) I-30 6.4. Derivation of the coloring algorithm We can now derive the coloring algorithm from the stereo algorithm. Recall the stereo system: &&&~~i. By Lemma 4, the stereo system monotonic function) to any system of the form is conditionally equivalent given GPC (modulo a where “FG” is some computation this is conditionally equivalent given BTC to that performs figure/ground separation. By Lemma 3, where “filter” edge detector operating at a scale larger than the floor texture: filter restricted to the frequency band is any linear (0, dw), such as an it remains to be shown Since the coloring system and the stereo system yield outputs which differ by monotonic one for the other leads to the same functions, that substituting left and motor behavior. space are right distances that we can mode1 the steering motor invariant with respect to this substitution, provided as a first order system. Doing so, however, requires of still more math, reader is directed so the interested It can be shown that for a steering system based on balancing the attractor and repeller basins in the robot’s configuration the introduction to [ 191. reflectances Even this is a restricted derivation, to untextured objects with different a full derivation, tion can be extended ground. While space precludes tured objects still trigger the correct figure/ground map by filling image. However, operation, provided the screen, coloring reflectances since it assumes fully textured objects. The deriva- than the back- the argument goes as follows. Untex- the texture detector at their boundaries. We can then compute in the texture the interiors of closed contours tilling is in view (if part of it runs off the bottom of the raw they have different the coloring of the filled and unfilled versions will differ). Thus algorithm will still work on untextured objects, provided the column heights are invariant with respect and they are in full view. than the background that the full object to the interior The derivation shows that the background separation. More importantly, ure/ground If we wish to run the system texture constraint, but which does satisfy stitute any salience constraint that holds background such as that of Turk et al. [ 441, or Crisman has a distinctive in an environment color or set of colors, texture constraint fig- it shows that it is not used for anything else. is used to simplify the ground plane constraint, in the new environment. that does not satisfy the background then we can sub- if the then we might use a color system For example, [ 111, to find the floor: 1. HorswiWArtijkial Intelligence 73 (1995) l-30 17 +j-z&~]+. to build a system If we wanted implement both systems and switch between sufficient original information stereo system to determine which one in parallel with these systems and add another switch. to use. We could even that worked in both environments, them opportunistically, provided then we could there was the implement 7. Analysis of action selection transformational a number of formal conditions techniques to reactive systems. We will continue system with a known set of possible to action-selection tasks under which we can to model states. First, we systems In this section we will apply the goal of demonstrating planning as a dynamic (state with reduce deliberative the environment will add actions We will then model both deliberative planning of the control policies of classical control uniform vocabulary formal conditions (e.g. substitution transitions) to the environment, making it a full state-machine. systems and reactive systems as variants [ 261 or [ 71) . This gives us a (see for expressing both types of systems. We can then examine various of the control policy that allow simplifications theory on the environment of a reactive policy for a deliberative one) the focus of this paper is the use of transformational Again, of the notation used below. The notation which to apply the transformations. used by Rosenschein chosen for largely for compactness agent’s and Kaelbling internal state also turns out to be useful. is needed to establish The notation used here is largely equivalent [38], and by Donald and Jennings of presentation. The formal trick of externalizing analysis, not the specifics a framework within to those [ 121. It was the 7.1. Environments We will now allow different environments actions as mappings E = (S, A) formed of a state space S and a set of actions A which are mappings s to s. to have different state spaces and will treat from states to states. An environment will then be a state machine from For example, consider a robot moving along a corridor with n equally spaced offices 1, . . . , n - function, and where inc, and dec map an integer that dec( 0) = 0 and inc, (n - 1) = n - 1 the identity action is to stay in the same labeled 1, 2, and so on. We can formalize 1 }, { inc,, dec, i}) , where i is the identity i to i + 1 and i - 1, respectively, with the proviso (see Fig. 7). Note that the effect of performing state. this as the environment Z, = ((0, 7.1.1. Discrete control problems We will say that a discrete control problem, or DCP, is a pair D = (E, G) where E is an environment and G, the goal, is a region of E’s state space. The problem of getting for our robot would be the DCP (Z”, (0)). By abuse of notation, we will also write a DCP as a triple (S, A, G). A finite sequence of to the beginning of the corridor (dec,ij (i,inc) (inc,i) (inc,i) (i.inc) (dec,i) (i,dec) (incj) (inc,i) (i,dec) Fig. 7. The environment Zs (Top) and the serial product of & with itself (Bottom), expressed as graphs. Function products have been written as pairs, i.e. inc x i is written as (inc. i). Identity actions (i and i x i) have been omitted to reduce clutter. actionsa=(at,a2....,a,,) is solvable from s if such a sequence exists. D is solvable from all s E S. solvesDfromirzitialstutesifa,(a,-l(.,.a,(s))) (in general) EC. D if it is solvable 7.1.2. Cartesian products Often, is structured into distinct components the state space of the environment as being the “product” of the environment Zs with itself (since for example. Thus we would like to think of the king-on-a-chess- that can be acted upon independently. The position of the king on a chess board has row and column components, there board environment just as IR2 is the Cartesian product of the reals with are eight rows and eight columns), through an 8 x 8 themselves. However, consider an environment as being the product grid of city blocks. We would also like to think of this environment of Zs with itself. Both the car and the king have 8 x 8 grids as their state spaces, but the car can only change one of its state components the king can change both by moving diagonally. We will therefore distinguish two different Cartesian products of environments, in which a car drives at a time, whereas parallel product, which corresponds corresponds ,f x x: (a, 0) H ( f(u), g( b) ), and let i be the identity Et = (St, Al ) and E2 = (Sz, AZ), we will define the parallel product to the car case. Let the Cartesian product of two functions to the king case, and to be function. For two environments the the serial product, which f and g be El 11 E2 = (St x S2, {u, x u2 : ul E A,, u2 E A2}) and the serial product to be 1. Horswill/Art@cial Intelligence 73 (1995) l-30 19 El + E2 = (S, x S2, {a, x i : aI E A,} U {i x a2 : a2 E AZ}). The products of DCPs are defined in the obvious way: (EI,G) II (E29G2) = (El (1 E2,G x G2). (EI,GI) = (E2,G2) = (EI = E2,G1 x G2). The state diagram for & G+ Z2 is shown in Fig. 7. We will say that a an environment or DCP is parallel (or serial) separable if it is isomorphic to a product of environments or DCPs. 7.1.3. Solvability of separable DCPs The important property of separable DCPs is that their solutions can be constructed from solutions to their components: Claim 5. Let D1 and 02 be DCPs. Then DI ti D2 is solvable from state (~1, ~2) iff D1 is solvable from SI and D2 is solvable from ~2, Proof. Consider the sequences of actions S were the sequence a sequence S that solves the product from DI and D2, respectively, from (st , ~2). Let Sr and S2 be form S, so that if that together (uxi,ixx,ixy,bxi,ixz,cxi) in (gr, g2). By definition, gr and g2 must be goal states of DI and D2 then St would be (a, b, c) and S2 would be (x, y, z). S must some goal state and so Sr and S2 must be solution we can construct 0 components. to D1 and D2, respectively. Conversely, sequences for the to the product from solution the product a solution sequences sequence leave This = 1 - x. F has the property the agent no way of preserving The parallel product case is more complicated because the agent must always change both state components. leaves one solved sub- problem while solving another. Consider a “flip-flop” environment F = ((0, 1}, Gflip}) from every other where&(x) state. F + F also has this property. F 11 F does not however. F 11 F has only one action, from any which flips both state components given state in F (( F, the state and its flip. As with the king, the problem is fixed if we to leave one component of the product add the identity action is not necessary. intact, while changing A weaker, but still unnecessary, that always maps goal states to goal states. to F. Then the other. The identity action, while sufficient, is that F have some action at once. Thus only two states are accessible that every state is accessible it is possible condition Claim 6. Let D1 and D2 be DCPs. rf D1 // D 2 is solvable from state (~1, ~2) then DI is solvable from s1 and D2 is solvable from ~2. The converse is also true if for every goal state of D1 and D2, there is an action that maps to another goal state. 20 I. Hmswill/Artijicial Intelligence 73 (I 995) I-30 let S be a solution Proof. Again, sequences of obtained by taking element of S. Thus, if S is sequence from the first and second components, (si , ~2). Now let Si and & be the respectively, of each (axx,bxy,cxz) from solutions for their respective component then we again have that Si is (a, 19, c) and S2 is (x, y, z ). Again, Si and S2 are solution problems. Similarly, we can form a solution sequences to the product To loss of do this, the solutions to map a goal generality, let Si be the shorter solution. Since state to a goal state, we can pad Si with actions its goal region. The combination by combining to the components must be of the same there is always an action that will keep Dt within of S2 and the padded Si must then be a solution them element-wise. length. Without to the components to the product. 0 7.2. Agents We will assume an agent uses some policy to choose actions. A policy p is a mapping from states to actions. We will say that p: l generates a state sequence s; when s;+i = (p( si)) (si) for all i. l generates an action sequence ai when it generates l solves I3 from state s when p generates a solution sequence it solves D from all states. l solves D when l solves D and halts when it solves D and for all s E G, (p(s) si and ai = p( si) for all i. from s. ) (s) E G. For example, and halts. the constant function p(s) = dec is a policy that solves the DCP (Z,, (0))) 7.2.1. Hidden state and sensors A policy uses perfect In real life, information agents only have access to sensory type (see Section 6) provided by the agent’s sensors. The crucial question about T is what type is observable information if it is derivable the world to choose an action. information. Let T: S + X be the information can be derived from it. We will say that an information from T. about To choose actions, we need a mapping not from world states S to A, but from sensor for for D. We will say that p T-solves D from a given state it from any initial states X to A. We will call such a mapping a T-policy. A function p is a T-policy a DCP D if p o T is a policy if p o T solves state. it, and that p T-solves D (in general) if it T-solves 7.2.2. Externalization of internal state completely state. We will model We have also assumed by the state of its sensors. that the agent itself has no internal state-that its actions are In real life, agents generally have determined internal state with perfect sensors and effecters. Let the register environment RA over an alphabet A be the environment whose state space is A and whose actions are the constant over A. We will write the constant C,, “writes” a into functions function whose value is always a as C,. The action of E with the the register. We will call E 11 RA the augmentation state as a form of external (environmental) internal I. Horswill/Artificial Intelligence 73 (1995) l-30 21 alphabet A. An agent operating states of E and the register, perform an action register. in the augmentation can, at each point in E, and write a new value in time, read the the into Using external state for internal state is not simply mathematical artifice. Agents can and do use the world as external memory. An agent need only isolate some portion of the world’s state (such as the appearance of a sheet of paper) which can be accurately sensed and controlled. Humans do this routinely. Appointment keep their plans for the day in the world, rather than in their scarce memory. Bartenders to mix use the position of a glass on the bar to encode what type of drink and how far they are into the mixing that uses external state, see [2]. [ 61). For an example of a program books allow people they intend (see to 7.3. Progress functions A progress function is a measure of distance function Q, for a DCP D = (S, A, G) is a non-negative which function to a goal. In particular, a progress from S to the reals for ( 1) @ is nonnegative, (2) @(s) = 0 iff s E G. (3) For any initial state i from which D is solvable, i.e. Q(s) 2 0 for all s. S= (a,,. . . , a,) along which @ is strictly decreasing there exists a solution sequence (i.e. @( Uj(. . . (al (i) ) ) ) > to functions @(aj+l (aj(’ The term “progress it refers termination [26] ), admissible fields (see [21] or [24]). **al(i)))) function” over for all j). is taken from the internal functions of loops. Progress heuristics (see are also similar [ 5, Volume 1, Chapter the program verification state of the program that are used literature, where to prove (see and artificial potential functions to Liapunov II]), We will say that a policy p honors a non-negative - E or else Q(s) = @( (p(s) ) (s) ) = 0. A policy i.e. for all states s and some E > 0, either @((p(s))(s)) function @, if @ steadily decreases < that honors @ can be thought on @ and so will run until it reaches a local minimum of @. for the DCP, that local minimum will to be a progress corresponding function to the goal: it reaches zero, it until a(s) of as doing hill-climbing When @ also happens be a global minimum Lemma 7. Let @: S + R be non-negative and let p be a policy for a DCP D that honors @. Then p solves D and halts exactly when @ is a progress function on D. to zero within a(i)/& it reaches 0, after which the execution of p from an arbitrary Proof. Consider value of Q, decreases by at least E until Thus @ must converge is confined function converse, is solvable, generated by p is a such a sequence. initial state i. On each step, the it must remain zero. steps after which the state of the system to the set @-’ (0). We need only show that @-’ (0) C_ G iff @ is a progress function @-’ (0) c G holds by definition. To see the for D. If @ is a progress suppose @-’ (0) 2 G. We want to show that from every state from which D decreases @. The sequence that monotonically there is a solution sequence 0 Progress functions can be generated directly from policies. The standard progress function @,,,J on a policy p that solves D is the number of steps in which p solves D from a given state. An important property of product DCPs is that we can construct progress for their components: from progress for products functions functions Lemma 8. If @I is a progress then @: ( .Y, y) H @I (x) + @2(y) DCPs. function for DI and cP2 is a progress is a progress function for function for D2, the serial product of the Proof. Since @I > 0 and @2 > 0, we have that Q, > 0. Similarly, @ must be zero for the goal states of the product. Now suppose the product is solvable from ( SI , ~2). exactly decrease Then there must exist solution sequences to the @I and @2, respectively. Any combination product must then monotonically for (cid:144)J the product. decrease Cp, and so @ must be a progress of these sequences for the components to form a solution that monotonically function Again, the parallel case is more complicated: Lemma 9. lf @I is a progress for D2, and for every goal state of DI and D2 there is an action that maps that state to a goal for the parallel product state, then Cp: (x, y) H 01 (x) + @2(,) of the two DCPs. for DI and @2 is a progress is a progress function function function Proof. Again, we have that @ 3 0 and that @ is zero for exactly product. Now consider a state ( SI, ~2) from which the product sequences SI and S2 to the component problems be solution respectively, are strictly decreasing. Without shorter. Of the two solutions. We can pad SI and combine to the product. The padding cannot change solution along the combined of @ must be strictly decreasing the goal states of the is solvable. There must along which cP1 and @2, that SI is the to produce a the value of @I, and so the value solution. assume the solutions loss of generality, 0 7.4. Construction of DCP solutions by decomposition 7.4. I. Product DCPs We now have the tools to construct solutions to product DCPs from the solutions to their components: Lemma 10. Let pl be a policy which solves DI and halts from all states in some set of initial states 11, and let p2 be a policy which solves D2 and halts from all states in 12. Then the poliq P(X,Y> =PI(x) x P2C.v) .solves Dl 11 02 and halts from all states convention qf treating p, a ,function over pairs, as a function over two scalars.) in 11 x 12. (Note that here we are using the I. Horswill/Artificial Intelligence 73 (1995) I-30 23 Lemma 11. Let p1 be a policy which solves D1 from all states in some set of initial states II, and let p2 be a policy which solves 02 from all states in 12. Then any policy for which p(x,y) = PI (x) x i or i x p2(y> and y E G2,X $Gl *PP(&y) =p1(x) x i, ~EGI,Y#GGZ~P~X,Y)=~XP~~Y) will solve Dt + D2 and halt from all states in II x I2. functions. Let @‘,,,n, and @ppz,Dz be for p] and p2 on DI and D2, respectively. Their sum must be a for the serial case, and from the for both products clearly the sum, they must solve their respective products. Note that the constraint given Proof. We can prove both lemmas using progress the standard progress progress fact that PI and p2 halt for the parallel case. Since the policies honor in the second for the product. This follows directly is sufficient, but not necessary. function lemma 0 7.4.2. Reduction We can often treat one environment retains some of the fundamental distinctions vironment removes unimportant of concrete states and abstract actions correspond actions. between states. An abstract state corresponds to complicated of another; The abstract en- but to a set sequences of concrete structure of the concrete environment as an abstraction Let a projection of an environment (S’, A’) be a mapping ST: S + S’ U (1). crete state or else I states corresponding U SES 7r’(s). E = (S, A) T gives into an abstract environment E’ = the abstract state for a given con- the concrete if it has no corresponding to a given abstract state. For sets of states, we will let rr-’ (S) = abstract state. n--I gives from states corresponding We define a r-implementation that reliably moves the abstract state a’( s’) without visiting states corresponding to other abstract states. Thus for any s’ for which a’( s’) is defined, of an abstract action a’ to be a policy to an abstract state s’ to states corresponding the implementation solves the DCP (F’({s’,I,a’(s’)}),A,7rTT-‘(a’(s’))). Note that we do not require p to stay in mTT-’ (a’( s’) ) upon reaching it. Given 9r-implementattons in the concrete environment p’ to solve problems need only look up the abstract state corresponding the abstract action policy pa’ 0 f each abstract action a’, we can use an abstract policy the abstract actions. We by emulating to our current concrete state, look up the This suggests for the abstract state, and run its implementation. P(S) = Pp’fTr(s))(S). This concrete policy works by taking computing the state s, looking up its abstract state rTT( s), the and running the proper abstract action p’( r( s)), and then computing 24 1. Hmswill/Art$cial Intelligence 73 (1995) I-30 state, action that since it effectively to an abstract state, but the r-implementations in its implementation recomputes is no problem when P~!(~(~)). Note the abstract action each time the concrete environment next concrete no internal concrete action. This corresponds that have no abstract state. To handle to the environment policy environment name of the new abstract action implementation. When uses the abstract action stored in the register and preserves this policy has it chooses a is in a state that to visit states to add a state register to remember what abstract action is presently being performed. The the the it its is in a concrete state with no abstract state, it a new abstract action whenever state. It stores computes state with a corresponding in the register for later use, while also executing the value in the register: for the augmented is in a concrete the environment it is necessary this problem, are allowed environment abstract Lemma 12. Let D = (S, A, G), D’ = (S’, A’, G’) be DCPs, T be a projection of D into D’, and for each action a’ E A’, let pni be a r-implementation of a’ in D. If p’ is a policy which solves D’, then the policy p(s,a) = i P,(S) x &I, if r(s) = I, P~~(~(.~))(J) x C1j~~T(.y))~ otherwise, solves the augmentation of D with the alphabet A’, from any state in T-’ (S’). function the problem for p’ on D’ and let s E P-’ (S’). from is already solved, so suppose from states s for which @,!,D! (rr( s)) = n and consider an compute p' ( QT( s) ) , Proof. Let Qp,,nt be the standard progress Then Qp,/,oj (rr( s) ) is the number of abstract actions need to solve the problem the concrete state s. If @,l,Dt (r( s) ) = 0, then the problem that p solves s for which @,,,o, (r(s) begin store it into the register. Call this action a’. The policy p will also immediately of a’, the system must reach a executing pO/. Since state in r-’ in finite time, which is to say that it will reach the next state in D’. By assumption, p’ can solve D’ from this high level state in n steps, and so p must be able to solve D from s, and so, by induction p solves D for all s E P-’ (S’). ) = n + 1. The policy p will immediately is a p-implementation this policy (a’(n( s))) 0 We will say that D is reducible to D’ if there exists a projection r-implementations convert any solution of all of actions in D’. If D is reducible to D’ into a solution to D. 8. Analysis of a robot navigation system IT of D into D’ and to D’ then we can easily Consider the robot must decide given the problem of piloting a robot about the office environment shown in Fig. 8. how fast to turn and At any given moment, corridors how fast to move the coordinates of the except when it reaches intersection and intersection) turns north when the goal is to the north, south when the goal is to the south, and so on: intersections. At intersections of its goal forward or backward. Polly uses the policy of following to the coordinates to be another its destination it compares (presumed north east south west Fig. 8. Approximate layout of the seventh floor of the AI lab at MIT (Top) and its topological stmcture (Bottom). / stop, turn-north, turn-south, if at goal, if south of goal and at turn to north, if north of goal and at turn to south, pPOIIy (sensors) = ( ’ ’ ’ turn-north, turn-south, . . . follow-corridor, if south of goal and pointed south, if north of goal and pointed north, otherwise. The details of the perception and control systems are given in [ 191. 8.1. Derivation from a geometric path planner Geometric path planning is a common technique for solving this type of problem. Given a detailed description of the environment, a start position, and a goal position, a path planner computes a safe path through the environment from start to goal (see [ 241). Once the path has been planned, a separate system follows the path. Geometric planning is versatile and can produce very efficient paths, but is not computationally efficient. It also requires detailed knowledge of the environment which the perceptual system may be unable to deliver. We can clarify the relationship between a path planning system and Polly’s reactive algorithm by deriving Polly’s algorithm from the planing system. Let N be the DCP whose states are (position, orientation) pairs and whose actions are small (translation, 26 1. Hor.~will/ArtiJiciul Intelligence 73 (I 995) I-30 in one clock pairs such as the robot might move rotation) modeled as an N policy. However, policy. A planner/executive execute a plan. The planning portion uses scratch memory reads and store register and executes each segment the form: tick. Clearly, Polly can be the planner can equally well be modeled as an N state to compute and to gradually compute a plan the finished plan out of the architecture has in turn. Thus a planner/executive it in a plan register, while is simply a policy that uses internal the executive pa(s,plan,scr&&) = ’ ’ planN(s’scrurch)’ execute(plan) x i, 1’ if plan incomplete, otherwise; execute(pfan) = head(plun) x Crair(p/un). An agent in N will spend nearly all its time in corridors. The only real choice points intersections. Thus only the graph of corridors and rather than the full state space of N (see Fig. 8). the current in this environment are the corridor intersections N’, need be searched, By Lemma 12, we can augment north/south/east/west action and replace po with the policy the environment with a register to hold I’] (s, action) = p,,;c~~~,,(s) x C,,;(,(,)). P~~(./~O11( .s ) x Cut~liOn 3 if at intersection, otherwise, where: is the intersection l f(s) l the different puctfon p olicies at state S, implement following north, south, east, and west cor- ridors, respectively, and, l pi is an arbitrary N’ policy. The lemma requires always be started from a corridor and scratch registers and using a plan/execute that the goal always be a corridor and that the robot intersection intersection. We could now solve N’ by adding plan policy: pi (intersec,plun, scratch) = i x plan,, (intersec, scratch), if plan incomplete, execute(plutr) x i, i otherwise. We can simplify corridor network interleaves and the goal. We can then remove to actions further by noting is a 4 x 2 grid. By Lemma 11, we can replace p{ with any policy is isomorphic that N’ to Zb + Zz, that is, the that location the current to reduce grid coordinate differences between the plan and scratch registers from pr and reduce it pz (s, action) = pp;(j(,,,(.r) x C,;(j(,,,,, Puctio~t ( .r ) x CUtiOn? i if at intersection, otherwise, is any N’ policy satisfying it only moves north/south/east/west the constraints that (1) if the goal is north/south/east/west it only stops at the goal, of where pi and (2) I(S). There are still two important differences between p2 and p,,,,~t+ Polly uses a different state to keep instead of “go north”) and it has no internal (“turn north” set of actions I. Horswill/Art~@cial Intelligence 73 (1995) I-30 27 Table I Summary of constraints and optimizations used in Polly’s navigation system. Constraint Optimization ground plane constraint background-texture constraint corridor network grid structure orientation correlation use height for depth estimation use texture for obstacle detection replace planning in N with planning in N’ replace planning with difference reduction store state in orientation it appears it does not. Within a short period of beginning track of its abstract action. While we have derived, will always be pointed north. Similarly of the robot effectively register. There’s no need for internal memory. Polly stores its state in its motor. than different policy a north action, an agent for east, south, and west actions. The orientation register and turn commands to use a qualitatively effectively write the is the action We can summarize the transformations that the environment intersection The constraint be a corridor corridor graph. The isomorphism planning with difference its internal allows us to replace geometric planning with planning used in the derivation as follows (see Table 1) . consist of a network of corridors and that the goal in the to a grid allows us to replace the correlation of the robot’s orientation with of the corridor graph reduction. Finally, It is important state allows us to store the current action in the orientation. to note that either, both, or neither of the subproblems and corridor environment two decisions are orthogonal. is effectively system happens to allow active system could reverse optimization and reacting on the bottom one could were connected reactively, but corridor imagine [9]. the second optimization intact. The result would following) could be solved using deliberative If both are implemented a hierarchical the use of simple planner (see reactive policies In an environment with a more complicated (the abstracted the using planners, planning; then the resulting [ 391 or [ 221). Polly’s environment for both, so it is a layered graph re- topology, one the first on top for other examples). On the other hand, corridors were cluttered but the abstract problem could be solved planner, and use a deliberative leaving then be a hybrid system with planning (see [ 8,14,27,40] an environment where in a grid. In such an environment, the individual following might actually require deliberative planning. 9. Conclusions Fundamentally, this paper is about explanation. For one reason or another, we are type of that operate properly in one the agent’s performance but not in another. In such cases, we want to explain It reduces an agent’s environmental faced with agents or other mechanisms often environment in different environments. Transformational own programs. giving often more enlightening Polly uses. The constraint place on the choice of edge detector they can be used to predict obtained, the conditions the agents (given than analysis is a way of reverse-engineering specialization ones to a series of lemmas are possible. The lemmas are themselves. No one cares what edge detector surface markings is far more interesting. Once the lemmas have been the performance of old agents in new environments in Lemma 3) which background under which different optimizations 28 1. Hor.swill/Artificiul Intelligence 73 (I 995) l-30 for new agents or to suggest designs optimization imagine developing particular kinds of situated agents, much as cookbook methods are currently used electrical and mechanical in old environments. Given a sufficient cookbook methods lemmas, one can for designing stock of in engineering. A discussion of when specialization is not so much whether issue is appropriate is outside The as how we can be specialized about whether an agent works because of the generality of its design or because of serendipitous they are often not billed as such. We must think carefully properties of test data. to build specialized systems or general systems, although of specialization. consumers intelligent The the scope of this paper. systems is full of literature We must study the environment not only formally but experimentally. The knowledge I have used It is rare the structure of my sensors and environment well enough for my first for post-hoc analysis. incomplete. techniques discussed here primarily we use of the external world to design our agents is necessarily the transformational that I understand guess at an algorithm be robust. Performing that turn out to be empirically we encode within our agents are partial tested. If we take this notion seriously, form of natural science. To understand but our world. false a derivation based on plausible constraints constraints is wasted effort. The environmental theories of the environment. Theories must be then we must view artificial as a intelligence, we must study not only ourselves intelligence Acknowledgements Phil Agre, Rod Brooks, Bruce Donald, Eric Grimson, Maja Mataric, David Michael, and Lynn Stein all provided much needed feedback of these ideas. The reviewers provided many useful suggestions Ray Paton, Stan Rosenschein, during the development for improving University Research 0685, and in part by the Advanced Research Projects Agency under Office of Naval Research contract N00014-85-K-0124. Initiative under Office of Naval Research contract NOOO14-86-K- for this research was provided the presentation. in part by the Support References I I I FE. Agre, The dynamic structure of everyday life. Tech. Report 1085, MIT Artificial Intelligence Laboratory, Cambridge, MA ( 1988). 1’2 I RE. Agre and 1. Horswill, Cultural support (1992). for improvisation, in: Proceedings AAAI-92, San Jose, CA 13 I A.V. Aho, R. Sethi and J.D. Ullman, Compilers: Principles. Techniques. and Tools (Addison Wesley, Reading, MA, 1986) [4 I S.T. Barnard and M.A. Fischler, Computational and biological models of stereo vision, in: Proceedings DARPA Image Understandin,q Workshop ( 1990) I S I A. Barr and E.A. Feigenbaum, The Handbook of’Artijicia1 Intelligence (William Kaufmann, Los Altos, 1981). 16 I K. Beach, Becoming a bartender: the role of external memory cues in a work-directed educational activity, J. Appl. Cop. Psychol. ( 1992). I. Horswill/Arttj%ial Intelligence 73 (1995) l-30 29 171 R. Beer, A dynamical systems perspective on autonomous agent-environment interaction, Artif Intelf. 72 (1995) 173-215. CES 92-11, Case Western Reserve University, Cleveland, OH (1992). ]81 J. Brcsina and M. Drummond, in: J.,Hendler, ed., AAAI Spring Integrating planning and reaction, Symposium on Planning in Uncertain, Unpredictable or Changing Environments ( AAAl Press, Asilomar, CA, 1990). [9] R.A. Brooks, A robust layered control system for a mobile robot, IEEE .t. Rob. Autom. 2 ( 1) (1986) 14-23. [ IO] A. Church, The Calculi of Lambda [ 1 I] J.D. Crisman, Color region tracking for vehicle guidance, in: A. Blake and A. Yuille, eds., Active Vision Conversion (Princeton University Press, Princeton, NJ, 1951). (MIT Press, Cambridge, MA, 1992)) Chapter 7. [ 121 B.R. Donald and J. Jennings, Constructive recognizability for task-directed robot programming, J. Rob. Auton. Syst. 9 (1992) 41-74. [ 131 M.M. Fleck, Boundaries and topological algorithms, Tech. Report 1065, MIT Artificial Intelligence Laboratory, Cambridge, MA ( 1988). 1141 E. Gat, Integrating planning and reacting in a heterogeneous asynchronous architecture for controlling real-world mobile robots, in: Proceedings AAAI-92, San Jose, CA ( 1992). [ 151 R.W. Hamming, Coding and information Theory (Prentice-Hall, Englewood Cliffs, NJ, 1980). [ 161 K.J. Hammond and T.M. Converse, Stabilizing environments to facilitate planning and activity: an engineering argument, in: Proceedings AAAI-91, Anaheim, CA (1991) 787-793. [ 171 J.L. Hennessy and D.A. Patterson, Computer Architecture: a Quantitative Approach (Morgan Kaufmann, San Mateo, CA, 1990). [ IS] I. Horswill, Polly: a vision-based artificial agent, in: Proceedings AAAI-93, Washington, DC (1993) 824-829. [ 191 I. Horswill, Specialization of perceptual processes, Ph.D. Thesis, Massachusetts Institute of Technology, Cambridge, MA (1993). [20] I. Horswill and R. Brooks, Situated vision in a dynamic environment: chasing objects, in: Proceedings AAAI-88, St. Paul, MN (1988). [ 211 0. Khatib, Real-time obstacle avoidance for manipulators and mobile robots, In?. J. Rob. Res. 5 ( 1) ( 1986) 90-98. (221 C.A. Kuoblock, J.D. Tenenbetg and Q. Yang, A spectrum of abstraction hierarchies for planning, in: Proceedings AAAI-90, Boston, MA ( 1990). [23] J. KoSecka, Control of discrete event systems, GRASP LAB Report 313, Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA ( 1992). [ 241 J.-C. Latombe, Robot Motion Planning (Kluwer Academic Publishers, Boston, MA, 1991). [25] M.L. L&man, An optimization-based categorization of reinforcement learning environments, in: J.-A. Meyer and S.W. Wilson, eds., From Animals to Animats: The Second International Conference on Simulation of Adaptive Behavior (MIT Press, Cambridge, MA, 1993) 262-270. [26] D.G. Luenberger, Introduction to Dynamic Systems: Theory, Models, and Applications (Wiley, New York, 1979). [27] D.M. Lyons and A.J. Hendriks, Exploiting patterns of interaction to achieve reactive behavior, Artg Intell. 73 (1995) 117-148 (this volume). [28] D. Marr, Ksion (Freeman, New York, 1982). [29] D. McFarland, What it means for robot behavior to be adaptive, in: J.-A. Meyer and S.W. Wilson, eds., From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior (MIT Press, Cambridge, MA, 1991) 22-28. [30] J.-A. Meyer and A. Guillot, Simulation of adaptive behavior in animats: review and prospect, in: J.-A. Meyer and S.W. Wilson, eds., From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior (MIT Press, Cambridge, MA, 1991) 2-14. [ 3 1 ] J.-A. Meyer and S.W. Wilson, eds., From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior (MIT Press, Cambridge, MA, 1991). [ 321 J.-A. Meyer and S.W. Wilson, eds., From Animals to Animats: The Second International Conference on Simulation of Adaptive Behavior (MIT Press, Cambridge, MA, 1993). 1331 M. Minsky, Computation: Finite and Infinite Machines (Prentice--Hall, Englewood Cliffs, NJ, 1967). 30 1. Horswill/Arri$ciul Intelligence 73 (1995) l-30 [ 34 1 R.C. Patton, H.S. Nwana, M.J.R. Shave and T.J.M. Bench-Capon, Computing at the rissue/organ level (with particular f3.5 J H.L. Roitblat. [ 36 1 S.J. Rosenschein, reference to the liver) (MIT Press, Cambridge, MA, 1992) 41 I-420. fnfroducrion Formal fo Compari/ive Cognition theories of knowledge (Freeman, New York, 1987). in AI and robotics, Research Report CSLI-87-84, Center for the Study of Language and Information. Stanford, CA ( 1987). I37 I S.J. Rosenschein, Synthesizing information-tracking automata from environment descriptions, in: R.J. Brachman, H.J. Levesque and R. Reiter, eds., Proceedings First Infernafional und Reasoning, Toronto, Ont. ( 1989) 386-393. of Knowledge Representation Conference on Principles I38 1 S.J. Rosenschein in: J. Halpem, Monterey. CA ( 1986) 83-98. and L.P. Kaelbling, The synthesis of machines with provable epistemic properties. ed., Proceedings Conjkrence on Theoretical Aspecfs of Reasoning about Knowledge, I39 ] E.D. Sacerdoti, Planning 1401 L. Spector and J. Hendler, The supervenience in a hierarchy of abstraction architecture, Fall Symposium on Sensory Aspects c?f Robofic Infelligence spaces, Art$ Intell. 5 (2) ( 1974). in: A. Kak, ed., Working notes of the AAAI ( AAAI Press, Asilomar, CA, I99 I ) 93- 100. lambda for the extended 141 I G.L. Steele and G.J. Sussman, The revised report on Scheme: an interpreter calculus, Al Memo 452, MIT Artificial Intelligence Laboratory, Cambridge MA ( 1978). [ 421 M.J. Swain, Rochester ( 1990). Color indexing, Tech. Report 390, Department of Computer Science, University of I43 I P.M. Todd and S.W. Wilson, Environment structure and adaptive behavior from J.-A. Meyer and SW. Wilson, eds., From Animals Simulation of Adaptive Behavior (MIT Press, Cambridge, MA, 1993) I I-20. to Animuts: The Second International I44 1 M.A. Turk, D.G. Morgenthaler, K. Gremban and M. Marra, Video road following the ground up, in: Conference on Conference on Roborirs and Automurinn for the autonomous ( 1987) land vehicle, 273-280. in: Proceediqs IEEE Internationcrl (MIT Press, Cambridge, MA, 1961). 145 I N. Wiener, Cybernetics [ 46 I S.W. Wilson, The animat path to Al, in: J.-A. Meyer and S.W. Wilson, eds., From Animals to Animafs: Proceedings of the First Cambridge, MA, 1991) 15-21. International Corzference on Simulation of Adaptive Behavior (MIT Press, I47 I J. Woodfill and R. Zabih, Using motion vision for a simple robotic task, in: Proceedings AAAI FuU Symposium on Sensory Asperrs of Robotic lntelligetxe ( 199 1 ), 