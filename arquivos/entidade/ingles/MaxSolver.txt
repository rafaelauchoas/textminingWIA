Artificial Intelligence 164 (2005) 47–80www.elsevier.com/locate/artintMaxSolver: An efficient exact algorithm for(weighted) maximum satisfiabilityZhao Xing, Weixiong Zhang ∗Department of Computer Science and Engineering, Washington University in Saint Louis,Saint Louis, MO 63130, USAReceived 17 April 2004Available online 2 March 2005AbstractMaximum Boolean satisfiability (max-SAT) is the optimization counterpart of Boolean satisfiabil-ity (SAT), in which a variable assignment is sought to satisfy the maximum number of clauses in aBoolean formula. A branch and bound algorithm based on the Davis–Putnam–Logemann–Lovelandprocedure (DPLL) is one of the most competitive exact algorithms for solving max-SAT. In this pa-per, we propose and investigate a number of strategies for max-SAT. The first strategy is a set ofunit propagation or unit resolution rules for max-SAT. We summarize three existing unit propaga-tion rules and propose a new one based on a nonlinear programming formulation of max-SAT. Thesecond strategy is an effective lower bound based on linear programming (LP). We show that the LPlower bound can be made effective as the number of clauses increases. The third strategy consistsof a binary-clause first rule and a dynamic-weighting variable ordering rule, which are motivated bya thorough analysis of two existing well-known variable orderings. Based on the analysis of thesestrategies, we develop an exact solver for both max-SAT and weighted max-SAT. Our experimentalresults on random problem instances and many instances from the max-SAT libraries show that ournew solver outperforms most of the existing exact max-SAT solvers, with orders of magnitude ofimprovement in many cases. 2005 Elsevier B.V. All rights reserved.Keywords: Weighted maximum satisfiability; DPLL; Unit propagation; Linear programming; Nonlinearprogramming; Variable ordering* Corresponding author.E-mail addresses: zx2@cse.wustl.edu (Z. Xing), zhang@cse.wustl.edu (W. Zhang).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.01.00448Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–801. Introduction and overviewBoolean satisfiability (SAT) is an archetypical decision problem in artificial intelligence,logic and theory of computation. SAT with more than two literals (variables or their nega-tions) per clause is NP-complete [6,29]. Maximum Boolean satisfiability (max-SAT) is theoptimization counterpart of SAT, whose aim is to maximize the number of satisfied clauses.Max-SAT is more general than SAT; the solution to max-SAT can be used to answer thequestion of its decision counterpart, but not vice versa. Therefore, max-SAT is more diffi-cult to solve than SAT. Max-SAT is NP-hard [15] even when each clause has no more thantwo literals, while SAT with two literals per clause (2-SAT) is polynomial soluble.Weighted max-SAT is an extension of max-SAT in which a clause carries a weight, rep-resenting the significance of the clause or an induced penalty if it is violated. In weightedmax-SAT, the objective is to maximize the total weight of the satisfied clauses. Max-SATand weighted max-SAT have many real-world applications in domains such as scheduling,configuration problems, probabilistic reasoning, auction, and pattern recognition [14,20].For simplicity, in this paper, when we mention max-SAT, we refer to both weighted and un-weighted max-SAT. Following the convention for SAT, we refer to the ratio of the numberof clauses to the number of variables as the “constrainedness” of max-SAT.The Davis–Putnam–Logemann–Loveland (DPLL) algorithm for SAT [10] can be ex-tended to a branch-and-bound (BnB) algorithm for max-SAT. A BnB-based DPLL algo-rithm has been shown to be among the most competitive for max-SAT [43]. Much efforthas been devoted to improving the performance of such a BnB-based DPLL algorithm formax-SAT by combining the techniques previously developed for SAT [4,28,43] and manymethods used in Operations Research (OR), such as integer linear programming (ILP) andcutting plane methods [12,23,28]. However, these efforts have enjoyed limited success, es-pecially on large, complex problems. In particular, the current OR-based approaches aremore effective than the DPLL-based algorithms only on max-2-SAT [28], which is max-SAT with no more than two literals per clause. On the other hand, even though a BnB-basedDPLL algorithm is an efficient algorithm for max-SAT, it can handle relatively small prob-lems with moderate degrees of constrainedness.Therefore, despite the previous effort, much work is still needed in order to developefficient algorithms for both max-SAT and weighted max-SAT, and special care is requiredwhen extending SAT techniques to max-SAT. In principle, most techniques developed forSAT can be extended to max-SAT [14,20,43]. However, the SAT techniques take advantageof the fact that SAT is a decision problem, so that a search avenue can be abandoned assoon as a constraint violation becomes evident. This fact has been explicitly captured inthe unit propagation or unit resolution methods and different variable orderings used bythe DPLL algorithm and its variants. In contrast, the study of unit propagation methodsand variable orderings for max-SAT is limited. It is important to note that max-SAT hasits own intrinsic features that are remarkably different from its decision counterpart. Manyexisting techniques for SAT must be carefully reconsidered when being applied to max-SAT. Overall, it is much harder to develop an effective and efficient algorithm for max-SATthan for SAT, and the research of developing efficient exact max-SAT solver deserves muchattention, due to the generality and importance of the problem.Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8049Aiming at solving difficult max-SAT and weighted max-SAT problems optimally, wereview the previous research on max-SAT, those taking the DPLL framework for SAT inparticular, and develop an efficient exact max-SAT algorithm based on DPLL. Our algo-rithm has three ingredients, which can be viewed as novel extensions to the main ideasbehind the existing methods for SAT. The first is a combination of four unit propaga-tion rules for max-SAT. Three of these rules were proposed by others in previous studies;we analyze them extensively in this research. The fourth, new unit propagation rule isdeveloped in this research based on an integer nonlinear programming formulation ofmax-SAT. This is an innovative contribution, enlarging our arsenal of unit propagationsfor max-SAT. We also consider different ways to combine these four propagation rules inour study.The second element of our max-SAT algorithm is an effective lookahead lower boundto estimate the minimum number of clauses unsatisfiable at a node during the search. Ourlower bound is based on linear programming (LP) [21]. This is a remarkable contribution;it is perhaps the first successful application of LP to max-SAT, despite similar (but notsuccessful) previous efforts to apply integer LP (ILP) to max-SAT [12,23,28].The third ingredient consists of two new variable-ordering or branching rules, whichwere inspired by the results of a close examination of two popular variable-ordering rulesfor SAT, i.e., the Mom’s rule [8,30] and the two-side Jeroslow–Wang rule [24], on max-SAT. The first new variable-ordering rule is designed for max-2-SAT. As its name, binary-clause first rule, indicates, this rule gives a higher priority to a variable in binary clausesthan those in unit clauses. The second new rule is designed to cope with large range ofconstrainedness values of max-3-SAT instances. It is a dynamic variable-ordering heuristicthat is able to dynamically change its variable ordering from close to the Mom’s rule toclose to the two-sided Jeroslow–Wang rule as the constrainedness increases.The paper is organized as follows, we first discuss max-SAT and describe two types ofmathematical formulation of the problem in Section 2. In Section 3, we review the DPLLalgorithm for SAT and how it can be extended to max-SAT. We discuss various factors thataffect its performance, including initial upper bound, value ordering, lower bound from unitclauses, and two existing variable ordering rules. In Section 4, we present four unit propa-gation rules for max-SAT. In Section 5, we develop a lower bound function based on linearprogramming, and discuss why LP-based lower bound is effective on highly constrainedproblem instances. In Section 6, we propose the binary-clause first and dynamic-weightingvariable ordering rules. We present experimental results of our new strategies, and describean efficient max-SAT algorithm that combines all our new strategies in Section 7. We alsosystematically compare our new solver with the most existing max-SAT solvers in Sec-tion 7. Finally, we discuss some related work in Section 8, and conclude in Section 9.Preliminary results of the research and an extended abstract of this paper appeared in[45].2. Formulation of maximum satisfiabilityA satisfiability problem (SAT) is a Boolean formula involving a set of Boolean variablesand a conjunction of a set of disjunctive clauses of literals, which are variables and their50Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80negations. A clause with only one literal is called unit clause, a clause with two literalsis named binary clause, a clause with three literals is referred to as a clause of size three,and so on. A clause is satisfied if at least one of its literals takes value T , and a formula issatisfied if all the clauses are satisfied. The conjunction defines constraints on the possiblecombinations of variable assignments. SAT is to find a variable assignment that satisfiesall the clauses. Specially, 3-SAT is SAT where each clause has three literals. When thereexists no variable assignment to satisfy all clauses, it is required to find an assignmentthat maximizes the total number (or weight) of satisfied clauses [14]. This is maximumsatisfiability, maximum SAT, or max-SAT for short.In general, a weighted max-SAT can be formulated as a minimization problem. Given aset of m clauses defined on n Boolean variables, {v1, v2, . . . , vn}, it is to minimize objectiveW =subject towiyi,m(cid:1)i=1(cid:2)yi =if the ith clause is unsatisfied,1,0, otherwise,where wi is the weight of the ith clause, and yi is a decision variable [21] correspondingto the ith clause, for i = 1, 2, . . . , m. When the problem is unweighted, wi = 1.2.1. Linear programmingMax-SAT can be formulated as an integer linear program (ILP) [28] or a pseudo-Boolean formula [12,44]. We map a Boolean variable vi to an integer variable xi that takesvalue 1 when vi is True or 0 when it is False, i.e., xi = 1 or 0 when vi = T or F , respec-tively. We then map ¯vi to 1 − xi . With these mappings, we can formulate a clause as a linearinequality. For example, clause (v1 ∨ ¯v2 ∨ v3) can be mapped to x1 + (1 − x2) + x3 (cid:1) 1.Here, the inequality means that the clause must be satisfied in order for the left side of theinequality to have a value not smaller than one.However, a clause in a max-SAT may not be satisfied at all, so that the correspondinginequality may be violated. To address this issue, we introduce an auxiliary integer variableyi (or decision variable) to the left side of the ith mapped inequality. Variable yi = 1 ifthe corresponding clause is unsatisfied, making the inequality valid; otherwise, yi = 0.Since the objective is to minimize the total weight of violated clauses, it is equivalentto minimizing the sum of the products of the clause weights and the decision variablesthat are forced to take value 1. For example, (v1 ∨ ¯v2 ∨ v3) (weight 2), (v2 ∨ ¯v4) (weight3) can be written as an ILP of minimizing W = 2y1 + 3y2, subject to the constraints ofx1 + (1 − x2) + x3 + y1 (cid:1) 1 and x2 + (1 − x4) + y2 (cid:1) 1.The linear 0-1 program formulation of max-SAT suggests that the problem could besolved by integer linear programming (ILP). However, ILP is NP-hard. Furthermore, asshown in [28], except for max-2-SAT, a direct application of ILP to other max-SAT prob-lems does not seem to be effective.Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80512.2. Nonlinear programmingThe ILP formulation of max-SAT can be extended to a nonlinear program formulation.We will use this formulation to derive a new unit resolution rule for max-SAT in Sec-tion 4.4. This extension can be achieved by applying the inclusion-exclusion principle [31]to turn the inequalities in an ILP formulation into equalities. Here, we introduce an integerexpression to represent a literal. For example, given (v1 ∨ ¯v2 ∨ v3), we introduce integerexpressions x1, 1 − x2 and x3 for the literals v1, ¯v2 and v3. Such an integer expression takesvalue 1 if its corresponding literal is set to true, or value 0 otherwise. Using the inclusion-exclusion principle, we then write a nonlinear equation fi + yi = 1 for the ith clause of agiven formula, where yi is a decision variable taking value 0 or 1. Taking (v1 ∨ ¯v2 ∨ v3) asan example, we havefi = [x1 + 1 − x2 + x3] −(cid:3)x1(1 − x2) + x1x3 + (1 − x2)x3(cid:4)+ x1(1 − x2)x3.Note that fi can take value 1 or 0. Specifically, fi = 0 if no literal in the clause is set totrue, or fi = 1 otherwise. As in the ILP formulation, we introduce decision variables, yi ’s,to count for unsatisfied clauses. Here, yi = 1 if fi = 0, and yi = 0 if fi = 1. For a binaryclause, e.g., (v1 ∨ v3), or a unit clause, e.g., ( ¯v2), the corresponding nonlinear equationbecomes x1 + x3 − x1x3 + yi = 1 or 1 − x2 + yi = 1, respectively.In general, fiis a function of xu, xv, xw, . . . , xuxv, xuxw, . . . , xuxvxw, . . . , wherexu, xv, xw, . . . are integer variables introduced for the Boolean variables in the ith clause.By using yi = 1 − fi , a max-SAT problem is to minimize the following nonlinear objectivefunctionm(cid:1)W =i=1= c +m(cid:1)wiyi =(cid:1)i=1πixi +wi(1 − fi)(cid:1)πi,j xixj +(cid:1)πi,j,kxixj xk + · · · ,(1)xi ∈Vxi ,xj ∈Vxi ,xj ,xk∈Vwhere V = {x1, x2, . . . , xn} is a set of variables to be instantiated to 0 or 1, c is a constant,and πi, πi,j , πi,j,k, . . . are the coefficients of items xi, xixj , xixj xk, . . . , respectively.3. DPLL algorithm for maximum satisfiability: a brief reviewThe Davis–Putnam–Logemann–Loveland (DPLL) algorithm for SAT [11] is a back-tracking algorithm that progressively instantiates one variable at a time in searching for asatisfying variable assignment. In each step, the algorithm selects a variable and branchesoff to assign two possible values, T and F , to the variable. Whenever a clause is violatedafter setting a variable to T and F , the algorithm backtracks to the previous variable. Theprocess continues until either a satisfying assignment is found or it can conclude that nosuch assignment exists.DPLL for SAT can be extended to max-SAT using depth-first branch-and-bound (DF-BnB). DFBnB is a special branch-and-bound that explores a search tree in a depth-firstorder. DFBnB uses an upper bound α on the minimum total weight of clauses that cannot52Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80be satisfied, whose initial value can be infinity or the value of a sub-optimal solution gen-erated by an approximation algorithm. Starting at the root node, DFBnB always selects arecently generated node to examine next. If all the variables of the current node have beeninstantiated, and the total weight of clauses violated so far (the g value in the A* algorithm)is less than the current upper bound α, α is revised to the g value; if some variables arestill un-instantiated in the current node, and the g value accumulated so far is greater thanor equal to α, the current node is pruned.For simplicity, here we point out the two main differences between DFBnB for max-SAT and backtracking for SAT. First, the upper bound α may not be zero for max-SAT.Therefore, backtracking for SAT can be viewed as a special case of DFBnB for max-SATwhere α = 0 throughout the search, forbidding any clause violation and resulting in a muchreduced search cost. In fact, the special condition of α = 0 makes unit propagation (dis-cussed in Section 4) very effective for SAT. Second, DFBnB for max-SAT can abandon anode during the search only if the g value plus a lower bound on the minimum total weightof clauses that must be violated in the remaining clauses (the h value in the A* algorithm)at the node exceeds the current upper bound α. This indicates that max-SAT becomes moredifficult when the constrainedness increases, causing more clauses unsatisfied and result-ing in a higher upper bound α. This also implies that one method to reduce the search costof DFBnB is to accurately estimate the total weight of the clauses that cannot be satisfiedin the remaining clauses at a node (h value), so as to increase the possibility of pruningthe node if it indeed cannot lead to a better variable assignment. This last observation hasmotivated our work on LP-based lower bound (discussed in Section 5).3.1. Initial upper boundOne way to improve DPLL on max-SAT is to obtain a good initial upper bound α. Thesmaller the initial α, the more nodes will be pruned. Ideally, the initial α should be set tothe cost of an optimal solution, which is typically unknown before the problem is solved.An initial α can be obtained by an approximation algorithm. A local search algorithm suchas WalkSAT [32,38], one of the best local search algorithms for SAT, is a good choice. Inour experiments in Section 7, for example, we apply WalkSAT multiple times to reducethe initial upper bound. Such a combination of local search and systematic search is calleda two-phase algorithm [4].3.2. Lower bounds from unit clausesAnother way to improve DPLL on max-SAT is to compute a lower bound on the mini-mum total weight of clauses that cannot be satisfied at the current node of the search.3.2.1. Freuder and Wallace’s lower boundOne simple lower bound uses only unit clauses. At a node during the search, if theliterals in two unit clauses negate each other, one of them must be violated. Let Cv andC ¯v be the sets of unit clauses with literal v and ¯v, respectively. Then the minimum weightof violated clauses due to variable v is the smaller of the total weight of the clauses inC ¯v and the total weight of the clauses in C ¯v. A lower bound to a node of a search treeZ. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8053can be obtained by summing up all such minimum weights associated with the variablesappearing in all the unit clauses of the node. It has been shown that this simple lower boundcan significantly improve the performance of the DPLL algorithm for max-SAT [14]. Weadopt this lower bound function in our implementation of DPLL algorithm to deal with allthe max-SAT problems except unweighted max-2-SAT.3.2.2. Shen and Zhang’s lower bound for max-2-SATRecently, Shen and Zhang proposed several efficient lower bound functions for max-2-SAT [39]. These functions are developed from Freuder and Wallace’s lower bound. Byanalyzing the number of unit clauses and where the literals in the unit clauses appear inbinary clauses, Shen and Zhang have deduced three new lower bound functions, LB3, LB4,and LB4a, and shown that they are stronger than Freuder and Wallace’s lower bound. Thedetail of the new lower bounds are left to their original paper [39]. In our implementationof the integrated DPLL algorithm (Section 7.2), we adopted Shen and Zhang’s strongestLB4a for solving unweighted max-2-SAT. Note that it is unclear if these new lower boundfunctions can be extended to max-3-SAT and weighted max-2-SAT.3.3. Variable orderingEach step of DPLL chooses a variable to be instantiated next. Strategies for making suchchoices are referred to as variable orderings. The performance of the DPLL algorithm isgreatly affected by the variable ordering used.3.3.1. The two sided Jeroslow–Wang ruleA well-known rule for 3-SAT is the two-sided Jeroslow–Wang (J–W) rule [24]. Let{C1, C2, . . . , Cm} be the set of clauses to be satisfied. The two sided J–W rule selects avariable v that maximizes J (v) + J ( ¯v) over all un-instantiated variables, where(cid:1)J (v) =−ni2v∈Ciand ni the number of literals in the ith clause.This variable ordering is based on the intuition that shorter clauses are more importantthan longer ones. It gives the variables that appear in shorter clauses higher weights so thata variable appearing more often in unit clauses is more likely to be selected. It also assumesa ratio of 4:2:1 for the weights for variables in unit, binary and three-literal clauses. (It isinteresting to note that the idea of progressively halving the weighting factors was used byJohnson [27] thirty years ago in an approximation algorithm for max-SAT.) We call a rulegiving different weightings to variables in clauses of different sizes a weighted variableordering or a weighted branching rule.3.3.2. The Mom’s ruleWeighted variable ordering has been shown to be very effective for 3-SAT [13,30].Moreover, experimental results supported the scheme of giving the highest weighting tovariables in the shortest clauses [13,30]. This scheme has led to another popular SATheuristic, the Mom’s rule (or the shortest clauses first rule), which branches next on the54Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80variable having the maximum occurrence in the clauses of minimum size [8,30]. TheMom’s rule is better than the two-sided J–W rule on 3-SAT [13,30]. In [13,30], the Mom’sheuristic was represented as a formula for weighted variable ordering where a clause oflength i has a weighting that is 5 times (rather than 2) as large as the weighting of aclause of length i + 1, namely, the Mom’s heuristic selects a variable v that maximizesJ (v) + J ( ¯v) over all un-instantiated variables, whereJ (v) =(cid:1)v∈Ci−ni .5The Mom’s rule is successful on 3-SAT, because it tends to get rid of unit clauses soon,and forces the lower bound to increase and the search to backtrack early.3.4. Value orderingValue ordering, which determines which of the two possible instantiations of a branch-ing variable to be explored first, is another element affecting performance. Different valueordering very often results in different search complexity. Generally, the better a value or-dering strategy, the sooner a search process can reach a better solution, if it exists, so thatthe upper bound can be reduced more quickly and the total search cost will be smaller. Onthe other hand, if the initial upper bound is the same as the cost of an optimal solution,search is merely to verify that the optimal solution at hand is indeed optimal. In this case,exploring either one of the two branches of a variable instantiation will not affect the num-ber of nodes to be visited in the other branch. Therefore, the effect of value ordering is inlarge part dominated by an effective initial upper bound strategy, especially one that is ableto provide an optimal or nearly-optimal solution. Our experimental analysis supported thisobservation (data not shown). In our extended DPLL algorithm for max-SAT, because weapply an efficient local search, the WalkSAT algorithm [32,38], to get a good initial upperbound, we do not use any value ordering strategy, i.e., we use a fixed value ordering, firstsetting a variable to T and then to F .4. Unit propagationUnit propagation for SAT, which recursively sets literals in unit clauses to T , is themost powerful strategy for SAT, and the central piece of a DPLL-based SAT solver. Unitpropagation forces the variable in a unit clause to take the value that satisfies the clauseimmediately and ignores the other value completely. Furthermore, all the clauses contain-ing the literal equal to the forced value of the variable can be removed (satisfied) and thenegated literal can also be eliminated from all clauses. The result is a simplified formula.More importantly, the power of unit propagation largely comes from its cascade effect,i.e., setting a variable in a unit clause to a fixed value may subsequently generate more unitclauses, which can further simplify the formula at hand. Conversely, if two unit clauseshaving opposite literals, e.g., (v) and ( ¯v), appear in the current formula, the formula isobviously unsatisfiable and the current search avenue can be abandoned.Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8055In max-SAT, a clause may not be satisfied at all. Such an unsatisfiable clause may besimplified to a unit clause during the search. Therefore, we cannot force the literal in a unitclause to value T , but rather have to consider setting it to F as well, as long as doing sodoes not cause the total weight of violated clauses to exceed the current upper bound α.Therefore, unit propagation for SAT in its pure form does not apply to max-SAT.Nonetheless, the principle of unit propagation can be extended to max-SAT. Indeed,three unit propagation rules have been suggested before by many different groups of re-searchers. We summarize them all in this section and experimentally analyze them inSection 7. Moreover, we develop a new unit propagation rule that is significantly differ-ent from the existing ones. In the rest of this section, we describe these four rules. Weexperimentally examine their effects and the effect of their combination in Section 7.To make our presentation of the three existing rules simply, we first introduce someterms. For a max-k-SAT problem where each clause has k literals, consider a node N of asearch tree, and an uninstantiated variable v in N . Let g be the total weight of clauses thathave been violated at N , and pi(v) and ni(v) be the total weights of clauses of i literals inN which have v as positive and negative literals, respectively.4.1. UP1: Pure literal rule(cid:5)• Pure literal rule: Ifki=1 ni(v) = 0, force v = T and ignore v = F ; ifforce v = F and ignore v = T .(cid:5)ki=1 pi(v) = 0,The pure literal rule is also known as monotone variable fixing [28]. Although an algorithmusing this rule can only get a very moderate improvement on SAT [33], experiments doneby Wallace showed that improvement of the pure literal rule is considerable for max-2-SAT [42]. We include this rule in our extended DPLL algorithm for max-SAT.4.2. UP2: Upper bound rule• Upper bound rule: If p1(v) + g (cid:1) α, force v = T and ignore v = F ; if n1(v) + g (cid:1) α,force v = F and ignore v = T ; if both conditions hold, prune the current node.The upper bound rule is self evident. When setting v = F , at least p1(v) + g clauses willbe violated, making it unfavorable comparing to the best variable assignment found so far.4.3. UP3: Dominating unit-clause rule• Dominating unit-clause rule: If p1(v) (cid:1)ki=1 ni(v), set v = T and ignore v = F ;(cid:5)ki=1 pi(v), set v = F and ignore v = T ; if both conditions hold, i.e.,if n1(v) (cid:1)p1(v) = n1(v), set v = T or v = F and ignore the other value.(cid:5)The dominating unit-clause rule was first proposed by Niedermeier in [35]. It has beenapplied to max-2-SAT in [46]. This rule is self-evident, because setting v = F causes p1ki=1 n1(v) clausesclauses to be violated immediately, which is no better than violatingif v = T . Nevertheless, for a pedagogical purpose and to simplify the proof to the next,(cid:5)56Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80new propagation rule, we prove UP3 in Appendix A using the nonlinear formulation ofmax-SAT.4.4. UP4: Coefficient-determining propagation ruleUP4 is a new unit propagation rule that was derived from a nonlinear programmingformulation of max-SAT. It significantly differs from the other three propagation rules; itfocuses on individual variables rather than collectively on all clauses of certain lengths.The main idea of UP4 is to infer whether the coefficient Fxi of a (single) variable xi is(cid:2) 0, we need to fix variable xi to false ornonpositive or nonnegative; if Fxitrue, respectively, in order to minimize the objective function of the problem. However, to(cid:2) 0 is not straightforward, particularly for max-3-SAT and beyond,ensure Fxibecause Fxi is no longer a linear function of the variables of the problem. To circumventthe difficulty, we consider an upper bound UB(xi) and a lower bound LB(xi) of Fxi . IfUB(xi) (cid:2) 0, Fxi cannot be positive; likewise, if UB(xi) (cid:1) 0, Fxi cannot be negative. UP4can be summarized as follows.(cid:1) 0 or Fxi(cid:1) 0 or Fxi• Coefficient-determining propagation rule: For each un-instantiated variable vi and itscorresponding integer variable xi , if LB(xi) (cid:1) 0, set vi = F and ignore vi = T ; ifUB(xi) (cid:2) 0 set vi = T and ignore vi = F ; if both conditions hold, i.e., UB(xi) =LB(xi), set vi = T or vi = F and ignore the other value.For max-2-SAT,UB(xi) = πi +(cid:1)πi,jandLB(xi) = πi +xj ∈V \{xi },πi,j >0(cid:1)πi,j ,xj ∈V \{xi },πi,j <0where πi and πi,j are as defined in Eq. (1). The detail for the derivation of these bounds isin Appendix B.For max-3-SAT, it seems to be difficult to obtain closed forms for UB(xi) and LB(xi).However, upper and lower bounds can be still computed at each node during the search bysimplifying quadratic terms into linear terms. The simplification process involves differentways of turning quadratic terms into linear ones under different conditions to get tightbounds. In other words, the process computes something like piece-wise linear functions.The detail is provided in Appendix B.Note that simplying a quadratic term to a linear term loosens the tightness of the corre-sponding bounds, making them less effective. There are also interactions among quadraticterms as well as interactions between quadratic and linear terms, which may further de-grade the tightness of the bounds. Their ramification is that the UP4 rule becomes lesseffective as problem constrainedness increases. Such consequences have been observed inour experiments, including those reported in Section 7.Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80575. Linear programming based lower boundAs mentioned in Section 3, an effective way to improve DPLL for max-SAT is to in-troduce an admissible lower bound function h to estimate the total weight of clauses thatcannot be satisfied at a node during the search. If the lower bound estimate h plus the totalweight g of clauses that have already been violated is greater than or equal to the currentupper bound α, i.e., g + h (cid:1) α, the node can be pruned. One of the main contributions ofthis paper is such an effective lookahead lower bound for max-SAT.The new LP lower bound is simple. To compute the h value of a node N , we apply theILP formulation (Section 2) to N . However, rather than solving the remaining max-SAT atN by ILP, we apply linear programming (LP) to it instead. In other words, we do not restrictthe mapped variables (e.g., x1, x2, . . . , y1, . . .) to integers 0 or 1, but rather allow them tobe real values in [0, 1]. As a result, we obtain an admissible estimate of the actual solutioncost of the ILP instance since LP is less restricted than ILP. By relaxing the problem to LP,we can obtain lower bound estimation with less computation.However, the application of an LP-based lower bound needs to be handled with furthercare. Note that the solution to an LP relaxation problem at a node may have too manyvariables that take values in the middle of the range of [0, 1], i.e., taking a value close to1/2. Such “fractional” variables are troublesome in binary clauses. For example, two suchvariables in a binary clause can take values slightly more than 1/2, forcing the auxiliaryvariable (y variable in the LP formulation, Section 2) for the clause to take value 0, yieldingno contribution to the overall lower bound function. Similar scenarios can occur to three-literal clauses. Fortunately, such situations will not occur in unit clauses because decisionvariables can always contribute to the overall lower bound function even setting literalswithin unit clauses to “fractional” value. Therefore, we only apply the LP lower bound tothe nodes that have unit clauses, making it more accurate and more efficient to compute.Moreover, during the search, unit clauses do not need to be eliminated, since the increase inthe expected lower bound from eliminating unit clauses has already been calculated exactlyby applying the LP lower bound, namely, if we apply the LP lower bound to compute h,any expected gain on the g value from unit clauses has already been taken into account inthe h value. All in all, DPLL + LP boosts the lower bound value even without increasingthe g value.In principle, applying a stronger lower bound function (i.e., LP-based lookahead lowerbound in our case) can reduce the effective branching factor of a search. The complexityof extended DPLL algorithm is exponential in the number of constraints. Assuming thatthe effective branching factor of the extended DPLL algorithm is b and its average searchdepth for a given problem is d, we have d = O(km), where k is a constant factor lessthan 1, and m is the number of constraints. The complexity of extended DPLL is thenT = O(bd ) = O(bkm). Using LP-based lower bound, since more nodes can be pruned,the effective branching factor will be reduced to bLP < b, and the total node expendedwill become O(bkmLP ). However, there is an overhead on the time of computing the LP-based lookahead lower bound. In our implementation of the LP-based lower bound, weused the Simplex algorithm in CPLEX package [26] for LP. Theoretically, the worst-casecomplexity of the Simplex algorithm is exponential [9]. However, in practice, the Simplexalgorithm can efficiently solve most problems in nearly linear time of the dimension of a58Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80problem or the number of constraints encoded in a linear program [16,41]. Therefore, wecan consider the overhead for each LP call to be approximately O(m). Thus, the overalltime complexity of extended DPLL using an LP-based lower bound is TLP = O(m)O(bkmLP ).Combining these factors, TLP < T when the number of constraints m is large. This willbe verified by our experiments in Section 7. This also means that on under-constrainedor modest-constrained problems, the overhead of LP makes the LP-based lower boundineffective. This observation may explain why it has been difficult to make LP effective onsatisfiability problem instances.6. Variable ordering, revisitedVariable ordering has not been very well studied for max-SAT. The two most popularvariable ordering heuristics, the Mom’s rule and the two-side J–W rule (see Section 3.3),were originally developed for SAT. To take advantage of the power of unit propagations inSAT, these rules focus on variables appearing more often in the shortest clauses, which maynot be effective for max-SAT. In addition, as our empirical analysis in Section 7 shows, theydo not perform well on problems with various constrainedness; neither of these two rulesdominates the others under all conditions. Motivated to address these issues, we proposethe following two new variable ordering rules for max-2-SAT and max-3-SAT, respectively.6.1. Binary-clause first variable ordering for max-2-SATDue to the efficient Lower bound functions and unit propagation rules in max-2-SAT,the conflicting unit clauses in max-2-SAT, e.g., (v) and ( ¯v), can cause the lower boundto increase without being branched off. Therefore, a plausible strategy for max-2-SAT isto generate, rather than remove, as many unit clauses as possible so as to produce moreconflicting unit clauses to increase lower bound. An effective implementation of this strat-egy is to give a higher weighting to the variables appearing often in binary clauses thanthe variables in unit clauses, since the instantiation of this variable may give rise to themaximum number of new unit clauses. We call this variable selection rule binary clausesfirst rule. As we will see in Section 7, binary clauses first rule is effective on max-2-SAT;with the weighting ratio of 1:25, binary clause first rule is more effective than the Mom’sand the two-side J–W rules in max-2-SAT.6.2. Dynamic-weighting variable ordering for max-3-SATThe Mom’s and the two-side J–W rules described in Section 3 use static weightings, inthat the weighting ratios in the variable ordering are fixed throughout a search regardlessof problem constrainedness. As we will see in the next section, in max-3-SAT, they are ef-fective within different ranges of problem constrainedness. Compared to SAT, max-3-SATcan contain problem instances with various constrainedness. These two variable order-ings for SAT may not be effective for max-3-SAT. To address this problem, we propose adynamic-weighting variable ordering.Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8059Dynamical-weighting variable ordering for a max-3-SAT problem with the total numberof clauses C and the total number of variables V , in each node of a DFBnB searchtree explored by the extended DPLL algorithm, select a variable v that maximizesJ (v) + J ( ¯v) over all un-instantiated variables, whereJ (v) =(cid:1)v∈Ciwiβ(r)−nini is the number of literals in the ith clause Ci , wi is the weight of the ith clause,r is the clause/variable ratio (r = C/V ), and(cid:6)β(r) =5,26 − 3.33r,2,if r < 6.3;if 6.3 (cid:2) r (cid:2) 7.2;if r > 7.2.In the above function, the values 6.3 and 7.2 are determined empirically on randomlygenerated problem instances (see Section 7 for information of how they were generated).To obtain these empirical values, we tested the different weighting ratios βs on probleminstances of different constrainedness, recorded the best β value for each individual con-strainedness, and then built a linear function to best fit these data points. Our experimentsin Section 7 show that in max-3-SAT, when clause/variable ratio is smaller than 6.3, theMom’s rule performs better; when clause/variable ratio is bigger than 7.2, the two-sidedJ–W rule works better. Therefore, this method can switch weighting ratio β in variableordering from that close to the Mom’s rule to that similar to the two-side J–W rule asconstrainedness increases, thus having good performance in nearly all cases.7. Experimental evaluation and applicationsThe combination of the three strategies discussed in Sections 4, 5, and 6 leads to anintegrated algorithm for max-SAT, which we shorthand as MaxSolver. In this section, weexperimentally evaluate the performance of MaxSolver using various problem instances,including those from the SATLIB [25]. When not explicitly stated otherwise, all our exper-iments obeyed the following conditions: (15) an initial upper bound for each problem wascomputed by WalkSAT [32,38] with 10 random restarts and 100 ∗ |V | flips per try, where|V | is the number of variables for a given problem instance; (2) all experiments were runon PCs with Pentium 2.4 GHZ processor and 512 MB cache; (3) The LP solver we used tocompute the h value was CPLEX 8.0 [26]. Note that we used Dual-Simplex algorithm inCPLEX, which optimizes the computation of the h value of the current node based on theexisting solution to its parent node in the search tree. This feature can significantly reducethe number of iterations of the Dual-Simplex algorithm, particularly if the current problemis similar to the problem solved in the parent node.We start with an investigation on the efficacy of the three improving strategies, and thencompare our MaxSolver directly with all existing max-SAT algorithms that we are awareof and able to get source code from their authors.60Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–807.1. Evaluation of new strategiesWe first compared the average running time of the extended DPLL with and withoutunit propagations (or the LP lower bound) in combinations of different variable orderings.We ran three algorithms: DPLL, DPLL with different unit propagation (DPLL + UPs), andDPLL with the LP lower bound (DPLL + LP), where UP and LP stand for unit propaga-tions and the LP lower bound, respectively. Each algorithm was tested with two variableorderings, the Mom’s rule and the two-sided J–W rule. In the following figures, the averagerunning time of each experiment was given with a 95% confidence interval.7.1.1. Max-3-SAT problemsThe experiments were carried out on random max-3-SAT with 80 variables andclause/variable (C/V ) ratios ranging from 4 to 8 in an increment of 0.5. For C/V ratiosfrom 4 to 6 and from 6.5 to 8, 100 and 10 problem instances were used, respectively.Unit propagation rules are only effective on certain arrangement of constrainedness.As shown in Fig. 1, each UP rule except the UP1 can reduce DPLL’s running time by2–10 times. Detailed running time and speedup for each UP rule are in Tables 1 and 2.When the C/V ratio is low (from 4 to 5.5), the initial upper bound α is close to 0, thanksto the effectiveness of the Walksat algorithm. As a result, solving max-3-SAT is similar toFig. 1. Effects of unit propagation (UP) rules on unweighted max-3-SAT. For each group of error bars, from leftto right are the results from DPLL, DPLL with UP1, UP2, UP3 and UP4, respectively, and DPLL with all fourUP rules.DPLL + UP2DPLL + UP1Table 1Effects of unit propagation (UP) rules on unweighted max-3-SAT, tested on two-sided J–W rule. The runningtime in seconds is given, followed by its relative speedup (DPLL/DPLL + UPs) in parenthesesDPLL + UP1,2,3,4C/V DPLL0.001 (148.0)0.074 (2.0)0.1484.00.001 (148.0)0.118 (12.5)0.878 (1.7)1.4774.5(37.9)0.039(5.4)2.3167.251 (1.7)12.5545.0(14.4)0.870(3.8)23.85954.697 (1.7)90.4115.5(7.0)12.950(3.0)123.904227.258 (1.6)376.3906.0(3.6)103.533(2.7)1157.851433.563704.714 (1.6)6.5(2.5)465.809(2.4) 1496.634 (2.4) 1732.674 (2.1) 1443.2927.03643.094 2203.376 (1.6) 1502.187(2.5)(2.2) 4514.648 ( 2.2) 5734.217 (1.7) 4533.2127.5 10005.426 6076.131 (1.6) 4637.295(2.2)(2.0) 10656.930 (2.1) 13643.647 (1.6) 10323.3298.0 22153.242 13526.077 (1.6) 11053.094(2.1)0.004 (37.0)0.172 (8.6)2.153 (5.8)21.453 (4.2)132.326 (2.8)478.864 (2.4)0.002 (74.0)0.144 (10.0)2.372 (5.3)23.410 (3.9)119.434 (3.2)431.936 (2.7)DPLL + UP4DPLL + UP3Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8061DPLL + UP1DPLL + UP3Table 2Effects of unit propagation (UP) rules on unweighted max-3-SAT, tested on the Mom’s rule. The running time inseconds is given, followed by its relative speedup (DPLL/DPLL + UPs) in parenthesesDPLL + UP4DPLL + UP2C/V DPLL4.04.55.05.56.06.57.07.58.00.002 (3.5)0.004 (1.8)0.0070.0010.001 (7.0)0.001 (7.0)0.034 (3.2)0.073 (1.5)0.1080.0120.017 (6.4)0.015 (7.2)0.394 (5.4)1.339 (1.5)2.1100.2210.384 (5.5)0.377 (5.6)10.164 (3.3)21.932 (1.5)33.8434.6327.343 (4.6)7.229 (4.7)112.176 (2.3)171.548 (1.5)261.84360.33564.755 (4.0)64.875 (4.0)419.782 (2.7)1141.163717.444 (1.6)303.323309.602 (3.7)380.333 (3.0)1859.716 (2.8) 1975.385 (2.6) 2912.623 (1.8)5136.232 3928.692 (1.3)2142.34622737.991 17490.939 (1.3)9060.268 (2.5) 10335.454 (2.2) 12303.489 (1.8) 11016.21451183.832 39371.538 (1.3) 29720.075 (1.7) 26938.421 ( 1.9) 29934.167 (1.7) 32912.432DPLL + UP1,2,3,4(7.0)(9.5)(9.4)(7.3)(4.3)(3.8)(2.4)(2.1)(1.6)Fig. 2. Effects of the LP lower bound on unweighted max-3-SAT.solving 3-SAT. In this case, the percentage of unit clauses is relatively high throughout thesearch, making the conditions of unit propagations easy to satisfy and unit propagationshappen frequently.DPLL + LP, on the contrary, is ineffective on low-constrainedness regions, due to itsoverhead to the running time. However, as shown in Fig. 2, where we directly comparedDPLL + LP and DPLL without unit propagation, the running time overhead of LP is gradu-ally compensated by the amount of pruning it provides as the C/V ratio increases, makingLP effective on over-constrained problems. As we mentioned in Section 5, the computa-tion time required by an LP call is linear to the number of constraints of the problem athand. When constrainedness is low, such a linear-time overhead may be still too costlycompared to a single DPLL node expansion. On the other hand, in a highly constrainedsituation where the upper bound α is large, DPLL without LP lower bound may have tosearch sufficiently deep along a search avenue before it can backtrack, resulting in a largeamount of search cost, which is typically exponential in search depth. DPLL + LP, on theother hand, can estimate a reasonably accurate h value with a relatively small overheadfor over-constrained problems. As shown in Fig. 3(a), the number of expanded nodes withLP grows more slowly than that without LP. The different growth rates in the number ofexpanded nodes between using LP and not using LP make DPLL + LP outperform theoriginal DPLL on over-constrained problems.62Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80Fig. 3. (a) Expanded nodes of DPLL + LP, (b) effects of not assigning weightings to unit clauses in DPLL + LP.Both (a) and (b) are on unweighted max-3-SAT.Note that when running DPLL + LP, we modified both Mom’s and the two-sided J–Wrules. Instead of using weighting ratios of 4:2:1 and 25:5:1, we assigned 0:5:1 as weightingratio to the Mom’s rule and 0:2:1 to the two-sided J–W rule. As discussed in Section 5, weneed not eliminate any unit clause in DPLL + LP, so we assign “zero value” to unit clause inweighted variable order. The effect of this “zero unit clause weighting” in the Mom’s ruleis shown in Fig. 3(b). In DPLL + LP, when we change weighting ratio from 25:5:1 to 0:5:1,the CPU time can be reduced by 20 percent in low-constrained regions, e.g. (C/V = 4),and 80 percent in high-constrained regions, e.g. (C/V = 8). The similar effect also existsfor the two-sided J–W rule.The Mom’s and the two-sided J–W rules affect unit propagations and the LP lowerbound differently. As shown in Figs. 4(a) and 4(b), the Mom’s rule combined with DPLLand DPLL + UP has relatively better performance in not highly constrained regions(C/V < 6), while it is outperformed by the two-sided J–W rule as C/V ratio increases.(Note that the vertical axes of the figures are logarithmic, so the actual difference in run-ning time is substantial.) In DPLL and DPLL + UP, the Mom’s rule tends to get rid of unitclauses quickly. If the C/V ratio is low, so is the upper bound α. It is more likely that anearly increase in the number of violated constraints g will result in a lower bound valueexceeding α, forcing the search to backtrack early. However, if the C/V ratio and upperbound α are high, it is not so easy for the value of g + h to exceed α. Therefore, althoughthe Mom’s rule can increase the g value in an early stage of the search, it actually producesfewer unit clauses to contribute to the g value as the search progresses. This is mainly be-cause in the Mom’s rule, the weightings on binary and three literal clauses are smaller thanthose in the two-sided J–W rule, making it more difficult for non-unit clauses to be turnedinto unit clauses. Therefore, the Mom’s rule performs better than the two-sided J–W rulein under-constrained regions, but worse in over-constrained regions.In short, our results showed that the Mom’s and the two-sided J–W rules are effectiveunder different problem constrainedness. Our new dynamic-weighting variable orderingrule was developed to combine their strengths under different conditions. Moreover, insteadof statically setting the weightings, the new rule dynamically adjusts the weightings basedon the current situation of the search. As the results in Figs. 4(a) and 4(b) show, the newrule is nearly always the winner under different constraint tightness.Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8063Fig. 4. Effects of different variable orderings on unweighted max-3-SAT.Compared to DPLL and DPLL + UP, the Mom’s and the two-sided J–W rules do notmake much difference to DPLL + LP as shown in Fig. 4(c). Unlike DPLL and DPLL + UPthat use only the g value, DPLL + LP uses both the g value and the h value. The g valueis only from unit clauses, while the h value can be contributed by binary and three-literalclauses, making all clauses in DPLL + LP contribute to the lower bound. Namely, no matterwhether a clause is removed early or later during the search process of a DPLL + LP searchtree, it can contribute to the lower bound through the g value (if the clause is removedearly) or the h value (if the clause is removed later). As a result, it does not matter whethera variable is branched early or later in DPLL + LP; and DPLL + LP is relatively lesssensitive to variable ordering than DPLL and DPLL + UP.7.1.2. Max-2-SAT problemsCompared to max-3-SAT, the scenario on max-2-SAT is relatively simple. Most strate-gies applicable to max-2-SAT are less sensitive to constrainedness. Because there are onlytwo literals in each clause, any simplification to a problem formula will result in some unitclauses, which, in turn, make unit propagations happen frequently. In addition, a relativelyhigher percentage of unit clauses gives rise to higher h values, which make the LP lowerbound more efficient.These arguments can be verified by experimental results. In the experiments, we usedrandom instances with 80 variables and C/V ratios ranging from 2 to 5 in an incrementof 0.5. For C/V ratios from 2 to 3 and from 3.5 to 5, 100 and 10 problem instances wereused, respectively. As shown in Fig. 5, unit propagation rules are very effective on all con-64Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80Fig. 5. Effects of unit propagation (UP) rules on unweighted max-2-SAT. For each group of error bars, from leftto right are the results from DPLL, DPLL with UP1, UP2, UP3 and UP4, respectively, and DPLL with all fourUP rules.DPLL + UP1Table 3Effects of unit propagation (UP) rules on unweighted max-2-SAT, tested on two-sided J–W rule. The runningtime in seconds is given, followed by its relative speedup (DPLL/DPLL + UPs) in parenthesesC/V DPLL2.02.53.03.54.04.55.0DPLL + UP40.1090.001 (109.0) 0.001 (109.0)2.1660.007 (309.4) 0.007 (309.4)18.8200.042 (448.1) 0.040 (470.5)127.6510.276 (462.5) 0.254 (502.6)394.2741.068 (369.2) 1.090 (361.7)1061.1484.067 (260.9) 3.936 (269.6)3086.905 1442.981 (2.1) 20.246 (152.5) 15.846 (194.8) 10.457 (295.2) 9.634 (320.4)DPLL + UP30.002(54.5)0.013 (166.6)0.073 (257.8)0.432 (295.5)1.449 (272.1)4.762 (222.8)DPLL + UP20.001 (109.0)0.019 (114.0)0.113 (144.2)0.657 (194.3)1.965 (200.6)6.284 (168.9)0.032 (3.4)0.828 (2.6)8.952 (2.1)50.205 (2.5)167.938 (2.3)482.873 (2.2)DPLL + UP1,2,3,4DPLL + UP1Table 4Effects of unit propagation (UP) rules on unweighted max-2-SAT, tested on the Mom’s rule. The running time inseconds is given, followed by its relative speedup (DPLL/DPLL + UPs) in parenthesesDPLL + UP1,2,3,4DPLL + UP4DPLL + UP2DPLL + UP3C/V DPLL0.0010.0022.0(90.0)(45.0)0.002(45.0)0.001 (90.0)0.015 (291.8)0.042 (104.2)2.50.028 (156.3)0.014 (312.6)0.171 (461.5)0.505 (156.3)3.00.310 (254.5)0.169 (466.9)2.377 (427.1)5.795 (175.2)3.53.694 (274.3)2.246 (451.9)10.064 (403.2)24.543 (165.4)4.017.092 (237.4)9.585 (423.4)73.602 (114.5)4.542.926 (196.3)57.354 (146.9)40.899 (206.0)203.894 (116.8) 124.990 (190.6) 110.876 (216.6)(89.6)5.00.030 (3.3)1.589 (2.8)27.526 (2.8)1015.202 234.585 (4.3)4058.255 871.081 (4.6)8425.353 2161.377 (3.9)23822.247 6383.872 (3.7) 261.7550.0904.37778.910strainedness ranges of max-2-SAT. In either variable ordering, each unit propagation rulecan independently reduce DPLL’s running time by 10–1000 times, and their combinationmakes the greatest effect under most constrainedness. Moreover, unlike max-3-SAT, theeffectiveness of unit propagation rules on max-2-SAT does not degrade as problems be-come highly constrained. (See Tables 3 and 4 for detailed performance of each UP rule.)As shown in Fig. 6, DPLL + LP is also very effective in all constrainedness ranges. Forthe variable orderings in Fig. 7, although binary clause first rule is the worst one in DPLLexperiments, it is the winner for nearly all the situations in DPLL + UP experiments. Sinceit is DPLL + UP but not DPLL that we will implement in our integrated max-2-SAT algo-Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8065Fig. 6. Effects of the LP lower bound on unweighted max-2-SAT.Fig. 7. Effects of different variable orderings on unweighted max-2-SAT.rithm, we will adopt binary clause first rule for max-2-SAT. All these results suggest thatfor max-2-SAT, the LP lower bound and all the unit propagation rules should be appliedand binary clause first rule is our final choice.7.1.3. Weighted max-SATWe used the same set of random max-SAT problems that we experimented with in theunweighted case, except that each clause was given a random integer weighting uniformlydistributed between one and ten. We show the results of combined effects of unit propa-gation rules on weighted max-3-SAT (Fig. 8), and on weighted max-2-SAT (Fig. 9). Theresults show that our conclusions on unweighted max-SAT are almost equally valid onweighted max-SAT, i.e., unit propagation rules are effective on weighted max-2-SAT ormoderately constrained weighted max-3-SAT, LP lookahead lower bound is effective onweighted max-2-SAT or highly constrained weighted max-3-SAT, and the new dynamic-weighting variable ordering is still effective on weighted max-3-SAT. One additional ob-servation is that for the same problem size, weighted problems are usually easier than thecorresponding unweighted problems, which can be seen by comparing Figs. 1 and 5 withFigs. 8 and 9, respectively.66Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80Fig. 8. Effects of unit propagations (UP) on weighted max-3-SAT.Fig. 9. Effects of (a) unit propagations, (b) variable ordering on weighted max-2-SAT.7.2. Integrated algorithm and its performanceBased on our understanding of the effects of the existing strategies and heuristics, in thissection, we study the efficacy of our new integrated algorithm, MaxSolver. To reiterate,MaxSolver incorporates in extended DPLL the three new strategies. In our experimentswith MaxSolver, we applied the unit propagation rules only to max-2-SAT or moderatelyconstrained max-3-SAT (with c/v ratio of 3 to 6), the LP lookahead lower bound to max-2-SAT or highly constrained max-3-SAT (with c/v ratio more than 6), and our new dynamic-weighting variable ordering to max-3-SAT.To fully evaluate its performance, we compared MaxSolver with following existing al-gorithms for max-SAT and maximum CSP (max-CSP) which we are aware of and whosesource codes are available to us:• A DPLL-based solver BF developed by Borchers and Furman [4].• A DPLL-based solver AMP developed by Alsinet, Manya, and Planes [2].• A DPLL-based max-2-SAT solver SZ_LB4a developed by Shen and Zhang [39].• A Pseudo Boolean Optimization solver PBS2.1 developed by Aloul [1].• A Weighted CSP-based solver WCSP developed by Givry and Larrosa [17].Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8067These algorithms contain most of the known techniques for SAT, max-SAT and max-CSP. To the best of our knowledge, BF, AMP, and SZ_LB4a are the only exact max-SATsolvers implemented in C language that are variants of DPLL method. Another earlier exactmax-SAT solver implemented by Wallace [43] was in Lisp, so we do not include it in ourcomparison. BF is an extended DPLL with the Mom’s rule and a simple unit propagationthat is similar but weaker than our UP2. AMP is derived from BF and includes a lowerbound function described in Section 3.2 and uses the two-sided J–W rule. SZ_LB4a is aspecialized max-2-SAT solver with a powerful max-2-SAT lower bound. However, it is notapplicable to weighted max-2-SAT. PBS is a specialized 0-1 ILP solver and uses advancedtechniques such as conflict diagnosis, random restarts, improved backtracking, and cuttingplanes. WCSP encodes a max-CSP (and max-SAT) into a weighted constraint network andsolves the problem using the state-of-art algorithms for weighted CSP. We used the defaultsettings for all these solvers, except for PBS which used VSIDS decision heuristic [34](as advised by the author). The results presented below can be viewed as a comprehensiveevaluation of these existing algorithms on max-SAT.We used random unweighted max-SAT instances generated by the MWFF package ofSelman [37], random max-SAT instances from Borcher’s max-SAT library [5], and unsatis-fiable instances in SATLIB [25], which were generated from applications such as planningand model checking. The results are respectively in Tables 5–11, where “–” indicates anincomplete run after 5 hours of CPU time. For each problem class, the tables list either theC/V ratio r or the numbers of variables V and clauses C, followed by columns for therunning times of all solvers in seconds. #Unsat in Tables 7, 8, and 11 are the number ofviolated clauses in unweighted max-SAT, and cost in Tables 9 and 10 are the total weightTable 5Average CPU times on unweighted max-2-SAT of 80 variablesC/V MaxSolver2.02.53.03.54.04.55.00.000.010.040.180.853.8913.00BFAMP0.041.2151.79687.55(36)(207)(1300)(3900)12228.00 (14000)––0.071.0411.8780.00485.10– 2073.52– 4617.56(66)(179)(298)(449)(575)(532)(355)3.01PBSWCSP0.03(3013)0.14186.00 (320612)0.57–1.59–5.80–– 17.28– 45.47–––––SZ_LB4a0.00(–)0.01 (1.0)0.05 (1.3)0.34 (1.9)1.62 (1.9)8.23 (2.1)32.73 (2.5)(27)(14)(14)(9)(7)(4)(3)Table 6Average CPU times on unweighted max-3-SAT of 80 variablesC/V4.04.55.05.56.06.57.07.5MaxSolver0.000.010.154.2538.00228.001723.007493.00BF0.000.010.196.95104.00629.009498.00–(1.0)(1.0)(1.3)(1.6)(2.7)(2.8)(5.5)–AMP0.001.147.4364.79386.001342.527937.17–(1.0)(87.3)(50.5)(15.2)(10.2)(5.9)(4.6)–PBS0.0144.90––––––(16)(3563)––––––WCSP0.031.186.6027.54107.25379.49877.173792.67(48.0)(90.4)(44.0)(6.5)(2.8)(1.7)(0.5)(0.5)Table 7Computation results for unweighted max-2-SAT test problems from Borcher’s libraryInstancep100p150p200p250p300p350p400p450p500p2200p2300p2400p2500p2600p2300p2450p2600|V |505050505050505050100100100100100150150150|C|100150200250300350400450500200300400500600300450600#Unsat MaxSolver4816223241456366515294465422380.010.010.020.020.070.120.090.650.420.080.040.3211.82106.220.061.9310.41BF0.010.044.8128.16394.092875.612592.49––0.34575.69–––0.08––(1.0)(4.0)(240.5)(108.0)(5629.9)(23963.4)(28805.4)––(4.25)(14392.3)–––(1.3)––AMP0.160.070.830.5710.6122.479.7295.8139.780.88106.162261.25––0.51––(16.0)(7.0)(41.5)(28.5)(151.6)(187.3)(108.0)(147.4)(94.8)(11.0)(2654.0)(7066.4)––(8.5)––PBS0.061.64–––––––0.10––––0.99––(6.0)(164.0)–––––––(1.3)––––(16.5)––WCSP0.010.010.020.020.190.290.151.520.800.131.6713.991539.562762.361.28154.962987.56(1.0)(1.0)(1.0)(1.0)(2.7)(2.4)(1.7)(2.3)(1.9)(1.6)(41.8)(43.7)(130.3)(26.0)(21.3)(80.3)(287.0)SZ_LB4a0.010.030.030.040.060.100.060.180.140.030.330.8850.7295.640.075.5940.41(1.0)(3.0)(1.5)(2.0)(0.9)(0.8)(0.7)(0.3)(0.3)(0.4)(8.3)(2.8)(4.3)(0.9)(1.2)(2.9)(3.9)68Z.Xing,.WZhang/ArtificialIntelligence164(2005)47–80Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8069BFPBS#Unsat MaxSolverTable 8Computation results for unweighted max-3-SAT test problems from Borcher’s libraryInstance |V |p3250p3300p3350p3400p3450p3500p3500p3550p3600p3675p3750AMP3.96 (132.0)0.01 (0.3)3.150.10 (0.8)6.53 (2.3)7.8144.71 (3.5) 23.74250.69 (7.3) 42.86150.74 (7.3) 29.84–––––|C|250 250450 30050 350850 400 1150 450 1550 500 154100 5005100 5508100 6002150 6755150 750(7.3)0.22(26.2) 121.30 (1010.8)–(2.8)–(1.9)–(1.2)–(1.4)–––––––0.030.122.8412.7334.4920.698.8737.192913.418.182343.048.27 (0.9)41.01 (1.1)6385.55 (2.2)3.48 (0.4)2775.47 (1.2)–––––––––WCSP0.020.181.122.993.862.48103.59221.973149.86(0.7)(1.4)(0.4)(0.2)(0.1)(0.1)(11.7)(6.0)(1.1)– 1419.54 (173.8)–––BFPBSAMPWCSP|C| Cost MaxSolver0.030.050.585.9722.77Table 9Computation results for weighted max-2-SAT test problems from Borcher’s libraryInstance |V |0.0716wp2100 50 1000.0934wp2150 50 1500.1169wp2200 50 2000.17wp2250 50 250960.23wp2300 50 300 1320.92wp2350 50 350 2110.38wp2400 50 400 2110.67wp2450 50 450 2571.88wp2500 50 500 3180.057wp2200 100 2000.29wp2300 100 300676.94wp2400 100 400 119532.37wp2500 100 500 241289.76wp2600 100 600 2660.2424wp2300 150 300wp2450 150 45053.4879wp2600 150 600 189 3527.520.01 (0.1)(0.4)0.03(0.6)0.040.01 (0.1)(0.4)(7.6)0.680.040.01 (0.1)(1.5) 220.25 (2002.3)0.160.03 (0.2)––(5.2)0.880.04 (0.2)––1.26(5.5)0.29 (0.3)––28.32 (30.8)0.07 (0.2)––9.16 (24.1)0.09 (0.1)––8.12 (12.1)0.36 (0.2)–0.0142.30 (22.5)0.01 (0.2)––0.10(2.0)0.46 (1.6)––23.05 (79.5)––– 3728.47 (537.2)15.35 (52.9)– 220.61 (0.4)––––– 145.37 (0.5)––––0.94 (3.9)(6.1) 11.361.47(1.8)(47.3)––32.35 (0.6)– 5321.10 (1.5)–(0.4)(0.6)(5.3)(35.1)(99.0)1078.74 (1172.5)532.97 (1402.6)1720.42 (2567.8)5141.21 (2734.7)(2.0)86.56 (298.5)6857.52 (128.2) 5752.42 (107.6)–––––0.430.10––Table 10Computation results for the weighted max-3-SAT test problems from Borcher’s library|V |Instance50wp325050wp330050wp335050wp340050wp3450wp350050wp3500 100wp3600 100wp3675 150wp3750 150PBS|C| Cost MaxSolver BF2503003504004505003006006757500.040.070.210.530.3721.150.1645.130.282.1711325333577626250.060.110.691.701.52143.440.52213.94(1.5)(1.6)(3.3)(3.2)(4.1)(6.8) 50.73 (2.4)(3.2)–(4.7)–3.96 (14.1)–(7.9)17.09–AMP(0.3)0.06 (1.5)(18.9)0.14 (2.0)1.13 (5.4)(2429.1)3.07 (5.8) 7043.20 (13289.1)(8253.8)2.03 (5.5) 3053.90––37.37(233.6)–877.06–0.011.32510.11(3132.4)–WCSP0.010.070.310.530.294.121.39– 313.66(0.3)(1.0)(1.5)(1.0)(0.8)(0.2)(8.7)(7.0)8.71 (31.1)94.99 (43.8)––––70Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80Table 11CPU times on unsatisfiable SATLIB instances|C| #Unsat MaxSolver BFAMPPBSWCSP|V |Instance100 850 2jnh8100 850 2jnh9100 850 2jnh14100 800 2jnh211100 900 3jnh307100 900 2jnh30850 100 1aim50-2.0no150 100 1aim50-2.0no2aim50-2.0no350 100 1aim100-1.6no1 100 160 160 160 1pret60-4060 160 1pret60-6060 160 1pret60-7575 200 1dubois2590 240 1dubois300.010.020.010.010.020.040.060.030.03649.253.273.354.1216.772217.630.04 (4.0)0.05 (2.5)0.03 (3.0)0.03 (3.0)0.32 (16.0)0.06 (1.5)0.02 (0.3)0.02 (0.7)0.02 (0.7)0.32 (32.0)1.18 (118.0)2.89 (289.0)0.32 (16.0)1.65 (82.5)2.90 (145.0)0.31 (31.0)3.1 (310.0)2.38 (238.0)0.31 (31.0)0.89 (89.0)1.60 (160.0)0.76 (38.0) 24.80 (1240.0)3.97 (198.5)0.38 (9.5)3.59 (89.8)6.61 (165.2)0.10 (1.7)(2.5)0.15(0.2)0.010.07 (2.3)(1.3)0.04(0.3)0.010.09 (3.0)(2.0)(0.3)0.010.06449.55 (0.7) 1047.19 (1.6)(1.0)(0.0) 670.720.0110.49 (3.2)4.68 (1.4)85.27 (26.1)(0.0)0.0110.53 (3.1)4.69 (1.9)85.07 (25.4)(0.0)0.144.62 (1.1)10.59 (2.6)(0.0)0.0184.94 (20.6)99.31 (5.9) 234.81 (14.0)(0.0) 2358.37 (140.6)0.212947.50 (1.3) 7280.33 (3.3) 64.42–(0.0)–of violated clauses in weighted max-SAT. The numbers in parentheses are MaxSolver’srelative speedups over the best existing method.For random unweighted max-2-SAT (Tables 5 and 7), BF degrades quickly as the C/Vratio increases. As BF is the only solver for max-2-SAT in which the Mom’s rule is applied,its poor performance indicates that the Mom’s rule alone is ineffective on max-2-SAT.Maxsolver is also much faster than AMP, which implies that our unit propagation rulescan dramatically reduce the node expansions, and that our LP lower bound is effective aswell. SZ_LB4a performs the second best for instances from Borcher’s library (Table 7),which indicates that SZ_LB4a’s special lower bound function is efficient for max-2-SAT.The other two non-DPLL solvers, PBS and WCSP, perform much worse than MaxSolver.PBS is unable to solver problems with more than moderate degree of constrainedness.For random max-3-SAT (Tables 6 and 8), BF performs better than what it does on max-2-SAT and is sometimes competitive when the C/V ratio is low. However, it still degradesfaster than MaxSolver and even AMP as the C/V ratio increases, indicating that not onlythe Mom’s rule on max-3-SAT becomes less effective, but also the LP lower bound be-comes effective as the C/V ratio increases. WCSP becomes not as efficient as MaxSolveron max-2-SAT, when the problem size exceeds 100 variables. PBS is not competitive at allon max-3-SAT.For random weighted max-2-SAT (Table 9) and weighted max-3-SAT (Table 10) in-stances from Borcher’s max-SAT library [5], we compared MaxSolver with BF and WCSP,since the other two algorithms cannot apply. In Table 9, WCSP outperforms MaxSolverand BF on 13 out 17 instances. However, most of the instances that WCSP wins have smallsizes and high constrainedness. For large problems with moderate constrainedness, Max-Solver is still the winner. MaxSolver is significantly superior to BF in Table 9, mainly dueto the tremendous effects of our new UP4 unit propagation rule. Moreover, UP4 rule be-comes increasingly more effective as the constrainedness increases. In Table 10, when theeffect of UP4 rule is moderate on weighted max-3-SAT, MaxSolver can still substantiallyoutperform BF and WCSP in all but three cases.Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8071MaxSolver also outperforms the other solvers on many instances from SATLIB. Asshown in Table 11, jnh instances are best solved using MaxSolver. For pret instances anddubois25, PBS is the winner. Note that PBS is a few orders of magnitude slower than Max-Solver on jnh instances, each of which has at least two unsatisfiable clauses. This matchesthe results in Tables 5 and 6, where PBS is the worst on highly over-constrained problems.Therefore, PBS is not suitable for hard max-SAT. worse than our MaxSolver, suitable forlow-constrained or special structure instances. WCSP is much worse than MaxSolver onall the instances tested, as it was originally developed for max-CSP. Finally, MaxSolveroutperforms BP and AMP on nearly every problem, and solves every one of them in areasonable amount of time. Therefore, all results indicate that our MaxSolver, althoughdeveloped based on random max-SAT, works fairly well on these instances with specialstructures embedded.In summary, our results show that MaxSolver and its three improving strategies areeffective on max-SAT problems, outperforming the five existing algorithms on randommax-SAT and many instances from SATLIB, often with orders of magnitude reduction inrunning time.8. Related work and discussionsA tremendous amount of research has been devoted to SAT. In this section, we discusssome previous works on max-SAT and exact algorithm for max-SAT.8.1. Exact algorithms for max-SATThere are at least three different types of exact algorithms for max-SAT. The most pop-ular among them is an extended DPLL algorithm based on Branch-and-Bound procedure.So far, the known existing DPLL-based max-SAT algorithms include BF [4], AMP [2],and SZ (in which, one of three lower bound functions LB3, LB4, and LB4a can be cho-sen) [39]. Our MaxSolver belongs to this category. The second type is an OR-based PseudoBoolean algorithm like PBS [12]. The third type is a weighted CSP-based algorithm likeWCSP [17].Freuder and Wallace carried out an early and significant study of over-constrained sat-isfaction problems by directly extending the techniques for constraint satisfaction [14,43].They proposed a number of basic ideas of constructing a DPLL-based exact max-SATsolver, most of which were discussed in Section 3.In BF algorithm [4], Borchchers and Furman first applied a local search to obtain aninitial upper bound for an exact max-SAT algorithm. This idea of obtaining a good initialupper bound has been adopted by nearly every exact max-SAT algorithm. Based on BFalgorithm, Alsinet, Manya, and Planes introduced a lower bound function and used the two-sided J–W rule for variable ordering in AMP [2]. In SZ_LB4a, Shen and Zhang developed anovel and very effective lower bound function for max-2-SAT [39]. We extend and improvethe DPLL-based max-SAT paradigm in our MaxSolver algorithm in three aspects: unitpropagation, lower bound function and variable ordering.72Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80PBS is an OR-based Pseudo Boolean algorithm [12]. It is efficient only on critically con-strained problems; its performance degrades greatly on over-constrained problems. WCSPis a weighted CSP-based algorithm [17]. Its performance improves as the constrainednessincreases. However, WCSP is still outperformed by MaxSolver on large problems. More-over, WCSP is more efficient on max-2-SAT than on max-3-SAT.8.2. Analysis of max-SATNiedermeier and Rossmanith analyzed the complexity of a particular exact max-SATalgorithm [35]. They proved that the time complexity of that algorithm is O(|F | · 1.3803K ),where |F | is the total number of literals in a formula F in conjunctive normal form andK is the number of clauses. They also proved a time bounds O(|F | · 1.3995k), where k isthe maximum number of satisfiable clauses, and O(1.1279|F |) for the same problem. Formax-2-SAT, their results imply a bound of O(1.2722k).Zhang studied the relationship between phase transitions of SAT (decision problem)and backbones (variables with fixed values among all optimal solutions) of max-SAT (op-timization problem) [47]. His results suggest that the backbone of max-SAT is an orderparameter for the problem hardness. Shen and Zhang also studied phase transitions ofmax-2-SAT [40] and empirically examined the results of phase transitions of [7].8.3. Unit propagationThe three existing unit propagation rules, UP1, UP2, and UP3, which we summarized inthis paper, were considered in many previous studies. The unit propagation rule UP1 anda rule similar to UP2 were studied in [2,42,46]. UP3 was first proposed by Niedermeierand Rossmanith [35], and was applied to max-2-SAT in [46]. Niedermeier and Rossmanithalso presented a set of transformation and splitting rules in order to provide a worst casecomplexity for max-SAT [35]. However, conditions for using most of those rules are toodifficult to satisfy. In this paper, we provide an extensive comparative analysis of theserules. Our new unit propagation rule UP4 was developed based on the idea of formulatingmax-SAT as a nonlinear program. The combination of all these four rules has been shownvery efficient in our experiments. Note that the first nonlinear 0-1 formulation of max-SATwas suggested by Hammer and Rudeanu earlier [19].8.4. Lower bounds and LP and ILP heuristicsJoy, Mitchell, and Borchers are perhaps the first to apply ILP to max-SAT [28]. Theyshowed that an ILP-based solver was able to outperform DPLL-based solvers on max-2-SAT. However, when applied to max-3-SAT, the ILP-based solver was much slower thana DPLL-based algorithm. Blair, Jeroslow and Lowe applied LP to SAT [3]. However, thebounds that they obtained were not tight at all when compared to the bounds from applyingILP. Hooker speculated that better bounds from LP might be possible [22]. In this paper,we proposed to use LP for max-SAT, and successfully showed its power on max-3-SAT forthe first time.Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80738.5. Variable orderingLittle research has been done on variable ordering for max-SAT, except the work in [43]on the effects of applying in-most-unit-clause and in-most-shortest-clause heuristics onsmall random unweighted max-SAT of 25 variables. Our binary-clause first and dynamic-weighting variable ordering heuristics are novel. The binary-clause first heuristic is ableto take advantage of the strong unit propagations and lower bound functions for max-2-SAT problem instances; the dynamic variable ordering heuristic is able to adjust itselfaccording to problem characteristics to cope with different constraint situations for max-3-SAT problem instances.8.6. Weighted max-SATIn contrast to the amount of effort devoted to SAT and unweighted max-SAT, researchon weighted max-SAT is rather limited. In addition to the BF and WCSP algorithms wecompared in this paper, the most relevant previous work is the branch-and-cut algorithm forweighted max-SAT [28]. We did not include this branch-and-cut algorithm in our analysisbecause it is compatible with the BF algorithm, as discussed in [28].9. Conclusions and future workMax-SAT is an important problem that has many real-world applications. However, theexisting algorithms for max-SAT are typically restricted to simple problems with smallnumbers of variables and low constrainedness. The main contributions of this research area novel unit propagation rule for max-SAT based on an integer nonlinear programming for-mulation of the problem, an efficient lower bound function based on linear programming,and two effective variable ordering heuristics designed specifically for max-SAT. The keyresults of this paper are three effective methods for max-SAT and an algorithm that inte-grates these methods for solving hard max-SAT instances. The three methods are a set ofunit propagation rules, a linear-programming based lookahead lower bound, and two newvariable ordering rules. We call the new integrated algorithm for max-SAT MaxSolver.We experimentally showed that these new strategies and MaxSolver are effective ondifferent max-2-SAT and max-3-SAT problems. MaxSolver is significantly superior to fiveexisting state-of-the-art algorithms for max-SAT. MaxSolver is able to significantly out-perform the existing algorithms, sometimes with orders of magnitude improvement, onmany random max-SAT instances and max-SAT instances converted from real applicationdomains.As our future plan, we will apply MaxSolver to over-constrained real-world appli-cations. For example, the Maximum Probable Explanation (MPE) problem in BayesianNetworks has been formulated as a weighted max-SAT and subsequently solved, approx-imately, by an approximation max-SAT algorithm [36]. We plan to optimally solve largeMPE problems using our new MaxSolver.74Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80AcknowledgementsMany thanks to Zhongsheng Guo for an early implementation of the DPLL algorithm,to Fadi Aloul, Javier Larrosa, Haiou Shen, and Jordi Plane for making their programsavailable to us for this research, to John Hagar for a careful reading of the paper, and tothe reviewers of this paper and an early version in [45] for many constructive commentsand suggestions, which helped improve the research and the presentation of the paper. Thisresearch was supported in part by US National Science Foundation Grants IIS-0196057and EIA-0113618 under the ITR program, and in part by US Defense Research ProjectsAgency and Air Force Research Laboratory, Air Force Material Command, USAF, un-der Cooperative Agreements F30602-00-2-0531 and F33615-01-C-1897. The views andconclusions herein are those of the authors and should not be interpreted as necessarilyrepresenting the official policies or endorsements, either expressed or implied, of the USGovernment.Appendix A. Proof of dominating unit-clause rule (UP3)• Dominating unit-clause rule: If p1(v) (cid:1)ki=1 ni(v), set v = T and ignore v = F ;ki=1 pi(v), set v = F and ignore v = T ; If both conditions hold, i.e.,If n1(v) (cid:1)p1(v) = n1(v), set v = T or v = F and ignore the other value.(cid:5)(cid:5)Our proof starts with the nonlinear formulation of max-SAT introduced in Section 2.For clarity, here we only consider for max-2-SAT. The proof for max-k-SAT (k (cid:1) 3) isessentially the same but lengthy. Specifically, we only prove that when p1(v) (cid:1) n1(v) +n2(v), setting v = T and ignoring v = F will not miss an optimal solution. The case forn1(v) (cid:1) p1(v) + p2(v) is symmetric.Following the discussion on nonlinear formulation of max-SAT in Section 2.2, we canintroduce an integer variable that takes value 0 or 1 to present a Boolean variable that takesvalue F or T . The problem of a max-2-SAT, which may contain unit clauses, is to minimizethe objective functionW =m(cid:1)i=1wiyi,(A.1)where m is the number of clauses, wi is the weight of the ith clause, and yi is a decisionvariable for the ith clause and is subject to the following constraints(cid:6)yi = 1 − fi;fi = li1,fi = li1 + li2 − li1li2,if the ith clause is a unit clause;if the ith clause is a binary clause,(A.2)for i = 1, 2, . . . , m, where li1 and li2 are the 0-1 integers corresponding to the Booleanvariables in the ith clause.Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8075The restrictions in (A.2) can be directly used in the objective function in (A.1). Let Ckbe the sets of clauses of k literals, for k = 1 or 2, and let ci be the ith clause. The objectivefunction in (A.1) can be rewritten asW =m(cid:1)i=1wi(1 − fi) =m(cid:1)i=1wi −(cid:1)ci ∈C2wi(li1 + li2 − li1li2) −(cid:1)ci ∈C1wili1.(A.3)To minimize W , we separate positive and negative literals. Let Ck(vj ) ⊆ Ck and Ck( ¯vj ) ⊆Ck be the sets of k-literal clauses that contain literal vj and ¯vj , respectively. As discussed inSection 2.1, we can represent positive literal vi by integer variable xj and negative literal¯vj by integer expression 1 − xj . Furthermore, Boolean variable vj may be in unit andbinary clauses. We now consider these clauses with vj in turn.• If vj is in positive literal (corresponding to integer variable xj ) and in unit clauses,wili1 = −wixj = −p1(vj )xj .(A.4)(cid:1)ci ∈C1(vj )ci ∈C1(vj )(cid:1)(cid:1)−−• If vj is in positive literal (corresponding to integer variable xj ) and in binary clauses,wi(li1 + li2 − li1li2) = −wi(xj + li2 − xj li2)(cid:1)ci ∈C2(vj )(cid:1)= −(cid:1)wili2 +ci ∈C2(vj )wili2xj − p2(vj )xj .(A.5)ci ∈C2(vj )ci ∈C2(vj )• For the other two cases where vj is in negative literal (corresponding to 1 − xj ), wehaveand−−(cid:1)ci ∈C1(vj )(cid:1)ci ∈C2( ¯vj )wili1 = −n1(vj ) + n1(vj )xj ,(A.6)wi(li1 + li2 − li1li2) = −n2(vj ) −(cid:1)ci ∈C2( ¯vj )wili2xj + n2(vj )xj . (A.7)We now focus on the coefficient Fxj of integer variable xj . From (A.4) to (A.7), summingup the coefficient of xj in each case, we have(cid:1)(cid:1)Fxj= n1(vj ) + n2(vj ) − p1(vj ) − p2(vj ) +wili2 −wili2.(cid:5)Becauseci ∈C2(vj ) wili2 (cid:2) p2(vj ), andn1(vj ) − p1(vj ) − p2(vj ) (cid:2) Fxj(cid:5)i∈C2(vj )i∈C2( ¯vj )ci ∈C2(vj ) wili2 (cid:2) n2(xj ), we then have(cid:2) n1(vj ) + n2(vj ) − p1(vj ).If p1(vj ) (cid:1) n1(vj ) + n2(vj ), Fxj cannot be positive, thus to minimize the objective func-tion W , xj should take value 1, i.e., vj = T . If n1(vj ) (cid:1) p1(vj ) + p2(vj ), Fxj can not benegative, to minimize W , xj should take value 0, i.e., vj = F . This concludes the proof.76Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80Appendix B. Derivation of coefficient-determining propagation rule (UP4)• Coefficient-determining propagation rule: For each un-instantiated variable vi andcorresponding integer variable xi , if LB(xi) (cid:1) 0, set vi = F and ignore vi = T ; ifUB(xi) (cid:2) 0 set vi = T and ignore vi = F ; if both conditions hold, i.e., UB(xi) =LB(xi), set vi = T or vi = F and ignore the other value.To derive rule UP4, we first introduce a lower bound LB(xi) and an upper bound UB(xi)for the coefficient Fxi of a variable xi , for 1 (cid:2) i (cid:2) n, i.e., LB(xi) (cid:2) Fxi(cid:2) UB(xi). To deriveLB(xi) and UB(xi), we first represent the objective function W in such a way that the finalnonlinear formula only contains variables xi . From the objective function in Eq. (1) inSection 2.2, we haveW =m(cid:1)i=1wiyi = c +for max-2-SAT, andW =m(cid:1)i=1wiyi = c +(cid:1)xi ∈V(cid:1)xi ∈Vπixi +(cid:1)xi ,xj ∈Vπi,j xixj(B.1)(cid:1)πixi +πi,j xixj +(cid:1)xi ,xj ∈Vxi ,xj ,xk∈Vπi,j,kxixj xk(B.2)for max-3-SAT. We now derive LB(xi) and UB(xi) for the coefficient Fxi of xi . We con-sider max-2-SAT and max-3-SAT separately.B.1. Upper and lower bounds for max-2-SATFor max-2-SAT, from Eq. (B.1), we haveFxi= πi += πi +(cid:1)πi,j xjxj ∈V \{xi }(cid:1)xj ∈V \{xi },πi,j >0(cid:5)Note thathave(cid:1)πi,j xj +πi,j xj .(B.3)xj ∈V \{xi },πi,j <0(cid:5)xj ∈V \{xi },πi,j >0 πi,j xj (cid:1) 0 andxj ∈V \{xi },πi,j <0 πi,j xj (cid:2) 0. Therefore, we(cid:5)(cid:5)UB(xi) = πi +LB(xi) = πi +LB(xi) (cid:2) Fxi(cid:2) UB(xi).xj ∈V \{xi },πi,j >0 πi,j ,xj ∈V \{xi },πi,j <0 πi,j ,B.2. Upper and lower bounds for max-3-SATFor max-3-SAT, from Eq. (B.2), we can write(cid:1)(cid:1)Fxi= πi +πi,j xj +πi,j,kxj xk.(B.4)xj ∈V \{xi }xj ,xk∈V \{xi }Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8077The main difference between Fxi in Eq. (B.3) and Fxi in Eq. (B.4) is that the former is alinear function of xj ’s, while the latter is quadratic.Since Fxi is quadratic for max-3-SAT, to derive a linear upper bound for Fxi we define a(cid:1) Fxi under all possible assignments. Similarly,of Fxi which satisfies F rlinear roof F rxixiwe define a linear floor F fxi satisfying F f(cid:2) Fxi under all possible assignments. Similarxidefinitions of linear roof and linear floor were introduced earlier by Hammer et al. [18]. Asa bound on quadratic Fxi is difficult to get, we then use an upper bound of F rto bound Fxixifrom above and a lower bound of F fxi to bound Fxi from below. In the remaining discussion,we consider how to get F rxiand their corresponding bounds., F lxiA simple method to generate F rxixi ) is to first relax each individual quadratic termπi,j,kxj xk in Fxi to a linear term, and then sum up all the resulting linear terms. By doingso, we expect some of the linear terms to cancel out each other to arrive at a tighter bound.To relax a quadratic term to linear, we apply a set of inequalities introduced by Hammer etal. [18], specifically,(or F f(cid:2)πi,j,kxj xk (cid:2) λπi,j,kxj + (1 − λ)πi,j,kxk,πi,j,kxj xk (cid:2) λπi,j,k(xj + xk − 1),if πi,j,k > 0;if πi,j,k < 0;and(cid:2)πi,j,kxj xk (cid:1) λπi,j,k(xj + xk − 1),πi,j,kxj xk (cid:1) λπi,j,kxj + (1 − λ)πi,j,kxk,if πi,j,k > 0;if πi,j,k < 0,(B.5)(B.6)where xj and xk are 0–1 integer variables and λ is a real value satisfying 0 (cid:2) λ (cid:2) 1. Theproof to these two sets of inequalities are straightforward and can be found in [18]. We canapply inequality (B.5) to relaxing quadratic term πi,j,kxj xk to a linear term for computingan upper bound and inequality (B.5) for a lower bound. We now consider upper bound first.Recall that πi,j,kxj xk is a quadratic term in Fxi , and πi,j xj and πi,kxk are the linearterms involving xj and xk. Without loss of generality, assume that πi,j (cid:2) πi,k. We canapply inequality (B.5) to relaxing πi,j,kxj xk to linear function, where λ can be taken asfollows,,λ =+ πi,k−πi,j2πi,j,k1,120,|πi,j ||πi,j,k| ,1,if πi,j,k > 0 and πi,j,k (cid:2) πi,k − πi,j ;if πi,j,k > 0 and πi,j,k > πi,k − πi,j ;if πi,j,k < 0 and πi,j (cid:2) 0;if πi,j,k < 0 and 0 < πi,j < |πi,j,k|;if πi,j,k < 0 and πi,j (cid:1) |πi,j,k|.The intention behind Eq. (B.7) is to try to cancel (or partially cancel) some resulting linearterm with an existing linear term in Fxi as much as possible so as to get a tight linear upperbound F r. If πi,j,k > 0, one of the first two values in Eq. (B.7) is used, otherwise, one ofxithe last three values is chosen.(B.7)By applying λ in Eq. (B.7) to inequality (B.5) and summing up all terms for different xj(cid:2) F rcan bexii,j xj . Following the discussion for deriving bounds fori,j and thus havexj ∈V \{xi },π rand xk, we then obtain a linear function F rxi+written as F rximax-2-SAT in Section B.1, we take UB(xi) = π riFxisuch that Fxi(cid:5). Linear function F rxixj ∈V \{xi } π r(cid:2) UB(xi).i,j >0 π r= π ri(cid:5)+(cid:2) F rxi78Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80The case for a lower bound is similar and symmetric to the case for the upper boundconsidered above. Specifically, without loss of generality, assuming that πi,j (cid:2) πi,k, wechoose λ as follows,λ =,0,|πi,k|πi,j,k1,0,12− πi,k−πi,j|2πi,j,k| ,if πi,j,k > 0 and πi,k (cid:1) 0;if πi,j,k > 0, πi,k < 0, and |πi,k| (cid:2) πi,j,k;if πi,j,k > 0, πi,k < 0, and |πi,k| > πi,j,k;if πi,j,k < 0 and |πi,j,k| (cid:2) πi,k − πi,j ;if πi,j,k < 0 and |πi,j,k| > πi,k − πi,j .(B.8)By applying λ from Eq. (B.8) to inequality (B.6), we write F fxiand have F fxiLB(xi) = π fii,j xj(cid:2) Fxi . By the same reasoning for the lower bound for max-2-SAT, we have+i,j and LB(xi) (cid:2) F fπ fxixj ∈V \{xi } π f(cid:2) Fxi .= π fi(cid:5)+xj ∈V \{xi },π fi,j <0(cid:5)Putting all the pieces together, we finally have(cid:5)UB(xi) = π riLB(xi) = π fiLB(xi) (cid:2) Fxi+(cid:5)xj ∈V \{xi },π r+(cid:2) UB(xi).xj ∈V \{xi },π fi,j >0 π ri,j ,π fi,j ,i,j <0B.3. Coefficient-determining propagation ruleFor the above UB(xi) and LB(xi) in max-2-SAT and max-3-SAT problems, if UB(xi) (cid:2)m0, Fxi cannot be positive, thus to minimize the objective W =i=1 wiyi , xi should takevalue 1, i.e., vi = T . If LB(xi) (cid:1) 0, Fxi cannot be negative, to minimize W , xi should takevalue 0, i.e., vi = F . This concludes the proof.(cid:5)References[1] F. Aloul, A. Ramani, I. Markov, K. Sakallah, Generic ILP versus specialized 0-1 ILP: an update, in: Inter-national Conference on Computer Aided Design (ICCAD), 2002.[2] T. Alsinet, F. Manya, J. Planes, Improved branch and bound algorithms for Max-SAT, in: Proceedings ofSAT2003, 2003.[3] C.E. Blair, R.G. Jeroslow, J.K. Lowe, Some results and experiments in programming techniques for prepo-sitional logic, Comput. Oper. Res. 13 (5) (1986) 633–645.[4] B. Borchchers, J. Furman, A two-phase exact algorithm for Max-SAT and weighted Max-SAT problems,J. Combin. Optim. 2 (4) (1999) 299–306.[5] http://www.nmt.edu/~borchers/maxsat.html.[6] S. Cook, The complexity of theorem-proving procedures, in: Proceedings of the 3rd ACM Symposium onthe Theory of Computing, 1971, pp. 151–158.[7] D. Coppersmith, D. Gamarnik, M. Hajiaghayi, G.B. Sorkin, Random MAX SAT, random MAX CUT, andtheir phase transitions, in: Proceedings of the 14th Annual ACM-SIAM Symposium on Discrete Algorithms,2003, pp. 364–373.[8] J.M. Crawford, L.D. Auton, Experimental results on the crossover point in satisfiability problems, in: Pro-ceedings of AAAI-93, Washington, DC, 1993, pp. 21–27.[9] G.B. Dantzig, M.N. Thapa, Linear Programming 1: Introduction, Springer, New York, 1997.[10] M. Davis, G. Logemann, D. Loveland, A machine program for theorem proving, C. ACM 5 (1962) 394–397.Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8079[11] M. Davis, H. Putnam, A computing procedure for quantification theory, J. ACM 7 (1960) 201–215.[12] H. Dixon, M.L. Ginsberg, Inference methods for a pseudo-boolean satisfiability solver, in: Proceedings ofAAAI-02, Edmonton, AB, 2002, pp. 635–640.[13] J.W. Freeman, Improvements to propositional satisfiability search algorithms, PhD thesis, Univ. of Pennsyl-vania, 1995.[14] E.C. Freuder, R.J. Wallace, Partial constraint satisfaction, Artificial Intelligence 58 (1992) 21–70.[15] M.R. Garey, D.S. Johnson, Computers and Intractability, Freeman, New York, 1979.[16] P.E. Gill, W. Murray, M.A. Saunders, J.A. Tomlin, M.H. Wright, On projected Newton barrier methods forlinear programming and an equivalence to Karmarkar’s projective method, Math. Programming 26 (1986)183–209.[17] S.D. Givry, J. Larrosa, P. Meseguer, T. Schiex, Solving Max-SAT as weighted CSP, in: Proceedings of 9thInternational Conference on Principles and Practice of Constraint Programming (CP2003), 2003, pp. 363–376.[18] P.L. Hammer, P. Hansen, B. Simeone, Roof duality, complementation and persistency in quadratic 0-1 opti-mization, Math. Programming 28 (1984) 121–155.[19] P.L. Hammer, S. Rudeanu, Boolean Methods in Operations Research and Related Areas, Springer, Berlin,1968.[20] P. Hansen, B. Jaumard, Algorithm for the maximum satisfiability problem, Computing 44 (1990) 279–303.[21] F.S. Hillier, G.J. Lieberman, Introduction to Operations Research, McGraw-Hill, New York, 2001.[22] J.N. Hooker, Input proofs and rank one cutting-planes, ORSA J. Comput 1 (1989) 137–145.[23] J.N. Hooker, G. Fedjki, Branch-and-cut solution of inference problems in prepositional logic, Ann. Math.Artificial Intelligence 1 (1990) 123–139.[24] J.N. Hooker, V. Vinay, Branching rules for satisfiability, J. Automated Reasoning 15 (1995) 359–383.[25] H.H. Hoos, T. Stuzle, http://www.satlib.org, 1999.[26] http://www.ilog.com/products/cplex.[27] D.S. Johnson, Approximation algorithms for combinatorial problems, J. Comput. System Sci. 9 (1974) 256–278.[28] S. Joy, J. Mitchell, B. Borchers, A branch and cut algorithm for Max-SAT and weighted Max-SAT, in:D. Du, J. Gu, P.M. Pardalos (Eds.), Satisfiability Problem: Theory and Applications, 1997, pp. 519–536.[29] R. Karp, Reducibility among combinatorial problems, in: R. Miller, J. Thatcher (Eds.), Complexity of Com-puter Computations, Plenum Press, New York, 1992, pp. 85–103.[30] C.M. Li, Anbulagan, Heuristics based on unit propagation for satisfiability problems, in: Proceedings ofIJCAI-97, Nagoya, Japan, 1997, pp. 366–371.[31] C.L. Liu, Introduction to Combinatorial Mathematics, McGraw-Hill, New York, 1968.[32] D. McAllester, B. Selman, H. Kautz, Evidence for invariants in local search, in: Proceedings of AAAI-97,Providence, RI, 1997, pp. 321–326.[33] D.B. Mitchell, B. Selman, H. Levesque, Hare and easy distributions of SAT problems, in: Proceedings ofAAAI-93, Washington, DC, 1993, pp. 459–465.[34] M. Moskewics, C. Madigan, Y. Zhao, L. Zhang, S. Malik, Chaff: engineering an efficient SAT solver, in:Proceedings of the Design Automation Conference, 2001.[35] R. Niedermeier, P. Rossmanith, New upper bounds for maximum satisfiability, J. Algorithm 36 (2000) 63–88.[36] J.D. Park, Using weighted MAX-SAT engines to solve MPE, in: Proceedings of AAAI-02, Edmonton, AB,2002, pp. 682–687.[37] B. Selman, Mwff: Program for generating random max k-SAT instances, Available from DIMACS.[38] B. Selman, H. Kautz, B. Cohen, Noise strategies for local search, in: Proceedings of AAAI-94, Seattle, WA,1994, pp. 337–343.[39] H. Shen, H. Zhang, Study of lower bound functions for Max-2-SAT, in: Proceedings of AAAI-02, Edmonton,AB, 2002, pp. 185–190.[40] H. Shen, H. Zhang, An empirical study of Max-2-SAT phase transitions, in: Proceedings of LICS Workshopon Phase Transitions, 2003.[41] D.A. Spielman, S. Teng, Smoothed analysis of algorithms: why the simplex algorithm usually takes polyno-mial time, J. ACM 51 (1) (2004) 385–463.80Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80[42] R.J. Wallace, Enhancing maximum satisfiability algorithms with pure literal strategies, in: 11th CanadianConf. on AI, 1996.[43] R.J. Wallace, E.C. Freuder, Comparative study of constraint satisfaction and Davis–Putnam algorithms formaximum satisfiability problems, in: D. Johnson, M. Trick (Eds.), Cliques, Coloring, and Satisfiability,1996, pp. 587–615.[44] J.P. Walser, Integer Optimization Local Search, Springer, Berlin, 1999.[45] Z. Xing, W. Zhang, Efficient strategies for (weighted) maximum satisfiability, in: Proceedings of 10th Inter-national Conference on Principles and Practice of Constraint Programming (CP2004), 2004, pp. 690–705.[46] H. Zhang, H. Shen, F. Manya, Exact algorithms for Max-SAT, in: Workshop on First-Order Theorem Proving(FTP-03), 2003.[47] W. Zhang, Phase transitions and backbones of 3-SAT and maximum 3-SAT, in: Proceedings of 7th Interna-tional Conference on Principles and Practice of Constraint Programming (CP2001), 2001, pp. 155–167.