6102yaM1]EC.sc[1v30300.5061:viXraA Self-Taught Artificial Agent for Multi-PhysicsComputational Model PersonalizationDominik Neumanna,c,∗, Tommaso Mansib, Lucian Itud,e,Bogdan Georgescub, Elham Kayvanpourf, Farbod Sedaghat-Hamedanif,Ali Amrf, Jan Haasf, Hugo Katusf, Benjamin Mederf, Stefan Steidlc,Joachim Horneggerc, Dorin ComaniciubaMedical Imaging Technologies, Siemens Healthcare GmbH, Erlangen, GermanybMedical Imaging Technologies, Siemens Healthcare, Princeton, USAcPattern Recognition Lab, FAU Erlangen-N¨urnberg, Erlangen, GermanydSiemens Corporate Technology, Siemens SRL, Brasov, RomaniaeTransilvania University of Brasov, Brasov, RomaniafDepartment of Internal Medicine III, University Hospital Heidelberg, GermanyAbstractPersonalization is the process of fitting a model to patient data, a criticalstep towards application of multi-physics computational models in clinicalpractice. Designing robust personalization algorithms is often a tedious,time-consuming, model- and data-specific process. We propose to use artifi-cial intelligence concepts to learn this task, inspired by how human expertsmanually perform it. The problem is reformulated in terms of reinforce-ment learning.In an off-line phase, Vito, our self-taught artificial agent,learns a representative decision process model through exploration of theit learns how the model behaves under change ofcomputational model:parameters. The agent then automatically learns an optimal strategy foron-line personalization. The algorithm is model-independent; applying itto a new model requires only adjusting few hyper-parameters of the agentand defining the observations to match. The full knowledge of the modelitself is not required. Vito was tested in a synthetic scenario, showing thatit could learn how to optimize cost functions generically. Then Vito wasapplied to the inverse problem of cardiac electrophysiology and the person-alization of a whole-body circulation model. The obtained results suggestedthat Vito could achieve equivalent, if not better goodness of fit than stan-dard methods, while being more robust (up to 11% higher success rates)and with faster (up to seven times) convergence rate. Our artificial intel-ligence approach could thus make personalization algorithms generalizableand self-adaptable to any patient and any model.∗Corresponding authorEmail address: dominik.neumann@siemens.com (Dominik Neumann)Preprint submitted to Medical Image AnalysisNovember 5, 2018   Keywords: Computational Modeling, Model Personalization,Reinforcement Learning, Artificial Intelligence.1. IntroductionComputational modeling attracted significant attention in cardiac re-search over the last decades (Clayton et al., 2011; Frangi et al., 2001; Hunterand Borg, 2003; Kerckhoffs et al., 2008; Krishnamurthy et al., 2013; Kui-jpers et al., 2012; Noble, 2002). It is believed that computational modelscan improve patient stratification and therapy planning. They could be-come the enabling tool for predicting disease course and therapy outcome,ultimately leading to improved clinical management of patients sufferingfrom cardiomyopathies (Kayvanpour et al., 2015). A crucial prerequisite forachieving these goals is precise model personalization: the computationalmodel under consideration needs to be fitted to each patient. However, thehigh complexity of cardiac models and the often noisy and sparse clinicaldata still hinder this task.A wide variety of manual and (semi-)automatic model parameter estima-tion approaches have been explored, including Aguado-Sierra et al. (2010,2011); Augenstein et al. (2005); Chabiniok et al. (2012); Delingette et al.(2012); Itu et al. (2014); Konukoglu et al. (2011); Le Folgoc et al. (2013);Marchesseau et al. (2013); Neumann et al. (2014a,b); Prakosa et al. (2013);Schmid et al. (2006); Seegerer et al. (2015); Sermesant et al. (2009); Wall-man et al. (2014); Wang et al. (2009); Wong et al. (2015); Xi et al. (2013);Zettinig et al. (2014). Most methods aim to iteratively reduce the misfitbetween model output and measurements using optimization algorithms,for instance variational (Delingette et al., 2012) or filtering (Marchesseauet al., 2013) approaches. Applied blindly, those techniques could easily failon unseen data, if not supervised, due to parameter ambiguity, data noiseand local minima (Konukoglu et al., 2011; Neumann et al., 2014a; Wallmanet al., 2014). Therefore, complex algorithms have been designed combiningcascades of optimizers in a very specific way to achieve high levels of robust-ness, even on larger populations, i.e. 10 or more patients (Kayvanpour et al.,2015; Neumann et al., 2014b; Seegerer et al., 2015). However, those methodsare often designed from tedious, trial-and-error-driven manual tuning, theyare model-specific rather than generic, and their generalization to varyingdata quality cannot be guaranteed. On the contrary, if the personalizationtask is assigned to an experienced human, given enough time, he almost al-ways succeeds in manually personalizing a model for any subject (althoughsolution uniqueness is not guaranteed, but this is inherent to the problem).There are several potential reasons why a human expert is often supe-rior to standard automatic methods in terms of personalization accuracyand success rates. First, an expert is likely to have an intuition of the2model’s behavior from his prior knowledge of the physiology of the modeledorgan. Second, knowledge about model design and assumptions, and modellimitations and implementation details certainly provide useful hints on the“mechanics” of the model. Third, past personalization of other datasetsallows the expert to build up experience. The combination of prior knowl-edge, intuition and experience enables to solve the personalization task moreeffectively, even on unseen data.Inspired by humans and contrary to previous works, we propose to ad-dress the personalization problem from an artificial intelligence (AI) perspec-tive. In particular, we apply reinforcement learning (RL) methods (Suttonand Barto, 1998) developed in the AI community to solve the parameterestimation task for computational physiological models. With its roots incontrol theory on the one hand, and neuroscience theories of learning on theother hand, RL encompasses a set of approaches to make an artificial agentlearn from experience generated by interacting with its environment. Con-trary to standard (supervised) machine learning (Bishop, 2006), where theobjective is to compute a direct mapping from input features to a classifica-tion label or regression output, RL aims to learn how to perform tasks. Thegoal of RL is to compute an optimal problem-solving strategy (agent behav-ior), e.g. a strategy to play the game “tic-tac-toe” successfully. In the AIfield, such a behavior is often represented as a policy, a mapping from states,describing the current “situation” the agent finds itself in (e.g. the currentlocations of all “X” and “O” on the tic-tac-toe grid), to actions, which allowthe agent to interact with the environment (e.g. place “X” on an empty cell)and thus influence that situation. The key underlying principle of RL is thatof reward (Kaelbling et al., 1996), which provides an objective means for theagent to judge the outcome of its actions. In tic-tac-toe, the agent receivesa high, positive reward if the latest action led to a horizontal, vertical ordiagonal row full of “X” marks (winning), and a negative reward (punish-ment) if the latest action would allow the opponent to win in his next move.Based on such rewards, the artificial agent learns an optimal winning policythrough trial-and-error interactions with the environment.RL was first applied to game (e.g. Tesauro, 1994) or simple controltasks. However, the past few years saw tremendous breakthroughs in RL formore complex, real-world problems (e.g. Barreto et al., 2014; Kveton andTheocharous, 2012; Nguyen-Tuong and Peters, 2011). Some noteworthy ex-amples include M¨ulling et al. (2013), where the control entity of a robotarm learned to select appropriate motor primitives to play table tennis, andMnih et al. (2015), where the authors combine RL with deep learning totrain an agent to play 49 Atari games, yielding better performance than anexpert in the majority of them.Motivated by these recent successes and building on our previous work(Neumann et al., 2015), we propose an RL-based personalization approach,henceforth called Vito, with the goal of designing a framework that can, for3Figure 1: Overview of Vito: a self-taught artificial agent for computational model person-alization, inspired by how human operators approach the personalization problem.the first time to our knowledge, learn by itself how to estimate model pa-rameters from clinical data while being model-independent. As illustrated inFig. 1, first, like a human expert, Vito assimilates the behavior of the physi-ological model under consideration in an off-line, one-time only, data-drivenexploration phase. From this knowledge, Vito learns the optimal strategyusing RL (Sutton and Barto, 1998). The goal of Vito during the on-linepersonalization phase is then to sequentially choose actions that maximizefuture rewards, and therefore bring Vito to the state representing the solu-tion of the personalization problem. To setup the algorithm, the user needsto define what observations need to be matched, the allowed actions, and asingle hyper-parameter related to the desired granularity of the state-space.Then everything is learned automatically. The algorithm does not dependon the underlying model.Vito was evaluated on three different tasks. First, in a synthetic ex-periment, convergence properties of the algorithm were analyzed. Then,two tasks involving real clinical data were evaluated: the inverse problemof cardiac electrophysiology and the personalization of a lumped-parametermodel of whole-body circulation. The obtained results suggested that Vitocan achieve equivalent (or better) goodness of fit as standard optimizationmethods, increased robustness and faster convergence rates.A number of novelties and improvements over Neumann et al. (2015)are featured in this manuscript. First, an automatic, data-driven state-space quantization method is introduced that replaces the previous manualtechnique. Second, the need to provide user-defined initial parameter valuesis eliminated by employing a new data-driven technique to initialize per-sonalization of unseen data. Third, a stochastic personalization policy isintroduced, for which the previously used standard deterministic policy isa special case. Fourth, the convergence properties are evaluated in param-eter space using a synthetic personalization scenario. In addition, thoroughevaluation of Vito’s performance with increasing amount of training sam-ples was conducted and personalization of the whole-body circulation modelwas extended to several variants involving two to six parameters. Finally,the patient database used for experimentation was extended from 28 to 83patients for the cardiac electrophysiology experiments, and from 27 to 56for the whole-body circulation experiments.4On-line phase Off-line phase Assimilate model behavior Learn optimal personalization strategy Personalize model for new patients The remainder of this manuscript is organized as follows. Sec. 2 presentsthe method. In Sec. 3, the experiments are described and the results arepresented. Sec. 4 concludes the manuscript with a summary and discussionsabout potential limitations and extensions of the method.2. MethodThis section presents the reinforcement-learning (RL) framework forcomputational model personalization. Sec. 2.1 introduces Markov decisionprocess (MDP). Sec. 2.2 defines the personalization problem and how it canbe reformulated in terms of an MDP. Sec. 2.3 describes how the artificialagent, Vito, learns how the model behaves. Next, Sec. 2.4 provides detailsabout state-space quantization, and Sec. 2.5 describes how the model knowl-edge is encoded in the form of transition probabilities. All steps mentionedso far are performed in an off-line training phase. Finally, Sec. 2.6 explainshow the learned knowledge is applied on-line to personalize unseen data.2.1. Model-based Reinforcement Learning2.1.1. MDP DefinitionA crucial prerequisite for applying RL is that the problem of inter-est, here personalization, can be modeled as a Markov decision process(MDP). An MDP is a mathematical framework for modeling decision mak-ing when the decision outcome is partly random and partly controlled bya decision maker (Sutton and Barto, 1998). Formally, an MDP is a tupleM = (S, A, T , R, γ), where:• S is the finite set of states that describe the agent’s environment, nSis the number of states, and st ∈ S is the state at time t.• A is the finite set of actions, which allow the agent to interact withthe environment, nA is the number of actions, and at ∈ A denotes theaction performed at time t.• T : S × A × S → [0; 1] is the stochastic transition function, whereT (st, at, st+1) describes the probability of arriving in state st+1 afterthe agent performed action at in state st.• R : S × A × S → R is the scalar reward function, where rt+1 =R(st, at, st+1) is the immediate reward the agent receives at time t + 1after performing action at in state st resulting in state st+1.• γ ∈ [0; 1] is the discount factor that controls the importance of futureversus immediate rewards.52.1.2. Value IterationThe value of a state, V ∗(s), is the expected discounted reward the agentaccumulates when it starts in state s and acts optimally in each step:V ∗(s) = E(cid:40) ∞(cid:88)k=0γkrt+k+1(cid:41)(cid:12)(cid:12)(cid:12)st = s(cid:12)(cid:12),(1)where E{} denotes the expected value given the agent always selects theoptimal action, and t is any time step. Note that the discount factor γ isa constant and the superscript k its exponent. V ∗ can be computed usingvalue iteration (Sutton and Barto, 1998), an iterative algorithm based ondynamic programming. In the first iteration i = 0, let Vi : S → R denotean initial guess for the value function that maps states to arbitrary values.Further, let Qi : S × A → R denote the ith “state-action value function”-guess, which is computed as:Qi(s, a) =(cid:88)s(cid:48)∈ST (s, a, s(cid:48)) (cid:2)R(s, a, s(cid:48)) + γVi(s(cid:48))(cid:3) .Value iteration iteratively updates Vi+1 from the previous Qi:∀s ∈ S :Vi+1(s) = maxa∈AQi(s, a) ,(2)(3)until the left- and right-hand side of Eq. 3 are equal for all s ∈ S; thenV ∗ ← Vi+1 and Q∗ ← Qi+1. From this equality relation, also known asthe Bellman equation (Bellman, 1957), one can obtain an optimal problem-solving strategy for the problem described by the MDP (assuming that allcomponents of the MDP are known precisely). It is encoded in terms of adeterministic optimal policy π∗ : S → A:π∗(s) = arg maxQ∗(s, a) ,a∈A(4)i.e. a mapping that tells the agent in each state the optimal action to take.2.1.3. Stochastic PolicyIn this work not all components of the MDP are known precisely, in-stead some are approximated from training data. Value iteration, however,assumes an exact MDP to guarantee optimality of the computed policy.Therefore, instead of relying on the deterministic policy π∗ (Eq. 4), a gen-eralization to stochastic policies ˜π∗ is proposed here to mitigate potentialissues due to approximations. Contrary to Eq. 4, where for each state onlythe one action with maximum Q∗-value is considered, a stochastic policystores several candidate actions with similar high Q∗-value and returns one6Figure 2: A computational model f is a dynamic system that maps model input parame-ters x to model state (output) variables y. The goal of personalization is to tune x suchthat the objectives c, defined as the misfit between y and the corresponding measureddata z of a given patient, are optimized (the misfit is minimized).of them through a random process each time it is queried. To this end, theQ∗(s, ·)-values for a given state s are first normalized:˜Q∗s(a) =Q∗(s, a) − mina(cid:48)∈A[Q∗(s, a(cid:48))]maxa(cid:48)∈A[Q∗(s, a(cid:48))] − mina(cid:48)∈A[Q∗(s, a(cid:48))].(5)s-value is below a threshold of (cid:15) = 4All actions whose normalized ˜Q∗5 (setempirically and used throughout the entire manuscript) are discarded, whileactions with large values are stored as potential candidates. Each timethe stochastic policy is queried, a = ˜π∗(cid:15) (s), it returns one of the candidateactions a selected randomly with probability proportional to its ˜Q∗s-value:˜Q∗s(a(cid:48)); the sum is over all candidate actions a(cid:48).s(a)/ (cid:80)a(cid:48) ˜Q∗2.2. Reformulation of the Model Personalization Problem into an MDP2.2.1. Problem DefinitionAs illustrated in Fig. 2, any computational model f is governed by a set ofparameters x = (x1, . . . , xnx)(cid:62), where nx denotes the number of parameters.x is bounded within a physiologically plausible domain Ω, and characterizedby a number of ny (observable) state variables y = (y1, . . . , yny )(cid:62). Thestate variables can be used to estimate x. Note that some parameters maybe pre-estimated or assigned fixed values. The goal of personalization is tooptimize a set of nc objectives c = (c1, . . . , cnc)(cid:62). The objectives are scalarsdefined as ci = d(yi, zi), where d is a measure of misfit, and zi denotesthe patient’s measured data (z) corresponding to yi. In this work d(yi, zi) =yi−zi. Personalization is considered successful if all user-defined convergencecriteria ψ = (ψ1, . . . , ψnc)(cid:62) are met. The criteria are defined in terms ofmaximum acceptable misfit per objective: ∀i ∈ {1, . . . , nc} : |ci| < ψi.2.2.2. Problem ReformulationPersonalization is mapped to a Markov decision process as follows:States: An MDP state encodes the misfit between the computed modelstate (outcome of forward model run) and the patient’s measurements.Thus, MDP states carry the same type of information as objective vectors c,yet the number of MDP states has to be finite (Sec. 2.1), while there are aninfinite number of different objective vectors due to their continuous nature.Therefore the space of objective vectors in Rnc is reduced to a finite set of7Model parameters Model Model state Measured data Objectives Patient representative states: the MDP states S, each s ∈ S covering a small regionin that space. One of those states, ˆs ∈ S, encodes personalization successas it is designed such that it covers exactly the region where all convergencecriteria are satisfied. The goal of Vito is to learn how to reach that state.Actions: Vito’s actions modify the parameters x to fulfill the objectives c.An action a ∈ A consists in either in- or decrementing one parameter xi by1×, 10× or 100× a user-specified reference value δi with δ = (δ1, . . . , δnx)(cid:62).This empirically defined quantization of the intrinsically continuous actionspace yielded good results for the problems considered in this work.Transition function: T encodes the agents knowledge about the compu-tational model f and is learned automatically as described in Sec. 2.5.Rewards: Inspired by the “mountain car” benchmark (Sutton and Barto,1998), the rewards are defined as always being equal to R(s, a, s(cid:48)) = −1(punishment), except when the agent performs an action resulting in per-sonalization success, i.e. when s(cid:48) = ˆs. In that case, R(·, ·, ˆs) = 0 (no pun-ishment).Discount factor: The large discount factor γ = 0.99 encourages policiesthat favor future over immediate rewards, as Vito should always prefer thelong-term goal of successful personalization to short-term appealing actionsin order to reduce the risk of local minima.2.3. Learning Model Behavior through Model Explorationi1, ep2, . . . }. An episode epLike a human operator, Vito first learns how the model “behaves” byexperimenting with it. This is done through a “self-guided sensitivity anal-ysis”. A batch of sample transitions is collected through model explorationepisodes E p = {epis a sequence of ne-steps consec-utive transitions generated from the model f and the patient p for whomthe target measurements zp are known. An episode is initiated at timet = 0 by generating random initial model parameters xt within the phys-iologically plausible domain Ω. From the outputs of a forward model runyt = f (xt), the misfits to the patient’s corresponding measurements arecomputed, yielding the objectives vector ct = d(yt, zp). Next, a random ex-ploration policy πrand that selects an action according to a discrete uniformprobability distribution over the set of actions is employed. The obtainedat ∈ A is then applied to the current parameter vector, yielding modifiedparameter values xt+1 = at(xt). From the output of the forward model runyt+1 = f (xt+1) the next objectives ct+1 are computed. The next action at+1is then selected according to πrand, and this process is repeated ne-steps − 1times. Hence, each episode can be seen as a set of consecutive tuples:e = {(xt, yt, ct, at, xt+1, yt+1, ct+1),t = 0, . . . , ne-steps − 1} .(6)In this work, ne-steps = 100 transitions are created in each episode as a trade-off between sufficient length of an episode to cover a real personalizationscenario and sufficient exploration of the parameter space.8The model is explored with many different training patients and the re-sulting episodes are combined into one large training episode set E = (cid:83)p E p.The underlying hypothesis (verified in experiments) is that the combinedE allows to cancel out peculiarities of individual patients, i.e. to abstractfrom patient-specific to model-specific knowledge.2.4. From Computed Objectives to Representative MDP StateAs mentioned above, the continuous space of objective vectors is quan-tized into a finite set of representative MDP states S. A data-driven ap-proach is proposed. First, all objective vectors observed during training areclustered according to their distance to each other. Because the ranges ofpossible values for the individual objectives can vary significantly depend-ing on the selected measurements (due to different types of measurements,different units, etc.), the objectives should be normalized during cluster-ing to avoid bias towards objectives with relatively large typical values. Inthis work the distance measure performs implicit normalization to accountfor these differences: the distance between two objective vectors (c1, c2) isdefined relative to the inverse of the convergence criteria ψ:(cid:107)c1 − c2(cid:107)ψ =(cid:113)(c1 − c2)(cid:62) diag(ψ)−1 (c1 − c2) ,(7)where diag(ψ)−1 denotes a diagonal matrix with ( 1, . . . ) along its di-ψ1agonal. The centroid of a cluster is the centroid of a representative state.In addition, a special “success state” ˆs representing personalization successis created, which covers the region in state-space where all objectives aremet: ∀i : |ci| < ψi. The full algorithm is described in Appendix A. Fi-nally, an operator φ : Rnc → S that maps continuous objective vectors c torepresentative MDP states is introduced:, 1ψ2φ(c) = arg mins∈S(cid:107)c − ξs(cid:107)ψ(8)where ξs denotes the centroid corresponding to state s. For an examplestate-space quantization see Fig. 3.2.5. Transition Function as Probabilistic Model RepresentationIn this work, the stochastic MDP transition function T encodes theagent’s knowledge about the computational model f . It is learned from thetraining data E. First, the individual samples (xt, yt, ct, at, xt+1, yt+1, ct+1)are converted to state-action-state transition tuples ˆE = {(s, a, s(cid:48))}, wheres = φ(ct), a = at and s(cid:48) = φ(ct+1). Then, T is approximated from statisticsover the observed transition samples:T (s, a, s(cid:48)) =(cid:12)(cid:12){(s, a, s(cid:48)) ∈ ˆE}(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12){(s, a, s(cid:48)(cid:48)) ∈ ˆE}(cid:12),(cid:12)(cid:12)(cid:12)(9)(cid:80)s(cid:48)(cid:48)∈S9Figure 3: State-space quantization. Left: Example data-driven quantization of a two-dimensional state-space into nS = 120 representative states. The states are distributedaccording to the observed objective vectors c in one of the experiments in Sec. 3.2. Theobjectives were QRS duration [ms] (c1) and electrical axis [deg] (c2). The center rectangle(green region) denotes the success state ˆs where all objectives are met (∀i : |ci| < ψi); seetext for details. Right: Manual quantization as used in Neumann et al. (2015).where |{·}| denotes the cardinality of the set {·}. If nS and nA are largecompared to the total number of samples it may occur that some state-action combinations are not observed:In that caseuniformity is assumed: ∀s(cid:48)(cid:48) ∈ S : T (s, a, s(cid:48)(cid:48)) = 1/nS.|{(s, a, ·) ∈ ˆE}| = 0.M is now fully defined. Value iteration (Sec. 2.1) is applied and thestochastic policy ˜π∗(cid:15) is computed, which completes the off-line phase.2.6. On-line Model PersonalizationOn-line personalization, as illustrated in Fig. 4, can be seen as a two-stepprocedure. First, Vito initializes the personalization of unseen patients fromtraining data. Second, Vito relies on the computed policy ˜π∗(cid:15) to guide thepersonalization process.2.6.1. Data-driven InitializationGood initialization can be decisive for a successful personalization. Vito’sstrategy is to search for forward model runs in the training database E forwhich the model state f (x) = y ≈ zp is similar to the patient’s measure-ments. To this end, Vito examines all parameters Ξ = {x ∈ E | f (x) ≈ zp}that yielded model states similar to the patient’s measurements. Due toambiguities induced by the different training patients, data noise and modelassumptions, Ξ could contain significantly dissimilar parameters. Hence,picking a single x ∈ Ξ might not yield the best initialization. Analyzing Ξprobabilistically instead helps Vito to find likely initialization candidates.The details of the initialization procedure are described in Appendix B.10-150-100-50050100-150-100-50050100150150-150-100-50050100150-150-100-50050100150Data-driven quantizationManual quantizationFigure 4: Vito’s probabilistic on-line personalization phase. See text for details.Given the patient’s measurements zp, the procedure outputs a list of initial-ization candidates X0 = (x(cid:48)0, . . . ). The list is sorted by likelihood withthe first element, x(cid:48)0, being the most likely one.0, x(cid:48)(cid:48)2.6.2. Probabilistic PersonalizationThe first personalization step initializes the model parameter vector x0with the most likely among all initialization candidates, x0 ∈ X0 (see pre-vious section for details). Then, as illustrated in Fig. 4, Vito computes theforward model y0 = f (x0) and the misfit between the model output and thepatient’s measurements c0 = d(y0, zp) to derive the first state s0 = φ(c0).Given s0, Vito decides from its policy the first action to take a0 = ˜π∗(cid:15) (s0),and walks through state-action-state sequences to personalize the computa-tional model f by iteratively updating the model parameters through MDPactions. Bad initialization could lead to oscillations between states as ob-served in previous RL works (Kveton and Theocharous, 2012; Neumannet al., 2015). Therefore, upon detection of an oscillation, which is done bymonitoring the parameter traces to detect recurring sets of parameter values,the personalization is re-initialized at the second-most-likely x0 ∈ X0, etc. Ifall |X0| initialization candidates have been tested, a potential re-initializationdefaults to fully random within the physiologically plausible parameter do-main Ω. The process terminates once Vito reaches state ˆs (success), or whena pre-defined maximum number of iterations is reached (failure).3. ExperimentsVito was applied to a synthetic parameter estimation problem and to twochallenging problems involving real clinical data: personalization of a car-diac electrophysiology (EP), and a whole-body-circulation (WBC) model.All experiments were conducted using leave-one-out cross-validation. Thenumbers of datasets and transition samples used for the different experi-ments are denoted ndatasets and nsamples, respectively.3.1. Synthetic Experiment: the Rosenbrock FunctionFirst, Vito was employed in a synthetic scenario, where the ground-truthmodel parameters were known. The goals were to test the ability of Vito to11Update parameters Run forward model Initialization Select action Observe state Check convergence and detect oscillations Unseen patient Personalized parameters Figure 5: Synthetic experiment. Left: Contour plot of the Rosenbrock function f α=1 withglobal minimum at x = (1, 1)(cid:62) (red dot). The color scale is logarithmic for visualizationpurposes: the darker, the lower the function value. Mid: Maximum L2-error in parameterspace after personalization over all functions for varying initial parameter values. See textfor details. Yellow represents errors ≥ 5 (maximum observed error ≈ 110). Right: Sameas mid panel, except the extended action set was used. The red dots are the 100 ground-truth parameters x = (α, α2)(cid:62) generated for random α.optimize cost functions generically, and to directly evaluate the performancein the parameter space.3.1.1. Forward Model DescriptionThe Rosenbrock function (Rosenbrock, 1960), see Fig. 5, left panel, isa non-convex function that is often used to benchmark optimization algo-rithms. It was treated as the forward model in this experiment:f α(x1, x2) = (α − x1)2 + 100 · (x2 − x21)2 ,(10)where x = (x1, x2)(cid:62) were the model parameters to estimate for any α, andf α : Ω → R. As described in Sec. 2.2.2, each of Vito’s actions a ∈ A in- ordecrements a parameter value by multiples (1×, 10×, 100×) of parameter-specific reference values. The reference values were set to δ = (0.01, 0.01)(cid:62),determined as 0.1% of the defined admissible parameter space per dimension,Ω = [−5; 5]2. The parameter α ∈ R defines a family of functions {f α}. Thegoal was to find generically arg minx1,x2 f α(x1, x2).The Rosenbrock function has a unique global minimum at x = (α, α2)(cid:62),where both terms T1 = (α − x1) and T2 = (x2 − x21) evaluate to 0. Thepersonalization objectives were therefore defined as c = (|T1 − 0|, |T2 − 0|)(cid:62),with the measured data z = (0, 0)(cid:62) were zero for both objectives and thecomputed data y = (T1, T2)(cid:62). The convergence criteria were set empiricallyto ψ = (0.05, 0.05)(cid:62).3.1.2. EvaluationVito was evaluated on ndatasets = 100 functions f α with randomly gen-In the off-line phase, for each function, nsamples =erated α ∈ [−2, 2].12Maximum observerd error100.5≥ 54.5431.522.53.5-5  -4  -3  -2  -1  0   1   2  3   4   5-3-5-45431-2-102-5  -4  -3  -2  -1  0   1   2  3   4   5-5  -4  -3  -2  -1  0   1   2  3   4   50.250.250.250.2510 · ne-steps = 1000 samples, i.e. ten training episodes, each consisting inne-steps = 100 transitions (Sec. 2.3), were generated to learn the policy. Thenumber of representative states was set to nS = 100. To focus on Vito’son-line personalization capabilities, both the data-driven initialization andthe re-initialization on oscillation (Sec. 2.6) were disabled. In total, 441 ex-periments with different initializations (sampled on a 21 × 21 uniform gridspanned in Ω) were conducted. For each experiment all 100 functions werepersonalized using leave-one-family-function-out cross validation, and theerror value from the function exhibiting the maximum L2-error (worst-casescenario) between ground-truth (α, α2) and estimated parameters was plot-ted. As one can see from the large blue region in Fig. 5, mid panel, for themajority of initial parameter values Vito always converged to the solution(maximum L2-error < 0.25; the maximum achievable accuracy depended onthe specified convergence criteria ψ and on the reference values δ, which“discretized” the parameter space). However, especially for initializationsfar from the ground-truth (near border regions of Ω), Vito was unable to per-sonalize some functions properly, which was likely due to the high similarityof the Rosenbrock function shape in these regions.To investigate this issue, the experiment was repeated after additionallarger parameter steps were added to the set of available actions: A(cid:48) =A ∪ {±500δ1; ±500δ2}. As shown in Fig. 5, right panel, Vito could nowpersonalize successfully starting from any point in Ω. The single spot withlarger maximum error (bright spot at approximately x = (−1, 2)(cid:62)) can beexplained by Vito’s stochastic behavior: Vito may have become unlucky ifit selected many unfavorable actions in sequence due to the randomnessintroduced by the stochastic policy. Enabling re-initialization on oscillationsolved this issue entirely. In conclusion, this experiment showed that Vitocan learn how to minimize a cost function generically.3.2. Personalization of Cardiac Electrophysiology ModelVito was then tested in a scenario involving a complex model of cardiacelectrophysiology coupled with 12-lead ECG. Personalization was performedfor real patients from actual clinical data. A total of ndatasets = 83 pa-tients were available for experimentation. For each patient, the end-diastolicbi-ventricular anatomy was segmented from short-axis cine magnetic reso-nance imaging (MRI) stacks as described in Zheng et al. (2008). A tetrahe-dral anatomical model including myofibers was estimated and a torso atlasaffinely registered to the patient based on MRI scout images. See Zettiniget al. (2014) for more details.3.2.1. Forward Model DescriptionThe depolarization time at each node of the tetrahedral anatomicalmodel was computed using a shortest-path graph-based algorithm, similar13to the one proposed in Wallman et al. (2012). Tissue anisotropy was mod-eled by modifying the edge costs to take into account fiber orientation. Atime-varying voltage map was then derived according to the depolarizationtime: at a given time t, mesh nodes whose depolarization time was higherthan t were assigned a trans-membrane potential of −70 mV, 30 mV other-wise. The time-varying potentials were then propagated to a torso modelwhere 12-lead ECG acquisition was simulated, and QRS duration (QRSd)and electrical axis (EA) were derived (Zettinig et al., 2014). The modelwas controlled by the conduction velocities (in m/s) of myocardial tissueand left and right Purkinje network: x = (vMyo, vLV, vRV)(cid:62). The latter twodomains were modeled as fast endocardial conducting tissue. The admis-sible parameter space Ω was set to [200; 1000] for vMyo and [500; 5000] forboth vLV and vRV. Reference increment values to build the action set Awere set to δ = (5, 5, 5)(cid:62) m/s for the three model parameters. The goal ofEP personalization was to estimate x from the measured QRSd and EA.Accounting for uncertainty in the measurements and errors in the model,a patient was considered personalized if QRSd and EA misfits were belowψ = (5 ms, 10◦)(cid:62), respectively.3.2.2. Number of Representative StatesIn contrast to Neumann et al. (2015), where state-space quantizationrequired manual tuning of various threshold values, the proposed approachrelies on a single hyper-parameter only: nS, the number of representativestates (Sec. 2.4). To specify nS, eight patients were selected for scouting.Exhaustive search was performed for nS ∈ {10, 20, . . . , 490, 500} represen-tative states. The goodness of a given configuration was evaluated basedon the success rate (relative number of successfully personalized cases ac-cording to convergence criteria ψ) over five independent, consecutive, leave-one-patient-out cross-validated personalization runs of the eight patients.Furthermore, the average number of required forward model runs was con-sidered. To this end, 100 training episodes (100·ne-steps = 104 transition sam-ples) per patient were generated for each personalization run as described inSec. 2.3. As one can see from Fig. 6, good performance was achieved from 50to 300 representative states. The large range of well performing nS indicatesa certain level of robustness with respect to that hyper-parameter. A slightperformance peak at 120 representative states was observed. Therefore,nS = 120 was selected for further experimentation as compromise betweenmaintaining a low number of states and sufficient state granularity. An ex-ample quantization with nS = 120 is visualized in Fig. 3. The eight scoutingdatasets were discarded for the following experiments to avoid bias in theanalysis.14Figure 6: Hyper-parameter scouting. Vito’s performance for varying number of represen-tative states nS on eight scouting datasets. The solid and dashed curves represent successrate and average number of forward runs until convergence, respectively, aggregated overfive personalization runs with varying training data.3.2.3. Reference MethodsVito’s results were compared to two standard personalization methodsbased on BOBYQA (Powell, 2009), a widely-used gradient-free optimizerknown for its robust performance and fast convergence. The first approach,“BOBYQA simple”, mimicked the most basic estimation setup, where onlythe minimum level of model and problem knowledge were assumed. Theobjective function was the sum of absolute QRSd and EA errors: (cid:80)nci=1 |ci|.It was minimized in a single optimizer run where all three parameters inx were tuned simultaneously. The algorithm terminated once all conver-gence criteria ψ were satisfied (success) or if the number of forward modelevaluations exceeded 100 (failure). The second approach, “BOBYQA cas-cade”, implemented an advanced estimator with strong focus on robustness,which computed the optimum parameters in a multi-step iterative fashion.It is based on Seegerer et al. (2015), where tedious manual algorithm andcost function tuning was performed on a subset of the data used in thismanuscript. In a first step, the myocardial conduction velocity was tuned toyield good match between computed and measured QRS duration. Second,left and right endocardial conduction velocities were optimized to minimizeelectrical axis error. Both steps were repeated until all parameter estimateswere stable.To remove bias towards the choice of initial parameter values, for eachof the two methods all datasets were personalized 100 times with differentrandom initializations within the range of physiologically plausible valuesΩ. The differences in performance were striking: only by changing theinitialization, the number of successfully personalized cases varied from 13 to37 for BOBYQA simple, and from 31 to 51 for BOBYQA cascade (variabilityof more than 25% of the total number of patients). These results highlightthe non-convexity of the cost function to minimize.15Success rate00.20.40.60.81Average # forward model runs020406080100Number of representative states       50      100      150      200     250     300     350      400      450     50012010Figure 7: Absolute errors over all patients after initialization with fixed parameter values(blue), after data-driven initialization for increasing amount of training data (white), andafter full personalization with Vito (green). Data-driven initialization yielded significantlyreduced errors if sufficient training data were available (> 102) compared to initializationwith fixed values. Full personalization further reduced the errors by a significant margin.The red bar and the box edges indicate the median absolute error, and the 25 and 75percentiles, respectively. Left: QRS duration errors. Right: Electrical axis errors.3.2.4. Full Personalization PerformanceFirst, Vito’s overall performance was evaluated. The full personalizationpipeline consisting in off-line learning, initialization, and on-line personal-ization was run on all patients with leave-one-patient-out cross-validationusing 1000 training episodes (nsamples = 1000 · ne-steps = 105 transition sam-ples) per patient. The maximum number of iterations was set to 100. Thegreen box plots in the two panels of Fig. 7 summarize the results. Themean absolute errors were 4.1 ± 5.6 ms and 12.4 ± 13.3◦ in terms of QRSdand EA, respectively, a significant improvement over the residual error afterinitialization. In comparison to the reference methods, the best BOBYQAsimple run yielded absolute errors of 4.4 ± 10.8 ms QRSd and 15.5 ± 18.6◦EA on average, and the best BOBYQA cascade run 0.1 ± 0.2 ms QRSd and11.2 ± 15.8◦ EA, respectively. Thus, in terms of EA error all three methodsyielded comparable performance, and while BOBYQA simple and Vito per-formed similarly in terms of QRSd, BOBYQA cascade outperformed bothin this regard. However, considering success rates, i.e. successfully person-alized patients according to the defined convergence criteria (ψ) divided bytotal number of patients, both the performance of Vito (67%) and BOBYQAcascade (68%) were equivalent, while BOBYQA simple reached only 49% orless. In terms of run-time, i.e. average number of forward model runs un-til convergence, Vito (31.8) almost reached the high efficiency of BOBYQAsimple (best: 20.1 iterations) and clearly outperformed BOBYQA cascade(best: 86.6 iterations), which means Vito was ≈ 2.5× faster.16Training samples per datasetTraining samples per datasetAbsolute QRSd error [ms]Absolute EA error [deg]Data-driveninitializationFull personalizationFixed initializationFull personalizationFixed initializationData-driveninitialization459013518005010015003.2.5. Residual Error after InitializationA major advantage over standard methods such as the two BOBYQA ap-proaches is Vito’s automated, data-driven initialization method (Sec. 2.6.1),which eliminates the need for user-provided initial parameter values. Toevaluate the utility of this step, personalization using Vito was stopped di-rectly after initialization (the most likely x0 was used) and the errors in termsof QRSd and EA resulting from a forward model run f with the computedinitial parameter values were quantified. This experiment was repeated forincreasing number of transition samples per dataset: nsamples = 100 . . . 105,and the results were compared to the error after initialization when fixedinitial values were used (the initialization of the best performing BOBYQAexperiment was used). As one can see from Fig. 7, with increasing amountof training data both errors decreased notably. As few as 102 transitions perdataset already provided more accurate initialization than the best testedfixed initial values. Thus, not only does this procedure simplify the setupof Vito for new problems (no user-defined initialization needed), this ex-periment showed that it can reduce initial errors by a large margin, evenwhen only few training transitions were available. It should be noted thatVito further improves the model fit in its normal operating mode (continuepersonalization after initialization), as shown in the previous experiment.3.2.6. Convergence AnalysisAn important question in any RL application relates to the amount oftraining needed until convergence of the artificial agent’s behavior. For Vitoin particular, this translates to the amount of transition samples requiredto accurately estimate the MDP transition function T to compute a solidpolicy on the one hand, and to have enough training data for reliable param-eter initialization on the other hand. To this end, Vito’s overall performance(off-line learning, initialization, personalization) was evaluated for varyingnumber of training transition samples per dataset. As one can see from theresults in Fig. 8, with increasing amount of training data the performanceincreased, suggesting that the learning process was working properly. Evenwith relatively limited training data of only nsamples = 102 samples per pa-tient, Vito outperformed the best version of BOBYQA simple (49% successrate). Starting from nsamples ≈ 3000, a plateau at ≈66% success rate wasreached, which remained approximately constant until the maximum testednumber of samples. This was almost on par with the top BOBYQA cascadeperformance (68% success rate). Also the run-time performance increasedwith more training data. For instance, Vito’s average number of iterationswas 36.2 at 103 samples, 31.5 at 104 samples, or 31.8 at 105 samples.These results suggested that not only Vito can achieve similar perfor-mance as an advanced, manually engineered method, but also the numberof required training samples was not excessive.In fact, a rather limitedand thus well manageable amount of data, which can be computed in a17Figure 8: EP personalization results. Personalization success rate in blue and averagenumber of iterations in red. Left: Vito’s performance for increasing number of trainingtransition samples per dataset. Each dot represents results from one experiment (cross-validated personalization of all 75 datasets), solid/dashed line is low-pass filtered mean,shaded areas represent 0.5× and 1× standard deviation. Right: Performance of bothreference methods. Each shade represents 10% of the results, sorted by performance.reasonable time-frame, sufficed.3.3. Personalization of Whole-Body Circulation ModelNext, Vito was asked to personalize a lumped-parameter whole-bodycirculation (WBC) model from pressure catheterization and volume data.A subset of ndatasets = 56 patients from the EP experiments were used forexperimentation. The discrepancy was due to missing catheterization datafor some patients, which was required for WBC personalization only. Foreach patient, the bi-ventricular anatomy was segmented and tracked fromshort-axis cine MRI stacks throughout one full heart cycle using shape-constraints, learned motion models and diffeomorphic registration (Wanget al., 2013). From the time-varying endocardial meshes, ventricular volumecurves were derived. Manual editing was performed whenever necessary.3.3.1. Forward Model DescriptionThe WBC model to personalize was based on Itu et al. (2014). It con-tained a heart model (left ventricle (LV) and atrium, right ventricle andatrium, valves), the systemic circulation (arteries, capillaries, veins) and thepulmonary circulation (arteries, capillaries, veins). Time-varying elastancemodels were used for all four chambers of the heart. The valves were modeledthrough a resistance and an inertance. A three-element Windkessel modelwas used for the systemic and pulmonary arterial circulation, while a two-element Windkessel model was used for the systemic and pulmonary venouscirculation. We refer the reader to Itu et al. (2014); Neumann et al. (2015);Westerhof et al. (1971) for more details. Personalization was performed withrespect to the patient’s heart rate as measured during catheterization.The goal of this experiment was to compare Vito’s personalization per-formance for the systemic part of the model in setups with increasing num-ber of parameters to tune and objectives to match. To this end, Vito was18Training samples per dataset100101102103104Success rate00.20.40.60.81VitoAverage # forward model runs020406080100BOBYQAReference MethodsSuccess rate00.20.40.60.81Average # forward model runs020406080100simpleBOBYQAcascade# Forward model runsSuccess rateSuccess rate# Forward model runsSuccess rate# Forward model runsxInitial volumeLV max. elastanceAortic resistanceAortic complianceDead volumeTime to EmaxDefault value400 mL2.4 mmHg/mL1100 g/(cm4 s)1.4 ·109 cm4 s2/g10 mL300 msΩ[200; 1000] mL[0.2; 5] mmHg/mL[500; 2500] g/(cm4 s)[0.5; 6] ·109 cm4 s2/g[−50; 500] mL[100; 600] msSetups6, 5, 3, 26, 5, 3, 26, 5, 36, 56, 56Table 1: WBC parameters x, their default values and domain Ω. The last column de-notes the experiment setups in which a parameter was personalized (e.g. “5”: parameterwas among the estimated parameters in 5p experiment). Default values were used inexperiments where the respective parameters were not personalized.cEnd-diastolic LV volumeEnd-systolic LV volumeMean aortic pressurePeak-systolic aortic pressureEnd-diastolic aortic pressureEjection timeψ20 mL20 mL10 mmHg10 mmHg10 mmHg50 msMeasured range[129; 647] mL[63; 529] mL[68; 121] mmHg[83; 182] mmHg[48; 99] mmHg[115; 514] msSetups6, 5, 3, 26, 5, 3, 26, 5, 36, 56, 56Table 2: WBC objectives c, their convergence criteria ψ and range of measured values inthe patient population used for experimentation.employed on setups with two to six parameters (2p, 3p, 5p, 6p):initialblood volume, LV maximum elastance, time until maximum elastance isreached, total aortic resistance and compliance, and LV dead volume. Thereference values δ to define Vito’s allowed actions A were set to .5% of theadmissible parameter range Ω for each individual parameter, see Table 1 fordetails. The personalization objectives were MRI-derived end-diastolic andend-systolic LV volume, ejection time (time duration during which the aor-tic valve is open and blood is ejected), and peak-systolic, end-diastolic, andmean aortic blood pressures as measured during cardiac catheterization, seeFig. 9. To account for measurement noise, personalization was consideredsuccessful if the misfits per objective were below acceptable threshold valuesψ as listed in Table 2.3.3.2. Number of Representative StatesAlong the same lines as Sec. 3.2.2, the hyper-parameter for state-spacequantization was tuned based on the eight scouting patients. The larger thedimensionality of the state-space, the more representative states were neededto yield good performance. In particular, for the different WBC setups, thenumbers of representative states (nS) yielding the best scouting performancewere 70, 150, 400 and 600 for the 2p, 3p, 5p and 6p setup, respectively. Thescouting datasets were discarded for the following experiments.19Figure 9: Goodness of fit in terms of time-varying LV volume and aortic pressure for Vitopersonalizing an example patient based on the different WBC setups. The added objectivesper setup are highlighted in the respective column. With increasing number of parametersand objectives Vito manages to improve the fit between model and measurements.3.3.3. Reference MethodA gradient-free optimizer (Lagarias et al., 1998) based on the simplexmethod was used to benchmark Vito. The objective function was the sumof squared differences between computed and measured values, weighted bythe inverse of the convergence criteria to counter the different ranges ofobjective values (e.g. due to different types of measurements and differentunits): (cid:107)c(cid:107)ψ (Eq. 7). Compared to non-normalized optimization, the al-gorithm converged up to 20% faster and success rates increased by up to8% under otherwise identical conditions. Personalization was terminatedonce all convergence criteria were satisfied (success), or when the maximumnumber of iterations was reached (failure). To account for the increasingcomplexity of optimization with increasing number of parameters nx, themaximum number of iterations was set to 50 · nx for the different setups.As one can see from Fig. 10, right panels, with increasing number ofparameters to be estimated, the performance in terms of success rate andnumber of forward model runs decreased slightly. This is expected as theproblem becomes harder. To suppress bias originating from (potentiallypoor) initialization, the reference method was run 100 times per setup (asin EP experiments), each time with a different, randomly generated set ofinitial parameter values. The individual performances varied significantlyfor all setups.202040608010012014016000.20.40.60.8111012514015517018520000.20.40.60.8100.20.40.60.8100.20.40.60.81WBC2pWBC 3pWBC 5pWBC 6pAortic pressure [mmHg]LV volume [mL]Time [s]Time [s]Time [s]Time [s]End-diastolicvolumeEnd-systolicvolumeEjectiontimeMeasuredComputed204060801001201401601101251401551701852002040608010012014016011012514015517018520020406080100120140160110125140155170185200MeanpressureEnd-diastolicaortic pressurePeak-systolicpressureEnd-diastolicvolumeEnd-systolicvolumeMeanpressureEnd-diastolicaortic pressurePeak-systolicpressureMeanpressureEnd-diastolicvolumeEnd-systolicvolumeEnd-diastolicvolumeEnd-systolicvolumeFigure 10: WBC model personalization results (top: success rate, bottom: average numberof forward model runs until convergence) for various estimation setups (different colors),see text for details. Left: Vito’s performance for increasing number of training transitionsamples per dataset. Each dot represents results from one experiment (cross-validatedpersonalization of all 48 datasets), solid/dashed lines are low-pass filtered mean, shadedareas represent 0.5× and 1× standard deviation. Right: Performance of reference method.Each shade represents 10% of the results, sorted by performance; darkest shade: best 10%.21100101102103104Success rate00.20.40.60.81Vito00.20.40.60.81Reference MethodTraining samples per dataset1001011021031040501001502002503002p3p5p6p#Parameters2p3p5p6p0501001502002503002p3p5p6pAverage # forward model runs2p3p5p6p3.3.4. Convergence AnalysisFor each WBC setup the full Vito personalization pipeline was evaluatedfor increasing training data (nsamples = 100 . . . 105) using leave-one-patient-out cross-validation. The same iteration limits as for the reference methodwere used. The results are presented in Fig. 10, left panels. With increasingdata, Vito’s performance, both in terms of success rate and run-time (it-erations until convergence), increased steadily until reaching a plateau. Asone would expect, the more complex the problem, i.e. the more parametersand objectives involved in the personalization, the more training data wasneeded to reach the same level of performance. For instance, Vito reached80% success rate with less than nsamples = 50 training samples per dataset inthe 2p setup, whereas almost 90× as many samples were required to achievethe same performance in the 6p setup.Compared to the reference method, given enough training data, Vitoreached equivalent or better success rates (e.g. up to 11% higher successrate for 6p) while significantly outperforming the reference method in termsof run-time performance. In the most basic setup (2p), if nsamples ≥ 103, Vitoconverged after 3.0 iterations on average, while the best reference methodrun required 22.6 iterations on average, i.e. Vito was seven times faster. Forthe more complex setups (3p, 5p, 6p), the speed-up was not as drastic. Yet,in all cases Vito outperformed even the best run of the reference method bya factor of 1.8 or larger.4. Conclusion4.1. Summary and DiscussionIn this manuscript, a novel personalization approach called Vito has beenpresented. To our knowledge, it is the first time that biophysical modelpersonalization is addressed using artificial intelligence concepts. Inspiredby how humans approach the personalization problem, Vito first learns thecharacteristics of the computational model under consideration using a data-driven approach. This knowledge is then utilized to learn how to personalizethe model using reinforcement learning. Vito is generic in the sense that itrequires only minimal and intuitive user input (parameter ranges, authorizedactions, number of representative states) to learn by itself how to personalizea model.Vito was applied to a synthetic scenario and to two challenging per-sonalization tasks in cardiac computational modeling. The problem setupsand hyper-parameter configurations are listed in Table 3. In most setupsthe majority of hyper-parameters were identical and only few (nS) requiredmanual tuning, suggesting good generalization properties of Vito. Anotherkey result was that Vito was up to 11% more robust (higher success rates)compared to standard personalization methods. Vito’s ability to generalize22ApplicationRosenbrockRosenbrock ext.EPWBC 2pWBC 3pWBC 5pWBC 6pnx nc ndatasets223235610010083 (75)56 (48)56 (48)56 (48)56 (48)2222356nS nA/nx nplateaun/a100n/a1003 000120450702 0001503 50040020 0006006866666Table 3: Applications considered in this manuscript described in terms of the numberof parameters (nx), objectives (nc) and datasets (ndatasets) used for experimentation (inbrackets: excluding scouting patients, if applicable); and Vito’s hyper-parameters: thenumber of representative MDP states (nS ) and the number of actions per parameter(nA/nx). The last column (nplateau) denotes the approximate number of samples neededto reach the performance “plateau” (see convergence analyses in Sec. 3.2.6 and Sec. 3.3.4).the knowledge obtained from a set of training patients to personalize un-seen patients was shown as all experiments reported in this manuscript werebased on cross-validation. Furthermore, Vito’s robustness against trainingpatients for whom we could not find a solution was tested. In particular, forabout 20% of the patients, in none of the electrophysiology experiments inSec. 3.2 any personalization (neither Vito nor the reference methods) couldproduce a result that satisfied all convergence criteria. Hence, for somepatients no solution may exist under the given electrophysiology model con-figuration1. Still, all patients were used to train Vito, and surprisingly Vitowas able to achieve equivalent success rate as the manually engineered per-sonalization approach for cardiac EP.Generating training data could be considered Vito’s computational bot-tleneck. However, training is i) performed off-line and one-time only, andii) it is independent for each training episode and each patient. Therefore,large computing clusters could be employed to perform rapid training byparallelizing this phase. On-line personalization, on the contrary, is not par-allelizable in its current form: the parameters for each forward model rundepend on the outcome of the previous iteration. Since the forward com-putations are the same for every “standard” personalization method (notincluding surrogate-based approaches), the number of forward model runsuntil convergence was used for benchmarking: Vito was up to seven timesfaster compared to the reference methods. The on-line overhead introducedby Vito (convert data into an MDP state, then query policy) is negligible.As such, Vito could become a unified framework for personalization ofany computational physiological model, potentially eliminating the need for1Potential solution non-existence may be due to possibly invalid assumptions of theemployed EP model for patients with complex pathologies.23an expert operator with in-depth knowledge to design and engineer complexoptimization procedures.4.2. Challenges and OutlookImportant challenges still remain, such as the incorporation of continuousactions, the definition of states and their quantization. In this work we pro-pose a data-driven state-space quantization strategy. Contrary to Neumannet al. (2015), where a threshold-based state-quantization involving severalmanually tuned threshold values (Fig. 3) was employed, the new methodis based on a single hyper-parameter only: the number of representativestates. Although it simplifies the setup of Vito, this quantization strategymay still not be optimal, especially if only little training data is available.Therefore, advanced approaches for continuous reinforcement learning withvalue function approximation (Mnih et al., 2015; Sutton and Barto, 1998)could be integrated to fully circumvent quantization issues.At the same time, such methods could improve Vito’s scalability towardshigh-dimensional estimation tasks. In this work we showed that Vito can beapplied to typical problems emerging in cardiac modeling, which could bedescribed as medium-scale problems with moderate number of parameters topersonalize and objectives to match. In unreported experiments involving>10 parameters, however, Vito could no longer reach satisfactory perfor-mance, which is likely due to the steeply increasing number of transitionsamples needed to sample the continuous state-space of increasing dimen-sionality sufficiently during training. The trends in Sec. 3.3 confirm the needfor more data. In the future, experience replay (Adam et al., 2012; Lin, 1993)or similar techniques could be employed to increase training data efficiency.Furthermore, massively parallel approaches (Nair et al., 2015) are startingto emerge, opening up new avenues for large-scale reinforcement learning.Although the employed reinforcement learning techniques guarantee con-vergence to an optimal policy, the computed personalization strategy maynot be optimal for the model under consideration as the environment is onlypartially observable and the personalization problem ill-posed: there is noguarantee for solution existence or uniqueness. Yet, we showed that Vitocan solve personalization more robustly and more effectively than standardmethods under the same conditions. However, a theoretical analysis in termsof convergence guarantees and general stability of the method would be de-sirable, in particular with regards to the proposed re-initialization strategy.As a first step towards this goal, in preliminary (unreported) experiments onthe EP and the WBC model we observed that the number of patients whichdo not require re-initialization (due to oscillation) to converge to a successfulpersonalization consistently increased with increasing training data.The data-driven initialization proposed in this work simplifies Vito’ssetup by eliminating the need for user-provided initialization. However,currently there is no guarantee that the first initialization candidate is the24one that will yield the “best” personalization outcome. Therefore, one couldinvestigate the benefits of a fuzzy personalization scheme: many personaliza-tion processes could be run in parallel starting from the different initializa-tion candidates. Parameter uncertainty quantification techniques (Neumannet al., 2014a) could then be applied to compute a probability density func-tion over the space of model parameters. Such approaches aim to gathercomplete information about the solution-space, which can be used to studysolution uniqueness and other interesting properties.An important characteristic of any personalization algorithm is its sta-bility against small variations of the measured data. A preliminary ex-periment indicated good stability of Vito: the computed parameters fromseveral personalization runs, each involving small random perturbations ofthe measurements, were consistent. Yet in a small group of patients someparameter variability was observed, however, it was below the variability ofthe reference method under the same conditions. To what extent certaindegrees of variability will impact other properties of the personalized modelsuch as its predictive power will be subject of future research. We will alsoinvestigate strategies to improve Vito’s stability further. For instance, thegranularity of the state-space could provide some flexibility to tune the sta-bility:less representative states means a larger region in state space perstate, thus small variations in the measured data might have less impacton personalization outcome. However, this could in turn have undesirableeffects on other properties of Vito such as success rate or convergence speed(see Sec. 3.2.2).Beyond these challenges, Vito showed promising performance and ver-satility, making it a first step towards an automated, self-taught model per-sonalization agent. The next step will be to investigate the predictive powerof the personalized models, for instance for predicting acute or long-termresponse in cardiac resynchronization therapy (Kayvanpour et al., 2015; Ser-mesant et al., 2009).Appendix A. Data-driven State-Space QuantizationThis section describes the details of the proposed data-driven quantiza-tion approach to define the set of representative MDP states S (see Sec. 2.4).It is based on clustering, in particular on the weighted k -means algorithmdescribed in Arthur and Vassilvitskii (2007). To this end, all objective vec-tors C = {c ∈ E} are extracted from the training data (Sec. 2.3). C ⊂ Rncrepresents all observed “continuous states”. The goal is to convert C intothe finite set of representative MDP states S while taking into account thatVito relies on a special “success state” ˆs encoding personalization success.The success state ˆs does not depend on the data, but on the maximumacceptable misfit ψ. In particular, since personalization success implies thatall objectives are met, ˆs should approximate a hyperrectangle centered at25Figure A.11: Preprocessing of k -means input data to enforce the success state ˆs. Left:Continuous state-space with observed objective vectors c (blue points). The points withdashed outline will be canceled out. Right: Delineation of ˆs in green, enforced by insertedvectors (green / red points) with large weights. See text for details.0 and bounded at ±ψ, i.e. a small region in Rnc where ∀i : |ci| < ψi. Toenforce ˆs, the input to weighted k -means is preprocessed as follows.First, the 0-vector is inserted into C, along with two vectors per dimen-sion i, where all components are zero, except the ith component, which is setto ±2ψi. These 2nc + 1 inserted vectors are later converted into centroidsof representative states to delineate the desired hyperrectangle for ˆs as il-lustrated in Fig. A.11. Furthermore, to avoid malformation of ˆs, no otherrepresentative state should emerge within that region. Therefore, all vectorsc ∈ C, where ∀i : |ci| < 2ψi (except for the inserted vectors) are canceledout by assigning zero weight, while the inserted vectors are assigned largeweights → ∞ and all remaining vectors weights of 1.Next, k -means is initialized by placing a subset of the initial centroids atthe locations of the inserted states, and the remaining nS − 2nc − 1 centroidsat random vectors in C. Both the large weight and the custom initializationenforce the algorithm to converge to a solution where one cluster centroidis located at each inserted vector, while the other centroids are distributedaccording to the training data. To ensure equal contribution of all objectives(cancel out different units, etc.), similarity is defined relative to the inverseof the user-defined convergence criteria (Eq. 7).Finally, after k -means converged, the resulting centroids, denoted ξs, areused to delineate the region in Rnc assigned to a representative state s.Appendix B. Data-driven InitializationThis section describes the details of the proposed data-driven initializa-tion approach to compute a list of candidate initialization parameter vectorsX0 = (x(cid:48)0, . . . ) for a new patient p based on the patient’s measurementszp and the training database E (see Sec. 2.6.1).0, x(cid:48)(cid:48)26First, all model states are extracted from the training database: Υ ={y ∈ E}. Next, Υ is fed to a clustering algorithm (e.g. k -means). As inAppendix A, the distance measure is defined relative to the inverse of theconvergence criteria (Eq. 7). The output is a set of centroids (for simplicity,in this work the number of centroids was set to nS), and each vector isassigned to one cluster based on its closest centroid. Let Υp ⊆ Υ denote themembers of the cluster whose centroid is closest to zp and Ξp = {x ∈ E |f (x) ∈ Υp} the set of corresponding model parameters. For each cluster, anapproximation of the likelihood over the generating parameters is computedin terms of a probability density function. In this work a Gaussian mixturemodel is assumed:GMMp(x) =M(cid:88)m=1νmN (x; µm, Σm) .(B.1)The parameter vectors in Ξp are treated as random samples drawn fromGMMp. Its properties, namely the number of mixture components M , theirweights νm, and their means µm and covariance matrices Σm, are estimatedfrom these samples using a multivariate kernel density estimator with au-tomated kernel bandwidth estimation, see Kristan et al. (2011) for moredetails. Finally, the M estimated means are selected as initialization can-didates and stored in a list X0 = (µm(cid:48), µm(cid:48)(cid:48), . . . ). The elements of X0 aresorted in descending order according to their corresponding νm-values to pri-oritize more likely initializations: µm(cid:48) is the mean with m(cid:48) = arg maxm νm.ReferencesReferencesAdam, S., Busoniu, L., Babuska, R., 2012. Experience replay for real-timereinforcement learning control. IEEE Sys. Man. Cybern. 42 (2), 201–212.Aguado-Sierra, J., Kerckhoffs, R. C. P., Lionetti, F., Hunt, D., Villongco,C., Gonzales, M., Campbell, S. G., McCulloch, A. D., 2010. A compu-tational framework for patient-specific multi-scale cardiac modeling. In:Kerckhoffs, R. C. (Ed.), Patient-Specific Modeling of the CardiovascularSystem. Springer, pp. 203–223.Aguado-Sierra, J., Krishnamurthy, A., Villongco, C., Chuang, J., Howard,E., Gonzales, M. J., Omens, J., Krummen, D. E., Narayan, S., Kerckhoffs,R. C. P., McCulloch, A. D., 2011. Patient-specific modeling of dyssyn-chronous heart failure: a case study. Prog. Biophys. Mol. Bio. 107 (1),147–155.Arthur, D., Vassilvitskii, S., 2007. k-means++: The advantages of carefulseeding. In: ACM-SIAM Symp. Discr. Algorithm. pp. 1027–1035.27Augenstein, K. F., Cowan, B. R., LeGrice, I. J., Nielsen, P. M., Young, A. A.,2005. Method and apparatus for soft tissue material parameter estimationusing tissue tagged magnetic resonance imaging. J. Biomech. Eng. 127 (1),148–157.Barreto, A., Precup, D., Pineau, J., 2014. Practical kernel-based reinforce-ment learning. arXiv preprint arXiv:1407.5358.Bellman, R., 1957. Dynamic Programming. Princeton University Press.Bishop, C. M., 2006. Pattern recognition and machine learning. Vol. 4.Springer New York.Chabiniok, R., Moireau, P., Lesault, P.-F., Rahmouni, A., Deux, J.-F.,Chapelle, D., 2012. Estimation of tissue contractility from cardiac cine-mri using a biomechanical heart model. Biomech. Model. Mechan. 11 (5),609–630.Clayton, R., Bernus, O., Cherry, E., Dierckx, H., Fenton, F., Mirabella,L., Panfilov, A., Sachse, F., Seemann, G., Zhang, H., 2011. Models ofcardiac tissue electrophysiology: progress, challenges and open questions.Prog. Biophys. Mol. Bio. 104 (1), 22–48.Delingette, H., Billet, F., Wong, K. C. L., Sermesant, M., Rhode, K., Ginks,M., Rinaldi, C. A., Razavi, R., Ayache, N., 2012. Personalization of car-diac motion and contractility from images using variational data assimi-lation. IEEE T. Biomed. Eng. 59 (1), 20–24.Frangi, A. F., Niessen, W. J., Viergever, M., 2001. Three-dimensional model-ing for functional analysis of cardiac images, a review. IEEE T. Med. Imag-ing 20 (1), 2–5.Hunter, P. J., Borg, T. K., 2003. Integration from proteins to organs: thephysiome project. Nat. Rev. Mol. Cell Bio. 4 (3), 237–243.Itu, L., Sharma, P., Georgescu, B., Kamen, A., Suciu, C., Comaniciu, D.,2014. Model based non-invasive estimation of PV loop from echocardiog-raphy. IEEE Eng. Med. Biol. Soc., 6774–6777.Kaelbling, L. P., Littman, M. L., Moore, A. W., 1996. Reinforcement learn-ing: A survey. J. Artif. Intell. Res., 237–285.Kayvanpour, E., Mansi, T., Sedaghat-Hamedani, F., Amr, A., Neumann, D.,Georgescu, B., Seegerer, P., Kamen, A., Haas, J., Frese, K. S., Irawati, M.,Wirsz, E., King, V., Buss, S., Mereles, D., Zitron, E., Keller, A., Katus,H. A., Comaniciu, D., Meder, B., 2015. Towards personalized cardiology:Multi-scale modeling of the failing heart. PLoS ONE 10 (7), e0134869.28Kerckhoffs, R. C. P., Lumens, J., Vernooy, K., Omens, J., Mulligan, L., Del-haas, T., Arts, T., McCulloch, A., Prinzen, F., 2008. Cardiac resynchro-nization: insight from experimental and computational models. Prog. Bio-phys. Mol. Bio. 97 (2), 543–561.Konukoglu, E., Relan, J., Cilingir, U., Menze, B. H., Chinchapatnam, P.,Jadidi, A., Cochet, H., Hocini, M., Delingette, H., Ja¨ıs, P., Ha¨ıssaguerre,M., Ayache, N., Sermesant, M., 2011. Efficient probabilistic model per-sonalization integrating uncertainty on data and parameters: Applica-tion to eikonal-diffusion models in cardiac electrophysiology. Prog. Bio-phys. Mol. Bio. 107 (1), 134–146.Krishnamurthy, A., Villongco, C. T., Chuang, J., Frank, L. R., Nigam, V.,Belezzuoli, E., Stark, P., Krummen, D. E., Narayan, S., Omens, J. H.,McCulloch, A. D., Kerckhoffs, R. C. P., 2013. Patient-specific models ofcardiac biomechanics. J. Comput. Phys. 244, 4–21.Kristan, M., Leonardis, A., Skoˇcaj, D., 2011. Multivariate online kerneldensity estimation with gaussian kernels. Pattern Recogn. 44 (10), 2630–2642.Kuijpers, N. H., Hermeling, E., Bovendeerd, P. H., Delhaas, T., Prinzen,F. W., 2012. Modeling cardiac electromechanics and mechanoelectricalcoupling in dyssynchronous and failing hearts. J. Cardiovasc. Transl. Res.5 (2), 159–169.Kveton, B., Theocharous, G., 2012. Kernel-based reinforcement learning onrepresentative states. In: Association for the Advancement of ArtificialIntelligence. pp. 977–983.Lagarias, J. C., Reeds, J. A., Wright, M. H., Wright, P. E., 1998. Conver-gence properties of the Nelder-Mead simplex method in low dimensions.SIAM J. Optimiz. 9 (1), 112–147.Le Folgoc, L., Delingette, H., Criminisi, A., Ayache, N., 2013. Current-based4D shape analysis for the mechanical personalization of heart models. In:Medical Computer Vision. Recognition Techniques and Applications inMedical Imaging. Vol. 7766 of LNCS. Springer, pp. 283–292.Lin, L.-J., 1993. Reinforcement learning for robots using neural networks.Tech. rep., DTIC Document.Marchesseau, S., Delingette, H., Sermesant, M., Cabrera-Lozoya, R., Tobon-Gomez, C., Moireau, P., Figueras i Ventura, R. M., Lekadir, K., Hernan-dez, A., Garreau, M., Donal, E., Leclercq, C., Duckett, S. G., Rhode,K., Rinaldi, C. A., Frangi, A. F., Razavi, R., Chapelle, D., Ayache, N.,2013. Personalization of a cardiac electromechanical model using reduced29order unscented kalman filtering from regional volumes. Med. Image Anal.17 (7), 816–829.Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare,M. G., Graves, A., Riedmiller, M., Fidjeland, A. K., Ostrovski, G., Pe-tersen, S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumara, D.,Wierstra, D., Legg, S., Hassabis, D., 2015. Human-level control throughdeep reinforcement learning. Nature 518 (7540), 529–533.M¨ulling, K., Kober, J., Kroemer, O., Peters, J., 2013. Learning to select andgeneralize striking movements in robot table tennis. Int. J. Robot. Res.32 (3), 263–279.Nair, A., Srinivasan, P., Blackwell, S., Alcicek, C., Fearon, R., De Maria,A., Panneershelvam, V., Suleyman, M., Beattie, C., Petersen, S., Legg, S.,Mnih, V., Kavukcuoglu, K., Silver, D., 2015. Massively parallel methodsfor deep reinforcement learning. arXiv:1507.04296.Neumann, D., Mansi, T., Georgescu, B., Kamen, A., Kayvanpour, E., Amr,A., Sedaghat-Hamedani, F., Haas, J., Katus, H., Meder, B., Hornegger,J., Comaniciu, D., 2014a. Robust image-based estimation of cardiac tissueparameters and their uncertainty from noisy data. In: MICCAI. Vol. 8674of LNCS. Springer, pp. 9–16.Neumann, D., Mansi, T., Grbic, S., Voigt, I., Georgescu, B., Kayvanpour,E., Amr, A., Sedaghat-Hamedani, F., Haas, J., Katus, H., Meder, B.,Hornegger, J., Kamen, A., Comaniciu, D., 2014b. Automatic image-to-model framework for patient-specific electromechanical modeling of theheart. In: IEEE Int. Symp. Biomed. Imaging. pp. 935–938.Neumann, D., Mansi, T., Itu, L., Georgescu, B., Kayvanpour, E., Sedaghat-Hamedani, F., Haas, J., Katus, H., Meder, B., Steidl, S., Hornegger,J., Comaniciu, D., 2015. Vito – a generic agent for multi-physics modelpersonalization: Application to heart modeling. In: MICCAI. Vol. 9350of LNCS. Springer, pp. 442–449.Nguyen-Tuong, D., Peters, J., 2011. Model learning for robot control: asurvey. Cogn. Process. 12 (4), 319–340.Noble, D., 2002. Modeling the heart – from genes to cells to the whole organ.Science 295 (5560), 1678–1682.Powell, M. J., 2009. The BOBYQA algorithm for bound constrained opti-mization without derivatives. Cambridge NA Report NA2009/06.Prakosa, A., Sermesant, M., Allain, P., Villain, N., Rinaldi, C., Rhode,K., Razavi, R., Delingette, H., Ayache, N., 2013. Cardiac electrophysio-30logical activation pattern estimation from images using a patient-specificdatabase of synthetic image sequences. IEEE T. Biomed. Eng.Rosenbrock, H., 1960. An automatic method for finding the greatest or leastvalue of a function. Comput. J. 3 (3), 175–184.Schmid, H., Nash, M., Young, A., Hunter, P., 2006. Myocardial ma-terial parameter estimation – a comparative study for simple shear.J. Biomech. Eng. 128 (5), 742–750.Seegerer, P., Mansi, T., Jolly, M.-P., Neumann, D., Georgescu, B., Kamen,A., Kayvanpour, E., Amr, A., Sedaghat-Hamedani, F., Haas, J., Ka-tus, H., Meder, B., Comaniciu, D., 2015. Estimation of regional electricalproperties of the heart from 12-lead ECG and images. In: Statistical At-lases and Computational Models of the Heart – Imaging and ModellingChallenges. Vol. 8896 of LNCS. Springer, pp. 204–212.Sermesant, M., Billet, F., Chabiniok, R., Mansi, T., Chinchapatnam, P.,Moireau, P., Peyrat, J.-M., Rhode, K., Ginks, M., Lambiase, P., Arridge,S., Delingette, H., Sorine, M., Rinaldi, C. A., Chapelle, D., Razavi, R.,Ayache, N., 2009. Personalised electromechanical model of the heart forthe prediction of the acute effects of cardiac resynchronisation therapy.In: Functional Imaging and Modeling of the Heart. Vol. 5528 of LNCS.Springer, pp. 239–248.Sutton, R. S., Barto, A. G., 1998. Reinforcement learning: An introduction.Vol. 1. MIT press Cambridge.Tesauro, G., 1994. Td-gammon, a self-teaching Backgammon program,achieves master-level play. Neural Comput. 6 (2), 215–219.Wallman, M., Smith, N. P., Rodriguez, B., 2012. A comparative study ofgraph-based, eikonal, and monodomain simulations for the estimation ofcardiac activation times. IEEE T. Biomed. Eng. 59 (6), 1739–1748.Wallman, M., Smith, N. P., Rodriguez, B., 2014. Computational methodsto reduce uncertainty in the estimation of cardiac conduction propertiesfrom electroanatomical recordings. Med. Image Anal. 18 (1), 228–240.Wang, V. Y., Lam, H., Ennis, D. B., Cowan, B. R., Young, A. A., Nash,M. P., 2009. Modelling passive diastolic mechanics with quantitative mriof cardiac structure and function. Med. Image. Anal. 13 (5), 773–784.Wang, Y., Georgescu, B., Chen, T., Wu, W., Wang, P., Lu, X., Ionasec, R.,Zheng, Y., Comaniciu, D., 2013. Learning-based detection and trackingin medical imaging: a probabilistic approach. In: Deformation Models.Vol. 7 of LNCVB. Springer, pp. 209–235.31Westerhof, N., Elzinga, G., Sipkema, P., 1971. An artificial arterial systemfor pumping hearts. J. Appl. Physiol. 31 (5), 776–781.Wong, K. C., Sermesant, M., Rhode, K., Ginks, M., Rinaldi, C. A.,Razavi, R., Delingette, H., Ayache, N., 2015. Velocity-based cardiac con-tractility personalization from images using derivative-free optimization.J. Mech. Behav. Biomed. 43, 35–52.Xi, J., Lamata, P., Niederer, S., Land, S., Shi, W., Zhuang, X., Ourselin,S., Duckett, S. G., Shetty, A. K., Rinaldi, C. A., Rueckert, D., Razavi,R., Smith, N. P., 2013. The estimation of patient-specific cardiac diastolicfunctions from clinical measurements. Med. Image. Anal. 17 (2), 133–146.Zettinig, O., Mansi, T., Neumann, D., Georgescu, B., Rapaka, S., Seegerer,P., Kayvanpour, E., Sedaghat-Hamedani, F., Amr, A., Haas, J., Steen,H., Katus, H., Meder, B., Navab, N., Kamen, A., Comaniciu, D., 2014.Data-driven estimation of cardiac electrical diffusivity from 12-lead ECGsignals. Med. Image Anal., 1361–1376.Zheng, Y., Barbu, A., Georgescu, B., Scheuering, M., Comaniciu, D., 2008.Four-chamber heart modeling and automatic segmentation for 3-D cardiacCT volumes using marginal space learning and steerable features. IEEET. Med. Imaging 27 (11), 1668–1681.32