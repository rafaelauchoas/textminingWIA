Artificial Intelligence 171 (2007) 951–984www.elsevier.com/locate/artintMetatheory of actions: Beyond consistencyAndreas Herzig, Ivan Varzinczak ∗IRIT – Université Paul Sabatier, 118 route de Narbonne, 31062, Toulouse Cedex 9, FranceReceived 25 April 2006; received in revised form 15 March 2007; accepted 23 April 2007Available online 29 April 2007AbstractTraditionally, consistency is the only criterion for the quality of a theory in logic-based approaches to reasoning about actions.This work goes beyond that and contributes to the metatheory of actions by investigating what other properties a good domaindescription should have. We state some metatheoretical postulates concerning this sore spot. When all postulates are satisfied wecall the action theory modular. Besides being easier to understand and more elaboration tolerant in McCarthy’s sense, modulartheories have interesting properties. We point out the problems that arise when the postulates about modularity are violated, andpropose algorithmic checks that can help the designer of an action theory to overcome them.© 2007 Elsevier B.V. All rights reserved.Keywords: Reasoning about actions; Action theory; Modularity; Ramifications1. IntroductionIn logic-based approaches to knowledge representation, a given domain is described by a set of logical formulasT , which we call a (non-logical) theory. That is also the case for reasoning about actions, where we are interested intheories describing particular actions (or, more precisely, action types). We call such theories action theories.A priori consistency is the only criterion that formal logic provides to check the quality of such descriptions. Inthe present work we go beyond that, and argue that we should require more than the mere existence of a model for agiven theory.Our starting point is the fact that in reasoning about actions one usually distinguishes several kinds of logicalformulas. Among these are effect axioms, precondition axioms, and boolean axioms. In order to distinguish such non-logical axioms from logical axioms, we prefer to speak of effect laws, executability laws, and static laws, respectively.Moreover we single out those effect laws whose effect is ⊥, and call them inexecutability laws.Given these types of laws, suppose the language is powerful enough to state conditional effects of actions. Forexample, suppose that action a is inexecutable in contexts where ϕ1 holds, and executable in contexts where ϕ2 holds.It follows that there can be no context where ϕ1 ∧ ϕ2 holds. Now ¬(ϕ1 ∧ ϕ2) is a static law that does not mention a.It is natural to expect that ¬(ϕ1 ∧ ϕ2) follows from the static laws alone. By means of examples we show that when* Corresponding author.E-mail addresses: herzig@irit.fr (A. Herzig), ivan@irit.fr (I. Varzinczak).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.04.013952A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984this is not the case, then unexpected conclusions might follow from the theory T , even in the case T is logicallyconsistent.This motivates postulates requiring that the different laws of an action theory should be arranged modularly, i.e.,in separated components, and in such a way that interactions between them are limited and controlled. In essence,we argue that static laws may entail new effects of actions (that cannot be inferred from the effect laws alone), whileeffect laws and executability laws should never entail new static laws that do not follow from the set of static lawsalone. We here formulate postulates that make these requirements precise. It will turn out that in all existing accountsthat allow for these four kinds of laws [1–6], consistent action theories can be written that violate these postulates.In this work we give algorithms that allow one to check whether an action theory satisfies the postulates or not. Withsuch algorithms, the task of correcting flawed action theories can be made easier.Although we here use the syntax of propositional dynamic logic (PDL) [7], all we shall say applies as well tofirst-order formalisms, in particular to the Situation Calculus [8]. All postulates we are going to present can be statedas well for other frameworks, in particular for action languages such as A, AR [9–11] and others, and for SituationCalculus based approaches. In [12] we have given a Situation Calculus version of our analysis, while in [13] wepresented a similar notion for ontologies in Description Logics [14]. The present work is the complete version of theone first appeared in [15].This text is organized as follows: after some background definitions (Section 2) we state some postulates concerningaction theories (Section 3). In Sections 4 and 5, we study the two most important of these postulates, giving algorithmicmethods to check whether an action theory satisfies them or not. We then generalize our postulates (Section 6) anddiscuss possible strengthening of them (Section 7). In Section 8 we show interesting features of modular actiontheories. Before concluding, we assess related work found in the literature on metatheory of actions (Section 9).2. Preliminaries2.1. Dynamic logicHere we establish an ontology of dynamic domains. As our base formalism we use ∗-free PDL, i.e., PDL withoutthe iteration operator ∗. For more details on PDL, see [7,16].Let Act = {a1, a2, . . .} be the set of all atomic action constants of a given domain. Our running example is in termsof the Walking Turkey Scenario [4]. There, the atomic actions are load, shoot and tease. We use a as a variable foratomic actions. To each atomic action a there is an associated modal operator [a]. Here we suppose that the underlyingmultimodal logic is independently axiomatized (i.e., the logic is a fusion and there is no interaction between the modaloperators [17,18]).Prop = {p1, p2, . . .} denotes the set of all propositional constants, also called fluents or atoms. Examples of thoseare loaded, alive and walking. We use p as a variable for propositional constants.We here suppose that both Act and Prop are nonempty and finite.We use small Greek letters ϕ, ψ, . . . to denote classical formulas, also called boolean formulas. They are recursivelydefined in the following way:ϕ ::= p | (cid:5) | ⊥ | ¬ϕ | ϕ ∧ ϕ | ϕ ∨ ϕ | ϕ → ϕ | ϕ ↔ ϕ.Fml is the set of all classical formulas.Examples of classical formulas are walking → alive and ¬(bachelor ∧ married).A classical formula is classically consistent if there is at least one valuation in classical propositional logic thatmakes it true. Given ϕ ∈ Fml, valuations(ϕ) denotes the set of all valuations of ϕ. We note |=CPL the logical conse-quence in classical propositional logic.The set of all literals is Lit = Prop ∪ {¬p: p ∈ Prop}. Examples of literals are alive and ¬walking. (cid:4) will be usedas a variable for literals. If (cid:4) = ¬p, then we identify ¬(cid:4) with p.A clause χ is a disjunction of literals. We say that a literal (cid:4) appears in a clause χ , written (cid:4) ∈ χ , if (cid:4) is a disjunctof χ .We denote complex formulas (possibly with modal operators) by capital Greek letters Φ1, Φ2, . . . They are recur-sively defined in the following way:Φ ::= ϕ | [a]Φ | (cid:11)a(cid:12)Φ | ¬Φ | Φ ∧ Φ | Φ ∨ Φ | Φ → Φ | Φ ↔ ΦA. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984953where Φ denotes a complex formula. (cid:11)a(cid:12) is the dual operator of [a], defined by: (cid:11)a(cid:12)Φ =def ¬[a]¬Φ. Sequentialcomposition of actions is defined by the abbreviation [a1; a2]Φ =def [a1][a2]Φ. Examples of complex formulas areloaded → [shoot]¬alive and hasGun → (cid:11)load; shoot(cid:12)(¬alive ∧ ¬loaded).If T is a set of formulas (modal or classical), atm(T ) returns the set of all atoms occurring in T . For instance,atm({¬¬¬p1, [a]p2}) = {p1, p2}.For parsimony’s sake, whenever there is no confusion we identify a set of formulas with the conjunction of itselements. The semantics is that for multimodal K [19,20].Definition 1. A PDL-model is a tuple M = (cid:11)W, R(cid:12) where W is a set of valuations (alias possible worlds), andR : Act −→ 2W ×W a function mapping action constants a to accessibility relations Ra ⊆ W × W .As an example, for Act = {a1, a2} and Prop = {p1, p2}, we have the PDL-model M = (cid:11)W, R(cid:12), whereW =(cid:2){p1, p2}, {p1, ¬p2}, {¬p1, p2}(cid:3),(cid:4)(cid:2)(cid:6)R(a1) =R(a2) =({p1, p2}, {p1, ¬p2}), ({p1, p2}, {¬p1, p2}),({¬p1, p2}, {¬p1, p2}), ({¬p1, p2}, {p1, ¬p2})(cid:7)(cid:3)(cid:6){p1, ¬p2}, {p1, ¬p2}{p1, p2}, {p1, ¬p2}.(cid:7),(cid:5),Fig. 1 gives a graphical representation of M.Given M = (cid:11)W, R(cid:12), a ∈ Act, and w, w(cid:14) ∈ W , we write Ra instead of R(a), and wRaw(cid:14) instead of w(cid:14) ∈ Ra(w).Definition 2. Given a PDL-model M = (cid:11)W, R(cid:12), the satisfaction relation is defined as the smallest relation satisfying:w p (p is true at world w of model M) if p ∈ w;• |=M[a]Φ if for every w(cid:14) such that wRaw(cid:14), |=M• |=Mw• the usual truth conditions for the other connectives.w(cid:14) Φ; andDefinition 3. A PDL-model M is a model of Φ (noted |=M Φ) if and only if for all w ∈ W , |=Ma set of formulas T (noted |=M T ) if and only if |=M Φ for every Φ ∈ T .w Φ. M is a model ofIn the model depicted in Fig. 1, we have |=M p1 → [a2]¬p2 and |=M p1 ∨ p2.Definition 4. A formula Φ is a consequence of the set of global axioms T in the class of all PDL-models (notedT |=PDL Φ) if and only if for every PDL-model M, if |=M T , then |=M Φ.1We here suppose that the logic under consideration is compact [21].Fig. 1. Example of a PDL-model for Act = {a1, a2}, and Prop = {p1, p2}.1 Instead of global consequence, in [5] local consequence is considered. For that reason, a further modal operator (cid:2) had to be introduced, givinga logic that is multimodal K plus monomodal S4 for (cid:2), and where axiom schema (cid:2)Φ → [a]Φ holds.954A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984Having established the formal substratum our presentation will rely on, we present in the next section the differenttypes of formulas we use to describe dynamic domains.2.2. Describing action theories in PDLBefore elaborating a theory, we need to specify what we are about to describe, i.e., what the formulas talk about.Following the tradition in the literature, we identify a domain (alias scenario) with the actions we take into accountand the fluents they can change. More formally, we have:Definition 5. A domain signature is a tuple (cid:11)Act, Prop(cid:12).An example of a domain is the well-known Yale Shooting Scenario (YSS) [22], whose signature comprises theactions load, wait and shoot, and fluents loaded and alive.Given a domain (cid:11)Act, Prop(cid:12), we are interested in theories whose statements describe the behavior of actions ofAct on the fluents of Prop. PDL allows for the representation of such statements, that we here call action laws. Wedistinguish several types of them. We call effect laws formulas relating an action to its effects. Statements of conditionsunder which an action cannot be executed are called inexecutability laws. Executability laws in turn stipulate thecontext where an action is guaranteed to be executable. Finally, static laws are formulas that do not mention actions.They express constraints that must hold in every possible state. These four types of laws are our fundamental entitiesand we introduce them more formally in the sequel.2.2.1. Static lawsFrameworks which allow for indirect effects of actions make use of logical formulas that state invariant propositionsabout the world. Such formulas delimit the set of possible states. They do not refer to actions, and we suppose herethat they are expressed as formulas of classical propositional logic.Definition 6. A static law is a formula ϕ ∈ Fml.In our running example, the static law walking → alive says that if a turkey is walking, then it must be alive.Another one is saved ↔ (mbox1 ∨ mbox2), which states that an e-mail message is saved if and only if it is in mailbox 1or in mailbox 2 or both [23].In some action languages, such as AR for example, we would write the statement always alive → walking, and inthe Situation Calculus it would be the first-order formula(cid:6)∀s.(cid:7)Holds(walking, s) → Holds(alive, s).The set of all static laws of a given domain is denoted by S . At first glance, no requirement concerning consistencyof S is made. Of course, we want S to be consistent, otherwise the whole theory is inconsistent. As we are going tosee in the sequel, however, consistency of S alone is not enough to guarantee the consistency of a theory.2.2.2. Effect lawsLogical frameworks for reasoning about actions contain expressions linking actions and their effects. We supposethat such effects might be conditional, and thus get a third component of such laws.In PDL, the formula [a]Φ states that formula Φ is true after every possible execution of action a.Definition 7. An effect law2 for action a is of the form ϕ → [a]ψ, where ϕ, ψ ∈ Fml, with ψ classically consistent.The consequent ψ is the effect which obtains when action a is executed in a state where the antecedent ϕ holds.An example of an effect law is loaded → [shoot]¬alive, saying that whenever the gun is loaded, after shooting the2 Effect laws are often called action laws, but we prefer not to use that term here because it would also apply to executability laws that are to beintroduced in the sequel.A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984955turkey is dead. Another one is (cid:5) → [tease]walking: in every circumstance, the result of teasing is that the turkey startswalking. For parsimony’s sake, the latter effect law will be written [tease]walking.Note that the consistency requirement for ψ makes sense: if ψ is inconsistent then we have an inexecutability law,that we consider as a separate entity and which we are about to introduce formally in the sequel. On the other hand, ifϕ is inconsistent then the effect law is obviously superfluous.For the first example above, in action languages one would write the statementshoot causes ¬ alive if loaded,and in the Situation Calculus formalism one would write the first-order formula(cid:6)(cid:6)Holds(loaded, s) → ¬Holds∀s.alive, do(shoot, s)(cid:7)(cid:7).2.2.3. Inexecutability lawsWe consider effect laws with inconsistent consequents as a particular kind of law which we call inexecutabilitylaws. (Such laws are sometimes called qualifications [24].) This allows us to avoid mixing things that are conceptuallydifferent: for an action a, an effect law mainly associates it with a consequent ψ, while an inexecutability law onlyassociates it with an antecedent ϕ, viz. the context which precludes the execution of a.Definition 8. An inexecutability law for action a is of the form ϕ → [a]⊥, with ϕ ∈ Fml.For example ¬hasGun → [shoot]⊥ expresses that shoot cannot be executed if the agent has no gun. Anotherexample is dead → [tease]⊥: a dead turkey cannot be teased.In AR we would write the statement impossible if ¬hasGun, and in the Situation Calculus our example would be(cid:6)¬Holds(hasGun, s) → ¬Poss(shoot, s)∀s.(cid:7).2.2.4. Executability lawsWith only static and effect laws one cannot guarantee that the action shoot can be executed whenever the agent hasa gun. We need thus a way to state such conditions.In dynamic logic the dual (cid:11)a(cid:12)ϕ, defined as ¬[a]¬ϕ, can be used to express executability. (cid:11)a(cid:12)(cid:5) thus reads “executionof action a is possible”.Definition 9. An executability law for action a is of the form ϕ → (cid:11)a(cid:12)(cid:5), where ϕ ∈ Fml.For instance hasGun → (cid:11)shoot(cid:12)(cid:5) says that shooting can be executed whenever the agent has a gun, and (cid:5) →(cid:11)tease(cid:12)(cid:5), also written (cid:11)tease(cid:12)(cid:5), establishes that the turkey can always be teased.Some approaches (most prominently Reiter’s) use biconditionals ϕ ↔ (cid:11)a(cid:12)(cid:5), called precondition axioms. This isequivalent to ¬ϕ ↔ [a]⊥, which highlights that they merge information about inexecutability with information aboutexecutability. Here we consider these entities to be different and keep them separate.In action languages such laws are not represented, they are rather implicitly inferred from inexecutability statements(cf. Section 7). In Situation Calculus our example would be stated as(cid:7)(cid:6)Holds(hasGun, s) → Poss(shoot, s)∀s..Whereas all the extant approaches in the literature that allow for indirect effects of actions contain static and effectlaws, and provide a way for representing inexecutabilities (in the form of implicit qualifications [2,4,25]), the statusof executability laws is less consensual. Some authors [3,4,26,27] more or less tacitly consider that executability lawsshould not be made explicit but rather inferred by the reasoning mechanism. Others [1,2,5,6] have executability lawsas first class objects one can reason about.It seems a matter of debate whether one can always do without executabilities. In principle it seems to be strangeto just state information about necessary conditions for action execution (inexecutabilities) without saying anythingabout its sufficient conditions. The justification is that given an action we have three possible situations: it is knownto be executable, known to be inexecutable, and unknown whether executable. This is the reason why we think thatwe need executability laws. Indeed, in several domains one wants to explicitly state under which conditions a given956A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984action is guaranteed to be executable, e.g. that a robot never gets stuck and is always able to execute a move action.And if we have a plan such as load; shoot (load followed by shoot) of which we know that it achieves the goal ¬alive,then we would like to be sure that it is executable in the first place!3 In any case, allowing for executability laws givesus more flexibility and expressive power.2.2.5. Action theoriesGiven a domain (cid:11)Act, Prop(cid:12), for an action a ∈ Act, we define E a as the set of its effect laws, X a the set of itsexecutability laws, and Ia that of its inexecutability laws.Definition 10. An action theory for a is a tuple (cid:11)S , E a, X a, Ia(cid:12).In our running scenario example, a theory for the action shoot would beS = {walking → alive},X shoot =(cid:2)hasGun → (cid:11)shoot(cid:12)(cid:5)(cid:3),E shoot =(cid:3)(cid:2)loaded → [shoot]¬alive,I shoot =¬hasGun → [shoot]⊥(cid:2)(cid:3).Given a dynamic domain we define(cid:8)(cid:8)E =E a, X =X a,and I =a∈Acta∈Act(cid:8)Ia.a∈ActAll these sets are finite, because Act is finite and each of the E a, X a, Ia is finite.Definition 11. An action theory is a tuple of the form (cid:11)S , E , X , I (cid:12).Given an action theory (cid:11)S , E , X , I (cid:12) and a formula Φ, we write S , E , X , I |=PDL Φ instead of S ∪ E ∪ X ∪I |=PDL Φ.When formalizing dynamic domains, we face the frame problem [8] and the ramification problem [28]. In whatfollows we formally present the logical framework in which action theories will henceforth be described.2.3. Dynamic logic and the frame problemAs the reader might have already expected, the logical formalism of PDL alone does not solve the frame problem.For instance, if (cid:11)S , E , X , I (cid:12) describes our shooting domain, thenS , E , X , I (cid:16)|=PDL hasGun → [load]hasGun.The same can be said about the ramification problem in what concerns the derivation of indirect effects not properlycaused by the action under consideration. For example,S , E , X , I |=PDL ¬alive → [tease]alive.Thus, given an action theory (cid:11)S , E , X , I (cid:12), we need a consequence relation powerful enough to deal with the frameand ramification problems. This means that the deductive power of PDL has to be augmented in order to ensure thatthe only non-effects of actions that follow from the theory are those that are really relevant. The presence of static lawsmakes that this is a delicate task, and starting with [2,3], several authors have argued that some notion of causalityis needed. In this work we opt for the dependence-based approach presented in [5], which has been shown [29] tosubsume Reiter’s solution to the frame problem [30], and moreover at least partially accounts for the ramificationproblem [31].In the logical framework developed in [5], metalogical information, given in the form of a dependence relation, isadded to PDL.Definition 12 (Dependence relation [5]). A dependence relation is a binary relation (cid:3)⊆ Act × Lit.3 Of course this would require a solution to the qualification problem [24].A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984957The expression a (cid:3) (cid:4) denotes that the execution of action a may make the literal (cid:4) true. In our example we have(cid:4)(cid:3)=(cid:11)shoot, ¬loaded(cid:12), (cid:11)shoot, ¬alive(cid:12),(cid:11)shoot, ¬walking(cid:12), (cid:11)tease, walking(cid:12)(cid:5),which means that action shoot may make the literals ¬loaded, ¬alive and ¬walking true, and action tease may makewalking true.Semantically, the dependence-based approach relies on the explanation closure assumption [26], and its solution tothe frame problem consists in a kind of negation as failure: because (cid:11)load, ¬hasGun(cid:12) /∈ (cid:3), we have load (cid:16)(cid:3) ¬hasGun,i.e., ¬hasGun is never caused by load. Thus, in a context where hasGun is true, after every execution of load, hasGunstill remains true. We also have tease (cid:16)(cid:3) alive and tease (cid:16)(cid:3) ¬alive. The meaning of all these independences is that theframe axioms hasGun → [load]hasGun, ¬alive → [tease]¬alive and alive → [tease]alive hold.We assume that (cid:3) is finite.A dependence relation (cid:3) defines a class of possible worlds models:Definition 13. A PDL-model M = (cid:11)W, R(cid:12) is a (cid:3)-model if and only if whenever wRaw(cid:14) then:• if a (cid:16)(cid:3) p, then (cid:16)|=M• if a (cid:16)(cid:3) ¬p, then |=Mw p implies (cid:16)|=Mw p implies |=Mw(cid:14) p; andw(cid:14) p.Fig. 2 depicts the dependence-based condition on models.Given a (cid:3)-model M, Φ and T , |=M Φ and |=M T are defined as in Definition 3.Definition 14. A formula Φ is a (cid:3)-based consequence of the set of global axioms T in the class of all (cid:3)-models(noted T |=(cid:2) Φ) if and only if for every (cid:3)-model M, if |=M T , then |=M Φ.In our example it thus holdsS , E , X , I |=(cid:2) hasGun → [load]hasGunandS , E , X , I |=(cid:2) ¬alive → [tease]¬alive.In this way, the dependence-based approach solves the frame problem. However, it does not entirely solve theramification problem: while indirect effects such as loaded → [shoot]¬walking can be deduced with |=(cid:2) withoutexplicitly stating that in the set of effect laws for shoot, we nevertheless still have to state indirect dependences suchas shoot (cid:3) ¬walking. However, according to Reiter’s view:“what counts as a solution to the frame problem [. . .] is a systematic procedure for generating, from the effect laws,[. . .] a parsimonious representation for [all] the frame axioms” [32].Fig. 2. Dependence-based condition: preservation of literal ¬p under hypothesis a (cid:16)(cid:3) p.958A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984Fig. 3. A model of an action theory and its big model Mbig.We comply with that as we can define a semi-automatic procedure for generating the dependence relation fromthe set of effect laws [33]. Moreover, as it has been argued in [23,31], our approach is in line with the state of theart because none of the existing solutions to the frame and the ramification problems can handle domains with bothindeterminate and indirect effects.In the next section we turn to a metatheoretical analysis of action theories and make a step toward formal criteriafor theory evaluation. Before that, we need a definition.Definition 15. Let (cid:11)S , E a, X a, Ia(cid:12) be an action theory for a, and (cid:3) a dependence relation. Then M = (cid:11)W, R(cid:12) is thebig (alias maximal/standard) model for (cid:11)S , E a, X a, Ia(cid:12) and (cid:3) if and only if:• M is a (cid:3)-model;• W = valuations(S ) (all valuations of S ); and• Ra = {(w, w(cid:14)): for all ϕ → [a]ψ ∈ E a ∪ Ia, if |=Mw ϕ, then |=Mw(cid:14) ψ}.For an example, consider an action theory whose components are given by(cid:2)(cid:3)(cid:2)E a =S = ∅,(cid:2)Ia =p2 → [a]⊥p1 → [a]¬p2(cid:3),and (cid:3)=, X a =(cid:11)a(cid:12)(cid:5)(cid:3)(cid:2)(cid:11)a, ¬p1(cid:12), (cid:11)a, ¬p2(cid:12).(cid:3),Fig. 3 depicts one of its models and its associated big model.Big models contain all valuations consistent with S . Clearly, for a big model M we have |=M S ∧ E a ∧ Ia. BecauseM maximizes executability, it is only X a which might not be true in M.In the rest of the paper we characterize when an action theory with a dependence relation has a big model.3. The postulates“When does a given action theory have a model?”, and, more importantly, “is that model intended?” are questionsthat naturally arise when we talk about action theories. Here we claim that all the approaches that are put forward inthe literature are too liberal in the sense that we can have satisfiable action theories that are intuitively incorrect. Weargue that something beyond the consistency notion is required in order to help us in answering these questions.Our central thesis is that the different types of laws defined in Section 2.2 should be neatly separated in modules.Besides that, we want such laws to interfere only in one sense: static laws together with action laws for a may haveconsequences that do not follow from the action laws for a alone. The other way round, action laws should not allowto infer new static laws; effect laws should not allow to infer inexecutability laws; action laws for a should not allowto infer action laws for a(cid:14), etc. This means that our logical modules should be designed in such a way that they are asspecialized and as little dependent on others as possible.A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984959A first step in this direction has been the proposed division of our entities into the sets S , E , X and I . In order to ac-complish our goal, we have to diminish interaction among such modules, rendering them the least interwoven we can.The rest of the section contains postulates expressing this. We here only state the postulates, and defer explanationsand discussions to Sections 4–6.PC (Logical consistency): S , E a, X a, Ia (cid:16)|=(cid:2) ⊥.The theory of a given action should be logically consistent.PS (No implicit static laws):if S , E a, X a, Ia |=(cid:2) ϕ, then S |=CPL ϕ.If a classical formula can be inferred from the action theory, then it should be inferable from the set of static lawsalone. (Note that on the left we use the (cid:3)-based consequence, while on the right we use consequence in classicallogic: as both S and ϕ are classical, ϕ should be inferable from S in classical logic.)PI (No implicit inexecutability laws):if S , E a, X a, Ia |=(cid:2) ϕ → [a]⊥, then S , Ia |=PDL ϕ → [a]⊥.If an inexecutability law for an action a can be inferred from its action theory, then it should be inferable in PDLfrom the static laws and the inexecutability laws for a alone. Note that we used |=PDL instead of |=(cid:2) because wealso suppose that neither frame axioms nor indirect effects should be relevant to derive inexecutability laws. The sameremark holds for the postulate that follows:PX (No implicit executability laws):if S , E a, X a, Ia |=(cid:2) ϕ → (cid:11)a(cid:12)(cid:5), then S , X a |=PDL ϕ → (cid:11)a(cid:12)(cid:5).If an executability law for a can be inferred from its action theory, then it should already “be” in X a, in the sensethat it should also be inferable in PDL from the set of static and executability laws for a alone.Postulate PC is obvious, for we are interested in consistent theories. It can be shown that PX is a consequence ofPS (see Corollary 41).Thus, while PC is obvious and PX can be ensured by PS, things are less obvious for Postulates PS and PI: it turnsout that for all approaches in the literature they are easily violated by action theories that allow to express the fourkinds of laws. We therefore study each of these postulates in the subsequent sections by means of examples, givealgorithms to decide whether they are satisfied, and discuss about what to do in the case the answer is ‘no’.4. No implicit static lawsWhile executability laws increase expressive power, they might conflict with inexecutability laws. Consider, forexample, the following action theory:(cid:4)S1= {walking → alive},(cid:2)(cid:11)tease(cid:12)(cid:5)(cid:3),(cid:2)=I1X1==E1¬alive → [tease]⊥[tease]walking,loaded → [shoot]¬alive(cid:3)(cid:5),and the dependence relation:(cid:4)(cid:3)=(cid:11)shoot, ¬loaded(cid:12), (cid:11)shoot, ¬alive(cid:12),(cid:11)shoot, ¬walking(cid:12), (cid:11)tease, walking(cid:12)(cid:5).From this description we have the unintuitive inference X teaseimplicit static law because alive does not follow from S, I tease111 alone: (cid:11)S|=PDL alive: the turkey is immortal! This is an1, E tease1(cid:12) violates Postulate PS., X tease1, I tease1960A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984Implicit static laws are not a drawback of our underlying logical formalism. They also appear in Situation Calculus-based approaches and in causal laws theories. To witness,4 suppose in Lin’s framework we haveHolds(p1, s) → Caused(p2, true, s)andCaused(p2, false, s).Then from (2) we get¬Holds(p2, s)and then conclude¬Caused(p2, true, s).Finally, from (1) and (4) we get¬Holds(p1, s)(1)(2)(3)(4)which is an implicit static law.To see how implicit static laws show up in McCain and Turner’s causal laws approach [3], let the causal law ϕ ⇒ ψand T = {¬ψ}. Then ¬ϕ is an implicit static law in such a description.How can we find out whether an action theory for a with a dependence relation (cid:3) satisfies Postulate PS?Theorem 16. (cid:11)S , E a, X a, Ia(cid:12) and (cid:3) satisfy Postulate PS if and only if the big model for (cid:11)S , E a, X a, Ia(cid:12) and (cid:3) is amodel of (cid:11)S , E a, X a, Ia(cid:12) and (cid:3).Proof. Let M = (cid:11)W, R(cid:12) be the big model of (cid:11)S , E a, X a, Ia(cid:12) and (cid:3).(⇒): As M is a big model of (cid:11)S , E a, X a, Ia(cid:12) and (cid:3), we have |=M S ∧ E a ∧ Ia. It remains to show that |=M X a.w ϕi . Therefore, for all ϕj ∈ Fml such that S , E a, X a, Ia |=(cid:2)Let ϕi → (cid:11)a(cid:12)(cid:5) ∈ X a, and let w ∈ W be such that |=Mϕj → [a]⊥, we must have (cid:16)|=Mw ϕj , because S , E a, X a, Ia |=(cid:2) ¬(ϕi ∧ ϕj ), and as (cid:11)S , E a, X a, Ia(cid:12) and (cid:3) satisfyPostulate PS, S |=CPL ¬(ϕi ∧ ϕj ), and hence |=M ¬(ϕi ∧ ϕj ). Then, by the construction of M, there is some w(cid:14) ∈ Ww ϕi →such that |=M(cid:11)a(cid:12)(cid:5), and thus M is a model of (cid:11)S , E a, X a, Ia(cid:12) and (cid:3).w(cid:14) ψ , for all ϕ → [a]ψ such that S , E a, Ia |=(cid:2) ϕ → [a]ψ and |=Mw ϕ, and wRaw(cid:14). Hence, |=M(⇐): Suppose (cid:11)S , E a, X a, Ia(cid:12) and (cid:3) do not satisfy Postulate PS. Then there must be ϕ ∈ Fml such thatS , E a, X a, Ia |=(cid:2) ϕ and S (cid:16)|=CPL ϕ. This means that there is a valuation val of S that falsifies ϕ. As val ∈ W(because M contains all possible valuations of S ), M is not a model of (cid:11)S , E a, X a, Ia(cid:12) and (cid:3). (cid:2)We shall give an algorithm to find a finite characterization of all5 implicit static laws of a given action theory(cid:11)S , E a, X a, Ia(cid:12). The idea is as follows: for each executability law ϕ → (cid:11)a(cid:12)(cid:5) in the theory, construct from E a, Iaand (cid:3) a set of inexecutabilities {ϕ1 → [a]⊥, . . . , ϕn → [a]⊥} that potentially conflict with ϕ → (cid:11)a(cid:12)(cid:5). For each i,1 (cid:2) i (cid:2) n, if ϕ ∧ ϕi is satisfiable w.r.t. S , mark ¬(ϕ ∧ ϕi) as an implicit static law. Incrementally repeat this procedure(adding all the implicit ¬(ϕ ∧ ϕi) to S ) until no more implicit static law is obtained., X tease(cid:12) with (cid:3)For an example of the execution of the algorithm, consider the action theory (cid:11)S1and (cid:3) we try to buildas above. For the action tease, we have the executability (cid:11)tease(cid:12)(cid:5). Now, from E teasean inexecutability for tease. We take [tease]walking and compute then all indirect effects of tease w.r.t. S1. Fromwalking → alive, we get that alive is an indirect effect of tease, giving us [tease]alive. But (cid:11)tease, alive(cid:12) /∈ (cid:3), whichmeans the frame axiom ¬alive → [tease]¬alive holds. Together with [tease]alive, this gives us the inexecutability∪ {(cid:5), ¬alive} is satisfiable ((cid:5) is the antecedent of the executability (cid:11)tease(cid:12)(cid:5)), we get¬alive → [tease]⊥. As S1¬alive → ⊥, i.e., the implicit static law alive. For this example no other inexecutability for tease can be derived, sothe computation stops.1, E tease1, I tease1, I tease11Before presenting the pseudo-code of the algorithm we need some definitions.4 The examples are from [34].5 Actually what the algorithm does is to find an interpolant of all implicit static laws of the theory.A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984961Definition 17. Let ϕ ∈ Fml and χ a clause. χ is an implicate of ϕ if and only if ϕ |=CPL χ .In our running example, walking ∨ alive and ¬walking ∨ alive are implicates of the set of formulas {walking →alive, walking}.Definition 18. Let ϕ ∈ Fml and χ a clause. χ is a prime implicate of ϕ if and only if• χ is an implicate of ϕ, and• for every implicate χ (cid:14) of ϕ, χ (cid:14) |=CPL χ implies χ |=CPL χ (cid:14).The set of all prime implicates of a formula ϕ is denoted PI(ϕ).For example, the set of prime implicates of p1 is just {p1}, and that of p1 ∧ (¬p1 ∨ p2) ∧ (¬p1 ∨ p3 ∨ p4) is{p1, p2, p3 ∨ p4}. In our shooting domain, alive is a prime implicate of {walking → alive, walking}. For more onprime implicates, their properties and how to compute them see [35].Definition 19. Let ϕ, ψ ∈ Fml. Then NewCons(ψ, ϕ) = PI(ϕ ∧ ψ) \ PI(ϕ).The function NewCons(ψ, ϕ) computes the new consequences of ϕ w.r.t. ψ: the set of strongest clauses that followfrom ϕ ∧ ψ , but do not follow from ϕ alone (cf. e.g. [36]). It is computed by subtracting the prime implicates ofϕ from those of ϕ ∧ ψ. For example, NewCons((¬p1 ∨ p2) ∧ (¬p1 ∨ p3 ∨ p4), p1) = {p2, p3 ∨ p4}. And for ourscenario, NewCons(walking, walking → alive) = {alive, walking}.The algorithm below improves the one in [37] by integrating a solution to the frame problem (via the dependencerelation (cid:3)). For convenience, we define Ca = E a ∪ Ia as the set of all formulas expressing the direct consequencesof an action a, whether they are consistent or not.Algorithm 1 (Finding all implicit static laws induced by a).input: (cid:11)S , E a, X a, Ia(cid:12) and (cid:3)output: Simp∗ , the set of all implicit static laws of (cid:11)S , E a, X a, Ia(cid:12)Simp∗ := ∅Ca := E a ∪ IarepeatSimp := ∅for all ϕ → (cid:11)a(cid:12)(cid:5) ∈ X a do(cid:9):=for all ˆCa ⊆ ˆCa such that ˆCa (cid:16)= ∅ do{ϕi: ϕi → [a]ψi ∈ ˆCa}ϕ ˆCa{ψi: ϕi → [a]ψi ∈ ˆCa}ψ ˆCafor all χ ∈ NewCons(ϕ ˆCa , S) do:=(cid:9)Simp∗ := Simp∗ ∪ Simpuntil Simp = ∅if S ∪ Simp∗ ∪ {ϕ, ϕ ˆCa , ¬χ} (cid:16)|=CPL ⊥ and ∀(cid:4)i ∈ χ, a (cid:16)(cid:3) (cid:4)i thenSimp := Simp ∪ {¬(ϕ ∧ ϕ ˆCa∧ ¬χ)}This is the key algorithm of the paper. In each step of the algorithm, S ∪ Simp∗ is the updated set of static laws (theoriginal ones fed with the implicit laws caught up to that point). At the end, Simp∗ collects all the implicit static laws.Theorem 20. Algorithm 1 terminates.Proof. Let Ca = E a ∪ Ia. First, the set of candidates to be an implicit static law that might be due to a and that areexamined in the repeat-loop is(cid:2)¬(ϕ ∧ ϕ ˆCa(cid:3)∧ ¬χ): ˆCa ⊆ Ca, ϕ → (cid:11)a(cid:12)(cid:5) ∈ X a and χ ∈ χ ∈ NewCons(ϕ ˆCa , S).962A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984As E a, Ia and X a are finite, this set is finite.In each step, either the algorithm stops because Simp = ∅, or at least one of the candidates is put into Simp in theoutermost for-loop. (This one terminates, because X a, Ca and NewCons(.) are finite.) Such a candidate is not goingto be put into Simp in future steps of the algorithm, because once added to S ∪ Simp∗ , it will be in the set of lawsS ∪ Simp∗ of all subsequent executions of the outermost for-loop, falsifying its respective if-test for such a candidate.Hence the repeat-loop is bounded by the number of candidates, and therefore Algorithm 1 terminates. (cid:2)While terminating, our algorithm comes with considerable computational costs: first, the number of formulas ϕ ˆCaand ψ ˆCa is exponential in the size of Ca, and second, the computation of NewCons(ψ ˆCa , S ) might result in exponentialgrowth. While we might expect Ca to be reasonably small in practice (because E a and Ia are in general small), thesize of NewCons(ψ ˆCa , S ) is more difficult to control.Example 21. For (cid:11)S1, E tease1, X tease1, I tease1(cid:12), Algorithm 1 returns Simp∗ = {alive}.Theorem 22. Let Simp∗ be the output of Algorithm 1 on input (cid:11)S , E a, X a, Ia(cid:12) and (cid:3). Then (cid:11)S , E a, X a, Ia(cid:12) with (cid:3)satisfies Postulate PS if and only if Simp∗ = ∅.Proof. See Appendix A. (cid:2)Theorem 23. Let Simp∗ be the output of Algorithm 1 on input (cid:11)S , E a, X a, Ia(cid:12) and (cid:3). Then(1) (cid:11)S ∪ Simp∗, E a, X a, Ia(cid:12) with (cid:3) satisfies PS (has no implicit static law).(2) S , E a, X a, Ia |=(cid:2)(cid:9)Simp∗ .Proof. Item (1) is straightforward from the termination of Algorithm 1 and Theorem 22. Item (2) follows from thefact that by the if-test in Algorithm 1, the only formulas that are put in Simp∗ at each execution of the repeat-loop areexactly those that are implicit static laws of the current theory, and therefore of the original theory, too. (cid:2)Corollary 24. For all ϕ ∈ Fml, S , E a, X a, Ia |=(cid:2) ϕ if and only if S ∪ Simp∗ |=CPL ϕ.Proof. For the left-to-right direction, let S , E a, X a, Ia |=(cid:2) ϕ, for given ϕ ∈ Fml. Then S ∪ Simp∗, E a, X a, Ia |=(cid:2) ϕ,by monotonicity. By Theorem 23(1), (cid:11)S ∪ Simp∗ , E a, X a, Ia(cid:12) has no implicit static law, hence S ∪ Simp∗ |=CPL ϕ.The right-to-left direction is straightforward by Theorem 23(2). (cid:2)What shall we do once we have discovered an implicit static law?The existence of implicit static laws may indicate too strong executability laws: in Example 21, we wrongly as-sumed that tease is always executable. Thus one way of ‘repairing’ our theory would be to consider the weakerexecutability alive → (cid:11)tease(cid:12)(cid:5) instead of (cid:11)tease(cid:12)(cid:5) in X tease.On the other hand, implicit static laws may also indicate that the inexecutability laws are too strong:Example 25. Consider S = ∅, E shoot = {loaded → [shoot]¬alive}, X shoot = {hasGun → (cid:11)shoot(cid:12)(cid:5)} and I shoot ={[shoot]⊥}, with the dependence relation (cid:3)= {(cid:11)shoot, ¬alive(cid:12), (cid:11)shoot, ¬walking(cid:12). For this theory Algorithm 1 re-turns Simp∗ = {¬hasGun}.In Example 25 we discovered that the agent never has a gun. The problem here can be overcome by weakening[shoot]⊥ in I shoot with ¬hasGun → [shoot]⊥.66 Regarding Examples 21 and 25, one might argue that in practice such silly errors will never be made. Nevertheless, the examples here given arequite simplistic, and for applications of real interest, whose complexity will be much higher, we simply cannot rely on the designer’s knowledgeabout all side effects the stated formulas can have.A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984963We can go further on this reasoning and also argue that the problem may be due to a too strong set of effectlaws, or even to too strong frame axioms (i.e., a too weak dependence relation). To witness, for Example 21, ifwe replace the law [tease]walking by the weaker alive → [tease]walking, the resulting action theory would satisfyPostulate PS. In the same way, stating the (unintuitive) dependence tease (cid:3) alive (which means the frame axiom¬alive → [tease]¬alive is no longer valid) guarantees satisfaction of PS. (Note, however, that this solution becomesintuitive when alive is replaced by awake.)To finish, implicit static laws of course may also indicate that the static laws are too weak:Example 26. Suppose a computer representation of the line of integers, in which we can be at a strictly positivenumber, pos, or at a negative one or zero, ¬pos. Let maxInt and minInt, respectively, be the largest and the smallestrepresentable integer number. Action goLeft is the action of moving to the biggest integer strictly smaller than the oneat which we are. Consider the following action theory for this scenario (ati means we are at number i):(cid:2)S = {ati → pos: 0 < i (cid:2) maxInt} ∪ {ati → ¬pos: minInt (cid:2) i (cid:2) 0},E =(cid:2)ati → [goLeft]ati−1: i > minInt(cid:3)atminInt → [goLeft]underflow(cid:2)(cid:11)goLeft(cid:12)(cid:5)I = ∅(cid:3),X =∪(cid:3),with the dependence relation (minInt (cid:2) i (cid:2) maxInt):(cid:11)goLeft, ati(cid:12), (cid:11)goLeft, pos(cid:12),(cid:11)goLeft, ¬pos(cid:12), (cid:11)goLeft, underflow(cid:12)(cid:3)=(cid:4)(cid:5).Applying Algorithm 1 to this action theory gives us the implicit static law ¬(at1 ∧ at2), i.e., we cannot be at numbers1 and 2 at the same time.To summarize, in order to satisfy Postulate PS, an action theory should contain a complete set of static laws or,alternatively, should not contain too strong action laws.Remark 27. S ∪ Simp∗ in general is not intuitive.Whereas in the latter example the implicit static laws should be added to S , in the others the implicit static lawsare unintuitive and due to an (in)executability law that is too strong and should be weakened. Of course, how intuitivethe modified action theory will be depends mainly on the knowledge engineer’s choice.To sum it up, eliminating implicit static laws may require revision of S , E a or (cid:3), or completion of X a and Ia.Completing Ia is the topic we address in the next section.5. No implicit inexecutability lawsLet S2= S1, E2= E1 and Xsatisfy Postulate PS. From [tease]walking it follows with Sturkey, it is alive: S2, E teasewe have S22, E teaseS22, E tease2|=(cid:2) ¬alive → [tease]¬alive. From the above, it follows|=(cid:2) ¬alive → [tease]⊥,, X tease2, I tease22= I2= ∅, and let (cid:3) be that for (cid:11)S(cid:12) and (cid:3)(cid:12). Note that (cid:11)S2 that [tease]alive, i.e., in every situation, after teasing the|=PDL [tease]alive. Now as tease (cid:16)(cid:3) alive, the status of alive is not modified by tease, and1, I12, I22, X1, X1, E2, Ei.e., an inexecutability law stating that a dead turkey cannot be teased. But2, I teaseS2(cid:16)|=PDL ¬alive → [tease]⊥,hence Postulate PI is violated. Here the formula ¬alive → [tease]⊥ is an example of what we call an implicit inexe-cutability law.In the literature, such laws are also known as implicit qualifications [25], and it has been often supposed, in a moreor less tacit way, that it is a positive feature of frameworks to leave them implicit and provide mechanisms for inferringthem [2,38,39]. The other way round, one might argue as well that implicit qualifications indicate that the domain hasnot been described in an adequate manner: the form of inexecutability laws is simpler than that of effect laws, and964A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984it might be reasonably expected that it is easier to exhaustively describe them.7 Thus, all inexecutabilities of a givenaction should be explicitly stated, and this is what Postulate PI says.How can we check whether PI is violated? We can conceive an algorithm to find implicit inexecutability laws ofa given action a. The basic idea is as follows: for every combination of effect laws of the form (ϕ1 ∧ · · · ∧ ϕn) →[a](ψ1 ∧ · · · ∧ ψn), with each ϕi → [a]ψi ∈ E a, if ϕ1 ∧ · · · ∧ ϕn is consistent w.r.t. to S , ψ1 ∧ · · · ∧ ψn inconsistentw.r.t. S , and S , Ia (cid:16)|=PDL (ϕ1 ∧ · · · ∧ ϕn) → [a]⊥, then output (ϕ1 ∧ · · · ∧ ϕn) → [a]⊥ as an implicit inexecutabilitylaw. Our algorithm basically does this, and moreover takes into account dependence information.For an example of the execution of the algorithm, take (cid:11)S(cid:12) with (cid:3) as given above. From E teasewe get the law (cid:5) → [tease]walking, whose antecedent is consistent with S . As long as |=(cid:2) ¬alive → [tease]¬aliveand S ∪ {walking} |=CPL alive, and because S , I tease(cid:16)|=PDL ((cid:5) ∧ ¬alive) → [tease]⊥, we caught an implicit inexe-cutability. As there is no other combination of effect laws for tease, we end the simulation here.2, E tease2, X tease2, I tease222Below is the pseudo-code of the algorithm for that (the reason X a is not used in the computation will be madeclear in the sequel):imp , the set of implicit inexecutability laws for aAlgorithm 2 (Finding implicit inexecutability laws for a).input: (cid:11)S , E a, X a, Ia(cid:12) and (cid:3)output: IaIa:= ∅impfor all ˆE a ⊆ E a do(cid:9):=(cid:9){ϕi: ϕi → [a]ψi ∈ ˆE a}ϕ ˆE a{ψi: ϕi → [a]ψi ∈ ˆE a}ψ ˆE afor all χ ∈ NewCons(ψ ˆE a , S ) do:=if ∀(cid:4)i ∈ χ, a (cid:16)(cid:3) (cid:4)i and S , Ia (cid:16)|=PDL (ϕ ˆE a∧ ¬χ) → [a]⊥}∪ {(ϕ ˆE a:= IaIaimpimp∧ ¬χ) → [a]⊥ thenTheorem 28. Algorithm 2 terminates.Proof. Straightforward, as we have assumed S , E , I and (cid:3) finite, and NewCons(.) is finite (because S and ψ ˆE a arefinite). (cid:2)Example 29. Consider S[tease]⊥}.2, E tease2, X tease2, I tease2and (cid:3) as given above. Then Algorithm 2 returns I teaseimp= {¬alive →Nevertheless, applying Algorithm 2 is not enough to guarantee Postulate PI, as illustrated by the following exam-ple:Example 30 (Incompleteness of Algorithm 2 without PS). Let S = ∅, E a = {p1 → [a]p2}, X a = {(cid:11)a(cid:12)(cid:5)}, Ia = {p2 →[a]⊥}, and (cid:3)= ∅. Then we have S , E a, X a, Ia |=(cid:2) p1 → [a]⊥, but running Algorithm 2 on (cid:11)S , E a, X a, Ia(cid:12) we getS , Ia(cid:16)|=PDL p1 → [a]⊥.impExample 30 shows that the presence of implicit static laws (induced by executabilities) implies the existence ofimplicit inexecutabilities that are not caught by Algorithm 2. One way of getting rid of this is requiring (cid:11)S , E a, X a, Ia(cid:12)and (cid:3) to satisfy Postulate PS prior to running Algorithm 2. This gives us the following result:Theorem 31. Let Iasatisfies Postulate PS, then it satisfies Postulate PI if and only if Iaimp be the output of Algorithm 2 on input (cid:11)S , E a, X a, Ia(cid:12) and (cid:3). If (cid:11)S , E a, X a, Ia(cid:12) with (cid:3)imp= ∅.7 Note that this concerns the necessary conditions for executability, and thus it is not related to the qualification problem, which basically saysthat it is difficult to state all the sufficient conditions for executability.A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984965Proof. See Appendix B. (cid:2)With Algorithm 2, not only do we decide whether Postulate PI is satisfied, but we also get information on how to“repair” the action theory. The set of implicit inexecutabilities so obtained provides logical and metalogical informa-imp can be added to Ia; in thetion concerning the correction that must be carried out: in the first case, elements of Iasecond one, Iaimp helps in properly changing E a or (cid:3). For instance, to correct the action theory of our example, theknowledge engineer would have the following options:(1) Add the qualification ¬alive → [tease]⊥ to I tease(2) Add the (unintuitive) dependence (cid:11)tease, alive(cid:12) to (cid:3); or(3) Weaken the effect law [tease]walking to alive → [tease]walking in E tease; or22.It is easy to see that whatever she opts for, the resulting action theory for tease will satisfy Postulate PI (while stillsatisfying PS).Example 32 (Drinking coffee [12]). Suppose a situation in which we reason about the effects of drinking a cup ofcoffee:S = ∅,E drink =,X drink = Idrink = ∅(cid:4)sugar → [drink]happy,salt → [drink]¬happy(cid:5)and the dependence relation(cid:3)=(cid:3)(cid:2)(cid:11)drink, happy(cid:12), (cid:11)drink, ¬happy(cid:12).Observe that (cid:11)S , E drink, X drink, Idrink(cid:12) with (cid:3) satisfies PS. Then, running Algorithm 2 on this action theory will giveus Idrinkimp= {(sugar ∧ salt) → [drink]⊥}.Remark 33. Ia ∪ Iaimp is not always intuitive.Whereas in Example 29 we have got an inexecutability that could be safely added to I tease, in Example 32 we gotan inexecutability that is unintuitive (just the presence of sugar and salt in the coffee precludes drinking it). In thatcase, revision of other parts of the theory should be considered in order to make it intuitive. Anyway, the problempointed out in the depicted scenario just illustrates that intuition is beyond syntax. The scope of this work relies on thesyntactical level. Only the knowledge engineer can judge about how intuitive a formula is.2In what follows we revisit our postulates in order to strengthen them to the case where more than one action isunder concern and thus get results that can be applied to whole action theories.6. Generalizing the postulatesWe have seen the importance that satisfaction of Postulates PC, PS and PI may have in describing the action theoryof a particular action a. However, in applications of real interest more than one action is involved, and thus a naturalquestion that could be raised is “can we have similar metatheoretical results for multiple action theories”?In this section we generalize our set of postulates to action theories as a whole, i.e., considering all actions of adomain, and prove some interesting results that follow from that. As we are going to see, some of these results arestraightforward, while others must rely on some additional assumptions in order to hold.A generalization of Postulate PC is quite easy and has no need for justification:PC∗ (Logical consistency): S , E , X , I (cid:16)|=(cid:2) ⊥.The whole action theory should be logically consistent.Generalizing Postulate PS will give us the following:PS∗ (No implicit static laws):if S , E , X , I |=(cid:2) ϕ, then S |=CPL ϕ.966A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984If a classical formula can be inferred from the whole action theory, then it should be inferable from the set of staticlaws alone. We have the following results:Theorem 34. (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy PS∗ if and only if (cid:11)S , E a, X a, Ia(cid:12) and (cid:3) satisfies PS for all a ∈ Act.Proof. (⇒): Straightforward: Suppose that for some a ∈ Act (cid:11)S , E a, X a, Ia(cid:12) does not satisfy PS. Then there is ϕ ∈Fml such that S , E a, X a, Ia |=(cid:2) ϕ and S (cid:16)|=CPL ϕ. Of course S , E , X , I |=(cid:2) ϕ, by monotonicity, but still S (cid:16)|=CPL ϕ.Hence (cid:11)S , E , X , I (cid:12) does not satisfy PS∗.(⇐): Suppose (cid:11)S , E , X , I (cid:12) with (cid:3) does not satisfy PS∗. Then there is ϕ ∈ Fml such that S , E , X , I |=(cid:2) ϕ andS (cid:16)|=CPL ϕ. ϕ is equivalent to ϕ1 ∧ · · · ∧ ϕn, with ϕ1, . . . , ϕn ∈ Fml and such that there is at least one ϕi such thatS (cid:16)|=CPL ϕi (otherwise S |=CPL ϕ). Because the logic is independently axiomatized, there must be some a ∈ Act suchthat S , E a, X a, Ia |=(cid:2) ϕi . From this and S (cid:16)|=CPL ϕi it follows that (cid:11)S , E a, X a, Ia(cid:12) and with (cid:3) do not satisfy PS. (cid:2)Corollary 35. (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗ if and only if the big model for (cid:11)S , E , X , I (cid:12) and (cid:3) is amodel of (cid:11)S , E , X , I (cid:12).Proof. The proof follows from Theorems 16 and 34. (cid:2)Theorem 36. If (cid:11)S , E , X , I (cid:12) with (cid:3) satisfies PS∗, then (cid:11)S , E , X , I (cid:12) with (cid:3) satisfies PC∗ if and only if(cid:11)S , E a, X a, Ia(cid:12) and (cid:3) satisfy PC for all a ∈ Act.Proof. Let (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy PS∗.(⇒): Suppose that (cid:11)S , E a, X a, Ia(cid:12) with (cid:3) does not satisfy PC, for some a ∈ Act. Because (cid:11)S , E , X , I (cid:12) and (cid:3)satisfy PS∗, (cid:11)S , E a, X a, Ia(cid:12) and (cid:3) satisfy Postulate PS (Theorem 34), and then S |=CPL ⊥. From this it follows that(cid:11)S , E , X , I (cid:12) does not satisfy Postulate PC∗.(⇐): Suppose (cid:11)S , E , X , I (cid:12) and (cid:3) do not satisfy PC∗. Then S , E , X , I |=(cid:2) ⊥. Because (cid:11)S , E , X , I (cid:12) with (cid:3)satisfies Postulate PS∗, S |=CPL ⊥. Since Act (cid:16)= ∅, there is some a ∈ Act such that S , E a, X a, Ia |=(cid:2) ⊥. (cid:2)A more general form of Postulate PI can also be stated:PI∗ (No implicit inexecutability laws):if S , E , X , I |=(cid:2) ϕ → [a]⊥, then S , I |=PDL ϕ → [a]⊥.If an inexecutability law can be inferred from the whole action theory, then it should be inferable in PDL from thestatic and inexecutability laws alone.Note that having that (cid:11)S , E a, X a, Ia(cid:12) with (cid:3) satisfies PI for all a ∈ Act is not enough to (cid:11)S , E , X , I (cid:12) with (cid:3)satisfy PI∗ if there are implicit static laws. To witness, let S = E a1 = ∅, and X a1 = {(cid:11)a1(cid:12)(cid:5)}, Ia1 = {ϕ → [a1]⊥}.Let also E a2 = X a2 = Ia2 = ∅. Observe that both (cid:11)S , E a1 , X a1, Ia1 (cid:12) and (cid:11)S , E a2 , X a2, Ia2 (cid:12) with (cid:3) satisfy PI, butS , E , X , I |=(cid:2) ϕ → [a2]⊥ and S , I (cid:16)|=PDL ϕ → [a2]⊥.Nevertheless, under PS∗ the result follows:Theorem 37. Let (cid:11)S , E , X , I (cid:12) with (cid:3) satisfy PS∗. (cid:11)S , E , X , I (cid:12) with (cid:3) satisfies PI∗ if and only if (cid:11)S , E a, X a, Ia(cid:12)and (cid:3) satisfy PI for all a ∈ Act.Proof. See Appendix C. (cid:2)In the next section we make a step toward an attempt of amending our modularity criteria by investigating possibleextensions of our set of postulates.7. Can we ask for more?Can we augment our set of postulates to take into account other modules of action theories, or even other metathe-oretical issues in reasoning about actions? That is the topic we discuss in what follows.A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–9849677.1. Postulates about action effectsIt seems to be in line with our postulates to require action theories not to allow for the deduction of new effect laws:if an effect law can be inferred from an action theory (and no inexecutability for the same action in the same contextcan be derived), then it should be inferable from the set of static and effect laws alone. This means we should have:PE (No implicit effect laws):if S , E , X , I |=(cid:2) ϕ → [a]ψ and S , E , X , I (cid:16)|=(cid:2) ϕ → [a]⊥,then S , E |=(cid:2) ϕ → [a]ψ.But consider the following intuitively correct action theory:(cid:5)(cid:4)S3X3=E3= ∅,(cid:2)hasGun → (cid:11)shoot(cid:12)(cid:5)=(cid:3)loaded → [shoot]¬alive,(¬loaded ∧ alive) → [shoot]alive,(cid:2)(cid:3),=I3¬hasGun → [shoot]⊥together with the dependence shoot (cid:3) ¬alive. It satisfies Postulates PS∗ and PI∗, but does not satisfy PE. Indeed:S3, E3, X3, I3|=(cid:2) ¬hasGun ∨ loaded → [shoot]¬alive3, ES3, X3, I3(cid:16)|=(cid:2) ¬hasGun ∨ loaded → [shoot]⊥,andbutS3, E3(cid:16)|=(cid:2) ¬hasGun ∨ loaded → [shoot]¬alive.So, Postulate PE would not help us to deliver the goods.Another possibility of improving our modularity criteria could be:P⊥ (No unattainable effects):if ϕ → [a]ψ ∈ E , then S , E , X , I (cid:16)|=(cid:2) ϕ → [a]⊥.This expresses that if we have explicitly stated an effect law for a in some context, then there should be no in-executability law for the same action in the same context. It is straightforward to design an algorithm which checkswhether this postulate is satisfied. We do not investigate this further here, but just observe that the slightly strongerversion below leads to unintuitive consequences:P⊥’ (No unattainable effects—strong version):if S , E |=(cid:2) ϕ → [a]ψ, then S , E , X , I (cid:16)|=(cid:2) ϕ → [a]⊥.Indeed, for the above action theory we haveE3|=(cid:2) (¬hasGun ∧ loaded) → [shoot]¬alive,butS3, E3, X3, I3|=(cid:2) (¬hasGun ∧ loaded) → [shoot]⊥.This is certainly too strong. Our example also illustrates that it is sometimes natural to have ‘redundancies’ or ‘over-laps’ between E and I . Indeed, as we have pointed out, inexecutability laws are a particular kind of effect laws, andthe distinction here made is conventional. The decision of considering them as strictly different entities or not dependsmainly on the context. At a representational level we prefer to keep them separated, while in Algorithm 1 we havemixed them together in order to compute the consequences of an action.In what follows we address the problem of completing the set of executability laws of an action theory.968A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–9847.2. Maximizing executabilityAs we have seen, implicit static laws only show up when there are executability laws. So, a question that naturallyraises is “which executability laws can be consistently added to a given action theory?”.A hypothesis usually made in the literature is that of maximization of executabilities: in the absence of a proof thatan action is inexecutable in a given context, assume its executability for that context. Such a hypothesis is captured bythe following postulate that we investigate in this section:PX+ (Maximal executability laws):if S , E a, X a, Ia (cid:16)|=(cid:2) ϕ → [a]⊥, then S , X a |=PDL ϕ → (cid:11)a(cid:12)(cid:5).Such a postulate expresses that if in context ϕ no inexecutability for a can be inferred, then the respective exe-cutability should follow in PDL from the executability and static laws.Postulate PX+ generally holds in non-monotonic frameworks, and can be enforced in monotonic approaches suchas ours by maximizing X a. We nevertheless would like to point out that maximizing executability is not alwaysintuitive. To witness, suppose we know that if we have the ignition key, the tank is full, . . . , and the battery tensionis beyond 10 V, then the car (necessarily) will start. Suppose we also know that if the tension is below 8 V, thenthe car will not start. What should we conclude in situations where we know that the tension is 9 V? Maximizingexecutabilities makes us infer that it will start, but such reasoning is not what we want if we would like to be sure thatall possible executions lead to the goal.8. Exploiting modularityIn this section we present other properties related to consistency and modularity of action theories, emphasizingthe main results that we obtain when Postulate PS∗ is satisfied.Theorem 38. If (cid:11)S , E , X , I (cid:12) with (cid:3) satisfies PS∗, then S , E , X , I |=(cid:2) ⊥ if and only if S |=CPL ⊥.This theorem says that if there are no implicit static laws, then consistency of an action theory can be checked byjust checking consistency of S .Theorem 39. If (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗, then S , E , X , I |=(cid:2) ϕ → [a]ψ if and only ifS , E a, Ia |=(cid:2) ϕ → [a]ψ.Proof. See Appendix D. (cid:2)This means that under PS∗ we have modularity inside E , too: when deducing the effects of a we need not considerthe action laws for other actions. Versions for executability and inexecutability can be stated as well:Theorem 40. If (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗, then S , E , X , I |=(cid:2) ϕ → (cid:11)a(cid:12)(cid:5) if and only if S , X a |=(cid:2)ϕ → (cid:11)a(cid:12)(cid:5).Proof. See Appendix E. (cid:2)Corollary 41. PX is a consequence of PS.Proof. Straightforward. (cid:2)Theorem 42. If (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulates PS∗ and PI∗, then S , E , X , I |=(cid:2) ϕ → [a]⊥ if and only ifS , Ia |=PDL ϕ → [a]⊥.A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984969Proof. (⇒): If S , E , X , I |=(cid:2) ϕ → [a]⊥, then from PS∗ and Theorem 39 we have S , E a, Ia |=(cid:2) ϕ → [a]⊥. Fromthis and PI∗ we get S , Ia |=PDL ϕ → [a]⊥.(⇐): Suppose S , E , X , I (cid:16)|=(cid:2) ϕ → [a]⊥. Then there is a (cid:3)-model M such that |=M S ∧ E ∧ X ∧ I and (cid:16)|=Mϕ → [a]⊥. Then, given a, we have |=M S ∧ E a ∧ X a ∧ Ia, and then |=M S ∧ Ia. Moreover, by definition, M is aPDL-model. Hence S , Ia (cid:16)|=PDL ϕ → [a]⊥. (cid:2)In Theorems 40 and 42, modularity guarantees moreover that no dependence is needed to derive, respectively,executabilities and inexecutabilities.(cid:10)(cid:10)(cid:10)Let E a1,...,an =Iai . Under Postulate PS∗, deduc-tion of an effect of a sequence of actions a1; . . . ; an (prediction) needs neither the effect and inexecutability laws foractions other than a1, . . . , an, nor the executability laws of the domain:X ai , and Ia1,...,an =E ai , X a1,...,an =1(cid:2)i(cid:2)n1(cid:2)i(cid:2)n1(cid:2)i(cid:2)nTheorem 43. If (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗, then S , E , X , I |=(cid:2) ϕ → [a1; . . . ; an]ψ if and only ifS , E a1,...,an, Ia1,...,an |=(cid:2) ϕ → [a1; . . . ; an]ψ.Proof. See Appendix F. (cid:2)The same result holds for testing inexecutability of a sequence of actions:Corollary 44. If (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗, then S , E , X , I |=(cid:2) ϕ → [a1; . . . ; an]⊥ if and only ifS , E a1,...,an, Ia1,...,an |=(cid:2) ϕ → [a1; . . . ; an]⊥.Proof. Straightforward, as a special case of Theorem 43. (cid:2)The next theorem shows that our notion of modularity is also fruitful in plan validation:Theorem 45. Let (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗. Then we have S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)ψ if andonly if S , E a1,...,an , X a1,...,an , Ia1,...,an |=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)ψ.Proof. See Appendix G.And as a consequence, we also optimize testing executability of a plan:Corollary 46. Let (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗. Then we have S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)(cid:5) ifand only if S , E a1,...,an , X a1,...,an , Ia1,...,an |=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)(cid:5).Proof. Straightforward, as a special case of Theorem 45.Theorems 43 and 45 together with Corollaries 44 and 46 suggest that we can simulate modularization by sub-domains [40]: If (cid:11){a1, . . . , an}, Prop(cid:14)(cid:12) is a sub-domain for some Prop(cid:14) ⊆ Prop, then (cid:11)S , E a1,...,an , X a1,...,an, Ia1,...,an (cid:12)with (cid:3) corresponds to the module for (cid:11){a1, . . . , an}, Prop(cid:14)(cid:12) in Lifschitz and Ren’s sense (see the next section).9. Related workPirri and Reiter have investigated the metatheory of the Situation Calculus [41]. In a spirit similar to ours, they useexecutability laws and effect laws. Contrarily to us, their executability laws are equivalences and are thus at the sametime inexecutability laws. As they restrict themselves to domains without ramifications, there are no static laws, i.e.,S = ∅. For this setting they give a syntactical condition on effect laws guaranteeing that they do not interact with theexecutability laws in the sense that they do not entail implicit static laws. Basically, the condition says that when thereare effect laws ϕ1 → [a]ψ and ϕ2 → [a]¬ψ, then ϕ1 and ϕ2 are inconsistent (which essentially amounts to having intheir theories a kind of “implicit static law schema” of the form ¬(ϕ1 ∧ ϕ2)).970A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984This then allows them to show that such theories are always consistent. Moreover they thus simplify the entailmentproblem for this calculus, and show for several problems such as consistency or regression that only some of themodules of an action theory are necessary.Amir [42] focuses on design and maintainability of action descriptions applying many of the concepts of the object-oriented paradigm in the Situation Calculus. In that work, guidelines for a partitioned representation of a given theoryare presented, with which the inference task can also be optimized, as it is restricted to the part of the theory that isreally relevant to a given query. This is observed specially when different agents are involved: the design of an agent’stheory can be done with no regard to others’, and after the integration of multiple agents, queries about an agent’sbeliefs do not take into account the belief state of other agents.In the referred work, executabilities are as in [41] and the same condition on effect laws is assumed, which syn-tactically precludes the existence of implicit static laws. The frame problem is solved using Reiter’s solution [32] andthen is also restricted to domains without static laws. Ramifications are dealt with by compiling them away à la Reiterand Lin [43] based on the method given in [44], which takes into account only some restricted state constraints.In spite of using many of the object-oriented paradigm tools and techniques, no mention is made to the concepts ofcohesion and coupling [45,46], which are closely related to modularity [12]. In the approach presented in [42], evenif modules are highly cohesive, they are not necessarily lowly coupled, due to the dependence between objects in thereasoning phase. We do not investigate this further here, but conjecture that this could be done there by, during thereasoning process defined for that approach, avoiding passing to a module a formula of a type different from those itcontains.The present work generalizes and extends Pirri and Reiter’s result to the case where S (cid:16)= ∅ and both these workswhere the syntactical restriction on effect laws is not made. This gives us more expressive power, as we can reasonabout inexecutabilities, and a better modularity in the sense that we do not combine formulas that are conceptuallydifferent (viz. executabilities and inexecutabilities). It also constitutes a better approach for domains with ramificationsas we do not impose any restriction on the domain laws we can deal with.Zhang et al. [47] have also proposed an assessment of what a good action theory should look like. They developthe ideas in the framework of EPDL [6], an extended version of PDL which allows for propositions as modalitiesto represent a causal connection between literals. We do not present the details of that, but concentrate on the mainmeta-theoretical results.Zhang et al. propose a normal form for describing action theories,8 and investigate three levels of consistency.Roughly speaking, a set of laws T is uniformly consistent if it is globally consistent (i.e., T (cid:16)|=EPDL⊥); a formula Φ isT -consistent if T (cid:16)|=EPDL¬Φ, for T a uniformly consistent theory; T is universally consistent if (in our terms) everylogically possible world is accessible.Furthermore, two assumptions are made to preclude the existence of implicit qualifications. Satisfaction of suchassumptions means the theory under consideration is safe, i.e., it is uniformly consistent. Such a normal form justifiesthe two assumptions made and on which their notion of good theories relies.Given this, they propose algorithms to test the different versions of consistency for a theory T that is in normalform. This test essentially amounts to checking whether T is safe, i.e., whether T |=EPDL(cid:11)a(cid:12)(cid:5), for every action a.Success of this check should mean that the theory under analysis satisfies the consistency requirements.Although they are concerned with the same kind of problems that have been discussed in this work, they take anoverall view of the subject, in the sense that all problems are dealt with together. This means that in their approach nospecial attention (in our sense) is given to the different components of the theory, and then every time something iswrong with it this is taken as a global problem inherent to the theory as a whole. Whereas such a “systemic” view ofaction theories is not necessarily a drawback (we have just seen the strong interaction that exists between the differentsets of laws composing an action theory), being modular in our sense allows us to better identify the “problematic”laws and take care of them. Moreover, the advantage of allowing to find the set of laws which must be modified inorder to achieve the desired consistency is made evident by the algorithms we have proposed (while their results onlyallow to decide whether a given theory satisfies some consistency requirement).8 But not as expressive as one might think: For instance, in modeling the nondeterministic action of dropping a coin on a chessboard, we arenot able to state [drop](black ∨ white). Instead, we should write something like [dropblack]black, [dropwhite]white, [dropblack,white]black and[dropblack,white]white, where dropblack is the action of dropping the coin on a black square (analogously for the others) and drop = dropblack ∪dropwhite ∪ dropblack,white, with “∪” the nondeterministic composition of actions.A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984971Lang et al. [48] address consistency of action theories in a version of the causal laws approach [3], focusing on thecomputational aspects.To solve the frame problem, they suppose an abstract notion of completion. Given a theory T a containing logicalinformation about a’s direct effects as well as the indirect effects that may follow (expressed in the form of causallaws), the completion of T a, roughly speaking, is the original theory T a amended of some axioms stating the per-sistence of all non-affected (directly nor indirectly) literals. (Note that such a notion of completion is close to theunderlying semantics of the dependence relation used throughout the present work, which essentially amounts to theexplanation closure assumption [26].)Their EXECUTABILITY problem is to check whether action a is executable in all possible initial states (Zhang etal.’s safety property). This amounts to testing whether every possible state w has a successor w(cid:14) reachable by a suchthat w and w(cid:14) both satisfy the completion of T a. For the Walking Turkey Scenario, the formalization of action teasewith causal laws is given by:(cid:4)(cid:5)T tease =(cid:5) tease⇒ walking,¬alive ⇒ ¬walkingwhere the first formula is a conditional effect law for tease, and the latter a causal law in McCain and Turner’s sense.We will not dive in the technical details, and just note that the executability check will return “no” for this example astease cannot be executed in a state satisfying ¬alive.In the mentioned work, the authors are more concerned with the complexity analysis of the problem of doing sucha consistency test and no algorithm for performing it is given, however. Despite the fact their motivation is the sameas ours, again what is presented is a kind of “yes-no tool” which can help in doing a meta-theoretical analysis of agiven action theory, and many of the comments concerning Zhang et al.’s approach could be repeated here.Another criticism that could be made about both these approaches concerns the assumption of full executabilitythey rely on. We find it too strong to require all actions to be always executable (cf. Section 7), and to reject as bad anaction theory admitting situations where some action cannot be executed at all. As an example, consider a very simpleaction theory (cid:11)S , E , X , I (cid:12), where S = {walking → alive}, E = {[tease]walking}, X = {(cid:11)tease(cid:12)(cid:5)}, and I = ∅, with adependence relation given by (cid:3)= {(cid:11)tease, walking(cid:12)}. Observe that, with our approach, it suffices to derive the implicitinexecutability law ¬alive → [tease]⊥, change I , and the system will properly run in situations where ¬alive is thecase.On the other hand, if we consider the equivalent representation of such an action theory in the approach of Lang etal., after computing the completion of T tease, if we test its executability, we will get the answer “no”, the reason beingthat tease is not executable in the possible state where ¬alive holds. Such an answer is correct, but note that with onlythis as guideline we have no idea about where a possible modification in the action theory should be carried out inorder to achieve full executability for tease. The same observation holds for Zhang et al.’s proposal.Just to see how things can be even worse, let the same action theory as above, but with X = {alive → (cid:11)tease(cid:12)(cid:5)},obtained by its correction with the algorithms we proposed. Observe that the resulting theory satisfies all our postu-lates. It is not hard to see, however, that the representation of such an action theory in the above frameworks, whenchecked by their respective consistency tests, is still considered to have a problem.This problem arises because Lang et al.’s proposal do not allow for executability laws, thus one cannot makethe distinction between X = {(cid:11)tease(cid:12)(cid:5)}, X = {alive → (cid:11)tease(cid:12)(cid:5)} and X = ∅. By their turn, Zhang et al. allowsfor specifying executabilities, however their consistency definitions do not distinguish the cases alive → (cid:11)tease(cid:12)(cid:5)and (cid:11)tease(cid:12)(cid:5).A concept similar to that of implicit static laws was firstly addressed, as far as we are concerned, in the realm ofregulation consistency with deontic logic [49]. Indeed, the notions of regulation consistency given in the mentionedwork and that of modularity presented in [37] and refined here can be proved to be equivalent. The main differencebetween the mentioned work and the approach in [37] relies on the fact that in [49] some syntactical restrictions onthe formulas have to be made in order to make the algorithm to work.Lifschitz and Ren [40] propose an action description language derived from C+ [50] in which domain descriptionscan also be decomposed in modules. Contrarily to our setting, in theirs a module is not a set of formulas for givenaction a, but rather a description of a subsystem of the theory, i.e., each module describes a set of interrelated fluentsand actions. As an example, a module describing Lin’s suitcase [2] should contain all causal laws in the sense ofC+ that are relevant to the scenario. Actions or fluents having nothing to do, neither directly nor indirectly, with972A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984the suitcase should be described in different modules. This feature makes such a decomposition somewhat domain-dependent, while here we have proposed a type-oriented modularization of the formulas, which does not depend onthe domain.In the referred work, modules can be defined in order to specialize other modules. This is done by making the newmodule to inherit and then specialize other modules’ components. This is an important feature when elaborations areinvolved. In the suitcase example, adding a new action relevant to the suitcase description can be achieved by defininga new module inheriting all properties of the old one and containing the causal laws needed for the new action. Suchideas are interesting from the standpoint of software and knowledge engineer: reusability is an intrinsic property ofthe framework, and easy scalability promotes elaboration tolerance.Consistency of a given theory and how to prevent conflicts between modules (independent or inherited) however isnot addressed.In this work we have illustrated by some examples what we can do in order to make a theory intuitive. This involvestheory modification. Action theory change has been addressed in the recent literature on revision and update [51–53].In [54] we have investigated this issue and shown the importance that modularity has in such a task.10. ConclusionOur contribution is twofold: general, as we presented postulates that apply to all reasoning about actions for-malisms; and specific, as we proposed algorithms for a dependence-based solution to the frame problem.We have defined here the concept of modularity of an action theory and pointed out some of the problems thatarise if it is not satisfied. In particular we have argued that the non-dynamic part of action theories could influence butshould not be influenced by the dynamic one.9We have put forward some postulates, and in particular tried to demonstrate that when there are implicit staticand inexecutability laws then one has slipped up in designing the action theory in question. As shown, a possiblesolution comes into its own with Algorithms 1 and 2, which can give us some guidelines in correcting an actiontheory if needed. By means of examples we have seen that there are several alternatives of correction, and choosingthe right module to be modified as well as providing the intuitive information that must be supplied is up to theknowledge engineer.Given the difficulty of exhaustively enumerating all the preconditions under which a given action is executable(and also those under which such an action cannot be executed), it is reasonable to expect that there is always going tobe some executability precondition ϕ1 and some inexecutability precondition ϕ2 that together lead to a contradiction,forcing, thus, an implicit static law ¬(ϕ1 ∧ ϕ2). This is the reason we propose to state some information about bothexecutabilities and inexecutabilities, and then run the algorithms in order to improve the description.It could be argued that unintuitive consequences in action theories are mainly due to badly written axioms and notto the lack of modularity. True enough, but what we have presented here is the case that making a domain descriptionmodular gives us a tool to detect at least some of such problems and correct it. (But note that we do not claim tocorrect badly written axioms automatically and once for all.) Besides this, having separate entities in the ontologyand controlling their interaction help us to localize where the problems are, which can be crucial for real worldapplications.In this work we have illustrated by some examples what we can do in order to make a theory intuitive. This involvestheory modification. In [31] we have presented a general method for changing a domain description given a formulawe want to contract. Their we have defined a semantics for theory contraction and also presented its syntactical coun-terpart through contraction operators. Soundness and completeness of such operators with respect to the semanticshave been established. In that work we have also shown that modularity is a sufficient condition for contraction to besuccessful. This gives further evidence that the notion of modularity is fruitful.Our postulates can be formulated in any reasoning about actions framework, but the algorithms require a decidablelogic (in particular Algorithm 2). PDL is one candidate for that, as we have seen along the paper. For first-order-basedframeworks the consistency checks of Algorithms 1 and 2 are undecidable. We can get rid of this by assuming thatthere is no function symbol in the language. In this way, the result of NewCons(.) is finite and the algorithm terminates.9 It might be objected that it is only by doing experiments that one learns the static laws that govern the universe. But note that this involveslearning, whereas here—as always done in the reasoning about actions field—the static laws are known once forever, and do not evolve.A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984973Hence another candidate for our ideas would have been the Situation Calculus fragment with only propositionalfluents.The present paper is also a step toward a solution to the problem of indirect dependences: indeed, if the implicitdependence shoot (cid:3) ¬walking is not in (cid:3), then after running Algorithm 2 we get an indirect inexecutability (loaded∧walking) → [shoot]⊥, i.e., shoot cannot be executed if loaded ∧ walking holds. Such an unintuitive inexecutability isnot in I and thus indicates the missing indirect dependence.The general case is nevertheless more complex, and it seems that such indirect dependences cannot be computedautomatically in the case of indeterminate effects (cf. the example in [23]). We are currently investigating this issue.The first work on formalizing modularity in logical systems in general is due to Garson [55]. Modularity of the-ories in reasoning about actions was originally defined in [15]. Modularization of ontologies in description logics isaddressed in [56]. A different viewpoint of the work we presented here can be found in [12], where modularity ofaction theories is assessed from a software engineering perspective. A modularity-based approach for narrative rea-soning about actions is given in [57]. In [13] we show that our modularity notion can also be extended to ontologiesin the description logic ALC.Our postulates do not take into account causality statements linking propositions such as those defined in[2,3,39,58]. This could be a topic for further investigation.AcknowledgementsThe authors are grateful to the anonymous referees for useful comments on an earlier version of this paper.Ivan Varzinczak has been supported by a fellowship from the government of the FEDERATIVE REPUBLIC OFBRAZIL. Grant: CAPES BEX 1389/01-7.Appendix A. Proof of Theorem 22Let Simp∗ be the output of Algorithm 1 on input (cid:11)S , E a, X a, Ia(cid:12) and (cid:3). Then (cid:11)S , E a, X a, Ia(cid:12) with (cid:3) satisfiesPostulate PS if and only if Simp∗ = ∅.We recall that |=CPL is logical consequence in classical propositional logic, and PI(A) is the set of prime implicatesof a set A of classical formulas.Before giving the proof of the theorems, we recall some properties of prime implicates [35,59] and of the functionNewCons(.) [36] (see Section 4). Let ϕ ∈ Fml, A ⊆ Fml finite (identified with the conjunction of its formulas), and χbe a clause. Then(cid:9)PI(ϕ) [35, Corollary 3.2].(1) |=CPL ϕ ↔(2) PI(A) ∪ NewCons(ϕ, A) = PI(A ∧ ϕ) (by definition of NewCons(,)).(3) |=CPL (A ∧ ϕ) ↔ (A ∧ NewCons(ϕ, A)) (from (1) and (2))(4) If PI(ϕ) |=CPL χ , then there is χ (cid:14) ∈ PI(ϕ) such that χ (cid:14) |=CPL χ [35, Proposition 3.4].Let (cid:11)S , E a, X a, Ia(cid:12) with (cid:3) be an action theory for a, and let ϕ → (cid:11)a(cid:12)(cid:5) ∈ X a, Ca = E a ∪ Ia, and ˆCa ⊆ Ca. Wedefine:=ϕ ˆCaψ ˆCa=(cid:11)(cid:2)(cid:11)(cid:2)(cid:3)ϕi: ϕi → [a]ψi ∈ ˆCaψi: ϕi → [a]ψi ∈ ˆCa,(cid:3).Moreover, let indepa= {¬(cid:4): a (cid:16)(cid:3) (cid:4)}.Lemma 47. Let indep(cid:14)a⊆ indepa. S ∪ {ψ ˆCa} ∪ indep(cid:14)a|=CPL ⊥ if and only if S ∪ NewCons(ψ ˆCa , S ) ∪ indep(cid:14)a|=CPL ⊥.Proof.S ∪ {ψ ˆCa} ∪ indep(cid:14)a|=CPL ⊥974A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984if and only if(cid:6)S ∪ {ψ ˆCa(cid:7)}∪ indep(cid:14)a|=CPL ⊥ (by property (1))PIif and only if(cid:7)(cid:6)S ∪ NewCons(ψ ˆCa , S )PI∪ indep(cid:14)a|=CPL ⊥ (by property (2))if and only ifS ∪ NewCons(ψ ˆCa , S ) ∪ indep(cid:14)a|=CPL ⊥ (by property (1)).(cid:2)Lemma 48. Let indep(cid:14)asuch that S ∪ {χ} ∪ indep(cid:14)a|=CPL ⊥.⊆ indepa. If S ∪ NewCons(ψ ˆCa , S ) ∪ indep(cid:14)a|=CPL ⊥, then there exists χ ∈ NewCons(ψ ˆCa , S )Proof.S ∪ NewCons(ψ ˆCa , S ) ∪ indep(cid:14)a|=CPL ⊥if and only ifPI(S ) ∪ NewCons(ψ ˆCa , S ) ∪ indep(cid:14)a|=CPL ⊥ (by property (1))if and only if(cid:6)S ∪ {ψ ˆCa(cid:7)}∪ indep(cid:14)a|=CPL ⊥ (by property (2))PIif and only if(cid:6)S ∪ {ψ ˆCa(cid:7)}PI|=CPL ¬(cid:11){¬(cid:4)i: ¬(cid:4)i ∈ indep(cid:14)a}if and only if(cid:6)S ∪ {ψ ˆCa(cid:7)}PI|=CPL(cid:12){(cid:4)i: ¬(cid:4)i ∈ indep(cid:14)a}if and only if there exists χ ∈ PI(S ∪ {ψ ˆCa}) such thatχ |=CPL(cid:12){(cid:4)i: ¬(cid:4)i ∈ indep(cid:14)a}(by property (4))if and only if{χ} ∪ indep(cid:14)a|=CPL ⊥if and only ifS ∪ {χ} ∪ indep(cid:14)a|=CPL ⊥.(cid:2)Lemma 49. Let indep(cid:14)a⊥, then there exists χ ∈ NewCons(ψ ˆCa , S ) such that S ∪ {χ} ∪ indep(cid:14)⊆ indepa. If we have S ∪ {ϕ, ϕ ˆCa} ∪ indep(cid:14)aa|=CPL ⊥.(cid:16)|=CPL ⊥ and S ∪ NewCons(ψ ˆCa , S ) ∪ indep(cid:14)a|=CPLProof. By Lemma 48 and classical logic. (cid:2)⊆ indepa. If we have S ∪ {ϕ, ϕ ˆCa} ∪ indep(cid:14)a|=CPL ⊥, then there exists χ ∈ NewCons(ψ ˆCa , S ) such that both S ∪ {ϕ, ϕ ˆCa(cid:16)|=CPL ⊥ and S ∪ NewCons(ψ ˆCa , S ) ∪} ∪ indep(cid:14)(cid:16)|=CPL ⊥ andaLemma 50. Let indep(cid:14)aindep(cid:14)aS ∪ {χ} ∪ indep(cid:14)a|=CPL ⊥.Proof. Trivially, by Lemma 49. (cid:2)A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984975Lemma 51. Let indep(cid:14)aindep(cid:14)|=CPL ⊥, then both S ∪ {ϕ, ϕ ˆCaa(cid:4)i} |=CPL ⊥.⊆ indepa. If χ ∈ NewCons(ψ ˆCa , S ) is such that S ∪ {ϕ, ϕ ˆCa(cid:16)|=CPL ⊥ and S ∪ {χ} ∪} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} (cid:16)|=CPL ⊥ and S ∪ {χ} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3)} ∪ indep(cid:14)aProof. Let S ∪ {ϕ, ϕ ˆCa} ∪ indep(cid:14)a(cid:16)|=CPL ⊥ and χ ∈ NewCons(ψ ˆCa , S ) be such that S ∪ {χ} ∪ indep(cid:14)a|=CPL ⊥.If χ = ⊥, the result is trivial. Otherwise, we have the following cases:• If atm(χ) (cid:16)⊂ atm(indep(cid:14)• If atm(χ) = atm(indep(cid:14)• Let atm(χ) ⊂ atm(indep(cid:14)S ∪ {ϕ, ϕ ˆCa} ∪ indep(cid:14)aa), then the premise is false (and the lemma trivially holds).a), the lemma holds.a). Then, from(cid:16)|=CPL ⊥ (the hypothesis)it followsS ∪ {ϕ, ϕ ˆCa} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} (cid:16)|=CPL ⊥.FromS ∪ {χ} ∪ indep(cid:14)a|=CPL ⊥ (hypothesis)and becauseS ∪ indep(cid:14)a(cid:16)|=CPL ⊥,it followsS ∪ {χ} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} |=CPL ⊥.(cid:2)Lemma 52. If χ ∈ NewCons(ψ ˆCa , S ) is such that both S ∪ {ϕ, ϕ ˆCa{χ} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} |=CPL ⊥, then S ∪ {ϕ, ϕ ˆCa , ¬χ} (cid:16)|=CPL ⊥ and for all (cid:4)i ∈ χ , a (cid:16)(cid:3) (cid:4)i .} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} (cid:16)|=CPL ⊥ and S ∪Proof. FromS ∪ {ϕ, ϕ ˆCa} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} (cid:16)|=CPL ⊥we concludeS ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} (cid:16)|=CPL ⊥.From this and the hypothesisS ∪ {χ} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} |=CPL ⊥,it followsS ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} |=CPL ¬χ.If S |=CPL ¬χ , then S ∪ {ψ ˆCa} |=CPL ¬χ , and because χ ∈ NewCons(ψ ˆCa , S ), we have χ |=CPL ¬χ , a contradic-tion. Hence S ∪ {χ} (cid:16)|=CPL ⊥.Suppose now there is a literal (cid:4) ∈ χ such that ¬(cid:4) /∈ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i}. Then, the propositional valuation inwhich χ(cid:4)←true satisfiesS ∪ {χ} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i},and thenS ∪ {χ} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} (cid:16)|=CPL ⊥.Hence there cannot be such a literal, and then for all (cid:4)i ∈ χ , a (cid:16)(cid:3) (cid:4)i .976A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984Now, from a (cid:16)(cid:3) (cid:4)i for all (cid:4)i ∈ χ , we have |=CPL(cid:9){¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} ↔ ¬χ . From this and the hypothesisS ∪ {ϕ, ϕ ˆCa} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} (cid:16)|=CPL ⊥it follows S ∪ {ϕ, ϕ ˆCa , ¬χ} (cid:16)|=CPL ⊥. (cid:2)Proof of Theorem 22. We are about to prove that (cid:11)S , E a, X a, Ia(cid:12) with (cid:3) satisfies Postulate PS if and only ifSimp∗ = ∅.(⇒): Suppose Simp∗ (cid:16)= ∅. Then at the first step of the algorithm there has been some ϕ → (cid:11)a(cid:12)(cid:5) ∈ X a and some∧ˆCa ⊆ Ca such that for some χ ∈ NewCons(ψ ˆCa , S ), S , E a, X a, Ia |=(cid:2) ¬(ϕ ∧ ϕ ˆCa¬χ). Hence (cid:11)S , E a, X a, Ia(cid:12) does not satisfy Postulate PS.∧ ¬χ) and S (cid:16)|=CPL ¬(ϕ ∧ ϕ ˆCa(⇐): Suppose that Simp∗ = ∅. Therefore for all ϕ(cid:14) → (cid:11)a(cid:12)(cid:5) ∈ X a and for all subsets ˆCa ⊆ Ca, we have thatfor all χ ∈ NewCons(ψ ˆCa , S ), if, ϕ ˆCa , ¬χ} (cid:16)|=CPL ⊥,S ∪ {ϕthen there exists (cid:4)i ∈ χ such that a (cid:3) (cid:4)i.(cid:14)From (A.1) and Lemma 52, we getfor all χ ∈ NewCons(ψ ˆCa , S ), if} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} (cid:16)|=CPL ⊥,S ∪ {ϕ, ϕ ˆCathen S ∪ {χ} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} (cid:16)|=CPL ⊥.From this and Lemma 51, it follows thatfor all χ ∈ NewCons(ψ ˆCa , S ), if S ∪ {ϕthen S ∪ {χ} ∪ indep(cid:14)a(cid:16)|=CPL ⊥.(cid:14), ϕ ˆCa} ∪ indep(cid:14)a(cid:16)|=CPL ⊥,This and Lemma 50 give usif S ∪ {ϕ(cid:14), ϕ ˆCaS ∪ NewCons(ψ ˆCa , S ) ∪ indep(cid:14)} ∪ indep(cid:14)aa(cid:16)|=CPL ⊥, then(cid:16)|=CPL ⊥From this and Lemma 47, it follows that for all indep(cid:14)a} ∪ indep(cid:14)(cid:16)|=CPL ⊥, then S ∪ {ψ ˆCaaif S ∪ {ϕ, ϕ ˆCa(cid:14)⊆ indepa, for every ϕ(cid:14) → (cid:11)a(cid:12)(cid:5) ∈ X a and all ˆCa ⊆ Ca,} ∪ indep(cid:14)a(cid:16)|=CPL ⊥.(A.1)(A.2)Now, suppose S (cid:16)|=CPL ϕ for some propositional ϕ. We will build a model M such that M is a (cid:3)-model for(cid:11)S , E a, X a, Ia(cid:12) that does not satisfy ϕ.Let M = (cid:11)W, Ra(cid:12) be such that W = valuations(S ), and Ra be such that for all w, w(cid:14) ∈ W , wRaw(cid:14) if and only if• |=M• |=Mw(cid:14) ψi for every ϕi → [a]ψi ∈ Ca such that |=Mw(cid:14) ¬(cid:4) for all (cid:4) such that a (cid:16)(cid:3) (cid:4) and |=Mw¬(cid:4).w ϕi ; andWe have that M is a (cid:3)-model, by the definition of Ra. By the definition of W , M is a model of S . We have that Mis a model of E a and Ia, too: for every ϕi → [a]ψi ∈ Ca and every world w ∈ W , if |=Mw ϕi , then, by the definitionw(cid:14) ψi for all w(cid:14) ∈ W such that wRaw(cid:14). Moreover, M is also a model of X a: for every ϕi → (cid:11)a(cid:12)(cid:5) ∈ X a andof Ra, |=Mevery world w ∈ W , if |=Mw ϕi , thenE a(w) =(cid:2)ϕi → [a]ψi ∈ E a: |=Mw ϕi,(cid:3)andindepa(w) =(cid:2)¬(cid:4): a (cid:16)(cid:3) (cid:4) and |=Mw(cid:3)¬(cid:4)A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984977are such that S ∪ {ϕi, ϕE a (w)} ∪ indepa(w) (cid:16)|=CPL ⊥, whereϕE a (w) =(cid:11)(cid:2)(cid:3)ϕi: ϕi → [a]ψi ∈ E a(w).From this and (A.2), we have S ∪ {ψE a (w)} ∪ indepa(w) (cid:16)|=CPL ⊥, where(cid:11)(cid:2)ψE a (w) =(cid:3)ψi: ϕi → [a]ψi ∈ E a(w)As W is maximal, there exists w(cid:14) such that |=MHence there exists at least one w(cid:14) such that wRaw(cid:14), and |=MwHence, M is a model of (cid:11)S , E a, X a, Ia(cid:12) and (cid:3). Clearly (cid:16)|=M ϕ, by the definition of W . Hence S , E a, X a, Ia (cid:16)|=(cid:2).w(cid:14) ψE a (w) ∧ indepa(w). As Ra is maximal by definition, we have wRaw(cid:14).(cid:11)a(cid:12)(cid:5).ϕ. Therefore (cid:11)S , E a, X a, Ia(cid:12) with (cid:3) satisfies Postulate PS. (cid:2)Appendix B. Proof of Theorem 31Let Iaimp be the output of Algorithm 2 on input (cid:11)S , E a, X a, Ia(cid:12) and (cid:3). If (cid:11)S , E a, X a, Ia(cid:12) with (cid:3) satisfies Postu-late PS, then it satisfies Postulate PI if and only if Ia= ∅.Let (cid:11)S , E a, X a, Ia(cid:12) be an action theory for a with a dependence relation (cid:3). For every ˆE a ⊆ E a we define:imp(cid:11)(cid:2)(cid:11)(cid:2)=ϕ ˆE aψ ˆE a=(cid:3),(cid:3)ϕi: ϕi → [a]ψi ∈ ˆE aψi: ϕi → [a]ψi ∈ ˆE a= {¬(cid:4): a (cid:16)(cid:3) (cid:4)}..Moreover, let indepa∧ indep(cid:14)Lemma 53. If S , Ia (cid:16)|=PDL (ϕ ˆE aNewCons(ψ ˆE a , S ) such that S , Ia (cid:16)|=PDL (ϕ ˆE aa) → [a]⊥ and S ∪ {ψ ˆE a∧ ¬χ) → [a]⊥ and a (cid:16)(cid:3) (cid:4)i for all (cid:4)i ∈ χ .} ∪ indep(cid:14)a|=CPL ⊥,then there is χ ∈a) → [a]⊥. This means that there is a possible world v ∈ W such that |=Ma) → [a]⊥. Then there is a PDL-model M = (cid:11)W, Ra(cid:12) such that |=M S ∧ Iaa and∧ indep(cid:14)v ϕ ˆE a∧ indep(cid:14)Proof. Let S , Ia (cid:16)|=PDL (ϕ ˆE aand (cid:16)|=M (ϕ ˆE a(cid:16)|=Mv∧ indep(cid:14)[a]⊥. From |=MS ∪ {ϕ ˆE av ϕ ˆE a} ∪ indep(cid:14)aFrom hypothesis S ∪ {ψ ˆE a(cid:16)|=CPL ⊥.} ∪ indep(cid:14)aS ∪ NewCons(ψ ˆE a , S ) ∪ indep(cid:14)∧ indep(cid:14)a, it follows|=CPL ⊥ and Lemma 47, we get|=CPL ⊥and from this and Lemma 48 we have that there is χ ∈ NewCons(ψ ˆE a , S ) such thataS ∪ {χ} ∪ indep(cid:14)a|=CPL ⊥.From (B.1), (B.2) and classical logic, there is χ ∈ NewCons(ψ ˆE a , S ) such that(cid:16)|=CPL ⊥ and S ∪ {χ} ∪ indep(cid:14)aFrom this and Lemma 51 it follows that there is χ ∈ NewCons(ψ ˆE a , S ) such that} ∪ indep(cid:14)aS ∪ {ϕ ˆE a|=CPL ⊥.S ∪ {ϕ, ϕ ˆE a} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} (cid:16)|=CPL ⊥andS ∪ {χ} ∪ {¬(cid:4)i: (cid:4)i ∈ χ and a (cid:16)(cid:3) (cid:4)i} |=CPL ⊥.This and Lemma 52 gives us that for all (cid:4)i ∈ χ , a (cid:16)(cid:3) (cid:4)i .∧ indep(cid:14)Now, because M above is such that |=Mv ϕ ˆE a∧ ¬χ . Because (cid:16)|=Mvv ϕ ˆE a[a]⊥, we therefore have S , Ia (cid:16)|=PDL (ϕ ˆE aa, from this and S ∪ {χ} ∪ indep(cid:14)a∧ ¬χ) → [a]⊥. (cid:2)|=M(B.1)(B.2)|=CPL ⊥, we have that978A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984Proof of Theorem 31. We are about to prove that if (cid:11)S , E a, X a, Ia(cid:12) with (cid:3) satisfies Postulate PS, then it satisfiesPostulate PI if and only if Ia= ∅.(⇒): Straightforward, as every time S , E a, X a, Ia |=(cid:2) ϕ → [a]⊥, we have S , Ia |=PDL ϕ → [a]⊥, and then Iaimpimpnever changes.(⇐): Suppose that Iaimp= ∅. Therefore for all subsets ˆE a ⊆ E a, we have thatfor all χ ∈ NewCons(ψ ˆE a , S ), if S , Ia (cid:16)|=PDL (ϕ ˆE athen there exists (cid:4)i ∈ χ such that a (cid:3) (cid:4)i.∧ ¬χ) → [a]⊥,From (B.3) and Lemma 53, it follows that for all ˆE a ⊆ E a,if S , Ia (cid:16)|=PDL (ϕ ˆE athen S ∪ {ψ ˆE a} ∪ indep(cid:14)a(cid:16)|=CPL ⊥.∧ indep(cid:14)a) → [a]⊥,(B.3)(B.4)Suppose S , Ia (cid:16)|=PDL ϕ → [a]⊥ for some ϕ ∈ Fml. Then there exists a PDL-model M = (cid:11)W, Ra(cid:12) such that |=MS ∧ Ia and (cid:16)|=M ϕ → [a]⊥. This means that there is a possible world v ∈ W such that |=Mv ϕ and (cid:16)|=Mv[a]⊥.(We are going to build a (cid:3)-model of (cid:11)S , E a, X a, Ia(cid:12), and hence conclude that S , E a, X a, Ia (cid:16)|=(cid:2) ϕ → [a]⊥.)For given w ∈ W , we define:(cid:2)Ia(w) =ϕi → [a]⊥ ∈ Ia: |=Mw ϕi(cid:3).Because (cid:11)S , E a, X a, Ia(cid:12) with (cid:3) satisfies Postulate PS, we can extend M to a big model M(cid:14) = (cid:11)W (cid:14), R(cid:14)a(cid:12) such thatW = valuations(S ), and R(cid:14)a is defined such that for all w, w(cid:14) ∈ W (cid:14), wR(cid:14)aw(cid:14) if and only ifw(cid:14) ¬(cid:4) for all (cid:4) such that a (cid:16)(cid:3) (cid:4) and |=M(cid:14)w(cid:14) ψi for every ϕi → [a]ψi ∈ E a such that |=M(cid:14)¬(cid:4);w• |=M(cid:14)• |=M(cid:14)• Ia(w) = ∅.w ϕi ; andBy definition, M(cid:14) is a (cid:3)-model. We also have |=M(cid:14) S , by the definition of W (cid:14). M(cid:14) is a model of E a, too: for everyϕi → [a]ψi ∈ E a and every w ∈ W (cid:14), if |=M(cid:14)aw(cid:14). Clearly M(cid:14) is also amodel of Ia: for every ϕi → [a]⊥ ∈ Ia and every w ∈ W (cid:14), if |=M(cid:14)a(w) = ∅. M(cid:14) is a modelof X a, too: for every ϕi → (cid:11)a(cid:12)(cid:5) ∈ X a and every w ∈ W (cid:14), if |=M(cid:14)w(cid:14) ψi for all w(cid:14) ∈ W (cid:14) such that wR(cid:14)w ϕi , then Ia(w) (cid:16)= ∅ and R(cid:14)w ϕi , thenw ϕi , then |=M(cid:14)E a(w) =(cid:2)ϕi → [a]ψi ∈ E a: |=Mw ϕi(cid:3)andindepa(w) =(cid:2)¬(cid:4): a (cid:16)(cid:3) (cid:4) and |=Mware such that S , Ia (cid:16)|=PDL (ϕE a (w) ∧ indepa(w)) → [a]⊥, where(cid:3)ϕi: ϕi → [a]ψi ∈ E a(w).ϕE a (w) =(cid:3)¬(cid:4)(cid:11)(cid:2)The justification is that S , Ia |=PDL (ϕE a (w) ∧ indepa(w)) → [a]⊥ would imply S , E a, X a, Ia |=(cid:2) (ϕE a (w) ∧indepa(w)) → [a]⊥, and as long as ϕi → (cid:11)a(cid:12)(cid:5) ∈ X a, S , E a, X a, Ia |=(cid:2) ¬(ϕi ∧ ϕE a (w) ∧ indepa(w)). As by hy-pothesis (cid:11)S , E a, X a, Ia(cid:12) satisfies PS, S |=CPL ¬(ϕi ∧ ϕE a (w) ∧ indepa(w)), and then w /∈ W (cid:14).Hence, from S , Ia (cid:16)|=PDL (ϕE a (w) ∧ indepa(w)) → [a]⊥ and (B.4), it follows that S ∪ {ψE a (w)} ∪ indepa(w) (cid:16)|=CPL⊥, whereψE a (w) =(cid:11)(cid:2)(cid:3)ψi: ϕi → [a]ψi ∈ E a(w).As W (cid:14) is maximal, there exists w(cid:14) such that |=M(cid:14)wR(cid:14)w(cid:14) ψE a (w) ∧ indepa(w). As R(cid:14)aw(cid:14), and then |=M(cid:14)w(cid:14) (cid:11)a(cid:12)(cid:5).aw(cid:14). Hence there exists at least one w(cid:14) such that wR(cid:14)Therefore, M(cid:14) is a model of (cid:11)S , E a, X a, Ia(cid:12) and (cid:3).Looking at v ∈ W (cid:14), we must have S , Ia (cid:16)|=PDL (ϕE a (v) ∧ indepa(v)) → [a]⊥, because otherwise Ra(v) = ∅, against[a]⊥. Hence, from (B.4) it follows that S ∪{ψE a (v)}∪indepa(v) (cid:16)|=CPL ⊥, and then there existsthe hypothesis that (cid:16)|=Mva is maximal by definition, we haveA. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984979at least one v(cid:14) such that vR(cid:14)(cid:11)S , E a, X a, Ia(cid:12) and (cid:3) satisfy Postulate PI. (cid:2)av(cid:14), and then |=M(cid:14)v(cid:14) (cid:11)a(cid:12)(cid:5). From this it follows that S , E a, X a, Ia (cid:16)|=(cid:2) ϕ → [a]⊥. ThereforeAppendix C. Proof of Theorem 37Let (cid:11)S , E , X , I (cid:12) with (cid:3) satisfy PS∗. (cid:11)S , E , X , I (cid:12) with (cid:3) satisfies PI∗ if and only if (cid:11)S , E a, X a, Ia(cid:12) and (cid:3)satisfy PI for all a ∈ Act.(⇒): Suppose that S , E a, X a, Ia |=(cid:2) ϕ → [a]⊥. By monotonicity, S , E , X , I |=(cid:2) ϕ → [a]⊥, too. Now supposethat S , Ia (cid:16)|=PDL ϕ → [a]⊥. Then there exists a possible worlds model M = (cid:11)W, Ra(cid:12) such that |=M S ∧ Ia and therea(cid:14) = ∅,is a possible world v ∈ W such that |=M= Ra. Then |=M(cid:14) S ∧ I , and then S , I (cid:16)|=PDL ϕ → [a]⊥. Hence (cid:11)S , E , X , I (cid:12) with (cid:3) does notfor all a(cid:14) (cid:16)= a, and R(cid:14)asatisfy PI∗.[a]⊥. Let M(cid:14) = (cid:11)W (cid:14), R(cid:14)(cid:12) be such that W (cid:14) = W , and R(cid:14)v ϕ and (cid:16)|=Mv(⇐): Suppose (cid:11)S , E , X , I (cid:12) and (cid:3) do not satisfy Postulate PI∗. Then there exists ϕ ∈ Fml such that S , E , X , I |=(cid:2)ϕ → [a]⊥ and S , I (cid:16)|=PDL ϕ → [a]⊥.Claim. S , E a, X a, Ia |=(cid:2) ϕ → [a]⊥.[a]⊥, i.e., there is v(cid:14) ∈ W such that Ra(v) = v(cid:14).Proof of the claim. Suppose S , E a, X a, Ia (cid:16)|=(cid:2) ϕ → [a]⊥. Then there exists a (cid:3)-model M = (cid:11)W, Ra(cid:12) such that|=M S ∧ E a ∧ X a ∧ Ia and (cid:16)|=M ϕ → [a]⊥. This means that there is a possible world v ∈ W such that |=Mv ϕ and(cid:16)|=Mv(We extend M to all other actions (cid:11)S , E , X , I (cid:12) speaks of and obtain a (cid:3)-model of (cid:11)S , E , X , I (cid:12).)Given w ∈ W , for each ai ∈ Act we define:(cid:3)(cid:2)Iai (w) =X ai (w) =ϕj → [ai]⊥ ∈ Iai : |=Mw ϕj(cid:2)ϕj → (cid:11)ai(cid:12)(cid:5) ∈ X ai : |=Mw ϕjLet M(cid:14) = (cid:11)W (cid:14), R(cid:14)(cid:12) be such that W (cid:14) = W , and R(cid:14) = Ra ∪,(cid:3).wRa(cid:14)w(cid:14) if and only if(cid:10)a(cid:14)(cid:16)=a Ra(cid:14) , where for each a(cid:14) (cid:16)= a and every w, w(cid:14) ∈ W (cid:14),• |=M(cid:14)• |=M(cid:14)• Ia(cid:14)w(cid:14) ¬(cid:4) for all (cid:4) such that a(cid:14) (cid:16)(cid:3) (cid:4) and |=M(cid:14)w(cid:14) ψi for every ϕi → [a(cid:14)]ψi ∈ E a(cid:14)(w) = ∅.w¬(cid:4);such that |=M(cid:14)w ϕi ; andBy definition, M(cid:14) is a model of the dependence relation (cid:3). Because, by hypothesis, (cid:11)S , E , X , I (cid:12) with (cid:3) satisfies PS∗,there is no implicit static law, i.e., for every ai ∈ Act and every w ∈ W (cid:14), if Iai (w) (cid:16)= ∅, then X ai (w) = ∅. Then, asW (cid:14) = valuations(S ), M(cid:14) is a model of S . We have that M(cid:14) is a model of E , too: it is a model of E a, and given a(cid:14) (cid:16)= a,w ϕi , then |=M(cid:14)for every ϕi → [a(cid:14)]ψi ∈ E and every w ∈ W (cid:14), if |=M(cid:14)w(cid:14) ψi for all w(cid:14) ∈ W (cid:14) such that wRa(cid:14)w(cid:14). Clearly M(cid:14) isalso a model of I : it is a model of Ia, and given a(cid:14) (cid:16)= a, for every ϕi → [a(cid:14)]⊥ ∈ I and every w ∈ W (cid:14), if |=M(cid:14)w ϕi , thenIa(cid:14)(w) (cid:16)= ∅ and Ra(cid:14) (w) = ∅. M(cid:14) is a model of X , too: besides being a model of X a, for every a(cid:14) (cid:16)= a and all worldsw ∈ W (cid:14) such that X a(cid:14)(w) (cid:16)= ∅ there is a world accessible by Ra(cid:14) , because Ra(cid:14)(w) = ∅ in this case would precludeX a(cid:14)(w) (cid:16)= ∅, and otherwise w /∈ W (cid:14), which is impossible as long as PS∗ is satisfied. Thus |=M(cid:14) S ∧ E ∧ X ∧ I , but ifthis is the case, S , E , X , I (cid:16)|=(cid:2) ϕ → [a]⊥, hence we must have S , E a, X a, Ia |=(cid:2) ϕ → [a]⊥. (End of the proof ofthe claim.)From S , I (cid:16)|=PDL ϕ → [a]⊥ it follows S , Ia (cid:16)|=PDL ϕ → [a]⊥. Putting all the results together, we have that(cid:11)S , E a, X a, Ia(cid:12) with (cid:3) does not satisfy Postulate PI. (cid:2)Appendix D. Proof of Theorem 39If (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗, then S , E , X , I |=(cid:2) ϕ → [a]ψ if and only if S , E a, Ia |=(cid:2) ϕ →[a]ψ.980A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984(⇒): Let (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗, and also suppose that S , E a, Ia (cid:16)|=(cid:2) ϕ → [a]ψ. Then there existsa (cid:3)-model M = (cid:11)W, Ra(cid:12), such that |=M S ∧ E a ∧ Ia and (cid:16)|=M ϕ → [a]ψ. This means that there is a possible worldv ∈ W such that |=M[a]ψ, i.e., there is v(cid:14) ∈ W such that Ra(v) = v(cid:14) and (cid:16)|=Mv ϕ and (cid:16)|=Mvv(cid:14) ψ.(We will extend M to obtain a (cid:3)-model of (cid:11)S , E , X , I (cid:12) and thus show that S , E , X , I (cid:16)|=(cid:2) ϕ → [a]ψ.)Given w ∈ W , for each ai ∈ Act we define:(cid:3)(cid:2)Iai (w) =X ai (w) =ϕj → [ai]⊥ ∈ Iai : |=Mw ϕj(cid:2)ϕj → (cid:11)ai(cid:12)(cid:5) ∈ X ai : |=Mw ϕjLet M(cid:14) = (cid:11)W (cid:14), R(cid:14)(cid:12) be such that W (cid:14) = W , and R(cid:14) = Ra ∪,(cid:3).wRa(cid:14)w(cid:14) if and only if(cid:10)a(cid:14)(cid:16)=a Ra(cid:14) , where for each a(cid:14) (cid:16)= a and every w, w(cid:14) ∈ W (cid:14),• |=M(cid:14)• |=M(cid:14)• Ia(cid:14)w(cid:14) ¬(cid:4) for all (cid:4) such that a(cid:14) (cid:16)(cid:3) (cid:4) and |=M(cid:14)w(cid:14) ψi for every ϕi → [a(cid:14)]ψi ∈ E a(cid:14)(w) = ∅.w¬(cid:4);such that |=M(cid:14)w ϕi ; andBy definition, M(cid:14) is a model of the dependence relation (cid:3). Because, by hypothesis, (cid:11)S , E , X , I (cid:12) satisfies PS∗,there is no implicit static law, i.e., for every ai ∈ Act and every w ∈ W (cid:14), if Iai (w) (cid:16)= ∅, then X ai (w) = ∅. Then, asW (cid:14) = valuations(S ), M(cid:14) is a model of S . We have that M(cid:14) is a model of E , too: it is a model of E a, and given a(cid:14) (cid:16)= a,w ϕi , then |=M(cid:14)for every ϕi → [a(cid:14)]ψi ∈ E and every w ∈ W (cid:14), if |=M(cid:14)w(cid:14) ψi for all w(cid:14) ∈ W (cid:14) such that wRa(cid:14)w(cid:14). Clearly M(cid:14) isalso a model of I : besides being a model of Ia, given a(cid:14) (cid:16)= a, for every ϕi → [a(cid:14)]⊥ ∈ I and every w ∈ W (cid:14), if |=M(cid:14)w ϕi ,then Ia(cid:14)(w) (cid:16)= ∅ and Ra(cid:14)(w) = ∅. M(cid:14) is a model of X , too: it is a model of X a, and for every a(cid:14) (cid:16)= a and all worldsw ∈ W (cid:14) such that X a(cid:14)(w) (cid:16)= ∅ there is a world accessible by Ra(cid:14) , because Ra(cid:14)(w) = ∅ in this case would precludeX a(cid:14)(w) (cid:16)= ∅, and otherwise w /∈ W (cid:14), which is impossible as long as PS∗ is satisfied. Thus |=M(cid:14) S ∧ E ∧ X ∧ I .Because there are v, v(cid:14) ∈ W (cid:14) such that |=M(cid:14)(⇐): Suppose S , E , X , I (cid:16)|=(cid:2) ϕ → [a]ψ. Then there is a (cid:3)-model M such that |=M S ∧ E ∧ X ∧ I and (cid:16)|=M ϕ →[a]ψ . Then, given a, we have |=M S ∧ E a ∧ X a ∧ Ia, and then |=M S ∧ E a ∧ Ia. Hence S , E a, Ia (cid:16)|=(cid:2) ϕ → [a]ψ. (cid:2)v(cid:14) ψ, we have S , E , X , I (cid:16)|=(cid:2) ϕ → [a]ψ.v ϕ, vRav(cid:14) and (cid:16)|=M(cid:14)Appendix E. Proof of Theorem 40If (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗, then S , E , X , I |=(cid:2) ϕ → (cid:11)a(cid:12)(cid:5) if and only if S , X a |=(cid:2) ϕ → (cid:11)a(cid:12)(cid:5).(⇒): Let (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗, and suppose S , X a (cid:16)|=PDL ϕ → (cid:11)a(cid:12)(cid:5). Then there exists a PDL-model M = (cid:11)W, Ra(cid:12), such that |=M S ∧ X a and (cid:16)|=M ϕ → (cid:11)a(cid:12)(cid:5). This means that there is a possible world v ∈ Wsuch that |=M(cid:11)a(cid:12)(cid:5).v ϕ and (cid:16)|=Mv(We extend M to build a (cid:3)-model of (cid:11)S , E , X , I (cid:12) and then conclude that S , E , X , I (cid:16)|=(cid:2) ϕ → (cid:11)a(cid:12)(cid:5).)Given w ∈ W , for each ai ∈ Act we define:(cid:3)(cid:2)Iai (w) =X ai (w) =ϕj → [ai]⊥ ∈ Iai : |=Mw ϕj(cid:2)ϕj → (cid:11)ai(cid:12)(cid:5) ∈ X ai : |=Mw ϕjLet M(cid:14) = (cid:11)W (cid:14), R(cid:14)(cid:12) be such that W (cid:14) = W , and R(cid:14) = Ra ∪,(cid:3).wRa(cid:14)w(cid:14) if and only if(cid:10)a(cid:14)(cid:16)=a Ra(cid:14) , where for each a(cid:14) (cid:16)= a and every w, w(cid:14) ∈ W (cid:14),• |=M(cid:14)• |=M(cid:14)• Ia(cid:14)w(cid:14) ¬(cid:4) for all (cid:4) such that a(cid:14) (cid:16)(cid:3) (cid:4) and |=M(cid:14)w(cid:14) ψi for every ϕi → [a(cid:14)]ψi ∈ E a(cid:14)(w) = ∅.w¬(cid:4);such that |=M(cid:14)w ϕi ; andBy definition, M(cid:14) is a model of the dependence relation (cid:3). Because, by hypothesis, (cid:11)S , E , X , I (cid:12) satisfies PS∗,there is no implicit static law, i.e., for every ai ∈ Act and every w ∈ W (cid:14), if X ai (w) (cid:16)= ∅, then Iai (w) = ∅. Then, asW (cid:14) = valuations(S ), M(cid:14) is a model of S . We have that M(cid:14) is a model of E , too: it is a model of E a, and given a(cid:14) (cid:16)= a,w ϕi , then |=M(cid:14)for every ϕi → [a(cid:14)]ψi ∈ E and every w ∈ W (cid:14), if |=M(cid:14)w(cid:14) ψi for all w(cid:14) ∈ W (cid:14) such that wRa(cid:14)w(cid:14). Clearly M(cid:14) isA. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984981w ϕi , then(w) (cid:16)= ∅ and Ra(cid:14) (w) = ∅. M(cid:14) is a model of X , too: besides being a model of X a, for every a(cid:14) (cid:16)= a and all worlds(w) (cid:16)= ∅ there is a world accessible by Ra(cid:14) , because Ra(cid:14)(w) = ∅ in this case would preclude(w) (cid:16)= ∅, and otherwise w /∈ W (cid:14), which is impossible as long as PS∗ is satisfied. Hence |=M(cid:14) S ∧ E ∧ X ∧ I .also a model of I : it is a model of Ia, and given a(cid:14) (cid:16)= a, for every ϕi → [a(cid:14)]⊥ ∈ I and every w ∈ W (cid:14), if |=M(cid:14)Ia(cid:14)w ∈ W (cid:14) such that X a(cid:14)X a(cid:14)Because there is v ∈ W (cid:14) such that |=M(cid:14)(cid:11)a(cid:12)(cid:5), we have S , E , X , I (cid:16)|=(cid:2) ϕ → (cid:11)a(cid:12)(cid:5).(⇐): Suppose S , E , X , I (cid:16)|=(cid:2) ϕ → (cid:11)a(cid:12)(cid:5). Then there is a (cid:3)-model M such that |=M S ∧ E ∧ X ∧ I and (cid:16)|=Mϕ → (cid:11)a(cid:12)(cid:5). Then, given a, we have |=M S ∧ E a ∧ X a ∧ Ia, and then |=M S ∧ X a. Moreover, by definition, M is aPDL-model. Hence S , X a (cid:16)|=PDL ϕ → (cid:11)a(cid:12)(cid:5). (cid:2)v ϕ and (cid:16)|=M(cid:14)vAppendix F. Proof of Theorem 43If (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗, then S , E , X , I |=(cid:2) ϕ → [a1; . . . ; an]ψ if and only if S , E a1,...,an ,Ia1,...,an |=(cid:2) ϕ → [a1; . . . ; an]ψ.Lemma 54. If S , E , X , I |=(cid:2) ϕ → [a1; . . . ; an]ψ,[a1; . . . ; an−1]ϕ(cid:14) and S , E , X , I |=(cid:2) ϕ(cid:14) → [an]ψ.then there is ϕ(cid:14) ∈ Fml such that S , E , X , I |=(cid:2) ϕ →Proof. Let S , E , X , I |=(cid:2) ϕ → [a1; . . . ; an]ψ. In the case we have S , E , X , I |=(cid:2) ϕ → [a1; . . . ; an]⊥, the resultw ϕ for some w ∈ W , if |=Mimmediately follows. Then, given a model M = (cid:11)W, R(cid:12) of (cid:11)S , E , X , I (cid:12) such that |=Mw[an]ψ. Take all such w(cid:14)(cid:11)a1; . . . ; an(cid:12)(cid:5), there must be at least one w(cid:14)n−1 and let ϕ(cid:14) ben−1 such that |=Mw(cid:14)n−1(cid:12)w(cid:14)n−1.|=M(cid:14)wn−1[an]ψThen we have both S , E , X , I |=(cid:2) ϕ → [a1; . . . ; an−1]ϕ(cid:14), and S , E , X , I |=(cid:2) ϕ(cid:14) → [an]ψ. (cid:2)Proof of Theorem 43. (⇒): The proof is by induction on the number of action operators.Base: n = 1. As (cid:11)S , E , X , I (cid:12) satisfies Postulate PS∗, the result follows from Theorem 39.Induction hypothesis: for any k < n, if S , E , X , I |=(cid:2) ϕ → [a1; . . . ; ak]ψ, then S , E a1,...,ak , Ia1,...,ak |=(cid:2) ϕ →[a1; . . . ; ak]ψ .Step: let S , E , X , I |=(cid:2) ϕ → [a1; . . . ; an]ψ. By Lemma 54, there is a classical formula ϕ(cid:14) such that S , E , X ,I |=(cid:2) ϕ → [a1; . . . ; an−1]ϕ(cid:14) and S , E , X , I |=(cid:2) ϕ(cid:14) → [an]ψ. From the induction hypothesis, we have S , E a1,...,an−1 ,Ia1,...,an−1 |=(cid:2) ϕ → [a1; . . . ; an−1]ϕ(cid:14) and S , E an, Ian |=(cid:2) ϕ(cid:14) → [an]ψ. Thus S , E a1,...,an, Ia1,...,an |=(cid:2) ϕ →[a1; . . . ; an]ψ .(⇐): Suppose S , E , X , I (cid:16)|=(cid:2) ϕ → [a1; . . . ; an]ψ. Then there is a (cid:3)-model M such that |=M S ∧ E ∧ X ∧ Iand (cid:16)|=M ϕ → [a1; . . . ; an]ψ. Then, given a1, . . . , an, we have |=M S ∧ E a1,...,an ∧ X a1,...,an ∧ Ia1,...,an , and then|=M S ∧ E a1,...,an ∧ Ia1,...,an . Hence S , E a1,...,an , Ia1,...,an (cid:16)|=(cid:2) ϕ → [a1; . . . ; an]ψ. (cid:2)Appendix G. Proof of Theorem 45Let (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗. Then we have S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)ψ if and only ifS , E a1,...,an, X a1,...,an , Ia1,...,an |=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)ψ.Lemma 55. Let (cid:11)S , E , X , I (cid:12) and (cid:3) satisfy Postulate PS∗. If S , E , X , I |=(cid:2) ϕ → (cid:11)a(cid:12)ψ, then S , E a, X a, Ia |=(cid:2)ϕ → (cid:11)a(cid:12)ψ .Proof. Let (cid:11)S , E , X , I (cid:12) satisfy Postulate PS∗ and suppose S , E a, X a, Ia (cid:16)|=(cid:2) ϕ → (cid:11)a(cid:12)ψ. Then there exists a (cid:3)-model M = (cid:11)W, Ra(cid:12), such that both |=M S ∧ E a ∧ X a ∧ Ia and (cid:16)|=M ϕ → (cid:11)a(cid:12)ψ. This means that there is a possibleworld v ∈ W such that |=M(cid:11)a(cid:12)ψ.v ϕ and (cid:16)|=Mv(We extend M to build a model of (cid:11)S , E , X , I (cid:12) and then conclude that S , E , X , I (cid:16)|=(cid:2) ϕ → (cid:11)a(cid:12)ψ.)Given w ∈ W , for each ai ∈ Act we define:982A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984(cid:2)(cid:3)Iai (w) =X ai (w) =ϕj → [ai]⊥ ∈ Iai : |=Mw ϕj(cid:2)ϕj → (cid:11)ai(cid:12)(cid:5) ∈ X ai : |=Mw ϕj,(cid:3).Let M(cid:14) = (cid:11)W (cid:14), R(cid:14)(cid:12) be such that W (cid:14) = W , and R(cid:14) = Ra ∪a(cid:14)(cid:16)=a Ra(cid:14) (we extend M to all other actions (cid:11)S , E , X , I (cid:12)speaks of), where for each a(cid:14) (cid:16)= a and every w, w(cid:14) ∈ W (cid:14), wRa(cid:14)w(cid:14) if and only if(cid:10)• |=M(cid:14)• |=M(cid:14)• Ia(cid:14)w(cid:14) ¬(cid:4) for all (cid:4) such that a(cid:14) (cid:16)(cid:3) (cid:4) and |=M(cid:14)w(cid:14) ψi for every ϕi → [a(cid:14)]ψi ∈ E a(cid:14)(w) = ∅.w¬(cid:4);such that |=M(cid:14)w ϕi ; andBy definition, M(cid:14) is a model of the dependence relation (cid:3). Because, by hypothesis, (cid:11)S , E , X , I (cid:12) satisfies PS∗,there is no implicit static law, i.e., for every ai ∈ Act and every w ∈ W (cid:14), if X ai (w) (cid:16)= ∅, then Iai (w) = ∅. Then, asW (cid:14) = valuations(S ), M(cid:14) is a model of S . We have that M(cid:14) is a model of E , too: it is a model of E a, and given a(cid:14) (cid:16)= a,w ϕi , then |=M(cid:14)for every ϕi → [a(cid:14)]ψi ∈ E and every w ∈ W (cid:14), if |=M(cid:14)w(cid:14) ψi for all w(cid:14) ∈ W (cid:14) such that wRa(cid:14)w(cid:14). Clearly M(cid:14) isalso a model of I : it is a model of Ia, and given a(cid:14) (cid:16)= a, for every ϕi → [a(cid:14)]⊥ ∈ I and every w ∈ W (cid:14), if |=M(cid:14)w ϕi , thenIa(cid:14)(w) (cid:16)= ∅ and Ra(cid:14) (w) = ∅. M(cid:14) is a model of X , too: besides being a model of X a, for every a(cid:14) (cid:16)= a and all worldsw ∈ W (cid:14) such that X a(cid:14)(w) (cid:16)= ∅ there is a world accessible by Ra(cid:14) , because Ra(cid:14)(w) = ∅ in this case would precludeX a(cid:14)(w) (cid:16)= ∅, and otherwise w /∈ W (cid:14), which is impossible as long as PS∗ is satisfied. Hence |=M(cid:14) S ∧ E ∧ X ∧ I .Because there is v ∈ W (cid:14) such that |=M(cid:14)(cid:11)a(cid:12)ψ, we have S , E , X , I (cid:16)|=(cid:2) ϕ → (cid:11)a(cid:12)ψ. (cid:2)v ϕ and (cid:16)|=M(cid:14)vLemma 56. If S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)ψ, then there is ϕ(cid:14) ∈ Fml such that S , E , X , I |=(cid:2) ϕ →(cid:11)a1; . . . ; an−1(cid:12)ϕ(cid:14) and S , E , X , I |=(cid:2) ϕ(cid:14) → (cid:11)an(cid:12)ψ.Proof. The proof is by induction on the number of action operators.Base: n = 2. Suppose S , E , X , I |=(cid:2) ϕ → (cid:11)a1; a2(cid:12)ψ. Then S , E , X , I |=(cid:2) ϕ → (cid:11)a1(cid:12)(cid:11)a2(cid:12)ψ. For every modelw(cid:14) (cid:11)a2(cid:12)ψ.w ϕ, there is w(cid:14) ∈ W such that wRa1w(cid:14) and |=MM = (cid:11)W, R(cid:12) of (cid:11)S , E , X , I (cid:12) and for every w ∈ W such that |=MLet ϕ(cid:14) be{(cid:4) : (cid:4) ∈ w(cid:14)} and the result follows.Induction hypothesis: for any k < n, if S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; ak(cid:12)ψ, then there is ϕ(cid:14) ∈ Fml such that(cid:9)S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; ak−1(cid:12)ϕ(cid:14) and S , E , X , I |=(cid:2) ϕ(cid:14) → (cid:11)ak(cid:12)ψ.Step: let S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)ψ. Then we have that S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; an−1(cid:12)(cid:5). Bythe induction hypothesis, there is ϕ(cid:14) ∈ Fml such that S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; an−2(cid:12)ϕ(cid:14) and S , E , X , I |=(cid:2)ϕ(cid:14) → (cid:11)an−1(cid:12)(cid:5). Because S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)ψ, given a model M = (cid:11)W, R(cid:12) of (cid:11)S , E , X , I (cid:12) suchw ϕ for some w ∈ W , there must be w(cid:14)(cid:11)an−1(cid:12)(cid:11)an(cid:12)ψ. Then we can safely takethat |=M(cid:9)ϕ(cid:14) as}. Now, S , E , X , I |=(cid:2) ϕ(cid:14) → (cid:11)an−1(cid:12)(cid:11)an(cid:12)ψ. By the base step, there is ϕ(cid:14)(cid:14) ∈ Fml suchthat S , E , X , I |=(cid:2) ϕ(cid:14) → (cid:11)an−1(cid:12)ϕ(cid:14)(cid:14) and S , E , X , I |=(cid:2) ϕ(cid:14)(cid:14) → (cid:11)an(cid:12)ψ. Putting all the results together, we getS , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; an−1(cid:12)ϕ(cid:14)(cid:14) and S , E , X , I |=(cid:2) ϕ(cid:14)(cid:14) → (cid:11)an(cid:12)ψ, for some ϕ(cid:14)(cid:14) ∈ Fml. (cid:2)∈ W such that |=Mw(cid:14){(cid:4): (cid:4) ∈ w(cid:14)n−2n−2n−2Proof of Theorem 45. (⇒): The proof is by induction on the number of action operators.Base: n = 1. As (cid:11)S , E , X , I (cid:12) satisfies Postulate PS∗, the result follows from Lemma 55.Induction hypothesis: for any k < n, if S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; ak(cid:12)ψ, then S , E a1,...,ak , X a1,...,ak , Ia1,...,ak |=(cid:2)ϕ → (cid:11)a1; . . . ; ak(cid:12)ψ.Step: let S , E , X , I |=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)ψ. By Lemma 56, there is ϕ(cid:14) ∈ Fml such that S , E , X , I |=(cid:2) ϕ →(cid:11)a1; . . . ; an−1(cid:12)ϕ(cid:14) and S , E , X , I |=(cid:2) ϕ(cid:14) → (cid:11)an(cid:12)ψ. By the induction hypothesis, we have S , E a1,...,an−1 , X a1,...,an−1 ,Ia1,...,an−1 |=(cid:2) ϕ → (cid:11)a1; . . . ; an−1(cid:12)ϕ(cid:14) and also S , E an , X an, Ian |=(cid:2) ϕ(cid:14) → (cid:11)an(cid:12)ψ. Then, this gives us S , E a1,...,an ,X a1,...,an , Ia1,...,an |=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)ψ.(⇐): Suppose S , E , X , I (cid:16)|=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)ψ. Then there is a (cid:3)-model M such that |=M S ∧ E ∧X ∧ I and (cid:16)|=M ϕ → (cid:11)a1; . . . ; an(cid:12)ψ. Then, given a1, . . . , an, |=M S ∧ E a1,...,an ∧ X a1,...,an ∧ Ia1,...,an , and henceS , E a1,...,an , X a1,...,an, Ia1,...,an (cid:16)|=(cid:2) ϕ → (cid:11)a1; . . . ; an(cid:12)ψ. (cid:2)A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984983References[1] G. De Giacomo, M. Lenzerini, PDL-based framework for reasoning about actions, in: M. Gori, G. Soda (Eds.), Proc. 4th Congress of theItalian Association for Artificial Intelligence (IAAI’95), in: Lecture Notes Artif. Intell., vol. 992, Springer-Verlag, 1995, pp. 103–114.∗[2] F. Lin, Embracing causality in specifying the indirect effects of actions, in: Mellish [62], pp. 1985–1991.[3] N. McCain, H. Turner, A causal theory of ramifications and qualifications, in: Mellish [62], pp. 1978–1984.[4] M. Thielscher, Computing ramifications by postprocessing, in: Mellish [62], pp. 1994–2000.[5] M. Castilho, O. Gasquet, A. Herzig, Formalizing action and change in modal logic I: The frame problem, Journal of Logic and Computa-tion 9 (5) (1999) 701–735.[6] D. Zhang, N. Foo, EPDL: A logic for causal reasoning, in: B. Nebel (Ed.), Proc. 17th Intl. Joint Conf. on Artificial Intelligence (IJCAI’01),Seattle, Morgan Kaufmann Publishers, 2001, pp. 131–138.[7] D. Harel, Dynamic logic, in: D. Gabbay, F. Günthner (Eds.), Handbook of Philosophical Logic, vol. II, D. Reidel, Dordrecht, 1984, pp. 497–604.[8] J. McCarthy, P. Hayes, Some philosophical problems from the standpoint of artificial intelligence, in: B. Meltzer, D. Mitchie (Eds.), MachineIntelligence, vol. 4, Edinburgh University Press, 1969, pp. 463–502.[9] M. Gelfond, V. Lifschitz, Representing action and change by logic programs, Journal of Logic Programming 17 (2/3–4) (1993) 301–321.[10] N. Kartha, V. Lifschitz, Actions with indirect effects (preliminary report), in: J. Doyle, E. Sandewall, P. Torasso (Eds.), Proc. 4th Intl. Conf.on Knowledge Representation and Reasoning (KR’94), Bonn, Morgan Kaufmann Publishers, 1994, pp. 341–350.[11] E. Giunchiglia, G. Kartha, V. Lifschitz, Representing action: Indeterminacy and ramifications, Artificial Intelligence 95 (2) (1997) 409–438.[12] A. Herzig, I. Varzinczak, Cohesion, coupling and the meta-theory of actions, in: Kaelbling and Saffiotti [60], pp. 442–447.[13] A. Herzig, I. Varzinczak, A modularity approach for a fragment of ALC, in: M. Fisher, W. van der Hoek, B. Konev, A. Lisitsa (Eds.),Proc. 10th Eur. Conf. on Logics in Artificial Intelligence (JELIA’2006), in: Lecture Notes Artif. Intell., vol. 4160, Springer-Verlag, 2006,pp. 216–228.[14] F. Baader, D. Calvanese, D. McGuinness, D. Nardi, P. Patel-Schneider (Eds.), Description Logic Handbook, Cambridge University Press,2003.[15] A. Herzig, I. Varzinczak, Domain descriptions should be modular, in: R. López de Mántaras, L. Saitta (Eds.), Proc. 16th Eur. Conf. on ArtificialIntelligence (ECAI’04), Valencia, IOS Press, 2004, pp. 348–352.[16] D. Harel, J. Tiuryn, D. Kozen, Dynamic Logic, MIT Press, Cambridge, MA, 2000.[17] M. Kracht, F. Wolter, Properties of independently axiomatizable bimodal logics, Journal of Symbolic Logic 56 (4) (1991) 1469–1485.[18] M. Kracht, F. Wolter, Simulation and transfer results in modal logic: A survey, Studia Logica 59 (1997) 149–177.[19] S. Popkorn, First Steps in Modal Logic, Cambridge University Press, 1994.[20] P. Blackburn, M. de Rijke, Y. Venema, Modal Logic, Cambridge Tracts in Theoretical Computer Science, Cambridge University Press, 2001.[21] M. Fitting, Proof Methods for Modal and Intuitionistic Logics, D. Reidel, Dordrecht, 1983.[22] S. Hanks, D. McDermott, Default reasoning, nonmonotonic logics, and the frame problem, in: T. Kehler, S. Rosenschein (Eds.), Proc. 5thNatl. Conf. on Artificial Intelligence (AAAI’86), Philadelphia, Morgan Kaufmann Publishers, 1986, pp. 328–333.[23] M. Castilho, A. Herzig, I. Varzinczak, It depends on the context! a decidable logic of actions and plans based on a ternary dependence relation,in: S. Benferhat, E. Giunchiglia (Eds.), Workshop on Nonmonotonic Reasoning (NMR’02), Toulouse, 2002, pp. 343–348.[24] J. McCarthy, Epistemological problems of artificial intelligence, in: N. Sridharan (Ed.), Proc. 5th Intl. Joint Conf. on Artificial Intelligence(IJCAI’77), Cambridge, MA, Morgan Kaufmann Publishers, 1977, pp. 1038–1044.[25] M. Ginsberg, D. Smith, Reasoning about actions II: The qualification problem, Artificial Intelligence 35 (3) (1988) 311–342.[26] L. Schubert, Monotonic solution of the frame problem in the situation calculus: An efficient method for worlds with fully specified actions, in:H. Kyberg, R. Loui, G. Carlson (Eds.), Knowledge Representation and Defeasible Reasoning, Kluwer Academic Publishers, 1990, pp. 23–67.[27] P. Doherty, W. Łukaszewicz, A. Szałas, Explaining explanation closure, in: Proc. 9th Intl. Symposium on Methodologies for IntelligentSystems, Zakopane, Poland, in: Lecture Notes Comput. Sci., vol. 1079, Springer-Verlag, 1996.[28] J. Finger, Exploiting constraints in design synthesis, Ph.D. thesis, Stanford University, Stanford, 1987.[29] R. Demolombe, A. Herzig, I. Varzinczak, Regression in modal logic, Journal of Applied Non-Classical Logics (JANCL) 13 (2) (2003) 165–185.[30] R. Reiter, The frame problem in the situation calculus: A simple solution (sometimes) and a completeness result for goal regression, in:V. Lifschitz (Ed.), Artificial Intelligence and Mathematical Theory of Computation: Papers in Honor of John McCarthy, Academic Press, SanDiego, 1991, pp. 359–380.[31] I. Varzinczak, What is a good domain description? Evaluating and revising action theories in dynamic logic, Ph.D. thesis, Université PaulSabatier, Toulouse, 2006.[32] R. Reiter, Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems, MIT Press, Cambridge, MA,2001.[33] M. Castilho, O. Gasquet, A. Herzig, A dependence-based framework for actions with indeterminate and indirect effects, Tech. Rep. RT-98-04-R, Institut de recherche en informatique de Toulouse (IRIT), Université Paul Sabatier, http://www.irit.fr/LILaC/, February 1998.[34] C. Schwind, Causality in action theories, Linköping Electronic Articles in Computer and Information Science 4 (4).[35] P. Marquis, Consequence finding algorithms, in: D. Gabbay, P. Smets (Eds.), Algorithms for Defensible and Uncertain Reasoning, in: S. Moral,J. Kohlas (Eds.), Handbook of Defeasible Reasoning and Uncertainty Management Systems, vol. 5, Kluwer Academic Publishers, 2000,pp. 41–145, Chapter 2.[36] K. Inoue, Linear resolution for consequence finding, Artificial Intelligence 56 (2–3) (1992) 301–353.984A. Herzig, I. Varzinczak / Artificial Intelligence 171 (2007) 951–984[37] A. Herzig, I. Varzinczak, On the modularity of theories, in: R. Schmidt, I. Pratt-Hartmann, M. Reynolds, H. Wansing (Eds.), Ad-vances in Modal Logic, vol. 5, King’s College Publications, 2005, pp. 93–109, selected papers of AiML 2004, also available athttp://www.aiml.net/volumes/volume5.[38] F. Lin, Embracing causality in specifying the indeterminate effects of actions, in: Shrobe and Senator [61], pp. 670–676.[39] M. Thielscher, Ramification and causality, Artificial Intelligence 89 (1–2) (1997) 317–364.[40] V. Lifschitz, W. Ren, Towards a modular action description language, in: Proc. 21st Natl. Conf. on Artificial Intelligence (AAAI’2006),Boston, AAAI Press/MIT Press, 2006.[41] F. Pirri, R. Reiter, Some contributions to the metatheory of the situation calculus, Journal of the ACM 46 (3) (1999) 325–361.[42] E. Amir, (De)composition of situation calculus theories, in: Proc. 17th Natl. Conf. on Artificial Intelligence (AAAI’2000), Austin, AAAIPress/MIT Press, 2000, pp. 456–463.[43] F. Lin, R. Reiter, State constraints revisited, Journal of Logic and Computation 4 (5) (1994) 655–678.[44] S. McIlraith, Integrating actions and state constraints: A closed-form solution to the ramification problem (sometimes), Artificial Intelli-gence 116 (1–2) (2000) 87–121.[45] I. Sommerville, Software Engineering, Addison Wesley, 1985.[46] R. Pressman, Software Engineering: A Practitioner’s Approach, McGraw-Hill, 1992.[47] D. Zhang, S. Chopra, N. Foo, Consistency of action descriptions, in: M. Ishizuka, A. Sattar (Eds.), Proc. 7th Pacific Rim Intl. Conf. onArtificial Intelligence: Trends in Artificial Intelligence, in: Lecture Notes Comput. Sci., vol. 2417, Springer-Verlag, 2002, pp. 70–79.[48] J. Lang, F. Lin, P. Marquis, Causal theories of action—A computational core, in: V. Sorge, S. Colton, M. Fisher, J. Gow (Eds.), Proc. 18th Intl.Joint Conf. on Artificial Intelligence (IJCAI’03), Acapulco, Morgan Kaufmann Publishers, 2003, pp. 1073–1078.[49] L. Cholvy, Checking regulation consistency by using SOL-resolution, in: Proc. 7th Intl. Conf. on AI and Law, Oslo, 1999, pp. 73–79.[50] E. Giunchiglia, J. Lee, V. Lifschitz, N. McCain, H. Turner, Nonmonotonic causal theories, Artificial Intelligence 153 (1–2) (2004) 49–104.[51] R. Li, L. Pereira, What is believed is what is explained, in: Shrobe and Senator [61], pp. 550–555.[52] P. Liberatore, A framework for belief update, in: Proc. 7th Eur. Conf. on Logics in Artificial Intelligence (JELIA’2000), 2000, pp. 361–375.[53] T. Eiter, E. Erdem, M. Fink, J. Senko, Updating action domain descriptions, in: Kaelbling and Saffiotti [60], pp. 418–423.[54] A. Herzig, L. Perrussel, I. Varzinczak, Elaborating domain descriptions, in: G. Brewka, S. Coradeschi, A. Perini, P. Traverso (Eds.), Proc. 17thEur. Conf. on Artificial Intelligence (ECAI’06), Riva del Garda, IOS Press, 2006, pp. 397–401.[55] J. Garson, Modularity and relevant logic, Notre Dame Journal of Formal Logic 30 (2) (1989) 207–223.[56] B. Cuenca Grau, B. Parsia, E. Sirin, A. Kalyanpur, Modularity and web ontologies, in: P. Doherty, J. Mylopoulos, C. Welty (Eds.), Proc. 10thIntl. Conf. on Knowledge Representation and Reasoning (KR’2006), Lake District, Morgan Kaufmann Publishers, 2006, pp. 198–208.[57] A. Kakas, L. Michael, R. Miller, Modular-E: An elaboration tolerant approach to the ramification and qualification problems, in: C. Baral,G. Greco, N. Leone, G. Terracina (Eds.), Proc. 8th Intl. Conf. Logic Programming and Nonmonotonic Reasoning, Diamante, Springer-Verlag,2005, pp. 211–226.[58] J. Gustafsson, P. Doherty, Embracing occlusion in specifying the indirect effects of actions, in: L. Aiello, J. Doyle, S. Shapiro (Eds.), Proc.5th Intl. Conf. on Knowledge Representation and Reasoning (KR’96), Cambridge, MA, Morgan Kaufmann Publishers, 1996, pp. 87–98.[59] P. Marquis, Knowledge compilation using theory prime implicates, in: Mellish [62], pp. 837–843.[60] L. Kaelbling, A. Saffiotti (Eds.), Proc. 19th Intl. Joint Conf. on Artificial Intelligence (IJCAI’05), Edinburgh, Morgan Kaufmann Publishers,2005.[61] H. Shrobe, T. Senator (Eds.), Proc. 13th Natl. Conf. on Artificial Intelligence (AAAI’96), Portland, AAAI Press/MIT Press, 1996.[62] C. Mellish (Ed.), Proc. 14th Intl. Joint Conf. on Artificial Intelligence (IJCAI’95), Montreal, Morgan Kaufmann Publishers, 1995.