Open Archive TOULOUSE Archive Ouverte (OATAO)OATAO is an open access repository that collects the work of Toulouse researchers and makes it freely available over the web where possible.This is an author-deposited version published in : http://oatao.univ-toulouse.fr/Eprints ID : 6862To link to this document : DOI:10.1016/j.dss.2012.06.009 URL : http://dx.doi.org/10.1016/j.dss.2012.06.009 To cite this version : Kamsu Foguem, Bernard and Tchuenté Foguem,Germaine and Allart, Laurent and Zennir, Youcef and Vilhelm, Christian andMehdaoui, Hossein and Zitouni, Djamel and Hubert, Hervé and Lemdani,Mohamed and Ravaux, Pierre User-centered visual analysis using a hybridreasoning architecture for intensive care units. (2012) Decision SupportSystems, vol. 54 (n° 1). pp. 496-509. ISSN 0167-9236 Any correspondance concerning this service should be sent to the repositoryadministrator: staff-oatao@inp-toulouse.fr.User-centered visual analysis using a hybrid reasoning architecture for intensivecare unitsBernard Kamsu-Foguem a,⁎, Germaine Tchuenté-Foguem b, Laurent Allart c, Youcef Zennir b,Christian Vilhelm b, Hossein Mehdaoui c, Djamel Zitouni d, Hervé Hubert d,Mohamed Lemdani b, Pierre Ravaux ba Laboratory of Production Engineering, EA 1905, ENIT, INPT, University of Toulouse, 47 avenue d'Azereix, BP 1629, 65016 Tarbes Cedex, Franceb Department of Biomathematics, EA 3614, Faculty of Pharmacy and Biology, University of Lille - North of France, 3 rue du Professeur Laguesse, BP 83, 59006 Lille Cedex, Francec Department of Intensive Care, Fort de France University Hospital, BP 632, 97261 Fort-de-France, Franced Department of Public Health, EA 2694, UDSL, Lille Institute of Management and Health Sciences (ILIS), University Lille - North of France, Loos, France⁎ Corresponding author.E-mail address: bernard.kamsu-foguem@enit.fr (B. Kamsu-Foguem).a b s t r a c tOne problem pertaining to Intensive Care Unit information systems is that, in some cases, a very dense dis-play of data can result. To ensure the overview and readability of the increasing volumes of data, some specialfeatures are required (e.g., data prioritization, clustering, and selection mechanisms) with the application ofanalytical methods (e.g., temporal data abstraction, principal component analysis, and detection of events).This paper addresses the problem of improving the integration of the visual and analytical methods appliedto medical monitoring systems. We present a knowledge- and machine learning-based approach to supportthe knowledge discovery process with appropriate analytical and visual methods. Its potential benefit to thedevelopment of user interfaces for intelligent monitors that can assist with the detection and explanation ofnew, potentially threatening medical events. The proposed hybrid reasoning architecture provides an inter-active graphical user interface to adjust the parameters of the analytical methods based on the users' task athand. The action sequences performed on the graphical user interface by the user are consolidated in a dy-namic knowledge base with specific hybrid reasoning that integrates symbolic and connectionist approaches.These sequences of expert knowledge acquisition can be very efficient for making easier knowledge emer-gence during a similar experience and positively impact the monitoring of critical situations. The providedgraphical user interface incorporating a user-centered visual analysis is exploited to facilitate the naturaland effective representation of clinical information for patient care.Keywords:Intelligent user interfaceVisual computingConnectionist-symbolic integrationKnowledge acquisitionIntensive care unitsMedical monitoring1. IntroductionThe dynamic environment sets special requirements for context-aware hospital applications to provide users with appropriate ser-vices and to offer a suitable interface to users [9]. The medical domainis particularly interesting for the application of techniques for visual-izing time-oriented data that is essential for analysis activities inmany application scenarios. A better integration of visual, analytical,and user-centered methods is key to adapting visual and analyticalmethods to the user's task at hand. The goal of model visualizationis to allow the user to form clear mental images of a model's structureand function [56]. The hybrid connectionist-symbolic approach todrive user-centered visual analysis seems to be promising for thefield. It eases the implementation of a task-orientation specificationto suggest and parameterize the visual, analytical, and interactionmethods. The user interface of the proposed hybrid reasoningarchitecture gives a physician a discrete overview of a patient's status(through clinical phases or “scenes”) and detects clinically meaning-ful abnormalities. In fact, the progression of different degrees of pa-rameter abnormalities is represented by a sequence of clinicalphases, which reflects the involved predominant physiologic process(e.g., increased blood gas pressures, vasodilatation, and hypotension).To do so, conceptualizing/representing the knowledge of some underly-ing reasoning that paves the way for specialized problem-solving ex-pertise is important [5]. A formal conceptualization of the implicitknowledge emerging during concrete actions can be exploited to notonly have accurate and effective knowledge bases but also dynamicallyadapt to changes [53]. In the user interface management, a knowledgecapitalization process can offer the user a way to reuse the cumulativeexperiences in browsing through patient records [27], which requiresexpert interface to capture domain knowledge in the form of a physio-logical/process model.In Intensive Care Units (ICUs), there exists a crucial need for intel-ligent monitoring systems that can help the physician to deal with themassive information flux. ICUs present intrinsic characteristics thatmake the reasoning and decision-making problem totally differentfrom other clinical areas [59]. To improve medical care management,more innovative tools are required [21]. These tools will help physi-cians to interpret clinical parameters more quickly and to choosethe appropriate treatment for the patient among many differentoptions [30]. In such circumstances, User Interface Engineering canbe a valuable tool in the medical domain because it is a think tankthat explores user experience, design, and the usability of technology[54]. Unlike the traditional design in which the goal is to make the ob-ject or application physically attractive, the goal of user interfacedesign is to make the users' interaction experience as simple andintuitive as possible [63]. A review of intelligent human-machineinterfaces in light of the ARCH model [40] has shown that the devel-opment of interface architectures based on artificialintelligencetechniques (using the knowledge of the user's cognition) can be in-corporated into a user interface to ease the task of the human user.The need for intelligent patient monitoring systems is continuous-ly reinforced by the necessity to automatically build a concise view ofthe patient's evolution to work “in understanding” with the user.Some studies try to capture automatically the way the user interactswith the system [41,71]. Yen and Acay demonstrated that throughmonitoring the user's actions, the system can determine the user'sintentions and transform the deduced intentions into system actions[41]. Understanding the user's implicit actions allows the effective-ness of the user interface enhancements to be assessed with a reduc-tion in the number of operations performed by the user to achieve aspecific goal while using the GUI. Kumar and Sekmen showed howIntelligent User Interfaces (IUIs) improve the communication be-tween humans and machines when the interface technology makesthe leap from a passive tool-set to a proactive assistant [71]. In fact,the studied User Interfaces use machine learning to improve their in-teractions with humans (information filtering, data value productionand command generation). For example, by inducing suggested datavalues based on previously observed values, the system reduces thedata entry time for a human operator and improves the human'sperformance at a task with the quality of the data.Studying interactive techniques for the visual analysis of time-oriented data is essential for building targeted user interfaces. Theinformation gained by these techniques can support the analysisand visualization process to provide additional guidance to users.For example, during their respective reasoning (e.g., to detect eventsof temporal data abstractions [11,64], practitioners would filter, map,and render information from data objects with the aim of takingadvantage of the visual analysis methods capabilities to do the follow-ing [36]: i) diagnose the pathology of the patient according to thesymptoms expressed by the patient, the observations or analysis ofthe doctor and the already known health problems of this pattern;and ii) determine the best possible therapeutic procedures. Thismethod fits with knowledge-assisted visualization that providessome opportunities to update and share knowledge through visuali-zation [70]. Studying tighter combinations of analysis steps andevent-based visualization could at least result in new, powerfulmeans for the visual analysis of time-oriented data. The user interfacemust provide different specification methods to allow the system togive relevant visual information based on the physician's experienceand interaction (e.g., expert, common and less-experienced visualiza-tion users).The rest of this paper is organized as follows. We discuss inSection 2 the state of the art, including the user interface issue inthe medical domain and information visualization with user-centered visual analysis. Then, in Section 3, we highlight the impor-tance of the Connectionist-Symbolic Integration used for generatingcontextualized visual representations in the user interfaces. A de-scription of its reasoning mechanisms, useful for extracting and auto-matically highlighting the relevant information from time-orientedis also presented in the Aiddiag's software architecture. Indata,Section 4, the impact of such architecture is illustrated for the intelli-gent or knowledge-based visualization of medical data. In Section 5,we provide some information about the effective use of the systemin the intensive care unit at a University Hospital. We outline inSection 6 the lessons learned on the implementation of our approachand note our findings and future works in the interactive informationvisualization.2. State of the art2.1. Related works: user interfaces within intensive care unitsIn the last few years, the user interface has proved to be a valuabletool in the medical sector for assisting medical doctors and variousphysicians (e.g., anesthetists [44] and neonatologists [49]) in manyapplications (e.g., oncological, cardiovascular [7], and respiratory as-pects [22]). In the Intensive Care Unit (ICU) domain in particular,the applications range from software to supervise patients throughquality scenario controllers to integrated strategic decisions.Boaz and Shahar developed IDAN/KNAVE-II [7], a conceptual andpractical architecture that fully implements the temporal-abstractionmediation approach. The KNAVE architecture comprises three types ofmodules: the temporal-abstraction module, knowledge-acquisitiontools, and the information visualization module. The KNAVE-II intelli-gent (knowledge based) interactive interface is used to monitor andexplore time-oriented clinical data and their abstractions. An earlydescription of the KNAVE-IIinteractive visualization module andconceptual interface was made by Shahar and Cheng [60,61], and theinterface itself and its semantics was described in detail later [62] andevaluated for its functionality, completeness, correctness, and usability[45]. The IDAN/KNAVE-II combined architecture supports multipleapplications, such as in a project focused on the assessment of the qual-ity of guideline-based care (mainly in the domains of oncology and an-tihypertensive therapy). Some knowledge-acquisition enhancementsare needed, both for the display of the definition of existing periodicand linear patterns and for the specification of new patterns.The systems described here illustrate that choosing between spec-ificity and generality is not easy. Many systems are typically devel-oped for a very narrow, specific application that lends itself torule-based approaches (e.g., VIE-VENT [49] or SENTINEL [44]) orconnectionist and statistical approaches (e.g., RESPAID [12]). Howev-er, the lessons learned and their success is limited to their domain ofexpertise. Meanwhile, generic architectures endeavor to support sev-eral application domains and strive for flexibility, modularity, andease of expansion (e.g. SIMON [20], Aiddiag [12] and IDAN/KNAVE-II[7]). This generality is often at the expense of expertise and perfor-mance in specific domains [25]. In this study, we have adopted thesecond approach with a focus on connectionist-symbolic integration,which combines machine learning and structured background knowl-edge representation.We follow this later approach and adopt a general framework ofknowledge representation and reasoning (namely the Think!-basedAiddiag framework [12,69]), and we aim to build an IUI consideringtraces of computer use as experience knowledge containers to sup-port a comprehensive visual analysis. Furthermore, this generalframework allows, using heterogeneous computing techniques, shar-ing and exchanging information between two or more medical com-puter systems (but designed and implemented independently).Within the ISIS (Intelligent Survey for Information Systems) program[48], we make some extensions in the Aiddiag framework by develop-ing new modules for medical research at the bedside in critical careunits. The position exposed in this paper is clearly a user-centered ap-proach [6] in which the system can offer visualization assistancebased on its knowledge of the user's aims. The main conclusive ideathat we can draw from this part is that most of the user interfacesused in the healthcare domain are traditional (contrary to theseapproaches, our objective is to propose something new: an intelligentapproach).• Clustering methods reduce the number of data tuples by findingexpressive representatives for groups of tuples.2.2. Integration of visual, analytical, and user-centered methodsThe explicit representation of reasoning methods is an essentialfeature for building a flexible system that offers various methods tosupport visual analysis and decision making. Interactive explorationand browsing information are means for a successful visual analysis.Displaying the relevant information on the screen according to thiscontext is useful as a medicine schema or patient record, for example,to enable the physician to access medical records and x-ray imagesusing IUIs while performing the diagnosis. More generally, thetemporal context is essential to decide which properties are initiatedor terminated by the occurrence of an event [34]. Furthermore, thephysicians could check if their action or decision is carrying theright medicine for the right patient. A typical example is the follow-ing: in the case of a patient with a respiratory health problem (e.g.,respiratory insufficiency or pulmonary edema), certain diagnosesshould not be overlooked before the patient can receive artificialventilation [67].In general, information visualization is a strategic component toachieve several goals (intuitive data formats, emphasizing subtleaspects of reasoning and information overload prevention). Chittaro'sclassification of such goals [14] may also be used to describe thesystems in the table along with some other criteria (e.g., expertknowledge adaptation [51], completely static vs. dynamic, complexi-ty, hospital-tested). We note some works in IUIs in medicine thatwere applied to patient populations, such as the IPBC (Interactive Par-allel Bar Charts) system [16]. The main feature of IPBC is a visual datamining (VDM) system devoted to the interactively analysis of collec-tions of time-series, and its application to the real clinical context ofhemodialysis was shown. There are recent works regarding the intel-ligent (knowledge-based) visualization of clinical data and the inter-pretation of those data of patient groups, such as those described byKlimov et al. [37–39].In fact, a typical survey of intelligent information visualizationmethods was performed by Aigner et al. [2], and they performedanother work involving visual analytical methods [3]. They haveelaborated on a categorization schema (based on time, data, andrepresentation criteria, such as 2D vs. 3D and static vs. dynamic)that is intended to help clarify a variety of concepts and methodsfor analyzing time-oriented data [2]. The concepts of temporal dataabstraction, principal component analysis, and clustering are detailedto illustrate the usefulness of a tighter integration of visual andanalytical methods:• Temporal data abstraction reduces value ranges from quantitativevalues to qualitative values, which are much easier to understand.• Principal component analysis reduces the number of variables byswitching the focus to major trends in the data.To emphasize relevant information according to the users' needs, theyproposed a task-driven approach called event-based visualization [3].Combining event-based methodology with visualization approacheseases the integration of the user into the visual analysis process. The op-erational model of event-based visualization consists of three majorsteps (Fig. 1): event specification (i.e., describing user interests), eventdetection (i.e., finding relevant data portions), and event representation(i.e., considering user interests in visual representations). The descriptionof user interests as formal event types can be specified with event formu-las directly, by parameterizing event type templates, or by selecting froma predefined application-specific collection of event types. The basic ideais to find events in the data and then trigger automatic parameter adjust-ments aimed at generating better targeted visual representations of theclinical information. Additionally, there are other research studies onthe knowledge-based, or ontology-based, visualization of clinical data,such as the classic theoretical and practical work by Cousins and Kahn[18] and Chittaro et al. [15,16].The logic of use can be attached to the visualization process to givefuture users a simple and adapted means to their work objectiveswithin a mixed perspective synthesizing theoretical and empiricalknowledge on clinical reasoning [13]. For example, the change inthe level of artificial ventilation control makes translating the inten-tion of a physician to modify the volume of oxygen taken in by thebody possible. This scenario refers to a sequence of user operations:to place the cursor on the level, to erase the old level, to keyboardthe new level, then to validate or position the cursor on the level, toselect another level in a list, and then to validate. To perform thisscenario, key domain concepts are useful for knowledge clarification,and they allow one to get lessons with learned descriptions that aresignificant [35]. These lessons would enable the practitioner tointeract in a natural manner with adequate assistance in the monitor-ing tasks.3. A connectionist-symbolic approach to support knowledge-assisted visualizationBecause no single knowledge formalism can model all the possiblepatterns in the medical knowledge, we suggest that a combination offormalisms and pattern-specific reasoning methods could achievebetter results [28]. There are both technical and philosophical reasonsfor this suggestion. First, each separate knowledge formalism offers adifferent set of expressive capabilities appropriate for specifying adifferent set of properties clearly and concisely [50]. Furthermore,the complexity of the medical domain requires the use of multipleapplications of artificial intelligence technologies (e.g., medical plan-ning, diagnosis and treatment) and implementing several knowledgerepresentation schemes (e.g., rule-based reasoning, artificial neural net-works) that do not overlap [52]. Therefore, the proposed methodologyFig. 1. The model of event-based visualization [3].is based on the use of a neuro-symbolic formalism called Think! [69],which takes inspiration from the cognitive and neural mechanismsbut also allows symbolic interpretation or interaction with symboliccomponents. In the Think!-based Aiddiag framework, we have devel-oped a visually driven analysis support system for medical knowledgemanagement, aimed at helping the patient's healthcare team (doctors,physicians, biologists, etc.)3.1. Connectionist-symbolic integrationTraditional symbolic Knowledge-based Systems (KBSs) are well-designed to handle expert knowledge represented by symbolicrules. Connectionist systems are powerful tools used to learn andgeneralize knowledge obtained from practical cases (including uncer-tain and imprecise data). NéoGanesh [22] and VIE-VENT [49] areexamples of rule-based systems that determine the optimal treat-ments for patients based on clinical and experimental guidelinesand protocols. In contrast, the works of Stacey and McGregor areconcerned with the applications of results from machine learningprocesses to data streams to detect adverse clinical conditions [64].Thus, combining these two approaches will explore their comple-mentarities to improve overall system performance with integratedreasoning and learning capabilities. Neural-Symbolic Learning Sys-tems contain six main phases [19]: (1) symbolic knowledge insertion,(2) inductive learning with examples, (3) massively parallel deduc-tion, (4) theory fine-tuning, (5) symbolic knowledge extraction, and(6) feedback (see Fig. 2). The major hypothesis of our proposedapproach is to use a hybrid connectionist system for building intelli-gent interfaces. This approach could help to suggest recommenda-tions for the elaboration of adapted information visualization andanalysis to ease further decision making. Hybrid connectionist sys-tems are computational systems that are based mainly on artificialconnectionist networks but also allow symbolic interpretation or in-teraction with symbolic components [65].The motivation for examining hybrid connectionist models is toprovide different processing mechanisms that can bridge the widegap between, for example, data acquired from biomedical equipmentand knowledge resulting from medical expertise. First, different cog-nitive processes are not homogeneous, and as expected, they arebased on different representations. Therefore, there is evidencefrom cognitive science and neuroscience that multiple architecturalrepresentations are involved in human processing. Second, from thepoint of view of KBSs, hybrid symbolic and connectionist representa-tions have some advantages. Even different, mutually complementaryproperties can be combined. Symbolic representations have theadvantages of easy interpretation, explicit control, fast initial coding,dynamic variable binding and knowledge abstraction. Connectionistrepresentations, however, show the advantages of gradual analogplausibility, learning, robust fault-tolerant processing, and generaliza-tion. Because these advantages are mutually complementary, a hybridsymbolic connectionist architecture can be useful if different process-ing strategies have to be supported [50].The use of techniques from the field of Connectionist-SymbolicIntegration and autonomous widgets provides a new complementarystyle of human-computer interaction,in which the computerbecomes an intelligent, active and personalized collaborator. Autono-mous interface widgets are computer programs that employ ArtificialIntelligence methods to provide active assistance to a user of a partic-ular computer application. The metaphor used is from a personalassistant collaborating with the user in the same work environment.The assistant becomes gradually more effective as it learns the user'sinterests, habits and preferences. To summarize, instead of the useradapting to an interface, an IUI can adapt to the user and its environ-ment. The IUI tries to determine the needs of an individual user andattempts to maximize the efficiency of the communication. Thisapproach is similar to an agent development toolkit according tospecifications for interoperable agent-based systems [68].3.2. Think! formalism: a connectionist-symbolic representation schemeBuilding a complete diagnosis support tool would require the useof several techniques, including decision trees, first-order logic expertsystems, and a trained neural network. All these techniques havetheir own preferred field of application, and they do not overlap.Requiring a user (developer, physician or biologist) to employ a singletechnique for a task may force undesirable restrictions on the expres-sion, analysis or production of a solution.Introduced by C. Vilhelm, the Think! formalism is a unifiedconnectionist-symbolic representation scheme that tries to subsumeseveral formalisms currently used in the ICU [69]. Vilhelm suggestedthat the addition of a pattern recognition capability using Connectionist-Symbolic Integration would allow the development of systems thatwould meet the stringent and complex requirements of the medical envi-ronment. The Think! formalism can be more easily updated thanrule-based systems, and it is useful in discovering knowledge fromphysiological data and their correlation with clinical events [69]. Beingable to integrate these knowledge representation schemes in a singlemodel enables us to use existing knowledge bases and existing knowl-edge extraction techniques to make them communicate and work togeth-er. Think! is based on a connectionist structure but is sparsely connectedto have explicit paths. We have introduced symbolic representationobjects into this network, together with the concept of propagatingtruth values associated with these symbols. Adding weights (data asFig. 2. Neural-symbolic learning systems [19].weights to either side of a balance) helps to strengthen or to weaken theidentified conclusions.The Think! formalism is based on three structure elements:containers, processes, and tubes. Containers hold the information(excitations), processes make calculations, and tubes transport theinformation. The structure elements define a network representingthe knowledge base. Reasoning is achieved by propagating excita-tions through the network from one element to another and makingcalculations based on these excitations. The information obtainedwith the calculations help fine-tune the network to better character-ize the knowledge domain. The symbolic knowledge extracted isanalyzed to enable the essential interaction between the networkand the external environment. The role of each of these elements isdescribed explicitly above (Fig. 3):• Containers are named data holders. They have only one input re-ceiving new values that change the internal state of the containerand one or more outputs transmitting the container's state toother elements of the network. The containers are the elementsby which an external system can communicate with the network.They are represented by rectangles.• Processes are the active elements of the network. They performcalculations on their inputs and produce a result that is transmittedthrough one or more output tubes. They are represented by circles.• Tubes are oriented links propagating the information from one elementto the other elements of the network. Tubes have characteristics such asweight, which attenuates or amplifies the propagated information, andlength, which conditions and respects a given delay of the propagationsat a given speed.The structure elements define a network representing the knowl-edge base. The information circulating in the network is called an excita-tion, which is the association of a numerical value with its truth value.Reasoning is achieved by propagating these excitations through thenetwork from one element to another and by making calculations onthese excitations. All numerical truth values are represented with fuzzyintervals.In Fig. 3, the window “3D visualization of a Think! Network” con-sists of two parts:• The left frame contains a display of a 3D movie of the Think! networkfor the interactive visualization of information processing. The 3Dmovie facilitates the task of the user by connecting the networksto his/her domain objects and attracts the user's attention onknowledge processing.• In the right frame, the settings of the different manipulation optionsare shown. The action ‘visualization’ allows the parameters of the3D objects to be seen; the action ‘creation’ allows a new Think!Internal knowledge representation and processing ContainerFig. 3. The 3D visualization of a Think! network.network to be built and the action ‘optimization’ allow the currentprogression of the information processing to be optimized. Drivingthe knowledge discovery with appropriate navigation operators isalso possible by visualizing the sequential pattern analysis de-scribed by Think! networks.When an excitation is in transit inside a tube, it is called a propa-gation. Each container and process has a function (called an activationfunction) that will be activated whenever a propagation reaches theelement. An activation function computes the output excitationfrom the input excitations and can also create or modify any elementof the network. The input process tubes are ordered, and input excita-tions are dated upon arrival. The movement of each propagation isensured by a specific rate-regulator with a basic time unit called atick. At each tick, all the propagations are moved, and if some reacha container or a process input, the corresponding activation functionis executed, and the result is carried out. Think! is a polyvalent knowl-edge representation formalism that simultaneously enables the use ofpreviously expressed knowledge in different formalisms by maximal-ly preserving the capacities for explanation of the reasoning and byacquiring new knowledge in a semi-automatic way. In a nutshell,the knowledge is represented by a symbolic language, whereas thededuction and learning are performed by a connectionist engine.For a more detailed description about this formalism, the reader canrefer to Vilhelm et al. [69].3.3. Aiddiag: a modular software architectureIn the Think!-based Aiddiag framework, we have developed aComputer-Assisted decision support system for medical knowledgemanagement to help the patient's healthcare team (doctors, physi-cians, biologists, etc.). As part of the Aiddiag project, to help thephysician, we have to build a central low-cost workstation to beplaced at the patient's bedside and that acts as a unique informationdisplay and interpretation system. The data produced by monitoringequipment is supposed to help the medical staff better diagnose andmonitor the evolution of the patient's status. The potentially availabledata include heterogeneous sources, such as blood gas partial pres-sures, hemodynamic parameters, or ventilator settings. The Aiddiagsystem has been designed to accommodate different types of data:images, parameters originating from ambient sound, therapeuticevent information and data that is retrieved from external databasesand knowledge bases. We have proposed data-driven techniques toimprove the exploitation of raw data coming from medical devicesthat are present at the patient's bedside. Clearly, a set of relevantindices has to be derived for the automatic recognition of complexclinical scenarios and the efficient detection of dangerous situations.To minimize the introduction of a priori knowledge, Calvelo et al.[10] describe a data-oriented methodology for the extraction oflocal trends from a set of raw physiological data and report itson-line application in the working Aiddiag platform. For example,acquiring and processing complex medical data (e.g., respiratoryfrequency (Fr), arterial hemoglobin oxygen saturation [SaO2]) andsignals (e.g., the detection of mechanical abnormalities, disconnec-tion, overpressure, very low levels of CO2), from biomedical devicesis possible. These data are checked, filtered, and described in theworking format before being transmitted to the database. Theadaptation of the GARCH method [24] improves the quality of thesymbolic time series transformation to construct a typical parameterevolution or scenario. GARCH models have been extensively investi-gated in the econometric domain and are employed commonly toanalyze the unpredictable movements of a time series. These modelsprovide an essential means for reliably capturing time-varying vola-tility (i.e., periods of swings followed by periods of relative calm)and effectively managing risk.Aiddiag is based on a totally modular architecture to allow acertain level of flexibility in varying circumstances, making theencapsulation of knowledge and expansion of the KBS by incrementaldevelopment easy. The Aiddiag architecture was re-designed toprovide a significantly more reliable infrastructure [4] (Fig. 4). Theapplication is built as an assembly of storage and module layers,implementing a simple function including data acquisition, datadisplay, and alert evaluation. There are four types of modules: thekernel controls Aiddiag's behavior, drivers acquire the data frombiomedical equipment, computing modules compute the data anddisplay modules show the data. Each module comes with its data asa separate shared memory segment (storage layer) that is availableto the other modules. The storage layer answers queries from othermodules and triggers alerts and alarms based on the data present inthe shared memory when pre-set thresholds are exceeded. TheAdgVariables are programming variables that are used to store dataand inform the modules of updates. All modules are loadable orunloadable dynamically without interrupting the application. Themodules can communicate through a messaging system, and whenFig. 4. Architecture of the Aiddiag's software [4].a module fails, its data remains available for the others. There are twotypes of modules, which differ in the way their information isdisplayed:• Modules without a graphic interface, such as the driver module thatis in charge of clinical data acquisition from biomedical equipment(e.g., the measure of the respiratory exchange ratio (VCO2/VO2).The driver module connects to the equipment with the availablecommunication medium (e.g., serial line, analog line, switched orwireless network). If a module crash is detected, the faulty moduleis restarted automatically by the kernel that controls Aiddiag'sbehavior, which is itself redundant and fault-tolerant. The computa-tion module is a neuro-symbolic engine for medical knowledgerepresentation and reasoning. With the processing of representa-tive parameters, for example, it defines the current state of thepatient and the evolution of that state. The knowledge base (includ-ing the medical knowledge acquired from data) should be easilyunderstandable so that the physician can judge the relevance ofthe rules and possibly develop his/her own rules that he/she maythen integrate into the system to test their accuracy.• Modules with a graphic interface, using contextual menus andwidgets (user interface elements such as buttons and drop lists),try to make the user interface as usable and useful as possible forthe medical staff. Aiddiag interface widgets mix graphical andartificial intelligence features, and they stay both in the Computingand Display modules. The integrating IUI in the Aiddiag's architec-ture allows a more comprehensive view of the time course of thepatient's state to be built, thereby giving it the ability to manageseveral therapeutic strategies depending on the patient's state.These strategies enable the synthetic visualization of a clinicalsituation by providing real-time video,imagery, diagrams andtextual information. For example, the status bar module located atthe top of the computer screen displays the current global statusof the patient (e.g., OK or alarm) along with his medical historyand a one-line text message (alarm text, event). The history canbe browsed to see what happened some time ago or to examine aspecific event. This knowledge-driven user interface is suitable tomodel and capture a substantial part of the physician's expertise.In user interface management, a widget engine is a software serviceavailable to users to run and display applets on a graphical user inter-face [63]. The automatic linking of widgets includes detecting a triggerevent associated with a first widget and providing access to a secondwidget in response to the trigger event in a respiratory system(Fig. 5). In such a respiratory system, a communication path or channelis established between widgets to share information to connect the leftlung with the right lung. A widget link manager is used to automaticallyestablish links between widgets and designate shared information, re-strictions or arrangements.The visible sequence in Fig. 5 derives contextual information fromsensors that monitor the clinical situation and provides active features7within the various components of the respiratory system. These thenalert physicians with hints and stimuli on what is going on in eachparticular context. The user can select other components of interestand get details on demand or perform a zoom-in/zoom-out of theexamined organ, causing a dynamic rearrangement of the organs andwidgets that are displayed. This example illustrates how the Aiddiaginterface widgets actually adapt themselves according to the contextacquired from the medical sensors or user actions. Therefore, thecomputing tool allows an easy modeling of medical processes andprovides a number of means of analysis (e.g., segmentation, clustering,detection of events) for both quantitative and functional properties(e.g., completion time, workloads, critical path, data flow, processtype, multistep simulation). In addition, the explanation facility enablesthe user to see an explanation of the reasoning used by the knowledgebase system to reach a given conclusion. The user can consequently ask“why” a conclusion was reached, and the system will explain its reason-ing in a human-readable form.4. Application to the intelligent (knowledge-based) visualizationof clinical dataMedical user interfaces need to adequately take into accounteffective presentations and interactions with data, information, andknowledge. These goals are also achieved by the computer-assisteduse of visual processing to gain understanding with three goals [14]:• to visually present medical data in more intuitive formats that areeasy to understand, easy to learn, easy to recognize, easy tonavigate, and easy to manage;• to visually magnify subtle aspects of the diagnostic, therapeutic,patient management, and healing process, which otherwise couldbe difficult to notice;• to prevent information overload and allow members of the clinicalstaff to master larger quantities of previous information.Medical user interfaces require some intelligent modules forknowledge acquisition and global automated real time monitoring,including the detection of technical hitches and human faults toreduce the lost work time [48]. For this aim, we link user interfaceto an inference engine in the Aiddiag tool. We propose scenario recog-nition as a technique for temporal reasoning in medical domains: thetime-course of a clinical process is compared with a predeterminedset of possible behaviors for this process [23]. This recognition allowsus to anticipate forthcoming events from the partial instantiation ofthe recognized scenario and to intervene in the process, for example,to prevent specific expected (undesirable) situations.The Aiddiag-associated tool provides some intelligent assistancemodules that will more specifically help the specialists, includingbiologists and doctors, with precise facts that are difficult to explainotherwise. Indeed, the system can provide some medical adviceunselected by the doctors but equally or even more accurate than123Fig. 5. A sequence of expert knowledge acquisition.the doctor's options because it studies different scenarios accordingto its medical knowledge base and the evolutionary data of thepertaining diseases or infections. Specific information concerningthe patient (e.g., morphology, type of pathology) and the foreseentherapy (e.g., adjustment of respiratory assistance to the patient'sneed) are specified by the physician in charge of the system's initial-ization. The user interface shows all useful information (respiratoryparameters, blood-pressure, etc.) to the clinical staff and predicts anunknown state (the etiology of a clinical problem or future prognosisof patient) from the current known states. Thus, the interface enablesthe physicians to choose appropriate actions over time to influencethe evolution of the patient's state.Aiddiag's software architecture illustrates the interest of the pro-posed approach to help the user easily understand the knowledgebase to visualize a reasoning or decision-making process. The benefitsof the use of computers in health care will be delivered if we designcomputerized medical assistants that can efficiently relieve theclinical staff of repetitive tasks, and more importantly, really supportpractitioners in their decision-making in real time. Plan recognitionand user modeling techniques enable the system to infer the user'sgoals and plans using evidence from the user's input and previousinteractions with the system [46]. The basic idea is presented here.The system should observe the user's actions and interpret theseactions in terms of his/her possible goals and plans. Aiddiag includesa limited goal recognition mechanism so that it may recognize thegeneral context of the users’ actions and possible problematic situa-tions. Aiddiag supports semantic modeling and formal reasoning toprovide context-aware actions (e.g., delivering contents, adaptingapplications or running applications), and it can free the user fromlearning complex command languages.4.1. Detection and creation of medical sequencesIdentifying user-dependent information that can be automaticallycollected helps build a user model (1) to predict what he/she wants todo next and (2) to perform relevant pre-processing tasks. Suchinformation is often relational to the user's tasks and best representedby a set of sequences. Therefore, we need to know the sequence ofactions made by the practitioner on the graphical user interface(GUI) to know which parameters he/she asked to be displayed andwhat modifications he/she made on these parameters. The idea is tolearn by observing the user, i.e., by finding regularities in the user'sbehavior and using these regularities for prediction. Context manage-ment incorporates the widget management network that generatesthe necessary knowledge for a decision on the selected actions toprovide context-aware support[42]. The widget managementnetwork is responsible for creating the Think! network representingthe sequences of the actions and uses the rules in the knowledgebase to activate adaptation. After a certain amount of time, whichcorresponds to the learning procedure, many sequences will exist inthe network. An analysis of these sequences will show which ofthem are most used. The credit assignment of reinforcement learningis achieved by weighing the various types of sequential actionsaccording to their observed occurrence. Which individual sequencesor scenarios are largely responsible for the success or failure of anaction in the medical context can then be determined. Thus, we willbe able to implement sequences and associated rules given by thephysicians and let the system refine them. After a certain learningtime, removing inadequate sequences and associated rules would bepossible.After a validation procedure, the information generated by theactivation function of the sequence processes will be used. Thephysician will not have to ask for specific parameters because theywill be automatically displayed. The characteristic of the system is thebinding of the widgets to the knowledge bases so that each of thesewidgets has associated semantics and the validation consequently hasa strongly contextual meaning. For example, the validation of asequence of actions aimed at the establishment of a diagnosis in lungpathology (e.g., affecting the transfer of gases and ventilation/perfusionrelationships within the lungs) is well distinguished from the validationof another sequence of actions leading to a treatment in defects ofrespiratory control (e.g., affecting the regulation of gas exchange andtherefore the respiratory pump).From a cognitive viewpoint, the detection and creation of medicalsequences are intended to provide optimal working conditions byremoving barriers to quality, productivity, and safe human perfor-mance. To adapt the knowledge base to the user's problem solvingstyle and to restructure the knowledge base to improve comprehen-sibility, having members of the health care staff who build themselvesa mental representation of the patient's case is useful. The userinterface widgets (buttons, drop lists, etc.) handled in the userinterface aim to enable a physician to partly visualize certain typesof information (trends, clinical conditions, view of respiratory system,time-stamped actions, etc.), share it with other physicians and makeit evolve through cooperation with other physicians. The Aiddiagdisplay can be updated in real time and also allow users to clearlyinteract with the GUI by selecting and modifying elements of theinterface. Moreover, this user interface strives to minimize thecognitive load (i.e., the level of effort associated with thinking andreasoning [66]) associated with operating the interface itself so thatall of a physician's cognitive resources are available for their tasksand the problems to solve. Thus, he/she would be more able to dealwith some unusual or unforeseen situations by a better utilizationof their clinical judgment to assess and treat their patients.4.2. An illustration of sequence creation for user interface elementsThe time of execution and temporal interval are pieces of informa-tion that may help capture the user's behavior. A sequence refers to aseries of ordered consequences (events or episodes) and will bedenoted throughout this paper by Pseq, but this technique can beunderstood as independent from the clinical domain. Sequences ofactions are represented by connections between widget managementnetworks of the active interface objects contained in the sequence.The battery device is used to detect the time between events. Whenan active object is selected by the user, a battery device is charged.The discharge of the batteries allows a simple mechanism to detectthe end sequence, or more precisely, the beginning of a new se-quence: if the charge of the previous object's battery is below agiven threshold, the new click is considered as a part of a newsequence and is not connected to the previously clicked object.When the user clicks on an object, its widget management networklooks for the previously clicked objects and creates a currentsequence with queries in the different system components. A logicallyordered set of Pseq elements holds valuable information, such astrends and patterns, which is used to improve medical monitoringand medical decisions. In the example shown in Fig. 6, the consequentPseq is derived from its corresponding widget management network.End Tidal CO2 (ETCO2 or PetCO2) determines the level of (partialpressure of) carbon dioxide released at the end of expiration, and itis directly related to the ventilation status of the patient. For example,ETCO2 monitoring may be used to verify if the tracheal tube is placedin the trachea and not in the esophagus before ventilating the patient.ETCO2 monitoring can also provide an early warning sign of shock fortrauma patients, cardiac patients and any patient at risk for shock.In the example shown in Fig. 7, VE denotes the minute ventilationof the lungs (i.e., the volume of air inhaled [inspired minute volume]or exhaled [expired minute volume] by the lungs in one minute). Mi-nute ventilation is calculated by taking the tidal volume and multiply-ing it by the respiratory rate (the number of breaths per minute aperson is taking). When an alarm occurs on the ETCO2 (End- TidalCarbon Dioxide – measured at the end of normal expiration), anexcitation is sent on the input of the ETCO2 container, activating thecorresponding network. When the physician wants to display theexpiratory minute ventilation, an excitation is sent to the input ofthe VE (Volume of Expired Minute Ventilation) container activatingits corresponding network. A process of the VE window managernetwork has an activation function that is looking for the objectwith the highest level of battery charge. Because the battery of theETCO2 object has the highest charge, a tube is created between thetwo networks at the level of the sequence process (Fig. 7). IncreasedETCO2 can reflect decreased VE or hypermetabolic states. DecreasedETCO2 can be caused by increased ventilation or states of low orabsent pulmonary blood flow or cardiac output [57].Thus, if the respiratory rate (RR) object is selected a few timesafter the VE (Volume of Expired Ventilation) object, the VE and RRobjects are connected (Fig. 8). If the tube already exists, its weightwill be reinforced with a value inversely proportional to the differ-ence of charges from the two batteries, i.e., it is reinforced more ifthe two clicks are close in time. If the previous sequence is repeated,then the weight of the tubes connecting the objects will be increased.When the learning phase is completed, the network is visualizedusing a 3D graphic tool. By exciting the starting point of a sequence(e.g., an event, such as the process representing the ETCO2 alarm inthe sequence chains), propagations will be sent through all thesequences originating at this event. The 3D representation allows usto follow the paths followed by the excitations, which represent thesequences of the actions performed during the learning phase. Thesequences that seem to be the most pertinent can then be introducedto the running of the system. More generally, given a set of respirato-ry parameters, relationships between attributes and parameters, suchas the presence of one pattern implying the presence of anotherpattern, can be identified. Sequential pattern analysis is useful in theinvestigation of relationships between parameters over a period oftime. For example, while monitoring ventilation, this analysis allowsthe identification of problems (e.g., ventilation asynchronies) beforethe patient's condition significantly deteriorates by providing anearly warning of an impending respiratory crisis, followed by auto-matically optimizing the ventilatory settings [29].To provide an intelligent assistance for the exploration of time-oriented clinical data, gaining knowledge about the problem solvingsteps from the observation of user activities and adapting the knowledgebase according to the lessons learned (success or weak points) is impor-tant [33]. The computational model underlying the Aiddiag interfacelearns and detects ICU-related clinical patterns (using an existing medicalknowledge base represented or previously learned by the network) instreaming time-oriented ICU clinical data, with the sequences of eventsbeing learned in the user interface. The sequential pattern analysisdraws some learning from the “macro-operators” of the user actions onETCO2Widget Management PseqBattery Fig. 6. Activation of the network related to ETCO2 (measured at the end of normalexpiration).ETCO2ETCO2AlarmVEVEDisplay Widget Management Widget Management Battery ∆t1PseqPseqBattery Fig. 7. Relationship between the measurements at end of normal expiration and thevolume of expired ventilation.the interface, such as a chain of actions performed once the user performsthe first event in the chain. The GUI reasoning is able to suggest the appro-priate chain to apply given a single prefix with contextual parameterswhen there are several potential continuations: contextual data areused to customize the way the inputs are processed and increase the pre-cision of the information retrieval [31]. The purpose is to extract pieces ofknowledge that will convey an improved understanding of the patient'sclinical facts or circumstances and support helpful decision makingprocesses.5. A practical example for the monitoring of severe brain injurypatientsThe first evaluation of the characteristics of the Aiddiag architec-ture was performed in 15 rooms at the intensive care unit at theFort-de-France University Hospitalin Martinique (French WestIndies). A study was completely carried out with the system on theclinical outcome of severe brain trauma patients after episodes ofcranial hypertension [4]. The importance of continuous monitoringfor neurosurgical patients has been outlined in the ICUs, and comput-erized monitoring has showed clinical advantages over manualrecording (e.g., reliability of the number of critical episodes and theaccuracy of estimating the severity of a patient's injury) [72].The appropriate modeling and analysis of medical time-seriesallow behavioral models to be extracted after intensive computation.The neuro-symbolic engine is used for the implementation of severebrain trauma care algorithms and later comparison with thephysician's behavior. The neural network can detect a clinical prob-lem (critical patient condition) quickly, suggesting diagnostic proce-dures, while the knowledge extracted from it can explain theproblem later on. If misguided, the information can be used to finetune the learning system. In the case study, the Aiddiag frameworkcombined intelligent temporal analysis and information visualizationtechniques for information feedback to caregivers and critical carerecommendations for assessment purposes. In particular, the Aiddiaginterface was able to perceive the patterns of expressive visualizationand ease visual analysis for the detection of an intracranial hyperten-sion situation. It facilitates the review and interpretation of the pa-tient data by presenting color trends, plots, and charts on a screendisplay. Finally, the detection of certain critical patient conditions isimproved, and they are displayed in a more relevant manner.In addition, we mention the possible utilization of existingmethods pertaining to the well-known and important task ofmapping clinical knowledge and particularly clinical guidelines tothe patient's electronic medical record. Examples of such mappingETCO 2ETCO2AlarmVEVEDisplay RRWidget Management Widget Management Widget Management Battery ∆t1 ∆t2 Battery Battery PseqPseqPseqFig. 8. A sequence of actions in a Think! network.solutions that employ international standardized vocabularies andterminologies include those proposed by Boxwala et al. [8], Germanet al. [26] and Peleg et al. [55]. In particular, we have implementeda medical protocol for the ICU management of severe head injury[17] and incorporated the consensus guidelines produced by theBrain Trauma Foundation and the European Brain Injury Consortium.This protocol firstly considers the maintenance of cerebral perfusionpressure (CPP) and secondly the management of intracranial pressure(ICP) or mean arterial pressure (MAP). The specific patterns, regular-ities or sequences of events (scenarios) associated with this algorithmare used to evaluate the medical orders. The set of deleterious situationscan be determined to assess the presence or absence of medical reactionsand their relevance according to the theoretical objectives (Table 1 [47]).In the Aiddiag user interface, both the acquired information andthe calculated information are presented by data display modules.On the one hand, there are some generic display modules (e.g., phys-iologic signals or care plans) applicable to different activities. On theother hand, specific display modules are dedicated to a predefinedactivity [4]. An example of a physician-designed module for the mon-itoring of severe brain injury patients is shown in Fig. 9. The screenconsists of three parts:• In the left frame of the window, the monitoring frame permits thedetection of certain clinical conditions such as hypoxemia (thedecreased partial pressure of oxygen in the blood), hyperthermia(a greatly increased body temperature due to failed thermoregula-tion) or intracranial hypertension. A minimal increase in the intra-cranial pressure (ICP) due to compensatory mechanisms is knownas stage 1 of intracranial hypertension. An increased ICP in thebrain affects the nervous centers and causes periods of high vaso-constriction and blood pressure. The characteristics of stage 2 ofintracranial hypertension include a compromise of neuronal oxy-genation and systemic arteriolar vasoconstriction to increase themean arterial pressure (MAP) and cerebral perfusion pressure(CPP). Jugular venous oxygen saturation (JVOS) measurements areused to monitor global cerebral oxygenation and metabolism.JVOS monitoring has been very useful in detecting cerebral ische-mia (the lack of oxygen- and nutrient-rich blood flow in a givenarea of the brain).• In the middle frame of the window, some trends are extracted andanalyzed for monitoring and decision support. For example, thetrends of systolic arterial pressure (SAP), arterial occlusion pressure(AOP), and human body temperature (T) are calculated anddisplayed. AOP determines the minimum cuff pressure that stopsarterial blood flow distal to the cuff and provides a measure of thecuff pressure required to maintain a bloodless surgical field. SAP ismeasured when the pressure is at its highest in the arteries of thebody, which generally occurs at the beginning of the cardiac cyclewhen the ventricles are contracting. Hypotension (an abnormallylow blood pressure with SAP b 90 mmHg) is a frequent and funda-mental source of cerebral ischemia following severe brain injury.• In the right frame of the window, the list of time-stamped actions are onview in the Interface Verification Plan (IVP), and the text block linesare used to inform nurses about past, current or future prescriptions(for example, Glucose+vitamin, Colloid bolus+Vasoconstrictor infu-sion, Mannitol/Furosemide). The color legibility and consistency ofthe text block lines are improved with backgrounds of a hue similarto the text or, for increased contrast, of a complementary hue. Thepurpose of a text box is to allow the user to input text information re-lated to clinical events (such as allergic reactions resulting frommedications) to make them available for further analysis.This application has a user-friendly interface touchscreen that wasadapted according to feedback from the caregivers. The middle andleft frames of the window contain sufficient recorded information tojustify the diagnosis and warrant the treatment. These frames permitclinicians to track patients and their progress, follow a course oftreatment, and keep a service history. The proposed GUI developmentmethodology potentially results in some improvements in patientsafety and care provider performance and reduces medical decision-Table 1Specific scenarios and verification of the adequacy of the medical reactions that were performed.Parameter patternsDiagnosisMedical ordersICPMAPCCPAbove thresholdNormal rangeAbove thresholdAbove thresholdNormal rangeNormal rangeBelow thresholdNormal rangeBelow thresholdNormal rangeNormal rangeBelow thresholdBelow thresholdBelow thresholdNormal rangeICPeventMAPeventICPeventMAPevent & ICPeventNormalICPactionAdequateInadequateAdequateInsufficientMAPactionInadequateAdequateInadequateInsufficientMAPaction & ICPactionExcessiveExcessiveExcessiveAdequateFig. 9. A specific display module of the Aiddiag interface for the management of severe head injury.making errors. Most reasoning and decision-making errors in medicineare execution mistakes (goal, intention or action mistakes) and evalua-tion mistakes (perception or interpretation mistakes) [54]. Thesemistakes are due to incorrect or incomplete knowledge or other factors(e.g., faulty heuristics, misperception, and information overload). Theproposed approach enhances the clinicians' ability to perform tasksthrough the reduction of evaluation mistakes because they can bettercomprehend the information (e.g., the number and duration of criticalepisodes), analyze the situation (e.g., estimate the severity of a patient'sinjury), and make decisions (e.g., the intensity of the treatmentrequired). In fact, clinical performance is improved by displayingcontext-relevant information in layouts (consistent with the user'sclinical processes without appealing to any auxiliary interpretation)that provide advice and guidance to support the reasoning anddecision-making of critical care health providers.In addition, the hybrid architecture of the Aiddiag framework as itstands can be extended to deal with data mining methods withoutsignificant modifications to predict the evolution of patients in anICU [58]. The evaluation consists of the application of ratings,structured interviews, and simulations to the system [43]. Theinterviews and simulations provide insights into the types of infor-mation that the clinical staff would need to have on-line (e.g., inmonitoring situations) to interpret developing trend data more effi-ciently. Feedback from the users who operated the computerizeddecision support for patient monitoring in the operating room (phy-sicians, nurses, medical students) enabled the iterative adaptation ofthe interface design and interaction sequences to the monitoring anddocumentation tasks of the physician. Therefore, the enumeration ofthe possible solutions in terms of planning and actions optimizationallows the identification of the possible action plans for the realizationof a task. Such mechanisms enable users to improve their level ofperformance [32] as they are involved in their day-to-day activitiesusing the IUI. The evaluation, which also included the usability aspectsof the Aiddiag interface, was performed by our collaborators in theFort-de-France University Hospital. They tested the effectiveness (com-plement to the collaborative knowledge construction), efficiency (workload or time required to use), and subjective satisfaction (annotationinterfaces and visual feedbacks) by asking the user to complete varioustasks (e.g., following a guideline or making diagnoses) to collect exper-imental feedback.6. Conclusion and future workInformation representation and interaction style through theintensive care monitoring of very critically ill patients call for a visualand efficient analysis of that information for direct patient care at thebedside. We have described a methodology for the provision of auser-centered visual analysis to medical decision support systems thatbuilds on an existing methodology (Think!) and an existing ICU moni-toring system (Aiddiag). Using the Think! formalism, the Aiddiagdata-acquisition software is a standalone application adapted topatient data recording from biomedical devices and to caregiverinputs. The underlying computational framework is used for a better in-tegration of visual and analytical methods to filter, display, label, andhighlight relevant medical information from patient time-orienteddata. Thus, these methods may inform the physicians about a usefulevolution of the patient's state of which the physician would otherwisenot be aware. With improved user interfaces, such as graphical displayand data analysis, the GUI reasoning (detection of changes in thecontext, panels, etc.) can support medical reasoning (e.g., diagnosticmethods) with the advantages offered by an easy-to-use interaction.In addition, the hybrid reasoning architecture allows medical personnelto view the acquired data, assess the visual analysis processes inreal-time, and occasionally influence the diagnostic process on theapplication. The hybrid reasoning architecture learns the patterns ofuser actions in the interface and the acquired sequences represent insome sense the cognitive path followed by the physician after theevent. The analysis of these sequences will allow us to extract medicalknowledge from the interaction between the medical staff and the sys-tem when some elements of the context, such as the modification of aprescription, are also taken into account. Therefore, capturing domain-expert knowledge for further analysis with respect to medical guidelinecompliance is possible.The described medical interface takes advantage of the graphical ca-pabilities of the hybrid reasoning architecture to generate a visual anal-ysis for adapting applications in critical care settings. The computationalmodel underlying the interface detects ICU-related clinical patterns(using an existing medical knowledge base represented or previouslylearned by the network) in streaming time-oriented ICU clinical data.Consequently, it facilitates the diagnostic procedures and strategies byefficiently organizing the relevant information into the user interfaceof the medical monitoring systems and facilitates the actions requiredto achieve the target medical care in critical settings. The model notonly aims to improve the working conditions of the users but alsotakes part in an evolution of safety and effectiveness by a reduction inerrors, better control rates of risky procedures, and increases in healthcare quality. In contrast to visual interactive tools such as KNAVE-II[62] or [1] CareVis, which require a significant computer programmingeffort, the proposed tool is designed to facilitate the users’ tasks andallow an easy handling by medical doctors to formalize their knowl-edge. This system is based on a human–computer collaborative ap-proach involving contextual data exploration, semantic informationmodeling and knowledge construction in a close interaction with clini-cians for knowledge formalization and capitalization in the ICU domain.Undoubtedly, many improvements can be made to the proposedproject manipulation interfaces. Some results from evaluating the pro-posed approach in a real clinical setting and showing which concrete as-pects are improved with regard to other approaches would bediscussed. Many useful suggestions have been received from physiciansduring this experiment. We have analyzed and incorporated the follow-ing valuable comments and feedback collected during the test andevaluation process:• A better understanding of how and when useful (general) adaptationtechniques can improve the interaction between the interface andmedical practitioners, such as the tools and methods that providereliable development and the maintenance of the intelligent parts ofthe system taking into account contexts and expertise levels.• Limitations have been detected during the intensive calculation ofrelevant sequences to clarify the 3D representation of the possibleaction plans. Fine adjustments of the computation module to obtainoptimum performance will suppress these limitations. Artificialintelligence-controlled automated complex medical guidelines areunder evaluation.For future work, we wish to focus on a more detailed explanation onthe World Wide Web based knowledge capitalization and sharing pro-cess to disseminate methodological advances in health informatics or intranslational bioinformatics. Further work will possibly lead to studythe impact of human and technological resources availability on thewaiting time of admitted patients in ICU with a scheduling approachguided by the principles for prioritization of emergency response actions.In addition, we are taking account of computer network studies to sup-port collaborative works between healthcare teams, and an economic ap-proach is under consideration for the cost estimation of hospital services.AcknowledgmentsThis work was partly funded by the European program FEDER,under the ISIS (Intelligent Survey for Information Systems) project.References[1] W. Aigner, S. Miksch, CareVis: integrated visualization of computerized protocolsand temporal patient data, Artificial Intelligence in Medicine 37 (3) (2006)203–218.[2] W. Aigner, S. Miksch, W. Müller, H. Schumann, C. Tominski, Visualizing time-orienteddata — a systematic view, Computers and Graphics 31 (3) (2007) 401–409.[3] W. Aigner, S. Miksch, W. Müller, H. Schumann, C. Tominski, Visual methods foranalyzing time-oriented data, Transactions on Visualization and ComputerGraphics 14 (1) (2008) 47–60.[4] L. Allart, C. Vilhelm, H. Mehdaoui, H. Hubert, B. Sarrazin, D. Zitouni, M. Lemdani, P.Ravaux, An architecture for online comparison and validation of processingmethods and computerized guidelines in intensive care units, Computer Methodsand Programs in Biomedicine 93 (1) (2009) 93–103.[5] J. Andrade, J. Ares, R. García, J. Pazos, S. Rodríguez, A. Silva, Formal conceptualisation as abasis for a more procedural knowledge management, Decision Support Systems 45 (1)(2008) 164–179.[6] M. Ben Ayed, H. Ltifi, C. Kolski, A.M. Alimi, A user-centered approach for the de-sign and implementation of KDD-based DSS: a case study in the healthcare do-main, Decision Support Systems 50 (1) (2010) 64–78.[7] D. Boaz, Y. Shahar, A framework for distributed mediation of temporal-abstractionqueries to clinical databases, Artificial Intelligence in Medicine 34 (1) (2005) 3–24.[8] A.A. Boxwala, S. Tu, Q. Zeng, M. Peleg, O. Ogunyemi, R.A. Greenes, E.H. Shortliffe,V.L. Patel, Towards a representation format for sharable clinical guidelines, Jour-nal of Biomedical Informatics 34 (3) (2001) 157–169.[9] N. Bricon-Souf, C.R. Newman, Context awareness in health care: a review, Inter-national Journal of Medical Informatics 76 (1) (2007) 2–12.[10] D. Calvelo, M.-C. Chambrin, D. Pomorski, P. Ravaux, Toward symbolisation usingdata-driven extraction of local trends for ICU monitoring, Artificial Intelligencein Medecine 19 (3) (2000) 203–223.[11] M. Campos, J.M. Juárez, J. Salort, J. Palma, R. Marín, Reasoning in dynamic sys-tems: from raw data to temporal abstract information, Neurocomputing 72(4–6) (2009) 871–878.[12] M.-C. Chambrin, P. Ravaux, A. Jaborska, C. Beugnet, P. Lestavel, C. Chopin, M. Boniface,Introduction of knowledge bases in patient's data management system: role of theuser interface, Journal of Clinical Monitoring and Computing 12 (1995) 11–26.[13] Y.-J. Chen, Development of a method for ontology-based empirical knowledgerepresentation and reasoning, Decision Support Systems 50 (1) (2010) 1–20.[14] L. Chittaro, Information visualization and its application to medicine, ArtificialIntelligence in Medicine 22 (2) (2001) 81–88.[15] L. Chittaro, C. Combi, Visualizing queries on databases of temporal histories: new met-aphors and their evaluation, Data & Knowledge Engineering 44 (2) (2003) 239–264.[16] L. Chittaro, C. Combi, G. Trapasso, Data mining on temporal data: a visual ap-proach and its clinical application to hemodialysis, Journal of Visual Languagesand Computing 14 (2003) 591–620.[17] T.J. Clayton, R.J. Nelson, A.R. Manara, Reduction in mortality from severe head in-jury following introduction of a protocol for intensive care management, BritishJournal of Anaesthesia 93 (6) (2004) 761–767.[18] S.B. Cousins, M.G. Kahn, The visual display of temporal information, Artificial In-telligence in Medicine 3 (6) (1991) 341–357.[19] A.S. d'Avila Garcez, L.C. Lamb, D.M. Gabbay, Neural-Symbolic Cognitive Reason-ing, Cognitive Technologies, Springer-Verlag, Berlin Heidelberg, 2009..[20] B.M. Dawant, S. Uckun, E.J. Manders, D.P. Lindstrom, The SIMON project, modelbased signal acquisition analysis and interpretation in intelligent patient moni-toring, IEEE Engineering in Medicine and Biology Magazine 1 (1993) 82–91.[21] S. Delisle, B. Moulin, User interfaces and help systems: from helplessness to intel-ligent assistance, Artificial Intelligence Review 18 (2002) 117–157.[22] M. Dojat, F. Pachet, Z. Guessoum, D. Touchard, A. Harf, L. Brochard, NeoGanesh: aworking system for the automated control of assisted ventilation in ICUs, Artifi-cial Intelligence in Medicine 11 (1997) 97–117.[23] M. Dojat, N. Ramaux, D. Fontaine, Scenario recognition for temporal reasoning inmedical domains, Artificial Intelligence in Medicine 14 (1–2) (1998) 139–155.[24] R.F. Engle, Dynamic conditional correlation: a simple class of multivariate gener-alized autoregressive conditional heteroskedasticity models, Journal of Business& Economic Statistics 20 (3) (2002) 339–350.[25] L. Findlater, J. McGrenere, Beyond performance: feature awareness in personalized in-terfaces, International Journal of Human Computer Studies 68 (3) (2010) 121–137.[26] E. German, A. Leibowitz, Y. Shahar, An architecture for linking medical decision-supportapplications to clinical databases and its evaluation, Journal of Biomedical Informatics42 (2) (2009) 203–218.[27] C. Ghédira, P. Maret, J. Fayn, P. Rubel, Adaptive user interface customizationthrough browsing knowledge capitalization, International Journal of Medical In-formatics 68 (1–3) (2002) 219–228.[28] B. Guijarro-Berdiñas, A. Alonso-Betanzos, O. Fontenla-Romero, Intelligent analy-sis and pattern recognition in cardiotocographic signals using a tightly coupledhybrid system, Artificial Intelligence 136 (1) (2002) 1–27.[29] T. Guyet, C. Garbay, M. Dojat, Knowledge construction from time series data using a col-laborative exploration approach, Journal of Biomedical Informatics 40 (2007) 672–687.[30] R. Haux, Medical informatics: Past, present, future, International Journal of Med-ical Informatics 79 (9) (2010) 599–610.[31] J.-Y. Hong, E.-H. Suh, S.-J. Kim, Context-aware systems: a literature review andclassification, Expert Systems with Applications 36 (4) (2009) 8509–8522.[32] H. Hubert, C. Guinhouya, L. Castra, S. Soubrier, C. Vilhelm, P. Ravaux, M. Lemdani,A. Durocher, F. Saulnier, Methodological approach for the evaluation of the per-formances of medical intensive care units, Journal of Critical Care 22 (3) (2007)184–190.[33] H. Jabrouni, B. Kamsu Foguem, L. Geneste, C. Vaysse, Continuous improvementthrough knowledge-guided analysis in experience feedback, Engineering Appli-cations of Artificial Intelligence 24 (8) (2011) 1419–1431.[34] B. Kamsu Foguem, V. Chapurlat, Requirements modelling and formal analysisusing graph operations, International Journal of Production Research 44 (17)(2006) 3451–3470.[35] B. Kamsu Foguem, T. Coudert, C. Béler, L. Geneste, Knowledge formalization in ex-perience feedback processes: an ontology-based approach, Computers in Indus-try 59 (7) (2008) 694–710.[36] J. Klein, O. Friman, M. Hadwiger, B. Preim, F. Ritter, A. Vilanova, G. Zachmann, D.Bartz, Visual computing for medical diagnosis and treatment, Computers andGraphics 33 (4) (2009) 554–565.[37] D. Klimov, Y. Shahar, M. Taieb-Maimon, Intelligent visualization of temporal asso-ciations for multiple time-oriented patient records, Methods of Information inMedicine 48 (3) (2009) 254–262.[38] D. Klimov, Y. Shahar, M. Taieb-Maimon, Intelligent querying, visualization, andexploration of the time-oriented data of multiple patients, Artificial Intelligencein Medicine 49 (1) (2010) 11–31.[39] D. Klimov, Y. Shahar, M. Taieb-Maimon, Intelligent selection and retrieval of mul-tiple time-oriented records, Journal of Intelligent Information Systems 35 (2)(2010) 261–300.[40] C. Kolski, E. Le Strugeon, A review of intelligent human-machine interfaces in thelight of the ARCH model, International Journal of Human Computer Interaction 10(3) (1998) 193–231.[41] S. Kumar, A. Sekmen, Single robot — multiple human interaction via intelligentuser interfaces, Knowledge-Based Systems 21 (6) (2008) 458–465.[42] O.B. Kwon, The potential roles of context-aware computing technology inoptimization-based intelligent decision-making, Expert Systems with Applica-tions 31 (3) (2006) 629–642.[43] . E. Letsu-Dake, C.A. Ntuen, A case study of experimental evaluation of adap-tive interfaces, International Journal of Industrial Ergonomics 40 (1) (2010)34–40.[44] A. Lowe, R.W. Jones, M.J. Harrison, The graphical presentation of decision supportinformation in an intelligent anaesthesia monitor, Artificial Intelligence in Medi-cine 22 (2) (2001) 173–192.[45] S. Martins, Y. Shahar, D. Goren-Bar, M. Galperin, H. Kaizer, L. Basso, D.McNaughton, M. Goldstein, Evaluation of an architecture for intelligent queryand exploration of time-oriented clinical data, Artificial Intelligence in Medicine43 (1) (2008) 17–34.[46] M.F. McTear, Intelligent interface technology: from theory to reality? Interactingwith Computers 12 (4) (2000) 323–336.[47] H. Mehdaoui, L. Allart, D. Resiere, R. Valentino, B. Sarrazin, P. Ravaux, Informationsystems' contribution to patient care improvement: severe brain injury as amodel, Reanimation 19 (6) (2010) 512–518.[48] H. Mehdaoui, B. Sarrazin, I. El Zein, L. Allart, C. Vilhelm, S. Guerra, D. Zitouni, M.Lemdani, R. Valentino, A. Herbland, P. Ravaux. ISIS program: a new tool for med-ical research at the bedside in critical care units. 27th International Symposiumon Intensive Care and Emergency Medicine, Brussels, Belgium, 27–30 March2007. Critical Care 11 (Suppl 2) (2007) P439, http://dx.doi.org/10.1186/cc5599.[49] S. Miksch, W. Horn, C. Popow, F. Paky, Utilizing temporal data abstraction for datavalidation and therapy planning for artificially ventilated newborn infants, Artifi-cial Intelligence in Medicine 8 (6) (1996) 543–576.[50] J. Mira, Symbols versus connections: 50 years of artificial intelligence, Neuro-computing 71 (4–6) (2008) 671–680.[51] R. Oppermann, Adaptive User Support: Ergonomic Design of Manually andAutomatically Adaptable Software, In: in: Reinhard Oppermann (Ed.), Con-tributors, Lawrence Erlbaum Associates, Hillsdale, New Jersey, USA, 1994,253 pages.[52] B. Pandey, R.B. Mishra, Knowledge and intelligent computing system in medicine,Computers in Biology and Medicine 39 (3) (2009) 215–230.[53] S.C. Park, S. Piramuthu, M.J. Shaw, Dynamic rule refinement in knowledge-baseddata mining systems, Decision Support Systems 31 (2) (2001) 205–222.[54] V.L. Patel, J. Zhang, N.A. Yoskowitz, R. Green, O.R. Sayan, Translational cognitionfor decision support in critical care environments: a review, Journal of BiomedicalInformatics 41 (3) (2008) 413–431.[55] M. Peleg, S. Keren, Y. Denekamp, Mapping computerized clinical guidelines toelectronic medical records: knowledge-data ontological mapper (KDOM), Journalof Biomedical Informatics 41 (1) (2008) 180–201.[56] W.E. Pracht, Model visualization: graphical support for DSS problem structuringand knowledge organization, Decision Support Systems 6 (1) (1990) 13–27.[57] W. Rabitsch, A. Nikolic, P. Schellongowski, J. Kofler, P. Kraft, C.G. Krenn, T. Staudinger,G.J. Locker, P. Knöbl, R. Hofbauer, M. Frass, Evaluation of an end-tidal portable ETCO2colorimetric breath indicator (COLIBRI), The American Journal of Emergency Medicine22 (1) (2004) 4–9.[58] J. Ramon, D. Fierens, F. Güiza, G. Meyfroidt, H. Blockeel, M. Bruynooghe, G. VanDen Berghe, Mining data from intensive care patients, Advanced EngineeringInformatics 21 (3) (2007) 243–256.[59] A. Rector, AIM: a personal view of where I have been and where we might begoing, Artificial Intelligence in Medicine 23 (1) (2001) 111–127.[60] Y. Shahar, C. Cheng, Intelligent Visualization and Exploration of Time-OrientedClinical Data, Topics in Health Information Management 20 (2) (1999) 15–31.[61] Y. Shahar, C. Cheng, Model-Based Visualization of Temporal Abstractions, Compu-tational Intelligence 16 (2) (2000) 279–306.[62] Y. Shahar, D. Goren-Bar, D. Boaz, G. Tahan, Distributed, intelligent, interactive vi-sualization and exploration of time-oriented clinical data and their abstractions,Artificial Intelligence in Medicine 38 (2) (2006) 115–135.[63] B. Shneiderman, C. Plaisant, M. Cohen, S. Jacobs, Designing the User Interface: Strat-egies for Effective Human-Computer Interaction, Fifth Edition Addison-Wesley Publ.Co, Reading, MA, USA, 2010. 606 pages.[64] M. Stacey, C. McGregor, Temporal abstraction in intelligent clinical data analysis:A survey, Artificial Intelligence in Medicine 39 (1) (2007) 1–24.[65] R. Sun, Artificial Intelligence: Connectionist and Symbolic Approaches, Interna-tional Encyclopedia of the Social & Behavioral Sciences (2004) 783–789.[66] J. Sweller, Cognitive load during problem solving: Effects on learning, CognitiveScience 12 (2) (1988) 257–285.[67] F.T. Tehrani, Automatic control of mechanical ventilation. Part 2: The existingtechniques and future trends, Journal of Clinical Monitoring and Computing 22(6) (2008) 417–424.[68] M. Tentori, J. Favela, M.D. Rodriguez, Privacy-aware autonomous agents for per-vasive healthcare, IEEE Intelligent Systems 21 (6) (2006) 55–62.[69] C. Vilhelm, P. Ravaux, D. Calvelo, A. Jaborska, M.-C. Chambrin, M. Boniface, Think!:a unified numerical-symbolic knowledge representation scheme and reasoningsystem, Artificial Intelligence 116 (1–2) (2000) 67–85.[70] X. Wang, D.H. Jeong, W. Dou, S.-W. Lee, W. Ribarsky, R. Chang, Defining and ap-plying knowledge conversion processes to a visual analytics system, Computersand Graphics 33 (5) (2009) 616–623.[71] G.G. Yen, D. Acay, Adaptive user interfaces in complex supervisory tasks, ISATransactions 48 (2) (2009) 196–205.[72] E.R. Zanier, F. Ortolano, L. Ghisoni, A. Colombo, S. Losappio, N. Stocchetti, Intracra-nial pressure monitoring in intensive care: clinical advantages of a computerizedsystem over manual recording, Critical Care 11 (1) (2007) R7.Bernard Kamsu Foguem is an Assistant Professor at theNational Engineering School of Tarbes (ENIT) of NationalPolytechnic Institute of Toulouse (INPT) and leads his re-search activities in the Production Engineering Laboratory(LGP) of ENIT-INPT, a research entity (EA 1905) of the Uni-versity of Toulouse. He has a Master's in Operational Re-search (2000) from National Polytechnic Institute ofGrenoble, and a PhD in Computer Science and Automatic(2004) from the University of Montpellier 2. His currentinterests are in Knowledge Representation, Visual Reason-ing, Ontology-based Semantic Analysis and KnowledgeExploitation for Collaboration and Decision Support. Appli-cation domains include continuous improvement process,industrial maintenance management, conventional andtraditional medicine. He has authored or co-authored twenty articles in scientificjournals and international conferences. He also participates in the evaluation of re-search papers (reviewer activity) in several scientific journals. His work has receivedtwo “Best Paper Award” at conferences sponsored by the Institute of Electrical andElectronics Engineers (IEEE).Germaine Tchuente Foguem is PhD student at the Lille2University. She has a Master of Advanced Studies fromthe University of Yaounde I (Cameroon) in 2007, in the do-main of synchronization in dynamic distributed systems,and a Research Master in automatic and decisional sys-tems obtained in 2010 from ENIT-INPT of Tarbes (France).She is co-author of an article from his internship report ofResearch Master whose study focused on the competencesmanagement under uncertainty. She currently takes an ac-tive interest in complex signals analysis with the specificaim of improving the patient monitoring in intensive careunits, through false alarm reduction strategies, to help cli-nicians to predict status changes for better patient care.Laurent Allart obtained a M.Sc. degree in Bioinformatics from University of Lille(North, France) in 2003. He has developed software tools for their application in bio-medical research and medical practice. His research interests focus on data acquisitionfrom the biomedical equipment, software interface modelling and computerizedguidelines.Youcef Zennir received the State Engineer degree in Au-tomatic from the University of Badji Mokhtar–Annaba–Algeria in 1998 and the Post-graduate degree in Industri-al Automation from the University of Chambery–Francein 2000. He received his Ph.D in Industrial Automationfrom Applied Sciences National Institute of Lyon, France(INSA of Lyon) in 2004. He is an assistant professor in In-dustrial automation, in the Department of Electrical En-gineering at Skikda University, Algeria. His currentresearch interests include Diagnostic Decision SupportSystems, control of complex systems, Multi-actor Sys-tems, Distributed Artificial Intelligence, Knowledge Elec-trical Engineering and Computer Science.Mohamed Lemdani obtained his Ph.D in 1995. He is a pro-fessor of biomathematics at the faculty of pharmacy of Lille(University Lille 2, France) and the head of its departmentsof biomathematics. As a member of the “Public Health, EA2694” research team, he specializes in biostatistics andmathematical models for biology and public health.Mohamed LEMDANI is an author or a co-author of severalscientific publications which address both theoreticalmathematical framework and applications for life sciences.Pierre Ravaux obtained his Ph.D in 1989. He is also a phar-macist and a lecturer at the faculty of pharmacy of Lille(University Lille 2, France). He is the head of the centerof information resources at his university and supervisesseveral programs of e-learning.As a member of the “Public Health, EA 2694” researchteam, he specializes in information models for intensivecare units, artificialintelligence for decision supportsystems for the patient and signal processing for human-data time series.Pierre Ravaux has also acted as scientific manager for sev-eral public-health related international collaborative pro-jects and is an author or a co-author of several scientificpublications.Christian Vilhelm has a PhD in Biomedical Engineering,obtained in 1998. He is teaching computer science at theUniversity of Lille 2 (France). His primary interests arecomputer representation of complex experience-basedheuristic knowledge, and computer security. Most of hisresearch is done in the area of intensive care medicine.He is co-author of several articles in journals.Hossein Mehdaoui is physician at Fort-de-France's university hospital, Martinique. Heis the operational director of an innovation and research program in the domain of helpin decision making using information technologies. He is also the CMO of the CriticalCare Unit, Hyperbaric chamber Unit.Djamel Zitouni has a PhD in mathematical and computerScience. He is a member of the EA2694 public health re-search unit, University of Lille 2, North of France. His re-search activities concern guideline automated medical.Most of his research works are applied in health care do-main. He is an author of many papers in international con-ferences and scientific journals.Hervé Hubert is full Professor of Health Engineering at theLille University School of Health Engineering where he isin charge of the Risks Management Master, and memberof the of Public Health laboratory at the University of Lille2. Born in Marseilles (France) in 1969, he obtained hisPh.D. degree in Health Economic at the University of Lille1 in 1998. His entire work is dedicated to medico-economic assessment and public health, more specificallyto the area of hospital emergency care. His teaching andresearch interests focus on the micro-economic evaluationand optimisation of health, the role played by the behav-iours of individual, and the evaluation of medical practices.Prof. Hervé Hubert is a member of several scientific socie-ties and he is the organizer of the 1st international day oflogistics and health’ optimization in Sousse (Tunisia, 2009). He is alsohospitalco-founder and head of the French Cardiac Arrest registry. Prof. Hervé Hubert has pub-lished more than 40 articles in the field of medico-economic assessment and publichealth.