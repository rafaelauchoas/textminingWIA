Artificial Intelligence 175 (2011) 49–78Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintModular-E and the role of elaboration tolerance in solvingthe qualification problemAntonis Kakas a, Loizos Michael b, Rob Miller c,∗a University of Cyprus, P.O. Box 20537, CY-1678, Cyprusb Harvard University, Cambridge, MA 02138, USAc University College London, London WC1E 6BT, UKa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Reasoning about actionsElaboration toleranceQualification problemDefault reasoningWe describe Modular-E (ME), a specialized, model-theoretic logic for reasoning aboutactions. ME is able to represent non-deterministic domains involving concurrency, staticlaws (constraints), indirect effects (ramifications), and narrative information in the formof action occurrences and observations along a time line. We give formal results whichcharacterize ME’s high degree of modularity and elaboration tolerance, and show howthese properties help to separate out, and provide principled solutions to, differentaspects of the qualification problem. In particular, we identify the endogenous qualificationproblem as the problem of properly accounting for highly distributed, and potentiallyconflicting, causal knowledge when reasoning about the effects of actions. We show howa comprehensive solution to the endogenous qualification problem helps simplify theexogenous qualification problem — the problem of reconciling conflicts between predictionsabout what should be true at particular times and actual observations. More precisely, wedescribe how ME is able to use straightforward default reasoning techniques to solvethe exogenous qualification problem largely because its robust treatments of the frame,ramification and endogenous qualification problems combine into a particular characteristicof elaboration tolerance that we formally encapsulate as a notion of “free will”.© 2010 Elsevier B.V. All rights reserved.1. IntroductionFor half a century the seminal work of John McCarthy has been instrumental in identifying the major areas, issues anddirections for progress in Knowledge Representation and logic-based A.I. In particular, research in reasoning about actionand change (RAC), originally initiated by McCarthy and collaborators, continues to be a central topic in this field. “Classical”RAC formalisms such as the Situation, Event and Fluent Calculi [26,28,32,36], as well as their more semantically specializedcounterparts such as TAL, Dynamic Logic and the Languages A, E and C+ [5,8,10,12,15], are increasingly proving their worthnot only in traditionally related areas such as planning and cognitive robotics, but also in fields as diverse as computationalbiology, the semantic web and software engineering [27,33,38].Irrespective of the particular logic or formalism being developed, certain issues have for a long time been consideredfundamental in RAC. Foremost among these is of course the frame problem — how to succinctly and flexibly represent andreason about the non-effects of actions, avoiding such pitfalls as the infamous Hanks and McDermott problem [11]. Morerecently there has been much focus on the ramification problem — how to accommodate knowledge and inferences about the* Corresponding author.E-mail addresses: antonis@ucy.ac.cy (A. Kakas), loizos@eecs.harvard.edu (L. Michael), rsm@ucl.ac.uk (R. Miller).URLs: http://www2.cs.ucy.ac.cy/~antonis/ (A. Kakas), http://www.eecs.harvard.edu/~loizos/ (L. Michael), http://www.ucl.ac.uk/slais/rob-miller/ (R. Miller).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.00850A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78indirect and knock-on effects of actions. Largely as a result of this, there has been a growing consensus that RAC formalismsneed to explicitly incorporate some notion of causality.However, a third fundamental issue identified by McCarthy, although generally perceived as important, has receivedrelatively little attention to date. This is the qualification problem [22,37], which, as we will see, relates to various difficultiesin adequately qualifying statements either about the executability or about the effects (both direct and indirect) of actions.One can in fact naturally cast the qualification problem in terms of McCarthy’s “Appearance and Reality” phenomenon [25].The reality in a domain, captured in the context of RAC formalisms by effect laws, is not directly observable, and theselaws are of necessity incomplete. This incompleteness leads in some cases to inconsistency, rendering the reasoning processincapable of drawing any conclusion. The qualification problem can be viewed as the problem of how to let appearancesin a domain (captured by observations, etc.) qualify our beliefs about the reality, so that the inconsistency is lifted, andmeaningful conclusions may be drawn.The qualification problem is the main focus of this paper. But, just as the ramification problem has proved to be in-timately related to the frame problem, the qualification problem is inextricably linked to both the frame and ramificationproblems, so that development of a solution to one inevitably leads to a re-examination of solutions to the other two. Hence,as a necessary preliminary to our main aim, we also present an exceptionally robust and complete solution to the frameand ramification problems combined. We also illustrate how McCarthy’s notion of elaboration tolerance [24], long considereddesirable in RAC frameworks, plays a key role in the combined solution to all three problems.1.1. Some terminologyIn order to describe the various aspects of the qualification problem, and our approach to solving them, it is convenientto first summarize some of the terminology commonly used in this research area. Time-varying properties of the world,i.e., those that can potentially be affected by actions, are usually referred to as fluents. The terms action and event are oftenused synonymously. A state is an assignment of a truth value to each fluent. Narrative-based formalisms (such as TAL, theEvent Calculus and the Language E ) employ a structure of time-points (or time intervals) that is defined independentlyfrom actions and fluents. One way or another, explicitly or implicitly, these frameworks associate a unique state with eachtime-point in each model. In such formalisms, a fluent holds at a time-point if it is true in the associated state. On theother hand, non-narrative-based formalisms (such as the Situation and Fluent Calculi and the Language A) avoid the useof an independent time structure by reasoning directly about sequences of actions. Such formalisms, one way or another,explicitly or implicitly, associate a unique state with each “allowed” action sequence in each model. The term situation issometimes used to refer to a sequence of actions and sometimes used to refer to the state associated with a sequence ofactions.There is also a common terminology as regards different types of statements or sentences within RAC formalisms. Theterms effect law, effect axiom, and causal law are sometimes used to characterize a sentence describing a specific causal effect.For example, to describe the effect of turning the ignition key of a car we may write (in the syntax of the Situation Calculus,the Event Calculus and the Language C+ respectively):Holds(EngineRunning, Do(TurnKey, s)) ← Holds(BatteryCharged, s)Initiates(TurnKey, EngineRunning, t) ← HoldsAt(BatteryCharged, t)TurnKey causes EngineRunning if BatteryChargedThe qualification BatteryCharged in this effect law is an example of a fluent precondition — although it is not necessaryfor BatteryCharged to hold in order for the TurnKey action to be successfully executed, BatteryCharged is necessary for theTurnKey action to have this particular effect on EngineRunning. In contrast to effect laws, executability laws specify conditionsunder which an action can or cannot be successfully executed, e.g. (Situation Calculus, Event Calculus and Language C+syntax respectively):Poss(TurnKey, s) ≡ Holds(HasKey, s)Impossible(TurnKey, t) ← ¬HoldsAt(HasKey, t)nonexecutable TurnKey if ¬HasKeyIn this statement the qualification HasKey is an executability or action precondition, and indeed such sentences are alsosometimes referred to as action precondition axioms.Most formalisms also allow various action-independent relationships between fluents or sets of fluents to be described.Domain constraints or state constraints are simply constraints on the set of allowed states that have to be taken into accountone way or another when constructing state transition rules from the domain description as a whole. For example, todescribe that broken cars’ engines cannot run we may write (in the Situation Calculus):¬[Holds(EngineRunning, s) ∧ Holds(EngineBroken, s)]A. Kakas et al. / Artificial Intelligence 175 (2011) 49–7851Exactly how a formalism should take such statements into account is of course debatable, a central issue being aboutwhether they should result in more or in less change. (In this particular example one might argue that an action thatcauses EngineBroken should therefore also cause ¬EngineRunning. But one is unlikely to argue that an action that causesEngineRunning should therefore also cause ¬EngineBroken, but rather that ¬EngineBroken should act as an extra fluentprecondition for effect laws that initiate EngineRunning.) In many formalisms the ambiguity of such statements can beavoided by re-expressing them as “unidirectional” ramification laws or indirect effect laws. For example, in the Language E wemay write:¬EngineRunning whenever {EngineBroken}to express that causing EngineBroken has the knock-on effect of causing ¬EngineRunning.Observation statements (or simply observations) are assertions that particular fluents hold or do not hold at particulartime-points or in particular states. For example, in the narrative-based Event Calculus we may assert that a car’s engine wasobserved to be running at time 3 by HoldsAt(EngineRunning, 3). The nearest we can get to such assertions in non-narrativeformalisms is via sentences such as Holds(EngineRunning, Do(TurnKey, S0)) (Situation/Fluent Calculus syntax). If regarded asan “observation”, the implication of this statement is (roughly) that the world was at some point in the past in state S0,that in that state a TurnKey action was performed, and that immediately afterwards EngineRunning was seen to be true.The last type of statement it is useful to identify here is an (action or event) occurrence statement. Occurrence statementsassert that a particular action was performed, or at least attempted, at a specific time-point (or over a specific time-interval), as e.g. in the Language E proposition TurnKey happens-at 2. Obviously such assertions are possible only innarrative-based formalisms. In what follows, we refer to the collection of observations and occurrence statements within atheory as its narrative.1.2. Aspects of the qualification problemMcCarthy [23] describes the qualification problem as follows: “In order to fully represent the conditions for the suc-cessful performance of an action, an impractical and implausible number of qualifications would have to be included inthe sentences expressing them”. In this section we disambiguate and provide some terminology for various aspects of thisproblem. The analysis offered here is inspired by, and borrows some vocabulary from, that of Thielscher [37].We first note that McCarthy’s assertion above applies equally to fluent and action preconditions. One consequence of theneed to describe a large number of conditions for a successful performance or effect of an action is the need to distributesuch information across several sentences. For example, we have already illustrated in the previous section how fluent pre-conditions may be contained both explicitly in effect laws and implicitly in domain constraints (turning the ignition keycauses a car’s engine to run if the battery is charged, but broken engines will not run). Therefore when computing or rea-soning about the effects or success of a particular action attempt, this distributed information about relevant qualificationswill have to be identified and combined in a principled way. We refer to this as the endogenous qualification problem —“endogenous” since it concerns the interpretation of information already contained within the given representation of thedomain. The endogenous qualification problem is closely related to the issue of elaboration tolerance [21,24], in that a goodsolution to it is more likely to allow new information about qualifications to be added to a theory as new sentences, withoutthe need to otherwise alter the existing theory. In turn, elaboration tolerance is strongly linked with the need to have amodular semantics for RAC frameworks that properly separates different aspects of the domain knowledge, as argued e.g.in [13].1But McCarthy’s description of the qualification problem principally relates to a more fundamental issue about modellingthe real world. Any model or representation (of any kind — logical, mathematical, analogical, etc.) is necessarily incompleteor approximate in some respects, arguably by the very definition of a model or representation. In this sense it is impossibleto “fully represent” anything. In particular, if a logic-based representation is used to make predictions about the real world,those predictions will occasionally be contradicted by direct experience. More particularly still, if a logic-based agent makespredictions about the effects of an (attempted) action, subsequent observations will occasionally reveal that the attemptfailed to produce some or all of the expected effects, because of factors (qualifications) outside the scope of the represen-tation. No amount of refining the representation will stop this from happening, albeit only very occasionally. We refer tothe exogenous qualification problem as the problem of engineering a representation flexible enough to be able to recoverfrom occasional mismatches between predictions about actions’ effects and actual observations, yet robust enough to beuseful as a predictive tool. “Exogenous” since it partially concerns factors outside the scope of, or even the language of, therepresentation. Note that, since the exogenous qualification problem involves the notions of observation and action occur-rence, its solution will require a narrative-based formalism, or at least a formalism enhanced with some narrative reasoningcapabilities.McCarthy and others (notably Thielscher) have illustrated that default and non-monotonic reasoning has a significant roleto play in dealing with aspects of the qualification problem [23,37]. Indeed, a “weak” version of the exogenous qualification1 In this paper, Herzig and Varzinczak show how, in “non-modularized” theories, pairs of action laws can sometimes give rise to unintended domainconstraints, and how in turn this can prevent the domain from being elaborated with conflicting domain constraints.52A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78problem is the problem of representing that some fluents (or their negations) always hold under “normal” circumstances,so that they should be assumed by default when inferring the effects of actions. However, two points should be noted.First, a solution to this problem will not help when abnormal factors unrepresentable by any combination of the fluents inthe language interfere with an (attempted) action. Second, if a fluent has a default truth value, this should manifest itselfeverywhere in the reasoning process, and not just when the fluent appears as a precondition in an effect or executabilitylaw. For example, if we are told only that car engines are not normally broken, we should be able to infer by default thata given car engine is not broken at a given time, irrespective of whether that car has had its ignition key turned. So theproblem of dealing with default fluent values is separate from, although strongly related to, the exogenous qualificationproblem.How do the endogenous and exogenous qualification problems interact? In this paper, we argue that “endogenous” ex-planations for particular observations are preferable to “exogenous” ones, and that a “complete” solution to the endogenousqualification problem is necessary for a “clean” solution to the exogenous problem. For example, suppose a simple represen-tation includes only the effect law “TurnKey causes EngineRunning” and the domain constraint ¬(Broken ∧ EngineRunning),but that the semantics fails to recognize ¬Broken as an implicit precondition for the effect law. A narrative in which aTurnKey action is followed by an observation of ¬EngineRunning then introduces a potential inconsistency. The formalismmay then be tempted to resolve this apparent conflict of information by prematurely appealing to some general solutionto the exogenous qualification problem — offering a mysterious, unrepresentable explanation for the “failure” of TurnKeyinstead of the obvious possibility of Broken.A full solution to the exogenous qualification problem necessitates a view of occurrence statements as identifying onlyattempts to execute actions (even though we may choose to build into a formalism a default principle that such attemptscan be assumed to result in actual action executions unless there is evidence to the contrary). If we do not view occurrencestatements in this way, we overly limit the options as regards recovery from unexpected observations. For example, supposewe have two effect laws stating that PushButton causes IndicatorLightOn and PushButton causes LifeSupportOn. Suppose alsothat we have a narrative which records an occurrence of PushButton but also a subsequent observation ¬IndicatorLightOn.Clearly we should not only consider the possibility that some unrepresented fluent precondition prevented the triggering ofthe IndicatorLightOn effect law, and hence confidently maintain the belief that LifeSupportOn. We also need to entertain thepossibility that an unrepresented action precondition stopped PushButton from executing correctly (i.e., that this instance ofPushButton represents a “failed” execution attempt), and therefore view both its effects with suspicion.The treatment of occurrence statements as execution attempts rather than certainties has another important benefit,concerning the modularity of action theories. Recent commentary about the need for modularity in RAC formalisms has beenconcerned with non-narrative aspects of theories — for example, the need to avoid generation of implicit domain constraintsfrom collections of effect laws (see e.g. [13]). In this paper we illustrate the importance of adhering to a complimentary,temporally directed, principle of modularity specifically concerning narratives — action occurrences in the future should notimplicitly force the past to necessarily have a certain property. As we will see, a model-theoretic analysis of this requirementshows it to be equivalent to the principle that an agent can attempt to execute an action in any circumstance (albeit entirelyineffectively if the action’s executability conditions are not satisfied). We therefore refer to this principle as the free willproperty. This “free will” is not only crucial to the decoupling of the exogenous and endogenous qualification problems, butalso helps avoid other problems such as anomalous plans in abductive planning systems. Conceptually, it helps to underlinethe ontological difference between actions and fluents. It makes good engineering sense as well — in cognitive roboticsterms, for example, it mirrors a proper differentiation between effectors, sensors and environment (in which actions areinternal signals from a robot’s reasoning engine to its effectors, whereas observations are signals from the environment tothe reasoning engine via sensors).1.3. Structure of the paperThe remainder of this paper is organized as follows. In Section 2 we discuss some shortcomings of existing RAC for-malisms with respect to the above analysis of the qualification problem and related issues. In Section 3 we introduce theaction description language Modular-E (ME ), engineered to overcome the limitations we have identified. Section 3.1 de-scribes the syntax of the language and gives an informal insight into its model-theoretic semantics via a series of examples,and Sections 3.2 and 3.3 give a formal definition of the semantics. In Section 4 we prove that ME does indeed have thenecessary characteristics (such as the “free will” property) that we have identified as important. In Section 5 we show howME can be extended to deal with default fluent values, and in Section 6 we show how this extension, together with theresults from Section 4, lays the groundwork for a principled solution to the exogenous qualification problem. We concludein Section 7 with a summary of our results, some implications for RAC formalisms in general, and some directions for futurestudy.2. Some shortcomings of existing approaches2.1. Incomplete solutions to the frame problemTo our knowledge, the most complete recent discussion of the qualification problem in the sense of Section 1.2 is given byThielscher [37]. He first demonstrates how a failure to take causality into proper account when engineering a non-monotonicA. Kakas et al. / Artificial Intelligence 175 (2011) 49–7853solution to the qualification problem can give rise to anomalous models. He then proposes a framework based on monotonicFluent Calculus embedded in a straightforward default theory to overcome these problems. The resulting formalism is ableto cope with a broad range of phenomena relating to the qualification problem, for example, covering both “accidents” (one-off failures of actions) and persistent failures, and offering the possibility of prioritizing between alternative explanations ofaction failure.However, Thielscher’s approach has a limitation that renders it inappropriate as a candidate solution to the narrative-centered exogenous qualification problem as described in Section 1.2. This is that the solution to the frame problem that itemploys does not cover the case of failed actions (or action “attempts”, as we have argued for above). This can be illustratedwith a variation of the “life support” domain mentioned in the previous section. In the Fluent Calculus, the basic knowledgeabout the effect that the PushButton action has on the fluents IndicatorLightOn and LifeSupportOn can be described by thestate update axiom (FC1) below. We will suppose that PushButton is unconditionally executable (FC2), and to motivate theneed to push the button, we will also assert (FC3) that the patient is very ill in the initial situation S0:Poss(PushButton, s) →[State(Do(PushButton, s)) =State(s) ◦ IndicatorLightOn ◦ LifeSupportOn]Poss(PushButton, s)Holds(PatientVeryIll, S0)(FC1)(FC2)(FC3)Axioms (FC1)–(FC3), together with the standard fluent calculus domain independent theory, correctly entail the followingthree facts about the situation after a PushButton action:Holds(PatientVeryIll, Do(PushButton, S0))Holds(IndicatorLightOn, Do(PushButton, S0))Holds(LifeSupportOn, Do(PushButton, S0))(Conclusion 1)(Conclusion 2)(Conclusion 3)As discussed above, the exogenous qualification problem is the problem of how to modify theories such as this so thatthey can accommodate unexpected “observations” such as ¬Holds(IndicatorLightOn, Do(PushButton, S0)). Thielscher accom-plishes this by augmenting the fluent calculus with abnormality fluents such as Ab(IndicatorLightable, BulbBroken), wherethe second argument is a “cause” for the abnormality indicated by the first argument. For convenience he also de-fines the macro Ab(x, s) as (∃ y)Holds(Ab(x, y), State(s)). For each abnormality fluent Ab( X, Y ), a default rule establishes¬Holds(Ab( X, Y ), S0). The domain description above is transformed into something likePoss(PushButton, s) →([¬Ab(IndicatorLightable, s) →State(Do(PushButton, s)) =State(s) ◦ IndicatorLightOn ◦ LifeSupportOn]∧[Ab(IndicatorLightable, s) →State(Do(PushButton, s)) = State(s) ◦ LifeSupportOn])Poss(PushButton, s) ↔ ¬Ab(ButtonPushable, s)Holds(PatientVeryIll, S0)(FC1(cid:9))(FC2(FC3(cid:9))(cid:9))(cid:9)(cid:9))–(FC3Because of the associated default rules, (FC1) still give (Conclusion 1)–(Conclusion 3). But if we now add tothe axiomatization the “observation” ¬Holds(IndicatorLightOn, Do(PushButton, S0)) the underlying default theory gives twoclasses of extensions, with Ab(IndicatorLightable, S0) and Ab(ButtonPushable, S0) respectively. Although this gives us the de-sired uncertainty about LifeSupportOn in Do(PushButton, S0), it also allows extensions with the negation of (Conclusion 1).In other words it admits the possibility that the failed PushButton action has cured the patient! The essence of the prob-lem here is that the solution to the frame problem, encapsulated as it is by state update axioms of the general formPoss( A((cid:11)x), s) → Γ [State(Do( A((cid:11)x), s)), State(s)], covers only successful actions and not failed action attempts. The same istrue of Reiter’s Situation Calculus [32]. Agents employing such formalisms are therefore required to detect action failures atthe instant of (attempted) execution.54A. Kakas et al. / Artificial Intelligence 175 (2011) 49–782.2. Action preconditions as narrative constraintsIn some formalisms able to represent action occurrences either at a syntactic level (e.g., the version of the Event Calculusin [30]) or at a semantic level (e.g., Language C+), action preconditions are expressed as constraints on the conditions underwhich actions can occur. For example, in the framework of [30] and in Language C+ the fact that ¬ButtonStuck is an actionprecondition for PushButton would be written respectively as:Happens(PushButton, t) → ¬HoldsAt(ButtonStuck, t)nonexecutable PushButton if ButtonStuckwhere the second of these expressions translates to the collection of “causal rules” ⊥ ⇐ t : (PushButton ∧ ButtonStuck) foreach time-point t. In both cases the semantics ensures that there can be no models in which a PushButton occurs at atime-point where ButtonStuck is true. Clearly this style of representing action preconditions renders these formalisms in-appropriate as a foundation for a solution to the exogenous qualification problem, because it excludes the possibility ofexplaining unexpected observations after the occurrence of such actions in terms of unusual values for the actions’ pre-conditions (e.g., explanations such as “the indicator failed to light because the button was stuck when an attempt wasmade to push it”). Other limitations of this type of approach to action preconditions, such as the difficulties it poses for astraightforward logical characterization of planning, are discussed in [28]. But the general point is that it militates againstmodularization of domain descriptions into narrative and non-narrative components, because the action preconditions con-strain the classes of narratives that can be considered.3. Modular-EWe have opted to investigate the qualification problem by development of an action description language Modular-E(ME ), thus following the methodology first proposed in [8]. ME is intended as a more expressive successor to the Lan-guage E , which in turn was developed from and is closely related to the Event Calculus (see [28] for an overview of theEvent Calculus and its relationship with Language E ). There are of course pros and cons to using action description lan-guages (ADLs) as opposed to general purpose logic. In this case we have found the ADL methodology useful because thelevel of abstraction it provides has helped expose key characteristics of a problem on which there has been little previouswork. The resulting constraints on the expressivity of ME (e.g., lack of quantification and nested sentence structures) are,at this stage of our investigation, a small price to pay for the insights gained. Furthermore we shall see that ME employs astandard model-theoretic notion of entailment, so that the approach may be in principle be adapted for classical logic-basedframeworks, such as the Event Calculus, at a later date.2In the next section we give ME ’s syntax and sketch its important characteristics via a series of examples. We thengive a model-theoretic semantics. ME ’s models, like Language E ’s, are designations of truth values for each fluent at eachpoint along a time-line that meet certain criteria, including an Event Calculus-like notion of default persistence (to solvethe frame problem). As in the Language E , ME ’s fluents can only change truth value at time-points at which events, actionlaws and ramification statements justify the change, but ME uses a notion of quasi-instantaneous “processes” to computeramifications, thus allowing it to identify all possible chains of quasi-instantaneous causation even in complex cases whereramifications loop, race and/or compete against each other.3.1. Modular-E syntax and examplesDefinition 1 (Domain language). An ME domain language is a tuple (cid:14)Π, (cid:2), (cid:4), Φ(cid:15), where (cid:2) is a total ordering defined overthe non-empty set Π of time-points, (cid:4) is a non-empty set of action constants, and Φ is a non-empty set of fluent constants.Definition 2 (Formula, literal and conjunction). A fluent formula is a propositional formula containing only fluent constants(used as extra-logical symbols), the standard connectives ¬, →, ←, ↔, ∨ and ∧, and the truth value constants (cid:17) and ⊥.A fluent literal is either a fluent constant or its negation. An action literal is either an action constant or its negation.A fluent conjunction is a conjunction of fluent literals.Definition 3 (Converse). Let E be an action or fluent constant. The converse of E, written E, is ¬E, and the converse of ¬E,written ¬E, is E.Definition 4 (Domain description or theory). A domain description or theory in ME is a collection of the following typesof statements, where φ is a fluent formula, T is a time-point, A is an action constant, C is a (possibly empty) finite set offluent and action literals, L is a fluent literal, and E is a non-empty finite set of action constants and fluent literals:2 An alternative methodology would have been to use the Event Calculus directly as a substrate to this investigation, and attempt to express the defini-tions in Sections 3.2 and 3.3 as classical logic axioms. However, a little experimentation along these lines shows that this would lead to an axiomatizationthat was rather dense and hard to follow.A. Kakas et al. / Artificial Intelligence 175 (2011) 49–7855– h-propositions of the form: φ holds-at T– o-propositions of the form: A occurs-at T– c-propositions of the form: C causes L– p-propositions of the form: φ prevents E– a-propositions of the form: always φA domain description is finite if it contains only a finite number of propositions.Singleton sets of fluent or action literals in c-propositions of the form {P } will sometimes be written without enclosingbraces, i.e., as P . The intended meaning of h-propositions is straightforward — they can be used to record “observations”about the domain along the time line. The o-proposition “ A occurs-at T ” means that an attempt to execute A occursat T . Together, the h- and o-propositions describe the “narrative” component of a domain description. “C causes L”means that, at any time-point, the combination of actions, inactions and preconditions described via C will provisionallycause L to hold immediately afterwards. As we shall see, the provisos automatically accompanying this causal rule arecrucial — in any model the potential effect L competes with other potential effects, and may be overridden, for example,because it would otherwise result in a more-than-instantaneous violation of a domain constraint described with an a-proposition. The rule “C causes L” is thus qualified both locally (via C ) and globally via the total set of c-, p- and a-propositions. “φ prevents E” means that the circumstances described by φ prevent the simultaneous causation/executionof the effects/actions listed in E. “always φ” means that ¬φ can never hold, other than in temporary, instantaneous“transition states” which form part of an instantaneous chain of indirect effects. In other words, “always φ” describes adomain constraint or static law at the granularity of observable time.In the remainder of this section we give a flavor of ME ’s semantics by discussing the models that a series of examplesgives rise to. As will be seen in Section 3.3, a model in ME is simply an assignment of a truth value to each fluent(and action) at each time-point that meets certain criteria, and a domain description is consistent if it has a model. Theseexamples (as opposed to the standard examples in the literature) have been chosen to illustrate the role of each typeof proposition in Definition 4 and to demonstrate how ME deals with such phenomena as non-determinism, conflictingeffects of simultaneously executed actions, looping chains of ramifications, and race conditions between competing seriesof indirect effects. For all the examples in the remainder of the paper, we assume (unless otherwise stated) that Π inDefinition 1 is the set of integers or real numbers, and that (cid:4) and Φ are exactly the action and fluent constants mentionedin the example’s propositions.Example 1 (Lift door). A lift door can be opened and closed by pressing the “open” and “close” buttons respectively. The dooris initially open, and both buttons are pressed simultaneously. This scenario can be described with a single fluent DoorOpenand two actions PressOpen and PressClose:{PressOpen} causes DoorOpen{PressClose} causes ¬DoorOpenDoorOpen holds-at 1PressOpen occurs-at 2PressClose occurs-at 2(LD1)(LD2)(LD3)(LD4)(LD5)Example 1 results in two models — one in which the door is open at times after 2 and one in which the door is closed.Note that, even though the conflicting actions are not prevented from executing together (i.e., there is no p-proposition“(cid:17) prevents {PressOpen, PressClose}”), they do not give rise to inconsistency. This is a manifestation of ME ’s “freewill” property (formally defined in Section 4) — from any consistent initial state, and for any given collection of c- andp-propositions, any series of actions may be attempted without giving rise to inconsistency (see Corollary 2, Section 4).Put another way, any finite collection of o-, c- and p-propositions is consistent with any internally consistent collection ofa-propositions. Consequently, the only way to engineer an inconsistent ME domain description (other than by inclusion ofinconsistent a-propositions) is to include “observations” (h-propositions) along the time line which contradict the predic-tions that would otherwise be given by ME ’s semantics. In Section 6 we show how this remaining type of inconsistencycan sometimes be overcome by attributing it to unknown exogenous reasons and applying a simple minimization to these.Example 2 (Alternative lift door). The lift is re-designed so that it is physically impossible to press both buttons at once. Buta passenger in the lift still attempts to press them simultaneously at time 2:{PressOpen} causes DoorOpen{PressClose} causes ¬DoorOpen(ALD1)(ALD2)56A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78(cid:17) prevents {PressOpen, PressClose}DoorOpen holds-at 1PressOpen occurs-at 2PressClose occurs-at 2(ALD3)(ALD4)(ALD5)(ALD6)Again, Example 2 results in two models — one in which the door is open at times after 2 and one in which the door isclosed. (ALD3) ensures that exactly one of the two actions fails to execute successfully, and hence fails in all of its effects.The following series of “broken car” examples is to illustrate the modularity and elaboration tolerance of ME , and howthis is linked to the way a- and c-propositions interact.Example 3 (Broken car A). Turning the key of a car causes its engine to start running. The key is turned at time 1:{TurnKey} causes RunningTurnKey occurs-at 1(BC1)(BC2)In all models of this domain the car engine is running at all times after 1. (A more complete description would typicallyinclude some local qualifications for (BC1), e.g., “{TurnKey, BatteryOK} causes Running” — turning the key starts the engineonly when the battery is OK, in which case models would also arise where, e.g., ¬BatteryOK and ¬Running at all time-points.)Example 4 (Broken car B). We elaborate the previous description by stating in (BC3) that broken cars’ engines cannot run:{TurnKey} causes RunningTurnKey occurs-at 1always ¬(Broken ∧ Running)(BC1)(BC2)(BC3)There are two classes of models for the elaborated domain (BC1)–(BC3) — one in which the car is broken and notrunning at times after 1, and one in which the car is not broken and running. The occurrence of TurnKey at 1 does noteliminate the model in which the car is broken because the semantics of ME allows (BC3) to act as a global qualification,in particular for (BC1). The TurnKey action does not force ¬Broken at earlier times, and thus if in addition the car is knownto be broken the theory remains consistent after this elaboration. Without this characteristic, we would have to alter (BC1)to “{TurnKey, ¬Broken} causes Running” to accommodate (BC3), in other words explicitly encode as a local qualificationthe global qualification effect of (BC3) on (BC1). In ME this local qualification is redundant thus illustrating its modularnature; the a-proposition (BC3) has been simply added without further ado.Example 5 (Broken car C). We elaborate Example 4 with two more causal rules and an extra action occurrence:{TurnKey} causes RunningTurnKey occurs-at 1always ¬(Broken ∧ Running){Break} causes Broken{Broken} causes ¬RunningBreak occurs-at 1(BC1)(BC2)(BC3)(BC4)(BC5)(BC6)In all models of the domain (BC1)–(BC6), the car is broken and not running at times after 1. (BC5) describes an “indirecteffect” or “ramification”. It introduces an asymmetry between the Running and Broken fluents and their relationship with(BC3), preventing (BC3) from acting as a qualification for (BC4) in the same way as it does for (BC1). Translating global to lo-cal/explicit qualifications is therefore complex, as it requires consideration of the interactions between a- and c-propositions.ME deals with indirect effects by considering chains of instantaneous, temporary transition states (“nodes”). Within thesecausal chains, “processes” are introduced to describe the initiation and termination of fluents. These processes may “stretch”across several links of a given chain before they are complete, thus allowing all possible micro-orderings of effects to beconsidered. Because of the potential coarseness of the domain description with respect to the granularity of time, this isimportant for a proper treatment of collections of instantaneous effects which compete or “race” against each other. Further-more, since the granularity of time in which these chains operate is finer than that of observable time, intermediate statesA. Kakas et al. / Artificial Intelligence 175 (2011) 49–7857within them may (temporarily) violate the static laws described by a-propositions. In Example 5, one of the chains allowedby the semantics completes the process initiating Running and then the process initiating Broken. At this point there is astate in which (BC3) is violated, but (BC5) then generates a new process terminating Running whose completion results ina consistent state further along the chain.We next elaborate the previous two examples with the observation (BC-obs1) that the car is running at time 2:Example 6 (Broken car D).{TurnKey} causes RunningTurnKey occurs-at 1always ¬(Broken ∧ Running)Running holds-at 2Example 7 (Broken car E).{TurnKey} causes RunningTurnKey occurs-at 1always ¬(Broken ∧ Running){Break} causes Broken{Broken} causes ¬RunningBreak occurs-at 1Running holds-at 2(BC1)(BC2)(BC3)(BC-obs1)(BC1)(BC2)(BC3)(BC4)(BC5)(BC6)(BC-obs1)Adding (BC-obs1) in Example 6 does not result in inconsistency, but allows us to infer that the car is not broken (inparticular at earlier times). Note that ME would facilitate the opposite conclusion (Broken) in exactly the same way hadthe observation been “¬Running holds-at 2”. This is because it accords exactly the same status to globally derived qual-ifications (in this case from (BC3)) as to qualifications localized to particular c-propositions. However, adding (BC-obs1) inExample 7 does give rise to inconsistency at the level of the ME ’s “base semantics”, because since there are no (local orglobally derived) qualifications to (BC4) and (BC5), the theory would otherwise entail ¬Running. An intuitive explanation for(BC-obs1) in this context is that one or both of the effects of (BC4) and (BC5) “failed” due to exogenous circumstances (i.e.,factors not included in the representation) implicitly qualifying these causal rules. This type of reasoning is captured withinME by the use of simple default minimization of such exogenous qualifications (see Section 6). The minimization policy isstraightforward and robust because the base semantics fully accounts for all endogenous qualifications (i.e., those expressedin the domain) by virtue of its modularity and its encapsulation of global as well as local qualifications, as described above.Example 8 (Broken car F). We elaborate Example 5 with the knowledge that the car was parked at time 0 in anti-theft mode(ATM), so that causing the engine to run (even for an instant) will trigger the alarm:{TurnKey} causes RunningTurnKey occurs-at 1always ¬(Broken ∧ Running){Break} causes Broken{Broken} causes ¬RunningBreak occurs-at 1(¬Broken ∧ ¬Running ∧ ¬Alarm ∧ ATM) holds-at 0{Running, ATM} causes Alarm(BC1)(BC2)(BC3)(BC4)(BC5)(BC6)(BC7)(BC8)Intuitively, even though at times after 1 the car will be broken and not running, the alarm may or may not be triggeredin this narrative, depending on whether the (indirect) effect of the Break action takes effect just before or just after theeffect of the TurnKey action. This is an example of a “race” condition between competing instantaneous effects. ME is ableto deal correctly with such representations via its process-based semantics. It gives two models of this domain — in bothmodels (Broken ∧ ¬Running) is true at times after 1, but in one model Alarm is true and in the other it is false. The example58A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78illustrates how ME ’s processes operate at a finer level of temporal granularity than “observable time” in order to deal with“instantaneous” indirect effects.3Example 9 (Oscillator).{On} causes ¬On{¬On} causes On(OSC1)(OSC2)This example (which might e.g. represent the internal mechanism of an electric buzzer) has an infinite number ofmodels in which the truth value of On is arbitrarily assigned at each time-point. It illustrates that ME is able to dealwith “loops” of indirect effects without over-constraining models. It is important, for example, not to restrict the set ofmodels to those in which the truth value of On alternates at each successive time-point. This is because the change withinthe domain is happening “instantaneously” — i.e., at an altogether finer granularity of time than “observable” time. Thereforethe observable time-points are best considered as arbitrarily spaced “snapshots” of the finer-grained time continuum. A fulltreatment of such loops along these lines (as well as a full treatment of concurrency and non-determinism) is necessary forME to exhibit the “free will” property and resulting modularity and elaboration tolerance described above.3.2. ME base semantics; states, processes and causal changeIn this and the next section we give a formal account of ME ’s semantics, starting with some straightforward definitionsconcerning states and processes.Definition 5 (States and satisfaction). A state is a set S of fluent literals such that for each fluent constant F , either F ∈ S or¬F ∈ S but not both. A formula φ is satisfied in a state S iff the interpretation corresponding to S is a classical model of φ.Definition 6 (A-consistency). Let D be a domain description and S a state. S is a-consistent with respect to D iff for everya-proposition “always φ” in D, φ is satisfied in S. D is a-consistent iff there exists a state which is a-consistent withrespect to D. Let Da denote the set of all a-propositions in D. Then given a fluent formula ψ , Da |(cid:19)a ψ iff ψ is entailedclassically by the theory T = {φ | always φ ∈ D}.Definition 7 (Process). A process is an expression of the form ↑F or ↓F , where F is a fluent constant of the language.↑F is called the initiating process of F and ↓F is called the terminating process of F . The associated processes of thec-propositions “C causes F ” and “C causes ¬F ” are respectively ↑F and ↓F . ↑F and ↓F will also sometimes be writtenas proc(F ) and proc(¬F ) respectively. An active process log is a set of processes.Definitions 8–15 concern the identification of fluent changes following instantaneously from a given state and set ofactions. A causal chain represents a possible instantaneous series of knock-on effects (i.e. ramifications) implied by thecausal laws. There is a repeated two-phase mechanism for constructing the “nodes” of causal chains — a triggering phase inwhich new processes are generated from c-propositions applicable at that point, immediately followed by a resolution phasein which some of the already-active processes complete, resulting in an update of the corresponding fluents’ truth values.The process triggering is appropriately limited by the p-propositions. The triggering and completion of a particular processmay be separated by several steps in the chain, so that consideration of all such chains gives an adequate treatment of“race” conditions between competing instantaneous effects. Chains terminate either because they reach a state from whichno change is possible (a static node) or because they loop back on themselves. We have made the working (but retractable)assumption that actions trigger processes only at the beginning of such chains, at which point the actions are “consumed”.Definition 8 (Causal node). A causal node (or node) is a tuple (cid:14)S, B, P (cid:15), where S is a state, B is a set of action constantsand P is an active process log. (cid:14)S, B, P (cid:15) is fully resolved iff P = ∅, and is a-consistent w.r.t. a domain description D iff S isa-consistent w.r.t. D.For example, the causal node intuitively associated with time 2 in Examples 1 and 2 is (cid:14){DoorOpen}, {PressOpen,PressClose}, ∅(cid:15).3 An interesting (and more contentious) variation of Example 8 is to delete (BC4) and (BC6), and replace (BC7) with “(Broken ∧ ¬Running ∧ ¬Alarm ∧ATM) holds-at 0” (so that the car is already broken at 1). ME ’s semantics still gives the two models with Alarm true in one and false in the other.This is because it treats (BC3) only as a “stability” constraint at the temporal granularity of “observable” time, and not as a “definitional” constraint thatwould transcend all levels of temporal granularity. Note, however, that we could eliminate the model in which Alarm was true by adding the p-proposition“Broken prevents Running”, meaning that Broken prevents Running from being caused (even instantaneously).A. Kakas et al. / Artificial Intelligence 175 (2011) 49–7859Definition 9 (Triggering). Let D be a domain description, N = (cid:14)S, B, P (cid:15) a node, Lt a set of fluent literals, P t = {proc(L) |L ∈ Lt}, and Bt a set of action constants. The set (Bt ∪ P t) is triggered at N with respect to D iff(1) Bt ⊆ B.(2) For each p-proposition “φ prevents E” in D, either φ is not satisfied in S or E (cid:2) (Bt ∪ Lt).(3) For each L ∈ Lt there is a c-proposition “C causes L” in D such that(i) for each action constant A ∈ C , A ∈ Bt ,(ii) for each action literal ¬ A ∈ C , A /∈ Bt , and(iii) for each fluent literal L(cid:9) ∈ C , L(cid:9) ∈ S.(Bt ∪ P t) is maximally triggered at N with respect to D iff there is no other set (B(cid:9)to D such that (Bt ∪ P t) is a strict subset of (Bt .(cid:9)t) or Bt is a strict subset of B∪ P(cid:9)t(cid:9)t∪ P(cid:9)t) also triggered at N with respectFor example, if N is (cid:14){DoorOpen}, {PressOpen, PressClose}, ∅(cid:15) and D is the domain of Example 2, then {PressClose} ∪in the above definition as {¬DoorOpen}). For Example 1,{↓DoorOpen} is maximally triggered at N w.r.t. D (with Lt{PressOpen, PressClose} ∪ {↑DoorOpen, ↓DoorOpen} is the only maximally triggered set at N w.r.t. D.Definition 10 (Process successor). Let D be a domain description and N = (cid:14)S, B, P (cid:15) a node. A process successor of N w.r.t. Dis a node of the form (cid:14)S, Bt , (P ∪ P t)(cid:15), where (Bt ∪ P t) is maximally triggered at N with respect to D.The node (cid:14){DoorOpen}, {PressOpen, PressClose}, ∅(cid:15), has the unique process successor (cid:14){DoorOpen}, {PressOpen, PressClose},{↑DoorOpen, ↓DoorOpen}(cid:15) in the context of Example 1.Definition 11 (Resolvant). Let N = (cid:14)S, B, P (cid:15) and NP = P(cid:9) = ∅, or there exists a non-empty subset R of P such that the following conditions hold.(cid:9)(cid:15) be causal nodes. N(cid:9), ∅, P(cid:9) = (cid:14)S(cid:9)is a resolvant of N iff either S(cid:9) = S and(cid:9) = P \ R.(1) P(2) For each fluent constant F such that both ↑F and ↓F are in P , either both or neither ↑F and ↓F are in R.(3) For each fluent constant F(cid:9)(i) if ↑F ∈ R and ↓F /∈ R then F ∈ S,(ii) if ↓F ∈ R and ↑F /∈ R then ¬F ∈ S(cid:9)(iii) if ↓F /∈ R and ↑F /∈ R then F ∈ S(cid:9),iff F ∈ S.(cid:9)Nis a full resolvant of N iff P(cid:9) = ∅.The node (cid:14){DoorOpen}, {PressOpen, PressClose}, {↑DoorOpen, ↓DoorOpen}(cid:15) has two full resolvants in the context of Exam-in Condition (3) of theple 1 — (cid:14){DoorOpen}, ∅, ∅(cid:15) and (cid:14){¬DoorOpen}, ∅, ∅(cid:15). This is because none of the constraints on Sabove definition are applicable.(cid:9)Definition 12 (Stationary/static nodes). Let D be a domain description and N = (cid:14)S, B, P (cid:15) a causal node. N is stationary iff foreach resolvant (cid:14)S(cid:9) = S. N is static w.r.t. D iff every process successor of N w.r.t. D is stationary.(cid:9)(cid:15) of N, S(cid:9), ∅, PThe central definition of causal chains now follows. Each non-terminating resolvant node in a chain represents an instan-taneous intermediary state in the middle of a sequence of ramifications, together with the unresolved processes that maycontribute towards the continuation of the sequence. The definition is slightly complicated by the need to deal with loops— Conditions (2), (3) and (4) below ensure that all chains will end when the first static or repeated node is encountered.Definition 13 (Causal chain). Let D be a domain description and let N0 be a node. A causal chain rooted at N0 with respectto D is a (finite) sequence N0, N1, . . . , N2n of nodes such that for each k, 0 (cid:3) k (cid:3) n − 1, N2k+1 is a process successor of N2kw.r.t. D and N2k+2 is a resolvant of N2k+1, and such that the following conditions hold:(1) N2n is fully resolved.(2) N2n is static, or there exists k < n s.t. N2n = N2k.(3) If there exists j < k (cid:3) n s.t. N2 j = N2k then k = n.(4) There does not exist a k < n s.t. N2k is static.In the context of Example 1, Fig. 1 shows the tree of all possible causal chains with the starting node (cid:14){DoorOpen},(cid:9){PressClose, PressOpen}, ∅(cid:15). N1 is the unique process successor of N0, and the nodes N2 and N2 (which are both static) arethe only resolvants of N1. Fig. 2 shows the corresponding tree for Example 2 — now N0 has two process successors, onewhere PressClose succeeds and ↓DoorOpen is triggered and one where PressOpen succeeds and ↑DoorOpen is triggered.60A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78N0: (cid:14){DoorOpen}, {PressClose, PressOpen}, ∅(cid:15)↓N1: (cid:14){DoorOpen}, {PressClose, PressOpen}, {↑DoorOpen, ↓DoorOpen}(cid:15)N2: (cid:14){DoorOpen}, ∅, ∅(cid:15)N(cid:9)2: (cid:14){¬DoorOpen}, ∅, ∅(cid:15)Fig. 1. A tree of causal chains in Example 1.N0: (cid:14){DoorOpen}, {PressClose, PressOpen}, ∅(cid:15)(cid:25)(cid:25)(cid:26)(cid:26)N1: (cid:14){DoorOpen}, {PressOpen}, {↑DoorOpen}(cid:15)↓N2: (cid:14){DoorOpen}, ∅, ∅(cid:15)N(cid:9)1: (cid:14){DoorOpen}, {PressClose}, {↓DoorOpen}(cid:15)↓(cid:9)2: (cid:14){¬DoorOpen}, ∅, ∅(cid:15)NFig. 2. A tree of causal chains in Example 2.N0: (cid:14){On}, ∅, ∅(cid:15)↓N1: (cid:14){On}, ∅, {↓On}(cid:15)↓N2: (cid:14){¬On}, ∅, ∅(cid:15)↓N3: (cid:14){¬On}, ∅, {↑On}(cid:15)↓N4: (cid:14){On}, ∅, ∅(cid:15)N(cid:9)0: (cid:14){¬On}, ∅, ∅(cid:15)↓(cid:9)1: (cid:14){¬On}, ∅, {↑On}(cid:15)↓NNN(cid:9)2: (cid:14){On}, ∅, ∅(cid:15)↓(cid:9)3: (cid:14){On}, ∅, {↓On}(cid:15)↓(cid:9)4: (cid:14){¬On}, ∅, ∅(cid:15)NFig. 3. Causal chains in Example 9.Example 9 shows why it is necessary to take loops into consideration when defining causal chains. Fig. 3 shows the onlytwo possible causal chains for this domain. In both chains, Condition (2) of Definition 13 is satisfied with k = 0 and n = 2.As regards Example 8, we may form several causal chains starting from the node corresponding to time 1. Here is achain terminating with a state in which Alarm holds (Br = Broken, Ru = Running, Al = Alarm):N0: (cid:14){¬Br, ¬Ru, ¬Al, ATM}, {Break, TurnKey}, ∅(cid:15)N1: (cid:14){¬Br, ¬Ru, ¬Al, ATM}, {Break, TurnKey}, {↑Br, ↑Ru}(cid:15)N2: (cid:14){Br, Ru, ¬Al, ATM}, ∅, ∅(cid:15)N3: (cid:14){Br, Ru, ¬Al, ATM}, ∅, {↓Ru, ↑Al}(cid:15)N4: (cid:14){Br, ¬Ru, Al, ATM}, ∅, ∅(cid:15)Here is another chain terminating with a state in which ¬Alarm holds:N0: (cid:14){¬Br, ¬Ru, ¬Al, ATM}, {Break, TurnKey}, ∅(cid:15)N1: (cid:14){¬Br, ¬Ru, ¬Al, ATM}, {Break, TurnKey}, {↑Br, ↑Ru}(cid:15)(cid:9)2: (cid:14){Br, ¬Ru, ¬Al, ATM}, ∅, {↑Ru}(cid:15)(cid:9)3: (cid:14){Br, ¬Ru, ¬Al, ATM}, ∅, {↓Ru, ↑Ru}(cid:15)(cid:9)4: (cid:14){Br, ¬Ru, ¬Al, ATM}, ∅, ∅(cid:15)NNNNodes, and in particular nodes that terminate causal chains, do not necessarily contain a-consistent states. But causal chainsthat do not terminate a-consistently are not discarded when computing direct and indirect instantaneous effects. Rather, thesemantics identifies proper causal descendants within a tree of all possible causal chains starting from a given root node.4These are a-consistent nodes which are either within the terminating loop of a chain (Condition (1) in Definition 14), orare such that there are no other a-consistent nodes further from the root of the tree (Condition (2) in Definition 14). (For(cid:9)2 are proper causal descendants of N0 by Condition (1) below, with j = k = n = 1. In Fig. 3, N0,example, in Fig. 1, N2 and NN2 and N4 are proper causal descendants of N0 with j = 0 and n = 2.)Definition 14 (Proper causal descendant). Let D be a domain description and let N0 and N be nodes. N is a proper causaldescendant of N0 w.r.t. D iff N is a-consistent w.r.t. D, and there exists a causal chain N0, N1, . . . , N2n w.r.t. D such thatN = N2k for some 0 (cid:3) k (cid:3) n and at least one of the following two conditions holds:(1) There exists j (cid:3) k such that N2 j = N2n.4 Note that in contrast to traditional tree terminology where a root is an “improper descendant”, here the root itself can potentially be a “proper causaldescendant”.A. Kakas et al. / Artificial Intelligence 175 (2011) 49–7861(cid:14){¬LO, ¬BS, OC}, {Promote}, ∅(cid:15)↓(cid:14){¬LO, ¬BS, OC}, {Promote}, {↑LO, ↑BS}(cid:15)↓(cid:26)(cid:25)(cid:14){LO, BS, OC}, ∅, ∅(cid:15)(cid:14){LO, ¬BS, OC}, ∅, {↑BS}(cid:15)↓(cid:14){LO, ¬BS, OC}, ∅, {↑BS}(cid:15)↓(cid:14){LO, BS, OC}, ∅, ∅(cid:15)(cid:14){¬LO, BS, OC}, ∅, {↑LO}(cid:15)↓(cid:14){¬LO, BS, OC}, ∅, {↑LO}(cid:15)↓(cid:14){LO, BS, OC}, ∅, ∅(cid:15)Fig. 4. A tree of causal chains in Example 10.(2) There does not exist a causal chain N0, N1, . . . , N2k, N(cid:9)2k+1, . . . , N(cid:9)2m w.r.t. D and a j such that k < j (cid:3) m and N(cid:9)2 j isa-consistent w.r.t. D.It is also useful to define a stable state as a state that does not always immediately cause its own termination (note thatstable states can be in loops, but must be a-consistent):Definition 15 (Stable state). Let D be a domain description and let S be a state. S is stable w.r.t. D if there exists a node(cid:14)S, ∅, P (cid:15) which is a proper causal descendant of (cid:14)S, ∅, ∅(cid:15).Example 10 (Promotion). An employee gets promoted at time 1. Promotion results in a large office (LO) and big salary (BS).But nobody gets a large office when the building is overcrowded (OC), which it is at time 1:always ¬(OC ∧ LO)Promote causes LOPromote causes BSPromote occurs-at 1(¬LO ∧ ¬BS ∧ OC) holds-at 1(PR1)(PR2)(PR3)(PR4)(PR5)The tree of possible causal chains that arise at time 1 in this example, with the single proper causal descendant of theroot node underlined, is given in Fig. 4.This example illustrates the role of a-propositions in defining possible change. In contrast with p-propositions, theydo not a-priori block processes from starting (being triggered). Rather, in the micro-cosmos of causal change at a singletime-point, they even allow instantaneous change to occur that would violate them, provided that terminating nodes areconsistent with them. If the terminating nodes are not consistent, as in this example, then we take as the possible changethe deepest nodes that are consistent in the sense that for each such node there is no other node in a branch emanatingfrom it that is also a-consistent. Hence a-propositions, as properties on the macro-cosmos of the observed states, constrainwhich triggered process are allowed to complete.3.3. ME base semantics; time and temporal changeIf a causal node corresponds to a particular time-point in the narrative of a given domain description (e.g., in Fig. 1, N0corresponds to time 2), then Definitions 16–22 below ensure that the states within its proper causal descendants indicatepossible choices as to which fluents will change values in the time period immediately afterwards. These definitions arelargely modifications of those in [16], but with the notion of a change set replacing that of initiation/termination points.Definition 16 (Interpretation/event matching). An interpretation of ME is a mapping H : (Φ ∪ (cid:4)) × Π → {true, false}. Hevent matches the domain description D iff{(cid:14) A, T (cid:15) | H( A, T ) = true} = {(cid:14) A, T (cid:15) | “ A occurs-at T ” ∈ D}.Definition 17 (Time-point satisfaction). Given a fluent formula φ of ME and a time-point T , an interpretation H satisfies φat T iff the mapping M T defined by ∀F , M T (F ) = H(F , T ) is a model of φ. Given a set Z of fluent formulae, H satisfies Zat T iff H satisfies φ at T for each φ ∈ Z .Definition 18 (State/event base at a time-point). Let D be a domain description, H an interpretation, and T a time-point. Thestate at T w.r.t. H , denoted S(H, T ), is the state {F | H(F , T ) = true} ∪ {¬F | H(F , T ) = false}. The event base at T w.r.t. H ,denoted B(H, T ), is the set { A | H( A, T ) = true}.62A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78The definitions of a causal frontier and a change set now follow. A causal frontier at a particular time-point representsthe state in a terminating node of a causal chain triggered at that time-point. The associated change set represents thedifference (in terms of fluent literals) between this state and the state at the start of the causal chain.Definition 19 (Causal frontier). Let D be a domain description, T a time-point, H an interpretation and Sa causal frontier of H at T w.r.t. D iff there exists a node N = (cid:14)S(cid:14)S(H, T ), B(H, T ), ∅(cid:15) w.r.t. D.is(cid:9), B, P (cid:15) such that N is a proper causal descendant ofa state. S(cid:9)(cid:9)Definition 20 (Change set). Let D be a domain description, H an interpretation, T a time-point and C a set of fluent literals.C is a change set at T w.r.t. H iff there exists a causal frontier S of H at T w.r.t. D such that C = S \ S(H, T ).Definition 21 (Change mapping). Let Φ∗language. A change mapping is a mapping c : Π → 2Φ∗.be the set of all fluent literals (i.e. all fluent constants and their negations) in theDefinition 22 (Model). Let D be a domain description and let H be an interpretation that event matches D. Then H is amodel of D iff there exists a change mapping c such that for all T , c(T ) is a change set at T w.r.t. H , and the followingthree conditions hold for every fluent literal L and time-points T 1 ≺ T 3:(1) If H satisfies L at T 1, and there is no time-point T 2 s.t. T 1 (cid:2) T 2 ≺ T 3 and L ∈ c(T 2), then H satisfies L at T 3.(2) If L ∈ c(T 1), and there is no time-point T 2 s.t. T 1 ≺ T 2 ≺ T 3 and L ∈ c(T 2), then H satisfies L at T 3.(3) H satisfies the following constraints:– For all h-propositions “φ holds-at T ” in D, H satisfies φ at T .– For all time-points T , S(H, T ) is a stable state.Intuitively, Condition (1) above states that fluents change their truth values only via successful effects of c-propositions,and (2) states that successfully initiating a literal establishes its truth value as true. Note also that Condition (3)’s require-ment of stability ensures that S(H, T ) is a-consistent.Definition 23 (Consistency and entailment). A domain description D is consistent if it has a model. D entails the h-proposi-tion “φ holds-at T ”, written D |(cid:19) φ holds-at T , iff for every model M of D, M satisfies φ at T .Example 11 (Faulty electric circuit). The current in a faulty circuit is switched on causing a broken fuse, which in turnterminates the current:{SwitchOn} causes ElectricCurrent{ElectricCurrent} causes BrokenFuse{BrokenFuse} causes ¬ElectricCurrentalways ¬(ElectricCurrent ∧ BrokenFuse)SwitchOn occurs-at 1(EC1)(EC2)(EC3)(EC4)(EC5)One causal chain that could be triggered at time 1 (with non-a-consistent nodes N4 and N5) is:N0: (cid:14){¬ElectricCurrent, ¬BrokenFuse}, {SwitchOn}, ∅(cid:15)N1: (cid:14){¬ElectricCurrent, ¬BrokenFuse}, {SwitchOn}, {↑ElectricCurrent}(cid:15)N2: (cid:14){ElectricCurrent, ¬BrokenFuse}, ∅, ∅(cid:15)N3: (cid:14){ElectricCurrent, ¬BrokenFuse}, ∅, {↑BrokenFuse}(cid:15)N4: (cid:14){ElectricCurrent, BrokenFuse}, ∅, ∅(cid:15)N5: (cid:14){ElectricCurrent, BrokenFuse}, ∅, {↓ElectricCurrent}(cid:15)N6: (cid:14){¬ElectricCurrent, BrokenFuse}, ∅, ∅(cid:15)This chain is well-formed because N6 is the first static resolvant node and is fully resolved (Definition 13). N6 is a-consistentand therefore is a proper causal descendant of N0 (Definition 14). So {¬ElectricCurrent, BrokenFuse} is a causal frontier at1 of any interpretation that satisfies (¬ElectricCurrent ∧ ¬BrokenFuse) at 1 (Definition 19), thus providing the change set{BrokenFuse} (Definition 20). Note that at the temporal granularity level of the representation of this example (i.e. thegranularity of models and of h-propositions), ElectricCurrent, the cause of BrokenFuse, is never true! ElectricCurrent is trueonly at a finer granularity (the granularity inside causal chains).A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78634. Properties and characteristics of ME4.1. Results concerning elaboration toleranceAs we have seen, ME provides principled, general mechanisms for causal laws to be qualified both by each other and bystatic laws, thus integrating all endogenous qualifications within one base-level semantic framework. We have also hintedthat ME provides a high degree of modularity by its separation of information about causality (c-, p- and a-propositions),narrative information about attempted actions (o-propositions), and narrative information in the form of observations aboutfluents (h-propositions), and that these qualities make ME domain descriptions particularly elaboration tolerant. We nowsubstantiate these claims with some formal results.Theorem 1 and its corollaries below effectively show that an action occurrence (o-proposition) cannot be used as a kindof “observation” about what holds at the associated time-point. We label these results as “free will” properties because theyeffectively state that an agent may attempt any action in any circumstance. This is an important principle of modularitybecause it helps separate narrative information about actions from narrative information about fluents, and an importantprinciple of elaboration tolerance because it allows us to add arbitrary o-propositions to the theory that refer to currentand future time-points, irrespective of observations (h-propositions) referring to past time-points. Theorem 2 focuses onthe elaboration tolerance of causal knowledge, showing in particular that we can add any arbitrary c- and p-propositionsto a previously consistent collection of causal statements. This is because of the “completeness” of our solution to theendogenous qualification problem — ME is guaranteed to automatically qualify the new and existing causal knowledge sothat it is mutually compatible.Definition 24 (Pre- and post-observation/action points). Given a domain description D, a post-observation point of D is atime-point T p such that, for every h-proposition of the form “φ holds-at T ” in D, T (cid:2) T p . A pre-action point (respectivelypost-action point) is a time-point Ta such that, for every o-proposition “ A occurs-at T ” in D, Ta (cid:2) T (respectivelyTa (cid:29) T ).Definition 25 (Projection domain description). The domain description D is a projection domain description if there exists atime-point which is both a post-observation point and a pre-action point of D.Lemma 1 (Existence of proper causal descendant). Let D be a finite domain description and let N0 = (cid:14)S0, B0, ∅(cid:15) be a node such thatS0 is a-consistent w.r.t. D. Then there exists a node N = (cid:14)S, B, P (cid:15) such that N is a proper causal descendant of N0. Furthermore, if S0is stable w.r.t. D then so is S.Proof. It is sufficient to show that there exist a non-zero, finite number of causal chains rooted at N0 w.r.t. D. The lemmathen follows by consideration of the (finite) tree of all causal chains rooted at N0, by noting that by Definition 14, if therewere no proper causal descendants of N0 then for any a-consistent node in the tree there would be another descendantnode that was also a-consistent. Given that N0 is a-consistent and the tree is finite this would lead to a contradiction.To show that there exists a causal chain rooted at N0 w.r.t. D, we argue as follows. First, notice that for any node therealways exists a (possibly empty) maximally triggered set w.r.t. D, and therefore there always exists at least one processsuccessor. By definition there also always exists a full resolvant of any node. Therefore the set of infinite sequences of theform N0, N1, . . . , N2m, . . . such that for each k, N2k+1 is a process successor of N2k w.r.t. D and N2k+2 is a full resolvant ofN2k+1 is non-empty. Consider the set of all finite sub-sequences of this set which start at N0 and have as their last nodethe first N2k which either appears earlier in the sub-sequence or is static w.r.t. D. Such a last node exists for each sequencebecause of the finiteness of D. By construction, each of these sub-sequences satisfy Conditions (1) to (4) of Definition 13and therefore are causal chains rooted at N0 with respect to D.For a finite domain D, there can only be a finite number of causal chains because of the repetition restriction of Condi-tion (3) of Definition 13. (cid:2)Lemma 2 (Existence of change set). Let D be a finite domain description, and let H be an interpretation of D and T be a time-pointsuch that S(H, T ) is a-consistent w.r.t. D. Then there exists a change set at T w.r.t. H .Proof. This follows directly from Lemma 1. (cid:2)Lemma 3 (Existence of empty change set). Let D be a domain description and T be a post-observation and post-action point of D. Let(cid:9) (cid:29) T . Then ∅ is a changeS be a state which is stable w.r.t. D, and let H be an interpretation of D such that S = S(H, Tset at T(cid:9)) for some Tw.r.t. H .(cid:9)Proof. This follows directly from Definition 15. (cid:2)64A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78Theorem 1 (Free will theorem). Let M be a model of a finite domain description D, let O be a finite set of o-propositions, and let Tn bea time-point which is both a post-observation point for D and a pre-action point for O . Then there is a model M O of D ∪ O such thatfor any fluent F and time-point T (cid:2) Tn, M O (F , T ) = M(F , T ).Proof. By induction on the number, k, of o-propositions in O . The base case of k = 0 is trivial. Suppose that the resultholds whenever O contains k o-propositions and consider a set O with k + 1 o-propositions. Choose an o-proposition,(cid:9) (cid:29) T g (i.e.A occurs − at T g , from O such that there exists no other o-proposition, Adenote the set O minus the element A occurs − at T g .one of the o-propositions with the greatest time-point). Let Osuch that for any fluent F and time-point T (cid:2) Tn,By the inductive hypothesis on OM O (cid:9) (F , T ) = M(F , T ).there exists a model M O (cid:9) of D ∪ OWe build the required model M O of D ∪ O as follows. For any fluent F and time-point T(cid:9)).(cid:9) ≺ T g this is equal to the change mapping of the model M O (cid:9) . For theChoose a change mapping c such that for any time Ttime-point T g , consider the state, S(M O (cid:9) , T g), at T g w.r.t. M O (cid:9) . By Lemma 2 there exists a change set, C, at T g w.r.t. M O (cid:9) .We then let c(T g) = C.(cid:9) occurs − at T(cid:9) (cid:2) T g , M O (F , T(cid:9)) = M O (cid:9) (F , Tin O with TWe complete the model M O and the change mapping c for time-points after T g as follows. For any fluent F if F , ¬F /∈ C(cid:9)(cid:9)) = true and if ¬F ∈ C(cid:9)(cid:9) (cid:29) T g , M O (F , T(cid:9)(cid:9)(cid:9)(cid:9)(cid:9)(cid:9) (cid:29) T g , M O (F , T(cid:9)(cid:9) (cid:29) T g , M O (F , T(cid:9)(cid:9)) = M O (cid:9) (F , T g). Otherwise, if F ∈ C then for any T(cid:9)(cid:9)) = false. For any time-point T(cid:9)(cid:9) (cid:29) T g , c(T(cid:9)(cid:9)) = ∅.then for any Tthen for any TBy construction and Lemma 3, c is a change mapping w.r.t. M O . The interpretation M O satisfies the three axioms of(cid:9) (cid:2) T g , Condition (3.ii)a model. Conditions (1) and (2) follow directly from its construction. Condition (3.i) is trivial. For T(cid:9)(cid:9) (cid:29) T g , the model M O is constructed directly from the change set C, and sofollows from the stability of S(M O (cid:9) , Tthe stability Condition (3.ii) follows from the observation that, by Definitions 14 and 15, the state component of a nodewhich is a proper causal descendant must necessarily be stable. (cid:2)(cid:9)). For TCorollary 1 (Free will corollary). Let D and DD and Dmodel M. Letdiffer only by o-propositions referring to time-points greater than or equal to Tn and let M be a model of D. Then there is aof D(cid:9)(F , T ) for all fluent constants F and all time-points T such that T (cid:2) Tn.be domain descriptions and let Tn be a post-observation point for both D and Dsuch that M(F , T ) = M(cid:9)(cid:9)(cid:9)(cid:9)(cid:9)can be constructed from D by first remov-Proof. This follows directly from Lemma 3 and Theorem 1, observing that Ding all the o-propositions in D which refer to time-points greater than or equal to Tn, and then adding the requiredo-propositions for D. (cid:2)(cid:9)(cid:9)Corollary 2 (Action elaboration tolerance corollary). Let D be a consistent domain description and let O be a finite set of o-propositions.If there exists a time-point Tn which is both a post-observation point for D and a pre-action point for O , then D ∪ O is consistent.Proof. This follows directly from Theorem 1. (cid:2)Theorem 2 demonstrates the robustness and elaboration tolerance of ME theories by showing that their consistency iscontingent only on the internal consistency of the static laws and on whether observations match with predicted effects.Theorem 2 (Theorem of causal elaboration tolerance). Let Da be a consistent domain description consisting only of a-propositions andlet E be a finite set of o-, c- and p-propositions. Then Da ∪ E is also a consistent domain description.Proof. Consider the domain D obtained from Da ∪ E by deleting all its o-propositions. Let val : Φ → {true, false} be a truthassignment on the set of fluents, Φ, of Da ∪ E which is a model of the a-propositions of Da (and hence also of D). Let Hbe the interpretation of D given by H(F , T ) = val(F ) for all time-points T and any fluent F . By Lemma 3 the empty set is achange set at any time-point T w.r.t. H . It is easy to then see that H is a model of D with these change sets. By Theorem 1the domain Da ∪ E, which can be obtained from D by adding back to it the o-propositions in E, has a model (that agreeswith H for all time-points smaller than or equal to the earliest time-point referred to in the (finite) o-propositions of E). (cid:2)4.2. The qualifying role of a-propositionsAs we have seen, ME ’s semantics allows the a-propositions in a domain description to implicitly qualify its causal effectlaws. It is natural to ask whether, in principle, we could do without the qualifying role of a-propositions (we would still ofcourse need to employ some mechanism for constraining, for example, the initial state). In other words, could the causalknowledge contained within an (arbitrary) domain description be re-written without a-propositions by including insteadextra explicit qualifications within (possibly additional) c- and p-propositions? And even if the formal correctness of sucha general transformation method could be ascertained, would it result in reasonably-sized, elaboration tolerant domaindescriptions, and could it in the general case be computed within a reasonable time-frame?It is outside the main focus of this paper to study these questions in detail and to answer them definitively — domainssuch as Example 8 with “side effects” (see in particular the remarks in the associated footnote) give an indication that aA. Kakas et al. / Artificial Intelligence 175 (2011) 49–7865(cid:14){¬AliceIn, ¬BobIn}, {AliceEnters, BobEnters}, ∅(cid:15)↓(cid:14){¬AliceIn, ¬BobIn}, {AliceEnters, BobEnters}, {↑AliceIn, ↑BobIn}(cid:15)↓(cid:14){AliceIn, BobIn}, ∅, ∅(cid:15)(cid:25)(cid:26)(cid:14){AliceIn, ¬BobIn}, ∅, {↑BobIn}(cid:15)(cid:14){¬AliceIn, BobIn}, ∅, {↑AliceIn}(cid:15)↓(cid:14){AliceIn, ¬BobIn}, ∅, {↑BobIn}(cid:15)↓(cid:14){AliceIn, BobIn}, ∅, ∅(cid:15)↓(cid:14){¬AliceIn, BobIn}, ∅, {↑AliceIn}(cid:15)↓(cid:14){AliceIn, BobIn}, ∅, ∅(cid:15)Fig. 5. Causal chains in Example 12.proof one way or the other5 for such a transformation would be technically involved. However, it is perhaps worth touchingthe surface of some of the issues involved in this question by considering an example.Example 12 (Full lift). A certain lift cannot hold more than one person. Two people attempt to enter the lift at the sametime:{AliceEnters} causes AliceIn{BobEnters} causes BobInalways ¬(AliceIn ∧ BobIn)¬AliceIn ∧ ¬BobIn holds-at 0AliceEnters occurs-at 1BobEnters occurs-at 1(FL1)(FL2)(FL3)(FL4)(FL5)(FL6)The tree of causal chains for this domain at time 1 is shown in Fig. 5. The two proper causal descendants (under-lined) show that under ME ’s semantics the two causal laws (FL1) and (FL2) are non-deterministically qualified by thea-proposition of the domain.(cid:9)(cid:9)) and (FL2Can this qualifying effect of the a-proposition be obtained in some other way? Let us first consider the naive approachof simulating the implicit qualification effect of the a-proposition (FL3) only by adding extra explicit qualifying conditions to) respectively. We consider the tree of causal chains for this new domain at time 1(FL1) and (FL2), to form (FL1starting from a state where both AliceIn and BobIn are false as before. There are two cases to consider. First, suppose that) are satisfied by the initial node. In this case we end up with the same tree ofthe extra conditions of both (FL1causal chains as in the original domain, the end nodes of which would give rise to a model in which both AliceIn and BobIn) are not satisfied by the initial node. Inwere true. Second, suppose the extra conditions of at least one of (FL1this case the corresponding effect will not be triggered. This implies that the new domain will not have at least one of thetwo models that ME gives to the original domain.) and (FL2) and (FL2(cid:9)(cid:9)(cid:9)(cid:9)An equivalent domain without extra c- or p-propositions is therefore impossible in this case. Intuitively, the role of thea-proposition (FL3) is best captured explicitly with three extra p-propositions:(cid:17) prevents {AliceIn, BobIn}AliceIn prevents {BobIn}BobIn prevents {AliceIn}It is easy to see that replacing (FL3) with these propositions does indeed give rise to the same models (even when onlyone of the fluent literals in (FL4) is negative, although these replacements do not of course independently constrain theinitial state in the same way as (FL3)). But this is not to say that, from a practical point of view, a-propositions are unnec-essary in examples such as this. For a similar example with a lift that cannot contain more than n people, the equivalenttransformation to exclude a-propositions will give rise to a domain with size exponentially larger in n than the origi-nal.So it is clear that a-propositions are a useful addition to the language. Moreover, Theorem 1 and its corollaries makea-propositions especially useful when thinking about ME in terms of state transition systems. A collection of c- and p-prop-ositions effectively defines a state transition graph, which is complete in the sense that each arbitrary finite collectionof actions gives rise to at least one directed edge from each vertex of the graph. The results of the previous subsectionguarantee that the addition of an a-proposition to the theory filters out vertices of the graph without compromising this5 To prove, for example, that a-propositions are necessary, we would have to show that, for some particular collection T of c-, p- and a-propositions,(cid:9) ∪ N have the same setof c- and p-propositions such that for any collection N of o- and h-propositions T ∪ N and Tthere does not exist any collection Tof models provided that the h-propositions in N ensure satisfaction of the a-propositions in T at an initial time-point.(cid:9)66A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78completeness.6 In turn this means that ME can guarantee static constraint properties that our problem specification mayrequire by simply adding the associated a-propositions in the domain description, without affecting the completeness orconsistency of the specification as a whole. We have studied the question of explicating the implicit qualifications of a-prop-ositions in more detail in a technical annex7 to this paper [14].5. Fluents with default valuesIn some domains it is useful to be able to specify that some fluents are “normally true” or “normally false”. For example,cars are normally not broken. In this section we extend the syntax of Modular-E with n-propositions to facilitate theexpression of such information. As we will see in Section 6, this extension also helps us address the exogenous qualificationproblem in a natural way.Definition 26 (N-theory or n-domain description). An n-theory or n-domain description in ME is a domain description whichmay additionally contain n-propositions of the formnormally Lwhere L is a fluent literal. An interpretation is a base model or b-model of an n-theory iff it is a model of the n-theorywithout its n-propositions.We have taken the view that n-propositions should play a relatively weak role in a domain description compared withexplicit causal information (and specific observations). Hence the intended meaning of “normally L” is “if there is noevidence or cause for L, assume L by default”. To illustrate this in more detail, it is helpful to consider various combinationsof the following n-, c- and h-propositions:normally ¬BrokenVeryColdWeather causes Brokennormally VeryColdWeather¬Broken holds-at 1(N1)(N2)(N3)(N4)= {(N1)}, D2n= {(N1), (N2)}, D3n= {(N1), (N2), (N3)}, and D4n= {(N1), (N2), (N3), (N4)}. Since n-propositions are “de-Let D1nfault statements”, ME provides semantics for them by using them to define a preference relation between b-models (i.e.,the models of the equivalent domain description without n-propositions). As we will see, we then define “n-models” as then should have just one n-model in which ¬Brokenmost preferred b-models under this relation. We take the view that D1holds at all time-points (assuming Broken is the only fluent in the language). D2n should have two n-models, one in whichVeryColdWeather and Broken are both true and one in which they are both false. In the context of D2n, (N1) should elimi-nate the combination of ¬VeryColdWeather and Broken, and (N2) should eliminate the combination of VeryColdWeather and¬Broken. But note that (N1) should not eliminate the combination of VeryColdWeather and Broken as an n-model of D 2n ,because (N2) gives a cause for Broken in this context. As regards D3n , the addition of (N3) should also eliminate the combi-nation ¬VeryColdWeather and ¬Broken (since there is no identifiable cause for ¬VeryColdWeather), leaving just one n-modelwith VeryColdWeather and Broken. As before, (N1) should not in this case eliminate this remaining model because (N2) givesBroken an identifiable cause. Finally, in the context of D4n , the addition of (N4) should override the default of (N3) to givejust one n-model in which ¬VeryColdWeather and ¬Broken (the same model as this domain description would have withoutthe n-propositions).For domains with a least time-point (i.e. time 0 in the case of the naturals), it is only necessary to compare b-models atthis initial time-point, since, in all ME models, all fluent truth values (default or otherwise) persist until their converse iscaused. But, since ME can also accommodate time structures such as the reals or integers with no least point, for maximumgenerality we compare b-models at all time-points in some initial interval of the time-line. To identify which fluents have a“cause” at such time-points, we can build upon the notion of stability (Definition 15) used to provide a pointwise constrainton models in Definition 22. Stability ensures that, at any time-point, the processes which are triggered by the associatedstate alone (i.e. disregarding actions) can result (directly or indirectly) in a return to that same state. We can examine these6 State transition graphs are widely used in Computer Science to model and specify system behavior, and it is often desirable to prove certain propertiesof these graphs. For example, in a safety-critical event-driven system it may be necessary to demonstrate that no possible combination of inputs (events)will ever lead to an unsafe output state. Using ME as the requirements specification language, it would be possible to guarantee such a safety constraintby simply adding the associated a-proposition, without compromising the completeness or consistency of the specification as a whole.7 In this we argue that an attempt to rely solely on explicit qualifications when representing a domain is often impossible due to the different natureof a-propositions from c-propositions and p-propositions. Under some severe restrictions on the domain description a translation is possible but thismight require an exponential growth of the domain size, or exponential-time reasoning in order to identify appropriate qualifications. Furthermore, suchtranslated domains compromise elaboration tolerance, in the sense that the translation is not modular: adding new information to the domain can requirethe re-translation of the whole domain, not just the newly added statements.A. Kakas et al. / Artificial Intelligence 175 (2011) 49–7867same processes to identify “instantaneous causes” for some of the fluent literals in the state (Condition (2) in the definitionbelow). Because causal chains terminate at static nodes, we also need to identify “one step” instantaneous causes separately(Condition (1) in the definition below).Definition 27 (Instantaneous cause). Let D be an n-domain description, T be a time-point, L be a fluent literal, and M be ab-model of D. L has an instantaneous cause at T w.r.t. D and M iff either one of the following conditions holds:(1) (cid:14)S(M, T ), ∅, ∅(cid:15) is static and has a (stationary) process successor w.r.t. D that contains proc(L).(2) There exists a k and n such that 0 (cid:3) k (cid:3) n, a set P of processes and a causal chain N0, N1, . . . , N2k, . . . , N2n such that(i) N0 = (cid:14)S(M, T ), ∅, ∅(cid:15),(ii) N2k = (cid:14)S(M, T ), ∅, P (cid:15),(iii) N2k is a proper causal descendant of N0, and(iv) proc(L) appears in N0, . . . , N2k.Continuing with our example, we can note that D3n has three b-models:M1 satisfying (VeryColdWeather ∧ Broken) at all time-points,M2 satisfying (¬VeryColdWeather ∧ Broken), andM3 satisfying (¬VeryColdWeather ∧ ¬Broken).At each time-point, each of these b-models has just one, single-node causal chain,8 so that we need refer only to Condi-tion (1) in Definition 27 when searching for instantaneous causes. In fact at any given time-point T we can identify justone instantaneous cause in just one model — Broken has an instantaneous cause at T w.r.t. D3n and M1.We can now define what it means for a fluent to have an “abnormal” truth value in an n-domain description:Definition 28 (Fluent abnormality). Let D be an n-domain description, T be a time-point of D, L be a fluent literal, and Mbe a b-model of D. L is a fluent abnormality at T w.r.t. D and M iff(1) M satisfies L at T ,(2) “normally L” ∈ D, and(3) L does not have an instantaneous cause at T w.r.t. D and M.The set of all fluent abnormalities at T with respect to D and M is written FluentAbs(D, M, T ).As regards the example n-domain description D3n , the fluent abnormalities at any time-point T ∈ Π with respect to D3nand each b-model are as follows:FluentAbs(D3FluentAbs(D3FluentAbs(D3n, M1, T ) = ∅n, M2, T ) = {¬VeryColdWeather, Broken}n, M3, T ) = {¬VeryColdWeather}(cid:9)Definition 29 (N-entailment). Let D be an n-domain description, and let M and MMFluentAbs(D, Mh-proposition “φ holds-at T ”, written D |(cid:19)n φ holds-at T , iff for every n-model Mn of D, Mn satisfies φ at T .be b-models of D. M is n-preferable to(cid:9)) ⊂(cid:9)(cid:9) ≺D M. D n-entails the(cid:9)). M is an n-model of D iff there is no other model M, iff there exists a time-point T 0 such that for every time-point Tw.r.t. D, written M ≺D M(cid:9), T(cid:9) (cid:2) T 0, FluentAbs(D, M, Tof D such that M(cid:9)(cid:9)(cid:9)(cid:9)In terms of our example, Definition 29 gives M1 ≺M3 ≺D3nD3nM2, so that M1 is the only n-model, and, for example,D3n|(cid:19)n (VeryColdWeather ∧ Broken) holds-at 0.We now identify one (wide) class of n-theories for which the semantics of n-propositions simplifies considerably, becauseit is not necessary to check for instantaneous causes.Definition 30 (N-simple domain description). Let D be an n-domain description. D is n-simple iff for every pair of propositions“normally L” and “C causes L” in D such that C does not contain a non-negated action constant, L (cid:31)= Land L (cid:31)= L(cid:9).(cid:9)(cid:9)8 Thethese(cid:14){¬VeryColdWeather, Broken}, ∅, ∅(cid:15) and (cid:14){¬VeryColdWeather, ¬Broken}, ∅, ∅(cid:15) respectively.nodes whichsuccessorscompriseprocesssingletheofcausalchainsare(cid:14){VeryColdWeather, Broken}, ∅, {↑Broken}(cid:15),68A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78Fig. 6. Circuit with two light bulbs.For n-simple theories, it follows directly from Definition 27 that it is necessary to check only Conditions (1) and (2)of Definition 28 when identifying fluent abnormalities, and necessary to compare sets of fluent abnormalities only at onearbitrary pre-action point when identifying n-models (see Definition 29).As an illustration, the domain of Fig. 6 is represented in the following example (Example 13) as an n-simple theory.Example 13 (Light bulbs). Pressing a switch causes two light bulbs connected in parallel to light up, as long as the bulbs arenot faulty and the switch is not stuck:normally ¬SwitchStucknormally ¬FaultyBulbAnormally ¬FaultyBulbBPressDownSwitch causes ElectricCurrent{ElectricCurrent, ¬FaultyBulbA} causes LightA{ElectricCurrent, ¬FaultyBulbB} causes LightBSwitchStuck prevents PressDownSwitchalways (¬ElectricCurrent → (¬LightA ∧ ¬LightB))¬ElectricCurrent holds-at 0PressDownSwitch occurs-at 0(LB1)(LB2)(LB3)(LB4)(LB5)(LB6)(LB7)(LB8)(LB9)(LB10)Let Dlb be the n-simple theory {(LB1), . . . , (LB10)}. Assuming time to be represented as the naturals, Dlb has eightb-models corresponding to the eight possible combinations of truth values at time 0 for the fluents SwitchStuck, FaultyBulbAand FaultyBulbB. But only the b-model in which each of these is false has no fluent abnormalities, so that this b-model isthe only n-model and, for example, Dlb |(cid:19)n (LightA ∧ LightB) holds-at 1.Now consider the following (unexpected) observation:¬LightA holds-at 1++= Dlb ∪ (LB11). DLet Dlb has six b-models, since (LB11) eliminates interpretations in which both SwitchStuck andlbFaultyBulbA are false. Just two of these are also n-models — the b-model in which SwitchStuck is true and both FaultyBulbAand FaultyBulbB are false has a single fluent abnormality SwitchStuck at 0, and the b-model in which FaultyBulbA istrue and both SwitchStuck and FaultyBulbB are false contains the single fluent abnormality FaultyBulbA at 0. Hence we+can infer neither “LightB holds-at 1” nor “¬LightB holds-at 1” from Dlb . However, since the two n-models differon the truth value of ElectricCurrent at times after 0, adding the observation “ElectricCurrent holds-at 1” or the con-verse “¬ElectricCurrent holds-at 1” would in each case eliminate one of the n-models, allowing us to infer respectively“LightB holds-at 1” or “¬LightB holds-at 1”.(LB11)Note the similarity of Example 13 to the “life support” example in Section 2.1 (substitute lights A and B for the indicatorlight and life support machine respectively), which gives rise to anomalous models under the approach in [37]. It is clearthat ME solves the problems identified in Section 2.1 whenever fluents with default values can be explicitly identified inthe representation.The extended semantics of the language ME as defined above, in order to incorporate default static knowledge in theformalism, is given through a simple minimization of abnormality on top of the base language semantics. This is linked tothe free-will property of ME in the sense that lack of this property would interfere with the default minimization of thestatic knowledge, causing the simple minimization policy to give anomalous models. Consider the following example thatillustrates this.normally VeryColdWeatherWater causes NewShoots9always ¬(VeryColdWeather ∧ NewShoots)(N1)(N2)(N3)A. Kakas et al. / Artificial Intelligence 175 (2011) 49–7869This domain has two classes of b-models, one where VeryColdWeather is true and one where it is false. The default knowl-edge given by the n-proposition gives the first class as the preferred default class with minimal abnormality. Consider nowthat an action of Water occurs at time 1. If the base framework did not have the free-will property, and in particular ifit failed to regard (N3) as providing an extra qualification for (N2), then some of these b-models would be lost. With theaddition of the action at time 1 the b-models with VeryColdWeather would become inconsistent. As a result we would beleft only with the class of b-models where VeryColdWeather is false and hence the simple minimization of abnormality onthese would not retain the conclusion that VeryColdWeather is true. These would be anomalous models as the attemptedexecution of an action cannot/should not change the default state of affairs of the past. Furthermore if we subsequentlyobserved at time 2 that NewShoots was false then in frameworks where the models with the default state of affairs (i.e.models with VeryColdWeather true) are lost this observation could not be accounted for.We end this section with an extension of Theorem 1 and Corollary 1 which covers n-models and n-entailment.Theorem 3 (Free will theorem for n-domains). Let D1 and D2 be n-domain descriptions and let Tn be a post-observation point for bothD1 and D2. Let D1 and D2 differ only by o-propositions referring to time-points greater than or equal to Tn and let M1 be an n-modelof D1. Then, there is an n-model M2 of D2 such that M1(F , T ) = M2(F , T ) for all fluent constants F and all time-points T such thatT (cid:2) Tn. In particular, for all fluent formulae φ and all time-points T such that T (cid:2) Tn, D1 n-entails “φ holds-at T ” iff D2 n-entails“φ holds-at T ”.(cid:9)a, M(cid:9)1 and D(cid:9)1 and D(cid:9)1 and DProof. Consider the domains DTn is a post-observation time-point for both Dpoints greater than or equal to Tn. Partition the models of each of DMCorollary 1 twice, it follows that there is a bijection between classes of models under D(cid:9)b in the same class, for each fluent F , and for each time-point T (cid:2) Tn, it holds that M(cid:9)2 obtained by removing all n-propositions from D1 and D2, respectively. Clearly,(cid:9)2, and these domains differ only by o-propositions referring to time-(cid:9)2 into classes, where for each pair of models(cid:9)(cid:9)a(F , T ) = Mb(F , T ). Applying(cid:9)2.(cid:9)1 in which M1 belongs. Consider the correspond-(cid:9)2 from this class(cid:9) (cid:2) Tn,(cid:9)), since D1 and D2 differ only by o-propositions referring to time-points greatering class of models under Dof models. Then, for any fluent F and time-point T (cid:2) Tn, M2(F , T ) = M1(F , T ). This implies that for every TFluentAbs(D2, M2, Tthan or equal to Tn.(cid:9)2, according to the bijection discussed above, and let M2 be a model of DConsider an n-model M1 of D1, and the class of models under D(cid:9)1 and classes of models under D(cid:9)) = FluentAbs(D1, M1, TAssume by way of contradiction that M2 is not an n-model of D2. Then, there exists a model M(cid:9)2 that is n-(cid:9)).preferable to M2 w.r.t. D2. Thus, there exists T 0 such that for every T(cid:9)1, accord-Consider the class of models under D(cid:9)ing to the bijection discussed above, and let M1 from this class of models. Then, for any fluent F and(cid:9)(cid:9)),time-point T (cid:2) Tn, M1, Tsince D1 and D2 differ only by o-propositions referring to time-points greater than or equal to Tn. Overall, there exists(cid:9)); a contradiction to the factT min = min{T 0, Tn} such that for every Tthat M1 is an n-model of D1. This proves the first claim.(cid:9) (cid:2) T 0, FluentAbs(D2, M(cid:9)2 belongs. Consider the corresponding class of models under D(cid:9)2 of D(cid:9)) ⊂ FluentAbs(D2, M2, T(cid:9)2(F , T ). This implies that for every T(cid:9) (cid:2) T min, FluentAbs(D1, M(cid:9)) ⊂ FluentAbs(D1, M1, T(cid:9) (cid:2) Tn, FluentAbs(D1, M(cid:9)1 be a model of D(cid:9)) = FluentAbs(D2, M(cid:9)2 in which M(cid:9)1(F , T ) = MFor the second claim consider a time-point T (cid:2) Tn. Note that D1 n-entails “φ holds-at T ” iff every n-model of D1satisfies φ at T . From the first claim, this holds iff every n-model of D2 satisfies φ at T , which then holds iff D2 n-entails“φ holds-at T ”, as required. (cid:2)(cid:9)2, T(cid:9)2, T(cid:9)1, T6. Exogenous qualificationsAs we have seen, ME ’s base semantics offers an elaboration tolerant solution to the endogenous qualification problem,where (general) properties of the domain can implicitly qualify the effect laws. It is, nonetheless, still possible that a domaincan lose its meaning when an expected effect (i.e. an effect that belongs to every change set of every model at some time-point) is observed not to materialize. The causal laws have unexpectedly failed. To illustrate such a scenario let us elaborateExample 3 by adding the observation that the car is not running at time 2.Example 14 (Extended broken car A). The key is turned at time 1 but we subsequently observe that the car is not running.{TurnKey} causes RunningTurnKey occurs-at 1¬Running holds-at 2(BC1)(BC2)(BC-obs2)No known reason (explicit or implicit) can account for this unexpected observation, and the domain is in fact inconsis-tent. The failure of the effect law (BC1) needs to be attributed to an exogenous reason.9 “Shoots” in the gardening sense.70A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78Similarly, an observation contrary to what we expect from a certain effect law may lead us to consider that other effectshave failed to be produced, perhaps because an action has failed to be executed properly for some unknown reason. The“life support example” discussed in Section 2.1 illustrates this.Example 15 (Life support). The life support button has been pushed at time 1 but we subsequently observe that the indicatorlight is not on.{PushButton} causes IndicatorLightOn{PushButton} causes LifeSupportOnPatientVeryIll holds-at 0PushButton occurs-at 1¬IndicatorLightOn holds-at 2(LS1)(LS2)(LS3)(LS4)(LS5)The failure of the first causal law (LS1) could be an isolated failure, or it could be that the PushButton action execution(LS4) failed thus resulting in the absence of all the effects associated with this.A way to reconcile such conflicts (and thus restore elaboration tolerance to the framework) is to assume that every effectlaw of a domain description is additionally qualified by a set of extra preconditions that encapsulate the normal conditionsunder which the law operates successfully [9]. These preconditions are outside the base logic’s language or exogenous [37],and symbolically package together all the unknown conditions necessary for the effect law to successfully generate itseffect. In what follows we will make the working (but retractable) assumption that these preconditions are unique andindependent for each c-proposition in the domain. We will write them in the form NormExo(Law_Id) where Law_Id is theunique identifier of the c-proposition. Similarly, action executions can be exogenously qualified by assuming that for eachaction constant A the domain contains a p-proposition AbExo( A) prevents A, where the unique new fluent AbExo( A)encapsulates all of the unknown conditions (outside the base logic’s language) that would prevent the proper execution ofthe action A.The exogenous qualifications NormExo(Law_Id) are assumed to hold true by default unless the observations in a givennarrative make the domain description inconsistent. Similarly, exogenous qualifications of the form AbExo( A) are assumedby default to be false. To formalize this we can simply add the n-propositionsnormally NormExo(Law_Id)normally ¬AbExo( A)for each NormExo(Law_Id) and AbExo( A), using the n-entailment semantics as given in Definition 29 in the previous section.The examples above can then be understood via the following transformed n-domain descriptions.Example 16 (Extended broken car A with exogenous fluents). A car key is turned at time 1 but we subsequently observe thatthe car is not running.{TurnKey, NormExo(BC1)} causes RunningTurnKey occurs-at 1¬Running holds-at 2AbExo(TurnKey) prevents TurnKeynormally NormExo(BC1)normally ¬AbExo(TurnKey)(BC1(cid:9))(BC2)(BC-obs2)(BC-ab1)(BCN1)(BCN2)This extended or transformed n-domain description now has models (n-models) according to the semantics given in Sec-tion 5, in which Running is false everywhere either because NormExo(BC1) is false or AbExo(TurnKey) is true. The exogenousqualifications allow us to recover from the apparent inconsistency introduced by the observation (BC-obs2).Example 17 (Life support with exogenous fluents). The life support button has been pushed at time 1 but we subsequentlyobserve that the indicator light is not on.{PushButton, NormExo(LS1)} causes IndicatorLightOn{PushButton, NormExo(LS2)} causes LifeSupportOnPatientVeryIll holds-at 0(LS1’)(cid:9)(LS2)(LS3)A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78PushButton occurs-at 1¬IndicatorLightOn holds-at 2AbExo(PushButton) prevents PushButtonnormally NormExo(LS1)normally NormExo(LS2)normally ¬AbExo(PushButton)71(LS4)(LS5)(LS-ab1)(LSN1)(LSN2)(LSN3)The failure of IndicatorLightOn to become true after the action execution at time 1 can now be attributed either to the(abnormal) falsity of NormExo(LS1) or to the (abnormal) truth of AbExo(PushButton). In the latter case this will also meanthat LifeSupportOn will also fail to become true. But note that the domain n-entails PatientVeryIll holds-at 2, illustratingthat our approach avoids the anomalous model problem exemplified by this same domain in Section 2.1.To illustrate how this problem of exogenous qualification can interact with the ramification problem and the constraintsimposed by a-propositions, consider the following transformation of Example 7 where the domain now is extended withexogenous qualifications in the manner discussed above.Example 18 (Broken car E with exogenous fluents).{TurnKey, NormExo(BC1)} causes RunningTurnKey occurs-at 1always ¬(Broken ∧ Running){Break, NormExo(BC4)} causes Broken{Broken, NormExo(BC5)} causes ¬RunningBreak occurs-at 1Running holds-at 2AbExo(TurnKey) prevents TurnKeyAbExo(Break) prevents Breaknormally NormExo(BC1)normally ¬AbExo(TurnKey)normally NormExo(BC4)normally NormExo(BC5)normally ¬AbExo(Break)(BC1(cid:9))(BC2)(BC3)(cid:9)(BC4)(BC5(cid:9))(BC6)(BC7)(BC-ab1)(BC-ab2)(BCN1)(BCN2)(BCN3)(BCN4)(BCN5)As explained in Section 3.1, the original Example 7 does not have any models. This extended n-domain does howeverhave models (n-models). A preliminary inspection might suggest that we could now attribute the unexpected observation ofRunning at time 2 to abnormal truth values for any of the exogenous fluents AbExo(Break), NormExo(BC4) or NormExo(BC5).But in fact, the a-proposition (BC3) ensures that whenever Running is true Broken is false, which cuts out the possibilitythat it is NormExo(BC5) that has the abnormal truth value. Hence the extended n-domain has only n-models where the caris not broken at any time, and in which NormExo(BC5) is true, and either NormExo(BC4) is false or AbExo(Break) is true.The examples above give an informal indication of part of our approach to exogenous qualification, illustrating howexogenous factors may be introduced via an automatic transformation of the domain into an extended language, hidden fromthe user. However, once we have introduced such exogenous factors we are faced with the problem of how to reason withthem — in effect, how to reason about the unexpected failure of actions. Of course, we have no direct causal informationabout the exogenous factors, but one interesting question that we can ask is the extent to which they persist. Are theconditions NormExo(. . .) and AbExo(. . .) ordinary fluents (as in the examples above) which therefore persist over time, or istheir existence limited to the instant at which they give rise to an unexpected non-effect? In the first case the persistence,for example, of the falsity of a NormExo(. . .) would mean that any subsequent application of the associated effect law wouldalso not give rise to an effect, and thus in the terminology of [37] we have a “failure” of that law. But if the exogenousconditions do not persist we would have only an isolated unexpected non-effect, i.e. an “accident”.In some cases “accidents” will be the only possible explanation for the observations. For instance, if Example 14 is furtherextended with the o-proposition TurnKey occurs-at 3 and the h-proposition Running holds-at 4, we can account forthis only by assuming that an exogenous factor prevented the expected application of (BC1) at time 1, but that this factorwas no longer present at time 3.72A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78We can capture such isolated exogenous conditions in our language by representing them as (abnormal) exogenousevents (actions) that occur at the specific time where the expected effect would otherwise have been generated. Hence aswell as introducing exogenous fluents of the form NormExo(. . .) and AbExo(. . .), we introduce exogenous (unknown) actionsof the form ExoAct(. . .). We can then qualify our effect laws with the negation (absence) of such actions meaning that, underthe normal assumption that no exogenous “blocking” event occurs at the time of interest, the effect law will be successful.For example, the exogenously qualified c-proposition{TurnKey, ¬ExoAct(BC1)} causes Runningrepresents that the action TurnKey causes Running under the assumption that no exogenous blocking action occurs at thesame time. We can exogenously qualify action executability via p-propositions in an analogous way:(cid:17) prevents {PushButton, ExoAct(PushButton)}means that an execution of PushButton cannot be successful at the same time as a (successful) occurrence of its associatedexogenous blocking action.Finally, we may also wish to consider the possibility that the unexpected observation of the converse of a particularfluent literal L indicates that exogenous factors have prevented it from being caused in any way whatsoever. Once again wecan indicate this either using persistent exogenous factors via extra p-propositions such as AbExo(L) prevents L, or usingnon-persistent exogenous factors via extra p-propositions such as (cid:17) prevents {L, ExoAct(L)}.The choice of which types of exogenous qualification to consider will to some extent be domain dependent. For example,for some domains it may be appropriate to explain observations of unexpected non-effects only in terms of non-persisting“accidents”. For other domains we may wish to regard some effect laws as exogenously qualified “defaults”, but others asunbreakable rules. In the next section we formally define a general transformation of domain descriptions which encom-passes all the types of exogenous qualification we have described above, for all effect laws, actions and fluents. But it willbe obvious to the reader that the definitions could be straightforwardly simplified to restrict attention to certain types ofexogenous qualification only.6.1. Extended semantics for exogenous qualificationWe begin by defining the syntactic transformation of a domain description D into its extended form.10Definition 31 (Default domain description). Let D be an n-domain description. The default domain description Dd associatedwith D is the n-domain obtained by:(i) replacing every c-proposition “C causes L” in D with the c-proposition “C ∪ {NormExo(id), ¬ExoAct(id)} causes L”,where id is a unique identifier for the c-proposition, and extending the underlying language with the action constantExoAct(id) and fluent constant NormExo(id),(ii) extending the underlying language with the action constant ExoAct( A) and fluent constant AbExo( A) for every actionconstant A, and adding the p-propositions “AbExo( A) prevents A” and “(cid:17) prevents { A, ExoAct( A)}”,(iii) extending the underlying language with the action constant ExoAct(L) and fluent constant AbExo(L) for every fluentliteral L, and adding the p-propositions “AbExo(L) prevents L” and “(cid:17) prevents {L, ExoAct(L)}”,(iv) adding the n-propositions:– “normally NormExo(id)” for every fluent constant NormExo(id) introduced in step (i),– “normally ¬AbExo( A)” for every fluent constant AbExo( A) introduced in step (ii),– “normally ¬AbExo(L)” for every fluent constant AbExo(L) introduced in step (iii).We will refer to the extra fluents and actions introduced in steps (i)–(iv) of Definition 31 as the exogenous fluents andactions of D and Dd. As an example, the default domain description associated with the domain of Example 14 is as follows.Example 19 (Extended broken car A default domain description).{TurnKey, NormExo(BC1), ¬ExoAct(BC1)} causes RunningTurnKey occurs-at 1¬Running holds-at 2AbExo(TurnKey) prevents TurnKey(BC1d)(BC2)(BC-obs2)(BC-p1)10 A further possibility for exogenous qualification is to introduce for every fluent literal L a new a-proposition of the form always ¬(L ∧ Abn(L))with normally ¬Abn(L). Then under the unknown exogenous condition Abn(L) the fluent L cannot become true in any state but, unlike the case ofp-propositions, it is allowed to be transiently true within the process of generating a change set. We will not discuss this further in this paper.A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78(cid:17) prevents {TurnKey, ExoAct(TurnKey)}AbExo(Running) prevents Running(cid:17) prevents {Running, ExoAct(Running)}AbExo(¬Running) prevents ¬Running(cid:17) prevents {¬Running, ExoAct(¬Running)}normally NormExo(BC1)normally ¬AbExo(TurnKey)normally ¬AbExo(Running)normally ¬AbExo(¬Running)73(BC-p2)(BC-p3)(BC-p4)(BC-p5)(BC-p6)(BC-n1)(BC-n2)(BC-n3)(BC-n4)The semantics of a domain description D can then be defined in terms of the models of the associated n-domain Dd,once we have also formalized the default interpretation of extra exogenous action occurrences. For this we can introducethe notion of an e-model as follows.Definition 32 (Exogenous action occurrence). Let D be an n-domain description. An exogenous action occurrence of D is ano-proposition of the form A occurs-at T , where A is an exogenous action of D.Definition 33 (E-model). Let D be an n-domain description, let Dd be the default domain associated with D and let H bean interpretation of Dd. Then H is an e-model of D iff there exists a set O of exogenous action occurrences of D such thatH is an n-model of Dd ∪ O .Definition 34 (Event abnormality). Let D be an n-domain description, Dd be the default domain associated with D, T be atime-point, A be an exogenous action constant of Dd, and M be an e-model of D. (cid:14) A, T (cid:15) is an event abnormality w.r.t. Dand M iff M( A, T ) = true. The set of all event abnormalities w.r.t. D and M is written EventAbs(D, M).Definition 35 (Exogenous abnormalities). Let D and Dd be an n-domain and its associated default domain, let M be ane-model of D, let O be the (unique) set of exogenous action occurrences such that M is an n-model of Dd ∪ O , and let Tbe a time-point. The set ExoFluAbs(D, M, T ) is defined as the set of exogenous fluent literals in FluentAbs(Dd ∪ O , M, T ). Theset ExogAbs(D, M, T ) is defined as ExoFluAbs(D, M, T ) ∪ EventAbs(D, M).The extended semantics of ME is given in terms of default models. A default model of a domain description D is givenby first minimizing all fluent abnormalities (just as for n-entailment in Section 5), which is done implicitly in the definitionof e-models in terms of n-models. From this set, further minimization selects those e-models of D with the fewest eventand exogenous fluent abnormalities. In this way the semantics gives preference to explanations of unexpected observationswhich involve only abnormal truth values of known fluents, as opposed to explanations involving abnormal exogenousfactors. The formal definition is as follows. Note that for n-consistent domains d-entailment is equivalent to n-entailment.(cid:9)w.r.t. D, written M ≺d(cid:9), TDefinition 36 (D-entailment). Let D be an n-domain description and let M and MMExogAbs(D, M“φ holds-at T ”, written D |(cid:19)d φ holds-at T , iff for every d-model Md of D, Md satisfies φ at T .(cid:9)). M is a d-model of D iff there is no other model M, iff there exists a time-point T 0 such that for every time-point Tbe e-models of D. M is d-preferable to(cid:9)) ⊂D M. D d-entails the h-proposition(cid:9) (cid:2) T 0, ExogAbs(D, M, Tsuch that M(cid:9)(cid:9) ≺dD M(cid:9)(cid:9)(cid:9)(cid:9)As regards Example 14 and its transformation into Example 19 we can see that Definition 36 gives rise to two typesof d-models. In d-models of the first type, there are no exogenous action occurrences, and exactly one of the exogenousfluents NormExo(BC1), AbExo(Running) or AbExo(TurnKey) has an abnormal truth value at time 1 (and therefore at all othertimes by persistence). For these d-models adding a later occurrence of TurnKey, e.g. “TurnKey occurs-at 3”, will makeno difference to the truth of Running at e.g. time 4, because the same persisting exogenous factor will re-prevent Runningbeing initiated. In d-models of the second type, all exogenous fluents have their normal truth values, but exactly one ofthe exogenous actions ExoAct(BC1), ExoAct(Running) or ExoAct(TurnKey) is true (i.e. occurs) at time 1. For these d-modelsadding “TurnKey occurs-at 3”, will make Running true at times after 3. So in this way, i.e. by implicitly qualifying withboth exogenous fluents and exogenous actions, we are able to represent domains in which, after observing an unexpectednon-effect, we are unable to decide whether subsequent identical attempts to produce the effect will actually produce theeffect.Definition 31 of an associated default domain results in each fluent literal being independently exogenously qualified viaa pair of p-propositions. This allows us to capture the possibility that an observed apparent failure of one effect law for theliteral might be due to reasons not linked specifically to that law, and therefore that subsequent attempts to generate theliteral via other causal laws will also not produce their normal effect. To illustrate this consider the following example.74A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78Example 20 (Jump start car).TurnKey causes RunningJumpStart causes RunningTurnKey occurs-at 1¬Running holds-at 2JumpStart occurs-at 3(JS1)(JS2)(JS3)(JS4)(JS5)The associated default domain of this example introduces exogenous fluents including NormExo(JS1), AbExo(TurnKey) andAbExo(Running) and exogenous actions including ExoAct(JS1), ExoAct(TurnKey) and ExoAct(Running). The unexpected obser-vation (JS4) ensures that in each of the six d-models of the domain exactly one of these six exogenous factors has anabnormal truth value at time 1. In five of the d-models Running becomes true at times after 3 by virtue of the combina-tion of (JS2) and (JS5). But in the d-model in which AbExo(Running) is true at time 1, the p-proposition “AbExo(Running)prevents Running” included in the associated default domain blocks the normal initiating effect of (JS2) at time 3, becauseAbExo(Running) persists from 1 to 3.Default models allow us to make sense of a wider class of domain descriptions while maintaining elaboration toleranceand modularity. They do this by essentially weakening the effect laws and thus reducing the change that they wouldbring about. But what kind of domain descriptions do not have a default model? Apart from the obvious cases whereobservations at a single time-point are inconsistent with the a-propositions, inconsistent domain descriptions are thosewhere an observed change in some fluent cannot be accounted for in terms of known action occurrences, as the followingexample illustrates.Example 21 (Engine noise).{TurnKey} causes Running{Running} causes EngineNoise¬Running holds-at 0¬EngineNoise holds-at 0EngineNoise holds-at 2(EN1)(EN2)(EN3)(EN4)(EN5)For any time-point in [0, 2) (and any initial state at time 0) the change set for any interpretation that satisfies theobservations at time 0 and the condition of persistence of ¬Running is empty. Hence the observed change in the truth valueof EngineNoise cannot be accounted for. In fact, ¬EngineNoise must persist and this is incompatible with the observationthat EngineNoise is true at time 2. Note that, as the change sets are empty, employing d-models (which as we have seenessentially reduce the change sets) cannot help us in this example.Now suppose that we add TurnKey occurs-at 1 to Example 21. The extended domain has an n-model and hence alsoa d-model. But then suppose we also add ¬Running holds-at 2. This domain will again have no d-model. This is becauseany exogenous qualification introduced to explain the absence of an initiating cause for Running also blocks the initiation ofEngineNoise. This elaborated example shows yet again the intricate link between the ramification and qualification problems— exogenous qualifications forced by unexpected observations sometimes break the causality chain associated with theeffect laws.Clearly, for such domains we need to allow models which do not event match the domain description (see Definition 16),but instead indicate additional event occurrences. The standard example for this type of domain is Kautz’s “Stolen Car Prob-lem” [18]. The problem of assuming or abducing new event occurrences has of course been extensively studied, especially inthe context of planning (see e.g. [7,18,29,34]). In particular, a recent study [1] has investigated how to reason with domainsin which such existentially quantified (partially ordered) events have been added.We end this section with an extension of Theorem 1 and Corollary 1 which covers d-models and d-entailment.Theorem 4 (Free will theorem for D-entailment). Let D 1 and D2 be n-domain descriptions over the same underlying language and letTn be a post-observation point for both D1 and D2. Let D1 and D2 differ only by o-propositions referring to time-points greater than orequal to Tn and let M1 be a d-model of D1. Then, there is a d-model M2 of D2 such that M1(F , T ) = M2(F , T ) for all fluent constantsF and all time-points T such that T (cid:2) Tn. In particular, for all fluent formulae φ and all time-points T such that T (cid:2) Tn, D1 d-entails“φ holds-at T ” iff D2 d-entails “φ holds-at T ”.Proof. Consider the default domain descriptions D1d and D2d associated with D1 and D2, respectively. Consider also anyset O of exogenous action occurrences of D1 and D2; since the two domains are over the same underlying language, theyA. Kakas et al. / Artificial Intelligence 175 (2011) 49–7875have the same possible exogenous action occurrences. Clearly, Tn is a post-observation time-point for both D1d ∪ O andD2d ∪ O , and these n-domains differ only by o-propositions referring to time-points greater than or equal to Tn. Partitionthe n-models of each of D1d ∪ O and D2d ∪ O into classes, where for each pair of n-models Ma, Mb in the same class, foreach fluent F , and for each time-point T (cid:2) Tn, it holds that Ma(F , T ) = Mb(F , T ). Applying Theorem 3 twice, it follows thatthere is a bijection between classes of n-models under D1d ∪ O and classes of n-models under D2d ∪ O .(cid:9) (cid:2) Tn, ExoFluAbs(D2, M2, TConsider a d-model M1 of D1, and the class of n-models under D1d ∪ O (for the unique set O implied by M1) inwhich M1 belongs. Consider the corresponding class of n-models under D2d ∪ O , according to the bijection discussedabove, and let M2 be an n-model of D2d ∪ O from this class of n-models. Then, for any fluent F and time-point(cid:9)), sinceT (cid:2) Tn, M2(F , T ) = M1(F , T ). This implies that for every TD1 and D2 differ only by o-propositions referring to time-points greater than or equal to Tn. Since it also holds thatEventAbs(D2, M2) = EventAbs(D1, M1), it follows that for every TAssume by way of contradiction that M2 is not a d-model of D2. Then, there exists a set O(cid:9)2 of D2d ∪ O(cid:9)) ⊂ ExogAbs(D2, M2, Toccurrences of D1 and D2, and an n-model Mthat for every Tbelongs. Consider the corresponding class of models under D1d ∪ Obe a model of D1d ∪ Oimplies that for every Treferring to time-points greater than or equal to Tn. Since it also holds that EventAbs(D1, Mthat for every Tevery Tproves the first claim.(cid:9)).of exogenous actionthat is d-preferable to M2 w.r.t. D2. Thus, there exists T 0 such(cid:9)in which M2(cid:9), according to the bijection discussed above, and let M1(cid:9)(cid:9)1(F , T ) = M2(F , T ). This(cid:9)), since D1 and D2 differ only by o-propositions(cid:9)(cid:9)1) = EventAbs(D2, M2), it follows(cid:9)). Overall, there exists T min = min{T 0, Tn} such that for(cid:9)); a contradiction to the fact that M1 is a d-model of D1. Thisfrom this class of models. Then, for any fluent F and time-point T (cid:2) Tn, M(cid:9)) = ExoFluAbs(D2, M(cid:9) (cid:2) Tn, ExoFluAbs(D1, M(cid:9)). Consider the class of models under D2d ∪ O(cid:9)) = ExogAbs(D1, M1, T(cid:9)(cid:9) (cid:2) Tn, ExogAbs(D2, M2, T(cid:9) (cid:2) T min, ExogAbs(D1, M(cid:9)) = ExoFluAbs(D1, M1, T(cid:9)) ⊂ ExogAbs(D1, M1, T(cid:9) (cid:2) Tn, ExogAbs(D1, M(cid:9) (cid:2) T 0, ExogAbs(D2, M(cid:9)) = ExogAbs(D2, M(cid:9)2, T(cid:9)2, T(cid:9)1, T(cid:9)1, T(cid:9)1, T(cid:9)2, TFor the second claim consider a time-point T (cid:2) Tn. Note that D1 d-entails “φ holds-at T ” iff every d-model of D1satisfies φ at T . From the first claim, this holds iff every d-model of D2 satisfies φ at T , which then holds iff D2 d-entails“φ holds-at T ”, as required. (cid:2)(cid:9)(cid:9)(cid:9)(cid:9)6.2. Failure associationsReasoning about the failure of actions and effect laws can involve problems orthogonal to the issue of the persistenceof failure. One such problem is that of failure associations — the possibility that failures of effects are linked to each other.We might for example know that if one effect law fails then another (associated) effect law will also fail, or more generallythat all other effect laws sharing the same set of preconditions will also fail. We have also seen some examples of failureassociations in the previous section. For instance, an association between the failure of all possible effects of an action Acan be provided by a p-proposition such as AbExo( A) prevents A.But this knowledge of failure associations might be domain dependent and highly specific. In this section we briefly andinformally explore how such information might be expressed in a domain description in a modular way. For brevity, and tominimize the introduction of new syntax, we assume here for the purposes of discussion that the user is able to refer toexogenous fluents directly.We can capture domain specific failure associations by enriching our language for n-domains (and hence also for theassociated default domains) to allow n-propositions that link together the exogenous qualification conditions of the effectlaws. These new n-propositions are of the form “normally φ” where φ is a propositional formula on the fluent languageextended with exogenous fluents.11 In addition, φ may be a formula expressing that under certain conditions a fluent literalL1 has priority over L2 via the special binary predicate L1 > L2. The following example illustrates this enrichment of thelanguage.Example 22 (Broken car with failure associations).TurnKey causes RunningTurnKey causes DashBoardLightsRunning causes EngineNoisenormally ¬NormExo(FA2) → ¬NormExo(FA1)normally PetrolCar → (¬NormExo(FA1) > ¬NormExo(FA3))normally PetrolCarTurnKey occurs-at 1¬Running holds-at 011 Here for simplicity we will assume that effect laws are exogenously qualified only by exogenous fluents.(FA1)(FA2)(FA3)(FA4)(FA5)(FA6)(FA7)(FA8)76A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78Here (FA4) expresses the domain dependent knowledge that (normally) “failure of (FA2) also means failure of (FA1)”.Hence if we subsequently observe that DashBoardLights is false at some time after 1 then (FA4) would lead us to alsoconclude that Running is false. This is captured by a preference of models that satisfy this association rule over those whichdo not and hence, since NormExo(FA2) must be false in any b-model, only models with NormExo(FA1) also false can bedefault models. Similarly, (FA5) states that “for petrol cars it is more likely for (FA1) to fail than (FA3)”. If we observe¬EngineNoise at 2 then, as cars in this domain are normally petrol cars (FA6), this priority will have the effect that onlyb-models that make NormExo(FA1) false can be default models, as these are preferred over b-models where NormExo(FA3)is false (thus capturing the preference of failure of (FA1) over (FA3)).Failure associations are expressed using n- rather than a-propositions because we want to capture the default natureof these failure links — they are defeasible when the observations present evidence to the contrary of the associations. Inour example above, if we observe both that DashBoardLights is false and that Running is true after time 1 then the only b-models possible have NormExo(FA2) false and NormExo(FA1) true, and hence in the default models of our theory the failureassociation rule (FA4) is not satisfied.The semantics of n-propositions can be extended to capture this intended meaning by re-interpreting the default se-mantics for n-domains presented in the previous sections in terms of argumentation where, for example, an n-propositionnormally L is understood as a stronger argument for L over its converse L. We can employ known methods (see e.g.[2,17,31]) for formalizing preference reasoning through argumentation and the comparison of arguments to suitably extendthe notion of a default model for domains with such n-propositions. The formal details are beyond the scope of this paper,but it is important to note that the semantics can be developed in a modular way, so that the default reasoning aboutpersistence is separated from the domain dependent default reasoning about the n-propositions for failure association rules,and indeed separated from any other default rules known about the particular domain at hand.7. Summary and related and future workWe have shown how ME can represent non-deterministic narrative domains involving concurrency, static laws andindirect effects. We have formally characterized ME ’s high degree of modularity and elaboration tolerance, enabled byan exceptionally full solution to the ramification problem able to deal with looping systems of indirect effects, and raceconditions between competing causal laws. These properties help separate out, and provide principled solutions to, theendogenous and exogenous qualification problems. Endogenous qualifications may be either locally specified or globallyderived within the base semantics, whereas exogenous qualifications are provided by the use of default minimization.Our approach to the qualification problem and its links to ramifications partly follows that in [37]. But ME ’s fullersolution to the frame problem, which covers both successful and failed action attempts, enables it to use the same defaultreasoning mechanism to deal with not just the “weak” but also the “strong” qualification problem as described in [37].Two other important aspects in which ME differs from [37] are (a) the more complete treatment of ramifications, e.g., forconcurrent effects and (b) the notion of global qualification which gives ME a higher degree of modularity. These resultsare in line with the recent study of modularity in [13] which again highlights the link between modularity and free-willproperties.Kvarnström and Doherty provide a detailed discussion and solution in [20] to more-or-less what we have termed theendogenous qualification problem. Comparison with ME is somewhat difficult, however, as the authors specifically restricttheir solution to “off-line planning and prediction” problems, and state that their formalism is not necessarily “able to con-clude that an action was qualified because its successful execution would have contradicted a [later] observation”, whichis of primary concern here. Nevertheless, Kvarnström and Doherty, like us, argue the need for a modular and elaborationtolerant approach, and their formalism is able to model a wide range of phenomena, including actions with duration andnon-boolean valued fluents (for which ME currently lacks the necessary expressivity). The paper also includes an interest-ing collection of benchmark problems and a comprehensive analysis of related work.Our solution to the qualification problem should be translatable to any action calculus expressive enough to represent anarrative of events and observations in “real time” and which exhibits (an equivalent of) the “Free Will” property describedin Section 4. The (non-deterministic version of the) Event Calculus in [28] is one such example, although it is less expressivethan ME in many respects (it has no equivalent of a-propositions, and cannot be used to describe indirect effects orramifications). To be useful predictive tools, such action calculi also need to adhere to, or be augmented with, the principlethat “failed” action attempts are ineffectual, with a solution to the frame problem that covers such scenarios, as discussedin Section 2.1.The solution to the ramification problem that we have proposed is related to that in [3] in that the indirect effects ofactions are defined constructively through causal laws. But ME ’s process-based semantics differs in that it (a) embracesnon-determinism resulting from the possible orderings by which effects are realized, and (b) attributes meaning to domains(e.g., Example 11) that are deemed ill-formed in [3].Irrespective of the qualification problem, the “free will” property of Theorem 1 is important to avoid anomalous planning,whereby unintended “plans” can be abduced or deduced for the converse of a precondition of an effect law by virtue ofa lack of model for the successful application of that law. (See [28] for an example.) Although lack of space prevents anillustration here, anomalous plans are easy to construct in formalisms such as the Language C+ [10] which express actionA. Kakas et al. / Artificial Intelligence 175 (2011) 49–7877non-executability in terms of inconsistency. But they also arise in any framework (such as [16]) unable to provide modelsfor all combinations of causal laws.We currently have a prototype implementation of ME ’s base semantics in Prolog. The declarative programming styleshould facilitate an easy proof of the soundness and completeness of the implementation w.r.t. to ME ’s semantics. Onthe other hand, different techniques might be needed to address the computational qualification problem [6] of avoidingconsidering the majority of qualifications during the computation. ME has a sound basis on which efficient reasoningtechniques might be built, namely its free-will property. When seen in the context of a prediction task, the free-will propertyamounts to some sort of memory. An action execution does not affect the action’s past, thus one need only consider thecurrent state of affairs when computing the effects of an action. This allows a prediction engine to cache-in knowledge asit reasons forward in time after each action execution, obviating the need to recompute everything from scratch. Similartechniques might also prove useful when computing default models in explanation tasks, where one does not want toconsider all possible ways causal laws might fail, but rather deduce which ones should fail. Things, however, are less clear inthis setting, since the free-will property no longer holds as stated. An action attempt that is observed to fail may necessitatethe reconsideration of assumptions on the values of certain default fluents, which in turn may affect the execution of pastactions. Thus, when unexpected observations are encountered, more elaborate reasoning might be required. To the end ofbuilding an efficient computational model for ME we are currently considering the use of satisfiability methods or AnswerSet Programming (along the lines of [4,19,35]), as well as argumentation (or abduction) based computational methods. Wealso aim to study subclasses (as in [4]) of ME , where the computational complexity of reasoning decreases.There are several aspects of ME that deserve further study. One is the extent to which static laws should be regardedas specific to the temporal granularity of the representation (how would we refine the role that a-propositions play incomputing indirect effects?). Another, as discussed in Section 6.2, is how to extend the syntax and semantics to allowfor succinct expression of domain dependent failure associations between causal laws. This requires us to study how tointegrate in ME default static information that is more general than simply positive or negative facts, a problem that is ofgreat interest on its own accord and which we are proposing to address with argumentation. A third issue is how to liftour approach to the first-order case while preserving properties such as the “Free Will Theorem” of Section 4. This wouldnot be entirely straightforward because, for example, in the non-finite case it would not necessarily be the case that causalchains always terminate or loop back to an earlier state. However, the introduction of non-boolean fluents and a limitedform of quantification over finite value sets in the manner of [10] should be unproblematic in ME .AcknowledgementsMany thanks to the anonymous reviewers for giving the originally submitted version of this paper such a careful anddetailed reading, and for the many helpful and insightful suggestions that helped improve it. This work was partially sup-ported by the IST program of the EC, FET under the IST-2001-32530 SOCS project, within the Global Computing proactiveinitiative.References[1] A. Bracciali, A.C. Kakas, Frame consistency: Computing with causal explanations, in: Proceedings of the 10th International Workshop on Non-MonotonicReasoning (NMR’04), 2004, pp. 79–87.[2] G. Brewka, T. Eiter, Preferred answer sets for extended logic programs, Artificial Intelligence 109 (1–2) (1999) 297–356.[3] M. Denecker, D. Theseider-Dupré, K. Van Belleghem, An inductive definition approach to ramifications, Electronic Transactions on Artificial Intelli-gence 2 (1–2) (1998) 25–67.[4] Y. Dimopoulos, A. Kakas, L. Michael, Reasoning about actions and change in answer set programming, in: Proceedings of the 7th International Confer-ence on Logic Programming and Nonmonotonic Reasoning (LPNMR’04), 2004, pp. 61–73.[5] P. Doherty, J. Gustafsson, L. Karlsson, J. Kvarnström, TAL: Temporal action logics language specification and tutorial, Electronic Transactions on ArtificialIntelligence 2 (3–4) (1998) 273–306.[6] C. Elkan, On solving the qualification problem, in: Working Notes of the AAAI Spring Symposium on Extending Theories of Actions: Formal Theory andPractical Applications, 1995, pp. 77–79.[7] K. Eshghi, Abductive planning with event calculus, in: Proceedings of the 5th International Conference and Symposium on Logic Programming(ICLP/SLP’88), 1988, pp. 562–579.[8] M. Gelfond, V. Lifschitz, Representing actions in extended logic programming, in: Proceedings of the Joint International Conference and Symposium onLogic Programming (JICSLP’92), 1992, pp. 559–573.[9] M. Ginsberg, D. Smith, Reasoning about action II: The qualification problem, Artificial Intelligence 35 (3) (1988) 311–342.[10] E. Giunchiglia, J. Lee, V. Lifschitz, N. McCain, H. Turner, Nonmonotonic causal theories, Artificial Intelligence 153 (1–2) (2004) 49–104.[11] S. Hanks, D. McDermott, Nonmonotonic logic and temporal projection, Artificial Intelligence 33 (3) (1987) 379–412.[12] D. Harel, Dynamic logic, in: D. Gabbay, F. Guenther (Eds.), Handbook of Philosophical Logic, vol. II. Extensions of Classical Logic, D. Reidel PublishingCompany, Dordrecht, The Netherlands, 1984, pp. 497–604.[13] A. Herzig, I. Varzinczak, Domain descriptions should be modular, in: Proceedings of the 16th European Conference on Artificial Intelligence (ECAI’04),2004, pp. 348–352.[14] A. Kakas, L. Michael, R. Miller, Modular-E and the role of elaboration tolerance in solving the qualification problem, Technical annex,http://www.ucl.ac.uk/slais/research/modular-e/, 2006.[15] A. Kakas, R. Miller, A simple declarative language for describing narratives with actions, Journal of Logic Programming 31 (1–3) (1997) 157–200.[16] A. Kakas, R. Miller, Reasoning about actions, narratives and ramification, Electronic Transactions on Artificial Intelligence 1 (4) (1998) 39–72.[17] A.C. Kakas, P. Mancarella, P.M. Dung, The acceptability semantics for logic programs, in: Proceedings of the 11th International Conference on LogicProgramming (ICLP’94), 1994, pp. 504–519.78A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78[18] H. Kautz, The logic of persistence, in: Proceedings of the 5th National Conference on Artificial Intelligence (AAAI’86), 1986, pp. 401–405.[19] H. Kautz, B. Selman, Pushing the envelope: Planning, propositional logic, and stochastic search, in: Proceedings of the 13th National Conference onArtificial Intelligence (AAAI’96), 1996, pp. 1194–1201.[20] J. Kvarnström, P. Doherty, Tackling the qualification problem using fluent dependency constraints, Computational Intelligence 16 (2) (2000) 169–209.[21] V. Lifschitz, Missionaries and cannibals in the Causal Calculator, in: Proceedings of the 7th International Conference on Principles of Knowledge Repre-sentation and Reasoning (KR’00), 2000, pp. 85–96.[22] J. McCarthy, Epistemological problems of Artificial Intelligence, in: Proceedings of the 5th International Joint Conference on Artificial Intelligence(IJCAI’77), 1977, pp. 1038–1044.[23] J. McCarthy, Circumscription — A form of non-monotonic reasoning, Artificial Intelligence 13 (1–2) (1980) 27–39.[24] J. McCarthy, Elaboration tolerance, http://www-formal.stanford.edu/jmc/elaboration/, 1999.[25] J. McCarthy, Appearance and reality, http://www-formal.stanford.edu/jmc/appearance.html, 2006.[26] J. McCarthy, P. Hayes, Some philosophical problems from the standpoint of Artificial Intelligence, Machine Intelligence 4 (1969) 463–502.[27] S. McIlraith, T. Son, H. Zeng, Semantic web services, IEEE Intelligent Systems (Special Issue on the Semantic Web) 16 (2) (2001) 46–53.[28] R. Miller, M. Shanahan, Some alternative formulations of the Event Calculus, in: Lecture Notes in Artificial Intelligence, vol. 2408, 2002, pp. 452–490.[29] L. Missiaen, M. Bruynooghe, M. Denecker, CHICA, a planning system based on the Event Calculus, Journal of Logic and Computation 5 (5) (1995)579–602.[30] E. Mueller, Commonsense Reasoning, Morgan Kaufmann, 2006.[31] H. Prakken, G. Sartor, A system for defeasible argumentation, with defeasible priorities, in: Proceedings of the International Conference on Formal andApplied Practical Reasoning (FAPR’96), 1996, pp. 510–524.[32] R. Reiter, The frame problem in the Situation Calculus: A simple solution (sometimes) and a completeness result for goal regression, in: VladimirLifschitz (Ed.), Artificial Intelligence and Mathematical Theory of Computation: Papers in Honor of John McCarthy, Academic Press, San Diego, CA,1991, pp. 359–380.[33] A. Russo, R. Miller, B. Nuseibeh, J. Kramer, An abductive approach for analysing event-based requirements specifications, in: Proceedings of the 18thInternational Conference on Logic Programming (ICLP’02), 2002, pp. 22–37.[34] M. Shanahan, An abductive Event Calculus planner, Journal of Logic Programming 44 (1–3) (2000) 207–240.[35] M. Shanahan, M. Witkowski, Event Calculus planning through satisfiability, Journal of Logic and Computation 14 (5) (2004) 731–745.[36] M. Thielscher, Introduction to the fluent calculus, Electronic Transactions on Artificial Intelligence 2 (3–4) (1998) 179–192.[37] M. Thielscher, The qualification problem: A solution to the problem of anomalous models, Artificial Intelligence 131 (1–2) (2001) 1–37.[38] N. Tran, C. Baral, C. Shankland, Issues in reasoning about interaction networks in cells: Necessity of event ordering knowledge, in: Proceedings of the20th National Conference on Artificial Intelligence (AAAI’05), 2005, pp. 676–681.