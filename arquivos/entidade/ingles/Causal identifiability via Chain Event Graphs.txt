Artificial Intelligence 195 (2013) 291–315Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCausal identifiability via Chain Event GraphsPeter ThwaitesSchool of Mathematics, University of Leeds, LS2 9JT, United Kingdoma r t i c l ei n f oa b s t r a c tWe present the Chain Event Graph (CEG) as a complementary graphical model to theCausal Bayesian Network for the representation and analysis of causally manipulatedasymmetric problems. Our focus is on causal identifiability — finding conditions for whenthe effects of a manipulation can be estimated from a subset of events observable in theunmanipulated system. CEG analogues of Pearl’s Back Door and Front Door theorems arepresented, applicable to the class of singular manipulations, which includes both Pearl’sbasic Do intervention and the class of functional manipulations possible on BayesianNetworks. These theorems are shown to be more flexible than their Bayesian Networkcounterparts, both in the types of manipulation to which they can be applied, and in thenature of the conditioning sets which can be used.© 2012 Elsevier B.V. All rights reserved.Article history:Received 15 April 2011Received in revised form 6 September 2012Accepted 12 September 2012Available online 13 September 2012Keywords:Back Door theoremBayesian NetworkCausal identifiabilityCausal manipulationChain Event GraphConditional independenceFront Door theorem1. IntroductionIn this paper we consider cause and effect through the analysis of controlled models. The standard apparatus for suchan approach is the Causal Bayesian Network (CBN) [8,14,15,24]. The CBN is a version of a Bayesian Network (BN) where thedirectionality of the edges of the graph is interpreted as causal and the BN as representing a causal model.BNs are specifically designed to work with problems which have a natural product space structure, but many problemswhich we might wish to model do not have such a structure, and are asymmetric in that problem variables can have differentsets of possible outcomes given different outcomes of their parental variables, or even no possible outcomes given someoutcomes of their parents. The future development at any specific point depends on the particular history of the problemup to that point (i.e. on the outcomes of ancestral variables), and the values of a particular set of covariates at that point. Itis these types of problem that we are primarily concerned with here.So for instance, consider an infectious disease which is serious for people who have blood type O. Following a firsttreatment, patients with this blood type either die or need a second treatment; patients with other blood types either needa second treatment or make a full recovery. At the next stage of the process, patients who have died or fully recovered arenot offered a second treatment, but all other patients are given one of three possible second treatments, the choice of whichis dependent on factors such as hospital policy, consultant preference etc. Similar examples occur in many other areas (seefor example [1,3,7,12]).Context-specific variants of BNs have been developed for tackling asymmetric problems [2,13,18,20]. They can be usedfor the representation and analysis of problems whose future development at any specific point depends on the particularhistory of the problem up to that point, but their use is more circumscribed in problems where there may be no possibleoutcomes of some variables given certain histories or values of covariates. In both cases however the problems being anal-ysed are no longer fully represented by the topology of the graph — context-specific BNs require supplementary informationE-mail address: P.A.Thwaites@leeds.ac.uk.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.09.003292P. Thwaites / Artificial Intelligence 195 (2013) 291–315in the form of trees, or tree-like conditional probability tables attached to vertices to depict the asymmetries in the prob-lem. The Chain Event Graph (CEG) introduced in [22,25] is specifically designed for the representation and analysis of suchproblems. It is a function of an event tree [21], whose topology expresses the full collection of independence properties as-sociated with a problem. It is particularly useful when problems do not exhibit a product space structure, or when there isa lot of context-specific information present. All aspects of the model structure, including any context-specific dependenciesare represented in the topology of the graph — these are not bolted on.There have been many recent advances in CBN theory (see for example [5,6,9,16,27,28]), but little of this has madethe causal analysis of such asymmetric problems simpler. In particular, techniques such as Pearl’s Back and Front Doortheorems [14,15] have conditions which are expressed in terms of the topology of the CBN — if the structure of the problemcan no longer be expressed fully in terms of the topology of the graph, then this benefit is lost.CBNs can be used for the basic Do intervention of Pearl [15], which sets a particular variable to a particular value;and their use has been extended to functional manipulations (Do X = g(W ) for some set of variables W ), and stochasticmanipulations which assign a new probability distribution over the outcomes of the manipulated variable. The ease withwhich necessary conditions can be checked on the unmanipulated graph however vanishes very rapidly as we move awayfrom basic interventions.It can be argued [4,21,26] that causes are more naturally expressed as events rather than the values of some randomvariable. The CEG provides an ideal graphical representation given this argument. It is also a sensible representation forthe analysis of manipulations to events. By making additional assumptions concerning a CEG model we can give it a causalinterpretation, and extend its use to causal analysis in an analogous manner to that in which CBNs extend the use of BNs.Unlike analysis using CBNs, the analysis of functional and stochastic manipulations using CEGs is no more complex than theanalysis of the basic Do manipulation. In using the CEG for causal analysis we are building on the ideas of researchers whohave attempted to use trees for this purpose [19,21,24].Note also that in CBN analysis the standard methods for reducing the complexity of a manipulated probability expression(for example Pearl’s Back and Front Door theorems) rely on the use of blocking sets consisting of problem variables. WithCEG-based analysis our blocking sets are composed of events, allowing us more flexibility in their construction; so insteadof conditioning on a set of variables Z = {Z1, Z2} say, we might only need to condition on the events {patient is male, patientis female and aged below 40}.A crude version of a Back Door theorem for CEGs was introduced in [26]. Here we present a much more general BackDoor theorem as well as two alternative versions of a Front Door theorem. No knowledge of the content of [26] is assumedin this paper. The earlier paper touched briefly on some topics covered here, such as the use of CEGs for more sophisticatedmanipulations, but here we offer a comprehensive overview of causal analysis on CEGs, and look more carefully at causalidentifiability — finding conditions for when the effects of a manipulation can be estimated from a subset of events ob-servable in the idle system. Pearl’s Back and Front Door theorems give sufficient conditions for causal identifiability in BNs,and their arrival prompted a search for a complete set of conditions, using which an analyst could gauge whether or not anexpression could be estimated from a subset of observable variables [6,27,28]. This paper provides several sets of sufficientconditions for causal identifiability in CEGs. We anticipate that future work will allow us to find necessary and sufficientconditions for identifiability, expressed in terms of subsets of observable events as opposed to observable variables.As the CEG is a comparatively new structure, there have been minor modifications since [22] and [26]. In particular wehave removed the undirected edges from previous definitions so that the CEG is now a DAG. This has led to a less clutteredrepresentation and made the CEG easier to read.In Section 2 we define the CEG and manipulated CEG. Section 3 develops the Back Door theorem and the idea ofsingular manipulations. A Front Door theorem is then introduced in Section 4, and Section 5 provides a discussion of possibledirections for future research.2. Definitions and notationIn this section we define the CEG. We also provide some notation that will be used throughout the paper. We then turnour attention to what it means when we manipulate a CEG to an event, and present a definition of a manipulated CEG.The CEG is a function of an event tree [21], retaining those features of the tree which allow for the transparent repre-sentation of asymmetric problems. They are a significant extension to trees since they express within their topology a morecomplete description of the conditional independence structure of a problem.An event tree T is a directed tree with vertex set V (T ) and edge set E(T ). It has a single root vertex v 0, and a collectionof leaf vertices (see for example Fig. 1, where there are 7 leaf vertices). The root-to-leaf paths {λ} of T form the atoms ofthe event space. Events measurable with respect to this space are unions of these atoms.Let V 0(T ) denote the set of non-leaf vertices of T . Then each vertex v ∈ V 0(T ) labels a random variable X(v) whosestate space X(v) can be identified with the set of directed edges e(v, v(cid:4)(cid:3)(cid:4)(cid:3)(cid:3)) ∈ E(T ) emanating from v. For each X(v) we let(cid:5)∈ X(v)(cid:3))) are called the primitive probabilities of the tree; andΠ(v) ≡where πe(vΠ(T ) ≡(cid:2)πe(cid:3)v| e(cid:3) | vv, v(cid:3) | v) ≡ P ( X(v) = e(v, v(cid:5)Π(v)(cid:2)v∈V (T )P. Thwaites / Artificial Intelligence 195 (2013) 291–315293There are a number of modifications we can make to an event tree to enable it to portray conditional independencestructure more transparently. The first of these is to highlight those vertices in V (T ) whose outgoing edges carry the samelabels and the same probabilities. We do this through the concept of a stage, and through the colouring of edges.Definition 1 (Stages and colour). For an event tree T with non-leaf vertex set V 0(T ) and edge set E(T )1. The set V 0(T ) is partitioned into equivalence classes, called stages, as follows:Vertices v 1, v 2 ∈ V 0(T ) are members of the same equivalence class (stage) if (a) v 1, v 2 do not lie on the same root-to-leaf path, and (b) there is a bijection ψ between X(v 1) and X(v 2) such that if ψ : e(v 1, v 1(cid:3)) (cid:5)→ e(v 2, v 2(cid:3)) thenπe(v 1(cid:3) | v 1) = πe(v 2(cid:3) | v 2).2. The set E(T ) is partitioned into equivalence classes, whose members have the same colour, as follows:Edges e(v 1, v 1(cid:3)), e(v 2, v 2(cid:3)) have the same colour if and only if the vertices v 1 and v 2 are in the same stage, andπe(v 1(cid:3) | v 1) = πe(v 2(cid:3) | v 2).The set of stages of the tree T is labelled L(T ), and individual stages are labelled u.Definition 2 (Coloured tree). An event tree T is a coloured tree if its edges are coloured in accordance with Definition 1.The second modification is to highlight those vertices in V (T ) from which the complete future development of theprocess is essentially the same. We do this through the concept of a position.For v ∈ V 0(T ), let T (v) denote the unique subtree of T whose root is v, and which contains all edges from E(T ) andvertices from V (T ) which lie on a v-to-leaf subpath of T .Definition 3 (Positions). For a coloured tree T with non-leaf vertex set V 0(T ) and edge set E(T ), the set V 0(T ) is parti-tioned into equivalence classes, called positions, as follows: Vertices v 1, v 2 ∈ V 0(T ) are members of the same equivalenceclass (position) if (a) the coloured subtrees T (v 1) and T (v 2) are topologically identical, and (b) there is a bijection betweenT (v 1) and T (v 2) such that edges in T (v 2) are coloured identically with their corresponding edges in T (v 1).The set of positions is labelled K (T ), and the individual positions are labelled w. Note that the partition into positionsis finer than the partition into stages, and that if two vertices are in the same position, they are necessarily in the samestage.Note also that vertices are in the same stage when the sets of possible immediate outcomes at each vertex are thesame and have the same (conditional) probability distribution. Vertices are in the same position when the sets of entirefuture evolutions from each vertex have the same probability distribution. Example 1 below puts the meanings of stage andposition into a simple practical context.Once we have the ideas of stages and positions we can make one last modification so that the conditional independencestructure of the problem is expressed entirely through the topology of the graph. Example 1 demonstrates how a tree-to-CEG conversion is implemented.Definition 4 (Chain Event Graph). The Chain Event Graph C(T ) is the coloured graph with vertex set V (C) and edge set E(C)defined by:1. V (C) ≡ K (T ) ∪ {w∞}, where w∞ is called the sink-vertex of C(T ).(cid:3) ∈ V (C) \ {w∞}, there exists a directed edge e(w, w2. (a) For w, w(cid:3) ∈ K (T ) and there is an edge e(v, vthat v ∈ w ∈ K (T ), v(cid:3) ∈ w(cid:3)) ∈ E(C) iff there are vertices v, v(cid:3)) ∈ E(T ).(cid:3) ∈ V 0(T ) such(b) For w ∈ V (C) \ {w∞}, there exists a directed edge e(w, w∞) ∈ E(C) iff there is a non-leaf vertex v ∈ V 0(T ) and aleaf vertex v(cid:3) ∈ V (T ) such that v ∈ w ∈ K (T ) and there is an edge e(v, v(cid:3)) ∈ E(T ).So the vertices of a CEG C(T ) correspond to the positions of the underlying tree T . We can therefore, without ambiguity,call the vertices of the CEG positions. Since the positions partition the vertices of the tree, and vertices in the same positionare necessarily in the same stage, we can transfer the concepts of stage and colour from the tree to the CEG.If positions w 1, w 2 in the CEG correspond to sets of vertices in the tree which are all members of the same stage u, wesay that w 1 and w 2 are in the same stage u in the CEG. We label the set of stages of C(T ) by L(C). The colouring of theedges leaving any vertex v, a member of the stage u in T , is inherited by the edges leaving any position w, a member ofthe stage u in C(T ).To aid in the reading of our CEGs we have in this paper given the same colour to positions in a CEG which are membersof the same stage (as well as colouring the edges emanating from these positions).There is a one-to-one correspondence between the root-to-leaf paths {λ} of T and the root-to-sink (w 0 → w∞) paths{λ} of C(T ), and these latter form the atoms of the event space of C(T ). Events measurable with respect to this space areunions of these atoms.294P. Thwaites / Artificial Intelligence 195 (2013) 291–315Fig. 1. Coloured tree for Example 1.Stages: {v 0}, {v 1, v 2}, {v 3, v 5}, {v 4}Positions: {v 0}, {v 1}, {v 2}, {v 3, v 5}, {v 4}Each stage u ∈ L(C) labels a random variable X(u) whose state space X(u) can be identified with the set of directededges e(w, w(cid:3)) ∈ E(C) emanating from any position w ∈ u.w 1, w 2 do not lie on the same root-to-sink path in C(T ).Note that Definition 1 (1)(a) implies that if the positions w 1, w 2 ∈ V (C) are members of the same stage u ∈ L(C), thenFor the remainder of this paper we abbreviate C(T ) to C, and assume that C has associated edge and vertex sets E(C)and V (C).Example 1 (CEG construction). We illustrate the construction of a CEG through a fault diagnosis example, which for illustrativeconvenience uses only binary variables.• A machine has two warning lights which indicate possible faults in two components.• If either light is on, the machine is checked and judged to be either faulty or not.• If both lights are off, operation proceeds as normal.Operational evidence indicates that(1) the warning lights come on independently of each other,(2) whether the machine is judged faulty is independent of whether or not light 1 is on, provided that light 2 is on.This information is represented in the coloured tree in Fig. 1. For ease of interpretation, only edges which share aprobability have been coloured.The edges leaving v 1 and v 2 are coloured to indicate that the probabilities of 2 on (blue) and 2 off (red) do not dependon whether light 1 is on or off. The vertices v 1 and v 2 are in the same stage.The edges leaving v 3 and v 5 are coloured to indicate that the probabilities of faulty (mauve) and not faulty (green) donot depend on whether light 1 is on or off, provided that light 2 is on. The vertices v 3 and v 5 are in the same stage. As v 3and v 5 are the roots of identically coloured subtrees, v 3 and v 5 are also in the same position.Definition 2 tells us that the vertex set of a CEG consists of the positions of the coloured tree and a sink-vertex whichgroups all the leaf-nodes of the tree together. So v 3 and v 5 are merged, and the (blue) edges e(v 1, v 3) and e(v 2, v 5) in thetree become edges e(w 1, w 4) and e(w 2, w 4) in the CEG (Fig. 2).It is possible to read both positions and stages in a CEG, in a manner similar to the reading of BNs. The position w 4can be read to give the context-specific conditional independence property that whether judged faulty or not is independent ofwhether light 1 is on or off, given that light 2 is on.Reading stages we only look into the immediate future. So reading {w 1, w 2} gives the conditional independence propertythat whether light 2 is on or off is independent of whether light 1 is on or off.P. Thwaites / Artificial Intelligence 195 (2013) 291–315295Fig. 2. Chain Event Graph for Example 1.Stages: {w 0}, {w 1, w 2}, {w 3}, {w 4}Fig. 3. BN and CEG for Example 2.A BN-representation of this problem would consist of three variables ( X1 denoting light 1 on/off, X2 denoting light 2 on/off,X3 denoting faulty/not faulty), with edges from each of X1 and X2 into X3. The additional knowledge that lights 1 & 2 bothoff implies not faulty, and that X3 is independent of X1 provided that light 2 is on, would not be represented in the topologyof the graph, and would have to appear as supplementary information.Example 2 (Reading CEGs). To show how CEGs relate to BNs we here provide a CEG-version of Pearl’s Sprinkler examplefrom [15].Here there are five variables X1, . . . , X5, the causal relationships between which are illustrated in the BN in Fig. 3.X1: seasonX2: rain {yes, no }X3: (water) sprinkler {on, off }X4: (pavement) wet {wet, dry }X5: (pavement) slippery {slippery, not slippery }From the BN we can read that X3 (cid:9) X2 | X1 (knowing whether it is raining or not does not help us in estimating a probabilityfor the event that the sprinkler is on, given that we know the season), but X3 /(cid:9) X2 | X4 (knowing whether it is raining or not does296P. Thwaites / Artificial Intelligence 195 (2013) 291–315Fig. 4. Second CEG for Example 2.help us in estimating a probability for the event that the sprinkler is on, given that we know whether the pavement is wet or dry). Wecan also read that ( X4, X5) (cid:9) X1 | ( X2, X3) and that X5 (cid:9) ( X1, X2, X3) | X4.The CEG for this example is also given in Fig. 3, where for illustrative convenience I have shown only two seasons —Spring and Summer.Here we have 13 positions {w 0, w 1, . . . , w 12}, each of which can be read for a unique context-specific independenceproperty. So for example, reading w 7 gives us that the state of the pavement (wetness, slipperiness) is independent of the seasongiven that it is raining and the sprinkler is on. Combining the readings for w 7, w 8, w 9 and w 10 we get (as in the BN) that( X4, X5) (cid:9) X1 | ( X2, X3).Similarly, reading w 11 gives us that the slipperiness of the pavement is independent of the season, whether it is raining ornot, and whether the sprinkler is on or off, given that the pavement is wet. Combining with the reading of w 12 gives us thatX5 (cid:9) ( X1, X2, X3) | X4.There are also two stages which contain more than a single position. These are {w 3, w 4} and {w 5, w 6}. When we readthese we only look into the immediate future. So reading {w 3, w 4} gives us that whether the sprinkler is on or off is independentof whether or not it is raining, given that it is Spring. Combining with the reading of {w 5, w 6} gives us that X3 (cid:9) X2 | X1.The example as it stands is clearly symmetric, and the CEG gives us no more information than the BN. Indeed, giventhe number of nodes and edges, the CEG here is a considerably less efficient representation than the BN. However, as inExample 1, we can build context-specific information into the model much more readily than with a BN. So suppose thatduring the Summer a gardener is on hand to check the weather before turning on the sprinkler. Then X3 is not independentof X2 when X1 takes the value corresponding to Summer, but is independent of X2 when X1 takes the value correspondingto Spring. In the BN-representation we would need to add an edge between X2 and X3, and supplement the graph withsome additional information. In contrast, this information can be represented directly in the topology of the CEG, as shownin Fig. 4, where w 5 and w 6 are no longer in the same stage.The following notation will be used throughout the remainder of the paper. Analogously with atoms in a tree, an atom λ(cid:3)when the position w precedes the position w— in Fig. 3 for example w 5 ≺ w 12, butis a w 0 → w∞ path in C. The set of atoms is denoted Ω . We write w ≺ won a w 0 → w∞ path (i.e. there exists a set of directed edges joining w to ww 5 ⊀ w 9). We call w a parent of wif there exists an edge e(w, w(cid:3)) ∈ E(C).Events are denoted Λ. Λ(w) is the event which is the union of all w 0 → w∞ paths passing through the position w, and(cid:3)(cid:3)(cid:3)Λ(e(w, w(cid:3))) is the union of all paths passing through the edge e(w, w(cid:3)).We can now define what we call the primitive probabilities of the CEG: We use the notation πe(w(cid:3) | w) to denote(cid:3)) having arrived at the position w. These probabilities have the samethe probability of passing along the edge e(w, wrelationship to the CEG as the sets of conditional probability tables associated with a BN do to the corresponding DAG, sofor example in Fig. 3, πe(w 11 | w 7) is the probability that the pavement is wet given that it is raining and that the sprinkleris on. For each u ∈ L(C) and random variable X(u) we letΠ(u) ≡(cid:3)(cid:2)πe(cid:3) | ww(cid:4)(cid:5)| w ∈ uandΠ(C) ≡(cid:2)(cid:5)Π(u)u∈L(C)P. Thwaites / Artificial Intelligence 195 (2013) 291–315297(cid:3))) | Λ(w)). Each w 0 → w∞Note that if we label the probability of the event Λ by π (Λ) then πe(wpath λ corresponds to a sequence of outcomes at a set of positions, or equivalently a vector of values of a set ofX(u) variables. So the probability of an atom λ can be expressed as a product of edge-probabilities, each of the form(cid:3))) corresponds to some value of X(u) and Λ(w) describes the parental config-π (Λ(e(w, wuration for the position w. But this is a product of probabilities of values of variables conditioned on the values of theirparents, so Π(C) satisfies the Directed Markov condition [15,10] with respect to the CEG C.(cid:3))) | Λ(w)), where Λ(e(w, w(cid:3) | w) ≡ π (Λ(e(w, wthe subpath. Λ(μ(w, wπ (Λ(μ(w, wA subpath of a root-to-sink path is denoted μ(w, w(cid:3)(cid:3)), where w and w(cid:3)(cid:3)(cid:3)(cid:3))) is the event which is the union of all paths utilising the subpath μ(w, windicate the start and end positions of(cid:3)(cid:3) | w) ≡(cid:3)(cid:3)). πμ(w(cid:3)(cid:3)) having arrived at the position w.Before moving on to manipulated CEGs we present a very useful lemma, a proof of which appears in Appendix A.(cid:3)(cid:3))) | Λ(w)) is the probability of passing along the subpath μ(w, wLemma 1 (Limited Memory). For a CEG C and positions w 1, w 2, w 3 ∈ V (C) such that w 1 ≺ w 2 ≺ w 3(cid:3)(cid:4)Λ(w 3) | Λ(w 1), Λ(w 2)π(cid:3)(cid:4)Λ(w 3) | Λ(w 2)= πHere w 1 precedes w 2 precedes w 3 in the sense described above. The lemma states that the probability of passingthrough the position w 3 given that we have previously passed through both w 1 and w 2 is equal to the probability ofpassing through the position w 3 given only the information that we have previously passed through w 2.This result can be extended so that the positions w 1 and w 2 can each be replaced by edges, and the position w 3 can bereplaced by a union of positions and/or edges.Essentially this tells us that being at a position (w 3) or edge (or collection of positions or edges), given that we havebeen at an earlier position (w 2) or edge, is independent of the path taken to that earlier position or edge. This result isused in the proof of Theorem 1.2.1. Manipulated CEGsAnything that we observe about a system or do to a system will change the topology of a graphical representation of thatsystem. In [25] we considered how the topology of a CEG is altered when we observe an event Λ. Here we investigate howthe topology of a CEG is altered when we manipulate to an event Λ. As the following definitions suggest, the process ofupdating our beliefs following a manipulation is very similar to that which happens following the observation of an event.How does this relate to the manipulation of a BN? When we talk about manipulating a BN or enacting an interventionon a BN, we are in general setting a variable or a collection of variables to some specified values. In the case of a stochasticmanipulation we are altering the probability distribution associated with a variable or set of variables. In the former casewe can see that this can be described as manipulation to an event (e.g. the event that X = x1 for some variable X andvalue x1). In the latter case the equivalent action on a CEG would be a reassignment of a subset of the edge-probabilities ofthe CEG; and we allow for this in Definition 5 below.The type of events we consider in this paper are intrinsic events (called C-compatible events in [25]). An intrinsic eventΛ is one which defines a subgraph of C, so every atom of Λ is a w 0 → w∞ path of a subgraph of C, and every w 0 → w∞path in this subgraph is an atom of Λ. The set of intrinsic events is large, and if the CEG is expressible as a BN then itcontains as a proper subset all sets of the form { X j ∈ A j} for subsets { A j} of the sample spaces of { X j}, the vertex variablesof the BN. It excludes a few events of a more convoluted structure, but if we wish to manipulate to such an event we canconvert it to intrinsic by relaxing some of the conditional independence structure represented by the CEG and expandingone or more merged vertices.A manipulation to an intrinsic event Λ is hence a reassignment of edge-probabilities so that ˆπ (Λ) = 1, where ˆπ denotesa probability following manipulation.Clearly such a reassignment might be done in several ways, so the description of any specified manipulation to Λ shouldinclude details of how edge-probabilities are to be assigned. Also, if Λ is a proper subset of Ω , a manipulation to Λmust assign zero-probabilities to a proper subset of E(C). We normally prune our manipulated CEG by removing edges andpositions which only lie on paths which are not elements of Λ.Example 3. Consider again Pearl’s Sprinkler example (Example 2) and the CEG for this in Fig. 3. Suppose we were to enactthe intervention Put sprinkler on. This is setting the variable X3 to the value associated with sprinkler on. If we let this valuebe 1 then Pearl would call this manipulation Do X3 = 1. The manipulated BN for this intervention is in Fig. 5.In the CEG-representation we are manipulating to the event Λ which is the union of all paths passing through an edgelabelled on. As we are not controlling any other aspect of the system, this is done by assigning an edge-probability of 1 toeach on edge, an edge-probability of 0 to each off edge, and leaving all other edge-probabilities unchanged. As suggestedabove we prune edges and positions which only lie on paths which are not elements of Λ — here the positions {w 8, w 10}and the edges entering or leaving these positions. The resultant manipulated CEG is given in Fig. 5.This is a symmetric manipulation of a symmetric system, and the CEG is a less efficient representation than a CBN. Butwe can also consider functional manipulations of the system such as: If it is Summer put the sprinkler on; if it is Spring and itis raining put the sprinkler off. In the BN-representation of the problem, instead of removing the edge from X1 to X3 as in298P. Thwaites / Artificial Intelligence 195 (2013) 291–315Fig. 5. Manipulated BN and CEG for Example 3.Fig. 6. Second manipulated CEG for Example 3.Fig. 5, there is now an additional edge from X2 to X3 since whether the sprinkler is on or off depends on both the seasonand whether it is raining. The BN would also have to be supplemented with the extra information given above. So anyadvantages gained through the simplicity of the BN topology are lost.Using a CEG, representing this manipulation is as straightforward as representing the simple Put sprinkler on intervention.The resultant CEG is shown in Fig. 6. Here, as again we are not controlling any other aspect of the system, the only edge-probabilities which might be modified are those leaving the positions {w 3, w 4, w 5, w 6}. The edges e(w 3, w 8), e(w 5, w 7)and e(w 6, w 9) are given probability 1; the edges e(w 3, w 7), e(w 5, w 8) and e(w 6, w 10) are given probability 0 and arepruned. As the description of our manipulation does not specify what happens when it is Spring but doesn’t rain, we leavethe edge-probabilities for e(w 4, w 9) and e(w 4, w 10) unchanged.Definition 5 (Manipulated CEG). For a CEG C and intrinsic event Λ, letsubgraph of C withˆCΛ (the CEG manipulated to the event Λ) be the(a) V ( ˆCΛ) ⊂ V (C) contains precisely those positions which lie on a w 0 → w∞ path λ ∈ Λ;(b) E( ˆCΛ) ⊂ E(C) contains precisely those edges which lie on a w 0 → w∞ path λ ∈ Λ;P. Thwaites / Artificial Intelligence 195 (2013) 291–315299(c) For w 1, w 2 ∈ V ( ˆCΛ), and e(w 1, w 2) ∈ E( ˆCΛ), the edge e(w 1, w 2) has primitive probability πe(w 2 | w 1) replaced byˆπ Λe (w 2 | w 1).Clearly there are many probability distributions over ˆCΛ that could be assigned via Definition 5(c) which do not corre-spond to any practical or theoretical manipulation. As with CBNs we make causal assumptions about the system. So in theSprinkler example, we know that we cannot control the season; we might be able to control whether it rains or not (orat least alter the probability distributions over these outcomes) by seeding clouds; we can definitely control whether thesprinkler is on or off; and can also alter the probability distributions over whether the path is wet or not. The allowableedge-probabilities in our manipulated CEG are governed by our causal assumptions. In Example 3 we specified that theonly aspect of the system being controlled was the sprinkler, so these are the only edge-probabilities that might alter, andtheir new values are determined by our causal model. The probability following manipulation of any atom λ is equal to theprobability of the corresponding w 0 → w∞ path in the manipulated CEG ˆCΛ. This is, as before, expressible as the productof probabilities of values of (stage) variables conditioned on the values of their parents, so Π( ˆCΛ) satisfies the DirectedMarkov condition with respect to ˆCΛ.For completeness we also define a conditioned CEG (first defined in [25]).Definition 6 (Conditioned CEG). For a CEG C and intrinsic event Λ, let CΛ (the CEG conditioned on the event Λ) be thesubgraph of C with V (CΛ), E(CΛ) defined and coloured analogously with V ( ˆCΛ), E( ˆCΛ) in Definition 5, and(c) For w 1, w 2 ∈ V (CΛ), and e(w 1, w 2) ∈ E(CΛ), the edge e(w 1, w 2) has primitive probability πe(w 2 | w 1) replaced byπ Λe (w 2 | w 1) =(cid:6)λ∈Λ π (λ, Λ(e(w1, w 2)))(cid:6)λ∈Λ π (λ, Λ(w1))Probabilities in C are denoted π , in CΛ are denoted π Λ, and in ˆCΛ are denoted ˆπ Λ.If instead of manipulating to Λ in Example 3, we had simply observed that the sprinkler was on, then in the conditionedCEG CΛ all edges associated with the variables season or rain would retain their original probabilities, but edges associatedwith the variables wet and slippery would have new probabilities as detailed in Definition 6(c).Causal analysis on CEGs was first discussed in [26], but the emphasis in the earlier paper was on manipulations whichwere exact analogues of BN interventions, and on manipulations to sets of positions within the CEG (a rather small subsetof the set of intrinsic events). This was a very narrow focus, and the manipulations considered here are more generic —the manipulation Put sprinkler on in Example 3 could be thought of as a manipulation to a set of positions, but the secondmanipulation in this example cannot be characterised in this way — it is a functional manipulation which, as noted above,can only be expressed as a BN by sacrificing some of the simplicity of the DAG-representation.3. The Back Door theoremSince 1995 there has been considerable effort put in to finding conditions for causal identifiability on BNs [6,16,17,27,28] — that is conditions for when the effects of a manipulation can be estimated from a subset of variables observed inthe idle system. The initial spur for this activity was the publication of Pearl’s Back Door theorem in [14], which providedsufficient conditions for such an analysis. The advantages in using Pearl’s formulation are threefold: the factors needingto be considered in the analysis are clearly identified, the probability of observing an effect following a manipulation isexpressed in terms of the idle or unmanipulated system, and the conditions for the analysis to be valid can be checked onthe unmanipulated BN. In particular, when a manipulation is impossible or unethical in practice, or its effects difficult orimpossible to observe, an analyst may still be able to estimate the probabilities of the theoretically possible effects of thismanipulation.Pearl’s Back Door theorem states that under certain conditions on sets of variables X, Y , Z , we can write down theprobability expression(cid:7)p( y (cid:12) x) =p( y | x, z) p(z)zwhere p( y (cid:12) x) denotes the probability of observing that an effect or response variable Y takes the value y, following amanipulation of the variable X to a specified value x. The manipulation here is sometimes described as the control or settingof the variable X to the value x, and the notation is that of Lauritzen [11]. By careful choice of the set Z we may be able tocalculate or estimate p( y (cid:12) x) without conditioning on the full set of measurement variables.As the Back Door theorem for BNs is the tool most widely used by causal analysts, a CEG-analogue is a principal focusof this paper. We have already noted that the CEG is a very good means of depicting asymmetric problems (e.g. Example 1),and that it also allows for transparent representation of what might be termed asymmetric manipulations (e.g. Example 3).The Back Door theorem for CEGs presented here also allows the analyst a fair amount of flexibility in the choice of the300P. Thwaites / Artificial Intelligence 195 (2013) 291–315CEG-analogue of Z . The topology of the CEG can be utilised to find functions of the data which can be observed in the idlesystem and which fulfil this role — these do not need to be vectors of values of the measurement variables of the problem.Our Back Door theorem also refers explicitly to manipulation to events (such as Put sprinkler on) rather than manipulationof variables (set the variable sprinkler to the value corresponding to on), which reflects the difference in topology betweenthe CEG and the BN. A primitive version of a Back Door theorem was given in [26], but this was restricted to manipulationsto sets of positions. The conditions required for this theorem were also very complex, and not easily checkable on thetopology of the CEG. The Back Door theorem presented here works for a far larger class of manipulations, the conditionsare simpler, and they can be checked on the topology of the CEG.The use of the description Back Door is not perhaps an obvious choice for our CEG-analogue, but we retain it to emphasiseits affinity with the Back Door theorem for BNs.So consider a manipulation to an event Λx (a specified union of root-to-sink paths). Suppose we wish to find theprobability of (observing) an event Λ y given that the manipulation to Λx has been enacted — that is we wish to producean expression for π (Λ y (cid:12) Λx). This is equal to the probability of the event Λ y on the CEG ˆCΛx , which is the sum of theprobabilities of the w 0 → w∞ paths in ˆCΛx which are consistent with the event Λ y :π (Λ y (cid:12) Λx) = ˆπ Λx (Λ y)Consider a partition of the atomic events (w 0 → w∞ paths in C) {Λz}. Then(cid:8)(cid:9)(cid:10)ˆπ Λx (Λ y) = ˆπ ΛxΛz, Λ y=(cid:7)ˆπ Λx (Λz, Λ y)zsince the events {Λz} form a partition of Ω(cid:7)z=ˆπ Λx (Λ y | Λz) ˆπ Λx (Λz)zDefinition 7 (Back Door partition). The partition {Λz} forms a Back Door partition of Ω if(cid:7)π (Λ y (cid:12) Λx) =π (Λ y | Λx, Λz)π (Λz)zNote that this expression holds if(A)(B)ˆπ Λx (Λ y | Λz) = π (Λ y | Λx, Λz);ˆπ Λx (Λz) = π (Λz)for all Λz ∈ {Λz}.The sets of variables Z in the BN-based Back and Front Door theorems are called blocking sets because they block certainpaths between X and Y in the BN. Z also blocks the effect on Y of other problem variables so that they can be ignoredwhen calculating the manipulated probability expression p( y (cid:12) x). In our CEG-analogue, the blocking set becomes a partitionof the w 0 → w∞ paths of the CEG into sets {Λz}. This is not so very different from the BN version, where the events Z = z(over the outcome space of Z ) partition the set of all possible vectors of problem variable values. As with the BN version, ifwe choose {Λz} carefully, we can calculate or estimate π (Λ y (cid:12) Λx) from a partially observed idle system.3.1. Singular manipulationsThe commonest form of manipulation on a BN is Pearl’s Do X = x intervention, where a variable X is set to a specificvalue x. There are also functional manipulations of the form If Z = z1, do X = x, orIf Z = z1, do X = x1; if Z (cid:13)= z1, do X = x2etc. In each of these cases a variable X is set to a specified value. In a CEG this is equivalent to manipulating the system soas to pass through a set of edges carrying a specified label, so for instance in Example 3, the intervention Do X3 = 1 (PutSprinkler on) imposes a probability of 1 on all the edges labelled on.Pearl’s Do interventions and functional manipulations when enacted on a CEG are examples of singular manipulations.These are manipulations where every w 0 → w∞ path passes through one of a collection of positions, and the manipulationimposes a probability of 1 on one edge emanating from each of these positions.The class of singular manipulations includes more subtle interventions than these, so for instance in Example 3 theintervention If it is raining, put the sprinkler off ; otherwise make pavement wet (If X2 = 1 (say), do X3 = 0; otherwise do X4 = 1(say)) is a singular manipulation. Whereas this would involve quite complicated analysis on a BN, with a CEG it is no moredifficult than the simple Do X3 = 1. Stochastic manipulations are not singular. These are interventions which impose a newprobability distribution on the values of the variable X , or in the case of the CEG on the outcome spaces for a selection ofpositions. Seeding the clouds in Example 3 would be an example of this type of intervention.P. Thwaites / Artificial Intelligence 195 (2013) 291–315301Definition 8 (Singular manipulation). A manipulation of a CEG C to an event Λ is called singular if there exist sets W ⊂ V (C),EΛ ⊂ E(C) such that(i) the elements of W partition Ω (i.e. every w 0 → w∞ path in C passes through precisely one w ∈ W ),(ii) for each w ∈ W , there exists precisely one emanating edge e(w, w(iii) Λ is the union of precisely those w 0 → w∞ paths that pass through some e(w, w(iv) all edge probabilities in ˆCΛ are equal to the corresponding edge probabilities in C, except that ˆπ Λ(cid:3)) which is an element of EΛ,(cid:3)) ∈ EΛ,e (w(cid:3) | w) = 1 forw ∈ W , e(w, w(cid:3)) ∈ EΛ.So in Example 3 our Put Sprinkler on manipulation is singular, with W = {w 3, w 4, w 5, w 6}, EΛ = {e(w 3, w 7), e(w 4, w 9),e(w 5, w 7), e(w 6, w 9)} is the set of edges labelled on. Λ is then the set of w 0 → w∞ paths defined by the CEG in Fig. 5,where all edge-probabilities are as in Fig. 3 except those on edges labelled on, which have a probability of 1.Similarly, for the intervention If it is raining, put the sprinkler off; otherwise make pavement wet, W = {w 3, w 5, w 9, w 10}and EΛ = {e(w 3, w 8), e(w 5, w 8), e(w 9, w 11), e(w 10, w 11)}. Λ is the set of w 0 → w∞ paths defined by the manipulatedCEG produced from that in Fig. 3 by pruning the position w 7 and all edges entering or leaving w 7, as well as the edgese(w 9, w 12) and e(w 10, w 12). Edge-probabilities are as in Fig. 3 except for edges in EΛ, which have a probability of 1.3.2. A Back Door theorem for singular manipulations(cid:3)X ).As we also consider effect events (Λ y ) and conditioning sets (Λz), we distinguish our manipulation event Λ by addinga suffix to give Λx. We also relabel the set W as W X , the positions within W X as w X , and the edges of Definition 8(ii) ase(w X , wAs the set of positions in W X partitions Ω , we can consider a random variable X , defined on Ω , which takes valueslabelled by the emanating edges of w X (for each w X ) with probabilities dependent on the history of the problem up tothat position w X (in Example 2, the histories up to the positions w 7 and w 8 are respectively rain, on and rain, off, and theprobability of the pavement being wet is different for these two histories).The singular manipulation to Λx assigns a probability of 1 to one of the values of X at each w X , dependent on thehistory of the problem up to that position w X . So Λx is of the form(cid:4)(cid:4)(cid:9)(cid:3)Λx ≡Λw X ∈W X(cid:3)ew X , w(cid:3)XWe are also interested in an effect event, the probability of which may be altered by our manipulation. We can define thisin exactly the same way as we defined Λx. So we define an effect variable Y , and a set of positions W Y (such that w Y ⊀ w Xfor all w X ∈ W X , w Y ∈ W Y ) which partitions Ω (i.e. every w 0 → w∞ path in C passes through one of the positions inW Y ). Then Λ y consists of all paths that passing through some w Y ∈ W Y , utilise some prespecified edge emanating fromthat w Y . So Λ y is of the form(cid:9)Λ y ≡Λw Y ∈W Y(cid:3)(cid:3)ew Y , w(cid:3)Y(cid:4)(cid:4)Pearl’s Back Door Theorem depends on the assumption that the CBN expresses a causal model, and that its edges representcausal dependencies. Given this assumption the conditions for the theorem are then expressed in terms of the topology ofthe unmanipulated CBN. Since then Dawid [5] and Lauritzen [11] have produced versions of the Back Door theorem whichincorporate similar causal assumptions but express the conditions in terms of conditional independence statements.Dawid and Lauritzen express their conditions with reference to augmented DAGs, but it is also possible to produceconditions in the form of conditional independence statements on unaugmented DAGs. So, assuming that our CBN is a validexpression of our causal model, and that Pearl’s two Back Door conditions hold, then the following conditional independenceproperties can be read from the DAG of the BN:Z (cid:9) X | Q (X) and Y (cid:9) Q (X) | (X, Z )where Z is the Back Door blocking set, and Q ( X) are the variable parents of X . Note that we are here ignoring thepossibility that Z ≡ Q ( X). We return to this case in Section 3.4.As noted in Section 2.1, and in direct analogy with CBNs, causal modelling with CEGs requires acceptance of the assump-tion that the CEG expresses a causal model. If this is the case then these conditional independence statements can be usedto produce Back Door conditions on the topology of the CEG.The first of our properties tells us thatp(z | q1) = p(z | q1, x)where x is any value of X , z is any vector of values of the variables Z , and q1 is any specified vector of values of thevariables Q ( X).302P. Thwaites / Artificial Intelligence 195 (2013) 291–315The events X = x, Z = z, Q ( X) = q1 have direct analogues for singular manipulations of CEGs: X = x corresponds tothe event Λx (the union of all paths passing through an edge to which the manipulation will assign a probability of 1);Z = z corresponds to Λz (an element in our Back Door partition); and noting that positions store the history of a processup to that point (and so in particular the values taken by any parent variables at that position), Q ( X) = q1 corresponds toΛ(w X(1)), where w X(1) is a specific w X ∈ W X . So p(z | q1) becomes π (Λz | Λ(w X(1))), the probability of observing thatthe event Λz has occurred, given that the event Λ(w X(1)) has occurred. The term p(z | q1, x) is translated similarly, andthe expression p(z | q1) = p(z | q1, x) becomes(cid:4)Λz | Λ(w X(1))= ππ(cid:3)(cid:4)(cid:3)Λz | Λ(w X(1)), Λx(cid:8)= πΛz | Λ(w X(1)),(cid:9)(cid:3)(cid:3)eΛw X , w(cid:3)X(cid:4)(cid:4)(cid:10)(cid:3)= πΛz | Λ(cid:3)(cid:3)efor any position w X(1) ∈ W X .w X ∈W X(cid:3)X(1)(cid:4)(cid:4)(cid:4)w X(1), w(3.1)Condition (3.1) translates to the topology of the CEG as: The probability (in the idle CEG) of the event Λz conditioned onpassing through the position w X (in W X ) must equal the probability (in the idle CEG) of Λz conditioned on passing through(cid:3)X ), where this is the edge leaving w X assigned a probability of 1 by the manipulation. This condition mustthe edge e(w X , whold for all w X ∈ W X .The second of our properties tells us thatp( y | x, z) = p( y | q1, x, z)where y is any value of Y , and the event Y = y corresponds to the event Λ y . Substituting into this expression givesπ (Λ y | Λx, Λz) = π= π(cid:3)Λ y | Λ(w X(1)), Λx, Λz(cid:8)(cid:9)Λ y | Λ(w X(1)),(cid:4)(cid:3)(cid:3)eΛw X , w(cid:3)X(cid:4)(cid:4), Λz(cid:10)(cid:3)= πΛ y | Λ(cid:3)(cid:3)ew X ∈W X(cid:3)X(1)w X(1), w(cid:4)(cid:4)(cid:4), Λz(3.2)and(cid:3)πΛ y | Λ(cid:3)(cid:3)ew X(1), w(cid:4)(cid:4)(cid:4), Λz(cid:3)X(1)(cid:3)= πΛ y | Λ(cid:3)(cid:3)ew X(2), w(cid:4)(cid:4)(cid:4), Λz(cid:3)X(2)for any positions w X(1), w X(2) ∈ W X .Condition (3.2) translates as: The probability (in the idle CEG) of the event Λ y (Y = y) conditioned on Λz and on passingthrough an edge e(w X , w(cid:3)X ) is independent of which w X ∈ W X this edge emanates from.Theorem 1 (Back Door theorem). With W X , W Y , Λx, Λ y detailed as above, and {Λz} a partition of Ω , then {Λz} is a Back Doorpartition if conditions (3.1) and (3.2) hold for all elements of {Λz}, w X ∈ W X .A proof of this theorem appears in Appendix A.Recall that Pearl’s Back Door conditions for BNs refer explicitly to sets of problem (or measurement) variables, and thatour conditions (3.1) and (3.2) are expressed in terms of events. An event here may be as simple as a measurement variabletaking a particular value, but may just as easily correspond to some collection of variables taking some combination ofvalues given one set of possible prior developments (histories), and another (perhaps overlapping) collection of variablestaking a different combination of values given a different set of possible prior developments.So our CEG-based Back Door theorem does not restrict analysis to manipulations which apply to one variable or to aspecific set of variables, nor to blocking sets which consist only of problem variables. In Example 4 (below) there is no BackDoor blocking set composed of problem variables which we can use, but we can still produce an identifiable probabilityexpression using our event-based Back Door theorem and conditions (3.1) and (3.2).3.3. Checking the conditions for the Back Door theoremOne of the strengths of Pearl’s Back Door theorem is that his conditions can be checked directly on the topology of theidle BN. The conditions for our Back Door theorem for singular manipulations can also be checked on the topology of theunmanipulated CEG. This is best illustrated by example, and this is done in Example 4 below. Before doing this we look atcondition (3.2) in a little more detail.An advantage of letting {Λz} be a collection of events is that we have considerable flexibility in what type of events wechoose. Each Λz could be of the form Λ(w) (the union of all root-to-sink paths passing through the position w), Λ(e) (theP. Thwaites / Artificial Intelligence 195 (2013) 291–315303Fig. 7. BN and CEG C for Example 4.union of all root-to-sink paths passing through the edge e), some union of such events, or a union of root-to-sink pathswhich fits none of these descriptions.For the remainder of Section 3 we use partitions where each Λz is an event associated with a collection of positions,and in Section 3.3 in particular, concentrate on sets of positions downstream of the manipulation (in that none of thesepositions precedes any w X ∈ W X on any root-to-sink path). Translating this work to events associated with edges, and toevents associated with positions upstream of the manipulation (no positions succeed any w X ∈ W X on any root-to-sinkpath) is straightforward. Some results on upstream positions are provided in Section 3.4 (and this was also the focus of thebasic Back Door theorem presented in [26]).We show here how we can choose each member of Λz (associated with a collection of positions) so that condition (3.2)is automatically satisfied.Let each element Λz in our Back Door partition be a union of events of the form Λ(w) for some (small) collectionof positions. Formally, let V z ⊂ V (C) be a set of positions which partitions Ω , such that V z lies downstream of W X andupstream of W Y (downstream and upstream used as above). Now, whereas all elements of V z exist in C, not all will existin ˆCΛx . So consider a partition of V z into a collection {V 1}, where N is the number of elements of V z which existz , . . . , V Nzin ˆCΛx , and each V iz contains precisely one element of V z which exists in ˆCΛx (plus some or none of the elements of V zwhich do not exist in ˆCΛx ).Now let {Λz} consist of N elements Λiz (i = 1, . . . , N), whereΛiz=(cid:9)w z∈V izΛ(w z)If we choose our Back Door partition {Λz} in this way then condition (3.2) is satisfied. A demonstration of this is providedin Appendix A.Example 4 (Using the Back Door theorem). We illustrate the use of our Back Door theorem through a medical example. Aswith earlier examples we use binary variables for illustrative convenience.Our interest is in a condition which can manifest itself in one of two forms (C = 1 or 2). Individuals who will as adultsdevelop the condition (in either of its forms) display either symptom S A before the age of ten, or S B in their late teens,or both. Whether or not an individual displays S A is labelled by a variable A, and whether or not they display S B by avariable B. In both cases the variable takes the value 1 if the symptom is displayed, and the value 0 if it is not. There is atreatment T available which has some efficacy if given in an individual’s early teens. Being treated is labelled X = 1, andnot treated X = 0. We have a life expectancy indicator Y , and dying before the age of fifty is labelled Y = 1, dying at fiftyor older Y = 2.The relationships between the variables A, X, B, C and Y are described below, and are portrayed by the CEG in Fig. 7,where for convenience edges are labelled a0 for A = 0 etc.Symptom S A is often missed by doctors, but if it is detected an individual is more likely to be given treatment T . Wetherefore do not know the distributions of A, X | A = 0 or X | A = 1. We do know however that X /(cid:9) A.304P. Thwaites / Artificial Intelligence 195 (2013) 291–315Evidence from previous studies indicates thatFig. 8. Manipulated CEG ˆCΛx for Example 4.• whether or not an individual displays symptom S B depends only on whether or not they displayed symptom S A(B (cid:9) X | A),• displaying either symptom means that an individual will develop the condition in one of its two forms,• for individuals displaying S A but not S B , developing the condition in form 1 does not depend on whether or not theyhad treatment T (C (cid:9) X | A = 1, B = 0). Also, how long they live depends only on which form of the condition theydevelop (Y (cid:9) X | A = 1, B = 0, C ),• for individuals displaying S B , developing the condition in form 1 does not depend on whether or not they displayed S A ,irrespective of whether they were treated or not (C (cid:9) A | X, B = 1). Also, how long they live depends on whether ornot they were treated and on which form of the condition they develop (Y (cid:9) A | X, B = 1, C ).If we were to attempt to portray the problem via a BN it would look like the one in Fig. 7. Without considerableannotation the BN cannot express the context-specific conditional independence structure illustrated by the CEG.We are interested in the effects on life expectancy if we were to treat everybody in the population in their early teens.So we consider the singular manipulation to Λx equivalent to Do X = 1, and calculate the probability π (Λ y (cid:12) Λx) ≡ P (Y =1 (cid:12) X = 1). The CEG satisfies the conditions that every path passes through a position from W X = {w 1, w 2} and a posi-tion from W Y = {w 8, w 11, w 12, . . . , w 16}. Also, every position in W X has an outgoing edge labelled x1 ( X = 1), and everyposition in W Y has an outgoing edge labelled y1 (Y = 1).Clearly A is a required variable in any Back Door blocking set Z based on the BN representation of the problem. But fromabove we do not know the distribution of A or of any joint distribution involving A. Can we use our Back Door theorem forCEGs to find an identifiable expression not involving A?In these situations we generally have a lot of flexibility in determining our Back Door partition/blocking set, and someexperimentation may be needed before we find the ideal allocation. Here we consider Λz of the formΛ(w). The choiceof positions will depend on what we can observe, and may be heavily influenced by observation costs. Note that theconnection between these constraints and our choice of positions can be very subtle — in this example we clearly cannotestimate P ( A = 1, B = 0, C = 1), but we can still include the position w 11 in our blocking set. Here we simply imaginethat these constraints and our experimentation have produced a blocking set of positions V z, lying between W X and W Y ,comprising {w 8, w 9, w 11, w 12, w 15, w 16}. The CEG ˆCΛx is given in Fig. 8.(cid:11)Checking condition (3.2) on the graph. There are 6 positions in V z, but only 4 of these appear in ˆCΛx . We can combine the(cid:11)original 6 positions to produce 4 events of the form Λz =Λ(w) in 65 different ways, and our choice of which way willdepend on a number of factors including whether a particular combination satisfies condition (3.1).Here we have chosen Λ1z= Λ(w 9) ∪ Λ(w 15) ∪ Λ(w 16). The positionsw 8, w 9, w 11, w 12 are the members of V z that exist in ˆCΛx , and w 15, w 16 are those that don’t. So, using the result from theparagraphs immediately preceding Example 4, this choice of {Λz} satisfies condition (3.2).= Λ(w 12), Λ4z= Λ(w 11), Λ3z= Λ(w 8), Λ2zChecking condition (3.1) on the graph. In Fig. 7 we have, as in earlier figures, labelled edges with probabilistic descriptionssuch as c1|a1b0. This is not actually necessary — the forms of these probabilities are completely specified by the topologyP. Thwaites / Artificial Intelligence 195 (2013) 291–315305and colouring of the CEG. In checking condition (3.1) we do not need to refer to the labels on the edges, or to probabilitytables or any separate lists of conditional independence properties.For (3.1) we need to show that π (Λz | Λ(w X )) = π (Λz | Λ(e(w X , w(cid:3)X ))) for each w X and each Λz. This can be done ina purely graphical manner.• Does π (Λ(w 11) | Λ(w 1)) = π (Λ(w 11) | Λ(e(w 1, w 3)))?π (Λ(w 11) | Λ(e(w 1, w 3))) = π (Λ(w 11) | Λ(w 3)) by Lemma 1. To get from w 1 to w 11 we go through either w 3 or w 4(with probability 1), and then follow a blue edge, and then the edge e(w 7, w 11).To get from w 3 to w 11 we follow a blue edge, and then the edge e(w 7, w 11). So these probabilities are equal.• Similarly for w 12.• w 1 ⊀ w 8.• Does π (Λ(w 9) ∪ Λ(w 15) ∪ Λ(w 16) | Λ(w 1)) = π (Λ(w 9) ∪ Λ(w 15) ∪ Λ(w 16) | Λ(e(w 1, w 3)))? From Fig. 7 we see thatΛ(w 15) ∪ Λ(w 16) = Λ(w 10). To get from w 1 to w 9 or w 10 we go through either w 3 or w 4 (with probability 1), andthen follow a red edge.w 3 ⊀ w 10, and to get from w 3 to w 9 we follow a red edge. So these probabilities are equal.Similar quick checks for w X = w 2 confirm that {Λz} satisfies condition (3.1). Our manipulated probability expressionp( y1 (cid:12) x1) = π (Λ y (cid:12) Λx) =π (Λ y | Λx, Λz)π (Λz)(cid:7)is evaluated on C, and simplifies tozp(b0) p( y1 | b0) + p(b1) p( y1 | x1b1)So we need only know the distribution of B (the incidence of symptom S B ), and the conditional distributions of Y (lifeexpectancy) on the events B = 0 (S B not displayed) and X = 1, B = 1 (treated and S B displayed). This expression doesnot involve A (the incidence of S A ), and interestingly neither does it involve C (which form the condition takes). It doeshowever involve B, which would be impossible if we used the BN from Fig. 7 for this model, as B does not block all BackDoor paths from X to Y .Note that this example gives an insight into how to choose the component Λz of our partition. If we can find w z suchthat Λ(w z) satisfies(cid:3)πΛ(w z) | Λ(cid:3)(cid:3)ew X , w(cid:3)X(cid:4)(cid:4)(cid:4)(cid:3)(cid:4)Λ(w z) | Λ(w X )= π∀ w X ∈ W Xthen we can make Λ(w z) a Λz.Other Λz are produced by combining one position w z that exists in ˆCΛx with other positions {w z} that disappear whenwe create ˆCΛx , in such a way that the union of their associated events satisfies condition (3.1) for all w X ∈ W X .3.4. Using W X to create a Back Door partitionIf we apply Pearl’s Back Door theorem to the BN in Fig. 3 we could use X1 (Season) as the blocking set for the manipu-lation Do X3 = 1 described in Example 3. Here X1 = Q ( X3), the set of parents of X3, and using a blocking set of this typegives us a revised Back Door expression(cid:7)p( y (cid:12) x) =pq(x)(cid:3)(cid:4)y | x, q(x)(cid:3)(cid:4)q(x)pwhere q(x) runs over the possible vectors of values of Q ( X).In our example we would getp(slippery (cid:12) sprinkler on) = p(slippery | sprinkler on, Spring) p(Spring)+ p(slippery | sprinkler on, Summer) p(Summer)The CEG-analogue of this is to use W X to create our Back Door partition. So, as in Section 3.3 we let each element Λzof our partition be a union of events of the form Λ(w), but these positions are now members of W X .In Section 3.2 we suggested an analogy between Q ( X) = q(x) for BNs and Λ(w X ) for CEGs. In fact this analogy is notperfect; a better analogy for parents in a BN is a set of stages rather than positions. Recall that two (or more) positions arein the same stage if the immediate future developments from these positions have the same probability distribution (i.e.their sets of emanating edges have the same colour scheme).Let each element of our Back Door partition have the formΛz =Λ(w X ) = Λ(u X )(cid:9)w X ∈u X306P. Thwaites / Artificial Intelligence 195 (2013) 291–315for some u X (the event Λ(u X ) is the union of all root-to-sink paths passing through some position w X , a member of thestage u X ).Note that (i) each w X ∈ W X needs to be a member of some stage u X , such that Λ(u X ) ∈ {Λz}, and (ii) each w X ∈ u X(cid:3)X ) must(where Λ(u X ) ∈ {Λz}) needs to be an element of W X . Also, for each w X ∈ u X , the manipulated edges e(w X , wcarry the same label (and hence colour). These labels can differ for different stages.This is not actually particularly restrictive, as the set of manipulations we can consider still contains all basic Do inter-ventions on BNs and all functional manipulations where the argument of the function is (a subset of) the parent set of themanipulated variable. In fact we can argue that this set contains all functional manipulations of a BN: If a manipulation isfunctional in that the value we manipulate X to depends on the value taken by another variable W , then essentially wehave a decision problem and the BN representation of the system becomes an Influence Diagram (ID) representation withX as a decision node. Clearly the value of W must be known before X is manipulated, so in this ID representation theremust be an edge from W to X (see for example [23]) and so W is a parent of X . Hence we argue that for all functionalmanipulations of BNs the argument of the function is (a subset of) the parent set of the manipulated variable.Given these conditions on Λz, our new CEG-based Back Door probability expression isπ (Λ y (cid:12) Λx) =(cid:7)(cid:3)πΛ y | Λ(u X ), Λx(cid:4)(cid:3)(cid:4)Λ(u X )πu XA demonstration of this result appears in Appendix A.For the intervention Do X3 = 1 (Put sprinkler on), our set W X = {w 3, w 4, w 5, w 6} (see Fig. 3), which separates into twostages u3 = {w 3, w 4} and u4 = {w 5, w 6}. Now Λ(u3) = Λ(w 3) ∪ Λ(w 4) = (Spring, rain) ∪ (Spring, no rain) = (Spring), soour CEG-based expression is identical to the BN-based one above.4. A Front Door theorem for CEGsPearl’s Front Door theorem [14,15] for BNs can be used in cases where the Back Door theorem conditions do not holdor where the events needing to be observed for the Back Door theorem have too large an observational cost. Like the BackDoor theorem, the Front Door theorem provides conditions for when the effects of a manipulation can be estimated from asubset of variables observed in the unmanipulated system.Pearl’s Front Door theorem states that under certain conditions on sets of variables X, Y , Z , we can write(cid:7)p( y (cid:12) x) =p(z | x)(cid:7)(cid:3)p(cid:3)y | x, z(cid:4)(cid:3)p(cid:4)(cid:3)xzx(cid:3)an expression whose value can be estimated from a partially observed idle system.This expression is more complex than that for the Back Door theorem, and in our CEG-analogue this imposes greaterrestrictions on the types of manipulation we can consider. We concentrate here on singular manipulations.The expression also suggests that we will need to sum over some variable corresponding to the variable X . Hence weneed to produce a partition of Ω , of which Λx (the event to which we manipulate) is one element. So, for instance inExample 3 we would partition Ω into two events (Λ1x ) — the union of all root-to-sink paths passing through anedge labelled on, and the union of all root-to-sink paths passing through an edge labelled off.x and Λ2For simplicity we look at manipulations of the form Do X = x, and consider positions w X ∈ W X which each have thesame number of emanating edges and these edges carry the same labels for each w X (e.g. in Example 3 the positionsw 3, w 4, w 5, w 6 each have emanating edges labelled on and off).Note that even for fairly regular problems depictable by BNs there may be histories or parental configurations of avariable X for which the probability of a particular outcome is zero. Although normally we do not draw zero-probabilityedges in a CEG, in this case it is advisable to do so, although only for the edges emanating from those positions associatedwith the variable X .Suppose we have a CBN which is a valid expression of our causal model, and that Pearl’s Front Door conditions hold.Then, just as with the Back Door Theorem, there are two conditional independence properties that can be read from theDAG of the BN. These are(cid:4)Z , Q (X)and Z (cid:9) Q (X) | XY (cid:9) X |(cid:3)Note that Z is normally a descendant of X and an ancestor of Y .If we have a CEG which expresses our causal model then these conditional independence statements can be used toproduce Front Door conditions on the topology of the CEG. The first of our properties tells us thatp( y | q1, z) = p( y | q1, xi, z)where as before y is any value of Y , q1 is any specified vector of values of Q ( X), and z is any vector of values of Z . Herexi is any value of X , and the event X = xi corresponds to an event on our CEG of the form ΛiX )),xwhere for each w X ∈ W X , the edge e(w X , w iX ) is the edge leaving w X labelled xi . The set of root-to-sink paths is partitionedΛ(e(w X , w iw X ∈W X(cid:11)=P. Thwaites / Artificial Intelligence 195 (2013) 291–315307by the {Λixwe manipulate is one element of this partition.}, which collection contains as many members as there are edges leaving any w X ∈ W X . The event Λx to whichSubstituting the CEG-analogues for these events from Section 3.2 into p( y | q1, z) = p( y | q1, xi, z) gives(cid:3)πΛ y | Λ(w X(1)), Λz(cid:4)= π(cid:3)Λ y | Λ(w X(1)), Λi(cid:8)x, Λz(cid:9)= πΛ y | Λ(w X(1)),(cid:4)(cid:3)(cid:3)eΛw X , w iX(cid:10)(cid:4)(cid:4), Λz(cid:3)= πΛ y | Λ(cid:3)(cid:3)ew X(1), w iX(1)w X ∈W X(cid:4)(cid:4)(cid:4), Λz(4.1)and(cid:3)πΛ y | Λ(w X(1)), Λix, Λz(cid:4)(cid:3)= πΛ y | Λ(w X(1)), Λ jx, Λz(cid:4)for any position w X(1) ∈ W X and any elements Λix, Λ jx of our partition (i.e. any edges leaving w X(1)).Note that {Λz} is a (Front Door) partition of Ω , and at present we have imposed no further restrictions on the form ofeach Λz (as for example is done in Section 3.3).Condition (4.1) translates to the topology of the CEG as: The probability (in the idle CEG) of the event Λ y (Y = y)conditioned on Λz and on passing along an edge emanating from w X ∈ W X is not dependent on which edge is utilised.This condition must hold for all w X ∈ W X , and any Λz in our Front Door partition.The second of our properties tells us thatp(z | xi) = p(z | q1, xi)Substituting into this expression gives(cid:3)(cid:3)πΛz | Λix(cid:4)= π= πΛz | Λ(w X(1)), Λix(cid:8)(cid:9)Λz | Λ(w X(1)),(cid:4)(cid:10)(cid:4)(cid:4)(cid:3)(cid:3)eΛw X , w iX(cid:3)= πΛz | Λ(cid:3)(cid:3)eandw X ∈W X(cid:4)(cid:4)(cid:4)w X(1), w iX(1)(4.2)(cid:3)(cid:4)(cid:3)(cid:4)πΛz | Λ(w X(1)), Λixfor any positions w X(1), w X(2) ∈ W X , and any element ΛiΛz | Λ(w X(2)), Λix= πCondition (4.2) translates as: The probability (in the idle CEG) of the event Λz conditioned on leaving a position in W Xvia the edge labelled xi is independent of which position w X ∈ W X is passed through. This condition must hold for alledges xi (i.e. values of X ).x of our partition (i.e. any edge leaving a w X ∈ W X ).4.1. A Front Door theorem for singular manipulationsTheorem 2 (Front Door theorem). If W X , W Y , Λ y are detailed as in Section 3, {Λixform detailed above, and {Λz} is a partition of Ω which satisfies conditions (4.1) and (4.2) above, then(cid:12)(cid:12) Λiˆπ Λx (Λ y) =π (Λz | Λx)(cid:7)(cid:7)Λ yππ(cid:3)(cid:4)(cid:3)(cid:4)x, ΛzΛix} is a partition of Ω with each individual Λix of thezWe call such a {Λz} a Front Door partition.iA proof of this theorem is in Appendix A.Example 5 (Using the Front Door theorem). We here consider the example from [15] Section 3.3.3, but without reference toPearl’s hypothetical data. This example relates to the debate concerning the relationship between smoking and lung cancersummarised in [24].In Pearl’s example the vertices of the BN in Fig. 9 correspond to binary variables as follows:X = 1: smoker, X = 0: non-smoker,Y = 1: lung cancer, Y = 0: no lung cancer,B = 1: tar in lungs, B = 0: no tar in lungs.The variable A is associated with an unobservable genetic tendency, the presence of which ( A = 1) in an individual affectsboth the probability that the individual smokes and that they get lung cancer. The variable B by contrast is observable. Pearl308P. Thwaites / Artificial Intelligence 195 (2013) 291–315Fig. 9. BN and CEG C for Example 5.Fig. 10. Manipulated CEG ˆCΛx for Example 5.uses the BN to show that it is possible to estimate p(lung cancer (cid:12) smoker) from joint or conditional distributions of thevariables X, B and Y even if there were to exist such an unobservable genetic tendency.We demonstrate the use of the Front Door theorem for CEGs using this example. The unmanipulated CEG is given inFig. 9, where as before edges are labelled a0 for A = 0 etc. We consider the manipulation to Λx equivalent to Do X = 1, anduse Theorem 2 to find an expression for π (Λ y (cid:12) Λx) ≡ P (Y = 1 (cid:12) X = 1). The manipulated CEG ˆCΛx is given in Fig. 10.Note that if A was observable we could use the Back Door theorem for CEGs here with W X = {w 1, w 2} doubling up asthe blocking set (as in Section 3.4), which would be possible since each element of W X is a distinct stage.For our Front Door theorem we again have W X = {w 1, w 2}, and our partition of Ω corresponding to the values of X isx is the union of all paths passing through an edge labelled x1,x is the union of all paths passing through an edge labelled x0.given byΛ1Λ2The event Λ y is the union of all paths passing through an edge labelled y1.We use the flexibility of CEG analysis to give each Λz a different form from that used in Section 3.3 — instead of beinga union of events of the form Λ(w), we make them a union of events of the form Λ(e). So letΛ1Λ2z be the union of all paths passing through an edge labelled b1,z be the union of all paths passing through an edge labelled b0.P. Thwaites / Artificial Intelligence 195 (2013) 291–315309Checking condition (4.1) on the graph. π (Λ y | Λ(w 1), Λ1x , Λ1z ) is the probability of taking an edge labelled y1, given thatwe have passed through the position w 1, along an edge labelled x1, and then an edge labelled b1. Note that we do notneed to know anything about the probabilities on these edges; nor do we need to refer to any separate list of conditionalindependence properties. Using Lemma 1 this probability is simply that of taking the upper edge leaving w 7 given that wehave passed through w 7.But this is clearly also equal to the probability π (Λ y | Λ(w 1), Λ2Using the symmetry of the problem, condition (4.1) holds.x , Λ1z ).Checking condition (4.2) on the graph. π (Λz | Λ(w 1), Λ1x ) is the probability of taking an edge labelled b1, given that wehave passed through the position w 1, and along an edge labelled x1. Using Lemma 1 this is the probability of a blue edge.But clearly π (Λz | Λ(w 2), Λ1Using the symmetry of the problem, condition (4.2) holds.x ) is also the probability of a blue edge, so these probabilities are equal.Our manipulated probability expression from Theorem 2 is evaluated on C, and is equal top( y1 (cid:12) x1) =(cid:7)bp(b | x1)(cid:7)xp( y1 | x, b) p(x)So as Pearl found, the expression p(lung cancer (cid:12) smoker) can be estimated from joint or conditional distributions of thevariables X (smoker), B (tar in lungs) and Y (lung cancer) only.4.2. An alternative form of the Front Door theoremAt the start of Section 4 we produced a partition of Ω of which Λx was one element, and confined ourselves to ma-nipulations of the form Do X = x. This required us to consider positions {w X } which had the same number of emanatingedges and where these edges carried the same label for each w X . This restriction dilutes one of the powerful reasonsfor using CEGs for causal analysis — the possibility of analysing more complicated functional manipulations of the formDo X = g(W ) for some set of variables W . Corollary 1 gives an alternative Front Door expression which is appropriate forthe full range of singular manipulations. It does however require knowledge of the probability distribution over the events{Λ(w X )}, w X ∈ W X , and joint or conditional distributions including these events. As these events do not always correspondto the values of some problem measurement variable, these distributions might not be easy to quantify. The Theorem 2 ver-sion of the Front Door expression requires knowledge of the probability distribution over the events {Λi}, which are oftenxjust the values of a problem variable X , and as such are more likely to be known.Corollary 1. If W X , Λx, Λ y are detailed as in Section 3, and {Λz} is a partition of Ω which satisfies conditions (4.1) and (4.2), then{Λz} is a Front Door partition, and(cid:7)ˆπ Λx (Λ y) =π (Λz | Λx)(cid:7)(cid:3)πΛ y | Λ(w X ), Λz(cid:4)(cid:3)(cid:4)Λ(w X )πzw X ∈W XThe proof of this corollary follows the proof of Theorem 2 until line (A.4).Note that the partitions {Λ(w X )} and {Λix} can differ considerably in size, with either partition being the larger. If wecan estimate all the relevant probabilities, we can choose between the two versions of the Front Door theorem dependenton the relative size of these sets.5. DiscussionAs noted in the Introduction, there have been a number of recent advances in BN theory which concentrate on therepresentation and analysis of asymmetric problems, and on the analysis of controlled models. The CEG is presented hereas a complementary graphical model, appropriate for analysis in both these areas.In this section we consider when it is appropriate to use CEGs rather than BNs, and in particular when it is appropriateto use them for causal analysis rather than CBNs. We also consider how CEG-based causal analysis might develop in thefuture.We use CEGs for problems which do not admit a natural product space structure, and where problem variables havedifferent sets of possible outcomes (or no possible outcomes) given different vectors of values of ancestral variables. InExample 1, if neither warning light shows then the machine is not checked; and in Example 4, if an individual displaysneither symptom they do not develop the condition in either of its forms. We also use the CEG when the degree of problemasymmetry is such that the topology of the associated BN yields little information of interest. In Example 1 the propertythat whether judged faulty or not is independent of whether light 1 is on or off, given that light 2 is on cannot be read from theDAG. In Example 4 the only conditional independence property readable from the BN is that B (cid:9) X| A. The four significantcontext-specific conditional independence properties are obscured.310P. Thwaites / Artificial Intelligence 195 (2013) 291–315We note here that every BN model is expressible as a CEG, but there are many problems where it is more sensible to usethe former graph. This is certainly the case when problems are essentially symmetric and the benefits of a concise graphoutweigh those of having an explicit representation of the outcome spaces of the problem variables.We use CEGs for causal analysis when the idle system is itself better modelled via a CEG, so for example they are idealfor the analysis of asymmetric controlled models such as treatment regimes. We also use them to analyse the effects ofasymmetric manipulations (e.g. functional and stochastic interventions). These manipulations tend to have a fairly simplerepresentation on a CEG, but such analysis is not necessarily straightforward on a BN, particularly if both the manipulatedvariable and the value this variable takes are dependent on the values of other variables. These types of intervention oftenrequire the addition of edges to the DAG-representation of the problem, which can cause difficulties for an analyst tryingto find suitable blocking sets. We also use CEGs for causal analysis when, using BN-based techniques, we cannot findidentifiable expressions for manipulated probabilities.Any manipulated probability identifiable as a result of using Pearl’s Back Door theorem for a simple or functional ma-nipulation of a BN is also identifiable from a CEG representation. However, as is the case for non-causal analysis, thereare many problems for which CBNs are the most appropriate graph. The obvious example here is when the idle system isessentially symmetric, and the manipulations of interest are simple Do X = x interventions; although even here there areoccasions when a CEG-based analysis might be useful (as we indicate below).Obviously we would use the CEG-based Back Door theorem if we were already using the CEG for our causal analysis.However there are other reasons for doing so. Pearl’s Back Door conditions are easily checked on the topology of the CBN,but this asset diminishes if either there is a lot of context-specific information not encoded in the DAG of the CBN, orthe manipulations of interest are more complex than Do X = x interventions. Furthermore, using the Back Door theoremfor BNs requires the analyst to be able to calculate or estimate p(z) and p( y | x, z) for all values z of the blocking set ofvariables Z . With the CEG our partition does not need to correspond to any fixed subset of the measurement variables thatdefine a BN. This flexibility is very useful when some of the events in the system ( X, Y and Z taking certain vectors ofvalues) are unobservable or have large observational costs. It is also very useful if measurements of the system have notyet been taken, in that the identification of some usable function over the measurement variables can prevent the possiblyexpensive collection of unnecessary information. We have also seen in Example 4 that we can use the CEG version of thetheorem in cases where it would be impossible to use the BN version, as the model does not obey the conditions specifiedby Pearl.The reasons outlined here for using the CEG-based Back Door theorem apply equally to the CEG-based Front Doortheorem.(cid:11)As indicated in Example 4, where there were 65 possible partitions {Λz} which satisfied condition (3.1) (even afterΛ(w z) and specifying the positions {w z}), our ability to choose our Back Door partitionrestricting Λz to the formso that its elements do not correspond to vectors of values of problem variables gives us a lot of flexibility. Now ourpartition {Λz} is fixed in the sense that its membership is constant. Suppose we let the membership depend in some wayon whichever w X ∈ W X our w 0 → w∞ path passes through. If we could do this then our choice of possible partitionswould be enormous.It would also be useful to adapt our Back and Front Door theorems to produce workable versions for some of the non-singular manipulations of the type described in [26] Section 3.2; and to automate the search over the event space of theCEG for partitions {Λz} which satisfy the conditions for these theorems.Longer term, we aim to produce necessary conditions for causal identifiability, expressed as functions of the topology ofthe idle CEG. In this we will be mirroring the work of [6,17,27,28] on causal identifiability on BNs.AcknowledgementsMuch of the initial work leading to this paper was done whilst the author was supported by the EPSRC through grantno. EP/F036752/1. Thanks are due to the referees for their very useful comments which have helped to markedly improvethe clarity of the paper.Appendix AProof of Lemma 1. Consider a single root-to-sink path λ passing through w 1, w 2, w 3. This path consists of a set of edges,and we can assign a probability to it, equal to the product of the primitive probabilities labelling each of these edges.Call this probability π (λ). Moreover, the probability of any subpath of λ is equal to the product of the primitive probabil-ities labelling each of its edges. So π (λ) can be written as the product of the probabilities of four subpaths: μ0(w 0, w 1),μ1(w 1, w 2), μ2(w 2, w 3), and μ3(w 3, w∞). Thusπ (λ) = πμ0 (w 1 | w 0)πμ1 (w 2 | w 1)πμ2 (w 3 | w 2)πμ3 (w∞ | w 3)Consider now the event Λ(w 1, w 2, w 3), which is the union of all root-to-sink paths passing through w 1, w 2, w 3. SinceΛ(w 1, w 2, w 3) is an intrinsic event (see Section 2.1) we haveP. Thwaites / Artificial Intelligence 195 (2013) 291–315311(cid:3)(cid:4)Λ(w 1, w 2, w 3)π=(cid:8) (cid:7)(cid:10)(cid:8) (cid:7)πμ0 (w 1 | w 0)(cid:10)πμ1 (w 2 | w 1)μ0∈M0(cid:8) (cid:7)×μ1∈M1(cid:10)(cid:8) (cid:7)πμ2 (w 3 | w 2)(cid:10)πμ3 (w∞ | w 3)μ3∈M3where Mi (i = 0, 1, 2) is the set of all subpaths from w i to w i+1, and M3 is the set of all subpaths from w 3 to w∞. But(cid:6)πμ0 (w 1 | w 0) isπμ3 (w∞ | w 3) is simply the probability of reaching w∞ from w 3, which equals 1. Andμ2∈M2(cid:6)μ3∈M3μ0∈M0the probability of reaching w 1 from w 0, which is π (Λ(w 1) | Λ(w 0)) etc. So(cid:3)(cid:4)Λ(w 1, w 2, w 3)π(cid:3)(cid:4)Λ(w 1) | Λ(w 0)π(cid:3)(cid:4)Λ(w 2) | Λ(w 1)π(cid:3)(cid:4)Λ(w 3) | Λ(w 2)= π× 1Similarly(cid:3)πand(cid:4)Λ(w 1, w 2)(cid:3)(cid:4)Λ(w 1) | Λ(w 0)π(cid:3)(cid:4)Λ(w 2) | Λ(w 1)= π× 1(cid:3)(cid:4)Λ(w 3) | Λ(w 1), Λ(w 2)π= π (Λ(w 1, w 2, w 3))π (Λ(w 1, w 2))(Λ(w 1) ∩ Λ(w 2) = Λ(w 1, w 2) etc. by construction)(cid:3)(cid:4)Λ(w 3) | Λ(w 2)= π(cid:2)Proof of Theorem 1.ˆπ Λx (Λ y) =(cid:7)(cid:3)ˆπ Λxw X ∈W XΛ(w X ), Λ y(cid:7)(cid:4)=w X ∈W X(cid:3)(cid:4)Λ(w X )(cid:3)(cid:4)Λ y | Λ(w X )ˆπ Λxˆπ Λxsince {Λ(w X )} form a partition of the atomic events(cid:3)(cid:4)Λ(w X )π(cid:3)(cid:4)Λ y | Λ(w X )ˆπ Λx(cid:7)w X ∈W X(cid:7)w X ∈W X(cid:7)===since every w X lies upstream of our manipulation (Definition 8(iv))(cid:3)(cid:4)Λ(w X )πˆπ Λx(cid:3)Λ y | Λ(w X ), Λ(cid:4)(cid:4)(cid:3)w(cid:3)Xsince Λ(w X ) = Λ(e(w X , w(cid:3)X )) ⊂ Λ(w(cid:3)(cid:4)Λ(w X )π(cid:3)X ) in ˆCΛx(cid:3)ˆπ ΛxΛ y | Λ(cid:4)(cid:4)(cid:3)w(cid:3)Xw X ∈W Xusing the form specified for Λ y , the fact that w X ≺ w(cid:3)XFrom the definition of our manipulation, any edge lying on a w≺ w Y for some w Y ∈ W Y in ˆCΛx , and the result of Lemma 1.(cid:3)(cid:3)X→ w∞ path in C remains in ˆCΛx , and retains itsX in ˆCΛx corresponds to a set of path-segments in C,(cid:3)X )) is the probability of a set oforiginal probability. Hence any set of path-segments starting at wand has the same probability as this set. Given the form specified for Λ y , ˆπ Λx (Λ y | Λ(wpath-segments starting at w(cid:3)(cid:3)ˆπ ΛxΛ y | Λ(cid:4)(cid:4)(cid:3)w(cid:3)XandX in ˆCΛx . Hence(cid:4)(cid:4)(cid:3)Λ y | Λw(cid:3)(cid:3)X= πˆπ Λx (Λ y) =(cid:7)(cid:3)(cid:4)Λ(w X )π(cid:3)πΛ y | Λ(cid:4)(cid:4)(cid:3)w(cid:3)X=w X ∈W X(cid:7)w X ∈W X(cid:3)(cid:4)Λ(w X )π(cid:3)πΛ y | Λ(cid:3)(cid:3)ew X , w(cid:3)X(cid:4)(cid:4)(cid:3), Λw(cid:4)(cid:4)(cid:3)Xusing the form specified for Λ y , the fact that e(w X , w≺ w Y for some w Y ∈ W Y in C, and the result of Lemma 1(cid:7)=w X ∈W X(cid:3)(cid:4)Λ(w X )π(cid:3)πΛ y | Λ(cid:3)(cid:3)e(cid:3)(cid:3)X ) ≺ wX(cid:4)(cid:4)(cid:4)(cid:3)Xw X , w312P. Thwaites / Artificial Intelligence 195 (2013) 291–315since Λ(e(w X , w(cid:3)X )) ⊂ Λ(w(cid:7)(cid:3)X ) in C(cid:3)πΛ(w X )(cid:4) (cid:7)(cid:3)πΛz, Λ y | Λ(cid:3)(cid:3)ew X , w(cid:3)X(cid:4)(cid:4)(cid:4)since {Λz} form a partition of the atomic events===w X ∈W Xz(cid:7)w X ∈W X(cid:7)w X ∈W X(cid:3)(cid:3)ππ(cid:4) (cid:7)Λ(w X )z(cid:4) (cid:7)Λ(w X )z(cid:3)πΛ y | Λ(cid:3)(cid:3)ew X , w(cid:3)X(cid:4)(cid:4)(cid:3)(cid:4)π, ΛzΛz | Λ(cid:3)(cid:3)ew X , w(cid:3)X(cid:4)(cid:4)(cid:4)π (Λ y | Λx, Λz)π(cid:3)(cid:4)Λz | Λ(w X )(A.1)substituting from (3.1) and (3.2)(cid:7)=zπ (Λ y | Λx, Λz)π (Λz)(cid:2)Satisfying condition (3.2). Let {Λz} consist of N elements of the form Λizz, only one position w z exists in ˆCΛx . Call this position w i1each V iz .Consider the expression π (Λ y | Λ(e(w X(1), w(cid:3)X(1))), Λie(w X(1), w(cid:3)X(1)) is the edge emanating from w X(1) which is assigned a probability of 1 under our manipulation. Thenz), where w X(1) is a specified element of W X , and the edge(cid:11)=w z∈V izΛ(w z) (for i = 1, . . . , N), where for(cid:3)πΛ y | Λ(cid:3)(cid:3)ew X(1), w(cid:3)X(1)(cid:4)(cid:4)(cid:4)(cid:3)= π, ΛizΛ y | Λ(cid:3)(cid:3)ew X(1), w(cid:4)(cid:4)(cid:3), Λw(cid:4)(cid:4)(cid:3)X(1), Λiz(cid:3)X(1)since passing through the edge e(w X(1), w(cid:3)X(1)) necessarily entails passing through the position w(cid:3)X(1)==π (Λiπ (Λizz, Λ y | Λ(e(w X(1), w(cid:3)| Λ(e(w X(1), wX(1))), Λ(w(cid:3)X(1)))(cid:3)X(1))), Λ(w(cid:3)X(1)))(cid:3)X(1)))π (Λiz, Λ y | Λ(w(cid:3)| Λ(wX(1)))π (Λizusing Lemma 1. Hence(cid:3)πΛ y | Λ(cid:3)(cid:3)ew X(1), w(cid:3)X(1)(cid:4)(cid:4)(cid:4), Λiz= πBut any path-segment in C starting at w(cid:3)(cid:3)(cid:4)(cid:4), Λiz(cid:3)X(1)wΛ y | ΛX(1) remains in ˆCΛx , and we know that {w(cid:3)(cid:3)X(1) to wi jz (for j (cid:2) 2) in ˆCΛx , and hence no path-segments joining w(A.2)i jz} j(cid:2)2 do not exist in ˆCΛx , so there(cid:3)i jz (for j (cid:2) 2)X(1) to ware no path-segments joining win C. Therefore(cid:3)(cid:3)(cid:4)(cid:4)(cid:3)X(1)∩ Λwi jz= φ for j (cid:2) 2Λwand(cid:3)Λw(cid:4)(cid:3)X(1)∩ Λiz= Λ(cid:3)w(cid:3)X(1)(cid:4)(cid:3)∩ Λ(cid:4)w i1zso expression (A.2) becomes(cid:4)(cid:4)(cid:4)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)eπΛ y | Λw X(1), wΛ y | ΛΛ y | Λusing Lemma 1. So Λ y is conditionally independent of which position w X ∈ W X is considered, and= π= π, Λizw i1zw i1zw(cid:3)(cid:3)(cid:3)X(1)(cid:4)(cid:4)(cid:3)(cid:4), Λ(cid:3)X(1)(cid:4)(cid:4)(cid:3)πΛ y | Λ(cid:3)(cid:3)ew X(1), w(cid:3)X(1)(cid:4)(cid:4)(cid:4)(cid:3)= π, ΛizΛ y | Λ(cid:3)(cid:3)ew X(2), w(cid:3)X(2)(cid:4)(cid:4)(cid:4), Λizwhere w X(1), w X(2) are any two positions in W X . Hence condition (3.2) is satisfied.Lemma 2 and W X -based Back Door probability expression. For a CEG C, w X ∈ W X ⊂ V (C), w X ∈ u X ∈ L(C), and Λx =(cid:11)w X ∈W X(cid:3)πΛ(e(w X , w(cid:3)X )); if each edge e(w X , w(cid:4)Λx | Λ(w X )(cid:4)Λx | Λ(u X )= π(cid:3)(cid:3)X ) for w X ∈ u X carries the same label thenP. Thwaites / Artificial Intelligence 195 (2013) 291–315313This tells us that the probability of leaving a stage by an edge carrying a particular label is the same as that of leaving anyof its component positions by an edge carrying this label.(cid:3)X ) label the same value of X for each w X ∈ u X . This is the case for all basic DoThe equality holds if the edges e(w X , winterventions and all functional manipulations.(A.3)(cid:3)X )}w X ∈u X carry theProof.(cid:3)(cid:4)Λx | Λ(u X )π(cid:8)= πΛx |(cid:9)(cid:10)Λ(w X )w X ∈u X(cid:11)=π (Λx,(cid:11)π (w X ∈u XΛ(w X ))w X ∈u XΛ(w X ))And the events {Λ(w X )}w X ∈u X are disjoint (Definitions 1 and 3) so this equals(cid:6)=w X ∈u X(cid:6)π (Λx, Λ(w X ))π (Λ(w X ))w X ∈u XConsider a specific w X ∈ u X . Call this w X(1). Then(cid:14)(cid:13) (cid:9)Λx ∩ Λ(w X(1)) =(cid:3)(cid:3)eΛw X , w(cid:3)X(cid:4)(cid:4)∩ Λ(w X(1))w X ∈u X(cid:3)(cid:3)e= Λw X(1), w(cid:4)(cid:4)(cid:3)X(1)∩ Λ(w X(1))since Λ(e(w X(2), w(cid:3)X(2))) ∩ Λ(w X(1)) = ∅ for w X(2) (cid:13)= w X(1) (w X(2) ∈ W X ).So π (Λx, Λ(w X )) can be written as(cid:3)e(cid:3)(cid:3)π(cid:4)| Λ(w X )Λ(w X ), Λ(cid:3)X )) | Λ(w X )) is constant for all w X ∈ u X , since u X is a stage, and the edges {e(w X , wBut π (Λ(e(w X , wsame label. So we can take this probability outside the summation to give(cid:4)Λ(w X )w X , ww X , w= π(cid:3)e(cid:4)(cid:4)(cid:4)(cid:4)(cid:4)Λ(cid:3)X(cid:3)Xπ(cid:3)(cid:3)(cid:3).(cid:3)(cid:4)Λx | Λ(u X )π=π (Λ(e(w X , ww X ∈u Xπ (Λ(w X ))(cid:6)(cid:3)X )) | Λ(w X ))(cid:6)w X ∈u X(cid:4)(cid:4)π (Λ(w X ))(cid:4)(cid:3)| Λ(w X )X(cid:3)X )), Λ(w X ))= π(cid:3)(cid:3)Λ(cid:3)w X , weπ (Λ(e(w X , wπ (Λ(w X ))= π (Λx, Λ(w X ))π (Λ(w X ))=from ( A.3) above(cid:3)(cid:4)Λx | Λ(w X )= π(cid:2)W X -based Back Door probability expression. Using the proof of Theorem 1 above we can writeπ (Λ y (cid:12) Λx) = ˆπ Λx (Λ y) =(cid:7)(cid:3)(cid:4)Λ(w X )π(cid:3)πΛ y | Λ(cid:3)(cid:3)ew X , w(cid:3)X(cid:4)(cid:4)(cid:4)=====(cid:7)(cid:3)w X ∈W X(cid:4)Λ(w X )π(cid:3)πΛ y | Λ(w X ), Λx(cid:4)w X ∈W X(cid:7)(cid:7)(cid:3)(cid:4)Λ(w X )π(cid:3)πΛ y | Λ(w X ), Λx(cid:4)u X(cid:7)w X ∈u X(cid:7)(cid:13)w X ∈u X(cid:13) (cid:6)u X(cid:7)(cid:14)π (Λ(w X ), Λx, Λ y)π (Λx | Λ(w X ))w X ∈u Xπ (Λ(w X ), Λx, Λ y)π (Λx | Λ(u X ))(cid:3)Λ y | Λ(u X ), Λx(cid:4)π(cid:4)Λ(u X )u X(cid:7)(cid:3)πu X(cid:14)π (Λ(u X ), Λx, Λ y)π (Λx | Λ(u X ))(cid:13)(cid:7)(cid:14)=u X(cid:2)314P. Thwaites / Artificial Intelligence 195 (2013) 291–315Proof of Theorem 2. This follows the proof of Theorem 1 until line (A.1). We then invoke conditions (4.1) and (4.2) to give(cid:4)(cid:4) (cid:7)(cid:7)(cid:3)(cid:3)ˆπ Λx (Λ y) =πΛ(w X )πΛ y | Λ(w X ), Λzπ (Λz | Λx)w X ∈W X(cid:7)π (Λz | Λx)z(cid:7)(cid:3)πΛ y | Λ(w X ), Λz(cid:4)(cid:3)(cid:4)Λ(w X )π==z(cid:7)zπ (Λz | Λx)since {Λix} forms a partition of Ω(cid:7)=π (Λz | Λx)w X ∈W X(cid:7)(cid:7)w X ∈W Xi(cid:7)(cid:7)(cid:3)π(cid:3)πΛ y | Λ(w X ), Λz(cid:3)(cid:4)πΛ(w X ), Λix(cid:4)(A.4)Λ y | Λ(w X ), Λix, Λz(cid:3)(cid:4)πΛ(w X ), Λix(cid:4)zw X ∈W Xiusing condition (4.1). But(cid:3)πΛ(w X ), Λix(cid:4)= π (Λ(w X ), Λix, Λz)π (Λz | Λ(w X ), Λix)= π (Λ(w X ), Λix, Λz)π (Λz | Λix)using condition (4.2)Soˆπ Λx (Λ y) ==(cid:7)z(cid:7)zReferences(cid:3)= πΛ(w X ) | Λix, Λz(cid:4)(cid:3)(cid:4)πΛixπ (Λz | Λx)(cid:7)(cid:7)(cid:3)πΛ y | Λ(w X ), Λix, Λz(cid:3)(cid:4)πΛ(w X ) | Λix, Λz(cid:4)(cid:3)(cid:4)πΛixπ (Λz | Λx)w X ∈W X(cid:7)(cid:3)πiΛ y | Λix, Λz(cid:4)(cid:3)(cid:4)πΛix(cid:2)i[1] T. Bedford, R. Cooke, Probabilistic risk analysis: Foundations and methods, in: Probabilistic Risk Analysis: Foundations and Methods, Cambridge, 2001,pp. 99–151.[2] C. Boutilier, N. Friedman, M. Goldszmidt, D. Koller, Context-specific independence in Bayesian Networks, in: Proceedings of the 12th Conference onUncertainty in Artificial Intelligence, 1996, pp. 115–123.[3] G.A. Churchill, Accurate restoration of DNA sequences, in: C. Gatsaris, et al. (Eds.), Case Studies in Bayesian Statistics, vol. 2, Springer-Verlag, 1995,pp. 90–148.[4] A.P. Dawid, Causal inference without counterfactuals, Journal of the American Statistical Association 95 (2000) 407–448.[5] A.P. Dawid, Influence diagrams for causal modelling and inference, International Statistical Review 70 (2002) 161–189.[6] A.P. Dawid, V. Didelez, Identifying the consequences of dynamic treatment strategies: A decision-theoretic overview, Statistics Surveys 4 (2010) 184–231.[7] S. French (Ed.), Readings in Decision Analysis, Chapman and Hall/CRC, 1989.[8] D. Glymour, G.F. Cooper, Computation, Causation and Discovery, MIT Press, 1999.[9] D. Heckerman, A Bayesian approach to Learning Causal Networks, in: W. Edwards, et al. (Eds.), Advances in Decision Analysis, CUP, 2007, pp. 202–220.[10] S.L. Lauritzen, Graphical Models, Oxford, 1996.[11] S.L. Lauritzen, Causal inference from graphical models, in: O.E. Barndorff-Nielsen, et al. (Eds.), Complex Stochastic Systems, Chapman and Hall, 2001.[12] R. Lyons, Random walks and percolation on trees, Annals of Probability 18 (1990) 931–958.[13] D. McAllester, M. Collins, F. Periera, Case factor diagrams for structured probabilistic modeling, in: Proceedings of the 20th Conference on Uncertaintyin Artificial Intelligence, 2004, pp. 382–391.[14] J. Pearl, Causal diagrams for empirical research, Biometrika 82 (1995) 669–710.[15] J. Pearl, Causality: Models, Reasoning and Inference, Cambridge, 2000.[16] J. Pearl, Statistics and causal inference: A review, Sociedad de Estadistica e Investigacion Operativa. Test 12 (2003) 281–345.[17] J. Pearl, J.M. Robins, Probabilistic evaluation of sequential plans from causal models with hidden variables, in: Proceedings of the 11th Conference onUncertainty in Artificial Intelligence, 1995, pp. 444–445.[18] D. Poole, N.L. Zhang, Exploiting contextual independence in probabilistic inference, Journal of Artificial Intelligence Research 18 (2003) 263–313.[19] J.M. Robins, A new approach to causal inference in mortality studies with sustained exposure period — application to control of the healthy workersurvivor effect, Mathematical Modelling 7 (1986) 1393–1512.[20] A. Salmeron, A. Cano, S. Moral, Importance sampling in Bayesian Networks using probability trees, Computational Statistics and Data Analysis 34 (2000)387–413.[21] G. Shafer, The Art of Causal Conjecture, MIT Press, 1996.[22] J.Q. Smith, P.E. Anderson, Conditional independence and Chain Event Graphs, Artificial Intelligence 172 (2008) 42–68.[23] J.Q. Smith, P.A. Thwaites, Influence diagrams, in: E.L. Melnick, B.S. Everitt (Eds.), Encyclopedia of Quantitative Risk Analysis and Assessment, vol. 2,Wiley, 2008, pp. 897–910.[24] P. Spirtes, C. Glymour, R. Scheines, Causation, Prediction and Search, Springer-Verlag, 1993.P. Thwaites / Artificial Intelligence 195 (2013) 291–315315[25] P.A. Thwaites, J.Q. Smith, R.G. Cowell, Propagation using Chain Event Graphs, in: Proceedings of the 24th Conference on Uncertainty in ArtificialIntelligence, Helsinki, 2008, pp. 546–553.[26] P.A. Thwaites, J.Q. Smith, E.M. Riccomagno, Causal analysis with Chain Event Graphs, Artificial Intelligence 174 (2010) 889–909.[27] J. Tian, Identifying dynamic sequential plans, in: Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence, Helsinki, 2008, pp. 554–561.[28] J. Tian, J. Pearl, A general identification condition for causal effects, in: Proceedings of the 18th National Conference on Artificial Intelligence, AAAIPress, 2002, pp. 567–573.