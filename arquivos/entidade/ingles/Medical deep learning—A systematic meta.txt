Computer Methods and Programs in Biomedicine 221 (2022) 106874 Contents lists available at ScienceDirect Computer Methods and Programs in Biomedicine journal homepage: www.elsevier.com/locate/cmpb Medical deep learning—A systematic meta-review Jan Egger a , b , c , d , e , ∗, Christina Gsaxner a , b , c , Antonio Pepe a , c , Kelsey L. Pomykala d , Frederic Jonske c , d , Manuel Kurz a , c , Jianning Li a , c , d , Jens Kleesiek d , e , f a Institute of Computer Graphics and Vision, Faculty of Computer Science and Biomedical Engineering, Graz University of Technology, Inffeldgasse 16, 8010 Graz, Styria, Austria b Department of Oral &Maxillofacial Surgery, Medical University of Graz, Auenbruggerplatz 5/1, 8036 Graz, Styria, Austria c Computer Algorithms for Medicine Laboratory, Graz, Styria, Austria d Institute for AI in Medicine (IKIM), University Medicine Essen, Girardetstraße 2, 45131 Essen, Germany e Cancer Research Center Cologne Essen (CCCE), University Medicine Essen, Hufelandstraße 55, 45147 Essen, Germany f German Cancer Consortium (DKTK), Partner Site Essen, Hufelandstraße 55, 45147 Essen, Germany a r t i c l e i n f o a b s t r a c t Deep learning has remarkably impacted several different scientific disciplines over the last few years. For example, in image processing and analysis, deep learning algorithms were able to outperform other cutting-edge methods. Additionally, deep learning has delivered state-of-the-art results in tasks like au- tonomous driving, outclassing previous attempts. There are even instances where deep learning outper- formed humans, for example with object recognition and gaming. Deep learning is also showing vast potential in the medical domain. With the collection of large quantities of patient records and data, and a trend towards personalized treatments, there is a great need for automated and reliable processing and analysis of health information. Patient data is not only collected in clinical centers, like hospitals and private practices, but also by mobile healthcare apps or online websites. The abundance of collected pa- tient data and the recent growth in the deep learning field has resulted in a large increase in research effort s. In Q2/2020, the search engine PubMed returned already over 11,0 0 0 results for the search term ‘deep learning’, and around 90% of these publications are from the last three years. However, even though PubMed represents the largest search engine in the medical field, it does not cover all medical-related publications. Hence, a complete overview of the field of ‘medical deep learning’ is almost impossible to obtain and acquiring a full overview of medical sub-fields is becoming increasingly more difficult. Never- theless, several review and survey articles about medical deep learning have been published within the last few years. They focus, in general, on specific medical scenarios, like the analysis of medical images containing specific pathologies. With these surveys as a foundation, the aim of this article is to provide the first high-level, systematic meta-review of medical deep learning surveys. © 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) Article history: Received 5 January 2021 Revised 22 April 2022 Accepted 10 May 2022 Keywords: Deep learning Artificial neural networks Machine learning Data analysis Image analysis Medical image analysis Medical image processing Medical imaging Patient data Pathology Detection Segmentation Registration Generative adversarial networks PubMed Systematic Review Survey Meta-review Meta-survey 1. Introduction Deep learning [1] had a remarkable impact on different sci- entific fields during the last years. This was demonstrated in nu- merous tasks, where deep learning approaches were able to out- perform the standard methods, including image processing and analysis [ 2 , 3 ]. Moreover, deep learning delivers reasonable results in tasks that could not have been performed automatically be- fore, like autonomous driving [ 4 , 5 ]. There are even applications ∗ Corresponding author. E-mail address: egger@tugraz.at (J. Egger) . where deep learning outperformed humans, like in object recog- nition [6] or games [ 7 , 8 ]. A field in which this development has begun to show huge po- tential is the medical domain. With the collection of large quan- tities of patient records and data, and a trend towards personal- ized treatments, there is a great need for automatic and reliable processing and analysis of this information [9] . Patient data is not only collected in clinical centers, like hospitals and private prac- tices, but also by mobile healthcare apps or online websites. To- gether this resulted in new, massive research efforts during the last years. In Q2 of 2020, the search engine PubMed returns already over 11.0 0 0 results for the search term “deep learning ”, and around https://doi.org/10.1016/j.cmpb.2022.106874 0169-2607/© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 90% of these publications are from the last three years. However, even though PubMed represents the largest search engine in the medical domain, it does not cover all medical-related publications. For example, medical topics are also covered in primary venues for computer science research, most often conferences [ 10 , 11 ]. De- spite their high impact and consideration within the community, conference proceedings are usually not listed under PubMed, with only a few exceptions, like the prestigious annual conference ‘ Med- ical Image Computing and Computer Assisted Intervention ’ (MICCAI). In addition, there are rather technical, non-interdisciplinary con- ferences, for example in computer vision, through which very in- fluential research on medical applications is published [12] . These contributions are often overlooked by medical search engines. This does not relate to survey and review articles, which, due to their length, are generally published in peer-reviewed, PubMed-indexed journals. However, for this reason, it is possible for a review article to miss some relevant contributions. Taking all these considerations into account, a complete overview of the field of medical deep learning is almost impossible to obtain and acquiring a full overview of medical sub-fields be- comes increasingly more difficult. Nevertheless, several review and survey articles about medical deep learning have been published within the last years. They focus, in general, on specific medical scenarios, such as the analysis of certain medical images contain- ing specific pathologies, like the automatic detection of a cardio- vascular disorder in computed tomography angiography acquisi- tions [13] . In this context, the aim of this contribution is to provide an introductory, high-level and systematic meta-review of medi- cal deep learning surveys. Modeled after existing meta-reviews in the medical domain, such as the systematic review of systematic reviews of homeopathy [14] , or the survey of surveys on the use of visualization for interpreting machine learning models [15] in a technical domain. The authors are not aware of any meta-review in medical deep learning or general deep learning so far. Compared to medicine, which has a millennia-old tradition, computer science is a very young discipline. Nonetheless, if this discipline continues growing at the current pace, meta-reviews like this will become more and more common. In this publication, we present all review and survey articles published from 2017 to 2019 found by a systematic PubMed search (see Search Strategy). We did not include articles published after 2019, since we also present the citations of the reviewed publica- tions. Thus, the relatively new reviews from 2020 are still ‘under- cited’ in comparison to the reviews from the previous years (as can also be seen in the decreasing number of citations for 2017: 6089 citations, 2018: 947 citations and 2019: 408 citations), and one aim of this contribution is to give an overall impression of the impact these works have already had on their respective scientific fields. Table 1 gives an overview of the number of reviews pub- lished each year, from 2017 to 2019. Furthermore, the table shows the sum of the overall references and citations for each year ac- cording to Google Scholar (status as of August 2020). Tables 2–4 describe the publications of each year in more detail. Systematic literature review phase. For our systematic review, we started with planning the overall structure and main headings of this manuscript, orienting on existing surveys and meta-surveys in the literature. Next, we decided on the databases and years of publication that we wanted to include in our meta-survey. While keeping in mind the overall number of publications we want to cover within our manuscript. Subsequently, we performed the fi- nal literature search (see next paragraph Search Strategy ), summa- rized every survey and extracted the citations, main architectures, evaluations, pros/cons, challenges and future directions. Finally, we analyzed the commonalities and drew a conclusion resulting in a discussion and future outlook. Search Strategy. For this systematic meta-review, a search in PubMed for the keyword ‘Deep Learning’ together with any key- word including {‘Review’, ‘Survey’} was performed. Based on the titles and abstracts, all records which were not actually review or survey contributions in the medical field, like [ 16 , 17 ] and [18] , or were not written in English, like [ 19 , 20 ], or are veterinarian re- views [21] , or are about a human learning strategy called Deep Learning [22] , were excluded (while the term “deep learning ” was coined by Geoffrey Hinton in terms of learning deep neural net- works in 2006 [ 23 , 24 ], the term seemed to have existed much ear- lier in educational psychology [25] . Note further, that non-shallow neural networks had already become an explicit research subject by the early 1990s, when they also became practically feasible to some extent through the help of unsupervised learning [26] ). This ultimately resulted in a total number of 43 review or survey pub- lications about deep learning in the medical field, which are cov- ered within this systematic meta-review. Summarized, this high- level systematic meta-review provides an overview of the pub- lished medical deep learning reviews and surveys in PubMed, as well as their references and citations (status as of August 2020). Note that our systematic search strategy does not cover all topics in medical deep learning, like a survey about uncertainty quantifi- cation in deep learning applications in medical data analysis [27] . However, we did not want to “break” our systematic meta-review search by adding what is arguably arbitrary additional literature. Manuscript Outline. The main body of this contribution presents exclusively reviews and surveys on medical deep learn- ing from a systematic PubMed search. To keep the manuscript concise for the reader, we provide only high-level summaries and excerpts, mainly form the review and survey abstracts (note that some of the presented reviews cover up to several hundred publi- cations themselves). Thus, every review or survey publication will be summarized in around 100 to 200 words. However, by pointing to the associated publications via the keyword classifications and chronological arrangement of the presented medical deep learn- ing reviews or surveys, the interested reader should be able to dive deeper into the specific categories and sub-categories. The rest of this manuscript is organized as follows: Section 2 presents the overview of the medical deep learning reviews and surveys divided into the years of publications from 2017 to 2019 in chronological order, beginning with the first published work in the respective year. The final Section 3 concludes this contribution with a discus- sion and outlines areas of future directions. Research questions. The overall aim of this systematic meta- review is to analyze reviews and surveys published between 2017 and 2019 in medical deep learning. In doing so, we defined the following main research questions for our study: Table 1 Overview of published reviews of deep learning in the medical field from beginning 2017 to end of 2019 according to PubMed and number of citations according to Google Scholar (status as of August 2020). Year (cid:2) Number of publications Number of references Citations (until August 2020) 2017 2018 2019 Sum 7 15 21 43 1060 1684 2279 5023 2 6089 947 408 7444 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 Table 2 List of published reviews of deep learning in the medical field in 2017 according to PubMed and number of citations according to Google Scholar (status as of August 2020); ordered by epub (electronic publication) date. Medical field/subject Publications Date (epub) (cid:2) Number of references Citations (until August 2020) Medical image analysis (I.) Healthcare Medical image analysis (II.) Stroke management Analysis of molecular images in cancer Health-record analysis Microscopy image analysis Sum Shen et al. [28] Miotto et al. [29] Litjens et al. [30] Feng et al. [31] Xue et al. [32] Shickel et al. [33] Xing et al. [34] –March 09, 2017 May 06, 2017 Jul. 26, 2017 Sep. 27, 2017 Oct. 15, 2017 Oct. 26, 2017 Nov. 22, 2017 117 119 439 55 60 63 207 1060 1232 624 3696 40 23 377 97 6089 Table 3 List of published reviews of deep learning in the medical field in 2018 according to PubMed and number of citations according to Google Scholar (status as of August 2020); ordered by epub (electronic publication) date. Medical field/subject Publications Toxicity of chemicals Pulmonary nodule diagnosis Physiological signals DNA sequencing Radiotherapy Ophthalmology Electronic health records Bioinformatics Personalized medicine 1-D biosignals Omics Sport-specific movement recognition Diabetic retinopathy Image cytometry Radiology Sum Tang et al. [35] Yang et al. [36] Faust et al. [37] Celesti et al. [38] Meyer et al. [39] Grewal et al. [40] Xiao et al. [41] Lan et al. [42] Zhang et al. [43] Ganapathy et al. [44] Zhang et al. [45] Cust et al. [46] Nielsen et al. [47] Gupta et al. [48] Mazurowski et al. [49] –Date (epub) (cid:2) Mar. 01, 2018 Apr. 2018 Apr. 11, 2018 Apr. 12, 2018 May 17, 2018 May 30, 2018 Jun. 08, 2018 Jun. 28, 2018 Aug. 07, 2018 Aug. 29, 2018 Sep. 26, 2018 Oct. 11, 2018 Nov. 03, 2018 Dec. 19, 2018 Dec. 21, 2018 Number of references Citations (until August 2020) 103 42 166 52 234 33 123 127 142 117 143 98 42 137 125 1684 13 14 301 14 86 29 146 85 8 19 40 35 12 46 99 947 Table 4 List of published reviews of deep learning in the medical field in 2019 according to PubMed and number of citations according to Google Scholar (status as of August 2020); ordered by epub (electronic publication) date. Medical field/subject Publications Medical imaging Brain cancer classification Electroencephalogram Pulmonary nodule detection Neuro-oncology Diabetic retinopathy Cardiac arrhythmia Protein structure Electroencephalography Neurology Cancer diagnosis Ultrasound Radiation oncology Drug–drug interaction Urology Sleep apnea Ophthalmic diagnosis Alzheimer’s disease Pulmonary nodule detection Liver masses Pulmonary medical imaging Sum Biswas et al. [50] Tandel et al. [51] Craik et al. [52] Pehrson et al. [53] Shaver et al. [54] Asiri et al. [55] Parvaneh et al. [56] Wardah et al. [57] Roy et al. [58] Valliani et al. [59] Munir et al. [60] Akkus et al. [61] Boldrini et al. [62] Zhang et al. [63] Suarez-Ibarrola et al. [64] Mostafa et al. [65] Sengupta et al. [66] Ebrahimighahnavieh et al. [67] Li et al. [68] Azer [69] Ma et al. [70] –Date (epub) (cid:2) Jan. 01, 2019 Jan. 18, 2019 Feb. 26, 2019 Mar. 07, 2019 Jun. 14, 2019 Aug. 07, 2019 Aug. 08, 2019 Aug. 12, 2019 Aug. 14, 2019 Aug. 21, 2019 Aug. 23, 2019 Sep. 03, 2019 Oct. 01, 2019 Nov. 04, 2019 Nov. 05, 2019 Nov. 12, 2019 Nov. 22, 2019 Nov. 27, 2019 Nov. 29, 2019 Dec. 15, 2019 Dec. 16, 2019 Number of references Citations (until August 2020) 94 123 123 48 81 138 20 72 249 83 167 78 64 180 56 93 123 201 60 45 181 2279 28 33 91 21 9 21 4 7 101 8 20 7 10 4 10 5 13 4 3 5 4 408 1) What are the different applications of deep learning in medicine? 2. Medical deep learning: a compact overview of reviews and surveys 2) What are the methods most frequently or successfully em- ployed by deep learning in medicine? 3) What are the strengths and limitations of these methods, espe- cially with respect to the field they are applied to? 4) What are the key research gaps that are being investigated or should be investigated according to researchers? This section presents an overview of review and survey pub- lications in medical deep learning. The publications are arranged in three sub-sections by their year of publication, from 2017 to 2019. Within the yearly sub-sections, the publications are arranged chronologically by their date of publication starting with the first 3J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 Fig. 1. Collage mapping all figures from the reviewed articles to a left hemisphere brain surface. published work in the corresponding year. Typically, review or sur- vey contributions order the reviewed publications in categories, like medical image classification, object detection, segmentation, registration, and other tasks. However, for this meta-review we de- cided explicitly for an order by publication date to show the histor- ical sequence in which they occurred to the reader. Still, the tables provide also a quick overview of the different categories. Hence, at the beginning of every section (2017, 2018 and 2019), the areas of the reviews are summarized in a listing, which corresponds to the chronical order of the publications of this year in the following de- scriptions. Consequently, Tables 1–4 are also divided into the years 2017 to 2019 and chronically ordered. Note, that the reviewed sur- veys can focus on a specific subject, like the survey about diabetic retinopathy screening, or span over a general field, like the survey about healthcare. Moreover, the tables present the number of refer- enced works and the current citations for every year and publica- tion according to Google Scholar, which reveals an overall number of 5023 referenced works in the proposed reviews, and an over- all number of 74 4 4 citations for the reviews themselves (status as of August 2020). Furthermore, Fig. 1 shows a collage, where we mapped all figures of the reviewed articles to the surface of the left hemisphere of the brain. Finally, and equivalent to [37] , Fig. 2 shows a network visualization for the review articles supplied key- words from 2017 to 2019. More specifically, the figure shows the co-occurrence network and the topic clusters for the article key- words, and it reveals the two main clusters, namely “humans”and “deep learning”, and their connections. Further main clusters center around the keywords “machine learning”, “neural networks (computer)” and “algorithms”. Overall, the clusters and connections show how the medical domain has been affected by deep learning in these years, covering a broad range of topics and applications. 2.1. Medical deep learning reviews in 2017 With the described search strategy, seven medical deep learn- ing surveys published in 2017 were discovered. Fig. 3 shows a net- work visualization of the review article keywords from 2017 re- vealing the keyword “humans” with its connections as the main cluster. Further main keyword clusters are “deep learning” and “neural networks (computer)”, which also reveal the main com- monalities and trends for the surveys in 2017. More specific topics in the surveys of 2017 are “electronic health records” and “diag- nostic imaging”. The reaming clusters are of a more general na- ture, like “machine learning”, “algorithms” and “image processing”. The presented reviews from 2017 cite 1060 contributions and have been cited 6089 times (status as of August 2020). They cover the following categories and are ordered by epub (electronic publica- tion) date in 2017 (see Table 2 ): – Medical image analysis (I.); – Healthcare; – Medical image analysis (II.); – Stroke management; – Analysis of molecular images in cancer; – Health-record analysis; – Microscopy image analysis. Medical image analysis (I.) – The aim of medical image analy- sis is to automatically or semi-automatically extract information from patient data. For instance, this could be an automatic de- termination of the tumor volume from a patient’s magnetic res- onance imaging (MRI) scan with the aim to choose the appropri- ate therapy strategy. Shen et al. [28] introduce in their publication the basics of deep learning-based approaches and survey their suc- 4 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 Fig. 2. Network visualization for the review articles supplied keywords from 2017 to 2019 performed with VOSviewer. Fig. 3. Network visualization for the review articles supplied keywords in 2017 performed with VOSviewer. cess in fields like image registration, tissue segmentation, anatomi- cal/cell structures detection, computer-aided disease diagnosis, but also computer-aided disease prognosis. They conclude their work by pointing out remaining research challenges and give suggestions for future research directions that could advance medical image analysis. Healthcare – The umbrella term healthcare envelopes the main- tenance and advancement of people’s health by diagnosis, preven- tion, treatment, but also recovery or even cure of illness, disease, injury, or any further physical or mental maladies. In that con- text, the survey article of Miotto et al. [29] , reviews published re- search using deep learning-based approaches and technologies to improve the healthcare field. Centered on the analyzed publica- tions, they conclude and propose that deep learning-based meth- ods can be used to advance human health by exploring and ex- ploiting big biomedical data. Furthermore, they depict limitations and the need for improved methods and applications and discuss future challenges in this area. 300 works within the area and analyze the usage of deep learning- based methods for object detection, image classification, segmen- tation, but also registration and further tasks. Moreover, they give compact, categorized outlines of studies in different areas of appli- cation, namely digital pathology, neurological, pulmonary, retinal, breast, as well as abdominal, cardiac, and musculoskeletal imag- ing. Finally, they give a summary of the current works at that time and discuss the remaining research questions and directions for upcoming research contributions. Stroke management – Stroke can cause a long-term disability and a vast amount of research has been focused on using neu- roimaging to explore regions of ischemia, which have not been affected by cellular death. In this context, Feng et al. [31] re- view clinical applications for deep learning-guided stroke manage- ment. They identify the following core topics for translating deep learning-based methods in the management of strokes, namely im- age segmentation, multimodal prognostication, but also radiomics (automated featurization). Medical image analysis (II.) – The publication of Litjens et al. [30] surveys the main deep learning-based concepts that are rel- evant for the area of medical image analysis. They summarize over Analysis of molecular images in cancer – Molecular imaging is of major interest for early cancer detection, because it opens the pos- sibility to visualize biological changes on a molecular, but also on a 5 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 cellular level, which enables a quantitative analysis of them. Hence, Xue et al. [32] published a survey about deep learning-based ap- plications for an automated analysis of molecular cancer image ac- quisitions. They survey the deep learning-based applications in the field of molecular imaging with regards to a segmentation of tu- mor lesions, classification of tumors, and a prediction of patient survival. Health-record analysis – Health-record analysis explores the dig- ital information stored in electronic health databases. The initial intention for storing information of patients are administrative tasks in healthcare, such as billing. However, subsequently health records also became interesting for numerous applications in clin- ical informatics for researchers. Hence, Shickel et al. [33] perform a review about deep learning-based research for clinical applica- tions that depend on the analysis of health-record data. They ex- plore numerous deep learning-based frameworks and techniques that have been used for various clinical tasks; for example, in- formation extraction, representation learning, outcome prediction, phenotyping, and de-identification. The authors discovered several remaining research challenges, such as heterogeneity of data, the lack of available universal benchmark tests, and the interpretability of models. They finalize their analysis by recapitulating the recent works, as well as pointing out directions that could be upcom- ing research topics in deep learning-based processing of health- records. Microscopy image analysis – Microscopy images are images ac- quired from a microscope that can be utilized for the characteri- zation of various diseases, such as brain tumors, breast cancer or lung cancer. Xing et al. [34] explore the image analysis domain for medical microscopy by providing at first a dense overview of com- mon deep neural networks. Then, they analyze and review state- of-the-art results of deep learning in the analysis of microscopy images, for example in the tasks of image segmentation, object de- tection and classification. The authors also describe several archi- tectures in deep learning, namely convolutional and fully convo- lutional neural networks, but also deep belief and recurrent neu- ral networks, and lastly, stacked autoencoders. Thereby, they in- vestigate and depict the specific network structures for the dif- ferent applications in the analysis of microscopy images. The au- thors end their review by outlining remaining research needs, and by highlighting possible research directions in the domain of deep learning-based processing of microscopy images. 2.1.1. Diving deeper: architectures, evaluations, pros, cons, challenges and future directions in 2017 Table 5 presents more details about the presented methods, pros, cons, evaluations, challenges and future directions for the re- views from the year 2017. All reported surveys share a number of important conclusions. They agree that deep learning is a promis- ing approach for a wide variety of medical fields and tasks and predict that it will find increasing use in diagnosis, predictions, de- cision making and task automation. The deep learning-based meth- ods explored by the respective surveys typically outperform previ- ous state-of-the-art algorithms based on more naive approaches. In addition, the authors of the surveys all share the opinion that several challenges remain unsolved so far and will require addi- tional exploration in the future. Among those are the inherently low explainability of deep learning approaches (often termed the “black box” problem) and lack of structured and expert-labeled or -annotated data, suggesting the creation of large-scale public datasets. 2.2. Medical deep learning reviews in 2018 With the proposed search strategy, 15 surveys were identified in medical deep learning from 2018. Fig. 4 shows a network visu- alization for the review articles supplied keywords in 2018 that re- veals, equivalent to the surveys from 2017, the keywords “humans”and “deep learning”, and its connections, as the main clusters. Further main keyword clusters center around the more general keywords “machine learning”, “neural networks (computer)” and “algorithms”. However, the smaller clusters around the keywords “electrocardiography”, “computational biology”, “surveys and ques- tionnaires”, “genomics” and “animals”, show that the works in medical deep learning broadened in 2018 compared to 2017. The proposed reviews from 2018 themselves refer to 1684 contribu- tions and have been cited 947 times (status as of August 2020). They cover the following categories, ordered by epub date in 2018 ( Table 3 ): – Toxicity of chemicals; – Pulmonary nodule diagnosis; – Physiological signals; – DNA sequencing; – Radiotherapy; – Ophthalmology; – Electronic health records; – Bioinformatics; – Personalized medicine; – 1-D biosignals; – Omics; – Sport-specific movement recognition; – Diabetic retinopathy; – Image cytometry; – Radiology. Toxicity of chemicals – Toxicity testing and evaluation of chem- icals is important for humans and animals, because they are ex- posed lifelong to natural and synthetic chemicals. Tang et al. [35] analyze in their work how deep learning-based tools can be a utilized for toxicity prediction, by building models for quantitative structure-activity relationships. They focus on large datasets, where classic data analysis techniques cannot deliver fast results. First, a technical overview about deep neural networks is provided by the authors. Then, recent works for the prediction of chemical toxicity models based on deep neural network approaches are explored. Fi- nally, the important data sources for toxicity are outlined, remain- ing challenges are highlighted, and future directions for deep neu- ral network-based approaches for the prediction of chemical toxic- ity are provided. Pulmonary nodule diagnosis – A pulmonary nodule is a small, rounded opacity within the pulmonary interstitium. In their re- view, Yang et al. [36] present deep learning works that aid the decision-making in pulmonary nodule diagnosis. The deep learning-based methods they survey focus on computer-assisted feature extraction, false-positive reduction and nodule detection, but also on a benign-malignant classification in large volume scans of the chest. Physiological signals – Physiological signals are signals from psycho-physiological measurements. In their survey, Faust et al. [37] review deep learning-based approaches utilized in healthcare applications that exploit physiological signals. Their bibliometric review revealed that the analyzed contributions focused mainly on Electromyograms (EMGs), Electroencephalograms (EEGs), Elec- trocardiograms (ECGs) and Electrooculograms (EOGs). Hence, they used these four categories to structure the content of their survey. DNA sequencing – Deoxyribonucleic acid (DNA) sequencing is the determination procedure to reveal the order of nucleotides in DNA. Celesti et al. [38] review deep learning-based approaches to accelerate the process of DNA sequencing, given that huge amount of genomics data is emerging from next-generation sequencing (NGS) techniques. They provide a taxonomic analysis, by outlining the main deep learning-based NGS tools and software, and discuss 6 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 Table 5 Methods, pros, cons, challenges and future directions in medical deep learning in 2017. Publication Methods Pros Cons Challenges Future Directions Medical image analysis I ∗Shen et al. [28] CNN, DBM, DBN, SAE -DL can learn features through labeled data itself -Can be used experts outside of the medical domain -Overfitting due to limited training samples -Image features learnt by deep learning are difficult to understand and interpret Healthcare Miotto et al. [29] AE, CNN, RBM, RNN -DL can model, represent and learn from heterogenous EHR -Neural networks need improvement in interpretability, data integration, and security -Low data volume -Data heterogeneity -Low interpretability -Domain complexity -Disease temporality Medical image analysis II ∗Litjens et al. [30] AE, CNN, DBN, GAN, RBM, SAE, VAE -End to end training (CNN) -Freely available pre-trained deep learning models -Hyper-parameter tuning is empirical -Subjective medical image annotation is susceptible variability and uncertainty -Medical image annotation is time consuming and expensive Stroke Management Feng et al. [31] Analysis of molecular images in cancer Xue et al. [32] CNN, DNN AE, CNN, DNN, SAE -Can apply automated featurization, image segmentation, multi-model prognostication, CAD -Improved speed and performance in tumor segmentation, classification, and survival prediction -Neural networks need improvement -CNN may overfit -CNNs have time consuming training, challenging with low data Health Record Analysis Shickel et al. [33] AE, CNN. MLP, RBM, RNN -LSTM, RNNs, and variant can process sequential data -Lack of transparency and interpretability -DL requires substantial programming skills -Data scarcity -Insufficient and imbalanced datasets -Subjective model depth, architecture and hyperparameters -Abstract high-level features -Heterogenous data -Lack of reproducibility and universal benchmarks Microscopy image analysis Xing et al. [34] CNN, FCN, RNN, SAE -Unsupervised training (SAE) -Unfixed input size (FCN) -easily parallelized training (CNN) -Obtaining large number of annotated microscopy images is expensive -NN requires a fixed input size -Low interpretability -Processing high volumes of medical data require computational acceleration -Build medical equivalent of ImageNET -Incorporate domain-specific knowledge in design/training -Develop a universal algorithm compatible with various imaging modalities and protocols -Use of federated learning, explainable AI -Modeling temporality -Include expert knowledge into modeling -Preserve privacy -upscale and standardize EHR -Task-specific pre-processing and data augmentation techniques -Incorporate prior knowledge of the specific domain into training -Radiological reports could be used to annotate medical images -Leverage non-expert annotation through crowd-sourcing -Unsupervised learning using unlabeled data -Interpretable DL -DL will increasingly become a personalized medicine tool for stroke specialists due to its speed, power and versatility -Self-supervised approaches can solve the annotation problem and make larger datasets usable -Explore model optimization and explainability -Establish larger-scale public datasets -Include robust mechanisms to handle EHR irregularity -Focus NLP on the clinical notes -Unify the representation of various types of patients’ data -Patient deidentification using DL -Increase interpretability -Develop DL methods for WSI analysis -Use a patch-based strategy to reduce computational expenses -Fusing different types of patients’ data -Design task-specific DL architecture based on domain knowledge -Develop unsupervised or semi-supervised learning algorithms Abbreviations: AE: auto-encoder, CAD: computer-assisted diagnosis, CNN: convolutional neural network, DBM: deep Boltzmann machine, DBN: deep belief network, DL: deep learning, DNN: deep neural network, EHR: electronic health record, FCN: fully convolutional network, GAN: generative adversarial network, MLP: multilayer perceptron, NLP: natural language processing, LSTM: long short-term memory, RBM: restricted Boltzmann machine, RNN: recurrent neural network, SAE: stacked auto-encoder, VAE: variational auto-encoder, WSI: whole slide imaging. ∗Also discussed in [74] . remaining research questions with a special focus on cloud com- puting. seven unique categories that are related to the workflow of the patient. Radiotherapy – Radiotherapy (or radiation therapy) utilizes ion- izing radiation to control or kill malignant cancer cells. There- fore, treatment planning and delivery is complex and may be fa- cilitated and partially automated by artificial intelligence. In their review, Meyer et al. [39] start explaining the fundamentals of deep learning-based techniques by relating them to the wider machine learning field. They give an overview of main network architectures, with special attention to convolutional neural net- works. Afterwards, they analyze and summarize deep learning- based works for radiotherapy applications by classifying them into Ophthalmology – The diagnosis and treatment of eye dis- orders in medicine is called ophthalmology. In their review, Grewal et al. [40] explore deep learning as a new technology for ophthalmology with various possible applications. They ex- plore deep learning-based methods that have been utilized in various diagnostic modalities, such as digital photographs, visual fields, and optical coherence tomography. They identify appli- cations in the evaluation of numerous diseases, like cataracts, age-related macular degeneration, glaucoma, and diabetic retinopathy. 7J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 Fig. 4. Network visualization for the review articles supplied keywords in 2018 performed with VOSviewer. Electronic health records – Electronic health records (EHR) sum- marize the data that is routinely collected from millions of patients across diverse healthcare centers, including information about pa- tient demographics, diagnoses, medication prescriptions, clinical notes, laboratory test results, and medical images. Xiao et al. [41] performed a systematic analysis of deep learning-based mod- els for exploring such EHR data by outlining them in regards to the kind of analytics task they perform and the kind of deep learning- based model architecture they use. They also depict the specific challenges resulting from such health data and tasks, and discuss potential solutions, as well as strategies for an evaluation in this field. Bioinformatics – Bioinformatics is an interdisciplinary field de- veloping approaches and software tools for the understanding of biological data with a strong focus on large and complex datasets. Lan et al. [42] survey research works combining deep learning- based methods with data mining, aiming to explore particular knowledge of the bioinformatics domain. The survey work gives a summary of several conventional algorithms in the data mining field that have been utilized for different tasks, like pre-processing, clustering and classification, but also of optimized neural network- based architectures and deep learning-based approaches. Finally, they outline the advantages and disadvantages in practical appli- cations and discuss and compare them in terms of their industrial usage. Personalized medicine – The aim of personalized medicine is to provide tailored patient-specific medical treatments via the identi- fication of common features, like their inheritance, genetics and so on. Zhang et al. [43] provide a research outline concerning learn- ing algorithms and methods, and their application, with an empha- sis on deep learning-based approaches for personalized medicine. They explore three main application domains by giving insights into their pros and cons, namely disease characteristic identifica- tion, drug development, and a prediction of the therapeutic effect. They conclude that the analyzed learning algorithms and methods cannot be seen as a general solution for all kinds of medical prob- lems. 1-D biosignals – Biosignals are electrical, thermal, mechanical or other signals measured over time, coming from the human body or other organic tissues, for example an ECG measures electrical ac- tivity originating from the heart muscle. Ganapathy et al. [44] sur- vey deep learning approaches for 1-D biosignals in the field of computer-aided diagnosis. Further, they aim to establish a taxon- omy to categorize the increasing number of applications in that area. The deep learning-based models were arranged according to the origin, type and dimension of the biosignal, the application goal, type and size of the ground truth data, type and schedule of network learning, and the overall model topology. Omics – The emergence of big data has also involved the field of omics, including genomics, transcriptomics and proteomics. Zhang et al. [45] aim to give an entry-level overview, to understand the usage of deep learning approaches and methods for tackling prob- lems and challenges in the omics domain. They outline and dis- cuss various deep learning-based techniques that have fused deep learning with omics. Furthermore, they explore deep learning- based open-source frameworks with regard to their performances and features, but also highlight upcoming challenges and chances. Sport-specific movement recognition – Sport-specific movement recognition can be utilized for the objective performance analysis of an (elite) athlete. In that regard, Cust et al. [46] explore the au- tomated recognition and characterization of movements in sports, which can provide an alternative for an otherwise manual, time- consuming, limited performance analysis. The authors perform a systematical literature analysis on machine learning- and deep learning-based approaches for movement recognition in sports de- pending on input data from computer vision and inertial measure- ment units. They conclude that the experiment set-up, data pre- processing, and method development need to be considered and adjusted in accordance with the specific characteristics of the ex- amined (sport) movements to achieve good results. 8 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 Diabetic retinopathy – Diabetes is on the rise worldwide and the most frequent microvascular complication is diabetic retinopathy, which can lead to visual impairment or even blindness. Nielsen et al. [47] performed a systematic review of deep learning tech- niques used for diabetic retinopathy screening. They explore works utilizing deep learning-based approaches for the classification of full-scale diabetic retinopathy, using retinal fundus images from di- abetes patients. However, they only include works, which used a grading scale for diabetic retinopathy, a deep learning performance score, and have been compared to a reference standard from a hu- man grader. Image cytometry – Cytometry is the measurement of cell char- acteristics, like the cell size, cell count, cell morphology, cell cycle phase and DNA content. Gupta et al. [48] review how deep learn- ing has been used to analyze microscopy image data of tissue sam- ples and cells. They begin with an overview of neural networks and deep learning. They outline requirements for the input data, com- putational resources, and limitations and challenges in published works on deep learning in image cytometry, as well as identify methods that have not yet been used for cytometry data for po- tential future work. Radiology – Radiology is the medical field of extracting useful information from images, like computed tomography (CT) or MRI, for diagnosis and treatment of humans and animals. In their re- view, Mazurowski et al. [49] give an introduction about the field of radiology and outline open research questions that could be tackled with deep learning techniques. They further provide an overview of basic deep learning concepts, such as convolutional neural networks. Next, they outline deep learning-based research contributions published within the radiology discipline. Thereby, they organize the reviewed works by the specific type of tasks they aim to support. They conclude their work by discussing remaining problems, but also highlight opportunities for using deep learning- based approaches within the practice of radiology. 2.2.1. Diving deeper: architectures, evaluations, pros, cons, challenges and future directions in 2018 Table 6 presents more details about the presented methods, pros, cons, evaluations and challenges and future directions for the reviews from the year 2018. Again, all the reported reviews share several important conclusions. Deep learning methods out- perform machine learning methods over a wide variety of sub- jects, tasks, and datasets. All reviews predict an increase in (and increasing importance) of deep learning-assisted research and, at some future junction, practical applications. Most deep learning methods covered in the individual papers were CNNs and the re- view authors specifically cite CNNs as yielding impressive auto- matically extracted features and performances. The same general issues that were already reported in 2017, such as lack of inter- pretability and high-quality dataset availability, are reported again. Lastly, while generally considered promising, deep learning meth- ods at this point have not been integrated into practical workflows. 2.3. Medical deep learning reviews in 2019 With the proposed search strategy, 21 surveys were identified in the area of medical deep learning in 2019. Fig. 5 shows a net- work visualization for the review articles supplied keywords in 2019 that reveals the keyword “deep learning” and its connec- tions as the main cluster. Further main keyword clusters are “hu- mans”, “machine learning”, and “artificial intelligence”. New clus- ters arise around the keywords “brain” and “brain-computer in- terfaces”, which shows that this organ has been heavily targeted by the research community in 2019. Also interesting is the clus- ter around “convolutional neural network”, which shows that CNN gained momentum in the medical domain by 2019. The proposed reviews from 2019 refer to 2279 contributions and have already been cited 408 times (status as of August 2020). They are or- dered by epub date in 2019 ( Table 4 ) and cover the following categories: – Medical imaging; – Brain cancer classification; – Electroencephalogram; – Pulmonary nodule detection; – Neuro-oncology; – Diabetic retinopathy; – Cardiac arrhythmia; – Protein structure; – Electroencephalography; – Neurology; – Cancer diagnosis; – Ultrasound; – Radiation oncology; – Drug-drug interaction; – Urology; – Sleep apnea; – Ophthalmic diagnosis; – Alzheimer’s disease; – Pulmonary nodule detection; – Liver masses; – Pulmonary medical imaging. Medical imaging – Medical imaging covers the field of produc- ing visual representations of the internal body, for example using computed tomography, magnetic resonance imaging or ultrasound, just to name a few. Biswas et al. [50] explore various types of deep learning systems available, with a focus on current deep learning- based applications in medical imaging. They also outline the tran- sition of technology from machine learning to deep learning and provide a complexity analysis and potential advantages for devel- opers and users. Brain cancer classification – In general, brain tumors are clas- sified into several types, depending on whether they are, for ex- ample, benign or malignant, which helps to choose an optimal treatment for the patient. Tandel et al. [51] review machine learn- ing and deep learning-based methods in the field of brain cancer, with a focus on pathophysiology. They include a review of imaging modalities and automatic, computer assisted methods for the char- acterization of brain cancer. Moreover, they outline the analysis of connections between cancer in the brain and additional brain dis- orders, such as Alzheimer’s disease, Wilson’s disease, Parkinson’s disease, stroke, leukoaraiosis, and further neurological disorders. Electroencephalogram – In the field of neuroscience, EEG analy- sis is an important technique with applications not only in neuro- science, but also neural engineering, like brain-computer interfaces (BCIs). Craik et al. [52] perform a systematic review on deep learn- ing applications for EEG classification, addressing several questions, including specifiying specific EEG tasks. They analyze the studies based on several categories, like preprocessing algorithms for EEG, the kind of input, and the type of deep neural network architec- ture. The deep learning tasks were divided into five groups, namely the mental workload, emotion recognition, seizure detection, mo- tor imagery, event related potential detection, and sleep scoring. For every kind of task, they outline the specific formulation of the input, classifier recommendations, and other major important char- acteristics. Pulmonary nodule detection – Pehrson et al. [53] systematically reviewed the deep learning or machine learning-based methods used for the automatic detection of pulmonary nodules using a common dataset, the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) database. They divide the works into two subcategories based on their overall architecture. 9J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 Table 6 Methods, pros, cons, challenges and future directions in medical deep learning in 2018. Publication Methods Pros Cons Challenges Future directions Toxicity of chemicals Tang et al. [35] DNN Pulmonary nodule diagnosis Yang et al. [36] AE, CNN, DBN, MTANN, SDAE -DNNs outperform ML in prediction of epoxidation, quinone formation, metabolite reactivity, classification of toxicity effects, and chemical-target interaction prediction -Inclusion of CAD, feature extraction and benign-malignant classification -CNNs outperform SVMs and handcrafted rule-based algorithms -Overfitting in DNNs -DNN underperformance with small quantities of training data -Large amounts of data are required for successful training -Imbalanced, inhomogeneous, small datasets -Necessity of long training times and large computational resources -To facilitate DL, large datasets must be set up using time-consuming and unreliable manual labeling Physiological signals Faust et al. [37] AE, CNN, DBN, DNN, KNN, LSTM, RBM, RNN, SDAE, SVM -Eliminates tedious and error-prone manual feature selection -Successful applications include state predictions, classifications and signal decoding. DNA sequencing Celesti et al. [38] AE, CNN, DNN, HMM, MLFF, RNN -Integrated into software for gene expression analysis, genome analysis, SNP research, and early cancer detection -Computational efficiency and best performance/generalization Radiotherapy ∗Meyer et al. [39] AE, CNN, DNN, RNN -Availability of large amount of training data -Increasing power of GPUs Ophthalmology Grewal et al. [40] CNN, others unnamed Electronic health records Xiao et al. [41] AE, CNN, GAN, GRU, LSTM, RNN, UE Bioinformatics ∗Lan et al. [42] Personalized medicine Zhang et al. [43] CNN, DBN, decision tree, DNN clustering, NB, KNN, RNN, SAE, SVM ANN, Bayesian networks, CNN, DBN, DNN, linear regression, MLP, RF, SDAE, SVM -DL has superior performance compared to older automated methods -Successful application for early diagnosis of age-related macular degeneration, diabetic retinopathy, glaucoma -DL: better performance and less manual feature engineering required -Availability of large and complex datasets in healthcare for training -Successfully applied to clinical event prediction, disease classification, phenotyping, text labeling, generating continuous medical time series -DL can learn knowledge from massive amount of data automatically -More modern DNNs and CNNs outperformed older algorithms -Scale more efficiently with increasing dataset complexity -Feature recognition and structural association in structured data -Successfully applied for drug development, disease characteristics and therapeutic effects -Long training times -Need for large training sets -Most existing NGS library preparation devices, sequencing instruments, and software tools have not been designed to work in a clinical networked environment -Building coherent, large and balanced medical datasets that represent real-world scenarios -Difficulty of interpretation -Overinterpreting results from neural networks -Variability in dataset labels, and medical definitions -Temporality and irregularity of EHR data with lack of labels and multi-modality -Lack of generalization -Data imbalance is prevalent in the medical domain -Dataset limited availability, uncertainty, idiosyncrasy, size -Lack of reproducibility overfitting, computational complexity -Data privacy, lack of clinical approval, intellectual property rights, genetic correlation validation -Time consuming -Model architecture and hyperparameters decided without statistical evaluation -Failure to capture information in a generalizable way for chaotic signals -Not discussed -DL theories are empirically and experimentally obtained -Small noise, imperceptible to humans, could alter the output completely -Difficulty conveying quantitative results (such as disease severity) -Overfitting on uncorrelated features, noise, or dataset-inherent biases -Lack of interpretability -DL requires large datasets for training -Dependent on high-end hardware -Lack of interpretability -Have not been applied to large scale datasets -Human intervention is required to extract new knowledge and for safe action 10 -Creation and curation of larger, public datasets by combining datasets from published works, patents and the web -DL for decision support in pulmonary nodule diagnosis and classification -Alleviate the burden of dataset labeling with reinforcement learning -Create public datasets similar to ImageNet -Multi-scale patches during training to bridge data gap -Testing DL applications in practical settings -DL for comparative genomics, forensic biology, biological systematic field, virology) -Cloud computing services will provide scalability and data sharing possibilities -Not discussed -Retinal photography with smartphones and DL deep learning could enable self-ophthalmology and diagnoses -Integrate DL in the ophthalmologic routine -Interpretable and transparent model creation and data curation -Aggregate different ML algorithms -Fuse data from different modalities -Develop semi-supervised and reinforcement learning algorithms -Upgrade clinical data and integration of already developed algorithms -Develop more reliable automated feature selection -Field growth ( continued on next page ) J. Egger, C. Gsaxner, A. Pepe et al. Table 6 ( continued ) Computer Methods and Programs in Biomedicine 221 (2022) 106874 Publication Methods Pros Cons Challenges Future directions 1-D biosignals Ganapathy et al. [44] AE, ANN, CNN, DBN, DNN, RBM, RNN Omics Zhang et al. [45] CNN, DBN, DNN, GRU, LSTM, MLP, RBM, RNN, SAE Sport-specific movement recognition Cust et al. [46] Diabetic Retinopathy Nielsen et al. [47] CNN, DTW, KNN, LSTM, MLP, HMM, NB, RF, SVM CNN, DNN Image cytometry Gupta et al. [48] AE, CNN, DNN, GAN, MLP, RNN -Non-linearity and complexity handled well -Good performance even with multi-modal or complex data -Successfully applied to enhancement, detection, clustering, diagnostics, and prediction. -Successfully applied to DNA, RNA, protein structure analysis, gene expression regulation analysis, disease prediction, protein function analysis -CNNs can analyze spatial information in images -RNNs can analyze correlated features and time-series -DNNs are highly adaptable to almost all types of data -DL outperforms other ML methods in performance and computational efficiency -Does not rely on heuristic features -Reduced manpower due to automation, cost of screening, and issues relating to interrater reliability -Features are generated independently and automatically -Use of “transfer learning”-Successful application areas covered all modalities, tasks and scales Radiology ∗Mazurowski et al. [49] ANN, CNN -Effective in medical image classification, segmentation, detection, reconstruction and registration -Weaknesses not explicitly covered, only the inherent challenges -Older RNNs are unstable during training -Data cleaning is time-consuming and labor-intensive -More training data, computations resources, and higher data quality required -Lack of interpretability -Not discussed -Small and complex datasets, device specificity, noise -Real-time requirements for clinical applications -Missing ground truths -Model selection and parameter tuning -Increase standardization of network topology and parameters -Increasing relevance of reinforcement learning, incremental learning, and transfer learning -Mitigation techniques for the disadvantages of DL methods will continually be developed -Lack of uniformity in data acquisition -Fusion of IMU and vision data in models -Lack of trust due to “black box” nature -Require large amounts of annotated data -Lack of interpretability -Overfitting and underfitting -DL only outperformed human experts in a minority of radiological tasks -Introducing DL into clinical practice will cause legal and ethical issues -Risk of bias towards favorable results due to exclusion of difficult images from datasets -Lack of interpretability -Requires computational resources and programming expertise -Class imbalances can impede the generalization ability -Lack of interpretability -Datasets are smaller and often imbalanced, leading to suboptimal training -Proper clinical validation is often overlooked -Overcome challenges with prediction uncertainty, quality control and lack of interpretability -Combine hand-crafted features and neural network analysis for strong, grounded results -Optimally incorporate DL in existing radiology workflow Abbreviations: AE: auto-encoder, ANN: artificial neural network, CAD: computer-assisted diagnosis, CNN: convolutional neural network, DBN: deep belief network, DL: deep learning, DNN: deep neural network, GAN: generational adversarial networks, GPU: graphic processing unit, GRU: gated recurrent units, HMM: hidden Markov model, IMU: inertial measurement unit, KNN: K-nearest neighbors, LSTM: long short-term memory, ML: machine learning, MLFF: multi-layer feed forward, MLP: multi-layer perceptrons, MTANN: massive training artificial neural network, NB: Naïve Bayes, NGS: next-generation sequencing, RBM: restricted Boltzmann machine, RF: random forest, RNN: recurrent neural network, SDAE: stacked denoising auto-encoder, SNP: single nucleotide polymorphism, SVM: support vector machine,. UE: unsupervised embedding, ∗Also discussed in [74] . They conclude that machine learning and deep learning methods can be used for the detection of lung nodules, even with a high level of sensitivity, specificity and accuracy, however, they also conclude that there is no general technique to evaluate the per- formance of machine learning methods and algorithms. Neuro-oncology – Gliomas represent 80% of all primary malig- nant brain tumors. Shaver et al.’s [54] survey provides an overview of the recent deep learning-based approaches and applications uti- lized for glioma detection and outcome prediction. They focus on the pre-operative and post-operative segmentation of tumors, genetic tissue characterization, and further prognostication. They show and conclude that deep learning-based approaches and ap- plications are promising research directions for the segmentation and characterization of gliomas, their grading, and for giving a sur- vival prediction. Diabetic retinopathy – Another survey about diabetic retinopa- thy was published by Asiri et al. [55] . They focus on deep learning- based computer-aided diagnosis (CAD) systems, which they struc- ture into various stages such as lesion segmentation, lesion detec- tion, and lesion classification of fundus images. Furthermore, they discuss pros and cons of published deep learning-based methods to accomplish these tasks. Cardiac arrhythmia – Cardiac arrhythmias are most commonly detected by an ECG, mainly because of its low cost and convenient usage. For these reasons, every day, ECG data is acquired in large amounts in hospitals and homes, which, on the downside, prevents a detailed manual data inspection. Parvaneh et al. [56] perform a review of recent advancements on cardiac arrhythmia detection using deep learning. They outline existing works according to five different aspects, namely the used dataset, the input data type, the kind of application, the applied architecture model, and finally, the evaluation of performance. They conclude by presenting the short- comings of the surveyed studies and discuss possible future up- coming research directions. Protein structure – The three-dimensional form of local seg- ments of proteins is called protein secondary structure. Wardah et al. [57] wrote a review on predicting the secondary structures of proteins with deep learning-based approaches such as neural net- works. They start with a background section about the secondary structure of a protein and introduce the basics of artificial neural 11 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 Fig. 5. Network visualization for the review articles supplied keywords in 2019 performed with VOSviewer. networks. The authors conclude that there are several challenges left for the in silico predictions of secondary protein structures. Electroencephalography – As stated beforehand in the review about EEG classification, EEG analysis is an important yet difficult task, which requires several years of training because of its com- plexity. Roy et al. [58] performed a systematic survey of the anal- ysis of electroencephalography with deep learning methods, cov- ering various applications domains, like sleep, epilepsy, cognitive and affective monitoring, and brain-computer interfacing. In addi- tion, they collected information pertaining to the data, such as the pre-processing methodology, the selection of the deep learning de- sign, the results, and the experiments’ reproducibility. Neurology – The medical branch related to nervous system dis- orders (central and peripheral) is named neurology. Neurology cov- ers the diagnosis and treatment of such disorders. Valliani et al. [59] review various neurology domains where deep learning algo- rithms have already been applied, like Alzheimer’s disease diagno- sis and early acute neurologic event detection. They also survey the segmentation of medical images for a quantitative evaluation of the neuroanatomy and vasculature structure, connectome mapping for Alzheimer’s diagnosis, autism spectrum disorder (ASD), and at- tention deficit hyperactivity disorder (ADHD), as well as explore the granular genetic signatures and the signals of microscopic elec- troencephalograms. Cancer diagnosis – A range of diseases, involving an abnormal growth of cells, which can also spread and invade other parts of the body, is called cancer. Munir et al. [60] give a bibliographic analysis on cancer diagnosis with deep learning-based approaches, starting with a background description of the cancer diagnosis do- main. They cover the individual steps for cancer diagnosis, but also classification methods, like the asymmetry, border, color and diam- eter (ABCD) method, the Menzies method, the seven-point detec- tion method, and pattern analysis. For each reviewed deep learning technique, they link to Python code. They also compile the applied deep learning models for different cancer types. Specifically, they discuss brain cancer, breast cancer, skin cancer and lung cancer. Ultrasound – Ultrasound (US) is commonly used in the clinical routine due to it is nonionizing, low-cost, and portable characteris- tics, coupled with the ability of providing real-time images. Akkus et al. [61] present a review on deep learning-based applications in the ultrasound domain with the aim to improve the clinical workflow, including improving the acquisition of the US images, real-time evaluation image quality, objective detection and disease diagnosis, and in general, an overall optimized clinical workflow during ultrasound examinations. They also give a specific fore- cast of upcoming research trends and directions for deep learning- based methods that can facilitate an US diagnosis, but also re- duce costs in health care, and provide an optimized clinical US workflow. Radiation oncology – A physician or doctor who is specialized in the treatment of cancer using ionizing radiation, like radionu- clides or megavoltage X-rays, is called a radiation oncologist. In that context, Boldrini et al. [62] perform a literature review in PubMed/Medline with a search strategy including the search terms “radiotherapy” and “deep learning”. They identify recent publica- tions on deep learning in radiation oncology, which they present with a focus on clinically oriented readers. The review shows how deep learning can support clinicians during their daily work, such as by reducing segmentation times, or predicting treatment out- comes and toxicities. However, they conclude that these techniques have yet to be employed in the clinical routine, and it remains to be seen how well they translate into practice. Drug-drug interaction – Drug-drug interactions (DDIs) can cause adverse drug effects that have the potential to threaten public health and patient safety. Hence, these interactions are crucial for drug research and pharmacovigilance. Zhang et al. [63] review the state-of-the-art deep learning-based methods used for DDI ex- ploration. They briefly outline every deep learning method from their surveyed studies and systematically evaluate their efficiency, strengths and weaknesses. They conclude their work by provid- ing a discussion and giving an outlook on several future research challenges for the extraction of DDIs with deep learning-based ap- proaches. Urology – The medical branch of urology is focused on surgi- cal and medical urinary-tract system diseases, including the ure- thra, urinary bladder, ureters, adrenal glands and kidneys. The urol- ogy branch also focuses on the reproductive organs of males, in- cluding the prostate, testes, penis, epididymis, seminal vesicles and vas deferens. Suarez-Ibarrola et al. [64] review recent and upcom- ing machine learning- and deep learning-based applications in the urology domain, with a focus on renal cell carcinomas, urolithi- asis, prostate and bladder cancer. This covers, for example, the prediction of endourologic surgical outcomes in urolithiasis, the automatic distinction between malignant and benign small renal masses, the analysis of texture features and radiomics for the dif- ferentiation between low-grade and high-grade tumors in blad- der cancer, MRI-based computer-aided diagnosis, biochemical re- currence prognosis, and prognosis algorithms for the Gleason score for prostate cancer. Sleep apnea – Sleep apnea is a sleep disorders characterized by repeated stopping and starting of breathing. Sleep apnea can be scored with polysomnography, which is unfortunately expen- sive, inaccessible, uncomfortable and requires an expert techni- cian. Mostafa et al. [65] preform a systematic review on the pub- lished deep learning-based research contributions used for detect- ing sleep apnea. They focus on exploring research subjects includ- ing the implementations of neural networks, a possible need for pre-processing or manual feature extraction, and finally, explore 12 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 Table 7 Methods, pros, cons, challenges and future directions in medical deep learning in 2019. Publication Methods Pros Cons Challenges Medical Imaging Biswas et al. [50] Brain cancer classification Tandel et al. [51] AE, (fully) CNN, DBN, DRN, FCN, SVM ANN, CNN, EM, KNN, NB, RF, SVM Electroencephalogram Craik et al. [52] Neuro-oncology Shaver et al. [54] AE, CNN, DBN, LSTM, MLP, RBM, RNN, SAE, SVM ANN, CNN, CRNN, LSTM, SVM Diabetic retinopathy Asiri et al. [55] AE, CNN, DBN, RNN Cardiac arrhythmia Parvaneh et al. [56] AE, CNN, DBN, LSTM, RNN Protein structure Wardah et al. [57] ANN, CNN, GRU, HMM, RNN Electrocephalography Roy et al. [58] AE, CNN, DBN, GAN, MLP, RBM, RNN, SDAE Neurology Valliani et al. [59] Cancer diagnosis Munir et al. [60] Ultrasound Akkus et al. [61] AE, CNN, DNN, GAN, GRU, LSTM, NB, RNN, SVM AE, AFINN, (fully) CNN, DBN, GAN, LSTM, RBM, RNN AE, (fully) CNN, RBM, RNN, SDAE, SVM -DBM has easy inference -Automated feature extraction -Learning of complicated and composite relationships in data -DL methods surpass in robustness and performance -Automatically produce features that are stable to deformation and translation invariant -DL outperforms other ML methods -Successfully applied to motor imagery, seizure detection, mental workload, sleep stage scoring, event related potential, and emotion recognition -Do not require human-constructed features -CNN architectures provide high accuracies on segmentation, characterization, grading and survival prediction tasks -Automatic discovery of relevant features -Ability to train and deliver solutions in an end-to-end manner -Successfully applied to vessel and optic disk segmentation, lesion detection and classification, diabetic retinopathy diagnosis -Unsupervised information capture and feature generation -Automatic protein structure prediction -Reduced time and costs compared to traditional in vitro analysis -Avoids time-consuming traditional feature engineering and provides end-to-end solutions -Can flexibly work with either small or large amounts of data -Can generalize to other tasks or datasets -Successfully applied to tasks including brain–computer interfacing, sleep staging, epilepsy, cognitive and affective monitoring -No manual feature crafting -Performance gains with larger datasets -Successfully applied for medical image classification, segmentation, functional connectivity, classification of brain disorders and risk prognosis -Learn features from raw images instead of requiring manually constructed features -Successfully applied to cancer diagnosis on multiple image modalities -DL outperformed ML in generalizability -Successfully applied to detection, classification, segmentation, and diagnosis of lesions and nodules -Unknown generalization capabilities (DBN) -Vanishing gradient problems during training (AE) -Computationally more expensive -Improvement needed before techniques could be integrated into clinical workflows -Only trained on small datasets -Not discussed Future Directions -Widespread use in research and clinical routine -Develop real-time applications -Provide the fast, non-invasive diagnosis tool that the field needs -Combine convolutions and recurrent or RBM architectures -Use de-noised EEG data -Undisruptive integration into workflows -Work with regulatory bodies who currently restrict the use of ML/DL in clinical practice -More standardization in data, labels, and test metrics -Research GANs -Formulation of the input data (PSD, wavelet decomposition, etc.) -Lack of large amounts of annotated data -Lack of large-scale annotated uniform training data -Generalization of DL methods -Lack of interpretability -Large datasets needed -Need in vitro techniques to determine hard truths, limiting datasets -Lack of comparability -Lack of labeled data -Dataset augmentations and hyperparameter searches are difficult to identify -Research interpretability -Identify optimal dataset sizes for training and testing -Automated prediction methods will drive the benchmark in the field closer to the theoretical accuracy boundary (approx. 88%) -Efforts in reproducibility -Exploratory research into data quantity vs performance -Not discussed -Requires large quantities of annotated data, necessitating medical expert knowledge and significant amounts of time -Overfitting -Require large amounts of labeled data -Tendency to overfit -Convergence of DL methods not always guaranteed -Lack of interpretability -Class imbalance of datasets -Highest scoring ML outperformed best DL -Overfitting -Not discussed -Lack of reproducibility and interpretability -Require large amounts of data to learn -High quality labels are time-consuming to create -Overfitting -Lack of interpretability -Medical data suffers from heterogeneity and complexity -Data privacy, accessibility and ethical concerns over potential biases -Research into generalizability and interpretability -Require large datasets, generally with labels, a major time/cost investment -Lack of interpretability and explainability -Not discussed -Lack of available datasets -Datasets suffer from a strong disparity between positive and negative samples -Dataset quality and performance vary in acquisition and interpretability -Size and quantity of public datasets are limited -Clinical workflow and cost can be reduced -Include 3D, multiview cine clips, or spatiotemporal data into AI models ( continued on next page ) 13 J. Egger, C. Gsaxner, A. Pepe et al. Table 7 ( continued ) Computer Methods and Programs in Biomedicine 221 (2022) 106874 Publication Methods Pros Cons Challenges Future Directions Radiation Oncology Boldrini et al. [62] Drug-drug interaction Zhang et al. [63] ANN, (fully) CNN, DNN, GAN, SVM CNN, GRU, LSTM, RNN, recursive neural network Urology Suarez-Ibarrola et al. [64] ANN, CNN, SVM Sleep Apnea Mostafa et al. [65] Ophthalmic diagnosis Sengupta et al. [66] Alzheimer’s disease Ebrahimighahnavieh et al. [67] Pulmonary nodule detection Li et al. [68] CNN. DBN, GRU, LSTM, MLP, RNN, SSAE (fully) CNN, FNN, MBNN, RF, SSAE, SVM AE, CNN, DBN, DNN, DPN, HMM, DBM, RBM, SVM (MT)ANN, CNN, SDAE Liver masses Azer [69] (fully) CNN, GAN -Can analyze unstructured data and extract non-linear features without human supervision -Capable of dimensional reduction -Successfully applied to segmentation, outcome, response, and survival predictions -No need for manual feature engineering -CNNs can generate translation-invariant descriptions from data -RNNs can selectively hold relevant information in memory and analyze arbitrary length text inputs -Details not discussed -Increased performance of DL vs ML methods -DL outperforms for lesion and vessel segmentation, acute macular degeneration, glaucoma and diabetic retinopathy classification -Suited for modeling non-linear relationships -Robust against translation and transformations of target features -Capable of automated feature generation -MTANNs and SDAEs can learn with fewer training examples than CNNs and generate new data easily -Successfully applied to detection and classification of pulmonary nodules -Successfully applied to detection, classification, and segmentation of liver masses -Loss of functions are non-convex and no algorithm can guarantee to find an optimal solution -Overfitting -Need for expert knowledge in oncology and DL for dataset curation and training -Need for bigger standardized datasets -Tendency to be unstable during training -Lack of interpretability -Unstructured data and class imbalances -In some cases, ML/DL were favorable to human raters, but traditional statistical methods outperform them, particularly in the field of urolithiasis -Details not discussed -Equipment variants and non-standardized data collection -Generalization -Heterogeneity of employed models and datasets -Imbalanced heterogenous datasets -Hyperparameter search -Semi-/self-supervised learning, joint learning models, N-ary relation extraction, feature enrichment, interpretable modeling -Create large-scale public datasets -Keep downscaling in mind to employ DL methods in real-time or on mobile devices -Not discussed -Requires large amounts of annotated data for training -Can suffer from domain shift between training and test sets -Generalizability -Require large amounts of data for training -Loss of generalization capability -Overfitting, computational cost and robustness -Longer training times and greater dataset requirements -Small datasets in medicine -Overfitting -Class imbalance -Data acquisition and performance indicators are heterogeneous across reported papers -Research generative models to augment existing datasets or balance classes -Domain adaptation -Unpublished code bases -Dataset imbalances and lack of data -ROI-based methods require extensive domain expert knowledge -Heterogeneity of results -Public benchmarking platform for fair comparisons of models -Explainable AI -Generation methodology -Research into consistent, standardized integration of DL into clinical workflow -Details not discussed -Heterogeneity of results Pulmonary medical imaging Ma et al. [70] ANN, (fully) CNN, DPN, neural hy- pernetwork -Self-learning and generalization -Can extract information both from simple and complex data structures -High computational and dataset size requirements -Lack of interpretability -Class imbalances in datasets -Varying image quality Abbreviations: AE: auto-encoder, AFINN: adaptive fuzzy inference neural network, ANN: artificial neural network, CNN: convolutional neural network, CRNN: convolutional recurrent neural network, DBN: deep belief network, DBM: deep Boltzmann machine, DL: deep learning, DNN: deep neural network, DPN: dual path network, DRN: deep residual network, EM: expectation maximization, FCN: fully connected network, FNN: feed-forward neural network, GAN: generational adversarial networks, GRU: gated recurrent units, HMM: hidden Markov model, KNN: K-nearest neighbors, LSTM: long short-term memory, MBNN: Multi-branch neural network, ML: machine learning, MLP: multi-layer perceptrons, MTANN: massive training artificial neural network, NB: Naïve Bayes, RBM: restricted Boltzmann machine, RF: random forest, RNN: recurrent neural network, SAE: stacked auto-encoder, SSAE: Stacked sparse auto-encoder, SVM: support vector machine. the reported applications in terms of implementation and perfor- mance. The applied sensors, signals, databases and implementation difficulties have also been taken into consideration for an auto- matic, deep learning-based scoring process. Ophthalmic diagnosis – Sengupta et al. [66] provide another re- view on ophthalmology, focusing on ophthalmic diagnosis using deep learning approaches based on fundus images (the back sur- face of the eye). They discuss recent deep learning approaches for diabetic retinopathy, glaucoma and age-related macular degenera- tion, and describe numerous datasets consisting of retinal images, which can be processed for deep learning-based ophthalmic tasks. Areas of applications from their surveyed works include segmen- 14 -Standardize reporting, report multiple performance metrics, practically apply, reproduce -Collaborative data acquisition -Case control studies to compare DL methods with human raters -Make use of unlabeled medical data to ease the annotation bottleneck -Develop more interpretable DL models J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 tation of the optic cup, optic disk, and blood vessels, as well as lesion detection. Alzheimer’s disease – In developed countries, Alzheimer’s Dis- ease (AD) is one of the leading causes of death. AD is a chronic neurodegenerative disease that often starts slowly, but progres- sively worsens in the long-term. In this regard, Ebrahimighah- navieh et al. [67] systematically reviewed deep learning-based methods for an automatic AD detection from neuroimaging. They focus on the extraction of effective f eatures and biomarkers, like genetic data, personal information, and scans of the brain, as well as required pre-processing steps and tips for handling neuroimag- ing data that comes from single- or multi-modality investigations. Moreover, they compare the performance of the deep learning models in AD detection and discuss remaining challenges, includ- ing the applied training strategies and datasets that can be ac- cessed. Pulmonary nodule detection – Another systematic review on deep learning-based methods in pulmonary nodule detection was published by Li et al. [68] . They focus on the detection and classification of nodules using CT scans not from the LIDC-IDRI database. They found that three types of deep learning architec- tures are commonly used, namely convolutional neural networks, deep stacked denoising autoencoder extreme learning machine (SDAE-ELM) methods and massive training artificial neural net- works (MTANN). They conclude that high accuracy, specificity and sensitivity scores can be obtained with deep learning-based ap- proaches in nodule classification and detection using CT scans not from the LIDC-IDRI cases. Liver masses – A liver mass is a lesion in the liver that can be caused by an abnormal cell growth, a cyst, hormonal changes, or an immune reaction, but is not necessarily cancer. Azer [69] per- forms a systematic analysis on deep learning-based approaches, specifically convolutional neural networks (CNNs), for the detec- tion of liver masses as well as hepatocellular carcinomas (HCCs). PubMed, the Web of Science, EMBASE and further research books were searched systematically, thereby identifying works analyzing cellular images, pathological anatomy images, and radiological im- ages of liver masses or HCCs. The level of accuracy and CNN per- formance in cancer detection were presented with a focus on an- alyzing the kinds of liver masses and cancers and determining the image types which proved optimal for the precise detection of can- cer. Pulmonary medical imaging – Ma et al. [70] present an anal- ysis on deep learning-based approaches for pulmonary medical imaging. Topics include classification, detection, and segmentation tasks in regard to pulmonary medical images, but also benchmarks and datasets. They provide an outline of the reviewed approaches, which have been implemented for different diseases of the lung, such as pneumonia, pulmonary embolisms, pulmonary nodules, and interstitial lung disease (ILD). Finally, they discuss the future challenges and potential directions in the area of medical imaging with deep learning techniques. 2.3.1. Diving deeper: architectures, evaluations, pros, cons, challenges and future directions in 2019 Table 7 presents more details about the presented methods, pros, cons, evaluations and challenges and future directions for the reviews from the year 2019. Interestingly, while most reviews cite largely the same advantages and disadvantages for deep learning, authors occasionally disagree on whether specific aspects of neu- ral networks pose advantages, disadvantages or challenges, par- ticularly concerning data availability. Some studies have had suc- cess training with very small datasets, while others did not, sug- gesting that not all the nuances of data pre-processing, augmen- tation, and training processes are fully understood yet. Many re- views report that individual papers could not be fairly compared in terms of performance due to the heterogeneity of methods and key performance indicators used, as well as due to the mani- fold differences in both datasets and data acquisition between re- ported papers. There appears to be a significant research gap in terms of standardization for these issues. Sometimes simpler sta- tistical methods or traditional machine learning outperform deep learning and occasionally deep learning is reported to work better when shallower architectures are used, but typically deep learn- ing methods handily outperform any competitors except human raters with years of experience. CNN architectures are typically used/reported the most often in the various review papers and many authors specifically report that CNNs appear to dominate the field both in terms of performance and prevalence. Lastly, deep learning methods are not deployed in clinical practice de- spite regularly achieving state-of-the-art results. Authors typically cite ethical concerns due to lack of interpretability, potential lack of generalizability, and unknown (or unknowable) biases as the rea- son. Thus, practical applications and real-world performance test- ing of newly developed deep learning methods, as well as deeper investigations into Explainable AI, constitute significant research gaps. 3. Conclusion In this work, reviews and surveys on medical deep learning are presented in a systematic meta-review contribution. A systematic search has been performed in the common medical search engine PubMed, which resulted in over 40 review or survey publications published during the last three years. In addition to a brief sum- mary of each survey, the references and citations of these reviews are presented (status as of August 2020). Before 2017, no medical deep learning review article has been indexed under PubMed according to the proposed search strat- egy. This is easily explainable, because even though these kind of approaches had already been suggested and applied at the end of the last century [ 71 , 72 ], deep learning-based approaches only started to gain massive popularity after the convolutional neu- ral network architecture AlexNet [73] won the ImageNet chal- lenge in 2012. From that moment on, deep learning and convo- lutional neural networks have received inexorably increasing at- tention in various communities, including medical image analysis. However, it took some time to have enough published works for the first review or survey articles. In addition, there is also a mas- sive number of review and survey articles in other, general disci- plines. To give a rough impression of these, we performed an addi- tional non-systematic search, which is, however, far from complete and the results are only presented in a systematic listing, because these works would go far beyond the scope of this contribution. Nonetheless, they may be an inspiration for interested readers and we arranged them in three categories (more details can be found in [74] ): 1. Computer vision Object detection [75–77] Image segmentation [ 78 , 79 ] Face recognition [80–82] Action/motion recognition [ 83 , 84 ] Biometric recognition [ 85 , 86 ] Image super-resolution [87] Image captioning [88] Data augmentation [89] Generative adversarial networks [90] 2. Language processing General language processing [91] Language generation and conversation [92–95] 15 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 Named entity recognition [ 96 , 97 ] Sentiment analysis [ 98 , 99 ] Text summarization [100] Answer selection [101] Word embedding [ 102 , 103 ] Financial forecasting [104] 3. Further works Big data [105–107] Reinforcement learning [108–110] Mobile and wireless networking [111] Mobile multimedia [112] Multimodal learning [113] Remote sensing [114] Graphs [115] Anomaly detection [116] Recommender systems [117] Agriculture [118] Multiple areas [119–121] 4. Discussion Typically, new trends in image processing are applied at first to general computer vision tasks, for example to 2D photos, before they are adapted and translated to tasks in the medical domain. This has several reasons. Firstly, 2D image processing is much less computationally intensive compared to processing large 3D image volumes from CTs or MRIs. Secondly, the algorithms are in gen- eral more “complex” and sophisticated (in terms of implemen- tations) for 3D volumes than for 2D image processing, because they need to process one or more dimensions (if several scans at different time points have been acquired). Thirdly, often sev- eral image modalities and volumes, like combined positron emis- sion tomography-computed tomography (PET-CT) scans, are avail- able, and processing them jointly leads to information gain, but also increases the complexity. This is even more cumbersome if scans from different time points and/or different modalities, like CT and MRI, are not registered to each other. Finally, yet impor- tantly, medical data is much harder to acquire and collect than for example natural images, especially in large quantities, not only because of the very time-consuming, often slice-by-slice manual ground truth generation and memory capacities, but also because of privacy concerns. Medical data is usually highly sensitive and personal, and therefore, using it for research purposes requires in- stitutional review board (IRB) approvals and patient consent. Gen- erally, data has to be pseudonymized / anonymized, by removing meta-information from the images and corresponding files, includ- ing name, sex and birth date. However, this is relatively easy com- pared to patient information that is encoded within the images themselves, like the patient’s face in a head scan. Removing the eye area for patient de-identification within a 3D volume is pos- sible, but laborious, because it must be done manually for every scan to make sure the volumes are properly de-identified. A fully automatic approach is conceivable, yet highly risky and potentially disastrous if it fails for even a single case. For head scans, de- identification by removing the eye area can be an option if the re- search is performed on a structure in another area of the head, like the lower jawbone [ 122 , 123 ], but on the downside, it can render the images unusable for applications requiring the entire volume, for example, facial-based medical augmented reality for the head and neck regions, for which all facial features are needed [ 124 , 125 ]. The IRB may allow the usage of the medical data for research pur- poses, but only within their own institution. This means that re- searchers from other institutions cannot re-use the existing data to validate published results or build upon existing methods to push the research boundaries. As a result, a considerable amount 16 of effort has to be invested into obtaining IRB approval, acquiring data, and de-identification, which may delay new research by a few months, at best. Therefore, for large collections of rare patho- logical cases, it can easily take several years to establish a com- prehensive database. Nonetheless, and against all odds, the mas- sive amount of medical deep learning contributions is still increas- ing, and the proposed search strategy already reveals around 50 reviews or surveys for deep learning in PubMed by August 2020, which is more than all reviews from 2017 to 2019 together ( Fig. 6 ). Equivalent to [58] , we also looked at the locations of the first au- thor’s affiliations to get a sense of the geographical distribution of the medical deep learning reviews from this meta-review, and it reveals that the hotspots are the USA and China ( Fig. 7 ). In case the first author provided several affiliations, we chose the very first one listed in the article. The large amount of survey and review papers on medical deep learning published within the last three to four years is an in- dicator of the massive influence and importance that these algo- rithms already have in the medical community, and resulting clin- ical applications. This meta-review shows that, on average, a med- ical deep learning review has been published almost every month during the last years, with an approximately exponential increas- ing trend that seems to continue, if the distribution into the year 2020 is considered. Another indicator for the impact of deep learn- ing in the medical field is the number of references ( > 5.0 0 0) and citations ( > 7.0 0 0) of the reviewed works. Besides the successes in outperforming state-of-the-art methods, there are several further reasons for and increase in research activities in (medical) deep learning: – (1) The relatively easy application of deep learning algorithms to new data, enabled by comprehensive and user-friendly li- braries and toolkits, like TensorFlow [126] , PyTorch [127] or Caffe [128] , just to name a few. These frameworks do not nec- essarily require an in-depth education in computer science. In contrast, in the era before deep learning, very good coding skills in programming languages like C or C ++ were required to im- plement complex image processing algorithms. Factors like op- timization for a reasonable runtime played a much larger role, as hardware was much weaker a few years ago. – (2) Related to the first reason, most deep learning libraries and toolkits support Python bindings, which is a high-level, inter- preted programming language, and therefore, easier to learn, apply and deploy compared to the aforementioned, compiled programming languages, like C or C ++ . – (3) Relating to hardware, the broader availability of graphical processing units (GPUs) certainly contributed to the large dis- tribution and application of medical deep learning and deep learning in general. Pretty much all deep learning libraries and toolkits natively support optimized training and execution of algorithms on a GPU, which speeds up the computation time many times over and makes many interesting big data appli- cations possible. High-capacity GPUs decreased in price over the last few years, and GPU clusters, nowadays usually available at universities, research centers and companies, enable further parallelization and faster processing. Furthermore, GPU cloud servers and services (e.g. from Google Cloud or Amazon Web Services) can be accessed by everyone. – (4) Another reason for the rapid spreading and adoption of deep learning (note that there is also already a review about artificial intelligence / deep learning techniques in imaging data acquisition, segmentation and diagnosis for covid-19 [129] , and another one is on the horizon [130] ), is that many researchers make their code publicly available to the research commu- nity, which is easily possible thanks to online repositories, like GitHub or GitLab. Because most implementations use common J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 Fig. 6. Review and survey articles for medical deep learning in PubMed over the years (status as of August 2020). Fig. 7. World map showing the number of reviews per country according to the first author’s affiliations. deep learning toolkits, they can often be applied to new data without too much adaption. data creators get an additional (citable) journal publication for their effort s. – (5) The beforehand mentioned open access culture is promoted by publication venues, which require source code and data to be made openly available alongside the publication, like the Scientific Reports journal. This ensures reproducibility and ver- ification by other researchers. – (6) Furthermore, there are specific data journals, like Scien- tific Data or Data in Brief that provide venues to make medical datasets and data descriptors available to the research commu- nity. This makes it attractive to offer in-house datasets to the community (which is, first of all, a free service), because the – (7) Finally, deep learning is data-driven, which means it lives and dies by the amount of data it is fed, hence, the increasingly number of public medical databases, like the Cancer Imaging Archive or the Human Connectome Project, can be seen as very import driving forces behind the translation of deep learning into the medical domain. It will be interesting to see what the future holds for us in the field of medical deep learning. Deep learning certainly already has an immense impact on the daily life of a large number of peo- 17 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 ple via the countless applications that are based on this technique, such as, virtual personal assistants like Amazon’s Alexa, Apple’s Siri or Google’s Now. However, as several real-life examples recently demonstrated, deep learning algorithms are not inerrant, as evi- denced by tragic car accidents with self-driving cars, racist miss- classifications of images, or the machine learning bot Tay from Mi- crosoft that became (some kind of) a (virtual) sexist neoNazi [131] . Another relevant example is Google Photos, which identified two black persons as gorillas back in 2015 [132] . Someone could argue that a human raised and educated in a sexist or racist environment might also develop a similar behavioral attitude: Whether the al- gorithm did this willingly is more of a philosophical discussion. In- terestingly, Google “fixed ” the problem by removing and blocking the image categories “gorilla ”, “chimp ”, “chimpanzee ” and “monkey ”. So, in summary, even leading technology companies face difficul- ties when it comes to ensuring that the output of data-driven algo- rithms do not lead to prejudices, racism or stereotypes of any kind. If we translate this issue to the medical area, where complex 3D volumes are used for (life-critical) clinical support, this is very sig- nificant. It should also be mentioned that tasks where deep learn- ing outperformed humans have often been performed under labo- ratory conditions , with a fixed set of samples, not including real-life tests, or further weaknesses [133] , and recent publications show how deep neural networks can easily be fooled [134] . In summary, we identified the following primary research gaps while analyzing the reviewed works: • Almost none of the reported deep learning algorithms were in- corporated into clinical workflows, mostly due to ethics and trust concerns (“How can we trust the neural network not to be wrong/biased, when we don’t understand why it answers the way it does?”), making the testing and integration into clinical practice a prominent research gap. • Along the same vein, research into more interpretable “Explain- able AI” constitutes a large research gap that is particularly rel- evant to understand the underlying methods. And even more relevant to healthcare is an evidence-based medicine where an efficacy must be demonstrated empirically [135] . • A lack of well-annotated, multi-institutional, public datasets (particularly for medical disciplines using data other than ra- diographic images) was reported by most review authors, who also suggested that many individual papers reported the po- tential for increased performance based on more data. This re- search gap still exists today (early 2022), with particular rel- evance in niche disciplines or concerning rare diseases, where the data volume is low to begin with, but decreases in signif- icance over time, as more and more such datasets and other techniques, like Federated Learning [136] , become available. • There exists a distinct lack of reliable standardized key per- formance indicators for deep learning methods in the field of medical research. Therefore, standardization of data, data acqui- sition and performance reporting represents an important facet of deep learning (albeit less of a research gap and more of a trend in the field). • The tuning of model architecture, data processing and augmen- tations, and training hyperparameter choice appears to have a significant effect on the eventual performance of the model. However, due to the “black box” nature of most deep learning models, optimal choices in this regard are often difficult to as- certain. Optimization of this trial-and-error process represents a significant research gap, which is already an intensively dis- cussed topic in the wider deep learning community. • Only a few works cover multimodal data and the majority of works focus on single-modality data. However, physicians con- sider a multitude of resources when treating patients, which computer-assisted methods should also do and there should be a stronger focus on methods that can simultaneously process multimodal data [137] . 5. Author’s perspective From a high-level point of view, and to formulate it provoca- tively, some tasks like medical image segmentation have already been solved over thirty years ago, as can be seen by the claims within the countless publications released in the past years. In ad- dition, the entire computer vision field seems to move from a gen- eral hot topic to another one over the years, like deformable mod- els in the late ‘80 s [138] , graph-based approaches in early ‘00 s [139] , and, finally, deep neural networks after 2010 [140] . This is also reflected by the sharp drop or rise of citations for these pub- lications, depending on the addressed methodology. A more realis- tic picture of the feasibilities of the proposed works during these times may be biomedical challenges, where authors are encour- aged to develop algorithms for a specific task [141] , for exam- ple the very influential brain tumor segmentation (BraTS) chal- lenge, about the automatic segmentation of brain tumors or our new AutoImplant challenge from 2020 [142] , about automatic cra- nial implant design. The quantitative and qualitative evaluation re- sults are often presented afterwards in a compact summary publi- cation [143] . This definitely enables a more objective view on what is currently possible with the state-of-the-art methods (in this re- gard, also note the new BIAS guidelines for transparent reporting of biomedical image analysis challenges [144] ), even though such challenges usually cannot replace a real evaluation in a clinical set- ting. Finally, it should be mentioned that most medical deep learn- ing applications are still in an early phase of development and have not yet found their way into real clinical practice. This stands in strong contrast to non-learning approaches, like those used in medical navigation systems for neurosurgery [ 145 , 146 ]. However, most computer science venues for dissemination, especially flag- ship venues, explicitly prefer and demand new algorithms, while works that focus on the applicability of existing methods to real, variable, and noisy clinical scenarios are nipped in the bud with the argument that they lack technical novelty. At the same time, to foster their status in academia, researchers commonly need to fulfill the expectations of selected publication venues. In many sit- uations, world-leading experts and members of the MICCAI com- munity have been expressing concerns about the practical usabil- ity of the research output, too often limited to ideal scenarios. It is not uncommon to hear criticism about that fact that even high- impact conference proceedings usually contain a huge number of tools and algorithms that are designed for ideal or limited sce- narios and may be therefore inapplicable or sometimes unneeded. MICCAI fellow D. Shen (author of the very first review article in the field of medical deep learning according to our search strategy, see epub date in Table 2 ) summed up this issue in a recent public statement on LinkedIn [147] : “In MICCAI field, people are studying same problems (sometimes ideal problems) with very similar meth- ods for many years. Everyone claims their method is new (although mostly just simply borrowing from others). This is very serious issue, since people in this small academic field judge contributions of their works by themselves. If MICCAI people can just move a little bit out of their academic field, i.e., thinking more on real applications in clin- ical workflow, this issue can be largely avoided. We, as faculty, have more responsibility for changing this situation ”. A step towards this direction could be that interdisciplinary and application-oriented venues encourage the involvement of a medical partner, includ- ing a statement of feasibility in the clinical practice. Furthermore, several interdisciplinary venues do not explicitly require any IRB approval statement, even if the manuscripts deal with clinical pa- tient data (an exception here are publicly available datasets, but 18J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 many works are still evaluated on private datasets provided by a medical partner, which also hinders an objective analyzing and re- porting in reviews). In most medical venues, this is a standard re- quirement and submissions are rejected if the manuscript does not contain an official IRB or patient consent statement. Note that an approval from an ethics commission is also a pre-check for reason- ability and should stop research endeavors that would harm the patient, for example by additional radiation exposure, or do not adhere to clinical workflows. Nevertheless, and to pick up the “not yet found their way into the real clinical practice ” and “limited to ideal scenarios ” thoughts from before, some deep learning experts claim that just adding enough (training) data will automatically lead to perfect results. Contradictory to this opinion, cars have driven already millions of kilometers to acquire training data, but fully self-driving capabili- ties are still far away from being reliable, especially under different weather and light conditions. In this light, Tesla recently removed the “full self-driving ” option from its car store on its website and Uber completely abandoned the development of self-driving cars. It should also be noted that in the medical field, such a massive amount of data will, in many cases, never be available. Certain pathologies are simply (and thankfully) not frequent enough, so even by collecting all the patient data for this pathology from the hospitals around the world and applying additional data augmen- tation methods [148] , there still might not be enough for training powerful algorithms. Nonetheless, there have been certain tasks where machine learning has undoubtedly outperformed humans already. Examples are Deep Blue [149] and AlphaGo [150] in games, where machine learning algorithms could even beat the best (known) human play- ers around the world. However, these tasks have strong constraints by fixes rules on which algorithms can rely on. In contrast, medical tasks usually do not follow such rules and theoretically, unlimited possibilities exist. For example, a brain tumor [151] looks differ- ent for every patient in terms of shape, size, texture, etc. Another example is the human voice, with individual pitches and pronun- ciations, and further the inter-human variations when expressing different emotions [152] . In addition, algorithms can fall back on a massive database of pre-trained games and game moves, with- out any further uncertainty. Another example where deep learning works very well in practice is the automatic detection and anal- ysis of car licenses. Despite several challenges and uncertainties, like different fonts, colors, languages, deformities, complex back- grounds, hazardous situations, speeding vehicles, occlusion, hor- izontal or vertical skew, blurriness, and illumination diversions [153] , the recognition task still stays within a restricted rule set. Therefore, learning algorithms can be pre-trained, for example, by just going over the alphabet with variations, like changing the font, colors, adding some occlusion, etc. It should be kept in mind that still, vehicular license plate recognition is far from perfect. In principle, deep learning is trying to mimic the human brain, especially the learning process of a human brain [154] . Equiva- lent to the fact that we cannot look into someone’s brain with its thoughts or mindset, it is also not yet fully understood what is going on inside a deep neural network (even though we have ac- cess to all neurons and its connections, in contrast to a human’s brain) [155] . Hence, it is as hard to predict exceptions and fail- ures as seen in recent events, like car accidents, as it is to foresee human behavior and mistakes (even if there are, ironically, deep learning works that try to predict human behavior [156] ). Trained neural networks with several layers and with a few hundred or a few thousand neurons are not understandable anymore in all de- tail [155] . This stands in strong contrast to pure engineering ap- proaches, which can be understood in every detail. That makes the acceptance of such black box (some even call it Voodoo [157] ) approaches, like deep learning, by the general population much harder. At this point, we want to refer the interested reader to the concept of disentanglement, which tries to make latent represen- tations interpretable [158] . To conclude, deep learning is an exciting new field with a lot of potential, but not free of controversies. We believe that this first meta-review of medical deep learning reviews and surveys can provide a quick and comprehensive reference for scientists (or just interested readers) who want to get a high-level overview of this field, and maybe want to contribute and thus, accelerate the development in medical deep learning. Hence, the contribution of this systematic meta-review is sixfold: • providing an overview of current deep learning reviews where a medical application plays the key role, • arranging the researched works chronologically for a historical “roten Faden ” ( red/common thread ) and picture over the years, • extracting the overall number of referenced works and citations to give an impression of the research influence and footprints of the respective field, • analyzing, exploring and highlighting the main reasons for the massive research efforts on this topic, • conducting a comprehensive discussion of the current state-of- the-art methods in the deep learning area with achievements but also failures from other domains that should be avoided in the medical area, • and providing a critical expert opinion and pointing out further controversies. Declaration of Competing Interest The authors declare no competing financial interests. Acknowledgements This work received funding from the Austrian Science Fund (FWF) KLI 678-B31 : “enFaced: Virtual and Augmented Reality Train- ing and Navigation Module for 3D-Printed Facial Defect Reconstruc- tions ”, FWF KLI 1044: “Instant AR Tool for Maxillofacial Surgery ”and the TU Graz Lead Project ( Mechanics, Modeling and Simula- tion of Aortic Dissection ). Moreover, this work was supported by CAMed (COMET K-Project 871132 ), which is funded by the Austrian Federal Ministry of Transport, Innovation and Technology (BMVIT), and the Austrian Federal Ministry for Digital and Economic Affairs (BMDW), and the Styrian Business Promotion Agency (SFG). Fur- thermore, we acknowledge the REACT-EU project KITE (Plattform für KI-Translation Essen). Finally, we want to make the interested reader aware of our medical image processing framework Studier- Fenster ( www.studierfenster.at ) [159] , where medical deep learning approaches can be tried out in a standard web browser. Supplementary materials Supplementary material associated with this article can be found, in the online version, at doi: 10.1016/j.cmpb.2022.106874 . References [1] Y. LeCun, Y. Bengio, G. Hinton, Deep learning, Nature 521 (7553) (2015 May) 436–4 4 4 . [2] J. Yu, Z. Lin, J. Yang, X. Shen, X. Lu, T.S. Huang, Generative image inpainting with contextual attention, in: Proceedings of the IEEE conference on com- puter vision and pattern recognition, 2018, pp. 5505–5514 . [3] B. Liu, J. Liu, Overview of Image Denoising Based on Deep Learning, Journal of Physics: Conference Series, 1176, IOP Publishing, 2019 Mar . [4] A. Loquercio, M. Segu, D. Scaramuzza, A general framework for uncertainty estimation in deep learning, IEEE Robot. Automat. Lett. 5 (2) (2020 Feb 18) 3153–3160 . [5] H. Fujiyoshi, T. Hirakawa, T. Yamashita, Deep learning-based image recogni- tion for autonomous driving, IATSS Res. 43 (4) (2019 Dec 1) 244–252 . 19 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 [6] K. He, X. Zhang, S. Ren, J. Sun, Delving deep into rectifiers: surpass- ing human-level performance on imagenet classification, in: Proceedings of the IEEE International Conference on Computer Vision, 2015, pp. 1026–1034 . [7] F. Fuchs, Y. Song, E. Kaufmann, D. Scaramuzza, P. Duerr, Super-Human Per- formance in Gran Turismo Sport Using Deep Reinforcement Learning. arXiv preprint arXiv: 2008.07971 . 2020 Aug 18. [8] D. Silver, A. Huang, C.J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, Mastering the game of Go with deep neural networks and tree search, Nature 529 (7587) (2016 Jan) 4 84–4 89 . [9] S. Dash, S.K. Shakyawar, M. Sharma, S. Kaushik, Big data in healthcare: man- agement, analysis and future prospects, J. Big Data 6 (1) (2019 Dec 1) 54 . [10] M. Franceschet, The role of conference publications in CS, Commun. ACM 53 (12) (2010 Dec 1) 129–132 . [11] M. Eckmann, A. Rocha, J. Wainer, Relationship between high-quality jour- nals and conferences in computer vision, Scientometrics 90 (2) (2012 Feb 1) 617–630 . [12] A.V. Dalca, J. Guttag, M.R. Sabuncu, Anatomical priors in convolutional networks for unsupervised biomedical segmentation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 9290–9299 . [13] A. Pepe, J. Li, M. Rolf-Pissarczyk, C. Gsaxner, X. Chen, G.A. Holzapfel, J. Egger, Detection, segmentation, simulation and visualization of aortic dissections: a review, Med. Image Anal. (2020 Jul 7) 101773 . [14] E. Ernst, A systematic review of systematic reviews of homeopathy, Br. J. Clin. Pharmacol. 54 (6) (2002 Dec) 577–582 . [15] A. Chatzimparmpas, R.M. Martins, I. Jusufi, A. Kerren, A survey of surveys on the use of visualization for interpreting machine learning models, Inf. Vis. (2020 Mar 19) 1473871620904671 . [16] H. Liang, X. Sun, Y. Sun, Y. Gao, Text feature extraction based on deep learn- ing: a review, EURASIP J. Wirel. Commun. Netw. 2017 (1) (2017 Dec) 1–2 . [17] F. Hohman, M. Kahng, R. Pienta, D.H. Chau, Visual analytics in deep learning: an interrogative survey for the next frontiers, IEEE Trans. Vis. Comput. Graph. 25 (8) (2018 Jun 4) 2674–2693 . [18] A. Voulodimos, N. Doulamis, A. Doulamis, E. Protopapadakis, Deep learning for computer vision: a brief review, Comput. Intell. Neurosci. 2018 (2018 Feb 1) . [19] Q. Zhao, P. Kong, J. Min, Y. Zhou, Z. Liang, S. Chen, M. Li, A review of deep learning methods for the detection and classification of pulmonary nodules, J. Biomed. Eng. 36 (6) (2019 Dec 1) 1060–1068 . [20] Y. Liu, Z. Zhao, Review of research on detection and tracking of minimally invasive surgical tools based on deep learning, J. Biomed. Eng. 36 (5) (2019 Oct) 870–878 . [21] K.A. Weigel, P.M. VanRaden, H.D. Norman, H. Grosu, A 100-Year Review: methods and impact of genetic selection in dairy cattle—From daughter–dam comparisons to deep learning algorithms, J. Dairy Sci. 100 (12) (2017 Dec 1) 10234–10250 . [22] L. Cadorin, A. Bagnasco, A. Tolotti, N. Pagnucci, L. Sasso, Instruments for mea- suring meaningful learning in healthcare students: a systematic psychometric review, J. Adv. Nurs. 72 (9) (2016 Sep) 1972–1990 . [23] G.E. Hinton, S. Osindero, Y.W. Teh, A fast learning algorithm for deep belief nets, Neural Comput. 18 (7) (2006 Jul) 1527–1554 . [24] G.E. Hinton, R.R. Salakhutdinov, Reducing the dimensionality of data with neural networks, Science 313 (5786) (2006 Jul 28) 504–507 . [25] J. Biggs, D. Kember, D.Y. Leung, The revised two-factor study process ques- tionnaire: R-SPQ-2F, British J. Edu. Psychol. 71 (1) (2001 Mar) 133–149 . [26] J. Schmidhuber, Deep learning in neural networks: an overview, Neural Netw. 61 (2015 Jan 1) 85–117 . [27] M. Abdar, F. Pourpanah, S. Hussain, D. Rezazadegan, L. Liu, M. Ghavamzadeh, P. Fieguth, X. Cao, A. Khosravi, U.R. Acharya, V. Makarenkov, A review of un- certainty quantification in deep learning: techniques, applications and chal- lenges, Inf. Fusion (2021 May 23) . [28] D. Shen, G. Wu, H.I. Suk, Deep learning in medical image analysis, Annu. Rev. Biomed. Eng. 19 (2017 Jun 21) 221–248 . [29] R. Miotto, F. Wang, S. Wang, X. Jiang, J.T. Dudley, Deep learning for health- care: review, opportunities and challenges, Brief. Bioinform. 19 (6) (2018 Nov) 1236–1246 . [30] G. Litjens, T. Kooi, B.E. Bejnordi, A .A . Setio, F. Ciompi, M. Ghafoorian, J.A. Van Der Laak, B. Van Ginneken, C.I. Sánchez, A survey on deep learning in medical image analysis, Med. Image Anal. 42 (2017 Dec 1) 60–88 . [31] R. Feng, M. Badgeley, J. Mocco, E.K. Oermann, Deep learning guided stroke management: a review of clinical applications, J. Neurointerv. Surg. 10 (4) (2018 Apr 1) 358–362 . [32] Y. Xue, S. Chen, J. Qin, Y. Liu, B. Huang, H. Chen, Application of deep learn- ing in automated analysis of molecular images in cancer: a survey, Contrast. Media Mol. Imaging 2017 (2017 Oct 15) . [33] B. Shickel, P.J. Tighe, A. Bihorac, P. Rashidi, Deep EHR: a survey of recent ad- vances in deep learning techniques for electronic health record (EHR) analy- sis, IEEE J. Biomed. Health Inform. 22 (5) (2017 Oct 27) 1589–1604 . [34] F. Xing, Y. Xie, H. Su, F. Liu, L. Yang, Deep learning in microscopy image anal- ysis: a survey, IEEE Trans. Neural Netw. Learn. Syst. 29 (10) (2017 Nov 22) 4550–4568 . [35] W. Tang, J. Chen, Z. Wang, H. Xie, H. Hong, Deep learning for predicting tox- icity of chemicals: a mini review, J. Environ. Sci. Health, Part C 36 (4) (2018 Oct 2) 252–271 . [36] Y. Yang, X. Feng, W. Chi, Z. Li, W. Duan, H. Liu, W. Liang, W. Wang, P. Chen, J. He, B Liu, Deep learning aided decision support for pulmonary nodules di- agnosing: a review, J. Thorac. Dis. 10 (Suppl 7) (2018 Apr) S867 . [37] O. Faust, Y. Hagiwara, T.J. Hong, O.S. Lih, U.R. Acharya, Deep learning for healthcare applications based on physiological signals: a review, Comput. Methods Programs Biomed. 161 (2018 Jul 1) 1–3 . [38] F. Celesti, A. Celesti, J. Wan, M. Villari, Why deep learning is changing the way to approach NGS data processing: a review, IEEE Rev. Biomed. Eng. 11 (2018 Apr 12) 68–76 . [39] P. Meyer, V. Noblet, C. Mazzara, A. Lallement, Survey on deep learning for radiotherapy, Comput. Biol. Med. 98 (2018 Jul 1) 126–146 . [40] P.S. Grewal, F. Oloumi, U. Rubin, M.T. Tennant, Deep learning in ophthalmol- ogy: a review, Can. J. Ophthalmol. 53 (4) (2018 Aug 1) 309–313 . [41] C. Xiao, E. Choi, J. Sun, Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review, J. Am. Med. Inform. Assoc. 25 (10) (2018 Oct) 1419–1428 . [42] K. Lan, D.T. Wang, S. Fong, L.S. Liu, K.K. Wong, N. Dey, A survey of data mining and deep learning in bioinformatics, J. Med. Syst. 42 (8) (2018 Aug 1) 139 . [43] S. Zhang, S.M. Bamakan, Q. Qu, S. Li, Learning for personalized medicine: a comprehensive review from a deep learning perspective, IEEE Rev. Biomed. Eng. 12 (2018 Aug 7) 194–208 . [44] N. Ganapathy, R. Swaminathan, T.M. Deserno, Deep learning on 1-D biosig- nals: a taxonomy-based survey, Yearb. Med. Inform. 27 (1) (2018 Aug) 98 . [45] Z. Zhang, Y. Zhao, X. Liao, W. Shi, K. Li, Q. Zou, S. Peng, Deep learning in omics: a survey and guideline, Brief Funct. Genomics 18 (1) (2019 Jan) 41–57 . [46] E.E. Cust, A.J. Sweeting, K. Ball, S. Robertson, Machine and deep learning for sport-specific movement recognition: a systematic review of model develop- ment and performance, J. Sports Sci. 37 (5) (2019 Mar 4) 568–600 . [47] K.B. Nielsen, M.L. Lautrup, J.K. Andersen, T.R. Savarimuthu, J. Grauslund, Deep learning–based algorithms in screening of diabetic retinopathy: a system- atic review of diagnostic performance, Ophthalmol. Retina 3 (4) (2019 Apr 1) 294–304 . [48] A. Gupta, P.J. Harrison, H. Wieslander, N. Pielawski, K. Kartasalo, G. Partel, L. Solorzano, A. Suveer, A.H. Klemm, O. Spjuth, I.M. Sintorn, Deep learning in image cytometry: a review, Cytometry Part A 95 (4) (2019 Apr) 366–380 . [49] M.A. Mazurowski, M. Buda, A. Saha, M.R. Bashir, Deep learning in radiology: an overview of the concepts and a survey of the state of the art with focus on MRI, J. Magnet. Reson. Imag. 49 (4) (2019 Apr) 939–954 . [50] M. Biswas, V. Kuppili, L. Saba, D.R. Edla, H.S. Suri, E. Cuadrado-Godia, J.R. Laird, R.T. Marinhoe, J.M. Sanches, A. Nicolaides, J.S. Suri, State-of-the-art review on deep learning in medical imaging, Front. Biosci. (Landmark Ed) 24 (2019 Jan) 392–426 . [51] G.S. Tandel, M. Biswas, O.G. Kakde, A. Tiwari, H.S. Suri, M. Turk, J.R. Laird, C.K. Asare, A .A . Ankrah, N.N. Khanna, B.K. Madhusudhan, A review on a deep learning perspective in brain cancer classification, Cancers (Basel) 11 (1) (2019 Jan) 111 . [52] A. Craik, Y. He, J.L. Contreras-Vidal, Deep learning for electroencephalogram (EEG) classification tasks: a review, J. Neural Eng. 16 (3) (2019 Apr 9) 031001 . [53] L.M. Pehrson, M.B. Nielsen, Ammitzbøl Lauridsen C. Automatic pulmonary nodule detection applying deep learning or machine learning algorithms to the LIDC-IDRI database: a systematic review, Diagnostics 9 (1) (2019 Mar) 29 . [54] M.M. Shaver, P.A. Kohanteb, C. Chiou, M.D. Bardis, C. Chantaduly, D. Bota, C.G. Filippi, B. Weinberg, J. Grinband, D.S. Chow, P.D. Chang, Optimizing neu- ro-oncology imaging: a review of deep learning approaches for glioma imag- ing, Cancers (Basel) 11 (6) (2019 Jun) 829 . [55] N. Asiri, M. Hussain, F. Al Adel, N Alzaidi, Deep learning based comput- er-aided diagnosis systems for diabetic retinopathy: a survey, Artif. Intell. Med. 99 (2019 Aug 1) 101701 . [56] S. Parvaneh, J. Rubin, S. Babaeizadeh, M. Xu-Wilson, Cardiac arrhythmia de- tection using deep learning: a review, J. Electrocardiol. 57 (2019 Nov 1) S70–S74 . [57] W. Wardah, M.G. Khan, A. Sharma, M.A. Rashid, Protein secondary structure prediction using neural networks and deep learning: a review, Comput. Biol. Chem. 81 (2019 Aug 1) 1–8 . [58] Y. Roy, H. Banville, I. Albuquerque, A. Gramfort, T.H. Falk, J. Faubert, Deep learning-based electroencephalography analysis: a systematic review, J. Neu- ral Eng. 16 (5) (2019 Aug 14) 051001 . [59] A .A . Valliani, D. Ranti, E.K. Oermann, Deep learning and neurology: a system- atic review, Neurol. Ther. (2019 Aug 21) 1–5 . [60] K. Munir, H. Elahi, A. Ayub, F. Frezza, A. Rizzi, Cancer diagnosis using deep learning: a bibliographic review, Cancers (Basel) 11 (9) (2019 Sep) 1235 . [61] Z. Akkus, J. Cai, A. Boonrod, A. Zeinoddini, A.D. Weston, K.A. Philbrick, B.J. Er- ickson, A survey of deep-learning applications in ultrasound: artificial intel- ligence–powered ultrasound for improving clinical workflow, J. Am. College Radiol. 16 (9) (2019 Sep 1) 1318–1328 . [62] L. Boldrini, J.E. Bibault, C. Masciocchi, Y. Shen, M.I. Bittner, Deep learning: a review for the radiation oncologist, Front. Oncol. 9 (2019) 977 . [63] T. Zhang, J. Leng, Y. Liu, Deep learning for drug–drug interaction extraction from the literature: a review, Brief. Bioinform. (2019 Nov 4) . [64] R. Suarez-Ibarrola, S. Hein, G. Reis, C. Gratzke, A. Miernik, Current and future applications of machine and deep learning in urology: a review of the liter- ature on urolithiasis, renal cell carcinoma, and bladder and prostate cancer, World J. Urol. (2019 Nov 5) 1–9 . [65] S.S. Mostafa, F. Mendonça, A. G Ravelo-García, F Morgado-Dias, A systematic review of detecting sleep apnea using deep learning, Sensors 19 (22) (2019 Jan) 4934 . 20 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 [66] S. Sengupta, A. Singh, H.A. Leopold, T. Gulati, V. Lakshminarayanan, Oph- thalmic diagnosis using deep learning with fundus images–A critical review, Artif. Intell. Med. 102 (2020 Jan 1) 101758 . [67] M.A. Ebrahimighahnavieh, S. Luo, R. Chiong, Deep learning to detect Alzheimer’s disease from neuroimaging: a systematic literature review, Com- put. Methods Programs Biomed. 187 (2020 Apr 1) 105242 . [68] D. Li, B. Mikela Vilmun, J. Frederik Carlsen, E. Albrecht-Beste, C. Ammitzbøl Lauridsen, M. Bachmann Nielsen, K. Lindskov Hansen, The performance of deep learning algorithms on automatic pulmonary nodule detection and clas- sification tested on different datasets that are not derived from lidc-idri: a systematic review, Diagnostics 9 (4) (2019 Dec) 207 . [69] S.A. Azer, Deep learning with convolutional neural networks for identification of liver masses and hepatocellular carcinoma: a systematic review, World. J. Gastrointest. Oncol. 11 (12) (2019 Dec 15) 1218 . [70] J. Ma, Y. Song, X. Tian, Y. Hua, R. Zhang, J. Wu, Survey on deep learning for pulmonary medical imaging, Front. Med. (2019 Dec 16) 1–20 . [71] K. Fukushima, S. Miyake, Neocognitron: a self-organizing neural network model for a mechanism of visual pattern recognition. In Competition and Co- operation in Neural Nets 1982 (pp. 267–285). Springer, Berlin, Heidelberg. [72] Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, Gradient-based learning applied to document recognition, Proc. IEEE 86 (11) (1998 Nov) 2278–2324 . [73] A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep con- volutional neural networks. In Advances in neural information processing sys- tems 2012 (pp. 1097–1105). [74] J. Egger, A. Pepe, C. Gsaxner, Y. Jin, J. Li, R Kern, Deep learning—A first meta–survey of selected reviews across scientific disciplines, their commonalities, challenges and research impact, Peer J. Comput. Sci. 7 (2021 Nov 17) e773 . [75] L. Liu, W. Ouyang, X. Wang, P. Fieguth, J. Chen, X. Liu, M. Pietikäinen, Deep learning for generic object detection: a survey, Int. J. Comput. Vis. 128 (2) (2020 Feb) 261–318 . [76] Z.Q. Zhao, P. Zheng, S.T. Xu, X. Wu, Object detection with deep learning: a review, IEEE Trans. Neural Netw. Learn. Syst. 30 (11) (2019 Jan 28) 3212–3232 . [77] L. Jiao, F. Zhang, F. Liu, S. Yang, L. Li, Z. Feng, R. Qu, A survey of deep learn- ing-based object detection, IEEE Access 7 (2019 Sep 5) 128837–128868 . [78] A. Garcia-Garcia, S. Orts-Escolano, S. Oprea, V. Villena-Martinez, P. Martinez–Gonzalez, J. Garcia-Rodriguez, A survey on deep learning techniques for image and video semantic segmentation, Appl. Soft Comput. 70 (2018 Sep 1) 41–65 . [79] S. Minaee, Y. Boykov, F. Porikli, A. Plaza, N. Kehtarnavaz, D. Terzopoulos, Image segmentation using deep learning: a survey. arXiv preprint arXiv: 2001.05566 . 2020 Jan 15. [80] I. Masi, Y. Wu, T. Hassner, P. Natarajan, Deep face recognition: a survey, in: 2018 31st SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI), IEEE, 2018 Oct 29, pp. 471–478 . [81] S. Li, W. Deng, Deep facial expression recognition: a survey, IEEE Trans. Affect. Comput. (2020 Mar 17) . [99] H.H. Do, P.W. Prasad, A. Maag, A. Alsadoon, Deep learning for aspect-based sentiment analysis: a comparative review, Expert Syst. Appl. 118 (2019 Mar 15) 272–299 . [100] T. Shi, Y. Keneshloo, N. Ramakrishnan, C.K. Reddy, Neural abstractive text summarization with sequence-to-sequence models. arXiv preprint arXiv: 1812. 02303 . 2018 Dec 5. [101] T. Lai, T. Bui, S. Li, A review on deep learning techniques applied to answer selection, in: Proceedings of the 27th International Conference on Computa- tional Linguistics, 2018 Aug, pp. 2132–2144 . [102] Y. Zhang, M.M. Rahman, A. Braylan, B. Dang, H.L. Chang, H. Kim, Q. McNa- mara, A. Angert, E. Banner, V. Khetan, T. McDonnell, Neural information re- trieval: a literature review. arXiv preprint arXiv: 1611.06792 . 2016 Nov 18. [103] F. Almeida, G. Xexéo, Word embeddings: a survey. arXiv preprint arXiv: 1901. 09069 . 2019 Jan 25. [104] F.Z. Xing, E. Cambria, R.E. Welsch, Natural language based financial forecast- ing: a survey, Artif. Intell. Rev. 50 (1) (2018 Jun 1) 49–73 . [105] Q. Zhang, L.T. Yang, Z. Chen, P. Li, A survey on deep learning for big data, Inf. Fus. 42 (2018 Jul 1) 146–157 . [106] M. Mohammadi, A. Al-Fuqaha, S. Sorour, M. Guizani, Deep learning for IoT big data and streaming analytics: a survey, IEEE Commun. Surv. Tutor. 20 (4) (2018 Jun 6) 2923–2960 . [107] F. Emmert-Streib, Z. Yang, H. Feng, S. Tripathi, M Dehmer, An introductory re- view of deep learning for prediction models with big data, Front. Artif. Intell. 3 (2020) 4 . [108] S.S. Mousavi, M. Schukat, E. Howley, Deep reinforcement learning: an overview. In Proceedings of SAI Intelligent Systems Conference 2016 Sep 21 (pp. 426–440). Springer, Cham. [109] Y. Li, Deep reinforcement learning: an overview. arXiv preprint arXiv: 1701. 07274 . 2017 Jan 25. [110] K. Arulkumaran, M.P. Deisenroth, M. Brundage, A .A . Bharath, Deep reinforce- ment learning: a brief survey, IEEE Signal Process. Mag. 34 (6) (2017 Nov 9) 26–38 . [111] C. Zhang, P. Patras, H. Haddadi, Deep learning in mobile and wireless networking: a survey, IEEE Commun. Surv. Tutor. 21 (3) (2019 Mar 13) 2224–2287 . [112] K. Ota, M.S. Dao, V. Mezaris, F.G. Natale, Deep learning for mobile multime- dia: a survey, ACM Trans. Multim. Comput. Commun. Appl. (TOMM 13 (3s) (2017 Jun 28) 1–22 . [113] D. Ramachandram, G.W. Taylor, Deep multimodal learning: a survey on re- cent advances and trends, IEEE Signal Process. Mag. 34 (6) (2017 Nov 9) 96–108 . [114] J.E. Ball, D.T. Anderson, C.S. Chan, Comprehensive survey of deep learning in remote sensing: theories, tools, and challenges for the community, J. Appl. Remote Sens. 11 (4) (2017 Sep) 042609 . [115] Z. Zhang, P. Cui, W. Zhu, Deep learning on graphs: a survey, IEEE Trans. [82] W. Mei, W. Deng, Deep face recognition: a survey. arXiv preprint arXiv: 1804. Knowl. Data Eng. (2020 Mar 17) . 06655 . 2018;1. [83] S. Herath, M. Harandi, F. Porikli, Going deeper into action recognition: a sur- vey, Image Vis. Comput. 60 (2017 Apr 1) 4–21 . [84] P. Wang, W. Li, P. Ogunbona, J. Wan, S. Escalera, RGB- d -based human motion recognition with deep learning: a survey, Comput. Vis. Image Understand 171 (2018 Jun 1) 118–139 . [85] K. Sundararajan, D.L. Woodard, Deep learning for biometrics: a survey, ACM Comput. Surv. (CSUR) 51 (3) (2018 May 23) 1–34 . [86] S. Minaee, A. Abdolrashidi, H. Su, M. Bennamoun, D. Zhang, Biometric recog- nition using deep learning: a survey. arXiv preprint arXiv: 1912.00271 . 2019 Nov 30. [87] Z. Wang, J. Chen, S.C. Hoi, Deep learning for image super-resolution: a survey, IEEE Trans. Pattern Anal. Mach. Intell. (2020 Mar 23) . [88] M.Z. Hossain, F. Sohel, M.F. Shiratuddin, H. Laga, A comprehensive survey of deep learning for image captioning, ACM Comput. Surv. (CSUR) 51 (6) (2019 Feb 4) 1–36 . [89] C. Shorten, T.M. Khoshgoftaar, A survey on image data augmentation for deep learning, J. Big. Data 6 (1) (2019 Dec 1) 60 . [90] Z. Wang, Q. She, T.E. Ward, Generative adversarial networks in computer vi- sion: a survey and taxonomy. arXiv preprint arXiv: 1906.01529 . 2019 Jun 4. [91] T. Young, D. Hazarika, S. Poria, E. Cambria, Recent trends in deep learning based natural language processing, IEEE Comput. Intell. Mag. 13 (3) (2018 Jul 20) 55–75 . [92] A. Gatt, E. Krahmer, Survey of the state of the art in natural language gener- ation: core tasks, applications and evaluation, J. Artif. Intell. Res. 61 (2018 Jan 27) 65–170 . [93] S. Santhanam, S. Shaikh, A survey of natural language generation techniques with a focus on dialogue systems-past, present and future directions. arXiv preprint arXiv: 1906.0 050 0 . 2019 Jun 2. [94] J. Gao, M. Galley, L. Li, Neural approaches to conversational AI, in: The 41st International ACM SIGIR Conference on Research & Development in Informa- tion Retrieval, 2018 Jun 27, pp. 1371–1374 . [95] H. Chen, X. Liu, D. Yin, J. Tang, A survey on dialogue systems: recent advances and new frontiers, ACM Sigkdd Expl. Newslett. 19 (2) (2017 Nov 21) 25–35 . [96] J. Li, A. Sun, J. Han, C. Li, A survey on deep learning for named entity recog- nition, IEEE Trans. Knowl. Data Eng. (2020 Mar 17) . [97] V. Yadav, S. Bethard, A survey on recent advances in named entity recognition from deep learning models. arXiv preprint arXiv: 1910.11470 . 2019 Oct 25. [98] L. Zhang, S. Wang, B. Liu, Deep learning for sentiment analysis: a survey, Wi- ley Interdis. Rev. 8 (4) (2018 Jul) e1253 . [116] D. Kwon, H. Kim, J. Kim, S.C. Suh, I. Kim, K.J. Kim, A survey of deep learn- ing-based network anomaly detection, Cluster Comput. (2019 Jan) 1–3 . [117] S. Zhang, L. Yao, A. Sun, Y. Tay, Deep learning based recommender system: a survey and new perspectives, ACM Comput. Surv. (CSUR) 52 (1) (2019 Feb 25) 1–38 . [118] A. Kamilaris, F.X. Prenafeta-Boldú, Deep learning in agriculture: a survey, Comput. Electron. Agricul. 147 (2018 Apr 1) 70–90 . [119] S. Pouyanfar, S. Sadiq, Y. Yan, H. Tian, Y. Tao, M.P. Reyes, M.L. Shyu, S.C. Chen, S.S. Iyengar, A survey on deep learning: algorithms, techniques, and applica- tions, ACM Comput. Surv. (CSUR) 51 (5) (2018 Sep 18) 1–36 . [120] S. Dargan, M. Kumar, M.R. Ayyagari, G. Kumar, A survey of deep learning and its applications: a new paradigm to machine learning, Arch. Comput. Methods Eng. (2019 Jun 1) 1–22 . [121] M. Raghu, E. Schmidt, A survey of deep learning for scientific discovery. arXiv preprint arXiv: 2003.11755 . 2020 Mar 26. [122] J. Wallner, M. Schwaiger, K. Hochegger, C. Gsaxner, W. Zemann, J. Egger, A review on multiplatform evaluations of semi-automatic open-source based image segmentation for cranio-maxillofacial surgery, Comput. Methods Pro- grams Biomed. 182 (2019 Dec 1) 105102 . [123] J. Wallner, I. Mischak, J. Egger, Computed tomography data collection of the complete human mandible and valid clinical ground truth models, Sci. Data 6 (2019 Jan 29) 190 0 03 . [124] C. Gsaxner, A. Pepe, J. Wallner, D. Schmalstieg, J. Egger, Markerless im- age-to-face registration for untethered augmented reality in head and neck surgery, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Cham, Springer, 2019 Oct 13, pp. 236–244 . [125] C. Gsaxner, J. Wallner, X. Chen, W. Zemann, J. Egger, Facial model collection for medical augmented reality in oncologic cranio-maxillofacial surgery, Sci. Data 6 (1) (2019 Dec 9) 1–7 . [126] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghe- mawat, G. Irving, M. Isard, M. Kudlur, Tensorflow: a system for large-scale machine learning, in: 12th {USENIX} Symposium On Operating Systems De- sign And Implementation ({OSDI} 16), 2016, pp. 265–283 . [127] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Des- maison, L. Antiga, A. Lerer, Automatic differentiation in pytorch. [128] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadar- rama, T. Darrell, Caffe: convolutional architecture for fast feature embedding, in: Proceedings of the 22nd ACM International Conference on Multimedia, 2014 Nov 3, pp. 675–678 . 21 J. Egger, C. Gsaxner, A. Pepe et al. Computer Methods and Programs in Biomedicine 221 (2022) 106874 [129] F. Shi, J. Wang, J. Shi, Z. Wu, Q. Wang, Z. Tang, K. He, Y. Shi, D. Shen, Review of artificial intelligence techniques in imaging data acquisition, segmentation and diagnosis for covid-19, IEEE Rev. Biomed. Eng. (2020 Apr 16) . [130] M. Islam, F. Karray, R. Alhajj, J. Zeng, A review on deep learning techniques for the diagnosis of novel coronavirus (covid-19). arXiv preprint arXiv: 2008. 04815 . 2020 Aug 9. [131] A. Shuldiner, in: Raising Them Right: AI and the Internet of Big Things. In Artificial Intelligence For the Internet of Everything, Academic Press, 2019 Jan 1, pp. 139–143 . [132] R. Yu, G.S. Alì, What’s inside the Black Box? AI Challenges for Lawyers and Researchers, Legal Inf. Manage. 19 (1) (2019 Mar) 2–13 . [133] X. Liu, L. Faes, A.U. Kale, S.K. Wagner, D.J. Fu, A. Bruynseels, T. Mahendiran, G. Moraes, M. Shamdas, C. Kern, J.R. Ledsam, A comparison of deep learn- ing performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis, Lancet Digit. Health 1 (6) (2019 Oct 1) e271–e297 . [134] A. Nguyen, J. Yosinski, J. Clune, Deep neural networks are easily fooled: high confidence predictions for unrecognizable images, in: InProceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 427–436 . [135] L.G. McCoy, C.T. Brenna, S.S. Chen, K. Vold, S. Das, Believing in black boxes: machine learning for healthcare does not need explainability to be evi- dence-based, J. Clin. Epidemiol. 142 (2022 Feb 1) 252–257 . [136] N. Rieke, J. Hancox, W. Li, F. Milletari, H.R. Roth, S. Albarqouni, S. Bakas, M.N. Galtier, B.A. Landman, K. Maier-Hein, S. Ourselin, The future of digital health with federated learning, NPJ Digit. Med. 3 (1) (2020 Sep 14) 1–7 . [137] L. Heiliger, A. Sekuboyina, B. Menze, J. Egger, J. Kleesiek, Beyond medical imaging-a review of multimodal deep learning in radiology. [144] L. Maier-Hein, A. Reinke, M. Kozubek, A.L. Martel, T. Arbel, M. Eisenmann, A. Hanbury, P. Jannin, H. Müller, S. Onogur, J. Saez-Rodriguez, BIAS: transpar- ent reporting of biomedical image analysis challenges, Med. Image Anal. 66 (2020 Dec 1) 101796 . [145] C. Nimsky, O. Ganslandt, B. von Keller, J. Romstöck, R. Fahlbusch, Intraopera- tive high-field-strength MR imaging: implementation and experience in 200 patients, Radiology 233 (1) (2004 Oct) 67–78 . [146] J.S. Perlmutter, J.W. Mink, Deep brain stimulation, Annu. Rev. Neurosci. 29 (2006 Jul 21) 229–257 . [147] D. Shen, Public Statement. LinkedIn. 2020 Oct (accessed on 11/24/2020). https://www.linkedin.com/feed/update/urn:li:activity:6719177936513089536/ [148] M. Frid-Adar, E. Klang, M. Amitai, J. Goldberger, H. Greenspan, Synthetic Data Augmentation Using GAN for Improved Liver Lesion Classification, in: 2018 IEEE 15th International Symposium On Biomedical Imaging (ISBI 2018), IEEE, 2018 Apr 4, pp. 289–293 . [149] M. Campbell, A.J. Hoane Jr, F.H Hsu, Deep blue, Artif. Intell. 134 (1–2) (2002 Jan 1) 57–83 . [150] J.X. Chen, The evolution of computing: AlphaGo, Comput. Sci. Eng. 18 (4) (2016 Jul) 4–7 . [151] J. Egger, T. Kapur, A. Fedorov, S. Pieper, J.V. Miller, H. Veeraraghavan, B. Freisleben, A.J. Golby, C. Nimsky, R. Kikinis, GBM volumetry using the 3D Slicer medical image computing platform, Sci. Rep. 3 (1) (2013 Mar 4) 1–7 . [152] S. Johar, Emotion, Affect and Personality in Speech: The Bias of Language and Paralanguage, Springer, 2015 Dec 22 . [153] M.Y. Arafat, A.S. Khairuddin, U. Khairuddin, R. Paramesran, Systematic review on vehicular licence plate recognition framework in intelligent transport sys- tems, IET Intell. Transp. Syst. 13 (5) (2019 Jan 2) 745–755 . [154] V. C ¯ın ̲ iv ¯aca Cakkaravartti, Demystifying the Brain: A Computational Approach, [138] M. Kass, A. Witkin, D. Terzopoulos, Snakes: active contour models, Int. J. Com- Springer, 2019 . put. Vis. 1 (4) (1988 Jan 1) 321–331 . [139] Y. Boykov, O. Veksler, R. Zabih, Fast approximate energy minimization via graph cuts, IEEE Trans. Pattern Anal. Mach. Intell. 23 (11) (2001 Nov) 1222–1239 . [140] Q.V. Le, Building high-level features using large scale unsupervised learning, in: 2013 IEEE International Conference On Acoustics, Speech and Signal Pro- cessing, IEEE, 2013 May 26, pp. 8595–8598 . [141] L. Maier-Hein, M. Eisenmann, A. Reinke, S. Onogur, M. Stankovic, P. Scholz, T. Arbel, H. Bogunovic, A.P. Bradley, A. Carass, C. Feldmann, Why rankings of biomedical image analysis competitions should be interpreted with care, Nat. Commun. 9 (1) (2018 Dec 6) 1–3 . [142] J. Li, J. Egger, in: Towards the Automatization of Cranial Implant Design in Cranioplasty. First Challenge, AutoImplant 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 8, 2020, Proceedings, Springer Nature, 2020 . [143] B.H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J. Kirby, Y. Bur- ren, N. Porz, J. Slotboom, R. Wiest, L. Lanczi, The multimodal brain tumor image segmentation benchmark (BRATS), IEEE Trans. Med. Imaging 34 (10) (2014 Dec 4) 1993–2024 . [155] V. Buhrmester, D. Münch, M. Arens, Analysis of explainers of black box deep neural networks for computer vision: a survey. arXiv preprint arXiv: 1911. 12116 . 2019 Nov 27. [156] J.S. Hartford, J.R. Wright, K. Leyton-Brown, Deep learning for predicting hu- man strategic behavior. In Advances in Neural Information Processing Systems 2016 (pp. 2424–2432). [157] S. Saeb, L. Lonini, A. Jayaraman, D.C. Mohr, K.P. Kording, Voodoo machine learning for clinical predictions, bioRxiv (2016 Jan 1) 059774 . [158] J. Fragemann, L. Ardizzone, J. Egger, J. Kleesiek, Review of Disentanglement Approaches for Medical Applications–Towards Solving the Gordian Knot of Generative Models in Healthcare. arXiv preprint arXiv: 2203.11132 . 2022 Mar 21. [159] J. Egger, D. Wild, M. Weber, C.A. Bedoya, F. Karner, A. Prutsch, M. Schmied, C. Dionysio, D. Krobath, Y. Jin, C. Gsaxner, Studierfenster: an open science cloud-based medical imaging analysis platform, J. Digit. Imaging (2022 Jan 21) 1–6 . 22 