Artificial Intelligence 124 (2000) 243–282A comparison of structural CSP decompositionmethods IGeorg Gottlob a, Nicola Leone b, Francesco Scarcello c;(cid:3)a Institut für Informationssysteme, Technische Universität Wien, A-1040 Vienna, Austriab Department of Mathematics, University of Calabria, I-87036 Rende (CS), Italyc Dipartimento di Elettronica, Informatica e Sistemistica, University of Calabria, I-87036 Rende (CS), ItalyReceived 25 May 2000AbstractWe compare tractable classes of constraint satisfaction problems (CSPs). We first give a uniformpresentation of the major structural CSP decomposition methods. We then introduce a new class oftractable CSPs based on the concept of hypertree decomposition recently developed in DatabaseTheory, and analyze the cost of solving CSPs having bounded hypertree-width. We provide aframework for comparing parametric decomposition-based methods according to tractability criteriaand compare the most relevant methods. We show that the method of hypertree decompositiondominates the others in the case of general CSPs (i.e., CSPs of unbounded arity). We alsomake comparisons for the restricted case of binary CSPs. Finally, we consider the application ofdecomposition methods to the dual graph of a hypergraph. In fact, this technique is often used toexploit binary decomposition methods for nonbinary CSPs. However, even in this case, the hypertree-decomposition method turns out to be the most general method. (cid:211)2000 Elsevier Science B.V. Allrights reserved.Keywords: Constraint satisfaction; Decomposition methods; Hypergraphs; Tractable cases; Degree of cyclicity;Treewidth; Hypertree width; Tree-clustering; Cycle cutsets; Biconnected componentsI Part of this work has been published in preliminary form in the Proceedings of the Sixteenth InternationalJoint Conference on Artificial Intelligence (IJCAI-99), Stockholm, Sweden, 1999.* Corresponding author.E-mail addresses: gottlob@dbai.tuwien.ac.at (G. Gottlob), leone@unical.at (N. Leone),scarcello@deis.unical.it (F. Scarcello).0004-3702/00/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 0 0 ) 0 0 0 7 8 - 32000 Elsevier Science B.V. All rights reserved.244G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–2821. Introduction and summary of resultsThe efficient solution of Constraint Satisfaction Problems (CSPs) has been for manyyears an important goal of AI research. Constraint satisfaction is a central issue ofproblem solving and has an impressive spectrum of applications [23]. A constraint.Si; Ri / consists of a constraint scope Si , i.e., a list of variables and an associatedconstraint relation ri containing the legal combinations of values. A CSP consists of a setf.S1; r1/; .S2; r2/; : : : ; .Sq ; rq /g of constraints whose variables may overlap (for a precisedefinition, see Section 2). A solution to a CSP consists a of an assignment of values toall variables such that all constraints are simultaneously satisfied. By solving a CSP wemean determining whether the problem has a solution at all (i.e., checking for constraintsatisfiability), and, if so, compute one solution.Constraint satisfiability is equivalent to various database problems [4,7,18,21], e.g.,to the problem of conjunctive query containment [21], or to the problem of evaluatingBoolean conjunctive queries over a relational database [22] (for a discussion of this andother equivalent problems, see [15]). Actually, evaluating Boolean conjunctive queries,and deciding constraint satisfaction can be also recast as the same fundamental algebraicproblem of deciding whether, given two finite relational structures A and B, there exists ahomomorphism f : A ! B [21].Constraint satisfiability in its general form is well known to be NP-hard. Much efforthas been spent by both the AI and database communities to identify tractable classesof CSPs. Both communities have obtained deep and useful results in this direction. Thevarious successful approaches to obtain tractable CSP classes can be divided into two maingroups [23]:(cid:15) Tractability due to restricted structure. This includes all tractable classes ofCSPs that are identified solely on the base of the structure of the constraint scopesfS1; : : : ; Sq g, independently of the actual constraint relations r1; : : : ; rq .(cid:15) Tractability due to restricted constraint relations. This includes all classes that aretractable due to particular properties of the constraint relations r1; : : : ; rq .This paper deals with tractability due to restricted structure. There are several papersproposing polynomially tractable classes of constraints based on different structuralproperties of the constraint scopes. Usually, these properties can be formalized as graph-theoretic properties of the constraint graph in case of binary constraints, or of theconstraint hypergraph in the general case. The constraint hypergraph of a CSP is thehypergraph whose vertices are the variables of the CSP and whose hyperedges are thesets of all those variables which occur together in a constraint scope.It is well known that CSPs with acyclic constraint hypergraphs are polynomiallysolvable [7]. The known structural properties that lead to tractable CSP classes are all(explicitly or implicitly) based on some generalization of acyclicity. In particular, eachmethod defines some concept of width which can be interpreted as a measure of cyclicity ofthe underlying constraint (hyper)graph such that, for each fixed width k, all CSPs of widthbounded by k are solvable in polynomial time. There is a plethora of proposed methodsG. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282245based on various different measures of cyclicity, but little was known so far on the relativestrength of the different methods. A comparison of the main methods is called for.In this paper we establish a framework for uniformly defining and comparing structuralCSP decomposition methods. Within this framework we compare the main methods thathave been published so far. In particular, we deal with the following methods (which arereviewed in detail in Section 4): Cycle Cutset [7], Tree Clustering [9], Treewidth [24],Hinge Decomposition [18,19], Hinge Decomposition with Tree Clustering [18], CycleHypercutset, and Hypertree Decomposition [16].We first point out that every considered CSP-decomposition method D gives rise to aninfinite hierarchy of CSP classes:C.D; 1/ (cid:26) C.D; 2/ (cid:26) (cid:1) (cid:1) (cid:1) (cid:26) C.D; i/; (cid:1) (cid:1) (cid:1)such that the CSPs of each class C.D; k/ are solvable in time bounded by a polynomial.In particular, for each CSP C belonging to class C.D; k/ there exists a decomposition ofwidth 6 k, i.e., a data structure witnessing that C can be transformed in polynomial timeinto an equivalent acyclic CSP.For each CSP-decomposition method D, the class C.D; k/ is a tractable class of CSPsbecause the following important tasks are tractable:(1) Checking membership of a CSP C in C.D; k/, and computing a corresponding CSPdecomposition for C.(2) Solving the CSP C. In turn, this task usually consists of the following two subtasks:(cid:15) Transforming C in polynomial time into an equivalent acyclic CSP C0, and(cid:15) solving C0 in polynomial time by using well-known algorithms.In this paper we compare only those methods that are tractable in the above sense. In fact,there are methods for solving CSPs, reported in the literature, for which only one of thetwo tasks (1) and (2) above is tractable, while the other one is NP-hard. For instance, task(1) is NP-complete for the method of bounded query decompositions defined by Chekuriand Rajaraman [6] (see [16] for an NP-completeness proof), while task (2) is intractablefor an early method proposed by Freuder [10,11] (see Section 4 for an NP-completenessproof).For a pair of decomposition methods D1 and D2, we define the following comparisoncriteria:(cid:15) Generalization. D2 generalizes D1 if there exists a constant (cid:14) such that, for each levelk, C.D1; k/ (cid:18) C.D2; k C (cid:14)/ holds. In practical terms, this means that whenever a classC of constraints is tractable according to method D1, it is also tractable accordingto D2. Moreover, the worst case runtime upper bound guaranteed by method D2 ispolynomially bounded by the worst case upper bound guaranteed by method D1;more precisely, the overhead of D2 with respect to D1 is at most n(cid:14), where n is thesize of the input CSP. Note that for all pairs of methods compared in this paper, (cid:14)is at most 1. This means that there is no significant loss of efficiency when replacingmethod D1 with the more general method D2.(cid:15) Beating. D2 beats D1 if there exists an integer k such that C.D2; k/ is not containedin class C.D1; m/ for any m. Intuitively, this means that some classes of problems are246G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282tractable according to D2 but not according to D1. For such classes, using D2 is thusbetter than using D1.(cid:15) Strong generalization. D2 strongly generalizes D1 if D2 generalizes D1 and D2beats D1. This means that D2 is really the more powerful method, given that,whenever D1 guarantees polynomial runtime for constraint solving, then also D2guarantees tractable constraint solving, but there are classes of constraints that canbe solved in polynomial time by using D2 but are not tractable according to D1.(cid:15) Equivalence. D1 and D2 are equivalent if D1 generalizes D2 and D2 generalizes D1.Intuitively, this means that the methods are polynomial on the same classes of CSPsand do not differ significantly from each other.In this paper we completely classify all above-mentioned decomposition methodsaccording to these criteria. The result of the classification is given in Fig. 1. This figure,in addition mentions another method (!(cid:3)) which is known to be equivalent to the tree-clustering method [9].An arrow from a method D1 to a method D2 in Fig. 1 indicates that D2 is strongly moregeneral than D1. Since this relationship is transitive, also a directed path between twomethods indicates the same relationship. The picture is complete in the sense that there isa directed path from method D1 to method D2 if and only if D2 strongly generalizes D1.On the other hand, whenever two methods are not related by a directed path, then they areincomparable with respect to the generalization relation, and, moreover, each of the twomethods beats the other.Fig. 1 shows that the method of Hypertree Decompositions dominates all other methods,as it is strongly more general than the other decomposition methods. This methodwas originally introduced in the database field for identifying a large class of tractableconjunctive queries [16]. In this paper we adapt this notion to the setting of constraints andwe show that constraints of bounded hypertree-width are polynomially solvable, providingFig. 1. Constraint tractability hierarchy.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282247a precise complexity analysis. In particular, we show that CSPs of hypertree width k canbe solved in time O.nkC1 (cid:2) log n/.Hypertree width is a measure of cyclicity specifically designed for hypergraphs. It isinteresting to see how the situation changes in the special case of graphs, i.e., of binaryCSPs. To answer this question, we have compared all considered method in the binary case(in Section 8; see Fig. 25). Again, it turns out that the method of Hypertree Decompositiondominates the others, but this time in a slightly weaker sense to be explained in Section 8.It was recently asked 1 whether the method of Hypertree Decompositions can beexplained in terms of simpler and well-known graph cyclicity measures. To everyhypergraph H one defines the dual graph of H by taking as vertices the hyperedges of Hand by connecting two vertices by an edge if their corresponding hyperedges intersect. Thequestion arose whether the hypertree width of a hypergraph coincides with the treewidthor TCLUSTER width of the dual graph of H (See Section 9 for definitions). We study thisinteresting question in Section 9 and give a negative answer. More generally, we show thatthe method of hypertree decompositions strongly generalizes all relevant binary methodsbased on the dual graph of a given hypergraph.This paper is organized as follows. Section 2 contains preliminaries on CSPs. InSection 3 we discuss tractability of CSPs due to restricted structure. In Section 4 we reviewwell-known CSP decomposition methods. In Section 5 we describe the new method ofhypertree decompositions and analyze the cost of solving CSPs having bounded hypertree-width. In Section 6 we explain our comparison criteria and in Section 7 we present thecomparison results for general CSPs. The case of binary CSPs is briefly discussed inSection 8. In Section 9 we consider the application of “binary” methods to the dual graphof a hypergraph. Finally, in Section 10, we draw our conclusions.2. Constraint satisfaction problemsAn instance of a constraint satisfaction problem (CSP) (also constraint network) is atriple I D .Var; U; C/, where Var is a finite set of variables, U is a finite domain of values,and C D fC1; C2; : : : ; Cq g is a finite set of constraints. Each constraint Ci is a pair .Si ; ri /,where Si is a list of variables of length mi called the constraint scope, and ri is an mi -ary relation over U , called the constraint relation. (The tuples of ri indicate the allowedcombinations of simultaneous values for the variables Si ). A solution to a CSP instanceis a substitution # : Var ! U , such that for each 1 6 i 6 q, Si # 2 ri . The problem ofdeciding whether a CSP instance has any solution is called constraint satisfiability (CS).(This definition is taken almost verbatim from [20].)Many well-known problems in Computer Science and Mathematics can be formulatedas CSPs.Example 1. The famous graph three-colorability (3COL) problem, i.e., deciding whetherthe vertices of a graph G D .Vertices; Edges/ can be colored by three colors (say: red,green, blue) such that no edge links two vertices having the same color, is formulated as1 Rina Dechter, personal communication at IJCAI-99.248G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282Fig. 2. The graph G1.Fig. 3. A crossword puzzle.follows as a CSP. The set Var contains a variable Xv for each vertex v 2 Vertices. Foreach edge e D fv; wg 2 Edges, where v < w according to some ordering on Vertices, theset C contains a constraint Ce D .Se; re/, where Se D .Xv; Xw/ and re is the relation r6Dconsisting of all pairs of different colors, i.e., r6D D fhred; greeni, hred; bluei, hgreen; redi,hgreen; bluei, hblue; redi, hblue; greenig.For instance, the set of constraints for the graph G1 in Fig. 2 is the following C Df..A; B/; r6D/, ..A; D/; r6D/, ..A; G/; r6D/, ..B; C/; r6D/, : : : , ..G; H /; r6D/g.Example 2. Fig. 3 shows a combinatorial crossword puzzle, which is a typical CSP [7,23]. A set of legal words is associated to each horizontal or vertical array of white boxesdelimited by black boxes. A solution to the puzzle is an assignment of a letter to each whitebox such that to each white array is assigned a word from its set of legal words.This problem is represented as follows. There is a variable Xifor each whitebox, and a constraint C for each array D of white boxes. (For simplicity, we justwrite the index i for variable Xi .) The scope of C is the list of variables corre-sponding to the white boxes of the sequence D; the relation of C contains the legalwords for D. For the example in Fig. 3, we have C1H D ..1; 2; 3; 4; 5/; r1H /, C8H D..8; 9; 10/; r8H /, C11H D ..11; 12; 13/; r11H /, C20H D ..20; 21; 22; 23; 24; 25; 26/; r20H/,C1V D ..1; 7; 11; 16; 20/; r1V /, C5V D ..5; 8; 14; 18; 24/; r5V /, C6V D ..6; 10; 15; 19; 26/;r6V /, C13V D ..13; 17; 22/; r13V /. Subscripts H and V stand for “Horizontal” and “Ver-tical”, respectively, resembling the usual naming of definitions in the crossword puzzles.A possible instance for the relation r1H is fhh; o; u; s; ei; hc; o; i; n; si; hb; l; o; c; kig.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282249It is well-known and easy to see that Constraint Satisfiability is an NP-complete problem.Membership in NP is obvious. NP-hardness follows, e.g., immediately from the NPhardness of 3COL [13].3. Tractable classes of CSPsMuch effort has been spent by both the AI and database communities to indentifytractable classes of CSPs. Both communities have obtained deep and useful results inthis direction. The various successful approaches to obtain tractable CSP classes can bedivided into two main groups [23]:(1) Tractability due to restricted structure. This includes all tractable classes of CSPsthat are identified solely on the base of the structure of the constraint scopesfS1; : : : ; Sq g, independently of the actual constraint relations r1; : : : ; rq .(2) Tractability due to restricted constraints. This includes all classes that are tractabledue to particular properties of the constraint relations r1; : : : ; rq .The present paper deals with tractability due to restricted structure.The structure of a CSP is best represented by its associated hypergraph and by thecorresponding primal graph, defined as follows. To any CSP instance I D .Var; U; C/, weassociate a hypergraph HI D .V ; H /, where V D Var, and H D fvar.S/ j C D .S; r/ 2 Cg,where var.S/ denotes the set of variables in the scope S of the constraint C. Fig. 4 showsthe hypergraph Hcp associated to the crossword puzzle of Example 2.Since in this paper we always deal with hypergraphs corresponding to CSPs instances,the vertices of any hypergraph H D .V ; H / can be viewed as the variables of someconstraint satisfaction problem. Thus, we will often use the term variable as a synonymfor vertex, when referring to elements of V . Moreover, for the hypergraph H D .V ; H /,var.H/ and edges.H/ denote the sets V and H , respectively.Let HI D .V ; H / be the constraint hypergraph of a CSP instance I . The primal graphof I is a graph G D .V ; E/, having the same set of variables (vertices) as HI and an edgeconnecting any pair of variables X; Y 2 V such that fX; Y g (cid:18) h for some h 2 H .Fig. 4. Hypergraph Hcp of the crossword puzzle in Example 2.250G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282Note that if all constraints of a CSP are binary, then its associated hypergraph is identicalto its primal graph.The most basic and most fundamental structural property considered in the context ofCSPs (and conjunctive database queries) is acyclicity. It was recognized independently inAI and in database theory that acyclic CSPs are polynomially solvable. A CSP I is acyclicif its primal graph G is chordal (i.e., any cycle of length greater than 3 has a chord) and theset of its maximal cliques coincide with edges.HI / [2].A join tree JT .H/ for a hypergraph H is a tree whose vertices are the edges of H suchthat, whenever the same variable X 2 V occurs in two edges A1 and A2 of H, then A1 andA2 are connected in JT .H/, and X occurs in each vertex on the unique path linking A1 andA2 in JT .H/. In other words, the set of vertices in which X occurs induces a (connected)subtree of JT .H/. We will refer to this condition as the Connectedness Condition of jointrees.Acyclic hypergraphs can be characterized in terms of join trees: A hypergraph H isacyclic iff it has a join tree [2,3,22]. There exist various equivalent characterizations ofacyclic hypergraphs [2,14,22]. Checking the satisfiability of acyclic CSPs (or, equivalently,evaluating acyclic conjunctive queries) is not only tractable but also highly parallelizable.In fact, as shown in [15], this problem is complete for the complexity class LOGCFL, avery low class contained in the parallel classes AC1 and NC2.Many CSPs arising in practice are not acyclic but are in some sense or another closeto acyclic CSPs. In fact, the hypergraphs associated with many naturally arising CSPscontain either few cycles or small cycles, or can be transformed to acyclic CSPs by simpleoperations (such as, e.g., lumping together small groups of vertices). Consequently, CSPresearch in AI and in database theory concentrated on identifying, defining, and studyingsuitable classes of nearly acyclic CSPs, or, equivalently, decomposition methods, i.e.,techniques for decomposing cyclic CSPs into acyclic CSPs [7,23].4. Decomposition methodsIn order to study and compare various decomposition methods, we find it useful toSintroduce a general formal framework for this notion.Let H be a hypergraph. For any set of edges H 0 (cid:18) edges.H/, let var.H 0/ Dh2H 0 h.Without loss of generality, we assume that var.H / D var.H/, i.e., every variable invar.H/ occurs in at least one edge of H, and hence, any hypergraph can be simplyrepresented by the set of its edges. Moreover, we assume without loss of generality thatall hypergraphs under consideration are both connected, i.e., their primal graph consists ofa single connected component, and reduced, i.e., no hyperedge is contained in any otherhyperedge. All our definitions and results easily extend to general hypergraphs.Let HS be the set of all (reduced and connected) hypergraphs. A decomposition method(short: DM) D associates to any hypergraph H 2 HS a parameter D-width(H), called theD width of H.The decomposition method D ensures that, for fixed k, every CSP instance I whosehypergraph HI has D-width 6 k is polynomially solvable, i.e., it is solvable in p.kI k/ DO.kI kO.1// time, where kI k denotes the size of I . For any CSP instance I , the size of I isG. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282251defined in the standard way, i.e., as the number of bits needed for encoding I by listing, foreach constraint in I , its constraint scope and all tuples occurring in its constraint relation.For any k > 0, the k-tractable class C.D; k/ of D is defined byC.D; k/ D fH j D-width.H/ 6 kg:Thus, C.D; k/ collects the set of CSP instances which, for fixed k, are polynomiallysolvable by using the strategy D. Typically, the polynomial p.kI k/ depends on theparameter k. In particular, for each D, there exists a function f such that, for each k,each instance I 2 C.D; k/ can be transformed in time O.kI kO.f .k/// into an equivalentacyclic CSP instance. (It follows that all problems in C.D; k/ are polynomially solvable.)k>1 C.D; k/. Note that, byEvery DM D is complete with respect to HS, i.e., HS DSour definitions, it holds that D-width.H/ D minfk j H 2 C.D; k/g.All tractable classes based on restricted structure that we have studied in the literaturefit into this framework. We next describe how the notion of width is defined in thedecomposition methods we shall compare in this paper. Detailed descriptions of thesemethods can be found in the corresponding reference (see below) and in many surveyson this subject, e.g., [7,23].4.1. Biconnected components (short: BICOMP) [11]Let G D .V ; E/ be a graph. A vertex p 2 V is a separating vertex for G if, by removingp from G, the number of connected components of G increases. A biconnected componentof G is a maximal set of vertices C (cid:18) V such that the subgraph of G induced by C isconnected and remains connected after any one-vertex removal, i.e., has no separatingvertices.It is well known that, from any graph G, we can compute in linear time a vertex-labeledtree hT ; (cid:31)i, where the labeling function (cid:31) is a bijective function that associates to eachvertex of the tree T a set of vertices S of G, such that S is either a biconnected componentof G, or a singleton containing a separating vertex for G. There is an edge fp; qg in thetree T , if (cid:31).p/ is a biconnected component of G and (cid:31).q/ contains a separating vertex forG belonging to the component (cid:31).p/, i.e., (cid:31).q/ (cid:18) (cid:31).p/, holds. We say that hT ; (cid:31)i is theBICOMP decomposition of G.For a hypergraph H, the BICOMP decomposition of H is the BICOMP decompositionof its primal graph, and the biconnected width of H, denoted by BICOMP-width.H/, is themaximum number of vertices over the biconnected components of the primal graph of H.Example 3. Fig. 5(a) shows a hypergraph Hb and Fig. 5(b) its primal graph. The verticesG; C; D, and E are the separating vertices of this primal graph. Note that the maximumnumber of vertices over its biconnected components is 3, and thus BICOMP-width.H/ D 3.Fig. 6 shows the BICOMP decomposition of Hb.4.2. Tree clustering (short: TCLUSTER) [9]The tree clustering method is based on a triangulation algorithm which transforms theprimal graph G D .V ; E/ of any CSP instance I into a chordal graph G0. The acyclic252G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282Fig. 5. (a) The hypergraph Hb, and (b) its primal graph.Fig. 6. The BICOMP decomposition of the hypergraph Hb in Example 3.hypergraph H.G0/ having the same set of vertices as G0 and the maximal cliques of G0as its hyperedges is a TCLUSTER decomposition of HI . Intuitively, the hyperedges ofH.G0/ are used to build the constraints of an acyclic CSP I 0 equivalent to I . The width ofthe TCLUSTER decomposition H.G0/ is the maximum cardinality of its hyperedges. Thetree-clustering width (short: TCLUSTER width) of HI is 1 if HI is an acyclic hypergraph;otherwise, it is equal to the minimum width over the TCLUSTER decompositions of HI .Example 4. Consider the hypergraph Ht c shown in Fig. 7(a). Fig. 7(b) shows its primalgraph.This graph can be triangulated as shown in Fig. 8(a). If we associate a hyperedge toeach maximal clique of this triangulated graph, we get the acyclic hypergraph shown inFig. 8(b). This acyclic hypergraph is a TCLUSTER decomposition of Ht c of width 3.Moreover, it is easy to see that there is no TCLUSTER decomposition for Ht c having asmaller width, and hence the TCLUSTER width of Ht c is 3.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282253Fig. 7. (a) The hypergraph Htc, and (b) its primal graph.Fig. 8. (a) A triangulation of the primal graph of Htc, and (b) a TCLUSTER decomposition of Htc.4.3. Treewidth (TREEWIDTH) [24]A tree decomposition of a graph G D .V ; E/ is a pair hT ; (cid:31)i, where T D .N; F / is a tree,and (cid:31) is a labeling function associating to each vertex p 2 N a set of vertices (cid:31).p/ (cid:18) V ,such that the following conditions are satisfied:(1) for each vertex b of G, there exists p 2 N such that b 2 (cid:31).p/;(2) for each edge fb; dg 2 E, there exists p 2 N such that fb; dg (cid:18) (cid:31).p/;(3) for each vertex b of G, the set fp 2 N j b 2 (cid:31).p/g induces a (connected) subtreeof T .The width of the tree decomposition hT ; (cid:31)i is maxp2N j(cid:31).p/ (cid:0) 1j. The treewidth of Gis the minimum width over all its tree decompositions. The TREEWIDTH of a hypergraphH is 1 if H is an acyclic hypergraph; otherwise, it is equal to the treewidth of its primalgraph. As pointed out below, TREEWIDTH and TCLUSTER are two equivalent methods.Example 5. Consider again the hypergraph Ht c in Example 4. Fig. 9 show a treedecomposition of Ht c having width 2. It follows that the treewidth of Ht c is 2 as onlyhypergraphs having acyclic primal graphs have treewidth 1.254G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282Fig. 9. A tree decomposition of hypergraph Htc in Example 4.4.4. Hinge decompositions (short: HINGE) [18,19]Let H be a hypergraph, H (cid:18) edges.H/, and F (cid:18) edges.H/ (cid:0) H . Then F is calledconnected with respect to H if, for any two edges e; f 2 F , there exists a sequencee1; : : : ; en of edges in F such that(i) e1 D e;(ii) for i D 1; : : : ; n (cid:0) 1, ei \ eiC1 is not contained in(iii) en D f .Sh2H h; andThe maximal connected subsets of edges.H/ (cid:0) H with respect to H are called theconnected components of H with respect to H . It is easy to see that the connectedcomponents of H with respect to H form a partition of edges.H/ (cid:0) H .Let H 2 HS and let H be either edges.H/ or a proper subset of edges.H/ containingat least two edges. Let C1; : : : ; Cm be the connected components of H with respectto H . Then, H is a hinge if, for i D 1; : : : ; m, there exists an edge hi 2 H such thatvar.edges.Ci // \ var.H // (cid:18) hi . A hinge is minimal if it does not contain any other hinge.A hinge decomposition of H is a tree T such that all the following conditions hold:(1) the vertices of T are minimal hinges of H;(2) each edge in edges.H/ is contained in at least one vertex of T ;(3) two adjacent vertices A and B of T share precisely one edge L 2 edges.H/;moreover, L consists exactly of the variables shared by A and B (i.e., L D var.A/ \var.B/);(4) the variables of H shared by two vertices of T are entirely contained within eachvertex on their connecting path in T .It was shown in [19] that, for any CSP instance I , the cardinality of the largest vertex ofany hinge decomposition of HI is an invariant of HI , and is equal to the cardinality of thelargest minimal hinge of HI . This number is called the degree of cyclicity of HI . We willalso refer to it as the HINGE width of HI .Example 6. Consider a CSP instance Ihg having the following constraint scopes:s1.X1; X10; X11/I s2.X1; X2; X3/I s3.X1; X4/I s4.X3; X6/I s5.X4; X5; X6/Is6.X4; X7/I s7.X5; X8/I s8.X6; X9/I s9.X2; X3; X10; X11/:Fig. 10 shows the corresponding hypergraph Hhg, which is clearly cyclic. The minimalhinges of Hhg are H1 D fs1; s2; s9g, H2 D fs2; s3; s4; s5g, H3 D fs5; s6g, H4 D fs5; s7g,G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282255Fig. 10. (a) Hypergraph Hhg , and (b) a hinge-tree decomposition of Hhg .H5 D fs5; s8g, H6 D fs3; s6g, and H7 D fs4; s8g, where si denotes the set of variablesoccurring in the scope si , for 1 6 i 6 9.Since the cardinality of the largest minimal hinge of Hhg (hinge H2) is 4, it follows thatthe HINGE width of Hhg is 4. Fig. 10(b) shows a HINGE decomposition of Hhg.4.5. Hinge decomposition C tree clustering (short: HINGETCLUSTER) [18]It has been observed [18] that the minimal hinges of a hypergraph can be furtherdecomposed by means of the triangulation technique of the above-described tree-clusteringmethod. This leads to a new decomposition method, that we call HINGETCLUSTER, whichcombines HINGE and TCLUSTER and can be formally defined as follows. Let T D .N; E/be a hinge tree of a hypergraph H. For any hinge H 2 N , let w.H / be the minimumof the cardinality of H and the TCLUSTER width of the hypergraph .var.H /; H /. TheHINGETCLUSTER width of H with respect to T is maxH 2N fw.H /g. A HINGETCLUSTERdecomposition of H with respect to T is an acyclic hypergraph H0 having the same setof vertices as H, and whose set of edges is obtained from T and H as follows. For eachhinge H 2 N , if w.H / D jH j, then H0 contains an edge var.H /; otherwise, H0 containsthe edges of any TCLUSTER decomposition of the (sub)hypergraph .var.H /; H / havingwidth w.H /.The HINGETCLUSTER width of H is the minimum HINGETCLUSTER width over all itsHINGETCLUSTER decompositions.Example 7. Consider again the constraint scopes of Example 6 and the hinge-treedecomposition for the hypergraph Hhg shown in Fig. 10(b). From this hinge-treedecomposition, we construct a HINGETCLUSTER decomposition H0hg of Hhg.Consider the sub-hypergraph .var.H1/; H1/ corresponding to the minimal hingeH1 occurring in this hinge-tree decomposition. The primal graph of the hypergraph.var.H1/; H1/ is a clique containing the vertices X1; X2; X3; X10, and X11, thus it iseasy to see that the TCLUSTER width of this hypergraph is 5. However, the hinge H1contains three edges, hence we get w.H1/ D 3, and the HINGETCLUSTER decompositionH0hg contains the edge fX1; X2; X3; X10; X11g with all the variables occurring in H1.A different situation concerns the sub-hypergraph .var.H2/; H2/ corresponding to theminimal hinge H2. This hypergraph is identical to hypergraph Ht c in Example 4. We256G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282Fig. 11. A HINGETCLUSTER decomposition of hypergraph Hhg in Example 6.observed that Ht c has TCLUSTER width 3, which is smaller than jH2j D 4, and hencew.H2/ D 3 holds. This means that, in this case, it is convenient to further decompose.var.H2/; H2/ using the TCLUSTER decomposition method, and the HINGETCLUSTERdecomposition H0hg contains all the edges belonging to the TCLUSTER decompositionof Ht c D .var.H2/; H2/ shown in Fig. 7.Similarly, for i 2 f4; 5; 6g, the sub-hypergraphs .var.Hi/; Hi/ corresponding to theother hinges occurring in the hinge-tree decomposition at hand are acyclic hypergraphs.Therefore, w.Hi / D 1 holds, because the TCLUSTER width of acyclic hypergraphs is 1.The resulting HINGETCLUSTER decomposition H0hg of Hhg is the acyclic hypergraphshown in Fig. 11. The thickest edges in this figure come from the TCLUSTER decompo-sition of .var.H2/; H2/. Recall that both w.H1/ and w.H2/ are 3, which is the maximumvalue over the hinges occurring in the given HINGE decomposition of Hhg. Thus, the widthof H0hg is 3, and it is easy to verify that there is no other HINGETCLUSTER decompositionhaving smaller width. It follows that the HINGETCLUSTER width of Hhg is 3.4.6. Cycle cutset (short: CUTSET) [7]A cycle cutset of a hypergraph H is a set S (cid:18) var.H/ such that the subgraph of theprimal graph of H (vertex-)induced by var.H/ (cid:0) S is acyclic. That is, after deleting thevertices in S, the primal graph of H becomes acyclic. The CUTSET width of H is 1 if His acyclic; otherwise, it is the minimum cardinality over all its possible cycle cutsets.Example 8. The hypergraph Hb shown in Fig. 5(a) has CUTSET width 4. Indeed,fG; C; D; Eg is a cycle cutset of this hypergraph, and any smaller set of vertices doesnot allow to break all the cycles in its primal graph (see Fig. 5(b)). As another example,consider the hypergraph Ht c shown in Fig. 7. The CUTSET width of Ht c is 2, becausethere is no cycle cutset of cardinality 1, while there are cycle cutsets of cardinality 2, e.g.,the set fX1; X4g.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–2822574.7. Cycle hypercutset (short: HYPERCUTSET)This is a simple modification of the CUTSET method where the cutset is composedof (hyper)edges rather than vertices of the given hypergraph. A cycle hypercutset of ahypergraph H is a set bH (cid:18) edges.H/ such that the subhypergraph of H induced byvar.H/ (cid:0) var. bH / is acyclic. The HYPERCUTSET width of H is 1 if H is acyclic;otherwise, it is the minimum cardinality over all its possible cycle hypercutsets.Example 9. The hypergraph Hb shown in Fig. 5(a) has HYPERCUTSET width 2. Indeed,the set containing the two edges fF; G; Cg and fC; D; Eg is a hypercutset of thishypergraph, as deleting these edges it becomes acyclic. Moreover, by deleting any singleedge, we cannot achieve acyclicity. Instead, the hypergraph Hhg shown in Fig. 10 hasHYPERCUTSET width 1. Indeed, e.g., by just deleting from Hhg the edge fX4; X5; X6gwe get an acyclic hypergraph.4.8. Solving CSPs using decomposition methodsFor each of the above decomposition methods D, it was shown (or it is easy to see)that, for any fixed k, given a CSP instance I , deciding whether a hypergraph HI has D-width.HI / at most k is feasible in polynomial time and that solving CSPs whose associatedhypergraph is of width at most k can be done in polynomial time. In particular, D consistsof two phases. Given a CSP instance I ,(1) the (k-bounded) D width w of HI along with a corresponding decomposition iscomputed;(2) exploiting this decomposition, I is then solved in time O.nwC1 log n/, where n isthe size of I plus the size of the given decomposition (for most methods this phaseconsists of the solution of an acyclic CSP instance equivalent to I ).Actually, for these methods it is always possible to give the decompositions in suitableforms without redundancies. Thus, the cost above reduces to O.kI kwC1 log kI k/, i.e., itdepends only on the CSP instance, and does not depend on the size of the decomposition.For a detailed analysis, see Section 5, where we study the complexity of evaluatingbounded-width CSPs according to a new decomposition method, based on hypertreedecompositions [16].The cost of the first phase is independent on the constraint relations of I ; in fact, it isO.kHI kc1kCc2 /, where kHI k is the size of the hypergraph HI , and c1, c2 are two constantsrelative to the method D (0 6 c1; c2 6 3 for the methods above). As usual, the size ofhypergraph HI is defined as the number of bits needed for encoding all the edges of HI aslists of variables. Clearly, the size of HI is always smaller than than kI k, because theencoding of I includes the encoding of its constraint relations, too. Observe also thatcomputing the D-width w of a hypergraph in general (i.e., without the constant boundw 6 k) is NP-hard for most methods, while it is feasible in polynomial time for HINGE,and even in linear time for BICOMP.Remark 10. The above complexity bounds, given as functions of the total size of theCSP instance, are appropriate for all considered decomposition methods for general CSP258G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282instances. Of course, if one considers some restricted cases, e.g., CSP instances with a fixedconstant domain size, some finer analysis may be useful. In fact, by exploiting additionalinformation, more accurate complexity bounds may be found in order to choose a methodthat is better tailored for such a special case.4.9. Freuder width and adaptive widthFurther interesting methods, that do not explicitly generalize acyclic hypergraphs, arebased on a different notion of width, that we call Freuder width [10,11]. If < is a totalordering of the vertices of a graph G D .V ; E/, then the <-width of G is defined byw<.G/ D maxv2V jffv; wg 2 E such that w < vgj. The Freuder width of G is the minimumof all <-widths over all possible total orderings < of V . For each fixed constant k, it canbe determined in polynomial time whether a graph is of Freuder width k. The graph G1shown in Fig. 2 has Freuder width 3. This width can be obtained taking the orderingb < d < e < a < g < h < c < f . Freuder observed that many naturally arising CSPshave a very low width [10]. He showed that a CSP of width k whose relations enjoy theproperty of k0-consistency, where k0 > k, can be solved in a backtrack-free manner, andthus in polynomial time [10,11]. Clearly, since the consistency condition on the constraintrelations must be satisfied, we cannot define a purely structural decomposition methodbased on Freuder width. In fact, the following theorem pinpoints that the structural propertyof bounded Freuder width does not make the CSP problem any easier.Theorem 11. Constraint solvability remains NP-complete even if restricted to CSPs whoseprimal graph has Freuder width bounded by 4.Proof. 3COL remains NP-complete even for graphs of degree 4 (cf. [13]). Such graphs,however, have width at most 4. By the encoding of 3COL as a CSP, as given in Section 2,the theorem follows. 2One can try to enforce a suitable level of consistency on the constraint relations of agiven CSP instance. However, the algorithms used to increase the level of consistency inthe data also increase the Freuder width of the instance [8,25]. Of course, one can thinkof devising a more powerful procedure to find an equivalent CSP instance whose Freuderwidth stays below a fixed bound. However, from the above theorem, if P 6D NP, such aprocedure cannot run in polynomial time.Dechter and Pearl subsequently introduced the notion of induced width w(cid:3) [8], whichis—roughly—the smallest Freuder width k of any graph G0 obtained by triangulationmethods from the primal graph G of a CSP such that G0 ensures k C 1-consistency.Graphs having induced width at most k can be also characterized as partial k-trees [12] or,equivalently, as graphs having treewidth at most k [1]. It follows that, for fixed k, checkingwhether w(cid:3) 6 k is feasible in linear time [5]. If w(cid:3) is bounded by a constant, a CSP issolvable in polynomial time. The approach to CSPs based on w(cid:3) is referred to as the w(cid:3)-Tractability method [7]. Note that this method is implicitly based on hypergraph acyclicity,given that the used triangulation methods enforce chordality of the resulting graph G0 andG. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282259thus acyclicity of the corresponding hypergraph. It was noted [7,9] that, for any cyclic CSPinstance I , TCLUSTER width.HI / D w(cid:3).HI / C 1.5. Hypertree decompositions of CSPsA new class of tractable conjunctive database queries, which generalizes the class ofacyclic queries, has recently been identified [16]. This is the class of queries having abounded-width hypertree decomposition [16]. Deciding whether a given query has thisproperty is feasible in polynomial time and even highly parallelizable. In this sectionwe first adapt the notion of hypertree decomposition, previously defined in the databasecontext, to the general framework of hypergraphs. Then, we show how to employthis notion in order to define a new CSP decomposition method we will refer to asHYPERTREE.A hypertree for a hypergraph H is a triple hT ; (cid:31); (cid:21)i, where T D .N; E/ is a rootedtree, and (cid:31) and (cid:21) are labeling functions which associate to each vertex p 2 N two sets(cid:31).p/ (cid:18) var.H/ and (cid:21).p/ (cid:18) edges.H/. If T 0 D .N 0; E0/ is a subtree of T , we define(cid:31).T 0/ Dv2N 0 (cid:31).v/. We denote the set of vertices N of T by vertices.T /, and the root ofT by root.T /. Moreover, for any p 2 N , Tp denotes the subtree of T rooted at p.SDefinition 12. A hypertree decomposition of a hypergraph H is a hypertree HD DhT ; (cid:31); (cid:21)i for H which satisfies all the following conditions:(1) for each edge h 2 edges.H/, there exists p 2 vertices.T / such that var.h/ (cid:18) (cid:31).p/(we say that p covers h);(2) for each variable Y 2 var.H/, the set fp 2 vertices.T / j Y 2 (cid:31).p/g induces a(connected) subtree of T ;(3) for each p 2 vertices.T /, (cid:31).p/ (cid:18) var.(cid:21).p//;(4) for each p 2 vertices.T /, var.(cid:21).p// \ (cid:31).Tp/ (cid:18) (cid:31).p/.Note that the inclusion in condition (4) is actually an equality, because condition (3)implies the reverse inclusion.An edge h 2 edges.H/ is strongly covered in HD if there exists p 2 vertices.T / suchthat var.h/ (cid:18) (cid:31).p/ and h 2 (cid:21).p/. In this case, we say that p strongly covers h.A hypertree decomposition HD of hypergraph H is a complete decomposition of H ifevery edge of H is strongly covered in HD.The width of a hypertree decomposition hT ; (cid:31); (cid:21)i is maxp2vertices.T / j(cid:21).p/j. TheHYPERTREE width hw.H/ of H is the minimum width over all its hypertree decomposi-tions. A c-width hypertree decomposition of H is optimal if c D hw.H/.The acyclic hypergraphs are precisely those hypergraphs having hypertree width one.Indeed, any join tree of an acyclic hypergraph H trivially corresponds to a hypertreedecomposition of H of width one. Furthermore, if a hypergraph H0 has a hypertreedecomposition of width one, then, from this decomposition, we can easily compute a jointree of H0, which is therefore acyclic [16].Remark 13. From any hypertree decomposition HD of H, we can easily compute acomplete hypertree decomposition of H having the same width. For any “missing” edge h,260G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282choose a vertex q of T such that var.h/ (cid:18) (cid:31).q/ (such a vertex must exist by condition (1)),and create a new vertex p as a child of q with (cid:21).p/ D h and (cid:31).p/ D var.h/. Assuming theuse of suitable data structures, this computation can be done in O.kHk(cid:1)kHDk/ time, wherekHDk denotes the size of a hypertree decomposition, i.e., the number of bits needed forencoding HD (that is, for encoding the rooted tree of HD and, for each vertex v of thistree, the labelings (cid:31) and (cid:21) for v, encoded as a list of variables and a list of edge identifiers,respectively).Intuitively, if H is a cyclic hypergraph, the (cid:31) labeling selects the set of variables to befixed in order to split the cycles and achieve acyclicity; (cid:21).p/ “covers” the variables of (cid:31).p/by a set of edges.Example 14. Fig. 12 shows a hypertree decomposition of width 2 of the hypergraph Hcpof the crossword puzzle in Example 2 (see Fig. 4). Each box b in this figure represents avertex v of the hypertree decomposition of Hcp. The two sets depicted in the box b are thelabelings (cid:31).v/ and (cid:21).v/. The hypergraph Hcp is clearly cyclic, therefore hw.Hcp/ > 1 (asonly acyclic hypergraphs have hypertree width 1). Thus, it follows that the HYPERTREEwidth of Hcp is 2.Example 15. Consider the following constraint scopes:j .J; X; Y; X0; Y 0/I a.S; X; X0; C; F /I b.S; Y; Y 0; C0; F 0/Ic.C; C0; Z/I d.X; Z/I e.Y; Z/I f .F; F 0; Z0/I g.X0; Z0/I h.Y 0; Z0/:Let H1 be their corresponding hypergraph. Since H1 is cyclic, hw.H1/ > 1 holds. Fig. 13shows a (complete) hypertree decomposition of H1 having width 2, hence hw.H1/ D 2.In order to help the intuition of what a hypertree decomposition is, we also present analternative representation, called hyperedge representation. (Also, “atom representation”,in the conjunctive-queries framework.) Fig. 14 shows the hyperedge representation ofthe hypertree decomposition HD1 of H1. Each node p in the tree is labeled by a setof hyperedges representing (cid:21).p/; (cid:31).p/ is the set of all variables, distinct from ‘_’,Fig. 12. A hypertree decomposition of width 2 of hypergraph Hcp in Example 2.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282261Fig. 13. A 2-width hypertree decomposition of H1.Fig. 14. Hyperedge representation of hypertree decomposition HD5.appearing in these hyperedges. Thus, the anonymous variable ‘_’ replaces the variablesin var.(cid:21).p// (cid:0) (cid:31).p/.Using this representation, we can easily observe an important feature of hypertreedecompositions. Once an hyperedge has been covered by some vertex of the decompositiontree, any subset of its variables can be used freely in order to decompose the remainingcycles in the hypergraph. For instance, the variables in the hyperedge corresponding toconstraint j in H1 are jointly included only in the root of the decomposition. If we wereforced to take all the variables in every vertex where j occurs, it would not be possibleto find a decomposition of width 2. Indeed, in this case, any choice of two hyperedgesper vertex yields a hypertree which violates the connectedness condition for variables (i.e.,condition (2) of Definition 12).Let k be a fixed positive integer. We say that a CSP instance I has k-boundedHYPERTREE width if hw.HI / 6 k, where HI is the hypergraph associated to I . Fromthe results in [16], it follows that k-bounded hypertree width is efficiently decidable, andthat a hypertree decomposition of width k can be efficiently computed (if any).262G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282Fig. 15. A hypertree decomposition of hypergraph Hhg in Example 6.Example 16. Consider again the CSP instance Ihg in Example 6. Fig. 15 shows thehyperedge representation of a width 2 hypertree decomposition of its hypergraph Hhg. Itfollows that hw.Hhg/ D 2, because Hhg is cyclic. Thus, Ihg has 2-bounded HYPERTREEwidth and, more generally, k-bounded HYPERTREE width for any integer k > 1.Let H be a hypergraph, and let V (cid:18) var.H/ be a set of variables and X; Y 2 var.H/.Then X is TV U-adjacent to Y if there exists an edge h 2 edges.H/ such that fX; Y g (cid:18) h (cid:0) V .A TV U-path (cid:25) from X to Y is a sequence X D X0; : : : ; X‘ D Y of variables such thatXi is TV U-adjacent to XiC1, for each i 2 T0; : : : ; ‘-1U. A set W (cid:18) var.H/ of variables isTV U-connected if, for all X; Y 2 W , there is a TV U-path from X to Y . A TV U-componentis a maximal TV U-connected non-empty set of variables W (cid:18) var.H/ (cid:0) V . For any TV U-component C, let edges.C/ D fh 2 edges.H/ j h \ C 6D ;g.Let HD D hT ; (cid:31); (cid:21)i be a hypertree for H. For any vertex v of T , we will often use vas a synonym of (cid:31).v/. In particular, TvU-component denotes T(cid:31).v/U-component; the termTvU-path is a synonym of T(cid:31).v/U-path; and so on. We introduce a normal form for hypertreedecompositions.Definition 17 [16]. A hypertree decomposition HD D hT ; (cid:31); (cid:21)i of a hypergraph H is innormal form (NF) if, for each vertex r 2 vertices.T /, and for each child s of r, all thefollowing conditions hold:(1) there is (exactly) one TrU-component Cr such that (cid:31).Ts/ D Cr [ .(cid:31).s/ \ (cid:31).r//;(2) (cid:31).s/ \ Cr 6D ;, where Cr is the TrU-component satisfying condition (1);(3) var.(cid:21).s// \ (cid:31).r/ (cid:18) (cid:31).s/.Intuitively, each subtree rooted at a child node s of some node r of a normal formdecomposition tree serves to decompose precisely one TrU-component.Proposition 18 [16]. For each k-width hypertree decomposition of a hypergraph H thereexists a k-width hypertree decomposition of H in normal form.This normal form theorem immediately entails that, for each optimal hypertreedecomposition of a hypergraph H, there exists an optimal hypertree decomposition of Hin normal form.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282263The fact that no redundancies occur in hypertree decompositions in normal form allowsus to give a precise bound on the number of vertices in such hypertree decompositions.Lemma 19. Let HD D .T ; (cid:31); (cid:21)/ be a hypertree decomposition in normal form of ahypergraph H. Moreover, let n be the number of vertices of the decomposition tree T ,and m the number of strongly covered edges of H in HD. Then, n 6 m holds.Proof. Let s be some vertex in T . We say that a variable X 2 (cid:31).s/ (respectively, an edgeH (cid:18) (cid:31).s// is “first covered” in s if X =2 (cid:31).vertices.T / (cid:0) vertices.Tp// (respectively, H 6(cid:18)(cid:31).vertices.T / (cid:0) vertices.Tp//); otherwise, X (respectively, H ) is said to be “previouslycovered”. By condition (2) of Definition 17 and by condition (2) of Definition 12, it followsthat, for any vertex p of T , there exists at least a variable X in var.H/ which is “firstcovered” in p. Since X 2 (cid:31).p/, from condition (3) of Definition 12, it follows that thereis an edge H of H such that X 2 H and H 2 (cid:21).p/. Moreover, from condition (4) ofDefinition 12, it follows that every variable belonging to H and not covered in some vertexin vertices.T / (cid:0) vertices.Tp/ must be first covered in p, and belongs to (cid:31).p/.Moreover, since HD is in normal form, it satisfies condition (3) of Definition 17 (i.e.,var.(cid:21).s// \ (cid:31).r/ (cid:18) (cid:31).s/). It follows that, in fact, any previously-covered variable Ybelonging to H must belong to (cid:31).p/. Indeed, since the variable X was not previouslycovered, the edge H cannot be previously covered, and thus there exists some vertex p0in the subtree Tp such that H (cid:18) (cid:31).p0/, in order to fulfill condition (1) of Definition 12.Assume that the variable Y 2 H does not belong to (cid:31).p/. Since H is strongly coveredby p0, Y 2 (cid:31).p0/. Moreover, by the choice of Y , this variable is previously covered withrespect to p. It follows that Y violates the connectedness condition, a contradiction.Thus, all the variables in H belong to (cid:31).p/. Recall that H 2 (cid:21).p/, too. It follows thatat least one edge of H is first covered in vertex p and strongly covered by p, and, ingeneral, that each vertex in T first and strongly covers some edge of H. This entails thatthe cardinality of the set of vertices in the decomposition tree T of HD is less than or equalto the number m of the strongly covered edges in the normal form hypertree decompositionHD of H. 2A polynomial time algorithm opt-k-decomp which, for a fixed k, decides whether ahypergraph has k-bounded hypertree width and, in this case, computes an optimal hypertreedecomposition in normal form is described in [17]. As for many other decompositionmethods, the running time of this algorithm to find the hypergraph decomposition isexponential in the parameter k. More precisely, opt-k-decomp runs in O.m2kv2/ time,where m and v are the number of edges and the number of vertices of H, respectively.We next show that any CSP instance I is efficiently solvable, given a k-boundedcomplete hypertree-decomposition HD of HI . To this end, we define an acyclic CSPinstance which is equivalent to I and whose size is polynomially bounded by the sizeof I .For each vertex p of the decomposition HD, we define a new constraint scope whoseassociated constraint relation is the projection on (cid:31).p/ of the join of the relations in (cid:21).p/.This way, we obtain a join-tree JT of an acyclic hypergraph H(cid:3). H(cid:3) corresponds to a newCSP instance I (cid:3) over a set of constraint relations of size O.nk/, where n is the input size264G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282(i.e., n D kI k) and k is the width of the hypertree decomposition HD. By construction, I (cid:3)is an acyclic CSP, and we can easily show that it is equivalent to the input CSP instanceI . Thus, all the efficient techniques available for acyclic CSP instances [7,9], or for anyproblem equivalent to CSP [15,21,26], can be employed for the evaluation of I (cid:3), and henceof I .Remark 20. According to our definition, any hypertree is a labeled rooted tree.The rooting is necessary for technical reasons concerning the notion of hypertreedecomposition only, but has no impact on the actual evaluation of the given CSP instance.In fact, the above discussion describes how to compute from a hypertree decompositionand a CSP instance I a join tree JT of an acyclic instance I (cid:3) that is equivalent to I . Thisconstruction does not use the fact that the hypertree is rooted. Moreover, note that theacyclic instance I (cid:3) can be evaluated rooting the join tree JT at any vertex.The following theorem provides a detailed analysis of the complexity of evaluating aCSP given a hypertree decomposition for it.Theorem 21. Given a CSP I and a k-width hypertree decomposition HD0 of HI in normalform, I is solvable in O.kI kkC1 log kI k/ time.Proof. Let I be a CSP instance and HD0 D .T 0; (cid:31) 0; (cid:21)0/ a k-width hypertree decompositionof HI in normal form. We proceed as follows.Step 1. We compute from HD0 a complete hypertree decomposition HD D .T ; (cid:31); (cid:21)/ ofHI .Step 2. We compute from HD and I an acyclic instance I (cid:3) equivalent to I , as describedabove.Step 3. We evaluate the acyclic instance I (cid:3) employing any efficient technique for solvingacyclic CSPs.Let m be the number of edges of HI . The following statements hold:Claim 1. The decomposition tree of the complete hypertree decomposition HD has at mostm vertices.Proof. This immediately follows from the construction of HD and from Lemma 19, sincein Step 1 above we just add to the decomposition tree T those edges of HI that are notstrongly covered in HD0. 2Claim 2. Step 1 is feasible in O.kHI k2/.Proof. As observed in Remark 13, this computation takes O.kHD0k (cid:1) kHI k/ time. FromLemma 19, it easily follows that kHD0k is O.kkHI k/ D O.kHI k/, because the number ofvertices in T 0 is at most the number of edges of HI , and the number of edge-labels of eachvertex of T 0 is bounded by the constant k. 2Claim 3. kI (cid:3)k D O.kI kk/, and computing I (cid:3) from I takes time O.kI kk/.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282265Proof. Consider a constraint C D .Sc; rc/ in the acyclic instance I (cid:3). As described above,the relation rc is obtained as the natural join of at most k relations occurring in the inputinstance I . One of these input relations, say ri , – in fact, its constraint scope Si – iscovered by some vertex p in the decomposition tree of HD which corresponds to C in theacyclic instance I (cid:3). (In particular, its scope Si corresponds to some edge hi 2 edges.HI /such that hi 2 (cid:21).p/, and hi (cid:18) (cid:31).p/.) Let rmax be the constraint relation having themaximum size krmaxk over all the constraint relations occurring in the input instance I .Then, krck 6 .krmaxkk(cid:0)1 (cid:1) kri k/. Recall that the instance I (cid:3) has at most m constraints.Considering all the constraints in I , we get the following upper bound for the size of thewhole CSP I (cid:3):(cid:0)kI (cid:3)k 6(cid:1)krmaxkk(cid:0)1 (cid:1) kr1k C (cid:1) (cid:1) (cid:1) C krmaxkk(cid:0)1 (cid:1) krmkand hencekI (cid:3)k 6 krmaxkk(cid:0)1 (cid:1)(cid:1)(cid:0)kr1k C (cid:1) (cid:1) (cid:1) C krmk6 krmaxkk(cid:0)1 (cid:1) kI k:It follows that kI (cid:3)k 6 kI kk . Moreover, the effective computation of I (cid:3) from I takestime O.kI kk/. Indeed, computing the natural join of two relations r1 and r2 takes timeO.kr1k(cid:1)kr2k/, which is exactly the same bound that we have for the size of the result of thisjoin operation. Thus, by applying the same line of reasoning as used for the space bound,we get that the computation of the acyclic instance I (cid:3) is feasible in O.kI kk/ time. 2From Claims 1–3 and from the well-known O.m (cid:1) kI (cid:3)k (cid:1) log kI (cid:3)k/ complexity ofevaluating the acyclic CSP I (cid:3) (see, e.g., [7,9]), it follows that the overall cost of thisevaluation procedure is O.kI k (cid:1) kI kk (cid:1) log kI kk/ C O.kHI k2/ D O.kI kkC1 (cid:1) log kI k/,because k is fixed, kHI k 6 kI k, and k > 1. 2It is worthwhile noting that the crucial difference between the HYPERTREE methodand the TCLUSTER method is the objective function to be minimized in order to obtainthe most convenient acyclic decomposition of a given CSP instance. The HYPERTREEmethod minimizes the number of hyperedges of HI associated to any vertex of the acyclicequivalent instance, thus exploiting the fact that one hyperedge “covers” many variables atonce. The TCLUSTER method minimizes the number of variables occurring in any vertexof the equivalent acyclic instance, as evidenced by the following example.Example 22. For any m > 0, let T .m/ be the hypergraph having the m C 3 hyperedgesfh1; h2; h3; e1; e2; : : : ; emg defined as follows:(cid:15) h1 D fX1; : : : ; Xm; Y1; : : : ; Ym; Ag;(cid:15) h2 D fY1; : : : ; Ym; Z1; : : : ; Zm; Bg;(cid:15) h3 D fZ1; : : : ; Zm; X1; : : : ; Xm; Cg;(cid:15) ei D fXi; Yi ; Zig, 81 6 i 6 m.The TCLUSTER width of T .m/ is 3m, because its primal graph is chordal and itsmaximal clique C D fX1; : : : ; Xm; Y1; : : : ; Ym; Z1; : : : ; Zmg has cardinality 3m. In fact,according to the TCLUSTER method, we have to solve a subproblem involving everyhyperedge ei (1 6 i 6 m).266G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282On the other hand, for any m > 0, the HYPERTREE width of T .m/ is 2. It is worthwhilenoting that the number of variables occurring in the largest vertex of this decomposition is3m C 2. Hence, the equivalent acyclic instance we obtain according to HYPERTREE is not“optimal” according to the TCLUSTER method, because its associated primal graph has aclique of cardinality 3m C 2. Nevertheless, the constraint relation associated to this vertexis computable very easily as the join of the constraint relations r1 and r2 corresponding toh1 and h2, respectively.A simple way to get decomposition methods which in some way exploit the power ofhyperedges is using the dual graph associated to a CSP. We give a detailed analysis of theseapproaches and of their relationships with the HYPERTREE method in Section 9. It turnsout that even such methods do not exploit the full power of hyperedges, and are less generalthen HYPERTREE, according to a strong notion of generalization, formally defined in thenext section.6. Comparison criteriaFor comparing decomposition methods we introduce the relations (cid:22), (cid:3), and (cid:30)(cid:30) definedas follows:D1 (cid:22) D2 (in words, D2 generalizes D1) if there exists (cid:14) > 0 such that, for every k > 0,C.D1; k/ (cid:18) C.D2; k C (cid:14)/. Thus, D1 (cid:22) D2 implies that every class of CSP instances whichis tractable according to D1 is also tractable according to D2.Note that the constant (cid:14) above allows us to get rid of small differences among tractabilityclasses that should be irrelevant in the comparison. E.g., it is known (see discussion inSection 4.9) that TCLUSTER and TREEWIDTH are equivalent methods and one wouldexpect TCLUSTER to generalize TREEWIDTH (as well as vice versa). However, forany k > 1, C.TREEWIDTH; k/ 6(cid:18) C.TCLUSTER; k/, because the treewidth is definedthrough the cardinality of the vertex-labeling minus one. Rather, C.TREEWIDTH; k/ (cid:18)C.TCLUSTER; k C 1/ holds. Thus, by taking (cid:14) D 1, we easily get TREEWIDTH (cid:22)TCLUSTER.D1 (cid:3) D2 (D1 beats D2) if there exists an integer k such that, for every m; C.D1; k/ 6(cid:18)C.D2; m/. To prove that D1 (cid:3) D2, it is sufficient to exhibit a class of hypergraphs containedin some C.D1; k/ but in no C.D2; j / for every j > 0.Intuitively, D1 (cid:3) D2 means that, at least on some class of CSP instances, D1 outperformsD2 with respect to tractability, because these instances are tractable according to D1, butnot according to D2. For such classes, using D1 is thus better than using D2.D1 (cid:30)(cid:30) D2 if D1 (cid:22) D2 and D2 (cid:3) D1. In this case we say that D2 strongly generalizesD1.This means that D2 is really the more powerful method, given that, whenever D1guarantees polynomial runtime for constraint solving, then also D2 guarantees tractableconstraint solving, but there are classes of constraints that can be solved in polynomialtime by using D2 but are not tractable according to D1.Mathematically, (cid:22) is a preorder, i.e., it is reflexive, transitive, but not antisymmetric. Wesay that D1 is (cid:22)-equivalent to D2, denoted D1 (cid:17) D2, if both D1 (cid:22) D2 and D2 (cid:22) D1 hold.Note that, on the other hand, (cid:30)(cid:30) is transitive and antisymmetric, but not reflexive.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282267The decomposition methods D1 and D2 are strongly incomparable if both D1 (cid:3) D2 andD2 (cid:3) D1. Note that, if D1 and D2 are strongly incomparable, then they are incomparablewith respect to the relations (cid:22) and (cid:30)(cid:30), too.7. Comparison resultsIn this section we present a complete comparison of the decomposition methodsdescribed in Section 4, according to the above criteria. Fig. 1 (reproduced here as Fig. 16with the acronyms of decomposition methods for the reader’s convenience) shows arepresentation of the hierarchy of decomposition methods determined by the (cid:30)(cid:30) relation.Each element of the hierarchy represents one decomposition method, apart from thatcontaining Tree Clustering, w(cid:3), and Treewidth which are grouped together because theyare (cid:22)-equivalent as easily follows from the observations in Section 4.Theorem 23. For each pair D1 and D2 of decompositions methods represented in Fig. 16,the following holds:(cid:15) There is a directed path from D1 to D2 if and only if D1 (cid:30)(cid:30) D2, i.e., if and only if D2strongly generalizes D1.(cid:15) D1 and D2 are not linked by any directed path if and only if they are stronglyincomparable.Hence, Fig. 16 gives a complete picture of the relationships holding among the differentmethods.The following lemmas, together with the transitivity of the relations defined in Section 6,prove Theorem 23.For any n > 2 and m > 0, let Circle.n; m/ be the hypergraph having n edges fh1; : : : ; hngdefined as follows:(cid:15) hi D fX1(cid:15) hn D fX1i ; : : : ; Xmn; : : : ; Xmi ; X1n ; X1iC1; : : : ; XmiC1g.1; : : : ; Xm1g 81 6 i 6 n (cid:0) 1;Fig. 16. Constraint tractability hierarchy.268G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282Fig. 17 shows the hypergraph Circle.n; 2/, for some n > 8. For m D 1, Circle.n; 1/is a graph consisting of a simple cycle with n edges (like a circle). Note that, for anyn > 2 and m > 0, Circle.n; m/ has hypertree width 2. A width 2 hypertree decompositionof Circle.n; m/ is shown in Fig. 18. It follows that the (infinite) class of hypergraphsSfCircle.n; m/g is included in the tractability class C.HYPERTREE; 2/.n>2;m>0For any n > 0, let triangles.n/ be the graph .V ; E/ defined as follows. The set ofvertices V contains 2n C 1 vertices p1; : : : ; p2nC1. For each even index i, 2 6 i 6 2n,fpi; pi(cid:0)1g, fpi; piC1g, and fpi(cid:0)1; piC1g are edges in E. No other edge belongs to E.Fig. 19 shows the graph triangles.n/. The HYPERTREE width of triangles.n/ is 2. Indeed,a hypertree hT ; (cid:31); (cid:21)i, where T is a simple chain of n vertices v1; : : : ; vn and, for each vi(1 6 i 6 n), (cid:31).vi / D fp2i(cid:0)1; p2i; p2iC1g and (cid:21).vi / contains the two edges fp2i(cid:0)1; p2i g andfp2i; p2iC1g, is a width 2 HYPERTREE decomposition of triangles.n/.For any n > 0, let book.n/ be a graph having 2n C 2 vertices and 3n C 1 edges that formn squares (pages of the book) having exactly one common edge fX; Y g. It is easy to seethat the HYPERTREE width of book.n/ is 2. Fig. 20 shows the graph book.4/.Fig. 17. The hypergraph Circle.n; 2/.Fig. 18. 2-width hypertree decomposition of Circle.n; m/.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282269Fig. 19. The graph triangles.n/.Fig. 20. The graph book.4/.Lemma 24. CUTSET (cid:30)(cid:30) HYPERCUTSET.Proof. HYPERCUTSET clearly generalizes CUTSET. Moreover, HYPERCUTSET (cid:3)fCircle.n; m/g 6(cid:18) C.CUTSET; k/ holds for any k > 0; while,CUTSET. Indeed,SfCircle.n; m/g (cid:18) C.HYPERCUTSET; 1/, as deleting any edge of Circle.n; m/n>2;m>0Sn>2;m>0yields an acyclic hypergraph. 2Lemma 25. BICOMP (cid:3) HYPERCUTSET.Proof. Consider the graph triangles.n/ for some n > 0. It is easy to see that theHYPERCUTSET width of triangles.n/ is dn=3e, while its BICOMP width is 3. Hence,Sftriangles.n/g 6(cid:18) C.HYPERCUTSET;ftriangles.n/g (cid:18) C.BICOMP; 3/, while,Sn>1n>1k/ holds for every k > 0. 2Lemma 26. BICOMP and CUTSET are strongly incomparable.Proof. (BICOMP (cid:3) CUTSET.) Follows from Lemma 25 and Lemma 24.(CUTSET (cid:3) BICOMP.) Consider the graph book.n/ for some n > 0. The whole graphbook.n/ is biconnected. Thus, its BICOMP width is 2n C 2. On the other hand, the setfX; Y g is a cycle cutset of book.n/. Thus,fbook.n/g (cid:18) C.CUTSET; 2/ holds. 2Sn>1Lemma 27. BICOMP (cid:30)(cid:30) HINGE.Proof. In [18], it was shown that BICOMP (cid:22) HINGE. Thus, it suffices to prove thatHINGE (cid:3) BICOMP: Consider the graph book.n/ defined above, for some n > 0. Asobserved above, the BICOMP width of book.n/ is 2n C 2, while its HINGE width is 4.Indeed, the minimal hinges of book.n/ correspond to the pages of the book, and each ofthem has cardinality 4. 2270G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282Lemma 28. BICOMP (cid:30)(cid:30) TCLUSTER.Proof. In [7], it was observed that BICOMP (cid:22) TCLUSTER. (In fact, BICOMP wascompared with w(cid:3), which is (cid:22)-equivalent to TCLUSTER.) Furthermore, TCLUSTER (cid:3)BICOMP follows from CUTSET (cid:3) BICOMP and from the fact, observed in [7], thatTCLUSTER generalizes CUTSET, i.e., CUTSET (cid:22) TCLUSTER. 2Lemma 29. CUTSET (cid:30)(cid:30) TCLUSTER.Proof. As mentioned above, CUTSET (cid:22) TCLUSTER [7]. Moreover, TCLUSTER (cid:3)CUTSET follows from BICOMP (cid:3) CUTSET and BICOMP (cid:22) TCLUSTER. 2Lemma 30. CUTSET (cid:3) HINGE.SfCircle.n; 1/g has CUTSET width 1, because deleting anyProof. Every graph invertex of the graph we get an acyclic graph. However, for any n > 2, the degree of cyclicityof Circle.n; 1/ is n [18]. 2n>2Lemma 31. HINGE and TCLUSTER are strongly incomparable.Proof. (HINGE (cid:3) TCLUSTER). Let S D fCircle.3; m/ j m > 1g. For any m > 1, theprimal graph G of Circle.3; m/ is a clique of 3m variables. Thus, G does not need anytriangulation, because it is a chordal graph. The TCLUSTER width of Circle.3; m/ isclearly 3m; while its HINGE width is 3, because every hypergraph in S has only three(hyper)edges.(TCLUSTER (cid:3) HINGE). Followsfrom CUTSET (cid:3) HINGE and CUTSET (cid:22)TCLUSTER. 2Lemma 32. HINGE (cid:30)(cid:30) HINGETCLUSTER and TCLUSTER (cid:30)(cid:30) HINGETCLUSTER.is easy to see that both HINGE (cid:22) HINGETCLUSTER and TCLUSTER (cid:22)Proof. ItHINGETCLUSTER hold. Furthermore, HINGETCLUSTER (cid:3) HINGE follows from TCLUSTER(cid:22) HINGETCLUSTER and TCLUSTER (cid:3) HINGE; and HINGETCLUSTER (cid:3) TCLUSTER fol-lows from HINGE (cid:22) HINGETCLUSTER and HINGE (cid:3) TCLUSTER. 2Lemma 33. HINGETCLUSTER (cid:22) HYPERTREE.Proof. Let H be a hypergraph, and H0 be a HINGETCLUSTER decomposition of H ofwidth k. We show that there exists a hypertree decomposition for H of width k. We willuse as a running example the hypergraph Hhg in Example 6. Fig. 11 shows the width 3HINGETCLUSTER decomposition H0hg of Hhg, described in Example 7.Recall that, by construction, the HINGETCLUSTER decomposition H0is an acyclichypergraph. Note that, in general, H0 is not a reduced hypergraph. For instance, H0hg isnot reduced, as the edge fX1; X2; X3g, coming from the TCLUSTER decomposition of thehinge H2, is a subset of fX1; X2; X3; X10; X11g, which comes from the hinge H1.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282271Let H00 be the reduced and acyclic hypergraph obtained from H0 deleting each edgehg contains all thethat is a subset of some other edge of the hypergraph. Therefore, e.g., H00edges of H0hg, but the edge fX1; X2; X3g.We partition the edges of H00 into three sets AE, HE, and TE defined as follows.(cid:15) The set AE contains all edges of H00 that come from the TCLUSTER decompositionof some hinge Hi of H such that the subgraph .var.Hi/; Hi/ is acyclic. In the runningexample, this property holds for hinges H4, H5, and H6. Recall that, in this case,w.Hi / D 1 holds, and the decomposition of this hinge is just the acyclic hypergraph.var.Hi/; Hi/. For example, for H00hg, AE contains the edges corresponding to theconstraint scopes s5, s6, s7, and s8, i.e., fX4; X5; X6g, fX4; X7g, fX5; X8g, andfX6; X9g, respectively.(cid:15) The set TE contains all edges in edges.H00/ (cid:0) AE that come from the TCLUSTERdecomposition of some hinge Hi of H such that the subgraph .var.Hi/; Hi/ iscyclic. Since the TCLUSTER decomposition of this hypergraph is bounded by k, itfollows that each edge in TE contains at most k variables. In our running example,TE contains two edges fX1; X3; X6g and fX1; X4; X6g that we call te1 and te2,respectively.(cid:15) The set HE contains all those edges in edges.H00/ (cid:0) AE (cid:0) TE that come from somehinge of H. Thus, any edge h in HE is the union of at most k edges belonging tosome hinge Hi of H. We denote the hinge Hi corresponding to h by hinge.h/. In ourrunning example, HE contains one edge fX1; X2; X3; X10; X11g that we call he1 andcomes from the hinge H1 D fs1; s2; s9g of Hhg. Therefore, hinge.he1/ D fs1; s2; s9g.Let JT be a jointree of the acyclic hypergraph H00. Recall that each vertex of the treeJT is an edge of H00 and vice versa, and that the connectedness condition holds, i.e., thesubgraph of JT induced by any variable of H0 is connected. Fig. 21 shows a jointree ofH00hg.From JT , we define a hypertree decomposition HD D hT ; (cid:31); (cid:21)i, where the tree T has thesame shape as JT , and the labelings (cid:31) and (cid:21) are defined through the following procedure.For each vertex h of JT , denote by ph the corresponding vertex in the tree T of H.(1) for each edge h of AE, label the corresponding vertex ph as follows: (cid:31).ph/ D h and(2) for each edge h of HE, label the corresponding vertex ph as follows: (cid:31).ph/ D h(cid:21).ph/ D fhg.and (cid:21).ph/ D hinge.h/.Fig. 21. A jointree of the hypergraph H00hg .272G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282Fig. 22. The hypertree for the running example in the proof of Lemma 33 after steps (1), (2), and (3).Fig. 23. The hypertree for the running example in the proof of Lemma 33 after step (4).(4) for each edge h of TE, label the corresponding vertex ph as follows: (cid:31).ph/ D hand (cid:21).ph/ D ;. For the running example, Fig. 22 shows the hypertree obtained afterthese three steps.(4) for each edge Nh of the hypergraph H such that there is no vertex q in T withNh 2 (cid:21).q/, choose a vertex h of JT such that Nh (cid:18) h and h 2 TE, and add Nh to the(cid:21) labeling of the corresponding vertex ph in T (i.e., (cid:21).ph/ VD (cid:21).ph/ [ f Nhg). In ourrunning example, we add the edge s3, whose variables are X1 and X4, to the (cid:21)labeling of the hypertree’s root, and the edge s4, whose variables are X4 and X6, tothe (cid:21) labeling of the left child of the root, as shown in Fig. 23.(5) While there is a vertex p in T such that (cid:31).p/ contains a variable X not covered by(cid:21).p/ (i.e., X 2 (cid:31).p/ (cid:0) var.(cid:21).p//), proceed as follows.(A) Find a path (cid:25) in T linking p to a vertex q such that(i) X 2 var.(cid:21).q// and,(ii) X =2 var.(cid:21).s// for every vertex s in (cid:25) (cid:0) fqg.(B) Choose an edge h 2 (cid:21).q/ such that X 2 h.(C) Add h to both (cid:21).s/ and (cid:31).s/, for every vertex s 2 (cid:25) (cid:0)fqg (i.e., (cid:31).s/ VD (cid:31).s/[h,and (cid:21).s/ VD (cid:21).s/ [ fhg).In the running example, the root contains the variable X6 that is not covered by theedge s3 (see Fig. 23). Then, we choose the path connecting the root and its rightchild, because X6 occurs in some edge belonging to its (cid:21) labeling, namely in theedge s5. Thus, we add s5 to the (cid:21) labeling of the root, and the covering of X6 isdone. Similarly, the variable X1 occurring in the left child of the root is covered byadding to its (cid:21) labeling the edge s1, which occurs in its child. Fig. 24 shows the finalhypertree obtained for the running example.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282273Fig. 24. The final hypertree for the running example in the proof of Lemma 33.Note that, after steps (1), (2), and (3), the connectedness condition (i.e., condition (2)of Definition 12) clearly holds in HD because it holds in the jointree JT . However, forany vertex ph of T corresponding to a vertex h 2 TE of JT , step (3) only provides the (cid:31)labeling for ph. Thus, in step (4), we select the edges of H that cover these variables in thevertex ph of the decomposition HD, i.e., we define the (cid:21) labeling for ph.Since the connectedness condition is preserved in step (3) above, it is easy to verifythat, at the end of the procedure, HD is a hypertree decomposition of H. Moreover, itsHYPERTREE width is at most k. Indeed, by the above construction, it follows that for eachvertex h 2 HE, j(cid:21).ph/j D jhinge.h/j 6 k, and, for each vertex h0 2 TE, j(cid:21).ph/j 6 jhj 6k. 2Lemma 34. HINGETCLUSTER (cid:30)(cid:30) HYPERTREE.Proof. From Lemma 33, HINGETCLUSTER (cid:22) HYPERTREE holds. We next show thatHYPERTREE (cid:3) HINGETCLUSTER. Consider the cyclic hypergraph Circle.n; m/, for anyn > 2; m > 0. This hypergraph has a unique hinge containing allits edges, andtherefore its HINGE width is n. Moreover, its primal graph contains maximal cliquesof cardinality at least 2m, and thus its TCLUSTER width is at least 2m. It follows thatSfCircle.n; m/g 6(cid:18) C.HINGETCLUSTER; k/ holds for any k > 0. However, forfCircle.n; m/g (cid:18) C.HYPERTREE; 2/ holds. (See Fig. 18 for an>2;m>0HYPERTREE,hypertree decomposition of Circle.n; m/ of width 2.) 2n>2;m>0SLemma 35. HINGETCLUSTER and HYPERCUTSET are strongly incomparable.Proof. HINGETCLUSTER (cid:3) HYPERCUTSET follows from BICOMP (cid:3) HYPERCUTSET andBICOMP (cid:22) HINGETCLUSTER.HYPERCUTSET (cid:3) HINGETCLUSTER. Indeed,fCircle.n; m/g 6(cid:18) C.HINGETCLUSTER; k/n>2;m>0[[holds for any k > 0; while,fCircle.n; m/g (cid:18) C.HYPERCUTSET; 1/:2n>2;m>0Lemma 36. HYPERCUTSET (cid:30)(cid:30) HYPERTREE.274G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282Proof. We have that HYPERTREE (cid:3) HYPERCUTSET because, from Lemma 25, BICOMP(cid:3) HYPERCUTSET, and BICOMP (cid:22) HYPERTREE.We next prove that HYPERCUTSET (cid:22) HYPERTREE. Let H be a hypergraph andH (cid:18) edges.H/ a cycle hypercutset of H. Let k be the cardinality of H . Let H0 be thesubhypergraph of H induced by var.H/ (cid:0) var.H /, i.e., the hypergraph having an edgeh0.h/ D h (cid:0) var.H / for each edge h 2 edges.H/ such that h (cid:0) var.H / 6D ;. Note that,in general, H0 is not connected. By definition of cycle hypercutset, H0 is acyclic. Thus,there exists a join forest for H0, i.e., a set of jointrees JT1; : : : ; JT‘ corresponding to the sconnected components of H0.We show that there exists a hypertree decomposition HD D hT ; (cid:31); (cid:21)i of H havingwidth k C 1. The root r of T is labeled by the cycle hypercutset H , i.e., (cid:21).r/ D H , and(cid:31).r/ D var.H /. The root r has ‘ children fp1; : : : ; p‘g corresponding to the ‘ jointreesJT1; : : : ; JT‘. In particular, each subtree Tpi rooted at a child pi (1 6 i 6 ‘) has the sametree shape as the jointree JTi . Moreover, let q be a vertex of the jointree JTi , and h be anedge of H such that h0.h/ is the edge of H0 associated to the vertex q of JTi . We label thecorresponding vertex Nq in Tpi as follows: (cid:21). Nq/ D fhg [ H , and (cid:31). Nq/ D h [ var.H /.It is easy to see that the hypertree HD is a hypertree decomposition of H, and its widthis k C 1. It follows that HYPERCUTSET (cid:22) HYPERTREE. 28. Binary CSPsIn this section, we focus on binary constraints satisfaction problems, i.e., on CSPs wherethe constraints relations have arity at most two.On binary constraint networks, the differences among the decomposition strategies,highlighted in Section 7, become less evident. Indeed, bounding the arities of the constraintrelations, the k-tractable classes of some decomposition strategies collapse, while somegeneralizations are no longer strong generalizations.Let (cid:30)(cid:30)bin; (cid:22)bin, (cid:3)bin, and (cid:17)bin the relations on the decompositions strategies inducedby (cid:30)(cid:30); (cid:22), (cid:3), and (cid:17), respectively, when only binary CSPs are considered.In Fig. 25, full arcs (and paths containing full arcs) represent (cid:30)(cid:30)bin relationships, while adashed arc from a method D1 to a method D2 means that D1 (cid:22)bin D2 and D2 6(cid:22)bin D1, butat the same time D1 6(cid:30)(cid:30)bin D2. From the latter relationship, it follows that every class C thatis tractable according to D1 is also tractable according to D2, i.e., the D2 width of everygraph belonging to the class C is bounded by some constant k > 0. However, D2 6(cid:22)bin D1entails that D2 decompositions are more “efficient”, in the sense that solving a D1-tractableclass by D2-solution methods is feasible by augmenting the worst-case complexity by atmost an additive constant in the exponent, while this is not possible in the other direction.Theorem 37. For each pair D1 and D2 of decompositions methods represented in Fig. 25,the following holds:(cid:15) There is a directed path from D1 to D2 if and only if D1 (cid:22)bin D2.(cid:15) There is a directed path containing at least one full arrow from D1 to D2 if and onlyif D1 (cid:30)(cid:30)bin D2.G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282275Fig. 25. Tractability hierarchy for binary CSPs.(cid:15) D1 and D2 are not linked by any directed path if and only if they are incomparablewith respect to the (cid:22)bin relationship, i.e., if both D1 6(cid:22)bin D2 and D2 6(cid:22)bin D1 hold.The following lemmas provide the proof of this theorem.Lemma 38. HINGE (cid:30)(cid:30)bin TCLUSTER.Proof. First note that TCLUSTER (cid:3)bin HINGE follows from the proof showing thatTCLUSTER (cid:3) HINGE. Indeed, for any n > 2, the graph Circle.n; 1/ has degree of cyclicityn, while it has TCLUSTER width 3.To prove that HINGE (cid:22)bin TCLUSTER, we show that for any graph G D .V ; E/ HINGE-width.G/ > TCLUSTER-width.G/. If G is an acyclic graph, then its degree of cyclicity is2 and its TCLUSTER width is 1, by definition. Now, assume G is a cyclic graph and let Tbe a hinge decomposition of G. From the definition of hinge decomposition, it follows thatT represents a join tree of an acyclic hypergraph.We recall from [19] that, given a hinge H of G, H 0 (cid:18) H is a hinge of G if and onlyif H 0 is a hinge of the graph .var.H /; H /. It follows that any minimal hinge of G mustbe a connected set of edges. Moreover, it is easy to see that if H is a minimal hinge and.var.H /; H / is acyclic, then jH j D 2.Let T 0 be a new join tree initially set equal to T . As long as there exists some vertex ofT 0 corresponding to a 2-edges hinge of G, modify T 0 as follows:(1) select a vertex p of T 0 containing two edges of G e1 and e2;(2) add to T 0 two vertices p1 and p2 containing edges e1 and e2, respectively;(3) add an edge connecting p1 and p0 for any vertex p0 of T 0 connected to p and sharinge1 with p;276G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282(4) add an edge connecting p2 and p0 for any vertex p0 of T 0 connected to p and sharinge2 with p;(5) remove p and all its incident edges from T 0.It is easy to verify that the final tree T 0 obtained when the procedure above terminatessatisfies the connectedness condition of join trees. In fact, it represents an acyclichypergraph, say H0.Let G0 be the primal graph of H0. The graph G0 is clearly chordal and E (cid:18) E0, thus it canbe obtained by some suitable triangulation of G. Let k be the number of variables occurringin the largest clique C of G0. Since G is a cyclic graph, k > 2. By construction of G0, theclique C corresponds to some minimal hinge H of G such that the graph .var.H /; H / isboth connected and cyclic. This entails that jH j > var.H / D k.It follows that k 6 HINGE-width.G/, because HINGE-width.G/ is equal to thecardinality of the largest minimal hinge of G. Thus the lemma holds, because TCLUSTER-width.G/ 6 k, as G0 witnesses that there exists a graph obtained by some triangulation ofG whose maximal clique has cardinality k. 2Lemma 39. The following relationships hold between HYPERTREE and TCLUSTER:(cid:15) TCLUSTER (cid:22)bin HYPERTREE;(cid:15) HYPERTREE 6(cid:3)bin TCLUSTER; and(cid:15) HYPERTREE 6(cid:22)bin TCLUSTER.Proof. (TCLUSTER (cid:22)bin HYPERTREE.) Easily follows from the same constructiondescribed in Lemma 33 to prove that HINGETCLUSTER (cid:22) HYPERTREE.(HYPERTREE 6(cid:3)bin TCLUSTER.) Follows from the factfor any graph G,TCLUSTER-width.G/ 6 2 (cid:1) HYPERTREE-width.G/. Let HD be any k-width hypertreedecomposition of a graph G. The hypergraph corresponding to the acyclic instance builtaccording to HD has a primal graph G0 whose largest clique contains 2 (cid:1) k variables at most.Indeed, at most k edges can be associated to any vertex p of the hypertree decompositionand hence var.p/ 6 2 (cid:1) k.that,(HYPERTREE 6(cid:22)bin TCLUSTER.) Observe that, for every n > 3, the complete graphKn has HYPERTREE width dn=2e, while it has TCLUSTER width n. Thus, Kn 2C.HYPERTREE; n0/, for each n0 > dn=2e, while Kn =2 C.TCLUSTER; n00/, for each n00 <n. It follows that there is no fixed (cid:14) such that, for every k > 0, C.HYPERTREE; k/ (cid:18)C.TCLUSTER; k C (cid:14)/. 2Lemma 40. The following relationships hold between HYPERCUTSET and CUTSET:(cid:15) CUTSET (cid:22)bin HYPERCUTSET;(cid:15) HYPERCUTSET 6(cid:3)bin CUTSET; and(cid:15) HYPERCUTSET 6(cid:22)bin CUTSET.Proof. The proofs of the first two points above are straightforward. We next show thatHYPERCUTSET 6(cid:22)bin CUTSET. Consider the graph triangles.n/ for some n > 0. It iseasy to see that the HYPERCUTSET width of triangles.n/ is dn=3e, while its CUTSETwidth is dn=2e. Thus, triangles.n/ 2 C.HYPERCUTSET; n0/, for each n0 > dn=3e, whiletriangles.n/ =2 C.CUTSET; n00/, for each n00 < dn=2e. It follows that there is no fixed (cid:14)such that, for every k > 0, C.HYPERCUTSET; k/ (cid:18) C.CUTSET; k C (cid:14)/. 2G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282277All the other relationships follow from transitivity, or from the corresponding proofsgiven in the general case of hypergraphs, which carry over to the binary case.9. Solving nonbinary CSPs by dualizationMany structural decomposition methods have been designed to identify “easy” graphstructures, rather than “easy” hypergraph structures. In Section 4, we described binarydecomposition methods (i.e., decomposition methods designed for graphs, but not forhypergraphs) acting on the primal graph of the hypergraph associated to the given CSPinstance. As we showed in the previous section, for binary CSPs some methods becomecloser to the hypertree-decomposition method.An alternative approach to the solution of nonbinary CSPs is to exploit binary methodson the dual graph of a hypergraph. (See, e.g., [7].) Given a CSP instance I , the dualD .V ; E/ defined as follows: the set ofgraph [7,9,22] of the hypergraph HI is a graph GdIvertices V coincides with the set of (hyper)edges of HI , and the set E contains an edgefh; h0g for each pair of vertices h; h0 2 V such that h \ h0 6D ;. That is, there is an edgebetween any pair of vertices corresponding to hyperedges of HI sharing some variable.The dual graph often looks very intricate even for simple CSPs. For instance, in general,acyclic CSPs do not have acyclic dual graphs. However, it is well known that the dual graphI can be suitably simplified in order to obtain a “better” graph G0 which can still be usedGdto solve the given CSP instance I . In particular, if I is an acyclic CSP, GdI can be reducedto an acyclic graph that represents a jointree of HI . In this case, the reduction is feasiblein polynomial (actually, linear) time. (See, e.g., [22].)Definition 41. Let G D .V ; E/ be the dual graph of some hypergraph H. For any pair ofvertices h; h0 2 V , let ‘.fh; h0g/ D h \ h0. A reduct G0 of G is a graph .V 0; E0/ satisfyingthe following conditions:(i) V 0 D V ;(ii) E0 (cid:18) E; and(iii) for each edge q D fh; h0g belonging to .E (cid:0) E0/, there exists in G0 a path P from hto h0, such that the variables in ‘.q/ are included in ‘.q 0/ for each edge q 0 occurringin the path P . That is, if all the variables shared by two vertices occur in some otherpath between these vertices, the edge connecting them can be safely deleted fromthe dual graph.We denote by red.G/ the set of all the minimal reducts of a graph G, i.e., the setcontaining every graph G0 which is a reduct of G and whose set of edges is minimal (withrespect to set inclusion) over all the reducts of G. Clearly, computing a graph belonging tored.G/ is feasible in polynomial time, because one can just repeatedly delete an edge aslong as possible.It is thus natural to try to solve a nonbinary CSP I using any decomposition method DMon its dual graph:I a suitable reduct G 2 red.Gd(1) compute from Gd(2) compute a DM decomposition of the graph G;I /;278G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282(3) solve the instance I using this decomposition.For instance, BICOMP can easily be modified to be used on the dual graph of a givenhypergraph [11]. Call this dual version BICOMPd . The relationship between BICOMPdand HINGE has already been discussed in [18]: it was proved that HINGE is more generalthan BICOMPd . However, Gyssens et al. observed that a fine comparison between the twomethods is quite difficult because the performance of BICOMPd strongly depends on thesimplification applied to GdI / selected tosolve the given CSP instance I . They also argued that there is no obvious way to find asuitable simplification good enough to keep small the biconnected width of the reduct tobe used for solving the problem.I , i.e., depends on the particular graph in red.GdSince HYPERTREE strongly generalizes HINGE, it follows that HYPERTREE stronglygeneralizes BICOMPd . However, as suggested by Dechter (personal communication), itwould be interesting to compare HYPERTREE with the dual version of TCLUSTER (short:TCLUSTERd ), defined as follows. Let H be a hypergraph, and G its dual graph. Anacyclic hypergraph H(cid:3) is a TCLUSTERd decomposition of H of width w if H(cid:3) is aTCLUSTER decomposition of G0 of width w, for some reduct G0 2 red.G/. The dualtree-clustering width (short: TCLUSTERd width) of H is equal to the minimum width overthe TCLUSTERd decompositions of H.We next show that HYPERTREE strongly generalizes the TCLUSTERd method, too. Tothis end, we introduce a new class of hypergraphs. For any n > 1 let D-Clique.n/ be thehypergraph having n C 2 edges fha; hb; h1; h2; : : : ; hng defined as follows:(cid:15) ha D fXaij(cid:15) hb D fXbij(cid:15) for 1 6 i 6 n, hi D fXai(cid:0)1i ; XbWe denote by Gd .n/ the dual graph of D-Clique.n/.j 1 6 i < j 6 ng;j 1 6 i < j 6 ng;2i; : : : ; Xa1i; Xai(cid:0)1i ; Xag:iiC1; : : : ; Xbin2i; : : : ; Xb1i; XbfXbiiC1; : : : ; Xaing [Example 42. Consider the hypergraph D-Clique.4/. Its edges areh1 D fXah2 D fXah3 D fXah4 D fXaha D fXaijhb D fXbij12; Xb12; Xb13; Xb14; Xb12; Xa12; Xa13; Xa14; Xa13; Xb23; Xb23; Xb24; Xb13; Xa23; Xa23; Xa24; Xa14; Xb1424; Xb2434; Xb3434; Xb34gIgIgIgIj 1 6 i < j 6 4gIj 1 6 i < j 6 4g:Fig. 26 shows the dual graph Gd .4/. Note that this graph cannot be reduced, andhence red.Gd .4// D fGd .4/g. For instance, consider the vertices h1 and h4. Their sharedg, which clearly14. For any t =2 f1; 4; a; bg, ht \ h1 D fXa14 and Xbvariables are Xa14 =2 h1 \ hb. Thus, we cannotg. Moreover, Xbdoes not include fXa14; Xb14delete the edge fh1; h4g, and in fact no edge can be deleted from Gd .4/.14 =2 h1 \ ha and Xa1t ; Xb1tApply TCLUSTER to Gd .4/. It is already a chordal graph, therefore we can directlyidentify the maximal cliques, that form the edges of the TCLUSTER decompositionG. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282279Fig. 26. The dual graph of D-Clique.4/.Fig. 27. A hypertree decomposition of D-Clique.4/.of Gd .4/. The resulting acyclic hypergraph has the two edges fha; h1; h2; h3; h4g, andfhb; h1; h2; h3; h4g. Thus, the TCLUSTERd width of D-Clique.4/ is 5.The HYPERTREE width of D-Clique.4/ is 2. Fig. 27 shows a complete hypertreedecomposition .T ; (cid:31); (cid:21)/ of D-Clique.4/ having width 2. Observe that, exploiting the twoedges h1 and h2, even the root of T alone covers all the variables occurring in D-Clique.4/,and is in fact a hypertree decomposition of this hypergraph. To obtain the completehypertree decomposition shown in Fig. 27, the remaining edges are simply “attached” assingletons to the root.Theorem 43. TCLUSTERd (cid:30)(cid:30) HYPERTREE.n>0Proof. (HYPERTREE (cid:3) TCLUSTERd .) Consider the hypergraph class fD-Clique.n/ jn > 1g. Generalizing the above example, it is easily seen that, for any n > 3, theset red.Gd .n// is a singleton containing only the dual graph Gd .n/ of D-Clique.n/.This graph is chordal, its maximal cliques are fha; h1; : : : ; hng and fhb; h1; : : : ; hng,and hence the TCLUSTERd width of D-Clique.n/ is n C 1. Thus, for any k > 0,SfD-Clique.n/g 6(cid:18) C.TCLUSTERd ; k/, whereas the hypertree width of all thesefD-Clique.n/g (cid:18) C.hypertree; 2/. Indeed, a tree with a singlehypergraphs is 2, i.e.,vertex r with (cid:21).r/ D fha; hbg and (cid:31).r/ D ha [ hb is a hypertree decompositionof D-Clique.n/,though not complete. Fig. 27 shows what a complete hypertreedecomposition for such hypergraphs looks like.(TCLUSTERd (cid:22) HYPERTREE.) Let H0 be a TCLUSTERd decomposition of a hyper-graph H of width k. Then, H0 is an acyclic hypergraph whose edges are sets containingat most k edges from H. Any join tree JT of H0 can be mapped straightforwardly to ahypertree decomposition .T ; (cid:31); (cid:21)/ of H with the same tree-shape as JT. Every vertex pn>0S280G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282in T corresponds to a vertex p0 in JT. The vertex p0 of the join tree of H0 correspondsto a maximal clique of (some reduct of) the dual graph of H, and hence contains a set Sof edges occurring in H. Then, the vertex p in the hypertree decomposition is labeled by(cid:21).p/ D S and (cid:31).p/ D var.S/. Clearly the hypertree decomposition .T ; (cid:31); (cid:21)/ has the samewidth as the TCLUSTERd decomposition H0. 2Note that the TCLUSTERd width of H does not depend on the choice of the reductof the dual graph. The width is in fact computed using an optimal reduct of G, i.e., areduct leading to a lowest-width TCLUSTER decomposition of H. However, as observedin [18], it is not clear how to choose the right reduct in order to obtain the TCLUSTERddecomposition having the smallest width. In fact, it is currently not known whether, for afixed k, deciding whether the TCLUSTERd width of a hypergraph is at most k is feasible inpolynomial time. Thus, compared to TCLUSTERd , HYPERTREE is strongly more generaland k-bounded hypertree decompositions are efficiently computable.Clearly, the above result holds for TREEWIDTH and w(cid:3), too, given the equivalence ofthese methods (see Section 4).10. ConclusionIn this paper we have established a framework for systematically comparing structuralCSP decomposition methods with regard to their power of identifying large tractableclasses of constraints. We have compared the main decomposition methods published inthe AI literature. Moreover, we have adapted the method of hypertree decompositions,previously defined in the database context, to the CSP setting. We compared all methodsboth for CSPs of arbitrary arity and for binary CSPs. In both cases it turned out that thehypertree decomposition method is more general than the others; in the case of generalCSPs this holds even in a very strong sense. We have also shown that the method ofhypertree decompositions is more general than any dualization method which applies astandard decomposition method to the dual graph of the constraint hypergraph of a CSP. Wehave derived the upper time bound O.kI kkC1 log kI k/ for the solution of a CSP instanceI having a k-width hypertree decomposition. Note that this bound is not worse than thebound for any other considered method of CSP decompositions. Thus, it appears that themethod of hypertree decompositions is currently the most powerful CSP decompositionmethod.The comparison results and complexity bounds presented in this paper are valid forgeneral CSP instances whose domain size is unrestricted. Further work is needed both onsuitable extensions or modifications of decomposition methods and on the comparison ofthe various methods for some relevant special cases, in particular, for CSPs with a fixeddomain size. Moreover, as already remarked, both the HINGE and the BICOMP widthof a hypergraph can be computed in polynomial time even if no fixed bound is given.Thus, these methods may be useful for providing in polynomial time a “measure of thecyclicity” of any arbitrary CSP instance. For some practical applications where the givenCSP instances have large hypertree width, HINGE and BICOMP decompositions may beused for the fast identification of “easy” and “hard” modules (or clusters) of the constraintG. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282281hypergraph. Moreover, the algorithm for computing hypertree decompositions itself maysuitably be modified to identify and output clusters of low hypertree-width in case theentire hypergraph has a high width.We believe that our comparison results provide insight into the relationship of variousstandard methods of constraint decomposition. Constraint satisfaction is a very lively fieldand several new methods and techniques for decomposing and solving CSPs are expectedto be proposed in the years to come. We hope that the results of this paper, our comparisonframework, and our proof techniques will be useful to other authors for assessing therelative strength of their methods, and for comparing them to existing methods.AcknowledgementsWe thank the anonymous referees for their useful comments and suggestions.Research supported by FWF (Austrian Science Funds) under the project Z29-INF. Partof the work of Francesco Scarcello has been carried out while visiting the TechnischeUniversität Wien. Part of the work of Nicola Leone has been carried out while he was withthe Technische Universität Wien.References[1] S. Arnborg, J. Lagergren, D. Seese, Problems easy for tree-decomposable graphs, J. Algorithms 12 (1991)308–340.[2] C. Beeri, R. Fagin, D. Maier, M. Yannakakis, On the desirability of acyclic database schemes, J. ACM 30 (3)(1983) 479–513.[3] P.A. Bernstein, N. Goodman, The power of natural semijoins, SIAM J. Comput. 10 (4) (1981) 751–771.[4] W. Bibel, Constraint satisfaction from a deductive viewpoint, Artificial Intelligence 35 (1988) 401–413.[5] H.L. Bodlaender, Treewidth: Algorithmic techniques and results, in: Proc. MFCS-97, Bratislava, LectureNotes in Computer Science, Vol. 1295, Springer, Berlin, 1997, pp. 19–36.[6] Ch. Chekuri, A. Rajaraman, Conjunctive query containment revisited, Theoret. Comput. Sci. 239 (2) (2000)211–229.[7] R. Dechter, Constraint networks, in: Encyclopedia of Artificial Intelligence, 2nd edn., Wiley, New York,1992, pp. 276–285.[8] R. Dechter, J. Pearl, Network based heuristics for constraint satisfaction problems, Artificial Intelli-gence 34 (1) (1988) 1–38.[9] R. Dechter, J. Pearl, Tree clustering for constraint networks, Artificial Intelligence 38 (1989) 353–366.[10] E.C. Freuder, A sufficient condition for backtrack-free search, J. ACM 29 (1) (1982) 24–32.[11] E.C. Freuder, A sufficient condition for backtrack-bounded search, J. ACM 32 (4) (1985) 755–761.[12] E.C. Freuder, Complexity of k-tree structured constraint satisfaction problems, Proc. AAAI-90, Boston,MA, 1990.[13] M.R. Garey, D.S. Johnson, Computers and Intractability. A Guide to the Theory of NP-completeness,Freeman, New York, NY, 1979.[14] N. Goodman, O. Shmueli, Syntactic characterization of tree database schemas, J. ACM 30 (4) 767–786.[15] G. Gottlob, N. Leone, F. Scarcello, The complexity of acyclic conjunctive queries, in: Proc. FOCS-98, PaloAlto, CA, 1998, pp. 706–715. Full version: Technical Report DBAI-TR-98/17, available on the web as:http://www.dbai.tuwien.ac.at/staff/gottlob/acyclic.ps, or by email from the authors.[16] G. Gottlob, N. Leone, F. Scarcello, Hypertree decompositions and tractable queries, in: Proc. PODS-99,Philadelphia, PA, 1999. Full version to appear in Journal of Computer and System Sciences. A preprint ofthe full version is currently stored in The Computer Research Repository, http://xxx.lanl.gov/archive/cs.282G. Gottlob et al. / Artificial Intelligence 124 (2000) 243–282[17] G. Gottlob, N. Leone, F. Scarcello, On tractable queries and constraints, in: Proc. Conference on Databaseand Expert Systems Applications DEXA-99, Florence, Lecture Notes in Computer Science, Vol. 1677,Springer, Berlin, 1999, pp. 1–15.[18] M. Gyssens, P.G. Jeavons, D.A. Cohen, Decomposing constraint satisfaction problems using databasetechniques, Artificial Intelligence 66 (1994) 57–89.[19] M. Gyssens, J. Paredaens, A decomposition methodology for cyclic databases, in: Advances in DatabaseTheory, Vol. 2, Plenum Press, New York, 1984, pp. 85–122.[20] P. Jeavons, D. Cohen, M. Gyssens, Closure properties of constraints, J. ACM 44 (4) (1997).[21] Ph.G. Kolaitis, M.Y. Vardi, Conjunctive-query containment and constraint satisfaction, in: Proc. Symp.on Principles of Database Systems (PODS-98) Seattle, WA, 1998, pp. 205–213. Full version to appearin Journal of Computer and System Sciences.[22] D. Maier, The Theory of Relational Databases, Computer Science Press, Rockville, MD, 1986.[23] J. Pearson, P.G. Jeavons, A Survey of Tractable Constraint Satisfaction Problems, CSD-TR-97-15, RoyalHolloway, University of London, London, 1997.[24] N. Robertson, P.D. Seymour, Graph Minors II. Algorithmic aspects of tree width, J. Algorithms 7 (1986)309–322.[25] R. Seidel, A new method for solving constraint satisfaction problems, in: Proc. IJCAI-81, Vancouver, BC,1981.[26] M. Yannakakis, Algorithms for acyclic database schemes, in: C. Zaniolo, C. Delobel (Eds.), Proc. Internat.Conference on Very Large Data Bases (VLDB-81), Cannes, France, 1981, pp. 82–94.