Artificial Intelligence 78 ( 1995) 289-326 Artificial Intelligence Recognition of object classes from range data I.D. Reid*, J.M. Brady Department of Engineering Science, lJniversi@ of Oxford, Oxford OXI 3PJ, UK Received September 1993; revised October 1994 Abstract We develop techniques for recognizing instances of 3D object classes (which may consist of multiple and/or repeated sub-parts with internal degrees of freedom, linked by parameterized transformations), from sets of 3D feature observations. Recognition of a class instance is structured as a search of an interpretation tree in which geometric constraints on pairs of sensed features not only prune the tree, but are used to determine upper and lower bounds on the model parameter values of the instance. A real-valued constraint propagation network unifies the representations of the model parameters, model constraints and feature constraints, and provides a simple and effective mechanism for accessing and updating parameter values. Recognition of objects with multiple internal degrees of freedom, including non-uniform scaling and stretching, articulations, and sub-part repetitions, is demonstrated and analysed for two differ- ent types of real range data: 3D edge fragments from a stereo vision system, and position/surface normal data derived from planar patches extracted from a range image. Keywords: Object recognition; Parametric objects; Range data; Stereo 1. Introduction Consider a robot performing a task in an unknown or partially known environment. If it is to react to that environment in other than a haphazard “trial-and-error” fashion, the robot must learn about its surroundings using sensed data. Perhaps the simplest requirement is to avoid obstacles; for this task the robot need know nothing more about obstacles than roughly their positions and extents. A considerably more complicated task involves finding and manipulating a specific object in the environment. In this case the robot must not only locate an object, but also recognize it. Recognition demands the use of both sensed data and prior knowledge about the object in order to detect its * Telephone: +44-1865 273168. Fax: +44-1865 273908. E-mail: ian@uk.ac.ox.robots. 0004-3702/95/$09.50 SSDIOOO4-3702(95)00062-3 @ 1995 Elsevier Science B.V. All rights reserved 290 I.D. Reid, J.M. Rrud.v/Artijbal Intelligence 7X (1995) 289-326 Fig. I Two typical pallets. The one the left is considerably pallet has five slats and three struts. larger and has six slats and four struts. The smaller presence, and to determine model-based vision paradigm addresses just this problem. its pose (position and orientation) relative to the sensor. The Model-based vision embraces a class of techniques which achieve object recognition by encoding objects’ observable “best interpretation” lates the problem as one of finding or edges), determining tween a transformation sensor(s). Such a formulation involves The paradigm those of representation, uncertainty. these features and object high-level prior knowledge about objects properties, of a scene, given and comparing the sensed data. A common in models which describe the the models with sensed data to find a formu- in sensory data (such as surfaces be- to certain matching constraints) approach low-level features correspondences (subject represented features tits into a class known as constraint some of the major research problems search strategies, interpretation in a model, and then computing to the reference frame of the satisfaction problems. intelligence; of sensory data, and handling in artificial from a model-centred reference frame fixed objects systems built to date-whether range data-have The vast majority of recognition views of objects, or three-dimensional they use single to (e.g. [ 8, 15,22,24] ) or objects with only a few intensity operate with geometrically internal degrees of freedom applied involve cannot be defined a priori. A good example of such, and which has motivated research we report, is the use of a mobile vehicle Fig. 1 depicts two such items, clearly showing [ 14, 19,401. While such systems have been successfully tasks, many other applications for which a fixed geometry the to locate and acquire industrial pallets. to the same they belong that although to a number of useful the need to recognize members of object classes robotic and automation been designed I.D. Reid, J.M. Brady/Art$icial Intelligence 78 (1995) 289-326 291 they vary considerably object class, they have. Such object classes are common, particularly Most of the systems mentioned necessitate a separate model. are unsuitable in size, shape, and in the number of slats and struts in man-made environments. since each variation within a class would To address system for recognizing this deficiency we develop a 3D recognition poly- hedral objects which may have multiple and repeated sub-parts which may move relative free parameters. Our system to one another, each of which may have multiple either 3D line segment data (from, takes as input a set of primitive (for for example, example, a laser range triangulation the pose of an instance of a model class, at the same time placing upper and lower bounds on the parameter values noise and occlusion. Furthermore, of the instance, between different an additional instances of the same class. a stereo vision system) or surface patch data from a range the presence of significant allows level of competence features-currently to distinguish system)-and the system determines internal despite finder The system is based on three techniques, well established in their own right in the literature: tree search l interpretation l binary geometric constraints l a continuous-valued [ 171; [20] ; constraint propagation network [ 141. The use of the first two items ticularly (or assignments) with those already viewpoint-invariant and bounds on these measurements in [ 20 1. Interpretations-branches features of observed in the interpretation. measurements in recognition systems has been well documented, par- grown by adding matches to model features which are pairwise consistent of the tree-are Pairwise consistency (such as angles and distances) precomputed from a model. is defined using a set of on pairs of features, Our system is designed to use either surface patch data normal or straight 3D edge fragments. For either a pair of surface patches or a pair consisting of one angle and in in our system are given invariants, The sets of invariants used there exist four independent (position/surface points) of edge fragments, three distance measurements. Appendix A. through the combination [ 61, who, in the ACRONYM constraints. So-called SUP/INF is a powerful way of representing The novelty of our system comes for object recognition. A set of inequality of the first two items and solving sets of networks were developed by Fisher and Orr above with the third item, which inequality [ 14 3 based on the work of Brooks of 3D models from 2D images, was the first to introduce satisfaction the viewing parameters was solved symbolically to give the pose and internal parameters of an instance of a parametric object class. Fisher and Orr’s development was to show how much of the work involved can be performed off-line constraint propagation network. by compiling They used the resulting networks internal in performance over the transformations purely symbolic system for recognition the idea of symbolic constraint constraints on the model and on in such symbolic manipulation into a real-valued such as articulations, approach of ACRONYM. to solve for object pose and some (limited) gaining an improvement the symbolic constraints For linear constraints, the SUP/INF method is guaranteed However the major weakness of both the Brooks and the Fisher/Orr to give a correct solution. is that approaches 292 I.D. Reid, J.M. Brady/Artijicial Intelligence 78 (1995) 289-326 H W Fig. 2. A model class of equal volume boxes: (a) a parametecization and constraints; (b) model surfaces. on object pose result constraints poor (sometimes useless) bounds on the pose transformation work Orr et al. have argued uncertainty than in order to obtain more realistic pose computations for a probabilistic in complex nonlinear rather inequalities which often lead to in later of Indeed representation parameters. interval [ 301. In our method, the pose computation are separated. and internal parameter estimation is used to store internal model parameter values (upper and lower and define relations between parameters, which are updated and propagated as The constraint network bounds) an interpretation grows. This parameter as we show in later sections. However using a two-stage which rotation the benefits of the SUP/INF [ 111 followed by a best-fit is performed is ideally suited to the application, representation the network is not used for pose computation, least-squares method by first finding a best-fit [ 151. This trade-off makes full use of from its major drawback. translation network without suffering Prior to give the reader an intuitive in order the general principles by example. Consider by to detailed description, feel for the system’s operation, we illustrate the class its three of equal volume boxes depicted free parameters, H, W and D, the height, width and depth of the box. Here, the angles the surfaces are constant values, independent of the model parameters. However, between the distance d of a point on the top surface from the plane defined by the for example, (invariant fi for surfaces, surf-dist-1, is constrained by front surface 0 6 d < 0, where D is the depth of the box, initially unknown. in Fig. 2. This class in Appendix A) is characterized We draw two major insights from this, which form the basis for the remainder of this work. These are: is a symbolic bound. Algorithms less efficiently exist for solving sets of than numeric ones; we exploit one such symbolic l d E [0, DJ equations, method albeit rather in our algorithm. l The measurement that D > d; namely value of D. actually gives information i.e. the measurement about the unknown parameter value, d provides a lower bound on the true Suppose then, that the system is exploring in Fig. 3. At Level 2 of the tree the assignment the branch of the interpretation s1 -+ ,UO is considered. Initially tree shown there is I.D. Reid, J&f. Brady/Artificial Intelligence 78 (1995) 289-326 293 Level 1 Level 2 Level 3 Fig. 3. Constraining the interpretation tree search and parameter values: (a) observations from a box instance; (b) exploration of the interpretation tree. no knowledge of the parameter values, i.e.: Initially: WE [O,ca], HE [O,cml, DE [O,col. Three distance invariants with values 1, 0.5 and 4 may be computed from the pair of surface patch observations so and si (see Fig. 3 and Appendix A). Therefore the pairwise consistency of the matches so -+ ~1, si + ,CQ is determined by the three expressions: Test: 1 E [O,ool, 0.5 E [O,col, 4 E [O,co], which are all clearly satisfied. The match si -+ ,LQ is therefore accepted, but we now note that this match implies that W 3 1, H > 0.5 and D > 4, thus the lower bounds can be updated: Update: w E [l,ool, HE [0.5,co], D E [4,m]. Furthermore, once this update from the observations is complete, enforcement of the model constraint WHD = 10 (i.e. the equal volume condition, which is equivalent to the two conditions WHD 3 10 and WHD < 10) leads to upper bound estimates for the parameters: Propagate: W 6 lO/HD =+ W 6 5, H 6 lO/WD + H < 2.5, D < lO/WH =+ D 6 20. so WE [1,51, HE [0.5,2.5], D E [4,20]. Subsequent assignments (e.g. s2 -+ ,u2) provide further evidence of the parameter values, gradually improving the bounds. Thus our system is based around an observe-test-update cycle, in which we test an observation for consistency with the current size/shape estimate of the model, and if consistent, use the observation to update the estimates of size/shape. In the following sections these ideas are formalized and generalized, and used to build a general-purpose parametric object recognition system. 294 1.1). Keid. J.M. Hrudy/Art$cial fnielligence 78 (1995) 289-326 in Section 4, we show how different and identified. Secondly, Initially we consider of one part. However Firstly, distinguished sub-parts multiple give a performance compares work in the context of previous efforts in Section 7 and conclude the case of finding an instance of a single object class consisting in a number of ways. in later sections we extend instances of the same object class may be in Section 5 we show how the system copes with and even variable numbers of repetitions of sub-parts. Finally, we analysis of the system favourably with systems which enforce (Section 6) and show that the performance rigidity. We place in Section 8. strict model the system the 2. Principles 2. I. Interpretaticm tree search systems (e.g. [5,11,21,23,24]). the basis of‘ our system tree, using geometric constraints is the well known hypothesize/test level, to most recognition At the highest paradigm common for pruning, generates pairwise consistent interpretation from these matches of sensed features matches. Previously, Grimson fixed objects, binary geometric constraints between pairs of data to model feature matches are a surprisingly powerful tree. Usually to a handful; often only the number of hypotheses which must be tested the case even for one. A major contribution parameterized to model features and computes a pose hypothesis of our work is to show that this is still [ 201 has shown that for geometrically search space of the interpretation tool for pruning A search of an the exponential is reduced objects Formally, an object (see Section 6). is modelled by a set M of m model features, (e.g. the object’s surfaces or edges): When observed in the world an object gives rise to a set S of n sensed features: /=I (Oxford/NEL) In our work we consider either Only rarely will a full model feature be observed. More typically, due to occlusion and noise, only a portion of the feature will be observed; e.g. a small surface patch or an type of input data: either surface data edge fragment. or 3D edge fragments from our in-house [ 3 I I. Surface data are represented by a 3D position and unit from a stereo vision system surface normal, the dense range maps supplied by the Oxford/NEL about surface extent in Section 3.5. Edge data are represented by a this further and connectivity. We discuss set of edge fragments, is its midpoint, m Then, we define: s = (e, M, I) ; e is a unit vector in the direction of the fragment, s = (p, n). This representation sensor give information and 1 is the fragment is rather conservative laser range finder [33,35], length. since I.D. Reid, J.M. Brady/Art$cial Intelligence 78 (1995) 289-326 295 features Definition 1. An image measurement or measurable invariant is a function maps a set of observable we make use of binary measurements general several such independent measurements {fk}. For pairs of either surface patches four independent f which In our work and in are available, with this set denoted by (e, m, I), there exist invariants. We list those used in our system to a scalar, independent of the viewpoint. (p, n) or edge fragments from a pair of features), in Appendix A. invariants (i.e. to a pair of observations Consider applying the kth invariant features. As the locations of the observations value of the invariant. Thus each pair of model features generates an interval giving valid range of the kth invariant u E ,U to denote an observation normal point on a model surface) we can formalize (for example, a position/surface the definition of this valid range: on a pair of model vary over the model features, so will the the If we use the notation for that pair of model features. on a model feature Definition 2. Thefeature constraint interval for the kth invariant and the model features pi and p,j is given by This interval can be precomputed of parameterized models, parameters. is a function of the model. For geometrically as part of the object model as was done they will often be known fixed objects, these intervals the case in [21]. functions of the unknown model In Definition 3. A feature constraint table (or FCT) intervals for feature constraint in which entry is a convenient (i, j) of table k refers storage method to the interval zk(b‘i, pi). Definition 4. A feature constraint is a constraint sensed features to a pair of model features, st ---f pi, ~2 -+ pj: on a potential match of a pair of The left-hand right-hand invariant for all invariants, side of the expression side is the feature constraint from observations. The is true if the measured the valid range for the pair of model features pi and pj and if true derived interval. The expression is a measurement lies within then the match is consistent. test which accounts /Lj) given an uncertain In practice sensing errors mean s^. A consistency zk(pi, system we use the method of [ 2 1 ] to model errors, by constructing around constraint that a sensed feature s is a corruption of a true value test the likelihood of fk ($1, $2) E fk( St, ~2). In Our an interval Fk ( SI , ~2) the kth feature test: for the potential match st -+ ,~i, s2 --f pj becomes (but hopefully nearby) measurement the true value. Then, fk(st, ~2) which the intersection for this must to contain is known Fk(St 5 SZ) n zk(,%* Pjui) z 8. 296 I.D. Reid. J.M. Brudy/Artijicial Intelligence 78 (1995) 289-326 interpret(f,j) ,- if j = II verify(l); return; i - 0; while i < m if consistent(l,{ S,j,p;}) 1 + 1 U (Sj3 pu,} interpret(f,,j + 1) i i--i+1 ! return; Fig. 4. Pseudo-code feature matches the call interpret({},O). for a recursive version of the interpretation representing the current interpretation. to model tree search. I is a list of data feature and j is the level in the tree. The search begins with the interpretation in Fig. 4. The function Given these definitions, tree search for geometrically consistent fixed objects applies the for dealing [20] shows how this may be overcome by to the search which always matches, however at the can be described by the pseudo-code rule in the equation above. The reader will note that there is no mechanism with outlying data in this search. Grimson adding a so-called “null” expense of greatly we discuss ways in which the problem research. the size of the search. In Section 7 and in the conclusions the outlier and clutter problem may be overcome. However the subject of on-going in the work we report, this being is not addressed increasing feature 2.2. Model representation The previous section has established the familiar either 3D edge fragments or surface patches which uses binary geometric to control an interpretation this framework specific definition of an object class suited to many parametric object recognition and then discuss of the framework described above with respect definition. It should be clear, however, generic objects. from constraints that as it stands, In this section we give a tasks, to this for recognizing for recognition the limitations is insufficient tree search. framework 2.2.1. Object classes We model an object class using: l a set of sub-parts, each with a REV-graph boundary faces, edges and vertices of the sub-part, and the topological them; each sub-part is defined relative sociated to the model base-frame; to a local coordinate (possibly parameterized) which defines its position transformation representation i.e. the [2], relationships between system, and has an as- relative I.D. Reid, J.M. Brady/Artificial Intelligence 78 (1995) 289-326 297 l a set of internal model parameters; l a set of constraints on the parameters, called model constraints; l a set of feature constraint tables which store information about the geometrical relationships between pairs of model features (including those which do not come from the same sub-part) ; l a specialization hierarchy, with each sub-level of the hierarchy corresponding to a specialization of the parent through the addition of extra model constraints, active for that sub-model and all its children. Multiple and repeated sub-parts are allowed, including parameterized numbers of repe- titions. We discuss recognition of multiple sub-part objects with parameterized tmnsfor- mations between sub-parts and those with parameterized part repetitions in Section 5. We now discuss the salient features of the representation and elaborate on its various aspects. The REV-graph of the object is used to define the underlying shape of the object. The planar equations of the surfaces, the directions of the edges, and the positions of the vertices, stored with the REV-graph, are all functions of the model parameters. For example in the box example of Fig. 2 the vertices would be described by the coordinates {(O,O,O), (O,O,D), (w,H,O)}. (w,O,D), (O,H,D), (%O,O), (O,KO), (KH,D), If the model is geometrically fixed then we have numeric values for W, H and D and it is straightforward to compute numeric upper and lower bounds on the binary invariants for storage in feature constraint tables (see Section 2.1). However, if the boundary features are functions of unknown parameters this computation must be performed symbolically, and entries in the feature constraint tables must be uninstantiated symbols rather than numbers. We discuss this in Section 3.1. Model constraints are inequalities involving one or more of the model parameters (note that equalities may be represented by two inequalities). They are used for two separate purposes: l to enforce dependencies between parameters; l to impose size/shape constraints on the model. Consider the square pyramid class shown in Fig. 5. A possible parameterization of the class is the set (6, h, 8). This parameterization is not independent, containing the implicit constraint tan B = 2h/b. This is an example of the former use of model constraints. An example of the latter is the constraint 3h > 6, which restricts the shape of the class somewhat. It should be clear that the mechanisms described in the preceding sub-sections (based on the work of Grimson and others) are incapable of recognizing instances of such a model class. Models can no longer be represented by constant feature constraint tables; the bounds are now functions of the uninstantiated model parameters. For example, if we define a class which is fixed but for a uniform scale factor, o (the simplest possible parameterization), then each distance constraint now involves the unknown value of the parameter ff. However, as we observed in the introduction, the invariant measurements are functions of the parameters of the instance being observed and, in principle, we should be able to recover the model parameters from observed data during the interpretation tree search. Grimson [ 20,221, in extensions to the RAF system [ 2 11, describes a method for coping 298 I.D. Reid, J.M. Brudy/Art#cial Intelligence 78 (1995) 289-326 Fig. 5. A square pyramid class. parameterized by the set {h, h, B}. with simple parameterizations-uniform of 2D models. The method measurements arbitrary parameterizations 4231 that, and modifying scale and stretching and simple articulations- involves solving for parameter values explicitly the search algorithm accordingly. The generalization and 3D models was never achieved. Grimson from image to states [20, p. The main difficulty constraints, updating of feasible especially . . is finding a clean way of representing the parameterized in a manner that will easily allow the computing and ranges for each of the parameters. In summary, parameterizations the extensions are: required in order to cope with arbitrary and compound l a representation l a way of defining and representing l a way of computing symbolic feature constraint for model parameters; constraints on model parameters; tables off-line and then instantiating these at run-time; l a way of updating parameter estimates based on sensed data (specifically, from invariant values) ; l a way of determining To this end we next present a representation if the constraints have been violated. for parameters based upon Fisher’s network In addition enough and other linear and nonlinear to handling to specify arbitrary scaling (not only uniform scaling) constraints on model parameters. implementation [ 12-141 of the SUP/INF method all the cases Grimson describes, the representation and model constraints [4,6]. is general in full 3D, articulations 2.3. SUPANF algorithm The SUP/INF algorithm, devised by Bledsoe [ 41 and refined by Brooks [ 6,7], is a method for solving symbolically a set of inequality constraints. It is based on recursive I.D. Reid, J.M. Brady/Artificial Intelligence 78 (1995) 289-326 299 application and lower bounds, algorithm what ranges of the variables of two functions, and inf (Infimum), which find upper in the constraints. The goal of the is to determine whether or not a solution can be achieved, and if so, over respectively, on the free variables sup (Supremum) the constraints can be satisfied. first used this algorithm Brooks from 2D data. 3D objects as a constraint satisfaction viewing parameters. A constraint manipulation symbolically In ACRONYM problem involving in the ACRONYM system [6] for recognition of the recognition constraints problem was formulated the model and on the on system (CMS) evaluated the constraints at run-time using ribbon cues extracted from an image. The principle behind x < (expr) means The SUP/INF method recursively and sups and infs of atoms; e.g. that (expr) is an upper bound for x, or equivalently, the operation of the CMS is as follows. An inequality of the form supx = sup(expr). applies sup and inf to (expr) until it consists of atoms * * supx = sup-y supx = -infy. there is encountered if the system determines An inconsistency in which case algorithm produces both necessary and sufficient conditions introduction no longer a sufficient to the inequalities means (though still necessary) is no solution of nonlinearity condition. to the problem. For sets of linear inequalities that supx < infx for a solution, however that the result of the algorithm for any x, the the is The nature of the measurable invariants attractive, since the knowledge of upper and lower bounds on variables We have developed a CMS based on Brooks’ rule-base metric functions, using takes a set of model parameters, substitutions out in Section 2.2 may be implemented symbol NaN denotes “undefined”). in our domain makes the use of this algorithm is made explicit. for trigono- [42]. The system and applies strategic laid in Table 1 (the to obtain simplifications where possible. The type of parameterizations and model and feature constraints the symbolic manipulation the operator set described [6] with extensions tool Mathematics using symbolic is slow-this, computation, Unfortunately, as with most automatic evaluation of the ex- indeed, was a major drawback of ACRONYM. Fisher and Orr the much of the cost to an off-line procedure; pressions constraints [ 141 showed how to transfer are reduced off-line by a CMS as much as possible without knowing variable values and then compiled constraint expressions. A SUP/INF from nodes and directed arcs, where each node is one of: 0 a constant; l a variable, V, with associated l an operator which performs a given operation on its input(s). into a network whose topology derives from the SUP/INF [ inf V , sup V] ; network is built interval set in a network The allowable operator reciprocal, min, max, sqrt, the three main integer to ensure functions the constants and NaN. rounding (used fco is as above, i.e.: f, -, *, reciprocal, trigonometric that integer variables functions and their remain integral) signed inverses, and 300 Table I Operator set Operation Minimum Maximum Unary minus Addition Subtraction Multiplication Square root Reciprocal I.D. Reid. J.M. Br&/Artificial Intelligence 78 (1995) 289-326 Domain Sup/ lnf supmin{x,,v} = min{supx,suPv} infminlx, v} = minfinfx. inf v1 supmax{r,v} = max{supx, supy} infmax{x, y} = max{infx,infy} sup --x = - inf x inf -x = - swx SUP(X + v) = supx + supy inf( x + v) = infx + inf v sup(x - v) = supx - inf,v inf( x -. v) = infx - sup y sup xv = max{inf x inf y, inf x sup y. sup x inf y, sup x sup y} inf xx = min{inf x inf .v. inf x sup y. sup x inf y. sup x sup y} If inf.1 i 0 Then NaN Else sup ~5 = &i@ inf&= %I&& supl/x= I/infx infI/x= I/supx Signed reciprocal If 0 E linfx,supx] Then NaN Else inf 1 /x = I / sup x supl/x = l/infx Sine x E I-7r.xI If ~r/2 E [infx,supx] Then sup sin x = I Else If -r/2 sup sin x = max{ sin inf x, sin sup x} E ] inf n, supx] Then inf sin x = -I Else infsin x = midsin infx. sin SUD xl Cosine xE I-7r.7rI If 0 E Iinfx,supx] Then supcosx = 1 Else sup cos x = max{cosinf x, cos sup x) infcosx = min(cosinfx.cossuDx1 Tangent YE I-?7,7rl If +rr/2 E Iinfx,supxl Then NaN Else sup tan x = tan sup x inftanx = taninfx If a variable’s bounds change, the change is propagated via the network requires variables. Convergence infy = max{infy,inff(x)} only ever improve. A further requirement to interrupt asymptotic convergence. that bounds on each variable y = f(x) and supy =min{supy,supf(x)}. This ensures is that there be a small, but nonzero to other be evaluated as that bounds threshold, I.D. Reid, J.M. Brady/Artificial Intelligence 78 (1995) 289-326 301 Operation Aresine Domain L-T, %-I (Range) F--r. PI (Range) I--~>~1 (Range) Arccosine Arctangent Integer Sup/Inf If 0 E [infx,supx] Then sup arcsin x = P - arcsin sup n inf arcsin n = -7r + arcsin inf x If infx > 0 Then sup arcsin x = ?r - arcsin inf x inf arcsin x = arcsin inf x If supx < 0 Then suparcsin x = arcsin sup n inf arcsin x = -w + arcsin SUD n sup arccos x = arccos inf x inf arccos x = - arccos inf x If 0 E [infx,supn] Then sup arctan x = R + arctan inf x inf arctan x = arctan inf x If infx > 0 Then sup arctan x = arctan sup .r inf arctan n = -37 + arctan infx If supx < 0 Then sup arctan n = ?r + urctan sup x inf arctan n = arctan inf x supint x = [supx] infint n = rinfxl 3. Coping with parameterizations We now show how the SUP/INF algorithm and SUP/INF networks may be used to satisfy the five requirements laid out in Section 2.2. 3.1. Feature constraint tables from geometrically The generation of FCTs significantly more difficult functions of the parameters which are not necessarily feature constraint entries. For each feature constraint compute fixed models for parameterized models because is a simple matter. It is are until run-time. Our (where possible) and symbolic fk and for each pair of features pi and pj we must tables therefore consist of both numeric the feature constraints the interval quantifiable For example, consider the feature constraint surf-dist-2 A) applied to a pair of surfaces ~1 and ~2 shown (see invariant fs in Appendix in Fig. 6. The inf and sup for this 302 I.D. Reid. J.M. Brady/Artijiicrul lntellip!nce 78 (1995) 289-326 Fig. 6. ‘rho parxm~ric model surfaces measurement-i.e. the upper and lower bounds on the interval Z~(,LL~ ,,uz)-are given by :; {~uoo--us) .n2,( UI --zy) .n2.(z’2 ~- US) .n2,(u7 -us) .n2}. Upon substitution bolically (off-line) for vertex coordinates by the CMS using the constraints: and face equations, they are simplified sym- w, w’, w 3 0, 0 < 8 < n-12. w = M’ + w’. /z/w’ = tan 0 to the expressions 0. w sin 8. If an expression is not atomic created, and a new model constraint a variable table for surf-dist-2 are 0 and II, indicating that (I and add the constraint U = wsin 0. The entries (as is the case for w sine) is added to the model. For example, we would create in the feature constraint then a new variable inf&(~l,kb2) =O, SUPZ3(~l>~2) =supIl. I.D. Reid, J.M. Brady/Art@cial Intelligence 78 (1995) 289-326 303 Fig. 7. A sample network, generated from the constraint 3h > b. 3.2. Model parameters and constraints Parameter values at run-time, and the constraints between a SUP/INF created during FCT construction. Network paths represent: network. Model parameters are variables them, are represented using in the network, as are the variables l the functions that relate the FCT entries to the model parameters (see the example in the previous sub-section, U = w sin 6); l implicit constraints between dependent model parameters (see the example in Sec- tion 2.2, tan 0 = 2h/b); l other model constraints 3h 2 b). for model restrictions (see the example in Section 2.2, This latter constraint would be parsed and simplified to the two equations h > fb =+ infh = iinfb, b<3h+supb=3suph. and compiled to the network shown in Fig. 7. 3.3. Algorithm is a dynamic if they are found structure, growing as consistent assignments the topology) network hold the current estimates of the parameter values and feature tree. Fig. 8 shows a recursive version for the current state of the interpretation to be inconsistent. The variables in tree The interpretation are added and shrinking (static constraints of the modified Consistency interpretation of assignments tree search algorithm, explained sr -+ pi, s2 + pj is checked in further detail below. (by function consistent) by enforcing each of the feature constraints Fk(st,s2) n [infL,supUl Z 0, the L and U variables where their sup and inf are readily available. Note that L and U need not refer to the same variable; a measurement may be bounded below by one parameter and above by another. are the appropriate FCT entries, and therefore 304 I.D. Reid, J.M. Brud~/Artijicial Intelligence 78 (1995) 289-326 interpret(f,Rj) if ,j = 0 verifytl, P); return; [ i - 0; while i < HI if COnSiStent(l,P,{s,,,lIi}) P’ -- update(/,{.si,pui}, P) if P’ f 8 I- 1 lJ (s,, p,} interpret( I, P’, j f 1) I I i-i+1 return: for interpretation the modified Fig. 8. Pseudo-code same as in Fig. 4. The major difference multi-dimensional the consistency to the current network the upper and lower bounds of a network variable crossed during network is the is the addition of P, the current network state, which describes a satisfies the update rules given in the text that space. The function consistent in the text. The new function update to converge. The condition P’ = 0 represents the basic structure of the search rectangular test described true if each feature constraint state and then allows tree search: the network iteration. applies returns If an assignment derived from it are used the network. The lower bound L must be less than the measured value, so a then the image measurements is consistent to update correct update for L is: supL = min{supL,sup F~(.sI, ~2) 1 and the upper bound must be greater U is: than the measured value, so a correct update for in the update Including the previous values remain stable or improve. Thus progressive measurements invariant measurement, network. and then propagates are performed. The function update rule ensures that bounds can only ever refinements of the legal bounds of the image the updates above for each in the to all other variables the effects performs If, at any stage, a variable’s bounds cross, and the interpretation the search proceeds downwards with the new improved model parameter constraint tree search backtracks. then an inconsistency found If not, once the network has converged, and feature has been estimates. Thus we have satisfied constraints at run-time, and that we provide a mechanism measurements. the requirements the feature that we be able to determine when constraints have been violated, for updating parameter estimates based on the image that we be able to determine I.D. Reid, J.M. Brady/Artificial Intelligence 78 (1995) 289-326 305 hl Fig. 9. A parameterization for a chimney object. After the interpretation tree search, each complete branch of the tree constitutes a a best-fit translation least-squares rotation using by ACRONYM [ 15,281. Finding the pose via least-squares and by Fisher’s system IMAGINE which both attempt approach the quaternion method of [ 111, followed by the problems feasible hypothesis. The pose is then computed using a two-stage by first finding a best-fit encountered solve for pose using by the pose computation pose parameters. Our method provides a compromise recovers computation tasks making use of the results of recognition. Further details, and descriptions hypothesis verification procedures used may be found in [ 341. to imposed often result in poor or even useless bounds being placed on the the SUP/INF method pose the least-squares provides a stable, accurate pose estimate which is crucial for any subsequent in which it is well suited, while the SUP/INF method. The complex nonlinear internal parameters, constraints to which of the avoids 3.4. System operation We now present an example of the system in operation. Fig. 9 depicts a class of chimney objects. The class is parameterized by the set: size parameters. A synthetic in Fig. 10(a), and six position/surface two angle and fourteen class is shown range data are indicated by small vectors and a point number, Uncertainty computed parameter than noise. is due only to slight aliasing effects; is attributable in these points ranges normal data estimated i, for observation image of an instance of the from the (pi, ni), in the rather thus uncertainty to a lack of evidence almost entirely range 306 I.D. Reid, J.M. Brady/Artificial intel&ence 78 (1995) 289-326 I 0.00 0.40 0.80 1 .‘O I .60 hl. 112. h3, 114: w I : W?: w3, ,.I w5. ~6: - (a) (bf Fig. IO. Chimney recognition: (a) a range image with position/surface normal data extracted, and the computed pose/size superimposed; (b) the computed parameter ranges. Legal interpretations for these data, and valid parameter search and network propagation the constrained tions. Four legal interpretations were found corresponding principal tation). axis, thus they are all equivalent algorithm described ranges were derived using sec- the interpre- in previous around to the symmetries (i.e. there is only one truly unique A wireframe for the class instance IO(a) ) . The parameter lO( b). Intervals is shown superimposed on the range in ranges for the distance parameters are 8 and cy, were for the angle parameters, image the computed pose (Fig. shown graphically computed to be: in Fig. B E [2.585,2.650] (true value = 5~/6 zz 2.618), LY E [ 2.255,2.461] (true value = 37~/4 M 2.356). In some cases very good bounds have been computed; the surf-dist-2 for example, e.g. dj, h3, ~2. We can see feature constraint (invariant why this is so by considering, fs) applied to the matches SO + ,UO. s:! -+ ,Us, which results in the constraints [infh3,suph?l nJ?(so,s2) + 0, where F3 ( SO, ~2) is the error interval around the updates the measurement n2. (p. - p2), and hence infhs = max(infhs, infFs(sa,ST)), sup h3 = min{sup h3, sup F3( so, ~2)). I.D. Reid, J.M. BradyIArtijCcial Intelligence 78 (1995) 289-326 307 Thus h3 can be determined up to some small error. The final computed range was h3 E [0.068,0.088] (true value = 0.075). However for many other parameters found. Consider the lower bound the parameter dt . Here, surf-dist-1 is a poor estimate, and no (invariant upper bound has been f2) applied to the matches SO -+ ~0, ss --) ~1 gives the constraint [infMdl,Ol flF2(~5,~0) + 0, where Mdt is a variable defined such that Mdt = -dt around the measurement n5 . (p. - p5), hence the subsequent update and F2 (ss, so) is the error interval is: sup Mdl = min{sup Mdl, supF2 (~5, SO)}. The final range for Mdl was [ -00, -0.351 and hence for dl: dl E [0.35,x1] (true value = 0.45). 3.5. Improving parameter bounds Grimson and Lozano-Perez [ 2 1 ] first advocated features in order to avoid the problems caused by noise, occlusion and deficiencies it is a minimalist the use of sparse point-based to over-segmentation. Because leading invariants algorithms, and because for recognition in segmentation representation match to the same model surface) major advantage of this data representation elegant is that it leads example, in Fig. 10 clearly shows reason for the conservative not a particularly good representation to the search strategy can compensate for points which in many cases the computed Firstly, the IT search is data-driven it copes with data fragmentation (i.e. multiple observations may gracefully. A second simple and is that it leads and feature constraints. However a drawback of the representation to convenient, to the computation bounds. For range for dl is [ 0.35, co], while inspection of the range image be computed. The is tighter bounds could potentially bounds stems from the fact that a position/surface of overly conservative that much normal of a large surface. Fortunately, minor extensions for the representational deficiencies. the search, simply by requiring lie on the same observed surface patch, a connectivity con- that they all match to the same the patch entirely, and these will lower bound size estimates. As well as improving parameter the remainder is enforced during straint model surface. Usually only a few key points delimit provide estimates of the search, Secondly, to improved performance. leading if a point the best possible this has the obvious virtue of providing better constraint during is known from easily the range data since termined near side of a depth discontinuity), albeit one of them rent interpretation surfaces. Because invisible. Having established a secondary match is sought the surface is invisible, a match from amongst no surface normal to lie on an occluding it corresponds the point must then (this can be de- boundary to the point the lying on lie on two model surfaces, in the cur- the adjacent model is observed, meaning for the point 308 I.D. Reid, J.M. Bmd_v/Art@cial Intelligence 78 (1995) 289-326 0.80 I .20 I .60 d4: hi: h2 h3- h4: WI: w2: W3: w4: WS: w6: . - (a) (b) Fig. I I. Improved chimney recognition: (a) range image with position/surface normal data extracted, and the computed pose/size superimposed; (b) the computed parameter ranges (see text for details), four invariants the constraints) cannot can still be computed, three of surf-d& bound estimate. A further advantage of secondary matching on an occluding boundary dom of the object’s pose surface). (one of the an upper is that a point matched degrees of free- to only one for a point on the interior of a be computed. and constrains (as opposed it is this which provides two of the three translational however fourth The Fig. 11 (a) shows the range image of Fig. the near side of steps IO with a number of additional in the image. The surface improved wireframe from on the image is superimposed from examination points extracted estimate apparent which gives boundary observations-note observations with secondary matching-note and lower bounds. top to bottom: from in the computed pose. The real improvement of the parameter ranges, shown the original the improvement ranges in lower bounds; the significant is in part (b) of the figure, from from boundary in both upper from Fig. 10(b) ; ranges ranges improvement I.D. Reid, J.M. Brady/Artificial Intelligence 78 (1995) 289-326 309 I h2 dsi” hl Fig. 12. A parameterization of a “widget” class. 4. Discrimination and identification Part of the model definition given in Section 2.2 was a specialization sub-level of the hierarchy addition of extra model constraints, the class of “widgets” Consider corresponds to a specialization of the parent active for that sub-class and all its children. shown in Fig. 12 parameterized by the set: hierarchy. Each through the ’ specialization specialize An exemplary model constraints widgets, A, B and C are completely geometrically interpretations hierarchy the previous Having established a set of legal level, until, at the leaf nodes, determined. using a high (general) is given in Fig. 13. At each level of the tree extra three different level of the it is then a simple matter to check lower levels for sub-class membership. This traversal of the hierarchy. However a depth-first hierarchy, can be performed more informative children; a useful feature of this method of the tree with which the observations is the same as finding an interpretation as a straightforward search tests each child of a parent node before descent is that we obtain directly to consistent level are consistent. Note that neither of these methods checking at each level of the model hierarchy; the most specific ’ Brooks [6] discussed a similar representation with respect to ACRONYM, although this was never ade- quately demonstrated experimentally. 310 I.D. Reid, J.M. Brady/Arfijicial Intelligence 7% (1995) 289-326 0.5dl 0.4~1 <= WI <= hl <= <= 1.5dl 1.0~1 1 \ l.lh3 c= d2 <= dl d2 = = 70s 18s w2 c= 0.6~1 h2 >= 0.45h 0.9h3 .__.___.___.___..___--, . _. d5 = 35s 1 d5 = dl = 52s 18s d2= 18s hl = 53s h2 = 35s wl = 72s w2 = 37s dl=52 d2= d5= hl=53 h2=35 wl = 72 w2=37 = 70 dl d2= 18 d5 = 35 hl=36 h2= 18 wl = 72 w2=36 hl=36s h2 = 18s wl = 72s w2 = 36s ._._______.________..---.-- Widget B Widget C 18 18 ____.___. _____.___.____.__.__._---_ d2 = 25s d5 = 25s hl = 50s h2 = 25s wl = 75s w2 = 25s t I Widget A 1 dl = 75 d2=25 d5=25 hl=50 h2=25 wl = 75 w2=25 Fig. 13. A model hierarchy for the widget class. and three instances of the class, consistent with the leaf nodes of the tree. I.D. Reid, J.M. Brady/Artificial Intelligence 78 (1995) 289-326 311 a specialization is a cheap operation. The specialized constraints are precompiled along with the most general ones, but only invoked during the specialization process. Only a handful of network iterations are then required to find a subset of the rectangular parameter space, indicating either the new parameter ranges, or if the space is empty, that no interpretation of the observations exists for the current node in the model hierarchy. Even if an exact identification or sub-class membership cannot be established, the parameter ranges can be used to distinguish between instances simply by testing for non-intersecting ranges of the same parameter in the different instances. Fig, 14(a) shows the left camera view from a stereo pair of the three widgets jumbled together, and the 3D line segments found by the TINA stereo vision system [ 3 11. Fig. 14(b) shows the computed pose and size of the three widgets superimposed on the left-hand view (alternative views of each are shown below). Each has been correctly identified using the parameter ranges shown in Fig. 14(d). 5. Objects with multiple and repeated sub-parts Sub-parts are defined in a model relative to a coordinate frame local to the sub- part, and by a REV-graph, a set of sub-part model parameters, and a set of model constraints. In addition, each sub-part has an associated transformation, possibly param- eterized, which gives the location of the sub-part relative to the global model frame. The transformation is given by terms (either numbers or parameters) specifying: 0 an axis of rotation; l an angle of rotation about the axis; 0 a translation. In contrast to other recognition systems which search separately for different sub-parts, then test the consistency of the poses of the sub-parts with an overall model [ 10,14,19], our system attempts to match over the whole model immediately. This has the advantage that in instances where there is insufficient evidence to hypothesize the presence of individual sub-parts, it may still be possible to hypothesize the presence of the model as a whole. Each sub-part also has an associated number of repetitions. Usually this will be a constant (frequently equal to one), but on occasions it is useful to define an object in terms of a parameterized number of repetitions; the pallet, which we use as an exemplar here, is one such object. This is achieved by defining the number of repetitions to be a parameter constrained to take on integer values, and defining the transformation between local and global coordinate systems to be a function of the sub-part number. Although the model is defined in terms of sub-parts, the search algorithm operates on a “flattened” version of the model. This is created when the system first reads in the model. For each part encountered in the model definition, r copies of the part are created, where r is the maximum number of repetitions of the sub-part allowed (this is specified in the model). The copies are identical except for a sub-part number (from 1 to r) and the local to global transformation for each (which is a function of the sub-part number). In addition r copies of each feature in the part are created, identical except that each maintains a record of which sub-part it belongs to. (a> (b) - Cd) Fig. 14. Pose and identification of widgets A, B and C with stereo edge fragments of each widget superimposed; computed parameter (from objects top to bottom: widget A, B and C) in millimetres-the ranges from stereo edge fragments: (a) superimposed; solid bars indicate (b) the left view from a stereo pair of images the computed pose, size and identity the for the three the ranges for each parameter (c) alternative views of each widget and the edge fragments used; (d) I.D. Reid, J.M. BradylArtiJcial Intelligence 78 (1995) 289-326 313 interpret( I, P, j) [if j=n P); II verify(Z, return; i +-- 0; while r i < m if pXllXIl(/&) < SUP r(k) t +- inf r(&) inf r(&) +- max(t,pnual(~i)) if COIlSiSteIlt(Z,P, {Sj,&}) P’ + update( if P’ # 0 I, {Sj,/Li}, P) 1 + 1 U (sj9 Pi} interpret(l, P’, j + 1) [ 1 _inf I(/Ji) f-t i+i+l 1 return; Fig. 1.5. Pseudo-code for the extended search: the basic structure of the search is the same as those in Figs. 4 and 8. The new condition involves a function pnum(p) which returns the sub-part number of the part to which feature p belongs, and r(p) which returns the current upper and lower bounds on the number of repetitions of the sub-part to which feature p belongs. The variable t is temporary storage for the value of inf r(p;). By insisting that the maximum in advance, we can create a list of all features which are in the maximu set of model features and guarantee that an instance of the model tables is a subset of the maximal are computed and stored for the maximal model. set. Feature constraint number of repetitions is known An extended version of the search is given in Fig. 15. The additions in this algorithm correspond to the following tests and associated actions: l If the current sub-part number of the sub-part to which the feature belongs is greater the match than the maximum then constraints no need to test matches allowed is invalid: that the model (which may be dependent on the current i.e. if it has already been established is a proper subset of the maximal model, interpretation) through various then there is l If the current greater current minimum: minimal the minimal to features not in the subset. than the minimum sub-part number of the sub-part allowed i.e. if we match (in the current to a feature set, but in the current maximal set, then henceforth set must be expanded to include the extra sub-part. to which interpretation) the feature belongs then update is the from a sub-part not in the current in this interpretation In order to illustrate the use of these extensions, we now return example used to motivate our work, that of recognizing data (for other examples, recognition including to the specific in NEL range of articulated objects, refer to [341). A industrial pallets 314 I.D. Reid, J.M. Brudy/Artijiciul Intelligence 78 (1995) 289-326 ht Fig. 16. The simplified pallet model: the model contains a top surface, parameterized by {w, ht. d}, and a set of struts parameterized by { wr, A,, d}. The strut positions relative to the top surface are governed by the overlap at each end, R. and the strut separation, S. The figure shows only three struts, however in the model a fourth is possible; the number of struts, II. being an integer parameter of the model. pallet consists of several parallel, equal-sized rectangular running perpendicular Fig. 1. prisms, and several equal-sized to the slats. Typical examples were shown struts of similar dimension top and bottom slats, which are long, Rat to the slats but in in the introduction slats are omitted In the recognition examples slats), and which have either three or four struts (a parameter&d in this section we consider a class of pallets which have instead of quantity). an arbitrary number of slats (all slats are modelled as a single solid board individual The bottom the observation REV-graph include secondary model features, meaning but are eligible as secondary matches. from that in most poses of the pallet many of the surfaces defined by the image. These surfaces, which in the model as the ends and sides of the slats and the strut ends are marked they are not considered during primary matching, the model. A further simplification cannot be reliably detected in an NEL range comes from are defined Two sub-parts strut parameterized parameter, y1 E [3,4], where li is defined by the constraints: in the model: a top, parameterized by { w,, h,, d}. The number of struts is parameterized and the transformation of each strut is the translation by {w, ht, d}, and a by an integer [li,O,OIT, I, = g + is, Yli = 0,. . , II - I (g is the overhang of a slat at the edge of the pallet and s is the strut separation). The simplified model, parameterized by the set {n,w,h,d,s,wc,h,,ht,g} is shown in Fig. 16 (an annotated version of the model definition appears as an appendix in [34]). I.D. Reid, J.M. Brady/Artificial Intelligence 78 (1995) 289-326 (b) (cl Fig. 17. A scene containing two pallets of different sizes and a cardboard widget: (a) an intensity image of the scene with a small pallet on the left and a large pallet on the ground; (b) an NEL range image of a similar scene in which lighter represents closer, and white means no valid range data;(c) pose and size results for both pallets and the widget. A complex scene involving occluded, and a large widget, in Fig. 17. The pallet on the left has three struts and the one on the right has two pallets, one substantially is shown four, but the furthest strut has not been detected by the range sensor. The recognition algorithm was run for each of three sets of surfaces, corresponding to the two pallets and the widget. These surfaces were extracted automatically range image but the selection of which surfaces for the two pallets each generated from the to use was made manually. The searches four legal hypotheses; two symmetric interpretations 316 I.D. Reid, J.M. Brudy/Arrijiciul Intelligence 78 (1995) 289-326 with three struts, and two symmetric ated two legal interpretations and depth. The correct Fig. 17(c). interpretations corresponding interpretations with four struts. The widget gener- of its width in image are shown superimposed to the symmetric on the range interpretation In the case of the smaller (upright) are the the system makes no use of negative evidence which might rule could Likewise, one of the two widget the three strut interpretations interpretations pallet, correct ones. However out the four strut interpretation. be ruled out by considering requires the size computed interpretations (no rule out the three strut interpretation. use of negative initial guesses research. in order global evidence about the scene since in this interpretation the base of the widget to extend below the floor. The correct for the larger pallet are the four strut ones, but the lack of evidence to These results present a strong case for both the to follow up and for future to resolve ambiguities, which will form and global evidence, for the system it impossible the basis intelligent strategies sensing fourth strut was detected by the sensor) makes 6. Performance For the case of parameterized models, the ability of geometric constraints to prune of in assessing of the the search space of the interpretation parameter values, particularly the practicality constraints early of the algorithm we have presented and how the search performance have confirmed Our experiments the intuition is affected. tree is hampered by the lack of knowledge in the search. It is therefore crucial to study the effectiveness that a data driven search such as the close to result invariants the edge the experiment set of comparisons smaller for surfaces limit being geometrically a meaningful (the as a performance recognition one we use, is better suited by the number of model features, which is considerably Furthermore, (see Appendix A) networks. Therefore Section 4 of widget case” scenario. In order to surface data since the breadth of the tree is determined than edges. in more complex in shown to a “worst- tend gauge, we consider from stereo data which represents to provide levels the of model specialization search for each of the levels separately. Fig. 18 shows three graphs, one for each of the interpretations four plots, each one against to a complete search using one level from the model hierarchy. Although corresponding the performance of the parameterized models is considerably worse than for fixed models early is that they show that the the most striking search has been brought under control after 2 or 3 matches, and has comparable performance matches. Also note that despite few levels, (the model has 24 edges and n is the level in the tree search). feature of the graphs (i.e. the number of tests is no longer to the fixed models after 4 or 5 in the search over the first less than the worst case for this model of 0(24”+‘) the number of consistent assignments of the segmented data, plotting the level of the interpretation fixed models) we invoked tree. Each graph contains the effort is still much the combinatorial in the search, the various increasing) between increase 1200 1100 1000 900 600 700 600 500 400 300 200 100 0 1200 1100 1000 900 600 700 600 500 400 300 200 100 0 I.D. Reid, J.M. Brady/Art@cial Intelligence 78 (1995) 289-326 317 q level 1 (fully parameter&d) level 2 (fully parameterbed) . level 3 (scale only) W level 4 (fixed) x 0 . w X level 1 (fully parametarized) level 2 (fully parameterizad) level 3 (scale only) level 4 (fixed) 0 1 2 3 4 5 6 6 7 (b) 9 IO 11 12 13 14 1.5 16 12001 700 600 500 400 300 200 100 0 0 level 1 (fully parameterized) n level 2 (fully parameterbed) w x level 3 (scale only) level 4 (fixed) 0 1 2 3 4 5 6 0 7 (cl 9 10 11 12 13 14 15 16 Fig. 18. Number of assignments made during the tree search for each widget in the scene. The horizontal axis corresponds to tree level, and the vertical axis to the number of consistent assignments made: (a) widget A; (b) widget B; (c) widget C (see text for details). Fig, 19. Percentage of false positives allowed by each feature constraint plotted against at each level of the tree search for each of the four edge constraints: (see text for details). (c) edge-proj-I, (d) edge-proj-2 (a) edge-angle, (b) edge-dist, We have measured the pruning power of each of the feature constraints by considering the percentage of false positives accepted by each feature constraint at a given tree level, calculated as c-t lOO---- c (where, and t number of correct matches). This percentage has been plotted against of the tree in Fig. 19 (for effect: for the edge-angle parameterized parameterized model ), and the performance of the distance constraints, proj- I and edge-proj-2, but improves for a given level of the tree, c is the number of times the constraint was tested the level the widget C example). These graphs show the expected the fixed and the the mode1 angles are fixed even in the edge-dist, edge- is poorer for parameterized models over the first few tree levels, as for fixed models thereafter. in Table for all the results given in this paper are summarized there is little difference between the same performance to give approximately in this experiment Performance constraint statistics (since cases 2, giving network statistics tion. These on a SunSparc-2 workstation (which, (number of iterations and total network the network size, size of the tree search required, number of interpretations, flops), and time for recogni- running for the algorithm steps except network compilation latter times reflect the total time for recognition in any case, is negligible). all algorithm including I.D. Reid, J.M. Brady/Art$icial Intelligence 78 (1995) 289-326 319 Table 2 System performance summary Experiment Network size (nodes) Search size (IT nodes) Interpret- ations Total network iterations Total network operations Time (CPU sets) widget A (Fig. 14) widget B (Fig. 14) widget C (Fig. 14) chimney (Fig. 10) chimney (Fig. II ) pallet3 (Fig. 17) pallet4 (Fig. 17) widget (Fig. 17) 699 699 699 4094 4094 2328 2328 699 693 1443 2553 67 99 115 145 980 1 1 1 4 4 4 4 2 1984 3783 7202 237 326 277 529 2573 357516 616380 1177030 350378 383412 333425 709792 196978 8.38 14.10 28.37 2.86 3.43 3.49 4.69 4.03 7. Relationship to previous work The extensive literature on three-dimensional object recognition fixed objects, since it was realised has concentrated, for led to the most part, on geometrically powerful constraints which could be exploited and localization. We begin this section with a brief tour of the seminal work in the area to of fixed 3D object recognition, from 3D data, paying particular attention work which has influenced the is beyond in 131). and we scope of the paper for parametric object therefore concentrate recognition. our own. A full survey of these techniques in numerous ways to achieve recognition though dated, survey can be found on the considerably that such objects (an excellent, less common particularly systems 7.1. Fixed 30 object recognition A popular approach, and one adopted in our work described is that of hypothesis seeking appropriate matches generation, Grimson and Lozano-Perez search of an interpretation driven earlier sections. Developments constraints scale invariant system range data. A useful and interpretation constraints on 3D edge fragments [ 151 using unary and binary constraints in the previous sections feature space through a search of the object-model followed by a global verification stage. developed the RAF system tree which we have already discussed from their work, using tree search were made by Murray and Cook in detail [ 20,211 based on a data- in the same principles of geometric [28] using and by Flynn and Jain in the Bonsai from on planar and quadric surfaces refinement an object pose frame) approach coordinate support using model-driven rather the model driven approach of the IT is based around (i.e. a transformation which maps a model into is computed as soon as possible, and then a search initiated the concept of alignment. In this the sensor to provide such an approach than data-driven of is that the nature of the search restricts each model feature pose. Faugeras and Hebert developed tree search [ 111. A major disadvantage for the hypothesized 320 I.D. Reid, J.M. Brady/Artificial Intelligence 78 (1995) 289-326 algorithm, ideally all match the 3DP0 system support subsequent lead to fragmented In practice, occlusions focus [ 81 using to at most one data feature. that of finding maximal cliques to one model [5] replaced tree search with so-called feature foci-features hypothesis idea have appeared and poor segmentation to match feature. often data features which the first The work of Bolles and Horaud, who developed few levels of the interpretation which when matched would determine, or greatly restrict the pose of the object. The IT search in a graph, was replaced by an equivalent for obtaining of the systems developed by Chen and feature ideas from 3DP0 Kak and RAF systems such as three concurrent 3D line segments. Lowe’s SCERPO system [24] was based on similar principles consistency constraint, and proceeded once an initial pose had been estimated perceptual group (another edge segments images using object-feature match search techniques that by Goad [ 181 and Huttenlocher by the viewpoint from a formed by from 2D includes range data, and Pollard et al. [32] who combined in the scene. Other notable work on recognition foci were groups of 3D edge fragments images. Matching was constrained to pose estimation. Generalizations of 3D objects to alignment such as a parallelogram but used 2D intensity in 3D recognition term for feature and Ullman subsequent in which feature focus) An alternative to search through feature-match Mundy 1381 who used vertex-edge further vertex) Each vertex-edge with the true one(s) to estimate a transformation pairs pair casts a vote in transformation estimated as peaks in this space. [23]. space was proposed by Thompson and vertex and a (two edges with a coincident from model to scene under affine projection. transformation space for a particular Finally, we briefly mention the relatively recent developments of recognition invariants, the use of projective pioneered by Weiss system developed by Rothwell et al. [ 16,371. To date most of this work has concentrated [ 361 have extensions on planar objects. Only recently achieved bilateral symmetries), will prove to full automation. objects been (for objects which can be “caged” by polyhedral point sets, and objects with these methods and it is too early to tell how robust and amenable [41], and best illustrated to three-dimensional through in the 7.2. Parametric object recognition The systems above were all designed to operate with fixed, rather than parametric to cope with internal degrees for parametric objects below. [6], schemes images). is ACRONYM intensity objects. Some of these have been extended more recently these, and other systems designed of freedom. We discuss object recognition The best known of all parameterized designed ACRONYM consisted of three distinct parts massaged instances of 3D models to find l a powerful representational itives each defined by an axis, a cross-section how the cross-section blocks and a frame-based, and a hierarchy of models and sub-models; changes as it sweeps along semantic network (i.e. in single 2D views together: scheme which used generalized cones (volumetric prim- rule which determines the axis) as the basic building [27] of objects, parts and sub-parts and a sweeping l a symbolic of Bledsoe inference [ 41, for the propagation of symbolic and numeric constraints; engine, CMS, which was based on the SUP/INF algorithm I.D. Reid. J.M. Brady/Artificial Intelligence 78 (1995) 289-326 321 l a prediction mechanism which used ribbons (the two-dimensional equivalent of generalized cones) observed in an image to hypothesize the presence of generalized cones and set up constraints appropriate to the observed data. Although there is a multitude of good ideas within ACRONYM, it was slow (owing to the nature of symbolic computation). More seriously, it was only ever demonstrated on a handful of images meaning that many of its potential uses were never tested (including objects with repeated sub-parts, as demonstrated in this paper). This was a result of the difficulty in extracting data from intensity images useful for constraining the size and positions of the generalized cones representation. Grimson [ 19,201 described how to extend the RAF system for simple parameteriza- tions of 2D objects, dealing with the cases of uniform scale, uniform stretching along one axis, and rotation about a common axis. The former two were incorporated by treat- ing each as a special case hard-coded into the search algorithm itself, and the latter by recognizing sub-parts and then finding parts consistent with a rotation about a common axis. The system thus lacked generality, a limitation overcome in the work we have described in this paper. Ettinger [lo] generalized the latter part of Grimson’s strategy, building a system based on a bottom-up hierarchical search, in which primitive features (in this case components of the cu~ature primal sketch located in 2D images of 2D models such as road-signs) are built into sub-parts which ultimately are linked to recognize objects. A limited amount of parameterization was allowed. [l] Fisher’s IMAGINE system [ 12,141 also allows the definition of objects in terms of sub-parts, and parameterizations are introduced in the form of rigid motions between sub-parts may not have internal degrees of freedom such as scale sub-parts-although is based on a bottom up or stretch. Like Ettinger’s system, IMAGINE recognition approach using feature clusters, similar to the feature foci mentioned above, formed using topological constraints and matched to sub-parts. A SUP/INF network is used to solve for the transformations between sub-parts and the overall model to sensor transformation. Vayda and Kak [40] have demonstrated a system for recognition of generic postal objects from range data. Individual items are recognized in scenes of piles of postal objects. The system’s geometric reasoning algorithms consider not only information about single objects but about the entire scene (for example, intersection tests are performed between hypothesized objects in the scene). However the success of the algorithms used depends largely on the limited scope of the representation; objects are modelled as either a box with three scaling degrees of freedom or cylinders with two scaling degrees of freedom. The major research on 3D parametric object recognition from 2D data has been conducted by Lowe [ 251 (an extension of the SCERPO system) and Nguyen et al. [29]. Both methods use gradient descent from an a priori estimate of parameter values (including pose parameters) to solve simultaneously for pose and parameters. Such systems are extremely useful for tracking articulated objects from a dense sequence of frames where the previous frame gives a good guess for the current frame, as interfaces where a good initial guess can demonstrated in [26], or in human-computer in non- be provided by a user, as in [ 291. However the problems with gradient descent 322 I.D. Reid, J.M. Brudy/Arti’ciul Intelligence 78 (1995) 289-326 is well documented, convex spaces reliance on prior estimates combined with inability values. and the major problem with these methods is their to self-bootstrap unknown parameter resemblance [ 391 bears closest Recent work by Umeyama to the work we have In common with our work he represents parameters by intervals, and bases solution around depth-first search of an interpretation of articulations presented. recognition for parameter values. General parameterizations and arbitrary scaling and stretching are allowed, however a major limiting it operates only with 2D models from points found on silhouettes projection). factor is that (formed under parallel tree with simultaneous such as combinations 8. Discussion As we have mentioned limitation is a clear recognition earlier, most previous in many environments techniques and/or (which may consist of multiple this deficiency we have developed systems have been designed to instances of 3D for recognizing repeated sub-parts with internal transformations), from sets of 3D feature is structured as a search of an interpretation to work with fixed objects. This address object classes degrees of freedom, observations. Recognition the tree, tree in which geometric constraints on pairs of sensed features not only prune but are used to determine upper and lower bounds on the model parameter values of the instance. A real-valued of the model parameters, model constraints and provides a simple and effective mechanism linked by parameterized of a class instance for accessing and updating parameter values. constraint propagation network unifies and feature constraints, the representations and We have examined types-3D edge fragments derived from planar patches extracted is effective in determining with recognition demonstrate of parametric objects from a stereo vision system, and position/surface from a range image-and a number of different cases using real 3D data of two different normal data that the system the cost associated is greater than for fixed objects, our experiments object pose and parameters. Although shown As it stands, that in many cases this is a price worth the flexibility gained. is based around a very general the system however, the system of an object is to introduce is unacceptable, in a non-cluttered and Lozano-Perez scene. One way around [ 21,281. However currently used in, for example, the pose and parameters problem as suggested by Grimson technique, number of interpretations can be gained [ 5,8,32]. group avoiding many problems of our system. A major of these tools into the parametric interest to minimize uncertainty this the notion of a “null feature” which always successfully matches, this the [ 201. We noted in Section 7 that a great increase in efficiency through a more strategic search, seeded by a focus feature or perceptual the search to specific areas of interest, a limitation target of our future research will therefore be the incorporation framework we have described. One point of particular strategically in [22]. The price paid when using in associated with excessive scene clutter, currently is that the search could be controlled The effect of this is to direct raised by such an extension about parameter values. in combinatorial as it results explosion interpretation is limited tree search, as to determining I.D. Reid, J.M. Brady/Artificial Intelligence 78 (1995) 289-326 323 A second obvious way of improving is to exploit parallel nature of many aspects of the method. To this end we have a the performance of the system the network throughout evaluation both the potentially explored distributing MIMD processor network the tree search and [ 93. Acknowledgements We are indebted to David Murray to Steve Pollard of Sheffield University and to an anonymous a Rhodes scholarship. referee for some insightful for many useful discussions. We are also grateful for the use of the TINA stereo vision system, Ian Reid was supported by comments. Appendix A. Binary geometry constraints specifies This appendix the feature constraints the fk) used Two types of data may be input: either surface data from our in-house laser range-finding system Demonstrations to 5. [ 33,351, or three-dimensional [31]. Below we give sets of feature constraints of the system working with both types of data are given system (i.e. edge fragments from a stereo for each of these data types. in Sections 4 in our system. (Oxford/NEL) remains segmentation is rather conservative, Surface data are represented range finder give information This representation ford/NEL range-image sentation obviates cause a single surface occlusions. as connectivity example, enforcing the same model surface, or that data from adjacent surfaces adjacent model surfaces. by a 3D position and a unit surface normal, s = (p, n). since dense range maps supplied by the Ox- about surface extent and connectivity. However, data repre- (or other factors) facets, and those problems created by such itself, by, for to in the scene must match to to the interpretation that data from the same scene surface must match topological to the tree search (when available) the constraint a difficult problem, and a conservative of over-segmentation where noise it is a simple matter the problems to be broken into multiple Furthermore, to transfer constraints We use the same set of surface constraints as in the original 3D version of RAF. This (and feature constraints) is given by: set of image measurements nt . n2. ( 1) surf-angle: (2) (3) (4) surf-dist-1: nl . (p, - p2). surf-dist-2: n2 . (p2 - p, ) . surf-cross-dist: the possible and orientation These measurements available normal data points. They are depicted in Fig. A. 1 (a). If, instead of nl . n2, we use arccos nl . n2, with the sign adjusted so that surfaces which from two position/surface on position constraint embody all 324 I.D. Reid, J.M. Brady/Artijicial Inrelligence 78 (199.5) 289-326 a h Fig. A. I. Feature constraints fragments. used by our system: (a) for planar surface patches; (b) for straight edge face each other have positive angles and surfaces which point away from each other have negative angles then sign ambiguity the same convention surf-angle refers to this revised measurement. is avoided. Henceforth in the model), is adopted (and Edge data are represented by a set of edge fragments, s = (e, m, 1); e is an unsigned fragments in the direction of the fragment, m is the midpoint of the fragment and 1 to define the endpoints of the [28] proposed a set of length. From these it is straightforward unit vector is the fragment’s fragment, p, = m + {le and p2 = m - k&e. Murray and Cook feature constraints based on edge directions. The recognition problem from moving edge because of the depth/speed scaling under perspective projection. For the case where scale independence constraints new, but equivalent, ( 1) edge-angle: (2) edge-dist: set of feature constraints, can be extended listed below: * images-required ambiguity scale constraints in visual motion processing is not an issue their to include distances as well. Instead of these, we propose a they considered- arccos ei . el. independent inherent sensed if ( si and sj parallel) sgn( ei . ei) (u . u - (u . ej)*)“* else o . f?i A t?j !eiA where v = m, - m.i is a vector between the edges. ( 3 ) edge-proj- 1: (P,, -mj). [Ci A f$$] and (p, -m.j). [ej A a], (4) edge-proj-2: Image measurement the fragments the lines on which lie and edge-proj gives upper and lower bounds on the distance of edge is the perpendicular distance between edge-dist 2 This constraint set more closely resembles those used by Pollard [ 321. I.D. Reid, J.M. Brady/Arrifcial lnrelligence 78 (1995) 289-326 325 Sj with surface normal ej A ei A ej. These measurements are si to the plane containing in Fig. A.1 (b) . depicted References III 121 131 141 r51 161 [71 l81 191 [ 101 1111 1121 [I31 [I41 I151 I161 [I71 [I81 I191 ( 1986) 3-26. H. Asada and J.M. Brady, The curvature primal sketch, IEEE Trans. Pattern Anal. Much. Inrell. 8 ( 1) (1986) 2-14. B.G. Baumgart, Winged-edge polyhedron representation, Technical Repoti AIM-179, Stanford University (1972). P.J. Besl and R.C. Jain, Three-dimensional object recognition, Cornput. Surv. 17 ( I) (1985) 75-145. W.W. Bledsoe, The sup-inf method in presburger arithmetic, Technical Report Memo ATP 18, Department of Mathematics and Computer Science, University of Texas (1974). R.C. Bolles and P Honud, 3DPO: a three-dimensional part orientation system, Inr. J. Robotics Research 5 (3) R.A. Brooks, Symbolic reasoning among 3D models and 2D images, Arrif: Intell. 17 ( 1981) 285-348. R.A. Brooks, Symbolic error analysis and robot planning, Inr. J. Robotics Research 1 (4) (1982) 29-68. C.H. Chen and A.C. Kak, A robot vision system for recognizing 3D objects in low-order polynomial time, /EEE Trans. Syst Man Cybern. 19 (6) (1989) 1535-1563. E Chenavier, I.D. Reid and J.M. Brady, Recognition of pammeterized objects in range images: a parallel implementation, Image Vision Compur. 12 (9) (1994) 573-582. G.J. Ettinger, Large hierarchical object recognition using libraries of parameterized mode1 sub-parts, in: Proceedings IEEE Conference on Computer Vision and Pattern Recognition (1988) 32-41. O.D. Faugeras and M. Hebert, The representation, recognition and locating of 3D objects, Inr. J. Robofics Research 5 (3) R.B. Fisher, From Surf&es to Objects: Computer Usion and Three Dimensional Scene Analysis (Wiley, New York, 1989). R.B. Fisher and M.J.L. On; Solving geometric constraints in a parallel network, in: Proceedings 3rd Alvey Vision Conference ( 1987) 87-9.5. R.B. Fisher and M.J.L. On; Geometric reasoning in a parallel network, hr. J. Robofics Research 10 (2) (1991) 103-122. P.J. Flynn and A.K. Jain, BONSAI: 3D object recognition using constrained search, in: Proceedings 3rd Inrernarional Conference on Computer Vision ( 1990) 263-267. D.A. Forsyth, J.L. Mundy, A.P Zisserman, C. Coelho, A. Heller and C.A. Rothwell, Invariant descriptors for 3D object recognition and pose, IEEE Trans. Parrern Anal. Mach. Intell. 13 (IO) ( 1991) 971-991. PC. Gaston and T. Lozano-P&z, Tactile recognition and localization using object models: the case of polyhedra on a plane, IEEE Trans. Pattern Anal. Mach. Intell. 6 (3) ( 1984) 257-265. C. Goad, Special purpose automatic programming for 3d model-based vision, in: Proceedings Image Understanding Workshop ( 1983) 37 l-38 1. W.E.L. Grimson, Recognition of object families using parametrized models, in: Proceedings International Conference on Computer Vision, London (1987) 93-101. ( 1986) 27-52. Isr [ 201 W.E.L. Crimson, Object Recognition by Computer: The Role of Geometric Constraints (MIT Press, Cambridge, MA, 1991). [ 2 I ] W.E.L. Grimson and T. Lozano-Pkrez, Model-based recognition and localization from sparse range or tactile data, Inr. J. Robotics Research 3 (3) (1984) 3-35. [ 221 W.E.L. Grimson and T. Lozano-P&z, Localizing overlapping parts by searching the interpretation tree, IEEE Trans. Pattern Anal. Mach. Intell. 9 (4) ( 1987) 469-482. [ 231 D.P. Huttenlocher and S. Ullman, Recognizing solid objects by alignment, Inf. J. Cornput. Vision 5 (2) ( 1990) 255-274. 1241 D.G. Lowe, The viewpoint consistency constraint, hr. J. Compur. Vision 1 (1) (1987) 57-72. [ 251 D.G. Lowe, Fitting parameterized 3D models to images, Technical Report TR 89-26, Computer Science Department, University of British Columbia, Vancouver, BC ( 1989). [26] D.G. Lowe, Robust model-based motion tracking through the integration of search and estimation, ht. J. Compuf. Vision 8 (2) (1992) 113-122. 326 I.D. Reid, J.M. Brudy/Artijiciul Inteiligence 78 (1995) 289-326 [27 ) M. Minsky, A framework Vision (McGraw-Hill, New York, 1975) for representing knowledge, in: P.H. Winston, ed., The Psychology of Computer I28 1 D.W. Murray and D.B. Cook, Using the orientation of fragmentary 3D edge segments for polyhedral object recognition, Int. .I. Cornput. Vision 1 (2) (1988) 153-169. [ 29 I V.D. Nguyen, J.L. Mundy and D. Kapur, Modelling generic polyhedral objects with constraints, in: Proceedings IEEE Conference on Computer Vision und Puttern Recognition ( 199 I ) 479-485. ( 301 M.J.L. Orr, R.B. Fisher and J. Hallam, Computing with uncertainty: in: P Mowforth, ed., Proceedings of the British Machine Vision Conference (Springer-Verlag, Berlin, 199 I ) 351-354. intervals versus probability, 1311 S.B. Pollard, J.E.W. Mayhew and J.P. Frisby, PMF: a stereo correspondence algorithm using a disparity gradient limit, Perception 14 ( 1985) 449-470. I32 I S.B. Pollard, J. Porrill, J.E.W. Mayhew and J.P. Frisby, Matching geometrical descriptions in three-space, Imuge und Vision Computing 5 (2) ( 1987) 73-78. [ 33 I G.T. Reid, S.J. Marshall, R.C. Rixon and H. Stewart, A laser scanning camera for range data acquisition, J. Phys. D A@. Phys. 21 (1988) I-3. 1341 I.D. Reid, Recognizing parameterized objects from range data, Ph.D. Thesis, OUEL TR 1918/92, University of Oxford ( I99 I ). 13.51 I.D. Reid and J.M. Brady, Model-based (1992); Special Vision Comput. 10 (3) recognition and range Issue on Range Image Understanding. imaging for a guided vehicle, image I 36 I CA. Rothwell, Extracting projective information from single views of 3d point sets, in: Proceedings 4th Inrernutional Conference on Computer Vision ( 1993) 573-582. I37 1 C.A. Rothwell, Recognition I 38 1 D.W. Thompson and J.L. Mundy, Three-dimensional model matching invariance, Ph.D. Thesis, University of Oxford from an unconstrained using projective ( 1993). viewpoint, in: Proceedings IEEE Conference on Robotics and Automation, Raleigh, NC ( 1987). [ 39 I S. Umeyama, Parameterized point pattern matching and its application to recognition of object families, IEEE Trans. Pattern Anal. Much. Intel/. 15 (2) (1993) 136-144. [ 40 1 A.J. Vayda and A.C. Kak, A robot vision system for recognizing generic shaped objects, Comput. Vision Graph. Image Process fmqe Understunding 54 ( I ) ( 199 I ) l-46. 141 I 1. Weiss, Geometric I42 I S. Wolfram, Muthematicu: A sysrenr fijr Doing Mathematics by Computer (Addison-Wesley, invariants and object recognition, Inf. J. Comput. Vision 10 (3) ( 1993) 207-232. Reading, MA, 1988). 