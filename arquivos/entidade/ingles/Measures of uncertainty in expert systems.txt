ELSEVI.ER Artificial Intelligence 83 (1996) l-58 Artificial Intelligence Measures of uncertainty in expert systems Peter Walley * Department of Mathematics, The Universiry of Western Australia, Nedlands, WA 6907, Australia Received April 1991; revised January 1995 Abstract This paper compares four measures that have been advocated as models for uncertainty in expert systems. The measures are additive probabilities (used in the Bayesian theory), coherent lower (or upper) previsions, belief functions (used in the Dempster-Shafer theory) and possibil- ity measures (fuzzy logic). Special emphasis is given to the theory of coherent lower previsions, in which upper and lower probabilities, expectations and conditional probabilities are constructed from initia I assessments through a technique of natural extension. Mathematically, all the measures can be regarded as types of coherent lower or upper previsions, and this perspective gives some insight into the properties of belief functions and possibility measures. The measures are eval- uated according to six criteria: clarity of interpretation; ability to model partial information and imprecise assessments, especially judgements expressed in natural language; rules for combining and updating uncertainty, and their justification; consistency of models and inferences; feasibility of assessment; and feasibility of computations. Each of the four measures seems to be useful in special kinds of problems, but only lower and upper previsions appear to be sufficiently general to model t.he most common types of uncertainty. Keywords: Possibility lndependerlce Inference; Decision; Prevision; Bayesian theory; Lower probability; Upper probability; theory; Dempster-Shafer theory; Belief functions; Imprecise probabilities; Conditional probability; 1. Introduction My aim in this paper tainty that can be used in expert systems. The measures probabilities, cial emplhasis lower previsions, belief functions to the theory of coherent is to compare and evaluate mathematical measures of uncer- that I will consider are Bayesian and possibility measures. Spe- as this approach has coherent is given lower previsions * E-mail: peter@maths.uwa.edu.au. 0004-3702/96/$15.00 SSDf 0004-3702(95)00009-7 @ 1996 Elsevier Science B.V. All rights reserved 2 P Walley/ArtQicial intelligence 83 (1996) I-58 comparisons interpretation less attention in the AI literature, although level, than the others received the one that is most widely applicable. On a mathematical can be regarded as special the behavioural some illuminating For example, it is (in my view) the other measures types of lower or upper previsions. They can also be given of lower or upper previsions. This point of view leads to they use for defining, the four theories differ greatly the rules they use to define updating and combining measures of uncertainty, conditional of indepen- dence. The rules used in the theory of lower previsions, which are based on a general procedure and possibility can be applied measures, in Dempster-Shafer thus theory and possibility called natural &ension, and in the calculus especially and how they model judgements they can be compared with and expectations the rules used the theories. probabilities to belief functions between theory. to be a wide-ranging and quickly growing in expert systems. References between probability measures, belief to be a survey of the four theories from a neutral position survey of mathematical models for literature on numerical measures to the and possibility measures. in [ 8,3 1,79,86,89] The paper is not intended and it is certainly not intended uncertainty. There is a substantial of uncertainty relationships Readers can learn more about the subject by consulting and the proceedings of the annual workshops on Uncertainty shall not discuss non-numerical methods of reasoning with uncertainty of endorsements parative probability approaches can be found I take it for granted I Intelligence. such as the theory com- [59,104]. Surveys of the non-numerical [ 27,104] and modal logics [ 131, default reasoning are good introductions and nonmonotonic [ 59,63,67,68], in [47,79,86]. in Artificial the surveys [46,47,88] functions logics that most practical reasoning information, involves uncertainty, partial ignorance to formally model to make inferences and that it is often useful and decisions? These questions (a) what is the best way to model uncertainty? and incomplete or conflicting the uncertainty. This raises the questions (b) how should we assess, combine and update measures of uncertainty? should we use the measures relevant expert systems are an especially good testing-ground they aim to formalise an expert system to formulate appropriate domain experts and these assessments required to supply guide him through and (c) how are to all kinds of reasoning with uncertainty, not only in expert systems. However for theories of uncertainty because and automate as much as possible of the reasoning process. As it is possible strategies, models and patterns of reasoning which are can be assessed by in the system. A user may be but the expert system should be able to some further assessments this process. is concerned only with a narrow domain of application, to that application. Many of the relevant uncertainties special assessment can be encoded The measures of uncertainty that are combined in an expert system may come from or there may be statistical models. the frequency of a disease various sources. Some may be “objective” measures, based on relative on well established data concerning between a symptom and a disease.) Other assessments of uncertainty may be supplied by the domain expert (e.g., concerning in diagnosis, or the association between a symptom and a disease when there is little statistical data). the system. Further assessments Indeed several experts may have contributed the irrelevance of specific observations or the statistical association (In medical diagnosis, in a population, for example, frequencies in building I! Walley/Art@cial Intelligence 83 (1996) l-58 3 may be made by the user of the system exhibited by a patient). All the expert system patient). What, inferences to make (e.g. about the uncertainties in the symptoms these measures of uncertainty and decisions (e.g. to make a diagnosis need to be combined by for this assessments that its uncertainty the expert system as a consultant elicits others from the user, combines the user “if you accept all these judgements then, is the meaning of the combined measures of uncertainty? Whose uncer- It is the user of the system who will act on the conclusions tainties do they measure? are acceptable of the system, provided he is satisfied that supplies various models to him. One can regard and finally and assessments, informs then you should draw these con- clusions”. So the expert system constructs a single model for uncertainty which the user and as a basis for action. then considers and its rea- The expert system should be able to justify soning procedures, when requested by the user, to make its model and conclusions more convincing. and assessments It should also be able to modify some of its assumptions if requeste:d by the user. In the end, the uncertainty measures on which conclusions based mus,t be acceptable its assessments of uncertainty for his own uncertainty adopting as a model all the judgements, to the user. are 2. Criteria for evaluating measures of uncertainty In the rest of this paper I will compare measures of uncertainty according to the following broad criteria. (a) (b) to be used to guide assessment, Intl?);pretution. The measure should have a clear interpretation definite system and use them as a basis for action, and to support the rules for combining and updating measures. Imprecision. The measure should be able to model partial or complete limited or conflicting and imprecise assessments of uncertainty. that is sufficiently the conclusions to understand information, ignorance, of the (c) Culculus. There should be rules for combining measures of uncertainty, updating them to calculate other uncer- and to make decisions. Some justification must be and using them after receiving new information, tainties, to draw conclusions given conditional probabilities (d) Cortsistency. There should be methods and expectations for the rules. Special attention will be given to the rules for computing and default assumptions should ensure that the conclusions tainty assessments the calculus ments. notion of consistency In the Bayesian theory and the theory of lower previsions, is formalised in mathematical principles of coherence. from unconditional probabilities. for checking the consistency of all uncer- used by the system, and the rules of are consistent with these assess- the intuitive (e) Assessment. for a user of the system It should be practicable comfortable with) all the uncertainty system should give some guidance on how to make the assessments. able to handle judgements in natural language judgements with quantitative expressions of uncertainty such as “if A then probably B”, and to combine qualitative to make (and feel that are needed as input. The It should be assessments of uncertainty. types, including assessments of various P Walley/Artijicial Intelligence 83 (1996) 1-58 It should be computationally feasible for the system to derive and conclusions from the assessments. (f) Computation. inferences Readers may wish to attempt to add other desiderata to this list. It does seem for a theory of uncertainty the first four criteria, which are theoretical, to me that it to satisfy all six criteria. We might the last two, which are in the sense that one would expect an irrespective of the in the sense that they will be in some applications but not in others, depending on the type of model involved, needed, practical constraints of time and computing power, is essential distinguish practical. The first four criteria are “theoretical” adequate specific application. The last two criteria are “practical” satisfied the number of assessments and the abilities of the user. to show that they can be satisfied, theory of uncertainty from interpretation, if an expert system seems essential of the system. The second, information are common from the uncertainty is to be im- in order to give is imprecision, in practice. assessments, See [99] for further justification consistency, is needed to avoid of these criteria, to these criteria. Naturally in probability intelligence, computation and philosophy, on science and computer enough, the second (f), and has mostly The two practical criteria are obviously necessary in practice. The first criterion, to, and to justify, the conclusions plemented meaning necessary because partial A calculus is needed so the third criterion erroneous especially There and irrational conclusions. (a), (d) and (e). is a striking divergence (b), ignorance and conflicting in order to derive conclusions is needed. The fourth criterion, practical concerning their attitude between workers the one hand, and those in expert systems, artificial engineering, group has emphasised recognised judgements consistency philosophy pays more attention of assessment to the problem of assessment. the need (e). They have given much (d) and justification of the calculus to these theoretical and computation. There is surprisingly criteria, especially less attention to issues of interpretation in probability (c) . The literature issues, but less to the practical (a), and issues in all the literature, little attention, for imprecise measures of uncertainty (b) and natural-language influential to help physicians In MYCIN uncertainty infections of the blood is typified by MYCIN, perhaps Much of the work in expert systems expert system, which was designed [ 6,47,80,81]. the best-known diagnose and most bacterial in terms of certainty factors. MYCIN does well on the practical criteria (e) and (f), largely amongst variables are because of the modularity ignored) factors, but it does badly on the theoretical largely because of the lack of a clear interpretation (An earlier version of this paper factors with other measures of uncertainty the referees.) Although for the rules of combination. of certainty and the use of simple (a), but this has been omitted on the advice of system to combine (d), factors and a lack of justification all six criteria seem essential, (dependencies certainty a detailed comparison rules (c) and [ 1001 contained of its inference is measured of certainty I regard criteria the most fundamental, the first criterion-the because an interpretation the rules of the calculus, to formulate principles of coherence (consistency), is needed need for a to to and to understand conclusions. Criterion is well made (This point (d) and (e). (a) is therefore a prerequisite in [ 331.) The importance of interpretation-as clear support guide assessment, (c), for criteria P: Walley/Art@ial Intelligence 83 (1996) 1-58 5 [99], to derive and hence to compare by workers interpretation In the following of linear previsions or lower previsions and updating the theories of de Finetti to be underrated tends to them how an interpretation rules for combining interpretation it is unclear derive anrd justify illuminating a behavioural principles of coherence certainty in expert systems, perhaps because of uncertainty measures could be used to the measures. Readers may find it in which [28,29] or Walley is used to support the entire calculus, with the literature on factors and fuzzy logic, in which the rules of the calculus seem quite arbitrary. theory and the theory followed of coherent rule of by the Dempster-Shafer logic, which combination, the four theories differ greatly emphasises and their in their calculus, all the measures can be regarded, from a mathematical point of view, as special types of coherent from this perspective. the possibility measures used in fuzzy language. Although and finally consider in natural theory of belief functions, which emphasises and the four theories will be compared I will outline de Finetti’s Bayesian lower previsions, which emphasise their methods of assessment lower or upper previsions, of uncertainty measures, and consistency, interpretation interpretation judgements a simple sections 3. Bayesian probabilities The most highly developed and best understood theory of uncertainty to the theory and is the Bayesian are wor- and references. Bayesian probability models have been used [91] [ 21, PATHFINDER is a good introduction [20,21], GLADYS include HUGIN [28,29] [47] [56] is a good introduction study. In the field of expert systems, are important theory. The book thy of careful [50,60,63,90] in quite different ways in the expert systems PROSPECTOR and MUNIN [ 371, BAIES its strengths the Bayesian approaches. and weaknesses approach [ 43,47,50]. More recent applications [38]. The discussion [ 141, and in a form are quite well known. The main aim illuminate here will be brief, as the theory and is to summarise the other the comparison with that will probabilities In the theory uncertainty to bet on or against event A at rates arbitrarily close to P(A), is measured by unconditional conditional probabilities P (A 1 B), numbers between zero and one which are interpreted is taken as fair betting rates. That is, the person whose uncertainties or at rates to be willing arbitrarily that the bet is called off unless event B occurs. The key assumption here is that a person should always have the same marginal rate for betting on or against an event. This assumption precision. Bayesians have given several arguments of the arguments is called the Buyesian dogma of the assumption, but none see 199, Chapter 51 for a thorough discussion. is at all compelling; are being modelled 1 B) on condition to support to P(A or by close P(A) additivity, the behavioural from countable Apart derived from the coherence principle is certain is a normalised, imply that updated probabilities nonnegative, interpretation and the dogma of precision, all the familiar properties of probabilities can be together with of acceptable bets that function P set function. Further coherence principles after observing an event B should agree with conditional imply that the probability finitely-additive that there should be no finite combination to produce a net loss. These assumptions 6 R Walley/Art@cial Intelligence 83 (1996) 1-58 to unconditional rule P( A n B) = P( A 1 B) P( B) . If the unconditional probabilities P(A 1 B), and that these should be related through Bayed P( A n B) and P(B) probability P(A 1 B) be used as a rule for computing conditional probabilities It can also be used as a rule for computing P( A fl B) from P( A 1 B) and P(B) indeed it is frequently used for that purpose. have been assessed and P(B) is uniquely determined from unconditional is nonzero then probabilities probabilities the conditional through Bayes’ rule. Thus Bayes’ rule can probabilities. , and If an unconditional probability measure P is specified, the possibility of a random variable X, denoted by P(X), When be regarded as coherence from assessments about probabilities of previsions determine upper and lower probabilities of probabilities, from assessments of previsions, space fi is finite, P(X) = CoEn P(w)X(w). relationships. They can be used to compute the prevision (or expectation) from P(X) = J XdP. Again these should the value of P(X) information as in [ 281. In general, assessments rather than precise values. but they could also be used to provide can be computed If coherent probabilities X, there is a unique value of P(X) that, for Bayesians, means probabilities; previsions carry over to imprecise probabilities: general, by upper and lower probabilities. are specified for all events then, for every random variable that is coherent with the specified probabilities. This in terms of are uniquely determined by probabilities. This result does not in is lost by modelling uncertainty upper and lower previsions are not determined, no information The Bayesian theory of probability is closely related to a theory of decision making. that the utility Suppose resulting precise number U(a, w) which depends on the unknown variable X, by X,(w) = V( a, w) . A Bayesian would compute expected utility of action a, for each feasible action, and attempt maximise from each feasible action a can be measured by a the random the to the prevision P( X,), to choose an action expected utility. state w. Define and other probabilities probabilities (conditional) (conditional) to calculate set of mutually of independence is an exhaustive in practice by selecting The Bayesian theory is applied or previsions or exchangeability, then applying or previsions. exclusive hypotheses some events or variables can be precisely assessed, adding any the rules of the if For example, and B is an event, one might make precise assessments of the prior probabilities P(Ai) the predictive prob- whose judgements theory {A,, AZ,. . . , Ak} observable and likelihoods P( B 1 Ai) for 1 6 i < k, and use these to calculate ability P(B) = cff, P( B 1 Ai) P( Ai). After event B is observed, provided P(B) zero, one might update uncertainty about probabilities in the Bayesian easier to assess P (Ai I B) directly Uncertain that are conditional written more conveniently the prior odds on Al, p(B) = P(AI and A(B) = P(B 1 Al)/P(B I AZ) posterior odds = prior odds x likelihood is not their posterior is nothing in this way-it might be than to assess the quantities P( Ai) and P( B I Ai) .) rule can be is is the posterior odds on AI, is, in the form p(B) = PA(B), where p = P(Al)/P(Az) I B) the hypotheses by calculating I Ai)P(Ai)/P(B). using Bayes’ rule, P(Ai 1 B) = P(B in terms of posterior probabilities information. When k = 2, Bayes’ that forces one to calculate P(Ai ratio generated by B. That typically be expressed on all the available conclusions will is the likelihood I B)/P(Az (There theory ratio. I B) l? Walley/Artijicial Intelligence 83 (1996) l-58 I the Bayesian approach can be applied are coherent and that they determine it can be difficult to determine a complete probability model, and to check involving uncer- in any problem to make the many precise assessments of probabil- In principle, tainty. In practice, ities that are needed assessments sufficiently many assessments determined-we of assessments are made, so the probabilities the assessments will be incoherent. There are also computational assessments and independence whether a given set of probability which is equivalent a solution. that the a unique probability model. Unless are made, the probabilities of interest will not be precisely [60,62]. But if a larger number typically in verifying is coherent, to checking whether a system of linear and quadratic equations has obtain upper and lower probabilities of interest are overdetermined, difficulties judgements To alleviate PROSPECTOR are probabilistically simple rules (similar However incoherent probabilities. the difficulties of assessment the simplifying incorporated the early expert system that separate pieces of evidence on the hypotheses of interest, and used to combine pieces of evidence. these rules are inconsistent with the Bayesian calculus and they can produce and computation, assumption independent to the max/min rules of fuzzy logic) conditional More recently, attention has been directed to special types of models, notably the judgements “belief nel works”, “causal networks” or “directed acyclic graphs” studied in [ 50,63,90]. involve These models independence, based on an expert’s of conditional of the causal relations between variables, which can be represented graph- understanding in many practical problems. For these ically by directed models, of in the tree, and the effect of conditional1 probabilities locally. Belief networks can also be new information about possible actions and elaborated utilities, and thereby used to make decisions. into “influence diagrams” by adding trees and which are reasonable the effort of assessment can be propagated are needed only and computation on probabilities for the links assessments information is greatly reduced: Assuming that precise probabilities calculus are uncontroversial. there is little information probability able. When to assess any precise probability P(A). containing you assess a precise probability [ 1011 for discussion with imprecise, qualitative or natural-language B” [ 1041. of this example.) coloured balls. Without any further can be assessed for all events, It is the assumption of precision the rules of the that is unaccept- a possible event A it is inappropriate concerning (Suppose, information for example, that I produce an urn about the balls, how would that the first ball drawn from the urn will be red? See approach cannot deal such as “if A then probably the Bayesian judgements Similarly Conclusion The Bayesian theory does very well on criteria calculus (b) and (e) . Bayesian probabilities of the probability guarantee consistency of models, notably especially many practical problems. for singly-connected for dealing with judgements can be justified (coherence). Computations (a), (c) and have a simple behavioural through (d), but poorly on interpretation. The rules and the rules types belief networks. The theory is highly developed, in of conditional this are feasible for some important [ 631, and useful interpretation, independence 8 I? Walley/ArttjIcial Intelligence 83 (1996) l-58 The fundamental difficulties with the Bayesian they demand precise probability models, Bayesians Because ignorance, partial information, between expert opinions. There is a compelling (see ments of uncertainty much of the expert systems uncertainty which do admit imprecision. literature. [99] theory concern the dogma of precision. cannot adequately model language, or conflict imprecise assess- in In the rest of this paper I consider measures of in natural for allowing and this has been accepted assessments of uncertainty argument for detailed discussion), 4. Coherent lower previsions This section summarises the theory of coherent in detail in [ 991, using mathematical lower previsions. The theory veloped related work in expert systems see [ 25,30,35,60,62,66,94,113], pers (except here; adopt a different Fuller discussion of many of the ideas in this section can be found in [99]. is de- in [ 28,87,1 lo]. For but note that these pa- respects from the approach outlined than previsions, they concept of independence. upper and interpretation which lower probabilities leads the last one) differ in some important rather to a different they emphasise suggested concepts and Assessment First consider how an expert system might, ideally, elicit assessments of uncertainty suggest what probabilities the assessments. the probabilities It might of interest, or what kinds of independence from the domain expert and the user. The system should give some guidance on how to make to constrain and probability models may be reasonable. But the user should not be forced to accept any of these judgements the system may suggest default assumptions such as conditional but if these are unacceptable them, typically obtaining weaker conclusions. to the user then the system should be able to operate without or to make assessments type. For example, could be assessed of any particular independence, judgements Generally of unconditional the system should be able to work with whatever combination of judgements the user is able to make, including precise or imprecise and expressions of uncertainty or conditional language assessments than B”, “if A then probably B” or “A is very likely”, such as “A is more probable and various other kinds of judgements. The judgements combine them consistent, system would check whether the questions to construct to the user. If the conclusions were of interest, and report indeterminate, the in order try to make probability model more precise, but he may not always be able to do so. independence, these judgements an overall probability model and to draw conclusions the model and conclusions further assessments the user might of (conditional) are mutually judgements probability, in natural to make about The assessment process involves a sequence of judgements. After each judgement, the expert system could compute and display summaries of the current probability model, should be considered next in and analyse order to reduce In the light of the current and modify earlier judgements, make further model, the model to suggest what kinds of judgements in inferences or decisions. the user may choose the indeterminacy to reconsider P. Walley/Arhjicial Intelligence 83 (1996) 1-58 9 the process. Each of these steps modifies the model to take account of new information, in a simple way: see [99, Section 4.31 for the mathematical update space, or terminate assessments, the possibility model the user may decide nonmonotonic implications, decide about one possibility space to provide is related. to the first space through a multivalued mapping. he may recognise tc’ consider other possibilities, to retract some of the assumptions that his previous possibility the current model reasoning) because refine or reformulate the current details. For example, (a kind of or judgements is incoherent or has unacceptable space is not exhaustive and or he may use imprecise probabilistic information about a second possibility information space that The key step in this process is the construction of uncertainty further input judgements. from a user, of an overall probability model from This can be carried out by the procedure through a mathematical an arbitrary combination expert system, without called natural extension. Interpretation Before we can give a formal definition of natural extension we must characterise requirements kind of probability model models for imprecise probabilities consistency adequate model lower prevision A gamble elements and is interpreted in general, I’, which is a bounded mapping represent possible as an uncertain that we aim to construct. In fact there are several that are more or less equivalent, [99, Section 3.81. (Lower and upper probabilities for reasons is a real-valued to be explained later.) The simplest model from the possibility function defined on the set C of all gambles. space of interest, 0 (a set whose to the real numbers, states of affairs or “possible worlds”), reward in units of utility. the types of subject to appropriate are not an is a interpretation for the gamble The interpretation for X: it is the supremum of prices which of the quantity p(X) (uncertain is that you are disposed reward) X. Loosely, we may call p(X) less than e(X) supremum buying price that you are willing -X). The -p( price greater than p(X). but here we concentrate will buy or sell X if the price may be reasonable. Similarly, a conditional supremum of buying prices for X that you would be willing that event B has occurred. to pay any price a the model asserts to pay for X. A conjugate upper prevision P is defined by P(X) = to sell the gamble X for any in terms of 7, about whether you either course of action lower prevision e( X 1 B) is interpreted as a to pay if you learned only on P.) The model does not say anything theory could be presented equivalently is that you are disposed lies between p(X) and H(X); (The Buying and selling gambles are somewhat artificial activities and they are introduced also and P(X). These quantities (outlined near the end of Section types of implications for p(X) interpretation in more practical decision problems they could be interpreted in terms of their to give a simple for other here merely have implications 4), and decisions. This interpretation of upper and lower previsions not necessarily interpretation, available evidence; an expert system but can be given a logical as marginal buying and selling prices that are uniquely determined by the that is concerned with a sufficiently narrow domain In some problems, Z’(X) and F(X) and behavioural, is epistemic subjective. 10 I! Walley/Artifcial Intelligence 83 (1996) 1-58 and that does not require any subjective inductive previsions of information information logic [ 1011. The interpretation (like all the other measures considered is reassessed. and will usually change when more from users might encode a system of input is epistemic in the sense that upper and lower state is obtained or when reflect a particular in this paper) information judgements, and P(X) for quantities for a person’s and P(X) that could be specified more precisely, need not be maximally precise. They may be merely in the same lifetime, e.g. 400 and 300 could be generated by merely as in the football example below. This should make it clear that, does not demand as a Bayesian model. Note also that, while it may be possible The quantities p(X) lower and upper bounds way that we could give lower and upper bounds B.C. in the case of Aristotle. The values p(X) qualitative contrary “twice as much precision” to sharpen precise assessment could be represented by a precise point in time. Imprecise may be needed In particular lifetime (upper and lower) previsions incompleteness is no justification could be made, any more the specification of P(X) to common objections, to model there of F’(X) and p(X), there is no reason the assessments than Aristotle’s to suppose that a and P(X) = P(X) p(X) value. This interpretation tion of Z’(X) and F(X), which linear prevision P(X) underlying abilities are similarly interpreted probability vious publications [ 25,30,35,36,41,60,62,66,94]. sometimes ities”. upper and lower bounds preferred the new term “belief called “probability (The term “upper and lower probability” for a precise probability; function”.) information. in the available them as lower and upper bounds or conflict for a Buyesiun sensitivity analysis interpreta- regards for some that is not known precisely. Upper and lower prob- for an unknown, precise as upper and lower bounds in most pre- those in the AI literature are seems to have been taken for granted including Upper and lower probabilities with this interpretation bounds ” “probability , also may be misleading intervals” or “generalised probabil- if it suggests [ 711 to be why Shafer this seems on upper and lower probability, interpretation is both misleading and unnecessary. in most problems, no useful meaning can be given analysis The Bayesian sensitivity It is misleading because, linear prevision”. “underlying be given a direct behavioural gambles or in terms of their implications interpretation is sufficient tion is important because different methods to justify the behavioural for modelling It is unnecessary interpretation, because upper and lower previsions in terms of buying and selling prices in other decision problems, and the behavioural the axioms and calculus of the theory. The distinc- interpretation and sensitivity analysis lead to independence and other structural [ 991. to the can for contributions that belief functions One of the important of the Dempster-Shafer should not be given a sensitivity is that emphasised interpretation [ 751. Every belief function can be represented as a lower envelope of a set of probability measures. This is merely a mathematical unnecessary measure. lower prevision can be represented as a lower envelope of a set of linear previsions, but this is no reason to regard the lower prevision about an unknown as a model for partial representation, to regard a belief function as a lower bound for some unknown probability In the same way, every coherent linear prevision. it is misleading information however; it has and In the theory of coherent lower previsions purely in terms of the behavioural [ 991, all the axioms and rules are justified to a sensitivity interpretation, without appealing judgements theory analysis R Walley/Artijicial Intelligence 83 (1996) l-58 11 (This interpretation. analysis rules for conditioning rely in any way on a sensitivity differ from the Dempster-Shafer includes the axioms for conditional or updating.) So the theory of coherent previsions the lower previsions does not it does not and and in this respect analysis theory or possibility interpretation, theory. Of course there are some examples where E does represent partial information an unknown Bayesian probability measure and a sensitivity justified. The behavioural modellecl by coherent general. which the sensitivity lower previsions. But the behavioural It can be applied, for example, interpretation interpretation still applies is usually analysis to belief functions and possibility measures, inappropriate. analysis interpretation in these cases and interpretation about is they can be is much more for This enables us, in Sections 5 and 6, to view multivalued mappings language in natural interpretation judgements behavioural they are normally given as “measures of evidential-support” it does seem somewhat more definite and useful. although as sources of coherent of these kinds of models need not exclude inexact lower and upper previsions. A and the interpretations or “degrees of possibility”, Coherence Coherence of the lower prevision e can be characterised by three axioms: p(X) 2 inf{X(w): (Pl) (P2) p( AX) = Ap(X) (P3) p(X+ Y) 2 p(X) +p(Y) w E 0) for all X E 13, A > 0, for all X E L, for all X,Y E L. There are various equivalent characterisations the coherence axioms theory and semantics, and this may appeal of coherence in [ 991. Wilson and Moral in the form of a logic, with an associated to readers who are familiar with [ 1131 have expressed proof classical logic. Coherence implies the inequalities (for all gambles X and Y) P(X) +P(Y) <p(x+Y) <P(X) +p(Y) <P(x+Y) <P(X) +B(Y). (Pl) through for any positive constant A. Thus to increase utility. Axiom if AZ is acceptable The three axioms are consistency interpretation the to pay any price less that X is interpreted reward in units of utility.) This is reasonable because such a transaction (P2) says, in effect, that a gamble 2 is acceptable requirements which can be justified behavioural asserts a willingness of L. Axiom than the infimum possible value of X for the gamble X. (Recall as an uncertain is certain of if and only in which its rewards are expressed. To a gamble does not depend on the unit of utility involve two acceptable gambles which (P3), consider justify paying up to p(X) to paying up to P(X) +P( Y) for X+ Y. Hence E( X+ Y), the supremum buying price for (P2) and (P3) are compelling only if X + Y, should be at least E(X) + E( Y). Axioms if gambles are expressed gambles were expressed then depend on whether of two acceptable monetary its units were dollars or thousands of dollars and the combination in terms of a linear utility scale. They would not be reasonable in monetary units, as the acceptability transactions might not be acceptable. for Y. The combined gamble for X and up to p(Y) of a gamble might the superlinearity the acceptability is equivalent axiom 12 P: Walley/Arti&ial Intelligence 83 (1996) 1-58 In general, conditional previsions will be specified as well as unconditional ones. Co- that apply to general specifications of conditional previsions are given in herence axioms [ 991. In the simplest case, where unconditional lower previsions e(. 1 Bi) are specified for each event Bi in a finite partition {Bt , B2,. . . , Bk}, coherence can be characterised lower previsions &’ and conditional in terms of axioms such as (Cl) P(X) 2 min{P(XI (C2) P(X) 6 m={P(X (C3) l’(Bi(X-P(XI Bi),P(X I h),F(X 1 &),...,P(X I &I,. Bi)))=Ofori=1,2,...,k. . . ,p(X 1 &)}, I Bd}, The Bayesian theory of de Finetti lower previsions for all gambles X. Linear previsions which are simply coherent p(X) are the vucuous previsions a}, which maximise ignorance about a. l’(X) In general, the degree of imprecision [28,29] is presented in terms of linear previsions, that satisfy the precision condition p(X) = are maximally precise. At the other extreme = inf{X( w): w E 0) and F(X) = sup{X( w): w E - p(X) and model complete the degree of imprecision P(X) on which information (e.g. between of information mation and statistical data). in conclusions indeterminacy more probable) and greater is better). they are based and the degree of conflict between different in previsions can reflect both the amount of types the assessments of several experts, or between prior infor- leads to greater In turn, greater is to say which of two actions to say which of two hypotheses (we may be unable (we may be unable in previsions imprecision indecision For example, is the most precise model if several experts assess precise previsions Pt (X) , . . . , P,,(X) then it is to define p(X) = min{Pi( X) : 1 < i 6 n} and F(X) = max{ Pi( X) : 1 6 i 6 n}. the and the extent of conflict or disagree- information to every expert to all the experts, a kind of “consensus”), the experts concerning X [ 1031. Other ways of aggregating sources are studied of assessments [97; 99, Sections 4.3, 5.3 and 5.4; 1021. The in expert natural Then p behavioural dispositions the degree of imprecision P(X) ment amongst from several combination systems. in from different is an important problem - p(X) measures that is acceptable that are common (it represents sources Any coherent lower prevision E can be written as the lower envelope of a closed or as the lower i.e. Z’(X) = min{P(X): P E M}, i.e. E(X) = min{ P (X) : P E ext M}. convex set M of linear previsions, envelope of the set of extreme points ext M, Often the simplest way probability mass function ext M. to characterise (or probability the lower prevision E function) density is by specifying of each linear prevision the in Now we return many judgements with any other judgements to compute a coherent the judgements all the constraints prevision e simple example. that satisfies in the system for the expert system to the problem of natural extension. Suppose of uncertainty. The problem that a user makes finitely these is to combine those supplied by domain experts) lower prevision P. This can be done in three steps: ( 1) translate that into constraints lower is illustrated by the following terms, hence consistent; the constraints. This procedure on E; the minimal (2) check coherent into behavioural are mutually (3) compute (including P Walley/ArtQicial Intelligence 83 (1996) 1-58 13 Example 1 (Football game). Consider win ( W), draw (D) or loss (L) the outcome, the user makes the judgements: a football game whose possible outcomes for the home team. To express his uncertainty are about (a) prclbably not W, (b) W is more probable (c) D is more probable To construct than D, than L. to mean terms. We take (a) that the user is willing the natural extension of these judgements we first translate if W occurs, provided he gains one unit in which behavioural of utility notation, (the p( W) < i, or equivalently Z’( D + L) 3 to pay one unit if D occurs, provided he receives one unit if W occurs. This yields constraint Z’( W - D) 3 0. Similarly into to give up one unit if not W. We will use de Finetti’s that pays one unit if event W occurs and zero otherwise the constraint is denoted also by W. Then is willing the (c) yields Z’( D - L) 2 0. function of W) i. According the gamble the subject (a) yields indicator to (b), them the system of linear can be computed by finding The natural extension of the three judgements the set M by d + I 2 i, w 2 d, d 2 1, w 2 0, d 2 0, 1 > 0, (w, d, I) that are consistent with the judgements, of all probability mass functions solving w + d + I = 1. Because The extreme points of M are the three probability mass functions (i, $, a). The lower prevision of any gamble X can then be calculated as the minimum expected value of X under these three mass functions. For example, this system has solutions, the three judgements (3,:) $), (i, 4 , 0) , are consistent. inequalities: EJW)=min{t,&,#}={, F(W)=max{4,i,$}=f. Many other kinds of qualitative or quantitative we have considered, for example, judgements could be added to the three if rtot D then W is very likely, (d) (e) W is between 1 and 2 times as probable as D, ( f) I am willing (g) W has precise probability Some orher natural-language to bet on L at odds of 4 to 1, 0.4. judgements conditional probabilities, independence, are considered in Section 6 and further exam- ples are given in [ 991. In more complicated problems, one might also make judgements positive or negative dependence, of conditional func- permutabi‘lity or exchangeability, can be regarded as tions or distribution although constraints the linear programming are to special types of assessment or made, and then it may be necessary (b) and (c) can model. Note especially be combined with numerical in occur together many applications. intervals of measures, upper and lower density these judgements functions on E. They can be combined intractable when many assessments the two types of judgement problem may become by natural extension, that ordinary-language to restrict attention or quantiles. All (in principle) such as (a), assessments; judgements How would Bayesians deal with the football example? They would require a user to that to go beyond arbitrary numbers which would not make more precise assessments is consistent with judgements judgements, these qualitative (a), except by choosing (b) and (c). But he may be unable a single probability measure in order to determine 14 P. Walley/Arti$cial Intelligence 83 (1996) 1-58 reflect his state of uncertainty the game or expertise in assessing probabilities. about the game, because he lacks either information about from M One popular method for selecting a unique probability measure is by max- ($, 3, 3) in the football example. But a second-order probability the mass function such as assigning imising entropy. This gives distribution there are alternative methods, on M, which yield different answers, and any choice of a single probability measure the partial information seems arbitrary. Note that maximum entropy does not distinguish provided by the three judgements the same probability model at all about the game. No precise probability would be selected measure can reflect the imprecision of the three judgements. For discussion of maximum entropy, see [ 4232,991. if we had no information from complete ignorance: Upper and lower probability By applying interpretation the behavioural of event A can be interpreted as specifying the lower (or upper) probability rates for betting on (or against) A. Consider a choice of whether to bet on or against A at betting you rate x, meaning odds of x to 1 - x on A. You will bet OIE A if x is less than P(A), will bet against A if x is greater than F(A), (it may be reasonable and your choice is not determined of lower and upper previsions, to choose either way) if x is between &A) acceptable and p(A). Upper and lower probabilities the empty set, P( 0) = p( 0) = 1, p(A) = 1 - E( AC), where AC denotes have the basic properties E(8) = p(8) = 0, where 0 the and are determined by lower probabilities, of A (hence upper probabilities denotes complement vice versa), 0 < l’(A) 6 p(A) < 1, and P(A)+P(B) <P(AUB) <P(A)+P(B) <P(AUB) <B(A)+B(B) when A and B are disjoint. These properties are necessary but not sufficient for coherence. The further property that p( A U B) +F’( A JIB) 2 c(A) +F’( B) for all events A and B, is for coherence but not necessary. Some of the mathematical simplifies when the lower probabilities of 2-monotonicity, sufficient lower probabilities as “Choquet capacities of order 2”); see especially probabilities theory of coherent (also known for conditional in [40,96,102]. a lower prevision R is to assess upper and lower probabilities the simple formulas at the end of this section, and the theory One way of constructing and expectations are 2-monotone and l’(A) for all events A and can be constructed to construct _P_ by natural extension. Not all lower in this way, because many coherent p(A) coherent previsions lower previsions can generate the same upper and lower probabilities. that the initial assessments are upper probabilities f , a , 0 for the events F D, L respectively. generated by the three judgements considered (These are earlier.) suppose In the football example, i, i, 4 and lower probabilities the upper and lower probabilities Their natural extension the lower envelope of the five probability mass functions to a lower prevision &, calculated as in the previous example, is (4, a, f), i, 3). This is different from the lower prevision Et constructed earlier, although =0 but&(X) then P,(X) = (l,-1,O) i,O), =-i, (i,:, (i, i), the same upper and lower probabilities for all events. (i, i, i) and (5, e.g. if (X(W),X(D),X(L)) e, and & generate l? Walley/Art$cial Intelligence 83 (1996) 1-58 15 Thus lower previsions probabilities modelled prevision previsions (defined on all events), (defined on all gambles) than lower is solely in terms of upper and lower probabilities. That is why we take lower to be the fundamental model, rather than lower probability. Lower (or upper) than lower (or upper) probabilities. are more expressive and information may be lost when uncertainty contain more information The extra in lower previsions conditional information upper and lower probabilities. Without it the conditional probabilities may be excessively imprecise. That can be seen in the football example. Taking B = {K D}, the first (lower (lower prevision) model gives p(W 1 B) = $ and F(W 1 B) = 3, whereas is often crucial in defining the second probability) model gives less precise values E( W 1 B) = $ and F( W 1 B) = 3. (In both cases the conditional the extreme points probabilities were calculated by conditioning and finding upper and lower envelopes. This agrees with natural extension.) In general, conditional upper and lower probabilities unconditional ditional upper and lower probabilities conditional nonzero lower probability. lower previsions, upper and lower probabilities through and previsions through axiom (C3), provided the coherence are uniquely determined are not uniquely determined by axioms. But con- by un- event has the conditioning for regarding as fundamental Another reason quantity whose value lower previsions than lower probabilities. is uncertain, be assessed more easily a real-valued easier to assess upper and lower previsions probabilities are also needed when we start by assessing upper and lower probabilities, an event and condition by natural extension; updated upper and lower probabilities Thus upper and lower probabilities is that they can often If we are primarily concerned with such as a person’s age, it may be rather than upper and lower to particular sets. Lower previsions then observe the again information may be lost if only that the quantity belongs for the quantity for the events [41]. and, on the interpretation is a defect of all theories of upper and lower probability, functions theory, dealing with upper and lower previsions needed. In particular, upper and lower probabilities language mdgements of uncertainty. are reported are often inadequate models for uncertainty. This the theory of belief including theory. A more general is adopted here, possibility or an equally general alternative, are inadequate for modelling natural- Natural extension Now consider the general procedure of natural extension. Suppose I Bi) > pi for 1 < i < k, where say p(Xi finitely many judgements which can be translated previsions, (The case of unconditional precise judgements Then the natural extension by solving a linear program, using to any conditional the formula previsions P( X I B) = p by taking p(X 1 B) > ,x and J’( -X I B) 2 -p.) lower prevision P( X 1 B) can be computed into constraints on conditional ,zi are specified is included by taking Bi = R, and the case of that a user makes lower real numbers. k ,UU: B(X-p) 2 CAiBi(Xi-pi) for some A; 20 (1) i=I 16 t! Walley/Art@cial Intelligence 83 (1996) l-58 through where Y > Z denotes Y(w) > Z(w) functions, can be justified willing tiples of such gambles, on B. The resulting value of p(X in the sense consistent [ 991. coherence to pay up to ,ui for Xi conditional induce you I can 1 B) for all w E 0, B and Bi stand for indicator and p and pi denote constant gambles. This definition of natural extension interpretation the behavioural of lower previsions: if you are positive mul- for X conditional judgements that they “avoid sure loss”, a much weaker requirement on Bi then, by combining ( B) the initial to pay up to p(X is finite provided are than that satisfy the initial constraints all the inferences that can be derived In fact, the natural extensions from the initial e are the and are coherent. There may but they must in the sense that E”( X 1 B) 2 I’( X 1 B) for all gambles that is not the initial constraints, information additional summarises the rules of coherence. Natural extension through lower previsions the natural extensions lower previsions p’ that satisfy judgements minimal be other coherent dominate X and all events B, and implied by the initial set of judgements. often disagrees with natural extension conditional may not be consistent with the initial belief function. they incorporate independence therefore rule of conditioning of judgements function and which For example, Dempster’s because it implicitly involves that are not implied by the initial belief Indeed construction the following of conditional Natural extension [ 281; construction from probabilities; from unconditional to express his uncertainty can be regarded as special judgements. The initial constraints is a very general method of inference. types of natural extension: construction tant constructions (upper and lower) expectations and lower) probabilities bility” of de Finetti probabilities from qualitative impor- of (upper ones; the “Fundamental Theorem of Proba- of inner and outer measures; construction of joint from marginal and conditional ones; and construction of probability models are quite general and this allows a e.g. through expressions in Section 6, or judgements. The results of natural it can be used to construct a lower prevision p( X 1 B) gamble X and event B, hence to construct upper and lower proba- lower and decisions functions, both of which user qualitative judgements through a combination extension for any conceivable bilities and preferences between gambles. previsions of important variables conditional by computing are linear programming such as the natural-language of qualitative can be made by computing information, lower previsions of differences between utility forms are most convenient, are also very general; and quantitative on all available in whatever Inferences problems. listed Alternatively the natural extension can be computed, inequalities solving a set of linear are consistent with the initial constraints, the dual linear programming judgements what is known as “probabilistic problem. logic” are precise and no independence to obtain [60,62]. the extreme probability mass functions as in the football example, by that their lower envelope. This is and then forming In the special case where all the initial probability judgements are made, it is equivalent to This alternative procedure breaks down when independence constraints are included these are nonlinear. On the behavioural that two events are independent means because judgement of one event would not change This is quite different interpretation that the upper and lower probabilities if you learned whether or not the other event occurred. that the events are independent under some Bayesian of lower previsions, from judging a P Walley/Artijicial Intelligence 83 (1996) 1-58 17 probability measure definition of independence that satisfies the other constraints, which would be the appropriate [ 1051. analysis interpretation sensitivity under a Bayesian C0nside.r the simplest case where upper and lower probabilities events A and B that are judged and p(B) = j?. Then constraints P(A) Z’( BC ) AC) 3 1 - p, and the natural extension of the judgements natural exlension of these constraints, for two say P(A) = cx, p(A) = 6, p(B) = p the 12 2 g, F’( A 1 B) 2 ct, l’(A 1 BC) 2 cy, . . ., P( BC 1 A) 2 1 - fi, can be computed by to be independent, of independence the behavioural using E!q. (1). interpretation are assessed imposes Bayesian sensitivity analysis would model in a different way, by the: set of joint probability measures P which satisfy the constraints g < P(A) < is the judgements constraint j? 6 P(B) < fi and P(A n B) = P(A) P( B). difficult finding 5, nonlinear this makes and Upper and lower previsions solutions. The two approaches do produce different numerical of two unreliable witnesses the computations in Section 5. are then defined as upper and lower envelopes of the set of answers; see the example independence (The in more complicated examples.) All previous work in AI, e.g. [ 25,30,35], definition of independence A comparative and computational methods. study of the two approaches for granted, without considering seems to have taken the sensitivity analysis definition. is needed, with regard to both interpretation the behavioural judgements ‘constraints on lower previsions, Using the behavioural definition of independence, of conditional are made. Computations is more complicated when many structural in general, by solving a finite sequence of linear programs with progressively constraints. At each stage the independence conditional lower previsions stage, giving a stronger set of constraints It is not yet clear whether this is feasible numbers of conditional independence that have been studied by Bayesians. the computation of natural extension or other independence, can be carried out, stronger to the in the previous for the next application of natural extension. large for complex problems with moderately or for the types of belief networks that were produced by natural extension and structural constraints judgements, are applied There has been a substantial tion of upper and lower probabilities [ 10,941 using measures the sensitivity amount of work in recent years concerning the propaga- [ 25,30,94] or convex sets of Bayesian probability analysis definition of independence. Natural extension can be applied to a completely but the linear programming of assessments are made. problems.:1 When (Of course Bayesian is sufficiently independence intractable this happens, several approaches might be considered. large, especially when many also become computations computations will become arbitrary collection of assessments, impracticable when the number judgements in unstructured only involving formulas, local computations, First, we could use simpler for E’( X 1 B) and upper bounds to give for Ti( X 1 B). Some examples of (see also [ 66,941) . This approach that are always valid but less precise than those produced by natural I B) without necessarily lower bounds such formulas are given in the following produces conclusions extension. Alternatively we might finding a lower bound. Some approximation methods are suggested in which than the first as it may produce in [60] for the case is less appealing are precise. This approach invalid conclusions. try to approximate ,a11 the probability assessments subsections p(X 18 P Walley/Art$cial intelligence 83 (1996) l-58 Finally, the approach that seems most likely to be useful in practical problems types of imprecise probability models, such as the 2-monotone develop special probabilities functions, for which natural extensions gramming. Examples are given in the following or models defined in terms of upper and lower density can be computed explicitly, without subsections. is to lower functions or mass linear pro- to diagnose to measure uncertainty but differs The expert system INFERNO [66], designed upper and lower probabilities from the approach suggested here. First, INFERNO works by propagating straints on upper and lower probabilities. localising much weaker while valid, may often be too weak to be useful. Second, of updating probabilities only be regarded as specifying measure. This has the advantage of simplifying the propagation method and constraints the conclusions faults on oil rigs, uses in two important ways simple con- and are of the system, the system provides no way can further constraints on a fixed, unconditional on new evidence. Any new information those given by natural extension, computations. However, because by conditioning probability than Calculus follow example interpretation of coherence is a coherent the behavioural lower prevision the rules of the theory defined on a sufficiently the principles through from and they can therefore be justified and natural of is the generalised Bayes rule (GBR) : when and large set of gambles is the unique solution n of the and take xa to be any estimate of x, All extension, lower previsions. An important p p(B) > 0, the conditional lower prevision equation &‘( B( X - x) ) = 0. This equation otherwise by simple and define asequence to the solution x, and the error is bounded by CCP where Then are uniquely a = (p(B) determined in the GBR have been specified and J’(B) > 0. The GBR can be used to update the initial prevision p after learning the GBR reduces the sequence converges - I’(B)) that event B has occurred. When p can sometimes be solved explicitly, , a version of the usual Bayes’ rule. by x,,+t =x,+2f’(B(X--x,))/(p(B) is a linear prevision, the lower previsions .) Thus conditional iterative algorithms. /(P( B) + f’(B)) by unconditional ones, provided (For example, ofestimates !‘(X 1 B) previsions involved +P(B)). exclusive hypotheses, B is an observable suppose {Al, AZ,. . . , Ak} is an exhaustive event, and upper and lower for 1 < i < k. (This that the assessments 1 Ai) are assessed in Section 3.) Assume to P (X 1 B) = P (BX) /P(B) As another example of natural extension, 1 Ai),P(B the Bayesian model considered conditions set of mutually probabilities P(Ai),I’(Ai),P(B generalises satisfy P(A;) < 1, and F(Ai) +Cj#eP(Aj) We might wish probabilities the coherence to calculate and P(B), J’(B) To do so, it is convenient l’(A,i) < P( A,/) < B(A,i) A,,,&,..., j < r, equal to p( A,j) A,,, determines 0 < p( B 1 Ai) < P( B 1 Ai) 6 1, 0 < p( Ai) < for every 1 < i < k. < 1 < P(Ai) +C,P(Aj) and to posterior probabilities P(Ai the natural extensions of these assessments to predictive I B) and P( Ai I B). to define the extremal probability measures P which satisfy for 1 Q j < k. Any ordering of the hypotheses, denoted by if an extremal P as follows. Set P(A,) equal to p( A,j) if j > r, and intermediate between e( A,,,) and F( A,,, ) if j = r, where the values of r and P( A,,,) are determined by $=i P(A,,) = 1. P Walley/Art@cial Intelligence 83 (1996) l-58 19 [99, Theorem Using C;=l P(13 extremal probability measure determined b values of F’( B 1 Al). Similarly = I Aj)Pl (Aj)T a weighted mean of the values P( B 1 A,i), where Pt is the ordering the hypotheses to have decreasing fr( B) = cj=, P (B 1 Aj) P2( Aj), where P2 is defined by can be written the natural extension as P(B) 6.7.21, r- for- ordering mulas simplify when Z’( A,!) = P( Al) for all j, as then PI (Aj) = P2( Aj) = e( Aj) .) In to have increasing P( B I Aj). (These and the following the hypotheses is bounded by C;=t P(B general J?(B) but these bounds may be far from sharp. from [99, 8.5.41, Using a result observing B are I Aj)P(Aj) the posterior < P(B) 6 & P(B I A,/)P(Aj), lower and upper probabilities after PC4 I B) = P(B I Ai>P3(Ai) P(B I Ai>& + Cj#P(B 1 AjJP3CA.i) ’ (2) where 91 is defined by setting nl = i and ordering p( B 1 A,i), and the other hypotheses to have increasing F( Ai 1 B) = - f’(B P(B I Ai)fi(Ai) I A,)P4(Ai) + Cj#iP(B I Aj)fi(Aj) ’ where P4 is defined by setting nk = i and ordering P( B 1 Al). In this problem could be obtained by substituting Eqs. models prior upper and lower previsions involving belief networks are studied the computations concerning (2) and either p( AJ) or P( Aj) for P3 (Aj) and Pd(Aj) the other hypotheses to have decreasing are quite simple. If needed, simpler bounds in in [25]. More general in [ 941. Other results, allowing general (3). A special case of these results was used the hypotheses Aj, are in [ 96,991. These formulas simplify in the case where there are only two hypotheses, Al and A?. the ptior upper and lower odds Let p = 7’( Al > /I’( AZ) and p = &( Al ) /P( AZ) denote on AI, and let x(B) = F(B-1 Al)/l’(B I AZ) be I Al)/itr(B the upper and lower likelihood ratios generated by B. The posterior upper and lower are determined by the posterior upper and lower odds probabilities of the hypotheses on A 1, which are given by the multiplicative I AZ) and A(B) = P(B formulas F(B) = F’(A, 1 B) f’(A2 1 B) =pA(B)’ _- P(AI I B) p(B) = = P(A2 I B) = phW. These generalise the Bayesian formula: posterior odds = prior odds x likelihood ratio. Conditional probabilities Suppose that coherent upper and lower probabilities, P and p, are specified for all ) B) and F’(. ( B), e.g. to update beliefs after observing subsets of a, and that we wish to construct conditional upper and lower probabilities the event B. This problem B(. in this paper (Bayesian, belief func- is of interest because and expectations tions and possibility from the classical in terms of unconditional to define conditional probabilities (This seems to be a hangover the other theories examined theory) attempt probabilities. 20 P. Walley/Art@cial Intelligence 83 (1996) 1-58 It is important theory of probability.) of a much more general problem. ments we can and use natural extension it may often be easier and more and previsions directly problem in the previous subsection). tional upper and lower probabilities are made, should be regarded as atypical. to recognise, however, In general we will make whatever probability to construct other probabilities that this is a special case assess- and previsions; probabilities informative than to assess all unconditional to assess some conditional probabilities So the problem considered here, in which uncondi- are assessed for all events but no other assessments (e.g. consider the Let B be any subset of 0 such that f’(B) > 0, and let M denote the set of all probability measures P such that P(C) > p(C) conditional on B can be computed by applying giving for all C C 0. Then lower probabilities the general formula for natural extension, P(A 1 B) =SUp PU: B(A-,u) > kA,i(Ai-P(Ai)) { i=l for some n 2 0, Ai G 0, hi 2 0 1 =inf{P(A fl B)/P(B): P E M}. (4) Provided fi is finite, P(A 1 B) can be computed by linear programming simpler (Much discussed below.) A more general formulas can be used in the special case where E formula, which applies whenever P(B) > 0, is techniques. is 2-monotone, &(A ) B) = inf{P(A fl B)/P(B): P E M, P(B) > 0). The conditional upper probabilities are defined by F(A 1 B) = sup{P(A n B)/P(B): P E M, P(B) > 0). The conditional probabilities p( e 1 B) and P(- 1 B) defined by these formulas are lower and upper probabilities. Thus conditioning always coherent preserves coherence. Moreover, &a 1 B) and B( - 1 B) are always coherent with the unconditional lower probabilities, by natural extension. probabilities belief functions and possibility measures are also closed under conditioning e and P. We will see that the families of 2-monotone by natural extension Provided p(B) > 0, the conditional probabilities satisfy the following inequalities: P(A n B) P(AnB)+P(ACnB> P(AnB) P(AnB)+lJACf7B) <P(A I B) < min J’(AnB) F(AnB) F’(B) ’ P(B) ’ >P(A I B) 2 max P(AnB) B(AnB) Z’(B) ’ B(B) > ’ These hold whenever p and P are coherent, but the lower bound actually achieved whenever p has the stronger property of 2-monotonicity. the natural extensions are for P(A I B) is In that case R Walley/Artifcial Intelligence 83 (1996) I-58 21 &PI 1 B) = Pt.4 n B) P(AnB) +P(ACnB)’ P(P, 1 B) = _ F(AnB) P(AnB) +P(ACnB)’ (5) = 0, provided the denominators apply when F(B) (The same formulas are nonzero; is zero, and H(A 1 B) = 0 if the second denominator > 0 and provided Z’(B) > 0 [9,15,23,96]. set P(A 1 B) = 1 if the first E(B) is zero. This case denominator ] B) = 0 and p(A 1 B) = 1 for every A that satisfies is uninteresting p( A n B) > 0 and F( AC n B) > 0.) Numerical examples of this rule will be discussed in Sections 5 and 6. It has been generalised the posterior probabilities function and prior lower probabilities that are Z!-monotone. generated by a statistical in [96,102,108] because &A to characterise likelihood When p is 2-monotone, the conditional as well as coherent. Thus conditioning (See for a proof.) [96] Expectations lower probabilities P(. 1 B) are 2-monotone by natural extension preserves 2-monotonicity. (bounded are specified that coherent upper and lower probabilities to construct upper and lower previsions or “expectations”, Again suppose sets of 0. We wish and P’(X) , for gambles in order to make decisions we would need to compute upper and lower previsions of differences between functions. But again we must point out that the case considered here, in which utility are di- unconditional rectly assessed, judgements and lower probabilities. in the football example, cannot be modelled adequately is atypical; especially as some judgements, for all events but no other previsions random variables) X. For example, such as the natural-language in terms of upper are assessed for all sub- probabilities F(X) Again natural extension the upper and lower previsions ( 1)) giving can be computed from the general formula for p(X)=SUp ,UU: X-p>k&(Ai--P(Ai)) forsomen>O, AiG 0, Ai>O i=l = inf P(X)=inf /LU: X-/L<eAi(Ai-P(Ai)) forsomen>O, AiLa, Ai>O i=l = sup {I XdP: P E M . > (6) (7) Again these formulas simplify 2-monotone. Define F;x and &, in the special case where the upper and lower distribution the lower probability E is of X, by functions 22 R Walley/Art@cial Intelligence 83 (1996) 1-58 = P({,: Fx(x) 2-monotone, X(w) < x)1 and &(x> = p( {w: X(o) can be written as Choquet the natural extensions M P(X) = s xdFx(x), -co 02 P(X) = s x@,(x). --oo < x}). Provided c is integrals [96] (8) Decision making the decision problem Upper and lower previsions are used to make decisions in the following way. Suppose we need to choose an action from a finite set of possible actions {al, a2,. . . , ak}, where the utility U( a, w) of action a depends on the unknown w. (We assume that utilities are specified precisely; otherwise gamble Xj by Xj( w) = U(aj, W) for each j = 1,2,. and a,j we compute on all available preferred information action aj that is preferred reasonable real decision problems is more complicated.) Define a two actions ai the upper and lower previsions P( Xi - Xj) and p( Xi - X,j) based to aj if &(Xi - Xj) > 0, a,j is to choose any of the maximal actions. For more details and applications if there is no other and it is to - X,j) < 0, and if neither condition holds there is insufficient a preference. Say that action ai is maximal see [99, Sections 3.9 and 5.6; 101; 1031. information. Then action ai is preferred to ai if P(Xi to determine actions can be eliminated, to ai. The non-maximal . . , k. TO compare This method produces only a partial preference ordering for generating than one maximal in [57,85,99]. All such methods seem somewhat arbitrary. judgements in general, and there may are complete preferences It should be ac- there may be more than action. Methods are imprecise, be more discussed knowledged one reasonable that, when probability course of action. Imprecise conclusions The inferences produced by natural extension are often imprecise. That can be seen in events and an expert assesses about their degree of depen- for their intersection is used to compute conditional independent i but makes no judgement to upper and lower probabilities then the natural extension simple examples, e.g. if A and B are logically that each has precise probability dence, is p( A n B) = i, E( A n B) = 0. When natural extension upper and lower probabilities be highly amples are discussed such as Dempster’s Advocates produce excessive of the alternative methods have suggested rule often produce conditional later in the paper.) from unconditional imprecision. imprecise, especially when the initial probabilities In such cases, other methods of conditioning that are more precise. to that natural extension probabilities tends ones, the conditional probabilities may (Two ex- are 2-monotone. Wilson and Moral [ 1131 have given an interesting example of this, also discussed in that an expert makes two assessments of conditional [ 1201. Suppose E( B 1 A) = 1 and Z’(C 1 B) 2 0.999, where A, B and C are logically events. What do these judgements imply about p(C 1 A)? lower probabilities: independent P WaNey/Arttj?cial Intelligence 83 (1996) 1-58 23 is “close judgement It may seem to” P(C 1 B) = 1 which, that we can make a fairly strong the inference E( C 1 A) = 1 by natural extension. the 1 A) = 1, second the would yield general ( 1), and use A n Cc C (A rl BC) u (B n Cc) to show that A (C - 1) 2 A (B - 1) + B (C - 1) .) However, natural extension of the expert’s judgements These inferences p( C 1 A) = 0 and P( C 1 A) = 1. indeed seem “excessively imprecise”, but I believe produces only the trivial in this case, because for natural extension (To see that, apply together with P(B inferences may that they inference formula Suppose the further further assumptions. because nothing more can be derived from the two explicit judgements are reasonable that an alternative method of inference without making lthe conclusion p(C 1 A) 2 S from the two judgements, where 6 is a specified produced positive number. The expert might then make some further assessments about the events, rl C) = 0. Suppose he makes since all four These judgements judgements are consistent with a Bayesian probability measure P that satisfies P(B) = 1, P(AflB) new judgements F(C in the two initial inconsistent with the expert’s other beliefs. that the inference goes beyond it relies on extra (implicit) I A) = 0. This shows judgements; are perfectly consistent with the two initial judgements, are not consistent with the inference p(C ( A) > S because the information that P(A) > 0.001 and P(A =0.999andP(ArlC)=O.Howeverthe assumptions which may be they imply contained =O.OOl,P(BnC) judgements =P(C) =P(A) can be generalised as follows. Let Dt and V2 denote let Et denote a set of inferences produced from Dt by applying This argument and judgements rules of the calculus. Then we require set of judgements (Dt U 2)~) is consistent the following consistency principle: then (Et U VT) should be consistent. two sets of the if the overall The force of this principle depends on the technical meaning that is given to “consis- sure and they are are “consistency” the consistency inferences possible, therefore, the explicit the rules of natural extension do satisfy is identified with “avoiding principle, if the consistency principle that natural extension produces exactly tency”. In the theory of lower previsions loss”, the strongest the most precise It seems, implied by imprecise, not because natural extension because and assumptions tation of natural extensions will often reveal that compels us to make our judgements more precise. For example, unconditional probabilities are more informative rules which do so. That is, the inferences given by natural extension is to be satisfied. the inferences Inferences may be excessively is the wrong method of inference, but rather the compu- are excessively or decisions that tend to generate very imprecise conditional can sometimes be resolved by assessing upper and lower previsions, which upper and lower probabilities and assumptions. the judgements in conclusions indeterminacy the problem judgements imprecise. Indeed that are than probabilities inferences and therefore generate more precise is to add judgements in many problems tional p( C I B) 2 0.999. The natural extensions must satisfy or dependence. Consider again the judgements P(B the coherence conditions One way to sharpen independence inferences. of condi- I A) = 1 and P(CIA)>P(BnCIA)>R(CIAnB)P(BIA), hence p( C I A) 2 p(C p(C independent I An B) to P’(C ) A n B) in this case. This is useful only if we can relate I B). One way to do so is to judge that A and C are conditionafly 1 B) 2 0.999 and hence I A n B) = p(C given B, which gives p(C 24 F! Walley/Art$cial Intelligence 83 (1996) l-58 I’(C 1 A) 3 0.999, a very strong conclusion. The same inference weaker judgement P(C 1 A n B) > p(C A and C are essentially nontrivial is produced by the on B, so that that events, and this must be ruled out before any that A and C are nonnegatively correlated conditional inference can be obtained. to rule out the possibility 1 B). Either condition incompatible suffices Another way to sharpen inferences assessment of &(A 1 B). Coherence in this problem that requires is to make a further numerical p(C 1 A) Zp(C IAnB) aP(AnC 1 B)/(fJAnC 1 B) +F(AnCC 1 B)). Here Hence P( C I A) 2 1 - O.OOl/p( A I B), and any assessment of f’(A 0.001 will produce a nontrivial that Z’( A 1 B) 2 0.01 gives the strong conclusion E( C I A) > 0.9. lower bound for &( C 1 A). For example, I B) greater than the judgement are needed independence that, in moderately complex expert systems, or assumptions It appears of conditional and produce useful conclusions, Many expert systems use expert knowledge about causal relationships to build “belief networks” based on assumptions systems supplies no information are assumed In other are taken as default assumptions; if the expert or user then they to reduce the effort of assessment about the relationship between two events or variables to be independent. of conditional independence. independence judgements constraints Such default assumptions may sometimes be needed to produce useful conclusions, but that they always be made as explicit as possible (they may be inconsistent it is important with an expert’s other beliefs), reasonable set of judgements with and without default assumptions of default assumptions in [113]. in a particular application, becomes that users be encouraged inconsistent. and that they can be easily retracted inferences Ideally, so that a user can compare to consider whether they are if the overall should be computed both their effects. A logic is outlined that is compatible with the theory of lower previsions Conclusion The theory of coherent lower previsions is a general and partial ignorance. Lower previsions theory of reasoning the are more general and in They have a simple behavioural as supremum buying prices for gambles and they should not be interpreted, lower and upper probabilities. presence of uncertainty than more expressive interpretation in general, as lower bounds for an unknown Bayesian prevision. satisfies criteria The theory certainly (a)-(d) interpretation which supports of Section 2. Lower previsions have a the principles of coherence and natural clear behavioural and they extension. All the rules of the theory can be derived can be used to check consistency and to ensure consistency of assessments with conclusions. The imprecision of lower previsions can be used to model of the initial assessments these principles, from P. Walley/Artifcial Intelligence 83 (1996) 1-58 25 several of probability conflict between a lack of information, opinions, or the vagueness models can be produced by combining precise or imprecise numerical assessments. Because lower previsions have a behavioural interpretation, are expressed it is quite easy to understand in terms of them, and to use them in making decisions. in principle, by allowing or between expert language. Coherent judgements with types of information in natural the practical meaning of conclusions (natural-language) can be handled, judgements qualitative that he finds most comprehensible In particular he can express his uncertainties and natural the user to make from a wide variety in ordinary in Section 6. Other important sources of some ways of doing so are discussed include multivalued mappings (Section 5)) partial information [ 1031 and various models It seems that, in complex problems, assumptions of expert opinions combination independence will be needed and produce useful conclusions. Further work is needed judgements, to study how independence independence in expert systems, and to determine to reduce the effort of to compare several can be used its effect on the precision The genera1 method for making the computation inferences and decisions of natural extension problem, or (in the case of independence judgements) these problems may be intractable types of models are required. Again further work is needed are made, and then (as in the Bayesian in moderately in the theory can be reduced is natural to a linear to a finite sequence large ex- theory) to find computation- especially when independence (e.g. using 2-monotonicity for propagating lower natural extensions, to develop tractable types of models and to develop efficient methods The task of assessment judgements judgements. lower previsions whatever of admissible language; coherent about precise probabilities, based on statistical data [99,101,102]. of independence assessment ways of modelling as a default assumption of coaclu,sions. or conditional In general, extension. programming of linear programs. Again, pert systems when many assessments special ally efficient methods judgements or upper and lower densities), in belief networks. previsions for computing are involved, 5. Belief functions The th’eory of belief functions was initiated by Dempster the 1960s and developed by Shafer [ 34,741]. For more in [ 19,65,76,84,92,107,112]. called “the transferable belief model” systems PULCINELLA [69] and [49,58]. include OASES [5] and its shell recent developments see Smets has developed [ 711. Its relevance to expert systems [64,75] and an interesting [ 82-851. Applications of belief functions [ 391, PSEIKI [4], MacEvidence in a series of papers in is discussed the ensuing discussion theory in expert [44,47], variant of the A belicffunction p is a real-valued function, defined on all subsets of a possibility in the form P(A) = CBCA m(B) for all subsets A, space 0, which can be written where m is a probability mass function on subsets of 0, i.e. m(0) = 0, m(B) 2 0 for all B C 0, and ~ecnm(B) = 1. Here C denotes set inclusion, not necessarily strict. (In Smets’ theory m@) may be positive.) The conjugate upper probabilities are defined by B(A)= 1 -f'(AC)=~,,,gm(B). 26 P Walley/Art$cial Intelligence 83 (1996) l-58 the probability assignment formula m(B) = C,,,( a function m through-this -1) lB-Alp( A). Any for E. It is determined by lower formula, and p is a belief as a if m is a probability mass function. One can think of m(B) The mass function m is called the Mobius p inversion through probability function p determines function that is free to move fluid probability mass measures are a special type of belief function set. The vacuous lower probability if and only to any element of B. Bayesian probability for which m(B) = 0 unless B is a singleton is a belief function, defined by m( 0) = 1. Interpretation The natural extension of a belief the coherence axioms is a coherent gambles X by p(X) satisfies function behavioural rates for betting on event A. interpretation (Pl)-(P3) lower probability = xBcam( B) inf{X( w): w E B}. function E to a lower prevision is defined It is easily verified in Section 4, and it follows function. So belief functions can be given of lower probabilities: P(A) is a supremum for all that p that every belief the of acceptable functions of belief interpretations ; see [ 831 for a survey. Shafer prefers Various other 65,72,75,76,85,104] by drawing an analogy with a “canonical [ 72,751. In Shafer’s canonical the belief function through a multivalued mapping lying precise probability measure underlying probability measure does appear to have a behavioural of rational betting through interpretation also a necessary consequence rates, and the belief function [99, p. 1821. So it seems the multivalued mapping of his interpretation. of belief functions example, inherits have been discussed in [36,63- to interpret belief functions coded message” from an under- (defined below). The in terms interpretation is generated this behavioural interpretation to me that a behavioural is not only compatible with Shafer’s interpretation, but example” of a “randomly Indeed, implications the behavioural functions have certain I regard Shafer’s semantics and the other interpretations interpretation It requires the behavioural “minimal” that belief of belief functions interpretation. On [ 99, pp. 20 and 611, as possible ways of elaborating it is compatible with a wide because I call for variety of elaborations. betting and other decisions, but it does not exclude other semantics which relate belief functions Shafer to the evidence on which they are based. [75] describes the random coding example as a “metaphor” which may pro- is functions. The behavioural are used in making decisions. The two types of (I prefer to call Shafer’s of belief to construct belief to make decisions [ 331. Without one, is rather In practice we need functions vide some guidance concerned with how belief interpretation are compatible canonical functions, functions and this seems the practical meaning of inferences somewhat unclear. See [ 1071 for an interesting In [ 721 Shafer does accept the behavioural example an “assessment but that is not to deny from evidence, but we also need in constructing belief functions to require some kind of behavioural and I think that both are needed. in terms of belief functions comparison of the two interpretations. interpretation of belief functions, although In [75] he argues functions, of belief that other aspects of their meaning against a Bayesian sensitivity strategy” its utility.) he argues vehemently than an “interpretation” that are expressed to use belief interpretation interpretation interpretation important. are more analysis I? Walley/Art@cial Intelligence 83 (1996) l-58 27 interpretation. that the whole Dempster-Shafer theory is compatible interpretation. The theory of coherent is irrelevant to the present discussion the sensitivity lower previsions and the rules of natural as I also reject but that argument analysis extension rule from Of course rely only on a behavioural I am not claiming interpretation for combining of belief belief inferences of the theory the “random together with an with a behavioural Dempster’s rule produces presentations naturally functions, fact, even under Shafer’s own semantics, on stronger assumptions in many applications. do the other Dempster’s compatible with a behavioural rule is not. interpretations rule. Shafer’s of conditional assumptions semantics of belief (These that are unacceptable under a behavioural [75,76] give the impression coding” or “multivalued mapping” inocuous assumption of unconditional functions. Much of the theory functions, and interpretation. is based on in many problems Dempster’s Some rule follows for belief In rule relies that Dempster’s of Dempster’s independence. semantics the justification independence which seem in are discussed later functions and provide a convincing justification the concept of a multivalued mapping interpretation, but the indiscriminate use of Dempster’s to be unreasonable this section.) Nor for are Assessment Belief functions are often generated by a multivalued mapping mapping A. from points of an underlying simplicity assess a Bayesian probability measure P on !P, using either frequency subjective . . , &} that the sets A( @I ) , . . . , A( en) are distinct. space P = ($1,. function on 0 this induces judgement, I assume a belief and [ 151, which is a to subsets of 0. For to or through m( A(q$)) = It may be possible information p($i). example, this simplest that he observed an event C. Either an unreliable witness Example Z! (An unreliable witness). In (@I ) he did observe C, so A(& ) = C, or claims (& ) he observed nothing, that, after hearing his report, we a, so P( $1) = (Y and P (I&) = 1 -a. This generates judge the witness belief the probability in favour of C (we function has P(C) = cy and Ti( C) = 1. Thus there is some evidence would bet on C at any odds better than 1 - (Y to (Y), but no evidence against C (we are not prepared assignment m(C) = (Y and m( 0) = 1 - (Y, and the corresponding to bet against C at any odds). so A( &) = R. Suppose to have credibility reflects function of this belief on the practical the absence of information imprecision simply the “base rate” frequency of C, P(C 1 &). A Bayesian would need to make a 1 92). on which The about precise assessment of P(C 1 $2) and then compute P(C) = (Y + (1 - a)P(C Depending context, to assess P( C 1 t,&t). In general, we may only be able to assess c:<C 1142) andP(fit) =g+(l-(y)p(C P(C) = 1 by natural extension. Note that Bayesians of a and I’( C 1 CCI;! ) , the multivalued mapping we can reach useful conclusions without making any precise assessments. there may or may not be information requires one precise assessment =LX, and then weobtainP(C) two precise assessments, lower probabilities 11,bz) and (a), but require 28 R Walley/Artijicial Intelligence 83 (1996) l-58 (Although it is somewhat Belief functions should be needed and assessing underlying Bayesian probabilities. precise assessments general model, which does not assume the underlying be able to assess be frequency outcome take the past relative assessment can often be assessed by using the model of a multivalued mapping that in a theory of imprecise probabilities! A more can be specified on In other problems we may there may the then [ 19,104]. Some other space P’, is given the probability about is recorded as a subset Bi of 0 rather in [99, Section 4.3.53.) assignment m more directly. For example frequency of B as our assessment of m(B) the outcomes Bt , . . . , B, of previous than a single element. We might strategies have been suggested that precise probabilities in [ 71,73,75]. trials, where information ironic It is important to recognise, however, that there are Example 3 (Football example). types of information which cannot be modelled by belief functions. One simple many is the football example of Section 4, where three judgements were expressed example in ordinary by natural extension of the three judgements, which is the lower envelope of the three probability mass functions formula, language. Let p be the lower probability onR={wD,L}.BytheMGbiusinversion constructed function (i,i,O), ($,i,i), (i,i,i) m(W=P(Q -P(WUD) -P(WUL) -P(DUL) +p(W) +p(D) +p(L) &$;_;+;+~+o=-~. As m( L?) is negative, m cannot be a probability mass function function. so P is not a belief language It appears judgements that probability cannot be modelled, in do yield a (As in natural functions. Note also that, even when such judgements are less expressive further assessments to sharpen p, and than the appropriate this may be less informative function. There are other examples lower prevision. than lower previsions.) is generated by a multivalued mapping, we may be in Section 4, lower probabilities function p general, by belief belief function, explained Even when a belief lower probability able to make of models may not be a belief that are not belief and assessment correlation functions. to belief between functions, lower previsions. Nor is it clear why unconditional belief functions are taken to be the fundamental measures of are often uncertainty. Direct assessments needed rules that are prevalent in expert systems the outcomes.) There seems to be no good reason to restrict attention two tosses of a fair coin with unknown the uncertainty [ 641. strategies which produce coherent lower and upper probabilities associated with the “if-then” rather than coherent lower probabilities lower probabilities in [48,64,96,99] of conditional for example, the resulting or coherent to measure (Consider, Dempster’s rule of combination Dempster’s rule is extensively used in the theory to combine and update belief func- tions. Let ml and m2 be probability assignments based on separate (“independent”) P Walley/Artijicial Intelligence 83 (1996) 1-58 bodies of evidence. A combined probability assignment m is defined by m(C) =p-’ C ml (A)m2( B) for all non-empty sets C, 29 (9) ArlB=C where P= c ml (A)MB) is a normalizing feasible Ito use Dempster’s tain kinds of tree structures [34,61,79,111,112]. constant, provided p is nonzero. to combine belief It appears rule functions [ 77,78,114]. Other computational to be computationally that are defined on cer- in results are discussed Example 4 (Two unreliabEe witnesses). As a simple example of Dempster’s pose that there are two unreliable witnesses of the type considered witness, who has credibility ness, with credibility q : 1 -at, ml(O) indlependent cally assignment [71] m(Q)=(l-cut)(l-a2). rule, sup- earlier. The first that he observed event Cr. The second wit- a~, reports C2. So ml and m2 are defined by ml (Cl) = al, that Ct and C2 are logi- rule and the combined probability mz(C2) = ff2, m?(a) = 1 - (~2. Suppose events. Then p = 1 in Dempster’s is m(C1 n C2) = cqcq, m(CI) = cut(l - Ly2), m(C2) = (1 - CWI)CQ, cyt, reports by Dempster’s in other problems rule? The rule appears answers tconclusions should beliefs be combined in some problems, but it produces unsatisfactory When reasonable Its applicability roneous indepen- of conditional seems that beliefs, based on the report dence. of one witness, by further information which specified both the report of the other witness and whether his report was correct. to rely, in general, on some rather delicate In. the example, is correct would be unchanged the rule is applicable provided about whether her report is given below). and seemingly to give er- (an example judgements This is a type of conditional independence, from the type of unconditional [ 72,75,76] as a justification nesses. It is quite different by Shafer in [ 951 .:I In the example, each witness sometimes correctly, and the two witnesses may be unconditionally learning whether one witness reported correctly would not change our belief that the other witness for Dempster’s Unconditional independence is a simple judgement conditional independence rule. (A similar distinction on the reports of both wit- that is suggested is made in- that (without knowing what the report was) reports correctly and sometimes in the sense independent reported correctly. rule, because the use of Dempster’s to have no interaction. But it is not sufficient instance when the witnesses are known justify rule are based on (or “conditional of witness credibility of witness i, in order to determine beliefs based on all the available evidence. [ 72, p. 51, equates will report correctly, but Levi [55] has shown that this is unjustified.) in Dempster’s the specific reports of the two witnesses. The on the report (Shafer this posterior probability with the prior probability i (q) must be a posterior probability, the belief functions that witness conditional involved on”) i and often a reasonable one, for to 30 P: Walley/Art@cial Intelligence 83 (1996) 1-58 Dempster’s is harder rule therefore to justify. this most details and were otherwise compatible, is correct would certainly and conditional inconsistent, cases. independence would even though unconditional relies on an assumption of conditional If the two witnesses gave detailed for example, give us more confidence fail. It would that fail also independence might be reasonable then learning the other independence reports which agreed and in that one report is correct if the two reports were in these two report is always and carefully of conditional considered. But conditional that Dempster’s that the implicit in most other, more complex examples rule of combination judgements I am not suggesting such examples, merely be made explicit reasonable it because about the true state w and hence change beliefs about will typically provide which mechanism produced the other body of evidence. That is especially clear in cases of conditioning, where one body of evidence actually restricts w to a subset of the initial possibility in should less independence than in the case of the two witnesses, learning one body of evidence and which mechanism or “code” produced independence inappropriate information space LL seems Dempster’s rule is therefore unreliable unless careful attention independence. For a general mathematical is given to the implicit of formulation and for further discussion, to, but slightly different reaches a similar conclusion see [99, Section 5.131. The conditions those given by Voorbraak of from, about the limited applicability of conditional assumptions these assumptions given in [ 95, p. 1881. Voorbraak Dempster’s rule. [99] are similar = P(C1 f3 C2) = q, and judge Example 5 (Independent witnesses). Even in the simple example of the two witnesses, independence. One way is to make the assessments there are other ways of modelling p( Ct ) = at, (conditional on the testimony one event would not change Coherent for if we learned whether or not the other event occurred. lower previsions can then be computed by natural extension of the judgements = ~1 and p(C2) =p(C2 that events Ct and C2 are independent that upper and lower probabilities of both witnesses), meaning 1 Cl) =J’(C2 1 Cl”> = LYE. rule. For example, and which is more precise let A denote P(CI) Natural extension produces a lower probability model not even 2-monotone), Dempster’s value (i.e. both occur or neither occurs). Then Dempster’s whereas natural extension gives F’,(A) = alcy2/( cq + (~2 - qq) larger than &(A) This is one type of application than Dempster’s more precise rule. (Compare with conditioning.) is strictly provided 0 < (~1 < 1 and 0 < LUZ < 1. (Both rules give F(A) = 1.) that are in which natural extension produces that is not a belief function (it is than the belief function produced by the event that Ct and C:! have the same truth rule gives &,(A) which inferences = LYICX~, = P(Cl I c2> I cg A third approach, suggested by Bayesian sensitivity analysis, probability measures P which satisfy P( Cl ) > CYI and P(Q) Ct and C2 are independent we obtain a lower probability model and again is not a belief function. For this model is to look for all Bayesian > a~, and under which the lower envelope of all such measures, than the two previous models that is more precise [ 10.51. By forming P,(A) =min{crt,a:!,Qta2 + (1 -nt)(l -a2)} P: Walley/Arti&ial Intelligence 83 (1996) 1-58 31 > Z&(A), provided 0 < q < 1 and 0 < a2 < 1. If each witness and &(.4) has credibility > &(A) $, for example, we obtain Pe (A) = 6, &(A) = 3 and Z’o (A) = $. The three models do agree on some probabilities, in particular p(Ct II C2) = qcq (A fourth model, based on possibility in Section 6. This gives &‘(CI II C2) = min{q, than the other solutions.) The differences between and p( Cl n C2) = 1 for each model. will be given reasonable important because clear which model 9;105] for some comparisons. is most appropriate judgements of independence are common for practical applications, a~}, which seems theory, less the four models may be It is not but see [99, Chapter in expert systems. Dempster’s rule of conditioning Suppose that the second probability I= 1, representing m2( B) combination most simply whenever p(B) > 0, with &( A 1 B) = 1 --FD(A~ of belief functions then reduces in terms of upper probabilities knowledge to Dempster’s rule assignment that event B has occurred. Dempster’s in Dempster’s is defined by rule of rule of conditioning, which can be written as PO (A 1 B) = P( A fl B) /F( B), defined ) B). This rule is used in the theory Compare this rule with every belief function E is 2-monotone, extension are given by the simple formulas to update beliefs after receiving new information. the rule of natural extension given the conditional probabilities in Section 4. Because defined by natural &(A I B) = P(AnB) P(A n B) +P(ACnB)’ PE(A / B) = _ P(AnB) P(AnB)+I’(ATB) (10) the denominators provided is a bselief function p [ 4 I] .) Thus conditioning function. then so is &(a 1 B). are nonzero. Several authors that if is true whenever F(B) > 0; see a belief function by natural extension produces another belief have shown [23,41,93] (This The conditional probabilities defined by Dempster’s rule are always at least as precise as those defined by natural extension [ 151, in the sense that &(A 1 B) < &,(A 1 B) < FD(A 1 B) < BdA I B). (11) probabilities [ 1!>,23,48] for interesting Both rules yield (and is precise typically yields conditional (See duces conditional upper and Dempster’s Dempster’s ster’s rule seems the same conditional probabilities when the initial probability measure rule then both agree with Bayes’ rule), but, in other cases, Dempster’s than natural extension. of the two rules.) Natural extension pro- that are coherent with the unconditional defined by the conditional lower probabilities. rule may also be coherent with the unconditional even when rule and natural extension produce different answers. For instance, Demp- inferences when it is used to update possibility upper and lower probabilities In some cases probabilities probabilities, that are more precise comparisons to produce reasonable 32 P: Walley/Art@cial intelligence 83 (1996) l-58 measures in which Dempster’s (see the examples in Section 6). But there are examples, such as the following, rule produces inferences that seem to be seriously wrong. the two rules of conditioning, the same type of inconsistency statistical model. A random variable X takes values con- Example 6 (e-contamination model). To compare in the sample sider the following , N}. To be specific we will take N = 104. (In fact Dempster’s space X = {1,2,3,... for any value of N greater than 1, but rule will produce 0.99, X is generated the degree of inconsistency 0.01, X is generated by by the uniform probability on X. Thus almost all observa- another, completely to be tions follow a uniform distribution (but possi- a “gross error”, bly drastically different) mechanism. This sampling model is called an &-contamination neighbourhood that it is generated by a completely unknown increases with N.) With probability of the uniform distribution on X. With probability unknown, probability but one observation (here E = 0.01) in a hundred in the sense is expected distribution distribution [ 401. Let B, denote the event that X = x, let A denote the event and define y = 1 if A occurs and y = 0 otherwise. There that X is generated by is about both the value of X and whether A occurs, so we take the possibility x=1,2 ,..., N; y=O,l}. about D can be modelled by a belief function whose probability assignment m is defined by m(A . . , N, m(AC) = 0.01, and m(C) = 0 for all other sets C. This model is imprecise because we do not know how to distribute the probability mass 0.01 amongst to a uniform distribution. fl B,) = 0.99/N the alternatives for x = 1,2,. Before observing X, the probability of A is precisely 0.99. Now suppose we make a single observation X = x. How should we update our uncertainty about A? Dempster’s rule of conditioning produces the uniform distribution, uncertainty spacetobefi={(x,y): The uncertainty Fo(A I B,) = F(An B,) m(A n B,) fl B,) + m(AC) = 0.99/N + 0.01 0.99/N = m(A F(&) 99 =- 99 + N < 0.01 when N = 104. Similarly PO ( AC 1 B,) = N/( 99 + N), hence &(A 1 B,) = 1 -Po(AC 1 B,) =PD(A 1 B,). Thus Po( A I B,) = &(A x, the updated probability of A is precise and smaller than 0.01, whatever 1 B,) < 0.01 for every possible value of x. After observing the value of x. Intuitively there is a strong inconsistency Initially we are very confident But if we use Dempster’s whatever value of X we observe, that X will be generated by the uniform distribution. rule to update our beliefs then we will become very confident, that X was not generated by the uniform distribution! the initial and updated probabilities. rule would be used to update probabilities between Indeed an observer who knew that Dempster’s the inconsistency could exploit and, after x is observed, betting on A at a more favourable probabilities sure loss” in the mathematical the coherence axioms to make a sure gain, by initially betting against event A rate. The initial and updated and (C2) of Section 4 and they “incur sense of [ 991. violate (Cl) P. Walley/Artifcial Intelligence 83 (1996) 1-58 33 the wrong answer because the is spread over all possible values of x, as if it rule produces Indeed Dempster’s assessments from the precise probability it treats and P( AC II B,) = 0.01, which are incoherent when asserted for earlier that Dempster’s independence that X = x would not change holds. In this problem rule is applicable when a particular is that, likelihood of A n 8, and the required condition the relative In simple terms, Dempster’s rule produces focused on the x that is actually observed. that a Bayesian would obtain probability mass m(AC) = 0.01, which were entirely the inferences P( A n B, 11 = 0.99/N every possible x. I mentioned type of conditional for each x, learning AC. Of course this condition There appear to be many problems is unreasonable. bination produces incoherent or unacceptable in [99, Section 5.131 and in [36,48,64,65,98]. in which Dempster’s or com- inferences; other examples can be found rule of conditioning Compare Dempster’s always produces coherent erated by natural extension rule of conditioning with the method of natural extension, which gen- inferences. The conditional upper and lower probabilities can be easily computed as follows: F&A 1 B,) =_ P(AnB,) F(AnB,) 0.99/N +P(ACnB,) = 0.99/N+O = ” &(A I B,) = P(A i-7 Bx) 0.99/N P(A n B,) + P(Ac n B,) = 0.99/N + 0.01 =Z<OOl 99+N * ’ that are In this problem, coherent with the initial belief function. two rules of conditioning these are the unique updated upper and lower probabilities The lower probability the same updated is that, for each possible rule are precise, whereas those given by natural extension i, the initial model for A, produce given by but they produce very different upper probabilities. The updated probabilities im- are highly Dempster’s is consistent with the precise. The reason hypothesis Hi that, whenever AC occurs, X takes the value If we knew H* to be true we would obtain precise probability P( A 1 B,) = 99/(99 + N), but if i $ x) we would obtain P( A 1 B,) = 1. The range of we knew lower of A is precisely 0.99 under all the hypotheses Hi, but the updated probabilities are very different under different hypotheses in the updated upper and lower probabilities. to upper updated probabilities must cover both values. The initial probability to be true (where and this produces i for certain. imprecision /4 function. (precisely) some readers may feel that observation about A and that the updated probabilities this explanation, no effect on uncertainty these updated probabilities If you take the updated probabilities Despite absolutely be P( A 1 B,) = 0.99 ability P (,4) = 0.99. However initial belief you must modify natural extension assessments P(A P(AC fl Bx) = 0.01/N probability mass m(AC) = 0.01 can be distributed generated of x should have should for every possible x to agree with the initial prob- the are not coherent with to be precisely 0.99 then Indeed, we can use that are generated by the for all x, and we obtain that the i.e. that X is If to make it precise. the initial probability model to compute probabilities the unconditional I B,) = 0.99 and P(A rl B,) = 0.99/N by a uniform distribution when AC occurs, as well as when A occurs! for all x. This is tantamount to assuming (precisely) uniformly over X, 34 I? Walley/Artificial Intelligence 83 (1996) I-58 there is really no information probability model should be imprecise, updated probabilities. about how X is generated when AC occurs then the initial in the leads to imprecision and this inevitably Expectations It is assumed in the Dempster-Shafer theory that uncertainties are modelled in terms of upper and lower probabilities. As discussed may not be sufficient. abilities are needed and information probabilities. Assuming that beliefs are specified in Section 4, upper and lower probabilities In many problems upper and lower previsions or conditional prob- is lost if these are defined in terms of unconditional in terms of a belief function c with probability assignment m, lower and upper previsions of a gamble X can be computed by natural extension, the formulas through cc P(X) = s -cc cc xdFx(x) = cm(B) inf{X(w): w E B}, BCfJ B(X) = xdF,(x) = cm(B) sup{X(w): w E B}, (12) s --oo EC&f where Fx and & are the upper and lower distribution (8) ). Preferences between actions can be constructed previsions of differences between utility functions, of using belief functions in decision making are described functions of X under 41 (see Eq. upper and lower by computing in Section 4. Other ways as outlined in [ 85,921. Conclusion Belief functions various be represented mathematically coherent combining Belief types of partial are a special ignorance type of coherent and limited or conflicting in terms of a probability mass function m, belief functions appear and computationally lower previsions. Computationally efficient methods have been developed in some ways, simpler, lower probability. They can model they can evidence. Because to be than the general class of for through multivalued mappings or in other ways, and propagating belief functions. can be assessed strategies suggested by the theory are useful belief functions valuable.) However, many other assessment functions and the assessment (Shafer’s emphasis on constructing is especially lower probabilities e.g. judgements belief functions. previsions. The theory gives no justification rather previsions. of probability In fact belief functions that are not belief lower probabilities, than coherent in ordinary functions. Some important in many applications. from simple evaluations of evidence strategies produce coherent types of uncertainty, are much language, cannot be adequately modelled by lower to belief functions lower than rather attention or to lower probabilities less expressive than coherent for restricting P Walley/ArtijEcial Intelligence 83 (1996) I-58 35 The calculus of belief functions relies heavily on Dempster’s in some problems where rule may be useful of conditional that are intuitively Dempster’s judgements inferences to be given to the exact conditions under which Dempster’s to Dempster’s but it is unreliable and formally role it gives independence inconsistent rule of combination. it is supported by explicit in general and it can produce incoherent. More attention needs rule is applicable. rule, the fundamental to be broadly compatible with the theory of coherent that are constructed lower previsions. through a multivalued mapping have a behavioural the Dempster-Shafer and can be regarded as coherent lower probabilities, and updated through the rules of natural extension and they could be rather than by Dempster’s Apart from theory appears Belief functions interpretation combined rule. 6. Possibility measures the imprecision and ambiguity of ordinary The the.ory of fuzzy sets was introduced by Zadeh [ 1161 for the purpose of mod- is often mea- elling sured in this theory by possibility measures, which are described in [ 16,17,46,115,118]. Concerning the use of possibility measures and fuzzy logic in expert systems, see [ 17,120,1:2 1 ] . Specific applications to expert systems include DIABETO [ 71, CADIAG- 2 [ I 1, SP.HINX [ 261, TAIGER [ 241, SPII-2 [ 5 11, PULCINELLA [ 53,691. language. Uncertainty Zadeh in expert systems”. In particular, Bayesian probabilities [ 1211 argues that “classical probability is insufficiently expressive to cope with the multiplicity of kinds of uncertainty which one encounters in AI and, more for particularly, dealing wj th vague such as “young” or “tall”, such as “probably”. These two types or with natural-language of vaguenfess occur that Mary is young”. Many “it is likely rules in expert systems such as MYCIN are fuzzy in these ways. (See of the production [ 22,120] If expert systems are to be widely used, it does seem necessary for many examples.) to provide mathematical models for vague expressions expressions of probability, in the expression (inexactly defined) events or predicates, are inadequate in natural language. together Dejnitions to Zadeh, this provides about Mary’s precise age X, and the information Consider the expression “Mary is young”. According some informatia’n can be modelled by a possibility distribution function TX, defined on the set D of possible ages. The number VQ (w) 1ie:s between zero and one and is read as “the degree to which it is possible that that sup{~x( w) : w E Mary has precise age o, given that she is young”. 0) = 1, t:hat is, the function 7~ [ 1181 did not require Zadeh identifies on 0. Thus a possibility distribution enables to have supremum value one. (Zadeh but it has been assumed by most later authors.) for the fuzzy set “young” function, and this th,e basic theory of fuzzy sets to be carried over to possibility distributions. function is a type of membership the function 7~ with the membership this normalisation It is assumed is normalised function A possibility measure T is defined for all subsets A of L? by v(A) = sup{rx (w) : w E (for all subsets A and B) : 0 < A}, with V( 8) = 0. It follows that +7r has the properties 36 P Walley/Art@cial Intelligence 83 (1996) l-58 rr( A n B) < min{lr( A), T(B)} but there is equality = 1, max{rr(A),7r(AC)} n(A) < 1, ~(0) In general case where A and B are “non-interactive” correspond in probability analogous is analogous to a probability measure. to independence to a probability mass function or density = 1, and ?T(A UB) = max{r(A),T(B)}. events in the important [ 1171. Non-interaction theory. A possibility distribution special to is function, and a possibility measure appears function Interpretation expressions Thus Zadeh to distinguish degrees of possibility translates natural-language of possibility measures. But how should we interpret wishes sumption which underlies our approach languages which is intrinsic tic in nature. relates of attainment, whereas probability [ 1191 frequency, or proportion.” It is widely recognised in natural . . . possibility to approximate that possibility into the mathematical formalism these measures? Zadeh clearly “A basic as- from degrees of probability: reasoning is, in the main, possibilistic is that the imprecision rather than probabilis- to our perception of the degree of feasibility or ease likelihood, is associated with the degree of belief, is distinct from probability e.g. [ 281. Degrees of probability rates or as relative frequencies, but it is less clear that it is meaningful and this distinction is can be interpreted to talk such as “slightly possible” rather [ 1181 refers to expressions that these usually indicate degrees of probability to all theories of probability, central as betting of “degrees of possibility”. Zadeh and “quite possible” but admits than degrees of possibility. is somewhat different Zadeh’s explication of degrees of possibility [ 118,119], and the example he gives to it, takes them to be measures of how easy or feasible it is to perform an action. are used in fuzzy from the way that degrees of possibility is true. Given for example, ~~(20) might measure how plausible it as a measure of “how to be aged 20. The general usage is consistent as upper probabilities, which of degrees the illustrate This logic, where they seem to measure how plausible it is that a proposition the information it is that Mary easy” or “how feasible” with the following are sometimes of possibility usual min-max of degrees of possibility called “degrees of plausibility”. Various other interpretations “Mary is aged 20, but it is difficult [ 16,171, but I do not know of any that justifies have been suggested it is for Mary to understand interpretation is young”, rules of combination. to have a clear interpretation earlier. If we do not understand to assess them in practical problems, It is essential mentioned will be difficult expressed of “degree of possibility” the meaning of the numbers Q(W) conclusions to understand for the reasons then it that are them. in terms of them, and to justify the calculus that is used to manipulate Interpretation as upper probability In fact, as suggested by Giles [ 32,331, possibility measures can be given a behavioural as upper probabilities. That is, we regard a possibility measure 7r as an interpretation upper probability measure, H(A) = T(A) = sup{7rx(w): w E A}, and interpret T(A) lower as a marginal rate for betting against A. The corresponding acceptable betting I? Walley/Artifcial Intelligence 83 (1996) l-58 37 for example, are sometimes are defined by P(A) = 1 - sup{~(w): called necessity measures [ 17,461. They have (for all subsets A, B of 0): F(A U B) = max{P(A) P(A) 6 F(A), min{P(A),P(AC)} w E AC} = 1 - r(AC). The the ,B( B)}, P(A II B) = = 0, and either F’(A) = 0 or probabilities lower probabilities properties min{P(A),P(B)}, F(A) = 1. that A is the event that Mary’s age is at least 30 years. Given Suppose, is young”, we might assess r(A) = 0.4 and V( AC) = 1, so that the information p(A) = 0.4 and P(A) = 0. The behavioural is that we would bet against A at odds of 3 to 2 against, but we would not bet on A at any finite odds. (As noted in Section 4, a more general behavioural in terms of the implications for decision making. Decisions would be made, as in Section 4, by computing upper and lower previsions of differences between utility functions, using Eqs. ( 13) and ( 14) below.) of possibility measures could be given interpretation interpretation “Mary All possibility measures are coherent upper probabilities. One way their natural extensions to lower and upper previsions. to see that If the possibility is distribution IQ, its natural extensions are (for any gamble Z to construct measure has possibility defined on a) p(Z) 1 = J inf{Z(w): 0 TX(O) > u}du =supz sup Z - J sup{~xW: Z(w) < y)dy infZ (13) 1 F(Z) = J 0 sup{Z(o): Q(W) 3 u}du SUD z =infZ + J SUP{~X(W): infZ Z(w) > y)dy (14) inf Z and sup Z denote where the infimum w E 0. The second versions of each formula I] for a derivation of these formulas. the first expression From and supremum over all follow from Eqs. (8). See [ 102, Lemma values of Z(o) to upper and lower probabilities (Pl)-(P3) satisfies axioms restriction:5 A} and P(A) = 1 - sup{~(w): are coherent. 2-monotone (Alternatively, lower probabilities There are great advantages it is easy to verify for ZJ Z), of Section 4 and is therefore coherent. Then verify that the lower prevision p that its are defined by P(A) = sup{rx( w): w E w E AC}, hence these upper and lower probabilities and use the result that all verify that p is 2-monotone are coherent.) in adopting this interpretation especially to guide them. But note as the theory of coherent upper and lower previsions the assessment of possibility distributions of possibility measures, then be used could and to derive rules for combining that possibility measures are a very special type of coherent upper 38 I? Walley/Artijicial Intelligence 83 (1996) I-58 e.g. if A and B are logically probability. Their characteristic property P( AUB) = max{P( A), p( B)} is not necessary events and you assess F(A) = for coherence, p(B) = i, the natural extension is P(A U B) = 1, and any assessment of P(A U B) between $ and 1 would be coherent with the initial assessments, whereas p( A U B) = i is necessary for P to be a possibility measure. independent r function, type of belief [ 711, and the corresponding characterised by the property For finite 0, a possibility measure is just a consonant plausibility function in the lower probability p(A) = 1 - 7r( AC) is a sense of Shafer that the sets B for which special m(B) > 0 form a nested sequence to call [46]. than a degree of possibility. Event A is more or z-(A) a degree of plausibility rather to the amount of evidence pointing against A, e.g. if there is less plausible according no evidence against A then A is fully plausible, T(A) = 1, and there is no reason to bet against A at any odds. We could also interpret F’(A) = 1 - r( AC) as a “degree [54,70], or as a of potential surprise” [ 701 “degree of provability” and Cohen to possibility measures and thus they are special of A [ 121. The uncertainty measures proposed by Shackle [ 121 appear to be mathematically it seems more appropriate that we would experience lower probabilities. types of coherent if A failed equivalent to occur Indeed Imprecision Possibility measures can be used to model some types of imprecise or partial mation. For example, complete possibility distribution Q(W) upper and lower probabilities. be measured Some natural-language in the following However, subsections, in general by p(A) judgements, ignorance = 1 for all w in 0, which corresponds The degree of imprecision infor- about a variable w can be modelled by the to the vucuous an event A can r( AC)}. such as “Mary is young” and the variants discussed - I’( A) = T(A) + T( AC) - 1 = min{rr(A), concerning can be modelled by possibility measures. first-order possibility measures do not seem to be sufficiently flexible to types of uncertainty. The football example and other examples cannot be adequately modelled by of uncertainty judgements and certainly not by first-order possibility measures which correspond considered but they are possibility measures, of uncertainty, judgements function. than first-order measures.) Most examples of multival- (Second-order type of belief to model natural-language model many common involving natural-language belief functions, to a special later, can be used considerably more complicated ued mappings functions, involve coherent upper probabilities order) possibility measures model precise probability measures a special non-degenerate i.e. P(A) is large for many events A. possibility distribution type of belief and belief - l’(A) are a special type of possibility measure. The upper and lower probabilities but not defined by a are always imprecise and usually very imprecise, such as the e-contamination model in Section 5, that are not possibility measures. Nor can (first- assessments. Bayesian probability lower probability, function or coherent Example 7 (ModeDing vague predicates). Zadeh [ 1211 argues that Bayesian probabil- ities are unable like “Mary young”. He shows how these judgements can be modelled by possibility distributions, is young” or “it is likely to model judgements that Mary is t? Walley/Art@cial Intelligence 83 (1996) l-58 39 although he does not give numerical to indicate how these judgements previsions for the same judgements I want lower to which this is consistent with fuzzy reasoning. Other models are proposed of the required distributions. can be modelled using the theory of coherent and the extent in [ 11,181. assessments Consid’er the proposition “Mary is young”. This provides some (but not much) mation about Mary’s age. We could model our uncertainty information that she is young, by a coherent ways of constructing a lower prevision. infor- the lower prevision. There are many possible about Mary’s age, given One way, which seems suitable “rich” distribution to an appropriate functions [ 991. numerical for relating scale, terms such as “young”, “old”, “tall” and lower of upper and is through assessments 6 o) = p(X is young, is a vacuous assessment, Let X denote Mary’s precise age. The upper and lower distribution = P(X < w) and F(w) functions of X for all w > 0. Given that X < w for any specific w, so so F could that she is that she is under 40. On this basis, one might assess for 15 < o < 40, F(w) = 1 for is young” does provide some evidence = 0 for 0 < w < 15, F(w) = (w - 15)/25 it is entirely plausible to take F(w) = 1 for all w. (This are defined by F(w) only that Mary it is natural be ignored altogether.) But “Mary under 30, and strong evidence F(w) w 3 40. (Alternatively, X < 25” and “very probably X < 30” which can be translated Note that the information in which to the context retiring”?-- of context:. We must assume, at least, that Mary is human!) one might make a few qualitative provided by the assertion “Mary is young” she “young it is made-is such as “probably into constraints on E. is highly sensitive to be and it is debatable whether a useful model can be given that is independent to be walking” or “young judgements A coherent lower prevision ments. For any set A of possible ages (positive lower probabilities probability model is then constructed by natural extension of these judge- real numbers), we obtain upper and p(A) = sup{ 1 - E(w) : w E A}, p(A) = inf{& w) : w E AC}. This is highly imprecise, as one would expect. Here the upper probability P is actually a possibility measure, with possibility dis- = P(X > w), so 7rx(w> = 1 if 0 < w 6 15, = (40-w)/25 tribution Function 7~ (o) = 1 -F(w) Q(W) the degree to which it is possible upper probability of the lower distribution distribution upper and lower distribution are non-vacuous, by natural extension will not be a possibility measure. rx; both generate functions the same possibility measure if 15 < w < 40, and TX(W) = 0 if w > 40. In this case rrx(w), that Mary has precise age w, can be identified with the that Mary’s age exceeds w, and the analysis based on natural extension function F agrees with the analysis based on the possibility i? In general, when both the the upper probability produced Conditional possibilities Suppose that unconditional tribution probabilities (Otherwise The conditional :r by P(A) = sup{7r(o): P(. 1 B). Assume is no useful there that r(w) information upper probabilities are defined through a possibility dis- w E A} and we wish to construct conditional upper > 0 for some w in B, so that F(‘(B) > 0. to construct P(. 1 B) .) in 7r from which by natural extension, using Eq. (5). probabilities can be constructed 40 l? Walley/Art$cial Intelligence 83 (1996) 1-58 Because the corresponding lower probabilities are 2-monotone, F(A 1 B)=- F(A n B) P(AnB) +p(ACnB) sup{~( w) : w E A r-7 B} =sup{a(w): w cAnB}+l -sup{~(w): we AUP} = sup{~( w 1 B) : o E A} where the conditional possibility distribution IT(. 1 B) is defined by T(W ( B) = dw) T(W) + 1 - max{7r(w),/3}’ 0, if w E B and n-(w) > 0, if w E BC or T(W) = 0, (15) (16) and p =P(BC). It can be verified This shows distribution. measure sion, provided p(B) produces another possibility measure. then so is the conditional that if the unconditional that sup{~( w 1 B): w E L?} = 1 so that T(. 1 B) is a possibility is a possibility upper probability P upper probability p(. 1 B) defined by natural exten- a possibility measure by natural extension > 0. Thus conditioning characterised by the possibility Example 8 (Examples of conditioning). Consider is young”, z-(w) = (40 - w) /25 additional We can update upper and lower probabilities the possibility distribution T to T(. 1 B). information if 15 < w < 40, T(W) = 0 if w 2 40. Suppose we learn that Mary’s age belongs the model for the judgement “Mary distribution T(W) = 1, if 0 < o < 15, the to a specified set of real numbers, B. concerning Mary’s age simply by updating First let B be the event that Mary is no older than 30 years. Using Eq. (16) we find if 0 < w < 30, T(W 1 B) = 0 if w > 30. Here T is updated / B) = r(w) it at age 30; the plausibility if B is the event of ages below 30 does not change. As a second example, that Mary’s age is not between 20 and 30 years, we find that TT( w 1 B) = n-(w) if 0 < w < 20, n-( w I B) = 0 if 20 < w < 30 or w 3 40, and T( w 1 B) = (40 - w) /(45 of ages below 20 does not change, but the new information makes ages between 30 and 40 more plausible Finally, notice - w) if 30 < o < 40. Here the plausibility than before. (0,151 probabilities will be vacuous, I B) = 0 otherwise. If we learn, T(W then T( w I B) = 1 if 5 < w < 40 and T(W 1 B) = 0 otherwise; and 40 become fully plausible. More generally, (i.e. T(W) = 1) then F(BC) = 1 and hence plausible B are vacuous, otherwise. if BC contains interval I B) = 1 if w E B n (0.40) that Mary then the updated and is at least 5 years old all ages between 5 a state w that is fully on I B) = 0 conditional the probabilities in that rr(w 1 B) = 1 if w E B and T(W) > 0, while T(W that if B does not contain in the sense the entire that a(o for example, In this last case, where P(B) = 0, the conditional extension are essentially vacuous. This is generally probabilities defined by natural the case when natural extension that T(W simply by truncating P. Walley/Arti@ial Intelligence 83 (1996) l-58 41 principle lower probability on an event with to condition the consistency stated near the end of Section 4. In the example is used through let A denote “Mary’s age is less than 30” and let B denote “Mary’s age is at least 5”. Then P(B) to make a that P(A rl B) = 0 precisely, which would produce P(A 1 B) = 0. To further judgement be consistent with this we need E(A 1 B) = 0. The same argument applies when A is any proper subset of the interval = 0, and it would be consistent with the initial possibility measure zero. It can be understood [ 5,40). So natural extension cannot produce any nontrivial inferences when the conditioning = 0. (Unfortunately, event B has P(B) events B. In fact, for every event B, either E(B) = 0 or E( BC) = 0.) The problem that the initial model to avoid this is to specify a more precise model, Of course there are many such is probabilities. One way in particular one in which P(B) > 0. upper probability may no longer be a possibility measure. for possibility measures the corresponding is too imprecise to determine conditional Dempster’s rule of conditioning Another option is to use a different rule of conditioning when p(B) = 0. When applied gives the to a possibility measure ?r for which F(B) > 0, Dempster’s upper probabilities FD(A 1 B) = sup{?s)(w the conditional is defined by conditional rule of conditioning 1 B): w E A}, where distribution possibility I B) fl(. ,&u 1 B) = if o E B, if o E BC, (17) rrE(. 1 B) and FE(. and conditional I 13) < T~(OJ I B) and k = sup{~-( w): w E B} = p(B). a possibility measure. Writing distribution #(w Thus the conditional precise as those defined by natural extension. the three examples of conditioning (0,301, probabilities Consider upper probability for all w, and PD(A The conditional upper probability FD(. I B) for the conditional is I B) possibility defined by natural extension, we have for all sets A. rule are always at least as I B) < F&A I B) determined by Dempster’s the information rD (. I B) = c#(. than 7rE ( w I B) . The biggest difference between about Mary’s age. In the I B) and the two rules In the second example, where B = [ 20,30]‘, T’ (w 1 B) is the two rules occurs in the third first example, where B is the interval produce the same solution. agrees with ,rrE( w 1 B) except when 30 < o < 40, in which case &‘( w I B) = T(W) smaller example, where B = [ 5, cm): wD (w 1 B) agrees with the initial degree of possibility n-(w) by Dempster’s in the initial possibility distribution but natural extension rule preserves I B) = T(W) does not, and Dempster’s (In fact &‘(w for all w in B in all three examples, because k = p(B) = 1 in each case.) if 5 < w < 40, whereas rE (w I B) = 1. In this case conditioning rule is arguably more reasonable. the information rule for conditioning theory. The Dempster’s within possibility by a possibility combined with the initial possibility distribution the conditional information distribution distribution rf which possibility possibility ~(w distributions that event B has occurred (17) can also be derived is represented is simply the indicator function of B. This is r using I B) 0: min{r(w), the minimum n’(w)}, rule, producing I B) so ~(0 42 P. Walley/Arti$cial Intelligence 83 (1996) I-58 if w E B and V(W 1 B) = 0 if w E BC. The proportionality c( z-(w) determined by the fact that r(. 1 B) is a possibility distribution, with Dempster’s proposed rule ( 17). A different rule for conditioning in [ 171. constant is and the solution agrees is possibility distributions function that Mary is young”. Zadeh quali$cation). Now consider [ 1211 treats this as information the qualified judgement “it is Example 9 (Probabilistic likely probability density about Mary’s age. Let B denote used by the speaker. The conditional identified with young” which were defined previously. The judgement 2 i. The natural extensions of these assessments p(B) about an underlying it simply as information to the criteria probabilities P(A 1 B) and Z’( A 1 B) can be is based on the information that B is likely as are the event that Mary is young, according “Mary is translated for Mary’s age, whereas the (unconditional) probabilities I regard P(A) =iP(A 1 B) = iinf{F(w): w E AC} = i - $sup{r(w): OJ E AC}, P(A) = i + iP(A 1 B) = 1 - i inf{F(w): w E A} = i + $ sup{rr(w): w E A}, for any set A of possible ages. the upper probability Again the lower distribution function 7~( w) = 1 - to reduce i + ir.) Although is much simpler defined on the space of all probability than that of Zadeh function is a possibility measure, with possibility iF( w). The effect of the qualification “it is likely I; by a factor of $. (Equivalently, distribution that” is simply replace r by for Mary’s age X, this analysis to be [ 1211, who requires a possibility distribution it produces a possibility distribution More generally, suppose that B(. I B) are upper and lower probabilities density I B) and p(. functions for X. B, and information this information based on translated as J’(B) 2 /?, e.g. by asserting the other natural-language probabilities and p(A) = pP( A 1 B) + 1 - p. This is a simple method of discounting in some way that can be that B is “very probable” or by using one of listed later in this section. Then upper and lower can be computed by e(A) = pl’( A I B) based on the qualified information. is qualified expressions information generated by natural extension To see that such an analysis will not always produce a possibility measure, consider from the two judgements “it is is older than 10 years”. Let A is older than 40 so H is not the upper probabilities that Mary likely and B denote is younger years”. Then ‘ir( A) = P(B) = i but P( A U B) = 1 > max{P( A), p( B)}, a possibility measure. is young” and “it is likely than 10 years” and “Mary the events “Mary that Mary Cheeseman [ 1 l] suggests several Bayesian models “Mary the information age, given tainty given “Mary age, and similarly bly” he would construct a second-order probability analogous is young” by specifying for the uncertainty to Zadeh’s second-order possibility distribution given “Mary a probability for the uncertainty about Mary’s the uncer- for Mary’s function is not young”. To model “proba- density on the unit interval. This is density is probably young”. He would first model for “likely”. Thus Cheeseman’s analysis requires second-order assessments of similar complexity to Zadeh’s. However Cheeseman claims that “For the accuracy appropriate to this type P Walley/Artifcial Intelligence 83 (1996) l-58 43 to extract a single estimate density, and he chooses (probability)” the precise probability as an 0.9 given to bet on A at odds of 9 to 1 to represent “probably”. So Cheeseman, density) information, it is sufficient the information to the second-order of linguistic approximation (the mean of his second-order only on! Both concerning for an imprecise about Mary’s age is a precise probability density to model the vagueness of the information rates and other decisions, the second-order betting term like “probably”. Cheeseman’s “probably A”, would be willing density and the precise value 0.9 have strong and they are therefore overall model function, which is similarly on which it is based. implications inadequate models for the uncertainty inadequate Vague probability judgements (second-order possibility measures) Now consider the translation of vague probability judgements into possibility distributions. Zadeh such as “event A is treats such it [0, 11. distribution as information about the precise probability [ 117,121] (p) of event A, and models function 7rt, defined on the probability that A” by a possibility distribution likely” or “A is very likely” a judgement interval through a possibility function rP(p) For instance, he models “it is likely on i < p 6 1 to a maximum that is zero when 0 < p < i and increases nonlinearly 7rP( I) = 1. He models “it is very likely rt,. Watson, [ 1091 model “pretty Weiss and Donnell function that is zero on the interval 0 < p 6 0.55 and roughly constant on 0.65 < p < 0.9. More that Mary is young” would be translated by generally, assigning function f for Mary’s age. It is strange a judgement a degree of possibility m(f) that the theory of possibility measures, apparently designed to every conceivable probability density likely” by a possibility that A” by squaring such as “it is likely the function distribution to model the judgements of uncertainty, needs to refer to underlying that are precise. The number r,.,(p) measures of A is precisely p (given uncertainty imprecisiamn in ordinary-language that probabilities that A”), the true probability I have already i.e. it measures is a but there remarked more basic difficulty here: it is not even clear what is meant by “the true probability of A”, and why this should be assumed measure. the judgement about a first-order probability. is meant by “degree of possibility”, second-order that it is unclear what the degree of possibility “it is likely to have the properties of a Bayesian probability of A” is the subjective is that the “true probability The most natural assigned interpretation to A by the speaker, who provides only partial that A”. But there is no reason to suppose (or could make) a precise assessment of this probability-the about it probability that the speaker when he asserts “it is likely vagueness of has made in [99] .) at length his assertion Similarly, sense. If we do not understand what is meant by “the true probability of A”, how can we hope to assess the degree of possibility Compare Zadeh’s that p is the true probability? translation of “it is likely there will rarely be a “true probability” is discussed in any objective that A” with the behavioural the opposite. information translation suggests (This issue just of “probably A” that was suggested “probable” speaker is willing as “more or less synonymous”.) to accept an even-money in Section 4. (Zadeh The behavioural [ 1171 regards “likely” and the 2 i. translation is that bet on A, which is modelled by P(A) I! Walley/Art@cial Intelligence 83 (1996) I-58 45 because the first judgement regarded as “non-interactive” questionable for w - d. But this kind of “interaction” is not clear how possibility by the minimum distribution, and a joint distribution effectively between theorists would combine restricts judgements formed by taking minima. is the range of possible values and it if not is very common, the possibility distributions (This rule.) Thus, assuming w + d + 1 = 1 so that (w, d, Z) is a probability ~(w,d,Z)~min{~l(w),~~(W-d),~~(d-Z)} cx max{O, min{ 1 - 2w, w - d, d - I}}. It is necessary and this yields to renormalise the joint possibility distribution the right-hand expression to have maximum value one, 7r( w, d, Z) = 9 max{O, min{ 1 - 2w, w - d, d - I}}. The maximum possibility is achieved by w = 8, d = f, I= $. Compare this with the lower prevision envelope of the set M of all probability the three _iudgements, is positive when boundary of M, and it is zero otherwise. (w, d, 1) lies in the interior of M, constructed distributions in Section 4, which is the lower (w, d, 2) that are consistent with rTT( w, d, 1) from the it increases with distance i.e. satisfy w < 1, w 2 d, d b 1. The joint possibility Marginal possibility distributions can be computed from the marginal possibility distribution r by maximisation. For for 2 is found to be example, after some calculations rrL(I) =max{7r(w,d,Z): 0 < w < 1, 0 < d < 1, w+d = 1-Z) =9max{O,min{$, i- 1}}, which is unimodal with mode m = f . Hence, using Eqs. ( 19), this model generates upper and lower probabilities P(L) =m+ 1 rL(y)dy= s ,?1 $ =0.2 78, p(L) =m - I 0 rTTL(y) dy = ; =O.ll 1. These probabilities are more precise than the values P(L) = 5 and p(L) = 0 generated by the model the earlier model. in Section 4; here P(L) -c(L) = & r~(y) dy = i, compared with 3 for Calculus As seen example, in the preceding bility distributions derived from the basic rules of fuzzy sets proposed by Zadeh interpretation measures are interpreted possi- involve operations of forming maxima and minima. These rules are [ 1161. Without a definite the rules appear quite arbitrary. But if possibility as coherent upper probabilities, the rules for combining of possibility measures as suggested earlier, and manipulating the rules 46 P: Walley/Artificial Intelligence 83 (1996) 1-58 the rules, to whether they preserve coherence, the overall upper probability model need to be evaluated according after applying cial cases, such as (b) below, the rules agree with natural extension preserve coherence. This gives some justification for these rules. But other rules, such as (c), disagreee with natural extension be investigated whether such rules can produce upper probabilities incur sure loss. I am currently elsewhere. studying It needs to in general. that are incoherent or these questions and the results will be reported is coherent. in the sense that, In some spe- and then they do rules are as follows. The most important (a) Given a joint possibility distribution 7rx,r for two variables X and Y, a marginal = sup{7~x,r(x, y): y E L$} space. This rule It does preserve (x, y) E 0) and D is the joint possibility into the definition of a possibility measure. upper probabilities. possibility distribution where 0, = {y: is essentially coherence of the corresponding for X is defined by Q(X) built (b) Given variables, a joint possibility distribution two marginal possibility distributions TX and rr~~y, where X and Y are logi- for X and Y is defined cally independent in terms of the correspond- by ?TX,J( x, y) = min{rx(x), ing upper probabilities, for product sets A x B, and this rule agrees with natural extension of the marginal upper probabilities for sets that are not products. that Px,r( A x B) = min{Fx( A), &( B)} to a joint upper probability. However the two rules can disagree 7ry( y)}. This implies, (c) Given distributions two possibility is defined by 7~( w) c( min{rt ~1 and ~2, concerning bodies of evidence, the same unknown a combined possibility w but based on “non-interactive” (w), 772( to)}, where the normalising distribution factor is chosen so that n has supremum value 1. This rule was used to combine in the football example. Rule (b) can be regarded as a special case judgements of (c) with w = (x, y). Another special case is the rule of conditioning discussed earlier, where ~2 is the indicator event, which agrees with Dempster’s function of the conditioning rule of conditioning (c) appears ( 17). to have a similar The more general rule to combine to Dempster’s distributions systems natural extension and it need not produce coherent Dempster’s rule of combination information in general role in combining rule for combining functions. from different sources. However possibility in expert the rule disagrees with (although one special case of agreement was noted in (b)), inferences. The next example shows that rule (c) and It is used belief can produce quite different answers. first witness has credibility Example 11 (Two unreliable witnesses). Consider unreliable witnesses. The occurred. This can be modelled by a marginal possibility ~1 (Cl) = 1 and ~1 (C-f) = 1 - “1. This generates assumed by the second witness 1 -cQ. in Section 5, PI (Cl ) = 1 and et (Ct ) = cyt . Similarly the example at and reports distribution in Section 5 of two that event Ct 7~1 that assigns the upper and lower probabilities the information provided is modelled by a possibility distribution ~2 (C2) = 1 and 7r2( Cg) = If we combine the two marginal possibility distributions by the minimum rule, we obtain degrees of possibility 1, 1 - LYZ, 1 - LYI and 1 - max{Lyt , a~} for the elementary P. Walley/Artijicial Inrelligence 83 (1996) l-58 47 events CI flC2, CI nC;, CfflC2 and CynCi. This generates upper and lower probabilities p( Cl n C;!) = 1 and ~(CI is quite different in Section 5, based on different from the value alay2 which is given by all three models ways of formalising is also the judgement the values of F(C,” fl Ci), which are 1 - max{crl , a~} for this a discrepancy model and ( 1 - CYI ) ( 1 - a~> for the three earlier models. that the two reports are independent. There fl C2) = min{cul, CQ}. The lower probability between the combined In this example the three earlier models. When crl = cy:! = $, for example, p( Cl n Cz) = i whereas 4. The latter value seems unreasonable; than the earlier models give the rule for combining possibility measures gives p( Cl n CT) = one would expect p( Cl n C2) to be somewhat less satisfactory distribution possibility seems less than the marginal there is evidence lower probabilities a and E( CZ), which are each i, unless that the two reports are correlated in a particular way. In fact, for any joint possibility measure, satisfy p(Cl n C;?) = min{P(CI),P(C2)} measures. But this property seems inappropriate when the two sources of information judged judgements to be independent. So it does not seem possible using possibility measures. the corresponding lower probability must since this is a general property of necessity are to adequately model independence Computation The computation of inferences and decisions from possibility problem. in Section 4, which distributions requires, (Compare with the com- linear pro- involves only For example, decisions are made from second-order possibility distributions for all possible expected i.e. degrees of possibility n-(P) over all probability distributions rr( P) will generally be a nonlinear suggested “fuzzy expectations”, the solution of a nonlinear programming in general, putation of natural extension gramming.) by computing values x of a random variable X, by maximising P which satisfy P(X) = x. Because probability masses, problem the computation involves, linear programs. So computations will often be difficult, despite of the calculus. The computations butions lower-diml:nsional for each possible value of x! (See [ 109,117,121] this entails a nonlinear programming of a marginal possibility than for second-order are generally distributions distribution because spaces. problem-in function of the fact, a separate for more details.) Similarly in general, many non- the apparent simplicity distri- are generally over easier for first-order possibility the optimisations Assessment language, How di:fficult is it to make is to allow users of the system natural the task OF assessing uncertainty are passed on to the experts on fuzzy judgements distributions. into possibility that A” into a function in whatever the assessments required (or domain experts) for a fuzzy analysis? The aim in to express forms are most convenient. This is valuable, as it makes simple for the system user. The difficulties their uncertainty relatively logic, who must For example, rr defined on the probability translate they must interval the natural-language translate “it is likely [0, l] . More complex 48 I? Walley/Art@cial Intelligence 83 (1996) 1-58 of uncertainty judgements on the space of all probability specify these functions, them. Again second-order space. it is generally distribution concerning distributions 0 must be translated on 0. A great deal of input to be a great deal of arbitrariness into a function 71 defined is needed to in selecting and there seems easier because to assess a first-order possibility the former is usually defined on a lower-dimensional distribution than a in the literature on possibility are sometimes given to illustrate (But see [ 17, p. 191, for some suggestions.) There seems to be little guidance functions. the required and no justification two quite different possibility to select assessments of possibility distributions but these appear quite arbitrary [ 1171 specifies distributions in successive examples: his Example 1.1 has 40.8) “likely” translation, has 7r(O.8) = 0.5. Another different again. No reasons are given hard to see how they could be supported until clarified. shown graphically theory about how Specific the methodology, is offered. For example, Zadeh the judgement in his Fig. 1, seems to model = 0.9 while Example 1.2 to be it is is and to support any of these assessments, the meaning of the numbers m(p) In practice one might use standard translations likely” or “more “very would be translated distribution may still be somewhat arbitrary but no further into the same possibility than”. That is, all instances likely for common terms such as “likely”, likely” distribution. The choice of this standard of the term “very input would be needed. The danger of using standard translations sions like “very likely” one would be impracticable However one could require meanings follows, using the behavioural in different ways and usage varies with context like to use a different translation in most cases, as it would require the standard translation of “very is that different people seem to use expres- Ideally, for each person and context. That would from the person. input the to encompass likely” the idea as too much [ 3,106]. intended by most speakers in most contexts. We can illustrate interpretation of upper and lower probabilities. Standard translations into lower probabilities Consider the expression “probably A”. Most people who use this expression would be they would accept the behavioural a lower probability E(A) translation for person to bet on A. Provided 2 0.5 is acceptable odds at which he is willing i, the behavioural translation l’(A) in principle, determine the least favourable 2 0.5 for all persons to bet on A at even stakes. Hence willing p(A) > 0.5. We could, i by finding &(A) to all, and we may say that it encompasses persons. “probably A” that is acceptable problem we would translation of his judgement, he is willing judgement P(A) > 0.6. If he was unwilling carried out, then the standard It could then be used as a standard in the great majority of problems. try to (a) check with the person that he accepts the meanings of “probably A” for all the of or “default”) (“cautious” translation In any particular the behavioural to bet on A at odds of 3 to 2 on then he will accept and (b) encourage him to make this more precise, e.g. if the more precise to do this, or if the checks could not be The standard translations translation would be used. should be based on empirical terms such as “probably”. It seems, for example, of that most people do not apply the term studies of the meanings P. Walley/Art@ial Intelligence 83 (1996) 1-58 49 6 0.9, as well as l’(A) 2 0.5, in the standard to events with very high probability, so that one might include the constraint judgements “probable” P(A) the light of empirical common synonymous with “likely”. positive expressions which is equivalent evidence other translations studies such as [ 3,45,106], language. in natural In all these expressions I identify negative expressions such as “AC is probable”. The latter is translated to P(A) < 0.5. This translation I suggest the following translation of “A is probable”. In translations of to be I take “probable” such as “A is improbable” with into &( AC) > 0.5, is somewhat cautious, as there is translation P(A) < 0.4. Many of the that most people would accept a stronger could be strengthened considerably in suitable contexts. 2 0.9. 2 0.75. 2 0.65. 2 0.98. -+ I’(A) > 0.85. l’(A) --) l’(A) [likely] + [unlikely] 2 0.6. l’(A) > 0.5. l A is extremely probable + l A has very high probability l A is highly probable l A is very probable + P(A) l A has a very good chance + P(A) l A is quite probable + P(A) l A is probable l A is improbable l A is somewhat unlikely l A is very unlikely l A has little chance l A is highly l A has very low probability + p(A) < 0.1. l A is extremely unlikely l A has a good chance l The probability l A is more probable [quite --f P(A) < 0.25. --+ P(A) < 0.2. improbable + P(A) < 0.15. --+ F(A) < 0.5. improbable] -+ P(A) < 0.02. than B + F’(A - B) 2 0. + P(A) < 0.4. -+ Z’(A) 2 0.4, P(A) < 0.85. of A is about (Y --+ Z’(A) 2 a - 0.1, P(A) 6 a + 0.1. There is some degree of arbitrariness in choosing a single number but this is much (0.85) to translate less than the arbitrariness r, i.e. a degree of possibility r(p) for a possibility such as “highly probable”, an expression in choosjng every value of p between 0 and 1. Similar to lingui:stic expressions, more comprehensible distribution to a user. function could be used to make a system’s conclusions translations, from imprecise probabilities and reasoning Possibility theory and fuzzy judgements of uncertainty derstanding natural-language Provided variety of uncertainty Bayesian probabilities judgements, sions may be adequate, especially type of coherent upper probability. second-order measures judgements, are inadequate as in “Mary contribution possibility measures logic have made a substantial by drawing attention and suggesting to our un- to the important problem of modelling as suitable models. are allowed, possibility measures can mode1 a wide language. judgements to mode1 vague predicates and vague probability is probably young”, but it appears that upper and lower previ- as possibility measures can be regarded as a special in natural imprecise including SO f? Walley/Art$cial Intelligence 83 (1996) 1-58 It is important to distinguish between first- and second-order possibility measures. generated by the uncertainty like “young” and “tall”, can be interpreted as coherent upper probabili- simpler than the other types of coherent upper probabilities First-order possibility measures, which are used to model vague predicates ties. They are mathematically as they can be defined LJ rather than e.g. possibility measures can sometimes be assessed functions. First-order possibility measures are likely to be useful models systems where information in terms of possibility the power set of a. This may simplify in terms of vague predicates. computations distributions, is elicited and assessment, through upper or lower distribution in many expert functions whose domain is The main defect of first-order possibility measures is that they cannot model many of the common judgements a very special belief function), lower previsions Second-order of uncertainty or precise probability types of uncertainty. In particular they cannot model natural-language assessments. Possibility measures are type of to a special in many problems; upper and type of upper probability and upper probability are needed possibility measures, defined on the set of all probability distributions, (in fact they correspond is itself inadequate in general. judgements of uncertainty. But they are much more complicated than first-order measures. They can model both precise and than first- to are much more expressive imprecise order measures and they have some serious defects. Second-order models are difficult interpret and assess and they seem overly complicated Theoretical second-order tations, e.g. of marginal require nonlinear programming. judgements. the practical problem of assessing distributions. Compu- or fuzzy expected values, generally each defined on a space of probability to model qualitative papers on fuzzy distributions possibility to ignore functions, logic tend for combining and minimising), The rules of maximising tification. If possibility measures the rules can be compared with gate whether general. possibility measures (they but they do not appear are interpreted the rules of natural extension are simple to have any compelling as coherent upper probabilities involve operations jus- then investi- to do so in some cases but not in and we can they preserve coherence. They appear 7. Comparison and evaluation Most practical reasoning it is frequently fields, use? Four measures have been considered to which they satisfy the criteria proposed necessary involves uncertainty. to measure the uncertainty. What measure In expert systems, as in many other should we in this paper. Here is a summary of the extent in Section 2. Interpretation, calculus and consistency These criteria are satisfied only by the theories of Bayesian probability lower previsions, which start with a simple behavioural tify principles of coherence and to derive rules for combining There is a general method, called natural extension, for computing new previsions interpretation and updating probabilities. from and coherent and use this to jus- R Walky/Art~cial Intelligence 83 (1996) 1-58 51 an arbitrary decisions. There are general methods and the rules of natural extension judgements. set of judgements. Natural extension can be used to make for checking consistency of the initial judgements, inferences and ensure that conclusions will be consistent with the theory do not do so well on these cri- theory and the Dempster-Shafer theories propose mathematical Possibility teria. These their uncertainty measures and simple rules for combining measures, but they fail to give any compelling justification for their properties and rules. Belief functions can be interpreted multivalued mappings but this supports Dempster’s strong assumptions for checking conclusions in terms of only when some lack methods and their rules can produce rule of combination are added. Both theories the consistency that are intuitively inconsistent with the initial model. of models and conclusions, to characterise of conditional independence properties Imprecision Bayesian probabilities cannot adequately model of uncertainty, or vague predicates judgements can do so to some extent, but belief functions not sufficiently general to model common ignorance, in natural and first-order possibility measures imprecise or qualitative language. The other measures are types of imprecise judgements. Assessment Insufficient guidance is given in these theories (especially possibility the theories of belief functions theory) about and although of uncertainty, or non-interaction, how to make assessments lower previsions do take this problem seriously. All the theories seem to need judgements of independence in multivariate assessments. Lower previsions variety of uncertainty assessments although arbitrary. Assessment and a complete probability model; the number of and second-order possibility measures can model a wide language, judgements and including qualitative possibility for Bayesians because of second-order is onerous the other theories are more flexible. they require precise assessments seem complicated distributions judgements, in ordinary to reduce problems, Computation For all the measures, computational the number of assessments. For lower previsions, feasibility will depend on the type and complexity the computation by natural extension computationally is needed and decisions to develop based on conditional of the model and of inferences work particularly and first-order possibility measures, as special simpler be computationally networks, models. computations involve nonlinear programming. and independence. Bayesian probabilities, involves efficient methods linear programming. More tractable models, belief functions types of lower or upper previsions, may belief for Bayesian in singly-connected in some cases. (They are tractable !$econd-order possibility measures are less tractable than the other measures- for example.) Computational methods are most highly developed 52 P. Walley/Artifcial Intelligence 83 (1996) l-58 8. Conclusion should be used lower probabilities, in different in expert systems? belief types of problems, functions I believe that and first-order for instance when probabilities, So what measures of uncertainty upper and Bayesian possibility measures can all be useful the information multivalued mappings or natural-language All these measures can be useful is in the form of extensive statistical data, bounds on probabilities, judgements respectively. in special types of problems, but none of them is judgements in many problems, adequate as a general model of uncertainty. For example, none of them can adequately in the football example. Bayesian probabilities model the three qualitative are not sufficiently genera1 because, is scarce and judge- ments are imprecise. Belief functions and possibility measures are not sufficiently genera1 that are not even 2-monotone. Up- because many examples they do not uniquely per and lower probabilities lower determine upper and previsions produce greater precision that upper the other measures as special cases, are sufficiently and lower previsions, which include types of uncertainty. the most important general are not sufficiently lower probabilities lower previsions general because and conditional and decisions. in inferences probabilities; upper and information I suggest to model involve This raises the question: to what extent is the theory of coherent It is compatible with the Bayesian interpretation lower previsions theory as the two theory types of natural extension. So the theory of lower previsions can be regarded the two theories agree in the special case analysis or to a large extent, compatible with the theory of lower compatible with the other theories? theories have a similar behavioural are special as a generalisation where all probability models are precise. The theory of Bayesian “probability previsions. and the rules of the Bayesian of the Bayesian sensitivity intervals” is also, theory; Possibility theory appear theory and Dempster-Shafer the theory of lower previsions. However can incorporate some of the most useful of the main contributions powerful methods multivalued mappings for assessing for modelling particular and natural-language I believe features of these theories. to be less compatible with that the theory of lower previsions In particular, one to suggest some flexible and of the two theories has been types of partial through information, judgements. These can be used as methods notably lower previsions. The theories differ in their interpretation interpretation and possibility measures of uncertainty measures. The interpretation is unsettled and controversial, that have been proposed of belief functions to me that at least some of the interpretations sures are consistent with the behavioural Two advantages of the behavioural to decisions principles which can be used to check consistency features are lacking inexact judgements pretation and lower envelopes of Bayesian probability measures as sources of lower previsions, yet specific enough the rules of natural extension. but it seems for these mea- of lower and upper previsions. are that it relates uncertainty measures to coherence (Both inter- of models with conclusions. theory.) The behavioural is sufficiently genera1 to encompass multivalued mappings, they can be used, and thereby explains how in Dempster-Shafer and possibility the principles of coherence interpretation to support it leads and and I? Walley/Art@cial Intelligence 83 (1996) 1-58 53 they do appear rules for combining to be incompatible. Dempster’s The theories have quite different rule for combining possibility distributions that are incoherent, and and updating uncertainties, and rule of combination in this respect can, in some problems, produce the minimum upper and lower probability models and in these cases the rules are not compatible with the theory of lower previsions. These rules are controversial. They can lead to intuitive and they seem If these rules were given a more to be applicable only restricted then the three role in the Dempster-Shafer theories would be considerably more compatible. inconsistencies in a limited theory and in possibility as well as mathematical range of problems. incoherence theory to Dempster’s Natural extension is an alternative other rules that preserve coherence but produce stronger conclusions the calculus of belief functions and principles of coherence can worth investigating than natural extension. This may be a way of developing and possibility measures. The behavioural impose some much needed discipline on the theories of belief functions and possibility measures, without which these theories can produce rule and the minimum interpretation rule, and it is inconsistencies. is itself undeveloped the practical problems of modelling, in some important the theory of lower previsions into is needed investigation and computation. Of course repects. Further sessment independence previsions efficiently. istically complex expert systems. these problems. consider judgements, Particular problems are to determine and how to compute natural extensions to compare It is also important the four approaches how best and propagate I hope that this paper will persuade some people as- to model lower in some real- to Acknowledgements I am grateful to Dr. Hitoshi Furuta for inviting me to lecture on this subject in Osaka on an earlier in April 1990 and for suggesting I must version of the paper thank Terrence Fine, Frank Hampel and Philippe Smets for stimulating discussions, and Smets, Nit Wilson and George Klir for sending me copies of relevant papers. Nit Wilson contributed comments on an earlier version detailed and insightful and the final version has benefited greatly from his suggestions. this paper. Many people commented [ 1001 which was circulated in April 1991. In particular some exceptionally References 1 1 1 K.-P. Adlasnig and G. Kolarz, CADIAG-2: computer-assisted medical diagnosis using fuzzy subsets, in: M M. Gupta and E. Sanchez, eds., Approximate Reasoning in Decision Analysis (North-Holland, Amsterdam, 1982) 219-247. 12 1 S.K. Andersen, K.G. Olesen, F.V. Jensen and E Jensen, HUGIN-a shell for building Bayesian belief universes for expert systems, in: Proceedings IJCAI-89, Detroit, MI (Morgan Kaufman% San Mateo, CA, 1989) 1080-1085. 13 1 R. Beyth-Marom, How probable is probable? Numerical translations of verbal probability expressions, J. Forecasting 1 (1982) 257-269. 54 P Walley/Artijicial Intelligence 83 (1996) I-58 14 1 G. Biswas and T.S. Anand, Using expert system shell, in: L.N. Kanal, T.S. Levitt and J.F. Lemmer, eds., Uncertainty in Artificial Intelligence 3 (North- Holland, Amsterdam, in a mixed-initiative the Dempster-Shafer 1989) 223-239. scheme 15 I G. Biswas, M. Oliff and R. Abramczyk, OASES (Operations Analysis Expert System): an application in fiberglass manufacturing, Int. J. Expert Sysf. Res. Appl. 1 (1988) 193-216. 16 I B.C. Buchanan and E.H. Shortliffe, eds., Rule-Eased Expert Systems (Addison-Wesley, Reading, MA, 1984). 17 I J.-C. Buisson, H. Farreny and H. Prade, The development of a medical expert system and the treatment of imprecision in the framework of possibility theory, InjI Sci. 37 (1985) 21 l-226. 18 I R. Buxton, Modelling uncertainty 19 I L.M. De Campos, M.T. Lamata and S. Moral, The concept of conditional in expert systems, Int. J. Man-Mach. Stud. 31 ( 1989) 415-476. fuzzy measure, fnr. J. Intell. Syst. 5 ( 1990) 237-246. I IO I J.E. Cano, S. Moral and J.F. Verdegay, Propagation of convex sets of probabilities in directed acyclic networks, I 1 I I F Cheeseman, Probabilistic in: Proceedings Fourth IPMU Conference (1992) 289-292. versus fuzzy reasoning, in: L.N. Kanal and J.F. Lemmer, eds., Uncertainty in Artificial bzfelligence (North-Holland, Amsterdam, 1986) 85-102. I I2 I L.J. Cohen, The Probable and fhe Provable (Clarendon Press, Oxford, 1977). I I3 I P.R. Cohen, Heuristic Reasoning about Uncertainty: An Art@cial Intelligence Approach (Pitman, London, 1985). 1 I4 I R.G. Cowell, BAIES-a in: J.M. Bemardo, Press, Oxford, 1992) 595-600. probabilistic learning, J.O. Berger, AI? Dawid and A.F.M. Smith, eds., Bayesian Statistics 4 (Clarendon expert system shell with qualitative and quantitative [ IS I A.P. Dempster, Upper and lower probabilities induced by a multivalued mapping, Ann. Math. Stat. 38 (1967) 325-339. [ I6 I D. Dubois and H. Prade, An introduction to possibilistic and fuzzy logic& in: P Smets, A. Mamdani, D. Dubois and H. Prade, eds., Non-Standard Logics for Aufomated Reasoning (Academic Press, London, 1988) 287-326. [ I7 I D. Dubois and H. Prade, Possibility Theory (Plenum Press, New York, 1988). 1 I8 I D. Dubois and H. Prade, Modelling uncertain and vague knowledge theories, in: R.D. Shachter, T.S. Levitt, L.N. Kanal and J.F. Lemmer, eds., Uncertainty in Arti’cial Intelligence 4 (North-Holland, Amsterdam, in possibility and evidence 1990) 303-318. I I9 I D. Dubois and H. Prade, Evidence, knowledge, and belief functions, Int. J. Approx. Reasoning 6 ( 1992) 295-J 19. [ 20 I R.O. Duda, PE. Hart and N.J. Nilsson, Subjective Bayesian methods for rule-based systems, inference in: Proceedings 1976 National Computer Conference, AFIPS 45 (1976) 1075-1082; also in: B.W. Webber and N.J. Nilsson, eds., Readings in Artificial Infelligence (Morgan Kaufmann, Los Altos, CA, 1981) 192-199. 12 I I R.O. Duda and R. Reboh, AI and decision making: the PROSPECTOR experience, in: W. Reitman, ed., Artificial fntelligence Applicationsfor Business (Ablex, Norwood, NJ, 1984) I 11-147. in expert systems, Inf Sci. 37 ( 1985) 3-24. I22 I A. Dutta, Reasoning with imprecise knowledge I23 1 R. Fagin and J.Y. Halpern, A new approach to updating beliefs, in: PP. Bonissone, M. Henrion, L.N. Kanal and J.F. Lcmmer, eds., Uncertainty in Arttficial Intelligence 6 (North-Holland, 1991) 347-374. Amsterdam, I 24 I H. Farreny, H. Pnde and E. Wyss, Approximate reasoning Interval influence diagrams, in: H.J. Kugler, ed., Information Processing theory: a case study, 1986) 407-413. K.W. Fertig and J.S. Breese, and J.F. Lemmer, eds., Uncertainty in Artificial Intelligence 5 (North-Holland, 149-161. M. Fieschi, M. Joubert, D. Fieschi, G. Botti and M. Roux, A program therapeutic decision, Med. I$ 8 ( 1983) 127-135. T.L. Fine, Theories of Probability (Academic Press, New York, 1973). B. de Finetti, Theory of Probability Vol. I (Wiley, London, 1974). B. de Finetti, Theory of Probability Vol. 2 (Wiley, London, 1975). 125 1% I 27 128 I 29 in a rule-based expert system using possibility Amsterdam, ‘86 (North-Holland, in: M. Henrion, R.D. Shachter, L.N. Kanal 1990) Amsterdam, for expert diagnosis and I? Walley/Art$cial Intelligence 83 (1996) I-58 55 I 30 ] L.C. van der Gaag, Computing probability intervals under independency constraints, in: l?P Bonissone, M. Hencion, L.N. Kanal and J.F. L.emmer, eds., Uncertainty in Art@cial Intelligence 6 (North-Holland, Amsterdam, 199 1) 457-466. I 3 I I W.A. Gale, ed., Artificial Intelligence and Statistics (Addison-Wesley, Reading, MA, 1986). 1321 R. Gales, Foundations for a theory of possibility, in: M.M. Gupta and E. Sanchez, eds., Fuzzy and Decision Processes (North-Holland, Amsterdam, 1982) 183-195. I&m&on R. Giles, Semantics for fuzzy reasoning, Int. .I. Man-Mach. Stud. 17 (1982) 401-415. J. Gordon and E.H. Shortliffe, A method for managing evidential reasoning in a hierarchical hypothesis space. Artif: Intell. 26 (1985) 323-357. 133 [34 I35 I B.N. Grosof, An inequality paradigm for probabilistic knowledge, in: L.N. Kanal and J.F. Lemmer, 1% 137 138 I39 eds., Uncertainty in Artificial Intelligence (North-Holland, Amsterdam, 1986) 259-275. J.Y. Halpem and R. Fagin, Two views of belief: belief as generalized probability and belief as evidence, Artif: Intell. 54 (1992) 275-317. D. Heckerman, E. Horvitz and B. Nathwani, Toward normative expert systems 1: the PATHFINDER project, Methods Inky Med. 31 (1992) 90-105. M. Henrion, J.S. Breese and E.J. Horvitz, Decision analysis and expert systems, AI Muguzine 12 (1991) 64-91. Y.-T. Hsia and PP. Shenoy, An evidential language for expert systems, in: 2. Ras, ed., Methodologies for Intelligenf Systems 4 (North-Holland, New York, 1989) 9-16. I 40 1 l?J. Huber, Robust Stafisfics (Wiley, New York, 198 1) 141 ) J.-Y. Jaffmy, Bayesian updating and belief functions, IEEE Trans. Syst. Man Cybern. 22 ( 1992) 1144- 1152. I42 I E.T. Jaynes, Pupers on Probability, Sfutistics and Statistical Physics (Reidel, Dordrecht, 1983). I43 ) F.V. Jensen, SK. Andersen, U. Kjaerulff and S. Andreassen, MUNIN-on the case for probabilities in medical expert systems, Lecture Notes in Medical Informutics 33 (Springer, Berlin, 1987). 1441 A.C. Kak, K.M. Andress, C. Lopez-Abadia, MS. Carol1 and J.R. Lewis, Hierarchical evidence accumulation in the PSEIKI system, in: M. Henrion, R.D. Shachter, L.N. Kanal and J.F. Lemmer, eds., Uncertainty in Artijcial Intelligence 5 (North-Holland, Amsterdam, 1990). 145 I S. Kellt, Words of estimated probability, Stud. Intell. 8 ( 1964) 49-65. I46 ] G.J. Klir and T.A. Folger, Fuzzy Sets, Uncertainty, und Information (Prentice-Hall, Englewood Cliffs, NJ, 1!)88). 147 I F? Krause and D. Clark, Representing Uncertain Knowledge (Kluwer, Dordrecht, 1993). I48 I H.E. Kybuxg Jr, Bayesian and non-Bayesian evidential updating, Art& Intell. 31 (1987) 271-293. 149 I K.B. Laskey, M.S. Cohen and A.W. Martin, Representing and eliciting knowledge about uncertain evidence and its implications, IEEE Trans. Sysf. Man Cybern. 19 ( 1989) 536-557. I 50 I S.L. Lauritzen and D.J. Spiegelhalter, Local computations with probabilities on graphical structures and their application to expert systems (with discussion), J. Roy. Stat. Sot. Ser. B 50 (1988) 157-224. 15 I I J. Lebailly, R. Martin-Clouaire and H. Prade, Use of fuzzy logic in rule-based systems in petroleum geology, in: E. Sanchez and L.A. Zadeh, eds., Approximate Reasoning in Intelligent Systems, Decision und Control (Pergamon Press, Oxford, 1987) 125-144. I 52 I J.F. Hemmer, Generalised Bayesian updating of incompletely specified distributions, Large Scale Syst. 5 (1983) 51-68. I53 I K.S. Leung, W.S.F. Wong and W. Lam, Applications of a novel fuzzy expert system shell, Expert Syst. 6 (1939) 2-10. I54 I 1. Levi, Potential surprise: its role in inference and decision making, in: L.J. Cohen and M. Hesse, eds., Applications of Inductive Logic (Oxford University Press, Oxford, 1980) l-27. I55 I 1. Levi, Consonance, dissonance and evidentiary mechanisms, in: P Gbdenfors, B. Hansson and N.E. Sahlin, eds., Evidentiury Value, Library of Theoria 15 (Gleerups, Lund, 1983) 27-43. I 56 I D.V. Lindley, Making Decisions (Wiley, London, 197 1). I57 I R.P. Loui, Interval-based decisions for reasoning systems, in: L.N. Kanal and J.F. Lemmer, eds., L’ncertuinty in Artijicial Intelligence (North-Holland, Amsterdam, 1986) 459-472. 158 I J.D. Lowrance, Automated argument construction, J. Stat. Planning Inference 20 (1988) 369-387. I59 I R.C. Moore, Semantical considerations on nonmonotonic logic, Art$ Intell. 25 ( 1985) 75-94. I60 I N.J. Nilsson, Probabilistic logic, Artif Intell. 28 (1986) 71-87. 56 P. Walley/Ar~ifcial Inrelligence 83 (1996) l-58 I61 I P. Orponen, Dempster’s I62 I G. Paass, Probabilistic rule is #P-complete, A@ logic, Intell. 44 ( 1990) 245-253. Logic.7 fiw Aufumated Reasoning I63 I J. Pearl, Probabilistic Reasoning I64 I J. Pearl, Reasoning with belief functions: in: P Smets, A. Mamdani, D. Dubois and H. Prade, eds., Non-Standard (Academic Press, London, 1988) 213-25 1. in Intelligent Systems (Morgan Kaufmann, San Mateo, CA, 1988). an analysis of compatibility, Int. J. Approx. Reasoning 4 (1990) 363-389. I65 I J. Pearl, Rejoinder to comments on “Reasoning with belief functions: an analysis of compatibility”, Int. J. Approx. Reasoning 6 (1992) 425-443. Inferno: a cautious approach 1661 J.R. Quinlan, I67 I R. Reiter, A logic for default reasoning, Artif 168 1 R. Reiter, Nonmonotonic I69 I A. Saffiotti and E. Umkehrer, PULCINELLA: in: B.D. D’Ambrosio, on Uncertainfy networks, Cwtference 323-331. to uncertain inference, Cornput. J. 26 ( 1983) 255-269. Intell. 13 ( 1980) 81-132. reasoning, Ann. Rev. Comput. Sci. 2 (1987) 147-186. a general in valuation tool for propagating P. Smets and PP. Bonissone, eds., Proceedings Seventh Inrernarional San Mateo, CA, 1991) (Morgan Kaufmann, uncertainty in AI, Los Angeles, CA I70 I G.L.S. Shackle, Decision, Order; and 7ime in Human Affairs (Cambridge University Press, Cambridge, 1969). I 7 I I G. Shafer, A Mathematical Theory of Evidence I72 I G. Shafer, Constructive I73 I G. Shafer, Belief functions and parametric models probability, Synrhese 48 ( 1981) L-60. (Princeton Universtiy Press, Princeton, NJ, 1976). (with discussion), J. Roy. Star. Sot. Ser. E 44 ( 1982) 322-352. I74 I G. Shafer, Probability I75 I G. Shafer, Perspectives ( 1990) 323-362. I76 I G. Shafer, Rejoinders judgement on the theory and practice of belief functions, intelligence and expert systems, Star. Sci. 2 ( 1987) 3-16. Int. J. Approx. Reasoning 4 in artificial to comments on “Perspectives on the theory and practice of belief functions”, Int. .I. Approx. Reasoning 6 ( 1992) 445-480. I77 I G. Shafer and R. Logan, Implementing Dempster’s rule for hierarchical evidence, A@ Intell. 33 (1987) 271-298. I78 1 P. Shenoy and G. Shafer, Propagating belief functions with local computations, IEEE Expert 1 (3) ( 1986) 43-52. I79 I F.K.J. Sheridan, A survey of techniques for inference under uncertainty, Artif: Intell. Rev. 5 ( 1991) 89-l 19. (Elsevier, New York, 1976). in medicine, Math. Biosci. 23 ( 1975) 182 I functions, I80 I E.H. Shortliffe, Computer-Based Medical Consultations: MYCIN E.H. Shortliffe and B.G. Buchanan, A model of inexact reasoning 181 35 l-379. P. Smets, Belief Logics for Automated Reasoning P. Smets, The transferable Bonissone, M. Henrion, L.N. Kanal and J.F. Lemmer, eds., Uncertainty (North-Holland, Amsterdam, 1991) 375-383. P Smets, Resolving misunderstandings 321-344. belief model and other interpretations (Academic Press, London, 1988) 253-286. about belief functions, I 84 183 of Dempster-Shafer’s model, in Arrifcial in: PP. Intelligence 6 Int. J. Approx. Reasoning 6 ( 1992) in: P Smets, A. Mamdani, D. Dubois and H. Prade, eds., Non-Standard I85 1 P. Smets and R. Kennes, The transferable belief model, Artif: Intell. 66 (1994) 191-234. I86 I P. Smets, A. Mamdani, D. Dubois and H. Prade, eds., Nun-Standard Logics for Automated Reasoning (Academic Press, London, 1988). I 87 ] C.A.B. Smith, Consistency in statistical inference and decision (with discussion), J. Roy. Stat. Sot. Ser. B 23 (1961) l-37. [ 88 I M. Smithson, 1891 D.J. Spiegelhalter, A statistical view of uncertainty Ignorance and Uncertainty (Springer, Berlin, 1989). in expert systems, in: W.A. Gale, ed., Arrifcial Intelligence and Staristics (Addison-Wesley, Reading, MA, 1986). ( 901 D.J. Spiegelhalter, AI? Dawid, S.L. Lauritzen and R.G. Cowell, Bayesian analysis in expert systems (with discussion), [ 9 I I D.J. Spiegelhalter Stat. Sci. 8 (1993) 219-283. and R.P. Knill-Jones, Statistical and knowledge-based systems, with an application support 147 ( 1984) 35-76. in gastroenterology (with discussion), approaches to clinical decision- J. Roy. Stat. Sot. Ser. A P Walley/Arti$cial Intelligence 83 (1996) l-58 57 [ 92 I T.M. Strat, Decision analysis using belief functions, ht. J. Approx. Reasoning 4 ( 1990) 391-417. 1931 C. Smdberg and C. Wagner, Generalized finite differences and Bayesian conditioning of Choquet capacities, Unpublished manuscript (1991). I94 I B. Tessem, Interval probability propagation, Int. J. Approx. Reasoning 7 ( 1992) 95-120. I 95 I F. Vaorbraak, On the justification of Dempster’s rule of combination, Artif Intell. 48 ( 199 1) 17 l- 197. I 96 I F? Walley, Coherent lower (and upper) probabilities, Statistics Research Report, University of Warwick, Coventry (1981). I97 I P. Walley, The elicitation and aggregation of beliefs, Statistics Research Report, University of Warwick, Coventry (1982). I98 I F? Walley, Belief function representations of statistical evidence, Ann. Stat. 15 (1987) 1439-1465. I99 1 P. Walley, Statistical Reasoning with Imprecise Probabilities (Chapman and Hall, London, 1991). I 1001 P. Walley, Measures of uncertainty in expert systems, Statistics Research Report, Department of I101 I102 [ 103 Mathematics, University of Western Australia, Perth ( 199 1) . I? W;rlley, Inferences from multinomial data: learning about a bag of marbles (with discussion), J. Roy. Stat. Sot. Ser. B 58 (1996) 3-57. P. Walley, Statistical inferences based on a second-order possibility distribution (with discussion), J. Ant. Srat. Assoc. 91 ( 1996). I! Walley and FM. Campello de Souza, Uncertainty and indeterminacy in assessing the economic viabil!ity of energy options: a case study of solar heating systems in Brazil, Energy Syst. Policy 14 ( 19913) 28 I-304. I 104 I P. Walley and T.L. Fine, Varieties of modal (classificatory) and comparative probability, Synthese 41 ( 197’9) 321-374. I 105 I P. Walley and T.L. Fine, Towards a frequentist theory of upper and lower probability, Ann. Stat. 10 (1982) 741-761. I 1061 T.S. ‘Wallsten, D.V. Budescu, A. Rapoport, R. Zwick and B. Forsyth, Measuring the vague meanings of ptobability terms, J. Exper. Psych. General 115 (1986) 348-365. I 107 1 L.A. Wasserman, Comments on Shafer’s “Perspectives on the theory and practice of belief functions”, Int. J. Approx. Reasoning 6 (1992) 367-375. I 108 I L.A. Wasserman and J. Kadane, Bayes’ theorem for Choquet capacities, Ann. Stat. 18 (1990) 132% 1339 I 109 I S.R. Watson, J.J. Weiss and M.L. Donnell, Fuzzy decision analysis, IEEE Trans. Svst. Man Cvbern. 9 1110 1 III I112 I113 (1979) 1-9. P.M. Williams, Indeterminate probabilities, in: M. Przelecki, K. Szaniawski and R. Wojcicki, eds., Formal Methods in the Methodology of Empirical Sciences (Reidel, Dordrecht, 1976) 229-246. N. Wilson, A Monte-Carlo algorithm for Dempster-Shafer belief, in: B.D. D’Ambrosio, P Smets and PP Elonissone, eds., Proceedings Seventh International Conference on Uncertainty in AI, Los Angeles, CA (Morgan Kaufmann, San Mateo, CA, 1991) 414-417. N. Wilson, The combination of belief: when and how fast?, Int. J. Approx. Reasoning 6 (1992) 377-,388. N. Wilson and S. Moral, A logical view of probability, in: A. Cohn, ed., Proceedings Eleventh European Conference on Artificial Intelligence (Wiley, London, 1994) 386-390. I 1 14 I H. XII, An efficient implementation of belief function propagation, in: B.D. D’Ambrosio, E! Smets and PP. Eionissone, eds., Proceedings Seventh International Conference on Uncertainty in AI, Los Angeles, CA (Morgan Kaufmann, San Mateo, CA, 1991) 425-432. I 1 IS I R.R. Yager, An introduction to applications of possibility theory (with discussion), Human Syst. Manage. 3 (1983) 246-269. I I 16 I L.A. Zadeh, Fuzzy sets, I@ Control 8 ( 1965) 338-353. I I 17 I L.A. Zadeh, The concept of a linguistic variable and its application to approximate reasoning (Part 3), I@ Sci. 9 (1976) 43-80. I I 18 I L.A. Zadeh, Fuzzy sets as a basis for a theory of possibility, Fuzzy Sets Syst. 1 (1978) 3-28. I II91 L.A. Zadeh, A theory of approximate reasoning, in: J. Hayes, D. Michie and L.I. Mikulich, eds., Machine Intelligence 9 (Halstead Press, New York, 1979) 149-194. I 1201 L.A. Zadeh, The role of fuzzy logic in the management of uncertainty in expert systems, Fuzzy Sets Syst. 11 (1983) 199-227. 58 P: Walley/Artijcial Intelligence 83 (1996) I-58 1 1211 L.A. Zadeh, Is probability theory sufficient for dealing with uncertainty Kanal and J.E Jxmmer, eds., Uncertainty in Art$cial Intelligence (North-Holland, Amsterdam, 103-l 16. in AI: a negative view, in: L.N. 1986) 