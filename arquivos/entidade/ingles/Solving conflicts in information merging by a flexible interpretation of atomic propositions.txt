Artificial Intelligence 175 (2011) 1815–1855Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSolving conflicts in information merging by a flexible interpretationof atomic propositionsSteven Schockaert a,∗,1, Henri Prade ba Ghent University, Department of Applied Mathematics and Computer Science, Krijgslaan 281, 9000 Gent, Belgiumb Toulouse University, Université Paul Sabatier, IRIT, CNRS, 118 Route de Narbonne, 31062 Toulouse Cedex 09, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 20 July 2010Received in revised form 21 April 2011Accepted 23 April 2011Available online 28 April 2011Keywords:Information fusionSimilarity-based reasoningPrioritized knowledge basesPossibilistic logicPenalty logic1. IntroductionAlthough many techniques for merging conflicting propositional knowledge bases havealready been proposed, most existing work is based on the idea that inconsistency resultsfrom the presence of incorrect pieces of information, which should be identified andremoved. In contrast, we take the view in this paper that conflicts are often causedby statements that are inaccurate rather than completely false, suggesting to restoreconsistency by interpreting certain statements in a flexible way, rather than ignoringthem completely. In accordance with this view, we propose a novel approach to mergingwhich exploits extra-logical background information about the semantic relatedness ofatomic propositions. Several merging operators are presented, which are based on differentformalizations of this background knowledge, ranging from purely qualitative approaches,related to possibilistic logic, to quantitative approaches with a probabilistic flavor. Bothsyntactic and semantic characterizations are provided for each merging operator, and thecomputational complexity is analyzed.© 2011 Elsevier B.V. All rights reserved.In applications where information from different sources needs to be combined, conflicts are often the rule rather thanthe exception. The presence of conflicts requires special attention, as it casts doubt on the reliability of available information.Even worse, if information is encoded in classical logic, the combined pieces of information become trivial, as anything canbe derived from contradiction. To accommodate the possibility of conflicts in a more useful way, a wide array of approacheshas been proposed in the literature, ranging from purely syntactic approaches to semantic operators that manipulate sets ofinterpretations. In general, the problem of information merging has been studied both in logical and in numerical settings.An example of the latter case are situations where different probability or possibility distributions need to be fused [1,2].This paper focuses exclusively on merging in a logical setting.A common idea underlying many approaches to logical information merging is to get rid of the least reliable pieces ofinformation. The exact mechanism being employed may, among others, be based on prior knowledge about the reliabilityof different pieces of information and of sources [3,4], on discriminating between pieces of information according to thenumber of supporting sources [5], or on the dialectical principles of argument and counter-argument [6]. The essentialpoint of view underlying such approaches is that conflicts are caused by errors that are in some sense arbitrary: any pieceof information has some chance of being wrong, and agreement between sources (or prior knowledge) is all that can helpus to decide which pieces are more likely to be correct. A closely related idea is to weaken the information that is provided* Corresponding author.E-mail addresses: steven.schockaert@ugent.be (S. Schockaert), prade@irit.fr (H. Prade).1 Postdoctoral fellow of the Research Foundation – Flanders (FWO).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.04.0011816S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855by each of the sources [7–10]. For instance, if some source claims p ∧ q, we may change this, among others to p ∨ q. Thismay be motivated in several ways. If the sources express conflicting goals or preferences, for instance, we may consider thateach competing source needs to concede to arrive at a feasible global strategy. Alternatively, when sources express beliefs,we may consider that weaker information is more reliable, and that by progressively weakening these beliefs we ultimatelyend up with beliefs that are correct, and thus consistent. Without extra-logical information, however, approaches based onthis idea tend to be rather coarse, often depending on the assumption that all atoms in the language encode properties thatare approximately of equal importance in the domain being modeled.A quite different approach to dealing with conflicts is to relax the assumption that sources need to be combined con-junctively. Indeed, if individual sources are consistent, combining them disjunctively trivially restores consistency. Startingfrom this basic idea, more refined techniques have been developed, e.g. based on disjunctively combining conjunctions ofmaximal consistent subsets of knowledge bases [11,12]. Paraconsistent logics [13] offer yet another solution to the problemof conflict. Rather than trying to modify the knowledge bases, the logic itself is changed such that only non-trivial conclu-sions can be derived, even in the face of logical contradiction. The fact that both p and ¬p may be entailed by a non-trivialtheory may, in some paraconsistent logics (e.g. the logic of formal inconsistency [14]), be interpreted as evidence that theproperty modeled by p is controversial (or ill-defined, vague, etc.) in which case it is natural that different sources mayhave a different standpoint regarding p. A consequence of this methodology is that, contrarily to most other methods, thereis no real loss of information when conflicts arise. Indeed, when p is asserted by some source and ¬p by another source,we do not give up our belief in p but rather gain the insight that p is controversial.In this paper, we are exploring a new direction, which is motivated by the fact that in real-world applications, randomerrors occur side-by-side with conflicts that are due to the use of properties that may be understood differently by differentsources (e.g. vague properties such as ‘tall’). The method being used to deal with conflicts is then not only determined bythe nature of conflicts, but also — and perhaps even especially — by the nature of available background knowledge. Logics offormal inconsistency, for instance, require that some atoms are designated as uncontroversial, to ensure meaningful results.In general, most methods assume no, or very little prior knowledge, making them widely applicable, but at the sametime limiting their ability to correctly identify the real cause of conflicts, and thus, ultimately, their usefulness. A similarconsideration applies to the problem of belief revision, for which it is well known that extra-logical information about theepistemic state of an agent (e.g. in the form of an epistemic entrenchment ordering) is key to meaningful results [15]. Forthe task of merging the beliefs expressed by different sources, however, the use and importance of extra-logical informationis less well-understood. Nonetheless, there are many situations where appropriate background knowledge is paramount incorrectly dealing with conflicts.Example 1. Consider a situation where predictions are available about tomorrow’s weather from three well-reputed sources.Predictions from all sources are expressed in a propositional language over the set of atoms {overcast, partiallyCloudy,openSky}, subject to the integrity constraint that overcast, partially cloudy, and open sky are Jointly Exhaustive and PairwiseDisjoint atoms (a property called JEPD in the following):K1 = {partiallyCloudy ∨ overcast}K2 = {openSky}K3 = {overcast}(1)(2)(3)If all three sources are considered equally reliable, classical merging strategies would either yield the trivial result overcast ∨partiallyCloudy ∨ openSky, or conclude overcast, which is the only atom that is compatible with the majority of the sources.Since all three sources are well-reputed, however, the extreme conclusions openSky and overcast seem less plausible than theintermediate conclusion partiallyCloudy. However, without additional information, encoding this idea of being intermediate,there are no reasons to prefer partiallyCloudy over overcast or openSky.The core idea in this example is that atoms such as overcast should be understood in a flexible way. The need forflexibility regarding the meaning of atoms may stem from different causes, including all of the following:1. Sources are overconfident, and the assertions they make are too precise, given the knowledge they actually have. In theexample above, it is clear that people prefer more informative weather reports (e.g. it will be sunny tomorrow), withthe risk of being slightly wrong from time to time, over completely honest but less informative or uninformative reports(e.g. it may be sunny or cloudy).2. Atoms refer to properties for which precise, generally accepted definitions are lacking. Typically these are propertiesthat depend on threshold values in some continuous domain, or properties whose definition may slightly vary with thecontext. For instance, there may be situations that are described as an open sky by some people and partially cloudyby others.3. Atoms refer to terms with a well-understood meaning, which are nonetheless used in a more liberal, or more restrictiveway in certain contexts. It is not hard to imagine, for example, a person in a civil union answering affirmatively tothe question “Are you married (yes/no)?”, e.g. when filling in a web form. As another example, the term Asian is oftenS. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551817reserved to refer to people from South Asia in the UK, or the people from East Asia in the USA, thus restricting theactual meaning of the term.4. Atoms refer to ambiguous terms, which may mean completely different things. The term “public school”, for instance, isused with an entirely different meaning in the UK and USA; also, different people, places, or events are often describedby the same name; etc.The underlying idea common to the aforementioned causes of conflict is that there are some countermodels of a state-ment that are in some sense similar to models of the statement. Given that the statement is asserted by a reliable source,we may then consider that normally, the actual state of affairs is described by one of the models of that statement, althoughexceptionally, it might also be described by one of these similar countermodels. The aim of this paper is to formalize thisintuition, leading to merging operators for propositional knowledge bases that effectively take available background infor-mation about the relatedness of atoms into account.The paper is structured as follows. In the next section, we provide the required background on a number of well-known approaches to information merging in the propositional setting: distance-based merging, conflict-based mergingand morpho-logical merging. Next, Section 3 introduces the basic ingredient of our approach, i.e. background informationabout the semantic relatedness of atoms. After outlining the main idea, it is shown how relatedness can be representedat the syntactic level and at the semantic level, and what the correspondences are between both representations. Whatresults is a general framework, in which different types of relatedness can be expressed. To cope with this generality, fourprototypical scenarios are presented in Section 4. By showing how the general framework can be instantiated to implementeach of these scenarios, we bridge the gap between the general, but abstract framework and practical applications. InSection 5 we subsequently turn to the merging problem itself. We show how different merging operators naturally arisefrom different interpretations of the weighted knowledge bases that encode how different atoms are related. After definingthe merging operators at the syntactic level, we provide semantic characterizations that reveal close links with existingmerging operators. The computational complexity of the merging operators is studied in Section 6, after which we presentour conclusions.2. Background on propositional mergingIn the following, we consider a propositional language built from a finite set of atoms A and the connectives ∨, ∧, →,≡, ¬ in the usual way. An interpretation I is defined as a subset of atoms a in A, where I |(cid:7) a for an atom a iff a ∈ I . Aninterpretation is said to be a model of a formula (resp. set of formulas) if it satisfies that formula (resp. every formula inthe set) in the usual sense. We write (cid:2)φ(cid:3) to denote the set of all models of a formula φ.We will also need a few order-theoretic concepts. Given a relation (cid:2) in a universe U , we write min(U , (cid:2)) for the set ofelements from U that are minimal w.r.t. (cid:2), i.e.min(U , (cid:2)) = {u ∈ U | ¬∃v ∈ U . v (cid:2) u ∧ u (cid:2) v}Given a list of relations (cid:2)1, . . . , (cid:2)n in U , we write par((cid:2)1, . . . , (cid:2)n) and lex((cid:2)1, . . . , (cid:2)n) to denote their Pareto and lexico-graphic extensions respectively, i.e.(u, v) ∈ par((cid:2)1, . . . , (cid:2)n)iff ∀i ∈ {1, . . . , n} . u (cid:2)i vand (u, v) ∈ lex((cid:2)1, . . . , (cid:2)n) iff either (u, v) ∈ par((cid:2)1, . . . , (cid:2)n) or∃k ∈ {1, . . . , n} .(cid:2)∀i ∈ {1, . . . , k − 1} . u (cid:2)i v(cid:3)∧ (u <k v)where u <k v is used as a shorthand for u (cid:2)k v ∧ v (cid:2)k u. Note that in the case of the lexicographic ordering, the numbering iof the relations (cid:2)i encodes an ordering of their importance.Let K1, . . . , Kn be propositional knowledge bases that are individually consistent, and let C be a set of integrity con-straints. The purpose of a merging process is to find one knowledge base (cid:3)(K 1, . . . , Kn) which is consistent with the in-tegrity constraints (i.e. (cid:2)(cid:3)(K1, . . . , Kn)(cid:3) ⊆ (cid:2)C(cid:3)), and which integrates the information from the knowledge bases K 1, . . . , Knto the best extent possible.A variety of methods to obtain a suitable knowledge base (cid:3)(K 1, . . . , Kn) have already been studied. For instance, thereis a long tradition in inconsistency management to restore consistency by identifying maximal consistent subsets [16]. Inparticular, we may define (cid:3)(K1, . . . , Kn) to be the disjunction of (a subset of) these maximal consistent subsets (where a setof formulas is treated as a conjunction). Such approaches, however, mainly attempt to isolate the inconsistency, rather thanreconciling any conflicting views that different sources may hold. Our approach will therefore be based on a different line ofwork, which tries to resolve inconsistencies using the idea that the models of (cid:3)(K 1, . . . , Kn) should be those interpretationsthat are in some sense close to the models of the knowledge bases K 1, . . . , Kn. Next, we briefly recall three importantclasses of existing merging operators that are based on this idea, and will play a role in the remainder of this paper.1818S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18552.1. Distance-based mergingA common strategy is to define merging operators based on a pseudo-metric d on interpretations [8,5,17]. Although d isnot required to satisfy the mathematical properties of a metric (e.g. triangle inequality or even symmetry), it is common torefer to d as a distance. Given two interpretations I and J , the well-known Hamming distance dHam is often used to thisend:dHam(I, J ) =(cid:4)(cid:4)(cid:4) = |I \ J | + | J \ I|(cid:4)(I \ J ) ∪ ( J \ I)i.e. dHam(I, J ) is equal to the number of atoms on which interpretations I and J disagree. The Hamming distance is some-times also called Dalal distance, as Dalal first proposed to use it in the context of belief revision [18]. A given distance dallows us to quantify the distance between an interpretation I and a propositional knowledge base K :d(I, K ) = minJ ∈(cid:2)K (cid:3)d(I, J )Given an appropriate aggregation operation f , this can be extended to lists of knowledge bases K = (K 1, . . . , Kn):d(I, K) = f(cid:2)(cid:3)d(I, K1), . . . , d(I, Kn)(4)where f may, for instance, be the sum, a weighted sum, or (refinements of) the maximum. Now, a preorder (cid:2)d betweeninterpretations can be defined as(cid:2)(cid:3)(cid:13)I (cid:2)d Iiff d(I, K) (cid:2) d(cid:13)I, Kand the result of the merging process can semantically be defined as the knowledge base whose models are those interpre-tations that are minimal w.r.t. this preorder:(cid:4)(cid:5)(cid:3)dist(K1, . . . , Kn; C; (cid:2)d)(cid:2)= min(cid:2)C(cid:3), (cid:2)d(cid:3)(5)Although this class of merging operators is quite general and has a strong intuitive appeal, in practical applications it isalmost exclusively applied for d = dHam. An important limitation of dHam and related distances is that they are very sensitiveto the particular translation of a given problem into propositional logic [19]. In addition, such distances do not allow us toexpress that two atoms have a meaning which is in some sense related.2.2. Conflict-based mergingThe motivating idea behind conflict-based merging [20] is that many merging operators derive from manipulating theconflict set diff (I, J ) between two interpretations I and J in the following sense:diff (I, J ) = (I \ J ) ∪ ( J \ I)(6)The Hamming distance dHam(I, J ), for example, is equal to the cardinality of this conflict set. By comparing conflict setsin other ways than by their cardinality, other merging operators may be obtained. Similar to the distance-based mergingscheme, from conflict sets between interpretations, we may define the conflict between an interpretation and a knowledgebase [20]:diff (I, K i) = min(cid:2)(cid:5)diff (I, J )(cid:4)(cid:4) J ∈ (cid:2)K i(cid:3)(cid:3)(cid:6), ⊆Note that since conflict sets may be incomparable with each other (w.r.t. set inclusion), diff (I, K i) may contain multipleconflict sets ci . The conflict between an interpretation and a list of knowledge bases K = (K 1, . . . , Kn) is then representedby a set of conflict vectors, i.e. vectors of conflict sets [20]:diff (I, K) =(cid:5)(cid:14)c1, . . . , cn(cid:15)(cid:4)(cid:6)(cid:4) ci ∈ diff (I, K i)The challenge now arises to define, from such conflict vectors, the models of the knowledge base that results from mergingK1, . . . , Kn under the integrity constraints C . First, we need a relation (cid:2)confl comparing conflict vectors. Although manyalternatives can be conceived, we will only consider the case where (cid:2)confl is par(⊆, . . . , ⊆) in this paper. Note that thischoice essentially corresponds to a qualitative counterpart of the Hamming distance. Given a choice of (cid:2)confl, we mayconsider the relation (cid:2)E∃c ∈ diff (I, K) . ∀cconfl between interpretations, defined by I (cid:2)E(cid:13)(cid:13) ∈ diff ( J , K) . c (cid:2)confl cconfl J iffIt is then proposed in [20] to use the following merging operator:(cid:4)(cid:5)(cid:3)confl1 (K1, . . . , Kn; C; (cid:2)confl)(cid:2)= min(cid:3)(cid:2)C(cid:3), (cid:2)Econfl(7)S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551819following the same intuition as the distance-based merging scheme: the models of the resulting knowledge base are thosemodels of the integrity constraints that are closest to each of the given knowledge bases. The main difference is that thenotion of closest is now seen in a more general perspective.When applied to (cid:2)confl = par(⊆, . . . , ⊆), however, this merging operator appears to be too tolerant, allowing more mod-els than is intuitively required.Example 2. Consider the situation of merging the single knowledge base K 1, whose only models are J 1 = {c, d, e} andI2 = {c, d} and I3 = {b, c}. The relevantJ 2 = {a, b, c}, with the integrity constraints C , whose models are I1 = {b, c, d},conflict sets are given bydiff (I1, J 1) = {b, e},diff (I2, J 1) = {e},diff (I3, J 1) = {b, d, e},diff (I1, J 2) = {a, d}diff (I2, J 2) = {a, b, d}diff (I3, J 2) = {a}Among all these conflict sets, only {e} and {a} are optimal w.r.t. ⊆. This means that, of all models of C , I1 is neither theclosest to J 1 nor the closest to J 2. On the other hand I2 is the closest to J 1 and I3 is the closest to J 2. Therefore, it seemsappropriate to take {I2, I3} as models of the merged knowledge base. Using (7), on the other hand, leads to {I1, I2, I3}. Thereason is that I1 is a minimal element of (cid:2)C(cid:3) since{e} (cid:3) {a, d} and {a, b, d} (cid:3) {a, d}which means I2 (cid:2)Econfl I1, and{b, d, e} (cid:3) {b, e} and {a} (cid:3) {b, e}which means I3 (cid:2)Econfl I1.To address the issue illustrated in the previous example, we propose the following alternative:iffI ∈ (cid:2)C(cid:3) ∧ ∃c ∈ diff (I, K) . ∀I(cid:13) ∈ (cid:2)C(cid:3) . ∀c(cid:13) ∈ diff(cid:2)(cid:3)(cid:13)I, K. c(cid:13) ≮confl c (8)(cid:4)I ∈(cid:5)(cid:3)confl2 (K1, . . . , Kn; C; diff , (cid:2)confl)(cid:13)(cid:13) (cid:2)confl c and c (cid:2)confl c(cid:13) <confl c iff c. Note that when we apply (8) to the scenario in Example 2, we indeed findwhere cthe desired result {I2, I3}. The operator in (8) directly encodes the idea that models of the merged knowledge base shouldbe those that are closest to the given knowledge bases, treating the conflict sets as qualitative (partially ordered) distances.Note that the operator is parametrized by the conflict-operator diff , which will also allow us to consider alternatives to (6).In general, while providing extra flexibility, the conflict-based merging scheme has similar advantages and disadvan-tages as the distance-based approach. In particular, straightforward implementations do not allow to deal with semanticbackground information about the relatedness of atoms.2.3. Morpho-logical mergingAnother interesting view on propositional merging [10] is to weaken propositions using a logical counterpart of mathe-matical morphology [21]. In particular, the dilation D B (φ) of a formula φ is defined by(cid:6)(cid:4)(cid:5)(cid:5)D B (φ)=I ∈ 2 A(cid:4)(cid:4) B(I) ∩ (cid:2)φ(cid:3) (cid:17)= ∅(9)where B(I) ⊆ 2 A is a set of interpretations that are related to I in some way. Note that B, which is called the structuringelement, can be regarded as a relation between interpretations. Again the Hamming distance is most commonly used,choosingB(I) =(cid:5)(cid:13) ∈ 2 AI(cid:2)(cid:4)(cid:4) dHamI, I(cid:3)(cid:13)(cid:6)(cid:2) t(10)for some t ∈ N. This particular choice makes it straightforward to syntactically characterize D B (φ) (see [10]). The knowledgebases K1, . . . , Kn may be merged, subject to the integrity constraints C , using the operator (cid:3)morph defined by:(cid:4)(cid:5)(cid:3)morph(K1, . . . , Kn; C; B)= (cid:2)C(cid:3) ∩ (cid:2)D B (K1)(cid:3) ∩ · · · ∩(cid:4)(cid:5)D B (Kn)where the structuring element B is chosen such that consistency is effectively restored, i.e. (cid:2)(cid:3)morph(K1, . . . , Kn; C; B)(cid:3) (cid:17)= ∅.For instance, when using (10), we may choose the smallest value of t that restores consistency. Interestingly, in [22], themorpho-logical approach to merging has been generalized to first-order logic. In the propositional case, however, it is clearthat morpho-logical merging is similar in spirit as distance-based and conflict-based merging.1820S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18553. Modeling heterogeneous vocabulary usageOur approach to merging is based on interpreting statements that are provided by the sources in a flexible way. Con-ceptually this boils down to weakening each of the considered knowledge bases, i.e. increasing their set of models. Belowwe present the main ideas of our procedure. First, Section 3.1 elaborates on the relationship between weakening knowl-edge bases and interpreting atoms in a flexible way. Section 3.2 then discusses how this idea can be implemented at thesyntactic level. Subsequently, Section 3.3 provides the semantic counterpart of the syntactic mechanism for weakening ourunderstanding of statements.3.1. Weakening knowledge bases(cid:13)n(cid:13)1Let K1, . . . , Kn be sets of statements (knowledge bases) that are asserted by distinct sources s1, . . . , sn, where eachsource is assumed to use a propositional language over the same set of atoms A. We furthermore consider an additionalknowledge base C containing the integrity constraints of the domain being modeled. Throughout this paper, we will tacitlyassume that the set of integrity constraints C is consistent, and that each knowledge base K iis individually consistent.(cid:13)(cid:13)Our goal then is to weaken the statements from the knowledge bases K 1, . . . , Kn, resulting in knowledge bases K1, . . . , Kn∪ C is consistent. The term weakening reflects the fact that all models of K i are contained in the∪ · · · ∪ Ksuch that K(cid:13)set of models of Ki . While this general idea of weakening knowledge bases underlies many existing merging strategies, ourapproach is particular in its use of extra-logical information and the idea of similarity. Specifically, our point of departureis that some sources may have a slightly different understanding of the meaning of atom a. To formalize this intuition,let us write a@si to denote the understanding of atom a by source si . In other words, a@si is an artificial notation that weintroduce to precisely capture what can be assumed to hold when source si claims a. Depending on the application context,the atom a itself could then correspond to the official meaning of a given term (assuming one exists), or to the particularway this term is to be understood w.r.t. the integrity constraints in C . Moreover, given a subset of atoms X ⊆ A, we writeX @si for the set {x@si | x ∈ X}. Given a knowledge base K i , we write K @sito denote the knowledge base that results fromsubstituting each occurrence of an atom a ∈ A by the corresponding atom a@si . Thus we tacitly admit that (¬a)@si = ¬a@si ,(a ∧ b)@si = a@si ∧ b@si and (a ∨ b)@si = a@si ∨ b@si .iExample 3. Consider again the weather example (1)–(3). Consistency can be trivially restored by assuming that the threesources use a slightly different terminology:(cid:5)(cid:5)(cid:5)K @s11K @s22K @s33===(cid:6)partiallyCloudy@s1 ∨ overcast@s1(cid:6)(cid:6)openSky@s2overcast@s3As each of the knowledge bases K @s1∪ K @s3that K @s13∪ C is consistent.∪ K @s2211, K @s22, K @s33and C contain occurrences from disjoint sets of atoms, we clearly haveTo obtain more interesting conclusions than from the trivial solution in Example 3, we additionally encode how atomsof the form a@si relate to the atoms from A. This idea of using a disjoint vocabulary for each of the sources, and subse-quently imposing constraints that allow useful results without introducing inconsistency can also be found in [23]. Thislatter approach, in our notation, boils down to adding a maximal set of equivalences of the form a@si ≡ a@s j which doesnot introduce inconsistency (a procedure called belief set merging), or a maximal set of equivalences of the form a@si ≡ awhich does not introduce inconsistency (a procedure called belief set projection). The underlying idea is that the knowledgeexpressed by particular sources about particular variables is ignored. In this sense, the approach from [23] is also similar tothe procedure proposed in [24], which is more explicitly based on this idea of ignoring variables.In this paper, we propose a different solution, which may be understood as a refinement of the belief set projectionapproach from [23]. Our purpose in adding constraints, however, is not to ignore certain variables, but rather to encode inwhich way they may be understood. Although we may not know with certainty how atom a is understood by source si , inmany contexts it seems reasonable to assume that information is available about which understandings are possible. In thecase of Example 3, the understanding of overcast by source s1 may be one of the following:1. The intended meaning of overcast is adopted by source s1, i.e. we have overcast@s1 ≡ overcast, or in other wordsovercast@s1 → overcast and overcast → overcast@s1 .2. Source s1 takes a more liberal interpretation of overcast which includes some of the cases that are normally describedas partiallyCloudy, i.e. overcast@s1 → overcast ∨ partiallyCloudy and overcast → overcast@s1 .3. Source s1 takes a more restrictive interpretation of overcast which includes only some of the cases that are normallydescribed as overcast, the remaining cases being described as partiallyCloudy. We then have overcast@s1 → overcast andovercast → overcast@s1 ∨ partiallyCloudy@s1 .S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551821Assume furthermore that the first situation is considered more plausible than the second situation, which is in turn con-sidered to be more plausible than the last. Using possibilistic logic [25], for instance, we may describe our backgroundassumptions on the possible state of affairs as follows:M =(cid:5)(cid:2)(cid:2)(cid:2)(cid:2)(cid:3)(cid:2)(cid:2)(cid:3)(cid:2)(cid:3)(cid:3)(cid:2)(cid:2)oc@s1 ≡ oc(cid:3)oc@s1 ≡ oc∨(cid:2)(cid:2)oc@s1 → oc ∨ pc(cid:3)oc@s1 → oc ∨ pc∧(cid:2)oc → oc@s1(cid:3)(cid:3)oc → oc@s1∧∨∨(cid:3), λ1,∧oc@s1 → oc(cid:2)oc@s1 ≡ oc, λ0(cid:3)(cid:2)oc → oc@s1 ∨ pc@s1(cid:3)(cid:6)(cid:3)(cid:3)(cid:3), 1,where we have abbreviated overcast and partiallyCloudy as oc and pc respectively, and 0 < λ0 < λ1 < 1. The possibilisticknowledge base M encodes that we are certain that at least one of the three situations described above is correct. Withless certainty, we believe that at least one of the first two situations is correct, and with even less certainty that the firstsituation is correct. It can be verified2 that the possibilistic knowledge base M may be equivalently expressed as(cid:5)(cid:2)M =oc@s1 → oc ∨ pc, 1(cid:3)(cid:2),oc → oc@s1 ∨ pc@s1 , 1(cid:3)(cid:2),oc → oc@s1 , λ1(cid:3)(cid:2),oc@s1 → oc, λ0(cid:3)(cid:6)(11)Note how the knowledge base M encodes more or less plausible ‘mistakes’ that may explain conflicts between differentsources. This idea of merging propositional knowledge bases by trying to identify the underlying mistakes that have beenmade by the sources has been advocated in [26].3.2. Syntactic encodingNote that implications are used as the basic building blocks instead of equivalences in (11). This is due to the fact thatthe exact meaning of e.g. oc@s1 may not be expressible using the available terminology (i.e. the atoms in A). All we canexpress then, are necessary and sufficient conditions under which oc@s1 and ¬oc@s1 hold. This gives rise to four types ofimplications, which are used to encode the relationship between the atoms in A@si and those in A:(cid:7)(cid:5)a@si →(cid:7)(cid:5)a →¬a@si →(cid:7)(cid:5)¬a →x@si(cid:7)(cid:5)a(cid:6)(cid:4)(cid:4) w ∈ W lw(cid:4)(cid:6)(cid:4) x ∈ Xl(cid:4)(cid:4) y ∈ Y la(cid:4)(cid:6)(cid:4) z ∈ Z l¬ ya¬z@sia(cid:6)where l ∈ {0, . . . , k} and W la, Xla, Y la, Z la⊆ A are sets of atoms such that(12)(13)(14)(15){a} = W 0⊆ W 1aa⊆ · · · ⊆ Y k⊆ Y 1{a} = Y 0a ,aa⊆ · · · ⊆ W ka ,{a} = X 0a{a} = Z 0a⊆ X 1a⊆ Z 1a⊆ · · · ⊆ Xka⊆ · · · ⊆ Z kaNote that an arbitrary number of disjuncts may appear in the right-hand side of the implications. The disjuncts that appearin the right-hand sides of the implications are denoted as W la, where l is a tolerance parameter, i.e. ratherthan considering one implication of each type, we consider a sequence of implications which allow for an increasingly moreliberal view. For l = 0, the implications (12)–(15) simply assert that a@si ≡ a. For larger values of l, these implications cor-respond to increasingly weaker constraints on the exact logical relationship between a and a@si . The underlying idea is thatthe larger the value of l, the more certain we are that the logical relations expressed by (12)–(15) are valid. By consideringlarger values of l, we effectively stretch the meaning of what is asserted by the source, until it becomes consistent withwhat is asserted by other sources. As the meaning of propositions cannot be stretched indefinitely, some fixed upper boundk is assumed. Note that in the approach presented in [23], we have either a@si ≡ a, or a@si ≡ (cid:19) when the literal a should beignored for the sake of consistency.a and Z la, Xla, Y lNote that (12) and (14) respectively correspond to necessary and sufficient conditions for having a@si true, expressed inthe standard usage of the vocabulary. Similarly, (13) and (15) respectively correspond to necessary and sufficient conditionsfor having a true, assuming the vocabulary usage of source si . In practice, depending on the characteristics of the domain,several of the implications (12)–(15) may be trivial. To allow us to trivialize the implications in a convenient way, we treat(cid:19) and ⊥ as special atoms from A (rather than primitives in the language). We will tacitly assume that C contains at leastthe formula (cid:19) ∧ ¬⊥, enforcing that (cid:19) is contained in any model of the integrity constraints, and ⊥ is contained in no suchmodel, and furthermore that (cid:19)@si = (cid:19) and ⊥@si = ⊥ for every source si .Example 4. In the case of (11), implications of the form (14) or (15) were not considered for l > 0. This is due to the factthat the vocabulary does not allow us to express sufficient conditions for a or a@si , using respectively the vocabulary ofsource si and the standard vocabulary. This leads to:2 By repeated application of the possibilistic resolution rule (¬p ∨ q, λ), (p ∨ r, μ) (cid:21) (q ∨ r, min(λ, μ)).1822S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855W 0ocW 1ocW 2oc= {oc},= {oc, pc},= {oc, pc},X 0ocX 1ocX 2oc= {oc},= {oc},= {oc, pc},Y 0ocY 1ocY 2oc= {oc},= {oc, ⊥},= {oc, ⊥},Z 0ocZ 1ocZ 2oc= {oc}= {oc, ⊥}= {oc, ⊥}Note how the occurrence of ⊥ in Y lnote that in this example, the upper bound k is 2.oc and Z loc for l (cid:3) 1 effectively trivializes the corresponding implications. Furthermore,The following example illustrates a situation where all four types of implications play a non-trivial role.Example 5. The concept of a public school has a meaning in the UK which is different from the one in the USA. In particular,what is called a public school in the UK is called a private school in the USA, and what is called a public school in the USAis called a state school in the UK. Now assume that sources are supposed to use the UK terminology, but that occasionally,some source makes the mistake of using the term public school in its USA meaning. The possible understandings of theatom pu (public school) in terms of the remaining atoms pr (private school) and st (state school) can then be encoded inpossibilistic logic as follows:(cid:5)(cid:2)M =(cid:2)pu@si → pu ∨ st, 1(cid:2)pu@si → pu, λ0(cid:3),pu → pu@si ∨ pr@si , 1(cid:3)(cid:6)pu → pu@si , λ0(cid:3)(cid:2),(cid:3)(cid:2),¬pu@si → ¬pu ∨ ¬st, 1(cid:3)(cid:2),¬pu → ¬pu@si ∨ ¬pr@si , 1(cid:3),where 0 < λ0 < 1. In this case, we get:W 0puW 1pu= {pu},= {pu, st},X 0puX 1pu= {pu},= {pu, pr},Y 0puY 1pu= {pu},= {pu, st},Z 0puZ 1pu= {pu}= {pu, pr}Throughout the paper, certainty degrees which are attached to formulas will be interpreted in a variety of different ways(including necessities, priorities, and penalties). In each case, the knowledge base will syntactically be expressed in the sameway, however. In particular, given the sets W la, for each source si , we will consider the following weightedknowledge base:(cid:8)(cid:9)a and Z la, Xla, Y l(cid:11)=Msi∪∪∪(cid:7)(cid:5)(cid:7)(cid:5)wa@si →(cid:8)(cid:9)a →(cid:8)(cid:9)(cid:8)(cid:9)¬a@si →(cid:7)(cid:5)¬a →(cid:10) (cid:4)(cid:10) (cid:4), λW(l,si ,a), λ X(l,si ,a)(cid:6)x@si(cid:7)(cid:5)(cid:6)a(cid:6)(cid:4)(cid:4) w ∈ W l(cid:4)(cid:4) x ∈ Xl(cid:4)(cid:4) y ∈ Y la(cid:4)(cid:6)(cid:4) z ∈ Z l¬ ya¬x@sia, λY(l,si ,a), λ Z(l,si ,a)(cid:4) a ∈ A, l ∈ {0, . . . , k}(cid:11)(cid:4) a ∈ A, l ∈ {0, . . . , k}(cid:11)(cid:10) (cid:4)(cid:4) a ∈ A, l ∈ {0, . . . , k}(cid:11)(cid:4) a ∈ A, l ∈ {0, . . . , k}(cid:10) (cid:4)(16)×(l,si ,a) (with × ∈ {W , X, Y , Z }) are certainty values (or priorities) taken from a totally or partially orderedwhere the values λ(l2,si ,a) when l1 (cid:2) l2, i.e. the more the constraints on the meaning of a certain atom a areset (Λ, (cid:2)) such that λrelaxed, the more certain that they are correct. Note that the full generality of (16) is not always needed, and sometimeseven a single sequence of certainty values λl would be enough. Among others this depends on how the certainty weightsare interpreted (symbolic weights, penalties, priorities, etc.). In Section 5 we will discuss how different interpretations ofthese certainty values lead to merging operators with a different behavior.×(l1,si ,a)(cid:2) λ×In the following, we also consider the following alternative to the set Msi :M(cid:13)si=(cid:8)(cid:9)(cid:9)a@si →(cid:9)(cid:7)(cid:5)w(cid:7)(cid:5)∧¬a →¬x@si(cid:6)(cid:10)∧(cid:6)(cid:10)(cid:4)(cid:4) w ∈ W l(cid:4)(cid:4) z ∈ Z laa(cid:9)a →(cid:7)(cid:5)(cid:4)(cid:4) x ∈ Xlax@si(cid:6)(cid:10)(cid:9)∧(cid:10) (cid:4), λ(l,si ,a)(cid:4) a ∈ A, l ∈ {0, . . . , k}¬a@si →(cid:11)(cid:7)(cid:5)(cid:4)(cid:4) y ∈ Y la¬ y(cid:6)(cid:10)(17)with the corresponding assumption that l1 (cid:2) l2 implies λ(l1,si ,a) (cid:2) λ(l2,si ,a). Note that in possibilistic logic, when λWλ X(l,si ,a)logic [27,28] due to the additive interpretation of the weights.= λ(l,si ,a), we have that Msi is equivalent to M, while this is not the case in, for instance, penalty= λ Z= λY(l,si ,a)(l,si ,a)(l,si ,a)=(cid:13)siClearly, the combined use of the four types of implications (12)–(15) results in a powerful mechanism which encom-passes a wide variety of inconsistency scenarios. To bridge the gap between this general, but abstract mechanism andpractical applications, we discuss in Section 4 four prototypical scenarios in which our framework could be applied. Wethen also introduce a graph representation, which allows to describe in a compact and intuitive way, how an atom may beunderstood flexibly, at a given level of tolerance.S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–185518233.3. Semantic encodingAt the semantic level, a flexible understanding of statements can be obtained by using suitable operators that manipulatesets of atoms (i.e. interpretations). Let R be a reflexive relation in A, and let I ⊆ A be a set of atoms. Then we define theexpansion (cid:14)I(cid:15)R and contraction [I]R of I w.r.t. R as the following sets:(cid:4)(cid:4) ∃b ∈ A . (a, b) ∈ R ∧ b ∈ I(cid:4)(cid:4) ∀b ∈ A . (a, b) ∈ R ⇒ b ∈ I(cid:14)I(cid:15)R =[I]R = co(cid:14)coI(cid:15)R =(cid:5)a ∈ A(cid:5)a ∈ A(19)(18)(cid:6)(cid:6)where co X is understood as the set complement of X w.r.t. A, i.e. co X = A \ X . Since R was assumed to be reflexive, weclearly have [I]R ⊆ I ⊆ (cid:14)I(cid:15)R . Also note that when R is an equivalence relation, expansion and contraction correspond to thenotion of upper and lower approximation from rough set theory [29]. In that case, (cid:14)I(cid:15)R is the union of the equivalenceclasses that overlap with I , whereas [I]R is the union of the equivalence classes that are included in I .The intuition behind (18)–(19) is best seen when we interpret R as modeling some form of similarity. Then (cid:14)I(cid:15)R con-tains those atoms that are similar to at least one atom from I . Hence J ⊆ (cid:14)I(cid:15)R can be interpreted as asserting that Jisapproximately included in I , in the sense that every atom in J is similar to an atom in I . The set [I]R , on the other hand,contains those atoms that are only similar to atoms from I . This means that [I]R ⊆ J can be interpreted as asserting thatco J is approximately included in coI , in the sense that every atom outside J is similar to an atom outside I . Let us nowconsider the following relation:[I]R1⊆ J ⊆ (cid:14)I(cid:15)R2σ(R1,R2)(I, J )iff(20)Then σ(R1,R2)(I, J ) expresses some form of similarity between interpretations I and J . Indeed, since J ⊆ (cid:14)I(cid:15)R2 we know thatevery atom interpreted as true by J is similar (w.r.t. R2) to an atom interpreted as true by I , and since [I]R1⊆ J we knowthat every atom interpreted as false by J is similar (w.r.t. R 1) to an atom interpreted as false by I .In the particular case where R1 and R2 are both equal to the identity relation (i.e. (a, b) ∈ R1 iff (a, b) ∈ R2 iff a = b),then also σ(R1,R2) degenerates to the identity relation (i.e. σ(R1,R2)(I, J ) iff I = J ). In general, when R1 and R2 capture someform of similarity between atoms, σ(R1,R2) captures a notion of similarity between interpretations. Note however that ingeneral σ(R1,R2) is not symmetric, not even when R1 and R2 are symmetric and/or R1 = R2.Example 6. Let pu and pr correspond to public and private schools, as before, and let un refer to a university. Then wemay consider that public and private schools are similar to each other, but neither is similar to a university, i.e. we letR = {(pu, pu), (pr, pr), (un, un), (pu, pr), (pr, pu)}, I = {pu, un} and J = {un}. Then we have[I]R = {un},[ J ]R = {un},(cid:14)I(cid:15)R = {pu, pr, un}(cid:14) J (cid:15)R = {un}In particular we find that [I]R ⊆ J ⊆ (cid:14)I(cid:15)R , but not [ J ]R ⊆ I ⊆ (cid:14) J (cid:15)R . Thus σ (R, R)(I, J ) holds but not σ (R, R)( J , I).Thus the relatedness between interpretations I and J may be parametrized by four reflexive relations R 1, R2, R3, R4between atoms, by considering that I is similar to J when σ(R1,R2)(I, J ) and σ(R3,R4)( J , I) both hold. From a practical pointof view, however, it is not immediately clear why we need four different relations, and how they should be defined tomodel a particular scenario. This situation is reminiscent of the four types of implications (12)–(15) we have considered ata and Z lthe syntactic level. The intuitive correspondence between the aforementioned relations and the families W lacan be made explicit by interpreting the latter families as relations W l, Xl, Y l and Z l, where W l = {(a, b) ∈ A2 | b ∈ W l},aand analogously for the other relations. The exact correspondence is revealed by the following proposition.a, Xla, Y la, Y la, and Z la for a ∈ A and l ∈ {0, . . . , k} be defined as before. Then we have the following characterizations:Proposition 1. Let W la, Xl(cid:3)(cid:2)a ∈J \ (cid:14)I(cid:15)⇔ I ∪ J @si(cid:2)(cid:2)(cid:2)a ∈a ∈a ∈W l(cid:3)XlI \ (cid:14) J (cid:15)(cid:3)(cid:3)[I]Y l \ J[ J ]Z l \ I(cid:7)(cid:5)(cid:9)a@si →(cid:17)|(cid:7)(cid:9)a →(cid:17)|(cid:7)(cid:7)(cid:5)⇔ I ∪ J @si(cid:9)⇔ I ∪ J @si(cid:17)|(cid:7)¬a@si →⇔ I ∪ J @si(cid:17)|(cid:7)(cid:9)¬a →(cid:7)(cid:5)x@si(cid:7)(cid:5)(cid:4)(cid:4) w ∈ W la(cid:6)(cid:10)w(cid:4)(cid:4) x ∈ Xl(cid:4)(cid:4) y ∈ Y l(cid:4)(cid:4) z ∈ Z l¬ yaa¬z@si(cid:6)(cid:10)(cid:6)(cid:10)a(cid:6)(cid:10)(21)(22)(23)(24)Intuitively, e.g. (21) teaches us that I ∪ J @si |(cid:7) (a@si →}) means that whenever a ∈ J for an atom a, we}) for all a ∈ A is equivalent to statingW l . Thus, Proposition 1 essentially reveals that the relations R1, R2, R3 and R4 correspond to Y l, W l, Z l and XlW l . In other words, the fact that I ∪ J @si |(cid:7) (a@si →{w | w ∈ W l(cid:12)a{w | w ∈ W laalso have a ∈ (cid:14)I(cid:15)that J ⊆ (cid:14)I(cid:15)(cid:12)1824S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855Fig. 1. Four prototypical types of weakening the meaning of an atom.respectively. This observation also makes clear why we need, in general, the flexibility of parametrizing similarity betweeninterpretations by four different relations between atoms. In practice, on the other hand, these four relations do not have tobe specified explicitly most of the time, as we will explain in the following section.4. Prototypical use casesThe use of four different families of nested sets, W la, Y la, results in an expressive method to encode howknowledge bases may be weakened. This generality is needed, as the fact that an atom may be understood in a flexible waymay mean different things in different contexts. For illustrative purposes, let us write ext(a) to denote the set of situationsin which property a holds (e.g. we may think of ext(a) as some region of a conceptual space in the sense of Gärdenfors[30]). There seem to be four prototypical scenarios that are often encountered in practice:a and Z la, Xlliberalization In certain contexts, and depending on the view one takes, we may be more liberal regarding the exactmeaning of a certain property. As a result, for borderline situations, a given property may be considered to besatisfied according to some sources, but not satisfied according to others. In this scenario, flexibility means thatwe need to admit that the sources may have a more liberal understanding of the meaning of a property: ext(a) ⊆(cid:13)i ext(a@si ). This situation is illustrated in Fig. 1(a).restriction The opposite situation also occurs: sources may hold a stricter view on the meaning of certain properties, forinstance restricting the situations in which a property is considered to hold to the most typical situations. Beingflexible then means that we may need to exclude certain borderline cases of the property: ext(a) ⊇i ext(a@si ).This situation is illustrated in Fig. 1(b); note, however, that the understandings by different sources do not neces-sarily need to overlap.(cid:14)continuity The meaning of a property may depend on some threshold value in a continuous domain, which is to someextent arbitrary. Statements provided by different sources may then be based on slightly different threshold values.This means that there are a number of situations in which the property would hold according to all sources, inaddition to situations in which it is the particular definition adopted by a source that determines whether or notthe property is considered to hold: ext(a) ∩i ext(a@si ) (cid:17)= ∅. Furthermore, due to the continuity there is potentiallyan infinite number of reasonable delineations of those situations in which the property is considered to hold. Dueto the finite number of atoms that are considered in the language,3 the exact meaning of a property, according toone source, is typically not expressible. Fig. 1(c) depicts this situation.(cid:13)ambiguity The meaning of a property may be ambiguous. This means that some sources may interpret an atom in acompletely different way than other sources. In such a case, it may happen that there is not a single situation inwhich the property is considered to hold according to two different sources. Intuitively, the meaning of an atom3 Note that even moving from a finite number of atoms to a countably infinite number of atoms would not change this situation.S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551825Fig. 2. Similarity graph for atoms related to marriage.Table 1Defining the sets W la , Xla , Y la and Z la in terms of the sets of related atoms Sla .LiberalizationRestrictionContinuityAmbiguityW laSla{a}SlaSlaXla{a}{a, (cid:19)}Sla{b | a ∈ Slb}Y la{a}Sla{a, ⊥}SlaZ la{a, ⊥}{a}{a, ⊥}{b | a ∈ Slb}is then translated, rather than stretched: ext(a) = ext(a@si ) or ext(a) ∩ ext(a@si ) = ∅. This situation is depicted inFig. 1(d).Note that from a formal point of view, in continuous domains, liberalization and restriction may be seen as special cases ofcontinuity. However, we reserve the term continuity for scenarios in which it is not known a priori whether sources willassume a more liberal, more restrictive, or overlapping meaning. Moreover, when considering liberalization and restrictionbelow, we will focus on discrete domains, and in particular assume that the exact meaning of a@si can be expressed as adisjunction, resp. conjunction of atoms from A.In each of these four scenarios, it suffices to specify, for each given atom a and tolerance level l, a single set of atoms Sla.This set Sla may be understood as the set of atoms that are similar, or related to a at the given tolerance level, although theprecise interpretation of this set will differ in each of the scenarios. In practical applications, the sets Sla may be convenientlyand compactly described using a weighted, directed graph. As such graphs encode some notion of similarity, we will refer tothem as similarity graphs. Figs. 2, 3 and 4 depict examples of such graphs. The underlying intuition is that whenever thereis a path from node a to a node b, if some source claims that a holds, it is somewhat plausible that b is the case instead.The level of plausibility depends on the weights on the edges, which in turn correspond to the tolerance levels. Hence, likethe tolerance levels, the weights may be given a number of different interpretations (qualitative as well as quantitative), aswill become clear below. In many situations, these weights will be given an ordinal interpretation, in which case it sufficesto rank the edges according to how likely the corresponding transition is.Given a similarity graph, Sla can be defined as(cid:5)b=Sla(cid:4)(cid:4) b ∈ A, dist(a, b) (cid:2) l(cid:6)(25)where dist(a, b) is the sum of the weights on the shortest path between a and b in the similarity graph under con-sideration.Intuitively, the graph from Fig. 2 specifies, among others, that married can progressively be weakened tomarried ∨ civilUnioned and then married ∨ civilUnioned ∨ widowed ∨ divorced ∨ cohabitating. When the atoms in a similar-ity graph express jointly exhaustive and pairwise disjoint (JEPD) properties, i.e. when in every possible world exactly one ofthese atoms is true, symmetric and uniformly weighted similarity graphs essentially correspond to conceptual neighborhoodgraphs in the sense of Freksa [31,32].It is important to note that similarity graphs are nothing more than a convenient vehicle to specify the sets Sla in someapplications. Sometimes, it may not be appropriate to use such a graph, and it makes more sense to specify the sets Sladirectly. For instance, the use of a similarity graph to specify the sets Sla andc ∈ Sl2a implies some form of transitivity, i.e. b ∈ Sl1.b implies that c ∈ Sl1+l2Depending on the scenario, the exact nature of the sets Slaa is different, resulting in different definitions of the sets W la,a. Thea and Z la, Xla, Y la and Z lXla, Y lresults that are going to be established are summarized in Table 1.a. Below we discuss in more detail how each given scenario dictates the definition of W l1826S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18554.1. LiberalizationThe atoms that are connected to married in the graph from Fig. 2 represent situations that can be considered as specialcases of being married, when assuming a liberal usage of this term. This means that non-standard understandings of marriedmay only enlarge its intended meaning by designating extra atoms to be special cases of married. Such a reading of asimilarity graph may be formalized as follows:(cid:7)(cid:7)(cid:10)S(26)(cid:9)a@si ≡{a}⊆S⊆Slawhich directly translates the intuition that the understanding of a by source si can be expressed as the disjunction of aparticular set S of atoms, i.e. a@si ≡S. We do not know which atoms are in S, but we assume that all atoms in S aresimilar to a (at a given tolerance level l). This reading can be equivalently expressed using the following implications:(cid:12)a@si →(cid:7)Sla,a → a@si(27)Lemma 1. The formula (26) is satisfied for all a ∈ A iff the implications in (27) are satisfied for all a ∈ A.We may thus define:W la= Sla,Xla= Y la= {a},Z la= {a, ⊥}= {a} and Y la= {a},where we used the fact that a → a@si is equivalent to ¬a@si → ¬a. Alternatively, we may define Xla= {a, ⊥}. Note in particular that negative literals of the form ¬a@si are always understood as ¬a. Thisor Xlacorresponds to the observation that married in its standard understanding is truly atomic, i.e. there are no situations thatare normally considered as married but may not be considered as such by certain sources. Conversely, when ¬a holds, onlytrivial conclusions can be expressed using the atoms in A@si , unless W la= {a}, in which case a@si ≡ a.= {a, (cid:19)} and Y laExample 7. When a source claims that somebody is married, we may consider the possibility that he or she is actually in acivil union, whereas the standard understanding of marriage only permits the strict meaning (for l = 1):W 1marriedX 1married= {married, civilUnion}= {married}When ¬married is known to hold, no conclusions can be expressed using the atoms in A@si because source si may use theterm married in a more liberal sense, such that married@si holds. On the other hand, when ¬married@si holds, we know thatalso ¬married holds. This may be expressed as:Y 1marriedZ 1married= {married}= {married, ⊥}4.2. RestrictionThe idea of restriction is dual to the idea of liberalization. Rather than admitting more borderline cases, here we need toconsider the possibility of excluding borderline cases:(cid:7)(cid:9)a@si ≡(cid:15)(cid:10)S{a}⊆S⊆Sla(28)which expresses the intuition that some source may only consider a to hold when some additional properties are satisfied.Although we do not know which set S of properties needs to be satisfied for a@si to hold, but we make the assumptionthat all these properties are similar to a. Although the sets Sla may, in principle, again be specified as a graph, such agraph would look less natural. Indeed, rather than specifying similar atoms, the set Sla here contains properties describingtypicality. Again, implications of the form (12)–(15) may be used to describe the state of affairs:¬a@si →(cid:7)(cid:5)(cid:6)(cid:4)(cid:4) s ∈ Sla,¬s¬a → ¬a@si(29)Lemma 2. The formula (28) is satisfied for all a ∈ A iff the implications in (29) are satisfied for all a ∈ A.S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551827Fig. 3. Similarity graph for atoms related to the weather.We may thus define:W la= {a},Xla= {a, (cid:19)},Y la= Sla,Z la= {a}where we used the fact that ¬a → ¬a@si is equivalent to a@si → a. Alternatively, we may define W laor W la= {a, ⊥}. Note in particular that positive literals of the form a@si are always understood as a.= {a} and Z la= {a, (cid:19)} and Z la= {a},Example 8. The term polyhedron in mathematics is sometimes defined as the finite union of convex polyhedra, where aconvex polyhedron is the intersection of a finite number of half-spaces in some particular dimension. Different definitionsare used, however, where the term polyhedron is sometimes used only for convex polyhedra, for bounded polyhedra, or forthree-dimensional polyhedra. Thus we have, for instance:S 1polyhedron= {polyhedron, convex, bounded, threeDimensional}When a source claims polyhedron@si we may not know which particular definition was assumed, but in each case we mayconclude polyhedron, as all possible definitions are more specific. If the source claims ¬polyhedron@si , however, this maynot be sufficient to conclude ¬polyhedron as it may, for instance, be the case that the source is describing an unboundedpolyhedron. Hence, all that may be concluded from ¬polyhedron@si is ¬polyhedron∨¬convex∨¬bounded∨¬threeDimensional.Of course, it may be the case that both more liberal and more restrictive definitions of some property exist, dependingon the considered source. As such hybrid situations can be treated entirely analogously as the scenarios of liberalization andrestriction, we omit the details.4.3. ContinuityThe notion of similarity from Fig. 3 relates to the fact that the atoms involved are the result of a partially arbitrarydiscretization of a continuous domain. There is no well-defined, crisp boundary between situations that should be describedas overcast and situations that should be described as partiallyCloudy. As a result, what is called overcast by one source maybe called partiallyCloudy by another source. Due to their particular nature, such similarity graphs are symmetric. Formallywe may describe the underlying intuition as:a@si →(cid:7)W la,(cid:7)(cid:2)(cid:3)@siW laa →While we may not be able to exactly express the meaning of a@si using the atoms in A, we know at least that when a sourceasserts a@si , an atom similar to a will be the case. Conversely, when a holds, we may assume that b@si holds for some atomb similar to a. Note that the information described in a similarity graph, under this reading, is completely captured byimplications of the form (12)–(13), hence we may take the implications (14)–(15) to be trivial:W la= Xla= Sla,Y la= Z la= {a, ⊥}In particular, this means that unless a → a@si or a@si → a is assumed, no conclusions can be drawn from ¬a or ¬a@si , usingrespectively atoms from A@si and atoms from A.Example 9. The use of the atom partiallyCloudy may arise in conflict because the exact boundary between overcast situationsand partiallyCloudy situations may be slightly different according to different sources, as does the exact boundary betweenopenSky situations and partiallyCloudy situations. This situation is symmetric in that statements we believe to hold mayassume a boundary which is more liberal or more restrictive than the boundary assumed by a given source, i.e.:W 1partiallyCloudy= X 1partiallyCloudy= {openSky, overcast, partiallyCloudy}Moreover, from ¬partiallyCloudy@si no conclusions can be formulated in terms of the atoms in A. The reason is that when¬partiallyCloudy@siis claimed by a source, it may assume a more restrictive definition of the atom partiallyCloudy, and itmay still be the case that partiallyCloudy holds in our standard understanding of this term. Thus we obtain:Y 1partiallyCloudy= Z 1partiallyCloudy= {partiallyCloudy, ⊥}1828S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18554.4. AmbiguityFig. 4. Similarity graph for atoms related to school types.Fig. 4 illustrates a third possible reading of similarity graphs. Edges in this graph correspond to atom-pairs that aresometimes confused. Whereas the readings discussed in Sections 4.1 and 4.3 relate to the issue of vagueness, the similaritygraph from Fig. 4 is centered around the ambiguity of the term publicSchool. While there is no straightforward possibilityto be flexible about the meaning of a public school in either the UK or the USA meaning, confusion is caused by the factthat we do not know with absolute certainty that all sources conform to the requirement to adopt the UK interpretation. Asimilarity graph should then be understood as follows:(cid:7)(cid:7)a@si ≡ b,a ≡ b@si(30)b∈W laa∈W lbThe formula on the left expresses that when a source asserts a@si , this either means a or some atom with which a mayhave been confused. Conversely, the formula on the right expresses that the standard understanding of a corresponds toa@si or to an atom b@si such that sources may confuse b with a. It is not hard to see that (30) is equivalent to the followingimplications:a@si →¬a@si →(cid:7)(cid:5)b(cid:7)(cid:5)(cid:6)(cid:4)(cid:4) b ∈ W l,(cid:4)(cid:4) b ∈ W l¬ba(cid:6),a(cid:7)(cid:5)a →¬a →b@si(cid:7)(cid:5)(cid:6)(cid:4)(cid:4) a ∈ W lb(cid:4)(cid:4) a ∈ W l¬b@si(cid:6)bWe obtain:Xla= Z la=(cid:5)b(cid:4)(cid:4) a ∈ Slb(cid:6),Y la= W la= SlaExample 10. While we can be confident that statements we believe to be true are based on a usage of the term publicSchoolin its UK meaning, we need to consider the possibility that some source has assumed the USA meaning. Moreover, thisconfusion remains regardless of whether the atom publicSchool is used in a positive or in a negative literal:W 1publicSchool= Y 1publicSchool= {publicSchool, stateSchool}X 1publicSchool= Z 1publicSchool= {publicSchool, privateSchool}5. Merging operators and interpretation of the weightsThe methodology that was outlined above leaves us with a list of propositional knowledge bases K @s1, a setof integrity constraints C , and a list of weighted knowledge bases Ms1 , . . . , Msn , defined by (16), that express flexible con-straints on how atoms may be understood by the different sources. All these knowledge bases are built from different, A in the case of C , and A@si ∪ A in the case of Msi . Given this point of de-sets of atoms: A@siparture, we are now interested in finding a single, consistent knowledge base K which encodes the combined beliefs ofsources s1, . . . , sn to the best extent possible, such that all models of K satisfy the integrity constraints, i.e. (cid:2)K (cid:3) ⊆ (cid:2)C(cid:3). Wewrite K = (cid:3)(K1, . . . , Kn; C; Ms1 , . . . , Msn ) to denote the result of applying a specific merging operator (cid:3). When the setsMs1 , . . . , Msn and C are clear from the context, we will also write this as (cid:3)(K 1, . . . , Kn). The exact behavior of the operator(cid:3) primarily depends on the following two factors:in the case of K @si, . . . , K @sn1ni1. The weights λ(l,si ,a) in the weighted knowledge bases Msi may be interpreted as necessities, priorities, or as penalties,among others. They may be totally ordered or partially ordered, and may either depend on all of l, si and a, only on land a, only on l and si , or only on l. In each case, the nature of the knowledge bases Msi changes, and so should theresult K .2. There is a trade-off between having a more informative result and having a more cautious result. By appropriatelytuning this trade-off, the result may be configured to match the needs of a particular application. Another solution isS. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551829to combine both informative and cautious results, by representing the result as a weighted knowledge base, giving themost cautious results the highest certainty or priority.In this section, we analyze how exactly these two factors may influence the result K . First, we illustrate some of thepossibilities in the following example.Example 11. Consider again the weather example, but assume that the language contains 5 atoms: os, pc1, pc2, pc3 andoc, where pc1 intuitively corresponds to just a sky which is mostly open with the exception of a few clouds, pc2 to abouthalf-open and half-cloudy, and pc3 to a sky which is mostly cloudy. Now consider the following three knowledge bases:K1 = {os},K2 = {os},K3 = {oc}together with integrity constraints expressing that os, pc1, pc2, pc3 and oc are JEPD properties. Then one may wonder whatwould intuitively be the most desirable result, assuming as before that all sources are well-reputed. We may consider thatsince the sources make claims which are completely opposite, we cannot draw any reliable conclusions and should thereforedefine the result as{os ∨ pc1∨ pc2∨ pc3∨ oc}A different point of view is that the majority of the sources agrees on os and this should therefore be the result:{os}although we may also prefer the following, more cautious alternatives:{os ∨ pc1},{os ∨ pc1∨ pc2}Another point of view is to consider that none of the sources would be completely wrong, and that the result shouldtherefore be in (or close to) the middle of os and oc, e.g. one of the following alternatives:{pc2},{pc1∨ pc2∨ pc3}Finally, because os is asserted by two out of three sources, we may also consider that the result should be between os andoc, but closer to os, e.g.:{pc1},{os ∨ pc1∨ pc2},{os ∨ pc1∨ pc2∨ pc3}∨ pc2The type of flexibility illustrated by the previous example cannot be achieved using standard approaches, which are basedon the Hamming distance. Indeed, the only conclusions that can reasonably be motivated in terms of the Hamming distance∨ oc}, {os}, and {os ∨ oc}. In this section, we study a number of different merging operators, basedare {os ∨ pc1∨ pc3(cid:13)introduced in (16) and (17). Each of these merging operators naturally results from interpretingon the sets Msi and Msi(cid:13)the weights in Msi or Min a particular way. Moreover, in each case, we characterize the behavior of the merging operatorsiat the semantic level, establishing close links with the existing frameworks for merging propositional knowledge bases thatwere recalled in Section 2. In some cases, our merging operators are a special case of distance-based or morphologicalmerging operators, albeit w.r.t. a completely novel type of distance which is based on the idea of interpreting atoms in aflexible way. In other cases, merging operators can be described in natural extensions of distance-based or conflict-basedmerging operators. It is important to note here, however, that the aim of our paper is not to introduce a new familyof merging operators per se, but rather to advocate a different way of measuring the similarity (or distance) betweeninterpretations.In the discussion that follows, we specifically consider the task of merging the beliefs held by different sources, ratherthan merging incompatible goals or preferences [33,34]. As such, the intuition behind each merging operator will be tofind the interpretations that are most likely to be models of the real world, given the assertions of the different sources(rather than looking for a trade-off between conflicting objectives). By interpreting this notion of likelihood in different ways(ranging from purely qualitative to purely quantitative), and by assuming different levels of caution, it will become clearthat a variety of behaviors can be obtained in a natural way, including those that are illustrated in Example 11.5.1. Basic structure of the merging operatorsBefore going into the details of particular merging operators, we discuss the underlying idea which is common to eachof the approaches that are introduced below. For the ease of presentation, we define the weighted knowledge bases P andPas follows:(cid:13)1830S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855(cid:16)P =∪Msi(cid:16)(cid:5)(α, 1)(cid:4)(cid:4) α ∈ K @sii(cid:6)(cid:5)∪(cid:6)(cid:4)(cid:4) c ∈ C(c, 1)i(cid:16)(cid:13) =PM(cid:13)si∪i(cid:16)(cid:5)ii(α, 1)(cid:4)(cid:4) α ∈ K @sii(cid:6)(cid:5)∪(cid:6)(cid:4)(cid:4) c ∈ C(c, 1)(31)(32)iare defined as in (16) and (17). Let us furthermore write Pwhere we reinterpret the propositional knowledge bases K @siand C as weighted knowledge bases in which all weights(cid:13)are equal to 1, and Msi and Mfor the sets ofsi(cid:13) ∗(unweighted) formulas that appear in P and in P. Throughoutthis section, we implicitly assume that λ(l,si ,a) < 1 for all l ∈ {0, . . . , k}, i ∈ {1, . . . , n} and a ∈ A. The idea is that the formulasin K @siand C are unconditionally true, hence they receive a maximal certainty level, while the formulas in Msi and Mareimore or less plausible assumptions that may be violated, and thus receive a certainty level that is strictly smaller than 1.= λl for every source si andMoreover, unless otherwise stated, we assume that λ(l,si ,a) = λWatom a, which implies among others that the weights are totally ordered, and in particular that we may assume that theweights λ(l,si ,a) = λl correspond to numbers in [0, 1[. As a notational convenience, let us furthermore introduce the followingabbreviations:(cid:13) ∗∗ = {α | ∃λ . (α, λ) ∈ P } and similar for Prespectively, i.e. P= λ X= λ Z= λYand P(l,si ,a)(l,si ,a)(l,si ,a)(l,si ,a)(cid:13)si∗(cid:13)α W(l,si ,a)α X(l,si ,a)αY(l,si ,a)= a@si →(cid:7)(cid:5)= a →= ¬a@si →= ¬a →α Z(l,si ,a)α(l,si ,a) = α W(l,si ,a)(cid:7)(cid:5)x@si(cid:7)(cid:5)aa(cid:6)(cid:4)(cid:4) w ∈ W lw(cid:4)(cid:6)(cid:4) x ∈ Xl(cid:4)(cid:4) y ∈ Y la(cid:4)(cid:6)(cid:4) z ∈ Z l∧ αY¬ ya¬z@si(l,si ,a)(l,si ,a)(cid:6)∧ α X(cid:7)(cid:5)∧ α Z(l,si ,a)(l,si ,a) is the formula which appears with weight λ×(l,si ,a) in Msi , and α(l,si ,a) is the formula which appears with weightEach of the merging operators (cid:3) that we will consider proceeds by selecting particular consistent subsets of P. Let Pref (P ) and Pref (P∗(cid:13) ∗or P,(cid:13)) be thethat are selected according to some criterion. A first idea might then be to define the correspondingwhich contain at least all the formulas with weight 1, i.e. the formulas from C and K @sisubsets Pand Pmerging operators (cid:3) and (cid:3)(cid:13)as follows:(cid:13) ∗∗i(cid:4)(cid:4)(cid:3)(K1, . . . , Kn)(cid:13)(cid:3)(K1, . . . , Kn)(cid:5)(cid:7)=(cid:7)(cid:5)=Pref (P )(cid:2)PrefP(cid:3)(cid:13)where the sets of formulas in Pref (P ) and Pref (P(cid:13)) are treated as conjunctions of formulas.One possible drawback of this method is that the results (cid:3)(K 1, . . . , Kn) and (cid:3)(cid:13)(K1, . . . , Kn) still refer to atoms from A@si .Recall that these atoms were introduced mainly for technical reasons, and their exact meaning is not known. Thus it seemsreasonable to require that no occurrences of these atoms remain after merging (although they may provide insight to theuser regarding the source of conflicts). To this end, we employ the notion of variable forgetting [35,24], defined for a set ofpropositional formulas Φ, an atom x and a set of atoms X as:i.e. α×λ(l,si ,a) in M(cid:13)si.forgetVar(Φ, ∅) = ∅(cid:2)(cid:3)forgetVar(cid:2)forgetVarΦ, {x}Φ, {x} ∪ X(cid:3)= Φ[x := (cid:19)] ∨ Φ[x := ⊥](cid:2)= forgetVarforgetVar(Φ, x), X(cid:3)where Φ[x := φ] for an atom x and a formula φ denotes the set of formulas that is obtained from Φ by replacing everyoccurrence of x by φ; sets of formulas are interpreted as conjunctions. The propositional knowledge base forgetVar(Φ, X) canbe seen as a projection of Φ which does not contain any occurrence of atoms from X and moreover, if ψ does not containoccurrences of atoms from X , we have Φ |(cid:7) ψ iff forgetVar(Φ, X) |(cid:7) φ. Thus, to merge the knowledge bases K 1, . . . , Kn wemay take (cid:3)(K1, . . . , Kn) or (cid:3)(cid:13)(K1, . . . , Kn) and forget the variables in A@s1 ∪ · · · ∪ A@sn :(cid:3) f (K1, . . . , Kn) = forgetVar(cid:13)f (K1, . . . , Kn) = forgetVar(cid:3)(cid:2)(cid:2)(cid:3)(K1, . . . , Kn), A@s1 ∪ · · · ∪ A@sn(K1, . . . , Kn), A@s1 ∪ · · · ∪ A@sn(cid:3)(cid:13)(cid:3)(cid:3)While variable forgetting is computationally expensive in general, in certain cases efficient syntactic procedures can beobtained. In Appendix B, an example of such a procedure is provided.In Sections 5.2–5.6 merging operators are introduced that result from interpreting the certainty weights in different ways.In Section 5.2, certainty weights are interpreted in a purely ordinal way, as possibilistic certainty weights. In Sections 5.3S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551831Fig. 5. Similarity graph for atoms related to Toulouse.and 5.4 this approach is refined by using the concept of preferred subtheories, respectively defined w.r.t. subset-inclusionand w.r.t. cardinalities. Subsequently, in Section 5.5 a purely qualitative approach is presented, which uses symbolic certaintyweights that are taken from an arbitrary partially ordered set. Finally, Section 5.6 discusses a quantitative approach witha probabilistic flavor based on penalty logic. Each of these five sections first introduces merging operators at the syntacticlevel, and subsequently provides a semantic characterization which clarifies their relationship to existing approaches forinformation merging. Moreover, the five sections can be read independently from each other.5.2. Possibilistic certainty weights5.2.1. Merging operatorsIn this section, we interpret the weighted knowledge bases Msi as possibilistic knowledge bases. In this case, the weightsreflect lower bounds on a necessity measure. Following the standard treatment of inconsistencies in the possibilistic setting,4we obtain the following merging operators(cid:3)poss(K1, . . . , Kn) = forgetVar(K1, . . . , Kn) = forgetVar(cid:13)(cid:3)possP inc(P ), A@s1 ∪ · · · ∪ A@sn(cid:2)(cid:13)inc(P (cid:13)), A@s1 ∪ · · · ∪ A@snP(cid:2)(cid:3)(cid:3)(33)(34)where P inc(P )words, we take Pref (P ) = {P inc(P )} and Pref (P(cid:3)poss(K1, . . . , Kn) ≡ (cid:3)poss(cid:13)is the set of formulas from P whose weight is strictly above the inconsistency level of P .(cid:13)) = {P(cid:13)inc(P (cid:13))}. As P inc(P ) is equivalent to PIn other(cid:13)inc(P (cid:13)), we immediately find that(K1, . . . , Kn), hence we will only consider (33) henceforth.Example 12. Consider two sources, where one source claims that Peter is married, lives in Toulouse, and works in Mon-tauban (a city about 50 km from Toulouse). A second source also claims that Peter is married, and that he works inSaint-Alban. However, there are at least four places called Saint-Alban5: in the regions Ain, Côtes-d’Armor, Haute-Garonne(in France), and in Québec (in Canada). We assume that the source does not want to commit itself to one of the four places.We may then encode the two knowledge bases as follows:(cid:6)(cid:5)mar(p), li(p, t), wo(p, m)(cid:6)(cid:5)mar(p), wo(p, saa) ∨ wo(p, sacda) ∨ wo(p, sahg) ∨ wo(p, saq)K1 =K2 =where e.g. li(p, t) means that Peter lives in Toulouse and wo(p, m) means that Peter works in Montauban. The integrityconstraints C specify the JEPD nature of the propositions related to marriage from Fig. 2, the fact that a person can onlywork in one place, and can only live in one place (e.g. li(p, t) → ¬li(p, m)), and that Toulouse and Saint-Alban (Haute-Garonne) are both contained in the Urban Community of Greater Toulouse (e.g. li(p, t) → li(p, gt)). The families W la, Xla,Y la and Z la are defined according to the similarity graph from Fig. 2 for the atoms a related to marriage, and according tothe similarity graph from Fig. 5 for the remaining atoms. In both cases, the similarity graphs are interpreted in terms ofliberalization, and they are understood in a transitive way.To obtain the result of merging K1 and K2 using (cid:3)poss, we may use Proposition 10:(cid:6)(cid:5)mar(p) ∨ civ(p), li(p, t) ∨ li(p, gt), wo(p, m)(cid:6)(cid:5)mar(p) ∨ civ(p) ∨ wid(p) ∨ div(p) ∨ coh(p), li(p, t) ∨ wo(p, t) ∨ li(p, gt), wo(p, m) ∨ li(p, m)KK(1)1(2)1==4 A brief introduction to possibilistic logic is provided in Appendix A.5 http://en.wikipedia.org/wiki/Saint-Alban, accessed May 31, 2010.1832S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855KK(1)2(2)2==(cid:5)(cid:5)(cid:6)mar(p) ∨ civ(p), wo(p, saa) ∨ wo(p, sacda) ∨ wo(p, sahg) ∨ wo(p, gt) ∨ wo(p, saq)mar(p) ∨ civ(p) ∨ wid(p) ∨ div(p) ∨ coh(p), wo(p, saa) ∨ li(p, saa) ∨ wo(p, sacda) ∨ li(p, sacda)(cid:6)∨ wo(p, sahg) ∨ li(p, sahg) ∨ wo(p, gt) ∨ wo(p, saq) ∨ li(p, saq)where we write K( j)iwork in two disjoint places. On the other hand, KP λ jias an abbreviation of K(2)1mar(p) ∨ civ(p) ∨ wid(p) ∨ div(p) ∨ coh(p),(1)1(2)∪ C is consistent, hence (cid:3)poss(K1, K2) = K1(cid:2)wo(p, t) ∧ li(p, m)∪ C is inconsistent, since Peter cannot, according to C ,∪ C , where(cid:3)(cid:6)(cid:3)li(p, sahg) ∧ wo(p, m). Clearly K(2)∪ K2∪ K∪ K(2)2(1)2∨(cid:2)(cid:3)poss(K1, K2) ≡ C ∪(cid:5)This solution reveals two possible hypotheses regarding the origin of the conflict between K 1 and K2. The first hypothesis isthat the claim of the first source that Peter lives in Toulouse, should be interpreted as Peter living in Greater Toulouse, andthat the second source has confused the fact that Peter lives in Saint-Alban with the statement that Peter works in Saint-Alban; this leads to li(p, sahg) ∧ wo(p, m). The second hypothesis is that the first source has swapped the places where Peterlives and works, i.e. in fact Peter works in Toulouse and lives in Montauban. In addition, the second source has confusedSaint-Alban with Greater Toulouse. The second hypothesis leads to wo(p, t) ∧ li(p, m).Note that after merging, in the example, ma(p) is also understood in a liberal sense, although this is not necessary forsolving the inconsistency. This can be seen as a shortcoming of the possibilistic approach, which is overly cautious here.Intuitively, this issue can be addressed by first determining which atoms participate in the conflict, and only weakeningthese atoms. Several of the refined merging operators that are proposed below are based on this intuition.5.2.2. Semantic characterizationSemantically, (cid:3)poss can be seen as a particular case of morpho-logical merging (cf. Section 2.3), using a structuringelement that is defined in terms of the similarity relation σ defined in (20). In particular, we define the structuring elementB(W l, Xl,Y l, Z l) asB(W l, Xl,Y l, Z l)(I) =J ∈ 2 A(cid:5)(cid:4)(cid:6)(cid:4) σ(Y l,W l)(I, J ) ∧ σ( Z l, Xl)( J , I)Then we have the following characterization.Proposition 2. Assume that λ(l,si ,a) = λl for every source si , atom a and l ∈ {0, . . . , k}, and assume λk < 1. Moreover, assume that P λkis consistent, and let r be the smallest value from {0, . . . , k} such that P λr is consistent, i.e. inc(P ) = λr−1 < λk. It holds that(cid:3)poss(K1, . . . , Kn; C; Ms1 , . . . , Msn ) ≡ (cid:3)morph(K1, . . . , Kn; C; B(W r , X r ,Y r , Z r ))Note however that this linkage can only be established once the structuring element of the morpho-logical approachis no longer defined by means of the Hamming distance, as usual, but in terms of the similarity relation underlying ourapproach.5.3. Inclusion-based preferred subtheories5.3.1. Merging operatorsAs illustrated by Example 12, the standard possibilistic approach leads to results that may be deemed too cautious. Inparticular, the conflict about where Peter lives and works should, intuitively, not influence our belief that Peter is married,a belief which is shared by both sources. This behavior is due to the drowning effect in possibilistic logic, i.e. the fact thatevery statement whose certainty is not greater than the inconsistency level is ignored, regardless of whether it participatesin any conflict. In Example 12, for instance, mar(p) has a lower priority than mar(p) ∨ civ(p) ∨ wid(p) ∨ div(p) ∨ coh(p);the former expression is below the inconsistency whereas the latter is above, which is why the disjunction is entailed bythe result but mar(p) is not. A refined merging strategy, in which this drowning effect no longer occurs, can be obtained byresorting to methods based on maximal consistent subsets. A standard approach was proposed by Brewka [36] within thecontext of default reasoning. The idea is to use priorities attached to formulas to designate particular maximal consistentsubsets of formulas as preferred. In particular, let K be a prioritized knowledge base, where all priorities are taken fromthe set {λ0, . . . , λk} with λ0 < · · · < λk. As for possibilistic knowledge bases, we write Kλ to denote the set of formulas inK whose priority is at least λ. A consistent set of formulas F = Fk ∪ · · · ∪ F 0 is then called an (inclusion-based) preferredsubtheory of K , with Fl a subset of the formulas that appear in K with priority λl (l ∈ {0, . . . , k}), iff Fk ∪ · · · ∪ Fl is a maximal(cid:13) ⊃ Fk ∪ · · · ∪ Fl. Thisconsistent subset of Kλl for all l ∈ {0, . . . , k}, i.e. there is no consistent subset Fboils down to selecting as many formulas with priority λk as possible (without getting inconsistency), subsequently addingas many formulas with priority λk−1 as possible, etc. Given a prioritized knowledge base K , we write Pref ⊆(K ) for the setof all inclusion-based preferred subtheories of K . A standard approach to deal with inconsistency in prioritized knowledgebases is to only consider formulas that are entailed by every preferred subtheory. Considering again the weighted knowledgebase P defined in (31), this leads to the following merging operator:of Kλl such that F(cid:13)(cid:3)prior⊆ (K1, . . . , Kn) = forgetVar(cid:9)(cid:7)Pref ⊆(P ), A@s1 ∪ · · · ∪ A@sn(cid:10)S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551833By considering Pknowledge base, whenever Iparticular that(cid:13)instead of P , the merging operator (cid:3)prior(cid:13)⊆ is obtained. Note that when we interpret P as a possibilisticis a model of a preferred subtheory of P we also have that I ∈ (cid:2)P inc(P )(cid:3). This means in(cid:3)prior⊆ (K1, . . . , Kn) |(cid:7) (cid:3)poss(K1, . . . , Kn)⊆ (K1, . . . , Kn) |(cid:7) (cid:3)poss(K1, . . . , Kn)(cid:3)prior(cid:13)(35)(36)i.e. the use of preferred subtheories is indeed a refinement of the possibilistic treatment of inconsistency.Example 13. Let us go back to the scenario of Example 12, and let us consider the weighted knowledge base Pis not equivalent to considering P , in contrast to the possibilistic setting. In general, using Presults, whereas using P may lead to more informative results. Since Psubtheory should in each case contain all formulas that appear in Pmaximal consistent subsets of P, whichmay lead to more cautiousis consistent, we know that every preferredwith weight at least λ2. There are two different, leading to the following two preferred subtheories(cid:13)λ2(cid:13)(cid:13)(cid:13)λ1(cid:13)(cid:5)(cid:5)B1 = PB2 = P(cid:13) ∗ \(cid:13) ∗ \We findα(0,s1,li(p,t)), α(0,s2,wo(p,sahg )), α(1,s2,wo(p,sahg ))α(0,s1,wo(p,m)), α(1,s1,wo(p,m)), α(0,s1,li(p,t)), α(1,s1,li(p,t)), α(0,s2,wo(p,sahg ))(cid:6)(cid:6)(cid:5)(cid:5)(cid:5)(cid:5)(cid:6)mar(p), li(p, t) ∨ li(p, gt), wo(p, m)(cid:6)mar(p), li(p, t) ∨ li(p, gt) ∨ wo(p, t), wo(p, m) ∨ li(p, m)(cid:6)mar(p), wo(p, saa) ∨ wo(p, sacda) ∨ wo(p, sahg) ∨ wo(p, gt) ∨ li(p, sahg) ∨ wo(p, saq)(cid:6)mar(p), wo(p, saa) ∨ wo(p, sacda) ∨ wo(p, sahg) ∨ wo(p, gt) ∨ wo(p, saq)====K B11K B21K B12K B22which, using Proposition 10 leads to(cid:3)prior(cid:13)⊆ (K1, K2) ≡ C ∪≡ C ∪(cid:5)(cid:2)(cid:3)(cid:2)(cid:3)(cid:6)(cid:5)∨K B11mar(p),∧ K B12(cid:3)(cid:2)li(p, sahg) ∧ wo(p, m)∧ K B22K B21(cid:2)wo(p, t) ∧ li(p, m)(cid:3)(cid:6)∨Hence, as desired, the belief that Peter is married is kept, while obtaining the same conclusions about where Peter mightlive or work as in the possibilistic setting (i.e. Example 12).5.3.2. Semantic characterizationSemantically, the merging operators (cid:3)prior⊆ and (cid:3)prior(cid:13)⊆ are similar in spirit to the idea of conflict based merging. Inthe following, we reveal the exact relationship between both approaches. At a given tolerance level l we may define thefollowing partial conflict sets for all interpretations I and JW ldiff adiff bdiff cdiff dW l (I, J ) = J \ (cid:14)I(cid:15)Xl (I, J ) = I \ (cid:14) J (cid:15)XlY l \ JY l (I, J ) = [I]Z l \ IZ l (I, J ) = [ J ](37)(38)(39)(40)Xl (I, J ) ∪ diff cW l (I, J ) ∪Note in particular that for l = 0, we recover the standard notion of conflict set, as defined in (6), i.e. diff (I, J ) = diff adiff bW l (I, J ) if it is in J and it is not similar to an atomin I (where similarity is defined w.r.t. the relation W l). The intuition behind the other partial conflict sets is analogous. Thehigher the value of l, the more pairs of atoms are considered similar, and the fewer atoms remain in the partial conflictsets, i.e. for l > 0 we haveZ l (I, J ). An atom p will be contained in diff aY l (I, J ) ∪ diff ddiff cdiff aW l (I, J ) ⊆ diff aY l (I, J ) ⊆ diff cXl−1 (I, J )Z l−1 (I, J )Intuitively, for larger values of l, the sets (37)–(40) only contain the most important conflicts between I and J . This idea ofpriorities among conflicts will allow us to refine the relation (cid:2)EW l−1 (I, J ),Y l−1 (I, J ),Xl (I, J ) ⊆ diff bZ l (I, J ) ⊆ diff ddiff ddiff bconfl that was defined in Section 2.2.To gather all the information about the conflict at a given tolerance level l, two alternatives present themselves:1834S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855(I, J ) =(cid:17)diff adiff 1Sldiff 2SlW l (I, J ), diff bW l (I, J ) ∪ diff bXl (I, J ), diff cXl (I, J ) ∪ diff cY l (I, J ), diff d(cid:18)Z l (I, J )(I, J ) = diff aZ l (I, J )where we write Sl as a shorthand for (W l, Xl, Y l, Z l). Note that diff 1stays closer toSlthe standard approach of conflict-based merging. In particular, for l = 0, diff 2(I, J ) = diff (I, J ) with diff (I, J ) defined asSlin (6). In contrast to standard conflict-based merging, where the conflict between two interpretations is characterized usingone conflict set, here we have a different conflict set for each tolerance level. All available information about the conflictbetween two interpretations is thus described as a vector of conflict sets:is more informative, while diff 2SlY l (I, J ) ∪ diff d(cid:17)diff 1S (I, J ) =diff 1Sk(I, J ), . . . , diff 1S0(cid:18)(I, J )S . We use S as a shorthand for (Sk, . . . , S0). Analogously as for the standard conflict-based mergingand similar for diff 2scheme, we may then define the conflict between an interpretation I and a knowledge base K . We consider the followingtwo variants:diff 1diff 2S (I, K ) = minS (I, K ) = min(cid:2)(cid:5)(cid:2)(cid:5)diff 1diff 2S (I, J )S (I, J )(cid:4)(cid:4) J ∈ (cid:2)K (cid:3)(cid:4)(cid:4) J ∈ (cid:2)K (cid:3)(cid:6)(cid:6)(cid:2)⊆4, . . . , ⊆4, lex(cid:3), lex(⊆, . . . , ⊆)(cid:3)(cid:3)where ⊆4 = par(⊆, ⊆, ⊆, ⊆). Note the use of the lexicographic ordering here. Indeed, when comparing conflicts, it makessense to first look at the most important conflicts, i.e. those that only disappear when considering high values for thetolerance level l.Accordingly, we may define conflict vectors between an interpretation I and a list of knowledge bases K = (K 1, . . . , Kn):diff 1S (I, K) =(cid:5)(cid:14)c1, . . . , cn(cid:15)(cid:4)(cid:4) ∀i . ci ∈ diff 1S . The conflict vectors in diff 1(cid:6)S (I, K i)(cid:18)(cid:17)(cid:17)(cid:17)S (I, K) and diff 2and similar for diff 2between interpretations. To compare such conflict vectors, first let us define (cid:2)1(cid:17)(cid:17)(cid:18)(cid:13)0(cid:13)k, . . . ,1 , . . . , cc1(cid:3)(cid:2)⊆4, . . . , ⊆4∈ par(cid:18)(cid:17)(cid:17)(cid:13)0(cid:13)k1 , . . . , cc1∈ par(⊆, . . . , ⊆)1, . . . , c0ckn, . . . , c0ck, . . . ,n(cid:2)(cid:17)(cid:17)(cid:18)(cid:13)l(cid:13)l1, . . . , clcl,1, . . . , ciffcnn(cid:17)(cid:17)(cid:18)(cid:18)(cid:17)(cid:18)(cid:2)2ck1, . . . , c0n, . . . , c0ck, . . . ,nl(cid:18)(cid:3)(cid:17)(cid:18)(cid:2)(cid:17)(cid:13)l1, . . . , clcl,1, . . . , cciff(cid:13)0(cid:13)kn, . . . , ccn(cid:13)kn , . . . , c(cid:2)1l(cid:18)(cid:3), . . . ,(cid:17)c(cid:13)0n(cid:13)ln(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)11n(cid:17)S (I, K) are now vectors of vectors of conflict representationsl and (cid:2)2l asi in the first inequality are 4-tuples of sets of atoms, while the clwhere the clatoms. Thus, (cid:2)1at a given tolerance level l. We now have the following characterization.i in the second inequality are simply sets ofl compare conflict vectors, by considering the conflicts between interpretations and knowledge basesl and (cid:2)2Proposition 3. Let P and Pthat(cid:13)be defined as before and assume that λ(l,si ,a) = λl for every source si and atom a, with λk < 1. It holds(cid:3)prior⊆ (K1, . . . , Kn) ≡ (cid:3)confl2⊆ (K1, . . . , Kn) ≡ (cid:3)confl2(cid:3)prior(cid:13)(cid:2)(cid:2)with (cid:3)confl2 defined as in (8).(cid:2)K1, . . . , Kn; C; diff 1K1, . . . , Kn; C; diff 2S , lex(cid:2)1(cid:2)S , lex(cid:2)2k , . . . , (cid:2)1k , . . . , (cid:2)200(cid:3)(cid:3)(cid:3)(cid:3)(41)(42)This means that semantically, the use of preferred subsets in (cid:3)prior⊆ and (cid:3)prior(cid:13)⊆ is very close to the standard approachof conflict-based merging. The key difference is that the conflict between two interpretations is not represented as a singleset, but as a vector of (vectors of) sets, discriminating between conflicts that are more important than others, in the sensethat they are more difficult to explain in terms of flexible usage of atoms.5.4. Cardinality-based preferred subtheories5.4.1. Merging operatorsA further refinement can be obtained by looking only at consistent subsets of maximal cardinality. A consistent set offormulas F = Fk ∪ · · · ∪ F 0 is a cardinality-based preferred subtheory of K , with Fl a subset of the formulas that appear(cid:13)in K with priority λl (l ∈ {0, . . . , k}), iff for every consistent set of formulas Fl a subset of the∗ ∈ {0, . . . , k} such thatformulas that appear in K with priority λl, it holds that either ∀l . |Fl| = |F(cid:13)|Fl| = |Fl∗ |. We write Pref card(K ) for the set of all cardinality-based preferred subtheories of K .The corresponding merging operators are given by| or there exists some land |Fl∗ | > |F(cid:13)0, with F| for all l > l∪ · · · ∪ F(cid:13) = F(cid:13)k(cid:13)l(cid:13)l∗(cid:3)priorcard (K1, . . . , Kn) = forgetVar(cid:9)(cid:7)Pref card(P ), A@s1 ∪ · · · ∪ A@sn(cid:10)S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551835(43)Again we consider the variant using Pi.e.(cid:13)instead of P , which we write as (cid:3)prior(cid:13)card . Clearly, (cid:3)priorcard is a refinement of (cid:3)prior⊆ ,(cid:3)priorcard (K1, . . . , Kn) |(cid:7) (cid:3)prior⊆ (K1, . . . , Kn)The choice between (cid:3)poss, (cid:3)prior⊆ and (cid:3)priorcard depends, in practice, on how the weights can be interpreted. Evidently,the weaker the merging operator, the weaker the assumptions that need to be made on the meaning of the weights. Inparticular, in the possibilistic approach, weights may be interpreted in a purely qualitative way: formulas with a higherweight are assumed to be more plausible than formulas with a lower weight. The intuitive interpretation of the priorities,in the case of (cid:3)prior⊆ is in terms of order-of-magnitudes of probabilities [37,38], which can be formally studied usingSpohn’s ordinal conditional functions [39], or equivalently using quantitative possibility theory [40]. The fact that a formulaφ has a higher priority than a formula ψ then intuitively means that the probability that φ is true is an order-of-magnitudehigher than the probability that ψ is true. Under this interpretation, the preferred subtheories may be seen as those subsetsof formulas that most likely correspond to the formulas that are correct. The restriction to consistent subsets of maximalcardinality, when using (cid:3)priorcard , is motivated from the additional assumption that formulas with the same priority haveapproximately the same probability of being true, and an assumption of independence, i.e. the probability that one formulais true, is independent from the probability that other formulas with the same priority are true.Example 14. Continuing on Example 13, we find that the inclusion-preferred subtheory B 2 is not cardinality preferred, sinceB1 satisfies strictly more formulas from P(cid:6)with weight λ1. Thus we obtain(cid:5)(cid:5)(cid:13)(cid:13)(cid:3)card⊆ (K1, K2) ≡ C ∪K B11∧ K B12≡ C ∪(cid:6)mar(p), li(p, sahg), wo(p, m)which is more informative, and less cautious, than the result we found in Example 13.5.4.2. Semantic characterizationNext, we establish a semantic counterpart to (cid:3)priorcard and (cid:3)prior(cid:13)card , and show the connection between these operatorsand the distance based framework. First, note that two “distances” can naturally be defined between two interpretations, ateach tolerance level l:l (I, J ) =d1l (I, J ) =d2(cid:4)(cid:4) J \ (cid:14)I(cid:15)W l(cid:4)(cid:2)(cid:4)J \ (cid:14)I(cid:15)(cid:4)(cid:4) +(cid:3)(cid:4)(cid:4)I \ (cid:14) J (cid:15)Xl(cid:2)∪I \ (cid:14) J (cid:15)W l(cid:4)(cid:4) +(cid:3)(cid:4)(cid:4)[I]Y l \ J(cid:2)[I]∪Y l \ J(cid:4)(cid:4) +(cid:3)(cid:4)(cid:4)[ J ](cid:2)[ J ]∪Z l \ IZ l \ I(cid:4)(cid:4)Xl(cid:3)(cid:4)(cid:4)The notion of distance that is considered here is very weak, obeying neither the triangle inequality nor symmetry. Nonethe-less, we will refer to d1l as distances, to preserve the terminology of the distance-based framework. Clearly, in thespecific case where l = 0, we havel and d2l (I, J ) = 1d2while for l > 0, we find2l (I, J ) = dHam(I, J )d1l (I, J ) (cid:2) d1d1l (I, J ) (cid:2) d2d2l−1(I, J ),That is, for larger values of l, the distances d1interpretations, independent of a given tolerance level l, can be represented as a (k + 1)-dimensional vector:l−1(I, J )l and d2l only consider the most important conflicts. The distance between twod1(I, J ) =(cid:17)k (I, J ), . . . , d1d1(cid:18)0(I, J )The distance between an interpretation and a knowledge base K is then given byd1(I, K ) = min(cid:2)(cid:5)d1(I, J )(cid:4)(cid:4) J ∈ (cid:2)K (cid:3)(cid:6)(cid:3), lex((cid:2), . . . , (cid:2))(44)In particular, note that to compare distance vectors, we first look at the distances for higher tolerance levels l, as thesereveal the most important discrepancies between interpretations, using the distances at lower tolerance levels only as afurther refinement. The distance between an interpretation and a list of knowledge bases K = (K 1, . . . , Kn) is then given byd1(I, K) = d1(I, K1) + · · · + d1(I, Kn)The only difference with standard distance-based merging, when considering f =in (4), is that the additions in theright-hand side are vector additions instead of additions between real numbers. It turns out that d1(I, K) and d2(I, K)card . First, note that the closeness of interpretations to Kcorrespond to the notion of distance underlying (cid:3)priorcard and (cid:3)priorcan be compared by(cid:13)(cid:19)1836S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855I (cid:2)1 I(cid:13)iff(cid:2)d1(I, K), d1(cid:2)(cid:13)I, K(cid:3)(cid:3)∈ lex((cid:2), . . . , (cid:2))(45)In entirely the same way, we arrive at the relation (cid:2)2 by considering d2lsition.instead of d1l . We then have the following propo-Proposition 4. Let P and Pthat(cid:13)be defined as before and assume that λ(l,si ,a) = λl for every source si and atom a, with λk < 1. It holds(cid:3)priorcard (K1, . . . , Kn) ≡ (cid:3)dist(K1, . . . , Kn; C; (cid:2)1)card (K1, . . . , Kn) ≡ (cid:3)dist(K1, . . . , Kn; C; (cid:2)2)(cid:3)prior(cid:13)(46)(47)Note that for k = 0, we obtain a syntactic encoding of distance-based merging with the Hamming distance, for the special(but common) case where the sum is used as aggregation operator; existing syntactic encodings of Hamming-distance basedmerging can be found in [5] and [41].5.5. Partially ordered weights5.5.1. Merging operators×(l,si ,a)×(cid:2) λ×(l1,si ,a)The results in Propositions 2, 3 and 4 are based on the assumption that λ= λ(l,si ,a) = λl for every × ∈ {W , X, Y , Z },source si and atom a. Due to the assumption that l1 (cid:2) l2 implies λ(l2,si ,a) and λ(l1,si ,a) (cid:2) λ(l2,si ,a), this means inparticular that all priorities are totally ordered. In practice, however, this requirement is often too strong. Consider againthe weather forecast scenario from Example 11. It may be the case that some source s1 is known to be more reliable thananother source s2, in the sense that predictions from s1 are likely to be closer to the truth than predictions from s2. In sucha situation, however, it is often not possible to exactly quantify the difference in reliability between s1 and s2. For example,we may be in a case where we can reasonably assume that λ(1,s1,os) > λ(1,s2,os), without having sufficient information todecide whether λ(1,s1,os) > λ(2,s2,os), λ(1,s1,os) = λ(2,s2,os) or λ(1,s1,os) < λ(2,s2,os). Moreover, even the assumption that, for afixed source s, λ(1,s,os) = λ(1,s,oc) may be considered too strict. It may, for instance, be the case that os is less likely to beaccurate than oc (e.g. because the sources prefer an optimistic attitude when available evidence is inconclusive). In general,we will typically not be able to exactly quantify the “amount of stretching” that is needed to go from one atom to another,and as a consequence, insisting that λ(l,s,a) = λ(l,s,b) for a (cid:17)= b may be considered too imprudent.We now show how the merging operators that have been proposed may be adapted to cope with partially orderedcertainty weights. The possibilistic merging operators may still be used, provided that we extend the notion of λ-cut topartially ordered certainty weights. Several such extensions have been proposed in [42], based on the idea of selectingparticular maximal consistent subsets. In particular if K 1 and K2 are two subsets of a possibilistic knowledge base K withpartially ordered weights, we consider the following relation:K1 (cid:4) K2iff ∀(α1, λ1) /∈ K1 . ∃(α2, λ2) /∈ K2 . λ1 (cid:2) λ2Let Pref (cid:2)(K ) be the corresponding preferred subtheories, i.e.Pref (cid:2)(K ) =(cid:5)(cid:4)(cid:2)(cid:4) B ∈ min∗BCons(K ), (cid:4)(cid:3)(cid:6)where we write Cons(K ) for the consistent subsets of K , and Bmerging operator:(cid:3)poss(K1, . . . , Kn) = forgetVarPref (cid:2)(P ), A@s1 ∪ · · · ∪ A@sn(cid:9)(cid:7)∗ = {α | (α, λ) ∈ K }. We may then consider the following(cid:10)and the variant (cid:3)poss(cid:3)poss and (cid:3)poss(cid:13)coincide with (33).(cid:13)which is based on P(cid:13). It is easy to see that when λ×(l,si ,a)= λ(l,si ,a) = λl, we have indeed that bothExample 15. When going back to the weather forecast of Example 11, we may notice that (cid:3)poss, (cid:3)prior⊆ and (cid:3)priorcard}. While the use of inclusion- and cardinality-based preferred subtheories refinesall lead to the same conclusion, viz. {pc2the possibilistic approach, by avoiding the drowning effect, these strategies are essentially based on the same intuition ofpriority. This intuition dictates that pc2 is a more plausible conclusion than e.g. pc1 as pc1 is intuitively further away fromoc than pc2 is away from either os or oc. In other words, what is maximized is the minimal similarity between models ofthe resulting base and any given knowledge base K 1. In practice, however, we may be less confident in where exactly is themiddle between os and oc. Assume that the weights are ordered as follows:λ(l,s,a) (cid:2) λ(l(cid:13),s(cid:13),a(cid:13))with θ = 1. Then Pref (cid:2)(P(cid:3)(cid:2)a = a(cid:13) ∧ l (cid:2) l(cid:13)iff(cid:13)) contains three subsets:∨(cid:2)l (cid:2) l(cid:3)(cid:13) − θ(48)S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551837Bpc1Bpc2Bpc3= P= P= P(cid:13) ∗ \ {α(0,s1,os), α(0,s2,os), α(0,s3,oc), α(1,s3,oc), α(2,s3,oc)}(cid:13) ∗ \ {α(0,s1,os), α(1,s1,os), α(0,s2,os), α(1,s2,os), α(0,s3,oc), α(1,s3,oc)}(cid:13) ∗ \ {α(0,s1,os), α(1,s1,os), α(2,s1,os), α(0,s2,os), α(1,s2,os), α(2,s2,os), α(0,s3,oc)}which leads to(cid:3)poss(K1, K2, K3) ≡ C ∪ {pc1∨ pc2∨ pc3}In the same way, choosing θ = 2, we obtain the trivial conclusion(cid:3)poss(K1, K2, K3) ≡ C ∪ {os ∨ pc1∨ pc2∨ pc3∨ oc}Finally, note that by encoding information about the relative reliability of different sources, results may be obtained that arenot centered around pc2.The idea of inclusion-based preferred subtheories of a prioritized knowledge base, in the case where priorities are par-tially ordered, was already proposed in [36]. The basic idea is to consider all possible linearizations κ . Specifically, let alinearization κ be any mapping from Λ to [0, 1] satisfying λ1 (cid:2) λ2 ⇒ κ(λ1) (cid:2) κ(λ2), and let us write Lin(Λ, (cid:2)) to denotethe set of all such linearizations. Given a linearization κ , the linearized version κ(K ) of the prioritized knowledge base K isobtained by replacing all weights λ by their value in [0, 1]:κ(K ) =(cid:5)(cid:2)α, κ(λ)(cid:3) (cid:4)(cid:4) (α, λ) ∈ K(cid:6)The preferred subtheories of K are then simply the maximal consistent subsets that are preferred for κ(K ), for somelinearization κ . Thus we arrive at the following merging operators:(cid:3)prior⊆ (K1, . . . , Kn) = forgetVar(cid:3)priorcard (K1, . . . , Kn) = forgetVar(cid:20)(cid:21)(cid:7)(cid:7)(cid:2)(cid:3)κ(P )Pref ⊆, A@s1 ∪ · · · ∪ A@snκ(cid:20)(cid:7)(cid:7)κ(cid:2)(cid:3)κ(P )Pref card, A@s1 ∪ · · · ∪ A@sn(cid:21)as well as the variants (cid:3)priordefinitions coincide with (35), (43), (35) and (43) respectively.(cid:13)card which are based on P(cid:13)⊆ and (cid:3)prior(cid:13). It is trivial to see that when λ×(l,si ,a)= λ(l,si ,a) = λl, these5.5.2. Semantic characterizationThus, in the special case where all weights are totally ordered, the definitions of the operators we have presented here tocope with partially ordered weights coincide with those that were presented in the previous sections. At the other extreme,when all weights λ(li ,si ,ai ) and λ(l j ,s j ,a j ) are incomparable unless si = s j and ai = a j , it turns out that (cid:3)prior⊆ , (cid:3)priorcard and(cid:3)poss, as well as (cid:3)prior(cid:13)card and (cid:3)poss(cid:13)⊆ , (cid:3)priorcoincide.(cid:13)Proposition 5. Let P and P(cid:13)be defined as before and assume that λ×i(li ,si ,ai )(cid:2) λ× j(l j ,s j ,a j ) iff li (cid:2) l j , si = s j , ai = a j and ×i = × j . It holdsthat(cid:2)(cid:2)(cid:3)(cid:3)(cid:2)1S , par(cid:3)confl2k , . . . , (cid:2)1K1, . . . , Kn; C; diff 1≡ (cid:3)poss(K1, . . . , Kn)≡ (cid:3)prior⊆ (K1, . . . , Kn)≡ (cid:3)priorcard (K1, . . . , Kn)Furthermore, when λ(li ,si ,ai ) (cid:2) λ(l j ,s j ,a j ) iff li (cid:2) l j , si = s j and ai = a j , it holds that(cid:2)(cid:3)(cid:3)(cid:2)0(cid:3)confl2K1, . . . , Kn; C; diff 2S , par(cid:2)2k , . . . , (cid:2)20(cid:13)≡ (cid:3)poss≡ (cid:3)prior≡ (cid:3)prior(K1, . . . , Kn)(cid:13)⊆ (K1, . . . , Kn)(cid:13)card (K1, . . . , Kn)(49)(50)(51)(52)(53)(54)The fact that merging operators correspond to the Pareto extensions par((cid:2)10), rather thanthe lexicographic extensions as in Proposition 3 confirms our intuition that by being more cautious in defining the orderingon Λ, a more tolerant merging operator is obtained which provides more cautious results. In practice, useful mergingoperators may be somewhere in between, adopting a balance between cautiousness and informativity.0) and par((cid:2)2k , . . . , (cid:2)1k , . . . , (cid:2)21838S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855As a general remark, let us also mention that when the weights are maximally incomparable, as in Proposition 5, thedifferent approaches recover the intersection of the maximal consistent subsets. In this way, these approaches implementthe idea that was suggested after Example 12, to apply the possibilistic approach, but only looking at those formulas thatare not involved in any conflict.5.6. Penalties5.6.1. Merging operatorsThe treatment of partially ordered weights in the previous section deals with situations where less information is avail-able than is required by the merging operators from Sections 5.2–5.4. In this section, we show how penalty logic, conversely,allows to handle the case where precise information is available about the certainty of the statements in Msi or M. To this×(l,s,a), λ(l,s,a) < +∞. The weightedend, we assume that the weights λthen correspond to theories in penalty logic6 [27,28]. In this case, rather than encoding an×(l,s,a) and λ(l,s,a) are non-negative integers, i.e. 0 (cid:2) λknowledge bases Msi and Mordering, the weights have a numerical interpretation with a probabilistic flavor.(cid:13)si(cid:13)siLet us define the following penalty logic bases:(cid:16)(cid:5)(cid:16)(cid:6)Q =(cid:13) =Q(Msi )λ ∪(cid:3)(cid:2)i(cid:16)(cid:13)si∪λMi(α, +∞)(cid:4)(cid:4) α ∈ K @sii(cid:5)(c, +∞)(cid:6)(cid:4)(cid:4) c ∈ C∪(α, +∞)(cid:4)(cid:4) α ∈ K @sii(cid:6)(cid:5)∪(c, +∞)(cid:6)(cid:4)(cid:4) c ∈ Ci(cid:16)(cid:5)i(55)(56)∗(cid:13) ∗and Qand let us write Qfor the corresponding classical knowledge bases that are obtained by ignoring the penalties.In [28], some relationships between penalty logic and Dempster–Shafer theory [43,44] are revealed, essentially suggesting−p . Whento interpret a penalty logic formula (α, p) as an upper bound on the probability that α is violated: P (¬α) (cid:2) ethe correctness of formulas appearing in a penalty logic base K is independent of the correctness of other formulas, the(cid:19)i pi .probability that a set of formulas (αi, pi) from K are violated in the true world is then upper bounded byThis independence assumption is, however, quite strong, and presupposes that no formula is entailed by a subset of theremaining formulas. In particular, the independence assumption cannot be made in the case of Q and Q, since we alreadyhave α×→ α×(cid:13)(l,s,a) for any source s, atom a, × ∈ {W , X, Y , Z }, and l > 0. However, in the case of Q, it seems natural(l−1,s,a)to interpret λ(l,s,a) by−pi = ei e(cid:22)−(cid:13)P (¬α(l,s,a) | ¬α(l−1,s,a)) (cid:2) e−λ(l,s,a)for l > 0, andP (¬α(0,s,a)) (cid:2) e−λ(0,s,a)This only presupposes that the amount of tolerance required for a given atom when considering a given source, is indepen-dent of the amount of tolerance required for other atoms and other sources. A similar interpretation could be given to the(l,s,a),penalties in Q(l,s,a) and α ZαY, although this requires additional information about the probability that the four implications α W(l,s,a) are correct, and about the dependencies between these probabilities.(l,s,a), α X(cid:13)Given a penalty logic base K , we may consider the following relation between subsets B 1 and B2 of formulas that appearin a weighted knowledge base K :B1 (cid:2)p B2iff penK (B1) (cid:2) penK (B2)(cid:19)where penK (B i) =mulas that are minimal w.r.t. (cid:2)p . Merging operators corresponding to Q and Q(cid:9)(cid:7)(α,p)∈K ,α /∈Bi(cid:10)(cid:13)p (see Appendix A for further details). We write Pref pen(K ) to denote the subsets of for-can then be defined as follows:(cid:3)pen(K1, . . . , Kn) = forgetVar(cid:13)(cid:3)pen(K1, . . . , Kn) = forgetVar(cid:9)(cid:7)Pref pen(Q ), A@s1 ∪ · · · ∪ A@sn(cid:2)Pref penQ(cid:3)(cid:13), A@s1 ∪ · · · ∪ A@sn(cid:10)(57)(58)Now assume, as in Sections 5.2–5.4 that λ(l,si ,a) is independent of the source si and the atom a, and depends only onthe tolerance level l, i.e. λ(l,si ,a) = λl. From an application point of view, a natural choice seems to assume that λl is equalto a constant. As the exact value of this constant does not affect the result of the merging operators (57) and (58), we may(cid:13)) simply areassume this constant to be 1. It is not hard to see that in this case, the elements of Pref pen(Q ) and Pref pen(Qthe consistent subsets with maximal cardinality of Q and Q. Note that in this case, we have the following interpretation(cid:13)6 A brief introduction to penalty logic is provided in Appendix A.S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551839P (¬α(l,si ,a)) = P (¬α(l,si ,a) | ¬α(l−1,si,a)) · · · · · P (¬α(0,si ,a)) (cid:2) γ l+1for some constant γ .As a second important interpretation of the penalties λl, we consider the case where tolerance levels correspond todifferent order-of-magnitudes of probabilities. In this view, the probability P (¬α(l,si ,a) | ¬α(l−1,si ,a)) should be decreasingin l. In particular, we assume that this conditional probability is upper bounded by (cid:13)rlfor some (cid:13) ∈ ]0, 1[ and a sufficientlylarge r. The corresponding penalty is of the form λl = γ · rl, where in fact γ = − log((cid:13)). Note that the exact value of γ > 0does not influence the result, hence we may assume γ = 1. Recall that the motivation of using cardinality-based preferredsubtheories was also in terms of order-of-magnitudes of probabilities. Accordingly, we have the following proposition.Proposition 6. Let Q and Qit holds that(cid:13)be defined as before, and assume that λ×(l,s,a)= λ(l,s,a) = λl = rl for some r ∈ N. If r is sufficiently large,(cid:3)pen(K1, . . . , Kn) ≡ (cid:3)priorcard (K1, . . . , Kn)(cid:13)(cid:3)pencard (K1, . . . , Kn)(K1, . . . , Kn) ≡ (cid:3)prior(cid:13)(59)(60)In addition to constant weights (λl = 1) and exponential weights (λl = rl), we may also consider weights that are pro-portional to l + 1, i.e. choose λl = l + 1. Note that l + 1 is considered rather than l to ensure a non-zero weight for the casewhere l = 0.Example 16. Consider again the weather scenario from Example 11. Recall that the approaches from Sections 5.2–5.4 all∨ocyield the same result pc2, while the more cautious alternative pc1can be obtained using the partially ordered weights from Section 5.5. Example 11 suggests a number of other possibilities,which, as we will see, can be obtained by interpreting the penalties as weights.∨pc3 and the trivial conclusion os∨pc1∨pc2∨pc3∨pc2There are five maximal consistent subsets of Q(cid:13):Bos = Q= QBpc1= QBpc2= QBpc3Boc = Q(cid:13) ∗ \ {α(0,s3,oc), α(1,s3,oc), α(2,s3,oc), α(3,s3,oc)}(cid:13) ∗ \ {α(0,s1,os), α(0,s2,os), α(0,s3,oc), α(1,s3,oc), α(2,s3,oc)}(cid:13) ∗ \ {α(0,s1,os), α(1,s1,os), α(0,s2,os), α(1,s2,os), α(0,s3,oc), α(1,s3,oc)}(cid:13) ∗ \ {α(0,s1,os), α(1,s1,os), α(2,s1,os), α(0,s2,os), α(1,s2,os), α(2,s2,os), α(0,s3,oc)}(cid:13) ∗ \ {α(0,s1,os), α(1,s1,os), α(2,s1,os), α(3,s1,os), α(0,s2,os), α(1,s2,os), α(2,s2,os), α(3,s2,os)}are constant, the following penalties are obtained (for λl = 1):(cid:13)siWhen the penalties in MpenQ (cid:13) (Bos) = 4,penQ (cid:13) (Bpc1 ) = 5,penQ (cid:13) (Bpc2 ) = 6,penQ (cid:13) (Bpc3 ) = 7,penQ (cid:13) (Boc) = 8Hence only Bos is minimal which leads to(cid:13)(cid:3)pen(K1, K2, K3) ≡ C ∪ {os}When considering exponential penalties of the form λl = rl, with a sufficiently large r, we obtain using (58)(cid:13)(cid:3)pen(K1, K2, K3) ≡ C ∪ {pc2}Finally, when considering penalties of the form λl = l + 1, we findpenQ (cid:13) (Bos) = 10,penQ (cid:13) (Bpc1 ) = 8,penQ (cid:13) (Bpc2 ) = 9,penQ (cid:13) (Bpc3 ) = 13,penQ (cid:13) (Boc) = 20leading to(cid:13)(cid:3)pen(K1, K2, K3) ≡ C ∪ {pc1}Clearly, by using constant penalties of the form λl = 1, the result reflects the opinion of the majority. By choosing expo-nential penalties of the form λl = rl, for a sufficiently large r, we obtain an opinion in the middle, as for the operators thatwere discussed in Sections 5.2–5.4. Finally, using linearly increasing penalties of the form λl = r + 1, the result intuitively re-flects the center-of-gravity of the opinions held by the sources. This latter behavior is related to least squares approximation,∗(a,s) to denote the largest value of l for which α(l,s,a) iswhich can be made explicit as follows. For each atom a, let us write l∗+ 1 measures how abnormal the situation= −1 if even α(0,s,a) is satisfied. Then lviolated in the real world, where l(a,s)+ 1 is, in fact, the discrete approximationw.r.t. atom a and source s is. If we make the assumption that the abnormality lof a continuous parameter which follows a normal distribution, and the degree of abnormality of each atom a and source∗(a,s)∗(a,s)1840S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855(cid:13)i=0 λi = γ · (l + 1)2 fors is independent, the most likely situation is recovered by (cid:3)pensome constant γ . This is due to the well-known correspondence between least squares and maximum likelihood estimation· (l + 1) · (l + 2), which may indeed serve as anof normally distributed variables. By taking λl = l + 1, we findapproximation of γ · (l + 1)2 for γ = 12 .when the penalties are such thati=0 λi = 1(cid:19)lDepending on how the penalties are chosen, we either find a solution in the middle between the beliefs of the differentsources, a solution expressing the majority opinion, or the centre-of-gravity of the beliefs of the sources. Formally, however,(cid:13)it is not hard to show that for every non-trivial choice of penalties (i.e. 0 < λ(l,s,a) < +∞ for all l, s and a), (cid:3)pen and (cid:3)penare majority operators in the sense of [17]:2(cid:19)l∀K1, K2 . ∃n ∈ N . (cid:3)pen(K1, . . . , K1(cid:26)(cid:23)(cid:24)(cid:25)n, K2) |(cid:7) K1(cid:13)and similar for (cid:3)pen. On the other hand, we do have the intuition that the more λl increases with l, the less the notionof majority plays a role. Interestingly, such weak majority operators are also studied in [45], considering a distance-basedmerging operator which is based on the square of the Hamming distance.Finally, note that, due to their quantitative nature, a more cautious variant of (cid:3)pen and (cid:3)pencan straightforwardly be(cid:13)defined, by being more tolerant in the definition of Pref pen(Q ) and Pref pen(Q(cid:13)). For instance, we may defineB1 ∈ Pref pen(Q )iff penQ (B1) (cid:2) γ · minpenQ (B)Bfor some constant γ (cid:3) 1. Thus, in the scenario of Example 11, results such as os ∨ pc1, or os ∨ pc1∨ pc2 may be obtained.5.6.2. Semantic characterization(cid:13)Semantically, (cid:3)pen and (cid:3)pendepend on the underlying source,7 i.e. for each × ∈ {W , X, Y , Z }, tolerance level l, source s and atom a, λsome λ∈ [0, +∞], and λ(l,s,a) = λ(l,a) for some λ(l,a) ∈ [0, +∞]. Then, we may consider the following distances:(cid:27)(cid:5)can be described in the distance-based framework, provided that the penalties do not×(l,a) for×(l,s,a)(cid:27)(cid:5)×(l,a)= λ(cid:6)(cid:6)Q (I, J ) =d1λW(l,a)(cid:27)(cid:5)+(cid:27)(cid:5)(cid:4)(cid:4) l ∈ {0, . . . , k}, a ∈ J \ (cid:14)I(cid:15)(cid:4)(cid:4) l ∈ {0, . . . , k}, a ∈ [I]λY(l,a)(cid:4)(cid:4) l ∈ {0, . . . , k}, a ∈ J \ (cid:14)I(cid:15)+(cid:6)+W lY l \ JW l ∪ I \ (cid:14) J (cid:15)λ X(l,a)(cid:27)(cid:5)λ Z(l,a)Xl ∪ [I](cid:4)(cid:4) l ∈ {0, . . . , k}, a ∈ I \ (cid:14) J (cid:15)(cid:4)(cid:4) l ∈ {0, . . . , k}, a ∈ [ J ]XlZ l \ I(cid:6)Y l \ J ∪ [ J ]Z l \ I(cid:6)Q (I, J ) =d2λ(l,a)Accordingly, we may define the distance between an interpretation and a knowledge base, or an interpretation and a list ofknowledge bases, exactly as in the distance-based framework. This leads to the following proposition.Proposition 7. Let Q and Qsi and atom a. It holds that(cid:13)be defined as before and assume that λ×(l,si ,a)= λ×(l,a) < +∞ and λ(l,si ,a) = λl,a < +∞ for every source(cid:3)pen(K1, . . . , Kn) ≡ (cid:3)dist(K1, . . . , Kn; C; (cid:2)d1Q(cid:13)(cid:3)pen(K1, . . . , Kn) ≡ (cid:3)dist(K1, . . . , Kn; C; (cid:2)d2Q))(61)(62)When comparing Proposition 7 with Proposition 4, it becomes obvious that (cid:3)pen and (cid:3)priorcard present two differentsolutions to deal with the fact that the distance between interpretations is most naturally represented as a vector in oursetting, which was defined in (44). While (cid:3)pen uses a quantitative approach, which aggregates such vectors to scalar values,before proceeding in the standard distance-based framework (albeit with a non-standard distance), (cid:3)priorcard follows a morequalitative approach, in which a lexicographic extension of the distance-based framework is rather used.6. Computational complexityIn this section, we investigate the computational complexity of our merging operators. First note that the proposedmerging operators have syntactically been defined in existing logical formalisms. Hence existing algorithms for reasoning ine.g. possibilistic logic or penalty logic can readily be reused to implement the merging operators. Moreover, the membershipresults for these existing frameworks immediately carry over to the present setting.Typically, propositional merging tasks are at the lower levels of the polynomial hierarchy. Recall that the complexityk , which constitute the polynomial hierarchy, are defined as follows (i ∈ N) [46]:k and Π Pk , Σ Pclasses, (cid:3)P7 The general case can be treated by a straightforward generalization of the distance-based framework in which a difference distance is used for eachsource; we omit the details.S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551841Table 2Complexity of entailment checking for different merging operators.(cid:3)poss(cid:3)prior⊆(cid:3)priorcard(cid:3)penlinear weightspartially ordered weightslinear weightspartially ordered weightslinear weightspartially ordered weightsexponentially bounded penaltiespolynomially bounded penaltiesΘ PΠ P2 -complete2 -completeΠ PΠ P2 -complete2 -complete(cid:3)PΠ P2 -complete2 -complete(cid:3)PΘ P2 -complete2 -complete(cid:3)P0= Σ P= Π P00(resp. PΣ P= P,(cid:3)Pi+1= PΣ Pi ,Σ Pi+1= NPΣ Pi ,Π Pi+1= co(cid:3)(cid:2)Σ Pi+1iwhere NPΣ Pi ) is the class of problems that can be solved in polynomial time on a non-deterministic machine(resp. deterministic machine) with a Σ Pi problems in constant time.All problems in the polynomial hierarchy are solvable with a polynomial amount of space and an exponential amount oftime, e.g. using systematic search based on branch-and-bound. In particular, so far, no complexity class of the polynomialhierarchy is known to be strictly harder than P . Knowing which class of the polynomial hierarchy a given problem belongsto, however, is still important, as it serves as an indication of how hard we can expect the problem to be in practice. Inthe following, we also refer to the class Θ Pi which contains the problems that are solvable in polynomial time using alogarithmic number of calls to a Σ Pi oracle, i.e. assuming a procedure that can solve Σ PFor each merging operator (cid:3), the main decision problem consists of checking whether (cid:3)(K 1, . . . , Kn; C; Ms1 , . . . , Msn ) |(cid:7)φ for given knowledge bases K i , integrity constraints C , weighted knowledge bases Msi and a propositional formula φ overthe set of atoms A. Note that the computational complexity is not affected if the sets W la are given asinput instead of the weighted knowledge bases Msi . The complexity classes of the merging operators that were studied inSection 5 are summarized in Table 2. From a complexity point of view, it does not matter whether P or Pis considered( Q or Qin the case of penalties). The following proposition summarizes the main results.a and Z la, Xla, Y li oracle [47].(cid:13)(cid:13)Proposition 8. Let K1, . . . , Kn be propositional knowledge bases over a set of atoms A, C a set of propositional integrity constraintsover A, and let Ms1 , . . . , Msn be defined as in (16). For a propositional formula φ, the complexity of deciding whether(cid:3)(K1, . . . , Kn; C; Ms1 , . . . , Msn ) |(cid:7) φholds is summarized for different merging operators (cid:3) in Table 2.Note that by exponentially bounded penalties, we mean that there exists an exponential function f of the problemsize n, such that the value of all penalties is at most f (n). In other words, the number of bits required to encode thepenalties is polynomial in n. Polynomially bounded penalties are then upper bounded by g(n) for a polynomial function g.In other words, the cases of exponentially and polynomially bounded queries respectively assume that penalties are encodedusing binary and unary notation. Furthermore, note that we do not need to make such a distinction in the other cases, aspossibilistic certainty weights, priorities and symbolic weights are all interpreted in an ordinal way.In some sense, the complexity results are unsurprising, as it is well-known that entailment relations based on e.g.possibilistic logic or inclusion-based preferred subtheories are Θ P2 respectively. What the proposition shows ismainly that the restricted setting in which possibilistic logic, preferred subtheories, and penalty logic are used does notcause a decrease in complexity.2 and Π POverall, we can see that the possibilistic and penalty-logic based interpretations of the weights yield the most efficientprocedures. Moreover, the complexity of (cid:3)poss depends on the number of different weights. The smaller this number, thefewer calls to the NP-oracle are required. In particular, in the case of k + 1 different weights λ0, . . . , λk, entailment canbe verified by solving 1 + (cid:27)log2(k + 1)(cid:28) instances of the boolean satisfiability problem SAT, viz. (cid:27)log2(k + 1)(cid:28) instancesfor calculating the inconsistency level and 1 instance for entailment checking. In the same way, the number of requiredsatisfiability checks for (cid:3)priorcard is given by k + 2, when the weights are linearly ordered. On the other hand, (cid:3)prior⊆ (withlinearly or partially ordered weights) and (cid:3)priorcard with partially ordered weights remain computationally hard, even in thecase where k = 1. In the case of (cid:3)pen, the number of required satisfiability checks depends on both k and the actual valuesof the penalties. In addition to these effects of restricting the value of k, in all cases, efficient procedures can be obtained= {a} for all l and for all but aby restricting the number of atoms that may be weakened, i.e. by taking W lafew atoms a.= Xla= Z la= Y laWhen weights are interpreted as priorities, a number of entailment relations may be considered that are not basedon calculating the merged knowledge bases (cid:3)prior⊆ (K1, . . . , Kn) and (cid:3)priorcard (K1, . . . , Kn). When the weights are linearlyordered, well-known entailment relations |≈∃⊆ and |≈∃card are defined as follows:1842S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855Table 3Complexity of alternative entailment relations based on priorities.Entailment relation|≈∃⊆|≈∃∃⊆|≈∃∀⊆|≈∀∃⊆ComplexityΣ P2Σ P2Σ P3Π P3(K1, . . . , Kn) |≈∃(K1, . . . , Kn) |≈∃⊆ φ iff ∃B ∈ Pref ⊆(P ) . B |(cid:7) φcard φ iff ∃B ∈ Pref card(P ) . B |(cid:7) φEntailment relation|≈∃card|≈∃∃card|≈∃∀card|≈∀∃cardComplexityΣ P2Σ P2Σ P2Π P3Hence, rather than looking for conclusions that are common to all preferred subtheories, we only require that φ is aconclusion of one of the preferred subtheories. Of course, this means that it may happen that both φ and ¬φ can bederived. When weights are partially ordered, even more alternatives may be conceived:(cid:2)(cid:3)κ(P )(cid:2)(K1, . . . , Kn) |≈∃∃(K1, . . . , Kn) |≈∃∀(K1, . . . , Kn) |≈∀∃⊆ φ iff ∃κ∃B ∈ Pref ⊆⊆ φ iff ∃κ∀B ∈ Pref ⊆⊆ φ iff ∀κ∃B ∈ Pref ⊆. B |(cid:7) φ. B |(cid:7) φ. B |(cid:7) φand similar for the alternatives based on Pref card. Note that |≈∃∀⊆ could, for instance, be used to verify whether there exists anassessment of the relative reliability of the sources, such that a formula φ could be concluded after merging the knowledgebases. Similarly, |≈∀∃⊆ could be used to verify whether φ is a plausible consequence, independent of which sources areconsidered most reliable.(cid:3)κ(P )(cid:3)κ(P )(cid:2)Interestingly, in some cases, the complexity goes up a level in the polynomial hierarchy when these alternative entail-ment relations are used.Proposition 9. Let K1, . . . , Kn be propositional knowledge bases over a set of atoms A, C a set of propositional integrity constraintsover A, and let Ms1 , . . . , Msn be defined as before. For a propositional formula φ, the complexity of deciding whether(K1, . . . , Kn; C; Ms1 , . . . , Msn ) |≈ φholds is summarized for different entailment relations |≈ in Table 3.7. Related workAlthough many approaches to merging propositional knowledge bases have already been studied, we are not awareof any proposals that model the fact that different atoms may be closely related in meaning, or indeed, that we maybe uncertain about how exactly we should understand a given assertion. On the other hand, the fact that uncertainty inmeaning (or if we prefer ‘vagueness’) is pervading social interaction has been recognized early in AI [48]. This phenomenonhas also been extensively studied by (cognitive) linguists, especially in the context of dialogues, which can be consideredas the simplest form of social interaction. The reasons for adopting vague language in conversations may be many. Forinstance, vague language may help the listener to determine how much processing effort should be devoted to a givenutterance, focusing him or her to the most relevant information; it may indicate a lack of certainty about the exact stateof affairs; or it may be used to serve social functions, such as softening implicit complaints and criticism [49]. Whether ornot vagueness in conversations lead to misconceptions depends on the participants’ ability to relate what is expressed totheir common ground. Thus, successful communication depends on the establishment of such a common ground, a processcalled grounding [50]. This common ground allows for a common language on which the points of view of the speaker andlistener in a dialogue can be aligned. A key issue in communication is that this alignment between speaker and listener maybe faulty, in which case a repair mechanism is needed [51]. In some cases, the misalignment is deliberate. This aspect ofcommunication is stressed in [52], where a bipolar view on assertability is put forward, distinguishing between situationsin which a statement is definitively assertable, situations in which it is merely acceptable to assert it, and situations inwhich it cannot be asserted without condemnation. As an example where misalignment is deliberate, [48] considers theexample of a hotel manager, who claims that a room of his hotel is ‘quite large’, despite knowing that the client may notagree with this. In general, misalignments can be discovered because of inconsistencies, but, due to the interactive natureof dialogues also by means of explicit clarification requests and reformulation. Clearly, the issue of merging multiple-sourceinformation can be related to this view. However, as the interactive component is missing, the main vehicle to establishplausible alignments is by detecting and interpreting inconsistencies. In this sense, the integrity constraints C could be seenas explicit common ground between the sources, which may or may not be properly aligned with them. The weightedknowledge bases Msi then encode strategies for repairing situations of detected misalignment. This point of view is alsoS. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551843reminiscent of approaches to causal diagnosis [53], which attempt to find the most likely disorders, given a set of observedsymptoms. Here, conflicts take the role of symptoms and the possible misalignments take the role of disorders.Another line of related work is the use of similarity relations between interpretations to define approximate entailmentrelations. This idea was first proposed in [54] where “p approximately entails q” is understood as “every model of p issimilar to a model of q”. This idea can be contrasted with non-monotonic reasoning, where “if p, generally q" iff the mostplausible models of p are also models of q [55], i.e. in the former case the set of models of q is expanded, whereas inthe latter case the set of models of p is restricted. A detailed comparison between similarity-based and non-monotonicentailment was made in [56,57], e.g. pointing out that, while similarity-based entailment is monotonic, it fails to satisfy theso-called cut property: from p |≈ r and p ∧ r |≈ q it does not follow that p |≈ q. The use of a similarity relation betweeninterpretations was also briefly discussed from a belief revision point of view in [58].In certain application domains, ideas have been examined that are to some extent similar to the motivation of ourapproach, although only within more restrictive settings. To repair inconsistent description logic ontologies, for instance,[59] looks for overgeneralized concept inclusions that create conflicts, and accordingly replaces concepts by more liberalor more restrictive variants. For instance, the conflict that arises from ‘children only like ice cream’ and ‘children only likechocolate’ is resolved by replacing these assertions by ‘children only like sweeties’, thus taking advantage of known conceptrelations to resolve the conflict in a meaningful way. In this approach, we can clearly recognize the view that inconsistenciesare often caused by sources that are not sufficiently cautious when asserting information, although what they claim maynot be far from the truth. Another related application is presented in [60], where the problem of merging networks ofqualitative temporal and spatial relations is considered. The idea is to deal with conflicts by finding spatial or temporalscenarios that are similar to scenarios that are compatible with what is claimed by each of the sources. For instance, if onesource claims that spatial regions a and b are disjoint while another asserts that in fact a is a part of b, we could concludethat a overlaps with b. The notion of similarity here operates at the level of the spatial or temporal relations, and is directlyrelated to the conceptual neighborhood diagrams of Freksa [31]. Somewhat related, [61] discusses an application in whichtemporal relations are extracted from web documents, and conflicts are solved by reinterpreting the temporal relationshipsas fuzzy temporal relations that only hold to some degree. In the presence of a conflict, ‘a happened during b’ may then beinterpreted as, e.g., ‘a happened during b to degree 0.6’. Such fuzzy temporal relations can be modeled in a generalizationof Allen’s interval algebra [62], which was proposed in [63]. Intuitively, ‘a happened during b to degree 0.6’ means that thedegree of similarity between the actual state of affairs and a temporal configuration in which a happened during b is 0.6.A similar approach in the spatial domain, based on a generalization of the region connection calculus [64], was proposedin [65].The idea that flexibility of terms may be interpreted in different ways (cf. the four scenarios from Section 4) is somewhatreminiscent of the study of linguistic hedges such as ‘very’ in the framework of fuzzy set theory [66,67]. In particular,a linguistic phrase such as ‘more or less old’ can be understood in at least two different ways. There is an inclusive reading,in which ‘more or less old’ is a liberalization of ‘old’, i.e. everybody who is considered old, is also considered more or lessold. However, there also is an exclusive reading in which the meaning of ‘more or less old’ does not encompass the meaningof ‘old’, i.e. people who are very old are not considered to be ‘more or less old’. In other words, when modeling linguistichedges, there is a choice between expanding (or contracting, depending on the type of modifier) the meaning of a term andshifting it [68].Finally, note that preliminary versions of the approach we have presented in this paper can be found in [69] and [70]. Inparticular, [69] has introduced the idea of using a similarity graph and of defining merging operators, at the semantic level,in terms of the operators (cid:14).(cid:15)R and [.]R defined in (18)–(19). In [70], merging operators were defined at the syntactic level.The syntactic procedures that were proposed there essentially correspond to the application of Proposition 10 in the specificcase where the weights are interpreted in a possibilistic setting, or in the setting of inclusion-based preferred subtheories.8. ConclusionsIn this paper, we have proposed a novel approach to merging, which differs from existing approaches in its use of extra-logical background information about the semantic relatedness of atoms. The central idea is that in many applications, atomscorrespond to natural language terms that may be understood in a slightly different way by different sources. By exploitingavailable knowledge about which of these terms have a similar meaning (or may otherwise be confused), consistency canbe restored in a more informed way. The requirement for this extra-logical information may be seen as a disadvantage, inthe sense that we cannot expect such information to be available in every application. However, in such cases, the mergingoperators we have proposed degenerate to existing approaches such as morphological, conflict-based or distance-basedmerging. In general, our operators refine (special cases of) these existing approaches using whatever information is availableabout the relatedness of terms.Rather than defining one specific merging operator, we have proposed a general framework which is based on (i) as-suming a disjoint vocabulary for each source to trivially restore consistency, and (ii) introducing an additional weightedknowledge base to encode flexible constraints on how the vocabularies of different sources relate to each other. Sub-sequently, we have analyzed how different interpretations of these weights naturally lead to merging operators with adifferent behavior. The interpretations we have considered range from purely qualitative approaches, in which weights aretaken from an abstract, partially-ordered scale, to purely quantitative approaches with a probabilistic flavor. This diversity1844S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855allows us to appropriately handle cases where more, or less information is available about the reliability of sources, thestrength of known semantic relationships, etc.Each of the proposed merging operators is based on the intuition of finding the interpretations that are most plausible,given what is asserted by the sources. In this sense, they are tailored towards merging beliefs, rather than towards mergingpreferences or goals. While the exploitation of semantic relatedness between terms is clearly of interest for the latterproblem as well, the scenario of merging preferences additionally requires to consider principles from social choice theoryto ensure that the result is fair.AcknowledgementsWe would like to thank the anonymous reviewers, whose detailed comments have greatly improved the readability ofthis paper.Appendix A. Tools for managing inconsistencyA.1. Possibilistic logicA possibility distribution in a universe X is an X − [0, 1] mapping, used as a convenient way to encode a complete or-dering that models plausibility or preference. Given a possibility distribution π on the set of all possible interpretations 2 A ,the possibility Π(φ) and necessity N(φ) of a formula φ are defined asΠ(φ) = maxI∈(cid:2)φ(cid:3)π (I)N(φ) = 1 − Π(¬φ) = minI∈(cid:2)¬φ(cid:3)1 − π (I)A possibilistic logic [25] formula (φ, λ) is a pair made of a classical logic formula φ, and a weight λ ∈ ]0, 1] expressing itscertainty or priority. The formula (φ, λ) is semantically interpreted as N(φ) (cid:3) λ, where N is a necessity measure. Necessitymeasures N are characterized by the decomposability property N(φ ∧ ψ) = min(N(φ), N(ψ)). A possibilistic logic base, i.e.a set of possibilistic logic formulas can always be put in clausal form thanks to this property. The basic inference rule is thefollowing resolution rule, here written in the propositional case:(¬φ ∨ ψ, λ); (φ ∨ γ , μ) (cid:21)(cid:2)(cid:3)ψ ∨ γ , min(λ, μ)Given a possibilistic logic base K and a certainty level λ, two particular classical knowledge bases can be defined:(cid:5)(cid:5)φφ(cid:4)(cid:6)(cid:4) (φ, μ) ∈ K and μ (cid:3) λ(cid:4)(cid:6)(cid:4) (φ, μ) ∈ K and μ > λKλ =Kλ =A possibilistic logic base K = {(φi, λi) | i = 1, n} is semantically equivalent to a possibility distribution πK which restrictsthe set of interpretations that are more or less compatible with K . The possibility distribution πK is the min-based con-junctive combination of the representations π(φi ,λi ) of each formula in K . An interpretation I is all the more possible as itdoes not violate any formula φi with a high certainty level λi :(cid:28)π(φi ,λi )(I) =πK (I) = mini11 − λiπ(φi ,λi )(I)if I (cid:5) φiif I (cid:5) ¬φiAn important feature of possibilistic logic is its ability to cope with inconsistency. The inconsistency level of K is defined asinc(K ) = max{λ | Kλ inconsistent}(A.1)with max ∅ = 0. We have inc(K ) = λ iff maxI πK (I) = 1 − λ. Formulas in Kinc(K ) are safe from inconsistency.A.2. Penalty logicPenalty logic [27,28] is similar in spirit to possibilistic logic, but with an additive interpretation of the weights. A penaltylogic formula (φ, p) consists of a classical formula φ and a penalty p ∈ [0, +∞]. In particular, weights are not restricted tothe unit interval anymore, but can be any non-negative real number or +∞. The intuition behind a penalty logic formula(φ, p) is that p is the cost that has to be paid for having φ violated. Given a penalty logic base K , we can naturally associatepenalties to classical interpretations I :penK (I) =(cid:27)p(φ,p)∈K , I(cid:17)|(cid:7)φS. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551845∗Let us write Kformulas B ⊆ K∗for the set of classical formulas that appear in K , i.e. Kcan then be defined as∗ = {φ | ∃p . (φ, p) ∈ K }. The penalty of a set ofpenK (B) =(cid:27)p(α,p)∈K , α /∈BLike possibilistic logic, penalty logic can naturally deal with inconsistency. In particular, a consistent subset B ⊆ Kis calledpreferred if its penalty penK (B) is minimal among all consistent subsets of K. An inconsistency-tolerant entailment relation|≈ can then be defined as K |≈ φ iff B |(cid:7) φ for all preferred subsets of K. Note that in this setting, multiplying all penaltiesby a strictly positive constant does not affect the treatment of inconsistency. Without any practical restriction, we may thusassume that all penalties are taken from N ∪ {+∞} which has clear computational advantages.∗∗∗Appendix B. Variable forgettingIn this appendix, we introduce an efficient syntactic procedure that can be used, under some restrictions, to implement(cid:13)), letthe step of variable forgetting. In particular, for a source si , an atom a, × ∈ {W , X, Y , Z }, B ∈ Pref (P ) and Bw(a, si, ×; B) and w(a, si; B(cid:13)) be defined as follows:(cid:13) ∈ Pref (P(cid:28)w(a, si, ×; B) =(cid:28)(cid:2)a, si; B(cid:3)(cid:13)w=∈ B}min{l ∈ {0, . . . , k} | α×k + 1min{l ∈ {0, . . . , k} | α(l,si ,a) ∈ Bk + 1(l,si ,a)(cid:13)}∈ Bif α×(k,si ,a)otherwiseif α(k,si ,a) ∈ Botherwise(cid:13)(cid:12)all occurrences of positive literals a bywhere we define W k+1Now, let us assume that all knowledge bases are in conjunctive-normal form. For any given B ∈ Pref (P ), we then define theB-weakened version K Bi of knowledge base K i as the propositional knowledge base which is obtained from K i by replacing{¬ y | y ∈ Y w(a,si ,Y ;B)},as the(cid:13))W w(a,si ;Bpropositional knowledge base which is obtained from K i by replacing all occurrences of positive literals a by}. It is easy to see that the operations of B-weakeningand all occurrences of negative literals ¬a by-weakening indeed weaken a knowledge base K i , in the sense that its set of models is increased. Intuitively, it is thusand Bclear that by sufficiently weakening all knowledge bases in this way, consistency can be restored. In some cases, the mergingoperators (cid:3) f (K1, . . . , Kn) and (cid:3)(cid:13)f (K1, . . . , Kn), in fact, implement this idea, as made explicit in the following proposition.W w(a,si ,W ;B)= {⊥}. Similarly, for Band all occurrences of negative literals ¬a by-weakened version K Bi{¬ y | y ∈ Y w(a,si ;B(cid:13)), we define the B= {(cid:19)} and Y k+1(cid:13) ∈ Pref (P(cid:12)(cid:12)(cid:12)(cid:13))aaaaaa(cid:13)(cid:13)(cid:13)Proposition 10. Assume that for each a ∈ A and l ∈ {0, . . . , k}, it holds that Xlaeach knowledge base K i is equal to its set of prime implicates. It holds that(cid:7)(cid:3) f (K1, . . . , Kn) ≡(cid:3)(cid:13)f (K1, . . . , Kn) ≡K B1∪ · · · ∪ K Bn∪ CB∈Pref (P )(cid:7)B(cid:13)∈Pref (P (cid:13))(cid:13)K B1∪ · · · ∪ K Bn(cid:13)∪ C= {a, (cid:19)} and Z la= {a, ⊥}. Furthermore, assume that(B.1)(B.2)= {a, (cid:19)} and Z la, if γ (cid:13) |(cid:7) γ then also γ |(cid:7) γ (cid:13)Recall that a clause γ is an implicate of propositional knowledge base Φ iff Φ |(cid:7) γ , and a prime implicate if furthermorefor every other implicate γ (cid:13). Moreover, we additionally require that no literals are repeatedin prime implicates (e.g. if a ∨ b is a prime implicate of Φ then a ∨ a ∨ b is not considered as prime implicate). Everypropositional knowledge base can then be represented by its set of prime implicates. Also note that the condition that= {a, ⊥} is, in fact, satisfied in two of the four scenarios considered in Section 4: liberalization andXla= {a} in the case of liberalization, we may equivalently takerestriction. Indeed, although Table 1 e.g. suggest rather XlaXla= {a, (cid:19)} since Y laInterestingly, the technique we have proposed in [70] to weaken propositional knowledge bases corresponds to a specialcase of Proposition 10, thus revealing that the approach we take in this paper is compatible with the approach from [70],although it is more general.= {a} and a → a@si is equivalent to ¬a@si → ¬a.Note that the condition from Proposition 10 that each knowledge base K i should be equal to its set of prime implicatesis not redundant, as illustrated by the following example.Example 17. Let C = ∅, K1 = {a ∨ b, ¬b}, K2 = {¬a}, where W 1aX 1b , Z 1pref (Pa , Z 1a ,c are trivial. Clearly, K1 is not equal to its set of prime implicates, which is given by {a, ¬b}. Let= {b, c} and the sets X 1= {a, c} and W 1bc , Y 1(cid:13)}, whereb , W 1(cid:13)) = {Bc and Z 1= Y 1b= Y 1ac , X 1B(cid:13) = K @s11∪ K @s22∪ {α(1,s1,a), α(1,s1,b), α(1,s1,c), α(0,s1,c), α(1,s2,a), α(1,s2,b), α(1,s2,c), α(0,s2,a), α(0,s2,b), α(0,s2,c)}1846S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855Then we have(cid:13)(cid:13)K B1K B2= {a ∨ b ∨ c, ¬b ∨ ¬c}= {¬a}The right-hand side of (B.2) is then equivalent to ¬a ∧ ((b ∧ ¬c) ∨ (¬b ∧ c)). To find the left-hand side of (B.2), whichcorresponds to forgetting the variables from A@s1 ∪ A@s2 in B, we may write K1 as {a} and apply Proposition 10 to obtain(cid:3)(cid:13)f (K1, K2) ≡ (a ∨ c) ∧ ¬a ≡ c ∧ ¬aClearly we have ¬a ∧ ((b ∧ ¬c) ∨ (¬b ∧ c)) (cid:17)≡ c ∧ ¬a.Note that due to the restriction to sets of prime implicates, the result of the merging operation does not depend on thesyntactic structure of the knowledge bases. Finally note that when the families W la and Z la,a counterpart to Proposition 10 can be obtained, which is based on knowledge bases in disjunctive-normal form. BecauseW la are not simultaneously trivial in any of the four scenarios discussed in Section 4, we omit the details.a are trivial, instead of Xla and Y la and Y lAppendix C. ProofsC.1. Proof of Proposition 11. We first show (21). Assume that a ∈ ( J \ (cid:14)I(cid:15)a we have w /∈ I , which means I (cid:17)|(cid:7)if w ∈ W l} and also (I ∪ J @si ) (cid:17)|(cid:7)other hand we find J @si |(cid:7) a@si and I ∪ J @si |(cid:7) a@si . Together this means that I ∪ J @siConversely, assume I ∪ J @sior equivalently J @si |(cid:7) a@si and I (cid:17)|(cid:7)W la} we find that there is no w ∈ I such that (a, w) ∈ W l, and thus a /∈ (cid:14)I(cid:15){w | w ∈ W la{w | w ∈ W la(cid:17)|(cid:7) (a@si →(cid:12)W l ); we find a /∈ (cid:14)I(cid:15)(cid:12){w | w ∈ W laW l and hence for every w ∈ I , (a, w) /∈ W l. Therefore,{w | w ∈ W l}. From a ∈ J on the(cid:12)a}).{w | w ∈ W la{w | w ∈ W l(cid:17)|(cid:7)(cid:12)a(cid:17)|(cid:7) (a@si →}. From J @si |(cid:7) a@si we immediately derive a ∈ J . From I (cid:17)|(cid:7)W l . We conclude that a ∈ ( J \ (cid:14)I(cid:15)}). This implies that I ∪ J @si |(cid:7) a@si and I ∪ J @si},{w | w ∈W l ).(cid:12)(cid:12)(cid:12)2. In entirely the same way, we can show (22).3. To show (23), first note that ([I](cid:12){¬ y | y ∈ Y la(cid:17)|(cid:7) (¬a@si →hence for every y ∈ coI , (a, y) /∈ Y l. Therefore, if y ∈ Y l(I ∪ J @si ) (cid:17)|(cid:7)means that I ∪ J @siConversely, assume I ∪ J @siY laI (cid:17)|(cid:7)a ∈ (co J \ (cid:14)coI(cid:15){¬ y | y ∈ Y la{¬ y | y ∈ Y l(cid:12)a}, or equivalently J @si |(cid:7) ¬a@si and I (cid:17)|(cid:7){¬ y | y ∈ Y laY l ).(cid:17)|(cid:7) (¬a@si →}).(cid:12)(cid:12)(cid:12)Y l \ J ) = co(cid:14)coI(cid:15)Y l and} and also}. From a ∈ co J on the other hand we find J @si |(cid:7) ¬a@si and I ∪ J @si |(cid:7) ¬a@si . Together thisa we have y ∈ I , which means I (cid:17)|(cid:7)Y l ), we find a /∈ (cid:14)coI(cid:15){¬ y | y ∈ Y laY l ∩ co J = co J \ (cid:14)coI(cid:15)Y l . If a ∈ (co J \ (cid:14)coI(cid:15)(cid:12){¬ y | y ∈ Y la} we find that there is no y ∈ coI such that (a, y) ∈ Y l, and thus a /∈ (cid:14)coI(cid:15)}). This implies that I ∪ J @si |(cid:7) ¬a@si and I ∪ J @si{¬ y | y ∈}. From J @si |(cid:7) ¬a@si we immediately derive a ∈ co J . FromY l . We conclude that(cid:17)|(cid:7)(cid:12)4. Finally, (24) is shown in the same way as (23).C.2. Proof of Lemma 1(⇒) Assume that (26) holds for all a ∈ A. First assume that a@si is true. Then we clearly have that(cid:12)a is the case. We conclude a@si →Sl(cid:12)S will be true for every S satisfying {a} ⊆ S ⊆ Slsatisfying {a} ⊆ S ⊆ Sla, which means thatNext assume that a is true. This means thata@si will be true. Hence we have shown a → a@si .S is true for some SSla using the deduction theorem.a and consequently that(cid:12)(⇐) Assume that the implications in (27) hold for all a ∈ A. First assume that a@si holds. Then we know from a@si →(cid:12)that some b ∈ Slsome S satisfying {a} ⊆ S ⊆ Sla is satisfied, and hence also (26). Conversely, if a@si is false it is sufficient to show that(cid:12)a. In particular for S = {a} we immediately haveS false from ¬a@si → ¬a.(cid:12)SlaS is false for(cid:12)C.3. Proof of Lemma 2(⇒) Assume that (28) holds for all a ∈ A. First assume that a@si is false. Then we clearly have thatS satisfying {a} ⊆ S ⊆ Slconclude ¬a@si →be false for every S satisfying {a} ⊆ S ⊆ Sl{¬s | s ∈ Sla(cid:12)a, which means that for some s ∈ Sla, ¬s is the case, or in other words} using the deduction theorem. Next assume that a is false. This means thata and consequently that a@si will be false. Hence we obtain ¬a → ¬a@si .(⇐) Assume that the implications in (29) hold for all a ∈ A. First assume that a@si holds. Then we know from ¬a → ¬a@si ,S.S will bewhich is equivalent to a@si → a, that a is the case. This means that for S = {a},Conversely, if a@si is false, we know from (29) that there is an s ∈ Slfalse for some S satisfying {a} ⊆ S ⊆ Sla such that s is false. This means thatS holds, and thus a@si ≡(cid:29)(cid:29)(cid:29)(cid:29)S.a, and thus a@si ≡(cid:29)S is false for some(cid:12){¬s | s ∈ Sl}. We(cid:29)aS willS. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551847C.4. Proof of Proposition 2(C.1)(C.2)We show that(cid:4)I ∈(cid:5)(cid:3)poss(K1, . . . , Kn; C; Ms1 , . . . , Msn )is equivalent to(cid:4)(cid:5)(cid:3)morph(K1, . . . , Kn; C; B(W r , X r ,Y r , Z r ))I ∈Clearly, by definition of variable forgetting, (C.1) is equivalent to∃ J 1, . . . , Jn ∈ 2 A . I ∪ J @s11∪ · · · ∪ J @snn ∈ P inc(P )or, by definition of r∃ J 1, . . . , Jn ∈ 2 A . I ∪ J @s11∪ · · · ∪ J @snn∈ P λrApplying the definition of P , this corresponds to∃ J 1, . . . , Jn ∈ 2 A . I ∈ (cid:2)C(cid:3) ∧ ∀i . I ∪ J @siiwhich is equivalent toI ∈ (cid:2)C(cid:3) ∧ ∃ J 1, . . . , Jn ∈ 2 A . ∀i . I ∪ J @sii(cid:4)∈(cid:4)∈(Msi )λr(Msi )λr(cid:5)(cid:5)∧ J @sii∈(cid:5)(cid:4)K @sii∧ J i ∈ (cid:2)K i(cid:3)From Proposition 1, we know that this is equivalent toI ∈ (cid:2)C(cid:3) ∧ ∃ J 1, . . . , Jn ∈ 2 A . ∀i . J i ⊆ (cid:14)I(cid:15)W l ∧ I ⊆ (cid:14) J i(cid:15) X r ∧ [I]Y r ⊆ J i ∧ [ J i]Z r ⊆ I ∧ J i ∈ (cid:2)K i(cid:3)or in other wordsI ∈ (cid:2)C(cid:3) ∧ ∃ J 1, . . . , Jn ∈ 2 A . ∀i. σ(Y r ,W r )(I, J i) ∧ σ( Z r , X r )( J i, I) ∧ J i ∈ (cid:2)K i(cid:3)By definition of B(W r , X r ,Y r , Z r ) we findI ∈ (cid:2)C(cid:3) ∧ ∃ J 1, . . . , Jn ∈ 2 A . ∀i . J i ∈ B(W r , X r ,Y r , Z r )(I) ∧ J i ∈ (cid:2)K i(cid:3)or, equivalentlyI ∈ (cid:2)C(cid:3) ∧ ∀i . B(W r , X r ,Y r , Z r )(I) ∩ (cid:2)K i(cid:3) (cid:17)= ∅which corresponds to (C.2).C.5. Proof of Proposition 3As an example, we show (41); the proof of (42) is entirely analogous.Note that I ∈ (cid:2)(cid:3)prior⊆ (K1, . . . , Kn)(cid:3) is equivalent to∃ J 1, . . . , Jn ∈ 2 A . I ∪(cid:16)(cid:7)J @sii|(cid:7)Pref ⊆(P )iwhich means that for some B ∈ Pref ⊆(P )∃ J 1, . . . , Jn ∈ 2 A . I ∪(cid:16)iJ @sii|(cid:7) BLet us write Bl for the formulas from B that appear in Msisubtheory means that I |(cid:7) C (since the integrity constraints C are assumed to be consistent),base is assumed to be individually consistent), and furthermore, that there can be no r ∈ {0, . . . , k} and Isuch that Iappear in P with weight λl and that are satisfied by Ifor all i ∈ {1, . . . , n} the following four inclusions hold:(cid:18)(cid:18)for some i with weight λl. The fact that B is a preferredJ i |(cid:7) K i (since each knowledge(cid:13), J∈ 2 A(cid:13)l for the set of formulas which⊆ Bl is equivalent to asserting that= Bl for all l > r, where we write B(cid:14). Using Proposition 1, B|(cid:7) K i and such that Br ⊂ B(cid:13)(cid:13)r while Bl(cid:13) ∪(cid:13)1, . . . , J(cid:13) |(cid:7) C ,(cid:13) @siii J(cid:13)n(cid:13)l(cid:13)i(cid:17)(cid:17)JJ i \ (cid:14)I(cid:15)[I](cid:13)W l ⊆ J\i(cid:30)(cid:31)(cid:13)IY l \ J i ⊆Y l(cid:13)I\ JW l ,(cid:13)i,I \ (cid:14) J i(cid:15)[ J i]Z l \ I ⊆Xl ⊆ I(cid:30)J(cid:13) \(cid:31)(cid:13)iZ l(cid:13)JXli(cid:13)\ I1848S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855In other words, for all idiff aW ldiff cYl(I, J i) ⊆ diff aW l(cid:2)(I, J i) ⊆ diff cYl(cid:3),(cid:2)(cid:13)I(cid:13)I, J(cid:13), Ji(cid:3)(cid:13)i,(I, J i) ⊆ diff bdiff bXlXl(cid:2)(I, J i) ⊆ diff dZldiff dZlI(cid:2)(cid:13)I, J(cid:3)(cid:13)i(cid:13), J(cid:3)(cid:13)ior, equivalently∀i ∈ {1, . . . , n} . diff 1Sl(I, J i) ⊆4 diff 1Sl(cid:3)(cid:2)(cid:13)I, J(cid:13)iwhich means(cid:17)diff 1S (I, J 1), . . . , diff 1(cid:18)S (I, Jn)(cid:2)(cid:17)diff 1S(cid:13)I, J(cid:13)1(cid:3)(cid:2)1l, . . . , diff 1S(cid:3)(cid:18)(cid:2)(cid:13)I, J(cid:13)nThus, we obtain∃c ∈ diff 1S (I, K) . ¬∃r . ∃I(cid:13)for c (cid:2)1l c(cid:13) ∈ 2 A . ∃c(cid:13) (cid:2)1(cid:13) ∧ cwhere we write c =1(cid:13) ∈ diff 1S(cid:2)(cid:3)(cid:2).(cid:13)I, K∀l > r . c =1(cid:13)∧ c<1(cid:3)(cid:13)l c(cid:13) (cid:2)1r c(cid:13)r c∃c ∈ diff 1S (I, K) . ∀Il c(cid:13) ∈ 2 A . ∀cl c, and we write c(cid:3)(cid:3)(cid:2)(cid:2)(cid:13) ∈ diff 1S(cid:13)I, K(cid:13)c, c.(cid:2)∈ lex(cid:13) <1r c for cr c ∧ c (cid:2)1(cid:2)(cid:3)(cid:13)c∨. But this is nothing else than saying(cid:3), c(cid:2)/∈ lexk , . . . , (cid:2)1(cid:2)1(cid:3)0(cid:2)1k , . . . , (cid:2)10and thus, since I moreover satisfies the integrity constraints C , we have(cid:4)I ∈(cid:3)confl2(cid:2)K1, . . . , Kn; C; diff 1(cid:2)S , lexC.6. Proof of Proposition 4(cid:3)(cid:3)(cid:5)(cid:2)1k , . . . , (cid:2)10As an example, we show (46); the proof of (47) is entirely analogous.Note that I ∈ (cid:2)(cid:3)priorcard (K1, . . . , Kn)(cid:3) is equivalent to(cid:16)(cid:7)∃ J 1, . . . , Jn ∈ 2 A . I ∪J @sii|(cid:7)Pref card(P )which means that for some B ∈ Pref card(P )∃ J 1, . . . , Jn ∈ 2 A . I ∪J @sii|(cid:7) Bi(cid:16)iLet us write Bl for the formulas from B that appear in Msi for some i with weight λl. The fact that B is a cardinality-J i |(cid:7) K i (sincebased preferred subtheory means that I |(cid:7) C (since the integrity constraints C are assumed to be consistent),each knowledge base is assumed to be individually consistent), and furthermore, that there can be no r ∈ {0, . . . , k} and(cid:13)(cid:13), JIl forthe set of formulas which appear in P with weight λl and that are satisfied by I. Using Proposition 1, we findthat:| = |Bl| for all l > r, where we write B|(cid:7) K i and such that |Br| < |B∈ 2 A such that I| while |B(cid:13)1, . . . , J(cid:13) |(cid:7) C ,(cid:13) @sii(cid:13) ∪i J(cid:14)(cid:13)n(cid:13)r(cid:13)l(cid:13)iJ|Bl| =(cid:4)(cid:4) =(cid:4)(cid:4)B(cid:13)l(cid:27)(cid:4)(cid:4) J i \ (cid:14)I(cid:15)(cid:4)(cid:18)(cid:17)(cid:4) Ji(cid:27)\I(cid:13)(cid:13)i(cid:4)(cid:4) +W l(cid:4)(cid:4) +W l(cid:4)(cid:4)I \ (cid:14) J i(cid:15)(cid:4)(cid:18)(cid:17)(cid:4)I(cid:13) \J(cid:13)i(cid:4)(cid:4) +(cid:4)(cid:4)[I]Xl(cid:4)(cid:4) +(cid:4)(cid:30)(cid:4)IXl(cid:13)(cid:4)(cid:4)(cid:4)(cid:4) +(cid:4)(cid:4)[ J i](cid:4)(cid:30)(cid:4)(cid:4)(cid:4) +Y l \ J i(cid:31)\ J(cid:13)iY lZ l \ I(cid:31)(cid:13)iJ\ IZ l(cid:4)(cid:4)(cid:13)iIn other words,|Bl| = d1l (I, K),|B(cid:13)l| = d1l(cid:2)(cid:3)(cid:13)I, KFrom which we immediately find that I being a model of a cardinality-based preferred subtheory is equivalent to the fact(cid:13) (cid:2)1 I while I (cid:2)1 Ithat there cannot be an interpretation I, or in other words, I ∈ (cid:2)(cid:3)dist(K1, . . . , Kn; C; (cid:2)1)(cid:3).such that I(cid:13)(cid:13)C.7. Proof of Proposition 5As an example, we show (52)–(54). The proof of (49)–(51) is analogous.First, note that I ∈ (cid:2)(cid:3)confl2 (K1, . . . , Kn; C; diff 2S (I, K) such that for every I(cid:2)k , . . . , (cid:2)2S , par((cid:2)2(cid:3)diff 2(cid:13) ∈ (cid:2)C(cid:3), we have either for every i ∈ {0, . . . , n} and l ∈ {0, . . . , k}0))(cid:3) means that I ∈ (cid:2)C(cid:3) and that there is a (cid:14)c1, . . . , cn(cid:15) ∈ci ⊆ diff 2Sl(cid:13)I, K iS. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551849or for at least one i ∈ {0, . . . , n} and l ∈ {0, . . . , k}(cid:3)(cid:2)(cid:13)I, K i(cid:3) cidiff 2SlFurthermore, by construction, each ci corresponds to a modelK1, . . . , Kn such that for all models J(cid:13)1, . . . , J(cid:13)n of K1, . . . , Kn, it holds that either for every i ∈ {0, . . . , n} and l ∈ {0, . . . , k}J i of K i . Thus, we have that there exist models J 1, . . . , Jn ofdiff aW l (I, J i) ∪ diff b(cid:3)(cid:2)⊆ diff aI(cid:13)(cid:13)iY l (I, J i) ∪ diff dXl (I, J i) ∪ diff cZ l (I, J i)(cid:3)(cid:2)(cid:3)(cid:2)(cid:13)∪ diff d∪ diff c∪ diff b, JIiZ lY lXl(cid:13)iI(cid:13)(cid:13), Jor for some i ∈ {0, . . . , n} and l ∈ {0, . . . , k}, JW l(cid:3)(cid:2)(cid:13)I, J(cid:13)i(cid:2)(cid:13)I(cid:3)(cid:13)idiff aW l(cid:3) diff a∪ diff b∪ diff c∪ diff d, J, J, JIIIXlY lZ lY l (I, J i) ∪ diff dXl (I, J i) ∪ diff cW l (I, J i) ∪ diff b(cid:2)(cid:13)(cid:3)(cid:13)i(cid:2)(cid:13)(cid:3)(cid:13)i(cid:2)(cid:3)(cid:13), J(cid:13)iZ l (I, J i)Using Proposition 1, we find that this is equivalent to stating that the set B(I, J 1, . . . , Jn) of formulas from Ms1(cid:13)that are satisfied by I ∪ J @s1n) of formulas from Ms1(cid:13)that are satisfied by I1is not properly included in the set B(I@sn .∪ · · · ∪ J @snn(cid:13)@s1 ∪ · · · ∪ JnWe now show (52), (53) and (54).(cid:13)1, . . . , J1(cid:13) ∪ J(cid:13), J∪ · · · ∪ Msn∪ · · · ∪ Msn1. The fact that B(I, J 1, . . . , Jn) (cid:17)⊂ B(I(cid:13), J(cid:13)n) means thatB(I, J 1, . . . , Jn) ⊇ B(cid:13)I, J(cid:13)1, . . . , Jor B(I, J 1, . . . , Jn) (cid:3) B(cid:2)(cid:13)I, J(cid:13)1, . . . , J(cid:13)n(cid:3)(cid:2)(cid:13)1, . . . , J(cid:3)(cid:13)nNow due to the structure of the possibilistic knowledge bases Msi and the choice of the ordering on Λ, for (α, λ(l,s,a))and (α(cid:13), λ(l(cid:13),s(cid:13),a(cid:13))) in Ms1λ(l,s,a) (cid:2) λ(l(cid:13),s(cid:13),a(cid:13))∪ · · · ∪ Msn , it holds thatimplies α → α(cid:13)(C.3)∪In particular, this means that whenever a formula α is satisfied which appears with weight λ(l,s,a)in Ms1(cid:13)· · · ∪ Msn , all formulas with a higher weight are also satisfied. Therefore, B(I, J 1, . . . , Jn) ⊇ B(In) is the(cid:13)same as B(I, J 1, . . . , Jn) (cid:4) B(In) (cid:17)(cid:4)B(I, J 1, . . . , Jn). Since I ∈ (cid:2)(cid:3)poss(K1, . . . , Kn)(cid:3) is equivalent to saying that I ∈ (cid:2)C(cid:3) and there exist models J i ∈ (cid:2)K i(cid:3) such(cid:13)n) (cid:17)(cid:4) B(I, J 1, . . . , Jn),that for all Ithe stated follows.(cid:13)n), and B(I, J 1, . . . , Jn) (cid:3) B(I∈ (cid:2)K i(cid:3), B(I, J 1, . . . , Jn) (cid:4) B(I(cid:13)n) is the same as B(I(cid:13)1, . . . , J(cid:13)(cid:13), J1, . . . , J(cid:13) ∈ (cid:2)C(cid:3) and all models J(cid:13)n) or B(I(cid:13)1, . . . , J(cid:13)1, . . . , J(cid:13)1, . . . , J(cid:13)1, . . . , J(cid:13), J(cid:13), J(cid:13), J(cid:13), J(cid:13), J(cid:13)i∪ · · · ∪ J @sn2. It is straightforward to construct a linearization κ such that the set B(I, J 1, . . . , Jn) is a preferred subtheory of κ(P(cid:13)).Indeed, it suffices to rank the weights such that κ(λ(l,s,a)) > κ(λ(l(cid:13),s(cid:13),a(cid:13))) whenever the formula with weight λ(l,s,a)appears in B(I, J 1, . . . , Jn) and the formula with weight λ(l(cid:13),s(cid:13),a(cid:13)) does not. The fact that such a linearization can alwaysbe obtained follows straightforwardly from (C.3). Conversely, it is furthermore clear that for every linearization κ , and(cid:13)), it holds that the set B(I, J 1, . . . , Jn) is a maximalevery model I ∪ J @s11∪ · · · ∪ Msn . In other words, there is a one-on-one correspondence between theconsistent subset of formulas from Ms1models of Pref ⊆(P(cid:13)).(cid:13)) ⊆3. By construction we already have Pref card(P(cid:13)) with weight l, and let Bl(cid:13)). Now let B ∈ Pref ⊆(PPref card(P(cid:13)) be l1 < · · · < lr .the formulas outside B that appear in κ(PWithout lack of generality, we may assume that l1 > 0, since only the relative ordering of these weights is important.We now construct a new linearization κ (cid:13)(cid:13)) and let Bl be the formulas from B that appear in κ(P(cid:13)) with weight l. Let the different weights appearing in κ(P(cid:13)). To show (54), it therefore suffices to show Pref ⊆(Pof a preferred subtheory of κ(P(cid:13)) and those of Pref (cid:2)(P(cid:13)) ⊆ Pref ⊆(Pas follows:nκ (cid:13)(λ(l,s,a)) =lili+li−12if the unique formula from P(cid:13)with weight λ(l,s,a) is in Botherwisewhere li = κ(λ(l,s,a)) and l0 = 0 < l1. By construction, B is still a preferred subtheory of κ (cid:13)(Ppriority level l in κ (cid:13)(Pconsequence, B is also a cardinality-based preferred subtheory of κ (cid:13)(P(cid:13)). Moreover, for each(cid:13)) it holds that either all formulas belong to B or none of these formulas belong to B. As a(cid:13)).C.8. Proof of Proposition 6As an example, we show (59), the proof of (60) being analogous. If I ∈ (cid:2)(cid:3)pen(K1, . . . , Kn)(cid:3), we have I ∈ (cid:2)C(cid:3) and forsome models J i ∈ (cid:2)K i(cid:3) we have B(I, J 1, . . . , Jn) ∈ Pref pen(Q ), with B(I, J 1, . . . , Jn) the formulas from Q that are satisfiedby I ∪ J @s1. By construction, all formulas that appear in Q with weight +∞ are contained in B(I, J 1, . . . , Jn)(which is the case exactly when I ∈ (cid:2)C(cid:3) and J i ∈ (cid:2)K i(cid:3) for all i). Let us write Bl(I, J 1, . . . , Jn) for the set of formulas in(cid:13) ∈ (cid:2)C(cid:3) such that for some modelsB(I, J 1, . . . , Jn) that have weight λl in Q . Now suppose that there was an interpretation I(cid:13)(cid:13)n)| > |Bk(I, J 1, . . . , Jn)|. Then we haveJi∈ (cid:2)K i(cid:3), |Bk(I∪ · · · ∪ J @sn(cid:13)1, . . . , J(cid:13), J1n 1850S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855(cid:27)(cid:5)(cid:27)(cid:5)ppwhere(cid:4)(cid:6)(cid:4) (α, p) ∈ Q , α /∈ Bk(I, J 1, . . . , Jn)(cid:4)(cid:3)(cid:6)(cid:4) (α, p) ∈ Q , α /∈ Bk(cid:13)1, . . . , J, J(cid:13)n(cid:2)I(cid:13)= γkrk + γk−1rk−1 + · · · + γ0k−1rk−1 + · · · + γ (cid:13)= γ (cid:13)krk + γ (cid:13)0(cid:4)(cid:4)(cid:4)Bl(I, J 1, . . . , Jn)(cid:4),(cid:13), J(cid:13)1, . . . , Jγl =From |Bk(I(cid:13), JBk(Iγk−1rk−1 + · · · + γ0, this is trivial. On the other hand, if γ (cid:13), JIn)| > |Bk(I, J 1, . . . , Jn)| we thus know that γ (cid:13)(cid:13)(cid:13)1, . . . , J(cid:19){p | (α, p) ∈ Q , α /∈ Bk(I, J 1, . . . , Jn)} as soon as r is sufficiently large. Indeed, if γ (cid:13)(cid:13)n)} >k > γk, which implies that(cid:13)1, . . . , Jk−1rk−1 + · · · + γ (cid:13)(cid:4)(cid:4)Blγ (cid:13)(cid:3)(cid:4)(cid:4)(cid:19)=(cid:13)n(cid:2)(cid:13)l0 < γk−1rk−1 + · · · + γ0, it suffices to choose{p | (α, p) ∈ Q , α /∈k−1rk−1 + · · · +γ (cid:13)(cid:3)0!r > k(γk−1rk−1 + · · · + γ0) − (γ (cid:13)− γkγ (cid:13)kk−1rk−1 + · · · + γ (cid:13)0)(cid:13)(cid:13)We may proceed in entirely the same fashion when |Bl(I1, . . . ,1, . . . , J(cid:13)n)| > |Bl0 (I, J 1, . . . , Jn)|. Thus, provided that r is sufficiently large, B(I, J 1, . . . , Jn) is minimal w.r.t. (cid:2)p iff B(I, J 1, . . . , Jn) ∈J(cid:3)priorcard , from which the stated immediately follows.(cid:13)n)| = |Bl(I, J 1, . . . , Jn)| for all l > l0 and |Bl0 (I(cid:13), J(cid:13), JC.9. Proof of Proposition 7∈ (cid:2)K i(cid:3), it holds that B(I, J 1, . . . , Jn) (cid:2)p B(IAs an example, we show (61); (62) is shown entirely analogously.The fact that I ∈ (cid:2)(cid:3)pen(K1, . . . , Kn)(cid:3) means that I ∈ (cid:2)C(cid:3) and there exist models J i ∈ (cid:2)K i(cid:3) such that the subset(cid:13) ∈ (cid:2)C(cid:3) and(l,si ,a), p) /∈ B(I, J 1, . . . , Jn)(l,si ,a), p), and for(cid:13)1, . . . , JW l , and similar for formulas of the form (α Xn(cid:13)n). From Proposition 1, we know that (α WB(I, J 1, . . . , Jn) of formulas from Q that are satisfied by I ∪ J @s1(cid:13)Jiis equivalent to a ∈ J i \ (cid:14)I(cid:15)(cid:13)(cid:13)n). Thus, we immediately haveB(I1, . . . , J(cid:27)(cid:5)(cid:4)(cid:6)(cid:4) (α, p) ∈ Q , α /∈ B(I, J 1, . . . , Jn)is preferred, i.e. for any other I(l,si ,a), p) and (α Z(l,si ,a), p), (αY∪ · · · ∪ J @snQ (I, J 1) + · · · + dnQ (I, J 1)= d1(cid:13), J(cid:13), Jp1and consequently, that I (cid:2)d1Q(cid:13)(cid:13), JB(I, J 1, . . . , Jn) (cid:2)p B(I1, . . . , JIiff there exist models J i ∈ (cid:2)K i(cid:3) such that for all models I(cid:13)n). In other words, we have that I ∈ (cid:2)(cid:3)dist(K1, . . . , Kn; C; (cid:2)d1Q(cid:13) ∈ (cid:2)C(cid:3) and J∈ (cid:2)K i(cid:3) it holds that)(cid:3) iff I ∈ (cid:2)(cid:3)pen(K1, . . . , Kn)(cid:3).(cid:13)i(cid:13)C.10. Proof of Proposition 81. Let us first consider the case of (cid:3)poss with linear weights. Membership in Θ P2 follows straightforwardly from the factthat deciding whether Kinc(K ) |(cid:7) φ for a possibilistic knowledge base K and propositional formula φ is in Θ P2 (see [71]).We show Θ P2 -hardness by reduction from PARITY(SAT) [47,72]. Given n instances S 1, . . . , Sn of the boolean satisfia-bility problem SAT, the problem PARITY(SAT) consists of deciding whether the number of satisfiable instances amongS1, . . . , Sn is odd. This problem is Θ P2 -hard, even under the assumption that the instances are such that whenever S i isunsatisfiable, S i+1, . . . , Sn are unsatisfiable as well. We will now show that this problem, under the latter assumption,can be reduced to the problem of deciding (cid:3)poss(K1, . . . , Kn; C; Ms1 , . . . , Msn ) |(cid:7) φ in polynomial time.Let us choose K i = S i ∪ {ai} for all i ∈ {1, . . . , n}, where a1, . . . , an are atoms which do not occur in any of the instancesS1, . . . , Sn. Furthermore, we choose C = ∅, and the weighted knowledge bases Msi such that(cid:28)(cid:15)×∈{W , X,Y , Z }α×(l,si ,a)≡(cid:19)(a@si ≡ a) otherwiseif l > k − i + 1= λl for some λl ∈ [0, 1]. Clearly, P λk is satisfiable iff S1 is satisfiable, P λk−1The weights are chosen such that λis satisfiable iff S1 ∪ S2 is satisfiable, which, due to the assumption on the instances S i , is equivalent to the conditionthat S2 is satisfiable. In general, we find that P λk−i is satisfiable iff S i+1 is satisfiable. By taking φ = (a1 ∧ ¬a2) ∨ (a3 ∧¬a4) ∨ · · · we have that (cid:3)poss(K1, . . . , Kn; C; Ms1 , . . . , Msn ) |(cid:7) φ iff the number of λs in {λ1, . . . , λk} for which P λ issatisfiable is odd, which is in turn equivalent to the fact that an odd number among S 1, . . . , Sk are satisfiable.×(l,si ,a)2. Next, we consider (cid:3)poss with partially ordered weights. To prove membership in Π P2 , we provide a Σ P2 procedure forchecking(cid:3)poss(K1, . . . , Kn; C; Ms1 , . . . , Msn ) (cid:17)|(cid:7) φ∗• Guess a subset K of P• Verify that K is consistent using one call to the NP oracle;;S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551851(cid:13)(cid:13)(cid:13)(cid:13)∗• Verify that K (cid:17)|(cid:7) φ using one call to the NP oracle;• Verify that K is minimal w.r.t. (cid:4). First, construct in polynomial time a minimal subset K, by removing from K all formulas (α, λ) such that for some (α(cid:13), λ(cid:13)) ∈ (P(cid:13) (cid:4) K and. It is clear(cid:13). To verifycontains no formula with weight λ, and, inleads to an inconsistent subset. Clearly, theof K such that K∗ \ K ), it holds that λ (cid:2) λ(cid:13)will then lead to a subset which is strictly less preferred than K or KK (cid:4) Kthat removing any formula from Kthat K is minimal, it now suffices to consider all weights λ such that K(cid:13)each case, check whether adding all formulas (α, λ(cid:13)) with λ(cid:13) (cid:3) λ to Knumber of required satisfiability checks is at most polynomial in the size of P.To show that entailment checking for (cid:3)poss with partially ordered weights is Π P2 -hard, we provide a reduction fromquantified boolean formula problems of the form ∀a . ∃b . F (a, b).= {ai, ⊥}Define K1 = {a1, . . . , am, c}, K2 = {¬a1, . . . , ¬am}, C = {F (a, b) ≡ c}, k = 1, W 1ai= {c, ⊥}. Let P be defined in terms of K1, K2, C, Ms1 and Ms2 as before, and letand W 1cthe ordering on Λ be defined as in Proposition 5. It is clear that for any (cid:4)-preferred subset B, and for every i, we(cid:13) =either have B |(cid:7) ai or B |(cid:7) ¬ai . Indeed, if neither B |(cid:7) ai nor B |(cid:7) ¬ai we could construct a new consistent subset B(cid:13) (cid:4) B but not B (cid:4) B(cid:13) |(cid:7) ai and BB ∪{α W. Furthermore, it is clear that for any subset A0 ⊆}, for which it holds that B∗{a1, . . . , am} there exists a consistent subset B of Psuch that B |(cid:7) ai if ai ∈ A0 and B |(cid:7) ¬ai otherwise. We furthermorehave B |(cid:7) c for such a minimal subset B iff α W∈ B in which case we also have B |(cid:7) F (a1, . . . , am, b1, . . . , br). Due∈ B will hold as soon as there exists a truth valuation for the atoms b1, . . . , brto the minimality of B w.r.t. (cid:4), α Wwhich makes F (a1, . . . , am, b1, . . . , br) true, given that the atoms in A0 are true and those in {a1, . . . , am} \ A0 are not.Thus, we can conclude that (cid:3)poss(K1, K2; C; Ms1 , Ms2 ) |(cid:7) F (a1, . . . , am, b1, . . . , br) iff B |(cid:7) F (a1, . . . , am, b1, . . . , br) forevery (cid:4)-preferred B, which is equivalent to ∀a1, . . . , am . ∃b1, . . . , br . F (a1, . . . , am, b1, . . . , br).Note that using Proposition 5, it follows from this result that also the following decision problems are Π Pthe weights are partially ordered:= {ai, (cid:19)} and Y 1ai= {c, (cid:19)} and Y 1c2 -hard when= X 1ai= Z 1ai= X 1c= Z 1c(0,s1,ai )(0,s1,c)(0,s1,c)(cid:13)(cid:3)prior⊆ (K1, . . . , Kn; C; Ms1 , . . . , Msn ) |(cid:7) φ(cid:3)priorcard (K1, . . . , Kn; C; Ms1 , . . . , Msn ) |(cid:7) φ(C.4)(C.5)3. For the operator (cid:3)prior⊆ with linear weights, membership in Π P2 follows from the Π PUNI-INCL considered in [73]. The Π Pchecking for (cid:3)poss with partially ordered weights.2 -hardness is shown in entirely the same way as the Π P2 -completeness of the problem2 -hardness of entailment4. Entailment checking for (cid:3)prior⊆ with partially ordered weights is Π Pcase where all weights are totally ordered. Membership in Π Pin Σ P2 . Indeed, to decide whether2 -hard, which follows by restricting to the special2 is proven by showing that the complement problem is(cid:3)prior⊆ (K1, . . . , Kn; C; Ms1 , . . . , Msn ) (cid:17)|(cid:7) φ2 procedure (inspired by the Π Pwe may use the following Σ P• Guess a linearization κ ;• Guess a subset K of κ(P 0);• Verify that K is consistent by calling the NP oracle;• Verify that K (cid:17)|(cid:7) φ by calling the NP oracle;• Verify that K is preferred w.r.t. inclusion. For this step, let λ1 < · · · < λr ∈ [0, 1] be the weights that appear in κ(P ):2 -hardness proof of PBR revision [74]):\ K , check that (K ∩ P λr ) ∪ {φ} is inconsistent;– For each formula φ in P λr– For each formula φ in P λr−1– . . .– For each formula φ in P λ1Clearly, the number of calls to the NP oracle is at most linear in the number of formulas in P .\ (K ∪ P λr ), check that (K ∩ P λr−1 ) ∪ {φ} is inconsistent;\ (K ∪ P λ2 ), check that K ∪ {φ} is inconsistent;5. Membership in (cid:3)P2 of entailment checking for (cid:3)priorcard with linearly ordered weights follows from the (cid:3)P2 -completenessof the UNI-LEX problem considered in [73]. We show hardness by reduction from the problem ALM, following an anal-ogous approach as the proof of (cid:3)P2 -hardness in [73]. Given a satisfiable set of clauses Ψ over the variables a1, . . . , an,(cid:13) ∩ {a1, . . . , ai},models of Ψ can be ordered as follows: I (cid:2) Iai+1 /∈ I and ai+1 ∈ I. ALM is then the problem of deciding whether the model I of Ψ that is maximal w.r.t. thisordering makes an true.= {ai} for i (cid:2) n − lIn particular, let C = Ψ , K1 = {a1, . . . , an}, and k = n − 1. We furthermore define W lai= {ai, ⊥} otherwise. Then there is only one preferred subset of P according toand W laiwhich it will first be tried to satisfy a1, then a2, etc. Thus we find that (cid:3)priorcard (K1; C; Ms1 ) |(cid:7) an iff the maximal modelof Ψ in the sense described above is such that an is true.or there is an i such that I ∩ {a1, . . . , ai} = I= {ai, (cid:19)} and Y laiiff I = I= Xlai= Xlai= Z lai= Z lai= Y lai(cid:13)(cid:13)(cid:13)6. For partially ordered weights, the fact that entailment checking for (cid:3)priorcard is Π P2 -hard was already established in (C.5).2 follows analogously as for (cid:3)prior⊆ , using the fact that the MAX-GSAT-ARRAY problem consideredMembership in Π Pin [73] is NP-complete.1852S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855(cid:19)i∗∗∗∗exists with pen(B) = p7. Finally, let us consider the problem of checking entailment for (cid:3)pen. Let m =(α,p)∈Q , p<+∞ p. By construction, theonly formulas in Q with weight +∞ are those in the knowledge bases K @siand C , which together are consistent byassumption. This means that the optimal consistent subsets of Qwill have a penalty which is at most m. Checkingsuch that pen(B) (cid:2) p for a given p is clearly in NP. Using a number ofwhether there exists a consistent subset B of Qsuch that a consistent subset Bcalls to an NP-oracle which is logarithmic in m, we can thus find the smallest value p. To decide (cid:3)pen(K1, . . . , Kn; C; Ms1 , . . . , Msn ) |(cid:7) φ it then suffices to verify whether B |(cid:7) φof Q∗for all consistent subsets of Q. This can be done in coNP; indeed, the complement can beand that I (cid:17)|(cid:7) φ. This means that overall, we have ashown by guessing an interpretation I , verifying that pen(I) = pprocedure which takes polynomial time on a deterministic machine, and makes a number of calls to an NP oracle whichis logarithmic in m. Hence, if the penalties are bounded by an exponential function of the problem size, then log(m) ispolynomial in the problem size, yielding membership in (cid:3)P2 , and if the penalties are bounded by a polynomial function,then log(m) is logarithmic in the problem size, yielding membership in Θ P2 .In the case of exponentially bounded penalties, hardness follows from Proposition 6 and the fact that entailment check-ing for (cid:3)priorcard with linear weights was shown to be (cid:3)P2 -hardness is the case of polynomiallybounded penalties follows from the Θ P2 -completeness of distance-based merging with the Hamming distance and thesum as aggregation operator [9]. Indeed, by restricting to the case k = 0, we know from Proposition 7 that (cid:3)pen degen-erates to standard Hamming-distance based merging.2 -complete. The Θ Pfor which pen(B) = p∗∗∗C.11. Proof of Proposition 91. Membership of |≈∃⊆ and |≈∃card in Σ P2 follows from the Σ P2 -completeness of the EXI-INCL and EXI-LEX problems studiedin [73]. To show hardness, we give a reduction from quantified boolean formula problems of the form ∃a . ∀b . F (a, b).In particular let K1 = {a1, . . . , am}, K2 = {¬a1, . . . , ¬am}, C = ∅, λ= {ai, (cid:19)} and= {ai, ⊥}. Then it is easy to see that there is a preferred subtheory B such that B |(cid:7) F (a, b) iff the QBFY 1ai∃a . ∀b . F (a, b) is satisfied. Moreover, all preferred subtheories will satisfy exactly half of the formulas that appear inMs1 and Ms2 with weight λ0, and all formulas that appear with weight λ1 (as the latter are all trivial). As a consequencethe hardness results holds both for |≈∃= λl ∈ ]0, 1[, k = 1, and W 1ai= X 1ai= Z 1ai×(l,s,a)⊆ and |≈∃2. Σ P2 membership of |≈∃∃⊆ and |≈∃∃card is shown in the same way as for |≈∃⊆ and |≈∃card. Hardness follows immediately bycard.restriction to the linearly ordered case.3. Membership of |≈∃∀⊆ in Σ PB ∈ Pref card(κ(P )) using a Σ Pform ∃a . ∀b . ∃c . H(a, b, c). Consider knowledge bases3 is straightforward: guess a linearization κ and verify whether the entailment holds for all2 oracle. Hardness is shown by reduction of quantified boolean formula problems of theK1 = {a1, . . . , am, b1, . . . , br, z}K2 = {¬a1, . . . , ¬am, ¬b1, . . . , ¬br}C =(cid:6)z ≡ H(a, b, c)(cid:5)+×(0,s2,ai )and W 1xλ= {x, ⊥} for all atoms x. Furthermore, let us take λ= Z 1= {x, (cid:19)} and Y 1= X 1xxx×+= λ= λ, λ, λ(0,s j ,bi )ii < λ∗for all i, and the weights λfor all atoms x,××= μ, where the ordering on the weights is such that μ <(0,s1,ai )(0,s1,z)−+j are all incomparable for i (cid:17)= j. Then it is clear that any choice fori , λλthe truth values of the atoms ai is enforced by some specific linearization, and thus that (K 1, . . . , Kn) |≈ H(a, b, c) iffthere is a choice of truth values for the atoms ai such that H(a, b, c) is consistent with every choice of truth values forthe atoms bi , or indeed iff ∃a . ∀b . ∃c . H(a, b, c) is satisfiable.= μ and λ+−−j , λ, λii, λ−iholds for all B ∈ Pref card(κ(P )). The complexity of this last step is (cid:3)Ppolynomial time using an NP-oracle. Hardness is shown by takingcard follows from the following procedure: guess a linearization κ and verify that the entailment2 (see Proposition 8), hence it can be performed in4. Membership of |≈∃∀×(1,s,x)= λ∗K1 = {a1, . . . , am},K2 = {¬a1, . . . , ¬am},C = ∅×(1,s,ai )= Z 1ai= X 1ai= {a, (cid:19)} and Y 1ai= {a, ⊥}. Furthermore, let λis incomparable to λ j for i (cid:17)= j. Then every choice of truth values for the atoms ai= λi such that λi < λ∗and W 1andaiλiis enforced by some specificlinearization, hence we clearly have that ∃a . ∀b . F (a, b) iff there is a linearization κ such that B |(cid:7) F (a, b) for everyB ∈ Pref card(κ(P )).5. Membership in Π P3 for |≈∀∃3 . Indeed, it suffices toguess a linearization κ and then use a Σ P2 oracle to verify wether for every preferred subtheory B of κ(P ), it is thecase that B (cid:17)|(cid:7) φ. This is not the case if ∃B ∈ Pref ⊆(κ(P )) . B |(cid:7) φ, and verifying this latter expression was already shownto be in Σ PTo show Π P2 (in the first item). For the same reason, we have that |≈∀∃3 -hardness we simulate QBFs of the form ∀a . ∃b . ∀c . H(a, b, c). The knowledge bases here are chosen as⊆ is easily seen, by showing that the complement problem is in Σ Pcard is in Π P3 .= λ∗and λ×(0,s,ai )S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551853K1 = {a1, . . . , am, b1, . . . , br}K2 = {¬a1, . . . , ¬am, ¬b1, . . . , ¬br}C = ∅where the weights and the families W l⊆ . Again we havethat every choice of the truth values of the atoms ai is enforced by some linearization κ . Given such a linearization κ ,each preferred subtheory corresponds to a choice of the truth values of the atoms bi . Hence, we have (K1, . . . , Kn) |≈∀∃⊆H(a, b, c) iff ∀a . ∃b . ∀c . H(a, b, c) holds. Since every preferred subtheory satisfies the same number of formulas at eachpriority level, Π Px are defined as in the hardness proof of |≈∃∀x and Z lx, Xlx, Y l3 -hardness for |≈∀∃card follows as well.C.12. Proof of Proposition 10As an example, we show (B.1), the proof of (B.2) being entirely analogous. Since clearly forgetVar(Φ1 ∨ Φ2, X) ≡forgetVar(Φ1, X) ∨ forgetVar(Φ2, X), it suffices to show that for every B ∈ Pref (P ), we have(cid:2)forgetVarB, A@s1 ∪ · · · ∪ A@sn(cid:3)≡ K B1∪ · · · ∪ K Bn∪ CLet us write B i for the formulas from Msi that are contained in B. We then findforgetVar(cid:3)(cid:2)B, a@si∧ · · · ∧ K≡ K @s11∧ C ∧ forgetVar@si−1i−1(cid:2)∧ K@si+1i+1∧ B i, a@si(cid:3)K @sii∧ · · · ∧ K @snn∧ B1 ∧ · · · ∧ B i−1 ∧ B i+1 ∧ · · · ∧ Bnisince only K @siand B i contain occurrences of a@si . Without lack of generality, we may assume that K @siis of the formi{αi ∨ a@si | 1 (cid:2) i (cid:2) s} ∪ {βi ∨ ¬a@si | 1 (cid:2) i (cid:2) t} ∪ Φ, where none of the formulas αi , βi or the formulas in Φ contain occurrences(cid:12)a and ¬a@si →of a. Moreover, note that the only non-trivial formulas in B i that contain occurrences of a@si are a@si →(cid:12)(cid:13) (cid:3) w(a, si, Y ; B); let Ψ be the set of formulas from B i which do not refer to} for r (cid:3) w(a, si, W ; B) and r{¬ y | y ∈ Y raW r(cid:13)a@si . We find(cid:2)(cid:3)K @si∧ B i, a@sii(cid:30)(cid:31)a@si := (cid:19)∧ B i(cid:15)Φ ∧βi ∧(cid:15)Φ ∧βi ∧≡forgetVar(cid:2)K @sii(cid:20)t(cid:15)≡(cid:20)i=1t(cid:15)i=1≡≡≡(cid:15)(cid:15)(cid:15)(cid:15)Φ ∧Φ ∧(cid:30)a@si := (cid:19)(cid:31)(cid:3)∨(cid:2)K @sii(cid:30)(cid:31)a@si := ⊥(cid:20)(cid:21)∧ B is(cid:15)(cid:30)a@si := ⊥(cid:31)(cid:3)k(cid:15)(cid:7)W ra∧(cid:15)Ψ∨(cid:15)Φ ∧k(cid:15)(cid:7)(cid:5)(cid:6)(cid:4)(cid:4) y ∈ Y ra∧¬ y(cid:15)Ψαi ∧(cid:21)r=w(a,si,W ;B)(cid:7)W w(a,si ,W ;B)a(cid:15)∧Ψs(cid:15)i=1αi ∧(cid:15)Φ ∧(cid:7)(cid:5)r=w(a,si,Y ;B)(cid:4)(cid:4) y ∈ Y w(a,si ,Y ;B)¬ ya(cid:21)(cid:15)(cid:6)∧Ψ(cid:21)(cid:20)∨(cid:21)(cid:20)(cid:20)t(cid:15)(cid:7)βi ∧Ψ ∧W w(a,si ,W ;B)a∨i=1(cid:20)s(cid:15)(cid:7)(cid:5)(cid:4)(cid:4) y ∈ Y w(a,si ,Y ;B)a(cid:6)¬ yαi ∧(cid:21)(cid:21)i=1s(cid:15)(βi ∨ α j) ∧t(cid:15)Ψ ∧t(cid:15)(cid:9)(cid:7)(cid:5)βi ∨i=1(cid:4)(cid:4) y ∈ Y w(a,si ,Y ;B)a¬ y(cid:6)(cid:10)i=1j=1W w(a,si ,W ;B)a∨ αi(cid:10)∧s(cid:15)(cid:9)(cid:7)∧j=1i=1(cid:9)(cid:7)W w(a,si ,W ;B)a(cid:7)(cid:5)∨(cid:4)(cid:4) y ∈ Y w(a,si ,Y ;B)a¬ y(cid:6)(cid:10)(cid:12)(cid:12)W w(a,si ,W ;B). Further-Note thatmore, for each i and j, we have that Φ contains a formula which is equivalent to βi ∨ α j , from the assumption that K i isequal to its set of prime implicates. This leads toaaaa{¬ y | y ∈ Y w(a,si ,Y ;B)} is trivially satisfied since a ∈ W w(a,si ,W ;B)and a ∈ Y w(a,si ,Y ;B)∨(cid:15)(cid:15)t(cid:15)(cid:9)(cid:7)(cid:5)(cid:4)(cid:4) y ∈ Y w(a,si ,Y ;B)a¬ yβi ∨(cid:6)(cid:10)∧Ψ ∧Φ ∧s(cid:15)(cid:9)(cid:7)W w(a,si ,W ;B)a∨ α j(cid:10)i=1j=1which corresponds exactly to replacing every occurrence of a positive literal a@si bya negative literal ¬a@si byleading to the stated equivalence.{¬ y | y ∈ Y w(a,si ,Y ;B)(cid:12)a}. This process can be repeated for all other atoms from A@s1and every occurrence of∪ · · · ∪ A@snn ,1(cid:12)W w(a,si ,W ;B)a1854S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855References[1] M. Abidi, R. Gonzalez, Data Fusion in Robotics and Machine Intelligence, Academic Press, 1992.[2] I. Matzkevich, B. Abramson, The topological fusion of Bayes nets, in: Proceedings of the Eighth Conference on Uncertainty in Artificial Intelligence,1992, pp. 191–198.[3] L. Cholvy, A logical approach to multi-sources reasoning, in: International Conference on Knowledge Representation and Reasoning Under Uncertainty,Logic at Work, 1994, pp. 183–196.[4] S. Benferhat, D. Dubois, H. Prade, How to infer from inconsistent beliefs without revising, in: IJCAI’95: Proceedings of the 14th International JointConference on Artificial Intelligence, 1995, pp. 1449–1455.[5] J. Lin, Integration of weighted knowledge bases, Artificial Intelligence 83 (2) (1996) 363–378.[6] L. Amgoud, S. Kaci, An argumentation framework for merging conflicting knowledge bases, International Journal of Approximate Reasoning 45 (2)(2007) 321–340.[7] R. Booth, Social contraction and belief negotiation, Information Fusion 7 (1) (2006) 19–34.[8] P. Revesz, On the semantics of theory change: arbitration between old and new information, in: Proceedings of the 12th ACM SIGACT-SIGMOD-SIGARTSymposium on Principles of Database Systems, 1993, pp. 71–82.[9] S. Konieczny, J. Lang, P. Marquis, DA2 merging operators, Artificial Intelligence 157 (1–2) (2004) 49–79.[10] I. Bloch, J. Lang, Towards mathematical morpho-logics, in: Technologies for Constructing Intelligent Systems, Physica-Verlag GmbH, 2002, p. 380.[11] D. Dubois, H. Prade, Possibility theory and data fusion in poorly informed environments, Control Engineering Practice 2 (1994) 811–823.[12] D. Dubois, H. Fargier, H. Prade, Multiple-sources informations fusion – a practical inconsistency-tolerant approach, in: Proc. 8th International Conferenceon Information Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU’00), Madrid, July 13–17, 2000, pp. 1047–1054.[13] G. Priest, Paraconsistent logic, in: Handbook of Philosophical Logic, vol. 6, Kluwer Academic Publishers, 2002, pp. 287–393.[14] W. Carnielli, M. Coniglio, J. Marcos, Logics of formal inconsistency, in: Handbook of Philosophical Logic, vol. 14, Springer, 2005, pp. 1–93.[15] P. Gärdenfors, Knowledge in Flux, MIT Press, 1988.[16] N. Rescher, R. Manor, On inference from inconsistent premisses, Theory and Decision 1 (1970) 179–217.[17] S. Konieczny, R. Pino Pérez, Merging information under constraints: a logical framework, Journal of Logic and Computation 12 (5) (2002) 773–808.[18] M. Dalal, Investigations into a theory of knowledge base revision: preliminary report, in: Proceedings of the 7th National Conference on ArtificialIntelligence, 1988, pp. 475–479.[19] C. Lafage, J. Lang, Propositional distances and compact preference representation, European Journal of Operational Research 160 (3) (2005) 741–761.[20] P. Everaere, S. Konieczny, P. Marquis, Conflict-based merging operators, in: Eleventh International Conference on Principles of Knowledge Representationand Reasoning (KR’08), 2008, pp. 348–357.[21] J. Serra, Image Analysis and Mathematical Morphology, Academic Press, 1982.[22] N. Gorogiannis, A. Hunter, Merging first-order knowledge using dilation operators, in: Proceedings of the 5th International Conference on Foundationsof information and knowledge systems, 2008, pp. 132–150.[23] J. Delgrande, T. Schaub, A consistency-based framework for merging knowledge bases, Journal of Applied Logic 5 (3) (2007) 459–477.[24] J. Lang, P. Marquis, Reasoning under inconsistency: A forgetting-based approach, Artificial Intelligence 174 (12–13) (2010) 799–823.[25] D. Dubois, J. Lang, H. Prade, Possibilistic logic, in: D.N.D. Gabbay, J. Robinson, C. Hogger (Eds.), Handbook of Logic in Artificial Intelligence and LogicProgramming, vol. 3, Oxford University Press, 1994, pp. 439–513.[26] P. Liberatore, Merging locally correct knowledge bases: A preliminary report, Tech. rep., Computing Research Repository (CoRR), arXiv:cs.AI/0212053,2002.[27] G. Pinkas, Propositional non-monotonic reasoning and inconsistency in symmetric neural networks, in: Proceedings of the 12th International JointConference on Artificial Intelligence, vol. 1, 1991, pp. 525–530.[28] F. Dupin de Saint-Cyr, J. Lang, T. Schiex, Penalty logic and its link with Dempster–Shafer theory, in: Proceedings of the 10th International Conferenceon Uncertainty in Artificial Intelligence, 1994, pp. 204–211.[29] Z. Pawlak, Rough sets, International Journal of Parallel Programming 11 (5) (1982) 341–356.[30] P. Gärdenfors, Conceptual Spaces: The Geometry of Thought, MIT Press, 2000.[31] C. Freksa, Conceptual neighborhood and its role in temporal and spatial reasoning, in: M. Singh, L. Travé-Massuyès (Eds.), Decision Support Systemsand Qualitative Reasoning, North-Holland, Amsterdam, 1991, pp. 181–187.[32] C. Freksa, Temporal reasoning based on semi-intervals, Artificial Intelligence 54 (1–2) (1992) 199–227.[33] D. Dubois, H. Prade, R. Yager, Merging fuzzy information, in: J. Bezdek, D. Dubois, H. Prade (Eds.), Fuzzy Sets in Approximate Reasoning and InformationSystems, in: The Handbooks of Fuzzy Sets Series, Kluwer, Boston, Mass., 1999, pp. 335–401.[34] D. Gabbay, O. Rodrigues, G. Pigozzi (Eds.), Journal of Logic and Computation, special issue on Connections between Belief Revision, Belief Merging andSocial Choice 19 (3) (2009).[35] F. Lin, R. Reiter, Forget it, in: Working Notes of AAAI Fall Symposium on Relevance, 1994, pp. 154–159.[36] G. Brewka, Preferred subtheories: An extended logical framework for default reasoning, in: Proc. of the 11th Int. Joint Conf. on, Artificial Intelligence,1989, pp. 1043–1048.[37] T. Eiter, G. Gottlob, The complexity of logic-based abduction, Journal of the ACM 42 (1) (1995) 3–42.[38] M. Goldszmidt, J. Pearl, Qualitative probabilities for default reasoning, belief revision, and causal modeling, Artificial Intelligence 84 (1–2) (1996)57–112.[39] W. Spohn, Ordinal conditional functions: A dynamic theory of epistemic states, Causation in Decision, Belief Change and Statistics 2 (1988) 105–134.[40] D. Dubois, H. Prade, Epistemic entrenchment and possibilistic logic, Artificial Intelligence 50 (2) (1991) 223–239.[41] S. Benferhat, D. Dubois, S. Kaci, H. Prade, Possibilistic merging and distance-based fusion of propositional information, Annals of Mathematics andArtificial Intelligence 34 (1–3) (2002) 217–252.[42] S. Benferhat, S. Lagrue, O. Papini, Reasoning with partially ordered information in a possibilistic logic framework, Fuzzy Sets and Systems 144 (1)(2004) 25–41.[43] A. Dempster, Upper and lower probabilities induced by a multivalued mapping, The Annals of Mathematical Statistics 38 (2) (1967) 325–339.[44] G. Shafer, A Mathematical Theory of Evidence, Princeton University Press, Princeton, NJ, 1976.[45] S. Konieczny, R. Pino-Pérez, On the frontier between arbitration and majority, in: Eighth International Conference on Principles of Knowledge Repre-sentation and Reasoning, 2002, pp. 109–120.[46] C. Papadimitriou, Computational Complexity, John Wiley and Sons Ltd., 2003.[47] T. Eiter, G. Gottlob, The complexity class (cid:20)p2 : Recent results and applications in AI and modal logic, in: Proceedings of the 11th International Sympo-sium on Fundamentals of Computation Theory, in: LNCS, vol. 1279, Springer, 1997, pp. 1–18.[48] W. Wahlster, Implementing fuzziness in dialogue systems, in: B. Rieger (Ed.), Empirical Semantics, Brockmeyer, Bochum, 1980.[49] A.H. Jucker, S.W. Smith, T. Lüdge, Interactive aspects of vagueness in conversation, Journal of Pragmatics 35 (12) (2003) 1737–1769.[50] D. Traum, A computational theory of grounding in natural language conversation, PhD thesis, University of Rochester, 1994.S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551855[51] M. Pickering, S. Garrod, Toward a mechanistic psychology of dialogue, Behavioral and Brain Sciences 27 (2) (2004) 169–190.[52] J. Lawry, Imprecise bipolar belief measures based on partial knowledge from agent dialogues, in: Scalable Uncertainty Management, in: Lecture Notesin Computer Science, vol. 6379, Springer, 2010, pp. 205–218.[53] J. Reggia, D. Nau, P. Wang, H. Peng, A formal model of diagnostic inference, Information Sciences 37 (1985) 227–285.[54] E. Ruspini, On the semantics of fuzzy logic, International Journal of Approximate Reasoning 5 (1991) 45–88.[55] S. Kraus, D. Lehmann, M. Magidor, Nonmonotonic reasoning, preferential models and cumulative logics, Artificial Intelligence 44 (1–2) (1990) 167–207.[56] D. Dubois, H. Prade, F. Esteva, P. Garcia, L. Godo, A logical approach to interpolation based on similarity relations, International Journal of ApproximateReasoning 17 (1) (1997) 1–36.[57] D. Dubois, H. Prade, Similarity versus preference in fuzzy set-based logics, in: E. Orlowska (Ed.), Modelling Incomplete Information: Rough Set Analysis,Physica-Verlag, Heidelberg, 1998, pp. 441–461.[58] R. Rodriguez, P. Garcia, L. Godo, Relating similarity-based models, counterfactuals and theory change, in: Proc. EUFIT’ 95, 1995, pp. 230–234.[59] E. Ovchinnikova, T. Wandmacher, K.-U. Kühnberger, Solving terminological inconsistency problems in ontology design, Interoperability in BusinessInformation Systems 2 (1) (2007) 65–80.[60] J.-F. Condotta, S. Kaci, N. Schwind, A framework for merging qualitative constraint networks, in: Proc. of the 21st International FLAIRS Conf., 2008,pp. 586–591.[61] S. Schockaert, M. De Cock, E.E. Kerre, Reasoning about fuzzy temporal information from the web: towards retrieval of historical events, Soft Comput-ing 14 (8) (2010) 869–886.[62] J. Allen, Maintaining knowledge about temporal intervals, Communications of the ACM 26 (11) (1983) 832–843.[63] S. Schockaert, M. De Cock, Temporal reasoning about fuzzy intervals, Artificial Intelligence 172 (2008) 1158–1193.[64] D. Randell, Z. Cui, A. Cohn, A spatial logic based on regions and connection, in: Proceedings of the 3rd International Conference on KnowledgeRepresentation and Reasoning, 1992, pp. 165–176.[65] S. Schockaert, M. De Cock, E.E. Kerre, Spatial reasoning in a fuzzy region connection calculus, Artificial Intelligence 173 (258–298).[66] G. Lakoff, Hedges: A study in meaning criteria and the logic of fuzzy concepts, Journal of Philosophical Logic 2 (4) (1973) 458–508.[67] L. Zadeh, A fuzzy-set-theoretic interpretation of linguistic hedges, Cybernetics and Systems 2 (3) (1972) 4–34.[68] P. MacVicar-Whelan, Fuzzy sets, the concept of height and the hedge very, IEEE Transactions on Systems, Man and Cybernetics 8 (1978) 507–511.[69] S. Schockaert, H. Prade, Merging conflicting propositional knowledge by similarity, in: Proceedings of the 2009 21st IEEE International Conference onTools with Artificial Intelligence, 2009, pp. 224–228.[70] S. Schockaert, H. Prade, An inconsistency-tolerant approach to information merging based on proposition relaxation, in: Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence, 2010.[71] J. Lang, Possibilistic logic: complexity and algorithms, in: J. Kohlas, S. Moral, D. Gabbay, P. Smets (Eds.), Algorithms for Uncertainty and DefeasibleReasoning, in: Handbook of Defeasible Reasoning and Uncertainty Management Systems, vol. 5, Kluwer Academic Publishers, 2001, pp. 179–220.[72] K.W. Wagner, More complicated questions about maxima and minima, and some closures of NP, in: International Colloquium on Automata, Languagesand Programming on Automata, Languages and Programming, Springer-Verlag, New York, 1986, pp. 434–443.[73] C. Cayrol, M.-C. Lagasquie-Schiex, T. Schiex, Nonmonotonic reasoning: from complexity to algorithms, Annals of Mathematics and Artificial Intelli-gence 22 (3–4) (1998) 207–236.[74] B. Nebel, Syntax-based approaches to belief revision, in: P. Gärdenfors (Ed.), Belief Revision, Cambridge University Press, 1992, pp. 52–88.