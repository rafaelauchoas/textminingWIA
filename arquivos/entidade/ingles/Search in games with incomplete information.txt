ELSEVIER Artificial Intelligence 100 (1998) 87-123 Artificial Intelligence Search in games with incomplete information: a case study using Bridge card play Ian Frank a,*, David Basin by’ il Cotnplex Games Lab, Electrotechnical L.aboratmy, Umezono I-l-4, Tsukuba. Ibaraki, Japan 305 h Institut ji?r Inj&matik, Univer~sitiit Freiburg, Am Flughafen 17, Freiburg, Germany Received 9 February 1996; revised 15 March 1997 Abstract We examine search algorithms in games with incomplete information, formalking a best defence model of such games based on the assumptions typically made when incomplete information problems are analysed in expert texts. We show that equilibrium point strategies for optimal play exist for this model, and define an algorithm capable of computing such strategies. Using this algorithm as a reference we then analyse search architectures that have been proposed for the incomplete information game of Bridge. These architectures select strategies by analysing some statistically significant collection of complete information sub-games. Our model allows us to clearly state the limitations of such architectures in producing expert analysis, and to precisely formalise and distinguish the problems that lead to sub-optimality. We illustrate these problems with simple game trees and with actual play situations from Bridge itself. @ 1998 Elsevier Science B.V. Keywnrds: Game tree search; Incomplete information; Game theory; Computer Bridge 1. Introduction In games with incomplete information, the actual “state of the world” is unknown; for example, be visible, or the outcome of some moves may not be known. For such games, ing often some playing pieces may be hidden, some of the playing area may not find- is for for timely play. An example of an incomplete the optimal required is typically NP-hard approach game thus a heuristic information [4] and strategy * Corresponding ’ Email: basin@informatik.uni-freiburg.de. author. Email: ianf@etl.go.jp. 0004-3702/98/$19.00 PIISOOO4-3702(97)00082-9 @ 1998 Elsevier Science B.V. All rights reserved. 88 I. Frunk, D. Basin/Artijicial Intelligence 100 (1998) G-123 on which good heuristics demic research more solutions [ 12,231. or systems than two dozen commercial the game have yet to be found is Contract Bridge; a history of aca- of to produce capable of competing with even good novice human players [ 5,10,11,17,22,24,27,31,32] software packages [ 19,331 have failed and a proliferation in reveal instead [2,36]. The the uncertainty to each other and considering [ 3]), or by removing suits information (first suggested altogether to automating Bridge card play involve reducing the sub-problems independently their cards some researchers, architectures significant that are consistent with a player’s knowledge. They speculate The common approaches space by either considering in individual complete players prompted Bridge-playing of the worlds any given situation ing and transposition to be established promising Recently, Matt Ginsberg has produced what he claims [35] of Bridge-playing proach. the search of the card combinations over in- the situation where all the has to suggest number that in (such as alpha-beta prun- the minimax value of each possible action the most sub-problems, to be chosen by statistical evaluation based on these values. to be a “whole new standard” ap- based on such a sampling for example Levy that work by examining [ 201 and Ginsberg a statistically program with an architecture the use of search reduction latter of these approaches tables) would enable in each of these overall action techniques generated randomly [ 14,151, and information Our interest in incomplete of such a model from those found [ 8, lo], and in particular that we first had to formalise games arose from our own work in designing from investigating why this program a system to play Bridge the rea- texts. To identify in expert could produce analyses different sons for these discrepancies, we found the actual model used by human players when analysing Bridge; surprisingly, we could find no explicit the best defence model of an in- descriptions the way that experts complete of this paper. We analyse problems go on to show that an equilibrium point for the two players’ strategies is well-defined for the best defence model, and describe an algorithm, which we call exhaustive strat- egy minimisation, that identifies points. We then use our best defence formalisation against “best defence”. in authoritative Bridge texts-is we formalised by considering in the literature. Thus, as a tool to investigate the first contribution the characteristics such equilibrium of sampling game-which information algorithms such problems Whilst others have noted before that computer Bridge architectures may not “play the same way as humans”, without a formal model of the assumptions made by experts the qualitative differences when solving to describe. Our formalisation that can afflict allows us to identify sampling algorithms, these problems both theoretically, play situations the two problems of how many worlds they consider. We demonstrate using simple game trees, and in practice, using actual in play have been difficult independently from Bridge itself. to combine The first of these problems, which we name strategy fusion, affects any algorithm for particular worlds to produce an optimal strategy subset) of worlds. The flaw in this approach that the exact state imposes that attempts across all (or some statistically occurs because of the property of incomplete of the world at any given point of play may not be known games to a player. This information significant strategies 1. Frank, D. Basin/Artificiul Intelligence 100 (1998) 87-123 89 on a player’s strategy a constraint worlds at such points; a constraint for individual worlds. that he must behave typically broken when combining the same way in all possible strategies designed clearly between such an opponent the two. Non-locality can direct play towards the portions of the game In general, determining what nodes in the worlds he expects. Thus, some positions The second problem, which we name non-locality, is more subtle than strategy fusion, occurs because an and we take care to distinguish opponent with some knowledge of the actual world state can use this to his advantage. tree In particular, that are most favoutable in the game (as the opponent may always find better may never be reached under particular worlds in the search space will be reached alternatives). the entire tree of possibilities under what worlds requires examining (since each move an to select different portions of the tree in different opponent makes gives him the chance in the sense worlds). Tree search algorithms, the best play at an internal node of a search space by analysing that they determine will not take into only account the therefore make mistakes node by erroneously in world states that are in fact of no consequence at that position notion of strategy only partial specify what actions would have been the tree. the subtree of that node. Such algorithms that under some worlds for the entire game would also have to that portion of (e.g., minimaxing) the play may never actually considering in the tree. As in strategy the problem that locally evaluates they are examining. When selecting moves, the subtrees considers in all other nodes outside incorrectly. An algorithm however, are generally strategies taken is one of handling “compositional” the possibility the complete they may strategies; payoffs fusion, reach Thus, we demonstrate exactly how the analysis of sampling this shortcoming is an issue for empirical [ 131). Our interest information is actually sufficient algorithms will differ their testing (such as that apparently being involved in is in clarifying the nature of to undermine the issues games, and in understanding from that of experts. Whether practical playing potential carried out by Matt Ginsberg finding solutions the models to incomplete implicitly used by different approaches. concepts We proceed as follows. In Section 2 we introduce preliminary these in Section 3 to games with incomplete this framework. We follow this in Section 4 by giving an algorithm from game theory and apply in particular we show how the common model of Bridge play against best defence can be formalised within for computing in our best defence model. The second half of the paper then considers optimal strategies Bridge for Bridge card in Sections 6 and 7 we use our game play based on theoretic results against best defence. Finally, Section 8 draws conclusions. to identify why such architectures yield suboptimal in Section 5 we present sampling in some detail: the minimax architectures information; framework algorithm, and 2. Game theory background In this section we introduce definitions and terminology necessary self-contained. and Lute and Raiffa [ 211. This is based largely on the work of von Neumann and Morgenstern to make the paper [ 341 90 I. Frank, D. Busin/Arrijicial Intelligence 100 (1998) 87-123 2.1. The extensive and the normal forms of two-player games In its extensive is a finite the branches tree in which each node corresponds to a form, a game move where a selection between is made. Each node is identified as being either a personal move or a chance move. Personal moves are made freely by one of the two-player games. players, creatively named “1” and “2”, since we will consider only Chance moves are decided by some mechanical the shuffling of a pack in accordance with definite of cards, or the tossing of a coin) the start of the game. A probabilities. There play, a, of the game node and allowing each of to choose a branch until a leaf node of the tree is reached. The the players to the outcome of a play (Y, (i.e., a leaf of the tree), value the is given by a numerical utility function K;( cu). This value is sometimes payoff and Ki a payofffunction. (or chance) that each player starting at this distinguished node which represents that selects a branch is one distinguished also called i attaches involves device (e.g., to that point One complication to all players. Also, the play begins with in the play. For example, the shuffling and dealing of a pack of cards is that at any particular move a player may not have full knowl- in many card into hands, the outcome of personal moves may be face down. At any that a player will be unsure of the actual position of the form of a game, there- the extensive into sets between which a player to these sets as in- edge of the choices made prior games which are not visible from hidden move, then, play within fore, requires will not be able to distinguish. We will follow formation requiring lowing: sets. We will also mode1 our actual definition the specification the other player(s), it is possible the game on that of [ 21, pp. 39-511, the fol- the nodes of the tree to be partitioned of a two-player game in extensive such as when a card tree. To precisely form to include in referring is played formalise [21] l A finite tree, t, with a distinguished l A partition, P(n), node (the first move in the game). of the nodes, n, of the tree into ( 1 or 2) or chance (0) selects three sets. These sets tell the next move at each which of the two players node. signing a probability distribution r(n) l A probability over the branches of each chance move, defined by as- l A refinement of the player partitions i. Each node, n, at which P(n) nodes distinguish. as integers (numbered to each daughter of a chance node. into information = i is classified by Z;(n) sets, Z;(n), l,2, .) between which player for each player into one of the sets of i will not be able to l An identification branches of corresponding for each of the moves in each of the sets. (Since a player cannot distinguish between nodes in an informa- to him at each node of a set. the same form, we must therefore of the extensive to the “first” the “second” possible move, and so on. In our diagrams, we will information tion set, the possible moves will appear When constructing the tree representation indicate which branch at each node of an information possible move, assume that this identification left-right order.) set corresponds . For each player, i, a numerical function, K;, defined over the set of end is in simple utility points of the game tree. 1. Frank, D. Basin/Artifirial Intelligence I00 (1998) 87-123 1 0 0 11 0 0 11 0 1 00 1 1 00 1 1 0 Fig. I. Information sets in the extensive form of a two player game with one chance move. i.e., there (represented set for this player, whatever Fig. 1 gives an example of the extensive by a diamond). This move has five possible outcomes, form of a two-player game that starts with a and chance move by a circle). The is followed by a personal move of one of the players the outcome of the first chance move, contains information tree. in the game only one node, to him. For the second This means player’s moves sets. This is because he is only aware of the outcome of the previous player’s move, and not of the outcome of the initial chance move. The actual payoff he will receive by the numbers to him. (represented that is not known that the outcome of the initial chance therefore depends on information there are two information over his actual position by squares), however, at the leaf nodes) is no ambiguity (represented (represented is known form analysis in practice. to be given formalisation they would make by a game In order forces each player, before Most games will be represented to work instead with an equivalent tree that is too large to enable to facilitate mathematical tensive therefore common form. This formalisation what choices course of the game. Such a specification of a game, an easy way to formulate I,. sign a number strategy which each element to the move ing this notion of strategy, a two-person game ing: the ex- it is the normal the game starts, to state in advance in any situation that could possibly arise during the form is to as- for each player strategies from a node with r branches. A in in one of the sets. Utilis- is defined by specify- the possible stemming sets can then be represented for a player with q information to be made in normal forms a strategy. Given . , r, to each branch the extensive by a q-tuple corresponds called form l two strategy spaces Xl and X2, which are the respective sets from which the two players can choose their strategy, and l two real-valued payoff in the game, then a given strategy selection functions Ki (xi, ~2) and Kz(xi, x2) that give the utility i. If there are no chance for each player when strategy xi is selected by player moves a unique play of the game, a, and we can define K;(?i ,I?z) = Ki( a). If the game contains over all the chance moves possible plays. when (?t,?p) mathematical impose a probability to denote the payoff for each player then (Zi,Zz) If we use prob(a) are chosen, of play cy occurring in terms of the expectation K; (21,222) = C, prob( cr) K; (a). (2,) T2) determines the probability is expressed distribution instead 92 I. Frank, D. Busin/Artijicial Intelligence 100 (1998) 87-123 Formulated in this way, the course of a single play of a game first involves games, between In non-cooperative of a strategy by each player. any pre-play communication games any selection of strategies by each player as being a “solution” no single player can individually his strategy selection. That is, a pair (Z?i,?*) hold. is based on the concept of an equilibrium point, due to Nash [25]. This views to a game whenever increase his payoff, or expected payoff, by changing if the following the players. The basic theory of non-cooperative is an equilibrium this choice point the choice is made without K,(%,~z) 2 Kl(.v,~22) vxi E XI, KzC?,,Z22) 2 Kz(%,x2) Vx2 E X2. (1) A special case, relevant to our domain, K2(xi, x2) = 0, for all XI E Xi, x2 E X2. Under a Ki (we choose KI ) and rewrite ( 1) as is that of zero-sum games, where K1 (XI, x2) + select this condition, we can arbitrarily K,(x,,Z2) f KI(TI,:z) < K,(?I,x~) \JXI E X1,x2 E X2. (2) This states that K1 has a saddle point; we consider next when this holds. 2.2. Minorant and majorant games: the minimax theorem zero-sum, and Morgenstern Let r represent a non-cooperative, two-player game where the players pick such games, two variations on r. The first of these, ri, their strategies without knowledge of that of their opponent. To analyse von Neumann introduce is defined so that it agrees with r before player 2 chooses x2, so that player 2 makes his choice particular XI decided on by player 1. Since player 1 is at a disadvantage compared The second variation, game is termed in every detail except that player 1 must choose x1 in full knowledge of the in this game the minorunt game of r. first; this in the original game, ri is the dual whereby player 2 chooses his strategy the mujorunt game of r. to his position is termed r2, in which player 1 is the first to select a strategy. For any particular For these new games, ri and r2, the identification of the optimal strategy is simplified, the minorant selection, the value of K, (21, x2). Thus, when player that the expected is a function of xi alone, and the best expected outcome he will as the “best way of playing” may be given a clear meaning. Let us consider game r,, Zi, player 2 will choose an x2 to minimise 1 is choosing an xt he can be sure (assuming outcome of the game since player 1 is attempting therefore be able to achieve to maximise his payoff, is is min,, K1 (x1, x2). This formula a competent opponent) ul = rn~axrn$ K1 (XI ,x2) A similar resulting payoff that can be expected by player 1 is argument shows that if both players play the majorant game well, the u2 =m$nm~axKi(xi,x2). I. Frank, D. Busin/Arrijcial lnrelligence 100 (1998) 87-123 93 Von Neumann and Morgenstern and lower bounds on the value, u, that player 1 can hope for from a play of r This result zero-sum is equivalent show that these values can be used to establish upper itself. that states that there is a subclass of for which u1 = u = ~2. This two-player games (those with perfect information) to produce a theorem is then refined to writing maxminKj(xl,X2) XI *2 =minmxTxKj(rl,~2), .Q (3) (i.e., it states that K1 must have a saddle point). The which is in turn equivalent form of (3) has led Von Neumann to as the minimax theorem and it forms the basis of the well-known minimax algorithm suggested by Shannon and Morgenstern’s to be referred to (2) [ 301. result 2.3. Pure and mixed strategies The minimax theorem does not hold for all two-player games. To achieve an existence extend the notion of strategy the players, rather . . ,pm) (p;, qi 3 0, C pi = 1, C 4; = 1) where pi gives the probability the ith member of XI as his strategy and q; is the probability the players select their strategies is the of the expected outcome theorem for general games, Von Neumann and Morgenstern as follows. If the sizes of the sets XI and X2 are m and n respectively, than choosing an XI and an x2 from these sets, instead specify vectors p = (PI,. and q= (ql,..., that player 1 will select that player 2 will select the ith member of X2. When in this probabilistic manner, interpretation mathematical the natural expectation q,,) K(p, q) = c c K, (xi, x,i)~iqi. ,=; j=] (4) As section, saddle point it is possible theorem, and in the previous to show is a probability that for this augmented interpretation game, the function K has a saddle point. This of the previous is a definite disadvantage to having your strategy “found out” by the opponent. Using a probability vector to select randomly from among a number of possible strategies affords protection sense are called mixed from exactly such an occurrence. Strategies strategies. The strategies of the previous section are a special case of mixed strategies to as pure in which the probability distribution strategies. is a l-point distribution, that in some games in this augmented and are referred illustrates theoretic there 2.4. Preliminarity and anterior@ Let us consider again the extensive of a game as a sequence of moves MI, M2, M3, . . ., we can define anterior this property form of a game. If we represent a particular play that are that to some personal move Mk as being any move Mi with i < k. Notice then to M,, on the outcome is anterior to M,. We can also look at the amount of information to MA and MA is anterior is transitive, i.e., if M, the moves is anterior M, 94 1. Frank. D. Basin/Art$cinl intelligence 100 (1998) 87-123 that that is available to the player who is called upon this player will know which branch was chosen . . , kfk-1, but it may also be that he has only partial knowledge, at all. The simplest way to describe a player’s state of information to make move of the anterior moves for each of Mk. It is possible the moves Ml,. or no knowledge at move Mk is to form a Set of preliminary moves, P. This set consists of the moves M;, is for some l}, such that the branch chosen known is not. for any of the Mj E p to the player. but the exact choice made at any of the other anterior moves i E {l,...,k- The class of games in which preliminarity and anteriority coincide called upon to make a move is informed about the outcome of all the anterior moves) called perfect information theorem enables each player’s optimal such games. However, we call property of preliminarity which we quote from in a precise way for (which the need not be transitive, as illustrated by the following example, games. We have already seen in Section 2.2 that the minimax to be interpreted in games where anteriority does not imply preliminarity features can result. For instance, information games), peculiar [ 34, p. 521: incomplete strategy (i.e., where a player is personal move of 1; M, Poker: Let M, be the deal of his “hand” first bid of player l-a player 2-a but M, “hand”; 2 makes his first bid knowing time 2 is ignorant of l’s “hand”.) personal move of 2. Then M, is not preliminary to M, l-a to player the first (subsequent) chance move; MA the bid of to MA and MA to M, (i.e., 1 makes his first bid knowing his own first bid; but at the same I’s (preceding) is preliminary intransitivity of preliminarity could be intransitive This preliminarity Bridge provides an example of this, since although of the game dictate Again using a description that these players from [ 34, p. 531: involves both players, but it is also possible that the personal moves of one particular player. the rules it is played by four players, form two teams, which play against each other. among two representatives A and C and 2 through is a two-person game, but the two players 1 and 2 do not play it them- two repre- of 1, A and C. The rules between chance move; MA the first Bridge selves. 1 acts through sentatives B and D. Consider now the representatives of the game restrict communication, them. E.g.: let M, be the deal of his “hand” card played by A-a personal move of 1. Then M, preliminary only one player. to M,. Thus we again have intransitivity, i.e., the exchange of information, to MA and MA to M, but M, is not it involves personal move of 1; M, the card played [. . .] by C-a but this time is preliminary to A-a raises the possibility of preliminarity to other players). Intransitivity of information see each other’s cards will wish to promote conventional lies in preventing illogical behaviour when making a choice. The first of these two types of procedures is inverted signalling. direct signalling the spreading team but cannot and an elaborate system of this. In Poker, the interest of a player and this is usually achieved by irregular and seemingly In Bridge, players who form one this signalling, signals has been developed and the second this signalling, of signalling to enable (i.e., is 1. Frunk. D. Busin/Artijiciul Intelligence 100 (1998) 87-123 95 3. A model of the game of Bridge of the previous the definitions the way in which Bridge its characteristics With formalise the game and that model that allows us to meaningfully expert-level in Bridge importantly results to describe precisely the situation analysed is analysed section behind us, we are now in a position to in the expert literature. We first describe formal assumptions of this model texts. It is the formalisation assess whether any given algorithm will produce correct, and more (as judged by those found in more detail, and then present in expert in the literature), the problems that can lead to sub-optimality. 3. I. Bridge as a game of incomplete information Bridge each containing abbreviate is a card game played with a deck containing 52 cards, comprised of 4 suits the 13 cards Ace, (spades 4, hearts 0, diamonds 0, and clubs 4) the first five of these to King, Queen, Jack, 10, . ., 2 (we will sometimes the deck, and A, K, Q, J, and T). The game begins with the chance move of shuffling named North, South, East the cards are then dealt between against East/West. Card play starts and West. The players form two teams: North/South when one player then cover in turn lays a card on the table, which all the other players (in a clockwise direction) with a card from their own hand. Each round of four cards to play a card on is called a trick, and the winner of one trick becomes rules are: the succeeding round. For the purposes of this paper, the only significant the first person four players, traditionally l The first player in a trick can freely choose which card to play from all those present l Subsequent in his hand. trick, among players must play a card of the same suit as the one that started the they do not, they can make a free choice from if they hold such a card-if the remaining cards in their hand. l The winner of the trick A > K > Q > J > 10 > when there is a suit declared as the trump suit; if any trump cards are played, the player playing > 2) of the suit led. The only exception is the player who plays trump card is the winner. by to this rule is then the highest card the highest (ranked In addition, play involves one player-the hands of cards, since his partner-the then to see, and examples will always assume dumnzy-places in the proceedings. For simplicity, that South is the declarer, so that North is the dummy. complete control over two his cards on the table for all our Bridge takes no further part declarer-having Analysis the dividing is extraordinarily for the subsequent of the game of Bridge complicated. The shuffling and dealing of the pack of cards at the start of the game in effect selects one of 52!/13!4 play (the order of the cards in a hand does not possible positions factors). Further, each player can initially see only their own matter-hence hand, so (as we have already seen) preliminarity will be intransitive the moves of the players, giving between partners, and inverted signalling between example, examined the available although not motivated by considering the situation where two players have evaluation the opponents, A related problem caused by this mis-match information, that are not known an opponent’s beliefs. Korf, for for both direct signalling is that of predicting the opportunity games with information incomplete to confuse functions among 96 I. Frank, D. Basin/Artificial Intelligence 100 (1998) 87-123 functions in which in evaluation [ 181. Such a game can be viewed either as a zero-sum game functions the evaluation receive, or as an incomplete in which is due to their heuristic nature, or as a non-zero- that each player functions the difference to each player. the two to the other the difference sum game would actually in evaluation Korf’s description the common players MAX and MIN. In the context of the previous chose Kt as the payoff the value of KI. Similarly, MIN will be player 2, since he tries to minimise The decision process in a three-level MAX-MIN-MAX follows: convention section where we (arbitrarily) function, MAX will be player 1, since he tries to maximise the value. tree is described by Korf as the payoffs game represent information of this situation uses to the differing information of naming in which available is due the evaluation is based on what MAX thinks function MAX’s decision will be based on what he thinks MIN will do. However, MIN’s decision will be based on what he thinks MAX will do two levels down. Thus, MAX’s decision that MAX will that is applied to each of the frontier nodes do. Therefore, is MAX’s model of MIN’s model of MAX’s evaluation function, and the nodes values are backed up to the MAX nodes directly above the with the maximum frontier. Next, MAX’s model of MIN’s evaluation to the backed up nodes, and the nodes with the minimum values are backed up to the MIN nodes directly below the root. Finally, MAX’s evaluation to these backed up nodes that MIN thinks the final move. to determine is applied is applied In Bridge, then, we can identify games. First, the following four related complications over perfect the moves of the between the opposing the intransitivity inverted signalling possible, making the spread of information for direct signailing, of preliminarity the problem of ever-deepening levels of reasoning side’s beliefs. Second, as we saw in Section 2.4, this intransitivity information two sides will lead us to encounter about also makes about their position to prevent in which the two players who form the opposition the opportunity the absence of their side’s situation. Finally, play to increase each other’s that are mixed strategies, since using a pure of perfect if they can “find out” what an advantage strategy will this strategy from nature of mixed strategies prevents knowing which pure strategy will be followed, even if they are aware of the exact mixed strategy information will entail solutions the opponents give for one side to attempt to the other side. Third, there is is. The probabilistic that will be used. it advantageous the opponents information typically 3.2. The best defence model of an incomplete information game the size of those generated The problems outlined above present serious difficulties when combined with game (a lower bound of 1.05 x IO” can be even when all the cards and texts are able to analyse play situations for dealing with any given problem. Here, we will on the expected number of legal play sequences trees established are revealed to recommend examine how this is done, formalising games that captures a best defence model of incomplete implicitly made in such expert analyses. information [ 81). Yet authors of Bridge the assumptions in Bridge “optimal” strategies I. Frank, D. Basir~/Arti$cial Intelligence 100 (1998) 87-123 97 AKQJ9 xx Tricks required: Strategy: Chance of success: 5 Cash top honors hope of dropping 87% in the the Ten Fig. 2. Third card combination from the Bridge Encyclopedia. 3.2. I. Expert analysis of Bridge As a representative Encyclopedia devotes 56 pages to presenting for different card combinations. example of expert texts we will look at the authoritative Bridge [ 11, published by the American Contract Bridge League. This reference (with percentage chances of success) the best strategies In Fig. 2, we reproduce one of these examples. Ten plus five low cards (x)-may In this game situation we are concerned with only the cards of one suit and North so that South plays both the North and South hands. The remaining their own hand and the dummy. The Encyclopedia’s is the dummy, cards-the just honours” describes this is done, When player who holds it also has at least four low cards. be held by either East or West, who see the top the process of playing, one by one, the Ace, King, Queen and Jack. the the Ten will “drop” (be played by either East and West) unless solution of “Cashing collectively To verify the Encyclopedia’s splits we then check whether all the possible ways to distribute this process more efficient, we will refer to these possibilities the number of cards held by the two players. For example, a l-5 describes remainder solution, we can proceed as follows. First, we enumerate the unseen cards between East and West. To make to according split of the cards the six possible ways to give just one of the unseen cards to West, and the to East. For each of the possible strategy the strategy will fail if the unseen cards are split O-6, since East succeeds. For example, will be able to play a low card on each of the Ace, King, Queen, and Jack, and then beat the 9 with the Ten. If the cards are split I-5, on the other hand, playing the four high cards may succeed, but only if the Ten is the single card that is held by West. in the case of a 6-O split. In this situation, East will Note that special care is required in this suit have to play a card from another suit when the Ace is cashed. The situation then effectively becomes one of complete that West must hold a trick with the 9 can be if West doesn’t play the Ten, guaranteed by playing the 9 will win the trick, but if West does play the Ten it will be beaten by the King, allowing information, these conditions, winning the low card from the South hand; the 9 to win a trick later on. the Encyclopedia’s since it is known the remaining cards. Under In the table of Fig. 3 we give, for each possible split of the cards, the probability the split, the actual distributions the number of ways to produce of in the Encyclopedia’s strategy succeeds, and the probability of these distributions these probabilities results in the chance of success given in the the split occurring, which occurring. Summing Encyclopedia. 98 1. Frmk. D. Bnsin/ArrijicLd Intelligence 100 (1998) 87-123 Split Probability Total cases Strategy succeeds Contribution O-6 1-5 2-4 3-3 4-2 5-l 6-O 0.007 0.073 0.242 0.355 0.242 0.073 0.007 6ce= 1 %Z, = 6 6c2 = 15 6Cj = 20 6c4 = I5 = 6 $ 6C6= 1 none T-xxxxx all all all xxxxx-T Txxxxx- Total 0 (l/6) * 0.073 = 0.012 ( 15/15) * 0.242 = 0.242 * 0.355 = 0.355 (20/20) * 0.242 = 0.242 (15/15) ( l/6) * 0.073 = 0.012 * 0.007 = 0.007 ( l/l) 0.87 Fig. 3. Verifying the chance of success of the Bridge Encyclopedia solution. 3.2.2. The best defence model The probabilistic analysis of all the strategies used when of the remaining the Encyclopedia’s in the above way: that is, by examining their author, Eric Crowhurst. According be verified possible distributions the technique contacting problem by first using his Bridge expertise strategies, and then determining possible distributions their best strategy opponents situations. Based on this evidence, we formalised expert analysis of Bridge problems as follows: of the remaining are allowed to choose cards. We verified, listed in the Bridge Encyclopedia can their outcome under each of the too, that this was actually by generated, [6], he solved each solutions were originally to Crowhurst to select a small number of promising their chances of success as we did above: enumerate the the return produced when the cards and analyse in each of these perfect the assumptions implicitly made in information A-I. MIN has perfect information (i.e., preliminarity and anteriority coincide). A-II. MIN chooses his strategy after MAX. A-III. The strategy adopted by MAX is a pure strategy. We call the result of transforming any game by making these modifications its best above. the best strategy for each pos- to choose the opponents in effect assumes that they will always know this distribution. that A-II follows directly from our discussion that the Encyclopedia makes an implicit assumption defence form. It should be obvious A-I also follows since allowing sible card distribution Further evidence formation combination North as the hidden hand. From the perspective of East or West, these problems information. be significantly for MAX will in genera1 be from his actual moves in- is that all of the problems are presented only one way around. That is, a card such as that of Fig. 2 is never presented with South as the dummy and should mixed strategies, since this will afford some degree of protection Under assumptions A-I and A-II, different, unless we assume that they have complete the optima1 strategies of complete I. Frunk, D. Bnsin/ArtifciuI Intelligence 100 (1998) 87-123 99 problem the restriction the Encyclopedia to pure strategies form the solutions that we are trying scalar maximisation that pure strategies to a set of constrained the best pure strategies only gives pure strategies), the identification it feasible to capture. However, we should point out that the ability in A-III typically given in expert texts and it is this implicit expert to for MAX can in turn be used to generate good mixed strategies of a small number of good (pure) for each to form a matrix of the payoffs produced set up by this problems, which can in this way theorem being completely predicted by MIN. We justify by the observation (for example, model identify strategies. For example, for each player makes possible pair of strategy selections. The vector maximisation matrix can be reduced be solved by techniques of mathematical would be solutions introduced in solving Bridge Note to formal analysis. A-I cuts the cycle problems, in Section 3.1, since now MIN knows exactly what of reasoning at any stage of the game, and MIN’s model of MAX’s information MAX possesses itself. Further, A-II is the same assumption evaluation as that made by von Neumann to its minorant form, for which (as we saw in Section 2.2) the outcome can be specified as a function strategy of MAX’s strategy only. Finally, A-III enables MAX’s optimal to be found to the set of possible from among a finite (although possibly very large) set, in contrast mixed strategies. in discussing how the best defence In the next section, we will make use of these properties the assumptions made by experts function will be MAX’s function form of a game may be solved. that as well as capturing about beliefs discussed form is also amenable Strategies produced to the probability and Morgenstern the best defence of the minimax in Section 2.3. programming. interpretation in reducing theoretic a game 4. Solving the best defence model In order to use the best defence model to analyse proposed architectures information we now introduce an algorithm to the assumptions of the model. We do not suggest incomplete relative under solutions practical use (although we analyse will form for Bridge card play, allowing us to understand analysis, and to formalise its complexity the two types of sub-optimality the basis for a rigorous evaluation of architectures in Section 4.5). Rather, this algorithm that have been proposed expert in producing from which they will suffer. limitations their for play that can compute optimal for this algorithm 4.1. Exhaustive strategy minimisation As we mentioned in the previous strategy after MAX) makes a perfect information (player 1) in such a game is the best defence model similar game. From Section 2.2, the value section, assumption A-II (that MIN chooses his form of to be expected by MAX to the minorant ui =maxminKi(xi,X2). x, +: (5) For the minorant game, min,, Ki (XI, x2) is a function of xi, so it is easily maximised. information. Specifically, MIN In the best defence model, however, there is asymmetric 100 1. Frunk, D. Bnsin/Arrijicial lnfellipnce 100 (1998) 87-123 Algorithm esm( r) : Returns optimal strategies for player 1 (MAX) extensive form, two-player game r. in the best defence, l Form the set of player l’s strategies, S, as q-tuples that is chosen at all nodes, n, for which Zi (n) = i. the branch in which the ith entry represents l For each s,i E S, calculate l Return the strategy lZi = esm( t, s,~). (or strategies) Sj for which E; is maximum. Here, the result of esm( t, s) is defined as follows: Condition f is leaf node P(node(t)) (i.e., MIN to move) is 2 P(node(t)) (i.e., MAX is 1 to move) P(node(t)) (i.e., chance move) is 0 Result Ki (t) min,,E,srrh(r) esm(ti, s) esm( t;, s), where i is the Zt (node(t) ) th element of s C,,E.SUhW 7T(nUde(ti))esm(t;,s) Fig. 4. The exhaustive strategy minimisation algorithm. (player 2) now has perfect information. He therefore always knows his current position in the game tree, and for any choice of XI by MAX he can select an optimal x2. MAX, as MIN and will not be able to on the other hand, since MAX does not directly have perfect the outcome but MAX does not. Selection of an optimal x2 will require reasoning about the outcome of these moves. in the game for which MIN knows is not party to the same information identify whether any x2 is optimal for MIN. Specifically, there may be moves information, this problem by identifying The algorithm we formulate deals with dif- choices of x2 that are optimal under each of the possible outcomes of these (5) with respect to the best defence and for each of them each possible this carries out a min- strategy ferent) moves. Essentially, model: all strategies xi min,, KI (XI, x2) x2 under each possible outcome of the chance moves. Since imisation operation minimisation. the algorithm directly computes for player 1 (MAX) and exhaustively are enumerated evaluated by examining for each MAX strategy, we call the algorithm is separately exhaustive (possibly that for t a tree, node(t) subtrees of node(t). returns its root node and sub(t) Fig. 4 then defines exhaustive More concretely, assume the set of immediate computes strategy minimisation. The assumptions involved a game into its best defence form are required to establish the optimal MAX strategy given by (5). First, to be able to actually form a finite set of MAX strategies, S, in fixing assumption A-III restricting consideration in modifying strategy minimisation correctly computes is needed. Second, to pure strategies that exhaustive I. Frmk, D. Basin/Art$icial Intelligence 100 (1998) 87-123 101 a particular after MAX used at chance and MIN nodes, since it is only valid to assume particular node depends position game trees t, that for any strategy s for MAX, esm( t, s) computes which MAX can be restricted by MIN. Therefore, given the top-level maximisation the optimal strategy for MAX and thus correctly computes the algorithm s,; E S and calling esm( t, s,i), assumption A-II that MIN selects his strategy is is required. Finally, assumption A-I (that MIN has perfect that the evaluation of a just on the subtree of that node if there is no ambiguity over the it follows by induction on the height of the minimal payoff to loop, (5). in the tree. Under these assumptions, information) returns 4.2. An example this diagram under the common convention as circles. MAX therefore has two information To illustrate exhaustive I. Let us interpret strategy minimisation, we will consider again the example of that nodes where it Fig. turn to move are represented as squares, and those where it is MIN’s turn are is MAX’s represented sets, with two possible moves in each, allowing him four strategies. These strategies can be identified by the tuples ( 1, I), ( 1,2), (2, I), and (2,2). Let us assume sets in Fig. 1 is the set “I”, and the “upper” to the selecting left-hand branch at all the MAX nodes in the lower set and the right-hand branch in the “upper” set, and so on. is the set “2”: the tuple (I ,l) corresponds to choosing the left-hand branch at every MAX node; that the “lower” of the information ( 1,2) corresponds In (5), the result of each of MAX’s possible strategies is found by minimising over algorithm models this by calculating responses by MIN. The esm(r) from the strategy under consideration, is recovered recursive calls on the subtrees along all the possible for esm( t, s) for each possible MAX strategy, s. Let us consider how this will function ( 1, 1). The original call to the esm( t, s) algorithm will examine the root of the strategy the tree, find it to be a chance node, and make recursive calls on each of the subtrees. Each of these subtrees has a MIN node at the root, so further recursive calls will then be made on each of their subtrees. The roots of these trees are now MAX nodes, so the branch to to select be branch 1. Further leaf the payoffs are returned. These payoffs are then passed back up nodes, at which point is returned. This the tree. At the MIN nodes, process ( I, 1) will lead to a payoff is depicted the third. If the outcomes of the of 0 under each outcome of the chance move except chance move are all equally the remaining likely, then, the evaluation of the strategy strategies (1,2) leads to a payoff of 1 in just the first two of the outcomes of the chance move, strategy always (2,l) produces a payoff of 0. If we assume equally for the chance move, the two strategies which maximise the final two outcomes, and strategy likely outcomes in Fig. 5, which shows that the strategy leads to a payoff of I in just of the subtree evaluations these branches encounter in the same way shows (5) are therefore that the strategy (1, 1) is l/5. the minimum and found Examining and (2,l). (2,2) (1,2) 4.3. Comparison with standard minimaxing The exhaustive strategy minimisation algorithm maxing, which correctly produces the game-theoretic should not be confused with mini- value of any finite tree in which 102 1. Frmk. D. Buir~/Artijiciul intelligence 100 (1998) 87-123 0 1 0 1 1 0 1 0 1 Fig. 5. MAX’s expected payoffs when selecting strategy ( I, 1). Algorithm mm(r): Take the following actions, depending on t. Condition t is leaf node P(node(t)) (i.e., MIN to move) is 2 P(node(t)) (i.e., MAX to move) is I P(node(t)) (i.e., chance move) is 0 Result KI(~) mm,E.sub(r) mm( ti> maxI,Esuh(t) mm(h) C,,EWhW T(flUdt?(ti))TWiZ(ti) Fig. 6. Simple adaptation of the minimax algorithm to best defence, two-player, extensive form games. the players have perfect of the minimax algorithm on games in extensive form. information. For comparison. in Fig. 6 we give a formalisation Notice the mm(r) and analysing strategies by passing that, where the esm( r) algorithm explicitly manipulates algorithm builds a MAX strategy them as arguments them, for each of the possible outcomes of the chance moves by determining a course of action for each MAX node on the basis of the subtree with the largest minimax value. It should be clear that this approach will always produce an evaluation that is greater algorithm. To see this, than or equal consider and algorithm selects the esm( r) algorithms essentially differ). At these nodes, the mm(r) the esm( t, si) algorithm maximum must select the mm(T) algorithm can therefore never be less than that produced by esm( r). to the maximum E,i produced by the esm(r) the actions of the mm(r) (the only node at which the branch determined by s,j. The evaluation to back up through the tree, whereas any MAX node subtree value produced by The differences between ( I) mm(r) does nof respect it does not always choose set. information the two algorithms can be summarised as follows: the constraint imposed by information the same branch at nodes that belong sets. That is, to the same 1. Funk, D. Busin/Artt$ciul Intelligence 100 (1998) 87-123 103 WI w2 w3 w4 w5 1 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 Fig. 7. Flattened tree of MIN and MAX moves in a domain with five worlds. (2) mm(T) commits to one branch selection at each MAX node, whereas esm(r) therefore risks incomplete- the result of each possible strategy. mm(r) examines ness. In Sections 6 and 7 we show that these differences in games with Specifically, we will show that the first leads to the problem of cause difficulties incomplete strategy fusion, and the second information. leads to the phenomenon of non-locality. 4.4. Possible worlds Let us say that in a tree that contains chance nodes, each possible pure strategy for player 0 (chance) defines a world state, or more simply a world, in which the play takes the tree of Fig. 1 has just one chance move, which has five possible place. For example, there are five possible chance strategies and five corresponding outcomes. Therefore, possible worlds. the extensive We will use the notion of possible worlds to visualise form of a game In particular, we will consider cases, such as Fig. 1, where in in a more compact manner. the one chance node occurs at the root of the game each possible world have the same shape (i.e., the same node and branching patterns). In such situations as differing payoffs at the leaf nodes, rather than in the horizontal dimension using different if we subtrees to right) of the initial chance move as the worlds refer to the possible outcomes for each world. Fig. 7 shows how the tree of Fig. 1 can be represented the possible worlds can be represented in the vertical dimension tree, and where the subtrees (left wi, ~2, ws, ~4, and wg. One part of the game definition sets. However, that is obscured this information in this modified is easily recovered by allowing form of presentation is the information players to make For example, in distinct their branch selections in Fig. 7, the MIN node at each node conditional is the result of identifying information sets, whereas the two MAX nodes each identify the on the world state. five nodes together five together 104 1. Frank. D. Bnsin/Artijicial Intelligence 100 (1998) 87-123 from the same information set. A MIN strategy must therefore allow different nodes branch choices at each MIN node under each world and a MAX strategy must specify the branches Allowing to be chosen at each MAX node under all worlds. a different choice of branch at each MIN node in every world effectively as in our assumption A-I about the best defence model. to the possible outcomes of the the same move at each MAX node under every world. gives MIN perfect MAX, on the other hand, can only assign probabilities chance move, and must make We will call form trees. We will use such simplified simply present trees presented trees in the remainder of this paper to compactly and in this way jkttened and interpreted the extensive the extensive information, form of games that start with a single chance move. to represent game trees in Bridge it will not be possible that in general form, even though in a Note flattened they will always have just one chance move at the top of the tree. This chance move will determine a world, but the possible plays under each of these worlds will not in general be the same. For example, MAX will only be able to in worlds where he was actually dealt the card to play a given card, such as the Ah, begin with. Thus, as device described above. The introduction to allow simple game trees in extensive in each world are different and cannot be “flattened” of the flattened form is simply a presentational form to be presented more easily. the subtrees 4.5. The complexity of exhaustive strategy minimisation We have stated that the purpose of defining exhaustive strategy minimisation is to form of other architectures. That it is probably not the characteristics a basis for investigating a practical algorithm itself can be seen by examining its complexity. Exhaustive trees we introduced incorporates a top-level loop that examines the set of investigate the algorithm’s complexity in the previous section, using that this tree represents strategy minimisation all possible MAX strategies, S. We will therefore by considering flattened Fig. 8 as an example. Recall information, occurs at the start. Each MAX node corresponds single they would be encountered numbering by virtue of the ith element (effectively, the size of this set. For simplicity, we do this by looking at the type of tree of a game where MIN has perfect that that come from a the MAX nodes in the order in which traversal of the tree. We will use this in the game to the possible i set. Here, we have numbered during a pre-order that correspond the choice to be made at the node numbered the outcome of the one chance move but where MAX never knows representing set). to construct 5-tuples the complete binary the ith information to a set of nodes information strategies selects selections. Let us consider MAX’s possible branch the left-hand branch at the root of the tree, play is directed In the strategies where MAX to the left- initially hand MIN node. Since we do not know which branch will be selected at this node, we must now specify branch selections to examine throughout both its subtrees. Continuing first, we encounter MAX node 2 and then MAX node 3, where we the left-most branch that we initially again select the left-hand branch. It should be clear that by will assume selecting the left-hand branches at these two nodes, we will in fact complete a strategy for the game; once the left-hand branch has been selected at the root of the tree, it is indicate no longer necessary for nodes 4 and 5. We will to specify branch selections I. Frmk. D. Busin/Ar@hd Intellipnce 100 (1998) 87-123 10.5 Fig. 8. Complete binary tree of MIN and MAX moves. such superfluous branch selections by an underscore. The strategy we have generated by the set of possible always selecting strategies then, is (1, 1, 1, _, _); overall, the left-most branch, is: Left-hand branch at root Right-hand branch at root I,-,-) (1,l. (1,2,1,-.-I ( I,11 2, -> -> ( I12,2, -, -1 (2, -, -, 1, 1) (Z-,-,2, I> (2. -, -, 1,2) (2, -,-, 2,2) In general trees, the number of actual strategies of possible n-tuples. As we have seen above, when encountering of the branches may be selected. However, at nodes MAX will have to cater for all of the possible branches tree, t, the total number of strategies g(t) a given in a game is bounded by the number a MAX node, any one that are moves of another player, that may be chosen. Thus, for is given by the following: g(ti) if MAX is to move at the root of t, c t,Esuh( t) g(t) = g(t;> if another player is to move at the root node of t, l-I r,E.suh(t) 1 I if t is a leaf node. For complete b-ary trees that alternate between can be written as a standard MIN nodes we will write this recurrence For a b-ary strategies, g,, as the moves of MAX and MIN this formula relation. As the addition of an extra layer of to the leaves of a tree does not alter the number of MAX strategies present, levels, n, in a tree. as a function of the number of MAX tree with a MAX node at the root, then, we can write the number of MAX recurrence 106 1. Frank, D. Basin/Artificial lnrelligence 100 (1998) 87-123 g11 = b ifn= I, b(g,,_l)” if tl > 2, which has the solution g, = b’““-“/‘“-1’ For the example expected. For trees with a MIN node at the root, we can solve a similar produce above where n = 2, and b = 2 this formula gives 8 strategies, recurrence the formula as to g II = bb(h”-I)/+1) For b-ary trees in general, then, in the number of MAX the number of strategies levels is that the tree contains. Further, all that must be examined doubly exponential of these strategies are examined strategy minimisation all but the smallest of game only an upper bound is a more efficient way of finding in the following tute. in each of the possible worlds. Thus, the exhaustive algorithm will require too much computation trees. However, note to the complexity of this problem. We do not know to be applied to that the algorithm given provides if there strategy; however, as we will show based on it, are not a substi- sections, minimaxing, and algorithms the optimal 5. Bridge architectures based on standard minimaxing reveal instead their cards for strategy in particular of simplifying to each other. Since the technique, mentioned the task of card play by solving In the remainder of this paper we use our model of best defence selection, in Bridge to examine in the other algorithms the easier problem Introduction, the perfect knowledge where all the players their cards on the table in situation created by this act is akin to the opponents placing is often described as double-dummy Bridge. the same manner as the dummy, architectures proposed by both Levy and Ginsberg Below, we present [ 14, 15,201. to demonstrate why that such approaches produce suboptimal can afflict search algorithms the question that motivates us is not “How well will such algorithms play in practice?’ but the stiffer “How will the solutions found by experts?” sections, we then use our framework results and to formalise produced by such algorithms in games with incomplete two general problems information. Thus, the double-dummy compare against In the following the solutions this scenario Repeated minimaxing The first person to explicitly propose to play Bridge appears for a program Million Pound Bridge Program”, he is confident the I million pound prize offered by former Bridge World Champion, Zia Mahmood, solver as the basis the use of a double-dummy to have been Levy 1201. In the paper “The that this kind of program could win to I. Frmrk, D. Basirl /Art@icd intelligence 100 (1998) 87-123 107 trees of legal moves in world W, Fig. 9. The minimax values, ei,, of each move Mi under world Wj. the designers of a computer player has produced what he claims with an architecture based on this principle [ 351. that could defeat him. More recently, Matt Ginsberg program to be a “whole new standard” of Bridge-playing incomplete Let us describe Levy’s algorithm by considering the general problem of selecting information that, for some MAX’s next move in an arbitrary that are consistent with the outcomes of move under consideration, the previous to choose an n such that when we randomly generate n members, WI,. . . , w, of W, we have sufficient computing information) is given by W. Let us also say that it is possible to find the minimax value of the current tree under each of these worlds. the set of worlds (anterior) moves game. Suppose resources game (complete If there are m possible moves, the minimax value of the in in this world will be as depicted . . > M,?,, to choose between and we use e;; to denote MI,. ith possible move under world w,i, the situation Fig. 9. Levy’s proposal was that each legal move, M,, could be given a score based on its expected payoff. In the context of Fig. 9, Levy’s score can be expressed as the scoring function, f: f(M;) = ~e;.iP~h(w.i) .j= I Selecting a move is achieved by actually using the minimax algorithm the the M, for which the value of f( Mi) is greatest. Since to problems with information, we will refer to it as repeated minimaxing, and to the limiting case values of the eiis, and determining this technique perfect where every possible world is examined as exhaustive minimaxing. relies on repeated applications of the minimax algorithm to generate Of course, other possible definitions for the scoring function f can be envisaged, and indeed Ginsberg’s notion of selecting “the play that works best on average” suggests the following alternative: [ 141 108 I. Frank. D. Basin/Artijiciul Intelligence 100 (1998) 87-123 from 1 to m, and 2 is an infix function where k ranges equal, and 0 otherwise is the best, or equal best, alternative). Another possibility the objective moves that equals 1 if both sides are (that is, a move is given a score of 1 for each world in which it in Bridge, where is to only consider that guarantee a result at least as large as some minimum value, e, say. That is, to win at least a certain number of tricks) (particularly is usually than the choice of the scoring function in our current context is However, more important the answer that this kind of architecture Below we show that no possible scoring to the more fundamental question of whether Levy is justified is the key to playing the cards “perfectly” function can work optimally. in speculating (Levy’s quotes). 6. How repeated minimaxing fails: strategy fusion of outstanding i.e., suboptimal cards and using The repeated minimaxing sample of possible distributions the best strategy. We use our framework architecture described above is based on looking at a rep- to resentative this evaluate Indeed, we show that even an may fail, examining all the possible distributions, may fail to exhaustive minimaxing select experi- enced by repeated minimaxing, we also show that any algorithm which shares specific the same difficulties. We use examples characteristics with minimaxing will experience in real lead to improper play from Bridge games. algorithm, the correct strategy. Although our discussion to show that against best defence to show how such sub-optimal strategies may be returned. is driven by the problems algorithms them that we have already examined four possible he may select strategies the right-hand branch, which Let us return to the flattened version of the game tree we first introduced in Section 2, this time labelling the nodes and adding one extra possible path, as shown by the nodes d, e, and f in Fig. 10. If MAX picks the left-hand branch at node d, he will encounter in Section 4. the tree with in which Alternatively, no further MAX choices are necessary. Thus, the number of possible MAX strategies by one. Since we have already seen that none of the strategies subtree give a payoff of 1 in more than two worlds, MAX’s best option in the left-hand at the root of the tree, guaranteeing the right-hand branch. However, using the two in any single MIN nodes a and e will always have a minimax world MAX can always choose a branch with a payoff of 1 at nodes b, c and f). irrespective of the scoring Applying the the right-hand function to the root of the tree then, the left-hand branch and repeated minimaxing used, must assign both leads to a subtree increases algorithm under any single world, a return of 1 under every world, the standard minimax value of 1 (since the extra branch is to select branch I. Frank, D. Busin/Arrificial Intelligence IO0 (1998) 87-123 109 Fig. IO. A tree of MIN and MAX choices that is mis-analysed by exhaustive minimaxing. in only reducing in which the assumption in the limiting this modification, three worlds. Despite the two moves, even the number of worlds repeated minimaxing will perform no better the payoffs on the right-hand branch have been modified so that a payoff of 1 than making a random case of exhaustive minimaxing. the right-hand branch gives a in which repeated minimaxing will usually select the same score. Thus, choice between Furthermore, payoff of 1 can produce situations incorrect move, and indeed where exhaustive minimaxing will always select incorrectly. For example, consider how exhaustive minimaxing behaves in the situation of Fig. 11 (a), where is achieved this branch still represents MAX’s best move at the root of the tree, under that all the worlds are equally likely. For exhaustive minimaxing, that will be selected by any of the scoring functions of Section 5, as the left-hand MIN node has a minimax value of 1 in all five worlds, whereas the right-hand node has a value of 1 in if it does not just examine either of the worlds WI and w2 and then makes a fortunate guess). Any sensible scoring to select the right-hand branch as it clearly cannot be rational behaviour, given a set of alternatives in this situation, less than or equal to choose between, function can cope with all to that of one of the others. To see that no possible scoring such situations, this tree that of Fig. 11 (a), as the minimax values of the MIN will be indistinguishable the best move nodes in Fig. 11 (a) the best move is the left-hand branch. Any is the right-hand branch, and in Fig. 11 (b) given scoring in just one of these situations or will be unable (Repeated minimaxing may pick the correct branch, but only function will therefore either make the correct choice in each are the same under every world. However, to prefer an option whose evaluation I I (b). To an exhaustive minimaxing the best move in either case. lead exhaustive minimaxing it is the other branch function will never consider Fig. to distinguish algorithm, is always however, three. from 110 / 1 1 1 0 0 WI W2 % w4 W5 Intelligence 100 (I 998) 87-123 1. Frtmk. D. Basin/Arti$cicd r !i I /\ 0 0 1 1 0 0 Wl \ 0 0 1 1 0 1 1 1 (4 1 0 0 0 0 1 1 1 W2 w3 W4 w5 1 1 1 1 0 1 1 1 (b) Fig. II. Two trees with the best initial move marked in bold. examines algorithm strategy minimisation in Section 4. Recall imposed by information that repeated minimaxing to find the best strategy the result of every possible The source of the difficulty it makes from the exhaustive strategy. Repeated minimaxing, that for each world that it considers, exhaustive sets: it allows difSerent strategies values of these strategies the minimax that can be expected under each world ignores experiences on these trees lies algorithm we strategy on in a number of in this way does not respect to be chosen and assuming the fact strategy has to be made. We therefore call this problem to ignore than or equal Repeated its scoring of any node; that it has the luxury of choosing a different in each world, instead of the best single strategy across all worlds. For example, to to produce a payoff of 1. Node n will therefore always have a minimax value that when a single is a payoff of 1 in at most in a crucial deviation presented minimisation the other hand, uses the minimax worlds. As we pointed out in Section 4.3, using minimaxing the constraint in different worlds. Collecting that they represent the payoffs that a choice of a particular strategy fusion. As we saw in Section 4.3, allowing imposed by information the constraint to the correct values minimaxing will therefore have the tendency the strategy fusion effect leads it to believe strategy given perfect select of 1 under strategy selection two worlds. at node b or node c it is easy to determine which branch repeated minimaxing. However, we have already seen (e.g., produced by exhaustive the best that can be achieved strategy minimisation). to over-estimate in evaluations the minimax is enforced, sets results information algorithm greater Another way to visualise minimaxing architecture the strategy actually models fusion problem the task of selecting between is to note that the repeated some number 1. Frank, D. Busin/Artijicial Intelligence 100 (1998) 87-123 III 4A Q- OA SA Outstanding: 42 Q- 054 $543 Fig. 12. A Bridge situation requiring a guess over the best strategy. information information that the subtrees in a game starting with a chance move rooted on nodes a and e in Fig. 10 represent games each starting with the same chance move. For example, the MIN and that selects one of the possible that they have of perfect imagine MAX moves worlds WI,. . . , w5. Which of these games would we rather play given perfect that exhaustive minimaxing answers, and to which repeated minimaxing It should be clear that such to win the game based on the tree of node a and the an algorithm will always expect game based on the tree of node e. It should also be clear that the situation modelled by from the original game as well from the model produced by this algorithm our assumptions about MAX, as well as MIN, having perfect about best defence, since it involves assumptions (for both players)? This is the question approximates. information. is different 6.1. A Bridge example (the 24) but cannot To see an example of strategy fusion the situation of two opponents that cards in the trump suit beat cards in every that spades are trumps-recall that it is South’s in the game of Bridge, consider Fig. 12, where we control both the North and the South hands against who see just their own hand and the North hand, which is the dummy. Assume turn to play. We are worried about the last outstanding other suit-and the Ah trump because currently in the suit. However, whichever opponent has the last trump must also have at least one diamond or one club. Since players must always follow the suit of the card that starts a trick, it is therefore possible with the last trump holds, winning the trumps with the Ah. clearing the suit that the opponent in the North hand with the Ace of that suit, and then leading a diamond or a force the opposition turn to play, and South has no cards In reality, this choice between to play this card by leading to win all the remaining it is not North’s tricks by leading 112 1. Frank, D. Basin/ArtiJicial Intelligence 100 (1998) 87-123 4A VA UA &A Outstanding: 42 O- 0654 46543 Fig. 13. A Bridge example where strategy fusion obscures the best strategy. club is a guess, but a double-dummy program will find that it is always possible because it has perfect knowledge of every world. A Bridge situation where repeated minimaxing is misled by strategy above situation, fusion can therefore be constructed by adding as in Fig. 13. four cards to the In this new situation, let us assume that the lead is now in the North hand, so that either of evaluated by a repeated minimaxing the lead of the Ace of any suit. Choosing to a trump played by an opponent. Choosing the Ace may lose the other hand, will be (correctly) there will be no remaining is played there are four possible moves: the diamond or the club suits will be (correctly) algorithm as less than 100% plays, provided the algorithm examines at least one world in which the spade suit, on evaluated as a 100% play, since after trumps and North’s other Aces will be the AI guaranteed winners. However, exhaustive minimaxing will also assess the Ace of hearts to be a 100% play. This the the trick) and then the North hand re-entered by making a guess South hand is clearly not between diamonds to succeed, as would be revealed by an algorithm such as exhaustive strategy guaranteed minimisation, the North hand with a club or with a diamond, that they would each lose under some of the possible worlds. a trump can be played on this card from which would separately evaluate above. This play, of course, the strategies of re-entering and clubs as described is because (winning finding 4.2. Further discussion: a tendency to delay To our knowledge, the concept of strategy formalised before. others have noted the same way as the absence of a formal model of the assumptions made by experts when have fusion has not been their algorithms may not “play that the qualitative differences such problems has meant in performance that Although humans”, solving I. Frto~k. D. Brrsit~/ArtiJiciul Intelligence I00 (1998) 87-123 113 KJTx A98x Fig. 14. An example card combination used by Ginsberg (again, North is dummy) to describe. Thus, while others have occasionally in performance, lacking. By providing such as strategy been aware of some a way to formally describe and analyse such occurrences to pinpoint fusion, but also to make more general characterisa- such a formalisation, we are able not only for example concerning the way in which repeated minimaxing will deal with been difficult peculiarities has been precise problems tions, decisions. is known, if we know the card combination To illustrate, consider it will always be possible of Fig. 14 introduced by Ginsberg. This low card (as in the example is a single suit situation, and an “x” represents an arbitrary is that if the location of the missing of Section 3.2.1). The essence of this situation to win four tricks. To see this, consider Queen that West holds the Queen. We start by playing a low card what happens from the South hand, and if West plays the Queen we win with the King and cash the remaining top cards. If West chooses not to play the Queen, we win with the Jack or the Ten (this play is called a jfinesse), and repeat the same procedure on the following trick. Similarly, we can always win the trick the Queen, the location of the Queen this time by leading is unknown the finesse. However, a double-dummy program will always see the position of the cards and “know” which opponent realises to play for the card. this problem, pointing out that a double-dummy if we know low from the North hand. In practice, that it can always play KJTx opposite A98x “won’t mind playing program Ginsberg for no losers”. However, will “assume he also suggests this suit by starting with the 9 (for example)“, whereas human players “might play the Ace first to cater to a singleton Queen on our right”. To see why this is not the whole story, consider a game tree composed of just We have already seen that under any single world the minimax value of node b is and must be guessed; a wrong guess will allow the node b in Fig. 1.5. that such an algorithm that East holds the Queen to defeat correctly in this new situation is at the root of the tree of possibilities. this tree, the best move is found by determining always 1, and that such nodes can lead to strategy fusion. However, the node analyse score under some function freedom to select alone can guarantee 0 in some worlds. strategies within a game to that has the highest the for each world, and since neither of these branches there must now be a payoff of a point where a choice between that win under different worlds has to be made. If such a decision point occurs itself tree, as in Fig. 10, a repeated minimaxing a payoff of 1 under every world, If we use repeated minimaxing f. This separate examination then, node b represents algorithm will deceive the best strategy of each branch the branch In effect, removes 114 I. Frank. D. Basin/Arti$cial Intelligence 100 (1998) 87-123 Fig. IS. A simple tree with just one MAX choice. thinking than “doing to be better in Ginsberg’s example, observe the correct choice. in different worlds that it can always make it now”. Only when it actually is lost. A repeated minimaxing to delay such decision points wherever possible, as “doing into at the root of the tree as in Fig. 15, however, some of the freedom strategies have a tendency always appear where a choice has to be made will it realise by the effects of strategy fusion. To see how this is relevant If the decision point occurs to choose different algorithm will therefore it later” will reaches a point that its previous evaluations were inflated to always win the finesse necessary of these cards, in the suit under every world. Repeated minimaxing will the play of the Ace or the King at less than 100% if it selects any of these worlds examine. The play of any other card in the suit, however, against either opponent 100%. Therefore, in the suit, as Ginsberg 8, x. Indeed, an exhaustive minimaxing that in order to be able for the outstanding Queen against either East or West, it is to retain both the Ace and the King. Starting a trick by actually playing either to win all the tricks therefore correctly evaluate to to finesse of is indifferent over the card to lead to play one of the J, T, 9, algorithm will only choose to play these cards. the delaying of a crucial decision can be important, as the later an actual the decision. For the aim is to win all the tricks and suggests, but rather that it will prefer it is not that repeated minimaxing in an (over-estimated) the more information this ability, making in Fig. 16, where then, will remove to be to inform there is likely intact, always it impossible the situation Sometimes the ability evaluation is made, resulting leaves choice example, consider there is no trump suit. this is not necessarily The spade suit is identical information will be gained which will increase one’s chance of making the position of the Queen. However, [7, p. 2071 points out in a similar example, “by playing out the winners three suits, right play, possibly up to certainty”. algorithm minimaxing made. However, as we have already seen, although plays, choose to that of Ginsberg’s example, so there is again a guess over a complete guess. As Frank in the other the It might be hoped that the tendency of a repeated to delay such decisions would result in this discovery play being the Ace and King are less than 100% algorithm may well the lower cards in the suit are not, so a repeated minimaxing to play the spade suit early. 1. Frunk, D. Busin/ArtQSiciul Intelligence 100 (1998) 87-123 115 4KJTx VAKQ UAKQ 4xXx hA98x Vxxx oxxx 4AKQ Fig. 16. An example deal in Bridge. South is declarer, North is dummy and there are no trumps Wl W2 w3 w4 % I 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 Fig. 17. Simple tree of MIN and MAX choices in a domain with five possible worlds. 7. Non-locality (how repeated minimaxing fails again) The failure of minimax-like algorithms we address here is more subtle fusion and, to our knowledge, has not been studied before. To illustrate strategy will refer once more to the flattened version of the tree introduced we repeat in Fig. 17 for ease of reference. than that of it, we in Section 2, which I16 I. Frank. D. Busin/Art$cinl Intelligence 100 (1998) 87-123 are actually here ( 1,2) and (2, 1) ! is distinct from When actually playing set in the game). Let us again assume equally the game represented by this tree, MAX will only ever have to the selection of a move at either node b or node c (effectively, one make one decision: choice for each information likely worlds, Irrespective of the MAX node at which the play arrives after MIN’s move at the root of from Section 5, will using any of the scoring the tree, repeated minimaxing, usually the left-hand branch will always be chosen). Thus, the strategy that will typically be chosen the one that will always be selected by exhaustive by repeated minimaxing, as ( I, 1). However, we have already minimaxing will be the one we have identified seen in Section 4 that under the best strategy selections (in the limiting case of exhaustive minimaxing, the left-hand branch the assumption likely worlds, and indeed of equally functions select The problem that of strategy fusion, and can be traced is made at a node on to the in making a cause: selection situations the way evaluation In perfect is justified information (i.e., where this assumption this assumption and the minimax in which a branch this assumption function, of the game. tree is known), in the tree. This is the manifestation a different basis of an evaluation only of its direct subtree. The inherent assumption branch selection continuations in the game with its compositional possible world, however, procedure making of a tree: the actual strategies MAX nodes in Section 4.3. To illustrate in this way is that the correct move is a function only of the possible the position algorithm, finds optimal strategies. With more than one is no longer valid. This is because a decision considers only partial strategies at any internal node themselves would have to specify further choices at other to in our the subtree of node b, we see that the left-hand branch it produces a payoff of 1 in three out of the the left-hand example appears five possible worlds. In the context of the entire game, however, selecting branch at node b affects the left-hand branch at node b produces payoffs of 0 in worlds w4 and wg, MIN (who chooses his strategy after MAX to and has knowledge of the state of the world) will be able to restrict MAX’S payoff 0 in these worlds it this circumstance, irrespective of MAX’s choice at node c. Under that is the best choice at node c, since it offers a payoff of 1 is the right-hand branch in two worlds to the single payoff of 1 (in world ~3) offered if we consider making a branch selection at node b by the left-hand branch. Similarly, after choosing the one that leads to a payoff of 1 in most worlds. tree. If we just analyse to be the best choice because a branch at node c, we find that the best selection of the incompleteness we alluded to the task of selecting a strategy the discussion here, let us return the analysis of node c. Since ( w1 and wz), compared is no longer In general, the choice of a branch at a given MAX node y1 is not simply a function of the payoffs of the paths that contain ~1, but of the payoffs along any path in the tree. (in any world) If MIN can choose a move at an ancestor of n that reduces from what MAX would expect by examining then the best branch at in the case of Fig. 18, the initial selection of branch a may n may change. For example, in the maximum value of be rendered the function incorrect f being achieved at a different branch. some of the e;,, can result n’s direct subtree if reducing the payoff We call this problem of having TO see that no possible scoring to consider all other nodes function can cope with in the tree non-locality. the effects of non-locality, 1. Frank, D. Bnsin/Artijicial Intellipmz 100 (1998) 87-123 117 MIN will direct play down these branches if the largest payoff in some world, W,, say, is fess than r IO Values found by examining only direct subtree of MAX node. Branch selection determined by applying some scoring function,f, to these values Fig. 18. A search process in which the selection of branch N may he rendered incorrect by non-locality. tree always give a payoff of 0). No algorithm the correct selection irrespective of the accuracy of the evaluations analysing consider the examples of Fig. 19. The left-hand to a MAX payoff of I in just one of the two worlds. However, it is the right branch and in each to make is the left-hand in isolation will be able a MIN player who knows leads the best choice is based. For example, the e’s were produced using fusion) and tree against gies nodes ther, non-locality will occur node selection whether caused by strategy the results of the optimal Thus, non-locality modified versions, The back-up rules into account tree, peated minimaxing but non-locality will still be present. Also, to the result alpha-beta computed. in such algorithms means architecture may or by applying strategy pruning take the actual subtree in both is the same in the other state of the world, trees, in one (since the other strate- these MAX in both situations. Fur- on which in Fig. 18, non-locality would still be possible incorrect values repeated minimaxing to find exhaustive exact values). the minimax algorithm with [ 28,291. to propagate up the the re- in fusion, the effects of strategy the very fact that each node contributes [ 261 or product propagation a value strategy minimisation (therefore producing (risking reduce therefore that search enhancement techniques cannot be eradicated by simply replacing such as average propagation in such algorithms, when calculating cannot be used to improve efficiency without affecting the value of each subtree at a node. Their use such as the values for the subtree related Non-locality is closely to the presence of differing the players of the game. MIN’s ability tween under certain worlds by selecting branches higher in the tree relies both on his ability choose a strategy after MAX edge of the actual state of the world (which assumption A-I, but need not be so complete). Given be- to lead the play away from a given node to (assumption A-II in our best defence model), and knowl- from is perfect knowledge, these conditions, non-locality will levels of information in our examples 118 I. Frunk, D. Busirz/Arf~jiciul Intelligence 100 (1998) 87-123 Wl W2 1 0 0 1 1 0 Wl w2 1 0 0 1 0 1 (a) (b) Fig. 19. Two trees with the best MAX strategy marked in bold. that determines the best choice at a node by analysing arise in any search algorithm just the node’s subtree. Note that one consequence of this is that non-locality will only occur it will only be observed with a repeated at internal nodes of the search space. Thus, minimaxing in a game is analysed. This may explain why the effect has not been formalised before: using partially played game situations than simply examining initial game configurations. type architecture when a move other than the first is a far less obvious choice as test examples Currently, we are aware of no correct algorithm against best defence other than the exhaustive tion 4. This algorithm overcomes both non-locality expedient of examining has a complexity game. 2 optimal strategies algorithm of Sec- fusion by the simple the possible outcomes of each complete strategy separately, but in the for identifying strategy minimisation in the number of a player’s moves that is doubly exponential and strategy 7.1. A Bridge example We give below an example of non-locality is difficult below to construct simple examples for the non-specialist is, however, representative of the kinds of problems as it can occur in Bridge. Note in Bridge. The example that can arise during actual that it play. Consider the situation of Fig. 20, where one trick must be lost because card is held by the opposition. For ease of exposition we will assume remaining possible options are represented using a slightly higher-level selecting between possible moves, we will examine applicable representation: tactics [ 8, IO] -operators the highest that the rather than 2 Recently we have tested a new algorithm, pclyo~reduction wzinirnuxing 18) that does not suffer from strategy fusion and also reduces the occurrence of non-locality. In 191, we have shown that on simple game trees, payoff-reduction minimaxing significantly out-performs sampling architectures such as repeated minimaxing. I. Frank, D. Brrsir~/ArtQicittl Intrlli~ence 100 (1998) 87-123 119 587 W N L-J E S Q95 T32 Outstanding: Fig. 20. A Bridge card combination where one trick must be lost. that specify not just a card to lead on a trick, but also the card to played by the declarer from the third hand, after the first opponent has responded.3 that succeed two tricks. Finally, the Ten. If East plays We will look at the two tactics in most worlds. The first of these is a play that begins by leading the 7 from the North hand. If East plays the Queen straight away, declarer plays a low card from the South hand and wins the next two tricks with the 9, declarer covers with the Ten and is again the Jack and low, declarer again plays a low card from guaranteed the South hand, hoping forcing out the type of finesse (of the 7) Queen or winning against East. The other possibility we will examine this type of finesse, time of the Jack, against West. This play begins by leading a low card from the South the Queen. Of the eight possible hand, ways to split under which each of these tactics would produce if East plays to find that East also held the trick outright. This play is a particular cards, two tricks are shown the distributions in Fig. 21. to play the outstanding the Jack unless West plays the 9, thus either is a different intending information With no further to guide a choice, then, the most promising of the two to be the finesse of the Jack. This will fail to win two tricks in only one the finesse of the in from the state where the cards tactics appears of the eight possible worlds 7 will fail in two. However, notice one round of play (each player contributing are initially distributed that the situation of Fig. 20 can in fact be reached is also the least likely), whereas as in Fig. 22. one card) (which If the declarer does not know the actual distribution of the outstanding cards, his best play in this situation is to lead the 6 from the North hand and play low from the South hand unless East plays the 9 or one of the King or Queen. Faced with this play, East’s is to play low with the 5. If he does this, West best option to just two tricks in the will win the trick with the 9 and the declarer will be restricted if he holds the cards shown 3 Note that Ginsberg suggests a similar representation when discussing the example of Fig. 14. When leading a card, he proposes that declarer should “decide in advance” the other card he will play on the trick- essentially creating tactics. Within the repeated minimaxing framework, such a representation change has the effect of delaying the onset of strategy fusion for one level of search. since instead of choosing between individual moves-which are really just partial strategies with only now between options that are partial strategies with the first step determined-the the first two steps determined. However, choice is the strategy fusion that results from allowing d@w~t completions of these partial strategies in dt&rent worlds will still remain beyond this new horizon. Although the use of tactics can indeed “correct” the problems caused by strategy fusion in Ginsberg’s example, then. it cannot provide a complete solution unless the “tactics” extend to the end of the play, at which point they become complete strategies. 120 I. Frank. D. Basin/Ar~ificial Intellipxce 100 (1998) 87-123 Possible worlds: East holds Finesse of the 7 Finesse of the J Q95 Q9 Q5 95 Q 9 5 void . . . 0 . . l . l . . . . Fig. 21. Possible worlds under which each tactic will produce 2 tricks. 94 5876 N E W s L-----l AT32 KQ5 Fig. 22. A Bridge example giving rise to non-locality. suit. Similarly, Thus, if the situation of Fig. 20 is encountered to beat the King with the Ace, there will be extra information Specifically, because under chosen by East to restrict if East starts with Kx or Qx, the best option will again be to play low. the 6 and having about the lie of the cards. the Q5 or the singleton 5 can be ruled out, in the tree, would have been another branch, higher to just two tricks. the cases where East holds as the result of leading these circumstances the declarer This extra information would have a crucial effect on the situation in Fig. 20. If it the two distributions where that this position would not be reached under the Q5 or the 5, we can see from Fig. 21 that the finesse of the 7 would the finesse of the Jack would still two tricks in this scenario in was known East holds then succeed under all the remaining worlds, whereas fail in one. The probability therefore be higher would this position would need to be reversed. of the finesse of the 7 producing than that of the finesse of the J, and the selection made 7.2. Estimating the practical significance As we mentioned in the Introduction, [ 8, lo], and in particular a Bridge playing program why this program could produce analyses different our interest in Bridge arose from our work on from coming of from those found in expert texts. Our to an understanding I. Frunk, D. Basin/Artificial Intelligence 100 (1998) 87-123 121 program searches the Bridge example round of cards, and are designed (such as playing to the point where, analysed. However, space, as their composition strategies found by conducting node up the payoffs a bottom-up the assumption (under for strategies using a set of tactics above. These tactics formalise partial strategies to represent commonly a winner, or @essing). The use of tactics restricts for single-suit the tactics do not eliminate problems, all possible any optimal strategies occurring Bridge like the ones we used to describe for playing one techniques the search space can be from the search tactic combinations in the Bridge Encyclopedia. Our program solves single-suit can be used to represent any of the (textually described) problems at each in Fig. 18, backing likely worlds) as indicated tree, selecting branches pass of the tactic search of equally in each world of the selected branch. We tested this program against solutions from the Bridge Encyclopedia, to the 650 cases where the model strategies were designed restricting attention the goal of obtaining where the Encyclopedia than maximum payoff) Hence, non-locality We conjecture the maximum concentrates [ 81. The program produced sub-optimal possible payoff on safety plays (ignoring, that attempt affected 33.5% of the problem set. 4 its consequences in these problems that one reason for the prevalence of non-locality is that they are very hard: they were designed as an expert reference and contain no trivial problems the opportunity (e.g., where all the top cards are held); hence there is always for some element of manceuvre. Note, however, that although non-locality a frequent problem, of local algorithms than produces a poorer result. For example, the maximum model solution. Hence, set with randomly distributed outstanding maximum possible payoff will be missed to be for the use In an actual playing situation, a more important question strategy solutions produce the less than problem cards, the expected number of cases where the is just 0.07 * 218 M 15 cases (about 2.3%). possible payoff with, on average, a probability to play the entire Encyclopedia to match expert analysis if we use the program need not necessarily that a sub-optimal spell catastrophe in our program is the chance the incorrect in practice. the ability of 0.07 appears for simplicity to produce for example, problems to guarantee a lower in 2 18 cases. strategies 8. Conclusions with captures We showed exhaustive We have looked at the problem of strategy selection incomplete information, formalising in zero-sum a best defence model of such games two-player games that the assumptions that equilibrium implicitly used by Bridge experts in analysing play situations. point strategies exist for this model and gave an algorithm, strategy minimisation, capable of computing them. The formalisation algorithms play. Our model allowed us to precisely demonstrate of an explicit model allowed us to rigorously evaluate other search expert analysis of Bridge in producing based on mini- and to understand that algorithms limitations their 4 More recently, Ginsberg has reported similar findings on complete Bridge deals using a fast repeated sampling approach [ IS 1. On a hard test set taken from the Bridge tutoring program Bridge Master Ginsberg’s program failed to solve 35.6% of the problems 1 I3 1. [ 161, 122 I. Frrrnk. D. Basir~/Arr@cicrl Intelligence 100 (1998) 87-123 return results, suboptimal independently maxing must backup rule. Furthermore, us to pinpoint fusion results from combining different MAX strategies from examining non-locality evidence tree. We gave experimental function or allowed strategy in different possible worlds, and only partial strategies at internal nodes of a game that non-locality of exhaustive strategy minimisation in repeated minimaxing: the sources of sub-optimality of their evaluation our formalisation exactly results against While our results provide a clear means of understanding the practical merits of systems designed of search the commonly used mode1 of expert Bridge play, we caution against play. there may be a real that is unacceptable for the complexity of exhaustive the effects of incomplete information a lower bound to judge them the poor complexity in overcoming algorithms using Given cost involved in practice. However, we have not yet established of computing open-and like Bridge. for the reduced game model; for the design of programs this remains an that play games strategy minimisation, important-problem for man-machine point strategies equilibrium apparently occurs often in actual systems. the performance Acknowledgements Our thanks go to Alan Bundy and Brian Drabble and feedback on this work. The first author was funded by a Science and Engineering Research award number 92314771. The second author Council was funded by the German Ministry (BMFT) under grant ITS 9102. The responsibility (SERC) Advanced Studentship, for Research and Technology lies with the authors. for their discussions for the contents References 11 1 ACBL, The Official Encyclopedia of Bridge, 5th ed., American Contract Bridge League, Inc., 2990 Airways Boulevard, Memphis, TN 38 I 16-3875, 1994. 121 E.R. Berlekamp, Program for double-dummy Bridge problems-a new strategy J. ACM IO (4) playing, York, 1988. ( 1963) 357-364: also in: D. Levy (Ed.), Computer Games for mechanical game II, Springer, New 13 1 D.L.S. Berlin, Span: 1985, pp. 1047-1051. integrating problem solving tactics, in: Proceedings IJCAI-85, Los Angeles, CA, 141 J.R.S. Blair, D. Mutchler, C. Liu, Games with imperfect information, in: Games: Planning and Learning, Papers from the 1993 Fall Symposium, AAAI Press, 1993, pp. 59-67. 15 1 G. Carley, A program to play Contract Bridge, Master’s Thesis, Department of Electrical Engineering, Massachussets Institute of Technology, Cambridge, MA, 1962. 161 E. Crowhurst, Personal communication. May 17. 1996 (Crowhurst made a point of crediting Dorothy Truscott with helping him to verify his results). 171 A. Frank, Brute force search in games of imperfect Intelligence 2-The information, in: D.N.L. Levy, D.F. Beal (Ed%). Second Computer Olympiad, Ellis Horwood, in Artificial Heuristic Programming Chicester, UK, 1989, pp. 204-209. 18) I. Frank, Search and planning under Thesis, Department of Artificial Springer, Berlin. to appear. incomplete Intelligence, Edinburgh, information: A study using Bridge card play, Ph.D. 1996; also: Distinguished Dissertations Series, in Japan (GPW-97). Laboratory, Umezono, I. Frcmk. D. Basin/Arr$iciul Intelligence 100 (1998) 87-123 113 [ 9 I I. Frank, D. Basin, Payoff-reduction minimaxing, in: Proceedings Fourth Game Programming Workshop Hakone, Japan, 1997; also: Technical Report ETL-97-21, Electrotechnical Japan. [ 10 1 1. Frank, D. Basin, A. Bundy, An adaptation of proof-planning ECAI-92, Vienna, Austria, 1992, pp. 72-76; 1 I I 1 B. GambPck, M. Rayner. B. Pell. An architecture (Eds.), Heuristic Programming Levy, D.E Beal Olympiad, Ellis Horwood, Chichester, UK, 1991, pp. 87-107: Cambridge University Computer Laboratory, in Artificial 1993. to declarer play in Bridge, in: Proceedings longer version: DA1 Research Paper No. 575, Edinburgh. for a sophisticated mechanical Bridge player, in: D.N.L. Second Computer later version: Technical Report 299, Intelligence 2-The 1121 E. Geake, Playing to win, New Scientist [ 131 M. Ginsberg, GIB vs Bridge Baron: (19 September 1992) 24-25. results, Usenet news message posted on the newsgroup rec.games.Bridge, 3 I October 1996; Message-id: <56cqmi$914@pith.uoregon.edu>. 1 I41 M. Ginsberg, How computers will play Bridge, The Bridge World, 1996; also available as the file /papersiBridge.ps. for anonymous ftp from dt.cirl.uoregon.edu [ IS 1 M. Ginsberg, Partition search, [ 161 E Gitelman, Bridge master, Computer Bridge Program, in: Proceedings AAAI-96, Portland, OR, 1996, pp. 228-233. 15 Lillian Street, Toronto, ON, Canada M4S 2H7. 1 171 D. Kibler, K. Schwamb, Complete contingency planners, Technical Report UC1 TR 92-94, University of California, Irvine, CA, 1992. [ 18) R.E. Korf, Generalized game 119) R. Lee (Ed.), Reviews trees, in: Proceedings IJCAI-89, Vol. 1, Detroit, MI, 1989, pp. 328-333. available as the file /pub/Bridge/ FAQ.ReviewsFromCanadianMasterPoint from Canadian Master Point, 199221994; from the site arp.anu.edu.au. 1201 D.N.L. Levy, The million pound Bridge program, (Eds.), Heuristic First Computer Olympiad, Ellis Horwood, Chichester. UK, in: D.N.L. Levy, D.F. Beal Programming 1989, pp. 95-103. in Artificial Intelligence-The [ 21 [ R.D. Lute, H. Raiffa, Games and Decisions-Introduction I22 1 R. Lustig, Hibrid: a hierarchically designed Bridge playing program, Master’s Thesis, Weizmann and Critical Survey, Wiley, New York, 1957. Institute of Science, Rehovot, Israel, 198.5. ( 231 B. Manley. Bridge software: moving forwards or backwards‘?, The Bulletin, American Contract Bridge League 1994). 1241 C.N. Napjus, Declarer: a learning Bridge-playing (October program which generalizes and infers, Ph.D. Thesis, University of Washington, [ 25 I J.F. Nash, Non-cooperative 1261 D. Nau, P. Purdom, C.-H. Tzeng, An evaluation of two alternatives 1969. games, Ann. of Math. 2 (54) ( 19.5 I ) 286-295. to minimax, in: L.N. Kanal, J.F. Lemmer (Eds. ), Uncertainty in Artiticial 1271 Y. Nygate, L. Sterling, Aspen-designing Intelligence, theory: survey of recent results. Symposium [ 28 i 1. Pearl, Heuristic on Artificial search 1993, pp. 5 l-60. Intelligence, Elsevier, Amsterdam, complex knowledge based systems, 1988, pp. 505-509. in: Proceedings 10th Israeli in: Proceedings IJCAI-81, vol. I, Vancouver, for playing chess, Philos. Mag. 41 ( 1950) 256-27s. Intelligence 20 ( 1983) 427-453. in: Games: Planning and in: Proceedings AISB Summer Conference, 1976, pp. 256- 1291 (30 131 I 1331 1341 1351 1361 information a computer for imperfect to make tricks at Bridge, in game searching, Artificial BC, 1981, pp. 554-562. J. Pearl. On the nature of pathology C.E. Shannon, Programming S.J.J. Smith, D.S. Nau, Strategic planning Learning, Papers from the 1993 Fall Symposium, AAAI Press, 1993, pp. 84-91, A. Stanier. Planning 265; also in: D. Levy (Ed.), Computer Games T. Throop, Computer Bridge, Hayden, 1983. J. von Neumann, Press, Princeton NJ, 1944. G. Walker, Beaten R. Wheen. Solving double dummy Bridge problems by exhaustive (Eds.), Heuristic Programming Chichester. UK, 19X9, pp. 89-94. in spades, New Scientist ( I6 November 1996) 26-27. II, Springer. New York, 1988. Intelligence-The in Artificial games, search, in: D.N.L. Levy, D.F. Beal Firsi Computer Olympiad, Ellis Horwood, 0. Morgenstern, Theory of Games and Economic Behaviour, Princeton University 