Artificial Intelligence 191–192 (2012) 1–19Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintApplicability conditions for plans with loops: Computability resultsand algorithmsSiddharth Srivastava∗, Neil Immerman, Shlomo ZilbersteinDepartment of Computer Science, University of Massachusetts, Amherst, MA 01003, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 15 November 2010Received in revised form 18 July 2012Accepted 20 July 2012Available online 25 July 2012Keywords:Automated planningPlans with loopsPlan verificationReachability in abacus programsGeneralized planning1. IntroductionThe utility ofincluding loops in plans has been long recognized by the planningcommunity. Loops in a plan help increase both its applicability and the compactness ofits representation. However, progress in finding such plans has been limited largely dueto lack of methods for reasoning about the correctness and safety properties of loopsof actions. We present novel algorithms for determining the applicability and progressmade by a general class of loops of actions. These methods can be used for directing thesearch for plans with loops towards greater applicability while guaranteeing termination,as well as in post-processing of computed plans to precisely characterize their applicability.Experimental results demonstrate the efficiency of these algorithms. We also discuss thefactors which can make the problem of determining applicability conditions for plans withloops incomputable.© 2012 Elsevier B.V. All rights reserved.The problem of planning in AI is to compute a plan, or a procedure which can be executed by an agent to achieve acertain goal. This paper presents methods which can be used for the computation of compact plans that resemble computerprograms with branches and loops.In the classical formulation of AI planning, the agent’s state is assumed to be completely observable, and effects ofactions are assumed to be determined entirely by this state. Classical plans consist of linear sequences of actions whichlead to a goal state from a particular initial state. Even in this restricted, deterministic formulation, the planning problemis PSPACE-complete [2] when the input is specified in the STRIPS framework [8]. More general formulations which allowthe agent to possess only partial information about its current state, and its actions to be non-deterministic make theproblem significantly harder [18]. Consequently, numerous approaches have been proposed for reusing sequences of actionscomputed for related problems [7,10] and for computing generalized plans which can be used to solve large classes ofplanning problems [19,14,26,24].Approaches for generalized planning build extensively upon the power of including loops of actions for representingcyclic flows of control in plans. Not only are such constructs necessary when the input problem instances can be un-bounded in size, but they also allow significant reductions in plan sizes for larger problems—particularly when contingentsolutions are required in order to deal with partial observability [1,23]. Plans with loops therefore present two very appeal-ing advantages: they can be more compact, and thus easier to synthesize, and they often solve many problem instances,offering greater generality.* Corresponding author.E-mail addresses: siddharth@cs.umass.edu (S. Srivastava), immerman@cs.umass.edu (N. Immerman), shlomo@cs.umass.edu (S. Zilberstein).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.07.0052S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–19Loops in plans, however, are inherently unsafe structures because it is hard (and even impossible, in general) to de-termine the general conditions under which they will terminate and achieve their intended goals. It is therefore crucial todetermine when a plan with loops will be able to solve a given problem instance. Unfortunately, there is currently very littleunderstanding of when the applicability conditions of plans with loops can even be computed, and if so, whether this canbe done efficiently. This limitation significantly impacts the development and usability of approaches for finding generalizedplans.In this paper, we present methods for computing the conditions under which a plan with a particular class of loops willterminate at a desired state. Our approach elaborates and builds upon the ideas presented in [22]. We further develop theseideas to identify more clearly the factors that make the problem of determining termination of plans with loops difficult.We also present new results for determining termination for a broader class of plans with loops and illustrate how ourmethods can be applied.We first formulate the notion of plans with loops using the concept of generalized planning problems introduced in priorwork [21,24]. Solutions to such problems are expressed as generalized plans. Generalized plans are rich control structuresthat include loops and parameterized or “lifted” actions whose arguments must be instantiated during execution. Thesenotions are described in Section 2.In spite of their expressiveness, a broad class of generalized plans can be easily translated into abacus programs—formalmodels of computation that use primitive actions, but are as powerful as Turing machines. Abacus programs have finitesets of non-negative registers, and actions that may increment or conditionally decrement these registers (Section 2.4).Abacus programs have been shown to have a close relationship with numerical planning problems. Helmert [11] showedthat abacus programs can be reduced to a class of planning domains over numerical variables where the goal conditions donot use numerical variables, but action preconditions include comparisons of these variables with zero and action effectsincrement or decrement these variables. This leads to a negative result that the plan existence problem is undecidable forsuch planning domains due to the undecidability of the halting problem for abacus programs. In this work however, wepresent some positive results capturing classes of abacus programs for which the halting problem is decidable.Our approach for computing applicability conditions for plans with loops is to first develop methods for computing theconditions under which a given abacus program will reach a desired state. This is referred to as the reachability problem ofabacus programs. Undecidability of the halting problem in abacus programs implies that the reachability problem for abacusprograms is also undecidable in general. However, we show that certain classes of abacus programs, categorized in terms ofthe graphical structure used to represent their control flow, do have solvable reachability problems. We develop methodsfor addressing the reachability problem of abacus programs in these classes.These methods can be used to compute applicability conditions for a broad class of generalized plans by translatingthem into abacus programs. Furthermore, the fact that this translation preserves the structure of the control flow makesthese methods applicable also in synthesis of “tractable” generalized plans: during synthesis, we can choose to permit onlythose control structures in generalized plans that would allow the computation of reachability conditions upon translationto abacus programs. Prior work describes one possible instantiation of this process in greater detail [25]. The fundamentalnature of abacus programs also makes our methods more generally applicable to plans with loops that may not be expressedas generalized plans in our representation, but which have suitable translations into abacus programs.The following section develops the formal framework for the rest of the paper and describes the connection betweengeneralized plans and abacus programs. We develop methods for solving the reachability problem for abacus programswhose control flow only uses simple loops in Section 3. We then introduce a class of nested loops in Section 4 and developmethods for addressing the reachability problem for deterministic and non-deterministic abacus programs with this class ofnested loops in Section 5. Finally, we conclude with a demonstration of the scope and efficiency of these methods.2. Formal foundationsIn this work we consider loops of actions whose every iteration, during any execution of the plan, will make measurableprogress towards a goal. We call such necessarily terminating loops, progressive. For example, in the blocks-world, a loopof actions which in every iteration unstacks a block that is clear but not on the table, makes incremental progress towardsthe goal of having all blocks on the table. In contrast, a loop could also be used with actions that need to be repeated untilthey succeed. For example, in order to pick up a block using a slippery gripper, we need a loop that executes the pickupaction until it succeeds. Plans with such loops are considered in strong cyclic planning [3] but are not the focus of thispaper. Our motivation for considering only progressive loops is to facilitate the computation of plans with strong guaranteesof termination and correctness in situations where the number of objects to be manipulated is unknown.To clarify these notions, we begin the formal description of our approach with a brief summary of a recently proposedframework for generalized planning in which progressive loops turn out to be very useful. This is followed by a descrip-tion of our representation for generalized plans (Section 2.2). The latter half of this section presents the formal definitionof abacus programs (Section 2.4) and some conditions under which we can view generalized plans as abacus programs(Section 2.3).S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–1932.1. Generalized planning problemsFig. 1. A generalized plan for transporting objects from L1 to L2.Intuitively, a generalized planning problem consists of a domain schema, a set of initial states and a goal condition.A domain schema includes a predicate vocabulary (the set of predicate symbols that can be used in formulas; constantsare represented as special unary predicates), a set of action operators and integrity constraints. We use first-order logicto represent domain schemas and generalized planning problems. This allows us to represent planning domains withoutreferring to the specific objects that may occur in a particular generalized planning problem. Further, a generalized planningproblem may include uncertainty about object quantities and properties. We refer the reader to prior work for details [21,24]and present the essentials below.Definition 1 (Domain schema). A domain schema is a tuple D = (cid:3)V, A, K(cid:4) where V is a vocabulary, A is a set of actionsexpressed in first-order logic with transitive closure (FO(TC)), and K is an integrity constraint expressed in FO(TC).pHere (cid:2)+Action representation. For each predicate p that action a1 affects, the action operator for a1 includes an expression of thefollowing form, where p(¯x) ≡denotes the predicate after action application:(cid:3)(cid:3)−+p,a(¯x)p,a(¯x)¬p(¯x) ∧ (cid:2)p(¯x) ∧ ¬(cid:2)∨(cid:2)(cid:2)(cid:5)(cid:5)p,a denotes the conditions under which predicate p is changed to true on application of action a, and (cid:2)−p,adenotes the conditions under which it is changed to false. Intuitively, Eq. (1) states that p becomes true for a tuple iffeither (a) it was false and action a changes it to true, or, (b) it was already true, and is not removed by action a. Thisrepresentation is similar to frame axioms in situation calculus [15]. To compute the effect of an action on a given state, foreach affected predicate p we evaluate the truth of the RHS of Eq. (1) on the given state.We define a generalized planning problem as follows:Definition 2 (Generalized planning problem). A generalized planning problem is a tuple (cid:3)α, D, γ (cid:4) where α is an FO(TC)formula describing the possible initial states, D is the domain schema, and γ is an FO(TC) formula specifying the goal states.2.2. Generalized plansWe represent generalized plans using graphs. We provide a brief illustration of the main features of this representationhere and refer the interested reader to prior work for further details [24].Definition 3 (Graph-based generalized plan). A graph-based generalized plan Π = (cid:3)V , E, (cid:6), s, T (cid:4) is defined as a tuple whereV and E are respectively, the vertices and edges of a finite connected, directed graph; (cid:6) is a function mapping nodes toactions and edges to conditions represented as linear inequalities; s is the start node and T a set of terminal nodes.The edge conditions in graph-based generalized plans are represented as linear inequalities over the number of objectsthat satisfy certain properties (unary predicates). The interested reader is referred to [24] for details. Fig. 1 shows a simplegeneralized plan for a transport problem, where a single truck incrementally loads an object from location L1, drives to L2and unloads the object. The predicate vocabulary in this example consists of the unary predicates obj(x) denoting that x is anobject to be transported; atLi(x) denoting that x is at Li, where i ∈ 1, 2; and inT (x), denoting that x is in the truck. The startand terminal nodes for this plan are labeled with dummy Start() and Stop() actions. Most edges have the default edge con-dition, “True”. The two non-True edge conditions use the number of objects that satisfy the predicates obj and atL1 (denotedas #{obj, atL1}). These two edge conditions depend on whether or not the cardinality of the set of objects at L1 is equal to 0.4S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–19The execution of a generalized plan begins at the start node and continues along edges whose conditions are satisfied bythe world state resulting from the last action’s application. Fig. 1 also lists the changes in cardinalities of certain predicatecombinations. These changes are significant to the translation from plans to abacus programs and we will revisit them inthe next section.This example illustrates how a generalized plan may use choice actions to select arguments for subsequent actions.Choice actions select an object which satisfies a given formula in first-order logic, and assign it to a constant used in actionupdate formulas. Intuitively, if multiple objects satisfy a formula used in a choice action, the generalized plan is consideredto solve a problem iff all executions of the plan with all choices of the qualifying objects will solve the problem.2.3. Cardinality changes in generalized plansThe generalized plan in Fig. 1 is annotated with the changes in cardinalities of various properties. The class of possibleproperties whose cardinalities are kept track of can be specific to a particular approach for generating generalized plans. Weconsider the special case where the space of possible properties is the powerset of all unary predicates in the domain. Moreprecisely, we define the role of an element in a state to be the set of unary predicates that it satisfies (e.g., {obj, atL1}). Therole-count of a role (e.g., #{obj, atL1}) in a state denotes the cardinality of that role, or the number of elements that satisfythat role. Thus, in Fig. 1, the cardinality changes indicate that the loadT (c) action decrements the number of objects at L1by one and increments the number of objects at L1 and in the truck by one.In the following development we will utilize two crucial aspects of cardinality changes that are demonstrated in Fig. 1:1. Action branches in the plan (nodes with out-degree greater than 1) are distinguished by inequalities between a constant(zero) and the cardinalities of certain properties.2. The changes due to actions on these cardinalities are deterministic. Every possible execution of a particular action nodein the plan leads to the same change in the cardinality.In fact, these aspects are fundamental to computation—as we will see in the next section, some form of such cardinalitychanges can be used to express any plan with loops.In prior work we showed how generalized plans could be computed together with such cardinality changes in a wideclass of domains [24]. This class includes all PDDL-like domains that use only unary predicates in their vocabulary and aparticular class of domains with binary predicates, defined as extended-LL domains. In that work, action branches dependon comparisons between role-counts and the constant 1, while we use the constant 0 in this paper. The two representationsare equivalent however and plans can be easily translated from one to the other [20]. Another direction of study, whichwe defer to future work, would be to identify the changes caused by each action node on a selected group of cardinalities,given an arbitrary generalized plan.The main insight of this paper is that we can effectively determine the applicability of a generalized plan by lookingonly at the effect of each action on the cardinalities that determine action branches. Thus, we can reduce a generalized planinto a simpler structure whose actions increment or decrement non-negative integer valued variables, and whose actionbranches depend on the values of these variables. Such structures are known as abacus programs and are described formallyin the next section.Viewing generalized plans as abacus programs allows us to study more easily the conditions under which a particularsequence of action branches will be taken during an execution. This in turn allows us to compute the conditions underwhich the execution of a generalized plan will lead to a desired state in the plan. In most applications this state will beone that can only be reached when the world state satisfies a goal condition (recall that a generalized plan’s edges arelabeled with conditions on world states). In such configurations our methods will compute the conditions under which ageneralized plan will terminate in a finite number of steps and achieve the goal. A domain can also be designed so that thenon-occurrence of an undesirable property is included as a part of the goal formula—in which case, goal reachability willalso ensure that unsafe situations do not occur.2.4. Abacus programsWe now introduce the formal framework of abacus programs [13]. Abacus programs are finite automata whose statesare labeled with actions that increment or decrement a fixed set of registers.Definition 4 (Abacus programs). An abacus program (cid:3)R, S, s0, sh, (cid:6)(cid:4) consists of a finite set of non-negative, integer-valuedregisters R, a finite set of states S with special initial and halting states s0, sh ∈ S and a labeling function (cid:6) : S \ {sh} (cid:10)→ Act.The set of actions, Act, consists of actions of the form:• Inc(r, s): increment r ∈ R; goto s ∈ S, and• Dec(r, s1, s2): if r = 0 goto s1 ∈ S else decrement r and goto s2 ∈ S.S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–195Fig. 2. A simple abacus machine for the program: while (r1 > 0) { r1 − −; r2 + +}.We represent abacus programs as bipartite graphs with edges from nodes representing control states to nodes repre-senting actions and vice-versa. In the rest of this paper, we will use the term “state” in connection with abacus programsto refer to a node that represents a control state and the term “action” to refer to a node that represents an action. “Node”will be used as a more general term, only in situations where the type of the label of the node is irrelevant to the propertybeing discussed. States have at most one outgoing edge and actions have at most two outgoing edges; the two edges out ofa decrement action are labeled = 0 and > 0 respectively (see Fig. 2).Given an initial valuation of its registers, the execution of an abacus program starts at s0. At every step, an action isexecuted, the corresponding register is updated, and a new state is reached. An abacus program terminates iff its executionreaches the halt state. The set of final register values in this case is called the output of the abacus program.Abacus programs are equivalent to Minsky Machines [16], which are as powerful as Turing machines and thus have anundecidable halting problem:Fact 1. The problem of determining whether an abacus program will reach the halt state starting with a given set of initialregister values is undecidable.Nevertheless, we identify in this paper a general class of abacus programs for which the halting problem is decidable.As discussed in the previous section, our approach for determining the utility and applicability conditions of planswith loops is to view them as abacus programs. However, the abacus program framework is restrictive from this point ofview: it does not include non-deterministic actions. In planning on the other hand, non-deterministic sensing actions arecommon. We need a way to effectively translate them into the abacus framework, without changing the loop structure.For this purpose, we extend the abacus program framework by adding the following non-deterministic form of action toDefinition 4:Definition 5 (Non-deterministic abacus programs). Non-deterministic abacus programs are abacus programs whose set ofactions, Act, includes, in addition to the Inc and Dec actions, non-deterministic actions of the form:• NSet(s1, s2): non-deterministically go to s1 ∈ S or go to s2 ∈ Swhere S is the set of states of the abacus program.A non-deterministic action thus has two outgoing edges in the graph representation. Either of these branches may betaken during execution. Although the original formulation of abacus programs is sufficient to capture any computation, theseactions will allow us to conveniently translate plans with loops for non-deterministic domains into abacus programs.3. Applicability conditions for deterministic simple-loop abacus programsWe now show that for any simple-loop abacus program, we can efficiently characterize the exact set of register valuesthat lead not just to termination, but to any desired “goal” state defined by a given set of register values (Theorem 1). Weonly consider deterministic actions in this section; the case for simple loops with non-deterministic actions is analogousand can also be handled as a special case of the methods presented in Section 5.2 for a more general class of loops. Recallthat a non-trivial strongly connected component is one which has more than one node.We define simple-loop abacus programs as follows:Definition 6 (Simple-loop abacus programs). A simple loop in a graph is a strongly connected component consisting of exactlyone cycle. A simple-loop abacus program is one all of whose non-trivial strongly connected components are simple loops.1, R0Let S 1, a1, . . . , Sn, an, S1 be a simple loop (see Fig. 3). We denote register values at states using vectors. For example,¯R0 = (cid:3)R0(cid:4) denotes the initial values of registers R1, . . . , Rm at state S1. Let a(i) denote the index of the registerpotentially changed by action ai . Since these are abacus actions, if there is a branch at ai , it will be determined by whetheror not the value of Ra(i) is greater than or equal to 0 at the previous state.2, . . . , R0mbe represented as ¯R0We use subscripts on vectors to project the corresponding registers, so that the initial count of action ai ’s register cana(i). Let (cid:2)i denote the vector of changes in register values R1, . . . , Rm for action ai corresponding to its6S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–19Fig. 3. A simple loop with (right) and without (left) shortcuts.branch along the loop. For any action, this change vector has 0’s in all dimensions except possibly for the register indexthat the action affects, where the change can be +1, −1, or 0 (corresponding to an “= 0” branch of a decrementing action).Let a linear segment of an abacus program be a distinct sequence of states and actions, S 1, a1, S2, a2, . . . , an−1, Sn, such thatS i has an edge to ai and ai has an edge to S i+1 in the program. Let (cid:2)1..i = (cid:2)1 + (cid:2)2 + · · · + (cid:2)i denote the register-changevector due to a sequence of abacus actions a1, . . . , ai . Given a linear segment of an abacus program, we can easily computethe preconditions for reaching a particular register value and state combination:Proposition 1. Suppose S1, a1, S2, a2, . . . , Sn is a linear segment of an abacus program where S i are states and ai are actions. Let ¯F bea vector of register values (constants and/or variables). A set of necessary and sufficient linear constraints on the initial register values¯R0 at S1 can be computed under which Sn will be reached with register values ¯F .Proof. We know ¯F = ¯R0 + (cid:2)1..n, if the linear segment is executed until Sn. However, we need to determine the conditionsunder which flow of control will not take a branch leading out of this linear segment. Since the sequence of actions isknown, register values at each state S i can be represented in terms of ¯R0. More precisely, the register vector before actionai (at S i−1) is ¯R + (cid:2)1..i−1. The condition for taking the > 0 branch of ai can therefore be expressed as ( ¯R + (cid:2)1..i−1)ai > 0.A conjunction of such expressions for each decrementing action in the given linear segment constitutes the necessary andsufficient conditions (by induction on the length of the linear segment). This conjunction can be computed in time linear inthe length of the input segment. (cid:2)Proposition 2. Suppose we are given a simple loop, S1, a1, . . . , Sn, an, S1, of an abacus program. Then in O (n) time we can computea set of linear constraints, C( ¯R0, ¯F , (cid:6)), that are satisfied by initial and final register tuples, ¯R0, ¯F , and natural number, (cid:6), iff starting anexecution at S 1 with register values ¯R0 will result in (cid:6) iterations of the loop, after which we will be in S1 with register values ¯F .Proof. Consider the action a4 in the left loop in Fig. 3. Suppose that the condition that causes us to stay in the loopafter action a4 is that Ra(4) > 0. Then the loop branch is taken during the first iteration starting with fluent-vector ¯R0 if( ¯R0 + (cid:2)1..3)a(4) > 0. For one full execution of the loop starting with ¯R0 we require, for all i ∈ {1, . . . , n}:(cid:4)¯R0 + (cid:2)1..i−1(cid:5)◦ 0a(i)where ◦ is one of {>, =} corresponding to the branch that lies in the loop; (this set of inequalities can be simplifiedby removing constraints that are subsumed by others). Since the only variable term in this set of inequalities is ¯R0, werepresent them as LoopIneq( ¯R0). Formally, for any vector of register values ¯R and a given simple loop sl, we define LoopIneqas follows:LoopIneqsl( ¯R) =n(cid:6)(cid:7)(cid:4)i=1¯R + (cid:2)1..i−1(cid:5)a(i)(cid:8)◦ 0where in the ith inequality, ◦ is the inequality on the branch following action a(i) that is in the loop. We omit the subscriptsl where it is clear from the context. Let ¯R(cid:6) = ¯R0 + (cid:6) × (cid:2)1..n, the register vector after (cid:6) complete iterations. Thus, forexecuting the loop completely (cid:6) times, the required condition is LoopIneq( ¯R0) ∧ LoopIneq( ¯R(cid:6)−1). This conjunction ensuresthat the conditions for execution of intermediate loop iterations hold, because the changes in register values due to actionsare constant, and the expression for ¯R(cid:6)−1 is linear in them. These conditions are necessary and sufficient since there is noother way of executing a complete iteration of the loop except by undergoing all the register changes and satisfying all thebranch conditions.Hence, the necessary and sufficient conditions for achieving the given register value after (cid:6) complete iterations are:¯F = ¯R(cid:6)(cid:4)≡ LoopIneq(cid:4)∧ LoopIneq¯R0, ¯F , (cid:6)¯R(cid:6)−1¯R0∧C(cid:5)(cid:4)(cid:5)(cid:5)(cid:4)(cid:5)S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–197Fig. 4. An abacus program for integer division by 2.The inequality for each action is of constant size because it concerns a single register. The total length of all the inequalitiesis O (n) and as described above they can be computed in a total of O (n) time. (cid:2)An exit during the first iteration amounts to a linear segment of actions and is handled by Proposition 1. Instead ofnon-negative integers, each component of ¯F may be an algebraic expression representing the register values which makea subsequent state in the abacus program reachable. These expressions may be derived from reachability computationsfor subsequent segments of the abacus program. More precisely, the precondition for reaching the goal by executinga segment Π j of a simple loop abacus program will be expressed in terms of the register vector at the start of Π j(say ¯R j ). Representing the precondition for reaching ¯F by executing an abacus program Π starting with the register vec-tor ¯R0 as preΠ ( ¯R, ¯F ), the precondition for reaching the goal by executing a segment Π2 followed by Π1 is computed as¯preΠ2 ( ¯R2, ¯R1) ∧ preΠ1 ( ¯R1, ¯F ). Here the final register vector for preΠ2R1. This process is similar toregression [17] but it applies to plans with loops of actions rather than acyclic plans. The following example illustrates thesepoints.is the vector of variables,Example 1. The abacus program shown in Fig. 4 can be used to divide the value of a register by 2. Suppose the initial(cid:4). The total change vector due to one iteration of the loop is (cid:2)1..3 = (cid:3)−2, +1(cid:4). LoopIneq( ¯R0)register vector is ¯R0 = (cid:3)r01 > 0 ∧ r0for this loop is r01, r0− 1 > 0; LoopIneq( ¯R(cid:6)−1) ≡ r0+ ((cid:6) − 1) · (−2) > 0 ∧ r01+ ((cid:6) − 1) · (−2) − 1 > 0.121To obtain conditions for reaching S2 via the exit from action a1 we include the condition that the value of r1 must be+ ((cid:6) − 1) · (−2) = 0. In general, this condition can be computed by treating thezero before the last application of a1: r01last, partial iteration of the loop required to reach an exit node (action a1 in this case), as a linear segment in an abacusprogram.+ r0Therefore, reachability conditions for S2 via a1 with at least one iteration of the simple loop are: r01 > 0 ∧ r0= 2((cid:6) − 1), where (cid:6) represents the number of loop iterations. The final register vector at S 2 will be ¯F = (cid:3)0, r00 ∧ r011/2(cid:4)). The conditions for reaching S2 via a1 during the first iteration are: r0(= (cid:3)0, r02necessary and sufficient conditions for reaching S 2 with register vector ¯F via a1 are: Ra1+ (cid:6) − 1(cid:4)} ∨ {r0(cid:3)0, r012In other words, if r02similarly and capture the case when r0The complete reachability conditions for S2 are Ra1be used as the components of the final register vector for precondition computation over that segment.− 1 >1+ (cid:6) − 1(cid:4)2(cid:4). Therefore, the= 2((cid:6) − 1) ∧ ¯F == 0.1 is even, then r2 will be r1/2 at S2. Reachability conditions for S2 via a2 can be computed(cid:4)}.2i could= 0; ¯F = (cid:3)0, r0≡ {(cid:6) > 0 ∧ r01(cid:4)}. If we include the condition that the final value of r2 must be r0= 2(cid:6)+ 1∧ ¯F = (cid:3)0, r0∨ Ra2 . If another segment of the program led to S1, variables r0= 0 ∧ ¯F = (cid:3)0, r0= 0 and r01 is odd. Here, we get Ra2= 1∧ ¯F = (cid:3)0, r01/2, we get r0≡ {(cid:6) > 0∧r01+(cid:6)(cid:4)}∨{r0122212When used in combination with Proposition 1, the method described above produces the necessary and sufficient con-ditions for reaching any state and register value in an abacus program:Theorem 1. Let Π A be a simple-loop abacus program. Let S be any state in the program, and ¯F a vector of register values. We can thencompute a disjunction of linear constraints on the initial register values that is a necessary and sufficient condition for reaching S withthe register values ¯F .Proof. Since Π A is acyclic except for simple loops, it can be decomposed into a set of segments starting at the commonstart-state, but consisting only of linear paths and simple loops. One approach for carrying out this process is to firstcollapse every simple loop in the graph of the abacus program into a “super node”. All edges ending or beginning at anode in a simple loop are changed to end or begin respectively, at the super node that replaced the simple loop. Theresulting graph will be acyclic and we can compute all linear paths leading from the start state to the desired state. In eachsuch path, we replace the super nodes with their corresponding simple loops. During this process, we re-attach the edgesfrom neighbors of the super node to the original nodes that they were attached to. By Propositions 1 and 2, necessaryand sufficient conditions for each of these segments can be computed. The disjunctive union of these conditions gives the8S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–19Fig. 5. Many “nested” loops encountered in programming can be viewed as simple loops with shortcuts by distinguishing the loop-orienting node from theloop entry node. In this example, the linear path from a1 to j < k can be treated as a linear segment, followed by a simple loop with shortcuts.desired necessary and sufficient condition. In the worst case, the total size of the disjunction could be exponential in thenumber of nodes in the graph. (cid:2)4. Nested loops due to shortcutsDue to the undecidability of the halting problem for abacus programs, it is impossible to find preconditions of abacusprograms with arbitrarily nested loops. The previous section demonstrates, however, that structurally restricted classes ofabacus programs admit efficient applicability tests.In this section, we show that methods developed in the previous section can be extended to a class of graphs represent-ing nested loops obtained by adding unidirectional paths, or shortcuts to a simple loop. We first define the general class ofnon-simple loops as follows:Definition 7 (Complex loops). Let A be an abacus program. A complex loop in A is a non-trivial strongly connected compo-nent that is not a simple loop.In particular, we will be interested in a special class of complex loops, i.e., those obtained by adding “shortcuts” in asimple loop:Definition 8 (Simple loop with shortcuts). Let A be an abacus program. A simple loop with shortcuts in A is a stronglyconnected component C which includes a node n0, designated the loop-orienting node, such that removing n0 makes Cacyclic.We say that an abacus program has only simple loops with shortcuts if all its strongly connected components are simpleloops with shortcuts.Note that a loop-orienting node may be labeled with either an action or a state. Intuitively, such a simple loop withshortcuts consists of a simple loop with all elements, starting at the loop-orienting node, in increasing linear order. For anypair of nodes along the loop, a preceding b, a shortcut from a to b may be added; different shortcuts may overlap as longas this does not create cycles. (e.g., state S2 can be designated the loop-orienting node in Fig. 3). The loop-orienting nodedoes not have to be the node through which the flow of control enters a simple loop with shortcuts. Indeed, if we wishto determine the preconditions with respect to a node other than the loop-orienting node as the “entry” node for a givensimple loop with shortcuts, we first find the preconditions with respect to the loop-orienting node as the entry node andthen propagate these conditions back along the acyclic path(s) connecting the entry node to the loop-orienting node (byTheorem 1 as applied to an acyclic segment of the abacus program).Simple loops with shortcuts form a very general class of complex loops: graph theoretically, this is exactly the class ofstrongly connected components with cycle rank 1 [6]. Many control flows that are typically understood as “nested” loopsin programming can be represented as simple loops with shortcuts by choosing an appropriate loop-orienting node. Fig. 5shows an example. Further, for abacus programs we show in Section 4.1 that this class of graphs is powerful enough toexpress any computation.The advantage of this class of loops is that we can decompose them into simple loops; in the definition below, a cyclehas no repeated states other than the start and end states.Definition 9 (Loop decomposition). Let A be an abacus program and let C a strongly connected component of A in the formof a simple loop with shortcuts, with the loop-orienting node n0. The loop decomposition of C is defined as the set of allcycles of C beginning with n0.S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–199Fig. 6. Construction for translating a general abacus program into one with a simple loop with shortcuts.In the worst case, the size of this decomposition can be exponential in the number of shortcuts. This construction provesuseful because in a simple loop with shortcuts, every cycle must contain the loop-orienting node (this is immediate fromDefinition 8). Thus, the execution of a simple loop with shortcuts in an abacus program can be viewed as a sequence ofcomplete executions of the simple loops in its decomposition. For instance, we can view the loop with shortcuts in Fig. 3as consisting of 3 different simple loops. The order of execution of these loops, and whether a given loop will be executedat all, will depend on the results of actions a3 and a5.We now define a special class of simple loops with shortcuts for abacus programs. In the next section we presentmethods for finding preconditions of such programs.Definition 10 (Monotone simple loops with shortcuts). Let the net change on a register due to a simple loop in an abacusprogram be the total change that will be caused on that register in one full execution of the loop. A simple loop withshortcuts in an abacus program is monotone iff for every register, the sign (positive or negative) of the net change, if any,on that register is the same for every simple loop in its decomposition.In the next section we show that removing this restriction can significantly increase the power of abacus programs: anyabacus program can be represented as a program consisting of a simple loop with possibly non-monotone shortcuts.4.1. Relaxing monotonicityWe now consider the problem of computing the preconditions of an abacus program with simple loops with shortcutsthat need not be monotone. As noted earlier, in terms of computational expressiveness this class is very powerful. We showbelow that any abacus program can effectively be represented as a program consisting of one simple loop with shortcuts.Theorem 2. Let Πg be an abacus program with R g , N g and E g as the sets of registers, nodes and edges respectively. Then there existsan equivalent abacus program, ΠS with R S (⊇ R g), N S (⊇ N g), and E S as the sets of registers, nodes and edges respectively, such that:1. ΠS consists of one simple loop with shortcuts.2. Execution of Πg with an initial register vector ¯Rinit is equivalent to that of ΠS with an initial vector ¯Rreachable with a register vector ¯R f in Πg iff it is reachable in ΠS with a register vector ¯Rfrom R g .(cid:5)init: a node n ∈ N g isf which matches ¯R f on all the registers(cid:5)Proof. In order to construct ΠS , we add a new flag register li for each ni ∈ N g . The values of these flag registers will neverrise above 1; at any stage during execution, at most one of the flag registers will be non-zero. We will use these flags totranslate edges from Πg into a set of “case statements” starting with a common, new start state.Let n0 → a0, a0 → n1, a0 → n2 be a set of edges corresponding to a single (decrementing) action a0 inConstruction of ΠS .Πg . We translate this sequence into a sequence beginning with the action decrementing l0. The > 0 branch from this actionrepresents the case that we were at state n0. This branch will lead to the node for a0; the two branches from a0 lead toactions incrementing l1 and l2, corresponding to the branches that lead to n1 and n2. The construction is illustrated in Fig. 6.The translation is similar for incrementing actions. To get ΠS , we perform this construction for the edges corresponding toeach action in Πg in this manner and attach the each resulting graph to the = 0 branch of the last flag decrementing action,as shown in Fig. 6. The resulting abacus program ΠS consists of one simple loop with shortcuts.Computation of ¯Rcorresponding to Πg ’s start state is initialized as 1 and all the other flag registers are initialized as 0.init. The initial values for all the original registers R g are the same as those in ¯Rinit; the flag register(cid:5)By construction, executing an action on a register vector leads to a node niin Πg iff executing that action on theextended register vector with all flag variables zero (note that the flag-testing action also decrements the only non-zero flag10S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–19to zero) leads to li , and subsequently, ni in ΠS . By induction on path lengths, we therefore have the result that a node ni isreachable from ¯Rinit in Πg iff it is reachable from ¯R(cid:5)init in ΠS . (cid:2)Simple loops with non-monotone shortcuts are therefore sufficient to capture the power of Turing machines:Corollary 1. The class of abacus programs whose strongly connected components are simple loops with shortcuts is Turing-complete.Removing the condition of monotonicity therefore makes the problem of computing preconditions of abacus programswith simple loops with shortcuts unsolvable. Currently, there are no intermediate characterizations of simple loops withshortcuts that bridge the gap between monotone shortcuts, where this paper demonstrates the existence of efficient meth-ods for finding preconditions, and non-monotone loops where the problem becomes undecidable. An important direction forfuture work is to identify useful, yet tractable generalizations of the notion of monotonicity where reachability conditionscan be computed.5. Applicability conditions for monotone simple loops with shortcutsWe now consider the problem of computing applicability conditions for monotone simple loops with shortcuts. We firstpresent the more specific case of programs with deterministic actions. In the following section we present methods forcomputing reachability conditions for abacus programs with non-deterministic actions.5.1. Deterministic monotone shortcutsWe address the problem of determining whether a program will terminate with a given register vector by designingan algorithm which takes as input an initial register vector, and provides a yes/no answer. More precisely, the algorithmwill efficiently compute the final register vector for the given initial register vector. Without loss of generality, we considerthis problem in the setting where we have a single simple loop with shortcuts and the start state for the program is theloop-orienting node of this loop.Our approach relies on the following observations:1. Because of monotonicity, if a loop is executed for a certain number of iterations and then exited, flow of control willnever return to that loop.2. For any given configuration of register values with which a loop-orienting node is reached, at most one of the sim-ple loops in the given loop’s decomposition may be completely executable. This is because if multiple simple loopscan be executed starting from a given register value configuration, then at some action in the program, it should bepossible for the control to flow along more than one outgoing edge. However, this is impossible because every actionwhich has multiple outcomes (a decrementing action) has exactly two branches, whose conditions are always mutuallyinconsistent.As a consequence of the second observation, given such an abacus program and an initial register vector, we can computethe first loop which will be executed and the number of iterations for which it will be executed (the precise method forcomputing this is described below); we can then remove this loop from consideration because of the first observation andrepeat the process. This can be continued until no loop can be executed completely. When this process terminates, we getthe sequence of loops and the number of iterations of each that must be executed before exiting the given simple loop withshortcuts.Taking an initial register valuation as input, Algorithm 1 performs these computations. Let Π A be an abacus programin the form of a simple loop with monotone shortcuts and only deterministic actions. Algorithm 1 works by identifying¯the unique loop (cid:6) whose LoopIneq(cid:6) is satisfied by the value ¯R (initialized toR0) [steps 5–8], calculating the number ofiterations which will be executed for that loop until LoopIneq(cid:6) gets violated [step 9], updating the register values to reflectthe effect of those iterations [step 12] and identifying the next loop to be executed [the while loop, step 4].The subroutine FindMaxIterations uses the inequalities in LoopIneq(cid:6) (see Proposition 2) to construct the vector equation( ¯R + (cid:6)max(cid:2)(cid:6) + (cid:2)1..i−1)a(i) ◦ 0 for every action in loop (cid:6). This system of equations consists of an inequality of the followingform for every i corresponding to a decrementing action in the loop:(cid:4)(cid:5)(cid:6)max <¯Ra(i) + (cid:2)1..i−1a(i)/(cid:2)(cid:6)a(i)Since ¯R is always known during the computation, the floor of minimum of the RHS of these equations for all i yieldthe largest possible value of (cid:6)max. Equality constraints either drop out (if the net change in their register’s value due to theloop (cid:6) is zero and they are satisfied during the first iteration), or set (cid:6)max = 1 (if the net change in their register’s value isnot zero, but it is satisfied during the first iteration). Equality constraints will be satisfied when FindMaxIterations is calledbecause we know that LoopIneq(cid:6) was satisfied. Note that if there is any loop which does not decrease any register’s value,it will never terminate. This will be reflected in our computation by an (cid:6)max value of ∞ [step 11]. Thus, we have:S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–1911Algorithm 1: Reachability for deterministic, monotone shortcutsInput: Deterministic abacus program in the form of a simple loop with monotone shortcuts with loop-orienting node (say thestate Sstart ), an initial register configurationOutput: Sequence of (loop id, #iterations) tuples and final value of ¯R at Sstart .¯R01 ¯R ← ¯R02 Iterations ← empty list3 LoopList ← simple loops in the loop decomposition4 while LoopList (cid:16)= ∅ do5if no (cid:6) ∈ LoopList satisfies LoopIneq(cid:6)( ¯R) then6789101112Return Iterationsend(cid:6) ← id of loop for which LoopIneq(cid:6)( ¯R) holdsRemove (cid:6) from LoopList(cid:6)max ← FindMaxIterations( ¯R, (cid:6))if (cid:6)max = ∞ thenReturn “Non-terminating loop”endIterations.append(((cid:6), (cid:6)max))¯R ← ¯R + (cid:6)max(cid:2)(cid:6)end13 Return Iterations, ¯RTheorem 3. Given a deterministic abacus program Π in the form of a simple loop with monotone shortcuts, a loop-orienting noderepresenting state S, and an initial register vector ¯R0, Algorithm 1 returns the number of times each simple loop in Π ’s decompositionwill be executed, the register vector at S after all these iterations as well as the order of execution of the simple loops in the loopdecomposition of Π .Depending on the rest of the abacus program, the final register vector output by Algorithm 1 can be used as the initialregister vector for determining the reachability of a subsequent state with a desired register vector.Let b be the maximum number of branches in a loop in the decomposition of the given simple loopComplexity analysis.with shortcuts, and L the total number of simple loops in the decomposition. The most expensive operation in this algorithmis step 5, where ¯R is tested on every loop’s inequality (these loop inequalities only need to be constructed once). Step 5is executed in O (Lb) time and step 9 in O (b) time. The entire loop may be executed at most L times, resulting in atotal execution time of O (L2b). On the other hand, if such a program is directly applied on a problem instance and theprogram terminates, then the execution time for the program will be of the order of the largest input register value, whichis unbounded.5.2. Non-deterministic monotone shortcutsWe now consider the problem of computing applicability conditions for abacus programs whose simple loops have mono-tone shortcuts with non-deterministic actions. We presented methods for extending the approach of creating generalizedplans with cardinality changes (summarized in Section 2) to this setting in prior work [23].We will find that the accuracy of the reachability conditions that we compute is determined by order independence(Definition 11), or the extent to which the execution of different loops in the decomposition of a simple loop with shortcutscan be rearranged without significantly affecting the overall outcomes. The methods discussed in this section can also beapplied to settings with only deterministic actions—yet, simple loops with shortcuts in most such situations demonstrateorder dependence. Therefore, reachability conditions obtained in this manner will tend to be subsumed by those computedusing methods from Section 5.1.Suppose an abacus program Π is a simple loop with shortcuts which can be decomposed into m simple loops withthe loop-orienting node representing a state, Sstart (analysis for the case where the loop-orienting node is labeled with anaction is analogous). We consider the case of l complete iterations of Π counted at its loop-orienting node, with k1, . . . , kmrepresenting the number of times loops 1, . . . , m are executed, respectively. The final, partial iteration and the loop exit canbe along any of the simple loops and can be handled as a linear program segment. Then,k1 + · · · + km = l(1)Determining final register values. We denote the ith loop in the decomposition of the given simple loop with shortcuts asloopi . The final register values after the l =mi=1 ki complete iterations (provided that these iterations are indeed executed(cid:9)12S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–19without exiting the simple loop with shortcuts) can be obtained by adding the changes due to each simple loop, with (cid:2)loopidenoting the change vector due to loopi :¯F = ¯R0 +m(cid:10)i=1ki(cid:2)loopi(2)Let R+, R−Cumulative branch conditions. For computing sufficient conditions on the achievable register values after k1, . . . , km completeiterations of the given loops, our approach is to treat each loop as a simple loop and determine the preconditions forexecuting it. Note that every required condition for a loop’s complete iteration stems from a comparison of a register’svalue with zero. We consider the case where the conditions required for staying in the loop are always > 0 and discussthe situation with equality constraints in the following section (“Accuracy of the Computed Conditions”). Thus, we want todetermine the lowest possible value of each register during the k1, . . . , km iterations of loops 1, . . . , m, and constrain thatvalue to be greater than zero.be the sets of registers undergoing net non-negative and negative changes respectively, by any loop. Thesequence of actions in an iteration of a simple loop may first decrease a register and then increase it. Through this process,the net decrease in a register due to one full iteration of a simple loop may be smaller than the greatest decrease thatit underwent due to a an initial segment of the loop. We denote the change due to an initial segment (w.r.t. the loop-orienting node) of a simple loop on a register as a partial change due to that loop on that register. Let δij be the greatestpartial negative change caused on R j by loopi . Let min( j) = arg minx{δxj : x ∈ {1, . . . , m}}.For R j ∈ R+, the lowest possible value is R0j+ δmin( j)jThe required constraint on R j ∈ R++ δmin( j)jrefers to the register value before a decrement takes place).therefore is R0j, since the value of R j can only increase after the first iteration.(cid:2) 0 (we require “(cid:2) 0” because the condition “> 0” on an edgeWe now compute a lower bound on the least value of R j that can be achieved with k1, . . . , km iterations of loops 1, . . . , mrespectively.Lemma 1. In any execution of k1, . . . , km iterations of loops 1, . . . , m, the value of register R j can never fall below R0jˆjj, where ˆj = arg minx{δxj: x ∈ {1, . . . , m}}.− (cid:2)loopxjloop ˆjj− (cid:2)δ+(cid:9)mi=1 ki(cid:2)loopij+Proof. Suppose the last loop to be executed is loopx. If δxj , then the least possible value of R j during the last executionjof loopx is given by first computing the value of R j after execution of all iterations of all the required loops, and thensubtracting from it the effect of one complete iteration of loopx, and adding δxj , the greatest partial negative change of loopx:(cid:16)= (cid:2)x+R0jm(cid:10)i=1ki(cid:2)loopij− (cid:2)loopxj+ δxjTo obtain the lowest value of this expression over all possible choices for the last loop, we need to minimize thisexpression w.r.t. x. In most cases encountered in planning, this can be done effectively by choosing the loop which minimizesδxj and using that loop for x (this method was used by Srivastava et al. [22]). In this paper, we use the more general approachby selecting the last loop, ˆj , as follows:(cid:7)ˆj = arg min: x ∈ {1, . . . , m}(cid:8)δxj− (cid:2)loopxjx(cid:9)This minimization requires the same number of comparison operations as the minimization over δxj alone.Let Rlbj= R0j+mi=1 ki(cid:2)loopi+ δ− (cid:2)ˆjjloop ˆjj. Our claim is that this expression is a lower bound on the possible values of R jin any execution of the given loops and their iteration counts. Suppose this is not true. Then, a strictly lower value of R jmust be achieved during an execution of some loop, loopq, which is not the last loop to be executed. This is not possiblehowever, because R j ∈ R−and every successive loop iteration can only decrease its value. (cid:2)jNow that we can compute the minimum possible values of all registers, we can state the required constraints as:(cid:11)∀R j ∈ R−+R0jm(cid:10)ki(cid:2)loopij+δˆjj−(cid:2)loop ˆjj(cid:2) 0(cid:12)(cid:7)+R0ji=0+ δmin( j)j(cid:8)(cid:2) 0∀R j ∈ R(3*)(4*)Together with Eqs. (1)–(2), these inequalities provide sufficient conditions binding reachable register values with thenumber of loop iterations and the initial register values. However, the process for deriving them assumed that for every j,loop ˆj and loopmin( j) will be executed at least once. We can make these constraints more accurate by using a disjunctiveS. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–1913formulation for selecting the loop causing the greatest negative change among those that are executed at least once. Forregister R j , let 0 ˆj , . . . , m ˆj be the ordering of loops in increasing order of the values δx. We will use this ordering forjwriting the constraints for registers in R−j , withthe intended purpose of writing constraints for registers in R+. In each of the following constraints, we will use ki<x = 0to denote the constraints {ki = 0: i < x}, where the ordering is the one being used in that constraint. We can now writedisjunctions of constraints corresponding to the first loop in these orderings that is executed at least once, as follows:. Similarly, let 0 j, . . . , mj be the ordering of loops in increasing values of δx− (cid:2)loopxj(cid:13)(cid:14)ki<x = 0; kx (cid:16)= 0; R0j(cid:10)+ki(cid:2)loopij+ δxj− (cid:2)loopxj(cid:2) 0(cid:15)∀R j ∈ R−∀R j ∈ R+x=0 ˆj ,...,m ˆj(cid:13)(cid:7)ki<x = 0; kx (cid:16)= 0; R0jx(cid:2)i(cid:2)m ˆj(cid:8)(cid:2) 0+ δxjx=0 j,...,m j(3)(4)Constraints (3) and (4) are derived from (3*) and (4*) by replacing the argmins ˆj and min( j) by the variable x, whichiterates over loops in the order 0 ˆj , . . . , m ˆj for registers in R−and in the order 0 j, . . . , mj for registers in R+.Constraint (3) is tighter than (3*) only when changing the loop that executes last will have an impact on the lowestwill be the same for every loop for each register R j , representing thevalue of at least one register. Otherwise, δx − (cid:2)loopxsituation where the lowest achievable value of register R j is independent of which loop’s execution occurs last.jThe following example illustrates the computation of conditions (3) and (4).Example 2. Suppose the decomposition of an abacus program in the form of a simple loop with shortcuts consists of twoloops. A single iteration of loop1 first decrements R1 by 5 (i.e., the “first” five actions starting from the loop-orienting nodeare decrements) and then increments it by 1. A single iteration of loop2 first decrements R1 by 3 and then increments itby 2. Effects on register R2 are as follows. A single iteration of loop1 first decrements R2 by 2 and then increments it by 3;loop2 first decrements R2 by 1 and then increments it by 2.Conditions (1) and (2) are easily computed. We need to compute condition (3) for R1 since it undergoes a net decrement.In this example, the greatest partial negative changes (δxare−4, −1 for x = 1, 2 respectively. The expressions δxevaluate to −1, −2 for x = 1, 2 respectively, and therefore thejordering of loops 1 and 2 in increasing order of this value is {2, 1}. Consequently, the lowest possible value of R 1 willoccur when loop2 is executed last, by Lemma 1. Thus, we first write the conditions when loop2 is executed last: k2 > 0 and− 4k1 + 4 − 5 =R01R01− 4k1 − k2 + 1 − 3 = R01− 4k1 − 1 > 0. The disjunction corresponding to condition (3) therefore is:(cid:5)− 4k1 − k2 − 2 (cid:2) 0. If loop2 is never executed, we have k2 = 0, k1 > 0 and R01) are −5, −3 for x = 1, 2 respectively; the net changes, (cid:2)loopx− (cid:2)loopxj(cid:5)11(cid:4)k2 (cid:16)= 0 ∧ R01− 4k1 − k2 − 2 (cid:2) 0∨(cid:4)k2 = 0 ∧ k1 (cid:16)= 0 ∧ R01− 4k1 − 1 (cid:2) 0Condition (4) is computed by ordering the loops in increasing order of δxrespectively. Thus the desired condition (4) is:− 2 (cid:2) 0(cid:4)k1 = 0 ∧ k2 (cid:16)= 0 ∧ R02(cid:4)k1 (cid:16)= 0 ∧ R02− 1 (cid:2) 0∨(cid:5)(cid:5)2, which takes the values −2, −1 for x = 1, 2We could also use conditions (3*) and (4*) to compute a more conservative (not complete) condition for executing k1 and k2iterations of loops 1 and 2:R01− 4k1 − k2 − 2 (cid:2) 0 ∧ R02− 2 (cid:2) 0These conditions do not use the loop orderings but miss only a small number of initial register values which would alsohave allowed the required iterations of both loops.5.2.1. Accuracy of the computed conditionsIn order to discuss when conditions (1)–(4) are accurate we first define order independence:Definition 11 (Order independence). A simple loop with shortcuts is order independent if for every initial valuation of theregisters at Sstart, the set of register values possible at Sstart after any number of iterations does not depend on the order inwhich those iterations are taken.An equality constraint in a loop is considered spurious, if no loop created by the shortcuts changes the register on whichequality is required. During the execution of the loop, the truth of such conditions will not change. Consequently, suchequality conditions do not introduce order dependence. In practice, these conditions can be translated into conditions onregister values just prior to entering the loop.A simple loop with shortcuts will have to be order dependent if one of the following holds: (1) the lowest value achiev-able by a register during its execution depends on the order in which shortcuts are taken. In this case, possible lowest valueswill impose different constraints for each ordering; or, (2) a non-spurious equality condition has to be satisfied to stay in14S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–19a loop. In the latter case, the non-deterministic branch leading to the shortcut that has the equality condition will have tobe taken at the precise iteration when equality is satisfied. In fact, the disjunction of these two conditions is necessary andsufficient for a loop to be order dependent.Proposition 3. A simple loop with shortcuts is order dependent iff either (1) the lowest value achievable by a register during itsexecution depends on the order in which shortcuts are taken or (2) a non-spurious equality condition has to be satisfied to continue aloop iteration.Proof. Sufficiency of the condition was discussed above. If the loop is order dependent, then there is a register value thatis reachable only via a “good” subset of the possible orderings of shortcuts. Consider an ordering with the same number ofiterations of these shortcuts, not belonging to this subset. During the execution of this sequence, there must be a first stepafter which a loop iteration that could be completed in the good subset, cannot be completed in the chosen ordering. Thishas to be either because an inequality > 0 is not satisfied before a decrement, which implies (1) holds, or because R j = 0is required to continue the iteration; this must have been possible in the good loop orderings, but R j > 0 must hold here,which implies case (2) holds. (cid:2)A naive approach of even expressing the necessary conditions for an order dependent loop can be exponential in thenumber of shortcuts, even while considering just a single iteration of each loop. We can now see the computation of ˆj ashandling a very specific kind of order dependence, when the lowest value of a register only depends on the last iteration tobe executed.Example 3. Consider loops l1, l2 in the decomposition of a simple loop with monotone shortcuts in an abacus program. l1increases R1 by 5 and R2 by 1. l2 first decreases R1 by 4 and then increases it by 5. l1, l2 are monotone shortcuts but theircombination is order dependent: at S start with R1 = 1, l2 cannot be executed completely before executing l1. Expressingprecise preconditions for reachable register values thus requires a specification of the order in which the shortcuts have tobe taken.Loops with non-spurious equality constraints are thus special cases of order dependent loops. Although we did notencounter any loops with non-spurious equality constraints in any of the test problems we considered, conditions (1)–(4)can be extended to include equality conditions for the first and last iteration of each loop. Because the registers increaseor decrease monotonically, this will make (1)–(4) sufficient (but not necessary) conditions for situations where equalitybranches are required to stay in the loop. Unfortunately, in the worst case this can also make (1)–(4) unsatisfiable. We cannow present two results capturing the accuracy of the conditions (1)–(4).Proposition 4. If Π is an order independent simple loop with monotone shortcuts, then Eqs. (1)–(4) provide necessary and sufficientconditions on the initial and achievable register values.Proof. By construction, the inequalities ensure that none of the register values drops to zero, so that if a register valuesatisfies the inequalities, then it will be reachable. This proves that the conditions are sufficient. Suppose that a registervalue ¯F is reachable from ¯R0, after k0, . . . , km iterations of loop0, . . . , loopm respectively. Eq. (2) cannot be violated, becausethe changes caused due to the loops are fixed; Eq. (1) will be satisfied trivially. If ¯R0, k0, . . . , km don’t satisfy Eqs. (3–4), thelowest value achieved during the loop iterations will fall below zero because the loop is order independent. Therefore, (1–4)must be satisfied. (cid:2)Proposition 5. If Π is a simple loop with monotone shortcuts, then Eqs. (1)–(4), together with constraints required for equalitybranches during the first and last iterations of the shortcuts containing them give sufficient conditions on the possible final registervalues in terms of their initial values.Proof. By construction, conditions (1)–(4) and the equality constraints ensure that every branch required to complete kiiterations of loop i will be satisfied. (cid:2)In other words, if we don’t have order independence, the conditions (1)–(4) are sufficient, but not necessary. In adver-sarial formulations however, if the next simple loop to be executed depends on non-deterministic actions, then we requireexactly the conditions (1)–(4) which ensure that all the stipulated iterations of all the loops will be executed. In Section 6we present several examples of this scenario. This leads to the main result of this section, which is analogous to Theorem 1for simple loops.Theorem 4. Let Π be an abacus program, all of whose strongly connected components are simple loops with monotone shortcuts. LetS be any state in the program, and ¯F a vector of register values. We can then compute a disjunction of linear constraints on the initialS. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–1915Table 1Timing results for computing preconditions.ProblemTime (s)ProblemTime(s)AccumulatorCorner-ADiagonalHall-APrize-A(5)0.010.000.010.010.01Prize-A(7)RecyclingStriped TowerTransportTransport (conditional)0.020.020.020.010.06Fig. 7. Solution plan for the transport problem.register values for reaching S with the register values ¯F . If all simple loops with shortcuts in Π are order independent, the obtainedprecondition is necessary and sufficient.Proof. Similar to the proof by decomposition for Theorem 1, using Propositions 4 and 5. (cid:2)Semantics of the computed conditions. Since we are working in the setting where non-deterministic actions are allowed,the variable ki may implicitly capture the number of times particular outcomes of non-deterministic actions presentin loopi must occur during its ki iterations. This may appear to be measuring an inherently unpredictable property (non-determinism) and seem to mitigate the utility of the computed preconditions. However, as we will see in Section 6,non-deterministic abacus actions may stand for sensing actions; while we may not be able to predict the outcome ofeach sensing action, it may still be possible to know how many times a certain outcome is possible, which is all that weneed to use the conditions above. In addition, if ki ’s are used as parameters, the conditions above capture their tolerablevalues under which a desired register value may be achieved.In this section we addressed the problem of determining when a program can reach a certain state with a given registervector by deriving constraints between the initial and final register values for a given abacus program. In order to achievethese results, we used the concept of order independence to summarily deal with a collection of simple loops and thenumber of times each had to be executed.These methods could also be applied to deterministic programs but the methods we proposed in Section 5.1 will bemore accurate in general. This is because simple loops with shortcuts that are created by deterministic actions are highlyorder dependent: they include non-spurious equality conditions due to which the order of execution of loops is determinedexactly by the initial register values.6. Example plans and preconditionsWe implemented the algorithm for finding preconditions for simple loops and order independent nested loops due toshortcuts, and applied it to various plans with loops that have been discussed in the literature (references are includedwith the descriptions below). Existing approaches solve different subsets of these problems, but almost uniformly withouttermination guarantees [14,1].Our system takes as input an abacus program or a generalized plan with cardinality changes marked for each action. Forevery strongly connected component, it first determines if it is a simple loop. If not, it determines whether the componentis a simple loop with shortcuts. In order to do so it searches for a loop-orienting node, removal of which would make theentire component acyclic. If no such node exists, or if the shortcuts are found to be non-monotone then the input cannotbe handled using our methods and failure is reported. Reachability conditions are constructed for simple loops and simpleloops with monotone shortcuts as described in the previous sections. Table 1 shows timing results for 10 different plans.Plan representation. Figs. 7, 8 and 9 show solution plans for some of the test problems. In order to make the plans easyto read, we show only actions. The default flow of control continues line by line (semicolons are used as linebreaks).Edges are shown when an action may have multiple outcomes and are labeled with the conditions that must hold priorto action application for that edge to be taken (as with abacus programs). Only the edges required to continue executing16S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–19Fig. 8. Solution plan for the conditional version of transport.Fig. 9. Solution plan for the recycling problem.the plan are drawn; the preconditions must ensure that these edges are always taken. For clarity, in some cases we labelonly one of the outcomes of an action, and the others are assumed to have the complement of that label. Actions arewritten as “ActionName(args:argument-formula(args))”. Any object satisfying an action’s argument formula may be chosenfor executing the plan. The desired halt nodes are indicated with the action “Stop”.Transport.In the transport problem [21] two trucks have to deliver sets of packages through a “Y”-shaped roadmap. Lo-cations D1, D2 and D3 are present at the three terminal points of the Y; location L is at the intersection of its prongs.Initially, an unknown number of servers and monitors are present at D1 and D2 respectively; trucks T1 (capacity 1) and T2(capacity 2) are also at D1 and D2 respectively. The goal is to deliver all objects to D3, but only in pairs with one of eachkind.The problem is modeled using the predicates {server, monitor, atD i, inT i, atL, T 1, T 2}. As discussed in the previous sec-tion, role-counts in this representation can be treated as register values and actions as abacus actions on these roles. Theplan shown in Fig. 7 first moves a server from D1 to L using T1. T2 picks up a monitor at D2, moves to L, picks up the serverleft by T1 and transports both to D3. The first action, load, uses as its arguments an object s (satisfying server(s) ∧ atD1(s)),and the constant T1 representing the truck T1. It decrements the count of the role {server, atD1} and consequently hastwo outcomes depending on its value. Note that the second load action in the plan also has two outcomes, but only theone used in the plan is shown. In order to reach the Stop state with the goal condition, we require that final values ofs1 = #{server, atD1} and m2 = #{monitor, atD2} be zero. Let s3 = #{server, atD3} and m3 = #{monitor, atD3}. The changescaused due to one iteration of the loop are +1 for m3, s3 and −1 for s1, m1. Using the method developed in Proposition 2,the necessary and sufficient condition for reaching the goal after l iterations of the loop is that there should be equalnumbers of objects of both types initially: m02= l = s01.Transport conditional.In the conditional version of the transport problem [23], objects left at L may get lost, and serversmay be heavy, in which case the forkLift action has to be used instead of the load action. Fig. 8 shows a solution plan foundby merging together plans which encountered and dealt with different non-deterministic action outcomes [23]. If a server isnot found when T2 reaches L, the plan proceeds by moving T2 to D1, loading a server, and then proceeding to D3. Note thatthe shortcut for the “server lost” has a sub-branch, corresponding to the server being heavy. The plan can be decomposedS. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–1917into 8 simple loops. Of these, 4, which use the “server lost” branch use one extra server (loops 0, 5, 6 and 7 in the inequalitybelow). Let role-counts s2, m2, s3, m3 be as in the previous problem. Then, the obtained applicability conditions are:sf3= mf3=7(cid:10)i=0ki,mf2= m02−7(cid:10)i=0ki = 0,sf1= s01−7(cid:10)i=0ki − k0 − k5 − k6 − k7 = 0These conditions show that every possible loop decrements the role-counts s and m; however, in order to have all objectsat D3 the conditions now require extra servers to be kept at D1, amounting to the number of times a server was lost.Recycling.In this problem a recycling agent must inspect a set of bins, and from each bin, collect paper and glass objects intheir respective containers. The solution plan includes nested loops due to shortcuts (Fig. 9), with the start state at PickObj.senseType is a sensing action, and the collect actions decrement the available capacity of each container, represented asthe role-count of {for X, ¬full} where X is paper or glass. Let e,f p, p, denote the role-counts of non-empty bins,glass container capacity, paper container capacity, paper objects and glass objects respectively. Let l1 denote the number ofiterations of the topmost loop, l2 of the paper loop and l3 of the glass loop. The applicability conditions are:f g,e f = e0 − l1 = 0,f p f = f p0 − l2 (cid:2) 0,p f = p0 + l2,f g f = f g0 − l3 (cid:2) 0,g f = g0 + l3Note that the non-negativity constraints guarantee termination of all the loops.Accumulator. The accumulator problem [14] consists of two accumulators and two actions: incr_acc(i) increments register iby one and test_acc(), tests if the given accumulator’s value matches an input k. Given the goal acc(2) = 2k − 1 where k isthe input, Kplanner computes the following plan:incr_acc(1);repeat {incr_acc(1); incr_acc(2); incr_acc(2)}until test_acc(1);incr_acc(2).Although the plan is correct for all k (cid:2) 1, Kplanner can only determine that it will work for a user-provided range ofvalues. This problem can be modeled directly using registers for accumulators and asserting the goal condition on the finalvalues after l iterations of the loop (even though there are no decrement operations). We getacc(1) = l + 1;acc(2) = 2l + 1 = 2k − 1This implies that l = k − 1 (cid:2) 0 iterations are required to reach the goal.Further test problems and discussion. We tested our algorithms with many other plans with loops. Table 1 shows a summaryof the timing results. The runs were conducted on a 2.5 GHz AMD dual core system. Problems Hall-A, Prize-A(5) and Prize-A(7) [1] concern grid world navigation tasks. In Hall-A the agent must traverse a quadrilateral arrangement of corridors ofrooms; the prize problems require a complete grid traversal of 5 × n and 7 × n grids, respectively. Note that at least one ofthe dimensions in the representation of each of these problems is taken to be unknown and unbounded. Our implementationcomputed correct preconditions for plans with simple loops for solving these problems. In Hall-A, for instance, it correctlydetermined that the numbers of rooms in each corridor can be arbitrary and independent of the other corridors. TheDiagonal problem is a more general version of the Corner problem [1] where the agent must start at an unknown positionin a rectangular grid, reach the north-east corner and then reach the southwest corner by repeatedly moving one step westand one step south. In this case, our method correctly determines that the grid must be square for the plan to succeed.In Striped Tower [21], our approach correctly determines that an equal number of blocks of each color is needed in orderto create a tower of blocks of alternating colors. In all the problems, termination of loops is guaranteed by non-negativityconstraints such as those above.7. Related workAlthough various approaches have studied the utility and generation of plans with loops, very few provide any guaranteesof termination or progress for their solutions. Approaches for cyclic and strong cyclic planning [3] attempt to generate planswith loops for achieving temporally extended goals and for handling actions which may fail. Loops in strong cyclic plansare assumed to be static, with the same likelihood of a loop exit in every iteration. The structure of these plans is suchthat it is always possible–in the sense of graph connectivity–to exit all loops and reach the goal; termination is thereforeguaranteed if this can be assumed to occur eventually. Among more recent work, Kplanner [14] attempts to find planswith loops that generalize a single numeric planning parameter. It guarantees that the obtained solutions will work in auser-specified interval of values of this parameter. Distill [26] identifies loops from example traces but does not address theproblem of preconditions or termination of its learned plans. Bonet et al. [1] derive plans for problems with fixed sizes, butthe controller representation that they use can be seen to work across many problem instances. They also do not addressthe problem of determining the problem instances on which their plans will work, or terminate.18S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–19Finding preconditions of linear segments of plans has been well studied in the planning literature [7]. Approaches forregression [17,9] in planning directly address the problem of computing preconditions of acyclic plan segments. However,there has been no concerted effort towards finding preconditions of plans with loops. Static analysis of programs deals withsimilar problems of finding program preconditions [5]. However, these methods typically work with the weaker notion ofpartial correctness [12], where a program is guaranteed to provide correct results if it terminates. Methods like Terminator [4]specifically attempt to prove termination of loops, but do not provide precise preconditions or the number of iterationsrequired for termination.8. Conclusions and future workIn this paper we presented an approach for formulating and studying the problem of determining when a certain loopof actions can be guaranteed to (a) terminate, and (b) lead to a desired result. We showed how this problem can be studiedeffectively as the problem of reachability of desired states in the context of primitive actions that can only increase, decreaseor non-deterministically change the value of some counters. Although this approach is the first to address this problemcomprehensively, it is very efficient and scalable for commonly encountered loops of actions in planning. In addition tofinding preconditions of computed plans, it can also be used as a component in the synthesis of plans with safe loops.We established tractability results of reachability analysis for several classes of plans or programs with such actions. Forsimple loops of actions, this problem admits very efficient algorithms; slight extensions to this class of loops (i.e., simpleloops with shortcuts), however, were found to be general enough to capture the full power of Turing machines and thereforehad an undecidable reachability problem (Theorem 2) in general. On the other hand, the property of monotonicity in thiscase does permit development algorithms for determining reachability, with their accuracy depending upon the notion oforder dependence (Proposition 4). Order dependence itself is not very restrictive in non-deterministic situations from anadversarial point of view, where the exact sequence of non-deterministic outcomes of actions cannot be predicted, and weneed to plan for the worst case.These results contribute to the understanding of the factors that make these problems difficult: when order dependencecannot be overcome by conservative approximations, and when the property of monotonicity does not hold. Although non-monotone simple loops with shortcuts have an undecidable reachability problem in the worst case, in some cases theproblems of reachability, and at the least termination, can be answered. Further identification of tractable classes of non-monotone simple loops with shortcuts is left for future work. Computation and expression of order dependent preconditionsare also important directions for future work on pushing the theoretical limits of solvability of these problems.We showed one approach for interpreting planning actions as abacus actions in this paper. The underlying methods fordetermining reachability in abacus programs, however, can be used whenever actions can be interpreted as incrementing ordecrementing counters. Development of more general reductions, for instance by using description logic to construct rolesin planning problems, is also an important direction for future work.AcknowledgementsWe thank the anonymous reviewers for their detailed and helpful comments. Support for this work was provided in partby the National Science Foundation under grants IIS-0915071, CCF-0830174 and CCF-1115448.References[1] B. Bonet, H. Palacios, H. Geffner, Automatic derivation of memoryless policies and finite-state controllers using classical planners, in: Proc. of the 19thInternational Conference on Automated Planning and Scheduling, 2009, pp. 34–41.[2] T. Bylander, The computational complexity of propositional STRIPS planning, Artificial Intelligence 69 (1–2) (1994) 165–204.[3] A. Cimatti, M. Pistore, M. Roveri, P. Traverso, Weak, strong, and strong cyclic planning via symbolic model checking, Artificial Intelligence 147 (1–2)(2003) 35–84.[4] B. Cook, A. Podelski, A. Rybalchenko, Termination proofs for systems code, in: Proc. of the 2006 ACM SIGPLAN Conference on Programming LanguageDesign and Implementation, 2006, pp. 415–426.[5] E.W. Dijkstra, Guarded commands, nondeterminacy and formal derivation of programs, Communications of the ACM 18 (1975) 453–457.[6] L.C. Eggan, Transition graphs and the star-height of regular events, Michigan Mathematical Journal 10 (1963) 385–397.[7] R. Fikes, P. Hart, N. Nilsson, Learning and executing generalized robot plans, Technical report, AI Center, SRI International, 1972.[8] R.E. Fikes, N.J. Nilsson, STRIPS: A new approach to the application of theorem proving to problem solving, Technical report, AI Center, SRI International,1971.[9] C. Fritz, S.A. McIlraith, Monitoring plan optimality during execution, in: Proc. of the Seventeenth International Conference on Automated Planning andScheduling (ICAPS), 2007, pp. 144–151.[10] K.J. Hammond, CHEF: A model of case based planning, in: Proc. of the 13th National Conference on Artificial Intelligence, 1986, pp. 267–271.[11] M. Helmert, Decidability and undecidability results for planning with numerical state variables, in: Proc. of the Sixth International Conference onArtificial Intelligence Planning and Scheduling, 2002, pp. 44–53.[12] C.A.R. Hoare, An axiomatic basis for computer programming, Communications of the ACM 12 (1969) 576–580.[13] J. Lambek, How to program an infinite abacus, Canadian Mathematical Bulletin 4 (3) (1961) 295–302.[14] H.J. Levesque, Planning with loops, in: Proc. of the 19th International Joint Conference on Artificial Intelligence, 2005, pp. 509–515.[15] H.J. Levesque, F. Pirri, R. Reiter, Foundations for the situation calculus, Electronic Transactions on Artificial Intelligence 2 (1998) 159–178.[16] M.L. Minsky, Computation: Finite and Infinite Machines, Prentice-Hall, Upper Saddle River, NJ, USA, 1967.[17] R. Reiter, Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems, The MIT Press, Massachusetts, MA, 2001.S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–1919[18] J. Rintanen, Complexity of planning with partial observability, in: Proc. of the 14th International Conference on Automated Planning and Scheduling,2004, pp. 345–354.[19] J.W. Shavlik, Acquiring recursive and iterative concepts with explanation-based learning, Machine Learning 5 (1990) 39–70.[20] S. Srivastava, Foundations and Applications of Generalized Planning, PhD dissertation, Department of Computer Science, University of MassachusettsAmherst, 2010.[21] S. Srivastava, N. Immerman, S. Zilberstein, Learning generalized plans using abstract counting, in: Proc. of the 23rd National Conference on AI, 2008,pp. 991–997.[22] S. Srivastava, N. Immerman, S. Zilberstein, Computing applicability conditions for plans with loops, in: Proc. of the 20th International Conference onAutomated Planning and Scheduling, 2010, pp. 161–168.[23] S. Srivastava, N. Immerman, S. Zilberstein, Merging example plans into generalized plans for non-deterministic environments, in: Proc. of the 9thInternational Conference on Autonomous Agents and Multiagent Systems, 2010, pp. 1341–1348.[24] S. Srivastava, N. Immerman, S. Zilberstein, A new representation and associated algorithms for generalized planning, Artificial Intelligence 175 (2)(2011) 615–647.[25] S. Srivastava, N. Immerman, S. Zilberstein, T. Zhang, Directed search for generalized plans using classical planners, in: Proc. of the International Confer-ence on Automated Planning and Scheduling, Freiburg, Germany, 2011, pp. 226–233.[26] E. Winner, M. Veloso, LoopDISTILL: Learning domain-specific planners from example plans, in: Workshop on AI Planning and Learning, in conjunctionwith ICAPS, 2007.