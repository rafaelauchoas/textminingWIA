Artificial Intelligence 100 (1998) 5-85 Artificial Intelligence Interpreting a dynamic and uncertain world: task-based control Richard J. Howarth ’ School of Cognitive and Computing Sciences, University of Sussex, Falmer; Brighton BNI 9QH, United Kingdom Received 13 May 1995; revised 23 July 1997 Abstract In this paper we show that it can be beneficial to have a high-level vision component that guides the reasoning of the whole vision system when interpreting a dynamic and uncertain world. This guidance is provided by an attentional mechanism that exploits knowledge of the specific problem being solved. Here we develop a general framework for such an attentional mechanism and its application to understanding dynamic scenes. This attentional mechanism can enable a vision system to perform a given domain task while expending minimal resources. We have developed a component that uses Bayesian networks combined with a deictic representation to select what, when and how to use processed data from a fixed camera. We apply two forms of Bayesian network, which ( 1) create a dynamic structure to reflect the spatial organisation of the data and (2) measure task relatedness. Together these give attentional focus making the reasoning performed relevant to the task. @ 1998 Elsevier Science B.V. Keyw0rd.v: High-level computer vision; Surveillance; Attention; Event reasoning; Visual behaviour 1. Introduction In the modern world there is an increasing use of surveillance, need for automatic or semi-automatic methods of processing Surveillance concerns more than just observation. and knowledge, some known automated, to is still along way to go before such systems can be fully in this paper is a step in this direction. A visual is often much more purposive, complying to having some intelligence the processing performed the work described the dynamic task. There In addition although resulting in the input data. ’ Email: richardh@cogs.susx.ac.uk or howarth@dcs.qmw.ac.uk. 0004.3702/98/$19.00 PIISOOO4-3702(98)00004-6 @ 1998 Elsevier Science B.V. All rights reserved. 6 R.J. Howarth/Art$cial Intelligence 100 (1998) 5-85 the perceiver surveillance system since problem of understanding in the scene, and also with processing general to extract system also provides a less complex problem just views than a fully interacting vision the scene of interest. We are still left with the the various unfolding dynamic behaviours of the actors/objects associated with using machine-based to noise, occlusion, is subject the many problems the visual evidence which and the ill-posed nature of inferring what we perceive the scene from image data. a restricted and consider is often a surprisingly the full visual understanding problem, case of the surveillance difficult process and we instead we make a number of Understanding do not address assumptions scenes. Our restricted visual understanding more of rigid objects interest the main in the activities of the various special vehicles aeroplanes. surveillance problem has the following tractable: we use a fixed camera of wide-area dynamic that make the activity in a structured domain. Examples scene where is the road vehicles, and airport holding areas where we are interested the passenger simplifications that observes a road-traffic that unload and service include: To perform surveillance we need to reason about to this work. We can separate vision the activities of the objects is performed that is complex is an important part of into (or late). Low-level [ 721)) and concerns visual receptors, sensors, with low-level image features vision is less well understood, and high-level to provide (Horn (or early), this visual perception that acts on the results from the visual receptors, intermediate-level [ 5 11, Marr from a television video camera or biological low-level is the best understood are perceived. The process by which and will not be fully addressed here. However, since perception surveillance we need to sketch its relationship three stages: vision be they artificial, processing such as edges, corners and flow vectors. Intermediate-level and concerns describes vision. High-level vision the evolving what intermediate-level In progressing be performed. is at the lower levels and levels. It is the development intermediate-level we use this to obtain a greater understanding is the least well understood that is provided by intermediate-level visual processing of objects for 3D interpretation, of high-level visual processing the more abstract, visual processing the recognition a framework information up these (e.g., model matching and tracking). Marr [ 721 to address intermediate-level that begins (or even low-level visual processing) and concerns of the interpretation vision as well as directing should information levels we see that image oriented symbolic descriptions are at the higher that allows the results from to be used for reasoning over longer time scales and of what is going on in the field-of-view. Until techniques that extract rare to find visual behaviours [ 881 and Howarth issues of high-level In this paper we concentrate it has been (but see, for example, Rimey and Brown to be on lower-level recently computer vision The focus tends rather than on identifying operate. placed on how what we know about an environment observed object behaviour. And, by using a single issues associated with active cameras and multisensor visual data to address surveillance tasks. Understanding starts by tracking objects objective of this work is to go further and form conceptual descriptions control connected with [55] >. from images tasks and how these on the role of high-level vision, with emphasis of the the interpretation fixed camera we ignore difficult ample fusion, while providing the activity of moving objects the beginning. The the that capture in an image sequence, but this is just appropriate information for visual affects R. J. Howarth /Art@cial Intelligence 100 (1998) 5-85 7 interactions dynamic of the advantages obtained by reinterpreting more active vision, situated approach. * of objects in a meaningful way. To discuss this we describe some a pipelined, passive vision system under a To address the surveillance problem we introduce the concept of the “official-observer” of our single that takes place in any interaction the official-observer the official-observer does not participate and is not a partner aware of this. Things In the surveillance problem here the tasks from the particular point-of-view visually attends to them, the observed people/objects which acts to coordinate camera. the environment Although not necessarily to differ greatly from those of the parties official-observer’s place in the dynamic wide-area scene it perceives and from this obtain an understanding interactions of the scene objects. There are constraints on of the dynamic and improvised the official-observer’s in the scene: we only see the objects of the objects that are in the camera’s field-of-view; we do not know each participant’s goal (typically something (rather than deeply planned). fixed in in the scene. 3 are are likely interaction. From the taking like “go to place X”) ; and what we see is mostly reactive behaviour input we wish to obtain a description of the activity that are relevant involved to the official-observer in the observed interpretation camera a in order that uses task-based to illustrate and motivation This paper begins by describing the background control program to address In Section 2 the initial project framework and the constraints computer problem. brought are explained. Then in Section 3 we describe an initial attempt at addressing surveillance problem. This first architecture serve first architecture why it is appropriate of the architecture used in Section 6, where theoretical details are given. Implementation in Section 7 and control operates. The parts of this paper following Section 8 consist of a discussion of related work, conclusions for developing the surveillance this framework the control, but does of this for why task-based control was developed and In Section 5 we present an overview that are details are given that illustrate how task-based the surveillance problem. Section 4 contains that does use task-based control, emphasizing for the surveillanceproblem. does not use task-based in Section 8 examples and appendices. those elements a reassessment are presented justification presenting 2. VIEWS and HIVIS In the ESPRIT II project 2152, VIEWS (Yisual (for an overview see Corral1 et al. [ 28,291)) area Scenes) is from images steps, which, as shown Component (2) to behavioural or “conceptual” descriptions. This involves a number of (PC) which performs in Fig. 1, can be coarsely separated low- and intermediate-level ( 1) the Perceptual and (SAC) which performs high-level control and visual processing, into: the Situation Assessment Component Inspection and Evaluation of Wide- the overall flow of information ’ The ideas behind “active vision” are described at the beginning of Section 5. By using the word “situated” we are recognising the broader ‘We use the word “object” issues of “being to refer to physical in the world” some of which are covered in Section 5.3.1. entities like cars, trams, and planes, where the person operating the machine may not be visible to the official-observer. R.J. Howarth/Artificial Intelligence 100 (1998) 5-85 I. The perception Fig. visual processing. The SAC performs high-level processing. and situation-assessment components. The PC performs low- and intermediate-level interpretation. On the left of the figure we depict an example scene, a complex junction, in this case a roundabout. What we want to determine is the behaviour of the vehicles that pass through this junction. This separation of the two components was done to allow simultaneous that we discuss but also led to a strong interface between in this paper, HIVIS-MONITOR of both components systems4 in effect alternative Situation Assessment Components, with HIVIS-MONITOR passive architecture based on “event reasoning” which is the identification primitives, active-vision of the system, approach where the surveillance let us call this “task-based of behavioural takes a more task of the observer affects the behaviour their selection and composition. In contrast, HIVIS-WATCHER and HTVIS-WATCHER, control”. development the two. The two HIVIS- are having a This interface that falls between for the pragmatic purpose of enabling (see, for example, Howarth and Buxton the interface between intermediate-level processing intermediate- research and high-level processing was initially to be performed on the VIEWS project [ 201) . Drawing from the results for to be collected as a stream of “compact encodings”5 [ 56,571 and Buxton and Gong in Fig. 1, allows the PC and SAC, as shown 4 HIVIS s The compact encodings is an acronym for HJgh-level mien. take the form of a sequence of ground-plane is called a “posebox”. Each posebox outline “pose position” of the object extent of the object, and its frame-of-reference details are given in [54). that determined represents a result from the model-matcher in the scene for a given image frame. The “shape” of the posebox denotes outlines of each object, where each the the left and right. More front, back, in the form of the object’s Fig. 2. Three images showing typical vehicle activity on the roundabout can be transformed to a ground-plane view. and how the 3D pose descriptions processing. high-level in the research subsequent highlighted stage would require addressing much more material and this more complex problem the subject of future work. The problems ensuing from reported here. Unfortunately moving this initial decision are the interface back one is In the computer program HIVIS-MONITOR event reasoning rally evolving episodic descriptions of all moving objects pipelined jects. in a scene. The identification to provide a database of results about that act as basic elements is used to build tempo- for conceptual descriptions of conceptual descriptions can be the activities of all the moving ob- In the computer program HIVIS-WATCHER task-based those scene objects likely to be worth attending because control they promise is used to identify to to be relevant 10 R.J. Howarth/Artijkial Intelligence 100 (1998) 5-85 Fig. 3. An outline of HIVIS-MONITOR. the given surveillance information processed. about all scene objects, instead only data that is potentially approach, we no longer collect is task related task. In contrast to the monitoring the im- is mainly that recognise and motivation To demonstrate in HIVIS-WATCHER. to provide background the initial design, which systems we have developed approaches changing world. We first briefly describe HIVIS-MONITOR, In these HIVIS-based portance of the continually embodying is how task-based control operates and how it for the main subject of this paper which has been implemented the different behaviour of the two systems we will use examples drawn from the road-traffic domain. Fig. 2 illus- trates this application taken domain with three image frames selected In this part of the sequence a number of episodic behaviours at a German the roundabout; are unfolding: another the rear of the image a car begins roundabout; the image frames we provide an illustration model-matcher assumption view. Here changing real world. is in an entry to the to overtake a lorry. Below from a and because we have made the the data from an overhead in the the camera position of a known ground-plane, we are able to display the display viewpoint has not changed of the poseboxes, which are results from a sequence [33,73,97,110,11 l] for details), also towards one vehicle roundabout. leaves (see lane 3. HIVIS-MONITOR In our first system, HIVIS-MONITOR, flow of data from images the general we adopt a pipelined approach to conceptual descriptions. As shown that reflects in Fig. 3 R.J. Howarth/Art@cial Intelligence 100 (1998) S-85 11 centres around extracting spatio-temporal three components: the stream of compact encodings produced by low- and intermediate- high-level visual processing primitives from level visual processing, detecting events from these primitives, and composing to form episodic extended as new events continue, begin or end the various episodes under construction. The problem is left to the query-based component in an evolving database. This database of matching that interrogates sequences which are stored to a user question the events is behaviours the database. this seems an admirable At first sight, of both the low- and intermediate-level development high-level one. However, as we will see, the passive, data-driven for high-level vision control. causes problems system design, allowing the parallel, separate visual processing component and the flow of the processing 3. I. Script-based approach To describe the behaviour of participants [ 781 to describe events, which captures upon that presented by Nagel notions of the terms being used. One of the projects NAOS system NAOS system the HIVIS generator. [80] which uses an extensive is the formation of off-line natural-language systems we are generating what could be the input in the scene we are using an ontology based the common sense is Neumann’s that Nagel describes list of motion verbs. The objective in the descriptions where as in to a natural-language Our use of events and episodes is similar in some respects to that described by Schank typical behaviour of a [27], layering between to describe into scripts decomposition and relationships [ 921, who compose events the island parsing described by Corral1 and Hill [29], or the compositional such as entering, going to a table, ordering, eating and paying. from events to episodes, and then to more complex the behaviours. This hierarchical elements can be used to define a grammar where events are terminal symbols to be parsed. This approach could use the syntactic methods described by [ 391 and and Abelson customer at a restaurant This provides a hierarchical script-like behavioural in the language Fu [ 401, the static semantics of an attributed grammar as described by Frost Clark [54] semantics but give more details of how the HIVIS-MONITOR in basically that have been detected and then use an the scene ongoing to the database consists of the events and activities associated with a particular property. that In addition of the update value/signal the necessary property values from the available properties. the approach is to note down the event primitives for each property. To identify an episode we use a filter that extracts computer program a history of the behaviour to see how these events fit together. The input given is implemented, that takes place [ 1091. Howarth and Buxton there are further functions structure by beginning, described by Woods extending or ending [56] and Howarth to the functions for maintaining the continuity that compute the temporal these values interpretation process This has described script-based database between conceptual descriptions. approach, constructing how HIVIS-MONITOR it follows the in an evolving for the history of each individual object and the interactions that of object behaviour an interpretation is data-driven and that holds entries them. This passive bottom-up approach reflects the flow of data from image to 12 R. J. Howarth/Artijcial Intelligence 100 (1998) S-85 composite regions turning zone give-way ,, ,” Fig. 4. A spatial decomposition of a fragment from the Bremer-Stem roundabout. This shows the separation between the leaf-regions and composite-regions, and the typical path flow that connects some composite-regions (e.g., the roundabout sectors). 3.2. Spatio-temporal representation used by HIVIS-MONITOR is based on a model of space for representing digitised spaces and which she has used for The spatial representation [ 36,311 developed by Fleck both edge detection and stereo matching. can be used for qualitative The spatial and temporal based on a mathematical work on combinatorial space foundation topology. Cellular (see Fig. 5 6 ) which we augment reasoning representation Fleck uses and calls “cellular and for modelling In [ 371 she describes how this representation semantics. is itself [ 1071 as part of his developed by Whitehead topology” language natural topology uses cells to structure the underlying slightly by adding a metric. We can attach ’ Note that the regular cell pattern illustrated in Fig. 5 is not necessary for a regular cell complex. R.J. Howarth/ArtiJiciul Intelligence 100 (1998) 5-85 13 Fig. 5. A regular cell complex. a rise These regions the world to separate a 2D spatial (e.g., rooms) by introducing of a ground plane if we just consider (which may include to a hierarchy of regions, topology. These meaningful to this underlying implementation spatial representation issues from the data being represented. representation that edges (e.g., walls) which we use to cut space up into in accordance with the rules that govern what can be things relationships, about information level of abstraction For example, contains a number of important regions meaningful represented by cellular like typical paths through a space) may overlap or have subset/superset giving “leaf-regions”. “composite-regions”, various attributes attached how the leaf-regions plane depicts paths for trams, data held in spatial-layout of composite-regions, transition information this database Howarth the smallest common units of which we call the spatial component, where as the can have primitives, the leaf-region tessellation given in Fig. 2, shows This ground- typical some of the the hierarchy and how For more details and how [56] and roundabout cyclists and pedestrians. Fig. 4 illustrates showing how type attributes are attached can be used to link composite-regions. for “contextual cut up the space viewed by the official-observer. leaf-regions which are composed the Bremer-Stern road-vehicles, database used in HIVIS-MONITOR, only represent from see Howarth and Buxton to them. The ground-plane in Germany and contains to composite-regions, the various indexing” is used [ 541. topology (see [ 371) is the real number used of situations to model line R. This in linguistics time using a cell com- time-line is combined and originally to due this “Aristotle-Kenny-Vendler” [ 105, pp. 133 and 1961 calls like own a house, be a student; “state-changes”‘, Fig. 6 illustrates into: like get to work, find a book; like travel to work, after an the program compiled. To which we can add another situation called showing how they are divided like eating, driving a car; “accomplishments”, the situations We also use Fleck’s cellular space classification (van Benthem plex whose underlying with a four-way Vendler verb classification). “states”, “activities”, hour’s debugging ’ Also called “achievements”. 14 R.J. Howarth/Artijicial Intelligence 100 (1998) 5-85 state actions activity accomplishment episode Fig. 6. State and action models of situations using cellular using a progressive permission. form. Adapted from Fleck [ 37, p. 211. Copyright topology. The shaded cells can be referred to 1996 by Elsevier Science. Adapted by to denote accomplishments “episode” term “actions” episodes. Similar classifications [ 31. From as follows: these we identify is used as a cover term for activities, accomplishments, that have a definite beginning and ending. The and state-changes [98], and Allen the key parts of our event ontology which can be defined have been used by Ryle [91], Taylor Definition 1. An event is a significant change to a property’s value. This definition action definition given by Newtson to that described by Nagel [ 811. is similar [78] and conforms to the point-of- Definition 2. An activity is a continuous sequence of states that have the same property. tries to capture This definition of activity one thing, and that it is steady and consistent. These definitions used by McDermott change in the world. Here an event appropriate, described as an activity or a state. the idea of an evolving activity being about to those that initiate could be, if [94] where events are propositions is the change and [74] and Shoham the proposition are different Definition 3. An episode expresses a sequence of related activities bounded by two events. The objective of HIVIS-MONITOR is to identify when an episode This has now covered an evolving is useful for representing the underlying temporal history, in the gaps” as illustrated this in a linguistic [ 373 places representing of situations allowing us to “fill [ 541. Fleck in this paper, however, component into the HIVIS-systems. is taking place. and a model discrete observations static spatial representation for in terms of actions and states. This model input, in more detail in language in Fig. 7 and outlined context, which we will not discuss provided by camera it does provide one route for the integration of a natural R.J. Howarth/Ar@cial intelligence I00 (1998) 5-85 observations ( OU) 0 0 0 time-cells (‘IT) 0 0 l oo 0 0 0 l oo 0 0 Fig. 7. The time-cells, where II may be fixed and n 2 I, n E N. time-cells provide a discrete model of the R time-line, and we receive observations every II Fig. 8. Entering onto a roundabout The stream of posebox data supplied by the model-matcher describes the space swept is [21]. [48 ] “histories”, It also corresponds described by Cameron covering a much more restricted is used to provide an approximation is exited or entered. To do this, we extrapolate form of the extrusion form of Hayes’ out in time by each object’s path to form what we call a “conduit”. The conduit a simplified to a simplified of physical properties. The conduit the space-time description which a region between updates. The path formed will depend upon the curve or line used to connect the points the is used stay on the road). This method of small scale path road-traffic to error or about missing updates due to reasoning completion the past history of an object’s occlusion. Conduits of continuity passage of travel, and occupancy. Fig. 8 providing and whether knowledge domain cars usually can also be applied form representation transition set of the time at the scene, providing in spatio-temporal for illustrating (for example, the regions an unusual framework a useful through capture region about in 16 R. J. Howarth/Artijicial Intelligence 100 (1998) 5-85 Fig. 9. The frames show four vehicles traversing part of a roundabout. Fig. 10. The conduits to try and clarify the picture. from above of vehicles 5 and 7. The other objects have been removed in this example provides an illustration of the various elements like entering-the-roundabout the vehicle. This is described by identifying involved in identifying a simple behaviour the pattern produced by the activity of in greater detail in [ 561. identified, [ 1001 who use a slightly different can be similarly Other behaviours by Toal and Buxton described here, and define following delay”. These analogical overtaking. vehicles poseboxes where we see the 2D+t conduits For example, consider traversing approaches do not easily extend to representing representation as an “overlap such as following spatial which is described to that in spatial history within some time like the sequence shown in Fig. 9 where we have four stacked in Fig. 11 behaviours the roundabout. Fig. 10 shows two conduits of temporally for objects 5 and 7, with the temporal axis displayed more clearly from the side. Once we have generated the conduits, we have the problem of interpreting what they mean. of conduits dimension If they intersect then there is unusual. Other tests can be made possible by removing is a likely collision or near miss, but intersections a pertinent in the test to see if the components of the reduced model overlap, and testing R. J. Howarth/ArtiJicial Intelligence 100 (1998) 5-85 17 Fig. 1 I. The conduits from the side. behaviour we tested for an overlap with some the spatial dimension parallel for following can be identified by ignoring motion however, “rectifying space curve of each object’s path. Mapping perform such as test is difficult, although this spatial dimension developable” (as described by Koenderink the conduits time delay. Overtaking to the objects direction of the that fits the to into one of these manifolds [ 661, for example), called should really be the 2D manifold, in principle it should be possible. 3.3. General features We claim that HIVIS-MONITOR demonstrates typical AI approaches we have called “script-based”. features: have the following In general, all script-based traits of the class of traditional systems will over the whole scene, for all the episodes Maximal detail is derived from the input data. This approach obtains a description of all objects and all interactions, been designed Representation that is used to construct more abstract descriptions using hindsight. Single object reasoning this approach. Simple is performed with ease using can be achieved using standard AI techniques. first and the results are placed to detect. is extracted in an evolving database implementation it has 18 R.J. Howarth/Art(ficial Intelligence 100 (I 998) 5-85 (see, for example, It is quite likely that better implementations by Allen et al. [ 41, and approach the results * from the VIEWS project given by Corral1 et al. [28,29], King et al. [ 641 and Toal and Buxton the exemplar developed here should be enough to judge whether to remain with this approach or to investigate an alternative. the description of plan recognition that fulfill the script-based [ 1001 ) . However, can be developed 3.4. Limitations . . . . storage in size. reasoning limitations: is monotonically the construction has the following is difficult within the database structure that we have identified, of the results database that there is a problem getting to any form of intermediate-level is required because any pieces of data contained is an off-line visual pro- timely recognition of perceived in its processing, operating a simple control policy, that is, not affected in the perceived data. HIVIS-MONITOR . It is passive by changes It is not real-time because process, and does not send feedback cessing. This means object activity. in the results Unbounded later either to compose some more abstract description or database might be needed to be accessed by the user to answer a query. Since we do not retract what we have seen or the episodes increasing Multiple object express pose positions. The computation number of objects This model constraints of the predicates provided activities), may be difficult. The addition of new operators objects most binary object operators object operators the increase the number of objects The behavioural text in which pretation. possible due to only seeing part of an episode. the that describe events and new behavioural models can be added. However, defining new predicates the number of tests performed on all the for and for most multiple performed by HIVIS-MONITOR in the input data, i.e., it is data-dependent. the temporal con- to the process of inter- is not is polynomial with a maximum of 0( n”), where n is that the selection of the “correct” episode description it only deals with known episodes. Within the events have occurred, which contributes in the scene. For a single object operator does not take into consideration the global coordinate is inflexible because is mainly dependent (language primitives there is an O(n) system used to decomposition in the scene. It is possible is an O(n2) increases increase, increase, there upon the . . . 3.5. Discussion From computation these features is performed and limitations we can identify the following key problems: to obtain results that may never be required; and as the x Initial achievements on the project. of the project are illustrated by the video [ 191, and Geake 1421 provides a brief report R.J. Howarth/ArtQicial Intelligence 100 (1998) S-85 19 Fig. 12. The different coordinate systems of frame values used by the official-observer and the vehicles it is watching. the performance increases to address in size, these by extending database of results might be possible we will not take this evolutionary approach. This new approach differs greatly from the passive, data-driven approach task-driven, It approach however, a more situated script-based to obtain an active, of the system will degrade. situated solution. Instead we will the script-based of the problem and requires reformulation a complete investigate route. 4. Reassessment To begin this reformulation we first consider the use of more local forms of reasoning in terms of the frame-of-reference these objects and the use of contextual of the perceived objects, the spatial arrangements of indexing from knowledge about the environment. system was assumed. By taking held Western view of how to represent approach described by Hutchins to perform navigation. The absolute coordinate [ 431 and Kosslyn to be (see Gibson In HIVIS-MONITOR a global extrinsic coordinate to the egocentric a global view we comply with a commonly space in a map-like way as opposed [ 611 as being used by the Micronesians system also fits well with the concept of the optic-array et al. [ 671 for details), analogical to be performed represented in terms of the optic-array’s like the video-game world used by Agre and Chapman recognition mechanism and Tsotsos et al. properties, such as, colour and roundedness) that does not need full object (see Chapman . if we can consider placing a grid over the ground-plane to the optic-array of the perceiver. This representation would allow reasoning relationships recognition with spatial absolute coordinates (in some respects this is [ 2 ] where the “winner-takes-all” [ 1031) allows objects and their positions [25], Koch and Ullman [65], Tsotsos [ 1021 to be identified by key In contrast it would be useful object could be described nising each object to this global viewpoint, when reasoning about the behaviour of each scene to each object recog- together with its in its own relative coordinate to the extent that an intrinsic-front if the representation system. However, of the properties can be identified this involves related 20 R.J. Howarth/Art@cial Intelligence l&J (1998) 5-85 In our surveillance problem we can obtain places in the optic-array spatial extent. This requirement of how the image data present environment. objects via model-matching making terms of the complexity of intermediate-level how we can just use the official-observers of an attended object we can reference other scene objects object’s pose position. Pertinent background summarised in [ 551. We can define local reasoning these different the need for a more sophisticated relates understanding to how objects exist in the the pose positions of the scene its extra cost in attractive, although vision should be noted. Fig. 12 illustrates perspective or once we have the pose position to this attended in relation [50] and details are given by Herskovits frames-of-reference as follows: Definition 4. The frame-of-reference local-form is representation and reasoning of a perceived object (exocentric with respect that uses to the observer). the intrinsic Definition 5. The global-form frame-of-reference, to the observer). and reasoning which operates over the whole field-of-view is representation that uses the perceiver’s (egocentric with respect it, like the local-form, and global-form a shared world frames-of-reference are not just different is our familiar, everyday is not a public world since to only exists in terms of each local-form the different reasoning present when using each of these frames-of-reference. frame-of-reference, The global-form the perceiver. We are not dealing with representing participant. The include global-form integrated model of the various spatial objects of-reference an attended object to provide a relative spatial framework, cognitive effort in its use. Both Biihler of-reference being the experience horizontal ground of encountering are both illustrated they also The such that it provides one overall frames- of the frame-of-reference seems to require a little more these frame- For example, Herskovits describes how a human ( 1) straight ahead with his or her body standing upright on as being incompatible. to construct a frame-of-reference used by each local-form. The local-form, using (we will call this the “canonical position”), the experience These from two basic experiences: instead of the different another human being [ 181 and Herskovits (the “canonical [50] describe in Fig. 13. encounter”). face-to-face of looking individual and (2) starting learns the right and left axes can be interpreted In part (b) of Fig. 13 the perceiver “combines” his or her own point of view with (i.e., the person called Bob in the figure). As the figure to those of the onlooker. in two different ways with respect to right and left axes: either the same, which is called “mirror order”, or the that of the person encountered illustrates Bob’s front and back axes point in directions opposite However, the observer’s opposite, called “basic order”. Note that basic order is Bob’s own frame-of-reference. We can resolve to Fig. 12 and identifying 5) and that basic order is using that mirror order is using of a perceived object, we (Definition the local-form through space of the object in can then analyse all the changes terms of our own field values and experience. This representation seems natural because we use it in our everyday the global-form 4). By using the frame-of-reference involved or transpositions interactions with the world. these two different interpretations by referring (Definition R. J. Howarth /Artijicial Intelligence 100 (I 998) 5-85 21 (a) observer (b) Fig. 13. Frames of reference: from Herskovits (a) an observer [50, pp. 158-1591. Copyright in “canonical position”, (b) the “canonical encounter”. Adapted 1986 by Cambridge University Press. Adapted by permission. by asking is detailed a query-based The suitability the importance first, we remove in Table 1, providing of each HIVIS-system system. This removes to know when something can be forgotten. The development the problem of the monotonically it is difficult an indication to the surveillance problem. HIVIS-MONITOR would the in HIVIS-WATCHER, of the results database because we are no of the extent of the reformulation be useful for off-line query of behaviour, whereas question longer providing and solves MONITOR a more situated approach viewpoint using HIVIS-MONITOR in cases where of the surveillance problem we are inherently evolving contexts of both observer and scene objects, and the formation of a consistent, task relevant HIVIS-WATCHER information of space and time. In some applications, all scene objects might be necessary however, In the context the the need to remember everything in HIVIS- of is part of the adoption of a more local in we do not name and describe every object, and we register only and processing it is not, the HIVIS-MONITOR of this observed behaviour. By taking a deictic approach in HIVIS-WATCHER representation concerned with: the “here-and-now”, about objects relevant that uses a “deictic”’ database because interpretation is ungainly. increasing approach to task. 5. HIVIS-WATCHER overview In HIVIS-WATCHER we remove the reliance on the pipelined use feedback in control representation to control the behaviour of the system. This use of feedback theory, but not so common plays an important in AI (Nilsson [ 831 discusses role in this framework because flow of data and instead is common this point). Deictic it supports attentional ’ Deixis is used in several disciplines Heritage 1491) and spatial representation deictic word (e.g., I, now, this, that, here) and is an aspect of a communication whose it occurs. on knowledge of the context [41 1, [50, pp. 156-1921). Deixis is the use or referent of a depends such as linguistics (Herskovits [ 18 ] ), the social sciences interpretation (Garfinkel in which (Buhler 22 R. J. Hnwarth/Ar@cial Intelligence 100 (1998) 5-85 Table I This table summarises the comparison between describing what each row is about. the two HIVIS-based systems, with the illuminates column HlVIS-MONITOR HIVIS-WATCHER passive open-loop/pipelined off-line structured global maximal detail unlimited extract representation answer question data-dependent resources first from representation active closed-loop/feedback on-line purposive local and global sufficient detail limited resources ask question first answer question task-dependent from scene data data illuminates control architecture immediacy approaches viewpoint investigation complexity timeliness memory cost rather task-driven requirements vision approach than just representing processing with emphasis placed on the behaviour of the perceiver as it interprets activity of the scene objects objects on their own. This active/animate active, [ 1041 proposed this animate vision approach: engaging behaviours scene; and second, processing within of active vision methods integration of multiple visual routines. Ballard cites two key reasons for in the context of the visual of the representation that integrates visual is the adaptation the the behaviour of the scene that takes account of more [6], and builds on Ullman’s the system without requiring detailed it is important the task context. What is new in HIVIS-WATCHER to allow selective processing is described by Ballard is better understood to have a system first, vision framework internal in advanced visual surveillance. some of the concepts used in HIVIS-WATCHER In Sections 3 and 4 we introduced the world, the “peripheral-system” has three separate elements: in Fig. 14, HIVIS-WATCHER for events and actions used in HIVIS-MONITOR and the local- and such as the notation the global-forms. As shown “virtual world” which holds data about which can access this data about the world, the “central-system” which controls system behaviour. The peripheral-/central-system to that advocated by both of Ballard’s key reasons given above. Agre it contains a set of visual operators. The The peripheral-system to run, based on the central-system feedback of the results from the visual operators just run. Because of this the peripheral- and central-systems is an important feature. form a tightly coupled architecture where feedback that selects which visual operators architecture fulfilling is in effect the plant, used here is similar [ I] and Chapman is the controller [25] Here we briefly describe machinery needed detailed description of task-based control. to support the the three elements of HIVIS-WATCHER, the examples given in Section 8, before providing a more that contain 5.1. Virtual world The virtual world acts as the interface with the real world, containing a priori knowledge about the environment being observed which includes a “buffer” and the spatial- R.J. Howarth/Art$cial Intelligence 100 (1998) 5-85 23 conceptual descriptions produced as effector results Fig. 14. An outline of HIVIS-WATCHER data from and dynamic it is a representation of the world, instead in Section 3.2. The data held in the virtual world is accessed layout database described via visual routines. The virtual world is not an internal by the rest of HIVIS-WATCHER of both static a priori “mental” representation vision processing. The virtual knowledge the signal from a vision component whose global “overhead” viewpoint world represents in Section 2). The virtual has been obtained to hold information world representation for access by the peripheral-system. had direct links to the vision system then the visual operators would directly access the available vision system results. from the visual processing Instead we are using a time frame stamped compact encoding as described from a fixed camera position If HIVIS-WATCHER it is used solely does no runtime intermediate-level in Section 2. (as described reasoning, about The buffer holds the dynamic perceptual data from the intermediate-vision component (i.e., 3D pose positions). The dynamic the scene objects and is replaced on each system clock gives each that arrives as a frame of compact encodings data provides knowledge tick when a new frame of compact encodings object a unique name and when a new object is used by preattentive processing, and by some in the virtual world. The buffer-address updates attentional markers for each object are put in the respective buffer-addresses when this information about each new frame arrives. The virtual world does not maintain any history of past updates, only the ones for the current frame. When a buffer-address (i.e., it is reused and will be given to a new object the object when one is identified. in Section 5.2). The model-matcher it represents has let the scene) is given. The model-matcher it is given a “buffer-address” is not given an update (which are described is identified Although all the image data (in the form of conceptual encodings) is present in the virtual world. The rest of HIVIS-WATCHER can only obtain certain preattentive 24 R.J. ffowarth/Arti$cial intelligence 100 (1998) S-85 properties of all objects and attend when a marker is attached to a buffer-address. (i.e., obtain all the results from the model-matcher) 5.2. Peripheral-system The peripheral-system is based upon Ullman’s argument [ 1041 for a “visual integrates multiple visual operators processor” which perceptual work such as tracking, This part of HIVES-WATCHER man processor. Both HIVIS-systems ference time, they are only run when selected by the task-based control system. relations. the approach described by Agre [ I] and Chap- of such a visual routine the key dif- operators are not run all the that perform particular and spatial employ event detection operators however, is that in the HIVIS-WATCHER [ 521 describes a real-time shape properties peripheral-system [ 251. Horswill implementation representing follows routine sorts of figures The problem of selecting 5.2. I. Attention and Gestalt primitives important [ 891 and Treisman to two stages called “preattentive” is reviewed by LaBerge [ 1011 who propose attributing and “attentive” (or peripheral) [68], and de- visual pro- (or fovea]). theory by separating indexing stage and in selecting a response. At the first stage simple registered, by what we will call “simple operators”, which features but not fine detail. Treisman provides examples of texture seg- for figure ground separation). Murray et al. [77] discuss other scribed by both Rock cessing Pylyshyn and Storm multitarget visual the other a serial checking stage invoked features are preattentively describe global regation cue like processes such as one to detect “looming motion”. into two stages, one a parallel preattentive [ 861 also use this separation in their “FINST” (a prerequisite tracking [ 7 1 ] describe how the results from demonstrations At the second stage objects are identified using the candidates their use for directly from irrelevant can propose stage support is distinguished tive stage. Mahoney and Ullman the preattentive figure of interest In this way preattentive processing This example, once this location and bring specialised processing things downward of deictic the first stage has identified to align with parts of the object. like working out what it is, by first attending the description ties in with set up by the preatten- of local features as long as the figures by a single one of these features. figures for use by attentive processing. indexing representation a contiguous given in Section 5.2.2. For blob of space we can mark to bear on the target. This may involve then adjusting to the whole object In the first stage some of the object to the early discoveries made [ 46, pp. 46-751) are similar Gordon good configuration, symmetry. The Gestalt primitives used in HIVIS-WATCHER: common concerning that we wish interrelationships in Gestalt psychology to describe for example, grouping properties, such as: proximity, similarity, and closure, simple operators act as the basis for the following continuity), temporal and/or (see, fate (spatial . Proximity. One of the most elementary the relative nearness of one object cerns tentive cue because objects generally plementation of how the nearest other object is selected, spatial primitives in spatial reasoning to another. We use proximity con- as a preat- interact with those that are nearby. The im- is based upon an approach R. J. Howarth/Art$cial Intelligence 100 (1998) S-8.5 25 Fig. 15. The nearer to the object the higher the value of “nearness”. Fig. 16. The dissipation of nearness.. close, very-close, in robot motion planning field that conceptually (see Latombe [69]). Figs. 15 and 16 show the surrounds each object. The height of the field re- relationship. The higher the value the nearer the used repulsive flects the nearness of the proximity other object. The nearness measure consists of five qualitative values: not-near, nearby, rather like the concentric how the intensity of a stimulus Schiine uses the example of a scent gland) decreases gradually as the distance its source to a discrete variable Bayesian network pp. 344-3571 more standard discrete model was selected While Fig. 15 presents an ideal model [ 93, p. 3 1 ] for modelling (in his work on the spatial control of behaviour from so that the input can be given form. Although Pearl [85, the variables can be accommodated for its relatively greater simplicity. increases. Fig. 16 shows a compromise does describe how continuous gradient described by Schiine in a qualitative touching. l Discontinuity. identifies In contrast the distinguishing to the Gestalt primitive is not part of Gestalt psychology because “common property of a change fate” the preattentive in spatio- instead a group we are identifying when a figure changes between groups. In for a short time when it changes (for the moving to become part of the it from the cue of discontinuity temporal continuity. This primitive of identifying the scene, an object may become distinguishable one of its properties and so changing membership to “ground”). example, objects represent a group and when one object stops moving static background other moving objects. In the scene under surveillance from one group to another briefly distinguishes its spatio-temporal from “figure” discontinuity 26 R. .I. Howarth /Artijicial Intelligence 100 (1998) S-85 provide the preattentive in this paper. Neither of these Gestalt primitives primitives information example Gestalt provided by the posebox These WATCHER sitional probably work just as well. lo In HIVIS-WATCHER “pop out” an interesting vestigate central-system (i.e., shape, speed, and so on) and its relationship nearest object can then use attentional operators future contents. Once a marker buffer-address the buffers cues used by HIVIS- the detailed po- needs result, a less accurate estimate would to to in- each preattentive cue is used to which a marker can then be attached to find out properties about this object the to its local environment (e.g., to it if there is such a proximate object) as described next. is attached, HIVIS-WATCHER’s 5.2.2. Deictic representation is that it allows a propositional An advantage of using a deictic representation that is proportional to be developed to the number of propositional surveillance we do not need that will ever pass number of properties of interest of the scene objects. To do this we use the following Chapman theory to the number of properties of interest, as opposed that when performing object through our field of view. Instead we can define a fixed, smaller the activities terms from the work of Agre and to provide a unique name in the world. This means that the official-observer for every propositional uses to describe [ 1,2,25] objects : Definition 6. An entity is something that is in a particular relationship to the agent. Definition 7. An aspect describes a property of an entity in terms of the agent’s purpose. about information the-car-I-am-driving the current state or activity of an object, not its An aspect provides events. For example, driving-has-enough-fuel (say by looking at the fuel gauge of the-car-Z-am-driving) We still have the problem of identifying values (such as the event when but this is made more complex because I might not use the same car all the time and each of these different cars is likely have different particular car. is the name of an entity and the-car-l-am- is the name of an aspect of it. Each time we obtain an aspect its value may be different. sequence of aspect becomes false) the same (for example, to there is local temporal continuity while using a events from the temporal the-car-l-am-driving-has-enough-fuel levels of fuel). However is not always the entity Temporal continuity the entity). Markers are described by Ullman can be maintained by using a marker to point at the scene object [ 1041 and Agre and Chapman. and is described by Pylyshyn called FINST, reference, form of indexical (i.e., A similar the results to the source these preattentive cues without using images would provide does not have access the the original lo We could calculate HIVIS-WATCHER Access in the image plane (for example, by background clustering the nearness model to the image plane and by tracking objects ratio test [ 13, p. 1.521). Perhaps mapping using a structured the model-matcher. However, image sequence only the stream of compact encodings. to obtain object positions [ 7, 10.14 I or by forms of the Gestalt primitives could be performed by mapping the sequential probability for example, is an option since we are results into the ground-plane environment which might make performing the option of using a simple approach the mutual-proximity test easier. to provide an object’s silhouette [45] ). Then modified flow vectors the position road-traffic subtraction (using, from R.J. Howarth/Art$icial Intelligence 100 (1998) 5-85 21 Table 2 Simplifications entity aspect entity aspect using the-refobj and the-other. long form the-reference-object-l-have-selected tlze-reference-object-l-have-selected-is-moving the-secondary-object-to-the-refobj the-secondary-object-to-the-refobj-is-moving abbreviation the-refobj the-refobj-is-moving the-other the-other-is-moving that can be tracked at one evidence is pertinent four or five objects [X6], who present psychophysical Storm four or five on the number of objects ity to track used to place an upper bound on system complexity, form surveillance with such benchmark scenes, objects) may be inappropriate paper. here, are able this upper limit on system complexity to perform all surveillance limitations. There thus to the surveillance problem that there is a numerical limit of time. ” The abil- as it can be since a human observer can per- is the issue of whether humans, our in traffic than four or five in this tasks sufficiently well (i.e., no more than we consider for tasks of greater complexity When reasoning about an object in the scene it is useful to use the object’s local-form (see Definition 4) and obtain aspects about the other objects the attended object. To do this we extend reference object the deictic approach by identifying in relation and relative to a primary that we will call the-refobj and which is short for the-reference-object- where I refers to the official-observer. We also use the abbreviation I-have-selected other as described to these deictic references in Table 2 to refer to these secondary objects of interest. the following primitives are used in HIVIS-WATCHER: the- In relation l Positional. The positional locations like the-other-is- formed by the field values of an object are used is used in system etc., as illustrated coordinate so that we get things like the-other-is-on-the-right, regions. I2 This qualitative to cut space into qualitative to obtain values for the aspects Fig. 17. These aspects can be composed behind-and-on-the-right each dark oval represents that we can reason about where the-other object is without needing is. I3 Fig. 18 demonstrates two objects. For example, position via Q’s frame-of-reference, we can say that (X inf ront Y) is not necessarily because, in Fig. 18 we do not show the half spaces extending the illustration the relative qualitative position of the nearest object, extending is not strictly necessary. clearer, and because and (b behind in Fig. 18, (c this positional is true, infront b) to describe all eight relative qualitative positions. In Fig. 17 the position of the-other object. An oval is used to show to know what it that there need not be a clear inverse relationship between like (P position Q) to describe P’s if we use notation then i.e., Q is the-refobj and P is the-other, the same as (Y behind X), c) is false. Also in order to make test is typically only used to find the lines to infinity to infinity [ 751 describes ” Miller ‘* In HIVIS-WATCHER we have implemented I3 As Koenderink says 166, p. 601 “On a sufficiently similar limits on the capacity of processing information from other stimuli. the “basic order” frame-of-reference introduced low level of resolution any shape appears in Fig. 13. ils an ovoid”. 28 R. J. Howarth/Arti$cial Intelligence 100 (I 998) 5-85 POSITIONAL the-other-is- the-other-is-infront I 0 I Fig. 17. The positional aspects of the-refobj. Fig. 18. The half spaces of three cars. in rela- the aspect values for the-other-is-parallel, the- Heading difference. The relative values for the heading of the other objects tion to the-refobj are used to provide other-is-at-right-angles, or the-other-is-head-on. We use either the heading property of the two objects, or the orientation property (e.g., the scene). Heading because one or both the objects is preferred it uses the direction of motion and can take account of unusual since situations Speed difference. To determine in relation to the-refobj we use the values for object speed. The results provide values for the aspects the-other-has-same-speed, the-other-is-faster, and the-other-is-slower. such as reversing or travelling backwards. the relative motion of the-other object is stationary or has just entered is not available if the heading These are the relative qualitative direction of motion, and speed) object, where proximity obtain all binary relationships can point to in the scene, relationships (for position, used in HIVIS-WATCHER from the reference object to an identified nearest other cue for to that the-refobj and the-other for each identified by the preattentive is that if we want between each pair of objects then we have an O(n2) number of tests to perform (see Section 5.2.1). The problem with this approach the nearest other object has been R.J. Howarth/Artificial Intelligence 100 (1998) 5-85 29 view of object properties via the-refobj. This facilitates the deictic representation Fig. 19. The local-form described in Section 5.2.2. relationship. This problem is partially addressed by using the typical-object- is the subject of Section 6. Next we look at the framework within which in Section 5.3, however, we still need to select what to attend, these particular model, which we discuss which attentional references are made. 5.2.3. Perceived environment To coordinate perceiver references the physical in the scene we use the frame-of-reference pro- to the intuitive is not needed as shape of scene objects and does not involve the object concerned. representing regions. More detailed object oriented properties vided by the global-form. This global viewpoint of the scene conforms idea of using general and abstract properties. Great spatial resolution the global-form ground-plane can be obtained by attending a coarse HIVIS-WATCHER following the local-form Z2 providing position tation is given peripheral-system the local-form) In the global-form we only require (in these markers are identified pictorially by shapes like 0, + and +, and which can be used to access system uses that has a qualitative description of object represen- that this grid is part of the in Section 4. A comparison in Figs. 19 and 20 with Fig. 21 showing and not part of the real or virtual world. the approach used by Agre and Chapman) should this be required. This global coordinate the location of the fovea/marker a “grid” over the ground-plane local and global representation as discussed that denotes of position information between (e.g., The grid is part of the implementation for describing marker positions and also the size of all the markers, the is of size “grid square”. To some extent granularity of this grid is not important, which perhaps sounds strange. As Fig. 20 shows i.e., each marker 30 R.J. Howarth/Artificinl Intelligence 100 (1998) 5-85 Fig. 20. The global-form view of objects as being indexable positions in a grid, i.e., the displayed marker shapes. environment plant controller 11 m central- system poseboxes, scene spatial database layout markers, activation planes rules, MACNET tasknet, DDN Fig. 21. Environment, plant, controller, its position in HIVIS-WATCHER object so that its size plays no role in this process. The size of the markers purposes. Although not used in HIVIS-WATCHER, important the marker size is about a vehicle width. As the marker tracks an from the centroid of the object it is tracking is purely for display the size of each marker would be the extent of the zone of attention. in the grid is calculated if it represented R.J. Howarth/Artif?cial Intelligence 100 (1998) 5-85 31 program Chapman’s “BLOCKHEAD” in the “blocks world” domain) provides an illustration of how the real world might be modelled to comply with that mimic (which copies stacks of blocks this analogy between the optic-array representations this structure. and storage [24] 5.3. Central-system separation made in cognitive science between the traditional the and central-systems. On the input side we have a collection of to each of which are to a large part innate, localised [ 381 describes (or input-) and motor processes, Fodor peripheral- perceptual specific brain areas, and task- and domain-independent. is a module of the input-system. is not modular, being this is that anything you know can potentially is not held by all researchers, that uses an orthogonal Agre and Chapman for example, Brooks separation based on task-achieving say that the central-system instead a single homogeneous Each element of this collection Fodor argues that the central side is different, saying central-system. The justification it for task. This view [ 16,171 provides a different view be used in any cognitive behaviours. should contain no detailed internal argument the world architecture of the environment planner with world models and do no explicit planning to do now based on how (see, for example, Chapman is an exemplar of Agre and Chapman’s interaction with the world consists of continual (as would be done in a [ 23 ] ) ) . that improvisation where we representation classical STRIPS-like This central-system our everyday are deciding what [25] contains a set of loosely connected (also see Howarth to form patterns of activity called “routines” (and which should not be confused with plans). The rules that make up these routines are not rigidly classical STRIPS-like interaction. This prominent attended objects and reason about markers) reference. One (context-dependent) is in how attentional markers are used to reference that we represent the number of attentional but instead allow a wide variety of system-environment than using explicit object names. This means in the world (see Ballard et al. [ 81). the number of properties of interest is achieved by the use of deictic in a language called MACNET is now. The central-system tied to particular objects to the number of objects they would be in a in the environment “rules” written use of deictic that combine as opposed reference [53,54]) planner) rather (e.g., (as select when an operator is to be to its activation. Crafting is done by making of the next rule. However, the rule-operator the result produced is not to react route. A routine provides an abstraction the mechanism thus allowing this fulfill situations rule can be fulfilled, (constructing the input the rules in the central-system are to be supplied routines) requirement In HIVIS-WATCHER used and what arguments pairs into sequences by one operator the only way a particular to similar for a common pattern of interaction peripheral-system. to do “now” based upon how the world the virtual world data structures and the central-system operators. This allows and only needs restricted state ensures that arise via a different to have the information necessary and between HIVIS-WATCHER’s This reduces “planning what to do next” to a matter of deciding what to the results of the to use a simplified description of the world, This the operators have access its action-selection. the central-system is “now”. Only central-system only receives for making that the system can only reason about the current situation. 32 R.J. Howurth/Artijicial Intelligence 100 (I 998) 5-85 53.1. Situatedness and normal behaviour in the central-system instead activity interprets is important (see Norman is not neutral, it is fundamentally [ 841 for an introduction) and AI, which and Flores [ 108, pp. 27-371 describe how the interpretation they are in a state of what Heidegger calls “thrownness” provides to how HIVIS-WATCHER a link between the of the social. The activities of agents are not Situated social science world. Winograd perceiver planned out in detail, (for details see [ 1081). When interacting to step back, reflect and plan. This has been investigated by Suchman that can evolve out of situated activity, so that previous experience can be used to structure future activity. This distinction to the difference is similar (e.g., previous, now, next) and McDermott’s between deictic [74] useful observation reasoning we reason from the past and the future, which allows us to the side, taking a step back and representing give names [96] who identifies plans as something that in most AI models of temporal temporal durations. it is not possible representation and planning thrownness temporal between to time points, such as dates, and measure in [ 551 we can take inspiration to begin example, it is likely As described to understand its observation in his discussion [49]. For example, [41]. This example is using what Gartinkel from the work of Garfinkel to his fellow colleague which [49, p. 1161 provides an illustrative is from the office-worker domain where from opposite ends of a corridor are about needs some “model” of the various behaviours [ 4 1 ] and the behaviour of other actors in the to of the scene. To give some idea of the complexity of two to pass such that one, let is ignored. the from which Oscar can choose In this process of explaining why his greeting was ignored, where Oscar uses his to greeting, We Heritage scene the official-observer encounter during this problem Heritage of Garfinkel’s work people walking us call him Oscar here, gives a greeting This gives rise to a number of options behaviour of his colleague. Oscar own model of “normal” determine only really become aware of our “model” of other peoples behaviour when something and Flores describe goes wrong the Heidegger’s (i.e., he tried to work out what might cause his colleague not norm becomes apparent the greeting was not returned). This to greet him) when it was breached element of identifying when observed behaviour deviates is it would be a useful extension. The in HIVIS-WATCHER, not implemented description that these models do exist. Another example (i.e., not as expected or becomes “broken”-Winograd usage of this the “norm”) that might give rise to this unacknowledged calls “reflexive (called is provided by Gibson’s “valence” given here is more to illustrate In our example with Oscar, or “maxims of conduct” that there is research the kinds of reasons the expected norm [ 108, pp. 36-371). that demonstrates accountability” (i.e., when to explain behaviour approach although from term steer adaptively [44] describe what ple/animals Crooks tion of the region of psychological the environment. a complex how the official-observer the field of safe travel) scene. It represents form of path prediction. to interpret locomotion their they call a “field of safe travel” which through forces or vectors the environment. Gibson [ 43,441 of how peo- and is a representa- that move with the agent through like is possible, in (i.e., how it uses in the observed the awareness of what behaviour rather In the surveillance problem we are interested from driving its knowledge can employ its perception of the participants R.J. Howarth/Art$cial Intelligence 100 (1998) 5-85 33 The agent model used here is an approximation scene object’s normal conduct, which we call the “typical-object-model”. not have to go into to much detail here let us just use the following definition. of a human observer’s model of a So that we do Definition 8. A typical-object-model routine behaviour observer’s knowledge the MACNET about how objects behave. expressed using is a collection of rules (or rather elements language) that describe of the official- is used to reason about the various aspects relating to those given in Section 5.2.2 as include the typical-object-model it is run upon. These aspects Basically the attended object well as aspects relating and location attributes indexing). The typical-object-model on the current aspect values. Further details about in [54]. to properties of the attended object itself such as speed, direction in Fig. 4, used for contextual (such as the region to run next based are given is used to select which operators the typical-object-model types, shown Although all the MACNET rules in HIVIS-WATCHER could have been implemented collection by repeating set of rules, with as one homogeneous one set for each object we might want to reason about at the same time. To simplify things that is run for each attended object. The effect of either approach is the same. The first simplifies some data the second reduces management, there is just one typical-object-model the typical-object-model the number of rules. in HIVIS-WATCHER 5.3.2. Elements for task-based control in the central-system In HIVIS-WATCHER the central-system also includes other elements in addition to rules. It contains a small amount of memory MACNET networks used for task-based control, in Section 7.2.1) into the more global viewpoint of the global-form. We describe how these operate in Sections 6 and 7. in the form of the Bayesian rules (described together with additional information local object-centred to be combined that enable inference 5.4. Summary This section has described the three main elements of HIVIS-WATCHER shown in the preattentive Fig. 14. We have covered model and other forms of reasoning used in the central-system. Next we describe how the individual task-based results from attending task relevant objects are selected to be integrated and how useful, ties these disparate elements and attentive operators, to different objects in the first place. the typical-object- together enabling control 6. A computational theory for task-based control in HIVIS-WATCHER The above overview sets out the framework within which task-based control has been implemented. We first provide a more generalised description of the main elements of this approach and then, in Section 7, describe how it has been implemented in HIVIS- WATCHER. 34 R. J. Howurth /Artificial Intelligence 100 (1998) S-85 6.1. Guiding computation A fundamental step in the approach complex that act upon the application taken here is to separate of the more computationally the input data, and use the results of appropriate operations to guide application the irrelevant by ensuring performed the reasoning of understanding what a scene object primitives agent based computations when we consider and the complex one to be a fovea1 one (e.g., recognition). We can summarise considering is relevant is doing, simple operations in Section 5.2.1, while complex operations the simple and complex from the simple operations functions. The goal here is to reduce complex operations In the context the Gestalt attentional, expensive to the task at hand. in Section 5.2.2. The connection with perception to be a peripheral one (e.g., motion detection) the simple operation include include a general case: described described this by is two operators OPi and 0P2 where less complex and runs faster than OP2, Definition 9. Given (1) OPI is much (2) OPI does not return an answer (3) OPI is true in all situations where OP2 would provide a useful result, (4) OPI is false in all situations where the preconditions that is as useful as OP2, of OP2 would not be met or where we do not want to apply 0P2. If these conditions call OPI the simple operator and OP2 the complex operator. are fulfilled, OPI can act as a guide for the application of 0P2. We OPl is part of the preattentive the attentive for a particular observed objects and those engaging cue, and OP2 is part of stage. We next describe how the appropriate OPis and OP2s are chosen the behaviour of the task, and then look at how the distinction between stage providing a preattentive the perceiver, affect task-based control. 6.1.1. Policy In HIVIS-WATCHER the user inputs its query before any processing is done. This question takes the form of the tuple, called a “policy” or surveillance task. Definition 10. A policy (cue, attend, ignore) specifies as a preattentive cue, a set of behaviours to look for, and a set of behaviours the simple operator OPI that acts to ignore. those features The policy defines that are interesting. Each policy has a preattentive “cue” which may be the same for more than one policy and may apply to policies other of all than those selected. The policies considered such as “tanker refuling aircraft”. This causes occurrences HIVIS-WATCHER to the current policy. of some specified behaviour to be blinkered to any observed behaviour in this paper concern that is not related the identification 6.1.2. Agency and kernel As shown in Fig. 22 there is a horizontal separation into two sections called “agency” and “kernel”. The agency represents HIVIS-WATCHER’s model of the behaviour of R. J. Howarth/Art@cial Intelligence 100 (1998) 5-85 3s compact encodings from intermediate-level visual processing kernel Fig. 22. The elements of HIVIS-WATCHER about reasoning In contrast in the scene). (i.e., those it observes the kernel contains other actors/objects reasons about a model of the observer’s more explicit visual behaviours. The agency in the scene. The kernel takes a more abstract the actual object shapes and relationships The kernel in the global grid representation. the markers approach [2], where as the follows more closely local to the agency that control attended object. Also, in the agency, input, which objects HIVIS-WATCHER run and receive because the selection of which OP2s to run is dependent upon factors other than the OPI results alone. to their work, taking account of the environment attends. These various elements assign, provide the approach used by Agre and Chapman the general case is more complicated is an extension the global-form those elements the results. In practice contains 61.3. Markers HIVIS-WATCHER to the two elements run the same set of rules uses two types of attentional marker called “agent” and “kernel” agency and kernel. The main difference between the typical-object- that correspond the two is that all agent markers types model) and that each kernel marker runs a different set of rules. The two marker they perform also access different classes of operator to buffer- different visual actions. For example, property values addresses associated with the attended object. Kernel markers, on the other hand, have their own operators which provide more extensive such as being placed at any grid address, noting the position or tracking an agent marker, accessing properties about the environment and once attached can obtain attentional agent markers can only be attached in the peripheral-system being marked, etc. (grid position) functionality tracking) because (called (called As described shape (see Table 3) that is not part of the original is determined by its address in Section 5.2.3 we denote the position of a marker by a small geometric image data. The position of a marker to in the grid, and for display this is mapped (scaled, etc.) 36 R.J. Howarth/Art$cial Intelligence 100 (1998) 5-85 Table 3 The various attentional marker types used in Section 8 display shape global variable square diamond pentagon down triangle up triangle cross n + 0 V A + *age&O* *agentl* *agent2* *tail-marker* *head-marker* *stationary-marker* type agent agent agent kernel kernel kernel entity the-vehicle the-vehicle the-vehicle the-trailing-vehicle the-leading-vehicle the-stationary-vehicle provide an indication been allocated the grid, its presence This discussion of its place on the ground-plane in Fig. 20). Although or scene object it has in Section 8 do not show to which the results (as shown is apparent by the location of each marker. of the agency, kernel and markers sets out the background in to guide or initiate used the following description of how the results from the OPis are used the use of the attentional OP2s. 6.2. The agency evolving mass of input data, an provided by the set of pose Task-based control stream of frame updates by resolving is used to reduce three key problems concerning: the computation performed when processing a load of determining what all the objects are doing; ( 1) the computational (2) from the temporally the amount of evidence issue even with the relatively compact representation positions; the viewpoint complex The official-observer form of the spatial arrangements problem (3) integration of the aspects from different attended objects (a more introduced in Section 7.2.1) two or three objects such as that set of known frames, and the interac- (introduced task relevant behaviour the perceiver’s interactions may between from for “interesting” or interactions to an instance take a number of image is looking some particular object behaviour, fulfill some measure of similarity behaviours. These tion might complete or be initiated out of shot. The typical-object-model in Definition about jects, different objects and the typical-object-model if an extensive historical difficult that the local-form at the wrong computational observer. information attention swiftly applied, something 8) does not maintain much contextual to the deictic approach, enabling is too reactive and dumb level context had to be maintained. However, to provide useful to act as an attentional in accordance controller individual ob- to be switched between that would be this means results directly and is for the official- To enhance these features so that the central-system global-form results scene’s happenings together, has been added. The global-form to produce a single consistent that are deemed interesting to the official-observer. can do event the is used to collect all the relevant agent those features of the story capturing reasoning, R.J. HowarthlArtifcial intelligence 100 (1998) 5-85 37 6.2. I. Allocate The objective of the ALLOCATE component is to direct attention. The allocation pro- about information to each object and select pertinent operators appropriate attends local environment. for is part of the it can only this is because when HIVIS-WATCHER the object and the object’s cess assigns an attentional agent marker to a scene object so that the typical-object-model can both generate deictic state descriptions this object’s current behaviour. Fig. 22 shows that the AGENTS component local-form, obtain LOCATE, part of the global-form, in the scene. ALLOCATE consists of two parts: a task-dependent relevant preattentive data is processed; and an “allocation” this processing these attentional markers have names an “agent”. The cue theory provides a framework results and reasoning about allocation system: global view of the objects theory of how theory of how the result from is used to assign an attentional marker to an object. As shown in Table 3 so we call each attended object the Gestalt primitive figures. The that guide the reasoning of the runtime theory consists of three main functions has the official-observer’s to obtain an ordered list of interesting for representing like *agentO* “cue” them In contrast AL- (1) focus-of-attention, which only updates the selected set of target hypotheses and their associated functions; (2) selective-attention, which continues to watch; (3) hypothesis terminate-attention, which stops all activities associated with a target hypothesis once it has been confirmed or denied to an acceptable degree of confidence. to dynamically select the most interesting By identifying those objects the computational load problem introduced is determined attention to do when a situation interesting ALLOCATE component objects involved tion process context-dependent allows more behaviour via the typical-object-model. that the policy deems interesting, these provide a solution to at the beginning of Section 6.2. Terminate- from data given by COLLECT, which is identified (a task goal achieved). Fast identification time to be spent looking for relevant is used to decide what of un- features. The the ignore to them. This alloca- also made should is used to decide whether HIVIS-WATCHER in the exhibited behaviour or continue to attend is task driven not data driven, with the processing performed 62.2. Collect the collects together to ALLOCATE. Fig. 22 shows The COLLECT component the results from each agent and provides feedback of identified behaviour that like ALLOCATE, COLLECT is also part of the global-form. Each agent provides a sequences of activities takes into account everything into an episode. This episode which COLLECT combines frame features) important (or at least the recent results from each updates. The COLLECT component measures agent against the observed operates with a longer action the various deictic time frame than the agents in the scene. states detected by each agent into a continuous This contextual knowledge to make sound predictions the other “happenings” (typical, untypical) is used to enable HIVIS-WATCHER’s or illegal. The global-form story of what is happening that have been detected about what is happening and is able to combine the typical-object-model to determine whether in the local-form in the scene. in the scene global-form is legal from 38 R.J. Howarth/Artijicial Intelligence 100 (1998) 5-85 In Section 7.2 we provide an implementation is simplified by the fact that the official-observer originally to attend and thus the execution of an agent’s typical-object-model of the COLLECT component that shows integration problem caused by the use of deictic represen- selected is like it is attending. that needs to be retained the possible next actions of an object the amount of evidence considering how it can solve the viewpoint tation. This problem which objects the official-observer The COLLECT component by identifying also reduces the task relevant values. 6.2.3. Task-based control of agency Fig. 22 shows how ALLOCATE and COLLECT are linked together, being two parts of the task-based control the results from task-based control operates process in the kernel. theory that first identifies what to look at and that then integrates the larger picture. Next we look at how into the attentional 6.3. The kernel relationships, episode may take longer Fig. 22 shows how the kernel and agency co-exist in HIVIS-WATCHER. There are two in Section 6.2: ( 1) although useful it is not suitable for coordinat&g reasoning outlined related binary objects, the expression of such non-local object behaviour as an problems with the local deictic single or spatially for describing non-local and (2) identifiable of representation. second arises from the use of local spatio-temporal this second problem object behaviour. The typical-object-model events and, because of this we are not able to identify accomplishments on being able to recognise situation before To address and the reasoning. While COLLECT addresses to cope with non-local does not retain a temporal history of past (this depends from the than can be easily modelled using is another version of viewpoint the state change). We call this the temporal history limitation problem. in the agency, we need a different approach that the situation after the state change the kernel, a more global component, The first problem the local-form is different integration (2) provide a spatial representation that can ( 1) to to scene objects and other parts of the environment, in HIVIS- is able to meet these requirements. references. The basic architecture used for different application domains are given [25]. Agre and for reasoning is appropriate and SONJA In PENGI and SONJA the perceiver time spans, reason about the programs PENGI also provide arguments references these perceiver suitability [ 1,2], BLOCKHEAD from the work of Agre and Chapman, of this architectures these we introduce operate over longer episode-length coordinate (3) WATCHER, Illustrations by Chapman for why this approach about evolving, dynamic visual data from the environment. central-system the kernel part of the central-system model of the observer’s own behaviour as it interprets scene under observation. With the kernel routines used to determine behaviour has taken place. Each stage in the routine corresponds of observed object behaviour, the correct sequence describes visual operators and the transition an episode. The peripheral-system that are manipulated [24] by these routines of behaviour. the evolving data unfolding providing a in the if a particular policy to an accomplishment through each stage of the routine in contains appropriate takes the role of the person playing a video game. In HIVIS-WATCHER takes the role of the official-observer, R.J. Howarth/Artijicial Intelligence 100 (1998) S-85 39 typical-object-model task relevant objects While ALLOCATE and COLLECT form an integrated couple, ALLOCATE is also used agent for the kernel. This (or “warps” as the between agency and using attentional markers provides to identify marker’s Agre and Chapman would say) a kernel marker on top of the agent marker “telling” kernel an interesting object has been found. While communication kernel could have been done an elegant solution. is done via the allocated in the central-system, that moves an effector producing result 6.4. Summary The separation described agency central-system reasoning being used to convert form picture. reasoning chooses about to attend. contains between is given credence by the observation, agency and kernel in Section 4, that egocentric and exocentric viewpoints the AGENT component are incompatible. The local, exocentric about each attended object, with the ALLOCATE and COLLECT components into one overall egocentric, global- results only does egocentric, global-form this part of HIVIS-WATCHER the objects and other scene the kernel central-system the separate exocentric that performs In contrast features This has covered the theory of task-based control describe how the various elements are implemented which makes clear the kind of roles the kernel markers and provide an example in the agency and kernel. Next we in the agency (principally ALLOCATE and COLLECT) that are used in the kernel, set of routines in Table 3 play. operator The complex ( HIVIS-WATCHER’s tentional encodings minimising. applications WATCHER’s main objective). reasoning hides that HIVIS-WATCHER recognition process) attentional that uses the model-matcher results. While the cost of performing model-matching is guiding is the model-matcher together with the associated at- the stream of compact that it is worth the number of attentional marker (HIVIS- we assume task policy the surveillance the agency and kernel minimise Both to scene objects, while still fulfilling 7. An implementation of task-based control in HIVIS-WATCHER the operators We have separated in the peripheral-system simple, and of low-cost; and attentive ones which are applied into: preattentive ones that are global, to a single object and are more complex. The preattentive operators are used to guide application and gross- of attentive ones. Example preattentive change-in-motion which are described below. The motivation behind the preattentive cues chosen here, was their potential usefulness on low-level data such as the identification of possible objects [45] is used to develop expectations of describe how knowledge about a known ground-plane and if they comply with likely object motion). Once we have these coarse descriptions, the preattentive such to obtain aspects about as model-matching (or some other form of object-recognition) cue, then they become candidates (for example, Gong and Buxton for further attentional processing include mutual-proximity from clustering flow-vectors operators 40 R.J. Howarth/Arti&ial Intelligence 100 (1998) 5-85 Table 4 The DDN node types. Preattentive operator mutual-proximity gross-change-in- motion Node Ni(f) R(i.j)(‘) Phi(r) Psi(t) h(t) States and function {not-near, The proximity of object nearby, close, very-close, touching} i to it’s nearest neighbour at time r watch} {ignore, The result value saying how interesting lationship between the pair of objects i and j is. the mutual-proximity re- slow, move} {stat, For the motion-prior is short for “stationary”. value is moving (i.e., prior moving). stat slow, move} {stat, For the motion-prior value is stationary (i.e., prior stationary). {ignore, watch} The result value saying how interesting of object i is. the motion-prior change the object. Basically, once we have found where something and workout what it is. interesting is, we then try 7. I. Allocate is allocated, Here we describe the implementation (see Section 6.2.1) is a simple operator of the two different preattentive is used by ALLOCATE should be allocated cues introduced in Section 8. Each of these preattentive that acts as a guide for its more complex operator to de- to a scene object. Once such the more complex process of obtaining visual aspects of this preat- cue theory. We [ 851) because of the that we are using as cues. The Bayesian network approach can both represent and reason about foundation. Other ap- in the examples in Section 5.2.1 and used (OPI) cues (OP2). The preattentive cue, OPl, termine whether an agent marker an agent marker the agent by attending tentive cue we have used a Bayesian network use Bayesian networks uncertainty present preattentive this uncertainty, proaches here. like Fuzzy Logic might provide a viable alternative, but these are not considered to the scene object can be performed. To calculate and are attractive because of their mathematical in the results provided by the Gestalt primitives details are given by Pearl to model ALLOCATE’S (background We do not extend in a dynamic present a novel use of them, called Bayesian networks steps (or clock ticks) evolves over time to represent These simple graph structures Details of how these are constructed the computational theory of Bayesian networks, ‘Dynamic Decision Networks” although we do (DDN). This uses in discrete context, with the graph structure updated to reflect the contents of the scene. The graph used by the DDN relationships being modelled. that execute quickly. the evolving spatio-temporal form singly connected tree structures is given in Appendix A. R.J. Howarth/Artijicial Intelligence 100 (1998) 5-85 41 probabilities Table 5 DDN conditional is present and returns a single higher-order matrix by performing described by Kim and Pearl conditional [63]; and (3) probability matrices are provided. to define Mr,lNN; (2) CJP is a function for the proximity mechanism. Note that ( 1) MRfN is not used directly, and probability matrices that takes a list of ZD conditional the equation P(ni 1 bk, dt ) = cyP(a; 1 bk)P( a; 1 (II) for which child node right are the subgraphs illustrated bottom not-near nearby close very-close touching Combining joint probabilities 7. I. I. Mutual proximity The mutual-proximity test is used to identify when two proximate objects are travelling in the same direction. The spatio-temporal proximity N;(t) test described in Section 5.2.1 which provides in Table 4. In the DDN used here the basic graph primitive used for OPl function is the the qualitative values used by is depicted as: proximity NA(t) o-o-0 NE(~) R(A.B) (1) this mutual-proximity relationship between objects A and B, capturing This graph describes a mutual-proximity the primitive notion of object A being near B and B being near A. The relationship node R denotes and holds a belief value that reflects how interesting this is. The states and purpose of the two node types are given in Table 4. The directed the fixed conditional in Table 5. These matrices were edges hold derived from careful consideration is specified by the matrix Malx, capturing increasingly more interesting input values. The spatial relationship relationship becomes as two objects are identified as being nearer to each other. probabilities of the possible the belief that a proximity given 42 R. J. Howarth/Artijicial Intelligence 100 (1998) 5-85 shows that when we evolve the network over time we make use of maintained in Fig. 23 (b) . From representing links are to the next time point. These directed links the relative time point, A and to the image data. If, at the current from the previous node temporal temporal position of the temporal temporal continuity. Fig. 23 (c) shows in part (b). This is done than a multiply connected from the previous value to the formation of the new belief than once all from the graph to evaluate the results obtained tree is built for each one, enabling, that a tree is easier preserves them to contribute that now holds between object A and B. If there is more effectively to be ordered in terms of their “interestingness” reason object references to each other we can form time point the temporal Fig. 23(a) official-observer B are still near to the current ones as shown previous edges each hold one of the matrices how we extract a singly connected network for the parsimonious network. This graph simplification propagation allowing about the relationship one relationship propagations relevant relationships if NB is missing neighbour nearest and mutual-proximity given then a separate the pairs present are complete, for two time points links and nodes in Appendix B. to the current preattentive the new between to NA now becomes NC. When NB is detected again structurally over time to reflect task. The network changes the the objects of interest. For example, Fig. 24 shows what happens (t3 and t4) due, say, to occlusion and the nearest it is identified as being this. The details are in the network are created cue is used in Section 7.2 and implementation to reflect 7.1.2. Gross change in motion to moving” is used to enable ALLOCATE cue “gross-change-in-motion” to any scene object The preattentive an agent marker “stationary described in Section 5.2.1. This preattentive cue would raise an attention-calling in situations where there is a change of steady velocity, such as, when a vehicle stops at a junction in the same place for some time. to assign or operator we response and is based on the spatio-temporal or when people get up after sitting to assess the road conditions, from “moving to stationary” that changes discontinuity To denote the current then stopping that motion-prior prior such moving, unusual. We assume If the observed motion of an object behaviour is taking place becomes typical motion of an object we use a prior value called motion- is is E {moving,stationary}. is unusual; when When the prior value that normal behaviour of an object is stationary, for motion-prior the prior value moving is moving. then abnormal is different (see Section 5.3.1). from the motion-prior If this abnormal behaviour persists it is changed to reflect this. the norm and the motion-prior In Table 6 we describe various conditional table describing type allocation” the patterns of graph node and joint probability matrices, with the these “Node matrices are assigned. Fig. 25 gives an example of the simple graph structure produced, preattentive cue. Although which is like half of the graph used for the mutual-proximity the graph structure may stay the same the node types change to reflect the motion prior, in Fig. 25 are either of type PM or PS from from Table 4. In Table 4 i.e., the P* nodes the qualitative that hedge forward to take account of vehicles at a junction. The gross-change-in-motion cue is used in Section 7.3 with implementation details given in Appendix C. value slow preattentive is included to which R.J. Howarth/Artijicial Intelligence 100 (1998) 5-85 43 (t-1) ,.. . ,. x NA (1) ,, _ (l-1) ,,” ^I (t) ,, FL? (t) x,,l :H, !jf (b) (4 Fig. 23. Graph linking structure. t1 t2 t3 r4 ts t6 Fig. 24. Change over time. @-@ formed the MACDDN primitive Basic graph primitive by now-errf . ($---qM &&* i 8 Fig. 25. Basic graph primitive. 7.1.3. After allocate identified the potentially Once ALLOCATE has and HIVIS- then done ap- WATCHER has then worked out what each to this object, the next process is to form some propriate contains understanding two different approaches and the second is provided by the kernel routines. We look at each of these in the next two subsections. to this. The first is the COLLECT component, of interest are doing. HIVIS-WATCHER of what the object(s) object(s) is and task relevant interesting interesting reasoning relating object 44 R.J. Howarth/Art$icial Intelligence 100 (I 998) 5-85 Table 6 DDN conditional motion and is used by the subgraphs described in the “Node type allocation” for gross-change-in-motion. probabilities Note that MO denotes table. the general description of stat ignore I, slow 0.0 0.4 1.0 move watch I.0 0.6 0.0 ignore watch stat 1.0 0.6 Imove( 0.0 slow 0.0 0.4 1.0 1 MRlPM = MRlPS = MMOIMO = Combining joint probabilities ‘%jRPM ‘%ol~ono = cJP( ["HO~MO.M~~~M~l) = cJW [&IR> ‘%lPMl) = cJJ’( [MRIR, = cJP( L”RiPH. = cJP( [&;,s, M,;,s]) MRiPMPM MRIPSPS MRjRPS MRIPS~ ‘%PMl) 1 Node type allocation child parents matrix PM PM PM PS PM PM PM PM PM PS R R R PM RPM PM PM PS PS PS PM PS PM PS PS PS PS R PS R RPS R PS PS w4OIMO %OlMO MMO(MOMO ‘%O~MOMO Malts MRIRPM MRIPMPM wl0IM0 ‘%OlMO MMD\MOMO MMOIMOMO MRIPS MRIRPS W,IPSPS is to pull the 7.2. Collect The purpose of the COLLECT component, introduced in Section 6.2.2, results related in Definition 9 we are using is used to guide the applicability agent providing deictic state descriptions two types of operator OPI and OP2, where agent markers. To do this COLLECT takes from different of two mutually-proximate objects, such that each deictic viewpoint of the other object. As the together deictic viewpoints is from an attentional described simple OPl operator ones. The complex operators, 0P2, used here are the positional, heading and speed tests given in Section 5.2.2. All three of which are guided by the same OPI-the cue for mutual-proximity implemented using to the-refobj. (Note the result saying which, operator only works when given The result such as behind-me, reference, is a deictic between the-other and the-refobj. Often both objects in a description attended in Section 5.2.1. Section 7.1 .l described how this is relative complex if any, is the nearest object.) aspect the positional pair are in the mutually-proximate from both objects of its twins relationship. described the DDN to identify that conditions ( 1) -( 4) of Definition 9 are fulfilled-the of the more complex attentional relevant pairs of objects, i.e., the-other preattentive describing resulting R.J. Howarth/Art&ial Intelligence 100 (1998) 5-85 4s COLLECT combines the two disparate deictic viewpoints, in- following, queueing or some other, unknown to say whether they seem the most probable three identifiable behaviours the presence of likely overtaking, approach, here a Bayesian network dicate but similar, behaviour. These mutually-proximate stationary. While machine does not represent evidence collected network, a preprocessing tive deictic properties the information dimension conditional qualitative unification the Bayesian network, called TASKNET, for objects with queueing being more likely if the scene objects are both the input agent marker results could be integrated using a finite state approach it does hold an evolving model of the to the Bayesian the respec- Inputting it would just require higher in the stage and then look at how stage is used to reduce the state-space by unifying to produce a single qualitative value for each property. probability matrices stage. First we discuss legal transition so far. Rather the deictic states directly to a Bayesian network is used. Although the relationships is implemented. this unification the Bayesian is possible, information than input to express contained directly representation system scene objects. These spatial arrangements (as described coordinate the positional To describe how 7.2. I. Unifying mined deictic states from states. Spatial the results consider deictic in the surveillance problem, such as the representation of the observed an absolute spatial arrangements problem we use the deictic 5.2.2. However, objects involved This problem described only half of the matrix needs the local-form framework within which to describe framework three tables, each containing in Table 7. These rules describe a matrix this introduces into a common and once each object’s We can use is illustrated to combine the problem of composing representation intrinsic two attended objects are integrated plays an important of binary spatial arrangements let us first part in Section 3.4) and representation to define are difficult in this in Section the deictic descriptions of the to overcome introduced and resolved by the composition that can be used by the official-observer. rules for relative position symmetric values so that contains to be specified. I4 The approach used here is based on it provides a natural front is identified, the spatial arrangements of objects and for relative heading the same a set of statements of the form speed. ” Table 7 shows to form the com- “a b ---f c” where on each line the two viewpoints a and b are composed posite c. This composite can be thought of as an iconic model representing the fusion of both viewpoints given by a and 6. Some illustrations of the icons for relative position are given that correspond position to the numbered rules. Each small illustration of a pair of poseboxes. Where each posebox shows a prototypical results (representing in the scene. relationship the values and and which is given to a LISP macro the heading is true ” This is the format used in the LISP implementation full matrix used at rnntime. ” Unlike position, if inverse, (a faster-than that as both objects are attended, combining the to combining in [60], an object’s values for heading and speed of the two attended own heading can be described using eight qualitative values with the combination of such heading values from two paired objects producing in Table 7. In this paper I have chosen is used for each property. the results for the relative differences of heading and speed is similar to use relative values so that the same (extendible) the-refobjs. For example, as described to those given for relative heading relationships is true. a) do have a valid similar composite speed pairwise (b slower-than that generates This means framework results then e.g., the b) 46 R.J. Howarth/Artijicial Intelligence 100 (1998) 5-85 Table I The composition rules for relative position, heading and speed. Positional viewpoints Composite I behind-me behind-me -back-to-back 2behind-me 3behind-me 4behind-me leftside-of-me +trans-overtaking-back rightside-of-me -+traus-overtaking-back infront-of-me + following 5leftside-of-me infront-of-me -+trans-overtaking-front 6rightside-of-me infront-of-me -+trans-overtaking-front 7leftside-of-me leftside-of-me ----t same-side-adjacent 8rightside-of-me rightside-of-me --+ same-side-adjacent gleftside-of-me rightside-of-me + overtaking-passing 10 infront-of-me infront-of-me -head-on Heading difference viewpoints Composite parallel-to-me parallel-to-me 4 alongside-consecutive similar-heading-to-me parallel-to-me -+ alongside-consecutive similar-heading-to-me similar-heading-to-me 4 alongside-consecutive similar-heading-to-me perpendicular-to-me + converge-diverge perpendicular-to-me perpendicular-to-me 4 converge-diverge opposite-to-me parallel-to-me parallel-to-me opposite-to-me -+ opposing perpendicular-to-me -+unknown opposite-to-me +unknown opposite-to-me perpendicular-to-me "unknown similar-heading-to-me opposite-to-me -+unknown Speed difference viewpoints Composite *slower-than-me faster-than-me -disparate similar-speed-to-me faster-than-me + disparate *similar-speed-to-me similar-speed-to-me -flowing slower-then-me slower-then-me slower-than-me 4 flowing similar-speed-to-me -+ flowing moving-slowly-like-me faster-than-me faster-than-me faster-then-me -+ flowing ---f flowing *moving-slowly-like-me moving-slowly-like-me -+ sluggish slower-than-me moving-slowly-like-me ---* sluggish stationary-like-me similar-speed-to-me ---f sluggish stationary-like-me faster-than-me -sluggish moving-slowly-like-me similar-speed-to-me -+ sluggish *stationary-like-me stationary-like-me + congested slower-than-me stationary-like-me + congested stationary-like-me moving-slowly-like-me + congested R.J. Howarth/Artijcial Intelligence 100 (1998) 5-85 47 Table 8 The TASKNET node types. Node J4 i.1 j UP(i.,l UH(,.j) us(i.j) States and function {overtaking, The likely-episode following, queueing, unknown} of the marker pair (i, j) {back-to-back, overtaking-passing, The unified positional same-sides-adjacent,head-on} state of the marker pair (i. j). trans-overtaking-back, following, trans-overtaking-front, {alongside-consecutive, The unified heading difference of the marker pair (i, j). converge-diverge, opposing,unknown} {disparate, The unified speed difference of the marker pair (i, j). congested} sluggish, flowing, described for completeness. the starred For example, in the tables are given in an abbreviated in Section 2) contains an arrow denoting (*) the value disparate from the model-matcher the table for speed difference included and so is best described by one vehicle going points short for the-refobj saying position the official-observer’s dedicated TASKNET which, as described next, builds a coherent temporally its front. In lines are the main entries with the others denotes different speeds than another. The deictic view- -me is These com- to provide to the pair’s of the the deictic viewpoints of the selected pairs of agents interpretation of the relationship. This acts as input evolving object relationship. that the-other-is-on-the-lef form, for example, rules resolve interpretation lef tside-of tside-of-me. faster 7.2.2, The TASKNETs The TASKNETs in HIVIS-WATCHER performed based on spatio-temporal the computation to Rimey and Brown’s work to guide This is similar rect the camera using geometric scene surveillance TASKNET has a temporally defined before runtime. A TASKNET a description represent key features identify. The output root node represents lected so far, in a set of candidates tasks, and the default unknown of how observed properties relevant task. [87] use of Bayesian networks relationships. Here, however, our application relative reasoning according are implemented to the selected surveillance using a static Bayesian net- task. to actively di- requires to a static camera. Each that are to each pair of indexes I6 to provide to known behaviour. The input nodes to the overall belief, based on the evidence col- task, related but unwanted probabilities relate consisting of the wanted to the task that the TASKNET has been constructed fixed tree structure with conditional is allocated In Section 8 we use TASKNETs to distinguish lowing behaviour based on the unified values implementation ple structure in Fig. 26(a), shown the TASKNETs use the nodes described between for position, likely overtaking speed and heading. and fol- In this in Table 8 and have the sim- the root l7 with UP(;,,i), USci,j) and UHci,j) being is a buffer-address with the pairing created by the preattentive DDN for mutual-proximity. I6 Each “index” ” LE stands state, UH stands ference, US stands for Unified Speed difference, with the *-PRO forms representing Bayesian network for Likely-Episode, UP stands that are used for PROcessing. for Unified Positional for Unified Heading dif- the internal nodes of the 48 R. J. Howarth/Art$cial Intelligence 100 (1998) 5-85 features /- positional speed \ heading likely- episode Deictic states Deictic agents i and j likely- episode (a) Preattentive selection t (b) Fig. 26. The TASKNET graph. of the task-based control mechanism. (a) The TASKNET network used in the proximity example. (b) A summary given summary relationship probabilities is illustrated in the DDN by the pictorial the mutual-proximity in Table 9. Each TASKNET’s nodes to run on which the output node. These nodes are related according are used to select which agents running the correct agents from the DDN graph provides preattentive from to the nodes, and LE(i,j) being to the agency conditional in Fig. 26(b). At part of HIVIS-WATCHER selection of the two deictic agents. the bottom (index pairs of the form The results (i, j)) the i and j are in results the scope of the global-form. Next, up from the selected agents, are the deictic states of these generated by the typical-object-model together with a composite agent other evidence that the two agents are from the agent results has two engaged components: E -me}. The input given {behind-me, is the result from an appropriate composition matrix @ (such as those to TASKNET,i,j, described algorithm in Section 6.2.1, on each TASKNET of the nearest object; and the deictic-event-primitive to produce an estimate of the likely episode in Section 7.2.1). The result from running the index-reference rightside-of run on each agent. The composition to guide agent allocation, indexes. We can combine feature value, which i and j, because results produces in. For example, feature obtained -me, leftside-of -me, infront-of the positional the Bayesian is integrated as described on indexes inference is used R.J. Howarth/Artificial Intelligence 100 (1998) 5-85 49 Table 9 TASKNET conditional probabilities for the road-traffic example. overtk follow queue unk MLEIUP = back-to-back tram-overtaking-back following tram-overtaking-front overtaking-passing same-sides-adjacent head-on 0.0 0.6 0.0 0.6 0.6 0.0 0.0 0.0 0.0 0.6 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.4 0.4 0.0 0.4 0.4 0.0 0.0 0.0 0.0 1.0 1.0 M,(, = = vo,i E UP, P(0 j i) if 0 = i, 0.70 0.05 if 0 # i. sluggish coneested 0.15 0.0 0.15 0.0 0.5 0.7 0.2 0.3 1 overtk follow queue unk MmllUH = Vo, i E UH, P(0 1 i) (0.79 if 0 = i, 0.07 if 0 f i MLEIUS = MLEIUU = Combining joint probabilities MLEl”PUS”S =cJp( ["LE~US~MLE~US~MLE~UP~) by identifying queueing theory location attended or not. the likelihood that the relationship is either overtaking, following, or unknown, and then, as described if this identified in Appendix D, using ALLOCATE'S al- to be likely behaviour should continue to determine 7.3. Kernel routines As outlined in Section 6.3, some scene object behaviours in Section 7.2, because in an episodic way over time. This type of surveillance evolve the TASKNET described distinct stages that involve different scene participants. To illustrate how kernel routines can be used associated with for the presence of one vehicle giving way to another. the official-observer The first kernel cue, as in Sections 6.3 and 7.1.2, which is used to detect when a vehicle stops at a described junction. to detect such an episode we will describe is initiated by the gross-change-in-motion identification the routines preattentive it requires looking routine that we wish to recognise for task is not suitable of a number of The perceptual task of the official-observer two correspond to the two roles the first in the giveway episode and are denoted by S for three important entities: involves 50 R. J. Howarth/Art$icial Intelligence 100 (I 998) 5-85 frame 192 global variable l ~CtiV.3tiO~-Dl~t31* 'activation-pwula2* *COnfliCt-Dh,l." entity display the-stationary-vehicle’s- path-predict& the-hlocking-path- prediction the-conflict-area black dark grey light grey Fig. 27. A table describing here. the regions used by the three activation planes used in the example developed Fig. 28. RA is the giveway region linked to RB, its giveway-to-zone. See also Fig. 4. and PI? for the-vehicle-that-S-is-giving-way-too; the-stationary-vehicle, denoted CA for the-conjlict-area have been found, an area of mutual conflict, C4 can be identified S and through which PB will pass). This area links S to its cause. All that remains to determine behaviour and the third is the two roles of S and PI3 (the space in front of is traffic, and exhibits no other plausible that S is giving way to approaching region). When (a special (e.g., broken down, parked). the giveway episode We separate into five routines that use region-based-prediction (see Figs. 4 and 27 with more details given in [ 54]), and perceiver These routines are: level coordination. l Notice-stopping-object, change-in-motion prompts answers however, most likely answer which on completion to stationary event-gwl. The gross- an agent, called S, and the question “why is vehicle S stationary?” There are a number of possible the if S is in a giveway zone of an entry lane to a roundabout, generates allocates from moving is that S is giving way to something on the roundabout. R.J. Howarth/Art$icial Intelligence 100 (1998) 5-85 51 generates state-change-gw2. l Look-for-path-blocker, which on completion stage identifies PI3. For PB to be blocking S it does not need to be physically the way, it can also block by having “right-of-way” S. If PB exists giveway-zone contextual-indexing causing S to avoid a collision by stopping, this is true. This in such that its path will block corresponding to the this in Fig. 28, and using that PB is blocking S’s path the next two routines are to prove that typically be in the giveway-to-zone we find Pt3. Having proposed that S is occupying. This is illustrated it will l Work-out-conflict-area, which on completion the paths of S and PZ3, we intersect Hav- shared in stage look- and binds both S and PI3 together. CA should be invariant during ing predicted conflict area, Cd. The presence of C4 supports for-path-blocker, the giveway episode. them to find the mutually the proposal made state-change-gw3. generates l Watch-for-enter-conflict-area, which on completion generates state-change-gw4. to determine whether S gives way to Pt3, we wait until PI3 has passes that S is giving way, we only need to check that at least In order through CA. To determine one object passes l Notice-starts-to-move, through Cd. if S moves. The gross-change-in-motion agent to S. which on completion generates event-gw5. We then observe an from stationary to moving reallocates of perceiver These five routines given above order and, as a continuous sequence activity identifying a giveway episode are intended check for things pulled out into) which would contribute and support a giveway episode. These to be an illustrative subset of routines sequence, describe a temporal for that also there is a space that the waiting car could have away giveway behaviour that the car has broken down or been parked. towards explaining like hesitation the belief identifies routines (where that 7.4. Top-level loop Fig. 29 shows the top-level in cognitive separation made loop which describes loop shows is an important that HIVIS-WATCHER feature. As described the order of execution of the various has a tightly in Section 5.3 input and central systems in HIVIS-WATCHER. The that obtains object aspects, while the central system to fulfill and elements top-level in Fig. 22. This coupled architecture where feedback the traditional provides a description of the two tightly coupled components input system holds the functionality guides which objects should be attended so that their aspects can be obtained the given surveillance task. The separation of preattentive the use of a task directed central mechanism those task related features HIVIS-WATCHER the scene. for identifying is looking for. Using this architecture that the official-observer timely surveillance provides what is needed and attentive processing, about what is happening science between information provides in The whole of HIVIS-WATCHER constitutes the official-observer subset of the ideal official-observer) implemented distinction made between called agency and kernel. The agency part is more concerned with reasoning with, as described to task-based control the two sections important (or rather some in Section 6, a that we have about the 52 R.J. Howarth/ArtQicial Intelligence 100 (1998) S-85 ( 1) Update buffer with new frame of compact encodings. (2) Run peripheral-system present to the inputs central-system. and then (3) Run the agency central-system and then run the kernel central-system. (2.1) (2.2) Run agency peripheral-system. Run kernel peripheral-system. (3.1.1) (3.1.2) (3.1.3) (3.2) Allocate agents. Run each allocated agent’s typical-object-model. Collect results. Run kernel routines. (4) Run the effector-system. Fig. 29. Top-level loop of HIVE-WATCHER. observed behaviour of the actors/objects with the range of visual behaviours in some surveillance used for task-based control are different in Section 8.4, it is useful in the scene. Where as the kernel is concerned it is engaged task. These are both instances of the selective-attention machinery control. (as described that they in Section 6) and in some cases, such as that discussed that the actions of the official-observer that the official-observer their operation. to combine uses when It is just 7.5. Implementation HIVIS-WATCHER sic Bayesian network program tan [79] with extensions is used to formulate the description as described description To test this reimplementation the spatial-layout in [ 54,561. and the underlying implementation the rules in the central-system has been implemented follows as described in LISP (Franz has been reimplemented the algorithms given by Pearl in Appendix A. The MACNET Inc.? Allegro CL). The ba- [ 851 and Neapoli- that language following 1251 where possible, with slight syntactic changes [ I] [ 991. used as part of a of follows it has been successfully of MACNET also draws on Agre’s [ 241. The implementation that used by Terman execution mechanism of MACNET of Chapman’s program BLOCKHEAD database (see Section 3.2) and associated programs are described given by Chapman in [ 53,541. This implementation The results shown program which output in the Tables 11-15 were all written by the HIVIS-WATCHER the results directly to file in the LaTeX l8 table format. I8 LaTeX is a document formatting language. R.1 Howarth/Art$cial Intelligence 100 (1998) 5-85 53 Table IO The policies. cue attend ignore see Table in position Figs. 30 and 31 see Figs. mutual proximity overtaking mutual proximity following gross change in giveway motion mutual proximity and gross change in motion overtaking, following and giveway following overtaking 11 12 13 15 nearside middle farside 30, 31 30, 31 30, 31 32, 33 8. Examples of how task-based control operates in HIVIS-WATCHER The examples used here are drawn from the road-traffic domain. Fig. 2 illustrates roundabout. from a sequence a number of episodic behaviours taken at a German frames selected are unfolding: this In one vehicle the also towards image with three this part of the sequence leaves another the roundabout; rear of the image a car begins is in an entry to overtake a lorry. lane to the roundabout; the effect of using four different “look for likely following behaviour”, tasks: “look for likely overtaking “look for likely giveway behaviour” of these behaviours. Table 10 lists the policies we will be using the format of In from HIVIS-WATCHER we will use Figs. 30-31 and Tables 11-13. the three columns, each showing a sequence of results from the same raster task-based control is the spatial-layout show the effect of different to each result frame in Table 10. The background in Figs. 30-33. To explain results are displayed (numbers 96-228), from the model-matcher where it has identified a scene object/vehicle is only accessed when a marker as described in Section 3.2. The rectangular poseboxes depict the however (i.e., one of the six shapes a, +, 0, to an object. The numbers near the centroid of each posebox (or arrow head) (see Section 5.1) and the chevron the object’s buffer-address the object’s front (as determined by the model-matcher). In frame 192 the shaded regions show the path predictions and identified in Section 7.3 (in particular plane” I9 for the conflict-area area as discussed the “activation Section 5.2.3) used during Section 7.3. The activity of the various markers Tables 11-13. In these tables the routine “watch-for-enter-conflict-area” in formats are used although all three tables as described the accompanying two different is described see Fig. 27). Frames 204-228 represented in the marker’s grid conflict- show (see in planes are used to keep track of interesting “Activation for computing three activation planes, one for each path-prediction See also Fig. 21 and Chapman containment. regions in an image, as in Ullman’s [25]. The calculation of the conflict-area [IO41 routine uses and one to hold the result of their intersection, Here we compare behaviour”, and the combination and their corresponding these results the figures image frame sequence policies given of the ground-plane results this information v, A, + ) is allocated gives indicates erongiedosipeylekilseulavdoohilekilsetatscitciedjboferstnegahctawsriaplortnocdesab-ksaTnoitatneserpercitcieDnoitceleSknueueuqwollofktrevoetatscitcied0slnehT.erugifehtnideyalpsidoslaeradna,sexednisserdda-reffuberasnmuloctnegaehtnisrebmunehT.ruoivahebgnikatrevoylekilrofgnikoolmorfstluserehTdnaflessetalertahtseulavdleifs’jbofer-ehfehtgnisudnuofetatscitciedehthtiwrehtegot,rehtodnaflesrofsemanrekramehtstsilnmuloc”setatscitciedjbofer“1IelbaTl233221995.0909.0779.0)O.1(.)23(.)23(789.0.)23(441.rehtoemit69801021231gnikatrevo261.0232.0720.0975.0gnikatrevo700.0350.0830.0109.0gnikatrevo800.0060.0250.0978.0gnikatrevo800.0060.0250.0978.0em-ot-gnidaeh-ralimisem-ot-deeps-ralimisem-fo-edisthgirem-ot-lellarapem-ot-deeps-ralimisem-fo-edistfelem-ot-lellarapem-ot-deeps-ralimisem-fo-edisthgirem-ot-lellarapem-ot-deeps-ralimisem-fo-edistfelem-dnihebem-naht-rewolsem-fo-edistfelem-ot-lellarapem-naht-retsafem-fo-edisthgirem-fo-edistfelem-ot-lellarapem-naht-retsafem-fo-edisthgir $0 a0044 040044 0t0444432189.0.)23(65132779.0)23(.861                                                                                       A'gnikatrevo800.0060.0623.0606.0em-ot-gnidaeh-ralimisem-ot-gnidaeh-ralimisem-naht-retsafem-fo-tnorfniem-naht-rewolsem-fo-edistfelem-dnihebgnikatrevo800.0060.0623.0606.0gnikatrevo800.0160.0993.0235.0gnikatrevo800.0060.0623.0606.0gnikatrevo800.0060.0623.0606.0em-ot-lellarapem-naht-retsafem-fo-tnorfniem-ot-lellarapem-naht-rewolsem-fo-edistfelem-ot-lellarapem-dnihebem-ot-deeps-ralimisem-ot-deeps-ralimisem-ot-lellarapem-fo-tnorfniem-fo-edistfelem-ot-lellarapem-naht-retsafem-fo-tnorfniem-ot-lellarapem-naht-rewolsem-fo-edistfelem-dnihebem-ot-lellarapem-naht-retsafem-ot-lellarapem-naht-rewolsem-fo-edistfelem-fo-tnorfniem-dnihebem-dniheb00 l0 l4l00 l0ll lt l0llll0 l0lll0 l0llllll:000lll0l*0lll0000lll00*0lll000*32779.0)23(.08132779.0)2.3(29132779.0)23(.40232769.0)2.3(61232169.0)2.3(822                                                                          erongiedosipeylekilseulavdoohilekilsetatscitciedjboferstnegahctawsriaplortnocdesab-ksaTnoitatneserpercitcieDnoitceleSemit.ruoivahebgniwollofylekilrofgnikoolmorsftluserehT2 1elbaTtttgnikatrevo261.0232.0720.0975.0gnikatrevo800.0060.0250.0978.0gnikatrevo800.0060.0623.0606.0em-ot-deeps-ralimisem-ot-lellarapem-fo-edisthgirem-ot-lellarapem-ot-deeps-ralimisem-fo-edistfelem-fo-edisthgirem-fo-edistfelem-ot-lellarapem-naht-retsafem-fo-tnorfniem-ot-lellarapem-naht-rewolsem-fo-edistfelem-dniheb0 l+ll000000lllll000 l0lllll0000knueueuqwollofktrevoetatscitcied0s0232ln231995.0909.0779.0587.0069.0)O.1(.)23()23(..)23()23(.6980102123144165132676.0839.0)23(.)23(.861081                                                                 QF53$z:;g2rzerongiedosipeyleki llortnocdesab-ksaTnoitatneserpercitcieDnoitceleSemitdeunitnoc -21elbaTseulavdoohilekilsetatscitciedjboferstnegahctawsriaptgnikatrevo800.0060.0623.0606.0tgnikatrevo800.0060.0623.0606.0em-fo-tnorfniem-naht-retsafem-naht-rewolsem-fo-edistfelem-ot-lellarapem-dnihebem-ot-lellarapem-naht-retsafem-fo-tnorfniem-ot-lellarapem-naht-rewolsem-fo-edistfelem-dnihebem-ot-lellarapllll00000 l0lll000l4llll3000knueueuqwollofktrevoetatscitcied0s02l3H6760.8390.)2.3()2.3(291402325850.1780.)2.3()2.3(612822                                                       R. J. Howarth/ArtiJcial Intelligence 100 (I 998) 5-85 R.J. Howarth/Artl@zial Intelligence 100 (1998) 5-85 5 5 5 Rd. Howarth/Artijicial Intelligence 100 (1998) S-RS R.J. Howarth/Artijcial Intelligence 100 (1998) 5-85 61 62 R.J. Howarth/Artijicial Intelligence 100 (1998) 5-85 Table 13 The kernel results from looking for the giveway episode. agents n l 0 1 1 1 1 time 96 108 120 132 144 156 168 180 192 204 216 228 kernel A v 3 3 3 3 + I I I I I I 1 events and state changes (:EVENT-GW 1) (:STATE-CHANGE-GW2) (:STATE-CHANGE-GW3) ( STATE-CHANGE-GW4) time count used to number from the result the results in the pairing are as calculated cue for mutual-proximity by the DDN. This uses in Tables 11 and 12 shows results the probability measure of how close cover the same sequence as denoted by the camera footage the raster image frames. The format used shows to which objects. The three shapes n , + and l denote cue, so the higher the value the closer together the pairing the agency. The “pairs” as indicated (see Sec- the two from the the objects is. The “agent” column says which attentional the three in the column for each agent marker to). Once (i.e., allocated can then access the results from the model- the deictic states the object’s pose position. This information enables “0” (self), to be calculated and presented under the subheadings s and o from the preattentive column by each LISP dot paired cons cell. The object numbers are buffer-addresses tion 5.1). The “watch” column gives objects preattentive mutual-proximity are and the more interesting markers are allocated agent markers as described says which object the marker matcher and obtain for each the-refubj (other) because The column the episode being observed unknown most likely explanation. The “ignore” column nored so that HIVIS-WATCHER interesting of the probability that following, queueing or some the this pairing should be ig- can check to see if there is anything else that is more and “deictic it is via marker allocation that the positional deictic state has been calculated. behaviour. The “likely episode” column presents state”. The marker shapes are used under is allocated, HIVIS-WATCHER is an instance of overtaking, in Table 3. The numbers (to HIVIS-WATCHER) to its current policy. (i.e., buffer-address) the distribution says whether the headings the marker “likelihood is “on” values” shows values “9 to watch in accordance In Table 13 the time and agents column is as for Tables 11 and 12. The next column, titled “kernel”, described numbers “events shows the allocation of the kernel markers v, A and + which are as the behaviour of the kernel. The the marker to. The in Section 7.3. in Table 3. This part of the table describes (buffer-address) again denote which object relate to those described and state changes” is allocated R. J. Howarth/Artifcial Intelligence 100 (1998) 5-85 63 8.1. Overtaking an overtaking that are performing The purpose of this example is to show that the DDN and TASKNETs to likely overtaking and ignore are also shown can pick out episode. To do this we use the likely following”. The results the selected objects are in the agent columns. The missing entries are because one of the a pair of vehicles TASKNET policy “attend from the frame sequence denoted by the entries vehicles occludes proximate objects are visible which affects the contents of the frame updates because we are dependent upon what is visible from the camera position not what is visible from the overhead view. By frame 132 overtaking frames 96 and 108, so no mutually field-of-view to the observer. Fig. 2 shows the camera’s the other from the camera during in Table 11 where is positively identified. 8.2. Following Alongside these overtaking pictures are those that illustrate to “attend the difference following in agent and ig- the TASKNET policy allocation when we change nore likely overtaking”. Comparing Table 11 with Table 12 shows the effect changing of the same data. When the ignore boolean, TASKNET’s policy has on the interpretation in Table 12, is true, HIVIS-WATCHER to the allo- (in accordance the current watch value (for the attended cation theory given in Section 6.2.1) re-setting object to 0.0, which causes terminates-attention to be removed. in the DDN) the marker likely 8.3. Giveway To illustrate the need for local and global viewpoints we use the policy “look for are given in In the table the giveway detection to the five routines described likely giveway behaviour”. The results from the giveway Table 13 and in the sequence next to those for overtaking HIVIS-WATCHER routine, in Section 7.3. In Figs. 30-31 *agent2* before the motion-prior was altered from moving change-motion-prior! of At frame 120 the vehicle moved again, by the agency operator the motion-prior of the preattentive cue for the the frames 108, 132-156 describe only uses three attentional markers cued by gross-change-in-motion. table correspond which changes and following. implementation the allocation to stationary the events to perform in this listed and Table 14 The problems. Problem surveillance spatial arrangements load computational amount of evidence viewpoint integration temporal history limitation See Section(s) I-10 7.2.1, 1.2 6.2 6.2 6.2, 6.2.2, 6.3, 7.2 6.3, 7.3 64 R. J. Howarth/Artijicial Intelligence 100 (1998) 5-85 Fig. 32. Pact Bl. (see Section 7.1.2). The value of motion-prior the object ceases to have an interesting motion property attended object because has been that generate activation plane for CA Frame 228 shows the removal of *head-marker* successful intersection with CA. Frame 192 shows the results removed). from the contents of the kernel activation planes. Frames 204-258 display is changed by frame 168 (i.e., the agent marker the region path predictions the a following R.J. Howarth/Arti$cial Intelligence 100 (1998) 5-85 65 Fig. 33. Part B2. 8.4. Assessment and ambiguity of interpretation This short example has illustrated how a given surveillance task can affect interpre- tation and that uncertainty is present even after scene objects have been identified. The task-based control developed here has enabled HIVIS- WATCHER in the element of the surveillance problem and its scene. Task-based related in this in Table 14. The solutions developed the situated approach described here, endowing HIVIS- paper have contributed WATCHER with timely to obtain a viable control description of what is happening sub-problems, which are listed towards response is an important task-dependent to each surveillance the task-based task. control model described in Sec- The first two examples demonstrate tion 6.2. Overtaking and following are similar behaviours, and in the implementation R.J. Howarth/Artijcial Intelligence 100 (1998) 5-85 R. J. Howarth/Artificial Intelligence 100 (I 998) 5-85 67 68 R.J. Howarth/Artzjkial Intelligence 100 (1998) S-85 described here, both are identified by the same preattentive and agency are further behaviour the identification the kernel from similar such as when a car pulls out to overtake but then drops back. Thus enabling of likely overtaking by the TASKNET to enable overtaking to be distinguished cue. In [54] integrated The shows for identifying third example that HIVIS-WATCHER can haviour. We have described how the gross-change-in-motion be used as the foundation history of a giveway episode, with demonstrating different model. This example has shown how the local-form to provide a task-dependent this approach are given in [ 541. is able to coordinate scene objects. This the three central how the kernel is in contrast interpretation to be verified. identify preattentive likely giveway be- operator can in the temporal routines of the giveway episode about the collection of information the first and last routines to the local reasoning of the typical-object- can be combined and global-form of the image sequence. Some refinements to It is possible are independent 8.4. I. Doing visual tasks in parallel for HIVIS-WATCHER following behaviour”. This is because gross-change-in-motion and 33 and Table 15 show for following, overtaking we just show the positional deictic states. It is interesting interact causing the flexibility of the kernel that used in Tables 11-13. the detection of giveway behaviour and giveway behaviour the results the preattentive operators for mutual-proximity to “look for both giveway and overtaking and/or and in Appendices B and C. Figs. 32 tasks of looking in parallel. To make the table shorter tasks as described from doing all three visual to see how these visual routines. The format used in Table 15 is a combination of to be slightly delayed, demonstrating 8.4.2. General applicability of this approach that It might also be useful The preattentive cues used in Section 6 can be implemented in the examples here are to illustrate cues may be appropriate are needed. the theory in a working computer program. Other in different applications where different attention- described preattentive calling responses example mutual-proximity domain likely to select stop walking, similarity, members of these clusters also form a network of mutual-proximity might coalesce pass through). to combine preattentive cues, for could be used in an indoor office i.e., they face-to-face, stand still and have a chat. In [54] another Gestalt grouping primitive, in the same direction. The relationships which for a tram to to identify clusters of objects if there is any congestion and gross-change-in-motion two people are talking (such as waiting instances where into a queue travelling is used 84.3. Pei$ormance One of the benefits of task-based control on the number of objects task. This has been demonstrated application and actions of the scene objects, but not on the number of scene objects. The graph in is that the processing done is not dependent in the sequence, but is instead dependent on the given visual in Figs. 30-33 where marker the relationships tasks, and shown surveillance in the examples the different is dependent upon R.J. Howarth/Arti$cial Intelligence 100 (1998) 5-85 69 sequence duration (312 frames at 25 f s’) HIVIS- WATCHER runtime G OFG .x ..2.56s. ,244s .., 2.28 s OFG’ ,, . ., . ., 3..sss, 0 I 5 time in seconds I 10 Fig. 34. Performance than real-time. timings for the different official-observer behaviours, showing that computation is faster Table 16 Which percentage of runtime is spent doing what. Function Top-level-loop Update buffer Run agency peripheral-system Preattentive Attentive Run kernel peripheral-system Allocate agents Build DDN Run DDN Run each agents typical-object-model Collect results Run kernel routines Run effector-system 0 100.0 21.1 34.3 16.0 17.8 31.0 14.1 11.7 8.0 4.2 0.9 F 100.0 21.1 33.0 14.4 18.2 33.0 16.7 12.9 8.6 3.8 0.5 % of total time G 100.0 24.6 14.2 13.4 0.8 14.2 42.5 26.5 9.7 <I.0 3.4 <I.0 OFG 100.0 17.8 14.5 6.5 7.5 10.3 45.0 25.1 14.5 4.9 3.6 3.6 <I.0 G’ 100.0 33.3 18.0 15.3 2.6 18.5 22.8 11.1 5.8 2.1 4.8 <I.0 OFG’ 100.0 19.4 19.4 11.0 8.4 12.3 32.7 17.5 12.6 7.8 4.2 2.9 <I.0 Fig. 34 shows the different durations sequence for the visual (F) or giveway that HIVIS-WATCHER 2o took to process the given (0) or following for overtaking for all three at once (OFG) . The figure looking (G) behaviour and of looking tasks of individually 2” The implementation The timings all used the “real-time” seven runs. used here was written in Allegro Common Lisp version 4.2 and running on a Spare 20. from time and were averaged the LISP function value returned from 70 R.J. Howarth/Artijicial Intelligence 100 (1998) 5-85 Table 17 The number of model-matches. in this table are from the twenty seven frames used here not the full 312 frame sequence, but they give an idea of the proportions The numbers involved. Input data and Attentional behaviours compact encoding stream 0 F G OFG number of model-matches 106 38 31 20 57 frame, frames twelfth (GUM) is created in this instance, it should be noted and mutual-proximity In the genera1 case the preattentive for each scene object, and a MP network is less than the real-time that we only spaced in Fig. 34 and Table 16 show the various intervals. The results cue for gross-change-in-motion operator also shows that the processing performed by HIVIS-WATCHER duration of the image sequence used here. Although process every i.e., there are twenty-nine at roughly half second costs of the preattentive (MP). where a GCIM network created for those object pairs that have a mutual-proximity shown by the values networks can be greatly reduced as shown by the values for G’ and OFG’. Illustrating of using knowledge where to look). As shown is applied over the whole scene, is only relationship. The results are the use of GCIM (see Fig. 4 the GCIM overhead the benefits (i.e., knowing included In the table a count of the number of model-matches made the cost of model-matching. for the frames shown is given together with those identified as being necessary by the attachment of an attentional marker for the various behaviours used in this paper. The values task can be fulfilled with minima1 resources. in Table 17 the differences would be more marked in this table illustrate how a given surveillance for 0, F, G and OFG. However, by limiting in the 312 frame sequence that are in giveway/turning to guide preattentive if the timings processing the scene to objects regions about 9. Related work We have already covered some related work in Section 5, particularly is a bias representation the foundation by Agre and Chapman deictic description of active vision. We also provided split that provides there there are a number of alternative [ 521, Nilsson’s Teleo-Reactive based approach example. towards Agre and Chapman’s approaches condition-action [ 701, and Rosenschein and related the background issues from Ballard’s to the peripheral/central the use of [6] for the situated approach developed here. Although here, of the central-system description such as Horswill’s Prolog-like mechanism [ 831, Mackworth’s constraint- rules and Kaelbling’s situated automata [90], for R. J. Howarth /A rtijicial Intelligence 100 (I 998) 5-85 71 This separation of input- and central-system (i.e., runtime execution cycles or oscillates) between and the feedback provided by the tight these two systems allows (see Allen traditional planning or plan recognition a common is not idea in control [83] has pointed out that this may in part be due to how we or planning. When we step back and consider a temporal [74]) from the side (as described by McDermott however, when we perform or act upon a plan, theory, feedback nature of program execution, but it could also be related temporal reasoning its past, present and future, coupling us to address control without using for example). Although et al. [4] in AI systems. Nilsson often used to the sequential perform history, the idea of feedback seems incongruous, “execution” our real-world feedback with the world. is in continuous The temporal representation we employ uses a deictic approach, uncommon tend representations [74]) because to use a time Temporal McDermott which time-maps here and have instead adopted a simple model of time. events (see Dean and McDermott they are reasoning for predicting is useful line and “reason about symbolic from time points [47]) (see Hanks and McDermott [ 321). We do not use such temporal the side” in AI. (see (e.g., dates) and building reasoning to model construction the dynamic and Goldman The application [ 261)) but the result iteration of the NE1 algorithm described of Bayesian networks used in HIVIS-WATCHER temporal is novel and, although we only use simple graphs they make clear the general of Bayesian networks (see is a single static network, in Appendix A. Other is rea- time state or time-slice to a single the time-slices holding a value time-slices. They call this into a single root node properties approach. Related work includes [ 151, Charniak Breese like a single rather researchers have investigated soning over time. Sometimes might not be needed making node, Sucar and Gillies use of relationship that describes how each property changes between successive “dynamic for each recognised object. domains where a complete model of the previous it possible [95] call this “semi-static the world changes and the focus that sit on the boundary between recognition”. They also describe the relevant history results are collected the temporal recognition” to simplify because nodes [82]) have investigated A few researchers (see Dagum et al. [ 301, Dean et al. [ 3 I], Kiaerulff dynamic networks [ 621, Nicholson that have a repeated structure, and Brady the state of each domain variable at different where, as the network grows over time, times is represented by a series of nodes that has a limit on the history maintained (i.e., a window of time-slices). Like the DDN developed here, they obey the Markov property that the future of the past given is conditionally the present. independent proof that task-based HIVIS-WATCHER is more an engineering based on known psychophysical control evidence. Chapman of SONJA, and most of the experimental the work described here. Other psychophysical than being an implementation makes both cases for his implementation he references can also be used to support [ 1061 some of which experiments that [5] suggests provide general form of fo- selection in close cusing. And van der Heijden cooperation and is controlled by both the subject and the world. Some researchers are more concerned with biologically plausi- [ 51 and van der Heijden control. For instance Allport is feasible [ 25 ] data and interaction with expectations are described by Allport is based on goal-directed a task/action-specific [ 1061 emphasizes action, providing and intentions, for task-based that selection is performed support 12 R. J. Howarth/Artijicial Intelligence 100 (1998) 5-85 that task requirements locations when subsequent [ 761. Tsotsos et al. [ 103, p. 5371 suggest spatial working memory of what has been seen may play a role and have developed connectionist models. For example, van der Heijden [9] and some in eye movement brings pre- to the seems similar grid described provides this ble approaches describes “SLAM” his SeLective Attention Model. Also see Baluja and Pomerleau and Mozer kind of internal to re-attend determining whether viously attended objects back into view. This identified description of task-based in Sections 4 and 5.2.3. Van der Heijden also identifies temporal order or temporal has more probably between the functionality der Heijden’s description of the time course of activation identity which seems to where the Gestalt process provided by the DDN as part of preattentive selection and van to from location to do with marker manipulation, in Section 6 and the global-form there may be a correspondence structured visual world. While that selective-attention is most likely to take place. control given in a spatially for mapping requirement structure 10. Conclusion to limit represents (such its a theory of task-based control an advance over more traditional AI approaches due to its greater expressive power and its ability HIVIS-WATCHER as HIVIS-MONITOR) inference according of a scene has to take into account observer’s knowledge about what integrating typical object behaviour is the preattentive/attentive preattentive (simple) In the implementation which has been used to model the spatio-temporal and a static level of control and a collection of rules that describe Together distributed under to the demands of the task at hand. We have shown that interpretation the dynamic nature of the world and also the official- in the world. Doing so involves typically happens (see Section 6) with a theory of representing (see Section 5.3.1). The main concept behind task-based control reasoning. The operators are illustrative only. form of Bayesian network information, in the form of both an evidence gathering Bayesian network routine visual behaviour of the official-observer. these promise a highly effective attentional developed here, we use a dynamic to deliver real-time performance. control mechanism which can be evolution of preattentive processing of attentive operators and attentive the agent formalism split or sequential (complex) Other benefits of HIVIS-WATCHER reducing ( 1) the deictic runtime representation, representation the situated approach has taken scene objects and also the task-oriented over HIVIS-MONITOR reasoning has simplified are due to its task In HIVIS- and complexity. the computational model of into account both the evolving context the use observer’s context, (3) orientedness WATCHER: behaviour, (2) of the dynamic of selective-attention provides a more viable form of real-time processing. Other key points of this paper concern: l The distinction between script-based l The separation and integration of global and local reasoning and more situated approaches. in the context of a sin- together with the illustration of how both play complementary gle official-observer, roles in developing different of reasoning l The propagation levels of understanding. in the “here-and-now” in order to reflect the reactive quality of dynamic object behaviour. through to the control mech- anism R.J. Howarth/Artificial Intelligence 100 (1998) 5-85 13 the research And although traffic surveillance applicable application, to other application domains. in this paper has been illustrated by using data from a road- should be is that the general the intention framework two important is addressing issues. The first concerns illustrated the PC and SAC/HIVIS, between tightly coupled. The result of this will enable the in Fig. 1, and mak- task-based the HIVIS removing Current work interface strong ing them more control component to directly attentive process of working out what an object carried out when a marker tentially be considered tem. task relevant influence as a prototype of this more complete is applied to what the preattentive interesting object. The current version of HIVIS-WATCHER the visual data-collection is (e.g., model-matching), process, so that the is only cue identifies as a po- can sys- computer-vision attentional The second concerns learning element of choosing preattentive Acknowledgements the behavioural and attentive cues in HIVIS-WATCHER. information, removing the hand coded I would discussions also thank Mike Brady, Duncan Gillies and the anonymous like to thank Hilary Buxton, Mike Clarke and Dave Saunders and guidance the work described that contributed reviewers. towards for helpful in this paper. I This work has been funded by SERC under a CASE award with the GEC Marconi Re- search Centre and by the EPSRC project “Behavioural Analysis using Bayesian networks” (grant GR/K08772). for Visual Surveillance I thank Annette Herskovits for giving me permission to base Fig. 13 on Figs. 10.2 and 10.3 from pp. 158-159 of her book [50]. I also thank Margaret Fleck for giving me permission to base Fig. 6 on Fig. 11 from p. 83 of [ 351 and on Fig. 16 from p. 21 of [37], copyright 1996, with kind permission of Elsevier Science, Sara Burgerhartstraat 25, 1055 KV Amsterdam, The Netherlands. Parts of the work described here have appeared [ 551. [58] and [59] and the survey paper papers in earlier forms in the conference illustration The in-line in Section 7.1 .l is reprinted from Fig. 2 of [58], Table 4 includes from [SS], Fig. 23 is based on Fig. 1 of [58], Fig. 24 is reprinted the entries from Table 1 of [58], part of Table 5 is from Table 2 of [58], and part of Table 7 is from Table 3 of [ 581. These are from tional Conference Intelligence, on Artificial Intelligence, (http: / / www.mkp.com) Fig. 2 is reprinted Interna- Joint Conferences Inc., 1993. Reprinted with permission. Morgan Kaufmann of the Thirteenth the Proceedings frames used in Figs. 30-31 are reprinted from Fig. 1 of [59], Table 1 is based on Table 1 of [59], and from Figs. 2, 3 and 4 of from and are used with permission some of the result [ 591. These are copyright 1996 by Springer-Verlag Springer-Verlag, Heidelberg, Germany. on Artificial International copyright . Fig. 12 is reprinted Fig. 29 is based on Fig. 8 of [55]. These are used with kind permission Academic Publishers. from Fig. 3 of [55], Fig. 22 is based on Fig. 9 of [55], and from Kluwer 74 R.J. Howorth/Arti$cial Intelligence 100 (1998) 5-85 (1) (2) run update-graph-structure update prior values of root nodes and supply evidence node values to run inference-algorithm (3) update beliefs Fig. A. 1. The Network Expansion and Inference (NEI) algorithm. Appendix A. A probabilistic dynamic graph representation The Dynamic Decision Network preattentive prominent each clock tick to mirror the information run the Network Expansion model continuous the graph structure graph approach overheads different continuous multiply connected). causal polytree. of the update-graph-structure form of Bayesian network or changing), (DDN) to identify used by ALLOCATE features consists of a dynamic graph structure the most that is updated at in the new image frame. To do this we (NEI) algorithm given in Fig. A. 1. It cannot time because If is constant over time a better solution would be the more usual static (as described by Pearl [ 851) , because using a DDN incurs the additional the process of graph extension in necessarily discrete. and Inference contained step. We can distinguish in two distinct ways: topological between the structure (either tree, causal polytree or and graph structure (one of: causal The Bayesian network described here is a topologically changing A. 1. Connection rules To express manipulations rules and are needed “MACDDN” 2’ which uses construction structures. These connection now, next, previous), graph which would of connection two forms “now-connections” The NOWCs adjacent invalidate rules determine time values. link nodes to constrain rules are very local, use a deictic model of time to the DDN graph structure we develop a language called the set of possible graph (i.e., the inference algorithm. The set in the graph and consist of (OSTC) . link nodes with to ensure the use of a causal polytree the validity of each edge that loops are not formed within and “one-step-temporal-connections” time value, and OSTCs (NOWC) that share the current a is an attribute Each node owner symbol, important, node’s position within hold all the nodes for a particular defining is defined by a tuple (n, o, a, b) where n is a node type symbol, o is an is in the that this idea, with OSTCs the graph. Time is modelled as subgraphs, called “buckets”, the links that can be made between nodes in adjacent buckets. it is not expressed explicitly as part of each node, instead symbol, and b is a belief symbol. Although time-cell. Fig. A.2 illustrates it is implicit time *’ MACDDN LISP macros stands (giving a macrology) -- that specify how to construct a DDN. for MACro DDN because the rule language has been implemented as a collection of R. J. Howurth/ArtiJicial InteNigence 100 (1998) 5-85 Fig. A.2. The time-cell as a bucket holding a set of nodes that rewrites is defined, and nf the type, owner and attribute symbols For graph construction we use a more compact notation (n, o, a, b) as nz in the case where as attribute if not, where 4 acts as a wild card. This notation hides the belief value because and makes explicit rules operate in the DDN, using upon. This part of the language the syntax: NT is the set of node type symbols, OVI is the set of owner symbols, 0V2 is is the set of owner symbols the powerset of OVl, VT is the set of node tuples, and OVla extended by the wild card, tuple nt E VT, we have n E NT, o E OV2, and a E OVl& it is not used during graph construction, that the construction is used to express the vertices present i.e., OVla = OVI U (4). In each node and ostc says whether tests: nowc(p) (p, q) says whether the node p is present We use three predicate nowc(p A q) says whether both nodes p and q are present in the in the bucket bucket for t,,,; for t,,,; the nodes p and q are in the consecutive buckets under consideration. Buckets are held in an indexable data structure, and at the end of so that what was each system-cycle, is given held at ti in [54] however, tests on the node tuples held in the bucket structure. is now held at ti-1. A more concrete semantics that we use to perform for these predicates the functionality this has given reallocation) (by pointer the storage is “moved” A.2. Construction algorithm The MACDDN language uses the following notation.22 To add an edge we use the of type VT -+ infix operator + called “add directed edge”, VT 4 DDNG ---f DDNG, that updates the DDN graph of type DDNG. To make the notation less cluttered we will hide the DDNG parameter so that we only need to specify first two the node arguments of ( +). For example, we will write p+q tuples p and q where p, q E VT. to adding edges, to add an edge between that is a function the MACDDN In addition also needs ( +) adding a new node. This is done using which creates a node tuple with a wild card attribute type NT --+ 0V2 --) VT); and add-vertex(DDNG, now we will hide the DDNG parameter and define it as add-vertex(p), (i.e., make-node NODE) which adds a node tuple language two functions: make-node functionality for (NODE-TYPE, NAME) is a function of (for where p E VT). language we will use together with additional To describe the constructor macros used the notation that are written using in the MACDDN above, introduced templates 22 An introductory functionality is given by Bird and Wadler [ 12, pp. 8-121. explanation of the type notation used here (including “currying”) to describe the MACDDN 76 R.J. Howarth/Artijicial Intelligence 100 (1998) 5-85 for tests (if antecedent do consequent od) and value assignment (denoted by syntax the := symbol). 0 now-ref (p) = if nowc (p) do o := node-owner(p) r := make-node(R, o) ; add-vertex(r); ; p+r od this adds a result node to the graph so that the output from the belief slot can be translated to a more useful form. l now-relationship(p, q) = if nowc(p A q) do o := {node-owner(p), r := make-node add-vertex(r); (R, o) ; p+r; node-owner(q)} ; q-+r od this combines and is used as part of the solution the results from two nodes denoting some relationship between them, to the spatial arrangements problem. l temporal-change(p, this temporally q) = if ostc(p, links nodes that are of different q> do p+q od types, but the same owner. l temporal-continuity(p) links nodes = if ostc(p, that are the same p) do p+p od in terms of the type, owner and rules express that are denoted by the set of edge-destinations the essential details but do not describe how the are made, for this we first need a description of the DDN graph structure separated buckets. Each bucket has a set of vertex-indexes V and connections in terms of temporally edges ES. ED and ES are subsets of the set of graph indexes GI, such that each graph index is they also refer to the relative defined so that in addition time, e.g., relative to the vertex-index if g E GI, h E H, u E V then g = (h, o) where h is a deictic-time-index ED and the set of edge-sources to referring to t,,,. Denoting edges with edge-destinations links between buckets. In the examples a general definition is: and edge-sources the in this paper we use only three buckets, however, enables us to describe Definition 11. A DDN graph DDNG = (TS, {sgl, . . . , sg,}) where TS is a list of bucket- status. Each bucket sg; = (vi, es;, edi) indexes ordered temporal where Vi C V are sgi’s vertices, esi C GI are sg;‘s edge-sources, and ed; 2 GI are sgi’s edge-destinations. their current to reflect this temporally attribute slots. The construction functions which need of directed edges decomposes This definition two distinct areadd-edge-destination(DDNG, NODE, FROM-NODE), they both operate on graph-indexes GI +DDNG. to be executed the meaning of the ( +) to add an edge. These function into functions NODE, TO-NODE)andadd-edge-source(DDNG, and are of type DDNG -+ GI --f We have now described the macro elements used to specify is done before runtime the given predicate rules. that is able to link tests. LISP macros were used to simply common to provide a function the construction The macro expansion nodes functionality that match and enable the specification of similar DDN functions. R.J. Howarth/Artijicial Intelligence 100 (1998) S-85 77 __________________._........._..............~.~~.........~~.....~...................~~,, update DDNG 1 update - update node tuple belief slots Y-- run infsrence- algorithm Fig. A.3. A break down of the various forms of DDN graph and Bayesian network used to perform one complete update to the DDN. A.3. Graph properties The complexity of the graph is related that has no temporal history the length of history, also increases over. A graph Increasing the number of nodes, n, at time ti-1 increase Neapolitan arbitrary is linear with respect DDN scales well with respect singly connected network, is the same as at time ti to the length of temporal history just reasons about the current the size of the graph. If we assume reasoned time value. that then we have a linear i.e., 0( n x h) . that in the case of an for the update of all variables that the the time requirement in the number of nodes as the length of history, h, in increased, to the number of variables in the network. This means [79, p. 2491 (also see Pearl [ 85, p. 1741) describes All the MACDDN to the length of temporal history. construction macros, except now-relationship, generates an O(n logn) algorithms. now-relationship have a Cartesian product of p and q, and can ignore means O(nlogn). of all the links between the generation that generate O(n) algorithm, the symmetric this is because we component. This is in the DDN graph the nodes We can ensure The number of nodes in the DDN at time t, is determined by the results from the preattentive operators, which are themselves dependent on the number of scene objects. if ( 1) we that share the current that no loop is formed by the directed edges added by the OSTCs. is a static test that can be restrict the DDN graphs to tree-like forms. only allow non-temporal time value, and (2) The first part is present performed prior to runtime. These constraints that no loops are formed connections in the use of NOWCs. The second in the DDN graph at runtime to be made between nodes A.4. Updating algorithm Updating the DDNG takes three stages as described in the NE1 algorithm given in Fig. A.1 and this is also shown, in more detail, in Fig. A.3. 78 R. J. Howurth/Artijicial Infelligence 100 (1998) 5-85 Table B. I Mutual-proximity MACDDN construction rules. Constructor macro now-connections (Vx, y E ABSi, now-relationship(N;Xj, Niy) )) one-step-temporal-connections (Vx E ABSi, temporal-continuity(N*,))) (Vs E ABSP, temporal-continuity(R, b )) Pattern running defined the connection and node-linking It consists of two components rules and is called update-graph- language in the MACDDN that are used to describe which node The first stage involves structure. called node-building tuples are to be created and how they are to be connected. an equivalent Bayesian network, and then The second stage involves constructing probability matrix for each the appropriate conditional setting processor node in the Bayesian network. The belief slots from the DDNG node tuples provide In the third stage the inference update the initial values for the root nodes in the Bayesian network. the belief values of selected result nodes is run, with the results from this used to it up by identifying in the DDNG. algorithm The second stage is really redundant and it would be much more efficient inference were applyed directly Bayesian network afresh for each execution approach prove to be a useful that can make local changes technique to Bayesian network for updating network structure. to the DDNG, so removing cycle. Chang and Fung the need if Bayesian for creating the [22] describe an topology and which might Appendix B. Mutual-proximity graph graph is specified The form of the mutual-proximity in Table B.l which uses the node in Table 4. We will also use the variables x and y to denote (i.e., x # y) in the MACDDN constructor now-relationship active buffer-addresses, with ABSl 2 OVI and ABS2 being types N and R introduced any two distinct objects where they are used to define the attribute symbol of the node tuple. In Table B.l, ABS the stands for the currently in Table B.l powerset of ABSI such that ABS2 G 0V2. From the MACDDN specification and node-linking we generate used function generates all the in the NE1 algorithm nodes which are then linked function. Part of the node-linking function of the NOWC MACDDN For more details see [ 541. is shown in Fig. B.l by the example expansion, rule mutual-proximity-relationship that perform node-building (see Section A.4). The node-building into a graph by the node-linking shown in Table B. 1. the two functions in pseudo-code, The DDN itself does not hold an overall picture of what the creation of a fuller picture we use a separate Bayesian network called TASKNET which is described in Sections 7.2 and Appendix D. is happening. For R.J. Howarth/Artifcial Intelligence 100 (1998) 5-85 79 procedure mutual-proximity-relationship(SG,,”, and and = “nearest”) = “nearest”) if (node-type(A) (node-type(B) (node-owner(A) = reversecnode-owner(B))) do A, B) node-owner(A)) (now, R) (now, A) B) let R be make-node(“mutual-proximity”, let RGI be make-graph-index let AGI be make-graph-index let BGI be make-graph-index(now, add-vertex add-edge-source(SG,,. add-edge-destination(SG,,,, add-edge-source add-edge-destination(EX&,, od (SG,,, , R) (St&,, , RGI , BGI) , RGI , AGI) AGI, RGI) BGI, RGI) Fig. B.1. An example proximity-relationship expansion which of the now-relationship is part of the node-linking constructor macro for the mutual- function. Table C.1 Gross-change-in-motion addresses, with ABSl C OVl. MACDDN construction rules. Note that ABS stands for the currently active buffer- Pattern Constructor macro now-connections (Vx E ABSI, now-ref (Vx E ABS1, now-ref (PS+x))) k (PMfX))) one-step-temporal-connections (tix E ABSI, temporal-continuity(R* (Vx E ABSl, temporal-continuity(PS (Vx E ABSI, temporal-change(PS* )) )) ‘2 2 ,PM k} )) g} (Vx E ABSl, temporal-change(PMiX),PS(xl)) (VX E ABSI, temporal-continuity(PMt))) Appendix C. Gross change in motion To define gross-change-in-motion rules shown construction R, which stand for motion-prior result. The R node is present the result of running for mutual-proximity The NOWC rules combine in Table C.l. These rules use three node value as a preattentive cue we specify the set of MACDDN types PS, PM, and value is moving, and that represents of those This set of rules is independent is stationary, motion-prior ignore} to hold the belief value for {watch, the inference-algorithm. and their use changes the behaviour of the system. of this object and the node type reflects the current and previous values denoting the motion-prior of the object. When an object the interestingness 80 R. J. Howarth/Artijcial Intelligence I00 (I 998) 5-85 Fig. C. 1. A sequence of graph examples to illustrate how gross-change-in-motion affects the allocation of PM and PS nodes. is stationary is used and when an object a PS node the sequence of graphs shown is moving a PM node illustrate how these rules operate consider where an object changes the figure are the frame (i.e., time-cell is used. To in Fig. C.l the top of the contents of the contents the t,,, of the tnow+ time-cell. the figure also shows the nodes that are in these buckets and the links between and inside each bucket. Notice how the contents of the ti now bucket become the ti-1’s prev bucket, and that to conform the links are changed from moving time-cells, with the two buckets now holding the time of the current to the two buckets for now and prev, frame) and prev holding to moving again. Along to the connection to stationary In addition rules. Appendix D. TASJCNET, the DDN and allocate As described in Section 7.2.2 each identified pair of buffer-addresses (i, j) is given a distinct TASKNET, denoted TASKNET(i,j,. Also the buffer-addresses are used mechanism, component’s in the DDN as owner symbols by the node and their pairings (see Appendix A). The the three stages of the ALLOCATE that manages allocation theory given in Section 6.2.1. the TASKNETs, reflects tuples the root nodes and runs the inference algo- the TASKNET is initialised that an agent marker information stage ensures stage updates that on allocation related to the pair, and then ensures The focus-of-attention and collecting is running on both selected objects. The selective-attention rithm. When an uninteresting held in the pair’s current DDN reference node. On the next clock DDN is updated and the inference algorithm a high will ensure that, unless a potentially the relationship will be ignored. This high ignore causing both the allocated agents and TASKNET achieving is recognised, we first instantiate the terminate-attention to be terminated interesting is placed indicator situation ignore stage. value the belief value tick when the is still present, in the reference node at what is now tnov-1. This run, if the relationship is present at time t,,,, value is temporally propagated, for the pair. Thus this method, once a relationship Using watched. is identified it can be ignored or continue to be R.J. Howarth/Art$cial Intelligence 100 (1998) 5-85 81 References [ I ] P.E. Agre, The dynamic structure of everyday life, Ph.D. Thesis, MIT AI Lab., AI-TR 1085, Cambridge, MA, 1988. [ 21 P.E. Agre, D. Chapman, Pengi: an implementation of a theory of activity, in: Proceedings AAAI-87. Seattle, WA, 1987, pp. 268-272. [3] J.F. Allen, Towards a general theory of action and time, Artificial 141 J.F. Allen, H.A. Kautz, R.N. Pelavin, J.D. Tenenberg, Reasoning Intelligence 23 ( 1984) 123-154. about Plans, Morgan Kaufman, Los Altos, CA, 1991. [ 5 1 A. Allport, Visual attention, in: M.I. Posner (Ed.), Foundations of Cognitive Science, MIT Press, Cambridge, MA, 1989, pp. 631-682. [ 61 D.H. Ballard, Animate vision, Artificial [ 71 D.H. Ballard, CM. Brown, Computer Vision, Prentice-Hall, Englewood Cliffs, NJ, 1982. ]S] D.H. Ballard, M.M. Hayhoe, Feng Li, SD. Whitehead, Hand-eye coordination Intelligence 48 (1991) 57-86. tasks, (Eds.), Natural and Artificial Low-level Issue), Philos. Trans. Roy. Sot. London Ser. B: Biological Sci. 337 ( 1992) J.P. Frisby, M.A. Jeeves during sequential in: G.A. Horridge, H.B. Barlow, Seeing Systems 331-339. (Special [9 ] S. Baluja, D.A. Pomerleau, Using the representation in a neural network’s hidden layer for task-specific focus of attention, in: Proceedings 1 lo] A. Baumberg, D. Hogg, Learning IJCAI-95, Montreal, Que., 1995, pp. 133-139. flexible models (Ed.), 3rd ECCV Conference, Stockholm, Sweden, Vol. I, Lecture Notes in Computer Science, in: J.-O. Eklundh image sequences, from Proceedings Vol. 800, Springer, Berlin, 1994, pp. 299-308. [ 1 I] D.C. Beardslee, M. Wertheimer, Readings [ 121 R. Bird, P. Wadler, Introduction [ 131 S.S. Blackman, Multiple-Target Tracking with Radar Applications, Artech House, 1986. [ 141 R.D. Boyle, R.C. Thomas, Computer Vision: A First Course, Blackwell, Oxford, 1988. [ 151 J.S. Breese, Construction [ 161 R.A. Brooks, A robust of belief and decision networks, Comput. in Perception, Van Nostrand, New York, 1958. to Functional Programming, layered control system Intell. 8 (4) ( 1992) 624-647. for a mobile robot, IEEE J.. Robotics and Automation Prentice-Hall, Englewood Cliffs, NJ, 1988. 2 (I) (1986) 1 171 R.A. Brooks, 595. 14-23. Intelligence without reason, in: Proceedings IJCAI-91, Sydney, Australia, 1991, pp. S69- 1 181 K. Bilhler, The deictic field of language and deictic words, in: R.J. Jarvella, W. Klein (Eds.), Speech, in Deixis and Related Topics John Wiley and Sons, New York, 1982, Place, and Action: Studies (abridged pp. 9-30 translation of: Sprachtheorie, Fischer, Jena, 1934). ] 191 H. Buxton, D.R. CorralI, R. Godden, R. Howarth, 2. Hussain, M. Popovich, C.K. Sung, J. Thorn&e, in: A.F. Toal, G. Sullivan, A. Worrall, VIEWS: Visual Inspection and Evaluation of Wide-area Scenes, IJCAI-91 Videotape Program, Morgan Kaufmann, Los Altos, CA, 1991 (ISBN 155860-183-X). 1201 H. Buxton, S.G. Gong, Visual surveillance in a dynamic and uncertain world, Artificial Intelligence 78 (1995) 371405. I21 ] S. Cameron, Collision detection by four dimensional intersection testing, IEEE Trans. Robotics and Automation (1990) 291-302. 6 (3) 1221 K.-C. Chang, R. Fung, Refinement Henrion, L.N. Kanal, J.F. Lemmer Amsterdam, 1991, pp. 435-445. and coarsening (Eds.), Uncertainty of Bayesian networks. in Artificial Intelligence, Vol. 6 North-Holland, in: P.P. Bonissone, M. [23 I D. Chapman, Planning ]24] D. Chapman, Penguins can make cake, AI Magazine 10 (4) (1989) 45-50. 1251 D. Chapman, Vision, Instruction and Action, MIT Press, Cambridge, MA, 1991. [26] E. Chamiak, R.P. Goldman, A probabilistic model of plan recognition, for conjunctive goals, Artificial Intelligence 32 (1987) 333-377. in: Proceedings AAAI-91, Anaheim, CA, 1991, pp. 160-165. I271 A.N. Clark, Pattern recognition of noisy sequences of behavioural events using functional combinators, Comput. J. 37 (1994) 385-398. ]28] D.R. Corrall, A.N. Clark, A.G. Hill, Airside ground movements Intelligence on Machine in Air Traffic Management, Berlin, Germany, surveillance, in: NATO AGARD 1993, pp. 29:1- Symposium 29:13. 82 R.J. Howarth/Artijcial Intelligence 100 (1998) 5-85 [ 291 D.R. Corrall, A.G. Hill, Visual surveillance, GEC Review 8 (1992) 15-27 [ 301 P. Dagum, A. Galper, E. Horvitz, Dynamic network models for forecasting, in: Uncertainty in Artificial Intelligence, Vol. 8, Morgan Kaufman, Los Altos, CA, 1992, pp. 41-48. [ 3 11 T. Dean, T. Camus, J. Kirman, Sequential decision making for active perception, in: Proceedings Image Understanding Workshop, Pittsburgh, PA, 1990, pp. 889-894. I32 1 T.L. Dean, D.V. McDermott, Temporal data base management, Artificial 1331 Li Du, G.D. Sullivan, K.B. Baker, Quantitative analysis of the viewpoint Intelligence 32 ( 1987) l-55. consistency constraint in model-based vision, in: Proceedings 4th International Conference on Computer Vision, Berlin, Germany, 1993, pp. 632-639. [ 341 M.A. Fischler, 0. Firschein (Eds.), Readings in Computer Vision: Issues, Problems, Principles, and Paradigms, Morgan Kaufman, Los Altos, CA, 1987. 1351 M.M. Fleck, Boundaries and topological algorithms, Ph.D. Thesis, MIT AI Lab., AI-TR 1065, Cambridge, MA, 1988. [36] M.M. Fleck, Representing space for practical reasoning, Image and Vision Computing 6 (2) ( 1988) 75-86. [ 371 M.M. Fleck, The topology of boundaries, Artificial [ 38 1 J.A. Fodor, The Modularity of Mind: An Essay on Faculty Psychology, Press, Cambridge, MA, 1983. (1992) 376- 1391 R.A. Frost, Constructing programs as executable attribute grammars, Comput. J. 35 (4) Intelligence 80 ( 1996) l-27. 387. 1401 KS. Fu, Syntactic Methods 1411 H. Garfinkel, Studies (421 E. Geake, Camera keeps an eye on airport vehicles, New Scientist 136 ( 1850) ( 1992) 21. 143 I J.J. Gibson, The Ecological Approach [ 441 J.J. Gibson, L.E. Crooks, A theoretical in Pattern Recognition, Academic Press, New York, 1974. Prentice-Hall, Englewood Cliffs, NJ, 1967. of automobile-driving, in Ethnomethodology, to Visual Perception, Houghton Mifflin, Boston, MA, 1979. in: E. Reed, R. Jones for Realism: Selected Essays of James J. Gibson, Lawrence Erlbaum Associates, field-analysis (Eds.), Reasons London, 1982, pp. 119-136; also in: Amer. J. Psychology 51 (1938) 453-471. [45] S.G. Gong, H. Buxton, Bayesian nets for mapping contextual knowledge to computational constraints in motion segmentation Surrey, UK, BMVA Press, 1993, pp. 229-238. and tracking, in: Proceedings 4th British Machine Vision Conference, Guildford, 1461 I.E. Gordon, Theories of Visual Perception, 1471 S. Hanks, D. McDermott, Modeling John Wiley and Sons, New York, 1989. I: symbolic and uncertain world and probabilistic reasoning about change, Artificial a dynamic Intelligence 66 (1) (1994) l-55. 1481 P. Hayes, The second naive physics manifesto, in: J.R. Hobbs, R.C. Moore (Eds.), Formal Theories of the Commonsense World, Ablex, Norwood, NJ, 1985, pp. l-36. 149 J J. Heritage, Garfinkel and Ethnomethodology, 1501 A. Herskovits, Language Polity Press, Cambridge, UK, 1984. and Spatial Cognition: An Interdisciplinary Study of the Prepositions in English, Cambridge University Press, Cambridge, UK, 1986. [ 5 I 1 B.K.P. Horn, Robot Vision, MIT Press, Cambridge, MA, 1986. [ 521 I. Horswill, Visual routines and visual search: a real-time implementation and an automata-theoretic analysis, in: Proceedings I53 I R.J. Howarth, MACNET: a language IJCAI-95, Montreal, Que., 1995, pp. 56-62. for situated AI systems, Technical Report 684, Queen Mary and Westfield College, London, 1994. 1541 R.J. Howarth, Spatial representation, reasoning and control for a surveillance system, Ph.D. Thesis, Queen Mary and Westfield College, University of London, 1994. a dynamic 155 I R.J. Howarth, Review 9 (I) Interpreting (1995) 37-63. and uncertain world: high-level vision, Artificial Intelligence representation of space and time, Image and Vision Computing 1561 R.J. Howarth, H. Buxton, An analogical (1992) 467478. ( 57 I R.J. Howarth, H. Buxton, Analogical 10 (7) in: B. Neumann pp. 785-789. traffic behaviour, (Ed.), Proceedings ECAI-92, Vienna, Austria, John Wiley and Sons, New York, 1992, of spatial events for understanding representation (581 R.J. Howarth, H. Buxton, Selective attention in dynamic vision, in: Proceedings IJCAI-93, Chambtry, France, 1993, pp. 1579-1584. R.J. Howarth/Artifcial Intelligence 100 (1998) 5-85 83 [ 591 R.J. Howarth, H. Buxton, Visual surveillance monitoring in: B. Buxton, R. Cipolla 4th European Conference on Computer Vision, Cambridge, UK, Vol. II, Lecture and watching, (Eds.), Proceedings Notes in Computer Science, Vol. 1065, Springer, Berlin, 1996, pp. 321-334. [60] R.J. Howarth, H. Buxton, Attentional control for visual surveillance, India, IEEE Press, New York, 1998, pp. 86-93 in: S. Maybank, T. Tan (Eds.), (held IEEE Workshop on Visual Surveillance, Bombay, at ICCV-98). [ 61 1 E. Hutchins, Understanding Micronesian navigation, in: G. Dedre, A.L. Stevens (Eds.), Mental Models, Lawrence Erlbaum Associates, London, 1983, pp. 191-225. [62 1 U. Kiaerulff, A computational in Artificial in dynamic probabilistic networks, Intelligence, Vol. 8, Morgan Kaufman, Los Altos, CA, 1992, pp. 121-129. scheme for reasoning in: Uncertainty [ 63) J.H. Kim, J. Pearl, A computational model for causal and diagnostic reasoning in inference systems, in: Proceedings IJCAI-83, Karlsruhe, Germany, 1983, pp. 190-193. I64 ] S. King, S. Motet, J. Thorn&e, F. Arlabosse, A visual surveillance in: 1993 AAAI Workshop on AI in Intelligent Vehicle Highway Systems, AAAI Press, Menlo Park, CA, 1994, pp. 30-36. for incident detection, system 1651 C. Koch, S. Ullman, Shifts in selective visual attention: 4 ( 1985) 2 19-227. Neurobiology towards the underlying neural circuity, Human [66] J.J. Koenderink, Solid Shape, MIT Press, Cambridge, MA, 1990. 167) S.M. Kosslyn, R.A. Flynn, J.B. Amsterdam, G. Wang, Components analysis and accounts of neurological Sci. 1 (3) neuroscience syndromes, Cognition 34 ( 1990) 203-277. (1990) 156-162. 1681 D.L. LaBerge, Attention, Psychological [69] J.-C. Latombe, Robot Motion Planning, Kluwer Academic Publishers, Dordrecht, 1991. [ 701 A.K. Mackworth, Quick and clean: constraint-based IEEE International Conference on Image Processing, Lausanne, Switzerland, Vol. II, IEEE Press, New York, 1996, pp. 789-791. I71 ] J.V. Mahoney, S. Ullman, Image chunking defining spatial building blocks for scene analysis, vision for situated in: Proceedings robots, of high-level vision: a cognitive Pylyshyn Norwood, NJ, 1988, pp. 169-209. (Ed.), Computational Processes in Human Vision: An Interdisciplinary I72 1 D. Marr, Vision, W.H. Freeman and Company, New York, 1982. 1731 R.F. Marslin, G.D. Sullivan, K.B. Baker, Kalman filters Mowforth pp. 371-374. (Ed.), British Machine Vision Conference in constrained model-based in: P. 1991, Glasgow, UK, Springer, Berlin, 1991, tracking, 1741 D. McDermott, A temporal logic for reasoning about processes and plans, Cognitive Sci. 6 ( 1982) 101-155. I75 1 G.A. Miller, The magic number seven, plus or minus two: some limits on our capacity for processing information, Psychological Review 63 (1956) 81-97; also in: D.C. Beardslee, M. Wertheimer, Readings in Perception, Van Nostrand, New York, 1958, pp. 90-I 14. 1761 M.C. Mozer, The Perception of Multiple Objects: A Connectionist Approach, MIT Press, Cambridge, MA, 1991. [ 77 I D.W. Murray, K.J. Bradshaw, P.F. McLauchlan, I.D. Reid, P.M. Sharkey, Driving saccade to pursuit using image motion, I 78 I H.-H. Nagel, From (1988) 59-74. (2) Intemat. J. Computer Vision 16 (1995) 205-228. image sequences towards conceptual descriptions, Image and Vision Computing 6 I79 1 R.E. Neapolitan, Probabilistic Reasoning in Expert Systems: Theory and Algorithms, John Wiley and Sons, New York, 1990. 1801 B. Neumann, Natural Structures: Advances pp. 167-206. in: D.L. Waltz (Ed.), Semantic language descriptions in Natural Language Processing, Lawrence Erlbaum Associates, London, 1989, of time-varying scenes, 18 I ] D. Newtson, Foundations of attribution: Ickes, R.F. Kidd (Eds.), New Directions London, 1976, pp. 223-247. the perception of ongoing behaviour, in: J.H. Harvey, W.J. in Attribution Research: Vol. 1, Lawrence Erlbaum Associates, [ 821 A.E. Nicholson, J.M. Brady, The data association in: B. Neumann robot vehicles using (Ed. ), Proceedings ECAI-92, Vienna, Austria, John Wiley problem when monitoring dynamic belief networks, and Sons, New York, 1992, pp. 689-693. in: Z.W. Perspective, Ablex, 84 R.J. Howarth/Art@cial Intelligence 100 (1998) S-85 [ 831 N.J. Nilsson, Teleo-reactive [84] D.A. Norman, Cognition programs for agent control, J. Artif. Intell. Research I (1994) 139-158. in the head and in the world: an introduction to the special issue on situated action, Cognitive Science 17 (1993) l-6. [ 851 J. Pearl, Probabilistic Reasoning Kaufman, Los Altos, CA, 1988. in Intelligent Systems: Networks of Plausible Inference, Morgan 1861 Z.W. Pylyshyn, R.W. Storm, Tracking multiple independent targets: evidence for a parallel tracking mechanism, Spatial Vision 3 (1988) 179-197. [ 87 I R.D. Rimey, C.M. Brown, Where (Ed.), Proceedings to look next using a Bayes Net: incorporating 2nd European Conference relations, on Computer Vision, Santa Margherita geometric Italy, Lecture Notes in Computer Science, Vol. 588, Springer, Berlin, 1992, pp. 542-550. in: G. Sandini Ligure, 1881 R.D. Rimey, CM. Brown, Control of selective perception using Bayes nets and decision theory, Intemat. J. Computer Vision 12 (2.3) (1994) 173-207. [ 891 1. Rock, The Logic of Perception, MIT Press, Cambridge, MA, 1983. 1901 S.J. Rosenschein, L.P. Kaelbling, The synthesis of digital machines with provable epistemic properties, 1986 about Knowledge, (Ed.), Theoretical Aspects of Reasoning in: J.Y. Halpem Conference, Timberline, OR, Morgan Kaufman, Los Altos, CA, 1986, pp. 83-98. Proceedings I91 ] G. Ryle, The Concept of Mind, Hutchinson, 1921 R.C. Schank, R.P. Abelson, Scripts, Plans, Goals and Understanding, 1949; Penguin Books, 1990. Lawrence Erlbaum Associates, London, 1977. I931 H. Schiine, Spatial Orientation: The Spatial Control of Behaviour in Animals and Man, Princeton University Wissenschaftliche Press, Princeton, NJ, Verlagsgesellschaft. 1984 (English translation of: Orientierung im Raum ., 1980). 1941 Y. Shoham, Reasoning about Change: Time and Causation from the Standpoint of Artificial Intelligence, MIT Press, Cambridge, MA, 1988. [ 95 1 L.E. Sucar, D.F. Gillies, Expressing in: Uncertainty in Artificial relational and temporal knowledge in visual probabilistic networks, Intelligence, Vol. 8, Morgan Kaufman, Los Altos, CA, 1992, pp. 303-309. Communication, Cambridge 196 ] L. Suchman, Plans and Situated Actions: The Problems of Human-Machine University Press, Cambridge, UK, 1987. [97] G.D. Sullivan, Visual interpretation of known objects in constrained scenes, in: G.A. Horridge H.B. (Special in: G. Sandini Italy, J.P. Frisby, M.A. Jeeves Barlow, Issue), Philos. Trans. Roy. Sot. London Ser. B: Biological Sci. 337 (1992) 361-370. (Eds.), Natural and Artificial Low-level Seeing Systems [ 981 B. Taylor, Tense and continuity, Linguistics 1991 C. Terman, Simulation tools and Philosophy I ( 1977) 199-220. for digital LSI design, Ph.D. Thesis, MIT Laboratory for Computer Science, MIT/LCS/TR-304, Cambridge, MA, 1983. [ 1001 A.F. Toal, H. Buxton, Spatio-temporal reasoning within a traffic surveillance system, (Ed.), Proceedings Lecture Notes in Computer Science, Vol. 588, Springer, Berlin, 1992, pp. 884-892. 2nd European Conference on Computer Vision, Santa Margherita Ligure, [ 101 1 A. Treisman, Preattentive processing Human Vision: An Interdisciplinary Comput. Vision Graphics Image Process 31 (1985) 156-177. in vision, Perspective, Ablex, Norwood, NJ, 1988, pp. 341-369; (Ed.), Computational in: Z.W. Pylyshyn Processes also in in: [ 1021 J.K. Tsotsos, Toward a computational model of attention, in: T. Papathomas, C. Chubb, A. Gorea, E. Kowler (Eds.), Early Vision and Beyond, MIT Press, Cambridge, MA, 1995, pp. 207-218. [ 1031 J.K. Tsotsos, S. M Culhane, W.Y.K. Wai, Y. Lai, N. Davis, E Nuflo, Modeling visual attention via selective tuning, Artificial Intelligence 78 ( 1995) 507-545. [ 1041 S. Ullman, Visual routines, in: S. Pinker and Paradigms, Morgan Kaufman, Los Altos, CA, 1987, pp. 298-328; (Ed.), Visual Cognition, MIT Press, Cambridge, MA, 1985, in Computer Vision: Issues, Problems, also in: Cognition (Eds.), Readings pp. 97-159; also in: M.A. Fischler, 0. Firschein Principles, 18 (1984). 1 1051 J.F.A.K. van Benthem, The Logic of Time, Reidel, Dordrecht, [ 1061 A.H.C. van der Heijden, Selective Attention [ 1071 J.H.C. Whitehead, Combinatorial homotopy 1983. I, Bull. Amer. Math. Sot. 55 (1949) 213-245; also in: I.M. (Ed.), The Mathematical Works of J.H.C. Whitehead: Vol. III on Homotopy Theory, Pergamon in Vision, Routledge & Kegan Paul, London, 1992. James Press, Oxford, 1962, pp. 85-177. R. J. Howarth /Art&ial Intelligence 100 (I 998) 5-85 85 [ 1081 T. Winograd, E Flares, Understanding Computers and Cognition: A New Foundation for Design, Ablex, Not-wood, NJ, 1986. I109 1 W.A. Woods, Transition network grammars for natural language analysis, Comm. ACM 13 ( 10) ( 1970) 591-606. [ llO( A.D. Worrall, R.F. Marslin, G.D. Sullivan, K.B. Baker, Model-based tracking, in: P. Mowforth (Ed.), British Machine Vision Conference 1991, Glasgow, UK, Springer, Berlin, 1991, pp. 310-318. 1 1 I I ] A.D. Worrall, G.D. Sullivan, K.B. Baker, Advances in model-based traffic vision, in: Proceedings 4th British Machine Vision Conference, Guildford, Surrey, UK, BMVA Press, 1993, pp. 559-568. 