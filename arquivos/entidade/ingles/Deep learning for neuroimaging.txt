1Deep Learning for Neuroimaging-based Diagnosisand Rehabilitation of Autism Spectrum Disorder:A ReviewMarjane Khodatars, Afshin Shoeibi, Delaram Sadeghi, Navid Ghassemi, Mahboobeh Jafari, Parisa Moridian,Ali Khadem, Roohallah Alizadehsani, Assef Zare, Yinan Kong, Abbas Khosravi, Saeid Nahavandi,Sadiq Hussain, U. Rajendra Acharya, Michael Berk1202voN1]GL.sc[4v58210.7002:viXraAbstract—Accurate diagnosis of Autism Spectrum Disorder(ASD) followed by effective rehabilitation is essential for the man-agement of this disorder. Artificial intelligence (AI) techniquescan aid physicians to apply automatic diagnosis and rehabili-tation procedures. AI techniques comprise traditional machinelearning (ML) approaches and deep learning (DL) techniques.Conventional ML methods employ various feature extractionand classification techniques, but in DL, the process of featureextraction and classification is accomplished intelligently andintegrally. DL methods for diagnosis of ASD have been focused onneuroimaging-based approaches. Neuroimaging techniques arenon-invasive disease markers potentially useful for ASD diagno-sis. Structural and functional neuroimaging techniques providephysicians substantial information about the structure (anatomyand structural connectivity) and function (activity and functionalconnectivity) of the brain. Due to the intricate structure andfunction of the brain, proposing optimum procedures for ASDdiagnosis with neuroimaging data without exploiting powerfulAI techniques like DL may be challenging. In this paper, studiesconducted with the aid of DL networks to distinguish ASD areinvestigated. Rehabilitation tools provided for supporting ASDpatients utilizing DL networks are also assessed. Finally, we willM. Khodatars and D. Sadeghi are with the Dept. of Medical Engineering,Mashhad Branch, Islamic Azad University, Mashhad, Iran.A. Shoeibi and N. Ghassemi are with the Faculty of Electrical En-gineering, FPGA Lab, K. N. Toosi University of Technology, Tehran,Iran, and the Computer Engineering Department, Ferdowsi University ofMashhad, Mashhad, Iran. (Corresponding author: Afshin Shoeibi, email:afshin.shoeibi@gmail.com).M. Jafari is with Electrical and Computer Engineering Faculty, SemnanUniversity, Semnan, Iran.P. Moridian is with the Faculty of Engineering, Science and ResearchBranch, Islamic Azad University, Tehran, Iran.A. Khadem is with the Faculty of Electrical Engineering, K. N. ToosiUniversity of Technology, Tehran, Iran. (Corresponding author: Ali Khadem,email: alikhadem@kntu.ac.ir).R. Alizadehsani, A. Khosravi and S. Nahavandi. are with the Institutefor Intelligent Systems Research and Innovation (IISRI), Deakin University,Victoria 3217, Australia.A. Zare is with Faculty of Electrical Engineering, Gonabad Branch, IslamicAzad University, Gonabad, Iran.Y. Kong is with the School of Engineering, Macquarie University, Sydney,2109, Australia.S. Hussain is with the Dibrugarh University, Assam, India, 786004.U. R. Acharya is with the Dept. of Electronics and Computer Engineering,Ngee Ann Polytechnic, Singapore 599489, Singapore, the Dept. of BiomedicalInformatics and Medical Engineering, Asia University, Taichung, Taiwan, andthe Dept. of Biomedical Engineering, School of Science and Technology,Singapore University of Social Sciences, Singapore.M. Berk is with the Deakin University, IMPACT - the Institute forMental and Physical Health and Clinical Translation, School of Medicine,Barwon Health, Geelong, Australia, and the Orygen, The National Centreof Excellence in Youth Mental Health, Centre for Youth Mental Health,Florey Institute for Neuroscience and Mental Health and the Department ofPsychiatry, The University of Melbourne, Melbourne, Australia.present important challenges in the automated detection andrehabilitation of ASD and propose some future works.Index Terms—Autism Spectrum Disorder, Diagnosis, Rehabil-itation, Deep Learning, Neuroimaging, Neuroscience.I. INTRODUCTIONA SD is a disorder of the nervous system that affectsthe brain and results in difficulties in speech, socialinteraction and communication deficits, repetitive behaviors,and delays in motor abilities [1]. This disease can generallybe distinguished with extant diagnostic protocols from theage of three years onwards. Autism influences many partsof the brain. This disorder also involves a genetic influencevia the gene interactions or polymorphisms [2], [3]. One in70 children worldwide is affected by autism. In 2018, theprevalence of ASD was estimated to occur in 168 out of 10,000children in the United States, one of the highest prevalencerates worldwide. Autism is significantly more common in boysthan in girls. In the United States, about 3.63 percent of boysaged 3 to 17 years have autism spectrum disorder, comparedwith approximately 1.25 percent of girls [4].Diagnosing ASD is difficult because there is no pathophys-iological marker, relying instead just on psychological criteria[5]. Psychologicaltools can identify individual behaviors,levels of social interaction, and consequently facilitate earlydiagnosis. Behavioral evaluations embrace various instrumentsand questionnaires to assist the physicians to specify the partic-ular type of delay in a child’s development, including clinicalobservations, medical history, autism diagnosis instructions,and growth and intelligence tests [6].Several investigations for the diagnosis of ASD have re-cently been conducted on neuroimaging data (structural andfunctional).Analyzing anatomy and structural connections of brain areaswith structural neuroimaging is an essential tool for study-ing structural disorders of the brain in ASD. The principaltools for structural brain imaging are magnetic resonanceimaging (MRI) techniques [7], [8], [9]. Cerebral anatomy isinvestigated by structrul MRI (sMRI) images and anatomicalconnections are assesed by diffusion tensor imaging MRI(DTI-MR) [10]. Investigating the activity and functional con-nections of brain areas using functional neuroimaging canalso be used for studying ASD. Brain functional diagnostic   2tools are older approaches than structural methods for studyingASD. The most basic modality of functional neuroimaging iselectroencephalography (EEG), which records the electricalactivity of the brain from the scalp with a high temporalresolution (in milliseconds order) [11]. Studies have shownthat employing EEG signals to diagnose ASD have been useful[12], [13], [14]. Functional MRI (fMRI) is one of the mostpromising imaging modalities in functional brain disorders,used as task-based (T-fMRI) or resting-state (rs-fMRI) [15],[16]. fMRI-based techniques have a high spatial resolution (inthe order of millimeters) but a low temporal resolution dueto slow response of the hemodynamic system of the brain aswell as fMRI imaging time constraints and is not ideal forrecording the fast dynamics of brain activities. In addition,these techniques have a high sensitivity to motion artifacts.It should be stressed that in consonance with studies, threeless prevalent modalities of electrocorticography (ECoG) [17],functional near-infrared spectroscopy (fNIRS) [18], and Mag-netoencephalography (MEG) [19] can also attain reasonableperformance in ASD diagnosis. An appropriate approach is toutilize machine-learning techniques alongside functional andstructural data to collaborate with physicians in the processof accurately assessing ASD. In the field of ASD, applyingmachine learning methods generally entail two categories oftraditional methods [20] and DL methods [21]. As opposedto traditional methods, much less work has been done on DLmethods to explore ASD or design rehabilitation tools.This study reviews ASD assesment methods and patients’rehabilitation with DL networks. The outline of this paper isas follows. Section 2 is search strategy. Section 3 conciselypresents the DL networks employed in the field of ASD. Insection 4, existing computer-aided diagnosis systems (CADS)that use brain functional and structural data are reviewed.In section 5, DL-based rehabilitation tools for supportingASD patients are introduced. Section 6 discusses the reviewedpapers. Section 7 reveals the challenges of ASD diagnosisand rehabilitation with DL. Finally, the paper concludes andsuggests future work in section 8.II. SEARCH STRATEGYIn this review, IEEE Xplore, ScienceDirect, SpringerLink,ACM, as well as other conferences or journals were used toacquire papers on ASD diagnosis and rehabilitation using DLmethods. Further, the keywords ”ASD”, ”Autism SpectrumDisorder” and ”Deep Learning” were used to select the papers.The papers are analyzed till June 03th, 2020 by the authors(AK, SN). Figure 1 depicts the number of considered papersusing DL methods for the automated detection and rehabilita-tion of ASD each year.III. DEEP LEARNING TECHNIQUES FOR ASD DIAGNOSISAND REHABILITATIONNowadays, DL algorithms are used in many areas ofmedicine including structural and functional neuroimaging.The application of DL in neural imaging ranges from brainMR image segmentation [22], to detection of brain lesionssuch as tumors [23], diagnosis of brain functional disordersFig. 1: Number of papers published every year for ASDdiagnosis and rehabilitation.Fig. 2: Illustration of various types of DL methods.such as ASD [24], and production of artificial structural orfunctional brain images [25]. Machine learning techniquesare categorized into three fundamental categories of learning:supervised learning [26], unsupervised learning [27], andreinforcement learning [28], and a variety of DL networks areprovided for each type. So far, most studies applied to identifyASD using DL have been based on supervised or unsupervisedapproaches. Figure 2 illustrates generally employed types ofDL networks with supervised or unsupervised learning tostudy ASD.IV. CADS-BASED DEEP LEARNING TECHNIQUES FOR ASDDIAGNOSIS BY NEUROIMAGING DATAA traditional artificial intelligence (AI)-based CADS en-compasses several stages of data acquisition, data pre-processing, feature extraction, and classification [29], [30],[31], [32]. In [33], [34], [35] existing traditional algorithms fordiagnosing ASD have been reviewed. In contrast to traditionalmethods, in DL-based CADS, feature extraction, and classi-fication are performed intelligently within the model. Also,due to the structure of DL networks, using large dataset totrain DL networks and recognize intricate patterns in datasetsis incumbent. The components of DL-based CADS for ASDdetection are shown in Figure 3. It can be noted from thefigure that, large and free databases are first introduced todiagnose ASD. In the second step, various types of pre-processing techniques are used on functional and structuraldata to be scrutinized. Finally, the DL networks are appliedon the preprocessed data.3Fig. 3: Block diagram of CAD system using DL architecture for ASD detection.A. Neuroimaging ASD DatasetsDatasets are the heart of any CADS development and thecapability of CADS depends primarily on the affluence ofthe input data. To diagnose ASD, several brain functionaland structural datasets are available. The most complete freedataset available is ABIDE [36] dataset with two subsets:ABIDE-I and ABIDE-II, which encompasses sMRI, rs-fMRI,and phenotypic data. ABIDE-I involves data from 17 inter-national sites, yielding a total of 1112 datasets, including 539individuals with ASD and 573 healthy individuals (ages 64-7).In accordance with HIPAA guidelines and 1000 FCP / INDIprotocols, these data are anonymized. In contrast, ABIDE-II contains data from 19 international sites, with a total of1114 datasets from 521 individuals with ASD and 593 healthyindividuals (ages 5-64). Also, preprocessed images of theABIDE-I series called PCP [37] can be freely downloaded bythe researchers. The second recently released ASD diagnosticdatabase is called NDAR, which comprises various modalities,and more information is provided in [38].B. Preprocessing TechniquesNeuroimaging data (especially functional ones) is of rela-tively complicated structure, and if not pre-processed properly,it may affect the final diagnosis. Preprocessing of this datatypically entails multiple common steps performed by differentsoftware as standard. Indeed, occasionally prepared pipelinesare applied on the dataset to yield pre-processed data for futureresearches. In the following section, preprocessing steps arebriefly explained for fMRI data.1) Standard (Low-level) fMRI preprocessing steps: Low-level pre-processing of fMRI images normally has fixed num-ber of steps applied on the data, and prepared toolboxesare usually used to reduce execution time and yield betteraccuracy. Some of these reputable toolboxes contain FMRIBsoftware libraries (FSL) [39], BET [40], FreeSurfer [41],and SPM [42]. Also, important and vital fMRI preprocess-ing incorporates brain extraction, spatial smoothing, temporalfiltering, motion correction, slice timing correction, intensitynormalization, and registration to standard atlas, which aresummarized as follows:BRAIN EXTRACTION: the goal is to remove the skull andcerebellum from the fMRI image and maintain the brain tissue[43], [44], [45].SPATIAL SMOOTHING: involves averaging the adjacent vox-els signal. This process is persuasive on account of neighbor-ing brain voxels being usually closely related in function andblood supply [43], [44], [45].TEMPORAL FILTERING: the aim is to eliminate unwantedcomponents from the time series of voxels without impairingthe signal of interest [43], [44], [45].REALIGNMENT (MOTION CORRECTION): During thefMRI test, people often move their heads. The objective ofmotion correction is to align all images to a reference image sothat the coordinates and orientation of the voxels be identicalin all fMRI volumetric images [43], [44], [45].SLICE TIMING CORRECTION: The purpose of modifyingthe slice time is to adjust the time series of the voxels so thatall the voxels in each fMRI volume image have a commonreference time. Usually, the corresponding time of the firstslice recorded in each fMRI volume image is selected as thereference time [43], [44], [45].INTENSITY NORMALIZATION: at this stage, the averageintensity of fMRI signals are rescaled to compensate for globaldeviations within and between the recording sessions [43],[44], [45].REGISTRATION TO A STANDARD ATLAS: The human brainentails hundreds of cortical and subcortical areas with var-ious structures and functions, each of which is very time-consuming and complex to study. To overcome the problem,brain atlases are employed to partition brain images into aconfined number of ROIs, following which the mean timeseries of each ROI can be extracted [46]. ABIDE datasets use amanifold of atlases, including Automated Anatomical Labeling(AAL) [47], Eickhoff-Zilles (EZ) [48], Harvard-Oxford (HO)[49], Talaraich and Tournoux (TT) [50], Dosenbach 160 [51],Craddock 200 (CC200) [52] and Craddock 400 (CC400) [53]and more information is provided in [54]. Table I providescomplete information on preprocessing tools, atlases, andsome other preprocessing information.2) Pipeline Methods: Pipelines present preprocessed im-ages of ABIDE databases. They embrace generic pre-processing procedures. Employing pipelines, distinct methodscan be compared with each other. In ABIDE datasets, pre-processing is performed by four pipeline techniques: neu-roimaging analysis kit (NIAK) [55], data processing assistantfor rs- fMRI (DPARSF) [56], the configurable pipeline for theanalysis of connectomes (CPAC) [57], or connectome com-putation system (CCS) [58]. The preprocessing steps carriedout by the various pipelines are comparatively analogous. Thechief differences are in the particular algorithms for eachstep, the software simulations, and the parameters applied.Details of each pipeline technique are provided in [54]. Table I4Fig. 4: Overall block diagram of a 2D-CNN used for ASD detection.Fig. 5: Overall block diagram of a 3D-CNN used for ASD detection.demonstrates the pipeline techniques used in autism detectionexploiting DL.3) High-level preprocessing Steps: High-level techniquesfor pre-processing brain data are important, and using them ac-companying preliminary pre-processing methods can enhancethe accuracy of ASD recognition. These methods are appliedafter the standard pre-processing of functional and structuralbrain data. These include sliding window (SW) [24], dataaugmentation (DA) [59], functional connectivity matrix (FCM)estimation [60], [61] and applying fast Fourier transformation(FFT) [62]. Furthermore, some of the researches utilizedfeature extraction [63] techniques and some also use featureselection methods. Precise information on reviewed studies isindicated in detail in Table I.C. Deep Neural NetworksDeep learning in various medical applications, including thediagnosis of ASD, has become extremely popular in recentyears. In this section of the paper, the types of Deep Learningnetworks used in ASD detection are examined, which includeCNN, RNN, AE, DBN, CNN-RNN, and CNN-AE models.1) Convolutional Neural Networks (CNNs) : In this section,the types of popular convolutional networks used in ASDdiagnosis are surveyed. These networks involve 1D-CNN, 2D-CNN, 3D-CNN models, and a variety of pre-trained networkssuch as VGG.1D AND 2D-CNNThere are many spatial dependancies present in the dataand it is difficult to extract these hidden signatures from thedata. Convolution network uses a structure alike to convolu-tion filters to extract these features properly and contributeto the knowledge that features should be processed takinginto account spatial dependencies; so the number of networkparameters are significantly reduced. The principal applicationof these networks is in image processing and due to thetwo-dimensional (2D) image inputs, convolution layers form2D structures, which is why these networks are called 2Dconvolutional neural network (2D-CNN). By using anothertype of data, one-dimensional signals, the convolution layers’structure also resembles the data structure [64]. In convo-lution networks, assuming that various data sections do notrequire learning different filters, the number of parameters aremarkedly lessened and make it feasible to train these networkswith smaller databases [21]. Figure 4 shows the block digramof 2D-CNN used for ASD detection.3D-CNNBy transforming the data into three dimensions, the con-volution network will also be altered to a three-dimensionalformat (Figure 5). It should be noted that the manipulation ofthree dimensional CNN (3D-CNN) networks is less beneficialthan 1D-CNN and 2D-CNN networks for diverse reasons.First, the data required to train these networks must be muchlarger which conventionally such datasets are not utilizable andmethods such as pre-training, which are extensively exploitedin 2D networks, cannot be used here. Another reason is thatwith more complicated structure of networks, it becomes muchtougher to fix the number of layers, and network structure.The 3D activation map generated during the convolution of a3D CNN is essential for analyzing data where volumetric ortemporal context is crucial. This ability to analyze a series offrames or images in context has led to the use of 3D CNNs astools for action detection and evaluation of medical imaging.[65].2) Deep Belief Networks (DBNs): DBNs are not populartoday as they used to be, and have been substituted by newmodels to perform various applications ( e.g., autoencoders forunsupervised learning, generative adversarial networks (GAN)for generative modes [66], variational autoencoders (VAE)[67]). However, disregarding the restricted use of these net-works in this era, their influence on the advancement of neural5Fig. 6: Overall block diagram of a DBN used for ASDdetection.Fig. 7: Overall block diagram of an AE used for ASDdetection.networks cannot be overlooked. The use of these networksin this paper is related to the feature extraction without asupervisor or pre-training of networks. These networks serveas unsupervised, consisting of several layers after the inputlayer, which are shown in Figure 6. The training of thesenetworks is done greedily and from bottom to top, in otherwords, each separate layer is trained and then the next layer isappended. After training, these networks are used as a featureextractor or the network weights are used as initial weights ofa network for classification [21].3) Autoencoders (AEs): Autoencoders (AEs) are more than30 years old, and have undergone dramatic changes over theyears to enhance their performance. But the overall structureof these networks has remained the same [21].These networksconsist of two parts: coder and decoder so that the first partof the inputleads to coding in the latent space, and thedecoder part endeavors to convert the code into preliminarydata (Figure 7). Autoencoders are a special type of feedforwardneural networks where the input is the same as the output.They compress the input into a lower-dimensional code andthen reconstruct the output from this representation. The codeis a compact “summary” or “compression” of the input, alsocalled the latent-space representation. Various methods havebeen proposed to block the data memorization by the network,including sparse AE (SpAE) and denoising AE (DAE) [21].Trained properly, the coder part of an Autoencoder can be usedto extract features; creating an unsupervised feature extractor.4) Recurrent Neural Networks (RNNs): In convolution net-works, a kind of spatial dependencies in the data is addressed.But interdependencies between data are not confined to thismodel. For example in time-series, dependencies may beFig. 8: Overall block diagram of an LSTM used for ASDdetection.highly distant from each other, on the other hand, the long-term and variable length of these sequences results in thatthe ordinary networks do not perform well enough to processthese data. To overcome these problems, RNNs can be used.LSTM structures are proposed to extract long term and shortterm dependencies in the data (Figure 8). Another well-knownstructure called GRU is developed after LSTM, and since then,most efforts have been made to enhance these two structuresand make them resistant to challenges (e.g., GRU-D [68] isused to find the lost data).5) CNN-RNN: The initial idea in these networks is to utilizeconvolution layers to amend the performance of RNNs so thatthe advantages of both networks can be used; CNN-RNN,on the one hand, can find temporal dependencies with theaid of RNN, and on the other hand, it can discover spatialdependencies in data with the help of convolution layers [69].These networks are highly beneficial for analyzing time serieswith more than one dimension (such as video) [70] but furtherto the simpler matter, these networks also yield the analysisof three-dimensional data so that instead of a more complexdesign of a 3D-CNN, a 2D-CNN with an RNN is occasionallyused. The superiority of this model is due to the feasibilityof employing pre-trained models. Figure 9 demonstrates theCNN-RNN model.6) CNN-AE:In the construction of these networks, theprincipal aim and prerequisite have been to decrease thenumber of parameters. As shown before, changing merely thenetwork layers to convolution markedly lessens the numberof parameters; combining AE with convolution structures alsomakes significant contribution. This helps to exploit higherdimensional data and extracts more information from the datawithout changing the size of the database. Similar structures,with or without some modifications, are widely deployed forimage segmentation [71], and likewise unsupervised networkcan be applied for network pre-training or feature extraction.Figure 10 depicts the CNN-AE network used for ASD detec-tion. Tables I and II, provide the summary of papers publishedon detection and rehabilitation of ASD patients using DL,6Fig. 11: Block diagram of ios application for ASD rehabilita-tion.Fig. 12: Cloud system design for ASD rehabilitation.another similar study, they achieved an accuracy of 78.32%[73].B. Cloud SystemsMohammadian et al. [74] proposed a new application of DLto facilitate automatic stereotypical motor movement (SMM)identification by applying multi-axis inertial measurementunits (IMUs). They applied CNN to transform multi-sensortime series into feature space. An LSTM network was thencombined with CNN to obtain the temporal patterns for SMMidentification. Finally, they employed the classifier selectionvoting approach to combine an ensemble of the best baselearners. After various experiments, the superiority of theirproposed procedure over other base methods was proven.Figure 12 shows the real-time SMM detection system. First,IMUs, which are wearable sensors, are used for data collec-tion; the data can then be analyzed locally or remotely (usingWi-Fi to transfer data to tablets, cell phones, medical centerservers, etc.) to identify SMMs. If abnormal movements aredetected, an alarm will be sent to a therapist or parents.C. Eye TrackingWu et al. [75] proposed a model of DL saliency predic-tion for autistic children. They used DCN in their proposedparadigm, with a SM saliency map output. The fixation densitymap (FDM) was then processed by the single-side clipping(SSC) to optimize the proposed loss function as a true labelalong with the SM saliency map. Finally, they exploited anautism eye-tracking dataset to test the model. Their proposedmodel outperformed other base methods. Elbattah et al. [76]aimed to combine unsupervised clustring algorithms with deeplearning to help ASD rehabilitation. The first step involved thevisualization of the eye-tracking path, and the images capturedfrom this step were fed to an autoencoder to learn the features.Using autoencoder features, clustering models are developedusing the K-Means algorithm. Their method performed betterthan other state-of-art techniques.Fig. 9: Overall block diagram of a CNN-RNN used for ASDdetection.Fig. 10: Overall block diagram of a CNN-AE used for ASDdetection.respectively.V. DEEP LEARNING TECHNIQUES FOR ASDREHABILITATIONRehabilitation tools are employed in multiple fields ofmedicine and their main purpose is to help the patients torecover after the treatment. Various and multiple rehabilitationtools using DL algorithms have been presented. Rehabilitationtools are used to help ASD patients using mobile, computerapplications, robotic devices, cloud systems, and eye tracking,which will be discussed below. Also, the summary of paperspublished on rehabilitation of ASD patients using DL algo-rithms are shown in Table II.A. Mobile and Software ApplicationsFacial expressions are a key mode of non-verbal commu-nication in children with ASD and play a pivotal role insocial interactions. Use of BCI systems provides insight intothe user’s inner-emotional state. Valles et al. [72] conductedresearch focused on mobile software design to provide assis-tance to children with ASD. They aimed to design a smartiOS app based on facial images according to Figure 11. Inthis way, people’s faces at different angles and brightnessare first photographed, and are turned into various emojiso that the autistic child can express his/her feelings andemotions. In this group’s investigation [72], Kaggle’s (TheFacial Expression Recognition 2013) and KDEF (Kaggle’sFER2013 and Karolinska Directed Emotional Faces) databaseswere used to train the VGG-16. In addition, the LEAP systemwas adapted to train the model at the University of Texas.The research provided the highest rate accuracy of 86.44%. InTABLE I: Summary of articles published using DL methods for neuroimaging-based ASD detection.Number ofLayersClassifierK foldWorkDatasets[24]Clinical Acquisition[77]Clinical Acquisition[78]HCP Dataset inthe HAFNI ProjectNeuroimagingModalitiesT-fMRIresidual-fMRIT-fMRIT-fMRIrs-fMRI[59]Clinical AcquisitionT-fMRI[79]Different DatasetsT-fMRIrs-fMRIPhenotypic Info[80][80][81][82][83][84][85][86][87][62]ClinicalAcquisitionABIDE-IABIDE-IABIDE IIABIDE-IABIDE-IABIDE-IT-fMRIrs-fMRIrs-fMRIrs-fMRIrs-fMRIrs-fMRIABIDE-Irs-fMRIABIDErs-fMRIABIDE-IABIDE-IABIDE-IIABIDE-I + IIrs-fMRIrs-fMRI[88]ABIDErs-fMRI[89]ABIDE-Irs-fMRI[90]ABIDE-Irs-fMRI[91]ABIDErs-fMRI,PhenotypicInfo[92]ABIDErs-fMRI[93]ABIDE-Irs-fMRI[94]ABIDE-Irs-fMRINumberof Cases82 ASD48 HC82 ASD48 HC68 Subjects with7 Tasks and1 rs-fMRI Data21 ASD19 HC1711 ASD15903 HC82 ASD48 HC41 ASD54 HC379 ASD, 395 HC163 ASD, 230 HC505 ASD530 HC872 subjects474 ASD539 HC13 ASD22 HC11 ASD16 HC55 ASD55 HC54 ASD62 HC156 ASD187 HC542 ASD625 HC465 ASD507 HC539 ASD573 HC505 ASD530 HC42 ASD42 HCNY siteUM siteUS siteUC site408 ASD401 HCPipelinesNANANANANANANACPACCPACCPACCCSNANANIAKImageAtlasMNI152AALNAAALAALAALAALAll AtlasesABIDECC-200AALDosenbach160HOAALAALNAAALPreprocessingToolboxFSLNAFSLFSLSPMSpeedyPPNeurosynthFSLNANANilearnNASPM8RESTDPARSFFSLBETNANANASPM8CPACAllAtlasesDPARSFAALNANACCSCraddock200NeurosynthNACC200DPABINANAFSLHigh levelPreprocessingSWSVE, C-SVE, H-SVE, MonteCarlo ApproximationDictionary Learningand Sparse CodingInputsDNNSingle Mean Channel InputSingle STD Channel InputCombined 2-Channel InputMean-Channel SequenceSTD-ChannelFunctional RNSs MapsDNNToolboxNANANADNN2CC3D2CC3D3D-CNNDAROIs Time-SeriesKerasLSTMWavelet Transform andDifferent TechniquesSWCorrupting StrategyPrediction DistributionAnalysisFCMFCM, DANAFCMQcut, NMIStatistic MatrixConvert NII Filesto PNG ImagesFCM, FeatureSelectionDimension ReductionFFTCreating StochasticParcellations by PoissonDisk SamplingFCMDASlicetiming, SpatialStandardization, Smoothing,Filtering, RemovingCovariates, FCM, AE-MKFCIndependent Components(Time Course, PowerSpectrum and Spatial Map)FCMKeras2D-CNNOriginal fMRI SequenceMean-Channel Sequencestd-channel sequenceCorrupt a ROI of Original ImageConcatenating Voxel-Level Mapsof Connectivity FingerprintsMaskingCorrelationsRaw ImagesFunctionalConnectomesPearson CorrelationCoefficient MatrixNMI MatrixPreprocessedPNG ImagesWhole-Brain FCPsImages with 95 × 68, 79 × 68,and 79 × 95 Dimensions, Aroundthe x, y, and z AxesNANANA2CC3D2CC3D3D-CNNPyTorchAENANANAG-CNNsBrainNetCNNwith ProposedLayersDAEMultipleSAEsMCNNEsNAKeraswithTheanobackendGray MatterMask ParcellationsNA3D-CNNEdge Weights of Subjects’Brain GraphKerasVAEMean Time Coursesfrom ROIs4005-DimensionalEigenvectorKerasLSTMNASAETime Courses ofEach SubjectNASAEfMRI ROI Time-Series,Functional ConnectivityKerasLSTMCCSAALNeurosynthCPACHOAALCC200FSLDANA3 Different FCM+Demographic DataKerasDANN25Sigmoid[95]ABIDErs-fMRIAt Least 60SubjectsCCSAALFSLDTL-NN Framework:Offline Learning, TransferLearning FCMFC PatternsNASSAE[96]ABIDE I+IIrs-fMRI993 ASD1092 HCNAAALSchaefer-100HOSchaefer-400FASTBETFASTNAMean Time-Serieswithin Each ROINA1D-CNN451714871416167NA515NAMajorityVotingSigmoidSoftmaxSigmoidSoftmaxSigmoidSigmoidSigmoidSLPSoftmaxSoftmaxNA49635396SoftmaxregressionBinary SRVariousMethodsNASigmoidSoftmaxSigmoidSoftmaxregressionCaffeLeNet-5StandardSoftmaxPerformanceCriteria (%)F1-Score = 89Acc = 97.32Acc = 94.61Acc=69.8Ensemble AUROC=0.92Ensemble Acc=85.19Acc= 87.1Acc= 85.3Acc= 73.3Acc=70.1Sen=67.8Spec=72.8Acc=70.86Acc= 68.7Sen= 69.2Spe= 68.3Acc=54.49Acc=100Sen=99.99Spec=100Acc=86.36Acc=72.73Sen=71.2Spec=73.48Acc=72NAAcc=68.5NANANA10NANANA1010105NANA51010NA10ClusteringNAAcc=61F1-Score=60.22110105Acc=87.21Sen=89.49Spec=83.73Acc=74.8Acc=73.2Sen=74.5Spec=71.7Avg Acc= 67.1Avg Sen=65.7Avg spec=68.3AUC=0.71Softmax10Acc=687[97][98][99]ABIDE-Irs-fMRI529 ASD573 HCAllPipelinesABIDE-IIABIDErs-fMRIrs-fMRI303 ASD, 390 HC40 ASD, 40 HCNACCS[100]ABIDErs-fMRIWholeDatasetAllPipelinesNANANAParcellatedinto 200RegionsGlass Brain andStat Map Images1D Time Series from VoxelsWM, GM, CSFUpper Triangle Part ofthe Correlation MatrixKerasNANANAFCMPyTorch4 DeepEnsembleClassifiertechniques1D-CAEAlexNetASD-DiagNetAuto-ASD-Network1614SigmoidNAStandardSoftmaxProposedSLPProposedSVMSingle VolumeImage GeneratorNAThresholding BasedSegmentationDA Using SMOTEand Graph NetworkMotifs, FCMTime Series Extractionfrom Different Regions,Connectivity Matrix,SMOTE AlgorithmFCMFCMNAOnline Dictionary Learningand Sparse RepresentationTechniques, GeneratingSpatial Overlap PatternsPopulation Graph Construction,Feature Selection Strategies(RFE, PCA, MLP, AE)DAFCMNAFSLNANANANANAFreeSurferNAFSLFEATNANAFSLBrainsuiteSPM8CONN12 ASD14 HC505 ASD530 HC505 ASD530 HC539 ASD573 HC501 ASD553 HC100 ASD100 HC529 ASD571 HC403 ASD468 HC505 ASD530 HCCPACSCSCCPACCC400NANANANADPARSFAALNANACPACHOFSLCCSCC200CPACCraddock200FCM, Converting to1D-Vector1000 Features Selectedby the SVM-RFENASSAEFCMNA2D-CNN1D-Vector of FCMNA1D CNN-AESingle 3D ImageTheano3D-FCNN4D Matrix with 150 3DNetwork Overlap MapsTheano3D-CNNPopulationGraphScikit-learnGCNMean Time-Seriesfrom ROIsKerasLSTMNAExtraction of FetalBrain fMRI Data, SWMean Time Seriesof 3D fMRI VolumesPyTorch3D-CNNSigmoidNA1D-Vector of FCMNATwoSdAE+ MLPNASoftmaxAALSPM8Segmentation, AverageMean Time Seriesof Each ROIRs-fMRI + GM+WMData FusionsTheanoDBNAllatlasesAALCC200DestrieuxNAProposedAtlasNANANAFCM, FeaturesExtraction from S-MRIFCM VectorAnatomical FeaturesCombination of BothAnatomical and ConnectivityFCM VectorKerasTensor-FlowCaffeFreesurferNAFSLBETIn-HouseToolsFSLiBEATFCM,Fisher Score1D-Vector of FCMData-Driven Landmark DiscoveryAlgorithm, Patch Extraction50 Patches Extractedfrom 50 LandmarksPICA, Extractionof PSDPSDs of 34Components3D Patches ExtractionPatch Size 16×64×16Segmentation, ShapeFeature ExtractionCDF Valuesof FeaturesNANANANANADifferentNetworksEnsembleof 5 StackedAEs andMLPMulti-Channel CNN34SAEsDDUNETSNCAENASoftmax75 QualifiedSubjects116 ASD69 HC418 ASD497 HCNANANA368 ASD449 HCCPAC61ASD215 HC78 ASD124 HC60 ASD, 211 HC21 ASD, 21 HC16 ASD, 16 HC10 ASD, 10 HCNANANANANANANANA510101010101031010NA5NAMLPSoftmaxNASoftmax6SoftmaxDifferentFolds207133141167683113EachSAEHas 2Layers11BlocksNASoftmaxSigmoidLRVariousMethodsLabel Fus-ion Usingthe Averageof SoftmaxProbabilitiesSoftmaxPSVMNA8Acc=87F1-score=86Recall=85.2Pre=86.8Acc= 65.3Acc=82.61Acc=82Sen=79.1Spec=83.3Acc=80Sen=73Spec=83Acc=70.20Sen=77.00Spec=61.00Acc=70Sen=74Spec=63Mean DSC=91.56Mean MHD=14.05Acc=93.59Sen=92.52Spec=94.56Average Acc= 70.5Average Sen= 74Average Spec= 67Acc=80.0Acc=70.1Acc=70Sen=74Spec=63F1-score=84AUC=91Acc=65.56Sen=84Spec=32.96AUC= 80Acc= 85.06Sen= 81Spec= 89Acc=76.24Acc=88.5Sen=85.1Spec=90.4NAAcc=96.88[60]ABIDE-Irs-fMRI[61]ABIDE-Irs-fMRI[101]ABIDErs-fMRI[102]ABIDE-Irs-fMRI[103]ABIDE-Irs-fMRI[104]ABIDE-Irs-fMRI[105]ABIDE-I[106]ABIDE-I[107]ABIDE-I[108]Clinical Acquisition[109]ABIDE-IABIDE-II[110]IMPAC[111]ABIDE-I[112]NDAR[63]NDAR[113][114]NDARABIDE-INDAR/PittNDAR/IBISrs-fMRI &Phenotypic Infors-fMRI &Phenotypic Infors-fMRI &S-MRI &PhenotypicInfors-fMRIFetalBOLD fMRIrs-fMRIs-MRIrs-fMRIs-MRIrs-fMRIs-MRIrs-fMRIs-MRIAllModalitiess-MRIs-MRI[115]ABIDE-Is-MRIDestrieuxFreeSurferConstruction of IndividualNetwork, F-score3000 Top FeaturesNASAE[116][117]HCPABIDE-IABIDECombiRx78 ASD104 HC1113 HC83 ASD105 HCs-MRIs-MRI1112 Subjects[118]ABIDE-IIs-MRINA[119]ABIDE-Is-MRI500 ASD500 HCNANANANANADesikan–KilliaFreeSurferNormalization, ApplyOne-Hot CodingNASPM12NAPreprocessed Images32 SlicesAlong Each Axial,Coronal, and SagittalTensor-FlowKerasDEA33SoftmaxNAKerasDCNN17Sigmoid1010NANAAcc=90.39Sen=84.37Spec=95.88AUC=63.9Acc=84Sen=77Spec=85NADKTFreeSurferSegmentationCoronal, Axial and Sagittal2D SlicesPyTorchFastSur-fer CNNProposedSoftmaxHO CorticalandSubcorticalStructuralAtlasFSLGABM Method, NewChromosome EncodingSchemePreprocessedMRI ScansNA3D-CNNSoftmax5Acc=70[120]ClinicalAcquisitions-MRI48 HCNANAFreeSurfer[121]ABIDE-Irs-fMRI270 ASD305 HCCPAC[122][123][124]ClinicalAcquisitionClinicalAcquisitionDifferentDatasetsfNIRSfNIRS25 ASD22 HC25 ASD22 HCs-MRINANoNoNABrain-NetomeAtlas(BNA)NoNoVariousMethodsNANoNoFreeSurferFSLSPM12VolBrainSparse Annotations,DAFiltering, CalculatingMean Time Series forROIs Using BrainNetomeAtlas (BNA), NormalizationTransformation ofthe Time Seriesto Three VariantsSWConverted into the3D Tensor111814Image PatchCaffe3D-CNNMean Time Series DataStacked Across ROIsNACNN-GRUSoftmaxNASigmoid5PM, GM, SMKeras1D CNN-LSTMNABaggingNA3D TensorNACGRNN7NANAGeometric DA3D Cortical MaskTheanoConvNetU-NetsNA[125]ABIDE I+IIrs-fMRI[126]ABIDE-I[127]ABIDE-Irs-fMRIPhenotypicInformationrs-fMRI ands-MRI[128]ABIDE-Irs-fMRI620 ASD2085 HC184 ASD110 HC403 ASD468 HC505 ASD530 HCCPACHOFSLPerformed an Automatic QualityControl, Visually Inspection,9 Temporal Summary Measures,Mean and STD of the SummaryMeasures, Normalization,Occlusion of Brain RegionsEach Summary MeasureNACPACNANADown SamplingRaw 4D VolumeNA264 ROIsBasedParcellationSchemeAFNIFSLMATLABFCM,Feature Extraction(Different Features)Normalized FeaturesNANAMM-ensemble(3D-CNN)3D-CNNC-LSTMAE7217CPACCC200NAFCM1D-Vector of FCMPyTorchCapsNetStandardMajorityVotingSoftmaxDNNK-MeansClustering8551010Acc=91.6AUC=94.1Acc=74.54Sen=63.46Spec=84.33Acc=95.7Sen=97.1Spec=94.3Acc=92.2Sen=85.0Spec=99.4NAAcc=64F1-Score=66Acc=77F1-score=78Acc= 79.2AUC= 82.4Acc=71Sen=73Spec=669TABLE II: Summary of papers published on rehabilitation of ASD patients using DL algorithms.WorkDatasetsType ofApplications[129]OSIE—[73]KDEFFacial Expression RecognitionNumberof Cases20 ASD19 HC70IndividualsPreprocessingHFM Construction,Filtering Normalizing, DAInputsDNNHFMs, NaturalScene ImagesDNNToolboxCaffeTensorFlowDNNsVGGNeTDARGB Images (562×762)KerasDCNN[130][72]ClinicalAcquisitionKaggle’sFER2013KDEFDetecting Audio Regimes That DirectlyEstimate ASD Severity Social Affect scores33 ASDMFCC Spectrograms32 SpectrogramsNAFacial Expression RecognitionNANo48×48-Pixel ImagesKeras(TensorFlowBackend)Noisemes NetworkDiarTK DiarizationNetworkDCNN[131]SALICONASD Classification14 ASD14 HCSalGAN Model,Feature ExtractionSequence of Image PatchesNASP-ASDNetNumber ofLayers5044StandardNetwork4411[132]BigFaceXFacial Expression Recognition196 SubjectsSW, Merge in the Channel Dimension, DA5-channel Sub-Sequence Stackswithin a Specific Time WindowKerasTimeConvNetPreTrain NetsSoftmax[133]DifferentDatasetsSuitable Courseware for Children with ASDNA[134]Camera ImagesEstimating Visual Attention inRobot-Assisted Therapy6 ASD and ID[135]SensorDataAutomatic SMM detection6 ASD5 HC[136]KOMAAFacial Expression Recognition55 subjectsASD ClassificationASD Classification using Eye Tracking31 ASD36 HC136 ASD136 HCPredicting Visual Attentionof Children with ASD.ASD ClassificationInteractive and IntelligentChatbot , NLP, Visual AidResizing, Frame Extraction,Visual InspectionFace Detection (Viola–Jones),Feature Extraction (HOG Descriptors)Different InputsNADifferent NetsNA5 Facial Landmarks - 36HOG DescriptorsNAR-CNNVGG-16MTCNNCascaded CNNsArchitectureResampling, Filtering, SWTime-Series of Multiple SensorsKerasCNN-LSTMSegmentation, DifferentFeatures, Z-scoresGreedy Forward Feature SelectionDA, ChineseWord2Vec32-Dimensional Word VectorNANACNNLSTMTLD Method, AccumulativeHistogram ComputationAngle Histogram, LengthHistogram and Fused Histogram,KerasLSTMNAK-NNNa¨ıveMajorityVotingSVMCoherence Representation ofLSTM Forget GateNANA300 ImagesNARaw ImagesNADCN14 ASD14 HCDA MethodsImage, Data PointsPytorchResNet18StandardSoftmaxASD Classification704Different MethodsPreprocessed DataNACNNASD Classification29 ASD30 HCVisualization of Eye-Tracking ScanpathsScaling Down, PCA100*100 ImageEngagement Estimationof Children with ASD During aRobot-Assisted Autism Therapy30 childrenNAModeling Typical and Atypical Behaviorsin ASD Children68 video ClipsDifferent MethodsBehavioral Data Extractedfrom Video Analysis ofChild-Robot Interactions.Developing Automatic SMMDetection Systems5 ASD7 HC6 ASDSegmentation, Upper Body tracking,Laban Movement Analysis toDrive Weight, Different featuresResampling, Filtering, SW,Data Balancing, NormalizingTime-Series of MultipleAccelerometer SensorsCropped Face Images(256 *256)Sequences of Individual Framesat a Rate of 30 fps3 Movement Features with 68Facial Key-PointsKeras,Scikit-LearnKeraswithTensorFlowBackendopenCV,CaffeNADeeppyLibraryAECultureNetDCNNCNNCNN[145]ASD ScreeningAutism Screening513 ASD189 HCCleaning Missing Values and Outliers,Visualization, Identity MappingThe Embedded Categorical Variablesare Concatenated with NumericalFeatures as New Feature VectorsNADENN[146]ASD ScreeningDatasetsClassification ofAdults with ASD—Handling of Missing Values, VariableReduction, Normalization, andLabel EncodingNormalized VariablesKerasDNNSVMNAF1-score=95SigmoidSigmoidNANAAcc=100Spec=99Sen=100F1-score=99Acc=99.40Sen=97.89Spec=10010ClassifierK foldPerformanceCriteria (%)SoftmaxSoftmaxSyntheticRFSoftmaxNANAK-MeansClusteringSoftmaxDTSoftmax13NANANANANANA10NANANA10NANANANANA5NAAcc=85Sen=80Spec=89Acc=78.32Acc=84.7Acc=86.44Acc=57.90Rec=59.21Pre=56.26Acc=97.9NAAcc= 88.2Pre=83.3Sen=83.0Spec=87.3NAAcc=96Acc=92Acc=92.6Sen=91.9Spec=93.4SIM=67.8CC=76.9AUC-J=83.4Acc=55.13Sen=63.5Spec=47.1Acc=99.53Sens=99.39Spec=100Silhouettescore=60ICC=43.35CCC=43.18PC=45.17Avg Pre=73Avg Recall=75Avg Acc=71Acc=88.46Pre=89.12Recall=88.53[137][138]Story-TellingNarrative CorporaExt-Dataset(video dataset)[139]MIT1003[75][140][76]Scan Path Data,Including Locationand DurationUCI MachineLearningRepositoryEye TrackingScanpath[141]Video Data[142][143][144]YouTubeASDDatasetVideoDatasetVideoDataset139142678R-CNN +ResNet50+5FC layersNA1084711Fig. 13: Number of DL tools used for the diagnosis andrehabilitation of ASD patients in reviewed papers.Fig. 14: Number of of DL networks used for ASD detectionand rehabilitation in the reviewed works.VI. DISCUSSIONIn this study, we performed a comprehensive overview ofthe investigations conducted in the scope of ASD diagnosticCAD systems as well as DL-based rehabilitation tools for ASDpatients. In the field of ASD diagnosis, numerous papers havebeen published using functional and structural neuroimagingdata as well as rehabilitation tools, as summarized in TableIII in the appendix. A variety of DL toolboxes have beenproposed for implementing deep networks. In Tables I andII the types of DL toolboxes utilized for each study aredepicted, and the total number of their usage is demonstratedin Figure 13. The Keras toolbox is used in the majority of thestudies due to its simplicity. Keras offers a consistent high-level application programming interface (APIs) to build themodels more straightforward, and by using powerful backendssuch as TensorFlow, its performance is sound. Additionally,due to all pre-trained models and available codes on platformssuch as GitHub, Keras is quite popular among researchers.Number of DL networks used for the ASD detection in thereviewed works is shown in Figure 14. Among the variousDL architectures, CNN is found to be the most popular oneas it has achieved more promising results compared to otherdeep methodologies. The autoencoder, as well as RNN, haveyielded favorable results. It can be noted that in recent years,the number of DL-based papers has increased exponentiallydue to their sound performance and also the availability ofvast and thorough datasets.The number of various classification algorithms used in DLnetworks are shown in Figure 15. One of the best and mostwidely used is the Softmax algorithm (Tables I and II). It ismost popular since it is differentiable in the entire domain andcomputationally less expensive.VII. CHALLENGESSome of the most substantial challenges in ASD diagnosisscope using DL-based techniques are addressed in this section,which comprise database and algorithmic problems. There areonly two-class brain structural and functional datasets (ASDFig. 15: Number of various classification algorithms used forthe detection of ASD and rehabilitation in DL.and healthy) available in the public domain. Hence, researchersare not able to broaden their investigation to all sub-typesof ASD. Two of the cheapest and most pragmatic functionalneuro-screening modalities for diagnosis of ASD are EEG, andfNIRS. But unfortunately the deficiency of freely availabledatasets has resulted in little research in this area. Anotherobstacle is that multi-modality databases such as EEG-fMRIare not available to researchers to evaluate the effectiveness ofincorporating information of different imaging modalities todetect ASD. Although fMRI and sMRI data are ubiquitous inthe ABIDE dataset, the results of merging these structural andfunctional data for ASD diagnosis using DL have not yet beeninvestigated. Another problem grappling the researchers isdesigning the DL-based rehabilitation systems with hardwareresources. Nowadays, assistive tools such as Google Colabare available to researchers to improve the processing power;however, the problems still prevail when implementing thesesystems in real-world scenarios.The receiver operating characteristic curve (ROC-curve)depicts the performance of the proposed model at all clas-sification thresholds. It is the graph of true positive rate vs.false positive rate (TPR vs. FPR). Equations for calculation ofTPR and FPR are presented below.T P R =F P R =T PT P + F NF PF P + T N(6)(7)AREA UNDER THE ROC CURVE (AUC)AUC presents the area under the ROC-curve from (0, 0)to (1, 1). It provides the aggregate measure of all possibleclassification thresholds. AUC has a range from 0 to 1. A100% wrong classification will have AUC value of 0.0, whilea 100% correct classified version will have the AUC valueof 1.0. It has two folded advantages. One is that it is scale-invariant, which implies how well the model is predicted ratherthan checking the absolute values. The second advantage isthat it is classification threshold-invariant as it will verify theperformance of the model irrespective of the threshold beingselected.APPENDIX BTable III shows details of Deep Nets in all the papersreviewed in this study.ACKNOWLEDGMENTMB is supported by a NHMRC Senior Principal Re-search Fellowship (1059660 and 1156072). MB has receivedGrant/Research Support from the NIH, Cooperative ResearchCentre, Simons Autism Foundation, Cancer Council of Vic-toria, Stanley Medical Research Foundation, Medical BenefitsFund, National Health and Medical Research Council, MedicalResearch Futures Fund, Beyond Blue, Rotary Health, A2 milkcompany, Meat and Livestock Board, Woolworths, Avant andthe Harry Windsor Foundation, has been a speaker for AstraZeneca, Lundbeck, Merck, Pfizer, and served as a consultantto Allergan, Astra Zeneca, Bioadvantex, Bionomics, Collab-orative Medicinal Development, Lundbeck Merck, Pfizer andServier - all unrelated to this work.12VIII. CONCLUSION AND FUTURE WORKSASD is typically characterized by social disorders, com-munication deficits, and stereotypical behaviors. Numerouscomputer-aided diagnosis systems and rehabilitation tools havebeen developed to assist patients with autism disorders. In thissurvey, research on ASD diagnosis applying DL and func-tional and structural neuroimaging data were first assessed.The researchers have taken advantage of deep CNNs, RNNs,AEs, and CNN-RNN networks to improve the performanceof their systems. Boosting the accuracy of the system, thecapability of generalizing and adapting to differing data andreal-world challenges, as well as reducing the hardware powerrequirements to the extent that the final system can be utilizedby all are the principal challenges of these systems. To enhancethe accuracy and performance of CADS for ASD detection inthe future, deep reinforcement networks (RL) or GANs can beexploited. Scarcity of data is always an aparamount problem inthe medical field that can be resolved relatively with the help ofthese deep GANs. Also, as another direction for future works,handcrafted features can be extracted from data and fed toDL networks in addition to raw data; this can help increasingperformance by adding the potential of traditional methods toDL-based models.Many researchers have proposed various DL-based rehabil-itation tools to aid the ASD patients. Designing a reliable,accurate, and wearable low power consumption DL algorithmbased device is the future tool for ASD patients. An achievablerehabilitation tool is to wear smart glasses to help the childrenwith ASD. These glasses with the built-in cameras will acquirethe images from the different directions of environment. Thenthe DL algorithm processes these images and produces mean-ingful images for the ASD children to better communicatewith their surroundings.APPENDIX ASTATISTICAL METRICSThis section demonstrates the equations for the calculationof each evaluation metric. In these equations, True positive(TP) is the correct classification of the positive class, Truenegative (TN) is the correct classification of the negative class,False positive (FP) is the incorrect prediction of the positives,False negative (FN) is the incorrect prediction of the negatives.Accuracy(Acc) =T P + T NT P + T N + F P + F NSpecif icity(Spec) =Sensitivity(Sen) =P recision(P rec) =T NT N + F PT PT P + F NT PT P + F PF 1 − Score = 2 ∗P rec ∗ SensP rec + Sens(1)(2)(3)(4)(5)RECEIVER OPERATING CHARACTERISTIC CURVE (ROC-CURVE)TABLE III: Details of Deep Nets. For ASD diagnosis and Rehabilitation.Work[24][77][78][59][79][80][81][82][83][84][85][86][87][62][88][89][90][91][92][93][94][95][96][97][98][99][100][60][61][101][102][103][104][105][106][107][108][109][110][111][112][63][113][114][115][116][117][118][119][120][121][122][123][124][125][126][127][128][129][73][130][72][131][132][133][134][135][136][137][138][139][75][140][76][141][142][143][144][74][145][146]Network2CC3D2CC3D3D-CNNLSTMCNN2CC3DCNNAEG-CNNBrainNetCNN withProposed LayersDAELeNet-5SAEMCNNEs3D-CNNVAELSTMSAESAELSTMMultichannel DANNSSAE1D-CNNCNN1D CAE-CNNAlexNetASD-DiagNetAuto-ASD-NetworkCNN2 SdAE-CNN3D-FCNNSSAE3D-CNNGCNAELSTM2 SdAE-MLP3D-CNNDBNFeedFWDEnsembleof 5 SAEsand MLPsMulti-Channel CNN34 SAEsDDUNETSNCAESpAEDAEDCNNFastSurfer CNN3D-CNN3D-UNETCNN-GRU1D CNN - LSTMCGRNNConvNet3D-CNN3DCNN C-LSTMAECapsNetsVGGNets + ASDNetDetails for Deep NetworksCNN Layers (6) + Pooling Layers (4) + FC Layers (2)CNN Layers (6) + Pooling Layers (4) + FC Layers (3)CNN Layers (2) + LReLU Actication + Pooling Layers (1) + FC Layers (1)LSTM Layers (1) + Pooling Layers (1) + FC Layers (3)CNN Layers (2) + ReLU Activation + BN Layers (4) + FC Layers (3)CNN Layers (6) + Pooling Layers (4) + FC Layers (2)CNN Layers (2) + ELU Activation + Pooling Layers (2) + FC Layers (2)Standard AE with Tanh ActicationProposed G-CNN with 3 Layer CNNElement-wise layer (1) + E2E layers (2) + E2N layer (1) + N2G layer (1)+ FC layers (3)+ Leaky ReLU Activation+ Tanh ActivationStandard DAEStandard LeNet-5 ArchitectureSAE with LSF ActivationCNN Layers (3) + ReLU Activation + Pooling Layers (3) + FC Layers (1)CNN Layers (2) + ELU Activation + Pooling Layers (2) + FC Layers (3)VAE with 3 LayersLSTM Layers (1) + Pooling Layers (1) + FC Layers (1)SAE Layers (3) + Sigmoid ActivationSAE Layers (8) + Sigmoid ActivationLSTM Layers (2) + Pooling Layers (1) + FC Layers (2)3 MLP (1 Dropout Layer and 4 Dense Layers) + Self-Attention (3) + Fusion (3)+ Aggregation Layer + Dense Layer (1) + ReLU, ELU, Tanh Activations3 SSAE LayersCNN Layers (1) + Pooling Layers (1) + FC Layers (1)CNN Layers (6) + Pooling Layers (4) + BN Layers (2) + FC Layers (2)Encoder (4 layers) + Decoder (4 layers) + CNN layers (2) + pooling layers (2) + FC layers (2)Standard AlexNet ArchitectureProposed DiagNetProposed Auto-ASD-NetworkCNN layers (7) + Pooling layers (7) + FC layers (3)Proposed SDAE-CNN with 7 Layes CNNCNN Layers (9) + PReLU Activation + FC Layers (3)2 Layers SSAECNN layers (7) + Pooling Layers (3) + FC Layers (2) + Log-Likelihood ActivationGCN with ReLU and Sigmoid ActicationSAE wth Tanh ActivationProposed Deep NeworkProposed 2-SDAE-MLP NetworkCNN Layers (2) + ReLU Activation + Pooling Layers (2) + FC Layers (2)DBN with 5 Hidden LayersDense layers (5) + LReLU activation5 [ AE (3) + MLP (2)] + SoftmaxCNN Layers (5) + ReLU Activation + Pooling Layers (2) + FC Layers (5)34 [ SAE network (2)]Proposed DDUNET with 11 blocks and ReLU ActivationProposed SNCAE NewtorkSpAE with 2 NetworksAE (3) + SELU ActivationCNN Layers (6) + ReLU Activation + Pooling Layers (6) + FC Layers (4)Proposed FastSurfer CNN NetworkCNN Layers (3) + ReLU Activation + Pooling Layers (3) + FC Layers (2)DCNN Layers (7) + ReLU Activation + Pooling Layers (2) + BN Layers (6)CNN Layers (4) + GRU Layers (2) + ReLU Activation + Pooling Layers (2) + FC Layers (5)Proposed 1D-CNN LSTM with ReLU ActivationCNN layers (3) + ReLU Activation + Pooling Layers (1)+ GRU Layers (1) + Sigmoid Activation + FC Layer (1)Variation of the U-net Convolutional ArchitectureCNN Layers (2) + ELU Activations + Pooling Layers (2) + FC Layers (2)CNN Layers (8) + Conv-Bi LSTM Layers (2) + Sigmoid Activation (for LSTM)+ Pooling Layers (1) + FC Layers (1)Proposed AE with 7 LayersStandard ArchitectureCNN Layers (27) + ReLU Activation + Pooling Layers (10) + FC Layers (6)DCNNCNN Layers (7) + Activation+ Pooling Layers (13) + FC Layers (3) + BN Layers (10)Noisemes netDiarTK Diarization netStandard NetworksDCNNCNN Layers (7) + ELU Activation + Pooling Layers (13) + FC Layers (3) + BN Layers (10)SP-ASDNetTimeConvNetDifferent NetworksRCNNMTCNNCNN-LSTMCNNLSTMLSTMDCNPretrained Resnet18CNNAECultureNetDCNNCNNSA-B3D withLSTM ModelCNNDENNDNNCNN Layers (2) + LSTM Layers (2) + Pooling Layers (3) + FC Layers (2)Convolutional Spatiotemporal Encoding Layer+ Backbone ConvolutionalNeural Network Architecture (Mini-Xception, ResNet20, MobileNetV2)Proposed StructureVGG-16Cascaded CNNs ArchitectureCNN Layers (3) + LSTM Layers (1) + ReLU Activation+ Pooling Layers (3) + FC Layers (3)CNN Layers (4) + Pooling Layers (2) + FC Layers (2)LSTM layer (1)LSTM Layers (3) + Sigmoid Activation + FC Layers (1)CNN Layers (17) + Pooling Layers (3) + Deconvolution Layers (3) + Learned Priors (3)Standard ResNet-18 ArchitectureCNN Layers (2) + ReLU Activation + Pooling Layers (2) + FC Layers (2)AE with 8 LayersFaster R-CNN + Modified ResNet50 + 5FC LayersProposed DCNN Architecture with Different LayersCNN Layers (2) + ReLU Activation + FC Layers (3)CNN Layers (5) + LSTM Layers (1) + Pooling Layers (4) + FC Layers (1)CNN Layers (3) + ReLU Activation + Pooling Layers (3) + FC Layers (1)Proposed DENN Architecture with ReLU Activation + FC Layers (2)Propoded DNN with ReLU Activation + FC Layers (2)Dropout2 (rate=0.5)2 (rate=0.65)NA3 (rate=NA)1 (rate=0.5)2 (rate=0.3)2 (rate=0.7)2 (rate=NA)NANA(rate=0.3)5 (rate=0.5)1 (rate= 0.6)NANANA1 (rate=0.5)NANA1(rate=0.5)NANANA1 (rate=NA)NA(rate=0.2)1 (rate=0.25)NANANANA1 (rate=0.25)NANANA2 (rate=0.2)(rate=0.3)(rate=0.5)NANANA3 (rate= NA)5 (rate=NA)NANA(rate=0.1)NANANANANA2 (rate=0.5)2 (rate=0.5)NA(rate=0.2)1 (rate=0.5)NANA8 (rate=0.2)NANA6 (rate=0.5)7 (rate=0.25)3 (rate=0.5)NA7 (rate=0.25)3 (rate=0.5)2 (rate=NA)NANANA1 (rate=0.5)1 (rate=0.2)NANANANAStandard1 (rate=0.5)NANANA4 (rate=0.2)NANANA(rate =0.2)(rate =0.4)13Loss FunctionBCENAMNLLMSENANANAMSEBCENAProposed Loss FunctionProposed Loss functionNANABCEBCEMSDProposed Loss FunctionBCENAMSEBCEMSECEProposed Loss FunctionNAPropose Loss FunctionNACENANLLFNANACENAMNLLCEMSEBCEMSEMSEBCENABCENACENACENAMSESum of MSE + 2 CE + CCBCELogistic & Dice LossesCEweighted CEBCECCEBCEProposed Loss FunctionBCECENAProposed Loss FunctionCENANANABCECCENANANAClassifierSigmoidSigmoidSoftmaxSigmoidSoftmaxSigmoidSigmoidSLPSoftmaxSoftmaxNASoftmaxSoftmaxBinary SRSigmoidNASigmoidClusteringSRSigmoidSigmoidSoftmaxSoftmaxSigmoidNASoftmaxSLPSVMMLPSoftmaxSoftmaxSoftmaxNASoftmaxSigmoidSoftmaxSigmoidLRNAAveraging theSoftmaxActivationProbabilitiesSoftmaxPSVMNASoftmaxSoftmaxNASigmoidSoftmaxSoftmaxSoftmaxSigmoidSoftmaxNANASigmoidSoftmaxDNNK-Means ClusteringSoftmaxSoftmaxRFSoftmaxNASoftmaxNAKNNSoftmaxOptimizerNANASGDAdadeltaAdamNASGDNAAdamAdamNANALBFGSAdamAdamaxSGDAdamAdadeltaAdadeltaProposed Opt.L-BFGSAdamNAScaled ConjugateGradient DescentAdamAdamNANANANANANASGDNASGDNAAdadeltaNASGDNAAdamNANAL-BFGSSGDNANAAdamAdamAdamAdadeltaSGDAdamAdamAdamAdamSGDAdamNAAdamSGDSGDNASGDAdamAdamNANASGDSoftmaxCoherence RepresentationNANAStandardNAK-Means ClusteringSoftmaxDecision Tree (DT)SoftmaxSigmoidSVMSigmoidSigmoidNANANANAAdamAdamNAAdeltaManual OptimizationNAAdamSGDmini-batch SGDAdamNANACEProposed Loss FunctionBCEBCENAProposed Loss FunctionNANACEProposed Loss FunctionNACCEBCE14REFERENCES[1] J. Kang, X. Han, J. Song, Z. Niu, and X. Li, “The identification ofchildren with autism spectrum disorder by svm approach on eeg andeye-tracking data,” Computers in Biology and Medicine, p. 103722,2020.[2] B. S. Abrahams and D. H. Geschwind, “Advances in autism genetics:on the threshold of a new neurobiology,” Nature reviews genetics,vol. 9, no. 5, pp. 341–355, 2008.[3] E. Stevens, D. R. Dixon, M. N. Novack, D. Granpeesheh, T. Smith,and E. Linstead, “Identification and analysis of behavioral phenotypesin autism spectrum disorder via unsupervised machine learning,” In-ternational journal of medical informatics, vol. 129, pp. 29–36, 2019.[4] M. J. Maenner, K. A. Shaw, J. Baio et al., “Prevalence of autism spec-trum disorder among children aged 8 years—autism and developmentaldisabilities monitoring network, 11 sites, united states, 2016,” MMWRSurveillance Summaries, vol. 69, no. 4, p. 1, 2020.[5] S. Yazdani, A. Capuano, M. Ghaziuddin, and C. Colombi, “Exclusioncriteria used in early behavioral intervention studies for young childrenwith autism spectrum disorder,” Brain Sciences, vol. 10, no. 2, p. 99,2020.[6] C. Andy and R. S. Masters, “Improving motor skill acquisition throughanalogy in children with autism spectrum disorders,” Psychology ofSport and Exercise, vol. 41, pp. 63–69, 2019.[7] S. Mostafa, L. Tang, and F.-X. Wu, “Diagnosis of autism spectrumdisorder based on eigenvalues of brain networks,” IEEE Access, vol. 7,pp. 128 474–128 486, 2019.[8] A. Kazeminejad and R. C. Sotero, “Topological properties of resting-state fmri functional networks improve machine learning-based autismclassification,” Frontiers in neuroscience, vol. 12, p. 1018, 2019.[9] O. Dekhil, M. Ali, R. Haweel, Y. Elnakib, M. Ghazal, H. Hajjdiab,L. Fraiwan, A. Shalaby, A. Soliman, A. Mahmoud et al., “A compre-hensive framework for differentiating autism spectrum disorder fromneurotypicals by fusing structural mri and resting state functional mri,”in Seminars in Pediatric Neurology. Elsevier, 2020, p. 100805.[10] B. G. Travers, N. Adluru, C. Ennis, D. P. Tromp, D. Destiche,S. Doran, E. D. Bigler, N. Lange, J. E. Lainhart, and A. L. Alexander,“Diffusion tensor imaging in autism spectrum disorder: a review,”Autism Research, vol. 5, no. 5, pp. 289–313, 2012.[11] J. Vicnesh, J. K. E. Wei, S. L. Oh, N. Arunkumar, E. W. Abdulhay, E. J.Ciaccio, U. R. Acharya et al., “Autism spectrum disorder diagnosticsystem using hos bispectrum with eeg signals,” International Journalof Environmental Research and Public Health, vol. 17, no. 3, p. 971,2020.[12] D. Haputhanthri, G. Brihadiswaran, S. Gunathilaka, D. Meedeniya,S. Jayarathna, M. Jaime, and C. Harshaw, “Integration of facialthermography in eeg-based classification of asd,” International Journalof Automation and Computing, vol. 17, pp. 1–18, 2020.[13] J. Kang, T. Zhou, J. Han, and X. Li, “Eeg-based multi-feature fusionassessment for autism,” Journal of Clinical Neuroscience, vol. 56, pp.101–107, 2018.[14] T. Sinha, M. V. Munot, and R. Sreemathy, “An efficient approach fordetection of autism spectrum disorder using electroencephalographysignal,” IETE Journal of Research, pp. 1–9, 2019.[15] M. Sadeghi, R. Khosrowabadi, F. Bakouie, H. Mahdavi, C. Eslahchi,and H. Pouretemad, “Screening of autism based on task-free fmri usinggraph theoretical approach,” Psychiatry Research: Neuroimaging, vol.263, pp. 48–56, 2017.[16] A. Kazeminejad and R. C. Sotero, “Topological properties of resting-state fmri functional networks improve machine learning-based autismclassification,” Frontiers in neuroscience, vol. 12, p. 1018, 2019.[17] J. C. Siero, D. Hermes, H. Hoogduin, P. R. Luijten, N. F. Ramsey,and N. Petridou, “Bold matches neuronal activity at the mm scale:A combined 7 t fmri and ecog study in human sensorimotor cortex,”Neuroimage, vol. 101, pp. 177–184, 2014.[18] L. Xu, Q. Hua, J. Yu, and J. Li, “Classification of autism spectrumdisorder based on sample entropy of spontaneous functional near infra-red spectroscopy signal,” Clinical Neurophysiology, 2020.[19] R. G. Port, J. C. Edgar, M. Ku, L. Bloy, R. Murray, L. Blaskey, S. E.Levy, and T. P. Roberts, “Maturation of auditory neural processes inautism spectrum disorder—a longitudinal meg study,” NeuroImage:Clinical, vol. 11, pp. 566–577, 2016.[20] R. C. Deo, “Machine learning in medicine,” Circulation, vol. 132,no. 20, pp. 1920–1930, 2015.[21] I. Goodfellow, Y. Bengio, and A. Courville, Deep learning. MITpress, 2016.[22] J. Dolz, C. Desrosiers, L. Wang, J. Yuan, D. Shen, and I. B. Ayed,“Deep cnn ensembles and suggestive annotations for infant brain mrisegmentation,” Computerized Medical Imaging and Graphics, vol. 79,p. 101660, 2020.[23] N. Ghassemi, A. Shoeibi, and M. Rouhani, “Deep neural networkwith generative adversarial networks pre-training for brain tumorclassification based on mr images,” Biomedical Signal Processing andControl, vol. 57, p. 101678, 2020.[24] X. Li, N. C. Dvornek, X. Papademetris, J. Zhuang, L. H. Staib,P. Ventola, and J. S. Duncan, “2-channel convolutional 3d deep neuralnetwork (2cc3d) for fmri analysis: Asd classification and featurelearning,” in 2018 IEEE 15th International Symposium on BiomedicalImaging (ISBI 2018).IEEE, 2018, pp. 1252–1255.[25] Q. Delannoy, C.-H. Pham, C. Cazorla, C. Tor-D´ıez, G. Doll´e, H. Me-unier, N. Bednarek, R. Fablet, N. Passat, and F. Rousseau, “Segsr-gan: Super-resolution and segmentation using generative adversarialnetworks—application to neonatal brain mri,” Computers in Biologyand Medicine, p. 103755, 2020.[26] R. Reed and R. J. MarksII, Neural smithing: supervised learning infeedforward artificial neural networks. Mit Press, 1999.[27] G. E. Hinton, T. J. Sejnowski, T. A. Poggio et al., Unsupervisedlearning: foundations of neural computation. MIT press, 1999.[28] M. Wiering and M. Van Otterlo, Reinforcement learning.Springer,2012, vol. 12.[29] J. Eldridge, A. E. Lane, M. Belkin, and S. Dennis, “Robust features forthe automatic identification of autism spectrum disorder in children,”Journal of neurodevelopmental disorders, vol. 6, no. 1, p. 12, 2014.[30] S. Bhat, U. R. Acharya, H. Adeli, G. M. Bairy, and A. Adeli,“Autism: cause factors, early diagnosis and therapies,” Reviews in theNeurosciences, vol. 25, no. 6, pp. 841–850, 2014.[31] A. Dejman, A. Khadem, and A. Khorrami, “Exploring the disordersof brain effective connectivity network in asd: A case study using eeg,transfer entropy, and graph theory,” in 2017 Iranian Conference onElectrical Engineering (ICEE).IEEE, 2017, pp. 8–13.[32] N. Ghassemi, A. Shoeibi, M. Rouhani, and H. Hosseini-Nejad, “Epilep-tic seizures detection in eeg signals using tqwt and ensemble learning,”in 2019 9th International Conference on Computer and KnowledgeEngineering (ICCKE).IEEE, 2019, pp. 403–408.[33] S. Bhat, U. R. Acharya, H. Adeli, G. M. Bairy, and A. Adeli,“Automated diagnosis of autism: in search of a mathematical marker,”Reviews in the Neurosciences, vol. 25, no. 6, pp. 851–861, 2014.[34] F. Thabtah, “Machine learning in autistic spectrum disorder behavioralresearch: A review and ways forward,” Informatics for Health andSocial Care, vol. 44, no. 3, pp. 278–297, 2019.[35] D. Eman and A. W. Emanuel, “Machine learning classifiers for autismspectrum disorder: A review,” in 2019 4th International Conference onInformation Technology, Information Systems and Electrical Engineer-ing (ICITISEE).IEEE, 2019, pp. 255–260.[36] “Autism brain imaging data exchange i,” http://fcon 1000.projects.nitrc.org/indi/abide/abide I.html, 2016.[37] “Abide preprocessed,” http://preprocessed-connectomes-project.org/abide/.[38] N. Payakachat, J. M. Tilford, and W. J. Ungar, “National databasefor autism research (ndar): big data opportunities for health servicesresearch and health technology assessment,” Pharmacoeconomics,vol. 34, no. 2, pp. 127–138, 2016.[39] M. Jenkinson, C. F. Beckmann, T. E. Behrens, M. W. Woolrich, andS. M. Smith, “Fsl,” Neuroimage, vol. 62, no. 2, pp. 782–790, 2012.[40] V. Popescu, M. Battaglini, W. Hoogstrate, S. C. Verfaillie, I. Sluimer,R. A. van Schijndel, B. W. van Dijk, K. S. Cover, D. L. Knol, M. Jenk-inson et al., “Optimizing parameter choice for fsl-brain extraction tool(bet) on 3d t1 images in multiple sclerosis,” Neuroimage, vol. 61, no. 4,pp. 1484–1494, 2012.[41] B. Fischl, “Freesurfer,” Neuroimage, vol. 62, no. 2, pp. 774–781, 2012.[42] J. Ashburner, “Computational anatomy with the spm software,” Mag-netic resonance imaging, vol. 27, no. 8, pp. 1163–1174, 2009.[43] H. A. Jaber, H. K. Aljobouri, ˙I. C¸ ankaya, O. M. Koc¸ak, and O. Algin,“Preparing fmri data for postprocessing: Conversion modalities, pre-processing pipeline, and parametric and nonparametric approaches,”IEEE Access, vol. 7, pp. 122 864–122 877, 2019.[44] M. Behroozi, M. R. Daliri, and H. Boyaci, “Statistical analysis methodsfor the fmri data,” Basic and Clinical Neuroscience, vol. 2, no. 4, pp.67–74, 2011.[45] B.-y. Park, K. Byeon, and H. Park, “Funp (fusion of neuroimagingpreprocessing) pipelines: a fully automated preprocessing software forfunctional magnetic resonance imaging,” Frontiers in neuroinformatics,vol. 13, p. 5, 2019.[46] J. A. Maldjian, P. J. Laurienti, R. A. Kraft, and J. H. Burdette, “Anautomated method for neuroanatomic and cytoarchitectonic atlas-basedinterrogation of fmri data sets,” Neuroimage, vol. 19, no. 3, pp. 1233–1239, 2003.[47] N. Tzourio-Mazoyer, B. Landeau, D. Papathanassiou, F. Crivello,O. Etard, N. Delcroix, B. Mazoyer, and M. Joliot, “Automated anatom-ical labeling of activations in spm using a macroscopic anatomicalparcellation of the mni mri single-subject brain,” Neuroimage, vol. 15,no. 1, pp. 273–289, 2002.[48] S. B. Eickhoff, K. E. Stephan, H. Mohlberg, C. Grefkes, G. R.Fink, K. Amunts, and K. Zilles, “A new spm toolbox for combiningprobabilistic cytoarchitectonic maps and functionalimaging data,”Neuroimage, vol. 25, no. 4, pp. 1325–1335, 2005.[49] R. S. Desikan, F. S´egonne, B. Fischl, B. T. Quinn, B. C. Dickerson,D. Blacker, R. L. Buckner, A. M. Dale, R. P. Maguire, B. T. Hymanet al., “An automated labeling system for subdividing the humancerebral cortex on mri scans into gyral based regions of interest,”Neuroimage, vol. 31, no. 3, pp. 968–980, 2006.[50] J. Talairach, “Co-planar stereotaxic atlas ofthe human brain-3-dimensional proportional system,” An approach to cerebral imaging,1988.[51] N. U. Dosenbach, B. Nardos, A. L. Cohen, D. A. Fair, J. D. Power,J. A. Church, S. M. Nelson, G. S. Wig, A. C. Vogel, C. N. Lessov-Schlaggar et al., “Prediction of individual brain maturity using fmri,”Science, vol. 329, no. 5997, pp. 1358–1361, 2010.[52] R. C. Craddock, G. A. James, P. E. Holtzheimer III, X. P. Hu, and H. S.Mayberg, “A whole brain fmri atlas generated via spatially constrainedspectral clustering,” Human brain mapping, vol. 33, no. 8, pp. 1914–1928, 2012.[53] M. Kunda, S. Zhou, G. Gong, and H. Lu, “Improving multi-site autismclassification based on site-dependence minimisation and second-orderfunctional connectivity,” bioRxiv, 2020.[54] “Abidepreprocessing,”//preprocessed-connectomes-project.org/abide/Pipelines.html.preprocessedfunctional-http:[55] P. Bellec, C. Chu, F. Chouinard-Decorte, Y. Benhajali, D. S. Margulies,and R. C. Craddock, “The neuro bureau adhd-200 preprocessed repos-itory,” Neuroimage, vol. 144, pp. 275–286, 2017.[56] C. Yan and Y. Zang, “Dparsf: a matlab toolbox for” pipeline” dataanalysis of resting-state fmri,” Frontiers in systems neuroscience, vol. 4,p. 13, 2010.[57] C. Craddock, S. Sikka, B. Cheung, R. Khanuja, S. S. Ghosh, C. Yan,Q. Li, D. Lurie, J. Vogelstein, R. Burns et al., “Towards automatedanalysis of connectomes: The configurable pipeline for the analysis ofconnectomes (c-pac),” Front Neuroinform, vol. 42, 2013.[58] T. Xu, Z. Yang, L. Jiang, X.-X. Xing, and X.-N. Zuo, “A connectomecomputation system for discovery science of brain,” Science Bulletin,vol. 60, no. 1, pp. 86–95, 2015.[59] N. C. Dvornek, D. Yang, P. Ventola, and J. S. Duncan, “Learning gen-eralizable recurrent neural networks from small task-fmri datasets,” inInternational Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2018, pp. 329–337.[60] T. Eslami and F. Saeed, “Auto-asd-network: a technique based ondeep learning and support vector machines for diagnosing autismspectrum disorder using fmri data,” in Proceedings of the 10th ACMInternational Conference on Bioinformatics, Computational Biologyand Health Informatics, 2019, pp. 646–651.[61] Z. Sherkatghanad, M. Akhondzadeh, S. Salari, M. Zomorodi-Moghadam, M. Abdar, U. R. Acharya, R. Khosrowabadi, and V. Salari,“Automated detection of autism spectrum disorder using a convolu-tional neural network,” Frontiers in Neuroscience, vol. 13, 2019.[62] M. A. Aghdam, A. Sharifi, and M. M. Pedram, “Diagnosis of autismspectrum disorders in young children based on resting-state functionalmagnetic resonance imaging data using convolutional neural networks,”Journal of digital imaging, vol. 32, no. 6, pp. 899–918, 2019.[63] O. Dekhil, H. Hajjdiab, B. Ayinde, A. Shalaby, A. Switala, D. Sosnin,A. Elshamekh, M. Ghazal, R. Keynton, G. Barnes et al., “Using restingstate functional mri to build a personalized autism diagnosis system,”in 2018 IEEE 15th International Symposium on Biomedical Imaging(ISBI 2018).IEEE, 2018, pp. 1381–1385.[64] F. Chollet, Deep Learning mit Python und Keras: Das Praxis-Handbuch vom Entwickler der Keras-Bibliothek. MITP-Verlags GmbH& Co. KG, 2018.[65] L. Zou, J. Zheng, C. Miao, M. J. Mckeown, and Z. J. Wang, “3d cnnbased automatic diagnosis of attention deficit hyperactivity disorderusing functional and structural mri,” IEEE Access, vol. 5, pp. 23 626–23 636, 2017.15[66] A. Radford, L. Metz, and S. Chintala, “Unsupervised representationlearning with deep convolutional generative adversarial networks,”arXiv preprint arXiv:1511.06434, 2015.[67] C. Doersch, “Tutorial on variational autoencoders,” arXiv preprintarXiv:1606.05908, 2016.[68] Z. Che, S. Purushotham, K. Cho, D. Sontag, and Y. Liu, “Recurrentneural networks for multivariate time series with missing values,”Scientific reports, vol. 8, no. 1, pp. 1–12, 2018.[69] J. Wang, Y. Yang, J. Mao, Z. Huang, C. Huang, and W. Xu, “Cnn-rnn: Aunified framework for multi-label image classification,” in Proceedingsof the IEEE conference on computer vision and pattern recognition,2016, pp. 2285–2294.[70] Y. Fan, X. Lu, D. Li, and Y. Liu, “Video-based emotion recognitionusing cnn-rnn and c3d hybrid networks,” in Proceedings of the 18thACM International Conference on Multimodal Interaction, 2016, pp.445–450.[71] M. Chen, X. Shi, Y. Zhang, D. Wu, and M. Guizani, “Deep featureslearning for medical image analysis with convolutional autoencoderneural network,” IEEE Transactions on Big Data, 2017.[72] M. I. U. Haque and D. Valles, “Facial expression recognition usingdcnn and development of an ios app for children with asd to enhancecommunication abilities,” in 2019 IEEE 10th Annual Ubiquitous Com-puting, Electronics & Mobile Communication Conference (UEMCON).IEEE, 2019, pp. 0476–0482.[73] M. I. U. Haque and D. Valles, “Facial expression recognition fromdifferent angles using dcnn for children with asd to identify emotions,”in 2018 International Conference on Computational Science and Com-putational Intelligence (CSCI).IEEE, 2018, pp. 446–449.[74] N. M. Rad, S. M. Kia, C. Zarbo, T. van Laarhoven, G. Jurman,P. Venuti, E. Marchiori, and C. Furlanello, “Deep learning for automaticstereotypical motor movement detection using wearable sensors inautism spectrum disorders,” Signal Processing, vol. 144, pp. 180–191,2018.[75] C. Wu, S. Liaqat, S.-c. Cheung, C.-N. Chuah, and S. Ozonoff, “Predict-ing autism diagnosis using image with fixations and synthetic saccadepatterns,” in 2019 IEEE International Conference on Multimedia &Expo Workshops (ICMEW).IEEE, 2019, pp. 647–650.[76] M. Elbattah, R. Carette, G. Dequen, J.-L. Gu´erin, and F. Cilia,“Learning clusters in autism spectrum disorder: Image-based clusteringof eye-tracking scanpaths with deep autoencoder,” in 2019 41st AnnualInternational Conference of the IEEE Engineering in Medicine andBiology Society (EMBC).IEEE, 2019, pp. 1417–1420.[77] X. Li, N. C. Dvornek, Y. Zhou, J. Zhuang, P. Ventola, and J. S.Duncan, “Efficient interpretation of deep learning models using graphstructure and cooperative game theory: Application to asd biomarkerdiscovery,” in International Conference on Information Processing inMedical Imaging. Springer, 2019, pp. 718–730.[78] Y. Zhao, Q. Dong, S. Zhang, W. Zhang, H. Chen, X. Jiang, L. Guo,X. Hu, J. Han, and T. Liu, “Automatic recognition of fmri-derivedfunctional networks using 3-d convolutional neural networks,” IEEETransactions on Biomedical Engineering, vol. 65, no. 9, pp. 1975–1984, 2017.[79] M. Leming, J. M. G´orriz, and J. Suckling, “Ensemble deep learningon large, mixed-site fmri datasets in autism and other tasks,” arXivpreprint arXiv:2002.07874, 2020.[80] X. Li, N. C. Dvornek, J. Zhuang, P. Ventola, and J. S. Duncan,“Brain biomarker interpretation in asd using deep learning and fmri,” inInternational Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2018, pp. 206–214.[81] M. Khosla, K. Jamison, A. Kuceyeski, and M. R. Sabuncu, “3d convo-lutional neural networks for classification of functional connectomes,”in Deep Learning in Medical Image Analysis and Multimodal Learningfor Clinical Decision Support. Springer, 2018, pp. 137–145.[82] F. Saeed, T. Eslami, V. Mirjalili, A. Fong, and A. Laird, “Asd-diagnet:A hybrid learning approach for detection of autism spectrum disorderusing fmri data,” Frontiers in Neuroinformatics, vol. 13, p. 70, 2019.[83] R. Anirudh and J. J. Thiagarajan, “Bootstrapping graph convolutionalneural networks for autism spectrum disorder classification,” in ICASSP2019-2019 IEEE International Conference on Acoustics, Speech andSignal Processing (ICASSP).IEEE, 2019, pp. 3197–3201.[84] C. J. Brown, J. Kawahara, and G. Hamarneh, “Connectome priorsin deep neural networks to predict autism,” in 2018 IEEE 15thInternational Symposium on Biomedical Imaging (ISBI 2018).IEEE,2018, pp. 110–113.[85] D. Liao and H. Lu, “Classify autism and control based on deep learningand community structure on resting-state fmri,” in 2018 Tenth Interna-16tional Conference on Advanced Computational Intelligence (ICACI).IEEE, 2018, pp. 289–294.[86] X. Yang, S. Sarraf, and N. Zhang, “Deep learning-based framework forautism functional mri image classification,” Journal of the ArkansasAcademy of Science, vol. 72, no. 1, pp. 47–52, 2018.[87] X. Guo, K. C. Dominick, A. A. Minai, H. Li, C. A. Erickson, andL. J. Lu, “Diagnosing autism spectrum disorder from brain resting-state functional connectivity patterns using a deep neural network witha novel feature selection method,” Frontiers in neuroscience, vol. 11,p. 460, 2017.[88] M. Khosla, K. Jamison, A. Kuceyeski, and M. R. Sabuncu, “En-semble learning with 3d convolutional neural networks for functionalconnectome-based prediction,” Neuroimage, vol. 199, pp. 651–662,2019.[89] H. Choi, “Functional connectivity patterns of autism spectrum disorderidentified by deep feature learning,” arXiv preprint arXiv:1707.07932,2017.[90] N. C. Dvornek, P. Ventola, K. A. Pelphrey, and J. S. Duncan, “Iden-tifying autism from resting-state fmri using long short-term memorynetworks,” in International Workshop on Machine Learning in MedicalImaging. Springer, 2017, pp. 362–370.[91] H. Lu, S. Liu, H. Wei, and J. Tu, “Multi-kernel fuzzy clustering basedon auto-encoder for fmri functional network,” Expert Systems withApplications, p. 113513, 2020.[92] Z. Xiao, C. Wang, N. Jia, and J. Wu, “Sae-based classification ofschool-aged children with autism spectrum disorders using functionalmagnetic resonance imaging,” Multimedia Tools and Applications,vol. 77, no. 17, pp. 22 809–22 820, 2018.[93] N. C. Dvornek, X. Li, J. Zhuang, and J. S. Duncan, “Jointly discrimina-tive and generative recurrent neural networks for learning from fmri,”in International Workshop on Machine Learning in Medical Imaging.Springer, 2019, pp. 382–390.[94] K. Niu, J. Guo, Y. Pan, X. Gao, X. Peng, N. Li, and H. Li, “Multichan-nel deep attention neural networks for the classification of autism spec-trum disorder using neuroimaging and personal characteristic data,”Complexity, vol. 2020, 2020.[95] H. Li, N. A. Parikh, and L. He, “A novel transfer learning approachto enhance deep neural network classification of brain functionalconnectomes,” Frontiers in neuroscience, vol. 12, p. 491, 2018.[96] A. El Gazzar, L. Cerliani, G. van Wingen, and R. M. Thomas, “Simple1-d convolutional networks for resting-state fmri based classification inautism,” in 2019 International Joint Conference on Neural Networks(IJCNN).IEEE, 2019, pp. 1–6.[97] M. R. Ahmed, Y. Zhang, Y. Liu, and H. Liao, “Single volume imagegenerator and deep learning-based asd classification,” IEEE Journal ofBiomedical and Health Informatics, 2020.[98] Y. Zhao, H. Dai, W. Zhang, F. Ge, and T. Liu, “Two-stage spatial tem-poral deep learning framework for functional brain network modeling,”in 2019 IEEE 16th International Symposium on Biomedical Imaging(ISBI 2019).IEEE, 2019, pp. 1576–1580.[99] B. Pugazhenthi, G. Senapathy, and M. Pavithra, “Identification ofautism in mr brain images using deep learning networks,” in 2019International Conference on Smart Structures and Systems (ICSSS).IEEE, 2019, pp. 1–7.[100] T. Eslami, J. S. Raiker, and F. Saeed, “Explainable and scalablemachine-learning algorithms for detection of autism spectrum disorderusing fmri data,” arXiv preprint arXiv:2003.01541, 2020.[101] K. Sairam, J. Naren, G. Vithya, and S. Srivathsan, “Computer aidedsystem for autism spectrum disorder using deep learning methods,”International Journal of Psychosocial Rehabilitation, vol. 23, no. 01,2019.[102] J. Dolz, C. Desrosiers, and I. B. Ayed, “3d fully convolutional networksfor subcortical segmentation in mri: A large-scale study,” NeuroImage,vol. 170, pp. 456–470, 2018.[103] C. Wang, Z. Xiao, B. Wang, and J. Wu, “Identification of autism basedon svm-rfe and stacked sparse auto-encoder,” IEEE Access, vol. 7, pp.118 030–118 036, 2019.[104] Y. Zhao, F. Ge, S. Zhang, and T. Liu, “3d deep convolutional neuralnetwork revealed the value of brain network overlap in differentiatingautism spectrum disorder from healthy controls,” in InternationalConference on Medical Image Computing and Computer-AssistedIntervention. Springer, 2018, pp. 172–180.[105] S. Parisot, S. I. Ktena, E. Ferrante, M. Lee, R. Guerrero, B. Glocker,and D. Rueckert, “Disease prediction using graph convolutional net-works: Application to autism spectrum disorder and alzheimer’s dis-ease,” Medical image analysis, vol. 48, pp. 117–130, 2018.[106] N. C. Dvornek, P. Ventola, and J. S. Duncan, “Combining phenotypicand resting-state fmri data for autism classification with recurrentneural networks,” in 2018 IEEE 15th International Symposium onBiomedical Imaging (ISBI 2018).IEEE, 2018, pp. 725–728.[107] A. S. Heinsfeld, A. R. Franco, R. C. Craddock, A. Buchweitz, andF. Meneguzzi, “Identification of autism spectrum disorder using deeplearning and the abide dataset,” NeuroImage: Clinical, vol. 17, pp. 16–23, 2018.[108] X. Li, J. Hect, M. Thomason, and D. Zhu, “Interpreting age effects ofhuman fetal brain from spontaneous fmri using deep 3d convolutionalneural networks,” in 2020 IEEE 17th International Symposium onBiomedical Imaging (ISBI).IEEE, 2020, pp. 1424–1427.[109] M. A. Aghdam, A. Sharifi, and M. M. Pedram, “Combination of rs-fmri and smri data to discriminate autism spectrum disorders in youngchildren using deep belief network,” Journal of digital imaging, vol. 31,no. 6, pp. 895–903, 2018.[110] C. Mellema, A. Treacher, K. Nguyen, and A. Montillo, “Multiple deeplearning architectures achieve superior performance diagnosing autismspectrum disorder using features previously extracted from structuraland functional mri,” in 2019 IEEE 16th International Symposium onBiomedical Imaging (ISBI 2019).IEEE, 2019, pp. 1891–1895.[111] M. Raki´c, M. Cabezas, K. Kushibar, A. Oliver, and X. Llad´o, “Improv-ing the detection of autism spectrum disorder by combining structuraland functional mri information,” NeuroImage: Clinical, vol. 25, p.102181, 2020.[112] G. Li, M. Liu, Q. Sun, D. Shen, and L. Wang, “Early diagnosis ofautism disease by multi-channel cnns,” in International Workshop onMachine Learning in Medical Imaging. Springer, 2018, pp. 303–309.[113] G. Li, M.-H. Chen, G. Li, D. Wu, Q. Sun, D. Shen, and L. Wang,“A preliminary volumetric mri study of amygdala and hippocampalsubfields in autism during infancy,” in 2019 IEEE 16th InternationalSymposium on Biomedical Imaging (ISBI 2019).IEEE, 2019, pp.1052–1056.[114] M. Ismail, G. Barnes, M. Nitzken, A. Switala, A. Shalaby, E. Hosseini-Asl, M. Casanova, R. Keynton, A. Khalil, and A. El-Baz, “A newdeep-learning approach for early detection of shape variations in autismusing structural mri,” in 2017 IEEE International Conference on ImageProcessing (ICIP).IEEE, 2017, pp. 1057–1061.[115] Y. Kong, J. Gao, Y. Xu, Y. Pan, J. Wang, and J. Liu, “Classificationof autism spectrum disorder by combining brain connectivity and deepneural network classifier,” Neurocomputing, vol. 324, pp. 63–68, 2019.[116] W. H. Pinaya, A. Mechelli, and J. R. Sato, “Using deep autoencodersto identify abnormal brain structural patterns in neuropsychiatric disor-ders: A large-scale multi-sample study,” Human brain mapping, vol. 40,no. 3, pp. 944–954, 2019.[117] S. J. Sujit, I. Coronado, A. Kamali, P. A. Narayana, and R. E. Gabr,“Automated image quality evaluation of structural brain mri using anensemble of deep learning networks,” Journal of Magnetic ResonanceImaging, vol. 50, no. 4, pp. 1260–1267, 2019.[118] L. Henschel, S. Conjeti, S. Estrada, K. Diers, B. Fischl, and M. Reuter,“Fastsurfer-a fast and accurate deep learning based neuroimagingpipeline,” NeuroImage, p. 117012, 2020.[119] H. Shahamat and M. S. Abadeh, “Brain mri analysis using a deeplearning based volutionary approach,” Neural Networks, 2020.[120] J. E. Iglesias, G. Lerma-Usabiaga, L. C. Garcia-Peraza-Herrera, S. Mar-tinez, and P. M. Paz-Alonso, “Retrospective head motion estimationin structural brain mri with 3d cnns,” in International Conferenceon Medical Image Computing and Computer-Assisted Intervention.Springer, 2017, pp. 314–322.[121] K. Byeon, J. Kwon, J. Hong, and H. Park, “Artificial neural networkinspired by neuroimaging connectivity: Application in autism spectrumdisorder,” in 2020 IEEE International Conference on Big Data andSmart Computing (BigComp).IEEE, 2020, pp. 575–578.[122] L. Xu, Y. Liu, J. Yu, X. Li, X. Yu, H. Cheng, and J. Li, “Characterizingautism spectrum disorder by deep learning spontaneous brain activityfrom functional near-infrared spectroscopy,” Journal of NeuroscienceMethods, vol. 331, p. 108538, 2020.[123] L. Xu, X. Geng, X. He, J. Li, and J. Yu, “Prediction in autism by deeplearning short-time spontaneous hemodynamic fluctuations,” Frontiersin Neuroscience, vol. 13, 2019.[124] B. Thyreau and Y. Taki, “Learning a cortical parcellation of the brainrobust to the mri segmentation with convolutional neural networks,”Medical Image Analysis, vol. 61, p. 101639, 2020.[125] R. M. Thomas, S. Gallo, L. Cerliani, P. Zhutovsky, A. El-Gazzar,and G. van Wingen, “Classifying autism spectrum disorder usingthe temporal statistics of resting-state functional mri data with 3dconvolutional neural networks,” Frontiers in Psychiatry, vol. 11, p. 440,2020.the 2020 ACM/IEEE International Conference on Human-Robot Inter-action, 2020, pp. 275–277.17[144] K. Sun, L. Li, L. Li, N. He, and J. Zhu, “Spatial attentional bilinear3d convolutional network for video-based autism spectrum disorderdetection,” in ICASSP 2020-2020 IEEE International Conference onAcoustics, Speech and Signal Processing (ICASSP).IEEE, 2020, pp.3387–3391.[145] H. Wang, L. Li, L. Chi, and Z. Zhao, “Autism screening using deepembedding representation,” in International Conference on Computa-tional Science. Springer, 2019, pp. 160–173.[146] M. F. Misman, A. A. Samah, F. A. Ezudin, H. A. Majid, Z. A.Shah, H. Hashim, and M. F. Harun, “Classification of adults withautism spectrum disorder using deep neural network,” in 2019 1stInternational Conference on Artificial Intelligence and Data Sciences(AiDAS).IEEE, 2019, pp. 29–34.[126] A. El-Gazzar, M. Quaak, L. Cerliani, P. Bloem, G. van Wingen, andR. M. Thomas, “A hybrid 3dcnn and 3dc-lstm based model for 4dspatio-temporal fmri data: An abide autism classification study,” inOR 2.0 Context-Aware Operating Theaters and Machine Learning inClinical Neuroimaging. Springer, 2019, pp. 95–102.[127] S. Mostafa, W. Yin, and F.-X. Wu, “Autoencoder based methods fordiagnosis of autism spectrum disorder,” in International Conferenceon Computational Advances in Bio and Medical Sciences. Springer,2019, pp. 39–51.[128] Z. Jiao, H. Li, and Y. Fan, “Improving diagnosis of autism spectrumdisorder and disentangling its heterogeneous functional connectivitypatterns using capsule networks,” in 2020 IEEE 17th InternationalSymposium on Biomedical Imaging (ISBI).IEEE, 2020, pp. 1331–1334.[129] J. Xie, L. Wang, P. Webster, Y. Yao, J. Sun, S. Wang, and H. Zhou,“A two-stream end-to-end deep learning network for recognizingatypical visual attention in autism spectrum disorder,” arXiv preprintarXiv:1911.11393, 2019.[130] S. Sadiq, M. Castellanos, J. Moffitt, M.-L. Shyu, L. Perry, andD. Messinger, “Deep learning based multimedia data mining for autismspectrum disorder (asd) diagnosis,” in 2019 International Conferenceon Data Mining Workshops (ICDMW).IEEE, 2019, pp. 847–854.[131] Y. Tao and M.-L. Shyu, “Sp-asdnet: Cnn-lstm based asd classificationmodel using observer scanpaths,” in 2019 IEEE International Confer-ence on Multimedia & Expo Workshops (ICMEW).IEEE, 2019, pp.641–646.[132] J. R. H. Lee and A. Wong, “Timeconvnets: A deep time windowedconvolution neural network design for real-time video facial expressionrecognition,” in 2020 17th Conference on Computer and Robot Vision(CRV).IEEE, 2020, pp. 9–16.[133] A. Vijayan, S. Janmasree, C. Keerthana, and L. B. Syla, “A frameworkfor intelligent learning assistant platform based on cognitive computingfor children with autism spectrum disorder,” in 2018 International CETConference on Control, Communication, and Computing (IC4).IEEE,2018, pp. 361–365.[134] A. Di Nuovo, D. Conti, G. Trubia, S. Buono, and S. Di Nuovo,“Deep learning systems for estimating visual attention in robot-assistedtherapy of children with autism and intellectual disability,” Robotics,vol. 7, no. 2, p. 25, 2018.[135] N. M. Rad, S. M. Kia, C. Zarbo, T. van Laarhoven, G. Jurman,P. Venuti, E. Marchiori, and C. Furlanello, “Deep learning for automaticstereotypical motor movement detection using wearable sensors inautism spectrum disorders,” Signal Processing, vol. 144, pp. 180–191,2018.[136] S. Jaiswal, M. F. Valstar, A. Gillott, and D. Daley, “Automatic detectionof adhd and asd from expressive behaviour in rgbd data,” in 201712th IEEE International Conference on Automatic Face & GestureRecognition (FG 2017).IEEE, 2017, pp. 762–769.[137] Y.-S. Liu, C.-P. Chen, S. S.-F. Gau, and C.-C. Lee, “Learning lexicalcoherence representation using lstm forget gate for children with autismspectrum disorder during story-telling,” in 2018 IEEE InternationalConference on Acoustics, Speech and Signal Processing (ICASSP).IEEE, 2018, pp. 6029–6033.[138] J. Li, Y. Zhong, J. Han, G. Ouyang, X. Li, and H. Liu, “Classifyingasd children with lstm based on raw videos,” Neurocomputing, 2019.[139] W. Wei, Z. Liu, L. Huang, A. Nebout, and O. Le Meur, “Saliencyprediction via multi-level features and deep supervision for childrenwith autism spectrum disorder,” in 2019 IEEE International Conferenceon Multimedia & Expo Workshops (ICMEW).IEEE, 2019, pp. 621–624.[140] S. Raj and S. Masood, “Analysis and detection of autism spectrum dis-order using machine learning techniques,” Procedia Computer Science,vol. 167, pp. 994–1004, 2020.[141] O. Rudovic, Y. Utsumi, J. Lee, J. Hernandez, E. C. Ferrer, B. Schuller,and R. W. Picard, “Culturenet: A deep learning approach for engage-ment intensity estimation from face images of children with autism,”in 2018 IEEE/RSJ International Conference on Intelligent Robots andSystems (IROS).IEEE, 2018, pp. 339–346.[142] A. Cook, B. Mandal, D. Berry, and M. Johnson, “Towards automaticscreening of typical and atypical behaviors in children with autism,” in2019 IEEE International Conference on Data Science and AdvancedAnalytics (DSAA).IEEE, 2019, pp. 504–510.[143] H. Javed and C. H. Park, “Behavior-based risk detection of autismspectrum disorder through child-robot interaction,” in Companion of