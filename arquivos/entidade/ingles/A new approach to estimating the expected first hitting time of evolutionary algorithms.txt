Artificial Intelligence 172 (2008) 1809–1832Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA new approach to estimating the expected first hitting timeof evolutionary algorithmsYang Yu, Zhi-Hua Zhou∗National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 12 December 2007Received in revised form 8 July 2008Accepted 9 July 2008Available online 12 July 2008Keywords:Evolutionary algorithmsExpected first hitting timeConvergence rateComputational complexity1. IntroductionEvolutionary algorithms (EA) have been shown to be very effective in solving practicalproblems, yet many important theoretical issues of them are not clear. The expected firsthitting time is one of the most important theoretical issues of evolutionary algorithms,since it implies the average computational time complexity. In this paper, we establisha bridge between the expected first hitting time and another important theoreticalissue, i.e., convergence rate. Through this bridge, we propose a new general approach toestimating the expected first hitting time. Using this approach, we analyze EAs withdifferent configurations, including three mutation operators, with/without population, arecombination operator and a time variant mutation operator, on a hard problem. Theresults show that the proposed approach is helpfulfor analyzing a broad range ofevolutionary algorithms. Moreover, we give an explanation of what makes a problem hardto EAs, and based on the recognition, we prove the hardness of a general problem.© 2008 Published by Elsevier B.V.Evolutionary algorithms (EAs) are a kind of optimization technique, inspired by the natural evolution process. Despitemany different implementations [1], e.g., genetic algorithm, genetic programming and evolutionary strategies, traditional evolu-tionary algorithms can be summarized below by four steps:(1) Generate an initial population of random solutions;(2) Reproduce new solutions based on the current population;(3) Remove relatively poor solutions in the population;(4) Repeat from Step 2 until a stop criterion is satisfied.In the evolutionary process, a population of randomly initialized solutions is maintained and evolved. Mutation and re-combination are two popular operators for reproduction in Step 2. A fitness function is employed to guide Step 3. Theevolutionary repetition stops when, e.g., an optimal solution is found or time runs out.EAs solve problems in straightforward ways and do not require, for example, continuous or differentiable functions orinversable matrices. So, EAs have been applied to bioinformatics [17], circuit design [3], data mining [9], information retrieval[4], etc. Despite the remarkable success achieved by EAs on practice problems, EAs are often criticized for the lack of a solidtheoretical foundation. Actually, such a theoretical foundation is very desired in order to gain deep understanding of thestrength and weakness of current EAs and thus develop better EAs.* Corresponding author.E-mail address: zhouzh@nju.edu.cn (Z.-H. Zhou).0004-3702/$ – see front matter © 2008 Published by Elsevier B.V.doi:10.1016/j.artint.2008.07.0011810Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832The first hitting time of EAs is the time that, in a run, EAs find an optimal solution for the first time, and the expected firsthitting time (EFHT) is the average time that EAs require to find an optimal solution, which implies the average computationaltime complexity of EAs. It is evident that the EFHT is one of the most important theoretical issues of EAs.Many papers have been devoted to the analysis of simple EAs. The (1 + 1)-EA, i.e., EA without population, has beenstudied on the long path problem [22], the OneMax problem [23], the uni-model functions [5,7] and linear functions [6,7].Another EA without population has been studied on the OneMax problem [10]. More details can be found in Beyer et al.’ssurvey [2]. Owing to these efforts, several theoretical properties of EAs become more clear. In these works, however, adhoc approaches were used to analyze simple EAs on simple problems, yet a general approach that can be used to analyzewider kinds of EAs to gain deeper insights is more desired. Recently, several works [13–15] have been devoted to developinggeneral analysis approaches, which are summarized in the latest survey [19].He and Yao [13,15] have developed a general approach to analyzing a wide class of EAs based on drift analysis [11], whichis a significant advance. Intuitively, if we know the length of the whole path toward the optimum and the length of thedrift of the EA at each step, we can estimate the EFHT by dividing the path length by the step drift. However, no practicalmeasure of these quantities is known.He and Yao [14] have developed another framework based on the analytical solution of EFHT to analyze and compareEAs. Under this framework, two hard problem classes (i.e., problems that can only be solved in exponential time), the‘wide gap’ problem class and the ‘long path’ problem class, were identified. Since the analytical framework is derived fromhomogeneous Markov chain models, only EAs with static reproduction operators can be analyzed, although EAs with time-variant operators or adaptive operators are very popular and powerful [8].The convergence rate is another important theoretical issue of EAs, which implies how close the current state is to theoptimal area at each step. The convergence issue has been studied for years [12,16,21,23,25]. He and Yu [16] did a thoroughstudy based on the minorization method [20].In this paper, we present the first study on the relationship between the EFHT and the convergence rate, and establisha bridge between them. Through this bridge, we propose a new general approach to estimating the expected first hittingtime. In contrast to previous researches where easy problems (i.e., problems that can be solved in polynomial time) [6,15,23] were studied, we use the proposed approach to analyze EAs on a hard problem. The analyzed EAs involve variousconfigurations, including three mutation operators, with/without population, a recombination operator and a time variantmutation operator. The results show that the proposed approach is helpful for analyzing a broad range of EAs. Moreover,we give an explanation of what makes a problem hard to an EA, and based on the recognition, we prove the hardness of ageneral problem.The rest of this paper is organized as follows. In Section 2, we briefly review some related work and introduce how tomodel EAs using Markov chains. In Section 3, we introduce a new approach to estimating the EFHT, which is the main resultof this paper. In Section 4, we analyze several EAs on a hard problem using the proposed approach, which is followed bydiscussions in Section 5. Finally, in Section 6, we conclude the paper.2. Modeling EAs using Markov chainEAs evolve solutions from generation to generation. Each generation stochastically depends on the previous one, exceptthe initial generation which is randomly generated. This conditional independence can be modeled natually by Markov chains[12–14,18,24,25].Combinatorial optimization problems are among the most common problems in practice, whose solutions can be repre-sented by a sequence of symbols. In this paper, we use EAs to tackle them. To model this kind of EAs, we construct Markovchains with discrete state space. The key to construct such a Markov chain is to bijectively map the populations of an EAto the states of the Markov chain. A popular mapping [12,16,25] enables one state of the Markov chain to correspond toone possible population of the EA. Suppose an EA encodes a solution in a vector of length L, each component of the vectoris drawn from an alphabet set B, and each population contains M solutions. Let S denote the solution space. There are|S| = |B|L number of different solutions. Let X denote the population space. There are | X| =number of differentpossible populations [25]. A Markov chain which models the EA is constructed by taking X as the state space, i.e., a chain{ξt}+∞t=0 is built where ξt ∈ X .A population is called an optimal population if it contains at least one optimal solution. Let X∗ (∈ X) denote the set of all∗from an initial population. Thus, the process of an EA which seeks XM+|B|L −1M(cid:3)(cid:2)∗optimal populations. The goal of EAs is to reach Xcan be analyzed by studying the corresponding Markov chain [12,16].In the rest of this section, we introduce several notations and definitions. Given a Markov chain {ξt}+∞t=0 (ξt ∈ X) and atarget subspace X(cid:4)μt =∗ ⊂ X , let μt (t = 0, 1, . . .) denote the probability of ξt being in XP (ξt = x).∗, i.e.,x∈ X ∗Definition 1 (Convergence). Given a Markov chain {ξt}+∞to Xif∗t=0 (ξt ∈ X) and a target subspace Xlimt→+∞μt = 1.(1)∗ ⊂ X , {ξt}+∞t=0 is said to converge(2)Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18321811In [16], convergence rate is measured by 1 − μt at step t, which is equivalent to that used in [25]. Therefore, we also use1 − μt as the measure of convergence rate in this paper.Definition 2 (Convergence rate). Given a Markov chain {ξt}+∞to Xat time t is 1 − μt .∗t=0 (ξt ∈ X) and a target subspace X∗ ⊂ X , the convergence rateDefinition 3 (Absorbing Markov chain). Given a Markov chain {ξt }+∞be an absorbing chain, ift=0 (ξt ∈ X) and a target subspace X∀t ∈ {0, 1, . . .}:P(cid:2)ξt+1 /∈ X(cid:3)∗ | ξt ∈ X∗= 0.∗ ⊂ X , {ξt}+∞t=0 is said to(3)We use absorbing Markov chains to model all the EAs studied in this paper, because absorbing Markov chains have goodtheoretical properties and can be practically achieved. An EA can be modeled by an absorbing Markov chain if it neverloses an optimal solution once found. Actually, most EAs for real problems satisfy this condition because, if an optimalsolution can be identified, the EA will stop when it finds them; otherwise, when optimal solutions cannot be identified,the commonly used strategy of keeping the best-so-far solution in every generation can make the condition be satisfied.Moreover, EAs that can be modeled by absorbing Markov chains converge to optimal solutions with certain operators [16],which is a desirable property in practice.Definition 4 (Expected first hitting time, EFHT). Given a Markov chain {ξt}+∞random variable τ denote the eventst=0 (ξt ∈ X) and a target subspace X∗ ⊂ X , let aτ = 0: ξ0 ∈ Xτ = 1: ξ1 ∈ Xτ = 2: ξ2 ∈ X∗,∗ ∧ ξi /∈ X∗ ∧ ξi /∈ X∗∗. . .τ = t: ξt ∈ X∗ ∧ ξi /∈ X∗(i = 0),(cid:2)∀i ∈ {0, 1}(cid:3),(cid:2)∀i ∈ {0, 1, . . . , t − 1}(cid:3), . . . .The mathematical expectation of τ , E[τ ], is called the expected first hitting time (EFHT) of the Markov chain.This definition of EFHT is equivalent to those used in [13,14]. The EFHT of an EA is the average time in which it finds anoptimal solution, which is its average computational time complexity.Markov chains model the essential of the corresponding EA processes, thus the convergence, convergence rate and EFHTof EAs can be obtained by analyzing the corresponding Markov chains. So, in the rest of the paper, we do not distinguishthe convergence, convergence rate and EFHT of EAs and those of the corresponding Markov chains.3. Deriving expected first hitting time from convergence rateThe convergence rate has been studied for many years [12,25] and recently a general bound has been developed in [16]through the minorization condition method [20]. Since we focus on using EAs to solve combinatorial optimization problemsin this paper, a discrete space version of Theorem 4 in [16] is proven below.Lemma 1. Given an absorbing Markov chain {ξt}+∞satisfyt=0 (ξt ∈ X) and a target subspace X∗ ⊂ X , if two sequences {αt}+∞t=0 and {βt}+∞t=0+∞(cid:5)t=0(1 − αt) = 0andβt (cid:2)(cid:4)x /∈ X ∗(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:3) P (ξt = x)1 − μt(cid:2) αt,then the chain converges to X∗and the convergence rate is bounded by(1 − μ0)t−1(cid:5)i=0(1 − αi) (cid:2) 1 − μt (cid:2) (1 − μ0)t−1(cid:5)i=0(1 − βi).(4)(5)(6)1812Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832Proof. From Eqs. (1) and (3), it follows that(cid:4)(cid:3)∗ | ξt−1 = xμt − μt−1 =(cid:2)ξt ∈ XPP (ξt−1 = x),x /∈ X ∗and by applying Eq. (5) we get(1 − μt−1)αt−1 (cid:3) μt − μt−1 (cid:3) (1 − μt−1)βt−1,(1 − μt−1)(1 − αt−1) (cid:2) 1 − μt (cid:2) (1 − μt−1)(1 − βt−1),by applying this inequality recursively, we have(1 − μ0)t−1(cid:5)i=0(1 − αi) (cid:2) 1 − μt (cid:2) (1 − μ0)t−1(cid:5)i=0(1 − βi).(cid:2)Lemma 1 implies that as far as the probability of an EA ‘jumping’ into the set of optimal solutions can be estimatedfor each step, the bounds of its convergence rate can be derived. The only requirement is that the EA can be modeled byan absorbing Markov chain, i.e., the EA satisfies Eq. (3). As mentioned before, most EAs used in real problems meet thisrequirement.In Definition 4, the EFHT is the mathematical expectation of the random variable τ . Meanwhile, the probability distribu-tion of τ is the probability of an optimal solution being found before step t (t = 0, 1, . . .). Thus, as long as the EA can bemodeled by an absorbing Markov chain, it holds thatμt+1 − μt =(cid:4)x∈ X ∗P (ξt+1 = x) −(cid:4)x∈ X ∗P (ξt = x)= P (τ = t + 1).This implies that the probability distribution of τ is equal to μt , which is one minus the convergence rate. So, the conver-gence rate and the EFHT are two sides of a coin.Meanwhile, the bounds of the probability distribution and bounds of the expectation of the same random variable havea relationship shown in Lemma 2.Lemma 2. Let u and v denote two discrete random variables that are nonnegative integers with limited expectation, and D u(·) andD v (·) denote their distribution functions, respectively, i.e.,D u(t) = P (u (cid:3) t) =D v (t) = P (v (cid:3) t) =t(cid:4)i=0t(cid:4)i=0P (u = i),P (v = i).If D u(t) (cid:2) D v (t) (∀t = 0, 1, . . .), then the expectations of the random variables satisfyE[u] (cid:3) E[v],where E[u] =(cid:6)t=0,1,... t P (u = t) and E[v] =(cid:6)t=0,1,... t P (v = t).(7)Proof. Since D u is the distribution of u,E[u] = 0 · D u(0) +(cid:2)(cid:3)D u(t) − D u(t − 1)t+∞(cid:4)t=1==+∞(cid:4)+∞(cid:4)(cid:2)(cid:3)D u(t) − D u(t − 1)i=1+∞(cid:4)t=i(cid:7)limt→+∞i=0(cid:8)D u(t) − D u(i)+∞(cid:4)(cid:3)(cid:2)1 − D u(i),=i=0and same for v. Thus,Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18321813E[u] − E[v] =+∞(cid:4)(cid:2)(cid:3)1 − D u(i)+∞(cid:4)(cid:2)(cid:3)1 − D v (i)−i=0+∞(cid:4)(cid:2)i=0(cid:3)D v (i) − D u(i)=i=0(cid:3) 0.(cid:2)Since one minus the convergence rate is the probability distribution of τ , and the EFHT is the expectation of τ , Lemma 2reveals that the lower/upper bounds of the EFHT can be derived from the upper/lower bounds of the convergence rate.Thus, based on Lemmas 1 and 2, a pair of general bounds of the EFHT in Theorem 1 can be obtained.Theorem 1. Given an absorbing Markov chain {ξt}+∞satisfyt=0 (ξt ∈ X) and a target subspace X∗ ⊂ X , if two sequences {αt}+∞t=0 and {βt}+∞t=0+∞(cid:5)t=0(1 − αt) = 0andβt (cid:2)(cid:4)x /∈ X ∗(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:3) P (ξt = x)1 − μt(cid:2) αt,then the chain converges and, starting from non-optimal solutions, the EFHT is bounded byE[τ ] (cid:3) α0 +andE[τ ] (cid:2) β0 ++∞(cid:4)t=2+∞(cid:4)t=2tαt−1t−2(cid:5)i=0(1 − αi)tβt−1t−2(cid:5)i=0(1 − βi).Proof. Applying Lemma 1 with Eq. (9), we have1 − μt (cid:3) (1 − μ0)t−1(cid:5)i=0(1 − αi).(8)(9)(10)(11)Considering that μt expresses the distribution of τ , i.e., μt = Dτ (t), we can get the lower bound of Dτ (t) as(cid:9)Dτ (t) (cid:2)μ01 − (1 − μ0)(cid:10)t−1i=0(1 − αi)t = 0,t = 1, 2, . . . .Imagine a virtual random variable η whose distribution equals the lower bound of Dτ . The expectation of η is(cid:13)t ·(1 − μ0)+∞(cid:4)(cid:12)+t=2t−2(cid:5)(1 − αi) − (1 − μ0)t−1(cid:5)i=0i=0(cid:14)(1 − αi)E[η] = 0 · μ0 + 1 ·(cid:11)1 − (1 − α0)(1 − μ0) − μ0(1 − αi)(1 − μ0).(cid:13)=α0 ++∞(cid:4)t=2t−2(cid:5)tαt−1i=0(cid:13)+∞(cid:4)t=2t−2(cid:5)tαt−1i=0(cid:14)(cid:14)E[τ ] (cid:3)α0 +(1 − αi)(1 − μ0).Since Dτ (t) (cid:2) Dη(t), according to Lemma 2, E[τ ] (cid:3) E[η]. Thus, the upper bound of the EFHT isNote that the EA is assumed to start from non-optimal solutions, i.e., μ0 = 0.The lower bound of the EFHT can be derived similarly. (cid:2)Two points in Theorem 1 remain to be clarified. Firstly, ‘starting from non-optimal solutions’ is just a theoretical assump-tion that is used to make the result easy to read. Practically, for the problems where EAs are applied, the probability of arandomly generated solution being optimal is exponentially small. In such case, this assumption will not affect the result ofthe asymptotic analysis. Secondly, Theorem 1 is written in a compact form, i.e., we will have both lower and upper bounds1814Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832of the EFHT if we have both βt and αt in Eq. (9). Actually, it is also applicable when we only have one of them. We willhave a lower bound of the EFHT if we have βt , and we will have an upper bound of the EFHT if we have αt .The bounds of EFHT, i.e., Eqs. (10) and (11), have an intuitive explanation. The part αt−1t−2i=0(1 − αi) (or replacing αby β) indicates the probability of the event that the EA finds an optimal solution at the tth step, but does not find it at anyearlier step.(cid:10)Theorem 1 shows that we can have bounds of the EFHT from the bounds of the formula(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:3) P (ξt = x)1 − μt.(12)(cid:4)x /∈ X ∗∗ | ξt = x) is the probability of the EA ‘jumping’ into an optimal population, whichThe first part of the formula P (ξt+1 ∈ Xwe call as success probability. The second part P (ξt =x)is a normalized distribution over non-optimal states. As long as these1−μttwo parts are estimated, the bounds of the EFHT can be derived. The more accurate the estimated probability, the tighterthe derived bounds.4. Case study on a hard problemIn this section, we will prove that the Trap problem is hard (i.e., can only be solved in exponential time) for several EAs,using our proposed approach. The Trap problem is defined below.Definition 5 (Trap problem). Given a set of n positive values, i.e., W = {w i}n∗i=1, and a capacity value c, to find xfrom∗ = arg maxxx∈{0,1}nn(cid:4)i=1w i · xis.t.n(cid:4)i=1w i · xi (cid:3) c,where w 1 = w 2 = · · · = wn−1 > 1, wn = ((cid:6)n−1i=1 w i) + 1 and c = wn.Trap problem has one optimal solution x∗ = (000 . . . 01). A solution is a feasible solution if it satisfies the constraint,otherwise it is an infeasible solution.We try to tackle the Trap problem using several EAs which are configured commonly as below. The Reproduction will beimplemented by concrete operators later.• Encoding: Each solution is encoded by a string with n binary bits, where the ith bit is 1 if w iis included and 0otherwise.• Initial: Randomly generate a population of M solutions encoded by binary strings.• Reproduction: Generate M new solutions from the current population.• Selection: Select the best M solutions among the current population and the reproduced solutions, which is also calledplus-selection, to form the population of the next generation. The selected M solutions are with the best fitness value(according to the definition below).• Fitness: The fitness of a solution x = (x1x2 . . . xn) is defined asFitness(x) = θn(cid:4)i=1w i xi − c,(13)where θ = 1 when x is a feasible solution, i.e.,maximized, and the larger the fitness is, the better the solution is. Here, the maximum fitness value is zero.i=1 w i xi (cid:3) c, and θ = 0 otherwise. The fitness function is to be• Stop criterion: If the largest fitness value in population is zero, stop and output the solution with the maximum fitness.(cid:6)nTo implement the Reproduction operator, we use several popular operators, listed below.Mutation#1 (bitwise mutation with constant probability): Independently flip each bit of each solution with an constantprobability pm ∈ (0, 0.5].Mutation#2 (bitwise mutation with probability 1/n): Independently flip each bit of each solution with probability pm = 1n .This may be the most commonly used mutation operator.Mutation#3 (one-bit mutation): Randomly flip one bit of each solution.Mutation#4 (time-variant mutation): Independently flip each bit of each solution with probability (0.5 − d)ed ∈ (0, 0.5] and t = 0, 1, . . . .−t + d, whereRecombination (one-point crossover): Exchange the leading σ bits of randomly selected two solutions, where σ is drawnrandomly from {1, 2, . . . , n − 1}.Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18321815Mutation#1 seems like a special case of Mutation#2. However, there is a significant difference, that is, the mutation prob-ability of Mutation#2 is adapted to the problem size while that of Mutation#1 is a constant. So, the asymptotic behaviors,as n → +∞, of the two are different.To focus on the order of the asymptotic complexity of EFHT of EAs, we use the Ω(·) representation. For two functionsf (·) and g(·), we write f (n) = Ω(g(n)) to represent that g(n) is an asymptotic lower bound of f (n), if and only iflimn→+∞f (n)g(n)> 0,and meanwhile, we write g(n) = O ( f (n)).4.1. Static mutation without populationFirst, we show how the three static mutation operators, Mutations #1, #2 and #3, perform on the Trap problem, withpopulation size 1, that is, (1 + 1)-EA. Since a population is equal to a solution, the population state space is equal to thesolution state space, i.e., X = S.Proposition 1. Solving the Trap problem using the EA with Reproduction implemented by Mutation#1 (bitwise mutation with constantprobability) and with a population size 1, i.e. (1 + 1)-EA, if starting from non-optimal populations, the EFHT is bounded byE[τ ] = Ω(θ n),where θ = (1 − pm)−1 ∈ (1, 2] is a constant and n is the problem size.(14)To prove this proposition, we need to find an upper bound of formula (12) applying Theorem 1. We first investigate the∗ | ξt = x). Assuming a solution has k bits different from the optimalpart of success probability of formula (12), P (ξt+1 ∈ Xm(1 − pm)n−k using Mutation#1. Sosolution, the probability of the solution being mutated to be the optimal solution is pkthe maximum probability of a solution being mutated to be the optimal solution is pm(1 − pm)n−1, which means that there∗ | ξt = x) (cid:3) pm(1 − pm)n−1. Then, by applying Theorem 1 with thisis only one bit difference. Therefore, we have P (ξt+1 ∈ Xupper bound, we get this proposition.∗ | ξt = x) (cid:3) pm(1 − pm)n−1, we haveProof. Since P (ξt+1 ∈ X(cid:2)ξt+1 ∈ X(cid:4)Px /∈ X ∗(cid:3)(cid:4)x /∈ X ∗∗ | ξt = x(cid:3) P (ξt = x)1 − μtpm(1 − pm)n−1 P (ξt = x)1 − μt(cid:6)x /∈ X ∗ P (ξt = x)1 − μt= pm(1 − pm)n−1= pm(1 − pm)n−1. %% by Eq. (1)Let βt = pm(1 − pm)n−1, by Theorem 1,+∞(cid:4)t−2(cid:5)E[τ ] (cid:2) β0 +tβt−1t=2i=0(1 − βi) = 1pm(cid:16)n−1(cid:15)11 − pm= 1pmθ n−1.Considering that pm is a constant, E[τ ] = Ω(θ n). (cid:2)Proposition 2. Solving the Trap problem using the EA with Reproduction implemented by Mutation#2 (bitwise mutation with proba-bility 1/n) and with a population size 1, i.e. (1 + 1)-EA, if starting from non-optimal populations, the EFHT is bounded byE[τ ] = Ω2n(cid:2)(cid:3),where n is the problem size.If we follow the idea in the proof of Proposition 1 to obtain an upper bound of success probability, i.e., P (ξt+1 ∈ Xξt = x) (cid:3) 1/(en), we can only obtain an Ω(n) lower bound for the EFHT, which is too loose.To get a tighter bound, we take two steps. First, we show that formula (12) is O (1/2n) at the beginning, i.e., t = 0.Second, we show that formula (12) decreases as t increases. So O (1/2n) is an upper bound of formula (12). By applyingTheorem 1 we get Proposition 1.There is a trick for calculating formula (12). We divide the state space into subspaces, in which states share somei=0, wherecommon properties, and treat each subspace as a whole. We first divide the state space into n + 1 subspaces { Xi}n(15)∗ |1816Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832Xi contains all the solutions that have exactly i identical bits with the optimal solution, so that the solutions in eachsubspace have the same probability of being mutated to be the optimal solution. By this division, the success probability att = 0 is calculated. We then divide the state space into the optimal space X, the feasible space X F and the infeasible spaceX I , according to whether solutions satisfy the constraint, and combine this division with the previous one. By this division,we find that formula (12) decreases as t increases.∗is the optimal solution, which means solutions in Xi have i bits identical with theProof. Let(cid:17)Xi =x ∈ X | (cid:9)x − x,∗where (cid:9) · (cid:9)H is Hamming distance and xi=0 Xi , | Xi| =optimal solution, and that X =∗(cid:9)H = n − i(cid:19)n(cid:3)(cid:2)ni(cid:18), and Xn = X∗.Then, by applying Mutation#2, we calculate the success probability∀x ∈ Xi:(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xP=(cid:15)1n(cid:16)n−i(cid:15)1 − 1n(cid:16)i.At t = 0, we have(cid:4)(cid:2)ξ1 ∈ XP∗ | ξ0 = x(cid:3) P (ξ0 = x)1 − μ0(cid:3)∗ | ξ0 = xx /∈ X ∗=(cid:4)(cid:2)ξ1 ∈ XPP (ξ0 = x) %% by assumption μ0 = 0x /∈ X ∗n−1(cid:4)(cid:4)(cid:2)P (ξ1 ∈ X(cid:3)∗ | ξ0 = x)P (ξ0 = x)%% by X =n(cid:20)i=0Xi(cid:16)n−i(cid:16)(cid:15)1 − 1ni 12n1n%% by ∀x: P (ξ0 = x) = 12n==i=0n−1(cid:4)x∈ Xi(cid:15)n(cid:16)(cid:15)i=0(cid:15)i(cid:15)=1 −n − 1n(cid:16)n(cid:16)12n12n∼ e − 1e∗ ∪ X F ∪ X I , where X.Let X = X∗contains the optimal solutions, X F contains all non-optimal feasible solutions whoselast bit is 0, and X I contains all the infeasible solutions whose last bit is 1. DenoteX Fi= Xi ∩ X F .According to the fitness function, we have∀x0 ∈ X F1 , . . . , xn−1 ∈ X F0 , x1 ∈ X F) > f (x0) > f (x1) > · · · > f (xn−1) > f (xI )n−1, xI ∈ X I :∗f (xand due to the selection behavior, i.e., the solutions with the largest fitness will be selected, we haveP∀ j, q (n − 1 (cid:2) j > q (cid:2) 0):(cid:3)(cid:2)ξt+1 ∈ X FjP (ξt+1 ∈ X FjP (ξt+1 ∈ X Fq| ξt ∈ X F= 0,q| ξt ∈ X I )| ξt ∈ X I )∀ j, q:P (ξt+1 ∈ X I | ξt ∈ X F ) = 0,P (ξ0 ∈ X Fj )P (ξ0 ∈ X Fq ),=where the last equation is by that, since every infeasible solution has the same lowest fitness, there is no selection pressureon the leading n − 1 bits when the solution is infeasible, and thus each of the leading n − 1 bits has probability 0.5 to beeither zero or one.(cid:19)ki=0 X Fi and X Bk(cid:19)=n−1i=k+1 X Fi , at time t = 0, for all k ∈ {0, 1, . . . , n − 1},For all k ∈ {0, 1, . . . , n − 1}, denoting X Ak=there exists η Ak,t, ηBk,t, ηF ,t and ηI,t such that(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xP(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xPP (ξt = x) = η Ak,t P (ξt ∈ X Ak ),P (ξt = x) = ηBk,t P (ξt ∈ X Bk ),(cid:4)x∈ X Ak(cid:4)x∈ X BkY. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18321817(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xPP (ξt = x) = ηF ,t P (ξt ∈ X F ),(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xPP (ξt = x) = ηI,t P (ξt ∈ X I ).(cid:4)x∈ X F(cid:4)x∈ X IOn the relationship between η Ak,t and ηBk,t , it holds thatη Ak,t < ηBk,t,by P (ξt+1 ∈ X∗ | ξt ∈ X Ak ) (cid:3) P (ξt+1 ∈ X∗ | ξt ∈ X Fk ) (cid:3) P (ξt+1 ∈ X∗ | ξt ∈ X Bk ).On the relationship between η Ak,t and ηI,t , it holds that at t = 0,η Ak,0 < ηI,0,by, first, η Ak,0 < ηF ,0, which is by ηF ,0 = η Ak,0by ∀x1, x2 ∈ X: P (ξ0 = x1) = P (ξ0 = x2) and(cid:6)x∈ X F∗ | ξ0 = x)P (ξ1 ∈ XP (ξ0 ∈ X F )(cid:6)x∈ X I<∗ | ξ0 = x)P (ξ1 ∈ XP (ξ0 ∈ X I ).P (ξ0∈ X A )P (ξ0∈ X F )+ ηBk,0P (ξ0∈ X B )P (ξ0∈ X F ) and η Ak,0 < ηBk,0, and second, ηF ,0 < ηI,0, which isAnd for t > 0,η Ak,t < ηI,0,by that, sinceP (ξt+1 ∈ X Ak ) = P (ξt ∈ X Ak ) += P (ξt ∈ X Ak ) +(cid:4)∪X Ix∈ X Bk(cid:4)P (ξt+1 ∈ X Ak| ξt = x)P (ξt = x) −(cid:2)ξt+1 ∈ X AkP(cid:3)| ξt = xP (ξt = x) −(cid:2)ξt+1 ∈ XP∗ ∪ X Bk(cid:3)∪ X I | ξt = xP (ξt = x)(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xPP (ξt = x)(cid:4)x∈ X Ak(cid:4)x∈ X Akx∈ X Bk∪X I(cid:2)ξt+1 ∈ X Bk(cid:3)%% by P(cid:2)ξt+1 ∈ X(cid:2)1 − P>∪ X I | ξt ∈ X Ak= 0P (ξt ∈ X Ak ) +(cid:3)(cid:3)∗ | ξt ∈ X Fk(cid:4)P%% by −P(cid:2)ξt+1 ∈ X∗ | ξt ∈ X A(cid:3)(cid:2) −Px∈ X I(cid:2)ξt+1 ∈ X(cid:2)ξt+1 ∈ X Ak(cid:3)∗ | ξt ∈ X Fk(cid:3) t(cid:5)(cid:2)1 − P (ξi+1 ∈ X(cid:3)∗ | ξi ∈ X Fk )> P(cid:2)ξ0 ∈ X Ak(cid:21)t(cid:4)(cid:4)+i=0(cid:2)ξi+1 ∈ X AkP(cid:3)| ξi = x(cid:22)(cid:21)P (ξi = x)t(cid:5)(cid:2)1 − P (ξ j+1 ∈ X(cid:22)(cid:3)∗ | ξ j ∈ X Fk )(cid:3)| ξt = xP (ξt = x)i=0x∈ X Ij=i= P (ξ0 ∈ X Ak )t(cid:5)(cid:2)1 − P (ξi+1 ∈ Xi=0(cid:3)∗ | ξi ∈ X Fk )(cid:21)+t(cid:4)i=0(cid:2)ξi+1 ∈ X AkP(cid:3)| ξi ∈ X IP (ξi ∈ X I )t(cid:5)(cid:2)j=i1 − P (ξ j+1 ∈ X(cid:3)∗ | ξ j ∈ X Fk )(cid:22),(cid:3)∗ | ξi ∈ X Fk )(cid:21)P (ξi ∈ X I )t(cid:5)j=iand similarly,P (ξt+1 ∈ X Bk ) < P(cid:3) t(cid:5)(cid:2)(cid:2)ξ0 ∈ X Bki=01 − P (ξi+1 ∈ X+t(cid:4)i=0(cid:2)ξi+1 ∈ X BkP(cid:3)| ξi ∈ X IandP (ξt+1 ∈ X FjP (ξt+1 ∈ X Fq| ξt ∈ X I )| ξt ∈ X I )=P (ξ0 ∈ X Fj )P (ξ0 ∈ X Fq ),we thus have∀k:P (ξt+1 ∈ X Ak )P (ξt+1 ∈ X Bk )>P (ξ0 ∈ X Ak )P (ξ0 ∈ X Bk );(cid:2)1 − P (ξ j+1 ∈ X(cid:22)(cid:3)∗ | ξ j ∈ X Fk ),1818Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832since P (ξt+1 ∈ X(cid:6)∗ | ξt ∈ X Ak ) < P (ξt+1 ∈ XP (ξt+1 ∈ X∗ | ξt = x)P (ξt = x)∗ | ξt ∈ X Bk ), by enumerating k, we have∗ | ξt = x)P (ξ0 = x)P (ξ1 ∈ X(cid:6)x∈ X Akx∈ X Ak<P (ξ0 ∈ X Ak ),P (ξt ∈ X Ak )which is η Ak,t < η Ak,0, and by η Ak,0 < ηI,0, it holds η Ak,t < ηI,0.Then, we haveP (ξt+1 ∈ X Ak )1 − μt+1==>(cid:6)P (ξt ∈ X Ak ) −1 − μt −(cid:6)x∈ X Akx∈ X Ak∪X I∪X Bk∗ | ξt = x)P (ξt = x)P (ξt+1 ∈ XP (ξt+1 ∈ X ∗ | ξt = x)P (ξt = x)(1 − η Ak,t)P (ξt ∈ X Ak )1 − μt − η Ak,t P (ξt ∈ X Ak ) − ηBk,t P (ξt ∈ X Bk ) − ηI,t P (ξt ∈ X I )(1 − η Ak,t)P (ξt ∈ X Ak )1 − μt − η Ak,t P (ξt ∈ X Ak ) − η Ak,t P (ξt ∈ X Bk ) − η Ak,t P (ξt ∈ X I )%% by η Ak,t < ηBk,t , η Ak,t < ηI,0 and ηI,t = ηI,0=(1 − η Ak,t)P (ξt ∈ X Ak )(1 − η Ak,t)(1 − μt)= P (ξt ∈ X Ak )1 − μt(cid:19)kwhich is ∀n − 1 (cid:2) k (cid:2) 0: P (ξt+1∈i=0 X Fi )1−μt+1,(cid:2) P (ξt ∈(cid:19)ki=0 X Fi )1−μtby writing back X Ak=(cid:19)ki=0 X Fi . So, we have(cid:4)x /∈ X ∗=(cid:3)(cid:4)x∈ X F(cid:4)x∈ X F(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:3) P (ξt = x)1 − μt(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:2)ξ1 ∈ XP∗ | ξ0 = x(cid:3) P (ξt = x)1 − μt(cid:3) P (ξ0 = x)1 − μ0+(cid:4)+(cid:2)ξt+1 ∈ XP∗ | ξt = xx∈ X I(cid:4)(cid:2)ξ1 ∈ XP∗ | ξ0 = xx∈ X IP (ξt+1 ∈(cid:19)ki=0 X Fi )1 − μt+1%% by both that ∀n − 1 (cid:2) k (cid:2) 0:(cid:21)%% Pξt+1 ∈ X∗ | ξt ∈k(cid:20)(cid:22)(cid:21)X Fi(cid:3) Pξt+1 ∈ X∗ | ξt ∈P (ξt ∈(cid:2)(cid:22)k(cid:20)i=0X Fi(cid:3) P (ξt = x)1 − μt(cid:3) P (ξ0 = x)1 − μ0(cid:19)ki=0 X Fi )1 − μtand∗ | ξ0 = xi=0(cid:3) P (ξ0 = x)1 − μ0(cid:4)=(cid:2)ξ1 ∈ XPx /∈ X ∗= e − 1e12n.Let βt = e−1e12n , by Theorem 1,E[τ ] (cid:2) ee − 12n,that is, E[τ ] = Ω(2n). (cid:2)Proposition 3. Solving the Trap problem using the EA with Reproduction implemented by Mutation#3 (one-bit mutation) and with apopulation size 1, i.e. (1 + 1)-EA, if starting from non-optimal populations, the EFHT is bounded byE[τ ] = Ω(2n),where n is the problem size.(16)We can follow the idea of the proof to Proposition 2. First, at t = 0, formula (12) is calculated to be O (1/2n). Then wefind that formula (12) reduces as t increases, which leads to an upper bound O (1/2n) of formula (12). By Theorem 1, theEFHT has a lower bound Ω(1/2n). The difference to the proof of Proposition 2 is that the solution space is divided intosubspaces in a different way, according to the characteristic of Mutation#3. To arrive at the proof, we divide the state spaceinto subspaces, in each subspace solutions have the same Hamming distance to the optimal solution. By this division, weY. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18321819find that only the solutions, which have only one bit different from the optimal solution, have non-zero probability of beingmutated to be the optimal solution. Thus, formula (12) is calculated.Proof. LetXi =(cid:17)x ∈ X| (cid:9)x − x∗(cid:9)H = n − i(cid:18),∗where (cid:9) · (cid:9)H is Hamming distance and xThen, by applying Mutation#3, the success probability isif i = n − 1,otherwise.(cid:3)∗ | ξt = x(cid:2)ξt+1 ∈ X∀x ∈ Xi:1n ,0,=(cid:9)Pis the optimal solution, such that X =(cid:19)ni=0 Xi , | Xi| =(cid:3)(cid:2)ni, and Xn = X∗.Noticing that Xn−1 contains the one feasible solution, which has the lowest fitness among feasible solutions, and n − 1infeasible solutions, which has the lowest fitness among all solutions, we have∗ | ξt ∈ Xn−1(cid:2)ξt+1 ∈ Xn−1 | ξt ∈ X − Xn−1 − X(cid:2)ξt+1 ∈ X − Xn−1 − X< P(cid:3).P(cid:3)∗At t = 0, we have(cid:4)Px /∈ X ∗(cid:2)ξ1 ∈ X∗ | ξ0 = x(cid:3) P (ξ0 = x)1 − μ0(cid:4)(cid:2)ξ1 ∈ XP∗ | ξ0 = x==x∈ Xn−1(cid:4)x∈ Xn−1n2n= 1n(cid:3) P (ξ0 = x)1 − μ0(cid:2)ξt+1 ∈ X%% by P%% by subspace dividing∗ | ξt ∈ Xn−1(cid:3)= 1n1nP (ξ0 = x)1 − μ0= 12n. %% by P (ξ0 ∈ Xn−1) =| Xn−1|2n= 12nAt time t + 1, on the relationship between μt and μt+1, we haveμt+1 = μt + P= μt + P(cid:3)∗(cid:2)ξt+1 ∈ X(cid:2)ξt+1 ∈ X(cid:2)ξt+1 ∈ X∗ | ξt ∈ X − Xn−1 − X∗ | ξt ∈ Xn−1(cid:3).∗ | ξt ∈ X − Xn−1 − X%% by P(cid:3)∗= 0(cid:2)ξt+1 ∈ X∗ | ξt ∈ Xn−1(cid:3)+ POn the relationship between P (ξt ∈ Xn−1) and P (ξt+1 ∈ Xn−1), we haveP (ξt+1 ∈ Xn−1) = P (ξt ∈ Xn−1) + P(cid:2)ξt+1 ∈ Xn−1 | ξt ∈ X − Xn−1 − X(cid:3)∗(cid:3)(cid:2)ξt+1 ∈ X− P∗ | ξt ∈ Xn−1(cid:3) P (ξt ∈ Xn−1) − P (ξt+1 ∈ X(cid:2)ξt+1 ∈ Xn−1 | ξt ∈ X − Xn−1 − X− P∗ | ξt ∈ Xn−1).%% by P(cid:2)ξt+1 ∈ X − Xn−1 − X(cid:3)∗ | ξt ∈ Xn−1(cid:3)∗(cid:2)ξt+1 ∈ X − Xn−1 − X< P∗ | ξt ∈ Xn−1(cid:3)Considering the above two relationships together, we haveP (ξt+1 ∈ Xn−1)1 − μt+1<P (ξt ∈ Xn−1) − P (ξt+1 ∈ X∗ | ξt ∈ Xn−1)1 − μt − P (ξt+1 ∈ X ∗ | ξt ∈ Xn−1)(cid:3) P (ξt ∈ Xn−1)1 − μt%% by ∀t: 1 − μt (cid:2) P (ξt ∈ Xn−1) (cid:2) 0.Therefore,(cid:4)(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:3) P (ξt = x)1 − μt(cid:3) P (ξ0 = x)1 − μ0∗ | ξ0 = xx /∈ X ∗(cid:3)(cid:4)x /∈ X ∗(cid:2)ξ1 ∈ XP%% byP (ξt+1 ∈ Xi)1 − μt+1(cid:3) P (ξt ∈ Xi)1 − μt= 12nSo, let βt = 1.2n , by Theorem 1, the EFHT is lower boundedE[τ ] (cid:2) 2n,that is, E[τ ] = Ω(2n). (cid:2)1820Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18324.2. Static mutation with populationNow we study how the three static mutation operators perform with population size larger than 1. Specifically, let usconsider the case where the population size is equal to the problem size n, i.e. (n + n)-EA, which is a practical strategy. Inthis case, the population state space consists of solution state spaces, which means a population x ∈ X contains n solutionsfrom solution space S.We can consider each population as a set of solutions without order. Denoting ‘(· · ·)’ as a solution and ‘{· · ·}’ as a popula-tion set, the two populations, which consist of the same solutions with different orders, are equal, e.g., {(001), (011), (110)} =(cid:2)2n+n−1{(110), (011), (001)}. By this consideration, there are | X| =number of population states [25]. But if we generatena population by generating each bit of each solution independently from an uniform distribution, we will have differ-ent probabilities to choose different states, e.g., P ({(001), (001), (001)}) = 0.59 but P ({(001), (011), (110)}) = 6 × 0.59.Meanwhile, we can equivalently consider each population as an ordered set of solutions. Denoting ‘[· · ·]’ as a popu-lation with order, the two populations, which consist of the same solutions with different orders are unequal, e.g.,[(001), (011), (110)] (cid:13)= [(110), (011), (001)]. By this consideration, there are | X| = 2n×n number of different population states,and the probability of randomly generating every population is exactly 1/| X|. We use the second consideration in thefollows, such that the calculation will be simple.(cid:3)Proposition 4. Solving the Trap problem using the EA with Reproduction implemented by Mutation#1 (bitwise mutation with constantprobability) and with a population size equals to the problem size, i.e. (n + n)-EA, if starting from non-optimal populations, the EFHTis bounded byE[τ ] = Ω(cid:15)(cid:16)θ nn,(17)where θ = (1 − pm)−1 ∈ (1, 2] is a constant and n is the problem size.The proof of this proposition is the same as of Proposition 1, except that the state level is upgraded to the populationstates. We know that the maximum probability of a solution being mutated to be the optimal solution by Mutation#1 ispm(1 − pm)n−1, which leads to that the maximum probability of a population being mutated to be an optimal population is1 − (1 − pm(1 − pm)n−1)n. Therefore, we can have an upper bound of formula (12). By Theorem 1, we get this proposition.∗ | ξt = x) (cid:3) 1 − (1 − pm(1 − pm)n−1)n, we haveProof. Since P (ξt+1 ∈ X(cid:2)ξt+1 ∈ X(cid:4)Px /∈ X ∗(cid:3)(cid:4)∗ | ξt = x(cid:3) P (ξt = x)1 − μtpm(1 − pm)n−1 P (ξt = x)1 − μt(cid:6)(cid:3)(cid:3)n=(cid:2)1 − pm(1 − pm)n−1(cid:3)nx /∈ X ∗(cid:2)1 −(cid:2)1 − pm(1 − pm)n−1x /∈ X ∗ P (ξt = x)1 − μt= 1 −%% by Eq. (1)∼ npm(1 − pm)n−1. %% asymptotically equalLet βt = npm(1 − pm)n−1, by Theorem 1,+∞(cid:4)t−2(cid:5)E[τ ] (cid:2) β0 +tβt−1t=2i=0(1 − βi) = 1n(cid:16)n−1(cid:15)1pm11 − pm= θ nnpm.Considering that pm is a constant, E[τ ] = Ω( θ nn ). (cid:2)Proposition 5. Solving the Trap problem using the EA with Reproduction implemented by Mutation#2 (bitwise mutation with proba-bility 1/n) and with a population size equals to the problem size, i.e. (n + n)-EA, if starting from non-optimal populations, the EFHT isbounded by,(18)E[τ ] = Ω(cid:15)(cid:16)2nn2where n is the problem size.Following the proof of Proposition 2, we divide the population state space X = {0, 1}n∗n into n + 1 subspaces { Xi}ni=0,where Xn contains all optimal populations, Xi (i ∈ {0, . . . , n − 1}) contains non-optimal populations, and the solution withY. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18321821the worst fitness in each Xi has i identical bits with the optimal solution. By doing so, the state subspaces hold the sameproperties as those in the proof of Proposition 2, which leads to the calculation of formula (12). The only difference from theproof of Proposition 2 is that the upper bound of formula (12) is calculated at the population level but not at the solutionlevel, which results in O ( n22n ). Therefore a lower bound Ω( 2nn2 ) is obtained by Theorem 1.Proof. Let(cid:23)Xi =x ∈ X| mins∈x(cid:9)s − s∗(cid:9)H = n − i(cid:24),where (cid:9) · (cid:9)H is Hamming distance, x denotes a population, s denotes a solution, and s∗is the optimal solution.Denote˜Xi =(cid:17)x ∈ Xi | ∀s ∈ x: (cid:9)s − s∗(cid:9)H = n − i(cid:18).By applying Mutation#2, the success probability is∀x ∈ Xi:(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xP(cid:2)ξt+1 ∈ X(cid:3) P∗ | ξt ∈ ˜Xi(cid:3)%% by considering the worst population in the subspace Xi(cid:16)nn−i(cid:15)(cid:16)(cid:16)(cid:15)(cid:15)i1 − 1n11 −(cid:16)n−i= 1 −(cid:15)∼ n1n(cid:16)in(cid:15)1 − 1n. %% asymptotically equalBecause all the solutions in every population of subspace Xi have at most i bits identical to the optimal solution, and thereis at least one solution holding the exact i bits of that, we have the probability at the initialization that(cid:22)n−1(cid:21)(cid:15)(cid:16)(cid:16)(cid:16)(cid:16)(cid:16)(cid:15)(cid:15)nn·1i12n·i(cid:4)(cid:15)njj=012n(cid:15)ni(cid:3) n12n.P (ξ0 ∈ Xi) =At t = 0, we have(cid:4)(cid:2)ξ1 ∈ XP∗ | ξ0 = x(cid:3) P (ξ0 = x)1 − μ0(cid:3)∗ | ξ0 = xx /∈ X ∗=(cid:4)(cid:2)ξ1 ∈ XPP (ξ0 = x) %% by assumption μ0 = 0x /∈ X ∗n−1(cid:4)(cid:4)(cid:2)(cid:2)ξ1 ∈ X(cid:3)∗ | ξ0 = x(cid:3)P (ξ0 = x)P%% by X =n(cid:20)i=0Xi=(cid:3)i=0n−1(cid:4)x∈ Xi(cid:15)n2i=0(cid:15)n(cid:15)= n21 −∼ e − 1en22n.(cid:16)n−i1(cid:15)1 − 1n(cid:16)i(cid:16)(cid:15)ni12nn − 1n(cid:16)n(cid:16)12nLet the solution space S be divided into three subspaces S = Scontains the optimal solution, S Fcontains all the non-optimal feasible solutions whose last bit is 0, and S I contains all the infeasible solutions whose last bitis 1. Denote∗ ∪ S F ∪ S I , where S∗X F = {x ∈ X | ∀s ∈ x: s ∈ S F },X I = X − X F − X∗and then denoteX Fi= Xi ∩ X F ,˜X Fi= ˜Xi ∩ X F .According to the selection behavior, i.e., the solutions with the largest fitness will be selected, we have∀ j, q(n − 1 (cid:2) j (cid:2) q (cid:2) 0):∀ j, q:P (ξt+1 ∈ X FjP (ξt+1 ∈ X FqP| ξt ∈ X I )| ξt ∈ X I )(cid:2)ξt+1 ∈ X FjP (ξ0 ∈ X Fj )P (ξ0 ∈ X Fq )=,| ξt ∈ X Fq(cid:3)= 0,(cid:2)ξt+1 ∈ X I | ξt ∈ X F(cid:3)P= 0,1822Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832where the last equation is by that, since every infeasible solution has the same lowest fitness, there is no selection pressureon the leading n − 1 bits when there is at least one solution in the current population is infeasible, and thus each of theleading n − 1 bits has probability 0.5 to be either zero or one.(cid:19)ki=0 X Fi and X Bk(cid:19)=n−1i=k+1 X Fi , at time 0, for all k ∈ {0, 1, . . . , n − 1}, thereFor all k ∈ {0, 1, . . . , n − 1}, denoting X Ak=exists η Ak,t, ηBk,t, ηF ,t and ηI,t such that(cid:4)(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xPP (ξt = x) = η Ak,t P (ξt ∈ X Ak ),x∈ X Ak(cid:4)(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xPP (ξt = x) = ηBk,t P (ξt ∈ X Bk ),x∈ X Bk(cid:4)(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xPP (ξt = x) = ηF ,t P (ξt ∈ X F ),x∈ X F(cid:4)x∈ X I(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xPP (ξt = x) = ηI,t P (ξt ∈ X I ).On the relationship between η Ak,t and ηBk,t , it holds thatη Ak,t < ηBk,t,(cid:3)by P (ξt+1 ∈ X∗ | ξt ∈ X Ak ) (cid:3) P (ξt+1 ∈ X(cid:2)ξt+1 ∈ X(cid:2)ξt+1 ∈ XP∗ | ξt ∈ X Ak(cid:3) Paccording to the definition of ˜X Fk , and(cid:2)ξt+1 ∈ X∗ | ξt ∈ ˜X F(cid:3) P(cid:3)(cid:2)ξt+1 ∈ XPwhen n → +∞.k∗ | ξt ∈ X Bk ), which is by(cid:3)∗ | ξt ∈ ˜X Fk(cid:3)∗ | ξt ∈ X BkOn the relationship between η Ak,t and ηI,t , it holds that at t = 0,η Ak,0 < ηI,0,by, first, η Ak,0 < ηF ,0, which is by ηF ,0 = η Ak,0by∀x1, x2 ∈ X:P (ξ0 = x1) = P (ξ0 = x2) andP (ξ0∈ X A )P (ξ0∈ X F )+ ηBk,0P (ξ0∈ X B )P (ξ0∈ X F ) and η Ak,0 < ηBk,0, and second, ηF ,0 < ηI,0, which is(cid:6)x∈ X F∗ | ξ0 = x)P (ξ1 ∈ XP (ξ0 ∈ X F )(cid:6)x∈ X I<∗ | ξ0 = x)P (ξ1 ∈ XP (ξ0 ∈ X I ).And for t > 0,η Ak,t < ηI,0,by that, sinceP (ξt+1 ∈ X Ak ) = P (ξt ∈ X Ak ) += P (ξt ∈ X Ak ) +(cid:4)∪X Ix∈ X Bk(cid:4)P (ξt+1 ∈ X Ak| ξt = x)P (ξt = x) −P (ξt+1 ∈ X Ak| ξt = x)P (ξt = x) −(cid:2)ξt+1 ∈ XP∗ ∪ X Bk(cid:3)∪ X I | ξt = xP (ξt = x)(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xPP (ξt = x)(cid:4)x∈ X Ak(cid:4)x∈ X Akx∈ X Bk∪X I%% by P (ξt+1 ∈ X Bk(cid:2)(cid:2)ξt+1 ∈ X1 − P∗ | ξt ∈ X F∪ X I | ξt ∈ X Ak ) = 0P (ξt ∈ X Ak ) +(cid:3)(cid:3)k>(cid:4)(cid:3)(cid:2) −Px∈ X I(cid:2)ξt+1 ∈ XP (ξt+1 ∈ X Ak(cid:3)∗ | ξt ∈ X Fk| ξt = x)P (ξt = x)∗ | ξt ∈ X A(cid:2)ξt+1 ∈ Xt(cid:5)(cid:2)1 − P (ξi+1 ∈ X(cid:3)∗ | ξi ∈ X Fk )i=0(cid:2)ξi+1 ∈ X AkP(cid:3)| ξi = x(cid:22)(cid:21)P (ξi = x)(cid:2)1 − P (ξ j+1 ∈ X(cid:22)(cid:3)∗ | ξ j ∈ X Fk )t(cid:5)j=i%% by −P> P (ξ0 ∈ X Ak )(cid:21)t(cid:4)(cid:4)+i=0x∈ X I= P (ξ0 ∈ X Ak )t(cid:5)(cid:2)1 − P (ξi+1 ∈ Xi=0(cid:3)∗ | ξi ∈ X Fk )(cid:21)+t(cid:4)i=0(cid:2)ξi+1 ∈ X AkP(cid:3)| ξi ∈ X It(cid:5)j=iP (ξi ∈ X I )(1 − P (ξ j+1 ∈ X(cid:22)∗ | ξ j ∈ X Fk )),Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18321823and similarly,P (ξt+1 ∈ X Bk ) < P (ξ0 ∈ X Bk )(cid:2)1 − P (ξi+1 ∈ Xt(cid:5)i=0(cid:3)∗ | ξi ∈ X Fk )(cid:21)+t(cid:4)i=0(cid:2)ξi+1 ∈ X BkP(cid:3)| ξi ∈ X IP (ξi ∈ X I )t(cid:5)(cid:2)1 − P (ξ j+1 ∈ X(cid:22)(cid:3)∗ | ξ j ∈ X Fk ),j=i)) >P (ξ0∈ X AkP (ξ0∈ X Bk)) ; since P (ξt+1 ∈ X∗ | ξt ∈ X Ak ) < P (ξt+1 ∈ X∗ | ξt ∈andP (ξt+1∈ X FjP (ξt+1∈ X Fq|ξt ∈ X I )|ξt ∈ X I )X Bk ), by enumerating k, we have= P (ξ0∈ X Fj )P (ξ0∈ X Fq )(cid:6), we thus have ∀k: P (ξt+1∈ X AkP (ξt+1∈ X BkP (ξt+1 ∈ X∗ | ξt = x)P (ξt = x)x∈ X AkP (ξt ∈ X Ak )(cid:6)x∈ X Ak<P (ξ1 ∈ X∗ | ξt = x)P (ξ0 = x)P (ξ0 ∈ X Ak ),which is η Ak,t < η Ak,0, and by η Ak,0 < ηI,0, it holds η Ak,t < ηI,0.Then, we haveP (ξt+1 ∈ X Ak )1 − μt+1>=>(cid:6)P (ξt ∈ X Ak ) −1 − μt −(cid:6)x∈ X Akx∈ X Ak∪X I∪X Bk∗ | ξt = x)P (ξt = x)P (ξt+1 ∈ XP (ξt+1 ∈ X ∗ | ξt = x)P (ξt = x)(1 − η Ak,t)P (ξt ∈ X Ak )1 − μt − η Ak,t P (ξt ∈ X Ak ) − ηBk,t P (ξt ∈ X Bk ) − ηI,t P (ξt ∈ X I )(1 − η Ak,t)P (ξt ∈ X Ak )1 − μt − η Ak,t P (ξt ∈ X Ak ) − η Ak,t P (ξt ∈ X Bk ) − η Ak,t P (ξt ∈ X I )%% by η Ak,t < ηBk,t , η Ak,t < ηI,0 and ηI,t = ηI,0=(1 − η Ak,t)P (ξt ∈ X Ak )(1 − η Ak,t)(1 − μt)which is ∀n − 1 (cid:2) k (cid:2) 0 : P (ξt+1∈(cid:2) P (ξt ∈(cid:19)ki=0 X Fi )1−μtby writing back X Ak=(cid:19)ki=0 X Fi . So, we have(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:4)+(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:3) P (ξt = x)1 − μt(cid:3) P (ξ0 = x)1 − μ0+(cid:2)ξ1 ∈ XP∗ | ξ0 = xx∈ X I(cid:4)(cid:2)ξ1 ∈ XP∗ | ξ0 = xx∈ X IP (ξt+1 ∈(cid:19)ki=0 X Fi )(cid:2)1 − μt+1(cid:21)(cid:3) Pξt+1 ∈ X∗ | ξt ∈(cid:3) P (ξt = x)1 − μt(cid:3) P (ξ0 = x)1 − μ0(cid:19)ki=0 X Fi )P (ξt ∈1 − μt(cid:22)n−1(cid:20)i=k+1X Fi,= P (ξt ∈ X Ak )1 − μt(cid:19)ki=0 X Fi )1−μt+1(cid:3) P (ξt = x)1 − μt∗ | ξt = x(cid:2)ξt+1 ∈ XP(cid:4)x /∈ X ∗=(cid:3)(cid:4)x∈ X F(cid:4)x∈ X F%% by both that ∀n − 1 (cid:2) k (cid:2) 0:(cid:21)%% and Pξt+1 ∈ X∗ | ξt ∈(cid:22)k(cid:20)i=0X Fi∗ | ξ0 = x(cid:3) P (ξ0 = x)1 − μ0(cid:4)=(cid:2)ξ1 ∈ XPx /∈ X ∗= e − 1en22n.Let βt = e−1en22n , by Theorem 1,2nn2n2 ). (cid:2),E[τ ] (cid:2) ee − 1that is, E[τ ] = Ω( 2n1824Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832Proposition 6. Solving the Trap problem using the EA with Reproduction implemented by Mutation#3 (one-bit mutation) and with apopulation size equals to the problem size, i.e. (n + n)-EA, if starting from non-optimal populations, the EFHT is bounded by,(19)E[τ ] = Ω(cid:15)(cid:16)2nn2where n is the problem size.As in the proof of Proposition 5, we can divide the population state space X = {0, 1}n∗n into n + 1 subspaces { Xi}ni=0,where Xn contains all the optimal populations, and Xi (i ∈ {0, . . . , n − 1}) contains non-optimal populations, among whichthe solution with the worst fitness in the population has n − i bits different from the optimal solution. By doing so, the statesubspaces hold the same properties as those in the proof of Proposition 2, which leads to the calculation of formula (12).The only difference from the proof of Proposition 2 is that the upper bound of formula (12) is calculated at the populationlevel but not at the solution level, which results in O ( n22n ). Therefore a lower bound Ω( 2nn2 ) is obtained by Theorem 1.Proof. Let(cid:23)Xi =x ∈ X | mins∈x(cid:9)s − s∗(cid:9)H = n − i(cid:24),where (cid:9) · (cid:9)H is Hamming distance, x denotes a population, s denotes a solution, and s∗is the optimal solution.By applying the one-bit mutation, the success probability is(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xP(cid:9)(cid:3) 1 − (1 − 1= 0,n )n,x ∈ Xn−1,x ∈ X − Xn−1 − X∗,by considering that only populations in Xn−1 have chance to mutate to be optimal, and that the best case that all solutionsin Xn−1 have only 1 bit different from the optimal solution. Since there are n solutions that have one bit different from theoptimal solution, the probability of being in Xn−1 at initialization isP (ξ0 ∈ Xn−1) = 1 −(cid:15)1 − n2n(cid:16)n.Noticing that Xn−1 consists of populations that contain either the feasible solution that has the lowest fitness among feasiblesolutions, or n − 1 infeasible solutions that are with the lowest fitness among all solutions, we have(cid:2)ξt+1 ∈ Xn−1 | ξt ∈ X − Xn−1 − X(cid:3)∗P(cid:2)ξt+1 ∈ X − Xn−1 − X< P∗ | ξt ∈ Xn−1(cid:3).At t = 0, we have(cid:2)ξ1 ∈ X(cid:4)P∗ | ξ0 = x(cid:3) P (ξ0 = x)1 − μ0(cid:3)∗ | ξ0 = x(cid:4)(cid:2)ξ1 ∈ XPP (ξ0 = x)%% by assumption μ0 = 0x /∈ X ∗==x /∈ X ∗(cid:4)x∈ Xn−1(cid:3)1 −∼ n22n.(cid:2)ξ1 ∈ X(cid:3)∗ | ξ0 = xPP (ξ0 = x)%% by P(cid:15)(cid:15)(cid:2)ξt+1 ∈ X(cid:16)(cid:15)(cid:16)n1 − 1n(cid:3)∗= 0(cid:15)∗ | ξt ∈ X − Xn−1 − X1 − n2n1 −(cid:16)n(cid:16)At time t + 1, on the relationship between μt and μt+1, we haveμt+1 = μt +(cid:4)(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xPP (ξt = x) +x∈( X− Xn−1− X ∗)(cid:4)(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xP (ξt = x)P= μt +(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xPP (ξt = x)(cid:4)x∈ Xn−1x∈ Xn−1(cid:2)ξt+1 ∈ X%% by P∗ | ξt ∈ X − Xn−1 − X∗(cid:3)= 0.On the relationship between P (ξt ∈ Xn−1) and P (ξt+1 ∈ Xn−1), we haveY. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18321825P (ξt+1 ∈ Xn−1) = P (ξt ∈ Xn−1) +(cid:4)P (ξt+1 ∈ Xn−1 | ξt = x)P (ξt = x)(cid:4)−x∈ X− Xn−1− X ∗(cid:3)∗ | ξt = x(cid:2)ξt+1 ∈ XPP (ξt) −(cid:4)(cid:2)ξt+1 ∈ X − Xn−1 − X(cid:3)∗ | ξt = xPP (ξt = x)x∈ Xn−1< P (ξt ∈ Xn−1) −(cid:4)(cid:2)ξt+1 ∈ XPx∈ Xn−1(cid:3)∗ | ξt = xP (ξt )x∈ Xn−1(cid:2)ξt+1 ∈ Xn−1 | ξt ∈ X − Xn−1 − X%% by P(cid:3)∗(cid:2)ξt+1 ∈ X − Xn−1 − X< P∗ | ξt ∈ Xn−1(cid:3).Considering the above two relationships together, we have(cid:6)x∈ Xn−1<(cid:6)P (ξt ∈ Xn−1) −1 − μt −(cid:3) P (ξt ∈ Xn−1)1 − μtP (ξt+1 ∈ X∗ | ξt = x)P (ξt )x∈ Xn−1P (ξt+1 ∈ X ∗ | ξt = x)P (ξt = x). %% by ∀t : 1 − μt (cid:2) P (ξt ∈ Xn−1) (cid:2) 0∗ | ξt = xx /∈ X ∗(cid:3)(cid:4)(cid:2)ξ1 ∈ XP∗ | ξ0 = x(cid:3) P (ξt = x)1 − μt(cid:3) P (ξ0 = x)1 − μ0%% byP (ξt+1 ∈ Xn−1)1 − μt+1(cid:3) P (ξt ∈ Xn−1)1 − μtP (ξt+1 ∈ Xn−1)1 − μt+1Therefore, we have(cid:4)(cid:2)ξt+1 ∈ XPx /∈ X ∗(cid:3) n22nSo, let βt = n2.2n , by Theorem 1, the EFHT is lower boundedE[τ ] (cid:2) 2nn2,that is, E[τ ] = Ω( 2nn2 ). (cid:2)4.3. Mutation and recombination with populationWe implement the Reproduction by a mutation operator and a recombination operator together as follows, where ξ Mt+1and ξ Ct+1 are defined as the sets of solutions produced by mutation and recombination from ξt , respectively:1. the population ξt contains n solutions,2. apply the mutation on ξt to produce another n solutions ξ Mt+1,3. apply the recombination on ξt to produce n more solutions ξ C4. choose the best n solutions from ξt ∪ ξ Mt+1∪ ξ Ct+1.t+1,Considering the fitness function of the Trap problem, when the last bit of a solution is 1, it is either the optimal solutionor a solution with the worst fitness. We can divide the solution space S into SF and SI , where the last bit of solutions inSF is 0, and the last bit of solutions in SI is 1. This separation is helpful for our analysis on recombination. We first give alemma, based on which the lower bounds of three EAs are then derived.Lemma 3. Solving the Trap problem by the EA with population size equals to the problem size, i.e. (n + n)-EA. Let Φ : X → Z be afunction that cuts off the last bit of all solutions in the population from X , and Z is another population space Z = {0, 1}n∗(n−1) whereeach population contains n solutions of n − 1 bits long. Then, as long as there is at least one solution in the current population ξt isfrom SI , we have∀ ˜Z ⊆ Z :(cid:2)Φ(ξt ) ∈ ˜Z(cid:3)P=| ˜Z || Z |.This lemma tells that how the leading n − 1 bits of solutions in the population distribute, given that there is at least onesolution whose last bit is 1. To prove the lemma, first, we find that, by initialization, each of the leading n − 1 bits of everysolution has probability 0.5 to be either zero or one. Second, we notice that applying of the mutation and the recombinationoperators does not change that distribution. Finally, the selection does not change the distribution of those n − 1 bits so faras at least one solution from SI remains in the population after the selection operation. Thus, the lemma is proved.where ξ MBy applying an arbitrary symmetric operator, i.e., one for which it holds P (ξt+1 = y | ξt = x) = P (ξt+1 = x | ξt = y) fort+1 denote the populations of ξt after the mutation and the recombination operators, respectively.1826Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832Proof. At t = 0, we have∀ ˜Z ⊆ Z :(cid:2)Φ(ξ0) ∈ ˜Z(cid:3)P=| ˜Z || Z |,due to random initialization.At time t + 1, the mutation operators and the recombination operator are all symmetric, i.e.,(cid:25)P (ξ Mt+1P (ξ Rt+1t+1 and ξ R= y | ξt = x) = P (ξ Mt+1= y | ξt = x) = P (ξ Rt+1= x | ξt = y),= x | ξt = y),arbitrary x ∈ X and y ∈ X , we have∀ y:P (ξ1 = y) − P (ξ0 = y)(cid:4)P (ξ1 = y | ξ0 = x)P (ξ0 = x) −(cid:4)x∈ X−{ y}P (ξ1 = x | ξ0 = y)P (ξ0 = y)x∈ X−{ y}(cid:4)===P (ξ1 = y | ξ0 = x)(P (ξ0 = x) − P (ξ0 = y))x∈ X−{ y}%% by P (ξ1 = y | ξ0 = x) = P (ξ1 = x | ξ0 = y)(cid:4)(cid:15)(cid:16)P (ξ1 = y | ξ0 = x)1| X|− 1| X|x∈ X−{ y}= 0.Therefore, we have∀ ˜X ⊆ X:(cid:2)ξ M1P(cid:3)=∈ ˜X| ˜X|| X|,(cid:2)ξ C1P(cid:3)=∈ ˜X| ˜X|| X|for the mutation operators and the recombination operator, respectively. This leads to(cid:2)∀ ˜Z ⊆ Z :| ˜Z || Z |by noticing the universal quantifier ∀.(cid:2)Φ∈ ˜Zξ M1=P(cid:3)(cid:3),(cid:3)(cid:2)(cid:2)ΦPξ C1(cid:3)=∈ ˜Z| ˜Z || Z |solution from SI survives in ξt+1, we have(cid:2)∀s ∈ SF :Ps ∈ ξt+1 | s ∈ ξt ∪ ξ Mt+1∪ ξ Rt+1(cid:3)= 1,The Selection operation generates ξt+1 by choosing the best n solutions from ξt ∪ ξ Mt+1∪ ξ Rt+1. Since there is at least oneby considering that every solution in SF has a better fitness value than all the non-optimal solutions in SI . Since all thenon-optimal solutions in SI have the same fitness values, they have the same probability to survive in ξt+1, i.e.,= P∪ ξ R∪ ξ Rs1 ∈ ξt+1 | s1 ∈ ξt ∪ ξ Mt+1s2 ∈ ξt+1 | s2 ∈ ξt ∪ ξ Mt+1∀s1, s2 ∈ SI :(cid:3).t+1t+1P(cid:2)(cid:2)(cid:3)Therefore,∀ ˜Z ∈ Z :(cid:2)Φ(ξt+1) ∈ ˜Z(cid:3)P=| ˜Z || Z |.(cid:2)Proposition 7. Solving the Trap problem using the EA with a population size equals to the problem size, i.e. (n + n)-EA, if starting fromnon-optimal populations,(a) if the Reproduction is implemented by Mutation#1 (bitwise mutation with constant probability) and Recombination, the EFHT isbounded byE[τ ] = Ω(cid:15)(cid:16),2nn3(20)(b) if the Reproduction is implemented by Mutation#2 (bitwise mutation with probability 1/n) and Recombination, the EFHT isbounded byE[τ ] = Ω(cid:15)(cid:16),2nn3(21)Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832(c) if the Reproduction is implemented by Mutation#3 (one-bit mutation) and Recombination, the EFHT is bounded byE[τ ] = Ω(cid:15)(cid:16)2nn3,1827(22)where n is the problem size.To prove the proposition, we first notice that the recombination operator could not generate the optimal solution froma population that does not contain any solutions from SI , which derives an upper bound for when the recombination hasnon-zero success probability. Then we find that the probability of being in populations that contain solutions from SIisdecreasing. Thus we get an upper bound of formula (12), which leads to the proposition.Proof. Considering that the mutation and recombination are applied independently and the Selection operation does notgenerate new solutions, we have(cid:4)x /∈ X ∗=(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:3) P (ξt = x)1 − μt(cid:4)x /∈ X ∗(cid:2)ξ Mt+1P∈ X∗ | ξt = x(cid:3) P (ξt = x)1 − μt+(cid:4)x /∈ X ∗(cid:2)ξ Rt+1P∈ X∗ | ξt = x(cid:3) P (ξt = x)1 − μt,where ξ MLett+1 is the population reproduced from ξt+1 with only mutation, and ξ Rt+1 is that with only recombination.X F = {x ∈ X | ∀s ∈ x: s ∈ SF },∗X I = X − X F − X(cid:2)x ∈ X I | Pξ RX Pt+1I∈ X=(cid:17),(cid:3)∗ | ξt = x(cid:18)> 0.Then, we have∀t:∀t:P (ξt+1 ∈ X I | ξt ∈ X F ) = 0,(cid:2)= 0,ξ Rt+1∗ | ξt ∈ X F∈ XP(cid:3)by considering the behavior of the selection and the recombination.When ξt ∈ X F , we have exactly the same results as with using mutation operators only, since the recombination is notuseful.When ξt ∈ X I , for the mutation operators we have(cid:4)x /∈ X ∗(cid:2)ξ Mt+1P∈ X∗ | ξt = x(cid:3) P (ξt = x)1 − μt⎧⎪⎪⎨(cid:3)⎪⎪⎩npm(1 − pm)n−1,e−1en22n ,n22n ,for Mutation#1,for Mutation#2,for Mutation#3.For the recombination operator, we have(cid:3) P (ξt = x)1 − μt∗ | ξt = x(cid:2)ξ Rt+1∈ X(cid:4)Px∈ X I(cid:4)x∈ X PI(cid:4)x∈ X PI(cid:2)ξ Rt+1P∈ X∗ | ξt = x(cid:3) P (ξt = x)1 − μt%% by the definition of X PI(cid:2)ξ Rt+1P∈ X∗ | ξt = x(cid:3) P (Φ(ξt ) = Φ(x))(1 − μt)1 − μt%% by optimistic assumption that the last bits of all solutions in x are all 1(cid:4)(cid:3)(cid:2)Φ(ξt ) = Φ(x)P%% by P(cid:2)ξ Rt+1(cid:3)∗ | ξt = x∈ X(cid:3) 1=(cid:3)(cid:3)x∈ X PI(cid:2)Φ(ξt ) ∈ {Φ(x) | x ∈ X PI}||{Φ(x)|x ∈ X PI| Z |= P=(cid:3)}, %% by Lemma 3where Φ(·) and Z are defined in Lemma 3.1828Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832By the definition of X PI should contain at least one solution whose leading d bits are the sameas those of the optimal solution, and at least one solution whose tailing n − 1 − d bits are the same as those of the optimalsolution. Thus we haveI , every population in X P|{Φ(x)|x ∈ X PI| Z |}|=n−2(cid:4)(cid:15)n(cid:16)(cid:15)(cid:15)1d=112(cid:16)d+1(cid:15)(cid:15)(cid:15)1 −1 −12(cid:16)n−d(cid:16)n(cid:16)(cid:16)(cid:3) n(cid:15)(cid:15)n−2(cid:4)d=1(cid:16)d+1(cid:15)n1212(cid:16)n−d(cid:16)= n2(n − 2)2n+1.Then, we get(cid:4)x∈ X I(cid:2)ξ Rt+1P∈ X∗ | ξt = x(cid:3) P (ξt = x)1 − μt(cid:3) n2(n − 2)2n+1.Therefore, for Mutation#1,(cid:4)x∈ X(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:3) P (ξt = x)1 − μt(cid:3) npm(1 − pm)n−1 + n2(n − 2)2n+1.Let β = npm(1 − pm)n−1 + n2(n−2)2n+1(cid:15)npm(1 − pm)n−1 + n2(n − 2)E[τ ] =2n+1= Ω(cid:16).2nn3, the EFHT is obtained,(cid:16)−1(cid:15)For Mutation#2,(cid:4)Px∈ XLet β = e−1e(cid:2)ξ Ct+1∈ X∗ | ξt = x(cid:3) P (ξt = x)1 − μt(cid:3) e − 1en22n+ n2(n − 2)2n+1.n22n + n2(n−2)2n+1(cid:15)e − 1en22n, the EFHT is obtained,(cid:15)(cid:16)−1+ n2(n − 2)2n+1= Ω(cid:16).2nn3E[τ ] =∗ | ξt = x(cid:3) P (ξt = x)1 − μt(cid:3) n22n+ n2(n − 2)2n+1., the EFHT is obtained,(cid:16)−1(cid:15)n22n+ n2(n − 2)2n+1= Ω(cid:16).(cid:2)2nn3For Mutation#3,(cid:4)(cid:2)ξ Ct+1P∈ XLet β = n2x∈ X2n + n2(n−2)2n+1(cid:15)E[τ ] =4.4. Time variant mutation(cid:2)(cid:3)E[τ ] = Ωθ nProposition 8. Solving the Trap problem using the EA with Reproduction implemented by Mutation#4 and with a population size 1,i.e. (1 + 1)-EA, if starting from non-optimal population, the EFHT is bounded by(23)where θ ∈ (1, 2] is a constant and n is the problem size.Since we model the evolution process by a non-homogeneous Markov chain, we can easily model the time-variant mu-tation, and simply reduce it to a homogeneous Markov chain to prove the proposition following the proof of Proposition 1.Proof. Applying Mutation#4, for x such that (cid:9)x − x(cid:2)(cid:3)∗ | ξt = x(0.5 − d)e−t + d ∈ (0, 0.5], we have−t + d(cid:3)k=P(cid:2)ξt+1 ∈ XSince (0.5 − d)e(cid:2)ξt+1 ∈ XP∗ | ξt ∈ X − X∗(cid:3)(cid:2)(0.5 − d)e(cid:3)−t + d(cid:3)(cid:2)1 − (0.5 − d)e−t − d(cid:3)n−1.∗(cid:9)H = k, we have−t − d(cid:2)1 − (0.5 − d)e(cid:3)n−k.Thus,Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18321829(cid:4)x /∈ X ∗(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:3) P (ξt = x)1 − μt(cid:2)(0.5 − d)e(cid:3)−t + d(cid:3)(cid:2)1 − (0.5 − d)e(cid:3)n−1(cid:4)−t − d(cid:3)(cid:2)(cid:2)(0.5 − d)e−t + d=1 − (0.5 − d)e(cid:3) 0.5(1 − d)n−1. %% further relax(cid:3)n−1−t − dP (ξt = x)1 − μtx /∈ X ∗%% by Eq. (1)Therefore, βt = 0.5(1 − d)n−1, by Theorem 1, the EFHT is lower bounded(1 − βi) = 2(1 − d)−n+1 = 2θ n−1,E[τ ] (cid:2) β0 ++∞(cid:4)t=2tβt−1t−2(cid:5)i=0that is, E[τ ] = Ω(θ n). (cid:2)5. DiscussionIn the previous section, we have proved that it needs exponential time to obtain the optimal solution to the Trapproblem using several variations of EAs. To arrive the proof of that the Trap problem is hard to be solved by the EA usingMutation#1, we need only to bound the part of success probability of formula (12). In the same way, we can also provethat any problem with exponential size of solution space, even easy problems such as the OneMax problem, is hard forthe EA using Mutation#1. This suggests that a non-adaptive mutation rate is not suitable for any problem which is withexponential size of solution space, and in those cases an adaptive mutation rate is preferred.From the proofs for EAs using Mutations #2, #3 and Recombination, we find a common trick. At first the successprobability at the initial step is exponentially small, then the EA goes toward a wrong direction which makes the successprobability even lower. To disclose what is behind this trick, we re-investigate formula (12), i.e.,(cid:4)x /∈ X ∗(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:3) P (ξt = x)1 − μt=(cid:2)P(cid:4)x /∈ X ∗∗ ∈ ξ Mt+1s∪ ξ Rt+1| ξt = x(cid:3) P (ξt = x)1 − μt,%% by that Selection does not generate solutionswhere ξ Mis the optimal solution.t+1 and ξ Rt+1 are the populations reproduced by mutation and recombination operators from ξt , respectively, and s∗The above formula consists of two parts. The success probability part(cid:2)P∗ ∈ ξ Mt+1s∪ ξ Rt+1(cid:3)| ξt = xis determined by the Reproduction operators. Once the operators of the EA are fixed, the success probability is determined.In other words, this part is at the algorithm side. The normalized distribution part P (ξt =x)is calculated by a recursive(1−μt )equationP (ξt+1 = x) = P (ξt = x) +P (ξt+1 = x | ξt = y)P (ξt = y) −P (ξt+1 = y | ξt = x)P (ξt = x),(cid:4)(cid:4)y /∈ X ∗y /∈X ∗in which, once the Reproduction operators have been fixed, the non-recursive terms P (ξt+1 = x | ξt = y) and P (ξt+1 = y |ξt = x) are determined by how solutions are favored, which is dominated by the fitness. Considering that when we applyan existing EA to tackle a problem, the Reproduction operator is fixed before we see the problem, while the fitness fullydepends on the problem. So, the normalized distribution part is at the problem side.So, our explanation to the question that what makes a problem hard to an EA is, on such problem the EA will run ina direction, which causes that the probability of being in good areas (i.e., having a large success probability) to decreasewhile that of being in bad areas (i.e., having a small success probability) to increase. In other words, the algorithm sidemismatches the problem side.Motivated by this recognition, we raise a question: how large is a problem class which, for any EA, contains at least oneproblem instance that cannot be solved by the EA in polynomial time? The answer to this question implies a general boundon the effectiveness of EAs.At the first glance, this question seems related to the No Free Lunch theorem [26] which indicates that if all possibleproblems are considered, and if every problem instance has equal chance to be encountered (which is arguable), any twoalgorithms will have equal average performance. But note that the No Free Lunch theorem only considers whether onealgorithm is relatively better than another algorithm, and an algorithm performs poor on a problem does not mean otheralgorithms will also perform poor on this problem. While, what we want to know is, whether there is some problem classwhich is hard for all EAs, that is, for any EA the problem class contains at least one hard problem instance.We find that, for any EAs there must exist a problem instance which is hard in an exponential size general problem.1830Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832Definition 6 (General problem). A general problem with a solution space S and solution space size |S| is a finite set ofproblem instances, where every function in a bijective function cluster F : S → {1, 2, . . . , |S|} corresponds to the fitnessfunction of a problem instance.In other words, a general problem contains |S|! number of problem instances, each is a permutation of solutions. Thus,every point in the solution space can be found as the optimal solution to an instance of the general problem.We denote exp(n) as the exponential order of n, and poly(n) as the polynomial order of n, omitting the exact componentsof that order.Theorem 2. Given that(a) a general problem with a solution space size no smaller than exp(n),(b) an EA with a population size no larger than poly(n),(c) every solution has an equal probability to appear in the initial population,there exists at least one problem instance on which the EFHT of the EA is no smaller than exp(n)/ poly(n), where n is the problem size.Proof. Denote Reprod(ξt ) as the solution set generated by Reproduction operators, of which the size is no more thanpoly(n) (otherwise it already costs exp(n) time). Considering that |S| = exp(n) and population size is no more than poly(n),the population state space | X| = exp(n)poly(n). We have(cid:2)(cid:3)s ∈ Reprod(ξt) | ξt = xP(cid:3)(cid:30)(cid:30)(cid:30) (cid:3) poly(n)(cid:30)Reprod(ξt)(cid:4)s∈S⇒(cid:4)(cid:4)s∈Sx∈ X⇒ ∃˜s ∈ S :(cid:2)(cid:3)s ∈ Reprod(ξt ) | ξt = xP(cid:3) poly(n) exp(n)poly(n)(cid:4)x∈ X(cid:2)(cid:3)˜s ∈ Reprod(ξt) | ξt = xP(cid:3) poly(n) exp(n)poly(n)1exp(n).%% otherwise the sum over S will exceed poly(n) exp(n)poly(n)Let ˜s denote the optimal solution sAt time t = 0, we have∗.(cid:4)x /∈ X ∗==(cid:2)ξ1 ∈ XP∗ | ξ0 = x(cid:3) P (ξ0 = x)1 − μ0(cid:2)Ps(cid:4)x /∈ X ∗∗ ∈ Reprod(ξ0) | ξ0 = x(cid:3) P (ξ0 = x)1 − μ0%% by that the selection does not generate new solutions(cid:4)(cid:3)∗ ∈ Reprod(ξ0) | ξ0 = xP(cid:2)s%% by assumption μ0 = 01exp(n)poly(n)x /∈ X ∗(cid:3) poly(n) exp(n)poly(n)1exp(n)1exp(n)poly(n)= poly(n)exp(n).At time t + 1, we sort all non-optimal population states into a sequence {xi} (xi /∈ X(cid:2)ξt+1 ∈ XP(cid:3)∗ | ξt = xi(cid:3) P(cid:2)ξt+1 ∈ X∗ | ξt = xi+1(cid:3).∗), such thatAfterwards, we have(cid:4)x∈ X(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = xP=(cid:4)x∈ X(cid:2)(cid:3)∗ ∈ Reprod(ξt) | ξt = xsP(cid:3) poly(n) exp(n)poly(n)exp(n)⇒ ∃ˆx ∈ X:(cid:2)ξt+1 ∈ X(cid:3)∗ | ξt = ˆxP(cid:3) poly(n)exp(n).%% otherwise the sum over X will exceedpoly(n) exp(n)poly(n)exp(n)Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18321831Therefore,(cid:2)ξ RtP= x∗ | ξt = x0(cid:3)(cid:2)ξ Rt(cid:3) P= x∗|ξt = ˆx(cid:3)(cid:3) poly(n)exp(n),by considering that x0 has the lowest success probability.Now, we choose a fitness function f (·) such that∗f (x) > f (x0) > · · · > f (xi) > f (xi+1) > . . . .Since the solutions with larger fitness values will have higher probability to survive from the selection, we have∀k:P (ξt+1 ∈ {x0, . . . , xk})P (ξt+1 ∈ X − {x0, . . . , xk} − {x∗})P (ξt+1 ∈ {x0, . . . , xk})1 − μt+1⇒ ∀k:(cid:2) P (ξt ∈ {x0, . . . , xk})1 − μt.>P (ξt ∈ {x0, . . . , xk})P (ξt ∈ X − {x0, . . . , xk} − {x∗})Then, we have(cid:4)x /∈ X ∗(cid:3)(cid:2)ξt+1 ∈ XP∗ | ξt = x(cid:2)ξ1 ∈ XP(cid:4)x /∈ X ∗∗ | ξ0 = x(cid:3) P (ξt = x)1 − μt(cid:3) P (ξ0 = x)1 − μt(cid:3) poly(n)exp(n),which makes E[τ ] (cid:2) exp(n)poly(n) by Theorem 1. (cid:2)6. ConclusionThis paper extends our preliminary research [27]. We establish a bridge between two of the most important theoreticalissues of evolutionary algorithms (EAs), that is, the expected first hitting time (EFHT) and the convergence rate. With thisbridge, we propose a new approach for analyzing the EFHT of EAs. The proposed approach bases on non-homogeneousMarkov chains, and thus it is suitable for analyzing a broad range of EAs.Using the proposed approach, we proved that a problem is hard (i.e., can only be solved in exponential time) for severalEAs under various settings, including three static mutation operators, with/without population, a recombination operatorand a time-variant mutation operator. It is noteworthy that the time-variant operator was hard to analyze before, while theproposed approach is naturally useful for this situation.We gave an explanation to the question that what makes a problem hard to EA, that is, the algorithm part and theproblem part mismatch. EAs are usually considered as general optimization approaches, or in other words, they are problemindependent. Thus, when the parameters of an EA are fixed, the EA may run toward a wrong direction on some problems,which makes the problems hard for the EA. Based on this recognition, we proved that a general problem is hard if it has anexponentially large state space.In the future, we intend to extend our approach to optimization problems for real-valued functions.AcknowledgementsWe want to thank the anonymous reviewers for their helpful comments and suggestions, and want to thank Tianshi Chen,Xiang-Nan Kong, Chao Qian and De-Chuan Zhan for proofreading the paper. We also want to thank the editor RaymondPerrault for his generous help in polishing the final version of the paper. This research was supported by the NationalScience Foundation of China (60635030, 60721002).References[1] T. Bäck, Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms, Oxford University Press,Oxford, UK, 1996.[2] H.-G. Beyer, H.-P. Schwefel, I. Wegener, How to analyse evolutionary algorithms, Theoretical Computer Science 287 (1) (2002) 101–130.[3] S.-J. Chang, H.-S. Hou, Y.-K. Su, Automated passive filter synthesis using a novel tree representation and genetic programming, IEEE Transactions onEvolutionary Computation 10 (1) (2006) 93–100.[4] Y.-C. Chang, S.-M. Chen, A new query reweighting method for document retrieval based on genetic algorithms, IEEE Transactions on EvolutionaryComputation 10 (5) (2006) 617–622.[5] S. Droste, T. Jansen, I. Wegener, On the optimization of unimodal functions with the (1 + 1) evolutionary algorithm, in: Proceedings of the 5thInternational Conference on Parallel Problem Solving from Nature (PPSN V), Amsterdam, Netherlands, 1998.[6] S. Droste, T. Jansen, I. Wegener, A rigorous complexity analysis of the (1 + 1) evolutionary algorithm for linear functions with boolean inputs, Evolu-tionary Computation 6 (2) (1998) 185–196.[7] S. Droste, T. Jansen, I. Wegener, On the analysis of the (1 + 1) evolutionary algorithm, Theoretical Computer Science 276 (1–2) (2002) 51–81.1832Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832[8] A.E. Eiben, R. Hinterding, Z. Michalewicz, Parameter control in evolutionary algorithms, IEEE Transactions on Evolutionary Computation 3 (2) (1999)124–141.[9] A.A. Freitas, A survey of evolutionary algorithms for data mining and knowledge discovery, in: A. Ghosh, S. Tsutsui (Eds.), Advances in EvolutionaryComputing: Theory and Applications, Springer-Verlag, New York, NY, 2003, pp. 819–845.[10] J. Garnier, L. Kallel, M. Schoenauer, Rigorous hitting times for binary mutations, Evolutionary Computation 7 (2) (1999) 173–203.[11] B. Hajek, Hitting time and occupation time bounds implied by drift analysis with applications, Advances in Applied Probability 14 (1982) 502–525.[12] J. He, L. Kang, On the convergence rates of genetic algorithms, Theoretical Computer Science 229 (1–2) (1999) 23–39.[13] J. He, X. Yao, Drift analysis and average time complexity of evolutionary algorithms, Artificial Intelligence 127 (1) (2001) 57–85.[14] J. He, X. Yao, Towards an analytic framework for analysing the computation time of evolutionary algorithms, Artificial Intelligence 145 (1–2) (2003)59–97.[15] J. He, X. Yao, A study of drift analysis for estimating computation time of evolutionary algorithms, Natural Computing 3 (1) (2004) 21–35.[16] J. He, X. Yu, Conditions for the convergence of evolutionary algorithms, Journal of Systems Architecture 47 (7) (2001) 601–612.[17] P.C.H. Ma, K.C.C. Chan, X. Yao, D.K.Y. Chiu, An evolutionary clustering algorithm for gene expression microarray data analysis, IEEE Transactions onEvolutionary Computation 10 (3) (2006) 296–314.[18] A.E. Nix, M.D. Vose, Modeling genetic algorithms with Markov chains, Annals of Mathematics and Artificial Intelligence 5 (1) (1992) 77–88.[19] P.S. Oliveto, J. He, X. Yao, Time complexity of evolutionary algorithms for combinatorial optimization: A decade of results, International Journal ofAutomation and Computing 4 (3) (2007) 281–293.[20] J.S. Rosenthal, Minorization conditions and convergence rates for Markov chain Monte Carlo, Journal of the American Statistical Association 90 (430)(1995) 558–566.[21] G. Rudolph, Convergence analysis of canonical genetic algorithms, IEEE Transactions on Neural Networks 5 (1) (1994) 96–101.[22] G. Rudolph, How mutation and selection solve long path problems in polynomial expected time, Evolutionary Computation 4 (2) (1996) 195–205.[23] G. Rudolph, Convergence Properties of Evolutionary Algorithms, Verlag Dr. Kovaˇc, Hamburg, Germany, 1997.[24] G. Rudolph, Finite Markov chain results in evolutionary computation: A tour d’horizon, Fundamenta Informaticae 35 (1–4) (1998) 67–89.[25] J. Suzuki, A Markov chain analysis on simple genetic algorithms, IEEE Transactions on Systems, Man and Cybernetics 25 (4) (1995) 655–659.[26] D. Wolpert, W.G. Macready, No free lunch theorems for optimization, IEEE Transactions on Evolutionary Computation 1 (1) (1997) 67–82.[27] Y. Yu, Z.-H. Zhou, A new approach to estimating the expected first hitting time of evolutionary algorithms, in: Proceeding of the 21st National Confer-ence on Artificial Intelligence, Boston, WA, 2006, pp. 555–560.