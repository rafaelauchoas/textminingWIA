Artificial Intelligence 175 (2011) 2198–2222Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDecision-theoretic planning with generalized first-order decisiondiagramsSaket Joshi a, Kristian Kersting b, Roni Khardon c,∗a School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR 97331, USAb Knowledge Discovery Department, Fraunhofer IAIS, 53754, Sankt Augustin, Germanyc Department of Computer Science, Tufts University, Medford, MA 02155, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 19 February 2010Received in revised form 9 September 2011Accepted 11 September 2011Available online 16 September 2011Keywords:Knowledge representationAutomated reasoningFirst order logicModel checkingMarkov decision processDynamic programmingDecision theoretic planningMany tasks in AI require representation and manipulation of complex functions. First-OrderDecision Diagrams (FODD) are a compact knowledge representation expressing functionsover relational structures. They represent numerical functions that, when constrained tothe Boolean range, use only existential quantification. Previous work has developed a setof operations for composition and for removing redundancies in FODDs, thus keeping themcompact, and showed how to successfully employ FODDs for solving large-scale stochasticplanning problems through the formalism of relational Markov decision processes (RMDP).In this paper, we introduce several new ideas enhancing the applicability of FODDs. Morespecifically, we first introduce Generalized FODDs (GFODD) and composition operationsfor them, generalizing FODDs to arbitrary quantification. Second, we develop a novelapproach for reducing (G)FODDs using model checking. This yields – for the first time –a reduction that maximally reduces the diagram for the FODD case and provides a soundreduction procedure for GFODDs. Finally we show how GFODDs can be used in principleto solve RMDPs with arbitrary quantification, and develop a complete solution for the casewhere the reward function is specified using an arbitrary number of existential quantifiersfollowed by an arbitrary number of universal quantifiers.© 2011 Elsevier B.V. All rights reserved.1. IntroductionThe problem of an autonomous agent acting optimally in an environment is central to Artificial Intelligence. There aremany variants of this problem. For the case where the stochastic dynamics of the environment are known and the objectivecan be described by a reward function, Markov decision processes (MDP) have become the standard model [1,2]. Classicaldynamic programming algorithms for solving MDPs [3,4], however, require explicit state enumeration. This is often imprac-tical as the number of states grows very quickly with the number of domain objects and relations. For example in a domainwith predicate on( X, Y ), and n objects that can be substituted for X and Y , we have at least n2 ground propositions and 2n2potential states. Classical solutions require enumeration of these 2n2states. In other words, classical dynamic programmingsolutions to MDPs do not scale to bigger problems because the size of the state space is too large.One potential solution to this problem is the use of structure in representing state and action spaces. Many problems arenaturally described by referring to objects and relations among them. Relational representations naturally factor the statespace and they can capture parameterized functions over the state space. The past few years have seen the successes of thisapproach in the field of Statistical Relational Learning [5] which combines expressive knowledge representation formalisms* Corresponding author.E-mail address: roni@cs.tufts.edu (R. Khardon).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.09.001S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222199with statistical approaches to perform probabilistic inference and learning in relational domains. MDPs enhanced with suchrepresentations are known as relational or first-order MDPs.Recently, Boutilier et al. [6] have shown how algorithms for relational MDPs (RMDP) can be used to solve stochasticplanning problems. Inspired by this seminal work, several authors have developed different representation schemes and al-gorithms implementing this idea [7–10]. In particular, Wang et al. [9] and Joshi and Khardon [11] introduced the First-OrderDecision Diagram (FODD) representation, showed how RMDPs can be solved using FODDs, and provided a prototype imple-mentation that performs well on problems from the International Planning Competition. The use of FODDs to date, however,has two main limitations. The first is representation power. FODDs (roughly speaking) represent existential statements butdo not allow universal quantification. This excludes some basic planning tasks. For example, a company that has to plan aphysical meeting of all employees requires that they are all in a single location thus requiring a quantifier prefix ∃∀ for thegoal; the goal can be expressed as “there exists a location such that all employees are in that location”. The second is thatmanipulation algorithms for FODDs require special reductions to ensure that their size is small. Such reductions have beenintroduced but they are not complete, i.e., they may not yield a small FODD although one exists.In this article, we show how one can overcome these limitations. Specifically, we make the following three contributions.First, we introduce Generalized FODDs (GFODD), a novel FODD variant that allows for arbitrary quantification as well asmore general aggregations of values. Basic algorithms that allow us to perform operations over functions represented byGFODDs are developed. Second, we show how GFODDs can be used to solve RMDPs with arbitrary quantification. Finally, weprovide a novel reduction approach based on model checking. This provides the first reduction for FODDs that guaranteesthat the resulting FODD is “maximally reduced” in a sense which is defined precisely in the technical section. This isa significantly stronger reduction than ones that existed previously for FODDs. In addition we develop model checkingreductions for the ∃∗∀∗quantifier setting of GFODDs, where a finite number of existential quantifiers is followed by afinite number of universal quantifiers. We show that this enables solutions for RMDPs with reward functions given by ∃∗∀∗statements, where all intermediate constructs in the algorithm are maintained in this form. The new representations andalgorithms developed form a significant extension of the scope of the FODD approach to decision-theoretic planning and asignificant improvement of our understanding of their reductions.The new reductions presented in the paper have a relatively high complexity and are not likely to be efficient in practicefor large diagrams. However, they provide the basis for easy-to-implement heuristic reductions for FODDs. In recent work[12] we developed such heuristic reductions as well as heuristics for generating the models from problem descriptions. Thenew reductions provide significant speedup in planning time, over an implementation using theorem proving reductions,while maintaining state-of-the-art performance on problems from the international planning competition. Model checkingreductions are therefore important in expanding applicability of FODDs to decision theoretic planning. Practical implemen-tations of reductions for GFODDs will be similarly important for their applicability.Our results are also closely related to recent work on probabilistic inference with large models. In fact, the relationalvalue iteration algorithm of Boutilier et al. [6] and our implementation of this algorithm using (G)FODDs can be seen toperform some form of lifted inference in probabilistic models. Recently several algorithms that take advantage of modelstructure in inference have been proposed [13–21]. Whereas, existing approaches essentially take a single ground modeland a single ground question and calculate a numerical solution for the question, our solutions for RMDPs take a familyof models and a potentially non-ground question as input, and calculate numerical solutions for all members of the family.Of course the planning models must have some structure to make this possible and this is precisely the structure ouralgorithms take advantage of.We proceed as follows. After briefly reviewing FODDs, we present the model checking reduction operator for FODDs inSection 3. Then, in Section 4, we introduce GFODDs and their composition operations. Section 5 extends the model checkingreduction operator to GFODDs with the quantifier setting ∃∗∀∗. Finally Section 6 shows the utility of GFODDs for solvingRMDPs. To that end we devise a value iteration approach for RMDPs using GFODDs. Note that, since knowledge of RMDPsis not required for the development and algorithms for GFODDs, we have deferred the introduction of RMDPs to Section 6.2. First-order decision diagramsThis section briefly reviews previous work on FODDs [9]. We use standard terminology from first-order logic [22]. A first-order decision diagram is a labeled directed acyclic graph, where each non-leaf node has exactly 2 outgoing edges labeledtrue and false. The non-leaf nodes are labeled by atoms generated from a predetermined signature of predicates, con-stants and an enumerable set of variables. Leaf nodes have non-negative numeric values. The signature also defines a totalorder on atoms, and the FODD is ordered with every parent smaller than the child according to that order.Example 1. Two examples of FODDs are given in Fig. 1; in these and all diagrams in the paper left going edges representthe branch taken when the predicate is true and right edges are the false branches.Thus, a FODD is similar to a formula in first-order logic. Its meaning is similarly defined relative to interpretations of thesymbols. An interpretation defines a domain of objects, identifies each constant with an object, and specifies the truth valueof each predicate over these objects. In the context of relational MDPs, an interpretation represents a state of the world withthe objects and relations among them. Given a FODD and an interpretation, a valuation assigns each variable in the FODD2200S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–2222Fig. 1. Examples of FODDs. Left going edges represent the branch taken when the predicate is true and right edges are the false branches.Fig. 2. A FODD example illustrating the need for DPOs.to an object in the interpretation. Following Groote and Tveretina [23], the semantics of FODDs are defined as follows. If Bis a FODD and I is an interpretation, a valuation ζ that assigns a domain element of I to each variable in B fixes the truthvalue of every node atom in B under I . The FODD B can then be traversed in order to reach a leaf. The value of the leaf isdenoted by MapB (I, ζ ). MapB (I) is then defined as maxζ MapB (I), that is, an aggregation of MapB (I, ζ ) over all valuations ζ .Example 2. Consider the FODD in Fig. 1(a) and the interpretation I with objects a, b and where the only true atoms arep(a), q(b). The valuations {x/a, y/a}, {x/a, y/b}, {x/b, y/a}, and {x/b, y/b}, will produce the values 0, 1, 0, 0 respectively. Bythe max aggregation semantics, MapB (I) = max{0, 1, 0, 0} = 1. Thus, this FODD is equivalent to the formula ∃x∃ y, p(x) ∧q( y).In general, max aggregation yields existential quantification when leaves are binary. When using numerical values wecan similarly capture value functions for relational MDPs.The following notation will be used to discuss FODDs and their properties. If e is an edge from node n to node m, thentarget(e) = m. For node n, the symbols n↓t and n↓ f denote the true and false edges out of n respectively. Furthermore,l(n) denotes the atom associated with node n. Node formulas (NF) and edge formulas (EF) are defined recursively as follows.For a node n labeled l(n) with incoming edges e1, . . . , ek, the node formula NF(n) = (i EF(ei)). The edge formula for thetrue outgoing edge of n is EF(n↓t) = NF(n) ∧ l(n). The edge formula for the false outgoing edge of n is EF(n↓ f ) =NF(n) ∧ ¬l(n). These formulas, where all variables are existentially quantified, capture the conditions under which a nodeor edge are reached. Similarly, if B is a FODD and p is a path from the root to a leaf in B, then the path formula for p,denoted by PF(p) is the conjunction of literals along p. When the variables of p, are existentially quantified, satisfiabilityof PF(p) under an interpretation I is a necessary and sufficient condition for the path p to be traversed by some valuationunder I . If ζ is such a valuation, then we define PathB (I, ζ ) = p. The leaf reached by path p is denoted as leaf (p).(cid:2)As seen above FODDs can represent functions over relational structures. These functions can be combined under arith-metic operations, and reduced in order to remove redundancies, in a manner that extends ideas developed for propositional(binary and algebraic) decision diagrams [24,25]. In particular, Groote and Tveretina [23] introduced four reduction oper-ators (R1 . . . R4) and these were augmented with seven more reductions (R5 . . . R11) [9,11]. Intuitively, redundancies inFODDs arise in two different ways. In the first scenario, some edges may never be traversed by any valuation. Reductionoperators for such redundancies are called strong reduction operators. The second scenario requires more subtle analysis:there may be parts of the FODD that are traversed under some valuations but because of the max aggregation, the valu-ations that traverse those parts are never important for determining the map. Operators for such redundancies are calledweak reductions operators. Strong reductions preserve MapB (I, ζ ) for every valuation ζ (thereby preserving MapB (I)) andweak reductions preserve MapB (I) but not necessarily MapB (I, ζ ) for every ζ . Using this classification R1–R5 are strongreductions and R6–R11 are weak reductions.Weak reductions have their basis in the idea that some parts of the FODD dominate the map and therefore parts thatare dominated can be removed or replaced by a 0 leaf. However, there are cases when two parts of the FODD dominateeach other.Example 3. Consider the FODD in Fig. 2. This simple FODD contains only 2 paths leading to non-zero leaves:1. p(x), ¬p( y) → 1;2. ¬p(x), p(z) → 1.S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222201Notice that whenever there is a valuation traversing one of the paths, there is another valuation traversing the other andreaching the same leaf. Either of the two edges reaching the 1 leaf can point to a 0 leaf without changing the map. Howeverwe cannot allow both the edges to point to a zero leaf as that would change the map of some interpretations.To avoid this ambiguity we must specify a total order on the paths, and in this way we can choose which path to remove.A descending path ordering (DPO) is constructed specifically for this purpose.Definition 1. A descending path ordering (DPO) is an ordered list of all paths from the root to leaves in a FODD, sorted indescending order by the value of the leaf reached by the path. The relative order of paths reaching the same leaf can be setarbitrarily.A DPO provides a preference ordering over paths. Paths with different values are naturally ordered by their values andthis is incorporated in the DPO. Paths with the same value are ordered according to the (arbitrary) ordering in the DPOwhere paths with a lower index are preferred to paths with a higher index. This preference is captured in the notion ofinstrumental paths which is defined next.Definition 2. If B is a FODD, and PL is a DPO for B, then a path p j ∈ PL is instrumental with respect to PL iff there is aninterpretation I such that1. there is a valuation ζ such that PathB (I, ζ ) = p j , and2. for all valuations η, if PathB (I, η) = pk, then k (cid:2) j.Paths that are not instrumental can be removed from a diagram without changing the function it computes. The choiceof DPO can affect the size of the reduced diagram, but it is not clear at the outset how to best choose a DPO so as tomaximally reduce the size of a diagram. This is illustrated and discussed further in the context of the R12 reduction.Finally, an additional subtlety arises because for RMDP domains we may have some background knowledge about thepredicates in the domain specifying some constraints on them. For example, in the blocks world, if block a is clear thenon(x, a) is false for all values of x. This fact might help simplify the diagram. We denote such background knowledge by Band allow reductions to rely on such knowledge.3. R12: The model checking reduction for FODDsIn this section we introduce a new reduction operator R12 (numbered to agree with previous work). The basic intuitionbehind R12 is to use the semantics of the FODD directly in the reduction process. According to the semantics of FODDsthe map is generated by aggregation of values obtained by running all possible valuations through the FODD. Therefore,if we run all possible valuations through the diagram and document the paths taken by the valuations under all possibleinterpretations, we can identify parts of the diagram that are never important for determining the map. Such parts can thenbe eliminated to reduce the diagram. Crucially, with some bookkeeping, it is possible to obtain this information withoutenumerating all possible interpretations and by enumerating all possible valuations over just the variables in the diagram.This is the basic intuition behind R12.We can avoid enumerating all possible interpretations with the observation that although there can be many interpreta-tions over a set of domain objects, there are only a fixed number of paths in the FODD that a valuation can traverse. For agiven valuation ζ , any interpretation can be classified into one of a set of equivalence classes based on the path p that itforces ζ through. All interpretations belonging to an equivalence class have the following in common.1. They force ζ through path p and leaf (p), the leaf reached by path p.2. They are consistent with PF(p)(ζ ).PF(p)(ζ ) is, thus, the most general interpretation that forces ζ through p and can be viewed as a key or identifierfor its equivalence class. For the purpose of reduction we are not interested in the interpretations themselves but only inthe paths that they force valuations through. Therefore we can restrict our attention to the equivalence classes and avoidenumerating all possible interpretations. In other words, if we collect the abstract interpretation PF(p)(ζ ) for every pathp that a valuation ζ could possibly take (i.e. every path where PF(p)(ζ ) is consistent), along with the corresponding pathand leaf reached, we will have all information we need to describe the behavior of ζ under all possible interpretations. Theprocedure getBehaviors described below, does exactly that by simulating the run of a valuation through a FODD. The outputof the procedure is a set of (cid:9)leaf , EL, I(cid:10) 3-tuples, where leaf is the leaf reached by the valuation ζ by traversing the path p(described by the set of edges EL) and I = PF(p)(ζ ). Recall that B denotes the background knowledge on the domain. Theprocedure is as follows.2202S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–2222Fig. 3. An example of reduction operator R12 for FODDs. Each entry of the form value-{path}-{interpretation} in the table (enclosing angle brackets removedin figure to improve readability) expresses the value obtained by running the valuation of the corresponding row through the diagram under an equivalenceclass of interpretations. The max3 aggregation function then calculates the possible aggregates that could be generated under different equivalence classesof interpretations. Since the edge 1 f does not appear in any of the paths in the result of max3, it is not important toward determining the map and canbe removed.Procedure 1. getBehaviors(valuation ζ , PathFormula PF, EdgeList EL, Node n)1. If n is a leaf, return {{l(n), EL, PF}}2. If B |(cid:11) PF → l(n)(ζ ), thenreturn getBehaviors(ζ , PF ∪ l(n)(ζ ), EL ∪ n↓t , target(n↓t ))Else If B |(cid:11) PF → ¬l(n)(ζ ), thenreturn getBehaviors(ζ , PF ∪ ¬l(n)(ζ ), EL ∪ n↓ f , target(n↓ f ))Elsereturn getBehaviors(ζ , PF ∪ l(n), EL ∪ n↓t , target(n↓t ))∪ getBehaviors(ζ , PF ∪ ¬l(n), EL ∪ n↓ f , target(n↓ f ))Example 4. Fig. 3 shows an example of the R12 reduction whose details are developed below. For this example we focus onthe table in the center of the figure. The table illustrates the result of running the getBehaviors procedure on all possiblevaluations over the set of domain objects {a, b} and the variables x and y appearing in the left FODD. For example, thetraversal of valuation {x/a, y/b} through the FODD has 3 possible eventualities. Either it reaches a 10 leaf by traversing path{1t} (which is short for the path consisting of the true edge of node 1), under abstract interpretation {p(a)}, or it reaches a10 leaf by traversing path {1 f 2t} (which is short for the path consisting of the false edge of node 1 followed by the true edge ofnode 2), under abstract interpretation {¬p(a), p(b)} or (in all other cases) it reaches a 0 leaf.Note that the different behaviors of a valuation are mutually exclusive because the abstract interpretations associatedwith these behaviors partition the space of worlds. Any interpretation must be consistent with exactly one of these abstractinterpretations and hence must force the behavior corresponding to that abstract interpretation on the valuation.Thus, as in Fig. 3, with the help of the getBehaviors procedure we can tabulate the possible behaviors of all valuationsover a set of domain objects. The next step is to generate all possible ways in which an aggregate value can be derived.This can be done without enumerating all interpretations. The table of potential behaviors gives sufficient information tolist all possible ways to aggregate over the set of all valuations, by considering all combinations of behaviors over the set ofvaluations. Every combination, as long as it is consistent, produces the map as an aggregate value. To facilitate reduction theaggregation has to be augmented so as to expose the valuations and paths that prove to be important for determining themap. Intuitively, paths that were not shown to be important in spite of listing all possible ways to aggregate over the set ofall valuations can be removed. To this end, the next section introduces variants of the max aggregation function, max2 andmax3.3.1. Generalized aggregation function and the R12 reductionWhen calculating the map, the max aggregation operation is applied to values obtained by evaluating the FODD underdifferent valuations. As discussed above, for R12, we are interested not just in the aggregate value but also in informationthat will help us identify which edges are used to determine the map. Toward that, when calculating the maximum, weS. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222203collect information about the winning path, the valuation that leads to it, and the interpretation (captured by the groundpath formula) for which this happens. To enable the such accounting we define three variants of the max aggregationoperator.max1: The first variant max1 is the usual aggregation operator that given a set of values {v 1, . . . , vn} returns the aggregatev = max({v 1, . . . , vn}).max2: requires a DPO to calculate its output. The input to max2 is a set of 3-tuples of the form (cid:9)v i, pathi, I i(cid:10) with theintention that each 3-tuple was produced by getBehaviors on a different valuation ζi . The output is a 3-tuple (cid:9)vo, patho, Io(cid:10)where:1. vo = max1({v 1, v 2 · · · vn}).2. Io =3. patho(cid:3)ni=1 I i .= pathi and pathi has the least index in the DPO among paths with value vo.In other words, max2 takes as input one possible behavior from every valuation (one entry from each row in the valuationtable in Fig. 3) and aggregates the result, recording the winning path, and the interpretation that induces the correspondingbehavior on each valuation.Example 5. The example in Fig. 3 shows the DPO and the 3 possible aggregation results derived from the table. Each ofthe 3 results is derived using the max2 variant. For example, aggregating over• (cid:9)10, {1t}, {p(a)}(cid:10) for {x/a, y/a},• (cid:9)10, {1t}, {p(a)}(cid:10) for {x/a, y/b},• (cid:9)10, {1t}, {p(b)}(cid:10) for {x/b, y/a},• (cid:9)10, {1t}, {p(b)}(cid:10) for {x/b, y/b},using the max2 variant gives (cid:9)10, {1t}, {p(a), p(b)}(cid:10) indicating that there is a possible aggregation where the path consistingof the edge {1t} is instrumental in determining the map.The example illustrates that max2 captures the combined behavior of all valuations on the interpretation I0 which ispart of its output. As motivated above, we would like to capture this information for all possible interpretations. Instead ofenumerating interpretations, we generate all possible scenarios by considering all possible ways in which rows in the tableproduced by getBehaviors can be combined. This is done by max3.max3: requires a DPO to calculate its output. The input to max3 is a set of sets of 3-tuples, where each set of 3-tuples is associated with a valuation (this corresponds to the entire table from Fig. 3), denoted as T = {(cid:9)valuation1 −valueset1(cid:10), (cid:9)valuation2 − valueset2(cid:10), . . . , (cid:9)valuationn − valuesetn(cid:10)}. Let Tbe the Cartesian product of {valueset(cid:4)} so thatei ∈ Tis a set of tuples (cid:9)value, path, Interpretation(cid:10).(cid:13)(cid:13)max3(T ) is defined as(cid:4)max3(T ) =(cid:9)valuer, pathr, Ir(cid:10) = max2(ei)(cid:5)(cid:5) ei ∈ T(cid:13), valuer (cid:2) 0 and Ir is consistent(cid:6).Thus, max3(T ) is the collection of results of max2 applied to each element of Tcombined interpretation is consistent and the aggregate value is greater than zero.(cid:13)but restricted to the cases where theExample 6. The example in Fig. 3 shows the result of applying max3 to the elements in the table. There are 2 ×3 × 3 × 2 = 36 possible combinations of valuation behaviors, and hence 36 elements in Tand corresponding callsto max2. However, only 3 of these combinations result in a consistent combined interpretation and positive value. Forexample, under the given DPO, max2({(cid:9)10, {1t}, {p(a)}(cid:10), (cid:9)10, {1t}, {p(a)}(cid:10), (cid:9)10, {1 f 2t}, {p(a), ¬p(b)}(cid:10), (cid:9)10, {1t}, {p(b)}(cid:10)}) =(cid:9)10, {1t}, {p(a), p(b), ¬p(b)}(cid:10) is omitted from the result of max3(T ) because the combined abstract interpretation is in-consistent. Aggregations resulting in 0 value are ignored because 0 being the smallest obtainable value, is uninterestingunder the max aggregation semantics. Observe that in this example, the path {1t} is the only instrumental path. Intuitivelythis implies that the target of any edge not on this path (for instance edge 1 f ) can be set to 0 without changing the map.The resulting FODD is shown on the right.(cid:13)Example 7. Consider the example of Fig. 3 but with a DPO that reverses the order of paths 1 and 2. In this case the tableproduced by getBehaviors is identical, and so is the aggregated value. But the maximizing paths are not the same. The threeoutputs of max3 are (cid:9)10, {1t}, {p(a), p(b)}(cid:10), (cid:9)10, {1 f 2t}, {p(a), ¬p(b)}(cid:10), and(cid:9)10, {1 f 2t}, {¬p(a), p(b)}(cid:10). Thus in this case bothpaths are instrumental and no reduction is achieved. This illustrates that the choice of DPO can be important in reducing adiagram. However, it is not clear how to best choose the DPO. A preference for shorter paths that defaults to lexicographicordering over equal length paths makes for an easy implementation but may not be the best. Our implementation [11,12]heuristically alternates this DPO and its reverse in hope of enabling more reductions.2204S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–2222The reduction is formalized in Procedures 2 and 3.Procedure 2. R12(FODD B)1. Let PL be a DPO for B.2. Let O be a set of v objects where v is the number of variables in B.3. Let U be the set of all possible valuations of the variables in B over O .4. Let S be the output of Reduction-Aggregation(B, U , PL).That is, S = {(cid:9)value1, path1, I1(cid:10), (cid:9)value2, path2, I2(cid:10), . . . , (cid:9)valuen, pathn, In(cid:10)}.(cid:13)be the set of all edges that appear on any path pathi in any 3-tuple in the set S.5. Let E6. Define E = B E − E7. For all edges e ∈ E, set target(e) in B to 0 to produce FODD B8. Return B, where B E is the set of all edges in B..(cid:13)(cid:13)(cid:13).Procedure 3. Reduction-Aggregation(FODD B, set of valuations U , DPO PL)1. Let Val = {}.2. Do for every valuation ζ ∈ U .2.1. valueset = getBehaviors(ζ, {}, {}, B root).2.2. Add the entry (cid:9)ζ − valueset(cid:10) to Val.3. Let T = max3(Val) under PL.4. Return T .3.2. Proof of correctnessThis section shows that the R12 procedure removes exactly the right edges on its input FODD. The proof relies on thenext lemma which shows that every instrumental path, for any potential interpretation I , is discovered by the procedure.This is shown by arguing that a small portion of I suffices for this purpose and that such a portion is constructed by R12.Lemma 1. If a path pi in FODD B is instrumental under PL, and the path reaches a non-zero leaf, then there exists an interpretation Iosuch that {leaf (pi), pi, Io} is in the set S calculated in Step 4 of the R12 procedure.(cid:13)(cid:13)Proof. If pi is instrumental under PL then there exist I and ζ such that PathB (I, ζ ) = pi and such that for all η, PathB (I, η)(cid:13)| (cid:3) |O | where O is the set of objects= p j implies j (cid:2) i. Let Oto make the sets O andconstructed in Step 2 of the algorithm. Let o1 be an object in OOand then defining truthvalues and predicates over the new objects to behave identically to o1.(cid:13)| new objects to O. Add |O | − |Oby first projecting I to include only the objects in Obe the set of objects in I that participate in ζ . Clearly 1 (cid:3) |Oequal in size. Construct interpretation Iincludes the relevant portion of I the valuation ζ traverses pi under I(cid:13), ˆζ ) = p j and j < i, we can construct valuation ˆζ (cid:13)such that PathB (IPathB (I, ˆζ (cid:13)) = p j . But this is not possible by the assumption. Therefore we conclude that for all η, PathB (Ij (cid:2) i.. Additionally, if there exists a valuation ˆζby replacing the new objects in ˆζ by o1 so that(cid:13), η) = p j impliesSince I(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)Let U be the set of all valuations of the variables in B over O(cid:13)that participate in traversing paths in B for all η ∈ U . By construction, the corresponding parts PF(PathB (Iatoms of Iwill be included in the valueset returned by the getBehaviors procedure. Clearly Io ⊆ Iis Io. By the definition of max3, S = max3(Val) under PL must contain {leaf (pi), pi, Io} when leaf (pi) is non-zero. (cid:2). Therefore if I(cid:13)(cid:13)(cid:13), η))η. That is, Io includes all the(cid:13), η))ηis consistent then so(cid:3)(cid:13). Let Io =η∈U PF(PathB (IThe proof of the previous lemma implicitly assumes that the signature does not include equality, whose truth valuechanges when the objects are reassigned. The lemma and all subsequent discussion can allow for equality by having steps 2–4 of R12 repeated for object set sizes up to v and step 5 take the union of exposed edges. This makes for longer argumentswithout adding any significant insight and we therefore focus on the simpler version in the paper.The previous lemma implies that we discover all edges on instrumental paths and this in turn implies that removingother edges does not change the map of the diagram. This intuition is captured in the next lemma and theorem.Lemma 2. If there exists an instrumental path under PL that contains the edge e in B and the path reaches a non-zero leaf, then e is inthe set Ecalculated in Step 5 of the R12 procedure.(cid:13)Proof. If there is an instrumental path pi ∈ PL that contains the edge e and reaches a non-zero leaf, then by Lemma 1 thereexists an interpretation Io such that {leaf (pi), pi, Io} ∈ S. By definition of E, e ∈ E. (cid:2)(cid:13)(cid:13)Theorem 1 (Soundness). For any FODD B, if FODD B(cid:13)is the output of R12(B), then for all interpretations I , MapB (I) = MapB(cid:13) (I).S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222205Fig. 4. Example where R12 can reduce the diagram but previous reductions fail.(cid:13)(cid:13)Proof. By the definition of R12, the only difference between B and Bpoint to the 0 leaf in Bcrossing these edges achieves a value of 0 in BValuations not crossing these edges will achieve the same value in Band valuation ζ , MapB (I, ζ ) (cid:2) MapB(cid:13) (I, ζ ) and hence MapB (I) (cid:2) MapB(cid:13) (I).is that some edges that pointed to subFODDs in B,. These are the edges in the set E at the end of the R12 procedure. Therefore any valuationbut could have achieved a higher value in B under the same interpretation.as they did in B. Therefore for any interpretation IFix any interpretation I and v = MapB (I). Let ζ be a valuation such that MapB (I, ζ ) = v. If there is more than one ζ thatgives value v, we choose one whose path p j has the least index in PL. By definition, p j is instrumental and by Lemma 2,either leaf (p j) = 0 or none of the edges of p j are removed by R12. In both cases, MapB(cid:13) (I, ζ ) = v = MapB (I). By thedefinition of the max aggregation semantics, MapB(cid:13) (I) (cid:2) MapB(cid:13) (I, ζ ) and therefore MapB(cid:13) (I) (cid:2) MapB (I). (cid:2)(cid:13)(cid:13)We next show that the reduction achieved by R12 is the best possible with respect to our notions of DPO and instru-mental paths.Theorem 2 (Maximum reduction w.r.t. DPO). If no path crossing edge e and reaching a non-zero leaf in B is instrumental under PL,then R12 removes e.Proof. By definition the set of all edges in B is partitioned into sets E and E, then thereexist a path pi ∈ PL and an interpretation Io such that e is an edge on pi , leaf (pi) is non-zero and {leaf (pi), pi, Io} is inthe set S calculated in Step 4 of the R12 procedure. The existence of {leaf (pi), pi, Io} in S implies that under Io, there is avaluation ζ ∈ U such that PathB (Io, ζ ) = pi and for all η ∈ U , PathB (Io, η) = p j implies j (cid:2) i. Therefore pi is instrumental.Therefore all edges in Ebelong to some instrumental path. This implies that e from the statement of the theorem is notin E(cid:13)and therefore it is removed by R12. (cid:2). Now, by construction, if e ∈ E(cid:13)(cid:13)(cid:13)3.3. DiscussionThe R12 procedure provides a comprehensive reduction operation for FODDs, by guaranteeing maximum reduction w.r.t.a DPO on its own. This is in contrast with the fact that all previous published reductions, taken together, do not provide thesame guarantee. The main reason is that previous reduction operators rely on theorem proving over single path formulas oredge implications. As the following example shows there are cases where such reduction operators fail to reduce a diagrambut R12 is successful.Example 8. Fig. 4 shows an example where R12 succeeds but previous reductions fail. Notice that there are two pathsreaching the 10 leaf in the left FODD. In this diagram, whenever a valuation reaches the 1 leaf there is another valuationthat reaches the 10 leaf through one of the two paths. However, neither of the path formulas are individually implied bythe formula for the path reaching the 1 leaf. Similarly neither of the edge formulas for the edges terminating in the 10 leafare implied by the edge formula for the edge terminating in the 1 leaf. R12, on the other hand, relies on model checkingand is able to reduce the FODD on the left to the FODD on the right.It is important to note, however, that one can in principle define a theorem proving reduction giving the same guaran-tees.1 For example, to state that path i is instrumental one can write(cid:7)(cid:8)∃xpi PF(pi)∧(cid:9)(cid:10)(cid:7)(cid:11)(cid:8)¬∃xp j PF(p j).j<iThe path is instrumental if and only if this formula is satisfiable. Thus theorem proving can provide maximum reductionwith respect to a DPO in the same way that R12 does. However, the theorem proving may be complex because it involves1 We are grateful to the anonymous reviewer who suggested this.2206S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–2222disjunctive reasoning. In fact, the R10 reduction [11] performs similar reasoning except that it checks the paths j (cid:3) ione at a time in order to make for simpler theorem proving, and therefore does not provide the same guarantees. Moreimportantly, this formulation has a significant disadvantage (shared with R10) in that it enumerates all the paths whoseindex is smaller than i. The main point in adopting a decision diagram representation over a decision tree, is the fact thata diagram can be exponentially smaller because of repeated sub-trees that are represented only once in a decision diagram.In other words, the number of paths in a diagram can be exponential in its size. In this case, enumerating the paths ina DPO is not practical and the theorem proving formulation will fail. In contrast, R12 does not need to generate the DPOexplicitly. Instead the procedure only needs to be able to compare two paths (in max3) and decide which one is higher inthe DPO. As mentioned above this is easy to perform efficiently for suitably chosen DPOs, such as ones preferring shorterpath and using lexicographic ordering. Therefore, when the number of paths is large R12 will be superior to the theoremproving formulation.On the other hand the complexity of R12 is also high in that it involves the enumeration of all possible valuations, andis thus exponential in the number of variables. Therefore, a direct implementation of R12 as specified here will not bepractical for FODDs with a large number of variables. In recent work we have introduced heuristic variants of R12 that aremore efficient and have shown that they lead to significant speedup over theorem proving reductions [12].Finally, R12 is distinguished from previous reductions by the fact that it employs the aggregation function of the FODDitself as its main subroutine. Therefore, one can imagine generalizing it for diagrams containing other aggregation functions.Indeed the next two sections define such generalized diagrams and model checking reductions for them. Correspondinggeneralized variants of the reductions based on theorem proving are not easy to obtain.4. Generalized FODDs: Syntax and semanticsThe max aggregation of FODDs makes them sufficiently expressive to represent many planning problems of interest.However, since the max aggregation mirrors existential quantification over the variables of the FODD, many other functionsover logical spaces cannot be represented by FODDs. These functions could be represented if the aggregation function wasmore complex. This idea is captured in the following definition.Definition 3. An aggregation function is any function f that takes as input a non-empty set of real values and returns a realvalue.Concrete examples of aggregation functions that are discussed further below include max, min, sum, and mean. Otherfunctions like product, variance and so on are also possible. We will pay special attention to min aggregation that allowsus to capture universally quantified formulas. In this section and the next, we discuss the properties of generalized FODDsusing arbitrary aggregations and the operations that can be performed to manipulate them. We start by a formal definitionof Generalized First-Order Decision Diagrams.Definition 4. A Generalized First-Order Decision Diagram (GFODD) is a 2-tuple (cid:9)V , D(cid:10), where(1) V is an ordered list of pairs (v i, opv i ), where v i is a variable and opv i(2) The variables v i are distinct, that is, v i has exactly one aggregation operator in V .(3) D is a FODD except that the leaves can be labeled by a special character D (for discard).is an aggregation operator.An example of a GFODD is given in Fig. 5. The corresponding list V as in the formal specification above is[(c, max), (b, min)] but we use the more intuitive alternative notation max(c) min(b) or maxc minb where this is clear fromthe context.The discard value D in the definition above allows for some paths in the diagram to provide no value. This can be usefulwhen multiple types of aggregations are used because one does not need to have a “default value” (like the value zero formax aggregation) which does not affect the result. This simplifies the implementation and analysis of one of the reductionspresented below.4.1. Semantics of GFODDsThe semantics for GFODDs follow the same approach of FODDs in that they first calculate the map for all valuationsand then aggregate these values. Whereas in FODDs we take a maximum over these values the computation for GFODDs ismore complex and follows the aggregation function. To simplify the notation, in the following when B = (cid:9)V , D(cid:10) and ζ is avaluation we sometimes refer to MapD (I, ζ ) as MapB (I, ζ ).Formally, let B = (cid:9)V , D(cid:10) be a GFODD where V = [(v 1, op1v1), (v 2, op2v2) · · · (vn, opnvn)] and let I be an interpretation. Themap value MapB (I) is defined by the following steps:(1) Each valuation ζ , mapping v 1 · · · vn to the domain of interpretation I is associated with a value MapD (I, ζ ). (2) Wecan now divide up these valuations into blocks. All valuations in a block have the same assignment of values to variablesS. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222207Fig. 5. A generalized FODD example.v 1 · · · vn−1 but they differ in the value of the variable vn. (3) We then “collapse” each block to a single valuation overvariables v 1 · · · vn−1 by eliminating the variable vn and replacing the set of associated values by their aggregate value. If allthe values in the block have the value D then the aggregate value is D. Otherwise, we remove D from the set of valuesand apply opn to the remaining set. This yields a table with the set of all possible valuations defined over the variablesv 1 · · · vn−1 each associated with a value (which was obtained by aggregating over the valuations of variable vn in theblock). (4) We repeat the same procedure for variables vn−1 to v 1 to produce a final aggregate value. The value of MapB (I)is this final aggregate value.The treatment of D values in step (3) captures the idea of ignoring the corresponding paths when calculating theaggregate value. Thus any D inputs to an aggregation operator are ignored and if all values are D this information is passedon to the next level.Example 9. The GFODD B in Fig. 5 captures the following statement from the logistics domain: There exists a city c suchthat for all boxes b, box b is in city c. The output of B is 10 if all boxes are in one city and 0 otherwise.2 In the exampleGFODD shown, V = [(c, max), (b, min)]. Aggregation is done from right to left, one variable at a time. In the example, thetable on the left shows the value of MapB (I, ζ ) for every possible valuation ζ . MapB (I) is calculated by first aggregating thevalues MapB (I, ζ ) over all assignments for the variable b using the min aggregation. This yields the table in the middle. Wethen aggregate all of the produced values over all assignments for variable c using the max operation. The resulting value,0 in this case, is MapB (I).In the following we need a notation to refer to the map value and its calculation. The procedure described can be seento perform aggregation over variables in V by nesting aggregation operators from left (outermost) to right (innermost), i.e.MapB (I) = op1v1(cid:7)op2v2(cid:7)· · ·(cid:7)opnvn(cid:7)MapB(cid:12)I, [v 1, v 2, . . . , vn](cid:13)(cid:8)(cid:8)(cid:8)(cid:8).· · ·The term in the center, MapB (I, [v 1, v 2, . . . vn]), is the value obtained by running a valuation defined by an assignmentto the variables v 1, . . . , vn through B under I . In order to reduce the notational clutter, in the rest of the paper we willdrop brackets so that the above equation looks as followsop2v2· · · opnvn(cid:7)(cid:12)MapBI, [v 1, v 2, . . . , vn](cid:13)(cid:8)= op1v1op2v2· · · opn−1vn−1opn(cid:7)c[v1···vn−1]1· · · c[v1···vn−1]m(cid:8)is a value corresponding to a different object assignment to variable vn in the block defined by theMapB (I) = op1v1[v1···vn−1]iwhere each cvalues assigned to the variables v 1 · · · vn−1.4.2. Basic properties of GFODDsSeveral observations can be made on GFODDs and their semantics. First, the order of variables in V is important. Chang-ing the order of the variables can obviously change the map of the diagram.Second, FODDs form a proper subclass of GFODDs where the aggregation operator associated with every variable is max.In this case, due to properties of the max aggregation, the order of variables in V is not important.Third, GFODDs with 0/1 leaves express the same functions as closed, function-free first-order formulas. In particularthis can be done by employing the min aggregation operator over universally quantified variables and the max aggregation2 In this example, to keep the GFODD diagram simple, we assume the variables are typed and use only valuations that conform to the types of thevariables. Had we used all possible valuations over the set of objects {b1, b2, c1, c2}, the diagram would have been more complicated as it would have hadto represent the formula ∃c, ∀b, city(c) ∧ [box(b) → in(b, c)].2208S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–2222Table 1List of some safe and unsafe pairs for operators.opc⊕⊕⊕⊕⊗⊗⊗⊗maxmaxmaxmaxopamaxminsumavgmaxminsumavgmaxminsumav gSafe/unsafesafesafeunsafesafesafesafesafesafesafesafeunsafeunsafeoperator over existentially quantified variables. To see this consider any GFODD (cid:9)V , D(cid:10) with 0/1 leaves and let F be aquantifier-free formula capturing the disjunction of path formulas for paths leading to the 1 leaf. Then interpreting V asquantifiers V , F is a closed first order formula that evaluates to true exactly when (cid:9)V , D(cid:10) evaluates to true. On the otherhand, given a closed first-order formula in prenex normal form V , F where F is in disjunctive normal form, we can builda FODD D by representing each conjunct in F as a FODD directly and then represent their disjunction using the applyprocedure of Wang et al. [9]. Now, as above (cid:9)V , D(cid:10) is equivalent to V , F .Finally, the definition above allows the final aggregate value to be D in the case where all reachable paths for I yieldthe value D. To ensure that GFODDs always represent well defined functions we disallow this case.Definition 5. A GFODD B is legal iff it obeys the GFODD syntax and for all interpretations I there is a valuation ζ such thatMapB (I, ζ ) (cid:17)= D.4.3. Combining GFODDsSo far we have focused on the syntax and semantics of GFODDs that can represent complex functions over relationalstructures. The utility of such a representation, though, is in performing operations over such functions, for example max(taking the maximum), + (addition) and × (multiplication). We call these operators combination operators and provide analgorithm Ex-apply to implement them. Notice that combination operators operate on functions and they are different fromaggregation operators that operate on sets of real values. The next definition provides the intended meaning of combination.Definition 6. GFODD B is a combination of GFODDs B 1 and B2 under the binary combination operator opc iff for allinterpretations I , MapB (I) = MapB1 (I) opc MapB2 (I).In the above we assume that the functions represented by B 1 and B2 are independent, i.e., that the variables theyaggregate over do not constrain each other. In principle, one could try to define the meaning of combination when a variableappears in both diagrams and aggregated similarly. However, this seems awkward and is not necessary for the calculus offunctions we use. Therefore, in the following we assume that the functions being combined do not share variables, that is,their quantifier-free portion is standardized apart.Aggregation and combination operators can interact, complicating the result of the combination operation. In the follow-ing we show that in some cases this does not happen and we can essentially use the algorithm that combines FODDs tocombine GFODDs. This is captured by the following condition on combination and aggregation operators:Definition 7. A combination operator opc and an aggregation operator opa are a safe pair iff opc distributes over opa, that is,iff for any set of non-negative values x1, x2, . . . , xk and any non-negative constant b it holds thatopa(x1, x2, . . . , xk) opc b = opa(x1 opc b, x2 opc b, . . . , xk opc b).Example 10. The aggregation operator max and combination operator + form a safe pair because for any set S = {c1 · · · cm}and constant b, max{c1 · · · cm} + b = max{c1 + b, . . . , cm + b}. The aggregation operator mean and the combination op-erator max do not form a safe pair. For example max{mean{1, 5, 3}, 4} = 4 but mean{max{1, 4}, max{5, 4}, max{4, 4}} =mean{4, 5, 4} = 4.33.Table 1 summarizes the safe and unsafe pairs for operators that are of interest to us. We later use the fact that themax and min aggregation operators are safe with all the combination operators listed. As mentioned above this conditionwill allow us to use a simple algorithm for combination. The cases that are not safe might still be processed using otheralgorithms but we leave the details of this for future work.S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222209Fig. 6. A simple example of adding two FODDs.We next review the details of the procedure apply(B 1, B2, op) for combining FODDs B1 and B2 under operation op [9].Recall that FODDs use an ordering over the atoms labeling nodes, so that atoms higher in the ordering are always higher inthe diagram. Let p and q be the roots of B 1 and B2 respectively. The apply procedure chooses a new root label (the loweramong labels of p, q) and recursively combines the corresponding sub-diagrams, according to the relation between the twolabels (≺, =, or (cid:19)).Example 11. Fig. 6 illustrates the operation of the apply procedure. In this example, we assume predicate ordering p1 ≺ p2,and parameter ordering x1 ≺ x2. Non-leaf nodes are annotated with numbers and numerical leaves are underlined foridentification during the execution trace. For example, the top level call adds the functions corresponding to nodes 1 and 3.Since p1(x1) is the smaller label it is picked as the label for the root of the result. Then we must add both left and rightchild of node 1 to node 3. These calls are performed recursively to yield the diagram on the right.The next lemma, by Wang et al. [9], shows that the apply procedure provides the correct map for every valuation:Lemma 3. (See [9].) Let C = apply( A, B, op), then for any I and ζ , MAP A(I, ζ ) op MAPB (I, ζ ) = MAPC (I, ζ ).We next define the combination procedure for GFODDs and prove its correctness.Definition 8. Let B1 = (cid:9)V 1, D1(cid:10) and B2 = (cid:9)V 2, D2(cid:10) be GFODDs where V 1 and V 2 do not have any variables in common, andlet opc be any combination operator.Ex-apply(B1, B2, opc ) returns (cid:9)V , D(cid:10), where1. V is the aggregation function obtained by appending V 2 to V 1.2. D = apply(D1, D2, opc).To show that this procedure is correct, we start by observing that when combining a diagram B with a constant (a de-generate diagram that has just one leaf node whose value is that constant) one can push the combination operation to theleaves.Lemma 4. Let B = (cid:9)V , D(cid:10) be a GFODD, b a non-negative constant, and opc a combination operator. If for every aggregation operatoropa in V , (opa, opc) is a safe pair, then, for all interpretations I , MapB (I) opc b = op1v1[MapB (I, [v 1, v 2 · · · vn]) opc b].· · · opnvnop2v2Proof. The proof is by induction on n, the number of operators (and variables) in V . By the semantics of GFODDs,(cid:13)(cid:8)(cid:12)(cid:7)MapB (I) opc b = op1v1· · · opnvnMapBI, [v 1 · · · vn]opc b.When n = 1, we haveMapB (I) opc b = op1v1(cid:12)(cid:7)MapB(cid:13)(cid:8)I, [v 1]opc b = op1v1(cid:7)MapB(cid:12)(cid:13)I, [v 1]opc b(cid:8)because op1 and opc form a safe pair. Assume that the statement is true for all V of n − 1 or fewer aggregation operators.Consider a V with n aggregation operators. We then have,(cid:13)(cid:8)(cid:12)(cid:7)(cid:8)opc b = op1v1[v1]1· · · c[v1]mopc b(cid:7)cMapB (I) opc b = op1v1= op1v1· · · opnMapBvn(cid:7)[v1]opc b · · · cc1(cid:8)I, [v 1 · · · vn][v1]m opc b[v1]ibecause op1 and opc form a safe pair. Here each cv 1. By the inductive hypothesis we know that(cid:13)(cid:8)(cid:12)op2v2· · · opnvn(cid:7)MapBI, [v 1, v 2 · · · vn]opc b = op2v2= op2v2· · · opnvn[MapB (I, [v 1, v 2 · · · vn])] for the ith value of the variable· · · opnvn(cid:7)MapB(cid:12)(cid:13)I, [v 1, v 2 · · · vn](cid:8).opc b2210Thus,S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–2222MapB (I) opc b = op1v1op2v2· · · opnvn(cid:7)(cid:12)(cid:13)I, [v 1, v 2 · · · vn](cid:8).opc bMapB(cid:2)The next theorem uses the lemma repeatedly with different constants to prove the correctness of Ex-apply.Theorem 3. Let B1 = (cid:9)V 1, D1(cid:10) and B2 = (cid:9)V 2, D2(cid:10) be GFODDs that do not share any variables and assume that opc forms a safe pairwith all operators in V 1 and V 2. Then B = (cid:9)V , D(cid:10) = Ex-apply(B1, B2, opc) is a combination of B1 and B2 under operator opc .Proof. Let opi, j and v i, j denote the ith operator and variable respectively in V j . V is a concatenation of V 1 and V 2 by thedefinition of Ex-apply. Therefore by the definition of the GFODD semantics, for any interpretation I ,(cid:7)MapBI, [v 1,1 · · · vn,1 v 1,2 · · · vm,2]MapB (I) = op1,1v1,1· · · opm,2vm,2· · · opn,1vn,1op1,2v1,2(cid:13)(cid:8).(cid:12)Since D = apply(D1, D2, opc), by Lemma 3 we have that for allinterpretations I and valuations ζ , MapD (I, ζ ) =MapD1 (I, ζ ) opc MapD2 (I, ζ ). In addition, since the variables in V 1 and V 2 are disjoint, we can write any valuation ζ asζ1ζ2 such that ζ1 is the sub-valuation of ζ over the variables in V 1 and ζ2 is the sub-valuation of ζ over the variables inV 2. Thus we can writeMapB (I) = op1,1v1,1· · · opn,1vn,1op1,2v1,2· · · opm,2vm,2(cid:7)MapB1(cid:12)(cid:13)I, [v 1,1 · · · vn,1](cid:12)opc MapB2I, [v 1,2 · · · vm,2](cid:13)(cid:8).Now the important observation is that since MapB1 (I, [v 1,1 · · · vn,1]) does not depend on the variables in V 2, when aggre-gating over the variables in V 2, MapB1 (I, [v 1,1 · · · vn,1]) can be treated as a constant. Since opc forms a safe pair with allaggregation operators of V 2, by Lemma 4,(cid:12)(cid:13)(cid:13)(cid:13)(cid:12)(cid:12)(cid:12)MapB (I) = op1,1v1,1= op1,1v1,1· · · opn,1vn,1· · · opn,1vn,1(cid:12)MapB1MapB1(cid:12)(cid:13)I, [v 1,1 · · · vn,1](cid:13)I, [v 1,1 · · · vn,1]· · · opm,2opc op1,2v1,2vm,2(cid:13)opc MapB2 (I).MapB2I, [v 1,2 · · · vm,2]Similarly when aggregating over variables in V 1, MapB2 (I) can be treated as a constant because it does not depend on thevalue of any of the variables in V 1. Since opc forms a safe pair with all the aggregation operators in V 1, by Lemma 4,(cid:13)(cid:13)(cid:12)(cid:12)MapB (I) = op1,1v1,1· · · opn,1vn,1MapB1I, [v 1,1 · · · vn,1]opc MapB2 (I) = MapB1 (I) opc MapB2 (I).Thus by definition, B = Ex-apply(B 1, B2, opc) is a combination of B1 and B2 under the combination operator opc . (cid:2)The following theorem strengthens this result showing that Ex-apply has some freedom in reordering the aggregationoperators while maintaining correctness. This property is useful for our solution of RMDPs.Theorem 4. Let B1 = (cid:9)V 1, D1(cid:10) and B2 = (cid:9)V 2, D2(cid:10) be GFODDs that do not share any variables and assume that opc forms a safe pairwith all operators in V 1 and V 2. Let B = (cid:9)V , D(cid:10) = Ex-apply(B1, B2, opc). Let Vbe any permutation of V so long as the relative orderof operators in V 1 and V 2 remains unchanged, and let B(cid:13), D(cid:10). Then for any interpretation I , MapB (I) = MapB(cid:13) (I).(cid:13) = (cid:9)V(cid:13)k and V 2 = F 2· · · F 1Proof. Let V 1 = F 1k F 21 F 11 F 2tors in V i . Then VV 2 remains unchanged. By the semantics of GFODDs,1 F 12(cid:13) = F 1· · · F 1· · · F 22 F 222k so that each F i1 F 2j is a series of zero or more consecutive aggregation opera-k represents a permutation of V such that the relative order of operators in V 1 andMapB(cid:13) (I) = F 11 F 21· · · F 1k F 2k MapB(cid:12)(cid:13)I, [v 1,1 · · · vn,1 v 1,2 · · · vm,2]where v i, j, is a variable in B j . Now, by applying Lemma 3 we get(cid:7)MapB1(cid:13)I, [v 1,1 · · · vn,1]MapB(cid:13) (I) = F 1· · · F 1k F 21 F 2opc MapB2(cid:12)1k(cid:12)I, [v 1,2 · · · vm,2](cid:13)(cid:8).Since B1 and B2 do not share any variables, and opc forms a safe pair with all operators in V 1 and V 2, we have thefollowing sequence of equations where in each step we use Lemma 4 and the fact that one of the arguments is a constantwith respect to the corresponding block of aggregation operators:1MapB(cid:13) (I) = F 1= F 1= · · ·1 F 21 F 21· · · F 1k· · · F 2(cid:12)(cid:7)MapB1(cid:7)F 1k MapB1k−1(cid:13)I, [v 1,1 · · · vn,1](cid:12)opc F 2(cid:13)I, [v 1,1 · · · vn,1]k MapB2opc F 2(cid:12)k MapB2(cid:12)I, [v 1,2 · · · vm,2]I, [v 1,2 · · · vm,2](cid:13)(cid:8)(cid:13)(cid:8)= F 11· · · F 1k MapB1(cid:12)(cid:13)I, [v 1,1 · · · vn,1]opc F 21· · · F 2k MapB2(cid:12)(cid:13)I, [v 1,2 · · · vm,2].Finally by Theorem 3, the last term is equal to MapB (I) implying that MapB(cid:13) (I) = MapB (I). (cid:2)5. Model checking reductions for GFODDsS. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222211The R12 procedure introduced in Section 3 can be extended to operate on GFODDs. In this section we present extensionsof R12 for two forms of aggregation functions. The first is a set of diagrams using only min aggregation. The second is theset of diagrams with maxaggregation. In this case the aggregation function consists of a series of zero or more maxoperators followed by a series of zero or more min operators. For this case we introduce two variants, R12D and R120,with differing computational costs and quality of reduction. We will discuss each of those in turn starting with the R12procedure for the min operator.min∗∗5.1. R12 for min aggregationThe case of min aggregation is obtained as a dual of the max aggregation case. However, it is worthwhile considering itexplicitly as a building block for the next construction. The notion of instrumental paths here is the dual of the notion ofinstrumental paths for the max aggregation:Definition 9. If B is a GFODD with only the min aggregation function, and PL is the DPO for B, then a path p j ∈ PL isinstrumental with respect to PL iff there is an interpretation I such that1. there is a valuation, ζ , such that PathB (I, ζ ) = p j , and2. for all valuations η, if PathB (I, η) = pk, then k (cid:3) j.The generalized aggregation function for the min aggregation operator is the same as the one for the max operatorexcept that the max is replaced by the min and no special treatment is given to paths reaching the 0 leaf. We thus have amin3 generalized aggregation function. Notice that whereas for max aggregation we choose the reachable path with smallestindex as instrumental (and record it in max3), for min3 we pick the reachable path with greatest index as instrumental. Thereduction procedure is identical to the case of max aggregation except that min3 is used instead of max3 and that edges inE have the targets replaced by the discard value D instead of 0. This is not strictly necessary, as we can replace the targetof the edges with a large value (or ∞). But it is useful in preparation for the next construction. A trivial adaptation of theproofs in the previous section yields the corresponding properties for min aggregation.Lemma 5. If a path pi in GFODD B is instrumental under PL, then there exists an interpretation Io such that {leaf (pi), pi, Io} ∈ S.Lemma 6. If there exists an instrumental path under PL that contains the edge e in B then e ∈ E(cid:13).Theorem 5 (Soundness). For any GFODD B using only min aggregation, if GFODD Btions I , MapB (I) = MapB(cid:13) (I).(cid:13)is the output of R12(B), then for all interpreta-Theorem 6 (Maximum reduction w.r.t. DPO). If no path crossing edge e in B is instrumental under PL, then R12 removes e.5.2. Model checking reduction for max∗∗minaggregation∗∗This section is concerned with GFODDs employing maxaggregation. The aggregation function consists of a seriesminof zero or more max operators followed by a series of zero or more min operators. The aggregation function V is thereforesplit into V l – the variables aggregated over using the max aggregation operator, and V r – the variables aggregated overusing the min aggregation operator. Thus, V = V l V r . We use the superscripts l and r (for left and right) to refer to thecorresponding blocks of max and min variables. The set U of all possible valuations of the variables in B can be split intoU l and U r , the sets of all valuations over the variables in V l and V r respectively. Any valuation ζ ∈ U can then be writtenas ζ lζ r where ζ l ∈ U l and ζ r ∈ U r . Thus by the definition of GFODD semantics, for any interpretation I ,(cid:13)(cid:8)(cid:14)(cid:12)(cid:12)(cid:7)MapB (I) = op1v1· · · opnvn(cid:7)MapBI, [v 1 · · · vn]= maxζ l∈U lminζ r ∈U rMapB(cid:13)(cid:8)(cid:15).I, ζ lζ r5.2.1. The procedure R12DOur first reduction operator captures a simple notion of instrumental paths. The intuition is that we can view modelevaluation as if performed in blocks. First, for every ζl, an assignment of objects to V l (of max variables), we perform a mincompetition among all valuations to V r . Each ζl is then associated with a path and value that won the min competition andwe perform a max competition among the corresponding values. Therefore, if a path never wins any min competition wemay be able to change its value without changing the map of the diagram. The new value must be chosen carefully so thatit does not affect any min or max competition on any interpretation, and this requires complex analysis. Instead of choosingsuch a concrete value we change the value to D. This makes sure that the path will not win any min or max competitionsand hence does not change the final value of the diagram.2212S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–2222∗Fig. 7. An example of reduction operator R12D for GFODDs with maxAggregation. Each entry of the form value-{path}-{interpretation} in the table(enclosing angle brackets removed in figure to improve readability) expresses the value obtained by running the valuation of the corresponding row throughthe diagram under an equivalence class of interpretations. The min3 aggregation function applied to every block (in this case there is just one block withζ l = a because there is only one variable x associated with the max aggregation operator) then calculates the possible aggregates that could be generatedunder different equivalence classes of interpretations. Since the edge 3t does not appear in any of the paths in the result of min3, it is not instrumentaland can be removed.min∗We proceed with the technical details of this idea. A path is instrumental if it wins a min competition for some inter-pretation I .Definition 10. If B is a GFODD with the maxinstrumental iff there is an interpretation I and valuation ζ = ζ lζ r , where ζ ∈ U , ζ l ∈ U l and ζ r ∈ U r , such that,aggregation function, and P is a DPO for B, then a path pi ∈ P ismin∗∗1. PathB (I, ζ ) = pi .2. For every ηr ∈ U r , if PathB (I, ζ lηr) = p j , then j (cid:3) i under P .∗The R12D procedure for the maxmin∗following exceptions.aggregation is identical to the R12 procedure for the min aggregation with the1. Recall that the variables are split into V l with max aggregation followed by V r using min aggregation. The set U ofvaluations is built in the following way. Let O l be a set of |V l| objects and O r a set of |V r| objects where O l and O r aredisjoint. Let U l be the sets of all possible valuations of the variables in V l over the objects in O l and let U r be the setof all possible valuations of the variables in V r over the objects in the union of O l and O r . The set U is then definedas U = {ζ lζ r | ζ l ∈ U l and ζ r ∈ U r}.The set of valuations U therefore captures an arbitrary valuation of the variables in V l to objects in O l that are notconstrained. Similarly the valuation of V r is not constrained in that it is allows to bind to objects in O l or to otherobjects (for which O r serves as unconstrained objects). The proof below shows that this set is sufficient to expose anyinstrumental paths.2. The set S is defined as S =ζ l Reduction-Aggregation(B, U ζ l , PL), where U ζ l is the block of valuations correspondingto ζ l. Thus the set Val in the procedure is divided into blocks, each containing a set of valuations with the same ζ l. Sis the union of the sets generated as a result of applying Reduction-Aggregation using min3 to each block of Val.(cid:3)Example 12. Fig. 7 shows a small example of this reduction. The process is similar to the R12 procedure for the maxaggregation, except for the generalized aggregation function. A DPO is first established as shown. Sets O l = {a} and O r = {b}are constructed and the table (Val) is generated by running the getBehaviors procedure on the valuations generated fromthose. Finally, since Val consists of a single block (since only one variable is associated with the max operator), min3(Val) isevaluated to produce the 5 (cid:9)leaf, path, Interpretation(cid:10) 3-tuples as shown. For example combining 0-{1t2 f 3 f }-{p(a), ¬q(a)}with 10-{1t2 f 3t4t}-{p(a), ¬q(a), q(b), r(b)} under min3 we get 0-{1t2 f 3 f }-{p(a), ¬q(a), q(b), r(b)}. The targets of all edgesother than the ones present in the paths of the resultant 3-tuples, and concretely the edge 3t, can be replaced by thevalue D.S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222213The proof of correctness follows the same outline as above but accounts for the extra aggregation operators. We firstshow that every instrumental path, for any potential interpretation I , is discovered by the procedure.Lemma 7. If a path pi in GFODD B employing the maxIo such that {leaf (pi), pi, Io} is in the set S calculated by the R12D procedure.∗∗minsemantics is instrumental under PL, then there exists an interpretation(cid:13) l1(cid:13) r .(cid:13) l and oProof. If pi is instrumental under PL then there exists an interpretation I over a set of objects O I and a valuation ζ = ζ lζ r(cid:13) l be the set of objects thatsuch that PathB (I, ζ ) = pi and for every ηr , if PathB (I, ζ lηr) = p j , then j (cid:3) i under PL. Let O(cid:13) r| (cid:3)(cid:13) l| (cid:3) |V l| and 1 (cid:3) |Oparticipate in ζ l and let O(cid:13) r|V r|. Let o∈ O1(cid:13) r be the set of objects that participate in ζ r but not in ζ l. Clearly 1 (cid:3) |O∈ O(cid:13)Construct interpretation I(cid:13) r and then defining truth values(cid:13) r be theand predicates over the new objects in Osets O l and O r used in the R12D procedure to generate the set of valuations U . The set U can be split into blocks so thateach valuation η = ηlηr belonging to U can be assigned to the block corresponding to ηl. Let U ζ l be the block correspondingto ζ l.(cid:13) r . Add |V l| − |O(cid:13) l and |V r| − |O(cid:13) l| new objects to Oby first projecting I to include only the objects in O(cid:13) r| new objects to O(cid:13) l and O(cid:13) r1 respectively. Let O(cid:13) r to behave identically to o(cid:13) l1 and o(cid:13) l and O(cid:13) l and OLet Io =Since ζ ∈ U ζ l , and Icontains the relevant portion of I , ζ traverses pi under I. Additionally if there is a valuation η ∈ U ζ l(cid:13), η) = p j , and j > i under PL, we could construct another valuation ˆη = ηl ˆηr by replacing the new objects(cid:13) r1 , so that PathB (I, ˆη) = p j . However, we know that no such ˆη exists. Therefore there is no η ∈ U ζ l such that(cid:3)(cid:13), η) = p j , and j > i under PL.such that PathB (Iin ˆηr by oPathB (I(cid:13), η))η. That is, Io includes all the atoms of Ithat participate in traversing paths in B for all(cid:13), η))η will be included in the valueset returned by thevaluations in U ζ l . By construction, the corresponding parts PF(PathB (IgetBehaviors procedure. Clearly Io ⊆ Iis consistent then so is Io. If Valζ l is the block in Val correspondingto the valuations in U ζ l , then by the definition of min3, min3(Valζ l ) must contain an entry {leaf (pi), pi, Io}. Finally sincemin3(Valζ l ) is a subset of S, S must contain {leaf (pi), pi, Io}. (cid:2). Therefore if IPF(PathB (Iη∈U ζ l(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)The lemma implies that all edges on instrumental paths are discovered and as a result that replacing the values of otheredges with D does not change the map of the diagram. This intuition is formalized in the next lemma and theorem.Lemma 8. If there exists an instrumental path in B under PL that contains the edge e then e ∈ E(cid:13).Proof. If there is an instrumental path pi ∈ PL that contains the edge e, then by Lemma 7 there exists an interpretation Iosuch that {leaf (pi), pi, Io} ∈ S. By definition of E, e ∈ E. (cid:2)(cid:13)(cid:13)Theorem 7 (Soundness). For any GFODD B with maxtations I , MapB (I) = MapB(cid:13) (I).∗∗minaggregation, if GFODD B(cid:13)is the output of R12D(B) then for all interpre-Proof. By the definition of R12D , the only difference between B and Bis that some edges that pointed to subFODDs in(cid:13)B, point to the discard leaf D in B. These are the edges in the set E at the end of the R12D procedure. Therefore anyvaluation crossing these edges is discarded from the aggregation function. Valuations not crossing these edges will achievethe same value in Bas they did in B.(cid:13)(cid:13)Fix any interpretation I over any set O I of objects. Let U be the set of all valuations of the variables in B over O I . Eachvaluation η ∈ U can be expressed as η = ηlηr such that ηl ∈ U l and ηr ∈ U r . MapB (I) can then be expressed asMapB (I) = maxηl∈U lminηr ∈U r(cid:14)(cid:12)(cid:7)MapBI, ηlηr(cid:13)(cid:8)(cid:15).Now for any ηl ∈ U l, let pi be a path such that there exists a valuation ηr ∈ U r, PathB (I, ηlηr) = pi and for all ιr ∈U r, PathB (I, ηlιr) = p j implies that j (cid:3) i under the same DPO employed in the R12D reduction procedure. By definitionis instrumental and hence by Lemma 8 none of the edges on pi are affected by R12D . Therefore MapB (I, ηlηr) =piMapB(cid:13) (I, ηlηr). We therefore conclude that for the block of ηl at least one real value (the minimizing one) exists, andother values may be replaced with D which is ignored by the aggregation function. Therefore,(cid:12)(cid:7)MapBI, ηlηr(cid:13)(cid:8)minηr ∈U r= minηr ∈U r(cid:12)(cid:7)MapB(cid:13)(cid:13)(cid:8).I, ηlηrSince this is true for every ηl ∈ U l, it is also true for the aggregation, that is(cid:14)maxηl∈U lminηr ∈U r(cid:12)(cid:7)MapBI, ηlηr(cid:13)(cid:8)(cid:15)(cid:14)= maxηl∈U lminηr ∈U r(cid:12)(cid:7)MapB(cid:13)I, ηlηr(cid:13)(cid:8)(cid:15).Therefore MapB (I) = MapB(cid:13) (I). (cid:2)2214S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22225.2.2. The procedure R120∗∗minThe introduction of the discard value in the leaves makes handling and interpretation of diagrams awkward. In thissection we show that at some additional computational cost this can be avoided. With some extra bookkeeping, a variant ofthe R12 procedure can avoid replacing edge targets with the discard value D, and in the process, potentially remove moreGFODD. To motivate the new procedure, consider again what happens during evaluationredundancies from a maxof interpretation I on GFODD B. As observed above, each block b of valuations corresponding to a ζ l is collapsed undermin aggregation. Let P b denote the set of paths in B traversed by the valuations in b and ordered by the given DPO. Weview this procedure as a competition among the paths in P b. The winner of this competition is the path of highest indexin P b. Denote this path by pb. The min competition applied to all blocks creates a “super block” ˆb of all the winners, eachcorresponding to a ζ l. Finally all the ζ ls are collapsed under the max aggregation. This process can, in turn, be viewed as amax competition among the paths in P ˆb. Obviouslythis path also wins the min competition inside its own block. Note that the block winning the max competition is notuniquely determined because there can be more than one block with the same path winning the min competition. We, and refer to the unique winning path as pb∗ . Then,call any such block a max block, refer to max blocks generically as bMapB (I) = leaf (pb∗ ).. The winner of this competition is the path with the least index in P ˆb∗We use the notation introduced in this discussion in the rest of this section. In particular we have: ζl a valuation to themax variables, its block b, the set of paths P b and the path winning the min competition pb. In addition we have each maxblock bwith the corresponding P b∗ and the unique winning path pb∗ . All these implicitly depend on the interpretation I ,but we suppress I from the notation because it will always be clear from the context.∗Using this analysis we observe the following:1. If the value of the leaf reached by any path in a max block is reduced to a value at least as large as leaf (pb∗ ), themap remains unchanged. This is because the min competition on the max block will still produce the same result.Additionally, since we are only reducing the values of other paths, the values of winners of other min competitions canonly be reduced and therefore pb∗ will still win the max competition.2. If the value of the leaf reached by any path in any block b other than the max blocks is reduced to 0, leaf (pb∗ ) will stillwin the max competition and the map will be preserved.The above observations suggest that we can reduce a GFODD in the following way:1. Preserve the targets of all edges in all paths winning the final max competition under any interpretation. We call theseinstrumental edges.2. Identify edges on paths in B that appear in the max blocks under any possible interpretation I . We call these blockedges. For each block edge e, replace target(e) by a value that is (1) at least as large as leaf (pb∗ ) under I and (2) nolarger than the smallest leaf reachable by traversing e. Notice that (1) means that pb∗ wins the min competition of maxblocks and (2) makes sure we never add value to any path.3. Replace the targets of all other edges by 0.In the remainder of this section, we develop these ideas more formally, describe the R120 reduction procedure and prove. Weits correctness. The input to the procedure is a GFODD B = (cid:9)V , D(cid:10) and a DPO for B. The output is a reduced GFODD Bfirst redefine the generalized aggregation functions min3 and max3 to capture the bookkeeping needed for block edges.(cid:13)min3: as before the input Val to min3 is a set of sets of 3-tuples (cid:9)value, path, interpretation(cid:10), where each set of 3-tuples isassociated with a valuation. The output is a set of all possible 4-tuples (cid:9)vo, po, Eo, Io(cid:10) generated as follows:1. Let X = {(cid:9)v 1, p1, I1(cid:10), . . . , (cid:9)v|Val|, p|Val|, I|Val|(cid:10)} be a set constructed by picking one 3-tuple from the set corresponding toeach valuation ζ ∈ Val.2. vo = min{v 1, . . . , v|Val|}.3. po is the path of highest index under DPO PL that appears in a 3-tuple in X and such that leaf (po) = vo.4. Eo is the set of all the edges appearing in all the paths in all of the 3-tuples in X except the edges in po.5. Io =6. Io is consistent.i I i where (cid:9)v i, pi, I i(cid:10) ∈ X .(cid:3)Thus min3 is exactly as before except that we also collect the set Eo. Notice that if p0 happens to be instrumentalthen E0 identifies the edges that act as block edges in this case. If p0 is not instrumental then E0 is not of interest. Next,max3 is adapted to take as input the set of outputs of min3 (each run for a different ζl) and identify in its output theinstrumental path and winning blocks and blocks edges for each I0 generated.max3: the input Val to max3 is a set of sets of 4-tuples (cid:9)value, path, EdgeList, interpretation(cid:10) where each set of 4-tuples isassociated with a valuation. The output is a set of all possible 4-tuples (cid:9)vo, po, Eo, Io(cid:10) generated as follows.1. Let X = {(cid:9)v 1, p1, E1, I1(cid:10), . . . , (cid:9)v|Val|, p|Val|, E|Val|, I|Val|(cid:10)} be a set constructed by picking one 4-tuple from the set corre-sponding to each valuation ζ ∈ Val.2. vo = max{v 1, . . . , v|Val|}.S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–222222153. po is the path of least index under DPO PL that appears in a 4-tuple in X such that leaf (po) = vo.4. Eo is a set E i such that po = pi and vo = v i ; here if there is more than one i satisfying the condition then each suchE i is given in a separate output tuple.(cid:3)i I i where (cid:9)v i, pi, E i, I i(cid:10) ∈ X .5. Io =6. Io is consistent.Thus max3 is exactly as before except that we also process the sets E i and produce the set Eo. max3 picks the E i thatcorresponds to the winning path pi from its input. If there is more than one block with the same winning path then eachof them produces an output tuple. Therefore, in the output of max3, I0 is a consistent interpretation whose instrumentalpath is p0 and where some of its block edges are listed in E 0.The R120 procedure is as follows.1. Recall that the variables are split into V l with max aggregation followed by V r using min aggregation. The set U ofvaluations is built in the following way. Let O l be a set of |V l| objects and O r a set of (|V l||V l| + 1)|V r| objects whereO l and O r are disjoint. Let U l be the sets of all possible valuations of the variables in V l over the objects in O l and letU r be the set of all possible valuations of the variables in V r over the objects in the union of O l and O r . The set U isthen defined as U = {ζ lζ r | ζ l ∈ U l and ζ r ∈ U r}.As in the previous reduction the set U is constructed to allow for a sufficiently rich set of valuations. Here we allowfor an arbitrary valuation to V l using objects in O l. Next we consider every fixed valuation to V l and the block ofvaluations to V r that extends it. We allow each of the |V l||V l|blocks to use a fresh set of |V r| objects (or any of theother objects). In this way the winner of the min competition in each block is not constrained by valuations in otherblocks. Finally, we must allow a path of block edges to be unconstrained by other bindings in the block. We thereforeadd another set of |V r| objects. As the proof below shows this allows us to expose all instrumental paths and all blockedges in the diagram.2. For every edge we maintain 3 variables. low(e) and high(e) are bounds on its value and InstrEdge(e) is a flag. Theseare initialized as follows. For all edges e in B, set low(e) = −1, high(e) = le , where le is the value of the smallest leafreachable through e in B, and InstrEdge(e) = 0.3. Run the max min3 procedure as follows.(a) Divide Val into |U l| blocks of valuations each block corresponding to a valuation ζ l ∈ U l. Let X be the set of theseblocks.(b) Let Y = {(cid:9)ζ l, Reduction-Aggregation(B, b, PL)(cid:10) | ζ l ∈ U l and b ∈ X is the block corresponding to ζ l}, where Reduction-Aggregation uses the newly defined min3.(c) Let S = max3(Y ).(d) For every 4-tuple (cid:9)vo, po, Eo, Io(cid:10) ∈ S, doi. For every edge e ∈ po, set InstrEdge(e) = 1.ii. For every edge e ∈ Eo, set low(e) to max{low(e), vo}.4. Finally the target of every edge e is replaced as follows:(a) If InstrEdge(e) = 1, do not replace.(b) If InstrEdge(e) = 0 and low(e) (cid:17)= −1 (that is, e is a block edge) and high(e) (cid:2) low(e), then replace target(e) by anysuitable value v, such that low(e) (cid:3) v (cid:3) high(e).(c) If InstrEdge(e) = 0 and low(e) = −1 (that is, e is not a block edge) then replace target(e) by 0.Fig. 8 shows an example of the R120 reduction where several of the steps in the algorithm are illustrated.In the remainder of this section we provide a proof of soundness for R120. To that end we first define idealized propertiesof a reduction procedure in the style of R120. We then show that if a reduction has these properties then it is sound, andthat R120 indeed has these properties. This allows us to break the argument into two independent portions and in this waysimplifies the proof.Definition 11. An edge e in a GFODD B is instrumental iff e ∈ pb∗ under some interpretation.Definition 12. An edge e in a GFODD B is a block edge if it is not instrumental and e ∈ path ∈ P b∗ for some max block bunder some interpretation.∗Definition 13. For any block edge e, CannotExceed(e) is the value of the smallest leaf reachable through e and CannotLag(e)is the value of the largest value of leaf (pb∗ ) over all possible interpretations, when a path containing e appears in a maxblock.Definition 14. A reduction procedure R that reduces a given GFODD B to produce GFODD Bthe following rules.(cid:13)is block-safe if it conforms to2216S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–2222Fig. 8. An example of the reduction R120. The initial diagram is the same as in Example 12 and Fig. 7. We have |V l| = |V r | = 1 and hence |O l| = 1and |O r | = (|V l||V l | + 1)|V r | = 2 and therefore y is allowed to bind to the 3 objects in O l ∪ O r . Each entry of the form value-{path}-{interpretation} inthe table (enclosing angle brackets removed in figure to improve readability) expresses the value obtained by running the valuation of the correspond-ing row through the diagram under an equivalence class of interpretations. The max min3 aggregation function then calculates the possible aggregatesthat could be generated under different equivalence classes of interpretations. Since we have only one block, we only need to run the extended min3aggregation on this example. The result is shown below the table. For example the entries 0-{1t2 f 3 f }-{p(a), ¬q(a)}, 10-{1t2 f 3t4t}-{p(a), ¬q(a), q(b), r(b)}and 10-{1t2 f 3t4t}-{p(a), ¬q(a), q(c), r(c)}, give the last row in the result. Overall, the edges 3t, 4t and 4 f are identified as a block edges. For edge 3t,InstrEdge(3t) = 0 because no winner of the max block contains edge 3t. high(3t) = 0 because the smallest leaf reachable by traversing 3t is 0. Themaxmin3 procedure sets low(3t) to 0 because the highest leaf reached by any path defeating the paths containing 3t in the max block is 0. Thus target(3t)can be set to 0 without violating the constraint low(3t) (cid:2) target(3t) (cid:2) high(3t). Setting the target of 3t to 0 reduces the diagram. Note that in this exampleall edges shown are block edges because there is only one block – the max block. All the edges appearing in the result of max min3 are instrumental edgesand their targets are preserved by the reduction procedure.1. R identifies all instrumental edges in B and for each such identified edge e, R maintains target(e).2. R identifies all block edges in B and for each such identified edge e, R replaces target(e) by any leaf value v such thatCannotLag(e) (cid:3) v (cid:3) CannotExceed(e).3. For each edge e that is not identified by R as an instrumental or block edge, R replaces target(e) by 0.Thus our idealized reduction is block-safe; the next theorem shows that any such procedure is sound.Theorem 8. If reduction procedure R is block-safe and B(cid:13) = R(B), then for every interpretation I , MapB (I) = MapB(cid:13) (I).Proof. Fix any interpretation I over any set O I of objects. Let U be the set of all valuations of the variables in B over O I .Let ζ = ζ lζ r ∈ U be a valuation traversing pb∗ in B. MapB (I) can then be expressed asMapB (I) = maxηl∈U l(cid:14)= max(cid:14)(cid:7)MapBminηr ∈U r(cid:7)MapBminζ r ∈U r(cid:13)(cid:8)(cid:15)(cid:12)I, ηlηr(cid:13)(cid:8)(cid:12)I, ζ lζ r(cid:14), maxηl(cid:17)=ζ l∈U lminηr ∈U r(cid:12)(cid:7)MapBI, ηlηr(cid:13)(cid:8)(cid:15)(cid:15).Since the definition of block-safe guarantees that the target of every edge e is not replaced by a value greater thanCannotExceed(e), target(e) only decreases in value. Therefore, for any valuation η ∈ U , leaf (PathB (I, η)) (cid:2) leaf (PathB(cid:13) (I, η)).Therefore we have,(cid:14)maxηl(cid:17)=ζ l∈U lminηr ∈U r(cid:12)(cid:7)MapB(cid:13)I, ηlηr(cid:13)(cid:8)(cid:15)(cid:14)(cid:12)(cid:7)MapBI, ηlηr(cid:13)(cid:8)(cid:15).(cid:3) maxηl(cid:17)=ζ l∈U lminηr ∈U rAdditionally, the definition of block-safe guarantees that all instrumental edges are preserved and that the value reached bythe block edges is never reduced below leaf (pb∗ ). Therefore, ζ reaches leaf (pb∗ ) in both B and B. No other valuation inany max block b. Thus,∗(cid:13)(cid:13)reaches a value less than leaf (pb∗ ) when evaluated on B(cid:12)(cid:13)(cid:8)(cid:13)(cid:8)(cid:12)(cid:7)MapB(cid:13)I, ζ lζ rminζ r ∈U r(cid:7)MapB= minζ r ∈U rI, ζ lζ r= leaf (pb∗ ).Finally,(cid:14)MapB(cid:13) (I) = maxminζ r ∈U r= MapB (I).S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222217(cid:7)(cid:12)MapB(cid:13)I, ζ lζ r(cid:13)(cid:8)(cid:14), maxηl(cid:17)=ζ l∈U lminηr ∈U r(cid:7)(cid:12)MapB(cid:13)I, ηlηr(cid:13)(cid:8)(cid:15)(cid:15)= minζ r ∈U r(cid:7)(cid:12)MapB(cid:13)I, ζ lζ r(cid:13)(cid:8)= leaf (pb∗ )(cid:2)Therefore, to prove soundness of R120, we can focus on showing that it is block-safe as we do in the next theorem.It is clear from the construction that R120 identifies some instrumental edges and some block edges. The difficulty isin showing that it identifies all such edges over an infinite set of interpretations some of which have infinite domains. Thefollowing proof shows that each such edge is discovered by one of the finite combinations in our procedure. Note that evenif two edges are the block edges of the same pb∗ , they do not need to be discovered at the same time or using the same Ioin our procedure. Instead it is sufficient that each is discovered and marked as a block edge at some point in the algorithm.This is the approach taken in the next proof showing that every instrumental edge (on pb∗ below) and block edge (on p jbelow) are appropriately accounted for by R120.Theorem 9. R120 is block-safe.Proof. Line 4 in the R120 procedure enumerates the treatment of different edges in B. Accordingly to prove the theoremwe need to show that:1. If an edge e in B is instrumental under some interpretation I , then R120 sets InstrEdge(e) = 1.2. If an edge e is a block edge under some interpretation I , then R120 sets the value low(e) (cid:2) CannotLag(e).3. If an edge e is a block edge under some interpretation I , then R120 sets the value high(e) (cid:3) CannotExceed(e).Of the above, 3 is true by the definition of R120 because high(e) is initialized to the correct value and is never changed. Wenext show that the procedure correctly identifies every instrumental edge and every block edge, and sets the correct boundfor block edges.Consider any interpretation I . Let ζ = ζ lζ r be a valuation traversing pb∗ = pi in B under I . Therefore ζ l identifies a maxblock and we refer to this block as bthat does not winthe min competition and let PathB (I, η) = p j . Therefore, pi is instrumental, and the edges in p j are potentially block edges(this holds unless they are instrumental for some other I ) and the lower bound for these edges must be (cid:2) leaf (pi).below. Let η = ζ lηr be any other valuation in the max block b∗∗Let O(cid:13) l be the set of objects that participate in ζ l and define the set O(cid:13) r = {o /∈ O(cid:13) l and ιlιr wins the min competition in the block of ιl}. By construction |O(cid:13) l and o(cid:13) r1∈ O(cid:13) r . Add |V l| − |O(cid:13) l| new objects to O(cid:13) l | o participates in ηr or in ιr , where(cid:13) l| (cid:3) |V l| and(cid:13) r| new(cid:13) l and (|V l||V l| + 1)|V r| − |Oιl contains only the objects from O(cid:13) r| (cid:3) (|V l||V l| + 1)|V r|. Let o|Oobjects to O(cid:13) r .(cid:13) l1∈ O(cid:13)Construct interpretation Iby first projecting I to include only the objects in Oand predicates over the new objects added to Obe the sets O l and O r used in the R120 procedure to generate the set of valuations U .(cid:13) r to behave identically to o(cid:13) l and O(cid:13) l and O(cid:13) l1 and o(cid:13) r and then defining truth values(cid:13) r(cid:13) r1 respectively. Let O(cid:13) l and O(cid:13)Since Icontains the relevant portion of I , PathB (Iunder I(cid:13), η) = p j . In addition, pi is the winner of the min(cid:13), ζ lιr) = pk. To see this, note that if there exists valuation ζ lιr ∈ U such that PathB (Icompetition in the block band k > i under PL, then we could construct another valuation ζ l ˆιr by replacing the new objects in ιr by o(cid:13) r1 so thatPathB (I, ζ l ˆιr) = pk. However, we know that there is no such ζ l ˆιr . An identical argument proves that if b is a block in Ucorresponding to ιl, then pb defined relative to I is the winner of the min competition in b under I(cid:13), ζ ) = pi and PathB (I∗.(cid:13)(cid:13)So far we have shown that the winners of all min competitions in I for blocks in U are maintained in Iwithout direct(cid:13)reference to our algorithm. We next focus on R120 showing that the appropriate paths are discovered.Let Iιlιr = PF(PathB (I(cid:13), ιlιr))ιlιr be the set of atoms on the path pιlιr(cid:13)in B traversed by some valuation ιlιr under I.By construction, a 3-tuple (cid:9)leaf (pιlιr ), pιlιr , Iιlιr (cid:10) appears in the output of the getBehaviors procedure, when run on ιlιr .Therefore, by the definition of Reduction-Aggregation and min3, the set Y generated in Step 3b of R120 must contain an(cid:13), ιlιr))ιlιr . Similarly the set produced by applying min3 to the maxentry (cid:9)leaf (pb), pb, Eb, Ib(cid:10), where Ib =(cid:13), ζ lιr))ζ lιr . In addition by the sameblock bargument, Eb∗ must contain all the edges in p j .must contain an entry (cid:9)leaf (pb∗ ), pb∗ , Eb∗ , Ib∗ (cid:10), where Ib∗ =ιr ∈U r PF(PathB (Iιr ∈U r PF(PathB (I(cid:3)(cid:3)∗Now, by the definition of max3, the set S built in Step 3 of R120 must contain an entry (cid:9)leaf (pb∗ ), pb∗ , Eb∗ , Io(cid:10) where(cid:3)Io =ι∈U PF(PathB (I(cid:13), ι))ι is consistent because it is a subset of I(cid:13).Therefore e ∈ pb∗ is marked instrumental by R120. Every edge e ∈ p j is marked with low(e) (cid:2) leaf (pb∗ ). Since the choiceof I , pb∗ and p j was arbitrary in the above argument, this holds for all block edges, implying that low(e) (cid:2) CannotLag(e).Thus R120 is block-safe. (cid:2)Corollary 1 (Soundness). For any GFODD B with maxtations I , MapB (I) = MapB(cid:13) (I).∗∗minaggregation, if GFODD B(cid:13)is the output of R120(B) then for all interpre-2218S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22226. An application of GFODDs for value iteration in relational MDPsSo far we have described a general theory of GFODDs. This included the syntax and semantics of GFODDs, combinationprocedures and reduction procedures for GFODDs. In this section we show how GFODDs can be used to solve RelationalMDPs.6.1. Relational Markov decision processesA Markov decision process (MDP) is a mathematical model of decision making in a dynamic environment [1,2]. Formallya MDP is a 4-tuple (cid:9)S, A, T , R(cid:10) defining a set of states S, set of actions A, a transition function T defining the probabilityP (s j | si, a) of getting to state s j from state si on taking action a, and an immediate reward function R(s). The objective ofsolving a MDP is to generate a policy that maximizes the agent’s total, expected, discounted, reward. Intuitively, the expectedutility or value of a state is equal to the reward obtained in the state plus the discounted value of the state reached(cid:13))].by the best action in the state. This is captured by the Bellman equation as V (s) = Maxa[R(s) + γThe value iteration algorithm is a dynamic programming algorithm that treats the Bellman equation as an update ruleand iteratively updates the value of every state until convergence. The value iteration update is V n+1(s) ← Maxa[R(s) +(cid:13))]. Once the optimal value function is known, a policy can be generated by assigning to each state theγaction that maximizes expected value.(cid:13)|s, a)V n(s(cid:13)|s, a)V (ss(cid:13) P (ss(cid:13) P (s(cid:16)(cid:16)Several approaches have been introduced to take advantage of factored state spaces where a state is described by spec-(cid:13) | s, a) and V (s) canifying values of a set of propositions [26–28]. In particular Hoey et al. [29] showed that if R(s), P (sbe represented using algebraic decision diagrams (ADD) [24,25], then value iteration can be performed entirely using theADD representation avoiding the need to enumerate the state space. This improved the scalability of classical solutions toMDPs by replacing the enumeration of states implicit in the equation above with ADDs, a compact feature based represen-tation, thereby taking advantage of the structure in the problem. However, further structure in the domain can be exploitedand more general solutions can be found by viewing the world as consisting of objects with relations among them. MDPsrepresented in this way are known as Relational MDPs. Addressing Relational MDPs, Boutilier et al. [6] developed the Sym-bolic Dynamic Programming (SDP) algorithm in the context of situation calculus. This algorithm provided a framework fordynamic programming solutions to Relational MDPs that was later employed in several formalisms and systems [7,8,10,9].One of the important ideas in SDP was to represent stochastic actions as deterministic alternatives under nature’s control.This helps simplify the probabilistic reasoning required because goal regression over deterministic action alternatives can bedecoupled from the probabilities of action effects. This separation is necessary when transition functions are represented asrelational schema. Using these ideas, a RMDP is specified by1. A set of world predicates. Each literal, formed by instantiating a predicate using objects from the domain, canbe either true or false in a given state. For example in the boxworld domain, world literals are of the formbox-in-city(box, city), box-on-truck(box, truck), truck-in-city(truck, city), etc.2. A set of action predicates. Each action literal,formed by instantiating an action predicate using objects fromthe domain, defines a concrete action. For example in the boxworld domain, action literals are of the formload-box-on-to-truck-in-city(box, truck, city), unload-box-from-truck-in-city(box, truck, city), drive-truck(truck, source-city,dest-city), etc.3. A state transition function that provides an abstract description of the probabilistic move from one state to another. Forexample, using a STRIPS-like notation, the transition defined by the action load-box-on-to-truck-in-city can be describedasAction: load-box-on-to-truck-in-city(box, truck, city)Preconditions: box-in-city(box, city), truck-in-city(truck, city)Outcome 1: probability 0.8, box-on-truck(box, truck), ¬box-in-city(box, city)Outcome 2: probability 0.2, nothing changes.If the preconditions of the action, box-in-city(box, city) and truck-in-city(truck, city), are satisfied then with probability0.8, the action will generate the effect box-on-truck(box, truck) and ¬box-in-city(box, city). The state remains unchangedwith probability 0.2. As this example illustrates, the effects of actions in RMDPs are often correlated and cannot beconsidered to occur independently of one another. Therefore, a scheme that captures such correlations compactly isuseful in this context.4. An abstract reward function describing conditions under which rewards are obtained. For example in the boxworlddomain, the reward function is [∀box∀city, destination(box, city) → box-in-city(box, city)] constructed so as to capturethe goal of transporting all boxes from their source cities to their respective destination cities.An interesting fact to notice about RMDPs is that the state space in the underlying MDP is not fully specified becausethe set of objects in the domain is left out. When fixing the domain of objects the specification induces a concrete MDP.Thus a RMDP represents a family of concrete MDPs.The above RMDP can be described using various schema languages. Wang et al. [9] describe the RMDP by representingthe reward function and the domain dynamics using FODDs. Domain dynamics are described by Truth Value DiagramsS. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222219Fig. 9. Example of Regression and Object Maximization in the VI-GFODD algorithm. This domain contains a single deterministic action. Therefore Steps 2and 4 of the algorithm are not needed. The reward is 1 if [∃x, ∀ y, p(x, y)] and it is 0 otherwise. The reward function is regressed over the deterministic∗). The action is defined such that p(U , V ) is true after the action if it was true before or if q(U , V ) was true before and the action performedaction A(xwas A(U , V ). Regression replaces every node in the value function with the corresponding TVD and object maximization replaces the action parameterswith quantified variables.∗, y(TVD), and diagrams capturing probabilistic action choice. A TVD is a FODD describing, for each deterministic alternative ofeach probabilistic action and for each world predicate, the conditions under which the corresponding world literal is truewhen the action is executed and that action alternative occurs. Fig. 9 shows an example of a TVD for the parameterized∗) in a hypothetical planning domain. In addition, for each∗, yworld predicate p(U , V ) under the deterministic action A(xdeterministic action variant A j((cid:22)x), the diagram prob( A j((cid:22)x)) provides the probability that A j((cid:22)x) is chosen when A((cid:22)x) isexecuted.6.2. The VI-GFODD algorithmIn this section we show that the FODD based value iteration (VI) algorithm can be generalized to handle cases whereaggregation. We start by describing the VI-GFODD algorithm.the reward function is described by a GFODD with maxA subsequent discussion shows why VI-GFODD produces the correct result at each step. The algorithm is as follows:∗min∗1. Regression: The n step-to-go value function V n is regressed over every deterministic variant A j((cid:22)x) of every action A((cid:22)x)to produce Regr(V n, A j((cid:22)x)) by replacing each node in V n−1 by its corresponding Truth Value Diagram (TVD) withoutchanging the aggregation function.2. Add action variants: The Q-function Q A((cid:22)x)V nated by combining regressed diagrams using Ex-apply.= R ⊕ [γ ⊗ ⊕ j(prob( A j((cid:22)x)) ⊗ Regr(V n, A j((cid:22)x)))] for each action A((cid:22)x) is gener-3. Object maximization: Maximize over the action parameters of Q A((cid:22)x)V nfor each action A((cid:22)x), thus ob-taining the value achievable by the best ground instantiation of A((cid:22)x). This step is implemented by converting actionparameters in Q A((cid:22)x)to variables each associated with the max aggregation operator, and appending these operators toV nthe head of the aggregation function.to produce Q AV n4. Maximize over actions: The n + 1 step-to-go value function V n+1 = max A Q AV nusing Ex-apply., is generated by combining the diagramsExample 13. Fig. 9 shows an example of the VI algorithm using GFODDs for a simple domain. This domain contains a singledeterministic action. Therefore we do not need to multiply by prob( A j((cid:22)x)) and to sum over the variants A j in Step 2 ofthe algorithm and similarly Step 4 is not needed. In this example we completely skip Step 2 and focus on the other twosteps in the algorithm. The reward is 1 if [∃x, ∀ y, p(x, y)] holds and is 0 otherwise. The reward function is regressed over∗), which is defined such that p(x, y) is true after the action if it was true before or ifthe deterministic action A(xq(x, y) was true before and the action performed was A(x, y). Since the action can make at most one p(x, y) true at a time,intuitively, the regressed diagram should capture the union of the following conditions for returning a value of 1.∗, y2220S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22221. There exists x, such that for all y, p(x, y) holds.2. There exists x, such that for all but one y, p(x, y) is true and for that y, q(x, y) is true.Fig. 9 shows the diagram after being regressed and object maximized. The final diagram is correct because it returns a 1iff one of above situations occur. If [∃x, ∀ y, p(x, y)] is true, then all valuations in the blocks with that value of x and fixedvalues for w and z will reach the 1 leaf directly from the root. Evaluating Min( y) will collapse these blocks to partialvaluations with a 1 value. Now since the rest of the aggregation is maximization, the 1 value will be returned as the map. Ifthere exists x, such that for all but one y, p(x, y) is true and for that y, q(x, y) is true, then all valuations in the blocks withthat value of x, the other values of y and fixed values for w and z reach a 1 leaf directly through the root. The valuationin the block with the one value of y would traverse right from the root but would still reach the 1 leaf depending on thecondition w = x and z = y. Note that there will be exactly one block where this valuation will reach the 1 leaf. EvaluatingMin( y) would collapse that block into a valuation with value 1. Since the rest of the aggregation is maximization, the 1value will be returned as the map. When neither of the conditions is true, there will be at least one valuation in every blockthat reaches a 0 leaf. Hence evaluating Min( y) would collapse every block to a valuation with a 0 value.For Value Iteration to work correctly with GFODDs, all the steps of the algorithm listed above must be correct. Regressionby block replacement is correct regardless of the aggregation function. Recall that a TVD for a predicate under deterministicaction A j((cid:22)x) describes conditions under which the predicate is true after A j((cid:22)x) is executed. Wang et al. [9] impose theconstraint that TVDs cannot include free variables. Using this constraint the diagrams before and after regression haveexactly the same variables. Wang et al. [9] show that regression is correct for any valuation.Lemma 9. (See [9].) Fix any concrete instantiation of the state space. Let s denote a state resulting from executing an action A((cid:22)x) instate ˆs.If V n is the n step-to-go value function, BR-regress(V n, A((cid:22)x)) is the result of regressing V n over the deterministic actionA((cid:22)x), and ζ is any valuation to the variables of V n (and thus also the variables of BR-regress(V n, A((cid:22)x))), then MAPV n (s, ζ ) =MAPBR-regress(V n, A((cid:22)x))(ˆs, ζ ).The lemma shows that the corresponding map values are the same for any valuation ζ . Therefore, the aggregation of thevalues is the same for any aggregation function, and any V n.The third step, Object Maximization, is correct because converting action parameters in Q A((cid:22)x)V nto variables each associatedunder any interpretation will now be the map of Q A((cid:22)x)V nwith the max aggregation operator, and appending these operators to the head of the aggregation function of Q AV nthat the map of Q Amaximized over all possible values of theV naction parameters, as required. Steps 2 and 4 are correct by Theorem 4 showing the correctness of Ex-apply. Since valueiteration requires combining diagrams under the ⊕, ⊗ and the max operators, only GFODDs with aggregation operatorsthat are safe with the combination operators ⊕, ⊗ and max may be used. Thus aggregation operators max and min canbe used. To extend the algorithm to use other aggregation operators (like sum and mean) one needs to develop appropriatecombination algorithms but the rest of the algorithm remains the same., impliesThus we have a correct value iteration algorithm for GFODDs with max and min aggregations. In addition, Theorem 4guarantees that if we start with a reward function GFODD with an aggregation of the form max, then throughoutvalue iteration all GFODDs produced can be made to have an aggregation function of the same form. With the R12 reduc-tions for this case, we have a sound procedure that can help keep the diagrams compact over the value iteration process.We have therefore shown:min∗∗Theorem 10. For any Relational MDP where the aggregation function of the reward function diagram contains only operators that aresafe with the combination operators +, × and max, the algorithm VI-GFODD produces the correct value function at every iteration.Corollary 2. For any Relational MDP where the reward function has a maxfunction at every iteration, all intermediate results and the final result use maxto reduce the diagrams throughout the algorithm.∗∗min∗aggregation, VI-GFODD produces the correct value∗aggregation, and the R12 procedure can be usedmin7. Conclusions and future workThis paper significantly extends the representation power of first-order decision diagrams and our algorithmic under-standing of their reductions. We show how Generalized FODDs allow for arbitrary aggregation functions, thereby facilitatingrepresentation of complex functions, and how basic operations on them can be performed. In particular we can naturallycapture and manipulate logical formulas with existential and universal quantifiers using max and min aggregation. In addi-tion we show that first-order value iteration can be supported in a more expressive setting when the MDP is representedby GFODDs. This new formulation can naturally handle universal goals that were handled heuristically by previous imple-mentations of first-order value iteration [10,11].S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222221Fig. 10. Reward and value function for the goal cl(a) in the blocksworld domain.Additionally, GFODDs might prove useful in addressing issues related to problems where the lifted value function isinfinite in size. For instance, Kersting et al. [7] showed an example in the blocksworld domain where the goal is to makea particular block, a, clear (denoted by cl(a)) and the value function is infinite in size because there could be any numberof blocks on top of a. However, the value function can be represented compactly using GFODDs in conjunction with a moredescriptive predicate, above, as shown in Fig. 10. In the figure, above( X, a) is true for any block X that is part of a towerstacked on top of block a, aggregation over X is performed by the multiplication operator and the discount factor is 0.9.Thus the multiplicative aggregation implicitly captures the number of steps to the goal. Although the existence of a compactvalue function does not imply an efficient algorithm to produce it, at least in this particular case we know that the problemis not inherently that of representation.The other main contribution in the paper is the idea and analysis of model checking reductions. The same basic ideaprovides model checking reduction operators for both FODDs and a useful subset of GFODDs. In the former case, we provethe reduction to be, in some technical sense, maximal. The maximum reduction guarantee for FODDs falls short of providinga normal form because it relies on a DPO to define which parts of a diagram may be reduced when there are mutual impli-cation relations. Therefore the same semantic function may have different minimal representations. However, the guaranteeis much stronger than those of previous reductions. Wang et al. [9] discuss normal form for FODDs. Examples of FODDsgiven there, using a simple decidable fragment, show that for normal form we may need some syntactic manipulation ofdiagrams. Therefore going beyond the guarantee given in this paper may be hard or expensive to compute. Nevertheless,there is a potential for exploring this and the possibility of efficient reductions for other interesting subsets of GFODDs infuture work.This work also suggests a new approach for practical implementations of FODDs. The model checking reductions of thispaper require enumeration of substitutions which has high complexity. A promising idea is to use a sample of interpre-tations, judicially chosen, and reduce the diagrams relative to these interpretations. We refer the reader to [12] for recentwork providing a validation of this idea in the context of RMDPs where the implementation shows a significant speedupover theorem proving reductions while maintaining performance in terms of solving planning problems using FODDs. Itwould be interesting to develop extensions of these heuristics that support efficient reductions for GFODDs. Such an ap-proach will allow for the very expressive setting of GFODDs to be handled efficiently through the heuristic approximationembedded in the model checking reductions.Finally it would be interesting to investigate the utility of GFODDs in other applications, like lifted inference and Statis-tical Relational Learning, that can benefit from expressive function representations.AcknowledgementsKristian Kersting was supported by the Fraunhofer ATTRACT fellowship STREAM. Saket Joshi and Roni Khardon werepartly supported by the NSF grants IIS 0936687 and IIS 0964457, and Saket Joshi was additionally supported by a ComputingInnovation Postdoctoral Fellowship.References[1] M.L. Puterman, Markov Decision Processes, Discrete Stochastic Dynamic Programming, Wiley, 1994.[2] S. Russel, P. Norvig, Artificial Intelligence: A Modern Approach, Prentice Hall Series in Artificial Intelligence, 2002.[3] R. Bellman, Dynamic Programming, Princeton University Press, Princeton, NJ, 1957.[4] R. Howard, Dynamic Programming and Markov Processes, MIT Press, 1960.[5] L. Getoor, B. Tasker, An Introduction to Statistical Relational Learning, MIT Press, 2007.[6] C. Boutilier, R. Reiter, B. Price, Symbolic dynamic programming for first-order MDPs, in: Proceedings of the International Joint Conference of ArtificialIntelligence, 2001, pp. 690–700.[7] K. Kersting, M. van Otterlo, L. De Raedt, Bellman goes relational, in: Proceedings of the International Conference on Machine Learning, 2004, pp. 465–472.[8] S. Hölldobler, E. Karabaev, O. Skvortsova, FluCaP: a heuristic search planner for first-order MDPs, Journal of Artificial Intelligence Research 27 (2006)419–439.[9] C. Wang, S. Joshi, R. Khardon, First-order decision diagrams for relational MDPs, Journal of Artificial Intelligence Research 31 (2008) 431–472.[10] S. Sanner, C. Boutilier, Practical solution techniques for first-order MDPs, Artificial Intelligence 173 (2009) 748–788.[11] S. Joshi, R. Khardon, Probabilistic relational planning with first-order decision diagrams, Journal of Artificial Intelligence Research 41 (2011) 231–266.[12] S. Joshi, K. Kersting, R. Khardon, Self-taught decision theoretic planning with first-order decision diagrams, in: Proceedings of the International Confer-ence on Automated Planning and Scheduling, 2010, pp. 89–96.[13] D. Poole, First-order probabilistic inference, in: Proceedings of the International Joint Conference of Artificial Intelligence, 2003, pp. 985–991.2222S. Joshi et al. / Artificial Intelligence 175 (2011) 2198–2222[14] R. Braz, E. Amir, D. Roth, Lifted first-order probabilistic inference, in: Proceedings of the International Joint Conference of Artificial Intelligence, 2005,pp. 1319–1325.[15] A. Jaimovich, O. Meshi, N. Friedman, Template-based inference in symmetric relational Markov random fields, in: Proceedings of Uncertainty in ArtificialIntelligence, 2007, pp. 191–199.[16] B. Milch, L. Zettlemoyer, K. Kersting, M. Haimes, L. Kaelbling, Lifted probabilistic inference with counting formulas, in: Proceedings of the NationalConference on Artificial Intelligence, 2008, pp. 1062–1068.[17] P. Singla, P. Domingos, Lifted first-order belief propagation, in: Proceedings of the National Conference on Artificial Intelligence, 2008, pp. 1094–1099.[18] P. Sen, A. Deshpande, L. Getoor, Exploiting shared correlations in probabilistic databases, in: Proceedings of the International Conference on Very LargeData Bases, 2008, pp. 809–820.[19] P. Sen, A. Deshpande, L. Getoor, Bisimulation-based approximate lifted inference, in: Proceedings of Uncertainty in Artificial Intelligence, 2009, pp. 496–505.[20] K. Kersting, B. Ahmadi, S. Natarajan, Counting belief propagation, in: Proceedings of Uncertainty in Artificial Intelligence, 2009, pp. 277–284.[21] J. Kisynski, D. Poole, Lifted aggregation in directed first-order probabilistic models, in: Proceedings of the International Joint Conference of ArtificialIntelligence, 2009, pp. 1922–1929.[22] J. Lloyd, Foundations of Logic Programming, second edition, Springer-Verlag, 1987.[23] J. Groote, O. Tveretina, Binary decision diagrams for first-order predicate logic, Journal of Logic and Algebraic Programming 57 (2003) 1–22.[24] R. Bryant, Graph-based algorithms for boolean function manipulation, IEEE Transactions on Computers C-35 (1986) 677–691.[25] R. Bahar, E. Frohm, C. Gaona, G. Hachtel, E. Macii, A. Pardo, F. Somenzi, Algebraic decision diagrams and their applications, in: Proceedings of theIEEE/ACM International Conference on Computer-Aided Design, 1993, pp. 188–191.[26] C. Boutilier, R. Dearden, M. Goldszmidt, Stochastic dynamic programming with factored representations, Artificial Intelligence 121 (2000) 49–107.[27] M. Kearns, D. Koller, Efficient reinforcement learning in factored MDPs, in: Proceedings of the International Joint Conference of Artificial Intelligence,1999, pp. 740–747.[28] C. Guestrin, D. Koller, R. Parr, S. Venkataraman, Efficient solution algorithms for factored MDPs, Journal of Artificial Intelligence Research 19 (2003)399–468.[29] J. Hoey, R. St-Aubin, A. Hu, C. Boutilier, SPUDD: Stochastic planning using decision diagrams, in: Proceedings of Uncertainty in Artificial Intelligence,1999, pp. 279–288.