Artificial Intelligence 160 (2004) 105–143www.elsevier.com/locate/artintA causal approach to nonmonotonic reasoningAlexander BochmanComputer Science Department, Holon Academic Institute of Technology, 52 Golomb St., Holon 58102, IsraelReceived 11 January 2004; accepted 24 July 2004AbstractWe introduce logical formalisms of production and causal inference relations based on in-put/output logics of Makinson and Van der Torre [J. Philos. Logic 29 (2000) 383–408]. Theseinference relations will be assigned, however, both standard semantics (giving interpretation totheir rules), and natural nonmonotonic semantics based on the principle of explanation closure.The resulting nonmonotonic formalisms will be shown to provide a logical representation of ab-ductive reasoning, and a complete characterization of causal nonmonotonic reasoning from McCainand Turner [Proc. AAAI-97, Providence, RI, 1997, pp. 460–465]. The results of the study suggestproduction and causal inference as general nonmonotonic formalisms providing an alternative repre-sentation for a significant part of nonmonotonic reasoning. 2004 Elsevier B.V. All rights reserved.Keywords: Nonmonotonic reasoning; Causality; Abduction; Reasoning about action and change1. IntroductionThe field of nonmonotonic reasoning is so abundant with different formalisms, thatan attempt to introduce and justify yet another one appears to be doomed from the verybeginning. Nevertheless, this is precisely the main aim of this study.1 Accordingly, we haveto explain, first of all, what was the problem such that the new formalism is the suggestedsolution.E-mail address: bochmana@hait.ac.il (A. Bochman).1 A preliminary version of this paper has appeared as [7].0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.07.002106A. Bochman / Artificial Intelligence 160 (2004) 105–143To begin with, studies in nonmonotonic reasoning have given rise to two basicallydifferent approaches that could be called, respectively, preferential and explanatory non-monotonic reasoning, with little interaction between them.2 The first approach encom-passes nonmonotonic inference relations of [20], as well as a general theory of beliefchange. A detailed description of this approach can be found in [6]. The second approachincludes various default and modal nonmonotonic logics, as well as logic programming. Infact, all the papers in the famous 1980 issue of the Artificial Intelligence on NonmonotonicReasoning could be seen as belonging to this latter camp (though McCarthy’s circumscrip-tion is expressible also by the first approach). The formalism suggested in the present paperwill also belong to the explanatory approach.The above two approaches reflect, respectively, two different senses in which a logi-cal system can be nonmonotonic. First, its rules may not admit addition of new premises,that is, they do not satisfy Strengthening the Antecedent. Second, adding further rules tothe system may possibly invalidate earlier conclusions. These two kinds of nonmonotonic-ity are largely independent. Thus, preferential inference relations are nonmonotonic in thefirst sense, but monotonic in the second sense, since addition of new conditionals does notinvalidate previous derivations. On the other hand, default logic exemplifies monotonic-ity of the first kind and nonmonotonicity of the second kind. Default rules freely admitstrengthening of their pre-requisites and justifications, since this does not change the setof extensions (see [5]). However, adding arbitrary new rules to a default theory may cre-ate new extensions, so the nonmonotonic conclusions made earlier will not, in general, bepreserved.We believe that nonmonotonic reasoning should give us a more direct and adequatedescription of the actual ways we think about the world than, say, the classical logic. Inthis respect, the preferential nonmonotonic reasoning has a definite advantage over exist-ing explanatory counterparts in that it provides a direct semantic representation for its mainnonmonotonic objects, namely default conditionals “If A, then normally B”. This semanticrepresentation allows us to assess our default claims and determines, ultimately, the actualchoice of default assumptions made in particular circumstances. Default logic and its rel-atives take a different, less direct, route to assessing what can be inferred from a givenset of default rules. Namely, they require from the user to provide an explicit informationabout when one default can ‘block’ another default. This information is used as a sole fac-tor in determining acceptable combinations of defaults. This strategy can be remarkablysuccessful in resolving difficult cases of default interaction, which can be seen as the mainreason why the explanatory nonmonotonic reasoning so far has had a greater impact onpractical applications of nonmonotonic reasoning in AI. Still, the explanatory approach re-mains largely syntactic in nature, and does not give us a transparent and systematic way ofrepresenting empirical data. More precisely, due to the fact that default rules do not havea direct semantic interpretation, the task of knowledge representation in these formalismsbecomes really an art rather than a systematic methodology.32 They have been called, respectively, classical and argumentative nonmonotonic reasoning in [6].3 As was rightly mentioned by the reviewer, this is actually the problem with many other KR formalisms aswell.A. Bochman / Artificial Intelligence 160 (2004) 105–143107An additional, more specific, problem with the explanatory approach consists in theepistemic understanding of default rules it presupposes. A distinctive feature of both de-fault and modal nonmonotonic logics is that they are inherently epistemic formalisms.Namely, they are essentially based on such notions as belief and knowledge, unlike theextensional classical logic used for a direct representation of facts about the world. Accord-ingly, the intended semantic models of these formalisms represent (possibly incomplete)sets of beliefs one can have, while their rules allow to make inferences based on absenceof belief, or consistency, with respect to candidate belief sets (cf. the introductory sectionsof [33]). It seems that this modal formulation of many nonmonotonic formalisms is mainlydue to historical reasons: at the time these formalisms have emerged, modal logics alreadyreigned in the literature as a standard paradigm of logical representation. The epistemicinterpretation strongly influenced also logic programming in that the negation as failurehas often been formulated as absence of knowledge (or derivation).Due to its modal character, default logic has turned out to be a logically weak formalismthat does not support many classical inference principles (such as reasoning by cases). Ithas also other well-known shortcomings, and numerous variants of default logic have beensuggested in attempts to overcome them and make it more in accord with our intuitions.On our opinion, however, a relatively modest success of these attempts has shown that it isimpossible to radically improve default logic without abandoning its underlying epistemicinterpretation.The shortcomings of default logic became especially vivid in attempts to apply it toone of the primary application fields of nonmonotonic reasoning, a formal representationof actions and change. It was realized quite early that classical logic alone cannot providean efficient representation for reasoning about change due to the famous frame problem[30]—a problem of giving an efficient description for the state of the world after perform-ing an action that would avoid computationally unbearable reproduction of all the factsthat remain unaffected. There was also a related ramification problem of determining theindirect effects (ramifications) of actions that arise due to the laws of the domain. Andit was only natural to expect that nonmonotonic reasoning should help in resolving theseproblems.After some less successful attempts to formalize temporal nonmonotonic reasoning inexisting nonmonotonic logics, a dominant recent approach to solving these problems hasbeen based on causal reasoning. Given a set of action and causal rules describing the do-main, the causal approach employs a distinction between facts that hold in a situationversus facts that are caused (explained) by other facts and the rules. The corresponding ex-planation closure assumption amounts to a requirement that all facts that hold in a situationshould be either caused by other occurrent facts, or else preserve their truth-values in time(due to the associated inertia assumption). A natural formalization of these principles hasbeen given in the framework of causal theories, introduced in [26]. A causal theory is a setof causal rules that express causal (or explanatory) relations among propositions. The non-monotonic semantics of such theories is determined by causally explained models, namelythe models that both satisfy the causal rules and such that every fact holding in them isexplained by some causal rule. The resulting nonmonotonic formalism has been shown toprovide a plausible and efficient solution for both the frame and ramification problem (see[17,21,37] for a detailed exposition and applications in representing action domains). Re-108A. Bochman / Artificial Intelligence 160 (2004) 105–143lated causal approaches to representing actions and change have been suggested in [23,36,38], to mention only a few.From the point of view of the present study, the causal reasoning constitutes an impor-tant conceptual shift in the general framework of explanatory nonmonotonic reasoning,since it is based on a direct and transparent description of factual and causal (explanatory)information about the world. In other words, it shows that the epistemic view of non-monotonic reasoning is not the only possibility. Accordingly, the primary aim of our studywill consist in laying down logical foundations for this kind of nonmonotonic reasoning.As we will see, the resulting nonmonotonic formalism will form a most natural and imme-diate generalization of classical logic that allows for nonmonotonic reasoning. We will tryto demonstrate also that the suggested framework constitutes a general-purpose formalismthat covers significant parts of general nonmonotonic reasoning. In this respect, it forms aviable non-epistemic alternative to default and modal nonmonotonic logics.The logical foundations of the suggested formalism will be built in the framework of aninference system for causal rules, called production inference relations, that originates ininput/output logics of [25]. These logics will be assigned below two semantics. The first isan ordinary logical (monotonic) semantics that will give a semantic interpretation for thecausal rules. The second is a natural nonmonotonic semantics, which gives rise to a newkind of nonmonotonic reasoning.As a first general application, we describe a special kind of abductive production in-ference relations that provide a logical, syntax-independent representation of abductivereasoning. It will be shown, in particular, that in many regular cases such inference rela-tions will be sufficient for describing the nonmonotonic semantics of causal theories.As a next step, we will describe a particular kind of production inference, called causalinference relations. Such inference relations will already admit an objective interpreta-tion as reasoning systems about the world. Accordingly, the nonmonotonic semantics forsuch inference relations will also be based on worlds. It will be shown that the resultingnonmonotonic formalism provides both an adequate and complete characterization of thereasoning with causal theories of [26]. It will be shown also that any causal theory is re-ducible with respect to this nonmonotonic semantics to a determinate causal theory thatcontain only Horn causal rules A ⇒ l, where l is a literal. The importance of determinatetheories lies in the fact, established already in [26], that the explained interpretations ofsuch a theory are precisely the interpretations of its classical completion. Consequently,the nonmonotonic consequences of such causal theories are obtainable by the use of clas-sical inference tools.We will assume in this paper that our underlying language is an ordinary classical propo-sitional language with the usual connectives and constants {∧, ∨, ¬, →, t, f}. In addition, (cid:1)and Th will stand, respectively, for the classical entailment and the associated logical clo-sure operator. We will reserve also the letters p, g, r, . . . for denoting propositional atoms,while A, B, C, . . . will denote arbitrary classical propositions of the language.(cid:2)(cid:1)For a finite set a of propositions,a andand disjunction of all propositions from a. As a special case,will denote f.a will denote, respectively, the conjunction∅∅ will denote t, while(cid:2)(cid:1)In what follows, we will use also a few facts about ordinary Tarski consequence relationsbased on the classical language (see, e.g., [6]). Such a consequence relation (cid:6) is calledA. Bochman / Artificial Intelligence 160 (2004) 105–143109supraclassical, if it subsumes the classical entailment, that is, (cid:1) ⊆ (cid:6). The sets of premisesin the rules of a supraclassical consequence relation can be replaced by their conjunctions,that is, a (cid:6) A is equivalent toa (cid:6) A. This means that such consequence relations canbe represented as binary relations on the set of classical propositions, namely as relationssatisfying, for instance, the following postulates:(cid:1)Dominance If A (cid:1) B, then A (cid:6) B.Transitivity If A (cid:6) B and B (cid:6) C, then A (cid:6) C.If A (cid:6) B and A (cid:6) C, then A (cid:6) B ∧ C.AndA consequence relation will be called classical, if it is supraclassical and satisfies oneof the following postulates:Deduction If A ∧ B (cid:6) C, then A (cid:6) B→C;OrIf A (cid:6) C and B (cid:6) C, then A ∨ B (cid:6) C.In a classical consequence relation, any rule A (cid:6) B is reducible to an axiom (cid:6) A→B,so it can be viewed as a classical entailment augmented with a set of auxiliary axioms.2. Production inferenceWe will begin with a general notion of production inference that will be just a slightmodification of input–output logic from [25].Definition 2.1. A production inference relation is a binary relation ⇒ on the set of classicalpropositions satisfying the following conditions:(Strengthening) If A (cid:1) B and B ⇒ C, then A ⇒ C;(Weakening) If A ⇒ B and B (cid:1) C, then A ⇒ C;If A ⇒ B and A ⇒ C, then A ⇒ B ∧ C;(And)(Truth) t ⇒ t;(Falsity) f ⇒ f.Conditionals of the form A ⇒ B will be called production rules. A characteristic prop-erty of production inference is that reflexivity A ⇒ A does not necessarily hold.Production inference relations almost coincide with input-output logics, except for thelast postulate, Falsity. The latter allows to restrict the universe of discourse to classicallyconsistent theories. This will give us more smooth semantic characterizations, and someadditional important properties. Our description of different kinds of production relations,however, will closely follow the classification of input-output logics given in [25].We will extend production rules to rules having arbitrary sets of propositions as premisesusing the familiar compactness recipe: for any set u of propositions, we define u ⇒ A asfollows:(cid:3)u ⇒ A ≡a ⇒ A,for some finite a ⊆ u110A. Bochman / Artificial Intelligence 160 (2004) 105–143C(u) will denote the set of propositions ‘produced’ by u, that isC(u) = {A | u ⇒ A}.As could be expected, the production operator C will play much the same role as theusual derivability operator for consequence relations. Note first that C(u) is always a de-ductively closed set:Lemma 2.1. For any set u of propositions, C(u) is a deductively closed set.(cid:1)Proof. If A ∈ C(u) and A (cid:1) B, thenWeakening, that is, B ∈ C(u). In addition, if A, B ∈ C(u), then(cid:1)some a, b ⊆ u. Consequently,A ∧ B ∈ C(u). (cid:1)a ⇒ A, for some a ⊆ u, and hencea ⇒ A anda ⇒ B byb ⇒ B, for(a ∪ b) ⇒ A ∧ B by Strengthening and And, and therefore(cid:1)(cid:1)(cid:1)In addition, C satisfies the following basic property:Monotonicity If u ⊆ v, then C(u) ⊆ C(v).(cid:4)ui) =Actually, due to compactness, C is not only monotonic, but also a continuous operator:(cid:4)C(ui), for any chain {ui | i ∈ I } totally ordered with respect to set inclusion.C(Still, C is not inclusive, that is, u ⊆ C(u) does not always hold. Also, it is not idempotent,that is, C(C(u)) can be distinct from C(u).The following fact will be used in proving completeness theorems for different kinds ofproduction inference.Lemma 2.2. If A /∈ C(u), then there exists a consistent deductively closed set v such thatu ⊆ v, A /∈ C(v), and A ∈ C(v(cid:11)), for any v(cid:11) ⊃ v.(cid:4)Proof. If U is an inclusion-ordered family of sets that do not produce A, then a usualU also does not produce A. Consequently, if A /∈compactness argument shows thatC(u), then u is included in some maximal set v that does not produce A. Suppose now thatv is not deductively closed, that is, v (cid:1) B, for some B /∈ v. Then A ∈ C(v ∪ {B}) due tomaximality of v, and hence V ∧ B ⇒ A, where V is a conjunction of some propositionsfrom v. But v implies V ∧ B, and hence V0 (cid:1) V ∧ B, where V0 is again a conjunction ofsome propositions from v. Then V0 ⇒ A holds by Strengthening, and therefore A ∈ C(v)—a contradiction. Consequently, v is a deductively closed set. Moreover, f /∈ v, since f ⇒ Aby Falsity. Therefore, v is also consistent. (cid:1)The reader should note that the theory v in the formulation of the above lemma neednot be a world, that is, a complete deductively closed set.2.1. SemanticsWe will describe now a general semantic framework for production relations. Our basicsemantic object will be a pair of deductively closed theories that will be called a bimodel. InA. Bochman / Artificial Intelligence 160 (2004) 105–143111accordance with the ‘input–output’ understanding of productions, a bimodel will representan initial state (input) and a possible final state (output) of a production derivation based ona given set of production rules. The set of such bimodels will give a semantic descriptionfor these production rules.Definition 2.2. A pair of consistent deductively closed sets will be called a bimodel. A setof bimodels will be called a production semantics.Bimodels have been defined above in a syntactic fashion, namely as pairs of theories.This formulation will make subsequent constructions simpler and more transparent. Still,any bimodel (u, v) can be safely identified with a pair of sets of worlds (or propositionalinterpretations):(cid:5)(u, v) ≡{α | u is valid in α}, {β | v is valid in β}(cid:6).All our subsequent constructions will permit such a purely semantic reformulation. Notethat a production semantics can also be viewed as a binary relation on the set of deductivetheories.Now we will define the notion of validity of production rules with respect to a produc-tion semantics.Definition 2.3. A production rule A ⇒ B will be said to be valid in a production semanticsB if, for any bimodel (u, v) from B, A ∈ u only if B ∈ v.We will denote by ⇒B the set of all production rules that are valid in a semantics B. Itcan be easily verified that this set satisfies all the postulates for production relations, andhence we haveLemma 2.3. For any production semantics B, ⇒B is a production relation.In order to prove completeness, for any production relation ⇒ we will construct itscanonical semantics B⇒ as the set of all bimodels of the form (w, C(w)), where w isan arbitrary consistent and deductively closed set. Then the following result is actuallya representation theorem showing that this semantics is strongly complete for the sourceproduction relation.Theorem 2.4. If B⇒ is the canonical semantics for a production relation ⇒, then, for anyset of propositions u and any A,u ⇒ A iff A ∈ v, for any bimodel (w, v) ∈ B⇒ such that u ⊆ w.Proof. If u ⇒ A and u ⊆ w, for some deductively closed theory w, then clearly A ∈ C(w).In the other direction, if u (cid:1) A, then by Lemma 2.2, u is included in some theory v suchthat v (cid:1) A. Clearly, (v, C(v)) is a bimodel from B⇒ such that u ⊆ v and A /∈ C(v). Thiscompletes the proof. (cid:1)112A. Bochman / Artificial Intelligence 160 (2004) 105–143As an immediate consequence of the above results, we obtain the basic completenessresult:Corollary 2.5. A binary relation ⇒ on the set of propositions is a production inferencerelation if and only if it is determined by a production semantics.2.2. Causal theoriesIn what follows, by a causal theory we will mean an arbitrary set of production rules.Since all the postulates for production relations are Horn ones (that is, they have non-disjunctive conclusions), intersection of production relations is again a production relation,and hence for any causal theory ∆ there exists a least production relation that includes ∆.We will denote it by ⇒∆, while C∆ will denote the corresponding production operator.Clearly, ⇒∆ is the set of all production rules that can be derived from ∆ using the postu-lates for production relations.For a set u of propositions and a causal theory ∆, we will denote by ∆(u) the set of allpropositions that are directly produced from u by ∆, that is,∆(u) = {A | B ⇒ A ∈ ∆, for some B ∈ u}.In what follows we will use the following explicit description of ⇒∆, given, in effect,in [25]:Proposition 2.6. C∆(u) = Th(∆(Th(u))).3. Regular production inferenceA production inference relation will be called regular if it satisfies the following well-known rule:(Cut)If A ⇒ B and A ∧ B ⇒ C, then A ⇒ C.Cut is one of the basic rules for ordinary consequence relations. In the context of produc-tion inference it plays the same role, namely, allows for a reuse of produced propositions aspremises in further productions.4 It corresponds to the following characteristic conditionon the production operator:(cid:5)u ∪ C(u)(cid:6)C⊆ C(u).Regular production relations have a number of additional properties. Thus, any suchrelation will already be transitive, that is, it will satisfy(Transitivity) If A ⇒ B and B ⇒ C, then A ⇒ C.4 Such production relations correspond to input–output logics with reusable output in [25].A. Bochman / Artificial Intelligence 160 (2004) 105–143113Note, however, that Transitivity is a weaker postulate than Cut, since it does not implythe latter (see below).A production rule of the form A ⇒ f will be called a constraint in what follows. Suchrules can be used for incorporating a purely factual information into causal theories: a ruleA ⇒ f says, in a sense, that A is production- or explanatory inconsistent, and hence itshould not hold in any intended model.Now, an important property of regular relations is that any production rule implies thecorresponding constraint:5(Constraint) If A ⇒ B, then A ∧ ¬B ⇒ f.(Indeed, if A ⇒ B, then A ∧ ¬B ⇒ B by Strengthening and A ∧ B ∧ ¬B ⇒ f by Falsity.Hence A ∧ ¬B ⇒ f by Cut.6)In particular, we have that t ⇒ A implies ¬A ⇒ f. Note, however, that the reverseentailment does not hold even in the latter special case.As a special case of Constraint, we have also the rule(Coherence) If A ⇒ ¬A, then A ⇒ fthat says that if a proposition produces propositions that are incompatible with it, then it isexplanatory inconsistent. Actually, Coherence turns out to be equivalent to Constraint forall production inference relations (see Lemma 7.1 below).Remark. Regular production inference sanctions, in effect, an atemporal understanding ofthe notion of production. For example, the rule p ∧ q ⇒ ¬q cannot be understood as sayingthat p and q jointly produce ¬q (afterwards) in a temporal sense; instead, by Coherenceit implies p ∧ q ⇒ f, which means, in effect, that p ∧ q cannot hold. Speaking generally,production-consistent propositions cannot produce a result incompatible with them. Justas in classical logic, however, a representation of temporal domains in this formalism canbe obtained by adding explicit temporal arguments to propositions; this is what has beenactually done in [26].Regular production relations can already be described in terms of a usual notion of atheory.Definition 3.1. A set u of propositions will be called a theory of a production relation, if itis deductively closed, and C(u) ⊆ u.A theory of a production relation is closed with respect to its rules: if A ∈ u and A ⇒ B,then B ∈ u. Accordingly, such theories have much the same properties as ordinary theoriesof consequence relations. Thus, theories that are worlds have a very simple characteriza-tion:5 Cf. Corollary 1 in [17].6 Notice that the use of Falsity is essential here.114A. Bochman / Artificial Intelligence 160 (2004) 105–143Lemma 3.1. A world α is a theory of a regular production relation if and only if α (cid:1) f.Proof. Clearly, if α ⇒ f, then C(α) is an inconsistent theory, and hence C(α) ⊆ α cannothold. Assume now that a world α is not a theory. Then A, ¬B ∈ α, for some propositionsA, B such that A ⇒ B. But then we have also A ∧ ¬B ⇒ f by Constraint, and thereforeα ⇒ f. (cid:1)Theories of a production relation will determine its canonical semantics, described inthe proof of the completeness theorem below. Notice, however, that the production relationwill be determined not only by what its theories are, but also by what they produce.The semantic characterization of regular production relations can be obtained by con-sidering only bimodels (u, v) such that v ⊆ u. We will call such bimodels (and the corre-sponding semantics) inclusive ones.Theorem 3.2. ⇒ is a regular production relation if and only if it is generated by an inclu-sive production semantics.Proof. It is easy to check that the production relation generated by an inclusive semanticssatisfies Cut. In the other direction, for a regular production relation ⇒, we will constructa canonical semantics as the set of bimodels of the form (w, C(w)), where w is a theoryof ⇒. Clearly, if u ⇒ A and u ⊆ w, then A ∈ C(w). In the other direction, if u (cid:1) A,then by Lemma 2.2, u is included in some maximal deductively closed set w such thatw (cid:1) A. Assume that w ⇒ B, for some B, though B /∈ w. Due to maximality of w, wehave w ∪ {B} ⇒ A. Since w is deductively closed, there are propositions C, D ∈ w suchthat C ⇒ B and D ∧ B ⇒ A. But then by Strengthening and Cut we obtain C ∧ D ⇒ A,contrary to our assumption that w (cid:1) A. Hence w is a theory of ⇒, and therefore (w, C(w))is an inclusive bimodel that invalidates u ⇒ A. This completes the proof. (cid:1)We will denote by ⇒r∆ the least regular production relation containing a causal theory∆, while Cr∆ will denote the corresponding production operator.A set u of propositions will be called a ∆-theory, if it is closed both deductively and withrespect to the rules from ∆. As can be anticipated, ∆-theories are precisely the theoriesof ⇒r∆. The following proposition provides a constructive description of this productionrelation, obtained in [25].Proposition 3.3 [25].v ⇒r(cid:5)∆ A iff A ∈ Th(cid:6), for any ∆-theory u ⊇ v.∆(u)If we denote by Cl(v) the least ∆-theory containing v, we immediately obtain a simplercharacterization (that will be used later):Corollary 3.4. Cr∆(v) = Th(∆(Cl(v))).As a final result, we will show that regular production relations allow to define an appro-priate notion of equivalence among propositions such that equivalent propositions wouldA. Bochman / Artificial Intelligence 160 (2004) 105–143115be substitutable in any production rule. Namely, let us say that propositions A and B areproduction-equivalent with respect to a production inference relation, if t ⇒ (A ↔ B)holds. Then we haveLemma 3.5. Propositions A and B are production-equivalent with respect to a regularproduction relation ⇒ if and only if any occurrence of A can be replaced by B in the rulesof ⇒.Proof. If A can be replaced by B in any rule of ⇒, then it can be replaced also in t ⇒(A↔A), which holds by Truth. Hence, t ⇒ (A↔B) holds in ⇒.Let X be a propositional formula. We will denote by X(A/B) an arbitrary for-mula obtained from X by replacing some of the occurrences of A in it by B. Clearly,A↔B (cid:1) X↔X(A/B). Assume now that A and B are production-equivalent, and X ⇒ Y .Then X ⇒ (A↔B) by Strengthening, and hence X ⇒ (Y ↔Y (A/B)) by Weakening.Consequently, X ⇒ Y (A/B) by And and Weakening. Thus, B can replace A in theheads of the rules from ⇒. In addition, we have X(A/B), A↔B (cid:1) X, and thereforeX(A/B) ∧ (A↔B) ⇒ Y by Strengthening. But we have also X(A/B) ⇒ (A↔B), sowe can apply Cut and obtain X(A/B) ⇒ Y . This shows that A can be replaced by B alsoin the bodies of the rules from ⇒. (cid:1)Due to the above result, production-equivalence can be used, in particular, to describedefinitional extensions of the underlying language with new propositions (cf. [37]).4. General nonmonotonic semanticsIn the preceding sections, we have given a formalization and standard (monotonic) se-mantics for a logical system of production inference. It turns out, however, that productioninference relations determine also a natural nonmonotonic semantics, and provide therebya logical basis for a particular form of nonmonotonic reasoning. Namely, the fact that theproduction operator C is not reflexive creates an important distinction among theories of aproduction relation.Definition 4.1.• A theory u of a production inference relation will be called exact, if it is consistent,• A set u of propositions is an exact theory of a causal theory ∆, if it is an exact theoryand u = C(u).of ⇒∆.An exact theory describes an informational state in which every proposition is produced,or explained, by other propositions accepted in this state. Accordingly, restricting our uni-verse of discourse to exact theories amounts to imposing a kind of an explanation closureassumption on a production relation. Namely, it amounts to requiring that any accepted116A. Bochman / Artificial Intelligence 160 (2004) 105–143proposition should also have reason, or explanation, for its acceptance. This suggests thefollowing notion of a nonmonotonic semantics:Definition 4.2. A general nonmonotonic semantics of a production inference relation (or acausal theory) is the set of all its exact theories.The general nonmonotonic semantics, as defined above, is a certain set of propositionaltheories. This abstract definition still leaves us much freedom in determining what can beseen as nonmonotonic consequences of a causal theory. The most obvious choice consistsin taking propositions that belong to all exact theories. As we will see, however, this meansthat we accept only propositions that belong to the least exact theory. But we can alsochoose propositions that belongs to all maximal exact theories. Similarly, we can considerall propositions that do not belong to any such theory as nonmonotonically rejected. Allthese options determine common variants of a cautious (sceptical) nonmonotonic seman-tics. A credulous nonmonotonic semantics can be defined by considering propositions thatbelong (or not belong) to at least one exact theory. As studies in nonmonotonic reasoningshow, each of these options could be appropriate for particular reasoning tasks. Speakinggenerally, all the information that can be discerned from the general nonmonotonic seman-tics of a causal theory, or a production inference relation, can be seen as nonmonotonicallyimplied by the latter.The general nonmonotonic semantics for causal theories is indeed nonmonotonic in thesense that adding new rules to the production relation may lead to a nonmonotonic changeof the associated semantics, and thereby to a nonmonotonic change in the derived informa-tion (a number of examples will be presented below). This happens even though productionrules themselves are monotonic, since they satisfy Strengthening (the Antecedent).Exact theories are precisely fixed points of the production operator C. Since the latteroperator is monotonic and continuous, exact theories (and hence the nonmonotonic seman-tics) always exist. Moreover, there always exists a least exact theory. For regular inferencerelations, the least exact theory coincides with C(t), that is, with the set of propositionsthat are produced by tautologies. In addition, the union of any chain of exact theories (withrespect to set inclusion) is an exact theory, so any exact theory is included in a maximalsuch theory.A useful property of exact theories for regular production relations is described in thenext lemma.Lemma 4.1. If ⇒ is a regular production relation, and u ⊆ C(u), then C(u) is an exacttheory of ⇒.Proof. If u ⊆ C(u), then C(u) ⊆ C(C(u)) by monotonicity of C. In addition, the charac-teristic property of regular productions C(u ∪ C(u)) ⊆ C(u) implies in our case C(C(u)) ⊆C(u), and therefore C(u) = C(C(u)). (cid:1)Unfortunately, the following example shows that exact theories are not closed with re-spect to arbitrary intersections.A. Bochman / Artificial Intelligence 160 (2004) 105–143117Example. Let us consider a causal theory ∆ = {pi ⇒ pi, pi ⇒ q | i (cid:2) 0}. Then, for anyun = Th(q) is notnatural n, the set un = Th(q, pn) is an exact theory of ⇒∆. However,an exact theory of ⇒∆.(cid:7)As a result, a least exact theory containing a given set of propositions does not alwaysexist.The following simple lemma gives a constructive description of the general non-monotonic semantics of a causal theory. The proof is immediate by Proposition 2.6.Lemma 4.2. u is an exact theory of a causal theory ∆ iff u = Th(∆(u)).We are going to show now that regular production inference provides an adequate andmaximal logical framework for reasoning with exact theories.Definition 4.3. Two causal theories will be called nonmonotonically equivalent if they havethe same general nonmonotonic semantics.Note that production inference relations can also be considered as (rather big) causal∆ denote the least regular production relation that contains atheories. As before, let ⇒rcausal theory ∆. Then we haveLemma 4.3. Any causal theory ∆ is nonmonotonically equivalent to ⇒r∆.Proof. If v is a ∆-theory, then v = Cl(v), and hence Th(∆(v)) = Th(∆(Cl(v))). Conse-quently, v = Th(∆(v)) iff v = Th(∆(Cl(v))). By Corollary 3.4, this implies that v is anexact theory of ∆ if and only if it is an exact theory of ⇒r∆. (cid:1)The above lemma implies that the postulates of regular inference are adequate for rea-soning with exact theories, since they preserve the latter. Moreover, we will show nowthat regular inference relations constitute a maximal logic suitable for the general non-monotonic semantics.Let us say that causal theories ∆ and Γ are regularly equivalent, if each can be obtainedfrom the other using the postulates of regular production inference. Or, equivalently, when⇒r∆Γ . Now, as an immediate consequence of Theorem 4.3, we obtain=⇒rCorollary 4.4. Regularly equivalent theories are nonmonotonically equivalent.The reverse implication in the above corollary does not hold, and a deep reason for thisis that the regular equivalence is a monotonic (logical) notion, and hence, unlike the non-monotonic equivalence, it is preserved under addition of new causal rules. What we need,therefore, is a stronger, monotonic counterpart of the notion of nonmonotonic equivalencethat would be preserved under addition of new causal rules. This immediately suggests thefollowing definition.Definition 4.4. Two causal theories ∆ and Γ will be said to be strongly equivalent if, forany set Φ of causal rules, ∆ ∪ Φ is nonmonotonically equivalent to Γ ∪ Φ.118A. Bochman / Artificial Intelligence 160 (2004) 105–143Strongly equivalent theories are ‘equivalent forever’, that is, they are interchangeablein any larger causal theory without changing the general nonmonotonic semantics. Conse-quently, strong equivalence can be seen as an equivalence with respect to the backgroundmonotonic logic of causal theories. And the next result shows that this logic is preciselythe logic of regular production relations.Theorem 4.5. Two causal theories are strongly equivalent if and only if they are regularlyequivalent.Proof. To simplify notation, ⇒Ψ below will denote the least regular production relationcontaining a causal theory Ψ , while CΨ will denote the associated production operator.The direction from right to left follows from Corollary 4.4 and the fact that if ∆ and Γare regularly equivalent, then, for any Φ, ∆ ∪ Φ and Γ ∪ Φ are also regularly equivalent.Assume now that ∆ is not regularly equivalent to Γ . Then we may assume for certaintythat there are propositions A, B such that A ⇒∆ B and A (cid:1)Γ B. The latter fact meansthat there is a theory u of Γ such that A ∈ u and B /∈ CΓ (u). Let us consider two cases.Suppose first that u is not a theory of ∆. Then we choose Φ = {C ⇒ C | C ∈ u}. Clearly,u is an exact theory for Γ ∪ Φ, though not for ∆ ∪ Φ.Suppose now that u is a theory of ∆. Since B ∈ C∆(u), we have B ∈ u. Let β be a worldthat includes both CΓ (u) and ¬B (since B /∈ CΓ (u), such a world should exist). Then wedefine Φ as {C ⇒ C | C ∈ u ∩ β}. Note first that CΓ ∪Φ (u) = u ∩ β, and hence u is notan exact theory for Γ ∪ Φ. But u is the least theory that contains both C∆(u) and u ∩ β,and hence it is an exact theory for ∆ ∪ Φ. Indeed, if C ∈ u, then B→C ∈ u ∩ β, andtherefore B→C ∈ C∆∪Φ(u). In addition, B ∈ C∆∪Φ (u) (since B ∈ C∆(u)). Consequently,C ∈ C∆∪Φ (u), and therefore u ⊆ C∆∪Φ (u). (cid:1)The above result implies, in effect, that regular production relations are maximal infer-ence relations that are adequate for reasoning with causal theories: any postulate that isnot valid for regular production relations can be ‘falsified’ by finding a suitable extensionof two causal theories that would determine different nonmonotonic semantics, and hencewould produce different nonmonotonic conclusions.Note that ‘discriminating’ sets of causal rules Φ were restricted in the proof to rules ofthe form C ⇒ C. Such rules will play below an important role in representing abductivereasoning in the framework of production inference.As a last result in this section, we will show that, under some special conditions, thenonmonotonic semantics of causal theories grows monotonically with the growth of thesecausal theories.Definition 4.5. Causal theories Γ and ∆ will be called supraclassically equivalent, if ⇒∆and ⇒Γ have the same theories.Recall that theories of ⇒∆ are precisely deductively closed sets that are closed also withrespect to the rules of ∆. Accordingly, supraclassical equivalence amounts, in effect, to theequivalence of ∆ and Γ viewed as ordinary rules of a consequence relation. More exactly,A. Bochman / Artificial Intelligence 160 (2004) 105–143119∆ and Γ are supraclassically equivalent if and only if the rules of Γ and ∆ are inter-derivable using the postulates of supraclassical consequence relations (see Introduction).Now we can show the followingLemma 4.6. If causal theories Γ and ∆ are supraclassically equivalent, and Γ ⊆ ∆, thenany exact theory of Γ is an exact theory of ∆.Proof. If u = CΓ (u), then clearly u ⊆ C∆(u). But u is a theory of Γ , and hence it is atheory of ∆, that is, C∆(u) ⊆ u. Therefore u = C∆(u), and consequently u is an exacttheory of ∆. (cid:1)The above result clarifies, in effect, the reasons why the semantics of exact theories isnonmonotonic. Indeed, if the production rules added to a causal theory do not change theset of theories of the latter, then they extend, in general, the set of its exact theories, andtherefore not all the conclusions made earlier will be preserved.4.1. On informational content of causal theoriesThe existence of two kinds of semantics for production inference relations, monotonicand nonmonotonic ones, poses a nontrivial question about the meaning, or informationalcontent, of causal theories. Moreover, this conceptual question becomes a practical prob-lem when we need to compare such theories from informational point of view, or update acausal theory with new information in such a way that would produce a minimal change inits informational content.The above question is clearly not specific to production inference, and it can be posedabout practically any nonmonotonic formalism. And unfortunately, a common (though of-ten tacit) answer to this question consists in a direct identification of the meaning of anonmonotonic theory with its nonmonotonic semantics. Furthermore, in the case of defaultlogic, the nonmonotonic semantics (of extensions) is even presented as the only semanticsthat we have for default theories.The above solution to the problem of informational content of nonmonotonic theoriesturns out to be problematic, however. To begin with, quite diverse theories can have thesame ‘meaning’ according to this understanding, witness all default theories that do nothave extensions. Moreover, adding new rules to a theory does not necessarily mean that theextended theory contains more information. Speaking generally, the meaning associatedwith a theory by this solution is non-modular, and hence cannot be viewed as composedfrom the meanings of its components. As a result, meaning of this kind turns out to beuseless for most purposes we could possibly have in invoking this notion, be it knowledgerepresentation or informational updates.Intuitively, an informational content of a causal theory should contain all the informa-tion needed to determine the properties and behavior of this theory. Thus, it is natural tosuppose that when two causal theories have the same informational content, they shouldbe interchangeable in any larger causal theory without changing its properties. Moreover,it seems natural to expect also that adding new rules to a theory should normally in-crease its informational content (unless the added rules are derivable somehow from the120A. Bochman / Artificial Intelligence 160 (2004) 105–143source theory). All these requirements will not be met if we will identify the content of thecausal theory with its nonmonotonic semantics. Indeed, it is nonmonotonic precisely in thesense that adding new production rules to a theory may result in removal of some of thepreviously derivable information. Consequently, the nonmonotonic semantics is patentlyinsufficient for capturing the full content of a causal theory.An alternative, and seemingly more plausible, solution to this problem is based on aclear separation between logical (monotonic) and nonmonotonic aspects of reasoning withnonmonotonic theories. Once such a separation is made, the meaning, or an informationalcontent, of a theory could be identified with its logical meaning naturally determined bythe underlying monotonic logic and its semantics. The nonmonotonic semantics will playno direct role in this description; the logical meaning will usually determine also the as-sociated nonmonotonic semantics, though not vice versa. For default theories, such anunderlying monotonic logic has been described in [5] as a set of inference rules for defaultrules that preserve the extension-based nonmonotonic semantics. In the present study, wesuggest a similar solution for causal theories.As has been established, regular production relations constitute a maximal logic suitablefor the general nonmonotonic semantics. Accordingly, the informational content of a causaltheory ∆ with respect to the latter can be safely identified with the set of causal rules thatare derivable from ∆ by the postulates of regular production inference, that is, with ⇒r∆.Clearly, such a definition of an informational content will satisfy all the desired properties,mentioned above. Moreover, since the general nonmonotonic semantics of a productionrelation is uniquely determined by its canonical production semantics, the nonmonotonicsemantics of a causal theory constitutes, in a sense, part of its informational content.A more detailed description of informational content will be given below for a specialcase of causal nonmonotonic semantics.5. Abductive production inferenceIn this section we will describe a special kind of regular production inference relationsthat provides a formal representation for general abductive reasoning. In addition to spe-cific results, this will give us also a broader perspective on the representation capabilitiesof production inference relations as a general-purpose formalism for nonmonotonic rea-soning.A general abductive framework can be defined as a pair A = (Cn, A), where Cn isa consequence relation, and A is a distinguished set of propositions called abducibles.A proposition A is explainable in an abductive framework A if there exists a consistent setof abducibles a ⊆ A such that A ∈ Cn(a).A general correspondence between abductive frameworks and production inference hasbeen established in [10]. The correspondence has been based on the identification betweenthe above notion of explainability and production derivability. By this correspondence,abducibles are representable by ‘reflexive’ propositions satisfying the rule A ⇒ A, and theabductive frameworks themselves correspond to production inference relations satisfyingan additional postulate of Abduction, given below.A. Bochman / Artificial Intelligence 160 (2004) 105–143121Definition 5.1.• A proposition A will be called an abducible in a production relation ⇒, if A ⇒ A;• A production relation will be called abductive if it is regular and satisfies(Abduction) If A ⇒ B, then A ⇒ C ⇒ B, for some abducible C.As can be seen, production inference in abductive production relations is always me-diated by abducible (self-explanatory) propositions. Consequently, for such productionrelations, propositions caused by worlds are caused, in effect, by the abducibles that holdin these worlds:C(α) = C(α ∩ A),where A is the set of abducibles of ⇒.By the correspondence established in [10], the general nonmonotonic semantics of ab-ductive production relations describes, in effect, the explanatory closure, or completion, inassociated abductive frameworks (see [12,18]). These results have shown, in effect, thatproduction inference allows to give a syntax-independent representation of abductive rea-soning, a representation in which abducibles are defined not as a syntactically distinguishedset of propositions, but logically as propositions that satisfy certain property (namely re-flexivity A ⇒ A).Example. The following causal theory ∆ represents a variant of the well-known examplefrom [31].Sprinkler ⇒ Grasswet Rained ⇒ StreetwetRained ⇒ GrasswetRained ⇒ Rained ¬Rained ⇒ ¬RainedSprinkler ⇒ Sprinkler ¬Sprinkler ⇒ ¬Sprinkler¬Grasswet ⇒ ¬Grasswet ¬Streetwet ⇒ ¬StreetwetThe first three rules give a causal description of the domain, while the rest describes theassociated abducibles. It can be verified that the regular production relation determined by∆ is abductive.By stipulating that both Rained and ¬Rained are abducibles, we make Rained an inde-pendent (exogenous) parameter. However, since ¬Grassswet is an abducible, but Grasswetis not, non-wet grass does not require explanation, but wet grass does. Thus, any exact the-ory of ∆ that contains Grasswet should contain either Rained, or Sprinkler. Similarly, thenonmonotonic semantics of ∆ sanctions in this sense that Streetwet implies both Rainedand Grasswet.5.1. The abductive subrelationHere we will show that any production relation includes an important abductive subre-lation; as we will see, in many regular situations the latter subrelation will determine thesame nonmonotonic semantics.122A. Bochman / Artificial Intelligence 160 (2004) 105–143Given a regular production relation ⇒, we will define the following production relation:A ⇒a B ≡ (∃C)(A ⇒ C ⇒ C ⇒ B).Theorem 5.1. If ⇒ is a regular production relation, then ⇒a is the greatest abductiveproduction relation included in ⇒.Proof. We need to check first that ⇒a satisfies the postulates of production inference.Strengthening, Weakening, Truth and Falsity are obvious.And. Assume that A ⇒a B and A ⇒a D. Then there are C1 and C2 such that A ⇒ C1 ⇒C1 ⇒ B and A ⇒ C2 ⇒ C2 ⇒ D. Note first that C1 ∧ C2 ⇒ C1 ∧ C2 by Strengtheningand And, as well as A ⇒ C1 ∧ C2 and C1 ∧ C2 ⇒ B ∧ D. Hence A ⇒a B ∧ D. Thus, Andholds.Cut. Assume that A ⇒a B and A ∧ B ⇒a D. Then there are C1 and C2 such thatA ⇒ C1 ⇒ C1 ⇒ B and A ∧B ⇒ C2 ⇒ C2 ⇒ D. As before, we have C1 ∧C2 ⇒ C1 ∧C2.In addition, since A ⇒ B (by Transitivity) and A ∧ B ⇒ C2, we have A ⇒ C2 by Cut, andtherefore A ⇒ C1 ∧ C2. Also, C2 ⇒ D implies C1 ∧ C2 ⇒ D. Therefore, A ⇒a D, whichshows that Cut holds for ⇒a.Thus, ⇒a is an abductive production relation. Moreover, if A ⇒a B, then A ⇒ B byTransitivity, so ⇒a is included in ⇒.Let ⇒1 be some abductive production relation that is included in ⇒, and A ⇒1 B.By Abduction, there is C such that A ⇒1 C ⇒1 C ⇒1 B. But ⇒1 is included in ⇒, andtherefore A ⇒ C ⇒ C ⇒ B. The latter implies A ⇒a B, which shows that ⇒1 is includedin ⇒a. Thus, ⇒a is the greatest abductive production relation included in ⇒. (cid:1)It turns out that the above abductive subrelation of a production relation preserves manyproperties of the latter. For example, both have the same constraints, that is, A ⇒ f holds ifand only if A ⇒a f. Similarly, both have the same ‘axioms’: t ⇒ A holds iff t ⇒a A. Lastbut not least, both have the same abducibles.5.2. Quasi-abductive production inferenceThe general nonmonotonic semantics is based on the explanation closure assumption,according to which any accepted proposition should be produced by other accepted propo-sitions. But the latter should also be produced by accepted propositions, and so on. Itshould be clear that if our ‘production resources’ are limited (for example, if our languageis finite), such a production process should stop somewhere. More exactly, it should reachabducible (self-explanatory) propositions. This indicates that in many regular cases thenonmonotonic semantics of a production relation should coincide with the nonmonotonicsemantics of its abductive subrelation. Below we will make this claim precise.Definition 5.2. A production relation will be called quasi-abductive if it is nonmonotoni-cally equivalent to its abductive subrelation.The next definition will give us an important sufficient condition for quasi-abductivity.A. Bochman / Artificial Intelligence 160 (2004) 105–143123Definition 5.3. A regular production relation ⇒ will be called well-founded if any infinitesequence {A0, A1, A2, . . .} of propositions such that An+1 ⇒ An, for every n (cid:2) 0, containsan abducible.The above definition describes a variant of a standard notion of well-foundedness withrespect to the partial order determined by a regular production relation. Namely, it says thatany infinite descending sequence of productions should always contain reflexive elements.It should be clear that any production relation in a finite propositional language shouldbe well-founded. Moreover, let us say that a regular production relation is finitary, if it is aleast regular production relation containing some finite causal theory. Then the followingresult shows that any such production relation is well-founded.Theorem 5.2. Any finitary regular production relation is well-founded.Proof. Let ⇒ be a regular production relation determined by a finite causal theory ∆, andassume that {Ai | i (cid:2) 0} is an infinite sequence of propositions such that An+1 ⇒ An, forany n (cid:2) 0.Let us say that a proposition C is explicit with respect to ⇒ if it is a conjunction of headsof some rules from ∆. Since ∆ is finite, the set of explicit propositions will also be finite (upto logical equivalence). Moreover, Proposition 3.3 implies that A ⇒ B holds only if A ⇒C, for some explicit C such that C (cid:1) B. This means, in particular, that in the above infiniteproduction sequence, any production is ‘mediated’ by an explicit proposition: Ai+1 ⇒Ci (cid:1) Ai .Since the set of explicit propositions is finite, there must exist at least two propositionsAj , Ak in the sequence such that j > k, Aj +1 ⇒ C (cid:1) Aj and Ak+1 ⇒ C (cid:1) Ak, for someexplicit C. Then we have C (cid:1) Aj and Aj ⇒ C (by Transitivity), and hence Aj ⇒ Aj byWeakening. Hence, any sequence of productions in ⇒ should be well-founded. (cid:1)Finally, the following basic result shows that a well-founded production relation deter-mines precisely the same general nonmonotonic semantics as its abductive subrelation.Theorem 5.3. Any well-founded regular production relation is quasi-abductive.Proof. We will denote by Ca the production operator corresponding to ⇒a.Assume first that u is an exact theory of ⇒, that is, u = C(u). Then clearly Ca(u) ⊆ u.Let A0 ∈ u. Then A0 ∈ C(u), and hence there must exist A1 ∈ u such that A1 ⇒ A0.Repeating this argument, we obtain an infinite chain {A0, A1, A2, . . .} of propositions suchthat all Ai belong to u and Ai+1 ⇒ Ai , for any i (cid:2) 0. But our production relation iswell-founded, so there must exist some abducible An in the chain. Clearly, An ∈ u andAn ⇒ An ⇒ A0 (by Transitivity). Hence An ⇒a A0, and therefore A0 ∈ Ca(u). This showsthat u ⊆ Ca(u), and hence u is an exact theory of ⇒a.Assume now that u is an exact theory of ⇒a. Then clearly u ⊆ C(u). So we have toshow only that u is a theory in ⇒. Suppose that A ∈ u and A ⇒ B. Then A ∈ Ca(u), andhence there exists D ∈ u such that D ⇒a A. Consequently D ⇒ C ⇒ C ⇒ A, for some C.124A. Bochman / Artificial Intelligence 160 (2004) 105–143But then C ⇒ B, and therefore D ⇒a B. The latter implies that B ∈ Ca(u), and thereforeB ∈ u. Thus, u is a theory in ⇒, and consequently it is an exact theory in ⇒. (cid:1)Recall now that abductive production relations correspond to abductive systems. Ac-cordingly, the above result shows that in the well-founded case the general nonmonotonicsemantics of a regular production relation is describable by some abductive framework, andvice versa. As a general conclusion, however, we can say that production inference con-stitutes a proper generalization of abductive reasoning, a generalization that goes beyondwell-foundedness.6. Basic production inferenceFollowing [25], a production inference relation will be called basic if it satisfies(Or)If A ⇒ C and B ⇒ C, then A ∨ B ⇒ C.The above inference rule allows for reasoning by cases, and hence basic production rela-tions can already be seen as systems of objective production inference, namely as systemsof reasoning about complete worlds.The postulate Or corresponds to the following characteristic property of the productionoperator: for any deductively closed sets u, v,C(u ∩ v) = C(u) ∩ C(v).As a consequence of this condition, the set of propositions produced by a theory ucoincides with the set of propositions that are produced by every world containing u:(cid:8)C(u) ={C(α) | u ⊆ α}.Another important fact about basic production inference is that a production rule A ∨B ⇒ C is equivalent to the pair of rules A ⇒ C and B ⇒ C. As a result, any productionlj , where li, ljrule is reducible to a set of clausal production rules of the formare classical literals.li ⇒(cid:1)(cid:2)For any causal theory ∆, a least basic production relation containing ∆ will be denotedby ⇒b∆. The following characterization of this relation has been obtained in [25]:Proposition 6.1. u ⇒b∆ A iff A ∈ Th(∆(α)), for every world α ⊇ u.6.1. Possible worlds semanticsThe semantic characterization of basic production relations can be obtained from thegeneral production semantics by restricting the set of bimodels to world-based ones,namely to bimodels of the form (α, β), where α, β are worlds. Clearly, the correspond-ing production semantics can be identified with a relational possible worlds model W =(W, B), where W is a set of worlds, and B is an accessibility relation on W . The followingdefinition provides the corresponding notion of validity for productions:A. Bochman / Artificial Intelligence 160 (2004) 105–143125Definition 6.1. A production rule A ⇒ B will be said to be valid in a possible worldsmodel (W, B) if, for any pair of worlds α, β ∈ W such that αBβ, if A holds in α, then Bholds in β.We will denote by ⇒W the set of all productions that are valid in a possible worldsmodel W. It can be easily verified that this set is closed with respect to the rule Or, andhence we haveLemma 6.2. ⇒W is a basic production relation.In order to prove completeness, for any basic production relation ⇒ we will constructits canonical possible worlds model W⇒ as a pair (W, B) such that W is a set of all worlds(maximal classically consistent subsets) of the language, and B is a relation on W definedas follows:αBβ ≡ C(α) ⊆ β.Then the following result shows that this semantics is strongly complete for the sourceproduction relation.Lemma 6.3. If W⇒ is the canonical semantics of a basic production relation ⇒, then, forany set of propositions u and any A,u ⇒ A iff A ∈ β, for any α, β ∈ W such that αBβ and u ⊆ α.Proof. If u ⇒ A and u ⊆ α, for some world α, then clearly A ∈ C(α), and therefore A ∈ β,for any world β that includes C(α). Thus, u ⇒ A is valid in the canonical semantics. Inthe other direction, if u (cid:1) A, then by Lemma 2.2, u is included in a maximal deductivelyclosed set α that does not produce A. Now, by the rule Or, B ∨ C ∈ α only if either B ∈ αor C ∈ α. Hence α should be a world. Now, since A /∈ C(α), there must exist a world βcontaining C(α) and such that A /∈ β. Clearly, (α, β) is a bimodel from B⇒ that refutesu ⇒ A. (cid:1)As a general conclusion from the above results, we obtainCorollary 6.4. ⇒ is a basic production relation if and only if it is determined by a possibleworlds semantics.The above semantics immediately suggests a modal translation of production rules de-scribed in [25] (see also [37,38]). Namely, let (cid:3) be the usual modal operator definable in apossible worlds model: (cid:3)A holds in α iff A holds in all β such that αRβ. Then the validityof A ⇒ B in a possible worlds model is equivalent to validity of the formula A → (cid:3)B.Consequently, causal rules are representable by modal formulas of the latter form.6.2. Four-valued semanticsIn this section we are going to show that basic production inference relations possessalso a natural four-valued semantics. Among other advantages, this semantics has turned126A. Bochman / Artificial Intelligence 160 (2004) 105–143out to be useful in establishing the correspondence between production inference relations,on the one hand, and logic programming and related nonmonotonic formalisms, on theother.According to the well-known Belnap’s interpretation (see [2]), a four-valued interpre-tation can be viewed as a function assigning each propositional atom a subset of the set{t, f } of classical truth-values. More exactly, the four truth-values (cid:17), t, f, ⊥ are identified,respectively, with {t, f }, {t}, {f } and ∅. Accordingly, (cid:17) means that a proposition is bothtrue and false (i.e., contradictory), t means that it is ‘classically’ true (that is, true withoutbeing false), f means that it is classically false (without being true), and ⊥ means that it isneither true nor false (undetermined).The above interpretation allows us to see any 4-assignment as a pair of ordinary classicalvaluations, corresponding, respectively, to independent assignments of truth and falsity topropositions. To be more exact, for any 4-assignment ν (under the above interpretation)and any proposition A we can define the following two valuations saying, respectively, “Ais true in ν” and “A is false in ν”:ν |= A ifft ∈ ν(A)ν =|A iff f ∈ ν(A).In this setting, any four-valued connective is definable via a pair of definitions stating,respectively, when the formula is true and when it is false (see [3] for details). Two suchfour-valued connectives will be of special interest for our present study. The first is a well-known conjunction connective:ν |= A ∧ B iffν =|A ∧ B iffν |= A and ν |= Bν =|A or ν =|B.The second is the following negation connective that can be seen as a most naturalextension of the classical negation to the four-valued setting:ν |= ¬A iffν =|¬A iffν (cid:19)|= Aν (cid:19)=|A.A common feature of these two connectives is that they have the same definitions fortruth as for non-falsity, and that the truth (respectively, falsity) of a compound formula isdetermined only in terms of truth (respectively, falsity) of its arguments. Four-valued func-tions of this kind will be called locally classical, since they behave as ordinary classicaltruth-valued functions with respect to each of the two contexts. Moreover, since a classi-cal conjunction and negation form a functionally complete set for classical (two-valued)functions, it should be clear that the above two four-valued connectives are functionallycomplete for the set of all locally classical connectives.Recall now that the semantics of a basic production inference is a set of pairs of worlds.By the above correspondence, such pairs can be identified with four-valued interpretations,whereas the classical connectives will correspond then to the relevant locally classical four-valued connectives. Given this understanding, the notion of validity of production ruleswith respect to a possible worlds semantics is transformed into the following definition ofvalidity with respect to a set of four-valued interpretations:A. Bochman / Artificial Intelligence 160 (2004) 105–143127Definition 6.2. A production rule A ⇒ B will be said to be valid with respect to a set offour-valued interpretations I whenν =|A or ν |= B,for any ν ∈ I.Let us denote by ⇒I the set of all production rules that are valid in a four-valued se-mantics I. Then, as an immediate consequence of the above correspondence, we obtainTheorem 6.5. A set of production rules ⇒ is a basic production inference relation if andonly if ⇒ = ⇒I, for some set of four-valued interpretations I.The above result shows that the four-valued semantics gives a complete semantic char-acterization of basic production inference relations.As a by-product of the above semantic representation, we obtain also that productioninference relations are closely related to biconsequence relations from [3]. Biconsequencerelations are sets of ‘double’ sequents (bisequents) of the forma : b (cid:4) c : d,where a, b, c, d are sets of propositions. Such bisequents have the following four-valuedinterpretation:If all propositions from a are true, and all propositions from b are false, then one of thepropositions from c is true, or one of the propositions from d is false.It has been shown in [3] that biconsequence relations provide a structural descriptionof four-valued reasoning. Namely, any four-valued connective is definable in this settingby using appropriate introduction and elimination rules, just as in the usual classical se-quent calculus. Biconsequence relations have been used in [4] as a logical basis of logicprogramming.Now, it follows from the above four-valued interpretation of bisequents that a bisequenta:b (cid:4) c:d has the same interpretation as the production rule(cid:3)(cid:9)(¬b ∪ d) ⇒(¬a ∪ c)while any production rule A ⇒ B has the same four-valued interpretation as a bisequent(cid:4) B:A. This shows, in effect, that basic production inference relations constitute an exactlogical counterpart of biconsequence relations in the language of local classical connec-tives. A more detailed description of this correspondence will be given elsewhere.7. Causal inferenceNow we will consider production relations that are both basic and regular.Definition 7.1. A production inference relation will be called causal if it satisfies Or andCut.128A. Bochman / Artificial Intelligence 160 (2004) 105–143Causal inference relations enjoy the properties of both basic and regular productionrelations described in the preceding sections. In particular, since they are basic, causal in-ference can also be considered as a particular (namely, regular) kind of objective productioninference.An interesting syntactic fact about causal inference relations is that the Cut rule turnsout to be equivalent to Coherence (see Section 3).Lemma 7.1. For basic production relations, Cut is equivalent to Coherence.Proof. It has been shown earlier that Cut implies Constraint (and hence Coherence). As-sume now that Coherence holds, and we have A ⇒ B and A ∧ B ⇒ C. Then the former im-plies A ∧ ¬B ⇒ ¬(A ∧ ¬B) by Strengthening and Weakening, and therefore A ∧ ¬B ⇒ fby Coherence.7 Consequently, A ∧ ¬B ⇒ C by Weakening, and therefore A ⇒ C by Or.Thus, Cut holds. (cid:1)Another important fact about causal relations is the following decomposition of causalrules:Lemma 7.2. Any causal rule A ⇒ B is equivalent to a pair of rules A ∧ ¬B ⇒ f andA ∧ B ⇒ B.Proof. The direction from left to right is immediate. In the other direction, if A ∧ ¬B ⇒ fand A ∧ B ⇒ B, then A ∧ ¬B ⇒ B by Weakening, and hence A ⇒ B by Or. (cid:1)Causal rules of the form A ∧ B ⇒ B are logically trivial, but they play an importantexplanatory role in causal reasoning. Namely, they say that, in any causally explained in-terpretation in which A holds, we can freely accept B, since it is self-explanatory in thiscontext. Accordingly, such rules will be called explanatory rules in what follows.Since causal inference is a special kind of an objective (world-based) inference, a con-straint A ∧ ¬B ⇒ f says, in effect, that the classical implication A → B should hold in anycausally consistent world.Now the above lemma says that any causal rule can be decomposed into a constraintand an explanatory rule. This decomposition neatly delineates two kinds of informationconveyed by causal rules. One is a factual information that constrains the set of admissiblemodels, while the other is an explanatory information describing what propositions arecaused (explainable) in such models.8Now we will turn to a semantic description of causal inference. It has been shown earlierthat possible worlds models with arbitrary accessibility relations provide a semantics forbasic production relations. It turns out that causal inference relations are determined bypossible worlds models in which the accessibility relation is quasi-reflexive, that is, satisfiesthe following condition for any two worlds:7 This shows, in effect, that Constraint and Coherence are equivalent rules.8 Cf. a similar decomposition of causal rules in [36].A. Bochman / Artificial Intelligence 160 (2004) 105–143129(Quasi-Reflexivity) If αRβ, then αRα.The next lemma shows that quasi-reflexive models determine causal inference relations.Lemma 7.3. A production inference relation determined by a quasi-reflexive possibleworlds model is causal.Proof. Suppose that (W, R) is a quasi-reflexive model in which A ⇒ B and A ∧ B ⇒ Care valid, while A ⇒ C is not valid. Then there are worlds α, β such that αRβ, A ∈ αand C /∈ β. Consequently, αRα by quasi-reflexivity, and hence A ⇒ B implies that B ∈ α.Thus, A ∧ B ∈ α, and therefore A ∧ B ⇒ C gives us that C should hold in β, contraryto our assumptions. Hence, production relations generated by quasi-reflexive models arecausal. (cid:1)The following theorem shows that causal relations are actually complete for such mod-els.Theorem 7.4. A production inference relation is causal if and only if it is determined by aquasi-reflexive possible worlds model.Proof. Given a causal relation ⇒, we construct the corresponding canonical model(W, Rc) by defining Rc as follows: αRcβ ≡ C(α) ⊆ α ∩ β. Notice that this definitiondirectly implies quasi-reflexivity of Rc.As in the proof of Lemma 6.3, it can be shown that if A ⇒ B holds, then it is valid in(W, Rc). Now if A (cid:1) B, the same proof shows that there are worlds α, β such that A ∈ α,B /∈ β and C(α) ⊆ β. Moreover, we will show that C(α) ⊆ α.Suppose that C(α) (cid:2) α. This means that there are propositions C, D such that D ∈ αand D ⇒ C, but C /∈ α. Now, α has been defined in the proof of Lemma 6.3 as a maximalset that does not produce B. Consequently, B ∈ C(α, C), and hence there must exist E ∈ αsuch that C ∧ E ⇒ B. The latter implies D ∧ C ∧ E ⇒ B. In addition, D ⇒ C impliesD ∧ E ⇒ C. Hence D ∧ E ⇒ B by Cut. But D ∧ E ∈ α, and therefore B ∈ C(α), contraryto the definition of α. Thus, C(α) ⊆ α.By the definition of Rc, we have now αRcβ, and therefore A ⇒ B is not valid in(W, Rc). This completes the proof. (cid:1)It is interesting to note that the above semantic interpretation gives clear semanticreasons why Transitivity is a weaker property than Cut. Indeed, it is easy to verify thatTransitivity holds for all production relations determined by possible world models witha dense accessibility relation, that is, a relation satisfying the condition that if αRβ, thenthere exists γ such that αRγ and γ Rβ. Clearly, quasi-reflexivity is a stronger propertythan density.In what follows, ⇒c∆ will denote the least causal inference relation containing a causal−→theory ∆. In addition,∆ will denote the set of material implications corresponding to theproduction rules from ∆, namely−→∆ = {A → B | A ⇒ B ∈ ∆}.130A. Bochman / Artificial Intelligence 160 (2004) 105–143As before, [25] provides a constructive description of ⇒c∆. Such a description canbe obtained from the corresponding description for regular production relations, given inProposition 3.3, simply by restricting the set of ∆-theories to worlds. Notice, however, thata world α is a ∆-theory if and only if−→∆ ⊆ α. Consequently, we obtainProposition 7.5. u ⇒c∆ A iff A ∈ Th(∆(α)), for any world α ⊇ u ∪−→∆.Thus, derivability in causal inference relations is reducible, in effect, to derivability in−→∆. This fact implies, inbasic production relations with an additional set of assumptionsparticular, that the material implications corresponding to the production rules can be usedas auxiliary assumptions in making derivations. In other words, causal inference relationsmake valid the following rule:If A ⇒ B and C ∧ (A→B) ⇒ D, then C ⇒ D.8. The causal nonmonotonic semanticsIf we concentrate on an objective understanding of production rules as rules acting inworld-based contexts, it is only natural to consider also the corresponding restriction of thegeneral nonmonotonic semantics to exact theories that are worlds. In this case, the principleof explanation closure can be justifiably called the principle of universal causation (see[37]).Definition 8.1. A causal nonmonotonic semantics of a production inference relation or acausal theory is the set of all its exact worlds.Since the causal nonmonotonic semantics forms a subset of the general nonmonotonicsemantics, it produces, in general, a larger set of nonmonotonic consequences. Moreover,the causal semantics is just a set of worlds, so its logical content is exhausted by the classi-cal propositional theory that is uniquely associated with this set of worlds. Note, however,that, unlike the general nonmonotonic semantics, the causal nonmonotonic semantics isnot guaranteed to exist for any causal theory.The following lemma gives a useful alternative description of exact worlds.Lemma 8.1. A world α is an exact world of a production inference relation if and only if,for any propositional atom p,p ∈ α iff α ⇒ pp /∈ α iff α ⇒ ¬p.Proof. Due to the fact that α is a world, the above conditions are sufficient for the equalityα = C(α). (cid:1)By Lemma 4.2, the causal nonmonotonic semantics of a causal theory ∆ is the set ofworlds α such that α = Th(∆(α)). Such worlds coincide with causally explained inter-A. Bochman / Artificial Intelligence 160 (2004) 105–143131pretations of [26], which determine the nonmonotonic semantics of their causal theories.Consequently the causal nonmonotonic semantics provides an adequate representation forthis nonmonotonic system.An alternative description of exact worlds for causal theories is given below.Corollary 8.2. A world α is an exact world of a causal theory ∆ if and only if, for anypropositional atom p,p ∈ α iff ∆(α) (cid:1) pp /∈ α iff ∆(α) (cid:1) ¬p.Proof. Follows from the fact that the above conditions are equivalent to α = Th(∆(α)). (cid:1)Now we will show that causal inference relations provide an adequate framework ofreasoning with respect to the causal nonmonotonic semantics. As before, we will introducefirst the following definitions:Definition 8.2. Causal theories Γ and ∆ will be called• objectively equivalent if they have the same causal nonmonotonic semantics;• strongly objectively equivalent if, for any set Φ of production rules, ∆ ∪ Φ is objec-tively equivalent to Γ ∪ Φ;• causally equivalent if ⇒c∆= ⇒cΓ .Two causal theories are causally equivalent if each theory can be obtained from theother using the inference postulates of causal relations.Lemma 8.3. Any causal theory ∆ is objectively equivalent to ⇒c∆.∆ denote the production operator corresponding to ⇒cProof. Let Ccimplies that, for any causally consistent world α, CcCc∆(α) if and only if α = Th(∆(α)). (cid:1)∆. Then Proposition 7.5∆(α) = Th(∆(α)). Consequently, α =The above lemma says that the postulates of causal inference relations are adequate forreasoning with exact worlds, since they preserve the latter. Moreover, the next theoremshows that causal inference relations constitute a maximal logic suitable for the causalnonmonotonic semantics.Theorem 8.4. Two causal theories are strongly objectively equivalent if and only if theyare causally equivalent.Proof. Coincides with the proof of Theorem 4.5, once we notice that, for our present case,the theory u in this proof is a world. (cid:1)132A. Bochman / Artificial Intelligence 160 (2004) 105–143Finally, just as for the general nonmonotonic semantics, under some conditions, thecausal nonmonotonic semantics grows monotonically with the growth of these causal the-ories.Definition 8.3. Causal theories Γ and ∆ will be called classically equivalent, ifcally equivalent to−→Γ .−→∆ is logi-Causal theories are classically equivalent if they are logically equivalent when viewedas sets of classical material implications. Recall now that causally consistent worlds−→∆. Consequently, classically equivalentof a causal theory ∆ are the worlds satisfyingcausal theories have the same causally consistent worlds, and hence as a consequence ofLemma 4.6, we obtainCorollary 8.5. If causal theories Γ and ∆ are classically equivalent, and Γ ⊆ ∆, then anyexact world of Γ is an exact world of ∆.As a particular application of the above result, suppose that we add a new inference rulefor production relations that corresponds to a valid rule of classical logic. Such a rule willnot change the causally consistent worlds of a production relation, and consequently thenew causal nonmonotonic semantics will include the original one.8.1. Factual and explanatory content of causal theoriesSince causal inference relations form a maximal logic with respect to the causal non-monotonic semantics, the informational content of a causal theory ∆ with respect to thelatter can be identified with ⇒c∆, that is, with the set of causal rules that are derivable from∆ by the rules of causal inference. Again, such a definition of an informational contentwill satisfy all the desired properties, mentioned earlier. For the case of causal inference,however, a more fine-grained analysis of informational content is possible.Recall that causal rules serve in causal inference simultaneously two informationalroles. One consists in determining causally consistent worlds, while the other in estab-lishing explanatory relations between propositions. Fortunately, these two roles can beneatly separated by decomposing any causal rule into a constraint and an explanation (seeLemma 7.2). This suggests the following definition.Definition 8.4.• The set of constraints A ⇒ f belonging to a causal relation will be called its factualcontent.• The explanatory content of a causal relation is the set of its explanatory rules, namelythe rules A ⇒ B such that A (cid:1) B.Constraints restrict the set of worlds that are admissible (causally consistent) with re-spect to a causal theory. In this sense they play the role of ordinary classical formulas,namely they just express facts about the world. However, they do not explain anything, andA. Bochman / Artificial Intelligence 160 (2004) 105–143133hence they can be seen as devoid of explanatory content. The later is expressed, however,by explanatory causal rules. Such rules are ‘factually trivial’, since they do not impose re-strictions on admissible worlds; their only role consists in determining what explains whatin admissible worlds. Consequently, the factual and explanatory contents are not only dis-joint, but are actually independent of each other. Moreover, the informational content ofcausal theories can be safely represented as a union of a factual and explanatory contents.The interplay of the factual and explanatory contents determines, eventually, the non-monotonic semantics, and it is responsible, in particular, for the nonmonotonic propertiesof the latter. Namely, the nonmonotonicity arises from the fact that the two kinds of contenthave opposite impacts on derivability. Thus, addition of constraints leads, as expected, toreduction of the set of admissible worlds (and hence to increase of factual information).However, the addition of explanatory rules leads, in general, to increase of exact worlds,and hence to decrease of nonmonotonically derived information (cf. Corollary 8.5). But inall cases, one of the effects of growth in informational content is a monotonic reduction ofthe set of non-exact (unexplained) worlds.8.2. Causal nonmonotonic reasoning: between default logic and logic programmingIn this section we will briefly address the question how the causal nonmonotonic rea-soning is related to default logic, on the one hand, and logic programming, on the other.As has been shown already in [27], causal theories can be translated into default logic,but the correspondence is quite restricted. Namely, production rules A ⇒ B are translatableas prerequisite-free default rules : A/B, and then the causal nonmonotonic semantics cor-responds to the set of extensions of the resulting default theory that are worlds. The limitedcharacter of this correspondence is due, of course, to the essential difference in underlyingsemantic interpretations, namely an epistemic interpretation of default rules versus the ob-jective interpretation of causal rules. Still, the existence of such a correspondence allows toexplain why default and causal representations often produce similar results. Nevertheless,the unidirectional character of this correspondence indicates that default logic is a strictlymore general formalism, which means also that causal inference is a more specific formal-ism with a stronger underlying logic, witness reasoning by cases that is valid for causalinference (by the Or postulate), but not for default logic.Though distinct from default logic, causal inference relations have turned out to be in-timately connected with logic programming. Thus, it has been shown in [9] that the causallogic, coupled with the Closed World Assumption (CWA), can be used as an underlyinglogic for logic programming involving negation as failure. Namely, a disjunctive programrule c ← a, not b (where a, b, c are sets of propositional atoms, and not a negation asfailure) can be interpreted as a causal rule ¬b ⇒ ∧a →∨c. In addition, CWA is naturallyinterpretable in causal logic as an additional postulate that all negated atoms are abducibles:Default Negation ¬p ⇒ ¬p, where p is a propositional atom.Then the causal nonmonotonic semantics of the resulting causal theories will corre-spond precisely to the stable semantics of logic programs [15]. Moreover, unlike knownembedding of logic programs into other nonmonotonic formalisms, namely default and au-134A. Bochman / Artificial Intelligence 160 (2004) 105–143toepistemic logics, the causal interpretation of logic programs turns out to be bi-directionalin the sense that any causal theory is reducible to a general logic program. This shows thatthe causal logic provides a more faithful representation of the declarative meaning of logicprograms.Actually, the very possibility of an alternative, causal interpretation of logic programsallows to explain the well-known differences between logic programming and defaultlogic. Thus, normal logic programs (under the stable semantics) can be translated into ei-ther default logic, or modal nonmonotonic logics, but the reverse translation, or reduction,is impossible. Moreover, this translation is not extendable directly to disjunctive programs,and requires a corresponding generalization of default logic to disjunctive default logic(see [16]). The differences have even led to an often expressed view that logic program-ming constitutes a separate formalism for knowledge representation and nonmonotonicreasoning in its own right (see, e.g., [1]). From the point of view of the present study,however, these differences show in effect, that logic programming constitutes a more spe-cific formalism, and hence a formalism with a reacher underlying logic. This logic can beexpressed, however, in the framework of causal inference.9. Determinate theories and completionNow we are going to show that any causal theory is objectively equivalent to a causaltheory of a special kind, called determinate one.A production rule will be called a Horn one, if it has the form A ⇒ l, where l is eithera literal or a falsity constant f.9 A causal theory will be called determinate, if it containsonly Horn rules. Finally, causal theories ∆ and Γ will be called Horn-equivalent, if ⇒∆and ⇒Γ have the same Horn rules.Causaltheories are Horn-equivalent, if they derive the same Horn rules. Now,Lemma 8.1 shows that the exact worlds of a production relation are uniquely determinedby the Horn rules that belong to it. Consequently,Lemma 9.1. Horn-equivalent causal theories are objectively equivalent.The above result implies that the causal nonmonotonic semantics of a causal theory isdetermined ultimately by the Horn rules that are derivable from the theory. This immedi-ately suggests that any causal theory can be transformed into a determinate theory that isobjectively equivalent to it. Such a transformation is provided below.10For a causal theory ∆, let us denote by ∆d the set of all Horn rules of the formfor which ∆ contains a (minimal) set of rules {Ai ⇒ Bi } such thatfollowing result shows that ∆d embodies the ‘determinate content’ of ∆.(cid:1)Ai ⇒ l,Bi (cid:1) l. Then the(cid:1)Lemma 9.2. ∆ is Horn-equivalent to ∆d .9 Note that any constraint is a Horn rule by this definition.10 A similar algorithm has been suggested earlier by Norman McCain (V. Lifschitz, personal communication).A. Bochman / Artificial Intelligence 160 (2004) 105–143135Proof. Note first that any production rule from ∆d is derivable from ∆ by Strengthening,And and Weakening. Assume now that A ⇒∆ l, for some literal l. Then ∆(Th(A)) (cid:1) lby Proposition 2.6. This can hold only if ∆ contains a set of rules Ai ⇒ Bi such thatAi ∈ Th(A), for any i, andAi ⇒ l belongs to ∆d , and thereforeA ⇒∆d l by Strengthening. This shows that ⇒∆d includes all Horn production rules from⇒∆, and consequently ∆ and ∆d are Horn-equivalent. (cid:1)Bi (cid:1) l. But then(cid:1)(cid:1)As a consequence, we obtain that ∆d is a determinate causal theory that is nonmonoton-ically equivalent to ∆.Unfortunately, the above algorithm is neither modular, nor polynomial. Moreover, thecomplexity considerations confirm that this is as it should be, due to the difference in com-plexity between arbitrary and determinate causal theories, established in [17]. Still, in manycases the algorithm gives a convenient recipe for transforming an arbitrary causal theoryinto an objectively equivalent determinate theory. It should be kept in mind, however, thatwe do not have strong equivalence here. The following example illustrates this.Example (Two gears). This is a simplified (atemporal) version of the example due to MarcDenecker that was described in [29]. Two gears are powered by separate motors that canturn them in opposite (i.e., compatible) directions. In addition, when the gears are con-nected, each can also turn the other. Let us assume that this domain is given the followingcausal representation ∆:Connected ⇒ Turning1 ↔ Turning2Motor1 ⇒ Turning1Motor2 ⇒ Turning2,plus the assumptions that (¬)Motor1, (¬)Motor2 and (¬)Connected are abducibles.The causal theory ∆ is not determinate (due to the first rule), but by the above algorithm,it can be reduced to a determinate theory ∆d obtained from ∆ by replacing the first rulewith the following two Horn rules:Connected ∧ Motor1 ⇒ Turning2Connected ∧ Motor2 ⇒ Turning1.∆ and ∆d have, of course, the same causal nonmonotonic semantics, namely the worldswhere both gears are turning, and either both motors are working, or else one of them isworking, and the gears are connected. Let us add, however, a causal rule ¬Turning2 ⇒¬Turning2 to each of these causal theories. Since the added rule is purely explanatory, itcan only extend the set of exact worlds. And indeed, being added to ∆, it creates a newexact world α in which the gears are connected, the two motors are not working, and bothgears are not turning. This is because ¬Turning2 is now self-explanatory, while ¬Turning1is explained by the rule Connected ∧ ¬Turning2 ⇒ ¬Turning1 that is derivable from thefirst rule of ∆ and ¬Turning2 ⇒ ¬Turning2. However, if the latter rule is added to ∆d ,the world α will not be an exact world of the resulting theory. As a result, we can stillnonmonotonically infer from the second theory that both gears are turning.As has been established in [26], for a special kind of determinate theories, the causalnonmonotonic semantics coincides with the classical semantics of their completions. Be-low we will reproduce this result in our framework.136A. Bochman / Artificial Intelligence 160 (2004) 105–143Definition 9.1. A causal theory will be called• locally finite if any propositional atom appears in heads of no more than a finite numberof its causal rules;• definite if it is determinate and locally finite.Any finite causal theory will be locally finite, though not vice versa. Similarly, any finitedeterminate theory will be definite.Given a definite causal theory ∆, we will define its completion, comp(∆), as the set ofall classical formulas of the forms(cid:9)p ↔{A | A ⇒ p ∈ ∆}(cid:9)¬p ↔{A | A ⇒ ¬p ∈ ∆},for any propositional atom p, plus the set {¬A | A ⇒ f ∈ ∆}.Note that if ∆ does not have rules with the head p, then comp(∆) contains the formula(cid:2)p ↔∅, which amounts to ¬p (and similarly for ¬p).The following result shows that the classical models of comp(∆) precisely correspondto exact worlds of ∆. The proof follows readily from Corollary 8.2 (see also Proposition 6in [17]).Proposition 9.3. The causal nonmonotonic semantics of a definite causal theory coincideswith the classical semantics of its completion.Example. (Reiter’s simple solution). As an illustration, we will use the framework of [26]in order to give a toy causal representation of the well-known Reiter’s simple solution tothe frame problem (see [34,35]). Despite its simplicity, the representation contains the mainingredients of causal reasoning in temporal domains.We consider a small causal theory for a single propositional fluent F . The temporalbehavior of F is described using two propositional atoms F0 and F1 saying that F holdsnow and, respectively, in the next moment.+ ⇒ F1CF0 ∧ F1 ⇒ F1F0 ⇒ F0− ⇒ ¬F1C¬F0 ∧ ¬F1 ⇒ ¬F1¬F0 ⇒ ¬F0.The first pair of causal rules describes the factors (actions or natural causes) that cancause F and, respectively, ¬F (C+ and C− can be arbitrary formulas, but they normallydescribe the present situation). Such rules correspond to Reiter’s effect axioms for fluentF , though in our description they are not relativized to particular actions. Second, insteadof Reiter’s explanation closure axioms, we have a pair of inertia axioms. The latter areinstances of explanatory production rules stating that if F holds (does not hold) now, thenit is self-explanatory that it will hold (respectively, not hold) in the next moment. Thelast pair of initial axioms states, in effect, that the truth-value of F0 is an independent(exogenous) parameter.A. Bochman / Artificial Intelligence 160 (2004) 105–143137The above causal theory is clearly definite, and its completion (with respect to F ) is asfollows:F1 ↔ C+ ∨ (F0 ∧ F1)¬F1 ↔ C− ∨ (¬F0 ∧ ¬F1).Now, it can be easily verified that the latter formulas are logically equivalent to thefollowing two:¬(C+ ∧ C−)F1 ↔ C+ ∨ (F0 ∧ ¬C−).The above formulas provide, in effect, an abstract description of Reiter’s simple solu-tion: the first formula corresponds to his consistency condition, while the second one—tothe successor state axiom for F , since it describes the conditions for F to hold in the nextstate. Note, however, that in our representation the above formulas are basically conse-quences of the effect axioms and the general principles of the nonmonotonic semantics,while in Reiter’s system we need each time to add appropriate explanation closure ax-ioms.1110. Beyond causal inferenceThough causal inference relations have turned out to be maximal production relationsthat are adequate for the causal nonmonotonic semantics, some stronger production rela-tions are also useful for the general study of production and causal inference.10.1. Quasi-classicalityWe consider first production relations that have an especially simple semantic interpre-tation.Definition 10.1. A causal inference relation will be called quasi-classical, if it satisfies therule(Weak Contraposition) If ¬A ⇒ f, then t ⇒ A.Weak Contraposition is equivalent to the following special case of the Deduction rule:(Weak Deduction) If A ⇒ B, then t ⇒ (A→B).The latter condition says, in effect, that material implications corresponding to produc-tion rules are universally valid propositions in causal inference.11 John McCarthy once called this procedure ‘doing nonmonotonic reasoning by hand’.138A. Bochman / Artificial Intelligence 160 (2004) 105–143A semantic interpretation of quasi-classical production relations can be obtained byrequiring full reflexivity of the accessibility relation.Theorem 10.1. A production relation is quasi-classical if and only if it is determined by areflexive possible worlds model.Proof. It is easily verified that the causal relation determined by a reflexive possible worldsmodel satisfies Weak Contraposition. In the other direction, it is sufficient to show that thecanonical semantics for causal productions, described in the proof of Theorem 7.4 is fullyreflexive in our case. Clearly, in evaluating productions, we can restrict the set of worldsto worlds that occur either in the domain or in the range of the accessibility relation. Then,since the canonical relation Rc constructed in Theorem 7.4 was quasi-reflexive, we haveto show only that if αRcβ, then βRcβ. So, let us assume that C(α) ⊆ α, β and that A ⇒ Bholds. Then A ∧ ¬B ⇒ f, and hence t ⇒ A→B by Weak Contraposition. Consequently,A→B ∈ C(α), and therefore A→B ∈ β. The latter means that β is closed with respect tothe production rules, that is C(β) ⊆ β. Consequently βRcβ, as required. (cid:1)A constructive description of the least quasi-classical production relation containing agiven causal theory is given in the next lemma.Lemma 10.2. If ⇒qtheory ∆, thenu ⇒q∆ A iff A ∈ Th(−→∆ ∪ ∆(α)), for any world α ⊇ u ∪−→∆.∆ is the least quasi-classical production relation containing a causalProof. It can be directly verified that the description on the right side of the above equiv-alence determines a quasi-classical causal relation containing ∆. Since ⇒q∆ is a leastsuch relation, this gives as the direction from left to right. Assume now that u (cid:1)q∆ A.Then there exists a world α that is a theory of ⇒q∆ and such that u ⊆ α and A /∈ Cq∆(α).a→A belongs toSuppose that A ∈ Th(a→A) (see Proposition 7.5), and consequentlyTh(∆(α)). The latter means that α ⇒c(cid:1)α ⇒qa due to quasi-classicality, and consequently−→α ⇒q∆ ∪ ∆(α)), which gives us the directionfrom right to left. (cid:1)−→∆ ∪ ∆(α)). Then there exists a ⊆∆ (a→A). But we have also α ⇒q∆ (∆∆ A—a contradiction. Consequently, A /∈ Th(−→∆ such that(cid:1)(cid:1)(cid:1)The above description shows that derivability in quasi-classical production relationsamounts to causal derivability which is based, however, on a classical consequence relationthat includes−→∆ as the set of axioms. As a consequence, we obtainCorollary 10.3. A world α is exact for ⇒q∆ iff α = Th(−→∆ ∪ ∆(α)).Recall that causally consistent worlds are precisely the worlds that satisfyingly, the above description says that α is an exact world of ⇒qcausally consistent world containing ∆(α).−→∆. Accord-∆ if and only if it is the onlyDespite apparent plausibility, the following example shows, however, that quasi-classical inference produce seemingly unexpected results.A. Bochman / Artificial Intelligence 160 (2004) 105–143139Example. A causal theory ∆ = {p ⇒ q, ¬q ⇒ ¬q} has an empty causal semantics. How-ever, p ⇒ q implies t ⇒ (p → q) by Weak Deduction, and then ¬q ⇒ (p → q) byStrengthening. Coupled with ¬q ⇒ ¬q, this gives us ¬q ⇒ ¬p, namely the contrapo-sition of p ⇒ q. As a result, ⇒q∆ already has an exact world, namely {¬p, ¬q}.The above example shows, of course, that quasi-classical inference can change thecausal nonmonotonic semantics. It still does not show, however, that such an inference canproduce downright wrong results. An additional argument in favor of quasi-classical infer-ence can be found in the fact, shown in [10], that such production inference correspondsprecisely to abductive reasoning based on classical consequence relations (see below). Ac-cordingly, the role of quasi-classical inference seems worth further study.Finally, note that a natural further strengthening of Weak Contraposition is full Contra-position:(Contraposition) If A ⇒ B, then ¬B ⇒ ¬A.As can be verified, Contraposition is valid for all symmetric accessibility relations.Note, however, that even this property still does not transform production relations into(reflexive) consequence relations, described in the next section.10.2. Reflexivity and consequence relationsA distinctive feature of production relations as compared with ordinary consequencerelations is the absence of the Reflexivity postulate:Reflexivity A ⇒ A.As can be verified, any supraclassical consequence relation satisfies already all the pos-tulates of regular production relations. Moreover, Reflexivity is then obviously the onlypostulate that need to be added to the postulates of a regular production relation in order toobtain a supraclassical consequence relation:Lemma 10.4. A production relation is a supraclassical consequence relation if and only ifit is regular and satisfies Reflexivity.Actually, there is a number of classical inference rules that imply Reflexivity in thecontext of production relations, such asDeduction If A ∧ B ⇒ C, then A ⇒ B→C;Import If A ⇒ B→C, then A ∧ B ⇒ C;Antecedence If A ⇒ B, then A ⇒ A ∧ B.Indeed, t ⇒ A ∨ ¬A implies A ⇒ A by Import, A ⇒ t implies A ⇒ A by Antecedence,and A ∧ ¬A ⇒ f implies A ⇒ A by Deduction.140A. Bochman / Artificial Intelligence 160 (2004) 105–143Clearly, any classical consequence relation will already be a kind of a causal inferencerelation. In addition, the above observations implyCorollary 10.5. A production relation is a classical consequence relation if and only if itis regular and satisfies Deduction.A simple and uniform way of transforming production relations into consequence rela-tions has been suggested in [25]. Namely, for any production relation, we can consider thefollowing relation:A ⇒i B ≡ A ⇒ (A→B).Then we haveTheorem 10.6. If ⇒ is a production relation, then ⇒i is a least reflexive production rela-tion containing ⇒. Moreover,• If ⇒ is regular, then ⇒i is a supraclassical consequence relation;• If ⇒ is quasi-classical, then ⇒i is a classical consequence relation.Proof. It is easy to verify that ⇒i is a reflexive production relation. Let ⇒1 be any re-flexive production relation that includes ⇒, and A ⇒i B. Then A ⇒ A→B, and henceA ⇒1 (A→B). But A ⇒1 A, and hence A ⇒1 B by And and Weakening. Thus, ⇒i isincluded in ⇒1, and therefore it is a least reflexive production relation containing ⇒.Assume that ⇒ satisfies Cut, and we have A ⇒i B and A ∧ B ⇒i C. Then A ⇒(A→B) and A ⇒ (A ∧ B)→C by Cut, and hence A ⇒ (A→C) by And and Weaken-ing. Hence, ⇒i will also satisfy Cut. As a result, if ⇒ is regular, then ⇒i will satisfyalready all the rules for supraclassical consequence relations.Finally, assume that ⇒ is quasi-classical, and we have A ∧ B ⇒i C. Then A ∧ B ⇒(A ∧ B)→C. Consequently, t ⇒ (A ∧ B)→C by Weak Deduction, and therefore A ⇒(A∧B)→C, that is, A ⇒i (B→C). This shows that Deduction holds for ⇒i , and thereforethe latter is a classical consequence relation. (cid:1)Note that the above ‘reflexivization’ construction does not preserve the Or rule. In otherwords, even for causal inference relations, ⇒i may be only supra-classical. That is whywe needed a stronger condition of quasi-classicality in order to secure that the resultingconsequence relation will be fully classical. And indeed, it has been shown in [10] thatabductive reasoning with respect to classical consequence relations corresponds already toquasi-classical production relations.11. Conclusions and perspectivesSumming up the main results of the paper, we can argue that production and causalinference constitute a natural and powerful formalism for nonmonotonic reasoning. In par-ticular, the general nonmonotonic semantics of production inference relations allows toA. Bochman / Artificial Intelligence 160 (2004) 105–143141give a syntax-independent representation of abductive reasoning, while the causal non-monotonic semantics and causal inference provide an exact description of nonmonotoniccausal theories from [26]. If we add to this also the correspondence between causal reason-ing and logic programming, described in [9], we can safely conclude that, already at thisstage, production inference covers a significant part of general nonmonotonic reasoning.Turning to applications, the causal nonmonotonic reasoning has already proved its use-fulness in representing action domains (see [17]) and planning theory [28]. In addition, itis natural to expect that production inference can be used, for example, in formalizing thenumerous application areas of abductive reasoning, such as assumption-based truth main-tenance (ATMS), update theory [11], or a theory of diagnosis. In fact, a causal approach todiagnosis has already been suggested in the literature—see, e.g., [13,19,32]. As was rightlyobserved in [32], however, a proper theoretical development of this approach requires anadequate underlying theory of causal reasoning, and we expect that the causal inferenceconstitutes precisely such a theory.In addition to the above applications, there is still a number of internal problems thatneed to be resolved in order to fully realize the opportunities created by the causal approachto nonmonotonic reasoning.As has been shown in [22], causal reasoning copes fairly well McCarthy’s principleof elaboration tolerance. Still, the nonmonotonic semantics for causal theories is based onthe principle of explanation closure, or universal causation, which is obviously very strong.The principle implies, for example, that if we have no causal rules for a certain proposi-tion, it should be false in all intended (explainable) models. This makes causal theoriesextremely sensitive to the underlying language in which they are formulated, and createsthereby an apparent conflict with elaboration tolerance. Of course, we can always exemptparticular propositions from the burden of explanation (by making them abducibles). More-over, we can even syntactically restrict the principle of universal causation to a particularsubset of explainable propositions (as has been suggested in [21]). However, this solu-tion is purely syntactical and hence retains language dependence. A proper and systematictrade-off between the principles of explanation closure and elaboration tolerance still hasto be found.More subtle, yet perceptible difficulties arise also in representing indeterminate causa-tion in causal theories (see [8]). Thus, we have seen that any causal theory is reducibleto a determinate theory with respect to the causal nonmonotonic semantics. Consequently,non-Horn causal rules are informative nonmonotonically only to the extent that they implysome Horn rules. This does not mean, however, that we cannot represent indeterminateinformation in causal theories. Actually, one of the main contributions of [26] consisted inshowing how we can do this in common cases (see also [24]). Still, there is yet no system-atic understanding whether all kinds of indeterminate information are representable in thisway by Horn causal rules.A more general problem concerns the role and place of causal reasoning in generalnonmonotonic reasoning. Though causal reasoning covers many areas of nonmonotonicreasoning, it does not cover them all. Thus, it does not seem suitable for solving the quali-fication problem in representing actions, due to the fact that causal rules are monotonic andfreely admit strengthening of their antecedents. Speaking generally, causal nonmonotonicreasoning still belongs to the explanatory approach to nonmonotonic reasoning, and hence142A. Bochman / Artificial Intelligence 160 (2004) 105–143it does not cover the kind of nonmonotonicity described by the preferential approach (seeIntroduction). Nevertheless, the causal reasoning creates a new opportunity here. Namely,both preferential and causal reasoning amount, in effect, to different reasoning systemsabout conditionals. This naturally suggests that the two kinds of nonmonotonic reasoningwith conditionals could be combined into a single formalism, a grand uniform theory ofnonmonotonic reasoning. Actually this idea is not new; it has been suggested and studiedmore than ten years ago in [14]. It remains to be seen whether the suggested theory ofcausal inference can contribute to viability of such a general theory.AcknowledgementsI would like to express my deep thanks to Vladimir Lifschitz, David Makinson, Leen-dert van der Torre, and especially to Hudson Turner for their comments and suggestions.Thanks also to the referees for instructive comments, despite occasional “philosophical”disagreements.References[1] C. Baral, M. Gelfond, Logic programming and knowledge representation, J. Logic Programming 19, 20(1994) 73–148.[2] N.D. Belnap Jr., A useful four-valued logic, in: M. Dunn, G. Epstein (Eds.), Modern Uses of Multiple-ValuedLogic, D. Reidel, Dordrecht, 1977, pp. 8–41.[3] A. Bochman, Biconsequence relations: a four-valued formalism of reasoning with inconsistency and incom-pleteness, Notre Dame J. Formal Logic 39 (1) (1998) 47–73.[4] A. Bochman, A logical foundation for logic programming, I and II, J. Logic Programming 35 (1998) 151–194.[5] A. Bochman, On the relation between default and modal nonmonotonic reasoning, Artificial Intelligence 101(1998) 1–34.[6] A. Bochman, A Logical Theory of Nonomonotonic Inference and Belief Change, Springer, Berlin, 2001.[7] A. Bochman, A logic for causal reasoning, in: G. Gottlob, T. Walsh (Eds.), Proceedings Internat. JointConference on Artificial Intelligence, IJCAI’03, Acapulco, Mexico, Morgan Kaufmann, San Mateo, CA,2003, pp. 141–146.[8] A. Bochman, On disjunctive causal inference and indeterminism, in: G. Brewka, P. Peppas (Eds.), Proc.Workshop on Nonmonotonic Reasoning, Action and Change (NRAC’03), 2003, pp. 45–50.[9] A. Bochman, A causal logic of logic programming, in: D. Dubois, C. Welty, M.-A. Williams (Eds.), Proc.Ninth Internat. Conf. on Principles of Knowledge Representation and Reasoning, KR2004, Whistler, BC,AAAI Press, 2004, pp. 427–437.[10] A. Bochman, Production inference, nonmonotonicity, and abduction, in: Proc. Eight Internat. Symp. onArtificial Intelligence and Mathematics, Fort Lauderdale, FL, 2004.[11] C. Boutilier, Abduction to plausible causes: an event-based model of belief update, Artificial Intelligence 83(1996) 143–166.[12] L. Console, D. Theseider Dupre, P. Torasso, On the relationship between abduction and deduction, J. LogicComput. 1 (1991) 661–690.[13] A. Darwiche, Model-based diagnosis using causal networks, in: Proceedings Internat. Joint Conf. on Artifi-cial Intelligence, IJCAI’95, Montreal, Quebec, 1995, pp. 211–217.[14] H. Geffner, Default Reasoning. Causal and Conditional Theories, MIT Press, Cambridge, MA, 1992.[15] M. Gelfond, V. Lifschitz, The stable model semantics for logic programming, in: R. Kowalski, K. Bowen(Eds.), Proc. 5th International Conf./Symp. on Logic Programming, MIT Press, Cambridge, MA, 1988,pp. 1070–1080.A. Bochman / Artificial Intelligence 160 (2004) 105–143143[16] M. Gelfond, V. Lifschitz, H. Przymusi´nska, M. Truszczy´nski, Disjunctive defaults, in: Proc. Second Internat.Conf. on Principles of Knowledge Representation and Reasoning, KR’91, Cambridge, MA, 1991, pp. 230–237.[17] E. Giunchiglia, J. Lee, V. Lifschitz, N. McCain, H. Turner, Nonmonotonic causal theories, Artificial Intelli-gence 153 (2004) 49–104.[18] K. Konolige, Abduction versus closure in causal theories, Artificial Intelligence 53 (1992) 255–272.[19] K. Konolige, Using default and causal reasoning in diagnosis, Ann. Math. Artificial Intelligence 11 (1994)97–135.[20] S. Kraus, D. Lehmann, M. Magidor, Nonmonotonic reasoning, preferential models and cumulative logics,Artificial Intelligence 44 (1990) 167–207.[21] V. Lifschitz, On the logic of causal explanation, Artificial Intelligence 96 (1997) 451–465.[22] V. Lifschitz, Missionaries and cannibals in the causal calculator, in: Proc. 7th Internat. Conference on Prin-ciples of Knowledge Representation and Reasoning, KR’00, Breckenridge, CO, Morgan Kaufmann, SanMateo, CA, 2000, pp. 85–96.[23] F. Lin, Embracing causality in specifying the indirect effects of actions, in: Proceedings IJCAI-95, Montreal,Quebec, Morgan Kaufmann, San Mateo, CA, 1995, pp. 1985–1991.[24] F. Lin, Embracing causality in specifying the indeterminate effects of actions, in: Proceedings AAAI-96,Portland, OR, 1996, pp. 670–676.[25] D. Makinson, L. Van der Torre, Input/Output logics, J. Philos. Logic 29 (2000) 383–408.[26] N. McCain, H. Turner, Causal theories of action and change, in: Proceedings AAAI-97, Providence, RI,1997, pp. 460–465.[27] N. McCain, H. Turner, On relating causal theories to other formalisms, Unpublished manuscript, 1997.[28] N. McCain, H. Turner, Satisfiability planning with causal theories, in: Proc. Internat. Conf. on Principles ofKnowledge Representation and Reasoning, KR-98, Trento, Italy, 1998, pp. 212–223.[29] N. McCain, Causality in commonsense reasoning about actions, PhD thesis, The University of Texas atAustin, 1997.[30] J. McCarthy, P. Hayes, Some philosophical problems from the standpoint of artificial intelligence, in: B.Meltzer, D. Michie (Eds.), Machine Intelligence, Edinburg University Press, Edinburg, 1969, pp. 463–502.[31] J. Pearl, Embracing causality in formal reasoning, Artificial Intelligence 35 (1988) 259–271.[32] D. Poole, Representing diagnosis knowledge, Ann. Math. Artificial Intelligence 11 (1994) 33–50.[33] R. Reiter, A logic for default reasoning, Artificial Intelligence 13 (1980) 81–132.[34] R. Reiter, The frame problem in the situation calculus: a simple solution (sometimes) and a completenessresult for goal regression, in: V. Lifschitz (Ed.), Artificial Intelligence and Mathematical Theory of Compu-tation: Papers in Honor of John McCarthy, Academic Press, San Diego, CA, 1991, pp. 359–380.[35] R. Reiter, Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems,MIT Press, Cambridge, MA, 2001.[36] M. Thielscher, Ramification and causality, Artificial Intelligence 89 (1997) 317–364.[37] H. Turner, A logic of universal causation, Artificial Intelligence 113 (1999) 87–123.[38] D. Zhang, N. Foo, EPDL: A logic for causal reasoning, in: Proceedings IJCAI’01, Seattle, WA, MorganKaufmann, San Mateo, CA, 2001, pp. 131–136.