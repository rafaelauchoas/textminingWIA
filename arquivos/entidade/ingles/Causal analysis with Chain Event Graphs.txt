Artificial Intelligence 174 (2010) 889–909Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCausal analysis with Chain Event GraphsPeter Thwaites a,∗, Jim Q. Smith a, Eva Riccomagno ba Department of Statistics, University of Warwick, Coventry, CV4 7AL, United Kingdomb Department of Mathematics, Università degli Studi di Genova, Via Dodecaneso 35, 16146 Genova, Italya r t i c l ei n f oa b s t r a c tAs the Chain Event Graph (CEG) has a topology which represents sets of conditionalindependence statements,it becomes especially useful when problems lie naturallyin a discrete asymmetric non-product space domain, or when much context-specificinformation is present. In this paper we show that it can also be a powerful represen-tational tool for a wide variety of causal hypotheses in such domains. Furthermore, wedemonstrate that, as with Causal Bayesian Networks (CBNs), the identifiability of the effectsof causal manipulations when observations of the system are incomplete can be verifiedsimply by reference to the topology of the CEG. We close the paper with a proof of a BackDoor Theorem for CEGs, analogous to Pearl’s Back Door Theorem for CBNs.© 2010 Elsevier B.V. All rights reserved.Article history:Received 16 January 2009Received in revised form 13 May 2010Accepted 13 May 2010Available online 20 May 2010Keywords:Back Door TheoremBayesian NetworkCausal manipulationChain Event GraphConditional independenceEvent treeGraphical model1. IntroductionMuch recent work in the field of causality has focused on how cause relates to control, and the analysis of controlledmodels. Here, with the advocates of this approach we assume the existence of a background idle system which is thensubjected to some sort of intervention or manipulation.The Bayesian Network (BN) is the most commonly used graphical tool for representing complex dependency relation-ships. Interpreting the directionality of the edges of the BN as causal leads to the Causal Bayesian Network (CBN), whichuses a non-parametric representation based on structural equation models [12,19,21,30]. CBNs provide a framework forexpressing assertions about what might happen when the system under study is externally manipulated and some of itsvariables are assigned certain values.BNs and CBNs are ideal for problems which admit a natural product space structure. However many processes do nothave this — they are asymmetric in the sense that measurement variables may have different collections of possible out-comes given different vectors of values for sets of ancestral variables. For a variety of examples see [4,1,10,16,2,17,23].Context-specific variants of BNs exist [2,26,23,18], usually with tree-structured conditional probability tables annexed to thevertices of the BN to allow for the analysis of context-specific independence properties. Although these graphs allow theanalyst a greater flexibility than unmodified BNs, they are still inefficient representations of processes (such as treatmentregimes) whose unfolding depends on the state of the system at any particular point and the values of specific covariates atthat point. Similarly, they are not ideal representations of problems where no outcomes of certain variables could logicallyoccur given some vectors of values of ancestral variables.* Corresponding author.E-mail address: Peter.Thwaites@warwick.ac.uk (P. Thwaites).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.05.004890P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909There have been major advances in CBN theory in the last decade (see [6,14,20,7,35,34], and [21] for a good review ofthese). The basic Do intervention of Pearl [19] has been extended to functional manipulations (Do X = g(Z )), and stochasticmanipulations which assign a new probability distribution to the state space of the manipulated variable. Nonetheless, atthe most primitive level a manipulation of a BN still corresponds to the setting of certain measurement variables to specificvalues, possibly following some rule or policy. However, whereas the effects of a cause can be reasonably represented by arandom variable, at times the specification of a cause as the value of a random variable can be artificial. Causes are morenaturally represented as conditioning events, and such conditioning is not elegantly expressed in the BN. An analogous caseis made by Dawid [5] who argues that causes are decisions and not decision rules.Although topologically complex, event trees (the elicitation of which often provides the first stage in the developmentof a model) explicitly acknowledge structural asymmetries — context-specific and sample space information is embeddedin the topology of the tree. Their semantics are also often closer to many verbal descriptions of the world, especially whenthose descriptions revolve around how things happen rather than how the world appears. Event trees however, cannot bereadily interrogated for the conditional independence structure of a model.Trees also have their advocates in the study of causality [27,30,25]. In the related field of decision analysis, French andInsua [11] argue that the advantages of influence diagrams over decision trees are illusory, and point out that asymmetricproblems in which a particular choice of action at a decision node makes available different choices of action at subsequent decisionnodes than those available after an alternative choice are the rule rather than the exception. Using trees we can also choosethe level of detail we include in our representation, and this can be dependent on what we intend to do to the system.We can incorporate context specific information that is informative about various causal hypotheses (see for example [8]).This is particularly useful in models of biological regulatory mechanisms, which typically contain many noisy and and orgates [28].In [28] we introduced an alternative graphical model — the Chain Event Graph (CEG), constructed from an event treetogether with a set of exchangeability assumptions. It can be seen as a generalisation of a probability graph [3,27], andtypically has many fewer nodes than the original tree. The CEG retains those characteristics of the event tree which allowfor the representation of asymmetric problems; but they are also more flexible and useful, since their nodes representintrinsic events in the problem and their edges dependencies between them. They express topologically all the conditionalindependence structure associated with a problem (this is not bolted on as with context-specific BNs), and also any samplespace information generated by the asymmetry of the problem. So in a non-causal context, CEGs provide a more expressive(if somewhat more complicated) topological framework for expressing collections of conditional independence statementsthan the discrete BN.We present here an extension of CEG models which provides a framework for causal reasoning. We believe this extensionto be as transparent and compelling as the extension from BNs to CBNs. In Section 2 we give a brief definition of the CEGand a description of how to read conditional independence properties from it. This section also contains an example of howan asymmetric problem can be depicted using such a graph. Section 3 introduces the manipulation of these graphs, and thistheory is developed in Section 4 where we address the identification of the effects of manipulations. Section 5 introduces aBack Door Theorem for CEGs, a generalisation of Pearl’s Back Door Theorem for BNs [21].2. Chain Event Graphs2.1. DefinitionWe provide here a brief definition and description of the CEG. A more comprehensive definition can be found in [28].The CEG is a function of an event tree [27], and we begin this section with a brief description of this graph. An event treeT is a directed, rooted tree, with vertex set V (T ) and edge set E(T ). The non-leaf vertices are called situations and the setof situations S(T ). The root-to-leaf paths {λ} of T form the atoms of the event space (called the path σ -algebra of T ), andlabel the different possible unfoldings of the described process. Events measurable with respect to this space are unions ofthese atoms.Each situation v serves as an index of a random variable X(v) whose values describe the next stage of possible de-velopments of the unfolding process. The state space X(v) of X(v) can be identified both with the set of directed edges(cid:3) ∈ V (T ) of these edges. For each X(v) (v ∈ S(T ))e(v, vwe let(cid:3)) ∈ E(T ) emanating from v in T and the set of end-nodes vΠ(v) ≡(cid:3)(cid:3)(cid:2)π(cid:4)(cid:4) v(cid:5) (cid:4)(cid:4) vv(cid:3) | v) ≡ P ( X(v) = v(cid:6)(cid:3) ∈ X(v)(cid:3)) are called the primitive probabilities of the tree; andwhere π (vΠ(T ) ≡(cid:2)(cid:6)Π(v)v∈S(T )A full specification of the probability model is given by (T , Π(T )).We extend Shafer’s definition of an event tree by the introduction of three further properties — coloured edges, stagesand positions.P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909891Definition 1. The stages, colouring and positions of an event tree are defined as follows:1. Two situations v 1 and v 2 are in the same stage u if X(v 1) and X(v 2) have the same distribution under some bijectionψ between their sample spaces. We label the set of stages of the tree T by L(T ).2. For v 1, v 2 ∈ u (for some stage u), the edges e(v 1, v 1(cid:3)) and e(v 2, v 2(cid:3)) have the same colour if e(v 1, v 1(cid:3)) maps to e(v 2, v 2(cid:3))under this bijection ψ , and π (v 2(cid:3) | v 2) = π (v 1(cid:3) | v 1).3. Two situations v 1 and v 2 are in the same position w if for each subpath emanating from v 1, the ordered sequence ofcolours is the same as that for some subpath emanating from v 2. We label the set of positions of the tree T by K (T ).So two situations are in the same stage when the immediate future evolution from both situations is governed by thesame probability law. Two situations are in the same position when the entire future evolution from both situations isgoverned by the same probability law.Definition 2. The Chain Event Graph C (a function of a tree T ) is the coloured mixed graph with vertex set V (C), directededge set Ed(C) and undirected edge set E u(C) defined by:1. V (C) ≡ K (T ) ∪ {w∞}.2. (a) For w, w(cid:3) ∈ V (C) \ {w∞}, there exists a directed edge e(w, w(cid:3)) ∈ Ed(C) iff there are situations v, v(cid:3) ∈ S(T ) suchthat v ∈ w ∈ K (T ), v(cid:3) ∈ w(cid:3) ∈ K (T ) and there is an edge from v to v(cid:3)in E(T ).(b) For w ∈ V (C) \ {w∞}, there exists a directed edge e(w, w∞) ∈ Ed(C) iff there is a situation v ∈ S(T ) and a leaf-node(cid:3)vof T such that v ∈ w ∈ K (T ) and there is an edge from v to vin E(T ).(cid:3)3. For w 1, w 2 ∈ V (C), there exists an undirected edge e(w 1, w 2) ∈ E u(C) iff there are situations v 1, v 2 ∈ S(T ) such thatv 1 ∈ w 1 ∈ K (T ), v 2 ∈ w 2 ∈ K (T ) but v 1, v 2 are members of the same stage u for some u ∈ L(T ). We say that w 1 andw 2 are in the same stage u, and label the set of stages of C by L(C).(cid:3)(cid:3) ∈ K (T ) and there is an edge from v to vin E(T ), then the edge e(w, w4. If v ∈ w ∈ K (T ), v(cid:3)) ∈ Ed(C) has the(cid:3) ∈ wsame colour as the edge e(v, v(cid:3)).There is a one-to-one correspondence between the root-to-leaf paths in T and the root-to-sink paths in C . Each atom ofT becomes a path λ(w 0, w∞) in C , and these paths form the atoms of the σ -algebra of the CEG. Events in C are unionsof w 0 → w∞ paths. We write w ≺ won a w 0 → w∞ path. We call w a(cid:3)) ∈ Ed(C). A collection W of positions w ∈ V (C) is called a fine cut of C if allif there exists an edge e(w, wparent of ww 0 → w∞ paths in C pass through exactly one w ∈ W .when the position w precedes the position w(cid:3)(cid:3)(cid:3)When the set of stages L(T ) of an event tree is identical to the set of positions K (T ), we call the resultant CEG C simple.Simple CEGs have no undirected edges and since the colouring is therefore redundant, they can be treated as directedacyclic graphs. An example of a simple CEG can be found in [33].Each stage u in our CEG C serves as an index of a random variable X(u) whose values describe the next stage ofpossible developments of the unfolding process. The state space X(u) of X(u) can be identified with the set of directededges e(w, w(cid:3)) ∈ Ed(C) emanating from any w ∈ u. For each X(u) we let(cid:6)(cid:2)(cid:2)(cid:3)Π(u) ≡(cid:3)eπ(cid:3)(cid:5) (cid:4)(cid:4) w(cid:5) (cid:4)(cid:4) w ∈ uw, wand Π(C) ≡(cid:6)Π(u)u∈L(C)A full specification of the probability model is given by (C, Π(C)).2.2. Conditional independenceThe conditional independence properties of a model can be read rapidly from the topology of a CEG-representation ofthe model.For a stage u ∈ L(C), let the event which is the union of all w 0 → w∞ paths passing through some w ∈ u be labelledΛ(u), and let Z (u) be a variable whose state space Z(u) can be identified with the set of w 0 → w ∈ u subpaths. Then asshown in [28] we have thatX(u) (cid:10) Z (u) | Λ(u)which can be read as — X(u) is independent of any variable defined upstream of u, given the event Λ(u).So, if we know that a unit has reached some stage u, then we do not need to know how our unit reached u (i.e. alongwhich w 0 → w ∈ u subpath) in order to predict how the process is going to unfold in the immediate future (i.e. alongwhich edge leaving w ∈ u our unit is going to proceed). In a BN the analogous result is that we need only the vector ofvalues taken by a variable’s parents in order to predict the value taken by that variable.For a position w ∈ V (C), let the event which is the union of all w 0 → w → w∞ paths be labelled Λ(w), let Y (w) bea variable whose state space Y(w) can be identified with the set of w → w∞ subpaths, and let Z (w) be a variable whosestate space Z(w) can be identified with the set of w 0 → w subpaths. Then (from [28]) we have that892P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909Y (w) (cid:10) Z (w) | Λ(w)which can be read as — variables defined downstream of w are independent of variables defined upstream, given the event Λ(w).So, if we know that a unit has reached some position w, then we do not need to know how our unit reached w in orderto predict how the process is going to behave during its complete future unfolding (i.e. along which subpath emanatingfrom w our unit is going to pass). In a BN the analogous result is that in order to predict the vector of values taken by aset of variables X, we need to know the vector of values of the set pa(X) \ X.If a model can be depicted by a BN then in our CEG of this model we can combine these position and stage-basedexpressions to give us exactly the same set of conditional independence statements that we could deduce from the BN(see [28]). However, as noted in Section 1, in many applications our processes are highly asymmetric, and model elicitationproduces asymmetric event trees with event spaces not admitting a natural product space structure. In such cases a CEG-depiction of the problem embeds context-specific conditional independence properties within the topology of the graph(which is not the case with BNs), and allows the analyst to deduce other context-specific properties that might not beapparent before the elicitation process is undertaken. The examples below illustrate these points.We believe that the Markov property will prove to be complete with respect to the class of independence propertiespresented here and in [31,28], but this is a topic for a future paper.2.3. An exampleThis section contains an example of a model with the type of asymmetric structure described above. For simplicity theproblem variables in this example are all binary and in the form of indicators — something happens or it doesn’t.Example 2.1. The police hold a suspect S whom they believe threw a brick through a shop window and stole a quantity ofmoney. They wish to bring S to court, but there may be reasons for them not proceeding (such as the lack of availabilityof a judge; police-force policy on the amount of money needing to be stolen before they are prepared to pay for forensictesting, or take suspects to court etc.). Whether they proceed or not can be thought of as outcomes of an indicator X1.It is uncertain that the suspect was present at the scene when the money was stolen (indicator X2), that he was theindividual who threw the brick and stole the money (indicator X3), that the forensic service will find glass matching thewindow glass on the clothing of S (indicator X4), that a witness W will identify S (indicator X5), and whether S will beconvicted or released (the effect indicator of interest X6).We could construct our event tree and hence our CEG in temporal order so that edges representing the outcomes ofX2 and X3 preceded those associated with X1. However, if we suppose that we are constructing our tree through elicitinginformation from members of the police force then X1 is the first indicator of interest. In this our method is similar to thatused in the construction of decision trees in decision analysis [29].Unless S is identified by the witness W , then S will not be convicted. The glass match is believed only to depend onwhether S threw the brick; and the quality of the witness identification is believed to depend only on whether S was atthe scene of the crime or not. This is sufficient information for us to construct a CEG for the problem. Our CEG is given inFig. 1, where for simplicity only a subset of the edges in Ed(C) have been coloured.As the reasons which might lead to the police not proceeding are not related to their beliefs about S’s presence at thecrime scene etc., we can see that the probabilities associated with edges labelled present, not present, stole money, did notsteal money are unaffected by whether they succeed edges labelled proceed or not proceed. Hence the positions w 1 and w 2in Fig. 1 are in the same stage (and so connected by an undirected edge), as are the positions w 3 and w 4. The positionw 3 represents the history (proceed, present). S could only have thrown the brick if he was present at the scene, so edgeslabelled present are succeeded by edges labelled stole money, did not, but edges labelled not present are not.If the police do not proceed, then forensic evidence is not collected, and as S is not taken to court, W will not be askedto testify. Hence there are no edges labelled glass match, no match, identifies S or does not on w 0 → w∞ paths starting withthe edge not proceed.The success of the forensic test being dependent only on whether or not S threw the brick tells us that the positions w 6and w 7 are in the same stage (and hence connected by an undirected edge). The quality of identification being dependentonly on whether S was at the crime scene or not tells us that the positions w 8 and w 9 are in the same stage, and that thepositions w 10 and w 11 are in the same stage.If W does not identify S (position w 13), then the probability of conviction is zero, and there is only one edgee(w 13, w∞). If W does identify S, then the probability of conviction depends on whether the forensic test was successful(position w 12) or not (position w 14). This last is not explicit in what the police have told us, but is apparent from the factthat the police would not pay for the forensic test if it was not going to be any use to them in the case.The detailing above of the possible developments of the case amounts to a description of the conditional independencestructure of the problem, and clearly most of the information provided is context-specific. Fig. 1 illustrates the fact that weare explicitly using the topology of the CEG to express the resulting asymmetric dependency structure.We can of course represent this problem using a BN by adding dummy outcomes to the sets of possible outcomes ofvariables X3, X4 and X5, and imposing a product space structure onto the problem. The BN would have to be supplementedby context-specific conditional independence information, but there are methods for doing this [2,23].P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909893Fig. 1. CEG for Example 2.1.Fig. 2. Three possible BNs for Example 2.1.The problem with such an approach is that our BN will then be ill-defined. If we add a third possible outcome to thepairs of outcomes already present for X3, X4, X5 (signifying that the conditions for Xi taking either of its current valueshave not been met), and add edges representing these outcomes to the subpaths leaving w 2 and w 4 and terminating in w 13,then we can use the resultant CEG to establish the following conditional independence properties involving the variable X5:X5 (cid:10) (X3, X4) | (X1, X2)X5 (cid:10) (X1, X3) | (X2, X4)X5 (cid:10) (X1, X2) | (X3, X4)(1)(2)(3)Coupling each of these in turn with the properties relating to X1, X2, X3, X4 and X6, we can draw three different BNs(shown in Fig. 2), but there is no single BN for this problem which depicts all three properties. We could choose one of theBNs in Fig. 2 and supplement it with context-specific information, but this is not ideal.Now we have already noted that our CEG could be drawn in a different order, so the CEG-representation of a problemis also not unique. But the difference here is that the conditional independence structure of a problem is encoded in thetopology of the CEG, and can easily be read from the graph if it is constructed in an order wherein problem variablesalways appear before their descendants. Furthermore, if the CEG is constructed in such an order, then by supplementingthe model with some additional assumptions discussed below, it has a causal interpretation. We are thus able to extend the894P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909CEG’s semantics to represent various causal hypotheses in a way analogous to that by which the semantics of the BN areextended to give a CBN.3. Manipulating the Chain Event Graph3.1. PrinciplesIn this section we define what we mean by a manipulation of a CEG, and in Section 3.2 we show how such manipulationsrelate to interventions on BNs.A CEG provides a flexible framework for expressing what might happen were a model to be manipulated or made subjectto some control. Such a manipulation results in a modification (usually a simplification) of the topology of our (idle) CEG toproduce a manipulated CEG. For many manipulations this modification consists simply of the pruning (removing) of specifiededges and positions and the reassignment of the probabilities on a small subset of the directed edges of the CEG.Discussions of causal manipulation can be found in [13,21,27,30]. Here we follow Pearl [21] whose Do operator describesinterventions on directed acyclic graphs (DAGs). The joint density function of a set of random variables X1, . . . , Xn withsample spaces X1, . . . , Xn factorises according to a DAG as:p(x1, . . . , xn) =n(cid:7)i=1p(xi | pai)where p(xi | pai) is the probability of Xi taking the value xi given that its parents among X1, . . . , Xn take values fromx1, . . . , xn.A random variable is forced to assume a specific value with probability one, say X j = ˆx j for some j ∈ {1, . . . , n} andˆx j ∈ X j . A new density p(· (cid:11) ˆx j) (using the notation of [15]) is defined on { X1, . . . , Xn} \ { X j} by the formula:p(x1, . . . , x j−1, x j+1, . . . , xn (cid:11) ˆx j) ≡ p(x1, . . . , xn)p(x j | pa j)(3.1)This formula expresses the effect of the manipulation Do X j = ˆx j . The distribution of the variable X j has been replaced bya new one which assigns the whole weight to the value x j . The expression can be readily modified for say a stochasticintervention by replacing the distribution of X j by some other (less crude) new distribution. The manipulation of CEGs isdefined in an analogous manner by the replacing of the distributions of some of the random variables sitting on positionsby new distributions.Definition 3. Let (T , Π(T )) be a tree with corresponding CEG (C, Π(C)). Let D ⊂ S(T ) be a subset of the situations of thetree, and ˆΠD ≡ { ˆπ (v(cid:3) ∈ X(v)} be a new distribution on v ∈ D. Then we define a manipulation of our tree by:(cid:5)(cid:3)v /∈ Dv ∈ D(cid:3) | v): v ∈ D, v(cid:3) | v)(cid:3) | v)X(v) = vπ (vˆπ (v≡ˆP(cid:8)(cid:3)(cid:3) ∈ X(v), v ∈ S(T ). The manipulated tree ( ˆT , ˆΠ( ˆT )) is the tree so defined, and the manipulated CEG ( ˆC, ˆΠ( ˆC)) isfor all vthe CEG of the manipulated tree.Definition 4. A manipulation of a tree is called positioned if the partition of the positions after the manipulation is equal toor a coarsening of the partition before manipulation. It is called staged if the partition of the stages after the manipulationis equal to or a coarsening of the partition before manipulation.A positioned manipulation of a tree treats all sample units identically when their future development distributions areidentical. A staged manipulation treats sample units identically if their next development in the idle system is the same. Inour experience, it is usually sufficient to restrict study to positioned manipulations. We note that the simple Do, functionaland stochastic interventions on a BN considered by Pearl [19,20] are all both positioned and staged.Useful manipulations of any system tend to be local in the sense that only a small number of components are ma-nipulated. This idea is formalised in Definition 3 where only a subset of edges of a tree or CEG have their probabilitiesreassigned. Where a manipulation of a CEG corresponds to a simple Do or a functional intervention, one edge only on eachroot-to-sink path will have its probability altered (to either 0 or 1). This intervention can also be considered as a manipu-lation to a set of positions W — those positions that terminate the edges which have been assigned a probability of one.Such a manipulation could be, for example, the assignment of patients with particular values of a set of covariates (detailedby their current positions) to a particular treatment regime (a set of subsequent positions W ).For interventions of this type, the conditional independence properties characterised by the stage-structure both up-stream and downstream of the manipulation are those of the idle system. When a manipulation is to a set of positions Wwhere not all root-to-sink paths pass through positions which are parents of positions in W , the stage-structure downstreamof W in the manipulated graph is retained from the idle CEG, but the stage-structure upstream of W is often altered. TheP. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909895Fig. 3. Manipulated CEG ˆC for manipulation to w 1.conditional independence properties associated with the edges emanating from positions that are parents of positions in Ware lost.This has the useful consequence that for staged manipulations of a CEG we can simply replace (T , Π(T )) by (C, Π(C)) in(cid:3)) | w): w ∈ u, u ∈ D}, whereDefinition 3; D ⊂ S(T ) by D ⊂ L(C);ˆπ (e(w, wˆΠD ≡ { ˆπ (v(cid:3)) | w) is a new distribution of the random variable X(u) for w ∈ u.(cid:3) ∈ X(v)} by ˆΠD ≡ { ˆπ (e(w, w(cid:3) | v): v ∈ D, vOur focus in this paper is on those manipulations which have analogues for BNs. We start our description with simpleinterventions which can be characterised as forcing to a manipulation set W (or as in Example 3.1, to a single position w),where each position that is a parent of a position in W has only one child in W . We label the set of parents of positions inW by pa(W ).Example 3.1. In Example 2.1, consider the manipulation forced to w 1 (manipulation set W = {w 1}, pa(W ) = {w 0}), whichcorresponds to ensuring that the suspect goes to court.This assigns a probability of 1 to the edge e(w 0, w 1), and all vertices and edges not lying on a w 0 → w 1 → w∞ pathare deleted. The probabilities on all edges in our manipulated CEG ˆC are identical to the corresponding edge-probabilitiesin C except the probability on the edge e(w 0, w 1). Our manipulated CEG ˆC is given in Fig. 3. As all probabilities after themanipulation remain unchanged, we have stages as marked.We assume that Fig. 3 shows a CEG which is valid for our manipulation. However this assumption is a substantive one.If a judge is available, sufficient money has been stolen and so on, then the police, believing S to be guilty, will make adecision to proceed. In this case our manipulated CEG is almost certainly valid. However suppose the police obtain CCTVfootage showing S to be present. Then the police will again make a decision to proceed (ensuring that there is a judgeavailable, and ignoring police-force policy if necessary). This can also be interpreted as a manipulation to w 1, but in thiscase edge-probabilities downstream of the manipulation may well change — the presence of S on CCTV footage may increasethe probability of the witness identifying S for example. This manipulation may also alter the topology of the manipulatedCEG — the witness failing to identify S may no longer result automatically in an acquittal.The alternative manipulation, forced to w 13, can be interpreted as a contingent manipulation — if the police proceed,the witness is forced not to identify the suspect. A CEG for this intervention is given in Fig. 4.896P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909Fig. 4. Manipulated CEG ˆC for manipulation to w 13.As the manipulation definition uses the phrase if the police proceed, there is no reason here for altering the probabilitieson the e(w 2, w 13) and e(w 4, w 13) edges, and so the stage structure is as in Fig. 4. Note that this manipulation might beenacted by an outside manipulator, such as the suspect’s brother!The manipulation forcing to {w 12, w 14} is considered in Section 5.Example 3.2. A university has residence blocks of apartments, with two rooms each. It allocates second year students, eitherEnglish ( X1 = 0) or Chinese ( X1 = 1), to one of the two rooms in each apartment. The second room is allocated to a firstyear student, either English ( X2 = 0) or Chinese ( X2 = 1), and this is done at random. A survey has recorded that theprobability of a high satisfaction rating for students placed with another student of the same ethnicity is higher than forstudents placed with another student of different ethnicity.Recording student satisfaction via a binary indicator Y , we can draw a CEG for this problem as in Fig. 5. As with Fig. 1,for simplicity only a subset of the edges have been coloured.The undirected edge between w 1 and w 2 indicates that these positions are in the same stage and hence X2 (cid:10) X1,reflecting the random allocation of first year students to apartments. Because w 1 and w 2 are not combined into a singleposition we can read that Y /(cid:10) X1. We can also read the positions w 3 and w 4 to give Y (cid:10)( X1, X2) | X1 = X2 and Y (cid:10)( X1, X2) |X1 (cid:13)= X2. These expressions can be combined into the single statement Y (cid:10) ( X1, X2) | | X1 − X2|. Since X1 (cid:10) X2 and Y dependson both X1 and X2, the obvious BN-representation of the problem is as in Fig. 6(a). The BN would need to be supplementedby the extra context-specific information, and if required the information that second year students are allocated before firstyears.If we consider the intervention wherein the university places first year students with second years of the same ethnicity,then this would be represented on the CEG in Fig. 5 as a manipulation to the position w 3. Note that this manipulationwould cause the removal of the undirected edge between w 1 and w 2 since X1 /(cid:10) X2 | ( X1 = X2). Using the BN in Fig. 6(a)this would be a functional manipulation Do X2 = x1; or alternatively we could redefine our variable X2 so that it hadoutcome space {0, 1} corresponding to {first year student has same ethnicity as second year student, first year student has differentethnicity from second year student}. This would give us the BN as in Fig. 6(b), and our manipulation would correspond toforcing X2 to the value 0, with the deletion of the arc from X1 to X2. However, as with the BN in Fig. 6(a), this BN wouldP. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909897Fig. 5. CEG for Example 3.2.Fig. 6. Possible BNs for Example 3.2.have to be supplemented by extra information (here the fact that first year students are allocated at random) in order tofully describe the idle system.The topology of the CEG here fully represents the idle system, and also allows us to both express our manipulation andanalyse its effects.3.2. Interventions on CEGs and BNsConsider again the BN from Fig. 6(a) and the CEG from Fig. 5. The BN is extended to a CBN by the assumption that thearrows on the edges represent causal directions and mechanisms [21]. So we could for example force X2 to the value 1,and analyse the effect on the variable Y . In the CEG we cannot make this assumption about edges — X1 edges immediatelyprecede X2 edges in Fig. 5, but X1 is not a cause of X2. But by embedding additional causal hypotheses CEGs can be given acausal interpretation in a very similar manner. Under this interpretation the CEG represents a controlled model where someor all of our variables are manipulable.For a CEG to be causal for a particular manipulation we require that all edges that are to be manipulated lie upstreamof any descendants of the variables labelling these edges. We also require that if the CEG were to be manipulated then theassumption that the distribution of variables downstream of the manipulation remains as in the idle system is a valid one.In Example 3.1 we briefly considered a case where this assumption might not be valid. Effectively, a CEG is deemed validfor a manipulation if the assumptions required for Definition 3 are valid.It is therefore possible for a CEG to have a causal interpretation when not all problem variables appear before theirdescendants. It is however necessary that the variables to be manipulated satisfy this condition.If the assumptions required for Definition 3 are valid for a particular CEG C , then a manipulation of this CEG is, in itsmost general form, the imposition of new probability distributions on the edges leaving one or more positions from V (C).So for example, in Fig. 5 the manipulation Do X1 = 0 assigns a probability of 1 to the edge e(w 0, w 1), a probability of 0 tothe edge e(w 0, w 2), and leaves all other edge-probabilities unchanged. In practice we would prune the edge e(w 0, w 2) andthe edges emanating from w 2 to give a less cluttered diagram.Clearly the assumptions required for Definition 3 may not be valid for all possible CEG orderings of a problem. We mayhave two CEGs which both accurately describe the idle state of a problem, but only one of which can be given a causalinterpretation for a particular manipulation. Indeed the choice of ordering will be governed by how we wish to use the CEG.898P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909This holds for other graphical representations — in decision analysis for example, a decision tree given a causal order willprovide an accurate description of how a problem unfolds, but to perform an optimal decision analysis, one would need tohave an extensive form decision tree.All the standard interventions on BNs [21,34] are possible on CEGs, and correspond to manipulations of collections ofpositions. For example the simple Do intervention becomes a manipulation of collections of stages, so in models where itis reasonable to talk about manipulating a variable X , the intervention Do X = x0 assigns a probability of 1 to all edgeslabelled x0, a probability of 0 to all edges labelled x j ( j (cid:13)= 0), and leaves all other edge-probabilities unchanged. In practicewe prune edges with zero probability and those lying only on zero-probability paths.Positions in a CEG store vectors of values of preceding variables, so a set of positions whose emanating edges all sharethe same labels can be partitioned by the values taken by a subset of the preceding variables. A functional manipulationDo X = g(Z ) can then be represented by assigning probabilities to the emanating edges of these positions dependent onwhich element of the partition the position falls into. A stochastic Do is represented simply by assigning a new probabilitydistribution to all the edges leaving each position in a set whose members’ emanating edges share the same labels.Definition 3 allows us to look beyond these basic manipulations. So for example they can all be extended so that themanipulated variable ( X ) no longer corresponds to one of the original measurement variables of the problem. The stochasticDo can also be adapted so that for some positions corresponding to X , the distribution imposed on the outgoing edgesis identical to that in the idle system. This leads to the case where some root-to-sink paths of the CEG have no edgesmanipulated, corresponding for example to treatment regimes where only patients with certain combinations of symptomsare treated.We can also consider interventions where some root-to-sink paths are subject to more than one manipulation. Or wecould modify our definition of a CEG manipulation to consider interventions which produce possible outcomes at a positionwhich are not possible in the idle system. This would involve not just imposing a new distribution on existing edges, but theadding of extra edges and hence the production of extra paths not present in the original CEG. If we enact the interventionBuild a dam across the valley mouth, then the event The village halfway up the valley side gets flooded next year, which has zeroprobability in the idle system, now has a probability greater than zero [31].We have described here how the manipulations of BNs have their counterparts on CEGs. In Section 4 we return to themore general class of manipulations possible with CEGs. The interventions described above can be thought of as specialcases of these generic types.4. Identifying the effects of manipulationsMuch of the causal BN literature [6,21,20] studies when the effects of a manipulation on a pre-specified random variableY can be identified from observing a subset of the BN’s variables that are observed or manifest in the idle system. Necessaryand sufficient conditions for causal identifiability (expressed as functions of the topology of the idle BN) have now beenproved for most scenarios [22,35,7,34]. These results allow us to use probabilities from the idle system in order to estimateeffects on the manipulated system, for example the effects of a proposed new treatment regime.The topology of the CEG can also be used for this purpose. Pearl [21] states that the causal effect of X on Y is identifiablefrom a graph G if the quantity p( y (cid:11) ˆx) can be computed uniquely from any positive probability of the observed variables.We can generalise this for the CEG and state that the causal effect on a variable Y is identifiable from a CEG C if theprobability of the event Y = y in the manipulated CEG ˆC can be expressed solely in terms of observable probabilities fromthe idle system. We can use the topology of the CEG to find functions of the data (not just subsets of possible measurements)that when observed in the idle system allow us to estimate the effect of a given manipulation of a causal CEG. As in [21]we prove several sufficient conditions for identifiability, and generalise Pearl’s Back Door Theorem to CEG models. We firstprovide some notation and a couple of definitions.We use λ to indicate a root-to-sink (w 0 → w∞) path of our CEG. Each λ is an atom of the path σ -algebra of the CEG,and the set of atoms is denoted Ω . A subpath of a root-to-sink path is denoted μ or μ(w 1, w 2), where w 1 and w 2 indicatethe start and end positions of the subpath.A union of atoms constitutes an event, denoted Λ. M is used to indicate a union of subpaths, so for example M(w 1, w 2)is the union of all subpaths from w 1 to w 2. Let Λ(w) denote the event which is the union of all paths passing through theposition w, and Λ(e) the union of all paths passing through the edge e. Λ(μ(w 1, w 2)) is the event which is the union ofall paths utilising the subpath μ(w 1, w 2).We use π (w) ≡ π (Λ(w)) to denote the probability of passing through the position w. Note that this is also the prob-ability of reaching w from w 0. The probability of reaching w 2 from w 1 is denoted by π (Λ(w 2) | Λ(w 1)) or more simplyπ (w 2 | w 1). Similarly πμ(w 2 | w 1) ≡ π (Λ(μ(w 1, w 2)) | Λ(w 1)) is the probability of utilising the subpath μ(w 1, w 2) giventhat a unit has reached w 1 — this can be thought of as the probability of the subpath μ(w 1, w 2). Let πe(w 2 | w 1) denotethe probability of passing from a position w 1 to an adjacent position w 2 along the edge e(w 1, w 2).Finally we let Y : Ω → R be a random variable measurable with respect to the path σ -algebra of the CEG; and let {Λ y}be the partition of Ω generated by Y — namely each Λ y is the union of those λ ∈ Ω for which Y = y.Definition 5. For a CEG (C, Π(C)), and a manipulation of this CEG yielding a manipulated CEG ( ˆC, ˆΠ( ˆC)), the manipulationis forced to the position w if:P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909899ˆπ (Λ(w)) = 1,1.2. under ˆΠ( ˆC) all primitive probabilities associated with edges downstream of w are those of the idle system.A manipulation which forces to a position w is one which ensures that at a specified point in a process, all units havethe same probability of following each of a set of possible future developments. This is done by arranging that each unithas the same vector of values for a subset of the preceding variables (characterised by Λ(w)). An example of this would bea company preparing employees for possible promotion by ensuring that they had each attended certain training courses orpassed certain professional examinations. In Example 3.1, both our manipulations are manipulations forced to a position.We now consider an effect random variable ˆY defined on the path σ -algebra of ˆC . ˆY generates a partition of the root-to-sink paths of ˆC with each outcome corresponding to a union of w 0 → w∞ paths. There then exists a variable Y definedon C such that any path in C which belongs to the event Y = y and which passes through w, has an equivalent path in ˆCwhich belongs to the event ˆY = y. Without ambiguity we can denote the union of w 0 → w∞ paths in ˆC belonging to theevent ˆY = y by Λ y .Now each w 0 → w∞ path in ˆC is a conjunction of a w 0 → w subpath with a w → w∞ subpath. We denote thesesubpaths by {μ(w 0, w)} and {μ(w, w∞)} and let the union of all w 0 → w subpaths be M(w 0, w).The random variable ˆY measures an effect after a manipulation forced to w. So heuristically ˆY needs to be realised afterw, i.e. be associated with events downstream of w. Formally we therefore require that our partition {Λ y} of ˆC consists ofevents each of which is M(w 0, w) conjoined to a union of subpaths from {μ(w, w∞)} — for outcome ˆY = y, call this unionM y(w, w∞).Suppose briefly that we are considering a problem which admits a natural product space structure (and could thereforebe depicted by a BN). We can then construct a CEG of the problem where all edges can be labelled with the outcomes ofthe problem variables (although we may sometimes choose to construct our CEG so that these variables are encountered indifferent orders on different root-to-sink paths). In this case we might well label a subset of edges with for example theoutcome y0. The event Y = y0 would then be the union of all w 0 → w∞ paths in C passing through one of these edges.In the manipulated CEG ˆC many of these edges will disappear. However those that are left will still be labelled y0, and theevent ˆY = y0 will be the union of all w 0 → w∞ paths in ˆC passing through one of these edges.Lemma 1. Providing that the probability of passing through the position w in the idle system is greater than zero, then for all levels y,under a manipulation forced to wˆπ ( ˆY = y) = π (Y = y | w)Proof. The proof of this lemma is presented in Appendix A. (cid:2)One consequence of this lemma is that for a manipulation forced to w it may be possible to observe indicators on theevents {Λ y ∩ Λ(w)} in the unmanipulated system and to identify the effect on Y of the manipulation, using this expression.However it is not always possible to observe these indicators, even in models that can be described by a CBN. Supposeinstead that we can observe indicators for a set of coarser events. We show below that being able to observe indicators onthe events {Λ y ∩ Λ(W )} (where W is some set of positions) can also be sufficient for identifiability.Definition 6. A set of positions W ⊂ V (C) is called C -regular (or simply regular) if(i) no two positions in W lie on the same directed path of C , and if(ii) no two positions in W share a parent in V (C).For any regular set of positions W , the collection of edges lying on w 0 → W subpaths can be partitioned into defining,refining and passive edges as follows:1. the defining edges of W are those edges lying on w 0 → W subpaths which emanate from positions not all of whoseoutgoing edges lie on w 0 → W subpaths,2. the refining edges of W are those edges lying on w 0 → W subpaths which emanate from positions all of whoseoutgoing edges lie on w 0 → W subpaths, but not all of whose outgoing edges lie on a w 0 → w subpath, for anyindividual w ∈ W ,3. the passive edges of W are those edges lying on w 0 → W subpaths which are neither defining nor refining edges.Definition 7. For a CEG (C, Π(C)), and a manipulation of this CEG yielding a manipulated CEG ( ˆC, ˆΠ( ˆC)), the manipulationis forced to the C -regular set W if:(cid:9)ˆπ (Λ(w)) = 1,w∈W1.2. under ˆΠ( ˆC) all primitive probabilities associated with edges downstream of any w ∈ W are those of the idle system.900P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909As noted in Section 3.1, the simple Do X = x and functional Do X = g(Z ) interventions on BNs can be represented on aCEG as manipulations to a regular set of positions.We now construct an effect random variable associated with a manipulation forced to a C -regular set W . So consider arandom variable ˆY defined on the path σ -algebra of ˆC . Each outcome y of ˆY corresponds to a union of w 0 → w∞ paths inˆC (Λ y ), and we wish ˆY to be downstream of W . As before, there exists a corresponding variable Y defined on C .For a position w ∈ W and outcome y, we can specify an event M(w 0, w) × M y(w, w∞) provided that the setˆY = y (or Λ y ) as the union over all w ∈ W of the events{μ y(w, w∞)} is not empty. We then define our event{M(w 0, w) × M y(w, w∞)}.We wish to be able to state conditions for the effect of a manipulation forced to a C -regular set of positions W beingdeterminable directly from probabilities in the idle system. We do this through the idea of an amenable manipulation.Definition 8. A regular set of positions W is simple if:1. all defining edges of W emanate from positions which have only one outgoing edge lying on a w 0 → W subpath,2. all refining edges of W emanate from positions which have only one outgoing edge lying on a w 0 → w subpath foreach w ∈ W ,3. for any w ∈ W , the refining edges on w 0 → w subpaths are independent of the defining and passive edges on thesesubpaths in the sense that(a) for each w 1 ∈ W and all w 2 ∈ W \ w 1, and for any μ(w 0, w 1) subpath, there must exist a μ(w 0, w 2) subpathwhich differs in colour from the μ(w 0, w 1) subpath only on refining edges,(b) for each w ∈ W the colouring of the refining edges is the same for each μ(w 0, w) subpath.An immediate consequence of Definition 8 is that for each w ∈ W , we can write(cid:3)(cid:5)Λ(w)π= π Rwπ(cid:3)(cid:5)Λ(W )where π Rresult is given in Appendix A.w is the product of probabilities on the refining edges of W lying on the w 0 → w subpaths. A derivation of thisNote that in direct analogy with results on causal identifiability in BNs, the conditions of this definition can all be checkedwith reference to the topology of the CEG. Condition 3(b) needs a slight modification if we have chosen to construct ourCEG so that different paths pass through the problem variables in different orders.Suppose briefly that a particular problem is regular enough to admit a natural product space structure, and the edges ofour CEG have been labelled with the outcomes of the problem variables. It is then possible to define passive, refining anddefining variables. The values labelling the defining edges of W correspond to the state of a vector of defining variables D;the vector of refining variables R defines the values labelling the refining edges; whilst the vector P defines the valueslabelling the passive edges. In this situation we can express condition 3 as R (cid:10) (P, D).Definition 9. A manipulation is called amenable forcing to a set W if:1. the set W is simple in (C, Π),2. the set W is simple in ( ˆC, ˆΠ), and ˆπ (Λ(W )) = 1,3. Π(C) and ˆΠ( ˆC) differ only on the defining edges of W .Lemma 2. Consider an amenable manipulation forcing to a simple set W . The distribution of ˆY (as defined above) is identified fromthe probabilities in the unmanipulated system of the events {Y = y, W }, and its probabilities are given by the equationˆπ ( ˆY = y) = π (Y = y, W )π (W )where π (W ) ≡(cid:9)w∈W π (Λ(w)), and provided that π (Λ(w)) > 0 ∀w ∈ W .Proof. The proof of this lemma is presented in Appendix A. (cid:2)Example 4.1. Consider the binary BN and corresponding CEG in Fig. 7. The manipulation to the set W = {w 7, w 9} (equivalentto the Pearl manipulation Do X = x0) is amenable and satisfies Lemma 2.For the CEG in Fig. 7 we have(cid:5)Λ(w 7)= π (c0)(cid:10)π(cid:3)π (d)π (x0 | d) = π (c0)π (x0)dP. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909901Fig. 7. BN and CEG for Example 4.1.and similarly for π (Λ(w 9)). W here is simple — the defining edges are those labelled x0, the refining edges are labelled c0and c1, and the passive edges are those labelled d0 and d1. π (Λ(W )) = π (x0), and π Rw7The CEG ˆC for this manipulation differs from C in that w 3, w 4, w 5 and w 6 are now all in the same stage; the edgesterminating at w 7 or w 9 all have probability 1; and all edges either terminating at or emanating from w 8 or w 10 arepruned. Hence= π (c0).(cid:3)(cid:5)Λ(w 7)ˆπ= π (c0)(cid:10)dπ (d) × 1 = π (c0) × 1ˆΠ differs only on the edges labelled x0, i.e. the defining edges; so thisand similarly for ˆπ (Λ(w 9)). So W is simple in ˆC .manipulation is amenable.Letting Λ y be the event Y = y0, we have(cid:10)(cid:10)ˆπ (Λ y) ≡ ˆπ ( ˆY = y0) =π (c)cdFrom Fig. 7 we have that(cid:4)(cid:5)(cid:4) Λ(W )πΛ y(cid:3)≡ π (Y = y0 | x0) =π (d) × 1 × π ( y0 | c, x0) =(cid:10)cπ (c)π ( y0 | c, x0)(cid:9)(cid:9)c π (c)(cid:9)(cid:9)d π (d)π (x0 | d)π ( y0 | c, x0)d π (d)π (x0 | d)c π (c)(cid:10)=cπ (c)π ( y0 | c, x0) = ˆπ (Y = y0)Suppose that our idle CEG can (as in Example 4.1) be represented as a BN, so that in particular defining, refining andpassive variables can be defined. In a CBN, the effect of a manipulation of a variable X on a later variable Y can be identifiedfrom observing the distribution of the unmanipulated pair ( X, Y ) if and only if the vector of unobserved (hidden) variablesH in the system can be partitioned as H = (H1, H2), whereH2 (cid:10) (H1, X) and (Y , H2) (cid:10) H1 | XReturning to the CEG, we learnt in Section 2.2 that for any position w we can write Y (w) (cid:10) Z (w) | Λ(w) — i.e. any variabledefined downstream of w is independent of variables defined upstream of w conditioned on the event Λ(w). Now forw ∈ W (a simple set), Λ(w) can be explicitly characterised simply in terms of the labelling of the defining and refiningedges on w 0 → w subpaths. So in this situation Λ(w) can be expressed in terms of the states of the vectors D and R, and902P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909we can write the collection of conditional independence properties {Y (w) (cid:10) Z (w) | Λ(w)}w∈W as Y (cid:10) P | (R, D). Since wealready know that R (cid:10) (P, D), we can deduce that (Y , R) (cid:10) P | D. Equating H1 above with P, X with D and H2 with R, wecan see that the conditions on the CBN are the same as on the CEG. So Lemma 2 is an exact analogue of this well knownresult for causal BNs for the more general class of CEGs. Moreover, the conditions required by Lemma 2 only depend on anappropriate factorisation of probabilities associated with the manipulated set W .Using Lauritzen’s [15] terminology and the (sets of) variables X, Y , H1, H2, we have from expression (3.1) that(cid:11)π ( y (cid:11) x) =(cid:10)h1,h2(cid:12)π (x, h1, h2, y)π (x | pa(x))Note that ( X, H1) (cid:10) H2 ⇒ X (cid:10) H2 | H1, so we can equate PA( X) with H1, and writeπ ( y (cid:11) x) =(cid:10)(cid:13)π (x | h1)(cid:14)−1π (x, h1)π (h2, y | h1, x)h1,h2(cid:10)=π (h1)π (h2, y | x) = π ( y | x)h1,h2using (Y , H2) (cid:10) H1 | X .Under these conditions, manipulating X to x has the same effect on Y as conditioning X to x. Note that in Example 4.1we can clearly see that C (cid:10) (D, X) and (Y , C) (cid:10) D | X, so our refining variable is C , our defining variable is X , and D is apassive variable.5. A Back Door Theorem for Chain Event GraphsA key component of causal analysis on BNs is Pearl’s Back Door Theorem [19,21], which owes its derivation in part tothe realisation that many manipulations are impossible, unethical or prohibitively expensive in practice, or may be possibleto enact but some of their effects may be impossible to observe. The Back Door Theorem gives sufficient conditions foridentifying the effect on a variable Y of manipulation of a variable X when we are able to observe the values taken by onlya subset Z of the remaining variables in the system. If the set Z is chosen carefully then we can calculate or estimate thiseffect from a partially observed idle system.In this section we produce an analogous theorem that applies a graphical and sufficient criterion to a CEG to determinewhether we can identify the effect of a manipulation on a random variable Y from the observation of a random variable Z(happening before the manipulation in the partial ordering induced by the paths) in the unmanipulated system. The event-based topology of the CEG allows us to consider a wider class of idle system models, and a wider class of manipulationsof these than is generally possible with a standard BN. Similarly, our random variable Z does not need to correspond toany fixed subset of the measurement variables of the problem, giving us more flexibility in our search for an appropriateprobability expression.Before proceeding to this theorem we provide some further notation and a couple of definitions.Definition 10. For a C -regular set of positions W , the graph C W with vertex set V (C W ), directed edge set Ed(C W ) andundirected edge set E u(C W ), is defined by1. V (C W ) consists of the union of {w}, a new root-node, with the set of precisely those positions from V (C) which lie•0on a w → w∞ subpath in C , for some w ∈ W .2. The root-node wwith the set of precisely those edges from Ed(C) which lie on a w → w∞ subpath in C , for some w ∈ W .•0 is connected by an edge to each w ∈ W . Ed(C W ) consists of the union of the set {e(w•0, w)}w∈W3. Edge-colourings (i.e. edge-probabilities) on w → w∞ subpaths of C W (for w ∈ W ) are retained from C .0, w) (w ∈ W ) is given the probability π (Λ(w))4. The edge e(wπ (Λ(W )) .5. If two positions in V (C W ) were connected by an undirected edge in C , then they are connected in C W . E u(C W ) is the•set of undirected edges in C W .It is straightforward to show that C W is a CEG.We now let Z be a random variable observed on C , whose events {Z = z} partition the set of w 0 → w∞ paths of C ;and consider W 1, a fine cut of C such that each event Z = z is precisely the set of w 0 → w∞ paths in C passing througha (specified) subset of positions from this cut. We can then, without ambiguity, identify each event Z = z with this set ofpositions — say W 1z .Let the set of positions to which we intend to manipulate be W 2. Then for Z to occur before the manipulation werequire that every position w 2 ∈ W 2 lies on a path in C between some position w 1 ∈ W 1z (for some level z) and w∞. Notethat our fine cut W 1 is going to take the role of Z in our Back Door Theorem. We therefore require that the manipulationdoes not change any primitive probabilities from the idle system lying on a subpath between w 0 and the positions in W 1.P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909903To ensure this we need to stipulate that for each w 1 ∈ W 1, there must exist a w 0 → w 1 → w 2 → w∞ path for somew 2 ∈ W 2. If there existed w 1 ∈ W 1 for which there was no such w 2, then ˆπ (Λ(w 1)) would equal zero, and hence wouldnot equal π (Λ(w 1)). Having imposed this condition, we can ensure that the probability of Z = z is the same in ˆC as in C .Definition 11. A set of C -regular positions W 2 ⊂ V (C) is called simple conditioned on Z if(cid:15)z W 2z where W 21. W 2 ≡2. There is a directed path in C from each position w 1zthose positions in W 2 which lie on a w 0 → w 1zz is simple in C W 1.z∈ W 1→ w∞ path for some w 1zz through a position w 2 ∈ W 2, and W 2∈ W 1z .z is the set of preciselyNote that the union in item 1 is not a disjoint union.Consider an amenable manipulation to a set W , and let W be simple conditioned on Z . Then Z is called a Back Doorvariable to the manipulation. Let our effect variable ˆY be the image of Y in the manipulated CEG.Theorem 1. If a set W is simple conditioned on Z (a Back Door variable), then the distribution of Y after an amenable manipulationto W is identified from the probabilities (in the idle system) of the events {Y = y, W , Z = z}, and its probabilities are given by:ˆπ ( ˆY = y) =(cid:10)zπ (Y = y, W , Z = z)π (W , Z = z)π (Z = z)Proof. The proof of this theorem is presented in Appendix A. (cid:2)Example 5.1. In Example 3.1 we considered a manipulation of the CEG in Fig. 1 to the position w 13, where if the policeproceeded the witness was forced not to identify S. Consider now the manipulation wherein the witness is forced toidentify S. This is a manipulation forced to W = {w 12, w 14}. The manipulated CEG is given in Fig. 8.Whereas the previous manipulation might have been enacted by an outside manipulator, such as the suspect’s brother,this intervention is likely to have been enacted by someone within the police force, probably acting in an unethical manner.They would wish to have a good idea of the effects (on the indicator X6) of this manipulation, but as a consequence of theimproper nature of their intervention, they might not have any means of obtaining reliable estimates of certain necessaryjoint distributions of the problem variables. In particular, they would probably have to treat X4 (indicating whether ornot the forensic service will find a glass match) as an unobservable variable. Can we produce a manipulated probabilityexpression which does not depend on X4?Consider the BNs in Fig. 2 and the use of Pearl’s Back Door Theorem [19,21]. For BN (1) we could use a Back Doorblocking set consisting of X1 with X2 and/or X3, whereas for BNs (2) and (3), any blocking set must include X4. So onlyBN (1) is of use to us here. If this BN is supplemented with the relevant context-specific information then we will be able toproduce an identifiable expression. But as noted in Section 2.3, none of the BNs in Fig. 2 are well-defined — none of themencodes the full set of conditional independence properties of the problem, whereas the problem has an unambiguousrepresentation as a CEG, and the CEG does not need to be supplemented with extra information. Moreover, we can useTheorem 1 to deduce the effect on X6 of our manipulation, and produce an expression which is not dependent on X4.Notice that the probabilities in ˆC differ only on the defining edges of W (a C -regular set), i.e. on those edges labelledproceed and identifies S. At first sight the manipulation does not seem to satisfy the conditions for Theorem 1 as the manipu-lated edge proceed must necessarily be upstream of any possible Back Door blocking set we propose. But all w 0 → W pathspass through w 1, so ˆπ (conviction) = ˆπ (conviction | Λ(w 1)). This is simply the manipulated probability of conviction in theCEG C w1 (see Definition 10). We can therefore simply consider this CEG C w1 and apply Theorem 1 to it. W is C w1 -regularand the defining, refining and passive edges of W in C w1 are precisely the defining, refining and passive edges of W in Cwhich lie downstream of the position w 1, so checking the conditions of Theorem 1 can be done on the original graph inFig. 1.The ideas here can be used to allow us to apply Theorem 1 in many situations where, at first sight, it is apparently notappropriate.Note that our set W 1 need no longer be a fine cut of C , but just one of C w1 , i.e. a partition of the root-to-sink pathsof ˆC . So consider the set W 1 = {w 5, w 6, w 7}, upstream of the set W ≡ W 2 = {w 12, w 14}. Assign the value z = 1 to pathspassing through w 5 (stole money); z = 2 to paths passing through w 6 (present, did not steal money); z = 3 to paths passingthrough w 7 (not present). Then W 1= W 3= {w 5}, W 1z=3= W 2, then by construction, if W 2 is simple in C W 1z , the conditions ofDefinition 11 are satisfied and W 2 is simple conditioned on Z (in C w1 ). We do not need to produce separate graphs forthe defining edges of W 2 are those labelled identifies Seach C W 1and the refining edges are those labelled glass match and no match. These edges obey the conditions of Definition 8, so W 2— we can do all our checking on C in Fig. 1. For each C W 1= {w 6}, W 1If we let W 2for each W 1= {w 7}.= W 2z=1z=1z=2z=2z=3zzz904P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909Fig. 8. Manipulated CEG ˆC for Example 5.1.is simple in each C W 1variable Y therefore satisfy the conditions for Theorem 1 with the X6 outcome conviction equating to Y = y.and hence simple conditioned on Z in C w1 . Our variable Z , manipulation set W ≡ W 2 and effectzHence in the CEG C w1ˆπ (conviction) =3(cid:10)z=1π (conviction, W , z)π (W , z)π (z) =3(cid:10)z=1π (conviction | identifies S, z)π (z)since the set W corresponds to the event that X5 takes the outcome identifies S.Note that all primitive probabilities in C w1 are identical to those in C except the probability on the edge e(w 0, w 1),so the probability of z in C w1 is the probability of z in C divided by π (proceed). Hence in C our manipulated probabilityexpression isˆπ (conviction) =1π (proceed)3(cid:10)z=1π (conviction | identifies S, z)π (z)It is not difficult to check that this formula correctly expresses the causal effect on X6 of our manipulation. Moreover, asour three positions w 5, w 6, w 7 can be characterised by values of X2 and X3, this expression does not require knowledgeof the distribution of X4 or of joint distributions including X4.As with BNs, we conjecture that it will be possible to devise simple automated methods for determining whether thereexist variables Z satisfying the conditions for Theorem 1, and procedures for choosing between candidate variables Z . Thesemethods are as yet not fully developed.If we believe such a variable does exist, then Example 5.1 shows us that the choosing of the positions within our partition} to satisfy the conditions of Theorem 1, but also to minimise the amountcan be straightforward. We construct the set {W 1zof work involved. The events {Z = z} must be observable or manifest within the system, but it is not necessary that theseevents are actually observed — in Example 5.1 the police do not observe whether the suspect was at the scene or threw thebrick, but they do have what they consider to be reliable estimates for these probabilities. How we assign z values to thepositions depends on the information we have available, so for example we could here assign the value z = 2 to both w 6and w 7, and let W 1, so this new partition also satisfies the conditions= {w 6, w 7}. W 2 is still simple in this new C W 1z=2z=2P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909905Fig. 9. CEG for Example 5.2.for Theorem 1. We therefore have a choice of coarser or finer partitions, and which we choose will depend on the structureof the information we hold on the conditional distributions of X6. If we are able to choose either then we should go for thecoarser partition, as the resulting expression for ˆπ (conviction) is simpler.The updating of the edge-probabilities of our CEG following a manipulation can already be done rapidly and automat-ically, using algorithms analogous to those described and coded for updating edge-probabilities following an observationin [33] and [32].Example 5.2. First year students at the university in Example 3.2 who made the university first choice on their application(Z = 0) are allocated a shared apartment on campus, whilst first year students who did not (Z = 1) are lodged in eithertown K or in town L (indicator X3). Students lodged in towns K and L may have a friendly landlord or an unfriendly landlord(indicator U ), and the friendliness of these landlords is not known to the university.When Z = 0 it is believed that the CEG in Fig. 5 is valid (where here Y is explicitly the satisfaction expressed by the firstyear student). If Z = 1 the town in which the student is lodged is chosen independently of the ethnicity X2 of the student;the friendliness of the landlord does not depend on either the town or the ethnicity of the student; but the satisfactionrating Y expressed by the first year student depends both on the friendliness of the landlord and the allocated town. Theproblem can be represented by the CEG in Fig. 9.We wish to consider a proposed manipulation of the allocation policy for next year. The university plans to matchcampus-based students so that those sharing an apartment are of the same ethnicity, and to allocate off-campus studentsonly to lodgings in town L. Our interest is in ˆπ (high) — the overall predicted probability of high satisfaction were this policyto be implemented. The university intends to estimate this probability with a small data set, collected from earlier years.The manipulation proposed is different for different contingencies, but this is irrelevant when analysing with a CEG.It can be considered as a manipulation to W = {w 6, w 11, w 13}. If we consider the partition {W 1} = {{w 1}, {w 2}}, it iszstraightforward to check that our variable Z , manipulation set W and effect variable Y satisfy the conditions for Theorem 1,and henceˆπ (high) =1(cid:10)z=0π (high | z, W )π (z)= π (high | Z = 0, X1 = X2)π (Z = 0) + π (Y = 1 | Z = 1, town L)π (Z = 1)So ˆπ (high) can be expressed as a function of three probabilities from the idle system — that a student resides on campus;that a campus-based student sharing with someone of the same ethnicity gives a high satisfaction rating; and that a studentlodging in town L gives a high satisfaction rating. It follows that the probabilities associated with the ethnicity of matchedpairs of campus-based students; the satisfaction ratings of unmatched pairs of campus-based students; the ethnicity of non-campus-based students; the friendliness of the landlords of non-campus-based students are all irrelevant to this calculation,and need not be estimated.906P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909Note also that ˆπ (high) is a function of the event X1 = X2, or alternatively of the variable | X1 − X2|. This is not one of theoriginal measurement variables of the problem, but appears naturally in the CEG of Fig. 9, where its outcomes correspondto the positions w 6 and w 7.To summarise — by examining the topology and colouring of an (idle) CEG, it is possible to determine sufficient con-ditions for whether an effect of a causal manipulation can be identified from a partial set of observations of the system.The CEG is ideally suited to the causal analysis of models which are highly asymmetric. Also, the search for an appropriaterandom variable Z , whose observation ensures identifiability, is not restricted to subvectors of the original (non-descendant)measurement vectors; we can search over all functions of such measurements. Searching over these functions to find thecheapest way of identifying the quantity of interest will often be of much greater value than simply searching over subsetsof measurements. This will be particularly useful if those measurements have not yet been collected, or their parameterisa-tions have been chosen by convention rather than because they reflect some natural description of how a process unfolds.If an intervention can be identified via a CEG, then it may well be the case that by imposing a product space on theproblem we will be able to express it as a BN and find an identifiable expression for the effects of the intervention via thisBN. However, this identification will probably require supplementary context-specific information which is not present inthe DAG of the BN, but which appears naturally in the CEG-representation of the problem.6. DiscussionWe have demonstrated that the CEG provides a flexible graphical framework within which to represent and analyse awide variety of causal hypotheses, even in highly asymmetrical domains. There is of course a cost for this flexibility in thatCEGs have, in general, more vertices and edges than BNs. For more symmetric problems this favours BN-based procedures,but as problems become less symmetric we have found that CEGs become more efficient both in model-storage space andin the algorithms used for updating probabilities [33]. An analysis of the comparative complexity of CBNs and CEGs is to bethe focus of a future paper.Of course the Back Door Theorem presented in this paper is not the only topological criterion for determining causalextensions; for example it is possible to produce and prove analogues of Pearl’s Front Door Theorem (see [31]). In [9]we have shown that CEGs admit conjugate learning and model selection. Currently under investigation are extensions tolearning CEGs when underlying experiments can be causally manipulated (similar in approach to [14]) — these also oftenadmit a conjugate analysis. Despite their more complex topology, causal CEGs, being more general and expressive than CBNs,provide a useful complementary technology.As with the BN, there are limits to the expressiveness of the CEG, and sometimes issues such as whether a cause canbe identified can only be addressed algebraically (see [24]). None-the-less, the popularity of the BN has demonstrated theappeal of graphical-based causal inference, as well as how useful such inference can be. CEGs provide a powerful additionalgraphical tool for the investigation of causal structures which are not easily or fully expressible as CBNs.AcknowledgementsThis research is being supported by the EPSRC, grant no. EP/F036752/1. We would like to thank the referees for theirperceptive and helpful comments which have enabled us to markedly improve the clarity of the paper.Appendix A. Proofs (and Lemma 3)Proof of Lemma 1. In ˆC we can express the event ˆY = y as Λ y = M(w 0, w) × M y(w, w∞) = Λ(w) ∩ Λ(M y(w, w∞)). Hence(cid:3)(cid:5)(cid:5)(cid:3)(cid:3)(cid:3)(cid:3)(cid:5)Λ(w)ˆπΛM y(w, w∞)(cid:5) (cid:4)(cid:5)(cid:4) Λ(w)ˆπ ( ˆY = y) ≡ ˆπ (Λ y) = ˆπ(cid:5)= ˆπΛ(w)(cid:3)Λ(w), ΛM y(w, w∞)ˆπM y (w∞ | w) = 1 × πM y (w∞ | w)= ˆπusing Definition 5(1) and (2).By definition of Y on C we haveπ (Y = y, w) ≡ π(cid:3)⇒ ˆπ ( ˆY = y) =(cid:5)Λ y, Λ(w)(cid:3)Λ(w)(cid:13)π(cid:3)(cid:5)Λ(w)(cid:3)πM y (w∞ | w)= π(cid:5)Λ y, Λ(w)Λ y(cid:3)= π(cid:5)(cid:14)−1π(cid:4)(cid:5)(cid:4) Λ(w)≡ π (Y = y | w)(cid:2)Derivation of result π (Λ(w)) = π Rpassive, defining and refining edges, so we can writew π (Λ(W )). Consider a single subpath μ(w 0, w) for w ∈ W . This consists of a set of(cid:3)(cid:3)Λπ(cid:5)(cid:5)μ(w 0, w)= π Pμπ Dμ π Rμwhere π Pμ is the product of the probabilities on the passive edges of μ (etc.).P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909907For simple W , Definition 8(3)(b) implies that π R(cid:10)(cid:3)(cid:5)Λ(w)π= π Rwμπ Dπ Pμμ is constant for all μ(w 0, w). Relabel this π Rw . Thereforeμ∈{μ(w 0,w)}Definition 8(3)(a) implies that for each μ ∈ {μ(w 0, w 1)}, there is a corresponding μ ∈ {μ(w 0, w 2)} for which π P(cid:9)the same value, for all w 2 ∈ W \ {w 1}, and hence thatThereforeμ takesμ is constant for all w ∈ W . Relabel this as π (cid:3)W .μ∈{μ(w0,w)} π Pμ π Dμ π D(cid:3)(cid:5)Λ(W )π≡(cid:10)w∈W(cid:3)(cid:5)Λ(w)π=(cid:10)(cid:13)(cid:14)=w π (cid:3)π RWw∈W(cid:11) (cid:10)(cid:12)π Rwπ (cid:3)Ww∈W(cid:9)By Definition 6(2) and by construction, the possible combinations of refining edges partition the set of w 0 → W subpaths,so= π (Λ(W )) andw∈W π Rw(cid:3)= 1. Hence π (cid:3)W(cid:5)Λ(w)= π Rπ(cid:3)(cid:5)Λ(W )wπProof of Lemma 2. As our manipulation is amenable, for each w ∈ W(cid:3)(cid:5)Λ(w)π= π Rwπ(cid:3)(cid:5)Λ(W )where π Rw is the product of probabilities on the refining edges of w. So(cid:3)(cid:3)(cid:5)Λ(w)ˆπ= ˆπ Rwˆπ(cid:5)Λ(W )= π Rwusing (i) Definition 9(3), Π(C) and ˆΠ( ˆC) differ only on the defining edges of W (i.e. not on the refining edges of anyw ∈ W ), and (ii) Definition 9(2). So(cid:5)(cid:14)−1π(cid:5)Λ(w)(cid:5)Λ(w)Λ(W )(cid:13)πˆπ=(cid:3)(cid:3)(cid:3)In ˆC , the event ˆY = y (or Λ y ) is equal toΛ y ∩ Λ(W ). So(cid:15)w∈W[M(w 0, w) × M y(w, w∞)]. The corresponding event in C is (Y = y, W ) ≡ˆπ ( ˆY = y) ≡ ˆπ (Λ y) ===(cid:10)w∈W(cid:10)(cid:3)(cid:5)Λ(w)ˆπ(cid:3)(cid:5)Λ(w)ˆπw∈W(cid:3)(cid:13)πΛ(W )(cid:5)(cid:14)−1ˆπM y (w∞ | w)πM y (w∞ | w) using Definition 7(2)(cid:10)(cid:3)(cid:5)Λ(w)ππM y (w∞ | w)(cid:13)== ππ(cid:3)(cid:3)(cid:5)(cid:14)−1πΛ(W )(cid:4)(cid:5)(cid:4) Λ(W )Λ yw∈W(cid:3)(cid:5)Λ y, Λ(W )≡ π (Y = y, W )π (W )(cid:2)Lemma 3. If W 1 and W 2 are C -regular sets of positions, and W 2 is simple in the CEG C W 1 then π (Λ(w 2) | Λ(W 1), Λ(W 2)) can bewritten as the product of probabilities on the refining edges of W 2 in C .Proof. Let w be a position in C W 1 other than its root. By construction of C W 1 , the sub-CEG of C W 1 rooted in w has preciselythe same topology and edge-colouring (i.e. edge-probabilities) as the sub-CEG of C rooted in w.Suppose the edges leaving w are refining edges of W 2 in C W 1 . Then all edges leaving w are on w→ w 2 ∈ W 2 subpaths→ w 2 subpath in C W 1 for anyin C W 1 , and hence in C . Also, as W 2 is simple in C W 1 , only one edge leaving w lies on a windividual w 2 ∈ W 2. So only one edge leaving w lies on a w 0 → w 2 subpath in C for any individual w 2 ∈ W 2. Hence theedges leaving w are refining edges in C . The refining edges of W 2 in C W 1 are therefore precisely the refining edges of W 2in C which lie downstream of W 1.Let probabilities in C W 1 be denoted ˜π . Then W 2 is simple in C W 1 implies that ˜π (Λ(w 2) | Λ(W 2)) can be expressed asthe product of probabilities on the refining edges of W 2 in C W 1 , and from above can therefore be expressed as the productof probabilities on the refining edges of W 2 in C . But•0•0908P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909(cid:3)(cid:3)Λ˜πw 2(cid:3)(cid:5) (cid:4)(cid:4) ΛW 2(cid:5)(cid:5)===(cid:3)(cid:3)(cid:13)˜πΛ(cid:11)(cid:10)W 2(cid:3)(cid:3)˜πΛ(cid:5)(cid:5)(cid:14)−1 ˜π(cid:3)Λ(cid:3)(cid:5)(cid:5)(cid:3)Λ˜πw 1(cid:5)(cid:5)w 2(cid:3)W 2(cid:12)−1 (cid:10)(cid:5)(cid:5)(cid:3)(cid:5) (cid:4)(cid:4) Λw 1(cid:3)(cid:3)Λ˜π(cid:5)(cid:5)(cid:3)(cid:3)Λ˜πw 1w 2(cid:3)(cid:5) (cid:4)(cid:4) Λw 1(cid:5)(cid:5)w 1(cid:11)(cid:10)w 1π (Λ(w 1))π (Λ(W 1))(cid:3)(cid:3)ΛπW 2(cid:3)(cid:5) (cid:4)(cid:4) Λw 1(cid:5)(cid:5)w 1(cid:12)−1 (cid:10)w 1π (Λ(w 1))π (Λ(W 1))(cid:3)(cid:3)Λπw 2(cid:3)(cid:5) (cid:4)(cid:4) Λw 1(cid:5)(cid:5)using Definition 10(3) and (4)(cid:3)(cid:5)(cid:3)(cid:3)=(cid:13)π(cid:3)= πΛ(cid:3)ΛW 1, Λ(cid:5) (cid:4)(cid:3)(cid:4) Λw 2W 2(cid:5)W 1(cid:3)(cid:5)(cid:5)(cid:14)−1πW 2, Λ(cid:3)Λ(cid:5)(cid:5)(cid:5)(cid:5)(cid:3)w 2(cid:3)(cid:5)W 1(cid:2), ΛProof of Theorem 1. Let W ≡ W 2. W 2 is simple conditioned on Z , so we can express W 2 ≡C W 1z. Now(cid:3)(cid:3)πw 2Λ⇒ ˆπ(cid:5)(cid:5)(cid:3)(cid:5) (cid:4)(cid:4) Λ(cid:3)(cid:3)ΛW 1z(cid:5) (cid:4)(cid:4) Λw 2= π(cid:3)W 1z(cid:3)(cid:3)Λ(cid:5)(cid:5)(cid:5)(cid:3)(cid:3)(cid:5) (cid:4)(cid:4) Λ(cid:3)Λ(cid:3)W 1, Λz(cid:5) (cid:4)(cid:3)(cid:4) Λw 2w 2= ˆπW 2(cid:5)W 1z(cid:5)(cid:5)π(cid:3), Λ(cid:3)(cid:3)ΛW 2W 2(cid:3)(cid:5)(cid:5)ˆπ(cid:5)(cid:5)(cid:3)(cid:5) (cid:4)(cid:4) Λ(cid:3)ΛW 1z(cid:5) (cid:4)(cid:4) ΛW 2(cid:3)W 1z(cid:5)(cid:5)(cid:3)(cid:3)Λw 2(cid:3)(cid:5) (cid:4)(cid:4) Λ= πW 1z(cid:5)(cid:3), ΛW 2(cid:5)(cid:5)(cid:15)z W 2z where W 2z is simple inusing (i) Lemma 3, π (Λ(w 2) | Λ(W 1z ), Λ(W 2)) can be written as the product of probabilities on the refining edges ofW 2 in C , and Definition 9(3), Π(C) and ˆΠ( ˆC) differ only on the defining edges of W 2; and (ii) the fact that ˆπ (Λ(W 2) |Λ(W 1z )) = 1. Therefore(cid:3)(cid:3)(cid:3)(cid:5) (cid:4)(cid:4) Λ(cid:5)(cid:5)(cid:3)(cid:3)(cid:13)π(cid:3)(cid:5) (cid:4)(cid:4) Λ(cid:3)(cid:5)(cid:5)(cid:14)−1π(cid:3)ˆπ=ΛΛw 2W 2W 1zConsider in ˆC the events:(Z = z) ≡ Λ(W 1(Z = z, ˆY = y) ≡ Λ(W 1Analogously with Lemma 2, we can express this latter event asz ) since every w 1 ∈ W 1z exists in ˆC by construction,z ) ∩ Λ(W 2) ∩ Λ y since in ˆC all paths pass through W 2.W 1zw 2Λ(cid:5) (cid:4)(cid:4) Λ(cid:5)(cid:5)(cid:3)W 1z(cid:16)(cid:16)(cid:13)(cid:3)Mw 0, w 1, w 2(cid:5)(cid:3)× M yw 2, w∞(cid:5)(cid:14)w 1∈W 1zw 2∈W 2where M(w 0, w 1, w 2) is the union of all μ(w 0, w 1, w 2) subpaths, and M y(w 2, w∞) is the union of all μ(w 2, w∞) sub-paths consistent with ˆY = y. So(cid:10)(cid:10)(cid:3)(cid:3)ˆπΛw 1(cid:5)(cid:3)(cid:5)(cid:5)w 2(cid:3)ˆπM yw∞(cid:5)(cid:4)(cid:4) w 2andˆπ (Z = z, ˆY = y) =w 1∈W 1z(cid:3)(cid:3)w 2∈W 2(cid:5)ˆπ ( ˆY = y | Z = z) = ˆπ(cid:13)ˆπ=Λ(cid:3)Λ, Λ y(cid:5)(cid:5)(cid:14)−1W 2(cid:3)W 1z, Λ(cid:5)(cid:5)(cid:10)(cid:3)(cid:4)(cid:4) ΛW 1z(cid:10)(cid:11)(cid:10)(cid:3)(cid:3)(cid:13)ˆπΛw 1∈W 1z(cid:5)(cid:5)(cid:14)−1w 2∈W 2(cid:10)W 1z(cid:3)(cid:3)Λˆπw 1(cid:5), Λ(cid:3)w 2(cid:5)(cid:5)(cid:3)ˆπM yw∞(cid:5)(cid:4)(cid:4) w 2(cid:3)(cid:3)Λˆπw 1(cid:5), Λ(cid:3)w 2(cid:12)(cid:5)(cid:5)(cid:3)ˆπM yw∞(cid:5)(cid:4)(cid:4) w 2(cid:3)(cid:3)Λˆπw 2(cid:3)(cid:5) (cid:4)(cid:4) Λ(cid:3)(cid:3)(cid:13)πΛW 2(cid:3)(cid:5) (cid:4)(cid:4) ΛW 1z(cid:3)w 1∈W 1z(cid:5)(cid:5)ˆπM y(cid:5)(cid:5)(cid:14)−1πW 1z(cid:5)(cid:4)(cid:4) w 2w∞(cid:3)(cid:3)Λw 2(cid:3)(cid:5) (cid:4)(cid:4) Λ(cid:5)(cid:5)(cid:3)πM yW 1z(cid:5)w∞ | w 2===w 2∈W 2(cid:10)w 2∈W 2(cid:10)w 2∈W 2(A.1)(A.2)using the above and Definition 9(3) (or Definition 7(2))(cid:3)(cid:3)(cid:3)(cid:3)(cid:5)(cid:3)(cid:3)(cid:13)π=ΛW 2(cid:5) (cid:4)(cid:4) Λ(cid:5)(cid:5)(cid:14)−1πW 1zΛW 2, Λ y(cid:4)(cid:4) Λ(cid:5)(cid:5)W 1zusing the equivalence of the entities in expressions (A.1) and (A.2) and removing the hats, which we can do as this proofhas used no aspect of the topology of ˆC which is not also true for C .Also, since W 1 is a fine cut, all w 0 → w∞ paths in C pass through some w 1 ∈ W 1, and by Definition 11(2) eachw 1 ∈ W 1 lies on a w 0 → W 2 path. So by Definition 6(1) no edges leaving positions upstream of W 1 are defining edges ofP. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909909W 2. But our manipulation is amenable to W 2 and by Definition 9(3), Π(C) and ˆΠ( ˆC) differ only on the defining edges ofW 2. So the probabilities on all edges upstream of W 1 are the same in ˆC as in C , and(cid:3)(cid:3)(cid:5)(cid:5)(cid:3)(cid:3)w 1= πw 1Λ(cid:3)⇒ ˆπ (Z = z) ≡ ˆπΛ(cid:5)(cid:5)(cid:3)Λ∀w 1 ∈ W 1(cid:3)= πW 1z(cid:5)(cid:5)Λ(cid:5)(cid:5)(cid:3)W 1z≡ π (Z = z)ˆπSoˆπ ( ˆY = y) ===References(cid:10)z(cid:10)ˆπ ( ˆY = y | Z = z) ˆπ (Z = z)(cid:5)(cid:5)(cid:14)−1π(cid:5) (cid:4)(cid:4) ΛW 2(cid:13)πΛ(cid:3)(cid:3)(cid:3)W 1z(cid:3)(cid:3)ΛW 2(cid:5), Λ y(cid:3)(cid:4)(cid:4) ΛW 1z(cid:5)(cid:5)(cid:3)(cid:3)ΛπW 1z(cid:5)(cid:5)z(cid:10)(cid:11)zπ (Y = y, W , Z = z)π (W , Z = z)(cid:12)π (Z = z)(cid:2)[1] T. Bedford, R. Cooke, Probabilistic Risk Analysis: Foundations and Methods, Cambridge, 2001, pp. 99–151.[2] C. Boutilier, N. Friedman, M. Goldszmidt, D. Koller, Context-specific independence in Bayesian Networks, in: Proceedings of the 12th Conference onUncertainty in Artificial Intelligence, Portland, Oregon, 1996, pp. 115–123.[3] R.E. Bryant, Graphical algorithms for Boolean function manipulation, IEEE Transactions of Computers C 35 (1986) 677–691.[4] G.A. Churchill, Accurate restoration of DNA sequences, in: C. Gatsaris, et al. (Eds.), Case Studies in Bayesian Statistics, vol. 2, Springer-Verlag, 1995,pp. 90–148.[5] A.P. Dawid, Causal inference without counterfactuals, Journal of the American Statistical Association 95 (2000) 407–448.[6] A.P. Dawid, Influence diagrams for causal modelling and inference, International Statistical Review 70 (2002) 161–189.[7] A.P. Dawid, V. Didelez, Identifying the consequences of dynamic treatment strategies, Research Report 262, University College London, 2005.[8] A.P. Dawid, J. Moertera, V.L. Pascali, D. Van Boxel, Probabilistic expert systems for forensic inference from genetic markers, Scandinavian Journal ofStatistics 29 (2002) 577–595.[9] G. Freeman, J.Q. Smith, Bayesian MAP model selection of Chain Event Graphs, Research Report 09-06, CRiSM, 2009.[10] S. French (Ed.), Readings in Decision Analysis, Chapman and Hall/CRC, 1989.[11] S. French, D.R. Insua, Statistical Decision Theory, Arnold, 2000.[12] D. Glymour, G.F. Cooper, Computation, Causation and Discovery, MIT Press, 1999.[13] D. Hausman, Causal Asymmetries, Cambridge University Press, 1998.[14] D. Heckerman, A Bayesian approach to Learning Causal Networks, in: W. Edwards, et al. (Eds.), Advances in Decision Analysis, CUP, 2007, pp. 202–220.[15] S.L. Lauritzen, Causal inference from graphical models, in: O.E. Barndorff-Nielsen, et al. (Eds.), Complex Stochastic Systems, Chapman and Hall, 2001.[16] R. Lyons, Random walks and percolation on trees, Annals of Probability 18 (1990) 931–958.[17] A.M. Madrigal, J.Q. Smith, Causal identification in Design Networks, in: L.E. Sucar, et al. (Eds.), Advances in Artificial Intelligence, vol. 2, Springer Verlag,2004.[18] D. McAllester, M. Collins, F. Periera, Case factor diagrams for structured probabilistic modeling, in: Proceedings of the 20th Conference on Uncertaintyin Artificial Intelligence, 2004, pp. 382–391.[19] J. Pearl, Causal diagrams for empirical research, Biometrika 82 (1995) 669–710.[20] J. Pearl, Statistics and causal inference: A review, Sociedad de Estadistica e Investigacion Operativa. Test 12 (2) (2003) 281–345.[21] J. Pearl, Causality Models, Reasoning and Inference, 2nd edition, Cambridge, 2009.[22] J. Pearl, J.M. Robins, Probabilistic evaluation of sequential plans from causal models with hidden variables, in: Proceedings of the 11th Conference onUncertainty in Artificial Intelligence, 1995, pp. 444–445.[23] D. Poole, N.L. Zhang, Exploiting contextual independence in probabilistic inference, Journal of Artificial Intelligence Research 18 (2003) 263–313.[24] E.M. Riccomagno, J.Q. Smith, The geometry of causal probability trees that are algebraically constrained, in: L. Pronzato, A. Zhigljavsky (Eds.), OptimalDesign and Related Areas in Optimization and Statistics, Springer, 2008, pp. 131–152.[25] J.M. Robins, A new approach to causal inference in mortality studies with sustained exposure period – application to control of the healthy workersurvivor effect, Mathematical Modelling 7 (1986) 1393–1512.[26] A. Salmeron, A. Cano, S. Moral, Importance sampling in Bayesian Networks using probability trees, Computational Statistics and Data Analysis 34 (2000)387–413.[27] G. Shafer, The Art of Causal Conjecture, MIT Press, 1996.[28] J.Q. Smith, P.E. Anderson, Conditional independence and Chain Event Graphs, Artificial Intelligence 172 (2008) 42–68.[29] J.Q. Smith, P.A. Thwaites, Decision trees, in: E.L. Melnick, B.S. Everitt (Eds.), Encyclopedia of Quantitative Risk Analysis and Assessment, vol. 2, Wiley,2008, pp. 462–470.[30] P. Spirtes, C. Glymour, R. Scheines, Causation, Prediction and Search, Springer-Verlag, 1993.[31] P.A. Thwaites, Chain Event Graphs: Theory and application, PhD thesis, University of Warwick, 2008.[32] P.A. Thwaites, J.Q. Smith, Non-symmetric models, Chain Event Graphs and propagation, in: Proceedings of the 11th International Conference on Infor-mation Processing and Management of Uncertainty in Knowledge-Based Systems, Paris, 2006, pp. 2339–2347.[33] P.A. Thwaites, J.Q. Smith, R.G. Cowell, Propagation using Chain Event Graphs, in: Proceedings of the 24th Conference on Uncertainty in ArtificialIntelligence, Helsinki, 2008, pp. 546–553.[34] J. Tian, Identifying dynamic sequential plans, in: Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence, Helsinki, 2008, pp. 554–561.[35] J. Tian, J. Pearl, A general identification condition for causal effects, in: Proceedings of the 18th National Conference on Artificial Intelligence, AAAIPress, 2002, pp. 567–573.