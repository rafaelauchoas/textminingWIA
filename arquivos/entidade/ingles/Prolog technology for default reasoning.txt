ELSEVIER Artificial Intelligence 106 (1998) l-75 Artificial Intelligence P’rolog technology for default reasoning: proof theory and compilation techniques Torsten Schaub a**, Stefan Briining b$l a Institut fiir Informatik Universitiir Potsdam, Posrfnch 60 15 53, D-14415 Potsdam, Germany b TLC GmbH, HahnstraJe 43a, D-60528 Fran&curt, Germany Received 24 February 1997; received in revised form 3 June 1998 Abstract The aim of this work is to show how Prolog technology can he used for efficient implementation of query answering in default logics. The idea is to translate a default theory along with a query into a Prolog program and a Prolog query such that the original query is derivable from the default theory iff the Prolog query is derivable from the Prolog program. In order to comply with the goal-oriented proof search of this approach, we focus on default theories supporting exemplified by so-called semi-monotonic default theories under Reiter’s interpretation, local proof procedures, as this does not capture general it does so under alternative ones’. theories. Although default For providing theoretical underpinnings, we found techniques upon a top-down proof procedure based on model elimination. We show how the notion of a model elimination for proof can be refined implementing and improving model elimination theorem provers (regularity, lemmas) can be adapted to default reasoning. This integrated approach allows us to push the concepts needed and extended for handling defaults from the underlying calculus onto the resulting compilation to capture default proofs and how standard the resulting compilation techniques. techniques theorem proving This meth’od for default to incremental consistency checking. We show that the crucial task of consistency checking can benefit from keeping models in order to restrict the attention to ultimately necessary consistency checks. This is supported by the concept of default lemmas that allow for an additional avoidance of redundancy. 0 1998 Elsevier Science B.V. All rights reserved. by a model-based is complemented approach Keywords: Defmlt reasoning; Automated reasoning; Default Logic; Model elimination; P’lTP, Model-based consistency checking * Corresponding author. Email: torsten@cs.uni-potsdam.de. ’ Email: Stefan.Brnening@tlc.de. 0004-3702/98/!6 -see front matter 0 1998 Elsevier Science B.V. All rights reserved. PII: SOOO4-3702(98)00092-7 2 I: Schaub, S. Briining /Artificial Intelligence 106 (1998) 1-75 1. Introduction In many AI applications default reasoning plays an important role since many subtasks is why there is a great need for In fact, the two of the underlying problems to default reasoning. Therefore, systems. For this undertaking, we reasoning from incomplete information. This involve systematic methods that allow us to integrate default reasoning capabilities. last decades have provided us with a profound understanding and have resulted in well-understood we are now ready to build advanced default reasoning have chosen Reiter’s default logic [71] as our point of departure. classical inferences formal approaches logic by dejbdt Default logic augments rules in sanctioning is represented from standard that rely upon given as well as absent information. that differ rules in default logics by default has two types of antecedents: inference (D, W) consisting of a Knowledge set of formulas W, also called facts, and a set of default rules D. A default rule consistent if a! is derivable y If both conditions hold, the and a justijication (sanctioned by default consequent y is concluded by default. A set of such conclusions logic) is called an extension of an initial set of facts: given a set of rules and classical formulas W and a set of default rules D, any such extension E is a deductively closed set of formulas containing W such that, for any ,6 which is established I_I which is established if /l is consistent. a prerequisite theories introduction to default logic is given in if a E E and -/I 4 E then y E E. (A formal Section 2.) In what the underlying the basic approach in implementing for determining whether a formula to query is in some that address this problem follows, we are interested that allows answering logic in default extension of a given default theory. 2 Unlike other approaches theorem prover as a separate module, we are proposing a by encapsulating theorem rather different approach that integrates default reasoning classical provers. to center the overall approach around local theorem provers, it is more or less indispensable that allow for deciding whether a set of default proof procedures rules forms a default proof by looking at the constituent rules only). This is because such procedures permit validating a default inference step during the goal-directed proof search in a locally determinable way (see Section 2 for details). In order to comply with the methodology into existing automated (i.e., proof procedures query-oriented underlying The methodology presented in this paper has its origins in an approach in [79]. This approach logic, which renders to default query the notion of a default proof into a by for implementations [79] furnishes a mating- of default proofs inside the framework provided by the connection answering proposed for classical calculus means of existing based characterization method in so-called semi- calculus monotonic default logics. (The advantage of these default systems is that they allow for the integrates it especially qualified theorem provers. To be more precise, Schaub [ 151. This results in a connection for query answering * Membership in all extensions is actually computable by appeal to a procedure testing membership in Verne extension (see [89]). 1: Schaub, S. Briining /Artij?cial Intelligence 106 (1998) I-75 3 aforementio’ned numerous implementations theorem prover SETHEO as a member of the family of connection local proof procedures, as we detail in Section 2.) In fact, there are already of connection calculi. Most of them, like the high performance [53] which can be regarded [47], are based on model elimination calculi. implementation first, we provide We draw on this relationship in this paper and show how an implementation technique namely Prolog Technology Theorem Proving (PTTP) [87,88], can can thus be looked at from different default for (semi-monotonic) theorem prover by means for handling proof for lemmas) can for model elimination, be used for (default reasoning. Our overall contribution perspectives: logics. Second, we extend an existing automated default information. can be refin’ed to capture (semi-monotonic) implementi:ng be adapted and extended somehow as a logic programming default negation. to default reasoning. And finally, one can view our contribution In particular, we show how the notion of a model elimination default proofs and how standard techniques and improving model elimination disjunction, classical as well as theorem provers (regularity, integrating techniques system procedure the deductive As anticipated above, we address In these formalisms, to default reasoning. is added to a standard to techniques borrowed To give a, more precise overview of our approach, we start by noting the consistency-based approaches of a consistency-driven is among logical formalization explained above, this is done in default logic by means of the justification In this way, default reasoning task. Of course, this carries over to the resulting proof procedures that default logic a logic. As of a default rule. is mapped onto a deductive task and a consistency checking too. task of default query answering by appeal from Prolog Technology Theorem Proving. The idea is to translate a default theory along with a query into a Prolog program and a Prolog query theory iff the Prolog such that the original query belongs query is derivable theoretical underpinnings, we found techniques upon a top-down proof procedure based on model-elimination. of default query answering given in [79], which also integrates into a calculus for classical needed for handling defaults from the underlying into the resulting compilation procedure, the task of consistency the notion of a default proof logic. This integrated approach allows us to push the concepts proof This proof procedure has its roots in the mating-based from the Prolog program. For providing calculus, over the corresponding to an extension of the default the first interesting question the resulting compilation for query answering, characterization As regards is whether techniques. checking, that a formula subproofs” while reducing checking. For this, we observe the computational is consistent we can find a way of pruning “inconsistent (or efforts for consistency iff it has a model. This to leads us to the following satisfiable) checking: we start with a model of the initial set of facts. Each time, we consistency default apply a default rule, we check whether logic). If this is the case, assumptions If not, we try to generate a new model of the initial set of facts we continue proving. the partial default proof satisfying at hand. If we succeed, we simply continue proving under the new model. Otherwise, we know that the considered default assumption cannot be assumed in a consistent way (since of our current default proof with the default rule at there is no model for the continuation the current as well as all default assumptions underlying (which can be done in linear time in propositional the actual model satisfies the underlying incremental approach 4 I: Schaub, S. Briining /Artificial Intelligence 106 (1998) 1-75 hand). In this way, we restrict ones. the generation of new models to the ultimately necessary is then whether a simultaneous The second interesting question checking allows for proof procedures benefiting sharing. This is important sources of (putative) exponential proving and satisfiability and information even orthogonal that query answering the idea is to communicate This communication traditional usage of lemmas for improving as a communication drastic reduction of the search space in case a new model has to be generated. treatment of theorem from structure since the two tasks encompass genuine and as reflected by the fact this issue, to a model generator. lemma handling. That is, apart from the logics information is accomplished by (default) two such processes. We will see that this allows for a inferential processes, we use them furthermore from the theorem prover [42]. For addressing device between is El-complete complexity, in default The paper is organized as follows. After inserting the current work into the literature, logic along with its basic proof theory furnishes to default (semi-monotonic) for query answering then a model-elimination in Section 2 an introduction that is proven to be sound and complete theories, see below). Section 3 introduces the theoretical in Section 5. This section extends we provide (for normal default in (normal) default calculus techniques of the compilation foundation logic. This calculus the work found in [75]. While our integral introduced approach addresses full-fledged default logics, which support local proof procedures, we restrict our exposition up to Section 6 to so-called normal default theories for over a propositional theories carry over to consistency the general case without any modifications. Hence, we present in Section 4 our model- based approach to consistency checking with normal default theories. This section extends to general default theories the work found in [20]. We ultimately lift the overall approach in Section 6. We accomplish approach of Section 4 in the model-based order to encompass the variety of consistency checks found in existing default logics. This builds on the work in [76]. As a final outcome, we obtain a PTTP-based platform for query answering language. This restriction checking all techniques developed in default logics that support local proof procedures. is justified by the fact that except for normal default this by extending implementation We draw the reader’s attention of our approach, such as proof theoretical right from the start to the fact that this paper focuses issues and compilation on the fundamentals techniques. A more detailed description experimental techniques along with the resulting “object-code”. analysis can be found in [59]; a companion paper on further implementation is in preparation, For an impression, consult Appendix A containing an example of the resulting system along with more Our system is freely available at [83]. Documentation and sets of test cases can be In order to make use of the system you will need a obtained standard Prolog system, preferably Eclipse Prolog. from the same location. In what follows, we assume the reader to be familiar with the basic concepts of propo- logic [ 10,321 and we presume some acquaintance with automated the paper, treats variables over is regarded is not considered). We sitional and first-order theorem proving we deal with the propositional a finite universe (in the rudimentary as the representative of all its ground instances; give some details of this in Section 5.2.5. sense that a formula or a rule, respectively, thus, skolemization case, even though our implementation language Prolog [27]. Throughout [15,53] and programming T. Schaub, S. Briining /Art$cial Intelligence 106 (1998) l-75 5 1.1. Related work The question of determining whether a formula framework of extension the approaches the construction it was extended to those containing like [2,11,25,45,50,63,81,82], integrating default reasoning or related decision procedures, in [71]. An alternative approach was recently proposed is in some extension of a given default in [79]. of like [62, [45] and Levy [50] propose truth maintenance [ 1 l] reduce default reasoning to a constraint into inference theory was first addressed In contrast to this, most of the work found in the literature focuses on the determination entire extensions, either by look-up operations 631. In the former approaches, queries are then answerable the query at hand. or by rest:ricting based systems. Ben- Junker and Konolige satisfaction problem. Eliyahu and Dechter systems for classical Among of extensions of logic, we find in 1821 a tableaux-based in [81] theories; normal default tableaux and to justified and constrained default logic in (721. In this framework, clausal this, Amati are used Sor capturing maximal and consistency et al. [2] use parallel tableau. checks. In both approaches, is proposed. Another hybrid method a sequent calculus based This system consists of three parts: a classical LK-calculus, rules. Along on “antisequents” for skeptical this line of research, Bonatti and Olivetti to these approaches, many others, like [5,25,45,63, reasoning in default theorem 7 11, abstract from an underlying prover mo’dule furnishing an oracle for classical relations. There is also a variety of approaches addressing certain fragments of default logic, like [ 13,18,7 1,821, and notably Poole’s Theorist framework inference [16] propose a sequent calculus default for capturing at once default final extensions are then characterized by a resulting is used in [17], where a cut-free sequent calculus inference engine and presuppose an automated rules”. Unlike inferences for the computation and certain default sets of “consistent logic. In contrast classical default for consistency to full-fledged [64,65,67,69]. checking, inference tableaux logic Apart from the context of default logic, we mention the work on automating temic logic, e.g., [61,62], and circumscription, conceptually different from our approach, Gelfond and Lifschitz tion into logic programs, while Przymusinski related to model elimination. e.g., [6,37,39,43,70]. Among autoepis- them, though [37] compile circumscrip- [70] uses a form of linear resolution that is Along techniques the broader for implementing default reasoning, literature. Among them, we find the work of Hoppe theme of our work, that is, the utilization of standard automated there is clearly a broader theorem proving [44] and range of background (default) reasoning in different settings, such as the Sattar [74] dealing with incremental in the latter case. Moreover, a lot of effort has already aforementioned Theorist framework been devoted to specific topics, like consistency lemma handling, etc., on which outcomes we rely without giving a detailed account of the literature. And last but not least we mentia’n the large efforts taken in the logic programming extended Among logic programming for implementing approaches community to default reasoning, checking, [36]. those of the groups around NiemelH [25], also due to the impressive performances arguably Truszczyiiski soning systems. These approaches are orthogonal reasons: (i) they aim primarily at computing entire extensions an exposed position is [63] and around Marek and exhibited by their default rea- to the one proposed in this paper for three (comprising query answer- the aforementioned held by 6 I: Schaub, S. Briining /Art$cial Intelligence 106 (1998) 1-75 the underlying theorem prover. Moreover, Niemela ing in the aforementioned way), (ii) they deal with Reiter’s original default logic only, and (iii) they encapsulate [63] puts strong techniques, while Cholewidski et al. [25] discuss in depth emphasis on conflict resolution (see below). In this paper, we shift the emphasis the influence of stratification techniques, while adopting towards the utilization of classical automated a query-oriented (As regards (iii), we acknowledge since we use an independent Davis-Putnam that relies on local proof procedures. perspective on default reasoning is also not fully homogeneous that our final implementation [28] for model-finding.) theorem proving techniques procedure As mentioned in the introductory section, our decision is motivated by the desire of integrating to center the approach around it into an existing goal- local proof procedures the validity of each oriented, top-down automated inference step when it is performed in order to improve upon proof search. A related aim is found in approaches splitting default theories into smaller parts in order to apply default [26] reasoning takes up the notion of stratification [3], which provide a salient part of the DeReS system [25]. them, we find [26,33,90]. For example, Cholewinski theorem prover. We thus aim at verifying in a local way. Among in logic programming techniques known In all, our restriction to default theories supporting local proof procedures (exemplified default theories) of the default the deductive power of advanced should be seen as a compromise between by semi-monotonic ultimate goal to exploit expressiveness fact that default logics denying semi-monotonicity, necessitate setting is incompatible with the idea behind local, goal-oriented proof procedures; requires a more global approach explains why many of the aforementioned are primarily in the computation the inspection of the entire set of default rules anyway. (i) our inference engines and (ii) the theories under consideration. The latter has to do with the like Reiter’s full-fledged default logic, the inspection of aZE default rules for answering no matter what query. This it rather relying arguably on bottom-up procedures. This also logic their setting necessitates approaches of entire extensions: to Reiter’s original default interested 2. Default logic This section introduces Reiter’s classical default logic along with some important formal concepts needed for providing a proof theory adequate for our purposes. section, default in the introductory As already sketched logic augments classical logic by default rules of the form 3 !G! . Such a rule is called normal if B is equivalent to y; it if /I impli& y . We sometimes denote the prerequisite u of a default is called semi-normal y by Conseq(G). rule 6 by Prereq(G), its justification in D; ./z&f(D) Accordingly, Prereq(D) and Conseq(D) are defined analogously. A set of default rules D and a set of consistent formulas 4 W form a default theory (D, W) that may induce a single or multiple extensions in the following way [7 11. /? by Justif(S) is the set of prerequisites and its consequent of all default rules 3 Reiter [71] considers default rules having finite sets of justifications. Marek and Truszczyriski [57] show that any such default rule can be tmnsformed into a set of default rules having a single (or no) justification. 4 The restriction to consistent set of facts is not really necessary, but it simplifies matters. T. Schaub, S. Briining /Art@icial Intelligence IO6 (1998) 1-75 7 Definition 2.1. Let (D, W) be a default theory. For any set of formulas S, let r(S) be the smallest set of formulas S’ such that: (1) w c S’; (2) Th(S’) = S’; (3) for any y E D, if a! E S’ and S U {j3} is consistent then y E S’. A set of formulas E is a classical extension of (D, W) iff r(E) = E. Observe that E must be a fixed point of r. Any such set represents a possible set of beliefs about the world at hand. it is sufficient logics is most feasible As already put forward in default in in [71], query answering the presence of the property of semi-monotonicity: if D’ C D for two sets of default rules, then if E’ is an extension of (D’, W), there is an extension E of (D, W) such that to consider a relevant subset of default rules E’ C E. Given this property, a query, since applying other default rules would only enlarge and thus while answering preserve a Rartial extension at hand. In Reiter’s default logic, semi-monotonicity is enjoyed by normal default theories. Moreover, all major variants of default logic such as classical default logic [71], justified default logic [55], cumulative default logic 5 [19], constrained default logi’c [30], and rational default logic [58] coincide on this particular fragment. This is why we have chosen normal default theories as an initial exemplar for our approach. We show in Section 6 how general default theories are treated in the aforementioned variants, provided they enjoy semi-monotonicity. In the presence of semi-monotonicity, in a truly iterative way by applying one applicable default rule after another by appeal to a rather local notion of consistency: are constructible extensions Theorem 2.1. Let (D, W) be a normal default theory and let E be a set offormulas. Then, E is an extension of (D, W) ifs there is some maximal D’ 5 D that has an enumeration (6i)iet such thatfor i E I, we have: E = Th( W U Conseq( D’)), W U lConseq({Go, . . . , Si-I}) k Prereq(&), W U ~Conseq({So, . . . , 8i-l)) y -CO%Wq(Gi). (1) (2) (3) This type of characterization was first given in [82], except for condition (3) reflecting an incremental approach, as opposed to a rather global approach requiring W U Conseq(D’) v 1. Condition (2) spells out that D’ has to be grounded in a set of facts W iff there exists an enumeration in W. In general, a set of default (6i)iez of D that (3) expresses the notion of incremental consistency. Here, application of a default rule is checked at each step, whereas this must be rules D is grounded satisfies condition the “consistent” done with respect to the$nal extension (2). Condition in a non-semi-monotonic default logic. 5 This is meant modulo the augmented language used by this system (see Section 6 for more details). 8 Z Schaub, S. Briining /Artificial Intelligence 106 (1998) l-75 These notions lead us to the following notion of a default proof from normal default theories, on which we build our initial formal characterization of query answering: Definition 2.2. Let (II, W) be a normal default theory and (p a formula. A normal default proof for p from (D, W) is a finite sequence of default rules (6i)iC1 with 6i E D for all i E I such that W U {Conseq(&) (2) and (3) are satisfied for all 1 i E I} t- yz~ and conditions i E I. The following immediate consequence of Theorem 2.1 assures that a query is in some extension of the (normal) default theory at hand iff it has a (normal) default proof: 6 Theorem 2.2. Let (D, W) be a normal default theory and cp a formula. Then, q E E for some extension E of (0, W) iff there is a normal defaultprooffor q from (D, W). Now, given the concept of a default proof, let us elucidate That is, for verifying whether q is in some extension of a default theory (D, W), it is enough to determine a grounded and consistent set of default rules D, C D that allows for proving 60 from the facts in W and the consequents of all default rules in OP. the computational for deciding whether a set of of local proof procedures provided by semi-monotonicity: default rules forms a default proof, it is sufficient rules only. A local proof procedure must thus never consider a rule in (D \ Dq) for deciding whether D, is a default proof for some query (o. Note that in the absence of a property like semi- monotonicity consider all default rules in the given the case for general default theories under Reiter’s default theory. 7 This is, for instance, as that we are not interested Finally, we emphasize interpretation. that we draw upon, since such, it is rather this is an essential that we are aiming at. a proof procedure must necessarily feature of the model elimination localness of proof procedures based theorem provers in semi-monotonicity the constituent to investigate the resulting advantage As an example, consider the following set of statements to an allergy against milk products: ’ “children normally usually contains mill<“, “ice-cream in case of a predisposition”. predispo (expressing the following one: that the considered The corresponding contains usually default sugar”, and “milk about a child predisposed “ice-cream eat ice-cream”, is an allergen theory along with facts child A is predisposition) child has the aforementioned child : icecream icecream : milk icecream : sugar icecream ’ milk ’ sugar [child, predispo, milk A predispo -+ allergen} . (4) 6 Since we deal with normal default theories up to Section 6, we omit the prefix norm01 up to this point. 7 Unless it has a particular the proof procedure, structure allowing for “localizing” syntactical for instance by stratification [3] or similar techniques. * This is actually an extremely rich and non-trivial domain for studying default reasoning. Z Schmb, S. Briining /Art$cial Intelligence IO6 (1998) l-75 9 For instance, we can explain allergen from child A predispo by means of default proof: the presence of an allergen in the above situation by proving chilcl : icecream icecream : milk ( icecream ’ milk ’ 1 Importantly, from the query by ignoring irrelevant default rule this proof can be found by a top-down backward-chaining (5) procedure that starts icecream : sugar sugar ’ This illustrates the great advantage of local proof procedures. in the following For the most part of the paper, we follow [79] in dealing with default theories in atomic format (D, W) in language CZ over some alphabet Z, let Lz/ be the language over the alphabet Z’, obtained by adding three new propositions, named og , #?s, ys for each 6 E D. Then, (D, W) is mapped into default theory (D’, W’) in Lx, where sense: for a default theory theory restrict our attention to atomic default rules without (D’, W’) is called the atomic format of the original default The resulting default does not affect the computation of theory, (D, W). As shown in [73], this transformation queries to the original default theory. That is in terms of default proofs, given a query ye in LE, then p has a default proof from (D, W) iff q has a default proof from (D’, W’). We losing generality. The can therefore are advantages of atomic default rules over arbitrary ones are, first, that their constituents them into clausal format (see Section 3) not spread over several clauses while transforming for this and, second, to. The motivations referable are uniquely that these constituents format are somehow similar to the ones for definitional clausal form in automated theorem the naming of defaults was first done by Poole in [67]. proving [31]. For default reasoning, For clarity, we refrain from turning default rules into their atomic counterparts whenever the case with Default to Section 4; they are composed of atomic components. This theory (4). For an example of the transformation Section 5.2 describes is for instance the reader level. its benefits on the implementation is referred 3. Query answering in default logics The aim of this section is to provide formal underpinnings for the compilation in Section 5. As mentioned characterization calculi as a structure-oriented means for characterizing in the introductory of default proofs developed of formulas. For brevity, we refer the reader for details on this approach to be introduced is rooted in the mating-based matings are used in connection unsatisfiability [79] and confine ourselves for a better understanding of the model elimination this section. techniques section, our approach in [79]. Such the to ideas, needed in the major part of in what follows to an introduction to its underlying calculus, presented 10 T. Schaub, S. Briining /Arti$cial Intelligence 106 (1998) I-75 First of all, we introduce the following to L. We mainly deal with formulas complementary which are given by a conjunction such formulas a clause is a set of literals {L 1, . . . , L,] representing is called negative iff it contains only negative literals. of disjunctions in clausal form, that is, a formula conventions: we let Lc denote the literal in conjunctive normal form (CNF), of literals. To ease notation, we denote in CNF is given as a set of clauses, where a disjunction L1 v f . . v L,. A clause The mating-based characterization can be decomposed of default proofs relies on the idea that an atomic implication u + y along with two into a classical conditions on the usage of the resulting clause {-LX, v}; these conditions are Intuitively, both of them rely on a sequence from default rules only, which is induced by the underlying mating of default rules (&)i,~, as given default rule G proof-theoretii referred to as admissibility and compatibility. of clauses, stemming (see [79]). Such a sequence amounts in Theorem 2.1 and Definition 2.2. In fact, while admissibility provides the proof-theoretic counterpart of condition consistency described (2), that is groundedness, to an enumeration the notion of compatibility in condition enforces (3). Now, in order to find out whether a formula p is in some extension of a default theory the default rules in D into a set of first, we transform (D, W), we proceed as follows: indexed implications WD. In our example, this encoding yields the set WD = {childs, + icecreams,, icecreams, -+ milks,, icecreams, + sugar,,). (6) The indexes denote the respective default rules in (4) from left to right. 9 Second, we transform both W and Wo into their clausal forms, Cw and CD. The clauses they are of the form lo { YCQ, ~8); all other clauses are referred In our example, we obtain the following clause set for CW U Co: in CD are called 8-clauses; to as w-clauses. { {predispo}, {child), (-predispo, -milk, allergen}} U { {-childs, , icecreams, 1, [-icecreams,, milks,}, (-icecreamg, sugars,}}. (7) a query 60 is derivable from (D, W) iff is unsatisfiable and agrees with the (mating-based) the set of clauses Cw U CD U and concepts of admissibility Finally, {{-lp}] compatibility. 3.1. A default model elimination calculus For providing the formal underpinnings for our compilation the sequel a proof procedure which finds a (default) CW U CD iff there exists a default proof for (p from (D, W). refutation techniques, we develop in for -(D from clause set [53]. This Unlike [79] though, we address this problem by means of a variant of model elimination a purely declarative (ME) of default proofs, which is much too abstract to provide an adequate basis characterization for the compilation it does not provide means for representing derivations and it cannot reflect the relation between goals in Section 5. In particular, approach provides the mating-based to be introduced is because techniques 9 Of course, these indexes do not influence lo Recall that the atomic format allows us to deal with binary S-clauses only. two literals’ complementarity. Z Schmb, S. Briining /Artijcial Intelligence 106 (1998) I-75 11 In contrast to this, an adequate account of these notions is furnished by and their subgoals. a ME-based approach. The basic inference -allergen an extension step amounts let us consider Intuitively, resolved with an input clause { Lc, K1, . . . , Kn} resulting For illustration, initial goal Tmilk can then be resolved with clause step renders the inference system complete is solved if it is complementary obtain the set {-allergen, steps; this allows for applying subsequently and milk. steps of ME-based calculi are called extension and reduction step. a subgoal L is to Prolog’s use of input resolution: in the new subgoals K1 , . . . , K, . the clauses in (7) along with query allergen: we can resolve subgoal and so on. The reduction clause logic: a subgoal l1 In our example, we thus extension steps to putative subgoals allergen -milk] of ancestor goals after the two aforementioned -milk, allergen]. The resulting to one of its ancestor subgoals. for (full) propositional {milks,, Acecreams,} with clause {-predispo, reduction default reasoning first, one has to take care of groundedness For incorporating adapted appropriately: this end, we have to guarantee (i) only ye is resolved upon, and (ii) after such an “extension the resulting subgoal -cog must not be used for subsequent each such “extension step” must guarantee (cf. condition Among into such a calculus, both inference steps have to be (2)). To that whenever a d-clause {-US, ys} is used as input clause, step” the ancestor goals of reduction steps. Moreover, (iii) the consistency with the previous proof segment the diverse mouldings of ME-based calculi, we consider a variant that relies on (cf. condition (3)). so-called ME-tableaux as basic proof objects (cf. [47,48]). Note that the original definition of ME given in [54] is based on so-called ME-chains which, roughly speaking, correspond rather than ME- to open tableau branches from time to chains as basic proof objects time whole derivations during a deduction for checking consistency. Such a global view on derivations is motivated by the requirement (see below). Our choice to use ME-tableaux to consider In what follows, we restrict is furnished by entire ME-tableaux. the definitions for full clause logic can be found in [47,48]). The following to the propositional definitions of the concepts needed for the resulting ME-calculus: case (corresponding list gives definitions Literal tree. A literal tree is a pair (t, h) consisting of an ordered tree t and a labeling function h assigning We say node a in t is labeled with literal L, if h(o) = L. literals to the non-root nodes in t. Successor sequence. The successor sequence of a node o in an ordered sequence of nodes with immediate predecessor o, in the order given by t. tree t is the Clausal tableau. A (CZUUSUZ) tableau 7 of a set of clauses M is a literal tree (t, h) in which {h(ol), . . . , A(o,)} E M for every maximal successor sequence (01, . . . , 0,). Tableau clause and literals. Such a clause (k(ol), . . . , h(on)} E M is called a tableau clause and the elements of a tableau clause are called tableau Ziterals. ’ ’ This is why in implementations these goals are normally accumulated by keeping the one from each previous input clause. 12 T Schaub, S. Briining /Artz$cial Intelligence 106 (1998) 1-75 Depth of a tableau clause. The depth of a tableau clause {h(ot), . . . , h(on)) in a clausal tableau (t, A) is defined as the depth of 01 in t (where the root node oft has depth 0, and the depth of a non-root node in t is the depth of its direct predecessor plus one). Model elimination tableau. A tableau is called model elimination tubkau if each inner node o labeled with a literal L has a leaf node o’ among successor nodes which is labeled with literal Lc. Given a tableau 7 containing 7 by Al(o) (or simply h(o), if clear from the context). some node o, we often denote the literal attached to o in (ME-tableau) its immediate Branch. A brunch of a tableau 7 is a sequence (or, . . . , on) of nodes in 7 such that or is the root of 7, oi is the immediate predecessor of oi+r for 1 < i < II, and o,, is a leaf of7. We sometimes denote a branch nodes, that is, we write (k-(02), . . . , h(o,)) labeled with a literal). (or, . . . , o,,) by a sequence containing the labels of its is never (note that the root node of a tableau Complementary branch. A brunch is complementary if the labels of its nodes 01, . . . , on contain some literal L and its complement Lc. Open and closed branch. In order to distinguish the simple presence of a complementary branch and the detection of this fact, we allow to label branches as closed. Each branch which is labeled as closed must be complementary. A branch which is not marked as closed is called an open branch. Open and closed tableau. A tableau is closed if each of its branches is closed, otherwise it is open. Ancestor node and ancestor literal. Given a branch (01, . . . , on) in an ME-tableau we call oi an ancestor (node) of oj and h7(oi) We denote the immediate ancestor oi of node oi+r by prev(oi). an ancestor (literal) of A7(oj) 7, iff i -C j. Successor node and successor literal. Correspondingly, we call oi a successor (node) of oj and h7(oi) a successor (liter&) of k7(oj) iff i > j. Open goal. Let b be an open branch of an ME-tableau 7. If literal L is the label of the leaf node of b, then L is called an open goal of 7. [allergen, the ME-tableau 7 given in Fig. 1; it contains -predispo} Consider {-allergen), (namely, (-allergen, plementary closed. Closed branches are marked by underlining open branches -milk, allergen), -icecreams,)). they contain complementary (-allergen, lpredispo), Two of these branches (-allergen, -milk, since it is not closed. and {milks,, -icecreams,)) (-allergen, three tableaux clauses (namely, and four branches and -milk, milks,) (the first and third one) are com- literals and can therefore be labeled as their leaf nodes. Since 7 contains The following theorem, proven among others in [49], forms the basis of calculi using ME-tableaux as proof objects: Z Schaub, S. Btining /Art$cial Intelligence 106 (1998) 1-75 13 lallergen allergen lpredispo Tmilk milks, Acecream6, Fig. 1. An M!Stableau of clause set (7) with query allergen. Each node of the tableau except for the root node which is depicted by a. is represented by its label Theorem 3.1. Let M be a clause set. Then, M is unsatis~able $ model elimination tableau of M. there exists a closed Based on the above definitions, we are now apt to introduce the inference steps for the the first inference calculus needed for furnishing model-elimination-based ME-tableaux: it allows to build using so-called w-extension extended by w- and b-clauses check the c~omplementarity of an open goal to some of its ancestors. step; tableaux consisting of a root node and one tableau clause. By tableaux can then be from a given clause set. Finally, reduction steps are used to steps and b-extension steps, respectively, a top-down is the so-called step to be introduced technique generating initialization initial Throughlout the following definitions, some set of input clauses M = CW U Co, comprising of d-clauses. let 7 = (t , h) be an arbitrary yet fixed tableau of and a set CD a set CW of o-clauses Definition .3.1 (Znitializ,ation step). Tableau 7’ is obtained by an initialization following way. step in the l Let o be the root of a one-node tree. Select in M a negative o-clause {L 1, . . . , L, } E M. l Then, attach n new successor nodes to o, and label them in turn with L1 , . . . , L, . ILl,..., L,,) is called top-clause. For extending tableaux, we define two different variants of extension steps. The first is restricted variant this is identical to the extension step in classical ME-calculi. to use input clauses from CW (i.e., w-clauses) for tableau expansion; Definition 3.2 (w-extension in the following way. step). Tableau 7’ is obtained from 7 by an w-extension step . Select in t a leaf node o of an open branch labeled with literal L. Let(Lt,..., L,}beaw-clauseinMsuchthatLC=L~forsomeiE(1,...,n). . Then, attach n new successor nodes 01, . _ , o, to o, and label them in turn with Ll,. . , Ln, respectively. l The new branch with leaf node oi is marked as closed. 14 I: Schaub, S. Briining /Artificial Intelligence 106 (1998) 1-75 from Co, we introduce S-extension For extending tableaux by 8-clauses the fact that defaults are inference rules rather a clause (-crs, ~6) from Co can only be applied with, their definition must reflect formulas: 7~6. Taking into account that ME is a top-down backward-chaining to the application of the underlying default rule. Note that taking { -cz!g w-clause allows for applying a w-extension reasoning by contraposition, which denies Such inferences are disallowed by s-extension step to an open goal a~; this corresponds the inference steps: steps. To begin than to a branch with open goal this amounts , ye} as an ordinary to rule character of default rules. calculus, Definition 3.3 (&extension the following way. step). Tableau 7’ is obtained from 7 by a a-extension step in l Select in t a leaf node o of an open branch labeled with literal L. Let { -cq, ys} be a d-clause in M such that Lc = ys . l Then, attach the two new successor nodes 01 and 02 to o, and label them in turn with -og and ys, respectively. l The new branch with leaf node 02 is marked as closed. vocabulary: the following follows, we need 3.3, respectively), we call oi (02) an o-extension In what (Definition and each element of (01, . . . , o,} \ {oi) ((ol}), w-extension-resulting resulting node), or simply a non-extension node (J-extension extension lited. We sometimes omit the prefixes w- and a-whenever context. node) is called o-extension literal (a-extension node. A literal attached considering Definition 3.2 node (b-extension node), node (A-extension- to an w-extension literal), otherwise non- it is clear from the As argued above, the use of &clauses for tableaux extension must reflect the properties of default rules. Apart from being an inference consistency-preserving step with b-clause this end, it is sufficient in the current derivation. way. Transposed l2 rule, default rules must be applied in a to &clauses, we must guarantee that a S-extension (-US, ys} does not violate consistency criterion to check whether ys is consistent with all other &extension (3) in Theorem 2.1. To literals Definition 3.4 (Compatible S-extension step). Let 7 be a tableau and let { ys, , . . . , ysj} be the set of S-extension literals occurring in ‘7. A d-extension step with S-clause {-a,~, ~8) applied to 7 is called compatible if CW U h, 9 . . .9 ysj } U (~6) is consistent. Observe that although this definition is in accord with consistency (2) flavor, it involves a different set of underlying default their common regarding rules. This is because fashion, while Definition 3.4 relies on a top-down approach. For a default rule 8k in an entire default proof (&)iCI > the former criterion the latter considers default IIlk in incremental the latter condition involves default rules in (& )i<k, while in a bottom-up is conceived condition (8i)i>k. I2 Note that &extension literals correspond (as long as normal default rules are considered) to the justifications of the respective default rules. T Schub, S. Btining /Artificial Intelligence 106 (1998) 1-75 15 lallergen -allergen -allergen allergen lpredispo -milk allergen lpredispo lmilk Fig. 2. The tableaux generated by three derivation steps from clause set (7) and top-clause (-allergen]. * +cecreams, Even though all these conceptions involve multiple default rules or b-clauses, tively, it is always sufficient only. This is due to the notion of localness backed up by semi-monotonicity. less compatibility a more global opposed to I~- and b-extension respec- to those used in the actual derivation Nonethe- treatment as steps. We come back to this issue at the end of this section. the Actually, Definition 3.3 furnishes only one-half of the machinery needed for ensuring has a special status because to restrict our attention it necessitates inference rule character of default rules. Intuitively, reasoning by cases for S-clauses. This is done by restricting step in classical ME-calculi. The sole difference literal -CQ must not be solved by reduction thus exist an independent other words, there must exist a closed ME-tableau with top-clause {-US}. is that subgoals of a S-extension-resulting steps using ancestors of -CQ. l3 There must default proof of -o!g, which ignores all ancestors of -a~, or in this is because we must also eliminate reduction the well-known Definition 3.5 (Reduction step). Tableau T is obtained from I in the following way. l Select in t the leaf node Ok of an open branch b = (01, . . . , Ok) where Ok is labeled with literal L . l If there is an ancestor node oi on b labeled with literal Lc and all nodes Oi+t , . . . , Ok are w-extension-resulting nodes, then mark b as closed. Consider the three tableaux depicted step with top-clause by an initialization from 55 by iapplying an o-extension sole open goal -allergen. The rightmost step with 8-clause &extension in Fig. 2. The leftmost {-allergen}. step with o-clause tableau 7j is generated The second tableau 72 is generated to the tableau emerges from 72 by the application of a -predispo) {allergen, -milk, {Acecreams,, milks,} to open goal -milk. The above inference steps provide us with a sound and complete calculus, as given in the next definition: Definition 3.6 (Default model elimination). A sequence called a DME-derivation for a clause set M (called the set of input clauses) if: (‘Tr, . . . , 7n) of ME-tableaux is l 71 is obtained by an initialization l for 1 K: i 6 n, x is obtained step and from x-1 by applying to 3-1 either - a reduction step, l3 This restriction reflects the property of admissibility, introduced in [79]. 16 I: Schaub, S. Briining /ArtQicial Intelligence 106 (1998) I-75 i -allergen i -allergen allergen Tpredispo Tmilk allergen lpredispo Tmilk Ih - predispo milka, +cecream62 ___ - I h predispo milka, +cecreams, ~ - icecreamg, -child&, icecreams, -childa, I child Fig. 3. Generating a closed tableau from clause set (7) and top-clause (-allergen}. - a w-extension - a compatible &extension step, or A DME-derivation step. is called a DME-refutation if it generates a closed tableau. Observe that each clause used in an extension step is by definition an input clause. (namely For convenience, we sometimes the elements of a derivation identify tableaux) with their generating Pi,...,ln), obtaining z. where each di denotes inference steps: we thus write the instance of the respective the (dl, . . . , dn) instead of rule used for inference Let L be an open goal attached to a node o in an ME-tableau 7. A DME-subderivation 2, for o (or L) is a sequence of derivation steps where the first element of D selects o and each further element selects a descendant of o. ID is called a DME-subrefutation if after applying V to 7, each branch containing o is closed. We sometimes omit the prefix DME whenever it is clear from the context. We continue the example developed in Fig. 2. A DME-refutation as follows: first, a w-extension tableau of the rightmost for query allergen step with w-clause in Fig. 2. Second, a is applied to open goal -predispo step with &clause from clause set (7) can be constructed (predispo) d-extension As a result, we get a tableau (the leftmost tableau in Fig. 3) containing a single open branch. This open branch is closed by the application of a w-extension step with unit clause {child}. Hence, the resulting tableau (the one in the right in Fig. 3) is closed and so we have found a DME-refutation The following of allergen from clause set (7). theorem , icecreams, } is applied to open goal Acecreams,. generating DME-derivations tells us that a mechanism [-childs, in an exhaustive manner constitutes a sound and complete proof mechanism in default logic (here, restricted to normal default theories). for query answering Theorem 3.2. Let (D, W) be a normal default theory and CP be an atomic formula. Let M be the clausal representation of the atomic format of (D, W). Then, there is a defaultprooffor q from (D, W) iff there is a DME-refutation for M with top-clause {IQ”}. Z Schaub, S. Briining /ArtQicial Intelligence 106 (1998) l-75 17 The restriction to atomic queries query formula 4 can always be replaced by an atomic one, say rp, and an additional 4 + q in IV. (This technique It is worth emphasizing is also used by PTTP [86].) that for pure propositional is no limitation of the approach, since an arbitrary formula like ordinary ME (as defined for, example, clause sets without S-clauses, Default in [47]). Model Elimination This is because: behaves exactly l the definitions of initialization steps and w-extension steps are exactly the same as for classical propositional ME-calculi, l 6-extension l if no d-clauses are used during a derivation, DME-reduction steps do not enter the derivation, and steps correspond exactly to classical ME-reduction steps. inspecting the reduction all a-extension implementation. for d-extension step, searching literals occurring The material presented in this section constitutes the latter allows for ignoring check. As a result, all inference logic. The resulting DME-calculus in default and systematic characterization is that it relies on a local proof procedure employing steps of our DME-calculus to compiling query answering with a homogeneous diverse design decisions as regards the ultimate of our approach consistency in a more or less local fashion. This comprises ancestor goals, as well as the verification of compatibility involves though it has nonetheless such a consistency derivations This would amount full clause combinatoric of disjunctions. Another objection is impractic,able of formulas necessary represent and then eventually issue is addressed Section 5. the fundamental basis for our approach provides us of default proofs that leaves room for In fact, a salient feature an incremental are executable among steps which in the tableau at hand. But even the current derivation, check. Of course, speaking, onto “unsuccessful” ME- l4 to to the is infeasible this gets even worse in the presence is that we aim at compiling DME-derivations which sets in Section 4 that it is not even checks, once we can actually check. This in that yield (ordinary) ME-tableaux to a generalization logic. We argue however explosion of (repeated) at least one open branch. mechanism due a special status due to the involved check can be mapped, 3.4). Moreover, we argue perform exhaustive consistency that such an approach saturations; in Section 4 before we introduce reuse the result of a successful since we deal with dynamically of Prolog’s “negation-as-failure” all default clauses outside the actual compilation to continuously for consistency (cf. Definition consistency consistency comprising techniques checking changing roughly 3.2. Extensions and re$nements 3.2.1. Lemma handling Lemma handling is an important means in automated for eliminating (cf. [4]). This task is however more difficult in our context, since proofs redundancy theorem proving may depend on default rules and their induced consistency requirements. In fact, in classical ME-based calculi, a lemma 1 is simply a set of literals that allows all elements of I as labels of its nodes. It is well known for closing each branch containing I4 A similar approach was pursued in [79] with a facile decision procedure. 18 T. Schaub, S. Briining /Art@icial Znrelligence IO6 (1998) 1-75 that, given two clause sets M and M’ with M’ c M, and a lemma 1 (generated during a ME-derivation for M. That is, each branch b generated during a derivation for M containing 1 as a subset of the labels of b can be marked as closed. for M’), then 1 can be applied safely during derivations Unlike this classical approach, in default it is impossible theorem proving. This is because a derivation was generated might depend on a set of d-clauses CDS. The use of 1 during a derivation employing defaults not consistent with CDS would lead to incorrect results. In the context of default theorem proving, we therefore have to extend the concept of lemmas: the subrefutation to simply use such lemmas, like 1, during from which 1 Definition 3.7 (DME-lemma). Let CW be a set of w-clauses, CD be a set of &clauses, and let 7 be a tableau generated from some DME-derivation for CW U CD. Let o be some node 2, in 7 such that each branch in ‘7 containing o is closed, i.e., there exists a subrefutation for o. Further, let 01, . . . , on be the ancestor nodes of o used for reduction steps in D and let M C Cw U CD be the set of input clauses used in D. Then, clause {h(o), k(ol), . . . , h(~,~)] is called a DME-lemma with respect to M and the set of default rules {S 1 {-as, ye} E (CD n M)}. Formal underpinnings for this notion can be given by appeal to so-called lemma default rules [78]. Restricted from (D, W), is constructed to normal default theories, a lemma default rule 61 for a formula 1 from a default proof (&)i,~ for 1 in the following way: 61 = : As,E, Conw@) 1 . in a non-normal default rule, the precise meaning has to be fixed with Since this results respect to a full-fledged default logic. For full-fledged Reiter’s default logic, it is shown in [78] that E is an extension of (D, W) iff E is an extension of (D U {al}, W). Our approach is justified by the following result. Theorem 3.3. Let Cw be a set of w-clauses and CD be a set of d-clauses such that W U Conseq(D) to some subset of is consistent. Let 1 be a DME-lemma with respect Cw U CD and some set of default rules D’ G D. Further let I be a tableau generated from Cw U CD, and let b = (01, . . . , ou, . . . , o,,,) be a branch of 1. by a DME-derivation nodes and 1 c {h(o,), . . ., o,,, are w-extension-resulting then b can . . , h(o,)}, Lf Ou+l, be marked as closed (without losing soundness). As a corollary to this result, we obtain that soundness is preserved when extending DME- derivations with an appropriate Lemma step, which can be given shape as follows. For this, let ‘7 = (t, h) and I= {LI , . _ . , L,} be in accord with Theorem 3.3: Definition 3.8 (Lemma step). Tableau 7’ is obtained from 7 in the following way. l Selectintanopenbranchb=(ol,..., 0 If ov+t,...,o~ K,,, }, then mark b as closed. are w-extension-resulting nodes on b and (Ll , . . . , L, ] E (K,, o,, ,..., o,)labeledwithKl,..., K, ,..., K,,,. . . , I: Schaub, S. Briining /Art$icial Intelligence 106 (1998) l-75 19 The concept of DME-lemmas is further discussed example. 1.n particular, we rely on DME-lemmas information from DME-derivations to an attached consistency checker. in Section 4, including an illustrative in Section 4 for communicating 3.2.2. LOO,D checking by blockwise regularity tableaux It forbids the search space in ME-based two nodes, 01 and 02 say, on Regularity provides a highly efficient means for restricting tableaux containing to generate Unfortunately, to be build during a deduction decreases considerably theorem proving. the same branch such that 01 and 02 are labeled with the same literal. Using this refinement, the number of possible many cases (e.g., see [47,48]). this important for classical ME cannot be applied to Default losing completeness. However, as we will show in the sequel, Model Elimination without to the needs of default reasoning. This leads us to what to adapt regularity it is possible (i) that no subgoal L1 is equal to one of its we call blockwise regularity, which requires literal between Lr and L2, and (ii) ancestors 1:~ unless that no two different a-extension resulting nodes on the same branch have ancestor nodes labeled with equal literals (in other words, there is no need to construct a branch using two &clauses corresponding to defaults with the same consequent). there is a &extension-resulting refinement in In fact, on the pure classical parts of a default proof, blockwise exactly like ordinary regularity, whereas in the parts of a derivation guarantees Besides pruning completeness large parts of the search space, blockwise since it is necessarily violated by infinite branches. that no d-clauses with the same consequent are used for constructing regularity involving b-clauses, regularity behaves it a branch. also guarantees The following definition formal defjnition of blockwise “classical” part of a branch; regularity introduces for a regularity. Roughly spoken, a block can be considered as a the concept of blocks which is required i.e., a block is a part of a branch to which the full (classical) restriction can be applied without losing completeness. Definition 3.9 (Block). Let 7 be an ME-tableau for a clause set M and let b = (01, . . . , on) be a branch of 7. The sequence oi, . . . , oj (i > 1, j < n) is called a block of b iff generated by a DME-derivation (1) Ok i!; the immediate ancestor of Ok+1 for i < k < j, (2) oi is, a a-extension (3) each ok with i < k < j is a w-extension node or a w-extension resulting node or was generated by an initialization step, and resulting node. (3) asserts simply that the literal attached to ok stems from a w-clause in M. Condition For illustration, is represented by its label except the root node which is indicated by l . The start of a block is marked by typesetting the respective consider Fig. 4. There, each node of a branch (The purpose of underlining is explained below.) Then, blockwise is defined as follows. literal in boldface. regularity Definition 3.10 derivation conditions hold. (Blockwise for a clause set M. 7 regularity). Let 7 be an ME-tableau generated by a DME- two is called blockwisely iff the following regular (1) Foreachblockot,..., o,ofabranchof7,h(oi)#h(oj)foralll<i<j<n. 20 T. Schaub, S. Briining /Art.ficial Intelligence 106 (1998) l-75 Fig. 4. Some branches illustrating blockwise regularity. (2) For each branch d-extension We call a DME-derivation blockwisely regular. (01, . . . , on) of 7, L@(prev(oi)) # h(prev(oj)) if oi and oj are resulting nodes for 1 6 i < j < n. regular D blockwisely iff the tableau generated by D is by using &clauses stemming The effect of blockwise Condition (2) asserts simply that there are no two literals on one branch which are proved from defaults having the same consequent. the nodes characterizing the failure of blockwise since these two branches violate condition regularity can be illustrated by the branches shown in Fig. 4, are underlined. An containing one of the first two branches need not to be considered during a (1) of Definition 3.10. The same (2) the same “consequent” Bs, and that the to different blocks. Only the rightmost where ME-tableau deduction, holds for any ME-tableau containing of Definition 3.10. This is because Ba2, respectively, have been used, namely {-As,, Bs, } and { 1 DJ, , BJ, ). Observe two occurrences of 1 B on the third branch belong branch does not violate any criteria for blockwise the third branch since it does not meet condition two b-clauses having regularity. regularity The following theorem guarantees that every derivation generating a non-regular tableau can be pruned away without losing completeness. Theorem 3.4. Let R be a DME-refutation generated by R is not blockwisely M such that the tableau I’ generated by R’ is blockwisely regular: of a clause set M such that the tableau 7 regular: Then, there exists a DME-refutation R’ for 4. Model-based consistency checking This section According compatibility we presuppose is devoted to the last section, of a-extension of incremental to the implementation this amounts checking. for verifying steps. For this, we start by taking an abstract point of view: for along with a mechanism to developing a mechanism consistency a procedure enumerating DME-derivations, I: Schaub, S. Briining /Arti$cial Intelligence 106 (1998) I-75 21 finding models of formulas in CNF. The usage of formulas ones is motivated by the need for continuous modifications reductions) to the formulas handed over to the consistency implemented more effectively for formulas in CNF. in CNF as opposed to arbitrary (like additions and subsequent check. These operations can be situations encounter a-extension incrementally, of the involved steps. The aim is then this search by a potentially Now, when checking consistency to to reuse such a checks as possible. Of course, this reusability of a (partial) default proof. In this way, a model bears witness for reducing computational that allows for pruning “inconsistent and thus, repetitively, we should clearly efforts. Our goal avoid exhau;stive general purpose mechanisms is therefore subproofs” while to furnish an approach restricting exhaustive consistency checks to the ultimately necessary ones. We address this problem by lmeans of a model-based approach: we use a model as a compact representation of the consistency the compatibility model for as many subsequent compatibility depends on the chosen model. Hence, we sometimes have to loolk for a “better” model. We support treatment of theorem proving and model handling. This approach reduced clause sets containing rules (or to be more precise, We refer to such clause sets as model-clause-sets representations for their underlying in the following way. First, each time a default rule applies, the model-clause-set. extension prover are added. Both sorts of added formulas are then used to reduce the model-clause- set at hand. Conversely, a theorem prover may also benefit provided by a model for the current derivation has already proven to be of great value in classical automated In what follows, however, we concentrate on realizing the search for models by transferring finder”. in which we synergistic relies on repeatedly of the applied default in the current derivation). them as compact set of models. Mutual benefits are then obtainable is added to literal of each 6- lemmas provided by the theorem from the semantic account its proof search. This avenue (cf. [SS]). the two former issues, supporting from the theorem prover to the “model That is, for normal default rules, the J-extension step is added to this set. In addition, certain the initial facts and the justifications because we exploit literals occurring theorem proving the b-extension its justification for governing information First of all, let us make precise how we treat consistency checks via model handling: for a set of formulas W and a sequence of default rules W U Conseq((G0, . . . , &_1)). Function V checks whether W U Conseq({So, . . . , Si_l}) -Conseq(&), let m be a model for if (3) (and Definition 3.4): as stipulated in condition (Sj)j<i (m, W, (Sj)j<i) (m’, W, (6j)j<i) if m I= Consed&), if m k Conseq(Si) and for some V(&, (m, W, (Sj)j&)) = I I m' fm m’ + W U {COTLSe~(Gj) 1 j <i}, if there is no m” such that mN b W U {COKWq(Sj) 1 j <i}. Function V gives a general description of our approach while making precise the intuition given above. We refine this specification in the sequel. The following result shows that V provides a sound and complete specification of the consistency condition expressed in condition (3) in Definition 2.1 (and Definition 3.4): 22 Z Schaub, S. Briining /ArtQicial Intelligence 106 (1998) l-75 Theorem 4.1. Let W be a set offormulas and (Si)i,I a sequence of normal default rules. Then, we have for all i E I that if there is a model m of W U Conseq({Go, . . . , &_I}), then there is either a model m’ of W U Conseq({Go, . . . , Si}) such that: V(&, (m, W, (Sj)j<i)> = (m’, W, (aj)j<i) ifs W U Conseq({Go, . ..,6i_l))y-COnSeq(Si) or V(6i, (m, W, (Sj)j<i))=-L iff W U Conseq({Go, . . ..Si-l))k ~CO?ZSeq(&). Observe that m and m’ need not be distinct; At the start of a derivation, m is set to an arbitrary model of the set of premises CW. l5 From a conceptual point of view, it is actually quite easy to read off such a model from the clause set by taking one literal from each clause, while never taking both a literal the w-clause set CW = {{predispo), and its negation. Consider -milk, for Cw: two models allergen)), the first two cases of V. in (7). We obtain [child), {-predispo, thus covering given and that such models are actually partial models that only along their degrees of {predispo, child, -milk) they are refineable (predispo, child, -allergen). fix the truth-values literals; hence, freedom. We rely on this feature in the sequel. of certain Note Whenever a &clause {-as, ys) is selected for a a-extension step in the course of a DME- derivation, we check whether JQ is satisfied by the current model m. In our setting, this can actually be done by simply checking whether 1~6 $ m, due to the nature of m and ~8. If that m U (~6) is a this is the case, ys is added to partial model m. In this way, we enforce model for 'W" {{VS*)3"',{YSi)} u{{YSJ}> (8) y6i stand for the consequents these are given by the S-extension where ~a,,..., derivations, This treatment amounts in Definition 3.4. Otherwise, for carrying on with the derivation. cannot be used in the current situation. literals occurring of the previously used defaults. In DME- in the tableau at hand. steps that is if -M E m, a new model for (8) has to be found If no such model can be provided, S-clause {-CQ, ~6) imposed on a-extension thus to the compatibility criterion relation, For reducing computational efforts of searching new models, we consider the afore- denoted by M, which are simplified yet equivalent variants mentioned model-clause-sets, con- of clause set (8). Coexisting models and model-clause-sets that is, a considered model always satisfies the current nected by the satisfiability equals CW. Dur- model-clause-set. At the start of a DME-derivation of the used defaults and by ing the DME-derivation certain lemmas provided by the theorem prover (see below). The principal idea is then to simpliJj, 44 after each such addition. Hence, in case a new model has to be generated, one does not have to start with the full clause set in (8) but rather a set which is already cut down as much as possible by appeal of previously gathered information. 16, t7 Each such it is then extended by the justifications the model-clause-set are therefore invariantly l5 Such a model exists since we assume W to be consistent (cf. Footnote 4). I6 Notably, such simplifications I7 Note, however, are doable in an anytime manner. that in case derivation steps have to be withdrawn, the corresponding modifications of the respective model-clause-sets have to be withdrawn, too. 7: Schaub, S. Briining /ArtQicial Intelligence 106 (1998) 1-75 23 techniques in automated to unit-reductions and subsumption-deletion, time. While unit-reduction L,] simplification has to be model-preserving, partial models as the original one. In all, simplifications possible further model generations by eliminating we restrict ourselves known reduction out in polynomial i.e., a simplified clause set has to have the same reduce the search space for easing invalid or superfluous ones. In this paper, both of which are well- theorem proving (cf. [23,53]) that can be carried allows us to replace a clause {Ll , . . . , L,} in the presence of some unit clause (LF}, subsumption- by{Ll,...,Li-l,Li+l,..., deletion allows us to remove a clause { Ll , . . . , L,} subsets. In fact, both reductions are essential proof procedures For illustration, in the presence of one of its proper (and Resolution-) based (cf. Section 5). l8 allergies of lively”, “ normally, she is stressed if she is lively children: “the considered child is usually if she is stressed and and must stay at home”, and “normally, scratches”. Also, we know that she was at home and that she had sugar or milk. In her case, milk causes an allergic reaction, as does sugar under stress. Her allergy makes her scratch. This can be represented by the following default theory: consider another set of statements dealing with nutrition [28], one of which is also a part of our implementation she becomes apathetic for Davis-Putnam- : lively lively A home : stress D= livtly’ 3 ( stress 9 stress A scratch : apathetic apathetic IT W = { home, sugar V milk, milk + allergy, stress A sugar -+ allergy, allergy + scratch}. For instance, we can explain why the considered child became apathetic via : lively lively A home : stress stress A scratch : apathetic --, lively ( stress apathetic )- The atomic format of our exemplary default theory (D, W) is (D’, W’), where D’ = : lively R : stress Q : apathetic lively’ stress ’ apathetic , and W’ = W U {lively A home -_) R, stress A scratch + Q}. (9) (10) (11) Let us illustrate our approach by explaining (D' , W’) by means of a DME-refutation for the child’s apathy, apathetic, from theory Cwt IJ Cp U {{-apathetic}]. (12) Figs. 5-9 give five snapshots of the interplay between DME-derivations models and model-clause-sets. in (lo/ 11) by their two first letters in capitalized For brevity, we abbreviate form. and corresponding in what follows the propositions As initial model of CW/, being the first model-clause-set MO, we take mu = {HO, SU, AL, SC, -LI, Q). MO and mu are given on the right of Fig. 5. Intuitivel.y, mu is obtained from Mu by taking HO from the first clause in Mu, SU from the second, AL from the third, etc. Now, we start a DME-derivation by an initialization step with top-clause (YAP}. The resulting tableau with open goal -AP is given on the left of Fig. 5. l8 An elabomted account on effective methods procedure can be found in [34]. Davis-Putnam for simplifying clause sets used in the implementations of the Z Schaub, S. Briining /Artificial Intelligence 106 (1998) I-75 ‘{ HO { MI -MI { SU AL 4T i YAP cWt=Mo = .t { AL { SC 1AL 1LI 4c G i ) } } } } 4iU 1HO 4T m0 = {HO,SU,AL,SC,~LI,Q} Fig. 5. Snapshot one of the derivation of AP. i TAP ‘{ HO { MI { YMI APB, lQ6s M1 = ’ \ ’ SU AL 4T -AL 1LI 4C -SU 4T } } ) } ), { { : AL SC i , { APa, 4T %--2c SC 1AL AL 4T +JJ 4 = m U {APJ,I = {HO, SU, AL, SC, lLl, Q} U {APb3} Fig. 6. Snapshot two of the derivation of AP. tableau steps). Since (the clause set in Fig. 6) contains in Fig. 6 emerges by applying the first S-extension steps (one 6- and four extension The second step uses a-clause {-es, , APs ), three w-extension that model-clause-set Ml Since mo satisfies clause [R, -LI, -HO) has been reduced (mo, W, (83)), we may extend mu to APg, or in other terms, V(63, (mu, W, 0)) equals rnb = mg U {APs,) and continue with mb. Recall that while V deals with total models, we actually account for partial ones by extending thus, the transition them along their degrees of freedom; to {R, -LI) by unit-reduction.) {APs3). (Observe from mg to mb. clause The next S-extension step is applied to subgoal -ST and it uses S-clause {STa,, -&) The following (see the tableau in Fig. 7). Since rn& satisfies ST8, , we may proceed by simply extending rnb to rn{ = rnb U [STs,). Furthermore, we add clause (STa*) to Ml and apply unit-reduction which gives us model-clause-set M2, the clause set in Fig. 7. steps are applied to subgoals (see the tableau in Fig. 8). The second one (a S-extension step) uses S-clause {Lls, ). Notably, rng does not satisfy Lla, . Therefore, we have to search for a new model ml of model-clause-set M3, which emerges from M2 U { (Lls, )) after the application of unit-reduction. Note that due to the rigorous application of unit-reductions, M3 comprises merely 25 = 32 potential models, as opposed to 23 x 33 = 216 in the case of Cwl. Formally, we get three extension -LI, and -HO -RJ~, V(&, (mi, w9 (63,62))) = (ml, w, (83,82, &)), with m 1 = {HO, SU, AL, SC, R, Q, APs, , STs,, Lls, ). i? Schaub, S. Briining /Art@icial Intelligence 106 (1998) 1-75 25 ‘t HO { MI -MI { SU AL { = < { AL SC Mz i A! \ 1 ST: -AL TLI --SC su } > 1 ;, rng = = rnb U {ST& } {HO, SU, AL, SC, yLl, Q, APa3} U {STJ~} Fig. 7. Snapshot three of the derivation of AP. i TAP _----I AP6, lQ6s _---- !i?-,;“c SC ?AL /.------T---- -ST M3 = 4T 2iu AL /----I ST6, -%a /------r--w 12 -7LI I L16, -HO I HO +u SU AL 7AL -SC ‘{ HO { MI { 1MI { { AL SC i A! { ST: Lb, . { ml = {HO,SU,AL,SC,R,Q,AP6,,ST62,Lldl} Fig. 8. Snapshot four of the derivation of AP. Now, the DME-derivation has reached a point where four subgoals, namely -LI, -HO, - RJ,, and -ST, are proven. According to Definition 3.7, we have that: is a DME-lemma with respect to {(HO}} and the empty set of defaults, l {-HO} l {-LI] is a DME-lemma with respect to {(Lls]}} and {Sl}, is a DME-lemma with respect to [{HO}, is a DME-lemma with respect to ((HO}, l {-Rs2} l (-ST} (Llsl }, (R, -LI, ILlsI}, (R, -LI, -HO}} and (al), and -HO], (STs,, -Ral}} and I’%, 821. In other words, we have shown that each open branch of a tableau generated by a DME- derivation from (13) 26 Z Schmb, S. Briining /Artificial Intelligence 106 (1998) l-75 . I TAP ‘f HO { MI SU { M4 = < { SC R ; A: { ST: Lb, { AL .{ Fig. 9. Snapshot five of the derivation of AP. can be marked as closed, if it contains one of -tLI, -HO, 7Ra2, or -ST. It is important can be exploited in a model-clause-set. to realize that this information for reducing even more the number of potential models This is because each partial model found in, for instance, Ma is also one in (13), l9 or, in the other way round, each set of lit- erals being no model of (13) cannot be a model of M3, either. Formally, we can capture this in Section 3.2.1: for a DME-lemma 1 as introduced idea by the concept of DME-lemmas, for a clause set M, no partial model in M contain- generated from some DME-derivation for a model of M. This is because ing 1 as a subset has to be considered while searching each DME-derivation (see the considera- tions after Theorem 3.2). Hence, the generation of a DME-lemma that -E is entailed by M. As a consequence, A4 implies as a subset must be invalid and can be ignored. I from some clause set each potential model containing 1 can be considered as a classical ME-derivation For simplification issues, so-called unit lemmas consisting of singleton sets of literals such a DME-lemma {L}, the clause {lL} are of particular interest. In fact, after generating and used for simplification. Other (non- can be added to the respective model-clause-set for a model in a unit) default lemmas can be used as a kind of constraints: while searching model-clause-set, as a sub- set. Moreover, there is no need for a consistency check, since all of these lemmas are drawn to the current default proof. We discuss such so-called relative dynamic to default rules belonging in Section 5.2.1. lemmas one can skip every potential model containing a DME-lemma Turning back to our running example, we could now take advantage of the generated the cor- cannot be and {-ST}. However, M3 already contains (negated) unit clauses and therefore these particular DME-lemmas DME-lemmas responding {-HO), [ -LI), I-R} lg This is because (i) each model-clause-set used in a derivation, a subset of it is added to the respective model-clause-set. contains C W, (in a simplified form), and (ii) whenever a S-clause is I: Schaub, S. Briining /Artificial Intelligence 106 (1998) 1-75 27 of M3. Nevertheless, steps illustrated by the tableau can be useful. Such a situation there are situations where the ex- is given after the following in Fig. 9 (note that these steps do not use -AL and +.C are proven; hence we negated unit clauses to M3 (note that we do not have to extend turns out to provide a useful -AL since adding the resulting unit clause {AL) to Ms allows for two subsequent used for further simplifications ploitation of DME-lemmas three inference &clauses). The reader may verify that now subgoals can add the corresponding ml since it iah-eady contains AL and SC). In particular, DME-lemma unit- and one subsumption-reductions. is the one in Fig. 9. Obviously, a new model (which is not needed in our example) could now be found with almost no efforts. The resulting model-clause-set M4 Finally, the sole remaining subgoal which has not been treated so far, viz. -ST, can be proven via the previously generated DME-lemma {-ST}. In all, we: have thus shown that there exists a DME-refutation for clause set (12) with steps was warranted and ml. We have thus shown that AP can be explained by means of the three involved a-extension top clause {-AP). The compatibility by models mu (mb/m$ of default proof (9) from (D’, W’). Apart from the reuse of models as compact representations of previous consistency are doable implementation (since classical of the model-clause-set. are subject to backtracking strategies. One extreme is to trigger simplifications (as shown above to put forward the approach In fact, in an anytime manner. And only the addition of lemmas lemmata can from the set of li-clauses used in a derivation). This leaves room for on each item in principle). checks, the last example puts emphasis on simplifications such simplifications depending on default assumptions be used independently different added to the model-clause-set is to do this by need, that is, only if enforced by a search for a new Another altlemative in a parallel setting, since then the model. The first moulding anytime property allows for continued simplifications without putting brakes on the actual inference engine. In a purely sequential setting, as ours, however, the second variant seems more appropriate, to the ultimately necessary ones. This is why we have chosen the latter option for implementing our model-based approach to consistency checking, as shown in the next section. is arguably very appealing efforts, though polynomial, since the simplification are restricted 5. Implementing query answering from default theories in this section The key observation that led to the results reported for query answering presented ogy in a rather straightforward manner. This is due to the fact that model elimination closely related to Prolog’s linear input resolution for implementation [86-883. As regards classical impressive high-performance vincing performance systems (or similar systems based on the Warren Abstract Machine is that the approach in the previous sections allows us to apply Prolog technol- is [53], which renders it especially qualified by means of so-called Prolog Technology Theorem Provers (PTTPs) theorem proving, in quite proof systems, like [9,41,86]. The main reason for their con- is their ability to take advantage of highly efficient underlying Prolog this approach has already resulted [l]). In what follows, we describe how Prolog technology can be used for implementing fault reasoning systems. As regards classical theorem proving, we follow de- the approach 28 lY Schaub, S. Briining /ArtiJicial Intelligence I06 (1998) 1-75 taken by Stickel’s PTTP [87,88]. PTTP can be seen as an extension of Prolog that pro- In order to attain this, one has to vides a proof system for full first-order predicate calculus. enhance Prolog via measures guaranteeing (ii) complete search, and In what follows, we concentrate on the last item, since we have inference. (iii) complete restricted our exposition to the propositional the classical methods addressing so that we refer the reader for details to [87]. case. In fact, there is no need for modifying the first two issues when dealing with default reasoning, (i) sound unification, 5.1. Implementation by an extended Prolog compiler The standard approach is based on the idea to transform a theory W along with a query q into a Prolog program Pw and a Prolog query Qp such that QV is derivable from PW iff W A -IJYJ is unsatisfiable. while the transformation this approach is conceptually very simple it has proven to be very successful. In this way, the Prolog inference mechanism has to guarantee remains unchanged, of items (i)-(iii). Although the implementation The first step of Stickel’s transformation into a set of Prolog rules. Since a Prolog rule a clauses cation a t b, a first idea would be to transform a clause log rule. More generally, a clause {Ll , . . . , L,} can be transformed Li t LE A ’ ’ ’ A Lf_1 A LF+;1 A . . . A Lh, which is referred into an implication to as a contrapositive of the is a direct translation of a given set of input : - b can be read as an impli- into such a Pro- like (a, -6) original clause. 2o However, in order to guarantee completeness of reasoning by contrapo- sition, one has to generate a Prolog rule for each contrapositive of a clause at hand. Our exemplary clause {a, -b} results thus in two contrapositives consider For further illustration, a t b and -b the classical -a. t contrapositive from {-milk, formulas t in (4). While child and predispo respectively, we t milk A and predispo allergen}, namely allergen t, child -predispo, -allergen A predispo, and -predispo schema [87], this amounts to the following Prolog rules: 21 t -allergen A milk. Following turned into a single are obtain three contrapositives predispo, t -milk PTTP’s translation . child. predispo allergen not-milk not_predispo :- milk, :- not-allergen, predispo. predispo. :- not-allergen, milk. We refer to such rules as o-rules. Prolog’s treatment of each w-rule corresponds extension step using the original clause as input clause, while closing with the head literal. For a set containing n clauses whose maximal cardinality thus obtain at most 12 x m w-rules. into account rule corresponds that Prolog’s inference Taking the branch to an w- labeled is m, we extension step, one obviously has to provide additional means for complete means for reasoning by cases). This is actually accomplished by extending in order to integrate reduction steps (see Section 3.1). Following P’ITP’s translation to the classical ME- inference (i.e., the translation schema 2o Taking commutativity 21 Following F’ITP’s syntax, allergen of A into account, a clause consisting of n literals has thus n contrapositives. etc. stand for allergen and -allergen and not-allergen I: Schaub, S. Briining /Ar@cial Intelligence 106 (1998) 1-75 29 in following way. First, one has to memorize [87], this is achieved adding an additional argument refer to this list as the ancestor or not-milk list (like allergen the ancestor order to allow for testing whether a subsequent memorized) example, we thus get the following ancestors goals by (a list tic) to each literal (see left column below). We list. Second, for each literal that is added in some rule to below) a further rule must be added in to this (possibly rules are given in the right column below. 22 In our subgoal is complementary literal. These additional rules. chil’d (Ant) . predispo (Ant) . allergen(Anc) :- KewAnc = [allergenlAncl, milk(NewAnc) predispo(NewAnc). , notLmilk(Anc) :- NewAnc = [not_milklAnc], rot_allergen(NewAnc) predispo(NewAnc). , not_allergen(Anc) :- member(allergen,Anc). milk(Anc) :- member(not_milk,Anc) . not_predispo(Anc) :- predispo(Anc) :- NewAnc = [not_predispolAnc], not_allergen(NewAnc), milk(NewAnc) . member(not_predispo, AT-K) . For a clause set over an alphabet counting Prolog rules. As shown in [88], the aforementioned a proof system for propositional rules implementing address these issues separately I letters, we thus obtain at most 2 x 1 additional provide clause logic. (For brevity, we refrain from adding Prolog in Section 3.2. We regularity checks and lemma handling, as discussed time transformations in Section 5.2.) compile Let us now turn to the transformations needed for integrating default rules. We have seen in Section 3.1, how a classical ME-based calculus can be adapted for default reasoning, namely classical definition of reduction schema further in order to incorporate steps. In what follows, we advance PTTP’s step for b-clauses and (ii) by restricting (i) by adding a restricted extension these two enhancements. As pointed out in Section 3.1, the definition of J-extension steps reflects the fact that translation the ;are used as d-extension that only literals corresponding defaults are inference rules by demanding of defaults conventional w-extension treat S-clauses and o-clauses {YCQ, ys} equals that of a w-clause, except that only one of its contrapositives for transformation, them from into account, we may thus in an analogous way. In fact, the translation of a &clause is considered namely ya t ~8. This yields a single Prolog literals. This is actually what distinguishes steps. 23 By taking this difference to consequents rule yd : - as. The 22 For further examples, 23 Note that we are not yet talking of compatible S-extension steps at this stage. take any second Prolog rule of any procedure in Fig. A.2. 30 T Schaub, S. Briining /Arti$cial Intelligence 106 (1998) I-75 to a single contrapositive inferences with &clauses restriction it refuses preserving 6’s inference and sometimes abbreviate a S-rule stemming obtain for the default rules in (4) the following Prolog rules: renders reason by contraposition ineffective because like {-as, ~8) to solve an open goal like CQ (thus rule character). We refer to the resulting Prolog rules as S-rules from a default 5‘ by rc . In our example, we icecream :- child. milk :- icecream. sugar :- icecream. In analogy to o-rules, each such &rule describes a possible transition between two tableaux by means of a S-extension step using the underlying default rule. For a clause set containing d &clauses, we thus obtain at most d &rules. As with ordinary clauses, we have to provide means for applying argument memorizing the resulting above, we add an additional extending list is set to the empty list for avoiding this way, the resulting Prolog program steps given in Definition 3.5. For the &clauses reduction implements ancestor reduction steps. As subgoals. But instead of the ancestor steps using ancestor subgoals of ~8. In reduction the restriction of classical in our example, we thus get: list by the head literal ~8 of the considered b-rule, icecream(Anc) child([]). :- milk(Anc) :- icecream( sugar(Anc) :- icecream( transformation for b-extension provides means The next step in our compatibility guaranteeing (partial) model m can be used as a compact representation proof. For implementing further argument mforCwU{{yj}Ij<i}providedthat?I-rtdesrs,,..., in the derivation up to this point. effectuated via b-rules r-6,) . . . , r6r_1 have preserved compatibility. by for checking steps. We have seen in Section 4 that a single of the consistency of a default checking, we add a among others a (partial) model t-s,_, have been successfully applied steps to each generated Prolog rule, containing In this way, m guarantees that all d-extension this model-based to consistency consistency approach When testing compatibility at d-rule rs, , we check whether yai is satisfied by m. (Note in the size of ysi .) If this easy test succeeds, we that such a satisfiability continue by extending partial model m in order to account for ysi. If not, we try to generate a new model m’ satisfying test is linear CWU{{YSj} lj <i}u{(YSil}. If this succeeds, we continue proving with m’. Otherwise, backtracking proceeding guards the compatible application of subsequent &extension to the specification of function V given in Section 4. (14) is engaged. This steps according T. Schub, S. Bribing /Artificial Intelligence 106 (1998) l-75 31 However, in order to be able to generate new models for dynamically increasing decreasing clause sets of form (14), we need an extremely corresponding model-clause-sets. sets along with the current model throughout them into rigid Prolog code. This is why we have chosen to propagate model-clause- instead of compiling the ongoing derivation flexible representation and for the As a consequence, its name suggests-verifies function V is implemented by the run-time predicate compa t i - ble / 3, which-as step with d-rule rsi of & given by ysi. 24 is compatib1.e or not. The first argument comprises the current model m along with the current model- While the second argument encapsulates clause-set, the same information, yet enriched by the informa- tion gathered after a successful application of Q . In case of failure, that is if m b 1~6, and no new model m’ of (14) can be found from the model-clause-set, ble/ whether a J-extension the justification the third argument contains 3 fails, and backtracking predicate compati- is engaged. In all, we thus need two physical variables two physical variables derivation. 13ecause of the tight relationship them by means of binary regroup example: (MM and NewMM) for propagating model-clause-sets (M and NewM) for propagating models and a between models and model-clause-sets, we in our the following &rules throughout functor m/ 2. This yields icecream(Anc,m(M,MM),m(NewM,NewMM)) child([],m(M,MM),m(Ml,MMl) 1, c~ompatible(icecream,m(Ml,MMl),m(NewM,NewMM)). :- milk(Anc,m(M,MM),m(NewM,NewMM)) :- i.cecream( [I ,m(M,MM) ,m(Ml,MMl)), c~ompatible(milk,m(M1,MMl),m(NewM,NewMM)). sugar(Anc,m(M,MYM),m(NewM,NewMM)) :- i.cecream( compatible(sugar,m(Ml,MMl) [] ,m(M,MM) ,m(Ml,MMl)), ,m(NewM,NewMM) ) . that pairs like m (M, MM) correspond Observe rng and M:! or ml and M3. to those used in Figs. 5-9, like for instance Notably, our implementation time whether we check compatibility finding a proof of the original prerequisite. From a &rule ya t CQ we may thus generate one of the following Prolog rules depending on whether we choose, say, compiler option u-corn or corn-a: allows us to decide at compile before or after (a-ccm) ys :- a8, compatible (ys) (corn-a) ya : - compatible (~a), ayg . Under option o-corn, Prolog tries to find a proof of the prerequisite cxg before checking compatibility of ~6, whereas under corn-a compatibility is checked first. 24 Actually, o~ur implemented first argument Icontains the CNF of the justification. See also Section 5.2.4. system deals with default components in negation normal form. Consequently, the 32 I: Schaub, S. Btining /Artificial intelligence 106 (1998) 1-75 Turning back to our example, the first of the above Prolog rules is replaced under corn-o by icecream(Anc,m(M,MM),m(NewM,NewMM)) :- compatible(icecream,m(M,MM) child([l,m(Ml,MMl),m(NewM,NewMM)). ,m(Ml,MMl) ) , (1% the search space in knowledge bases comprising A detailed empirical analysis of both options that a preceding verification of compatibility for pruning conflicts. For instance, for deciding Hamiltonian to much better results observed, less guided by classical for example, on terminological inferencing. 25 than a belated compatibility is given in Section 5.3. We just report here turns out to be extremely valuable (corn-o) a high number of potential this compiler option leads check (a-corn). The inverse can be knowledge bases, where the search is more or cycle problems, From a schematic perspective, simplistic setting 26 by the following predicate compatible/ two Prolog clauses: 3 can be defined in our compatible(K,m(M,MM),m([KIM],NewMM)) :- negated_literal(K,NOT_K), not member(NOT_K,M), reduced_clause_set([[]lMM],NewMM). compatible(K,m(M,MM) ,m(NewM,NewMM) ) :- negated_literal(K,NOT_K), (NOT-K, 1’4) , member reduced_clause_set( model (NewMM, NewM) . [ [KlIMMl,NewMM), teral (Run-time predicate negated_li X. Run-time predicate member / 2 implements sets are represented by lists of lists of literals.) (X, Y) is true if Y is bound the common membership-relation. to the negation of Clause To begin with, we observe that the combination of variable K and term m (M, MM) to the information passed to function V in Section 4 via V(6, (m, W, (Sj)j,J)). amounts While K stands for the justification the current model m along with the current model-clause-set M providing representation the justifications ye of 6 (i.e., Conseq(G) = ya), M and MM represent a compact I j E .I). This is sufficient because V deals only with of W U (Conseq(Sj) (or consequents, respectively) of the considered (normal) default rules. The first clause handles the case where K is satisfied by model M. In our simplistic setting, (NOT-K, M) . In addition, reduced by run- and subsumption- this can be tested by 1~s $ m, expressed by not member model-clause-set MM is extended by unit clause time predicate /2 (involving unit-reductions [ Kl and afterwards reduced_clause_set 25 In fact, the gain in the latter case is not that drastic as in the former case; on the other hand, the inherent complexity of the problem set is also decreasing. 26 This involves (i) one literal justifications normal form, (ii) closed formulas as justifications; details. (due to atomic format) as opposed these restrictions are unleashed to general ones in conjunctive in our system. See [59] for T Schaub, S. Briining /Art$cial Intelligence 106 (1998) l-75 33 as described in Section 4). Finally, ys is added deletions, occurrences’) through Prolog’s head matching. steps in: a new model NewM is computed via run-time predicate model clause-set NewMM, which results from the first clause. to m (neglecting multiple In case 1~s E m, the second Prolog clause / 2 from model- the same reductions as in [Kl and MM by applying This proc:eeding is in accord with our principled for continuous of the model-clause-set. As anticipated at the end of Section 4, we actually that simplifies only by is done whenever a model is reusable, as in the first case. simplifications pursue a more pragmatic approach need. Thus, no simplification This yields the following alternative pattern for the first clause: approach allowing in our (current) implementation compatible(K,m(M,MM) negated-literal not member (NOT_K,M) ,m( [KIM], , (K,NOT_K) . [ [Kl ]MMl) ) :- solution This pragmatic few model s,witches. Investigations with a profiler showed that in such cases considerable CPU-time is justified by the fact that we observe on many examples is consumed by simplification procedures. rather procedure For finding new models (via run-time predicate model the Davis-Putnam for finding propositional models. Importantly, by using information of the model-clause-set lead to a drastic reduction of the search space for finding new models, as illustrated Section 4. Further implementation-based / 2), we use an adapted variant of [28], which is currently one of the fastest complete methods this task is supported by repeated reductions the proof search. This may gathered during in impr.ovements are detailed in [21] (see also [83]). affects also the Prolog rules stemming The propagation of models and model-clause-sets from “classical” clauses, which completes the resulting Prolog program: child(Anc,MMM,MMM). predispo(Anc,MMM,MMM). allergen(Anc,MMMI,MMMO) :- not_allergen(Anc,MMM.MMM) :- NewAnc = [allergenIAncl. member(allergen,Anc) . milk(NewAnc,MMMI,MMMl), ]?redispo(NewAnc,MMMl,MMMO). not_milk(Anc,MMMI,MMMO) :- milk(Anc,MMM,MMM) :- New-c = [not_milklAncl , member(not_milk,Anc). :xot_allergen(NewAnc,MMMI,MMMl) :~redispo(NewAnc.MMMl,MMMO). not__predispo(Anc,MMMI,MMMO) :- predispo(Anc,MMM,MMM) :- :Bew_&nc = [notqredispo\Ancl, member(not_predispo,Anc) . not_allergen(NewAnc,MNMI,MMMl), :nilk(NewAnc,MMMl,MMMO) . The above material provides a (simplified) theory (D, W) into a Prolog program PD,~. For query answering, however, we have to provide like (p. Following PTTP, we use for this purpose a a further recipe for transforming transformation for queries, a default 34 7: Schaub, S. Briining /Art@icial Intelligence IO6 (1998) l-75 Number Purpose Source nxm 2x1 w-rules reduction rules d 1 &rules query rule W D cp > > (nxm)+(2xZ)+d+l W+D+cp Fig. 10. Estimated size of the Prolog code resulting from the basic compilation techniques. along with a Prolog rule of the form query special predicate query the application of this rule is similar treatment of consistency, however, it has to be enriched by run-time predicate model which generates an initial model of C w . Furthermore, list (which is set to the empty list) and to propagate : - (p. Basically, For our / 2 the ancestor the model generated by model step in DME-derivations. the rule has to initialize to an initialization /2. In our example (with query allergen), we thus get schematically the following Prolog rule, where C-W represents a reduced variant of Cw : query :- model (C_W,M) , allersen([l,m(M,C_W),m(_,_)). (16) This rule allows us to pose our initial query allergen via Prolog query ?-query. In all, we thus compile a default theory program PD,w,~ = PD,W U {(16)} along with a Prolog query query. program performance. Subsequent queries are easily posed by replacing and recompiling query rule only. (D, W) along with a query p into a Prolog The resulting leads to its impressive the single using a standard Prolog compiler which is compilable Finally, let us give an estimate on the number of resulting Prolog rules obtained from the compilation of an atomic default theory (D, W) along with query IJJ over alphabet _K’. Let symbols CW contain 12 clauses whose maximal cardinality in Fig. 10. and let D be of cardinality d. The estimate of the resulting code is summarized We refine this first estimate from refinements of our approach. in Section 5.2.6, where we incorporate is m, let Z: count 1 propositional further rules stemming For an impression, consult Appendix A containing some examples treated in this paper along with the resulting “object-code”. 5.2. Extensions, refinements and implementation The previous section has presented our basic approach to implementing default reasoning by taking advantage of the power provided by P’MP Our current implementation refines this basic approach in several ways in order to improve its flexibility and efficiency. This section summarizes the most important improvements. I: Schmb, S. Btining /Artificial Intelligence 106 (1998) l-75 35 5.2.1. Lemma handling We have already stressed in Section 3.2.1, the importance of lemma handling as a means theorem proving. We have also seen that this task for eliminating is more difficult in our context, since proofs may depend on default rules. between for lemma handling: two independent in automated redundancy subtasks We can a.ctually distinguish generation and usage of lemmas: used For generating on the subderivations stleps using ancestor goals outside lemmas, we must have knowledge for deriving them. This is because we must know (i) which subgoals have been solved by and (ii) which reduction consistency assumptions have been made during A-extension steps. This requires recording to be lemmatized. This is done by means of PTTP’s the subderivations the (overall) proof of the proof recording facilities, used in standard PTTP for recording in order query. For this purpose, further arguments must be added to each Prolog predicate to account by further runtime Prolog code for this is complemented extracting for subderivations; the relevant from these subderivations. for each proposition the considered subderivation information is then accomplished by passing a proven subgoal along with infor- to a predicate 1 emma t i z e, which encapsulates from its subderivation mation gathered the actual lemmatization to Prolog rules by simply attaching predicate 1 emma t i z e to the end of the rules’ bodies. At this location of a rule’s body, we are in possession of the entire subderivation, since all subgoals have been proven.. proceeding. Concretely, we add lemma generation Lemma generation For example, in the case of the Prolog rule headed by allergen, we obtain without detailing the extant construction the following rule: allergen :- milk, predispo, lemmatize(allergen) . allergen, subderivations, For propagating are then extended is then passed to lemmatize (allergen) by two additional variables whose outcome by extending to further compilations.) Note that lemma generation does thus not add entire rules to the resulting Prolog code, but rather a single subgoal for each proposition is then of course to be lemmatized. it appropriately. and predispo (The entire subject milk, rule This last subgoal, being composed lemma, and. its proof, does the aforementioned generated database available for later usage. The dumped lemma along with the information (by means of Prolog’s in its final form of predicate 1 emma t i z e, the actual the into the Prolog it becomes subproof analysis and then dumps its proof from assert/l), extracted so that standard predicate items have the following format: lemrrla(Goal,Ancestors,Assumptions). (17) This signifies Ancestors given by the disjunction Section 3.2, a lemma DME-lemma{L,Lt,..., that Goal under consistency assumptions Assumptions. has been proven by means of reductions with ancestor goals itself is then That is in terms of a (Ll , . . . , L,}, {& , . . . , /?A~}) represents and all literals in Ancestors. The lemma of Goal item such as lemma(L, L,} with respect to the set of default rules {St, . . . , 8k}. 36 I: Schaub. S. Briining /Artficial Intelligence 106 (1998) I-75 For using lemmas, we simply add terminating Prolog rules procedure. For resolving schematically a Prolog rule allergen via lemma usage, allergen lemma :- (allergen) . in front of each Prolog thus add for example, we at the top of procedure allergen. For the most part, predicate lemma looks up the Prolog database for corresponding it actually matches in its final form with the lemma items given in (17). Once such lemmas; an item is retrieved, we must (usually 27 ) take into account attached to the stored lemma; and 5. According rule: 28 the consistency this is done via model handling, as described steps of Section 5, we thus obtain to the compilation requirements in Sections 4 the following allergen(Anc,m(M,MM),m(NewM,NewMM)) lemma(allergen,Ancestors,Assumptions), compatible(Assumptions,m(M,MM) :- ,m(NewM,NewMM) ) . the entire rule As above, dealing with disjunctive Ancestors form a subset of those in ~nc. 29 is then subject to further compilations. Among lemmas, addressed by checking whether those the ancestor goals in them, In all, this feature adds at most 2 x I additional Prolog rules, where 1 is the size of the underlying alphabet. In our current implementation, we particularly in an unrestricted mechanisms swamping successful approaches the storage. To this end, we employ lemma fashion leads to the generation of a flood of useless lemmas in take care of the fact that using their roots techniques which have theorem proving. to restrict lemma usage in classical First, we actually distinguish between static and dynamic lemmas (cf. [51]). Dynamic lemmas that disappear lemmas are temporary steps but expires as soon as its own subderivation lemmas is derived during a deduction the number of available dynamic a lemma subsequent derivation Hence, subgoals warranted by the presence of its (compatible) are usable without any consistency checks. 3o For dynamic rule can thus be replaced by the following one: in the tableau under consideration. Notably, it can be used through backtracking: whenever in is tracked back. is limited by the number of proved is the consistent use of such lemmas lemmas the last Prolog lemma handling subderivation. Thus, valid dynamic (via some subderivation), allergen(Anc,MMM,MMM) :- lemma(allergen,Ancestors,_). 27 This applies to static lemmas only; see below for further details. *’ Anticipating clause set. the treatment of general default rules in Section 5.2.4, Assumptions represents actually a 29 While our actual implementation allows for generating disjunctive lemmas, we do actually never use them. We rather concentrate on unit lemmas, whose usage is much more effective. See below. 3o Hence the application of a dynamic lemma has never to be tracked back (see Section 5.2.3). T Schaub, S. Brining /Art$cial Intelligence IO6 (1998) I-75 31 Experiments have shown that the use of dynamic lemmas may result in a significant speed- up, while they practically never harm the proof search due to their restricted viability. This is actually related to a technique is illustrated used for classical ME-based folding-up the (highly effective) technique lemmas theorem proving, namely in Section 5.3. The use of dynamic [48] (or C-reduction [84]). As opposed to this, static lemmas are kept along with their underlying consistency Second, our implementation throughout a whole deduction; this requires verifying compatibility assumptions each time such a lemma is used. These lemmas have thus to be dealt with carefully, since they may flood of useless lemmas swamping lead to the aforementioned to so-called to restrict unit lemmas, which consist of one literal only. Due to the fact that the application of unit lemmas does not depend on the existence of suitable ancestor goals, such lemmas are if clearly more effective dynamic lookup in the database). For dynamic unit lemma handling the last Prolog rule can thus again be simplified: than ordinary ones. Furthermore, can be checked very efficiently the generation of lemmas lemmas are considered) their application (with a simple (in particular the storage. allows allergen(Anc,MMM,MIVM) lenuna(allergen, :- [I,_). In the field of classical strengthening theorem proving, unit lemmas have shown to be inevitable for the deductive power of ME-based proof systems (e.g., see [ 141). 5.2.2. Loop checking by blockwise regularity As described in Section 3.2.2, regularity provides a highly efficient means for discarding in proof systems based on model to one of their ancestor subgoals identical subgoals elimination. As with Ilemmas, we had to adapt this tool for default Section 3.2:2 to what we called blockwise regularity requiring two identical branch must not contain two identical literals to which a S-extension step has been applied. reasoning. This led us in (i) that each block of a literals and (ii) that every branch must not contain regularity). For verifying condition Both conditions can be easily implemented lists (as already put forward in (i) we make use of the fact that the [87] for classical steps. Hence, literals of a block are exactly we simply put in front of each Prolog procedure a further terminating Prolog rule clause that checks whether the ancestor steps contain the literals which can be used for reduction list memorizing potential candidates literals. For instance, two identical for reduction via ancestor allergen (Ant) : - member(allergen,Anc), !,fail. is put in front of the procedure allergen. of any procedure in Fig. A.2. For further examples, take any first Prolog rule For verifying condition (ii), we have to check that after using a S-rule ye : - ag , no b-rule with head ys is used to prove ~6. To this end, we must actually add another list memorizing 38 I: Schaub, S. Briining /Arti&ial Intelligence IO6 (1998) 1-75 the ancestors of b-extension ones for checking condition As with implementing resulting (i)) which prevent derivations violating condition steps, literals, and provide further clauses (similar (ii). reduction or lemma this feature adds at most 2 x 1 to the additional Prolog rules, where 1 is the size of the alphabet. 5.2.3. Avoiding useless backtracking For propositional step to G. The same holds for the application of dynamic clauses it is well known that reduction steps and extension steps with to apply such a derivation unit clauses need not to be tracked back. That is, if it is possible that apply step to some open goal G in a tableau 7, one does not have to check derivations another derivation if a branch with open goal G in a tableau ‘7 can be marked as closed due to the application of a dynamic or extension tableau 7 whose corresponding derivation contains for each b-rule r, used in the derivation of 1, at least one S-extension the application of E to 7 cannot restrict the application of further &extension Fortunately, both enhancements there is no need to check any other derivation step to G in 7. This is because a dynamic lemma 1 can only be applied to a are easily implementable that applies a reduction step with r. Hence, lemmas: lemma, steps. that (i) the Prolog-clauses has to guarantee with unit clauses, and lemma usage are put in front of the Prolog clauses extension steps, and (ii) that each of these clauses ends with “ ! . “. implementing using Prolog’s cut: one only steps reduction steps, extension implementing 5.2.4. General default rules For simplicity, our presentation was so far dominated by default rules having atomic in negation deals with formulas components only. As PTTP, however, our implementation normal form. Let us illustrate this by detailing the transformation of default rule AA(-BvC): -DvE 642 = -DvE ’ To begin with, note that translating this rule into its atomic format yields os4’ ’ I’642 along with (A A (1B v C)) + a~~,, ys42 + -D v E, /3642 + -D v E, y642 B&42 and y642 are new atoms. The obtained into the single contrapositive is then ( ys42 t CQ,,), which is itself turned into d-rule atomic default rule where ~42, transformed gamma(42) This d-rule :- alpha(42). is now -D v E. This furthermore is motivated concern the consistency -+ Bs42 JUstif themselves This is accomplished by wrapping justif but rather woven ication (Justif( into information used by the implications for handling that fact the by provided of form & + check only. These rules are therefore not transformed rule. from term the atomic default into the (intermediate) the S-rule stemming the justification Justif(6i) and adding the latter to the body of the d-rule. In general, we thus generate for any default rule 6i, exactly one d-rule of the following format: gamma(i) :- alpha(i), justification (Justif( . (18) Z Schaub, S. Btining /Artificial Intelligence 106 (1998) 1-75 39 Among is tumedinto Although the further compilation steps, the term formed by means of j us t i f i ca t i on / 1 a call to procedure compatible/3 implications, the two remaining (see below). viz. (A A (-B v C)) + a!gd2 and y642 + -D v E, can now be treated as ordinary w-clauses, we make use of the fact that aa42 for instance, normally, o- and y6/s42 are new atoms occurring (1~6~~ t D A -E), clause { -yg,, (-D is however redundant, t since there is never any rule having -vs,, among its body literals. Generally, we may thus leave out all contrapositives with head -ysi to three contrapositives yad2 A D). The first contrapositive , -D, E) would give rise at particular places only: from ysi + Conseq(&). that are obtained ysd2 A -E), and (E t A similar argument shows that we may eliminate all contrapositives, literals, because rule-bodies having -a!gi among there are no rules with head -CQ. Since PTTP supports the form, we obtain ((118~~ t A A (-B v C)). In general, we thus get for any default & a single in our example directly in negation normal their body furthermore contrapositive w-rule having alpha ( i ) as head and (the negation normal form of) Prereq(&) as body: alpha : - (i ) Prereq(6~). See below for the w-rule obtained results In all, this proceeding in our example. in d-rules sharing the syntactical format given in (18), that are then while the a’riginal constituents treated in the classical way by means of standard HTTP-techniques. of the default rules are pushed into w-rules In concrete terms, our system generates for the above default rule the following (intermedia.te) Prolog code: not__d : - :lot_e, lgamma(42). : _. e 13 I gamma(42). gamma(42) :- , (42) <alpha justification([[not_d, alpha ( 42 ) : - ‘3. I (not-b ; c). From the perspective of default rule AAI:-BvC): -DvE -DvE ’ ell). the first two rules tell us intuitively “apply” the default rule, indicated by gamma. That is, we can prove -D -E and gamma; and we can prove E if we can prove D and gamma. Analogously, -D v E if we can if we can prove the last that we can use its consequent 40 Z Schaub, S. Briining /Art$cial Intelligence 106 (1998) 1-75 for proving rule accounts receive special treatment as a d-rule; all others are treated by standard P’ITP-techniques. ( [ [not-d, the prerequisite. Only the third Prolog rule must subsequently The body of the S-rule comprises the term structure ication justif the clausal representation above, this term is later on turned el I ) containing As mentioned compatible/3. on a membership satisfiability such a test is linear in the size of the clause set. We refer the interested even [83]) for further implementation {I-D, E}} of the default rule’s justification. into a subgoal using run-time predicate does thus not rely in Section 5, but rather a test taking a partial model along with a clause set as arguments. Recall that reader to [59] (or of compatible/3 setting test, as put forward in the simplistic implementation The actual details. In view of these details, we can estimate from default rules in the non-atomic and consequents have at most m literals, we thus obtain for a default theory including d default rules, (m x d) w-rules (for each default, at most (m - 1) with ys in the body and 1 with ~!g as head) and d b-rules (for each default, one &rule). the number of Prolog rules stemming that all prerequisites case: assuming 5.2.5. Variables over afinite universe treatment a word on our Finally, respectively, is implemented thus, skolemization that a formula or a rule, implementation sense of variables. As mentioned treats variables over a finite Herbrand instances; logic, too, it allows for expressing from automated in the introductory universe is regarded as the is not considered. Although things more concisely. and theorem proving that makes Prolog rules range-restricted by inserting unary predicates section, our current in the rudimentary of all its ground representative this boils down to propositional This deductive databases enumerating [22]. In this way, during an inference, every unbound variable of an open goal is bound to a ground term (furnished by the unary predicate). This allows us to handle variables in default rules by Prolog variables and so to avoid the generation of ground occurring in instances. 31 The only particular justifications must occur either in the corresponding restriction we impose concerns default rules: variables for unbound variables violating prerequisite or consequent. the Herbrand universe range-restrictedness by a technique known 5.2.6. Intermediate Prolog code We have already given an estimate on the number of resulting Prolog rules obtained in the basic setting. Let us now make this more precise and further details discussed above. Consider a default theory (D, W) along with query p over in negation an alphabet E counting 1 propositional are in negation normal normal form. Let m be the maximal number of literals occurring constituent of a default rule. The resulting estimate form and let D contain d default rules, all of whose constituents symbols. Let W contain n formulas in the light of the refinements in a formula of W or as is given in Fig. 11. As an example, consider our initial default theory (4). With I = 6, n = 3, m = 3, d = 3, we get 60 Prolog clauses, as a worst case estimate. Without this reduces to 48 Prolog clauses. This has to be contrasted with the actual number of Prolog rules lemma handling, 31 A sort-oriented insertion of ground terms is currently implemented. Z Schaub, S. Briining /Artificial Intelligence 106 (1998) l-75 41 Number Purpose Source nxm 2x1 2x1 2x1 dxm d 1 1 1 w-rules reduction rules regularity rules lemma rules &rules w-rules regularity rule (gamma) lemma rule (gamma) query rule I I > W D v ((n + d) x m) + d + (6 x I) + 3 W+D+cp Fig. 11. Estimated size of the Prolog code resulting from the actual compilation techniques (including lemma handling and blockwise regularity). obtained, which is (without lemma handling) actually 34 only, as testified by the resulting Prolog code given in Fig. A.2. 5.3. Experimental results: a case study This secfon gives a series of experimental results obtained with our implementation, the XRay system [77]. A more detailed report on experiments, further implementation details here on a case study illustrating is given in [21,59] (or even [83]), so that we concentrate the main features of the resulting system. test series generators, and So, for be.ing able to concentrate on the utility of the different features, we have decided series of test cases. This is provided by an encoding of the cycle problem through default theories, as advocated in [24]. 32 This encoding to focus on a parameterizable Hamiltonian is detailed in [59]. To begin with, we give experimental is complemented inferences obtained by varying in Table 1, taken that provides from results on the impact of certain features on the runtime of our system. This time behavior and the number of by Table 2 that focuses on the compile [59], a test series these features. (excluding Table 1 i:s filled with items containing system time), along with the length of the resulting proof and user time33 in 1000 seconds. in parentheses. An entry like > 1000 means that no proof was obtained The test series vary in two respects, leading to four different columns: the first two columns contain results obtained when checking first for the existence of a proof for the prerequisite in seconds, comprising a time measure compile 32 Actually, the encoding maps the Hamiltonian default logic (see Section 6.1); this is arguably discussed after Theorem 6.1. 33 The sum of both system and user time is necessary due to the underlying bi-processor. cycle problem onto a query answering problem the variant of default logic closest to normal default in constrained theories, as 42 I: Schaub, S. Briining /Art$cial Intelligence 106 (1998) l-75 Table 1 Runtime experiments (on Linux Bi-PentiumPro, 200 MHz, 256 MB) ordering lemma handling (Y-corn 1 C orn-cr c people 0.08 (64) 0.08 (50) 0.09 (64) 0.08 (50) ham_4_min 0.01 (36) 0.0 (21) 0.01 (36) 0.0 (21) ham_4_max 424.03 (36) 16.99 (21) 1.34 (36) 0.5 (21) ham_5_min > 1000 > 1000 0.12 (52) 0.06 (26) ham_5_max > 1000 > 1000 7.51 (52) 1.66 (26) ham_6_min > 1000 > 1000 0.37 (71) 0.15 (31) ham_6_max > 1000 > 1000 330.53 (71) 69.72 (31) ham_7_min han_7_max ham_8_min 1 1000 > 1000 1.03 (93) 0.25 (36) > 1000 > 1000 > 1000 >lOoO > 2000 > 2000 11.83 (118) 1.76 (41) ham_8_max > 2000 > 2000 z 2000 >2000 ham_lO_min > 2000 z 2000 27.91 (177) 5.38 (51) ham_lO_max > 2000 > 2000 > 2000 > 2000 ham-2 O_min > 5000 t 5000 >5000 309.4 (101) ham-2 O_max > 5000 > 5000 > 5000 r5OcKl for its compatibility of a default rule and subsequently indicated by o-corn. The order of tasks is switched This is done via the compiler option described at (15). Furthermore, as concerns lemmas was set to dynamic unit lemmas stemming done with blockwise regularity checks and without static lemmas. the usage of dynamic lemmas, indicated by fZ. The configuration (during a &extension in the columns headed by corn-a. step); this is the columns differ for dynamic from default consequents. All tests are constraints, knowledge implications, For a contrast to our scalable given by a taxonomic integrity test series, we place in front a more meaningful base comprising 62 formulas, and default example, including rules, over 40 propositional people, disjunctive symbols. The test vector, obtained by querying a ternary disjunction, our tests on natural and well-structured prover are only rarely corrected by subsequent default-specific examples, efficient query answering underlying for theorem checks. Hence, on such is more or less obtained by means of the power of the the choices of the underlying inference engine. is representative examples: This changes when considering Hamiltonian default theory corresponding and II identifiers and n2 - 1 defaults (see [59] for details on the encoding). 34 For instance, the to a graph with n vertices; it is build over 3 predicate symbols for the nodes. Let us note that ham-n contains only one classical formula this results for cycle problems: we denote by ham-n 34 To be precise, IZ x (n - 1) + (n - 1) due to the special treatment of the starting node. Z Schaub, S. Briining /Artificial Intelligence 106 (1998) 1-75 43 ham-1 5, comprising originally 224 default rules, in an intermediate Prolog code (provided by XRay) containing 904 rules and around 400 kbytes; takes 3.9 seconds, including printing, under Eclipse Prolog (cf. Table 2). its compilation For the first test series, we have actually constructed selected permutations the minimal different we give for each column obtained over these ten permutations. (ham_n_min) randomly of the set of defaults. From for each problem ham-n ten these test series, times and maximal (ham_n_max) This witnjesses the important influence of “programming” can be solved in a time varying to more than 2000 seconds (in ham_8_max) same proble.m, for instance ham_8, ham_8_min) have pushed this a bit further by doing 200 permutations The minimum phenomenon In order to (diminish this influence, we may stick with PTTP’s search (although blockwise over the default set in ham_8. test vector 35 obtained was 0.05 (118), 0.02 (41), 0.04 (118), 0.02 (41). This is due to the fixed search strategy imposed by the underlying Prolog system. iterative deepening proof regularity guarantees a finite search space). the knowledge base, since the from 2 seconds (in in the last configuration. We lemma lemma indicate improve (move(1, inference, in ham-4 ,gamma(7, ) ) andgamma(3, 31, (move(2, lemmas always reduces Let us now take a closer is illustrated by Figs. 12 and 13, where look at Table 1. First of all, we observe the proof length and even more importantly the proof In these figures, ext, that the use of the time this proof. The latter is testified by the fact that no matter which or- even by an order of magni- (sometimes time. The impact of lemma handling on the proof (and in partic- is given red, unit, de- reduction, unit, default, that the (repeated) sub- 21, 41, vs t d ( 4 ) ) ) in Fig. 12 are entirely re- default lemmas, since they have already been dynamic spent for finding der of tasks, is employed, we always tude) on the elapsed ular its length) first withoult and then with the use of lemmas. f au1 t and dyn- or dynamic proofsofgamma(4, vstd(2) placed in Fig. 13 by using the corresponding solved when proving ext (vs td ( 4 ) ) . 37 Now, let us turn to Table 2 for observing the application of an extension, respectively. 36 In fact, we observe vstd(3))) features on the to the first series compile the theories simply of tests, we refrain that all samples have an analogous directly issued by our generator. This has the advantage the structure. The first two columns of Table 2 indicate lemma configuration time setting. Let us explain to compile the source into the target of 0.07/O. 11 tells us that it took XRay 7 milliseconds (including printing); to dump the Prolog file to disk and it took 4 additional milliseconds have it compiled by Eclipse Prolog. The size of source and target code is given by the number of default or Prolog rules, respectively, along with the number of resulting bytes. For instance, source file has 863 bytes (including the table by looking at the first line of ham_3. The compile it was compiled. Symbol e stands for the previous time behavior and the total number of inferences. further text). In the first setting, this is compiled consists of 8 default rules; the source code for ham-3 the impact of the previous rules and consider the corresponding from permuting the considered under which sample and the Prolog In contrast (move(3, into 35 Such a vet tar corresponds 36 A unit inference 37 Since XRay may use FTTP’s iterative deepening to a line in Table 1. is an extension inference with a unit clause. search, we can even assure shortest proofs. 44 ?: Schaub, S. Briining /Artijicial Intelligence 106 (1998) 1-75 ext(query) I--ext(vstd(2)) I-ext(alpha(3, I--ext(vstd(4)) 1 I--default(gamrna(3, I I I I I I I I I--ext(vstd(3)) 1 I--default(gamma(4, I I--ext(alpha(4, I I--ext(vstd(2)) I I I I I I I--unit(vstd(l)) I--ext(vstdtwice(l)) I--default(gamina(7, I--ext(alpha(7, l --ext(vstd(3)) I--unit(vstd(l)) (move(2, 4), vstd(4)))) vstd(2))) I--default(gamma(7, I--ext(alpha(7, (move(3, 2), vstd(2)))) vstd(3))) I--ext(vstd(3)) I--default(gamma(4, I--ext(alpha(4, (move(l, 3), vstd(3)))) vstd(l)) 1 I--unit(vstd(l)) (move(1, vstd(l))) 31, vstd(3)))) (move(3, vstd(3))) 2), vstd(2)))) l --default(gamma(4, I--ext(alpha(4, (move(1, 3), vstd(3)))) vstd(1) )) I--unit(vstd(l)) I--default(gamrna(l5, (move(4, I), vstdtwice(l)))) I--ext(alpha(l5, vstd(4))) I--ext(vstd(4)) I--default(gamma(3, I--ext(alpha(3, (move(2, 4), vstd(4)))) vstd(2))) I--ext(vstd(2)) I--default(gamma(7, I--ext(alpha(7, (move(3, Z), vstd(2)))) vstd(3))) I--ext(vstd(3)) I--default(gamma(4, I--ext(alpha(4, (move(1, 3). vstd(3)))) vstd(l))) I--unit(vstd(l)) Fig. 12.Prooftree obtained from ham-4 witboutlemmahandling and setting corn-u. files containing letters). A larger difference target sizes, viz. 11246 and 11207, obtained by switching a-corn 40 Prolog rules, having 11246 bytes, along with one query rule, having 442 bytes. The slightly different and corn-o are due to variable namings done by the Prolog compiler. In fact, our pretty printer like _g9 894 maps both to identical this is by single even reflected by the size of the query code, viz. 442 versus 512, due to two additional lemma proofs. The size of the query rule is also interesting because variables the initial model-clause-set. By and large, we observe on these examples its body contains the number (comprising many default rules and few classical ones) a factor of 1:4 between are rather of default and Prolog rules. 38 In all, the efforts taken for the overall compilation 8186 bytes (by replacing variables is observed when lemma handling for tracing is done; 38 The corresponding number of bytes is rather insignificant, since the resulting code is full of lengthy strings. Z Schaub, S. Briining /Art$cial Intelligence 106 (1998) I-75 45 ext(query) I--ext(alpha(3, vstd(2))) (move(2, 4), vstd(4)))) I--default(gamma(7, (move(3, 21, vstd(2)))) l --ext(alpha(7, vstd(3))) I--ext(vstd(3)) I--default(gamma(4, (move(l, 31, vstd(3)))) I--ext(vstd(2)) I--ext(vstd( 4)) 1 I--default(gamma(3, I I I I I I I I I--ext(vstd(3)) 1 I--dyn_lemma(gamma(4, I--ext(vstd(2)) 1 I--dyn_lemma(gamma(7, I--unit(vstd(l)) I--ext(vstdtwice(l)) I --ext(alpha(4, vstd(l))) I--unit(vstd(l)) (move(1, 3), vstd(3)))) (move(3, 2), vstd(2)))) /--default(gamma(l5, (move(4, l), vstdtwice(1)))) I--ext(alpha(l5, vstd(4))) (--ext(vstd(4)) I--dyn_lemma(gamma(3, (move(2, 4), vstd(4)))) Fig. 13. Proof tree obtained from ham-4 with lemma handling and setting corn-a. small, despite multiple pass compiling the fact that the measured technique times include printing 39 for easing implementation. and that we employ a for finding of our refinements The last two columns reflect the resulting to the ones in Table 1 and should help to relate run-time behavior. The format of the last the samples with its the total number the given figures substantiate one is identical two extreme mouldings given there. The last but one column provides of inferences performed the importance the same proofs with a significantly check allows for finding a preceding compatibility lemmas reduces this even further. This smaller number of inferences. The usage of dynamic is impressively witnessed by ham_4, where both features lead to a speed-up by several orders of magnitude, namely, 80 as opposed to 323136 inferences. Notably, both features is even free, lemma handling are obtainable at low compilation adds (under the given configuration) only a single Prolog rule (for predicate gamma) along with one further subgoal for each S-rule. the proof. 4o Actually, for enhancing costs: while task switching the basic approach: first, we see that A signilclcant speed-up on Hamiltonian cycle problems is achieved by verifying compatibil:ity before doing due to the rather complex justifications. the subsequent assumptions; proof search becomes in this way, we may discard a large number of putatively So, when it comes to guaranteeing constrained by the justifications’ compatibility, consistency applicable yet the actual A-extension steps. In our particular case, this is 39 In tbe current implementation, we actually goovertbe source code 17 times,ifall features areenabled. 4oWe refrained from doing so in tbe first series of tests, since counting inferences slows down the theorem prover considerably. 46 I? Schaub, S. Briining /Artijicial Intelligence IO6 (1998) 1-75 Table 2 Compile time experiments (on Solaris Ultra2,S 12 MB) Problem Contigu- Compile time Source Target Inferences Runtime ration (secskecs) (rules:bytcs) (rules:bytes) (sets (infers)) ham-3 o-corn 0.07Q 11 ham-3 corn-a 0.06/0.09 ham-3 o-corn, e 0.08/O. 11 ham-3 corn-o, e 0.09/o. 11 8:863 8:863 8:863 8:863 40:11246 1:442 302 0.07 (23) 40:11207 1:442 41:13495 1:512 41:13495 1:512 28 83 19 0.01 (23) 0.04 (16) 0.0 (16) ham-4 o-corn O.lUO.16 15:1505 68:20999 1:516 323136 194.13 (36) hart-4 corn-o 0.12/0.15 15:1505 68:21079 1:516 ham-4 a-corn, e 0.14/0.17 15:1505 69:25208 I:600 ham-4 corn-o, e 0.14/0.19 15: 1505 69:25354 1:600 ham-5 corn-o 0.21/0.27 2412525 104:33730 1:590 162 8079 80 369 0.45 (36) 8.51 (21) 0.16 (21) 3.07 (52) ham-5 o-corn, e 0.24/0.33 2412525 105:41311 1:706 14241619 15069.1 (26) ham-5 corn-o, f! 0.2410.3 1 24:2525 105:41307 1:706 ham-6 corn-o 0.3310.4 35:4035 148:51763 1:700 ham-6 corn-o, I 0.38/0.49 35:4035 149:61855 1~796 ham-7 corn-o 0.48/0.6 48:6131 200:72796 1:778 ham-7 corn-o,! 0.57lO.71 48:6131 201:87306 1:904 122 712 176 1225 242 0.58 (26) 14.26 (71) 1.77 (31) 51.31 (93) 4.67 (36) ham-8 c om-o 0.69/0.84 63:8909 260:9909 1 1:875 1942 153.96 (118) ham-8 corn-o, C 0.7310.92 63:8909 261:120270 1:1035 320 10.52 (41) hair-9 c om-o 0.9Y1.16 80:12465 328:128785 1:955 2897 411.21 (146) ham-9 corn-o, C l.OY1.3 80: 12465 329:158569 1:1131 410 22.08 (46) ham-1 5 corn-o 3.9314.52 224:58133 904:416574 1:1447 15529 24137.7 (377) ham-15 corn-o,! 4.45615.256 224:58133 905:531435 1:1757 1202 507.952 (76) ham-2 0 corn-o, e 11.1802.84 399:138978 1605:1081161 I:2388 2192 2968.59 (101) approach to consistency checking. The inverse phenomenon incompatible defaults in the course of the rest of the proof search. This is a great advantage of an incremental (albeit with is sometimes observed on our taxonomic knowledge base, a largely different significance) where the choices of the inference engine are only rarely corrected by the subsequent check. compatibility Another significant is given by using cycle problems lemmas practically never harm the proof search due dynamic to their restricted viability. This can be testified by a failing query 4’ to ham-4 yielding a test vector 3964.03 (-), 191.64 (-), 17.69 (-), 4.64 (-) (in the format of Table 1). We see that them. despite the usage of dynamic failure is detected much faster than without influence on resolving Hamiltonian lemmas. In addition, dynamic lemmas, 41 A failing query was obtained by adding f ai 1 to tbe end of the successful query. Z Schaub, S. Briining /Artijkial Intelligence 106 (1998) l-75 41 this is due to the fact that (propositional Technically, unit) lemmas are treatable as unit clauses; hence the application of a lemma during a derivation never needs to be replaced by another derivation step (cf. Section 5.2.3). in similar We have discussed the salient current work includes benchmark cycle problem. This problem has already been used features of XRay by means of a test series on the settings, [25] or the computation in classical default [60], as a basis for a parameterizable Hamiltonian like the colmputation of extensions of stable models of logic programs Actually, semi-monotonic problems, do not apply. A selection of our generators and the resulting test sets can be found at [83], among them, test sets on coloring problems and random graphs, all of them initially drawn from the Stanford GraphBase [46]. For a complement, we also give at [83] a couple of example A discussion of these examples default logics, since the existing ones, aiming at the two aforementioned problem to query answering from an application on model-based the scope of this paper. is however beyond files stemming generators diagnosis. set. in tailored logic 6. Treating general default theories on normal default logics. For generalizing Up to now, we have concentrated fragment of default theories as a somewhat greatest the approach, we may actually is because [30], or rational check. Due to our treatment of consistency, we may thus concentrate on this issue, while keeping common take over most of the techniques full-fledged default default 1ogi.c [58], differ only in the way they deal with the consistency modular the techniques developed for deduction and groundedness. [55], constrained in the previous sections. This [71], justified like classical developed logics, two alternatives: For implementing the (semi-monotonic fragments) of the aforementioned variants, we have actually in turn, or we provide a technique general enough to cover all of them. The latter option is clearly the more general one. Apart from the fact that it allows for realizing the first option anyway, it has moreover that we may mix multiple conceptions of default logics in the same setting. the advantage This is why we have chosen to pursue the more general approach. either we address each variant This undertaking benefits from the fact that its theoretical underpinnings in [ 121, where a context-based been established In this approach each variant of default logic corresponds and uniform default reasoning system, called contextual default logic. have already framework for default logics was proposed. to a fragment of a more general 6.1. The general setting: contextual default logic As mentioned above, full-fledged default logics differ basically consistency. While classical and justified default consistency by separately verifying rational default logic take a global approach by stipulating jointly consistent with an extension at hand. the consistency of each justification, logic employ a rather in the way they address local notion of and constrained have to be that all justifications Let us illustrate allergic children. Assume this briefly by taking a situation frequently encountered when inviting the kid stayed overnight, and we do not remember whether she 48 T. Schaub, S. Briining /Art$cial Intelligence 106 (1998) 1-75 must not eat eggs or whether her diet denies milk. If we can consistently may eat eggs, we will serve omelette, and if we can consistently milk, we will serve porridge. This can be represented by the following default theory: assume that she assume that she may have : eggs - omelette : milk - ’ porridge I , {-eggs v -milk} . > (19) ‘eggs logic provide two alternative and rational default logic yield a single extension containing omelette A While classical and justified default porridge, constrained extensions, one containing omelette and another one with porridge. Because all of these extensions contain to assume both moreover v -milk, a global approach does therefore not permit eggs and milk, while this is the case when treating separately. For brevity, justifications these results any further and refer the reader to the literature we refrain from commenting from these for a detailed discussion on the technical and intuitive consequences this literature shows different approaches In summary, that there is not only a formal need for distinct notions of consistency in order to obtain different from knowledge engineering formal properties, but moreover a need stemming due to numerous commonsense handled in the intuitively more appealing way. 42 that demand one or the other conception [19,30,35,38,68,80]. to consistency examples arising to be So, in order to combine variants of default logic, one has to compromise different notions of consistency. [ 121 capture this by means of the notion of pointwise closure Ths (T): Definition 6.1. Let T and S be sets of formulas. of T under S is defined as If T is non-empty, the pointwise closure %(T) = u Th(S U WI). #ET In addition, Ths(0) = Th(S). Given two sets of formulas T and S, we say that T is pointwisely closed under S iff T = Ths(T). For illustration, consider how we can express the “context” witnessing the derivation of omelette A porridge from Theory (19) in classical default logic: Th{-eggs”-milk,omelette,porridge)({eggs, milk]). (20) This set comprises and another one containing milk; taken together, these two sets are inconsistent thus yield any formula by applying deductive closure. Such contexts are made explicit the framework provided by contextual default logic. two consistent, deductively closed sets of formulas, one containing eggs and would in In this approach, one considers three sets of formulas: a set of facts W, an extension E, and a certain context C such that W 5 E C C. The set of formulas C is somehow established assumptions, given by the justifications consistency rules. For those familiar with from the facts, default consequents, of the applying default and underlying the 42 Interestingly, Reiter already anticipated in [71, p. 831 that “providing an appropriate formal definition ofthis consistency requirement the thorniest issue in defining a logic for default reasoning”. is perhaps T. Schaub, S. Briining /Art$cial Intelligence 106 (1998) 1-75 49 default aforementioned found in existing default default logic, and (Y E E and -(/3 A v) $! C in constrained default logic. conditions e.g., (Y E E and -B $ E in the case of classical logics, this approach trivially captures the application logics: for y, This variety of application conditions motivates an extended notion of a default rule [ 121: a contextual default rule S is an expression of the form owIoEIo!c : BCIBEISW Y where ow, CI!E, oc, /?c, BE, /3w and y are formulas. and C-prerequisites, also noted called the C -, E- and W-justifications, y is called lthe consequent, contextual d’efault rules in the obvious way (e.g., Justify convenience, we omit tautological identified with T. the W-, E- f?ereqw(6), PrereqE(S), Prereqc(@, PC, BE, & are and extend to sets of = Us,D{Justif~(6)}). For component must thus be also noted Justifc (S), Justify, also noted Conseq(G). These projections (YW, cz~, oc are called a non-existing components; Just$w(G) A contextual default theory is a pair (0, W), where D is a set of contextual default rules is a pair (E, C), where E closed set of formulas. We closed set of formulas and C is a pointwisely set of formulas. 43 A contextual extension and W is a consistent is a deductively give below the quasi-iterative characterization of contextual extensions: Definition 6,2. Let (II, W) be a contextual default formulas. Define theory and let E and C be sets of Eo = I%(W), co = Th( W) and for i 3 0 d,= 1 ‘~wIQEI~c : BcIBEIBw ED Wt-aw, EikaE, Citac, I. Y CY-PC, EV-BE, WY-Bw I ’ Ei+l == Z’h(W U Conseq(A~)), ci+l =’ “WUConses(Ai)UJusrifc(Ai)(J”‘ifE(’i)). Then, (E, C) is a contextual extension of (D, W) if (E*C)=(gEi,gCi). The extension E is built by successively of all applying contextual default rules. For each partial context Ci+r , the partial extension Ei+l is united with the C-justifications in turn with each E-justification of all applying contextual default rules. 41 This set is united of all applying contextual default rules. the consequents introducing 43 Originally, Besnard and Schaub [12] deal with a deductively closed set W in accord with the closure of E and C. By compactness, we must actually never consider deductively closed premises for automated theorem proving purposes. 41 To see this, observe that T/I WUConseq(Ai)UJ~~rifC(Ai)(J”tifE(’i)) = ‘hEi+,UJusfifc(Ai)(JUStif~(‘i)). 50 Z Schaub, S. Briining /Art&ial Intelligence 106 (1998) I-75 In [ 121, it was shown that classical, justified, and constrained default logic are embedded in contextual default to rational default logic. For brevity, we exemplarily give the resulting mappings and refer the reader to [ 12,521 for the corresponding logic. Linke and Schaub these embeddings [52] extend equivalence results: Definition 6.3. Let (D, IV) be a default theory. We define @m(D, IV) = (1 y 1 y! E D) , w) (Classical default logic), @JDJDL(D, W) =([ ‘a”ySBAy’ 1 y E D), W) (Justified default logic), (Constrained default logic), (Rational default logic). extend These embeddings to variants of default [19]): Delgrande et al. [30] show that constrained (or and cumulative default logic assertions [ 191 are equivalent modulo representation. The same is shown by Giordano and Martinelli [40] for classical and Q-default CA-default logic [40], and by Linke and Schaub [52] for rational and logic relying on labeled logic [40], respectively. formulas For example, we obtain for theory (D, W) , as given in ( 19), the following theories: @JDL(D, w) = omelette 11 : omelette ) eggs A omelette I 11 : porridge 1 milk A porridge 1 porridge I , {-eggsv -milk} , (21) 1 I : eggs A omelette I I I ( : milk A porridge I I %DL(D, w> = omelette ’ (22) to verify that @JDL(D, It is instructive omelette A porridge, while &DL(D, W) yields omelette and another with porridge. This is due to the different consistency used in each theory. While the C-justification W) has a single contextual two distinct extensions, eggs A omelette of extension containing one containing requirements I I : eggs A omelette I I omelette must not only be consistent with the extension at hand but moreover with all justifications of other applying default rules, the E-justification eggs A omelette of I I : omelette I eggs A omelette I omelette requires consistency with the extension only. This is why both default rules of @JDL contribute extension. (D, W) to its single extension, whereas each rule of RoL(D, W) engenders a distinct T Schaub, S. Briining /Artificial Intelligence 106 (1998) 1-75 51 In order to capture the family of default logics described in Definition 6.3, we may restrict ourselves to contextual default rules of the following form: (23) As motivated in the introductory sections, our approach relies on the ability of forming default proofs in a local fashion. This is why we have applied our approach up to now to normal default theories only, since these theories enjoy the property of semi-monotonicity. default proofs: we call a Analogously, contextual default if we have for any two subsets Df and D” of D with D” E D’ C D that if (E”, C”) is a contextual extension of (D”, W), then (E’, C’) of (D’, W) such that E” C E’ and C” G C’. For there is a contextual extension example, theory (0, W) semi-monotonic relies on locally determinable our generalization theories (21) and (22) are semi-monotonic. and constrained default justified Actually, logic enjoy semi-monotonicity (Yearly, this carries over to the corresponding in full fragments of contextual default generality. to these variants of default logic. Notably, logic, so that our approach extends immediately thus allowing for treating some this extends to the union of the respective default theories; default rules according to constrained default to justified default logic and others according logic. For classical and rational default logic, on the other hand, we must restrict ourselves to semi-monotonic by appropriate remains however future stratification work.) a concrete adaptation of such techniques should be determinable (Such fragments techniques; fragments. For furnishing an appropriate proof theory, we provide next a more proof-theoretic characterization of contextual extensions in the presence of semi-monotonicity: Theorem 6,-l. Let (D, W) be a semi-monotonic contextual default theory such that D s D* and let .E and C be sets offormulas. Then, (E, C) is a contextual extension of (D, W) iff there is some maximal D’ s D that has an enumeration i E I, we have: (6i)iEI such thatfor E q = Th( W U Conseq( D’)) C == Thmastifc(Dq @W-E CD’)) I ’ W II Conseq( (60, . . . , Si-1 )) I- PrereqE (Si), W J Conseq({So, . . . , Si}) UJustifc({60, . . . , &}) y -JustifE(&) jbrkE{O,...,i} I (24) (25) (26) It is instructive dealing with normal default theories (no matter which translation to verify that this specification is used). reduces to that given in Theorem 2.1 when As another example, consider for constrained default logic: while condition the same, the definition of C reduces to C = Th( E U Justifc (D’)), thus dealing with deductively closed (25) as well as the specification of E in (24) remain of this definition the instantiation 52 Z Schaub, S. Briining /ArtiJcial Intelligence IO6 (I998) 1-75 sets. Another simplification of E-justifications: 45 is observed when regarding condition (26) due to the absence W U COR!?eq({GfJ, . . . , Si-I}) U JUStifC({&), . . . , Si-l}) y -COllSefJ(Gj) V lJUStifC (Si). they must be distinguished condition 2.1). While (cf. Definition This consistency theories with consequents, constrained default logic, this distinctive over the whole machinery developed by simply replacing each manipulation the corresponding constrained default logic by maintaining set. justification is actually closely related theories justifications in normal default to that found in a full-fledged default in normal default coincide logic. In fact, in is done in such a way that we can take in normal default theories of a consequent y by that of its conjunction with in treatment for consistency checking checking fi A y . As a result, we can address compatibility a single model along with a single model-clause- In analogy to Definition 2.2, a default proof for a formula q from a contextual default theory (D, W) is then a finite sequence of contextual default rules (bi)ier with 6i E D for all i E I such that W U {Conseq(Gi) 1 i E I} I- cp and conditions (25) and (26) are satisfied that is, the derivation of ‘p from W and (6i)ieI for all i E I. Clearly, the first two conditions, in the previous sections. So that and also groundedness we can concentrate on the implementation in the next subsection. of (Si)iel, are treated as developed (26). This is accomplished of condition 6.2. Generalizing model-based consistency checking theories, in W satisfying In the sequel, we extend the model-based approach introduced setting described above. For normal default model of the premises the presence of putatively contradictory E-justifications, compatibility. model structures for guaranteeing of W, all of which must entail the consequents in the current derivation, while there must be at least one model of each E-justification among them. Observe that the models covering E-justifications distinctness in Section 4 to the general to furnish a single In however, we need more complex In fact, we might now need several models of the default rules and the C-justifications in the presence of contradictory E-justifications. are not necessarily distinct; all default conclusions in a proof at hand.46 is only necessary it was sufficient Let us make this precise in the sequel. For a formula 4 and a set of models M, we write for some m E M. For a set of for the semantic M b 4 if m t= C#I for all m E M; and M + 4 if m b -4 formulas S, we define its set of models as Mod(S). First, we account counterpart of the notion of pointwise closure (cf. Definition 6.1): for sets of formulas S and T, we define Mods(T) = &ET MO&S u Ml> if T #PI, Mod(S) I otherwise. 45 To be precise, all E-justifications 46 This extends actually are tautological rather than non-existent. to default logics employing C-justifications only, such as constrained default logic. T. Schaub, S. Briining /Art$cial Intelligence 106 (1998) 1-75 53 For a set of formulas W and a sequence of contextual default rules (&)i,~ of form (23), we are then interested in the set of models Mods(T) obtained by taking S = U’ U Cunseq({& 1 i E I)) U htifc((6i 1 i E Z]) and T = Jzistif~({& 1 i E I}). For readability, we abbreviate subset this set of models by Mw(Z); in analogy, we denote its {m E Mw(Z) 1 m + .hstifE(&)) by M&(Z) for i E I. In fact, for non-empty covers a different E-justification .ZUStifE (&) in .ZUsfifE ((8i I i E I)). I, Mw(Z) equals UiE, Ma(Z), each of which Consider .he semantic counterpart of the pointwisely closed set given in (20): This set of models eggs A -milk and the one satisfying milk A -eggs; is actually composed of two distinct sets: the model set satisfying they actually comply with M&({ 1,2}) and M$ ({ 1,2}), where { 1,2} is the index set corresponding to the default rules obtained by applying @ok to default theory (19). Such sets of models furnish the domain from which we select individual models witnessing the compatible application of default rules. Now, in o’rder to characterize compatible default proofs (&)i,l from a set of premises subsets M of Mw (I) such that M fl Ma(Z) # 0 for all i E I; W, we cons:ider non-empty and we use &I to indicate by writing M Cl Mw(Z) property holds. Observe all underlying model for each E-justification Justify. empty subset M of Mw (0) = Mod(W) is guaranteed, since W is assumed to be consistent. sets Ma(Z) are non-empty. This guarantees that for non-empty Z the existence of such a set M implies that that M contains at least one In case Z is empty, we also deal with a non- of M ; we write M &J Mw (0). The non-emptiness that this structural set inclusion For a contextual default rule and some index set Z = K U {i}, function V addresses condition mapping format if condition trilples of form (M, W, (Sk)kE~) with M & Mw(K) (26) is true; it yields I if condition (26) is false: (26) in Theorem 6.1 by onto triples of the same V(Ji.5 (M, W, (&)~E:K)) (M, W, (&)i,r) if M b y A /?c and m k BE for some m E M, (M’,W,(&)~,I) ifMky~r\c or m&tj3EforallmEM = and for M’ & Mw(K), M’ k y A #?c and m’ b BE for some m’ E M’, _L if there is no M” &K Mw(K), M” b y A PC and m” b BE for some m” E M”. 54 I: Schaub, S. Briining /Artificial Intelligence 106 (1998) l-75 in the discussion that M’ EK Mw(K) sets M’ in the absence of E-justifications; implies M’ # 0 even though K = 0 due to the consistency Observe of Theorem 6.1, we may restrict our attention of W. As anticipated this amounts more or less to to singleton the approach presented differing from the associated consequents). M’ must contain multiple models when dealing with inconsistent E-justifications. In the worst case, that is when dealing with IZ pairwisely inconsistent E-justifications, M’ includes at most n distinct models. in Section 4 (except for the integration of justifications The following result shows that this approach is in accord with the conception of consistency expressed in Definition 6.1. Theorem 6.2. Let W be a set of formulas and (6t)icI a sequence of contextual default rules such that 6i E D* for all i E I. Then, we have for all i E Z and K = (0, . . . , i - 1) then there is either a andL={O,..., non-empty set of models M’ EL Mw(L) i} that tf there is a set of models M CK Mw(K), such that V(6i, (M, W, (&)kE~)) = (M’, W, (&)tE~) #condition (26) is true or V(6i, (M, W, (&)kE~)) = I iff condition (26) is false. Observe that M and M’ need not be distinct; thus covering the first two cases of V. As argued in Section 4, we must provide efficient means for supporting model searching. For this purpose, we use extended model-clause-sets of form where M is a (compact) clausal representation of W U CO?ZSf?q([& 1 i E I}) UJUStifc((Si 1 i E I}) and the Mi are (compact) clause sets representing default proof fragment model-clause-setof Also in analogy invariantly clause-set for some (6i)iEr from (0, W). Similar to Section 4, we start with an extended form (Cw, 0) and a singular set of models M = {m} for some m b W. are to Section 4, coexisting model sets and extended model-clause-sets coupled via satisfiability. That is, for a model set M and an extended model- (M, (Mi]i,l), we have Justif E(Si), respectively, true for tautological E-justifications (This is trivially observe that a model like m may cover multiple clause sets of form Mi whenever jointly consistent with M. That is, the number of involved E-justifications, upper bound for the number of models in M. yielding Mi = 0.) It is important to they are 1 II, is only an The important supported by the DME-derivations reduction of the search space for models was obtained reductions of the model-clause-sets in Section 4 along with by appeal to continued model-preserving by means of lemmas. Actually, all these information to techniques apply also in the general case, although we must pay some more attention their scope of applicability. This is due to the fact that we share M with all clause sets of form Mi. In fact, a separate treatment of all instances of form M U Mi would allow for in Section 4 in a straightforward way, yet at the cost applying all techniques developed Z Schuub, S. Btining /ArtQicial Intelligence 106 (1998) 1-75 55 (Cw70) where cw = {{+G, +Wl MO = { t-Ml) ) W’, {W) where M’ =: {{TEG, -MI}, {OMg,}} == {{EG~J,{GMJ~I} M: ,.-+ {{E&II MI = { {+JV Obl, 6,) } (M”, {M:‘, AI’,‘}) where == {{?EG, lMI}, {OMB,}, {POsz)) M” My == {{EGsl}} M’,’ == {{f’~fI6~}, (P06z)) - {i”16,)) Fig. 14. Governing compatibility while deriving OM A PO from @JDL(D. W). of more redundancy. As a consequence, we allow for applying subsumptions are restricted in the current DME-derivation these are trivially compatible. They are addable entire extenlded model-clause-set, and from the same reductions on M U Mi on M, while modifications to Mi . We restrict lemma usage to those depending on default rules involved only. This is reasonable and actually highly efficient since in the to M which allows for reductions freely unit-reductions resulting Let us illustrate this by verifying compatibility including clause sets like Mi . of default proof ( ( : ‘omelette 1 eggs A omelette 1 - I I : porridge 1 milk A porridge I ( omelette porridge ) ((61, 62) for short) for omelette A porridge from @JDL(D, arbitrary model of CW into our model set, MO. The extended model-clause-set is given in the first line of Fig. 14. Applying one of the above rules after the other, yields: W). We start by putting an (CW, 0) V(%, (MO, W, 0)) = Ml and V(62, WI, W, @I))> = M2, where model sets MO, Ml and M2 are given in Fig. 14 (while abbreviating milk, eggs, omelette and porridge by Ml, EG, OM and PO, respectively). Ml is obtained from MO simply by extending the only model; this model ensures the compatible application of 61. M2 necessitates the generation of another model satisfying the E-justification Let us take a closer look at the underlying extended model-clause-sets. omelettes, to Cw, resulting eggs&, A omelettes, engenders makes us add its C-justification justification that M’ itself is not reducible. However, we may reduce M’ U M’, by subsumption. But even though there are two alternatives for deletion, such a reduction must only affect clauses in Mi . This is why (OMs, ) is deleted in M\ and not in M’ (this and all following by the symbol -). The same type of reduction reductions are indicated step. Actually, the creation of M’, . Observe is applied in the following in M’, whereas its E- of 82. Applying 61 56 ‘I: Schaub, S. Briining /Artifiial Intelligence 106 (1998) 1-75 (Cw, 0) where CW = {{lEG, YMI}} W’, 0) where MO = { {-MI} 1 MI = { {+t Ob;, EGq} } Fig. 15. Denial of compatibility while deriving OM A PO from @CDL(D, W). when applying 82, we are forced to generate an alternative model since the E-justifications of 61 and 82 are contradictory. This does however not prevent as explained above. Finally, model set M2 contains a model for 44” U M;’ and another for M” u M;‘. their joint application, For a complement, let us see why 11 : eggs A omelette ( 1 1) : milk A porridge ) I ( omelette ’ porridge ) is illustrated ((6;) 6;) for short) is no compatible default proof for omeletteA porridge from @cnL(D, W). in Fig. 15. First of all, we observe that this example does not The proceeding comprise any (non-tautological) hence there are no secondary clause sets in the extended model-clause-set, which allows us to restrict our attention model sets only. Applying 8; makes us add its C-justification to singleton to Cw, eggss; A omelettes; E-justifications; resulting in M’, from which we obtain a singular model set A41 = ( {-MI, OM,; , EGs; } }. is then reduced by unit-reduction. Next, our underlying DME-derivation makes us for 8;. The model in Mt does not satisfy the C-justification of S;, that M’ check compatibility is, {-MI, OM,; , EG,; } k Mls; A PO,;. Thus, we look for a new model testifying explanation). For this purpose, we extend the last model-clause-set resulting immediate which without performing an actual consistency joint compatibility in M”. Applying inconsistency. indicates reductions yields a clause set with an empty clause, In this case, we were thus able to detect inconsistency of Sl, and 6; (see above for an by 8;‘s C-justification, check. In terms of function V, we have V($, (MO, W, 0)) = Ml and V(6;, WI, W, (6;))) = I where Mu and Ml are given in Fig. 15. I: Schaub, S. Briining /Artificial Intelligence 106 (1998) I-75 5-l the generalized For implementing checking, we the extending encapsulated by functor m/ 2 ; also, we had to conceive additional means for check. All follow by and large the approach described datastructure treating and -notably reusing as many models as possible at each compatibility this is detaile:d in [21] (see also [83]). consistency in Section 5. This necessitates to model-based approach 6.3. Experimental results tests. inferences, for enhancing the XRay system [77], whose overall The appro,ach has been implemented in what performance has already been discussed follows on the implementation checking. For this purpose, we have developed a tool (see [59]) to build generic contextual default the number of model generations during query theories in order to be able to parameterize answering. Since we deal with different sorts of justifications, to study the influence of different compatibility in Section 5.3. Hence, we concentrate of our model-based to consistency it is moreover interesting approach For abstracting from the underlying all generated default tlhe query; it is just the fact whether a call to predicate compatible theories have a structure. As a result, all default rules are always applied in the same order fixed inferential results in for proving reusing or regenerating a model that varies in the test cases. This gives us a constant effort for inferencing no matter how many model switches are provoked. The different number the literals in the set of premises (and thus of model generations in the extended model-clause-sets) in view of the fixed application order of &rules and the known sear& strategy of the model generator. As an additional constraint, we imposed that all E-justifications give rise to different models. so that different E-justifications is achieved by reordering are pairwisely inconsistent For brevity, we present here two exemplary test series, taken from [59], and refer the to [21] (or even [83]): one series with 50 and another with 100 a fixed number of model switches. This gives a putative reader for more details default rules, each of which contains additionally 50 and 100 binary clauses, respectively, provoking models of 2”O and 21°0. The number of effectuated model generations first column of the subsequent default rules having (i) only C-justifications, (iii) both C- and E- justifications. These cases are listed in order in the columns headed by DC, BE and /?c + /?E furthermore between in Table 3. The column headed by fit + BE distinguishes test cases (left column) and those where where model generations are originated by C-justifications model generations are caused by E-justifications (right column). Each item contains a time measure 47 in seconds. search space for in the is indicated three major test cases comprising (ii) only E-justifications, tables. We distinguish Note that the two limiting cases are given in the first and last line, representing a single and consecutive ones. Also, we see that model switches are generally model generation more expensive in the presence of both types of justifications. This is reflected by the fact that we encounter higher figures in the two columns put together under /Ic + BE than in the corresponding ones headed by /?c and BE, respectively. 47 As above, comprising system and user time. 58 T. Schaub. S. Briining /Artificial Intelligence 106 (1998) 1-75 Table 3 Experimental results on model-based consistency checking (on lagaffe.univ-angers.fr HP 715-64) #I50 1 10 25 50 I% BE PC +pE #/loo PC BE kk +BE 3.6 3.6 2.6 8.1 5.7 7.6 4.4 9.3 8.0 18.8 9.8 19.1 1 11.1 9.4 38.5 28.5 25 50 16.3 66.3 42.2 87.6 46.6 132.1 92.5 166.2 11.9 31.3 18.0 35.2 100 102.7 260.7 135.6 330.4 consistency We observe are more expensive of BE can be confirmed. that model switches caused by E-justifications them, such a search is never successful on these particular than the former. That is, the consistency of a C-justification is thus immediate search for E-justifications: than those caused by C-justifications. This is related to the fact that the latter impose a stronger concerns consistency constraint needs a single model only. The failure of a all current models, while an E-justification if it falsifies a C-justification, while model for warranting this involves some subsequent as witnessed by the second case in the specification of V, we verify that m F BE for all models m before the ultimate failure (Since our aim is to provoke model generations of consistency test cases.) rather than recycling Note also that the sole use of C-justifications makes us treat in turn a single yet different that each model, while proof including n default rules involves handling n distinct models (due to the pairwise inconsistency of E-justifications). Hence, except for the case of a single model generation, the sole usage of C-justifications individual model can clearly be maintained The aforementioned primary clause set which is subject rapidly amortized with an increasing that we observed on non-artificial model switches which indicates detailed experimental number of model switches. Finally, we mention in Section 5.3 very few the putative feasibility of our approach in practice. A more details are given in [21] (see also than using E-justifications only, because an in a much easier way than n different models. to the reductions. These efforts however are the exclusive usage of E-justifications is due to the fact that C-justifications analysis along with implementation like those discussed in our setting to consecutive are added exception examples provokes is better P31). 7. Discussion and concluding remarks We showed how Prolog technology can be used for implementing by appeal to the approach systems. This was accomplished theory into a Prolog program PO, w,+, is derivable reasoning PTTP. We described how a default transformed that query A particularity that allow for verifying simplicity, we have restricted the arguably simplest fragment of default logic supporting of our approach stems from centering the validity of each inference the first part of our exposition (D, W) along with a query along with a Prolog query query efficient default taken by Stickel’s (p has to be such (D, W). local proof procedures it is performed. For to normal default theories, as local proof procedures, although step when it around from PD,w,~ iff (p has a finite default proof from Z Schaub, S. Briining /Artijicial Intelligence 106 (1998) 1-75 59 the approach applies to any semi-monotonic that the treatment of such full-fledged default logics is identical theories, except for the compatibility as a general methodology candidate in Section 6. Note to that of normal default check. In this way, our approach can be regarded logics, as a prime semi-monotonic local proof procedures. for default logics supporting logic, as detailed for implementing default default compilation From an&her perspective, we have shown how existing (high-performance) PTTP-based theorem provers can be enhanced by means for handling default information. For providing theoretical underpinnings for the underlying top-down proof procedure based on model-elimination. We called Default Model Elimination. This proof procedure has its roots in an approach query answering based on the connection method. This consequent automated logic feature of the approach; resulting system. As a byproduct, we have put forward appropriate enhancements known concepts in automated of lemma handling, techniques, we have proposed a the resulting method to default integration of classical is a salient technology for the overall performance of the of well- regularity and diverse forms the performance of our inference engine. techniques it is in particular for further improving and novel default theorem proving theorem proving, like blockwise responsible finally, one can view our contribution And gramming is, via the standard #system integrating logic pro- as well as default negation. That of logic program clauses (cf. [56]), such as p t through default rules interpretation . . , not (rn), where p, qi , ri are atomic formulas, also as a (propositional) disjunction, classical qm, not(rd,. q1,..., of form 41 A, ..r\qrn : -rl,...,-r, P Our approach First, exlcept for found in the literature: [5,25,45,63,71], we may actually experiment with the resulting default rules under the different tions, given in Section 6 (here for n = 1, a generalization ever straightforward). This allows furthermore are non-atolmic for investigating logic programming. interpreta- is how- extensions, where p, qi , ri justifications to multiple formulas, such as disjunctive is thus quite different from other approaches [2,17,72,81], inference engine. We integrate both groundedness all other approaches, like standard normal default into an existing theorem prover using a standard from an underlying consistency generating models. Poole proposes prerequisite-free restriction renders an implementation underlying the other hand, the resulting Theorist handling, whose treatment for in [69] an approach dealing with the fragment of to the to prerequisite-free default rules so that PTTP serves mainly as an .theorem prover (also used for consistency checking via failing derivations). On is rather advanced as regards variable to normal default rules, however, the restriction of groundedness unnecessary, and (incremental) sub-prover that is also based on PTTP In addition framework rules abstract the methods described Second, extensions in Reiter’s default This is somehow unavoidable and it does thus not allow for local proof procedures. This is why we concentrate on query answering logics, which is actually much more apt to the from semi-monotonic standard query answering process of PTTP. logic; queries are then answerable in Reiter’s default entire from such an extension. logic, since it lacks semi-monotonicity aim primarily at computing default is arguably rooted in [66]. in [25,45,50,63,81] 60 I: Schmb, S. Briining /Arti&ial Intelligence 106 (1998j l-75 Third, consistency checking is treated differently: for instance, Reiter [7 l] puts forward a belated consistency check; Schwind and Risch [8 l] computes first entire sets of “consistent default rules” and verifies groundedness separately. (exponential) such an exhaustive to restrict computational checks. In our framework, on the one hand, that the crucial task of consistency Moreover, our approach differs from all of the aforementioned ones in pursuing a model- compu- based treatment of consistency checking. This novel approach aims at minimizing tational efforts by reusing models as compact representations of former consistency checks. We have demonstrated, checking can efforts to ultimately necessary ex- benefit from keeping models check haustive consistency to the generation of a new model; otherwise, we rather aim at reusing existing amounts models for performing a fast (linear) satisfiability test. In Section 4, we have seen that even though three different defaults were used, a new model had to be generated only once. The tests. consistent application of the two other defaults was warranted by two satisfiability On the other hand, we have demonstrated together with a rigorous application of reductions, search space. Furthermore, we have shown that the concept of default lemmas allows for In this way, we achieved a syn- in model-clause-sets. additional avoidance of redundancy ergistic and potentially parallel Our handling of lemmas systems treatment of theorem proving and satisfiability to that of so-called nogoods is related [29]. For instance, Sattar and Goebel truth maintenance for amending Theorist is a kind of lemma consisting of literals a whose inconsistency DME-derivation literal, this derivation can be rejected prior to checking compatibility. The integration of such a technique checking. in assumption-based [74] use such nogoods In our setting, a nogood of defaults, contains each element of such a nogood as S-extension-resulting has been detected by a previous compatibility remains an interesting piece of future work. that the use of model-clause-sets reduction of the underlying in our implementation to the justifications check. Whenever that correspond for recognizing in a significant inconsistent hypothesis. results The extended approach of Section 6 has provided us with a general in default query answering logics supporting the variety of consistency by encompassing implementing was accomplished logics. Actually, default approach allows us moreover resulting system is thus unique default logics. apart from capturing diverse full-fledged to combine in offering simultaneously these variants framework checks found for local proof procedures. This in existing this logics, fashion. The of multiple in an arbitrary the expressiveness default taxonomies) and artificial examples For finding new models, our implementation Putnam procedure propositional models. Our current experiments on “meaningful” expressing and other parameterizable in the course of the proof search. That resulting default proofs contained only few occasions choosing incompatible &rules. For instance, we observed on many examples very few model switches. This is an argument check that reuses information gathered on previous compatibility a compatibility uses an adapted variant of the Davis- [28], which is currently one of the fastest complete methods for finding (to be more precise, rules random problems, show that a model has to be changed quite rarely that the the theorem prover by cycle problem, in favor of checks. is, on many examples, we observed (like graph problems, the Hamiltonian for distracting for deciding examples) Actually, current work includes benchmark generators in default logics, since the existing ones, aiming at the computation of entire to query answering semi-monotonic tailored 1: Schaub, S. Briining /Artificial Intelligence 106 (1998) 1-75 61 reasoning is quite promising. On different logic, do not apply. On the whole, our experiments in Reiter’s default that the pursued avenue implementation In fact, credulous [42], whose two sources of exponentiality extensions have shown families of examples, our current outperforms previous ones that do not rely on PTTP by an order of magnitude. logic is JC:- in propositional default complete are reflected by an extended PTTP inference engine along with model handling capacities. the approach is quite orthogonal to that of computing entire extensions. For instance, DeReS [25] performs very well on graph-based examples, cycle problems. Similar problem sets are is also feasibly manageable with our system (albeit on a smaller scale); the performance however sub.ject to the ordering of the rules in the default logic program. On the other hand, we have observed rapid answers due to short proofs on taxonomic knowledge bases, which1 made DeReS collapse. like Hamiltonian Interestingly, impressively Finally, the simplest symbols. Practically th(e natural questions arise, why choose PTTP when it is not unproblematic (for instance, [91] allows a simpler coding via an extended the number of generated Prolog rules? And, are there alternatives that while there are approaches as to the choice regards that could be of PTTP? For the latter case, we remark the approach of Umrigar used in place of PTTP, it is certainly this, set of connectives; and Pitchumani however, does not allow to apply compilation techniques). For the former, we note that the blow-up of the resulting code is still linear in the number of clauses, default rules and any space propositional topic for problems like for future research how approaches in a similar instance [7,8] and correspondingly way. Another major avenue for future research is the cross-fertilization top-down to default reasoning, manifested by the distinction among query and bottom-up approaches In this paper, we relied on the property answering of semi-monotonicity to [26], which aim at see how techniques framework. computing extensions stratification [90] and in particular in a local fashion, carry over to a query-oriented it remains an interesting the generation of all contrapositives for compiled knowledge bases. Nonetheless, speaking, we have so far not encountered the resulting systems [9] can be enhanced It will now be interesting local proof procedures. and the computation of extensions. like splitting for obtaining avoiding between Acknowledgements We are grateful to Mark Stickel for providing us with HTTP and for fruitful discussions during his stay at Darmstadt. Great thanks are also due to the anonymous referees for their detailed comments. This extends to Philippe Besnard and Pascal Nicolas, who provided a constant valuable feedback. Appendix A,. Compilation results on examples For ultim,ate transparency, we provide Example whereby (4) in Fig. A.l. The resulting the Prolog code stemming the authentic knowledge base corresponding to Prolog code is given in Fig. A.2, from the query is put in a separate file in order to ease (pretty-printed) 62 T Schaub, S. Briining /Artificial Intelligence 106 (1998) 1-75 % Filename : allergyl.kb % Usage % Date : xray(allergy1). : 14/11/96 child. predispo. not-milk ; not_predispo ; allergen. icecream :- child : icecream. milk :- icecream : milk. sugar :- icecream : sugar. query :- allergen. Fig. A.l. The knowledge base of Example (4). re-compilation lemma handling. of subsequent queries. This code was obtained from a compilation without These files along with the ones dealing with Example (10/l 1) can be retrieved at [83]. Appendix B. Proofs of theorems B. 1. Proofs of theorems in Section 2 Proof of Theorem 2.1. This is an immediate consequence of the general result expressed inTheorem6.1. q Proof of Theorem 2.2. The result follows from Theorem 2.1 by compactness monotonicity. 0 and semi- B.2. Proofs of theorems in Section 3 For the proof of Theorem 3.2 we need the following lemma: Lemma B.l. Let W be a set of formulas and 61 , . . . ,a,, be a sequence of default rules. Then, ViE{l,..., n} : W U Conseq((G1, . . . , Si_l}) I- Prereq(&) (B.1) iff ViE{l,..., n} : W U {Prereq(Sl) + Conseq(&), . . . , Prereq(&_1) -+ Conseq(Si_l)} k Prereq(&). (B.2) I: Schaub, S. Briining /Artificial Intelligence 106 (1998) l-75 63 ~llerqe~,_1._2,_3._4,_5._6,_6._1,_8):- ~denticalglember(allergen,_l), !,fail. allergen,_1,_2._3,_4,_,4,_5._5,_6,_7):~ identrcal_member(nat_allerqen,_2), -6 = ireduction(nof_allerqen)1_7]. !), a~~e~qe~~_1._2,_3._4,_5._6,_7._8,_9~:- ,_6 ,= 2._10 is -6 - 2). _I1 = ,allerqen,Lll. -8 = [extensioni? : allergen) 1_121, milkl_11,_2._3._4._13,_10,_14._12,_15~, Pred~spo,_11,_2,_.3._13,_5,_14,_7,_15,_9). not_allergen,_1,_2,_3._4,_5._6._6,-7,_8):- identlcal_member,not_allergen,_Z), !,fail. not_a~lerqen,_1._2,_3._4._4,_5,_5,_6,_7~:- identlcal_member:allergen._l),!), -6 = ,re*uctlon,r,llerqe",,_71. ident~cal_me*er~nar_chil*,_2~,!, -6 = [reduction,rlot_child) I-71. child, J_2,_3,_4,-4, -5._5,_6._7):- -6 = ,unit,l : child) I-71. icecreaml_1._2._3._4,.-5,-6,_6._8) :- identical_member,icecream,_l), !.fail. icecre?.m,_1,_2._3,_4,..4,_5,_7~:- identrcal_member,nct_icecream,_2), -6 = [reductlon(,,ot_lcecream,,_7]. !, lcecream,_1,_2._3,_4,._5,_6,_7._8,_9):- C-6 >= I,_10 is ._6 - 1). -11 = ,icecreaml_ll, -8 = Lextension(l : icecream) ILl.21, milkI_1._2.~3,_4,~5,_6,_6.7,_8):- identical_member(milk,_l), !,fail. milk,_1,_2._3,_4,_4,_5,-5,_6,_7):- identical_member,nat_milk,_Z).!, _6 = Lreductlon,not_milk) I-71. :- milk,_1,_2,_3,_4,_5,_6,_7,_8,_9) l-6 >= I,_10 is -6 - I), -11 = ,milkl_ll, -8 = iextensionC5 : milk)1_121, vamma~5.mi1k._11,_2._3,_4,_5,-10,_7._12,_9~. not_miLk,_1,_2._3,_4._5._6,_6._7,_8):- identlcal_member,natimilk,_2). !.f.ail. not_milk(_1._2._3._4,_4._5._5._6._7):- ident=cal_membel,mllk,_l),!, -6 - [reductlon,m=lk),_71. notJnilk,_1,_2._3,_4,_5,_6,_7,_9):- (-6 >- 2,_1O is -6 - 2). -11 = I"ot_mllk,_Pl, -8 = Lextension(3 : not_milk) l-121, predispoi_1.~l1.~3._4.-~3,~10,_14,-12,_15~. n0t_a11ergenl_1,_11,_3,-13,_5,_14,_7,_15,_9~. ~redispoL1._2._3._4._5._6,_6._7,_7,-8~:- identical_member ,predispo,_l), !.fail. xedispo,_1,_2,_3,_4,_4,_5,_5,_6,_7):~ identical_member,natgred=spo,_2).!. -6 = [reduct=onInotgredispo),_7,. JredisPo(_1,_2,_3,-4,_4._5,_5._6,_6,-7):~ -6 = [unit,2 : SNredispo) I-71. notqredispo,_1,_2,_3,_4._5,_6,_6,_7,_6): identical_memberjnotqredispo,_2), !,fail. notgredispo(_1,_2,_3,_4,_4,_5,_5,_6,_7) identical_member -6 = [reduction,predispo) l-71. not_psedispol_l,_2,_3,_4,-5,_6,_7,_9):- (predispo,_l) , ! ) , :- ,_6 >= 2._10 is -6 - 2). -11 = ,not_predispoI_Zl, -8 _ Lexte"slon(3 : notgredispo)l_121. milk,_1,_11,_3,_4,_13._10,_14._12,_15~, not_allerqen~_1._11,_3,_13,_5._14,_7,_l5,_9~. suq~r~_1._2._3._4._5,_6._6,_7,_~~:- identlcal~member(suqar,_l), !,fail. suvarl_1._2,_3,_4,_4._5,_5,_5,_6,_7):- ldent~calJnember,not_suqar,_Z),!, -6 = [reduct~on,not_suqar),_71. suvar,~l,.2,~3._4,~5._6.~7,~8,~9~:- I_6 >= .l_lO is -6 - l), -11 = ,suqar,_ll, -8 = [extension,6 : sugar) I-121, ga~a,6,suqar._11._2,_3._4,_5._10,_7._12._9~. wmna,4,icecream,_1,_2,_3._4,_5,_6,_7,_8,_9):- (-6 >= 1.10 is -6 - 1). -11 = ,qamma,4,icecream) I-31, -8 = (defaultC4 : licecream-child alphall.child, [I, ~1,_11._4,_13._10,_7,_12,_9~, compat~ble,I,icecreaml],~13.~5). ~amma,5.milk._1._2,_3._4._5,_6,_7,_6,_9~:- : [[icecreamll)] 1_12], C-6 >= l,_lO is -6 - i), -11 = Igamma,5,m~lk) I-31, -8 = [default,5 : (milk:-icecream : IImllkll)) 1_121, a1pha,5.icecream.11,~1._11,_4,~13._10._7._12.9~. compatible,fImilkll,_13,_5~. ~amma~6.suqar._1.~2._3,~4,_5._6._7.8,_9):- ,_6 >= l,_lO is -6 - I), -11 = ~qamma~6,suqar~1_31. -8 = [default,6 : [sugar:-icecream : [[suqarll)) 1~121, alpha,6,icecream.,1.,1._11._4._13._10._7,_12,_9~. compatlble,L,s"varll,_13,_5~. ~l~hal4,ch~ld,_1._2,_3,_4,-5,-6,_7,-8,_9):- ,_6 >= I,_10 IS -6 - 1). -8 = LextenslonIl : alpha,l,child)) 1_111, 1-6 >= l,_lO is -6 _8 = ,extension(5 : alphal5,icecream)F 1_111, icecream,~l,,l._3._4._5,_~0._7,_11._9~. - 1). ~lpha~6,icecream,_l,_2,_3,_4,_5,_6,_?,_8,_9~:- C-6 >= l,_lO is -6 - 1). -8 = [extensionC6 : alpha,6,icecream)) I-111, icecream,Il,,lr-3r_4r_5,_10,_7,_11,_9). queryl_1._2._3._4._5._6~ :- model_initialization~,lallergenl, ichild], Lpredispol -5 = [extension,7 : query) I_Bl, allergen,[l.[l. ~1,_7~_9._1,_2._3,_4._8,_6)). writegrove*1_5,_6). 1.11. Fig. A2 The Prolog code resulting from Example (4). 64 T. Schaub, S. Briining /Art$cial Intelligence I06 (1998) 1-75 Proof. The only-if part of Lemma B. I is trivial since Conseq(Gj) subsumes Prereq(Gj) + in { 1, . . , i - 1). In what Conseq(Gj). To prove the if-part, follows, we abbreviate Prf?Wq(&) by Pk and COnSeq(&) by Ck. Since let j be an arbitrary number WU(p1 ‘Cl,... Pj-1 + Cj-11 k Pj we obviously have: wu{pl+cl,... Pj-l+Cj-l~Pj’Cj~Pj9Pj+l+Cj+l~...~ Pi-l + Ci-1 k Pi. (B.3) (B.4) Because of(i) {pi -+ Cj uj} l- cj and (ii) cj subsumes pj + cj, (B.4) is equivalent to w u {Pl + Cl ,...,Pj-l+Cj-13Cj,Pj,Pj+l+Cj+l,..., Pi-1 + Ci-11 I- pi. But due to (B.3), (B.5) is equivalent to w u IPl -+ Cl 3.+.,Pj-l +Cj-ltCj,Pj+l ‘Cj+l,...,Pi-1~Cj-l}t-Pi. Applying this argumentation for each j E { 1, . . . , i - 1 ), we get Lemma B. 1. q (B.5) (B.6) Proof of Theorem 3.2. In what follows, let (D’, W’) be the atomic format of (D, W) and let CW be the clausal representation to prove the theorem for default theory (D’, W’). of W’. Due to [79, Theorem 3.31 it is sufficient (if-part) Let R be a DME-refutation c = {q”}. Let D = {-ak, yk} be the set of S-clauses used throughout R. In what follows, a to di. The {‘W,YlI,..., S-clause {-a;, vi} is abbreviated by di. Let 6i be the default corresponding tableau generated by R is denoted by T. for M with top-clause ME-refutation Sinceforeachi It remains Since c is the top-clause of R, and a DME-refutation for M, we know (since ME is sound) for M can be viewed as a restricted that Cw U D U {c) is inconsistent. ~{l,..., to prove (see Definition 2.2) that conditions k}, di is subsumed by vi, it follows that W’ U (~1, . . . , yn) t- cp. (2) and (3) of Theorem 2.1 can if W’ U {yl , . . . , yn} is consistent. But steps (note that the only of S-extension fulfilled be guaranteed. Condition this is guaranteed by the compatibility-restriction to use a di in a derivation possibility (3) is obviously To show that condition is the application of a compatible S-extension (2) holds is more difficult. This is due to the fact that in one subrefutation of R, a clause dj might be used to prove a subgoal -ai, whereas in another of R, the S-clause di is used to prove ‘oj. Hence the order of the b-clauses subrefutation give use the desired order of the in the tableau generated by R does not automatically defaults 61, . . . , &. However, such an ordered sequence &, , . . . ,6i, of defaults (which satisfies condition in an iterative manner as follows: (2)) can be constructed step). Let TC = (tl, , . . , tl] be the tableau clauses in T that were generated by a-extension steps. Let c = {loi, vi] be an element from TC with a maximal depth in T. Due to the definition of reduction steps, no reduction step used in the subrefutation Ri of -ai uses an ancestor literal of loi. Hence, the subrefutation Ri constitutes a refutation of -ai. Further (due to the maximal depth of c), all the clauses needed for Ri of lt~i are clauses from W’. Hence, W’ k cxi and we can set ii = i. Z Schaub, S. Briining /ArtQicial Intelligence 106 (1998) l-75 65 To determine i2 we first modify R (and T): every subrefutation of -ai, in R is replaced by Ri . This is possible because due to the definition of reduction step in Ri can use an ancestor goal of -~i. Now, let TC = {tl , . . . , tl} be the tableau clauses in steps using clauses from {dl , . . . , &) - di,, and let T that were generated by b-extension yi} be an element from TC with a maximal depth in T. Again, (with the same c = (-ai, constitutes a refutation of -ai. Then, argumentation as above) the subrefutation Ri of -ai due to the above modification of R it is guaranteed that Ri only uses clauses from W and the d-clause di, . With Lemma B. 1 if follows that W’ U { yi, } I- cti and we can set i2 = i . steps, no reduction This procedure can be iterated k times sequence 6i,, . . . , 6i, fulfills condition (since only k different &clauses were used (2) which completes throughout R). The resulting the proof of the if-part. (only-if--part) The proof of the only-if-part is an induction of the number of defaults used in the default proof for p. Let c = (@}. (n = 0) !jince the default proof for q uses no default rules, we have W’ F cp. Due to the of ME, there must exist a ME-refutation R of CW U (c) with top-clause c. equals a DME-derivation without completeness Since we have shown in Section 3.1 that a ME-derivation d-extension steps, R is a DME-refutation, too. (n > 0) Let 61,. . . ,a,, be the sequence of default rules used in the default proof DP for 40. Note, that the existence of DP implies the existence of a default proof DP’ for 40 from ((62, . . . , S,,}, W U (~1)). Since DP’ uses only n - 1 default rules, the induction hypothesis tells us thal there exists a corresponding DME-refutation R for Cw - (-Cal, ~1) U (( y1 }, c} with top-clause c. In what follows we modify R in such a way that the resulting DME-refutation R’ is a DME-refutation for Cw U {c) with top-clause c. To this end, we make use of the fact, that there must exist a proof for Cal from (0, W). Hence, there exists a DME-refutation R1 of CW U {--al ) with top-clause steps. Further, we can since each open goal assume that RI does not contain extension ~1 can be solved via a reduction step to the top-clause is in RI. only used as top-clause (-al) which uses no S-extension steps with clause (-al) literal 1~1. Hence, clause (-al) Now it is easy to construct R’. We simply replace each tableau clause {n) tableau clause (-YY~ , ~1). This replacement step with unit clause (~1) by a A-extension step with A-clause ( -CY~ goals can be solved via a subrefutation corresponds to RI. corresponding steps used in R’ is compatible That each of the a-extension (3) of Theorem 2.1 and the fact that the set of &extension by R’ equals (~1, . . . , yn) (consider the construction of R’ given above). o in R by the to a replacement of an extension , ~1). The resulting open is a consequence of condition literals in the tableau generated Proof of ‘I’heorem 3.3. Suppose the conditions of Definition 3.7 are fulfilled. Let Mw be the set of cc)-clauses in M, MD be the set of S-clauses in M, and let D’ be the set of defaults corresponding to the elements of MD. Then it is obvious that there exists a DME-refutation R with top-clause h(o) that uses only clauses from Mw U MD U ((h(ol))) U. . . U ((h(o,))) for extension steps. Further, the (i E (1, . . . , n)) in R can be restricted use of unit clauses (h(oi)) steps that are applied to nodes that do not have ancestors which are a-resulting nodes (note that these reduction steps during D; due to Definition 3.5, unit clauses are only needed to “substitute” to w-extension 66 I: Schaub, S. Briining /Artificial Intelligence IO6 (1998) l-75 these reduction steps were not used in a subrefutation of some a-resulting by D). This implies (see Theorem 3.2) that there is an enumeration literal generated (Si)i,l of D’ such that: Mw U Ch~eq({Sl, . . . , &i-l}) I- f’~~q(Gi), Mw U Conseq({S1,. . . , Si_I}) y -Conseq(&). (B.7) 03.8) Now, it is quite easy to recognize that for every i E { 1, . . . , n} there exists a default proof of +(oi) from (M’, 0’) where M’ = Mw U { {h(ol)}} U . . . U {{A(&-l))} U {Ih(@+l)J} U”’ u { mdJ} u {VW}. This is due to (B.7) and (B.8) and the fact that Mw u Mo U { IUol)}} U.. . u { {WJJ} U { GWJ} must be inconsistent corresponding DME-refutation R’ with top-clause [;i(oi)}. (otherwise R would not exist). Hence, we know that there exists a Furthermore, due to (B.7) and (B.8), we know resulting nodes in R can be used to prove S-extension-resulting R’ without any modification. This implies, (jE{l)..., o-extension-resulting resulting node. literal that has no node among its successors n}) and (A(o)} are only used for extension i-1,i+1,..., that the subproofs of S-extension- nodes generated during that in the course of R’, the unit clauses {h(oj)} steps to prove a that is a &extension- Now we can turn to the proof of Theorem 3.3. For readability, we distinguish the nodes given in this theorem by attaching a prime to each identifier. We thus have: Let 7 be a tableau generated by a DME-derivation (O’,, . . .) 0:, . . . , oh) be a branch of 7. from CW U Co, and let b = . . . , uk are w-extension-resulting If o;+,, can be marked as closed without losing soundness. nodes and 1 G [h(oL), . . . , k(ok)], then b Let{ko,...,k,}beasubsetof{v,...,m}suchthatZ={h(o~),...,~(o~~)}andko<k2< . . . < kn. For simplicity, we assume that m = k,, (i.e., ui lemma 1 could have been applied earlier in course of thlderivation). is the leaf node of b) (otherwise, Due to the above considerations, we know that there is a DME-refutation clause {h(d;,)} which uses clauses from Mw, MD and the unit clauses {h(oij)} R” with top- (where j # n) for extension steps. Further, these unit clauses are used during R” only to prove w- extension-resulting This, together with the fact that the b-clauses without violating consistency applied their successors. step that R” can be (a(~;~)} has to be literals among in R” can be used for any d-extension (see the conditions of the theorem), literals with no S-extension-resulting step using one of the unit clauses to ob . Only each extension implies replaced by i corresponding extension-resulting literals). Hence, b can be marked as closed. q reduction step (what is possible since o:+~, . . . ,oh are o- Proof of Theorem 3.4. Since 7 is is not blockwisely (1) or condition it must violate condition (2) of Definition 3.10. First, we show that in case 7 violates condition regular, I: Schaub, S. Briining /Arti$cial Intelligence 106 (1998) 1-75 61 (2), there exists a DME-refutation condition (2). R” that generates a tableau 7” which does not violate two d-extension are labeled with the same literal. Since oj is a a-extension If 7 violates condition (2), 7 contains a branch b = 01, . . . , on that violates condi- tion (2), that is b contains resulting nodes, oi and oj (i -C j) say, such that re- prev(oi) and prev(nodej) sulting node. no reduction step that was applied to a successor node of oj uses an ancestor node of oj (note that no reduction step can be applied to oj). But then, it is obvious that the DME-subrefutation to prev(oi). The resulting than R, and the tableau generated by R1 is strictly DME-refutation smaller than 7. Hence, this transformation can only be applied finitely many times and the resulting DME-refutation R” generates a tableau 7” that agrees with condition applied to prev(oj) R1 is strictly smaller can be applied directly (2). Second, we show that in case 7” violates condition (l), there exists a DME-refutation (l), and let 01, . . . , on be a R’ that is blockwisely block such that for two different nodes, oi and oj say, h7’ (oi) = Al” (oj). Then, let S1 be a clause set containing regular. Suppose 7” violates condition (i) W7”(ol)J, (ii) each tableau clause whose corresponding nodes are successors of 01 and belong to (iii) blocks starting with 01, and the unit clauses (A7” (ok,)], . . . , (AT” (okl)}, where Ok,, generated by S-extension and 110 node between 01 and Oki was generated by a S-extension . . . , Ok, are extension nodes steps such that for each 1 < i < I, Oki is a successor of 01 step. is a closed tableau, it is quite easy to see that there exists an ME-refutation Since 7” of S1 with top-clause {A/“(ol)}. But then there also exists a regular ME-refutation Rs of S1 with top-clause {h7”(ol)}. Let DS be the subderivation all derivation be a o-clause). That is, the only derivation initialization that contains steps of Rs that use clauses from M (note that each of these clauses must to DS are the . . . , {hT”(okr)). steps of 01 in R” are removed. The resulting derivation D1 to this labeled with steps with the unit clauses to the subrefutation a tableau with one open goal, namely derivation D2 contains h7” (01). Now, apply DS open goals belonging generates open goal. The step and extension steps using the unit clauses in {h7”(ok,)}, Rz from R” as follows: all derivation steps of Rs that do not belong Now, we construct applied to k7”(01) (in Rs, extension a DME-refutation that are resulting liter& frOn1 . . . , -h7”(OkI)) (Ok, ), {--h7” {a7” (Ok, ) ) , . . . , (h7”(okl)} are applied the DME-subrefutation for each 1 < i < I, that was applied to oki in R” is applied to the open goals labeled to these open goals). Finally, with A7” (or:.). (2). This is because the transformation Note, thalt the tableau 72 which is generated by the resulting DME-refutation R2 cannot steps and steps that use literals from that in case some literal L in 72 too, violate condition reduction steps to literals stemming S-clauses remain unchanged. that stems from a b-clause and has an ancestor this also holds for 7” (and therefore 72 cannot violate condition literal L’ that stems from a d-clause, (2)). only affects w-extension from w-clauses. it is guaranteed In particular, Inference However., R2 may be longer that R” and 72 may even contain more blocks than 7” that violate blockwise can only be regularity. However, it is easy to see that the transformation applied finitely many times. To this end, observe that the maximal number ml of blocks on Since m 1 is finite and the maximal one branch (does not increase during the transformation. 68 I: Schaub, S. Briining /Art$cial Intelligence 106 (1998) 1-75 number of literals per clause is finite, too, the maximal number rn2 of blocks in a tableau can be applied at most m2 times. is limited by a fix constant. Hence, our transformation Afterwards, regular tableau the resulting DME-refutation 7’. R’ must generate a blockwisely 13 B.3. Proofs of theorems in Sections 4 and 6 Proof of Theorem 4.1. Let W be a set of formulas and (Si)iel a sequence of normal default rules. Consider 6i for some i E I. By definition of V, we have V(&, (m, W, CSjljd)) =(m’, W, (aj)j<i) iff m’ is some model for W U (Conseq(Sj) 1 j < i). This includes m is a model of W U Conseq({Go, . . . , Si-1)) and by definition of V, m b Conseq(&). the case of m = m’ since And V(&, (m, W, (Sj)j<i)> = -l iff there is no model for W U {Conseq(Gj) 1 j < i}. two cases: We thus distinguish (1) W U Conseq({So, This is equivalent itself equivalent . . . . &-I}) to W U Conseq({So, tf lCOKWq(Gi). . . . , Si}) y 1. By propositional logic, this is to the existence of a model m such that m + W U (CO&Seq(Gj) 1 j < i} which proves the claim. (2) W U Conseq({Go, . . . , Si-I}) I- ~COKXq(&). This is equivalent itself equivalent establishes to the non-existence 0 the claim. to W U Conseq({So, . . . , 8,)) k 1. By propositional of a model for W U { Conseq(Gj) logic, this is I j < i} which Proof of Theorem 6.1. (if-part) Let (E, C) be a contextual extension of semi-monotonic contextual default theory (D, W) . Consider the set of generating contextual default rules The case where r = 0 is trivial so that we concentrate on non-empty r: according to [12, Theorem 5.11, r satisfies (24). That is, E = T/t(E) = Th(W U Conseq(r)), C = %(C) = Thwuconseq(r)uJustifC(r) (h&fE(r)). (B.lO) (B.ll) 03.9) Condition contextual extension. (29, that is groundedness, is also verified by r, due to the definition of a For ensuring condition (26), we observe that Justifc(~) # 0 and JustifE(r) # 0 provided that r # 0. We have -PC 4 ThWUconseq(r)UJustifc(r) (JuStifE m) I: Schuub, S. Briining /Art$cial Intelligence IO6 (1998) 1-75 69 for all PC E .Zustifc (r) . That is, Or, W U Conseq(F) U.hst$C(F) U {BE} if -/?C for all BE E .ZustifE (f ) . By PC E Justifc (r), we get W U Conseq(r) U Justifc(r) y -BE for all BE E JustifE(F). By monotonicity, thus establkhing condition Finally, suppose that r (26). is not maximal. Then, there is some r’ 2 r with some this property holds for any subset r’ 2 r, too, loI BCIBEI cr’\r Y satisfying conditions (25) and (26). Condition (25) implies 01 E E. Moreover, we have W U Conseq( I+) U Justifc (f ‘) y -BE for all /?E E JudfE manipulations BE +! E by monotonicity. Consequently, (I”). The fact r’ satisfies condition (24), yields by inversing that /Ic 4 C; also, we get from the previous non-derivability proposition the above that lo!1 :kIBEI Er; Y a contradiction. (only-if-part) Let (Si)ieZ be an enumeration of some maximal D’ g D satisfying conditions Consider (24)-(26). the sequence of default theories ({Sj E! D I j < i}, W) for i E Z along with a family of pairs of sets of formulas (( Ei , Ci))i,r such that Ei = Th(W U Conseq({Gj E D I j < i})), Ci = ThEi”Justifc((sjEolj<i))(JustifE(ISi E D I j < ‘I>)* With these, we define r,= I loI :kkIbi i Y ED @JEEEi,TBC$CiTIBE$Ei . By constructionof ((Ei, Ci))i,l and (T;)ieZ, we have E=[JEi, C=UCi, ~=UI;: iei id ieZ where E and C are defined in (24) and r is defined in (B.9). 7-Q I: Schaub, S. Briining /Artificial Intelligence IO6 (1998) 1-75 We prove by induction on I that (Ei+t, Ci+t) is an extension of ((Sj E D 1 j < i), W) and that (6j E D ) j 6 i) C I;:+1 for all i E I. From this, it follows by semi-monotonicity that (E, C) is a contextual extension of (D’, W). Clearly, (T/z(W), Thw(0)), or equivalently Now, suppose is an extension of (0, W). (T/z(W), Z%(W)), (Ei, Ci) is an extension of ({Sj E D I j < i), W) with (6j E D 1 j < i) C (E’, C’) of ((Sj E D ) j < i), W) there is contextual extension c. By semi-monotonicity, such that Ei s E’ and Ci C C’. Depending on whether si= IUI : BCISEI Y contributes to (E’, C’), we must consider two cases: a We have E’ = Ei and C’ = Ci and so either UE $ E’ or -PC E C’ or ‘BE E E’. Because W s Ei C E’ and {Sj E D I j < i) s c have -/!?c E C’ or -BE E E’. to (26) According imply cz~ E E’ by (23, we thus W U ConSeq({Su, . . , Si)) UJkStif~({&), . . . , Si)) If-B . . . , Si)). for all /3 E JudfE((60, By the fact that E’ = Ei = Th(W U Conseq({Gj E D I j < i))) and monotonicity, we deduce that -BE $ E’ (recall that /3~ = JustifE(%)). Rewriting order, yields: statement as done in the first part, yet in reverse the above non-derivability -DC 6 “WUC,,,e4({S,,...,Gi])UJusrifc((60,...,6i))(J”tifE(I’O, . . . t &I>) for all #Ic E Justif, the definition of C’ and monotonicity This is in contradiction to the assumption that -PC $ C’ (recall that PC = JUstifc(Si)). that E’ = Ei and C’ = Ci . ((60, . . . , 6i )) . As in the case of E’ and BE, we obtain by appeal to l We have E’ = Ei+l and C’ = Ci+l and SO a,y E E’ and -PC $ C’ and -BE 4 E’. that (Ei+l, Ci+l) is a contextual extension of ({Sj E D I j < i), W) and This implies that (6j E D I j < i) c fi+t. We have shown that (E, C) is a contextual extension of (D’, W). By maximality of D’, any contextual default rule 6 E D \ D’ violates either (25) or (26). This disqualifies any (E’, C’) with E c E’ and C C C’ that such 6 to contribute could be obtainable by semi-monotonicity. Hence, (E, C) is also a contextual extension of to any contextual extension (D,W). q Proof of Theorem 6.2. Let W be a set of formulas and (6i)iel a sequence of contextual default rules such that Si E D* for all i E I. Consider 6i= Ia!1 :kIBEI Y for some i E I and K = {0, . . . , i - 1) and L = {0, . . . , i). By definition of V, we have V(&3 (MT WT (Bk)kK)) = (M’, W3 (~Z)l~L) I: Schub, S. Briining /Artijicial Intelligence 106 (1998) l-75 71 iff there is al non-empty M = M’ because by assumption M & Mw(K), that is, set of models M’ 5~ Mw(L). This comprises the case where M G lJkEKM;W) and MnMk(K)#0 forallkEK. Because M I= y A ,!?c, we have for all k E K that M~(K)={mI+WUC onseq(K) U Justifc(K) U {Justify]} = {m 1 m + W U Conseq(L) UJustif~(L) U (Justify}} = M&(L), while m b PIE for some m E M gives us (by recalling that BE = Justif E(&)) MnM~(K)#0. Hence, M is also a non-empty set of models such that M LL Mw (L). And V(&, (M, W, (&)/WY)) = 1 iff there is no set of models M such that M LL Mw(L). This follows from the fact that there is no M” & Mw (K) satisfying y A /3c and including some m with m b BE. In analogy (1) Condition to Proof 4.1, we consider (26) is true. That is, two cases: we thus distinguish two cases: W U Conseq({So, . . . ,8i}) U JUdfc({So, . . . ,a,}) tf-J~~tif~(Sk) for all k E (0,. . . , i } . Or equivalently, W U Conseq({Go, . . . , &)) U JuGifc((60,. . . , Si}) U (.h.dfE(fik)) y _L for all k E (0, . . . , i). By propositional logic, this is equivalent to the existence of a model mk such that mk + W U Conseq((Go, . . . , Sj)) U Justifc((60,. . . , &)) U {JustifE(&)) for all! k E (0,. . . , i). Defining M = U kE~o,.,,,i~(mk) establishes (26) is false. That is, (2) Condition the claim. W U Conseq((Go, . . . ,%)) U JUstifc((So, . . . ,8i)) k dLYtif~(~k) for some k E (0, . . . , i). Or equivalently, W U Conseq((Go, . . . , Si)) U JUstifc((Go, . . . , Si)) U (JUStifE(Sk)) E I for some k E (0, . . . , i). logic, By p:ropositional satisfying this is equivalent to the non-existence of a model ink ink + W U Conseq((8o, . . . , &)) U Justifc((60, . . . , Sj)) U (Justify) forsomekE(O,...,i). In other words, M;(L) = 0 for some k E (0, . . . , i). That is, there cannot be any s’et of models M satisfying M EL Mw(L) k E (0, . . . , i). q since M f’ M&(L) = 0 for some 12 T Schmb, S. Briining /Artificial Intelligence 106 (1998) I-75 References [l] H. Ait-Kaci, Warren’s Abstract Machine: A Tutorial Reconstruction, MIT Press, Cambridge, MA, 1991. [2] G. Amati, L. Aiello, D. Gabbay, F. Pirri, A proof theoretical approach to default reasoning I. Tableaux for default logic, J. Logic Comput. 6 (2) (1996) 205-231. [3] K. Apt, H. Blair, A. Walker, Towards a theory of declarative knowledge, in: J. Minker (Ed.), Foundations of Deductive Databases and Logic Programming, Morgan Kaufmann, San Mateo, CA, 1987, Chapter 2, pp. 89-148. [4] 0. Astrachan, M. Stickel, Caching and lemmaizing in model elimination theorem provers, in: D. Kapur Intelligence, Vol. 607, (Ed.), Proceedings Conference on Automated Deduction, Lecture Notes in Artificial Springer, Berlin, 1992, pp. 224-238. [5] E Baader, B. Hollunder, Embedding defaults into terminological knowledge representation formalisms, in: B. Nebel, C. Rich, W. Swartout Knowledge Representation [6] A. Baker, M. Ginsberg, A theorem prover for prioritized circumscription, and Reasoning, Cambridge, MA, October 1992, pp. 306317. in: Proceedings International Joint (Eds.), Proceedings 3rd International Conference on the Principles of Conference on Artificial Intelligence (IJCAI-89), Detroit, MI, 1989, pp. 463-467. [7] P Baumgartner, U. Furbach, Model ehmination without contrapositives, Conference on Automated Deduction, Lecture Notes in Artificial 1994, pp. 87-101. in: A. Bundy (Ed.), Proceedings Intelligence, Vol. 814, Springer, Berlin, [8] P Baumgartner, U. Furbach, Model elimination without contrapositives and its application to PTTP, in: Preprints Tableaux-94, 1994. [9] P. Baumgartner, U. Furbach, PROTEIN: a PROver with a Theory Extension in: A. Bundy (Ed.), Proceedings Conference on Automated Deduction, Lecture Notes in Artificial Intelligence, Vol. 814, Springer, Berlin, 1994, pp. 769-773. INterface, [lo] J.L. Bell, M. Machover, A Course in Mathematical Logic, North-Holland, Amsterdam, [ll] R. Ben-Eliyahu, R. Dechter, Default logic and constraints, logic, propositional 1977. in: Proceedings AAAI National Conference on Artificial Intelligence (AAAI-91), Anaheim, CA, MIT Press, 1991, pp. 37&385. [12] P. Besnard, T. Schaub, An approach to context-based default reasoning, Fundamenta Informaticae 23 (2-4) (1995) 175-223. [ 131 P. Besnard, R. Quiniou, P. Quinton, A theorem-prover AAAI National Conference on Artificial Intelligence for a decidable subset of default logic, in: Proceedings (AAAI-83), Washington, DC, 1983, pp. 27-30. [14] W. Bibel, S. Brtining, U. Egly, T. Rath, KoMeT, in: A. Bundy (Ed.), Proceedings Conference on Automated Deduction, Lecture Notes in Artificial Intelligence, Vol. 84, Springer, Berlin, 1994, pp. 783-787. [15] W. Bibel, Automated Theorem Proving, 2nd ed., Vieweg, Braunschweig, [16] P. Bonatti, N. Olivetti, A sequent calculus for skeptical default logic, in: Proceedings Tableaux-97, Lecture 1987. Notes in Artificial Intelligence, Vol. 1227, Springer, Berlin, 1997, pp. 107-121. [17] P Bonatti, Proof systems for default and autoepistemic (Eds.), Proceedings Tableaux-96, Lecture Notes in Artificial in: P. Miglioli, U. Moscato, D. Mundici, Intelligence, Vol. 1071, Springer, logic, M. Omaghi Berlin, 1996, pp. 127-142. [18] S. Brass, Deduction with supernormal defaults, in: P. Schmitt, G. Brewka, K. Jantke (Eds.), Nonmonotonic and Inductive Logic, Springer, Berlin, 1991, pp. 153-174. [19] G. Brewka, Cumulative default logic: in defense of nonmonotonic inference rules, Artificial Intelligence 50 (2) (1991) 183-205. [20] S. Brilning, T. Schaub, A model-based approach (Eds.), Proceedings 9th International Symposium on Methodologies in Artificial Intelligence, Vol. 1079, Springer, Berlin, 1996, pp. 315-324. to consistency-checking, in: Z. Ras, M. Michalewicz for Intelligent Systems, Lecture Notes [21] S. Brtining, T. Linke, P. Nicolas, T. Schaub, Prolog technology and the XRay system, Technical Report, Institute of Informatics, University of Potsdam, 1998. (This is an extended version of [59].) Full version in preparation. [22] S. Ceri, G. Gottlob, L. Tanca, Logic Programming [23] C.L. Chang, R.C.-T. Lee, Symbolic Logic and Mechanical Theorem Proving, Academic Press, New York, and Databases, Springer, Berlin, 1990. for default reasoning: implementation 1973. [24] P. Cholewiriski, V. Marek, A. Mikitiuk, M. Truszczyriski, Experimenting with nomnonotonic reasoning, in: Proceedings International Conference on Logic Programming, MIT Press, Cambridge, MA, 1995. 7: Schaub, S. Briining /Artificial Intelligence 106 (1998) l-75 73 [25] P. Cholewiriski, V. Marek, M. Truszczydski, Default reasoning tional Conference on the Principles of Knowledge Representation Mateo, CA, 1996. system DeReS, in: Proceedings 5th Intema- and Reasoning, Morgan Kaufmann, San [26] P. Cholewifiski, Reasoning with stratified default theories, and Nonmonotonic Reasoning, 1995. Logic Programming in: Proceedings 3rd International Conference on [27] W. Clocksin, C. Mellish, Programming [28] M. Davis, H. Putnam, A computing procedure in Prolog, Springer, Berlin, 1981. for quantification theory, Journal of the ACM 7 (1960) 201- 215. [29] J. de Kleer, An assumption-based [30] J. Delgranh, T. Schaub, W. Jackson, Alternative approaches truth maintenance system, Artificial Intelligence 28 (1986) 163-196. to default logic, Artificial Intelligence 70 (l-2) (1994) l<r-237. [31] E. Eder, Relative Complexities of First-Order Calculi, Vieweg, Braunschweig, [32] H. Enderton, A Mathematical Introduction J. Crawford, Towards [33] D. Ether&ton, to Logic, Academic Press, New York, 1972. reasoning, efficient default 1992. in: Proceedings AAAI National Conference on Artificial Intelligence (AAAI-96), Portland, OR, 1996, pp. 627632. search algorithms, Ph.D. Thesis, University of [34] J.W. Freeman, Pennsylvania, to propositional Improvements 1995. J. Mengin, Default logic: a unified view, Computational satisfiability [35] C. Froidevaux, [36] D. Gabbay, C. Hogger, J. Robinson (Eds.), Handbook of Logic Programming, Oxford University Press, Oxford, 1994. circumscriptive [37] M. Gelfond, V. Lifschitz, Compiling theories in: Proceedings AAAI National Conference on Artificial Kaufmann, San Mateo, CA, 1988, pp. 455-459. Intelligence Intelligence 10 (3) (1994) 331-369. and Logic Intelligence in Artificial into logic programs: report, (AAAI-88), St. Paul, MN, Morgan preliminary [38] M. Gelfortd, V. Lifschitz, H. Przymusinska, M. Truszczyiiski, Disjunctive defaults, in: J. Allen, R. Fiies, (Eds.), Proceedings 2nd International Conference on the Principles of Knowledge Represen- E. Sandewall tation and Reasoning, Cambridge, MA, Morgan Kaufmann, San Matco, CA, 1991, pp. 230-237. [39] M. Ginsberg, A circumscriptive [40] L. Giordano, A. Martinelli, On cumulative default logics, Artificial Intelligence 66 (1) (1994) 161-179. [41] C. Goller. R. Letz, K. Mayr, J. Schumann, SETHEO V3.2: recent developments, theorem prover, Artificial Intelligence 39 (1989) 209-230. in: A. Bundy (Ed.), Intelligence, Vol. 814, Proceedings Conference Springer, Berlin, 1994, pp. 778-782. on Automated Deduction, Lecture Notes in Artificial [42] G. Gottlob, Complexity [43] N. Helft, K. Inoue, D. Poole, Extracting results for nomnonotonic l-4-28 Mita, Minato-ku, Tokyo 108, Japan; University of British Columbia, Vancouver, B.C., Canada V6T lW5, December 1989; ICOT Technical Memorandum No. 855. ICOT Research Center, in circumscription, answers logics, J. Logic Comput. 2 (3) (1992) 397-425. [44] T. Hoppe, Incremental Partial Deduction, Dissertationen zur Kiinstlichen Intelligenz., Vol. Diski 97, Infix, 1995. [45] U. Junker, K. Konolige, Computing Proceedings AAAI National Conference on Artificial Intelligence 283. the extensions of autoepistemic and default logic with a TMS, in: (AAAI-90), Boston, MA, 1990, pp. 278- [46] D. Knuth. The Stanford GraphBase: A Platform for Combinatorial Computing, Addison-Wesley, Reading, MA, 1993. [47] R. Letz, S. Bayerl, J. Schumann, W. Bibel, SETHEO: a high-performance theorem prover, J. Automat. Reason. 8 (2) (1992) 183-212. [48] R. Letz, K. Mayr, C. Goller, Controlled J. Automat. Reason. 13 (3) (1994) 297-338. integrations of the cut rule into connection tableau calculi, [49] R. Letz, Fist-order calculi and proof procedures for automated deduction, Ph.D. Thesis, Technische Hochschule Darmstadt, Fachbereich Informatik, 1993. [50] F. L&y, (Computing extensions of default theories, Conference on Symbolic and Quantitative Approaches Vol. 548, Springer, Berlin, 1991, pp. 219-226. in: R. Kruse, P. Siegel (Eds.), Proceedings European for Uncertainty, Lecture Notes in Computer Science, [51] T. Linke, T. Schaub, Lemma handling in default logic theorem provers, in: C. Froidevaux, J. Kohlas (Eds.), Proceedings European Conference on Symbolic and Quantitative Approaches Lecture Notes in Artificial Intelligence, Vol. 946, Springer, Berlin, 1995, pp. 285-292. to Reasoning and Uncertainty, 74 Z Schaub, S. Brtining /Art$cial Intelligence 106 (1998) I-75 [52] T. Linke, T. Schaub, Towards a classification of default logics, J. Appl. Non-Classical Logics 7 (4) (1997) 39745 1. [53] D. Loveland, Automated Theorem Proving: A Logical Basis, North-Holland, Amsterdam, [54] D. Loveland, Mechanical [55] W. Lukaszewicz, Considerations theorem proving by model elimination, Journal of the ACM 15 (1986) 236-25 1. Intelligence 4 alternative approach. Computational on default logic-an 1978. (1988) 1-16. [56] W. Marek, M. Truszczyiiski, Nonmonotonic Logic: Context-Dependent Reasoning, Artificial Intelligence, Springer, Berlin, 1993. [57] W. Marek, M. Truszczyriski, Normal form results for default logics, and Inductive Logic, Lecture Notes in Artificial in: G. Brewka, K. Jantke, P. Schmitt Intelligence, Vol. 659, Springer, (Eds.), Nomnonotonic Berlin, 1993, pp. 153-174. [58] A. Mikitiuk, M. Truszczyriski, Rational default (Eds.), Proceedings logic and disjunctive 2nd International Workshop on Logic Programming logic programming, in: A. Nerode, and Nonmonotonic L. Pereira Reasoning, MIT Press, Cambridge, MA, 1993, pp. 283-299. [59] I? Nicolas, T. Schaub, The XRay system: an implementation platform for local query answering in default in Information Systems, in: A. Hunter, S. Parsons (Eds.), Applications logics, Lecture Notes in Artificial Intelligence, Springer, Berlin, 1998. of Uncertainty Formalisms [60] I. Niemell, P. Simons, Evaluating an algorithm and Implementations Workshop on Applications 1995, pp. 66-72. for default reasoning, in: Working Notes of the IJCAI-95 of Nonmonotonic Reasoning Systems, Montreal, Quebec, [61] I. Niemell, Decision procedure for autoepistemic logic, in: Proceedings Ninth International Conference on Automated Deduction, Argonne, IL, 1988, pp. 675-684. [62] I. Niemell, A decision method for nonmonotonic in: J. Doyle, reasoning based on autocpistemic (Eds.), Proceedings 4th International Conference on the Principles of Knowledge reasoning, [63] I. Niemela, Towards efficient default and Reasoning, Bonn, Germany, Morgan Kaufmann, San Mateo, CA, 1994, pp. 473484. in: C. Mellish Joint (IJCAI-95) Montreal, Quebec, Morgan Kaufmann, San Mateo, CA, (Ed.), Proceedings International reasoning, P. Torasso, E. Sandewall Representation Conference on Artificial 1995, pp. 312-318. Intelligence [64] D. Poole, R. Goebel, R. Aleliunas, Theorist: a logical reasoning N. Cercone, G. McCalla Springer, New York, 1987, Chapter 13, pp. 331-352. (Eds.), The Knowledge Frontier: Essays for defaults and diagnosis, in: system in the Representation of Knowledge, [65] D. Poole, A Theorist to Prolog Compiler, Logic Programming of Computer Science, University of Waterloo, October 1987. and Artificial Intelligence Group, Department [66] D. Poole, Variables in hypotheses, in: Proceedings International Joint Conference on Artificial Intelligence (IJCAI-87), Milan, Italy, Morgan Kaufmann, San Mateo, CA, 1987, pp. 905-908. for default reasoning, Artificial Intelligence 36 (1988) 2747. [67] D. Poole, A logical framework [68] D. Poole, What the lottery paradox R. Reiter (Eds.), Proceedings and Reasoning, Toronto, Ontario, Morgan Kaufmann, San Mateo, CA, 1989, pp. 333-340. tells us about default in: R. Brachman, H. Levesque, reasoning, 1st International Conference on the Principles of Knowledge Representation [69] D. Poole, Compiling a default reasoning system into Prolog, New Generation Computing 9 (1) (1991) 3-38. [70] T. Przymusinski, An algorithm [71] R. Reiter, A logic for default reasoning, Artificial [72] V. Risch, Analytic [73] A. Rothschild, Algorithmische tableaux for default logics, J. Appl. Non-Classical Logics 6 (1) (1996) 71-88. to compute circumscription, Artificial Intelligence 38 (1) (1989) 49-73. zu Defaultlogiken, Diplomarbeit, Intelligence 13 (l-2) FG Intellektik, FB (1980) 81-132. Untersuchungen Informatik, TH Darmstadt, Germany, 1993. [74] A. Sattar, R. Goebel, Using crucial literals to select better theories, Computational Intelligence 7 (1) (1991) 1 l-22. [75] T. Schaub, S. Brtining, Prolog technology Conference on Artificial Intelligence for default reasoning, in: W. Wahlster (Ed.), Proceedings European (ECAI-96). Wiley, New York, 1996, pp. 105-109. [76] T. Schaub, P. Nicolas, An implementation theoretical in: Z. Ras, A. Skowron (Eds.), Proceedings 10th International Symposium on Methodologies underpinnings, for Intelligent Systems, Lecture Notes in Artificial Intelligence, Springer, Berlin, 1997. for query answering in default platform logics: [77] T. Schaub, S. Brtining, P. Nicolas, XRay: a Prolog technology theorem prover for default reasoning: a system J. Slaney (Eds.), Proceedings Conference on Automated Deduction, Lecture description, Notes in Artificial Intelligence, Vol. 1104, Springer, Berlin, 1996, pp. 293-297. in: M. McRobbie, T Schaub, S. Briining /Artificial Intelligence 106 (1998) 1-75 15 [78] T. Schaub, On constrained default Intelligence Artificial [79] T. Schaub. A new methodology theories, in: B. Neumann (Ed.), Proceedings European Conference on (ECAI-92), Vienna, Austria, Wiley, New York, 1992, pp. 304-308. in default logics via structure-oriented for query answering theorem proving, J. Automat. Reason. 15 (1) (lY95) 95-165. [80] T. Schaub, The family of default logics, in: D. Gabbay, P. Smets (Eds.), Handbook of Defeasible Reasoning and Uncertainty Management Systems, Vol. 2, Oxford University Press, Oxford, 1998, Chapter 5. [81] C. Schwirtd, V. Risch, Tableau-based characterization and theorem proving for default logic, J. Automat. Reason. 13 (1994) 223-242. [82] C. Schwirtd, A tableaux-based theorem prover for a decidable subset of defauit logic, in: M. Stickel (Ed.), Proceedings Conference on Automated Deduction, Springer, Berlin, 1990. [83] XRay, An implementation platform for local query answering in default logics, URL http : / /www _ haiti.cs.uni-potsdam.de/"xray,1998. [84] R. Shostak, Refutation graphs, Artificial Intelligence 7 (1976) 5 l-64. [85] J. Slaney, SCCYTT: a model-guided theorem prover, in: Proceedings Artificial :[ntelligence (IJCAI-93), Chamb&y, France, 1993, pp. 109-114. International Joint Conference on [86] M. Stickel, A Prolog technology [87] M. Stickel, A Prolog technology theorem prover, New Generation Computing 2 (1984) 371-383. theorem prover: a new exposition and implementation Institute (SRI), Menlo Park, CA, 1989. in Prolog, Technical Report Technical Note 464, Stanford Research [88] M. Stickel, A Prolog technology theorem prover, in: M. Stickel (Ed.), Proceedings Conference on Automated Deduction, Lecture Notes in Artificial Intelligence, Vol. 449, Springer, Berlin, 1990, pp. 673674. [89] M. Thielscher, T. Schaub, Default reasoning by deductive planning, J. Automat. Reason. 15 (1) (1995) l-10. Intelligence [90] H. Turner, Splitting a default theory, in: Proceedings AAAI National Conference on Artificial (AAAI-96), Portland, OR, 1996, pp. 64545 1. [91] Z. Umrigar, V. Pitchumaui, An experiment in programming with full first-order logic, in: IEEE 1985 Symposium on Logic Programming, Boston, MA, 1985, pp. 4&47. 