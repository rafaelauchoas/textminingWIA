Artificial Intelligence 174 (2010) 1323–1338Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintWhen is it better not to look ahead?Dana S. Nau a,∗, Mitja Luštrek b, Austin Parker a,1, Ivan Bratko c, Matjaž Gams ba University of Maryland, College Park, MD, USAb Jožef Stefan Institute, Ljubljana, Sloveniac University of Ljubljana, Ljubljana, Sloveniaa r t i c l ei n f oa b s t r a c tArticle history:Received 28 July 2009Received in revised form 30 July 2010Accepted 31 July 2010Available online 11 August 2010Keywords:Lookahead pathologyMinimaxGame-tree search1. IntroductionIn situations where one needs to make a sequence of decisions, it is often believed thatlooking ahead will help produce better decisions. However, it was shown 30 years ago thatthere are “pathological” situations in which looking ahead is counterproductive. Two long-standing open questions are (a) what combinations of factors have the biggest influenceon whether lookahead pathology occurs, and (b) whether it occurs in real-world decision-making.This paper includes simulation results for several synthetic game-tree models, andexperimental results for three well-known board games: two chess endgames, kalah (withsome modifications to facilitate experimentation), and the 8-puzzle. The simulations showthe interplay between lookahead pathology and several factors that affect it; and theexperiments confirm the trends predicted by the simulation models. The experiments alsoshow that lookahead pathology is more common than has been thought: all three gamescontain situations where it occurs.© 2010 Elsevier B.V. All rights reserved.In situations where one needs to make a sequence of decisions, it is often believed that looking ahead (to predictthe possible results of one’s actions) leads to better decisions. There have been some dramatic demonstrations of thisprinciple in board games such as chess and checkers, where the performance of computer programs has greatly improvedas improvements in computers and algorithms have made it possible to look farther ahead in the same amount of time [1,2].On the other hand, there are theoretical results saying that looking ahead does not always lead to better decisions.Thirty years ago a class of games was discovered [3] having a counterintuitive property called lookahead pathology, in whichsearching farther ahead consistently led to worse decisions rather than better ones. Furthermore, a game-tree model thatwas considered realistic at the time turned out to be pathological [4].Although many explanations of lookahead pathology have been proposed and several factors affecting it have been found[3,5–19], these studies have several limitations:• They have typically focused on a single factor at a time, without giving a clear understanding of the interplay among thefactors. Consequently, several researchers have claimed—erroneously, in our view—that one or another of these factorswas the reason for the absence of lookahead pathology in most real-world situations.* Corresponding author.E-mail addresses: nau@cs.umd.edu (D.S. Nau), mitja.lustrek@ijs.si (M. Luštrek), ajpark2@super.org (A. Parker), bratko@fri.uni-lj.si (I. Bratko),Matjaz.Gams@ijs.si (M. Gams).1 Current address: Center for Computing Sciences, 17100 Science Drive, Bowie, MD 20715, USA.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.08.0021324D.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–1338• Although lookahead pathology occurs in mathematical models and “artificial” games such as Pearl’s game [5], it hasremained unclear as to whether lookahead pathology occurs in real-world decision-making or is just a mathematicalcuriosity.The purpose of this paper is to resolve the above problems. Our main contributions are as follows:1. We use simulations of lookahead search for two- and one-player games to explore the interplay between lookaheadpathology and three major factors affecting it: the heuristic evaluation function’s granularity (the number of possiblereturned values), the game tree’s branching factor (the number of successors of each node), and the tree’s local similarity(the similarity among the values of closely related nodes). The simulations show that the benefit provided by a deepersearch increases with granularity, decreases with branching factor, and increases with local similarity. Consequently,lookahead pathology is most likely to occur with a low granularity, a high branching factor, and a low local similarity.2. Experimental tests on substantially different games (two chess endgames, modified kalah,2 and the 8-puzzle) show thatthe benefit provided by a deeper search follows the trends predicted by the simulations.3. The experimental tests also show that even though all three games are mostly nonpathological, they all contain situ-ations in which lookahead pathology occurs. This suggests that similar situations may occur in many decision-makingenvironments; and our models may be useful in helping to predict what these situations are and how to deal withthem.The paper is organized as follows. Section 2 defines the minimax and minimin algorithms, lookahead pathology, andseveral other terms and quantities used throughout the paper. Section 3 describes the factors influencing pathologythat we use as parameters in our game-tree models. Section 4 describes several other influences on pathology, and ex-plains why we do not include them as explicit parameters in our models. Section 5 describes simulations showing howthe factors described in Section 3 affect lookahead pathology in three game-tree models (two for two-player gamesand one for one-player games). Section 6 explores the influence of these factors in three games: chess, kalah and the8-puzzle.2. Definitions2.1. Two-player gamesA finite, two-player, perfect-information, zero-sum game can be represented by a game tree in which the nodes are thestates and the edges are the moves. Each terminal node x in the tree is assigned a utility value u(x). This utility value maybe the game’s final score or some other way of expressing which outcomes are preferable. We follow the usual conventionof calling the two players Max and Min, where Max is trying to maximize the utility value and Min is trying to minimize it.From the Minimax Theorem [20] it follows that each node x has a unique value m(x), which is the utility value that willbe obtained if both players play optimally:⎧⎨⎩m(x) =u(x),max y∈suc(x) u( y),min y∈suc(x) u( y),if suc(x) = ∅,if it is Max’s move at x,if it is Min’s move at x,(1)where suc(x) is the set of x’s successors.3 Most game trees are so large that computing m(x) is infeasible, but an approxi-mation me(x, d) can be computed using the minimax algorithm [21]:me(x, d) =⎧⎪⎪⎨⎪⎪⎩u(x),e(x),max y∈suc(x) me( y, d − 1),min y∈suc(x) me( y, d − 1),if suc(x) = ∅,if d = 0,if it is Max’s move at x,if it is Min’s move at x,(2)where d, the lookahead depth or search depth, is a nonnegative integer saying how far to look ahead from x; and e(x) is aheuristic evaluation function that computes an approximation of m(x) from various features of the current game position. Inorder to clearly differentiate between m(x) and me(x, d), we will call the former a utility value and the latter a heuristic value.We let opt(x, d) be the set of successors of x that look optimal according to the minimax algorithm, i.e.,(cid:7)y ∈ suc(x): me( y, d − 1) = me(x, d)opt(x, d) =(cid:6).(3)2 We made some simple modifications (see Section 6.2) to ensure a constant branching factor, strict alternation of play, and a uniform-depth game tree.3 We use “children” and “successors” synonymously throughout.If a player moves to one of these nodes at random, then the probability of making an optimal move isD.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–1338P opt(x, d) =| opt(x, d) ∩ opt(x, ∞)|| opt(x, d)|.1325(4)The minimax algorithm produces optimal play (i.e., P opt(x, d) = 1) if e is completely accurate (i.e., e = u) or if d exceeds theheight of the game tree. Neither is usually the case in practice, but variants of the minimax algorithm such as alpha–beta[22] and its derivatives are still widely and successfully used.The minimax algorithm’s decision error at a node x of a game tree is the probability of moving to a successor y of x suchthat m( y) (cid:7)= m(x). If the player to move at x chooses at random from among the nodes in opt(x, d), then the decision error isP err(x, d) = 1 − P opt(x, d) = 1 −| opt(x, d) ∩ opt(x)|| opt(x, d)|.(5)The degree of pathology at a node x is the ratio between the decision errors when searching to two different lookaheaddepths:p(x, i, j) = P err(x, i)P err(x, j),(6)where x is a node in the game tree, i and j are the search depths, and i > j. Values of p(x, i, j) > 1 indicate lookaheadpathology; p(x, i, j) = 1 means that the quality of the decisions will be the same when searching to the depths i or j; andp(x, i, j) < 1 means that searching deeper is worthwhile. Note that this definition of the degree of pathology refers to aparticular node x and depths i and j.A game or a model is considered pathological if p(x, i, j), averaged over x, is greater than 1.4 When a game or a modelis pathological for some values of i and j, usually it will also be pathological for other values.2.2. One-player gamesIn one-player games, the algorithm is similar to the minimax algorithm, except that there is only one player. If theobjective is to minimize the cost of reaching a goal, then the player plays the role of Min at every node, and the minimumcost at each node is(cid:8)m(x) =u(x),min y∈suc(x) c(x, y) + u( y), otherwise,if suc(x) = ∅,(7)where c(x, y) is the cost of the edge from x to y.5 An approximation of m(x) can be computed using the minimin algo-rithm [23]:⎧⎨⎩me(x, d) =u(x),e(x),min y∈suc(x) c(x, y) + me( y, d − 1), otherwise,if suc(x) = ∅,if d = 0,(8)where e is an A*-style heuristic function.If the objective is to maximize a gain, then “min” is replaced with “max” in the above equations, and the algorithm isreferred to as maximax. Maximax is what we used in the model in Section 5.3.3. Influences on pathology that appear explicitly in our modelsResearchers have investigated many different factors that influence whether or not lookahead pathology occurs in games.This section describes three factors that we will use as explicit parameters in our game-tree models in Section 5. Theseinclude the branching factor of the game tree (Section 3.1), the granularity of the heuristic function (Section 3.2), and localsimilarity among nodes of the game tree (Section 3.3).Later, Section 4 describes several other factors that influence pathology, and explains why they are not explicit param-eters in our game-tree models. Among other things, several of them can be viewed as special cases of the three factorsmentioned above.4 Depending on the game being studied and the objectives of the study, sometimes the average is over all x, and sometimes it is over a proper subset.For example, in the studies of Pearl’s game in [5], p(x, i, j) > 1 for all x such that a depth-i search reaches neither the terminal nodes (all of which are atthe same depth) nor their parents.5 It is conventional to include c(x, y) in one-player games (Eqs. (7) and (8)) and omit it in two-player games (Eqs. (1) and (2)), but in principle it couldbe included in both.1326D.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–13383.1. Branching factorA game tree’s branching factor, b, is the number of successor nodes at each node in the tree. In game-tree models,b usually refers to a uniform branching factor, i.e., exactly b choices at each nonterminal node. In games where the numberof successors may vary, b is the mean number of successors.Nau [3] showed mathematically that for an infinitely large class of games, lookahead pathology was inevitable if b wassufficiently large. Intuitively, this happened because of the minimax algorithm’s tendency to eliminate low values at Max’smove and high values at Min’s move. Increasing the values of b and d made it more and more likely that all values but onewould be eliminated. This increased the probability that all successors of the current node would get the same heuristicvalue, regardless of which successors were the best moves.In Nau’s experiments with Pearl’s game, a simple game designed for the analysis of search algorithms [5], lookaheadpathology was indeed more likely with large branching factors [9]. In Beal’s [4] game-tree models, for large branchingfactors, the error at the root of the tree increased by approximately log b with every additional level of the search.3.2. Granularity of the heuristic functionAn evaluation function’s granularity, g, is the size of its range, i.e., the number of different values that it can return.Luštrek et al. [17] discovered that as the branching factor increases, the granularity (discussed in the next subsection)required to avoid lookahead pathology also increases. Intuitively, decreasing the granularity of an evaluation function makesit less able to distinguish among situations that are similar but not identical, and makes it more likely that a deeper searchwill return the same value for every child of the current node, making it less likely that the search will tell us which of thechildren are actually better.In some of the early research on lookahead pathology (e.g., the work of Beal [4]), only granularity 2 was considered.Bratko and Gams [6] and Pearl [8] compared granularity 2 to higher granularities and concluded that higher granularitiesdo not prevent lookahead pathology. Scheucher and Kaindl [12], however, considered multi-valued evaluation functions (i.e.,high granularities) essential to the prevention of lookahead pathology. Their work is described in more detail in Section 4.3.3.3. Local similaritySeveral researchers have attempted to explain lookahead pathology by means of local similarity, i.e., similarity among theutility values of nearby nodes in the game tree [5,7,12,17,9]. Local similarity is probably the most widely accepted inhibitorof lookahead pathology; it generally is present in real games but absent in pathological models such as Pearl’s game [5].Intuitively, local similarity inhibits pathology in the following manner: if node a is better than node b, then the higherthe amount of local similarity, the more likely it will be that most of a’s descendants are better than most of b’s descendants,making it more likely that a deeper search will return a higher value for a than for b.Researchers have introduced local similarity into game-tree models in a variety of ways. Beal [7] included in his gametrees a fraction of nodes with all the successors having the same utility. Several other authors used “incremental” approachesin which the current position’s utility changes gradually as moves are made in the game:• Nau [5,9] modified Pearl’s game by randomly giving each edge in the game tree a value of +1 or −1. Each terminalnode x was assigned utility u(x) = 1 if the sum of the values on the path from the root to x exceeded 1, and u(x) = 0otherwise.• Game-tree models by Luštrek et al. [17] used real-valued utilities, which were set in a similar way: instead of assigning+1 or −1 to game-tree edges, they assigned normally distributed real values; terminal utilities were then simply thesums of these values.• Scheucher and Kaindl [12] also used an incremental approach, which was inspired by chess programs.All of the above types of local similarity resulted in the elimination of lookahead pathology, although it should be notedthat in the work of Scheucher and Kaindl, other factors described in Sections 3.2 and 4.3 are also important. There is nostandard way to measure local similarity, and in this paper we will use two different measures:• In our models (see Section 5), local similarity is expressed as a parameter 0 (cid:2) s (cid:2) 1, where s = 0 corresponds tocomplete independence among sibling nodes’ utility values, and s = 1 corresponds to the maximum amount of similarityor dependence among sibling nodes that the model allows. If s = 0, this means that each node’s utility value is in noway affected by the values of its siblings, as in Pearl’s game where all leaf nodes have independently assigned randomvalues. If s = 1, this means that the value of each node is as similar to the values of its siblings as the model allows.• Although s is useful for expressing local similarity in a game-tree model, it is not a measure of local similarity in anf , which is the ratio between the standardarbitrary game. In games we therefore use the game tree’s clustering factor,deviation of the sibling nodes’ utilities and the standard deviation of the utilities throughout the tree [15]. If fis lowthen s is high, and vice versa, but the precise numeric correspondence between s values and f values will generally bedifferent in different game-tree models.D.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–13381327Fig. 1. A game G whose state space is a graph, and the corresponding game tree T . The number below each node is its utility value.4. Other factors that influence pathologyThis section describes several other factors that influence whether or not lookahead pathology occurs in games, and ex-plains why we do not include them as explicit parameters in our game-tree model. One factor, graph structure (Section 4.1),can be mapped directly into local similarity. A second factor, reliably evaluated nodes (Section 4.3), maps into local similar-ity but only in an approximate fashion (the mapping involves applying the evaluation function in cases where one alreadyknows the exact value). A third factor, improved evaluations deeper in the game tree (Section 4.3), is related (though thereis not a direct mapping) to evaluation-function granularity. The remaining factors (Section 4.4) are specific to one-playergames.4.1. Graph structurePathology has been shown to vanish if there are sufficiently many different paths to the same position [10]. As we willnow explain, this can be viewed as a special case of local similarity.If G is a game whose state space is an acyclic graph, then we can map G into a game tree T that is an “unfolded”in T that are(2)(1)8 ,8 , nversion of G. If ni is a node of G and there are p paths from G’s root to ni , then there are nodes n“duplicates” of ni , and all of these duplicates have the same utility value as ni . For example, in Fig. 1, the nodes nand nare duplicates of n8, and u(n8) = u(n, . . . , n(p)i(1)i(1)8 ) = u(n(2)8 ) = u(n(3)8 ) = 2.(3)8Let ni and n j be sibling nodes in G, and suppose they have duplicates nhave in common, the more duplication there will be among the children of nwill be.(k)i(k)iin T . The more children ni and n j(l)and nj(l), hence the higher T ’s local similarityjand nFor example, consider Fig. 1 again. No two terminal nodes of G have the same utility value; but there are multiple pathsto nearly every terminal node, hence T contains many duplicates of G’s terminal nodes. Consequently, in 3 of the 7 pairs ofsibling nodes in T , the siblings have the same the utility value.1328D.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–1338Fig. 2. A two-player game tree with two types of reliably evaluated nodes: early terminations and roots of homogeneous subtrees.4.2. Reliably evaluated nodesIf sufficiently many nodes in a game tree are evaluated reliably (i.e., without error or with a very small error) comparedto other nodes on their level, minimaxing reduces the heuristic error, which means that a larger search depth is beneficial.One place where reliable evaluations are likely to occur is in subtrees with homogeneous utilities, in which most of theterminal nodes are either all lost or all won [6]. It is easy to see that this is a special case of local similarity, by noticingthat for nearly every node in the subtree, most or all of the nearby nodes will have the same utility (e.g., see the tworightmost subtrees in Fig. 2).Another place where reliable evaluations occur is at terminal nodes encountered by lookahead search, such as earlycheckmates in chess [8,24]. Early terminal nodes may also be considered as a case of local similarity, since they can beinterpreted as the roots of subtrees in which all the nodes have the same value. This also is illustrated in Fig. 2.4.3. Improved evaluations deeper in the game treeScheucher and Kaindl [12] proposed a game-tree model in which heuristic values have a local similarity inspired bychess: after each player’s move, only a limited change of value in favor of the moving player is possible, reflecting thechange in material caused by that move. The heuristic value of the root of the tree is set to 0. As the search depth increases,the heuristic values tend to get ever further apart.Scheucher and Kaindl observed that a lost position is less likely to be mistaken for a won one or vice versa in positionswith extreme (strongly positive or negative) heuristic values, since those positions are more clearly decided in favor ofone of the players. Therefore they introduced a function that determined the error in each game-tree node such that theprobability of mistaking a loss for a win or vice versa was inversely correlated with the absolute heuristic value of thatnode. Since heuristic values lower in the tree tend to be further apart, the frequency of extreme values increases with thesearch depth and the probability of a misevaluation decreases. This depth-related decrease—probably combined with theeffect of local similarity itself—was shown to be sufficient to eliminate lookahead pathology.It was later shown that if the heuristic error is modeled appropriately, lookahead pathology disappears for a similarreason as in the work of Scheucher and Kaindl even without local similarity [14]. If real-valued utilities drawn randomlyfrom a uniform distribution are assigned to terminal nodes of the game tree, they are also further apart lower in the tree.The mechanism that achieves this is minimaxing itself: the player who is maximizing the utility eliminates low values, andthe opponent, who is minimizing the utility, eliminates high values. Moving from terminal nodes towards the root, thisresults in an ever narrower range of utilities. The heuristic values are obtained by adding Gaussian noise to the utilities. Ifthe heuristic values and utilities are mapped to losses and wins using a threshold, it is more likely that both the heuristicvalue of a node and its utility are on the same side of the threshold lower in the game tree. This happens because utilitieslower in the tree are further apart and thus also further from the threshold, as is illustrated in Fig. 3. Since a loss is mistakenfor a win or vice versa when a heuristic value is on the opposite side of the threshold from the corresponding utility, theprobability of such a mistake decreases with the search depth. This decrease is sufficient to eliminate lookahead pathology.It is clear that sufficiently improved evaluations deeper in the game tree can reduce or eliminate lookahead pathology.The papers presented in this subsection are not trying to show that, but rather how such improved evaluations can beachieved realistically through increased granularity. For this reason we also do not address improved evaluations in thispaper, but we do address granularity.4.4. Influences on pathology in one-player gamesLookahead pathology in one-player games has not been studied in as much detail as that in two-player games, probablybecause it was discovered more than 20 years later [13]. The factors described in the previous subsections have not beenD.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–13381329Fig. 3. Utilities (circles) and heuristic values (dashed curves showing probability densities) are more likely on the same side of the threshold lower in thegame tree.thoroughly investigated in one-player games (which this paper attempts to remedy), but some other factors have beeninvestigated.Search algorithms for one-player games typically use an A*-style heuristic function h(x) that attempts to estimate theoptimal cost of reaching a goal from the state x. The first factor that influences lookahead pathology in one-player games ish(x) is optimistic or pessimistic. Pessimistic functions were found to be less prone to lookahead pathology in synthetic gametrees [16], in the 8-puzzle [25,18] and in path-finding [19]. Monotonically nondecreasing functions (the heuristic value of anode is not smaller than the heuristic value of its parent) were also found to be less prone to lookahead pathology [16].Two factors were shown to influence lookahead pathology in synthetic trees [16]: how the utilities of the children ofthe root node’s optimal successor compared to the utilities of the children of the root node’s other successors, and how theutilities of the root node’s successors compared to each other. However, the influence of these two factors seems to be tiedto the heuristic function in [16], which was an artificial one that is only suitable for one-player games.Finally, there are some results regarding lookahead pathology in path-finding using the LRTS algorithm [19]. This al-gorithm learns updates to the heuristic values during the search. A shallower search benefits more from learning than adeeper search. This makes decisions based on a shallower search better than mere depth would suggest and thus closer to adeeper search. Learning was therefore found to increase the degree of pathology and if turned off, the degree of pathologydecreased (although the quality of decisions also decreased). The second reason was that after each lookahead search, theplayer makes a number of moves equal to the search depth. Thus if a deeper search sends the player in a wrong direction,the mistake is larger than if a shallower search does so, which again increases the degree of pathology. These results appearto be specific to the LRTS algorithm, which is only one of the algorithms used for the real-time search in one-player games.This paper is concerned with factors that influence lookahead pathology in both one- and two-player games, attemptingto present a unified picture of pathology in both types of games. The factors discussed in this subsection, while certainlyhaving an influence on lookahead pathology in one-player games, are either not present in two-player games or are of littleinterest in that domain. Therefore we do not address them in this paper.5. Game-tree modelsThis section describes simulations with synthetic game trees showing how the degree of pathology varies as a functionof three factors: granularity g, branching factor b, and local similarity s [26]. Three probabilistic game-tree models aredescribed in the following three subsections. These models were used to build 10,000 trees for each combination of thesettings of the three factors of interest: g = 2, 3, . . . , 60 for the two-player models and g = 2, 3, . . . , 300 for the one-playermodel; b = 2, 3, . . . , 10; and s = 0.0, 0.1, . . . , 1.0. The values of g went as high as was needed to obtain nonpathologicaltrees for most of the settings of the remaining two factors. We made a simplifying assumption that the branching factor isuniform within each tree. It was limited to at most 10 because the size of the tree is exponential in b. Building trees withlarge branching factors is thus computationally expensive and the few that we did build exhibited the behavior one mightexpect based on the smaller trees.Each game tree was searched once to depth 1 and once to depth 5 to measure the degree of pathology p(root, 5, 1).Depth 5 (and not more) was chosen to ensure that enough trees could be generated in a reasonable time (i.e., a few weeks),to yield statistically reliable analyses. Depth 1 was chosen as the minimal depth needed for an informed move selection.Some experiments were also performed with other pairs of depths, such as (6, 2) and (7, 1), giving similar results. Minimaxresults with odd and even depths, such as (6, 1), were somewhat different due to one player having one move more.1330D.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–1338Fig. 4. Generation of utilities and heuristic values.Lookahead pathology was measured in the root of the game tree so that we did not need to build larger trees than requiredfor searching to the chosen depth. All three models build subtrees in the same manner as the whole tree, so choosing anon-root node as the starting point would not give qualitatively different results.The heuristic evaluation function was the utility of a node corrupted by Gaussian noise with σ = 0.1. We assumed thatno early terminations (such as checkmates), which could be evaluated perfectly, are encountered within the searched space.Furthermore, we made the classic assumption that the error of the evaluation function is the same at all search depths. Wealso did not attempt to model any specific phenomena that may appear in a real game tree, such as a position appearingunattractive in the short run, but eventually leading to victory. All these phenomena certainly occur in real games, but suchdetailed modeling is probably game-dependent and is beyond the scope of this paper. Despite these limitations, we believethat the chosen evaluation function models a typical game situation reasonably well. The magnitude of the static heuristicerror was chosen so that the error was not large compared to the utilities. At the same time, we did not want it to be sosmall as to produce few wrong moves, since in that case too many game trees would have to be generated for statisticallyreliable analyses.All three game-tree models model situations that are not strongly in favor of one of the players. Such situations areof greatest interest and previous work on lookahead pathology in two-player games was often focused on them [4,6,7,12].We use two mechanisms to ensure that the probabilities of a victory for both players are comparable. Each mechanism isexplained in the section describing the model it belongs to.5.1. Two-player top-down modelThe first step in generating a game tree according to this model is assigning the utilities to the terminal nodes. Thereare three cases, depending on what value we want for the tree’s local similarity s:• If s = 0 (the “independent” case), the terminal nodes’ utilities are independently chosen from a uniform distributionover the interval [0, 1].• If s = 1 (the “maximally similar” case), the root of the game tree is first assigned a so-called auxiliary value, which isthen propagated to the terminal nodes. The root node’s auxiliary value is 0. For each non-root node, the auxiliary valueis the sum of its parent’s auxiliary value and a random value drawn from a Gaussian distribution (if the random valueexceeds 3σ of the distribution, a new value is drawn). The utilities of the terminal nodes are their auxiliary valuesnormalized to the interval [0, 1].• If 0 < s < 1, the utility of each terminal node is taken with probability s from a game tree with s = 0, and withprobability 1 − s from a tree with s = 1.The utilities of the internal nodes are computed from the terminal utilities using the minimax algorithm. When searchingto depth d, heuristic utility estimates are assigned to the nodes at level d (the levels are numbered downwards, startingwith 0 for the root). They are generated by corrupting the utilities at level d with Gaussian noise representing the error ofthe heuristic evaluation function. The heuristic values of the nodes above depth d are computed from the heuristic valuesat depth d using the minimax algorithm. This is illustrated in Fig. 4.The number of possible utility values or heuristic values in a game tree is called granularity. The initial values duringthe generation of the tree are real numbers, but we afterwards convert them to g discrete values. The simplest way to dothis is by partitioning the interval [0, 1] into g buckets of equal width. However, in trees with local similarity s = 0, atsmall granularities there is a tendency for the values towards the root of the tree to converge to a single bucket containingthe value cb (called wb in [9] and also discussed in [4,6] and other studies on lookahead pathology in two-player games).This value is the solution of the equation cb = (1 − cb)b; c2 ≈ 0.38 and then cb slowly decreases with increasing b. Theconvergence to cb happens because the player who is maximizing the utility eliminates all the low values, and the opponent,who is minimizing the utility, eliminates all the high values. At the root of such a tree no meaningful choice of a move canbe made. We avoid this phenomenon by shifting the boundary between the two buckets most likely to appear at the topD.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–13381331Fig. 5. Shifting of buckets that ensures that not only a single value appears at the root of a two-player game tree.of the tree to cb, as shown in Fig. 5. The other bucket boundaries are also shifted so that all the buckets except for theoutermost two retain their original widths. By doing so, no single bucket contains the value cb and thus at least the twobuckets on each side of cb have a reasonable chance of being represented at the root. Consequently, the player to move atthe root may decide between at least two different values. We also generalize cb to game trees with the local similaritylarger than 0 by defining it as the value for which the ratio between the probability of a utility being smaller than cb at onelevel and the probability of a utility being larger than cb at the next level is closest to 1. This also achieves different utilityvalues for the moves available at the root of the game tree.5.2. Two-player bottom-up modelThis model differs from the two-player top-down model in two aspects: the generation of the utilities of terminalnodes, and the mixing of independent and maximally similar game trees. The generation of nonterminal utilities and allthe heuristic values and the granularization are the same as in the two-player top-down model.There are again three cases for the generation of terminal utilities:• Is s = 0, the terminal utilities are chosen in the same way as in the top-down model: they are independently chosenfrom a uniform distribution over the interval [0, 1].• If s = 1, bh uniformly distributed random numbers in the interval [0, 1] are generated. They are sorted and assigned tothe terminal nodes starting with the lowest number at the leftmost node and finishing with the highest number at therightmost node.• If 0 < s < 1, in principle the bottom-up model could use the same procedure as in the top-down model, i.e., randomlymixing terminal nodes from a game tree with s = 0 and a tree with s = 1. We tried this method and the relationsamong lookahead pathology, granularity, local similarity and branching factor were qualitatively similar to the othermodels presented in the paper. However, the maximally similar tree often seemed to overwhelm the independent oneat relatively low values of s, because inserting even a small number of utilities into a tree—if those are the ones thatare actually propagated to the root—may completely change the situation at the root. Because of that we modified themixing procedure by increasing the probability of taking a low or high utility from the maximally similar tree. Thissoftened the impact of the maximally similar tree because most of the low and high utilities are not propagated to theroot. As mentioned before, this happens because the player maximizing the utility eliminates most low values, and theopponent, who is minimizing the utility, eliminates most high values.5.3. One-player modelWe designed the model for one-player games similarly to the bottom-up model for two-player games, but it differsfrom the two-player bottom-up model in two aspects: the procedure for backing up (i) the utilities and heuristic valuesand (ii) the granularization. The generation of the utilities of terminal nodes and the mixing of independent and maximallysimilar game trees are the same as in the two-player bottom-up model.The utilities of the nonterminal nodes are computed from the utilities of the terminal nodes using the maximax algo-rithm. The same backing-up procedure is used for computing the heuristic values above depth d from the depth-d heuristicvalues.The problem of the convergence of the utilities toward the root of the game tree to a single value is even more pro-nounced in one-player games than in two-player games. The phenomenon occurs as soon as every decision at the root ofthe tree leads to at least one terminal node with the maximal utility, which is quite likely if the granularity is not large.We solve this by limiting the probability of the maximal utility being reached by each decision at the root to at most 50%,which ensures some variation in the values from among which the player is choosing. Let x be a direct successor of the root,h be x’s height (i.e., the path length from x to a terminal node), P max(x) be the probability of x having the maximal utility,and P max(t) be the probability of a terminal node having the maximal utility. Since x does not have the maximal utilityonly if none of the terminal nodes of the subtree rooted in x have the maximal utility, the following equations describe therelation between P max(x) and P max(t):1 − P max(x) =(cid:9)(cid:10)bh1 − P max(t),(cid:11)P max(t) = 1 − bh1 − P max(x).1332D.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–1338Fig. 6. Shifting of buckets that ensures that the probability of the maximal utility being reached by each decision at the root of a one-player game tree isat most 50%.Fig. 7. Amount of granularity needed to avoid pathology in the two-player top-down model. The space below the surface is pathological, the space above itis nonpathological.Fig. 8. Amount of granularity needed to avoid pathology in the two-player bottom-up model. The space below the surface is pathological, the space aboveit is nonpathological.In order to limit P max(x) to 50%, we allow P max(t) to be at most 1 − bh√0.5. This is accomplished by limiting the size ofthe bucket containing the largest utilities. If the bucket is too large, its lower boundary is increased as shown in Fig. 6. Theother bucket boundaries are again shifted so that all the buckets except for the outermost two retain their original widths.5.4. Results from the modelsWe used all three models to compute the granularity needed to avoid lookahead pathology, as a function of the branchingfactor b and the local similarity s. Figs. 7, 8, and 9 show the surfaces corresponding to p(root, 5, 1) = 1 for all three models.In each case the results are qualitatively similar: the granularity needed to avoid lookahead pathology decreases with localsimilarity and increases with the branching factor. We also tried varying the granularity, the branching factor, the lookaheaddepth, the way that local similarity was introduced, and other parameters, such as the magnitude and distribution of theheuristic error, but the results were still qualitatively similar to those in the three figures [14,17].D.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–13381333Fig. 9. Amount of granularity needed to avoid pathology in the one-player top-down model. The space below the surface is pathological, the space above itis nonpathological.Fig. 10. The degree of pathology p(root, 5, 1) measured using the two-player top-down model, as a function of branching factor b, granularity g, and localsimilarity s. The color of each point in the graph shows the value of p(root, 5, 1). The regions below the curved black lines are pathological, and the regionsabove those lines are nonpathological.One can study not only whether lookahead pathology occurs in a given situation, but more generally how beneficialor harmful it is to search deeper. Fig. 10 shows the degree of pathology (the smaller it is, the more beneficial a deepersearch is) with respect to the granularity, local similarity, and branching factor. We can observe the same relations amongthe factors affecting lookahead pathology as in Figs. 7, 8, and 9. In addition, Fig. 10 reveals that the branching factor hastwo different effects on the degree of pathology. One effect is that as b increases, the size of the pathological region alsoincreases. This is consistent with the results of related studies described in Section 3.1. The other effect is that large valuesof b amplify the difference in the degree of pathology between the pathological and nonpathological regions. For example,consider any two points x and y that are close to the boundary between the pathological and nonpathological regions,and on opposite sides of the boundary. As b increases, the difference between x’s degree of pathology and y’s degree ofpathology also increases.The findings from the experiments with these models are consistent with the early pathological models of two-playergames [3–9]: lookahead pathology occurs when s = 0 and g = 2. As shown in the following section, the findings are alsoconsistent with real games and game-playing programs.6. GamesThe simulations described in the previous section predict how the degree of pathology depends on the granularity, localsimilarity, and branching factor. This section presents experimental tests of those predictions in three real-world games:chess, kalah, and the 8-puzzle.1334D.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–1338Fig. 11. Degree of pathology as a function of granularity in KBBK chess endgames (average b = 13.52 and f = 0.58) and KQKR chess endgames (averageb = 16.93 and f = 0.37).6.1. ChessThe relation between lookahead pathology and granularity was studied in the KBBK (king + bishop + bishop vs. king)and KQKR (king + queen vs. king + rook) chess endgames [15]. Following the example of [15], the heuristic estimate of amove’s utility was defined as the number of moves on the shortest path to the end of the game from the resulting position,corrupted by Gaussian noise with σ = 2. To reflect the fact that the state space is a graph rather than a tree, the evaluationfunction cached each node’s corrupted value, so that whenever a node is reached along more than one path in the searchspace, it would return the same corrupted value for that node every time.It may be argued that distance to win is a rather artificial evaluation function because in chess the task is just to win,and not necessarily to win in the quickest way. As Sadikov et al. [15] argued, an appropriate interpretation of a heuristicevaluation function is that such a function roughly indicates, for a given position, the chances of a (fallible) player winningthe position against another (fallible) player. Distance to win can be interpreted as such an indicator. Although virtuallyall the positions in, say, KBBK are won for the stronger side, a fallible player may have difficulties in actually mating in50 moves (the number of moves to mate allowed by the rules of chess). Such an imperfect player will have much betterchances to win in a position where mate is possible in two moves, than in a position that requires 20 moves. Naturalheuristic functions for playing a specific endgame also typically exhibit preference for shorter wins and should thus alsohave some correlation with our distance to mate. For controlled simulation experiments, distance to win has the advantagethat it is a perfect evaluation which can be corrupted in a controlled way by our usual introduction of Gaussian noise.The granularity was varied by partitioning the interval in which the heuristic estimates lie into g buckets of equal width.For each of the two endgames, Fig. 11 shows the degree of pathology p(x, 5, 1) as a function of granularity, averaged overevery position x in the endgame database that is more than 5 moves away from a checkmate. Since different positionshad differing branching factors and clustering factors, the figure’s caption gives the average values of each. For g (cid:3) 10, anincreasing granularity increases the benefit of a deeper search, which is consistent with the predictions of the simulationsdescribed in the previous section. Some pathology can be observed at granularities up to 10, but this depends on thedepths of search i and j used to measure the degree of pathology p(root, i, j). The boundary between the pathological andnonpathological parts of the space in Fig. 10 is also around g = 10.Fig. 10 also illustrates that in cases where b and f have opposite effects, it can be hard to say much about either ofthem individually. The KBBK’s average branching factor (b = 13.52) is lower than the KQKR’s (b = 16.93), which might leadone to expect KBBK to be less pathological than KQKR. But the KBBK’s average clustering factor ( f = 0.58) is higher thanthe KQKR’s ( f = 0.37), which might lead one to expect the opposite. In Fig. 11, sometimes KBBK is less pathological thanKQKR, and sometimes the reverse.Apparently it is quite rare for an entire game to be pathological, but lookahead pathology in some game positions is morecommon. We analyzed 1092 chess positions from world championship matches [27]. Several chess programs searching todifferent depths were compared to Rybka (the strongest program available for our experiments) at depth 12. In 5.5% to 9.2%of the positions (depending on the program), we observed that the other programs chose Rybka’s move at their smallestsearch depths but chose other moves at depth 5. Assuming that these other moves were worse than Rybka’s (which seemslikely since Rybka is a better player and is searching considerably deeper), this suggests that lookahead pathology occurredfor these programs in 5.5% to 9.2% of positions. It should be noted, though, that Rybka’s move is not guaranteed to becorrect, and that occasionally several moves are all roughly comparable and can thus be considered equally best; so theseresults are not entirely conclusive.Having pathology in some positions is not nearly as alarming as it would be to have pathology most positions, or tohave larger average errors at deeper search depths than at shallower search depths. However, pathological positions are stillD.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–13381335Fig. 12. The degree of pathology in modified kalah as a function of granularity, for several different branching factors.of interest—firstly, because they are undesirable if unrecognized, and secondly, because we could select the best move withless effort than required by a default-depth search if we were able to recognize them.66.2. KalahKalah is an ancient African game [29] played on a board with a number of pits, each containing a number of seeds, inwhich the objective is to acquire more seeds than the opponent, either by moving them to a special pit (called a “kalah”)or by capturing them from the opponent’s pits. For our experiments, we made the following modifications to produce a“regularized” version of the game:• The game is normally played until no seeds are left on the board, but computability requires limiting the game to asmall number of moves (in our case, 8 moves).• To ensure a uniform branching factor, we allowed players to “move” from an empty pit; such a move has no effect onthe board. We obtained different branching factors by varying the number of pits.• We eliminated the “move-again” rule, where a player can move a second time when the last seed placed lands in theirown “kalah”.In our experiments, we generated random initial boards by distributing seeds across the available pits, and averaged ourresults over these initial boards. The utility of a terminal node was the difference in the numbers of seeds captured byeach player, and the utilities of the internal nodes were computed using the minimax algorithm from the terminal utilities.The heuristic evaluation function was the node’s utility corrupted by Gaussian noise with σ = 0.9. The same caching andgranularity techniques were used as in the chess experiments.As shown in Figs. 12 and 13, our experimental results with modified kalah are qualitatively consistent with the pre-dictions produced by the simulations in the previous section. Fig. 12 shows that lookahead pathology (i.e., p(x, 5, 1) > 1)occurs at most granularities when the branching factor b = 6, at small granularities when b = 5, and at granularity 3 (thesmallest we tried) when b = 4. In general, when the granularity g is small, increases in g cause sharp decreases in p(x, 5, 1),but when g is large, increases in g have little effect. Fig. 13 shows that p(x, 5, 1) decreases with increasing local similarity,which is again consistent with the simulations. This figure also shows that lookahead pathology is stronger when b is large,as expected.6 Some work has been done on heuristic techniques for recognizing such positions, but the work is still at an early stage [28].1336D.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–1338Fig. 13. The degree of pathology in modified kalah as a function of clustering factor f , for several different branching factors. Higher f means less localsimilarity.Fig. 14. Degree of pathology as a function of granularity in the 8-puzzle, using two different evaluation functions. On average, b = 2.67 and f = 0.73.6.3. The 8-puzzleA similar relation between lookahead pathology and granularity to that in chess and modified kalah was observed in the8-puzzle [25]. This is a one-player game that is played on a grid of numbered tiles with one tile missing. The goal of thepuzzle is to arrange the tiles sequentially by sliding them into the empty space, in turn revealing another empty space inthe position of the tile moved.For our experiments we used two heuristic evaluation functions: the number of moves to the solution, corrupted byGaussian noise as described earlier, and the Manhattan distance of the tiles from their final positions (commonly used insearch analyses).Fig. 14 shows the degree of pathology p(x, 5, 1) with respect to the granularity g. Both functions exhibit an increasedbenefit of a deeper search with increasing granularity, which agrees with the simulations in the previous section. AccordingD.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–13381337to Fig. 14, on average the 8-puzzle is pathological only at small granularities and only if the Gaussian-noise evaluationfunction is used.We also investigated how many positions in the 8-puzzle are pathological. With the Manhattan-distance heuristic eval-uation function, in 31.0% of positions a search to depth 5 gives better decisions than a search to depth 1, in 19.7% depth 1is preferable, and in 49.3% it does not matter. Other pairs of depths give different percentages, but the observation that theadvantage of a deeper search is not overwhelming is true quite generally in the 8-puzzle.7. ConclusionsTwo models of game trees for two-player games and one model for one-player games were constructed. Simulations withthem showed similar behavior for both minimax and maximax: lookahead pathology was more likely when the granularitywas low, the branching factor was high, and the local similarity was low. Furthermore, large branching factors amplified thedifference in the degree of pathology between pathological and nonpathological regions.In several substantially different games—two chess endgames, modified kalah, and the 8-puzzle—our experiments con-firmed that increasing the granularity generally increases the benefit of a deeper search. This effect of granularity wasobserved for many different combinations of the branching factor b and clustering factor f .In modified kalah, we performed additional experiments that confirmed two more of the simulation results: the degreeof pathology (measured as p(x, 5, 1)) decreased when the local similarity was high, and increased when the branching factorwas large.In modified kalah when the branching factor was sufficiently high, lookahead pathology occurred (i.e., p(x, 5, 1) > 1 onaverage) at almost every granularity. To the best of our knowledge, this is the first known game (other purely artificialgames such as P-games) where lookahead pathology occurs throughout most of the game. Apparently such games are quiterare.On the other hand, our experiments suggest that local pathologies, i.e., game positions where pathology occurs eventhough the game may be nonpathological on average, may be much more common. For example, in the chess championshipmatches, 6.9% to 8.5% of the positions were very likely pathological, and in the 8-puzzle, pathology occurred in 19.7% ofthe positions (i.e., p(x, 5, 1) > 1 at those positions). Thus in many games it might be useful to look for ways to detect andovercome local pathologies [28].Generalizing beyond board games, we suspect that in many decision-making problems there may be particular kindsof situations where lookahead pathology is likely to occur. If so, then our experiments may have a practical utility insuggesting what those situations are, so that decision-makers can recognize such situations and take appropriate measuresto deal with them. For example, one should be cautious about lookahead pathology when the branching factor is high andthe local similarity is low, and in such situations one might consider modifying the heuristic evaluation function to dofiner-grained evaluations that capture more properties of the domain.AcknowledgementsThis work has been supported in part by AFOSR grant FA95500610405, NAVAIR contract N6133906C0149, NSF grantIIS0412812, the Slovenian Ministry of Higher Education, Science and Technology and the Slovenian Research Agency underthe Research Programme P2-0209 Artificial Intelligence and Intelligent Systems. The opinions in this paper are those ofthe authors and do not necessarily reflect the opinions of the funders. In addition, we would like to acknowledge valuableintellectual contributions from Matej Guid, Boštjan Kaluža, Rok Piltaver, Aleksander Sadikov, and Aleš Tavˇcar.References[1] M. Campbell, A.J. Hoane Jr., F.-H. Hsu, Deep blue, Artificial Intelligence 134 (1–2) (2002) 57–83.[2] J. Schaeffer, N. Burch, Y. Björnsson, A. Kishimoto, M. Müller, R. Lake, P. Lu, S. Sutphen, Checkers is solved, Science 317 (5844) (2007) 1518–1522.[3] D.S. Nau, Quality of decision versus depth of search on game trees, PhD thesis, 1979.[4] D.F. Beal, An analysis of minimax, in: M. Clarke (Ed.), Advances in Computer Chess, vol. 2, Edinburgh University Press, 1980, pp. 103–109.[5] D.S. Nau, An investigation of the causes of pathology in games, Artificial Intelligence 19 (3) (1982) 257–278.[6] I. Bratko, M. Gams, Error analysis of the minimax principle, in: M. Clarke (Ed.), Advances in Computer Chess, vol. 3, Pergamon Press, 1982, pp. 1–15.[7] D.F. Beal, Benefits of minimax search, in: M. Clarke (Ed.), Advances in Computer Chess, vol. 3, Pergamon Press, 1982, pp. 17–24.[8] J. Pearl, On the nature of pathology in game searching, Artificial Intelligence 20 (4) (1983) 427–453.[9] D.S. Nau, Pathology on game trees revisited, and an alternative to minimaxing, Artificial Intelligence 21 (1–2) (1983) 257–278.[10] D.S. Nau, On game graph structure and its influence on pathology, International Journal of Computer and Information Sciences 12 (6) (1983) 367–383.[11] B. Abramson, A cure for pathological behavior in games that use minimax, in: Proc. First Workshop on Uncertainty and Probability in Artificial Intelli-gence, 1985.[12] A. Scheucher, H. Kaindl, Benefits of using multivalued functions for minimaxing, Artificial Intelligence 99 (2) (1998) 187–208.[13] V. Bulitko, L. Li, R. Greiner, I. Levner, Lookahead pathologies for single agent search, in: Proc. IJCAI, posters section, 2003, pp. 1531–1533.[14] M. Luštrek, I. Bratko, M. Gams, Why minimax works: An alternative explanation, in: Proc. IJCAI, 2005, pp. 212–217.[15] A. Sadikov, I. Bratko, I. Kononenko, Bias and pathology in minimax search, Theoretical Computer Science 349 (2) (2005) 261–281.[16] M. Luštrek, Pathology in single-agent search, in: Proc. Information Society, 2005, pp. 345–348.[17] M. Luštrek, M. Gams, I. Bratko, Is real-valued minimax pathological, Artificial Intelligence 170 (6–7) (2006) 620–642.[18] A. Sadikov, I. Bratko, Pessimistic heuristics beat optimistic ones in real time search, in: Proc. of the 17th European Conference on Artificial Intelligence,2006, pp. 148–152.1338D.S. Nau et al. / Artificial Intelligence 174 (2010) 1323–1338[19] M. Luštrek, V. Bulitko, Thinking too much: Pathology in pathfinding, in: Proc. of the 18th European Conference on Artificial Intelligence, 2008, pp. 899–900.[20] J. von Neumann, O. Morgenstern, Theory of Games and Economic Behavior, Princeton University Press, 1944.[21] C. Shannon, Programming a computer for playing chess, Philosophical Magazine 41 (1950) 256–275.[22] D.E. Knuth, R.W. Moore, An analysis of alpha–beta pruning, Artificial Intelligence 6 (4) (1975) 293–326.[23] R. Korf, Real-time heuristic search, Artificial Intelligence 42 (2–3) (1990) 189–211.[24] B. Abramson, Control strategies for two-player games, ACM Computing Surveys 21 (2) (1989) 137–161.[25] R. Piltaver, Search pathology in eight-puzzle, 2008 (in Slovene).[26] B. Kaluža, Analysis of pathological minimax models and Pearl’s game, 2008 (in Slovene).[27] M. Guid, I. Bratko, Computer analysis of world chess champions, ICGA Journal 29 (2) (2006) 64–65.[28] B. Wilson, A. Parker, D.S. Nau, Error minimizing minimax: Avoiding search pathology in game trees, in: International Symposium on CombinatorialSearch (SoCS-09), 2009.[29] H. Murray, A History of Board-Games Other than Chess, Oxford University Press, 2002.