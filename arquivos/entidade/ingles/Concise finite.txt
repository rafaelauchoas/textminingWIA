Artificial Intelligence 173 (2009) 503–535Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConcise finite-domain representations for PDDL planning tasks ✩Malte HelmertInstitut für Informatik, Albert-Ludwigs-Universität Freiburg, Georges-Köhler-Allee 052, 79110 Freiburg, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 16 November 2007Received in revised form 22 October 2008Accepted 29 October 2008Available online 25 November 2008Keywords:Automated planningProblem reformulationPDDL+SASWe introduce an efficient method for translating planning tasks specified in the standardPDDL formalism into a concise grounded representation that uses finite-domain statevariables instead of the straight-forward propositional encoding.Translation is performed in four stages. Firstly, we transform the input task into anequivalent normalform expressed in a restricted fragment of PDDL. Secondly, wesynthesize invariants of the planning task that identify groups of mutually exclusivepropositions which can be represented by a single finite-domain variable. Thirdly, weperform an efficient relaxed reachability analysis using logic programming techniques toobtain a grounded representation of the input. Finally, we combine the results of the thirdand fourth stage to generate the final grounded finite-domain representation.The presented approach has originally been implemented as part of the Fast Downwardplanning system for the 4th International Planning Competition (IPC4). Since then, it hasbeen used in a number of other contexts with considerable success, and the use of concisefinite-domain representations has become a common feature of state-of-the-art planners.© 2008 Elsevier B.V. All rights reserved.1. IntroductionConsider the transportation planning task illustrated in Fig. 1. There are three cars, a train, and two parcels, located intwo cities comprising several locations each. The cars may move along a network of roads within their respective city oforigin, while the train moves along a single railway link that connects the two cities. Parcels may be loaded into any vehiclethat is present at the same location, and parcels carried by a vehicle may be unloaded to the current location of that vehicleat any time. The objective is to move each parcel to a designated goal location.1.1. PDDL representationsIn order to find a plan for this example task using a general-purpose planning system, we must first represent it in away that such a system can reason about. Since its inception in 1998 [38], the Planning Domain Definition Language (PDDL)has become the de-facto standard language for representing classical planning tasks. The original PDDL formalism, as usedin the first two International Planning Competitions, was purely logic-based and can be considered a syntactic variant ofthe earlier ADL language [39] (excluding the support for functional fluents, which are present in ADL). Since then, thelanguage has been extended to more easily express additional aspects of real-world planning tasks, such as numbers anddurations [21], state variables whose values are derived from the values of other state variables [18], and most recently planconstraints and preferences [24].✩This work was partly supported by the German Research Council (DFG) as part of the Transregional Collaborative Research Center “AutomaticVerification and Analysis of Complex Systems” (SFB/TR 14 AVACS). See www.avacs.org for more information.E-mail address: helmert@informatik.uni-freiburg.de.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.10.013504M. Helmert / Artificial Intelligence 173 (2009) 503–535Fig. 1. A transportation planning task. Deliver parcel p1 from C to G and parcel p2 from F to E, using the cars c1, c2, c3 and train t. The cars may only useroads (thin edges), the train may only use the railway (thick edge).In PDDL, planning tasks are described in terms of objects of the world (cars, locations, parcels), predicates that describestatic or dynamic relations that hold between these objects (whether or not two given locations are connected by a road,whether or not a given parcel is currently inside a given vehicle), operators that manipulate these relations (moving a carfrom one location to another, unloading a parcel), an initial state that describes the situation before plan execution, and agoal specification describing the objectives that solution plans must achieve.While PDDL itself is a (restricted) first-order formalism, all state-of-the-art planning systems compile the input specifi-cation into a propositional representation at an early stage by grounding predicates, operators and goal specifications. Manyplanners go even further and transform the grounded task into a particularly simple syntactic form called propositionalSTRIPS, where states of the world can be represented as sets of (satisfied) atomic propositions and operators are representedin terms of which propositions must be true for the operator to be applicable (preconditions), which propositions the op-erator makes true (add effects), and which propositions it makes false (delete effects). The example task can be naturallymodelled in propositional STRIPS; (part of) such a representation is shown in Fig. 2.PDDL- or STRIPS-based representations of planning tasks have a number of desirable features. Due to the close rela-tionship to first-order logic (for ungrounded PDDL) and propositional logic (for grounded PDDL), the semantics are easy tounderstand for researchers and practitioners with a background in formal logics. Moreover, representing all properties of aworld state in terms of truth values has the appeal of simplicity. There is a certain mathematical elegance to the formalism,and it clearly achieves the language designers’ maxim of describing planning tasks in terms of their “physics, not advice”[38].1.2. Finite-domain representationsThe absence of any form of “advice” from the PDDL representation is appropriate for a language designed for generalproblem solvers, but it comes at a price, to be paid by planning algorithms that have to reason about the represented task.In particular, the state space induced by a propositional representation such as the one shown in Fig. 2 is very unstructured.A priori, a proposition like at-p1-a (stating that the first parcel is at location A) bears no closer relationship to at-p1-b(stating that the first parcel is at location B) than to, say, in-p2-t (stating that the second parcel is currently inside thetrain). However, if we take into account their intended meaning, propositions that represent potential locations of the sameparcel are clearly more closely related to each other than to ones that encode properties of the other parcel. In particular,only one of the propositions of the form at-p1-x can be true at the same time in any feasible world state. To the planner,there appear to be as many as 235 ≈ 3.4 · 1010 feasible world states in the example task, corresponding to all valuationsof the 35 propositional state variables, yet in truth the number of relevant states is only 11616 ≈ 1.2 · 104, as all othervaluations are not reachable from the given initial state.An alternative representation of the example task is shown in Fig. 3. This representation uses general finite-domainvariables, not just binary ones, to represent the state of the world. For example, a single variable p1 with a domain of11 values completely encodes the state of the first parcel, subsuming the information of all propositions at-p1-x andin-p1- y from the STRIPS encoding. Using this representation, the set of feasible world states coincides with the set ofsyntactically legal ones.In this article, we present an efficient algorithm for translating planning tasks specified in PDDL 2.2 into a compactfinite-domain representation. The algorithm has been implemented as part of the Fast Downward planner [29] and used bya number of other planning algorithms [3,27,31,48,49]. It extends an earlier algorithm by Edelkamp and Helmert [15] whichalso translates PDDL tasks to finite-domain representations, but is limited to a much smaller language fragment (STRIPS, notyping, no domain constants in operator definitions).As far as we know, no other algorithms for this problem have been described in the literature, so the main contributionof this article is the first description of a method to generate concise finite-domain representations from arbitrary (non-M. Helmert / Artificial Intelligence 173 (2009) 503–535505Fig. 2. Propositional STRIPS representation of the transportation planning task.numeric, non-temporal) PDDL tasks. From a high-level perspective, our approach follows very similar ideas to the algorithmof Edelkamp and Helmert, but the generalization beyond STRIPS requires significant extensions to the core components ofthe translation algorithm, invariant synthesis (Section 5) and grounding (Section 6). (Indeed, even though the emphasis in thisarticle is on the overall goal of transforming PDDL tasks into a concise finite-domain representation, we believe that theinvariant synthesis and grounding algorithms we present are also useful for planning algorithms that work on traditionalPDDL representations, so the algorithms presented in Sections 5 and 6 may be seen as additional contributions of thispaper.)1.3. Why finite-domain representations?Before diving into more technical matters, let us briefly discuss why compact finite-domain representations might bedesirable. We already noted that in the STRIPS representation, unlike the finite-domain representation, there is a vastlylarger number of syntactically valid states than feasible (reachable) states in the planning task. This is not necessarilyproblematic – for example, a planning algorithm based on forward search, such as Hoffmann and Nebel’s FF [33], will neverencounter any of the infeasible states, so there is no obvious advantage to the finite-domain representation. However, anumber of other planning approaches do benefit significantly from the changed representation:• Planning algorithms based on SAT-solving [35,36] can use SAT representations that disallow exploring partial valuationsthat assign inconsistent values to a single finite-domain variable. This is an example of the more general notion of mutexconstraints, which is critical to the performance of SAT planners [43]. A naive SAT encoding would need to search the506M. Helmert / Artificial Intelligence 173 (2009) 503–535Fig. 3. Finite-domain representation of the transportation planning task.full space of syntactically valid STRIPS states within each variable layer. In addition to the use of mutexes, the recentlysuccessful MaxPlan planner [7] also uses the finite-domain representation to derive so-called londex constraints, whichare reported as the key innovation of the planner. Londex constraints need finite-domain representations to be effective:for binary state variables, they offer no additional pruning power over mutex constraints.• Planners that perform a symbolic exploration of the state space with binary decision diagrams (BDDs) can use thefinite-domain representation to reduce the number of variables required in the BDD encoding, compared to a naiveencoding. Moreover, the finite-domain representation leads to a variable ordering where closely related propositions aregrouped together, which is critical to good performance of BDD exploration [17].• Heuristic planning approaches using pattern databases or other homomorphism abstractions [14,27,31] benefit from themore concise finite-domain encoding because larger subtasks can be solved and stored in memory and thus used as anabstraction heuristic. Moreover, as for BDDs, the finite-domain representation groups related propositions which shouldbe considered together in abstractions.• Planners based on constraint programming [11,47] can build more efficient CSP representations from finite-domainrepresentations than from a direct encoding of the state variables in the PDDL representation. As a case in point, CPlanby van Beek and Chen [47] uses hand-tailored CSP encodings of standard planning domains. In most cases, its staterepresentations are identical to the finite-domain representations generated by the algorithm presented in this article.• Compilations to integer programming (IP) can use the finite-domain representation to get more concise IP represen-tations. By modelling the value changes of a single finite-domain variable as a network flow problem, which is verynaturally expressible as a linear or integer program, it is also possible to use a richer notion of “plan steps” than intraditional Graphplan-like encodings. This helps reduce the IP size and often translates to better performance [49].• Planning approaches based on problem decomposition, such as the causal graph heuristic [28] used in the Fast Down-ward planner [29], benefit from the simpler causal structure of the finite-domain representation. To illustrate this,M. Helmert / Artificial Intelligence 173 (2009) 503–535507Fig. 4. Causal graph for the example task (STRIPS representation).Fig. 5. Causal graph for the example task (finite-domain representation).compare the causal graph of the STRIPS encoding of the example problem (Fig. 4) to the causal graph of its finite-domain counterpart (Fig. 5). Indeed, it has recently been shown that the causal graph heuristic degenerates to aninferior variant of the additive heuristic on binary representations [30].This concludes our discussion of the potential advantages of concise finite-domain representations. In the next section,we formally introduce PDDL and finite-domain representations, before we begin describing the translation algorithm inSection 3.2. DefinitionsAs remarked in the introduction, PDDL is the language in which planning tasks are most commonly expressed. In par-ticular, the planning tasks of the international planning competitions (IPC) are expressed in PDDL, so a planning systemmust be able to deal with this language in order to participate. In this work, we consider the non-numerical, non-temporalfragment of PDDL 2.2, i.e., “level 1” of that language (where level 2 introduces numerical state variables and level 3 intro-duces temporal planning features). We do not consider the most recent additions to the language, namely the capabilitiesfor expressing plan constraints and preferences in PDDL 3 [24]. However, these features are orthogonal to the issue of binaryvs. finite-domain encoding, so that extending our work in this direction is conceptually easy.Our definition of PDDL tasks uses common notations from first-order logic which we assume to be known; we referto the literature [13] for formal definitions. Throughout the section, we assume that all logical formulae are over a first-order language L which consists of sufficiently many constant symbols (objects in PDDL terminology), relation symbols(predicates) and variable symbols. There are no function symbols, unless one considers constants to be 0-ary functions. Weuse the notation free(ϕ) to refer to the set of free variables of a first-order formula ϕ.Definition 1 (PDDL operators). A PDDL operator is a pair (cid:3)χ , e(cid:4), which consists of a (possibly open) first-order formula χcalled its precondition and a PDDL effect e. PDDL effects are recursively defined by finite application of the following rules:• A first-order literal l is a PDDL effect called a simple effect.• If e1, . . . , en are PDDL effects, then e1 ∧ · · · ∧ en is a PDDL effect called a conjunctive effect.• If χ is a first-order formula and e is a PDDL effect, then χ (cid:2) e is a PDDL effect called a conditional effect.508M. Helmert / Artificial Intelligence 173 (2009) 503–535• If v 1, . . . , vk are variable symbols and e is a PDDL effect, then ∀v 1 . . . vk : e is a PDDL effect called a universally quan-tified effect or universal effect.Free variables of simple effects are defined as for literals in first-order logic. Free variables of other effects are definedby structural induction:• free(e1 ∧ · · · ∧ en) = free(e1) ∪ · · · ∪ free(en),• free(χ (cid:2) e) = free(χ ) ∪ free(e),• free(∀v 1 . . . vk : e) = free(e) \ {v 1, . . . , vk}.The set of free variables of a PDDL operator is defined as free((cid:3)χ , e(cid:4)) = free(χ ) ∪ free(e). Free variables are also calledparameters of the operator.PDDL operators define the ways in which a planning algorithm can move from one world state to another. If the currentstate satisfies the precondition of an operator, then the operator may be applied, leading to a new state which is like the oldone except that it is modified in certain ways specified by the effect of the operator. An operator with parameters cannotbe applied directly; it must first be grounded by substituting concrete objects for the parameters.Definition 2 (PDDL axioms). A PDDL axiom is a pair (cid:3)ϕ, ψ(cid:4) such that ϕ is a first-order atom and ψ is a first-order formulawith free(ψ) ⊆ free(ϕ). We write the axiom (cid:3)ϕ, ψ(cid:4) as ϕ ← ψ and call ϕ the head and ψ the body of the axiom.A set A of PDDL axioms is called stratifiable iff there exists a total preorder (cid:10) on the predicate symbols of A suchthat for each axiom where predicate Q occurs in the head, we have P (cid:10) Q for all predicates P occurring in the body, andP ≺ Q for all predicates P occurring in a negative literal in the translation of the body to negation normal form.Axioms provide a way of defining certain predicates based on other, “more basic” predicates. For example, given anontop predicate, we can define its transitive closure above with the two axioms above(x, y) ← ontop(x, y) andabove(x, z) ← ∃ y(ontop(x, y) ∧ above( y, z)).Stratifiability of a set of axioms is necessary for ensuring that the outcome of axiom evaluation is well-defined. Withoutsuch a condition, it would be possible to specify rules of the form “ P (x) is true whenever P (x) is false.” Intuitively, P ≺ Qmeans that the truth value of atoms over P must be determined before the truth value of atoms over Q .Definition 3 (PDDL tasks). A PDDL task is given by a 4-tuple (cid:5) = (cid:3)χ0, χ(cid:6), A, O(cid:4) with the following components:• χ0 is a finite set of ground atoms called the initial state.• χ(cid:6) is a closed formula called the goal formula.• A is a finite stratified set of PDDL axioms.• O is a finite set of PDDL operators.Predicates occurring in the head of an axiom in A are called derived predicates. Predicates occurring in the initial stateor in simple effects of operators in O are called fluent predicates. The sets of derived and fluent predicates are required tobe disjoint.We assume that the reader is already familiar with PDDL semantics and point to the language definition [18,21] for moreinformation. Apart from syntactic differences, there are three aspects of non-numerical, non-temporal PDDL 2.2 not capturedby our definition:• There are no operator names. Our translation algorithm maps each grounded PDDL operator to a unique finite-domainrepresentation operator, so that an implementation need only propagate operator names, and any plans generated forthe translated task need not undergo any form of post-processing to apply to the original task.• There is no distinction between domain constants and objects of the problem instance, or indeed between the domainand problem instance specification in general. At the level of individual problem instances at which the translationalgorithm works, there is no need for such a distinction.• There are no types. Our translation algorithm compiles away types into unary predicates in the very first processingstep (see Section 4.1), so we can assume untyped representations for all following stages.With PDDL as a starting point, let us now introduce the kinds of planning tasks that the translation algorithm gener-planning formalism [2,34],ates, which we call FDR (finite-domain representation) tasks. FDR tasks are based on the SASextended with axioms and conditional effects.+The definition exhibits a number of similarities, but also a few differences between PDDL tasks and our planning model.FDR tasks only allow simple conjunctions in goals, axioms and operators, and conditional effects cannot be nested. Moreover,M. Helmert / Artificial Intelligence 173 (2009) 503–535509PDDL tasks use first-order concepts such as schematic operators whose variables can be instantiated in many different ways,while FDR tasks are grounded. These two differences to PDDL, in particular the use of a grounded representation, are dueto a desire to keep the FDR formalism simple, to reduce the burden for planners that use it. Indeed, all the planningapproaches for finite-domain representations listed in the previous section have been introduced for (and, in most cases,require) grounded representations. (We believe, however, that many of the translation ideas introduced in this article canbe adapted to schematic finite-domain representations where such representations appear more desirable.)Definition 4 (Planning tasks in finite-domain representation (FDR tasks)). A planning task in finite-domain representation (FDRtask) is given by a 5-tuple (cid:5) = (cid:3)V, s0, s(cid:6), A, O(cid:4) with the following components:• V is a finite set of state variables, where each variable v ∈ V has an associated finite domain Dv . State variables arepartitioned into fluents (affected by operators) and derived variables (computed by evaluating axioms). The domainsof derived variables must contain the default value ⊥.A partial variable assignment over V is a function s on some subset of V such that s(v) ∈ Dv wherever s(v) is defined.A partial variable assignment is called a state if it is defined for all fluents and none of the derived variables in V . It iscalled an extended state if it is defined for all variables in V . In the context of partial variable assignments, we writev = d for the variable-value pairing (cid:3)v, d(cid:4) or v (cid:15)→ d.• s0 is a state over V called the initial state.• s(cid:6) is a partial variable assignment over V called the goal.• A is a finite set of (FDR) axioms over V . Axioms are triples (cid:3)cond, v, d(cid:4), where cond is a partial variable assignmentcalled the condition or body of the axiom, v is a derived variable called the affected variable, and d ∈ Dv is called thederived value for v. The pair (cid:3)v, d(cid:4) is called the head of the axiom.The axiom set A is partitioned into a totally ordered set of axiom layers A1 ≺ · · · ≺ Ak such that within the same layer,each affected variable must appear with a unique value in all axiom heads and bodies. In other words, within the samelayer, axioms with the same affected variable but different derived values are forbidden, and if a variable appears in anaxiom head, then it may not appear with a different value in a body. This is called the layering property.• O is a finite set of (FDR) operators over V . An operator (cid:3)pre, eff (cid:4) consists of a partial variable assignment pre over Vcalled its precondition, and a finite set of effects eff . Effects are triples (cid:3)cond, v, d(cid:4), where cond is a (possibly empty)partial variable assignment called the effect condition, v is a fluent called the affected variable, and d ∈ Dv is calledthe new value for v.For axioms and effects, we commonly write cond → v := d in place of (cid:3)cond, v, d(cid:4).To provide a formal semantics for planning for FDR tasks, we first need to formalize the semantics of axioms.Definition 5 (Extended states defined by a state). Let s be a state of an FDR task (cid:5) with axioms A, layered as A1 ≺ · · · ≺ Ak.The extended state defined by s, written as A(s), is the result sof the following algorithm:(cid:17)algorithm evaluate-axioms(A1, . . . , Ak, s):for each variable v:(cid:2)(cid:17)s(v) :=s(v)⊥if v is a fluent variableif v is a derived variablefor i ∈ {1, . . . , k}:while there exists an axiom (cond → v := d) ∈ Aiwith cond ⊆ sand sChoose such an axiom cond → v := d.(cid:17)(v) := d.s(cid:17)(v) (cid:18)= d:(cid:17)In other words, axioms are evaluated in a layer-by-layer fashion using fixed point computations, which is very similar tothe semantics of stratified logic programs. It is easy to see that the layering property from Definition 4 guarantees that thealgorithm terminates and produces a deterministic result. Having defined the semantics of axioms, we can now define thestate space of an FDR task.Definition 6 (FDR state spaces). The state space of an FDR task (cid:5) = (cid:3)V, s0, s(cid:6), A, O(cid:4), denoted as S((cid:5)), is a directed graph.Its vertex set is the set of states of V , and it contains an arc (cid:3)s, s(cid:17)(cid:4) iff there exists some operator (cid:3)pre, eff (cid:4) ∈ O such that:• pre ⊆ A(s),• s• s(cid:17)(v) = d for all effects (cond → v := d) ∈ eff with cond ⊆ A(s), and(cid:17)(v) = s(v) for all fluents v where no such effect exists.510M. Helmert / Artificial Intelligence 173 (2009) 503–535Finally, we can define the FDR planning problem.Fig. 6. Overview of the translation algorithm.Definition 7 (FDR planning). FDR-Plan is the following search problem: Given an FDR task (cid:5) with initial state s0, goal s(cid:6)and axioms A, compute a path in S((cid:5)) from s0 to some state s(cid:17)FDR-PlanEx is the following decision problem: Given an FDR task (cid:5) with initial state s0, goal s(cid:6) and axioms A, does(cid:17)), or prove that none exists.with s(cid:6) ⊆ A(sS((cid:5)) contain a path from s0 to some state s(cid:17)with s(cid:6) ⊆ A(s(cid:17))?The FDR-PlanEx problem is easily shown to be PSPACE-hard because it generalizes the plan existence problem forpropositional STRIPS, which is known to be PSPACE-complete [6]. It is also easy to see that the addition of non-binarydomains, axioms and conditional effects does not increase the theoretical complexity of FDR planning beyond propositionalSTRIPS. Thus, we conclude our formal introduction of FDR planning by stating that FDR-PlanEx is PSPACE-complete. In thefollowing section, we turn to the problem of generating concise finite-domain representations from PDDL representations.3. Translation overviewTranslation is performed in four stages. Starting from a PDDL specification, we first apply some well-known logicalequivalences to compile away types and simplify conditions and effects in the normalization stage (Section 4). Next, theinvariant synthesis stage computes mutual exclusion relations between atoms, which are later used for synthesizing the FDRvariables (Section 5). The grounding stage performs a relaxed reachability analysis to compute the set of ground atoms,axioms and operators that are considered relevant for the planning task and computes a grounded PDDL representation(Section 6). Invariant synthesis and grounding are not related to one another and could just as well be performed in theopposite order. Finally, the FDR task generation stage chooses the final set of state variables by using the information frominvariants and grounding and produces the FDR output (Section 7).The complete translation process is outlined in Fig. 6. Before we begin the detailed discussion of these stages in thefollowing sections, we should point out that of these four stages, only three are necessary to convert a PDDL task to anFDR task: the invariant synthesis stage can be omitted. However, without the use of invariants, there would be a 1:1correspondence between (relevant) ground atoms of the PDDL task and state variables of the FDR task; in particular, allstate variables in the generated FDR task would be binary. Therefore, invariants are important for obtaining a concise finite-domain representation.4. NormalizationThe normalization stage has three responsibilities: compiling away types, simplifying conditions, and simplifying effects.Its result is a normalized PDDL 2.2 task, which is a PDDL task with a number of strong syntactical restrictions.Definition 8 (Normalized PDDL tasks). A normalized PDDL task is a PDDL task that satisfies the following structural restric-tions:M. Helmert / Artificial Intelligence 173 (2009) 503–535511• The goal formula is a conjunction of literals.• All axiom bodies are conjunctions of literals (except for the possible implicit existential quantification of free variablesnot occurring in the axiom head).• All operator preconditions are conjunctions of literals.• All effect conditions are conjunctions of literals.• All operator effects are conjunctions of universally quantified conditional simple effects.4.1. Compiling away typesAs suggested earlier, types are compiled away as the very first processing step. For each type occurring in the input,and for the type object, we introduce a new unary predicate with the same name. Typed constructs occur in PDDL 2.2specifications in a semantically meaningful way in three places:(1) Definition of domain constants and objects of the task (typed objects).(2) Definition of formal parameters of schematic operators (typed operators).(3) Definition of quantified variables in existential and universal conditions and universal effects (typed quantifiers).Typed objects are translated into new atoms for the initial state. For example, the specification someobj - sometypeleads to a new initial atom (sometype someobj), plus an additional atom (supertype someobj) for each supertypeof sometype, including the universal supertype object.Typed operators are transformed by introducing new preconditions. For example, for an operator with parameter specifi-cation :parameters (?par1 - type1 ?par2 - type2) and precondition ϕ, the parameter specification is replacedby :parameters (?par1 ?par2) and the precondition is replaced by (and (type1 ?par1) (type2 ?par2)ϕ).Typed quantifiers in conditions are compiled away with the usual logic idioms, turning (exists (?v - type) ϕ)into (exists (?v) (and (type ?v) ϕ)) and (forall (?v - type) ϕ) into (forall (?v) (imply(type ?v) ϕ)).Finally, typed universal effects are compiled into universal conditional effects, so (forall (?v - type) e) becomes(forall (?v) (when (type ?v) e)).After types have been eliminated, we are left with a PDDL task in the sense of Definition 3. We will thus use the moreconcise logical notation from that definition in the following, rather than lengthy PDDL syntax. For example, we write ϕ ∨ ψinstead of (or ϕ ψ ) and ϕ (cid:2) e instead of (when ϕ e).4.2. Simplifying conditionsIn PDDL tasks, general first-order formulae may occur in many places: goal formula, axiom bodies, operator preconditionsand conditions of conditional effects. Our aim is to replace all these with simple conjunctions of literals.Towards this goal, we first eliminate implications with the equivalence ϕ → ψ ≡ ¬ϕ ∨ ψ and translate the resultingconditions into first-order negation normal form using de Morgan’s laws for first-order logic.The next step is slightly tricky. If there are any universally quantified conditions, we rewrite the outermost universalquantification in all conditions with the equivalence ∀xϕ ≡ ¬∃x¬ϕ. This might seem somewhat counterproductive becausethis transformation destroys negation normal form, so after the rewrite, we introduce a new axiom for the subformulathat violates the normal form property, ∃x¬ϕ. Formally, if free(∃x¬ϕ) = {v 1, . . . , vk}, we introduce a new derived predicatenew-pred of arity k, defined by the axiom new-pred(v 1, . . . , vk) ← ψ , where ψ is the translation of ∃x¬ϕ to negationnormal form. We can then replace the original condition ∀xϕ by ¬new-pred(v 1, . . . , vk). If several variables are universallyquantified together within the same expression, we transform them together, introducing only one new derived predicatefor the quantifier group. We repeat this step until there are no more universally quantified conditions. Note that onlyuniversally quantified conditions are translated, not universal effects, which also use the ∀ notation. Universal effects cannotbe compiled away easily, so we deal with them separately in a later stage.If after elimination of universal quantifiers the goal condition is not a simple conjunction (i.e., if it contains disjunctionsor existential quantifiers), we replace it by a new axiom, since the following transformations sometimes require splittingseveral conditions into two, which is easy to do for axiom bodies, operator preconditions and effect conditions, but notpossible in our formalism for goal conditions, of which there can be only one. So for example, if the goal is ϕ ∨ ψ , weintroduce a new parameterless derived predicate goal-pred and a new axiom goal-pred() ← ϕ ∨ ψ , replacing theoriginal goal with the atom goal-pred().The next step is the elimination of disjunctions. We move disjunctions to the roots of conditions by applying the equiv-alences ∃x(ϕ ∨ ψ) ≡ ∃xϕ ∨ ∃xψ and ϕ ∧ (ψ ∨ ψ (cid:17)) ≡ (ϕ ∧ ψ) ∨ (ϕ ∧ ψ (cid:17)) and the laws of associativity and commutativity. Intheory, moving disjunctions over conjunctions can lead to an exponential increase in formula size, which we could avoid byintroducing new axioms for component formulae. In practice, the conditions encountered in actual planning domains arenot problematic in this regard, so that axioms are not necessary. (For the intended applications of finite-domain represen-tations mentioned in Section 1.3, we believe that of two otherwise identical representations, the one that uses fewer state512M. Helmert / Artificial Intelligence 173 (2009) 503–535variables is usually preferable, so we attempt to avoid introducing new state variables unless there is a compelling reasonto do so.)After disjunctions have been moved to the root of all formulae, we can eliminate them by splitting the surroundingstructures. If the disjunction ϕ ∨ ψ is part of an axiom body, we generate two axioms with identical head, one with bodyϕ and one with body ψ . If the disjunction is part of an operator precondition, we replace the operator by two copies of theoriginal, one with precondition ϕ and one with precondition ψ . Finally, if the disjunction is part of an effect condition, wereplace the conditional effect (ϕ ∨ ψ) (cid:2) e by (ϕ (cid:2) e) ∧ (ψ (cid:2) e).Next, we move existential quantifiers out of conjunctions by applying the equivalence (∃xϕ) ∧ ψ ≡ ∃x(ϕ ∧ ψ). The equiv-alence only holds when x /∈ free(ψ), so to avoid trouble here and later, we first rename all variables bound by quantifiers tosome unique name.Having moved existential quantifiers to the root of conditions, we can eliminate them. For axioms, we simply drop them,following the logic programming convention that all free variables in the body that are not part of the head are implicitlyexistentially quantified. For operator preconditions, we also drop them, adding the existentially quantified variables to theparameter list of the schematic operator. For effect conditions, we replace (∃xϕ) (cid:2) e by ∀x : (ϕ (cid:2) e).4.3. Simplifying effectsAfter the somewhat laborious simplification of conditions, effect simplification is conceptually very simple. First, universal(cid:17)) and ϕ (cid:2) (e ∧and conditional effects are moved into conjunctive effects by the equivalences ∀x : (e ∧ e(cid:17)). Second, conditional effects are moved into universal effects by the equivalence ϕ (cid:2) (∀x : e) ≡ ∀x :(cid:17)) ≡ (ϕ (cid:2) e) ∧ (ϕ (cid:2) ee(ϕ (cid:2) e). Finally, nested effects of the same type are flattened, i.e., conjunctive effects containing conjunctive effects arecollapsed into a single conjunctive effects with more conjuncts, universal effects containing universal effects are collapsedinto a single universal effect quantifying over more variables, and nested conditional effects of the type ϕ (cid:2) (ψ (cid:2) e) aretransformed to (ϕ ∧ ψ) (cid:2) e. Note that this latter modification preserves the previously generated normal form for effectconditions.(cid:17)) ≡ (∀x : e) ∧ (∀x : eAfter these transformations, the possible nesting of effects is thus restricted to the simple chain conjunctive effect (cid:21)universal effect (cid:21) conditional effect (cid:21) simple effect. However, not all effect types must necessarily be present; for example,a universal effect may, but need not, contain a conditional effect. To enforce a regular effect structure, we replace simpleeffects e not surrounded by conditional effects by (cid:22) (cid:2) e ((cid:22) is seen as the empty conjunction, so this condition is in normalform), conditional effects e not surrounded by universal effects by ∀ : e (quantifying over zero variables), and universaleffects e not surrounded by conjunctive effects by a conjunctive effect containing the singleton e.As a result, after normalization each operator has a conjunctive effect, where each conjunct is a simple effect with anassociated set of universal quantifiers and an associated condition, both of which can be trivial. Thus it is not necessary tostore normalized operator effects in a tree structure; a flat vector is sufficient.This concludes the normalization stage. For the sake of the following discussion, we briefly recapitulate the structuralrestrictions for normalized PDDL tasks (Definition 8):• The representation is untyped.• All formulas (goal, preconditions, effect conditions, axiom bodies) are conjunctions of literals.• The effect of each operator is a conjunctive effect whose parts are of the form ∀v 1 . . . vk : ϕ (cid:2) e, where e is a simpleeffect.In the following, we will refer to the individual simple effects of an operator in a normalized PDDL task as being arrangedin an effect list. For the simple effect e occurring within the universal conditional effect ∀v 1 . . . vk : ϕ (cid:2) e, we will refer to{v 1, . . . , vk} as the set of bound variables of e and to ϕ as the condition of e. If e is a positive literal, we will call it an addeffect, otherwise a delete effect.5. Invariant synthesisAn invariant of a planning task is a property which is satisfied by all world states that are reachable from the initialstate. Many invariants are uninteresting; for example, the property “At least five state variables are true” is an invariant formost propositional STRIPS planning tasks, but does not seem to entail a useful (i.e., exploitable) piece of information for aplanner. Other invariants would be useful to know but are too difficult to verify. For example, “The goal is not satisfied” isan invariant iff the planning task is not solvable, so confirming the invariance of that state property is PSPACE-hard for apropositional STRIPS task.Nevertheless, invariants are a useful tool for many planning systems, which is why they have been studied by manyresearchers in a variety of contexts [20,25,41,42]. Section 5.5 discusses related work on invariants, and why we introduce anew invariant synthesis algorithm in the following instead of applying one of the algorithms from the literature. The shortanswer is that most algorithms from the literature are limited to STRIPS domains. Moreover, some of them are prohibitivelyexpensive for the largest planning tasks in the IPC benchmark suite.M. Helmert / Artificial Intelligence 173 (2009) 503–535513For the purposes of translating planning tasks to a finite-domain representation, mutual exclusion (mutex) invariants areespecially interesting. A mutex invariant states that certain propositions can never be true at the same time. This affectstranslation because a set of propositions which are pairwise mutually exclusive can be easily encoded as a single statevariable whose value specifies which of the propositions is true (or that none of them is true at all), rather than as anumber of state variables encoding the truth value for each proposition individually.Invariance is usually proven inductively. First, one shows that a hypothesized property is true in the initial state. Then,one shows that if the property is true in some state, it must also be true in all its successor states. Together, this impliesthat the property is true in all reachable states, and thus an invariant.As mentioned before, the automatic discovery of invariants is a hard problem in general, but for many relevant types ofstate properties, sufficient conditions exist that can be checked quickly. Still, synthesizing invariants is costly, and for thisreason, we are interested in algorithms working directly with the first-order PDDL description of a planning task, not on agrounded representation. Indeed, our algorithm goes beyond this requirement by not relying on the information in the taskpart of the PDDL input at all, solely exploiting information present in the domain part. This is a valuable feature, but it rulesout the possibility of directly proving mutex conditions, because a mutex cannot be established without checking the initialstate. Instead, we consider a slight generalization of mutexes.Definition 9 (Monotonicity invariant candidates). A monotonicity invariant candidate for a PDDL task (cid:5) is given by a pairI = (cid:3)V , (cid:7)(cid:4), where V is a set of first-order variables called the parameters of the candidate, and (cid:7) is a set of atoms.Variables occurring freely in (cid:7) which are not parameters are called counted variables of the candidate.For V = {v 1, . . . , vm} and (cid:7) = {ϕ1, . . . , ϕk}, we write I as ∀v 1 . . . vm ϕ1 + · · · + ϕk ↓. In the special case V = ∅, we write∀ · ϕ1 + · · · + ϕk ↓.In the following, we will mostly refer to monotonicity invariant candidates as invariant candidates or simply candidates,as we do not consider other kinds of invariant candidates.The preceding definition defines the syntax for invariant candidates; we now have to provide the semantics. This is some-what involved, so we provide an example from the Logistics domain first. Consider the candidate (cid:3){p}, {at(p, l), in(p, v)}(cid:4),where p, l and v are variable symbols. We write this as ∀p at(p, l) + in(p, v) ↓ and read it as “For all packages p, thenumber of locations l such that at(p, l) is true plus the number of vehicles v such that in(p, v) is true, is non-increasing.”In our terminology, p is the parameter of the candidate, while l and v are the counted variables. This invariant candidate isan actual invariant – it does hold in all reachable states – and it is one of the invariants found by our algorithm in Logistics.Let us now formalize what it means for a candidate to be an invariant.Definition 10 (Monotonicity invariants). Let I = (cid:3)V , (cid:7)(cid:4) be a monotonicity invariant candidate of a PDDL task (cid:5).An instance of I is a function α mapping the variables in V to objects of (cid:5).The set of covered facts of an instance α of I is the set of all ground atoms of the planning task (cid:5) which unify withsome ϕ ∈ (cid:7) under α, i.e., the set of all ground atoms ϕ0 of (cid:5) for which there exists a variable map β ⊇ α such thatβ(ϕ) = ϕ0 for some ϕ ∈ (cid:7).The weight of an instance α of I in a state s is the number of covered facts of α which are true in s.The monotonicity invariant candidate I is called a monotonicity invariant iff for all instances α of I, all states s(cid:17)is no greater than the weight ofof s, the weight of α in s(cid:17)reachable from the initial state of (cid:5) and all successor states sα in s.Similar to our convention for invariant candidates, we usually refer to monotonicity invariants simply as invariants.The definition is probably best understood by considering the previously discussed example invariant. To get an instanceof the candidate ∀p at(p, l) + in(p, v) ↓, we must map p to a particular object, say by α = {p (cid:15)→ package1}. The setof covered facts of α in a given state s then consists of all atoms of the form at(package1, l) or in(package1, v)that are satisfied in s. In a reachable state, there will typically only be one such atom, for example given by the mappingβ = α ∪ {l (cid:15)→ location1}, so the weight of α in s will be 1. But even if we consider strange states where α has a greaterweight than 1, it is easy to see that the weight of α in a successor state of s is never greater than the weight of α in s.This is true for all instances of the candidate, so it is indeed an invariant.As hinted before, monotonicity invariants are useful for grouping a number of related propositions into a single finite-domain variable: if we have found an invariant for a planning task and a given instance of that invariant has weight 1 in theinitial state, then the facts covered by that instance are pairwise mutually exclusive. This is how the synthesized invariantsare utilized during the later stages of translation.So how do we generate invariants? Since there are too many feasible candidates to enumerate exhaustively, we followa guided guess, check and repair approach. Starting from a set of a few simple initial candidates, we try to prove that agiven candidate is indeed an invariant. Whenever this is the case, we keep the invariant and do not consider it further.However, when the proof fails, we try to detect why this is the case and refine the candidate to generate more candidatesthat do not fail for the same reason (although they might fail for other reasons). From a high-level perspective, this is asearch problem, and indeed we solve it using standard breadth-first search, using a closed list to avoid exploring the same514M. Helmert / Artificial Intelligence 173 (2009) 503–535invariant candidate twice. (This guarantees termination of the algorithm.) To fully specify the invariant synthesis algorithm,it thus suffices to discuss its search space:• Initial states: What are the initial candidates?• Termination test: How do we prove that a candidate is an invariant?• Successor set: How do we refine a candidate for which this proof fails?In the following, we deal with these three questions in sequence.5.1. Initial candidatesBefore starting the actual invariant synthesis, we check which predicates are affected by operators at all: some predicates,including but not limited to those representing types, are constant in the sense that atoms over these predicates have thesame truth values in all states. Such predicates are no longer needed after grounding, so we need not consider them forinvariant candidates. Of course, a constant predicate trivially satisfies a monotonicity invariant, but these are not very useful.Therefore, we limit the set of interesting predicates to all modifiable fluent predicates, i.e., predicates which occur withinoperator effects (as part of a simple effect, not merely as part of an effect condition). Note that this also excludes derivedpredicates. In theory, there is no reason why there should be no monotonicity invariants involving derived predicates, butin practice we have not seen examples of this, and detecting them would require more global reasoning than the proofmethods we use for fluent predicates. We will come back to the issue of derived predicates when discussing our methodfor proving invariance.The set of initial invariant candidates consists of all those candidates (up to isomorphism, i.e., renaming of variables)which contain at most one counted variable and exactly one atom, over a modifiable fluent predicate, whose parameters aredistinct variables. In our experience, mutexes based on invariants with several counted variables per atom are exceedinglyrare; in fact, we have not seen an example in practice.To illustrate the initialization of invariant candidates, we show the three candidates generated for the binary at predicatein the Logistics domain:∀x at(x, l) ↓∀l at(x, l) ↓∀x, l at(x, l) ↓(1)(2)(3)Similar candidates are introduced for the in predicate. Intuitively, the first candidate states that no object can be at morelocations in the successor state than in the current state, the second candidate states that no location can be occupied bymore objects in the successor state than in the current state, and the third candidate states that a given object cannotoccupy a given location in the successor state if this is not the case in the current state.Candidates (2) and (3) are obviously not invariants. Candidate (1) is not an invariant either because an object which iscurrently inside a vehicle can be at some location in the successor state while being at no location in the current state.However, we will see that we can refine (1) into an invariant.5.2. Proving invarianceIn order to prove that a given invariant candidate is an invariant, we must show that no operator can increase theweight of any of its instances. An operator increases the weight of some instance of an invariant candidate iff the numberof covered facts that it makes true is greater than the number of covered facts that it makes false. If an operator does notincrease the weight of any instance, then we say that it is balanced with regard to the invariant.Ultimately, we are interested in instances of monotonicity invariants that give rise to mutexes, so that only instances ofweight 1 are relevant for us. For this reason, we use the following condition which is slightly stronger than balance.Definition 11 (Threatened invariant candidates). An invariant candidate I is threatened by a schematic operator iff one of thefollowing two conditions holds:• The operator has an add effect that can increase the weight of an instance of I in some state, but no delete effect thatis guaranteed to decrease the weight of the same instance in the same state. In this case, we say that the operator isunbalanced with regard to I.• When ignoring delete effects, the operator can increase the weight of some instance of I in some state by at least 2. Inthis case, we say that the operator is too heavy for I.Clearly, not being threatened by any schematic operator is a sufficient condition for being a monotonicity invariant.Note that just showing that no operator is unbalanced in the sense of the definition is not sufficient for invariance, asM. Helmert / Artificial Intelligence 173 (2009) 503–535515the balance test considers different add effects in isolation. For example, an operator might have two add effects, each ofwhich is individually balanced by a delete effect. However, the operator might still cause a net increase of the weight of aninvariant instance if the two balancing delete effects can be identical. This is not always obvious; for example, consider an(incorrectly modelled) operator for moving something which is currently at two locations l1 and l2 to two other locations l3and l4:Precondition: at(x, l1) ∧ at(x, l2)Add effects: at(x, l3) ∧ at(x, l4)Delete effects: at(x, l1) ∧ at(x, l2)At first glance, the operator does not seem to be problematic for the monotonicity invariant candidate ∀x at(x, l) ↓, butactually it is: in the case l1 = l2 and l3 (cid:18)= l4, it increases the number of locations that x is currently at. Attemptingto capture such subtleties in the balance test makes this test more complicated, and even more so in the presence ofuniversally quantified effects, which can add an arbitrary number of facts. We avoid such complications by adding theheaviness test, which would reject the invariant candidate because the operator can increase the weight of its instances bytwo.Clearly, the heaviness test is stricter than necessary. If the above operator were extended with the precondition l1 (cid:18)= l2,then ∀x at(x, l) ↓ might indeed be an invariant, but it would still be rejected due to the operator being too heavy for it.In the context of translation to finite domain representation, this does not appear to be problematic because we are onlyinterested in invariants for the purpose of generating mutex groups. In that setting, the weight of interesting invariantinstances is at most one, so operators that add more than one fact either do not exist or are never applicable, and typicalPDDL models do not contain schematic operators which are never applicable.Definition 11 gives rise to the algorithm shown in Fig. 7. Most of the actual work is in unifying operator parametersand quantified variables of universal conditions; the algorithm simplifies significantly in STRIPS domains. We do not discussthe algorithm in full detail, instead focusing on two points that require some explanation, namely the satisfiability andentailment tests that occur towards the end of functions is-operator-too-heavy and is-add-effect-unbalanced.(cid:17).precond is true in s), the triggering conditions of both add effects are satisfied (e.cond and eFor the heaviness test, two add effects can only lead to an operator being too heavy in states s where the operator isactually applicable (o.cond aretrue in s) and the add effects actually add propositions that were not true previously (e.atom and e.atom are false in s). Anoperator is considered too heavy by is-operator-too-heavy if all these conditions can hold together, i.e., their conjunction issatisfiable. (Even if the conjunction is satisfiable, it is of course possible that none of the satisfying states is reachable fromthe initial state, so this may be overly conservative.)(cid:17)(cid:17)For the imbalance test, an add effect leads to an imbalance by default. However, it can be balanced if whenever theoperator is actually applied in a state s (which requires that o.precond is true in state s) and the add effect triggers(e.cond is true in s) and actually adds something (e.atom is false in s), then something is deleted at the same time,.atomwhich means that the delete effect triggers (eis true in s). Function is-add-effect-unbalanced conducts logical entailment tests to check if a balancing delete effect isguaranteed to exist. (Again, this may be overly conservative because all states in which balance is violated might be un-reachable.).cond is true in s) and deletes something that was previously true (e(cid:17)(cid:17)(cid:17)Coming back to the earlier Logistics example, all three initial candidates are threatened by the same operatorunload-truck:Precondition: package(x) ∧ truck(t) ∧ location(l) ∧ at(t, l) ∧ in(x, t)Add effects: at(x, l)Delete effects: in(x, t)The operator is unbalanced with regard to all invariant candidates due to the add effect at(x, l). Thus, as indicated before,none of (1)–(3) is an invariant. We will discuss possible refinements of the candidates shortly.There are a few subtleties about the algorithm which we want to point out briefly:• We duplicate universal effects at the beginning of is-operator-too-heavy so that we can detect if two different in-stantiations of the same universal effect can simultaneously increase the weight of some instance of the invariantcandidate.• Where Fig. 7 contains statements like “Let obe a copy of o where variables are renamed so that. . . ”, the ques-tion arises whether such a renaming is uniquely determined, and what to do if it is not. Indeed, renamings areunique (and easy to compute) as long as all atoms of the candidate refer to different predicates, which is usuallythe case. However, the algorithm generalizes to invariant candidates with several occurrences of the same predicate,like ∀x at(x, y) + at( y, x) ↓. This requires that all possible (non-isomorphic) renamings must be considered for oin(cid:17)(cid:17)516M. Helmert / Artificial Intelligence 173 (2009) 503–535Fig. 7. Algorithm for proving that an invariant candidate (cid:3)V , (cid:7)(cid:4) is an invariant.function is-add-effect-unbalanced. In our experience, invariants of this type are not very useful, but our implementationdoes support them.• We have noted before that we do not consider invariants involving derived predicates. This is because axioms corre-spond to operators that have a single add effect, but no delete effect. Invariant candidates including derived predicatescan thus never be balanced in the sense of Definition 11, except if the axiom body already entails the head, which isnot a very interesting case.• Because the operator preconditions and effect conditions are in normal form (conjunctions of literals), the satisfiabil-ity test in function is-operator-too-heavy is performed on a conjunction of literals, which is possible in linear time.(Just check if any two literals in the conjunction are complementary.) Similarly, function is-add-effect-unbalanced testsentailment between two conjunctions of literals, which is also possible in linear time.One final subtlety concerns the semantics of PDDL operators with “conflicting” effects. Note that our balance test requiresthat e.atom does not equal e.atom, i.e., the atom that is added is different from the one which is deleted. The reason forthis is that PDDL semantics mandate that if the same atom is both added and deleted simultaneously, it is actually added,so that an atom cannot balance itself.(cid:17)M. Helmert / Artificial Intelligence 173 (2009) 503–535517Fig. 8. Algorithm for refining an unbalanced invariant candidate (cid:3)V , (cid:7)(cid:4).5.3. Refining failed candidatesAs indicated in the overview of the invariant synthesis algorithm, we do not give up immediately if we cannot prove agiven candidate to be an invariant. Instead, we try to refine it by adding atoms that can restore balance. In algorithmic terms,whenever we reject an invariant candidate (cid:3)V , (cid:7)(cid:4), we try to generate a set of new candidates of the form (cid:3)V , (cid:7) ∪ {ϕ(cid:17)}(cid:4).Whether or not this is promising depends on the reason why the candidate was rejected. If it was rejected because anoperator is too heavy, then no possible refinement that adds an atom to the candidate can change this fact, and we give upon the candidate completely. If, however, it was rejected because of unbalanced operators, there is hope that we can dealwith the flaw by adding an atom that can match some delete effect of the threatening operator, balancing the unbalancedadd effect.The basic refinement algorithm is shown in Fig. 8. The actual implementation does not generate all possible refiningnaively, but rather uses information from the set of delete effects of the threatening operator o and the failed callfor which there is a chance that the new balance check will succeed.atoms ϕ(cid:17)to is-add-effect-unbalanced to only consider atoms ϕ(cid:17)Since this is conceptually straight-forward, we do not go into more detail about this technique.Instead, let us return to the Logistics example. Recall that invariant candidate (1), ∀x at(x, l) ↓, is threatened by the op-erator unload-truck, whose add effect at(x, l) is unbalanced. The operator has only one delete effect, namely ¬in(x, t).Indeed, in(x, t) is a suitable refinement atom for ϕ(cid:17)without further variable renaming, since the unload-truck operatoris balanced with regard to the refined candidate ∀x at(x, l) + in(x, t) ↓. So we add this candidate to the set of currentlyconsidered candidates. At a later stage, it will be considered by prove-invariant, which will show that it is indeed an invari-ant.In contrast, the other two candidates cannot be suitably refined. For (3), consider the drive-truck operator:Precondition: truck(t) ∧ location(l) ∧ location(l(cid:17)) ∧ city(c) ∧in-city(l, c) ∧ in-city(l(cid:17), c) ∧ at(t, l(cid:17))Add effects: at(t, l)Delete effects: at(t, l(cid:17))(cid:17)(cid:17)) is theIn order to refine (3), ∀x, l at(x, l) ↓, to balance this operator, we would need to add the atom at(x, lonly delete effect of the operator and t unifies to x. However, this atom covers the original atom at(x, l) (note that the(cid:17)) where parameter l isconverse is not true, because only lunnecessary, so that it simplifies to ∀x at(x, l(cid:17)). This candidate is isomorphic to (1) and hence not considered again.is a counted variable), leading to the candidate ∀x, l at(x, l(cid:17)), as at(t, lConsidering candidate (2) and the drive-truck operator, the only possible refinement is ∀ · at(x, l(cid:17)) ↓ (“The totalnumber of at propositions is non-increasing”), but this has more than one counted variable and thus will not be considered(cid:17)) ↓by refine-candidate. Supposing that we removed the restriction to candidates with at most one counted variable, ∀· at(x, l(cid:17)) ↓(cid:17)) + in(x, lwould turn out to be violated by the unload-truck operator, but could be further refined to ∀ · at(x, l(“The total number of at and in propositions is non-increasing”). This latter candidate is actually a monotonicity invariant.However, its only instance clearly has a weight greater than 1 in the initial state of any non-trivial Logistics task and thusis not useful for providing any mutex information. (Of course, it would still be a monotonicity invariant, and be part of theoutput of the algorithm, if the restriction to at most one counted variable were removed. To derive mutex information frommonotonicity invariants, we must also consider the initial state information; this happens in the “Variable selection” stageof the translation algorithm, described in Section 7.1.)518M. Helmert / Artificial Intelligence 173 (2009) 503–5355.4. ExamplesFig. 9. Invariants found in some standard benchmark domains.This concludes our description of the invariant synthesis algorithm. To give an impression of the kind of invariants itgenerates, Fig. 9 shows some of the results obtained on IPC domains. The invariants found in the Grid domain are mostinteresting, as they include some monotonicity information that is not covered by mutexes: the third Grid invariant statesthat the total number of open and locked doors never increases, the fourth invariant states that the number of locked doorsnever increases, and the sixth invariant states that a door which is not locked can never become locked.5.5. Related workBefore moving on to the next translation stage, we should point out that the algorithm described in this section isnot the only approach to invariant synthesis proposed in the literature. We thus provide a brief comparison to six otherapproaches, sorted in decreasing order of relatedness:• Edelkamp and Helmert’s algorithm [15] proposed for the MIPS planner [16,17],• Scholz’s algorithm for finding c-constraints [44],• Gerevini and Schubert’s DISCOPLAN [25,26],• Rintanen’s invariant synthesis algorithm [42],• Bonet and Geffner’s algorithm for generating mutexes [5], and• Fox and Long’s TIM [9,20].Apart from the first algorithm in the list, all of these were developed independently from ours, although all but the lastone follow very similar ideas. Edelkamp and Helmert’s algorithm is the most closely related approach. In fact, our algorithmcan be considered an extension of the MIPS algorithm to non-STRIPS domains. Compared to the original algorithm, ourmethod incorporates some cosmetic and performance improvements, but the main difference is the coverage of universaland conditional effects. Note, however, that this is no small difference, as it is much easier to reason about STRIPS operatorsthan about the more general class of operators occurring in normalized PDDL tasks. On STRIPS domains, both algorithmsgenerate the same set of invariants.Scholz’s algorithm is very similar to Edelkamp and Helmert’s, with only slight differences in the way that failed invariantcandidates are refined to generate new invariant candidates. It shares the weakness of being limited to STRIPS domains.DISCOPLAN also uses a very similar guess, check and repair approach. However, its method for refining invariant candi-dates is quite different. In particular, while our algorithm immediately refines an invariant as soon as a threatening operatoris discovered, DISCOPLAN first collects all threats to an invariant for all operators. Only then does it generate refinements,which attempt to address all these threats at the same time. On the one hand, collecting threats across operators allowsmaking more informed choices in invariant refinement. On the other hand, it appears that this approach incurs a per-formance penalty. For example, while our algorithm always terminates in less than a second on all IPC benchmark tasks,DISCOPLAN exceeds a 30 minute timeout on large instances of the IPC4 Airport domain. It should be noted, though, thatDISCOPLAN generates many classes of invariants besides mutexes, because it was designed as a general invariant synthesistool, not with finite-domain representations in mind. This difference in purpose should be taken into account when compar-ing runtime results, as it is likely that better runtime results could be obtained for DISCOPLAN by only considering mutualexclusion invariants. (Modifying DISCOPLAN’s algorithm to derive such a specialization appears feasible, but an appropriatemodification of the available implementation appears to be a practically non-trivial task.) Apart from efficiency concerns,another consideration is that even though DISCOPLAN is not limited to STRIPS, it can only deal with a subset of ADL fea-tures which is not sufficiently rich for all IPC benchmarks. Finally, even for STRIPS domains, we found that some invariantsimportant for a concise finite-domain encoding which our algorithm discovers were missed by DISCOPLAN. For example, inM. Helmert / Artificial Intelligence 173 (2009) 503–535519the Driverlog domain, our approach can prove that a given driver can only be at one place or inside one truck at the sametime, which allows encoding driver location in a single variable. An encoding based on the invariants found by DISCOPLANwould need to introduce a separate state variable for each driver-location and driver-truck pair. (After discussing this pointwith the DISCOPLAN authors, the algorithm has been amended, so that the most recent version of DISCOPLAN now findsthis invariant.)Rintanen’s algorithm follows the same guess-check-repair structure as our algorithm and DISCOPLAN. One main dif-ference (and advantage) of Rintanen’s algorithm is that its “check” step uses the information from all current invariantcandidates, rather than just the one currently being considered, to strengthen the induction hypothesis. An interesting dif-ference is that, opposite to our algorithm, it always proceeds from stronger invariant candidates to weaker ones. Note thatfor inductive proofs, both strengthening and weakening an invariant candidate can be a promising refinement strategy. Inparticular, weaker statements are not necessarily easier to prove than stronger ones because the induction hypothesis is alsoweaker. A problem of Rintanen’s algorithm is that it is limited to propositional STRIPS and that it is not sufficiently efficientfor many of the IPC benchmarks. For this reason, we have not made a detailed comparison regarding the kinds of invariantsit can or cannot find; from our limited experience, we believe the approaches to be comparable in this respect, at least forthe mutexes we are interested in. Like DISCOPLAN, Rintanen’s approach can find more general classes of invariants thanmutexes.Bonet and Geffner’s algorithm for generating mutexes can be seen as a special case of Rintanen’s algorithm that startsfrom a different (weaker) set of invariant candidates and immediately rejects all failed candidates instead of trying to refinethem. Like Rintanen’s algorithm, it is limited to STRIPS and works on a grounded representation, which makes it muchmore expensive to compute for large IPC benchmarks than our first-order algorithm. To keep the runtime manageable,the algorithm puts some severe restrictions on the potential mutex pairs to consider. For example, if at(x) is a set ofpropositions that encodes the location of an object on a graph, the algorithm fails to prove mutual exclusion if the diameterof the graph is greater than 2. (Examples of this arise in the Airport, Driverlog, Grid, MPrime, Mystery and TPP domains.)Finally, Fox and Long’s TIM (for type inference module) is (or can be interpreted as) an invariant synthesis algorithm whichfollows a conceptually very different approach to the other algorithms described here, based on the notion of property spaceswhich are generated from the type structure of the task, which is in turn derived by a type inference technique which givesthe system its name. TIM was originally [20] limited to STRIPS and thus not directly usable for us. It has since been extendedto handle some ADL constructs [9], independently of the development of our invariant synthesis algorithm.6. GroundingAfter computing monotonicity invariants, the next translation stage generates a variable-free representation of the nor-malized PDDL task, a process which is called grounding.Definition 12 (Grounded PDDL tasks). A grounded PDDL task is a PDDL task such that all literals occurring in the goalformula, axioms and operators are ground literals (i.e., do not contain variables).Grounding is a conceptually simple operation. If O is the set of objects of the task, a variable x in a parameterizedstructure (operator, axiom or universally quantified effect) can be eliminated by replacing the original structure with |O |copies, one for each object o ∈ O , where x is substituted with o in the respective copy. If the PDDL task were not alreadyin normal form, quantifiers in conditions could be similarly eliminated by replacing ∃xϕ with the disjunctiono∈O ϕ[x/o]and ∀xϕ with the conjunction(cid:4)(cid:3)o∈O ϕ[x/o].In general, the grounded task can be exponentially larger than the original one: for example, an operator with k pa-rameters gives rise to |O |k many ground instances, and k can grow linearly with the task size. However, in practice thenumber of parameters k is usually low, and in particular it is fixed for a given planning domain. Moreover, the exponentialblowup through grounding is computationally unavoidable, since planning with grounded representations is exponentiallyeasier than planning with schematic representations [19].In practice, for the majority of common planning domains, grounding is not a time-critical operation, and simple ground-ing schemes like the one outlined above suffice. However, there are exceptions to this rule: the naive grounding algorithmis not computationally feasible for the whole spectrum of IPC planning domains. To illustrate that grounding can be chal-lenging, we tested the grounding algorithm implemented in the FF planner [33] on the IPC benchmark suite, imposing aruntime limit of 30 minutes and a memory limit of 2 GB. (FF does not directly support derived predicates, but for the pur-poses of grounding, derived predicates can be treated as if they were operators with a single effect, which we did for thisexperiment.) FF is particularly suited for comparison because it is one of the few planners that support the full ADL subsetof the PDDL language, and because its grounded tasks follow a very similar normal form to the one in this article. (Theonly significant difference is that it compiles away negative literals in conditions.) Moreover, it uses a fairly sophisticatedgrounding procedure, originally introduced by Koehler and Hoffmann for the IPP planner [37].Our experiment showed that even though grounding in FF is blazingly fast for the vast majority of benchmarks, thereare scaling issues in some domains. In particular, the grounding procedure failed on 57 tasks (28 from the OptTelegraphdomain, 2 from Pathways, and 27 from PSR-Large) by exhausting the memory limit. Being unable to ground a planningtask would not be a significant problem if these tasks were beyond reach of current planners, but most of them are not. For520M. Helmert / Artificial Intelligence 173 (2009) 503–535Fig. 10. Schematic operators of the Logistics domain.Fig. 11. Number of ground operator generated by different grounding algorithms for task Logistics #28 (IPC1).example, the results reported by Richter et al. [40] show that their landmark-based planner can solve (in at least one of theplanner configurations described in the paper) all these tasks except for 16 of the largest PSR-Large instances under similartime and memory constraints. Furthermore, even significantly increasing the memory limit for the grounding proceduredoes not eliminate the bottleneck in the grounding procedure: with a 28 GB memory limit, grounding with FF still fails on26 tasks (11 from OptTelegraph, 15 from PSR-Large), of which 16 are solved by the planner of Richter et al. with a 3 GBmemory bound.6.1. Improving the naive grounding algorithmHow can we perform grounding more efficiently than the naive algorithm that instantiates each variable with eachpossible object? The key observation here is that many ground operators produced by the naive algorithm are not applicablein any reachable state of the task, and thus can be safely omitted from the grounded representation.We illustrate this point with the operators of the Logistics domain, shown in Fig. 10, using instance #28 from IPC1 [38]as a running example. There are 490 objects in this task, so that the naive algorithm generates 490k ground instances ofeach operator with k parameters. There are 5 operators with 3 parameters each and one operator with 4 parameters, sowe end up with 5 · 4903 + 4904 = 5.82 · 1010 operators (cf. first row of Fig. 11), which is clearly infeasible. We will nowdiscuss a number of increasingly sophisticated techniques to reduce this number, leading up to the ideas underlying thenew grounding method introduced in this article, which is then discussed in the remainder of this section.6.1.1. Exploiting type informationA brief look at the output of the naive algorithm shows that the vast majority of operators is useless. For example,load-truck(city1, truck4, airport1) requires that package(city1) is true, which is never the case in a reachablestate. Indeed, even though the Logistics domain from IPC1 is untyped, it is easy to see that the unary predicates airplane,M. Helmert / Artificial Intelligence 173 (2009) 503–535521airport, city, location, package and truck are used as “implicit types”: they are static (do not appear in operatoreffects) and serve to restrict the possible instantiations of the operator parameters.As a first enhancement, we can take such (implicit or explicit) typing information into account. The example task has 42packages, 83 trucks, 5 airplanes, 20 cities and 340 locations (17 in each city). One location in each city is an airport, so thereare 20 airports. Exploiting this information, we only need to generate 42 · 83 · 340 ground instances of load-truck andunload-truck, 83 · 340 · 340 · 20 ground instances of drive-truck, 42 · 5 · 340 ground instances of load-airplaneand unload-airplane and 5 · 20 · 20 ground instances of fly-airplane, for a total of 1.94 · 108 ground operators(second row of Fig. 11). Despite the improvement of more than two orders of magnitude, this is still infeasibly large for a 2GB memory limit.6.1.2. Checking static preconditionsThe vast majority of generated ground operators are instances of drive-truck, and most of them are not usefulbecause the preconditions on the in-city predicate can never be true. Like the type predicates previously considered,in-city is a static predicate, so a natural second enhancement would be to avoid generating operators which violate aprecondition on any static predicate, not just unary ones. This reduces the number of ground instances for drive-truckto 83 · 340 · 17 · 1 (after parameters t and l are instantiated arbitrarily, there are only 17 valid options for parameter landonly one valid option for parameter c). The other operators do not mention any non-unary static predicates, so their numberof ground instances remains the same, for a total of 3.00 · 106 ground operators (third row of Fig. 11), another improvementof roughly two orders of magnitude.(cid:17)An important caveat, though, is that unlike the naive grounding algorithm and the algorithm that takes type informationinto account, a grounding algorithm that filters on static preconditions cannot be implemented in such a way that it isguaranteed to run in linear time in the size of its output, unless P = NP. To see this, consider a planning task with just asingle operator, whose precondition is a conjunction of atoms over static predicates. Such an operator then defines a con-straint satisfaction problem (CSP) [10], where the domains of the variables are given by the objects of the task, the constraintschemas are given by the facts for the static predicates in the initial state, and the preconditions of the operator correspondto the constraints. Deciding whether or not an operator has any valid instantiation is thus akin to deciding CSP solvability,which is NP-complete. The problem is already NP-hard in the case where (using planning terminology instead of CSP ter-minology) there are only three objects and predicates are at most binary, by reduction from 3-COLORABILITY [22, problemGT4], or in the case where there are only two objects and predicates are at most ternary, by reduction from 3-SAT [22,problem LO2]. The actual problem we need to solve, finding all valid instantiations of an operator, corresponds to findingall solutions to a CSP. This is even harder: even with only two objects and at most binary predicates (a case where decidingsolution existence is easy), counting the number of solutions is #P-complete [8].For this reason, a grounding algorithm that checks all static preconditions will in general do some wasteful work. Oneapproach is to enumerate all operators that satisfy the type constraints and reject those which violate a static precondi-tion. This approach is no faster than the algorithm that generates all type-correct operators without checking non-unarystatic predicates, but it generates fewer operators and hence requires less space, since infeasible ground operators can beimmediately removed.A more elaborate idea is to reject a partially instantiated operator as soon as one of its static preconditions can no longerbecome true given the current partial assignment. This is the approach taken by the IPP grounding algorithm [37], and it isclosely related to a technique called forward checking in the CSP literature [10], generalized to constraints on more than twovariables.The pruning power of the forward checking approach depends on the order in which variables of an operator are instan-tiated. To see this, let us return to the Logistics example. The only operator where we can potentially obtain a benefit overthe simpler type-checking algorithm is drive-truck. If its parameters are instantiated in the order shown in Fig. 10, theforward checking technique offers no benefit over the simpler approach: for all type-correct choices of truck t and locationsl and l, there exists a feasible value for the city c for each static precondition. (In most cases, there exists no value for cthat satisfies both in-city preconditions simultaneously, but this is not detected by the forward-checking algorithm.)(cid:17)However, if the variables are instantiated in the opposite order, many partial instantiations of land ccan be rejected immediately. The total number of partial instantiations to consider is then limited to 1 + 20 + 20 · 340 + 20 ·17 · 340 + 20 · 17 · 17 · 83 = 602161 (counting, in this sequence, instantiations of 0, 1, . . . , 4 variables). This is only 26% largerthan the number of ground operators that satisfy all static preconditions, 479740. In contrast, the simpler algorithm needsto test 1.92 · 108 instances of this operator, which is a factor of 400 larger than the number of surviving instantiations.and c or of l, l(cid:17)(cid:17)The price for the improvement offered by the forward checking algorithm is that large indexing structures are neededfor efficiently checking whether a given partial instantiation of a static predicate can be extended to a full instantiation.We believe that the space requirements of these indexing structures are to a large degree responsible for the failures ofthe IPP/FF grounding algorithm on some IPC tasks. We remark that the size of these index structures grows exponentiallywith the arity of predicates, and the domains on which we observe failures are all among the few domains in the IPC suitewhere predicate arity is not bounded by 2 (the maximal arity is 3 in Pathways and 4 in OptTelegraph and PSR).522M. Helmert / Artificial Intelligence 173 (2009) 503–5356.1.3. Checking relaxed reachabilityIn practice, for our Logistics example, the grounding algorithm that filters on static preconditions is fast enough toallow grounding in reasonable time, at least if we use the forward checking idea and instantiate variables in a favourableorder. However, significant enhancements are still possible and worthwhile, as reducing the number of ground operatorshas a beneficial influence on most planning algorithms. For example, the per-state overhead of a search algorithm tends toincrease with the number of ground operators it must test for applicability.In the Logistics example, more than 90% of the generated operators are still unreachable. The reason for this is thatthese operators have infeasible preconditions involving the non-static predicate at. In particular, a truck can never be at alocation that does not belong to its initial city, and an airplane can never be at a non-airport location. By respecting theseconstraints, we can restrict the number of ground instances to 42 · 83 · 17 for load-truck and unload-truck, to 83 ·17 · 17 for drive-truck, and to 42 · 5 · 20 for load-airplane and unload-airplane. (The number of instantiationsof fly-airplane cannot be reduced further.) This results in a total of 152911 = 1.53 · 105 ground operators, anotherimprovement by more than an order of magnitude (fourth row of Fig. 11).It is thus desirable to also rule out ground operators with infeasible preconditions on non-static predicates. However,there is a problem: checking whether a given atom can ever be satisfied in a reachable state is as hard as planning itself.Thus, in practice we need to compute an approximation of the set of reachable facts, which is at the same time conservative(includes all reachable facts) but also tight (excludes as many facts as possible). One such approximation method is the useof delete relaxations [33]. Instead of computing the set of reachable facts of a normalized PDDL task (cid:5) itself, we computethe reachable facts of a relaxed planning task R((cid:5)), which differs from (cid:5) as follows:• Negative literals in axiom bodies, operator preconditions, effect conditions and the goal condition are assumed to bealways true.• Delete effects of operators are ignored.+The set of reachable atoms of R((cid:5)) is a superset of the set of reachable atoms of (cid:5). (This follows from the fact thatthe so-called hheuristic is completeness-preserving; see Hoffmann’s article [32] for details.) In many practical cases, thissuperset relationship is quite tight. For example, in the Logistics domain, the sets of reachable atoms of R((cid:5)) and (cid:5)are identical. In other words, if we restrict the grounded representation of the Logistics task to those operators whosepreconditions are reachable in the delete relaxation, then no further pruning is possible without removing operators thatare actually reachable. (However, we remark that one may in some cases safely remove reachable operators. In our example,the grounded task contains about 1% no-op operators, namely movements of a vehicle from location l to l itself. The lastrow of Fig. 11 shows the number of remaining operators after no-op pruning. Our grounding procedure does not detect suchno-ops, but they are filtered out in a final post-processing stage when the finite-domain representation is generated.)Computing the reachable atoms of a relaxed planning task is much easier than for general planning tasks. In particular,if a relaxed planning task is already grounded, its reachable atoms can be computed in linear time with the marking algo-rithm for propositional Horn logic [12]. Indeed, the grounding algorithm of FF proceeds by first applying the IPP groundingalgorithm (i.e., the forward checking algorithm described above), and then computing the reachable atoms and operators ofthe delete relaxation to further reduce the grounded representation. While this leads to a tight representation, the drawbackof the approach is that it has the same time and space requirements as the IPP algorithm, as it generates the IPP output asan intermediate result. As discussed in the introduction to this section, there are a number of planning tasks for which thisapproach fails.For this reason, we have designed a new grounding algorithm which generates the set of facts and operators (andaxioms) that are reachable in the relaxed task directly, without ever considering any facts that are not relaxed reachable.We now turn to a description of this algorithm.6.2. Overview of Datalog explorationThe basic idea of our new grounding algorithm, which we call Datalog exploration, is to encode the atom reachabilityproblem for relaxed planning tasks as a set of logical facts and rules, i.e., as a logic program. This allows us to efficientlycompute the set of reachable atoms by computing the canonical model of that logic program, which consists of the set ofground atoms that it logically implies. The algorithm consists of three steps: generating the logic program, translating itinto a normal form that supports efficient evaluation, and computing its canonical model. Before going into detail for eachof these steps, let us formally define what we mean by a logic program. As in the other parts of the paper, we assume thatour logical vocabulary does not contain function symbols of non-zero arity.Definition 13 (Datalog programs). A Datalog rule (also called positive Horn clause) is a first-order formula of the formϕ1 ∧ · · · ∧ ϕk → ψ (k (cid:2) 0), where ϕi and ψ are (usually not ground) atoms. It can be written as ψ ← ϕ1, . . . , ϕk. Usingthis notation, ψ is called the head and ϕ1, . . . , ϕk is called the body of the rule. Datalog rules are usually assumed to beuniversally quantified: for a given Datalog rule χ with free(χ ) = {v 1, . . . , vk}, we define χ∀ = (∀v 1 . . . vk : χ ). Similarly, fora set of Datalog rules R, we define R∀ = {χ∀ | χ ∈ R}.M. Helmert / Artificial Intelligence 173 (2009) 503–535523A Datalog program is a pair (cid:3)F , R(cid:4), where F is a set of ground atoms called the set of facts and R is a set of Datalogrules called the set of rules.The canonical model of a Datalog program (cid:3)F , R(cid:4) is the set of all ground atoms ϕ with F ∪ R∀ |(cid:26) ϕ.Next, we show how to translate the relaxed reachability problem into a Datalog program. Afterwards, we demonstratehow to translate this logic program into a particularly simple form and how to compute the canonical model of the simpli-fied logic program efficiently.6.3. Generating the logic programReachability in a relaxed normalized PDDL task is straight-forward to represent as a logic program. A ground atom isreachable in the relaxed task iff it is true in the initial state or there exists some reachable axiom or operator of the relaxedtask that can make it true. Therefore, the set of facts of the logic program is formed by the atoms in the initial state ofthe planning task, and the set of rules is derived from the axiom and operator definitions. Additionally, we introduce a rulefor the goal of the planning task to detect whether the relaxed task is solvable; if not, the original task is also unsolvable,which we can report immediately to stop the translation process early.Recall from Section 4 that at this stage, all conditions occurring in the PDDL task are conjunctions of literals. For suchconjunctions ϕ, we denote the conjunction of all positive literals in ϕ by ϕ+. In the context of logic programs, we follow thePROLOG convention of using uppercase letters for first-order variables and lower-case letters for constants and predicates.The exploration rules for a normalized PDDL task are generated as follows:• Axioms: For schematic axioms a = (ϕ ← ψ) with ψ + = ψthe axiom applicability rulea-applicable( X1, . . . , Xk) ← ψ++1 , . . . , ψmand the axiom effect ruleϕ ← a-applicable( X1, . . . , Xk)+1∧ · · · ∧ ψ +m and free(ϕ) ∪ free(ψ) = { X1, . . . , Xk}, we generate• Operators: For schematic operators o with parameters { X1, . . . , Xk} and precondition ϕ with ϕ+ = ϕ+∧ · · · ∧ ϕ+m , we1generate the operator applicability ruleo-applicable( X1, . . . , Xk) ← ϕ+1 , . . . , ϕ+mand for each add effect e of o adding the atom ψ with bound variables {Y 1, . . . , Yl} and effect condition χ withχ + = χ +n , we generate the effect trigger rule∧ · · · ∧ χ +1e-triggered( X1, . . . , Xk, Y 1, . . . , Yl)o-applicable( X1, . . . , Xk), χ +1 , . . . , χ +nand effect ruleψ ← e-triggered( X1, . . . , Xk, Y 1, . . . , Yl)• Goal: For the goal ϕ with ϕ+ = ϕ+goal-reachable() ← ϕ+11 , . . . , ϕ+m∧ · · · ∧ ϕ+m , we generate the goal ruleThe correctness of these rules should be evident, as they are just literal translations of the PDDL semantics for the re-laxed planning task. The reader might wonder why we sometimes introduce new predicates that do not seem necessaryfor computing the set of reachable facts. For example, axiom applicability rules and axiom effect rules could be combinedinto a single rule without introducing the auxiliary predicate a-applicable. The purpose of these auxiliary predicates isto track which axioms and operators must be instantiated when grounding the PDDL task. For example, in the Logisticsdomain, we will not generate a ground operator fly-airplane(plane1, loc1, loc3) if loc3 is not an airport location,since in this case the canonical model of the logic program does not include the atom fly-airplane-applicable(plane1, loc1, loc3). The operator applicability predicates serve the additional purpose of factoring out common subex-pressions. Without them, all operator preconditions would need to be repeated in each effect trigger rule (or effect rule, ifeffect trigger rules were similarly eliminated).6.4. Translating the logic program to normal formHaving generated a logic program representation, we need to find a way to efficiently generate the canonical model.Returning to the Logistics example, one of the generated rules is524M. Helmert / Artificial Intelligence 173 (2009) 503–535drive-truck-applicable(T , L, L(cid:17), C) ← truck(T ), location(L),location(L(cid:17)), city(C), in-city(L, C), in-city(L(cid:17), C), at(T , L).Given a set of reachable facts, we need to determine the possible instantiations of the rule for which all conditions inthe body are reachable. We must do this without systematically trying out all possible instantiations – otherwise, nothingis gained over the naive instantiation method. Moreover, we prefer to evaluate the rule incrementally: whenever a newinstantiation of a predicate in the body is derived (say, the fact at(truck1, loc5)), we want to derive new consequencesof the rule without re-generating previously derived facts. In order to achieve these objectives, we consider a particularclass of Datalog programs.Definition 14 (Datalog programs in normal form). A first-order logic atom is called variable-unique if it does not contain twooccurrences of the same variable. (For example, an atom like P ( X, Y , X) is not variable-unique because variable X occurstwice. Repetition of constants is allowed.) A Datalog rule is called variable-unique if its head and all atoms in its body arevariable-unique.A Datalog rule is called a projection rule if it is variable-unique and of the form ϕ ← ϕ1 with free(ϕ) ⊆ free(ϕ1). Inother words, projection rules are unary rules where all variables in the head occur in the body.A Datalog rule is called a join rule if it is variable-unique and of the form ϕ ← ϕ1, ϕ2 with free(ϕ1) ∪ free(ϕ2) =free(ϕ) ∪ (free(ϕ1) ∩ free(ϕ2)). In other words, join rules are binary rules where all variables occurring in the head occur inthe body, and all variables occurring in the body but not in the head occur in both atoms of the body.A Datalog program is in normal form if all rules are projection or join rules.The names of the rule types in Definition 14 are reminiscent of the related database-theoretic operations from relationalalgebra [45]: projection rules correspond to the projection operator π and join rules correspond to the natural join operator(cid:3) (or strictly speaking, a combination of natural join and projection). The advantage of Datalog programs in normal form isthat each rule can be incrementally evaluated very efficiently. (We will describe an algorithm for this later on.) Note thatthe same is not true for general rules – as discussed in Section 6.1.2, deciding whether a general Datalog rule has any validinstantiation is equivalent to CSP solvability.We now describe how to convert Datalog programs to normal form. Firstly, we eliminate duplicate variable occurrencesas follows: if any rule contains atoms with duplicate occurrences of the same variable X , we change one occurrence of X in(cid:17)) to the rule body. We repeat until no further suchany such atom into a new variable Xtransformations are possible. If any such transformation was necessary, we add the fact equals(o, o) to the logic programfor each object o of the planning task.and add the atom equals( X, X(cid:17)Secondly, for any variable X that occurs in the head but not in the body of a rule, we add the atom object( X) to therule body. (Remember from Section 4.1 that object(o) is true for any object o of the planning task.)Thirdly, all rules with an empty body are converted into facts. Their heads must be ground atoms because all variablesoccurring in the head must occur in the (in this case, empty) body after the previous transformation.After these transformations, all remaining unary rules are projection rules; we still need to normalize rules with two ormore atoms in the body. This is essentially a conjunctive query optimization problem, commonly studied in database theory[46]. As a first step towards normalizing such a rule, we determine if any atom in its body contains variables that occurin no other atom of the rule, neither in the body nor in the head. If this is the case, such variables are projected away,following the general principle for query optimization that projections should be performed as early as possible. In detail,assume we are given the rule ϕ ← ϕ1, . . . , ϕm, where free(ϕi) = { X1, . . . , Xk} contains variables not present in any of theother atoms, say { X j+1, . . . , Xk}. Then we introduce a new predicate p and replace the original rule by the rules ϕ ←ϕ1, . . . , ϕi−1, p( X1, . . . , X j), ϕi+1, . . . , ϕm and p( X1, . . . , X j) ← ϕi .After this transformation, all binary rules are valid join rules, while rules with m > 2 atoms correspond to m-ary joinswhich still need to be decomposed into binary joins. How exactly this decomposition is performed can in general greatlyaffect performance. To see this, consider the ruledrive-truck-applicable(t, l, l(cid:17), c) ← in-city(l, c), in-city(l(cid:17), c), at(t, l).from Logistics. (For brevity, we omit some additional conditions from the body of the actual rule, which are not relevant tothe discussion.) One possible decomposition into binary join rules results in the following two rules:drive-truck-applicable(t, l, l(cid:17), c) ← temp1(t, l, c), in-city(l(cid:17), c).temp1(t, l, c) ← in-city(l, c), at(t, l).Another possible decomposition results in these rules:temp2(t, l, ldrive-truck-applicable(t, l, l(cid:17)(cid:17)(cid:17), c) ← in-city(l, c) ← temp2(t, l, l, c), at(t, l).(cid:17), c), in-city(l, c).M. Helmert / Artificial Intelligence 173 (2009) 503–535525Fig. 12. The greedy join algorithm for decomposing a rule into join rules.Of the two possibilities, the first is vastly preferable: the number of reachable instances of temp1 is only as largeas the number of reachable instances of at, because for any reachable fact at(t, l), exactly one city c will satisfyin-city(l, c). The number of reachable instances of temp2, on the other hand, is the product of the number of reach-able instances of at and the total number of locations, which is much larger than the number of reachable instances ofdrive-truck-applicable.Finding a good decomposition is thus key to good performance. Unfortunately, finding the best possible ordering is gen-erally not easy. Indeed, the closely related problem of join ordering is one of the central problems in query optimization fordatabases, and typical query optimizers address it by exhaustively considering an exponentially large space of possibilities[46, Chap. 11].The fact sets we have to deal with in planning tasks are not as large as the relations considered in database systems,so our normalization procedure does not quite go to such lengths. Instead of an exhaustive search that finds a globally op-timal decomposition, it applies a sequence of greedy (locally optimal, according to some simple heuristics) transformationswithout backtracking over any choices it makes. The algorithm, called greedy-join, is shown in Fig. 12. To decompose a rule,it iteratively picks two atoms ϕ and ϕ(cid:17)from the rule body and joins them, introducing a new predicate p for the result ofthe join and replacing the two atoms in the rule body by an instance of that new predicate. This process is repeated untilthe body of the rule no longer contains more than two atoms. In each step of the algorithm, the two atoms ϕ and ϕ(cid:17)tojoin are picked in order to minimize the (estimated) effort for computing their join, according to the following three rules(without loss of generality, ϕ has at least as many variables as ϕ(cid:17)):(1) Prefer joins where the arity of p minus the number of variables of ϕ is smallest.(2) If ties need to be broken, prefer joins where the arity of p minus the number of variables of ϕ(cid:17)(3) If ties still need to be broken, prefer joins where the arity of p is lowest.is smallest.The net effect of these rules is that the algorithm prefers joining atoms with a large number of common variables. In theLogistics example above, this heuristic steers clear of the second decomposition, where the sets of variables of the joinedatoms are disjoint.6.5. Computing the canonical modelOnce the Datalog program has been converted to normal form, we are ready to compute its canonical model. We use anincremental approach, shown in Fig. 13.526M. Helmert / Artificial Intelligence 173 (2009) 503–535Fig. 13. Computing the canonical model of a Datalog program (cid:3)F, R(cid:4) in normal form.The algorithm maintains two variables to keep track of reachable facts. Variable canonical-model records the set of allatoms that the algorithm has determined to be reachable so far. It grows monotonically throughout execution of the algo-rithm and contains the result upon termination. Variable queue keeps track of all atoms which are currently open, i.e., havebeen determined reachable, but have not yet been considered for matching conditions in the rule bodies. We say that anatom is closed if it is contained in canonical-model (has been reached) and is not open.In addition to canonical-model and queue, the algorithm uses the following data structures:• Rule matcher: A rule matcher is an indexing structure that supports efficient unification queries on the bodies of Datalogprograms. When given a ground atom a, the rule matcher determines all projection rules ϕ ← ϕ1 and join rules ϕ ←ϕ1, ϕ2 such that ϕ1 or ϕ2 unifies with a, i.e., such that it is possible to substitute objects for variables in ϕ1 or ϕ2 insuch a way that a is obtained. The rule matcher reports the matched rules and whether ϕ1 or ϕ2 was matched (if bothunify with a, two matches are generated).Note that matching ground atoms to the rules they can trigger is simple if the rules do not contain constants in thebody. Unfortunately, some of the IPC benchmarks contain a huge number of operator schemas involving constants (mostimportantly, the STRIPS formulation of the Airport domain), and an efficient indexing structure is important for those.Rule matchers are implemented as decision-tree like data structures very similar to successor generators [29].• Join rule indices: Each join rule r = ϕ ← ϕ1, ϕ2 maintains two hash tables r.index1 and r.index2 that map instantiationsof the common variables of ϕ1 and ϕ2 to instantiations of the variables of ϕ1 and ϕ2, respectively.At any time (except during updates) and for any assignment key to the common variables of ϕ1 and ϕ2, r.index1[key]contains those variable mappings α ⊇ key for the variables of ϕ1 for which α(ϕ1) belongs to the closed set. Similarly,r.index2[key] contains those variable mappings β ⊇ key for the variables of ϕ2 for which β(ϕ2) belongs to the closedset. We call this property the index invariant.The index information can be exploited for quickly determining all possible instantiations of ϕ2 that match a giveninstantiation of ϕ1, or vice versa, as is done in the algorithm. Note that the variable assignment α ∪ β considered in thealgorithm is indeed a well-defined function, since α and β agree on all variables for which they are both defined.The algorithm clearly terminates, as each loop iteration produces a new closed atom (by removing an open atom fromqueue), which can only happen a finite number of times. To motivate its correctness, we state an important invariant of thewhile loop: all atoms that can be derived in one step from the rules R and the closed atoms are contained in the canonical-model set.M. Helmert / Artificial Intelligence 173 (2009) 503–535527This property is true when the while loop is first entered because there are no closed atoms at this stage, and no atomscan be derived from R and the empty set of atoms. It is not hard to prove that the property is also preserved by a singleiteration of the while loop: each such iteration causes the single new atom current-fact to become closed, so we only need toconsider one-step derivations that make use of this atom, and possibly other atoms that are already closed. The processingof current-fact then causes precisely those atoms which can be generated by such derivations to be enqueued, adding themto canonical-model if they are not already present. Thus, the property is indeed a loop invariant. (A more formal proof wouldneed to establish this invariant simultaneously with the index invariant.)The loop invariant implies that upon termination of the algorithm, when all atoms in the canonical-model set are closed,the set is closed under application of R. Because it also contains all facts from F and only contains facts that can be derivedfrom F , it thus contains exactly the canonical model of (cid:3)F , R(cid:4).6.6. Axiom and operator instantiationWith the help of the canonical model, instantiating axioms and operators is very straight-forward. To compute thegrounded representation, we scan through the set of ground atoms in the canonical model in the order in which they weregenerated, creating axiom and operator instances as follows:• When encountering atoms of the form a-applicable(x1, . . . , xk) where a is a schematic axiom, we generate a groundinstance of a with the parameters substituted with x1, . . . , xk.• When encountering atoms of the form o-applicable(x1, . . . , xk) where o is a schematic operator, we generate aground instance of o without effects. Like in the case of axioms, the parameters of the operator are substituted withx1, . . . , xk, and the precondition is instantiated accordingly.• When encountering atoms of the form e-triggered(x1, . . . , xk, y1, . . . , yl) where e is an effect of some operator o, welook up the set of already generated ground operators to find the operator o(x1, . . . , xk). This operator must have beengenerated previously because an e-triggered atom can only be derived after the corresponding o-applicableatom. Having found the ground operator, we attach to it the effect obtained by instantiating the variables in e withy1, . . . , yl.After a single pass through the canonical model, this procedure has produced a grounded representation of the normal-ized PDDL task.6.7. PerformanceWe conclude our discussion of the Datalog exploration algorithm with some remarks on performance. In practice, theonly performance-critical part for grounding is algorithm compute-canonical-model: all the processing that happens before isgenerally negligible (linear-time for a fixed domain), and the processing that happens afterwards, while not always negligiblein absolute terms, only requires linear time in the combined size of its input and output, which is asymptotically optimal.How costly, then, is computing the canonical model? To simplify the analysis, we only consider the case where theplanning domain is fixed. In that case, the rules of the Datalog program are fixed, and only the facts differ from instanceto instance. Under this assumption, the runtime of compute-canonical-model is linear in the number of attempts to enqueuea fact (see Fig. 13). In the best case, this number is identical to the number of facts in the canonical model for the initialDatalog program (before normalization), so that the overall grounding algorithm runs in linear time in its combined inputand output size and is hence asymptotically optimal. However, this is not always the case, as there are two possible sourcesof inefficiency:• Duplicates: There may be several attempts to enqueue the same fact (e.g., if projection rules project different facts to thesame fact, or because the fact is generated by different rules). For a given run of the algorithm, we define the duplicateratio as the total number of attempts to enqueue a fact, divided by the size of the canonical model upon completion.• Irrelevant facts: Facts that correspond to temporary predicates introduced during normalization of the Datalog programare irrelevant for the final instantiation stage. For a given run of the algorithm, we define the irrelevance ratio as thesize of the canonical model, divided by the number of facts in the canonical model that are relevant (i.e., do not referto predicates introduced during normalization).The overhead of calculate-canonical-model, compared to an idealized algorithm that could generate the set of relevant factsin linear time in its size, is the product of the duplicate ratio and irrelevance ratio. In the perfect case, both numbers wouldbe equal to 1. However, as we saw in Section 6.4 for the different decompositions of the drive-truck-applicable ruleinto binary joins, the irrelevance ratio in particular can be considerably larger, especially if the greedy join algorithm makespoor choices. Indeed, the existence of a grounding algorithm with only polynomial overhead in the general case, where theDatalog rules are not fixed, would prove P = NP.It is thus natural to ask how large these ratios become in practice. To answer that question, we applied the grounding al-gorithm to all tasks of the IPC1–5 benchmark suite, measuring the duplicate ratio and irrelevance ratio for each. The results528M. Helmert / Artificial Intelligence 173 (2009) 503–535Fig. 14. Duplicate ratios (DR) and irrelevance ratios (IR) for the IPC benchmarks. For each domain, we report the range of ratios observed across all instances.are summarized in Fig. 14, which shows the minimal and maximal duplicate and irrelevance ratios that were observed ineach domain. The results show that the duplicate ratios are generally benign, always staying below a value of 4. The irrele-vance ratios are also usually low, consistently staying below a value of 5 for all but two domains: Miconic-Full and Rovers.For Miconic-Full, the irrelevance ratios can become as large as 6.48; however, the ratios are actually inversely correlatedwith problem size, becoming lower as the problem sizes increase. Only the 20% smallest instances have irrelevance ratiosover 3, and all instances of above average size have irrelevance ratios below 2. Thus, there are no serious scalability issuesin this domain.The only domain which produces somewhat worrying results is Rovers, where the irrelevance ratios become as large as27.96, significantly more than for all other domains. Moreover, the ratios tend to increase with scaling problem size. Closerinspection reveals that an unfortunate choice by the greedy join algorithm is to blame for this sub-par performance. Innormalizing the rule for the predicate communicate-rock-data-applicable(r, l, p, x, y), which has 11 conditions inthe body, the following four conditions remain after 7 join steps:temp1(r, p) ≡ waypoint(p) ∧ have-rock-analysis(r, p)temp2(r, x) ≡ rover(r) ∧ available(r) ∧ waypoint(x) ∧ at(r, x)temp3(l, y) ≡ lander(l) ∧ chan-free(l) ∧ waypoint( y) ∧ at-lander(l, y)visible(x, y)At this point, there are three possible joins that the greedy join algorithm considers optimal: joining temp1 with temp2,joining temp2 with visible, and joining temp3 with visible. Of these three possibilities, our implementation arbi-trarily picks the second, which happens to be the worst possible choice because there is a very large number of reachableinstantiations for temp2(r, x) ∧ visible(x, y), most of which cannot be extended to feasible assignments for all conditions.The reason for this is that there is only one value for y for which temp3(l, y) is reachable (there is only one lander and itis not mobile, so that at-lander has only one reachable instance).To determine the impact of this unfortunate tie breaking decision, we have instrumented the greedy join algorithm tooverride its default choice and instead join temp3 with visible at this choice point, and similarly for an equivalentchoice point for the isomorphic communicate-soil-data-applicable predicate. With this modification, the worst-case irrelevance ratio in the Rovers domain reduces from 27.96 to 4.83. By additionally overriding the subsequent joindecision to prevent the algorithm from joining temp1 with temp2, the worst-case irrelevance ratio can be further reducedto 1.97. In terms of overall runtime for the grounding algorithm, the reduced irrelevance ratio translates to an order-of-magnitude improvement.This small case study illustrates two things: on the one hand, we clearly see that join ordering choices can have asignificant impact on the performance of the grounding algorithm and thus do require attention. On the other hand, theessentially linear scaling behaviour for all domains except Rovers indicates that the heuristic decisions of the greedy joinalgorithm are usually quite solid.M. Helmert / Artificial Intelligence 173 (2009) 503–535529Fig. 15. Computing mutex groups from the set of monotonicity invariants invariants, the set of reachable atoms P f and the initial state s0.Fig. 16. Mutex groups for a Blocksworld task with four blocks. Some atoms, such as on(a, a), are reachable in the relaxed task although they are nevertrue in the “real” task.7. Generating the finite-domain representationTogether with the invariants synthesized earlier, the grounded PDDL task generated in the previous stage provides all theinformation we need for producing the finite-domain representation in the final translation stage. Recall from Definition 4that an FDR task is given by a set of finite-domain variables V , an initial state s0 and goal s(cid:6), axioms A and operators O.We start by defining suitable variables and variable domains; everything else then more or less falls into place.7.1. Variable selectionEach variable of the generated FDR task corresponds to one or more (reachable) ground atoms of the STRIPS task. Westart by extracting the set P of all such atoms from the canonical model and partitioning them into atoms P f whichare instances of modifiable fluent predicates or derived predicates and atoms Pc which are instances of constant predicates(cf. Section 5.1).We want to represent as many ground atoms by a single state variable as possible. To achieve this, we first determinethe set of mutex groups induced by the computed invariants. Mutex groups are computed in a straight-forward manner byinstantiating the monotonicity invariants in all possible ways, checking for each instance if it has weight 1 in the initialstate, and if so, which atoms from P fit covers. The algorithm is shown in Fig. 15. The actual implementation uses anindexing structure to efficiently determine the set of reachable atoms covered by a given invariant instance.Normally, not every mutex group will correspond to an FDR state variable, since the same atom can be part of severalmutex groups, but of course only needs to be encoded once. As an example of this phenomenon, consider Fig. 16, whichshows the mutex groups of a Blocksworld task with four blocks. If, for example, we decide to encode mutex groups (1)–(4) with four finite-domain state variables, then we only need to encode one atom from each of the other groups, sinceall on and holding atoms are already represented. Therefore, the translator would first generate four state variables withdomains consisting of seven values each, namely holding(x), clear(x), on(a, x), on(b, x), on(c, x), on(d, x) and theseventh option “none of the other six is true”. (Of these seven values, two – block x being on top of itself and none ofthe six atoms being true – are actually impossible.) Afterwards, it would encode the truth values of the remaining atomsontable(x) and handempty() with binary state variables.In this case, there was at least one atom in each mutex group that was unique to this particular group, so that theresulting encoding is not much better than an encoding which simply takes all mutex groups and introduces a state variablefor each. However, in other cases, one group can be completely covered by others; examples of this can be found in theAirport domain. In this case we prefer covering the set of reachable atoms with as few state variables as possible.Unfortunately, set cover problems of this kind are NP-complete [22, problem SP5] and indeed not even approximablewith a constant-factor approximation ratio [1], so we limit our covering efforts to the greedy algorithm shown in Fig. 17,which is among the best approximation algorithms known for this problem, achieving an O (log n)-approximation [1]. It-eratively, we pick a mutex group P of maximal cardinality and introduce a new FDR state variable with domain P ∪ {⊥},where ⊥ stands for “none of the elements of P is true”. We then remove all covered elements from all other mutex groups,removing groups that no longer contain more than one element. This process is repeated until all mutex groups have beenremoved. At this stage, the remaining uncovered atoms p are represented by binary variables with domain {p, ⊥}.530M. Helmert / Artificial Intelligence 173 (2009) 503–535Fig. 17. Greedy algorithm for computing the FDR variables and variable domains.After execution of the algorithm, for each reachable atom p ∈ P fthere is exactly one FDR variable whose domainincludes p. The translation will ensure that this variable, which we denote as var(p) in the following, assumes the valuep in an FDR state iff p is true in the corresponding state of the PDDL task. With this information, we can now go aboutconverting the rest of the PDDL task to the finite-domain representation.7.2. Converting the initial stateWe start by converting the initial state, which is the easiest step. For each atom p ∈ P f that is in the initial state, weset the initial value of var(p) to p. FDR variables for which there is no initial state atom p with var(p) = p are initializedto ⊥. Note that different initial state atoms p, pcould only berepresented by the same FDR variable if they were mutually exclusive, which implies their not being in the initial statetogether. Therefore, the converted initial state is well-defined.(cid:17) ∈ P f must satisfy var(p) (cid:18)= var(p(cid:17)), because p and p(cid:17)7.3. Converting operator effectsTranslating the state changes incurred by operator effects requires some care. For add effects setting an atom p to true,conversion is easy: such an effect is always translated to an FDR effect setting var(p) to p, because we know p to be trueafter operator application if the effect fires.However, for delete effects setting an atom p to false, the correct translation is not as clear. We cannot simply set var(p)to ⊥ (“none of the variables represented by var(p) is true”) unconditionally, because this is not always correct: it could bethe case that another effect of the same operator triggers simultaneously and adds another atom represented by the samevariable, or that p was not true when the operator was applied, but some other atom represented by var(p) was.Therefore, the correct behaviour is to set var(p) to ⊥ only if we know that p was previously true and that no effectadding an atom represented by var(p) triggers simultaneously. In other situations, the delete effect should not cause achange in the value of var(p). If the other effects of the operator that add atoms represented by var(p) have effect conditionsχ1, . . . , χk, then this is achieved by adding p ∧ ¬χ1 ∧ · · · ∧ ¬χk to the effect condition of the translated effect.If some of the formulae χi are proper conjunctions (i.e., neither constant true nor singleton literals), this results in aneffect condition which is not a conjunction of literals. In this case, we introduce a new derived variable v i that evaluates totrue whenever ¬χi is true, and use v i in the effect condition instead.All things considered, this conversion of delete effects looks very complicated, and indeed in most cases simpler transla-tions are possible. For this purpose, we detect two common special cases, with which we deal differently:• If we see that whenever the delete effect triggers, some add effect affecting the same variable must trigger as well,because it has the same or a more general effect condition, then we do not need to represent the delete effect in thefinite-domain representation at all. The add effect will take care of the value change of its affected variable.• On the other hand, if we see that no add effect affecting the same variable can trigger at the same time, because nosuch effect exists or each of their effect conditions is inconsistent with the condition of the delete effect, then we canconvert the delete effect to an effect setting var(p) to ⊥. If p is not already part of the operator precondition or effectcondition, we must add it to the effect condition to make sure that var(p) is only cleared if it was previously set to p.In most cases, translating delete effects is straight-forward because the two simpler cases are by far more common thanthe general case. In particular, for unconditional effects, one of the special cases always applies.7.4. Converting conditionsThe third major translation step is the conversion of conditions of the grounded PDDL task. Conditions occur in the goalspecification, in operator preconditions, in conditional effects and in axiom bodies.M. Helmert / Artificial Intelligence 173 (2009) 503–535531To translate a grounded condition, we first check if it contains any atoms not in P f . These have constant truth values,so that the condition can be simplified accordingly. If this leads to a constant false condition, we react accordingly (for thegoal, we report that the task is unsolvable; for axiom bodies, operator preconditions or effect conditions, we remove theaxiom, operator or effect).If the condition is not trivially false, we translate each of its positive literals p into the pairing var(p) = p. Translatingnegative literals ¬p is slightly more tricky. Recall the Blocksworld example discussed earlier, where we generated the FDRstate variable v with Dv = {holding(a), clear(a), on(a, a), on(b, a), on(c, a), on(d, a), ⊥}, and consider a conditionincluding the atom ¬on(c, a). If the condition also contains some positive literal represented by variable v, for examplethe atom clear(a), then we do not need to encode ¬on(c, a) at all, because it is implied by the condition v = clear(a).However, otherwise there is no simple way to represent ¬on(c, a) as an FDR condition. We would need to write somethinglike v (cid:18)= on(c, a), but conditions of this form are not supported by the representation.Therefore, in situations like this, similar to what we did when translating non-conjunctive effect conditions that mayarise for certain delete effects, we introduce a new derived variable not-p with domain {(cid:22), ⊥} and generate an axiom(v = d) → (not-p := (cid:22)) for each value d ∈ Dv \ {p}. The pairing not-p = (cid:22) can then serve as a translation of the literal¬p.If we wanted to avoid introducing new axioms, we could further normalize the PDDL task so that no negative literalsoccur in conditions. There are well-known compilation methods to achieve such a normal form [23]. However, this transfor-mation method may introduce many more state variables than necessary, which runs counter to our objective of a concisefinite-domain representation. (If it can be avoided, there is little point in having two finite-domain variables in the rep-resentation with the property that the value of each is a function of the value of the other.) As a compromise, we mightconsider to only use such a compilation method for propositions that appear in negative literals for which our translationmethod would otherwise introduce a new axiom. In practice (on the IPC domains), negative conditions are not commonlyused, so the choice of mechanism for dealing with them makes little difference.7.5. Computing axiom layersAs a final translation step, we must compute the axiom layers for the finite-domain representation in such a way thatthe semantics for stratified logic programs is matched (cf. Definitions 2 and 5).This is done as follows: whenever the body of an axiom with affected variable v includes the condition v(cid:17)(cid:17) = ⊥ for somemust be computed before the value of v, so we introduce an ordering constraint(cid:17) = d for derived variable vand d (cid:18)= ⊥, we introduce an(cid:17)(cid:17)derived variable v(cid:17) ≺ v. Similarly, if some axiom affecting v includes the condition vvordering constraint v, then the value of v(cid:17) (cid:10) v.Axiom layers can be derived from these ordering constraints in two stages. In the first stage, we compute the stronglyconnected components of the graph induced by the (cid:10) relation. All axioms that affect variables in the same strongly con-nected component belong to the same axiom layer.To compute the ordering of axiom layers, we topologically sort the graph whose vertices are the axiom layers and which(cid:17) ≺ v. The ith axiomaffects vhas an arc from layer Llayer is then the one which appears at the ith position in the computed topological order. If the axioms of the originalPDDL task are stratifiable, such a topological sort is always possible., some axiom in L affects v, and vto layer L iff some axiom in L(cid:17)(cid:17)(cid:17)7.6. Post-processingWith axioms partitioned into layers, the translation is complete. Before generating output, we apply a few post-processing techniques to simplify the generated task where possible.Most importantly, if there are two axioms with the same head, a = (cond → v := d) and a(cid:17)cond ⊂ conddomains where axioms encode transitive closures, we say that a dominates a, then a is triggered whenever ais triggered, so a(cid:17)(cid:17)(cid:17)(cid:17) → v := d) such thatis unnecessary. In such a case, which occurs frequently in(cid:17) = (condand remove afrom the representation.(cid:17)8. DiscussionHaving finished our presentation of the translation algorithm, the question arises how one should evaluate it. There aretwo important criteria to consider:• Performance: How quickly is the representation computed?• Quality: How good is the generated finite-domain representation?8.1. Notes on performanceWe will keep the discussion of performance short: on a state-of-the-art computer, the translation algorithm is sufficientlyefficient to generate finite-domain representations for all IPC1-5 benchmark tasks in reasonable time. In particular, in thedifferent planning systems that use the translator, including Helmert and Richter’s Fast Downward [29], van den Briel et532M. Helmert / Artificial Intelligence 173 (2009) 503–535Fig. 18. Absolute runtime on the IPC1-5 tasks.al.’s Integer Programming planner [49] and Helmert et al.’s flexible abstraction heuristics system [31], the conversion to FDRis never the main bottleneck of the overall planning algorithm – translation time is negligible compared to search time inthe vast majority of cases. (Some exceptions to this exist in “structurally simple” domains like Satellite and Logistics.)A summary of translation time for the IPC1-5 benchmark suite is shown in Fig. 18. All experiments were conducted ona machine with a 2.66 GHz Intel Xeon CPU under a 2 GB memory limit. The algorithm was implemented in the Pythonlanguage, and we estimate that a speed improvement by a factor of 10–100 is easily achievable with a C++ implementation.Even so, 65.4% of the instances are translated in less than one second, and 93.4% in less than ten seconds. Fewer than2% require more than one minute, and fewer than 1% require more than two minutes. The instances that take longest totranslate are all from the PSR-Large and Satellite domains and are very large: for example, the largest Satellite instancehas 989250 operators, and the largest PSR-Large instance has 544209 state variables (however, a backchaining analysisreveals that only 60467 of these are relevant to the goal).In addition to overall runtime, it is also interesting to identify which of the different stages of the algorithm form themain bottlenecks, and whether this varies from domain to domain. To address this question, we produced detailed runtimeresults for all tasks that required an overall runtime beyond 1 s in the first experiment. For each domain, we report theminimal and maximal percentage of overall runtime spent on each stage of the algorithm (Fig. 19). For example, the entry incolumn “FDR” for the Logistics domain indicates that on those Logistics tasks which required an overall runtime above onesecond (21 of the 63 instances), between 21% and 30% of the overall runtime was spent on the final stage of the algorithm,generating the finite-domain representation.The results show that normalization and invariant synthesis are not time critical. In absolute numbers, normalizationnever requires more than 0.74 s, and invariant synthesis never requires more than 0.38 s. In a typical domain, about 70% ofthe time is required for grounding, and about 25% for FDR generation. There are four domains where grounding can requiremore than 85% of the runtime (Miconic-Full, PSR-Large, PSR-Middle, Rovers). Relating this observation to our earlier anal-ysis of the Datalog grounding algorithm (Fig. 14), these are precisely the four domains with the highest average irrelevanceratio. For completeness, we mention that within the grounding stage, the vast majority of time is spent computing thecanonical model (Section 6.5) and performing the final operator and axiom instantiation (Section 6.6). The initial steps ofthe algorithm, generating (Section 6.3) and normalizing (Section 6.4) the logic program together require at most 1.88 s, andthere is only one task (PSR-Small #25) for which they require more than 1 s.8.2. Notes on qualitySo what about the quality of the representation? In almost all planning domains we considered (including all IPC1-5domains), the algorithm generates finite-domain representations that are very close or identical to one we would havedesigned manually. However, while this is encouraging, it is not how the quality of the representation should be measured.Ultimately, whether or not a finite-domain representation is useful depends on how well it serves its intended purpose.In Section 1.3, we discussed a number of possible uses for finite-domain representations, including SAT planning, sym-bolic state space exploration with BDDs, heuristic planning with pattern databases and other homomorphism abstractions,planning using integer programming compilations, and heuristic planning based on causal graph decompositions.For SAT planning, the MaxPlan system [7], joint winner of the optimal propositional track of IPC5, has clearly establishedthe usefulness of finite-domain representations. Although the exact details of the FDR translation method of MaxPlan havenot been published, it is directly inspired by the techniques presented in this article, and follows a very similar overallstrategy (personal communications). As Chen et al. report, finite-domain representations play a critical role in plannerperformance [7] – in the binary state variable case, the londex constraints that are the key innovation of MaxPlan reduceM. Helmert / Artificial Intelligence 173 (2009) 503–535533Fig. 19. Distribution of runtimes across the different stages of the translation algorithm, by domain. Only tasks with overall runtime above 1 s are takeninto account. The second column shows the number of such tasks in each domain, together with the number of total tasks in that domain. The followingcolumns show, in order, the percentage of time that was spent on input/output (including parsing), normalization (Section 4), invariant synthesis (Section 5),grounding (Section 6) and FDR generation (Section 7). Ranges denote the minimum and maximum percentage for all considered tasks in the domain.to the usual mutex constraints used by all state-of-the-art SAT planners, so londex constraints require non-trivial FDRencodings.For planning with BDDs, finite-domain representations have always been critical for performance, to the point wherecompilations that use a direct propositional encoding lead to prohibitively bad performance. Indeed, this is the reason whyEdelkamp and Helmert’s algorithm for devising concise finite-domain representations [15] was originally developed. Weremark that for those domains that their algorithm can handle – STRIPS domains without constants in operator definitions– the encodings generated by the algorithm presented here are generally equivalent to those found by the Edelkamp andHelmert algorithm.For planning with homomorphism abstractions, the situation is similar. For example, the flexible abstraction heuristicsof Helmert et al. [31] critically rely on the finite-domain representation generated by the method presented here, degradingby several orders of magnitude and solving significantly fewer tasks if a direct propositional encoding is used instead.The same performance degradation can be observed in heuristic planning based on causal graph decompositions [29] –without the concise FDR translation, the causal graph heuristic is not competitive with other approaches.Finally, van den Briel et al. [49] use our FDR translation algorithm within their Integer Programming compilation ap-proach and report significant performance advantages over earlier approaches based on propositional encodings.In summary, there is a wide spectrum of planning techniques that can significantly benefit from automatically derivedconcise finite-domain representations using the techniques presented in this work.AcknowledgementsMany thanks to Silvia Richter, Sylvie Thiébaux and the anonymous reviewers for their very helpful feedback on earlierdrafts of this paper.References[1] G. Ausiello, P. Crescenzi, G. Gambosi, V. Kann, A. Marchetti-Spaccamela, M. Protasi, Complexity and Approximation, Springer-Verlag, 1999.[2] C. Bäckström, B. Nebel, Complexity results for SAS[3] J. Benton, M. van den Briel, S. Kambhampati, A hybrid linear programming and relaxed plan heuristic for partial satisfaction planning problems, in:planning, Computational Intelligence 11 (4) (1995) 625–655.+Boddy et al. [4], pp. 34–41.534M. Helmert / Artificial Intelligence 173 (2009) 503–535[4] M. Boddy, M. Fox, S. Thiébaux (Eds.), Proceedings of the Seventeenth International Conference on Automated Planning and Scheduling (ICAPS 2007),AAAI Press, 2007.[5] B. Bonet, H. Geffner, Planning as heuristic search, Artificial Intelligence 129 (1) (2001) 5–33.[6] T. Bylander, The computational complexity of propositional STRIPS planning, Artificial Intelligence 69 (1–2) (1994) 165–204.[7] Y. Chen, X. Zhao, W. Zhang, Long-distance mutual exclusion for propositional planning, in: M.M. Veloso (Ed.), Proceedings of the 20th InternationalJoint Conference on Artificial Intelligence (IJCAI 2007), 2007.[8] N. Creignou, S. Khanna, M. Sudan, Complexity Classifications of Boolean Constraint Satisfaction Problems, SIAM Monographs on Discrete Mathematicsand Applications, vol. 7, SIAM, 2001.[9] S. Cresswell, M. Fox, D. Long, Extending TIM domain analysis to handle ADL constructs, in: AIPS ’02 Workshop on Knowledge Engineering Tools andTechniques for A.I. Planning, 2002.[10] R. Dechter, Constraint Processing, Morgan Kaufmann, 2003.[11] M.B. Do, S. Kambhampati, Planning as constraint satisfaction: Solving the planning graph by compiling it into CSP, Artificial Intelligence 132 (2) (2001)151–182.[12] W.F. Dowling, J.H. Gallier, Linear-time algorithms for testing the satisfiability of propositional Horn formulae, Journal of Logic Programming 1 (3) (1984)367–383.[13] H.-D. Ebbinghaus, J. Flum, W. Thomas, Mathematical Logic, 2nd ed., Springer-Verlag, 1994.[14] S. Edelkamp, Planning with pattern databases, in: A. Cesta, D. Borrajo (Eds.), Pre-proceedings of the Sixth European Conference on Planning (ECP’01),Toledo, Spain, 2001.[15] S. Edelkamp, M. Helmert, Exhibiting knowledge in planning problems to minimize state encoding length, in: S. Biundo, M. Fox (Eds.), Recent Advancesin AI Planning. 5th European Conference on Planning (ECP’99), in: Lecture Notes in Artificial Intelligence, vol. 1809, Springer-Verlag, Heidelberg, 1999.[16] S. Edelkamp, M. Helmert, On the implementation of MIPS, in: P. Traverso, M. Veloso, F. Giunchiglia (Eds.), Proceedings of the AIPS-2000 Workshop onModel-Theoretic Approaches to Planning, 2000.[17] S. Edelkamp, M. Helmert, The model checking integrated planning system (MIPS), AI Magazine 22 (3) (2001) 67–71.[18] S. Edelkamp, J. Hoffmann, PDDL2.2: The language for the classical part of the 4th International Planning Competition, Tech. Rep. 195, Albert-Ludwigs-Universität Freiburg, Institut für Informatik, 2004.[19] K. Erol, D.S. Nau, V.S. Subrahmanian, Complexity, decidability and undecidability results for domain-independent planning, Artificial Intelligence 76 (1–2) (1995) 65–88.[20] M. Fox, D. Long, The automatic inference of state invariants in TIM, Journal of Artificial Intelligence Research 9 (1998) 367–421.[21] M. Fox, D. Long, PDDL2.1: An extension to PDDL for expressing temporal planning domains, Journal of Artificial Intelligence Research 20 (2003) 61–124.[22] M.R. Garey, D.S. Johnson, Computers and Intractability — A Guide to the Theory of NP-Completeness, Freeman, 1979.[23] B.C. Gazen, C.A. Knoblock, Combining the expressivity of UCPOP with the efficiency of Graphplan, in: S. Steel, R. Alami (Eds.), Recent Advances in AIPlanning. 4th European Conference on Planning (ECP’97), in: Lecture Notes in Artificial Intelligence, vol. 1348, Springer-Verlag, 1997.[24] A. Gerevini, D. Long, Plan constraints and preferences in PDDL3, Tech. Rep. R. T. 2005-08-47, Dipartimento di Elettronica per l’Automazione, Universitàdegli Studi di Brescia, 2005.[25] A. Gerevini, L. Schubert, Inferring state constraints for domain-independent planning, in: C. Rich, J. Mostow (Eds.), Proceedings of the Fifteenth NationalConference on Artificial Intelligence (AAAI-98), AAAI Press, 1998.[26] A. Gerevini, L. Schubert, Discovering state constraints for planning: DISCOPLAN, Tech. Rep. 2005-09-48, Department of Electronics for Automation,University of Brescia, 2005.[27] P. Haslum, A. Botea, M. Helmert, B. Bonet, S. Koenig, Domain-independent construction of pattern database heuristics for cost-optimal planning, in:Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence (AAAI-2007), AAAI Press, 2007.[28] M. Helmert, A planning heuristic based on causal graph analysis, in: S. Zilberstein, J. Koehler, S. Koenig (Eds.), Proceedings of the Fourteenth Interna-tional Conference on Automated Planning and Scheduling (ICAPS 2004), AAAI Press, 2004.[29] M. Helmert, The Fast Downward planning system, Journal of Artificial Intelligence Research 26 (2006) 191–246.[30] M. Helmert, H. Geffner, Unifying the causal graph and additive heuristics, in: Proceedings of the Eighteenth International Conference on AutomatedPlanning and Scheduling (ICAPS 2008), 2008.[31] M. Helmert, P. Haslum, J. Hoffmann, Flexible abstraction heuristics for optimal sequential planning, in: Boddy et al. [4], pp. 176–183.[32] J. Hoffmann, Where ‘ignoring delete lists’ works: Local search topology in planning benchmarks, Journal of Artificial Intelligence Research 24 (2005)685–758.[33] J. Hoffmann, B. Nebel, The FF planning system: Fast plan generation through heuristic search, Journal of Artificial Intelligence Research 14 (2001)253–302.[34] P. Jonsson, C. Bäckström, State-variable planning under structural restrictions: Algorithms and complexity, Artificial Intelligence 100 (1–2) (1998) 125–176.[35] H. Kautz, B. Selman, Planning as satisfiability, in: B. Neumann (Ed.), Proceedings of the 10th European Conference on Artificial Intelligence (ECAI 92),John Wiley and Sons, 1992.[36] H. Kautz, B. Selman, Pushing the envelope: Planning, propositional logic, and stochastic search, in: Proceedings of the Thirteenth National Conferenceon Artificial Intelligence (AAAI-96), AAAI Press, 1996.[37] J. Koehler, J. Hoffmann, Handling of inertia in a planning system, Tech. Rep. 122, Albert-Ludwigs-Universität Freiburg, Institut für Informatik, 1999.[38] D. McDermott, The 1998 AI Planning Systems competition, AI Magazine 21 (2) (2000) 35–55.[39] E.P.D. Pednault, ADL: Exploring the middle ground between STRIPS and the situation calculus, in: R.J. Brachman, H.J. Levesque, R. Reiter (Eds.), Pro-ceedings of the First International Conference on Principles of Knowledge Representation and Reasoning (KR’89), Morgan Kaufmann, 1989.[40] S. Richter, M. Helmert, M. Westphal, Landmarks revisited, in: Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence (AAAI-2008),AAAI Press, 2008.[41] J. Rintanen, A planning algorithm not based on directional search, in: A.G. Cohn, L. Schubert, S.C. Shapiro (Eds.), Proceedings of the Sixth InternationalConference on Principles of Knowledge Representation and Reasoning (KR’98), Morgan Kaufmann, 1998.[42] J. Rintanen, An iterative algorithm for synthesizing invariants, in: H. Kautz, B. Porter (Eds.), Proceedings of the Seventeenth National Conference onArtificial Intelligence (AAAI-2000), AAAI Press, 2000.[43] J. Rintanen, Compact representation of sets of binary constraints, in: Proceedings of the 17th European Conference on Artificial Intelligence (ECAI 2006),2006.[44] U. Scholz, Extracting state constraints from PDDL-like planning domains, in: AIPS-2000 Workshop on Analyzing and Exploiting Domain Knowledge forEfficient Planning, 2000.[45] J.D. Ullman, Principles of Database and Knowledge-Base Systems, vol. I: Classical Database Systems, Computer Science Press, 1988.[46] J.D. Ullman, Principles of Database and Knowledge-Base Systems, vol. II: The New Technologies, Computer Science Press, 1989.[47] P. van Beek, X. Chen, CPlan: A constraint programming approach to planning, in: Proceedings of the Sixteenth National Conference on Artificial Intelli-gence (AAAI-99), AAAI Press, 1999.M. Helmert / Artificial Intelligence 173 (2009) 503–535535[48] M. van den Briel, J. Benton, S. Kambhampati, T. Vossen, An LP-based heuristic for optimal planning, in: C. Bessiere (Ed.), Proceedings of the ThirteenthInternational Conference on Principles and Practice of Constraint Programming (CP 2007), in: Lecture Notes in Computer Science, vol. 4741, Springer-Verlag, 2007.[49] M. van den Briel, T. Vossen, S. Kambhampati, Reviving integer programming approaches for AI planning: A branch-and-cut framework, in: S. Biundo, K.Myers, K. Rajan (Eds.), Proceedings of the Fifteenth International Conference on Automated Planning and Scheduling (ICAPS 2005), AAAI Press, 2005.