Artificial Intelligence 90 ( 1997) 25-77 Artificial Intelligence Continuous case-based reasoning A. Ram ‘, J.C. Santamaria* College of Computing, Georgia Institute of Technology, Atlanta, GA 30332, USA Received December 1994; revised September 1996 Abstract Case-based reasoning systems have traditionally been used to perform high-level reasoning in problem domains that can be adequately described using discrete, symbolic representations. However, many real-world problem domains, such as autonomous robotic navigation, are better representations. Such problem domains also require continuous characterized using continuous performance, such as on-line sensorimotor interaction with the environment, and continuous adap- tation and learning during the performance task. This article introduces a new method for contin- uous case-based reasoning, and discusses its application to the dynamic selection, modification, and acquisition of robot behaviors in an autonomous navigation system, SINS (self-improving navigation system). The computer program and the underlying method are systematically eval- uated through statistical analysis of results from several empirical studies. The article concludes with a general discussion of case-based reasoning issues addressed by this research. Keywords: Case-based control; Motor schema-based navigation reasoning; Machine learning; Reinforcement learning; Robot navigation; Reactive 1. Introduction reasoning Case-based systems have traditionally been used to perform high-level rea- soning in problem domains that can be adequately described using discrete, symbolic representations. For example, CHEF uses case-based planning to create recipes [ 211, AQUA uses case-based explanation to understand newspaper stories [ 451, HYPO uses case-based interpretation for legal argumentation [ 51, MEDIATOR uses case-based prob- lem solving for dispute resolution [26], and PRODIGY uses case-based reasoning in the form of derivational analogy for high-level robot planning [60]. * Corresponding ’ E-mail: ashwin@cc.gatech.edu. URL: http://www.cc.gatech.edu/faculty/ashwin. author. E-mail: carlos@cc.gatech.edu. URL: http://www.cc.gatech.edu/ai/students/jcs. 0004-3702/97/$17.00 PIISOOO4-3702(96)00037-9 @ 1997 Published by Elsevier Science B.V. All rights reserved. 26 A. Ram, J.C. Santamaria/Art$cial Intelligence 90 (1997) 25-77 In our research, we have been investigating real-time problem domains, the problem of performance such as autonomous and learn- robotic navigation. representations require different underlying solving process and place ad- [ 131. In this article, we present a reasoning which can be used to guide action and to learn the systems for the design of case-based this class of problems, to addressing In addition reasoning problem domains ing in continuous, Continuous ditional constraints new method in continuous research presented here has implications in general. problem domains. on the problem for case-based domains. 2 Learning called continuous Our method, mental assumptions bolic problem guided by previous adapting ing lies on the retrieve-adapt-apply-learn [21,27,49]. them. New cases are of what might be called “discrete” experience. New problems reasoning is integrated with performance. case-bused reasoning, shares many of the funda- in sym- case-based is cases and test- and solving mechanism re- systems reasoning are solved by retrieving solutions proposed cycle common by evaluating to case-based Performance learned them on a real or simulated world. The basic problem However, of continuous the requirements problem domains are significantly different reasoning methods. the problem of driving a car on a highway. Car driving experiences in ways that do not permit ready application of traditional case-based For example, consider can vary from one another in one experience might continuously from, say, the highway operate continuously; process at which and 54 mph in another. Within a given episode, to an exit ramp. The problem solving and learning process must there in the to do so. ’ in infinitely many ways. The speed of a car might be 55 mph the speed of the car to moment, and significantly think, nor a logical point vary, both infinitesimally from moment to stop and is no time Such problem domains are “continuous” in three senses. First, they require continuous (within representations problem domains Second, continuous the limits of the digitization task requires is a continuous For example, a robotic navigation information. The input representations. ceptual and motor control data from ultrasonic and other sensors; of an input parameter can vary infinitesimally sampling parameters). mance. For example, driving a car requires continuous, solving performance is incremental to the reasoning system can at best execute evaluate actually encounters and learning. As the problems encountered become more varied and difficult, necessary in an incremental manner to rely on continuous experiences. of per- stream of perceptual the data itself is analog in the sense that the value and require continuous perfor- on-line action. Often, problem of necessity because of limited knowledge available the to it and then re- it require continuous adaptation it becomes to act, and to adapt actions and learn from system and/or because of the unpredictability the “best” short-term its progress. A robot, for example, may not know where obstacles these problem domains detailed knowledge to use fine-grained, of the environment; actions available the environment them. Third, feedback lie until from 2 We do not eschew symbolic representations; representations, whether symbolic, numeric, or otherwise. rather, proposed the issue is the continuous, time varying nature of any A. Ram, J.C. Santamaria/Art$cial Intelligence 90 (1997) 25-77 21 enhancements requires significant in discrete, symbolic Case-based reasoning in such problem domains reasoning methods used to be addressed. When are two experiences the basic case-based Several issues need warrant consideration as independent is the entire car trip from one’s house example, can be used to guide and improve one’s driving performance should “continuous How can they be used to guide performance? How are they learned and modified experience? And how can this performance on-line, In to systems. to is the scope of a single case? For to the grocery store a single case that in future situations? How they be matched and retrieved? through into a continuous, real-time process? this article, we provide cases” be represented? How should and learning be integrated reasoning different cases? What enough an answer to these questions task. The proposed methods are fully for its performance for continuous adaptation experience. The computer through is into a robot navigation puter system which uses reactive control reasoning learning system), implemented tion of the task domain, proposed method and eral empirical studies are analyzed using proach, putational model, mic choices, eters under various mental methods. conditions, and studies of the system the appropriate to predict circumstances, to understand the computer to determine to analyze to analyze the system of the performance element the relevant (self-improving system, SINS based on our research implemented in a com- element and case-based and for continuous navigation robot. We begin with a descrip- technical details of the sev- to evaluate our approach. The results of these the efficacy of the ap- in terms of the design of the com- and algorith- the system’s design param- environ- the proposed system behavior under changing the “sources of power” behind it. We then present that implements representational to demonstrate settings for statistical methods the behavior of the system on a Denning MRV-III after which we discuss impact of different recommended systems-and to many case-based learning We conclude with the contributions systems reasoning of a case in response case”-a representations and adaptation. We discuss of the solution reasoning sign of case-based our approach, which are common cuss the merits of fine-grained support on-line adaptation”-adaptation tion, as in standard case-based modification the notion of a “virtual may not have actually had-and experiences subsequent uous dynamic memory”, reasoning SINS system, beneficial evaluation methods used here can be used fruitfully evaluate a proposed computer the system. analogous [53]. We argue such as time history (as similar experiences. Our system, to a situation representative in case-based in standard case-based reasoning) reasoning systems systems system but also analyze of our research and their implication for the de- in general. We discuss the assumptions underlying and show how such representations reasoning systems. Next, we dis- can the differences between “solution to fit a new situa- by a case “case modification”-retroactive in which experience it is used. We introduce that the system may or show how virtual cases can represent not just past but also alterations by introduced a kind of “contin- implements case-based therefore, to the dynamic memory of traditional that these and other than rather innovations instantaneous in general. We also believe representations, introduced in the can be that the empirical in other AI applications not just to the theoretical model underlying 28 A. Ram, J.C. Santamar~a/Artijicial Intelligence 90 (1997) 25-77 2. The robot navigation task Autonomous robotic navigation is defined as the task of finding a path along which a robot can move safely from a source point to a destination point in an obstacle ridden terrain, and executing the actions to carry out the movement in a real or simulated world. Several methods have been proposed for this task, ranging from high-level plan- ning methods to reactive methods. High-level planning methods use extensive world knowledge about available actions and their consequences to formulate a detailed plan before the actions are actually executed in the world (e.g., [ 15,18,33,51] ). Consid- erable high-level knowledge is also needed to learn from planning experiences (e.g., [ 2 1,37,4 1,551) . Situated or reactive control methods, in contrast, perform no planning in the traditional sense; instead, a simple sensory representation of the environment is [ 3,9,23,43]. Actions are rep- used to select the next action that should be performed resented as simple behaviors, which can be selected and executed rapidly, often in real time. These methods can cope with unknown and dynamic environmental configura- tions, but only those that lie within the scope of predetermined behaviors. Furthermore, such methods cannot modify or improve their behaviors through experience, since they do not have any predictive capability that could account for future consequences of their actions, nor a higher-level formalism in which to represent and reason about the knowledge necessary for such analysis. We have developed a self-improving navigation system that uses reactive control for fast performance, augmented with a continuous case-based reasoning method that allow the system to adapt to novel environments and to learn from its experiences. The system autonomously and progressively constructs representational structures that aid the navigation task by supplying the predictive capability that standard reactive systems lack. The representations are constructed using a hybrid case-based and reinforcement learning method without extensive high-level reasoning. The system is very robust and can perform successfully in (and learn from) novel environments, yet it compares favorably with traditional reactive methods in terms of speed and performance. A further advantage of the method is that the system designers do not need to foresee and represent all the possibilities that might occur since the system develops its own “understanding” of the world and its actions. Through experience, the system is able to adapt to, and perform well in, a wide range of environments without any user intervention or supervisory input. This is a primary characteristic that autonomous agents must have to interact with real-world environments. Before presenting the technical details of our approach, let us discuss reactive control for robot navigation and some of the approaches that have been proposed to perform the autonomous navigation task. 2.1. Background and related work Several different architectures for reactive autonomous robotic navigation have been proposed (e.g., [ 3,9,3 1,431) . Typically, these methods rely on a combination of several task achieving modules, behaviors, or schemas that perform simple substasks such as avoiding obstacles, wandering, or exploration. Each module has a stimulus response type A. Ram, J.C. Santamarfa/Artificial Intelligence 90 (1997) 25-77 29 of relationship with the world. The response of the robot is the result of the interaction of all the responses to different the response of some modules can supress or schemes, in which the subsume (e.g., in final response which such as subsumption, the response of other modules in the system. The interaction in which the final response depends on how many modules propose is a weighted average of individual [ 93 ) ; weighted summation, [3] ); or voting, is computed according responses it (e.g., [ 3 1 ] ). (e.g., is to precompile to solve this problem One of the main difficulties of the reactive control approach for autonomous navigation should be active and under what situations. The simplest the priorities among behaviors manually is to decide which modules approach and keep these priorities constant until the completion of the task (e.g., way, the problem of activating modules priorities performs well only those that are “simple” the entire scenario. fixed and constant. The problem with this approach [ 3,9] ). In this their activation and is that the system to solve and to handle that the architecture was designed in the sense that one predesigned is avoided altogether in specific scenarios is sufficient strategy remain since responsible that activates A more complex approach is to precompile specific conditions for module activation relevant modules under “switching circuitry” (e.g., robot might wander looking for an empty can this condition, only the modules avoid obstacle and wander would be the wandering behavior and activate this approach can be used to at design is to let the robot learn which modules it is still static and predetermined and powerful approach the can. Although for approaching the architecture ) . For example, a trash collecting into [ 4,7,50] on the floor. During active. Once the robot detects a can, it can deactivate a module perform more complex navigation time. A more interesting should be active as well as the situations the approach pursued situations to those situations the modules. that control not only the activation the robot commonly case-based faces as it navigates and to associate a set of parameters levels but also the priorities among that trigger their activation/deactivation. in this article. We use continuous This is to learn the reasoning tasks, updates to estimate incrementally and perceptual those modules that are positively Maes and Brooks of module activations correlated with positive feedback under the condition that are relevant and reliable the estimation of these correlations [34] propose an algorithm in a robot as it navigates. The algorithm uses the robot’s experiences correlations feedback. The algorithm activates only vates the modules correlated with negative limitation of this approach only on the currently mation perceived modules area may either past information, density of obstacles not only the currently perceived situations to learn how to coordinate modules the conditions with positive and negative and to the task, that is, it acti- feedback and negatively facing. One to activate based infor- that are to determine which in a cluttered through or back up. The right choice may depend on through or the the robot uses of tried squeezing the robot has already the robot will face if it backs up. In our approach, between different world situations information sensed situation. This becomes a problem when the sensory to activate and prioritize. For example, a robot is that the robot must decide which modules try to squeeze such as whether situation but also the recent history leading up to the current situation. and thus does not provide enough the robot is currently is not rich enough that finds itself (time sequence) to disambiguate similarly, 30 A. Ram, J.C. Santamar~a/Artijicial Intelligence 90 (1997) 25-77 to localize characterization its position within the current position to behavior selection of the robot’s sensors A less direct approach is based on landmarks it detects new landmarks itself in the world. Then, its sensors. For each navigation as the robot navigates. The map is proposed by Mataric to construct landmarks to the goal. As the robot navigates, the map. Additionally, to the next landmark on the map. However, [ 351. Her method a qualitative map uses a functional the robot of the environment task, the robot uses the learned map can detect with it uses the map to and the surrounding and plan the best route that can take it verifies this and other from about rely on hand-coded knowledge approaches qualitative map learning can achieve when activated using a what each behavior or combination the robot to decide what modules to particular priority scheme. This knowledge activate in the (e.g., get to the next landmark qualitative map). A more robust approach might be to allow the robot to learn not only the disposition the effects of its behaviors which can be used to its advantage as it navigates. Another difficulty with the is very dependent on the terrain map learning in in which that specific [ 291) (e.g., of behaviors enables objective the relative positions of the landmarks the robot is trained, since it encodes in the terrain but also knowledge is that the acquired knowledge it selects behaviors some intermediary to accomplish of landmarks approach terrain. about 2.2. Motivation for a case-based reasoning approach to behavior coordination towards situations navigation the robot and prioritize A robot performing the task of autonomous in complex environments space, its tendency that require different coordination in a free space with very few obstacles, for this is that in complex environments the goal rather to proceed directly using the operation of its there are and priorities among motor the robot should focus than worry about avoiding obstacles. This would in towards to avoiding obstacles and slow the robot should pay more attention to move a reactive control method must be able to coordinate modules or behaviors. The reason many different schemas. For example, on moving allow a cluttered down which are important as moving towards each responsible plished by a set of gains or control parameters, which determine the robot eter which modulates robot’s parameter towards the goal, since not to do so would invite collisions such by motor schemas, is accom- the final response of the param- the this the robot to take a relatively direct path (e.g., the output of the “obstacle avoidance” motor schema affects In a clear environment with very few obstacles, the goal and avoiding obstacles are implemented the goal without any delay. However, for one such behavior. Coordination reactive control, simple behaviors to avoid. In schema-based among motor schemas through a weighted [ 31). For example, should be reduced to avoid obstacles. so as to permit summation the goal. tendency towards schema to coordinate motor schema-based As mentioned previously, one approach their priorities to precompile designers know the types of situations dination what situation to successfully is the the robot may encounter and the appropriate coor- to use under those situations. Thus, the robot must simple detect under scheme and use the precompiled is to use a for encoding navigating its task, One method it is currently perform [ 41) . In this approach, (or gains) at design these situations coordination time (e.g., behaviors scheme A. Ram, J.C. Santamaria/Artijicial Intelligence 90 (1997) 25-77 31 situations in the past [ 471. However, that were not considered library of “cases” which encode navigation been experienced encounters whether encoded as cases or otherwise-is learned or modified by the robot over time. Additionally, appropriate priority may require optimal control parameters A more robust approach through is to provide result from the execution of specific coordinations the use of an expert, although for every foreseen at design scheme that have strategies these approaches may fail when the robot for different situations time since this knowledge- hand coded by the system designer and not an and (e.g., finding this process may be automated designers must determine is time consuming situation, which the robot with only knowledge to learn the robot perceives the topology of situations situations let the robot approach, scheme take it closer to the desired situation. Although not in the context of motor schema-based reactive control, this approach has been explored by other researchers and it is usually refered its current situation and selects the desired situation, or an intermediate to as qualitative map learning in the terrain as it navigates. the specific coordination to achieve either situation [29,35] that would (e.g., ). about which of motor schemas and then In this the use of genetic algorithms as in [ 461) . are not applicable when a priori knowledge is not reliable. for specific problems, that it should use under in the form of situations In such situations, schemes While useful priori knowledge approaches knowledge that require different coordination coordination schemes is unavailable experiences. This suggests an experience-based the method coordination since the robot a new situation, situation. This again suggests a case-based of case-based should use previous experience schemes (or control parameters) to have exactly or unreliable, reasoning [ 2 1,271. the robot must perform these and other similar require approaches and control parameter pairs. Thus, a these is not available, or when such the robot must learn not only the situations for motor schemas but also the appropriate those situations. Since a priori knowledge its own to this problem: or case-based approach and appropiate situations to use in those situations. Furthermore, to learn relevant based on learning this is unlikely it must be able to adapt the best candidate the right piece of knowledge in memory for to the specifics of the new part is a fundamental approach: adaptation Pandya and Hutchinson [ 421 discuss a case-based approach rather to robot motion planning. than robot navigation, strategies the solution strategies or methods a set of path planning It tries to solve a collision-free this research issues similar focusses on motion planning to the ones we are exploring. Although addresses its disposition planning problems. and applying similar problems. Some of the methods are computationally but can only solve simple problems. The planner use its own experience to apply a specific method planner descriptions, adaptation. The proposed method In case of a failure, a repairer and to suggest a repaired version of the method, which diagnosis it In their approach, a planner has at that it can use to solve path path planning problem by retrieving the planner has successfully used to solved previous than others, to learn when the to problems with similar that have been applied proposes a solution method, and applies it to the given problem after proper its effectiveness. the nature of the failure is then re-tested. The cycle of is the plan is deemed successful, or until a failure to a given problem. For every new problem is tested on a world model to evaluate is used to “diagnose” or “explain” retrieves cases with strategies and repair continues less expensive to be solved, until 32 A. Ram, J.C. Santamada/Art$icial Intelligence 90 (1997) 25-77 encountered the case library for future reference. that has no clear fix. In any case, the experience is stored as a new case in Another path planning system that uses case-based methods [ 191. The to perform high-level planning of in a topological map. The model-based method plans space in which the is ROUTER searching a hierarchical model of the navigation among occupied and empty regions of such space are represented. previously planned integrates model-based and case-based methods system routes that connect any two points paths by heuristically spatial relationships The case-based method plans new paths by adapting and combining paths. The system either selects a specific method divides subproblem, of the path segments navigation a robot may use to navigate using the original problem and combining to the destination. (non-case-based) itself is accomplished to solve a particular problem, or into several, simpler subproblems, solving each their solutions. The resulting path is a symbolic description recursively traditional to these approaches, our work focusses on case-based and real-time level, which requires on-line execution than at the high-level motion or path planning level, which the plan is actually executed. Additionally, that can be used to test and evaluate proposed high-level planning solutions, whereas task requires interaction with the real world. These differences the In ROUTER, reactive control. reasoning at the robotic control, carried relies the impose is typically While related robot navigation rather out off line before on a world model robot navigation different constraints and demands on the approaches used to solve them. to our problem task: on-line learning is central is that the learning into the performance One such constraint which reasoning “cases” consist of time sequences should go on to the best of the robot’s ability as learning a continuous, case-based In our approach, in this article. situations and control parameters. The robot periodically to the current situation and the recent history of situations suggested by the case have been successful task should should occur as the robot navigates, is taking place. and learning method of the of retrieves leading in the the current tries at in a new case for future use. The the architecture of the SINS system as well as the be integrated and navigation This suggests type proposed associations between the case most similar up to it. If the control parameters past, situation. a reasonable random) following methods the robot uses the same control parameters, then the robot control parameters and remembers section describes the coordination of behaviors. the outcome of this situation for selecting and adapting set of control parameters suitably modified, under to the current situation, If no case in memory even picking responsible is similar in detail (perhaps 3. The SINS system system (SINS) consists of a navigation module, reactive control methods, and an on-line adaptation and learn- case-based reasoning supported by reinforcement robotic navigation The self-improving which uses schema-based ing module, which uses continuous learning methods. The navigation module the environment location obstacles along The adaptation from the starting the way. The adaptation and learning module has two responsibilities. submodule performs on-line adaptation of the reactive control parameters through is responsible to the desired goal location while avoiding for moving the robot A. Ram, J.C. Santamar~a/Artijcial intelligence 90 (1997) 25-77 33 Robot Agent Learning and Adaptation Module * Sensors Navigation * Module ) Actuators - SfZll80~ InpUtS Motor Outputs Environment Fig. 1. SINS functional architecture. from the best performance the navigation module. The adaptation from cases that capture and model to get recommendations its environment. With such a model, of its actions and act accordingly. The learning system and incrementally modifies shows module observes and adapts the navigation module, which in turn drives the robot. is able to predict submodule monitors of the system. Note that the learning is based on the interaction of the system with the progress of the through experience. Fig. 1 the case representations future consequences and adaptation the functional architecture the system 3.1. Schema-based reactive control reacts representing that represent to sensory is based on the AURA architecture The reactive control navigation module consists of a set of motor schemas to the system. Each schema vector a velocity produces is to move given current environmental STATIC-OBSTACLE directs the system and the associated repulsive potential vectors produced by all the schemas are then combined directs avoidance, [3], and the individual motor behaviors available and information the robot the schema AVOID- itself away from detected obstacles, schema parameter Obstacle-Gain determines of the field generated by the obstacles perceived by the system. The velocity field that such as wandering, obstacle in the direction conditions. For example, to move the actual movement of the robot. Simple behaviors, to produce complex emergent behaviors to produce a potential and speed at which and goal following, the environment, the magnitude can combine from 34 A. Ram, J.C. Santamaria/Artifcial Intelligence 90 (1997) 25-77 a particular the simple behaviors. environment. Different emergent behaviors can be obtained by modifying directs the system the system schema directs reactive control methods can be found A detailed description of schema-based in [ 31. In this research, we used three motor schemas: AVOID-STATIC-OBSTACLE, MOVE-TO- to move itself away GOAL, and NOISE. AVOID-STATIC-OBSTACLE from detected obstacles. MOVE-TO-GOAL to move towards a particular point in the terrain. The NOISE schema makes the system move in a random it is used to escape from local minima and, in conjunction with other schemas, direction; that control to produce wandering behaviors. Each motor schema has a set of parameters field generated by the motor schema. In this research, we used the following the potential parameters: Obstacle-Gain, associated with AVOID-STATIC-OBSTACLE, the field generated by the obstacles perceived by the magnitude system; Goal-Gain, associated with MOVE-TO-GOAL, determines the magnitude of the the goal; Noise-Gain, associated with NOISE, attractive potential of the noise; and Noise-Persistence, also associated with determines NOISE, determines for which a noise value is allowed of the repulsive potential field generated the magnitude the duration determines to persist. by 3.2. Behavior selection and modi$cation reasoning at what grain size should Our first attempt at building a case-based reactive navigation to guide reactive control. A central issue of using case-based nature of the guidance: its behaviors, and what kind of “advice” should the case-based to the reactive control module? To investigate robotic) case-based using case-based learning system focussed on the issue here is the represent reasoning module provide (a solely on to guide reactive control but did not deal with the issue of to do so. these issues, we built the ACBARR the reactive control module system, a forerunner the cases necessary to SINS, which reasoning focussed reactive appropriate to represent of cooperating for complex environments; In order to achieve more robust behavior switching to dynamically for a given environment; dynamically called behavior assemblages, haviors appropriate existing behaviors behavior adaptations that might be considered. One option its current behaviors based on immediate past experience. This is a local response problem. A more global solution blages of behaviors based on the current environment system should be able to learn about and adapt to its environment these ways. Different robotic control, ACBARR used sets of behaviors, be- collections select behaviors and behavior adaptation to adapt and fine tune types of is to have the system modify to the new assem- in which it finds itself. A robust in both of schema parameters produce different behaviors is to have the system select completely in novel environments [47]. There are two combinations dynamically hibited by the system different environmental parameters ditionally, However, on-line the current environment evaluating ACBARR qualitatively selection (see Fig. 2). This allows configurations are fixed and determined and modification can enhance navigational and quantitatively to interact the system to be ex- in successfully “strategies”. Tra- ahead of time by the system designer. based on performance. We tested this idea by stud- through extensive parameters simulation of the appropriate requiring different navigational A. Ram, J.C. Santamanh/Artijicial Intelligence 90 (1997) 25-77 35 Fig. 2. Typical navigational behaviors of different tunings of the reactive control module. The figure on the left shows the non-learning system with high obstacle avoidance and low goal attraction. On the right, the learning system has lowered obstacle avoidance and increased goal attraction, allowing it to “squeeze” through the obstacles and then take a relatively direct path to the goal (top center). level, adaptation the system both behavior the ACBARR in which traditional show that ACBARR such as box canyons, it is able to navigate into a reactive control system, we incorporated framework. At the local to adapt its current behavior is working well, the system continues doing and behavior this is accomplished and several different performance metrics is very robust, performing through several “hard” reactive systems would perform ies using a variety of different environments [ 471, for details). The experiments (see well in novel environments. Additionally, environments, poorly. In switching by allowing something harder; conversely, little different. This technique allows the system to fine tune its current behavior patterns if the robot has been in an to the exact environment in which it finds itself. For example, it picks up speed open area for a period of time and has not encountered it is in a cluttered and does not worry as much about obstacles. reactive area, it lowers systems, pro- this translates the appropriate modifications. ACBARR vided the system has a method rules for behavior modification. These uses a case-based rules are then used encountered environmental to retrieve to set gain and parameter values appropriate if things are not proceeding well, the system attempts something its speed and treats obstacles more seriously. For schema-based any obstacles, If, on the other hand, for the environment based on current the schema gains and parameters continuously, If it a little bit a in order to build “momentum”. by the system, and reasoning method it and tries doing for determining these values incrementally into altering conditions to alter The other method the system no longer suited the environment is at a more global level. If is currently acting under the control of an assemblage of behaviors which are it selects a new assemblage based on what that the robot to the current environment, is now like. Continuing with the above example, suppose in ACBARR and past successes. for behavior modification 36 A. Ram, J.C. Santamaria/Artifcial Intelligence 90 (1997) 25-77 is in a very cluttered environment and is employing a conservative assemblage of motor behaviors. It then breaks out of the obstacles and enters a large open field (analogous to moving from a forested area into a meadow). If only local changes were allowed, the robot would eventually adjust to the new environment. However, by allowing a global change to take place, the system needs only to realize that it is in a radically new environment and to select a new assemblage of motor behaviors, one better suited to the new surroundings. Interestingly, case-based reasoning is used to realize this type of modification as well. Assemblages of behaviors are represented as cases, or standard scenarios known to the system, that can be used to guide performance in novel situations. As in a traditional case-based reasoning system [ 21,27,49], a case is used to propose a plan or a solution (here, a behavior assemblage) to the problem (here, the current environmental configuration). However, our method differs from the traditional use of case-based reasoning in an important respect. A case in our system is also used to propose a set of behavior adaptarions, rather than merely the behaviors themselves. This allows the system to use different strategies in different situations. For example, the system might use a “cautious” strategy in a crowded environment by gradually slowing down and allowing itself to get closer to the surrounding obstacles. In order to permit this, strategies suggest boundaries on behavioral parameters rather than precise values for these parameters. Cases are used both to suggest behavior assemblages as well as to perform dynamic (on-line) adaptation of the parameters of behavior assemblages within the suggested boundaries. The knowledge required for both kinds of suggestions is stored in a case, in contrast with traditional case-based reasoning systems in which cases are used only to suggest solutions, and a separate library of adaptation rules is used to adapt a solution to fit the current problem. Further details can be found in [47]. Two important requirements in ACBARR (and SINS) are the ability to manipulate continuous representations and the ability to perform continuously in real time. Manip- ulation of continuous representations is required because often it is not easy to extract information from sensors in real time to maintain symbolic representations of the envi- ronment, nor is it clear a priori what the “right” vocabulary for symbolic features and concepts ought to be. Continuous performance is required because the system needs to modify its behaviors in an on-line manner as it navigates. Thus, in ACBARR, sen- sor values are preprocessed to produce real-valued variables that represent the current environmental situation. The current environmental information is used to retrieve an appropriate case and to guide behavior adaptation. To guarantee continuous performance, the adaptation information stored in cases is coded as mathematical formulae that can produce a new set of parameter values in a timely manner. 3.3. Case representation While ACBARR demonstrated the feasibility of on-line case-based reasoning in sys- tems requiring continuous, real-time response, it relied on a fixed library of cases that were hand coded into the system. The system could adapt to novel environments-an important source of flexibility-but it could not improve its own adaptation behavior through experience. Since the knowledge required for behavior adaptation is stored in A. Ram, J.C. Santamaria/Artificial Intelligence 90 (1997) 25-77 37 cases, we turned our attention built SINS (self-improving but can learn and modify cases in SINS is different and is designed behind the two systems are very similar. navigation its own cases system), which is similar to the problem of learning cases through experience. We to the ACBARR system of the ideas through experience. The representation learning, but the underlying to support performance, is an approximation A primary motivation behind SINS was to avoid relying on hand-coded, high-level domain knowledge. There are several disadvantages of relying on such knowledge. First, it is based on an a priori model of the interaction of the robot and its environment. Such aspects a model by the for successful especially system designer. Second, such a model of the and thus the quality of the model depends highly on the the environment, robot and it is unclear how a system could and skills of the system designer. Third, knowledge in real time; extract input this is one of the standard motivations from does not provide a a theoretical standpoint, in the first place. scientific explanation to reality and may not cover all the relevant in novel circumstances not anticipated is based on the designer’s understanding the necessary high-level knowledge for developing high-level of how such knowledge comes representation to be learned reactive systems. Fourth, a user-designed from low-level sensory the representations under-constrained task. As Thus, are initially for the navigation module gradually modifies and provide environment reliable at hand. used by SINS to model and generic; they contain very little useful its interaction with the environment information the learning they become useful to the particular the environment, until system the system interacts with the content of the representations information for adapting the navigation The learning and navigation modules function in an integrated manner. The learning trying is always module environment so that it can tune The navigation module provides model of this interaction. The behavior of the system point established environment which need to be re-established generic enough at any point The navigation module by the learning module, which is complex and dynamic if the environment to find a better model of the interaction of the system with its its function better. to the learning module so it can build a better the navigation module feedback to perform is then the result of an equilibrium is trying to refine the model, and the in nature. This equilibrium may shift and is changes drastically; however, the model in SINS can be adapted to be able to deal with a very wide range of environments. to exhibit many different behaviors. its performance by learning how and when to tune the navigation module. config- therefore, must learn about and discriminate in each environmental SINS improves In this way, the system can use the appropriate behavior uration encountered. The learning module, between different environments, be performed on the motor schemas. This requires a representational not just between environment. However, sive high-level perceptual the external environment, to ensure easily available at the reactive the knowledge represented information and motor reasoning, scheme adaptations to to model, the system and the in exten- in the model must be based on but also the interaction that the system does not get bogged down and associate with each the appropriate SINS uses a model consisting of associations and schema parameters values Obstacle-Density) the AVOID-STATIC-OBSTACLE schema). Each set of associations inputs (e.g., associated with as a is represented between level. the sensory (e.g., Obstacle-Gain, 38 A. Ram, J.C. Santamaria/Artifcial Intelligence 90 (1997) 25-77 Sensory Inputs x;i-;-: Association -::i_:_ 1 / 1 \ ‘1 , , ’ I 1: p21iq Control Parameters- p3 1.k ‘1 ;I ’ ‘1 ‘I ‘I ‘I I’ I’ , I 1 I I I ’ ’ ~ r p4 l\,,k ir 4” ~ \ \, 0 ” 1 2 3 time Fig. 3. Sample representations showing the time history of analog values representing perceived inputs and schema parameters. Associations between sensory inputs and control outputs are arranged vertically, and the sequence of associations over time is arranged horizontally. Each case in the system is represented in this manner, as is the current on-going navigational experience of the system. from inputs provide type of information is obtained to adapt the system’s the reactive module case. Sensory and how cable. Each analog value corresponds rameter) able. A case models an association grouping tion. their respective vectors at a specific information about the configuration sensors. Schema parameter in the environments to which information of the environment, specifies is appli- as a vector of analog values. Each input or a schema pa- the trend or recent history of a vari- inputs and schema parameters by (a sensory the case is represented to a quantitative variable time. A vector represents between sensory together. Fig. 3 shows an example of this representa- A. Ram, J.C. Santamaria/ArtificiaI Intelligence 90 (1997) 25-77 39 This representation has three essential properties. First, the representation between sensory a wide range of possible associations it permits continuous Second, captures the representation of capturing parameters. Finally, time. This allows having to make a decision based only on instantaneous ability can be thought of as a kind of “time history clustering”; detail refinement trends or patterns of input and output values over than rather inputs. This in more time windows values of perceptual to detect patterns over larger this is discussed the system progressive later. is capable inputs and schema of the associations. In this research, we used four input vectors to characterize configurations: Obstacle-Density areas that impede navigation; Absolute-Motion measures the change the environmental and provides a the in motion activity; and to- re- is that the system has actually made updated with of these input parameters the information represents to isometric is insensitive representation of the world the input parameters the sensors. An important among different environment the goal. These from specifies how much progress input vectors are constantly characteristic discriminate measure of the occupied activity of the system; Relative-Motion Motion-Towards-Goal wards ceived they form a propioceptive tion Additionally, mation directly perceived. 3 For example, Obstacle-Density the environment surrounding vidual obstacles with respect movement representation environmental quire different control parameter values. Thus, the system’s given world or goal location; approaching situations. of the robot allows situations towards the system translations encode and yet discriminate learned navigational area, slow down”) information a cluttered the robot is but does not encode to the robot. Similarly, Motion-Towards-Goal measures the goal but does not encode to apply similar control parameter values among different situations summarizes level than the infor- how cluttered the positions of the indi- the its location. This coarse in similar that would re- to a (such as “when in a wide range of is not specific learning strategies are general and can be deployed is, the representa- and rotations of the world configuration. [2]. That at a higher We also used four output vectors to represent the schema parameter values used to the navigation module, one for each of the schema parameters (Obstacle-Gain, and Noise-Persistence) discussed to the recommendations of the case that best matches earlier. The values are set the current the next interval” until The new values remain constant for a “control adapt Goal-Gain, Noise-Gain, periodically environment. setting period. according The choice of input and output vectors was based on the complexity to the navigation task. The input vectors were chosen configurations and their relevance environment required culation represent processing obstacle position, output vectors were chosen uses to tune the navigation module, to produce in a generic manner but taking those vectors (e.g., obstacle density and can be obtained easily from the robot’s ultrasonic to represent directly the actions of their cal- to the than sensors). The that the learning module into account is more generic that is, the schema parameter values themselves. 3 Section 5 analyzes the impact of this and other design decisions in SINS, including library, and so on, via systematic choice of input empirical representation, studies. choice of adaptation method, size of the case 40 A. Ram, J.C. Santamaria/Art$cial Intelligence 90 (1997) 25-77 3.4. Case learning and control reasoning used for on-line The case-based case representations is to construct jective of the learning method interaction of the system with its environment, appropriate behavioral to continuously schema parameters detect and discriminate appropriate and on-line manner. This means is perceiving the schema parameters dating situations. schema parameter values in different environments. the environment, its own cases the observed to reflect detecting learning module creates, maintains, the adaptation of the reactive module. The main ob- and applies a model of the continuous that is, a mapping parameters. This model allows from sensory to (schema) the adaptation module the behavior of the navigation module by selecting and adapting is to the To learn a mapping configurations, among different environment in this context and to identify sensorimotor inputs to be used by the reactive module, that, as the system is navigating, an environment configuration, in a dynamic the learning module and modifying of the reactive module accordingly, while simultaneously results of the system’s actions up- in various of ideas reasoning The method is based on a combination from case-based and to deal with and learn learning, which deals with the issue of [ 571) . However, and from reinforcement the content of system’s knowledge based on feedback systems learning, which deals with the issue of using past experiences from novel situations, updating (see and adaptation planning classical planning [39]) behavior not fall back on slow non-reactive to avoid. Earlier attempts (e.g., requires a detailed model of the domain. This systems are trying systems in reactive control systems. Unlike also relied on deep reasoning [ lo] ) or explanation-based case-based planning and were typically from the environment [ 211) learning (e.g., is exactly what reactive reactive control with (e.g., systems too slow for the fast, reflexive these approaches, our method does reactive control. in traditional to combine techniques required learning and the effects of different actions, and prescribes for improving regularity between a particular environmental con- the values of the schema (as far as the system knows based on its previous tasks in The learning module performs the following Each case represents an observed figuration parameters experience) a cyclic manner: that are most appropriate for that environment. ( 1) perceive and represent (2) retrieve a case whose sensory to the current environment; the current environment; input vector represents an environment most similar (3) adapt the schema parameter values (4) the values recommended installing learn new associations to reflect any new information to enhance situation and/or adapt existing associations in use by the reactive control module by by schema parameter vectors of the case; and in the case the use of the case in the new represented through gained the reliability of their predictions. reasoning terms (e.g., case retrieval, adaptation, and learning, are carried out by executing the behaviors case-based In traditional uation assessment, evaluation fying the actual effects using sensory the control parameters and carrying out the suggested movements) information. [27] ), these steps correspond respectively; to sit- and suggested by the case (i.e., modi- and observing critiquing A. Ram, J.C. Santamda/Artifcial lnrelligence 90 (1997) 25-77 41 against between distance) representing the sensory The perceive (i.e., Euclidean case is handed to a convolution vectors of the cases (The reward signal corresponds values of the reactive behaviors currently using a reverse sweep over the time axis similar step builds a set of vectors the corresponding step. The case similarity metric that matches best. The best matching the schema parameter values from the case and modifies input, which are in the system’s memory is based on the mean squared differ- each of the vector values of the case over a is to to the the then matched in the retrieve ence trending window and the vector values of the environment. The best match window calculated process find the relative position step, which selects adapt corresponding metric and a scalar reward. in traditional is discussed on the goodness of match between of the chosen parameters reward signal current environment that the system will use the parameters as a kind of basic animal on the common in a particular respectively most AI learning (cases). the case similarity to the notion of “outcome” it is used to reinforce good performance and the actual adaptations performed depend both and the usefulness suggested by the case. This can be thought of is based of executing an action is beneficial or prejudicial, idea of increasing or decreasing state [ 591; however, unlike learning is satisfactory, a better match between learning or “law of effect”, which in SINS is mediated by intermediate as long as the the as indicated by the reward signal. case-based in more detail and the retrieved case will result terms; later.) Thus, the case and the environment in a higher probability that the performance that such action the probability representations if experience reinforcement in use using Intuitively, traditional reasoning indicates response systems, situation stimulus learning shows like and in learn measure Finally, formula information information configuration step uses statistical about prior applications reward or reinforcement the current environment of the from the current application of the case should this case, or whether a new case should be created. The vectors in which a relative signal. The relative is to the the case to determine whether to modify be used in the cases are adapted using a reinforcement encoded is used as a scalar similarity similarity measure quantifies how similar environment has been situation involves is modifying that will take it away from not quite as good, the case should not be modified because the regularity is a very bad fit to the case, it makes more sense to create a new case to represent what is probably a new class of situations. it was used that the case is beginning the case in the direction of the current situation. Alternatively, the environment the current that the situation thus, it is worthwhile in previous utilizations better the very regularities in, it is likely to capture; encoded by the case relative of the case. Intuitively, if the current situation it was converging towards. Finally, if case matches to how similar than previous if the match configuration situations In summary, as the system navigates it encounters new situations and schema param- eters are tuned so that the system can adjust its behavior accordingly. The system learns it has faced in the past and which control parameters by remembering which situations those situations. The system uses two measures have produced good outcomes during the relative similarity of success metric ensures and control that control parameters produce similar parameter values. This associations between situations that cases capture consistent algorithm. First, to the learning the likelihood to provide feedback increases 42 A. Ram, J.C. Santamaria/ArtifciaI Intelligence 90 (1997) 25-77 in future situations. Second, the external reward signal ensures are associated with each situation. that produce positive outcomes that appropri- In this way, the system can as measured by the reward results ate control parameters learn control parameters signal. A detailed description of each step is presented below. Note represent associations the system is performed the overall using a reinforcement the learning effect of between ification measure, verge on stable associations eters. Stable fied by to navigate teraction set of causal patterns or associations formed by the system. The method allows and to use them to modify ate. the system and experience, in future between through environment regularities in configurations the world and provide formula based on a relative is to cause process the cases that since case mod- similarity to con- and schema param- identi- that have been the predictive power necessary the in- by a finite inputs and the actions per- these causal patterns as appropri- this method to learn is that between the sensory the system situations. The assumption behind the environment can be characterized its actions by updating its schema parameters 4. Technical details The continuous case-based reasoning algorithm, as implemented in SINS, is as fol- lows: Algorithm 1 (SINS algorithm). do current-environment if (end of control = perceive ( ) ; interval) then { if (outcome was good) then -C reinforce_schemas( previous-case, if (prediction is good and at end of sequence) then current-environment) ; extend_case(previous_case); 1 else explore_schemas(previous_case); best-case if (best-case is not a good match) = retrieve_best_case( current-environment); then best-case = create_case( current-environment); aduptschemas( best-case) previous-case = best-case; ; ) execute ( ) while (not (goal reached or maximum number of steps exceeded) ) ; A. Ram, J.C. Santamaria/ArtificiaI Intelligence 90 (1997) 25-77 43 constructs the perceive The perceive and maintains that these representations function situation by reading in time, but of the sequence of values of the parameters over a given a representation the robot’s sensors and updating ronmental vectors accordingly. Recall rent instant interval. Thus, for each sensory k as described module performs by the reactive control module it learns useful sequences of associations parameters. of the current envi- the input and output not of the cur- time in a set of J = 4 input vectors Einrui,, one j, and K = 4 output vectors Eoutput,, one for each output vector and adaptation in use and and schema interval T, the learning it adapts the schema parameters currently in the new environment, situations earlier. Then, on every control so that it performs better between environment two main functions: are descriptions, function results input Schema parameters are adapted using the retrieve-best-case the case most similar and adaptschemas func- to the current environment function, the environment’s is selected by matching tions. In the retrieve-best-case situation E output, from the perceive step against G”tp”t, of the cases C” in the system’s memory Cnh;” and the position of the best match pbesi are handed which modifies dations Ci$, the schema parameter values currently the corresponding (pbest + 1) from the output vectors of the case. input and output vectors Ei,r”t,, input and output vectors C&,ut , (see Fig. 4). The best matching to the adaptschemas case function, in use based on the recommen- Finally, reinforces information the learning of the case the suggestions in three different ways: by improving and adaptation module decides how to utilize it more reliable, by creating a new case whenever from its case library. The system the current experience with the best case in order to improve the content of the case that was just used in learns the best case retrieved order to make is not good enough, or by extending the length of the case in order to build up longer sequences of associations. The contents of a case are improved by the reinforce_schemas function, which favorable outcome over the last control which uses random exploration set of values did not prove useful. Random exploration is to find parameter values in set of parameter values, is, values more likely implemented function4 the last control movement; instead. led to a if these suggestions function, interval, and by the exploreschemas to try out other schema parameter values if the suggested the main objective a positive outcome a poor of selecting that are is for the random exploration the behavior of the robot over as is lack of any other suitable performance metric could be used that have produced positive outcomes than using a non-uniform (or obtained positive that have produced negative outcomes. This probability is evaluated by monitoring In our application, the selection of parameter values The outcome interval. that increase in order the next cycle. However, the likehood of obtaining is done non-uniformly, in other applications, are undesirable, is used because to be selected the probability distribution to reduce collisions rewards) those In traditional case-based reasoning systems, case adaptation rule-based cf. [ 321). SINS, system which utilizes a hand-coded set of adaptation in contrast, uses a kind of reinforcement is carried out using a [ 241 but to provide rules learning method (e.g., 4 Section 5.7 presents two alternatives implemented in the SINS system and evaluated through systematic empirical studies. 44 A. Ram, J.C. Santamart’a/Artijicial Intelligence 90 (1997) 25-77 recent cast Environment length (IE) I current time \ Case length&.)- I ’ I ’ bst i Current Environment Configuration Representation Case Environment Configuration Representation ,> output Vectors I t Fig. 4. Schematic representation of the match process. Each graph in the case (below) is matched against the corresponding graph in the current environment (above) to determine the best match, after which the remaining part of the case is used to guide navigation (shown as dashed lines). necessary for case adaptation. the functionality The issues underlying the integration of multiple learning strategies into a single multistrategy learning system is discussed in more detail in [ 481. One difference between our methods and traditional reinforcement learning is that SINS is trying to maximize consistency in “useful” behaviors as deter- mined by a reward signal, whereas traditional reinforcement learning tries to maximize the expected utility the system is going to receive in the future as determined by the reward signal (cf. [ 58,621). In schema-based reactive control navigation, it is inher- ently a good idea to modify schema parameters in an on-line fashion; however, not all modifications are equally good since some may cause the robot to collide with obstacles or not to move at all. SINS uses the reward signal to decide whether to reinforce a behavior or to explore alternative behaviors; reinforcement, when chosen, is used to A. Ram, J.C. Santammfa/Art$cial Intelligence 90 (1997) 25-77 45 reinforce behaviors nal outcome, learning method. 5 that are consistent consistency is used as an “internal” across experiences. Thus, reward signal in addition for the reinforcement to exter- the states and what corresponds it learns how to associate actions learning reinforcement assumes a predefined to states in order to maximize set of known a to be task is to that are likely appropriate sequence situations. Thus, SINS is learning a model of its sensorimotor to “actions” are not known; part of the learning situations in turn, associate (the sequences of environmental (the adaptations of adaptations) and, on the navigation module) states traditional Furthermore, states and actions; reward. In SINS, performed discover to result adaptations interaction with the environment it is learning to improve reactive control schemas. the relevant from a given to different its navigational performance (represented as a set of cases) at the same time as through on-line adaptation of its criterion to judge situation. the current in prior applications If the best matching is based on statistical situation. This determination its cases, SINS can also extend to perform the appropriateness to modifying to decide which kind of learning similarity its cases and learn new in a given situation, SINS of the best matching information to the quality to the the case is probably to learn a new case to represent what In addition cases. In order uses a relative in case the quality of match about of match in the current current environment inappropriate the createnew_cuse is probably and add it to the case function library. To determine whether the current match with the mean match plus the standard deviation of the matches over the past utilizations of the case. This ensures that new sequences of associations available current environment. are created only when the in the case library do not fit the of the case as compared case to create a new case based on the current experience situation as it has been in previous situations, to create a new case, SINS compares If this occurs, SINS uses a new class of situations. sequences of associations for this situation; is not as similar already captured thus, it is better to increase is carried out by the extend_case_size situation and there are no more associations the best case makes an accurate prediction that the sequence of the case accurately predicts how the environment third kind of learning the length of a case whenever The extends the next environment allows the system confident if the suggested values are matched with the actual environmental is better predicts used in, it is likely is beginning the current function, which of in the sequence. This the length of the sequence of associations only when it is changes the predicted if this match if the case that it was that the case the case so as to incorporate is not quite as good, the case should parameters Intuitively the previous the very regularities the case is extended. than it predicted involves than the mean match, the current situation better this confidence, that result; (as before), situations that the current situation situation. Alternatively, are used. To estimate schema parameters it is worthwhile if the match to capture; extending thus, 5 SINS can be run with or without outcome, SINS learns cases that improve which do not improve performance perception-action model that is being an external reward signal. With a reward its navigational performance; without one, it sometimes signal based on external learns cases in the regularities but nevertheless learned. This issue is discussed are “correct” in that they represent in mote detail in Section 5.9. 46 A. Ram, J.C. Santamaria/Artijicial Intelligence 90 (1997) 25-77 not be modified because doing so would converging towards. take it away from the regularities it has been Since the reinforcement formulae are based on a relative similarity criterion, the over- in a given en- in the initial design of the is useful it cannot change schema parameters on line during navigation when schema parameters this approach is to cause the cases to converge on stable associations representing in and schema parameters, that the reward utility has identified as being useful and predictive perception-action models, in different the schema parameters regularities regularities capture consistent faces environments configurations interaction algorithms may also be used to modify [46]. However, while system, all effect of the learning process between environment the system-environment to learn. These and hence can be used as the basis for modifying situations. Genetic vironment navigation that are significantly the system used in the training phase of the genetic algorithm to self-organizing which a neural network ditional systems, is a fundamental task is improved. Their system incorporate new input data (i.e., conditional system, while SINS improves system the navigation module) input, but on patterns or regularities methods are also similar ment evolving world model. Unlike on the same world many world, responses. Although there location, or destination adaptive control difference to Sutton improves location. strategy learning stimuli) initial (i.e., is used to learn how to associate conditional is that of Verschure, Krose, and Pfeifer stimulus their system and ours are both self-improving from different the environments (but cf. [ 201). Another approach [61], in to uncon- navigation of the navigation by learning how to into an already working navigation in how the performance its navigation performance its navigation performance by learning how to adapt the itself. Our system does not rely on new sensory in perceived environments. Our learning detected reinforce- [ 561, whose system uses a trial-and-error to develop a world mode1 and to plan optima1 routes using the this system, however, SINS does not need to be trained to a particular times, nor are the results of its learning specific We now present a detailed description of and the mathematical formulae used in the perception, matching, adaptation, and learning tasks. 4.1. Perception situation. is to generate an accurate description The objective of the perceive function of the in current environment It performs the current each input and output vector one position back in time 6 and then calculating j = 1, . . . , J and output vector Eoutput, (0)) k = values 1 in time. The current values for the input vectors are based on the robot’s sensors, and the current values for the output vectors are just the respective values of the schema parameters interval. The vectors are updated at the end of each control for each input vector Ei,r”rj (0)) . . , K, where 0 is the current position in the previous control this task by shifting the previous values interval of time T. suggested 6 This is implemented using a circular buffer which does not require copying each of the values from one cell to the next. A. Ram, J.C. Santamaria/Art$icial Intelligence 90 (1997) 25-77 41 To update the input vectors, the system monitors corresponding to each input vector Ei,p”s. The sensors are monitored Sensorj time step over yield environment interval; the past control the new value for the corresponding the values of the robot’s sensors at each to in the are then averaged the input vectors readings these sensor input vectors. Thus, the following representation are updated using formula: 7 &put,(i- 1)~ if i > 0, &put, (i> = C:T_,SenSOrj(f) T ’ if i = 0, is the sensory where Sensorj(n) (sensed obstacles position and t ranges over each robot step since the last control for Relative-Motion, and normal for Obstacle-Density, distance that corresponds traveled relative position input interval. to the input vector Einput for Absolute-Motion, relativ; for Motion-Towards-Goal), 4.2. Retrieval and matching the current environment situation. The case similarity metric The function retrieve-best-case is responsible for selecting a case from the case library that best matches is based on the mean squared difference between each of the vector values of the case over a is trending window, and the vector values of the environment. The best match window process calculated using a reverse sweep over the time axis p similar to find is matched against the best matching case Pb”’ along with the relative position nest of the match (see Fig. 4). After the mean and variance of the case’s statistical match history retrieving are updated; criterion during learning. that matches best. Each case C” in the case using exhaustive search, which returns these will be used later to calculate the current environment the relative similarity the relative position to a convolution the best case, library The case similarity metric SM of a case C at position p relative to the environ- the sequence of associations that indicates the similarity between in the case to the sequence of associations in the current environment at position p. The lower the sequences of associations. the value of the case similarity metric, formula The case similarity metric sum of the squared difference between the corresponding the environment. For the SM to be valid, p must sit- the cal- vectors lie between 0 starting ment E is a value encoded uation more similar culates a weighted of the case and and 1~. SMCE,C,PI =&wj j=l c i=O P+l min(px”) ( Ei,p”tj (i) - Cinput J (p - i) ) ’ mi”(pSk) (Eoutputk(i) - Gutputk(p - i>>* k=l i=o P+l ’ Note that i counts back in time (i.e., i = 0 is the current time and i z 0 is the recent past). 48 A. Ram, J.C. Santammfa/Artificial Intelligence 90 (1997) 25-77 For this article, we used wj = wk = 1.0 (i.e., input and output vectors contribute equally in the similarity metric). The best case is obtained by matching each case C” in the case library at all the positions p and selecting the pair (&esr,&sr) that yields the lowest SM. Formally, this can be expressed as: Each case C maintains a statistical record of the similarity metrics it has produced in the past, which is updated every time the case is retrieved as the best case. The mean (CSM_) and variance (C SM, ) of the case similarity metric as well as the number of times the case has been used (C&d) are updated using standard formulae in descriptive statistics: new CSM,, = &/d&4,, + SM Cused + 1 ' new CSM, = C used - C used ’ CSM, + (new CSM,. - CSM,, ) * + (SM- new CSM,.)* C used 9 new cuxd = i&d + 1. 4.3. Adaptation The best matching case C”““’ is used to adapt the schema parameter values currently in use by the reactive control module. The values of output vectors for the next association C”“’ are used to determine the new set of schema parameter OW% after position fist values Param&rk until the next control interval. Since learning tends to reinforce those associations the new set of schema parameters can be expected to cause the robot to move safely and the next environment configuration that results from the movement can be expected to be the one predicted by the association. Since output vectors directly represent schema parameters, adaptation is a straightforward operation: that are consistently observed over several experiences, Parai?Wterk = CE&4, ( fiest + 1) , Vk = 1, . . . , K. 4.4. Learning In addition to perceiving the environment, retrieving the best matching case, and adapting the schema parameters being used by the reactive control module, SINS must also learn by updating its case library based on its current experience. Three types of learning are possible: modification of the associations contained in a case, creation of a new case based on the current experience, and extension of the size of a case to yield associations over larger time windows. Modification of case contents, in turn, A. Ram, J.C. Santamda/Artijicial Intelligence 90 (1997) 25-77 49 can be of two on a successful unsuccessful experience. types: reinforcement of the associations contained experience, and exploration of alternative associations in the case based based on an SINS decides which kind of learning it was used. If the current match to perform using a relative similarity criterion the quality of the best match. The match value of the best case, based is compared with the match values of the case in previous the mean match is since it has been a better match to create is invoked the values of the from the current situation, in the past. In this case, the create-case function a sequence of associations still the best match) the case (although is worse than than a standard deviation, which determines on the case similarity metric, situations in which value by more considered to other situations a new case containing sequence of associations to be too different formed by copying representation: in the current environmental c;g4 (0) = Jqgt, (0) 9 Vj=l,...,.l, towards. If the case provides good recommendations If, on the other hand, situation the best case matches is representative the current situation well, of the class of situations which to converge that the current beginning recommendations should be reinforced; In SINS, collisions with obstacles and lack of movement of the navigation does not lead to an undesirable improve schema parameter values the robot. task. A set of schema parameters functions the accuracy of prediction of the system’s cases and, in turn, to discover in environmental outcome. The objective of the learning that are beneficial that result situations it is likely the case is for action, its should be modified. by definition if using are undesirable is considered beneficial it is to those for if not, its recommendations If the best case recommends the expZore_schemas function set of schema parameters robot, different the output vectors C:&!, the best match position best are modified are not useful space of possible by the following schema parameters formulae: a set of schema parameters is used to modify in similar circumstances that are not beneficial to the the case such that it suggests a in the future. Specifically, following in a random manner since the current values the in a controlled manner. These changes are defined to explore situation to the system. The small random changes allow the system (best + 1) associated with the environment p = min ( 1, u collisions + /? max_velocity - velocity max._velocity >? c:sg”t, (Pbest + 1) = ( 1 - p> q&tk ( pbest + 1) + p random min C:$,Ut,, max C:&4, ( , > b’k=l,...,K, where p is a “reject” value dations of p = 0 specifies should be taken that determines the extent to which the current recommen- into account when determining that the value of the output vector should be left unchanged, the modified values. A value and a 50 A. Ram, J.C. Santamarfa/Artificial Intelligence 90 (1997) 25-77 value of p = 1 specifies by a new random value of p depends on (Y and 6, which represent moving, could be changed depending tion functions were implemented one using a best-reward that the value of output vector should be replaced completely the value in the allowable and respectively. For this article, we used LX = 0.5 and /3 = 1.0, but these values selec- and and evaluated, one using a Boltzmann distribution see Section 5.7 for details. on the desired application. Two different “random” the importance of avoiding collisions range. In any given learning cycle, function; If, on the other hand, the schema parameters the reinforcexhemas it more like the current environmental in similar situations function suggested by the best matching case pro- is invoked. This function updates so as to produce is done in the future. This reinforcement situation, results, duce desirable the case by making the same recommendations the following using formulae: C$$,(i) = & (&pu~(Pbest -9 - C$$,(i)) , Vj= l,...,J, Vi = 0,. . . ,phst where A determines the learning the extend-case function extends rate. For this article, we used h = 0.9. the sequence of associations Finally, case. The decision rion. If the case’s predictions CF$At (fist+ to extend a case is also based on a statistical 1) are similar to the resulting environment contained in a relative similarity crite- sit- uation within a standard deviation not have more associations parameters), ‘from the mean predictive similarity, and the case does (that is, it cannot provide a next set of schema in the sequence then the case is extended by duplicating the last association of the case: CkSt ,,,“li(Pbest+2)=C~~~tl(Pbest+1). Vj=l,...,J, C=brSl output, best + 2) = c::&tk (fiest + I), b’k = 1, _ . . , k: The net result of these learning procedures is to cause the cases in the system’s case to converge towards regularities in the system’s learns useful sequences of schema parameters interactions with its environment. for different environment situ- these are used to guide navigation and, in turn, are updated based on navigational so as to improve the reliability of their predictions in similar situations in the library The system ations; outcomes future. 5. Evaluation SINS is fully implemented in C++ on top of Arkin’s [3] AURA architecture for schema-based In real mode, reactive control. The system works the system controls a Denning MRV-III in two modes: robot real and simulation. through a radio link; the A. Ram, J.C. Santamaria/ArtificiaI Intelligence 90 (1997) 25-77 51 system of the robot consists of a Denning perceptual laboratory grade Polaroid Ultrasonic Rangefinders plane parallel Rangefinders to the floor. In simulation mode, and the dynamics of the actual robot. sonar ring which has twenty-four equally spaced over 360 degrees in a the values of the the system simulates performance the qualitative and environmental types of environments, in simulation mode, since running in which design parameters The methods presented above have been evaluated using extensive experiments across a variety of different criteria, and system configu- rations. The results presented here are based largely on experiments performed with the system that allows us to run several hundred exper- are systematically iments in the navigation varied. We measured the effects of various performance design decisions on the performance of the system. The results show the efficacy of the methods across a wide range of qualitative metrics, such as flexibility of the system and ability that measure performance, and the optimality experiments, we also evaluated validity of our approach. configurations, such as the number of navigational of the paths found for these problems. the system’s performance and quantitative metrics problems In addition solved successfully to the simulation to verify configurations improvement evaluated of the SINS system and systematically to deal with difficult environmental and quantitative in real mode the insight learning [ 1, 12,251. combinations is no a priori the performance to the theory-in the implementation to evaluate, not just are not known, and there like many other case-based into that underlies theoretical models for multistrategy and some of which are introduced and multistrategy formal in is also complex. One result of this Evaluation methods must not only verify it all the important other words, ideas, some of which have proven successful theory in past applications the range of problems the design of the system. The proposed system of the computer that the system can handle and is based of case- in this of these theoretical guarantee of the success the behavior of to relate empirical evaluations of the system the program, but the theory but also provide into the theory on several based reasoning application. However, methods of our approach, nor a theoretical basis for predicting or understanding the system. This makes back underlying SINS, it operates many sources this behavior significance of an observed behavior of the system in a specific situation. Straightforward performance not good enough: specific works or how the design decisions used given analyze [ 11,251. analyze how the performance some information they are based on extreme operating improves over time are improves on the about why the system affect the behavior of the system, nor can they be to of the system to these studies do provide in the performance of the system, (i.e., one or In such studies, one or more system modules are removed or deactivated of the system changes. Although for variability which cause any performance measure defined to have variability the domain the behavior of SINS has to evaluate the that show how the performance of a system although in the behavior of the system). Ablation system’s modules these curves show they do not provide useful the behavior of the system under different circumstances about the merit of different modules to predict the variability the impact of different studies can be used that the performance in the performance in turn makes that are often test problems, as well. This is complex information impractical it difficult (especially conditions to assess reasoning systems, is that curves and 52 A. Ram, J.C. Santamaria/Artijicial Intelligence 90 (1997) 25-77 more modules are set to be either active or inactive), Moreover, design decisions often deal with allocating to their resource allocation, disabling nature, ablation the possibility to allocate to each module. of deciding what would be the optimal amount of resources studies can only deal with all-or-nothing to different modules. Due amount of resources certain experiments (proposed by [ 521) We used a systematic characteristics. designed statistical evaluation methodology In this methodology, of the system statistical in terms of changes a mathematical model of the behavior of the system In such an analysis, to filter out undesirable the change and domain through systematic of the SINS system. in the performance (or problem) to eval- tools are used in design is sources of to tools in terms of design pa- is used to assess the merit of various the uate the performance to analyze decisions evaluated variability. The results of the experiments construct rameters and domain characteristics. design decisions performance Such an evaluation theory and design of the computational model, select the best system configuration a given domain, in case the characteristics the domain change. An important of the system when it faces problem domains with different characteristics. in terms of the for of and predict how the system will behave is that they use previous cases to are then analyzed using statistical the behavior of the system enables us to understand in the continuous and to analyze of case-based characteristic This model the system case-based algorithm reasoning systems improves, but that the variability solve new similar problems. Thus, it is important of the system solving new similar problems decreases as the number of problems increases. Any significant further deserves [ 17,381. Systematic verify the significance behavior of the system. to verify not only that the performance in the performance of the system when in the past these behaviors sources of the utility problem to in the empirical of these behaviors and to identify analysis based on statistical the system does not show the sources of variability tools can also be used reveal possible study since indication it might solved that 5.1. Systematic evaluation of SINS The performance for this is that the adaptation of SINS varies across different worlds, system configurations, and amounts of experience. Moreover, due to the nature of the task and the architecture of the same world and case library. The the system, SINS can perform differently reason tune the navigation module randomly when no appropriate case exists; this allows the system to explore and discover the system new regularities. This means should be must be treated as a random variable used to assess that any performance metric used to evaluate techniques and learning module its mean value. and statistical estimation given describe in detail The next subsections on SINS. The first set of experiments parameters number of cases, maximum of cases and maximum case size, belong one, world clutter, belongs studies perfomed evaluation (study 1) focuses on the effect of two design factor on the performance of SINS: maximum case size, and world clutter. The first two, maximum number to the design decision group of factors. The third group of factors. characteristic and one domain characteristic the systematic to the domain (or problem) A. Ram, J.C. Santamria/Artificial Intelligence 90 (1997) 25-77 53 We also consider how the experience that the system improves The second set of experiments indeed design decisions input SINS. The tation and adaptation method represent high-level systems, learning ing environment module adapts situation. The experimental brevity, the systematic study, and a summary of results (situation). the control parameters level influences the performance of SINS and verify as the experience its performance (study 2) focuses on how the choice of input represen- of SINS. Both of these factors reasoning in most case-based level increases. influence the performance that are important representation that the including and adaptation module of SINS uses to represent and categorize to the information refers the surround- The adaptation method refers to the method by which this suggested by the best matching case to the current thus, for the sake of in detail only for the first for both studies is described is similar; procedure evaluation methodology is presented for the second study. (study 3) verifies The third experiment provided by of the robot in an indoor room with a few static obstacles over several trials. We plot the the learning method on an actual performing performance improves along different metrics as the number of trials increases. the number of trials to verify that the navigation performance improvement the performance robot. We measure the performance curves against 5.2. Study I: experimental design and data collection as well as the conditions The objective of both sets of simulation studies between is applicable. the relationship the factors of interest and system performance describes characteristics) model by selecting system’s performance when operating under conditions in which In this way, it is possible the system was optimized. To collect data for the evaluation to optimize the appropriate configuration parameters and to analyze is to find an empirical model that (design parameters and domain under which such a the performance of the system the robustness of the that differ from the conditions simulations environment analysis, we performed that provided a batch mode facility; using a simulation us to run several hundred over a range of environments. A run consisted of placing and letting it reached time limit. The latter condition guarantees by the system. The data for the estimators was obtained each run. This was to ensure across experiences worlds of this size anyway). several runs on the system this facility allowed to gather statistics on the system’s performance the robot at the start location location or until it reached a maximum since some worlds are unsolvable terminated the effect of learning is less significant on that we were consistently measuring (which than within a single experience after the system the destination it run until termination rather for this is that the median We evaluated the performance of SINS using to solve a world. The reason mean and is not too sensitive control since the system can get trapped in local minima points, resulting change SINS (i.e., same number of cases, case size, and level of experience, world clutterness) reporting in the behavior of the system. An experiment to solve a world across five independent the median value of the time it takes is a robust estimator of the reactive in a significant the time consisted of measuring runs under the five runs as the response variable. to outliers. Outliers are common the same conditions the median among in schema-based takes and 54 A. Ram, J.C. Santamaria/ArtijiciaI Intelligence 90 (1997) 25-77 in which 15% of available Two experiments were designed the objectives of the first study. In the first i.e., in space is occupied by obstacles. the data to satisfy experiment, we ran different versions of SINS in the same 15% cluttered world, a randomly generated world Each system used different configuration that relates required parameters every time. In the second experiment, we ran the best system configuration, by the model created during world. In this way, we could verify domain characteristic and amount of experience when dealing with a specific 15% cluttered world as determined in a randomly generated 20% cluttered the the system performance with of the system holds when In this way, we collected the first experiment, if the performance to build a model the configuration parameters. changes. During both experiments, we collected the data from five independent holding the environmental out the effects of the configuration effects of other parameters how the design decisions same world or environment). domain characteristics environments). and system conditions constant. and experience such as noise. The first experiment parameters affect system performance The second experiment runs while In this way, we could balance level and block out the allows us to determine systems under (i.e., different the allows us to study how different (i.e., the same system under different in [ 521. are discussed affect system’s performance Further details of the methodology 5.3. Model construction to be determined As explained earlier, to solve a world. Thus, the performance the model and level of experience. We used the following of SINS is evaluated by estimating that needs time (T) as the response variable; parameters variables: maximum time iment has the median configuration independent level of experience terms C2, S*, and E2 and the quadratic considering plain variability in the response variable better than individual was used to reveal which of these terms are really significant in the final model. Eq. (1) shows the complete hypothetical model. all these factors is to allow for the possibility the median in the first exper- the mode1 relates T with the as case size (S), and regressors such as the quadratic for terms may ex- terms. Statistical analysis and should be considered interactions CE, SE, and CS. The reason (E). We also considered number of cases (C), maximum that interaction regressors additional T=Po+ PcC’ + PsS’ + PEE’ + &C’S + ,BmC’E + &S’E’ t* 12 + PccC'~+PSSS +PEEE + E (1) where V’ is the standardized* value of a variable V (i.e., V’ = (V - VI)/&-). x Use of standardized with multicollinearity values instead of the original values helps to reduce roundoff errors and other problems between independent variables. A. Ram, J.C. Santamaria/Artijicial Intelligence 90 (1997) 25-77 55 Table 1 Best subsets regression results Number of variables I 2 3 4 5 6 7 8 9 R* 53.9 66.1 73.7 75.9 77.5 79.0 79.3 79.6 79.8 RZdj B C S 53.8 66.5 13.6 75.7 77.3 78.8 79.0 79.2 79.4 II.031 9.394 8.346 8.002 7.732 7.482 7.434 7.402 7.372 x X x X X x X X X x X X E X X X X X X x X X CS CE SE C* S* E* X X X X x x X X X X X x x X x x X X X X x X x X between relationship a second order polynomial that the mathematical is “smooth”, variables such as the one proposed by the model, the response variable and the Assuming expression of that rela- independent is a good approximation. Also, early tionship, experiences with the system showed that its behavior was related to the maximum num- ber of allowable cases, maximum case size, and level of experience. The quadratic terms for the possibility for the maximum to allow for the possibility of utility problems of a direct relationship the response variable and the terms. 9 number of cases and maximum terms were included and the interaction case size allowed between significant regression An all-subsets terms have influence analysis was performed (i.e., which In this analysis, all possible subsets of regressors are considered to determine which of the terms in the response and a model using each subset. Table 1 shows the results of this analysis, We measure is the adjusted coefficient of multiple of the model by its Rzdj which to explain changes This coefficient measures is between 0%, which in the re- is explained in the model are really variable). is constructed the optimality determination. in the response variable by changes that none of the variation means gressors, and 100% which means by variation model. in the response that all of the variation the RS in the response the more explicative the ability of the model is explained by variation in the regressors. Thus, in the regressors. the larger Its range is the Table 1 shows the best model obtained within each subset of constant size or number the coefficient of variables. R2 shows shows the adjusted coefficient of multiple determination. deviation of the model. The “X” show which variables are included for each size. of multiple determination of that model. Rzdj lo B is the estimated standard in the best model y Among the three interaction terms only CS has physical meaning. The interaction to the system. This is an example of a particularly can influence each other under conditions term CS is a direct difficult of resource measure of the total amount of memory available evaluation limitations. ‘t’ The Rf is the R* adjusted to take into account since different design decisions problem having different number of parameters to be compared. the number of parameters in the model. This allows models 56 A. Ram, J.C. Santamaria/Artifcial Intelligence 90 (1997) 25-77 Table 2 Model coefficients Coefficients PO PE PC Ps PEE PCC Pss &E PSE PCS Table 3 ANOVA table Source Regression Residual Total Value 72.23 -11.92 -5.19 1.97 2.33 2.99 -0.95 -4.32 -0.91 0.74 Std. error P-value 95% Cl. 0.78 0.34 0.34 0.34 0.38 0.42 0.42 0.34 0.34 0.34 0.000 0.000 0.000 0.000 0.000 0.000 0.024 0.000 0.008 0.028 (70.70,73.77) (-12.58,-11.26) (-6.45, -5.13) (1.31,2.63) ( 1.59,3.07) (2.16.3.82) (-1.78,-0.12) (-4.99, -3.66) (-1.57,-0.24) (0.08,1.41) df 9 470 479 SS 100675.7 25543.7 126219.4 MS 11186.2 54.3 F P-value 205.824 7.1E-157 The best model obtained with the all-subsets analysis corresponds as independent results variables ” for each individual parameter to the one having (F = 205.824, P-value = 0.000). in the model as well all nine of the regressors Table 2 shows as the 95% confidence Table 3 shows the statistical the analysis tool that it is used of variance to determine identifies the significance respectively. The fifth column statistical first column show the degrees of freedom source, to determine A high significance explained by variation of the independent this model, calculus Considering using standard model with respect values for C’ and S’ at a given techniques, the relevant parameters value means the optimal interval estimation of its real value. a source of variation, and the second, (ANOVA the sources of variability table). The ANOVA is a table in a model. The third, and fourth columns (df), sum of squares (SS), and mean squared shows the value of the F statistic which of the regression. The sixth column shows that the variation in the response variable (MS) of a is used the P-value. is indeed variables or regressors. i.e., by setting system configuration parameters can be found of the the first partial derivatives to zero. Eqs. (2) and (3) show the optimal level of experience E’. t’ The F statistic is used to determine the significance of the regression. The P-value is the probability determined by F; the lower this value the better the result, since the significance of the regression is ( 1 - P-value) % which is 100% for P-value = 0. A. Ram, J.C. SantantmWArtifcial Intelligence 90 (1997) 25-77 51 Fig. 5. Residual plots. 2&&E - &SkhE g @S - WCCPSS = 0.80 + 0.7X’, c# = 2hSPS P$S - h& - 4PccPss $ 2hd%E - &S/kEE, P& - 4PccPss = 0.05 + 0.4lE’. (2) (3) According to these equations the optimal parameter values change with the level of experience. This is due to the interaction terms that exists among those variables. These equations can be used to determine the optimum configuration of the system for a given situation (see Section 5.5). 5.4. Model validation There are two assumptions that must be verified before accepting the proposed model as a valid model: the residuals have zero mean and constant variance, and the residuals have normal distribution. The least squared error technique relies on these assumptions; since the model coefficients were calculated using this technique we must verify if these assumptions hold. Otherwise, any conclusions derived from the model could be wrong and our understanding of how the factors influence the performance of the system could be misleading. In particular, violation of the assumption about the residuals having zero mean and constant variance could introduce inaccuracy in the estimation of the model coefficients, and violations of the assumption of the residuals being normally distributed could produce underestimation of the confidence intervals (i.e., bigger confidence inter- vals) . A scatter plot of the residuals against the fitted response was used to diagnose changes in variance and a normal probability plot of the residuals can be used to verify the normality distribution of the residuals. The results of each of these two validation techniques are shown in Fig. 5. The left chart in Fig. 5 shows a constant band of residuals along the horizontal axis. Thus, this chart indicates that the variability of the residuals is constant along the fitted values of the response variable (i.e., median time). 58 A. Ram, J.C. Santamaria/Art@cial Intelligence 90 (1997) 25-77 Table 4 Model coefficients Coefficients WJ LYE aEE Value 80.20 -2.86 2.53 Std. error P-value 0.71 0.48 0.55 0.000 0.000 0.000 95% C.I. (78.57,81.47) (-3.84,-1.87) (1.41.3.65) axis. The right chart in Fig. 5 shows a normal probability is not constant, the variability of the residuals the horizontal When along the residuals. value as drawn plot should show a straight we can conclude line from a normal distribution. that the residuals are normal. that crosses the band tends to narrow or widen plot of their expected then the the case, If the residuals are indeed normal, this is actually the origin. Since In this chart, the values of the residuals are plotted against Since the two assumptions, uals having normal distribution residuals with zero mean and constant variance and resid- hold, the model can be considered valid. 5.5. Robustness analysis A second experiment was designed to evaluate the generality of the SINS approach. of SINS (the “best” configu- the only difference being In this experiment, we evaluated a particular configuration ration as determined by the previous analysis) performing under different environmental conditions. The data for the experiment was collected experiment, 20% cluttered world selected using mance of the system around an experience to these conditions, size 11 (S’ = 0.26). in the same manner as the first that the robot solved a fixed randomly generated for the system were the perfor- level E equal to 20 (i.e., E’ = 0.52). Subject cases (C’ = 1.19) of the system was configured using 43 maximum in every run. The configuration in the first experiment the model constructed and to optimize parameters the model that needs to be determined As in the first experiment, time (T) as the response variable. However, variable only with the level of experience, way, if such a model is related experience learns under changing environmental can be compared with the respective coefficients derived nificant difference 15% to 20% affects the learning performance. Eq. (4) shows the complete hypothetical model for the second experiment. has the median in this case, the model relates the response In this since the model shows that the level of that the system still conditions. The coefficient derived from this model in the previous model. If a sig- from the world clutterness is found to the response variable), we can conclude the other factors are constant. is detected, we can conclude to be significant that changing (i.e., T = a0 + aEE’ + aEEE1= + E. (4) is a simplification This model (E’) is included parameter As the inferred model shows, a bigger in the regressor. Table 4 shows the statistical in the model as well as the 95% confidence level results for each individual interval estimation of its value. that the of the model in Eq. (1) where only the experience intercept value is obtained which means A. Ram, J.C. Santamar~a/Art@cial intelligence 90 (1997) 25-77 59 Cases system indeed needs more time to solve a 20% cluttered world. Also, the increased world clutter has a big influence to -2.86. This means (reduce learning it is in the 95% confident the mean rate ( LYEE) does not seem to be influenced by the change of world clutter as fast as in 15% cluttered world. The acceleration from -17.30 the performance that a more experienced (Q), which is reduced level does not improve in the rate of learning interval of PEE). of the (i.e., time) 5.6. Learning projiles if only increases, the above results demonstrate the validity of the SINS approach, to look at the learning profile of the system, it is also to provide an intuitive in the internal behaviors and external performance of the system as While interesting feel for the changes it gains experience. The learning profile of the system can be determined by assessing the number and the size of the cases in the case library as the experience level of the learning system curves based on the system’s and by looking at traditional the number and length of cases against performance. Fig. 6 shows a graph that displays the level of experience It can be seen section. that at early stages of experience cases with small in the time dimension). As the experience sequences to be consistent level increases, only those cases containing extended. are progressively (i.e., sequences of 2 or 3 samples focus on constructing for SINS configured as in the previous that have proven the system sequences Fig. 6 provides an intuitive understanding algorithm observable show based reasoning The externally beled “Median” experience or hand-coded point the graph in and the nature of case learning behavior of the system taken by the actual time high-level knowledge) trial is the median of five of the internals of the continuous and discrimination case- process. la- (starting with no prior on a randomly generated world; each “Fitted T” runs. The graphs is shown the system in Fig. 7. The graphs labeled 60 A. Ram. J.C. Santamada/Artificial Intelligence 90 (1997) 25-77 Fig. 7. Performance profiles showing median time from actual system runs and predicted time using “Fitted T’ empirical models. On the left is the general model over the entire range of configuration parameters and on the right is the specific model fitted to the configuration parameters used in the system runs. shows the predicted performance from the empirical model derived in the previous section along with the error bars for that model. The graph on the left describes the performance model over the entire range of configurations of the design param- eters; whereas a model for any specific configuration can be found using the same methodology, the observed performance of that configuration should fall within the general model as well. The model on the right describes the performance model for the specific configuration used in these runs; this was obtained by redoing the statis- tical analysis for the data obtained from this configuration alone. As shown in Fig. 7, the results demonstrate that the system does indeed improve its performance with ex- perience, and that this improvement is as predicted by the empirical models derived the performance of the system approaches from the statistical analysis. Furthermore, its optimal level around E = 20, as expected from the design decisions discussed in Section 5.5. 5.7. Study 2: choice of input representation and adaptation method Using the above methodology, we performed a second systematic evaluation study to find an empirical model that describes the relationship between the choice of input representation, adaptation method, and system performance as well as the conditions under which the model is applicable. In this study, we evaluated two choices of input representations and two choices of adaptation methods. The input representation refers to the information that the learning and adaptation module of SINS uses to represent and categorize the surrounding environment (situation). The adaptation method refers to the methods by which this module adapts the control parameters suggested by the best matching case to the current situation. The reason for studying choices of input representation is to analyze the influence of the “level of information” provided as input on the performance of the system. One option is to use sensory inputs with “low-level” information. In the navigation domain, this might involve using ultrasonic sensors to measure the distance of the closest obstacle in the direction of the goal. Another option is to use sensory inputs that encode “high-level” information; for example, using an array of ultrasonic sensors A. Ram. J.C. Santamada/Art$cial Intelligence 90 (1997) 25-77 61 input the cases surrounding a measure of the density of obstacles is very specific and may allow SINS to discover to compute type of sensory parameters that similar but not identical generic and may allow SINS to discover good control parameters. However, cases may cases. the robot. The former the best control the robot may use in specific situations. However, we would also expect in is more the learned in most to be very specific and not work as well the system may not perform near-optimally the latter type of sensory turn so coarse learned by the system In contrast, situations. input that information earlier. The low-level that impede navigation Obstacle-Distance-Behind, We studied types the low-level and high-level inputs: Obstacle-Distance-Ahead, and Obstacle-Distance-Left. two choices of input representations: introduced infor- type consists of the follow- Obstacle- Each of these variables provides a measure to, right mation ing four sensory Distance-Right, of the nearest obstacle of, and left of the direction of the perceived goal respectively. The high-level four sensory type consists of the following of the occupied areas around the robot that impede navigation; sures the activity of the system; Relative-Motion over an appropriate system has actually made and constantly (in our case, 24 ultrasonic encoders). information provides a measure ‘* Absolute-Motion mea- the change in motion activity the inputs are computed from the robot’s physical sensors the robot every 15 degrees and shaft the goal. Both types of sensory received interval; and Motion-Towards-Goal specifies how much progress sensors arranged around inputs: Obstacle-Density towards, contrary in the direction the information updated using represents towards that increase by a configuration the control parameters the case most similar new control parameters Another design decision the likehood of obtaining to the current environmental parameter, to the navigation module. To accomplish in SINS is the choice of the adaptation algorithm. Every few and learning module the adaptation steps, as determined this, may recommend situation over a recent it retrieves time window and adapts in use by the navigation module based on the values suggested by the case. The best values for the control parameters would a positive outcome in the next cycle be those the goal or number of towards (as measured by performance metrics such as progress control parameters, SINS must collisions with obstacles). In order to learn appropriate “explore” try several values that is, it must and learn which values produce positive or negative for each environmental for the adaptation method. One option results. This presents at least two design options is to select to the in the past. In this method, values outcome they have achieved likely that have produced positive outcomes is than to be selected to select in the value the past in similar situations. The former adaptation method enforces more exploration and may discover better solutions same reason, that have produced negative outcomes. Another option the best reward the latter one. On the other hand, due to the two those for each control parameter the new values of the control parameters the space of possible parameter the latter method may converge the former. We studied (or obtained positive that has produced stochastically in similar are more according situations rewards) situation values, faster than than I2 Note that this sensory input does not provide any information about the distances or direction of the obstacles; it simply measures the density of occupied area around the robot. 62 A. Ram, J.C. Santamaria/Ar@ciaI Intelligence 90 (1997) 25-77 choices of adaptation method: adaptation stochastic algorithm that lead to positive ing values distribution: P(U) = exp( R,,) / Ci exp( Ri), where Boltzmann for value pected that led to the most positive expected the stochastic method and the select-best method. The but favor- to a the ex- the value the value with largest selects control parameter reward. Specifically, values are selected according adaptation method simply selects the Ri represent in the past (i.e., i. The select-best randomly reward reward values &). As in the previous study, we performed experiments that relates the performance of design decisions combinations model independent (i.e., method, and the experience which parameters were significant residual plots. variables and used it to estimate of the system (i.e., to collect data from all possible of a linear time: T) with the the parameters the median the choice of input representation, level). We used all-subsets the choice of adaptation to determine regression analysis and performed model validation by analyzing the adaptation representations and the stochastic that achieves best performance algorithm For the purposes of brevity, details of this study are omitted here. The results show that the high-level is the one using the system configuration (T = 51.73 seconds at E = 15 representation experiences). High-level of the choice of adaptation method. However, when using the stochastic adaptation method the system adaptation the former provides method the choice better performance of input representations rate or system performance. While (/3 = - 12.79 seconds/experience), there is no interaction between and the adaptation procedures than the latter. Furthermore, although once converged that affects learning time to converge than when using takes a longer the best-value the following to effective independent limitations contribute learning the results are encouraging, plots show that from linearity which is not completely to other worlds. In addition, the residuals do have zero mean, but that the assumption indicates normal probability slight departure and normal distribution these results well the system knowledge a function of the choice of input representation, and other factors of interest. of constant variance valid. Thus, care must be taken to generalize to determine how further research the effect of the in one world on the performance of the system on another world as adaptation method, size of case library, is necessary that is, to investigate its learned knowledge, transfers acquired should be noted. The is a there 5.8. Study 3: experiments with a real robot While simulation allow us to evaluate the system’s performance it is also important experiments range of design decisions and domain characteristics, system works-and learns-with using the actual Denning MRV-III type of input representation the system configured with the high-level trials and measured adaptation method. We ran twenty and the number of virtual collisions. A trial consisted of placing point and let it run until either it reached came a real robot. We performed experiment robot to verify the validity of our approach. We used and the select-best time the robot at the starting the goal or 300 seconds had elapsed, whichever free first. The experiment was performed across a to verify that the room with a rectangular the accumulated in an indoor an additional learning A. Ram, J.C. Santamuria/ArtifciaI Intelligence 90 (1997) 25-77 63 Fig. 8. A picture (left) and a schematic (right) of the robot and its environment. In the schematic, the robot is shown at the bottom of the figure; the hollow circle near the top represents the goal; the black circles represent the static obstacles; and the black bars represent occupied areas that the robot cannot navigate through. 25 x 14 feet and with three circular static obstacles besides space of approximately walls. Two of these obstactles were 55gallon third obstacle was another Denning robot and the laboratory navigable that the shape is irregular. the drums with a diameter of 2 feet and the feet. Fig. 8 shows the room used in the experiment. Note that the boundaries of the the walls so there are desks and chairs against area are not flat; for example, robot with a diameter of 2; the performance of the robot plotted against trials. The in each (left) and the number of virtual collisions the first two trials the robot was not able to reach the destination point and trials, the after five minutes. During its performance. The robot to a final value of about 2 minutes the task successfully taken from over 5 minutes the following and improve the learning terminated (right) Fig. 9 shows the total time graphs show the time taken trial. During both trials were manually robot was able to complete reduced after the first 10 trials, after which reduced the first 15 trials, which produced therefore, taken by the robot in four different summarizes showed a significant The next subsection the number of virtual collisions it did not improve further on this metric. Also, it from about 60 to a steady state of about 10 after the path. The SINS system, along both metrics. Fig. 10 shows the path along jerky movements improvement trials: 1, 5, 10, and 20. the results found in the three studies. 5.9. Discussion of results The performance of SINS is very complex and depends not only on simple also on their interactions. The evaluation to solve a 15% cluttered world decreases mainly with the experience the maximum number of cases also improves in shows that the median term may deteriorate the performance, the performance its quadratic level. Increasing but a positive coefficient the other for big values. On time the system terms but takes 64 A. Ram, J.C. Santamaria/Artificiai InteNigence 90 (1997) 25-77 Fig. 9. Performance of the real robot. Left: total time per trial. Right: number of virtuaI collisions per trial. Fig. 10. Actual path followed by the robot in four different left), and 20 (bottom right). trials: trials 1 (top left), 5 (top right), 10 (bottom A. Ram, J.C. Santamaria/Art$cial Intelligence 90 (1997) 25-77 65 indicates interaction coefficients the maximum linear coefficient case size has a positive that large cases may improve performance indicate hand, coefficient, which small cases. Negative number of cases and case size, the system requires more experiences the more its performance. to store regularities, to construct The performance factor subject realized of SINS is influenced by the world clutter, influence. Finally, in both simulated and real mode. the more the experience this is to be expected the improvement to the greatest is significant Intuitively, required since that for bigger values of maximum to start improving the space available regularities. reliable the learning rate being in performance the that is and a negative quadratic as compared to The results shown above help us verify and understand several aspects of SINS. In particular: l The evaluation l The performance on interactions experience, both in simulation shows that SINS does improve significantly with its performance (Table 2 and Fig. 7) and on an actual robot (Fig. 9). of the system depends on alternative design decisions, as well as among them (Eq. ( 1) and Table 2). l The choice of input representation the performance (Section 5.7). The model allows us to determine and the choice of adaptation method of SINS and there are no interactions indepen- between the best choices influence dently these decisions for these design decisions. l High-level low-level to converge better solutions than the best-value (Section 5.7). input representations provide a better starting point for learning input representations. Also, the stochastic adaptation method adaptation method, but once converged than takes longer it arrives at l The model allows us to determine world for a prespecified level of experience l The results show how a change the performance affects l The analysis shows that using of SINS (Eq. (4)). the proposed the best way to configure SINS in a 15% cluttered (2) and (3) > . characteristics, (Eqs. in the environment namely clutter, in the performance the empirical model can only account actions variability explained by introducing more factors or by changing terms in Eq. ( 1) ; the rest of the variation in the system. in performance factors (C, S, and E) and their inter- (i.e., R*=O.798) of the of the system. Part of the remaining 21.2% could be forms of the the functional for 79.8% is due to the randomness l The empirical model in the second study can only account in the performance of the system. This result for 65.3% of the it is important because variability captures could be explained forms of the terms the limitations by of the derived model. Part of the remaining introducing more in the empirical model used. factors or by changing percentage the functional l When configured with high-level input representations and the select-best adaptation (as suggested by the simulation studies), on an indoor navigation the real robot does improve task with static obstacles its along method navigation different performance metrics and unexpected performance One interesting reinforcement lier, we had hypothesized learning method (Fig. 9). result deserves mention, one which arose out of the ear- reward signal based on consistency would that SINS uses for case adaptation. As discussed that an internal 66 A. Ram, J.C. Santamarta/Artijicial Intelligence 90 (1997) 25-77 models which provide accurate predictions reward signal. However, on the navigation SINS reduced all schema gains to zero; learning. This hypothesis enhance performance to guide be sufficient learns perception-action of its actions even without an external necessarily experiments, turned off all its motor control it went nowhere. While tination point, and might be useful tarily or without an external tem. it is nevertheless in other situations schemas, this is not useful to avoid a moving obstacle). As currently reward signal, depending about it learned task. For example, turned out to be correct; SINS indeed the results these models do not initial in our that if it that to a des- the physical world to stop momen- SINS can be run with the sys- implemented, on the user’s goals observe task of moving if it needed (correctly) the result in using in it would consistently for the particular a “correct” model of action (for example, The above evaluations focussed on the SINS system and the continuous the systematic in particular. However, we believe that used here can be successfully and usefully applied to other machine systems as well. Furthermore, several implications for case-based the continuous reasoning reasoning method methodology ing and case-based reasoning method provides general; reasoning these are discussed next. case-based evaluation learn- case-based theories in 6. Discussion and implications Continuous case-based reasoning is a variation of traditional tasks. The underlying case retrieval, adaptation case-based steps reasoning in the method and and execution, continuous assessment, and SINS systems perform to CHEF [21]. However, a kind of case-based there are several planning, interesting for robotics, to perform situation in that respect are similar that can be used are similar, namely, learning. The ACBARR and differences due to the continuous performance Lemmon’s not intended processing that performs approach combines real-time earlier attempts systems (e.g., our systems, in a tightly knit cycle, similar Ramsey to combine [ 10,391)) which the perception-action the learning [ 201. reasoning is designed and learning tasks. Our approach [ 281 use of case-based is also similar for real-time control. Their system, nature of the domain, and to the on-line nature of the to Kopeikina, Brandau, and though issues of time constrained and the need to represent cases that evolve over time. They suggest a system In contrast, our task in batch mode during off peak hours. reasoning with the on-line, from is also different reasoning think”. reactive control with other types of higher-level to “stop and of case-based In this respect, our research the learning the system the special capabilities to handle typically require aspects of reactive control. task and the adaptation-learning to the “anytime learning” approach of Grefenstette In task are integrated and Our approach the basic case-based methods, we conjecture case-based issues in more detail. reasoning to continuous reasoning case-based introduces reasoning paradigm. Due to the similarity several innovations in the assumptions to and that many of these innovations would be useful systems as well. Let us discuss the underlying case-based in traditional reasoning A. Ram, J.C. Santamaria/Art@cial Intelligence 90 (1997) 25-77 67 6. I. Assumptions underlying case-based reasoning Our approach combines continuous representations, continuous performance, and con- learning conditions would result tinuous that underlie environment under the same environmental outcomes, but such variations By consistent we mean vironmental that the system can use past experience the future and hope to obtain underlying future experiences, are similar mon to many assumption” manner. The third assumption our approach underlying integrated the interaction between framework. There are three basic assumptions the reasoning into a single system and the this approach. First, is causal and consistent. By causal we mean that the same actions executed conditions would result in the same outcomes (or similar are much slower than the execution cycle of the system). the same en- in the executed actions under in the outcomes. This guarantees that small changes in small changes to guide performance in similar situations in the same results from its actions. The second assumption is that the system’s experiences and that the system will usually encounter problem to those that it already has experience with. These assumptions (see, for example, to be typical of situations that are also com- the “typicality they are not always stated explicitly or in this exact traditional of [45] >, although case-based are likely reasoning systems our approach is discussed next. 6.2. Fine-grained representations adaptations. While case-based requires a formal and well-defined is required by the semantic concepts and operations The third assumption is, perhaps, unique two given situations, which also requires a similarity metric between of the necessary our current work, we have assumed titatively. This particular, our method similarity magnitude domains in existing between finitesimally if adequate for example, cess theory), similarity metric representations from each other on a similarity representations symbolic [ 131, for an approach but more research is needed that can compare not just systems are not fine grained enough cases or to place situations of variations continuous reasoning. case-based to continuous l3 In that the problem domain can be represented quan- In the and similarity metric in our method. to judge the direction in non-continuous is used to determine reasoning to determine that could vary continuously for partial matching, most such metrics used the degree of similarity and in- could be relaxed (see, based on qualitative pro- this issue. Furthermore, we require a of situations but and similarity metrics could be developed to continuous into instantaneous scale. This assumption descriptions planning in situations over periods of time. The fine-grained For example, using a rule that recommends in the SWALE system nature of the representations [24,54], as well. pattern may be adapted that a “man” be substituted by a “horse”. Similarly, CHEF is important an explanation in case adaptation that even domains that have traditionally been I3 However, note such as medical domains, may require ROENTGEN continuous attributes. Other domains, such as weather prediction, may also require hybrid symbolic continuous representations; For example, Berger’s therapy plans for patients, uses representations system, which is used to used design radiation reasoning with continuous see, for example, representations, representations. treated using symbolic [22]. [ 81 of 68 A. Ram, J.C. Santamanh/Arti$cial Intelligence 90 (1997) 2.5-77 representations of the two concepts; SWALE, that would be part-way between [ 2 1 ] might substitute “chicken” between the symbolic not invent a “man-horse” and “horse”. The continuous modifications able power to the system. This assumption, for constructive (see, for example, scope of traditional [40], but currently “discrete” case-based for “beef” in a recipe. But neither system can interpolate for example, can of “man” fine-grained consider- if adequate algorithms and modification were to be developed the implementation), too, could be relaxed this ability of the SINS system systems. representations the limits of the computer used in SINS permit arbitrarily concept creation, its representations interpolation, is outside providing reasoning (within 6.3. Time history representations Our methods represent a novel approach to case-based reasoning for a new kind of Furthermore, and continue this evaluation must be done using to a reactive control system, unlike on-line performance. The system must continuously task, one that requires continuous, evaluate its performance, on the current environment. features available perceptual features or abstract world models used many case-based a continuous the time course of these features over suitably are retrieved on the basis of a similarity metric current learned, on the basis of the system’s experiences. Additionally, reasoning case-based continuously while simultaneously to adapt the solution or seek a new one based the simple thematic in requires that represent time windows. Relevant cases the recent history of the in the case library; cases are adapted, and new cases in any in SINS are learned and modified in such task domains features, to retrieve cases and adaptation chosen that compares reasoning representation system, case representations being used to guide action. in terms of the available situation with the cases systems. Case-based as is desirable the complex of cases, strategies reasoning improvement [ 601, do represent to learn time history is the first AI system To our knowledge, SINS reasoning of (discrete) some case-based sequences is a significant systems. Whereas over previous case-based systems, they do not use the recent history of the current situation representations; reasoning or inductive [ 211 such as CHEF in their to these is not integrated with in the latter is not used in the former such as conceptual Similarly, clustering. input examples based on feature clustering lists but not on descriptions In effect, SINS can be thought of as learning this ability learning or PRODIGY cases, cases. Because the perceive-act for retrieval or temporal [ 161 classify COBWEB of how these associative or classificatory a situation but of the recent history of a situation. the retrieve-adapt-apply the progression loop, events and states as an index is not merely a description of rules in which an antecedent cycle of events features vary over in these systems systems time. 6.4. Abstract cases In a traditional, symbolic abstraction of one. For example, cases in CHEF the program. In a continuous histories of real parametric an actual experience or an [21] represent actual recipes created by domain, however, an actual experience consists of the time and control parameters. For example, values of perceptual task domain, a case represents A. Ram, J.C. Santamda/Art$icial Intelligence 90 (I 997) 25-77 69 some starting in propioceptive experience might location on a two-dimensional involve location of (6.71m, 10.98m) a navigational grid, and a destination same grid. The experience might consist of the values of perceptual parameters as the current position of the goal with respect of real numbers), (an integer), such as minimum robot parameters vary continuously time graphs of each of these parameters. Clearly, time history of each of these parameters it useful coordinates on that such (an x,y coordinate pair vicinity of the robot sensed to the nearest obstacle, and control parameters (in meters), the speed of the (in radians). These is represented by to store the entire that the robot solves, nor is or the current heading of the robot over time; thus the complete experience number of obstacles in meters to the robot in the immediate safe distance of approach (in meters per second), for each problem it is not feasible or the distance to an obstacle to do so. I4 Thus SINS learns and stores some abstraction that CHEF actually does the same, since an actual cooking (such as looking at the frying pan and judging whether enough) and control output of the actual experience. One might experience would the to the spatula (such as moving the experiences have already been abstracted in our the actual form. One of the open representations issues from in the pot). and represented In CHEF, in symbolic input have browned argue involve perceptual ingredients stir the ingredients by the programmer research continuous is the automatic experiences extraction of such symbolic [ 30,441). (e.g., of the system 6.5. Virtual cases is likely the system task domains in infinitely many ways, and differences A related, but different, problem with continuous the power of a case-based to have a representative is that an experience can range from signif- to infinitesimal. Only a tiny fraction of all possible experiences will actually be reasoning system comes library of cases that will the idea that the system could well to remember all the of each experience, or some to create to the abstraction process described earlier, with the an abstract or generalized can differ from another icant undergone by the system. However, from its cases, and so it is desirable cover the range of experiences of a virtual case, which represents a representative have had but may or may not actually have had. Rather details abstraction of these details, SINS combines past cases and present experiences a virtual experience. This is similar difference of an actual experience of but rather a virtual experience derived several actual experiences. A virtual case can be thought of as an “average” or “proto- in the space of typical” experience-a experiences to the grain size defined by the programmer) that a virtual case does not represent that represents all the points to encounter. We introduce that are close enough from a combination to the centroid. in a region than trying description experience centroid (down One problem with virtual cases is that usually there isn’t enough a priori information about where such centroids region centroids and boundaries should be located or how big the regions should be; thus, are are learned with experience. Since experiences I4 However, if the range of allowable variations of perceptual and control parameters is bounded by the nature of the task, such a “memory-based approach” may be in fact be feasible 161. 70 A. Ram, J.C. SantamarLa/Art@cial Intelligence 90 (1997) 25-77 sequentially, undergone manner. This means also on alterations from standard case-based a generalization content of a case (but cf. [45] ). cases must be learned and adapted progressively in an on-going the content of a case depends not only on a past experience, but similar experiences. This approach deviates reasoning where each case contains a previous experience or the of a previous one and future similar experiences introduced by subsequent do not modify The notion of a virtual case might be useful as well. To take a simple example, AQUA based on new experiences not be “true” of a single experience, these hypotheses reasoning, are more sophisticated since algorithms systems cases that may or may in future If used could be viewed as virtual cases. SINS’s virtual cases through use; the refinement they are continuously are also different, as discussed below. in symbolic case-based learns about and updates existing in hypotheses but are useful and plausible. [ 451. This process reasoning refined results 6.6. Dynamic memory to make cases “converge” to useful requires on-going problem solving is used to guide problem solving at learning in SINS are designed over the result time as it is being organized algorithms time. Since this learning process is that the system’s memory The regularities experiences, the same and usefulness. Cases experiences and may or may not be useful been used more often may contain virtual experiences refinement mechanisms associations. These cases are usually more reliable that guide cases in solving that have not been used often may contain into cases having several degrees of reliability actual navigational since future problems. Cases that have to the they are exposed and useful sequences of future problems. towards consistent in solving conceptual Thus, the representations and methods used in SINS allow it to incorporate into a single representation relative sensorimotor that are new and useful to the system successive in a gradual and incremental manner, and to each other. This has two implications. change to create higher-level, [ 441. Second, SINS implements similar experiences to differentiate these representations that consists of First, SINS carries out a process of constructive strategic set of low-level, using an original a kind of concepts (as in Schank’s MOPS), dynamic memory are formed that are consistent with each other (as in Schank’s example of visits to a dentist and to a doctor). The virtual cases in SINS can be thought experiences. Part of the learning process of as dynamic is to organize memory to the task at hand, and to use these concepts aggregates and to use them to act successfully; memory and a basis for most case-based [ 531 in which aggregate memory structures constructed tenet of dynamic into concepts to interpret that are relevant and useful in terms of the internally to organize experiences this is a fundamental the environment of prototypical reconstructions reasoning concepts systems. 6.7. Two types of behavior modification As discussed earlier, our systems use case-based reasoning (behavior cations selection) adaptation). The knowledge as well as to suggest more local modifications for both kinds of suggestions required to suggest global modifi- (behavior are stored in a case, A. Ram, J.C. Santamaria/Arti$cial Intelligence 90 (1997) 25-77 11 In many problem domains, even non-continuous case-based and a separate in contrast with traditional suggest solutions, fit the current problem. (or other types of problem solving) [ 361. In such situations, case-based tion) as well as continuously refine is that cases trajectory, but of the reactive control module the proposed trajectories. reasoning library of adaptation systems in which cases are used only to to rules is used to adapt a solution ones, planning cannot be performed separately from plan execution (or solu- can be used to propose a plan reasoning it during execution. Another difference of interest not directly of the plan or to itself which then result in modifications in ACBARR and SINS propose modifications, 6.8. Two types of adaptation systems reasoning Traditional case-based retrieve cases and adapt the solutions pro- posed by those cases in order to provide new solutions to new problems at hand. How- ever, in order to build virtual cases, our systems also need to adapt the cases themselves case modification is similar in response to using a case to deal with a new situation, process the system can use an experience to new experiences. This in that, in addition to the incremental in AQUA [45] to learn more about its existing cases. represent its experience. These provide environmental cases through in future situations. Cases are used for behavior adaptation; this can be viewed as the process of using terms, In our problem domain, reasoning case-based the system by to navigate identified necessary standard recommendations by the system. In addition, can be viewed as a process of discovery the world around it. The system “explores” traverse this space and find good “niches” could be viewed as a process of “solution modification”. regularities that have been the predictive power in the currently being pursued this through experience; the system develops a model of in which the search space as its case representations representing adaptation”, regularities. The former process and the latter as one of “case provided by the case to adapt the solutions can be adapted themselves cases [ 561, whose system uses a trial-and-error The particular method of case modification used of Sutton develop a world model and to plan optimal routes using although there are differences as discussed earlier. In general, we hypothesize in other modification may be useful although different methods may need AQUA’s incremental to SWALE’s solution adaptation reasoning types of case-based to be developed the modifications. to perform for example, can be viewed as such an extension to that to the evolving world model, that case systems as well, in our system reinforcement case modification, is similar [ 24,541. strategy learning Different criteria may also need to be developed to fit the new experience, when to learn a new case to represent when to use the case for solution adaptation but without modifying a relative approach was discussed earlier. We believe case-based enough represented for deciding when to modify a case the new experience, and it. Our system uses this that a similar approach can be used in other is different the information systems as well to determine whether a new experience it should be used to modify in the best available case. its own case or whether the intuition behind to identify potential similarity measure regularities; reasoning to merit 72 A. Ram, J.C. SantamarIa/Art@cial Intelligence 90 (1997) 25-77 6.9. On-line real-time response Unlike traditional case-based reasoning systems which [ 211)) and unlike other machine (e.g., analysis trol systems which fall back on non-reactive the system compared however, continuous are inherently to continue to perform case-based continuous and require continuous to a “pure” reactive control system. Even if real-time is not required, reasoning could still be used in problem domains which response representations. learning augmentations (e.g., reasoning rely on deep reasoning and to reactive con- [ lo] ) , our method allows overhead as reactively with very little performance 6.10. Adaptive reactive control and robot navigation demands, to reactive control than of single or multiple Our research also contributes for autonomous for the use of assemblages rather robots in the follow- tailored of behaviors be- these behaviors dynamically without for each nav- ing ways. One, we propose a method to particular environmental haviors. Two, our systems can select and adapt relying on the user to manually program igation problem. Three, is automatically our system exhibits considerable forms well and so on, without any reconfiguration; of environment on the case-based [47,48]. required through experience using multiple for behavior selection and modification learning methods. Finally, it per- in uncluttered worlds, highly cluttered worlds, worlds with box canyons, the results of learning in one kind In this article, we have focussed in furthermore, to other environments. aspects of our work; robot control flexibility over multiple domains. For example, the correct behavioral parameters transfer well reasoning issues are discussed the knowledge independent acquired Our research also contributes to and extends related work on behavior coordination. in Mataric’s [35] approach, in order to use because it learns the robot learns a topological map of land- it for future planning. The robot performs better in the terrain the current to get from and module activations the spatial arrangements to activate appropriate modules the mappings between conditions of landmarks that knowledge to the goal. However, under which at design in our method time. In contrast, to change control parameters the are those conditions. However, our approach does not allow the robot to learn informa- as perceived by the conditions under which module activation of the robot’s learns both and which control parameters surroundings immediate the robot information; is indexed are descriptive in a terrain For example, marks with experience and then uses position are precompiled conditions suitable under a map or landmark tion the robot. More research is needed to combine map learning approaches with navigational such as ours. Although maps can help in path planning, approaches to the terrain in which In contrast, although navigational egy learning are specific terrain changes. guidance strategies a robot might should slow down and navigate more carefully is not specific for path planning, to the terrain the robot in which learn they are robust across is that when obstacle density starts increasing terrains. For example, one of the the robot to avoid a collision. This it is learned. On the other hand, information if the terrain is trained and must be relearned strategies do not provide higher-level strat- they if the A. Ram, J.C. Santamar~a/Art$cial Intelligence 90 (1997) 25-77 13 a landmark-based is indeed available, information obstacle cluster altogether. One approach maps (and map learning local navigational navigation techniques) strategies once a global route has been planned. to combining to provide (and associated learning approach might be able to avoid the these techniques might be to use guidance, and the actual larger-scale navigational techniques) to perform Other approaches have focused on learning the mapping between situations and co- to update this information, feedback situations, the behaviors (or negatively between modules, [ 341 use experiences in which reinforcement correlated with negative the current situation. This approach rewards. Using to be positively and external that have proven correlated with feedback) with past situations ordination of behaviors. For example, Maes and Brooks correlations the robot selects only positive that match do other approaches through learn useful behavior and that of Maes and Brooks sensation disambiguate between different are used to since there and control parameters over a create cases time window. This allows the system to select the best control parameters based not only on the current with which is no history of the recent past. In our approach, experiences that capture feedback. One difference between our approach to reward is that in their approach that produce input but on the recent history of inputs which provides more information the robot may not be able the same perceptual in common with ours, as are used to shares much learning and similar to learn and select appropriate control parameters. between conditions regularities techniques situations 7. Conclusions We have presented control system reinforcement implemented analysis, a novel method case-based for augmenting reasoning for on-line case learning that combines learning and has been evaluated through extensive the performance of a reactive for on-line parameter adaptation and is fully and adaptation. The method statistical simulations, rigorous and actual implementation The power of the method derives on a robot. from its ability to capture common environmental the environment and regularities in the interaction between reactive control system because configurations through an on-line, adaptive process. The method adds considerably and flexibility of the underlying select and utilize different behaviors as appropriate to perform these functions SINS can be characterized in which it constructs higher-level actions is acquired automatically as performing situation at hand; furthermore, a kind of constructive for the particular from low-level (i.e., different representations representations sensorimotor sets of schema parameter values) required the knowledge through experience. change inter- representational (cases) of system-environment by the system and the system to the performance it allows the system to [ 441. the adaptation-learning task and to the “anytime and action are required learning” approach of Grefenstette so that the system can explore In SINS, the perception-action [20]. Perception in a tightly knit cycle, similar Ramsey environment derlying performance generalize these regularities and detect regularities; they also, of course, form task, that of navigation. Adaptation and provide predictive suggestions and learning task are integrated and its the basis of the un- to based on prior expe- are required 74 A. Ram, J.C. Santamaria/Art@cial Intelligence 90 (1997) 25-77 rience. Both the system while allowing manner. tasks occur simultaneously, progressively improving the performance of it to carry out its performance task in a continuous, on-line to work on the problems on which analysis presented here did not focus on that component is needed to determine studies, in continuous through simulation the extent of its cases dynamically, in our research. While we have been able the size domains but tested, of SINS and the generality of that aspect of the algorithm. the number of cases it has been issues There are still several unresolved appropriate time windows [27]. SINS can adjust issue the method appears for SINS to represent extended experiences to determine or extent of the cases needed is still an open although the systematic more research Furthermore, the retrieval process that the system can handle without deteriorating leading is to place an upper bound on the number of cases allowed solution would be to develop a method conventional memory organization [ 271) assume structured, nominal varying, analog schemes used in case-based (e.g., information to a kind of utility problem [ 17,381. Our current is very expensive for organization information performance, to this problem solution in the system. A better of cases in memory; however, (see time systems [ 141) rather than continuous, reasoning and limits the overall navigational of the kind used in our cases. is that of the nature of the regularities Another open issue of the methods, but also for possible is desirable, Interpretation learning methods tem’s cases. While SINS’ cases do enhance not only interpret. understanding ing and schema parameter values or modifying explanation-based vide better suggestions the best schema parameter This requires a symbolic cases. for these values, understanding into in integration of higher-level captured they are not easy its performance, for the purpose of obtaining the sys- to a deeper reason- initial trial and error, an could pro- thus speeding up the search process of finding situation. in the system’s instead of guessing through of the knowledge environment represented the system. For example, incrementally them module working on top of the case adaptation module values associated with a particular these SINS Despite limitations, is a complete and autonomous navi- gation system, which can interact with its environment without user input and without in its reactive control “domain knowledge” other than that implicit any pre-programmed its task, it builds a library of experiences schemas. As it performs its learning, Since the system performance. changes as well as fine tune situations. it can cope with major environmental in static and specific environment is always its navigation module that help it enhance self-improving Acknowledgements This research was supported by the Army Research Laboratory and by the Georgia Institute of Technology. We thank Ron Arkin, Kenny Moot-man, and Russ Clark for their the entire help with the ACBARR system and for their many useful suggestions during course of this research, and Anthony Francis, Mark Devaney, and anonymous reviewers for their helpful comments on earlier drafts of this paper. A. Ram, J.C. Santamaria/Artijicial Intelligence 90 (1997) 25-77 75 References [ I] D.W. Aha, Generalizing from case studies: a case study, in: Proceedings Ninth International Conference of Machine Learning, Aberdeen (1992) l-10. [2] P Agre and D. Chapman, Pengi: an implementation of a theory of activity, in: Proceedings AAAI-87, Seattle, WA (1987) 268-272. [ 31 R.C. Arkin, Motor schema-based mobile robot navigation, [4] R.C. Arkin and D.C. MacKenzie, Temporal coordination IEEE Trans. Rob. Autom. 10 (1994) 276-286. navigation, Int. J. Rob. Res. 8 (4) of perceptual algorithms (1989) 92-l 12. for mobile robot [ 5 ] K. Ashley and E. Rissland, Compare and contrast, a test of expertise, in: Proceedings AAAI-87, Seattle, WA (1987)273-284. [ 6 ] C.G. Atkeson, Memory-based learning in intelligent control systems, in: Proceedings 1990 American Control Conference, San Diego, CA (1990) 988. [ 71 T. Balch, G. Boone, T. Collins, H. Forbes, D. MacKenzie and J.C. Santamarfa, 10, Ganymede, and Callisto: a multiagent ] S] J. Berger, ROENTGEN: robot janitorial radiation team, AI Magazine 16 (2) ( 1995) 39-51. therapy and case-based reasoning, in: Proceedings Tenth Conference on ArtijZal Intelligence for Applications, San Antonio, TX ( 1994) 171-177. 191 R. Brooks, A robust layered control system 1 10 1 S.A. Chien, M.T. Gervasio and G.F. DeJong, On becoming decreasingly for a mobile robot, IEEE J. Rob. Autom. 2 (1986) 14-23. to deliberate reactive: learning minimally, 288-292. in: Proceedings Eighth International Workshop on Machine Learning, Chicago, IL ( 199 I ) [ 1 I] P.R. Cohen and A.E. Howe, How evaluation guides Al research, AI Magazine 9 (4) [ 121 P.R. Cohen and A.E. Howe, Towards AI research methodology: three case studies (1988) 35-43. in evaluation, f.EEE Trans. Syst. Man Cybern. 19 (1989) 634-646. [ 13 ] G.F. DeJong, Learning [ 141 E.A. Domeshek, Do the right thing: a component thesis, Department of Computer Science, Yale University, New Haven, CT ( 1992). to plan in continuous domains, Artif: Intell. 65 ( 1994) 71-141. theory for indexing stories as social advice, Ph.D. [ I5 I R.E. Fikes, P.E. Hart and N.J. Nilsson, Learning and executing generalized robot plans, Artif Intell. 3 (1972) 251-288. [ 161 D. Fisher, Knowledge acquisition via incremental conceptual clustering, Mach. Learn. 2 (1987) 139-172. [ 171 A. Francis and A. Ram, Computational models of the utility problem and their application to a utility in: Proceedings ML-93 Workshop on Knowledge Compilation and reasoning, analysis of case-based Speedup Learning, Amherst, MA ( 1993). ] 181 M. Georgeff, Planning, Ann. Rev. Comput. Sci. 2 (1987) 359-400. [ 191 A. Goel, A. Khaled, M. Donnellan, A. Gomez De Silva and T. Callantine, Multistrategy adaptive navigational [ 201 J.J. Grefenstette path planning, IEEE Expert 9 (6) ( 1994) 57-65. Conference on Machine Learning, Aberdeen to anytime ( 1992) 189-195. and C.L. Ramsey, An approach learning, in: Proceedings Ninth International [21] K.J. Hammond, Case-Based Planning: Viewing Planning as a Memory Task, Perspectives in Artificial Intelligence (Academic Press, Boston, MA, 1989). 1221 E.K. Jones and A. Roydhouse, Intelligent retrieval of archived meteorological data, IEEE Expert 10 (1995) 6. [ 23 I L. Kaelbling, Learning in Embedded Systems (MIT Press, Cambridge, MA, 1993). [24 ] A. Kass, Tweaker: old explanations C.K. Riesbeck, 295. in: R.C. Schank, A. Kass and to new situations, eds., inside Cuse-Based Explanafion (Lawrence Erlbaum, Hillsdale, NJ, 1994) 263- adapting [ 25 j D. Kibler and P. Langley, Machine Working Session on Learning, Glasgow learning as an experimental (1988) 81-92. science, in: Proceedings Third European [26] J.L. Kolodner, R.L. Simpson and K. Sycara, A process model of case-based reasoning in problem solving, in: Proceedings IJCAI-85, Los Angeles, CA ( 1985) 284-290. I 271 J.L. Kolodner, Case-Based Reasoning (Morgan Kaufmann, San Mateo, CA, 1993). ]28 1 L. Kopeikina, E. Brandau and A. Lemmon, Case-based reasoning for continuous control, Workshop on Case-Based Reasoning, Clearwater Beach, FL ( 1988) 250-259. in: Proceedings 76 A. Ram, J.C. Santamaria/Artificial Intelligence 90 (1997) 25-77 1291 B.J. Kuipem, A qualitative approach to robot exploration and map learning, in: Proceedings AAAI Workshop on Spatial Reasoning and Multi-Sensor Fusion, St. Charles, IL ( 1987) 390-404. [30] B.J. Kuipers and Y-T. Byun, A robust, qualitative method for robot spatial learning, in: Proceedings AAAI-88, St. Paul, MN (1988) 774-779. [ 3 I] D. Langer, J.K. Rosenblatt and M. Hebert, A behavior-based system for off-road navigation, IEEE Trans. Rob. Autom. 10 (1994) 776-783. [32] D.B. Leake, Learning adaptation strategies by introspective reasoning about memory search, in: Proceedings AAAI-93 Workshop on Case-Based Reasoning (AAAI Press, Menlo Park, CA, 1993) 57-63. [33] F? Maes, Situated agents can have goals, Rob. Autonom. Syst. 6 ( 1990) 49-70. [34] F? Maes and R.A. Brooks, Learning to coordinate behaviors, in: Proceedings AAAI-90, Boston, MA ( 1990) 796-802. [ 351 M.J. Matzuic, Environment learning using a distributed representation, in: Proceedings IEEE Conference on Robotics and Automation ( 1990) 402-406. [36] D. McDermott, Planning and acting, Cognit. Sci. 2 (2) (1978) 71-109. [ 371 S. Minton, Learning effective search control knowledge: an explanation-based approach, Ph.D. thesis, Tech. Rept. CMU-CS-88-133, Computer Science Department, Carnegie-Mellon University, Pittsburgh, PA (1988). [38] S. Minton, Quantitative results concerning the utility of explanation-based learning, Art@ Intell. 42 ( 1990) 363-39 1. [ 391 T.M. Mitchell, Becoming increasingly reactive, in: Proceedings AAAI-90, Boston, MA ( 1990) 105 I- 1058. [40] K. Moorman and A. Ram, A model of creative understanding, Proceedings AAAI-94, Seattle, WA (1994) 74-79. 1411 J. Mostow and N. Bhatnagar, FAILSAFE-a floor planner that uses EBG to learn from its failures, in: Proceedings IJCAI-87, Milan (1987) 249-255. [42] S. Pandya and S. Hutchinson, A case-based approach to robot motion planning, in: Proceedings 1992 IEEE International Conference on Systems, Man, and Cybernetics, Chicago, IL (1992) 492-497. [ 43 ] D. Payton, An architecture for reflexive autonomous vehicle control, in: Proceedings IEEE Conference on Robotics and Automation, San Francisco, CA ( 1986) 1838-1845. [44] A. Ram, Creative conceptual change, in: Proceedings Fifteenth Annual Conference of the Cognitive Science Society, Boulder, CO ( 1993) 17-26. [45] A. Ram, Indexing, elaboration & refinement: incremental learning of explanatory cases, Mach. Learn. 10 (1993) 201-248. [46] A. Ram, R.C. Arkin, G. Boone and M. Pearce, Using genetic algorithms to learn reactive control parameters for autonomous robotic navigation, Adapt. Behav. 2 ( 1994) 277-305. [47] A. Ram, R.C. Arkin, K. Moorman and R.J. Clark, Case-based reactive navigation: a case-based method for on-line selection and adaptation of reactive control parameters in autonomous robotic systems, Tech. Rept. GIT-CC-92/57, College of Computing, Georgia Institute of Technology, Atlanta, GA ( 1992). [48] A. Ram and J.C. Santamaria, Multistrategy learning in reactive control systems for autonomous robotic navigation, Informatica 17 (1993) 347-369. [49] C.K. Riesbeck and R.C. Schank, Inside Case-Based Reasoning (Lawrence Erlbaum, Hillsdale, NJ, 1989). [ 501 S.J. Rosenschein and L. Kaelbling, The synthesis of digital machines with provable epistemic properties, in: J. Halpem, ed., Proceedings Conference on Theoretical Aspects of Reasoning about Knowledge, Monterey, CA ( 1993). [ 5 1 ] E.D. Sacerdoti, A Structure for Plans and Behavior (Elsevier, New York, 1977). [52] J.C. Santamaria and A. Ram, Systematic evaluation of design decisions in case-based reasoning systems, in: Proceedings AAAI-94 Workshop on Case-Based Reasoning, Seattle, WA ( 1993) 23-29. [ 531 R.C. Schank, Dynamic Memory: A Theory of Learning in Computers and People (Cambridge University Press, New York, 1982). [54] R.C. Schank, Explanation Patterns: Llnderstanding Mechanically and Creatively (Lawrence Erlbaum, Hillsdale, NJ, 1986). A. Ram, J.C. SanramaridArtifcial Intelligence 90 (1997) 25-77 II [ 551 A.M. Segre, Machine Learning of Robof Assembly Plans (Kluwer Academic Publishers, Norwell, MA, 1988). [56] R.S. Sutton, Integrated architectures dynamic in: Proceedings Seventh International Conference on Machine Learning, Austin, TX for learning, planning, and reacting based on approximating programming, (1990) 216-224. [ 571 R.S. Sutton, ed., Special Issue on Reinforcement Learning, Mach. Darn. 8 (3-4) [SS] R.S. Sutton, A.G. Barto and R.J. Williams, Reinforcement ( 1992). in direct adaptive optimal control, learning in: Proceedings American Control Conference, Boston, MA (1991) 2143-2146. [ 591 E.L. Thorndike, Animal Intelligence (Hafner, Darien, CT, 19 I 1). 1601 M. Veloso and J.G. Carbonell, Derivational analogy in PRODIGY: automating case generation, storage, and retrieval, Mach. Learn. 10 (1993) 249-278. [ 6 I ] PP.M.J. Verschure, B.J.A. Kriise and R. Pfeifer, Distributed structured behavior, Rob. Autonom. Sysf. 9 ( 1992) 18 l- 196. adaptive control: the self-organization of 1621 C.J.C.H. Watkins, Learning from delayed rewards, Ph.D. thesis, University of Cambridge, Cambridge (1989). 