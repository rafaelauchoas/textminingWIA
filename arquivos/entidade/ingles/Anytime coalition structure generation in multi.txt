Artificial Intelligence 186 (2012) 95–122Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAnytime coalition structure generation in multi-agent systems withpositive or negative externalitiesTalal Rahwan a,∗,1, Tomasz Michalak a,b,1, Michael Wooldridge c, Nicholas R. Jennings a,da School of Electronics and Computer Science, University of Southampton, Southampton SO17 1BJ, UKb Institute of Informatics, University of Warsaw, Warsaw 02-097, Polandc Department of Computer Science, University of Liverpool, Liverpool L69 3BX, UKd Department of Computing and Information Technology, King Abdulaziz University, Saudi Arabiaa r t i c l ei n f oa b s t r a c tArticle history:Received 2 February 2011Received in revised form 29 October 2011Accepted 17 March 2012Available online 29 March 2012Keywords:Mechanism designClassificationGame theoryApproximationMuch of the literature on multi-agent coalition formation has focused on CharacteristicFunction Games, where the effectiveness of a coalition is not affected by how the otheragents are arranged in the system. In contrast, very little attention has been given to themore general class of Partition Function Games, where the emphasis is on how the formationof one coalition could influence the performance of other co-existing coalitions in thesystem. However, these inter-coalitional dependencies, called externalities from coalitionformation, play a crucial role in many real-world multi-agent applications where agentshave either conflicting or overlapping goals.Against this background, this paper is the first computational study of coalitional gameswith externalities in the multi-agent system context. We focus on the Coalition StructureGeneration (CSG) problem which involves finding an exhaustive and disjoint division ofthe agents into coalitions such that the performance of the entire system is optimized.While this problem is already very challenging in the absence of externalities, due to theexponential size of the search space, taking externalities into consideration makes it evenmore challenging as the size of the input, given n agents, grows from O (2n) to O (nn).Our main contribution is the development of the first CSG algorithm for coalitional gameswith either positive or negative externalities. Specifically, we prove that it is possible tocompute upper and lower bounds on the values of any set of disjoint coalitions. Buildingupon this, we prove that in order to establish a worst-case guarantee on solution quality itis necessary to search a certain set of coalition structures (which we define). We also showhow to progressively improve this guarantee with further search.Since there are no previous CSG algorithms for games with externalities, we benchmarkour algorithm against other state-of-the-art approaches in games where no externalitiesare present. Surprisingly, we find that, as far as worst-case guarantees are concerned, ouralgorithm outperforms the others by orders of magnitude. For instance, to reach a boundof 3 given 24 agents, the number of coalition structures that need to be searched by ouralgorithm is only 0.0007% of that needed by Sandholm et al. (1999) [1], and 0.5% of thatneeded by Dang and Jennings (2004) [2]. This is despite the fact that the other algorithmstake advantage of the special properties of games with no externalities, while ours doesnot.© 2012 Elsevier B.V. All rights reserved.* Corresponding author.E-mail address: tr@ecs.soton.ac.uk (T. Rahwan).1 Both Talal Rahwan and Tomasz Michalak are principle authors of this paper.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.03.00796T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–1221. IntroductionThe ability to create effective coalitions is one of the key goals of multi-agent systems research. Coalitional games aremodels that capture opportunities for cooperation by explicitly modeling the ability of the agents to take joint actions asprimitives [3]. In this context, one of the key challenges is to generate a coalition structure, i.e., an exhaustive and disjointdivision of the set of agents, such that the performance of the entire system is optimized. This Coalition Structure Generation(CSG) problem has received much attention in the multi-agent system literature [4,1,5,2,6].(cid:3)To date, work on the CSG problem in the AI community has focused primarily on a class of coalitional games known asCharacteristic Function Games (CFGs), where the effectiveness, or value, of a coalition is not affected by the way non-membersare partitioned. There are, however, many settings where this assumption does not hold. Such settings are known as PartitionFunction Games, or PFGs [7]. Specifically, in PFGs a coalition’s value may be influenced by the formation of another coalition(cid:3) = {C1, C2 ∪ C3}, the value of C1 may bein the system. For instance, given two coalition structures: CS = {C1, C2, C3} and CSdue to the merger of C2 with C3. Such an effect is known as an externality from coalition formationdifferent in CS than in CSand, in this example, it is induced upon C1 by the merge of C2 and C3, which leads to the formation of coalition C2 ∪ C3.2Games with externalities have been widely studied in economics and other social sciences, where interdependenciesbetween coalitions play an important role. Examples include collusion in oligopolies, where cooperating companies seekto undermine the competitive position of other firms in the market, as well as various forms of international (macro-economic/environmental) policy coordination between countries [8,9]. For instance, when high-tech companies decide tocooperate in order to develop a new technology standard, other companies lose some of their competitive position, i.e., theyare subject to negative externalities. For instance, in the 1970’s, Japanese firms established the Very Large Scale Integration(VLSI) consortium as well as the Fifth Generation Computer Systems (FGCS) project [10]. Another example is the decisionby one group of countries to reduce pollution, which has a positive impact on other countries or regions, i.e., it inducespositive externalities (see, e.g., Finus [11], Yi [10]).The issue of externalities is also becoming increasingly important in domains in which multi-agent system techniques areapplied. In e-commerce, for example, the British company, Aerogistics,3 enables small- and medium-size aircraft componentmanufacturers and service providers to form online, ad hoc supply-chain coalitions to bid for manufacturing projects toolarge for any individual participant. Since all components must ultimately conform to the same standards, the cost ofstandarization procedures incurred by any coalition depends on the number and structure of other winning coalitions.In many multi-agent systems, negative externalities between a coalition and non-members can be caused by sharingresources [12,1]. Thus, if agents, after forming a coalition, consume more resources than before, then this means thatfewer resources are now available to the other coalitions. This is the case, for instance, in congestion games [13]. Negativeexternalities can also be caused by conflicting goals. Intuitively, by satisfying its own goals, a coalition may actually movethe world further from the other coalitions’ goals [14]. Conversely, overlapping or partially overlapping goals may causepositive externalities as some coalitions may satisfy goals of other coalitions [1].In spite of so many important applications, very little attention has been given to the computational aspects of gameswith externalities. In particular, there exist no algorithms in the literature to solve the CSG problem in PFGs. To this end, itshould be noted that the space of possible solutions to the CSG problem is the same for both CFGs and PFGs, with O (nn)solutions for n agents. The main difference, however, lies in the size of the input, which is O (2n) for CFGs, but O (nn) forPFGs. This is because, for every coalition, the input contains a single value — representing its performance — in the CFG case,while in the PFG case it contains as many values as there are possible partitions of the agents outside that coalition (seeSection 2 for more details). This makes the CSG problem significantly more challenging compared to the CFG case, which isalready NP-complete [1]. In fact, it can easily be shown that for the general case of PFGs it is not possible to solve the CSGproblem without examining every possible coalition structure. Intuitively, even if all but one have been examined, this lastone may be arbitrarily better than the rest.Against this background, we focus on two important classes of PFGs:+• PFG— coalitional games with weakly positive externalities. In this class, externalities are always non-negative, i.e., themerge of any two coalitions is never detrimental to other coalitions in the system.−• PFG— coalitional games with weakly negative externalities. Here, all externalities are non-positive, i.e., the merge ofany two coalitions is never beneficial to other coalitions in the system.4It should be stressed that nearly all the examples of coalitional games with externalities that are listed above belong toeither one or the other class! Specifically, cartels, environmental policy coordination between countries, and multi-agent+systems with partially overlapping goals are all games with positive externalities. That is, they belong to the class PFG.Conversely, collusion in oligopolies, exogenous coalition formation in e-market places, as well as multi-agent systems withshared resources and/or conflicting goals all belong to the PFGclass.−2 In the remainder of this paper we will refer to coalitional games as, simply, games, and to externalities from coalition formation as, simply, externalities.3 See www.aerogistics.com for more details.4 Throughout the paper, we will refer to weakly positive (negative) externalities as simply positive (negative) externalities.T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–12297−+/PFGOur aim in this paper is to develop anytime techniques to solve the CSG problem in PFG, henceforth de-. To this end, an algorithm is deemed “anytime” if it can return a solution at any point in time duringnoted PFGits execution, and the quality of its solution improves monotonically until termination. This is particularly desirable in themulti-agent system context since the agents might not always have sufficient time to run the algorithm to completion, es-pecially when the search space of the problem at hand is of exponential size. Moreover, being anytime makes the algorithmmore robust against failure; if the execution is stopped before the algorithm would have normally terminated, then it wouldstill provide the agents with a solution that is better than the initial solution, or any other intermediate one.and PFGTo this end, one of the major obstacles when developing algorithms for PFGis how these algorithms can betested/evaluated. This is significantly more challenging — compared to the case of games with no externalities — due to twomain challenges:−+/PFG+−• The first is how to generate random input instances that are guaranteed to satisfy the positive/negative externalitycondition. To this end, note that, in the general CFG case, there are no conditions that have to be considered whengenerating input instances. Thus, the characteristic function can be sampled from any distribution, e.g., Uniform, Normal,), one has to ensure that only positive (negative) externalitiesetc. On the other hand, when dealing with PFGoccur whenever two coalitions merge. This means, in particular, that for any two arbitrary coalition structures, CS andcan be created from CS by a series of coalition merges, the value of any coalition not involved in theseCSmerges must not be smaller (greater) in CS, such that CSthan in CS.+(PFG−(cid:3)(cid:3)(cid:3)• The second challenge is how different input instances can be stored in memory. This is particularly needed to comparedifferent algorithms or settings. As mentioned above, the size of the partition function quickly becomes prohibitive witha growing number of agents. For instance, given 20 agents, the partition function consists of more than 4 × 1014 values,and these require 394 terabytes of memory. What would be desirable, then, is to be able to store partition functionsmore concisely.Taking all the above into account, our main contributions are as follows:• We develop the first CSG algorithm for PFG−+/PFG, which we call IP+/−. The building blocks of this algorithm can besummarized as follows:(i) We prove that it is possible to compute upper and lower bounds on the values of any set of disjoint coalitions. These bounds can be used to identify unpromising coalition structures and, hence, improve the−+/PFGin PFGefficiency of CSG algorithms;(ii) We prove that in order to establish a worst-case guarantee on solution quality in PFGsearch a certain set of coalition structures;−+/PFGit is necessary to(iii) We identify subsets of coalition structures that need to be searched — in a certain order — so that the worst-caseguarantee is proven to drop after each subset;(iv) In the general PFG case, it is not possible to prune any partition of a subset of agents, even if the upper bound of−+/PFGthat partition is lower than the lower bound of another partition of that subset. Yet, we show that in PFGsuch pruning is possible under specific conditions. Based on this result, we develop a pre-processing technique toprune unpromising coalition structures from the subsets that need to be searched;(v) In order to search through promising subsets, we extend the depth-first search algorithm of Rahwan et al. [6] sothat it is applicable to PFG−+/PFG.• We provide an equation for generating random input instances, and prove that the resulting partition function is guar-. We also prove that this function, which consists of O (nn) values, onlyanteed to satisfy the conditions of PFGrequires storing O (2n) values in memory. This function can be used as a standard benchmark for evaluating any poten-tial CSG algorithms that could be developed in the future for PFG−+/PFG−+/PFG.Since there are no previous CSG algorithms for games with externalities, we benchmark our algorithm against thestate-of-the-art algorithms in games where no externalities are present. We find that, as far as worst-case guarantees areconcerned, our algorithm outperforms the other algorithms by orders of magnitude. For instance, to reach a bound of 3given 24 agents, the number of coalition structures that need to be searched by our algorithm is only 0.0007% of thatneeded by Sandholm et al. [1], and 0.5% of that needed by Dang and Jennings [2]. This is despite the fact that the otheralgorithms take advantage of the special properties of games with no externalities, while ours does not.The remainder of the paper is organized as follows. In Section 2, we introduce basic concepts related to coalitionalgames with and without externalities. In Section 3, we describe the algorithms that are currently available for solving thecoalition structure generation problem, and discuss their relative advantages and limitations. In Section 4, we describe the. Empirical evaluation are provided in Section 5. Section 6 concludes the paper and outlinesCSG algorithm in PFGfuture work. Finally, we provide in Appendix A a summary of the main notations used throughout this paper.+/PFG−98T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–1222. PreliminariesIn this section we formally introduce the notions of coalitions and coalition structures (Section 2.1), games with noexternalities (Section 2.2), and games with externalities (Section 2.3). Finally, we formalize the CSG problem in coalitionalgames, and provide a list of the important notations used in this paper (Section 2.4).2.1. Coalitions and coalition structuresThroughout the paper, we denote by n the number of agents, and by A = {a1, a2, . . . , an} the set of agents. We assumethat every non-empty subset of A is a possible coalition, and denote by C the set of coalitions. More formally, C = {C : C ⊆A, C (cid:6)= ∅}. This implies that |C| = 2n − 1.Example 1. There are 15 coalitions that can be created from A = {a1, a2, a3, a4}: {a1}, {a2}, {a3}, {a4}, {a1, a2}, {a1, a3},{a1, a4}, {a2, a3}, {a2, a4}, {a3, a4}, {a1, a2, a3}, {a1, a2, a4}, {a1, a3, a4}, {a2, a3, a4}, and {a1, a2, a3, a4}.A formal definition of a coalition structure is as follows:Definition 1 (Coalition structure). A coalition structure, denoted CS = {C1, C2, . . . , C|CS|}, is an exhaustive partition of A intodisjoint coalitions, i.e., it satisfies the following conditions: (a) ∀i ∈ {1, . . . , |CS|}, Ci (cid:6)= ∅; (b)i=1 Ci = A; and (c) ∀i, j ∈{1, . . . , |CS|}: i (cid:6)= j, Ci ∩ C j = ∅.(cid:2)|CS|The set of all coalition structures will be denoted as P A , and the set of coalition structures containing exactly s coalitionss . The number of possible coalition structures — also known as the nth Bell number given n agents —will be denoted as P Ais computed as: |P A| =|P As|, where:(−1) j(s − j)n(1)(cid:3)ns=1(cid:6)(cid:7)sj(cid:4)(cid:4)P As(cid:4)(cid:4) = 1i!s−1(cid:5)j=0Example 2. In total, there are 15 coalition structures that can be created from A = {a1, a2, a3, a4}5:(cid:9)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8){a1}{a2}{a3}{a4}(cid:9){a1, a2}{a3}{a4}{a1, a3}{a2}{a4}{a1, a4}{a2}{a3}{a1}{a2, a3}{a4}(cid:9)(cid:9)(cid:9)(cid:9)(cid:9)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8){a1}{a2, a4}{a3}{a1}{a2}{a3, a4}(cid:9){a1, a2, a3}{a4}{a1, a2, a4}{a3}{a1, a3, a4}{a2}(cid:9)(cid:9)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:9)(cid:9)(cid:9)(cid:9){a1}{a2, a3, a4}{a1, a2}{a3, a4}{a1, a3}{a2, a4}{a1, a4}{a2, a3}(cid:9){a1, a2, a3, a4}Observe that the difference between |C| and |P A| grows exponentially with the number of agents. An example is shownin the following table:n|C||P A |111375531527127877951121 147112047678 57013819527 644 4371532 7831 382 958 5452.2. Characteristic function gamesConventionally, coalitional games with no externalities are modeled using the characteristic function, which takes, as aninput, a coalition C ∈ C and outputs its value, v(C) ∈ R, which reflects the performance of this coalition. Formally: v : C → R.A tuple ( A, v) is called a Characteristic Function Game (CFG). It is clear from the above definition that in this type of gamethe value of any coalition is independent of any other coalition. As standard in the literature (e.g., [1,2,6]) we assume thatv(C) (cid:2) 0 for all C ∈ C.5 For notational convenience, commas are omitted between coalitions whenever there is no risk of confusion.T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–12299Example 3. Let a sample characteristic function for A = {a1, a2, a3, a4} be defined as follows:(cid:10){a2, a4}(cid:10){a3, a4}(cid:10){a1, a2, a3}(cid:10){a1, a2, a4}{a1, a3, a4}{a2, a3, a4}{a1, a2, a3, a4}(cid:10){a1, a2}(cid:10){a1, a3}(cid:10){a1, a4}(cid:10){a2, a3}(cid:10){a1}(cid:10){a2}(cid:10){a3}(cid:10){a4}= 1= 2= 2= 1= 3= 4= 1= 5= 6= 4(cid:11)(cid:11)= 6= 8(cid:11)= 5= 5vvvvvvvvvvvv(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)= 7vvv(cid:10)(cid:10)(cid:10)(cid:11)(cid:11)(cid:11)(cid:11)2.3. Partition function gamesIn games with externalities, the value of a coalition depends on the way other agents are partitioned. A coalition Cthat is part of a coalition structure CS will be called an embedded coalition and denoted (C, CS ). The set of all embeddedcoalitions for the set A will be denoted EC. For any embedded coalition (C, CS ) ∈ EC, the partition function w outputs avalue that reflects the performance of C in CS. Formally: w : EC → R.(cid:8)(cid:9)(cid:11){a1, a2, a3}{a4}Example 4. Let a sample partition function for A = {a1, a2, a3, a4} be:(cid:9)(cid:11)= 1{a1}{a2}{a3}{a4}(cid:9)(cid:11)= 1{a2, a3}{a1}{a4}(cid:9)(cid:11)= 0{a2, a4}{a1}{a3}(cid:9)(cid:11)= 0.5{a3, a4}{a1}{a2}(cid:9)(cid:11)= 0{a1}{a2, a3, a4}(cid:9)(cid:11)= 2{a1}{a2}{a3}{a4}(cid:9)(cid:11)= 1{a3, a4}{a1}{a2}(cid:9)(cid:11)= 2{a1, a3}{a2}{a4}(cid:9)(cid:11)= 1{a1, a4}{a2}{a3}(cid:9)(cid:11)= 0{a1, a3, a4}{a2}(cid:9)(cid:11)= 2{a1}{a2}{a3}{a4}(cid:9)(cid:11)= 1{a1, a2}{a3}{a4}(cid:9)(cid:11)= 2{a1, a4}{a2}{a3}(cid:9)(cid:11)= 1{a2, a4}{a1}{a3}(cid:9)(cid:11)= 0{a1, a2, a4}{a3}(cid:9)(cid:11)= 1{a1}{a2}{a3}{a4}(cid:9)(cid:11)= 0.5{a2, a3}{a1}{a4}(cid:9)(cid:11)= 0.5{a1, a3}{a2}{a4}(cid:9)(cid:11)= 1{a1, a2}{a3}{a4}{a4},{a1, a2},{a1, a2},{a1, a3},{a1, a3},{a1, a4},{a1, a4},{a2, a3},{a2, a3},{a2, a4},{a2, a4},{a3, a4},{a3, a4},{a1, a2, a3},{a1, a2, a4},{a1, a3, a4},{a2, a3, a4},{a1, a2, a3, a4},{a1},{a1},{a1},{a1},{a1},{a2},{a2},{a2},{a2},{a2},{a3},{a3},{a3},{a3},{a3},{a4},{a4},{a4},{a4},= 0(cid:9)(cid:11){a1, a2}{a3}{a4}(cid:9)(cid:11){a1, a2}{a3, a4}(cid:9)(cid:11){a1, a3}{a2}{a4}(cid:9)(cid:11){a1, a3}{a2, a4}(cid:9)(cid:11){a1, a4}{a2}{a3}(cid:9)(cid:11){a1, a4}{a2, a3}(cid:9)(cid:11){a2, a3}{a1}{a4}(cid:9)(cid:11){a2, a3}{a1, a4}(cid:9)(cid:11){a2, a4}{a1}{a3}(cid:9)(cid:11){a2, a4}{a1, a3}(cid:9)(cid:11){a3, a4}{a1}{a2}(cid:9)(cid:11){a3, a4}{a1, a2}{a1, a2, a3}{a4}{a1, a2, a4}{a3}{a1, a3, a4}{a2}{a2, a3, a4}{a1}wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)= 3= 2= 4= 3= 1= 1= 5= 4= 6= 4= 4= 3(cid:9)(cid:11)(cid:9)(cid:11)(cid:9)(cid:11)(cid:9)(cid:11)= 5= 5= 6= 8(cid:9)(cid:11){a1, a2, a3, a4}= 7A tuple ( A, w) is called a Partition Function Game (PFG). Whenever convenient, we will use a concise notation to rep-resent partition functions, where values of all coalitions embedded in a given coalition structure are represented as avector. Formally, given a coalition structure CS = {C1, . . . , C|CS|}, the values of (C1, CS), . . . , (C|CS|, CS) will be denoted as[w(C1, CS), . . . , w(C|CS|, CS)].Example 5. A shorthand notation for the partition function from Example 4:Coalition structure{{a1}{a2}{a3}{a4}}{{a1, a2}{a3}{a4}}{{a1, a3}{a2}{a4}}{{a1, a4}{a2}{a3}}{{a1}{a2, a3}{a4}}{{a1}{a2, a4}{a3}}{{a1}{a2}{a3, a4}}{{a1, a2}{a3, a4}}Vector[1, 2, 2, 1][3, 1, 1][4, 2, 0.5][1, 1, 2][1, 5, 0.5][0, 6, 1][0.5, 1, 4][2, 3]Coalition structure{{a1, a3}{a2, a4}}{{a1, a4}{a2, a3}}{{a1, a2, a3}{a4}}{{a1, a2, a4}{a3}}{{a1, a3, a4}{a2}}{{a1}{a2, a3, a4}}{{a1, a2, a3, a4}}Vector[3, 4][1, 4][5, 0][5, 0][6, 0][0, 8][7]The partition function takes into account any externality from coalition formation. By this we mean a change in a value ofa given coalition caused by a merge of two other co-existing coalitions.6 More formally:6 For a discussion of alternative notions of externalities in multi-agents systems see [15], and for a comprehensive economic study of externalities andrelated issues see [16].100T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122Definition 2 (Externalities). Let CS, CS(cid:3), Cthat CS = {Con every other embedded coalition (C, CS) such that C (cid:6)= C(cid:3) ∈ P A be two coalition structures such that |CS(cid:3), CS, which is defined as:(cid:3)(cid:3)}. Then, the formation of (C(cid:3)(cid:3), CS) from (C(cid:3)(cid:3)} ∪ CS(cid:3) ∪ C(cid:3)(cid:3)(cid:3) \ {C(cid:3) ∪ C(cid:3) ∪ C(cid:3)| (cid:2) 3 and there exist C(cid:3)) and (C(cid:3)(cid:3), CS(cid:3), Csuch(cid:3)) imposes an externality(cid:3)(cid:3) ∈ CS(cid:3)(cid:2)(C, CS, CS(cid:3)) = w(C, CS ) − w(C, CS(cid:3))Thus, every externality is uniquely determined by a tuple (C, CS, CS(cid:3)). A set of all such tuples in a game ( A, w) will bedenoted by T (w).Now, we can formally define games with positive externalities (PFG+) and games with negative externalities (PFG−):Definition 3 (Game with positive (negative) externalities). We say that partition function game ( A, w) is characterized bypositive (negative) externalities if and only if, for all (C, CS, CS(cid:3)) ∈ T (w), the following holds:(cid:2)(C, CS, CS(cid:3)) (cid:2) ((cid:3)) 0Example 6. The game defined in Example 4 has only negative externalities. For example, the externalities affecting coalition{a1} are:(cid:10)(cid:9)(cid:11)(cid:8)(cid:8){a1}{a2, a3}{a4}− w{a1},{a1}{a2}{a3}{a4}(cid:9)(cid:11)(cid:9),(cid:8)(cid:9),{a1}{a2}{a3}{a4}(cid:10)(cid:8)(cid:9)(cid:11){a1}{a2, a4}{a4}(cid:8)(cid:9){a1}{a2}{a3, a4}(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:8)(cid:8)(cid:8){a1},(cid:10)= w(cid:10){a1},(cid:10)= w(cid:10){a1},(cid:10)= w(cid:10){a1},(cid:10)= w(cid:10){a1},(cid:10)= w(cid:10){a1},(cid:10)= w{a1}{a2, a3}{a4}{a1},(cid:8){a1}{a2, a4}{a3}{a1},(cid:8){a1}{a2}, {a3, a4}{a1},(cid:8){a1}{a2, a3, a4}{a1},(cid:8){a1}{a2, a3, a4}{a1},(cid:8){a1}{a2, a3, a4}{a1},(cid:8)(cid:8)(cid:8)(cid:9)(cid:9)(cid:9),,,{a1}{a2, a3, a4}{a1}{a2, a3, a4}{a1}{a2}{a3}{a4}(cid:10)(cid:8)(cid:9)(cid:11)− w{a1},,{a1}{a2}{a3}{a4}(cid:10)(cid:8)(cid:9)(cid:11)(cid:8)(cid:8)(cid:8)(cid:9)(cid:11){a1},− w{a1}{a2, a3}{a4}(cid:10)(cid:8){a1},− w{a1}{a2, a4}{a3}(cid:10)(cid:8){a1},− w{a1}{a2}{a3, a4}(cid:10)(cid:8){a1},− w(cid:9)(cid:11)(cid:9)(cid:11){a1}{a2}{a3}{a4}(cid:9)(cid:11){a1}{a2}{a3}{a4}(cid:9)(cid:11){a1}{a2, a3}{a4}(cid:9)(cid:11){a1}{a2, a4}{a3}(cid:9)(cid:11)(cid:9)(cid:11)(cid:9)(cid:11)(cid:9)(cid:11)= 0;= −1;= −0.5;(cid:9)(cid:11)(cid:9)(cid:11)(cid:9)(cid:11)= −1;= 0;= −0.5.{a1}{a2, a3, a4}{a1}{a2}{a3, a4}It is not difficult to check that externalities affecting other coalitions in the game are also non-positive.Observe that CFGs are a special case of PFGs where every externality equals zero. They are also a special case of−+/PFG. This means, in particular, that any available algorithm designed for games with no externalities cannot bearePFGdirectly applied to those with externalities. Conversely, the algorithms that are proposed in this paper for PFGdirectly applicable to CFGs.−+/PFG2.4. The CSG problem formalizedThe CSG problem is to find an optimal coalition structure CS∗ ∈ P A , which is formally defined for CFGs as follows:CS∗ = arg maxCS∈P A(cid:5)C∈CSv(C),while, for PFGs, it is defined as follows:CS∗ = arg maxCS∈P A(cid:5)C∈CSw(C, CS ).∗ = {{a1, a3}, {a2, a4}}. This isExample 7. Referring to the game with no externalities defined in Example 3, we have CSbecause v({a1, a3}) + v({a2, a4}) = 10 which is greater than the value of any other coalition structure in this game. As for∗) = 8 isthe game with externalities defined in Example 4, CSgreater than the value of any other coalition structure in this game.∗ = {{a1}{a2, a3, a4}} since w({a1}, CS∗) + w({a2, a3, a4}, CST. Rahwan et al. / Artificial Intelligence 186 (2012) 95–1221013. Related workIn this section we will briefly discuss the available CSG algorithms for games with no externalities (i.e., CFGs). Broadly,these can be divided into exact and non-exact algorithms [6]. Basically, the non-exact algorithms return “good” solutionsrelatively quickly, and scale up well with the increase in the number of agents involved (see, e.g., Shehory and Kraus [4],Sen and Dutta [5]). However, they provide no guarantees on the quality of their solutions. Exact algorithms, on the otherhand, are guaranteed to find an optimal coalition structure. In this paper, we are interested in finding the optimal coalitionstructure and so we focus solely on exact algorithms. To this end, such algorithms are based on two main techniques:• Anytime optimization — The basic idea is to generate an initial solution that is guaranteed to be within a finite boundfrom the optimal one. After that, more coalition structures are examined so as to improve the solution and boundquality, until an optimal solution is found (see, e.g., Sandholm et al. [1], Dang and Jennings [2], Rahwan et al. [17,6]).Although anytime CSG algorithms might, in the worst case, end up searching the entire space (i.e., they run in O (nn)time), they are robust against failure; if the execution is stopped before the algorithm would normally have terminated,then it can still return a solution that is better than the initial, or any other intermediate, one.• Dynamic Programming — The basic idea of dynamic programming is to break the optimization problem into sub-problems that can be solved recursively, and then combine the results to solve the original problem, thereby avoidingthe work of recomputing the answer every time the sub-problem is encountered (see, e.g., Yeh [18], Rothkopf et al. [19],Rahwan and Jennings [20]). The advantage of dynamic programming algorithms, compared to their anytime counterpart,is that they run in O (3n) time. However, the disadvantage is that they provide no interim solution before completion.Recently, a number of algorithms have been developed that combine the above two techniques (see, e.g., Rahwan andJennings [21], Service and Adams [22,23]).In all the above algorithms, the focus was on settings where the coalition values are given explicitly, i.e., as a table of 2nvalues. However, there is another line of research that focuses on solving the CSG problem given concise representations (see,e.g., Ohta et al. [24], Rahwan et al. [25], Ueda et al. [26]). However, this issue is beyond the scope of this paper.Next, we will describe in detail some algorithms from the CFG literature (since we will use similar techniques later on inSection 4 to construct our PFG algorithm). To this end, observe, that dynamic programming techniques cannot be applied inPFGs. This is because they depend heavily on the CFG assumption that a coalition (or a group of disjoint coalitions) has thesame value in any coalition structure containing it. This assumption makes it possible to re-use the same result in differentcoalition structures. In PFGs, however, this assumption does not hold since the externalities in one coalition structure canbe different from that in another. Against this background, we will only describe the anytime algorithms that do not usedynamic programming techniques. Such algorithms can be divided into two categories, where the focus in the first is onthe worst-case guarantee, and the focus in the second is on solution quality. The following two subsections describe thesecategories in more detail.3.1. Algorithms that focus on worst-case guaranteesThe main focus of such algorithm is on how to establish a worst-case ratio bound β on solution quality, i.e., how toidentify a subset of coalition structures P (cid:3) ⊆ P A such that:(cid:3)(cid:3)maxCS∈P AmaxCS∈P (cid:3)C∈CS w(C, CS)C∈CS w(C, CS)(cid:3) βIn more detail, these algorithms focus on dividing the search space into subsets, and identifying the sequence in whichthese subsets have to be searched so that β guaranteed to improve after each subset. The first anytime CSG algorithm wasdeveloped by Sandholm et al. [1]. Here, the space of coalition structures, i.e., P A , is represented as a coalition structure graph,where:• Every node represents a coalition structure. All nodes are categorized into n levels, noted as P A1 , . . . , P An where levelP Asis the set of coalition structures that contain exactly s coalitions;• Every undirected edge connects two coalition structures, belonging to two consecutive levels, P As , such thatthe coalition structure in level P As by merging exactly two coalitions intoone. In other words, an edge in the graph represents a merger of two coalitions when followed upwards, and a split ofa coalition into two when followed downwards.s−1 can be created from the one in level P As−1 and P AFig. 1 shows an example of the coalition structure graph given 4 agents. Sandholm et al. [1] proved that there exists aminimum set of coalition structures that have to be searched in order to establish any bound on the quality of the solution.Specifically, this is achieved by searching through the first two levels of the coalition structure graph (which contain 2n−1coalition structures in total) and the result of this search is within a ratio bound β = n from the optimal.If additional time is available after the first two levels have been searched, then it would be desirable to improve thebound with further search. To this end, Sandholm et al. proposed to search the remaining levels one by one, starting from102T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122Fig. 1. The coalition structure graph for 4 agents.the bottom level (i.e., P An ), and moving upwards. They proved that the bound improves as the algorithm searches morelevels. In more detail, assuming that the algorithm has just completed searching level P As , the bound becomes β = (cid:12)n/h(cid:13),where h = (cid:12)(n − s)/2(cid:13) + 2. The only exception is when n ≡ h − 1 (mod h) and n ≡ s (mod 2), in which case the boundbecomes β = (cid:15)n/h(cid:16).A different algorithm was proposed by Dang and Jennings [2]. This algorithm starts by searching the top two levels, aswell as the bottom one (as Sandholm et al.’s algorithm does). After that, however, instead of searching through the remaininglevels one by one (as Sandholm et al. do), the algorithm searches through certain subsets of all remaining levels. Specifically,it searches the coalition structures that have at least one coalition of which the size is not less than (cid:15)n(d − 1)/d(cid:16) (with drunning from (cid:12)(n + 1)/4(cid:13) down to 2). Dang and Jennings proved that, for any given value of d, the algorithm establishes abound β = 2d − 1.As mentioned in the introduction, however, such algorithms only identify the coalition structures that need to besearched in order to further improve the ratio bound. They do not specify how the search process is carried out, and itis implicitly assumed that a simple brute-force procedure is applied.3.2. Algorithms that focus on solution qualitySuch algorithms focus on searching the space of coalition structures as quickly as possible, and not on reducing theworst-case ratio bound. The state-of-the-art algorithm in this category is the IP algorithm [17]. This algorithm is based ona novel representation of the search space that divides the coalition structures into subspaces based on the sizes of thecoalitions they contain [27]. In more detail, a subspace is represented by an integer partition of n.7 For example, given4 agents, the possible integer partitions are [4], [1, 3], [2, 2], [1, 1, 2], [1, 1, 1, 1], and each of these represents a subspacecontaining all the coalition structures within which the coalition sizes match the parts of the integer partition. For example,[1, 1, 2] represents the subspace of all the coalition structures within which two coalitions are of size 1, and one coalitionis of size 2. The integer partition graph is a graph where a node represents an integer partition, and an edge connects two(cid:3) = (I \ {i, j}) (cid:17) {i + j} [21]. Fig. 2integer partitions I, Ishows an example of 4 agents.(cid:3)|, if and only if there exist i, j ∈ I such that I(cid:3) ∈ In, where |I| > |II on the value of the best solution in P AWhat is significant about this representation is that, for every subspace, it is possible to compute upper and lowerbounds on the value of the best solution that can be found in it. To this end, let Maxs and Avgs be the maximum andthe average values of the coalitions of size s respectively. Also, let In be the set of integer partitions of n, and P AI be thesubspace that corresponds to the integer partition I ∈ In. Then, for all I ∈ In, it is possible to compute an upper bound=I as follows: UB AUB AI on the value of(cid:3)Ithe best solution in P As∈I Avgs.8 These bounds are then used to establish worst-caseguarantees on the quality of the best solution found so far, and to prune any subspace that has no potential to contain asolution better than the current best one. As for the remaining subspaces, IP searches them one at a time, unless a value isfound that is higher than the upper bound of another subspace, in which case that subspace no longer needs to be searched.Searching a subspace is done using an efficient process that applies branch-and-bound techniques to avoid examining everysolution in it. For more details on the IP algorithm, see [6].I can be computed as follows: LBI =s∈I Maxs. Similarly, a lower bound LB A(cid:3)7 Recall that an integer partition of a positive integer number i consists of a set of positive integers (called “parts”) that add up to exactly i [28]. Forpresentation clarity, we use square brackets throughout this paper (instead of curly ones) to represent integer partitions.8 Interestingly, Rahwan et al. [17] proved that this lower bound is actually the average value of all the solutions in P AI.T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122103Fig. 2. The integer partition graph, and the subspaces represented by different nodes.4. The IP+/−algorithmIn this section, we describe our CSG algorithm for PFG−+/PFG. The name IP+/−comes from the fact that the algorithmis based on the integer partition representation of the coalition structure space (see Section 3 for more details).The remainder of this section is composed of five subsections that introduce the main building blocks of IP. Specifi-cally, in Section 4.1, we show that it is possible to compute upper and lower bounds on the values of coalitions and sets ofdisjoint coalitions. In Section 4.2, we prove that there exists a certain set of coalition structures that has to be searched inorder to establish a bound from the optimal solution. In Section 4.3, we present a procedure that identifies the subspacesof coalition structures that need to be searched in order to improve the bound. In Section 4.4 we propose a pre-processingprocedure that uses upper and lower bounds of subspaces to prune unpromising ones. Finally, in order to search the promis-ing subspaces, we extend in Section 4.5 the breadth-first search technique of Rahwan et al. [6] so that it is applicable toPFG−+/PFG+/−.4.1. Computing upper and lower bounds(cid:3)We define the value of a coalition structure CS ∈ P A , denoted W (CS), as the sum of the values of all the coalitions in CS,C∈CS w(C, CS). Moreover, for any coalition C ∈ C, we denote by C the agents in A that do not belong tothat is, W (CS) =C (i.e., C = A\C ). Furthermore, we define a partition of C as a set containing disjoint coalitions of which the union equals C ,and denote the set of all such partitions as P C .9 While every element of a partition P ∈ P C is a coalition, where there isno risk of confusion, we will denote such an element by small letter p for notational convenience. Finally, for any coalitionstructure CS, the value of a partition P ⊆ CS, denoted W (P , CS), is defined as the sum of the values of all the coalitions inthat partition, i.e., W (P , CS) =(cid:3)p∈P w(p, CS).Now, we have the following theorem:− (PFGTheorem 1. Consider a PFGfollowing holds, where the agents in C are denoted as a1, . . . , a|C|:+) setting. Given a coalition C ⊆ C, a partition P ∈ P C , and a coalition structure CS ⊇ P , the(cid:10)WP , {C } ∪ P(cid:11)(cid:3) ((cid:2)) W (P , CS) (cid:3) ((cid:2)) W(cid:10)(cid:8)P ,{a1}, . . . , {a|C|}(cid:9)(cid:11)∪ PProof. To simplify notation, let CSCS (cid:6)= CS. Then, given a PFG(cid:3)(cid:3)(cid:3)(cid:3) = {C} ∪ P and CS(PFG−+and CS (cid:6)= CS(cid:10)(cid:11)WP , CS(cid:3)(cid:3) ((cid:2)) W (P , CS)(cid:3)(cid:3) = {{a1}, . . . , {a|C|}} ∪ P . Also, without loss of generality, assume that) setting, we first need to prove that:(2)by performing multiple steps, each involving the merging of twoBeginning with CS, it is always possible to reach CScoalitions into one. In each step, the coalitions in P remain unchanged, and due to negative (positive) externalities, theirvalues can only decrease (increase). As a result, the inequality in (2) holds. Similarly, beginning with CS, it can be proved(cid:3)(cid:3)). (cid:2)that the following holds: W (P , CS) (cid:3) ((cid:2)) W (P , CS(cid:3)(cid:3)(cid:3)Theorem 1 bounds the value of any given partition of C . Specifically, for every partition P ∈ P C , the upper bound UBP andlower bound LBP can be computed in a PFG−+(PFG) setting as follows, where C = {a1, . . . , a|C|}:9 Note that if C = A then any partition of C would be a coalition structure.104T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122(cid:10)UBPLBP(cid:10)LBPUBP(cid:11)(cid:11)==(cid:10)(cid:10)ww(cid:5)p∈P(cid:5)p∈P(cid:11)p, P ∪ {C}(cid:8)p, P ∪{a1}, . . . , {a|C|}(cid:9)(cid:11)By assuming that P = {C}, it is possible, using the above equations, to compute an upper bound UBC and a lower boundLBC on the value of any coalition C .Now, let us denote by 2C the power set of C , i.e., the set of all subsets of C . Moreover, let us denote by Ik the setof possible integer partitions of number k ∈ N. Then, given a coalition C ∈ C, and an integer partition I ∈ I s: s (cid:3) |C|, wewill define P CI as the set consisting of every possible P ⊆ 2C such that the sizes of the subsets in P match the parts in I .Consider the following example:Example 8. For C = {a1, a2, a3, a4} and I = [1, 2] we have:P {a1,a2,a3,a4}[1,2]=⎧⎪⎨⎪⎩{{a1}, {a2, a3}}, {{a1}, {a2, a4}}, {{a1}, {a3, a4}},{{a2}, {a1, a3}}, {{a2}, {a1, a4}}, {{a2}, {a3, a4}},{{a3}, {a1, a2}}, {{a3}, {a1, a4}}, {{a3}, {a2, a4}},{{a4}, {a1, a2}}, {{a4}, {a1, a3}}, {{a4}, {a2, a3}}⎫⎪⎬⎪⎭Now, given Theorem 1, we can compute upper and lower bounds (denoted UBCI and LBCI respectively) on the values ofthe elements of P CI as follows:∀C ∈ C, ∀s (cid:3) |C|, ∀I ∈ I s, UBCI= maxP ∈P CIUBP ,and LBCI= minP ∈P CILBPObserve that P CIis not.P {a1,a2,a3,a4}[1,2]is a subset of P C if and only if I ∈ I|C|. For example, P {a1,a2,a3,a4}[1,1,2]is a subset of P {a1,a2,a3,a4}, while4.2. Establishing a worst-case boundHaving computed upper and lower bounds for coalition and partition values in the previous section, we now show howthese can be used to identify the minimum search required to establish a worst-case ratio bound β from the optimum. Inorder to do so, we will use the following general theorem:Theorem 2. Let us define X , Y , and Z as follows:• X is a set of elements;• Y is a set containing subsets of X .• Z is a set containing subsets of X such that every y ∈ Y can be partitioned using subsets from Z .Furthermore, let us define ν and V as follows:• ν is a function; ν : X × Y → R+ ∪ {0}. We call ν(x, y) the value of x in y, where ν(x, y) = 0 for all y and all x /∈ y.• V is a function defined for every y ∈ Y as follows: V ( y) =x∈ y ν(x, y). We call V ( y) the value of y.(cid:3)Then, for any Y (cid:3) ⊆ Y , if the following holds:(cid:5)∀z ∈ Z, ∃ y(cid:3) ∈ Y (cid:3):z ⊆ y(cid:3) ∧x∈z(cid:10)νx, y(cid:11)(cid:3)= maxy∈Y(cid:5)x∈zν(x, y)(3)We have:maxy∈YV ( y) (cid:3) maxy∈Y(cid:21) y(cid:21)Z ∗ maxy(cid:3)∈Y (cid:3)(cid:11)(cid:3)(cid:10)Vywhere (cid:21) y(cid:21)Zis defined as follows:(cid:21) y(cid:21)Z =(cid:2)Z(cid:3)⊆Z:minZ(cid:3)= y∧∀z,z(cid:3)∈Z(cid:3): z∩z(cid:3)=∅(cid:4)(cid:4)Z (cid:3)(cid:4)(cid:4)In other words, let us define (cid:21) y(cid:21)Zas the size of y with respect to Z , which is basically the minimum number of subsetsfrom Z that partition the subset. For example, if Z contains the following four subsets: {x1}, {x2}, {x4} and {x1, x3}, then,T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122105given y = {x1, x3, x4}, we have (cid:21) y(cid:21)Z = 2. In this case, we say that the size of y with respect to Z is 2. Now, if every subsetin Z appears with its maximum value in at least one of the subsets in Y (cid:3)is within a ratio boundfrom the best subset in Y . This bound equals the biggest subset in Y with respect to Z ., then the best subset in Y (cid:3)Proof. Let yThat is:∗be the best subset in Y , i.e., y∗ = arg max y∈Y V ( y). Moreover, let Z ∗be the smallest partition of y∗in Z .(cid:8)Z ∗ =∗1, . . . , z∗|Z∗|z(cid:9)⊆ Z:(cid:19)Z ∗ = y∗, z∗i∩ z∗j(cid:6)=iNow, since Z ∗(cid:11)(cid:10)∗=Vyis a partition of y(cid:5)(cid:10), then we can write V ( y(cid:10)(cid:5)(cid:11)∗(cid:11)∗x, y+ · · · +∗νx, y(cid:4)(cid:4) =(cid:20)(cid:20) y(cid:20)(cid:20)Z∗(cid:4)(cid:4)Z ∗= ∅,∗) as follows:νx∈z∗1This, in turn, implies that:(cid:4)(cid:11)(cid:4) ∗ max∈Z∗(cid:4)(cid:4)Z ∗(cid:3)Vy(cid:10)∗z∗ix∈z∗|Z∗|(cid:10)νx, y(cid:11)∗(cid:5)x∈z∗iNow since |Z ∗| = (cid:21) y∗(cid:21)Z, and since (cid:21) y(cid:5)∗(cid:21)Z (cid:3) max y∈Y (cid:21) y(cid:21)Z(cid:10)(cid:11), we find that:(cid:11)∗(cid:10)Vy(cid:3) maxy∈Y(cid:21) y(cid:21)Z ∗ max∈Z∗z∗i∗νx, yx∈z∗iFurthermore, assuming that (3) holds, we have:∀z∗i∈ Z ∗, ∃ y(cid:3) ∈ Y (cid:3):∗iz⊆ y(cid:3) ∧Now since the following holds for every z(cid:5)x∈z∗i(cid:10)νx, y(cid:11)∗(cid:3) maxy∈Y(cid:5)x∈z∗iν(x, y)(cid:5)x∈z∗i∗i(cid:10)νx, y(cid:11)(cid:3)= maxy∈Y∈ Z ∗:(cid:5)x∈z∗iν(x, y)Then, from (5) and (6), we find that:∀z∗i∈ Z ∗, ∃ y(cid:3) ∈ Y (cid:3):∗iz⊆ y(cid:3) ∧(cid:10)νx, y(cid:11)(cid:3)(cid:2)(cid:5)x∈z∗i(cid:10)νx, y(cid:11)∗(cid:5)x∈z∗iMoreover, we know that:∀ y(cid:3) ∈ Y (cid:3), ∀z⊆ y(cid:3):∗i(cid:5)x∈ y(cid:3)(cid:10)νx, y(cid:11)(cid:3)(cid:2)(cid:5)(cid:10)νx, y(cid:11)(cid:3)Based on (8), as well as the fact that V ( y(cid:5)∀ y(cid:3) ∈ Y (cid:3), ∀z∗i(cid:3)⊆ y(cid:10)(cid:11)(cid:3)(cid:2):Vyx∈z∗ix∈z∗i(cid:3)(cid:3)) =(cid:10)(cid:3)νx, yx∈ y(cid:3) ν(x, y(cid:11)(cid:3)), we find that:From (7) and (9), we find that:∀z∗i∈ Z ∗, ∃ y(cid:3) ∈ Y (cid:3):∗iz⊆ y(cid:3) ∧ V(cid:10)(cid:11)(cid:3)y(cid:2)(cid:5)x∈z∗i(cid:10)νx, y(cid:11)∗This, in turn, implies that:∃ y(cid:3) ∈ Y (cid:3):(cid:11)(cid:3)(cid:10)Vy(cid:2) max∗∈Z∗zi(cid:10)νx, y(cid:11)∗(cid:5)x∈z∗iFinally, from (4) and (10), we find that:∃ y(cid:3) ∈ Y (cid:3):(cid:11)∗(cid:10)Vy(cid:3) maxy∈Y(cid:21) y(cid:21)Z ∗ V(cid:10)(cid:11)(cid:3)y(cid:2)(4)(5)(6)(7)(8)(9)(10)Having proved Theorem 2, we now show how it can be used while proving the main theorem for establishing a ratiobound β in PFG−+/PFG.106T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122I : I ∈ In: |I| (cid:3) 2 mustTheorem 3. To establish a bound β on the value of a coalition structure given a PFGbe searched. With this search, the number of coalition structures searched is 2n−1, and the bound β = n. On the other hand, given aI : I ∈ {[n], [n − 1, 1], [n − 2, 1, 1], . . . , [1, 1, . . . , 1]} must be searched. With this search, the numberPFGof coalition structures searched is 2n − n + 1, and β = (cid:15) n2setting, every subspace P Asetting, every subspace P A(cid:16).−+Proof. To establish a bound, the maximum possible value of each coalition C has to be observed (in some coalition structure).+setting, the only coalition structure in which C is guaranteed to have its maximum value is {C, A\C}. BasedGiven a PFGon this, the subspaces P AI : I ∈ In: |I| (cid:3) 2 must be searched, and these contain 2n−1 coalition structures.To prove that β = n, we use Theorem 2 as follows:• We consider X to be the set of coalitions. That is, X = C.• We consider Y to be the set of coalition structures, and Y (cid:3)size 1 or 2. That is, Y = P A and Y (cid:3) = P AI : I ∈ In: |I| (cid:3) 2.• We consider Z = {{C}: C ∈ C}.to be a subset of Y containing the coalition structures ofNow since every subset in Z appears with its maximum value in one, or more, of the coalition structures in Y (cid:3)coalition structure in Y (cid:3)implies that β = n since (cid:21){{a1}, . . . , {an}}(cid:21)Z = n.is within a ratio bound β from the best coalition structure in Y , where β = max y∈Y (cid:21) y(cid:21)Z, then the best. ThisOn the other hand, given a PFGsetting, the only coalition structure in which C is guaranteed to have its maximumvalue is: {C, {a1}, . . . , {a|C|}}, where {a1} ∪ · · · ∪ {a|C|} = C . Based on this, the following subspaces have to be searched:P AI : I ∈ {[n], [n − 1, 1], [n − 2, 1, 1], . . . , [1, 1, . . . , 1]}. With this search, the number of searched coalition structures wouldbe 2n − n + 1 since every possible coalition appears in a unique coalition structure, except for the singleton ones (which allappear in a single coalition structure).−As in the PFG+case, we use Theorem 2 to prove that β = (cid:15) n2(cid:16). Here:• We consider X to be the set of coalitions.• We consider Y to be the set of coalition structures (i.e., Y = P A ), and consider: Y (cid:3) = P A[n] ∪ P A[n−1,1] ∪ P A[n−2,1,1] ∪ · · · ∪P A[1,...,1].• We consider Z = {{C}: C ∈ C} ∪ {{C : C ∈ C, |C| = 1}}, i.e., every subset in Z contains either a single coalition, ora combination of singletons. Note that the maximum possible value of every such combination has been observed inP A[1,...,1] (see Theorem 1).The above implies that the best coalition structure in Y (cid:3)is within a ratio bound β from the best coalition structure in Ysince every possible subset in Z appears with its maximum value in Y (cid:3). This bound equals the size of the biggest coalitionstructure with respect to Z (see Theorem 2). Importantly, since every combination of singletons belongs to Z then, for anyis derived from CS by groupingtwo coalition structures CS and CSall singletons into one coalition, we have (cid:21)CS(cid:21)Z = (cid:21)CS. Based on this, it can easily be shown that the biggest coalitionstructures with respect to Z are those belonging to P A[2,2,...,2] whenthe number of agents is even. In either case, we have: max y∈Y (cid:21) y(cid:21)Z = (cid:15) n(cid:3)(cid:21)Z[2,2,...,2,1] when the number of agents is odd, and to P Acontains more than one singleton, and CSsuch that CS(cid:16). (cid:2)(cid:3)(cid:3)(cid:3)2Interestingly, in CFGs, it is sufficient to search the first and second levels of the coalition structure graph in order tobound β [1]. However, it is also possible to bound β by searching any other set of coalition structures as long as everyI ∈coalition appears at least once in this set. On the other hand, given a PFG+I : I ∈ In: |I| (cid:3) 2 (see{[n], [n − 1, 1], [n − 2, 1, 1], . . . , [1, 1, . . . , 1]} and, given a PFGTheorem 3).setting, it is necessary to search P AI :setting, it is necessary to search P A−4.3. Improving the worst-case boundIn this section, we present our procedure for reducing the ratio bound with further search. This procedure is based onTheorem 2, where X is considered to be the set of coalitions, and Y is considered to be the set of coalition structures,and the basic idea is to select Y (cid:3)and Z so asto obtain the initial bound β identified in Theorem 3. After that, we add certain elements to Y (cid:3)and Z so as to drop thebound to β − 1, and then repeat the same process to drop it to β − 2, and so on.and Z such that the desired bound is obtained. That is, we first select Y (cid:3)For presentation clarity, we will first discuss an example of how the procedure works, and then present the pseudo codeof this procedure. In particular, an example of 10 agents with positive externalities is shown in Fig. 3, where integers are(cid:3) ∈ C, |C| =used to represent coalition sizes. For instance, {{C}: C ∈ C, |C| = 2} is represented by [2]. Similarly, {{C, C4, |C(cid:3)| = 3} is represented by [4, 3]. In more detail:(cid:3)}: C, C• Fig. 3(A): Z initially contains every possible subset of X that is of size 1, while Y (cid:3)tures in P AI : I ∈ I 10: |I| (cid:3) 2 (see how Z contains the integers 1, 2, . . . , 10 in the figure, while Y (cid:3)initially contains the coalition struc-contains the integerT. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122107Fig. 3. Example of our procedure for reducing the ratio bound algorithm with further search given 10 agents and positive externalities. The circles thatsurround the same combination of integers have the same color.partitions of 10 that contains exactly two integers each). Since every subset in Z appears in Y (cid:3)with its maximumvalue (see Theorem 1), then the best coalition structure in Y (cid:3)is within a ratio bound β from the best one in Y . Thisbound is equal to the size of the biggest subset of Y with respect to Z . Here, the biggest subset happens to be the onerepresented by [1, . . . , 1] (i.e., it is {{a1}, . . . , {an}}), which is of size 10.108T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122Fig. 4. Example of how the integer model finds the subspaces to be searched in order to improve the ratio bound.• Fig. 3(B): Here, we add to Z every combination of two singletons (see how Z now contains [1, 1] in the figure). Toensure that, after this addition, every subset in Z still appears in Y (cid:3)thecoalition structures that correspond to [8, 1, 1] (see Theorem 1). Importantly, the modification to Z reduces the size ofthe biggest subset in Y with respect to Z . In particular, when computing the size of {{a1}, . . . , {an}} with respect to Z ,we can see that it drops from 10 to 5.with its maximum value, we need to add to Y (cid:3)• Fig. 3(C): Here, we add to Z all the combinations of four singletons and all the combinations of two coalitions of sizethe coalition structures where those combinations appear with their maximum values (seein the figure). As a result of those additions to Z and Y (cid:3), we can see that2 each. We also add to Y (cid:3)the elements that were added to Z and Y (cid:3)the size of the biggest subset in Y with respect to Z has now dropped from 5 to 4.• Fig. 3(D): The key question, then, at every stage is the following: which elements should be added to Z and Y (cid:3)in orderto drop the size of the biggest subset in Y with respect to Z ? In our example, the biggest subsets in Y are now of size4 each, and they belong to the subspaces that are highlighted in the figure. As can be seen, it is not trivial to determinewhich elements to add to Z and Y (cid:3). We solve this problem by using an Integer Programming solver. The basic ideais to represent the problem as a boolean matrix, where every row corresponds to one of the subspaces that need tobe dealt with (i.e., a subspace containing subsets of which the size, with respect to Z , equals β), and every columncorresponds to a unique combination that could be added to Z (see Fig. 4). The value of the matrix at any given rowr and column c equals 1 if, by adding to Z the combination that corresponds to column c, we drop the size of thesubspace corresponding to row r. Otherwise, the value is 0.10 In Fig. 4, for example, the value at row 2 and column 4[4,3,2,1] drops from 4 to 3 by adding to Z all the combinations of twois 1. This is because the size of any subset in P Acoalitions where one is of size 2 and the other is of size 1. What we need, then, is to find a set of columns such that,for every row, the value in the matrix equals 1 in one or more of those columns. In Fig. 4, for example, the highlightedcolumns represent a possible solution. The process of finding the required set of columns is done using an integerprogramming solver. The integer formulation takes into consideration, for every column, the size of the subspace thatneeds to be added to Y (cid:3)(see the cost vector in Fig. 4). For example, adding to Z the combinations of coalitions of sizes2, 1, 1 has a cost of 1260. This is because we need to add P A, and this contains 1260 coalition structures.The integer solver finds a feasible set of columns of which the cost is minimal.[6,2,1,1] to Y (cid:3)+I : I ∈ In, |I| (cid:3) 2 in the PFGHaving presented a detailed example of our procedure for reducing the ratio bound, we now present the pseudo code ofcase, and search[n−1,1], . . . , P Athis procedure (see Algorithm 1). In more detail, we initially search P A(steps 1 to 5). This can be interpreted as putting those subspaces in Y (cid:3)P A[n−2,1,1] ∪ P A, andputting in Z the subsets of X that appear with their maximum value in those subspace (i.e., Z = {{C}: C ∈ C} ∪ {C(cid:3): C(cid:3) ⊆C ∧ ∀C ∈ C(cid:3)). It can easily beshown that the bound in this case would be β = (cid:15) nthat has not yet2been searched, we compute the smallest partition of I in Z , denoted partitionI (steps 6 to 8). This partition simply groupsall singletons together in the PFGcase (see how partitionI is initialized in+(cid:3) ∈ C, |C| = 1, |C(cid:3)| = 1}} in PFG(cid:16) (see Theorem 2). After that, for every subspace P AIcase, and every pair of singletons in the PFG, and Z = {{C}: C ∈ C} ∪ {{C, C−: |C| = 1}} in PFG[1,1,...,1] in the PFG(cid:3)}: C, C[n], P A−+−10 The values that are equal to 0 are omitted from the matrix in Fig. 4 for presentation clarity.T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122109Algorithm 1 Lowering the ratio bound with further search.1: if PFG2:−thenSearch P A[n], P A[n−1,1], P A[n−2,1,1], . . . , P A[1,1,...,1].3: else4:Search P AI : |I| (cid:3) 2 and then search P A[n−2,1,1].5: end if6: for I ∈ In such that searched(P A7:8: end for9: for β = (cid:15) n2r ← 1; c ← 1.10:for I ∈ In such that searched(P A11:initialize(partitionI ). {see Algorithm 1.1}(cid:16) down to 2 {main loop} doI ) = 0 dor ← r + 1.rows[r] ← partitionI ;for I(cid:3)(cid:3) ∈ partitionI do(cid:3), I(cid:3) (cid:17) Iif I(cid:3) (cid:17) Icolumns[c] ← I(cid:3)(cid:3) /∈ columns then;(cid:3)(cid:3)c ← c + 1.I ) = 0 and |partitionI| = β doend ifend forend forfor r = 1 to |rows| dofor c = 1 to |columns| doif ∃I(cid:3), I(cid:3)(cid:3) ∈ rows[r] : Imatrix[r][c] ← 1.(cid:3) (cid:17) I(cid:3)(cid:3) = columns[c] thenelsematrix[r][c] ← 0.end ifend forend forfor c = 1 to |columns| dothensubspace[c] ← P Aif PFG−columns[c](cid:17)Ielsesubspace[c] ← P Acolumns[c](cid:17)I(cid:3) ∈ In−|columns[c]|, I(cid:3) = [1, . . . , 1].(cid:3) : I(cid:3) : I(cid:3) ∈ In−|columns[c]|, I(cid:3) = [n − |columns[c]|].end ifend forfor c = 1 to |columns| doif searched(P Acost[c] ← 0subspace[c]) = 1 thenelsecost[c] ← |subspace[c]|end ifend forfor c = 1 to |columns| − 1 dofor c(cid:3) = c + 1 to |columns| doif subspace[c] = subspace[cfor r = 1 to |rows| do(cid:3)] thenif matrix[r][cmatrix[r][c(cid:3)] = 1 then(cid:3)] ← 0; matrix[r][c] ← 1end ifend forend ifend forend forλ ← integerSolver(matrix, cost) {call the integer solver}for c = 1 to |columns| doif λ[c] = 1 thenSearch through subspace[c].end ifend forfor I ∈ In such that searched(P A12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:32:33:34:35:36:37:38:39:40:41:42:43:44:45:46:47:48:49:50:51:52:53:54:55:56:57:58:59:I ) = 0 do(cid:3)(cid:3) ∈ partitionI such that I(cid:3)(cid:3)}partitionIfor c = 1 to |columns| doif λ[c] = 1 and ∃I(cid:3), I← partitionI60:61:62:63:64:65:66: end for67: Search through the remaining coalition structures. {This is to drop β from 2 to 1.}(cid:3)(cid:3) = columns[c] thenend ifend for(cid:3)(cid:3)} ∪ {Iend for(cid:3) (cid:17) I(cid:3) (cid:17) I\ {I(cid:3), I110T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122← ∅∪ {[i]}← partitionI(cid:3)| = multiplicity(1, I)Algorithm 1.1 initilize(partitionI ); part of Algorithm 1.1: partitionI2: for i ∈ I, i > 1 dopartitionI3:4: end for−then5: if PFG(cid:3) ← [1, . . . , 1] : |II6:partitionI7:8: else(cid:3) ← [1, 1]I9:for k = 1 to (cid:12)multiplicity(1, I)/2(cid:13) do10:← partitionI11:12:13:14:15:16: end if← partitionI← partitionIpartitionIpartitionI∪ [1]end if∪ I∪ I(cid:3)(cid:3)end forif (cid:12)multiplicity(1, I)/2(cid:13) (cid:6)= (cid:15)multiplicity(1, I)/2(cid:16) then+−= {[1, 1, 1], [3]} in PFG, and partitionI= {[1], [1, 1], [3]}Algorithm 1.1). For example, given I = [1, 1, 1, 3], we have partitionI. As described earlier, the size of the biggest such partition(s) is what determines the ratio bound β, and what wein PFGneed is to drop this size in order to improve the bound. This is done in the main loop (steps 9 to 66), where the size (i.e.,the bound β) drops by 1 after every iteration. More specifically, we build a matrix such that: (i) every row corresponds toone of the biggest partitions (steps 10 to 12), and (ii) every column corresponds to a combination that reduces the size ofat least one of those partitions (steps 13 to 17), and (iii) the matrix at row r and column c is assigned a value of “1” if thecombination at column c reduces the size of the partition at row r, otherwise it is assigned a value “0” (steps 19 to 27).An example of such a matrix can be seen in Fig. 4. After that, for every column c, we store in subspace[c] the subspacethat needs to be searched (i.e., needs to be added to Y (cid:3)) such that the combination corresponding to column c is observedwith its maximum value (steps 28 to 34). For example, given 10 agents, and given the combination [3, 4], the subspace thatneeds to be searched would be [1, 1, 1, 3, 4] in PFG, and [3, 3, 4] in PFG(see Theorem 1). An integer solver is then usedto find a set of columns such that, for every row, there exists at least one column in which the value is “1”. This solvertakes into consideration the “cost” of every column, which is computed in steps 35 to 41. In more detail, the cost of a givencolumn is the size of the corresponding subspace, unless that subspace has already been searched, in which case the costis 0. The integer formulation is as follows:+−Minimize|columns|(cid:5)c=1λ[c] × cost[c]s.t. ∀r ∈ {1, . . . , |rows|},|columns|(cid:5)λ[c] × matrix[r][c] (cid:2) 1(cid:8)(cid:9)1, . . . , |columns|∀c ∈c=1, λ[c] ∈ {0, 1}+An important point to note, here, is that different columns may have the same corresponding subspace. For example, givensetting with 10 agents, a column corresponding to the combination [5, 1], and another corresponding to [4, 1],a PFGboth require searching P A[5,4,1]. Similarly, the columns corresponding to [7, 1], [7, 1, 1] and [1, 1, 1] all require searchingP A[7,1,1,1]. This means that if we “pay the cost” of adding one of these combinations to Z (i.e., if we search the subspacein which this combination appears with its maximum value), then we can add the other combinations to Z “at no extracost”. To take this into account, all such columns need to be combined into one. More specifically, given a set of columnsI that require searching P A, we combine them all into one column, say cδI , . . . , cδc1I , c2I , as follows: For every row r, we set] = 1 if there exists at least one column ck] = 0. Asmatrix[r][cδIj] = 0. In Fig. 4, for example, since columns 2 and 9 requireI :for the remaining columns, i.e., csearching one subspace, namely P A[5,4,1], we can combine them into one column, say column 9, by setting matrix[1][9] = 1,matrix[2][9] = 1, and marix[3][9] = 1, and setting matrix[r][2] = 0 for every row r. Note that the cost of both columnsremains unchanged. Once the integer solver finds the required columns (step 53), we search the subspace that correspondsto each of these columns (steps 54 to 58). Finally, for every subspace P Athat has not yet been searched, we updateIpartitionI to take into consideration the combinations that have just been observed with their maximum values (steps 59 to65). For example, given partition[2,2,3,3] = {[2], [2], [3, 3]}, and given that we searched the subspace that corresponds to thecombination [2, 2], then this can be interpreted as adding [2, 2] to Z . As a result, we update partition[2,2,3,3] by setting it to{[2, 2], [3, 3]}.] = 1, otherwise we set matrix[r][cδII such that matrix[r][ckj (cid:6)= 1, we set matrix[r][cjIII4.4. PreprocessingBefore detailing the preprocessing procedure, we first discuss its underlying theoretical background. In particular, themain theoretical results upon which we build are as follows:T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122111Fig. 5. The figure shows how the integer partitions of 4 and 5 appear in the integer partition of 6.Lemma 1. Given the integer partition graph of s (i.e., G(I s)), let G(I s)spartition) contains at least sthen G(I s)s(cid:3)becomes identical to G(I s−sintegers that are equal to 1 (where s).(cid:3)(cid:3)(cid:3)(cid:3) < s). Then, if we remove those sdenote the part of G(I s) in which every node (i.e., integerparts from every node in G(I s)s,(cid:3)(cid:3)An example is shown in Fig. 5. What is interesting is that, by removing [1, 1] from every node in G(I 6)2 for example,then we will not only get all the integer partitions in I 4, but these integer partitions will also be ordered and connected inexactly the same way as they are in G(I 4). This particular observation will be used in our preprocessing algorithm as wewill see later in this section. Now, we give the main theorem:Theorem 4. Consider a PFGP can be pruned from the search space if there exists another partition P(PFG(cid:3) ∈ P C such that:) setting. Then, given a coalition C ⊆ C and a partition P ∈ P C , any coalition structure containing−+∀p(cid:3) ∈ P(cid:3), ∃p ∈ P :(cid:3) ⊆ (⊇)p and UBP (cid:3) LBPp(cid:3)−(cid:3), ∃p ∈ P : p, we will prove that, for any coalition structure CS ⊇ P , there exists another coalition structure CS) setting, and given two partitions P , P(cid:3) ∈ P C such that: ∀p(cid:3) ∈ P(PFG(cid:3) ⊆ (⊇) p and(cid:3) ⊇ Psuch that(cid:3)+Since P is a partition of C , then CS\P must be a partition of C . In particular, let P = CS\P , then of course, CS = P ∪ P .(cid:3) ∪ P . In this, we end up with a different coalition structure, denoted CS, such that: CS(cid:3) = P(cid:3)(cid:3)(cid:10)(cid:11)(cid:3)(cid:10)(cid:3)(cid:11)(cid:3)(cid:10)(cid:11)(cid:3)(cid:3), ∃p ∈ P : pW (CS) = W (P , CS) + W (P , CS) and W(cid:3) ∈ PSince we have: ∀pon this, as well as the fact that P and P( P ) by performing multiple steps, each involving the merging of two coalitions from P(CSand due to negative (positive) externalities, we have:(cid:11)(11)(cid:3)). Based(cid:3)) can be reached from P( P ). This, in turn, implies that CS(CS) by performing merging steps that do not involve any of the coalitions in P . As a result,are partitions of the same coalition, we find that P ( P(cid:3) ⊆ (⊇) p, then every coalition in P( P ) is a subset of some coalition in P (P) can be reached from CS+ W(cid:3)= WP , CS, CSCSP(cid:10)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)V (P , CS) (cid:3) V(cid:3)P , CSOn the other hand, since UBP (cid:3) LBP (cid:3) , then we have:V (P , CS) (cid:3) V(cid:3)P, CS(cid:10)(cid:11)From (11), (12), and (13), we find that V (CS) (cid:3) V (CSspace. (cid:2)(12)(13)(cid:3)). This, in turn, implies that CS can be pruned from the searchProof. Given a PFG(cid:3)UBP (cid:3) LBPW (CS) (cid:3) W (CS(cid:3)).Now, by replacing P with Pcase, we have:From Theorem 4, we can see that the following lemma holds:Lemma 2. Consider a PFGpartition G ∈ In: I ⊆ G can be pruned from the search space if there exists another integer partition I+) setting. Then, given an integer partition I ∈ I s: s (cid:3) n, any subspace represented by an integer(cid:3) ∈ I s such that:− (PFG∀i ∈ I(cid:11)(cid:3)(cid:10)I, ∃ J ⊆ I(cid:3)(I):= i and UBI (cid:3) LBI (cid:3)(cid:5)j∈ J112T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122for I ∈ (cid:21)I {Add [1] to every element in (cid:21)I} doAlgorithm 2 Prune subspaces based on Lemma 2.1: (cid:21)I ← {[1]} {Initialization}2: for s = 2 to n do3:4:5:6: (cid:21)I ← (cid:21)I ∪ getIntParts(s,2)7:8:I ← I (cid:17) [1]end forfor I ∈ (cid:21)I do−if ( PFGor (PFG+and ∃Iand ∃I(cid:3) ∈ (cid:21)I : I → I(cid:3) ∈ (cid:21)I : I(cid:21)I ← (cid:21)I\I {remove I from (cid:21)I}(cid:3), UBI (cid:3) LBI(cid:3) )(cid:3) → I, UBI (cid:3) LBI(cid:3) ) then9:end if10:end for11:12: end for13: return (cid:21)IThe condition ∀i ∈ I (Ithan the number of parts in Ibelonging to consequent levels of the graph. In this case, we use the notation: I → Ihave: [1, 5] → [1, 1, 1, 1, 2] ([1, 1, 1, 1, 2] → [1, 5]).= i in Lemma 2 implies that the number of parts in I is smaller (greater)are connected in the integer partition graph of s via a series of nodes(cid:3) → I ). In Fig. 5, for example, we(cid:3), and that I and I(cid:3)), ∃ J ⊆ I(cid:3)(cid:3)(I):j∈ J(I(cid:3)(cid:3)We can now show how both Lemmas 1 and 2 are used in our preprocessing algorithm to prune subspaces (see Algo-rithm 2). Basically, the algorithm tries to find the integer partitions in I 2 that can be pruned using Lemma 2, and thenmoves to I 3, and then I 4, and so on until it reaches In. The way it moves from I s−1 to I s is done using the observationfrom Lemma 1. More specifically, the algorithm adds [1] to every integer partition in I s−1, and then combines the resultinginteger partitions with those in I s that do not contain 1. To generate the integer partitions of s that do not contain any1s, we use getIntParts(s, 2). This function can be implemented using any algorithm that generates doubly-restricted11integer partitions, e.g., the Parta algorithm [29].4.5. Searching a subspaceIn this section, we briefly describe the searching method in the IP algorithm, and then show how it can be revised forthe PFG/PFGcase.+−(cid:3)(cid:3)I as follows: UBI =As mentioned earlier in Section 3, the IP algorithm computes, for all I ∈ In, upper and lower bounds on the value ofthe best coalition structure in P As∈I Maxs, LBI =s∈I Avgs. These bounds are used to identify, andconsequently prune, unpromising subspaces. As for the promising ones, IP searches them one at a time, unless a value isfound that is higher than the upper bound of another subspace, in which case, that subspace no longer needs to be searched.The order in which the algorithm searches through these subspaces is based on their upper bounds (i.e., it starts with theone with the highest upper bound, and then the second-highest and so on). Searching a subspace P AI : I = [i1, i2, . . . , i|I|] iscarried out using depth-first search combined with branch-and-bound. Basically, for every coalition of size i1, denoted C1, thealgorithm finds the coalitions of size i2 that do not overlap with C1, and for every such coalition, denoted C2, the algorithmfinds the coalitions of size i3 that do not overlap with C1 and C2, and so on. This is repeated until we reach the coalitionsof size i|I| that do not overlap with C1, C2, . . . , C|I|−1. For every such coalition, denoted C|I|, we would have a coalitionstructure CS = {C1, . . . , C|I|} ∈ P A. This process is repeated in such a way that is guaranteed to go through every coalitionIstructure in P AI exactly once. To speed up the search, IP applies a branch-and-bound technique as follows. If we denote byCSthe best coalition structure found so far, then, before the algorithm goes through the coalitions of size ix that do notoverlap with C1, . . . , C x−1, it checks whether the following holds12:∗∗v(C1) + · · · + v(C x−1) + Maxix+ · · · + Maxi|I| (cid:3) V(cid:11)∗∗(cid:10)CSIf the above holds, then there is no need to go through any of the coalitions of size ix that do not overlap with C1, . . . , C x−1.This is because any coalition structure containing C1, . . . , C x−1 cannot possibly be better than CS∗∗.The main difference in our PFGsetting (compared to CFGs) is that, instead of having one value for every coalitionC , we have a maximum value UBC and a minimum value LBC (see Section 4.1 for more details). Based on this, we modifyIP as follows:/PFG−+• We add a preprocessing stage, which consists of Algorithm 1 (to prune unpromising subspaces) and Algorithm 2 (toidentify the order by which the remaining subspaces need to be searched).11 Unlike restricted integer partitions, where the parts are only bounded by a maximum value, doubly-restricted integer partitions consist of parts that arealso bounded by a minimum value. getIntParts(s, 2) sets the minimum value to 2 so that the resulting integer partitions do not contain any 1s.12 Here, v(C) is used (instead of w(C, CS)) to refer to the value of C in CS. This is because IP deals with CFGs where every coalition has one value,regardless of the coalition structure to which it belongs.T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122113• We compute Maxs and Avgs as follows:∀s (cid:3) n, Maxs = maxUBCC⊆ A: |C|=sand Avgs= avgC⊆ A: |C|=s LBC .• The order in which we search through subspaces is based on our anytime algorithm for reducing the ratio bound β(i.e., we always search the subspaces that are necessary to drop the current ratio bound).• While searching a subspace P AI :I = [i1, i2, . . . , i|I|], and before going through the coalitions of size ix that do notoverlap with C1, . . . , C x−1, we check whether the following holds, where UB{C1,...,C x−1} is computed as in Section 4.1:UB{C1,...,C x−1} + Maxix+ · · · + Maxi|I| < V(cid:11)∗∗(cid:10)CS5. Performance evaluation(14)In this section, we propose an equation for generating random input instances to be used for evaluating CSG algorithms+−in PFG/PFG(Section 5.1). This equation is then used while evaluating our IPalgorithm (Section 5.2).+/−5.1. Input generation+/−In order to evaluate our IPalgorithm, we need to be able to generate random input instances of PFG−) suchthat only positive (negative) externalities occur whenever two coalitions merge. This means, in particular, that for any twocan be created from CS by a series of coalition mergers, the value ofarbitrary coalition structures, CS and CSany coalition not involved in these mergers must not be smaller (greater) in CSthan in CS. Next, we provide an equationfor generating random input instances, and prove that the resulting partition function is guaranteed to satisfy the conditionsof PFG, such that CS−+/PFG+(PFG.(cid:3)(cid:3)(cid:3)To this end, let us assume, without loss of generality, that the agents in every coalition are ordered ascendingly, and thatthe coalitions in any partition are also ordered ascendingly based on the smallest13 agent in each coalition. Now, let l(ai, C)be the location of agent ai in C (e.g., l(a6, {a2, a5, a6, a9}) = 3), and let l(ai, P ) be the location of the coalition in P thatcontains ai (e.g., l(a6, {{a1, a7}, {a3, a5, a6}, {a4, a9}}) = 2). With these definitions in place, we now show how to generate the) condition is met. At first, for every coalition C , we generate the following non-coalition values such that the PFGj=1 eC, j = eC . After that, for any coalition structurenegative random values: v C and eC and eC,1, eC,2, . . . , eC,|C| such thatCS (cid:23) C , we set the value of C as follows:(cid:3)|C|(PFG+−w(C, CS) = v C − (+)(cid:5)ai ∈CeC,l(ai,C)∗(cid:6)1 − l(ai, CS\{C}) − 1|C|(cid:7)(15)In more detail, v C represents the value of coalition C in the absence of any externalities, while the remainder of the left-hand side of (15) represents the externality induced upon C in CS. Note that this externality is always smaller than, or equalto, eC . This comes from the fact that: ∀ai ∈ C : l(ai, CS\{C}) (cid:2) 1, which implies that:(cid:6)(cid:5)ai ∈CeC,l(ai,C)∗(cid:7)1 − l(ai, CS\{C}) − 1|C|(cid:6)(cid:7)1 − 1 − 1|C|eC,l(ai,C)∗eC,l(ai,C)(cid:5)ai ∈C(cid:5)(cid:3)(cid:3)ai ∈C(cid:3) eCTheorem 5. By setting the value of each coalition as per Eq. (15), we obtain a PFG− (PFG+) setting.Proof. Given a partition P and a coalition p ∈ P , let s(p) denote the smallest agent in p, and let s(p, P ) be defined asfollows:s(p, P ) =(cid:8)(cid:9)s( ˜p): ˜p ∈ P , s( ˜p) < s(p)(16)In other words, s(p, P ) contains the smallest agent from every coalition that appears before p in P , e.g., s({a4, a9},(cid:3) ∈ P C such that ∀p(cid:3) ∈ P(cid:3), ∃p ∈ P : p(cid:3) ⊆ p, we will prove that{{a1, a7}, {a3, a5, a6}, {a4, a9}}) = {a1, a3}.Next, given a coalition C , and given any two partitions P , Pthe following holds:13 For any two agents ai , a j ∈ A, we say that ai is smaller than a j if i < j.114T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122(cid:10)vC, {C} ∪ P(cid:11)(cid:3) ((cid:2))(cid:10)vC, {C} ∪ P(cid:11)(cid:3)(17)From (15), we find that the inequality in (17) holds if, and only if:(cid:6)(cid:5)ai ∈CeC,l(ai,C)∗1 − l(ai, P ) − 1|C|(cid:7)(cid:2)(cid:5)ai ∈CeC,l(ai,C)∗(cid:6)(cid:3)) − 11 − l(ai, P|C|(cid:7)(cid:5)By removing eC,l(ai ,C), we find that:(cid:6)(cid:6)1 − l(ai, P ) − 1|C|(cid:5)(cid:2)(cid:7)(cid:7)(cid:3)) − 11 − l(ai, P|C|ai ∈C(cid:5)ai ∈C(cid:5)ai ∈Cl(ai, P ) − 1|C|l(ai, P ) (cid:3)(cid:5)ai ∈Cai ∈Cl(ai, P(cid:3)) − 1(cid:5)(cid:3)|C|ai ∈C(cid:10)ai, Pl(cid:11)(cid:3)Then, to prove that (17) holds, it is sufficient to prove that:(cid:10)ai, P(cid:11)(cid:3)∀ai ∈ C ,l(ai, P ) (cid:3) lTo this end, for any agent ai ∈ C , let pi, prespectively. Then, to prove that (18)holds, we need to prove that the number of coalitions that appear before pi in P is smaller than, or equal to, the number(cid:3))|. This can be done byof coalitions that appear before pproving that:. In other words, we need to prove that: |s(pi, P )| (cid:3) |s(p(cid:3)i be the coalitions that contain ai in P , P(cid:3)i in P(cid:3)i, P(18)(cid:3)(cid:3)s(pi, P ) ⊆ s(cid:11)(cid:3)(cid:10)(cid:3)i, Pp(cid:3)In order to do so, we will first prove that all the agents in s(pi, P ) belong to s(pi, P(cid:3)) that do not belong to s(pi, P ). To this end, note that:there could be agents in s(p(cid:3)i, P(cid:3)). After that, we will prove that(a) Every agent in s(pi, P ) appears in a different coalition in P(cid:3). In other words, no coalition in P(cid:3)from s(pi, P ). Otherwise, if two, or more, agents from s(pi, P ) appear in the same coalition in Pwould not be a subset of a coalition in P , which contradicts with the following assumption: ∀p(cid:3) ⊆ p.(cid:3)i is a subset of pi , which comes from the fact that ai ∈ pi and, ∃p ∈ P : pcontains more than one agent, then this coalition(cid:3)(cid:3)(cid:3) ∈ P(cid:3)(b) s(pi) is smaller than, or equal to, s(pi). This is because p(cid:3) ⊆ p.(cid:3) ∈ P(cid:3), ∃p ∈ P : pai ∈ p(cid:3)i and ∀pFrom the above two observations, as well as (16), we find that every agent in s(pi, P ) belongs to s(pshow that there could be agents in s(pAssume that i = 6, and that:(cid:3)). What is left is to(cid:3)) that do not belong to s(pi, P ). We show this through the following example.(cid:3)i, P(cid:3)i, P(cid:8)(cid:9)P =(cid:3) =P{a1, a8}, {a3, a4, a9}, {a5, a6, a7}(cid:8){a1, a8}, {a3, a9}, {a4}, {a5, a7}, {a6}(cid:9)In this case: p6 = {a5, a6, a7} and p(cid:3)6= {a6}. As can be seen: s(p6, P ) = {a1, a3}, while s(p(cid:3)6, P(cid:3)) = {a1, a3, a4, a5}. (cid:2)Importantly, Eq. (15) places no assumptions/restrictions on v C and eC . In other words, these can be sampled fromany distribution, e.g., Gaussian, Uniform, etc. Also note that, for any coalition C and coalition structure CS (cid:23) C , the totalexternality imposed upon C is smaller than, or equal to, eC . This gives the ability to place an upper bound on the externality.For example, in order to simulate a setting where a coalition’s value can only increase (decrease) by at most 30% due toexternalities, we simply set eC = 0.3 ∗ v C .Next, we analyze the memory required to store different input instances. In particular, while the resulting partitionfunction consists of O (nn) values, we will prove that it only requires storing O (n2n) values.Theorem 6. An input instance generated as per Eq. (15) can be stored in memory by maintaining O (n2n) values.Proof. From Eq. (15), we can see that for every coalition C the equation only requires storing v C and eC,1, eC,2, . . . , eC,|C|.14Moreover, for all C ∈ C, we have: |C| (cid:3) (n − 1). This means the number of values that need to be stored for any coalitionC ∈ C is less than, or equal to, n. The total number of values is therefore less than n ∗ 2n. (cid:2)14 Note that we do not need to store eC as it can be computed by simply summing the values: eC,1, eC,2, . . . , eC,|C|.T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122115Fig. 6. Given 24 agents, the figure shows the ratio bound as a function of the number of searched coalition structures (log scale).5.2. Performance evaluationAs mentioned earlier in the introduction, to establish progressively better ratio bounds in a PFG setting, we propose(i) a way of dividing the search space into subspaces, and (ii) a sequence in which these subspaces must be searched, sothat the bound is improved after each subspace. While there are two algorithms that do exactly that, namely Sandholm etal.’s [1] and Dang and Jennings’s [2], these are designed for CFGs, and so cannot be applied in a PFG setting. Nevertheless,since ours is the first such algorithm for PFGs, and since CFGs are a special case of PFGs, then we will benchmark oursagainst those two algorithms (in a CFG setting). Intuitively, one could expect our algorithm to perform worse than theothers, especially since they exploit the special properties of CFGs, while ours does not. In more detail, the CFG algorithmstake advantage of the assumption that every coalition has the same value regardless of the coalition structure in which it isembedded. Obviously, we do not take any such advantage since our algorithm is originally designed for PFGs.+Given 24 agents, Fig. 6 illustrates (using a log scale) the ratio bound as a function of the number of coalition structuressearched.15 As can be seen, given a PFGsetting, our algorithm is significantly faster than the existing CFG ones. Forexample, the number of coalition structures required by our algorithm to establish a ratio bound of 3 is only 0.001% of that−required by Sandholm et al. [1], and only 1% of that required by Dang and Jennings [2]. On the other hand, given a PFGsetting, our algorithm requires searching more coalition structures (compared to other algorithms) in order to establish its−11 of thefirst ratio bound (see Theorem 3). However, once it establishes this bound, which only requires searching 4 × 10space, it becomes significantly faster, compared to the others. For example, the number of coalition structures to establish aratio bound of 3 is only 0.0007% and 0.5% compared to Sandholm et al.’s and Dang and Jennings’s, respectively.The main reason behind this gain is that our steps are defined in a much more informed manner compared to the otheralgorithms. More specifically, every step in Sandholm et al.’s algorithm searches all coalition structures of certain size, andevery step in Dang and Jennings’s algorithm searches all coalition structures where the biggest coalition is of a certain size.Our results show that these are not the best steps that one can take to drop the bound. By tailoring our steps to suite ourobjective, which is to rapidly reduce the bound, we manage to outperform those algorithms.So far, we have evaluated the way IPdivides the search space, and the sequence in which the subspaces are searched.Next, we evaluate the algorithm’s ability to find progressively better solutions in various test settings. In this context, wetested our algorithm given:+/−• different numbers of agents, ranging from 10 to 2016;• different types of externalities (i.e., positive and negative);• different percentages of externalities ranging from 0% to 100%. Here, when reporting a result given x% externality, wemean that the total externality affecting any given coalition is at most x% of its value. More specifically, for any coalitionC , the value eC is sampled from the uniform distribution U (0, v(C) ∗ x/100);• different value distributions. Specifically, we use the following standard distributions in the CSG literature [30,6]:(a) Normal: v(C) ∼ |C| × N(μ, σ 2) where μ = 1 and σ = 0.1.(b) Uniform: v(C) ∼ |C| × U (a, b) where a = 0 and b = 1.|C|.(c) NDCS: v(C) ∼ N(μ, σ 2), where μ = |C| and σ =√15 Similar patterns were observed given different numbers of agents.16 The results are reported as an average of 500 runs given n ∈ {10, 11, 12}, 300 runs given n ∈ {13, 14, 15}, and 100 runs given n ∈ {16, . . . , 20}.116T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122Fig. 7. Given negative externalities, the figure shows on a log scale the total run time of IP+/−given different numbers of agents.Every combination of the above represents a different setting. For example, a possible setting would be: 18 agents,with positive externalities, with percentage of externalities equal to 10%, and with Uniform distribution. Hence, given thelarge number of possible settings, we only report the results for some of them, and that is whenever similar patterns areobserved for the remaining ones (e.g., if we report a certain result for only negative externalities, then this implicitly meansthat similar results where observed for positive externalities).In all our experiments, the process of calculating the sequence of subspaces took insignificant time and space, e.g., lessthan 1 second and less than 15 kb of memory for each of the aforementioned settings. This is because this process dealswith the space of integer partitions, not the space of coalition structures (e.g., given 20 agents, there are only 627 integerpartitions, as opposed to more than 5 × 1013 coalition structures). Furthermore, the process of calculating the sequence ofsubspaces needs to be done once for any given number of agents; the sequence can then be stored and used for differentproblem instances (unlike the process of searching the subspaces, which needs to be repeated for each problem instance).Given negative externalities, Fig. 7 shows on a log scale the total run time of IPgiven different numbers of agents,where time is measured as the clock time (in milliseconds) on a PC with 8 Intel 2.67 GHz processors and 12 GB of RAM.As can be seen, the growth rate of the run-time is similar to O (2.7n) given the NDCS distribution, and similar to O (2.32n)given Uniform and Normal distributions. This is significantly smaller than O (nn) — the growth rate of the size of the searchspace. This difference comes from the algorithm’s ability to identify, and thus prune, unpromising subspaces and coalitionstructures.−Next, we test our algorithm given different percentages of externalities. In particular, Fig. 8 shows how a change in thispercentage affects both the total run time and the number of expansions made by the algorithm.17 As expected, there isa direct correlation between the two results. The figure also shows that the number of expansions is always slightly morein PFG. This is because the effectiveness of the branch-and-bound technique, which is directly reflected in. To better understand the reason behind this, we need to analyzethe number of expansions made, is slightly less in PFGthe effect that different externalities have on Eq. (14) — the main equation in the branch-and-bound technique. Intuitively,while both sides of the equation increase in PFG, the ratio between the two sides becomes differentin PFG, resulting in a change in the effectiveness of branch-and-bound. In more detail:and decrease in PFGthan in PFGthan in PFG+−−++−+/−+∗∗) in Eq. (14) increases in PFG• the term V (CS• the terms “Maxix• the term “UB{C1,...,C x−1}” increases in PFG−.unchanged in PFG++ · · · + Maxi|I| ” increases in PFG+and decreases in PFG−.but remain unchanged in PFG−−.and decreases in PFG, except for when x = 0, in which case it remainsThe above means that the increase in the left-hand side of Eq. (14) in PFG−.turn, implies that the number of prunings is greater in PFGthan in PFG++is greater than the decrease in PFG−. This, inNext, we analyze how the solution quality and bound quality improve during run time. Observe that the bound thatis evaluated here is different from the one that was evaluated earlier in Fig. 6: here, the bound is calculated based on thecoalition values of the problem instance at hand, while the previous bound is calculated based on the sequence of subspaces(i.e., it is independent of the coalition values).17 Recall that each subspace is searched using depth-first search. The number of expansions is then the total number of nodes that were searched by thealgorithm in different subspaces.T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122117Fig. 8. Given 20 agents, the figure shows the total run time of IP(right-hand side) given different percentages of externalities.+/−(left-hand side) and the total number of expansions made by IP+/−in the search tree118T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122Fig. 9. Given 20 agents and negative externalities, the figure shows how the solution quality and bound quality improve during the run time of IP+/−.Fig. 9 shows how the solution quality and bound quality improve during run time, and that is given 20 agents andnegative externalities.18 In more detail, the X-axis in the figure corresponds to the percentage of time that has elapsed, with0% being the time at which the algorithm starts, and 100% being the time at which it terminates. For every percentage oftime t%, we report the following:18 Observer that this bound is calculated using information that was extracted from the problem instance at hand (unlike the bound that was calculatedearlier based on the sequence of subspaces, which is independent of the problem instance). Thus, it is different from the bound that was calculated earlierbased on the sequence of subspaces (which is independent of the problem instance).T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122119Fig. 10. Given negative externalities, the figure shows on a log scale the percentages of space that has been searched by IPagents.+/−given different numbers of120• IP+/−T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122solution quality: This is computed as the ratio between the value of the best coalition structure (found at time t%)and the value of the optimal coalition structure (found at time 100%).• IP+/−bound quality: This is computed as the ratio between the value of the best coalition structure found and themaximum upper bound of all remaining subspaces (i.e., those that were neither searched nor pruned).• Theoretical bound β: This is computed as shown in Section 4.3.As can be seen, the solution quality exceeds 90% in less than 1% of the run-time given the Normal and Uniform distribu-tions, and less than 10% given the NDCS distribution. Moreover, the bound quality is significantly better than the theoretical,worst-case, bound.Finally, given negative externalities, Fig. 10 shows on a log scale the percentage of space that has been searched by IPgiven different numbers of agents. This is computed as the ratio between the number of expansions made by the algorithmand the total number of expansions in the search space. As can be seen, the algorithm only searches an extremely smallfraction of the space (e.g., less than 0.00001% given 20 agents). Furthermore, this fraction gets consistently smaller as thenumber of agents increases.+/−6. ConclusionsThe Coalition Structure Generation (CSG) problem within the AI community has been studied almost exclusively in thecontext of characteristic function games where no externalities are allowed. This is despite the fact that, in many real-worldsettings, externalities do exist and need to be accounted for. Taking externalities into consideration makes the CSG problemsignificantly more challenging as the input size grows from O (2n) to O (nn).−+and PFG, where externalities are weakly positive in PFGAgainst this background, we provide in this paper the first computational study on CSG in partition function games. Morespecifically, we develop a novel, anytime algorithm that solves the CSG problem in two important classes of these games,. Our algorithmnamely PFGcapitalizes upon the following theoretical results. Firstly, we prove that it is possible to bound the values of any group of. Secondly, we identify the set of coalition structures that has to be searched in order to establishcoalitions in PFGa worst-case bound on solution quality. Thirdly, we prove that, by traversing the space of possible solutions in a particularmanner, we are guaranteed to improve this worst-case bound. Fourthly, we show that, by satisfying certain conditions, it ispossible to prune parts of the search space.and weakly negative in PFG−+/PFG+−To test our algorithm, we propose an equation for generating random input instances, and prove that the resulting. We also prove that this function, which consistspartition function is guaranteed to satisfy the conditions of PFGof O (nn) values, only requires storing O (2n) values in memory. This function can be used as a standard benchmark forevaluating any potential CSG algorithms that could be developed in the future for PFG+/PFG−+/PFG−.Since there are no previous CSG algorithms for games with externalities, we benchmark our algorithm against otherstate-of-the-art approaches in games where no externalities are present. Surprisingly, we find that, as far as worst-caseguarantees are concerned, our algorithm outperforms the others by orders of magnitude despite the fact that they takeadvantage of the special properties of games with no externalities, while our algorithm does not.With this paper, we have laid the foundations for further work on the CSG problem in partition functions games. Inparticular, we are keen to develop efficient CSG algorithm for classes of PFGs other than those considered in this paper.Indeed, building upon our theoretical results, the first such attempt was recently proposed by Banerjee and Landon [31],where externalities are influenced by the agents’ types. However, algorithms for more general classes are yet to be devel-oped. Another interesting direction is to extend our idea of generating random instances of PFGs using only O (n2n) space,and to use this idea as a building block for developing concise representations of various classes of PFGs.AcknowledgementsThis article is a significantly revised and extended version of [32] and [15]. Specifically, we present in this paper a morecomprehensive review of the CSG literature. Moreover, while our procedure for reducing the ratio bound was only brieflydescribed in [32], here we provide the pseudo code of this procedure, along with detailed explanations and extensive exam-game classes, andples. We also provide a mathematical proof for a function that generates random instances of PFGdiscuss its memory requirements. Furthermore, the evaluation section is substantially extended. In particular, we analyzethe effect that different amounts of externalities have on the run-time of the algorithm, and on the number of expansionsmade by the algorithm. We also show how the solution quality and worst-case guarantee improve during run-time. Finally,we analyze the percentage of space that is searched by our algorithm given different numbers of agents and different valuedistributions.−+/PFGTomasz Michalak and Michael Wooldridge acknowledge support from the EPSRC under the project Market Based Controlof Complex Computational Systems (GR/T10657/01). Tomasz Michalak acknowledges support from the EPSRC under theproject ALADDIN (Autonomous Learning Agents for Decentralised Data and Information Systems) project jointly funded bya BAE Systems and EPSRC strategic partnership.T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122121Appendix A. Summary of NotationThe set of agents.Agent in A.The number of agents in A.A coalition.Agents in A that do not belong to C , i.e., C = A\C .The set of all coalitions over A.The set of all coalitions of size s.A coalition structure.An optimal coalition structure.The set of all coalition structures.The set of all coalition structures of size s, i.e., level s in the coalition structure graph.The set of all coalition structures in which coalition sizes match the parts in integer partition I.The set of all partitions of coalition C .The set of all partitions of C in which coalition sizes match the parts in integer partition I.Partition in P C .Element of a partition P .Coalition C embedded in coalition structure CS.The value of C in CS, i.e., the value of embedded coalition (C, CS).The value of P in CS.The value of coalition structure CS.The value of coalition C .Upper bound on the value of the best CS in P AI .Upper bound on the values of the partitions in P CI .Upper bound on the value of coalition C .Upper bound on the value of partition P .Lower bound on the value of the best CS in P AI .Lower bound on the values of the partitions in P CI .Lower bound on the value of coalition C .Lower bound on the value of partition P .The set of all possible integer partition of number k.The integer partition graph of k.Level s in the integer partition graph of k.AainCCCCsCSCSP AP AsP AIP CP CI∗Pp(C, CS)w(C, CS)W (P , CS)W (CS)v(C)UB AIUBCIUBCUBPLB AILBCILBCLBPIkG(Ik)G(Iks )References[1] T.W. Sandholm, K. Larson, M. Andersson, O. Shehory, F. Tohme, Coalition structure generation with worst case guarantees, Artificial Intelligence(AIJ) 111 (1–2) (1999) 209–238.[2] V.D. Dang, N.R. Jennings, Generating coalition structures with finite bound from the optimal guarantees, in: Proceedings of the Third International JointConference on Autonomous Agents and Multi-Agent Systems (AAMAS), 2004, pp. 564–571.[3] S. Ieong, Y. Shoham, Marginal contribution nets: a compact representation scheme for coalitional games, in: EC-05, ACM, 2006, pp. 170–179.[4] O. Shehory, S. Kraus, Methods for task allocation via agent coalition formation, Artificial Intelligence (AIJ) 101 (1–2) (1998) 165–200.[5] S. Sen, P. Dutta, Searching for optimal coalition structures, in: Proceedings of the Sixth International Conference on Multi-Agent Systems (ICMAS-00),2000, pp. 286–292.[6] T. Rahwan, S.D. Ramchurn, A. Giovannucci, N.R. Jennings, An anytime algorithm for optimal coalition structure generation, Journal of Artificial Intelli-gence Research (JAIR) 34 (2009) 521–567.[7] W. Lucas, R. Thrall, n-Person games in partition function form, Naval Research Logistics Quarterly X (1963) 281–298.[8] E. Catilina, R. Feinberg, Market power and incentives to form research consortia, Review of Industrial Organization 28 (2) (2006) 129–144.[9] J. Plasmans, J. Engwerda, B. van Aarle, G.D. Bartolomeo, T. Michalak, Dynamic Modelling of Monetary and Fiscal Cooperation Among Nations, Springer,New York, USA, 2006.[10] S.-S. Yi, Endogenous formation of economic coalitions: a survey on the partition function approach, in: The Endogenous Formation of EconomicCoalitions, Edward Elgar, London, UK, 2003, pp. 80–127.[11] M. Finus, New developments in coalition theory: an application to the case of global pollution control, in: Environmental Policy in an InternationalPerspective, Kluwer Academic Publishers, Netherlands, 2003, pp. 19–49.[12] P. Dunne, Multiagent resource allocation in the presence of externalities, in: CEEMAS, 2005, pp. 408–417.[13] J. Oh, Multiagent social learning in large repeated games, Ph.D. thesis, School of Computer Science, Carnegie Mellon University, 2009.[14] J.S. Rosenschein, G. Zlotkin, Rules of Encounter: Designing Conventions for Automated Negotiation among Computers, MIT Press, MA, USA, 1994.[15] T.P. Michalak, T. Rahwan, J. Sroka, A. Dowell, M.J. Wooldridge, P.J. McBurney, N.R. Jennings, On representing coalitional games with externalities, in:J. Chuang, L. Fortnow, P. Pu (Eds.), ACM Conference on Electronic Commerce (ACM-EC), 2009, pp. 11–20.[16] R. Cornes, T. Sandler, The Theory of Externalities, Public Goods, and Club Goods, Cambridge University Press, 1996.[17] T. Rahwan, S.D. Ramchurn, A. Giovannucci, V.D. Dang, N.R. Jennings, Anytime optimal coalition structure generation, in: Proceedings of the TwentySecond Conference on Artificial Intelligence (AAAI), 2007, pp. 1184–1190.[18] D.Y. Yeh, A dynamic programming approach to the complete set partitioning problem, BIT Numerical Mathematics 26 (4) (1986) 467–474.[19] M.H. Rothkopf, A. Pekec, R.M. Harstad, Computationally manageable combinatorial auctions, Management Science 44 (8) (1995) 1131–1147.122T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–122[20] T. Rahwan, N.R. Jennings, An improved dynamic programming algorithm for coalition structure generation, in: Proceedings of the Seventh InternationalConference on Autonomous Agents and Multi-Agent Systems (AAMAS), 2008, pp. 1417–1420.[21] T. Rahwan, N.R. Jennings, Coalition structure generation: dynamic programming meets anytime optimisation, in: Proceedings of the Twenty ThirdConference on Artificial Intelligence (AAAI), 2008, pp. 156–161.[22] T.C. Service, J.A. Adams, Approximate coalition structure generation, in: Proceedings of the Twenty Fourth Conference on Artificial Intelligence (AAAI),2010.[23] T.C. Service, J.A. Adams, Constant factor approximation algorithms for coalition structure generation, Autonomous Agents and Multi-Agent Sys-tems 23 (1) (2011) 1–17.[24] N. Ohta, V. Conitzer, R. Ichimura, Y. Sakurai, A. Iwasaki, M. Yokoo, Coalition structure generation utilizing compact characteristic function representa-tions, in: I.P. Gent (Ed.), CP’09, in: Lecture Notes in Computer Science, vol. 5732, Springer, ISBN 978-3-642-04243-0, 2009, pp. 623–638.[25] T. Rahwan, T.P. Michalak, E. Elkind, P. Faliszewski, J. Sroka, M. Wooldridge, N.R. Jennings, Constrained coalition formation, in: Twenty Fifth AAAIConference on Artificial Intelligence (AAAI), 2011, pp. 719–725.[26] S. Ueda, M. Kitaki, A. Iwasaki, M. Yokoo, Concise characteristic function representations in coalitional games based on agent types, in: IJCAI’11: TwentySecond International Joint Conference on Artificial Intelligence, 2011, pp. 393–399.[27] T. Rahwan, S.D. Ramchurn, V.D. Dang, N.R. Jennings, Near-optimal anytime coalition structure generation, in: Proceedings of the Twentieth InternationalJoint Conference on Artificial Intelligence (IJCAI), 2007, pp. 2365–2371.[28] S.S. Skiena, The Algorithm Design Manual, Springer-Verlag, New York, USA, 1998.[29] W. Riha, K.R. James, Algorithm 29 efficient algorithms for doubly and multiply restricted partitions, Journal of Computing 16 (1974) 163–168.[30] K. Larson, T. Sandholm, Anytime coalition structure generation: an average case study, Journal of Experimental and Theoretical Artificial Intelli-gence 12 (1) (2000) 23–42.[31] B. Banerjee, K. Landon, Coalition structure generation in multi-agent systems with mixed externalities, in: Proceedings of the Ninth InternationalConference on Autonomous Agents and Multi-Agent Systems (AAMAS), 2010, pp. 175–182.[32] T. Rahwan, T. Michalak, N.R. Jennings, M. Wooldridge, P. McBurney, Coalition structure generation in multi-agent systems with positive and negativeexternalities, in: Proceedings of the Twenty First International Joint Conference on Artificial Intelligence (IJCAI), Pasadena, USA, 2009.