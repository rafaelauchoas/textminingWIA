ELSEVIER Artificial Intelligence 97 ( 1997) 45-82 Artificial Intelligence A logical notion of conditional independence: properties and applications Adnan Darwiche * Department of Mathematics, American University of Beirut, PO. Box 11-236, Beirut, Lebanon Received October 1995; revised April 1996 Abstract formulations to propositional several equivalent independence with respect logic and study of the proposed notion, towards a specific application of logical reasoning such as abduction and diagnosis. a framework a independence logic database around a directed acyclic graph. This structuring explicates many of We propose a notion of conditional some of its key properties. We present each oriented We suggest propositional the independences that is not necessarily Horn. The we develop an algorithm structure and can be used for deciding entailment, algorithm computing abductions and diagnoses. The presented results are motivated by similar results in the literature on probabilistic and constraint-based reasoning. @ 1997 Elsevier Science B.V. satisfied by the underlying database. Based on these structural for a class of structured databases in the size of a database computationally by structuring independences, for utilizing is linear logical Keywords: Independence; Structure-based reasoning; Graphoids; Causal networks; Pruning knowledge bases; Relevance; Logic; Probability 1. Introduction A major factor in slowing down sider irrelevant parts of a given database when computing prompted a considerable of identifying reasoners tend to con- to queries. This has amount of research on the notion of irrelevance, with the goal so they can be avoided by logical these [ 13,15,23,24]. irrelevant parts of a database logical computations is that reasoners answers Irrelevance has also been the subject of extensive to as independence referred it is typically where research reasoning, in probabilistic [ 191. The scope of independence ’ Email: darwiche@aub.edu.lb 0004-3702/97/$17.00 PII SOOO4-3702(97)00042-8 @ 1997 Elsevier Science B.V. All rights reserved 46 A. Danviche/Arti$cial Intelligence 97 (1997) 4.5-82 to be bigger than its scope there is a standard definition of independence in logic for at least two there in logic. This also contributes in probability, to be no agreement on a definition of irrelevance theory of logical Second, the computational irrelevance utility is perceived reasoning have not been based on irrelevance. This is contrary instead of a necessity since as a luxury reasoning where independence similar that irrelevance to the one for brings influential to is the building block of seems however, in probability, reasons. First, although seems to the lack of a comprehensive probabilistic to logical algorithms what one finds almost all state-of-the-art reasoning for logical in probabilistic independence. algorithms. Motivated by the role of independence can play a similar role in logical logic. Therefore, our definition of conditional reasoning, in probability, our goal in this paper is to show at least in the context of independence with respect independence with LCI, to of conditional Independence, resembles the definition distributions. We use Logical Conditional that independence propositional to propositional respect refer to the proposed definition. to probability databases here is not LCI per se, but rather Our contribution (a) (b) the framework we propose the various formulations ing tasks. for exploiting it computationally and of LCI that we provide with respect to different reason- for logical reasoning complexity of reasoning, We show that LCI introduces independence that conditional paradigm the computational of probabilistic clear how independence tasks. We utilize deciding abductions good example of how to use independence logical these formulations computing reasoning. The various entailment, reasoning. to propositional has introduced in which the amount of independence reasoning many of the tools and techniques to probabilistic reasoning. This includes a information decides the complexity controls just as independence of LCI formulations that we present make it can be computationally valuable to the corresponding reasoning by developing an algorithm and diagnoses. The algorithm provides information when deriving that can be used for a for algorithms In the following section, we provide a more extended notion of independence where we explain We also outline the structure of the paper in light of the results to be presented. introduction the choices we had to make in developing to the proposed it. 2. Key choices for independence When formulating a notion of independence, devote this section them. This helps in relating our approach It also provides a good opportunity to enumerating one faces a number of choice points. We some of these points and to presenting our position on to the spectrum of other existing approaches. for outlining the structure of the paper. What objects can appear sentences, dence relation a propositional in which predicates, even algorithms appear as part of an indepen- [ 131. In our proposal, four objects: database A and three sets of atomic propositions X, Y and 2. Specifi- relation? One finds proposals is a relation between in an independence atomic propositions, independence A. Darwiche/Art@cial Intelligence 97 (1997) 45-82 47 tally, LCI decides whether independence similar finds X independent to probabilistic of Y given Z. the holds, we write Indd (X, Z, Y) and refer to it as an LCI assertion. This is the database A finds X independent of Y given Z. When independence which tells us whether a probability distribution What decides literature on independence tions: the correctness of a definition of independence? (both probabilistic and logical), one finds In considering the two main posi- position and ( 1) A philosophical of independence ties. In most of these approaches, that is, formalizing change, [ 11,191. The probabilistic liefs on these grounds where belief ity. (2) A pragmatic position, where that starts with postulating then proposes a definition that adheres independence the irrelevance of certain notion of independence is formulated in a proposition corresponds some intuitive properties to these proper- in terms of belief to certain be- can clearly be motivated to its probabil- information one. That independence is not an absolute notion but rather is, there is no correct or incorrect definition of inde- in deciding the iden- test from A will not affect of independence may one. For example, if removed target the but rather a useful or not-very-useful test A k a, a definition of sentences in A that a task-specific pendence an entailment tification result. LCI, at least as developed provide different and equivalent a specific reasoning which are dual tasks. This computational leads in this paper, is meant formulations to be a pragmatic notion. of LCI, each explicating task. The tasks we cover are: deciding entailment abductions its usefulness and satisfiability, and diagnoses, which are also dual its of LCI that are meant to a total of four formulations tasks, and computing to explicate In fact, we to role in these different reasoning tasks. LCI, however, does have a formulation the closest one to probabilistic formulation satisfiability) and then lead into the other four formulations and Section 5 (abduction and diagnosis). based on belief change, which happens to be independence. We therefore start in Section 3 with this and in Section 4 (entailment to independence, independence be used computationally? How should approach task of interest. A very popular use of independence before attempting For example, the current practice a simpler irrelevant test A’ k LY, where A’ is obtained by removing to the test. If one is adopting a pragmatic then the usage of independence will depend on the reasoning a database for logical entailment, for reducing an entailment sentences test A t= CY into from A that are is to use independence though in testing certain computations. is in pruning Although LCI will support such usage, its main computational deciding for example, LCI will be used to decompose test A k LY into a number of local tests Al /= q, 42 k (~2, . . ., A,, k a,, where each A, is so small role is different. a global entailment entailment, test Ai b ai can be performed role of LCI, we point out that the following decom- in constant time. that its corresponding the computational To introduce In positions are generally not valid in logic: 48 A. Danviche/Artijcial Intelligence 97 (1997) 45-82 ( 1) Entailment: Decomposing an entailment test A b a V p into two simpler tests A+aandA+p. (2) Satis$abiZity: Decomposing two tests with respect (3) Abduction: Decomposing of cy and those of p. (4) Diagnosis: Decomposing of LY and those of p. a satisfiability test with respect to A U {cr A p} into to the smaller databases A U {a} the abductions of a finding and A U {p}. (Y V /? into the abductions the diagnoses of an observation cu/\p into the diagnoses We shall demonstrate, when certain ing in p. can be used tions. however, that each one of these decompositions independences hold between the atoms appearing becomes valid in (Y and those appear- In fact, Sections 4 and 5 provide examples of how such decompositions into a number of local computa- a global computation to decompose What is the source of independence to discover independence information Although strategy that is motivated by the following result: information ? Most existing approaches by pre-processing a given database [ 1517,231. attempt this is consistent with our utilization of independence, we advocate a different If a database A is graphically structured-that are dictated by a directed reveals many of the independences acyclic graph-then satisfied by the database. is, satisfies some conditions that the topology of the structure instead of automatically Therefore, we will propose explicating them by constructing Such databases how to read independences are defined precisely discovering the independences satisfied by a database, in the first place. in Section 6, which also contains a key result on a structured database from the topology of a database structure. independence a global reasoning is the degree of pruning the measure of success to decompose is the number of local tasks that result from the decomposition. What is the measure of success when using independence? When using independence to prune a database, using of success we identify task (entailment, in the number of arcs and nodes of the database of the algorithm in We start it allows. But when task into local tasks, the measure In Section 7, a reasoning into a number n of local tasks, where n is linear structure. We also discuss extensions a class of structured databases abduction, diagnosis) to other classes of structured databases. for which we can decompose three sections by providing five formulations the next of LCI, each are then shown to towards a specific reasoning oriented be equivalent. task. The different formulations 3. Belief change formulation Common intuitions about independence suggest that it is strongly of belief change. Therefore, many expect a formal definition of independence on such a notion. related to the notion to be based A. Danviche/Artijicial Intelligence 97 (1997) 45-82 49 Although we shall present a few formulations that we start with a formulation to be the one most resembling intuitions also happens of LCI in this paper, it is for these in terms of belief change. This formulation independence. probabilistic Before we present this first formulation, we need to define the notion of information. Definition 1. Information tence constructed sitions X. about a set of atomic propositions X is a propositional from these propositions. We use 8 to denote information sen- about propo- For example, if X contained the atoms p and q, then p V q, up and p > q are three pieces of information about X. Definition 2. Full of literals, one for each atomic proposition about propositions X. information about a set of atomic prop_ositions X is a conjunction full information in X. We use X to denote For example, there are four pieces of full information p A Tq, up A q and up A lq. We will also use the term conjunctive mean full information about atoms p and q: p A q, clause over X to Intuitively, Z with respect more information to database A if obtaining of LCI says that atoms X are independent about Y is irrelevant information about X given that we have already obtained full information of Y given to entailing about Z: about X. the first formulation Definition 3. Let X, Y, and Z be disjoint sets of atomic propositions. Database A finds X independent of Y given Z, written In&,(X, Z, Y), iff A U (2) k x precisely when A U (2, a} b _f for all X, 8, z^ such that A U {zh, a} of Y. is independent is consistent. If Z is empty, we simply say that X The database A U (2) database A U (2, a} results X is independent about X, that is, the information results from adding the full information from adding the extra information z^ to A, and the 8. Definition 3 says that the same information of Y given Z if both of these databases entail about Y is irrelevant. Examples To further illustrate Definition 3, consider the following database, A = {it-rained V sprinkler_was_on z wet-ground}. Let X = {sprinkler-was-on}, Y = {it-rained} and Z = 8. Then k&(X, Z, Y) because A #sprinkler-was-on A U {it-rained} #sprinkler-was-on A U {At-rained} #sprinkler_was_on, 50 A. Danviche/Art$cial Infelligence 97 (1997) 45-82 and, moreover, A w Tsprinkler-was-on A U {it-rained} #sprinkler_was_on A U {lit-rained} w~sprinkler-was-on. That is, adding information about it-rained in any information sprinkler-was-on However, if we let 2 = {wet-ground}, independent of it-rained. to the database does not change the belief about sprinkler-was-on. We say in this case that database A finds then we no longer have In&(X, Z, Y) because A U {wet-ground} #sprinkler-was-on AU {wet-ground, At-rained} k sprinkler_was_on. information the presence of complete in the database, That is, in adding about it-rained does change the belief sprinkler-was-on. We say in this case that the database A finds sprinkler-was-on depen- dent on it-rained given wet-ground. about wet-ground information information in some about Consider now the database, A = {it-rained > wet-ground, wet-ground > wet-shoes}. Let X = {wet-shoes}, Y = {it-rained} and Z = 8. Then we do not have Z&(X, Z, Y) because A #wet-shoes A U {it-rained} k wet-shoes. That is, adding information about it-rained in information dependent on it-rained. about wet-shoes. We say However, if we let Z = {wet-ground}, information presence of complete about it-rained does not change this for the reader independent of it-rained given wet-ground. to the database changes this case in some that database A finds wet-shoes the belief then we have In&,(X, Z, Y) because, in the about wet-ground in the database, adding information leave to verify. We say in this case that the database A finds wet-shoes the belief in any information about wet-shoes-we Properties of LCI Definition 3 of LCI satisfies the following properties. Theorem 4. Let X, I: Z and L be disjoint sets of atomic propositions propositional database. Then and let A be a (1) h&(XZQ)L (2) Zndb (X, Z, Y) precisely when In& ( I: Z, X) , (3) ha$(X,Z,Y) andZndb,(L,ZUX,Y) precisely whenZndb,(XUL,Z,Y). A. Danviche/Artijicial Intelligence 97 (I 997) 45-82 51 Properties (2) and (3) are known as the semi-graphoid was added is known ties: recently as symmetry. to them under Property the name (3) is trivial typically axioms independence into broken [ 191. Property ( 1) [26]. Property (2) three other proper- In&~( X U L, Z, Y) only if In&,(X, Z, Y) , l Decomposition: l Weak union: Znd”,( X U L, Z, Y) only if In&,( L, Z U X, Y) and l Contraction: Zndb,( X, Z, Y) and Zndb, (L, Z U X, Y) only if Zr& (X U L, Z, Y) . The semi-graphoid axioms are important intuitive properties an important of a structured database, which that independence result about the identification is the subject of Section 6. is expected for at least two reasons. First, [ 191. Second, of LCI assertions by examining they are they lead to the topology to satisfy Structured databases We now Section 6. introduce structured databases, which will be discussed in more detail in Figs. 1, 2 and 4 depict a number of structured databases. In general, a structured database has two parts: ( 1) a directed acyclic graph over atomic propositions, (2) a number of local databases, one for each atom n in the graph. and for atom n can only refer to n, its parents, and atoms in the directed graph. The local database in Figs. 1, 2 and 4. If a database is structured, The local database appear as shown satisfies can be detected by visual that we shall describe following LCI assertions inspection of the database in Section 6. For example, using the databases in Fig. 1: 2 that do not is typically depicted next to the atom it structure, using a method this method, one can detect the some of the LCI assertions regarding in Fig. 1.1. {B}) {B}, {C}) {A}, {C}) in Fig. 1.2. in Fig. 1.3. the formal definition of in Section 6. l Ir&({A},0, l In&’ ({A}, l In 2 d({B}, We provide key properties The next in testing use diagnoses. structured databases together with some of their two sections provide logical entailment four and other formulations and satisfiability, of LCI, corresponding in computing abductions to its and 4. Entailment and satisfiability formulations This section discusses the computational and satisfiability. For this purpose, we present towards one of these dual tasks. role of LCI in deciding two formulations logical entailment of LCI, each oriented ‘These are meant understand how these assertions assertions to review what will be covered in Section 6. The reader is not expected to are detected at this stage. 52 A. Danviche/ArtiJicial Intelligence 97 (1997) 45-82 B=>C A=rain B = sprinkler was on C= wet grass A = rain B = wet ground C = slippery ground A = battery ok B = lights on C = car starts Fig. 1. Three structured database. databases. Each graph identifies LCI assertions that are satisfied by its associated We start with the formulation of LCI that is oriented towards testing that is, deciding whether some propositional sentence Q is logically ment, a database A. We first present logical entailment when the database is structured. the formulation and then show how it can be applied logical entail- entailed by to difficulty in testing The computational for logical entailment (at least in the propo- to do decompositional testing. That is, although sitional case) stems from the inability the test A k LY A /I into testing whether A k cy and A b p, one one can decompose testing whether A b cx or the test A k (Y V p cannot decompose (in general) A k p. To see this, note that if A = {p V q}, then A k p V q holds while neither A k p nor A + q holds. Therefore, the decomposition into A b p V q precisely when A b p or A k q is not valid in this case. If such a decomposition were valid, however, easy. We would always be able to rewrite test 7cy k 7~1 V . . . V lcq, Tct! i= ~a~, which testing in turn are equivalent for logical entailment linear and then decompose the latter into n tests T(Y /= 1~~1, . . ., to (~1 /= LY, . . ., a, + a. This would make in the number n of sentences in a database. testing for entailment would be very the test {cyl , . . . , a,} k a into the equivalent Although the decomposition test A k (Y V ,8 is not valid in general, it can be valid when certain LCI assertions are satisfied by the database A. The second formulation of LCI is meant these assertions. of a disjunctive to explicate Entailment formulation We first need the following supporting definition. Definition of literals, one literal for each proposition over propositions X. 5. A disjunctive clause over a set of atomic propositions X is a disjunction clause in X. We use _? to denote a disjunctive A. Danviche/Art$cial Intelligence 97 (1997) 45-82 53 For example, there are four disjunctive clauses over p and q: p V q, p V 79, up V q and up V 79. The following formulation rem 7 proves change. the equivalence between of LCI is in terms of decomposing this formulation tests. Theo- and the first one based on belief disjunctive Definition 6. Let A be a propositional sets of atomic propositions. Database A finds X independent Inde,(X,Z,Y), database and let X, Y and Z be three disjoint of Y given Z, written iff A k T? V f V .f precisely when A f= _f V 2 or A k P V 2 for all disjunctive clauses X, P, Z. Theorem 7. Indb,(X, Z, Y) precisely when I& (X, Z, Y). Theorem 7 is then showing ( 1) the validity of decomposing the equivalence between certain disjunctive 6) and formulation of LCI (Definition (2) oriented the irrelevance oriented An important of certain information to certain beliefs, which is an intuition- formulation special case of Definition of LCI (Definition 3). 6 is when Z = 0. Here, false is the only tests, which is a computation- disjunctive clause over Z, and we have In&(X, 8, Y) iff A /= .% V p precisely when A k T? or A k f for all disjunctive clauses X and P. Example Consider the database A = {p > r,r > s}. This database satisfies the LCI assertion Indb,({s}, {r}, {PI). Th ere ore, f the following decompositions are valid: A k p V r V s precisely when A k p V r or A b r V s A b lp V r V s precisely when A b up V r or A /= r V s A f== p V lr V s precisely when A b p V -r or A b yr V s A k up V -v- V 7s precisely when A /= up V Tr or A k -v V 7s. Note, however, should not be surprising that the decomposition that A does not satisfy the assertion In&,( {s}, 8, {p}) . Therefore, it A k up V s precisely when A k up or A /= s does not hold (A /= yp V s holds but neither A /= up nor A b s does). 54 A. Danviche/Art#cial Intelligence 97 (1997) 45-82 Fig. 2. A structured database representing a digital circuit. The computational value of independence We have shown so far that: ( 1) disjunctive (2) if disjunctive would become tests of the form A k (Y V p cannot be decomposed in general; tests were always decomposable, then testing for logical entailment linear in the number of sentences in a database; (3) disjunctive tests could be decomposed when certain LCI assertions are satisfied by the database. When all disjunctive easy as we have shown. But when only certain independence tests are decomposable, is available-then the issue is no longer tests are decomposable-that that simple. taking advantage of this decomposability is is, limited The algorithm we present in Section 7 is a good example of how limited information a number of local decomposition can be utilized computationally. It decomposes tests Ai k cq, which are assumed two rewrite rules: using is accomplished a global to require constant independence test A + LY into time. The (1) case-analysis: A k (Y is rewritten (2) decomposition: A k (Y V p V y is rewritten into A k cr V /3 and A b a V -/? and into A k LY V y or A k p V y. The case-analysis rule is always valid because ( 1) (Y is equivalent (2) A~((~Vp)A(cuV~fl) However, ing to Definition the decomposition 6. to (a V /?) A (cz V -/3) and iffAbcuVpandA+cuVTp. rule is valid only when certain LCI assertions hold accord- Fig. 3 shows an example of this rewrite process as applied to the database that decomposes with respect process AI +XVyA, A2 /= 1D V 1A V 7B. Here Al and A2 are the local databases: in Fig. 2. Specifically, A2 ~=DVAVTB, A2 ~TDVAVB, the global to the test A + -6 V -D the figure depicts a trace of a rewrite test A b 4 V 1D into six local tests: Al /= YC V A, 42 k~Dv~AvB,and Al={A>X,~A>C} and A2={AAB > D,-J(AAB) > TD}. A. Dawiche/Artificial Intelligence 97 (1997) 45-82 55 I A entails -C v -D AND $entails -D v A v B 4 entails -D v A v -B Aptails -D Y -A v B ATent& -D Y -A v -B Fig. 3. A rewrite process shown is the evaluation of local tests. for decomposing a global test for entailment into a number of local tests. Also The process proceeds top-down, rewriting each test into a logical combination it. The case-analysis rule rewrites a test into a disjunction rule rewrites a test into a conjunction tests below The decomposition rewrite process constructs leaves of which are local tests. Note here that the two applications of the decomposition rule are validated by the LCI assertion structure lnd, ( {C}, {A}, {D}) , which follows of other tests. Therefore, tree, the root of which is the global an and-or from the of the of other tests. the test, and the the result of evaluating local tests. It is clear that this tree evaluates in Fig. 2. Fig. 3 also depicts test A k -C V TD. to this example. First, to true, which is the answer computed for the global paradigm to make with respect We have a few points that we are advocating into a number of local, constant the computational computation computational decomposition rule will be valid only when certain LCI assertions hold. Therefore, independence-based tasks we shall consider, rules. The case-analysis in this paper: decompose it exemplifies a global time computations. Second, for each of the and there will be a corresponding rule will always be valid, but the decomposition to develop an case-analysis algorithm, one must the decomposition the rewrite process so that: (completeness) rule is valid (soundness) it terminates it invokes ( 1) know when (2) control (a) (b) Structured databases goals: used to control The number the least number of rewrites possible (eficiency) that we shall introduce in Section 6 are central for achieving these are valid and can be the topology of a database tells us which decompositions the rewrite process so that it terminates. of invoked rewrites decides is the parameter the superiority of one algorithm versus another. As we shall see, for certain database structures, we can decompose a task using only a linear number of rewrites. These computational issues will be discussed in more detail later. the complexity for measuring of reasoning and 56 A. Danviche/Artificial Intelligence 97 (1997) 45-82 Satisfiability formulation We now provide the third formulation of LCI, which is oriented towards testing satisfiability: Definition 8. Let A be a propositional sets of atomic propositions. Database A finds X independent Zn$iXLZ, {Z, Y, X} is satisfiable database and let X, Y and Z be three disjoint of Y given Z, written iff A U (2, x^} and A U { z^, p} are both satisfiable precisely when A U clauses z^, ^r and x^. for all conjunctive Y), This formulation is dual to the second formulation for testing entailment. The equiv- alence is established below: Theorem 9. In&, (X, Z, Y) precisely when In&, (X, Z, Y). Now that we have established the superscripts sometimes Zndd will then be chosen depending on the context. drop the equivalence and simply write ZndA. The specific Inded and In&,, we will of interpretation between Im$, 5. Diagnosis and abduction formulations This section presents two more formulations and abduction. We define of LCI oriented the dual tasks the notion of a consequence tasks, of all diagnoses. We also define the notion of an is a semantical for diagnosis towards characterization and abduction and arguments of all abductions. are rooted in the in general. We in certain cases. in computing diagnoses of consequences the computations two more formulations assertions can validate this decomposition of LCI to spell out these cases. The two formulations characterization tasks, which for abduction that the difficulties of diagnosis which is a semantical argument We show inability also show that independence We present are dual since consequences to decompose are dual to arguments. We start with the fourth formulation towards diagnostic it though, we need to review some basics of diagnosis of LCI that is oriented appli- [ 71. cations. Before we present Basics of diagnosis In the diagnostic literature characterized is typically where A is a database constructed observation atoms in W are called assumables tion is that the database A describes the modes of system components behavior. For example, are A, B, C and D and a possible [ 71, a system is typically characterized by a tuple (A, P, W) from atomic propositions P U W. Moreover, a system from atoms P. The The inten- the assumables W represent system the observed and those in P are called non-assumables. and the sentence y represents by a sentence y constructed the system behavior, in Fig. 4, the assumables are okX and okY, the non-assumables system observation y is C A D. A. Darwiche/Artijicial InteNigence 97 (1997) 45-82 A&OKX=>-C A&B&OKY=>D -A&OKX =>C -(A & B) & OKY=> -D C D Fig. 4. A structured database representing a digital circuit. A diagnosis is defined as a conjunctive consistent with AU(y). Therefore, a diagnosis that is consistent with the system description and okX A TokY and okY are the assumables One goal of diagnostic reasoning to a user. Another goal is to characterize can be presented according can be achieved y, which extract to some preference criterion. We have shown elsewhere in two steps 141. First, we compute is a Boolean expression the most preferred diagnoses that characterizes from the computed consequence. clause over the set of assumables W that is is an assignment of modes to components and its observed behavior. is a potential diagnosis. In Fig. 4, okX compactly all diagnoses so they is to extract a subset of these diagnoses that these objectives the consequence of observation all the diagnoses of y. Second, we The consequence of an observation is defined formally below: Definition 10. Let A be a propositional be a set of atomic propositions cy with respect sentence @ such that A U {cr} /= m. 3 database, that do not appear to database A and atoms W, written Con&( a), (Y be a propositional sentence and W in LY. The consequence of sentence strongest is a logically When A and W are clear (u) for simplicity. Cons$( TokX V TokY because that can be concluded from the context, we will write Cons(n) In Fig. 4, for example, the consequence of observation Cr\D it is a logically from the given observation strongest sentence (constructed and system description. from assumables) instead of is A consequence characterizes all diagnoses in the following way: Theorem 11. G Con&y). is a diagnosis for system (A, P, W) and observation y iff @ b The consequence TokX V TokY for example characterizes three diagnoses: TokX A --okY, okX A TokY and TokX A okY. 3 A sentence LY is stronger than sentence p iff (Y \ /I. The sentence p is said to be weaker than (Y in such a case. 58 A. Darwiche/Art@cial Intelligence 97 (I 997) 45-82 Diagnosis formulation Similar to testing for logical entailment, the difficulty with computing diagnoses is that it cannot be done compositionally. to Cons( cr) V Cons( p) , Cons( a Ap) The following formulation of LCI followed by a theorem one based on belief change, consequences is valid. that shows the equivalence identifying therefore, is not equivalent In particular, although Cons( LY V p) is equivalent in general. It is the is in terms of decomposing to Cons(a) A Cons( p) this formulation consequences. between and conditions under which decomposing Definition 12. Let A be a database atomic propositions. I$,,,)(X,Z,Y), The pair iff (A, W) let X, Y, 2 and W be disjoint and finds X independent sets of of Y given Z, written + cons( x^ A i;: A z^) = cons( x^ A z^) A Cons( E A 2) for all conjunctive clauses .?, p and z^. Theorem 13. Zr~q~,~)( X, Z, Y) precisely when h&(X, Z U W Y). Given Theorem 13, we now have an equivalence between ( 1) the irrelevance of information (2) (3) (4) Before we present an example on the computational the validity of decomposing the validity of decomposing the validity of decomposing entailment satisfiability consequences 3), (Definition tests (Definition tests (Definition (Definition to beliefs 6), 8), and 12). use of this LCI formulation, we true is the only 12. When Z is empty, w) (X, 8, Y) iff note conjunctive the following special case of Definition clause over Z, and we have I$, /= Cons(X^ A i;) = Cons(X^) A Cons@) for all conjunctive clauses x^ and F. Example We have presented to a structured database of the form Co&( local consequences is based on the following elsewhere an algorithm for computing [4]. The algorithm works by rewriting consequences with respect a global consequence into a Boolean expression a) of the form CO& and ((ui) , where Ai is a local database. The algorithm logical connectives that involves two rewrites: ( 1) case-analysis: Cons(a) (2) decomposition: Cons( a A p A y) is rewritten into Cons( LY A /3> V Cons( a A -/3) ; 4 and into Cons( cy A y) A Cons( p A y) when the corresponding is rewritten LCI assertion holds. 4 The case-analysis rule follows because (a) a is equivalent to ((Y A p) V (a A -/3) and (b) Cons( (a A /3) V (a A -p) ) is equivalent to Cons(cu A /I) V Cons(u A -@). A. Danviclze/Art@ial Intelligence 97 (1997) 45-82 59 cons(C & D) cons(A & C & D) cons(-A & C & D) +.kr & cons(A & B & D) true A2 COMA & -B 8~ D) cons(-A & B & D) -0KY -0KY -0KY Fig. 5. A rewrite process for decomposing a global consequence into a number of local consequences. Also shown are the values of local consequences. We will now consider an example using these rewrites with respect the consequence Cons( C A D), where the set W contains to Fig. 4. Our the atoms goal is to compute okX and okY. Fig. 5 depicts a trace of the rewrite process that decomposes Cons( C AD) AAB), Cons**(D/\AATB), Al and A2 are the local databases: into six local consequences: Cons” (AAC), ConsA ( -AI\C), ConsA2(DA~AAB) and Cons’*(D/\lAAlB). the global consequence ConsA (DA Here, Al={AAokXx-C,lAAokX>C} and A2={AABAokY>D,+AAB)AokY>TD}. rewriting each consequence rule rewrites a consequence into the nodes below it. The into a disjunction of other consequences, while the rewrite process constructs top-down, rule rewrites a consequence The process proceeds case-analysis the decomposition Therefore, and consequence, local consequences, tree simplifies global consequence Cons( C A D). Note that local consequences operating on that the two applications tree, the root of which is the global the values of is the value of the can be computed by time. Note also rule are validated by the LCI assertion leaves of which are local consequences. Given to TokX V TokY, which local databases, which of other consequences. of the decomposition to require constant into a conjunction is assumed an and-or the the In&,,,({C}, {A}, {D}), w ic can be inferred by examining h’ h the database structure. Abduction formulation The fifth formulation There is no standard definition of an abduction, of LCI is oriented towards agree on the following two properties: the computation although existing definitions of abductions. seem to 60 A. Darwiche/Ar@icial Inrelligence 97 (1997) 45-82 should be as general as possible while still explaining (1) (2) The Generality: An abduction the finding. Scope: The language to avoid trivial abductions ( LY being an abduction of itself). following definition gives a generic notion of an abduction, in which an abduction is phrased must be restricted in order called an argument. is only a syntactic variation on the The ATMS argument label of a proposition, for example, for that proposition [ 6,211. Definition 14. Let d be a propositional W be a set of atomic propositions (Y with respect sentence w such that A U {R} b a. 5 to database A and atoms W, written A&,( a), database, cy be a propositional that do not appear in (Y. The argument sentence, and for sentence is the logically weakest The intention here is that A represents background and W restricts W to contain okX and okY in Fig. 4, the argument okX A okY. information, Q represents a finding, if we choose -C V -4 would then be for finding the language used in phrasing an abduction. For example, Arguments are dual to consequences as the following theorem shows: Theorem 15. AI&, z ~Consi(x). This also explains, indirectly, why ATMS engines are typically used for computing the difficulty to logical entailment, is re- to decompose arguments. That is, although Arg( cw Ap) is equivalent in general. For then Arg (r V s) = p while Arg (r) = false Arg(aVj?) if A = {p > (r V s) } and W = {p}, to Arg(a) VArg(j3) abductions/arguments is not equivalent in computing diagnoses. Similar lated to the inability to Arg(cY) AArg(P), example, and Arg( s) = false. The following formulation of LCI is in terms of decomposing arguments. by a theorem thus establishing that shows conditions the equivalence under which between it is valid to decompose this formulation arguments. It is followed and previous ones, Definition 16. Let A be a database atomic propositions. The pair (A, W) and finds X independent sets of of Y given Z, written let X, Y, Z and W be disjoint Inq,,,) (X, Z, Y), iff kArg(zV?V?) zArg(jiVZ) VArg(yVZ), for all disjunctive clauses 8, P, .??. Theorem 17. Zn~4,j( X, Z, Y) precisely when Znq’,,,) (X, Z, Y). 5 We will typically drop A and W, thus writing Arg(n), when no confusion is expected. A. Darwiche/Artificial Intelligence 97 (1997) 45-82 61 we will Now that we have established sometimes drop the superscripts of Ind will then be chosen depending on the context. the equivalence between Znq4,,) and simply write Znd(d,w). The specific and Inq,,,), interpretation We close empty, false this section with an important is the only disjunctive special case of Definition 16. When Z is clause over Z, and we have Znq.4,j (X, 8, Y) iff Arg(gVf) -Arg($) VArg(?), for all disjunctive clauses 2 and r’. 6. Structured databases The different the decomposition in parallel, compose a computation decompositions formulations of LCI show how independence of a computation into smaller computations a decomposition that is not sound in general. Although information can validate that can be performed to de- this ability such could be valuable from a complexity viewpoint, exploiting is not always straightforward. Structured databases make this utilization of independence more feasible. In particular, the structure of a database plays algorithms: two important roles in designing independence-based ( 1) it graphically (2) explicates valid applications flow that guarantees of the decomposition the termination rule, and of the decomposition it specifies a control process. This reasoning, is also the role that directed and our goal here is to extend acyclic graphs have been playing the role to propositional logic. 6 in probabilistic We will now provide the formal definition of structured databases, and then present two important operations on their structures: independences irrelevant parts of a database ( 1) reading (2) pruning off the database structure and structure before performing certain com- putations. 6.1. The syntax of a structured database A structured database l G is a directed acyclic graph with nodes representing l A is the union of local databases, one database is a pair (6, A) where atomic propositions, and for each node in Q. that appear The atoms exogenous atoms. For example, local database following corresponding conditions: in the database A but do not appear in the structure $7 are called atoms are okX and okY. The the n in 0, denoted by A,, must satisfy in Fig. 4, the exogenous to proposition ( 1) locality: the only atoms in 6 that A,, can mention are the family of atom n; 7 and ’ However, we later discuss a key difference between 7 Recall that the family of n consists of n and its parents the propositional and probabilistic framework. in the database structure. 62 A. Danviche/Artijicial Intelligence 97 (1997) 45-82 (2) modularity: if A,, entails a disjunctive clause that does not mention atom n, then the clause must be valid. The first condition makes sure relationship database the truth value of IZ. That direct between ensures mention the consistency atom IZ. relationship the that a local for atom IZ be only concerned with specifying how the parents of IZ determine between an atom and its parents. The second condition that each local database to specifying is restricted ensures is, the database should not be concerned with specifying a the parents of IZ. Note also that the modularity (falsehood) of a local database since the empty clause condition does not If the arcs of a structured database represent causal influences, then the conditions the functionality self-imposed. For example, suppose that a structured database above are typically to describe in the structure inputs of a gate into its output. The local database associated with atom n specifies behavior of the gate having output n. For this class of structured databases, and modularity is used in Figs. 2 and 4. Each atom the state of a wire in the circuit, and the arcs point from the the the locality of a digital circuit as shown are typically self-imposed conditions represents since ( 1) the locality condition means that one should not mention any wire that is not an (2) input or an output of the gate for which we are specifying the modularity the inputs of a gate in the process of specifying condition means that one should not specify a relationship between a behavior, and interpretation its behavior. of structured databases, We have focused elsewhere on a causal to as symbolic of LCI nonmonotonic reasoning [ 51. that include theories causal networks, where we discussed non-computational anomalous about actions and identifying referred applications extensions of 6.2. Structure-based independence By construction, a structured database satisfies some LCI assertions that can be easily detected from the database structure: Theorem 18. Let (G, A) be a structured database, W be its exogenous atoms, n be a Then Indd( {n}, U U W, N). node in 6, U be its parents, and N be its non-descendants. That is, each atom in the database its parents given theorem states that and exogenous structure atoms. With is independent of its non-descendants respect to the database in Fig. 4, this (1) {D} is independent (2) {B} is independent (3) {C} is independent of {C} given {A, B,okX,okY}, of {A} given {okX, okY}, and of {D} given {A,okX,okY}. Theorem 18 brings up a key difference between structured databases and Bayesian net- works: by this theorem are properties of a structured the independences database, but their corresponding a Bayesian network. That is, the restrictions on a structured database are sufficient ply these independences, the corresponding imply but similar restrictions on a Bayesian network are not enough probabilistic are part of the dejinition of to im- to of this: There are two implications independences. independences characterized probabilistic A. Dunviche/Artificial Intelligence 97 (I 997) 4.5-82 63 l By constructing independences; By constructing independences which correspond a Bayesian a structured database, one one is committing only network, however, one to Theorem 18 [ 191. is making no explicit commitment to the logical content of local databases. is explicitly committing to to l One can recover local databases, the independences that is, without having Note that having an explicit structure since LCI is a symmetric Specifically, is independent (4) {D} of {C} given {A,okX,okY}, satisfied by a structured database from only its to consider is very useful relation, in deducing the LCI assertion the database structure. * further independences. in (3) above implies which cannot be detected by applying Theorem 18 directly. As this example a structured database those characterized rem 18. We now present a topological these additional d-separation assertions. is a test on directed satisfies more LCI assertions test, called d-separation, that tells us whether acyclic graphs for identifying than illustrates, by Theo- some of two sets of the by a third set [ 191. According from the node {C} by the node {A} nodes are d-separated nodes {B, D} are d-separated d-separation when Z d-separates X from Y in the directed acyclic graph 6. The d-separation been instrumental it analogously in Fig. 4. Therefore, could be viewed as a relation SepB where Sepg (X, Z, Y) holds precisely test has in Bayesian networks. We shall use in structured databases. about independence test, for example, in reasoning to this We will define d-separation LCI assertions. The following reveals the importance of d-separation: later, but we first go over how it can be used to identify in [ 251, result, which is basically a corollary of a theorem Theorem 19. Let (G, A) be a structured database and let W be its exogenous atoms. If Z d-separates X from Y in 6, then A jinds X and Y independent given Z U W. That is, SepG (X, Z, Y) impEies Zndd (X, Z U W; Y). Therefore, d-separation allows one to infer LCI assertions satisfied by a given struc- tured database by simply examining the topology of its structure. Following are the key computational implications of Theorem 19. If atoms X and Y are d-separated by Z in the structure of database are valid with respect to database A: (0, A), then the following decompositions (1) A~~_V~_V~V[iffA~T?V~V&‘orA_~~V~V~, (2) A U {X A Z A W A Y} is satisfiable iff A U {X A Z A W} and A U {z^ A @ A 8) are satisfiable, (3) Arg(XVZVY) (4) Cons( x^ A z^ A i;;) is equivalent isequivalenttoArg(XVZ)VArg(ZVY),and to Cons( x^ A z^) V Cons( z^ A i;), for all disjunctive show why the complexity by the topology of a structured database. of reasoning clauses 2, Y, Z and all conjunctive in the framework we are proposing clauses x^, p, z^. These implications is decided The d-separation test will be defined next. We first need the following supporting definition: * We do not investigate this direction in this paper however. 64 A. Darwiche/Artificiul Intelligence 97 (1997) 45-82 J/ i k 8 Diverging Linear Converging J Fig. 6. There are three types of intermediate to its neighbors. A node is diverging relation is a parent and the other is a child. A node is converging nodes on a given path. The type of a node is determined by its if both neighbors are children. A node is linear if one neighbor if both neighbors are parents. Definition 20. Let G be a directed acyclic graph and let X, Y, and 2 be three disjoint sets of nodes in 6. A path between X and Y is Z-active precisely when its nodes satisfy the following conditions: ( 1) each converging node belongs (2) each diverging or linear node is outside Z. to Z or has a descendent in Z, and When Z is empty, we say the path is active. Fig. 6 gives the definition of converging, diverging, and linear nodes. In Fig. 4, for example, l the path A + D + B is {D}-active, l the path C + A + D is active, and l the path A --t D + B is not active. Following is the definition of d-separation: [ 191) . In a directed acyclic graph E, nodes Z d-separate X from Definition 21 (Pearl Y, written SepG (X, Z, Y), precisely when there is no Z-active path between X and Y in G. When Z is empty, we say that X and Y are d-separated. all LCI identify the structured databases The d-separation test is not complete in the sense that it cannot satisfied by a database. To illustrate this, consider the first one, {A} and {C} are independent assertions in Fig. 7. In separated. And separated. lead us to prove anything will help in proving anything about C. the second, Intuitively, in in the first database, there about C. Similarly {B} and {C} are also although they are not d- although not d- about A that could in the second database, neither B nor 7B is no information independent Existing structure-based assertions. are bound seems to be the practice work on utilizing non-structural It should be clear then that such algorithms to miss some independences algorithms use only the database structure for identifying LCI they This also for some recent that could be useful computationally. literature, except possibly cannot be optimal because in the probabilistic independence [ 1,181. A. Danviche/Artijicial Intelligence 97 (1997) 45-82 65 Fig. 7. Structured databases satisfying more independences than is revealed by their graphical structures. 6.3. Structure-based pruning attractive complexity The modularity and knowledge from computational that we are constructing this, suppose leaf nodes condition condition on local databases has strong implications that make struc- acquisition a structured database their local databases. When adding that the added database A, does not con- so far. For the database A, to contradict that is inconsistent with A. But this is impossible. Ev- clause the atom n. And any clause n cannot be inconsistent with A, since A does not mention n to start tured databases viewpoints. To illustrate incrementally by adding node n, the modularity tradict A, it must entail some clause ery non-valid that mentions with. the structured database A constructed that is entailed by A,, must mention together with ensures Therefore, structured databases are guaranteed to be consistent by construction, which is a very attractive property from a knowledge acquisition viewpoint.9 Another important to prune certain implication of the modularity condition on local databases is the (irrelevant) parts of a structured database before computing to certain queries. The following theorem identifies cases where this pruning is ability answers possible. Theorem 22. Let (G, A) be a structured database with exogenous variables W let N be some atoms to N. If (G’, A’) that results from is a structured database removing node n and its local database A,, from (with exogenous variables W’) (0, A), in structure G and n be a leaf node in G that does not belong then ( 1) Entailment: A b k _iJ A’ k fi, (2) Satisfiability: A U {N} is satisfiable iff A’ U {E} is satisfiable, (3) Abduction: Arg$( fi) is equivalent to Arg$ (4) Diagnosis: Con&(G) is equivalent to Con& for all disjunctive clauses I? and conjunctive clauses ( fi) and ( ti) fi. ‘Modularity works 1 IO]. is also a key property responsible for the desirable properties of directed constraint net- 66 A. Danviche/Art$cial Intelligence 97 (1997) 45-82 of a clause the result of the test. Applying For example, when attempting to test for the logical entailment fi that does not involve a leaf atom n, we can drop atom n and its local database d, without affecting this theorem recursively may prune a significant in certain cases. The amount of pruning, however, depends part of a structured database in the structure. For example, at on how the atoms of clause fi are spread topologically In this case, one extreme, clause no pruning in the structure, in the clause will be pruned. fi may refer to all leaf nodes in the database structure. in which case all nodes except for those mentioned is possible. At another extreme, the clause may only mention root nodes complexity viewpoint, the significance of Theorem 22 is in of a reasoning task is affected by the specific query. From a computational showing how the complexity 22 presents information some algorithm Theorem irrelevance applying database knowing mention, however, in practice, that we are proposing. This probabilistic is in decomposing independent in the following structured databases. a result which in spirit in the literature on logical reasoning is close for testing entailment, we prune to the traditional usage of [ 15,23,24]. That is, before some parts of the given the soundness of the test. We have to savings in the framework in can lead to great computational information that we will not compromise that although such pruning it is only a secondary usage of independence and constraint-based is also consistent with the way independence reasoning. The key usage of independence is used information a computation with respect to a global database into a number of computations with respect to local databases. This usage will be illustrated section, which presents an independence-based algorithm for a class of We close this section with the following corollary which says that we can prune a leaf that hold between the independences node from a structured database, without affecting nodes. any of the remaining Corollary 23. Let (G, A) be a structured database with exogenous variables W. Let X, Y and Z be atoms (with (G, A) that does exogenous variables W’) not belong in structure G and let (G’, A’) be a structured database that results from removing a leaf node from to X U Y U Z. Then Zndd (X, Z U W Y) precisely when Znddt (X, Z U W’, Y) . 7. Structure-based reasoning This section presents an algorithm for computing that are singly-connected, arguments. The algorithm which are introduced applies in the fol- to arbitrary structured complexity of the algorithm and its extensions depend on it applies. This is why this class of straightforwardly to structured databases only lowing section. The algorithm can be generalized databases. The computational the topology of the structured database algorithms Using computing to as structure-based. this algorithm, one can also decide entailment is referred to which consequences. We provide more details on this later. and satisfiability in addition to A. Danviche/Art@cial Intelligence 97 (1997) 45-82 JI D C A&OKX=>-C -A&OKX =>C A&B&OKY=>D -(A & B) & OKY=> -D :8- E C&D&OKZ=>E -(C & D) & OKZ=> -E A B C Y I? IE D Z 7 Fig. 8. A structured database representing a digital circuit. The structure of this database is multiply-connected because there is more than one undirected path between nodes A and E. Singly-connected structures A singly-connected structure tween any two nodes-the has a singly-connected ture. is one in which structure has no undirected there is only one undirected path be- in Fig. 4 struc- cycles. The database structure, but the one in Fig. 8 has a multiply-connected Singly-connected ( 1) Computation databases are important on a singly-connected for at least two reasons: structure is linear in the number of nodes and arcs of that structure, exponential only in the size of a family. lo (2) There is a simple algorithm for reducing a computation on a multiply-connected structure n is exponential into a number n of computations in the size of a structure cutset on singly-connected [ 2,191. I1 A singly-connected Figs. 2 and 4 are singly-connected database is not necessarily Horn. For example, clauses. and yet contain non-Horn structures, where the databases in The rewrite paradigm Given a singly-connected database atoms in 6, the algorithm we shall present computes database A. The algorithm ture, known as the polytree algorithm linear in the number of nodes and arcs in 6 and exponential to a well-known is symmetric [ 191, and has similar computational one in the probabilistic clause 6 over some to for 6 with respect litera- complexity: in the size of each family ($7, A), and a disjunctive the argument I” In the literature on structure-based to justify ” A cutset of a directed acyclic graph the arcs outgoing we remove the assumption reasoning, the size of a family is typically assumed to be small enough that any computation involving only a family will require constant is a set of nodes in the graph that satisfies time. the following property: if from every node in the cutset, the resulting graph becomes singly-connected. 68 A. Darwiche/Art@cial Intelligence 97 (1997) 45-82 in G. The algorithm (Y by first converting applying the algorithm can also be used to compute into conjunctive the sentence the argument of an arbitrary sentence form 61 A . . e A 6,, and then normal to each of the conjuncts: A&a) ~Arg(6~ A-46,) = l\Arg(d&. The algorithm works by rewriting a global argument ArgA( 6) into an expression logical connectives includes a local database. A local argument which applying the case-analysis is assumed to require constant ( 1) case-analysis: (2) decomposition: Arg (a V p V r) Arg (a) that and local arguments of the form ArgAi (q), where di is can be evaluated by operating on a local database, time operation. The algorithm alternates between and decomposition is rewritten rewrite rules: into Arg ( LY V p) A Arg( (Y V +), and is rewritten into Arg ( LY V y) V Alg (j3 V y) when the corresponding between The alternation pose an argument Arg (2 V P> , atoms X and Y must be independent. algorithm performs order to apply LCI assertion holds. the two rules takes place because of the following. To decom- If they are not, the in a case analysis on atoms Z (that make X and Y independent) the decomposition (1) the algorithm rewrites Arg (2 V f) rule. That is, into AAqg(%vl’vZ) 2 using rewrites the case-analysis the result into (2) rule, and then Arg(kVi) VArg(pV 2) A 2 using the decomposition Therefore, when an argument it is first expanded using case- cannot be decomposed, analysis and then decomposed. This process continues until we have a Boolean expres- sion in which all arguments are local. rule. The algorithm We now introduce some notation that is needed to state the algorithm as a set of rewrite rules. Let l x be an arbitrary node in the database structure, l u and u’ be distinct parents of x, l y and y’ be distinct children of x, and l U be all parents of x. The algorithm following rewrite rules: can be described as a recursive and deterministic l2 application of the I2 Except for the first rewrite rule, which applies only once. A. Datwiche/Art$icial Intelligence 97 (I 997) 45-82 69 for some node x in the structure 0 n(x) --+ (6) starts with the argument Arg(6). It then keeps on applying the rewrites that contains only the connectives A and V in to true, false and local arguments of the form Arg*” (X V 0). In its intermediate expression will also include the following intermediate terms z-, to construct an expression into other expressions using the above rewrites. that is free of these intermediate it is easy to verify is singly connected, that the the constructed The algorithm given above until it reaches an expression addition stages, A, r?,, A, and A, which will be rewritten The algorithm terms. Given rewrite process will terminate that the database structure is guaranteed and l Rewrite l Rewrites ( 1) will be applied only once, (2), structure, and (3) and (6) will be applied at most once per node in the database l Rewrites structure. (4) and (5) will be applied at most once for each arc in the database Therefore, expression of families of the database the complexity are linear structure. of the algorithm and in the number of nodes and arcs, and exponential the size of the constructed Boolean only in the size Deriving the rewrites We will now go over involved the derivation of this algorithm. This discussion would ically be part of Appendix A, but we include techniques cause independences algorithm. To develop such an algorithm, one needs to go into an exercise similar following. a structure-based one may arrive at database and therefore may be easy to solve using a specialized typ- to provide an example of the be- that imply strong structure-based in certain applications, algorithm. This in developing is important structures it here to the The algorithm starts by rewriting Arg( d) using the case-analysis rule into Arg(xVd) ~Arg(-aV6) A. Darwiche/ArtQicial Intelligence 97 (1997) 45-82 . -; 52 72 i o_ y==- XYm: I / ,/’ /J i ’ \ \ __.’ . ...* Ym ,*’ Yl ,’ .-: _I \ / \ I r; -2 -.-. _~ - \ Fig. 9. Decomposing a disjunctive clause in a singly-connected structure for some atom x in the structure loss of generality). To decompose (we will assume the argument Arg(K V 6)) that x does not appear in 6 without the algorithm partitions the disjunctive clause d into two parts: a clause a, mentioning only descendants of x and a clause 6,’ mentioning decomposition: only non-descendants of x; see Fig. 9. This validates the Arg(i! V 6) - - Arg(kV6lV6;) Arg(.?V#)VArg(ji-vd-) LX ml A(i) because x d-separates any of its descendants from any of its non-descendants. To decompose the argument Arg(i V a,), the algorithm partitions the clause a, into a number of clauses a,., Fig. 9. This validates the decomposition: each about the nodes connected to one child y of x; see Arg(X V ii,) - Arg (2 V v 6il,> ? -v Arg( f V a:,) !.- A,.(i) because x d-separates connected to other children. any nodes connected to one of its children from any nodes A. Darwiche/Art$cial Intelligence 97 (I 997) 45-82 71 To decompose the argument Arg(X V a,‘), the algorithm applies the case-analysis rule: Arg(X v ii,‘) - AArg(k v irv a:), ir where c! is a conjunctive clause over II, the parents of x. Using Theorem A.1 in Appendix A, we can decompose the argument into Note here that the first argument database for x. is local, that is, can he computed using only the local To decompose the argument Arg (DV 6,‘)) the algorithm partitions the clause 6,’ into a number of clauses Fig. 9. This allows ii,‘,, each about the nodes connected to x through its parent u; see the application of the decomposition rule: which is validated by d-separation: each parent u of x and the nodes in clause Gi,‘, are d-separated AY (i) from every other parent u’ of x and the nodes in clause Gs,. The rewrite for that x may appear and that for rrZ (ii) can be derived similarly. Moreover, given in 6, the term n must be inserted in the Rewrites (l)-(6) The algorithm presented in this section can be extended leading to an algorithm called cutset conditioning in the size of a structure cutset [ 2,19,20]. to multiply-connected [ 3,14,22]. Note that multiply-connected structures, however, but they are outside as shown. to multiply-connected data- that is expo- exten- the scope of this structures are not necessarily harder than There are more sophisticated ones in general. For example, n-bit adders lead to multiply-connected that behave computationally like singly-connected ones. bases straightforwardly, nential sions paper singly-connected structures Other reasoning tasks The algorithm we just presented computes for a given disjunctive the argument and consequence?, the algorithm clause can also be 6. Given used to compute the duality between arguments the consequence of a conjunctive clause 0 using Cons( 6) = lArg( -6). 72 A. Darwiche/Artificial Intelligence 97 (1997) 45-82 The algorithm can also be used to decide entailment since Al=a precisely when Arg$( a) E true. that appear if the structured database Therefore, atoms a clause 6 as entailed by the database A iff the computed argument to true. Given the duality between satisfiability (G, A) has no exogenous in A also appear is, all one can compute arguments and declare for 6 is equivalent in propositional logic, one can and entailment variables-that in &-then also use the algorithm for testing satisfiability. 8. Conclusion We have presented a notion of conditional independence with respect to propositional that resembles of logical databases formulations entailment, a database it satisfies and how structure. its probabilistic counterpart. We have also presented to deciding independence, abductions together with their applications and diagnoses. We have demonstrated computing around a directed acyclic graph can lead to explicating several logical how structuring the independences independence-based algorithms can then take advantage of this independence Our proposed approach for utilizing to the availability ties the computational information and in which complexity to therefore the complexity of paradigm of independence structure. This leads to a computational is parameterized is at the heart of causal-networks in the constraint is the key aspect deciding reasoning of logical database reasoning approach networks structure is what users need to control applications. The probabilistic this structure proposed framework. literature satisfaction in the probabilistic by the topology of a database structure. This structure-based literature and constraint- In both cases, a graphical the difficulty of a reasoning problem. This structure time for their in order to ensure an appropriate for tweaking for example, contains literature, times, most of which can be adopted by our response response techniques [ 8,9,12]. to ensure certain Appendix A. Proofs The proofs will not have the same order as the theorems. We will first establish the axioms using equivalence the abduction between all LCI formulations, then prove the semi-graphoid formulation in Definition 16. Proving equivalence between LCI definitions We first prove the equivalence nosis/abduction. We then prove formulations between belief-change lations. We will then have covered Theorems 7, 9, 13 and 17. between dualities: the equivalence followed by the equivalence entailment/satisfiability between belief-change and entailment and diag- and abduction formu- A. Darwiche/Art$cial Intelligence 97 (I 997) 4.5-82 73 Equivalence Suppose between entailment and consistency formulations that A k T? V ? V ?! precisely when A /= 2 V 2 or A k P V 2 clauses 8, Y, Z. Then A U (-2, for all disjunctive when either A U (-2 k, Y, Z. This means and A U { z^, ?} are satisfiable or AU (-2, ,-_f} that A U (2, ?, x^} -f, -z} . IS inconsistent precisely clauses -f} is satisfiable precisely when both A U (2, 2) is inconsistent for all disjunctive for all conjunctive clauses x^, p and z^. The other direction follows similarly. 0 Equivalence between diagnosis and abduction formulations We now prove the equivalence between the diagnosis and abduction formulations of LCI, therefore, proving the equivalence between Definitions 12 and 16 of independence. By Theorem 15, we have that Arg$(a) = Xons$( -a). Therefore, kArg(XVYVZ) =Arg(zVi) VArg(YVZ) is equivalent to which is equivalent to +COns(~XA~YA~Z) ~~(Cons(?BA~Z)ACons(~~A~i)), and /=cons(-RA~?Al.f) ~Cons(~BA~i)ACons(~~A~i). Therefore, kArg(XVYVZ) sArg(2Vi) VArg(YVZ) for all 8, Y and Z iff k Cons( x^ A ? A z^) E Cons( x^ A z^) A Cons( F A .?) for all x^, p and z^. 0 Equivalence between belief change and abduction We now prove that Znd”,( X, 2 U W Y) (Definition formulations 3) is equivalent to I$,,,) (X, Z, Y) (Definition 16). The following observations (lemmas) are useful in understanding the proof of this theorem: l Each sentence X is equivalent equivalentto(aVb)A(aV-b)A(laVb). .% is equivalent l Each sentence equivalentto(aAb)V(-aAb)V(TaATb). to the conjunction of some 2’s. Example: a A b is to the disjunction of some 2’s. Example: a > b is 74 A. Darwiche/Artijkial Intelligence 97 (I997) 45-82 l Suppose that there is no 2 and E such that ( 1) A U {Y} is consistent, (2) A #K (3) AU {p} + 8. Then there is no _% and P such that (1) A U {p} is consistent, (2) A #*, (3) Au(E) Because such that ? is consistent with A and A U {?} k 2. +k if ? is consistent with A and A U {E} k 2, then there must exist some ? l Suppose that there is no Y and X such that there is no Y and 8 such that /=%k. ( 1) A U {y} is consistent, (2) A #%, and (3) AU{p} Then ( 1) A U {E} is consistent, (2) A #_%, and (3) A u {?} k 8. Because and Au{?} l The following is always kg. true: if A k 2 and A U {P} k J?, then there must exist some 8 such that A # _% Arg(ivk) vArg(hp) /=Arg(hkvf). Because if AU{iir}~~V~oorAU{I%‘}~.??V~, then also AU{iir}+~V~V?. The proof of the theorem that Znq,,,) (+) Suppose is given below. ( X, 2, Y) does not hold. That is, we have Arg(ZvXVY) vArg(ZVjZ) vArg(hp) for some X, Y and Z. We want to show that Znd”,( X, 2 U W, Y) does not hold either. By supposition, (1) AU{@} (2) AU{@} (3) Au{%} This means that there must exist some @ such that k=zvJb/P, #ivX, #hit (1) Au{i?,d,~?} #ri, (2) AU{&z} (3) A U { @, -2, -p} +%, is consistent. Therefore, ZndD( X, 2 U U: Y) does not hold. We have then proved of implies I$,,,) (X, Z, Y) . that k&(X, Z U U: Y) (-+) Suppose and X such that (1) Au{@,.?} A. Danviche/Art@cial Intelligence 97 (1997) 45-82 15 that In&(X, Z U w Y) does not hold. Then there must exist @, Z, 8, #x, (2) AU{*@} (3) A U { @, Z, Y} is consistent. kg, By the above_lemmas, there must exist p and X such that ( 1) A U {y, z,>_# 2, (2) A U {y, z,, x} k 2, (3) A U {W, 2, Y} is consistent. That is, we have (1) AU{@} (2) AU{@} (3) Au{@} Therefore, #+.C?, +z^VriV~?, #-z^V+. Arg(~Z^vXv+ #Arg(~Z^v%) vArg(6/+), which means that In& (d,w)(X, Z, Y) does not hold. We have then proved that Inq,,,) (X, Z, Y) implies In&(X, Z U W; Y). 0 Equivalence between belief change and entailment formulations Suppose that Zndb, (X, Z, Y) . Then Zn~,,,=pj (X, Z, Y) and, hence, kArg(XVYVZ) =Arg(RvZ) VArg(pvZ). Since W is empty, arguments with respect to (A, W) can only be true or false. Moreover, l Arg( a) = true iff A k CY. iff A F (Y. l Arg( a) = false Therefore, ~Arg(~V~V~) =Arg(kiVg) VArg(Ev?I) is equivalent to A k 2 V Y V Z precisely when A !y _% V Z or A k P V Z and we have In&,(X, Z, Y) . The other direction follows similarly. 0 Proof of Theorem 4 The proof uses Definitions proof with respect ( 1) Trivial 12 of independence. 3 of independence. independence: Zndd( X, Z, 8). Note to Definitions If we choose W = 8, we obtain a that $ is false and that Arg( 2) + Arg( 2 V 2) since Z k X V Z. We have: /=Arg(~v$V~)~Arg(kifalseV~) EArg(XV Z) 76 A. Danviche/Artificial Intelligence 97 (1997) 45-82 =A& v i) VA&) =Arg(hd) VArg(tjv2). Therefore, Z&(X, Z, 8). (2) Symmetry: Znd~~,w) (X, Z, Y) precisely when Z~~~A,WJ (r: Z, X). Follows directly from definition. (3) Decomposition: If Znd(p,w, (X U L, Z, Y), then Znd(d,~) (X, Z, Y). This proof uses the following facts: (a) If ~~i-l/li,then~Aj~i_Air//. (b) k l\i(4V@i/i) (c) Suppose i= Aa~rg(gv = 4Vr\i$i. P) E Arg(i;). that Znd(d,~) (X U L, Z, Y) : We have ~Arg(~V~Vf)zArg(ZVf)VAArg(~v$vt) i =Arg(Z VP) VArg(i Vi?). Hence, Zndcd,~) (X, Z, Y). (4) Weak union: If Zndc~,~) (X U L, Z, Y), then Zrzd(~,~) (L, Z U X, Y). Suppose that Z@Ll,W)(X u L z Y): +Arg(ZVriVLV8) =Arg(~V~Vf,)vArg(~V~). Since Al;q( 2 V 2) b Arg( .?f V 2 V ,?), we have bArg(iV*VL) =Arg(iVriVt) VArg(ZV%), and /=Arg(pVJ?VLVp) = [Arg(ZVgVL) VArg(ZVg)] VArg(ZV?). Moreover, by decomposition, we have Z~LZ(~,~) (X, Z, Y) : /=Arg(iVJ?Vf) =Arg(iV%)VArg(iVf). Hence, and Znd(d,w) (L, Z U X, Y). A. Danviche/Artificial Intelligence 97 (1997) 45-82 77 (5) Contraction: If Znd(d,w) (X, Z, Y) and I~z~(~,w) (L, Z U X, Y), then Znd(d,Wj (X u L,Z,Y). Suppose that ZU$~,W)(X,Z,Y) and Z~I~(~,W)(L.Z UX,Y): bA~rg(pVXVf) sArg(ZV?) VArg(ZVg) and kArg(pVXVLVP) =Arg(ZV_%VL) VArg(hhI;). Expanding the second equation using the first: ~Arg(~V~V~V~) zArg(ZV*Vt) VArg(~V~)VArg(ZV&, which reduces to /=Arg(iVkViVp) =Arg(iVTV,?.i) VArg(Z VP), because +Arg(i?V& kArg(pVzVL). Hence, Zrzd(d,w) (X U L, Z, Y). Cl Proof of Theorem II Suppose that Con&,(y) = %i V . . . V Gn. Then A U {y} k 9’1 V . . . V Gn. We need to prove that ( 1) each @i is a diagnosis, if % is a diagnosis, (2) and then @ k @r V . . . V @,,. To show that_@i is a diagnosis, we need to show that AU {y, Gi} that A U {y, Wi} is not consistent. Then A U {y} k TGiri and is consistent. Suppose A U {y} b @I V . . . V %‘_I V @i+l V . . ’ V G’n. But this contradicts with %i V . . . V ii,, being a logically AU 1~). strongest sentence entailed by Suppose-that G @I-V. . . V W,,. This means TW,, . ..) A U {y, %} k 7sn. This means know it is not. 0 is a diagnosis. Then A U {y, @} that @ must belong is consistent and A U {y, %} b to @i V. . . V %,,, otherwise AU {y, @} + that A U {y, @} is inconsistent, which we Proof of Theorem 15 Suppose that Arg$,( a) s p. Then p is a logically weakest sentence that is constructed from atoms W such that It then follows that -/3 is a logically strongest sentence constructed from W such that A u {~a} + +. Therefore, Cons$(~cu) -fi is the consequence = -Arg$(n) and A&,(a) of icy, that is, Consd,(lcu) E ~Cons~(--a). = lp. This implies that 0 78 A, Danviche/Artificial Intelligence 97 (1997) 45-82 Proof of Theorem 18 We will prove Zndd( {a}, U U W, N) by assuming that n is a leaf node in 0. The proof will also work when n is not a leaf node since, by Corollary 23 of Theorem 22, we can prune of n to make it a leaf node without the descendants invalidating the proof. To prove Zrzdd( {n}, U U W N), we need to prove ,-.h A u {W, U} k ii precisely when AU{@&fi} +fiA, for all @, 6, fi, A where A U {@, 6, fi} is consistent. The direction AU{@$} b’A only if AU{%,6,fl} +Fr is trivial. The direction Au{ti&ti} +fi only if AU (@,6} k A is equivalent to AU{@,fi} #5 only if AU{@,6,A} #A and A’UA,U{@,fi} #A onlyif A’UA,,U{@,6,m) #A where A’=A\A,. that Suppose A'UA,U{i?,6}#li. One of the following must be true: ( 1) A, U {@, 6) is equivalent is equivalent (2) A,, U {@, 6) to {@, 6) 0,’ to {+z, W, U}. This holds because by definition of a local database, A,, must be equivalent disjunctive Moreover, each one of these clauses must either to IV, U and n and containing clauses, each referring only either to a set of ii or 15. ( 1) be entailed by {@, 6) (2) resolve with { @, 6) in which case it can be removed from A,, or to yield -5 in which case it can be replaced by +. l3 This means that we either have ( 1) A’ U A,, U {@, 6) is equivalent (2) A’UA, U{@,e} is eq uivalent to A’ U {%, 62 a_“d A’ U {@, 6) #_k cr to A’ U { +i, W, U} and A’ U { 4, W, U} # A, and therefore either (1) A’U{@,~,m} ir since A’ U {W, U, N} --_ # is consistent and does not refer to n, (2) ~u{+?,0,zV) #- II since A’ U {-ii, i%, 6, fi} is consistent. In either case, it follows that I3 The result of the resolution cannot be ii since A’ U 4, U { @, 6) # A. A. Danviche/Art$cial Intelligence 97 (1997) 45-82 79 Proof of Theorem 19 in [25] Verma has shown ( 1) N is a set of atomic propositions, (2) Z is an independence the semi-graphoid axioms, that if relation over N, a subset of 2N x 2N x 2N, that satisfies (3) G is a DAG over nodes N, (4) each node n in 6 is independent to 1, of its non-descendants given its parents according then whenever X and Y are d-separated by Z in Q, we must have I (X, Z, Y) . Given a structured database the semi-graphoid satisfies is independent whenever X and Y are d-separated by Z in 8, we must have In&(X, Z, Y). relation Znd4 axioms. And by Theorem 18, we know that each node in 6 to Znd,. Therefore, its parents, according that the independence of its non-descendants (6, d), we know given 0 Proof of Theorem 22 ( 1) The equivalence between A k &’ and A’ + fi follows immediately from the proof in (2) below. (2) The consistency of A U {fi} is equivalent to the consistency of where A are the other atoms of G (different to the consistency of A’ U {N} is equivalent from n and N). Similarly, of the consistency Therefore, it suffices to show that the consistency of each A U { f? A @A x} is equivalent to the consistency of its corresponding A’ U { fi A @A x}. Suppose that AU {z A % A A^) is consistent. Then A’ U { fi A % AA} must also be consistent since A’ C A. Now suppose that A’ U {G A @ A AI) is consistent. Then it must be equivalent to (3 A @ A x} since N U W U A are all the atoms appearing in A. Therefore, A U {@ A @ A A^) must be equivalent to A,, U {z A % A A^) since A = A’ U A,. By the definition of local database A,,, it follows We have {f? A @ A i} A U {%} therefore and is consistent (3) Note that Arg$( that A, U {$A @ A i} must be consistent. l4 between established the equivalence the consistency that of A’ U {fi A i? A A^). By that we have also established of A U that Therefore, Arg$ (I?) is equivalent to Arg* wuz ( fi) if atoms Z do not appear to Arg$ (ai) since W \ W’ do not appear in A’. All in A. iff A’ U {z} fi) is. is equivalent I4 Recall that any disjunctive {N^ALZ}. clause entailed by database A, must include atom n, which does not appear in 80 A. Darwiche/Art@cial intelligence 97 (1997) 45-82 we need to show then is the equivalence between A&(& and Arg$ (I?), which can be established by proving shown in (2) above. that A U {@} b I%’ iff A’ U {@} k fi. This can be proved as (4) The equivalence (3) and Theorem 15. between Con&($ 0 and Cons$ ( fi> follows immediately from Proof of Corollary 23 What we need to show is precisely when Argd,l,(hviv~) =Arg$,(%v& VArg&(liVi). This follows from Theorem 22, according to which ~Arg$(~V~V~) =Arg$(kV~V~), kArg$(%Vg) =Arg$(8Vz> and kArgd,(pVi?) =Arg$(pVZ). 0 Theorem A.1. Let ($7, A) be a structured database, n be a node in 6, U be its parents and N be some of its other ancestors. We then have Arg*(H V 0 V fi) rArg*“(fi V if) VArg*(oV I?). Proof. By Theorem 18, we have since tndA ( {n}, U U W N) . Therefore, it suffices to show since A&,( 0) entails Arg&( 0 V fii> . The direction Arg$(fiVo) VA&,(o) kArg$(iiVo) is trivial. To show the direction Argd,(AVo) +Arg$(AV@ VArg$(o) we need to prove that AU{@_ b AVir implies either A,U{@} b AVO or AU{@}h If we take 2 to be +z and U to be -0, inconsistent Suppose is inconsistent. and A,, U {%,Z, 6) only that A u {G, 2,6} if A,, U {@,Z, 6) or A U {@, 6) to show that A U {%, %, U} then we need is inconsistent 0. is A, U {@, G, 6) is equivalent to {@,Z, fi} and therefore A U {@,Z, 6) is consistent. Then to is equivalent A. Darwiche/Artificial Intelligence 97 (I 997) 45-82 81 A/A, U {%‘,i?;, 6). This means A/A, u {%‘, 6} Therefore, A U { @‘, 6) is also inconsistent is inconsistent. that A/A,, U {G,- n, I?} is inconsistent, which implies that in A/A,, U {%, 6). since atom n does not appear q References [ I 1 B.D. D’Ambrosio, Local expression languages for probabilistic dependence, Internat. J. Approximate I-15. Reasoning 11 (1994) [ 2 1 A. Darwiche, A symbolic Stanford, CA ( 1992). A. Darwiche, Conditioning generalization of probability theory, Ph.D. Thesis, Stanford University, algorithms for exact and approximate inference in causal networks, in: Proceedings I lth Conference on Uncertainty in ArttJicial Intelligence (l/AI) A. Darwiche, Model-based (1995) 211-217. A. Darwiche diagnosis using causal networks, and J. Pearl, Symbolic causal networks, ( 1995) 99-107. in: Proceedings IJCAI-95, Montreal, Que. in: Proceedings AAAI-94, Seattle, WA ( 1994) 238-244. J. de Kleer, An assumption-based TMS, Artificial Intelligence 28 (1986) 127-162. [ 7 ] J. de Kleer, A.K. Mackworth and R. Reiter, Characterizing diagnoses and systems, Artificial Intelligence 56 ( 1992) 197-222. [ 8 1 R. Dechter and A. Dechter, Belief maintenance in dynamic constraint networks, in: Proceedings AAAI-88, St. Paul, MN (1988) 37-42. ]9 1 R. Dechter and A. Dechter, Structure-driven algorithms for truth maintenance, Artificial Intelligence 82 (1996) I-20. [ 10 ] R. Dechter and J. Pearl, Directed constraint networks: A relational framework for causal modeling, in: Proceedings IJCAI-91, Sydney, Australia ( 199 1) I 164-1170. 1 I 1 1 F! Gtidenfors, Knowledge in Flux: Modeling the Dynamics of Episfemic States (MIT Press, Cambridge, MA, 1988). [ I2 1 H. Geffner and J. Pearl, An improved constraint-propagation algorithm for diagnosis, in: Proceedings IJCAI-87, Milan, Italy ( 1987) 1105-l 111. [ 131 R. Greiner and D. Subramanian, Relevance, Orleans, LA ( 1994). in: Working Notes, AAAI-94 Full Symposium Series, New 114 ]I5 ] F.V. Jensen, S.L. Lauritzen and K.G. Olesen, Bayesian updating in recursive graphical models by local computation, Comput. Statist. Quart. 4 (1990) 269-282. based in knowledge Irrelevance I A.Y. Levy, reasoning systems, Ph.D. Thesis, Stanford University, Stanford, CA ( 1993). I 16 1 A. Levy, I.S. Mumick and Y. Sagiv, Query optimization by predicate movearound, in: Proceedings 20th VLDB Conference, Santiago, Chile ( 1994). I17 I A.Y. Levy and Y. Sagiv, Queries Ireland (1993) 171-181. independent of updates, in: Proceedings 19th VLDB Conference, Dublin, 118 ] Z. Li and B.D. D’Ambrosio, Efficient inference in Bayes networks as a combinatorial optimization problem, Internat. J. Approximate Reasoning 11 ( 1994) 55-8 1. I19 1 J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference (Morgan Kaufmann, San Mateo, CA, 1988). ]20 81 M.A. Peot and R.D. Shachter, Fusion and propagation with multiple observations in belief networks, Arttjicial Intelligence 48 (1991) 299-318. 121 I R. Reiter and J. de Kleer, Foundations of assumption-based truth maintenance systems: preliminary report, in: Proceedings AAAI-87, Milan, Italy ( 1987) 183-l 88. 122 1 R. Shachter, S.K. Andersen and P Szolovits, Global conditioning for probabilistic inference in belief networks, in: Proceedings 10th Conference on Uncertainty in AI, Seattle, WA (1994) 514-522. I23 I D. Subramanian, A theory of justified reformulations, Ph.D. Thesis, Stanford University, Stanford, CA (1989). 82 A. Datwiche/Art@cial Intelligence 97 (I 997) 45-82 [24] D. Subramanian and M.R. Genesereth, The relevance of irrelevance, in: Proceedings IJCAI-87, Milan, Italy (1987) 416-422. [25] T. Verma and J. Pearl, Causal networks: semantics and expressiveness, in: Proceedings 4th Workshop on Uncertuinry in AI, Minneapolis, MN ( 1988) 352-359. [26] N. Wilson, Generating graphoids from generalised conditional probability, in: Proceedings 10th Conference on Uncertainty in AI, Seattle, WA ( 1994) 583-590. 