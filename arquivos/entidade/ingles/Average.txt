Available online at www.sciencedirect.comRArtificial Intelligence 155 (2004) 183–206www.elsevier.com/locate/artintAverage-case analysis of best-first searchin two representative directed acyclic graphsAnup K. Sen a, Amitava Bagchi a, Weixiong Zhang b,∗a Indian Institute of Management Calcutta, Joka, D. H. Road, Calcutta 700 104, Indiab Department of Computer Science and Engineering, Washington University in Saint Louis,St. Louis, MO 63130, USAReceived 5 May 2003AbstractMany problems that arise in the real world have search spaces that are graphs rather than trees.Understanding the properties of search algorithms and analyzing their performance have been majorobjectives of research in AI. But most published work on the analysis of search algorithms hasbeen focused on tree search, and comparatively little has been reported on graph search. One of themajor obstacles in analyzing average-case complexity of graph search is that no single graph canserve as a suitable representative of graph search problems. In this paper we propose one possibleapproach to analyzing graph search. We take two problem domains for which the search graphsare directed acyclic graphs of similar structure, and determine the average case performance of∗on these graphs. The first domain relates to one-machine jobthe best-first search algorithm Asequencing problems in which a set of jobs must be sequenced on a machine in such a way thata penalty function is minimized. The second domain concerns the Traveling Salesman Problem.Our mathematical formulation extends a technique that has been used previously for analyzing treesearch. We demonstrate the existence of a gap in computational cost between two classes of probleminstances. One class has exponential complexity and the other has polynomial complexity. For thejob sequencing domain we provide supporting experimental evidence showing that problems exhibita huge difference in computational cost under different conditions. For the Traveling SalesmanProblem, our theoretical results reflect on the long-standing debate on the expected complexityof branch-and-bound algorithms for solving the problem, indicating that the complexity can bepolynomial or exponential, depending on the accuracy of the heuristic function used. 2004 Elsevier B.V. All rights reserved.∗Keywords: Graph search; Average-case complexity; A; Job sequencing; Traveling salesman* Corresponding author.E-mail addresses: sen@iimcal.ac.in (A.K. Sen), bagchi@iimcal.ac.in (A. Bagchi), zhang@cse.wustl.edu(W. Zhang).0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.01.001184A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–2061. Introduction and overviewIn many real-world applications, graph search can be shown to be more efficient thantree search. Sometimes, tree search is simply not feasible. Consider sequence alignment, animportant issue in computational biology that can be formulated as a shortest-path problemin a grid. It can be solved only with the help of graph search [5,12,17]. Problems thatarise in single-machine minimum-penalty job sequencing can be solved with the help ofeither graph search or tree search, but in this case graph search outperforms tree search interms of running time even when the evaluation function is non-order-preserving [26]. Inaddition, in the determination of a winner in a combinatorial auction [25], a solution can beobtained in principle by enumerating exhaustive partitions of items in a search space thathas the form of a graph. These examples demonstrate that graph search has many possibleapplications. Moreover, graph search usually needs much less memory than best-first treesearch, making larger problems solvable on current machines [27].Although graph search plays an important role in understanding, characterizing andsolving difficult combinatorial optimization problems, the average-case performance ofgraph search algorithms has hardly been analyzed at all. In sharp contrast, there is a largeliterature devoted to the analysis of the performance of tree search algorithms [2,6,7,11,16,20–22,31]. One objective of this paper, which extends the work already reported in [28], isto try and redress the balance.A major consideration that has hamstrung the research on the performance analysis ofgraph search algorithms is that no single graph can claim to be a representative graph forthe search spaces that arise in real-world applications. Therefore, general results on theperformance of graph search seem to be out of reach. One way out of this dilemma is to doa separate independent analysis of each individual problem, but this makes generalizationdifficult. Here we take a middle road. Our analysis is neither perfectly general nor confinedto an individual case. We choose to study a representative model of a set of relatedproblems, in the hope that this will not only shed more light on the individual problems,but perhaps also lead to a generalization that will help to achieve a deeper understandingof graph search.Here we look at two classes of problems. The first class consists of one-machinejob sequencing problems, and the second consists of the Traveling Salesman Problem(TSP). Job scheduling and job sequencing problems arise frequently in manufacturing andproduction systems as well as in information processing environments [23]. We considera class of problems in which N given jobs must be sequenced on a machine in such away that a specified function of job completion times is minimized. The function can havemany different forms and might involve the minimization of measures such as the mean joblateness and/or earliness or the weighted sum of quadratic functions of completion times.Our analytical model for the job sequencing problem has the form of a graph that definesa partial ordering on the subsets of a set of N elements (jobs) under the set inclusionproperty. N determines the problem size. The graph itself has 2N nodes, and is a directedacyclic graph (DAG) with one root node, one goal node and multiple solution paths. The setof N elements forms the root node at level 0, and the empty set is the goal node at level N .To make the analysis feasible, it is assumed, following [22], that the normalized errorsof heuristic estimates of nongoal nodes are independent, identically distributed (i.i.d.)A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206185random variables. Using this abstract model, we analyze the complexity of the best-firstgraph search algorithm A∗. The measure of complexity is the expected number of nodeexpansions. We choose A∗ in preference to other search algorithms because it is optimal interms of the number of node expansions among all algorithms that use the same heuristicinformation [8].There are two main theoretical results. First, it is shown that under certain weakconditions the expected number of distinct nodes expanded by A∗ increases exponentiallywith the number N of jobs for large N . This is consistent with previous experimentalresults on the one-machine job sequencing problem [27]. Second, special cases of interestare identified in which the expected number of node expansions made by A∗ is polynomialin N for large N . The results indicate that the expected complexity of A∗ graph searchon job sequencing problems has two distinct phases, one exponential and the otherpolynomial, demonstrating the existence of a huge gap similar to a phenomenon ofphase transition. Experimental results support the theoretical analysis. We summarize theprevious results for the exponential case and provide new test results on the polynomialcase.A similar, but not identical, search graph arises in a solution procedure for theTraveling Salesman Problem (TSP). In essence, all known algorithms for solving the TSPexactly are implicit enumeration methods based on the branch-and-bound procedure whichprogressively construct complete tours [9,10,18]. One difference between these algorithmsrelates to the branching rules that determine whether the search space is a tree or a graph[3]. Even though some of the best TSP algorithms use a tree search space, e.g., [30], itremains to be determined which search space, tree or graph, is more efficient. It is verylikely that the search space to use would depend on the application at hand. In addition, agraph search space, originally proposed for the TSP in [22], has been used as a benchmarkdomain in some computational experiments [24]. Therefore, it is worthwhile to examinegraph search spaces in the context of the TSP. It is interesting to note that the theoreticalresults derived for the job sequencing domain have their counterparts in the TSP domain,which means that A∗ may run in exponential or nonexponential or polynomial time in thenumber N of cities. We state and prove the corresponding theorems. These results mayshed light on the long-standing debate on the expected complexity of specific branch-and-bound algorithms for solving the TSP in [4]. It has been argued that a branch-and-boundalgorithm can find an optimal solution to the TSP in time polynomial in N under certainconditions [4], or in time exponential in N when such conditions are hard to satisfy [15,19].When run on graphs, A∗ can be viewed as a special type of branch-and-bound algorithmthat uses a best-first search strategy and exits as soon as a solution is found. Therefore theresults in this paper seem to indicate that the expected complexity of a branch-and-boundalgorithm for the TSP can be polynomial or nonexponential or exponential, dependingboth on the definition of the inter-city cost function and the accuracy of the heuristicfunction.The paper is organized as follows. The application domains and their representativesearch graphs are introduced in Section 2. Basic concepts relating to graph search andthe framework of our analysis are presented in Section 3. In Section 4 we examine thejob sequencing problem in greater detail, derive the expected complexity of A∗, and also186A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206present supporting experimental results. Section 5 is concerned with the TSP, and Section 6concludes the paper. Proofs of theorems are supplied in Appendix A.2. Application problem domains and representative graphs2.1. One-machine job sequencing problemsWe now describe the representative graphs that model the search spaces of the twoapplication problem domains mentioned above. Consider the graph that defines the partialordering of subsets of a set of N elements under the set inclusion property. Let SN bethe set {1, 2, . . . , N}. The subsets of SN under the partial ordering relation induced by setinclusion form a directed acyclic graph Gjs of 2N nodes. In this graph SN is the root nodeat level 0, and the empty set { } is the goal node at level N . The immediate successors ofa node n are the various subsets of SN obtained from n by removing one element. Thus anode corresponding to a subset of k elements has k immediate successors. Gjs for N = 4is shown in Fig. 1. Such a graph has the following characteristics:(1) A node with i elements is at level N − i.(2) There are i! distinct paths to a node at level i.(3) There are C(N, i) nodes at level i.(4) The total number of paths starting at the root and going up to level i is C(N, i) · (i!).This graph arises in the solution of certain one-machine job sequencing problems, andexhibits top–down and left–right symmetry. Graphs with similar symmetries also arise ingraph search formulations for the Traveling Salesman Problem [22] and in the winnerdetermination problem in combinatorial auctions [25].Fig. 1. Analytical model Gjs for N = 4.A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206187(cid:1)In the job sequencing problem, jobs Ji with processing times Ai > 0 for 1 (cid:1) i (cid:1) N ,are submitted to a one machine job shop at time 0. The jobs, which are assumed to haveno setup times, are to be processed on the given machine one at a time. Let the processingof job Ji be completed at time Ti . Penalty functions Hi are supplied such that the penaltyassociated with completing job Ji at time Ti is Hi(Ti) > 0. Hi is nondecreasing in itsargument, and in general nonlinear. The jobs must be sequenced on the machine in such aNway that the total penalty F =i=1 Hi(Ti) is minimized. Nodes in the search graph Gjscorrespond to subsets of jobs that remain to be processed. The root node corresponds to theset of all N jobs, and the goal node to the empty set of jobs (i.e., to the completion of alljobs). Arc costs are assigned as follows. Suppose there is an arc from node n1 to node n2,and suppose job Ji is present in the subset of jobs associated with n1 but absent from thesubset of jobs at n2. Then c(n1, n2) = Hi(Ti). Here Ti is the time at which the processing ofjob Ji is completed; its value does not depend on the order in which jobs prior to job Ji areprocessed. Since setup times are ignored in this model, arc costs are order preserving [22].Such graphs have been searched in the past using A∗ or TCBB [13]. Here we restrictourselves to the A∗ algorithm because it is optimal in terms of node expansions [8].2.2. Traveling Salesman Problem (TSP)A graph-search solution procedure for the TSP gives rise to a similar search graph.Let the N cities be numbered 1, 2, . . . , N . Each node in the network is identified by apair (the set of cities already visited, current city). The trip is assumed to begin fromcity 1, and the start node is ({ }, 1), where { } represents the empty set. The goal nodeis ({1, 2, . . ., N}, 1). A∗ expands the start node and generates its N − 1 successor nodes({1}, 2), ({1}, 3), . . ., ({1}, N). The cost of the arc from ({ }, 1) to a successor ({1}, J ),where 2 (cid:1) J (cid:1) N , equals the cost of going from city 1 (the current city of the predecessornode) to city J (the current city of the successor node). The complete network Gtsp forN = 4 is shown in Fig. 2. For a specific cost matrix, a tour of minimum cost is foundby running A∗ on the above search graph. The heuristic estimate at a nongoal nodeis computed using a minimum spanning tree heuristic [10]. The network Gtsp has thefollowing characteristics:(1) The start node is at level 0, while the goal node is at level N . A node at level icorresponds to a partial tour in which i cities have already been visited and the (i +1)thcity has been reached.(2) A node at level i has (i − 1) incoming arcs for 1 < i (cid:1) N , and i incoming arcs fori = 0, 1. Similarly, a node at level i has (N − i − 1) outgoing arcs for 0 (cid:1) i < N − 1,and (N − i) outgoing arcs for i = N − 1, N .(cid:2)(3) The total number of nodes at level i isif 1 (cid:1) i < N,if i = 0 or i = N.i · C(N − 1, i)1(cid:2)(4) The total number of paths entering a node at level i isif 1 (cid:1) i (cid:1) N,if i = 0.(i − 1)!0188A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206Fig. 2. Analytical model Gtsp for N = 4.3. Basic conceptsA search graph (or network) G is a finite directed graph with nodes n, n(cid:9), n1, n2, . . . .The search always begins at the start (or root) node s, and ends at the goal node r. Eachdirected arc (n1, n2) in G has a finite arc cost c(n1, n2) > 0. A path is a sequence ofdirected arcs. A solution path is a path that begins at the start node s and ends at the goalnode r. The cost c(P ) of a path P is the sum of the costs of the arcs that make up the path.The objective of a search algorithm like A∗ is to find a solution path of minimum cost in G.To find such a solution path, A∗ uses a nonnegative heuristic estimate h(n) associated witheach nongoal node n in G; h(n) can be viewed as an estimate of h∗(n), which is the costof a path of least cost from n to the goal node.Let g∗(n) be the cost of a path of least cost from the start node to node n, and letf ∗(n) = g∗(n) + h∗(n). Then f ∗(n) is the cost of a solution path of least cost constrainedto pass through node n. During an execution of A∗, we use g(n) to represent the costof the path of least cost currently known from s to n. So g(n) can be viewed as thecurrent estimate of g∗(n), and f (n) = g(n) + h(n) as the current estimate of f ∗(n). As iscustomary, f ∗(r) denotes the cost of a minimum cost solution path in G.Our networks are directed acyclic graphs. In such graphs, introducing more than onegoal node does not add to the generality because there are multiple paths from the rootnode to the goal node in any case. When A∗ is run on such a network, a node may reenterOPEN from CLOSED; as a result, a node may get expanded more than once. Let Zd and Ztdenote, respectively, the number of distinct nodes expanded by A∗ and the total number ofnode expansions made by A∗ when run on a given network G. Zt − Zd is also sometimesreferred to as the total number of reopenings of nodes. Our primary goal is to determinethe expected values E(Zd ) and E(Zt ).In order to assign a probability distribution on the heuristic estimates of nongoal nodesin G in a meaningful way, we adopt the notion of a normalizing function [22, p. 184].A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206189A normalizing function Φ is a total function with the set of nonnegative real numbers asdomain and the set of real numbers greater than or equal to 1 as range. It has the followingproperties:(1) Φ(0) = 1;(2) Φ(x) is nondecreasing in x;(3) Φ(x) is unbounded, i.e., the range of Φ has no finite upper bound.We allow Φ to take one of three functional forms, viz., identity, less-than-linear andlogarithmic:Φ(x) = max{1, x}:Φ(x) = max{1, xδ}, for some δ, 0 < δ < 1:Φ(x) = max{1, ln(x)}:identity,less-than-linear,logarithmic.The normalized error at a nongoal node n is χ(n) = (h(n) − h∗(n))/Φ(h∗(n)). We assumethat for all nongoal nodes in G, the normalized errors are i.i.d. random variables. Thenormalizing function Φ determines the accuracy of the heuristic estimate function. WhenΦ is the identity function, the magnitude of the error h(n) − h∗(n) is proportional toh∗(n). The purpose of allowing other functions, such as logarithmic ones, for example,is to enable us to study the consequences of limiting the error h(n) − h∗(n) to lowerorder values, implying greater accuracy of heuristic estimates. We use χ in place ofχ(n), as the χ(n)’s are identically distributed. Let Fχ (x) = p(χ (cid:1) x) be the cumulativeprobability distribution function of χ . Then Fχ (x) is nondecreasing in x. We allow Fχ (x)to have discontinuities. These must be left-discontinuities, since Fχ (x) by definition isright continuous. We do not assume any specific functional form for Fχ (x).A heuristic function h is admissible if for every nongoal node n in the network G,h(n) (cid:1) h∗(n). Otherwise h is inadmissible. If Fχ (x) = 1 for x (cid:2) 0, then all nongoalnodes have admissible heuristic estimates with probability 1. Let a1 = lub{x | Fχ (x) = 0}and a2 = glb{x | Fχ (x) = 1}. For x < a1, Fχ (x) is identically 0, while for x (cid:2) a2,Fχ (x) is identically 1. The heuristic estimate function is admissible if a2 (cid:1) 0; it is purelyinadmissible if a1 > 0. When Φ(x) is the identity function, we must have a1 (cid:2) −1. Evenwhen the heuristic estimate function is not admissible (i.e., when a2 > 0), so long as a1 < 0,a node n will be expanded by A∗ if f (n) < f ∗(r) and at least one of the immediatepredecessors of n has been expanded. Note that by definition of a1 and a2, it must bethe case that(1) h(n) (cid:2) h∗(n) + a1Φ(h∗(n)) with probability 1;(2) h(n) (cid:1) h∗(n) + a2Φ(h∗(n)) with probability 1.A heuristic estimate function is consistent [22] if for every nongoal node n in thenetwork G and every immediate successor n(cid:9) of n, it is the case that h∗(n) (cid:1) c(n, n(cid:9)) +h∗(n(cid:9)). From now onwards, whenever a normalizing function is under discussion, weassume that the corresponding a1 and a2 are finite.190A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–2064. Analysis of one-machine minimum-penalty job sequencing problems4.1. Exponential complexityWe begin by assigning a probability distribution on the heuristic estimates of nodesin Gjs. To compute the number of nodes expanded, we impose some restrictions on thejob processing times and the penalty functions. We first suppose that the processing timesAi are integers and satisfy the condition 1 (cid:1) Ai (cid:1) k for 1 (cid:1) i (cid:1) N , for some constantk > 1. This imposes a fixed upper bound on the processing times of jobs. We then assumethat there is a positive integer constant β such that the penalty Hi(x) is an integer and hasorder o(xβ) for 1 (cid:1) i (cid:1) N . This means that the penalty functions are polynomial in theirargument, and the highest power in the polynomial is less than β. We also assume that allarc costs are greater than or equal to 1.These are reasonable assumptions to make about the processing of jobs in single-machine job sequencing problems. Similar assumptions were made in [27]. To test ourassumptions we carried out experiments in which the penalty function for a job wasproportional to the square of its completion time. All jobs were submitted at time t = 0.The jobs had processing times but no setup times. The objective was to sequence the jobsto minimize the sum of the penalties [29]. Penalty coefficients (proportionality constants)were random integers uniformly distributed in the range 1 to 9. Processing times wererandom integers uniformly distributed in the range 1 to 99. For a given number of jobs, 100random problem instances were generated and solved by A∗, and the results were averagedover these 100 runs. The heuristic estimate at a node was computed as suggested in [29].This heuristic is consistent and quite accurate, but we do not know the exact accuracylevel, i.e., whether we should take the normalizing function as linear, less-than-linear orlogarithmic. The average numbers of nodes generated and expanded by A∗ on problems ofdifferent sizes are shown in Table 1. The number of nodes generated never exceeds N · Zt ,where N is the number of jobs. No node is expanded more than once since the heuristic isconsistent. The results reported in [27] are similar but slightly better, because an additionalpruning rule was applied there. In Table 1, both the number of nodes generated and thenumber of nodes expanded increase fairly rapidly with the number of jobs.Let us try to offer a partial theoretical justification for these observations. Let us say thata function Ψ (N) of N varies exponentially in N for large N if there exists real constantsγ , δ, ε > 0 such thatlimN→∞Ψ (N)δ · exp(γ · N ε)→ 1.Let us also say that Ψ (N) varies polynomially in N for large N if there exists a real constantε > 0 such thatlimN→∞Ψ (N)N ε→ 0.We now prove below that when the normalizing function is the identity function anda1 < 0, the expected number of distinct nodes expanded is exponential in N for largeN , provided there is a fixed upper bound on the processing times of jobs.A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206191Table 1Performance of A∗using consistent heuristicsNo. ofjobsNodes generatedNodes expandedMeanStd. Dev.MeanStd. Dev.182022242628301299.372327.024207.797063.9912602.6922046.0537199.94837.371523.123193.395255.229273.0216912.9032578.06119.70191.52313.13477.35787.991268.682000.1286.13137.97267.38389.68638.921044.521893.12Theorem 4.1. Suppose that for 1 (cid:1) i (cid:1) N , Hi(x) is o(xβ) where β is a positive integerconstant, and 1 (cid:1) Ai (cid:1) k for some constant k > 1. If Φ is the identity function and a1 < 0,then E(Zd ), the expected number of distinct nodes of Gjs that get expanded, is exponentialin N for large N .Proof. See Appendix A. ✷This theorem is quite general and covers a wide variety of situations that arise inminimum-penalty job sequencing [26]. In particular, the theorem does not assume thatthe heuristic is admissible, merely that a1 < 0. Some of the constraints can be relaxed asexplained below:(1) There is really no need to assume a constant upper bound on the job processing times.We can just assume that there exists a positive integer constant ε such that Ai is o(N ε),1 (cid:1) i (cid:1) N .(2) The proof also remains valid for normalizing functions that are less-than-linear.We were curious to find out from observation what happens when the heuristic estimatesare admissible but not necessarily consistent. So we carried out a further set of experimentsmaking the same assumptions as those made above with a minor change. This time, for anode n, we took h(n) = h∗(n) − ℘ (n)h∗(n), where ℘ (n) is a uniformly distributed randomnumber in the open interval (0, 1) that is determined independently for each n. The resultsare shown in Table 2. Since heuristic estimates were inconsistent, a node was expandedmore than once as paths of lower cost were found to it. As a result, the number of nodesexpanded exceeded the number of nodes generated. These experiments confirm our earlierobservation that when the normalizing function Φ is the identity function, the performanceof A∗ tends to deteriorate very fast as N increases.We were also interested to find out what happens when the heuristic estimates are notpurely admissible, i.e., a1 < 0 but a2 > 0. We carried out experiments where heuristicestimates h of nodes were either under-estimated or over-estimated using the formulah = h∗ + ℘h∗ where ℘ is a uniformly distributed random number in the open interval(−0.5, 0.5) that is determined independently for each node. The results obtained can besummarized as follows:192A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206Table 2Performance of A∗under linear error and inconsistent hNo. ofjobs6810121416Nodes generatedNodes expandedMeanStd. Dev.MeanStd. Dev.61.22249.241001.674029.9216156.3364752.364.6922.2796.65400.121623.796529.4360.55317.281606.497906.9639349.97185991.0618.3187.12443.891886.6310288.7240743.79(1) Due to inadmissibility of the heuristic estimate, the number of nodes generated andexpanded were reduced, typical values averaged over 100 runs for 16 jobs were36 034.07 and 17 600.36 respectively. Algorithm A∗ ran faster than in the admissiblecase.(2) The number of node expansions increased by a factor of 4.0 when problem size wasincreased from 10 to 12 jobs. The factor increased to 4.2 and 4.6 when the number ofjobs were increased to 14 and to 16 jobs respectively. Thus the trend indicates that theperformance of A∗ deteriorated faster with problem size as expected.(3) The solutions obtained are not optimal because the heuristic estimates are sometimesinadmissible.We restricted our experiments to smaller problems because, for every instance, weneeded to find out h∗ for all the nodes of the search graph first and store them for computingthe heuristic estimates.What happens when the normalizing function is logarithmic? Unfortunately, nothingvery specific can be said.Example 4.1. Let all arcs in Gjs have unit cost. This would happen, for example, when thepenalty functions Hi take the constant value 1 for all arguments.(1) Suppose the heuristic estimate function h is perfect, i.e., h = h∗ for all nodes. ThenZd can be linear to exponential in N depending on how ties are resolved.(2) Now consider the more general case when the heuristic estimates are not necessarilyperfect. Let a1 < 0. This means that there is a probability p > 0 such that h(n) < h∗(n)with probability p. Hence f (n) < N with probability p. Then for the search graph Gjs,E(Zd ) (cid:2) 1 + p · C(N, 1) + p2 · C(N, 2) + · · · + pN = (1 + p)N is exponential in Nfor large N . This is true even when the normalizing function is logarithmic.Instead of imposing a constant upper bound on arc costs, we can just try to ensure thatthe majority of the outgoing arcs at a nongoal node have a low cost.Definition 4.1. Let θ : {1, 2, . . . , N, . . .} → R be a given increasing (total) function withthe positive integers as domain and the positive real numbers as range with θ (1) = 1. LetC be a cost function defined on the arcs in Gjs. Then (Gjs, C) is super-regular with respectA.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206193to θ if for each nongoal node n in Gjs and for each integer y > 0, node n has at leastmin{N − i, (cid:13)θ (y)(cid:14)} outgoing arcs with cost (cid:1) y, where i is the level of node n in Gjs.When (Gjs, C) is super-regular, the arcs costs are said to be θ -relaxed.Thus super-regular graphs have a large number of outgoing arcs at a node with arc costslying within a given upper bound, but there is no constant upper bound on the cost of anarc. In this case an exponential number of nodes get expanded when the functions θ and Φare positive (fractional) powers of their arguments.Theorem 4.2. Let θ (y) = yβ for y > 0, where 0 < β (cid:1) 1, and let (Gjs, C) be super-regularwith respect to θ , i.e., θ -relaxed. If Φ(x) = max{1, xδ} for 0 < δ (cid:1) 1, and a1 < 0, thenE(Zd ) is exponential in N for large N .Proof. See Appendix A. ✷4.2. Polynomial complexityTo get polynomial bounds on the number of nodes expanded whenΦ(x) = max{1, ln(x)},we need to impose an upper bound on the number of arcs emanating from a node with costslying within a specified limit. This brings us to the notion of a sub-regular graph, whichhas a definition very similar to that of a super-regular graph, except that instead of a largenumber of outgoing arcs of bounded cost, we now have a small number of such arcs.Definition 4.2. Let θ : {1, 2, . . . , N, . . .} → R be a given increasing (total) function withthe positive integers as domain and the positive real numbers as range with θ (1) = 1. LetC be a cost function defined on the arcs in Gjs. Then (Gjs, C) is sub-regular with respectto θ if, for each nongoal node n in Gjs, the following two conditions are both satisfied:(1) For each integer y > 0, there are at most min{N − i, (cid:13)θ (y)(cid:14)} outgoing arcs from noden with cost (cid:1) y, where i is the level of node n in Gjs.(2) Node n has an outgoing arc of unit cost.When (Gjs, C) is sub-regular, the arcs costs are said to be θ -restricted.An additional assumption about arc costs is also required. Consider the set SN at the rootof Gjs consisting of the jobs to be sequenced. We can view the elements of SN as totallyordered under some linear ordering. For example, suppose the jobs in SN have distinctprocessing times. Then the jobs can be viewed as ordered in increasing order of processingtimes. At each node n, the outgoing arcs corresponding to jobs that get processed can beordered from left to right in order of the processing times of the jobs. We can then imposethe condition that the costs of outgoing arcs at node n should also be increasing from leftto right, so that the outgoing arc corresponding to the job with the smallest processing timehas the lowest cost, and so on.194A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206Definition 4.3. A graph (Gjs, C) is said to be C-ordered if(i) jobs have distinct processing times, and(ii) at every nongoal node, whenever the processing time Ai of a job Ji is less than theprocessing time Ak of a job Jk, the cost of the outgoing arc corresponding to job Ji isless than the cost of the outgoing arc corresponding to job Jk.In [27], the graphs are C-ordered when the processing times of jobs are distinct andpenalty coefficients are identical. C-ordering imposes an additional structure on the graphand enables us to prove the following result when the normalizing function is logarithmic.Theorem 4.3. Let θ (y) = yβ for y > 0, where 0 < β (cid:1) 1, and let (Gjs, C) be θ -restrictedand C-ordered. If Φ is logarithmic, then E(Zt ) is polynomial in N for large N .Proof. See Appendix A. ✷Our experimental results for this case are given in Table 3. Here the jobs had distinctprocessing times and the penalty coefficients were identical. Moreover, below every node,there were at most k arcs having arc cost < 10 · (100k)2. Thus these graphs were C-orderedand also θ -restricted except that there might not be an outgoing arc of unit cost belowevery nongoal node. Heuristic estimates at nodes were admissible and generated usingthe formula h = h∗ − ℘ log(h∗), ℘ being defined as in the experiments corresponding toTable 2.In the next set of experiments, we set h = h∗ − ℘ log(κh∗) where κ is a large constant,thereby forcing the logarithmic error to be much larger than for the experiments in Table 3.The results obtained were similar, as shown in Table 4 for κ = 1025. When the error islogarithmic, the numbers of nodes generated and expanded reduce dramatically. Since theerror is relatively small, the heuristic estimate of a node is close to perfect. As a result, whenthe arc costs at a node are distinct and penalty coefficients are identical, A∗ generates andexpands only a small number of nodes.The following theorem specifies a sufficient condition which ensures that, in θ -restrictedgraphs, the total number of nodes expanded by A∗ is polynomial in N for large N . Therequired condition imposes an upper bound on the maximum possible value that θ (y) canattain, which in turn restricts the number of outgoing arcs of bounded cost at any node.Table 3Performance of A∗with logarithmic errorNo. ofNodes generatedNodes expandedjobsMeanStd. Dev.681012141621.0036.0055.0078.00105.00136.000.000.000.000.000.000.00Mean5.007.009.0011.0013.0015.00Std. Dev.0.000.000.000.000.000.00A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206195Table 4Performance of A∗with logarithmic error, κ = 1025No. ofNodes generatedNodes expandedjobsMeanStd. Dev.MeanStd. Dev.681012141621.0436.0655.1678.10105.24136.550.400.601.131.001.692.715.017.029.0211.0113.0215.040.100.200.140.100.140.20Theorem 4.4. Let y0 be a given positive integer independent of N . Let β > 0 be an integerconstant. Suppose(cid:6)θ (y) =yβyβ0for y (cid:1) y0,for y > y0.Let (Gjs, C) be θ -restricted and C-ordered. Then regardless of whether Φ is linear, less-than-linear or logarithmic, E(Zt ) is polynomial in N for large N .Proof. See Appendix A. ✷We end this section with the following general result. Here, unlike in the previoustheorem, we allow θ (y) to take a large value for arguments (cid:2) y0. In the θ -restricted case,this permits all the remaining arcs at a node to have a cost of y0.Theorem 4.5. Let y0 be a given positive integer independent of N . Let β > 0 be a constant.Suppose(cid:2)yβfor y < y0,N for y (cid:2) y0.θ (y) =Then,(1) If (Gjs, C) is super-regular with respect to θ , Φ(x) = max{1, xδ} for 0 < δ (cid:1) 1, anda1 < 0, E(Zd ) is exponential in N for large N ;(2) If (Gjs, C) is sub-regular with respect to θ , Gjs is C-ordered and Φ is logarithmic,E(Zt ) is polynomial in N for large N .Proof. See Appendix A. ✷5. Analysis of the Traveling Salesman Problem (TSP)We now consider the expected complexity of the N -city Traveling Salesman Problem(TSP), assuming the TSP is being solved by means of A∗ graph search on Gtsp. Let cost bean N × N matrix with positive (nonzero integer) entries that specify the cost (or distance)196A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206of travel, cost(I, J ) being the cost of going directly from city I to city J . In the symmetricversion of the TSP, cost is a symmetric matrix. We take cost(J, J ), 1 (cid:1) J (cid:1) N , to beinfinite (i.e., a very large positive integer). We will say that the given cost matrix satisfiesthe triangle inequality ifcost(I, J ) + cost(J, K) (cid:2) cost(I, K)for every triple I, J, K, where 1 (cid:1) I, J, K (cid:1) N . This is an intuitively appealing notion,since the usual distance metric in two-dimensional Euclidean space satisfies the triangleinequality.5.1. Exponential complexityWe now show that when the heuristic is admissible, the normalizing function is theidentity function, and the cost matrix is symmetric and satisfies the triangle inequality, theexpected number E(Zd ) of distinct nodes expanded is exponential in N for large N . Thisis a very general result.Theorem 5.1. Consider a symmetric N -city Traveling Salesman Problem where the costmatrix satisfies the triangle inequality. Let Φ be the identity function, and suppose a1 < 0.Then E(Zd) is exponential in N for large N .Proof. See Appendix A. ✷As can be seen, the heuristic need not really be admissible; a weaker condition suffices.The theorem generalizes readily to normalizing functions that are less-than-linear. Theonly additional requirement is that the cost of the best tour should not be too large. Inthe theorem below, we require the cost of the tour to be O(N), but this condition can berelaxed. For example, when δ = 0.5, it suffices if the cost of the best tour is of lower orderthan N 2.Theorem 5.2. Consider a symmetric N -city Traveling Salesman Problem where the costmatrix satisfies the triangle inequality condition. Let Φ(x) = max{1, xδ} for some δ,0 < δ < 1, and let a1 < 0. Then E(Zd ) is exponential in N for large N whenever thecost of the minimum cost solution path is O(N).Proof. See Appendix A. ✷A similar result can be proved even when the cost matrix is asymmetric, providedcost(I, J ) is not too large compared to cost(J, I ).Theorem 5.3. Consider an N -city asymmetric Traveling Salesman Problem where the costmatrix satisfies the triangle inequality condition. Let Φ be the identity function, and leta1 < 0. Suppose there exists a constant ε, 0 < ε < 1, such that cost(I, J ) (cid:1) N ε · cost(J, I )for 1 (cid:1) I, J (cid:1) N, I (cid:16)= J . Then E(Zd ) is exponential in N for large N .A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206197Proof. See Appendix A. ✷It is possible to relax the constraints even further. The cost matrix does not need tosatisfy the triangle inequality condition in a strict way. We will say that the triangleinequality condition holds α-weakly if the cost matrix satisfies the following conditionfor some real number α > 1:(cid:7)(cid:8)α ·cost(I, J ) + cost(J, K)(cid:2) cost(I, K)for all triples I, J, K where 1 (cid:1) I, J, K (cid:1) N . Theorem 5.1 remains valid when thetriangle inequality condition holds α-weakly provided α = o(N ε) for some ε < 1. Similarconditions can be derived for Theorems 5.2 and 5.3.In a Traveling Salesman Problem, all pairs of cities may not always be connecteddirectly by arcs, i.e., cost(I, J ) can sometimes be infinite. In such cases, the matrix entriesmay fail to satisfy the triangle inequality condition as defined above. But even then, aversion of Theorem 5.1 holds, provided the following technical condition is satisfied: Thereis a subsequence of cities 1, 2, . . . , N ε + 1 lying on a minimum cost tour, where 0 < ε < 1,such that the cost of the portion of the minimum cost tour lying within the subsequenceis < N ε, and the cost matrix restricted to the cities in the subsequence is symmetric andsatisfies the triangle inequality.What can be said when the normalizing function Φ(x) is logarithmic in x? Unfortu-nately, it seems that nothing very definite can be said in such a case, as the followingexamples show. The expected number of node expansions can be linear to exponential inN depending on the cost matrix.Example 5.1. Suppose cost(I, J ) = 1 for all I, J, 1 (cid:1) I, J (cid:1) N, I (cid:16)= J .This cost matrix is symmetric and satisfies the triangle inequality. Let a1 < 0, i.e., supposethat the heuristic estimates of nodes have a nonzero probability of being admissible. Then,for any nongoal node n, f (n) < N with probability p > 0, so that E(Zd ) = E(Zt ) (cid:2) 1 +p · C(N − 1, 1) + 2 · p2 · C(N − 1, 2) + · · ·+ (N − 1) · pN−1 = 1 + p · (N − 1) · (1 + p)N−2,which is exponential in N for large N . This holds even when the normalizing function islogarithmic.When the heuristic is perfect, E(Zt ) can be linear to exponential in N depending on howties are resolved. However, there are cases of polynomial complexity for certain restrictivetypes of cost matrix as described below.5.2. Polynomial and nonexponential complexityWe now try to determine what kind of restriction must be placed on the cost function toachieve polynomial complexity when the error is logarithmic.Theorem 5.4. Consider a symmetric N -city Traveling Salesman Problem having thefollowing cost matrix:(cid:2)cost(I, J ) =a when |I − J | = 1 or (I = 1 and J = N) or (J = 1 and I = N),a + b · ln N otherwise,198A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206where a and b are constants > 0. Suppose Φ(x) is logarithmic in x. Then the expectednumber of node expansions E(Zt ) is polynomial in N for large N .Proof. See Appendix A. ✷The conditions in Theorem 5.4 are very restrictive. When two cities I and J are adjacentin the city numbering scheme, then cost(I, J ) is a constant; otherwise, the cost increaseslogarithmically with N . One way to relax the conditions is as given below, but in that casethe result we get is weaker:Theorem 5.5. Consider a symmetric N -city Traveling Salesman Problem having thefollowing cost matrix:(cid:2)cost(I, J ) =a when |I − J | = 1 or (I = 1 and J = N) or (J = 1 and I = N),a + botherwise,where a and b are constants a > b > 0. Suppose Φ(x) is logarithmic in x. Then theexpected number of node expansions E(Zt ) is not exponential in N for large N .Proof. See Appendix A. ✷A similar result is obtained if cost(I, J ) varies with |I − J | at a rate that is no more thanlinear.Theorem 5.6. Let Ψ (z) = a +b ·zr , 0 < b < a and 0 < r (cid:1) 1. Consider a symmetric N -cityTraveling Salesman Problem where for every city I, 1 (cid:1) I (cid:1) N , cost(I, J ) = Ψ (K − 1) ifJ ≡ (I − 1 ± K) mod N + 1, K being a positive integer. Suppose Φ is logarithmic in x.Then the total number of node expansions E(Zt ) is not exponential in N for large N .Proof. See Appendix A. ✷The results in this section show that the expected complexity of the A∗ algorithm forthe TSP can be polynomial to exponential in the number of cities, depending on the costfunction and the accuracy of the heuristic function. Since A∗ on graphs can be viewed as aspecial type of best-first branch-and-bound algorithm, our results here shed some light onthe expected complexity of best-first branch-and-bound algorithms for the TSP.6. ConclusionThis paper has presented a general technique for extending the analysis of the average-case performance of A∗ from search spaces that are trees to search spaces that aredirected acyclic graphs. The topic has importance because many practical problems canbe solved more efficiently using search spaces that are graphs rather than trees. We havederived expressions for the expected number of nodes generated by A∗ and the expectednumber of node expansions made by A∗ when it is run on two general types of directedA.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206199acyclic graphs. Such search graphs are typical of those that arise in certain types of one-machine job sequencing problems. Similar graphs also arise in some solution proceduresfor the Traveling Salesman Problem (TSP). Our analytical results show that the expectedcomplexity of problems in these two domains can change from exponential to polynomialas the heuristic estimates of nodes become more accurate and restrictions are placed on thecost matrix. We have provided supporting experimental evidence for the one-machine jobsequencing problem.We expect that the analytical approach proposed here can be generalized and extendedin a number of directions. One possible way this can be done is by making use of theincremental random tree model described in [14,20,21,31]. Experimentally, we can tryto compare the expected number of nodes generated and/or expanded by graph searchand tree search on different types of problems. This will tell us how much saving can berealized in computational cost in practice by the use of a search space that is a directedacyclic graph, and can thereby help us to choose between graph and tree search spaceswhen implementing search algorithms in different application domains.AcknowledgementsAnup K. Sen was funded by CMDS grant AIT/2117 by the Indian Institute ofManagement Calcutta. W. Zhang was funded in part by NSF grants IIS-0196057 andITR/EIA-0113618, and in part by DARPA Cooperative Agreements F30602-00-2-0531and F33615-01-C-1897. Thanks to the anonymous reviewers for constructive comments.Appendix A. ProofsTheorem 4.1. Suppose that for 1 (cid:1) i (cid:1) N , Hi(x) is o(xβ) where β is a positive integerconstant, and 1 (cid:1) Ai (cid:1) k for some constant k > 1. If Φ is the identity function and a1 < 0,then E(Zd ), the expected number of distinct nodes of Gjs that get expanded, is exponentialin N for large N .Proof. The basic idea here is to take an initial segment of a minimal cost solution pathin Gjs, and consider the set S of jobs that get processed in this segment. Each subset of Scorresponds to a node in Gjs. The length of the segment is so chosen that the number ofelements in S is a fractional power of N , so that the number of subsets of S is exponentialin N . We then show that every such node gets expanded with nonzero probability, anddeduce that the expected number of nodes that get expanded is exponential in N .We renumber jobs if needed and assume that there is a minimal cost solution path in Gof cost M (cid:2) N , such that if we move along it from root to goal, jobs get scheduled fromthe set {1, 2, . . . , N} in the sequence (1 2 . . . N). Choose 0 < δ < 1/(β + 1), and considerthe nongoal nodes in Gjs for which all the missing jobs, corresponding to the jobs alreadycompleted, belong to the set {1, 2, . . . , V }, where V = N δ . There are 2V − 1 such nodesexcluding the root, and for any such node n,g(n) < V · (V · k)βand h∗(n) > M − V · (V · k)β .200A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206Let n(cid:9) be the node for which the missing elements are exactly 1, 2, . . . , V . Since n(cid:9)lies on a minimum cost solution path, we get h∗(n(cid:9)) < M. Moreover, the cost of thepath to n(cid:9) from any predecessor n of n(cid:9) cannot exceed V · (V · k)β . It follows thatM − V · (V · k)β < h∗(n) < M + V · (V · k)β . Let a(cid:9) = a1/2 < 0, so that p = Fχ (a(cid:9)) > 0.Then h(n) (cid:1) h∗(n) + a(cid:9) · Φ(h∗(n)) with probability p, so that f (n) < M with probabilityp, provided g(n) + h∗(n) < M − a(cid:9) · Φ(h∗(n)). As a(cid:9) < 0 and Φ is the identity function, itsuffices to show M + 2 · V · (V · k)β < M − a(cid:9) · M + a(cid:9) · V · (V · k)β , which always holds forlarge N because V β+1 is of smaller order than N , and hence of M. The above conditionsare true for n(cid:9) or any ancestor of n(cid:9). Thus if node n is at level i, it gets expanded withprobability at least pi . Therefore, E(Zd ) (cid:2) 1 + p · V + p2 · C(V , 2) + · · · + pV = (1 + p)Vwhich is exponential in N for large N . ✷Theorem 4.2. Let θ (y) = yβ for y > 0, where 0 < β (cid:1) 1, and let (Gjs, C) be super-regular with respect to θ . If Φ(x) = max{1, xδ} for 0 < δ (cid:1) 1, and a1 < 0, then E(Zd )is exponential in N for large N .Proof. Here we make use of the fact that in a super-regular graph there are many outgoingarcs at a node with arc costs lying within a given bound. Since θ (1) = 1 and (Gjs, C)is super-regular, it follows that each nongoal node in Gjs has at least one outgoing arcof unit cost. So there is a minimal cost solution path in Gjs of cost N . Let n be anode at level i. Then h∗(n) = N − i. Let a1 < a(cid:9) < 0, so that p = Fχ (a(cid:9)) > 0. Thenf (n) < N with probability p if g(n) + h∗(n) < N + |a(cid:9)| · Φ(h∗(n)), i.e., if g(n) <i + |a(cid:9)| · (N − i)δ. Let us confine our attention to those outgoing arcs having costs (cid:2) 1 and< k = 1 + |a(cid:9)| · ((N − i)δ − 1)/i. All paths from the root to node n composed of such arcswill have their g(n) values within the specified limit. Let P be such a path, and let m be apredecessor of n at level i(cid:9) < i. Then g(m) < i(cid:9) + i(cid:9) · |a(cid:9)| · (N − i)δ/i (cid:1) i(cid:9) + |a(cid:9)| · (N − i(cid:9))δ,so g(m) satisfies a similar condition. Thus node n will be expanded with probability (cid:2) pi .We will choose i = N ρ , where 0 < ρ < δ · β/(β + 1). Since there are i! paths fromthe root to a node at level i, there are at least (cid:13)[θ (k)]i/i!(cid:14) nodes with g-value less than(cid:1)N ρi + |a(cid:9)| · (N − i)δ at level i. Hence E(Zd ) (cid:2)j =0 pj (cid:13)[θ (k)]j /j !(cid:14). But the right-hand sumis no smaller than exp(N ρ ) which is exponential in N for large N . ✷Theorem 4.3. Let θ (y) = yβ for y > 0, where 0 < β (cid:1) 1, and let (Gjs, C) be θ -restrictedand C-ordered. If Φ is logarithmic, then E(Zt ) is polynomial in N for large N .Proof. We first find the total number of nodes n for which g∗(n) + h(n) (cid:1) f ∗(r) + |a2| ·ln(f ∗(r)); these include all the nodes that can possibly get expanded. But it is alwaysthe case that h(n) (cid:2) h∗(n) − |a1| · ln(h∗(n)). Suppose node n is at level i. Then, sinceevery nongoal node has an outgoing arc of unit cost, we must have f ∗(r) = N andh∗(n) = N − i. So the condition becomes g∗(n) < i + k0 · ln(k · N) where k and k0 arepositive constants. Since Gjs is θ -restricted, outgoing arcs at a node have costs boundedbelow by 1, (cid:13)21/β(cid:14), (cid:13)31/β(cid:14), . . . , where β (cid:1) 1, so that 1/β (cid:2) 1, implying (cid:13)21/β(cid:14) (cid:2) 2,(cid:13)31/β(cid:14) (cid:2) 3, and so on. In computing upper bounds on the number of expanded nodes,these lower bounds can be viewed as the exact costs of the outgoing arcs. We can now findhow many nodes at level i have g∗-values summing up to (cid:1) i + k0 · ln(k · N).A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206201Since Gjs is C-ordered, consider the subset of jobs already processed at a node n atlevel i. Let J1, J2, . . . , Ji be the jobs in the subset which are in SN but are missing fromnode n. Suppose J1 < J2 < · · · < Ji . There are i! ways of scheduling the i jobs leading toi! paths to node n from the root. The scheduling of the jobs in the sequence J1, J2, . . . , Jiwill determine the path of least cost from the root to node n. Moreover, the completiontimes of these jobs will be in increasing order. Gjs being C-ordered, the arc costs in thispath will form an increasing ordered sequence of integers, because jobs are processed inincreasing order of job number and a penalty function is nondecreasing in its argument. Theordered sequences of arc costs corresponding to the minimal cost paths to two differentnodes at level i cannot be identical. Thus we need to count the number of increasinginteger sequences of length i which sum up to at most i + k0 · ln(k · N). To get an upperbound on the number of such sequences, we take help of the Hardy–Ramanujan asymptoticformula [1, pp. 70, 97] for the number of (unrestricted) partitions of an integer q, whichhas the form (A/q) · exp(B · q 1/2), where A and B are constants. The number of partitionsso obtained is polynomial in N . We need to determine the total number of partitions of allintegers (cid:1) q, and this number is also polynomial in N . As explained above, our interest isconfined to only those partitions that have i − 1 or i parts, where the parts are in increasingorder of values. This shows that only a polynomial number of nodes get expanded at eachlevel i, 1 (cid:1) i (cid:1) N . Although each node n can get expanded multiple times, g(n) is aninteger and can take at most N + |a2| · ln N distinct values, so no node gets expanded morethan N + |a2| · ln N times. It follows that E(Zt ) is polynomial in N for large N . ✷Theorem 4.4. Let y0 be a given positive integer independent of N . Let β > 0 be an integerconstant. Supposeθ (y) =(cid:6)yβyβ0for y (cid:1) y0,for y > y0.Let (Gjs, C) be θ -restricted and C-ordered. Then regardless of whether Φ is linear, less-than-linear or logarithmic, E(Zt ) is polynomial in N for large N .Proof. Let k0 = yβ0 . Then k0 is a constant. Every node at level i for 1 (cid:1) i (cid:1) N , has at mostmin(k0, N − i) outgoing arcs with arc costs (cid:1) y for any y (cid:2) y0 and these are the leftmostarcs at that node. Other outgoing arcs can be viewed as having infinite cost. Because ofthe C-ordering, the jobs that get processed in moving from level 0 to level 1 all have jobnumbers (cid:1) k0; the jobs that get processed in moving from level 1 to level 2 all have jobnumbers (cid:1) k0 + 1; and so on. Thus the number of nodes at level i with finite g∗-value is(cid:1) C(k0 +i −1, i). So the total number of nodes in the graph with finite g∗-value is less than(cid:1)Ni=1 C(k0 + i − 1, i) + 1 (cid:1) C(k0 + N, N) which is polynomial in N for large N . A node ncan get expanded only if g(n) (cid:1) f ∗(r) · (1 + |a2|) = N · (1 + |a2|). As in Theorem 4.3, g(n)is an integer and can take at most N · (1 + |a2|) distinct values, so no node gets expandedmore than N · (1 + |a2|) times. It follows that E(Zt ) is polynomial in N as well. ✷202A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206Theorem 4.5. Let y0 be a given positive integer independent of N . Let β > 0 be a constant.Suppose(cid:2)yβfor y < y0,N for y (cid:2) y0.θ (y) =Then,(1) If (Gjs, C) is super-regular with respect to θ , Φ(x) = max{1, xδ} for 0 < δ (cid:1) 1, anda1 < 0, E(Zd ) is exponential in N for large N ;(2) If (Gjs, C) is sub-regular with respect to θ , Gjs is C-ordered and Φ is logarithmic,E(Zt ) is polynomial in N for large N .Proof. (1) Follows from the proof of Theorem 4.2, since at every nongoal node in thegraph, all outgoing arcs have cost (cid:1) y0.(2) Here, since the graph is θ -restricted, at any nongoal node at level i, at mostmin(N − i, θ (y)) arcs have cost (cid:1) y for y < y0, and at most N − i arcs have cost (cid:1) yfor y (cid:2) y0. Since the graph is also C-ordered, and since the costs of the outgoing arcs areintegers, these must be in increasing order of values from left to right, so at any nongoalnode there can be at most y outgoing arcs of cost (cid:1) y. Thus, for y (cid:2) y0, (Gjs, C) is θ -restricted with θ (y) = y. It does not make sense to take β > 1 in this case. We now relaxthe given conditions and assume that θ (y) = y for all y, since this can only increase theexpected number of nodes that get expanded. We put β = 1 and the proof of Theorem 4.3applies. ✷Theorem 5.1. Consider a symmetric N -city Traveling Salesman Problem where the costmatrix satisfies the triangle inequality. Let Φ be the identity function, and suppose a1 < 0.Then E(Zd) is exponential in N for large N .Proof. Let M be the cost of a minimum cost tour. Without loss of generality, renumber thecities (if necessary) so that 1 2 . . . N 1 is a minimum cost tour, and there is a subsequenceof cities 1 2 . . . N β N β + 1 for some β, 0 < β < 1, such that the cost of the portion of thetour from city 1 to city N β + 1 is (cid:1) N β · (M/N). Let k (cid:2) 2 be an integer, and consider alevel i = N β /k in Gtsp. Let S be the set of nodes at level i with current city N β + 1 andall other visited cities belonging to the set {1, 2, . . . , N β }. Then a node n in S correspondsto a situation where apart from city 1, (N β /k) − 1 cities have been visited out of thecities numbered 2 . . . N β . The number of nodes in S is C(N β − 1, (N β /k) − 1), which isexponential in N for large N .Since 0 > a1 (cid:2) −1, we have a(cid:9) = a1/2 < 0. Then a(cid:9) > a1, so that p = Fχ (a(cid:9)) > 0.We will show that each node n in S will enter OPEN and satisfy g∗(n) + h(n) < M withprobability pi . We will also show that a similar condition will hold for every predecessorof n. Since the minimum cost tour has cost M, this implies that each node n in S will beexpanded with probability pi . For a node n in S we must have h∗(n) (cid:1) (cost of travelingfrom city N β + 1 to an unvisited city of lowest number) + (cost of visiting all unvisitedcities with numbers in the set {2, 3, . . . , N β } in increasing order of city number) + (costof visiting the remaining cities in the tour and returning to city 1). Since the cost matrixA.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206203is symmetric and satisfies the triangle inequality, each of the first and second terms is(cid:1) N β · (M/N), and the third term is less than M, so thath∗(n) < M + 2 · N β · (M/N).But,∗g(n) (cid:1) N β · (M/N)by the triangle inequality.Hence,g∗(n) + h∗(n) < M · (1 + 3 · N β /N).On the other hand,∗h(n) (cid:2) M − g∗(n) (cid:2) M(1 − N β /N).Thus,g∗(n) + h(n) (cid:1) g∗(n) + h∗(n) + a(cid:9) · h∗(n) with probability p,< M + a(cid:9) · M + (3 − a(cid:9)) · M · N β /Nwith probability p, since a(cid:9) < 0,< M with probability p, the third term being ignored since it haslow order compared to −a(cid:9) · M.For a predecessor n(cid:9) of n at a level smaller than i in Gtsp, h∗(n) has the same bounds,since the arguments remain valid when the current city, instead of being N β + 1, is somecity in {2, 3, . . . , N β }. The bound remains the same for g∗(n(cid:9)) as well, so we still haveg∗(n(cid:9)) + h∗(n(cid:9)) < M with probability at least p. We conclude therefore that each nodein S at level i, gets expanded with probability at least pi , so that the expected number ofdistinct nodes expanded at level i is at least pi · C(N β − 1, (N β /k) − 1), which for thegiven value of i is easily shown with the help of Stirling’s approximation to be exponentialin N for large N if k is chosen to be greater than 1/p. ✷Theorem 5.2. Consider a symmetric N -city Traveling Salesman Problem where the costmatrix satisfies the triangle inequality condition. Let Φ(x) = max{1, xδ} for some δ,0 < δ < 1, and let a1 < 0. Then E(Zd ) is exponential in N for large N whenever thecost of the minimum cost solution path is O(N).Proof. Similar to the proof of Theorem 5.1. Here we have∗g(n) + h(n) < M + 3 · M · N β /N + a(cid:9) · M δ · (1 − N β /N)δ with probability pwhere M is O(N). The parameter β can be chosen as small as we like, and in particularsmaller than δ, so that for the given condition on M, the second term can be ignored withrespect to the third term, giving g∗(n) < M. Indeed, a weaker condition on M suffices; itcan be shown that the theorem holds if M is o(N ε) for some ε < (1 − β)/(1 − δ). ✷204A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206Theorem 5.3. Consider an N -city asymmetric Traveling Salesman Problem where the costmatrix satisfies the triangle inequality condition. Let Φ be the identity function, and leta1 < 0. Suppose there exists a constant ε, 0 < ε < 1, such that cost(I, J ) (cid:1) N ε · cost(J, I )for 1 (cid:1) I, J (cid:1) N, I (cid:16)= J . Then E(Zd ) is exponential in N for large N .Proof. Similar to the proof of Theorem 5.1. Here we have∗h(n) < M · (1 + N β /N + N β+ε/N);and the other inequalities remaining the same, so that, with probability p∗g(n) + h(n) < M · (1 + 2 · N β /N + N β+ε/N) + aThe theorem holds provided we choose β so that β + ε < 1. ✷(cid:9) · M · (1 − N β /N).Theorem 5.4. Consider a symmetric N -city Traveling Salesman Problem having thefollowing cost matrix:a(cid:6)when |I − J | = 1 or (I = 1 and J = N)or (J = 1 and I = N),cost(I, J ) =a + b · ln N otherwise,where a and b are constants > 0. Suppose Φ(x) is logarithmic in x. Then the expectednumber of node expansions E(Zt ) is polynomial in N for large N .Proof. Here the cost matrix is symmetric, but the triangle inequality condition is notsatisfied. We first find an upper bound on the expected number E(Zd ) of distinct nodeexpansions. The cost of going from a city to the city just before or just after it in thenumbering scheme is a constant amount, so f ∗(r) = a · N . A node n at level i canonly get expanded if g∗(n) + h(n) (cid:1) a · N + |a2| · ln(a · N), i.e., if g∗(n) + h∗(n) (cid:1)a · N + |a2| · ln(a · N) + |a1| ln(h∗(n)). Since h∗(n) (cid:2) (N − i) · a, the required condition fornode expansion can be written as g∗(n) < a ·i +a(cid:9) ·ln N +b(cid:9), where a(cid:9) and b(cid:9) are constants.To find an upper bound on E(Zd ), we have to count all nodes n at each level i havingg∗(n) < a · i + a(cid:9) · ln N + b(cid:9). Consider a path starting at the root along which nodes areexpanded, and examine the order in which cities have been visited and reached. There mustexist a positive constant q independent of i such that successive cities have numbers thatare adjacent in the city numbering scheme except at a maximum of q positions; otherwisethe required condition on the g∗-value cannot be satisfied. Whenever successive cities arenot adjacent, there are at most N possible choices for the next city. Therefore the totalnumber of distinct paths from the root to nodes at level i along which node expansions areqj =0 N j · C(i, j ) < (q + 1) · N q · C(i, q) for large i, and the total number ofpossible is <i=0 C(i, q) < (q +1)·N q+1 ·C(N, q).Nexpansions of nodes in the graph is < (q +1)·N q ·This is polynomial in N since q is a constant. ✷(cid:1)(cid:1)Theorem 5.5. Consider a symmetric N -city Traveling Salesman Problem having thefollowing cost matrix:a(cid:6)cost(I, J ) =when |I − J | = 1 or (I = 1 and J = N)or (J = 1 and I = N),otherwise,a + bA.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206205where a and b are constants a > b > 0. Suppose Φ(x) is logarithmic in x. Then theexpected number of node expansions E(Zt ) is not exponential in N for large N .Proof. We proceed as in the proof of Theorem 5.4. Here the cost matrix is symmetricand also satisfies the triangle inequality condition. For an expanded node n at level i, theupper bound on g∗(n) is the same as in Theorem 5.4. As before, consider a path starting atthe root along which nodes are expanded, and examine the order in which cities have beenvisited and reached. This time there can be at most O(ln N) positions where two successivecities are not adjacent in the city numbering scheme. Thus the expected number E(Zt ) ofnode expansions will be bounded above by an expression of the form N ln N+1 · C(N, ln N).This bound is not polynomial in N , but nor is it exponential in N . ✷Theorem 5.6. Let Ψ (z) = a +b ·zr , 0 < b < a and 0 < r (cid:1) 1. Consider a symmetric N -cityTraveling Salesman Problem where for every city I , 1 (cid:1) I (cid:1) N , cost(I, J ) = Ψ (K − 1) ifJ ≡ (I − 1 ± K) mod N + 1, K being a positive integer. Suppose Φ is logarithmic in x.Then the total number of node expansions E(Zt ) is not exponential in N for large N .Proof. We proceed as in the proof of Theorem 5.4. Here the cost matrix is symmetric andsatisfies the triangle inequality condition. For an expanded node n at level i, the upperbound on g∗(n) is the same as in Theorem 5.4. This time, if we take an expanded node andexamine the set of visited cities (to which the current city has also been added), there mustexist a positive global constant w such that if this set of cities is arranged in increasing orderof city number, there can be at most w places where the gap between two successive citiesis proportional to ln N . But in addition, there will exist another positive global constant usuch that at no more than O(ln N) places, the gap between successive cities will be > 1 but(cid:1) u. The gap between successive cities can take any value between a constant and ln N ,so long as the sum of all the gaps is O(ln N). Thus to get an upper bound on the numberof tours along which nodes can get expanded, we can suppose that there are O(ln N) gapseach of which can take O(ln N) different values. Thus E(Zt ) will be bounded above by anexpression of the form N · (ln N)ln N · C(N, ln N). This bound is not polynomial in N , butnor is it exponential in N . ✷References[1] G.E. Andrews, The Theory of Partitions, in: G.G. Rota (Ed.), Encyclopedia of Mathematics and ItsApplications, vol. 2, Addison–Wesley, Reading, MA, 1976.[2] A. Bagchi, A.K. Sen, Average case analysis of heuristic search in tree-like networks, in: Search in ArtificialIntelligence, Springer-Verlag, Berlin/New York, 1988, pp. 131–165.[3] E. Balas, P. Toth, Branch and bound methods, in: The Traveling Salesman Problem, Wiley, Essex, UK, 1985,pp. 361–401.[4] M. Bellmore, J.C. Malone, Pathology of traveling-salesman subtour-elimination algorithms, OperationsResearch 19 (1971) 278–307.[5] H. Carrillo, D. Lipman, The multiple sequence alignment problem in biology, SIAM J. Appl. Math. 48(1988) 1073–1082.[6] S.V. Chenoweth, H.W. Davis, High performance A91, Sydney, Australia, 1991, pp. 198–203.∗search using rapidly growing heuristics, in: Proc. IJCAI-206A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206[7] H.W. Davis, Cost error relationships in Atree searching, J. ACM 37 (1990) 195–199.∗[8] R. Dechter, J. Pearl, Generalized best-first search strategies and the optimality of A∗, J. ACM 32 (1985)505–536.[9] G. Gutin, A.P. Punnen (Eds.), The Traveling Salesman Problem and Its Variations, Kluwer Academic,Dordrecht/Norwell, MA, 2002.[10] M. Held, R.M. Karp, The traveling salesman problem and minimum spanning trees: Part II, MathematicalProgramming 1 (1971) 6–25.[11] N. Huyn, R. Dechter, J. Pearl, Probabilistic analysis of the complexity of A∗, Artificial Intelligence 15(1980) 241–254.∗[12] T. Ikeda, H. Imai, Enhanced Aalgorithms for multiple alignments: Optimal alignments for severalsequences and k-opt approximate alignments for large cases, Theoretical Computer Science 210 (1999)341–374.[13] H. Kaindl, G. Kainz, A. Leeb, H. Smetana, How to use limited memory in heuristic search, in: Proc. IJCAI-95, Montreal, Quebec, 1995, pp. 236–242.[14] R.M. Karp, J. Pearl, Searching for an optimal path in a tree with random costs, Artificial Intelligence 21(1983) 99–117.[15] R.M. Karp, J.M. Steele, Probabilistic analysis of heuristics, in: The Traveling Salesman Problem, Wiley,Essex, UK, 1985, pp. 181–205.[16] R.E. Korf, M. Reid, S. Edelkamp, Time complexity of iterative-deepening-A∗, Artificial Intelligence 129(2001) 199–218.[17] R.E. Korf, W. Zhang, Divide-and-conquer frontier search applied to optimal sequence alignment, in: Proc.AAAI-00, Austin, TX, 2000, pp. 910–916.[18] E.L. Lawler, J.K. Lenstra, A.H.G. Rinnooy Kan, D.B. Shmoys (Eds.), The Traveling Salesman Problem,Wiley, Essex, UK, 1985.[19] J.K. Lenstra, A.H.G. Rinnooy Kan, On the expected performance of branch-and-bound algorithms,Operations Research 26 (1978) 347–349.[20] C.J.H. McDiarmid, Probabilistic analysis of tree search, in: G.R. Gummett, D.J.A. Welsh (Eds.), Disorderin Physical Systems, Oxford Science, 1990, pp. 249–260.[21] C.J.H. McDiarmid, G.M.A. Provan, An expected-cost analysis of backtracking and non-backtrackingalgorithms, in: Proc. IJCAI-91, Sydney, Australia, 1991, pp. 172–177.[22] J. Pearl, Heuristics: Intelligent Search Strategies for Computer Problem Solving, Addison–Wesley, Reading,MA, 1984.[23] M. Pinedo, Scheduling: Theory, Algorithms and Systems, Prentice Hall, New York, 1995.[24] A. Reinefeld, T.A. Marsland, Enhanced iterative deepening search, IEEE Trans. Pattern Analysis andMachine Intelligence 16 (1994) 701–710.[25] T. Sandholm, Algorithm for optimal winner determination in combinatorial auctions, Artificial Intelli-gence 135 (2002) 1–54.[26] A.K. Sen, A. Bagchi, Graph search methods for non-order-preserving evaluation functions: Applications tojob sequencing problems, Artificial Intelligence 86 (1996) 43–73.[27] A.K. Sen, A. Bagchi, R. Ramaswamy, Searching graphs with A∗Trans. Syst. Man Cybern. A 26 (1996) 168–173.: Applications to job sequencing, IEEE[28] A.K. Sen, A. Bagchi, W. Zhang, An average-case analysis of graph search, in: Proc. AAAI-02, Edmonton,Alberta, 2002, pp. 757–762.[29] W. Townsend, The single machine problem with quadratic penalty function of completion times: A branchand bound solution, Management Science 24 (1978) 530–534.[30] W. Zhang, Depth-first branch-and-bound versus local search: A case study, in: Proc. AAAI-00, Austin, TX,2000, pp. 930–936.[31] W. Zhang, R.E. Korf, Performance of linear-space search algorithms, Artificial Intelligence 79 (1995) 241–292.