Artificial Intelligence 171 (2007) 42–71www.elsevier.com/locate/artintAudiences in argumentation frameworksTrevor J.M. Bench-Capon, Sylvie Doutre, Paul E. Dunne ∗Department of Computer Science, University of Liverpool, Liverpool L69 7ZF, UKReceived 11 October 2006; received in revised form 16 October 2006; accepted 17 October 2006Available online 20 November 2006AbstractAlthough reasoning about what is the case has been the historic focus of logic, reasoning about what should be done is an equallyimportant capacity for an intelligent agent. Reasoning about what to do in a given situation—termed practical reasoning in thephilosophical literature—has important differences from reasoning about what is the case. The acceptability of an argument for anaction turns not only on what is true in the situation, but also on the values and aspirations of the agent to whom the argument isdirected. There are three distinctive features of practical reasoning: first, that practical reasoning is situated in a context, directedtowards a particular agent at a particular time; second, that since agents differ in their aspirations there is no right answer for allagents, and rational disagreement is always possible; third, that since no agent can specify the relative priority of its aspirationsoutside of a particular context, such prioritisation must be a product of practical reasoning and cannot be used as an input to it.In this paper we present a framework for practical reasoning which accommodates these three distinctive features. We use thenotion of argumentation frameworks to capture the first feature. An extended form of argumentation framework in which valuesand aspirations can be represented is used to allow divergent opinions for different audiences, and complexity results relating to theextended framework are presented. We address the third feature using a formal description of a dialogue from which preferencesover values emerge. Soundness and completeness results for these dialogues are given.© 2006 Elsevier B.V. All rights reserved.Keywords: Argumentation frameworks; Practical reasoning; Dialogue1. IntroductionReasoning about what should be done in a particular situation—termed practical reasoning in the philosophicalliterature—is carried out through a process of argumentation. Argumentation is essential because no completely com-pelling answer can be given: whereas in matters of belief, we at least should be constrained by what is actually thecase, in matters of action no such constraints apply—we can choose what we will attempt to make the case. Even anorm as universal and deep seated as thou shalt not kill is acknowledged to permit of exceptions in circumstances ofself defence and war. Thus whether arguments justifying or urging a course of action are acceptable will depend onthe aspirations and values of the agent to which they are addressed: the audience for the argument. The importance ofthe audience for arguments was recognised and advocated by Perelman [28].* Corresponding author.E-mail address: ped@csc.liv.ac.uk (P.E. Dunne).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.10.013T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7143Arguments in practical reasoning provide presumptive reasons for performing an action. These presumptive argu-ments are then subject to a process of challenge, called critical questioning in [31]. These critical questions may takethe form of other arguments, which can in turn be challenged, or may be answered by further arguments, resultingin a set of arguments constructed as the debate develops. An extension of Walton’s account of practical reasoning isgiven in [2,6], which proposes an elaborated argument scheme for practical reasoning, which incorporates the valuepromoted by acceptance of the argument, and identifies all the ways in which it can be challenged. Although mostof our discussion will treat arguments at a very abstract level, where we have need of a more particular structure forarguments, we will have this account in mind.In this paper we will propose and explore a framework for the representation and evaluation of arguments in prac-tical reasoning. Any such framework must account for some important phenomena associated with such reasoning.We will review these features in this section, and will structure the development of our framework in the remainder ofthis paper around them.First, as is clear from the brief sketch of practical reasoning above, arguments cannot be considered in isolation.Whether an argument is acceptable or not depends on whether it can withstand or counter the other arguments putforward in the debate. Once the relevant arguments have been identified, whether a given argument is acceptable willdepend on its belonging to a coherent subset of the arguments put forward which is able to defend itself against allattackers. We will call such a coherent subset a position. This notion of the acceptability of an argument deriving frommembership of a defensible position has been explored in AI through the use of argumentation frameworks [9,19],and our account will be based on a framework of this sort. Dung’s framework [19] will be recapitulated in Section 2,and then extended as the paper proceeds. The reasoning involved in constructing argumentation frameworks andidentifying positions within them is naturally modelled as a dialogue between a proponent and a critic. Dialogues forthis purpose have been proposed in [8,13,22], and we will make use of the way of exploring argument frameworks.Dialogues are discussed in Section 5.A second important feature of practical reasoning is that rational disagreement is possible, the acceptability ofan argument depending in part on the audience to which it is addressed. Within Dung’s framework it is possiblefor disagreement to be represented since argumentation frameworks may contain multiple incompatible defensiblepositions. The abstract nature of arguments, however, means that there is no information that can be used to motivatethe choice of one option over another. Searle states the need to recognise that disagreement in practical reasoningcannot be eliminated as follows [29]:Assume universally valid and accepted standards of rationality, assume perfectly rational agents operating withperfect information, and you will find that rational disagreement will still occur; because, for example, the rationalagents are likely to have different and inconsistent values and interests, each of which may be rationally acceptable.What distinguishes different audiences are their values and interests, and in order to relate the positions acceptableto a given audience to the values and interests of that audience we need a way of relating arguments to such valuesand interests. Hunter [25] makes a proposal in terms of what he calls resonance, but we will build on Value BasedArgumentation Frameworks (VAFs) proposed in [9], in which every argument is explicitly associated with a valuepromoted by its acceptance, and audiences are characterised by the relative ranking they give to these values. Wewill describe VAFs in Section 3, their properties in Section 4, and discuss the relationship between our proposal andHunter’s in Section 7.The above machinery can allow us to explain disagreement in terms of differences in the rankings of values betweendifferent audiences, but it does not allow us to explain these rankings. This brings us to the third feature of practicalreasoning for which we wish to account—that we cannot assume that the parties to a debate will come with a clearranking of values: rather these rankings appear to emerge during the course of the debate. We may quote Searle again:This answer [that we can rank values in advance] while acceptable as far as it goes [as an ex post explanation],mistakenly implies that the preferences are given prior to practical reasoning, whereas, it seems to me, they aretypically the product of practical reasoning. And since ordered preferences are typically products of practicalreason, they cannot be treated as its universal presupposition. [29]44T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71The question of how value orders emerge during debate is explored in Section 6, in which we define a dialogueprocess for evaluating the status of arguments in a VAF, and in which we show how this process can be used toconstruct positions. In the course of constructing a position, the ordering of values will be determined.Although it is not reasonable to assume that participants in a debate come with a firm value order, and so we wishto account for the emergence of such an order, neither do participants usually come to an debate with a completelyopen mind. Usually there will be some actions they are predisposed to perform, and others which they are reluctantto perform, and they will have a tendency to prefer arguments which match these predispositions. For example apolitician forming a political programme may recognise that raising taxation is electorally inexpedient and so mustexclude any arguments with the conclusion that taxes should be raised from the manifesto, while ensuring that argu-ments justifying actions bringing about core objectives are present: other arguments are acceptable in so far as theyenable this. This kind of initial intuitive response to arguments will be used to drive the construction of positions andformation of a value order. A similar technique for constructing positions on the basis of Dung’s framework has beenproposed in [11]. Because this treatment does not make use of values, however, it cannot use these reasons for actionto motivate choices, and there is no relation between the arguments which can be exploited to demand that choicesare made in a consistent and coherent manner. Our extensions to include values enable us to impose this requirementof moral consistency on the reasoners.Our overall aim is to provide a framework for modelling practical reasoning, which is based on sets of argumentstogether with information as to the other arguments they attack, and the values promoted by their acceptance. Ourframework will account for three key features of practical reasoning: that evaluation of arguments is always in thecontext of a debate; that there is always potential for disagreement, explicable in terms of the different interests andvalues of the audiences; and that values are ordered in the course of the debate.2. Dung’s argumentation frameworksWe recall the following basic concepts that were introduced in Dung [19].Definition 1. An argument system is a pair H = (cid:3)X , A(cid:4), in which X is a finite set of arguments and A ⊂ X × X isthe attack relationship for H. A pair (cid:3)x, y(cid:4) ∈ A is referred to as ‘y is attacked by x’ or ‘x attacks y’. For R, S subsetsof arguments in the system H((cid:3)X , A(cid:4)), we say that(a) s ∈ S is attacked by R if there is some r ∈ R such that (cid:3)r, s(cid:4) ∈ A.(b) x ∈ X is acceptable with respect to S if for every y ∈ X that attacks x there is some z ∈ S that attacks y.(c) S is conflict-free if no argument in S is attacked by any other argument in S.(d) A conflict-free set S is admissible if every argument in S is acceptable with respect to S.(e) S is a preferred extension if it is a maximal (with respect to ⊆) admissible set.(f) S is a stable extension if S is conflict free and every argument y /∈ S is attacked by S.(g) H is coherent if every preferred extension in H is also a stable extension.An argument x is credulously accepted if there is some preferred extension containing it; x is sceptically accepted ifit is a member of every preferred extension.The concepts of credulous and sceptical acceptance motivate the following decision problems that have been con-sidered in [17,21].Credulous Acceptance (CA)Instance: Argument System, H = (cid:3)X , A(cid:4), x ∈ X .Question: Is x credulously accepted in H?Sceptical Acceptance (SA)Instance: Argument System, H = (cid:3)X , A(cid:4), x ∈ X .Question: Is x sceptically accepted in H?T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7145The results of [17] establish that CA is NP-complete, while [21] have proven SA to be (cid:2)p2 -complete.1 Abstractingaway concerns regarding the internal structure and representation of arguments affords a formalism which focuseson the relationship between individual arguments as a means of defining several different notions of acceptability.In this paper preferred extensions are of particular interest as these represent maximal coherent positions that can bedefended against all attackers.3. Value based argument frameworksAs explained in the introduction, whether a particular audience is persuaded by an argument depends on the attitudeof that audience to the values on which the argument is founded. Values are used in the sense of fundamental social orpersonal goods that are desirable in themselves, and should not be confused with any numeric measure of the strength,certainty or probability of an argument. Such values are recognised as important influences on choices. In the UK andUS people are increasingly said to base their voting intentions on values rather than specific policies. The NationalForensic League, which conducts debating competitions throughout the USA uses the “Lincoln-Douglas” (LD) debateformat which is based on the notion of a clash of values. Guideline 1 [27] stresses the central importance of values:“A decision should be based on1. Clear use of value argumentation throughout the round.(a) Establishing of a value premise to support the debater’s position in the round.(b) Establishing of values criteria to support the debater’s position in the round. Values criteria are a systemupon which to judge values. These criteria may range in format, but the relationship between the valuepremise and criteria should be clear so that the resolution can be evaluated.(c) Clash in the debate based upon the values criteria and/or the value premise.”So what are values? It may help to give a few examples. In the original debate between Abraham Lincoln and StephenDouglas on which LD debates are based, Douglas championed the rights of states to legislate for their particularcircumstances, whereas Lincoln argued on the basis that were certain inviolable human rights that all states had torespect. A perennial political choice is whether to raise taxes, promoting the value of social equality, or to reducethem, said to encourage personal freedom and enterprise. In [9] a moral dilemma centring on whether a person hasthe right to use the property of another if his life is endangered is discussed. Here the value clash is between propertyrights and the right to life. This scenario is used in Appendix B to provide a detailed illustration of the approach ofthis paper. In [4] a legal controversy is analysed with values of clarity of the law, property rights, economic benefitsand animal rights. As a final example [5] analyses a political debate in terms of arguments based on national security,world peace, democracy and respect for human life. In all these analyses, the importance of the audience, and whichvalues it chooses to prefer is clearly demonstrated. It is such “value clashes” that are at the heart of LD debate, asstated in 1(c) of the guidelines.These examples show that the values used in a debate will be particular to that debate. The relevant values areintroduced along with the arguments put forward, as indicated by 1(a) of LD debate guidelines above. An argumentscheme for reasoning about what should be done which associates arguments with values and a method for con-structing arguments using this scheme is fully described in [2]. In the remainder of this section we will introduce aframework for reasoning about arguments associated with values.Value Based Argument Frameworks (VAFs), were introduced in [8,9] as a mechanism with which to provide aninterpretation of multiple preferred extensions in a single argument system. Thus, the basic formalism of Dung’sframework as captured in Definition 1 is extended to provide a semantics for distinguishing and choosing betweenconsistent but incompatible belief sets through the use of argument values: arguments are seen as grounded on oneof a finite number of abstract values and, where there are multiple preferred extensions, the interpretation of whichto “accept” is treated in terms of preference orderings of the underlying value set according to the views held bya particular audience. Thus while in the standard Argumentation system the choice between preferred extensions is1 Assuming that the argument system is coherent, SA is CO-NP-complete. While the problem of testing coherence is itself shown to (cid:2)p2 -completein [21], there are polynomial-time verifiable properties which ensure coherence, e.g. if the directed graph structure defined by (cid:3)X , A(cid:4) contains noodd-length cycles.46T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71arbitrary, in a VAF we are able to motivate such choices by reference to the value ordering of the audience. The formaldefinition of such value-based argumentation frameworks is given below.Definition 2. A value-based argumentation framework (VAF), is defined by a triple (cid:3)H(X , A), V, η(cid:4), where H(X , A)is an argument system, V = {v1, v2, . . . , vk} a set of k values, and η : X → V a mapping that associates a valueη(x) ∈ V with each argument x ∈ X .Central to the development presented in [8,9] and to the main themes of the present article is the concept of anaudience.2 The definition presented below refines the original form presented in [9].Definition 3. An audience for a VAF (cid:3)X , A, V, η(cid:4), is a binary relation R ⊂ V ×V whose (irreflexive) transitive closure,R∗, is asymmetric, i.e. at most one of (cid:3)v, v(cid:9)(cid:4), (cid:3)v(cid:9), v(cid:4) are members of R∗ for any distinct v, v(cid:9) ∈ V. We say that vi ispreferred to vj in the audience R, denoted vi (cid:10)R vj , if (cid:3)vi, vj (cid:4) ∈ R∗.Viewing R∗ in graph-theoretic terms, if R is an audience then R∗ induces an acyclic directed graph over the vertexset V. Unless otherwise stated, we identify audiences R with their closure R∗, e.g. for R ⊂ V × V given as part of aninstance to some problem involving VAFs, we assume R = R∗.Typically, an audience, R, will not describe a unique total ordering of V, but will be “compatible” with severaldistinct such orderings, i.e. all total orders, σ , for which (cid:3)vi, vj (cid:4) ∈ R∗ implies that vi (cid:10)σ vj . Hence, if σ is a totalordering of V then σ is compatible with the audience R only if every preference (cid:3)vi, vj (cid:4) described by R∗ is alsoexpressed within σ , i.e. vi (cid:10)σ vj . Formally, this set of compatible total orderings corresponds to the set of linearextensions of the (strict) partial order induced by R∗.Definition 4. Let R be an audience, α is a specific audience (compatible with R) if α is a total ordering of V and∀v, v(cid:9) ∈ V (cid:3)v, v(cid:9)(cid:4) ∈ R∗ ⇒ (cid:3)v, v(cid:9)(cid:4) ∈ α.We use χ(R) to denote the set of specific audiences compatible with R.Example 1. For V = {A, B, C}.1. If R = ∅ then R∗ = ∅ and so χ(∅) contains every possible specific audience. Reflecting this property, we referto the special case R = ∅ as the universal audience. In addition when the term specific audience is used withoutexplicit reference to some audience R, the underlying audience will be understood to be the universal audience.2. If R = {(cid:3)A, B(cid:4), (cid:3)B, C(cid:4)} then R∗ = {(cid:3)A, B(cid:4), (cid:3)B, C(cid:4), (cid:3)A, C(cid:4)} so that χ(R) = {R∗}, i.e. χ(R) contains exactly onespecific audience: that corresponding to the ordering A (cid:10)σ B (cid:10)σ C.3. If R = {(cid:3)A, B(cid:4), (cid:3)C, B(cid:4)} then R∗ = R andχ(R) = {{(cid:3)A, B(cid:4), (cid:3)C, B(cid:4), (cid:3)A, C(cid:4)}; {(cid:3)A, B(cid:4), (cid:3)C, B(cid:4), (cid:3)C, A(cid:4)}}corresponding to the orderings A (cid:10)σ C (cid:10)σ B and C (cid:10)σ A (cid:10)σ B.We adopt the convention of using lower case Greek letters—α, β, γ , etc.—when referring to specific audiences,whilst reserving upper case calligraphic symbols—R, S, T , etc.—for audiences in the sense of Definition 3.Using VAFs, ideas analogous to those of admissible argument in standard argument systems can be defined. Notethat these notions are now relative to some audience. The key concept is that of an attack, (cid:3)x, y(cid:4) being successful.Definition 5. Let (cid:3)X , A, V, η(cid:4) be a VAF and R an audience. For arguments x, y in X , x is a successful attack on y(or x successfully defeats y) with respect to the audience R if: (cid:3)x, y(cid:4) ∈ A and it is not the case that η(y) (cid:10)R η(x).2 The term “audience”, the use of which derives from [28] is also used in Hunter [25], although he distinguishes between audiences only in termsof beliefs, whereas [9] distinguishes them in terms of values, while also accommodating differences in beliefs.T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7147Thus, by replacing “attack” in Definition 1(b)–(f) with “successful attack” we obtain formal parallels of the con-cepts: “argument acceptable to a set”, “conflict-free”, “admissible set”, “preferred extension” and “stable extension”.For example “x is acceptable to a subset S with respect to an audience R if: for every y ∈ X that successfully attacksx with respect to R, there is some z ∈ S that successfully attacks y with respect to R”.Note that with such definitions a preferred extension for an audience may contain an argument, x, and an argumentwhich attacks it, y, provided the audience concerned prefers the value of x to that of y. The sense of this is somethinglike “even though y, I will accept x”. For example we might say “even though lowering taxes would increase enter-prise, we should still not lower them because social equality is more important”. In such cases, of course, we cannotperform all the actions recommended by arguments in the preferred extension: the actions to be performed are thoserecommended by the effective arguments, namely those in the preferred extension which additionally do not fail inany of their attacks.We observe that in the case of R being the universal audience the forms arising from Definition 5 (as outlinedfollowing this definition) match exactly the corresponding structures in Dung’s framework as described in Defini-tion 1(a)–(f).A standard consistency requirement which we assume of the VAFs considered is that every directed cycle of ar-guments in these contains at least two differently valued arguments. We do not believe that this condition is overlyrestricting, since the existence of such cycles in VAFs can be seen as indicating a flaw in the formulation of the frame-work. While in standard argumentation frameworks cycles arise naturally, especially if we are dealing with uncertainor incomplete information, in VAFs odd length cycles in a single value represent paradoxes and even length cycles ina single value can be reduced to a dilemma which must be resolved by choosing one of the alternatives. Given theabsence of cycles in a single value the following important property of VAFs with respect to specific audiences wasdemonstrated in [9].Fact 6. For every specific3 audience, α, (cid:3)X , A, V, η(cid:4) has a unique non-empty preferred extension, P ((cid:3)X , A, V, η(cid:4), α)which can be constructed by an algorithm that takes O(|X | + |A|) steps. Furthermore P ((cid:3)X , A, V, η(cid:4), α) is a stableextension with respect to α.From Fact 6 it follows that, when attention is focused on one specific audience, analogues of many decision ques-tions known to be intractable in the standard setting become significantly easier.There are, however, a number of new issues that arise in the value-based framework from the fact that the relativeordering of different values promoted by distinct specific audiences results in arguments falling into one of threecategories.(C1) Arguments, x, that are in the preferred extension P ((cid:3)X , A, V, η(cid:4), α) for some specific audiences compatiblewith R but not all. Such arguments being called subjectively acceptable with respect to R.(C2) Arguments, x, that are in the preferred extension P ((cid:3)X , A, V, η(cid:4), α) for every specific audience compatiblewith R. Such arguments being called objectively acceptable with respect to R.(C3) Arguments, x, that are not in any preferred extension P ((cid:3)X , A, V, η(cid:4), α) no matter which specific audience, α,compatible with R is used. Such arguments being called indefensible with respect to R.While we have introduced these in terms of arbitrary audiences, R, the ideas presented in (C1)–(C3) are partic-ularly of interest in the case of the universal audience: subjective acceptability indicating that there is at least onespecific audience (total ordering of values) under which p is accepted; objective acceptability that p must be acceptedirrespective of the value ordering described by a specific audience; and, in contrast, p being indefensible indicatingthat no specific audience can ever accept p.As we indicated in the introductory discussion, one may often find in practical reasoning contexts that participantsdisagree on value priorities yet nonetheless have a “common stance” regarding the acceptability or otherwise ofparticular arguments. We may model such behaviours in terms of the following formalism.3 Recall that specific audiences induce a total ordering of the value set V. It is, of course, not the case that Fact 6 holds for audiences in general.48T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71Definition 7. Let (cid:3)X , A, V, η(cid:4) be a VAF and R, S audiences. Given x ∈ X we say that R and S have grounds foragreement over x if either(1) There are specific audiences α ∈ χ(R), β ∈ χ(S) such thatx ∈ P ((cid:3)X , A, V, η(cid:4), α)and x ∈ P ((cid:3)X , A, V, η(cid:4), β)or(2) For all specific audiences α ∈ χ(R) ∪ χ(S), x /∈ P ((cid:3)X , A, V, η(cid:4), α).We say that R and S are at issue over x if R and S do not have grounds for agreement over x, e.g. x ∈P ((cid:3)X , A, V, η(cid:4), α) for some α ∈ χ(R), but x /∈ P ((cid:3)X , A, V, η(cid:4), β) for all β ∈ χ(S).We observe, in passing, that while it may seem more natural to define R and S as having “grounds for agreementover x” via the existence of some α ∈ χ(R) ∩ χ(S) for which x ∈ P ((cid:3)X , A, V, η(cid:4), α), such a choice turns out to berather too restrictive: there could be no specific audience compatible with both R and S, e.g. if v (cid:10)R v(cid:9) and v(cid:9) (cid:10)S v,however, this need not prevent x being subjectively acceptable with respect to both, i.e. the disagreement of the relativeordering of {v, v(cid:9)} is irrelevant to either audience’s view of x.In the following section we consider the computational complexity of some naturally arising decision questionsregarding VAFs, audiences, and these classes of acceptability.4. Audience related properties of VAFsIn this section4 we review some complexity-theoretic and algorithmic issues related to a number of natural decisionquestions arising in VAFs.4.1. Complexity resultsWe consider the following decision problems:Subjective Acceptance (SBA)Instance: A VAF (cid:3)X , A, V, η(cid:4); argument x ∈ X ; audience R.Question: Is there a specific audience, α ∈ χ(R) for which x ∈ P ((cid:3)X , A, V, η(cid:4), α)?Objective Acceptance (OBA)Instance: A VAF (cid:3)X , A, V, η(cid:4); argument x ∈ X ; audience R.Question: Is x ∈ P ((cid:3)X , A, V, η(cid:4), α) for every specific audience α ∈ χ(R)?Audiences at Issue (AAI)Instance: A VAF (cid:3)X , A, V, η(cid:4); argument x ∈ X ; audiences R, S.Question: Is there a specific audience α ∈ χ(R) for which x ∈ P ((cid:3)X , A, V, η(cid:4), α) but no specific audience β ∈ χ(S)with x ∈ P ((cid:3)X , A, V, η(cid:4), β)?Regarding these three decision problems we have the results below.Theorem 8. SBA is NP-complete, even if R is the universal audience.Theorem 9. OBA is CO-NP-complete, again even if R is the universal audience.Theorem 10. AAI is Dp-complete,5 even in the special case R = {(cid:3)v, v(cid:9)(cid:4)}, S = {(cid:3)v(cid:9), v(cid:4)} for distinct values v, v(cid:9) ∈ V.4 The results described here are extended and revised treatments of work originally presented in [23,24]. We give statements of the main theoremsin Section 4.1 only here: proofs may be found in Appendix A.5 We recall that Dp is the class of languages that may be expressed as the intersection of some language L1 ∈ NP with a language L2 ∈ CO-NP.T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71494.2. Efficient algorithms on VAFsWe have now arrived at the position where we can detect efficiently the arguments acceptable to any specificaudience, but cannot guarantee that we will be able to determine the status of an argument with respect to the universalaudience. We now consider another problem relating to VAFs which does admit an efficient solution, namely findingan audience for whom a subset of arguments represents a preferred extension, if one exists.We begin by giving a formal statement of our problem:Set Acceptance (SAC)Instance: A VAF (cid:3)X , A, V, η(cid:4); a subset S of X .Question: Is there an audience R such that ∀α ∈ χ(R), S = P ((cid:3)X , A, V, η(cid:4), α)?In this section we address this problem and some related applications. On first inspection, it might appear that,given the status of SBA, this too would be an intractable problem. We will show, however, that this pessimistic viewis ill-founded: the critical difference between the two problems is that subjective acceptance concerns the existenceof a specific audience with respect to which a single given argument is accepted; whereas the current problem asksfor an audience with respect to which a given set of arguments defines the totality of what that audience is capable ofaccepting.Consider the following algorithm:FIND AUDIENCEInstance: VAF (cid:3)X , A, V, η(cid:4); S ⊆ X .Returns: Audience R such that ∀α ∈ χ(R), S = P ((cid:3)X , A, V, η(cid:4), α) or FAIL if no such audience exists.1. R := ∅;2. for each (cid:3)x, y(cid:4) ∈ S × S:2.1. if (cid:3)x, y(cid:4) ∈ A thena. if η(x) = η(y) then report FAIL elseR := R ∪ {(cid:3)η(y), η(x)(cid:4)}3. R := R∗, i.e. replace R with its transitive closure.4. if R is not an audience (i.e. contains (cid:3)v, v(cid:9)(cid:4) and (cid:3)v(cid:9), v(cid:4) for some v and v(cid:9)) then report FAIL else5. for each z /∈ Sa. if η(z) = η(x) for some x ∈ S thenFind some y ∈ S for which (cid:3)y, z(cid:4) ∈ A and (cid:3)η(z), η(y)(cid:4) /∈ R.report FAIL if no suitable y ∈ S is found.b. else—η(z) does not occur as the value of any x ∈ SChoose any y ∈ S with (cid:3)y, z(cid:4) ∈ A;R := R ∪ {(cid:3)η(y), η(z)(cid:4)}report FAIL if no y ∈ S attacks z.6. R := R∗.7. return RTheorem 11. Given an instance (cid:3)X , A, V, η(cid:4) and S ⊆ X the algorithm FIND AUDIENCE returns an audience Rsuch that ∀α ∈ χ(R), S = P ((cid:3)X , A, V, η(cid:4), α) or reports FAIL if no such audience exists. Furthermore the time takenis O(|X |2).Proof. Steps (2) and (3) of FIND AUDIENCE construct a partial ordering of the values in S that satisfies the requirementthat S must be conflict-free with respect to the audience: thus each (cid:3)x, y(cid:4) ∈ A for which both x and y are in S forces anordering of the values {η(x), η(y)} according to the constraints described in the discussion following Definition 5. Allconstraints arising thus are added by the loop comprising (2), resulting in the set of constraints R upon completion.At step (3), this set is extended to include all of the additional pair-wise orderings arising through the property that50T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71if (cid:3)η(x), η(y)(cid:4) ∈ R and (cid:3)η(y), η(z)(cid:4) ∈ R then any audience consistent with R must have η(x) (cid:10)R η(z): constructingall of the pair-wise orderings that should be included simply involves computing the (irreflexive) transitive closure ofthe relations identified after (2) has completed. Step (4) deals with the requirement that since the audience relationmust be asymmetric the set of pairs R cannot contain both (cid:3)vi, vj (cid:4) and (cid:3)vj , vi(cid:4): this would happen if, for example,there were {x, y, z} ∈ S with (cid:3)x, y(cid:4) ∈ A, (cid:3)y, z(cid:4) ∈ A and η(x) = η(z). Since (3) has formed the transitive closure ofthe constraint relationship identified in (2), the “consistency” test in (4) involves checking that for each x ∈ S the pair(cid:3)η(x), η(x)(cid:4) has not been added. Step (5) is concerned with checking that S is maximal with respect to the audiencethat has been constructed in the earlier stages. Again, via Definition 5, this simply involves testing for each argumentz /∈ S, that z cannot be added to S without creating a conflict. There are two possibilities. Firstly, the value η(z) isamong those considered in S: in this case it suffices to ensure that z is successfully attacked by some y ∈ S. Secondly,the value η(z) is distinct from any value used in S: in this case it suffices to find any y ∈ S that attacks z. (cid:2)4.3. Discussion: Algorithms and complexity in Dung’s framework and VAFsTurning to the relative complexity of seemingly related problems within VAFs and Dung’s framework, it couldappear that the result presented in Theorem 11 is at odds with that of Theorem 8. That this is not the case is easilyseen by noting that should the algorithm analysed in Theorem 11 return FAIL given some set S ⊆ X then this doesnot imply that each argument in S is indefensible. For example, consider the extreme case where S contains a singleargument x: each of the following is possible(1) x is subjectively acceptable and FIND AUDIENCE reports FAIL.(2) x is objectively acceptable and FIND AUDIENCE reports FAIL.(3) {x} is admissible w.r.t some R and FIND AUDIENCE reports FAIL.The algorithm FIND AUDIENCE returns R (rather than FAIL) only if S is both maximal and admissible: thus, thefirst two cases will arise whenever x is attacked by another argument; the final case would occur whenever S was notmaximal, i.e. there is some z /∈ S that is not successfully attacked by any member of S.We note that changing the loop condition governing (5) in this algorithm tofor each (cid:3)z, y(cid:4) ∈ A for which z /∈ S and y ∈ S(with the remainder of (5) unaltered) gives an algorithm to construct an audience with respect to which S is anadmissible set. It is well-known that checking if a given set of arguments is admissible or defines a stable extension(in the schema of [19]) can be done efficiently. In VAFs the unique preferred extension with respect to a specificaudience is a stable extension, so we may interpret FIND AUDIENCE (and its modification) as confirming that testingif S is admissible or stable remains tractable within VAFs, despite the additional constraints arising from the conceptof audience.The concepts of subjective and objective acceptance have a (superficial) similarity to those of credulous andsceptical acceptance. In this light, coupled with the facts that deciding if an argument is credulously accepted isNP-complete [17], deciding if an argument is sceptically accepted is (cid:2)p2 -complete [21] the intractability of SBA andOBA is unsurprising.6We note, however, that there are a number of differences between the two groups of problems. One obvious distinc-tion is in the form of the search-space structures: CA and SA ranging over subsets of X ; SBA and OBA over possible(total) orderings of V. In addition, we have the following,Theorem 12.(a) SBA((cid:3)X , A, V, η(cid:4), x, ∅) (cid:16)⇒ CA((cid:3)X , A(cid:4), x).(b) OBA((cid:3)X , A, V, η(cid:4), x, ∅) (cid:16)⇒ SA((cid:3)X , A(cid:4), x).6 In addition one can note the structural similarity of the VAF constructed in the reduction from 3-SAT of Theorem 8 to the argument systemconstructed in reductions from 3-SAT to credulous acceptance, e.g. [22, Definition 7, p. 234].T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7151Fig. 1. Example VAFs in proof of Theorem 12.(c) OBA((cid:3)X , A, V, η(cid:4), x, ∅) (cid:16)⇒ CA((cid:3)X , A(cid:4), x).(d) SA((cid:3)X , A(cid:4), x) (cid:16)⇒ OBA((cid:3)X , A, V, η(cid:4), x, ∅).(e) CA((cid:3)X , A(cid:4), x) (cid:16)⇒ SBA((cid:3)X , A, V, η(cid:4), x, ∅).(f) SA((cid:3)X , A(cid:4), x) (cid:16)⇒ SBA((cid:3)X , A, V, η(cid:4), x, ∅).Proof. Consider the three VAFs within which V = {A, B} shown in Fig. 1.For the system of Fig. 1(a), the unique preferred extension is the empty set. When interpreted as a VAF, however,the argument x is objectively acceptable, and the argument z is subjectively acceptable as witnessed by the specificaudience B (cid:10) A. These establish cases (a)–(c) of the theorem.In the system of Fig. 1(b), there is (again) a unique preferred extension comprising the arguments {y, z} (thus bothare sceptically accepted). For the specific audience A (cid:10) B the associated preferred extension is {x, z}: this does notcontain y thus proving (d).Finally noting that (f) subsumes (e), in the system depicted in Fig. 1(c), the preferred extension is {u, w, x}. Theargument x, however, is indefensible in the VAF interpretation: the specific audience A (cid:10) B leaves no counterattackto the attack by z on x since w does not successfully attack z with respect to the audience A (cid:10) B. Similarly, for theremaining specific audience B (cid:10) A, the attack by y on x can no longer be countered since u does not successfullyattack y with respect to the audience B (cid:10) A. (cid:2)Thus, it is not generally possible to deduce acceptance by specific audiences or indefensibility from correspondingacceptance classes in the underlying argument system produced by abstracting away references to values.5. Dialogue processes for determining argument statusGiven a standard argument system—(cid:3)X , A(cid:4)—and an argument x ∈ X resolving the question of whether or not x iscredulously accepted can be viewed, in a natural way, as a dialogue between a proponent of x (whom we shall denotePRO) and an opposing player (denoted as OPP): the latter advancing attacking arguments, y; the former selecting,in turn, arguments that counterattack these. This high-level abstraction of dialogue in argument systems is alreadyproposed within Dung’s original presentation [19, p. 332], but is not subsequently developed therein. Subsequently,however, a number of formalised dialogue processes building on standard argument systems have been developed andanalysed. In this section we review such approaches and, informally, present the notion of a “position” within a VAF:positions and dialogue mechanisms for constructing these are treated in depth in Section 6.An important generic formalism for defining dialogue schemes was introduced by Jakobovits and Vermeir [26].The model defined presents dialogue games on argument systems—(cid:3)X , A(cid:4)—as a sequence of moves, μ0μ1 · · · μr · · ·made by the players PRO and OPP. A specific instantiation of this generic scheme must provide a repertoire of movetypes (with particular move types involving parameters such as, e.g. individual arguments); and a legal move functionthat defines for any “partial” dialogue μ0 · · · μr which of {PRO, OPP} should contribute the next move, μr+1 andthe instantiations of available moves for the player concerned. While it is, usually, the case that PRO makes theinitial move and that players alternate turns thereafter, it is convenient to relax this under certain conditions, e.g.52T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71when the case being set out by PRO involves advancing a number of separate arguments prior to the dialogue propercommencing: such a convention is adopted in the dialogue mechanisms presented in Section 6. The formalism of[26] has been used to specify dialogue procedures for credulous reasoning and determination of preferred sets inwork of Cayrol et al. [12,13]. As has been shown in Amgoud and Cayrol [1] the formalism is general enough toaccommodate models that develop Dung’s frameworks: [1] describing instantiations yielding dialogue mechanisms inPreference-based argument frameworks.In addition to these schemes, one dialogue process—the class of Two Party Immediate response disputes (TPI-disputes)—has been the subject of detailed analysis. This approach was introduced by Vreeswijk and Prakken [30],and one feature is that it attempts to restrict the arguments that may be used by PRO and OPP to those that directlyattack the most recent argument advanced: thus if x is the argument put forward by PRO in move μr then the argumenty played by OPP in μr+1 must be such that (cid:3)y, x(cid:4) ∈ A. As was, however, noted in [30, p. 247] some provision mustbe made for both PRO and OPP to “backtrack” to some earlier point in the dialogue. The resulting dialectic proofprocedures described in [30] are proven to be sound and complete for deciding credulous acceptance. In the case ofproving sceptical acceptance, TPI-disputes are sound and complete when applied to coherent argument systems. Thedevelopment of sound and complete proof mechanisms for sceptical argumentation raises a number of difficultiesas discussed in [21, pp. 201–202]. An alternative formalisation of TPI-disputes is described and studied in [22]: thisanalyses the “efficiency” of TPI-disputes when applied as a propositional proof theory, showing it to be polynomially-equivalent7 to the CUT-free Gentzen calculus. Thus, there are examples in which demonstrations that an argument isnot credulously accepted require exponentially many moves in the total number of arguments in the system. Finally,there is the recent work of Dung et al. [20], proposing a novel approach to the synthesis of dialectic proof procedureswithin the assumption-based framework of [10]: in this the use of “backward reasoning” is promoted as a means ofresolving whether an argument is admissible.In Section 6 our aim is to develop similar dialogue based mechanisms to those outlined above, but tailored tothe characteristics of value-based argument frameworks.8 We note here that starting from the basis of a VAF andthe universal audience, player PRO has available options in addition to simply bringing forward “new” argumentsto counterattack those proposed by OPP: PRO can also render an attack ineffective by expressing a suitable valueordering. In fact we wish to consider such dialogues as not so much concerned with “individual” arguments but ratheras considering whether a set of arguments could be collectively acceptable to some audience. Thus in Section 6 ourprincipal interest is in whether a subset S ⊆ X in a VAF defines a position: that is, whether there is some set Tcontaining S and an audience R for which T is admissible.6. Dialogue processes for position construction in VAFsWe now turn to one of the central issues addressed in this paper: the concept of positions and the construction ofsuch by dialogue procedures: the first is formally presented in Section 6.1 with dialogue mechanisms then presentedin depth in Section 6.2.6.1. Definition of a positionThe notion of a position given at the end of the last section already addresses two of the crucial features for practicalreasoning identified in the introduction: we are dealing with sets of arguments within an argumentation framework, andso considering the context, and the fact that different positions will be acceptable to different audiences captures thedesired notion of rational disagreement. In this section we will address the remaining requirement: that the orderingof values should emerge from the debate, on the basis of some intuitive predisposition towards certain actions andreluctance to perform others.First, to allow reasoners to have certain arguments they wish to include in a position, and others they wish toexclude, while they are indifferent to the rest, we extend the definition of a VAF as follows:7 The concept of “polynomial-equivalence” of proof systems derives from Cook and Reckhow [16].8 A very brief overview of the ideas presented in this section was given in [18].T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7153Definition 13. A VAF (cid:3)X , A, V, η(cid:4) is DOR-partitioned if X = D ∪ O ∪ R for disjoint sets D, O and R, which denoterespectively a set of desired arguments, a set of optional arguments and a set of rejected arguments. We use Des(X )to denote D, Opt(X ) to denote O and Rej(X ) to denote R. A DOR-partitioned VAF is called a DOR-VAF.An admissible set which can be adopted as a position in a DOR-VAF, is a set that contains the desired argumentsand possibly some optional arguments, whose role is to help a desired argument to be acceptable to the position, by“defending” it against its attackers. Formally:Definition 14. Given a VAF (cid:3)X , A, V, η(cid:4), an argument y is a defender of an argument x with respect to an audienceR if and only if there is a finite sequence a0, . . . , a2n (n > 0) such that x = a0, y = a2n, and ∀i, 0 (cid:2) i (cid:2) (2n − 1), ai+1successfully attacks ai with respect to R.The new notion of a position is defined via:Definition 15. Given a DOR-VAF (cid:3)X , A, V, η(cid:4), a set S = Des(X ) ∪ Y where Y ⊆ Opt(X ), is a position if and only ifthere exists at least one audience R w.r.t. which S is admissible and ∀y ∈ Y , ∃x ∈ Des(X ) such that y is a defenderof x. An audience w.r.t. which S is a position is said to be a corresponding audience of S.This new notion of a position accommodates the third feature of practical reasoning: the preferences betweenvalues are not given as an input on the basis of which the position is constructed, but are a result of constructing theposition.6.2. Development of a positionHaving formalised the concept of position in the previous section, we now consider processes for constructingthese. An overview of the approach is given in Section 6.2.1, then in Section 6.2.2, we present a formal dialogueframework that we instantiate in Section 6.2.3 in order to check if a set of desired arguments is conflict-free for atleast one audience. We instantiate the dialogue framework in Section 6.2.4 to check if a conflict-free set of desiredarguments can be made acceptable. Finally, in Section 6.2.5 we combine these two instantiations of the dialogueframework to construct positions, and we give an example of such a construction.6.2.1. General ideaIn order to build a position, one may start by considering the set of desired arguments. This set must be first testedto demonstrate that there is at least one audience w.r.t. which it is conflict-free. It may be that this condition can onlybe satisfied by imposing some value preferences. If we can satisfy this test we must next ensure that any defeatedargument in the set has a defender in the set w.r.t. at least one audience. To this end, some optional arguments maybe added to the set as defenders of defeated arguments and/or some additional constraints on the ordering of valuesmay be imposed. We would like such extensions of the position under development to be kept to a minimum. If theprocess succeeds, then the set developed is a position and the set of constraints determined by the construction canbe extended into a corresponding audience of this position, by taking its transitive closure. Otherwise, the user has toreconsider the partition of the set of arguments; such issues are the subject of ongoing research.This construction can be presented in the form of a dialogue between two players. One, the opponent, outlineswhy the set under development is not yet a position, by identifying arguments which defeat members of the set.The other, the proponent, tries to make the set under development a position by extending it with some optionalarguments and/or some constraints between values. If the opponent has been left with no legal move available, thenthe set of arguments played by the proponent is a position and the set of constraints advanced can be extended intoa corresponding audience. On the other hand, if the proponent has no legal move available then the set of desiredarguments cannot be extended into a position.This presentation in a dialogue form has the main advantage of making clear why some constraints between valuesmust be imposed, and why some optional arguments must belong to the position. Moreover, it is highly appropriate tothe dialectical nature of practical reasoning identified above.54T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–716.2.2. Dialogue frameworkA dialogue framework to prove the acceptability of arguments in Dung’s argument system has been developedby [26] and refined in [13]. We extend this last framework to deal with the development of positions in a DOR-VAF.Informally, a dialogue framework provides a definition of the players, the moves, the rules and conditions underwhich the dialogue terminates, i.e. those situations wherein the current player has no legal move in the dialogue. Inorder to capture the construction of positions, the dialogue framework we define comprises two players, PRO andOPP. The rules are expressed in a so-called ‘legal-move function’. Regarding the definition of a move, since playingan argument may be possible only if some preferences between values hold, a move must comprise an argumentand a set of value preferences. In particular, a player may propose some ordering of values, i.e. without any specificargument being involved (for example, when he wants to make a set of desired arguments conflict-free for at leastone audience). To this end, it is convenient to extend the set of arguments of a DOR-VAF (cid:3)X , A, V, η(cid:4) with an ‘emptyargument’ that we denote by _. This argument can be used if the proponent’s move is only to advance a value ordering.We denote by X − the set X ∪ {_}.Definition 16. Let (cid:3)X −, A, V, η(cid:4) be a DOR-VAF. A move in X − is a pair [P , (cid:3)X, V (cid:4)] where P ∈ {PRO, OPP}, X ∈ X −,and V ⊆ V × V. PRO denotes the proponent and OPP denotes the opponent.For a move μ = [P , (cid:3)X, V (cid:4)], we use pl(μ) to denote P , arg(μ) to denote X, and val(μ) to denote V . The set ofmoves is denoted by M with M∗ being the set of finite sequences of moves.Let φ : M∗ → 2X −×2V×Vbe a legal-move function. A dialogue (or φ-dialogue) d about S = {a1, a2, . . . , an} ⊆ Xis a countable sequence μ01 μ02 . . . μ0n μ1μ2 . . . of moves in X − such that the following conditions hold:(1) pl(μ0k ) = PRO, arg(μ0k ) = ak, and val(μ0k ) = ∅ for 1 (cid:2) k (cid:2) n(2) pl(μ1) = OPP and pl(μi) (cid:16)= pl(μi+1), for i (cid:3) 1(3) (cid:3) arg(μi+1), val(μi+1)(cid:4) ∈ φ(μ01 μ02 . . . μ0n μ1 . . . μi).In a dialogue about a set of arguments, the first n moves are played by PRO to put forward the elements of the set,without any constraint on the value of these arguments (1), and the subsequent moves are played alternately by OPPand PRO (2). The legal-move function defines at every step what moves can be used to continue the dialogue (3). Wedo not impose the requirement that arg(μi+1) must attack arg(μi), because we want a dialogue to be sequential, sowe need to let OPP try all possible answers to any of PRO’s arguments, but only one at a time.Let (cid:3)X −, A, V, η(cid:4) be a DOR-VAF, S ⊆ X and d = μ01 . . . μ0nμ1μ2 . . . μi be a finite φ-dialogue about S. We denoteμi by last(d) and write φ(d) for φ(μ01 . . . μ0nμ1μ2 . . . μi). In addition, argPRO(d) (resp. valPRO(d)) will denote theset of arguments (resp. values) played by PRO in d.Now that we have a way to define a dialogue and the rules of a dialogue, let us define when a dialogue terminates(i.e. cannot be continued).Definition 17. Let (cid:3)X −, A, V, η(cid:4) be a DOR-VAF, φ be a legal-move function, and d be a finite φ-dialogue. d cannotbe continued if φ(d) = ∅. d is said to be won by PRO if and only if d cannot be continued, and pl(last(d)) = PRO.We introduce the notion of a definite attack and additional notations to instantiate the dialogue framework todevelop positions.Definition 18. Let (cid:3)X , A, V, η(cid:4) be a VAF, R be an audience, and x and y be two arguments of X . We say that xdefinitely attacks y with respect to R if: (cid:3)x, y(cid:4) ∈ A and, η(x) = η(y) or (cid:3)η(x), η(y)(cid:4) ∈ R∗.Notice that, if x definitely attacks y, then x successfully attacks y. Now, given an audience R and x ∈ X −:• A+• A++• A−• A−−R(x) = {y ∈ X | x successfully attacks y w.r.t. R},R (x) = {y ∈ X | x definitely attacks y w.r.t. R},R(x) = {y ∈ X | y successfully attacks x w.r.t. R},R (x) = {y ∈ X | y definitely attacks x w.r.t. R},T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7155• A±R(x) = A+R(x) ∪ A−R(x).Note that A+(cid:2)R(S) =x∈SR(_) = A−AεR(x).AεR(_) = A−−R (_) = A++R (_) = ∅. Moreover, given a set S ⊆ X and ε ∈ {+, −, ±, ++, −−},6.2.3. Checking conflict-freenessLet (cid:3)X −, A, V, η(cid:4) be a DOR-VAF and R be an audience. Des(X ) is not conflict-free w.r.t. R if there are twodesired arguments x and y such that y successfully attacks x, that is, (cid:3)y, x(cid:4) ∈ A and (cid:3)η(x), η(y)(cid:4) /∈ R. In order tomake Des(X ) conflict-free, the value of x should be made preferred to the value of y, that is, (cid:3)η(x), η(y)(cid:4) added to R.This is possible only if R ∪ {(cid:3)η(x), η(y)(cid:4)} is an audience.Consider a dialogue d about Des(X ), based on a legal-move function where OPP plays moves using argumentssuch as y and the value ordering is empty, and where PRO only exhibits constraints on the value of these arguments.Then the set of arguments played by PRO in d (i.e. argPRO(d)) is Des(X ), possibly along with {_}. The valueorderings played by PRO in d (i.e. valPRO(d)) must be the audience w.r.t. which moves are made. Formally:Definition 19. Let (cid:3)X −, A, V, η(cid:4) be a DOR-VAF, d be a dialogue about Des(X ) and R = valPRO(d). φ1 : M∗ →2X −×2V×Vis defined by:• if the last move of d is by PRO (next move is by OPP),(cid:3)φ1(d) ={(cid:3)y, ∅(cid:4)};y∈A−R(argPRO(d))∩argPRO(d)• if the last move of d is by OPP (next move is by PRO), let y = arg(last(d)), V =η(y)(cid:4)},(cid:4)φ1(d) ={(cid:3) _ , V (cid:4)}∅if R ∪ V is an audience,otherwise.(cid:2)x∈A+R(y)∩argPRO(d){(cid:3)η(x),In informal terms, the moves available to OPP under φ1 are to choose an argument (y) that is not only in the set ofarguments currently supported by PRO but also successfully attacks with respect to the audience R (another) argumentthat PRO supports. If OPP can identify such an argument then the set argPRO(d) cannot be conflict-free with respectto R. The response available to PRO requires such conflicts to be resolved by committing to value orderings underwhich the previously successful attacks will now fail. Thus the moves available to PRO under φ1 are to indicate valuepreferences V formed by the collection (cid:3)η(x), η(y)(cid:4) of arguments x it supports but are successfully attacked (w.r.t.R) using the argument y advanced by OPP in the previous move. In this case, PRO will only be able to continue d,i.e. φ1(d) (cid:16)= ∅, if it is still the case that the resulting value ordering relation, R ∪ V , remains an audience.The dialogue framework instantiated with the legal-move function φ1, is sound and complete w.r.t. the determina-tion of an audience w.r.t. which a set of arguments is conflict-free as shown by the two following properties.Property 1 (Soundness of φ1). Let (cid:3)X , A, V, η(cid:4) be a VAF and S ⊆ X . If d is a φ1-dialogue about S won by PRO, thenS is conflict-free w.r.t. audience valPRO(d).Lemma 1. Let (cid:3)X , A, V, η(cid:4) be a VAF and S ⊆ X . If d is a φ1-dialogue about S, the last move of which is played byPRO, then valPRO(d) is an audience.Proof. Let S = {a1, . . . , an} ⊆ X . Let d be a φ1-dialogue about S, the last move of which is played by PRO. If thelength of d is lower than or equal to n, then all the moves of d have the form [PRO, (cid:3)ai, ∅(cid:4)] where ai is an argument ofS (1 (cid:2) i (cid:2) n). So valPRO(d) = ∅, and then valPRO(d) is obviously an audience. If the length of d is strictly greaterthan n, then d has the form d = d (cid:9).[OPP, (cid:3)y, ∅(cid:4)].[PRO, (cid:3)_, V (cid:4)], where V is, by definition, a set of value preferencessuch that valPRO(d (cid:9).[OPP, (cid:3)y, ∅(cid:4)]) ∪ V is an audience. Since valPRO(d (cid:9).[OPP, (cid:3)y, ∅(cid:4)]) ∪ V = valPRO(d), valPRO(d)is an audience. (cid:2)Lemma 2. Let (cid:3)X , A, V, η(cid:4) be a VAF. Let d be a φ1-dialogue about a set S ⊆ X .56T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71• If d is of length strictly lower than |S| then argPRO(d) ⊆ S.• If d is of length |S| or |S| + 1 then argPRO(d) = S.• If d is of length strictly greater than |S| + 1 then argPRO(d) = S ∪ {_}.Proof. Obvious, since by definition, the first |S| moves of d are by PRO and contain S’s arguments; all the followingmoves by PRO contain the empty argument. (cid:2)Proof of Property 1. Let S ⊆ X . Let d be a φ1-dialogue about S won by PRO. Let R = valPRO(d). R is an audienceaccording to Lemma 1. Let us show that S is conflict-free w.r.t. R. Since d is won by PRO, the length of d is equal toor greater than |S| and so, according to Lemma 2, S = argPRO(d) \ {_}. Moreover, since d is won by PRO, we have:φ1(d) = ∅ ={(cid:3)y, ∅(cid:4)}(cid:3)y∈A−R(argPRO(d))∩argPRO(d)R(argPRO(d)) ∩ argPRO(d) = ∅. In other words, no argument of argPRO(d) is successfully attacked byso A−argPRO(d) w.r.t. R. Therefore argPRO(d), and then S, is conflict-free w.r.t. audience valPRO(d). (cid:2)Property 2 (Completeness of φ1). Let (cid:3)X , A, V, η(cid:4) be a VAF. If S ⊆ X is conflict-free w.r.t. at least one audience, andS (cid:16)= ∅, then there exists a φ1-dialogue about S won by PRO.Notation 1. Let (cid:3)X , A, V, η(cid:4) be a VAF. Let S ⊆ X . V(S) denotes the set of value preferences which makes ‘unsuccess-ful’ any successful (but not definite) attack between arguments of S, that is: V(S) =x∈S,y∈S s.t. (cid:3)y,x(cid:4)∈A{(cid:3)η(x), η(y)(cid:4)}.(cid:2)Lemma 3. Let (cid:3)X , A, V, η(cid:4) be a VAF. A set S ⊆ X is conflict-free w.r.t. an audience R if and only if V(S) ⊆ R∗.Proof. Let R be an audience such that V(S) ⊆ R∗. Let x ∈ S and y ∈ S such that (cid:3)y, x(cid:4) ∈ A. y does not successfullyattack x w.r.t. R since (cid:3)η(x), η(y)(cid:4) ∈ V(S). So S is conflict-free w.r.t. R. Now, let S be a conflict-free set w.r.t. anaudience R. For any x ∈ S and y ∈ S, if (cid:3)y, x(cid:4) ∈ A, then (cid:3)η(x), η(y)(cid:4) ∈ R∗. So V(S) ⊆ R∗. (cid:2)Lemma 4. Let (cid:3)X , A, V, η(cid:4) be a VAF. Let d be a φ1-dialogue about a set S ⊆ X , of the form d = d (cid:9).[OPP, (cid:3)y, ∅(cid:4)],and let R = valPRO(d). Then{(cid:3)η(x), η(y)(cid:4)} ⊆ V(S).(cid:2)x∈A+R(y)∩argPRO(d)Proof. The length of d is greater than |S| + 1 since the last move of d is by OPP. So, according to Lemma 2,argPRO(d) = S ∪ {_}. By definition, y belong to argPRO(d) and is not the empty argument, so y ∈ S. Any ar-gument x ∈ argPRO(d) successfully attacked by y w.r.t. R, is not the empty argument, and belongs to S. So(cid:2)x∈S,y∈S s.t. (cid:3)y,x(cid:4)∈A{(cid:3)η(x), η(y)(cid:4)}. (cid:2){(cid:3)η(x), η(y)(cid:4)} ⊆x∈A+(cid:2)R(y)∩argPRO(d)Lemma 5. Let (cid:3)X , A, V, η(cid:4) be a VAF and S ⊆ X . If d is a φ1-dialogue about S, then valPRO(d) ⊆ V(S).Proof. Let S = {a1, . . . , an} ⊆ X . Let d be a φ1-dialogue about S. If the length of d is lower than or equal to n, thenall the moves of d have the form [PRO, (cid:3)ai, ∅(cid:4)] where ai is an argument of S (1 (cid:2) i (cid:2) n). So valPRO(d) = ∅, and thenvalPRO(d) ⊆ V(S). Assume that if d is of a length k, with k > n, then valPRO(d) ⊆ V(S). Let us show that the prop-erty is true if d is of length k + 1. d can have two forms. (1) If d = d (cid:9).[OPP, (cid:3)y, ∅(cid:4)], then valPRO(d) = valPRO(d (cid:9)).Since d (cid:9) is of length k, valPRO(d (cid:9)) ⊆ V(S), and then valPRO(d) ⊆ V(S). (2) If d = d (cid:9).[PRO, (cid:3)_, V (cid:4)], then d (cid:9) is oflength k, and so valPRO(d (cid:9)) ⊆ V(S). According to Lemma 4, V ⊆ V(S). Consequently, since valPRO(d (cid:9)) ∪ V =valPRO(d), we have valPRO(d) ⊆ V(S). (cid:2)Lemma 6. Let (cid:3)X , A, V, η(cid:4) be a VAF. Let S ⊆ X be a conflict-free set for at least one audience, such that S (cid:16)= ∅.Let d be a φ1-dialogue about S of length equal to or greater than |S|, the last move of which is played by PRO.If V(S) (cid:2) (valPRO(d))∗, then there exist y ∈ X and V ⊆ V × V such that d.[OPP, (cid:3)y, ∅(cid:4)].[PRO, (cid:3) _ , V (cid:4)] is a φ1-dialogue.T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7157Proof. Let d be a φ1-dialogue about S of length equal to or greater than |S|, the last move of which is played byPRO. Let R = valPRO(d). According to Lemma 1, R is an audience. According to Lemma 3, since V(S) (cid:2) R∗, S isnot conflict-free w.r.t. R. Consequently, there exists y ∈ argPRO(d) that successfully attacks some x ∈ argPRO(d)w.r.t. R. In other words, there is some (cid:3)y, ∅(cid:4) ∈ φ1(d), and d (cid:9) = d.[OPP, (cid:3)y, ∅(cid:4)] is a φ1-dialogue. Now, let(cid:3)V ={(cid:3)η(x), η(y)(cid:4)}.x∈A+R(y)∩argPRO(d(cid:9))Let us show that valPRO(d (cid:9)) ∪ V is an audience. According to Lemma 5, valPRO(d (cid:9)) ⊆ V(S). According to Lemma 4,V ⊆ V(S). So valPRO(d) ∪ V ⊆ V(S). Let T be an audience w.r.t. which S is conflict-free. According to Lemma 3,V(S) ⊆ T ∗. So valPRO(d (cid:9)) ∪ V ⊆ T ∗ and then, (valPRO(d (cid:9)) ∪ V )∗ ⊆ T ∗. Consequently, valPRO(d (cid:9)) ∪ V is anaudience. Hence, (cid:3) _ , V (cid:4) ∈ φ1(d (cid:9)), and then d.[OPP, (cid:3)y, ∅(cid:4)].[PRO, (cid:3) _ , V (cid:4)] is a φ1-dialogue. (cid:2)Proof of Property 2. Assume that S is a conflict-free set for at least one audience, and that S (cid:16)= ∅. Let d1 =[PRO, (cid:3)a1, ∅(cid:4)] . . . [PRO, (cid:3)a|S|, ∅(cid:4)] be the sequence of the first |S| moves of a dialogue about S. Let, for i (cid:3) 2,di = di−1.[OPP, (cid:3)y, ∅(cid:4)].[PRO, (cid:3) _ , V (cid:4)]where, given that Ri−1 = valPRO(di−1) = valPRO(di−1.[OPP, (cid:3)y, ∅(cid:4)]):• y ∈ A−Ri−1(cid:2)• V =x∈A+R• valPRO(di) is an audience.(argPRO(di−1)) ∩ argPRO(di−1),(y)∩argPRO(di−1.[OPP,(cid:3)y,∅(cid:4)])i−1{(cid:3)η(x), η(y)(cid:4)}, andLemma 6 proves that the sequence is well-defined. Let us show that function φ1 is strictly decreasing, that is, φ1(di) ⊂φ1(di−1). Let Ri = valPRO(di). First, let us show that φ1(di) ⊆ φ1(di−1). Let• Zi = {z ∈ X | (cid:3)z, ∅(cid:4) ∈ φ1(di)} = A−Ri• Zi−1 = {z ∈ X | (cid:3)z, ∅(cid:4) ∈ φ1(di−1)} = A−(argPRO(di)) ∩ argPRO(di),(argPRO(di−1)) ∩ argPRO(di−1).Ri−1Ri−1(S) ∩ S and Zi−1 = A−According to Lemma 2, we have Zi = A−Ri(S) ⊆ A−A−(S). So Zi ⊆ Zi−1 and hence φ1(di) ⊆ φ1(di−1).RiSecond, let us show that there exists some pair in φ1(di−1) that does not belong to φ1(di). Consider the pair (cid:3)y, ∅(cid:4)(S) ∩ S.∗. Since Ri = Ri−1 ∪ V , for any x ∈ S(S) ∩ S, and hence (cid:3)y, ∅(cid:4) /∈ φ1(di). So φ1(di) ⊂which is in φ1(di−1). We have y ∈ A−Ri−1Hence there exists some x ∈ S such that (cid:3)y, x(cid:4) ∈ A and (cid:3)η(x), η(y)(cid:4) /∈ Ri−1such that (cid:3)y, x(cid:4) ∈ A, (cid:3)η(x), η(y)(cid:4) ∈ Riφ1(di−1).(argPRO(di−1)) ∩ argPRO(di−1). According to Lemma 2, y ∈ A−(S) ∩ S. Since valPRO(di−1) ⊆ valPRO(di),∗. Consequently, y /∈ A−RiRi−1Ri−1The empty set is the minimum of function φ1, and for this set, the dialogue is won by PRO. (cid:2)This instance of the dialogue framework can indeed be used to check if the set of desired arguments of a DOR-partitioned VAF is conflict-free for at least one audience, and if so, to give such an audience. It is a corollary of thetwo previous properties.Corollary 1. Let (cid:3)X , A, V, η(cid:4) be a DOR-VAF. If d is a φ1-dialogue about Des(X ) won by PRO, then Des(X ) isconflict-free w.r.t. audience valPRO(d). If Des(X ) (cid:16)= ∅ is conflict-free w.r.t. at least one audience, then there exists aφ1-dialogue about Des(X ) won by PRO.6.2.4. Making the arguments acceptableGiven a DOR-VAF (cid:3)X , A, V, η(cid:4), let us assume that the set Des(X ) is conflict-free in the most restricted sense, thatis, there are no arguments x and y in Des(X ) such that x attacks y. For R be an audience we call the set containing thedesired arguments which aims at being a position the ‘position under development’. The reason why the position underdevelopment would not be admissible w.r.t. R is that some arguments in it would not be acceptable to it w.r.t. R, i.e.58T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71there is (at least one) argument x in the position under development such that some argument y successfully attacks xw.r.t. R and no argument z in the position successfully attacks y w.r.t. R.Let us consider a dialogue d about the conflict-free set Des(X ), based on a legal-move function where OPP playsmoves in which the argument is y and the value ordering is empty, and where PRO plays in a way to make an argumentsuch as x acceptable. The arguments of the position under development are those played by PRO. The value orderingsplayed by PRO (i.e. valPRO(d)) must be the audience w.r.t. which the moves are made.We identify four ways to make an argument x acceptable to the position under development:(W1) Add to the position under development an optional argument z which definitely attacks y and which is not inconflict with any argument of the position under development.(W2) Make the value of x preferred to the value of y, if x is not definitely attacked by y.(W3) Add to the position under development an optional argument z which successfully but not definitely attacks yand which is not in conflict with any argument of the position under development.(W4) Add to the position under development an optional argument z which successfully attacks y, and which mightbe successfully but not definitely attacked by the position under development or which might successfully butnot definitely attack the position under development; the addition of value preferences to the current audiencein order for the addition of z to the position to be correct must form an audience.The following definition gives the formal translations of (W1) through (W4) as dialogue moves.Definition 20. Let (cid:3)X −, A, V, η(cid:4) be a DOR-VAF, d be a dialogue about Des(X ), R = valPRO(d). φ2 : M∗ →2X −×2V×Vis defined by:• if pl(last(d)) = PRO (next move is by OPP), then(cid:3)φ2(d) ={(cid:3)y, ∅(cid:4)};y∈(A−R(argPRO(d))\A+R(argPRO(d)))• if pl(last(d)) = OPP and arg(last(d)) = y (next move is by PRO), let:R (y)) \ A±Z1 = (Opt(X ) ∩ A−−Z2 = argPRO(d) ∩ (A+Z3 = (Opt(X ) ∩ (A−(cid:9)Z4 = {z ∈ Z4= (Opt(X ) ∩ A−(cid:9)Z4R(y) \ A++R(y) \ A−−R(argPRO(d)),R (y)),R (y))) \ A±R(argPRO(d)),| R ∪ VXY (z) is an audience} with:R(argPRO(d)) \ A++R (argPRO(d)))),R (argPRO(d)))R(y)) ∩ ((A+R(argPRO(d)) \ A−−and, given z ∈ Z(cid:9)4:∪ (A−X(z) = argPRO(d) ∩ (A−Y (z) = argPRO(d) ∩ (A+(cid:2)(R(z) \ A−−R(z) \ A++{(cid:3)η(z), η(x)(cid:4)} ∪R (z)),R (z)),(cid:2)⎧⎪⎨x∈X(z)∪ {(cid:3)η(z), η(y)(cid:4)})VXY (z) =⎪⎩(cid:2)(x∈X(z){(cid:3)η(z), η(x)(cid:4)} ∪w∈Y (z){(cid:3)η(w), η(z)(cid:4)}if η(z) (cid:16)= η(y) and (cid:3)η(z), η(y)(cid:4) /∈ (R)∗,{(cid:3)η(w), η(z)(cid:4)})otherwise.(cid:2)w∈Y (z)Then:or(W1)if Z1 (cid:16)= ∅,then φ2(d) =(W2)if Z2 (cid:16)= ∅,then φ2(d) =(cid:3)z∈Z1(cid:3)z∈Z2{(cid:3)z, ∅(cid:4)},{(cid:3) _ , {(cid:3)η(z), η(y)(cid:4)}(cid:4)},T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7159ororor(W3)if Z3 (cid:16)= ∅,then φ2(d) =(W4)if Z4 (cid:16)= ∅,then φ2(d) =(cid:3)z∈Z3(cid:3)z∈Z4{(cid:3)z, {(cid:3)η(z), η(y)(cid:4)}(cid:4)},{(cid:3)z, VXY (z)(cid:4)},if Z1 ∪ Z2 ∪ Z3 ∪ Z4 = ∅,then φ2(d) = ∅.Each of these four ways would be tried in turn. In responding to an attack, the proponent will wish to maintainas much flexibility to respond to further attacks as possible. The order in which the four ways are tried is thus deter-mined by the desire to make the least committal move at any stage. Flexibility is limited in two ways. If the positionis extended by including an additional argument, as in W1, W3 and W4, the potential attackers of the position isincreased since this argument must now also be defended by the position. If a commitment to a value ordering ismade, as in W2, W3 and W4, this must be subsequently respected, which restricts the scope to make such movesin future responses. We regard this second line of defence as more committal that the first. Therefore W1 should betried first since it imposes no constraints on the audience, although it does extend the position. W2 should be selectednext because, although it does constrain the audience to adopt a certain value preference, it does not introduce anyadditional arguments to the position, and so does not give rise to any additional attackers. If W3 is resorted to, boththe position is extended and a value ordering commitment is made, but the argument introduced is compatible with theexisting position. W4 should be the final resort because it extends the position, constrains the audience, and requiresfurther constraints to be imposed to enable it to cohere with the existing position.The dialogue framework instantiated with the legal-move function φ2, is correct and complete w.r.t. the determina-tion of an audience for which the conflict-free set of desired arguments is admissible for at least one audience:Property 3 (Soundness of φ2). Let (cid:3)X −, A, V, η(cid:4) be a DOR-VAF such that Des(X ) is conflict-free. If d is a φ2-dialogueabout Des(X ) won by PRO, then argPRO(d) \ {_} is a position such that valPRO(d) is a corresponding audience.Lemma 7. Let (cid:3)X , A, V, η(cid:4) be a VAF. Let v1, v2 ∈ V and R an audience. If (cid:3)v1, v2(cid:4) /∈ R∗ and v1 (cid:16)= v2, then R ∪{(cid:3)v2, v1(cid:4)} is an audience.Proof. Let us assume that (cid:3)v1, v2(cid:4) /∈ R∗ and v1 (cid:16)= v2. If (cid:3)v2, v1(cid:4) ∈ R, then obviously, R ∪ {(cid:3)v2, v1(cid:4)} is an audience.If (cid:3)v2, v1(cid:4) /∈ R, let us assume that R ∪ {(cid:3)v2, v1(cid:4)} is not an audience. Therefore, there would exist v ∈ V such that(cid:3)v, v(cid:4) ∈ (R ∪ {(cid:3)v2, v1(cid:4)})∗. Since v1 (cid:16)= v2, we know that (cid:3)v2, v1(cid:4) (cid:16)= (cid:3)v, v(cid:4). So (cid:3)v, v(cid:4) /∈ R ∪ {(cid:3)v2, v1(cid:4)}, but (cid:3)v, v(cid:4) ∈(R ∪ {(cid:3)v2, v1(cid:4)})∗. Hence, there would be in R a set of pairs such that:{(cid:3)v, x1(cid:4), (cid:3)x1, x2(cid:4), . . . , (cid:3)xi−1, xi(cid:4), (cid:3)xi, v2(cid:4), (cid:3)v1, xi+1(cid:4), (cid:3)xi+1, xi+2(cid:4), . . . , (cid:3)xn, v(cid:4)}for some n (cid:3) 0. Then R∗ would contain (cid:3)v, v2(cid:4), (cid:3)v1, v(cid:4), and (cid:3)v1, v2(cid:4). This is not possible since we have made theassumption that (cid:3)v1, v2(cid:4) /∈ R∗. Consequently, such a sequence does not exist and R ∪ {(cid:3)v2, v1(cid:4)} is an audience. (cid:2)Lemma 8. Given a DOR-VAF (cid:3)X −, A, V, η(cid:4) such that Des(X ) (cid:16)= ∅ is conflict-free, and a finite φ2-dialogue d,argPRO(d) is conflict-free w.r.t. the audience valPRO(d).Proof. We prove the result by induction on the number of elements of argPRO(d). If argPRO(d) only containsDes(X ), valPRO(d) = ∅, then argPRO(d) is conflict-free w.r.t. the audience valPRO(d). Suppose now that the prop-erty is true for any φ2-dialogue d such that argPRO(d) contains at most n − 1 elements, for some n > | Des(X )|. Let dbe a φ2-dialogue such that argPRO(d) contains n elements. Suppose first that the last move of d is played by PRO: dhas the form d = d (cid:9).[OPP, (cid:3)y, ∅(cid:4)].[PRO, (cid:3)z, V (cid:4)], where y ∈ A−valPRO(d(cid:9))(argPRO(d (cid:9))) and,given R = valPRO(d (cid:9)) = valPRO(d (cid:9).[OPP, (cid:3)y, ∅(cid:4)]) and d (cid:9)(cid:9) = d (cid:9).[OPP, (cid:3)y, ∅(cid:4)], either:valPRO(d(cid:9))(argPRO(d (cid:9))) \ A+60T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71R (y)) \ A±• (cid:3)z, V (cid:4) is played according to W1; in this case, z ∈ (Opt(X ) ∩ A−−R(argPRO(d (cid:9)(cid:9))) and V = ∅. Sincez /∈ A±R(argPRO(d (cid:9)(cid:9))), z is conflict-free w.r.t. R with argPRO(d (cid:9)(cid:9)), and R ∪ V = R is an audience. Moreover,since y /∈ A+R (z), z /∈ argPRO(d (cid:9)). Consequently, d (cid:9) contains strictly less than nelements. Thus, by induction hypothesis, argPRO(d (cid:9)) is conflict-free w.r.t. R. Hence, argPRO(d (cid:9)) ∪ {z} is conflict-free w.r.t. R ∪ V .R(argPRO(d (cid:9))) and y ∈ A++R (y)). z is obviously conflict-free with argPRO(d (cid:9)(cid:9)) w.r.t. R and R ∪ V . Moreover, since t ∈ A+• (cid:3)z, V (cid:4) is played according to W2; in this case, z = _ and V = (cid:3)η(t), η(y)(cid:4) for some t ∈ argPRO(d(cid:9)(cid:9)) ∩ (A+R(y) \ A++R(y) \A++R (y),we have (cid:3)η(y), η(t)(cid:4) /∈ (R)∗ and η(t) (cid:16)= η(y). So, by Lemma 7, R ∪ V is an audience. Assuming that the argumentz is different from any argument played in argPRO(d (cid:9)) (and especially any _), then d (cid:9) contains strictly less than nelements. Thus, by induction hypothesis, argPRO(d (cid:9)) is conflict-free w.r.t. R. Hence, argPRO(d (cid:9)) ∪ {z} is conflict-free w.r.t. R ∪ V .• (cid:3)z, V (cid:4) is played according to W3; in this case, z ∈ (Opt(X ) ∩ (A−R(argPRO(d (cid:9)(cid:9))), andV = (cid:3)η(z), η(y)(cid:4). Since z /∈ A±R(argPRO(d (cid:9)(cid:9))), z is conflict-free w.r.t. R with argPRO(d (cid:9)(cid:9)). Moreover, since z ∈A−R (y), (cid:3)η(y), η(z)(cid:4) /∈ (R)∗ and η(y) (cid:16)= η(z). So, by Lemma 7, R ∪ V is an audience. Now, sincey /∈ A+R(z), z /∈ argPRO(d (cid:9)). Consequently, d (cid:9) contains strictly less than n elements.Thus, by induction hypothesis, argPRO(d (cid:9)) is conflict-free w.r.t. R. Hence, argPRO(d (cid:9)) ∪ {z} is conflict-free w.r.t.R ∪ V .R(argPRO(d (cid:9))) and y ∈ A+R(argPRO(d (cid:9)(cid:9))) \ A−−• (cid:3)z, V (cid:4) is played according to W4; in this case, z ∈ (Opt(X ) ∩ A−R(y)) ∩ ((A+R (argPRO(d (cid:9)(cid:9))))∪ (A−R (argPRO(d (cid:9)(cid:9))))) and V = VXY (z) such that R ∪ VXY (z) is an audience. z is in conflictwith argPRO(d (cid:9)(cid:9)) w.r.t. R, but not w.r.t. R ∪ V : actually, for any argument x ∈ argPRO(d (cid:9)(cid:9)) that successfullybut not definitely attacks z w.r.t. R (i.e. x ∈ X(z)), (cid:3)η(z), η(x)(cid:4) ∈ V , and for any argument w ∈ argPRO(d(cid:9)(cid:9))that is successfully but not definitely attacked by z w.r.t. R (i.e. w ∈ Y (z)), then (cid:3)η(w), η(z)(cid:4) ∈ V . Now, sincey /∈ A+R(z), z /∈ argPRO(d (cid:9)). Consequently, d (cid:9) contains strictly less than n elements.Thus, by induction hypothesis, argPRO(d (cid:9)) is conflict-free w.r.t. R. Hence, argPRO(d (cid:9)) ∪ {z} is conflict-free w.r.t.R ∪ V .R(argPRO(d (cid:9))) and y ∈ A+R(argPRO(d (cid:9)(cid:9))) \ A++R (y))) \ A±R(y) \ A−−R(y) \ A−−Since argPRO(d (cid:9)) ∪ {z} = argPRO(d), and R ∪ V = valPRO(d), argPRO(d) is conflict-free w.r.t. the audiencevalPRO(d). Suppose now that the last move is played by OPP. Then d has the form d = d (cid:9).[OPP, (cid:3)y, ∅(cid:4)] where d (cid:9)is a φ2-dialogue such that argPRO(d (cid:9)) = argPRO(d) and valPRO(d (cid:9)) = valPRO(d). Therefore, argPRO(d (cid:9)) containsn elements. We have just proved that in this case, argPRO(d(cid:9)) is conflict-free w.r.t. valPRO(d (cid:9)), hence argPRO(d) isw.r.t. valPRO(d). (cid:2)Proof of Property 3. Let d be a φ2-dialogue about Des(X ) won by PRO. According to Lemma 8, argPRO(d) isconflict-free w.r.t. audience valPRO(d). Since d is won by PRO, φ2(d) = ∅, and hence:valPRO(d)(argPRO(d)) \ A+A−valPRO(d)(argPRO(d)) = ∅.In other words, every argument in argPRO(d) is acceptable to argPRO(d) w.r.t. valPRO(d). Consequently, argPRO(d)is admissible w.r.t. valPRO(d). Since d is a φ2-dialogue about Des(X ), Des(X ) ⊆ argPRO(d). Any optional argumentplayed by PRO in d is used to make acceptable another argument of argPRO(d) that would not be otherwise acceptableto argPRO(d). No rejected argument is played by PRO. The empty argument has no role in the admissibility ofargPRO(d). Consequently, argPRO(d) \ {_} is a position, and valPRO(d) is a corresponding audience. (cid:2)Property 4 (Completeness of φ2). Let (cid:3)X −, A, V, η(cid:4) be a DOR-VAF such that Des(X ) (cid:16)= ∅ is conflict-free. If(cid:3)X −, A, V, η(cid:4) has at least one position, then there exists a φ2-dialogue about Des(X ) won by PRO.Lemma 9. Let (cid:3)X −, A, V, η(cid:4) be a DOR-VAF such that Des(X ) (cid:16)= ∅ is conflict-free. Let d be a φ2-dialogue oflength greater than | Des(X )|, the last move of which is played by PRO. Let S be a minimal position that containsargPRO(d) \ {_}, and R be a minimal corresponding audience of S. If S (cid:16)= argPRO(d) \ {_} or (R)∗ (cid:16)= (valPRO(d))∗,then there exist y ∈ X , z ∈ X − and V ⊆ V × V such that the dialogue d (cid:9) = d.[OPP, (cid:3)y, ∅(cid:4)].[PRO, (cid:3)z, V (cid:4)] is a φ2-dialogue and S is minimal such that S is a position and contains argPRO(d(cid:9)) \ {_}, and R is a minimal correspondingaudience of S that contains valPRO(d (cid:9)).T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7161Proof. Since argPRO(d) \ {_} (cid:16)= S or (valPRO(d))∗ (cid:16)= R∗, and since argPRO(d) \ {_} ⊆ S, (valPRO(d))∗ ⊆ R∗,the minimality of S and the corresponding audience R imply that argPRO(d) is not admissible w.r.t. valPRO(d).From Lemma 8, we know that argPRO(d) is conflict-free w.r.t. valPRO(d). Thus A−valPRO(d)(argPRO(d)) \A+valPRO(d)(argPRO(d)) (cid:16)= ∅. Hence, φ2(d) (cid:16)= ∅. Let y ∈ A−valPRO(d)(argPRO(d)). SinceargPRO(d) \ {_} ⊆ S, (valPRO(d))∗ ⊆ R∗, and S admissible w.r.t. R, ∃z ∈ {_} ∪ (S ∩ Opt(X )) and ∃V ⊆ R∗ suchthat, either:valPRO(d)(argPRO(d)) \ A+valPRO(d)(z); in this case, z ∈ Z1, V = ∅.• y ∈ A++• V = (cid:3)η(t), η(y)(cid:4) for t ∈ argPRO(d) ∩ (A+• y ∈ A+• y ∈ A+valPRO(d)(y) \ A++valPRO(d)(z) and V = (cid:3)η(z), η(y)(cid:4); in this case, z ∈ Z3.valPRO(d)(y)) = Z2 and z = _.valPRO(d)(z) \ A++valPRO(d)(z) and z is in conflict with argPRO(d) w.r.t. valPRO(d), but, for any argument x that successfullybut not definitely attacks z, (cid:3)η(z), η(x)(cid:4) ∈ V , for any argument w that is successfully but not definitely attackedby z, (cid:3)η(w), η(z)(cid:4) ∈ V , and if η(z) (cid:16)= η(y), (cid:3)η(z), η(y)(cid:4) ∈ V ; in this case, z ∈ Z4.Consequently, (cid:3)z, V (cid:4) ∈ φ2(d.[OPP, (cid:3)y, ∅(cid:4)]). Thus, d (cid:9) = d.[OPP, (cid:3)y, ∅(cid:4)].[PRO, (cid:3)z, V (cid:4)] is a φ2-dialogue.We know that argPRO(d (cid:9)) = argPRO(d) ∪ {z}, argPRO(d (cid:9)) \ {_} ⊆ S, and (valPRO(d (cid:9)))∗ = (valPRO(d) ∪ V )∗ ⊆R∗. There remains to prove that no set S(cid:9) ⊂ S that contains argPRO(d (cid:9)) \ {_}, and no R(cid:9) ⊆ V × V such that(valPRO(d (cid:9)))∗ ⊆ (R(cid:9))∗ ⊂ R∗, are such that:• S(cid:9) is admissible w.r.t. R. Suppose that such a set S(cid:9) exists. Then argPRO(d) \ {_} ⊆ argPRO(d (cid:9)) \ {_}. Hence,argPRO(d) \ {_} ⊂ S. Since S is minimal such that S contains argPRO(d) \ {_} and S is admissible w.r.t. R, S(cid:9) is notadmissible w.r.t. R.is an audience w.r.t. which S is admissible. Suppose that such an R(cid:9) exists. Then (valPRO(d))∗ ⊆(valPRO(d (cid:9)))∗, and hence (valPRO(d))∗ ⊂ R∗. Since R is minimal such that R∗ contains (valPRO(d))∗ and Ris an audience w.r.t. which S is admissible, R(cid:9) is not an audience. (cid:2)• R(cid:9)Proof of Property 4. Let S be a minimal subset of X such that S is a position, and R be a minimal corre-sponding audience of S. Given Des(X ) = {a1, . . . , an}, let d1 = [PRO, (cid:3)a1, ∅(cid:4)] . . . [PRO, (cid:3)an, ∅(cid:4)]. Given j > 1, letdj = dj −1.[OPP, (cid:3)y, ∅(cid:4)].[PRO, (cid:3)z, V (cid:4)] if argPRO(dj −1) (cid:16)= S and (valPRO(dj −1))∗ (cid:16)= R∗; (cid:3)y, ∅(cid:4) ∈ φ2(dj −1) and(cid:3)z, V (cid:4) ∈ φ2(dj −1.[OPP, (cid:3)y, ∅(cid:4)]). Lemma 9 proves that the sequence is well defined, and that, when argPRO(dj ) = Sand (valPRO(dj ))∗ = R∗, there exists j (cid:3) 1 such that dj is a φ2-dialogue about Des(X ) won by PRO (since S isadmissible w.r.t. R, A−= ∅). (cid:2)\ A+valPRO(dj )valPRO(dj )6.2.5. Development of positionsLet us consider the following legal-move function:Definition 21. Let (cid:3)X −, A, V, η(cid:4) be a DOR-VAF, d be a dialogue about Des(X ). φ3 : M∗ → 2X −×2V×Vis defined by:• if pl(last(d)) = PRO (next move is by OPP), then, if φ1(d) (cid:16)= ∅, then φ3(d) = φ1(d) else φ3(d) = φ2(d);• if pl(last(d)) = OPP (next move is by PRO), if arg(last(d)) ∈ Des(X ) then φ3(d) = φ1(d), else φ3(d) = φ2(d).Property 5. Let (cid:3)X , A, V, η(cid:4) be a DOR-VAF. If d is a φ3-dialogue about Des(X ) won by PRO, then argPRO(d) \ {_}is a position such that valPRO(d) is a corresponding audience. If Des(X ) (cid:16)= ∅ is contained in a position, then thereexists a φ3-dialogue about Des(X ) won by PRO.Proof. Consequence of Corollary 1, Properties 3 and 4. (cid:2)Example 2. Consider the following VAF (cid:3)X , A, V, η(cid:4) shown in Fig. 2.The arguments are the vertices of the graph and the edges represent the elements of the attack relation. The setof values is V = {v1, v2, v3, v4, v5}. The value associated to an argument is indicated just below or just above theargument. The desired arguments are plain-circled, the optional arguments are dot-circled, and the rejected arguments62T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71Fig. 2. VAF example for position development.are not circled. Let us develop a position. We start a φ3-dialogue d about Des(X ). The first moves of d contain the= [PRO, (cid:3)c, ∅(cid:4)][PRO, (cid:3)f, ∅(cid:4)] [PRO, (cid:3)i, ∅(cid:4)] [PRO, (cid:3)l, ∅(cid:4)][PRO,desired arguments, i.e. μ01μ02 μ03μ04 μ05μ06μ07 μ08(cid:3)m, ∅(cid:4)][PRO, (cid:3)n, ∅(cid:4)][PRO, (cid:3)o, ∅(cid:4)][PRO, (cid:3)p, ∅(cid:4)]. Then, to ensure the conflict-freeness of Des(X ) w.r.t. one audience:μ1 = [OPP, (cid:3)m, ∅(cid:4)]μ2 = [PRO, (cid:3)_, {(cid:3)v3, v1(cid:4)}(cid:4)].Now, to make the arguments of Des(X ) acceptable:μ3 = [OPP, (cid:3)b, ∅(cid:4)]μ4 = [PRO, (cid:3)a, ∅(cid:4)]μ5 = [OPP, (cid:3)e, ∅(cid:4)]μ6 = [PRO, (cid:3)_, {(cid:3)v2, v1(cid:4)}(cid:4)]μ7 = [OPP, (cid:3)h, ∅(cid:4)]μ8 = [PRO, (cid:3)g, {(cid:3)v4, v2(cid:4)}(cid:4)]μ9 = [OPP, (cid:3)j, ∅(cid:4)]μ10 = [PRO, (cid:3)_, {(cid:3)v4, v3(cid:4)}(cid:4)]μ11 = [OPP, (cid:3)k, ∅(cid:4)]μ12 = [PRO, (cid:3)j, {(cid:3)v3, v2(cid:4), (cid:3)v3, v5(cid:4)}(cid:4)].(W1)(W2)(W3)(W2)(W4)d = μ01 . . . μ08μ1μ2μ3μ4μ5μ6μ7μ8μ9μ10μ11μ12 is a φ3-dialogue won by PRO. The set argPRO(d) = Des(X ) ∪{a, g, j } is a position, and valPRO(d) = {(cid:3)v4, v3(cid:4), (cid:3)v3, v2(cid:4), (cid:3)v4, v2(cid:4), (cid:3)v2, v1(cid:4), (cid:3)v3, v1(cid:4), (cid:3)v3, v5(cid:4)} is one of its corre-sponding audiences.At certain points we may be presented with a choice of arguments to use with W1–W4. For example b may beattacked by a or, if v1 is not preferred to v2, q. Similarly there are choices when we declare value preferences: in theexample we can either prevent the attack of j on g succeeding, or choose preferences which lead to i or o defeatingj . Such choices may, if badly made, lead to backtracking. Some heuristics seem possible to guide choices: it is betterto attack an undesired argument with an argument of its own value where possible, as with a and b above, as thisattack will succeed even if the value order changes. Also, when a value preference is required, a choice which keepsan optional argument available is better than one which defeats it, as the argument may be required to defeat a futureattack, as in the example where j is required to defeat k.We have illustrated our approach with an abstract example, as producing a VAF substantial enough to illustrate allthe features requires a thorough consideration of the details of the scenario to be represented, and of the argumentsrelevant to that scenario. Substantial VAFs have been reported in the legal domain [7], for ethical reasoning [3], andfor political debate [5]. A more extensive example, summarising the analysis fully presented in [3], may be found inAppendix B. Although these papers used the VAFs to analyse and explain disagreement, they are equally open to theidentification of audiences using the techniques described here. Law, in particular, gives a very natural partitioningof arguments: there are typically arguments that must be accepted if the party is to win its case, and others thatrepresent well established precedents that also must be accepted. Equally the arguments which would be decisive forthe opposing party must be rejected. The remaining indifferent arguments derive from precedents of lesser weight, andfrom controversial interpretations. Our technique will enable an interested party to identify which of these debatableprecedents and interpretations are needed to support his case, and identifies the key value clashes. Moreover it showsT.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7163how the value clashes were implicitly resolved in past cases, and how they need be resolved if the current case is tobe won.7. Related work7.1. AcceptanceIn this subsection our main purpose is to clarify the relation between the concepts of subjective (objective) ac-ceptance and credulous (sceptical) acceptance as used in standard argument systems. In addition we consider thebehaviour of the algorithm FIND AUDIENCE in rather more discursive terms relating it to the problems of testing a setarguments for admissibility or stability as defined in Definition 1.In earlier work, e.g. [23, p. 369], the Argument Systems of Dung [19] have been considered as VAFs in which asingle value is associated with all arguments (e.g. “truth”). We argue that a rather more subtle interpretation—alsorelevant to comparisons with the preference-based schema introduced by Amgoud and Cayrol [1]—is appropriate.We remarked earlier that Definitions 1 and 5 describe equivalent structures when the underlying audience is R = ∅,i.e. the universal audience. Thus one could view the apparent shift from intractability in Dung’s framework, e.g. asevidenced by the results of [17,21,22], to the polynomial-time procedures available for VAFs, e.g. as described inFact 6, Theorem 11 as indicative of how increased awareness of the underlying relationships offering reasons foracceptance of arguments within an argument system can assist in resolving issues. In order to amplify this point, ratherthan treating the standard systems of [19] as “VAFs in which only a single value is present”, we may consider theseas VAFs (in the sense of Definition 2) but in which one has (initially) no knowledge regarding the values associatedwith arguments or the relative orderings of these values that are held by protagonists. Thus, while one has (it maybe presumed) agreement on the set of values (V) germane to the framework and on the manner in which these relateto individual arguments—the mapping η : X → V—in the absence of any indication of value priorities, the case forsome argument, x say, being acceptable can only be “rationalised” in terms of the assumption that “every attack issuccessful”. In other words the effective audience is R = ∅—the universal audience—and an attack by y on x must,ceteribus paribus, be deemed to succeed, even when η(y) (cid:16)= η(x), since a rational disputant has no basis to reject theattack (cid:3)y, x(cid:4) in itself : to promote x its defenders must subsequently resort to finding attacks on y. Within the VAFframework, however, defenders of x have a rationale for rejecting the attack by y when η(y) (cid:16)= η(x): by indicatingthat they subscribe only to audiences wherein η(x) (cid:10)R η(y) so that the attack (cid:3)y, x(cid:4) is unsuccessful with respect tosuch audiences. In this way further debate concerning x takes place not in the context of the universal audience but inthe context of the audience R = {(cid:3)η(x), η(y)(cid:4)}.In summary, the revelation of successive value orderings, assuming these to be consistent in that R remains anaudience, may lead eventually to R being a specific audience: from the initial analysis of (cid:3)X , A, V, η(cid:4), knowledge andconditions on R have evolved from the state where nothing is assumed—R = ∅—to one in which a specific audiencehas been revealed, yielding exactly one (rational with respect to this audience) interpretation of which arguments areacceptable. We observe that in moving from R = ∅, the computational effect of adding (cid:3)v, v(cid:9)(cid:4) to R is modelled byremoving from the directed graph structure (cid:3)X , A(cid:4) all edges (cid:3)x, y(cid:4) for which η(x) = v(cid:9) and η(y) = v, so that (giventhe presence of at least two different values in any directed cycle of (cid:3)X , A(cid:4)) specific audiences will result in somedirected acyclic graph structure:9 that such forms have a unique, non-empty preferred extension is immediate from[19, Theorem 30], whose proof easily yields a polynomial-time algorithm for its construction.We note that the preference-based approach of [1] can also be treated as a mechanism to explain progression froman unrestricted argument system to an acyclic form: the response to an attack by y on x being that the argument x“is preferred to” the argument y and thence the attack (cid:3)y, x(cid:4) may be eliminated from (cid:3)X , A(cid:4) so that following thedeclaration of some finite number of preferences the resulting graph is acyclic. Unlike the interaction between Defini-tions 1 and 5 which we may relate via VAFs and the universal audience, analogues between VAF and preference-basedschemes are less clearly defined: while it is certainly the case that preference-based frameworks can be interpreted interms of VAFs in which every argument is associated with a unique value10 such an approach is unappealing, although9 It is, of course, possible that the reduction of A induced by an audience R defines an acyclic graph without R being a specific audience.10 In the same way, VAFs can be considered as preference-based frameworks where the argument preference relation is determined via the valueorderings. Where the preference relation supplies a total order, each argument will need to have a distinct value.64T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71it does emphasise that in such frameworks, unlike VAFs, the expression of a preference for one argument over anotherhas no implications for other choices that need to be made: in scenarios where VAF structures have been used, e.g. thesuite of legal examples presented in [9], typically the number of distinct values is “small” relative to the number ofarguments. A further important distinction between these two models can be seen in terms of our earlier discussion ofmechanisms for responding to an attack on x by y. Thus, in all three schemes, i.e. those of [1,8,19]—one option is tocounterattack y; in [1,8] there is the further possibility of “not recognising” the attack (cid:3)y, x(cid:4). In [1] a preference for xover y is expressed: these, however, are not “explained” and do not have implications for subsequent preferences thatmight be indicated.11 The VAF approach, however, requires an additional rationale for such a preference to be given:the attack by y on x fails because the defender of x regards its associated value, η(x), as having greater importancethan that of its attacker. One significant consequence of this implicit justification is that its speaker must act consis-tently regarding other attacks, e.g. an argument z with η(z) = η(y) can not be used to counterattack an argument wwith η(w) = η(x).7.2. Hunter’s notion of impact for an audienceAnother approach in which computational use is made of the notion of audience is that of Hunter [25]. Hunteradopts a notion of argument in which an argument is a pair comprising a set of formulae (the support) and a formula(the consequent) which can be classically derived from the support. Different arguments will have different resonancesfor different audiences. To calculate this each agent has a desideratabase comprising a set of propositional formulaedesiderata which the agent wishes to be satisfied, and a weighting which can be seen as a ranking over the set ofpossible worlds representing the set of classical interpretations given by the propositional language of the desiderata.Now an argument will have resonance for an agent if one or more desiderata (or their negations) can be derived fromthe support, and the weighting will determine the degree of resonance. Hunter uses this, together with the propositionalcost of an argument (lengthier arguments are more expensive) to determine the impact of an argument.Hunter’s notion of arguments differs from ours in that we ascribe values to arguments. One form of argumentthat would link arguments to values is that of [6]. In their approach an argument justifying an action instantiates thefollowing argument scheme:• in the current circumstances S• performing action A• will result in new circumstances R• which include goal G• which promotes value V.Viewed in Hunter’s terms we can see G as a desideratum derivable from the support comprising the theory whichstates that R is a consequence of performing A in S. Additionally we now also have V, the reason why the goal isdesired. Introducing V has two important effects:(1) it can distinguish two different arguments when agents wish to bring about the same state of affairs for differentreasons: for example, one may wish to restore fox hunting on the economic grounds of protecting livestock, orsimply for the hedonistic pleasure the activity affords.(2) it can relate two states of affairs in so far as they promote the same value: for example poverty can be alleviatedeither by distributing food, or by distributing money.It is in this ability to relate desirable states of affairs that values show their worth. It means that we can workwith a smaller number of values than desiderata, that we can add a desired state of affairs without need to extend ourset of values, and most importantly that desiring one state of affairs means that, in order to be consistent, we mustalso and equally desire other states of affairs. This greatly simplifies the weighting, and additionally means that some11 That is, other than the requirement that the irreflexive transitive closure of the preference relation be asymmetric, e.g. given three arguments x,y, and z with A = {(cid:3)x, z(cid:4), (cid:3)z, y(cid:4), (cid:3)y, x(cid:4)} it cannot be claimed (within the schema of [1]) that “x is preferred to y and y is preferred to z and z ispreferred to x”.T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7165weightings can be seen as inconsistent since they differentially weight states of affairs relating to the same value. Thisis essential if arguments attempting to change audience membership, which are often required for persuasion, are to bepossible. We would therefore argue that the use of values significantly enhances Hunter’s representation with respectto practical reasoning. Moreover by replacing his notion of a desideratabase with a set of values and their ranking wecan still make use of his theoretical notion of resonance to assess the impact of an argument for an audience.7.3. Concluding remarksIn this paper we have put forward a framework in which practical reasoning—reasoning about what should bedone in a given situation—may be addressed. The distinctive features of practical reasoning derive from the accept-ability of such arguments depending on the importance given to the values and purposes advanced if the argumentis accepted by the audience to whom it is addressed. Accordingly we have extended the Argumentation Frameworkof Dung by associating arguments with the values advanced by their acceptance. From this property we can derivepreferences between arguments with respect to particular audiences, and thus account for disagreements between dif-ferent audiences. We have explored the decision problems that arise in this extended framework, presented a numberof complexity results relating to these decision problems, and discussed the relation of the extended framework to theunderlying abstract framework.Another important question concerns how priorities between values can be determined by an agent in the courseof practical reasoning. We have presented a dialogue mechanism for determining these priorities, and shown it to besound and complete.Practical reasoning is a crucial activity for any intelligent agent, since it is through action that intelligence manifestsitself. The importance of the topic merits more investigation than it has so far been given, and we believe that we haveprovided a rich framework in which further investigation can be carried out.Appendix AWe present here proofs of the complexity results stated in Section 4.1.Proof of Theorem 8. For membership in NP simply non-deterministically choose an audience α from the k! availablethen test if α ∈ χ(R) and x ∈ P ((cid:3)X , A, V, η(cid:4), α), the latter test being accomplished by a polynomial-time algorithm,such as that given in [9].(cid:9)We prove that SBA is NP-hard for the special case of R being the universal audience, using a reduction from 3-SAT.mi=1(yi,1 ∨ yi,2 ∨ yi,3) of this we construct a VAF (cid:3)XΦ , AΦ , VΦ , η(cid:4) and argument x suchGiven an instance Φ(Zn) =that (cid:3)(cid:3)XΦ , AΦ , VΦ , η(cid:4), x, ∅(cid:4) is a positive instance of SBA if and only if Φ(Zn) is satisfiable.(cid:2)nThe framework uses 4n + m + 1 arguments which we denote {Φ, C1, . . . , Cm} ∪i=1{pi, qi, ri, si}. The rela-tionship AΦ contains attacks (cid:3)Cj , Φ(cid:4) for each 1 (cid:2) j (cid:2) m and attacks {(cid:3)pi, qi(cid:4), (cid:3)qi, ri(cid:4), (cid:3)ri, si(cid:4), (cid:3)si, pi(cid:4)} for each1 (cid:2) i (cid:2) n. The remaining attacks in AΦ are as follows. For each clause yi,1 ∨ yi,2 ∨ yi,3 of Φ(Zn) if yi,j is the literalzk, the attack (cid:3)pk, Ci(cid:4) is included in AΦ ; if yi,j is the literal ¬zk, then the attack (cid:3)qk, Ci(cid:4) is added.(cid:2)The final part of the construction is to describe the value set VΦ and association of arguments with values prescribedby η. The set VΦ contains 2n + 1 values {con} ∪} and the mapping η assigns the value con to Φ and{posi, negieach argument in {C1, . . . , Cm}. Finally the arguments {pi, ri} are mapped to the value posi and the arguments {qi, si}to the value negi . To complete the instance we set x to be Φ. We note that the constructed system satisfies therequirement that all cycles contain at least two distinct values.ni=1Fig. 3 illustrates the construction for the CNF.Φ(x, y, z) = (x ∨ y ∨ z)(¬x ∨ y ∨ ¬z)(x ∨ ¬y ∨ z).We claim that (cid:3)(cid:3)XΦ , AΦ , VΦ , η(cid:4), Φ, ∅(cid:4) is a positive instance of SBA if and only if Φ(Zn) is satisfiable.Suppose first that Φ(Zn) is satisfied by an instantiation (cid:3)a1, a2, . . . , an(cid:4) of Zn. Consider any specific audience(cid:10)α posi if ai = ⊥, and v (cid:10)α con for all v ∈ VΦ /{con}. Since Φ(Zn)α for which posiis satisfied, for each Ci there is some literal yi,j that is assigned (cid:19) in the instantiation (cid:3)a1, . . . , an(cid:4). Consider thearguments {pk, qk, rk, sk} for which yi,j ∈ {zk, ¬zk}. If yi,j = zk then pk is acceptable in {pk, rk} and, in addition,pk successfully attacks Ci with respect to α; if yi,j = ¬zk then qk is acceptable in {qk, sk} and, again, successfully(cid:10)α negi if ai = (cid:19), negi66T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71Fig. 3. VAF constructed for Φ(x, y, z) = (x ∨ y ∨ z)(¬x ∨ y ∨ ¬z)(x ∨ ¬y ∨ z).attacks Ci with respect to α. Thus every argument Ci is successfully attacked by an argument pk or qk and thenceΦ together with these form an admissible set with respect to α. Thus we have a specific audience, α, with respect towhich Φ is subjectively accepted.On the other hand, suppose α is a specific audience for which Φ belongs to P ((cid:3)XΦ , AΦ , VΦ , η(cid:4), α). It cannot bethe case that Ci ∈ P ((cid:3)XΦ , AΦ , VΦ , η(cid:4), α) since η(Φ) = η(Ci) = con and so the presence of any Ci would sufficeto eliminate Φ. The specific audience α must therefore be such that every Ci is successfully attacked by one of itsthree possible attackers with respect to α. Let (cid:3)t1, t2, . . . , tm(cid:4) be the choices which give these successful attacks on(cid:3)C1, . . . , Cm(cid:4). First observe that we cannot have ti = pk and tj = qk for any 1 (cid:2) k (cid:2) n and distinct Ci and Cj : underα either η(pk) (cid:10)α η(qk) and so qk would not succeed in its attack or η(qk) (cid:10)α η(pk) with the attack by pk failing. Itfollows that the instantiation of Zn by zi = (cid:19) if pi ∈ (cid:3)t1, t2, . . . , tm(cid:4), zi = ⊥ if qi ∈ (cid:3)t1, t2, . . . , tm(cid:4) is well-defined andyields a true literal in every clause, i.e. results in a satisfying instantiation of Φ(Zn). This completes the proof. (cid:2)Proof of Theorem 9. Membership in CO-NP follows by the algorithm which tests for all k! specific audiences, α,whether α ∈ χ(R) ⇒ x ∈ P ((cid:3)X , A, V, η(cid:4), α).We again establish CO-NP-hardness for the special case of R being the universal audience, via a reduction from3-UNSAT: the problem of deciding if a 3-CNF formula Φ(Zn) =mi=1(yi,1 ∨ yi,2 ∨ yi,3) is unsatisfiable.The reduction constructs an identical VAF to that of the previous theorem, but with one additional argument, {test},having η(test) = con and whose sole attacker is the argument Φ. Letting (cid:3)XΦ , AΦ , VΦ , η(cid:4)(cid:9) denote the resulting sys-tem, we claim that (cid:3)(cid:3)XΦ , AΦ , VΦ , η(cid:4)(cid:9), test, ∅(cid:4) defines a positive instance of OBA if and only if Φ is unsatisfiable. Fromthe proof of Theorem 8, test will fail to be acceptable with respect to any specific audience α for which Φ is admissi-ble. Such an audience exists if and only if Φ(Zn) is satisfiable. We therefore deduce that (cid:3)(cid:3)XΦ , AΦ , VΦ , η(cid:4)(cid:9), test, ∅(cid:4)is accepted as an instance of OBA if and only if Φ(Zn) is unsatisfiable. (cid:2)(cid:9)Proof of Theorem 10. For membership in Dp, define the language L1 to be{(cid:3)(cid:3)X , A, V, η(cid:4), R, S, x(cid:4): ∃α ∈ χ(R) such that x ∈ P ((cid:3)X , A, V, η(cid:4), α)}.Similarly, define L2 as{(cid:3)(cid:3)X , A, V, η(cid:4), R, S, x(cid:4): ∀α ∈ χ(S)x /∈ P ((cid:3)X , A, V, η(cid:4), α)}.Then (cid:3)(cid:3)X , A, V, η(cid:4), R, S, x(cid:4) is accepted as an instance of AAI if and only if it belongs to the set L1 ∩ L2. Since it isimmediate that L1 ∈ NP and L2 ∈ CO-NP this suffices to give AAI ∈ Dp.We prove that AAI is Dp-hard for the special case of R = {(cid:3)v, v(cid:9)(cid:4)} and S = {(cid:3)v(cid:9), v(cid:4)} for v, v(cid:9) distinct values in V.We first show that the problem Critical Variable (CV) is Dp-hard: instances of this comprise a CNF formula Φ(Zn)and a variable z ∈ Zn with instances accepted if there is a satisfying instantiation in which z = (cid:19) but no satisfyinginstantiation in which z = ⊥. To see that CV is Dp-hard we use a reduction from the Dp-complete problem SAT-UNSAT. Given an instance (cid:3)Φ1(Zn), Φ2(Zn)(cid:4) of this, the instance (cid:3)(cid:12), z(cid:4) of CV is simply (cid:3)(¬z ∨ Φ1) ∧ (z ∨ Φ2), z(cid:4)T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7167where z is a new variable. We note that for Φ in CNF, z ∨ Φ translates to the CNF formula in which every clause C ofΦ is replaced by the clause z ∨ C. It is easy to see that (cid:3)(¬z ∨ Φ1) ∧ (z ∨ Φ2), z(cid:4) is a positive instance of CV if andonly if (cid:3)Φ1(Zn), Φ2(Zn)(cid:4) is a positive instance of SAT-UNSAT: if Φ1 is satisfiable then (¬z ∨ Φ1) ∧ (z ∨ Φ2) has asatisfying instantiation with z = (cid:19) since it reduces to Φ1; if Φ2 is unsatisfiable then there is no satisfying instantiationwith z = ⊥ since the formula now reduces to Φ2, hence if (cid:3)Φ1, Φ2(cid:4) accepted as an instance of SAT-UNSAT then(cid:3)(¬z ∨ Φ1) ∧ (z ∨ Φ2), z(cid:4) is accepted as an instance of CV. Similarly, if (cid:3)(¬z ∨ Φ1) ∧ (z ∨ Φ2), z(cid:4) is a positiveinstance of CV then (¬z ∨ Φ1) ∧ (z ∨ Φ2) is satisfiable when z = (cid:19), i.e. Φ1 is satisfiable, and (¬z ∨ Φ1) ∧ (z ∨ Φ2)is unsatisfiable when z = ⊥, i.e. Φ2 is unsatisfiable.The proof that AAI is Dp-hard now follows easily, using the reduction of Theorem 8: given an instance (cid:3)Φ(Zn), z(cid:4)of CV form the VAF (cid:3)XΦ , AΦ , VΦ , η(cid:4) described in the proof of Theorem 8 (where we note that this trivially extendsto arbitrary CNF formulae). Set the audiences in the instance of AAI to be R = {(cid:3)posz, negz(cid:4)}.Finally fix the argument x to be Φ. Consider the resulting instance (cid:3)(cid:3)XΦ , AΦ , VΦ , η(cid:4), R, S, Φ(cid:4). If it is a positiveinstance of AAI then there is a specific audience α ∈ χ(R) for which Φ ∈ P ((cid:3)XΦ , AΦ , VΦ , η(cid:4), α): this specific(cid:4) ∈ R): it has already been seen that this indicates Φ(Zn) hasaudience must have posza satisfying instantiation with z = (cid:19). Similarly, if (cid:3)(cid:3)XΦ , AΦ , VΦ , η(cid:4), R, S, Φ(cid:4) is a positive instance of AAI, thenΦ /∈ P ((cid:3)XΦ , AΦ , VΦ , η(cid:4), α) for any specific audience in χ(S), i.e. all specific audiences within which negz(cid:10)α posz.From our earlier analysis, Φ(Zn) has no satisfying instantiation with z = ⊥.(cid:10)α negz (since (cid:3)posz, negz(cid:4)} and S = {(cid:3)negz, poszOn the other hand should (cid:3)Φ(Zn), z(cid:4) be a positive instance of CV then the argument of Theorem 8 yields a specific(cid:10)α negz i.e. α ∈ χ(R) for which Φ ∈ P ((cid:3)XΦ , AΦ , VΦ , η(cid:4), α) from a satisfying instantiation ofaudience α with poszΦ(Zn) with z = (cid:19). Similarly, the unsatisfiability of Φ(Zn) when z = ⊥ indicates that no specific audience α having(cid:10)α posz, i.e. those in χ(S), will result in Φ ∈ P ((cid:3)XΦ , AΦ , VΦ , η(cid:4), α). We deduce that (cid:3)Φ(Zn), z(cid:4) is a positivenegzinstance of CV if and only if (cid:3)(cid:3)XΦ , AΦ , VΦ , η(cid:4), R, S, Φ(cid:4) is a positive instance of AAI, thereby establishing that AAIis Dp-complete. (cid:2)Appendix B. Practical reasoning with valuesIn this appendix we will work through a detailed example of practical reasoning based on values. We will base ourconsiderations on a well-known problem intended to explore a particular ethical dilemma discussed by Coleman [15]and Christie [14], amongst others, and which has also been explored in full detail in [3]. The situation involves twoagents, called Hal and Carla, both of whom are diabetic. Hal, through no fault of his own, has lost his supply of insulinand urgently needs to take some to stay alive. Hal is aware that Carla has some insulin kept in her house, but Hal doesnot have permission to enter Carla’s house. The question is whether Hal is justified in breaking into Carla’s houseand taking her insulin in order to save his life. It also needs to be considered that by taking Carla’s insulin, Hal maybe putting her life in jeopardy. One possible response is that if Hal has money, he can compensate Carla so that herinsulin can be replaced. Alternatively if Hal has no money but Carla does, she can replace her insulin herself, sinceher need is not immediately life threatening. There is, however, a serious problem if neither have money, since inthat case Carla’s life is really under threat. Coleman argued that Hal may take the insulin to save his life, but shouldcompensate Carla. Christie’s argument against this was that even if Hal had no money and was unable to compensateCarla he would still be justified in taking the insulin by his immediate necessity, since no one should die because ofpoverty. Thus, argues Christie, he cannot be obliged to compensate Carla even when he is able to.The values of interest here are life and wealth. Life is demoted if Hal dies or if Carla dies, denoted as LH and LCrespectively. Wealth is demoted if Hal or Carla have to spend their money, denoted by WH and WC respectively. Wewill assume that everyone prefers life to wealth, but this still leaves a number of plausible value orderings to allow thearguments to be assessed differently by different audiences. These audiences areAud1 (LH=LC) (cid:10) (WH=WC)Aud2 LH (cid:10) LC (cid:10) WH (cid:10) WCAud3 LH (cid:10) WH (cid:10) WC (cid:10) LCAud4 LC (cid:10) LH (cid:10) WC (cid:10) WHAud5 LC (cid:10) WC (cid:10) LH (cid:10) WH.68T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71For audience 1, neither agent is preferred over the other: this may be seen as the standpoint of a neutral observer,or perhaps the “moral” audience. For audience 2, Hal is preferred to Carla, but Carla’s life is preferred to Hal’swealth. Adopted by Hal, this can been seen as self interested, preferring his own interests, but respecting Carla’s moreimportant interests over his own lesser interests. If Carla is this audience she may been seen as rather noble, givingway to Hal’s interests. Audience 3 prefers Hal to Carla in all respects: adopted by Hal this is purely selfish, adopted byCarla it is sacrificial. Audience 4 is like audience 2 but Carla is preferred, so that is can be adopted by a self interestedCarla or a noble Hal. Finally audience 5 represents a selfish Carla or a sacrificial Hal.Now let us consider the arguments that can be advanced in this scenario. In [3] the arguments are generated usinga particular argument scheme and critical questions, but here we will simply summarise the arguments.A1 Hal should take the insulin to avoid demoting LH.A2 Hal should not take the insulin to avoid demoting LC.A3 Hal should compensate Carla to avoid demoting LC.A4 Carla has money.A5 Carla should buy insulin to avoid demoting WH.A6 Carla has no money.A7 Carla should not buy insulin to avoid demoting WC.A8 Hal has money.A9 Hal has no money.A10 Even if Carla has money, Hal should not take the insulin to avoid demoting WC.A11 Even if Hal has money, Hal should not compensate Carla to avoid demoting WH.A12 Carla should buy insulin to avoid demoting LC.Arguments A4 and A6 and arguments A8 and A9 are simply assertions of the fact. Carla will know which of A4and A6 is true and Hal will know which of A8 and A9 are true. Since all arguments are associated with some value,cf. Definition 2, following [7], a value “(cid:19)” (for true) is associated with such factual assertions, the value (cid:19) alwaysbeing preferred to any other value. The attack relationships are shown in Table 1.This can be represented diagrammatically as shown in Fig. 4.We can now consider how this might be worked out in practice. Consider first the case where both have money.First we need to partition the arguments.All parties will need to accept what they know to be true: thus Hal must accept argument A8 and Carla will needto accept argument A4. In addition Hal will desire to accept argument A1 to avoid dying, and Carla will wish tobe compensated and so will desire to accept A3. Hal will wish to reject A2 and A10. To find an audience which isacceptable to both therefore we must have {A1, A3, A4, A8} as desired and {A2, A10} as rejected.We can now play the dialogue game to determine the audiences of which Hal and Carla will form part if they areto be in agreement.Table 1Attack structure ((cid:3)row, column(cid:4) = X denotes Arow is attacked by Acol)A1A2XA3XXA4XXA1A2A3A4A5A6A7A8A9A10A11A12A5A6A7A8A9XXA10XA11A12XXXXXXXXXT.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7169Fig. 4. VAF generated by Hal–Carla example.= [PRO, (cid:3)A1, ∅(cid:4)]μ01= [PRO, (cid:3)A3, ∅(cid:4)]μ02= [PRO, (cid:3)A4, ∅(cid:4)]μ03= [PRO, (cid:3)A8, ∅(cid:4)]μ04μ1 = [OPP, (cid:3)A10, ∅(cid:4)]μ2 = [PRO, (cid:3)_, (cid:3)LH, WC(cid:4)(cid:4)]μ3 = [OPP, (cid:3)A11, ∅(cid:4)]μ4 = [PRO, (cid:3)_, (cid:3)LC, WH(cid:4)(cid:4)].(W2)(W2)The set {A1, A3, A4, A8} is hence a position with respect to the audience that contains LH(cid:10)WC and LC(cid:10)WH. Thiswill exclude selfish and sacrificial agents.Suppose, however, that Hal additionally desires to hold on to his money and so moves arguments A5 and A11 tohis desired set, whilst removing A3. Now the audience (which will not now be able to include Carla, who rejects A11and desires A3) following the dialogue= [PRO, (cid:3)A1, ∅(cid:4)]= [PRO, (cid:3)A4, ∅(cid:4)]= [PRO, (cid:3)A5, ∅(cid:4)]= [PRO, (cid:3)A8, ∅(cid:4)]= [PRO, (cid:3)A11, ∅(cid:4)]μ01μ02μ03μ04μ05μ1 = [OPP, (cid:3)A7, ∅(cid:4)]μ2 = [PRO, (cid:3)_, (cid:3)WH, WC(cid:4)(cid:4)]μ3 = [OPP, (cid:3)A10, ∅(cid:4)]μ4 = [PRO, (cid:3)_, (cid:3)LH, WC(cid:4)(cid:4)](W2)(W2)becomes LH(cid:10)WC and WH(cid:10)WC; the set {A1, A4, A5, A8, A11} is thus a position with respect to this audience. NowHal must be either selfish or self-interested.Finally we can return to the positions of Coleman and Christie mentioned above. Recall that Coleman wished toinsist that Hal should compensate Carla or not take the insulin. Now, when Hal has no money (i.e. argument A9 holds),Hal should not, on Coleman’s view, take the insulin. Thus the desired arguments for Coleman in this situation will be{A2, A9} and he will wish to reject {A1}. Christie, in contrast, thinks that Hal should take the insulin even if he cannotcompensate: his desired arguments when Hal has no money are therefore {A1, A9}, and he will want to reject {A2}.Playing the dialogue game with Coleman’s partitioning we get70T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–71= [PRO, (cid:3)A2, ∅(cid:4)]μ01= [PRO, (cid:3)A9, ∅(cid:4)]μ02μ1 = [OPP, (cid:3)A5, ∅(cid:4)]μ2 = [PRO, (cid:3)_, (cid:3)LC, WH(cid:4)(cid:4)]μ3 = [OPP, (cid:3)A4, ∅(cid:4)]μ4 = [PRO, (cid:3)A6, ∅(cid:4)](W2)(W1)that is, argument A6 (Carla has no money) is part of Coleman’s position along with A2 and A9, and Coleman’saudience is LC(cid:10)WH. This excludes only selfish Hals and sacrificial Carlas.And with Christie’s= [PRO, (cid:3)A1, ∅(cid:4)]μ01= [PRO, (cid:3)A9, ∅(cid:4)]μ02μ1 = [OPP, (cid:3)A10, ∅(cid:4)]μ2 = [PRO, (cid:3)_, (cid:3)LH, WC(cid:4)(cid:4)]μ3 = [OPP, (cid:3)A2, ∅(cid:4)]μ4 = [PRO, (cid:3)A12, ∅(cid:4)]μ5 = [OPP, (cid:3)A6, ∅(cid:4)]μ6 = [PRO, (cid:3)A4, ∅(cid:4)](W2)(W1)(W1)that is, argument A4 (Carla has money) and A12 (Carla should buy insulin to avoid demoting LC) form part ofChristie’s position along with A1 and A9, and Christie’s audience is LH (cid:10) WC. This excludes selfish Carlas andsacrificial Hals. Thus the point of contention between Coleman and Christie is whose interests we might be allowedto favour. If it is necessary to choose, Coleman will favour Carla and Christie will favour Hal.This small example shows how our approach can be applied to a situation in which agents have competing interests,and in which commentators have expressed different intuitions. These different intuitions can be understood in termsof the differing audiences represented by the different orderings on values.References[1] L. Amgoud, C. Cayrol, A reasoning model based on the production of acceptable arguments, Annals of Mathematics Artificial Intelligence 34(2002) 197–215.[2] K. Atkinson, What should we do?: Computational representation of persuasive argument in practical reasoning, PhD thesis, Dept. of ComputerScience, The University of Liverpool, December 2005.[3] K. Atkinson, T. Bench-Capon, Addressing moral problems through practical reasoning, in: L. Goble, J.-J.Ch. Meyer (Eds.), Deontic Logicand Artificial Normative Systems (Proc. DEON’06), in: Lecture Notes in Artificial Intelligence, vol. 4048, Springer-Verlag, Berlin, 2006,pp. 8–23.[4] K. Atkinson, T. Bench-Capon, P. McBurney, Arguing about cases as practical reasoning, in: Proc. 10th ICAIL, ACM Press, New York, 2005,pp. 35–44.[5] K. Atkinson, T. Bench-Capon, P. McBurney, Multi-agent argumentation for edemocracy, in: M.P. Gleizes, G. Kaminka, A. Nowé, S. Ossowski,K. Tuyls, K. Verbeeck (Eds.), Proc. 3rd EUMAS, 2005, pp. 35–46.[6] K. Atkinson, T.J.M. Bench-Capon, P. McBurney, Justifying practical reasoning, in: F. Grasso, C. Reed, G. Carenini (Eds.), Proc. of the 4thWorkshop on Computational Models of Natural Argument (CMNA 2004), ECAI 2004, 2004, pp. 87–90.[7] T. Bench-Capon, K. Atkinson, A. Chorley, Persuasion and value in legal argument, Journal of Logic and Computation 15 (2005) 1075–1097.[8] T.J.M. Bench-Capon, Agreeing to differ: Modelling persuasive dialogue between parties with different values, Informal Logic 22 (3) (2002)231–245.[9] T.J.M. Bench-Capon, Persuasion in practical argument using value-based argumentation frameworks, Journal of Logic and Computation 13 (3)(2003) 429–448.[10] A. Bondarenko, P.M. Dung, R.A. Kowalski, F. Toni, An abstract, argumentation-theoretic approach to default reasoning, Artificial Intelli-gence 93 (1997) 63–101.[11] C. Cayrol, S. Doutre, M.-Ch. Lagasquie-Schiex, J. Mengin, “Minimal defence”: a refinement of the preferred semantics for argumentationframeworks, in: Proc. NMR’2002, 2002, pp. 408–415.T.J.M. Bench-Capon et al. / Artificial Intelligence 171 (2007) 42–7171[12] C. Cayrol, S. Doutre, J. Mengin, Dialectical proof theories for the credulous preferred semantics of argumentation frameworks, in: 6th Euro-pean Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU-2001), in: Lecture Notes in ArtificialIntelligence, vol. 2143, Springer-Verlag, Berlin, 2001, pp. 668–679.[13] C. Cayrol, S. Doutre, J. Mengin, On decision problems related to the preferred semantics for argumentation frameworks, Journal of Logic andComputation 13 (3) (2003) 377–403.[14] G. Christie, The Notion of an Ideal Audience in Legal Argument, Kluwer Academic, Dordrecht, 2000.[15] J. Coleman, Risks and Wrongs, Cambridge University Press, Cambridge, 1992.[16] S.A. Cook, R.A. Reckhow, The relative complexity of propositional proof systems, Journal of Symbolic Logic 44 (1) (1979) 36–50.[17] Y. Dimopoulos, A. Torres, Graph theoretical structures in logic programs and default theories, Theoretical Computer Science 170 (1996)209–244.[18] S. Doutre, T.J.M. Bench-Capon, P.E. Dunne, Explaining preferences with argument positions, in: Proc. IJCAI-05, 2005, pp. 1560–1561.[19] P.M. Dung, On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games,Artificial Intelligence 77 (1995) 321–357.[20] P.M. Dung, R.A. Kowalski, F. Toni, Dialectic proof procedures for assumption-based, admissible argumentation, Artificial Intelligence 170(2006) 114–159.[21] P.E. Dunne, T.J.M. Bench-Capon, Coherence in finite argument systems, Artificial Intelligence 141 (2002) 187–203.[22] P.E. Dunne, T.J.M. Bench-Capon, Two party immediate response disputes: properties and efficiency, Artificial Intelligence 149 (2003) 221–250.[23] P.E. Dunne, T.J.M. Bench-Capon, Complexity in value-based argument systems, in: Proc. 9th JELIA, in: Lecture Notes in Artificial Intelli-gence, vol. 3229, Springer-Verlag, Berlin, 2004, pp. 360–371.[24] P.E. Dunne, T.J.M. Bench-Capon, Identifying audience preferences in legal and social domains, in: Proc. DEXA’04, in: Lecture Notes inComputer Science, vol. 3180, Springer-Verlag, Berlin, 2004, pp. 518–527.[25] A. Hunter, Towards higher impact argumentation, in: Proc. of the 19th American National Conference on Artificial Intelligence (AAAI’2004),MIT Press, Cambridge, MA, 2004, pp. 275–280.[26] H. Jakobovits, D. Vermeir, Dialectic semantics for argumentation frameworks, in: Proc. ICAIL-99, 1999, pp. 53–62.[27] National Forensic League, Tournament handbook, 2006; http://www.nflonline.org/uploads/NationalTournament/ntman.pdf.[28] C. Perelman, L. Olbrechts-Tyteca, The New Rhetoric: A Treatise on Argumentation, Univ. of Notre-Dame Press, 1969.[29] J.R. Searle, Rationality in Action, MIT Press, Cambridge, MA, 2001.[30] G. Vreeswijk, H. Prakken, Credulous and sceptical argument games for preferred semantics, in: Proceedings of JELIA’2000, The 7th EuropeanWorkshop on Logic for Artificial Intelligence, in: Lecture Notes in Artificial Intelligence, vol. 1919, Springer-Verlag, Berlin, 2000, pp. 224–238.[31] D.N. Walton, Argument Schemes for Presumptive Reasoning, Lawrence Erlbaum Associates, 1996.