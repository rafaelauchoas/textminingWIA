A&i&l Intelligence 75 ( 1995) 63-92 Artificial Intelligence CLIP: concept learning from inference patterns Ken’ichi Yoshida *, Hiroshi Motoda Advanced Research Laboratory. Hitachi, Ltd., Hatoyama, Saitama, 350-03 Japan Abstract A new concept-learning method called CLIP (concept learning from inference patterns) is proposed that learns new concepts from inference patterns, not from positive/negative examples that most conventional concept learning methods use. The learned concepts enable an efficient inference on a more abstract level. We use a colored digraph to represent inference patterns. The is expressive enough and enables the quantitative analysis of the inference graph representation pattern frequency. The learning process consists of the following two steps: ( 1) Convert the original inference patterns to a colored digraph, and (2) Extract a set of typical patterns which appears frequently in the digraph. The basic idea is that the smaller the digraph becomes, the smaller the amount of data to be handled becomes and, accordingly, the more efficient the inference process that uses these data. Also, we can reduce the size of the graph by replacing each frequently appearing graph pattern with a single node, and each reduced node represents a new concept. Experimentally, CLIP automatically generates multilevel representations from a given physical/single-level representation of a carry-chain circuit. These representations involve abstract descriptions of the circuit, such as mathematical and logical descriptions. 1. Introduction Human beings use various abstract concepts, such as logic and mathematics, to ac- quire new knowledge. These concepts are crucial to achieve scientific and technical breakthroughs. We also use various concepts in daily life. For example, we sometimes complain, He is too stubborn CO negotiate. In this case, stubborn represents a certain characteristic of the person, and we can deduce some conclusion, such as Find another person to discuss the problem, without considering the details. How do human beings acquire these “concepts”? * Corresponding author. OOO4-3702/95/$G9.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00066-2 64 K. Yoshidu. H. Motodu/ArtiJiicial Intelligence 75 (1995) 63-92 Cin Fig. I. Carrychain circuit some answer to this question and representing it on a computer system is an Finding important theme in artificial this question intelligence. in more detail, we use qualitative [4] circuit simulation simulation To examine all displaying the qualitative the dependency information, among in current, voltage, etc. Note that Figs. 2(a), 2(b) them being is randomly generated, example of the concept utilization. Fig. 1 shows a carry-chain of the CPU, and Fig. 2 shows i.e., the changes the same difference each datum from other data. In Fig. 2(b), The X-axis mythical words, Fig. 2(b) uses some knowledge shown in Fig. 2(a). Fig. 2(c) also uses specific knowledge about the carry-chain here, the NOT circuit data are located circuit data are located below. traces as an [9] which is part results of its behavior, show and 2(c) the only the location of is calculated the spatial allocation of the data is selected by hand. from along with the name of the data. In other to lay out the data circuit, in the upper portion of the figure, and the NOR in the layout of the data. In Fig. 2(a), and the arrows display how a datum [4], and the Y-axis is sorted using about qualitative simulation is sorted using the data, with the simulation the time-step information causality among Which jigure is best.7 in which Fig. 2(a) imagine a situation the data dependency between is the best figure. It seems to be the best in various situations, the data or to memorize We think Fig. 2(c) to explain cannot Fig. 2 shows are for the physical behavior of circuits, such as the changes and currents, we seem to use abstract-level circuits, unnecessary and abstract-level complexity. e.g., the whole structure. We the data that in voltages concepts, such as the behavior of NOR/NOT details by giving a new concept name to understand are crucial of phenomena, figure by reducing to the aggregation this complex the figure. Here, we use abstract-level is the best to use. Although in understanding to leave out concepts concepts Based on the above introspection, we assume that A concept is something which makes inference easiel; K. Yoshida, H. Motoda/Ar@cial Intelligence 75 (1995) 63-92 65 (a) Naive Inference Pattern (b) Sorted by Qualitative Reasoning Knowledge (c) Sorted by Circuit Knowledge Fig. 2. Example of concept usage. 66 K. Yoshida, H. Motoda/Artijicial Intelligence 75 (I 995) 63-92 learning this assumption, CLIP analyses that satisfy typical patterns to a new abstract concept by use of which inference and propose a new concept-learning method, concept from inference patterns (CLIP). To find new concepts inference processes and tries to extract from them. Each extracted pattern corre- sponds is made efficient due to the is that it does not require any reduced complexity. CLIP’s most important characteristic prespecified knowledge about abstract concepts. For example, CLIP analyses qualitative simulation in voltage and current) of the digital circuits, and finds the logical concepts, such as NOR and NOT, without being logic. Here, the concepts NOR and NOT are generated provided any knowledge to achieve an efficient traces of the physical behavior (i.e., the changes Another important is that it also generates a set of rules to about inference. characteristic these and of CLIP interpretation interpret new concepts, This distinguishes CLIP from conventional [ 31, which do not aim to make inference at the abstract concept level. rules enable abstract-level learning methods, inference. such as that in is organized for extracting The rest of the paper CLIP and the algorithm mental their structures with additional experimentation. future Section 6 discusses results. Section 4 analyses as follows: Section 2 outlines idea of typical patterns, and Section 3 presents experi- the factors which affect the generated concepts and related work, Then, Section 5 examines the basic issues, and Section 7 summarizes the results, 2. Concept learning based on colored digraph representation inference inference the sample to represent CLIP analyzes in such a way that the new patterns can be used to make the inference more efficient. The learning process is outlined as follows: l First, sample traces and extracts patterns to or produced by the inference, traces. Each graph node represents traces of the inference are converted into a colored digraph. We use the and the direction of the graph edge the direction of the inference. Each node has two kinds of color. The rule that is used to calculate to the value itself. In the to the circuit equation number (more the circuit rule that is used to interpret to the value of the voltage, current, etc. analysis of the inference pattern a colored digraph data referred represents tirst color corresponds the value of the data, and the second color corresponds circuit domain, precisely, equation), This graph representation frequency. the first color corresponds the identifier of the interpretation and the second color corresponds to the identifier of the inference the quantitative enables l Next, based on the frequency algorithm extracts a set of typical patterns which frequently analysis of the inference pattern, a parallel-search appear in the digraph. The basic idea is: l We can reduce the size of the graph by replacing each frequently appearing graph that appears often in an inference process pattern with a single node. Any pattern probably represents an important concept. l The size of the graph corresponds the inference engine. Accordingly, to the amount of data referred to or produced by traces as the graph converted from the inference K. Yoshida, H. MotodalArtijicial Intelligence 75 (1995) 63-92 67 Shallow Level Inference (OUTPUn Power [OnI Inwt~ Q1 02 a3 Q4 05 WI [Ll WI N WI Find Typical Inference Pattern Deep Level Inference (INPUT) 1 Power vcc Ql Vl (HI WI I1 a2 Vl [HI IL1 [Ll P-1 IHI WI WI [L] 13 Q4 v4 [L] 12 a3 v3 ,4 Q5 [H] [L] Fig. 3. CLIP: concept learning from inference patterns. becomes smaller, the inference becomes easier. Fig. 3 summarizes this idea. The upper left part of Fig. 3 shows a simple digital circuit, and the lower part shows the inference trace that analyzes the physical behavior of the circuit. The graph edge in the lower part shows the data dependency. The numeral in each node indicates which of the interpretation rules (see Section 3.2) is used in that node to derive the value of the variable (vi, lit Qi+ etc.) attached to the node. For example, the value of the voltage VI is calculated from the electric charge Ql using Rule 2 in Fig. 3, and the value of the current I1 is calculated from voltages Vj and V,, using Rule 3. CLIP analyzes this inference trace and extracts typical patterns, such as The rule sequence 2, 3 and 4 is frequently used befare Rule I, from the graph. CLIP’s output for this case is summarized in the upper right part of Fig. 3. Here, the new inference Rule 5 is used to calculate the electric charge Qz from Ql, and the smaller amount of data in the inference process decreases the cost of the inference. Furthermore, the correspondence of the new Rule 5 and the original rule sequence 1, 2, 3 and 4 can be used to restore the original information involved in the lower graph from the upper right graph. Note that the pattern found by CLIP corresponds to the new abstract concepts which are not explicitly represented in the original graph. In Fig. 3, the lower part of the graph represents the inference process about the physical quantities, such as the voltage and the current, and the upper right graph represents the inference process about the logical values (here, [H/L] corresponds to [True/False] ). The lower part of the graph does not have any explicit information about logical behaviors. The extraction of patterns is solely based on finding repetitions of inference pat- terns in a colored graph, and no semantics are considered. This makes CLIP domain- independent. ’ * See. [ 171 for a recent study on other aspects and other application domains of CLIP. 6X K. Yoshidu, H. Motodu/Artijiciul Intelligence 75 (I 995) 63-92 Inference Pattern Colored Digraph. Diqraph in Tab!e Fig. 4. Inference pattern, colored digraph and representation. 2.1. Colored digraph representation reasoning discussion, we use qualitative the target object. For an electric circuit, reasoning system we used employs In the following traces. The qualitative [2] the entity to represent such as the voltage or the current at a node, and the relationship is a circuit equation is performed by interpreting new values of the physical data. We also use a set of interpretation how to use the circuit equations describe traces as the input inference the entity-relationship model is a physical datum, the entities between of the physical data. The inference i.e., the circuit equation, and calculating to describe a new value for each datum. These rules the relationships the relationship, for qualitative that describes in calculating simulation. rules the inference method Fig. 4 shows an inference pattern, the corresponding colored digraph representation, used to implement the CLIP program. In Fig. 4, the value of i.e., V, is calculated and the table representation Data (I), Data (m) corresponds the interpretation ordered, and this edge position use the information Fig. 5 shows partial about the edge position.) results of qualitative to Node (m), and from the value of Data (m) and Data (n) using Rule (L). identifies the color of the node, Color(R), edges are the incoming (See Sections 2.2.1 and 3.3 for how to the data value. Here, is also stored. rule used to calculate circuit. The the value of the data and the data. The right-side graph shows the qualitative values simulation rule used to calculate for a carry-chain left-side graph shows the interpretation the data dependency of the data. Similarly between to Fig. 2(c), from the simulation along with mythical causality, and the Y-axis is sorted using the name of the data. The leftmost names, e.g., v-op, i-c-oppd, etc., are the names of the data. The color rule of the graph node (*, 0, etc. in Fig. 5) in the left-side the interpretation is sorted using the time-step information the X-axis indicates K. Yoshida, H. Motoda/Artijicial Intelligence 75 (I 995) 63-92 69 I-c-olpdl l-8-Olpdl v-tout Iz:: LO1 LOI 101 101 fO1 IO1 Fig. 5. Sample input digraph. used to calculate the data. The qualitative values shown in the right-side are: [ +] , [ 01, [-I, [s-_I, and [vs-_I. +), the value of the data, and the arrows show the dependency [vs+](very small +), between (small [s+] rules calculate This graph contains the information about how the interpretation the upper-most part of Fig. 5 shows (first line, first value), and the current (the 34th line) and the interpretation first line, second value) of v-op. In Fig. 5, the interpretation about data dependency, as well as information the output values from inputs. For example, is [0] i-e-oppu the next value ( [s+] that: the initial value of the voltage v-op i-c-oppd (the second line of the figure), rule El are used to calculate : is used nine times. By analyzing relationship) of these occurrences, we can extract a qualitative relationship. I.e., “[vs-]+[s+]+[s+]“, missing corresponds rule “[O]+[s+]+[s+]“, such as “[ --I + [ 0] + [ -1” to the input graph. the extracted relationship this case, In rule 0 (qualitative inference rule about the values of the variables inference rule about is a subset of the additive and “[-]+[s+]-[-I”, is not necessary for the inference the additive in each the additive relationship, and the that The same technique larger patterns, and this is what CLIP to extract basically does. We can use the graph shown in Fig. 5 as the input graph. Since different there can be more traces are obtained for the same circuit, can be applied initial values for different 70 K. Yoshidu, H. Motoda/Arfijicial Intelligence 75 (1995) 63-92 than one trace. CLIP can take as many graphs as necessary. Hereafter, we call these graphs collectively large graph or a collection of small graphs. i.e., the input graph can be a single an input graph, The CLIP user may select a subset of a graph to be processed by CLIP It may help is from a graph that represent certain the amount of data. However, such preprocessing it learns new concepts to CLIP because to speed up learning by decreasing not crucial characteristics of the environment, and thus, examples are embedded Note that the spatial allocations of the nodes are carefully in Fig. 5. CLIP uses only topological in the graph. selected by hand on the and does information in Fig. 2(a), and does not use domain-specific information. In other words, CLIP only uses information such as knowledge knowledge alone basis of readability not have the benefit of visual involved about the carry-chain circuit. 2.2. Algorithm for finding typical patterns (See Section 3.2 for details.) After the learning problem is encoded as a colored digraph, is interpreted the algorithm, called CLIP, for performing amenable rule. (See Fig. 6.) Each pattern typical patterns. rule, and as an interpretation describe in detail search algorithm, to parallel in the colored digraph. The objective graph. In order to assist in the choice of desirable for comparing alternative procedure one. focuses on obtaining rewritten graphs is provided implementation, is to find typical patterns the key step is to extract in two ways: as an EBL macro In this section, we this task. CLIP is a beam- that searches for typical patterns the typical patterns, a selection criterion to the CLIP algorithm. The search the optimal that help rewrite a reasonably good solution, not necessarily Two different data structures, View and Pattern, are used to store the set of candidate In to a certain patterns. Here, a Pattern stores a single pattern, and a via0 stores a set of patterns.2 the digital circuit domain, Pattern stores a graph pattern circuit behavior, e.g., behavior of NOR and NOT. viav stores a set of these Patterns. that corresponds The method involves tion and View Selection. the view by the first two operations input parameter rewritten using patterns of the CLIP procedure to specify involves three basic operations: Pattern Modijcation, Pattern Combina- in It starts with N views, and iteratively extends (the old patterns are also retained) _ Here, N is an is the good views are retained. The heart the beam search width. In each iteration, in each view and only the input graph the patterns iteratively performing these basic operations. 2.2.1. Pattern Modification In Pattern Modijcation, to the patterns is replaced by a single node reduces (Figs. 7(a) the size of the graph by replacing first a view is selected and the digraph in the selected view. Each occurrence of the pattern is rewritten according in the input graph procedure each complex graph pattern with a single and 7(b)). This graph-rewriting ’ The current program uses an array structure to implement View, and a special Pattern, called null pattern, is used to indicate the absence of the pattern in the View. K. Yoshida, H. Motoda/Art$icial Intelligence 75 (1995) 63-92 71 flnltielize 3 Input : Selectton CrkWlon Colored Digmph -W Fig. 6. Algorithm.The mark in View Selection indicates the result of graph rewriting: 0 for good, and n for intermediate. x for bad Reduced Colored Digfaph Mgraph ( Before Rewriting ) Digraph ( After Rewriting ) Fig. 7. Digraph rewriting by pattern substitution. 12 K. Yr,shida, H. Motoda/Artijicial fnrelligence 75 (1995) 63-92 node. Accordingly, the inference becomes easier. as the graph converted from the inference traces becomes smaller, Note that this graph-rewriting three ways: following operation is different from the graph contraction in the all possible ( I) Standard graph-matching methods check the equivalence of two graphs by con- In our algorithm, however, we adopt edges are ordered, and edges is examined. An important time. In in polynomial edge combinations. identity as our matching criterion. The incoming sidering graph only the equivalence between implication contrast matching based on graph Nodes). This restriction does not seem to limit the algorithm can handle. identity has a time complexity of this is that graph-matching to matching based on graph (an NP-complete problem), of tasks that the class of learning that is O(Number the corresponding can be done isomorphism (2) The graph-matching procedure also checks the matching efficient by further pruning the equivalence the candidates. of node color. This (3) also makes If the data from the intermediate (Fig. 7(a) ), the original node is retained. graph node is used to calculate another value Fig. 8 shows how patterns are modified to as temporary patterns. Each such temporary pattern and every possible pattern made up of two linked nodes are referred based on patterns three new views, each with two patterns, are generated patterns pattern expanded pattern does not rewrite all the occurrence of the original pattern. in this step. The reduced graph is analyzed is considered. These patterns is then expanded in the current view, and used to create new views. In the example, from the current view. Note that in the new views. By rewriting an expanded the original pattern, we get a smaller graph even if the in the parent view are also stored first and then rewriting the circuit domain, node color corresponds In precisely, interpretation circuit equation which which corresponds this color (See Section 3.2 for this color). (more to a new from original equations. CLIP also uses node color to the value of the data. However, pattern modification does not use rule number). The new color, therefore, corresponds is translated to circuit equation number If the capacity of the view is exceeded, CLIP discards the result of (frequency of usage) from ijcution modifies Pattern modifies only one pattern, and therefore, multiple complex pattern, e.g., a pattern x in a stepwise manner. A single that corresponds low-priority patterns judging (size of pattern). Note that Pattern Mod- invocation of this operation invocations are required to generate a to NOR/ NOT circuits. 2.2.2. Pattern Combination Pairs of existing views are combined to obtain new views. All possible combinations are considered. Again, discarded. if the capacity of the view is exceeded, low-priority patterns are 2.2.3. View Selection Estimates are obtained be expected after rewriting the input graph using patterns for each view as to how much reduction in graph size can in that view, and only highly K. Yoshida. H. Motoda/Artijicial Intelligence 75 (1995) 63-92 13 input Digraph Current View Fig. 8. Pattern modification. ranked views are chosen, up to the allowable number of views. Note that the definition of the graph size is an important input for CLIP By changing this definition, CLIP can find various concepts from the same inputs. (See Section 4 for the details.) Fig. 9 illustrates how patterns evolve through iterations. In this example, the maximum number of views is limited to 4. In the first iteration, starting from null patterns, the pattern-modification step generates three views, each containing one pattern that consists of two nodes (e.g., l-2). In succeeding iterations, in addition to pattern modification, pattern combination is also performed. In pattern modification, all patterns in all views are considered in turn as candidates for modification. In each case, a new view is created consisting of the modified pattern appended to the original view. View selection is done after the pattern-modification and combination steps. The view-selection step selects the best N views (maximum number of views, which is a search parameter; 4 in Fig. 9) in each iteration. View selection is based on estimates of the relative effectiveness of views in graph- rewriting. These estimates are computed as follows: For each of the views Vprev;ous (that were selected in the previous iteration), the actual size C~xo~~( Vpmious) of the rewritten graph that results from applying patterns in that view to the graph is calculated at the beginning of the current iteration. For each new view Vcurmnr that is generated in the pattern-modification step, the estimated size C’Estimte ( V,,,,,) of the rewritten graph that would result from applying that view is calculated as a perturbation to the actual size of the rewritten graph due to the parent view Vprpyious. The graph size for views generated in the pattern-combination step is estimated as a linear combination of the two views involved in the combination. 14 K. fiuhida, H. Motoda/Arti$cial Intelligence 75 (1995) 63-92 2’nd Iteration 3’rd Iteration P.Modification PModification 1’s Iteration X (NULL L (NVLL (NULL vi4Bmww wevpmm ‘The mark at t,he upper left of each view indicates the result, of graph rewriting: () for good, x for bad and A for intermediate. A large mark indicates a result, based on actual rewriting of the graph; a small one. on estimation. Fig. 9. Data flow. The estimated size and the actual size (calculated at the beginning of the next itera- tion) may not agree. (See the difference between big and small marks at the top left of each view in Fig. 9.) However, that good views are usually of the actual size is computationally modification is necessary because computation in pattern expensive. The graph size is estimated selected. The estimation is reasonable the estimate to ensure process enough by CEstimote ( bmw~r 1 = ( 1 .O - a x F) x CErmt( Vprevious)~ F= Number of occurrences of temporary patterns @ -+ @ Number of occurrences of nodes B 0 In the case of the pattern combination, CEstimate ( bmxmr 1 = ( 1 - PI x CEmct( VPrrviousl 1 + P x CEma( breoious2) 7 for the experiments. step (see Fig. 8)) and is limited where cy and /I are input parameters the values and the results.) Note that graph-rewriting modification graphs were actually be required 15 (see Section 3.2). Obviously, (See Sections 3 and 4 for is performed only at the pattern- to the maximum number of views. If the rewritten during view selection, more than 500 rewritings would in circuit domain examples, while the maximum number of views was set at represents a great cost saving. in this section can be seen as a kind of genetic to Chromosome, Pattern to Gene, Pattern Mod- [ 71. Here, View corresponds then this size prediction algorithm explained The pattern-finding algorithm K. Yoshida, H. Motoda/Art$cial Intelligence 75 (1995) 63-92 15 Input Digraph (Subgraph) NOR / NOT (Analog) No more Improvement (6 min.) Fig. 10. Experimental result (resulting digraph) @cation to Mutation, Pattern Combination to Crossover, graph size to jitness function, and View Selection to Selection. 3. Outline of experimental results 3.1. Input and parameters We implemented the pattern-finding algorithm CLIP, described in the previous sec- tion, using the C programming language. An example of the graph-rewriting process performed by CLIP is shown in Fig. 10. The input graph was converted from the results of a qualitative simulation of the behavior of the carry-chain circuit shown in Fig. 1. The total number of nodes in the input graph was 2176 and the total number of edges was 2144. The carry-chain circuit has three boolean inputs, and the input graph involves the simulation results of eight (= 23) cases. The left-most part of Fig. 10 shows a subset of the input graph that corresponds to one such input case. The qualitative values used in the qualitative simulation are: [ +], [O], [-I, and [ vs-_I. By using this information [s+] (small +), [s-l, about the magnitude of the value, the qualitative simulation system can express infor- mation such as: The current through the pull-up transistor is smaller than the current through the pull-down transistor. [ vs+] (very small +), The graph size was evaluated using the following equations: c Exact = Number of Nodes + Number of Edges +x (N umber of I/O Combinations of the Interpretation Rule,)’ (N umber of Inputs to the Pattern,)* +c - Number of Graph-Rewritings. (1) C,Qimte for Pattern Modijkation = ( 1.0 - 0.1 X F) X CEwct(brevi0u.v) 9 76 K. tiuhidu. H. Motodu/Artijiciul Inrellipmx 75 (1995) 63-92 cb?,ul~ for Pattern Combination = the smaller first With this definition, the rewritten digraph becomes, (1) in Eq. represents the second combinations the numbers the matching required term term represents the amount of memory of I/O ference cost becomes. The be handled; third term represents For example, and NOR are 2 (“1False+True” “TrueVFalse+False”, the view is made up of two patterns each corresponding term becomes 20 (= 22 + 42). As with the first term, an increase in increased memory usage. Increasing cost to use the interpretation For example, becomes 5. ’ and “TTrue+False”) “FalseVTrue+False” term represents of the and “TrueVTrue*False”), the less the the amount of data in- to the inference. The rules. rule of NOT cost during to store the interpretation interpretation and 4 (“FalseVFalse+True”, respectively. If to NOR and NOT, the third in this term results the matching cost. term that matching the NOT receives 1 datum, and NOR receives 2 data, so the fourth rules, and the fourth the amount of input data increases found are not big enough The last term is to accelerate the patterns in the third and fourth term is to enforce used to rewrite term can be neglected because a pattern which results to result in small values for the first and the second the pattern search. In the early iterations of the search, reduce the graph size, and increases the search process. The purpose of this the frequently occurring patterns the effect of this in a great reduction of size tends the input graph. In the later iterations of the search, terms sometimes hinder the succeeding to sufficiently that follows search terms. 3.2. Results We set the maximum number of patterns per view at 7 and the maximum number of views per iteration at 15. In an experiment with 50 iterations, size was reached at the 25th iteration. The right-most part of Fig. 10 shows the graph generated in a later iteration. The pattern Increases in the third and fourth is bigger than that of the 25th iteration. further improvement. found terms prevent the minimum In Fig. I f, we show an example of a typical pattern extracted (lower corresponding macro/interpretation for this 6-node pattern was about 6 minutes on a IO-MIPS computer. The corresponding equations used during rules (right) at the 25th iteration. Computation the simulation relate to ( 1) voltage changes at the terminal, (2) voltage changes at the terminal caused by the incoming current, (3) collector and emitter currents (4) emitter current and base voltage, (5) collector current and V&, and (6) knowledge about VCC. in the transistor, 3 Note that both the number of nodes and edges were about 2000, and the number of I/O combinations and inputs of the pattern were I - IO. To compensate for the difference of the order of magnitude of the term value. the third and fourth terms are squared. left) and the time K. Yoshida, H. MotodalAriijicial Intelligence 75 (1995) 63-92 II Macro Rule for a New Concept Component IF a...Vnext=V+dV Q . . . dV = I1 + 12 0 . . . I1 = -le @ . . . le+Vb @ . . . I2+Vcc cp . . . vcc = [+] Then Vnext = NEW(Vb, V) Interpretation Rule for the above Concept Component Vnext = NEW(Vb, V) . = [+] / [+I / [+] / [Ol ! 101. . = [O] I [s+] / [+I / [s+l/ [+I. Then Vnext= [O] / [O] I is+]/ [+I I [+I. Fig. 11. Resulting patterns. Eqs. (3) and (4) are for a pull-down up transistor. The variables on the right-hand portion of the extracted concept correspond and 2 going into the node 0 to the numbers ) . The macro rule says that if there is a set of 6 relations transistor and Eqs. (5) and (6) are for a pull- in the conditional side of each equation (e.g., V and dV in Eq. @ ) are arranged so that they to each node (e.g., edges 1 indicated on the edges pointing it is to infer that V,,, can be calculated by some relation NEW from the current rule shown describes a set of relationships between rule defines rule are to be a in the graph. Since this is assumed In other words, this interpretation in the interpretation (equations) as shown, stored reasonable values of V and Vb. The interpretation the inputs V and Vb, and the output V,,. the new function NEW. The I/O combinations from the occurrence of the pattern extracted NOT circuit and [ +] / [ 0] should correspond such as [s+] value between (an intermediate imperfect. However, the method of inference using which does not have this defect.) this is still quite similar this pseudo-NOT. to [True] /[False], an analog component, [ +] and [ 0] ), makes this representation rule specifies (See Section 4.2 for another “NOT’ to NOT, and the interpretation the macro-rule The macro-rules into higher-level the physical-level the circuit equations generated by CLIP can be used to translate descriptions. For example, into pseudo-NOT descriptions. cir- the macro-rule in Fig. 11 In another result from the to NOR descriptions was also produced. shown in Figs. 10 and 11, the descriptions generated by the macro-rules If the purpose of the simulation cuit descriptions translates same experiment, In the examples and the interpretation for this is to predict purpose, and is more efficient as well. Note that the proposed method does not utilize any supplementary in order that explicitly defines to produce multilevel descriptions. rules enable the logical circuit behavior, inference. this higher-level It only tries to minimize the graph size. the hierarchical corresponding information the logical description structure suffices 78 K. Yoshidu, H. Motoda/Arr@cial Inlelligence 75 (1995) 63-92 Input of CLIP -Q-C+-@*- .n Pattern r 1 output Of CLIP __-.-.-_ 1 Pattern in Table : l_l;-3qQqqj q-z!--op; i+..l Pattern for Width:2 Depth:1 Pattern for Width:2 Depth::! Pattern for Width:2 Depth:3 Pattern for Width:2 Depth:4 / Pattern Length F(W,D) = 1 + W l F(W,D-1) / Matching can be done Numerically. * Efficient Matching (not Unification) 3.3. Analysis of CPU time and memory requirement Fig. 12. Pattern representation CLIP can be seen as a kind of EBL system which uses efficient graph-matching as a substitute for unification. (See [ 121 for the relationship between unification Fig. 12 shows the data structure used to implement Pattern and EBL.) in the C programming language. implementation: It shows the memory requirement, F( W, D), for a single pattern with this F(KD)= l+W*F(W,D-l), , L ifD> ifD= 1, 1. Here, D is the maximum pattern. We used 6 for D and 4 for W for the search shown matches any color in this implementation. depth of the pattern, and W is the maximum width of the in Fig. 10. The color 0 If we note the correspondence to a rule, the edge position corresponds between CLIP and EBL, the node color represented by to a variable name, and the EBL system uses unification or an equivalent a number corresponds the color 0 means any rule. Although operation extract patterns identity as the matching criterion, which has made the matching quite efficient. to from the input graph. This was also the motivation behind using graph to learn from an example, CLIP compares numbers for the pattern-matching In the experiments, the most important factor affecting the effect of pattern was the size of the input graph. CPU However, CPU set of experimental the iteration number. Although a single pattern in proportion increases results, size, time is roughly proportional i.e., the number of nodes the CPU time requirement to the graph size. in the pattern, on the In Fig. 13, showing one to to rewrite a single occurrence of in the in proportion the decrease the sizes of the pattern and view increase the CPU time needed to the size of the pattern, time requirement was not clear from our experiments. K. Yoshida, H. Motoda/Artifcial Intelligence 75 (1995) 63-92 79 CPU ONodes in a View .Nodes in a Pattern 20 sec.- l cPu l 15 sec.- 10 sec.- 5 sec.- . Node - 60 nodes - 55 nodes C- 50 nodes -45 nodes - 40 nodes - 35 nodes - 30 nodes - 25 nodes - 20 nodes - 15 nodes ' 10 nodes - 5 nodes 10 20 30 40 Iteration Fig. 13. Relationship between pattern length and CPU time. pattern occurrence the input graph. rate compensates for the increase in the total CPU time for rewriting Note that the direct implementation memory when D and W are large. However, use a hash table that uses F( W 0) as the key to reducing the memory requirement. of the pattern shown in Fig. 12 requires a large the values are almost always 0, and we can 4. Factors for generating concepts The basic idea of CLIP is simple: frequently which may affect the generation of new concepts. inference process. in the known to extract a set of typical patterns which appear factors In this section, we analyze various 4. I. Environments As described in Section 2, CLIP simply extracts patterns which originally occur in the input graph. The function of the algorithm described but extraction. However, we believe physics, are patterns extract a pattern environment. We believe that exist in the environment from their environments that humans’ behavior that many existing concepts, e.g., concepts used in life. Humans are able to to explain a certain aspect of the as a concept of human is similar to CLIP’s in this sense. in Section 2.2 is not generation, 80 K. lbshidu, H. Motr~da/Artijicial Intelligence 75 (199.5) 63-92 CLIP is designed to generate concepts It has two important environment.4 first input, colored digraph, and their frequencies, environment. contains thus it represents that can speed up inference in some specific inputs: colored digraph and selection criterion. The the pattern of inference system’s of the inference some characteristics the information about The second input, i.e., selection criterion, controls the behavior of CLIP by supplying criterion the method selection and third terms represent terms represent characteristics the inference costs. (see Section 3.1), to evaluate extracted patterns. Therefore, is important the design of Eq. ( 1 ), i.e., the Its first the amount of data to be handled, and the second and fourth If the reduce some of the inference under a given environment. the resulting concepts to control CLIP’s behavior. do not change, the matching cost during of the environment However, Eq. ( I ) does not cover all the factors which affect the performance of the inference. For example, descriptions with the implementation of the remaining to perform an inference with found concepts, the original should be re-expressed using the found concepts. The parameter also varies system. The rest of this section discusses some of the inference factors, using the results of additional experiments. 4.2. Approximation We have already shown experimentally does not exactly match a logical NOT function. This is because variable [ +] as an input, Is+]. rule interpretation the magnitude of each in the qualitative simulation. Even if a NOT circuit receives to [O], and it must go through (Fig. 1 I) that the obtained is taken into account the output directly it cannot change For the carry-chain to work as a logical circuit, a small amount of time must circuit seem to recognize elapse. Humans state changes, and a simpler representation details. Therefore, we need some kind of approximation the digital world. the object behavior by neglecting can be obtained by ignoring such intermediate the unnecessary to go from the analog world to We have considered two such approximations, both involving a kind of pattern reduc- from the found pattern about from the for which the values of some data are the same for all occurrences. These tion (See Fig. 14). Type I approximation if the output value of the found pattern can be calculated without variables rule subgraph approximations arise. from the original graph, as long as no contradictions in the subpattern. Type II approximation removes a subpattern remove a pattern the edge portion the information removes The second graph in Fig. 15 shows introduced. These results are exactly the initial pattern, CLIP obtained the results when a Type I approximation is this as the third graph using a Type I approximation. Nodes the same as those shown in Fig. 10. Using ’ Clearly, CLIP does not cover all human abilities of individual data, and delete the noise from the data. They can also extend to create new concepts. For example, humans can compare their reasoning the current environment. Although CLIP lacks these human abilities, we believe that it the importance to problems outside covers an important aspect of concept generation. K. Yoshida, H. Motoda/Art#cial Intelligence 7S (1995) 63-92 81 pS-iy>p IF there arises no contradiction by removing a particular pattern TYPE I : Utilize Rule Color (Equation Number) mq-zq Equations 1,2,3, and 4 form a new equation (NOT circuit). However, the variables in eq. 1 and 2 are not necessary to calculate the output. In such case, CLIP ignores unnecessary equations, and generates a simpler representation. TYPE II : Utilize VaIue Color ~!~,,I In the carry chain circuit, the clock signal is alway [O]. In such case, CLIP ignores the value of the signal, and generates a simpler representation. Fig. 14. Approximation. solid line correspond with a single-input correspond take [ +] as [True] and [ 0] as [False], NOR. to NOR. The resulting interpretation to NOT and nodes with two-input rules involve only solid lines [ +] and [ 01. If we to the truth table for NOT and they correspond The fourth graph in Fig. 15 was obtained starting from the third graph, and corresponds to a carry- by assuming indicated should be three. When we added a Type II approximation the actual number of inputs operation. However, (Fig. 16), the resulting graph clearly a as well as the digital NOT and NOR. The Type II the second and third figures, but the extracted NOT and the same. The only difference was that some parts of the graph physical node did not change during since the value of the corresponding carry-chain to a five-input chain circuit a default value for the clock signal three-input approximation NOR were essentially were neglected, the simulation. also affected carry-chain operation, Note that the characteristics of the environment important characteristic tradictions. For example, of the environment if the inference changes, system these approximations. enable these approximations If an result in con- is required to treat an intermediate 82 K. Yoshidu, H. Motoda/Artificiul Intellipxce 75 (I 995) 63-92 Input Digraph NOR/NOT (Analog, 5 min.) NOR / NOT (Digital) Carry ( 5 Inputs . total 7 min ) ~~~ ~~_~ “Rules for Logical Operation (Truth Table)” found by Assuming a Function (unknown to CLIP) of Pullup Transistor. Fig. IS. Importance of approximation (TYPE I) Input Digraph Inputs . 6 min ) I . b I I I .- i 1 I I _ Input Carry” found by Assuming a Default Value for the Clock Signal Fig. 16. Importance of approximation (TYPE II) K. Yoshida, H. Motoda/Artifcial Intelligence 75 (1995) 63-92 83 Intermediate Hierarchy NOR / NOT (Analog) Higher Matching Cost resulted in an Intermediate Level of Hierarchy Fig. 17. Impotice of rewriting costs. state change of the analog circuits, the logical concepts NOR and NOT do not help the analysis. 4.3. Inference system characteristics Another important factor affecting new concept generation is the inference system characteristics. To confirm the effect of the inference system characteristics on the generated concepts, different graph size definitions were used in other experiments: C Exact = Number of Nodes + Number of Edges + c (Number of I/O Combinations of the Interpretation Rule,)2 +x(N urn er of Inputs to the Pattern,)2 b + 10 * c Number of Nodes in Pattern2 - Number of Graph Rewritings. (2) The fifth term is a penalty for re-expressing the original descriptions using the found concepts. To perform an inference with the found concepts, the original descriptions should be re-expressed. As the number of nodes in the pattern increases, the cost of re-expressing, i.e., the graph-rewriting cost, increases proportionally. Although Eq. ( 1) ignores this re-expressing cost, EXq. (2) has a large penalty for it. With Eq. (2), the minimum size was reached at the 15th iteration, which is shown as the middle graph in Fig. 17. Each pattern is smaller than that of the previous result (Fig. lo), and corresponds to an intermediate physical structure, i.e., a pull-up or pull- down transistor. Starting from this pattern, CLIP obtained the rightmost graph, which is exactly the same as in the previous result (Fig. 10). This suggests that the optimal concept structure varies with the inference system characteristics. The more efficient the rewriting capability of the inference system becomes, the more efficient the inference becomes for fewer levels of hierarchy. CLIP can accommodate each inference system characteristic by adjusting the parameters in the size evaluation. 84 K. Rxhidu, H. Motoda/Arti$ciul Intelligence 75 (1995) 63-92 (a) Resulting Digraph (subgraph) with Rule (b) Resulting Digraph (subgraph) with Data Attribute (c) Resulting Digraph with Value Fig. 18. Importance of color. 4.4. Color of the graph node In the previous experiments, pattern mod@cation used the rule number In this section, we investigate concepts. the possibility of using other to find patterns. to generate information Fig. 18(a) shows partial results for the case using the rule number coded in the node (i.e., voltage, current, [ 01, the for the data attribute (i.e., results the results with the rule number color, and Fig. 18(b) etc.). Finally, Fig. 18(c) etc.). As described logical concepts NOT and NOR (Fig. 18 (a) ) CLIP extracts some patterns even when shows partial results shows complete in the previous sections, is used as the node color. for the data value the data attribute [ +], involve K. Yoshida, H. Motoda/Art$cial Intelligence 75 (1995) 63-92 85 Shallow Level Inference (OUTPUT with NOISE) Deep Level Inference (INPUT with NOISE) CUP can Learn a “Concept” even in the presence of Noise. Fig. 19. Effect of noise. One of them can be interpreted the current at the output of the transistor”, and it represents transistor behavior. The relationship variables in the circuit equation between as ‘The voltage at the input node of a transistor asects about some knowledge seems to be a cause of this pattern generation. the data attribute and the corresponding When we use the value of the physical data, the resulting graph also represents (Fig. 18 (c) ) . In this case, each pattern represents patterns the circuit. For example, of the calculations the two right-most graphs in Fig. 18(c) cases. in corresponding simulation performed some the distribution of the value in indicate the similarity Although we cannot find a method of using of concept-generation these concepts using in the inference, these other than rule information results suggest number. the possibility 4.5. Noise Humans can compare thus CLIP’s ability even from noisy data by deleting noiseless examples, In theory, however, CLIP can learn new concepts in Fig. 19, where the circuit has the input going through a pass transistor is simulated the behavior of the pass area of Fig. 19), and knowledge about transistor behavior detailed knowledge makes a kind of noise the importance of individual data items, and learn new concepts the noise. All of the results shown above are simple in question. from noisy data. The idea is illustrated (see hatched rough using (Rule 6). The other inferences are performed using levels (Rules 1, 2, 3 and 4)) and the imbalance in the inference process. 5 from noisy data remains in the description to learning transistor 5 Note that the value of VI in Fig. 3 is calculated from Qt using this kind of noise. In this section, we examined Fig. 3 does not involve the inference the detailed knowledge, the case where the occurrence i.e., Rule 2, and of [ 171 that does not have a relationship with the target concepts makes the noise. Recent study 86 K. Yashida. H. Motoda/Artificial Intelligence 75 (1995) 63-92 Table I COBWEB and CLIP characteristics COBWEB CLIP Input Set of object descriptions output Useful sets of objects Their conceptual descriptions Set of inference patterns theory Domain Characteristics of inference engine Useful set of chunks (composite objects) from inference patterns Conceptual descriptions to all chunks Note Maximize category utility: Minimize graph size: to predict unknown properties to improve eficiency Even in such a case, CLIP can learn concepts the noise is small enough. graph size, CLIP can ignore affects by noise, or typical noise patterns same, the learned concepts will make the inference efficient. if the part of the inference affected by In other words, if the noise does not cause a large error in the the hatched area of Fig. 19). If the noise (concepts affected is to be the the graph size, CLIP may learn somewhat different concepts themselves). However, if the environment the noise (i.e., Note that in the results shown in Figs. 15 and 16, some portion of the circuit behavior the outputs of to the value of the carry. These results also for cum, calculation. For example, acts as noise the NOTs in Fig. 1 have no direct relation indicate the learning potential of CLIP in noisy environments. in the learning process 5. Related work 5.1. Inductive learning inductive learning methods Most conventional learn a new concept examples, and generate classification [3] ). They do not aim to speed up abstract-level from posi- ID3 and Ver- tive/negative inference. CLIP assumes sion Space to speed up the that u concept the generated concepts. For example, CLIP generates new inference process by using traces of a concepts digital circuit. CLIP can generate NOT and NOR without having any knowledge of logic. such as NOT and NOR by analyzing is something which makes inference easy, and (e.g., INDUCE, the qualitative simulation rules tries (e.g., COBWEB) Conceptual clustering [ 51 is an important area of machine methods observations. CLIP is similar tions by clustering similar patterns, and gave little attention (See Table 1 for the difference.) The most important characteristic in which several from concepts from observa- in this area focused only on clustering to the inferences which use the learned concept. is that it similar patterns. Prior research in that it finds useful concepts to generate meaningful have been proposed to COBWEB of CLIP learning reveals clarify the relationship the relation between CLIP and noise. between CLIP and the conventional inductive learning studies, which contributes to K. Yoshida, H. Motoda/ArtiJTcial Intelligence 75 (1995) 63-92 87 Table 2 EBL and CLIP characteristics EBL CLIP Input Goal concept Training example Domain theory Operational&y criteria Multiple training examples Domain theory Characteristics of the inference engine output One macro rule Set of macro rules (operationality criterion implicitly embedded) Interpretation rule: (new domain theory for the abstract-level inference) Goal concept generates enable a set of rules the abstract-level to interpret inference using the generated concepts. the new concepts, and these interpretation rules 5.2. AM system. concepts concept-finding [3] is an important AM interesting in mathematics, axioms. Although CLIP does not use an explicit heuristic, size has a heuristics aspect. CLIP has two important size definition. The former latter, the characteristics the inference to find the initial of the graph i.e., the graph and the graph and the of the environment, that make system. CLIP tries to find concepts represents of the inference and can generate new theorems It uses a set of heuristics the given environment. the characteristics its minimization efficient under inputs, from We can see CLIP as a system which uses only one domain-independent heuristic: is something which makes inference easy. The generality of this heuristic a is one characteristic of CLIP concept important 5.3. EBL (explanation-based research EBL ficiency. jects, ISA( BCYITOM- 1 FLAT) Some such [ 111 aims at to as PART-OF(OBJl,BOITOM-l), learning) uses EBL improving base-level problem-solving descriptions ISA(B(YI’TOM-l,BOlTOM), translate ef- of ob- and into abstract-level descriptions, such as CUP( OBJl ) . Table 2 lists the features of EBL and CLIP for comparison. CLIP needs multiple theory. examples, while conventional EBL requires only one example. Both need domain CLIP also needs i.e., rules describing how to make an inference. interpretation rules, The main difference is that EBL needs a goal concept and operationality to be criteria in the algorithm in the capability of each system with an appropriately defined graph size, which in turn affects the form explicitly provided as inputs. and the multiple examples. CLIP can accommodate inference of the extracted patterns. In CLIP, these are implicitly differences embedded EBL produces one macro-rule set of macros, which can be viewed as a set of concepts for a given goal concept, whereas CLIP produces a in some domains. CLIP also 88 K. Yoshidu, H. Motodn/Art@ciul Intelligence 75 (1995) 63-92 Graph Size _ P. Combination q P. Modification Tape I Approximation Fig. 20. Log of search (using approximation) produces new generated concepts. interpretation rules that describe how to make an inference using the CLIP shares an aspect of the EBL system. CLIP uses the graph size as a substitute [lo]. Since criteria to the utility problem do not aim at generating to perform for the goal concept and operational [ 6,8, IO, 13, 141 related most studies they lack a framework new concepts, inference by the generated concepts. the utility problem to solve 5.4. Genetic algorithms in Section 2.2, CLIP’s pattern-finding As mentioned algorithm can be seen as a kind is of genetic algorithm the strong search ability of the pattern modification. Fig. 20 shows how the graph size and the ratio of the views generated by pattern modification change with progressive of the algorithm used in CLIP [7]. One notable characteristic and by pattern combination shown in Fig. 16. iterations during the experiment The Type I approximation is implemented as a kind of pattern modification by gen- to be neglected. node color. Type II indicating the edge to neglecting pattern which has a mark some edge is equivalent is performed by neglecting erating a temporary Neglecting approximation tion rules. When discards discard. The solid curve candidate views. Note that the size is reduced size. the view that contains the approximation indicates the connecting some inputs when CLIP generates the pattern. A solid circle on the top indicates interpreta- operation on a pattern results in contradiction, CLIP such a the average of the predicted graph sizes of all the to about one fifth of the original graph In Fig. 20, the hatched area indicates the ratio of the views generated by pattern modification. As shown included one important algorithms. CLIP operation, research improves i.e., pattern modification. in the figure, CLIP’s pattern modification with approximation is the main source of the search. is theme of genetic algorithms. CLIP shares an aspect of genetic the use of a special mutation the efficiency of the search the search efficiency Improving through Note that the current CLIP implementation does not use a probabilistic framework. K. Yoshida, H. Motoda/Arr@ial Intelligence 75 (1995) 63-92 89 Functional Descrbtion Shallow Knowledge (Depends on Task) Abnormal X Check Y and 2 I Then 7 CLIP automatically finds this type of relation ! Fig. 21. Scope of hierarchical knowledge base. In this respect, CLIP is similar to the beam search programs, such as INDUCE [ 31 and HARPY [l]. 5.5. Hierarchical knowledge representation To understand a complex system, humans view a system at different levels of abstrac- tion based on its functional structure. We have developed a method to represent complex systems in a hierarchical manner [ 15,161. The use of the entity-relationship model and the approximations are based on our previous research, and CLIP was designed to automate the process of hierarchically representing the functional descriptions. Fig. 21 shows our long-term research goal. We hope to integrate the hierarchical knowledge representation technique with the techniques for representing and acquiring the task knowledge. 6. Future research issues This section summarizes the remaining research issues. l Optimization of multi-level representation: CLIP can generate a hierarchical con- cept structure such as that shown in Fig. 15 in a stepwise manner. However, CLIP doesn’t have a mechanism that guarantees the optimality of the generated hierar- chical structure. For example, CLIP may make two hierarchies when in fact three hierarchies would be optimal. Creating a mechanism to search for the optimum 90 K. Yoshido. H. Mo/oda/Artificicrl Intelligence 75 (1995) 63-92 Size A . * ~~ *___---_t---- -. Fig. 22. Log of search (without approximation). ~- VIEW Iteration structure is one multi-level Section 5.5, CLIP generates grate this description with the task knowledge hierarchy are also important a hierarchical important issues. future issue. Furthermore, as described functional description. How and how the integration in to inte- affects the l Similarity to human concep: concepts known spond to human concepts concepts, and seems is necessary spondence. to confirm The concepts generated are all to be understood by humans. However, the reason why they corre- is not clear. The graph size definition affects the generated Further analysis for this corre- to be the key factor in this correspondence. that the graph size definition in the experiments is responsible Furthermore, the current implementation the generated carry-chain program expresses lack of multi-output concepts. It can treat only a concept circuit has two outputs, has some restriction on the form of the i.e., the carry and the column value, the current concepts. The that has one output. Since of two independent this circuit as a combination treatment concept is another defect to be remedied. l Searching ability: As described in Section 5.4, the current version of CLIP does not the searching ability. For example, framework, and this weakens use a probabilistic for Fig. 22 shows how the rewritten graph size changes with successive in Fig. 22, CLIP first the results shown in a local minimum. Then the size increased found a small pattern which resulted in the until a larger pattern was found at the third arrow. The number of nodes pattern to ignore other smaller patterns even if choosing one of these would result in a smaller graph. This is not a good aspect of CLIP’s search ability, and needs improvement. 6 in Fig. 11. At the leftmost white arrow to increase with and CLIP iterations iteration, tends tends 7. Summary CLIP is a system from the inference implemented fully that extracts a set of concepts traces produced during a problem-solving and tested. The results of our findings are summarized rules event. CLIP has now been together with their interpretation as follows: 6 Recent study 117 I has enhanced for extracting typical patterns algorithm seemingly different up inference. This, in turn, has increased beyond learning tasks: inductive the level assumed when we first wrote this paper. the generality of both the representation from the graph. capability of the digraph, and the In [ 171, we investigated how to apply CLIP to two rules, and learning macro rules to speed the importance of the theme of improving CLIP’s search capability learning of classification K. Yoshida, H. Motoda/Artijcial Inrelligence 75 (1995) 63-92 91 l CLIP analyzes sample inference traces and extracts typical patterns which frequently appear in the inference. We assume that such patterns probably represent important concepts. l CLIP generates a set of rules for interpreting new concepts, and these interpretation rules enable abstract-level inference. l The environment and the inference system characteristics are the most important factors in constructing new concepts. Approximation is also important for creating more abstract-level concepts. The proposed method automatically considers these factors in generating new concepts. In experiments, CLIP automatically generated multilevel representations of a carry- chain circuit from its given physical/single-level representations. The generated repre- sentations contain abstract-level concepts, including mathematical and logical concepts. Acknowledgements The authors would like to thank Masaru Takeuchi for his helpful comments on the relation between CLIP and genetic algorithms. They also extend their thanks to Chihiro Sugita for his help in implementing the CLIP program. References [ 11 A. Barr and E.A. Feigenbaum, eds., Handbook of Ar@cial Intelligence (William Kaufmann, 198 1) , Chapter 5. [ 21 PP. Chen, The entity-relationship model towards a unified view of data, ACM Trans. Database Sysr. 1 ( 1) ( 1976) 9-36. [ 31 P.R. Cohen and E.A. Feigenbaum, eds., Handbook of Artificial Intelligence (William Kaufmann, 1982), Chapter 12. [ 41 J. de Kleer, A qualitative physics based on confluences, Artif: Well. 24 (1984) 7-83. [ 51 D.H. Fisher, Knowledge acquisition via incremental conceptual clustering, Mach. Learn. 2 (1987) 139-172. 161 N.S. Flann, Applying abstraction and simplification to learn in intractable domains, in: ML-90 ( 1990) 277-285. [ 71 D.E. Goldberg, Generic Algorithms in Search, Optimization. and Machine Learning (Addison-Wesley, Reading, MA, 1989). [ 81 M. Lebowitz, Integrated learning: controlling explanation, Cognitive Sci. 10 ( 1986) 219-240. [ 91 C. Mead and L. Conway, Introduction lo VLSI Systems (Addison-Wesley, Reading, MA, 1980). [lo] S. Minton, Quantitative results concerning the utility of explanation-based learning, in: Proceedings AAAI-88, St. Paul, MN (1988) 564-569. [ 111 T.M. Mitchell, R.M. Keller and S.T. Kedar-Cabelli, Explanation-based generalization: a unifying view, Mach. Learn. ( 1986) 47-80. [ 121 R.J. Mooney and S.W. Bennett, A domain independent explanation-based generalizer, in: Proceedings AAAI-86, Philadelphia, PA (1986) 551-555. [ 131 S. Yamada and S. Tsuji, Selective learning of macro-operators with perfect causality, in: Proceedings IJCAI-89, Detroit, MI (1989) 603-608. [ 141 M. Yamamura and S. Kobayashi, An augmentation of EBL on plural examples (in Japanese), J. Japan. Sot. Artif: Intell. 4 (4) (1989). [ 151 K. Yoshida and H. Motoda, An approach to hierarchical qualitative reasoning (in Japanese), J. Japan. Sot. Artif: Infell. 4 (4) (1989). 92 K. Yishidu, H. h4ofoda/Artijiciul Intelligence 75 (1995) 63-92 I 16 ) K. Yoshida and H. Motoda, Hierarchical knowledge representation based on approximation, in: Proceedings XAW90, Kyoto, Japan ( 1990) 345-360. I 17 I K. Yoshida, H. Motoda, and N. Indurkhya, Graph-based induction as a unified learning framework, in: Applied Infelligence 4 (Kluwer Academic Publishers, Dordrecht, Netherlands, 1994) 297-328. 