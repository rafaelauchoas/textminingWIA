ELSEVIER Artificial Intelligence 82 ( 1996) 75-127 Artificial Intelligence ALX, an action logic for agents with bounded rationality Zhisheng Huang ‘, Michael Masuch 2, L&z16 Pblos Center for Computer Science in Organization and Management (CCSOM), University of Amsterdam, Sarphatistraat 143, 1018 GD Amsterdam, Netherlands Received June 1993; revised November 1994 Abstract We propose a modal action logic that combines ideas from H.A. Simon’s bounded rationality, is sound, complete and decidable, making it the first complete S. Kripke’s possible world semantics, G.H. von Wright’s preference Stalnaker’s minimal change and more recent approaches to update semantics. ALX logic) operators. ALX avoids important drawbacks of other action logics, especially necessitation closure of goals under logical logic, (the xth action logic for two-place preference the counterintuitive theorem must be a goal) and the equally counterintuitive logic, Pratt’s dynamic rule for goals implication. (every 1. Introduction use by intelligent [ 6,14, [ 24,471, or as a contribution robots is motivated by a different concern. We want for theories of logic. We leads to a new approach theories, especially to action language a formal The difference for (hypothetical) [64]. Our effort for social science logics are usually developed language of program behavior as a description logic Action 40,59,71], to philosophical to develop organizations. combine rationality, G.H. Wright’s approach in combination with binary modal operators, Pratt’s dynamic minimal change, and more recent 251. Although problems of action In particular, ALX avoids fairly simple in motivation logic. ideas from belief revision and update semantics in its construction, ALX is good at handling the counterintuitive logic, Stalnaker’s notion of [ 15, some crucial necessitation ideas from various strands of thought, notably H.A. Simon’s notion of bounded to preferences, Kripke’s possible world semantics ’ E-mail: huang@ccsom.uva.nl. * Corresponding author. Fax: (31-20) 5252800. E-mail: michael@ccsom.uva.nl. 0004.3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved SSDlOOO4-3702(94)00090-5 76 Z. Huang et al. /Art@cial Intelligence 82 (I 996) 75-127 rule for goals (every of goals under model property. logical theorem must be a goal) and the equally counterintuitive and enjoys is complete, decidable implication. ALX closure the finite 2. The framework for ALX Most social science theories are expressed to check language for “softness’‘-a that would allow one natural scaffold to disambiguate acquired a reputation are somewhat dubious. Reformulating would make consistency way for other tasks, such as the examination Understanding the deductive automating AI into theory building We focus on action [45]. logic as a formal the generation of theories in natural their consistency statements. As a consequence, soft way of saying in a rigorous language. They lack a formal fashion, or theories have that their logical properties language with known properties the easier. Also, it would pave these them in a formal of a theory’s deductive closure properties. checking or disambiguation closure properties of a set of formulas from a given set of assumptions is essential and introducing to agents are key to the understanding language, of social phenomena. because actions of individual theories of social relations must be action or In fact, most social [ 1,12, theories hard to grasp in to develop taking First-Order Logic off the shelf. We call the new logic [ 111. This drives our attempt Yet actions engender change and change context of first order languages is notoriously than collective scientists agree that adequate 16,39,52,61]. the extensional a new logic, ALX (the xth action logic). rather Possible Outcomes Behavior Alternatives Perceived Behavior Alternatives Fig. I. Simon’s bounded mtionality Z. Huang et al./Art$cial Intelligence 82 (1996) 75-127 17 to overcome the omniscience of rational action. He assumed of bounded rationality is intuitively Herbert A. Simon’s conceptualization (see Fig. 1). His approach [65] serves as a point appealing and had great impact on claims of the (1) an agent, with (2) a (3) a set of future states of affairs (each such state being and (4) a preference order of departure the postwar social sciences. Simon wanted traditional conceptualizations set of behavior alternatives, the outcome of a choice among over future states of affairs. The omniscient would know all behavior the and agent would also have a complete preference order for those outcomes. An agent with bounded in contrast, would not know all the alternatives, would not know the exact outcome of each, and would not have a complete preference order for those outcomes. the exact outcome of each alternative; agent, endowed with “perfect the behavior alternatives), rationality”, alternatives rationality, Kripke’s possible world semantics provides a natural setting for Simon’s conceptual- ization. We assume a set of possible worlds with various relations defined over this set (we may also call those possible worlds states). One can see a behavior alternative as an accessibility a mapping from states to states, so each behavior alternative constitutes for action, relation. An accessibility from a given state to another i.e., as an opportunity relations are expressed by one-place modal operators, as in dynamic state. Accessibility logic (a)4 would express the fact that the agent has an action a at his disposal such that effecting a in the present situation would result in the situation denoted by proposition in turn, can be interpreted as an opportunity relation, for changing the world by moving [ 241. For example, the formula c$. The perfectly rational agent would have a complete description relations and a complete preference of his actual state, order informed. They may have are less well of all accessibility a complete knowledge over states. Agents with bounded description an incomplete incomplete knowledge of the accessibility over situations. actions concept of goal in ALX’s object language. In particular, one can assume is finite. As it turns out, this assumption rationality of their actual state (we call those descriptions situations), relations, and an incomplete preference order that their knowledge and the range of their is crucial for defining a straightforward Situations are represented as sets of states and expressed by propositions. Propositions, about a situation, the more detailed the set of states where description limit case, a complete description, would uniquely in turn, denote knowledge situation would be. The one state. Less specific descriptions would those states where the description would hold (but remaining uncommitted “aspects” not covered by the description). incomplete l201.3 they obtain. So, the more specific an agent’s of that identify the set of about other This is the standard approach lack that uniqueness, the propositional in denotational to representing and epistemic information, identifying semantics [62,63] logic used ’ Framing bounded rationality can see that omniscience-the in an absolute not available. Any formal but those assumption, another. in terms of possible worlds semantics limiting case-is contingent upon the choice of the language. Full rationality reveals a fine point usually ignored: one sense would require a language isormorphic theory about full rationality has to make simplifying nature, violate assumptions the ontology of full rationality by their simplifying is about the world, in some sense or to the universe “out there”, but such a language 78 Z Huang et al./Artijkial intelligence 82 (1996) 75-127 statement goals-provide is understood Preferences-not the basis for rational action [ 721, a preference the statements that “I prefer oranges the states in which I have an orange in ALX. Following von Wright as a statement about situations. For example, to apples” as the fact that “I prefer to the states in which I have an apple.” to prefer oranges Following to apples should prefer a situation where he has an orange but no apple to a situation where he has an apple but no orange. Preferences are expressed via two-place modal q5 to the proposition +, we write c$IPI,~. operators; even when if the agent prefers the meaning von Wright again, we assume that an agent who claims is context-dependent, of a preference the proposition is interpreted Normally, statement change different approach to conditionals that are minimally cw, to the semantics to an apple later-perhaps he may prefer an orange true about which preferences in all other respects. For situations to prefer an apple to an orange-and this context dependency, we borrow from Stalnaker’s expansion principle only to situations this is not made explicit. An agent may claim actually mean it-but he already had an apple. To capture minimal the conjunction the agent’s present situation-just the propositions function, state, such state as much as possible cw to each element of the situation problems because then the notion of [ 681. The idea is to apply from as different as they really need to be in order to make a binary to a given the old (sets of states), we apply separately. This allows us to avoid some technical are expressed. We introduce a set of “closest” states relative that determines that the new states fulfill some specified conditions, of preferences, its machinery. Closing yields a preference order so one can de- the set that in terms of prefer- (we will argue that there are several plausible goal definitions, arising ALX provides rive new preference of preference serves as the basis ences and accessibilities corresponding this follows be unique; usually incomplete. Also, so agents need not treat undesired consequence use the concept of “goal” as the primitive notion of rational guidance). stronger notions of rationality). Note that goals need not and preference orders are from old ones by using the rules of inferences logic [ 38,50,68]. 4 syntactic characterization implication, (e.g., pain as a that logics the goal set need not be closed under from the fact that world descriptions of having one’s teeth repaired) in conditional a complete for deriving goals. Goals, statements under as goals (as opposed of desired outcomes in turn, are defined to increasingly but resemble consequences statements to action logical 3. Formal syntax and semantics 3.1. Syntax propositional is a multimodal alphabet consists of a set of lower-case Latin symbols pi to denote primitive propositions. The action letters 4, +, p, . . . (with or ALX countable alphabet has a finite set of actions ai. Lower-case Greek without subscript) existential to denote the one-place the two-place preference denote well-formed relation for action a and P to denote formulae. We have (a)$ logic. The propositional accessibility 4 The reader is referred to the discussion part of this paper for details. 2. Huang et al./Art$cial Intelligence 82 (1996) 75-127 19 relation. o serves as two-place operator action. Note that updates [ 151, so an update does not produce a new knowledge in ALX refer to real state changes, not epistemological state, but a new situation. for updates; updates are changes caused by an ones 1 (Syntax). Definition some k E w with w standing FML is defined recursively as follows: Let ATOM = {pi : i < o} and ACTION = {al,. . . , uk} for for the ordinality of natural numbers. The set of formulae l ATOM c: FML, l ~#JEFML++EFML, . q&G E FML+ (4r\t,b) l q5 E FML, a E ACTION + ((u)qS) E FML, . q&e E FML+ (c$ot+b) EFML, l $, 1,4 E FML =+ (c$P@) E FML. E FML, for an arbitrary 4, and [a]4 and the truth constant T from the given Boolean connectives the Boolean in as l(a)+. Define Define 1 as 4 A -4 {V, +, H} connectives the usual way. 3.2. Semantics Definition 2 (ALX models). We call M = (W; cw, >, {R’}aE~~,~~, if: V) an ALX model l W is a set of possible worlds, l cw : W x P(W) + P(W) 0 * C P(W) l R” C W x W is an accessibility l V : ATOM + P(W) x P(W) and if M satisfies the following is an assignment conditions: is a closest world function, is a comparison relation for preferences, relation for each a in ACTION, function for primitive propositions, (CSl) (CS2) (CSC) cw(w,X) c x. w E x =+ cw(w,X) = {w}. CW(W,~) nYc (NORM) (8 Y x>, (x $0). cw(w,Xrlr) (TRAN) cw(w,Ynx) and + cw(w,ZnY) + CW(W,xnZ) + cw(w,z nX), where r = W - Ii (CSl ), (CS2) and (CSC) (relative (and unique) the closest +-worlds that w is its own @ is true at the closest &world, world. normality of worlds would and transitivity; and (TRAN) (NORM) constrain to a given world) are indeed +-worlds; the closest world function. (CSl) closest &-world if r#~ is true at w. (CSC) ensures that (CS2) ensures says that if then constrain the closest +-world is also a closest &and+- the semantic preference that no comparison relation. They require two sets between stipulates “normality” involve an empty set of worlds. 80 2. Huang et al./Artijicial Intelligence 82 (1996) 75-127 In the following, we will use M = (W, cw, +, R”, V) to denote M = (W, cw, +, {R”}aE~~~~~, V) if the omission causes no ambiguity. Let FML be as above and function [ilM interpretation let A4 = (w cw, : FML + P(W) is Definition 3 (Interpretation t, R”, V) be an ALX model. The defined as follows: function). uPin‘+4 = V(Pi) 3 u-a4 =w \ udl,. u(+bn, = {W E w : 3~’ E W(R’ww’ and W’ E u4n,)j, [I4 0 @I, = {W E w : 3~’ E W(W’ E pn, and w E CW(W’, n$j,))}, umbn,={WE w :cw(w,u~~~~) +~~b+ewn~)~. of the primitive propositions letter pi evaluates The interpretation forward. A proposition negation of a proposition C$ evaluates junction The interpretation least one &world via action a. We use the “existential” because specific situation. ti evaluates of (a)~$ yields to the intersection real-life decisions of q5 and to the complement and the Boolean connectives to the set of worlds where pi obtains, is straight- the and the con- and the +-worlds. of the &worlds, of the &worlds the set of worlds from where the agent can access at version of the action modality, typically depend on the possibility of a specific action in a The interpretation of 4 o $ yields have got there from a closest e%world. Note that 4 o II, is a backward-looking [ 151. Note also that 4 o Cc, is closely known express “if 4 were the case, then $ would be the case”. 5 One can express not term-define) rule [ 151: (although in terms of the update operator via the so-called Ramsey the set of worlds where + holds so that one could operator (“wiggle”) is meant conditional [ 38,681, where qb +-+ $ and D. Lewis’ work to the intensional from Stalnaker’s the wiggle related to I- (/I+ (4-$)) e I- ((x04) -9). The interpretation of @P$ yields the set of worlds where the agent prefers (at each of those worlds) the closest +-and-not-$-worlds to the closest @-and-not-&worlds. Define the forcing relation as: 4 (The Definition models and let [I I], be as above logic ALX = (FML,Mod, logic ALX). [I nM) ALX logic. Let FML be as above, let Mod be the class of all ALX for every model M E Mod. We call the too, defined 5 In fact, in Stalnaker, the “wiggle” is a “corner” (>); we prefer the --+ because it frees the > for other uses. 2 Huang et al./Artijicial Intelligence 82 (1996) 75-127 81 Define the semantic consequence relation, k, as usual: M=(W,cw,t,RO,V)~~~(~wEW)(M,wII-~). k+r&(VyEr)(M+y). Mod(r) & {M E Mod: M k I-}. I- + qf~ k% Mod(r) C Mod({qb}). Definitions 2-4 provide characterization of ALX. The next definition a semantic syntactic characterization. inference system). Let ALXS be the following set of axioms and provides a complete Definition 5 (ALX rules of inference. (B-4) all propositional tautologies. (a)I (a)(+ V+) (a)(4A(CI) 40* +A* -(40~)3-(J-o4) (4V9) (+A$) (4o*) ox o$ AX (Ul) (U2) (U3) (U4) (US) (U6) (CEP) 4W (w4) A (9Px) 3~W),-($P~) HI H (a)$ V (a)@ + (a)4 A (aM -@ -+ +o* ++ ~OXV~OX -4 + 4o(tiAxx) H (+A+)P(+AG) -+ (Wx) (TR) (N? (MP) (NECA) (MONA) (MONU) (SUBA) (SUBU) (SUBP) l-4+@ l-4& I- 4 I- (44 & I- 4 --) ICI I- 4 O CCI & I- 4 + 4 I- (4 ++ 4’) I- (4 H 4’) & I- (Ic, ++ G’> =+ I- (4 ofi) c-f (4 occI’> I- (4 * 4’) & I- (ti ++ 4) * I- (WbI) H (4W’) =+ I-@ + I- [aI4 =+ I- (a)@ * I- 4 O * * I- ((44) H ((a)$‘) Most axioms (BA). Since ALX is not accessible disjunction are straightforward. As usual, we have the propositional tautologies is a normal modal so it the absurdum (Al). The action modalities behave as usual, so they distribute over (A3). is not true anywhere, in one direction both ways, but over conjunction logic, (A2) only and 82 Z. Huang et al./Artijicial Intelligence 82 (1996) 75-127 Indeed, we can get to &or-$-worlds a &world being able to get to $-worlds to a world that is both 4 and $. or to a $-world. However, being able to get to &worlds via action a does not necessarily mean via action a if and only if we can get via a to via action a and that a can get us (U2). As mentioned for updates. Since there is no world where operator. So, a successful $-update above, o is a backward-looking and i.e., to remain at that world over the update operator. The intuition (Ul) a vacuous $-update, the truth of both 4 and Ic, at a world allows us to ends up in a G-world the perform is true, the absurdum normality condition of the the left distribution an update with the absurdum disjunction is that if we have got to a X-world from a 4- or a $-world, we have updated either from a &world or from a G-world. (U5) (U6) posits that if x holds after updating 4 with *, then we can update 4 with I/I A x and obtain the same result. Readers more familiar with closest world functions may already sense how the update operator will mimic to construct tells us that a void update the closest world function to change any conditions. in the syntax, helping in the completeness a canonical model cannot succeed. is not going (U4) posits reiterates proof. (U3) expansion the conjunction principle (N). So, if we prefer $ to r~?, we will also to $, we are apt to that it is because we think If we prefer 4 transitivity The axioms for the preference operator posit the absence of Cc, to the absence of 4. and normality (TR), transitivity (CEP), prefer prefer &and-not-$ a natural principle preference via the only-if part of the contraposition an axiom, since it is derivable and asymmetry contraposition to +G-and-not+. We have of preference inconsistent statements. For example, without normality, we get a violation of irreflexivity orders. Normality is required to avoid principle. 6 We need not state irreflexivity as from (CEP) and (N) . By the same token, we can derive for the preference operator. Proposition 6 (More properties of the preference operator). are theorems of ALX: The following formulas Proof. See Appendix A. Cl We have modus ponens and the necessitation and monotonicity (NECA) we have left monotonicity, from a &world to the closest @‘-world even if J, implies $’ at w. Logically equivalent propositions action modality action modality. For the update operator, that a move to the closest e-world w might end up at a different world than the move are for the existential but not right monotonicity, rule for the universal the intuition being h An alternative method [ 221, requires it is less straightforward the “independence” because for preserving consistency, suggested by von Wright of propositions the definition of “independence” in certain axioms. We have used this approach is nontrivial. [72 ] and used by Hansson in [28], but 2 Huang et al./Art@cial Intelligence 82 (1996) 75-127 83 in action, update and preference substitutible Note that we do not have monotonicity avoid the counterintuitive deductive closure of goals. formulas (SUBA), (SUBU), (SUBP). for preferences. Because of this, we are able to 4. Formal properties of ALX ALX has pleasant logical properties. We have: Proposition 7 (Soundness formulas A and an arbitrary formula 4, of ALXS) . ALXS is sound, i.e., for an arbitrary set of Proof. See Appendix A. 0 Next, we have: Proposition 8 (Completeness formulas A and an arbitrary formula of ALXS). c$, ALX is complete, i.e., for an arbitrary set of Proof. See Appendix A. 0 Furthermore, ALX that is, for each non-theorem is decidable. Stronger even, we have $ there exists a finite model for 9. Since ALX is recursively axiomatizable, the finite model property that provides a that ALX is this means for ALX, counterexample decidable. Definition 9 (Finite model property). erty, iff, for arbitrary 4 such that ks 4, there exists a finite model M such that: A logic S is said to have the finite model prop- Iw(M,w (1) (2) Vp(I-s P =+ VJw(M, w I/- P)). I/- -@), Theorem 10. ALX has the$nite model property. Proof. See Appendix A. q ALXS is finite, so ALX is finitely axiomatizable. The finite model property together [ 3 1, p. 1531. As a consequence, we with finite axiomatizability have: imply decidability (cf. Corollary 11. ALX is decidable. 84 2. Huang et al./Artijicial Intelligence 82 (1996) 75-127 5. Applying ALX flexibility ALX provides considerable In the following, we assume in defining new modal operators by using the three primitive operators. We concentrate on operators of potential use in defining goals. that the preference order of an agent is finite and hence that statements. Call this set 27~. Recall furthermore the corresponding the range of action alternatives 1). Suppose that 2p = ($1, . . . , I,&}. In the following, we use the notation V@@(r,&) (where @(I/J) to denote is an formula to denote @(+I ) A . . . A @(I),,,) and 3+P(@) too (as stipulated set of preference that contains in Definition is finite, fi) @($I) V...V@(&l). Define accessibility as follows: Definition 12 (Accessibility). via an action. Define: Let A+ stand for the fact that situation (b is accessible def A+ * (al)4 V (a2)+ V.. V (ak)+. Thus, operator A acts as an existential quantifier over action terms; if situation 4 is accessible impinges language many action alternatives via an arbitrary action, on this definition. because we assume at their disposal. In defining then we have A$. Note how bounded inside accessibility we can stay and have only that agents are not omnipotent rationality the object finitely Define a “good” situation 4 as a situation that the agent prefers to its negation and conversely for a “bad” situation. Definition 13 (Good, bad situations). for a “bad” situation 4. Define: BA+ Let GO4 stand for a “good” situation 4 and Define an element of the agent’s preference order in the obvious way: Definition 14 (Element of the preference order). agent’s preference order. Define: Let FYI+ stand for an element in the 5.1. Goals for action logics. Following Goals are a crucial notion (and, for that matter, standard decision the basic notions of bounded theory), we derive goals from prefer- they are not a primitive notion as in other action logics. But there are many ways it it may is often identified rationality ences; to base goals on preferences. A situation may be singled out as a goal simply because is better be satisficing, outstanding it is better than other situations; rationality than its negation, or, perhaps, because or optimal. Bounded (extremal), Z. Huang et al./Artij?cial Intelligence 82 (1996) 75-127 85 rationality the existence, that agents do not optimize, into the search for extremal solutions; with the notion energy to satisficing the reduction of bounded relevant when or the accessibility, If a known alternative meets a given aspiration not search level, the agent will search for better solutions, agents might act irrational if they never do, aspiration introduced and a drive for improving one’s situation in order to develop a more realistic for a better state; conversely, is misleading. Satisficing of potential goal states level, at least not in the sense of putting much they are said to satisfice. However, instead, is, indeed, is unknown. the agent will the aspiration at least up to a certain point. However, alternatives; then, as a rule, if no known alternative meets if they do not pursue known better accessible levels could only go down). Bounded rationality has been framework of rational decision making, is apparent in many human decisions. We present four goal definitions (good, satisficing, extremal, optimal), and discuss some obvious modifications of these definitions. Agents might opt for a state simply because it is better than its negation, particularly if only a few alternatives at night far from home without a car, he might base his decision simple deliberation can be defined by using late to take a taxi on the that it is better to take a taxi than not to take a taxi. A “good” goal are considered. For example, the “good” operator GO: if an agent finds himself Definition 15 (Good goal). Let Gg4 denote the fact that $I is a good goal. Define: Gg+ & GO+. that is preferred to its negation. Thus a good goal is a situation The second definition addendum a procedural tant as it is-is the declarative part of bounded dural part concerns [ 671. So, satisficing enough search. Let S4 stand for an arbitrary action terms by allowing for mnemonic involves a satisficing goal. As noted above, satisficing-impor- rationality the question of what to do when concerns states are, in fact, satisfactory to the definition of bounded incomplete knowledge, rationality. Whereas the proce- is not complete states made accessible via situation 4 and relax the definition of the knowledge satisficing expressions: S4 @ (satisjicing-search)@ A FOC$. Note that this definition does not exclude that the satisficing name of search, but is not defining, or describing, satisficing goal in terms of a satisficing solution state: the possibility that the search is void in cases is using the itself. Define a the search process is already at hand. Note also that the definition Definition 16 (Satisjcing Define: goal). Let G”r$ denote the fact that 4 is a satisficing goal. As argued above, agents may try to maximize, or even optimize, supports the search for extremal values. For example, in production planning, if the context optimal 86 2 Huang et al./Artificial Intelligence 82 (1996) 75-127 are sought and implemented on a daily basis. Whether a solution solutions or optimal depends, of course, on the structure of the preference order of an agent. If it is partial, but not total, the order may contain several maximal, If, furthermore, more than one maximal element the intuitive goal can be identified same token, a partial order gives rise to an optimal goal if only one maximal is accessible. We define a “best choice” as a maximal goal and specify under which such a best choice may, in fact, be optimal. elements. then an optimal goal (in an optimal is accessible. By the situation the conditions if the order is total and at least one situation sense of a best overall solution) cannot be defined. Conversely, is accessible, incomparable is maximal Definition 17 (Maximal goal). Define: Let Gbc$ denote the fact that 4 is a best choice. Thus, a best choice is an accessible preferred. A best choice 4 is optimal, situation if 4 is unique: to which no other accessible situation is Definition 18 (Optimal goal). Let Cop4 denote the fact that 4 is optimal. Define: Cop4 a Gbc4 r\‘dt,b( (Gbc#) -+ (4 H t,Q)). Ironically, best choices need not be good nor satisficing. In a tight spot, an agent’s The above definitions according that goals be consistent, best alternative might simply be the best among dubious alternatives. can be modified stronger notion of rationality may require not select both 4 and + upfront, because contradictory requiring operator, good goals are always contradiction-free. as follows: there are many applications [ 4 1,421, but consistency of bounded can be built goals Define a consistent that a goal be, at least, a good goal. Because of the irreflexivity rationality into the goal definitions that do allow for by of the P satisficing goal to the domain. For example, a so that agents will as goals in the same situation. We did not require consistency Definition 19 (Satisjicing Consistent Goal). Let Gsc+ denote isficing, consistent goal. Define: the fact that 4 is a sat- best choice can be defined analogously. Optimal goals are always con- they are unique. reasonable modification is obtained by imposing of the goal definitions A consistent sistent because Another requirement uncertain whether goals is sometimes hailed as post-modern management circumstances, they are accessible of accessibility. Sometimes, (setting goals are pursued even when seemingly, but not really, the agent inaccessible [ 91) . In better-understood style however, accessibility may appear as a reasonable requirement for a the is Z Huang et al./Arti~?cial Intelligence 82 (I 996) 75-127 87 goal definition. All goal definitions the accessibility between maintenance add the goal situation case of a maintenance example, a “good” achievement requirement. Another useful modification is obtained by distinguishing above can be strengthened accordingly by adding and achievement as a conjunct goal and add the negation goals. Again, it is easy to see how to do this: in goal. For in case of an achievement to the definiens of the respective goal definition goal can be defined as follows: Definition 20 (Good achievement goal). goal. Define: achievement Let Gg”~ denote the fact that $ is a good It might go without saying about accessibility; stipulation that the definition of extremal goals must always make a otherwise, the sky is the only limit. 5.2. Using goal definitions: an example language Although propositional the underlying imposes obvious this by representing Max Weber’s large parts of twentieth-century three “types” of rationality: limitations present version of the logic, ALX can already serve as a knowledge-representation We demonstrate formed between (3) goal rationality. Traditional stimulus their lives. So, if a situation dition. Let G stand for an arbitrary goal; then we can characterize by the formula typology of rationality which [ 16,52,53]. Max Weber distinguishes (2) value rationality, as a mode of behavior along to improve is a goal, then it remains a goal, regardless of the precon- rationality sociology (1) rationality follow traditional is circumscribed the tradition, response patterns. Agents on the tool. in- rather than seeking rationality, traditional type of rationality, value rationality, that are singled out for The second goals ramifications. We can express furthermore, appear in the preference order: that the ramifications their intrinsic is circumscribed value and without to preset for possible that all goals must be good goals and, of such goals do not count and hence, should not as adherence regard this by stipulating third The solutions type of rationality (goal rationality). is circumscribed search for optimal as the unconditional In this rationality mode all goals are, at least, best choices: Gc,?I --f Gbc~. Weber cautions his readers repeatedly classification. Our formal building blocks entering types. Much of the confusion would realize this more clearly. representation the characterizations against immediately taking his typology for a complete shows, that, in fact, the set of can give rise to many alternative rationality about Weber’s typology would, in fact, go away, if one 88 Z. Huang et al./Artijicial Intelligence 82 (1996) 75-127 6. Discussion ALX provides tional description an update operator and a set of action modalities. the skeleton of a preference-driven language logic, based on a proposi- action and three types of modal operators, a preference operator, 6.1. Preferences Although preference-based decision making has received some attention in the AI- literature [ 8,701, ALX is actually the first preference-based action logic. [ 171 and codified by von Wright transitivity and the conjunction principle. We modified his approach by adding normality Our choice of irrejlexivity was made for technical Modal preference logic was introduced by Halldtn are less intuitive for reflexive preferences (indeed, Transitivity of preferences [ 72,731, whose preference operator satisfies irreflexivity, expansion erences context-dependent. The machinery statements language). natural rational, preference-based setup of bounded have done away with transitivity, [42]. ALX can accommodate without fact, allow for intransitive logic without claiming intransitive losing completeness decision making (TR) ALXFTR. and decidability as the following preferences, rationality. However, more radical applications that organizational preferences since transitivity [29]. This non-transitive example and making pref- reasons. also, reflexive preference of bounded in of in the basic rationality choice is often intransitive can be dropped in logic does, shows. Call an ALX is more complex; it is not easy to express reflexive preferences is widely seen as a basic requirement and has not been challenged Claim 21. There exists an ALX-TR model M = (W, cw, F, Ra, V) and a world w E W such is transitive. the comparison In particulal; we claim that M, w k (pPq) A (qPr) A -(pPr). that preferences transitive, are not relation though even t Proof. Suppose M = (W, cw, >-, R”, V) as follows: that the set of primitive propositions is {p, q, r}. We define the model w = {wpqr, w/>q, Wpr, Wqr, wp, wq> wr, w0). We define cw (to the extent that we need it for the example). CW(W,” [P A 1413J = {w,J. CW(W,I, 1-p A 4n‘& = {WJ. cw(w,,, [is A -rI,> = {wljq}. cw(w,, U-s A rDMM) = 1~~~~). CWCW,,, IIp A TrIMI = {w,& CW(W,,, [I-P A rDMM) = J&+1. >-= {(w,,3wq), (wpq3 w/w)). Z. Huang et al. /Artijicial Intelligence 82 (1996) 75-127 89 Fig. 2. Counterexample against the transitivity. V(P) = {w[Iy’> wpyl W/Y> W,I). V(q) = {qq,, wp*, Wyr, wq}. V(r) = {W,X,T, W/W, Wyr, w}. It is easy (pPq) A (qPr) A -(pPr) to see that the above model M is an ALXpTR model and 0 (see also Fig. 2). that M, w,, + Normality (N) was originally added to ALX in order to achieve completeness. (N) turns out to be instrumental in blocking counterexamples against Fur- the thermore, conjunction expansion principle. The conjunction expansion principle (CEP) itself has always [49]. We have kept (CEP) restricts the logic’s ability and for several to represent raised eyebrows to preference contributed reasons. First, we do not preferences examples where t,G to $-and-not+. preferences. result is the following or preference-related it makes If the conjunction think logic’s unpopularity that (CEP) notions, to prefer q5 above sense such as goals. At least, we cannot i/j but not think of to prefer &and-not- of context-dependent Second, we need in the construction (CEP) expansion principle is dropped from the semantics, the interpretation function of the preference operator: M, w /I- 4Pf) iff cw(w, U4],> * cw(w, I[&,> and on this interpretation function, the following formula becomes valid: But this formula traditional argue elsewhere assume, as in [4], Smith alone is happy: is obviously counterintuitive. counterexamples against (CEP) , because Third, ALX does not give rise to the (N) blocks these examples. As we [28 3, these examples instance, that it is better that Smith and his wife are happy (p A q), than that Ap are based on implicit partiality. For expansion yields (pAqATp)Pl(pAq) (pAq) Pp. Conjunction 90 Z Huang et al./Artijicial Intelligence 82 (1996) 7%127 and hence false in ALX because the preference (N) assures that: for a contradictory state of affairs. This example comes out forces the user is not happy: ALX his wife a contradictory counterexamples [ 4,2 1 ] and are blocked ALX has a situational to make the implication explicit that if Smith (p A q)P(p A -4). This statement entails no preference state of affairs; to the conjunction it is equivalent to its conjunction expansion principle also exploit in the same way in ALX. 7 is happy alone, for expansion. Other implicit partiality semantics of 4 above # as similar as possible can be unstable; hold a preference under conditions preferences and an opposite preference role in many applications of bounded still be handy for theoretical purposes theories where stability of preferences relation would be one stable preferences example, that can be expressed as propositions. following elsewhere axiom: [28]; to relations: the agent for preference iff she would prefer &and-not-$ to her actual situation. Obviously, the agent may hold a specific preference is supposed to Q-and-not-4 situational in one situation in another. Although unstable preferences play an important rationality 11, stable preferences might (e.g., when using the logic to represent economic [ IO] >. A stable preference to world. We have discussed relation does obtain, empty) is often assumed from world stability of the preference set of conditions [ 3,41,42,5 (possibly for Stable preferences can be characterized with the if a preference depends only on a finite that does not change ww (NV) 0 x -+ (e-v), as shown in [ 281. 6.2. Minimal change and actions It should be clear, however, is adopted from dynamic are is, in a sense, the question of whether a particular 4 is accessible via action the logic and its axioms that this notion of action if the agent does a), but it does not answer (Al)-(A3) Our notion of action it answers not problematic. contemplative: a (or conversely, what would happen question of whether We have used to reflect the context dependency statements, preference introduced minimal counterfactual backward-looking conditionals the agent will, in fact, do a. change the notion of minimal but minimal change to modal that reflect causality dual to Stalnaker’s conditional, is not bound should appear change logic serves other purposes in order to capture of as well. Stalnaker the semantics of the is a [38,68]. Our update operator as the “Ramsey rule” shows. In our setup, the action operator causal effects, minimal [ 14,33,7 11. This could address some nastier problems of action logics, in particular quali$cation, to minimal change. Since actions entail in the semantics of the action operator the frame, and ramiJcation problem. Actions may require a specific context change ’ Contraposition has also been vigorously it follows is, in fact, redundant; since (CP) attacked with similar examples. The similarity from (CEP) and (N) as we have proved in Proposition 6. is not surprising, Z Huang et al./Art$cial Intelligence 82 (1996) 75-127 91 through to minimal the accessibility (qualification) change that the action description must take into account. Linking can provide an implicit qualification of the context of a for that action. Using minimal change, is given by the actual state (that either will or will not permit action a to be no additional for execution actions specific action this context executed); relation not have to change as a function of a’s execution. And are “automatically” is given by those conditions the ramifications for action u is given. The frame of change the set of its weakest postconditions. that do of an action captured by identifying is required, once the accessibility of the context specification relation logic”, perhaps restrictions the standard even a full-fledged the closest world function definition. We have refrained i.e., a logic whose formal semantics ALX does not put strong constraints on the closest world function. Stronger constraints from might be desirable, for ALX for two reasons. First, we wanted to provide defining is more than a faithful mirror a “logicians setup without of its syntax. As a consequence, we have used strong on the definition of models and have not given a description of the properties of possible worlds. A definition of the closest world function would require such a description. of the notion to provide a definition of “closest worlds”, despite various attempts [ 14,22,23,33,36,71]. do not restrict the set contains the set of closest worlds as much as intuition between more worlds it should) is required, epistemically however, because the closest accessible world might very well be further away than the closest There are two main problems: seems than closest worlds and causally imaginable world, and this difference Second, we are not sure about the definitions (so closest worlds. This distinction do not clearly distinguish the exact meaning in the literature the definitions for an action is important to require semantic ; also, logic. We can this point by looking at minimal interpretation change. Unfortunately, illustrate action. After all, the standard in terms of minimal minimal where, by doing action a, the agent can achieve a minimally way to conceptualize via action a. Call this kind of “minimal condition to conceptualize the set of worlds different &situation. One such a change would be in terms of the closest world accessible truth change as a consequence of an is in terms of causality, hence to actions. We use (a)“4 (u)“‘. The corresponding there are several ways change with respect change action” of actions to denote is: [(~)“‘47]~ = {w : 3~’ E W(w’ E cw(w, {x : Rawx}) and w’ E [+jM)}. to this truth condition, According action a and from this set picks the @worlds (u)“‘@ first looks at the closest worlds accessible via that a denotes the door will cause Consider, as an example, the door” and assume that slamming to, say, the door” that will leave the picture unharmed). Assume 4 stands for the fact “closing that the door is shut. (u)“‘+ now looks at a world where the door is shut and the picture fell off the wall. to fall off the wall (as opposed the picture A second possible definition would approach the minimal change via minimally (see Fig. 3). the action of “slamming dif- (a)“” (see Fig. 4). The ferent &worlds. Call the corresponding minimal change action is: corresponding truth condition [(u)“‘~I],,, = {w : 3w’ E W(w’ E cw(w, [qS],) and R’ww’)}. Z. Huang et al./Artijicial Intelligence 82 (1996) 75-127 Fig. 3. Minimal change action (a)#‘. Fig. 4. Minimal change action (a)#2. Reconsider the previous example for (u) #’ Slamming . the door would now get us to worlds where the door is shut and the picture is back on the wall. Since an additional action is implicit in (u) #2, this kind of minimal change appears less if the intersection (u)#’ will give counterintuitive than (u)“‘. But (u) #’ has a drawback as well: of accessible worlds and 4-worlds of the closest u-accessible worlds with the &worlds if slamming is not empty and the is. This could happen, the door would not shut the door (say, because of reverberation intuitive results intersection for example, of the door frame). To cover this possibility we might want to look at the closest world in the the minimal change action of the accessible worlds and (u)#” (see Fig. 5). Th e corresponding is not empty. Denote truth condition this kind of minimal is: is not going the closest worlds of u-accessible worlds and &worlds. On the empty set if the intersection change by intersection this view, to return [(u)“%$], = {w : 3w’ E W(w’ E cw(w,{x : RQwx} n [&f))}. But (u)“” cannot be the last word either, because it leaves undecided the question of whether the picture of the closest world function until we can decide is on the wall or not. In sum, we should avoid a full-fledged definition this-and possibly other-questions. 2. Huang et al./ArtQicial Intelligence 82 (1996) 75-127 93 (x Rawx] Fig. 5. Minimal change action (a)#3 6.3. Goals Goal logics logical if pain primitive implication rule for goals in other action is an important is always a consequence as goals, as the necessitation that try to avoid these consequences (if LY is a goal and LY ---f p is a theorem, notion act as universal modalities. As a consequence, (if LY is a theorem, [ 5,6,59], where the the logics have these goal operators then (Y is a goal) and the closure of necessitation then /I must goals under rule and the deductive closure of goals have fairly severe be a goal). The necessitation counterintuitive of having For example, implications. one’s teeth fixed, then the pain itself becomes as a goal. Also, it does not make sense to rule would require. Much recent work in treat tautologies action logic has gone into systems an bring in other array of goal-related notions in Cohen and Levesque’s counterintuitive or additional the fact logic it is a theorem [5,6], becomes and qualified goals (agents need not adopt as goals logical closure true and they need not to adopt @ as a goal what they believe if they believe q5 -+ (CI to be inevitably always true and if they have 4 as a goal). But in order assumptions. a goal. ALX can avoid both by much simpler means, operator. world contains rule and the deductive closure of goals for the preference effects of goals. For example, that if an agent believes the agent’s goal. Rao and Georgeff’s paper [59] avoids both necessitation these results, Rao and Georgeff have to make other counterintuitive they must assume the necessitation since we need not require monotonicity that any believe-accessible to be inevitably always [ $6,591. Unfortunately, for certain epistemically these complications that a fact holds, by introducing For example, to obtain then Proposition 22. implication, do not sati& (i) Goals d ~5 d e ne i.e., k (q5 -+ @> does not imply + (G$ + GJI). ( as logical (ii) Furthermore, goals in this paper) are not closed under the necessitation rule, i.e., b 4 does not imply b Gq5 Proof. (i) We construct a model M = (K cw, +, Ra, V) for which M k (4 --f $j and M /& G+ --f G$ holds. Let W = {wl, w2}, let cw : W x P(W) + P(W) be a function that satisfies and let R” be any set. Define V Let %= {({wl},{w2})} (CSl>-(CSC). 94 2. Huang et al./Arttj?cial Intelligence 82 (1996) 75-127 as follows: V(p) = {wl}, V(q) = {wl,w2} and V(r) = (~2). It is easy to see that IIpl, c [qjM, so that M + (p -+ q). On the other hand, we have: cw(w1, IIp A V-l],) = {wl}, CW(W~, [q A 7nM) = {wl}, [Y A -pII,) cw(wl, CW(W~, Or A lqjM) = 0. = {w2}, Therefore, M, wl //- (pPr) A 7(qPr). Hence, M, ~1 II- -((M+) ---t (qpr) ). Thus the preference operator is not closed under logical implication. As a consequence, goals defined (ii) We have shown in terms of preferences that are not closed under logical implication either. T(TP+) is a theorem of ALX, hence rule. 0 6.4. Decision and planning the preference operator does not satisfy the necessitation to represent ALX is designed and his action alternatives theories about human actions, particularly theories about These theories are usually built around a decision cycle that has an agent of his problems in AI, is not a typical problem goals as a function as understood a procedural organizations. pondering it is Planning, sequence of actions primarily that an and find it fast. ALX’s logical properties to a particular goal can always be found, existence proof of an action sequence provided relation this action sequence RU. This may be more than can be said of some other planners. As an example, consider the case of conjunctive We have a machine i.e., a substructure of the accessibility given a goal, find an an optimal for such theories, because planning discussed (completeness, decidability) is feasible, guarantee problem: in [43]. [35,54]. leading quarters. Due to an unfortunate a quarter when can change four quarters to buy cakes and apples; a cake costs a dollar and an apple three the machine only accepts dollars and it returns to alleviate the machine in part this problem, (see Fig. 6). design, the user buys an apple; One meaningful planning is: Assume a user has five quarters can he get a cake and have some change left? We can represent in his pocket: the domain as follows: into a dollar problem ( 1) having-one-dollar + [buying-a-cake] having-a-cake. (2) having-one-dollar ----t [buying-an-apple] (having-an-apple A having-one-quarter-left). having-four-quarters --f [change] having-one-dollar. having-five-quarters -+ having-four-quarters A having-one-quarter-left. (3) (4) Z. Huang et al./Art$cial Intelligence 82 (1996) 75-127 9s buy cake buy apple change cake quarters Fig. 6. A simple conjunctive planning problem In the next three assumptions, we exploit be void: the fact that the universal action modality can (5) (6) (7) (8) having-one-quarter-left 4 [buying-a-cake] having-one-quarter-left. having-one-quarter-left -+ [buying-an-apple] having-one-quarter-left. having-one-quarter-left -+ [change] having-one-quarter-left. having-one-quarter-left 4 having-some-quarter-left. The following statement describes the specific situation of the user: (9) having-five-quarters. The planning following problem state accessible: is whether or not there exists an action sequence that makes the (having-a-cake A having-some-change-left). In proving proof is as follows:8 this state from the premises, we generate the required action sequence: the having-five-quarters + having-four-quarters A having-one-quarter-left + having-one-quarter-left A [change] having-one-dollar + having-one-quarter-left A (9) (4) (3) [change] [buying-a-cake] having-a-cake (1, MONA) ’ In the proof, we use the ALX theorem [a] (4 A $) ++ [ U]C$ A [a]+, which is derivable from ALXS, since: (4(-dJ v -JI) - (4-4 v (+b H y(rl)(-d V -$) ++ -((n)-4 V (a)-$) * +l)+& A $) - l(+#J A -l(u)-lc, * I~~l(4Afi) - lrll4A 1alJl (AZ) (Meta-reasoning) (Meta-reasoning ) (Definition of [ ] ) 96 Z Hung et al./Artificial Intelligence 82 (1996) 75-127 =+ [change] having-one-quarter-left A [change] [buying-a-cake] having-a-cake (7) + [change] [buying-a-cake] having-one-quarter-left A [change] [buying-u-cake] having-a-cake (5, MONA) + [change] [buying-u-cake] having-some-quarter-left A [change] [buying-u-cake] having-a-cake (8, MONA) * [change] [buying-u-cake] (having-some-quarter-left A having-a-cake) ( ALX theorem) ==+ [change] [buying-u-cake] (having-a-cake A having-some-quarter-left) (SUBA). its action modalities for finding plans efficiently. Also, ALX has, in its present ALX has no machinery to the execution of actions version, no way of linking plans; that a decision or an action has, in fact, occurred. An indirect way to simulate decisions would be by defining a necessity operator’ that choosing a particular goal makes and saying this goal necessary so there is no direct way to express (or, for that matter, attitudes) are contemplative, But this expression does not fully capture done operator would be helpful, but such an operator includes time explicitly. the intuitive meaning of “decision”. A do/has- that requires a semantic setup ALX could represent a planning procedure that builds an evaluation gradually as the preferences on states, so that certain planning process progresses, states allow for an evaluation whereas others don’t. But, again, this representation would not cover the dynamic flavor of a real planning process where “the world out there” acts as an oracle and the task is to make this oracle simply by conditioning talk and talk fast. 6.5. Expressive power There are still many is due limitations description to first-order is ALX’s present to ALX’s expressive power. The most to a propositional extension available knowledge and the knowledge available to the absence of a belief operator. We cannot distinguish restriction suggests a straightforward we think, construction limitation “objectively” maker, so we cannot model For example, we cannot distinguish between disbelief although we may need operator. For example, a time operator would be useful to express a notion of “tradition”, the future. Last, but not least, we may want to extend ALX or of expectations important, language; ALX’s logic. A second important between to an individual decision the difference between objective and individual knowledge. and accessibility, its goals. Third, the process of causality or to define a do- is important when a rational agent is pondering in inaccessibility time operators this distinction to represent regarding ‘) This can be done as follows: 0~) & -q5 -+ q5 2. Huang et al./Artijicial Intelligence 82 (1996) 75-127 97 acting, by allowing for indexing modal operators with agent terms and to multi-agent for quantification We have tried over agents and actions. important to incorporate rationality capacity. Yet it is one thing limits and another one to find out where The basic message of bounded information-processing of these case, one has to make sure that omniscience In the second case, one has to identify which logic would be able to fully answer empirical one. However, address Simon’s original conceptualization aspects, especially its procedural semantic setup. Incorporating we did in the definition of satisficing as a distinct object perhaps this area [ 57,581. to the logic. This, that future work may be able to exploit in this paper. It was not very difficult search explicitly in turn, seems elements of bounded is quite simple: remember to recognize these limits are drawn. rationality into ALX. the limits of human the abstract existence In the first claims are avoided. is processed and how. No since it is to a large extent an that we did not aspects 01 the declarative to transpose claims or omnipotence information the second question, the question does have some general aspects of bounded rationality search, may require a completely into an action logic. However, semantic different in the logic (rather than just naming it, as states) seems to require introducing to require at least a partial “information” the progress of situation semantics logic; in 7. Conclusions and future direction is fairly sim- and ALX is the first preference-based let an agent have context-dependent action logic. Its basic construction give about realizing construction preferences, that reflects of preferences and the ability nor are tautologies the idea of minimal it action alternatives and action alternatives. add a notion of causality to a multi-agent avoids its actions on the basis of preferences logics. For example, goals automatically ple: let it deliberate Furthermore, context-dependent ences gives ALX a strong expressive potential-although require an extension of the logic language. Also, ALX’s basic construction and preference implication, tion expansion ALX an ALX-theorem for the use of ALX as a planner, task is knowledge ALX show that the combination flexible representation Our plan extension a belief operator, continue. change. The to build nested prefer- this potential will setup and to a first-order description important weaknesses of other action logical the infamous conjunc- (N). the ground of logical properties would even allow albeit an inefficient one. However, ALX’s primary experiments with a first-order version of of preference, action and update modalities allows for a [ 461. is to build a sequence of more expressive versions of ALX, starting with an facilities, language, to first-order a “do” operator. Work on ALX will logic as a description time operators and (if possible) and decidable, which prepares its pleasant in ALX need not be closed under of a variety of theoretical problems then adding multi-agent is tamed by normality for the development prover. Furthermore, from von Wright’s goals. Furthermore, in organization representation. is complete Preliminary principle theory (CEP) logic 98 Z Huang et al./Artijicial Intelligence 82 (1996) 75-127 Appendix A. Proofs A. 1, More properties of the preference operator Proposition 6 (More properties of the preference operator). theorems of ALX: The following formulas are (W (IR) (NT) (AS) 4PG * (-$)P(3), -(4P4)7 -(TP@),-(+PT), 4P+ --f ,($P$). Proof. (CP) 4w H (-$)p(+). I- WV @ I- (4 A ,$,)P($ A -4, @ I- (-rcI A -(-4>)P(-+~ (+-+))I @ k ,*p+ (IR) -4#W). (CEP) (SUBP) (CW I- (w$) I- (4 A +)P(~J A -4) /-IPI * * *i-l (CEP) (Definition (N) of J-) So t-- ( $Pc$) + 1. Therefore, k -(+P+). (NT) 4TP4), -(W-V. I- (TP4) I- (+)P(TT) I- (3)Pl I- I * * * (CP) (Definition of T) (N So, I- -( TPq5). The proof for the second half of (NT) is similar. (AS) 4PQ + $$P4). I- (cm+) A (tip+> I- 4p4 * =+ j- I Cm) (IR) 17 A.2. Soundness Lemma 23 (Soundness ALX models. of the update axioms). (Ul)-(U6) are valid on the class of Z Huang et al./Artificial Intelligence 82 (1996) 75-127 99 Proof. WI) $o$ -*. M* w II- + O (I, ++ 3 E [4],(w E cw( i, [$] M) ) (Truth condition) =$ z E u+n,<w E [IAl,) =+ WE wn, H M, w II- cc, (CSl) (Meta-reasoning) (Definition of II-) (U2) $~$-)+oIcI. ++ M, w /I- 4 and M, w II-- 9 H w E ud4j, and w E utin, (Definition (Truth condition) of /I-) + w E pn, and CW(W [tin,) = {w) =+ ~W(W E wn, and w E cw (w, [[(cl] M) > H M,wI(-+o$ (U3) -(iO4).-(+oI). M,wIj-Io+ (CS2) (Meta-reasoning) (Truth condition) ti 3i( i E [[_L]lM and w E cw(i, [4],)) (Truth condition) + 3i(i E p-1,) + False (Meta-reasoning) (Meta-reasoning) (U4) (+vlCl)oxH(~OX)V(GoX). M,wII-(~VG)ox H 3i(i E [I~v+~J, and w E cw(i, [Ix],)) or ej 3i((i E [[4j, and w E CW(~, [I,&,,>> (i E usn and WE CWGJ,&))) (Meta-reasoning) (Truth condition) ~~ll-(~ox>orwll-(~~ox> @ wll-(~~x)v(~ox) (Truth condition) (Truth condition) =S 3i(i E [+I, and i E [t&, and w E cw( i, [[tin,) ) (Truth condition) (Truth condition) =+Lli(i~[+!~],andw=i) =+ we u+n, + M, W II- b%, (CS2) (Meta-reasoning) (Definition of I/-) 100 2. Huang et al./Artifcial Intelligence 82 (1996) 75-127 (U6) (4oG) Ax~+o(rcIAx). H 3i(i E [+I, and w E cw(i, [I+],,,,)) and w E [[x]~ =+ 3i(i E [[@I, and w E en+, u+n,) n uxn,)) + 3i(i E [4jj, and w E CW(~, [I$ A xj,) @ M,w /I- (PO(9AX) (Truth condition) (Meta-reasoning) (CS4) (Truth condition) 0 Lemma 24 (Soundness on the class of ALX models. of the preference axioms). (CEP), (TR), and (N) are valid Proof. For any ALX model M = (W cw, +, R,, V) and any w E W: (CEP) W@ ++ (4 A -ti)P(@ A -4). H cw(w, H cw(w, [[4 A -$],,,) + CW(W, [i+ A -+],I cw(w,u(~~l~) A a,) F ~~~~~~~~~~~ ~(4 A -ICI) A 39 (Propositional (Truth condition) logic) H M, w II- (4 A -G)P($ A -4) (Truth condition) (TR) (W@) A (tipx) -+ (Wx). M>w II- (+P$> A (tipx) @ cw(w, [[+ A +nM) k- cw(w, [I@ A -+n,) and CW(W, uti A -Xn,> + cw(w, ~4 A -xn,) @ M,w I/- (Wx) (N) -(J-W),3@~). t CW(W uX A -&) + CW( W, ux A +)nM) (Truth condition) (TRAN) (Truth condition) H CW(W, [I A -$I],) + CW(W, + cw(w,O) k cw(w, ua,) + 0 + cw(~, kg,) a False [+ A T],) (Truth condition) (Propositional logic) (CSl) (NORM of +) The proof about -(qSP_L) goes symmetrically. 0 Lemma 25 (Soundness ALX models. of the action axioms). (Al )-( A3) are valid on the class of Proof. For any ALX model M = (W, cw, +, R,, V) and any w E W: Z. Huang et ul./Artijicial Intelligence 82 (1996) 75-127 101 (Al) (a)1 c-) I M,w II- (4J- ej 3z ( RUwz and z E [Il.],) (Truth condition) =+ 3z(z E 0) + False (Meta-reasoning ) (Meta-reasoning) By propositional logic, I + (a)I_. So (a)l ++ I (AZ) (a)(4 V $) H (a)4 V (+b. H 3~ (R”wz and (z E !+I], or z E [$,I],)) (Truth condition) e 3z ( RL’wz and z E [4],) or 3~ ( Rawz and z E [[qb],) (Meta-reasoning) @ M, w II- ((44 v (4G) (Truth condition) M,w II- (a)($ArCI> H 3z(R”wz and z E u4wnM) (Truth condition) H 3z( R”wz and z E [Iqbjj, and z E [+j,) (Truth condition) + 2z( R”wz and z E [d$,J and 3~ (R”wz and z E I)&,& H M, w I/- (a)+ and M, w II- (a)$ @ M, w II- ((a)4 A k+b> (Meta-reasoning) (Truth condition) (Truth condition) 0 Lemma 26 (Soundness (NECA) , (MONA) of the inference rules). (MP), and (MONU) are validity-preserving (SUBA), (SUBU) , (SUBP) , for the class of ALX models. Proof. For any ALX model M = (W, cw, +, RU , V) : (MP) I- 4, I- (4 ---t ti) *I- ICI. 4 and (4 --) t+b) are valid for M + Mw E W( M, w II- 4) and ~‘wEW(M*WII-(4--,rC/)) (Definition of validity) =+ VW E W( M, w )I- 4 and M, w )I-- (4 + $>> (Meta-reasoning) * VwE W(M,WII-~A(~+~~~)) =+ VW E W( M, w /I- fi) + fi is valid for M (Truth condition) (Definition of -) (Definition of validity) (SUBA) I- (4 ++ 4’) =+ ((+J H (+#J’). 102 Z Hung et al./Art@cial Intelligence 82 (1996) 75-127 4 tf 4’ and (u)4 are valid for M II- (4 H 4’)) and + VW E W(M,w VW E W(M, W II- (u)4, + VW E W(M, w II- 4 H 4’) and VW E W(3w'~ W)(R’ww’and (VW E W) (3~' E W) (R'ww' and M, w’ I[-- 4’) M,w’#- 4)) + =+ (VW E W) (M, w II- (a)47 + (u)4 is valid for M (Definition of validity) (Truth condition) (Meta-reasoning) (Truth condition) (Definition of validity) Therefore, /- 4 ++ 4’ *I- (a)4 -+ (u)4’ is validity-preserving metrically, we can show that I- 4 H 4’ +I- (u)4’ + (u)4 is validity-preserving. (SUBA) is sound. on a model. Sym- So The soundness of (SUMP) and (SUMU) is established in a similar fashion. (NECA) I- 4 *I- Lal4. 4 is valid for M =+ (VW E W) (M, w II- 4) + (VW E W)('dw' E W)(R'ww' =+ M,w' II- 4) I/- [al4) =+ (VW E V(M,w + [a]4 is valid for M. (MONA) I- (a)43 t (4 --f q> +t (u)$. (a)4 and 4 + Ic, are valid for M (Definition of validity) (Meta-reasoning) (Truth condition) (Definition of validity) + VW E W(M, w II- (u)4) and U4j, 2 U+bjM (Definition =+ VW E W(3w'(R"ww' and w’ E U4j) and of validity) ~411, c ud, + VW E W( 3w’( R”ww’ and W’ E [[+jjM) =+ v’w E W(M,w /I- (@k) + (u)cC, is valid for M (MONU) i-40x+ (44$,> +tGox. 4 o ,.y and 4 + $ are valid for M (Truth condition) (Meta-reasoning) (Truth condition) (Definition of validity) + VW E W(MW II- 40~1 and U4JJM c iit%, (Definition + VW E W(~W’(W’ E [$j and of validity) w E CW(W’, [Ix],) u4n c uad and (Truth condition) =+ VIE ~(3~7~ E u+q, and w E cw(w’, axI,)) (Meta-reasoning) +VWE W(M,wII-$0~) d (CI o x is valid for M (Truth condition) (Definition of validity) Cl 2. Huang et al./Art@ial Intelligence 82 (1996) 75-127 103 Proposition 7 (Soundness of ALXS) . ALXS is sound. Proof. Lemmas A.l-A.4 together imply it. q A.3. More properties of the update operator Proposition 27 (Update of ALX models: theorems). The following propositions are sound for the class Wl”) W2”) (U3”) (U4”) (USO) (U@‘) (U7”) (US’) Proof. (VI01 @04,-b ti 3i(i E (IqbJ, and w E cw(i, [4],)) (Truth condition) @ WE WI, @ M, w II- 4 (CS2) (Definition of )I--) (U2”) (409) o+ -qbo$. Firstweprove (+). Mtw II- (40@) 0th ~2 3i(iE I[q50(//], and w E cw(i, /qbJJM,>) (Truth condition) * 3i3j(j E @$IM and i E cw(j, [t,b],) and w E cw(i, [[@I&) (Truth condition) =$ 3i3j(j E [q5], and i E cw(j, [+I,) and w = i) (CS2) (Meta-reasoning) (Truth condition) ++ 3j(.i E [$I, and w E cw(j, US],)) H M, w II- 4 0 * Next we prove (+). M>W II- (rbo$) =+ M,w I/- ($fJo$) A* (U1) =j M,w II- (40$) o$ w> Therefore, (q5 0 +!I) * (4 0 @) 0 $. 104 Z Huang et al./Artijicial Intelligence 82 (1996) 75-127 uJ3”) -4A (40$) -+ (+A+) OVQ. ~~,w/I-l~aandM,wII-~ocCr H M, w //- -4 and 3i((i E [qJ],) and w E cw(i, [$],)) (Truth condition) (Truth condition) Case 1: i E I[-@],. =+ 3i(i E [[4], and i E [[-en, and w E cw(i, [?,b,I],>> (Assumption) H 3i(i E 14 A +I, and w E cw(L [+l],)) @ M,w II- (4A-G> oti (Truth condition) (Truth condition) Case 2: i E u$j,. in wn, =+i=w (W E cw(41)&) and (CSW + M,W Ij- C$ and M, w II- -4 (in [[@, and M,w II--- -4) + False (4r\$) + H -(4 o $) + is valid (40+) -q!~ V w+b is valid H (-(~o~)v~)-+(~~v~_>V(~(//V_L)isvalid ~(~ocC,-I)~(~~I)V(~tI)isvalid H 3i(i E 141, and w E cw(i, [t+b],,,) and w E [+],) =+ 3i+w Suppose that M, i II- t+b, then (Truth condition) (Meta-reasoning) M,i I(- $ =S CW(~,[[$]~) = {i} + w = i + False. Therefore, M, i II f r,b, namely, M, w I/- -$ o I,!J. (U6”) (+01cI> A (%o$> + (+o+) A (+o+). Z Huung et al./Artifkial Intelligence 82 (1996) 75-127 105 (U7” ) (~~9)04~(4~~I)O1cI. M>W II- (+A$) 04 =+ M,w II- ((4AccI) 04) A4 NJ11 =+ M,w II- (GA41 =+ M,w/I-($A$)orCI WI (U2) Therefore, goes analogously. (~r\+)o~-+(~#~A~)o~.Theproofabout(~Ar/~)o~+(~r\~)o~ (US”) ((PA+) 04) ArcI -+ (pAti) 04. M, w I/- ((P A 4) 0 4) A ‘t+ =+ M,wI/-pA((pA+)o+)AICI =+ M,w II-PA~A$ =+ M,w II- (PA’/+) 04 (U5) (Ul) (I-Q) 0 A.4. Completeness proof The completeness for ALX proceeds along the lines of a Henkin-style to an axiom system) that axiom system). A finite set (91, . . . , C,Q} is consistent con- struction. We give a detailed proof. First, we need a definition of consistency. We say is not provable that a formula 40 is consistent if the formula (from if every finite subset (ol A and of it is consistent. A set F of formulas any strict superset reasoning it can be shown: is consistent is a maximal consistent set if it is consistent A (ok is consistent. An infinite set of formulas is inconsistent. With standard techniques of propositional if 1~ exactly (with respect Lemma 28 (Lindenbaum’s of propositional logic and the inference rule (MP) : Lemma). In any axiom system that includes all tautologies to a maximal consistent set. set, then for all formulas cp and +k ( 1) Any consistent set can be extended If F is a maximal consistent (2) (a) either(oEForTcpEF, (b) pA@ (c) (d) if q E F and 40 4 if I- p, then 40 E F. E F iffqog F and@ E F, Ic, E F, then $ E F, The completeness of ALX means that: (A) For arbitrary formula set A and arbitrary formula $, A k 4 + A I-ALX 4. It actually turns out to be easier to show the following statement: (B) For arbitrary formula set A, A is consistent with ALX # A has an ALX model. We show that (A) and (B) are equivalent: Z. Huang et al./Artijicial Intelligence 82 (1996) 75-127 106 Proof. (B) * (A). + A U {-#J} is consistent with ALX (Definition of consistency) + A U (-4) has an ALX model (B) =+ 3M E Mod(M b A and M + -4) (Definition of b) + 3M E Mod( M k A and M p 4) (Truth condition) + It is not the case that tlM E Mod( M + A + M + q5) (Meta-reasoning) *Al++ (A) =+ (B). (Definition of b) . A has no ALX model =+ 1(3M~Mod(M+d)) + b’M E Mod( M k A) (Definition of b) (Meta-reasoning) + YM E Mod( M F A or M k I) (Meta-reasoning) + VM E Mod( M j= A =+ M k I) (Meta-reasoning) *A+1 * A I-&x + A is inconsistent with ALX -l (Definition of k) (A) (Definition of consistency) El Assume that we can construct a canonical model M, where the possible worlds are sets, then, in order to show the completeness, we have to show that maximal consistent for any formula 4, (1) 4E w@wE (2) M, is an ALX model. [4],,9 (for the action and the update operators, So our task is to construct a canonical model lemmas of certain maximal sets required Let IV, be the set of all maximal consistent that is an ALX model. First, we need two that ensure the existence of the canonical model. respectively) in the construction sets built from the elements of FML. consistent Lemma 29 (Action Lemma). V’w E WC((U)4 E w + (32 E WC)($ E z and (V$ E z)((a)@ E w))). Proof. Suppose that (a)$ E w and let F = {qb} U {(cl : -(u)-Ic, E w}. Let w* = {1+4 : -(u)-lc, E w}. We show first that ( 1) w* and (2) F are consistent. We then show (3) the condition of the lemma, always extend F to an F’ such that F’ satisfies that we can i.e. F’ = z. (1) We claim that w* is consistent. This is implied by: ( 1.1) Assume that I E w* we then show that _L E w* -+ False. Z. Huang et al./ArtQicial Intelligence 82 (1996) 75-127 107 I E w* E w E w =+ +z)d =+ +)T * ?(a)T A (a)4 E w =+ +)T 3 False A (a)T E w (Definition of w*) (Propositional logic) (Assumption) (MONA) (Maximal consistency of w) (1.2) We show that &,+z E w* + (~$1 A 42) E w*. + -(a)-& E w and -(a)~& E w ==+ -(@)-#J1 v (4742) E W * -((a)(+1 v 352)) E w =+ 3++(41 A42)) E w =+ #I A42 E w* (Definition (Propositional of w*) (AZ) (Propositional (Definition of w* ) logic) logic) ( 1.3) For arbitrary $, we must show that I,+ E w*,+ E w* =S False. *EW*,+EW* =+ (t/b A-t/b> E w* *IEw* + False (1.2) (Propositional logic) (1.1) We conclude that w* is consistent. (2) We claim (2.2) for any + E w*,+ A@ + that F is consistent. This l_ + False. is implied by: (2.1) C$ + I + False and (2.1) Assume that 4 --t I, then: 4--l (u)i E w + ((a)4 E w and (MONA)) =+_LEW + False (AlI (Maximal consistency of w) (2.2) For arbitrary $ E w*, assume that 4 A Ic, -+ 1. We show that C/J A t+b + i =s False. Y3AcC,--tJ- =+ (4 + 3) =+ (4 + +) ==+ (4 -+ -$) =+ -(u)-1/1 E w and (u)-$ E w + False and $ E w* and (a)4 E w and T(U)-Ic, E w and (u)4 E w (Propositional logic) (Assumption) (Definition (MONA) of w* ) (Maximal consistency of w) We conclude that F is consistent. 108 Z Huang et al./Artificial Intelligence 82 (1996) 75-127 We show now that any maximal extension F’ of F satisfies the lemma. So, let F’ be extension of F. We must show that: (3.1) F’ exists, consistent an arbitrary maximal (3.2) 4 E F’, (3.3) (a)+4 # w + cc/ @ F’. (3.1) Straightforward (3.2) From (3.3) We have: the definition of F’. from Lindenbaum’s Lemma. (a)+ @ w -(a)@ E w * (Maximal consistency of w) =+ +I)-+ E w (Propositional logic) * -+ E w* (Definition of w*) ==ST$bEF =+ + E F’ =+G,F’ (Definition (Definition (Maximal of F) of F’) consistency of F') . 0 The next lemma parallels the Action Lemma for the update operator. Lemma 30 (Update Lemma). VWE W,(~OXEW+ (3 EW,)(~EZ and (V$EZ)($OXE~))). Proof. Suppose that 4 o x E w. Let F={4}U{$:~(+ox) EW}, w” = {(c, : 7(ll+b 0 /y) E w}. The proof’s geometry parallels F are consistent. We then show (3) the condition of the lemma, satisfies the Action Lemma. We show first that (1) w” and (2) that we can always extend F to an F’ such that F’ i.e. F’ = z. ( 1) We claim that w” is consistent. ( 1.1) Assume that _L E w’, then we can show that I E w” + False. i E w” =+ -(do/y) =+ ~(To,y) + l(To,y) E w E w (Definition of w” ) (Propositional logic) A (40~) E w (Assumption) -(To,y)~(Tox) + + False EW (MONU) (Maximal consistency of w) (1.2) We show that 41,42 E w” + (41 A42) E w”. + ~(T$I o ,y) E w and ~(142 o x) E w =+ ~(741 oxV~42ox) E w =+ -((741 vl42) ox) E w =+ l(-(41 =+ 41 A42 E w” A42) OX) E W (Definition (Maximal of w”) consistency of w) (U4) (Propositional logic) (Definition of w”) 2. Huang et al./Artijicial Intelligence 82 (1996) 75-127 109 (1.3) For arbitrary 1+4, we must show that Cc, E wO,-+ E w0 3 False. cc, E w”,+ E w” =+ (9 A -*) E w” =%iEWO + False (1.2) (Propositional logic) (1.1) We conclude that w” is consistent. (2) We claim that F is consistent. This is implied by: (2.1) 4 + _L + False and (2.2) For any + E w”,q4 AI/J -+ I + False. (2.1) Assume that 4 t 1, then: 441 +~OXEW *IEW + False (q4oXEwand(MONA)) (U3) (Maximal consistency of w) (2.2) For arbitrary I++ E w”, assume that 4 A Cc, -+ We show that 4 A 1+4 + I + False. 4A$-+l =+ (4--v+) (Q,--@) + andcC,Ew’and@oxEw + (4--q?) and-+oxEwand4oxEw =+ (-@ox) + False E wand (+0x> E w (Propositional logic) (Assumption) (Definition of w”) (MONU) (Maximal consistency of w) We conclude F’ of F satisfies F. We must show that: (3.1) F’ exists, that F is consistent. We now show that any arbitrary maximal extension the lemma. So, let F’ be an arbitrary maximal consistent extensions of (3.2) q!~ E F’, (3.3) fi ox # w + @ # F’. (3.1) Straightforward (3.2) From (3.3) We show that as follows: the definition of F’. from Lindenbaum‘s Lemma. @ox$w =+ -(@ox) =+ -(--r/Q * -* E w0 *+EF =+ -@ E F’ **#F’ E w 0 x) E w (Maximal consistency of w) (Maximal consistency of w) (Definition of w’) (Definition (Definition (Maximal of F) of F’) consistency of F') . 0 Proposition 8 (Completeness of ALXS) . ALXS is complete for the class of ALX models. 110 Z Huang et al./Ar@cial Intelligence 82 (1996) 75-127 Proof. We construct a canonical model h4, = (IV,, cw, Ra, t-, V) and show that: ( 1) Truth Lemma: x E w E WC ti w E [xjMC. (2) M, is an ALX model. Define M, = (WC, cw, Ra, +, V) as follows: WC = {i : i is a maximal consistent set}, w E cw(j, {w’ : Ic, E w’}) iff V’p(p E j * poq E w), (w,x) E R” iff Vp(p E x + (a)p E w), cw(w, {w’ : C$J A + E w’}) * cw(w, {w’ : 1# A + E w’}) iff c$P$ E w, V(pi) = {W 1 pi E W}. We prove the Truth Lemma by induction on the complexity of x. (1.1) XEpi. Pi E W H w E V(Pi) * w E UPilbf, ( 1.2) x S -4. -4 E w @4@w * wGU& * w E [I-&, (1.3) x-Cpr\$. (Definition of V) (Truth condition) (Maximal consistency of w) (Induction hypothesis) (Truth condition) +r\tiew @ &@ Ew H w E [+] M, and w E [q],, (Induction hypothesis) ++ we u4wnMc (Truth condition) (Maximal consistency of w) (1.4) x EE (a)C$. (+P E w ~32~W,(~,~andV~~~((a)~Ew)) + 3z(q5 E z and R’wz) a ~Z(Z E [+],, + w E wnM, and Pwz) (ActionLemma) (Definition of R”) (Induction hypothesis) (Truth condition) w 6 uwnMc x=+ 3~ E W,( Rawz and z E [[+jM,) (Truth condition) H 3z E Wc(Rawz and q5 E z) (Induction hypothesis) =+ (+$ E w (Definition of R’) Z Huang et al./Art@cial Intelligence 82 (1996) 75-127 111 (1.5) ,yr(tJo*. + 3z(+ E z and (V,pE z)((po+) + 3z (4 E z and w E cw( z, {w’ : Cc, E w’}) > E w)) =+ 3z(z E [4],,,, and w E c~(z,U$]~,)) =+ w E iI+&, w E II+&, (Update lemma) (Definition (Induction of cw) hypothesis) (Truth condition) H ~Z(Z E u+n,, and w~c~(~,ullrn,,)) (Truth condition) ++ 32 (4 E z and w E cw( z, {w’ : t,b E w’}) ) *qbo$bEw (Definition (Induction of cw) hypothesis) (1.6) x = qhPt,b. ‘3 cw(w,{w':c$ A-@ E w'}) + :Ic, A 14 E w'}) : 4 E w’} n {w' : -* cw(w,{w’ H CW(~, {w’ E w’}) >- (Definition of +) (Meta-reasoning) {w’ cw(w, H cw(w, wn,, n u-a,) + : $ E w’} n {w’ : -Cp E w’}) ~wban,,ab45n~~~ (Induction hypothesis) H CW(W, [I+ A -t,b],,) ++ w E uevnM, + CW(W, [(c, A +jM,) (Truth condition) (Truth condition) This concludes So, we have to show that cw satisfies the transitivity to show that + satisfies the proof of the Truth Lemma. We now show that M, is an ALX model. and (CSC). Moreover, we have (CS2), conditions. (CSl), and normality (csl) w E 4j9 w,,) + WE wh,. ‘++~'p(pEj*potiEw) (Definition of cw) + 3p( p E j and p o $ E w) (j is not an empty set) *$C,Ew w w E ud,, (Ul) (Truth Lemma) (CS2) j E [t,blM, + cw(j, [+],,) = {j}. We must show that: (a) j E [@],, + j E ~w(.i,[$],,L and (b) j E UIcIIM, andj'E 4_LU&,,,> *j =j'. For (a), we have: j E wn,, @*cEj + b”p( p E j + (p A $> E j) (Truth Lemma) (Maximal consistency of j) =+ vp(pEj* =+ j E cw(j, wn,,) (Definition (PO@) Ej) (U2) of cw) . 112 2. Huung el al./Arfijicial Intelligence 82 (1996) 75-127 For (b), suppose that j E [+], Then by the maximal consistency we proceed by reductio arbitrary p. ad absurdum and j’ E cw(j, [(c/],), we first show that j C j’. of both j and j’, we have j = j’. To show that j C j’, that p E j and p $ j’ ==+- False for and show p E j and p # j’ H p E j and up E j’ +pA$~jandlp~j’ (Maximal consistency of j’) (j E [+,D and maximal consistency of j) + * ( (p A 9) o @) E j’ and up E j’ (j’ E cw( j, [@_DMC) and definition of cw) ((PA$) o$) Ej’ and ~((PAvQ) o$) Ej’ (U5) + False (Maximal consistency of j’) w.3 ~~hu+n,~) n uen, c c~WWWI,~. For my j E ~~wJl4n,~~ n we have to show that j E cw( w, [q5 A +I,,). That is, for any p, if p E w, then u@n ,,,,, p o (4 A I+/?> E j by the definition of cw. For any p: p~wandjtcwtw,[I~a,~)nu~n,~ + p E w and j E cw(w, [q3],,) and il/ E j (Truth Lemma) =+po4~jand@~j =$ (po4)ArC,Ej * PO($A$) t.i (Definition of cw) (Consistency of w) W6). Therefore, j E cw( w, [I+ A t&,,, ) by the definition of cw, so (CSC) holds. (NORM) (8 $ X). We must show that 8 > X + False. 0b-x + 3w3@~+4(+6P+ E w and = 0 and cw(w, 114 A -fin,,) cw(w, [Ifi ~-&,c) =X and cwbmA -fin,,) w4M~~4n~,)) (Definition + of +) =+ cw(w, UQ”f, f + cw(w, U$ A -#II& + cw( w, [II A -(q A -a,,) + cw(w,uWhb) A71nMc) (Meta-reasoning) (cw(w,[&) =0 by (CSf)) + .lP($ A -4) E w (Definition of cw) + False WI (TRAN) CW(W,X~~) + CW(W,Y nX) and cw(w,Y nz> F cw(w,Z nL) + CW(W,Xnz) k cw(w,znX). 2. Huang et al./Art@cial Intelligence 82 (1996) 75-127 113 cw(w,Xnr> + cw(w,Ytlx) and cw(w,YflZ) * cw(w,Z nr> + 3@,Glx(~$Pa+b E w and @PXE w and [@Ii M, = X and UlclII,, = Y and UxilMM, = Z) (Definition of +) + &!A+b3~(c,bP,y~ w and t+$P,y~ w and UC&,, =X and lIdI,, = Y and UxllMc = Z) (TR) =+ 3&l@ X(cW(W, 114 A 7X],,,,) % X(cW(W, I[X A 7$],,) and U41 M, = X and [I+ll MC = Y and UxIIM, = Z) =+ CW(W,X~Z) s- CW(W,Z~X) (Definition of + ) (Meta-reasoning) This concludes the proof that M, is an ALX model. 0 A.S. The finite model property of ALX Definition 31 (Subfomzula p iff QP satisfies the following conditions: set). A formula set @, is said to be the subformula set of l PEG,, Claim 32. For any formula p, the subformula set of p is closed under subformulas. In ALX, the truth condition of g3P1+? depends on the conjunction cw(w, [II, A -c$],). prin- Because of this, we shall need an set expansion the problem. We define the extended subformula ciple cw( w, [[+ A -$I,) extended accordingly. subformula t set to handle Definition 33 (Extended subformulas. The extended subformula Let @+ be the set of single the formulas subformula set). Let @ be a formula set which is closed under set @++ is defined as the Boolean closure of @. class of for each propositional representatives equivalence in @++. In particular, we have @ 2 @. It is easy to see that @+ is finite, since @ is finite. Moreover, for any $, @ E @‘+, there exist formulas Xt,chi~ E @‘such that I- (Xi t--f (~$r\-+)) and /- (X2 H (e/\-4)). In particular, we have _L E @+. Definition 34 (Equivalence (W, >-, cw, R’, V) and @ be a formula w, ~1’ E W, we define relation on possible worlds). set which Let M be an ALX model is closed under subformulas. For any w x w’ with respect to M and 0’ iff Yp E @+( M, w II-- p # M, w’ I/- p). I14 Z Huang et al./Artifcial Intelligence 82 (1996) 75-127 Definition 35 (Equivalence with respect to M and @+ and w be a possible world, we define class) _ Let z be an equivalence relation on possible worlds [w] S{W’E w: w z w’ 1. Definition 36 (Filtration). model M* = (W”, +*,cw*, R”*, V”) which satisfies A filtration of M = (W, Y-, cw, Ra, V) through @’ is any the following conditions: ( 1) W* is a subset of W which consists of exactly one world from each equivalence class. (2) R“*, cw*, +* satisfy the following suitability conditions: (~.~)VW,W’E W*((%E W)(Rawuandw’~:) +R’*ww’), (2.2) VW, w’ E w* (R”*ww’ =S (Y(a)4 E @+) (M, w’ II- 4 + M, w II- (a)+)), (2.3) VW, w’ E W* ((V$E@+)((~UE W)(WECW(U,[@]~) andw’xu) + w-w*(w’,[$]~*))) (2.4) VW, w’ E W* ((V$ E @,‘) (w E CW*(w’, [[$I],*> =+ (Q E @+) ((M,w’II-~AIC,~M,wlI-(~A~)orCI) (M,~‘II-~A~~~M,wII-(~A~~,)~~) and and (M,w’ Ii- (-#A@) * M,w II_ (-#A+> o(cI) and (M,w’ /I- (+A+) + M,w II- (+A+> o(cI>>>)* (2.5) Vw,E w*(vC#l,+ E CD+> (cw*(w, [I4 A ~!4ql~* > )-* cw*(w,[-4ArcI],,J H M,w II- (+p$)). (3) V*(pi) = V(pi) for any pi E @+. Theorem 37 (Filtration Theorem). Let M = (W, +, cw, R’, V) be any ALX model, @ be is closed under subformulas and M* = (W”, +*, cw*, R”*, V’) set which any formula be any filtration of M through @+, then for any x E Qpf and any w E W* (M, w II- x @ M*,w I)- x). Proof. We prove the theorem by induction on the complexity of @+. For any x E @: (1) /YEPi. M, w II- pi @ w E V(E) (Truth condition) H w E V*(pi) (Definition of V*) ++ M*, w (I- pi (Truth condition) 2 Hung et al./Ar#cial Intelligence 82 (1996) 75-127 11s (2) x G -4. We know that 4 E @+, M, w I/- 14 @ M, w I\$+ (Truth condition) @ M*,w H M*, w I/- -4 iI++ (Induction hypothesis) (Truth condition) (3) x = 4 A 9. We know that 4, I+G E Qp+, M>w II-+ Ail, ++ M, w /I- (b and M, w II- (I, (Truth condition) H M*, w I/- 4 and M*, w II- q+ (Induction hypothesis) @ M*,w II- 4AlcI (Truth condition) (4) x E (LZ)~. We know that 4 E @+, M, w II- (a>+ + 3~ E W( Rawu and M, u II-- 4) (Truth condition) + 3w’ E W* (R“wu and w’ z u and M, u II- qb) (Definition of W*) + 3w’ E W*( R’wu and w’ M u and M, w’ II- 4) (Definition of E) =S 3w’ E W* (R”*ww’ and M, w’ /(- 4) + Zlw’ E W*(RU*ww’ and M*, w’ II- qS> * M*, w II- (a)$ M*,w II- (a)+ (2.1) (Induction hypothesis) (Truth condition) H 3w’ E W* (R”* ww’ and w’ E [q!~],* ) (Truth condition) u 3w’ E W* ( R’*ww’ and w’ E [c$],) =+ M> w /I- (a)4 (Induction hypothesis) (2.2) (5) XEC$O@. Weknowthatd,+ E@+, * 3u(M, u I/- 4 and w E cw(u, [$,I],)) + 3w’ E W*(M,u I\- C/J and w’ M u and (Truth condition) w E cw(uv Ulcl],)) (Definition of W* ) =+ 3~’ E W*(M,w’ II- c,A and w E CW(U,[I&,)> (Definition of =) + ~W’E W*(M,w’II-4andw~cw*(w’,(I$],,)) (2.3) + 3~’ E W*(M*,w’ )I- #J and w E cw*(w’,[&,.)) (Induction hypothesis) =+ M*,w II- 40$ M*,w II- 401c, (Truth condition) w 3~’ E W*(M*,w’ II- C$ and w E cw*(w’,[t,bJjM,)) (Truth condition) @ 3~’ E W*(M,w’ I)- C$ and w E cw*(w’,[@],.)) (Induction hypothesis) 116 Z Huang et ai./Art@cial Intelligence 82 (1996) 75-127 Case 1: M, w’ II- +. M, w’ II- + and M,w’ II- 4 and w E cw*(w’, [fi],.)) + M,w’ //- (&A$) and WE cw*(w’,~t,b],~>> (Truth condition) =+ M,wII-(+A$)ocC, =+ M,wII-4orCI Case 2: M, w’ II- -I@. (2.4) (MONU) M, w’ I/- -$ and M, w’ II- 4 and w E cw*(w’, [+l),*)) =+ M,w’II-(+A(-#)) andwEcw*(w’,[~],,,*)) (Truth condition) =+ M,w II- (4A (+))o@ =+ M,w II-+o$ (6) x E #Pg. We know that #,$ f Gp+, (2.4) (MONIJ) H cw*(w, ~4 A +n,) +* cw*(w, u(cl A -4n,.) H M*,w II- w* (2.5) (Truth condition) For any x such that x E @+ but x # @, we know the following facts: (7) x E -4 and 4 E @. So 4 E @+. M, w /I- -4 @ M, w Ilf 4 @ M*,w II+4 H M* , w II- -4 (Truth condition) (Induction hypothesis) (Truth condition) (8) x-$A$ and4,@ E@. M,wIl+4AcC, H M, w II- 4 and M, w I/- @ w M”, w )I- (b and M*, w /I- $J (Truth condition) (Induction hypothesis) * M*,w II- tir\ti (Truth condition) Therefore, for any x E @+, we have M, w II- x H M”, w II- x. 0 Corollary 38 (Filtration Corollary). be any formula be any filtration of M through Qi+, then for any 4, cc/ E @+ and w E W*: Let M = (W +, cw, RU, V) be any ALX model, @ set which is closed under subformulas and M* = (W* , %* , cw*, Ra’, V”) (a) M, w /I- -4 @ M’, w II- -4, (b) M, w II- 4 A $ @ M*, w II- 4 A 9, (c) M, w /I- qf~ A -$ ti M”, w II- q!~ A -@. Proof. Straightforward. 0 Z Huang et al./Artifcial Intelligence 82 (1996) 75-127 I11 Theorem 39 (Invalidity Theorem). then x is invalid in every jiltration of M through @s. Suppose that a formula x is invalid in a model M, is invalid in a model M = (W +, cw, R’, V), there is some w E W Proof. Since x is a filtration of M such that M, w (/- 1~. Suppose through @s. By the definition of W*, there is some w* E W’ such that w z w* with respect to M and @s. Obviously, x E QX, + therefore M, w* II-- TX. By Corollary 38(a), M*, w* II- TX and so x is invalid that M* = (W”, cw*, F*, R”*, V’) in M*. 0 Theorem 10. ALX has the jinite model property Proof. For arbitrary x, suppose that [fALx x, , cw, R”, V) and a world w E W such that M, w iI+ x. Let QX be the subformula x. We know that 0, Now, we construct is finite. Moreover, @i also is finite, by the definition of @s. there exists a model M = (W, + set of a filtration M* = (W”, +-*, cw*, Ra*, V”) of M through @s as then follows: ( 1) For W*, we first construct the equivalence class [ ] on W as: [w] &%{w’: V’~E~~X+~W’EW(M,W~~-~~M,W’~)-~)}. From each class Now let W* be the set of all representing worlds. [w], we select exactly one world w’ E [w] to represent this class. From the definition of the equivalence any class and M, ~2 I]+ P, or M, wl I]$ p and M, w2 II- p. Because @$ is finite, finitely many formulas p by which we can distinguish class [ 1, we know that for any class [ wl ] and [ ~21, then there exists p E @i such that either M, wl II- p there are only two different classes. Therefore, [ ~21, if [ wl] f there are only finite. finitely many equivalence classes, namely, at most 2CXd’@:‘. So W” is (2) For V*, we define V*(pi) 2% V(p;) if pi E @i. (3) For R”*, we define that, for any w, w’ E W*, (w, w’) E R“* iff (V(a)+ E @px’) (M, w’ II- 4 * M,w II- (a)+). (4) For cw*, we define that, for any w, w’ E W* and any $ E @f, w E cw* (w’, [$I M* > iff ((~~E~~)((M,w’II-~A~~M,~II-M,~()-(~A~CI)~~) and (M, w’ II- 4 A + + M, w II- (4 A -9) 0 $) and (M,w’ II- (-$A@) * M,w II- (+A+) oti) and (M,w’ II- (-+A+) =+ M,w II- (+A-$) 09))). (5) For +*, we define that, for any w E W* and any $,fl E @i, cw* ( w, [i+ A -Iclj,* ) +* cw* ( w, [I-$ A (cl] M* ) iff M, w )I- $P@. 118 Z Huang et al./Art@cial Intelligence 82 (1996) 75-127 Now, we have to show that M* satisfies the construction @s. From consists of exactly one world from each equivalence Therefore, for W* is satisfied. of W*, we know the condition the conditions of a filtration of M through that W* is a subset of W. Moreover, W* to M and @z. class with respect From the above definition of V*, Ra*, cw*, %-*, the suitability conditions (2.2)) (2.4), (2.5) of Definition 36 and the condition for V* are obviously satisfied. To show that (2.1) is satisfied, we have to show that VW, w’ E W*(3u E W)(w’ x u and R’wu)) 3 Ra*ww’). Suppose that 3u E W(w’ M u and Rawu) and for any (a)~$ E @i: (u)4 E @px’ and M, w’ II- 4 and R”wu =s (u)#J E @i and M,u )I-- qb and R”wu (Definition of z) + (cz)~ E @s and M, w I/- (u)+ (Truth condition) Therefore, according To show that (2.3) to the definition of R”“, we have Ra*ww’, so (2.1) holds. is satisfied, we have to show that For any w, w’ E W* and any Ic, E @i, suppose that (3~ E W)(w’ M u and w E cw(u, [I+jM)) and for any #I E @i: (1) Assume that M, w’ II- (4 A t,!~), then: M,w’ II- (4/1~,4) =+ M,u II- (4 A$) and w’ = u and w E cw(u, [$I,> and w E CW(U, wn,) =+ M, w /I- (4 A G) 0 9) (Definition of =) (Truth condition) (2) Assume that M, w’ /I- (4 A -$), then: M, w’ II- (4 A +) and w’ E u and w E cw(u, [$],> + M,u /I- (4 A +) and w E cw(u, [$I,) =+ M,w (I- ($A+) oti) (Definition of C) (Truth condition) (3) Assume that M, w’ II- (-4 A 4)) then: M,w’II-(+A$) and~‘zuaandwEcw(u,[I$]~) =+ M,u I/- (14 A @) and w E cw(u, [fin,) =+ M,w II- (+r\+) occI> (Definition of z) (Truth condition) Z Huaq et al./Art@cial Intelligence 82 (1996) 75-127 119 (4) Assume that M, w’ II- (-4 A -$), then: M, w’ II- (-4 A -$) and w’ x u and w E cw(u, [I@],) 3 M,u /I- (-4 A +) and w E cw(u, [@I],) =+ M, w I/- (-4 A 19) 0 $) (Definition of z) (Truth condition) Therefore, (2.3) holds. according to the definition of cw* above, we have w E cw* (w’, ([(cl] Me ) . So We know now that M* is indeed a filtration of M through IPf . Moreover, we know that M” is a finite model. By the above theorem, we know that there exists a w E W’ such that M*, w IIf x. Therefore, condition 9) is satisfied. (1) of the finite model property (Definition In order to show that condition (2) of the finite model property is to say, we have to show and the normality. the transitivity is also satisfied, we that cw* have satisfies to show that M* is an ALX model. That (CS 1) -( CSC) and +* satisfies For any w, w’ E W* and any Cc, E @i, (CSI) w E cww,u~~,.) + w E itin,*. w E cw*(wI, wn,.) @ (3 Eql) ((M,w’ II- (+A$) * M,w II- (+A$) o+) and (M,w’ I/- (4A3) =+ M,w /I- (+A$) oQ) and (M,w’ II- (-$A$) * M,w II- (+A@) o+) and (M, w’ /I- (+ A -fi) + M, w II- (-4 A -$) o fi)) (Definition of cw*) Case 1: M,w’ II-- (4r\+). M, w’ \I- (4 A @) + M, w II- (c$ A$) o+ (Definition of cw*) =+ M, w II- Ic, (M is an ALX model and (Ul)) =+ M*,w II- 9 + w E wn,. (Definition (Filtration Theorem) of [I I] ,,,,. ) The other cases (4 A -yi, satisfied. lq5 A 1+4, -q5 A -3) are proved similarly. Therefore, (CSI) is (CS2) w E [[$I] M* + CW* ( W, I[+1 Ms ) = {w}. We must show that: (a) w E utinrcI* =+ w E cw*(w, u+n,.), (b) WE [I$],,,* and W’ E cw*(w, + w E w’, [I$],.> where w E w’ means to M* and @$, namely, that w and w’ represent the same equivalence class with respect ~‘p~cD,f(M*,wI/-p~M*,w)I-p). For (a), we will show that w E [I$] M* and w $Z cw* (w, [ql] M* ) + False. 120 Z. Huang et ai./Artifcial Intelligence 82 (1996) 75-127 w E iId,,,* and w # cw*tw, [v+],,,*> * w E [IdI, and w 6 cw*(w, [$I],,,*) * w E u+n, and (34 E @f) ((MYwli-(4ArcI) andM,wll+(4~$)0$) or (M, w I/- (4 A -+) and M?wIlf(4A+)oJI) or CM, w I/- (lq5 A 1+9) and M,w or (M,w llf(-4AcCI) occI> )I-- (l+r\-@) and M, w llf (-+ A -rcI) 0 G> * w E II+], and (34 E a,‘) and II- (4~9) ((M,w or (M,w II- (+I and M,w llf (4 A ~$1 oq) or (M,w I]- -v$Afi and (Filtration Theorem) (Definition of cw* ) M,w II$(~JA~> 09) M,w lif(+ArCI) o$) or (M,w II-- (-fi> and MT w I/$ (-4 A -9) 0 ‘4) (MONU) * w E [[$I,,, and (34 E @;> ((M,w or (M,wll- (-4 A(b) II- (@ArCI) and M,w ll$t$ArcI) o+) and M,~~II$(+A$) o$) (Meta-reasoning) =S 34 E @5x’ ((M,w II- ((4 A$) A$) and M,wII$($A9)0@) or (M,w I/- ((-+A$+) A+) and M,w lif(+A$) oIcI> =+ $5 E@Px+ CM, w II- ti, and Truth condition) o@) and ((~,wII- ((+A$) M?wIl$(4A@)o$) or (M,w /I- ((+A@) M,w II$(-$A$) o+) 0’4) and (M is an ALX model, and (U2)) + False For (b), suppose that w E @I],,,,* and w’ E cw*(w,[(//],,), for any 4 E @i, we have to show that M*,w I/- p H M*,w' II- p. Z Huang et ul. /Art@cial Intelligence 82 (1996) 75-127 121 (=+) We show that M*, w II- p and M*, w’ II$ p + False. M*, w /I- p and M*, w’ I\$ p =+ M, w II- p and M*, w’ Ilf p (Filtration Theorem) + M, w /I- p and M*, w’ /(- up (Truth condition) + M, w I(- p and M, w’ II- up (Filtration Corollary (a) ) =+ M,w /I- pand M,w’II- ~((pAt,b) ot+b) (M is anALXmode1 and (U5)) =+ M,w /I- (PA+) and M,w’ II- -((PA@) oCCI) + M,w’ I\- (PA@) o1,4 and M,w’II--((~Afi)oglr) =+ False (w E U&4*) (Definition of cw* ) (x==) We show that M*, w’ I(- p and M*, w IIj p + False. M*,w’ 11-p and M*,w llfp =+ M, w’ I/- p and M*, w IIf p + M, w’ (I- p and M*, w /I- up + M, w’ /I- p and M, w II- up (Filtration Theorem) (Truth condition) (Filtration Corollary (a) ) + M, w’ II- p and M”, w II- qb and M, w II- up (w E b&J*) + M, w’ /I- p and M, w II- t,G and M, w II- up (Filtration Theorem) 3 M, w’ II- p and M, w (I- (-p A 1+9) (Truth condition) + M, w’ I/- p and M, w’ II- (up A qb) o Ic, (Definition of cw* ) + M,w’ II- 7(-p) and M,w’ II- (~pAf+b) o1,4 (Meta-reasoning) * M,w’//--(CC-pI A+) 01)) and (M is an ALX model) M,w’ (I- (~PA$) ofi and (U5)) =+ Fulse ((M,w II- (PA\) * M,j II- (pAti) 04) and (M, w II- (P A -4) 3 M, j /I- (P A -4) 0 4) and (M,w II- (-PA+) * M,j I(- (lpA$) 04) and (M,w II- (‘Pk+) * M,j /I- (-PAT+) II- CCI) M*,j =+ M,_i II- (CI 04) and (Definition of cw* ) (Filtration Lemma) 12 12 Z. Huang et al./Artificial Intelligence 82 (1996) 75-127 For any p E @s: Case 1: M,w II- (PA (4 A@>). M,w II- (PA (+A$)) =+ M,w II- (PA41 73 M,j II- (PA41 04 + tv,j II- (PA(+A+)) o(+~$) (Meta-reasoning) (j E Cw*(Wu4nD,*), (Mvj II-+ and W8’)) Case2: M,wII-pA+~A@) Case 2.1: ~M,wIl-(pAl~)V(PA~~). M, w I/- (P A -4) * M,j II- (p A -4) 0 4 * M,j II- (PA~~)o(#A~CI) * M,j II- (PA~$JVPA~)O(#A@/) =s M,j II- (PA~(~A$))o(~A$) tj E cw*tw, Ud4,.>> (M, j II- $ and W)) (MONU) (Meta-reasoning) Case 2.2: M, w II- p A +. Case 2.2.1: M> w II- 4 * M*, w II- 4 (Filtration Lemma) =+ {w} = cw*(w, [i&f*, ((32) (j E cw*(w,[+I,.)) (M, w II- 3) II- ti> (M,j + w=j * M, j II- -4 + False Case 2.2.2: M, w II- -4 * M,w II- (PA+) 0 do * M,j II- (P A -4) * M,j I/- (pA-$)o(+ArCI) + M,j II- (pAT4VpA-l) * M,j I/- (PA-(~A$)) o(4AccI) o(+A$I> (Meta-reasoning) (j E cw*(w,[+],-)) tU6) (MONV (Meta-reasoning) Case 3: M,w II- ‘PA (4Ar\ccI) * M,w II- ‘PAN * M,j I(- (-PA 4) 04 (Meta-reasoning) tj E cw*(w,[41iM-)) * M,j I\- (-PA(~A$)) 04 CM, j II- Cc, and (W’) 1 * M,jII-(?pA(~Aclr))o(~A~) (U4) Z Huang et al./Art@cial Intelligence 82 (1996) 75-127 123 Case4: M,wI)- Case 4.1: (~pA~(qhAq)) ~~,wII-(lpA~~)V(pA~~). M, w II- t-p A -4) =+ M,j II- (-PA+) I/- (-PA+) =+ M,j =+ M,j II- (-pA+VpA+) II- (-PAT(~A$)) + M,j 04 0(4Acl/) o(4AccI) o(+A@) tj E cw*tw$$n,*)> CM, j II- $ and UJ6) > (MONV (Meta-reasoning) Case 4.2: M, w II- lp A +. Case 4.2.1: M, w II- 4 =+ M*,w II- Cp (Filtration Lemma) =+ {w} = cw*tw, pII,*) (CS2) =+ w=j * M, j II- % + False Case 4.2.2: (j E cw*(w, [@I,.)) (M, w II- 3) (M,j /I- 9) M, w II- + =+ M,w II- (-PA+,) * M,j II- (-PAT+) 04 (Meta-reasoning) (j E cw*(w, id],.)) =+ M,j II- (TPA+) 0 (4A+) (U6) * M,j /I- (-PA~~VPA-$) o(@AccI) (MONU) * M,j II- (-PAT(~A~CI)) o(~A$) (Meta-reasoning) Therefore, CW* ( W, [I4 A @l] M* ) . So (CSC) by the results of Cases is satisfied. l-4 and the definition of cw*, we have that j E (NORM) (0 #* X). We must show that 0 t* X + False. CM, w II- qSP$ and cw*(w,[4A7$q,,J cw*(w,~+A+&,,,) =0and =Xand cw*(w, [[4 A 3],.) +* CW*(W,[J/ A7&,&) + cw*(w, uq,.) +* cw*(w, [[fi A -#$,_J (Definition of t- ) (cw*(w, [I],.) = 8 by (Gil)) 124 2 Huang et al/Artificial Intelligence 82 (1996) 75-127 cw* (w, [IJIM* ) ** cw*(w, [I) A-d],.) and L E @s and 3P E @x’( U&* = [[Cc, A +jM* cw* ( w, [I A yPjM* ) +* cw* ( w, up A llnM* ) M, w II- iPp False ) (Definition of @s) (Meta-reasoning) (Definition of cw*) (N) The proof for the second part of (NORM), (X #* 0)) is similar. (TRAN) cw*(w,XnY) cw*(w,xnZ) +* c~*(w,znX). +* cw*(w,Ynx) andcw*(w,YnZ) >-* cw*(w,Znr) + cw*(w,XnY) +* cw*(w,Ynx) and cw*(w,rn'i) k* ~w*(w,znY) + 3@,b,3p( X = [I+],, and Y = [$],, and Z = udw* and M, w I)- (dP$) and M, w II- ($Pp) and (~$,ti,p E @i,+)) (Definition of cw*) * M,w I/- @‘p and (6~ E @;) + cw* ( w, 14 A lpnw* ) t* cw* ( W, up A +n,. + cw*(w,xnZ) +* cw*(w,znX) ) (TR) (Definition of >* ) (Definitions of X, Y, Z) As a consequence, M* is an ALX model. Because of the soundness of ALX logic, we know that for any p, kALX p =+ Vw( M*, w II- p) . This means that ALX also satisfies 9). So ALX has the finite model condition property. (2) of the finite model property 0 (Definition Acknowledgement The authors gratefully Peter van Emde Boas, Scip Garling, This Foundation (# PGS 50-334). research was supported by a PIONIER grant acknowledge suggestions very helpful from Maarten Marx, Jaap Kamps, Jean-Jules Meyer and Yao-Hua Tan. the Dutch National Science from References I I I H. Blumer, Symbolic Interacfionism: Perspective and Methods (Englewood Cliffs, Prentice-Hall, NJ, 1969). 12 I A.L. Brown, S. Mantha and T. Wakayama, Preferences in: J.-J.C. Meyer and R.J. Wieringa, eds., Proceedings DEON’BZ, Amsterdam as normative knowledge: towards declarative (1991) 142- obligations, 163. Z Huang et al./Artijicial Intelligence 82 (1996) 75-127 125 13 1 K. Carley, Efficiency Weissinger-Baylon, in a garbage can: implications for crisis management, in: J.G. March and R. eds., Ambiguity and Command (Pitman, Marshfield, MA, 1986) 165-194. ( 41 R. Chisholm and E. Sosa, On the logic of “intrinsically [S 1 P.R. Cohen and H.J. Levesque, Persistence, and A.L. Lansky, eds., Proceedings 1986 Workshop on Reasoning about Actions and Plans (Morgan Kaufmann, San Mateo, CA, 1987) 297-340. intention and commitment, in: M.P. Georgeff better”, Amer. Philos. Q. 3 (1966) 244-249. 16 I P.R. Cohen and H.J. Levesque, 17 1 S. Danielsson, Preference and Obligation (Filosofischa 18 1 T. Dean and M.P. Wellman, On the value of goals, lntention is choice with commitment, Arti$ Intell. 42 ( 1990) 213-261, f(ireningen, Uppsala, 1968). in: Proceedings Rochester Planning Workshop, Rochester, NY ( 1989). 19 1 P.F. Drucker, The theory of business, Harvard Business Rev. (Sept.-Oct. [ 101 S. French, Decision Theory, an Introducrion to The Mathematics of Rationality (Ellis Horwood, 1994) 95-107. Chichester, England, 1988). 1 I 1 I L.T.F. Gamut, Logic, Language, and Meaning (The University of Chicago Press, Chicago, I I2 1 A. Giddens, Central Problems in Social Theory: Action, Structures, and Contradiction in Social Analysis IL, 1990). (University of California Press, Berkeley, CA, 1979). [ 13 ] M.L. Ginsberg, Counterfactuals, Art$ Intell. 30 ( 1986) 35-79. I 14 1 M.L. Ginsberg and D.E. Smith, Reasoning about action I: a possible worlds approach, Artz$ Intell. 35 ( 1988) 165-195; also in: M. Ginsberg, ed., Readings in Nonmonotonic Reasoning (Morgan Kaufmann, Los Altos, CA, 1987) 433-463. [ 15 I G. Grahne, Updates and counterfactuals, eds., Proceedings Second Internarional Conference on Principles of Knowledge Representation and Reasoning (Morgan Kaufmann, San Mateo, CA, 1991) 269-276. in: J. Allen, R. Fikes and E. Sandewall, 1 16 1 J. Habermas, The Theory of Communicative Action (Beacon Press, Boston, MA, 1984). 1 17 1 S. HalldCn, On the Logic of Better, Library of Theoria 2 (Lund, 1957). [ I8 I S. HalldCn, Preference logic and theory choice, Synthese 16 ( 1966) 307-320. [ 191 S. HalldCn, The Foundations of Decision Logic (CWK Gleerup, Lund, 1980). 1201 J.Y. Halpem and Y. Moses, A guide to completeness and complexity for modal logics of knowledge and belief, Art@ Intell. 54 (1992) 319-379. I21 I B. Hansson, Fundamental [ 22 I S.O. Hansson, A new semantical approach 123 1 SO. Hansson, Similarity I24 I D. Harel, Dynamic logic, axioms to the logic of preference, Erkenntnis 31 ( 1989) l-42. semantics and minimal changes of belief, Erkenntnis 37 ( 1992) 401-429. in: D. Gabbay and F. Guenthner, eds., Handbook of Philosophical Logic, Vol. for preference relations, Synthese 18 ( 1968) 423-442. II (Reidel, Dordrecht, Netherlands, 1984) 497-604. 125 I K. Hirofumi and A. Mendelzon, On the difference between updating a knowledge base and revising it, in: J. Allen, R. Fikes and E. Sandewall, eds., Proceedings Second International Conference on Principles of Knowledge Representation and Reasoning (Morgan Kaufmann, San Mateo, CA, 1991) 387-394. rationality, series 1994-10, University of for agents with bounded ILLC Dissertation I26 I Z. Huang, Logics Amsterdam ( 1994). I27 I Z. Huang and M. Masuch, Reasoning about action: a comparative survey, CCSOM Research Report 91-37 (1991). I28 I Z. Huang, M. Masuch and L. Wlos, A preference and D. King, eds., Artificial Intelligence in Organization Design, Modeling and Control, lnformation Systems Series (IEEE Computer Society Press, forthcoming). logic for rational actions, in: R. Blanning I29 I Z. Huang, M. Masuch and L. Wlos, ALX, the x’th action logic for agents with bounded rationality, CCSOM Research Report 92-70a ( 1992). I 30 I Z. Huang, M. Masuch and L. Pblos, ALXZ: the quantifier ALX logic, CCSOM Research Report 93-99 (1993). 13 1 I G.E. Hughes and M.J. Cresswell, A Companion to Modal Logic (Methuen, New York, 1984). I32 I E Jackson, ed., Conditionals (Oxford University Press, 1991). I 33 1 P. Jackson, On the semantics of counterfactuals, [ 34 1 R.C. Jeffrey, The Logic of Decision (New York, 2nd ed., 1983). 135 I S. Kambhampati in: Proceedings IJCAI-89, Detroit, MI ( 1989). and S. Kedar, A unified framework for explanation-based generalization of partially ordered and partially instantiated plans, Art$ Intell. 67 (1994) 29-70. 126 1361 1371 1381 1391 1401 141 I 1421 1431 1441 1451 1461 147 I48 149 l so 151 I 1521 1531 I.541 155 I I561 I.57 IS8 IS9 I60 I61 I 1621 1631 1641 1651 1661 I671 2. Huang et ul./Arn$cial Intelligence 82 (1996) 75-127 action action: concepts organization in rewriting Introduction, 1992) 1 - 19. of foolishness, 1976) 69-8 1. of Thompson’s in organizations, of organizational in: J.G. March and and P Hayes, Some philosophical logic, SRI-CSL Tech. Report 94-07 and J. Meseguer, Action and change logic, CCSOM Working Paper 94-120. in action, CCSOM Research Report 91-32 from the standpoint of Al, in: B. Meltzer and knowledge base revision and minimal change, Artif: in: J.G. March and J.F? Olsen, eds., Ambiguity and Choice in: M. Masuch and M. Warglien, eds., Artificial Intelligence in Organization eds., Ambiguity and Command (Pitman, Marshfield, MA, 1986) 1 l-53. problems Intelligence 4 (Edinburgh University Press, 1969). H. Katsuno and A.O. Mendelzon, Propositional Infell. 52 ( 1991) 263-294. A. Kron and V. MilovanoviC, Preference and choice, Theory Decision 6 (1975) 185-196. D.K. Lewis, Counterfactuals (Blackwell, Oxford, 1973). N. Luhmann, The Di$erentiafion of Society (Columbia University Press, New York, 1982). J. McCarthy D. Michie, eds., Machine J.G. March, The technology in Organizations (Bergen, Norway, Universitetsforlaget, J.G. March and J.l? Olsen, Garbage can models of decision making R. Weissinger-Baylon. N. Marti-Oliet (1994). M. Masuch, Formalization (1991). M. Masuch, and Management, Models of Distributed Acriviry ( Elsevier-North Holland, Amsterdam, M. Masuch and Z. Huang, A logical deconstruction Organizations in Action into a multi-agent J.-J.C. Meyer, Using programming van Emde Boas, eds., Semantics and Conrexrual Expression (Foris Publications, Dordrecht, Netherlands, 1989) 117-145. N.J. Moutafakis, The Logic of Preference J.D. Mullen, Does the logic of preference D. Nute, Conditional II (1986) 387-439. J.F. Padgett, Managing garbage can hierarchies, Administrative Sci. Q. 25 ( 1980) 583-604. T. Parsons, The Strucrure of Social Acfion (Free Press, Glencoe, T. Parsons, The Social System (Routledge M.E. Pollack, The uses of plans, Artif: Intell. 57 (1992) 43-68. J.L. Pollock, Subjunctive Reasoning (Reidel, Dordrecht, Netherlands, J.L. Pollock, A refined L. Wlos, Updated situation L. P6los and M. Masuch, Applied Logic: How, What and Why (Kluwer Academic Publishers, Dordrecht, Netherlands, 177-218. A.S. Rao and M.P. Georgeff, Modeling in: J. Allen, R. Fikes and E. Sandewall, eds., Proceedings Second international Conference on Principles of Knowledge Representation and Reasoning (Morgan Kaufmann, San Mateo, CA, 1991) 473-484. N. Rescher, Semantic for the logic of preference, of Pittsburgh Press, Philadelphia, PA, 1967). and Action (University A. Schutz, The Phenomenology of ihe Social World (Northwestern University Press, Evanston, D. Scott, Towards a mathematical (Reidel, Dordrecht, Netherlands, rest on a mistake, Metaphilosophy 10 (1979) 247-255. J. Symbolic Logic 58 (1993) 1143-l 144. states in situation IL, 1967). in: Proceedings Fourth Annual Princeton in: L. Wlos and M. Masuch, eds., to appear) IL, 1937). and Kegan Paul, London, 195 1) logic, in: D. Gabby and E Guenthner, eds., Handbook of Philosophical Logic, Vol. in: N. Rescher, ed., The Logic of Decision J. Philos. Logic 10 (1981) 239-266. in: R. Bartsch, J. van Benthem and P agents within a BDI-architecture, semantics, Information theory of counterfactuals, formalizing Thompson’s theory of computation, in deontic reasoning, foundations semantics, rational 1987). 1976). semantics, for denotational Berlin, 1982) 577-613. in: M. Nielsen and E.T. Schmidt, eds., Lecture Notes in Conference on Information Science and Systems (1970) 169-176. D. Scott, Domains Computer Science 140 (Springer-Verlag, K. Segerberg, The logic of deliberation H.A. Simon, A behavioral model of rational choice, Q. J. Economics 69 (1955) 99-l 18. H.A. Simon, On the concept of organizational H.A. Simon, Bounded 1987). R. Stalnaker, A theory of conditionals, J.D. Thompson, Organizations in Action, Social Science Bases of Administrative Theory (McGraw-Hill, New York, 1967). goal, Administrative Sci. Q. 9 (1964) 1-22. in: J. Eatwell et al., eds., The New Palgrave (Macmillan, London, in: Studies in Logical Theory, Amer. Philos. Q. 2 ( 1968) 98-122. action, J. Philos. Logic 11 (1982) 233-254. rationality, 1681 1691 Z. Huang et al./Artificial Intelligence 82 (1996) 75-127 121 ( 70 I MI? Wellman and J. Doyle, Preferential semantics for goals, in: Proceedings AAAI-91, Anaheim, CA (AAAI Press, 1991) 698-703. 171 ] M. Winslett, Reasoning Paul, MN ( 1988) 89-93. about action using a possible models approach, in: Proceedings AAAI-88, St. I72 ] G.H. von Wright, The Logic of Preference (Edinburgh, I73 I G.H. von Wright, The logic of preference 1963). reconsidered, Theory Decision 3 ( 1972) 140-169. 