Artificial Intelligence 154 (2004) 1–42www.elsevier.com/locate/artintOptimizing the mutual intelligibility oflinguistic agents in a shared worldNatalia Komarova a,b, Partha Niyogi c,∗a Institute for Advanced Study, Einstein Drive, Princeton, NJ 08540, USAb Department of Applied Mathematics, University of Leeds, Leeds LS2 9JT, UKc Department of Computer Science, University of Chicago, Chicago, IL 60637, USAReceived 4 October 2001; received in revised form 11 May 2003Abstract(cid:2)We consider the problem of linguistic agents that communicate with each other about a sharedworld. We develop a formal notion of a language as a set of probabilistic associations between form(lexical or syntactic) and meaning (semantic) that has general applicability. Using this notion, wedefine a natural measure of the mutual intelligibility, F (L, L(cid:2)), between two agents, one using thelanguage L and the other using L. We then proceed to investigate three important questions withinthis framework: (1) Given a language L, what language L(cid:2)maximizes mutual intelligibility with L?We find surprisingly that L(cid:2)need not be the same as L and we present algorithms for approximatingL(cid:2)arbitrarily well. (2) How can one learn to optimally communicate with a user of language Lwhen L is unknown at the outset and the learner is allowed a finite number of linguistic interactionswith the user of L? We describe possible algorithms and calculate explicit bounds on the numberof interactions needed. (3) Consider a population of linguistic agents that learn from each other andevolve over time. Will the community converge to a shared language and what is the nature of sucha language? We characterize the evolutionarily stable states of a population of linguistic agents in agame-theoretic setting. Our analysis has significance for a number of areas in natural and artificialcommunication where one studies the design, learning, and evolution of linguistic communicationsystems. 2003 Published by Elsevier B.V.Keywords: Linguistic agents; Optimal communication; Language learning; Language evolution; Game theory;Multi-agent systems* Corresponding author.E-mail address: niyogi@cs.uchicago.edu (P. Niyogi).0004-3702/$ – see front matter  2003 Published by Elsevier B.V.doi:10.1016/j.artint.2003.08.0052N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–421. IntroductionConsider two linguistic agents in a shared world. The agents desire to communicatedifferent messages (meanings) to each other. Such a situation arises in a number of differentcontexts in natural and artificial communication systems and it is important in such casesto be able to quantify the rate of success in information transfer, in other words, themutual intelligibility of the agents. Each agent possesses a communicative device or alanguage that allows it to relate code (signal) and message, form and meaning, syntax andsemantics, depending upon the context in which the communication arises. If they sharethe same language and this language is expressive enough and unambiguous, then mutualintelligibility will be very high. If on the other hand, they do not share the same language,or the languages are inexpressive or ambiguous, the mutual intelligibility will be muchlower. This is often the case in the real world and in this paper, we present an analysis ofthis situation. We view languages as probabilistic associations between form and meaningand develop a natural measure of intelligibility, F (L1, L2), between two languages, L1 andL2, which is a generalization of a similar function introduced in [10]. We ask the followingquestion: if there is a biological/cultural/technological advantage for an agent to increaseits intelligibility with the rest of the population, what are the ways to do this?The task of increasing intelligibility reduces ultimately to three related sub-problems:• Given a language L, what language L(cid:2) maximizes the mutual intelligibility F (L, L(cid:2))for two way communication about the shared world?• What are some acquisition mechanisms/learning algorithms that can serve the task ofimproving intelligibility?• What are the consequences of individual language acquisition behavior on thepopulation dynamics and the communicative efficiency of an interacting populationof linguistic agents?In this paper, we create a mathematical framework to address these questions analytically.We find, surprisingly, that the optimal language L(cid:2) need not be the same as L, andwe present an algorithm for approximating L(cid:2) arbitrarily well (Section 3). The optimallanguage, L(cid:2), can be either learned or inherited by each individual from its “parents”. In theformer case, we find some bounds on the performance of appropriate learning algorithms(Section 4). In the latter case, we study the resulting population dynamics in the context ofan evolutionary language game (Section 5).1.1. Communicability in animal, human and machine communicationThe simplest situation where communicability is readily defined corresponds to the casewhere the “language” may be viewed as an association matrix, A. Such a matrix simplylinks referents to signals. If there are M referents and N signals, then A is an N × Mmatrix. The entries, aij , define the relative strength of the association between signal iand meaning j . The matrix A thus characterizes the behavior of the linguistic agent in(i) production mode where it may produce any of the signals corresponding to a particularmeaning in proportion to the strength of the association, and in (ii) comprehension modeN. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–423where it may interpret a particular signal as any of the meanings in proportion to theassociation strengths.The specific settings in which such a scheme is a useful description include animalcommunication, human languages and artificial languages. For instance, it often makessense to talk about a lexical matrix as a formal description of human mental vocabular-ies. It is introduced to describe the arbitrary relations between discrete words and discreteconcepts of human languages ([10,14,19,26]; also see [36] for a more Bayesian perspec-tive). Each column of the lexical matrix corresponds to a particular word meaning (orconcept), each row corresponds to a particular word form (or word image). In the Saus-surean terminology of arbitrary sign, the lexical matrix provides the link between signifiéand signifiant [28].An equivalent of a lexical matrix is also at the basis of any animal communicationsystem, where it defines the relation between animal signals and their specific meanings [4,8,15,31,32]. A classic example of this is alarm calls in primates. There are a finite numberof referents that are coded using acoustic signals and decoded appropriately by recipients.Infinite association matrices can be used as a description of human languages [13,25].Human grammars mediate a complex mapping between form and meaning. There, thespace of possible signals is the set of all strings (sentences) over a finite syntactic alphabetand the set of possible meanings is the set of all strings over some semantic alphabet. Mostcrucially, the sets of possible sentences and meanings are infinite. This accounts for theinfinite expressibility of human grammars.In artificial intelligence, the problem arises in many different settings. A number ofstudies have emerged where linguistic agents interact with each other in simulated worldsand one studies whether coherent or coordinated communication ultimately emerges (see,for example, [2,12,21–23,33–35]). Much of this kind of research employs the simulationmethodology of Artificial Life. In this paper, we create a mathematical framework forthese kinds of problems and derive a number of analytic results. We also study languagecoordination in a game-theoretic setting and our results have consequences for the Nashequilibria for such problems (for related research on multi-agent systems and game-theoretic foundations, see [1,37] among others).In the design of natural language understanding systems, the goal is to develop acomputer system that is able to communicate with a human. The statistical approachto this problem assumes an underlying probabilistic model for the human source. Thisprobabilistic model is then recovered or learned from data either by randomly drawnsamples as in the case of corpus linguistics or statistical language modeling (see [3] and[16] for overviews of this point of view) or via some interactive exchanges and semanticreinforcement [7,11]. The primary implication of this paper is that optimal communicationwith a language user might require one to learn a language that is different from the targetsource.1.2. Main results in the context of previous workHere we outline the three main sets of results presented, respectively, in Sections 3, 4and 5.4N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–421.2.1. How to maximize the mutual intelligibility?Let us consider a population of agents and assume that each of them has a language. Anevolutionary process can then be described where individuals reproduce and the offspringdo not have an innate language, but acquire a language on the basis of interaction with thepopulation. This process was first explicitly modeled in [10] and later in [23] and [21]. Inthe approach of the latter two works, at each (discrete) moment of time, a randomly chosenindividual is replaced by a new one, which then learns the language of the population; in[10], the generations do not overlap. It is clear that the choice of a learning procedure usedby the offspring will influence the evolutionary dynamics that ensues and, in particular,whether or not the population will converge to (and maintain) a reasonably coherentlanguage.Several basic learning mechanisms have been considered. The “imitator” simply learnsthe averaged language of the population, both in the production and in the comprehensionmode. The “calculator” of Hurford (called “obverter” in [23] and “Bayesian learner” in[21]) does not copy the language of the population but rather constructs the “best response”to it: it adopts the production behavior which is best understood by the population, and thecomprehension strategy which is the best decoder for the population, thus maximizing itscommunicative efficiency with the population. The “Saussurean learner” of [10] imitatesthe production mode of the population and then adopts the comprehension behavior thatmaximizes its chances of understanding itself.It turns out that imitators do not do very well and a coordinated communication systemseems to be unstable in a population of such learners. Saussurean learners show a betterperformance, but the obverters are the most efficient (in the setting of [23] and [21]).Starting from a randomly chosen initial condition, a population of obverters quicklydevelops a highly coordinated communicative system, and reaches a state where signalsand meanings are related in the one-to-one fashion (plus perhaps some isolated synonymsor homonyms).A peculiar feature of both imitators and obverters is thattheir production andcomprehension modes are completely de-correlated.1 Before the perfect coordinationof language is reached, some obverters might find themselves speaking a very strangelanguage. Imagine a case where the language has two sentences, s1 and s2, and twomeanings, m1 and m2. A pathological linguistic agent might use s1 to communicate themeaning m1 and s2 to communicate m2 in production mode but interpret s1 to meanm2 and s2 to mean m1 in comprehension mode. Such a linguistic agent is therefore self-contradictory in its associations between form and meaning.In this paper, we avoid such internal contradictions by requiring that a linguisticagent’s production and comprehension modes be linked via a common association matrix.In doing so, we have two motivating considerations in mind. First, from a cognitivestandpoint, it seems natural to give symmetric consideration to form and meaning andtreat language as a relation between form and meaning rather than two separate functionalmappings for production and comprehension. Second, from a computational standpoint, a1 In other contexts, the obverter may be defined differently. A more general definition is that an obverterperforms to maximize comprehension on the assumption that the hearer’s reception behavior is the same as itsown.N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–425common association matrix provides a compact representation for a language from whichproduction and comprehension modes may easily be derived. The Saussurean learnersatisfies such a criterion; obverters that have reached a co-ordinated language do not violatethis constraint (see also [20]). The communicating neural networks also provide a linkbetween the production and comprehension modes, see, e.g., [20,29,30].In this paper, we execute a comprehensive analysis of this situation. The first questionwe address is whether the obverter algorithm can still be carried out if the self-consistencyconstraint is imposed on each of the learners.2 This requires us to understand what thebest response to an arbitrary language is, when it exists, and how to approximate it. Wedemonstrate the following:• If the language L is not self-consistent, then it is in general not possible to use theobverter procedure for finding the best response. In other words, the comprehensionbehavior and the production behavior designed to (separately) maximize the commu-nicative efficiency, do not obey the self-consistency requirement.• If the language L is fully co-ordinated (defines a one-to-one correspondence betweensignals and meanings), then the best response exists and is equal to the language Litself.• Next, suppose that the language L is self-consistent, but not fully co-ordinated. Theneven though it is not in general possible to find the best response, we can approximateit within any given accuracy, ε.• Finally, suppose that the language L is fully co-ordinated, but the communication isnoisy. Then, under some mild restrictions on the magnitude of the noise, we can stillfind the best response, and, under slightly stronger conditions, it is the language Litself.Incidentally, the first of the above statements suggests that the obverter mechanism cannotbe used for learning from a population of individuals. Even though each agent might have aself-consistent language, the average language of the population may not be self-consistent.The obverter procedure can be used by each newly introduced agent to learn from onerandomly chosen individual, or from its “parent” (i.e., an individual chosen proportionallyto its linguistic performance).1.2.2. Learning the optimal languageA second set of results relate to the problem of learning a self consistent languagefor the purpose of optimal communication with the chosen teacher or “parent”. Since theteacher’s language is not known at the outset, the learner must obtain relevant estimates ofit over a finite number of interactions with the teacher. This situation arises in a numberof artificial intelligence settings where a machine learning approach is taken to acquirea language for communicative purposes. For example, statistical language modeling forspoken language understanding between human and machine, or language learning forrobotic communication systems between two robots (machines) are natural applications. In2 The precise definition of self-consistency is that there exists a probability measure over the space of signalsand meanings, which is common for both the production and the comprehension modes.6N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42most such cases, particularly in statistical language modeling, it has been tacitly assumedthat collecting a corpus by sampling the target language and then reconstructing it on thebasis of this corpus is a sufficiently good strategy for designing a natural language basedhuman–computer interaction system. In the light of the results presented in this paper, wewill see that this assumption is mistaken. Specifically,• We consider two different frameworks for learning: (i) learning with full information,where the learner has access to both the sentence and its meaning in all interactions,and (ii) learning with partial information, where the learner has direct access only tothe sentence. The meaning is not directly accessible but the learner knows whethercommunication was ultimately successful. We present algorithms to learn how tocommunicate optimally in both settings.• We present explicit bounds on the number of examples (interactions) needed for anagent to be able to learn a self consistent language that yields communicability that isarbitrarily close to optimal with high probability. In a partial information setting, thenumber of examples is seen to be proportional to N 2M 2/γ 2, where N is the numberdistinct signals and M is the number of distinct meanings. In the full informationsetting where meanings are directly observable, the number of examples reducesto a quantity proportional to N 2/γ 2. In both cases, γ is a margin parameter thatcharacterizes the learning difficulty of the teacher’s language.It is interesting to compare our approach with the approach taken in the studies ofpopulations of neural networks. Oliphant [21] and Smith [29] used numerical simulationsto investigate the dynamics of an iterative learning model. While they did not address thequestion of convergence to a maximum communicability in a teacher-learner pair, theylooked at the convergence of the population of networks to an optimal communicationsystem. By varying the update rules of individual networks, they were able to showthat a learning bias toward a one-to-one mapping between meanings and signals led toan emergence of a coordinated communication system. In their setting, each individualdid not necessarily optimize its communication ability with the current population, butrather, each individual had a learning strategy which eventually facilitated a high long-term communicability outcome.1.2.3. Communicability and the evolutionary language gameFinally, we examine the implications of the communicability function in the languagegame framework. There has been considerable recent activity with work on computationalmodels for the evolution of natural languages and animal communication [8,12,23,25]. Inmodels that are based on selective fitness, the communicability function determines thepayoff of different languages. Individuals that communicate well receive a high payoffwhich translates into biological fitness, or reproductive success: individuals with higherfitness produce more children who learn their language. Alternatively, one can assumethat individuals with a high payoff have a high reputation (or standing in the group) andare more influential as language teachers. The assumption is that language performancemeasured by the function F contributes to the rate with which each language is spread.N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–427The function F defines the equilibria of the language game equation. In [38], suchequilibria (called the Nash equilibria) were found for a system where the production andcomprehension modes are independent. In this paper, we show that these results continueto hold if the requirement of self-consistency is imposed. In other words, all the stable andneutrally stable states of the language system can be attained even if the production andcomprehension modes are cognitively related.We also characterize all the evolutionarily stable strategies (ESS) [18] of the languagesystem. It can be proved that the (“strict”) ESS correspond to fully co-ordinated languages.However, there is another kind of an evolutionarily significant state, called weak ESS,which is stable modulo some random drift. This state have been observed in manynumerical studies of language systems including the above mentioned [10,21,23]. In thispaper we analytically prove that:• If the frequency of occurrence of events (subjects of communication) in the sharedworld is exactly uniform (i.e., all events occur with exactly the same frequency), thenweak ESS can be characterized as perfectly co-ordinated languages which might havesome isolated synonyms or homonyms (see Section 5.3 for the precise definition).• In the more general case of non-uniform frequencies of events, only isolated synonymsare possible, and homonyms are unstable.The latter result means that ambiguous languages are evolutionarily unstable. Indeed,while true homonyms will reduce the communicability potential of a language, (isolated)synonyms will not. On the other hand, it is commonly observed that human languages havenumerous homonyms, whereas true synonymy is extremely rare. To resolve this apparentcontradiction, we have to remember about the presence of context.Indeed, the relevant communicative accuracy of individuals should not be defined per-word, but rather per utterance. Therefore, the entries of the “lexical matrix” are not wordsas such, but slightly larger objects, which can roughly defined as “words in a context”.As soon as we accept this level of description, then the results of the mathematical modelcorrectly describe the following observation: in human languages, there are practicallyno true homonyms that remain homonyms in the presence of contextual clues, and, on theother hand, context-dependent synonyms are rather common.To give some examples, let us first consider a lexical homonymy, such as “fall” (autumn)and “fall” (down). This is a complete homonymy on the level of words, but not on the levelof larger utterances (clearly, the utterances “in the fall” and “to fall down” can never beconfused). Similarly, the words “beautiful” and “fair” cannot be regarded as true synonymson the level of words, but if we consider the utterances “beautiful lady” and “fair lady”,they are interchangeable. This illustrates the point that when context is taken into account,then synonyms are possible, and homonyms are unstable.The rest of the paper is structured as follows. In Section 2 we develop a general notion ofassociation matrices as probability measures on the cross product of forms and meanings.We then show how a measure of communicative efficiency or mutual intelligibility maybe naturally defined. In Section 3 we show how to construct an approximating family oflanguages that converges to the optimal communicator. We examine an extension of thisin Appendix B where we study communication with a perfect language across a noisy8N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42channel. We continue by examining the implications of our results for learning theory:in Section 4 we discuss algorithms for learning to communicate and present bounds ontheir sample complexity. Finally, in Section 5 implications for evolution are discussed; inparticular, we classify all Nash equilibria and characterize the possible evolutionarily stablestrategies. Conclusions are found in Section 6.2. Communicability for linguistic systems2.1. Basic notionsWe regard a linguistic system to be an association between form and meaning. LetS ⊂ N be the set of all possible linguistic forms (sentences or signals) and M ⊂ N be theset of all possible semantic objects (meanings or referents). Note that depending on thecontext, the elements of S can be words, codes, expressions, forms, signals or sentences.The elements of M can be meanings, messages, events or referents. We will use the generalterm signals for elements of S and meanings for elements of M.The sets S and M need not be finite, but it is essential that they are enumerable.The reason the sets S and M can be viewed as countable for human languages has todo with the discrete nature of language. In the lexical setting, S is the set of all words,and therefore is naturally countable, and the countability of M (the meanings) is assuredby categorization. In the case of human grammars, we may let S = Σ ∗1 be the set of allpossible strings over a syntactic alphabet (Σ1) and M = Σ ∗2 be the set of all possiblestrings over a semantic alphabet (Σ2). Note that in this case S and M are infinite.We define a communication system, or a language, as a probability measure µ overS × M. Note that in the case of finite languages (human or artificial lexicons and animalcommunication systems), µ is related to the association matrix, A, by means of a simplerescaling.Let us enumerate all possible signals, i.e., the elements of set S, as s1, s2, s3, . . . and allpossible meanings (elements of M) as m1, m2, m3, . . . . The coding and decoding schemesof the agent are contained in the measure µ in the following manner. Each user of µ ischaracterized by an encoding matrix P and a decoding matrix Q where(cid:1)(cid:2)Pij ≡ µ(si|mj ) =µ(si, mj )/0,(cid:1)Qj i ≡ µ(mi|sj ) =µ(sj , mi)/0,p µ(sp, mj ),p µ(sp, mj ) > 0,(cid:2)p µ(sj , mp),p µ(sj , mp) > 0,(cid:2)ifotherwise,(cid:2)ifotherwise.(1)(2)Both P and Q matrices are easily interpreted. Pij is simply the probability of producing thesignal si given that one wishes to convey the meaning mj . Similarly, Qij is the probabilityof interpreting the expression si to mean mj by the same user.Matrices analogous to P and Q were introduced in [10], however, they were notexplicitly related through a common measure, µ. An effective connection between Pand Q has been employed for a particular learning mechanism, called the Saussurean[10,21].N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–429Remarks.1. The user of a language is characterized in production mode by the matrix P and incomprehension mode by the matrix Q. This captures the fact that given a particularmeaning, there might be many different ways to express it. Correspondingly given aparticular signal, there may be no unique interpretation. Thus ambiguities in sentenceinterpretation or polysemy in lexical semantics are incorporated.2. A measure µ uniquely defines the corresponding P and Q matrices. The converse isnot generally true: given the P and Q matrices it might be possible to find more thanone µ which would have the correct encoding and decoding matrices. An examplewith 2 × 2 matrices is P = Q = I and(cid:3)(cid:4)µ1 =µ2 =(cid:3)1/201/3001/202/3(cid:4),.Clearly, both µ1 and µ2 lead to the same P and Q. In order to avoid such ambiguitieswe introduce the equivalence classes of measures. We will say that two measures µ1and µ2 are equivalent to each other (µ1 ≡ µ2) if and only if the corresponding P andQ matrices are equal, i.e., P (1) = P (2) and Q(1) = Q(2).3. For a probability measure µ let us introduces ∈ S | ∃m ∈ M s.t. µ(s, m) > 0Sµ =(cid:5)(cid:6).This defines the set of signals that are used in production or comprehension by alinguistic agent. In the sense of formal language theory, this is the set of well formedsyntactic expressions. In fact, the set Sµ is what is normally called “language”. Ourdefinition of language as a measure µ contains this notion of language as the supportof µ. Similarly, one may defineMµ =(cid:5)m ∈ M | ∃s ∈ S s.t. µ(s, m) > 0(cid:6).This defines the set of all meanings that are expressible by the linguistic agent. IfMµ = M then all meanings can be expressed. If Mµ is a proper subset of M thensome meanings are left unexpressed.4. The probability measure µ, the sets Sµ and Mµ, and the matrices P and Q in humansand animals arise out of highly structured systems in the brain. In fact, it is clearthat in human languages, these objects may not vary arbitrarily. A significant activityin generative linguistics attempts to characterize the nature of this structure and thevariation that exists among natural languages of the world.2.2. Probability of events and communicability functionThe communicating agents are immersed in a world and the need to communicatemessages arises as the corresponding events occur in this shared world. Thus one maydefine a measure σ on the set of possible meanings M according to which the agentsneed to communicate each of these meanings to each other. Given two communication10N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42systems, i.e., languages µ1 and µ2, the probability that an event occurs whose meaning issuccessfully communicated from µ1 to µ2 is given byP [1 → 2] =µ1(sj |mi)µ2(mi|sj ).(cid:7)(cid:7)σ (mi)ijSimilarly, one may compute the probability with which an event is successfully communi-cated from µ2 to µ1 as(cid:7)(cid:7)P [2 → 1] =µ2(sj |mi)µ1(mi|sj ).σ (mi)ijWe may then define the effective communicability function of µ1 and µ2 as(cid:8)F (µ1, µ2) = 12P [1 → 2] + P [2 → 1](cid:9).In matrix notation, this may be written as(cid:10)(cid:9)F (µ1, µ2) = 12(cid:8)(cid:8)Q(2)P (1)Λ(cid:9)Ttr(cid:8)(cid:8)P (2)ΛQ(1)(cid:9)(cid:11)(cid:9)T,(3)+ trwhere Λ is a diagonal matrix such that Λii = σ (mi ), and P (i), Q(i) refer to the coding anddecoding matrices associated with measure µi . Note that tr(P (1)Λ(Q(2))T) is simply theprobability that an event occurs and is successfully communicated from user of µ1 to userof µ2.Remarks.1. The function F (µ1, µ2) is the average probability with which µ1 and µ2 understandeach other in two way communication mode. The function F (µ1, µ2) is symmetricalwith respect to its arguments. If µ1 is a probability measure with support only onthe diagonal elements of S × M, then the P and Q matrices are identity and thecommunicative efficiency is 1.2. F (µ1, µ1) is the communicability of two identical linguistic agents. We have0 < F (µ1, µ1) (cid:1) 1.For two different agents µ1 and µ2 we also have0 (cid:1) F (µ1, µ2) = F (µ2, µ1) (cid:1) 1.3. The marginals µ(m) and σ (m) are not equal to each other. In other words, the languageof an agent is simply given by µ and the conditional probabilities associated withit. The probability with which agents communicate different meanings is determinednot by the language but by the external world in which the agents are grounded.Therefore, two agents might have high communicative efficiency in some world andlow communicative efficiency in another one.4. A function similar to our communicability function was introduced by Hurford [10].However, all meanings were treated to have equal probabilities (a uniform measure σ ),and thus the function was not suitable for infinite matrices.N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42113. Reaching the highest communicabilityLet us assume that one of the languages is given and call this language µ0. Accordingto definition (3), for any language µ we have(cid:7)F (µ0, µ) = 12σji,j(cid:10)µ0(si |mj )µ(mj |si) + µ(si |mj )µ0(mj |si)Let us define the best response as a language µ∗, such thatF (µ0, µ∗) = supµF (µ0, µ).(cid:11).(4)(5)In what follows we will present an algorithm of building a best response or a languagewhich in some sense approaches the best response. In particular, we show that the bestresponse need not exist. However, an arbitrarily good response can be constructed. Weshow how to construct a sequence of languages (µε where ε > 0) such that F (µ0, µε) canbe made arbitrarily close to supµ F (µ0, µ)—the maximum possible mutual intelligibilitybetween a user of µ0 and a user of any allowable language.The interesting question of finding the best response in a noisy environment isconsidered in Appendix B.3.1. A special case of finite languagesIn order to keep the argument as transparent as possible, we will first make threesimplifying assumptions. The effect of relaxing these assumptions will be demonstratedin Section 3.2. For now we will assume that the following conditions are satisfied:(i) The languages are finite, and the matrices have the size N × M.(ii) The distribution σ is uniform, i.e., σi = 1/M ∀i.(iii) The measure µ0 satisfies the property of unique maxima, i.e., for each i, there exist aunique p0(i) and a unique r0(i) such thatµ0(si|mp0(i)) = maxpµ0(si |mp), µ0(mi|sr0(i)) = maxrµ0(mi |sr ).(6)The last condition states that there exists strictly one element of each column of µ0(s|m)(row of µ0(m|s)) such that it is the biggest element in the column (row).Let us maximize each of the two terms in the right hand side of expression (4) separately.First, we find a matrix Q∗ such that(cid:7)(cid:7)∗µ0(si|mj )Qij= maxQi,ji,jµ0(si |mj )Qij ,(7)where we maximize over all matrices Q whose elements are non-negative and sum up toone within each row. This results in the following definition of Q∗:1, µ0(si|mj ) = maxp µ0(si |mp),0, otherwise.Q∗ij(8)=(cid:1)12N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42In other words, in order to construct the best decoder, Q∗, we need to find the largestelements in each of the rows of µ0(s|m) and put “ones” at the correspondent slots of Q∗.The rest of the entries of the matrix Q∗ are zero. This is a well defined operation becauseof the property of unique maxima. Similarly, we can find the matrix P ∗ such that(cid:7)i,jP ∗ij µ0(mj |si ) = maxPPij µ0(mj |si),(cid:7)i,jwhere we maximize over all matrices P whose elements are non-negative and sum up toone within each column. The best encoder, P ∗, is given by(cid:1)P∗ij=1, µ0(mj |si) = maxp µ0(mj |sp),0, otherwise,(9)i.e., we maximize each column of the matrix µ0(m|s). Now, we have the best encoder andthe best decoder for the language µ0. Finding the matrices P ∗ and Q∗ completes the taskof the obverter of [23]. However, in our setting, the two matrices cannot be independent,but they need to be related by a common measure. If a measure µ∗ existed such thatµ∗(s|m) = P ∗,µ∗(m|s) = Q∗,then it would satisfy Eq. (5), thus defining the best response. It turns out that in general, µ∗does not exist. However, there always exists a measure which approaches the performanceof P ∗ and Q∗ arbitrarily close. It is convenient to use the following short hand notation:P 0ij= µ0(si|mj ),Q0ij= µ0(mj |si).We are ready to formulate the followingTheorem 3.1. For any finite language µ0 satisfying the property of unique maxima, and auniform probability distribution σ , we have(cid:8)∗P 0(QF (µ0, µ) = 1/(2M) tr)T + P∗(Q0)T(cid:9).supµIn order to prove this statement, we need to show that(a) for all µ,(cid:8)F (µ0, µ) (cid:1) 1/(2M) trP 0(Q∗)T + P ∗(Q0)T(cid:9),(b) there exists a family of languages, µε, such that(cid:12)(cid:12)supµlimε→0F (µ0, µ) − F (µ0, µε)(cid:12)(cid:12) = 0.The proof of (a) immediately follows from the definitions of the best decoder and the bestencoder. The rest of this subsection is devoted to developing an algorithmic proof of (b).Given the matrices Q∗ and P ∗, we will build a family of measures, µε, such that∗µε(m|s) = Qµε(s|m) = P(10),∗.limε→0limε→0N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4213This is not a trivial task, which is demonstrated by the following example. Suppose thatthe P ∗ and Q∗ matrices are given by(cid:3)(cid:3)(cid:4)(cid:4)P ∗ =1 00 1,Q∗ =0 11 0.It is clear that we cannot find a measure µε which would satisfy conditions (10) for thispair (P ∗, Q∗). Fortunately, it turns out that situations like this never arise. In order to provethis we will need to consider some auxiliary matrices.3.1.1. The auxiliary matrix and the absence of loopsLet us define an auxiliary matrix X in the following way:ij > 0,(cid:1)Xij =1, P ∗+ Q∗ij0, otherwise.This means that the matrix X contains nonzero entries at the slots where either of thematrices, P ∗ or Q∗, contains a non-zero entry. Now let us draw lines connecting all the“ones” of the X matrix that belong to the same row, and all the “ones” of the X matrixthat belong to the same column. We will obtain some (disjoint) graphs. Let us refer to the“ones” of the X matrix as vertices.Lemma 3.2. Suppose that a finite measure µ0 has the property of unique maxima. Graphsconstructed as described above do not contain any closed loops.Proof. Let us assume that there exists a closed loop. It looks like a polygon with rightangles. Let us consider its “turning points”, i.e., such points which simultaneously belongto a horizontal and a vertical line. Suppose there are 2K such vertices (this can only be aneven number). We will refer to these vertices as xαi ,βj , where the pair of integers, (αi , βj ),gives the coordinates of the vertex. Clearly, 1 (cid:1) i, j (cid:1) K.Without loss of generality, let xα1,β1 be connected with xα1,β2 with a horizontal line.Then xα1,β2 is connected with xα2,β2 with a vertical line, . . . , xαK ,β1 is connected withxα1,β1 with a vertical line, thus closing the loop (see Fig. 1, where we used K = 3). It ispossible to show that exactly a half of the vertices corresponds to “ones” of the P ∗ matrix,and the rest—to “ones” of the Q∗ matrix. If a vertex correspond to a “one” of the Q∗matrix then the corresponding slot of the P ∗ matrix is zero, and vice versa. This is a directconsequence of the property of unique maxima.Let us now suppose that Q∗= 0 (the alternative is that P ∗= 1,= 0, in which case the proof remains very similar). This means that Q∗Q∗= 0,because by construction (see (8)), there can be only one nonzero element in the same rowof the Q∗ matrix. Then the element P ∗= 1, because the corresponding vertex is presentα1,β2in the X matrix. This leads to P ∗= 0 (we can only have one positive element in eachcolumn of the P ∗ matrix, Eq. (9)). This argument can be continued around the loop. TheQ∗ elements along the loop are alternating between 0 and 1, and so are the elements of theP ∗ matrix, see Fig. 1.= 1, P ∗α1,β1α1,β2α1,β1α2,β2α1,β1α1,β1We can conclude that P 0, because by construction, positive elements in theQ∗ matrix correspond to the largest elements in the corresponding rows of the P 0 matrix.Similarly, we obtain 2K inequalities:> P 0α1,β2α1,β114N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42Fig. 1. No loops in graphs.,P 0αi ,βi> P 0Q0αi+1,βi+1αi ,βi+1> Q0,1 (cid:1) i (cid:1) Kαi ,βi+1(11)(12)(here we set αK+1 ≡ α1 and βK+1 ≡ β1). In Fig. 1, the maximum elements of the rows ofP 0 and the columns of Q0 are marked by crosses. The arrows indicate the direction towardthe larger elements.We will now show that system (11)–(12) is incompatible. In order to do this, we writeij Mi , where Mi is the sum of the elements of the ith row of the matrix µ0:k µ0(si, mk). Then we can rewrite P 0ij in terms of Q0 and M:µ0(si, mj ) = Q0(cid:2)Mi ≡P 0ij=(cid:2)µ0(si , mj )k µ0(sk, mj )=(cid:2)Q0ij Mik Q0kj Mk.System (11)–(12) can be presented as a closed chain of inequalities for Q0:Q0α1,β1> Q0α1,β2Q0α2,β2> Q0α2,β3. . .(cid:2)(cid:2)(cid:2)(cid:2)k Q0kβ1k Q0kβ2k Q0kβ2k Q0kβ3(cid:2)MkMkMkMk, Q0α1,β2> Q0α2,β2, Q0α2,β3> Q0α3,β3,,Mkk Q0kβik Q0kβi+1MkQ0αi ,βi> Q0αi ,βi+1(cid:2), Q0αi ,βi+1> Q0αi+1,βi+1,. . .Q0αK ,βK> Q0αK ,β1(cid:2)(cid:2)kβKk Q0k Q0kβ1MkMk, Q0αK β1> Q0α1,β1.(13)(14)N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4215From the first two inequalities we know thatQ0α1,β1> Q0α2,β2(cid:2)(cid:2)k Q0kβ1k Q0kβ2MkMk,Q0then using the next pair we similarly derive that(cid:2)α1,β1> Q0k Q0kβ1k Q0kβ3Continuing along the chain, at the Kth step we have(cid:2)α3,β3MkMk(cid:2).MkQ0α1,β1> Q0k Q0kβ1k Q0Using the last two inequalities, we finally obtain: Q0proves that there can be no closed loops in the matrix X. ✷αK ,βKα1,β1Mk(cid:2)kβK.> Q0α1,β1. This contradiction3.1.2. Constructing the matrix µεNow we can systematically build the matrix µε. From Lemma 3.2 it follows that ifwe connect all the vertices of the matrix X by horizontal and vertical lines, the resulting(disjoint) graphs will contain no closed loops. Some of the graphs might only consist ofone vertex.For each of these graphs we will perform the following procedure. Take a pair ofvertices. If they are connected by a horizontal (vertical) line, refer to the correspondingentries of the Q∗ matrix (P ∗ matrix). One of them will be one and the other—zero. Drawan arrow on the graph from the element corresponding to zero to the element correspondingto one. Repeat this for all pairs of vertices. Next, starting from some vertex, replace thecorresponding element in the X matrix by ε, and then, following the arrows, keep replacingthe elements of X by entries of the form εk, where the integer k increases or decreasesfrom one vertex to the next depending on the direction of the arrow (we can always do thisbecause by Lemma 3.2, there are not closed loops in the graphs of matrix X). We will callthe resulting matrix Aε. The measure µε is obtained by re-normalizing the elements of thematrix Aε:µε(si, mj ) = AεijAεkl.(15)k,lRemark 3.3. In the algorithm above we used powers of the small parameter ε, εk, to assignto vertices of the matrix X. More generally, one can use any functions of ε, fk(ε), suchthat limε→0 fk(ε)/fk+1(ε) = 0. Thus, the family µε found above is just one of many suchfamilies.3.1.3. Proof of Theorem 3.1We are now ready to complete the proof of Theorem 3.1, part (b).Proof. Let us show that Eq. (10) holds. In order to find entries of µε(s|m), we need to re-normalize each column of the matrix µε so that its elements sum up to one. Obviously, each(cid:13) (cid:7)16N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42column will contain at most one segment of one of the graphs. By construction, the biggestelement of this segment of the graph corresponds to the positive element of Q∗. In thelimit ε → 0, the other elements will be vanishingly small in comparison with the biggestone, and the resulting column of the µε(s|m) matrix will be identical to the correspondingcolumn of the P ∗ matrix. The same argument holds for rows of the µε(m|s) matrix whichin the limit become the rows of the Q∗ matrix. Thus we conclude that the algorithm ofSection 3.1.2 leads to constructing a family of measures µε which satisfy the requirementsof Theorem 3.1. ✷Example 3.4. Consider the following 5 × 5 matrix:23 90264142 81 4292853 77 6050288 15 68 73 5939 48 66 65 37µ0 = 11245 .(16)For this language, supµ F (µ0, µ) = 394/6225. In Fig. 2 we show the calculated P ∗ andQ∗ matrices, and then construct the X and the Aε matrices. The family µε is given by0 10 00 00 0ε013(1 + ε) + ε2ε0ε200 .00001010ε0µε =As ε → 0, F (µ0, µε) → supµ F (µ0, µ).Remark 3.5. If we let µ∗ = µε|ε=0, i.e., µε evaluated at 0, we note that µ∗ (cid:17)= µ0 ingeneral. Further, F (µ0, µ∗) < supµ F (µ0, µ). Thus, we have that limε→0 µε = µ∗ yetF (µ0, µ∗) < limε→0 F (µ0, µε) = supµ F (µ0, µ). This is a consequence of a discontinuityin the definition of the communicability function, F (L1, L2). Namely, the conditionalprobabilities entering definition (4) are discontinuous when all the elements of a columnor a row of µ are zero, see Eqs. (1)–(2). Thus the value of F (µ0, µε) may have a jump atε = 0.3.2. General languagesNow we will demonstrate the effect of relaxing assumptions (i) through (iii) ofSection 3.1.3.2.1. Multiple maxima and neutral verticesIf condition (iii) of the previous section is not satisfied, that is the language µ0 does notpossess the property of unique maxima, then definitions (8) and (9) have to be changed.For instance, if µ0(sk|mα1) = · · · = µ0(sk|mαn) are all maximal values of the kth row ofmatrix µ0(s|m), then we can take= γn,= γ1, . . . , Q∗Q∗α1,kαn,kN. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4217Fig. 2. Construction of Aε for Example 3.4. We first form P 0 and Q0 matrices by normalizing columns androws of µ0 respectively; this step is not shown here. Then we can construct the best encoder, P ∗, by identifyingthe maximal elements in the columns of Q0, and the best decoder, Q∗, by identifying the maximal elements inthe rows of P 0, see the top of the figure. Next, we combine the positive elements (or vertices) of P ∗tocreate the auxiliary matrix X. The vertices of X that belong to the same column (row) are connected. In order todefine the direction of the arrows, we have to refer to the matrices P ∗. If two vertices are connected by avertical line, we find the corresponding elements of the P ∗matrix (they are encircled); the direction of the arrowis always toward the “one” of the P ∗matrix. Similarly, if two vertices are connected by a horizontal line, we findthe corresponding elements of the Q∗matrix (encircled) and direct the arrow toward the “one” of the Q∗matrix.Finally, we build the Aε matrix by replacing the “ones” of the X matrix by powers of ε. The powers of ε mustbe arranged in such a way that in each of the connected graphs, the arrows point from a smaller entry to a largerentry. Note that in this example P ∗are not compatible with any single measure.and Q∗and Q∗and Q∗(cid:2)i,j µ0(si |mj )Q∗ni=1 γi = 1.so that γ1, . . . , γn are arbitrary positive numbers with the only restriction that(cid:2)ij (Eq. (7)) does not depend on theThe result of evaluating the functionvalues of the coefficients γi . The same argument can be repeated for P ∗. Next we notethat some closed loops are possible in this case, so that Lemma 3.2 has to be modified.Let us generalize the procedure of assigning direction to the graphs in the case wherethe language µ0 does not possess the property of unique maxima. We will not assign adirection to segments of the graph corresponding to rows of P 0 (columns of Q0) whichdo not have a unique maximum. We will call the corresponding vertices neutral vertices.For vertices which are not neutral, we proceed as before, i.e., if two vertices are connectedwith a horizontal (vertical) line, then the arrow points toward the larger element of the Q∗(P ∗) matrix.For a closed loop of the auxiliary matrix X, we define the direction of each segmentas positive (negative) if it is clockwise (counterclockwise). The direction is zero if there isno arrow. We say that the direction changes sign if it changes from positive to negative orfrom negative to positive. Instead of Lemma 3.2 we have18N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42Lemma 3.6. The following is true for loops of the auxiliary matrix X:(a) they contain more than one neutral vertex.(b) the direction of the graph changes sign at least once, or it is identically zero.Proof. Statement (a) can be proved by assuming that there are no neutral vertices in aloop and applying Lemma 3.2. To prove statement (b) let us assume that the direction ofthe arrows in a loop is always positive or neutral. Then we can repeat the argument ofLemma 3.2 and write down a chain of equations/inequalities similar to (13)–(14). The onlydifference is that some of the inequalities will in fact have an “equals” sign. More precisely,a segment with a positive (zero) direction will correspond to a “<” (“=”). We immediatelyget a contradiction unless all signs are “=”, or the strict inequalities change direction atleast once. This proves statement (b). ✷The statement of Theorem 3.1 still holds in this case if the perfect encoder and decoderare redefined as indicated above. The algorithm of building the “best response” languagestays very similar. We assign powers of ε to all nodes so that the power decreases in thedirection of arrows. For adjacent neutral nodes, the power of ε must be the same, and somearbitrary weights can be assigned to the neutral nodes. If a loop is present, it is still possibleto assign powers of ε in a consistent way because of statement (b) of Lemma 3.6. It maybe necessary to use non-integer powers.Example 3.7. Consider the following 3 × 3 matrix:µ0 = 143(cid:20)(cid:21).8252 10 2293It is easy to calculate the P 0 and the Q0 matrices:(cid:20)(cid:20)(cid:21)P 0 =8/13 5/24 1/32/13 5/12 1/31/33/83/13,Q0 =8/151/35/71/73/14 9/14(17)(18)(cid:21).2/151/71/7We can see that this language does not possess the property of unique maxima: the thirdcolumn of Q0 contains two maximal elements. We have(cid:21)(cid:21)(cid:20)(cid:20)(cid:20)(cid:21)P ∗ =1000100γ1 − γ,Q∗ =,X =.(19)1 00 10 10001 00 10 1011The directed graph contains one loop with two neutral vertices marked by “N ”:11NNN. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4219The graph changes direction once along the loop. Applying our algorithm we obtain thefollowing Aε matrix:01√εAε =1000γ1εγ2ε(cid:20)(cid:21).For any positive numbers γ1,2 this family satisfies the conditions of Theorem 3.1, i.e.,approaches the best communicability. Note that if γ1/γ2 = γ then in the limit of ε → 0,the matrices P ∗ and Q∗ are recovered, see Eqs. (19).Note that in general it is not always possible to find an Aε matrix which would give riseto given P ∗ and Q∗; some conditions on the arbitrary neutral coefficients in P ∗ and Q∗matrices may be imposed (see also Lemma 5.3).3.2.2. Non-uniform distributionsBefore we only considered the uniform distributions σi = 1/M (condition (ii) above).Now let us assume some general distribution. It turns out that the argument changes verylittle. Namely, definition (8) becomes(cid:1)Q∗ij=1, µ0(si|mj )σj = maxp µ0(si |mp)σp,0, otherwise,(20)(and similarly for the case when we do not have the unique maxima property), anddefinition (9) stays the same. In the proof of Lemma 3.2, the argument follows the samelogics, and the only change comes into inequalities (11): we havePαi ,βi σi > Pαi ,βi+1σi+1.(21)However, the multipliers σl also get canceled out when we go around the loop, so thestatements of Lemmas 3.2 and 3.6 remain true in this case, and thus the algorithm ofbuilding the best response is the same.3.2.3. Infinite matricesFinally, we will deal with restriction (i) of Section 3.1. First of all let us show thatdefinition (4) makes sense in the case of infinite matrices. We have(cid:7)12i(cid:1) 12(cid:8)µ0(si|mj )µ(mj |si) + µ(si|mj )µ0(mj |si)(cid:7)(cid:8)µ0(si|mj ) + µ(si|mj )(cid:9)= 1.(cid:9)iSince σ is a measure, we have(cid:2)Now, us define the following quantities:j σj = 1, which leads to the conclusion F (L0, L) (cid:1) 1.Ai = supjP 0ij σj ,Bi = supjQ0j i .The generalization of Theorem 3.1 in the case of infinite matrices is given byTheorem 3.8. For infinite matrices, supµ F (µ0, µ) = 12(cid:2)i(Ai + Bi ).20N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42It is straightforward to see that for any µ, F (µ0, µ) (cid:1) 12i(Ai + Bi ). In order toconclude the proof of Theorem 3.8, it is necessary to construct a family of languages,µε, such that limε→0 | supµ F (µ0, µ) − F (µ0, µε)| = 0. This is done in Appendix A.(cid:2)3.2.4. The existence of the best responseTo end this section, we will address one more issue. From Theorem 3.1 and extensionsit follows that there exists a family of languages, µε, such that limε→∞ F (µ0, µε) =(cid:2)µ F (µ0, µ). Can it happen that the supremum is actually reached by some language?From previous considerations it is clear that a language µ∗ satisfies Eq. (5) if and only if italso obeysµ∗(s|m) = P ∗,µ∗(m|s) = Q∗(where P ∗ and Q∗ may not be unique, like in the case where the property of unique maximais not satisfied). The question of existence of µ∗ is answered by the followingTheorem 3.9. For a language µ0, the limiting measure µ∗ exists if and only if the auxiliarymatrix X satisfies the following property: the only vertices of the matrix X that share thesame row (column) are neutral vertices.Proof. The “if” part is easy: given the condition of the theorem, we can apply the algorithmof building the family µε (Section 3.1.2 and its extension from Section 3.2.1) and observethat the powers of ε simply get canceled when we normalize the matrix µε. This means thatµε does not depend on ε, and since we know that it satisfies the conditions of Theorem 3.1,we conclude that µε = µ∗.To finish the proof we need to show that if the condition of the theorem is not satisfied,then µ∗ does not exist. Let us assume that there are two adjacent (non-neutral) vertices, aand b, in the matrix X. Without loss of generality let us assume that they are connected bya horizontal line. This means that Q∗ has a 1 at the one of the vertices, say vertex a, anda 0 at vertex b. Therefore, if µ∗ exists then it must have a positive entry at a. On the otherhand, P ∗ has a 1 at vertex b and a zero at vertex a. Therefore, the matrix µ∗ must have azero at vertex a, which leads to a contradiction. ✷Corollary 3.10. If P ∗ = Q∗ are extended permutation matrices, i.e., square permutationmatrices perhaps with extra rows or columns consisting entirely of zeros, then µ∗ is definedas P ∗, properly normalized.Corollary 3.11. If the property of unique maxima is not satisfied and µ∗ exists, it is notunique.4. Implications for learningFrom the preceding discussion it is now clear that in order to maximize mutualintelligibility with a language user (characterized by the measure µ), it may be necessaryN. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4221to use a different measure, µ∗, where µ∗ (cid:17)= µ. This fact has implications both for learningand evolution of populations of linguistic agents.Let us first consider the problem of an agent trying to learn a language in order tocommunicate with some other agent whose language is characterized by the measure µ.Recall that µ∗ (the best response) itself may not exist, however, an arbitrarily closeapproximation µε (for any ε) does exist. Therefore, the learner’s task becomes to estimateµε. What degree of accuracy, ε, is useful or necessary will depend upon the particularapplication in mind. Since the measure µ is unknown to the learner at the outset, there aretwo natural learning scenarios depending upon how much information is available to thelearner on each interaction.(1) Full information: This corresponds to the situation where the learner is able to sampleµ directly to get (sentence, meaning) pairs. Thus, when the teacher speaks, bothsentence and meaning are directly accessible. The strategy of the learner is to estimateµ as well as it can and derive from it the P ∗ and Q∗ matrices and ultimately µε usingthe procedure described in the previous sections.(2) Partial information: In most natural settings, however, the meaning may not be directlyaccessible. In other words, the learner only hears the sentence while the intendedmeaning is latent. What the learner reasonably may have access to is whether itsinterpretation of the sentence was successful or not. On the basis of this information,the learner must somehow derive the optimal communication strategy. We refer tothis as learning with partial information. Note that we assume that the learner (hearer)receives weak reinforcement regarding the communicative exchange. This is similar tothe setting of selfish games developed in the work of Steels and pursued also in [40](always through simulations). There are variants where the learner could get strongreinforcement either in the extreme form of being told the true meaning after a failedcommunicative exchange or some alternative corrective feedback. We do not explorethe strong reinforcement setting here.Thus we see that (1) full information and (2) partial information suggest two differentframeworks for learning; in either case, the learner has to estimate P and Q matrices ofthe teacher.4.1. Estimating PAn important task for the learner is to estimate Q∗ which is derivable from the P matrixof the teacher. Recall that(cid:1)∗Qij=1, σj µ(si |mj ) = maxp σpµ(si |mp),0, otherwise.4.1.1. Learning with full informationThe learner, in this case, has access to (s, m) (sentence,meaning) pairs every time theteacher produces a sentence. We can define the eventAij = Teacher produces si to communicate mj .22N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42The probability of event Aij is simply σj µ(si|mj ). Therefore, if the teacher produces n(sentence, meaning) pairs (which are random, independent and identically distributed),then the ratioˆaij (n) =kijnis an empirical estimate of the probability of the event Aij . By the law of large numbers,as n → ∞ we haveˆaij (n) → σj µ(si |mj )with probability 1. For the case under consideration, we can even bound the rate at whichthis convergence occurs. For example, applying Hoeffding’s inequality, we have(cid:10)(cid:12)(cid:12) ˆaij (n) − σj µ(si|mj )(cid:12)(cid:12) > ε(cid:11)P(cid:1) 2 e−ε2n/2.This convergence is guaranteed for fixed (i, j ). In general, the learner must estimate acollection of events. The total number of events are given by the total number of possible(sentence, meaning) pairs. As before, let us assume that there are N possible sentences andM possible meanings. Therefore, there are NM different events whose probabilities needto be estimated. The collection of events Aij , i = 1, . . . , N; j = 1, . . . , M, are disjoint.For a finite collection of such events, we will derive a uniform law of large numbers.Let event Eij beEij =(cid:12)(cid:12) ˆaij (n) − σj µ(si|mj )(cid:12)(cid:12) > ε.Then, by the union bound, we obtain(cid:24)Eij(cid:1)(cid:22)(cid:23)Pi,j(cid:7)i,jP (Eij ) (cid:1) NM2 e−ε2n/2.Therefore, we have(cid:22)(cid:23)(cid:24)PEiji,j(cid:10)∀i, j(cid:12)(cid:12) ˆaij (n) − σj µ(si|mj )(cid:12)(cid:12) (cid:1) ε(cid:11)> 1 − NM2 e−ε2n/2.= PThus, with high probability (depending upon the number of examples, n) all empiricalestimates ˆaij (n) are close to σj µ(si|mj ), respectively. Estimating the σj µ(si|mj )’s is thestep to estimating the Q∗ matrix that is required for the optimal communication system.4.1.2. Learning with partial informationNow consider the setup in (2) where the learner has no access to the meaning directlybut has to guess a meaning and is told after the event whether the guess was correct orincorrect. Thus the learner has access to asymmetric information: if the guess was correct,the learner knows the true intended meaning; if the guess was incorrect, the learner merelyknows what the meaning was not. As it turns out, this does not dramatically change thestate of affairs. To see this, let the learner guess a meaning uniformly at random. Thuswith probability 1/M the learner chooses a meaning mj . Each time the teacher producesN. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4223a sentence, the intended meaning may be successfully communicated or not. Define theeventAij = Teacher produces si ; Learner guesses mj ; Communication is successful.M σj µ(si|mj ). The event Aij is observable sinceThe probability of event Aij is simply 1the learner knows (i) what sentence has been uttered by the teacher, (ii) what meaning it(the learner) assigned to the sentence, and (iii) whether communication was successful.Therefore after n sentences have been produced by the teacher, the learner can count kij —the number of times event Aij has occurred, and can make an empirical estimate of theprobability of Aij asˆaij (n) =kijn.By the same argument as before, ˆaij (n) converges in probability to 1M σj µ(si|mj ) and therates are provided by the Hoeffding bounds. Since M is fixed in advance and known, thisallows the learner to guess σj µ(si|mj ) for each i, j arbitrarily well. Let us be a little moreprecise about the rates of convergence. The learner’s estimate of σj µ(si|mj ) is really M ˆaijwhere ˆaij is defined above. Therefore we have that(cid:22)(cid:12)(cid:12)(cid:12) ˆaij − 1(cid:12)M(cid:10)(cid:12)(cid:12)M ˆaij − σj µ(si|mj )−ε2n/(2M2).σj µ(si|mj )(cid:12)(cid:12) > ε(cid:12)(cid:12)(cid:12)(cid:12) >(cid:1) 2 eεM= PP(cid:24)(cid:11)Thus the confidence in the ε-good estimate of σj µ(si|mj ) is poorer than before. By thesame argument as in case (2), we have a uniform bound as follows:−ε2n/(2M2).(cid:12)(cid:12)M ˆaij − σj µ(si |mj )> 1 − NM2 e(cid:12)(cid:12) (cid:1) ε∀i, j(22)P(cid:11)(cid:10)4.2. Estimating QLet us now consider the task of estimating P ∗ which is derivable from the Q matrix ofthe teacher. The same arguments of the previous section apply. Recall that(cid:1)P ∗ij=1, µ(mj |si ) = maxp µ(mj |sp),0, otherwise.4.2.1. Learning with full informationHere the learner has direct access to the meaning assigned by the teacher to eachsentence. Therefore, the learner need only pick a sentence uniformly at random (withprobability 1/N ) and produce it for the teacher to hear. Let us define the eventAij = Learner produces si; Teacher interprets as mj .The event Aij is observable on each trial. The probability with which it occurs is givenN µ(mj |si). After n trials (where the learner speaks in this manner), the learner simplyby 1counts the number kij of times event Aij occurs and its estimate of 1N µ(mj |si) is kij /n.Therefore, we have(cid:22)(cid:12)(cid:12)(cid:12) ˆaij − 1(cid:12)N−ε2n/(2N 2).(cid:12)(cid:12)(cid:12)(cid:12) > εµ(mj |si)(cid:1) 2 eP(cid:24)24N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42Using the same arguments as before, we have(cid:10)P∀i, j(cid:12)(cid:12)MN ˆaij − µ(mj |si )(cid:12)(cid:12) (cid:1) ε(cid:11)> 1 − NM2 e−ε2n/(2N 2).4.2.2. Learning with partial informationThe learner simply picks a (sentence, meaning) pair uniformly at random (withprobability 1/(NM)). Define the eventAij = Learner produces (si, mj ); Communication is successful.The event Aij is observable by the learner on each trial. The probability of event Aij isNM µ(mj |si ). After n trials (where the learner speaks), the learner counts the number kij1of times event Aij occurs. Therefore, we again have(cid:22)(cid:12)(cid:12)(cid:12) ˆaij − 1(cid:12)NMPµ(mj |si)(cid:1) 2 e−ε2n/(2M2N 2).(cid:24)(cid:12)(cid:12)(cid:12)(cid:12) > εUsing the same arguments as before, we have(cid:10)P∀i, j(cid:12)(cid:12)MN ˆaij − µ(mj |si )(cid:12)(cid:12) (cid:1) ε(cid:11)> 1 − NM2 e−ε2n/(2M2N 2).(23)4.3. Sample complexity boundsNow we can put the pieces together to determine the number of learning events that needto occur so that with high probability, the learner will be able to develop a language withε-good communicability. Let the teacher’s measure be µ. We will assume that µ is suchthat the P and Q matrices have unique row-wise and column-wise maxima respectively.First let us introduce the margin by which the maximum value clears all other values in therow and column respectively. This margin will play an important role in determining thenumber of learning events.Definition 1. For each i, let∗ij= arg maxjσj µ(si |mj )and for each j , let∗ji= arg maxiµ(mj |si ).Then, we define the margin γ to be the largest real number such thatσj ∗iµ(si|mj ∗i) (cid:2) σj µ(si|mj ) + γ∀j (cid:17)= j∗iandµ(mj |si∗j) (cid:2) µ(mj |si) + γ∀i (cid:17)= i∗j .N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42254.3.1. Learning with partial informationWe have described how to estimate the Q∗ and P ∗ matrices; the following theoremprovides a bound on the number of examples needed to ensure correct estimates:Theorem 4.1. If the total number, n, of interactions between teacher and learner(with partial information) is greater than (64M 2N 2/γ 2) log(4MN/δ), then with highprobability > 1 − δ, the learner can construct a measure that will give arbitrarily goodcommunicability with the teacher.Proof. Let there be n/2 interactions where the teacher speaks and the learner listens andn/2 interactions of the other form. The learner constructs estimates of σj µ(si |mj ) andµ(mj |si ) in the manner described previously. Let the estimates be denoted by ˆpij and ˆqij ,respectively. By setting ε = γ /4 in Eqs. (22) and (23), we obtain:(cid:12)(cid:12) (cid:1) γ /4(cid:12)(cid:12) ˆpij − σj µ(si|mj )> 1 − 2NM e−γ 2n/(64M2)∀i, jP(cid:10)(cid:11)and(cid:10)(cid:12)(cid:12) ˆqij − µ(mj |si)(cid:12)(cid:12) (cid:1) γ /4(cid:11)P∀i, j> 1 − 2NM eUsing the fact that P (A ∩ B) (cid:2) P (A) + P (B) − 1, we can see that with probability greaterthan 1 − 2NM(e−γ 2n/(64M2N 2) + e−γ 2n/(64M2)), the estimates ˆpij and ˆqij are both withinγ /4 of the true values. The learner chooses Q∗ and P ∗ using the estimated matrices. Letus first consider the case of Q∗. For each i the learner desires to obtain j ∗−γ 2n/(64M2N 2).i given byj ∗i= arg maxjσj µ(si |mj ).The learner choosesˆji = arg maxjˆpij ,and we claim that ˆji = j ∗get immediately:µ(si|mj ∗) (cid:2) σ ˆjiσj ∗iiµ(si|m ˆji) + γ .i . In order to prove this, assume that this is not the case. Then weσ ˆji) (cid:2) ˆpi ˆjiµ(si|m ˆjiHowever, we have the following chain of inequalities:− γ /4 (cid:2) σj ∗which leads to a contradiction. This argument holds for every i, therefore, since ˆji = j ∗ifor each i, the Q∗ matrix is identified exactly. Similarly, one can show that the P ∗ matrixis also identified exactly.− γ /4 (cid:2) ˆpij ∗µ(si|mij ∗) − γ /2,iiiThe only thing that remains is to ensure that n is large enough so that this occurs withhigh probability. We have(cid:8)2NMe−γ 2n/(64M2N 2) + e−γ 2n/(64M2)(cid:9)(cid:1) 4NM e−γ 2n/(64M2N 2) (cid:1) δ.This is satisfied for n > (64M 2N 2/γ 2) log(4MN/δ). Thus, with probability greater than1 − δ, both P ∗ and Q∗ are identified exactly. Now the procedure of approximating themeasure may be applied. ✷26N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42Remarks.1. The number of examples is seen to be a function of M, N and γ . The margin γ thatdepends upon the teacher’s language, µ, determines, in some sense, how easy it is toestimate Q∗ and P ∗ matrices for the learner. It therefore characterizes the learningdifficulty of µ in this setting.2. Finite matrices are applicable to settings such as alarm calls in animal communicationsystems and lexical learning in human linguistic systems. For example, [27] discussesthe problem of learning mappings between signals and meanings using a variety ofschemes from associative learning to Bayesian estimation.3. Infinite matrices are not learnable in general. In fact, infinite dimensional spaces areknown to be unlearnable (see [39]) and therefore further constraints will be requiredon the space of possible measures to which the teacher’s language belongs. There areseveral ways in which one could explore reasonable constraints on linguistic measures.One possibility might be to pursue the approach of Chomsky [5] and restrict the rangeof variation on possible syntactic forms and thereby on possible measures µ. Anotherpossibility might be to pursue some theory of compositional semantics (e.g., [6]) wherethe meanings of larger units like phrases and sentences are derived from compositionalrules applied to the meanings of smaller units like morphemes and words. Thus thetrue learning task is really to learn the meanings of words appropriately and then applythese compositional rules for all other syntactic forms. Since words are finite, thisreduces the infinite case to the finite one. A third possibility is to make use of contextheavily and claim that learning proceeds in a context by context (case based) fashionand in each particular context there are only a finite number of possible forms and theirinterpretations. A proper development of these issues is the subject of further researchand beyond the scope of the current paper.4. The constants in the bound on sample complexity may be tightened, although the orderis essentially correct. For example, we have let the interactions be symmetric, i.e., thenumbers of sentences the learner produces and receives are the same. It is easy tocheck that a more favorable bound is obtained when the learner speaks N 2 times asoften as it listens. In this case, it is enough to have (32M 2(N 2 + 1)/γ 2) log(4MN/δ)interactions in all.4.3.2. Learning with full informationFor completeness, let us state the number of interactions needed to learn in setting (1).This is given by the followingTheorem 4.2. If the total number, n, of interactions between teacher and learner (with fullinformation) is greater than (64N 2/γ 2) log(4MN/δ), then with high probability > 1 − δ,the learner can construct a measure that will give arbitrarily good communicability withthe teacher.The proof is very similar to that of the previous theorem and we omit it for this reason.It is noteworthy that learning with full information requires M 2 fewer interactions to learn.This is not surprising since the meanings are accessible, and the larger is the number, M,N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4227of different concepts, the greater is the difference between learning with full and partialinformation.5. Implications for evolutionIn this section we address the question of evolutionary significance of communicability.This has application in several different contexts.First, in artificial intelligence, one way to create communicating machines is to start witha population of agents with a sub-optimal communication system and let them evolve andlearn from each other. This general approach is pursued in various forms by researchersin evolutionary computation, genetic algorithms, and artificial life. Since the goal is toincrease information transfer, the function F can conveniently play a role of the “score”of different communication systems. Based on this, agents with higher intelligibility canbe arranged to proceed while agents with lower intelligibility score will be graduallyeliminated. The main question is whether such a process will ultimately lead to a coherentcommunication system. In what follows we develop a formalism that will allow one tocharacterize possible outcomes of such a dynamical system.Second, game-theoretic approaches may be relevant to the biological evolution ofsimple, innate signaling systems in the animal world. In this setting, the function Fcontributes to the biological fitness of individuals. The framework developed here hassome obvious drawbacks, such as the assumption that the signaler and the receiver are bothequally interested in the successful transfer of the information, which may not necessarilybe the case in many natural settings. However, studying basic properties of evolutionarilystable states of the simplest system may explain certain aspects of evolution, and thisapproach can later be extended to include more sophisticated scenarios, such as clashesof interest of signalers and receivers.Finally, in application to human languages, evolutionary theory can also potentiallymake a contribution. Here, it is not the innate genetic endowment that is considered tobe under the selective pressure, but the (learned and culturally transmitted) languagesthemselves [13,25]. For natural selection to act on language ability, there must be a rewardfor successful communication, which links language to biological fitness. We can thereforeassume that successful communication leads to a payoff for both the speaker and thehearer. In the spirit of evolutionary game theory, we link payoff to reproductive success [9,17]. Individuals that communicate more successfully have increased survival probabilitiesand leave more offspring. An alternative interpretation of this kind of dynamics, is thatsuch individuals will acquire a higher standing or reputation in the group and leave morefollowers who will learn their language. This simplified model, while leaving out manypotentially important aspects of the system, serves as a logical tool of reasoning about theevolution of human language. The inferred properties of the evolutionarily stable statescan be compared with the observed properties of human languages. The results of sucha comparison may shed light on the role of communicability in the evolution of humanlanguage.28N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42Fig. 3. Nash equilibria and ESS.5.1. PreliminariesLet us characterize the attracting states of the evolutionary system by means of thepayoff function, F (µ, µ(cid:2)). It is useful to recall some important definitions of the classicalgame theory [9]. Language µ is strict Nash equilibrium if we have F (µ, µ) > F (µ, µ(cid:2))for all µ(cid:2) (cid:17)= µ. It is Nash equilibrium if F (µ, µ) (cid:2) F (µ, µ(cid:2)) for all µ(cid:2) (cid:17)= µ.Language µ is called an evolutionarily stable state (ESS) [18] if µ is Nash and for everyµ(cid:2) with F (µ, µ) = F (µ, µ(cid:2)) we have F (µ, µ) > F (µ(cid:2), µ(cid:2)). Language µ is a weak ESS ifthe final strict inequality is relaxed to a weak one, F (µ, µ) (cid:2) F (µ(cid:2), µ(cid:2)).It can be shown (see [38]) that a language is an ESS if and only if it is a strict Nashequilibrium, see Fig. 3. It is clear that µ(cid:2) is a strict Nash equilibrium iff there exists a uniquebest response which is equal to µ(cid:2). From the algorithm of finding the best response given inthis paper it follows that strict Nash equilibria have to be square matrices and are given bypermutation languages, which is in accordance with [38]. In the presence of a non-trivialtransition matrix (the noisy environment), we can derive the following result: permutationlanguages are strict Nash equilibria if the T matrix is diagonally dominant both column-wise and row-wise, see Appendix B. (It is interesting that if these conditions on the Tmatrix are not satisfied then permutation languages are no longer stable! However, suchsituations correspond to the kind of noise which changes the signals beyond recognitionand can hardly be considered relevant in natural settings.) These results indicate thatperfectly coordinated systems with no homonyms or synonyms are evolutionarily stable.Strict Nash equilibria do not exhaust the set of important rest points of the system. Inorder to get the full picture we also need to characterize the weak ESS of the system. Oncethe system has reached one of the weak ESS, random drift is possible without change inthe average communicability.5.2. Nash equilibriaThe classification of Nash languages for uniform σ distributions was found in [38]; wewill reproduce their result because we will need to use it later:N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4229Theorem 5.1 [38]. For a uniform probability distribution, σ , a language is Nash if thesupports of its P and Q matrices coincide and if each row (column) of its P (Q) matrixcontains at most two distinct values, one of which is zero.3The case of general distributions will be considered in Section 5.4. An example of aNash language is given byExample 5.2. Consider the language with(cid:2)(cid:2) =PQ(cid:2)(cid:2) =a1a200000a30a5a100a40c1c1000(cid:2)c3000c20c30c20i=1 P (cid:2)(cid:2)Nija1a2000c4c40000a2a300a10a3000a2a3000c5c500(cid:2)c60c70c6c70000j =1 Q(cid:2)(cid:2)Mij ,000a4a5 .000c8c8The conditions= 1 and= 1 lead toc1 = 12− c4,c2 = c3 = 1 − c8,c5 = 12− c6,ai = 12 ,c6 = c8 − 12 .(24)This language satisfies the conditions of Theorem 5.1 and therefore, it is a Nash equilib-rium.We need to check whether the P and Q matrices of Nash equilibria are related througha common measure. We have the following usefulLemma 5.3. The P and Q matrices of Nash languages of Theorem 5.1 always correspondto a common measure µ.Proof. We will simply construct the measure µ. Let us form the diagonal M × M matrixDQ such that DQii is the value of the non-zero elements of the ith column of Q. Similarly,for the diagonal N × N matrix DP , the element DPii is the value of the non-zero elementsof the ith row of P . We have P = XDP and Q = DQX, where X is the auxiliary matrixof P and Q, i.e., it has ones on the support of Q and P and zeros everywhere else. Let usdefineA = DP XDQ.(25)3 These conditions can be derived by methods of Section 3.2.1 using the arbitrariness in the algorithm in thepresence of neutral vertices.30N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42It is easy to check that the matrix µ obtained by the proper normalization of A correspondsto the matrices P and Q. ✷Let us assume that µ is Nash and there exists a language µ(cid:2) such that F (µ, µ) =F (µ, µ(cid:2)), and F (µ(cid:2), mu(cid:2)) > F (µ, µ). There are selective pressures in the system for thelanguage µ to be replaced by the language µ(cid:2). A much more “reliable” equilibrium statesare given by weak ESS. If a system is at a weak ESS, it can only change its state becauseof a random drift which takes a very long time in large populations [24]. Therefore, it isimportant to be able to characterize all weak ESS of the language system.It has been observed by [38] that Nash equilibria may or may not correspond to weakESS. Here we derive specific conditions under which Nash equilibria are weak ESSlanguages.5.3. Weak ESS for uniform σ -distributionsWe will say that a language µ has synonyms (homonyms) if some column (row) of thematrix µ has more than one positive entries. Let us call a synonym (homonym) isolated ifthe corresponding rows (columns) of the matrix µ contain no other positive elements.Example 5.4. Consider the languageµ = 12 + β0 α 1 − αβ 0000000000γ1 − γ .(26)The synonyms µ34 and µ44 are isolated because the 3rd and the 4th rows do not containother positive entries. The homonyms µ12 and µ13 are also isolated because they are theonly entries in columns 2 and 3.We will call syno-homonyms such sets of elements that for each two of them it ispossible to find a chain of elements connecting the given two elements via synonym-synonym or homonym-homonym relationships. Example 5.2 contains syno-homonyms.Suppose that the only synonyms and homonyms of a language, µ, are isolated ones. Wehave the following observation.Observation 5.5. For any µ∗ which is a best response to µ, the function F (µ, µ∗) does notdepend on the actual entries in the matrices but is simply equal to 1/M times the number of“effective” elements, if we count all the synonyms corresponding to the same meaning asone effective element, and all the homonyms expressed by the same word as one effectiveelement.To illustrate this we note that in Example 5.4 we have three effective elements (the twosynonyms counted as one and the two homonyms counted as one). Thus F (µ, µ) = 34 .The following statement holds:N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4231Theorem 5.6. For the uniform probability distribution σ , the language µ is a weakESS if and only if the only kind of synonyms (homonyms) it has are isolated synonyms(homonyms).Proof. The proof contains two parts. First we assume that the language satisfies theconditions of the theorem and prove that (i) it is Nash and (ii) if for some µ(cid:2), F (µ, µ(cid:2)) =F (µ, µ) then F (µ(cid:2), µ(cid:2)) (cid:1) F (µ, µ). Then, we will show that the languages of Theorem 5.6are the only weak ESS.The languages µ of Theorem 5.6 are Nash because they obey the conditions ofTheorem 5.1. Next, we can see that by construction, the auxiliary matrix X containsno closed loops and no turns, and thus by Theorem 3.9, the best response exists. FromObservation 5.5 it follows that F (µ, µ∗) = F (µ, µ) = F (µ∗, µ∗), i.e., µ is a weak ESS.To conclude the proof we need to show that no other Nash language is an ESS. Letus suppose that a language µ(cid:2)(cid:2) does not satisfy the conditions of Theorem 5.6. Then itcontains sets of syno-homonyms. We will show that there exists a language ˜µ satisfyingthe conditions of Theorem 5.6 such that F (µ(cid:2)(cid:2), µ(cid:2)(cid:2)) = F (µ(cid:2)(cid:2), ˜µ) butF ( ˜µ, ˜µ) > F (µ(cid:2)(cid:2), µ(cid:2)(cid:2)).(27)Using the algorithm of finding the best response, we can see that the P ∗ and Q∗ matricesfor language µ(cid:2)(cid:2) have the same support as the language itself, but have no symmetries. It iseasy to check that the choice of P ∗ and Q∗ (and thus the best response, µ∗) is not unique.Let us identify all the groups of syno-homonyms in µ∗; generally, they can berepresented as sub-matrices of the size k × l for some 1 (cid:1) k (cid:1) N and 1 (cid:1) l (cid:1) M, with norows or columns consisting entirely of zeros. Each of the sub-matrices has to be consideredseparately to maximize its contribution to the function F (µ∗, µ∗). Below we will assumefor simplicity that there is only one group of syno-homonyms, as the generalization tomultiple groups is straightforward.Now we will build such ˜µ that F ( ˜µ, ˜µ) = maxµ∗ F (µ∗, µ∗); for clarity it is useful toconsult the example considered below. In the support of the matrices P ∗ and Q∗, X, letus identify the largest extended permutation matrix which belongs to the support. It isnot unique, and its size cannot be bigger than mkl ≡ min(k, l). This is the skeleton of thematrix (cid:25)X, the support of the matrix ˜µ. Next, we need to make sure that the support of(cid:25)X contains at least one element from each row and column of the sub-matrix—otherwiseF (µ(cid:2)(cid:2), µ(cid:2)(cid:2)) (cid:17)= F (µ(cid:2)(cid:2), ˜µ). This can be done by adding some elements from matrix X to theskeleton permutation matrix, one per each row (column) that are missing from (cid:25)X. It is easyto check that the resulting k × l matrix can only contain isolated synonyms or homonyms.To build the (cid:25)P and (cid:25)Q matrices out of (cid:25)X, we simply make sure that they satisfy the standardnormalization conditions. This leaves the entries corresponding to the isolated homonymsin the (cid:25)Q matrix (synonyms in the (cid:25)P matrix) undefined.All is left is to show that for this measure ˜µ, condition (27) holds. Let us consider thefunction F (µ∗, µ∗), where µ∗ is any best response to µ(cid:2)(cid:2). F (µ∗, µ∗) is a linear function ofits arguments, the entries of the matrices P ∗ and Q∗. A linear function can only reach itsmaximum on the boundary of the domain. For each row of the Q∗ matrix, its entries lie on asimplex. The maximum is reached when one of these elements is one and the rest are zero.Because of the restriction that the supports of the matrices P ∗ and Q∗ must coincide, the32N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42non-zero entries corresponding to the vertices of the simplexes must form a permutationmatrix. Note that the value of the function F (µ∗, µ∗) does not depend on the value of theentries corresponding to isolated synonyms/homonyms. This means that by construction,˜µ defined as above corresponds to the maximum of the function F (µ∗, µ∗), and thereforeinequality (27) holds.We conclude that for any language µ(cid:2)(cid:2) containing syno-homonyms, one can alwaysfind a matrix ˜µ satisfying conditions of Theorem 5.6 such that F ( ˜µ, ˜µ) > F (µ(cid:2)(cid:2), ˜µ) =F (µ(cid:2)(cid:2), µ(cid:2)(cid:2)). Theorem 5.6 is proven. ✷To illustrate Theorem 5.6 and the above algorithm, we consider Example 5.2. It presentsa Nash language which does not satisfy the conditions of Theorem 5.6, i.e., contains syno-homonyms. Its best response is defined by the following matrices:P ∗ =Q∗ =α1α2000a1b100000α30α500a20b2β100α40a300b30γ1β2000a4b40000γ2β3000a5b500δ10γ300a60b6000δ2δ3000a7b700 , ,000β4β5000a8b8with the usual normalization restrictions plus the condition that P ∗ and Q∗ must haveidentical support. The normalization conditions state that the elements of the columns ofP ∗ and rows of Q∗ belong to some simplexes, e.g., a1 + a3 + a4 + a6 = 1. Some of theentries of the matrices P ∗ and Q∗ are allowed to be zero, but there can be no rows orcolumns consisting entirely of zeros. If this holds, we have (µ(cid:2)(cid:2), µ∗) = 5/2 no matter whatthe entries of µ∗ are (this follows from Eqs. (24) and normalization conditions on P ∗, Q∗).The function F (µ∗, µ∗), on the other hand, depends on the entries of µ∗ and reachesits maximum at the corners of the simplexes. In order to find the maximum, we need toidentify the largest permutation matrix in the support of µ∗; in Fig. 4 its elements areencircled by solid lines. Then we make sure that there are no zero rows or columns byadding three more elements to (cid:25)X (they are encircled by a dotted line). The maximum˜µ (seevalue of F (µ∗, µ∗) is 5, because such is the number of effective entries ofObservation 5.5); in Fig. 4, the isolated homonyms are underlined. The matrices (cid:25)P and(cid:25)Q obtained from (cid:25)X are:(cid:25)P =100000 00 01 00 10 00 01 00 10 00 00 00 01 10 00 0 ,00001N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4233Fig. 4. Building the matrix ˜µ for Example 5.2.(cid:25)Q =01000 x1000000001with x1 + x2 + x3 + x4 = 1. The corresponding measure ˜µ satisfies (27). We conclude thatlanguage of Example 5.2 is not a weak ESS.0 00 10 01 00 000x20000x40000x300 ,5.4. Weak ESS for general σ -distributionsFirst of all we will generalize Theorem 5.1 for the case of non-uniform σ . We haveTheorem 5.1(cid:2). Let Λ be the diagonal matrix with elements Λii = σi . Then a language isNash if the supports of its P , P Λ and Q matrices coincide and if each row (column) of itsP Λ (Q) matrix contains at most two distinct values, one of which is zero.Example 5.7. For N = 2, M = 3 and σi given by (1/2, 1/4, 1/4), the language(cid:3)(cid:3)(cid:4)(cid:4)P =1/2 11/2 0(cid:3)01,Q =(cid:4)P Λ =1/4 1/41/4001/41/3 2/31/3002/3,is a Nash equilibrium.Next, let us generalize our results about the weak ESS. As we saw in the previoussection, for uniform σ -distributions weak ESS may contain isolated synonyms andhomonyms. This means that the evolutionary system can sometimes get stuck in a sub-optimal state where the average communicative efficiency is smaller than one; this isa consequence of having homonyms in a language and/or not being able to express allmeanings. Below we show that ambiguous languages can be stable only in the degeneratecase of uniform probability distribution, σ . As soon as we lift this degeneracy, homonymsdisappear from the language!34N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42Theorem 5.8. For non-uniform σ -distributions, the language µ is a weak ESS if and onlyif the only kind of synonyms it has are isolated synonyms. It cannot contain homonyms.Proof. First we will show that a Nash language for non-uniform σ -distributions cannotcontain isolated homonyms.Let us assume that there exists a Nash language, µ, such that it contains a string of lisolated homonyms. The fact that µ is Nash means that µ is the best response to itself,i.e., F (µ, µ) = supµ(cid:2) F (µ, µ(cid:2)). Let us follow the algorithm of Section 3.2.2 to constructthe X matrix. In order for the X matrix to contain the sting of homonyms, the Q∗matrix must contain them, which means that the P Λ matrix must contain a string of lidentical elements, say, (a, . . . , a). This in turn means that the P matrix must contain astring (a/σ1, . . . , a/σl). Since the values σ1, . . . , σl are not all the same, this means thatthe elements below and above the string (a/σ1, . . . , a/σl) of the matrix P cannot be allidentically equal to zero (remember that the columns of P must sum up to one). Therefore,the matrix µ must contain non-zero elements below or above this string, i.e., the homonymscannot be isolated, which is a contradiction.Now, we need to show that for any language, µ(cid:2)(cid:2), which contains syno-homonyms,another language ˜µ can be found such that F (µ(cid:2)(cid:2), ˜µ) = F (µ(cid:2)(cid:2), µ(cid:2)(cid:2)) and F ( ˜µ, ˜µ) >F (µ(cid:2)(cid:2), µ(cid:2)(cid:2)). We proceed with building the language ˜µ exactly as in the proof ofTheorem 5.6. The difference emerges when we consider the function F ( ˜µ, ˜µ). Before,its value did not depend on the values of the elements which corresponded to isolatedhomonyms. Say, if we had a string α1, . . . , αl in the (cid:25)Q matrix, the corresponding elementsli=1 αi , which is equal to one. Now, they enter as a linear combinationentered as(cid:2)li=1 σi αi , and in order to maximize their contribution, we would have to take αk = 1and αj = 0 for j (cid:17)= k, where σk is the largest of σi . Of course, this means that the supportof the resulting matrix (cid:25)Q is smaller than the support of Q(cid:2)(cid:2), so we cannot use this languageas a maximizer. However, we can take σk = 1 − ε and σj = ε/(l − 1). By choosing ε to besmall enough, we can always find the language ˜µ satisfying (27).(cid:2)We conclude that the only weak ESS are languages which may not contain homo-nyms. ✷Note that Nash equilibria in the case of non-uniform σ -distributions may containisolated synonyms. The important difference is that isolated synonyms do not introduceany ambiguity in the language. We can conclude that in the case of general distributions,the ESS and weak ESS of the system correspond to the states with perfect coherence, i.e.,no ambiguities may be present in the language. The only possible source of reduction ofthe average communicability function may come from poverty, i.e., the absence of certainmeanings from the language.Remark 5.9. Theorems 5.6 and 5.8 can be proven also if we do not assume that the matricesP and Q are connected through a common matrix µ, and the proofs are not much longerthan the ones presented here.N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42356. ConclusionsWe have considered a system of linguistic agents, each characterized by a language, i.e.,a measure µ on the (signal×meaning) space. The mutual intelligibility of such agents canbe characterized in a natural way as a simple probability to transmit signals successfullyboth ways. We have studied the problem of optimizing the mutual intelligibility oflinguistic agents in a shared environment.It turned out that, for a given language µ0, another language can be found which leadsto the mutual intelligibility higher than the one achieved with µ0 itself. (The exceptions arethe languages which correspond to Nash equilibria, for instance, permutation languages.)Moreover, a family of languages, µε, exists which leads to the optimization of intelligibilityas ε → 0. We have identified an algorithm to construct such languages with and withoutexternal noise in the system.The results are of consequence for learning theory. It is apparent that in order tomaximize intelligibility, the offspring is better off learning the “best response” languagesfound here rather than simply copying the language of their parents (or the population).We have identified some algorithms that can be used for this learning task and calculatedtheir efficiency.From the evolutionary prospective, we can identify all the languages which correspondto evolutionary stable strategies in a language game. It turns out that the strict ESS (i.e.,the stable equilibria of the system) are languages which relate signals to meanings in aone-to-one way. The weak ESS (the neutral equilibria in dynamics) may contain isolatedsynonyms, but never homonyms, which means that there cannot be ambiguity in language(the exception is the degenerate case where all meanings occur with exactly the samefrequency).Appendix A. Infinite matricesHere we present an algorithmic proof of Theorem 2 for infinite languages. The maindifficulty here is that the best decoder and the best encoder cannot be defined in the sameway as they were for finite matrices, formulas (8) and (9). In the present case we needto show that an equivalent of matrices P ∗ and Q∗ can be constructed. We will prove thefollowingLemma A.1. For any ε0, there exists an integer N and a pair ( (cid:25)P ∗, (cid:25)Q∗) of N × N matricessuch that(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) supµ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) supµ1212∞(cid:7)∞(cid:7)l=1∞(cid:7)σlσlk=1∞(cid:7)l=1k=1PklQ0kl− 12P 0klQkl − 12(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < ε0,(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < ε0.(cid:25)P∗klQ0klP 0kl(cid:25)Q∗klN(cid:7)N(cid:7)l=1N(cid:7)σlσlk=1N(cid:7)l=1k=1(A.1)(A.2)36N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42Remark A.2. The matrix (cid:25)P ∗ can be said to be within ε0 of the best decoder, and the matrix(cid:25)Q∗ is within ε0 of the best encoder. Finding these matrices is equivalent to controlling thebehavior of, respectively, the second and the first terms in the expression for F (µ0, µ):F (µ0, µ) = 12∞(cid:7)∞(cid:7)(cid:10)σll=1k=1klQkl + PklQ0P 0kl(cid:11).Proof. First of all, for any language µ, ∀ ε1 > 0, there exists an integer L such that(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)1212∞(cid:7)∞(cid:7)l=1∞(cid:7)σlσlk=1∞(cid:7)l=1k=1P 0klQkl − 12PklQ0kl− 12(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < ε1,(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < ε1.P 0klQklPklQ0klµ(cid:7)∞(cid:7)l=1L(cid:7)σlσlk=1∞(cid:7)l=1k=1(A.3)(A.4)(A.5)This is because σl is a measure and the “tails”, 1(cid:2)∞2l=L σl ×kl can always be made small enough by adjusting L. The same inequalitiesklQkl and 12k=1 PklQ0k=1 P 0l=L σl(cid:2)∞(cid:2)∞(cid:2)∞hold for the supremum values of all terms.Let us concentrate on the first term of F (L0, L). For any language L, ∀ε1 > 0, ∃K1 suchthat(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)12L(cid:7)∞(cid:7)σll=1k=1klQkl − 1P 02(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < ε1,P 0klQklL(cid:7)K1(cid:7)σll=1k=1(A.6)because P 0kl is a measure in the index k. Thus the behavior of the first term of F (L0, L)can be controlled at infinity, and limiting the range of l by L and the range of k by K1 onlyintroduces an error smaller than 2ε1.For 1 (cid:1) k (cid:1) K1 let us define ˜l(k) such that P 0k,l (here we assume forsimplicity that the property of unique maxima holds). Then we can set the “nearly bestdecoder” (cid:25)Q∗ to be= maxl P 0k,˜l(k)(cid:1)(cid:25)Q∗kl=l = ˜l(k),1,0, otherwise.(cid:2)L12l=1 σlClearly we have supLobtain(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) supL∞(cid:7)σl∞(cid:7)12l=1k=1(cid:2)K1k=1 P 0kl Qkl = 12(A.7)(cid:2)Ll=1 σl(cid:2)K1k=1 P 0kl(cid:25)Q∗kl . Therefore, weP 0klQkl − 12(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < 2ε1.P 0kl(cid:25)Q∗klL(cid:7)K1(cid:7)σll=1k=1(A.8)Next, we turn to the second term of F (µ0, µ). Its behavior is harder to control in the kkl is not a measure with respect to the index k. However, we can stillml using the following construction. We note that ∀l,l=1 σli,l , . . . is contained between 0 and 1. Therefore,direction because Q0(cid:2)Lapproach supL1 (cid:1) l (cid:1) L, the sequence Q0k=1 PklQ01,l, Q2,l, . . . , Q0(cid:2)∞12N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4237− supk Q0kl| < ε1. Now we define the “nearly best(A.9)(cid:2)Ll=1 σl supk Q0kl . Therefore, if we set K2 == 12we can find such ˜k(l) < ∞ that |Q0encoder” as follows:˜k(l),l(cid:1)(cid:25)P∗kl=k = ˜k(l),1,0, otherwise.(cid:2)∞(cid:2)LWe have: supµmaxi( ˜k(i)), we obtain∞(cid:7)L(cid:7)12l=1 σlk=1 PklQ0klPklQ0kl− 12(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < ε1.(cid:25)P ∗klQ0klL(cid:7)K2(cid:7)σll=1k=1σll=1k=1By combining this with inequality (A.5), we get12∞(cid:7)∞(cid:7)σll=1k=1PklQ0kl− 12L(cid:7)K2(cid:7)σll=1k=1(cid:25)P ∗klQ0kl(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < 2ε1.Next, let us take N = max(L, K1, K2). It is possible to show thatN(cid:7)K1(cid:7)N(cid:7)L(cid:7)l=1L(cid:7)σlσlk=1K2(cid:7)l=1k=1P 0kl(cid:25)Q∗kl− 12(cid:25)P ∗klQ0kl− 12P 0kl(cid:25)Q∗kl(cid:25)P ∗klQ0kll=1N(cid:7)σlσlk=1N(cid:7)l=1k=1(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < ε1,(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < ε1.(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) supµ12(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) supµ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)1212Finally, we set ε1 ≡ ε0/3. Combining formulas (A.8) and (A.13), we obtain inequality(A.2). Combining formulas (A.11) and (A.12) we obtain inequality (A.1). ✷Now we present a proof of Theorem 3.8 for infinite matrices.Proof. Following the algorithm for finite matrices developed in Section 3.1, let usconstruct a family of N × N languages, Lε, such that(cid:12)(cid:12)(cid:12)(cid:12)F (µ0, µε) − 1(cid:12)2N(cid:7)N(cid:7)σll=1k=1(cid:8)P 0kl(cid:25)Q∗kl+ (cid:25)P∗klQ0kl(cid:9)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < ε0.Combining this with inequalities (A.1) and (A.2) of Lemma A.1 we obtain:(cid:12)(cid:12) < 3ε0.F (µ0, µ) − F (µ0, µε)(cid:12)(cid:12)supµThus we conclude that the family of languages µε satisfies the conditions of Theorem 3.8.A generalization to the case when the language µ0 does not have the property of uniquemaxima is straightforward. ✷Appendix B. Noisy channelFrom the discussion of Section 3 it is clear that “perfect” languages, i.e., thosewhose association matrix is a permutation matrix, have communicability F (µ0, µ0) = 1.(A.10)(A.11)(A.12)(A.13)(A.14)(A.15)38N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42Therefore, the best language to communicate with a perfect language is that language itself.However, imagine that an agent needs to communicate with a perfect language user (sayµ0) across a noisy channel. What is the optimal language µ∗ for such communication?In this section we will use the same three assumption as in Section 3.1. We consideronly memoryless transmission media and therefore introduce the M × N matrix T suchthat Tij is the probability that signal j is received by the listener given that signal i wasconveyed by the speaker. We haven(cid:7)j =1Tij = 1.Now the F function can be rewritten in the following way:P 0T TQT(cid:8)P T T(Q0)T(cid:9)(cid:11).(cid:10)tr+ trF (µ0, µ) = 12(cid:9)(cid:8)Let us introduce the effective encoding and decoding matrices of language µ0:(cid:25)P 0 = P 0T T, (cid:25)Q0 = Q0T .We obtain:F (µ0, µ) = 12(cid:8)(cid:10)tr(cid:25)P 0(Q)T(cid:9)(cid:8)+ trP ( (cid:25)Q0)T(cid:9)(cid:11).(B.1)This definition is formally very similar to the definition with noiseless transmission, exceptthe matrices (cid:25)P 0 and (cid:25)Q0 are not necessarily related through a common association matrix.In the case when P 0 and Q0 are identity matrices we have(cid:25)P 0 = T T,(cid:25)Q0 = T .Given the matrix T , we would like to optimize the function F (µ0, µ) over all languages µ.Let us maximize the two terms in expression (B.1) separately. The best encoder, Q∗,is given by picking out the maximum elements in each row of the matrix (cid:25)P 0, i.e., in thematrix T T. The best decoder, P ∗, is given by picking out the maximum elements in eachcolumn of the matrix (cid:25)Q0, i.e., in the matrix T . Therefore, we haveP ∗ = (Q∗)T.(B.2)If for a language, µ∗, P = P ∗ and Q = Q∗, then F (µ0, µ∗) = supµ F (µ0, µ). In general,it is not possible to find such a language. However, under certain restrictions on the Tmatrix, we can approach the desired communicability.We will say that a matrix T is row-wise diagonally dominant, if for all 1 (cid:1) i (cid:1) M,Tii > Tij ,∀j (cid:17)= i.We can prove the followingTheorem B.1. If µ0 is a permutation language and T is diagonally dominated row-wise,then supµ F (µ0, µ) = 1/(2M) tr(P 0T T(Q∗)T + P ∗T T(Q0)T).The proof follows the same logics as the one given in Section 3.1. The key factor againis that there are no closed loops in the auxiliary matrix combining the positive entries ofP ∗ and Q∗. This is established byN. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4239Lemma B.2. If µ0 is a permutation language and the T matrix is row-wise diagonallydominant, then there can be no closed loops in the auxiliary matrix.Proof. Consider a closed loop with (α1, β1) going to (α1, β2) ultimately to (αK , βK ) andfinally back to (α1, β1). Without loss of generality, we can assume that the node (α1, β1)corresponds to a 1 in the Q∗ matrix. Immediately, it follows thatPα1β1 > Pα1β ∀β.But since P = T T, we have that∀β.Tβ1α1 > Tβα1(B.3)Now consider (α1, β2). For this node, Q∗ has a corresponding entry of 0 and therefore P ∗has a corresponding entry of 1. Since P ∗ is obtained by taking maxima of columns of Q,we haveQ0> Q0and since Q = T , we have that∀α,α1β2αβ2Tα1β2 > Tαβ2∀α.(B.4)Matrix T is row-wise diagonally dominant, and thereforeTii > Tik ∀k (cid:17)= i.Thus, from Eqs. (B.3) and (B.4) and the diagonal dominance property, we haveTβ1β1 > Tβ1α1 > Tα1α1 > Tα1β2 > Tβ2β2.Now continue from (α2, β2) and use the same logics. We get,Tβ2β2 > Tβ2α2 > Tα2α2 > Tα2β3 > Tβ3β3.This can be repeated to eventually obtainTβK−1βK−1 > TβK βK ,and finally,TβK βK > Tβ1β1.This leads to a contradiction. ✷From Lemma B.2 it follows, that if T is dominated by its diagonal, we can approachthe supµ F (µ0, µ) arbitrarily close by choosing an appropriate language µ. The proof ofTheorem B.1 is now straightforward. What is interesting is that the languages which havea high communicability with µ0 are not necessarily identity matrices. Here isExample B.3. Consider the following 3 × 3 T matrix:(cid:20)T =0.46 0.45 0.090.30.40.30.47 0.05 0.48(cid:21).40N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42For this matrix, we have(cid:21)(cid:20)∗ =P001100001,∗ =Q(cid:20)0 01 00 0(cid:21).101Then, the auxiliary matrix X combined out of positive elements of the P ∗ and Q∗ matrices,is given byX =(cid:20)011(cid:21).1 10 00 1It is symmetrical and contains no closed loops, and therefore we can construct the followingfamily of languages:Aε =(cid:20)0ε2εε200(cid:21).ε01As ε tends to zero, the language Aε tends to the best response to the perfect language µ0with the noisy channel T .Finally, we note thatif µ0 is not a permutation language and T is row-wisediagonally dominated , then supµ F (µ0, µ) (cid:1) 1/(2M) tr(P 0T T(Q∗)T + P ∗T T(Q0)T), andthe inequality can be strict, as is demonstrated byExample B.4. The language µ0 and the transition matrix, T , are given by(cid:20)µ0 ∝0.78 0.03 0.580.72 0.94 0.200.34 0.62 0.40(cid:21)(cid:20),T =0.72 0.00 0.280.28 0.43 0.290.02 0.41 0.57(cid:21).It turns out that the “best decoder” and the “best encoder” in this case are given by∗ =P(cid:20)010001(cid:21),100∗ =Q(cid:20)1 00 10 0(cid:21),001which leads to the following auxiliary matrix with a closed loop:1⇒1X =(cid:20)110(cid:21)0 11 01 111.11This suggests that finding the best encoder and the best decoder does not help us optimizethe communicability function.N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–4241References[1] C. Boutilier, Y. Shoham, M.P. Wellman, Economic principles of multi-agent systems (editorial), ArtificialIntelligence 94 (1–2) (1997) 1–6.[2] E.J. Briscoe, Language Evolution through Language Acquisition: Formal and Computational Models,Cambridge University Press, Cambridge, 2000.[3] E. Charniak, Statistical Language Learning, MIT Press, Cambridge, MA, 1993.[4] D.L. Cheney, R.M. Seyfarth, How Monkeys See the World: Inside the Mind of Another Species, Universityof Chicago Press, Chicago, IL, 1990.[5] N.A. Chomsky, Language and the Problems of Knowledge, MIT Press, Cambridge, MA, 1986.[6] D.R. Dowty, R.E. Wall, S. Peters, Introduction to Montague Semantics, Kluwer Academic, Dordrecht, 1980.[7] A.L. Gorin, S.E. Levinson, A.N. Gertner, Adaptive acquisition of spoken language, in: Proc. ICASSP’91,Toronto, ON, 1991, pp. 805–808.[8] M.D. Hauser, The Evolution of Communication, MIT Press, Cambridge, MA, 1997.[9] J. Hofbauer, K. Sigmund, Evolutionary Games and Replicator Dynamics, Cambridge University Press,Cambridge, 1998.[10] J.R. Hurford, Biological evolution of the Saussurean sign as a component of the language acquisition device,Lingua 77 (1989) 187–222.[11] C. Isbell, C. Shelton, M. Kearns, S. Singh, P. Stone, A social reinforcement learning agent, in: Proc. Agents2001, Montreal, QB, 2001, pp. 377–384.[12] S. Kirby, Syntax out of learning: The cultural evolution of structured communication in a population ofinduction algorithms, in: D. Floreano, J.-D. Nicoud, F. Mondada (Eds.), Advances in Artificial Life, 5thEuropean Conference, Lausanne, Switzerland, in: Lecture Notes in Computer Science, vol. 1674, Springer,Berlin, 1999, pp. 694–703.[13] N.L. Komarova, P. Niyogi, M.A. Nowak, Evolutionary dynamics of grammar acquisition, J. Theor.Biol. 209 (1) (2001) 43–59.[14] N.L. Komarova, M.A. Nowak, Evolutionary dynamics of the lexical matrix, Bull. Math. Biol. 63 (3) (2001)451–485.[15] J.M. Macedonia, C.S. Evans, Variation among mammalian alarm call systems and the problem of meaningin animal signals, Ethnol. 93 (1993) 177–197.[16] C. Manning, H. Schutze, Foundations of Statistical Natural Language Processing, MIT Press, Cambridge,MA, 1999.[17] J. Maynard Smith, Evolution and the Theory of Games, Cambridge University Press, Cambridge, UK, 1982.[18] J. Maynard Smith, G. Price, The logic of animal conflict, Nature 246 (1973) 15–18.[19] G.A. Miller, The Science of Words, Scientific American Library, New York, 1996.[20] M. Oliphant, The dilemma of Saussurean communication, BioSystems 37 (1–2) (1996) 31–38.[21] M. Oliphant, Formal approaches to innate and learned communication: Laying the foundations for language,PhD Thesis, Univ. of California, San Diego, CA, 1997.[22] M. Oliphant, The learning barrier: Moving from innate to learned systems of communication, AdaptiveBehavior 7 (1999) 371–384.[23] M. Oliphant, J. Batali, Learning and the emergence of coordinated communication, Center for Research onLanguage Newsletter 11 (1) (1997).[24] M.A. Nowak, An evolutionarily stable strategy may be inaccessible, J. Theor. Biol. 142 (1990) 237–241;M.A. Nowak, Stochastic strategies in the prisoners dilemma, Theor. Pop. Biol. 38 (1990) 93–112.[25] M.A. Nowak, N.L. Komarova, P. Niyogi, Evolution of universal grammar, Science 291 (2001) 114–118.[26] T. Regier, B. Corrigan, R. Cabasan, A. Woodward, M. Gasser, L. Smith, The emergence of words, in:Proceedings of the 23rd Annual Conference of the Cognitive Science Society, Edinburgh, 2001.[27] T. Regier, Emergent constraints on word-learing: A computational review, Trends in Cognitive Sciences 7(2003) 263–268.[28] F. de Saussure, in: C. Bally, A. Sechehaye (Eds.), Course in General Linguistics, Duckworth, London, 1983,Translated and annotated by Roy Harris.[29] K. Smith, The cultural evolution of communication in a population of neural networks, ConnectionSci. 14 (1) (2002) 65–84.42N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–42[30] K. Smith, The transmission of language: Models of biological and cultural evolution, PhD Thesis, Universityof Edinburgh, 2003.[31] W.J. Smith, The Behavior of Communicating, Harvard University Press, Cambridge, MA, 1977.[32] W.J. Smith, The behavior of communicating, after twenty years,in: D.H. Owings, M.D. Beecher,N.S. Thompson (Eds.), Perspectives in Ethnology, vol. 10, Plenum Press, New York, 1997, pp. 7–51.[33] L. Steels, Self-organizing vocabularies, in: C. Langston (Ed.), Proceedings of ALife V, Nara, Japan, 1996.[34] L. Steels, F. Kaplan, Spontaneous lexicon change, in: Proceedings of COLING-ACL, Montreal, QB, 1998,pp. 1243–1249.[35] L. Steels, P. Vogt, Grounding adaptive language games in robotic agents, in: P. Husbands, I. Harvey (Eds.),Proceedings of the Fourth European Conference on Artificial Life, MIT Press, Cambridge, MA, 1997.[36] J.B. Tenenbaum, F. Xu, Word learning as Bayesian inference,in: Proceedings of the 22nd AnnualConference of the Cognitive Science Society, Philadelphia, PA, 2000.[37] F. Tohme, T. Sandholm, Coalition formation processes with belief revision among bounded rational self-interested agents, J. Logic Comput. 9 (6) (1999) 793–815.[38] P.E. Trapa, M.A. Nowak, Nash equilibria for an evolutionary language game, J. Math. Biol. 41 (2000) 172–188.[39] V.N. Vapnik, Statistical Learning Theory, Wiley, New York, 1998.[40] P. Vogt, H. Coumans, Investigating social interaction strategies for bootstrapping lexicon development,J. Artificial Soc. Social Simul. 6 (1) (2003).