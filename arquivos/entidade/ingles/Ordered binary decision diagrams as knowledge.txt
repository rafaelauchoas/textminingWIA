Artificial Intelligence 136 (2002) 189–213www.elsevier.com/locate/artintOrdered binary decision diagrams asknowledge-basesTakashi Horiyama a,∗, Toshihide Ibaraki ba Graduate School of Information Science, Nara Institute of Science and Technology, Nara 630-0101, Japanb Department of Applied Mathematics and Physics, Graduate School of Informatics, Kyoto University,Kyoto 606-8501, JapanReceived 28 April 2000; received in revised form 22 November 2001AbstractWe consider the use of ordered binary decision diagrams (OBDDs) as a means of realizingknowledge-bases, and show that, from the view point of space requirement, the OBDD-basedrepresentation is more efficient and suitable in some cases, compared with the traditional CNF-based and/or model-based representations. We then present polynomial time algorithms for the twoproblems of testing whether a given OBDD represents a unate Boolean function, and of testingwhether it represents a Horn function.  2002 Published by Elsevier Science B.V.Keywords: Knowledge representation; Automated reasoning; Ordered binary decision diagrams (OBDDs);Recognition problems; Unate functions; Horn functions1. IntroductionLogical formulae are one of the traditional means of representing knowledge in artificialintelligence (AI) [24]. However, it is known that deduction from a knowledge-base thatconsists of a set of propositional clauses is co-NP-complete and abduction is (cid:2)p2 -com-plete [12]. Recently, an alternative way of representing knowledge, i.e., by a subset of itsmodels, which are called characteristic models, has been proposed (see, e.g., [17,18,20,21]). By restricting a knowledge-base to be Horn, deduction in this model-based approachcan be performed in linear time, and abduction is also performed in polynomial time [17].* Corresponding author.E-mail addresses: horiyama@is.aist-nara.ac.jp (T. Horiyama), ibaraki@i.kyoto-u.ac.jp (T. Ibaraki).0004-3702/02/$ – see front matter  2002 Published by Elsevier Science B.V.PII: S 0 0 0 4 - 3 7 0 2 ( 0 2 ) 0 0 1 1 9 - 4190T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213In addition to these favorable properties on the computational complexity, this approachhas good evaluation in the practical sense [18,19].In this paper, we propose yet another knowledge representation, i.e., the use of orderedbinary decision diagrams (OBDDs) [1,4,25]. An OBDD is a directed acyclic graphrepresenting a Boolean function, and can be considered as a variant of a decision tree. Byrestricting the order of variable appearances and by sharing isomorphic subgraphs, OBDDshave the following useful properties:(1) When an ordering of variables is specified, an OBDD has the unique reduced canonicalform for each Boolean function.(2) Many Boolean functions appearing in practice can be compactly represented.(3) When an OBDD is given, satisfiability and tautology of the represented function canbe easily checked in constant time.(4) There are efficient algorithms for many other Boolean operations on OBDDs.As a result of these properties, OBDDs are widely used for various practical applications,especially in computer-aided design and verification of digital systems (see, e.g., [6,7,27]).One of the notable advantages of OBDDs is that, in the practical sense, minimizationof DNFs (and also CNFs) can be done considerably faster than other approaches [8].These observations encourage the use of OBDDs as knowledge-bases. The manipulation ofknowledge-bases by OBDDs (e.g., deduction and abduction) was first discussed by Madreand Coudert [23].We first compare the above three representations, i.e., formula-based, model-based,and OBDD-based, on the basis of their sizes. This will give a foundation for analyzingand comparing time and space complexities of various operations. Comparisons betweenthese representations have been attempted in different communities. In AI community, itwas shown that formula-based and model-based representations are incomparable withrespect to space requirement [17]. Namely, each of them sometimes allows exponentiallysmaller sizes than the other, depending on the functions. In theoretical computer scienceand VLSI design communities, it was pointed out that formula-based and OBDD-basedrepresentations are also incomparable [14]. However, the three representations have neverbeen compared on the same ground. We show in this paper that, in some cases, an OBDD-based representation requires exponentially smaller space than the other two, while thereare also cases in which each of the other two requires exponentially smaller space than thatof an OBDD. Thus, OBDDs can find their place in knowledge-bases. We also point out anunfortunate result that there exists a Horn function which requires an exponential size forany of the three representations.OBDDs are known to be efficient for such knowledge-base operations as deductionand abduction [23]. Given two OBDDs as a knowledge-base and a deductive query, itcan be decided in polynomial time whether the query is a consequence of the knowledge,where the knowledge can be a general Boolean function [23]. As for abduction, we havea polynomial time algorithm for Horn knowledge-bases by introducing some constraintson its assumption set, while it remains NP-complete for the general case [15]. Byrestricting a knowledge-base to be Horn, OBDDs can be translated into their CNFs and intotheir characteristic models, respectively, in polynomial time (more specifically in outputT. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213191polynomial time), and vice versa [16]. Since a negative function is Horn, the techniquecan be applied to a unate OBDD after changing the polarities of some variables so that allvariables become negative.We investigate in this paper two fundamental recognition problems of OBDDs, thatis, testing whether a given OBDD represents a unate Boolean function, and testingwhether it represents a Horn function. We show that these recognition problems can besolved in polynomial time for both the unate and Horn cases. We often encounter theseproblems, since a knowledge-base representing some real-world phenomenon is sometimesrequired to be unate or Horn, from the hypothesis posed on the phenomenon and/orfrom the investigation of the mechanism causing the phenomenon. For example, if theknowledge-base represents a data set of test results with various physical measurements(e.g., body temperature, blood pressure, number of pulses and so on), it is often the casethat the diagnosis of a certain disease is monotonically depending on each test result.The dependency may have the unate property (i.e., some of the tests may have negativepolarity). Also in AI, it is common to assume Horn knowledge-bases as they can beprocessed efficiently in many respects (for example, deduction from a set of Horn clausescan be done in linear time [10]). These recognition problems also play a fundamental rolein the area of learning and identifying meaningful structures in empirical data [9,13,29].We emphasize here that OBDD-based approach is suitable for various tasks of structureidentification discussed in [9]; e.g., finding effective representations [4,12,29], devisingdecompositions of database schema [22,30], synthesizing simple Boolean expressions [3,11], and casting logical theories that render subsequent processing tractable [15,26].The rest of this paper is organized as follows. The next section gives fundamentaldefinitions and concepts. We compare the three representations in Section 3, and considerthe problems of recognizing unate and Horn OBDDs in Sections 4 and 5, respectively.2. Preliminaries2.1. Notations and fundamental conceptsWe consider a Boolean function f : {0, 1}n → {0, 1}. An assignment is a vector a ∈{0, 1}n, whose ith coordinate is denoted by ai . A model of f is a satisfying assignment a off , i.e., f (a) = 1, and the theory Σ(f ) representing f is the set of all models of f . Givena, b ∈ {0, 1}n, we denote by a (cid:1) b the usual bitwise (i.e., componentwise) ordering ofassignments; ai (cid:1) bi for all i = 1, 2, . . . , n, where 0 < 1. Given a subset E ⊆ {1, 2, . . . , n},i equals 1 if i ∈ E and 0χ E denotes the characteristic vector of E; the ith coordinate χ Eif i /∈ E.Let x1, x2, . . . , xn be the n variables of f , where each xi corresponds to the ithcoordinate of assignments and evaluates to either 0 or 1. Negation of a variable xi isdenoted by ¯xi . Variables and their negations are called literals. A clause is a disjunctionof some literals, and a conjunction of clauses is called a conjunctive normal form (CNF).We say that f is represented by a CNF ϕ, if f (a) = ϕ(a) holds for all a ∈ {0, 1}n. AnyBoolean function can be represented by some CNF, which may not be unique.192T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213We sometimes do not make a distinction among a function f , its theory Σ(f ), and aCNF ϕ that represents f , unless confusion arises. We define a restriction of f by replacinga variable xi by a constant ai ∈ {0, 1}, and denote it by f |xi =ai . Namely,f |xi =ai (x1, . . . , xn) = f (x1, . . . , xi−1, ai, xi+1, . . . , xn)holds. Restriction may be applied to many variables. We also define f (cid:1) g (respectively,f < g) by Σ(f ) ⊆ Σ(g) (respectively, Σ(f ) ⊂ Σ(g)).Lemma 2.1. Relation (cid:1) has the following properties:(1) f (cid:1) g holds if and only if f |xi =ai(2) f ∨ g (cid:1) h holds if and only if f (cid:1) h and g (cid:1) h hold.(cid:1) g|xi =ai holds for both ai = 0 and 1.For an assignment p ∈ {0, 1}n, we define a (cid:1)p b if (a ⊕bit p) (cid:1) (b ⊕bit p) holds, where⊕bit denotes the bitwise (i.e., componentwise) exclusive-or operation. A Boolean functionf is unate with polarity p if f (a) (cid:1) f (b) holds for all assignments a and b such thata (cid:1)p b. A theory Σ is unate if Σ represents a unate function. A clause is unate with po-larity p if pi = 0 for all positive literals xi and pi = 1 for all negative literals ¯xi in theclause. A CNF is unate with polarity p if it contains only unate clauses with polarity p. Itis known that a theory Σ is unate if and only if Σ can be represented by some unate CNF.A unate function is positive (respectively, negative) if its polarity is (00 · · · 0) (respectively,(11 · · · 1)).A theory Σ is Horn if Σ is closed under operation ∧bit, where a ∧bit b is bitwise ANDof two models a, b ∈ {0, 1}n. For example, if a = (0011) and b = (0101), then a ∧bit b =(0001). The closure of a theory Σ with respect to ∧bit, denoted by Cl∧bit (Σ), is defined asthe smallest set that contains Σ and is closed under ∧bit. We also use the operation ∧bit as aset operation; Σ(f ) ∧bit Σ(g) = {a | a = b ∧bit c holds for some b ∈ Σ(f ) and c ∈ Σ(g)}.We often denote Σ(f ) ∧bit Σ(g) by f ∧bit g, for convenience. Note that the two functionsf ∧ g and f ∧bit g are different.A Boolean function f is Horn if Σ(f ) is Horn; equivalently if f ∧bit f = f holds (assets of models). A clause is Horn if the number of positive literals in it is at most one,and a CNF is Horn if it contains only Horn clauses. It is known that a theory Σ is Horn ifand only if Σ can be represented by some Horn CNF. By definition, a negative function isHorn, but not conversely.For any Horn theory Σ, a model a ∈ Σ is called characteristic if it cannot be producedby bitwise AND of other models in Σ; a /∈ Cl∧bit (Σ − {a}). The set of all characteristicmodels of a Horn theory Σ, which we call the characteristic set of Σ, is denoted byChar(Σ). Note that every Horn theory Σ has a unique characteristic set Char(Σ), whichsatisfies Cl∧bit (Char(Σ)) = Σ. The set of minimal models of f with respect to p ∈ {0, 1}nis defined asminp(f ) =(cid:1)a ∈ Σ(f ) | there exists no b ∈ Σ(f ) satisfying b <p a(cid:2),where b <p a denotes that b (cid:1)p a and b (cid:17)= a hold. The following lemma gives an upperbound on the size (i.e., cardinality) of the characteristic set.T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213193Lemma 2.2 [21]. Let f be a Horn function on n variables. Then, the characteristic set of|minp(f )|, where Bn = {χ En,i | i = 0, 1, . . . , n} and χ En,i is thef has size at mostcharacteristic vector of the set En,i ⊆ {0, 1, . . . , n} given byp∈Bn(cid:3)(cid:4)En,0 = {1, 2, . . . , n}En,i = En,0 − {i}for i = 0 (i.e., χ En,0 = (11 · · · 1)),for i = 1, 2, . . . , n.2.2. Ordered binary decision diagramsAn ordered binary decision diagram (OBDD) is a directed acyclic graph that representsa Boolean function. It has two sink nodes 0 and 1, called the 0-node and the 1-node,respectively (which are together called the constant nodes). Other nodes are called variablenodes, and each variable node v is labeled by one of the variables x1, x2, . . . , xn. Letvar(v) denote the label of node v. Each variable node has exactly two outgoing edges,called a 0-edge and a 1-edge, respectively. One of the variable nodes becomes the uniquesource node, which is called the root node. Let X = {x1, x2, . . . , xn} denote the set of nvariables. A variable ordering is a total ordering (xπ(1), xπ(2), . . . , xπ(n)), associated witheach OBDD, where π is a permutation {1, 2, . . . , n} → {1, 2, . . . , n}. The level1 of a nodev, denoted by level(v), is defined by its label; if node v has label xπ(i), level(v) is definedto be n − i + 1. That is, the root node is in level n and has label xπ(1), the nodes in leveln − 1 have label xπ(2) and so on. The level of the constant nodes is defined to be 0. Onevery path from the root node to a constant node in an OBDD, each variable appears atmost once in the decreasing order of their levels.Every node v of an OBDD also represents a Boolean function fv, defined by thesubgraph consisting of those edges and nodes reachable from v. If node v is a constantnode, fv equals to its label. If node v is a variable node, fv is defined as var(v)f0-succ(v) ∨var(v)f1-succ(v) by Shannon’s expansion, where 0-succ(v) and 1-succ(v), respectively,denote the nodes pointed by the 0-edge and the 1-edge of node v. The function frepresented by an OBDD is the one represented by the root node. Fig. 1 illustrates threeOBDDs representing x3x2 ∨ x1 with a variable ordering (x3, x2, x1). Given an assignmenta, the value of f (a) is determined by following the corresponding path from the root nodeto a constant node in the following manner: at a variable node v, one of the outgoing edgesis selected according to the assignment avar(v) to the variable var(v). The value of thefunction is the label of the final constant node.When two nodes u and v in an OBDD represent the same function, and their levelsare the same, they are called equivalent. A node whose 0-edge and 1-edge both pointto the same node is called redundant. An OBDD is called dense if every variable nodev satisfy level(0-succ(v)) = level(1-succ(v)) = level(v) − 1 (i.e., all paths from the rootnode to constant nodes visit n + 1 nodes). A dense OBDD which has no equivalent nodesis quasi-reduced. An OBDD which has no mutually equivalent nodes and no redundantnodes is reduced. The OBDDs (a), (b) and (c) in Fig. 1 are dense, quasi-reduced andreduced, respectively. A reduced OBDD is obtained from a quasi-reduced OBDD bydeleting redundant nodes v and changing their incoming edges e = (u, v) to (u, 0-succ(v)).1 This definition of level may be different from its common use.194T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213Fig. 1. OBDDs representing x3x2 ∨ x1.In the following, we assume that all OBDDs are reduced, unless otherwise stated. The sizeof an OBDD is the number of nodes in the OBDD. Given a function f and a variableordering, its reduced OBDD is unique and has the minimum size among all OBDDs withthe same variable ordering. The minimum sizes of OBDDs representing a given Booleanfunction depends on the variable orderings [4].Given an OBDD that represents f , the OBDDs of f |xi =0 and f |xi =1 can be obtained inO(|f |) time, where |f | denotes the size of the OBDD of f [2]. The size does not increaseby a restriction. Given two OBDDs representing f and g, applying fundamental logicoperators, e.g., f ∧ g, f ∨ g, f ⊕ g and f → g, can be performed in O(|f | · |g|) time, andproperty f (cid:1) g can be also checked in O(|f | · |g|) time [4].A partition for f is a pair of sets (L, R) satisfying L, R ⊆ X = {x1, x2, . . . , xn},L ∪ R = X and L ∩ R = ∅. L is called a left partition and R is called a right partition. Letl denote an assignment to the variables in L, and r denote an assignment to the variables inR. Then, l · r denotes the complete assignment obtained by combining l and r. Let X(cid:21) bea subset of X, and ω be a positive number satisfying 0 < ω < 1. Then, a partition (L, R)is called ω-balanced for X(cid:21), if it satisfies (cid:22)ω|X(cid:21)|(cid:23) (cid:1) |X(cid:21) ∩ L| (cid:1) (cid:24)ω|X(cid:21)|(cid:25). Given a partition(L, R), a set A of assignments li for L and r i for R, i = 1, 2, . . . , h, is called a fooling setif it satisfies(1) f (li · r i ) = a for all i,(2) f (li · r j ) (cid:17)= a or f (lj · r i ) (cid:17)= a for all i (cid:17)= j ,for some a ∈ {0, 1}. The next lemma tells that the size h of a fooling set gives a lowerbound on the size of an OBDD that represents f .Lemma 2.3 [5]2. Let f be a Boolean function on n variables, X(cid:21) be some subset of thevariables and ω be some positive number satisfying 0 < ω < 1. If f has a fooling set of sizeat least h for every ω-balanced partition (L, R) for X(cid:21), then the size of OBDD representingf is at least h for any variable ordering.2 Although the original lemma (Lemma 2 in [5]) states the case when h is at least cn for some constant c > 1,its proof can be applied to any h in a straightforward manner.T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–2131953. Three approaches for knowledge-base representationIn this section, we compare three knowledge-base representations: CNF-based, model-based, and OBDD-based. It is known that CNF-based and model-based representationsplay orthogonal roles with respect to space requirement. Namely, each of them sometimesallows exponentially smaller sizes than the other, depending on the functions. We showthat OBDD-based representation is incomparable to the other two in the same sense.We start with relations between OBDD and CNF representations.Lemma 3.1. There exists a negative theory on n variables, for which OBDD and CNF bothrequire size O(n), while its characteristic set requires size $(2n/2).Proof. Consider a functionm(cid:5)fA =( ¯x2i−1 ∨ ¯x2i),i=1where n = 2m. The size of this CNF is obviously O(n). The characteristic set is givenby {a ∈ {0, 1}2m| exactly one of a2i−1 or a2i is 0 for all i = 1, 2, . . . , m}, whose size is$(2n/2) [17]. The OBDD representing fA is illustrated in Fig. 2, with a variable ordering(xn, xn−1, . . . , x1). The size of this OBDD is O(n). ✷Lemma 3.2. There exists a negative theory on n variables, for which OBDD requires sizeO(n) and the characteristic set requires size O(n2), while CNF requires size $(2n/2).Fig. 2. OBDD representing fA =(cid:6)mi=1( ¯x2i−1 ∨ ¯x2i ).196T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213Fig. 3. OBDD representing fB =(cid:7)mi=1( ¯x2i−1 ∧ ¯x2i ).Proof. Consider a functionm(cid:8)fB =( ¯x2i−1 ∧ ¯x2i) =(cid:5)(r 1 ∨ r2 ∨ · · · ∨ r m),i=1(r1,r2,...,rm)∈SBwhere n = 2m and SB = {(r1, r2, . . . , rm) | ri ∈ {x2i−1, x2i} for all i = 1, 2, . . . , m}. fB isdual to fA. The smallest CNF representation of fB , which is given above, has $(2n/2)clauses. The characteristic set is {χ {1,2,...,2m}−S ∈ {0, 1}2m | S = {2i − 1, 2i} or S ={2i − 1, 2i, j } for i ∈ {1, 2, . . . , m} and j ((cid:17)= 2i − 1, 2i) ∈ {1, 2, . . . , 2m}}, whose size isO(n2) [17]. The OBDD representing fB is illustrated in Fig. 3, with a variable ordering(xn, xn−1, . . . , x1). Note that, as fB is dual to fA, this OBDD is obtained by negating inputvariables (i.e., exchanging the roles of 0-edges and 1-edges) and negating output (i.e.,exchanging the roles of the 0-node and the 1-node) of the OBDD in Fig. 2. The size of thisOBDD is O(n). ✷By combining Lemmas 3.1 and 3.2, we show that, for some theory, OBDD can beexponentially smaller than its characteristic set and CNF representations.Theorem 3.1. There exists a negative theory on n variables, for which OBDD requires sizeO(n), while both of the characteristic set and CNF require sizes $(2n/4).Proof. Consider a function(cid:9)(cid:10)(cid:9)fC =( ¯x2i−1 ∨ ¯x2i)∧m(cid:5)i=1(cid:10)( ¯x2i−1 ∧ ¯x2i),2m(cid:8)i=m+1T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213197Fig. 4. OBDD representing fC = ((cid:6)mi=1( ¯x2i−1 ∨ ¯x2i )) ∧ ((cid:7)2mi=m+1( ¯x2i−1 ∧ ¯x2i )).where n = 4m. As shown in Lemma 3.1, the characteristic set requires size $(2n/4) torepresent the first half. Also by Lemma 3.2, CNF representation always requires size$(2n/4) to represent the second half. Note the first and second halves are independent sincethe variables in the first half do not appear in the second half and vice versa. Therefore, theabove lower bounds of the characteristic set and CNF are valid also for fC . An OBDD thatrepresents fC is illustrated in Fig. 4, with a variable ordering (xn, xn−1, . . . , x1). The sizeof this OBDD is O(n). ✷We now turn to the opposite direction, i.e., CNF and the characteristic set can beexponentially smaller than the size of OBDD.Lemma 3.3. The size of the characteristic set is O(n) for the following Horn function on nvariables xi,j , 1 (cid:1) i, j (cid:1) m + 1, where n = (m + 1)2:fD =(cid:9)m+1(cid:5)i=1(cid:9)xi,m+1 ∨(cid:10)(cid:10)(cid:9)¯xi,j∧m(cid:8)j =1m+1(cid:5)j =1(cid:9)xm+1,j ∨(cid:10)(cid:10)¯xi,j.m(cid:8)i=1198T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213Proof. Consider {χ En,0 } ∪ {χ En,i,j | 1 (cid:1) i, j (cid:1) m + 1} as the set Bn defined in Lemma 2.2,for convenience, where En,0 = {(i, j ) | 1 (cid:1) i, j (cid:1) m+1} and En,i,j is the set En,0 −{(i, j )}corresponding to variable xi,j . fD(χ En,0 ) = 1 holds for the characteristic vector χ En,0 .Thus, |minχ En,0 (fD)| = 1. Similarly, |minχ En,i,j (fD)| = 1 holds for i = 1, 2, . . . , m andj = 1, 2, . . . , m, since fD(χ En,i,j ) = 1.Next, since fD(χ En,i,m+1 ) = 0 is implied by(cid:10)(cid:9)m(cid:8)xi,m+1 ∨¯xi,j(cid:11)χ En,i,m+1(cid:12)= 0j =1(cid:7)for i = 1, 2, . . . , m, we enumerate all minimal models for each χ En,i,m+1 . By definition, weobtain χ En,0 by flipping the (i, m + 1)th coordinate of χ En,i,m+1 . This χ En,0 is a minimalmodel for χ En,i,m+1 since fD(χ En,0 ) = 1. When the (i, m + 1)th coordinate is fixed to0, the clause (xi,m+1 ∨¯xi,j ) is satisfied by flipping at least one of the (i, j )thcoordinates among j = 1, 2, . . . , m. However, if two or more (i, j )th coordinates areflipped, the corresponding vector is not minimal. Thus, we have |minχ En,i,m+1 (fD)| = m+1for i = 1, 2, . . . , m. Similarly, we have |minχ En,m+1,j (fD)| = m + 1 for j = 1, 2, . . . , m.mj =1We also enumerate all minimal models for χ En,m+1,m+1 since fD(χ En,m+1,m+1 ) = 0. Weobtain χ En,0 by flipping the (m + 1, m + 1)th coordinate. When the (m + 1, m + 1)thcoordinate is fixed to 0, minimal models are obtained by flipping exactly one of the(i, m + 1)th coordinates among i = 1, 2, . . . , m and exactly one of the (m + 1, j )thcoordinates among j = 1, 2, . . . , m. Thus, we have |minχ En,m+1,m+1 (fD)| = m2 +1. In total,|mina(fD)| = O(m2), i.e., O(n). By Lemma 2.2, this means that the sizewe haveof the characteristic set of fD is O(n). ✷a∈Bn(cid:3)Lemma 3.4 [28]. Let f be a Boolean function on n variables xi,j , 1 (cid:1) i, j (cid:1) m, wheren = m2. Then, for any partition (L, R) satisfying |L| = |R| = n/2, either of the followingproperties holds:(1) There are at least m/2 different i’s satisfying {xi,1, xi,2, . . . , xi,m} ∩ L (cid:17)= ∅ and(2) There are at least m/2 different j ’s satisfying {x1,j , x2,j , . . . , xm,j } ∩ L (cid:17)= ∅ and√{xi,1, xi,2, . . . , xi,m} ∩ R (cid:17)= ∅.√{x1,j , x2,j , . . . , xm,j } ∩ R (cid:17)= ∅.Lemma 3.5. The size of OBDD representing the following negative function fE on nvariables xi,j , 1 (cid:1) i, j (cid:1) m, where n = m2, is $(2m/(cid:10)(cid:10)2) for any variable ordering:(cid:10)(cid:10)(cid:9)(cid:9)(cid:9)(cid:9)√m(cid:5)m(cid:8)m(cid:5)m(cid:8)fE =¯xi,j∧¯xi,j.i=1j =1j =1i=1Proof. We prove this by Lemma 2.3 in Section 2.2. Let us consider that the set X(cid:21) inLemma 2.3 is given by the set of all variables, and ω = 1/2. Then, for every balancedpartition (L, R), assuming case (1) of Lemma 3.4 without loss of generality, we have at2 different i’s satisfying {xi,1, xi,2, . . . , xi,m} ∩ L (cid:17)= ∅ and {xi,1, xi,2, . . . , xi,m} ∩least m/√T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213199√R (cid:17)= ∅. We select m/two variables xik,lkassignment satisfies the following restrictions:∈ L and xik,rk2 of these i’s, I = {i1, i2, . . . , im/}. For every ik ∈ I , we can select∈ R. We construct a set A of assignments such that each√2(1) For every ik ∈ I , (xik ,lk , xik ,rk ) is assigned either (0, 1) or (1, 0).(2) For every ik ∈ I , all variables in {xik,1, xik,2, . . . , xik,m} − {xik,lk , xik,rk(3) Other variables are assigned 0.} are assigned 1.√The size of the set A is 2m/the assignment satisfying h =for each ik ∈ I . h satisfies 0 (cid:1) h < 2m/√22.2 since there are choices in restriction (1). Let lh · r h denote(cid:3)= ¯ak)k=1 ak · 2k−1, where xik,lk= ak ∈ {0, 1} (and xik ,rkm/√(cid:7)(cid:7)mi=1Next, we show that fE(lh · r h(cid:21)mfE(lh · r h) = 1 for all h. Since one of xik,lk and xik,rk is assigned 0,j =1for all ik ∈ I . For ik /∈ I , since xi,1, xi,2, . . . , xi,m are assigned 0, we haveAlsoNow, we prove that set A is a fooling set, defined just before Lemma 2.3. First, we show¯xik,j = 1 holds(cid:7)¯xi,j = 1.¯xi,j = 1 holds for all j ∈ {1, 2, . . ., m}. Thus, we have fE(lh · r h) = 1 for all h.) = 0 holds for h > h(cid:21). Since h > h(cid:21), there exists at least. By restriction (1), xik,rk. Therefore, xik,lk and xik,rk are assigned 1 by¯xik,j = 0 holds. This proves that A is a fooling set.2 for any balanced partition, this lemmaone variable xik,lk which is assigned 1 by lh · r h and 0 by lh(cid:21) · r h(cid:21)is then assigned 0 by lh · r h and 1 by lh(cid:21) · r h(cid:21)assignment lh · r h(cid:21)Since the size of this fooling set is at least 2m/follows from Lemma 2.3. ✷, implying thatmj =1mj =1(cid:7)√Theorem 3.2. There exists a Horn theory on n variables, for which both of the CNF and thecharacteristic set require sizes O(n), while the size of the smallest OBDD representationis $(22).n/√√Proof. Consider the function fD in Lemma 3.3. As stated in Lemma 3.3, the size ofits characteristic set is O(n). Also the size of the CNF is obviously O(n). The functionfE in Lemma 3.5 is obtained by restricting x1,m+1, . . . , xm,m+1, xm+1,1, . . . , xm+1,m andxm+1,m+1 of fD to 0. Since the size of OBDD does not increase by a restriction, the size2). ✷of the smallest OBDD of fD is $(2n/√√The above results show that none of the three representations always dominate the othertwo. Therefore, OBDDs can find a place in knowledge-bases as they can represent sometheories more efficiently than others.Unfortunately, by combining Theorems 3.1 and 3.2, we can construct the followingfunction, which is exponential for all representations.Corollary 3.1. There exists a Horn function on n variables, for which both of thecharacteristic set and CNF require sizes $(2n/8) and the size of the smallest OBDDrepresentation is $(2n/2).√Proof. Consider the conjunction fC ∧ fD, where fC (respectively, fD ) was defined in theproof of Theorem 3.1 (respectively, Theorem 3.2). Note that fC and fD both have n/2200T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213variables, but share none of the variables. Then, similarly to the case of Theorem 3.1, thestated lower bounds for the three representations are easily obtained. ✷4. Checking unateness of OBDDsIn this section, we discuss the problem of checking whether a given OBDD represents aunate function. We assume, without loss of generality, that the variable ordering is always(xn, xn−1, . . . , x1). The following well-known property indicates that this problem can besolved in polynomial time.Property 4.1. Let f be a Boolean function on n variables x1, x2, . . . , xn. Then, f is unatewith polarity p = (p1, p2, . . . , pn) if and only if f |xi=0 (cid:1) f |xi=1 for pi = 0 (respectively,f |xi=0 (cid:2) f |xi =1 for pi = 1) holds for every i = 1, 2, . . . , n.As noted in Section 2.2, an OBDD representing f |xi =0 (respectively, f |xi =1) can beobtained in O(|f |) time from the OBDD representing f , where |f | denotes its size. Thesize does not increase by a restriction f |xi=0 or f |xi=1. Since the property g (cid:1) h canbe checked in O(|g| · |h|) time, the unateness of f can be checked in O(n|f |2) time bychecking the conditions f |xi =0 (cid:1) f |xi =1 and f |xi=0 (cid:2) f |xi =1 for all i = 1, 2, . . . , n.The following well-known property is useful to reduce the computation time.Property 4.2. Let f be a Boolean function on n variables x1, x2, . . . , xn. Then, f is unatewith polarity p = (p1, p2, . . . , pn) if and only if (i) both f |xn=0 and f |xn=1 are unate withsame polarity (p1, p2, . . . , pn−1), and (ii) pn = 0 implies f |xn=0 (cid:1) f |xn=1 and pn = 1implies f |xn=0 (cid:2) f |xn=1.The unateness of functions f |xn=0 and f |xn=1 can be checked by applying Property 4.2recursively, but we also have to check an additional condition that f |xn=0 and f |xn=1 havethe same polarity. Our algorithm is similar to the implementation of OBDD-manipulation-systems by Bryant [4], in the sense that we cache all intermediate computational resultsto avoid duplicate computation. In Bryant’s idea, different computational results may bestored to the same memory in order to handle different operations, and hence the samecomputation may be repeated more than once. However, as our algorithm only aims atchecking the unateness, it can avoid such cache conflict by explicitly preparing memoryfor each result. This is a key to reduce the computation time.We check the unateness of f in the bottom-up manner by checking unateness ofall nodes corresponding to intermediate results. Note that the property f |xn=0 (cid:1) f |xn=1(respectively, f |xn=0 (cid:2) f |xn=1) can be also checked in the bottom-up manner, since g (cid:1) hholds if and only if g|xi =0 (cid:1) h|xi =0 and g|xi =1 (cid:1) h|xi =1 hold for some i.Algorithm CHECK-UNATE in Fig. 5 checks the unateness and the polarity of a givenOBDD in the manner as described above. We use an array p[+] to denote the polarityof f with respect to x+ in level +; each element stores 0, 1 or ∗ (not checked yet). Wealso use a two-dimensional array imp[u, v] to denote whether fu (cid:1) fv holds or not; eachelement stores YES, NO or ∗ (not checked yet). In Step 2, the unateness with the polarityT. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213201Algorithm CHECK-UNATEInput: An OBDD representing f with a variable ordering (xn, xn−1 . . . , x1).Output: “yes” and its polarity if f is unate; otherwise, “no”.Step 1 (initialize). Set p[i] := ∗ for all i = 1, 2, . . . , n;(cid:13)imp[u, v] :=if (fu, fv) = (1, 0);NOYES if (fu, fv) = (0, 0), (0, 1), (1, 1);∗otherwise;+ := 1.Step 2 (check unateness in level + and compute p[+]). For each node v in level +(i.e., labeled with x+), apply Steps 2-1 and 2-2.Step 2-1. Set pol := 0 if imp[0-succ(v), 1-succ(v)] = YES holds; set pol := 1 ifimp[1-succ(v), 0-succ(v)] = YES holds; otherwise, output “no” and halt.Step 2-2. If p[+] = ∗, then set p[+] := pol. If p[+] (cid:17)= ∗ and p[+] (cid:17)= pol hold,then output “no” and halt.Step 3 (compute imp in level +). For each pair of nodes (u, v) (where (u, v) is anordered pair) such that level(u) (cid:1) + and level(v) (cid:1) +, and at least one of level(u)and level(v) is equal to +, set imp[u, v] := YES if both imp[0-sussimp[1-sussStep 4 (iterate). If + = n, where n is the level of the root node, then output “yes” andpolarity p = (p[1], p[2], . . . , p[n]), and halt. Otherwise set + := + + 1 and return to Step 2.(cid:21)(v)] are YES; otherwise, set imp[u, v] := NO.(cid:21)(u), 0-succ(cid:21)(u), 1-succ(cid:21)(v)] andFig. 5. Algorithm CHECK-UNATE to check the unateness of an OBDD.specified by p[+] is checked for the nodes in level +. More precisely, the unateness forthem is checked in Step 2-1, and the consistency of their polarities is checked in Step 2-2.In Step 3, imp[u, v] is computed for the functions fu and fv in levels up to +.The unateness check of fv in Step 2-1 can be easily done, since both f0-succ(v) (i.e.,fv|x+=0) and f1-succ(v) (i.e., fv|x+=1) have already been checked to be unate with thesame polarity, and both imp[0-succ(v), 1-succ(v)] and imp[1-succ(v), 0-succ(v)] havebeen computed in the previous iteration. Note that constant functions 0 and 1 are consideredto be unate. The polarity of fv with respect to x+ in level + is temporarily stored in pol inthis step.In Step 2-2, the polarity consistency of x+ is checked by comparing the polarity of nodev (which is pol) and p[+]. If p[+] = ∗ (i.e., v is the first node checked in level +), westore pol in p[+]. Otherwise, pol is checked against p[+] and “no” is output if they are notconsistent. Note that CHECK-UNATE outputs p[+] = ∗ if there are no nodes in level +(i.e., f does not depend on x+).In Step 3, comparison between fu and fv is also performed easily, since the comparisonsbetween fu|x+=a+ and fv|x+=a+ for both a+ = 0 and 1 have already been completed.Here we use the convention that 0-succ(cid:21)(v) (respectively, 1-succ(cid:21)(v)) denotes 0-succ(v)(respectively, 1-succ(v)) if level(v) = +, but denotes v itself if level(v) < +. This is becausefv|x+=0 = f0-succ(v) and fv|x+=1 = f1-succ(v) hold if level(v) = +, and fv|x+=0 = fv|x+=1 =fv holds if level(v) < +. Note that fu = fv holds if and only if u and v are the same node.After Step 3 is done for some +, we know imp[u, v] for all pairs of nodes u and v such that202T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213Fig. 6. OBDD representing fF = x1x2 ∨ x2 ¯x3 ∨ ¯x3x1.level(u) (cid:1) + and level(v) (cid:1) +. We store all the results, although some of them may not beneeded.Example 4.1. Consider the OBDD of fF = x1x2 ∨ x2 ¯x3 ∨ ¯x3x1 with variable ordering(x3, x2, x1). As shown in Fig. 6, the OBDD has 6 nodes v1, v2, . . . , v6, which respectivelyrepresent the following functions:fv1fv2fv3fv4fv5fv6= 0,= 1,= x1,= x1x2,= x1 ∨ x2,= x1x2 ∨ x2 ¯x3 ∨ ¯x3x1.Algorithm CHECK-UNATE starts from the initializing step. Here we havep[i] := ∗ for all i = 1, 2, . . . , nimp[v1, v1] = imp[v1, v2] = imp[v2, v2] = YES,imp[v2, v1] = NO and + = 1.In the rest of this example, we pay attention to imp[ ]’s which are evaluated to be YES. InStep 2 of the first iteration, we have p[1] = 0 because v3 is the unique node in level + = 1and imp[0-succ(v3), 1-succ(v3)] = imp[v1, v2] = YES holds. In Step 3 of the first iteration,we haveimp[v1, v3] = imp[v3, v3] = imp[v3, v2] = YES,which can be confirmed by the implication from 0 (cid:1) x1 (cid:1) x1 (cid:1) 1. In the computa-tion of imp[v1, v3], 0-succ(cid:21)(v1) and 1-succ(cid:21)(v1) are interpreted as node v1 itself, while0-succ(cid:21)(v3) and 1-succ(cid:21)(v3) are interpreted as 0-succ(v3) (i.e., v1) and 1-succ(v3) (i.e.,v2), respectively. In the second iteration (level + = 2), we have p[2] = 0 becauseT. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213203imp[0-succ(v4), 1-succ(v4)] = imp[v1, v3] = YES and imp[0-succ(v5), 1-succ(v5)] =imp[v3, v2] = YES. We also haveimp[v1, v4] = imp[v1, v5] = imp[v3, v5] = imp[v4, v2] = imp[v4, v3]= imp[v4, v4] = imp[v4, v5] = imp[v5, v2] = imp[v5, v5] = YES.In the third iteration (level + = 3), we have p[3] = 1 because imp[1-succ(v6), 0-succ(v6)] =imp[v4, v5] = YES. Then, Algorithm CHECK-UNATE outputs the answer “yes” and thepolarity p = (0, 0, 1) of fF .Now, we consider the computation time of this algorithm. In Step 2, the computation foreach node v is performed in constant time from the data already computed in the previousStep 3. Thus, the total time of Step 2 is O(|f |). In Step 3, the comparison between fu andfv for each pair (u, v) is also performed in constant time. The number of pairs compared in|f |2 )) = O(|f |2), which requires O(|f |2) time.Step 3 during the entire computation is O((The time for the rest of the computation is minor.Theorem 4.1. Given an OBDD representing a Boolean function f , checking whether f isunate can be done in O(|f |2) time, where |f | is the size of the given OBDD.If we start Algorithm CHECK-UNATE with initial condition p[i] := 0 (respectively,p[i] := 1) for all i = 1, 2, . . . , n, we can check the positivity (respectively negativity) off . This is because f is positive (respectively, negative) if and only if the polarities of allnodes are 0 (respectively, 1).Corollary 4.1. Given an OBDD representing a Boolean function f , checking whether fis positive (respectively, negative) can be done in O(|f |2) time, where |f | is the size of thegiven OBDD.As stated above, it may not be necessary to compute imp[u, v]’s for all pairs (u, v) ofnodes. The following theorem however gives an unfortunate instance which requires thecomputation of imp[u, v]’s for -(|f |2) pairs.Theorem 4.2. There exists an OBDD of a positive function f which requires to check-(|f |2) imp[u, v]’s, where |f | is the size of the given OBDD.Proof. Consider the function fG with n = 3m + 1 variables as defined below:fG = ¯x3m+1fm ∨ x3m+1gm,(cid:4)fi =gi =(cid:4)(x2m+i ∨ fi−1)xm−i+10xm+igi−1 ∨ xm−i+10(i = 1, 2, . . . , m)(i = 0),(i = 1, 2, . . . , m)(i = 0).The OBDDs of fi and gi are illustrated in Figs. 7(a) and (b), respectively. As shown inFig. 8, the OBDD of fG has 4m + 2 nodes.204T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213Fig. 7. OBDDs representing (a) fi = (x2m+i ∨ fi−1)xm−i+1 and (b) gi = xm+i gi−1 ∨ xm−i+1.Fig. 8. OBDD representing fG = ¯x3m+1fm ∨ x3m+1gm.T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213205The upper bound O(|f |2) is obvious from Theorem 4.1. Now, in order to prove thelower bound, we show that fG requires to check at least m2 imp[ ]’s. Since fm and gmare positive functions, Algorithm CHECK-UNATE executes iterations of Steps 2 to 4 fromthe initial level + = 1 to level + = 3m. In level + = 3m + 1, in order to obtain the resultp[3m + 1] = YES in Step 2, it is necessary to have the property fm (cid:1) gm. By applyingLemma 2.1 recursively, property fm (cid:1) gm is confirmed by checking the properties f (cid:21)(cid:1) gmifor all i = 1, 2, . . . , m, where f (cid:21)k=1 xk. Similarly, property f (cid:21)(cid:1) gm is confirmed by=(cid:7)iichecking the properties f (cid:21)j for all j = 1, 2, . . . , m, where g(cid:21)(cid:1) g(cid:21)j=k=1 xk. Therefore,i(cid:1) g(cid:21)we need to check f (cid:21)j for all i = 1, 2, . . . , m and j = 1, 2, . . . , m; i.e., m2 imp[ ]’s. ✷i(cid:6)ij5. Checking the Horn property of OBDDsIn this section, we discuss the problem of checking whether a given OBDD represents aHorn function. After examining the condition for the Horn property in the next subsection,an algorithm will be given in Section 5.2.5.1. Conditions for the Horn propertyWe assume, without loss of generality, that the variable ordering is always (xn, xn−1, . . . ,x1). Denoting f |xn=0 and f |xn=1 by f0 and f1 for simplicity, f is given byf = ¯xnf0 ∨ xnf1,where f0 and f1 are Boolean functions on n − 1 variables x1, x2, . . . , xn−1. By definition,we can determine whether f is Horn by checking the condition f ∧bit f = f . For this, wemay first construct an OBDD of f ∧bit f , and then check the equivalence between f ∧bit fand f . However, the following theorem says that this check may require exponential timeand hence is intractable in general.Theorem 5.1. There exists a Boolean function f on n variables, for which OBDD requiressize O(n2), while the OBDD representing f ∧bit f requires $(2n/4) for the same variableordering.Proof. Consider a function2m(cid:8)fH =fi ,i=1fi = gi ∧ xi+2m ∧(cid:14) (cid:5)(cid:15)¯xj +2m(i = 1, 2, . . . , 2m),(cid:4)j ∈{1,2,...,2m}−{i}(i = m + 1, m + 2, . . . , 2m)¯xi−m ∧ ¯xi¯xi ∧ ¯xi+m (i = 1, 2, . . . , m),gi =where n = 4m. We first prove the upper bound on the size of the OBDD of fH . We assumethat the variable ordering is (x4m, x4m−1, . . . , x1). fH can be rewritten as206T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213fH = h2m,(cid:4)hi =xi+2m0(cid:11)gi ∧(cid:11)(cid:6)j ∈{1,2,...,i−1} ¯xj +2m(cid:12)(cid:12)∨ ¯xi+2mhi−1(i = 1, 2, . . . , 2m)(i = 0)by Shannon’s expansion. The OBDD of hi (i = 1, 2, . . . , 2m) has the root node labeledby xi+2m, and the 1-edge and the 0-edge pointing to the OBDD of hi |xi+2m=1 and that ofhi |xi+2m=0, respectively. Thus, the size of the OBDD of hi has the following upper bound:|hi | (cid:1) |hi |xi+2m=1| + |hi|xi+2m=0| + 1(cid:15)(cid:16)(cid:16)(cid:16)(cid:16) + |hi−1| + 1,j ∈{1,2,...,i−1} ¯xj +2m(cid:16)(cid:16)(cid:16)(cid:16)gi ∧(cid:6)=(cid:14)where |hi| denotes the size of the OBDD of hi . Since gi ∧ (j ∈{1,2,...,i−1} ¯xj +2m) is anAND of less than n negative literals, the size of its OBDD is O(n). By definition, h0 = 0means that the size of the OBDD of h0 is 1. By induction, we have|fH | = |h2m| (cid:1) O(n) + |h2m−1| + 1 (cid:1) O(2mn) + |h0| + 2m.(cid:6)Namely, the upper bound is O(n2).(cid:6)mi=1 gi) ∧ (Now, we consider the second part of the theorem, i.e. the lower bound on fH ∧bit fH .First, we show the identity fH ∧bit fH = fH ∨ g by considering their models, where g =(cid:7)¯xj +2m). Let b and c be models of fH . By definition, b (respectively,(c) is a model of fk (respectively, f+) for some k (respectively, +) (k, + ∈ {1, 2, . . ., 2m}).Then, we have two cases: (1) k = +, and (2) k (cid:17)= +. In case (1), since fk is Horn, a = b ∧bit cis also a model of fk. In case (2), model b satisfies2mj =1bk = bk(cid:21) = 0,and bj +2m = 0where k(cid:21) denotes k + m if k ∈ {1, 2, . . ., m}, but denotes k − m if k ∈ {m + 1, m + 2,. . . , 2m}. Similarly, model c satisfiesfor all j ∈ {1, 2, . . . , 2m} − {k},bk+2m = 1,c+ = c+(cid:21) = 0,c++2m = 1,and cj +2m = 0 for all j ∈ {1, 2, . . . , 2m} − {+}.Thus, k (cid:17)= + implies that a = b ∧bit c satisfies the following restrictions:ak = ak(cid:21) = a+ = a+(cid:21) = 0,and aj +2m = 0 for all j ∈ {1, 2, . . . , 2m}.This means that a is a model of g. By considering both cases, we haveΣ(fH ∧bit fH ) ⊆ Σ(fH ) ∨ Σ(g) = Σ(fH ∨ g).(1)On the other hand, let a be a model of g. Then, a is of form a = b ∧bit c where b and csatisfy the following restrictions:bk+2m = 1,ck+3m = 1,bj = ajcj = ajfor all j ∈ {1, 2, . . . , 4m} − {k + 2m},for all j ∈ {1, 2, . . . , 4m} − {k + 3m}.By definition, a satisfies ak = ak+m = 0 for some k ∈ {1, 2, . . ., m} and aj +2m = 0 for allj ∈ {1, 2, . . ., 2m}. Since both b and c are models of fH , we have Σ(g) ⊆ Σ(fH ∧bit fH ).Also, the definition of bitwise AND operation implies Σ(fH ) ⊆ Σ(fH ∧bit fH ). Thus, wehaveΣ(fH ∨ g) ⊆ Σ(fH ∧bit fH ).(2)T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213207(cid:7)The size of the OBDD ofBy combining (1) and (2), we have the identity fH ∧bit fH = fH ∨ g.mi=1 gi =mi=1( ¯xi ∧ ¯xi+m) is known to be $(2m) for thevariable ordering (x2m, x2m−1, . . . , x1) [4], where this function is obtained from fE ∧bit fEby restricting x4m, x4m−1, . . . , x2m+1 to 0. Since the size does not increase by a restriction,the size of the OBDD of fE ∧bit fE is $(2n/4). ✷(cid:7)Our main result however shows that the condition f ∧bit f = f can be checked inpolynomial time without explicitly constructing the OBDD of f ∧bit f . For this goal, thefollowing lemmas tell a key property that the problem can be divided into two subproblems,and hence can be solved by a divide-and-conquer approach.Lemma 5.1. Let f be a Boolean function on n variables x1, x2, . . . , xn, which is ex-panded as f = ¯xnf0 ∨ xnf1. Then, f is Horn if and only if both f0 and f1 are Hornand f0 ∧bit f1 (cid:1) f0 holds.Proof. We first prove the only-if-part. Let b and c be models of f , where b and c maybe identical. Then, by definition of a Horn function, a = b ∧bit c is also a model of f . Byconsidering the nth bits bn and cn of models b and c, without loss of the generality, wehave the following three cases:(1) Both are 0’s, i.e., b = (b(cid:21), 0) and c = (c(cid:21), 0), where (b(cid:21), bn) is a concatenation of b(cid:21)(∈ {0, 1}n−1) and bn.(2) Both are 1’s, i.e., b = (b(cid:21), 1) and c = (c(cid:21), 1).(3) One is 0 and the other is 1, i.e., b = (b(cid:21), 0) and c = (c(cid:21), 1).Case (1) implies (b(cid:21), 0) ∧bit (c(cid:21), 0) = (a(cid:21), 0). Namely, for any two models b(cid:21) and c(cid:21) of f0,b(cid:21) ∧bit c(cid:21) is also a model of f0. By definition, this says that f0 is Horn. Similarly, case (2)implies that f1 is Horn. Finally, case (3) implies (b(cid:21), 0) ∧bit (c(cid:21), 1) = (a(cid:21), 0). Namely, forany models b(cid:21) of f0 and c(cid:21) of f1, b(cid:21) ∧bit c(cid:21) is always a models of f0. Thus, we have theproperty Σ(f0) ∧bit Σ(f1) ⊆ Σ(f0), i.e., f0 ∧bit f1 (cid:1) f0.Now, the proof of the if-part is trivial. For any two models b and c of f , one of the abovethree cases (1), (2) and (3) holds. In case (1) (respectively, case (2)), since f0 (respectively,f1) is Horn, (a(cid:21), 0) = (b(cid:21), 0) ∧bit (c(cid:21), 0) (respectively, (a(cid:21), 1) = (b(cid:21), 1) ∧bit (c(cid:21), 1)) is also amodel of f . In case (3), since f0 ∧bit f1 (cid:1) f0 holds, (a(cid:21), 0) = (b(cid:21), 0) ∧bit (c(cid:21), 1) is also amodel of f . Since a = b ∧bit c is always a model of f , by definition, f is Horn. ✷The Horn property of f0 and f1 can be checked by applying Lemma 5.1 recursively.The following lemma says that the condition f0 ∧bit f1 (cid:1) f0 in Lemma 5.1 can be alsochecked recursively.Lemma 5.2. Let f , g and h be Boolean functions on n variables, which are expandedas f = ¯xnf0 ∨ xnf1, g = ¯xng0 ∨ xng1 and h = ¯xnh0 ∨ xnh1, respectively. Then, propertyf ∧bit g (cid:1) h holds if and only if f0 ∧bit g0 (cid:1) h0, f0 ∧bit g1 (cid:1) h0, f1 ∧bit g0 (cid:1) h0 andf1 ∧bit g1 (cid:1) h1 hold.208T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213Proof. The identity(cid:11)f ∧bit g = ¯xn(f0 ∧bit g0) ∨ (f0 ∧bit g1) ∨ (f1 ∧bit g0)(cid:12)∨ xn(f1 ∧bit g1)(3)can be proved in a manner similar to Lemma 5.1 by considering all models. Then, sincef ∧bit g (cid:1) h holds if and only if (f ∧bit g)|xn=0 = (f0 ∧bit g0) ∨ (f0 ∧bit g1) ∨ (f1 ∧bit g0) (cid:1)h|xn=0 = h0 and (f ∧bit g)|xn=1 = f1 ∧bit g1 (cid:1) h|xn=1 = h1 hold, this lemma follows fromLemma 2.1(2). ✷Note that the condition of type f ∧bit g (cid:1) f in Lemma 5.1 requires to check thecondition of type f1 ∧bit g0 (cid:1) f0 (i.e., checking of type f ∧bit g (cid:1) h for three functions f ,g and h). The last condition can be checked recursively by Lemma 5.2.5.2. Algorithm to check the Horn propertyAlgorithm CHECK-HORN in Fig. 9 checks the Horn property of a given OBDD inthe bottom-up manner by applying Lemmas 5.1 and 5.2 recursively. The bottom-up andcaching techniques used there are similar to those of CHECK-UNATE. However, weemphasize here that, in the case of unateness, the naive algorithm to check the condition ofProperty 4.1 was already polynomial time, while a naive algorithm to check the conditionof Lemma 5.1 would require exponential time by Theorem 5.1. This CHECK-HORN is thefirst polynomial time algorithm, which is made possible by using both Lemmas 5.1 and 5.2.In Algorithm CHECK-HORN, we use an array horn[v] to denote whether each node vrepresents a Horn function or not, and a three-dimensional array bit-imp[u, v, w] to denotewhether fu ∧bit fv (cid:1) fw holds or not. Each element of the arrays stores YES, NO or ∗ (notAlgorithm CHECK-HORNInput: An OBDD representing f with a variable ordering (xn, xn−1, . . . , x1).Output: “yes” if f is Horn; otherwise, “no”.Step 1 (initialize). Set(cid:4)horn[v] :=YES if v is a constant node 0 or 1;∗otherwise;(cid:13)bit-imp[u, v, w] :=if (fu, fv, fw) = (1, 1, 0);NOYES if fu, fv, fw ∈ {0, 1} and (fu, fv, fw) (cid:17)= (1, 1, 0);∗otherwise;+ := 1.Step 2 (check the Horn property in level +). For each node v in level + (i.e.,labeled with x+), set horn[v] := YES if all of horn[0-succ(v)], horn[1-succ(v)] andbit-imp[0-succ(v), 1-succ(v), 0-succ(v)] are YES; otherwise, output “no” and halt.Step 3 (compute bit-imp[∗] in level +). For each triple (u, v, w) of nodes such thatlevel(u) (cid:1) +, level(v) (cid:1) + and level(w) (cid:1) +, and at least one of level(u), level(v) andlevel(w) is equal to +, check whether fu ∧bit fv (cid:1) fw holds according to Fig. 10. Setits result YES or NO to bit-imp[u, v, w].Step 4 (iterate). If + = n then output “yes” and halt. Otherwise set + := + + 1 and returnto Step 2.Fig. 9. Algorithm CHECK-HORN to check the Horn property of an OBDD.T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213209YESif all of bit-imp[1-succ(cid:21)(v), 0-succ0-succand bit-imp[1-succ(cid:21)(v), 1-succ(cid:21)(u), 1-succ(cid:21)(w)], bit-imp[0-succ(cid:21)(u), 0-succ(cid:21)(v), 0-succ(cid:21)(w)], bit-imp[0-succ(cid:21)(v), 0-succ(cid:21)(u), 1-succ(cid:21)(u),(cid:21)(w)](cid:21)(w)] are YES.NOotherwise.Fig. 10. Checking bit-imp[u, v, w] (i.e., fu ∧bit fv (cid:1) fw) for a triple of nodes (u, v, w) in Step 3 of AlgorithmCHECK-HORN.checked yet); horn[v] = YES says that fv is Horn and bit-imp[u, v, w] = YES says thatfu ∧bit fv (cid:1) fw holds. We note here that, since the given OBDD is reduced, the conditionfu ∧bit fv (cid:1) fw may be checked for functions in different levels; in such case, all functionsare considered to have lmax variables x1, x2, . . . , xlmax, where lmax denotes the maximumlevel of the nodes u, v and w.In Step 2 of Algorithm CHECK-HORN, horn[v] for each v can be easily computedaccording to Lemma 5.1. Note that every node v satisfies fv|xlevel(v)=0 = f0-succ(v) andfv|xlevel(v)=1 = f1-succ(v). Also note that horn[0-succ(v)], horn[1-succ(v)] and bit-imp[0-succ(v), 1-succ(v), 0-succ(v)] have already been computed in the previous iterations.Similarly, bit-imp[u, v, w] in Step 3 for each triple (u, v, w) can be also computedeasily by Fig. 10, which corresponds to Lemma 5.2. Similar to the case of checkingunateness, 0-succ(cid:21)(v) (respectively, 1-succ(cid:21)(v)) denotes 0-succ(v) (respectively, 1-succ(v))if level(v) = +, but denotes v itself if level(v) < +. Upon completing Step 3 for +, wehave the results for all triples (u, v, w) of nodes such that level(u) (cid:1) +, level(v) (cid:1) + andlevel(w) (cid:1) +. These contain all the information required in the next iteration, althoughsome of them may not be needed.Example 5.1. Consider the OBDD of fI = (x3 ∨ ¯x2 ∨ ¯x1)( ¯x3 ∨ x2)( ¯x3 ∨ x1) with variableordering (x3, x2, x1). As shown in Fig. 11, the OBDD has 7 nodes v1, v2, . . . , v7, whichrespectively represent the following functions:fv1fv2fv3fv4fv5fv6fv7= 1,= 0,= ¯x1,= x1,= ¯x2 ∨ ¯x1,= x2x1,= (x3 ∨ ¯x2 ∨ ¯x1)( ¯x3 ∨ x2)( ¯x3 ∨ x1).Algorithm CHECK-HORN starts from the initializing step:horn[v1] = horn[v2] = YES, horn[vi] = ∗ for all i = 3, 4, . . . , 7,bit-imp[v1, v1, v2] = NO,bit-imp[vi, vj , vk] = YES for all triples (vi, vj , vk) ∈ {v1, v2}3 but (v1, v1, v2),and + = 1.210T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213Fig. 11. OBDD representing fI = (x3 ∨ ¯x2 ∨ ¯x1)( ¯x3 ∨ x2)( ¯x3 ∨ x1).In the rest of this example, we pay attention to bit-imp[ ]’s which are needed in thefollowing computation. In Step 2 of the first iteration, we have horn[v3] = horn[v4] = YESbecause horn[v1] = horn[v2] = YES and bit-imp[v1, v2, v1] = bit-imp[v2, v1, v2] = YEShold. In Step 3 of the first iteration, we havebit-imp[v1, v3, v1] = YES,which can be confirmed by the property1 ∧bit x1 = {0, 1} ∧bit {1} = {0, 1} = 1.We also have the propertybit-imp[v2, v4, v2] = bit-imp[v3, v2, v1] = bit-imp[v3, v4, v3]= bit-imp[v1, v4, v1] = YES.In the second iteration (level + = 2), we have horn[v5] = horn[v6] = YES because theproperties horn[v1] = horn[v2] = horn[v3] = horn[v4] = YES and bit-imp[v1, v3, v1] =bit-imp[v2, v4, v2] = YES hold. We also have the propertybit-imp[v5, v6, v5] = YESbecausebit-imp[v3, v4, v3] = bit-imp[v1, v2, v1] = bit-imp[v1, v4, v1]= bit-imp[v3, v2, v1] = YES.Note that bit-imp[v3, v2, v1] is an example of the general property that checking thecondition of type f ∧bit g (cid:1) f in Lemma 5.1 requires checking the condition of typef ∧bit g (cid:1) h. In the third iteration (level + = 3), we have horn[v7] = YES becausethe properties horn[v5] = horn[v6] = YES and bit-imp[v5, v6, v5] = YES hold. Then,Algorithm CHECK-HORN outputs the answer “yes” and halts. ✷T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213211Now, we consider the computation time of Algorithm CHECK-HORN. In Step 2,horn[v] for each node v is computed in constant time. Thus, the total time of Step 2 isO(|f |). In Step 3, bit-imp[u, v, w] for each triple (u, v, w) is also computed in constanttime. The number of triples to be checked in Step 3 during the entire computation isO(|f |3). The time for the rest of the computation is minor.Theorem 5.2. Given an OBDD representing a Boolean function f , checking whether f isHorn can be done in O(|f |3) time, where |f | is the size of the given OBDD.As stated above, it may not be necessary to compute bit-imp[u, v, w]’s for all triples(u, v, w) of nodes. The following theorem however gives an unfortunate instance whichrequires the computation of bit-imp[u, v, w]’s for -(|f |3) triples.Theorem 5.3. There exists an OBDD of a Horn function f which requires to check -(|f |3)bit-imp[u, v, w]’s, where |f | is the size of the given OBDD.Proof. By an argument similar to Theorem 4.2, we can prove this theorem. Consider thefunction fJ with n = 6m + 2 variables defined below:fJ = ¯x6m+2g0 ∨ x6m+2g1,g0 = ¯x6m+1hA,m ∨ x6m+1hB,m,g1 = ¯x6m+1hC,m ∨ x6m+10,(cid:4)hA,i =hB,i =hC,i =(cid:4)(cid:4)( ¯x3m+i ∨ hA,i−1) ¯x3m−i+1 ∨ ( ¯xm+1 ∨ ¯x1)0(i = 1, 2, . . . , m)(i = 0),( ¯x4m+i ∨ hB,i−1) ¯x2m−i+10(i = 1, 2, . . . , m)(i = 0),( ¯x5m+i ∨ hC,i−1) ¯xm−i+10(i = 1, 2, . . . , m)(i = 0).The OBDD of fJ has 6m + 6 nodes.The upper bound O(|f |3) is obvious from Theorem 5.2. We show that fJ requiresto check at least m3 bit-imp[ ]’s, which proves the lower bound. Since hA,m, hB,m andhC,m are negative functions (i.e., Horn functions), Algorithm CHECK-HORN executesiterations of Steps 2 to 4 from the initial level + = 1 to level + = 6m. In level + = 6m + 1,in order to obtain the result g0 ∧bit g1 (cid:1) g0 in Step 3, it is necessary to have the propertyhB,m ∧bit hC,m (cid:1) hA,m. (Note that the property g0 ∧bit g1 (cid:1) g0 is used for checking theHorn property of fJ .) By Lemma 5.2, g0 ∧bit g1 (cid:1) g0 holds if and only ifhA,m ∧bit hC,m (cid:1) hA,m,hA,m ∧bit 0 (cid:1) hA,m,hB,m ∧bit hC,m (cid:1) hA,m and hB,m ∧bit 0 (cid:1) hB,m212T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213hold. In order to confirm hB,m ∧bit hC,m (cid:1) hA,m, we need to check h(cid:21)for all triples (i, j, k) ∈ {1, 2, . . . , m}3, where∧bit h(cid:21)C,j(cid:1) h(cid:21)A,kB,ih(cid:21)A,i=¯x2m+k∨ ( ¯xm+1 ∨ ¯x1),h(cid:21)B,i=(cid:10)(cid:9)i(cid:5)k=1i(cid:5)k=1¯xm+kand h(cid:21)C,i=i(cid:5)k=1¯xk.Thus, it is necessary to check m3 bit-imp[ ]’s. ✷6. ConclusionIn this paper, we considered to use OBDDs to represent knowledge-bases. We haveshown that the conventional CNF-based and model-based representations, and the newOBDD representation are mutually incomparable with respect to space requirement. Thus,OBDDs can find their place in knowledge-bases, as they can represent some theories moreefficiently than others.We then considered the problem of recognizing whether a given OBDD representsa unate Boolean function, and whether it represents a Horn function. It turned out thatchecking unateness can be done in quadratic time with respect to the size of OBDD, whilechecking the Horn property can be done in cubic time.OBDDs are dominatingly used in the field of computer-aided design and verification ofdigital systems. The reason for this is that many Boolean functions which we encounterin practice can be compactly represented, and that many operations on OBDDs can beefficiently performed. We believe that OBDDs are also useful for manipulating knowledge-bases. Developing efficient algorithms for knowledge-base operations such as deductionand abduction should be addressed in the further work.AcknowledgementThe authors would like to thank Professor Endre Boros of Rutgers University for hisvaluable comments. This research was partially supported by the Scientific Grant-in-Aidfrom Ministry of Education, Culture, Sports, Science and Technology of Japan.References[1] S.B. Akers, Binary decision diagrams, IEEE Trans. Comput. C-27 (1978) 509–516.[2] K.S. Brace, R.L. Rundell, R.E. Bryant, Efficient implementation of a BDD package, in: Proc. ACM/IEEEDesign Automation Conference, Orlando, FL, 1990, pp. 40–45.[3] R.K. Brayton, G.D. Hachtel, A.L. Sangiovanni-Vincentelli, Multilevel logic synthesis, Proc. IEEE 78 (2)(1990) 264–300.[4] R.E. Bryant, Graph-based algorithms for Boolean function manipulation, IEEE Trans. Comput. C-35 (1986)677–691.[5] R.E. Bryant, On the complexity of VLSI implementations and graph representations of Boolean functionswith application to integer multiplication, IEEE Trans. Comput. 40 (1991) 205–213.T. Horiyama, T. Ibaraki / Artificial Intelligence 136 (2002) 189–213213[6] P. Buch, A. Narayan, A.R. Newton, A. Sangiovanni-Vincentelli, Logic synthesis for large pass transistorcircuits, in: Proc. IEEE/ACM International Conference on Computer Aided Design, San Jose, CA, 1997,pp. 663–670.[7] J.R. Burch, E.M. Clarke, K.L. McMillan, D.L. Dill, Sequential circuit verification using symbolic modelchecking, in: Proc. ACM/IEEE Design Automation Conference, Orlando, FL, 1990, pp. 46–51.[8] O. Coudert, Doing two-level logic minimization 100 times faster, in: Proc. ACM/SIAM Symposium onDiscrete Algorithms, San Francisco, CA, 1995, pp. 112–118.[9] R. Dechter, J. Pearl, Structure identification in relational data, Artificial Intelligence 58 (1992) 237–270.[10] W.F. Dowling, J.H. Gallier, Linear time algorithms for testing the satisfiability of Horn formula, J. LogicProgramming 3 (1984) 267–284.[11] R. Drechsler, N. Drechsler, W Günther, Fast exact minimization of BDDs, in: Proc. ACM/IEEE DesignAutomation Conference, San Francisco, CA, 1998, pp. 200–205.[12] T. Eiter, G. Gottlob, The complexity of logic-based abduction, J. ACM 42 (1995) 3–42.[13] C. Glymour, R. Scheines, P. Spirtes, K. Kelly, Discovering Causal Structure, Academic Press, Orlando, FL,1987.[14] K. Hayase, H. Imai, OBDDs of a monotone function and of its implicants, in: Proc. International Symposiumon Algorithms and Computation, Lecture Notes in Computer Science, Vol. 1178, Springer, Berlin, 1996,pp. 136–145.[15] T. Horiyama, T. Ibaraki, Reasoning with ordered binary decision diagrams,in: Proc. InternationalSymposium on Algorithms and Computation, Lecture Notes in Computer Science, Vol. 1969, Springer,Berlin, 2000, pp. 120–131.[16] T. Horiyama, T. Ibaraki, Translation among CNFs, characteristic models and ordered binary decisiondiagrams, in: Proc. International Symposium on Algorithms and Computation, Lecture Notes in ComputerScience, Vol. 2223, Springer, Berlin, 2001, pp. 231–243.[17] H.A. Kautz, M.J. Kearns, B. Selman, Reasoning with characteristic models, in: Proc. AAAI-93, Washington,DC, 1993, pp. 34–39.[18] H.A. Kautz, M.J. Kearns, B. Selman, Horn approximations of empirical data, Artificial Intelligence 74(1995) 129–245.[19] H.A. Kautz, B. Selman, An empirical evaluation of knowledge compilation by theory approximation, in:Proc. AAAI-94, Seattle, WA, 1994, pp. 155–161.[20] D. Kavvadias, C. Papadimitriou, M. Sideri, On Horn envelopes and hypergraph transversals, in: Proc.International Symposium on Algorithms and Computation, Lecture Notes in Computer Science, Vol. 762,Springer, Berlin, 1993, pp. 399–405.[21] R. Khardon, D. Roth, Reasoning with models, Artificial Intelligence 87 (1996) 187–213.[22] Y.T. Lai, K.R. Pan, M. Pedram, OBDD-based functional decomposition: Algorithms and implementation,IEEE Trans. CAD 15 (8) (1996) 977–990.[23] J.C. Madre, O. Coudert, A logically complete reasoning maintenance system based on a logical constraintsolver, in: Proc. IJCAI-91, Sydney, Australia, 1991, pp. 294–299.[24] J. McCarthy, P.J. Hayes, Some philosophical problems from the standpoint of artificial intelligence, in: D.Michie (Ed.), Machine Intelligence, Vol. 4, Edinburgh University Press, Edinburgh, 1969.[25] S. Minato, N. Ishiura, S. Yajima, Shared binary decision diagram with attributed edges for efficient Booleanfunction manipulation, in: Proc. ACM/IEEE Design Automation Conference, Orlando, FL, 1990, pp. 52–57.[26] K. Ravi, K.L. McMillan, T.R. Shiple, F. Somenzi, Approximation and decomposition of binary decisiondiagrams, in: Proc. ACM/IEEE Design Automation Conference, San Francisco, CA, 1998, pp. 445–450.[27] N. Takahashi, N. Ishiura, S. Yajima, Fault simulation for multiple faults using BDD representation of faultsets, in: Proc. IEEE/ACM International Conference on Computer Aided Design, Santa Clara, CA, 1991,pp. 550–553.[28] Y. Takenaga, Theoretical studies on memory-based parallel computation and ordered binary decisiondiagrams, Ph.D. Thesis, Graduate School of Engineering, Kyoto University, Kyoto, Japan, 1994.[29] L.G. Valiant, A theory of the learnable, Comm. ACM 27 (11) (1984) 1134–1142.[30] C. Yang, M. Ciesielski, V. Singhal, BDS: A BDD-based logic optimization system, in: Proc. ACM/IEEEDesign Automation Conference, Los Angeles, CA, 2000, pp. 92–97.