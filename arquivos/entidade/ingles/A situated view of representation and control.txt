ELSEVIER Artificial Intelligence 73 (1995) 149-173 Artificial Intelligence A situated view of representation and control Stanley J. Rosenschein ‘, Leslie Pack Kaelbling *v2 hnputer Science Departntent, Box 1910, Brown Universiiy Providence, RI 02912-1910, USA Received December 1993; revised September 1994 Abstract Intelligent agents are systems that have a complex, ongoing interaction with an environment that is dynamic and imperfectly predictable. Agents are typically difficult to program because the correctness of a program depends on the details of how the agent is situated in its environ- ment. In this paper, we present a methodology for the design of situated agents that is based on theory. This approach allows designers to describe the informational content of situated-automata an agent’s computational states in a semantically rigorous way without requiring a commitment to conventional run-time symbolic processing. We start by outlining this situated view of repre- sentation, then show how it contributes to design methodologies for building systems that track perceptual conditions and take purposeful actions in their environments. 1. Introduction Humans, delivery robots, and automated factories are all systems that have an in- telligent, ongoing interaction with environments that are dynamic and imperfectly pre- dictable. Such systems are often called situated agents. They constitute an important class of systems that are very difficult to program because of their close interaction with the environment in which they are situated. Specifications of correctness for situated agents amount to specifications of their interactions with the environment: what action should the agent take when the environment is in a particular configuration? Programs * Corresponding author. E-mail: lpk@cs.brown.edu. ’ Work on this paper was suppolted in part by the National Aeronautics and Space Administration under contract NAS2-13326 and by the Defense Advanced Research Projects Agency under NASA contract NASZ- 13229 and under TEC contract DATA76-93-C-0017. * Work on this paper was supported in pm by National Science Foundation National Young Investigator Award IRI-9257592 and in part by ONR Contract NOOO14-91-4052, ARPA Order 8225. OOO4-3702/95/$09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00056-5 150 S.J. Rosenschein. LJ? Kuelbling/Artificial Intelligence 73 (I 995) 149-I 73 for situated agents must allow them to respond appropriately situations. to diverse, rapidly changing is an important theories of representation The emphasis on an agent’s connection to its environment and control. based on situated-automata symbolic the symbolic from that of traditional an informal overview of a particular methodology This methodology, to use high-level without requiring folk wisdom our view, this is not at all the case, and we feel there is much to gain from analyzing the semantics of representations outlining methodologies actions change In this paper, we present for the design of situated agents. [ 14,161, allows system designers content of agents in the agent. It has become In In this spirit, we start by to design and take purposeful that “situated agents” and “representation” this situated view of representation, that track perceptual conditions then show how it contributes from a situated perspective. in their environments. to be implemented the informational are incompatible for building to describe languages structures concepts. systems theory 2. Situated representation and building situated agents, is, at each moment Our ultimate aim, in designing is to have them perform that that are a rich set of tasks correctly; and goals. In order to specify correct behavior, and then to their situations appropriate to show that a particular program will satisfy that specification, we need to make precise the relationship Once behavior the internal states of an agent and conditions is made precise, we can give clear specifications states of the agent that satisfies for an agent in an environment and then generate a program to carry out actions those specifications. in its environment. this relationship for manipulating of desired between internal For example, suppose we are designing an agent whose task it is to water a plant and only if it is dry. From the outset, we must take into account the agent and the environment: about the agent, water the plant, and a statement about the environment, when it is dry. In order to design such a controller, we must have a systematic way of talking about the relationship the agent and its environment. of our problem contains the specification between if the interaction between a statement 2.1. Existing approaches There has been a variety of approaches to describing the relationship between agents and their environments. Many simple embedded systems are designed according little internal that describe variables in parametric theory. These systems usually have very of estimates of a set of real-valued directly quantities estimate actions well when upon which correct control those quantities the agent’s responses depend, inside the agent based on incoming to then designs machinery sensory signals. The control taken by the agent depend on the estimates of the quantities. This approach works can be described by simple interaction with the environment form. The designer of the control system chooses state, which to the principles of control consists typically the state of the environment the real-world S.J. Rosenschein, L.P. Kaelbling/Artificial Intelligence 73 (1995) 149-I 73 151 functions continuous fairly directly. As agents and their environments information will have to be represented, the quantities and when In the artificial intelligence community, represented is typically environment the system’s designer, the agent’s memory is applicable complex world, but it can be computationally to arbitrarily including to the propositions that must be estimated can be sensed become more complex, more abstract and this approach will no longer suffice. an intended about semantics information an agent’s symbolically. A formal language that relates sentences the state of its is developed by in about the world that they denote. This approach states of the agent and the such a representation. relationships intractable between to maintain to provide ascriptional stored it useful have found in the world to a thermostat, speaks of attributing accounts of the re- researchers between in order for that agent’s actions states of an agent and states of the environment. McCarthy knowledge of the temperature [lo], and [ 121 gives a definition of knowledge of an agent in terms of what would have (in service of Many lationship for example, Newell to be true some goal). More formal notions of an agent’s having knowledge about its environment are found the knowledge of one agent about another’s knowledge tions, for example. Halpem and Moses knowledge tion protocols and Moses for specifying effective way of describing to model for the purpose of asking ques- [2] provide a concrete computational model of of communica- to that of Halpern to be an systems. We use an approach agents, finding similar the concept of knowledge in their applications in distributed in the work on epistemic logic: Moore between agent and environment. logic to the formalization [ 1 I] uses epistemic the relationship to be rational of epistemic embedded logic 2.2. The situated-automata model Traditional theories of computation putation of a function. The inputs are presented for some amount of time, then generates question and only one answer; of course, tially be changed. are based on the notion of computation process, to the computational as com- it works the answer and terminates. There is only one the question can be arbitrarily complex, poten- it cannot has started, including many simple questions, but once the computation 2.2.1. Interaction model It is more appropriate to think of an agent embedded in an environment from the environment For the purposes of this work, we model a transduction. It has a stream of inputs of outputs or actions to the environment. coupling between operating alternating then synchronous we require synchronously with one another; the agent generating turns, with interaction an output the agent In the transduction model, from inputs the agent and the environment as that of a pair of automata the world generating an input (or “perception”) that is, their interaction (or “action”) to the world. In order to make a plausible model of interacting with a dynamic environment, to generate actions, without fail, at strictly timed intervals. then, an agent is viewed as an automaton that generates a as performing and generates a stream the that are can be seen as taking to the agent, this mapping of the agent and its environment. We note in passing to outputs, mediated by its internal state. Fig. 1 shows the coupling there is only one agent that although 152 S.J. Rosenschein, L.l? Kaelbling/Art@cial Intelligence 73 (1995) 149-I 73 Fig. I. Interaction between agent and environment. interesting in this model, most perspective of this model, however, all of the other agents, whether robotic or biological, are taken the properties of a single agent from its perspective. to be part of the environment. This gives us a way to discuss have large numbers of agents. From environments the 2.2.2. Correlational deJnition of information tasks are often specified then the agent should take action A. This specification if the agent had direct access immediately that is not the case. Because an agent’s actions in the form: when P is true of the state of the Agent could only be environment, to arbitrary properties of the implemented in reality can only world. In general, depend on its inputs and internal state, agent programs must ultimately be expressed in the form: when P’ is true of the state of the agent, then the agent should take action A. between P and Our problem, P’; if we can find some P’ that implies P, then taking action A when P’ holds of the the specification. agent’s state is sufficient account of the relationship is to give a systematic to satisfy then, One way to view this relationship is in terms of a correlation between states of the agent and states of the external world. We will say that when an agent x is in state u, it carries the information that 9 if and only if whenever it is in state u, 4p is true in the world. This definition was originally classes of strings [ 141 in terms of equivalence leave an automaton in the same state. that would articulated Given the simple robot plant-watering this definition, we can specify the information this is a fairly weak specification. For example, task more pre- that the plant is dry, it should water the agent carries cisely: whenever it the plant. Of course, as it stands, could be satisfied trivially by any agent whose internal state is simply uncorrelated with the state of the plant. To rule out such a consequence, we might require further that the agent track whether is dry, the agent should carry is dry: that is, if the plant the information that it is not dry. These that will water the plant that it is dry, and if it is not dry, the agent should carry the information two informational if and only taken together specify an agent requirements if it is dry. the plant S.J. Rosenschein, L.P Kaelbling/Artificial Intelligence 73 (1995) 149-I 73 153 A:.. .-%...... I .,..,.,.,.... ~ . . . . . ..,. . ..‘..“.‘.~.~_,~,~~.S ,,\i*‘.F +:...,, Hg. 2. Circuit model of a finite-state machine. 2.2.3. Circuit model of computation We motivated the concept of information as a way to describe the relation between internal states of an agent and the external state of the world. In this section, we will introduce a way of describing the structure of agents and their internal states. Considering an agent as an automaton does not, in itself, give us much help in its design or analysis. We take a finer-grained view here, considering an agent to be made up of parts, called locations, each of which is capable of assuming a set of local states (or “values”) over time. The set of possible global states of the agent, then, will be the cross-product of the local state sets of the atomic locations. A machine is a set of locations whose values depend on one another over time. We can construct arbitrarily complex machines from machines of two primitive types: pure functions and delays. Pure function machines consist of two (possibly complex) locations and specify the values of one location (the output) as a function of the values of the other (the input). Delay machines also consist of two locations, but constrain the values of the output location to be the values that the input location had on the previous tick. 3 Given a network of delay and function elements, complete with feedback connections, it is possible to organize it into a circuit of the form shown in Fig. 2, in which there is a state-update function, f, that maps the input and the old value of the internal state into a new value of the internal state, and an output function, g, that maps the input and the old value of the internal state into the output. It is often useful to think of the internal state as being a “state vector” containing the state of all the individual delay elements in the machine. Although these definitions can be satisfied by machines made up of infinitely many locations, each of which can take on infinitely many values, we will focus our attention on machines with finite sets of atomic locations, each of which can take on only a finite set of values. One obvious model for this abstract notion of machine exists in the form of digital hardware: locations correspond to wires, function machines correspond to logic gates, 3 We use “tick” to mean one discrete time unit. 1.54 S.J. Rosenschein, L.i? Kaelbling/Art@iul Intelligence 73 (1995) 149-I 73 and delay machines state transduction correspond to flip-flops or registers. As is well known, any finite- can be carried out by a network of such basic components. 2.3. Consequences of the situated-automata model the correlational model of information it useful formalism, we have found Although need for logical a suitable syntax and semantics, formalization into the nature of situated representation. of the situated-automata model, for its application. can be used directly without to adopt a logical the framework, with In this section, we describe a logical it gives us insights some then consider is crucial because machines with complex 2.3.1. Formalization of the model We have adopted logic as a means of describing language information implementations about any proposition their interactions with the environment, izing This use of logic as a specification mentation strategy. This often have very simple tain state, carries state, there can be an infinity of propositions p. Those propositions simple example will illustrate and gate. Behaviorally, only input carries information information but it can be applied freely to reason about the information have about the information that ‘p 4 @, then whenever that +. The inference the output rule modus ponens if both its inputs are 1. Semantically, the state of the world. is very simple: the device that p and a 1 at the second and stating criteria is independent the structure of machines, character- for their correctness. of its use as an imple- logical descriptions the information 9 such that x carries and vice versa. Because a location x, in a cer- that is true whenever x is in that that symbolically. A that consists of a single is 1 if and if a 1 at the first the conditional the output of the machine it may be more involved: input carries location has value 1, it carries is not implemented the in the machine, that locations of the machine could not all be written down and manipulated this point. Consider a machine The correlational in epistemic the information formalized carries relation on possible worlds, axioms [3]: definition of information, [ 161, using introduced the form K(x, p) logic that cp. This definition of information thus giving rise to an accessibility in Section 2.2.2, can be directly that agent x to indicate induces an equivalence relation satisfying the S5 K(x, PD) ---f P K(x,qo + fJ) 4 (K(x,cp) -+ K(x,+)) (consequential closure), (truth), K(x, 40) + K(x, K(x, P)) TK(X, 40) * K(x, +(x3 PO) 1 (positive introspection), (negative introspection). We view an agent as the union of all of its locations, of states of component the agent as a whole, but also to its constituent in simple important location carries locations or in compound corollary of the axioms, the conjunction of the information locations locations, and aggregating the principle of spatial monotonic@: carried by its constituent locations. We find it useful to apply the K operator not only locations. Information to can be carried leads us to an an aggregate locations: so states of agents are comprised S.J. Rosenschein, L.P Kaelbling/Artificial Intelligence 73 (1995) 149-173 155 The formal model can be used to prove correctness properties of agents: given a description of the circuit properties of the inputs have certain informational embedded agent. that makes up the agent and a description of the informational it can, for example, be shown to the agent, [ 16 1. This constitutes properties that the outputs a correctness proof for an 2.3.2. Properties of representations In both standard programming methods and AI inference systems, the semantics of states is typically in mind for values machine meaning so that those stipulated attribute semantics definition of knowledge. between to values these two kinds of semantics. stipulated: the designer of the machine has a particular the machine locations and strives to construct in designated semantics will hold. The situated-automata view allows us to in locations more “objectively” based on the correlational In the following sections, we examine aspects of the relationship Time is meaning assigns content information The correlational definition of knowledge a value at time t and continuing to locations at a point in time as a function of the value they contain at that time and the world states is that with which that value can co-occur. One immediate consequence of this definition to hold that value until time t + k a location containing will be assigned as its information satisfied the designer has taken special care at any time instant in the interval to design mechanisms the objective at all. For example, consider information a robot to the designer the state every 10 be a representation all along will in all seconds. The actual information likelihood not be what was intended but some weaker (though not necessarily vacuous) proposition to the object, depending on the possible maximum relative velocity between at a location may not be what he intended stores for updating values in time to track external change, content [t, t + k]. Unless content of the stored representation to that object, and only updates the robot and the object. that senses an object, of world conditions reading, which of the distance the disjunction the distance that bounds the sensor takes Given the situated view of knowledge, this is not very surprising; but standard AI in a way that does not take seriously the degradation of information systems often operate over time. They get certain memory of the machine and manipulated the formulae were true when will change enough during the conclusions were based are no longer valid. sensory inputs the process began, that are written down symbolically over time. Even if the stipulated in the semantics of that the world that the data on which it is entirely possible the course of the inference process Machines that manipulate symbols framework The situated-automata symbol manipulation. sized in symbolic symbolic representations systems. It is possible, of propositional The requirement can also be applied that perform that intended semantics match real ones is empha- that manipulates to computations in theory, to design a system information about the world in such a way that 156 S.J. Rosenschein, L.P Kaelbling/Artijicial Intelligence 73 (1995) 149-l 73 theory; is only symbolically written a proposition lational This can be achieved dynamics of the world, but it has proven very difficult that is, when those locations carry that same propositional information. through careful use of time stamps and axioms that describe the in memory when it is justified by the corre- in practice and is rarely done. illustrating of whether information. to consider, It is interesting in more detail, an example In the second approach, in some other there is an obstacle within there is an obstacle and if it is off, it is not known whether obstacle) two different ways In the first case, we dedicate a particular bit in a machine two meters of the agent; there is < 2 can be written those locations will carry as the single bit of the first example being on. In the first case, we to the so the location of the encoding of the bit is crucial. the values of the locations is encoded “by value”; of values of encoding to the representation if it is on, then an obstacle. (or symbols anywhere the same information say that the information representation of a single condition, In the second case, the information involved occurring at any location would carry the same information. are crucial, but that same combination in memory and, if the system that particular bit is devoted language with compositional is encoded “by location”; (robot, semantics) the symbols distance is designed properly, the information in representing To see how a correctly functioning symbolic consider correlational semantics, unary predicates (e.g., fully-charged, (e.g., robot 1, ba1137, by simple juxtaposition john, wa112). Sentences of symbols as in this sequence: a very simple red, tired, representation the correct system yields language with symbols of two types: and individual constants in this language could be represented distant) [fully-charged robot1 red ball37 tired jobn distant wall21 . of a value at a location, under a more standard Tarskian account, time-varying as these the unary predicates might denote mappings from time to truth (e.g., mappings propositions individuals (or perhaps temporally- is uniformly veridical, that is, it is true, then at the level of propositions, individual propositions to temporally-indexical While the correlational account of information assigns the meanings symbols might be interpreted differently: from individuals values), while indexical if the sentence the two semantics agree. Importantly, however, have attached Tarskian semantics be externally There is in memory only when that if the representation constants might denote that meaning individuals). stipulated. these Note framework would the situated-automata to the symbol sequence whether or not the designer had that in mind. In other words, the attribution of semantic content need not information cases). When quite efficient. Symbolic two kinds of representation the number of bits or atomic is clearly a trade-off between using locations used can be very small, making a whole spectrum of intermediate location, form of representation inefficient, represented. However, expressible mation by value, any proposition storing by location, on the other hand, each be thought of in advance by the designer of the machine compilation requiring many bits to encode syntactically these representations (and largely by this space- to be infor- in the language can be represented; when proposition must (or, as we will see, by a content are also very flexible. When storing the propositional are notoriously representations is represented information individual system). S.J. Rosenschein, L.P Kaelbling/ArtQicial Intelligence 73 (1995) 149-173 1.57 Per Fig. 3. Pure-action case. As observed above, when a location carries the information that P, so does every super-location; there is a minimal location that carries the information that P. We will say that information is localized to a minimal location that carries it. An especially important consideration in the decision between encoding by value and by location is the amount of work that must be done to localize important information. In order to take a particular action when P is true, the locations that control the effector must eventually carry the information that P; it is insufficient for that information to be encoded in some collection of locations in a uniformly-interpreted memory. The amount of work that has to be done to take the information that P and localize it into the effector bits, or any other location where it might be further combined with other information, can crucially depend on how it was initially represented. When information is encoded by value, it can often take many complex operations of indexing and pattern matching to localize; information that is encoded by location can often be used directly. Such considerations should guide the representational choices that are made in designing and building agents. 3. Designing agents Given the situated view of agents and environments as interacting automata and the circuit model of computation, we can build a design methodology for agents situated in dynamic environments. We first consider the case in which the agent has no internal state, then the case in which the agent monitors, but does not affect, the environment. We conclude by combining our design methodologies for an entire agent. 3.1. Pure action We begin by considering control in a very simple setting, namely stimulus-response systems that map current inputs to outputs without any dependence on prior inputs. At each instant, the inputs carry information about the immediate state of the environment, but the agent has no internal memory by which to distinguish otherwise similar states through residues of past experiences. In the automaton model, the state set of a stimulus- response automaton contains only one state, and inputs are simply passed on to the output relation. This is illustrated schematically in Fig. 3. Although stimulus-response agents are extremely limited, they are complete agents, nonetheless, and constitute a relatively easy-to-analyze starting point. By what criteria can a stimulus-response system, or any action-selection system, be judged successful? A natural way to answer this question is to relativize success to 158 S.J. Rosenschein, L.P Kuelblin~/Artrficinl Intelligence 73 (199s) 149-l 73 some stated goal specification families of control problems arise, depending on what is meant by the term “goal”. that is taken to be part of the problem statement, Different of variability One dimension in defining goals is whether the goals are fixed or dy- goals), action-selection mappings are evaluated to the entire trajectory of states they engender. To model an agent as pursuing dy- namic. With fixed goals (or design-time relative namic goals, on the other hand, assumes some method for defining moment-to-moment variations at least consistent with its current goals and information. logical situations where agents might preserve not to know.) in what the agent seeks. Even with dynamic goals, the agent is seen as having selecting actions subtleties arise in patho- rationality by choosing not to want or the fixed goal of acting that is, at each moment (Interesting rationally, in which it is expressed. Goals can vary in complexity Another dimension of variability to optimizing goal and the form of maintaining cates, while minimizing complexity to complex quantification, Because, simple environmental complex numerical energy, with complex can vary from a simple enumeration formulas in expressive logical and rich temporal operators. invariants, in goal definition arises from the complexity of the that from temporal predi- throughput the form of presentation, of states, for goals of maintenance, closed under Boolean operations, evaluation trade-offs). Regarding arbitrary (e.g., maximize to satisfying criteria languages, such as look-up includes notations in very simple cases), for specifying particular to try to develop universal of action-selection mappings in a suitable expressions, solution methods. Rather, it is preferable in extreme cases, agent synthesis can be intractable, it is not a reasonable to develop action strategies, and to develop an inventory in practica1 situations. As take many can for defining tables or data-flow rather than functional language, circuit descriptions, that can expedite agent construction the specification objective a methodology of solved special cases with goal specification, forms, direct and indirect. One family of direct methods functions of one or more input variables (only functional graphs. A related family of methods uses the calculus of relations expressions, the output and restriction enumeratively Rex [4,8] to primitive or in more compact is a language relation has been composed by applying operations in some cases with a determinization operator applied as the last step, after like union, of an action mapping and compiles circuitry. A Gapps program consists of a set of goal reduction (as well as machines with internal state) as abstract circuit descriptions. Rex served as a substrate for Gapps [ 5,7 1, it into fixed which rules, which run-time specify how a high-level goal is transformed low-level goal. When given a fixed goal to satisfy, the Gapps compiler generates a provably correct (input-to-output map) for that goal. A Gapps (though possibly partial) if it outputs an action, program in every it is appropriate if many situation. One of the main strengths of Gapps is its least-commitment low-level they are all returned as part of the result, actions which allows nondeterministic construction choice of action; that satisfy multiple goals. to the situation, but it will not necessarily to be correct, but not necessarily complete; output an action approach: to a more specific and simpler relations can be represented satisfy a particular goal, relations. The base-level this greatly simplifies takes a symbolic reactive program the compositional action mappings for specifying is guaranteed of programs specification intersection, either form. S.J. Rosenschein, L.Ff Kaelbling/ArtQicial Intelligence 73 (1995) 149-173 159 Although Gapps programs are specified using symbolic to do a great deal of the work, especially in desired outcomes. Gapps does not support rules, they still require the in determining what chains of the reduction of goals programmer actions will result into sequences of action, himself based on perceived derived from much more abstract specifications. so the programmer has to maintain any such commitments conditions. In many cases, we would like programs to be 3.1. I. Maintaining invariants through goal regression Indirect methods define the action-selection mapping by deriving it from some descrip- in the form of an explicit combinatorial such as operator descriptions and the goal, whether in classical AI planning algorithmically tion of the environment object like a graph, or in the form of declarative assertions, found be constructed we consider illustrated does not scale well with large state sets, it does introduce and build up intuitions A stimulus-response about properties of action strategies. agent be represented invariants as a nondeterministic the special case of agents that maintains that maintain systems. To illustrate how a stimulus-response from an explicit description of an environment invariants. Although agent can and goal, the method important concepts can be synthesized automaton as follows. (S, P, A, init, Y, out), Let the environment where l S is a finite set of states of the environment; l P is a finite set of outputs (these are usefully viewed as percepts from the agent’s perspective) ; l A is a finite set of actions l init is a set of states containing that the agent can generate as input to the environment; the one that the environment is known to be in initially; l Y is a relation on S x A x S where v ( SI, a, S.L) holds if it is possible for the world from state si to state s2 when action a is generated by the to make a transition agent; and l out is a function mapping S to P For the simple pure-action case, we assume that the environment automaton outputs its full state as output. and out is the identity S, that the agent A solution is to maintain to this problem to stay indefinitely, be made agent should as follows: the percept set P is identical to the state set S In other words, function on states. Let the goal be represented by G, a subset of as an invariant condition. is G*, a subset of G within which and a mapping from G* to A, specifying the environment the actions can the iteratively, take in order to stay within G*. The set G* can be computed Let Go := G For n = 0 to . . . Let G,+i = 0 For all g E G, If 3a.Vg’. u(g, a, g’) -+ g’ E G, then add g to G”+l When G, = G,+r, terminate and return G,. 160 S.J. Rosenschein, L.P Koelbling/Artijiciol Intelligence 73 (1995) 149-I 73 Each intermediate set G, is the set of states from which G can be maintained for at least n steps. For any state g E G, if there exists an action such that from every possible for n steps, then in state g, G can be maintained successor state g’, G can be maintained for IZ + I steps. This step is the weakest [ 131 precondition planning). When or Waldinger this process the set, G* of states from which G can be maintained In order to maintain G* from some state g, the agent can do any action a such that ‘v’g’.v(g,a,g’) under which G, can be made true on the next step (see Rosenschein [ 171 for a more complete description of regression-based reaches a fixed point, then we have determined is called “goal because G,,+i --+ g’ E G*. regression”, indefinitely. 3.1.2. Goal regression example Consider a simple domain in which a robot must keep plants alive by watering them. to water each plant and no-op, the action actions The action set of the robot contains the that does nothing. The state of the world can be expressed as a vector describing level of each plant, where 4 is wet (just watered) and 0 is dead. For example, moisture the vector is wet, the second in which slightly drier, and the third is dead. Moisture decreases by one every time step on which that die (reach moisture the plant is not watered. Plants (4 3 0) describes the first plant a situation We consider a situation “no plants are dead”; G is enumerated condition different orderings of plants deleted, because to the maintenance of this goal): level 0) stay dead forever. in which there are three plants and the goal is to maintain below (with equivalent the identity of the individuals the states under is irrelevant (4 4 4) (4 2 1) (2 2 2) (4 4 3) (4 1 1) (2 2 1) (4 4 2) (3 3 3) I 1) (2 (4 4 1) (3 3 2) (1 1 1) (4 3 3) (3 3 1) (4 3 2) (3 2 2) (4 3 1) (3 2 1) (4 2 2) (3 1 1) The G* resulting from the goal regression algorithm is: (4 4 4) (4 2 1) (4 4 3) (3 3 3) (4 4 2) (3 3 2) (4 4 1) (3 3 1) (4 3 3) (3 2 2) (4 3 2) (3 2 1) (4 3 1) (4 2 2) state in G’ is (3 2 1). By watering level The most constrained to (4 2 11, and then to (4 3 11, and then to (4 3 2). At this point, 1, it is changed to the original starting state is allowed, and the robot can rest, leading the no-op action of (3 2 1). Note that there are no states in G* with two plants at level 1 or three at level 2; although they are not in these states are in G (no plants are currently dead), G*, because to keep all the plants from dying the plant at moisture it is not possible in the future. 3.1.3. Discussion As mentioned above, increases, to handle this construction and this motivates run-time goals of achievement, does not scale well as the number of envi- the use of other representations. Although the declarative operator de- states used ronment ordinarily scriptions used in AI planning graphs, and can be used to drive the construction interpretable a more intuitively systems encode form of expression the same information as state-transition above. Operator descriptions provide and can often be manipulated more S.J. Rosenschein. L.P. Kaelbling/Arti$cial Intelligence 73 (1995) 149-l 73 161 Perception Fig. 4. The pure-perception case. efficiently because they refer to large subspaces of the state space with terse symbolic labels. Rather than calculating G* through enumeration, operator descriptions allow it to be calculated through symbolic regression. This may be more or less efficient that the alternative, depending on specifics of the problem domain. This technique has been implemented and explored as an extension to the Gapps programming system [ 61. 3.2. Pure perception Until now we have assumed that inputs from the environment are sufficiently informa- tive, in that they encode all the world-state information needed to drive action. In cases where less information is available, the inputs to action selection must be derived by accumulating partial information over time, and for this purpose additional machinery is necessary. We refer to this additional machinery as the “perception system” and explore its properties in this section. As in the case of action selection, it will be useful to approach perception by beginning with a study of the pure phenomenon. By pure perception we mean agent-environment systems in which the outputs of the agent have no influence on the environment at all, and the agent is simply a tracking system, or monitor: a passive observer, seeing, but not seen by, the environment. This special type of agent, again, will be of limited practical use but does illustrates the essential features of information extraction. The set-up for pure perception is illustrated in Fig. 4. The lack of influence of the agent on the environment cannot be depicted graphically; the environment’s next state function is independent of the output of the agent. The focus in analyzing the perception system is on the kind of correspondence main- tained between its internal states and states of the environment. This correspondence, in fact, is a form of invariant of exactly the type investigated in the previous section, but over the states of the agent-environment pair rather than just the environment. Even when the environment is indifferent to the actions of the agent, it makes sense to ask how the perception component might be designed to maximize the degree of correlation between its states and those of environment, hence maximizing its information. To see this most clearly, consider an environment, modeled once again as a nondeter- ministic automaton (S, P, A, init, Y, out). What is the maximum amount of information encoded in an instantaneous percept? In general, the best we can do is to associate 162 S.J. Rosenschein, L.t? Kaelbling/Art$cial Intelligence 73 (I 995) 149-l 73 it is compatible states with which inventory of internal amount of information that could be accumulated (i.e., with each percept p the set of environment about the those s such that out(s) = p). What is the maximum by the agent automaton over time? Given a rich environment track the enough states. Let environment 2 = powerset( S) be the set of internal states of the agent, with the agent in state gi if and only if every world state s t ~i is consistent with the agent’s perceptual history so far. The agent’s init, internal state u, the last and its transition action a, and the last percept p, into a new internal state, is given by initial state is the set of possible function N( (T, a, p) which maps the previous to the powerset of environment’s initial states of the environment, by having states isomorphic states, a pure-perception agent could optimally N(cr,p,a) = {s’ / 3s E v.v( s, a, s’) A out(s) = p}. This powerset automaton might be cumbersome, be optimal. indeed, but its tracking behavior would infeasible, information intersection. homomorphic are homomorphic images allow useful tracker. Nevertheless, approximations. Mathematically, to be monitored, while carefully states in the powerset automaton, through efficient but information-rich projections of the powerset automaton Although as the number of environment space and time, under the designer’s control. One simple approach states rises, the powerset construction quickly it is useful as a thought experiment because much of its value can be these images of the ideal powerset automaton, and thus are these trading to is to choose a set of and close these under union of the powerset function of the above, but becomes preserved approximations consistent with, but not as complete as, that ideal, or optimal, homomorphic off computational constructing interesting or significant and Boolean perception with the true powerset elements approximated For example, a successor of that lattice which best approximates Thus transition degrades gracefully with would represented function maps a state to the element instead. and themselves that could be is a lattice, which will be a sub-lattice transition state will be returned transition The then proceeds as in the case of the powerset automaton state that is not an element of the homomorphic-image typically be Cartesian products of simpler if in the original powerset automaton algebra. The construction lattices, with elements by least upper bounds function approximates as parameter vectors. of the representation. in the sub-lattice. the successor of the initial the precision the transition the optimal The result the lattice compactly state and function lattices system lattice, This technique forms the basis of the RULER system [ 151. RULER takes an approach is described that are including that describe conditions in many ways to AI planning synthesizes perceptual machinery systems. In RULER, the environment analogous by a set of assertions, temporal assertions either true initially or that will be true in the next state, depending on current conditions. The RULER compiler function) constructing parameters of interpretation space under intersection, to a compositional methodology initial state and next state toward not with a view descriptive in the next state’s world model. The use of lattices as the semantic domain the parameter to be folded in nicely and leads of the model parameters, allows incremental individual but rather with a view perceptual update mechanisms. along with effectively closing by chaining action (an assertions, toward computing for constructing information sequences, together these S.J. Rosenschein, L.P. Kaelbling/Art@cial Intelligence 73 (1995) 149-173 163 3.2. I. Ruler compilation carried by the run-time RULER'S compilation method works as follows. The compiler tion of information variables, as well as a background The compiler operates by deriving will be true at any time, given what was true at the previous derivation, From updating a state vector with the desired takes as input a descrip- state the world. theorems about what is true initially and about what time. In the course of the systems. and in the manner of logic programming to the program and the internal free variables are instantiated extracts a program theory containing the instantiated for initializing the compiler informational facts about formulas, temporal inputs properties. inputs consist of the following: the compiler’s More precisely, 0 a list [al, . . . . a,] of input 0 a list [bt,..., l for each input l for each internal b,] of internal locations, state locations, location a, a formula P,(U) with free variable U, location b, a formula Pb( U) with free variable U and a function Konjb, l a finite set r of facts. The formulas Px( U) express propositions parameterized by 17, where U ranges over run-time values of location X; for example, PM(~) might denote “current soil mosture level > 6”. These values are drawn from a lattice so that degrees of partial information can be represented. The rconj operations values and combine content as precisely values in the natural way.) Using formulas implicit compiler. that take a pair of lattice their conjunctive to sets of lattice that were merely by the rconj in this way, the propositions are binary lattice value summarizing of the machine can be made explicit and manipulated (The rconj* operation extends them as possible. in the information into a single functions For each internal ib and Nb defined as follows “necessarily always”) : location b, the compiler computes (the 0 symbol is the temporal two sets of runtime value terms logic operator representing lb = {e ( r t q init &(e)}, h$,={f?‘I rttl(P,,(al) r\...r\Pb,,(b,) +?WXt Pb(e’))}, so ZM = (0). If our lower bound on moisture decreases 1 where e’ = f( [al,. . . ,a,], [bl,. . . , b,] ). If we are initially we might have only OPT, per time step, then we might have q l( PM(~) + next PM( n - 1) ) . Each set Ib contains terms representing to hold that can be proved initially that hold now as represented by the values of the to hold “next”, given input and state and used incrementally. that can be proved from the background terms in the world. Each set Nb contains This is discussed more fully below. If these sets are infinite, ignorant of soil moisture, they can be generated for properties the properties properties locations. theory r From these collections vector, uc, and its update function, of sets the compiler computes the initial value of the state f. The initial value is computed as follows: 164 S.J. Rosenschein. L.P. Kaelbling/Artijicial Intelligence 73 (1995) 149-I 73 the initial value of the state vector In other words, by rconj-ing values compiler about the initial state of the environment for the next state function: components. representing Similarly, the strongest propositions is the vector of values derived that can be inferred by the in the “language” of each of the state f([Q*. ..,~l,[h~...,b,,l) = Lrconj;l,(Nb,),...,rconj;jn(Nb.,)l. Without operators restricting containing that denote the execution are available. the background that will be used the strongest proposi- be nested expressions time of these operators Here the compiler constructs a vector of expressions tions about what will be true next, again in the language of the state components. at compile the rconj values can be computed In the case of the initial value, time In the case of the next state time. Rather, to the values of all the arguments the rconj terms will not denote values known at compile because function, however, they will generally compute values at run time. Assuming is bounded, the depth of the expressions will provide a bound on the update time of the state vector. that the sets Ib and case the finiteness of terms in the time can be the synthesis procedure exhibits the more This al- longer; to be achieved simply by running the procedure at any stage will still yield a correct program, although not nec- available. Since, in general, the program attuned approach would resources consumed and halt when some Nb will be finite. However, even in the unrestricted language guarantees computed strongly monotonic information we can ascribe lows incremental stopping essarily additional rconj operations consume be to have the compiler keep track of run-time resource the more elements of It, and Mb we compute, the environment. elements we can derive at compile time at run time. Furthermore, to the most specific information theory, we cannot guarantee resources, one reasonable that whichever improvements the compiler in bounded to run-time is reached. regarding behavior: locations run-time limit As we have observed, without placing it is obvious the background specify be practical; synthesis problem not only other stylized formalisms theory r, that environment-description restrictions on the symbolic language used to the synthesis method described above would hardly the languages but undecidable. However, as with Gapps and to certain style, by restricting exist that make ourselves intractable in the logic programming languages, practical synthesis techniques can be developed. language language and tractability. This restriction We have experimented with a restriction of the logical between expressiveness that seems to offer a is to a weak resembling Prolog but with the addition of init and nRvt good compromise temporal Horn-clause operators. The derivation process proceeds as described above using backward-chaining deduction implementing the Horn-clause language differs from Prolog time expressions. Compile-time and used expressions, run-time final program. The RULER system was run on several small examples tracking and aggregation, implementation. techniques as the specific form of inference. A prototype system has been built version of the synthesis algorithm. One of the ways the and run- in the ordinary manner; expressions undergo unification are simply accumulated the to generate involving object in our test is in the strong distinction between compile-time and the synthesis procedure has proved by contrast, tractable S.J. Rosenschein, L.I? Kaelbling/Artificial Intelligence 73 (1995) 149-173 165 Using off-line synthesis techniques, be recognized with limited machinery, the “reactive” bias to admit sophisticated care, the designer clarify can be generated response. the semantics of the domain by the compiler conditions and for this reason that are semantically semantic information complex can still it is entirely consistent with and models. With some forms can be used to representation, to guarantee and finite parametric bounded-time representations updates and real-time can have the best of both worlds: declarative 3.2.2. Ruler exumple This section sketches out a simple example of a pure-perception system synthesized by the RULER system. Imagine now concerned with constructing as much representation an interval, the plant. This gives us our first rule, as it can about representing information known that we again have a plant-watering its perceptual system so that it maintains, robot, but we are at all times, level of a collection of plants. The so we use uncertainty, level of lower and upper bounds on the true moisture the moisture used by the system must be able to accommodate moisture (p, CO, maxI> . which states that level. Additionally, moisture level from its sensor: the moisture of plant p is always between 0 and some maximum if the robot is at the plant, it can get an approximate reading of the moisture(p, Cv-l,v+ll) (p, 1) , at-plant moisture_sensor(v). :- is being sensed. In this case, there is an input bit, a, such that at-plant (p, 1) term requires The at-plant moisture The robot has been constructed known will treat other propositions similarly. that the robot know that it is at plant p at the time the (n, a>. is to be at that plant. We in such a way that if a has value 1, then the robot to be at plant n; if it has value 0, the robot is not known The dynamics of the world are specified rules. If we know that the robot’s last action was not to water the plant (either because we know it didn’t water or (perhaps because we know it wasn’t at the plant), due to rain) or decrease by 1: then the moisture may either increase in terms of next next moisture(p, Cl-l,h+l]) :- not-watering(l), moisture(p, next moisture(p, not-at-plant moisture(p, [l,h] > . [l-l,h+l]) (p, 1) , [l,h] > . :- If we know that the robot did just water the plant, maximum level: then the moisture will increase to its 166 S.J. Rasenschein, L.P Kuelbling/Artijicial Intelligence 73 (1995) 149-I 73 next moisture(p, [max,maxl> :- at_plant(p, watering(l). I>, the plant it watered or because we don’t know whether the robot watered If we don’t know whether whether spread quickly: (either because we don’t know the bounds it was at the plant), next moisture(p, Cl-1 ,maxl> : - moisture(p, [l,h]). that the last rule does not conflict with other rules Note on the moisture. We combine moisture. set of rules results moisture of the plant, given its inputs and the specified representation. tighter bounds an rconj rule for the intervals. Running RULER on this the to intersect that retains as much the results of these rules by specifying In this case, it is simply as possible about that provide in a circuit information 3.2.3. Objects, properties, und relations adequate domain models, RULER is limited for generating provably correct perceptual for modeling worlds importance. This is the case, for example, While conceptually at least for nonprobabilistic provision of special move scene concerns observer. To begin to address domains of this type, we developed an information-update schema we named Percm. subsystems, in that it makes no special in which objects and their properties and relations are in visual perception where objects to be extracted from the to one another and to the the identity of objects and their spatial relations in and out of view, and a prime form of information tracked and described. The descriptions The Percm schema can be thought of as a specialized binary is being set of objects as labeled graphs, with node labels representing finite, but shifting, represented and edge labels representing agent, and the rest of the objects can vary, moving scheme bears some relationship Chapman and Agre for Pengi, but with rigorous correlation-based and edge labels are drawn just as in the RULER case, only now of properties conjunction and relations) type property or relation, or to be coercible of semantic from a space of data values to the indexical-functional form of RULER in which a are unary properties of objects, is the focus. This developed by semantics. The node lattice elements, is fixed (i.e., a fixed to be representations representing the propositional matrix and the lattice elements are constrained relations between objects. One of the objects in and out of attentional to such values. Fig. 5 shows the basic runtime data structures that underlie a Percm with n elements. is a vector of length n, each of whose elements contains index 1 is reserved for the agent. In addition, the unary properties of there in which cell (i, j) contains the strongest representable information the relation between objects so that only i and j. In many cases, the relations will the upper triangle of the matrix needs There the ith element being tracked. Often, is an II x n matrix available be symmetric to be explicitly (or canonicalizable) represented. about The update cycle for this data structure is similar context, fixed background descriptions of the environment to RULER'S, but in the Percm are provided not in the form S.J. Rosenschein, L.P Kaelbling/Arti$cial Intelligence 73 (1995) 149-173 167 Properties Relations pi p, p3 P” E Fig. 5. Data structures supporting an instance of the Percm schema with n objects. strengthens properties and relations among objects x and y by deriving from existing properties and relations between each of x and object properties and relations. This information transitions, but rather as rules, both temporal is built the data structures. These operations are: inferable from l of propositional and atemporal, into . assertions about world-state for computing a set of operations used to update create: maps an input value to initial object properties and relations that input; propagate: what can be inferred y and some third object, z; merge: combines descriptions that they are identical; imply aggregate: tence of constituent initializes y’s description based on descriptions degrade: maps properties t+ 1. creates a new object y whose existence can be inferred at time I to new values of objects x and y if their properties of constituents; and relations from the exis- objects nt , . . . , x, with appropriate properties and relations, and inferable for time and relations system and iterating approximations. The perceptual is synthesized by composing the object descriptions, with values again drawn to to obtain grace- update size, to fully degrading complete the designer must also define how, in the case of object over-how, objects are to be discarded or withdrawn from active attention. Circuitry size. Operations of bounded a very shallow circuit with size O(n). to keep the data structures updated can be large, but is like finding an empty cell for a new object can be done in from lattices is a finite schema of bounded of an instance of the Percm schema, the specification these operations Because Percm 3.2.4. Percm example In order to illustrate of its operation. A mobile a representation the ideas behind robot, traveling the Percm schema, we present a simple example needs to construct through a new environment, of the salient objects and their spatial relations. The robot might begin by perceiving, instantaneously, that there are two objects in 168 S.J. Rosenschein, L.!? Kaelbling/Artificial intelligence 73 (1995) 149-I 73 front of it: a chair and a person. stores some of their unary properties hair-color of the person) between each one and the robot in Rt.2 and Rt,s. them indices 2 and 3, (such as type and color of the chair, gender and in cells P2 and P3, and stores bounds on the spatial relations It creates two objects, assigning a propagate Immediately, relations between objects 2 and 3 and store it in cell R 2,~. These objects can be neither merged nor aggregated. can compute bounds on the spatial operation Finally, typically has good local odometry in the degrude step, knowledge about the generic motion abilities of chairs and people, as well as the current motion of the robot, is used to degrade the spatial relation information. The robot so it knows how much it has moved relative these objects and can update RI,Z and R1.3 accordingly. static, objects, but still retain precise other. However, the bounds on all spatial person could potentially move in any direction, it was in when it first perceived If both of these objects were to the to each in this case, people are far from static, so the degrade step will increase the about the relation of the objects the robot could wander away and become confused the person and other objects, because relations between to the position information), its relation information (motion about On the next cycle, is able to measure the robot again sees the person, but because of its changed the person’s height. This person gets created as object is able to infer two people were not (and perhaps because that objects 3 and 4 must really be the same. They are merged them in a index. The other index is marked as free. Now, the height and hair color are both perspective, 4 in the Percm data structures. This time, on the merge step, the robot that, because of their close spatial positions seen simultaneously), by conjoining single known about a single person. The aggregate operation their properties and their relations to other objects and storing is useful when entire complex objects cannot be perceived individually to identify a large truck might instantaneously. identify wheels, a cab, and a flat bed, then aggregate Thus, a robot attempting them into a truck object. As the data structures begin way. Objects may be purged because by a complex object, or for a variety of attentional goals. to get full, it will be important their information to purge items in a useful is weak, or they are superseded reasons based on the robot’s current 3.3. Combined perception and action The techniques illustrated in the two previous sections can be combined using control both perception systems containing and action components. the Gapps approach, one could develop mappings to synthesize instance, states to actions, where the information synthesized among design decisions needed for the two subsystems, state of the agent would act as a clean interface, and the combined the intended behavior. In general, however, explore the RULER or Percm methodologies. the nature of those interactions there are interactions, information subsystem If there were no interactions the definition of the information system would exhibit and in this section we from states are the output of a perceptual and potential methods of dealing with them. using directly For S.J. Rosenschein, L.P. Kaelbling/Art$cial Intelligence 73 (1995) 149-I 73 169 The first problem is the specification of the information-state interface between the that the perceptual two modules. This problem exists even when the perceptual mechanism It is possible information available, but is encoded complexity. for the goal to be satisfied. Another difficulty arises in such a way that the localization machinery the environment inputs from is degenerate. do not provide enough is if the information is of intractable The design of the system becomes much more complex when affect the information attention must be given strategies, in the environment action the flow of information the agent choosing maintain acted on. In AI, this problem often goes under problem is appropriate; action [ 111: it is not enough is appropriate. necessary to be in an environmental for distinguishing the agent must know that it is in an environmental the actions taken by that will be available to it. When to how actions chosen now will among future states to be the label of the knowledge precondition state when a certain action that state in which The problem grows more complex when perceptual machinery distills information In state. the goal information to affecting in the sensory the agent’s own input stream, and still more complex when contained pertains structure of the perception module is, from module, part of some external environment whose dynamic properties are critical success or failure of its strategy. Unfortunately, without elaborating of the perception module and hence no valid action strategy can be chosen. to satisfy information perceptual machinery, perceptual machinery. goals can only coherently be developed in the context of articulated or, at least, to the the internal structure cannot be made, intended in the context of fixed the assumptions first, statements of fact about this environment the point of view of the action-selection itself the internal In general, action strategies these cases, about into the perception then, would be to design in the passive sense introduced to be tracked and defining update circuitry that will force it to the right state. After defining A natural development methodology, conditions first, choosing conditions the input streams an action strategy can be defined, as if it were part of the environment. flowing component makes use of constraints module. domain descriptions, both modules. description-like seek information. The RULER rules generate a perceptual invariant, correlations with conditions can involve a search, albeit at design tracked. the perception module these that tracks in the previous section, but does not guarantee this fixed machinery, relying on the definition of the perception component input streams states and actively chosen structure of the perception from declarative should suffice to generate rules, combined with operator- that to generate systems as an that maintains, system that the action system needs to test. This approach that can be effectively time, for suitable conditions imposed by the previously In principle, when perception and action modules are generated This strategy to drive it into the appropriate In other words, RULER-like state-transition a single set of facts about the environment contain enough constraints action descriptions, is designed to cause In all of these approaches, the result is an automaton with an objective informational to its environments, This is unlike relation and post-conditions to their environment have been analyzed using only through stipulated the usual case in AI, in which knowledge pre- that link internal states of agents relations attributed by semantic-denotation theories 170 S.J. Kosenschein, L.P. Kaelbling/Artijiciul Intelligence 73 (I 995) 149-173 designers encouraging tional AI planning and potentially somewhat arbitrarily to symbolic data. This distinction that many of the same semantic desiderata and representation systems can be achieved far more efficient, control-theoretic setting. is substantial, that have been pursued and it is in tradi- in a more mechanistic, A final area of complexity is the pervasive uncertainty found in natural environments. conservative and machines to information to avoid committing this work, we have modeled uncertainty using simple nondeterminism. While Throughout they do not this allows designers regard all alternative possess, these models are extremely In real task states that are not ruled out by hard constraints than others, and this domains, however, some of those alternatives that is midway fact is essential between deterministic in which state transitions, under a given input, are described by probability distributions. A natural mathematical model is the Markov process, which has been studied for such systems extensively by applied mathematicians. to be of equal are far more likely of the information. A model and nondeterministic models is the probabilistic model to the proper exploitation in that they importance. leads conditioning to use that module on further evidence, that a designer cannot, of probabilities, which technique. By conditioning together with the symbolic The difficulty above semantics of the first module. Furthermore, can either be reduced or increased. This means on the joint states of the modules may completely in using probabilistic models is the nonmonotonicity techniques to noncomposi- described the probability of tionality of the design in a proposition prove a strong statement about general, define a module of the perceptual component, together with other the semantics of its outputs, and then proceed undermine modules; the action strategy embodied the intended in the action-selection state- transition matrix of the entire system. Just as before when we could not, in principle, define an action strategy before providing a fixed definition of the perception component, here we cannot define apparent circularity integrated whole; mined only when all the boundary and incremental modeling sion processes controllers action first. The the agent as an is deter- Interim constraints refinement may be useful, but must be used cautiously, especially when theory of partially observable Markov deci- for deriving component without constraining to consider the behavior of the entire system, agent plus environment, [ 1,9] provides a theoretically well-founded methodology in stochastic domains, but it seems to be computationally to the definition of the probabilistic domains probabilistically. have been specified. to the fundamental very intractable. the perception only points component is integral conditions need The 4. Conclusions theory The aim of situated-automata is to provide a new semantic perspective on agents. Traditional AI has been dominated by “reasoning” metaphors drawn intelligent linguistic from folk psychology of action. elements, drawing conclusions The semantics of these systems have been made rigorous, but are almost always imposed traditional models have often failed to explain how so much by their designers. Moreover, architectures “reasoning” are seen as actors manipulating representations can get done so fast with so little hardware. Reactive-agent from premises, and constructing in which programs bolic systems; interpretation program specifications The shift from S.J. Rosenschein, L.P. Kaelbling/Art@cial Intelligence 73 (1995) 149-173 171 have been proposed as an alternative for this work have been less developed. to traditional AI, but to date theoretical foundations Situated-automata theory provides a semantic analysis of information processing that is of machine state or computational models based on run-time to apply to all embedded control systems without requiring designer-conceived intended interpretations It is based on a direct mathematical model of how the states of natural processes, the ways they unfold over time, reflect one another and correlations semantic precision that are not structured as conventional seem to “reason” excluded the logic-based AI to the analysis of systems intricate cross-dependencies states. The theory brings that give rise to semantically meaningful they are simply a special case. systems at all. Nor are systems from this style of analysis; associated with traditional inference. reasoning through that do in Note that none of this analysis is inconsistent with the construction it simply makes explicit to be valid and provides methods the constraints of agents as sym- that must hold for their intended for using symbolic characterizations as rather than as an implementation strategy. traditional in describing symbolic AI) is not “reasoning” of early cybernetic In this view, the fundamental from by an agent. but the mutual constraint system over time. The key lies in understanding the traditional AI view to the situated view brings us to an outlook subtlety and feedback models, but with more semantic being to be exhibited between parts of a how a process can naturally states questions can be modeled and grasped, for the environment while perhaps blurring others, and how can this be done in reminiscent sophistication (derived tracked and controlled explained physical mirror ripple out to overt actions include how the enormous how computational controlling real time with high reliability using relatively modest computational that eventually set of discernible achieve goals. The fundamental in its states subtle conditions conditions phenomenon and how these mirroring to preserve distinctions in its environment can be arranged that matter conditions resources. elements While the analytical approach presented here is very general the use of stylized off-line to synthesis problems and to the design of particular In this paper we have attempted involving time machinery with desired properties of information be done on the integration and exploitation techniques presented here. of automated of statistical covariance in scope, its application systems remains quite challenging. to sketch directions we regard as promising, primarily run- to and control. Work remains to generate reasoning symbolic tractable learning in ways analogous techniques as well as the modeling logic-based to the discrete Acknowledgments We derived a great deal of help and inspiration from our colleagues over the years robot platform, and of this project. Stanley Reifel built Flakey, an experimental mobile in elegant constantly formulas. Sandy Wells brought a knowledge of computer vision, hardware, and hacking that was invaluable. Nathan Wilson endless versions of and variations on implemented code for Flakey. Stuart Shieber was a valuable Rex and wrote some crucial navigational software what we derived us to match in working challenged 172 S.J. Rosenschein, L.F? Kuelbling/Arti$cial Intelligence 73 (I 995) 149-l 73 language, through both language modules natural influence theory. David Chapman adjunct to the group and implemented Fernando Pereira was an important automata a much better Ruler and some of its precursors. We are generally our colleagues University’s Center for the Study of Language and Information, We gratefully sponsors at the Defense Advance Research Projects Agency, and Space Administration, Research, and FMC. for the robot programs. of situated- on the early development spent some summers with us and helped make Rex He also worked on of at Stanford and at Teleos Research. as well as from the National Aeronautics the Air Force Office of Scientific Research, General Motors Intelligence Center of SRI International, to and appreciative at the Artificial implementation. acknowledge ideas and institutions indebted financial support these from References stochastic environment, in: revised III 121 131 141 I.51 161 Introduction ( 1984) 50-61; IBM RJ 4421. in partially observable and M.L. Littman, Acting optimally in an distributed Computing in: Proceedings AAAI-94, Seattle, WA ( 1994). and common knowledge of Distributed and Y. Moses, Knowledge Third ACM Conference on Principles A.R. Cassandra, L.P. Kaelbling domains, J.Y. Halpem Proceedings version: G.E. Hughes and M.J. Cresswell, An 1968). L.P Kaelbling, Rex: a symbolic systems, L.P. Kaelbling, Goals as parallel program MN (1988). L.P. Kaelbling, Compiling operator descriptions Report, Teleos Research, Palo Alto, CA ( 1991). L.P Kaelbling 6 ( I ) ( 1990) 3.5-48; also in: P Maes, ed., Designing Autonomous Agents: Theory and Practice Biology in Aerospace, Wakefield, MA (1987). in: Proceedings AAAI-88, Minneapolis-St. in: Proceedings AIAA Conference on Computers and Back (MIT Press, Cambridge, MA, 1991) and S.J. Rosenschein, Action and planning the design and parallel to Modal Logic implementation specifications, to Engineering language for into reactive strategies using goal regression, Technical in embedded agents, Rob. Autonomous Syst. Paul, from (Methuen and Company, London, of embedded L.F? Kaelbling and N.J. Wilson, Rex programmer’s manual, Technical Report 38 IR, Artificial Center, SRI International, Menlo Park, CA (1988). W.S. Lovejoy, A survey of algorithmic methods for partially observed Markov decision processes, Ann. Intelligence from the standpoint of artificial intelligence, 4 (Edinburgh University Press, Edinburgh, in: J.R. Hobbs and R.C. Moore, eds., Formal and action, problems Intelligence Oper. Res. 28 ( 1) ( 1991) 47-65. J. McCarthy and F?J. Hayes, Some philosophical in: B. Meltzer and D. Michie, eds., Machine 1969). R.C. Moore, A formal theory of knowledge Theories of the Commonsense World ( Ablex, Norwood, NJ, 1985). A. Newell, The knowledge level, Artif: S.J. Rosenschein, Plan synthesis: a logical perspective, reprinted Mateo, CA, 1990). S.J. Rosenschein, Formal 345-357. S.J. Rosenschein, Proceedings Toronto, Ont. ( 1989). S.J. Rosenschein properties, and L.P. Kaelbling, The synthesis ed., Proceedings in: J.F. Allen, J. Hendler and A. Tate, eds., Readings Infell. 18 (1982) 87-127. theories of knowledge information-tracking in: J.Y. Ha&m, on Principles Synthesizing International Conference in: Proceedings IJCAI-81, Vancouver, BC ( 198 1); (Morgan Kaufmann, San in Planning in Al and robotics, New Gen. Comput. 3 (4) (1985) from environment automata of Knowledge Representation in: descriptions, and Reasoning, epistemic of digital machines with provable of the Conference on Theoretical Aspects of Reasoning I71 181 I91 I101 Ill [ 12 ( 13 I141 1151 1161 S.J. Rosenschein, L.P Kaelbling/Artificial Intelligence 73 (1995) 149-l 73 173 About Knowledge (Morgan Kaufmann, San Mateo, CA, 1986) 83-98; updated version: Technical Note 412, Artificial Intelligence Center, SRI International, Menlo Park, CA. [ 171 R.J. Waldinger, Achieving several goals simultaneously, in: E.W. Elcock and D. Michie, eds., Machine Intelligence I3 (Ellis Horwood, Chichester, 1977); reprinted in: J.F. Allen, J. Hendler and A. Tate, eds., Readings in Planning (Morgan Kaufmann, San Mateo, CA, 1990). 