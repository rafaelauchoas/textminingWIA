478ANDERSON et al., Issues in Research Data ManagementResearch Paper (cid:1)Issues in Biomedical Research Data Management and Analysis:Needs and BarriersNICHOLAS R. ANDERSON, MS, E. SALLY LEE, MS, J. SCOTT BROCKENBROUGH, PHD, MARK E. MINIE, PHD,SHERRILYNNE FULLER, PHD, JAMES BRINKLEY, MD, PHD, PETER TARCZY-HORNOCH, MDA b s t r a c t Objectives: A. Identify the current state of data management needs of academic biomedicalresearchers. B. Explore their anticipated data management and analysis needs. C. Identify barriers to addressingthose needs.Design: A multimodal needs analysis was conducted using a combination of an online survey and in-depth one-on-one semi-structured interviews. Subjects were recruited via an e-mail list representing a wide range ofacademic biomedical researchers in the Pacific Northwest.Measurements: The results from 286 survey respondents were used to provide triangulation of the qualitativeanalysis of data gathered from 15 semi-structured in-depth interviews.Results: Three major themes were identified: 1) there continues to be widespread use of basic general-purposeapplications for core data management; 2) there is broad perceived need for additional support in managing andanalyzing large datasets; and 3) the barriers to acquiring currently available tools are most commonly related tofinancial burdens on small labs and unmet expectations of institutional support.Conclusion: Themes identified in this study suggest that at least some common data management needs will bestbe served by improving access to basic level tools such that researchers can solve their own problems.Additionally, institutions and informaticians should focus on three components: 1) facilitate and encourage the useof modern data exchange models and standards, enabling researchers to leverage a common layer ofinteroperability and analysis; 2) improve the ability of researchers to maintain provenance of data and models asthey evolve over time though tools and the leveraging of standards; and 3) develop and support informationmanagement service cores that could assist in these previous components while providing researchers with uniquedata analysis and information design support within a spectrum of informatics capabilities.(cid:1) J Am Med Inform Assoc. 2007;14:478 – 488. DOI 10.1197/jamia.M2114.IntroductionRapid advances in analytical technology coupled with wide-spread access to large amounts of highly detailed, heter-ogeneous and often public biomedical research data havedramatically increased the difficulties faced by biomedicalAffiliations of the authors: Division of Biomedical and HealthInformatics, Department of Medical Education and BiomedicalInformatics (NRA, ESL, MEM, SF, JB, PT-H); Department of Biolog-ical Structure (JSB, JB); Health Sciences Libraries and InformationCenter (MEM, SF); Department of Health Services, School of PublicHealth and Community Medicine (SF); Department of Pediatrics(PT-H); Department of Computer Science and Engineering (JB,PT-H), University of Washington, Seattle, WA.The authors would like to thank and acknowledge National Libraryof Medicine Training grant (Biomedical Health Informatics trainingprogram) T15LM07442, the BioMediator grant R01-HG02288, BISTIplanning grant P20-LM007714, and the Human Brain Project grantDC02310 for providing the funding to support parts of this work.Correspondences and reprints: Nicholas Anderson, University ofWashington, Department of Medical Education and BiomedicalInformatics, Boxe-mail:357240,(cid:1)nicka@u.washington.edu(cid:2).Seattle, WA 98195-7420;Received for review: 3/29/2006; accepted for publication: 3/27/2007.investigators in acquiring, archiving, annotating, and ana-lyzing data.1 Recognition of this fact is reflected in a numberof large scale initiatives by the major U.S. funding institu-tions as well as a profusion of software tools designed forbiomedical research data management and analysis.1–5 Overthe past several years we have met with many academicbiomedical researchers to discuss solutions to their datahandling problems as part of our own data integrationefforts.6 –12 Through informal discussions, we have beenstruck by the frequency with which they stated that: a) adata handling problem had become a major barrier to theprogress of their research, b) available computational solu-tions were prohibitively expensive, c) available solutionswere too complex for their needs, and/or d) computationalsolutions to their problem did not exist at all. In addition, wehave noticed that the needs of investigators can be extremelydynamic, often changing on a weekly basis. From a biomed-ical informatics standpoint, these issues raise several funda-mental questions:• How are researchers coping with managing these quicklyevolving information management problems in practice?• What obstacles are faced by researchers seeking individ-ual solutions to data management and analysis needs?lDownoadedfromhttps://iacademc.oup.com/jli////amaartice144478788143byguest/on03Juy2023l    Journal of the American Medical Informatics Association Volume 14 Number 4July / August 2007479• To what extent can biomedical research data handlingneeds be generalized across more than one lab (or evenmore than one project within a lab)?• What core design issues must be addressed in designingand implementing informatics solutions to aid biomedi-cal researchers in their data management and analysis?To address these questions, we have embarked on a project toidentify the data management and analysis needs of academicbiomedical researchers at the University of Washington.BackgroundInformatics journals report a steady stream of freely avail-able analytic and archiving tools with the potential tostreamline data analysis and integration tasks.6,8,10,13,14 Yetbiomedical researchers continue to struggle with increasingvolume and complexity of their own datasets. Accurate andthorough needs analysis is widely recognized as one of theearliest and most crucial events in virtually all softwaredevelopment cycles. For example, needs analyses for avariety of applications are frequently reported in softwareengineering15–20 as well in the medical fields.21–26 However,few attempts to assess the needs of biomedical research existin print27 despite recent calls for increased evaluation-basedscience to support informatics research.28 –30 We feel thatevaluation-based assessment of data management and anal-ysis needs of biomedical research is a crucial informaticsresearch area.Through our examination of existing methodologies de-scribed in the literature,21,31–37 we have concluded thatmutually supportive data resulting from a mixed methodsapproach has the greatest potential to support a comprehen-sive biomedical research needs assessment. Our approach isto use broad web-based surveys followed by personalizedin-depth interviews. The surveys were targeted toward alarge population of biomedical researchers to provide broadoverviews of generalized needs; however, surveys are lim-ited in that they don’t allow the elicitation of informationthat was not understood or imagined by the authors of thesurvey but is important to the respondents. Therefore, inaddition to the quantitative survey data, we gathered highlydetailed and context-specific qualitative data from individ-ual interviews. The semi-structured interview data not onlyprovided detailed contextual information, but helped revealideas that can be transferred to other domains.17,18,21,38 – 40Combining qualitative and quantitative methods has al-ready been successfully used in the discovery of user issuesassociated with the implementation of clinical ElectronicMedical Records (EMR) systems.36,37,41In this paper, we present the results of the survey and theinterviews in a combined analysis framework that we hopeto use in future biomedical research needs assessments.Using this multi-modal method, we describe the needs ofbiomedical investigators affiliated with the University ofWashington. The UW is an internationally recognized re-search university that was recently ranked #17 in the worldby the Economist newspaper.42 UW research supported over7,400 full-time equivalent positions in fiscal year 2005.43 Asa result, we feel that this study, though limited to one univer-sity and its local collaborator research institutes, can be appli-cable to other academic biomedical research settings.MethodsWe focused our assessment on data management and analysisneeds, including: a) current strategies for management andanalysis of experimental data, and b) obstacles to data man-agement and data sharing. A survey of 286 faculty, researchstaff, and students yielded quantifiable and moderately de-tailed data about informatics software needs. Fifteen volun-teers from this population were the subjects of semi-structuredinterviews. We conducted qualitative analysis on the interviewdata that represented in-depth views of individual needs.Human SubjectsTo ensure the safety and anonymity of the participants, allaspects of this research including participants in both thesurvey and the subsequent interviews were approved by theHuman Subjects Committee of the University of WashingtonInternal Review Board (IRB).SurveyThe survey consisted of two separate sections that togethertotaled 36 questions (See Appendix A, available as an on-linedata supplement at www.jamia.org). Twenty-three of thesequestions addressed a variety of library and informationscience issues and built on previous UW work from Yarfitzet al. involving library-based bioinformatics services.31 Thissurvey is part of a process of continuous evaluation ofbioresearch needs from both the academic research andinstitutional support perspectives. Of the 13 questions focus-ing on biomedical research information management needs,four questions related to subject demographics, with theremainder focusing on high-level overviews of generalizedneeds across biomedical research disciplines. Here we reportprimarily on data from the needs-related questions as wellas a limited set of data from the library and informationscience questions that have overlap with biomedical needs.More in-depth discussion of the library-service aspects ofthe survey will be published elsewhere.We pre-tested the initial survey with six volunteers activelyengaged in biomedical research who were also asked to givetheir opinions regarding survey length and question clarity.The survey was then deployed online via WebQ, an auto-mated survey and response analysis tool within the Univer-sity of Washington Catalyst system.44,45 Invitations toparticipate in the survey were sent out to 1,754 addresses inthe spring of 2005. The addresses were obtained directlyfrom an “opt-in” UW Health Sciences Center Library list46and were of researchers at the UW and collaborating re-search institutions in the Seattle area who are interested inbioinformatics resources and are actively involved in bio-medical research. We estimate that the e-mail list representsapproximately 30% of the active biomedical researchers inthe Seattle area. The survey was left online for 7 weeks with“reminder” messages sent via e-mail every two weeks to anyaddresses that had not yet responded.InterviewsUpon completion of the survey, respondents were solicitedto volunteer for one-on-one interviews. A total of 15 re-searchers volunteered for semi-structured interviews, whichwere conducted in the summer of 2005. Each interview beganwith a “critical incident” question38,47 followed by other rele-vant questions about data handling and analysis needs specificto that individual. All interviews lasted between 45 and 90lDownoadedfromhttps://iacademc.oup.com/jil////amaartice144478788143byguest/on03Juy2023l    480ANDERSON et al., Issues in Research Data ManagementlDownoadedfromhttps://iacademc.oup.com/jli////amaartice144478788143byguest/on03Juy2023lF i g u r e 1. Primary roles by percentage of respondents.minutes and were audio taped and transcribed with thevolunteer’s consent. The content of the transcripts (190 pages)were analyzed using ATLAS.Ti 5.0 software. Emerging pat-terns and themes were individually identified by two of theauthors experienced in qualitative methods (NRA, ESL), thentriangulated with input from the third author (JSB). Thisapproach to triangulation and inter-coder reliability is con-sistent with other published qualitative analysis methodol-ogies.21 All individual themes identified were maintainedseparately, establishing a clear audit trail by which toresolve any potential triangulation issues.ResultsSurvey Response Rate andRespondent DemographicsThe survey received a total of 286 respondents, or 16% of theoriginallist, with a margin of error of 5.3%. This is areasonable response for a web-based survey, but lackssufficient power for extensive statistical analysis.Forty-six percent of respondents identified themselves as prin-cipal investigators or collaborating faculty, followed by 36% asstaff scientists and lab managers, with the remainder postdoc-toral fellows, students, and technicians (Fig. 1). Respondentswere encouraged to select all choices that corresponded to theirresearch roles, so the total percent figures are greater than100%. “Small” labs (six people or fewer) and “medium” labs (7to 15 employees) comprised 87% of respondents (44% and 43%,respectively), with “large” size labs accounting for 13% ofrespondents. Neurosciences, Genomics, and Cell Biology werethe most frequently selected primary research sub-discipline(each specialty indicated by over 20% of respondents). Othercommonly chosen areas were Biochemistry (15%), Immunol-ogy (11%), Pathology (10%), and Microbiology (10%) (Fig. 2).We examined lab size as a function of stated research specialtyand found no clear association between these variables.Needs AnalysisthemesThree broad data management and analysisemerged from the analysis of the interview data within thecontext of the survey responses: 1) current state of datamanagement and analysis at the laboratory level; 2) antici-pated data management and analysis needs; 3) barriers toaddressing those needs.Current State of Data Management and AnalysisEighty-four percent of survey participants indicated thatthey currently have or in the past had experienced datahandling problems although only 52% of them sought tosolve their data handling problems (Question 33) (Fig. 3).There was a clear correlation between the size of a lab andthe likelihood it had experienced problems. Only 14% ofsurvey respondents reported currently having a LaboratoryInformation Management System (LIMS) (Question 30).48When broken down by sub-discipline, developmental biol-ogists were least likely to have a LIMS (4%) with proteomi-cists (18%), pathologists (17%), and cell biologists (16%)most likely to use a LIMS in their work (Table 1). Large labswere most likely to be using a LIMS (22%) but interestinglywere closely followed by the smallest labs (18%) (data notshown). Most researchers (59%) were already storing at leastsome of their images digitally while roughly a third (34%)partly relied on hard copy archiving (Fig. 4).Fifty percent of structural biologists and proteomicists and48% of genomicists reported that at least 10 employee-hoursper week are spent in data handling tasks (Question 29). Thebreakdown of weekly workload devoted to data handling as    Journal of the American Medical Informatics Association Volume 14 Number 4July / August 2007481lDownoadedfromhttF i g u r e 2. Primary research interest by percentage of respondents.a function of research sub-discipline is given in Figure 5.Over 50% of survey respondents reported spending morethan 5 person-hours per week in data handling tasks. Largersize labs were shown to spend more employee time eachweek at data handling.During the interviews, two core themes surrounding thecurrent state of biomedical data management and analysisemerged: the widespread use of non-specialized applica-tions, and the difficulty of organization, storage, and re-trieval of data.ps://iacademc.oup.com/jil////amaartice144478788143byguest/on03Juy2023lF i g u r e 3.respondents.Individuals reporting experiencing computational and informatics problem by lab size and percentage of    482ANDERSON et al., Issues in Research Data ManagementTable 1 y Percentage of Labs Using LaboratoryInformation Management System (LIMS) BySub-DisciplineBiochemistryCell BiologyDevelopmental BiologyGenomicsNeurosciencesPathologyProteomicsStructural BiologyAll5.3%16.4%4.5%10.7%8.5%16.7%18.2%14.3%13.8%Common Use of Non-Specialized ApplicationsMost researchers already used some form of electronicorganization; however, instead of using applications ad-dressing specific needs of biomedical research, manydepended on general-purpose applicationssuch asspreadsheets, text files, and simple file sharing programs.The reasons why these tools were commonly used includedsimplicity of data layout, widespread availability, and shortlearning curve.“Yeah, the spreadsheet has been our main workhorse, unfor-tunately”“Well, that stuff I currently have just in a Word document.So, I just have it all right here (shows document on com-puter)”“I have one spreadsheet that has all of my chromosomes—ithas a different tab page for each of 23 human chromosomesall in one Excel document - and it has all of my data it has mywhole experiment and then I’ve gone through and colorcoded it for homozygosity and linkage. So this has also takena considerable amount of time to set up, but I have this foreach one of my chromosomes.”“Well I’m a spreadsheet queen. So I’ve got everything inspreadsheets. This is just my data, I’ve got a spreadsheet onfamily information, on cell information . . .”Nine out of fifteen interviewed researchers recognized thatspreadsheet applications had disadvantages of size con-straint and limited processing power. Often these research-ers anticipated that they would soon reach the limits ofexisting general-purpose spreadsheet applications in termsof both storage and organizational capacities.“Well, we have multiple spreadsheets - that’s one of theproblems. We sort of have a master spreadsheet . . . We try tominimize it as much as we can, but I think that’s a majorproblem.”“However, that exceeds the capabilities of the spreadsheet.Spreadsheet really bogs down any time you get past say20,000 individual cells with columns.”lDownoadedfromhttps://iacademc.oup.com/jli////amaartice144478788143byguest/on03Juy2023lF i g u r e 4.Image archiving by sub-discipline by percentage of respondents.    Journal of the American Medical Informatics Association Volume 14 Number 4July / August 2007483lDownoadedfromhttps://iacademc.oup.com/jil////amaartice144478788143byguest/on03Juy2023lF i g u r e 5. Employee hours spent per-week by sub-discipline and percentage of respondents.“Well, it’s very cumbersome, I can’t print anything, I’d haveto paste it together. I end up just doing a freeze frame so thatI can scroll this way.”Difficulty of Organizing, Storing, and Retrieving DataA major component of biological research is the manage-ment of data. During the interviews, researchers frequentlymentioned the complex and varied data formats they dealwith throughout their research. We found it interesting thatmodern methods of information exchange (such as XML,MAGE) were not specifically mentioned, but we did notspecifically ask for this information during the interviews.Researchers also discussed issues surrounding the increas-ing number of files, growing file sizes, multiple formats,indexing and annotation of data. A common theme sur-rounding data management and analysis was that manyresearchers preferred to utilize their own individual meth-ods to organize data. The varied ways of managing datawere accepted as functional for most present needs. Someresearchers admitted to having no organizational method-ology at all, while others used whatever method best suitedtheir individual needs.“Yeah, I don’t have them organized in any particular wayand I don’t have them linked to my databases, I just havethem . . .”“They’re not organized in any way—they’re just thrown intofiles under different projects.”“We have thousands of very large .tiff files which everyoneorganizes according to how they think they should beorganized. We have kind of a lab standard like the filenamebegins with . . .”“I grab them when I need them, they’re not organized in anydecent way.”“It’s not even organized—a file on a central computer ofprotocols that we use, common lab protocols but those arejust individual Word files within a folder so it’s not search-able per se.”Although ad hoc organizational methods had been relativelysuccessful to date, this lack of standardized methods for dataorganization was generally perceived as having a limitedfuture. Specific technical problems associated with this lackof organization included: filenames being truncated whenstored on central servers, the inability to easily store anno-tation data, and the lack of standardized formats or nomen-clature for data sharing.“There are separate files but in independent computers thatdon’t talk to each other.”“Because what’s happened is separate nodes have sprung upwhere you can have your own little partition of a drivesomewhere and people will just password protect it withtheir name or whatever but technically everything is sup-posed to be shareable and viewable by everybody.”“There have been times when folders have vanished or somepiece of data was accidentally deleted or something getscorrupted and I think that that’s why people are a littleskeptical.”“Right now, again, everybody has to do on their own andthat it’s always a pain to go and talk to 5 labs and go to eachand say ‘I want to get your datasets can you send me all ofyour original cell files and DAT files’ and some of the labswon’t do it.”As a result of relatively disorganized data, search andretrieval capability was also limited. Most researchers didnot have a strategy for effective data retrieval. Many werenot even aware of the capabilities of existing search andretrieval tools. Of those who were aware, few had imple-mented search capability.“One of the things that would be interesting for us to do iswith PDF files—I have tons of PDF files saved on my desktopand they’re not (collectively) searchable for the text that’s inthe PDF file.”    484ANDERSON et al., Issues in Research Data ManagementAnticipated Data Management and Analysis NeedsIn response to whether data handling and managementcurrently caused a backlog in lab productivity (Question 28)41% responded, “Yes”, and 22% said “Somewhat.” Theproblem was greater in larger labs where 51% responded,issues“Yes.” Analyzed by specialty, data managementimpacting on productivity were most highly reported bystructural biologists (62%), followed by proteomicists (59%)and genomicists (50%) (Fig. 5). The most frequently men-tioned types of data causing management problems forsurvey respondents were microarrays (18%) and images(15%). Database capabilities (13%) and statistical analysis(13%) were also mentioned as obstacles to progress in thelab.Eighty-two investigators responded to the open-ended sur-vey question 35 asking them to detail their most urgentcomputational or data handling problem. Issues involvinglong-term digital archiving of a variety of data types werementioned by more than 28% of respondents. Various formsof computerized data analysis (not involving a specificsoftware product) were mentioned by 26%. Twenty-onepercent of respondents felt that access to a specific softwareproduct would solve their most urgent problems while only6% cited acquisition of hardware as a problem. Eighteenpercent required access to some form of computer science orinformatics expertise.When asked to characterize how they located and evaluatedtools to support these needs (Question 18), 41% stated theyused the World Wide Web, 29% used a dedicated e-mail listwith the remainder (24%) stating that this question was notapplicable to their information management and analysisissues or that they used blogs or wiki’s (combined 4%).Analysis of the interview data identified two commonanticipated needs: improved methods of managing largedatasets, and improved ways to process and analyze data.Need for Improved Methods of Managing Large DatasetsSome researchers were aware that their current ad hoc datamanagement methods needed improvements. Several dis-cussed the need for improvement of a whole laboratoryinformation organization, moving away from organizationbased on individual preference and need to an establishedlab-wide data organization. A specific example of ad hocorganization was the common practice of researchers inthe same lab creating custom spreadsheets without anycommon standard structure. The profusion of individuallycreated spreadsheets containing overlapping and inconsis-tently updated data created a great deal of confusion withinsome labs. There was little consideration to future dataexchange or submission requirements at the time of publi-cation. Although researchers in the past have used spread-sheets containing a global data presentation to synthesizeconcepts and generate hypotheses, this approach becameless feasible as data became more complex.“So we need really a way to store that in a database that iscompletely searchable, like you can search on any one of theitems. So we try sometimes to put it in a filename butfilenames become too long and when you store them to aserver that doesn’t like long filenames then they get trun-cated or they get misread. So this becomes, I think, one of ourbiggest problems.”“For me it’s mostly data organization and archiving—that’sone issue, and then just analysis, how do you deal with allthis data—it’s still something that’s very new to a lot of thelabs, what do you do when you’ve got 10,000 data points foreach time point - what’s the best way to look at the data.”“It makes me a little nervous the more databases that getgenerated . . . you know, which ones are really up to date . . .”Need for Improved Methods of Analyzing andProcessing DataAs mentioned earlier, though aware of the limitations ofgeneral-purpose applications such as spreadsheets, the ma-jority of researchers continued to rely on them due to theirease of use, low cost, and familiarity. Researchers sought theconvenience, low risk economics, and usability of thesegeneral-purpose tools while often recognizing that theywere making a tradeoff against complex functionality thatmay be of use to them in the future.“I think anything that makes the interface more simple andstraightforward is good.”“I’ve sort of created my own little sad and pathetic databasewhich is purely spreadsheet based, but it serves my needs.It’s just that I am not an information architect in any way, ora database person, so I’ve sort of created it from the perspec-tive of a scientist and having rows and columns and it’ssearchable and that’s all I really need . . .”“But I would love to be able to export all this into somethinglike [a spreadsheet] or some other program instead of mespending a week doing all this.”Similarly, many researchers relied on the general-purposestatistical analysis functions built into common spreadsheetsdespite there being better statistical analysis tools availablein most domain areas.Barriers to Addressing Data Management IssuesThree barriers to addressing data management and analysisemerged from the responses to question 35 in the survey andthe personal perspectives provided during the interviews:financial burden of acquiring new expertise or tools, lack oftime to invest in changing work practices to incorporate newtechnologies, and limited availability of institutional sup-port.Financial Burden of Acquiring New Expertise or ToolsTwenty-one percent of survey respondents felt that access toa specific software product would solve their most urgentproblems while only 6% cited acquisition of hardware as aproblem. Various forms of computerized data analysis (notinvolving a specific software product) were mentioned by26% and 18% required access to some form of computerscience or informatics expertise.“So the real problem is not so much the cost of the databaseand I don’t remember what the seed price is but it’s small.The real problem is supporting the cost of a databasemanager to support it.”Due perhaps to their lack of knowledge regarding the levelof resources needed for handling complex data, many re-searchers underestimate the resources required for datahandling in their grant proposals. Even if researchers hadknowledge of technology, they commonly associated newtechnology with additional investment, either in terms ofcapital, training, or both. The single largest consensus onappropriate funding sources for tools was from indirectcosts in research grants (37%)—this being the amount thatlDownoadedfromhttps://iacademc.oup.com/jil////amaartice144478788143byguest/on03Juy2023l    Journal of the American Medical Informatics Association Volume 14 Number 4July / August 2007485each awarded grant contributes to the parent institution forinfrastructure such as research space, administration, andutilities— commonly 50% or more of direct costs. Eightpercent felt that tools and support should be funded assubscriptions directly from research grants, 5% stated sub-scriptions funded from other sources, and a combined 38%thought that it would be appropriate to support this throughall three of these categories (Question 20). Ten percent didnot respond to this question, and 2% suggested othersources. In the interviews, limited funding made researcherswary of spending money on anything other than coreresearch needs despite their awareness of the need forimproved tools and/or additional support. Additionally, thelack of personal experience and/or the lack of success withprevious tools contributed to a wariness of the value ofinvesting in new solutions.“No, whenever I hear the word ‘LIMS’ I hear way too muchmoney to deal with.”“It’s expensive, yes. So we have quite a history of attempts touse different relational databases—I’ve been here 7.5 yearsand we’re going to be starting on the third one . . .”“I actually wanted the hospital to purchase it all and then Iwould just administer it. But since they fell down on that Iwas able to get 8 licenses—perpetual licenses—for DSGene,all the Wisconsin package, SeqWeb, everything else and onecopy of all the databases for about 7 grand and then a serverwas 3, so for 10 I’m totally up and running and I’m not goingto share them with anybody else because they haven’t kickedin.”“For whatever reason the university hasn’t made generallyavailable quicker access to these things and so it’s extremelycumbersome and time consuming to do the kind of searchesthat we need to do since we haven’t been able to find one ofthese big groups that have their own databases that we canhook up with.”Lack of Time to Invest in Changing Data ManagementPractices and Improving TrainingIn addition to limited financial resources, limited time alsopresented a significant barrier to improving data manage-ment and analysis processes. A common perception was thatthe time required for data management and training in theeffective use of new technologies was not an integral part ofexperimental research. As a result, researchers discussedtheir frustration at having to spend increasing amounts oftime to accomplish the physical management and analysis ofdata.“There are separate files but in independent computers thatdon’t talk to each other. And the processing of the stuff isdone through incredibly time wasteful methods on slowcomputers by untrained people that are doing it in smallbatches because that’s all their computer can hold, or one ata time and then on pieces of paper, collating datasets”“And the whole data processing part of this was taking about5 days. Not, you know, 40 hours, but from the point wherethe data was available and it had to go to this epidemiologistand then it had to come back, it generally took a whole weekto get from the beginning to the end. And maybe it mighthave taken the individual people crunching the data maybe5 hours or so of time, crunching.”The time commitment required for data transformations orchanging workflows was perceived to be a significant labexpense, even when the financial cost wasn’t necessarily anissue.“It’s free in terms of money, it’s not free in terms of yourtime.”These problems may have been exacerbated by the fre-quently reported high turnover of employees working inresearch labs.Limited Availability of Institutionally Provided Expertiseand SystemsMore than half of the researchers speculated that improvedsupport from their sponsoring institution would greatlyimprove the ability of individual researchers and their labsto focus on their research. Specific examples mentionedincluded lessening the financial burden for early stageresearchers, greater access to and availability of institution-ally supported data processing and analysis resource cen-ters, and better technical support for both hardware andsoftware development. Being within a large research univer-sity, there was a frequently held belief that the universitycould and should provide more basic support of datainfrastructure than was perceived to be available. This waswidely believed to be a potential way of relieving thelimitations of time and budget discussed previously.“. . . It’d be sort of nice if the university had those tools thatwe didn’t have to spend . . .”“. . . We should get something back from the university thathelps us minimize our other costs if they could spendsomething and develop some resource for that.”“I think the solution is the university needs to develop theirown thing that everyone can use, because like I pointed out,the new people that come here, they’ve hardly any moneyand all of a sudden they have to shell out $5000 for all thissoftware that they really need. If you kind of look at the waythe whole system works, the university, it’s advantageous tothe university to provide new researchers with this stuff,because hopefully it will accelerate their research and bringin more indirects, right?”“They should have low cost shared storage—it’s too expen-sive now—I think the University costs more than it does offcampus—I don’t know why storage needs to cost much ofanything anymore.”DiscussionThe themes and issues described in this work reflect a majorshift in the way that information management and analysishas been traditionally conducted within the academic bio-medical research laboratory. Prior to advances in highthroughput technologies such as gene sequencing or mi-croarray analysis, most researchers traditionally spent agreat deal of time and effort focusing on the creation ofhighly specialized data. Today, however, individual inves-tigators are increasingly required to study biological prob-lems involving large amounts of diverse data that requirespecial storage and analysis. Data management has becomemore complex with widely available high quality publicscientific datasets and easier access to high throughputtechnologies at shared instrumentation locations. The in-creasing use of core service facilities within institutions toprovide expertise such as biostatistics, or microarray as-says—as well as mass-producing scientific technologies suchas lab “kits”— has lowered many technical barriers, and hasallowed investigators to generate and collect data outsidetheir own discipline more easily. Yet despite these advances,the individual researcher or lab focused on specific problemslDownoadedfromhttps://iacademc.oup.com/jil////amaartice144478788143byguest/on03Juy2023l    486ANDERSON et al., Issues in Research Data Managementoften lacks the time, funds, or experience to efficientlyleverage these tools and services. At the present time biomed-ical research is in a phase where the quantity and the hetero-geneity of data have exceeded many investigators’ ability toanalyze, or in some cases, even archive their own data.These challenges have created opportunities for new re-search-support roles in biomedical research from the fieldsof informatics, statistics, and computer science. However, todate, the interaction between biomedical researchers, infor-maticians, and computer scientists has been marked bycommunication problems,27,41,49 –51 and there appears toremain an associated knowledge gap regarding what exist-ing tools and resources are available as well as how toincorporate them into the research laboratory. From our inter-view and survey analysis, it is clear that from the individualresearchers’ perspective, there is inadequate institutional datamanagement and analysis support for laboratory basedbiomedical researchers.The reasons behind this lack of support appears to be acombination of social, technical, and fiscal factors that areperhaps in-part associated with the tradition of biomedicallaboratory researchers being protective of their research. Ingeneral, most researchers we spoke with preferred to exertpersonal control over all aspects of data handling andorganization. This reluctance to seek out and collaboratewith a relational database expert or similar outside expertisemay have led the researchers to overly rely on well-knownbut relatively generic spreadsheet applications. Overall, wefound that the laboratory data management technology wasbounded on the lower side by spreadsheets (extremelyflexible but limited in capacity and capability) and on theupper side by relational databases (high in capacity andcapability but inflexible). However, virtually every investi-gator who was not familiar with relational databases pre-ferred to use a spreadsheet if it allowed them to easilymanipulate and manage their data— despite a lack of dataanalysis and scaling that would be available to them byusing database tools. Though there is significant research toaddress this gap by providing applications52–54 that inte-grate ease of configurability with powerful querying andpresentation capabilities, it remains to be seen if they will beadopted by typical investigators. One evolving example isthe open source analysis environment of Bioconductor,55which provides broad biological analysis and data integrationcapabilities, and has considerable general support in the re-search community facilitated through researcher contributedplug-ins that address specific analysis tasks. As of this writing,however, Bioconductor is a sophisticated development envi-ronment with a significant learning curve that may be beyondthe programming capabilities of many researchers.Collaboration between laboratories may encourage sharingof more sophisticated data management and analysis strat-egies; however, collaboration is difficult due to the highlyfocused and non-overlapping nature of different studygroups, where each group has its own terminologies andnuances.28 –30,56 Our results indicate that the needs of indi-vidual investigators have a great deal of overlap, but theneeds of different labs and sometimes even within labs varywidely. Several researchers were convinced that “everybodyneeds the same things” but their efforts to use softwaresolutions used by similar labs were not successful. A com-mon complaint was that those tools “only work for that lab.”It is possible that the researchers’ perceived shortcomings ofthe institutional support facilities were in fact due to theunique characteristics of individual lab needs. Many of theresearchers who did attempt to utilize institutional resourceshad unsatisfactory experiences and eventually decided theseresources could not be utilized in their own study. Based onour analysis, it appears that increased availability of central-ized expertise and resources might not be sufficient toaddress the diverse needs of labs when coupled with theirdesire to have flexible and customizable solutions. Toolsspecific to particular analysis tasks are difficult to centralizeand provide without particular domain knowledge. Uniquesolutions for each research area should be studied individ-ually without the added requirement of generalization;however, solutions that are unique to individual domainareas should be able to utilize a common informationsupport infrastructure as yet to be formed. Establishment ofsuch an infrastructure could facilitate the convergence ofcommonly used resources and allow for increased collabo-ration and information sharing among researchers, whilestill supporting individually unique research goals.Many investigators felt that some form of data managementsystems should be provided more centrally either by theirsponsoring institutions or by the funding agencies. Usuallylacking these services, researchers tended to avoid the timeand costs that are perceived to be associated with imple-menting more sophisticated systems. In interviews manyresearchers stated that in return for indirect costs from theirgrants, the institutions provided much less data supportthan they wanted. The researchers also expressed the viewthat if either funding agencies or institutions provided moresupport, they would be able to save badly needed researchfunds by preventing duplication of effort and expenditurefor analytic software and computer science expertise. If thetrend of increasing size and complexity of datasets continue—which is probable—funding entities may call for increasedinstitutional support of data management and analysis asthey do for lab space.ConclusionThe aims of this research were to evaluate the data manage-ment and analysis needs of biomedical researchers andidentify barriers to addressing those needs. We also soughtto better understand what information management needscould be generalized, if any. While we recognize that themethods used to gather this data reached only a smallpercentage of the researchers actively involved in this singleresearch location, these individuals had self-selected them-selves to be on this e-mail list out of a shared interest inon-going biomedical data management, analysis, and edu-cation issues at this institution. We believe that the themeswe identified reflect and characterize the common percep-tions of many researchers encountering on-going data anal-ysis problems and difficulties working with large datasets.Despite its limitations, this study has provided a basis forfurther research at our institution to identify likely solutionsto these data management and analysis problems.In summary, we suggest that at least some data manage-ment needs of biomedical researchers will best be served bylDownoadedfromhttps://iacademc.oup.com/jli////amaartice144478788143byguest/on03Juy2023l    Journal of the American Medical Informatics Association Volume 14 Number 4July / August 2007487improving and providing basic level tools such that scien-tists can solve their own problems, such as designingspecialized applications as plug-ins to evolving commonlyused frameworks such as Bioconductor. We also suggestthat both institutions and informaticians interested in sup-porting laboratory information management needs shouldincrease focus on three components: 1) facilitate and encour-age the use of modern data exchange models and standards,which will allow individual researchers with specific prob-lems to have a common layer of interoperability andanalysis; 2) improve the ability of researchers to maintainprovenance of research data and models as they evolve overtime; 3) develop and support biomedical information man-agement service cores that can facilitate both of these previ-ous components while providing a spectrum of supportoptions that could be used to address the range of uniqueindividual researcher needs. These basic infrastructure com-ponents could provide considerable secondary benefits,such as increased collaboration and greater leveraging ofexisting research personnel for core science roles.References y1. NIH. NIH Roadmap on Translational Research. 2005. Availablehttp://nihroadmap.nih.gov/clinicalresearch/overview-at:translational.asp. Accessed February 22, 2006.2. NIH. NIH RFP for Institutional Clinical and Translational Scienceaward. 2005. Available at: http://grants.nih.gov/grants/guide/rfa-files/RFA-RM-06-002.html. Accessed: March 14, 2006.3. NIH. Biomedical Information Science and Technology Initiative(BISTI). 2001. Available at: http://www.bisti.nih.gov/. Accessed:March 14, 2007.4. NSF. Science and Engineering Information Integration andInformatics. 2004. Available at: http://www.nsf.gov/pubs/2004/nsf04528/nsf04528.htm. Accessed: March 14, 2007.5. NIH Announces Draft Statement on Sharing Research Data.2002. Available at: http://grants.nih.gov/grants/guide/notice-files/NOT-OD-02-035.html. Accessed: March 14, 2007.6. Cadeg E, Louie B, Myler P, Tarczy-Hornoch P. BioMediatorData Integration and Inference for Function Annotation ofAnonymous Sequences. Pacific Symposium on Biocomputing.Maui, Hawaii, 2007.7. Louie B, Mork P, Martin-Sanchez F, Halevy A, Tarczy-HornochP. Data integration and genomic medicine. J Biomed Inform.2007;40:5–16.8. Mei H, Tarczy-Hornoch P, Mork P, Rossini AJ, Shaker R,Donelson L. Expression array annotation using the BioMediatorbiological data integration system and the BioConductor ana-lytic platform. AMIA Annu Symp Proc. 2003:445–9.9. Donelson L, Tarczy-Hornoch P, Mork P, et al. The BioMediatorsystem as a data integration tool to answer diverse biologicqueries. Medinfo. 2004;11(Pt 2):768 –72.10. Jakobovits RM, Rosse C, Brinkley JF. WIRM: an Open SourceToolkit for Building Biomedical Web Applications. J Am MedInform Soc. 2002;9(6):557–70.11. Li H, Gennari JH, Brinkley JF. Model Driven Laboratory Infor-mation Management Systems. American Medical InformaticsAssociation. Washington DC, 2006.12. Fong C, Brinkley, J. Customizable Electronic Laboratory Online(CELO): A web-based data management system builder forbiomedical laboratories. Fall Symposium of the American Med-ical Informatics Association. Washington DC, 2006.13. Oinn T, Addis M, Ferris J, et al. Taverna: a tool for thecomposition and enactment of bioinformatics workflows. Bioin-formatics. 2004;20(17):3045–54.14. Jeng S, Wang K, Barbero J, Brinkley J, Tarczy-Hornoch P. A PilotBridging Data Integration and Analytics: BioMediator and R.AMIA Annual Symposium. Washington DC, 2005.15. Jones C. Patterns of Software System Failure and Success.Stamford, CT: International Thompson Computer Press, 1996.16. Brooks FP. The Mythical Man-Month: Essays on SoftwareEngineering. Boston, MA: Addison-Wesley Professional, 1995.17. Seaman C. Communication and Organization in Software De-velopment: An Empirical Study. IBM Systems Journal. 1997;36:550 – 63.18. Seaman C. Qualitative Methods in Empirical Studies of Soft-ware Engineering. IEEE Transactions on Software Engineering.1999;25(4):557–72.19. Gittens R, Hope, S, Williams, I. Qualitative Studies of XP in aMedium Sized Business. Proceedings of the 2nd Conference oneXtreme Programming and Flexible Processes in Software En-gineering. Cagliari, Italy, 2001.20. Lindgaard G, Dillon R, Trbovich P, et al. User needs analysisand requirements engineering: theory and practice. InteractComp 2006;18(1):47–70.21. Bryman A. Integrating quantitative and qualitative research:how is it done? Qual Res 2006;6:97–113.22. Boverhof DR, Zacharewski TR. Toxicogenomics in risk assess-ment: applications and needs. Toxicol Sci. 2005;89:352– 60.23. Korjonen-Close H. The information needs and behaviour ofclinical researchers: a user-needs analysis. Health Info Libr J2005;22(2):96 –106.24. Strasberg HR, Tudiver F, Geiger G, Keshavjee KK, Troyan S.Moving towards an electronic patient record: a survey to assessthe needs of community family physicians. AMIA Annu SympProc 1998:965–9.25. Tanner C, Eckstrom E, Desai SS, Ririe MR, Bowen JL. Uncover-ing frustrations. a qualitative needs assessment of academicgeneral internists as geriatric care providers and teachers. J GenIntern Med. 2006;21(1):51–5.26. Rosenal TW, Forsythe DE, Musen MA, Seiver A. Support forinformation management in critical care: a new approach toidentify needs. Proc Annu Symp Comput Appl Med Care.1995:2– 6.27. Forsythe DE. Using ethnography to investigate life scientists’information needs. Bull Med Libr Assoc. 1998;86(3):402–9.28. Ammenwerth E, Shaw NT. Bad health informatics can kill--isevaluation the answer? Methods Inf Med. 2005;44(1):1–3.29. Kaplan B, Shaw NT. Future directions in evaluation research:people, organizational, and social issues. Methods Inf Med.2004;43(3):215–31.30. Kaplan B. Evaluating informatics applications - some alternativeapproaches: theory, social interactionism, and call for method-ological pluralism. Int J Med Inform. 2001;64:39 –56.31. Yarfitz S, Ketchell DS. A library-based bioinformatics servicesprogram. Bull Med Libr Assoc. 2000;88(1):36 – 48.32. Tran D, Dubay C, Gorman P, Hersh W. Applying task analysisto describe and facilitate bioinformatics tasks. Medinfo 2004;11(Pt2):818 –22.33. Anderson N, Ash J, Tarczy-Hornoch P. A qualitative study ofthe implementation of a bioinformatics tool in a biologicalresearch laboratory. Int J Biomed Inform. 2006 (e-pub ahead ofprint).34. Bartlett J, Toms E. Developing a protocol for bioinformaticsanalysis: an integrated information behaviour and task anal-ysis approach. J Am Soc Inform Sci Technol 2005;56(5):469 –82.35. Bartlett J, Toms, E. Discovering and structuring informationflow among bioinformatics resources. Proc 26th Annu InternACM SIGIR. Toronto, Canada, 2003.lDownoadedfromhttps://iacademc.oup.com/jli////amaartice144478788143byguest/on03Juy2023l    488ANDERSON et al., Issues in Research Data Management36. Ash JS, Sittig DF, Seshadri V, Dykstra RH, Carpenter JD, StavriPZ. Adding insight: a qualitative cross-site study of physicianorder entry. Int J Med Inform. 2005;74(7– 8):623(cid:3)8.37. Ash JS, Fournier L, Stavri PZ, Dykstra R. Principles for asuccessful computerized physician order entry implementation.AMIA Annu Symp Proc. 2003:36 – 40.38. Crabtree B, Miller W. Doing Qualitative Research. 2nd ed:Thousand Oaks, CA: Sage Publications, 1999.39. Fisher K, Erdelez S, McKenchie L. Theories of InformationBehavior. Medford, NJ: Information Today, 2005.40. Wolcott HF. Writing Up Qualitative Research: Thousand Oaks,CA: Sage Publications, 2001.41. Ash JS, Stavri PZ, Kuperman GJ. A consensus statement onconsiderations for a successful CPOE implementation. J AmMed Inform Assoc. 2003;10(3):229 –34.42. Wooldridge A. The Brains Business. The Economist. September8, 2005.43. University of Washington Office of Research. 2006. Available at:http://www.washington.edu/research/about.html. AccessedOctober 23, 2006.44. WebQ Home Page. Available at: http://catalyst.washington.edu/tools/web_q.html. Accessed February 1, 2006.45. Catalyst Home Page. Available at: http://catalyst.washington.edu/. Accessed February 1, 2006.46. University of Washington BioResearcher Toolkit. Available at:http://healthlinks.washington.edu/index.jsp?id(cid:4)210BCCB7-511A-4C6B-8B40-DFC47AABEA7F. Accessed February 1, 2006.47. Miles M, Huberman AM. Qualitative Data Analysis: An Ex-panded Sourcebook. Thousand Oaks, CA: Sage, 1994.48. Jakobovits R, Soderland SG, Taira RK, Brinkley JF. Require-ments of a Web-based experiment management system. ProcAMIA Symp. 2000:374 – 8.49. Arnstein L, Grimm R, Hung C, et al. Systems Support forUbiquitous Computing: A Case Study of Two Implementationsof LabScape. Proc First Intern Conf Perv Comp. Germany:Springer-Verlag, 2002.50. Flowers S. Software Failure: Management Failure: AmazingStories and Cautionary Tales. Hoboken, NJ: Wiley and Sons,1996.51. Forsythe DE. Using ethnography to build a working system:rethinking basic design assumptions. Proc Annu Symp ComputAppl Med Care. 1992:505–9.52. Pittendrigh S, Jacobs G. NeuroSys: a semistructured laboratorydatabase. Neuroinform. 2003;1(2):167–76.53. Marenco L, Tosches N, Crasto C, Shepherd G, Miller PL,Nadkarni PM. Achieving evolvable Web-database bioscienceapplications using the EAV/CR framework: recent advances.J Am Med Inform Assoc. 2003;10(5):444 –53.54. Li H, Brinkley J, Gennari J. Semi-automatic Database Design forNeuroscience Experiment Management Systems. Proceedings ofthe MedInfo 2004 Conference, San Francisco, CA, September7–11, 2004.55. Gentleman RC, Carey VJ, Bates DM, et al. Bioconductor: opensoftware development for computational biology and bioinfor-matics. Genome Biol. 2004;5(10):R80.56. Forsythe DE. New bottles, old wine: hidden cultural assump-tions in a computerized explanation system for migraine suffer-ers. Med Anthropol Q. 1996;10(4):551–74.lDownoadedfromhttps://iacademc.oup.com/jli////amaartice144478788143byguest/on03Juy2023l    