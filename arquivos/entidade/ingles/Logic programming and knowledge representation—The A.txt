Artificial Intelligence 138 (2002) 3–38www.elsevier.com/locate/artintLogic programming and knowledgerepresentation—The A-Prolog perspective ✩Michael Gelfond a,∗, Nicola Leone ba Department of Computer Science, Texas Tech University, Lubbock, TX 79409-3104, USAb Department of Mathematics, University of Calabria, 87030 Rende (CS), ItalyAbstractIn this paper we give a shortintroduction to logic programming approach to knowledgerepresentation and reasoning. The intention is to help the reader to develop a ‘feel’ for the field’shistory and some of its recent developments. The discussion is mainly limited to logic programsunder the answer set semantics. For understanding of approaches to logic programming built onwell-founded semantics, general theories of argumentation, abductive reasoning, etc., the reader isreferred to other publications.  2002 Elsevier Science B.V. All rights reserved.Keywords: Logic programming; Nonmonotonic reasoning; Default reasoning; Answer set programming1. IntroductionIf we want to design an entity (a machine or a program) capable of behaving intelligentlyin some environment, then we need to supply this entity with sufficient knowledge aboutthis environment. To do that, we need an unambiguous language capable of expressingthis knowledge, together with some precise and well understood way of manipulating setsof sentences of the language which will allow us to draw inferences, answer queries, andupdate both the knowledge base and the desired program behavior. A good knowledgerepresentation language should allow construction of elaboration tolerant knowledgebases, i.e., bases in which small modifications of the informal body of knowledgecorrespond to small modifications of the formal base representing this knowledge. Around✩ The work of Michael Gelfond was partially supported by the NASA contract ncc9-143. The work of NicolaLeone was partially supported by the European Commission project ICONS, project no. IST-2001-32429.* Corresponding author.E-mail addresses: mgelfond@cs.ttu.edu (M. Gelfond), leone@unical.it (N. Leone).0004-3702/02/$ – see front matter  2002 Elsevier Science B.V. All rights reserved.PII: S 0 0 0 4 - 3 7 0 2 ( 0 2 ) 0 0 2 0 7 - 24M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–381960, McCarthy [83,84] proposed the use of logical formulas as a basis for a knowledgerepresentation language of this type. It was soon suggested, however, that this tool is notalways adequate [94]. This may be especially true in modeling commonsense behaviorof agents when additions to the agent’s knowledge are frequent and inferences are oftenbased on the absence of knowledge. It seems that such reasoning can be better modeled bylogical languages with nonmonotonic consequence relations which allow new knowledgeto invalidate some of the previous conclusions. In precise terms a consequence relation|= (over language L) is called nonmonotonic if there are formulas A and B and a setof formulas T such that T |= B and T , A (cid:4)|= B. Obviously the consequence relation ofclassical logic does not satisfy this property and is, therefore, monotonic.The above observation has led to the development and investigation of new logicalformalisms, nonmonotonic logics. The best known of them are circumscription [85,86],default logic [111], and nonmonotonic modal logics [88,89,95]. All of these logics aresuper-classical, i.e., can be viewed as an extension of classical predicate or propositionallogic.Another direction of research, started by Green [55], Hayes [56] and Kowalski [61],and continued by many others, combined the idea of logic as a representation languagewith the theory of automated deduction and constructive logic. This led Kowalski andColmerauer to the creation of logic programming [61,62,124] and the development of alogic programming language, Prolog [23].Even though logic programming and nonmonotonic logic share many common goalsand techniques, for some time there were no strong ties between the two researchcommunities. Originally, Prolog was defined as a small subset of predicate calculus. Thisdialect of Prolog is now called Pure Prolog. The restricted syntax of Pure Prolog makes itpossible to efficiently organize the process of inference, while its semantics relies heavilyon the classical, model-theoretic notion of logical entailment. Unlike nonmonotoniclogics, with their emphasis on expressiveness, efficiency and development of programmingmethodology seemed to be the main concern of the logic programming community.With time, however, Prolog evolved to incorporate some nonclassical, nonmonotonicfeatures, which made it closer in spirit to the nonmonotonic logics mentioned above. Themost important nonmonotonic feature of modern Prolog is negation as failure. The initialdefinition of this construct, incorporated in the original Prolog interpreter, was purelyprocedural, which inhibited its use for knowledge representation and software engineering,as well as for the investigation of the relationship between logic programming and othernonmonotonic formalisms. Work, started by Clark and Reiter in the late 1970s [30,110],was aimed at the development of a declarative semantics for logic programs with negationas failure. Further work in this direction proved to be fruitful for logic programming as wellas for artificial intelligence and databases. The results uncovered deep similarities betweenvarious, seemingly different, approaches to formalization of nonmonotonic reasoning andshed a new light on the nature of rules and the negation as failure operator of Prolog.Among other things this led to the development of the knowledge representation andreasoning language A-Prolog discussed in this paper and several other logic programmingbased languages with nonmonotonic semantics [1,16,21,24,57,127].Unlike Prolog these languages have well-defined declarative semantics independent ofa particular inference mechanism. Unlike the ‘original’ nonmonotonic logics they are notM. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–385super-classical. Instead they use a collection of new connectives which we believe areoften more suitable for representing various forms of nonmathematical knowledge thantheir classical counterparts.Papers published in this issue are selected from those presented at LPNMR991—5thInternational Conference on Logic Programming and Non-Monotonic Reasoning, heldin 1999 in El Paso, Texas. These papers are significant extensions of the respectiveversions presented at the conference. They deal with several different aspects of LPNMR:knowledge representation and reasoning [72], computational complexity [54], systems[118], updates [2], revision [76], and applications [31]. The research work presented in[54] received the best paper award at LPNMR99.This introductory paper is aimed at providing potential readers with some backgroundinformation. This is not a survey of the field but rather a small collection of ideas andresults put together to help the reader to develop a ‘feel’ for the field’s history and someof its recent developments. There is by now a substantial number of books and surveysclosely related to logic programming and nonmonotonic reasoning. Accurate mathematicalexposition of the related formalisms can be found in [17,71,73,74,82]. For applications tovarious aspects of knowledge representation one can look at [1,9,10,28,32,39,45,51,52,98,100,102,115,116,122]. Issues related to reasoning methods of Prolog are discussed in[3,97,101]. Additional information and important historical perspective can be obtainedfrom [7,91,92]. An in-depth coverage of many aspects of knowledge representation andreasoning with A-Prolog can be found in the forthcoming book [8]; several logic-basedworks in artificial intelligence are collected in [93].The rest of the paper is organized as follows. Section 2 presents the syntax and semanticsof A-Prolog and defines a couple of relevant syntactic fragments of it. Section 3 addressescomputational aspects; it describes algorithms for reasoning associated with A-Prologprograms. Section 4 treats knowledge representation; it illustrates the basic methodology ofrepresenting knowledge in A-Prolog by examples. Section 5 highlights the relationship ofA-Prolog to other nonmonotonic formalisms. Section 6 discusses the treatment of negationin logic programming. Section 7 analyzes the computational complexity of A-Prologand its fragments, paying special attention to the impact of syntactic restrictions onnegation and disjunction. Section 8 comments on some general properties of the entailmentoperators. Finally, Section 9 draws our conclusions.2. The A-Prolog languageWe start with a description of syntax and semantics of A-Prolog (also called Answer SetProgramming [81])—a logic programming language based on answer sets/stable modelsemantics of [49,50].1 The first LPNMR was organized in 1991 by Anil Nerode. Since that time the conference served as the mainmeeting place of people interested in both subjects.6M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–382.1. SyntaxThe syntax of A-Prolog is determined by a signature σ consisting of types, types(σ ) ={τ0, . . . , τm}, object constants obj(τ, σ ) = {c0, . . . , cm} for each type τ , and typed functionand predicate constants func(σ ) = {f0, . . . , fk} and pred(σ ) = {p0, . . . , pn}. We willassume that the signature contains symbols for integers and for the standard functionsand relations of arithmetic. Terms are built as in typed first-order languages; positiveliterals (or atoms) have the form p(t1, . . . , tn), where t’s are terms of proper types andp is a predicate symbol of arity n; negative literals are of the form ¬p(t1, . . . , tn). Thesymbol ¬ is called classical or strong negation.2 Literals of the form p(t1, . . . , tn) and¬p(t1, . . . , tn) are called contrary. By ¯l we denote a literal contrary to l. Literals andterms not containing variables are called ground. The sets of all ground terms, atoms andliterals over σ will be denoted by terms(σ ), atoms(σ ) and lit(σ ), respectively. For a setP of predicate symbols from σ , atoms(P , σ ) (lit(P , σ )) will denote the sets of groundatoms (literals) of σ formed with predicate symbols from P . Consistent sets of groundliterals over signature σ , containing all arithmetic literals which are true under the standardinterpretation of their symbols, are called states of σ and denoted by states(σ ).A rule of A-Prolog is an expression of the forml0 or . . . or lk ← lk+1, . . . , lm, not lm+1, . . . , not ln(1)where li ’s are literals, not is a logical connective called negation as failure or defaultnegation, and or is called epistemic disjunction. The following notation will be usefulfor further discussion. A set {not li, . . . , not li+k} will be denoted by not{li, . . . , li+k}.If r is a rule of type (1) then head(r) = {l0, . . . , lk}, pos(r) = {lk+1, . . . , lm}, neg(r) ={lm+1, . . . , ln}, and body(r) = pos(r), not neg(r). A rule such that head(r) = ∅ is calleda constraint and is written as← lk+1, . . . , lm, not lm+1, . . . , not ln.If k = 0 then we writel0 ← l1, . . . , lm, not lm+1, . . . , not ln.(2)(3)Default negation is interpreted as a new logical connective. Intuitively not l says that thereis no reason to believe in l. Notice also the use of the symbol or instead of classical ∨. Themeaning of or differs from that of ∨. A formula A ∨ B says that “A is true or B is true”while a rule, A or B ←, may be interpreted epistemically and means “A is believed to betrue or B is believed to be true”. (This approach can be viewed as a generalization of an2 Logic programs with two negations appeared in [50] which was strongly influenced by the epistemicinterpretation of logic programs given below. Under this view ¬p can be interpreted as “believe that p is false”which explains the term “classical negation” used by the authors. A different view was advocated in [104,126]where the authors considered logic programs without negation as failure but with ¬. They demonstrated that inthis context logic programs can be viewed as theories of a variant of intuitionistic logic with strong negation dueto [96]. For more recent work on this subject see [105,106]. We believe that both views proved to be fruitful andcontinue to play an important role in our understanding of A-Prolog. A somewhat different view on the semanticsof programs with two negations can be found in [1].M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–387early work by J. Minker [90].) A rule r such that body(r) = ∅ is called a fact and is oftenwritten asl0 or . . . or lk.(4)Definition 2.1. A program of A-Prolog is a pair {σ, Π} where σ is a signature and Π is acollection of rules of the form (1). (In this paper we will often refer to programs of A-Prologas logic program and denote them by their second element Π . The corresponding signaturewill be denoted by σ (Π).)2.2. SemanticsIn our definition of semantics of A-Prolog we assume that the l’s in rule (1) are ground.Rules with variables (denoted by capital letters) will be used only as a shorthand for the setsof their ground instantiations. This approach is justified for the so called closed domains,i.e., domains satisfying the domain closure assumption [110] which asserts that all objectsin the domain of discourse have names in the language of Π . Even though the assumptionis undoubtedly useful for a broad range of applications, there are cases when it does notproperly reflect the properties of the domain of discourse. Semantics of A-Prolog for opendomains can be found in [9,58].The answer set semantics of a logic program Π assigns to Π a collection of answersets—consistent sets of ground literals over signature σ (Π) corresponding to beliefs whichcan be built by a rational reasoner on the basis of rules of Π . In the construction of thesebeliefs the reasoner is assumed to be guided by the following informal principles:• He should satisfy the rules of Π , understood as constraints of the form: If one believesin the body of a rule one must believe in at least one of the literals from the rule’s head.• He should adhere to the rationality principle which says that one shall not believeanything he is not forced to believe.The precise definition of answer sets will be first given for programs whose rules do notcontain negation as failure. Let Π be such a program and let S be a state of σ (Π).We say that S is closed under Π if, for every rulel0 or . . . or lk ← lk+1, . . . , lm(5)of Π such that {lk+1, . . . , lm} ⊆ S, {l0, . . . , lk} ∩ S (cid:4)= ∅. (Notice that for a constraint thiscondition means that the body is not contained in S.)Definition 2.2 (Answer set—part one). A state S of σ (Π) is an answer set for Π if S isminimal (in the sense of set-theoretic inclusion) among the sets closed under Π .It can be shown that a program without epistemic disjunction can have at most oneanswer set. To extend this definition to arbitrary programs, take any program Π , and let Sbe a state of σ (Π). The reduct, Π S , of Π relative to S is the set of rulesl0 or . . . or lk ← lk+1, . . . , lm8M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38for all rules (1) in Π such that {lm+1, . . . , ln} ∩ S = ∅. Thus Π S is a program withoutnegation as failure.Definition 2.3 (Answer set—part two). A state S of σ (Π) is an answer set for Π if S is ananswer set for Π S .(The above definition differs slightly from the original definition in [50], which allowedthe inconsistent answer set, lit(σ ). Answer sets defined in this paper correspond toconsistent answer sets of the original version.) Knowledge represented by programsof A-Prolog is frequently used for two different reasoning tasks, associated with twoentailment relations defined below:Definition 2.4 (Entailment relations).(1) A program Π cautiously entails a literal l (Π |= l) if l belongs to all answer sets of Π .(2) A program Π bravely entails a literal l (Π |=b l) if l belongs to some answer sets of Π .Obviously for programs having precisely one answer set, brave and cautious entailmentcoincide.Some query answering systems for A-Prolog are based on the notion on cautiousentailment; other use the brave one. Given a query l and program Π the cautious systemswill first check if Π |= l. If this is the case the cautious answer to l will be yes; if Π |= ¯l thecautious answer will be no; otherwise it will be unknown. In contrast, the brave systemsattempt to find an answer set of Π containing l. If there is such an answer set, the braveanswer to l will be yes; otherwise it will be no.Example 2.1. Consider for instance a logic programΠ0p(a) ← not q(a).p(b) ← not q(b).q(a).Using the definition of answer sets one can easily show that S0 = {q(a), p(b)} is an answerset of this program. In the next section we will introduce simple techniques which willallow us to show that it is the only answer set of Π0. Thus Π0 |= q(a), Π0 (cid:4)|= q(b),Π0 (cid:4)|= ¬q(b) and Π0’s cautious answers to queries q(a) and q(b) will be yes and unknown,respectively. The corresponding brave answers will be yes and no.If we expand Π0 by a rule¬q(X) ← not q(X)the resulting programΠ1 = Π0 ∪ (6)(6)would have the answer set S = {q(a), ¬q(b), p(b)} and hence the cautious answer to queryq(b) will become no. The brave answer to q(b) will not change. (Notice however that thebrave answer to query ¬q(b) will change from no to yes.)M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–389Rule (6), read as “if there is no reason to believe that X satisfies q then it does not”, iscalled the closed world assumption for relation q [110]. It guarantees that the reasoner’sbeliefs about q are complete, i.e., for any ground term t and every answer set S of thecorresponding program, q(t) ∈ S or ¬q(t) ∈ S.It is worthwhile noting that the brave inference operator |=b may entail a literal l and itscontrary ¯l.Example 2.2. Consider the following program.(cid:4)p(a) ← not ¬p(a).¬p(a) ← not p(a).It is easy to see that the above program has two answer sets, namely, {p(a)} and {¬p(a)}.Thus, both p(a) and ¬p(a) are brave consequences of the program; while the programdoes not have any cautious consequence.The cautious inference operator may entail, at the same time, a literal l and its contrary¯l only if the program does not have any answer set.2.3. Program propertiesIn this section we discuss several useful properties of logic programs. We hope that theyhelp the readers to better understand the notion of answer set and to provide them withsome insight into comparatively rich mathematical theory of A-Prolog.2.3.1. The basicsThe following simple propositions [9,66,77] are frequently used to establish basicproperties of logic programs.Proposition 2.1. For any answer set S of a logic program Π :(a) For any rule (1) from Π , if {lk+1, . . . , lm} ⊆ S and {lm+1, . . . , ln} ∩ S = ∅ then thereexists an i, 0 (cid:1) i (cid:1) k such that li ∈ S.(b) If l ∈ S then l is supported by Π ; i.e., there exists a rule r ∈ Π of the type (1) suchthat {lk+1, . . . , lm} ⊆ S, {lm+1, . . . , ln} ∩ S = ∅, and {l0, . . . , lk} ∩ S = {l}.Proposition 2.2. For any program Π if S0 and S1 are answer sets of Π and S0 ⊆ S1 thenS0 = S1.Let us use these propositions to show that S0 = {q(a), p(b)} is the only answer set ofprogram Π0 from Example 2.1. Suppose S1 is an answer set of Π0. By Proposition 2.1 wehave that q(a) ∈ S1, q(b) /∈ S1, p(b) ∈ S1, and hence, S0 ⊆ S1. By Proposition 2.2 we havethat S0 = S1.Programs of A-Prolog may have one, many, or zero answer sets. One can use the abovepropositions and the definition of answer sets to show that programsΠ2 = {p(a) ← not p(a).}M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3810andΠ3 = {p(a). ¬p(a).}have no answer sets while program Π4Π4e(0).e(s(s(X))) ← not e(X).p(s(X)) ← e(X), not p(X).p(X) ← e(X), not p(s(X)).has an infinite collection of them.Finally, let us look at a few examples containing connectives or and ¬. It is easy to seethat, due to the minimality condition in the definition of answer set, programΠ5 = {p(a) or p(b).}has two answer sets, S1 = p(a) and S2 = p(b). However, it will be wrong to view epistemicdisjunction or as exclusive. We say that a conjunction Q = l1 ∧ · · · ∧ ln of literals is true ina set S if l1, . . . , ln ∈ S; ¬Q is true in S if for some i, ¯li ∈ S; otherwise Q is undefined inS. Obviously, neither p(a) ∧ p(b) nor ¬(p(a) ∧ p(b)) holds in S1, S2 and therefore Π5’sanswer to query Q will be unknown. It is instructive to contrast Π5 with a programΠ6 = Π5 ∪ {¬p(a) or ¬p(b)}which has answer sets S3 = {p(a), ¬p(b)} and S4 = {p(b), ¬p(a)} and clearly contains¬(p(a) ∧ p(b)) among its consequences.The notion of answer set is an extension of an earlier notion of stable model definedin [49] for normal logic programs (nlp). Syntactically, an nlp is simply a logic programconsisting of rules of type (3) where l’s are atoms. But, even though stable models ofan nlp Π are identical to its answer sets, the meaning of Π under the stable modelsemantics is different from that under answer set semantics. The difference is caused bythe closed world assumption ‘hard-wired’ in the definition of stable entailment |=s : an nlpΠ |=s ¬p(a) iff for every stable model S of Π , p(a) /∈ S. In other words the absence ofa reason for believing in p(a) is sufficient to conclude its falsity. To match stable modelsemantics of Π in terms of answer sets, we need to expand Π by an explicit closed worldassumption,CWA(Π) = Π ∪ {¬p(X) ← not p(X)}for every predicate symbol p of Π . Now it can be easily shown that for any ground literall, Π |=s l iff CWA(Π) |= l.The next proposition (see [9,50]) shows how programs of A-Prolog can be reduced toprograms without ¬. We will need the following notation:For any predicate p occurring in Π , let p(cid:20) be a new predicate of the same arity. Theatom p(cid:20)(t1, . . . , tn) will be called the positive form of the negative literal ¬p(t1, . . . , tn).Every positive literal is, by definition, its own positive form. The positive form of a literal lwill be denoted by l+. Π +, called positive form of Π , stands for the normal logic programobtained from Π by replacing each rule (1) by← l++m+1, . . . , not l+n++l0 or . . . or lkk+1, . . . , l+m , not lM. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3811and adding the rules← p(t1, . . . , tn), p(cid:20)(t1, . . . , tn)for every atom p(t1, . . . , tn) of σ (Π). For any set S of literals, S+ stands for the set of thepositive forms of the elements of S.Proposition 2.3. A set S ⊂ lit(σ (Π)) is an answer set of Π if and only if S+ is an answerset of Π +.It is worthwhile noting that some answer set finders including DLV [27,42] andSMODELS [99,118] use the above rewriting technique to implement strong negation.2.3.2. Some syntactic properties of programsIn this section, we introduce two syntactically defined classes of logic programs with anumber of useful and interesting properties. These and similar properties are often used forproving correctness of A-Prolog based knowledge and reasoning systems. First we needthe followingDefinition 2.5. Functions || || from ground atoms of σ (Π) to ordinals are called levelmappings of Π .Level mappings give us a useful technique for describing various classes of programs.Definition 2.6. A logic program Π is called (locally) stratified [4,107] if there is a levelmapping || ||s of Π such that for every rule r of Π :(1) for any l ∈ pos(r), and for any l(cid:20) ∈ head(r), ||l||s (cid:1) ||l(cid:20)||s;(2) for any l ∈ neg(r), and for any l(cid:20) ∈ head(r), ||l||s < ||l(cid:20)||s .It is easy to see that program Π0 from Section 2 is stratified while programs Π2 and Π4are not.Theorem 2.1. A locally stratified normal program has exactly one answer set.The theorem is an easy consequence of the results of [4,107] which establish existenceand uniqueness of the intended (perfect) model of locally stratified logic program and theresults showing that perfect models of such programs coincide with their stable models. It isworthwhile noting that the above statement holds for normal logic programs; the presenceof epistemic disjunction or the presence of strong negation invalidates the theorem. Forinstance, the locally stratified program {a or b} has two answer sets (namely, {a} and{b}); while the program {a, ¬a}, which also is locally stratified, does not have any answersets at all. Theorem 2.1 is an example of a collection of results establishing existence anduniqueness of answer sets.12M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38Another interesting class consists of head-cycle free programs.Definition 2.7. A logic program Π is called head-cycle free (hcf) [11], if there is a levelmapping || ||h of Π such that for every rule r of Π :(1) for any l ∈ pos(r), and for any l(cid:20) ∈ head(r), ||l||h (cid:1) ||l(cid:20)||h;(2) for any pair l, l(cid:20) ∈ head(r), ||l||h (cid:4)= ||l(cid:20)||h.Example 2.3. Consider the following program Π7.(cid:4)a or b.a ← b.Π7It is easy to see that Π7 is head-cycle free. Consider now programΠ8 = Π7 ∪ {b ← a}.Program Π8 is not head-cycle free, since a and b should belong to the same level bycondition (1); while they cannot by condition (2).Among other things head-cycle free programs are interesting because epistemicdisjunction can be safely eliminated from them by “shifting” some head atoms to the bodiesof the rules. More precisely, by sh(Π) we denote the disjunction-free program obtainedfrom Π by substituting every rule of the forma1 or . . . or ak ← b1, . . . , bm, not c1, . . . , not cnby the following k rules:ai ← b1, . . . , bm, not c1, . . . , not cn, not a1, . . . , not ai−1, not ai+1, . . . , not akwhere i ranges over interval [1 . . . k].Theorem 2.2 [11]. If Π is a head-cycle free program, then Π and sh(Π) have exactly thesame answer sets.It is easy to see that the head-cycle free condition is essential: program Π8 above hasanswer set {a, b}; while sh(Π8) has none. Later we will show that, in general, epistemicdisjunction cannot be eliminated from A-Prolog without loss of the expressive power ofthe language.3. Reasoning algorithms of A-PrologThere are different systems which can be used for reasoning with programs of A-Prolog.The choice of the system normally depends on the form of the program and the type ofqueries one wants to be answered. Suppose for instance that our program Π has an infiniteHerbrand universe and belongs to the class of so called acyclic programs [5]: A program iscalled acyclic if it has a level mapping || || such that for any atom l occurring in the bodyM. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3813of a rule with the head l0, ||l0|| > ||l||. A normal acyclic logic program Π is stratified andtherefore has unique answer set. It can be shown that various queries to Π can be answeredby a variety of bottom-up evaluation algorithm (see for instance [5]). Moreover, acyclicityof R0 together with some results from [6,120] guarantee that the SLDNF resolution basedinterpreter of Prolog will always terminate on atomic queries and produce the intendedanswers. Similar approximation of the A-Prolog entailment for a larger classes of programswith unique answer sets can be obtained by the system called XSB [21] implementing thewell-founded semantics of [125]. Of course none of these traditional logic programminginference algorithms work for programs with multiple answer sets. Some algorithmsaddressing reasoning with such programs are based on the close relationship betweenanswer sets and truth maintenance systems [37,38,47]. In recent years however a numberof substantially more efficient algorithms were developed to reason with programs withfinite Herbrand universes, and a number of modern A-Prolog systems are now available.Two best known systems among them are DLV [27,42] and SMODELS [118]; but alsoother systems support A-Prolog to some extent, including CCALC [87], DCS [33], QUIP[34], and DeRes [22].In this section, we briefly sketch one of such algorithms—the procedure underlying thecomputational engine of the DLV system [27,42]. Similar computational schemes are usedby other answer set finding systems such as SMODELS [118].The first subsection illustrates a procedure for the computation of an answer set of anA-Prolog program Π . The second subsection describes how such a procedure can be usedfor answering queries.3.1. Computing an answer setIn this subsection, we describe a method for computing an answer set of a programΠ which does not contain strong negation ¬. In the first step of the computationan A-Prolog system replaces a program Π , which normally contains variables, by itsground instantiation ground(Π). It is worthwhile noting that ground(Π) is not the fullset of all syntactically constructible instances of the rules of Π ; rather, it is an (oftenmuch smaller) subset of it having precisely the same answer sets as Π . The abilityof the grounding procedure to construct small ground instantiation of the program maydramatically affect the performance of the entire system. As shown in [40], the adoption ofdatabase rewriting techniques has proved to be very useful for reducing the size of groundinstantiation.Once the variables have been eliminated from Π , the hard part of the computation isthen performed on Π0 = ground(Π).The heart of the computation is performed by the Model Generator, which is sketched inFig. 1. Roughly, the Model Generator produces some “candidate” answer sets of Π0. Thestability of each of them is subsequently checked by the function IsAnswerSet(I ), whichverifies whether the given “candidate” I is a minimal model of the reduct Π I0 of Π0 relativeto I . The function IsAnswerSet(I ) returns true if the interpretation I at hand is an answerset and false otherwise (see [60] for details on this function).14M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38Function ModelGenerator(I : Interpretation): Boolean;var inconsistency: Boolean;beginI := DetCons(I );if I = lit(σ ) then return false; (* inconsistency *);if no atom is undefined in I then return IsAnswerSet(I );else Select an undefined ground atom l according to a heuristic;if ModelGenerator(I ∪ {l}) then return true;else return ModelGenerator(I ∪ {not l});end;Fig. 1. Computation of answer sets.The Model Generator is first called with parameter I set to the empty interpretation.3 Ifthe program Π has an answer set, then the function returns true setting I to the computedanswer set; otherwise it returns false. The Model Generator is similar to the Davis–Putnamprocedure employed by SAT solvers. It first calls a function DetCons(), which returns theextension of I with the literals that can be deterministically inferred from I (or the set of allliterals lit(σ ) upon inconsistency). This function (see [19,41] for details) is similar to a unitpropagation procedure employed by SAT solvers, but exploits the peculiarities of A-Prologfor making further inferences (e.g., it exploits the knowledge that every answer set is aminimal model and must be supported). If DetCons does not detect any inconsistency, thenan atom l is selected according to a heuristic criterion and ModelGenerator is (recursively)called on I ∪ {l} and on I ∪ {not l}, to explore whether I can be extended to an answer setof Π . If one of such calls succeeds, then the function stops returning true, as an answerset of Π has been found. Upon failure of both such calls, the function returns false, as Icannot be extended to any answer set.It is worthwhile remarking the importance of the criterion for choosing the atom l.The atom l plays the role of a branching variable of a SAT solver. And indeed, likefor SAT solvers, the selection of a “good” atom l is crucial for the performance ofan A-Prolog system. The adopted heuristic is one of the major differences between theexisting A-Prolog systems, and often causes relevant performance gaps between them.An experimental analysis of a number of heuristics for A-Prolog systems can be foundin [42].3.2. Query answeringThe method for computing answer sets of A-Prolog programs without ¬, illustrated inthe previous section, can be used to implement both brave and cautious reasoning withgeneral A-Prolog programs.3 An interpretation is a set of ground literals representing a 3-valued state of σ (Π). An atom l can be true(l ∈ I ), false (not l ∈ I ) or undefined with respect to an interpretation I . During the computation, undefinednessis eliminated to eventually converge to a 2-valued state.M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3815Let L be a ground literal possibly preceded by the default negation not. By Π(L) wedenote the program Π with the addition of the following constraint: (i) ← l, if L = not l;(ii) ← not l, if L = l. The answer sets of Π(L) are exactly the answer sets of Π where Lhappens to be true.Let Π be an A-Prolog program (possibly containing ¬) and l be a ground literal. Toanswer the query l on Π , under brave and cautious entailments, one can proceed as follows.Build the positive form Π(l)+ of Π(l).4 Evaluate program Π(l)+Brave reasoning.as described in the previous subsection. If Π(l)+ has an answer set, then l is a braveconsequence of Π (i.e., Π |=b l); otherwise, it is not.Build the positive form Π(not l)+ and Π(not ¯l)+ of Π(not l)Cautious reasoning.and Π(not ¯l), respectively. Evaluate programs Π(not l)+ and Π(not ¯l)+ as described inthe previous subsection. If Π(not l)+ does not have any answer set, then l is a cautiousconsequence of Π (i.e., Π |= l). If Π(not ¯l)+ does not have any answer set, then ¯l is acautious consequence of Π (i.e., Π |= ¯l).4. A simple knowledge baseTo illustrate the basic methodology of representing knowledge in A-Prolog let usconsider the following example:Example 4.1. Let cs be a small computer science department located in the college ofscience, cos, of university, u. The department, described by the list of its members and thecatalog of its courses, is in the last stages of creating its summer teaching schedule. In thisexample we outline a construction of a simple A-Prolog knowledge base K containinginformation about the department. For simplicity we assume an open-ended signaturecontaining names, courses, departments, etc.The list and the catalog naturally correspond to collections of atoms, say:member(sam, cs). member(bob, cs). member(tom, cs).course(java, cs). course(c, cs).course(ai, cs).course(logic, cs).together with the closed world assumptions expressed by the rules:¬member(P , cs) ← not member(P , cs).¬course(C, cs) ← not course(C, cs).(7)(8)The assumptions are justified by completeness of the corresponding information. Thepreliminary schedule can be described by the list, say:teaches(sam, java).teaches(bob, ai).(9)Since the schedule is incomplete the use of CWA for teaches is not appropriate. Thecorresponding program correctly answers no to query ‘member(mary, cs) ?’ and unknownto query ‘teaches(mary, c) ?’.4 See Section 2.3 for the definition of positive form and for its properties.16M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38Let us now expand our knowledge base, K, by the statement: ‘Normally, computerscience courses are taught only by computer science professors. The logic course is anexception to this rule. It may be taught by faculty from the math department’. This is atypical default with a weak exception5 which can be represented in A-Prolog by the rules:¬teaches(P , C) ← ¬member(P , cs),course(C, cs),not ab(d1(P , C)),not teaches(P , C).ab(P , logic) ← not ¬member(P , math).(10)Here d1(P , C) is the name of the default rule and ab(d1(P , C)) says that default d1(P , C)is not applicable to the pair (cid:26)P , C(cid:27). The second rule above stops the application of thedefault to any P who may be a math professor. Assuming thatmember(mary, math).(11)is in K we have that K’s answer to query ‘teaches(mary, c) ?’ will become no while theanswer to query ‘teaches(mary, logic) ?’ will remain unknown. It may be worth noting that,since our information about persons membership in departments is complete, the secondrule of (10) can be replaced by a simpler ruleab(P , logic) ← member(P , math).(12)It is not difficult to show that the resulting programs have the same answer sets. Tocomplete our definition of teaches let us expand K by the rule which says that ‘Normallya class is taught by one person’. This can be easily done by the rule:¬teaches(P1, C) ← teaches(P2, C),P1 (cid:4)= P2,not ab(d2(C)),not teaches(P1, C).(13)Now if we learn that logic is taught by Bob we will be able to conclude that it is not taughtby Mary.The knowledge base K we constructed so far is elaboration tolerant with respectto simple updates. We can easily modify the departments membership lists and coursecatalogs. Our representation also allows strong exceptions to defaults, e.g., statements liketeaches(john, ai).(14)which defeats the corresponding conclusion of default (10). As expected, strong exceptionscan be inserted in K without causing a contradiction.5 An exception to a default is called weak if it stops application of the default without defeating its conclusion.M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3817Let us now switch our attention to defining the place of the department in the university.This can be done by expanding K by the rulespart(cs, cos).part(cos, u).part(E1, E2) ← part(E1, E),part(E, E2).¬part(E1, E2) ← not part(E1, E2).member(P , E1) ← part(E2, E1),member(P , E2).(15)(16)The first two facts form a part of the hierarchy from the university organizational chart. Thenext rule expresses the transitivity of the part relation. The last rule of (15) is the closedworld assumption for part; it is justified only if K contains a complete organizational chartof the university. If this is the case then the closed world assumption for member can bealso expanded by, say, the rules:¬member(P , Y ) ← not member(P , Y ).(17)Let us now have a closer look at our program and see how theory of A-Prolog allowsus to discover some of its interesting properties. First let us show that K has exactly oneanswer set, A0.Let K+ be the positive form of K. It is easy to see that it is locally stratified and hence,by Theorem 2.1 has unique answer set, S+. By Proposition 2.1 we conclude that thereis no atom l such that l, (¬l)+ ∈ S+. This implies that S is consistent and hence, byProposition 2.3 is the only answer set of K. This fact, together with Proposition 2.1 allowsus to show that K will (correctly) entail that, say, sam is a member of the university, that uis not part of u, etc.The answer set of K can be computed by the DLV system directly; some minormodifications are needed to run K on SMODELS to enforce “domain restrictedness” (see[118]).To check that sam is a member of the university we form a querymember(sam, u)?(18)Asking DLV to answer member(sam, u)? on program K under cautious entailment,6 weget precisely the response to our query. DLV also provides simple means of displaying allthe terms satisfying relations defined by a program and so we can use it to list, say, allmembers of the CS faculty, etc.Readers with some knowledge of Prolog undoubtedly noticed that K is not suitablefor the use with the Prolog interpreter. The program has a problem with left recursion inrule (15). In addition, Prolog interpreter will flounder7 on a large number of queries to K.6 In practice, this is done by adding member(sam, u)? to the file containing the program K, and running it onDLV with option -FC to specify that cautious entailment is required.7 Prolog interpreter is said to flounder if during the execution it arrives at negative query containing variables.In Prolog floundering constitutes a serious programming error.18M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38Fortunately, floundering can be eliminated by the use of type predicates. A standard leftrecursion elimination applied to K will replace recursive rules of (15) bypart_of (E1, E2) ← part(E1, E2).part_of (E1, E2) ← part(E1, E),¬part_of (E1, E2) ← not part_of (E1, E2).part_of (E, E2).(19)Using various termination and soundness and completeness results for Prolog typeinference (see for instance [5,6]) it is not difficult to show that if the transitive closure ofour part relation is irreflexive then Prolog interpreter terminates and returns correct answerto queries formed by predicates part_of and member.Let us now expand K by a new relation, offered(C, D), defined by the following, self-explanatory, rules:offered(C, D) ← course(C, D),teaches(P , C).¬offered(C, D) ← course(C, D),not offered(C, D).(20)Suppose also that either Tom or Bob are scheduled to teach the class in logic. A naturalrepresentation of this fact requires disjunction and can be expressed asteaches(tom, logic) or teaches(bob, logic).(21)It is easy to see that the resulting program has two answer sets and that each answer setcontains offered(logic, cs). The corresponding reasoning can be done automatically by theDLV system. The example shows that A-Prolog with disjunction allows a natural form ofreasoning by cases—a mode of reasoning not easily modeled by Reiter’s default logic.It is worth noting that this program is head-cycle free and therefore, by Theorem 2.2 thedisjunctive rule (21) can be replaced by two nondisjunctive rules,teaches(tom, logic) ← not teaches(bob, logic).teaches(bob, logic) ← not teaches(tom, logic).(22)and the resulting program will be equivalent to the original one. Now both, SMODELSand DLV can be used to reason about the resulting knowledge base.It is important to notice that development of an executable program by a series oftransformation preserving the initial (possibly nonexecutable) specification is a standardprogramming methodology. The above example shows how declarativeness of A-Prologand development of new reasoning algorithms allowed to shorten this transformationprocess and make programming easier.Even though in the above example disjunction was eliminated by the simple transforma-tion the complexity results [29] show that it is not always possible. Consider for instancethe following example from [18].Example 4.2. Suppose a holding owns some companies producing a set of prod-ucts. Each product is produced by at most two companies. We will use a relationproduced_by(P , C1, C2) which holds if a product P is produced by companies C1 andM. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3819C2. The holding below consists of four companies producing four products and can berepresented as follows:produced_by(p1, b, s). produced_by(p2, f, b).produced_by(p3, b, b). produced_by(p4, s, p).This slightly artificial representation, which requires a company producing a uniqueproduct to be repeated twice (as in the case of p3), is used to simplify the presentation.Suppose also that we are given a relation controlled_by(C1, C2, C3, C4) which holds ifcompanies C2, C3, C4 control company C1. In our holding, b and s control f , which isrepresented by controlled_by(f, b, s, s).Suppose now that the holding needs to sell some of the companies and that its policy insuch situations is to maintain ownership of so called strategic companies, i.e., companiesbelonging to a minimal (with respect to the set theoretic inclusion) set S satisfying thefollowing conditions:(1) Companies from S produce all the products.(2) S is closed under relation controlled_by, i.e., if companies C2, C3, C4 belong to S thenso is C1.It is easy to see that for the holding above the set {b, s} is not strategic while the set {b, s, f }is.Suppose now that we would like to write a program which, given a holding of the aboveform, computes sets of its strategic companies. In A-Prolog this can be done as follows.Consider the rules1. strat(C1) or strat(C2) ← produced_by(P , C1, C2)2. strat(C1)← controlled_by(C1, C2, C3, C4),strat(C2),strat(C3),strat(C4).defining the relation strat(C) (C is strategic). Let Π be a program consisting of rules (1),(2) and an input database X of the type described above. The first rule guarantees that, forevery answer set A of Π and every product p, there is a company c producing p such thatan atom strat(c) ∈ A. The second rule ensures that for every answer set of Π the set ofatoms of the form strat(c) belonging to this set is closed under the relation controlled_by.Minimality of this set follows from the minimality condition in the definition of answerset. It is not difficult to check that answer sets of Π correspond one-to-one to strategic setsof the holding described by an input database. The DLV reasoning system can be asked tofind an answer set of Π and display atoms of the form strat from it.It is worthwhile noting that disjunction plays a crucial role in the above example; itis essential to encode that problem. The program is not head-cycle free, transformingdisjunction to unstratified negation would alter the semantics of the program. Moreover,we cannot design at all another A-Prolog program encoding Strategic Companies withoutusing disjunction. Indeed, since the Strategic Companies problem is -P2 -hard [18], while20M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38normal logic programs can express “only” problems in NP (see Section 7), we can derivethat Strategic Companies cannot be expressed by a fixed normal logic program uniformlyon all collections of facts produced_by(p, c1, c2) and controlled_by(c, c1,c2, c3) (unless NP = -P2 , an unlikely event) [18].5. Logic programming and other nonmonotonic formalismsEven though some affinity between logic programs and nonmonotonic logics wasrecognized rather early [67,112], the intensive work investigating this phenomenon startedaround 1987 after the discovery of model theoretic semantics for stratified logic programs[4]. Almost immediately after this notion was introduced, stratified logic programswere mapped into the three major nonmonotonic formalisms investigated at that time:circumscription [68,107], autoepistemic logic [48] and default theories [12,78]. Furtherwork in this direction proved to be fruitful for logic programming as well as for artificialintelligence. The results uncovered deep similarities between various, seemingly different,approaches to formalization of nonmonotonic reasoning and shed a new light on thenature of rules and negation as failure operator of Prolog. One of the results of thisdirection of research was the development of A-Prolog and several other knowledgerepresentation languages with nonmonotonic semantics. In this section, we will give someresults establishing the relationship between A-Prolog and two other nonmonotonic logics.5.1. A-Prolog and autoepistemic logicWe will start with an autoepistemic logic [95] whose formulas are built from proposi-tional atoms using propositional connectives and the modal operator B.Definition 5.1. For any sets T and E of autoepistemic formulas, E is said to be a stableexpansion of T iff E = Cn(T ∪{Bφ: φ ∈ E}∪{¬Bψ: ψ /∈ E}) where Cn is a propositionalconsequence operator.Intuitively, T is a set of axioms and E is a possible collection of reasoner’s beliefsdetermined by T . A formula F is said to be true in T if F belongs to all stable expansionsof T . If T does not contain the modal operator B, T has a unique stable expansion [79].We will denote this expansion by Th(T ).Let us now consider a class G of programs of A-Prolog which consists of rules of theform:(i) p0 ← p1, . . . , pm, not pm+1, . . . , not pn(ii) ¬p ← not p (for every atom p)(23)where 0 (cid:1) m (cid:1) n. Let α be a mapping which maps rules (i) and (ii) into autoepistemicformulas:(i) p1 ∧ · · · ∧ pm ∧ ¬B pm+1 ∧ · · · ∧ ¬B pn ⊃ p0(ii) ¬B p ⊃ ¬pand let α(Π) = {α(r): r ∈ Π}.(24)M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3821Proposition 5.1. For any program Π ∈ G, and any set A of literals in the language of Π ,A is an answer set of Π iff Th(A) is a stable expansion of α(Π). Moreover, every stableexpansion of α(Π) can be represented in the above form.Mapping α is a simple generalization of the mapping from [48] where it was shownthat the declarative semantics of stratified logic programs can be characterized in terms ofthe autoepistemic theory obtained by this transformation, and that therefore, negation asfailure can be understood as an epistemic operator. The stronger result establishes a one-to-one correspondence between the stable models of an arbitrary normal logic program Πand the stable expansions of α(Π). There are other interesting mappings of programs ofA-Prolog into autoepistemic logic and its variants (see for instance [20,70,80,117]). Eventhough these results substantially increase our understanding of the situation, none of thesuggested mappings seem to provide a really good explanation of meaning of or and ←connectives of A-Prolog in terms of autoepistemic logic.5.2. A-Prolog and Reiter’s default theoriesA Reiter’s default is an expression of the formp : M j1, . . . , M jnf(25)where p, f and j ’s are quantifier-free first-order formulas;8 f is called the consequentof the default, p is its prerequisite, and j ’s are its justifications. An expression M j isinterpreted as “it is consistent to believe j ”. A pair (cid:26)D, W (cid:27) where D is a set of defaults andW is a set of first-order sentences is called Reiter’s default theory.Definition 5.2. Let (cid:26)D, W (cid:27) be a default theory and E be a set of first-order sentences.Consider E0 = W and, for i (cid:2) 0, let Di be the set of defaults of form (25) from D suchthat p ∈ Ei and ¬j1 /∈ E, . . . , ¬jn /∈ E. Finally, let Ei+1 = Th(Ei) ∪ {conseq(δ): δ ∈ Di }where Th(Ei) is the set of all classical consequences of Ei and conseq(δ) denotes the δ’sconsequent. The set E is called an extension for (cid:26)D, W (cid:27) ifE =∞(cid:6)0Ei.Extensions of a default theory D play a role similar to that of stable expansionsof autoepistemic theories. The simple mapping α from programs of A-Prolog withoutdisjunction to default theories identifies a rule, rl0 ← l1, . . . , lm, not lm+1, . . . , not lnwith the default, α(r),l1 ∧ · · · ∧ lm : M ¯lm+1, . . . , M ¯lnl0(26)8 We limit ourselves to the quantifier-free case. For an interesting discussion on defaults with quantifiers see[69] and [59].22M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38(recall that ¯l stands for the literal complementary to l).Proposition 5.2. For any nondisjunctive program Π of A-Prolog(i) if S is an answer set of Π , then Th(S) is an extension of α(Π);(ii) for every extension E of α(Π) there is exactly one answer set, S, of Π such thatE = Th(S).Thus, the class of nondisjunctive A-Prolog programs can be identified with the classof default theories with empty W and defaults of the form (26). This proposition from[50] is a simple extension of results from [12], and [78] where the authors consideredthis relationship for normal logic programs. Perhaps somewhat surprisingly, it is noteasily generalized to program with disjunction. One of the problems in finding a naturaltranslation from arbitrary A-Prolog programs to default theories is related to the inabilityto use defaults with empty justifications in reasoning by cases: The default theory with(cid:4)(cid:7)q :p,r :pD =andW = {q ∨ r}does not have an extension containing p and therefore, does not entail p. The correspond-ing logic programp ← qp ← rq or r.has two answer sets {p, q} and {p, r} and hence entails p.6. A-Prolog and negation in logic programsIn this section we will briefly discuss the treatment of negation in logic programming.Let us start with definite programs, i.e., programs consisting of the rulesl0 ← l1, . . . , lm(27)where l’s are atoms. Traditionally, such programs were viewed as (complete) definitions ofobjects and relations of the domain, and therefore, the lack of information about, say, truthof p(a) was interpreter as evidence of its falsity. This is a familiar closed world assumptionwhich, theoretically, can be formalized as an ‘inference rule’ of the formΠ (cid:4)|= l¬lor equivalentlyl /∈ MΠ¬l(28)M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3823where MΠ is the minimal Herbrand model of Π . Of course the above statements do notreally qualify as inference rules. First, their premises are not logical formulas, but thestatements of the meta language. Second, since nonprovability for definite programs isundecidable it is not always possible to determine if the rule is applicable or not. As aresult a somewhat weaker version of CWA was implemented in Prolog: ¬l is derivablefrom Π if the goal l has a finitely failed SLD tree with respect to Π . (For a definition ofSLD trees and other related concepts see [3] or [101].)l has a finitely failed SLD tree¬l.(29)To better understand the difference between the two let us consider a program Π = {p ←p}. It is easy to see that (28) entails ¬p while (29) does not. (The Prolog interpreteranswering query p to Π will go into an infinite loop.) The difference can be used to dividethe work on semantics of negation of Prolog into two parts. One approach attempts toformalize systems based on rule (28) and another is more interested in generalizations ofrule (29). For simplicity we limit our discussion to semantics of normal logic programs,programs consisting of rules of the forml0 ← l1, . . . , lm, not lm+1, . . . , not lnwhere l’s are (not necessarily ground) atoms.6.1. Clark’s completion(30)The research on finding a declarative semantics for the nlp negation started with thepioneering work of Clark [30]. Given a nlp Π we can view the bodies of rules with apredicate p in their heads as “sufficiency” conditions for inferring p from the program.Clark suggested that the bodies of these rules can also be taken as “necessary” conditions,with the result that negative information about p can be assumed if all these conditions arenot met. More precisely, let us consider the following two step transformation of a nlp Πinto a collection of first-order formula:Step 1: Let r ∈ Π , head(r) = p(t1, . . . , tk), and Y1, . . . , Ys be the list of variableappearing in r. By α1(r) we denote a formula:∃Y1 . . . Ys : X1 = t1 ∧ · · · ∧ Xk = tk ∧∧ l1 ∧ · · · ∧ lm ∧ ¬lm+1 ∧ · · · ∧ ¬ln ⊃ p(X1, . . . , Xk)where, X1, . . . , Xk are variables not appearing in r(31)α1(Π) = {α1(r): r ∈ Π}.Step 2: For each predicate p ifE1 ⊃ p(X1, . . . , Xk)...Ej ⊃ p(X1, . . . , Xk)24M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38are all the implications in α1(Π) with p in their conclusions then replace these formulasby∀ X1 . . . Xk : p(X1, . . . , Xk) ≡ E1 ∨ · · · ∨ Ejif j (cid:2) 1 and by∀ X1 . . . Xk : ¬q(X1, . . . , Xk)if j = 0.Definition 6.1. The resulting first-order theory combined with free equality axioms from[30] is called Clark’s completion of Π and is denoted by Comp(Π). A literal l is entailedby Π if l ∈ Th(Comp(Π)).The following theorem [4] establishes the relationship between models of Clark’scompletion of Π and the notion of supported model. (A set S of atoms is supported byΠ if, for every l ∈ S, there is a rule (30) such that l1, . . . , lm ∈ S and lm+1, . . . , ln /∈ S.)Theorem 6.1. A set S of atoms is a model of Clark’s completion of Π iff S is supportedand closed under the rules of Π .Models of Clark’s completion may obviously differ from answer sets of Π . Programp ← p has two Clark’s models, { } and {p}, but only one answer set { }. This shall notbe surprising—the completion semantics intends to capture the notion of finite failureof a particular inference mechanism, SLDNF resolution, while answer sets semanticsformalizes more general notion of default negation. It is also important to note that theabove theorem immediately implies that every literal entailed by Π with respect to theClark’s semantics is also entailed by Π with respect to the answer set semantics.The existence of Clark’s declarative semantics facilitated the development of the theoryof logic programs. It made possible first proofs of correctness of inference mechanismbased on SLDNF resolution, and of certain transformations of logic programs such asfold/unfold [121], proofs of equivalence and other properties of programs. It is stillwidely and successfully used for logic programming applications. Unfortunately in manysituations the Clark’s semantics appears too weak. Consider for instance the followingexample:Example 6.1. Suppose that we are given a graph, say,edge(a, b). edge(c, d). edge(d, c).and want to describe vertices of the graph reachable from a given vertex a. The naturalsolution seems to be to introduce the rules:reachable(a).reachable(X) ← edge(Y, X),reachable(Y ).M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3825We clearly expect vertices c and d not to be reachable. However, Clark’s completion of thepredicate ‘reachable’ gives onlyreachable(X) ≡(cid:8)X = a ∨ ∃Y : reachable(Y ) ∧ edge(Y, X)(cid:9)from which such a conclusion cannot be derived.The difficulty was recognized as serious and prompted the development of other logicprogramming semantics, including that of the A-Prolog. Even though now there arecomparatively few knowledge representation languages which use Clark’s completion asthe basis for their semantics the notion didn’t loose its importance. As an illustration let usconsider its use for computing answer sets of logic programs. We will need the followingterminology.Definition 6.2. A nlp Π is called tight if there is a level mapping || || of Π such that forevery rule (30) of Π||l0|| > ||l1||, . . . , ||lm||.(32)Theorem 6.2. If Π is tight then S is a model of Comp(Π) iff S is an answer set of Π .The above theorem is due to F. Fages [43]. There are some recent results extending thenotions of Clark’s completion and of tightness, and discovering more general conditionsfor equivalence of the two semantics. Note that whenever the two semantics of Π areequivalent, Π ’s answer sets can be computed by a satisfiability solver which, in somecases, can be more efficient than the direct use of SMODELS or DLV . More on this workcan be found in [14].6.2. Three-valued approachesThere were several important modifications of the Clark’s semantics which are basedon the use of three-valued logic. The first such modification [44,63,64], aimed at capturingfinite failure with respect to SLDNF resolution, uses three-valued completion of a program.The following example illustrates the difference between two-valued and three valuedcompletions:Example 6.2. Consider program Π9:p ← not p.q.It is easy to see that COMP(Π9) is inconsistent while three-valued completion is consistentand has a unique model in which p is undefined and q is true. This corresponds to thebehavior of the SLDNF resolution which answers yes to q and goes into the loop onquery p.SLDNF resolution is sound with respect to the three valued completion. Unfortunately,it can be incomplete, but as shown in [26] the only sources of incompleteness are26M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38floundering and unfair selection of literals in the SLDNF derivation. Since there aremultiple sufficient conditions for avoiding floundering three-valued completion andSLDNF resolution seem to be a good match.The well-founded semantics of [125] formalizes negation viewed as (a not necessarilyfinite) failure. To give a precise definition we need the following terminology.For any nlp Π , the function from sets of literals to sets of literals is defined by theequationγΠ (X) = A(33)where A is the answer set of the reduct, Π X, from Definition 2.3 of answer set. It is clearthat the answer sets of Π can be characterized as the fixpoints of γΠ . It is not difficult toshow that, if X ⊂ Y then γΠ (Y ) ⊂ γΠ (X). This implies that the function γ 2Π is monotoneand hence has the least fixpoint. Atoms belonging to this fixpoint are called well-foundedrelative to Π . Atoms belonging to the complement of the greatest fixpoint of γ 2Π are calledunfounded relative to Π .Definition 6.3. A three-valued interpretation which assigns 1 (true) to atoms well-foundedrelative to Π , 0 (false) to atoms unfounded relative to Π , and 1/2 (undefined) to all theremaining atoms is called the well-founded model of Π . A literal l is a well-foundedconsequence of Π if it is true in Π ’s well-founded model.From the above definition one can easily see that every nlp has the well-founded modeland that every well-founded consequence of Π is also Π ’s consequence with respect tothe stable model semantics. To better understand the difference between the semantics letus look at several examples.Example 6.3. Consider the program Π9 from Example 6.2. It has no stable model (andhence Π9’s set of stable consequences consists of {p, ¬p, q, ¬q}). In contrast, the onlywell-founded consequence of Π9 is q. The set of unfounded atoms is empty and the onlyundefined atom is p.Example 6.4. Consider the following program Π10:p ← not a.p ← not b.a ← not b.b ← not a.Π10 has two stable models {p, a} and {p, b}. The well-founded model of Π10 has emptysets of well-founded and unfounded atoms. Therefore, p is a consequence of Π3 in thestable model semantics, while the answer to p in the well-founded semantics is undefined.M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3827Finally, let us look at the following example from [25]:Example 6.5. Consider Π11 consisting of rules:a ← not b.b ← c, not a.c ← a.This program has one answer set {a, c}, and so has a and c as its consequences. The well-founded model of Π11 has no well-founded atoms. Its unfounded atoms are {a, b, c} andhence, according to the well-founded semantics, atoms a, b, and c are undefined.There are large classes of programs for which both, well-founded and stable model,semantics coincide. (See for instance [13,109].) The SLDNF resolution is sound withrespect to the well-founded semantics but it is not complete. Several attempts were madeto define variants of SLDNF resolution which compute answers to goals according to thewell-founded entailment. One interesting approach, SLS resolution, can be found in [108,113]. SLS resolution is based on a type of an oracle and cannot therefore be viewed as analgorithm. There are however several algorithms and systems which can be viewed as SLSbased approximations of the well-founded semantics [15,21]. One of the most powerfulsuch systems, XSB (www.cs.sunysb.edu/ sbprolog/xsb-page.html) expands SLDNF withtabling and loop checking. Its use allows to avoid many of the loop related problems ofProlog. For instance, XSB’s answer to query reachable(c) for program from Example 6.1will be no (the Prolog interpreters will loop on this query).7. Computational complexityIn this section we will give a short overview of results on the computational complexityof A-Prolog programs.7.1. MotivationsOne may wonder why we should be interested in analyzing the complexity of A-Prolog.This question has been addressed very clearly by Gottlob in [53], who pointed out thatthere are three main reasons, why one should be interested in studying the (worst case)complexity of logic programming formalisms. We report these reasons below.First, the worst case complexity is a very good indicator of how many sources ofstructural complexity are inherent in a problem. For example, if a problem is NP-complete,then it contains basically one source of intractability, related to a choice to be made amongexponentially many candidates. If a problem is -P2 -complete then there are usually twointermingled sources of complexity. For instance, the problem of checking whether anA-Prolog program has an answer set is -P2 -complete. The two sources of complexity are(1) the choice of a suitable interpretation which is a model of the reduct of the programand (2) the proof that this model is minimal.28M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38Secondly, once the sources of complexity are identified, one can develop smartalgorithms that take these sources into account. In addition, it becomes easier to discovertractable (i.e., polynomial) subcases by considering syntactic restrictions that eliminate allsources of intractability.Finally, a precise complexity classification gives us valuable information about thealgorithmic similarity and inter-translatability of different problems. For instance, bothbrave reasoning on normal (or-free) A-Prolog programs and brave reasoning on head-cyclefree A-Prolog programs are NP-complete (see Table 2). Therefore, there are simple (i.e.,polynomial) translations between these two reasoning tasks. In particular, this means thatif one has implemented a reasoning engine (theorem prover) for one of these formalisms,this system can easily be adapted to become a reasoning engine for the other formalism.In most cases, the translations between two decision problems that are complete for thesame complexity class can easily be deduced from the respective completeness proofs.At least, the underlying intuitions in these proofs may help to find a suitable translationscheme. On the other hand, if it is known that two problems are complete for differentcomplexity classes in the polynomial hierarchy, the existence of a polynomial translationfrom the harder to the easier problem is unlikely. For example, brave reasoning with normal(nondisjunctive) A-Prolog programs is NP-complete (see Table 2). Therefore, unless thepolynomial hierarchy collapses, a polynomial translation from full A-Prolog programs tonormal programs cannot exist.In summary, the complexity analysis of a problem gives us much more than merelya quantitative statement about its tractability or intractability in the worst case. Rather,locating a problem at the right level in the polynomial hierarchy gives us a deep qualitativeknowledge about this problem. Moreover, the complexity analysis is a precious tools todevelop efficient implementations of A-Prolog systems. For instance, consider the problemof checking whether a given set of literals is an answer set or not. This problem isco-NP-complete for general A-Prolog programs; while it is polynomial for head-cycle freeprograms (see Table 1). Consequently, a smart implementation of function IsAnswerSet()(see Fig. 1) should be able to efficiently check this property if the program is head-cyclefree. Indeed, in the A-Prolog system DLV , the function devoted to answer set checkingrecognizes whether the input program is head-cycle free or not. An efficient polynomial-time method is then applied on head-cycle free programs; while a backtracking procedureis employed on general (non head-cycle free) A-Prolog programs. Similar considerationsapply also to other syntactic fragments having lower complexity than the general case. Forinstance, reasoning on normal stratified programs should be performed by a polynomialtime procedure (see Table 3) by an efficient A-Prolog system.7.2. Preliminaries on complexity: the polynomial hierarchyWe assume that the reader has some aquaintance with the concepts of NP-completenessand complexity theory, the book [103] is an excellent source for deepening the knowledgein this field.The classes -Pk and 8Pk of the Polynomial Hierarchy (PH) (cf. [119]) are defined asfollows:-P0= 8P0= P and for all k (cid:2) 1, -Pk= NP-Pk−1 , 8Pk= co--Pk .M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3829In particular, NP = -P1 . NPC denotes the class of problems that aresolvable in polynomial time on a nondeterministic Turing machine with an oracle for anyproblem π in the class C.1 , and co-NP = 8PThe oracle replies to a query in unit time, and thus, roughly speaking, models a callto a subroutine for π that is evaluated in unit time. If C has complete problems, theninstances of any problem π (cid:20) in C can be solved in polynomial time using an oracle forany C-complete problem π , by transforming them into instances of π ; we refer to this bystating that an oracle for C is used. Notice that all classes C considered here have completeproblems.Observe that for all k (cid:2) 1,-Pk⊆ -Pk+1⊆ PSPACE;and 8Pk⊆ 8Pk+1⊆ PSPACE;each inclusion is widely conjectured to be strict. Note that, by the rightmost inclusions,all these classes contain only problems that are solvable in polynomial space. They allow,however, a finer grained distinction between NP-hard problems that are in PSPACE.7.3. Main problems consideredWe study the complexity of the following three important decision problems arising inA-Prolog:• Answer Set Checking. Given an A-Prolog program Π , and a set M of ground literalsas input, decide whether M is an answer set of Π .• Brave reasoning. Given an A-Prolog program Π , and a ground literal l, decidewhether l is true in some answer sets of Π (i.e., Π |=b l).• Cautious reasoning. Given an A-Prolog program Π , and a ground literal l, decidewhether l is true in all answer sets of Π (i.e., Π |= l).7.4. Complexity resultsWe analyze the computational complexity of the three decision problems mentionedabove for ground (i.e., propositional) A-Prolog programs. An interesting issue is the impactof syntactical restrictions on the logic program Π . In particular, comparing the power ofdisjunction with the power of negation is intriguing [29].Starting from normal positive programs (without negation and disjunction), we considerthe effect of allowing the (combined) use of the following constructs:• strong negation,• stratified (nonmonotonic) negation,• arbitrary negation,• head-cycle free disjunction,• arbitrary disjunction (or).The complexity results for Answer Set Checking, Brave Reasoning and Cautious Rea-soning over A-Prolog programs are summarized in Table 1, Table 2, and Table 3, respec-30M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38Table 1The complexity of answer set checking in syntactic fragments of A-Prolog{ }PPco-NP{¬}PPco-NP{nots}PPco-NP{¬, nots }PPco-NP{not}PPco-NP{¬, not}PPco-NP{}{or h}{or}Table 2The complexity of brave reasoning in syntactic fragments of A-Prolog{nots}PNP-P2{¬, nots}PNP-P2{}{or h}{or}NPNP-P2PNP-P2PNP-P2{not}{¬}{}NPNP-P2{¬, not}Table 3The complexity of cautious reasoning in syntactic fragments of A-Prolog{}Pco-NPco-NPa{¬}Pco-NPco-NPa{}{or h}{or}{nots}Pco-NP8P2{¬, nots}Pco-NP8P2{not}co-NPco-NP8P2{¬, not}co-NPco-NP8P2a Note that here we consider the complexity of deciding if Π |= L, where L is either an atomor an atom negated by strong negation. Deciding if Π |= not L, i.e., if there is an answer setwhich does not contain L, is harder, precisely, this problem is 8P2 -complete [35].tively. Therein, each column refers to a specific form of negation, namely: {} = no negation,¬ = strong negation, nots = stratified negation, not = unrestricted (possibly unstratified)negation. The lines of the tables specify the allowance of disjunction; in particular, {} =no disjunction, orh = head-cycle free disjunction, or = unrestricted (possibly not head-cycle free) disjunction. Each entry of the table provides the complexity class of the corre-sponding fragment of the language. For an instance, the entry ({orh}, {nots}) defines thefragment of A-Prolog allowing head-cycle free disjunction and stratified negation. The cor-responding entry in Table 2, namely NP, expresses that brave reasoning for this fragmentis NP-complete. The results reported in the tables represent completeness under logspacereductions, they are taken from [29,35,36,53].As expected, the results for brave and cautious reasoning are symmetric in most cases,that is, whenever the complexity of a fragment is C under brave reasoning, its complexityis co-C under cautious reasoning (recall that co-P = P).Strong negation does not affect at all the complexity of reasoning; each columncontaining strong negation is equal to the corresponding column without it. Limitingthe forms of disjunction and nonmonotonic negation reduces the respective powers. Fordisjunction free programs, brave reasoning is polynomial on stratified negation, while itbecomes NP-complete if we allow unrestricted (nonmonotonic) negation. Brave reasoningis NP-complete on head-cycle free programs even if no form of negation is allowed. TheM. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3831complexity jumps one level higher in the polynomial hierarchy, up to -P2 -complexity,if full disjunction is allowed. Thus, disjunction seems to be harder than negation, sincethe full complexity is reached already on positive programs, even without any kind ofnegation.The picture is a bit different for cautious reasoning. Full disjunction alone is notsufficient to get the full complexity of cautious reasoning on A-Prolog (8P2 ), whichremains in co-NP if default negation is disallowed. Intuitively, to disprove that a literall is a cautious consequence of a program Π , it is sufficient to find a model (which does notneed to be an answer set or a minimal model) which does not contain l. Indeed, for not-free programs, the existence of such a model guarantees that there exists also an answer setof Π which does not contain l. Therefore, under cautious inference, positive programs areeasier to evaluate than programs with default negation; while, this is not true under braveinference modality.The complexity results for Answer Set Checking, reported in Table 1, help us tounderstand the complexity of reasoning. Whenever Answer Set Checking is co-NP-complete for a fragment F , then the complexity of brave reasoning jumps up to thesecond level of the polynomial hierarchy (to -P2 ). Indeed, brave reasoning on full A-Prologsuffers of two “orthogonal” sources of complexity: (i) the exponential number of answerset “candidates”, and (ii) the difficulty of checking whether a candidate M is an answerset (the minimality of M can be disproved by an exponential number of subsets of M).Now, disjunction (unrestricted or even head-cycle free) or unrestricted negation preservethe existence of source (i); while source (ii) exists only if full disjunction is allowed (seeTable 1). As a consequence, reasoning lies at the second level of the polynomial hierarchy(-P2 ) for the A-Prolog fragments where both such complexity sources are present; while,it goes down to the first level of PH if only source (i) is present (unrestricted negation, orhead-cycle free disjunction), falling down to level zero (P) if both sources are eliminated.8. Further program’s propertiesIn previous sections we already discussed some properties of logic programs, such assyntactic conditions guaranteeing existence and uniqueness of answer sets, the relationshipbetween entailment under different semantics, soundness and completeness properties ofvarious inference systems and algorithms, etc. In this section we’d like to briefly commenton some results establishing general properties of logic programming entailment relations.Let us consider an A-Prolog program Π11 from Example 6.5. Its answer set is {a, c}and hence both a and c are the consequences of Π11. When augmented with the factc the program gains a second answer set {b, c}, and loses consequence a. The exampledemonstrates that the answer set entailment relation does not satisfy property:Π |= a, Π |= bΠ ∪ {a.} |= b(34)called cautious monotonicity. The absence of cautious monotonicity is an unpleasantproperty of the answer set entailment. Among other things it prohibits the developmentof general inference algorithms for A-Prolog in which already proven lemmas are simply32M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38added to the program. We will say that a class of programs is cautiously monotonic ifprograms from this class satisfy condition (34). To give an example of such a class let usconsider a syntactic condition on programs known as order-consistency [114].Definition 8.1. For any nlp Π and atom a, Π +that a ∈ Π +a and, for every rule r ∈ Π ,a and Π −a are the smallest sets of atoms such• if head(r) ∈ Π +• if head(r) ∈ Π −a then pos(r) ⊆ Π +a then pos(r) ⊆ Π −a and neg(r) ⊆ Π −a ,a and neg(r) ⊆ Π +a .Intuitively, Π +a is the set of atoms on which atom a depends positively in Π , and Π −ais the set of atoms on which atom a depends negatively on Π . A program Π is order-consistent if there is a level mapping || || such that ||b|| < ||a|| whenever b ∈ Π +∩ Π −a .aThat is, if a depends both positively and negatively on b, then b is mapped to a lowerstratum. It is easy to see that program Π3 from Example 6.4 is order-consistent, whileprogram Π4 from Example 6.5 is not. The following important theorem is due to H. Turner[123].Theorem 8.1. If Π is an order-consistent program and atom a belongs to every answer setof Π , then every answer set of Π ∪ {a.} is an answer set of Π .This immediately implies condition (34) for order-consistent programs.A much simpler observation guarantees that all nlp’s under the answer set semanticshave so called cut property: If an atom a belongs to an answer set X of Π , then X is ananswer set of Π ∪ {a.}.Both results used together imply another nice property, called cumulativity: augmentinga program with one of its consequences does not alter its consequences. More precisely,Theorem 8.2. If an atom a belongs to every answer set of an order-consistent program Π ,then Π and Π ∪ {a.} have the same answer sets.Semantic properties such as cummulativity, cut, and cautious monotonicity wereoriginally formulated for analysis of nonmonotonic consequence relations [46,65].Makinson’s [75] handbook article includes a survey of such properties for nonmonotoniclogics used in AI.9. ConclusionIn this paper we described several important themes related to research on logicprogramming and knowledge representation in A-Prolog. The papers in this volumeexpand on these foundations. They are selected from those presented at LPNMR99—5thInternational Conference on Logic Programming and Non-Monotonic Reasoning, held in1999 in El Paso, Texas. These papers are significant extensions of the respective versionspresented at the conference.M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3833Lifschitz’s paper [72] illustrates the application of the declarative programmingmethodology of A-Prolog to the planning domain. The work by Gottlob et al. [54]addresses some important fixed-parameter complexity questions in artificial intelligenceand nonmonotonic reasoning. The paper by Alferes et al. [2] deals with the issue ofupdates in logic programming, introducing a language, called LUPS, for specifyingdynamic changes in knowledge bases. Cui and Swift [31] report on the successfulapplication of the preference logic grammars to the problem of data standardization.Marek et al. [76] define an “annotated” version of the revision programs of Marekand Truszczy´nski. While revision programs are used to update, essentially, classicalpropositional interpretations (complete databases), annotated revision programs are morepowerful allowing one to update the general “T-valuations”. Finally, Simons and Niemelä[118] describe an interesting linguistic extension of A-Prolog, which allows us to expresscardinality constraints and weight constraints more naturally; it also illustrates one of themost popular A-Prolog systems, SMODELS.There is a number of other logical languages and reasoning methods which can beviewed as alternatives to A-Prolog. They were developed in approximately the same timeframe as A-Prolog, share the same roots and a number of basic ideas. The relationshipand mutual fertilization between these approaches is a fascinated subject which was notaddressed here. For more information the interested reader can look at [1,16,21,24,57,127].AcknowledgementsThe authors are grateful to Georg Gottlob for his contribution on complexity issues.References[1] J.J. Alferes, L.M. Pereira, Reasoning with Logic Programming, Springer, Berlin, 1996.[2] J.J. Alferes, L.M. Pereira, H. Przymusinska, T.C. Przymusinski, LUPS—A language for updating logicprograms, Artificial Intelligence 138 (2002) 87–116, this issue.[3] K. Apt, From Logic Programming to Prolog, C.A.R. Hoare Series, Prentice Hall, Englewood Cliffs, NJ,1997.[4] K. Apt, H. Blair, A. Walker, Towards a theory of declarative knowledge, in: J. Minker (Ed.), Foundationsof Deductive Databases and Logic Programming, Morgan Kaufmann, San Mateo, CA, 1988, pp. 89–148.[5] K. Apt, D. Pedreschi, Proving termination in general prolog programs, in: Proc. Internat. Conference onTheoretical Aspects of Computer Software, Lecture Notes in Computer Science, Vol. 526, Springer, Berlin,1991, pp. 265–289.[6] K. Apt, A. Pellegrini, On the occur-check free logic programs, ACM Trans. Program. LanguageSystems 16 (3) (1994) 687–726.[7] K. Apt, R. Bol, Logic Programming and negation: A survey, J. Logic Programming 19–20 (1994) 9–71.[8] C. Baral, Knowledge representation, reasoning and declarative problem solving with answer sets,Unpublished manuscript, www.public.asu.edu/~cbaral/bahi/.[9] C. Baral, M. Gelfond, Logic programming and knowledge representation, J. Logic Programming 19,20(1994) 73–148.[10] C. Baral, M. Gelfond, Reasoning agents in dynamic domains, in: J. Minker (Ed.), Logic Based AI, Kluwer,Dordrecht, 2000, pp. 257–279.[11] R. Ben-Eliyahu, R. Dechter, Propositional semantics for disjunctive logic programs, Ann. Math. ArtificialIntelligence 12 (1994) 53–87.34M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38[12] N. Bidoit, C. Froidevaux, Generallogical databases and programs: Defaultlogic semantics andstratification, J. Inform. Comput. 91 (1) (1991) 15–54.[13] N. Bidoit, C. Froidevaux, Negation by default and unstratifiable logic programs, Theoret. Comput.Sci. 79 (1) (1991) 86–112.[14] Yu. Babovich, E. Erdem, V. Lifschitz, Fages’ theorem and answer set programming, in: Proc. 8thInternational Workshop on Non-Monotonic Reasoning, Breckeridge, CO, 2000.[15] R. Bol, L. Degerstedt, Tabulated resolution for the well-founded semantics, J. Logic Programming 34 (2)(1998) 67–110.[16] A. Bondarenko, P.M. Dung, R. Kowalski, F. Toni, An abstract, argumentation-theoretic approach to defaultreasoning, Artificial Intelligence 93 (1–2) (1997) 63–101.[17] G. Brewka, J. Dix, K. Konolige, Nonmonotonic Reasoning: An Overview, CSLI Publications, Stanford,1997.[18] M. Cadoli, T. Eiter, G. Gottlob, Default logic as a query language, IEEE Trans. Knowledge Data Engrg. 9(3) 448–463.[19] F. Calimeri, W. Faber, N. Leone, G. Pfeifer, Pruning operators for answer set programming systems, DBAI-TR-01-10, Institut für Informationssysteme, Technische Universität Wien, Austria, April, 2001.[20] J. Chen, Minimal knowledge + negation as failure = only knowing (sometimes), in: Proc. Second Internat.Workshop on Logic Programming and Nonmonotonic Reasoning, Lisbon, 1993, pp. 132–150.[21] W. Chen, T. Swift, D. Warren, Efficient top-down computation of queries under the well-founded semantics,J. Logic Programming 24 (3) (1995) 161–201.[22] P. Cholewinski, W. Marek, M. Truszczy´nski, Default reasoning system DeReSe, in: Proc. Internat.Conference on Principles of Knowledge Representation and Reasoning, Morgan Kauffman, San Mateo,CA, 1996, pp. 518–528.[23] A. Colmerauer, H. Kanoui, R. Pasero, P. Roussel, Un systeme de communication homme-machine enFrancais, Technical Report, Groupe de Intelligence Artificielle Université de Aix-Marseilles II, Marseilles,1973.[24] D. De Schreye, M. Bruynooghe, B. Demoen, M. Denecker, G. Janssens, B. Martens, Project report onLP+: A second generation logic programming language, AI Comm. 13 (1) (2000) 13–18.[25] J. Dix, Classifying semantics of logic programs, in: Proc. International Workshop in Logic Programmingand Non-Monotonic Reasoning, Washington, DC, 1991, pp. 166–180.[26] W. Drabent, Completeness of SLDNF-resolution for nonfloundering queries, J. Logic Programming 27 (2)(1996) 89–106.[27] T. Eiter, N. Leone, C. Mateis, G. Pfeifer, F. Scarcello, A deductive system for nonmonotonic reasoning, in:Proc. 4th Logic Programming and Non-Monotonic Reasoning Conference (LPNMR-97), Lecture Notes inArtificial Intelligence, Vol. 1265, Springer, Dagstuhl, 1997, pp. 363–374.[28] T. Eiter, W. Faber, N. Leone, G. Pfeifer, Declarative problem solving using the DLV system, in: J. Minker(Ed.), Logic Based AI, Kluwer Academic, Dordrecht, 2000, pp. 79–103.[29] T. Eiter, G. Gottlob, H. Mannila, Disjunctive Datalog, ACM Trans. Database Systems 22 (3) (1997) 364–418.[30] K. Clark, Negation as failure, in: H. Gallaire, J. Minker (Eds.), Logic and Data Bases, Plenum Press, NewYork, 1978, pp. 293–322.[31] B. Cui, T. Swift, Preference Logic grammars: Semantics, standardization, and application to datastandardization, Artificial Intelligence 138 (2002) 117–147, this issue.[32] Y. Dimopoulos, B. Nebel, J. Koehler, Encoding planning problems in nonmonotonic logic programs, in:Recent Advances in AI Planning, Proc. 4th European Conference on Planning, ECP-97, Lecture Notes inArtificial Intelligence, Vol. 1348, Springer, Berlin, 1997, pp. 169–181.[33] D. East, M. Truszczy´nski, dcs: An implementation of DATALOG with Constraints,in: Proc. 8thInternational Workshop on Nonmonotonic Reasoning (NMR-2000), Breckenridge, CO, 2000.[34] U. Egly, T. Eiter, H. Tompits, S. Woltran, Solving advanced reasoning tasks using quantified booleanformulas, in: Proc. AAAI-00 2000, Austin, TX, AAAI Press/MIT Press, Cambridge, MA, 2000, pp. 417–422.[35] T. Eiter, G. Gottlob, On the computational cost of disjunctive logic programming: Propositional case, Ann.Math. Artificial Intelligence 15 (3–4) (1995) 289–323.M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3835[36] T. Eiter, N. Leone, D. Saccá, Expressive power and complexity of partial models for disjunctive deductivedatabases, Theoret. Comput. Sci. 206 (1–2) (1998) 181–218.[37] C. Elkan, A rational reconstruction of nonmonotonic truth maintenance systems, Artificial Intelligence 43(1990) 219–234.[38] K. Esghi, Computing stable models by using the ATMS, in: Proc. AAAI-90, Boston, MA, 1990, pp. 272–277.[39] E. Erdem, V. Lifschitz, M. Wong, Wire routing and satisfiability planning, in: Proc. CL-2000, 2000,pp. 822–836.[40] W. Faber, N. Leone, C. Mateis, G. Pfeifer, Using database optimization techniques for nonmonotonicreasoning, in: Proc. 7th International Workshop on Deductive Databases and Logic Programming (DDLP-99), Japan, 1999, pp. 135–139.[41] W. Faber, N. Leone, G. Pfeifer, Pushing goal derivation in DLP computations, in: Proc. 5th InternationalConference on Logic Programming and Non-Monotonic Reasoning (LPNMR-99), El Paso, TX, LectureNotes in Artificial Intelligence, Vol. 1730, Springer, Berlin, 1999, pp. 177–191.[42] W. Faber, N. Leone, G. Pfeifer, Experimenting with heuristics for answer set programming, in: Proc. IJCAI-01, Seattle, WA, Morgan Kaufmann, San Mateo, CA, 2001, pp. 635–640.[43] F. Fages, Consistency of Clark’s completion and existence of stable models, J. Methods Logic Comput.Sci. 1 (1) (1994) 51–60.[44] M. Fitting, A Kripke–Kleene semantics for logic programs, J. Logic Programming 2 (4) (1985) 295–312.[45] E. Franconi, A. Laureti Palma, N. Leone, S. Perri, F. Scarcello, Census data repair: A challengingapplication of disjunctive logic programming, in: Proc. LPAR-01, Cuba, Springer, Berlin, 2001.[46] D. Gabbay, Theoretical foundations for nonmonotonic reasoning in expert systems, in: K.R. Apt (Ed.),Proc. NATO Advanced Study Institute on Logics and Models of Concurrent Systems, La Colle-sur-Loup,France, Springer, Berlin, 1985, pp. 439–457.[47] L. Giordano, A. Martelli, Generalized stable models, truth maintenance and conflict resolution, in: D.Warren, P. Szeredi (Eds.), Logic Programming: Proc. Seventh International Conference, MIT Press,Cambridge, MA, 1990, pp. 427–441.[48] M. Gelfond, On stratified autoepistemic theories, in: Proc. AAAI-87, Seattle, WA, 1987, pp. 207–211.[49] M. Gelfond, V. Lifschitz, The stable model semantics for logic programming, in: R. Kowalski, K. Bowen(Eds.), Logic Programming: Proc. Fifth Internat. Conference and Symposium, 1988, pp. 1070–1080.[50] M. Gelfond, V. Lifschitz, Classical negation in logic programs and disjunctive databases, New GenerationComput. (1991) 365–387.[51] M. Gelfond, V. Lifschitz, Representing actions and change by logic programs, J. Logic Programming 17,301–323.[52] M. Gelfond, T. Son, Reasoning with prioritized defaults, in: J. Dix, L.M. Pereira, T. Przymusinski (Eds.),Lecture Notes in Artificial Intelligence, Vol. 1471, Springer, Berlin, 1998, pp. 164–224.[53] G. Gottlob, Complexity and expressive power of disjunctive logic programming, in: Proc. InternationalLogic Programming Symposium (ILPS-94), Ithaca, NY, MIT Press, Cambridge, MA, 1994, pp. 23–42.[54] G. Gottlob, F. Scarcello, M. Sideri, Fixed-parameter complexity in AI and nonmonotonic reasoning,Artificial Intelligence 130 (2002) 55–86, this issue.[55] C. Green, Theorem proving by resolution as a basis for question—Answering systems, in: B. Meltzer, D.Michie (Eds.), Machine Intelligence, Vol. 4, Edinburgh University Press, Edinburgh, 1969, pp. 183–205.[56] P. Hayes, Computation and deduction, in: Proc. Second Symposium on Mathematical Foundations ofComputer Science, Czechoslovakian Academy of Sciences, Czechoslovakia, 1973, pp. 105–118.[57] A.C. Kakas, R. Kowalski, F. Toni, The role of abduction in logic programming, in: D.M. Gabbay, C.J.Hogger, J.A. Robinson (Eds.), Handbook of Logic in Artificial Intelligence and Logic Programming, Vol. 5,Oxford University Press, Oxford, 1998, pp. 235–324.[58] M. Kaminski, A note on the stable model semantics of logic programs, Artificial Intelligence 96 (2) (1997)467–479.[59] M. Kaminski, A comparative study of open default theories, Artificial Intelligence 77 (2) (1995) 285–319.[60] C. Koch, N. Leone, Stable model checking made easy, in: Proc. IJCAI-99, Stockholm, Sweden, MorganKaufmann, San Mateo, CA, 1999, pp. 70–75.[61] R. Kowalski, Predicate logic as a programming language, in: J.L. Rosenfeld (Ed.), Information Processing74, Proceedings of IFIP Congress 74, Stockholm, Sweden, North-Holland, Amsterdam, 1974, pp. 569–574.36M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38[62] R. Kowalski, Logic for Problem Solving, North-Holland, Amsterdam, 1979.[63] K. Kunen, Negation in logic programming, J. Logic Programming 4 (4) (1987) 289–308.[64] K. Kunen, Signed data dependencies in logic programs, J. Logic Programming 7 (3) (1989) 231–245.[65] D. Lehmann, What does a conditional knowledge base entail?, in: Proc. KR-89, Toronto, ON, 1989,pp. 212–221.[66] N. Leone, P. Rullo, F. Scarcello, Disjunctive stable models: Unfounded sets, fixpoint semantics andcomputation, Inform. and Comput. 135 (2) (1997) 69–112.[67] V. Lifschitz, Closed-world databases and circumscription, Artificial Intelligence 27 (1985) 229–235.[68] V. Lifschitz, On the declarative semantics of logic programs with negation, in: J. Minker (Ed.), Foundationsof Deductive Databases and Logic Programming, Morgan Kaufmann, San Mateo, CA, 1988, pp. 177–192.[69] V. Lifschitz, On open defaults, in: J. Lloyd (Ed.), Computational Logic: Symposium Proceedings, Springer,Berlin, 1990, pp. 80–95.[70] V. Lifschitz, G. Schwarz, Extended logic programs as autoepistemic theories, in: Proc. Second Internat.Workshop on Logic Programming and Non-Monotonic Reasoning, Lisbon, 1993, pp. 101–114.[71] V. Lifschitz, Foundations of logic programming, in: G. Brewka (Ed.), Principles of Knowledge Represen-tation, CSLI Publications, 1996, pp. 69–128.[72] V. Lifschitz, Answer set programming and plan generation, Artificial Intelligence 138 (2002) 39–54, thisissue.[73] V. Lifschitz, Circumscription, in: D.M. Gabbay, C.J. Hogger, J.A. Robinson (Eds.), The Handbook onLogic in AI and Logic Programming, Vol. 3, Oxford University Press, Oxford, 1994, pp. 298–352.[74] J. Lobo, J. Minker, A. Rajasekar, Foundations of Disjunctive Logic Programming, MIT Press, Cambridge,MA, 1992.[75] D. Makinson, General patterns in nonmonotonic reasoning, in: D.M. Gabbay, C.J. Hogger, J.A. Robinson(Eds.), The Handbook on Logic in AI and Logic Programming, Vol. 3, Oxford University Press, Oxford,1993, pp. 35–110.[76] V. Marek, I. Pivkina, M. Truszczy´nski, Annotated revision programs, Artificial Intelligence 138 (2002)149–180, this issue.[77] W. Marek, V.S. Subrahmanian, The relationship between logic program semantics and nonmonotonicreasoning, in: G. Levi, M. Martelli (Eds.), Proc. Sixth Internat. Conference on Logic Programming, Lisbon,Portugal, 1989, pp. 600–617.[78] W. Marek, M. Truszczy´nski, Stable semantics for logic programs and default reasoning, in: E. Lusk,R. Overbeek (Eds.), Proc. North American Conference on Logic Programming, Cleveland, OH, 1989,pp. 243–257.[79] W. Marek, M. Truszczy´nski, Autoepistemic logic, J. ACM 3 (38) (1991) 588–619.[80] W. Marek, M. Truszczy´nski, Reflexive autoepistemic logic and logic programming, in: Proc. Second In-ternat. Workshop on Logic Programming and Non-Monotonic Reasoning, Lisbon, MIT Press, Cambridge,MA, 1993, pp. 115–131.[81] W. Marek, M. Truszczy´nski, Stable models and an alternative logic programming paradigm, in: The LogicProgramming Paradigm: A 25-Year Perspective, Springer, Berlin, 1999, pp. 375–398.[82] W. Marek, M. Truszczy´nski, Nonmonotonic Logic, Springer, Berlin, 1993.[83] J. McCarthy, Programs with common sense, in: Proc. Teddington Conference on the Mechanization ofThought Processes, Her Majesty’s Stationery Office, London, 1959, pp. 75–91.[84] J. McCarthy, P. Hayes, Some philosophical problems from the standpoint of artificial intelligence, in: B.Meltzer, D. Michie (Eds.), Machine Intelligence, Vol. 4, Edinburgh University Press, Edinburgh, 1969,pp. 463–502.[85] J. McCarthy, Circumscription—A form of nonmonotonic reasoning, Artificial Intelligence 13 (1–2) (1980)27–39.[86] J. McCarthy, Applications of circumscription to formalizing common sense knowledge, ArtificialIntelligence 26 (3) (1986) 89–116.[87] N. McCain, H. Turner, Satisfiability planning with causal theories, in: Proc. Sixth International Conferenceon Principles of Knowledge Representation and Reasoning (KR-98), Trento, Italy, Morgan Kaufmann, SanMateo, CA, 1998, pp. 212–223.[88] D. McDermott, Nonmonotonic logic II: Nonmonotonic modal theories, J. ACM 29 (1) (1982) 33–57.[89] D. McDermott, J. Doyle, Nonmonotonic logic I, Artificial Intelligence 13 (1–2) (1980) 41–72.M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–3837[90] J. Minker, On indefinite data bases and the closed world assumption, in: Proc. CADE-82, New York, 1982,pp. 292–308.[91] J. Minker, Overview of disjunctive logic programming, Ann. Math Artificial Intelligence 12 (1994) 1–24.in: H. Levesque, F. Pirri (Eds.), Logical[92] J. Minker, Logic and Databases: A 20 year retrospective,Foundations for Cognitive Agents: Contributions in Honor of Ray Reiter, Springer, Berlin, 1999, pp. 234–299.[93] J. Minker (Ed.), Logic-Based Artificial Intelligence, Kluwer Academic, Dordrecht, 2000.[94] M. Minsky, A framework for representing knowledge, in: P. Winston (Ed.), The Psychology of ComputerVision, McGraw-Hill, New York, pp. 211–277.[95] R. Moore, Semantical considerations on nonmonotonic logic, Artificial Intelligence 25 (1) (1985) 75–94.[96] D. Nelson, Constructible falsity, J. Symbolic Logic 14 (1949) 16–26.[97] A. Nerode, R. Shore, Logic for Applications, Springer, Berlin, 1997.[98] I. Niemelä, Logic programs with stable model semantics as a constraint programming paradigm, Ann.Math. Artificial Intelligence 25 (3–4) (1999) 241–273.[99] I. Niemelä, P. Simons, Smodels—An implementation of the stable model and well-founded semantics fornormal logic programs, in: Proc. 4th International Conference on Logic Programming and Non-MonotonicReasoning, Dagstuhl, Germany, 1997, pp. 421–430.[100] T. Soininen, I. Niemelä, Developing a declarative rule language for applications in program configuration,in: Practical Aspects of Declarative Languages, Lecture Notes in Conputer Science, Vol. 1551, Springer,Berlin, 1999, pp. 305–319.[101] U. Nilsson, J. Maluszynski, Logic, Programming and Prolog, www.ida.liu.se/~ulfni/lpp.[102] M. Nogueira, M. Balduccini, M. Gelfond, R. Watson, M. Barry, A-Prolog decision support system for theSpace Shuttle, in: Proc. Third International Symposium on Practical Aspects of Declarative Languages,Lecture Notes in Computer Science, Vol. 1990, Springer, Berlin, 2001, pp. 169–183.[103] C.H. Papadimitriou, Computational Complexity, Addison-Wesley, Reading, MA, 1994.[104] D. Pearce, G. Wagner, Reasoning with negative information 1—Strong negation in logic programming,Technical Report, Gruppe fur Logic, Wissentheorie and Information, Freie Universität Berlin, 1989.[105] D. Pearce, A new logical characterization of stable models and answer sets, in: J. Dix, L. Pereira,T. Przymusinski (Eds.), Nonmonotonic Extensions of Logic Programming, Lecture Notes in ArtificialIntelligence, Vol. 1216, Springer, Berlin, 1997, pp. 57–70.[106] D. Pearce, From here to there: Stable negation in logic programming, in: D. Gabbay, H. Wansing (Eds.),What is Negation?, Kluwer, Dordrecht, 1999.[107] T. Przymusinski, On the declarative semantics of deductive databases and logic programs, in: J. Minker(Ed.), Foundations of Deductive Databases and Logic Programming, Morgan Kaufmann, San Mateo, CA,1988, pp. 193–216.[108] T. Przymusinski, Every logic program has a natural stratification and an iterated fixed point model, in: Proc.8th Symposium on Principles of Database Systems, Philadelphia, PA, 1989, pp. 11–21.[109] H. Przymusinska, T. Przymusinski, Weakly perfect model semantics for logic programs, in: R.A. Kowalski,K.A. Bowen (Eds.), Proc. 5th International Conference and Symposium on Logic Programming, Seattle,WA, 1988, pp. 1106–1120.[110] R. Reiter, On closed world data bases, in: H. Gallaire, J. Minker (Eds.), Logic and Data Bases, PlenumPress, New York, 1978, pp. 119–140.[111] R. Reiter, A logic for default reasoning, Artificial Intelligence 13 (1–2) (1980) 81–132.[112] R. Reiter, Circumscription implies predicate completion (sometimes), in: Proc. AAAI-82, Pittsburgh, PA,1982, pp. 418–420.[113] K. Ross, A procedural semantics for well-founded negation in logic programs, J. Logic Programming 13(1992) 1–22.[114] T. Sato, Completed logic programs and their consistency, J. Logic Programming 9 (1990) 33–44.[115] C. Sakama, K. Inoue, Prioritized logic programming and its application to commonsense reasoning,Artificial Intelligence 123 (1–2) (2000) 185–222.[116] M. Shanahan, Solving the Frame Problem: A Mathematical Investigation of the Commonsense Law ofInertia, MIT Press, Cambridge, MA, 1997.[117] G. Schwarz, Autoepistemic logic of knowledge, in: A. Nerode, V. Marek, V.S. Subrahmanian (Eds.), LogicProgramming and Nonmonotonic Reasoning: Proc. First Internat. Workshop, 1991, pp. 260–274.38M. Gelfond, N. Leone / Artificial Intelligence 138 (2002) 3–38[118] P. Simons, I. Niemelä, T. Soininen, Extending and implementing the stable model semantics, ArtificialIntelligence 138 (2002) 181–234, this issue.[119] L. Stockmeyer, Classifying the computational complexity of problems, J. Symbolic Logic 52 (1) (1987)1–43.[120] K. Stroetman, A completeness result for SLDNF-resolution, J. Logic Programming 15 (1993) 337–355.[121] H. Tamaki, T. Sato, Unfold/fold transformation of logic programs, in: S. Tarnlund (Ed.), Proc. 2ndInternational Logic Programming Conference, Uppsala, Sweden, 1984, pp. 127–138.[122] H. Turner, Representing actions in logic programs and default theories, J. Logic Programming 31 (1–3)(1997) 245–298.[123] H. Turner, Order-consistent programs are cautiously monotonic, Theory and Practice of Logic Program-ming 1 (4) (2001) 487–495.[124] M. van Emden, R. Kowalski, The semantics of predicate logic as a programming language, J. ACM 23 (4)(1976) 733–742.[125] A. Van Gelder, K. Ross, J. Schlipf, The well-founded semantics for general logic programs, J. ACM 38 (3)(1991) 620–650.[126] G. Wagner, Logic programming with strong negation and inexact predicates, J. Logic Comput. 1 (6) (1991)835–861.[127] J.-H. You, L. Yuan, A three-valued semantics for deductive databases and logic programs, J. Comput.System Sci. 49 (1994) 334–361.