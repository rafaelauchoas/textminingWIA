Artificial Intelligence 172 (2008) 1360–1399www.elsevier.com/locate/artintSemiring induced valuation algebras:Exact and approximate local computation algorithmsJ. Kohlas a,1, N. Wilson b,∗,2a Department of Informatics, University of Fribourg, Switzerlandb Cork Constraint Computation Centre, Department of Computer Science, IrelandReceived 4 April 2006; received in revised form 7 March 2008; accepted 18 March 2008Available online 27 March 2008AbstractLocal computation in join trees or acyclic hypertrees has been shown to be linked to a particular algebraic structure, called val-uation algebra. There are many models of this algebraic structure ranging from probability theory to numerical analysis, relationaldatabases and various classical and non-classical logics. It turns out that many interesting models of valuation algebras may bederived from semiring valued mappings. In this paper we study how valuation algebras are induced by semirings and how thestructure of the valuation algebra is related to the algebraic structure of the semiring. In particular, c-semirings with idempotentmultiplication induce idempotent valuation algebras and therefore permit particularly efficient architectures for local computation.Also important are semirings whose multiplicative semigroup is embedded in a union of groups. They induce valuation algebraswith a partially defined division. For these valuation algebras, the well-known architectures for Bayesian networks apply. We alsoextend the general computational framework to allow derivation of bounds and approximations, for when exact computation is notfeasible.© 2008 Elsevier B.V. All rights reserved.Keywords: Semirings; Local computation; Join tree decompositions; Soft constraints; Uncertainty; Valuation networks; Valuation algebras1. IntroductionMany different formalisms from artificial intelligence, including constraint systems, probabilistic networks, sys-tems of possibility measures or belief functions, from database theory, from logic, statistics and from numericalanalysis exhibit a common structure permitting local computation, i.e. computation on acyclic hypertrees, or jointrees. This algebraic structure has first been isolated in an abstract setting and related to local computation in [59],see also [37,53]. It has been further extended and studied in detail in [34]. The algebraic structure has been called avaluation algebra in [34].* Corresponding author.E-mail addresses: juerg.kohlas@unifr.ch (J. Kohlas), n.wilson@4c.ucc.ie (N. Wilson).URL: http://diuf.unifr.ch/tcs/juerg.kohlas (J. Kohlas).1 Research supported by grant No. 2100–042927.95 of the Swiss National Foundation for Research.2 This material is based partly upon works supported by the Science Foundation Ireland under grant No. 00/PI.1/C075 and grant No. 05/IN/I886.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.03.003J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991361In a valuation algebra, each piece of information φ, called a valuation, has an associated set s of variables; φ givesinformation about variables s. For example, in a constraint satisfaction problem or relational database φ may expressa relation on s, saying which assignments of these variables are feasible. Alternatively, in a soft constraints system itmay express preferences for different assignments, or in a system for reasoning with uncertainty such as possibilitytheory or Bayesian networks, it may express degrees of uncertainty of the different assignments to variables s.It is assumed that we have a way of combining valuations, through an operation ⊗, which gives their combinedeffect; the combination operator is associative and commutative. If ψ is another valuation on variables t then thecombination φ ⊗ ψ is a valuation on variables s ∪ t, since φ and ψ together say something about variables s ∪ t.Valuation algebras also assume another operation, called projection or marginalization, which focuses informationonto a smaller set of variables. Suppose u is a subset of s. Then φ↓u represents what valuation φ tells us about u. If,for example, φ is a probability distribution or potential, then φ↓u is the marginal on u. Alternatively, if φ represents abinary constraint relating variables X1 and X2 then it tells us which assignments to {X1, X2} are possible, and φ↓{X1}tells us which assignments to X1 are possible.The inputs of many important computational reasoning problems can be expressed as a collection of valuationsφ1, . . . , φk (in an appropriate valuation algebra), where the associated sets of variables are all fairly small. The combi-nation of these gives us the combined effect of all our information. For example, in a constraint satisfaction problem,the combination represents all the solutions, and in a relational database, the combination is the join of all the relations.In a Bayesian network, the combination represents the full probability distribution over all the variables. It will veryoften be infeasible to represent this whole combination directly, since involves all the variables, for which there are anexponential number of assignments. Typically we are interested in what the information tells us about certain smallsets of variables. So, for particular sets u, we want to compute the projection of the whole combination to u. This isknown as the projection problem. Direct computation is very often not feasible. For a single set u, an approach basedon sequential variable elimination can be used to compute the associated marginal. For the computation for severalsets u, faster methods have been developed based on use of an appropriate join tree, that is, a tree whose nodes areassociated with sets of variables which satisfy the running intersection property: that if variable X is associated withtwo nodes then it is associated with every node in the path between the two nodes.Such join tree algorithms for computing several marginals have two parts: an inward phase where information ispassed iteratively from the leaves to a chosen root node; and an outward phase where information is distributed outagain, iteratively from the root to all the nodes. As discussed below (and in more detail in [34]) there are a number ofdifferent variations on this local computational architecture.It turns out that many important examples of valuation algebras can be induced by valuations taking values in asemiring. This has first been proposed in the domain of constraint systems, where classical crisp constraints are gener-alized to fuzzy constraints, weighted constraints and partially satisfied constraints [8,9]. But probability potentials asused in Bayesian networks [41] belong also to the same class of valuations, as do relational systems [4,42]. Possibilitypotentials and Spohn potentials [60] provide further examples of valuations based on semirings. Other instances andapplications of semiring-induced valuation algebras are described in [1].In the second section we introduce semirings and give several examples which are related to important valuationalgebras. A semiring consists of a set A with two operations on it, conventionally labeled + and ×, both of which weassume to be associative and commutative; it is also assumed that × distributes over +. An example is the nonnegativereal numbers under addition and multiplication. A valuation on variables s in the induced valuation algebra is a func-tion which assigns a nonnegative real number to each assignment to variables s. Combination is based on pointwisemultiplication, and marginalization involves summation over the values of variables being eliminated. This semiringinduced valuation algebra is therefore that of probability potentials, used for reasoning with Bayesian networks.Any semiring induces a valuation algebra in just the same way, as shown in Section 3, which also discusses localcomputation based on these semirings.In this paper we study valuation algebras induced by semirings in some detail. In particular, we want to knowhow the structure of a valuation algebra is conditioned by the structure of the inducing semiring. These are importantquestions for practical purposes: Valuation algebras provide the structure needed for local computation architectures.There exist particularly efficient architectures which use some form of division in the valuation algebra [29,41].It is therefore important to know, what properties of the inducing semiring guarantee the existence of a concept ofdivision in the induced valuation algebra and thus the usability of the corresponding architecture for local computa-tion [34,37]. Further, idempotent valuation algebras, so-called information algebras, have interesting properties and1362J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399allow particularly simple local computation architectures. Therefore it is important to know which semirings leadto idempotent valuation algebras. Idempotent valuation algebras and their corresponding computational structure areanalyzed in Section 4, and in Section 5 we study semirings which induce valuation algebras with division and discusstheir local computation architectures. This study helps to extend computational schemes, well known in probabilitynetworks and relational algebra, to more general structures and to develop generic architectures for local computation[47].It may well happen that, for a problem of interest, exact local computation is not feasible. For certain importantsystems of valuations, it has been demonstrated, e.g., in [24], how the local computations can be approximated usingthe ‘mini-buckets’ and ‘mini-clustering’ techniques. We show in Section 6 how this kind of technique can be appliedvery generally to valuation algebras, in particular, those induced by a semiring; we focus especially on computingupper and lower bounds. We also consider the use of constraint propagation for improving the efficiency of localcomputation.Provisional versions of parts of this work appear in [35] and [62].2. SemiringsThis section defines different kinds of semirings which are relevant to valuation algebras of interest in areas ofautomated reasoning, such as uncertain reasoning and constraint-based reasoning.Semirings are algebraic structures composed of two operations. So, let A be a set with two binary operations +and × defined in it. We call a tuple A = (cid:6)A, +, ×(cid:7) a semiring, if both operations + and × are commutative andassociative, and if × distributes over +. Elsewhere this is often called a commutative semiring. If there is an element0 ∈ A such that 0 + a = a + 0 = a and 0 × a = a × 0 = 0 for all a ∈ A, then A is called a semiring with zero element.In this case the zero element 0 is clearly unique. A zero element can be adjoined to any semiring. Let (cid:6)A, +, ×(cid:7) bea semiring. Add an extra element 0 to A and extend + and × to A ∪ {0} by, for all a ∈ A, a + 0 = 0 + a = a anda × 0 = 0 × a = 0. Then it is easy to verify that (cid:6)A ∪ {0}, +, ×(cid:7) is a semiring.Similarly, an element 1 ∈ A is said to be a unit element, if 1 × a = a × 1 = a for all a ∈ A. There can be at mostone unit element 1 in a semiring. Note that if in these cases A is a group under the operation +, then A is a ring. Iffurthermore A − {0} is a group under the operation ×, then A is a field.The associativity of + allows us to write expressions like a1 + a2 + · · · + an orI1 ∪ · · · ∪ In, where the Ij are finite and disjoint, then commutativity and associativity entail thati ai , and in particular, if I =(cid:2)n(cid:3)(cid:3)j =1i∈Ijai =(cid:3)i∈Iai.If A is a semiring with zero element and ifa + b = 0 implies a = b = 0,i ai .(cid:4)then A is called positive. In the same way, the associativity of × permits to write expressions like a1 × a2 × · · · × anorIf the operation + is idempotent, i.e. a + a = a for all a ∈ A, then the semiring A = (cid:6)A, +, ×(cid:7) can be extended toinclude a unit element as follows: For each a ∈ A define a new element a1 such that a (cid:9)= b implies a1 (cid:9)= b1. Let thenA(cid:10) = A ∪ A1, where A1 = {a1: a ∈ A}. Define +(cid:10) as follows, when a and b are arbitrary elements of A: a +(cid:10) b = a + b,and a +(cid:10) b1, a1 +(cid:10) b and a1 +(cid:10) b1 are all defined to be (a + b)1. Further define ×(cid:10) as follows: a ×(cid:10) b = a × b anda ×(cid:10) b1 and a1 ×(cid:10) b are both defined to be (a × b) + a and a1 ×(cid:10) b1 is defined to be (a1 ×(cid:10) b) +(cid:10) a1. The systemA(cid:10) = (cid:6)A(cid:10), +(cid:10), ×(cid:10)(cid:7) is then a semiring with unit element 01; and +(cid:10) is also idempotent.Let A = (cid:6)A, +, ×(cid:7) be a semiring. We define a relation (cid:11)A on A (abbreviated to (cid:11) in this section) by: a (cid:11) b, if andonly if, either a = b or there exists a c ∈ A such that a + c = b. If A has a zero element, then the last condition coversthe first one, since we may take c = 0.Proposition 1. For any semiring A = (cid:6)A, +, ×(cid:7), the associated relation (cid:11) satisfies the following properties:(1) Relation (cid:11) is a pre-order, i.e., it is reflexive and transitive;J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991363(2) a (cid:11) b and a(cid:10) (cid:11) b(cid:10) imply a + a(cid:10) (cid:11) b + b(cid:10) and a × a(cid:10) (cid:11) b × b(cid:10);(cid:2)n(3) if, for all i = 1, . . . , n, ai (cid:11) bi , theni=1 bi and(4) for all a, b ∈ A, a (cid:11) a + b and if a has a zero element 0 then 0 (cid:11) a;(5) if a + a = a and b + b = b, then a (cid:11) b if, and only if, a + b = b.ni=1 ai (cid:11)(cid:4)ni=1 ai (cid:11)(cid:2)(cid:4)ni=1 bi ;Proof. (1) Clearly (cid:11) is reflexive. Suppose that a (cid:11) b and b (cid:11) c. Thus, there exist d and e such that a + d = b andb + e = c, hence a + (d + e) = c. This proves that a (cid:11) c.(2) Suppose a (cid:11) b and a(cid:10) (cid:11) b(cid:10), i.e. there exist c and c(cid:10) with a +c = b and a(cid:10) +c(cid:10) = b(cid:10). Then a +a(cid:10) +(c +c(cid:10)) = b +b(cid:10),hence a +a(cid:10) (cid:11) b +b(cid:10) as required. For the second part it is sufficient to show that a (cid:11) b implies a ×a(cid:10) (cid:11) b ×a(cid:10) since thiscan be applied twice using commutativity of × to get the result. Suppose a (cid:11) b, so that there exists c with a + c = b.Then b × a(cid:10) = (a + c) × a(cid:10) = (a × a(cid:10)) + (c × a(cid:10)) which implies that a × a(cid:10) (cid:11) b × a(cid:10).(3) follows by repeated application of (2).(4) follows, since 0 + a = a.(5) If a + b = b, then by definition a (cid:11) b. Conversely, if a (cid:11) b, and there exists a c with a + c = b. Then a + b + c =b + b = b. Hence a + b = a + a + b + c = a + b + c = b as required. (cid:2)Often the operation + is assumed to be idempotent, i.e. ∀a ∈ A we have a + a = a. Note that idempotency of + isimplied by idempotency of the unit, since if 1 + 1 = 1 then a + a = a × (1 + 1) = a × 1 = a. If A has a zero and aunit element and if furthermore for all a ∈ A,a + 1 = 1,(and hence + is idempotent) then we call A a c-semiring [9] (“c” standing for constraint) [8]. This is a special kind ofcommutative dioid [3]. According to Proposition 1 (4) the pre-order (cid:11)A becomes a partial order (cid:2)A (abbreviated to(cid:2)) in A defined in the following way:a (cid:2)A bif, and only if,a + b = b.The intended meaning of this order in applications is often that b is preferred over a, or that b is “better” than a.We refer to the examples below. The following lemma summarizes a few elementary, but important properties of thisorder.Lemma 1. Let A be a c-semiring.(1) ∀a ∈ A we have 0 (cid:2) a (cid:2) 1;(2) ∀a, b ∈ A we have a (cid:2) a + b and a × b (cid:2) a;(3) a (cid:2) a(cid:10) and b (cid:2) b(cid:10) imply a + b (cid:2) a(cid:10) + b(cid:10) and a × b (cid:2) a(cid:10) × b(cid:10);(4) a × b = a implies a (cid:2) b;(5) a + b = sup{a, b};(6) A is positive.Proof. (1) This follows from 0 + a = a and from a + 1 = 1.(2) First we have a + (a + b) = (a + a) + b = a + b by idempotency. Further, by the distributive law, a + (a × b) =(a × 1) + (a × b) = a × (1 + b) = a × 1 = a since b (cid:2) 1 by (1).(3) By assumption we have a + a(cid:10) = a(cid:10) and b + b(cid:10) = b(cid:10). Hence we obtain that (a + b) + (a(cid:10) + b(cid:10)) = (a + a(cid:10)) + (b +b(cid:10)) = a(cid:10) + b(cid:10) and also, by distributivity (a × b) + (a(cid:10) × b) = (a + a(cid:10)) × b = a(cid:10) × b. So we see that a × b (cid:2) a(cid:10) × b. Butthen it follows also that a(cid:10) × b (cid:2) a(cid:10) × b(cid:10) and hence, by transitivity a × b (cid:2) a(cid:10) × b(cid:10).(4) We have a + b = (a × b) + b = (a + 1) × b = 1 × b = b.(5) By (2) a, b (cid:2) a + b. Let c be another upper bound of a and b, a (cid:2) c and b (cid:2) c. Then by (3) a + b (cid:2) c + c = c.Thus a + b is the least upper bound.(6) Suppose a + b = 0. Then 0 (cid:2) a (cid:2) a + b = 0 (see Proposition 1). By transitivity of the order we get thus 0 (cid:2)a (cid:2) 0, hence from the antisymmetry of the partial order (cid:2) it follows that a = 0. Similarly b = 0 can be derived. (cid:2)1364J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399Our definition of c-semiring is equivalent to that given in [9], and that given in later papers such as [5]. Thedefinition of c-semiring in [8] is somewhat stronger since it assumes that summation is defined over infinite sets. Mostof the properties proved in [8] hold also for the slightly weaker definition of c-semiring, in particular properties inLemma 1.One result from [8] which does not hold for the weaker definition of c-semiring is Theorem 9 of [8], stating thata c-semiring is a complete lattice; with the definition used in this paper, a c-semiring is not necessarily a lattice, asshown by the following example.Consider the set A of all finite unions of closed discs (i.e., circles and their interiors) in R2, together with the emptyset and the whole set R2, and including also discs of radius zero, i.e., points. For a, b ⊆ R2 define a + b = a ∪ b, anddefine (cf. Example 4.17 of [3]) a × b = {x ∈ R2: x = y + z, y ∈ a, z ∈ b}, so that a × ∅ = ∅ for all a ∈ S. It can beshown that + and × are commutative and associative and for all a, b, c ⊆ R2, (a + b) × c = (a × c) + (b × c), i.e. ×distributes over +. A is clearly closed under +. It is also closed under ×: this follows using the fact that if a and bare discs then a × b is also a disc; this can be seen, for example, by translating both discs to have centre at the origin;disc a × b has radius equal to the sum of the radii of a and b. The distributive property then implies that A is closedunder ×. Hence (cid:6)A, +, ×(cid:7) is a semiring with zero element ∅ and unit element R2. For all a ∈ A, a + R2 = R2, so(cid:6)A, +, ×(cid:7) is a c-semiring (with the above definition). Consider any pair a and b of overlapping discs, where neithercontains the other. It can be seen that their intersection a ∩ b is not in A (e.g., by considering the curvature at a pointon the boundary of a ∩ b). Element c ∈ A is a lower bound for a and b if and only if c is a subset of a ∩ b. But a andb have no greatest lower bound in A. In fact, for any lower bound c in A, one can construct a strictly greater lowerbound in A by taking c ∪ {x}, where point x is an element of (a ∩ b) − c. Therefore A is not a lattice.We shall also consider c-semirings where the operation × is idempotent too, i.e. a × a = a for all a ∈ A. Thena (cid:2) b if a × b = a defines also a partial order in A. According to Lemma 1 it is identical to the order (cid:2)A.Theorem 10 of [8] shows that a c-semiring (in their sense) with idempotent × is a distributive lattice. The followingsimple result states that this holds also for the definition of c-semiring used here. (However, unlike c-semirings definedin [8], it need not be a complete distributive lattice. Consider for example the c-semiring of rational numbers in theinterval [0, 1] with + being max and × being min.)Theorem 1. (Cf. Theorem 10 of [8].) If A is a c-semiring, and × idempotent, then A is a distributive lattice anda × b = inf{a, b}.Proof. Since sup{a, b} = a + b exists, it remains only to prove that a × b = inf{a, b}, as distributivity is guaranteedin the semiring. In fact, by Lemma 1 (2) a × b (cid:2) a, b. Assume c (cid:2) a, b. Then, by Lemma 1 (3), c = c × c (cid:2) a × bwhich shows that a × b is the largest lower bound. (cid:2)There are many instances of semirings. We look now at a variety of examples of semirings to get a sense of thedifferent systems of practical and theoretical interest covered by these algebraic structures.Example 1 (Arithmetic semirings). Take for A the set of nonnegative real numbers R+ ∪ {0} with + and × designatingthe usual addition and multiplication. This is clearly a semiring with the number 0 as zero element and the number 1as unit element. The semiring is positive too. The order (cid:11) is in this case the usual total order between numbers. Thissemiring is needed for defining probability potentials as used in probabilistic networks, e.g. Bayesian networks, etc.(see Section 3). We could also consider the field of reals, integers or natural numbers. For example, ordinary additionand multiplication on the nonnegative integers N ∪ {0} yield also a positive semiring.Example 2 (Boolean semiring). Here we take A = {0, 1} (with the intention that 0 designates “false” and 1 “true”).Define then operation + as a + b = max{a, b} and a × b = min{a, b}. Operation + represents then the logical “or”(disjunction) and × the logical “and” (conjunction). This is a semiring with zero element 0 and unit element 1. Further,both + as well as × are idempotent operations. In addition, we have 0 + 1 = 1. Therefore, A is a c-semiring. In fact,this semiring is used to describe (crisp) constraint systems and the relational algebra (see Section 3).J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991365Example 3 (Bottleneck algebra). We may also take max for the + operation and min for the × operation on the setof real numbers R augmented with +∞ and −∞. Then −∞ is the 0-element and +∞ the unity. This algebra is ac-semiring and in fact a distributive lattice. It is called bottleneck algebra [12].Example 4 (Distributive lattices). We have seen that a c-semiring with × idempotent is a distributive lattice (The-orem 1). Conversely, every distributive lattice is clearly a semiring with joins for + and meets for ×-operations (orinversely). Both operations are idempotent. If the lattice has a bottom element ⊥ then this is the zero element ofthe semiring. If it has also a top element (cid:18), then this is the unit element. In this case the semiring is a c-semiring.This example generalizes the Boolean semiring above. The bottleneck algebra, Example 3, is also an example of adistributive lattice. But distributive lattices can be more generally used to express qualitative degrees of membershipof elements to fuzzy sets. Further, Boolean algebras are distributive lattices. Elements of Boolean algebras can alsodescribe assumptions to be satisfied for membership to certain sets. This will be discussed in Example 12 in Section 3.Example 5 ((max / min, +) semirings). We consider here A to consist of all nonnegative integers N ∪ {0, +∞}. Wetake min as the + operation: a + b = min{a, b}, whereas × is the usual addition with the convention that a + ∞ = ∞.Both operations are commutative and associative. The distributive law holds too,a + min{b, c} = min{a + b, a + c}.The operation min is idempotent, ∞ is the zero element, the integer 0 is the unit element, and we havemin{a, 0} = 0.This shows that we have again a c-semiring. It is also called the tropical semiring. This structure has been used in [60]to define a dynamic theory of graded belief states based on ordinal numbers, see Section 3. It arises also in the contextof applying dynamic programming to minimizing a sum of functions [34,55], and applies to weighted and partiallysatisfied constraints [9]. Instead of min for the +-operation we can also take max. Further we may take for A also thereals R or nonnegative reals R+ ∪ {0} with or without +∞ or −∞ adjoined. These (min, +) or (max, +) semiringshave many applications in networks, graph optimization, queuing systems and discrete event systems [38]; they canalso be used (by taking the logarithms of the probabilities) for computing the most probable complete assignment toa Bayesian network, and hence for finding the most probable explanation [46].Example 6 (t-norms). Triangular norms (t-norms) were originally introduced in the context of probabilistic metricspaces [44,52]. They are simply binary operations on the unit interval A = [0, 1] which are commutative and associa-tive, have the number 1 as unit element and are, in addition nondecreasing in both arguments:(1) ∀a, b, c ∈ [0, 1] we have T (a, b) = T (b, a) and T (a, T (b, c)) = T (T (a, b), c).(2) a (cid:2) a(cid:10) and b (cid:2) b(cid:10) imply T (a, b) (cid:2) T (a(cid:10), b(cid:10)).(3) ∀a ∈ [0, 1] we have T (a, 1) = T (1, a) = a and T (a, 0) = T (0, a) = 0.We may define the operation × on the unit interval by a t-norm and + as max. Both operations are commutative andassociative. That the distributive law holds can be concluded from the following consideration:(cid:6)T (a, b), T (a, c)(cid:5)T (a, b), T (a, c) (cid:2) max,hence(cid:7)a, max{b, c}(cid:8)(cid:5)(cid:2) max(cid:6)T (a, b), T (a, c).TBut we have also, by the monotonicity of the t-norm,(cid:7)a, max{b, c}(cid:8)T(cid:3) T (a, b), T (a, c),hence(cid:7)a, max{b, c}(cid:8)(cid:5)(cid:3) max(cid:6)T (a, b), T (a, c).T1366J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399This shows thata × (b + c) = T(cid:7)a, max{b, c}(cid:8)(cid:6)(cid:5)= maxT (a, b), T (a, c)= (a × b) + (a × c).The operation + is idempotent and has the number 0 as zero element. Further, we have for all a ∈ A, a + 1 = 1, so Ais a c-semiring.The following are typical t-norms:(1) Minimum t-norm: T (a, b) = min{a, b}.(2) Product t-norm: T (a, b) = a · b.(3) Lukasziewicz t-norm: T (a, b) = max{a + b − 1, 0}.(4) Drastic product: T (a, 1) = T (1, a) = a whereas T (a, b) = 0 in all other cases.In the first case the t-norm is idempotent. So the c-semiring induces a complete, distributive lattice. This is not thecase for the other examples. We shall see later (Section 5) that different t-norms distinguish themselves also in otherimportant aspects.We note that distributivity depends only on the monotonicity of the t-norm, but not on 1 being the unit element. Wemay more generally require that any other element e ∈ [0, 1] is the unit element. Then we obtain a uninorm [63] andwe still have a semiring, albeit no more necessarily a c-semiring. Further, instead of max for the + operation we maytake any other commutative, associative and nondecreasing binary operation, i.e. any uninorm. If its unit element isthe number 0, then the uninorm is called a t-conorm. Then the semiring has 1 as its zero element. We refer to [18,33]for more information on uninorms and t-norms. The concepts of t-norms and t-conorms are important in possibilitytheory and fuzzy set theory.Example 7 (Multidimensional semiring). Let A be a semiring with operations + and ×. We define in An operations+ and × as follows(a1, . . . , an) + (b1, . . . , bn) = (a1 + b1, . . . , an + bn),(a1, . . . , an) × (b1, . . . , bn) = (a1 × b1, . . . , an × bn).Clearly, these operations inherit associativity, commutativity and distributivity from the operations in A. So An be-comes itself a semiring. Also if + in A is idempotent, then so is + in An. The same is true for the operation ×. If Ahas a zero element 0, then (0, . . . , 0) is the zero element in An. If 1 is a unit element in A, then (1, . . . , 1) becomesthe unit element in An. Thus if A is a c-semiring, then so is An.3. Valuation algebra induced by a semiringThe examples in the last section show the richness of semirings. In this section we describe how an algebraicstructure, called valuation algebra, is induced by semiring-valued mappings. A wide variety of important reasoningproblems can be expressed in terms of such a valuation algebra, and they can be solved by local computations basedon a join tree decomposition. Frameworks similar to semiring-induced valuation algebras have been described in [1](which also describes a number of important applications of the techniques), and in [13,14]; the framework of [32]can also be viewed in this way.3.1. A-valuationsConsider variables X, Y, . . .. For each variable X let ΩX be the finite set of possible values of X called frame of X.We assume that at least one frame ΩX contains at least two elements. Sets of variables are designated by lower-caseletters like x, y, . . . , r, s, t, . . .. These sets are also always finite. For a set s of variables let Ωs denote the Cartesianproduct of the frames ΩX for the variables in s,Ωs =(cid:9)ΩX.X∈sJ. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991367The elements of Ωs are called tuples or configurations with domain s.3 We use lower-case, bold-face letters such asx, y, . . . to denote tuples. It is convenient to include the case where s is empty. We adopt the convention that the framefor the empty set of variables consists of a single tuple, denoted by (cid:19), such that Ω∅ = {(cid:19)}. If x is a tuple with domains and t ⊆ s, then x↓t denotes the projection of x to the subdomain t. In particular, we have x↓∅ = (cid:19). Sometimes, inorder to emphasize the decomposition of a tuple x into components belonging to two disjoint subsets t and s − t of s,we write x = (x↓t , x↓s−t ).Consider a set A with operations + and ×, where + is assumed to be commutative and associative, and write Aas the triple (cid:6)A, +, ×(cid:7). An A-valuation φ with domain s associates a value in A with each configuration x ∈ Ωs : φis a function from Ωs to A. We denote the set of all valuations with domain s by Φs . Consider a non-empty set ofvariables r and let then(cid:10)Φ =Φss⊆rbe the set of all A-valuations. D denotes the lattice of subsets of the set of variables r, i.e. D = P(r) (the powersetof r). For any valuation φ ∈ Φ we define the labeling function d : Φ → D where d(φ) denotes the domain of thevaluation φ (i.e. d(φ) = s, if φ ∈ Φs ).We use now the operations + and × in A to define two operations in the pair (Φ, D):(1) Combination: ⊗ : Φ × Φ → Φ defined for x ∈ Ωd(φ)∪d(ψ) byφ ⊗ ψ(x) = φ(x↓d(φ)) × ψ(x↓d(ψ)).(2) Projection: ↓: Φ × D → Φ defined for all φ ∈ Φ and t ⊆ d(φ) for x ∈ Ωt by↓t (x) =φ(cid:3)φ(z).z∈Ωd(φ): z↓t =xThe defining equation for projection can also be written in the following way, if we decompose the tuples z of domains = d(φ) into subtuples x belonging to domain t and subtuples y belonging to domain s − t, z = (x, y),↓t (x) =φ(cid:3)φ(x, y).y∈Ωs−tNote that↓d(φ) = φ.φWe remark that projection is also sometimes called marginalization (motivated by applications to probability theory).Further projection could have been defined for arbitrary sets t simply by putting↓t := φ↓t∩d(φ).φFinally projection can also be used to define the operation of variable elimination for any variable X,−X := φφ↓d(φ)−{X}.The following axioms have been shown to be sufficient to perform local computation based on a join tree decom-position of valuations [59]. The present form of the axioms for a system (Φ, D) has been introduced in [34,37]. In[51] it has been shown that these axioms are also sufficient for local computation based on a covering join tree of afactorization of valuations.3 Note that the terminology of valuation algebras differs from that used in the constraint satisfaction and constraint optimization literature, andalso the relational database literature. The frame of a variable in valuation algebra terminology corresponds to the domain of a variable in theconstraints literature or in the relational database literature; if, for example, a valuation is a constraint (as in Example 10), then the domain of thevaluation is the scope of the constraint; if the valuation is a relation then the domain of the valuation is the relation type. A tuple or configuration isan assignment to a set of variables.1368J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399(1) Semigroup. Φ is associative and commutative under combination ⊗.(2) Labeling. ∀φ, ψ ∈ Φ we have that d(φ ⊗ ψ) = d(φ) ∪ d(ψ).(3) Marginalization. ∀φ ∈ Φ and s ⊆ d(φ) we have d(φ↓s) = s.(4) Transitivity. ∀φ ∈ Φ and t ⊆ s ⊆ d(φ) we have↓s)↓t = φ↓t .(φ(5) Combination. ∀φ, ψ ∈ Φ and d(φ) ⊆ s ⊆ d(φ) ∪ d(ψ) we have↓s∩d(ψ).↓s = φ ⊗ ψ(φ ⊗ ψ)A system (Φ, D) satisfying these axioms is called a valuation algebra.The following theorem is a basic result connecting the properties of systems of A-valuations with the propertiesof A. It implies that a system of A-valuations forms a valuation algebra if A is a semiring. Conversely if a system ofA-valuations forms a valuation algebra, and A has an additive identity element 0, then A must be a semiring. Thistheorem also implies the following converse: if A is such that any system of A-valuations forms a valuation algebrathen A is a semiring. Almost all of the standard examples of valuation algebras can be expressed as A-valuations, anexception being Dempster–Shafer belief functions. In particular, each formalism covered by the framework in [32] isa system of A-valuations for a semiring A (see their Definitions 3.1 and 3.3 and Theorem 4.4).Part (2) and the first part of (3) generalize Theorems 18 and 19 (respectively) of [8], and corresponding standardresults for probability potentials.Theorem 2. Consider a system of A-valuations (Φ, D), with combination and projection, as defined above.(1) Φ is a commutative semigroup if, and only if, A operation × is commutative and associative.(2) Projection is transitive.(3) If A operation × distributes over + then the combination property (5) holds. Conversely, if the combinationproperty holds, and there exists an additive identity 0 in A then × distributes over +. Also, if the combinationproperty holds, and there exists a variable whose frame contains exactly two elements, then × distributes over +.Proof. (1) The commutativity of the combination follows directly from the commutativity of the × operation inthe semiring A and the definition of combination. As for the associativity we have, assuming that φ, ψ and η arevaluations with domains s, t and u(cid:8)(cid:7)φ ⊗ (ψ ⊗ η)(x)= φ(x↓s) × (ψ ⊗ η)(x↓t∪u)(cid:8)(cid:7)= φ(x↓s) ×× ηψ= φ(x↓s) × ψ(x↓t ) × η(x↓u).(cid:7)↓t(x↓t∪u)(cid:7)(x↓t∪u)↓u(cid:8)(cid:8)The same result we obtain in exactly the same way for ((φ ⊗ ψ) ⊗ η)(x). Thus associativity holds.Conversely, assume that Φ is a commutative semigroup, and let a, b, c ∈ A. Consider valuations φ(x) = a, ψ(x) =b and η(x) = c for all configurations x of s. Then commutativity of ⊗ implies commutativity of ×: a × b = φ(x) ×ψ(x) = φ ⊗ ψ(x) = ψ ⊗ φ(x) = ψ(x) × φ(x) = b × a. Associativity of × follows similarly from associativity of ⊗.(2) Transitivity of projection means simply that we can sum out variables in two steps. That is, if t ⊆ s ⊆ d(φ) = u,then, for all x ∈ Ωt ,↓t (x) =↓s)(φ(cid:3)↓s(x, y) =φ(cid:3)(cid:3)φ(x, y, z)y∈Ωs−t(cid:3)=(y,z)∈Ωu−ty∈Ωs−tφ(x, y, z) = φ↓t (x).z∈Ωu−s(3) The combination property also follows easily if × distributes over +. Suppose that φ has domain t and ψdomain u and x ∈ Ωs , where t ⊆ s ⊆ t ∪ u, so that (t ∪ s) − s = u − s. Then we have for x ∈ ΩsJ. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991369(φ ⊗ ψ)↓s(x) =(cid:3)(φ ⊗ ψ)(x, y) =(cid:3)(cid:7)(cid:8)φ(x↓t ) × ψ(x↓s∩u, y)y∈Ωt∪u−s= φ(x↓t ) ×(cid:3)y∈Ωu−sψ(x↓s∩u, y) = φ(x↓t ) × ψ↓s∩u(x↓s∩u)y∈Ωu−s↓s∩u)(x).= (φ ⊗ ψ(3.1)Conversely, assume that the combination property holds in (Φ, D) and consider any triple of values a, b, c in A.Let Y be any variable whose frame contains at least two elements y1 and y2. Define valuation ψ with d(ψ) = {Y } byψ(y1) = b, ψ(y2) = c and ψ(y) = 0 for all other y ∈ ΩY . Define φ by d(φ) = ∅ and φ((cid:19)) = a.(φ ⊗ ψ)↓s((cid:19)) =(cid:8)(cid:7)φ((cid:19)) × ψ(y)= (a × b) + (a × c).(cid:3)y∈ΩYOn the other hand, the left hand side of this equation equals, by the Combination property in (Φ, D),(φ ⊗ ψ↓s∩u)((cid:19)) = φ((cid:19)) ×ψ(y) = a × (b + c).(cid:3)y∈ΩYThis shows that (a × b) + (a × c) = a × (b + c) for any triple a, b, c; hence distributivity holds in A. The sameargument also works, even without a zero element in A, if there exists some variable Y whose frame has preciselytwo elements. (cid:2)If A is a semiring, then property (1) of Theorem 2 means that the semigroup axiom is satisfied, property (2) assuresthe transitivity axiom and property (3) the combination axiom. The labeling axiom and the marginalization axiom aresatisfied by definition of combination and marginalization of A-valuations. This shows that the system of A-valuations(Φ, D) is a valuation algebra, if A is a semiring.This implies that local computation is possible with A-valuations for solution of the following problem:Definition 1. Projection Problem. Given a set of valuations φ1, . . . , φn and a set of domains sj ⊆ r, compute(φ1 ⊗ · · · ⊗ φn)↓sj ,for j = 1, . . . , m.(3.2)The graphical structure that underlies local computation is the join tree, i.e. a tree whose nodes i are labeled witha domain λ(i) such that, if node k lies on the path from node i to node j , thenλ(k) ⊇ λ(i) ∩ λ(j ).This condition is called running intersection property.If the domains d(φi) of the projection problem form a join tree, and each sj is a subset of some d(φi), then theprojection problem can be solved by a sequence of combinations and projections which take place only on the domainsof the join tree nodes, i.e. on the domains d(φi), and never on bigger domains [32,34,37,53,55,59]. (One wants, wherepossible, to generate a join tree with no large nodes and therefore a tree decomposition with small treewidth [10]; seefor example, [2,25] and the survey paper [11] for approaches to this problem.)A less strong condition for local computation has been worked out in [51] and states that the domains d(φi) mustonly be covered by some join tree node. If the valuation algebra (Φ, D) has neutral elements, these factors can easilybe extended to the corresponding node domains. However, not all A-valuation algebras have neutral elements (seeexamples below) and even if they exist, the proposed extension of the valuations to the join tree domains is not alwaysefficient. In [51] it is shown that this extension is not necessary: local computation is possible even in valuationalgebras without neutral elements. This is due to the fact, that one can adjoin a neutral element e∅, such thatφ ⊗ e∅ = φfor all elements φ of the valuation algebra, if such an element does not already exist in the algebra. We describe belowthis modification of the Shenoy–Shafer propagation scheme.1370J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399Consider a projection problem (3.2) and assume that there is a join tree J = (V , E) whose nodes are labeledby λ(k), k = 1, . . . , |V |, such that for each i = 1, . . . , n, there is a k such that d(φi) ⊆ λ(k) and also, for eachj = 1, . . . , m, there is a h such that sj ⊆ λ(h). Then J is called a covering join tree for the family of projectionproblems. We define an assignment mapping a : {1, . . . , n} → {1, . . . , |V |} such that d(φi) ⊆ λ(a(i)) and defineψk =i:a(i)=k φi . If there is no i assigned to k, then define ψk = e∅. We have then(cid:11)n(cid:12)u(cid:12)ψkφi =φ =i=1k=1and d(ψk) ⊆ λ(k), for k = 1, . . . , u.(3.3)According to [59] messages μk→j are then computed between neighboring nodes of the join tree. In [51] thesemessages are defined in a covering join tree as follows, if ne(k) denotes the set of neighbor nodes of k in the join tree:(cid:13)μk→j =ψk ⊗(cid:12)(cid:14)↓ωk→j ∩λ(j )μi→k,i∈ne(k),i(cid:9)=jwhereωk→j = d(ψk) ∪(cid:10)i∈ne(k),i(cid:9)=jd(μi→k).These messages can be computed sequentially, starting from the leaves of the join tree. The marginals of the factor-ization with respect to all nodes of the covering join are then obtained as↓λ(k) = ψk ⊗φ(cid:12)μi→k.i∈ne(k)(3.4)Example 8. Fig. 1 illustrates a complete run of the Shenoy–Shafer architecture by presenting domains ωi→j andmessages μi→j for each step. The factors which are distributed over the nodes of the covering join tree have domainsd(ψ1) = {A, B}, d(ψ2) = {C}, d(ψ3) = {A, B, C} and d(ψ4) = {A, C, D}. Note that at the end for each node kcombination (3.4) must be executed.This procedure involves redundant computations, if the nodes in the join tree have more than three neighbors.Therefore Shenoy [58] proposes a variant of the method, where the join tree is transformed into a binary join tree,i.e. a join tree whose nodes have at most three neighbors (the join tree in Fig. 1 is a binary join tree). Since all thetarget domains sj are subsets of some λ(k), finally all marginals of the projection problem are computed by localcomputations only, i.e. computations involving combinations and marginalizations only on domains λ(k) of the jointree.To complete the discussion of general semiring-induced valuation algebras, we add some remarks on some addi-tional properties, which are of some importance.If the semiring A which induces the valuation algebra (Φ, D) has a unit element 1, then we have for every domains a valuation es(x) = 1 for all x ∈ Ωs . This is the neutral valuation in the semigroup Φs defined by the combination,i.e. for all φ ∈ Φs we have es ⊗ φ = φ ⊗ es = φ. These neutral elements satisfy the following property:Theorem 3 (Neutrality). If the semiring A inducing the valuation algebra (Φ, D) has a unit element, then, for alls, t ⊆ r, we havees ⊗ et = es∪t .Proof. We have by definition for all x ∈ Ωs∪t(es ⊗ et )(x) = es(x↓s) × et (x↓t ) = 1 × 1 = 1.(cid:2)In general it is not true that the projection of the neutral valuation es to some subdomain t ⊆ s is still the neutralelement et . A counter example is provided by probability potentials (see Example 9 below). In this example we haveJ. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991371ωi→jω1→3 = d(ψ1)ω2→3 = d(ψ2)ω3→4 = d(ψ3) ∪ d(μ1→3) ∪ d(μ2→3) μ3→4 = (ψ3 ⊗ μ1→3 ⊗ μ2→3)↓ω3→4∩λ(4)ω4→3 = d(ψ4)ω3→1 = d(ψ3) ∪ d(μ4→3) ∪ d(μ2→3) μ3→1 = (ψ3 ⊗ μ4→3 ⊗ μ2→3)↓ω3→1∩λ(1)ω3→2 = d(ψ3) ∪ d(μ4→3) ∪ d(μ1→3) μ3→2 = (ψ3 ⊗ μ4→3 ⊗ μ1→3)↓ω3→2∩λ(2)Message content:μ1→3 = ψμ2→3 = ψ↓ω1→3∩λ(3)1↓ω2→3∩λ(3)2↓ω4→3∩λ(3)4μ4→3 = ψ123456Fig. 1. A complete run of the Shenoy–Shafer architecture.↓ts (x) =e(cid:3)y∈Ωs−tes(x, y) = |Ωs−t |since es(x, y) = 1. In the case of c-semirings however neutral elements project to neutral elements. This importantproperty is called stability.Theorem 4 (Stability). The valuation algebra (Φ, D), induced by the semiring A with unit is stable, i.e. for all s andt ⊆ s ⊆ r it holds that↓tse= et ,if the addition operation + in the semiring is idempotent.Proof. Assume that + is idempotent. Let x ∈ Ωt . Then we obtain↓ts (x) =e(cid:3)(cid:3)es(x, y) =1 = 1.(3.5)y∈Ωs−ty∈Ωs−tThis shows that e↓ts = et . (cid:2)Stability is important because it permits to extend valuations from a given domain to a superdomain and moregenerally to transport valuations from domains to other domains [34,53]. This means that in the case of c-semirings,valuations can be regarded as generalized constraints which can be extended to larger domains and even to the domainof all variables. More precisely, if φ is a valuation with domain s and s ⊆ t ⊆ r, then↑t def= et ⊗ φφ1372J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399is a valuation on domain t by the labeling property (Theorem 2). Using the combination property of Theorem 2 andstability we find that↑t )(φ↓s = (et ⊗ φ)↓s = e↑tSo we are entitled to call φsgenerally transport any valuation φ with domain s to any other domain t by⊗ φ = es ⊗ φ = φ.↓sta vacuous extension of φ, since we do not change its content. We may then more→t = (φ↑s∪t )↓t .φIn this case we may say that two valuations φ and ψ with domains s and t represent the same constraint, if→t = ψ and ψ→s = φ.φIn this sense, φ and φ↑r represent the same constraint. Therefore, we may treat all constraints on the level of the set rof all variables. In particular, it can easily be proved that↑r↑r = φ1(φ1 ⊗ · · · ⊗ φk)⊗ · · · ⊗ φ↑rk .So, stability is important if we want to consider valuations as generalized constraints, e.g. soft constraints or fuzzyconstraints. We refer to [34] for a discussion of stability and its consequences.If the semiring A inducing the valuation algebra (Φ, D) has a null element, then this introduces also null (i.e.absorbing) elements with respect to combination in Φs . In fact, define for all x ∈ Ωszs(x) = 0.Then, if φ is a valuation with domain s, we have(zs ⊗ φ)(x) = zs(x) × φ(x) = 0.Thus, we see that zs ⊗ φ = zs for all φ ∈ Φs , i.e. zs is the null (or absorbing) element in Φs . Intuitively, we mightexpect, that a valuation φ with domain s, which projects to the null valuation in a domain t ⊆ s, must itself be a nullelement. This is however not automatically the case. For example, if we consider the semiring of real numbers, thenwe may have0 = φ↓t (x) =(cid:3)φ(x, y)y∈Ωs−twithout necessarily φ(x, y) = 0 for all tuples. However, this can not happen, if the semiring is positive.Theorem 5 (Nullity). If the positive semiring A with null element induces the valuation algebra (Φ, D) then, for all sand t ⊆ s ⊆ r↓t = ztφimplies φ = zs .Proof. Let x ∈ Ωt . Then,(cid:3)0 = φ↓t (x) =φ(x, y)y∈Ωs−timplies by the positivity of the semiring that φ(x, y) = 0 for all tuples. (cid:2)A null valuation represents generally contradiction. If, for example in a c-semiring induced valuation algebra wehave φ ⊗ ψ = zs∪t , then the two general constraints are contradictory, they have no “common” (non-zero) configura-tions. In particular, if the projection problem with respect to the empty set yields the null element(φ1 ⊗ · · · ⊗ φn)↓∅ = z∅then this means that the set of generalized constraints φ1, . . . , φn is totally contradictory, i.e. not satisfiable. So, nullelements play an important role.J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–139913733.2. Examples of semiring-induced valuation algebrasExample 9 (Probability potentials). If we take for A the semiring of nonnegative real numbers (see Example 1 inSection 2), then the corresponding valuations are called probability potentials. They are used in the inference fromprobability networks, especially Bayesian networks, [41,54]. In fact they represent, up to normalization, discreteprobability densities and families of conditional probability densities. The combination is point-wise multiplicationwhich models the computation of multidimensional densities from prior densities and conditional densities, as forexample p(x, y) = p(x|y) · p(y). Projection corresponds to the usual marginalization operation in probability theory.Essentially the projection problem consists in computing a marginal of some factorized probability distribution. This isthe basic problem for example in Bayesian networks. We refer to [34] for a discussion of the use of these valuations forinference in probabilistic networks. If the usual addition is replaced by the max operator, then the resulting valuationalgebra serves to compute maximum likelihood or most probable values and configurations (see Example 15 below).Example 10 (Relational or constraint systems (CSPs)). If we use the Boolean semiring of Example 2 from Section 2,then a valuation φ over domain s defines a relation over domain s, i.e. a set of tuples, byRφ =(cid:5)x ∈ Ωs: φ(x) = 1(cid:6).This relation can also be considered as a (crisp) constraint on the variables in s. Combination of two valuations φ andψ with domains s and t corresponds then to the natural join of the corresponding relations,Rφ⊗ψ = Rφ (cid:23)(cid:24) Rψ = {x ∈ Ωs∪t : x↓s ∈ Rφ, x↓t ∈ Rψ }.Projection corresponds to the ordinary projection of relations,Rφ↓t = πt (Rφ) = {x↓t : x ∈ Rφ}.This gives us a subset of relational algebra, which is useful in query processing for relational databases and forconstraint solving. The projection problem formulated in terms of a set of constraints consists in computing the setof tuples in s which can be extended to tuples satisfying all constraints. If the projection is to the empty set, then theproblem is to find out whether the constraints have a solution (i.e. φ↓∅ = 1) or not (i.e. φ↓∅ = 0).Example 11 (Propositional logic). This is a variant of the previous example, where we consider only binary orBoolean variables X. Tuples x are then Boolean vectors. Valuations φ(x) ∈ {0, 1} represent then constraints, whichmay have been defined by formulae of propositional logic. The projection problem(φ1 ⊗ · · · ⊗ φn)↓∅is then the problem to decide whether the set of propositional formulae defining the valuations φ1, . . . , φn is satisfiableor not. We refer to [36] for a discussion of local computation in propositional logic. Further, Mengin and Wilson [45]study local computation for logic in general.Example 12 (Set-based constraints). We may generalize the example above and replace {0, 1} by a more generalBoolean algebra A. This would then be an instance of a c-semiring which is a distributive lattice (see Example 4 inSection 2). In particular the subsets of a set generate a c-semiring. Let D be a finite set. Define A = (cid:6)2D, ∩, ∪(cid:7) withnull element ∅ and unit D so that A is the set of subsets of D. The ordering (cid:11) equals ⊆.As an example, consider k binary variables ai , i = 1, . . . , k, each taking values in {0, 1}. The vector a of allbinary variables takes value in {0, 1}k. Let then A = P({0, 1}k), the power set of {0, 1}k. A valuation φ(x) can thenbe considered as a statement that x might be an acceptable tuple, if a ∈ φ(x). The variables ai are considered asunknown assumptions, which may hold or not. If then, for example, c ⊆ Ωs and we define φ(x) = Ac ⊆ A, if x ∈ c,and φ(x) = A otherwise, then this valuation defines an assumption-based constraint: If assumption Ac holds, then xmust belong to constraint c, otherwise x is free. Combination of two (or more) of such assumption-based constraintsφ1 and φ2, corresponding to constraints c1 and c2, gives a new assumption-based constraint, where for example∩ Ac2 means that x belongs to c1 ∩ c2, whereas φ(x) = Ac1 means that x belongs to c1 (it may or may notφ(x) = Ac1belong to c2). This is related to assumption-based reasoning [19] which may be enriched with a probabilistic structure1374J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399on the set of assumptions, which then leads to probabilistic argumentation systems [27]. Of course, the simple Booleansemiring of the previous example is a special case of this more general example.Example 13 (Counting solutions of a CSP). Here a semiring A = (cid:6)N ∪ {0}, +, ×(cid:7) with null element 0 and unit 1 isused. As in Example 10 a configuration x is a solution of a CSP if φ(x) = 1. But now φ↓∅((cid:19)) =φ(x) equalsthe number of solutions of the CSP. The value of φ↓{X}(x), for example, will give the number of solutions satisfyingthe assignment X = x.x∈Ωr(cid:2)Example 14 (Possibilistic constraints or fuzzy sets). If we take the semiring A with a t-norm for multiplication andmax for addition (see Example 6 in Section 2), then a valuation φ(x) is also called a possibilistic distribution, or apossibilistic constraint or also a fuzzy set. The t-norm is used to compute intersections of fuzzy sets or possibilisticconstraints. And the max-operator serves to compute projections of fuzzy sets or constraints. More generally, anyt-conorm could also be used for projection. This is related to the soft constraints in [49].Example 15 (Optimization, weighted CSPs). Consider the (max / min, +)-semiring of reals (see Example 5 in Section2). Suppose that we have, say, n valuations over domains s1, . . . , sn such that s1 ∪ · · · ∪ sn = r. If we combine themand project the combination to the empty domain, then we have, for x ∈ Ω,(φ1 ⊗ · · · ⊗ φn)↓∅((cid:19)) = maxx(cid:7)(cid:8)φ1(x↓s1) + · · · + φn(x↓sn ).This projection problem is an optimization problem, which can be solved by local computation [57]. If multiplicationis ordinary multiplication, instead of +, then the projection problem corresponds to the maximization of probabilityin a Bayesian network.These examples illustrate a number of quite different systems, which all represent different problems. As explainedabove, the projection problem in all these instances can be solved by the same generic local computation procedure.However there are structural differences between these examples which can in some cases be exploited to designalternative, and often more efficient local computation architectures. This will be discussed in the following Sections 4and 5.4. Idempotent valuation algebrasThis section considers the special case of idempotent valuation algebras. We derive sufficient conditions for asemiring to induce an idempotent valuation algebra which allows computation to be performed using an especiallyefficient computational architecture.4.1. IdempotencyA valuation algebra (Φ, D) is called idempotent, if the following additional property holds: For all φ ∈ Φ andt ⊆ d(φ) we haveφ ⊗ φ↓t = φ.This is a property we would like to have, if a valuation φ is to be interpreted as a piece of information in a strict sense.An information combined with a piece of itself should give nothing new. The existence of neutral elements es for alldomains s, representing vacuous information relative to a domain s, is usually also required. Further focusing, i.e.projection, of vacuous information should yield a vacuous information; hence stability should also hold. So, formally,an information algebra is a valuation algebra(1) with neutral elements satisfying neutrality (Theorem 3),(2) satisfying stability (Theorem 4),(3) satisfying idempotency.J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991375Important examples of information algebras are relational or ordinary constraint systems and systems related to logic(propositional, predicate logic and others).The idempotency property must hold in particular for t = d(φ) = s so that we must have for all tuples x ∈ Ωsφ(x) = (φ ⊗ φ)(x) = φ(x) × φ(x).This implies that the × operation of the semiring must be idempotent. As we have seen for the stability, the idempo-tency of the + operation, is a sufficient condition. Thus, a sufficient condition for semiring A to induce an idempotent,stable valuation algebra is that A is a c-semiring with idempotent multiplication ×. By Theorem 1 the semiring A isthen a distributive lattice, + is the supremum and × the infimum.The question is, whether A being a distributive lattice is also sufficient for the induced valuation algebra to beidempotent. The answer is affirmative. In fact, we see that for all x ∈ Ωs , since × corresponds to the infimum,(φ ⊗ φ↓t )(x) = φ(x) × φ↓t (x↓t ) (cid:2) φ(x).On the other hand, we find that for x ∈ Ωt and y ∈ Ωs−t ,(φ ⊗ φ↓t )(x, y) = φ(x, y) ×φ(x, y(cid:10))(cid:3)y(cid:10)∈Ωs−t(cid:3) φ(x, y) × φ(x, y) = φ(x, y)since φ(x, y) is a term of the sum. We see that indeed for all x ∈ Ωs(φ ⊗ φ↓t )(x) = φ(x).Thus idempotency holds. If the lattice has a top element (cid:18), then clearly neutral elements es(x) = (cid:18) exists for all setsof variables s and they satisfy neutrality (Theorem 3) and stability (Theorem 4).We have proven the following theorem.Theorem 6. The valuation algebra induced by a semiring A is an information algebra (i.e. a stable and idempotentvaluation algebra) if the semiring A is a distributive lattice with a top element.Information algebras (Φ, D) have many interesting properties, for a detailed account see [34]. Idempotency allowsfor example to define a partial order in Φ, similar as in A, byφ (cid:3) ψ,if φ ⊗ ψ = ψ.This is a partial order.4 Clearly φ (cid:3) ψ implies t = d(φ) ⊆ d(ψ) = s and for all x ∈ Ωs , we haveφ(x↓t ) × ψ(x) = ψ(x),hence φ(x↓t ) (cid:3)A ψ(x). So the information order is induced by the order in the underlying lattice A.There are many examples of information algebras, induced by semirings. They include relational systems or CSPs,propositional logic, valuation algebras induced by distributive lattices, etc.4.2. Local computation in information algebrasMost important however, from a computational point of view, is that idempotency allows to simplify considerablythe architectures for the solution of the projection problem. The point is, that division becomes trivial in idempotentvaluation algebras (see Section 5), such that architectures for local computation as proposed for Bayesian networks[29,41] can be considerably simplified [34]. Here the corresponding local computation architecture is only sketched;for proofs we refer to [34,51].Consider a projection problem (3.2) and assume that there is join tree J whose nodes are labeled by λ(k), k =1, . . . , u. Let then ψk be the valuations associated to the nodes k such that (see (3.3))4 In [34], the order is defined the other way round, φ (cid:2) ψ , meaning that φ is less informative than ψ if its combination with ψ does not changethe latter. More interesting, however, is a variant of this order, which applies to domain-free valuations, see [34].1376J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399n(cid:12)u(cid:12)ψkφi =φ =i=1k=1and d(ψk) ⊆ λ(k), for k = 1, . . . , u.The marginals φ↓λ(k) may then be computed for all k = 1, . . . , u by a local computation scheme as follows: Anarbitrary node of the join tree, say u, is selected as root node. All edges are directed towards the root and the nodesare numbered such that j < i if node i is on the path from node j to the root node u. The neighbor of node k towardsthe root node will be denoted by ch(k). For each node i of the join tree we store two associated items denoted by χiand ωi . To initiate the algorithm we assign for k = 1, . . . , u,χk =: ψk,ωk =: d(ψk).Then, in a first phase, for k = 1, . . . , u, repeat the following steps: Send message↓ωk∩λ(ch(k))μk→ch(k) = χkto its neighbor ch(k). In the node ch(k) combine the incoming message with its storage contentχch(k) =: χch(k) ⊗ μk→ch(k),and update alsoωch(k) =: ωch(k) ∪ (ωk ∩ λ(ch(k))).This is also called collect algorithm.In a second phase repeat, for k = u − 1, . . . , 1, the following steps: Send messageμch(k)→k = χ↓λ(ch(k))∩λ(k)ch(k)from the child ch(k) of k back to k. In the receiving node k combine the incoming message with the stored valuationχk =: χk ⊗ μch(k)→k.The second phase is also called distribute algorithm. For the proof of the following theorem we refer to [34,51]:Theorem 7. In the second phase, the stored valuation χk at node k when sending messages to its outward neighborsis equal to the marginal φ↓λ(k).Example 16. Reconsider the join tree in Fig. 1 previously used in Example 8 and let φ = ψ1 ⊗ ψ2 ⊗ ψ3 ⊗ ψ4. For theidempotent architecture we determine:Message content:1 μ1→3 = χ2 μ2→3 = χ3 μ3→4 = χ4 μ4→3 = χ5 μ3→1 = χ6 μ3→2 = χ↓ω1→3∩λ(3)1↓ω2→3∩λ(3)2↓ω3→4∩λ(4)3↓λ(4)∩λ(3)4↓λ(3)∩λ(1)3↓λ(3)∩λ(2)3= ψ= ψ↓ω1→3∩λ(3)1↓ω2→3∩λ(3)2= φ↓λ(4)∩λ(3)= φ↓λ(3)∩λ(1)= φ↓λ(3)∩λ(2)χχ3 =: χ3 ⊗ μ1→3 = ψ3 ⊗ μ1→3χ3 =: χ3 ⊗ μ2→3χ4 =: χ4 ⊗ μ3→4 = ψ4 ⊗ μ3→4 = φ↓λ(4)χ3 =: χ3 ⊗ μ4→3 = φ↓λ(3)χ1 =: χ1 ⊗ μ3→1 = ψ1 ⊗ μ3→1 = φ↓λ(1)χ2 =: χ2 ⊗ μ3→2 = ψ2 ⊗ μ3→2 = φ↓λ(2)Note that the messages of the collect algorithm (steps 1–3) correspond exactly to the messages of the first threesteps of the Shenoy–Shafer architecture in Example 8. For the computation of χ in steps 3–6 we apply Theorem 7.It is important to note that in difference to the Shenoy–Shafer architecture, a message cache is not needed, since thecomputation of the messages during the distribute algorithm does not refer to the messages of the collect algorithm.Since the target domains sj , for which that marginal φ↓sj are desired, are contained in the domains λ(k), it followsthat these marginals can all be obtained by local computation in the covering join tree J .J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–139913775. Division in valuation algebrasThere are efficient architectures for local computation which make use of some concept of division. One advantageof these architectures with respect to the Shenoy-Shafer architecture is that they, like the idempotent architecture,do not become less efficient if the join tree is not binary. These architectures have been developed for probabilisticnetworks [29,41]. But they can be applied to other systems provided that they share some properties with probabilisticsystems. The essential point is that valuations must have some kind of inverses [40]. However, this alone is notsufficient, the inverses must also satisfy some consistency conditions relative to marginalization [34]. In this sectionwe want to examine exactly what conditions the semiring A has to satisfy in order to induce a valuation algebra whichallows local computation with one of these architectures. In fact, in [34] regular and separative valuation algebraswere shown to allow architectures with division as proposed in [29,41]. The question is, what kind of semirings inducevaluation algebras with an appropriate concept of division.The problem can be solved by studying how to introduce division5 into semirings, or more generally, into the com-mutative semigroup of multiplication of a semiring. This is a well studied problem in semigroup theory. The simplestcase is the one of a regular semigroup, which decomposes into a union of disjoint groups [17]. We show in Section5.1 that corresponding regular semirings induce regular valuation algebras, i.e. valuation algebras which decomposealso into a disjoint union of groups. This is identified as a first case where the local computation architectures withdivision generalized from probability theory work. Two further cases are considered: cancellative algebras in Section5.2, and separative semirings leading to separative valuation algebras in Section 5.3.5.1. Regular algebrasA semigroup A with an operation × is called regular, if for all a ∈ A there is an element b ∈ A such thata × b × a = a.The theory of regular semigroups as semigroups with inverses has been developed in [17] and we summarize theresults as far as we need them here. Two elements a and b of A are called inverses, ifa × b × a = a,and b × a × b = b.In a regular semigroup, any element a has a unique inverse, which we denote by a−1. Further, for any element a ∈ Athe element a × a−1 is idempotent. These idempotent elements in A play an important role. First, if f1 and f2 ∈ A areidempotent elements, then f1 × f2 is idempotent. There is a partial order between idempotent elements of A definedby f1 (cid:2)I f2 if, and only if f1 × f2 = f1. And f1 × f2 is the largest lower bound of f1 and f2. Let a × A denote theset of all elements a × b, b ∈ A. Then, in a regular semigroup A there exists for all elements a a unique idempotentelement f such that a × A = f × A.The relation a ≡ b if, and only if a × A = b × A is an equivalence relation on A, a so-called Green relation. Andfurthermore, if a1 ≡ b1 and a2 ≡ b2, then a1 × a2 ≡ b1 × b2, i.e. it is a congruence in the semigroup A. Let [a] denotethe congruence class containing a. Then [a] is a commutative group with × as the group operation, a−1 the inverse ofa and the unique idempotent f[a] in the congruence class [a] as the unit element. Thus, we have that(cid:10)A =[a]a∈Ais the union of a disjoint family of groups. We remark that we may partially order these groups by defining [a] (cid:2)I [b]if, and only if f[a] (cid:2)I f[b]. The group [a] is also called the support of a.If A is a semiring, we call it regular, if it is regular as a semigroup under the operation ×. We have introduced thenotion of a positive semiring in Section 2. For regular semirings we strengthen this notion and call the semiring Apositive if, and only if, for all a, b ∈ A we have that [a] (cid:2)I [a + b]. Note that in any case, if a regular semiring A hasa zero element, then 0 is idempotent and [0] = {0}. Hence, if A is positive in the new sense, then a + b = 0 impliesa = 0. Therefore, A is positive in the former sense too.5 This problem is also considered briefly in [13,14], where they suggest adding the condition that multiplication is invertible; as we show here,much weaker conditions are sufficient.1378J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399Here follow a few examples.Example 17 (Arithmetic-semirings). Consider the set of reals R with ordinary addition and multiplication for + and× (i.e. the field of reals). This is a regular semiring. In this case A − {0} is a group, with 1 as the unit element. {0} isitself a one-element group. So we have the decomposition of A into these two groups:A = {0} ∪(cid:7)A − {0}(cid:8).It holds that [0] (cid:2)I [a] for a (cid:9)= 0. This holds still, if we restrict A to the nonnegative real numbers R+ ∪ {0}. However,the semiring of all reals is not positive. The semiring of nonnegative reals R ∪ {0} on the other hand is positive. Thisis the case of probability potentials. The arithmetic semiring on the integers N or the nonnegative integers N ∪ {0} isnot regular.Example 18 (t-norms). Most of the t-norms are not regular. The Lukasziewicz t-norm for example is clearly notregular. The product t-norm however is regular, as the previous example shows. The min-t norm is also regular,because it is idempotent (see Example 20 below).Example 19 (Multidimensional semiring of real numbers). We refer to Example 7 in Section 2. If the semiring A isregular, then the multidimensional semiring An is clearly also regular. Let A for example be the semiring of reals withthe usual operations of addition and multiplication. The idempotents in the semiring An are then the vectors consistingonly of components 0 and 1. If we define the support of such a vector f to be the set of variables supp(f ), for whichthe components equal 1, then we have f1 (cid:2)I f2 if, and only if, supp(f1) ⊆ supp(f2). We may identify the support [a]with supp(fa). The inverse of an element (a1, . . . , an) is the element (an ), where, as before, the inverse of0 is 0. The regular semiring An is positive if, and only if, the regular semiring A is positive. We have here with An anexample of a semiring which decomposes into more than two groups, in fact into 2n groups.−11 , . . . , a−1Example 20 (Idempotent semirings). If A is a semiring with an idempotent operation ×, then A is trivially regular:Each element is an idempotent, hence an inverse of itself. Thus, each element forms for itself a trivial group. If A isalso a c-semiring, then the order (cid:2)I is identical to the order (cid:2)A. Then A is also positive and the induced informationalgebra is regular.We show now, how a regular, positive semiring A induces a regular valuation algebra [34]. A valuation algebra(Φ, D) is called regular [34], if for all φ ∈ Φ and t ⊆ d(φ) there exists a valuation χ with domain t such thatφ ⊗ φ↓t ⊗ χ = φ.(5.1)Note that this implies that Φ is regular as the semigroup of combination (provided that φ↓d(φ) = φ). However, thedefinition (5.1) of regularity also involves the projection operation, which is essential, if we want to use architecturesof local computation with division [34].Clearly, a necessary condition for a semiring-induced valuation algebra to be regular, is that the underlying semiringis regular. This is however not sufficient. We claim that a regular, positive semiring induces a regular valuation algebra.Theorem 8. Let (Φ, D) be the valuation algebra, induced by a regular, positive semiring A. Then (Φ, D) is regular.Proof. Suppose d(φ) = s. Take any x ∈ Ωt . Define(cid:8)−1.χ(x) =↓t (x)(cid:7)φThen we have for any x ∈ Ωs(φ ⊗ φ↓t ⊗ χ)(x) = φ(x) × φ= φ(x) × φ= φ(x) × fφ↓t .↓t (x↓t ) × χ(x↓t )↓t (x↓t ) ×(cid:7)φ↓t (x↓t )(cid:8)−1J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991379We use the abbreviations fφ and fφ↓t for f[φ(x)] and f[φ↓t (x↓t )]. Thanks to the positivity of A we have [φ(x)] (cid:2)I[φ↓t (x↓t )], hence for all x ∈ Ωs we have fφ (cid:2)I fφ↓t and thereforeφ(x) × fφ↓t = (φ(x) × fφ) × fφ↓t= φ(x) × (fφ × fφ↓t )= φ(x) × fφ= φ(x).This shows that (5.1) holds. (cid:2)The examples of positive regular semirings presented above induce thus regular valuation algebras. They includeprobability potentials and possibility potentials with multiplication as the t-norm. For regular valuation algebras wecan use the Lauritzen–Spiegelhalter architecture (LS-architecture) [41] as well as the HUGIN-architecture [29] (seeSection 5.4). However regularity is not necessary for the applicability of these architectures, there are less restrictiveproperties which allow for these architectures.5.2. Cancellative algebrasThere are important examples, where A is not regular. For example, consider the (max, +) semiring on the non-negative integers (see Example 5 in Section 2); this is not regular, since there is no nonnegative integer b such thata + b + a = a. However, the negative integer b = −a would serve as a solution for this equation. The arithmeticsemirings on integers are not regular either, but again, inverses for all integers exist, as rational numbers. In theseexamples, the commutative multiplicative semigroup of the semiring must be embedded into larger groups.The first example can be generalized as follows: A semigroup A is called cancellative, ifa × b = a × calways implies b = c [15]. Such a semigroup can be embedded into a group G in the following way: We considerpairs (a, b) with a, b ∈ A and define(a, b) = (c, d)if a × d = b × c.Multiplication between such pairs is then defined by(a, b) × (c, d) = (a × c, b × d).This is well defined and multiplication is clearly commutative and associative. The unit e of multiplication is given bypairs (a, a). Then we have(a, b) × (b, a) = (a × b, a × b) = e.So (a, b) and (b, a) are inverses and the set G of pairs (a, b) is a group. The semigroup A is embedded into G by themapping a (cid:26)→ (a × a, a). If A itself has a unit element 1, then 1 (cid:26)→ (1, 1) = e. In the following we consider A as asubset of the group G.We call a semiring cancellative, if the semigroup of A under the operation × is cancellative.Example 21 (Tropical semirings). If multiplication is defined by addition as in the tropical (max / min, +) semiringson nonnegative integers N+ ∪ {0}, then the semiring is cancellative, since a + b = a + c always implies b = c. Thisholds also for nonnegative reals R+ ∪ {0}. To a pair of numbers a, b we assign the difference a − b, which is nomore necessarily in the semiring. Clearly, the additive semigroup is embedded into the group G of all integers. The(max, +)-semiring on all integers or reals is already itself a group under addition.Example 22 (Positive arithmetic semirings). The semiring of (strictly) positive integers or reals with the ordinaryaddition and multiplication is cancellative. In the case of reals the multiplicative semigroup is already itself a groupand we have A = G. This is because A is not only cancellative, but also regular. Note however that the semirings onthe nonnegative integers and real numbers are no more cancellative.1380J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399A valuation algebra (Φ, D) is called cancellative if, for all s ∈ D, the semigroup Φs is cancellative. When thevaluation algebra is induced by a cancellative semiring, then, if for all x ∈ Ωs , φ(x) × ψ(x) = φ(x) × η(x) it followsfor all x ∈ Ωs , ψ(x) = η(x), so that the valuation algebra (Φ, D) is cancellative. The converse can be shown byconsidering valuations with empty domain. Hence, if (Φ, D) is induced by a semiring, then it is cancellative if, andonly if, the semiring is cancellative.In this case Φs is embedded into a group Gs and this is in fact the group of valuations φ : Ωs → G. The inverse ofφ is defined by−1(x) =φ(cid:7)φ(x)(cid:8)−1for all x ∈ Ωs . The unit element of group Gs is defined byes(x) = e ∈ Gfor all x ∈ Ωs . If e belongs to A, then e = 1 is the unit of the semiring A. So we see that Φ, as a semigroup, isembedded into the disjoint union of groups(cid:10)Gs.s∈DIf A has a unit element, then es belongs to Φ, otherwise it is outside Φ. Also the inverses φ−1 in general do not belongto Φ. We note thates ⊗ et (x) = es(x↓s) × et (x↓t ) = e × e = e = es∪t (x).This implies that for any φ with d(φ) = s and t ⊆ s we haveφ ⊗ et = φ ⊗ es ⊗ et = φ ⊗ es = φ.This condition, together with the existence of inverse valuations outside Φ is sufficient to permit the use of the LS-and the HUGIN architectures for local computation in a valuation algebra induced by a cancellative semiring, seeSection 5.4 [34,51].5.3. Separative semiringsAbove we noted that the arithmetic semiring on nonnegative integers N ∪ {0} is neither cancellative, nor regular.Yet it is possible to embed it into a union of disjoint groups, i.e. the group {0} and the multiplicative group of thepositive rational numbers. This indicates that there are more general cases of commutative semigroups which can beembedded into a union of disjoint groups [15,61]. The corresponding semirings may under some additional conditionsgenerate valuation algebras which still allow the use of the architectures with division.In fact, it is known from semigroup theory [15,28,61] that a commutative semigroup can be embedded into asemigroup which is a union of disjoint groups if, and only if, it is separative. This means (expressed by the ×-operationof a semiring A), that for all a, b ∈ A,a × b = a × a = b × bimplies a = b. Now, if (Φ, D) is the valuation algebra, induced by the semiring A, then its semigroup is separativeif, and only if, the semiring is separative. So this semigroup can then also be embedded into a semigroup whichis the union of disjoint groups. But this is not sufficient for the application of local computation architectures withdivision [34]. We need an additional condition, which links separativity to marginalization (or to the +-operation inthe underlying semiring). The reason is that in local computation with division, inverses are used to divide marginalsφ↓t of a valuation φ out of it at some time and later the marginal is again multiplied into it. So, essentially, thecombination of a marginal with its inverse gives a neutral element f of some group, which must also be neutral withrespect to φ, though φ is not in the same group in general,φ ⊗ (φ↓t )−1 ⊗ φ↓t = φ ⊗ f = φ.This is what the additional condition must guarantee.J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991381In this section we develop the corresponding theory, which covers the two preceding structures (Sections 5.1 and5.2) as special cases. So let {Gα: α ∈ Y } be a family of disjoint groups, whose unionG =(cid:10)Gαα∈Yis a semigroup and assume that the multiplicative semigroup of the semiring A = (cid:6)A, +, ×(cid:7) is embedded into it.This means, that there is an injective mapping h : A → G such that h(a × b) = h(a) × h(b), where on the left × isthe multiplication in A and on the right the semigroup operation in G. This is the situation we may assume if themultiplicative semigroup of A is separative. For clarity, we identify each element a of A with its image h(a) in G, i.e.we assume without loss of generality that A ⊆ G.There is a unique unit element fα in each group Gα. This is an idempotent element, fα × fα = fα. Let f be anidempotent element in G. Then f belongs to some group Gα and f × f = f × fα which implies f = fα. So the unitelements of the groups Gα are the only idempotent elements in G. Thus, if the semiring possesses a unit element, thenit will be the unit element of some group. Now, fα × fβ is also an idempotent element, hence fα × fβ = fγ for someγ ∈ Y . We define α (cid:2) β iffα × fβ = fα.This relation is clearly reflexive, antisymmetric and transitive, i.e. it is a partial order between the elements of Y .Now, if fα × fβ = fγ , then it follows that γ (cid:2) α, β. Let δ ∈ Y be any other lower bound of α and β, i.e., such thatfα × fδ = fδ and fβ × fδ = fδ. Then, fγ × fδ = fα × fβ × fδ = fα × fδ = fδ. So δ (cid:2) γ , hence γ is the greatestlower bound of α and β, so we write γ = α ∧ β. We have thusfα × fβ = fα∧β .The family Y of groups forms therefore a semilattice, i.e. a partially ordered set where the infimum exists betweenany pair of elements.We denote the inverse element of an element a in some group Gα by a−1. Then a × a−1 = fα. Suppose b in somegroup Gβ . Then (a × b) × (a−1 × b−1) = fα × fβ = fα∧β . Therefore (a × b)−1 = a−1 × b−1. Suppose now thata × b ∈ Gγ . Then (a × b)−1 ∈ Gγ and (a × b) × (a × b)−1 = fγ . But as we have seen fγ = fα∧β , hence γ = α ∧ βand a × b ∈ Gα∧β .We define a ≡ b in A if a and b belong to the same group Gα. This is an equivalence relation in A. Assume thata ≡ a(cid:10) and b ≡ b(cid:10). Then a × b ≡ a(cid:10) × b(cid:10) and the relation is a ×-congruence in A. This implies that the equivalenceclasses [a] of this equivalence relation in A are semigroups. Thus A decomposes into a family of disjoint semigroups,(cid:10)A =[a].a∈AThe partial order of Y carries over to equivalence classes [a]. In fact, we have [a] (cid:2) [b] if and only if [a × b] = [a]and, for all a, b ∈ A also [a × b] = [a] ∧ [b]. Thus, the semigroups [a] form a semilattice, isomorph to Y . We call theequivalence class [a] of a the support of a.Reflexivity a ≡ a implies that a ×a ≡ a. So, a and a ×a have the same support, i.e. [a] = [a ×a]. We introduce nowan additional requirement, which generalizes this relation, and which links the decomposition of the multiplicativesemigroup of a semiring to the +-operation of the semiring. We call a semiring A = (cid:6)A, +, ×(cid:7) separative, if itsmultiplicative semigroup is separative and, in addition, there is an embedding into a union of groups, such that for alla, b ∈ A,[a] (cid:2) [a + b].(5.2)This is a kind of strengthening of positivity. In fact, if A has a zero element, then (5.2) implies that [0] (cid:2) [a] for allelements a of A. Also, if a (cid:11) b (see Section 2) then from condition (5.2) we conclude that [a] (cid:2) [b].Let’s illustrate these results by some examples. In particular, it must be stressed that the embedding of a semigroupinto an union of disjoint groups is not necessarily unique, as the second example shows.Example 23 (Regular and cancellative semirings). A cancellative semiring (Section 5.2) is clearly separative, sincecancellativity implies that from a × a = a × b it follows that a = b. Condition (5.2) is trivially satisfied, since there1382J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399is only one support. A regular positive semiring (Section 5.1) is also separative, since regularity implies that anyelement a ∈ A has an inverse in A and hence from a × a = a × b = b × b it follows that a and b are in the samegroup, [a] = [b], of the decomposition of the semiring, and then, multiplying with the inverse of a (or b) it follows thata = f[a] × b = b. Condition (5.2) is required for regular semirings too (see Section 5.1). So regular and cancellativesemirings are particular cases of separative semirings. In the first case the multiplicative semiring decomposes notonly into a semilattice of semigroups, but into a semilattice of groups, in the second case the semigroup is embeddedinto a group.Example 24 (Arithmetic semirings). Some of the arithmetic semirings (see Example 1) are regular or even cancella-tive. But consider the arithmetic semiring on nonnegative integers N ∪ {0}. It is neither cancellative nor regular. Butit is separative. It decomposes into the semiring {0} and the arithmetic semiring of natural numbers N. The first isalready a (trivial) group, the second is embedded into the multiplicative group of positive rational numbers. And theirunion, the nonnegative rational numbers form a multiplicative semiring too. The partial order between the two groupsis {0} (cid:2) N. Condition (5.2) holds too. So this arithmetic semiring is separative.There is an alternative embedding of the multiplicative semigroup. Consider finite sets of prime numbers. Forany such set of prime numbers, the natural numbers which factor exactly into those prime numbers form a semigroupwhich can be embedded into a group. The partial order between these semigroups is defined by set inclusion. However,with this decomposition condition (5.2) is not satisfied. For example 2 + 3 = 5, but [2] (cid:9)(cid:2) [5] since {2} is not a subsetof {5}.Example 25 (Nonnegative semirings). In many cases a semiring A = (cid:6)A, +, ×(cid:7) with zero element decomposes intotwo multiplicative semirings {0} and A − {0}. If the latter is cancellative, then the semiring is separative. It is thenembedded into the semiring which is the union of the group {0} and the group G into which A − {0} is embedded.In fact {0} ∪ G is a semigroup, since we may define 0 × g = 0 for all g ∈ G. The partial order between groups is{0} (cid:2) A − {0}. Further, since 0 + b = b for all b ∈ A condition (5.2) is clearly satisfied. The previous example belongsto this class of separative semirings. But we may in an arithmetic semiring for example replace addition by the maxoperator and then it remains a separative semiring.Example 26 (Multidimensional semirings). Consider a multidimensional semiring (Example 7) (cid:6)An, +, ×(cid:7) whosecomponent semiring A = (cid:6)A, +, ×(cid:7) is separative. Clearly the multidimension multiplicative semigroup is separativetoo. If A is embedded into a union of disjoint groups Gα, then the multiplicative semigroup of An is embedded intothe union of the disjoint Cartesian product of groups Gα× · · · × Gαn.= (fα1 , . . . , fαn). It follows that (α1, . . . , αn) (cid:2) (β1, . . . , βn)The idempotent elements of these groups are fα1,...,αnif, and only if, αi (cid:2) βi for all i = 1, . . . , n. In the same way [(a1, . . . , an)] (cid:2) [(b1, . . . , bn)] if [ai] (cid:2) [bi] for all i. Itfollows immediately that condition (5.2) is satisfied in the multidimensional semiring, if it is in A.Gα1,...,αn= Gα1If a semiring A is cancellative then it has no zero element (unless A = {0}). (If the semiring has a zero element 0then let a = b = 0, and let c be an arbitrary element of the semiring. The above cancellative property for semigroupsimplies that c = 0.) In particular, c-semirings are not cancellative. It is therefore natural to consider a weaker cancel-lation property, see [7]: let us say that A is weakly cancellative if for any a, b, c ∈ A, if a (cid:9)= 0 and a × b = a × c thenb = c. This property implies that if a × b = 0 then either a = 0 or b = 0. If a semiring is weakly cancellative then itis separative. For suppose a × a = a × b = b × b; if a = 0 then b × b = 0 and so b = 0 = a. Otherwise, if a (cid:9)= 0 thena × a = a × b which implies a = b.A separative semiring satisfies: if a (cid:9)= 0 then a × a (cid:9)= 0. Consider A = {0, 1, 2, . . . , k}, (for some k (cid:3) 2) with thesemiring addition operation being minimum, and the semiring multiplication being integer addition, truncated to keepthe result at most k. The value k is the zero element of the semiring and the value 0 is the unit element. This isan important semiring for reasoning with weighted constraints [39], where the k arises from the weight of the bestsolution found so far. It is not separative: consider, for example, a = k and b = k − 1.More generally, consider a totally ordered c-semiring (which corresponds to a valuation structure, used for valuedCSPs [9]), where there exists an idempotent element a and a non-idempotent element b with b > a and such thatJ. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991383there is no element between a and b. Then b > b × b (cid:3) a × a = a and so a × a = a × b = b × b, implying thatsuch a semiring is not separative. Because of this, many fair valuation structures [16], when viewed as totally orderedsemirings, are not separative.The use of kinds of division in semirings for soft constraints has been studied in [7,16].Let now A = (cid:6)A, +, ×(cid:7) be a separative semiring and (Φ, D) a valuation algebra induced by this semiring. Thenthe combination semigroup of Φ is also separative, i.e.φ ⊗ ψ = φ ⊗ φ = ψ ⊗ ψimplies φ = ψ. So, this semigroup can also be embedded into a semigroup which is a union of disjoint groups. Infact, the decomposition which is for our purposes of interest is the particular one induced by the decomposition of theunderlying semiring A.The decomposition of A induces a congruence in the combination semigroup of Φ as follows:φ ≡ ψif(1) d(φ) = d(ψ),(2) for all x ∈ Ωd(φ), φ(x) ≡ ψ(x).This is clearly an equivalence relation on Φ. Assume that φ ≡ ψ and φ ≡ η and d(φ) = d(ψ) = d(η) = s. Then itfollows that d(φ ⊗ ψ) = d(φ ⊗ η) = s and for all x ∈ Ωs also that φ(x) × ψ(x) ≡ φ(x) × η(x). So this equivalenceis also a combination congruence in Φ. It follows then that the equivalence classes [φ] are subsemigroups of thecombination semigroup of Φ.For any valuation φ with d(φ) = s define the mapping sp[φ] : Ωs → Y , where Y is the semilattice of the groupdecomposition of the separative semiring A, bysp[φ](x) = α,if φ(x) ∈ Gα.Note that this mapping is well defined, since sp[φ] = sp[ψ], if [φ] = [ψ]. We define for a valuation φ with d(φ) = sG[φ] =(cid:5)g : Ωs → G: ∀x ∈ Ωsg(x) ∈ Gsp[φ](x)(cid:6).It follows that G[φ] is a group, and the semigroup [φ] is embedded in it. The unit element f[φ] of group G[φ] is givenby f[φ](x) = fsp[φ](x). The inverse of φ is defined by φ−1(x) = (φ(x))−1. This induces also the partial order [φ] (cid:2) [ψ]if f[φ](x) (cid:2) f[ψ](x) for all x ∈ Ωs or [φ ⊗ ψ] = [φ]. In fact, this is a semilattice, i.e. f[φ⊗ψ] = f[φ] ∧ f[ψ]. The unionof these groups(cid:10)∗ =GG[φ]φ∈Φis a semigroup. In fact, if g1 ∈ G[φ] and g2 ∈ G[ψ], then g1 ⊗ g2 is defined for x ∈ Ωs∪t , if d(φ) = s and d(ψ) = t byg1 ⊗ g2(x) = g1(x↓s) × g2(x↓t )and belongs to G[φ⊗ψ].We have the equivalence φ ⊗ φ ≡ φ because [φ] is a semigroup. But, due to the separativity of the underlyingsemiring A it follows for any t ⊆ d(φ) and also for all x ∈ Ωs ,(cid:16)(cid:15)φ(x)(cid:15)φThis means that [φ] (cid:2) [φ↓t ] or also(cid:16)↓t (x↓t ).(cid:2)↓t ⊗ φ ≡ φ.φThis condition guarantees that↓t )−1 ⊗ φφ ⊗ (φ↓t = φ ⊗ f[φ↓t ] = φ(5.3)(5.4)1384J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399because, for any neutral element f[ψ] such that [φ] (cid:2) [ψ] we have that f[ψ] ⊗ φ = φ (see [34]).This in turn is, what is needed for the local computation architectures with division to be applicable [34]. A valua-tion algebra (Φ, D) which has a combination congruence which satisfies this condition and such that the equivalenceclasses [φ] are cancellative semigroups are called separative valuation algebras in [34].Let’s illustrate these results by the important example of nonnegative semirings.Example 27 (Valuation algebra induced by a nonnegative semiring). According to Example 25 a nonnegative semiringA = (cid:6)A, +, ×(cid:7) is embedded into a union of groups {0} ∪ G, where group G contains the positive part A − {0} of thesemiring A. If (Φ, D) is the valuation algebra induced by such a semiring, then we define the support supp(φ) of avaluation φ with domain d(φ) = s as(cid:6)(cid:5)x ∈ Ωs: φ(x) (cid:9)= 0.supp(φ) =Then, in this particular case, the congruence φ ≡ ψ holds exactly if the two valuations have the same support, i.e.supp(φ) = supp(ψ) and the equivalence class [φ] contains all valuations with the same domain as φ and the samesupport. In the case of arithmetic nonnegative semirings it becomes clear, that in such an equivalence class we candefine the inverse of a valuation φ asφ−1(x) = 1φ−1(x),if x ∈ supp(φ),and φ−1(x) = 0 otherwise. This defines the group G[φ]. The partial order between classes [φ] or groups G[φ] is definedby inclusion of supports: [φ] (cid:2) [ψ] if supp(φ) ⊆ supp(ψ).5.4. Local computation with divisionAs claimed above, for all the semiring-induced valuation algebras with division as defined by the division in theunderlying separative semiring, the local computation architectures proposed for probability potentials such as theLS- and the HUGIN-architectures can be applied.In the LS-architecture, first the collect algorithm is executed as in the architecture for idempotent valuation algebras,except that in node i, the node content χi is divided by the outgoing message to ch(i). So, in node i we storeχi =: χi ⊗(cid:7)↓si ∩sch(i)χi(cid:8)−1.After the collect algorithm, a distribute algorithm follows exactly as in the idempotent architecture. For a proof of thecorrectness of this architecture in valuation algebras with division as described in the previous sections we refer to[34]. The idempotent architecture for local computation (Section 4.2) is a special case of the LS-architecture, since ininformation algebras each element is its own inverse.The HUGIN architecture is a variant of the LS-algorithm in which between all nodes i and ch(i) of the join tree anadditional node, the so-called separator is introduced. The collect algorithm is as originally, except that the messageμi→ch(i) is stored in the separator. After the collect algorithm a distribute phase follows, where each node i, startingwith the root node m sends messages out as in the idempotent architecture. However the message is sent to theseparator nodes, where it is divided by the inverse of the content of the separator,μch(i)→i ⊗ (μi→ch(i))−1.This message arrives then at node i, where it is combined with the node content χi . The difference with LS-architectureis that division occurs on the smaller domain si ∩ sch(i) of the separator, instead of on the domain si . This is anadvantage. In the distribute phase, if a node k is ready to send a message, it stores χk = φ↓λ(k). We refer again to[34,51] for a proof of correctness of this architecture for regular and separative valuation algebras.Example 28. Reconsider the join tree in Fig. 1 previously used in Examples 8 and 16. Fig. 2 illustrates a complete runof the HUGIN architecture with φ = ψ1 ⊗ ψ2 ⊗ ψ3 ⊗ ψ4. The collect algorithm corresponds again to the first threesteps of the Shenoy–Shafer architecture, but every message is stored in a separator node represented as diamond inthe figure. Steps 3–6 use the correctness of the algorithm in the computation of χ .J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991385For the collect algorithm the messages are:Message to separator:123↓ω1→3∩λ(3)1↓ω2→3∩λ(3)2↓ω3→4∩λ(4)3χχχ= ψ= ψ↓ω1→3∩λ(3)1↓ω2→3∩λ(3)2Message from separator:μ1→3 = ψμ2→3 = ψμ3→4 = χ↓ω1→3∩λ(3)1↓ω2→3∩λ(3)2↓ω3→4∩λ(4)3χχ3 =: χ3 ⊗ μ1→3 = ψ3 ⊗ μ1→3χ3 =: χ3 ⊗ μ2→3χ4 =: χ4 ⊗ μ3→4 = ψ4 ⊗ μ3→4 = φ↓λ(4)In the distribute phase, we have then:Message to separator:↓λ(4)∩λ(3)4↓λ(3)∩λ(1)3↓λ(3)∩λ(2)3χχχ= φ↓λ(4)∩λ(3)= φ↓λ(3)∩λ(1)= φ↓λ(3)∩λ(2)456Message from separator:μ4→3 = φ↓λ(4)∩λ(3) ⊗ (μ3→4)−1μ3→1 = φ↓λ(3)∩λ(1) ⊗ (μ1→3)−1μ3→2 = φ↓λ(3)∩λ(2) ⊗ (μ2→3)−1χχ3 =: χ3 ⊗ μ4→3 = φ↓λ(3)χ1 =: χ1 ⊗ μ3→1 = φ↓λ(1)χ2 =: χ2 ⊗ μ3→2 = φ↓λ(2)Fig. 2. A complete run of the HUGIN architecture.It should be stressed that in both architectures the inverses used in the computation may be elements outside thevaluation algebra, whereas the final results in all nodes of the join tree belong to the algebra. Moreover, the divisionallows to define concepts like “conditional valuations” generalizing conditional probabilities. Then even in the originalfactorization of an element of the valuation algebra, the factors need not necessarily be elements of the algebra and yetthe local computation architectures return the correct marginals. This permits a generalization of Bayesian networksto more general structures than probability potentials. For details we refer to [34].6. Propagating upper and lower boundsA problem with the join tree based computational schemes (including fusion and bucket elimination) is that thepropagation will tend not to be feasible unless all the sets of variables associated with the nodes in the join tree aresmall. However, for a given problem, we may well not be able to find such a join tree; in particular, by definition, thereexists no such join tree unless the induced width (treewidth) [10,23,32] is small.In this section we consider how to compute upper and lower bounds of valuations. In particular, we consider howto adapt the general join tree propagation algorithm (see Section 3.1) to efficiently compute bounds for the projectionproblem; the key to the efficiency is avoiding having to perform the hardest combinations, such as those involvinglarge number of variables. The mini-buckets and mini-clustering techniques of Dechter et al. [20,22,24,30,31,43], havebeen developed for approximations and bounds of this kind for a number of important problems: belief updating, mostprobable explanation and combinatorial optimization for weighted constraints. We show how this kind of algorithmic1386J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399approach can be made much more general, so that it can be applied for general semiring-induced valuation algebras6and other valuation algebras.Upper bounds are important for an optimization problem, when using a branch-and-bound algorithm. For example,consider the problem of finding a maximum assignment to a collection M of A-valuations where A is a (max, +)semiring (Example 5) i.e., with the semiring addition as max and the semiring multiplication being +. (The applica-tion of the mini-clustering approach for (almost) this semiring, and within a branch-and-bound framework, has beendescribed in [22]). We generate a search tree where each node of the tree is associated with (i) an assignment z ∈ Ωtto some set t of variables, and (ii) a multiset M (cid:10) of valuations, which is M with variables t instantiated to z. (M)↓∅M (cid:10))↓∅ is the value of the maximum assignment which extends z.is the value of the maximum assignment, and (Let b be the value of the best solution found so far; suppose we have an efficient algorithm which generates an upperM (cid:10))↓∅. If b (cid:9)≺ a then we know that z cannot be extended to an assignment with value better than b,bound a for (and so we can backtrack at this node (given that we are looking for a single maximal assignment). This generalizes toother semirings with idempotent addition, including only partially ordered semirings.(cid:11)(cid:11)(cid:11)Furthermore, upper and/or lower bounds may be sufficient to answer a particular query. In a problem where thevariables are decision variables, an upper bound may be sufficiently low to imply that no decision is adequate. Inanother situation a lower bound may be sufficiently high to imply that it is possible to make a good choice, so it maybe worth investing in more computation time to find such a choice.A somewhat different approach to approximation is given in [26], which has the advantage of enabling one to keepa careful control on the computation time. This is based on the usual join tree message passing algorithms, but wherea combination on a node is approximated to keep the computation of the combination within a set time limit. Forprobability potentials ([26], Section 5.5.1) this approximate combination can be performed by processing tuples ofthe product set sequentially, and implicitly assigning zeros to tuples which are not reached before the time limit; (ananalogous approach is also suggested for Dempster–Shafer belief potentials). A significant disadvantage of this is that,if the product frame (associated with a node in the join tree) is very large then there are a very large number of tuplesto process; there will typically then be time to process only a tiny fraction of these, which will tend to lead to a verypoor approximation of the individual combination, and also of the overall result. However, it would be interesting toexplore the potential for combining the resource-bounding ideas in [26] with the generalized mini-clustering approachdeveloped here.(cid:11)In Section 6.1 we construct the upper and lower bounds framework for the general case of valuation algebras,and give the associated propagation algorithm in Section 6.2. The join tree propagation algorithms involve repeatedM)↓u. Mini-buckets/clusteringapplication of combination followed by projection i.e., computations of the form (algorithms and our extended algorithms approximate such marginalized combinations; they produce a multiset M (cid:10)M)↓u. (An important feature of these al-of valuations whose combination is an approximation of the message (gorithms is that we do not need then to combine together the valuations M (cid:10): instead these will form the inputs forapproximations of further messages.) In Section 6.3 we consider the case of semiring-induced valuations. Section6.4 discusses the same kind of algorithm for other types of approximation. Another important consideration for theefficiency of the propagation algorithm is the number of non-zero elements of the input valuations, since having fewnon-zero elements makes a combination much faster. In Section 6.5, it is shown how one can use a pre-processingstep of constraint propagation to potentially decrease the number of non-zero tuples in the input valuations. This ideais taken a step further in Section 6.6, where it is shown how, for certain types of query, one can increase the numberof zeros in the input valuations without changing the answer.(cid:11)6.1. Bounding the projection of a combinationIn this section we extend valuation algebras by adding an associated ordering, and we consider the problem ofconstructing upper and lower bounds of the projection of a combination of valuations. (Our definition of orderedvaluation algebra is slightly different to the one given in [26].)6 Independently, Chang and Mackworth have suggested a special form of this kind of approximation for semiring-induced valuation algebras;see [13] and Section 6.1 of [14]. They also consider other approximation methods, as does Aji and McEliece [1].J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991387Ordered valuation algebras(Φ, D, (cid:11)) is said to be an ordered valuation algebra (with neutral elements) if(i) (Φ, D) is a valuation algebra;(ii) for each set of variables s, there exists an identity element es (so that for each φ ∈ Φ, φ ⊗ ed(φ) = φ) and for anysets of variables s and t, es ⊗ et = es∪t ;(iii) the relation (cid:11) is a pre-order on Φ (i.e., a reflexive and transitive relation) which only orders valuations with thesame domain, i.e., φ (cid:11) ψ implies d(φ) = d(ψ); furthermore, projection and combination both respect (cid:11), that is,for arbitrary φ, ψ, χ ∈ Φ, if φ (cid:11) ψ then(a) φ↓u (cid:11) ψ ↓u for any u ⊆ d(φ) = d(ψ); and(b) φ ⊗ χ (cid:11) ψ ⊗ χ .This last property implies that if φi (cid:11) ψi for all i = 1, . . . , k, then φ1 ⊗ · · · ⊗ φk (cid:11) ψ1 ⊗ · · · ⊗ ψk.If φ (cid:11) ψ, we say that φ is a lower bound for ψ [with respect to (cid:11)], and that ψ is an upper bound for φ.The propagation algorithms involve sequences of combinations and projections. Because projection and combina-tion both respect (cid:11), if at any point we replace any valuation by an upper bound of it, the result will be an upper boundof the correct result. Similarly with lower bounds.We can extend the notion of upper and lower bounds to valuations with smaller domains. Suppose u = d(φ) ⊆d(ψ). We say φ is a u-lower bound for ψ if φ ⊗ ed(ψ)−d(φ) (cid:11) ψ. Similarly, we say that φ is a u-upper bound for ψif ψ (cid:11) φ ⊗ ed(ψ)−d(φ).Least upper bounds and greatest lower bounds can be defined in the obvious way: for valuations φ and ψ withd(φ) = u ⊆ d(ψ), we say that φ is a least u-upper bound of ψ if (i) φ is a u-upper bound of ψ, and (ii) φ (cid:11) θ for anyu-upper bound θ of ψ. If (cid:11) is a partial order then there can be at most one least u-upper bound. We define greatestu-lower bounds analogously.A valuation φ is a lower bound for a valuation ψ if and only if it is a d(ψ)-lower bound for ψ (and similarlyfor upper bounds) since φ ⊗ e∅ = φ ⊗ ed(φ) ⊗ e∅ = φ ⊗ ed(φ) = φ, so φ (cid:11) ψ ⇐⇒ φ ⊗ e∅ (cid:11) ψ. The properties forneutral elements also imply that for any valuation φ and set of variables q, φ ⊗ eq = φ ⊗ eq−d(φ). This is becauseφ ⊗ ed(φ)∩q = φ ⊗ ed(φ) ⊗ ed(φ)∩q = φ ⊗ ed(φ) = φ; so φ ⊗ eq−d(φ) = φ ⊗ ed(φ)∩q ⊗ eq−d(φ) = φ ⊗ eq . In particular,this implies that if u = d(φ) ⊆ d(ψ) then: φ is a u-lower bound for ψ if and only if φ ⊗ ed(ψ) (cid:11) ψ; similarly foru-upper bounds.The fusion algorithm (bucket elimination) and join tree propagation algorithms [21,32,34,56,59] involve repeatedM)↓u.application of: combination of a multiset M of valuations followed by projection to a set of variables u, i.e., (If M involves too many variables this may be infeasible. The key to mini-buckets and mini-clustering bounding(cid:11)M)↓u which involve only feasible combinations. Thetechniques is to generate upper and lower bounds for (M)↓u can be bounded above (and, similarly, below) by thefundamental result is the following, showing that (combination of a multiset of valuations derived from M but only involving variables in u.(cid:11)(cid:11)Proposition 2. For i = 0, . . . , k, let φi be a valuation in an ordered valuation algebra (Φ, D, (cid:11)), let s = d(φ0) ∪· · · ∪ d(φk), the set of variables involved in these valuations, let u be a subset of s, and let t = s − (u ∪ d(φ0)).For each i = 1, . . . , k, let τi be a u ∩ d(φi)-lower bound for φi , and let θi be a u ∩ d(φi)-upper bound for φi . Then↓u∩d(φ0)↓u∩d(φ0)is a lower bound for (φ0 ⊗ · · · ⊗ φk)↓u and φis anφ00upper bound.⊗ θ1 ⊗ · · · ⊗ θk ⊗ e⊗ τ1 ⊗ · · · ⊗ τk ⊗ e↓∅t↓∅tIn Section 6.3, we give general ways of constructing the lower bound functions τi and the upper bound functions θifor semiring-induced valuation algebras. For example, under appropriate conditions, θi can be obtained by projectingφi (see Lemma 2), generalizing the approximations used for the MPE problem in [24, p. 116], and for discrete opti-mization; furthermore, defining θi using pointwise max (see Section 6.3.2) generalizes the mini-bucket approximationfor belief updating in [24, p. 120].Proof. For each i = 1, . . . , k, by definition, τi ⊗ ed(φi )−u (cid:11) φi , so, since projection respects (cid:11), and by commutativityand associativity of combination,φ0 ⊗ ed(φ1)−u ⊗ · · · ⊗ ed(φk)−u ⊗ τ1 ⊗ · · · ⊗ τk1388J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399is a lower bound for φ0 ⊗ · · · ⊗ φk. By the assumed property of neutral elements, ed(φ1)−u ⊗ · · · ⊗ ed(φk)−u equalse(d(φ1)∪···∪d(φk))−u, and so, by the property of neutral elements shown above,φ0 ⊗ ed(φ1)−u ⊗ · · · ⊗ ed(φk)−u = φ0 ⊗ et ,since t = (d(φ1) ∪ · · · ∪ d(φk)) − u − d(φ0). Hence φ0 ⊗ et ⊗ τ1 ⊗ · · · ⊗ τk is a lower bound for φ0 ⊗ · · · ⊗ φk. Since(cid:11) respects projection, this implies that(φ0 ⊗ et ⊗ τ1 ⊗ · · · ⊗ τk)↓u.Write u0 = u ∩ d(φ0). Since t ∩ u = ∅, we have (d(φ0) ∪ t) ∩ u = u0. The combination axiom implies that↓u (cid:11) (φ0 ⊗ · · · ⊗ φk)(φ0 ⊗ et ⊗ τ1 ⊗ · · · ⊗ τk)↓u = (φ0 ⊗ et )↓u0 ⊗ τ1 ⊗ · · · ⊗ τk,since τ1, . . . , τk only involve variables in u. Because φ0 and et do not involve any common variables, the combination↓u0∩t↓u0axiom and transitivity axiom imply that (φ0 ⊗ et )↓u0 = φ⊗ et0↓u0↓u0 = φ0; in more detail:↓u0 =(φ0 ⊗ et )↓u00⊗ τ1 ⊗ · · · ⊗ τk ⊗ eThe upper bound result is proved in exactly the same way. (cid:2)(cid:8)↓u0 = (φ↓u∩d(φ0). Therefore φ0(cid:7)(φ0 ⊗ et )↓∅t↓u0which equals φ0⊗ et )↓u0∪t⊗ e↓u0∩ttis a lower bound for (φ0 ⊗ · · · ⊗ φk)↓u.⊗ e↓∅t,Consider the situation where each φi can be written as τi ⊗ ed(φi )−u, where d(τi) = d(φi) ∩ u (in this case φi reallyonly depends on variables in u). Then a similar argument as that used in the above proof can be used to prove that↓u∩d(φ0)φterms are in general0necessary.is actually equal to (φ0 ⊗ · · · ⊗ φk)↓u. This shows that the e⊗ τ1 ⊗ · · · ⊗ τk ⊗ e↓∅t↓∅t↓u∩d(φ0)⊗ τ1 ⊗ · · · ⊗ τk is a lower bound for (φ0 ⊗ · · · ⊗ φk)↓u and φ0However, in applying Proposition 2, we will often be able to ensure that d(φ0) contains all variables be-= e∅. For any ψ, we have ψ ⊗ e∅ = ψ so thening eliminated, i.e., d(φ0) ⊇ s − u and hence t = ∅ and e↓u∩d(φ0)⊗ θ1 ⊗ · · · ⊗ θk is an upper bound. Inφ0particular when applying this to approximate the result of the fusion algorithm (bucket elimination), the set s − u ofeliminated variables is always just a singleton {X}; it can be assumed that there exists some valuation which involves↓∅variable X, and so the edisappeart= e∅.also, since then eterms disappear. Similarly, if the valuation algebra is stable then the terms e↓∅t↓∅tApproximating (M)↓u without performing expensive combinationsLet M be a multiset of valuations, and let u a subset of the variables involved. We will give a procedure thatproduces a multiset M (cid:10) of valuations whose combination is a lower bound for (M)↓u; similarly, a procedure forgenerating an upper bound; furthermore we can restrict the combinations used in the procedures to ensure that onlyfeasible combinations of valuations are involved. These procedures form the basis of the propagation algorithm in Sec-tion 6.2. An important point is that, except in the final step in the propagation algorithm, the approximating multisetsM (cid:10) will not need to be combined; instead the combination of M (cid:10) and other multisets will be again approximated.Proposition 2 already gives a way of approximating a marginalized combination (M)↓u (and it does this withoutperforming any combinations). However, we can typically improve the approximations by combining some of thevaluations first, but still only performing feasible combinations.(cid:11)(cid:11)We assume functions UB and LB, where for valuation φ and set of variables u ⊆ d(φ), the valuation UB(φ, u) is a u-upper bound for φ and LB(φ, u) is a u-lower bound for φ. (Methods of generating UB and LB for different formalismsare derived in Section 6.3.2.) We also assume function Partition(Input : M, B; Output : M0, M1, . . . , Mk)which takes multiset M and nonnegative number B as inputs, and produces multisets M0, M1, . . . , Mk which partitionM, and are such that the size (see below) of each Mi is at most B. It is assumed that the implementation of thefunctions UB, LB and Partition do not involve any combinations of valuations.The size of a non-empty multiset M of valuations is intended to be a quickly-evaluated measure of how hard itis to combine together the valuations M (see also the notion of weight functions in [48]). The size of M is assumedto be a nonnegative real number (though one could generalize it to a partially ordered scale if one wished; this wouldallow easy generalization of the pair of parameters (i, m) used in the mini-buckets approximations [24]). The onlyfurther property we assume of size is that if M is a singleton then the size of M is 0; this is because then combining↓∅t(cid:11)J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991389M requires no work. size can be defined in various ways. Let M be a multiset of valuations which contains at leastφ∈M d(φ)|, i.e., the total number of variablestwo valuations. One definition is to say that size of M is |d(M)| = |involved in M. In this case the parameter B used below in e.g., UpperBound(M, u, B) corresponds to the parameteri used in the mini-buckets approximations such as mbe − bel − max(i, m) [24], page 121. We allow other definitionsof size because the number of variables is not the only factor in the complexity of a combination. Another naturaldefinition of size of M is |Ωd(M)|, the cardinality of the frame associated with the combination of the valuationsin M, as this gives an upper bound on the complexity of the combination. Other definitions are possible for semiringvaluations, for example, that take into account the number of non-zero values in the valuations (which is also veryrelevant to the computational efficiency for such valuations).(cid:17)Let M be a multiset of valuations, let u be a subset of the variables involved in M, and let B be a nonnegativereal number. LowerBound(M, u, B), which we define by the algorithm below, is a function that returns a multisetM)↓u. Multiset Mof valuations; we will show that the combination of the returned multiset is a lower bound for (is partitioned into multisets which are of sufficiently small size (no more than B), and each multiset is combined.Lower bounds for the results of these combinations are chosen which involve only variables in u.Function LowerBound(M, u, B)begin(cid:11)Partition(Input : M, B; Output : M0, M1, . . . , Mk).For each i = 0, . . . , k, let φi =Let t = d(φ1) ∪ · · · ∪ d(φk) − (u ∪ d(φ0)).↓u∩d(φ0)Return multiset {e, φ0φ∈Mi↓∅t(cid:11)φ., LB(φ1, u ∩ d(φ1)), . . . , LB(φk, u ∩ d(φk))}.The algorithm for LowerBound(M, u, B) involves performing combinations, but each combination is of a multi-set of size at most B.Function UpperBound(M, u, B) is defined in an exactly analogous manner (and in practice the functionsLowerBound and UpperBound might be combined):Function UpperBound(M, u, B)beginPartition(Input : M, B; Output : M0, M1, . . . , Mk).For each i = 0, . . . , k, let φi =Let t = d(φ1) ∪ · · · ∪ d(φk) − (u ∪ d(φ0)).↓u∩d(φ0)Return multiset {e, φ0φ∈Mi↓∅t(cid:11)φ., UB(φ1, u ∩ d(φ1)), . . . , UB(φk, u ∩ d(φk))}.endendThese procedures produce correct bounds on the projection of the combination, irrespective of the choice of func-tions Partition, LB and UB. Furthermore, the computations only require combinations of multisets of size atmost B.(cid:11)Proposition 3. Whatever choices are made for(cid:11)the valuationLowerBound(M, u, B) (the combination of all the elements in the multiset LowerBound(M, u, B)) is a lowerM)↓u. Furthermore,bound for (the computations of LowerBound(M, u, B) and UpperBound(M, u, B) do not involve the combination of anymultiset of valuations of size more than B.UpperBound(M, u, B) is an upper bound for (functions Partition, LB and UB,M)↓u and the valuation(cid:11)(cid:11)(cid:11)(cid:11)Proof. By Proposition 2,to ((cid:11)(M)↓u since M0, . . . , Mk is a partition of M. Similarly,M)↓u. The last part follows by the definition of Partition. (cid:2)LowerBound(M, u, B) is a lower bound for (φ0 ⊗ · · · ⊗ φk)↓u, which is equalUpperBound(M, u, B) is an upper bound for(cid:11)Choosing the function Partition.It is always possible to choose a valid function Partition; even in theextreme case of B = 0 we can choose each Mi to be a singleton. However, the choice of partition will affect thecloseness of the approximations. Ideally we would like, where possible, to choose each Mi so that its combination φidoes not depend very much on variables not in u.1390J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399If the upper bound B on size is chosen sufficiently large then we can choose Partition to always return asingle multiset, so k = 0 and M0 = M. In this case, the propagation algorithm in Section 6.2 (for both lower and upperbounds) reduces essentially to the exact computation.Choosing the functions LB and UB. Section 6.3 shows how we can generate these functions for semiring-inducedvaluation algebras. If possible, we would like to choose LB(φ, u) to be a least u-upper bound of φ, and UB(φ, u) tobe a greatest u-lower bound of φ. As we will see, these exist in many situations.6.2. Propagation algorithm for upper and lower boundsSection 3.1 described a propagation algorithm for the projection problem (Eq. (3.2)) based on the Shenoy–Shaferarchitecture. In this section we show how this can be modified to generate upper and lower bounds. We are givenvaluations φ1, . . . , φn and a set of target domains sl, l = 1, . . . , m, and we wish to compute upper and lower boundsfor (φ1 ⊗ · · · ⊗ φn)↓sl for l = 1, . . . , m. A value B is chosen globally; the computation ensures that we do not have tocompute a combination of a multiset of valuations of size more than B. The propagation is based on repeated useof functions LowerBound and UpperBound described in Section 6.1.We focus on the general projection problem; but if we just wish to compute bounds for a single set s1 then wecan choose a root of the join tree whose associated variables contain s1, and we only need send messages towards theroot (as in the collect algorithm [34]). The mini-buckets algorithm, approximating fusion or bucket elimination, canbe considered as a special case of this, where the join tree is generated from a variable elimination sequence.Let sl be any of the target domains. We require that sl is small enough in order for us to be able to perform arbitrarycombinations of valuations with domain sl. The reason for this is that at the very last stage of the computation, wecombine valuations with domain sl (or smaller). Formally, we assume that if d(ψ) ⊆ sl for all ψ ∈ M, then the sizeof M is at most B. For example, if we use the first suggested definition of size, then it is assumed that B is at leastas large as the cardinality of any target set of variables sl.Let L(k) be the multiset of input valuations associated with node k, so that, with the notation of Section 3.1,L(k) = {φi: a(i) = k}.As in [22,43], each message for the approximate propagations will be a multiset of valuations rather than a singlevaluation. We will inductively define message μk→j , message μlowerk→j for each pair k and j ofneighboring nodes. Formally, we could consider that the induction is on: the length of a longest path, from k to a leafnode, which doesn’t pass through j (where a path is not allowed to double back on itself).k→j and message μupperAssume, by induction, that we have defined messages μi→k and μupperi→k for all neighbors i (cid:9)= j of k.(This includes the induction base case as well, i.e., when k is a leaf node, since leaf nodes only have one neighbor.)i→k and μlowerLet Mk→j = L(k) ∪ {μi→k: i ∈ ne(k), i (cid:9)= j }, consisting of all input valuations associated with node k, and allmessages coming into k from directions other than j . Let uk→j = ωk→j ∩ λ(j ) (where ωk→j is the set of variablesinvolved in valuations in Mk→j , and λ(j ) is the set of variables associated with node j ). As in Section 3.1 we definethe message μk→j to be (Mk→j )↓uk→j .(cid:11)Analogously, letM lowerk→j= L(k) ∪and letM upperk→j= L(k) ∪(cid:10)μloweri→k ,i∈ne(k),i(cid:9)=j(cid:10)μupperi→k .i∈ne(k),i(cid:9)=jWe define μlowerk→j to be LowerBound(M lower= UpperBound(M upperk→j , uk→j , B).μupperk→jk→j , uk→j , B) and defineNext we define the multisets of valuations associated finally with each node k. Let M k = L(k) ∪ {μi→k: i ∈ ne(k)}.upperAnalogously, let M ki∈ne(k) μloweri∈ne(k) μupperi→k .i→k and M k= L(k) ∪= L(k) ∪(cid:17)(cid:17)lowerJ. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991391Let sl be any target set of variables; we choose (using some fixed deterministic method) k to be a node withλ(k) ⊇ sl. The valuation φllower is defined to be(cid:12)(cid:7)LowerBound(M k(cid:8)lower, sl, B)and φlupper is defined to be(cid:12)(cid:7)UpperBound(M k(cid:8)upper, sl, B).The results of Schneuwly et al. [51] (see Section 3.1), imply that (φ1 ⊗ · · · ⊗ φn)↓λ(k) =φn)↓sl = (M k)↓sl by the transitivity [of projection] axiom.(cid:11)(cid:11)M k, and hence (φ1 ⊗ · · · ⊗The lower bound computation involves modifying the exact computation by successively replacing valuations bylower bounds (or rather by multisets of valuations whose combination is a lower bound). The exact computationinvolves sequences of combinations and projections, and combination and projection respect (cid:11), which leads to thefinal results being correct bounds:lower is a lower bound for (φ1 ⊗ · · · ⊗ φn)↓slupper is an upper bound. Furthermore, the computation of these bounds does not involve combining multisets ofTheorem 9. With the above definitions, for all l = 1, . . . , m, valuation φland φlvaluations of size more than B.(cid:11)μlowerk→j is a lower bound for messageProof. We first prove by induction that, for any neighboring nodes j and k,μk→j andk→j is an upper bound for μk→j .μupper(cid:11)(cid:11)(cid:11)Then, since combination respects (cid:11), valuation(cid:11)respects (cid:11), valuation ((cid:11)Assume by induction that for all neighbors i (cid:9)= j of k, valuationμupperi→k is a lower bound for message μi→k andi→k is an upper bound (this includes the base case of the induction, since leaf nodes only have one neighbor).Mk→j , and, because projectionMk→j )↓uk→j . By Proposition 3, we havek→j is a lowerk→j is an upper bound for μk→j . This completes thek→j )↓uk→j , and so, by transitivity of (cid:11), we havek→j )↓uk→j is a lower bound for μk→j = (M lowerk→j , uk→j , B) (cid:11) (LowerBound(M loweris a lower bound forbound for μk→j . In just the same way, we have thatinduction.M lowerk→jμupperM lowerμlowerμlower(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)Let sl be any target set of variables, and let k be the chosen node with λ(k) ⊇ sl. Because combination and projec-(cid:11)upper)↓sl . Using Proposition 3 we thenM k)↓sl (cid:11) (M kM k(cid:11)(cid:11)tion respect (cid:11), the first part implies that (have thatφllowerLowerBound(M klower)↓sl (cid:11) ((cid:8)lower, sl, B)(cid:12)(cid:7)=(cid:11) (φ1 ⊗ · · · ⊗ φn)↓sland(φ1 ⊗ · · · ⊗ φn)↓sl (cid:11)(cid:12)(cid:7)UpperBound(M k(cid:8)upper, sl, B)= φlupper.The computations involve repeated use of functions LowerBound and UpperBound, each of which does notinvolve the combination of any multiset of valuations of size more than B, followed by, for each target set sl, a finalcombination of valuations involving variables sl. By the assumption on sl and B, the size of such combinations isalso no more than B. (cid:2)6.3. Application for semiring-induced valuation algebrasIn this section we discuss how to generate the lower and upper bound functions LB and UB when the orderedvaluation algebra is generated by a semiring with an ordering on it. This enables us to use the bounds propagationalgorithms from the previous section for semiring-induced valuation algebras.6.3.1. Orderings on semirings and on semiring-induced valuation algebrasOften we will wish to use some relation (cid:11) to order the elements of a semiring, where a (cid:11) b might indicate, forexample, that b is a greater degree of preference than a. Such a relation (cid:11) on A will always be assumed to be apre-order, i.e., a reflexive and transitive relation.1392J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399We say that relation (cid:11) satisfies:+ is monotone over (cid:11) if for all a, b, c ∈ A, a (cid:11) b implies a + c (cid:11) b + c.× is monotone over (cid:11) if for all a, b, c ∈ A, a (cid:11) b implies a × c (cid:11) b × c.Let ≡ be the equivalence relation corresponding to (cid:11), so that a ≡ b if and only if a (cid:11) b and b (cid:11) a. Given that +and × are monotone over (cid:11), if it is helpful computationally, we can replace semiring A by the quotient semiring A/≡consisting of the set of equivalence classes of A, and replace each A-valuation by the corresponding A/≡-valuation.This will lead to equivalent upper and lower bounds, since if a ≡ b then a (cid:11) c ⇐⇒ b (cid:11) c, and also c (cid:11) a ⇐⇒c (cid:11) b.In many situations the natural ordering relation is (cid:11)A given by a (cid:11)A b if and only if there exists c ∈ A witha + c = b. As shown by Proposition 1 in Section 2, operations + and × are monotone over (cid:11)A, and 0 (cid:11) a for alla ∈ A.We can extend any pre-order (cid:11) on A to a relation on semiring-induced valuations. We define relation (cid:11) on A-valuations, by φ (cid:11) ψ if φ and ψ involve the same set of variables s (i.e., d(φ) = d(ψ) = s) and for all x ∈ Ωs ,φ(x) (cid:11) ψ(x).Proposition 4. Let A = (cid:6)A, +, ×(cid:7) be a semiring. Let (cid:11) be pre-order on A.(i) If (cid:11) is a partial order then so is the associated relation (cid:11) on A-valuations.(ii) If × is monotone over (cid:11) then combination of A-valuations respects (cid:11).(iii) If + is monotone over (cid:11) then projection A-valuations respects (cid:11).Proof. Let φ, ψ and χ be A-valuations with φ (cid:11) ψ. Let s = d(φ) and so d(ψ) = s, and let t = d(χ). For all x ∈ Ωs ,φ(x) (cid:11) ψ(x).(i) Suppose (cid:11) on A is a partial order, and that ψ (cid:11) φ. To prove that relation (cid:11) on A-valuations is a partial order wejust need to show that φ = ψ. For any x ∈ Ωs , we have φ(x) (cid:11) ψ(x) (cid:11) φ(x) and so φ(x) = ψ(x), since (cid:11) on A is apartial order. This implies that φ = ψ.(ii) For any x ∈ Ωs∪t , (φ ⊗ χ)(x) = φ(x↓s) × χ(x↓t ) (cid:11) ψ(x↓s) × χ(x↓t ) (since × is monotone over (cid:11)) which equals(ψ ⊗ χ)(x), showing that φ ⊗ χ (cid:11) ψ ⊗ χ as required.(iii) Suppose u ⊆ s and let y be an element of Ωu. Since + is monotone over (cid:11),↓u(y) =φφ(x): x ∈ Ωs, x↓u = yψ(x): x ∈ Ωs, x↓u = y(cid:3)(cid:5)(cid:6)(cid:11)(cid:3)(cid:5)(cid:6),which equals ψ ↓u(y), showing that φ↓u (cid:11) ψ ↓u. Hence projection respects (cid:11). (cid:2)Consider a semiring A = (cid:6)A, +, ×(cid:7) with a unit element 1, and where + and × are both monotone over pre-order(cid:11). For set of variables u, the neutral element eu is the valuation which is uniformly equal to 1, i.e., for all x ∈ Ωu,eu(x) = 1. By Theorem 2 and Proposition 4, A-valuations based on ordering (cid:11) form an ordered valuation algebra.Therefore the results and algorithms of Sections 6.1 and 6.2 apply. We show below how the upper and lower boundfunctions LB and UB can be generated.6.3.2. Generating upper and lower bound functions LB and UBFor any relation (cid:11) on A it’s easy to generate upper and lower bounds of a valuation φ which involve less variables.Suppose u is a proper subset of s = d(φ). We can define u-lower and u-upper bounds τ and θ as follows: for eachassignment x ∈ Ωu we define τ (x) to be some lower bound of [each element of] the set {φ(xy): y ∈ Ωs−u} and θ (x)to be some upper bound.Proposition 5. Let φ, τ and θ be A-valuations, and suppose u = d(τ ) = d(θ ) ⊆ d(φ) = s. Then τ is a u-lower boundfor φ if and only if for all x ∈ Ωu, τ (x) is a lower bound for {φ(xy): y ∈ Ωs−u} (i.e., for all y ∈ Ωs−u, τ (x) (cid:11) φ(xy)).Furthermore, τ is a greatest u-lower bound for φ if and only if for all x ∈ Ωu, τ (x) is a greatest lower bound for{φ(xy): y ∈ Ωs−u}.J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991393Similarly, θ is a u-upper bound for φ if and only if for all x ∈ Ωu, θ (x) is a upper bound for {φ(xy): y ∈ Ωs−u}. θis a least u-upper bound for φ if and only if for all x ∈ Ωu, θ (x) is a least upper bound for {φ(xy): y ∈ Ωs−u}.Proof. By definition, τ is a u-lower bound for φ if and only if τ ⊗ es−u (cid:11) φ, which is if and only if for all z ∈ Ωs ,(τ ⊗ es−u)(z) (cid:11) φ(z), i.e., τ (z↓u) (cid:11) φ(z). This is if and only if for all x ∈ Ωu and y ∈ Ωs−u, τ (x) (cid:11) φ(xy). Hence τis a u-lower bound for φ if and only if for all x ∈ Ωu, τ (x) is a lower bound for {φ(xy): y ∈ Ωs−u}.Suppose for all x ∈ Ωu, τ (x) is a greatest lower bound for {φ(xy): y ∈ Ωs−u}, and let χ be any u-lower bound forφ. Then for all x ∈ Ωu, χ(x) is a lower bound for {φ(xy): y ∈ Ωs−u}, so χ(x) (cid:11) τ (x); hence χ (cid:11) τ , showing that τ isa greatest u-lower bound for φ.To prove the converse, suppose τ is a u-lower bound for φ and that there exists x0 ∈ Ωu such that τ (x0) is not agreatest lower bound for {φ(x0y): y ∈ Ωs−u}. It is sufficient to show that then τ is not a greatest u-lower bound forφ. There exists a lower bound a for {φ(x0y): y ∈ Ωs−u} such that a (cid:9)(cid:11) τ (x0). Define τ (cid:10) by τ (cid:10)(x0) = a, and for x (cid:9)= x0,let τ (cid:10)(x) = τ (x). Then, by the first part, τ (cid:10) is a u-lower bound for φ; however, τ (cid:10) (cid:9)(cid:11) τ which implies that τ is not agreatest u-lower bound for φ.The u-upper bound results follow similarly. (cid:2)When (cid:11) is a lattice one can define least u-upper bounds and greatest u-lower bounds in a simple canonical way.Least upper bounds and greatest lower bounds when (cid:11) defines a lattice. Suppose that A is a lattice under theordering (cid:11). Then any finite subset B of A has a least upper bound, which we write as sup B, and a greatest lowerbound, inf B. In particular when (cid:11) is a total order, sup is max with respect to (cid:11) and inf is min. For any A-valuationφ : Ωs → A, and any subset u of s we can define valuations φ⇓u and φ(cid:2)u both on set of variables u, as follows: forx ∈ Ωu, let φ⇓u(x) = sup{φ(z): z ∈ Ωs, z↓u = x}, and φ(cid:2)u(x) = inf{φ(z): z ∈ Ωs, z↓u = x}. Then, by Proposition5, φ⇓u is the least u-upper bound of φ and φ(cid:2)u is the greatest u-lower bound of φ. Hence we can define the lowerbound function LB used in the propagation algorithms by LB(φ, u) = φ(cid:2)u, and define the upper bound function UBby UB(φ, u) = φ⇓u.This covers most of the examples in the paper. The ordering used in each example is (cid:11)A; probability potentials(Examples 1/9), used for inference in Bayesian networks, is based on a semiring with a total order, and so we candefine LB and UB in this simple way (as in the definition used for mini-bucket approximation for belief updating [24]);similarly, for any c-semiring which is totally ordered e.g., Examples 2, 3, 5, and 6; furthermore, any c-semiring withidempotent multiplication generates a distributive lattice (Example 4).The following result implies that we could define in very general circumstances UB(φ, u) to be φ↓u (though it maynot be a close upper bound). However, if addition is idempotent, as in c-semirings, for example, it will be a leastu-upper bound.Lemma 2. Let φ be a valuation and let u be a subset of d(φ). Then φ↓u is a u-upper bound for φ with respect to (cid:11)A.If addition is idempotent then φ↓u is a least u-upper bound for φ with respect to (cid:11)A.Let (cid:11) be a pre-order such that addition is monotone with respect to (cid:11), and suppose that 0 is a lower bound forφ(z) for each z ∈ Ωd(φ). Then φ↓u is a u-upper bound for φ with respect to (cid:11). If also addition is idempotent then φ↓uis a least u-upper bound for φ with respect to (cid:11).This upper bound generalizes that used in the mini-bucket approximation for MPE (most probable explanation) in[24], page 116. See also [13] and [14] (Section 6.1) which uses an approximation of a similar form.Suppose 0 is a lower bound of finite sub-multiset G of A. For any a ∈ G, 0 is a lower bound forProof. We prove the second half of the lemma; the first half follows from the second half since addition is monotonewith respect to (cid:11)A, and for all a ∈ A, 0 (cid:11)A a.(cid:2){G − {a}}, so aG is an upper bound foris a lower bound forG. If also addition is idempotent then consider any upper bound b for G. Since addition is monotone with respect to(cid:11), we haveG, since addition is monotone with respect to (cid:11). This implies that(cid:2)a∈G b = b. Hence if addition is idempotent thenG is a least upper bound for G.a∈G a (cid:11)(cid:2)(cid:2)(cid:2)(cid:2)1394J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399Let s = d(φ) and let x be any element of the frame Ωu. Then φ↓u(x) equals{φ(xy): y ∈ Ωs−u}, so, by theabove argument, φ↓u(x) is an upper bound for {φ(xy): y ∈ Ωs−u}, and is a least upper bound if addition is idempotent.Therefore by Proposition 5, φ↓u is a u-upper bound for φ, which is a least u-upper bound if addition is idempotent. (cid:2)(cid:2)6.3.3. Computational efficiency of the propagationWe analyze the computational efficiency of computing the bounds, as described in Section 6.2, for semiring-induced valuations. We focus only on the efficiency of computing the lower approximations; almost identical analysiscan be used for the upper approximations (generating the same upper bounds on the number of operations required).lower for (φ1 ⊗ · · · ⊗ φn)↓sl . Let v beSo, as in Theorem 9, we wish to compute, for all l = 1, . . . , m, the lower bound φlthe number of variables involved, i.e., v = |d(φ1) ∪ · · · ∪ d(φn)|. The algorithm involves a join tree embedding. Wecan always construct, by variable elimination (as in fusion/bucket elimination), a join tree with at most v nodes. Solet us assume that the join tree has at most v nodes.To simplify, we assume that the order (cid:11) on the semiring is a lattice ordering, which covers most of the examplesin the paper; this kind of analysis can be extended to more general cases.We analyze computational efficiency in terms of the number of semiring basic operations. This is defined to be oneof the following binary operations on the semiring: multiplication, addition, or computing the greatest lower bound(or the least upper bound) of a pair of elements in the semiring. The computational efficiency clearly depends on thechoice of the function size. We first consider the case where size of a multiset M of valuations is defined to be thecardinality of the associated frame, i.e., |Ωd(M)|, where d(M) is the set of variables involved in some valuation in M.Consider a valuation ψ. Suppose that the cardinality of its associated frame is at most B i.e., |Ωd(ψ)| (cid:2) B. Let ube any subset of d(ψ). Computing (all the values of) ψ ↓u requires a total of less than B basic operations (additions).Similarly, computing (all the values of) the function LB(ψ, u) requires less than B basic operations (binary greatestlower bounds), where LB is defined as in the lattices paragraph in Section 6.3.2.Consider a multiset M of valuations, where M contains p valuations and size(M) (cid:2) B, i.e., the cardinality ofthe associated product set is at most B. The computation of the combination of M involves less than (p − 1)B basicoperations (multiplications).↓∅involved in the LowerBound function needs no computation if addition is idempotent, since it ist↓∅then equal to 1. Otherwise, e{X}for each variable X of interest (the cost of this pre-computation is at worst the number of variables times the meandomain size). Computing ethen involves less than |t| additional basic operations (multiplications).↓∅{X} is equal to↓∅{X}, where e1. We pre-compute ecan be written asThe term eX∈t eω∈ΩX↓∅t(cid:2)(cid:4)↓∅tComputations for LowerBound function We will assume that the Partition function does not involve any ba-ksic operations. By the previous remarks, computing φi for all i = 0, . . . k involves less thani=0(|Mi| − 1)B =involves less than |d(M)| basic operations. Computing the valu-B(|M| − (k + 1)) basic operations. Computing e↓u∩d(φ0), LB(φ1, u ∩ d(φ1)), . . . , LB(φk, u ∩ d(φk)) involves less than (k + 1)B additional basic operations.ations φ0Hence computing the LowerBound function involves less than B|M| + |d(M)| basic operations. Usually the secondterm will be much smaller than the first.Let n∗ be the maximum value of |M| over all the applications of LowerBound in the algorithm, and let v∗ be the↓∅t(cid:2)maximum value of |d(M)|, the number of variables involved.In computing the lower bound φllower for all l = 1, . . . , m, the procedure LowerBound is applied in both directionsfor each edge in the join tree; it is then applied once for each target set. So LowerBound is applied less than2|V | + m times where |V | is the number of nodes in the join tree, and m is the number of target sets, and hence,by our assumption, less than 2v + m times. Therefore the number of basic operations in all the applications of theLowerBound function is less than (m + 2v)(Bn∗ + v∗); the pre-processing adds another small term ¯Dv which islinear in the number v of variables, where ¯D is the mean domain (frame) size of the v variables.The final stage of the algorithm involves, for each l = 1, . . . , m, a combination of a multiset of valuations whosedomains are included in sl; this last part involves less than a total of Bm(n∗ − 1) basic operations. Hence overall thenumber of operations required is less than (m + 2v)(Bn∗ + v∗) + Bmn∗ + ¯Dv. A crude upper bound for n∗ is n, thenumber of input valuations (n∗ will tend to be much smaller than n unless B is very small), and, similarly v∗ (cid:2) v, soan overall upper bound on the number of operations required is (m + 2v)(Bn + v) + Bmn + ¯Dv, which is low orderJ. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991395polynomial. In particular, for classes of problems where m and n grow linearly with respect to the number of variablesv, and ¯D is bounded, then this is O(v2), since B is a constant.Suppose instead we define size of multiset M to be the number of variables involved in M; let D be an upperbound on the size of the frame of any variable involved. The number of operations is then less than (m + 2v)(DB n +v) + DB mn + Dv, which is again low order polynomial, since B is a constant.6.4. Approximations rather than boundsThe lower and upper approximations defined above will in certain situations be sufficient to answer queries. How-ever, they will not necessarily be close approximations. One can often get closer to the exact answers by using otherapproximations, based on replacing the bound function LB (or UB) by an approximating function AP.Let φ be a valuation with d(φ) ⊇ u. We let AP(φ, u) be some valuation θ with d(θ ) = u such that θ ⊗ ed(φ) insome sense approximates φ. The propagation algorithm can then be used with function AP replacing LB in the lowerbound propagation, to give approximations.If the ordered valuation algebra was generated by a semiring A and ordering relation (cid:11), then the approximationcan be made pointwise. In particular if (cid:11) is a total order then for each x ∈ Ωu we can set AP(φ, u)(x) to be someintermediate value (or some “average” value) of {φ(xy): y ∈ Ωd(φ)−u}, as opposed to LB which takes the minimumvalue, and UB which uses the maximum value. For example, for the case of probability potentials we could use themean value as suggested in [24], page 120, i.e., we define AP(φ, u)(x) to be the mean value of {φ(xy): y ∈ Ωd(φ)−u}.6.5. Using propagation of constraintsFrom a collection of semiring-induced valuations one can generate constraints based on the zeros. These can beused to deduce new constraints which may increase the number of zeros of the input valuations; in particular, thismay allow us to eliminate elements of the frame of a variable. The number of non-zero elements in the valuations isrelevant to the computational efficiency of the propagation algorithms in Sections 3.1 and 6.2; for example, if valuationφ has p non-zero tuples, and ψ has q, then the number of multiplications required in computing φ ⊗ ψ is at mostpq. This pre-processing step can sometimes greatly improve the efficiency, especially if many elements of frames areeliminated. This idea is related to the notion of shrinking in [6].6.5.1. Generating implied constraintsA constraint R on set of variables u is a subset of Ωu; we say that d(R) = u. Given A-valuation φ, define Rφ to bethe constraint on variables d(φ) given by x ∈ Rφ if and only if φ(x) (cid:9)= 0. Constraint Rφ gives the non-zero tuples of φ.Implied constraints give partial information about the zeros. Let R be a constraint on variables u ⊆ d(φ). ConstraintR is said to be an implied constraint of φ if the following condition holds, for any z ∈ Ωd(φ): φ(z) (cid:9)= 0 ⇒ z↓u ∈ R(or equivalently: z ∈ Rφ ⇒ z↓u ∈ R). So the complement of R gives zeros of φ: if z↓u /∈ R then φ(z) = 0. R is saidto be an implied constraint of multiset {φ1, . . . , φn} if it is an implied constraint of φ1 ⊗ · · · ⊗ φn. We also say that{φ1, . . . , φn} implies R.Let C be a set of constraints involving variables s, and let R be a constraint on variables u ⊆ s. We say that Cimplies R if z↓u ∈ R holds for all z ∈ Ωs which are solutions of the Constraint Satisfaction Problem C, i.e., such thatz↓d(R(cid:10)) ∈ R(cid:10) for all R(cid:10) ∈ C.Proposition 6. Let M be a multiset of A-valuations.(i) M implies Rφ for each φ ∈ M.(ii) Suppose that C is a set of implied constraints of M, and that C implies R. Then M implies R.(iii) If {Rφ: φ ∈ M} implies constraint R then M implies R.(iv) Suppose now that A has no zero divisors, i.e., a × b is non-zero for all non-zero a, b ∈ A. Then {Rφ: φ ∈ M}implies R if and only if M implies R.Proof. Let ψ =(cid:11)M and let s = d(ψ).1396J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399(i) Let z ∈ Ωs . For any φ ∈ M, if z↓u /∈ Rφ then φ(z↓u) = 0 so ψ(z) = 0, showing that Rφ is an implied constraintof ψ and hence of M.(ii) Let u = d(R), the set of variables of constraint R. By definition, u ⊆ s. Let z be any element of Ωs such thatψ(z) (cid:9)= 0. Then for all R(cid:10) ∈ C, z↓d(R(cid:10)) ∈ R(cid:10) since ψ implies R(cid:10), and so z↓u ∈ R, showing that M implies R.(iii) follows immediately from (i) and (ii).(iv) We need to show the converse of (iii). Suppose M implies R and that z ∈ Ωs is such that for all φ ∈ M,φ∈M φ(z↓d(φ)) is non-zero. Since R is an impliedz↓d(φ) ∈ Rφ. Then for all φ ∈ M, φ(z↓d(φ)) (cid:9)= 0, so ψ(z) =constraint of ψ, z↓d(R) ∈ R, showing that {Rφ: φ ∈ M} implies R. (cid:2)(cid:4)Part (i) of this proposition shows that, given input set of valuations M, we can initialize the set of implied constraintsto {Rφ: φ ∈ M}. (Part (iv) of Proposition 6 shows that if A has no zero divisors, any implied constraint of M is animplied constraint of {Rφ: φ ∈ M}.) We can apply a propagation algorithm to generate more implied constraints from{Rφ: φ ∈ M}; for example, we can use the upper bound approach of Sections 6.1, 6.2 and 6.3 applied to the initial setof constraints (or, similarly, a mini-clustering approach); we could also use arc consistency or e.g., path consistencyto generate new constraints. By part (iii) of Proposition 6, the new constraints will be implied constraints of M.6.5.2. Using implied constraintsThe following result shows how we can amend an input set of semiring-induced valuations by a set of impliedconstraints, increasing the number of zero values, but without changing the combination of the valuations.Proposition 7. Let A be a semiring and let C be a set of implied constraints of multiset of A-valuations {φ1, . . . , φn}.For i = 1, . . . , n, let φ(cid:10)i(x), for each x ∈ Ωd(φi ), as follows: if there exists an implied constraintR ∈ C with d(R) ⊆ d(φi) and x↓d(R) /∈ R then let φ(cid:10)(cid:10)φ1 ⊗ · · · ⊗ φn = φ1i(x) = 0; otherwise define φ(cid:10)i be given by defining φ(cid:10)i(x) = φi(x). Then⊗ · · · ⊗ φ(cid:10)n.Proof. For i = 1, . . . , n, let si = d(φi) and let s = d(φ1) ∪ · · · ∪ d(φn). Let z be an element of the frame Ωs . We needto show that (φ1 ⊗ · · · ⊗ φn)(z) = (φ(cid:10)i(z↓si ). So1suppose there exists i ∈ {1, . . . , n} with φi(z↓si ) (cid:9)= φ(cid:10)n)(z) = 0.Also, there exists an implied constraint R ∈ C on variables u ⊆ si with z↓u /∈ R. Since R is an implied constraint,(φ1 ⊗ · · · ⊗ φn)(z) = 0 and so equals (φ(cid:10)1n)(z). Clearly this holds if for all i = 1, . . . , n, φi(z↓si ) = φ(cid:10)⊗ · · · ⊗ φ(cid:10)i(z↓si ). Then by definition φ(cid:10)n)(z) as required. (cid:2)i(z↓si ) = 0 so (φ(cid:10)⊗ · · · ⊗ φ(cid:10)⊗ · · · ⊗ φ(cid:10)1The implied constraints tell us that some tuples can be set to have zero value; φ(cid:10)i is obtained from φi by setting suchtuples to zero. The point of replacing the elements φi by φ(cid:10)i is to make them easier to combine; the complexity of acombination is related to the number of non-zero tuples; decreasing the number of non-zero tuples can thus make thecomputations faster, potentially very substantially so if strong constraints can be deduced. An additional advantage isthat the upper bounds generated in a join tree propagation upper approximation (Sections 6.2 and 6.3) will sometimesbe made tighter by this pre-processing.6.6. Setting some semiring values to 0Let A = (cid:6)A, +, ×(cid:7) be a semiring with zero element 0 and unit element 1. Let (cid:11) be a pre-order on A such that +and × are monotone over (cid:11), and such that 0 (cid:11) a for every element a ∈ A.The element 0 is a lower bound for every element a ∈ A in the semiring. So a particular case of a lower bound ofan A-valuation is when we replace certain semiring values used in the input valuations by 0. This has computationaladvantages, as the efficiency of the computation is somewhat related to the number of non-zero values in the inputvaluations, and constraints propagation approaches can be used, as discussed in Section 6.5. We will consider theeffect of choosing a subset P ((cid:9) 0) of the semiring A, and replacing semiring values in the input valuations whichare not in P by 0. With appropriate semiring and choice of P , it can be shown that this does not affect the answer tocertain kinds of queries. This is related to the notion of sinking in [6].Consider φ = φ1 ⊗ · · · ⊗ φn. Let s = d(φ) and for i = 1, . . . , n let si = d(φi). Define Q = {φi(xi):i =} to be the set of all semiring values taken by any of the input valuations. Define Q× to be clo-1, . . . , n, xi ∈ Ωsisure of Q under the × operation.J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991397We consider input A-valuations and subset P of A satisfying the following condition:(∗) If a, b ∈ Q× and a × b ∈ P then a, b ∈ P .(cid:4)ni=1 ai is in P thenCondition (∗) implies that if elements ai of Q×, for i = 1, . . . , n are such that their productai is in P for all i = 1, . . . , n. Hence we have for all x ∈ Ωs , if φ(x) is in P then φi(x) is in P for all i = 1, . . . , n.Condition (∗) is satisfied if Q and P satisfy the pair of conditions (i) if a ∈ Q then a (cid:11) 1, and (ii) if a ∈ P anda (cid:11) b (cid:11) 1 then b ∈ P .An important special case is when, for some a ∈ A, P equals P!a which is defined to be {b ∈ A: b ! a}, or,similarly, when P equals P(cid:9)(cid:11)a = {b ∈ A: b (cid:9)(cid:11) a}. In either case, condition (∗) is satisfied as long as (i) is satisfied, i.e.,the input semiring values are all bounded above by 1.Consider P satisfying (∗). Define φP⊗i (x↓si ) (cid:9)= 0i (x↓si ) = φi(x↓si ) and so φ(cid:10)(x) = φ(x). We also have φ(x) ∈ P if and only if φ(cid:10)(x) ∈ P . So if φ(x) ∈ P (orn . By the above remarks, if φ(x) ∈ P then φ(cid:10)(x) = φ(x). Also, if φ(cid:10)(x) ∈ P then for all i, φPi (xi) = φi(xi) if φi(xi) ∈ P ; otherwise φPi (xi) = 0. Let φ(cid:10) = φPi by φP· · · ⊗ φPso φPφ(cid:10)(x) ∈ P ) then φ(cid:10)(x) = φ(x).1Suppose we are interested in finding complete assignments x whose combined semiring value is in P ; for example,if we are only interested in x whose semiring value has a lower bound of a, we could use P = P!a. The aboveargument shows that we can use φ(cid:10) instead of φ, without changing the result. This can sometimes greatly improveefficiency, as the components of φ(cid:10) can have many fewer non-zero values than those of φ. As in Section 6.5 we canpropagate the constraints associated with each φPi .Consider now the case where A is a c-semiring, with (cid:11) = (cid:11)A defined by a (cid:11) b if and only if a + b = b. Weconsider P of the form P(cid:9)(cid:11)a = {b ∈ A: b (cid:9)(cid:11) a}, for some a ∈ A; this is for a situation where semiring value a (orworse) is not considered significant. P always satisfies (∗). If φ(x) /∈ P then 0 (cid:11) φ(x) (cid:11) a. The results above implythat for any x ∈ Ωs , φ(cid:10)(x) (cid:11) φ(x) (cid:11) φ(cid:10)(x) + a, which leads to: for any y ∈ Ωu, (φ(cid:10))↓u(y) (cid:11) φ↓u(y) (cid:11) (φ(cid:10))↓u(y) + a,giving bounds on φ↓u. If (φ(cid:10))↓u(y) ! a then we have equality: (φ(cid:10))↓u(y) = φ↓u(y).If additionally, (cid:11) is a total order and φ↓u(y) ∈ P then φ↓u(y) = (φ(cid:10))↓u(y). Also, φ↓u(y) ∈ P if and only if(φ(cid:10))↓u(y) ∈ P . Hence if we want to compute projections of combinations of A-valuations then we can use the re-duced representation φ(cid:10) (only keeping input semiring values " a) if we are only interested in partial tuples with(output) semiring values in P (i.e., values more than a). This case of A based on a totally ordered c-semiring coversseveral interesting systems see [9,50] and Examples 3, 5 and 6.7. ConclusionSemirings are important algebraic structures which induce valuation algebras and permit thus the application of dif-ferent architectures for local computation. Such semirings can be used to define soft constraints or to generate differentuncertainty calculi. In any of these cases inference consists of the solution of the projection problem. A straightforwardsolution of this problem is in general not feasible, because the domains of the valuations to be treated become muchtoo large and both computing time as well as space requirement grow exponentially. However, the fusion algorithmallows one to limit the domains in which the operations of combination and projection have to be executed to oftenmuch smaller dimensions. This may make an otherwise unfeasible computation very fast, in fact, linear in the size ofthe largest frame to be treated—which is exponential only in the largest node domain size in the join tree, in contrastwith a naive algorithm which is exponential in the number of variables.The fusion algorithm is the base for different derived architectures for local computation. Idempotent semiringslead to idempotent valuation algebras, so-called information algebras. For these algebras the particularly simple andefficient idempotent architecture can be used. In many other cases a notion of division exists in the semiring and canbe exported to the induced valuation algebra. Then efficient architectures originally designed for probability networksthat use a concept of division can be used.For situations where the domains of the valuations are such that exact computation is still not feasible, upper andlower bounds can be efficiently derived for a broad class of formalisms, using a modification of the propagationalgorithms. These can be used, for example, within a branch and bound algorithm for optimization.1398J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399The knowledge of these generic architectures which apply to a multitude of inference problems in very differentcontexts and formalisms should be part of the tool box of any designer of inference or reasoning systems. It can beuseful to solve complex problems, which in the worst case demand an infeasible amount of computation and space.AcknowledgementsWe are very grateful to Marc Pouly, for his comments and proof reading, and to Cesar Schneuwly for his help,especially with the running propagation example.References[1] S.M. Aji, R.J. McEliece, The generalized distributive law, IEEE Trans. Inform. Theory 46 (2) (2000) 325–343.[2] E. Amir, Efficient approximation for triangulation of minimum treewidth, in: Proceedings of the 17th Conference on Uncertainty in ArtificialIntelligence, 2001, pp. 7–15.[3] F. Baccelli, G. Cohen, G.J. Olsder, J.-P. Quadrat, Synchronization and Linearity: An Algebra for Discrete Event Systems, Wiley, 1992.[4] C. Beeri, R. Fagin, D. Maier, A. Mendelzon, J. Ullman, M. Yannakakis, Properties of acyclic database schemes, in: ACM Symposium onTheory of Computing, ACM Press, New York, 1981, pp. 355–362.[5] S. Bistarelli, T. Fruewirth, M. Marthe, F. Rossi, Soft constraint propagation and solving in constraint handling rules, Comput. Intell. (2004),Special Issues on Preferences in AI and CP.[6] S. Bistarelli, S.K.L. Fung, J.H.M. Lee, H. Leung, A local search framework for semiring-based constraint satisfaction problems, in: Proc.CP2003 Workshop on Soft Constraints (Soft-2003), 2003.[7] S. Bistarelli, F. Gadducci, Enhancing constraints manipulation in semiring-based formalisms, in: Proc. 17th European Conference on ArtificialIntelligence (ECAI 2006), 2006, pp. 63–67.[8] S. Bistarelli, U. Montanari, F. Rossi, Semiring-based constraint satisfaction and optimization optimisation, J. ACM 44 (1997) 201–236.[9] S. Bistarelli, U. Montanari, F. Rossi, T. Schiex, G. Verfaillie, H. Fargier, Semiring-based CSPs and valued CSPs: Frameworks, properties andcomparison, CONSTRAINTS: An International Journal 4 (3) (1999).[10] H.L. Bodlaender, A tourist guide through treewidth, Acta Cybern. 11 (1–2) (1993) 1–22.[11] H.L. Bodlaender, Treewidth: Characterizations, applications, and computations, in: F.V. Fomin (Ed.), WG, in: Lecture Notes in ComputerScience, vol. 4271, Springer, 2006, pp. 1–14.[12] K. Cechlárová, J. Plávka, Linear independence in bottleneck algebras, Fuzzy Sets Syst. 77 (3) (1996) 337–348.[13] L. Chang, Semiring-based unifying framework for constraint-based inference, Master’s thesis, University of British Columbia, 2005.[14] L. Chang, A.K. Mackworth, Generalized constraint-based inference, Tech. Rep. TR-2005-10, Dept. of Computer Science, Univ. of BritishColumbia, 2005.[15] A.H. Clifford, G.B. Preston, Algebraic Theory of Semigroups. American Mathematical Society, Providence, Rhode Island, 1967.[16] M. Cooper, T. Schiex, Arc consistency for soft constraints, Artif. Intell. 154 (1–2) (2004) 199–227.[17] R. Croisot, Demi-groupes inversifs et demi-groupes réunions de demi-groupes simples, Ann. Sci. Ecole Norm. Sup. 79 (3) (1953) 361–379.[18] B. De Baets, Idempotent uninorms, European J. Op. Res. 118 (631-642) (1996) 00.[19] J. De Kleer, J. Brown, Theories of causal ordering, Artif. Intell. 29 (1986) 33–61.[20] R. Dechter, Mini-buckets: A general scheme for generating approximations in automated reasoning, in: Proc. Fifteenth International JointConference of Artificial Intelligence (IJCAI97), 1997, pp. 1297–1303.[21] R. Dechter, Bucket elimination: A unifying framework for reasoning, Artif. Intell. 113 (1–2) (1999) 41–85.[22] R. Dechter, K. Kask, J. Larrosa, A general scheme for multiple lower bound computation in constraint optimization, in: Proc. CP2001, 2001,pp. 346–360.[23] R. Dechter, J. Pearl, Network-based heuristics for constraint satisfaction problems, Artif. Intell. 34 (1) (1987) 1–38.[24] R. Dechter, I. Rish, Mini-buckets: A general scheme for bounded inference, J. ACM 50 (2) (2003) 107–153.[25] V. Gogate, R. Dechter, A complete anytime algorithm for treewidth, in: Proceedings of the 20th Conference on Uncertainty in ArtificialIntelligence UAI-04, 2004, pp. 201–208.[26] R. Haenni, Ordered valuation algebras: A generic framework for approximating inference, Internat. J. Approx. Reason. 37 (1) (2004) 1–41.[27] R. Haenni, J. Kohlas, N. Lehmann, Probabilistic argumentation systems, in: J. Kohlas, S. Moral (Eds.), Handbook of Defeasible Reasoningand Uncertainty Management Systems, vol. 5: Algorithms for Uncertainty and Defeasible Reasoning, Kluwer, Dordrecht, 2000, pp. 221–287;http://diuf.unifr.ch/tcs/publications/ps/hkl2000.pdf.[28] E. Hewitt, H. Zuckermann, The l1-algebra of a commutative semigroup, Trans. Amer. Math. Soc. 83 (1956) 70–97.[29] F. Jensen, S. Lauritzen, K. Olesen, Bayesian updating in causal probabilistic networks by local computations, Comp. Stat. Q. 4 (1990) 269–282.[30] K. Kask, R. Dechter, Branch and bound with mini-bucket heuristics, in: Proc. International Joint Conference on Artificial Intelligence(IJCAI99), 1999, pp. 426–433.[31] K. Kask, R. Dechter, Mini-bucket heuristics for improved search, in: Proc. UAI99, 1999, pp. 314–323.[32] K. Kask, R. Dechter, J. Larrosa, A. Dechter, Unifying cluster-tree decompositions for reasoning in graphical models, Artif. Intell. 166 (1–2)(2005) 165–193.[33] E. Klement, R. Mesiar, E. Pap, Triangular Norms, Trends in Logic, Kluwer Academic Publ. Dordrecht, 2000.J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991399[34] J. Kohlas, Information Algebras: Generic Structures for Inference, Springer-Verlag, 2003.[35] J. Kohlas, Valuation algebras induced by semirings. Tech. Rep. 04-03, Department of Informatics, University of Fribourg, 2004;http://diuf.unifr.ch/tcs/publications/ps/kohlas2004a.pdf.[36] J. Kohlas, R. Haenni, S. Moral, Propositionalinformation systems, J. Logic Comput. 9 (5) (1999) 651–681; http://diuf.unifr.ch/tcs/publications/ps/kmh99.pdf.[37] J. Kohlas, P. Shenoy, Computation in valuation algebras, in: J. Kohlas, S. Moral (Eds.), Handbook of Defeasible Reasoning and UncertaintyManagement Systems, vol. 5: Algorithms for Uncertainty and Defeasible Reasoning, Kluwer, Dordrecht, 2000, pp. 5–40.[38] V. Kolokoltsov, V. Maslov, Idempotent Analysis and its Applications, Kluwer Academic Publ. Dordrecht, 1997.[39] J. Larrosa, T. Schiex, Solving weighted CSP by maintaining arc consistency, Artif. Intell. 159 (2004) 1–26.[40] S. Lauritzen, F. Jensen, Local computation with valuations from a commutative semigroup, Ann. Math. Artif. Intell. 21 (1) (1997) 51–70.[41] S. Lauritzen, D. Spiegelhalter, Local computations with probabilities on graphical structures and their application to expert systems, J. RoyalStat. Soc. 50 (2) (1988) 157–224.[42] D. Maier, The Theory of Relational Databases, Pitman, London, 1983.[43] R. Mateescu, R. Dechter, K. Kask, Tree approximation for belief updating, in: Proc. AAAI-2002, 2002, pp. 553–559.[44] K. Menger, Statistical metrics, Proc. Nat. Acad. Sci. 28 (1942) 535–537.[45] J. Mengin, N. Wilson, Logical deduction using the local computation framework, in: A. Hunter, S. Parsons (Eds.), European Conf. EC-SQARU’99, London. Lecture Notes in Artif. Intell. Springer, 1999, pp. 386–396.[46] J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann Publishers Inc., 1988.[47] M. Pouly, Nenok 1.1 user guide, Tech. Rep. 06-02, Department of Informatics, University of Fribourg, 2006.[48] M. Pouly, J. Kohlas, Minimizing communication costs of distributed local computation, Tech. rep., Department of Informatics, University ofFribourg, 2005.[49] T. Schiex, Possibilistic constraint satisfaction problems or “how to handle soft constraints?” in: D. Dubois, M.P. Wellman, B. D’Ambrosio, P.Smets (Eds.), Uncertainty in Artificial Intelligence: Proc. of the Eighth Conference, Kaufmann, San Mateo, CA, 1992, pp. 268–275.[50] Schiex, T., Fargier, H., Verfaillie, G., Valued constraint satisfaction problems: Hard and easy problems, in: Proc. IJCAI-95, 1995, pp. 631–637.[51] C. Schneuwly, M. Pouly, J. Kohlas, Local computation in covering join trees, Tech. Rep. 04-16, Department of Informatics, University ofFribourg, 2004; http://diuf.unifr.ch/tcs/publications/ps/schneuwlypoulykohlas04.pdf.[52] B. Schweizer, A. Sklar, Statistical metric spaces, Pacific J. Math. 10 (1960) 313–334.[53] G. Shafer, An axiomatic study of computation in hypertrees, Working Paper 232, School of Business, University of Kansas, 1991.[54] G. Shafer, Probabilistic Expert Systems, CBMS-NSF Regional Conference Series in Applied Mathematics, vol. 67, SIAM, Philadelphia, PA,1996.[55] G. Shafer, P. Shenoy, Local computation in hypertrees, Tech. Rep. 201, School of Business, University of Kansas, Lawrence, 1988.[56] P. Shenoy, Valuation-based systems: A framework for managing uncertainty in expert systems, in: L. Zadeh, J. Kacprzyk (Eds.), Fuzzy Logicfor the Management of Uncertainty, John Wiley & Sons, 1992, pp. 83–104.[57] P. Shenoy, Axioms for dynamic programming, in: A. Gammerman (Ed.), Computational Learning and Probabilistic Reasoning, Wiley, Chich-ester, UK, 1996, pp. 259–275.[58] P.P. Shenoy, Binary join trees for computing marginals in the Shenoy--Shafer architecture, Internat. J. Approx. Reason. 17 (1997) 239–263;http://citeseer.ist.psu.edu/article/shenoy97binary.html.[59] P.P. Shenoy, G. Shafer, Axioms for probability and belief-function propagation, in: R.D. Shachter, T.S. Levitt, L.N. Kanal, J.F. Lemmer (Eds.),Uncertainty in Artificial Intelligence 4, in: Machine Intelligence and Pattern Recognition, vol. 9, Elsevier, Amsterdam, 1990, pp. 169–198.[60] W. Spohn, Ordinal conditional functions: A dynamic theory of epistemic states, in: W. Harper, B. Skyrms (Eds.), Causation in Decision, BeliefChange, and Statistics, vol. 2, Dordrecht, Netherlands, 1988, pp. 105–134.[61] T. Tamura, N. Kimura, On decompositions of a commutative semigroup, Kodai Math. Sem. Rep. (1954) 109–112.[62] N. Wilson, Bounds and pre-processing for local computation of semiring valuations, in: J. Kohlas, J. Mengin, N. Wilson (Eds.), ECAI’2004,Workshop 22: Local Computation for Logics and Uncertainty, 2004, pp. 53–56.[63] R. Yager, A. Rybalov, Uninorm aggregation operators, Fuzzy Sets Syst. 80 (1996) 111–120.