Artificial Intelligence 214 (2014) 1–25Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPotential-based bounded-cost search and AnytimeNon-Parametric ARoni Stern a,∗Ken Goldberg c, Ariel Felner a, Jur van den Berg b, Rami Puzis a, Rajat Shah c,∗a Information Systems Engineering, Ben Gurion University, Be’er Sheva, Israelb School of Computing, University of Utah, Salt Lake City, UT, USAc University of California, Berkeley, CA, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 1 May 2012Received in revised form 1 May 2014Accepted 3 May 2014Available online 10 May 2014Keywords:Heuristic searchAnytime algorithmsRobotics1. Introduction∗(APTS/ANAThis paper presents two new search algorithms: Potential Search (PTS) and Anytime∗Potential Search/Anytime Non-Parametric A). Both algorithms are based ona new evaluation function that is easy to implement and does not require user-tunedparameters. PTS is designed to solve bounded-cost search problems, which are problems∗where the task is to find as fast as possible a solution under a given cost bound. APTS/ANAis a non-parametric anytime search algorithm discovered independently by two researchgroups via two very different derivations. In this paper, co-authored by researchers fromboth groups, we present these derivations: as a sequence of calls to PTS and as a non-parametric greedy variant of Anytime Repairing AWe describe experiments that evaluate the new algorithms in the 15-puzzle, KPP-COM,robot motion planning, gridworld navigation, and multiple sequence alignment searchdomains. Our results suggest that when compared with previous anytime algorithms,∗: (1) does not require user-set parameters, (2) finds an initial solution faster,APTS/ANA(3) spends less time between solution improvements, (4) decreases the suboptimalitybound of the current-best solution more gradually, and (5) converges faster to an optimalsolution when reachable.∗.© 2014 Elsevier B.V. All rights reserved.Heuristic search algorithms are widely used to compute minimum-cost paths in graphs. Applications of heuristic searchrange from map navigation software and robot path planning to automated planning and puzzle solving. Different searchalgorithms return solutions of varying quality, which is commonly measured by a cost, where high quality solutions arethose with a low cost. Ideally, one would like to find optimal solutions, i.e., those with minimum cost. Given an admissible[2], return optimal solutions. However, many problems are veryheuristic, some search algorithms, such as Ahard to solve optimally [3] even with such algorithms.[1] or IDA∗∗In this paper we propose two algorithms: Potential Search (PTS) and Anytime Potential Search/Anytime Non-∗). These algorithms are especially suited for cases where an optimal solution is hard to find.Parametric APTS is designed to solve problems where any solution with cost less than C , an input to the problem, is acceptable, whilesolutions with cost ≥ C are useless. We call such problems bounded-cost search problems. Bounded-cost search problems(APTS/ANA∗* Corresponding author.http://dx.doi.org/10.1016/j.artint.2014.05.0020004-3702/© 2014 Elsevier B.V. All rights reserved.2R. Stern et al. / Artificial Intelligence 214 (2014) 1–25∗∗∗arise, for example, when the expense budget for a business trip is limited and the trip (e.g., flights and hotels) shouldbe planned as quickly as possible but within the budget limit. If an online travel agency such as Expedia or Priceline isplanning the trip, computational resources could be diverted to other clients once a plan is found within the budget limits(see Priceline’s “Name Your Own Price” option).∗The second algorithm we present, APTS/ANA, is an anytime search algorithm, i.e., an algorithm “whose quality of resultsimproves gradually as computation time increases” [4]. APTS/ANAcan be viewed as a translation of an anytime searchalgorithm into a sequence of bounded-cost search problems solved by PTS, or as an intelligent approach to avoid theparameter setting problem of Weighted A-based anytime search algorithms. Setting parameters to bounded-suboptimalsearch algorithms is a known problem in the heuristic search literature [5]. A key benefit of APTS/ANAis that it doesnot require users to set parameters, such as the w 0 and (cid:2)w parameters of ARA[6]. Furthermore, experiments suggestthat APTS/ANAimproves upon previous anytime search algorithms in most cases by (1) finding an initial solution faster,(2) spending less time between solution improvements, (3) decreasing the suboptimality bound of the current-best solutionmore gradually, and (4) converging faster to an optimal solution when reachable.are based on a new evaluation function u(n) = C−g(n)h(n)that was discovered independently bytwo research groups via two very different derivations. In this paper, co-authored by researchers from both groups, wepresent both derivations. The first derivation of u(·) is based on a novel concept called the potential of a node. The potentialof a node n is defined with respect to a given value C , and is the probability that a node n is part of a solution of cost lowerthan C . We prove that the node with the highest u(·) is the node with the highest potential, under certain probabilisticrelation between the heuristic function and the cost it estimates.Both PTS and APTS/ANA∗The second derivation of u(·) is based on the desire for a non-parametric version of the Anytime Repairing Aalgo-∗rithm [6]. We show that expanding the node with the highest u(·) has the same effect as setting the parameters of ARAdynamically to improve the best solution found so far as fast as possible. In addition, we show that u(·) bounds the subop-timality of the current solution.∗∗∗We compare PTS and APTS/ANAwith previous anytime algorithms on five representative search domains: the 15-puzzle,robot motion planning, gridworld navigation, Key player problem in communication (KPP-COM), and multiple sequencealignment. As mentioned above, the experimental results suggest that APTS/ANAimproves upon previous anytime searchalgorithms in terms of key metrics that determine the quality of an anytime algorithm. As a bounded-cost algorithm, ourresults suggest that PTS, which is specifically designed for bounded-cost problems, outperforms competing algorithms formost cost bounds and exhibits an overall robust behavior.∗∗This paper extends our preliminary work [7–9] by (1) providing a substantially more rigorous theoretical analysis ofthe presented algorithms, (2) extending the experimental results, (3) adding a comprehensive discussion on the relationbetween bounded-cost search and anytime search, and (4) discussing the limitations of PTS and APTS/ANA∗.The structure of this paper is as follows. First, we provide background and related work. In Section 3, we introducethe bounded-cost search problem and present Potential Search (PTS). In Section 4, we present Anytime Potential Search(APTS) [7,8] and Anytime Non-Parametric A) [9], showing that they are equivalent and discussing their theoreticalproperties. Section 5 presents experimental results comparing PTS and APTS/ANAwith previous algorithms. Finally, wediscuss a generalization of PTS (Section 6) and conclude with suggestions for future work (Section 7).(ANA∗∗∗2. Background and related workSearch algorithms find a solution by starting at the initial state and traversing the problem space graph until a goal stateis found. Various search algorithms differ by the order in which they decide to traverse the problem space graph. Traversingthe problem space graph involves generating and expanding its nodes. The term generating a node refers to creating a datastructure that represents it, while expanding a node means generating all its children.One of the most widely used search frameworks is best–first search (BFS) [10]. BFS keeps two lists of nodes: an openlist (denoted hereafter as OPEN), which contains all the generated nodes that have not been expanded yet, and a closed list(denoted hereafter as CLOSED), which contains all the nodes that have been previously expanded. Every generated node inOPEN is assigned a value by an evaluation function. The value assigned to a node is called the cost of the node. In everyiteration of BFS, the node in OPEN with the lowest cost is chosen to be expanded. This lowest-cost node is moved fromOPEN to CLOSED, and the children of this node are inserted to OPEN. The purpose of CLOSED is to avoid inserting nodes thathave already been expanded into OPEN. CLOSED is also used to help reconstruct the solution after a goal is found. Once agoal node is chosen for expansion, i.e., it is the lowest-cost node in OPEN, BFS halts and that goal is returned.1 Alternatively,BFS can be defined such that every node is assigned a value, and in every iteration the node with the highest value isexpanded.BFS is a general framework, and many well-known algorithms are special cases of it. For example, Dijkstra’s single-sourceshortest-path algorithm [12] and the Aalgorithm [1] are both special cases of BFS, differing only in their evaluationfunction.2 Dijkstra’s algorithm is BFS with an evaluation function that is g(n), which is the shortest path found so far from∗1 This is the textbook version of BFS [10]. However, there are variants of BFS where the search is halted earlier (e.g., BFS with lookaheads [11]).2 In this paper we consider Dijkstra’s algorithm in its best–first search variant, which is also known as Uniform Cost Search. It has been shown [13] thatthis variant of Dijkstra is more efficient than the implementation of Dijsktra detailed in the common algorithm textbook [14].R. Stern et al. / Artificial Intelligence 214 (2014) 1–253∗is BFS with an evaluation function that is f (n) = g(n) + h(n), where h(n) is a heuristicthe start of the search to node n. A∗(n) to denote the lowest-cost path fromfunction estimating the cost from state n to a goal node. We use the notation hnode n to a goal. h(n) is said to be admissible if it never overestimates the cost of the lowest-cost path from n to a goal,i.e., if h(n) ≤ his guaranteed to have found a lowest-cost path to a goalwhen a goal node is chosen for expansion. In general, we use the term optimal search algorithms to denote search algorithmsthat guarantee returning an optimal solution. Other known optimal search algorithms include IDA∗(n) for every node n. Using an admissible h(n), A[2] and RBFS [15].∗∗Finding an optimal solution to search problems is often infeasible. Additionally, it is often the case that non-optimalsolutions are good enough. Hence, there are search algorithms that provide a weaker guarantee on the solution they return,with respect to optimal search algorithms. We list below several types of search algorithms that provide such weakerguarantees.2.1. Bounded-suboptimal search algorithmsBounded-suboptimal algorithms guarantee that the solution returned is no more than w times the cost of an optimalsolution, where w > 1 is a predefined parameter. These algorithms are also called w-admissible, and the value of w isreferred to as the “desired suboptimality”. We use the term suboptimality of a solution of cost C to denote the ratio betweenthe cost of an optimal solution and C . Thus, the suboptimality of the solution returned by a w-admissible algorithm isbounded (from above) by the desired suboptimality w.The most well-known bounded-suboptimal search algorithm is probably Weighted Aexpands the node n in OPEN with minimaltrading off running time and solution quality. It is similar to A∗WAsooner a solution is typically found. If h(·) is an admissible heuristic, then WAi.e., the suboptimality of the solutions found by WAalgorithm include A∗(cid:3) [18], Optimistic Search [19] and Explicit Estimation Search [20].∗by(WA, except that it inflates the heuristic by a value w ≥ 1. Thus,f w (n) = g(n) + w · h(n). The higher w, the greedier the search, and theis a bounded-suboptimal search algorithm,is bounded by w. Other examples of a bounded-suboptimal search) [16].3 WAextends A∗∗∗∗∗∗2.2. Any solution algorithmsIn some cases, the solution quality is of no importance. This may be the case in problems that are so hard that obtainingany meaningful bound on the quality of the solution is not possible. We call algorithms for such settings any solutionalgorithms. Such algorithms usually find a solution faster than algorithms of the first two classes, but possibly with lowerquality. Examples of any solution algorithms include pure heuristic search (a BFS using h(·) as its evaluation function),4 beamsearch variants [21], as well as many variants of local search algorithms such as Hill climbing and Simulated annealing [10].2.3. Anytime search algorithmsAnother class of search algorithms that lies in the range between any solution algorithms and optimal algorithms isanytime algorithms. An anytime search algorithm starts, conceptually, as an any solution algorithm.5 After the first solutionis found, it continues to run, finding solutions of better quality (with or without guarantee on their suboptimality). Anytimealgorithms are commonly used in many domains, since they provide a natural continuum between any solution algorithms[6] that are introduced below, areand optimal solution algorithms. Some anytime algorithms, such as AWAguaranteed to converge to finding an optimal solution if enough time is given.∗[22] and ARA∗Many existing anytime search algorithms are loosely based on WA. Since this paper addresses anytime search algorithms∗-based anytime search algorithms. A commonly used anytime al-in depth, we next provide a brief survey of existing WAgorithm that is not related to WAis Depth-first branch and bound (DFBnB) [23]. DFBnB runs a depth-first search, pruningnodes that have a cost higher than the incumbent solution (= best solution found so far). DFBnB does not require any pa-rameters. However, DFBnB is highly ineffective in domains with many cycles and large search depth.6∗∗2.4. WA∗-based anytime search algorithms∗Anytime Weighted A∗(AWA) [22] is an anytime version of WAwith a given value of w until it finds the∗first solution. Then, it continues the search with the same w. Throughout, AWAexpands a node in OPEN with minimalf w (n) = g(n) + w · h(n), where w is a parameter of the algorithm. Each time a goal node is extracted from OPEN, animproved solution may have been found. Let G denote the cost of the incumbent solution. If h(·) is admissible, then thesuboptimality of the incumbent solution can be bounded by G/ minn∈OPEN{g(n) + h(n)}, as G is an upper bound of thecost of an optimal solution, and minn∈OPEN{g(n) + h(n)} is a lower bound of the cost of an optimal solution. Given enough. It runs WA∗∗∗3 The proof for the w-admissibility of WA∗is given in the Appendix of a later paper [17]. That paper proposed a variation on WA(dynamic weighting)but the same proof holds for plain WA∗.4 Pure heuristic search is sometimes called Greedy best–first search in the literature.5 One can use virtually any search algorithm to find an initial solution in an anytime algorithm.6 Large solution depth can be partially remedied by applying an iterative deepening framework on top of DFBnB.4R. Stern et al. / Artificial Intelligence 214 (2014) 1–25∗runtime, AWAoptimal solution.will eventually expand all the nodes with g(n) + h(n) larger than the incumbent solution, and return an∗∗Anytime Repairing A∗(ARARestarting Weighted A) [6] is also based on WA. First, it finds a solution for a given initial value of w. It thencontinues the search with progressively smaller values of w to improve the solution and reduce its suboptimality bound.The value of w is decreased by a fixed amount each time an improved solution is found or the current-best solutionis proven to be w-suboptimal. Every time a new value is determined for w, the f w (n)-value of each node n ∈ OPEN isupdated to account for the new value of w and OPEN is re-sorted accordingly. The initial value of w and the amount bywhich it is decreased in each iteration (denoted as (cid:2)w) are parameters of the algorithm.∗) [24] is similar to ARA, but each time w is decreased it restarts the search from the rootnode. That is, every new search is started with only the initial node in OPEN. It takes advantage of the effort of previoussearches by putting the nodes explored in previous iterations on a SEEN list. Each time the search generates a seen node,it puts that node in OPEN with the best g-value known for it. Restarting has proven to be effective (in comparison tocontinuing the search without restarting) in situations where the quality of the heuristic varies substantially across thesearch space. As with ARA, the initial values of w and (cid:2)w are parameters of the algorithm.Anytime Window A∗“breadth” of a regular AFor a comprehensive survey and empirical comparison of anytime search algorithms, see [27]., but rather limit thesearch. Iteratively increasing this breadth provides the anytime characteristic of these algorithms.∗) [25], Beam-Stack Search (BSS) [26], and BULB[21] are not based on WA∗(RWA(AWinA∗∗∗∗-based anytime search algorithms require users to set parameters, for example the w factor used toMost existing WA[6], for instance, has two parameters: the initial value of w and the amount by which w isinflate the heuristic. ARAdecreased in each iteration. Setting these parameters requires trial-and-error and domain expertise [25]. One of the contri-butions of this paper is a non-parametric anytime search algorithm that is based on solving a sequence of bounded-costsearch problems (Section 4).∗∗3. Bounded-cost search and potential searchIn this section we define the bounded-cost search problem, where the task is to find, as quickly as possible, a solutionwith a cost that is lower than a given cost bound. We then explain why existing search algorithms, such as optimal searchalgorithms and bounded-suboptimal search algorithms, are not suited to solve bounded-cost search problems. Finally, weintroduce a new algorithm called Potential Search (PTS), specifically designed for solving bounded-cost search problems. Wedefine a bounded-cost search problem as follows.Definition 1 (Bounded-cost search problem). Given an initial state s, a goal test function, and a constant C , a bounded-costsearch problem is the problem of finding a path from s to a goal state with cost less than C .3.1. Applications of bounded-cost searchIn Section 4 we show that solving bounded-cost search problems can be a part of an efficient and non-parametricanytime search. While constructing efficient anytime algorithms is a noteworthy achievement, solving bounded-cost searchproblems is important in its own right and has many practical applications.Generally, when a search algorithm is part of a larger system, it is reasonable to define for the search algorithm whatan acceptable solution is in terms of cost. Once such a solution is found, system resources can be diverted to other tasksinstead of optimizing other search-related criteria.For example, consider an application server for an online travel agency such as Expedia, where a customer requests aflight to a specific destination within a given budget. In fact, Priceline allows precisely this option when booking a hotel(the “Name Your Own Price” option). This can be naturally modeled as a bounded-cost problem, where the cost is the priceof the flight/hotel.Furthermore, recent work has proposed to solve conformant probabilistic planning (CPP) problems by compiling theminto a bounded-cost problem [28]. In CPP, the identity of the start state is uncertain. A set of possible start states is given,and the goal is to find a plan such that the goal will be reached with probability higher than 1 − (cid:3), where (cid:3) is a parameterof the search. We refer the reader to Taig and Brafman’s paper [28] for details about how they compiled a CPP problem toa bounded-cost search problem.A more elaborate application of bounded-cost search exists in the task of recognizing textual entailment (RTE). RTE isthe problem of checking whether one text, referred to as the “text”, logically entails another, referred to as the “hypothesis”.For example, the text “Apple acquired Anobit” entails the hypothesis that “Anobit was bought”. Recent work modeled RTEas a search problem, where a sequence of text transformation operators, referred to as a “proof”, is used to transform thetext into the hypothesis [29,30]. Each proof is associated with a cost representing the confidence that the proof preservesthe semantic meaning of the text. Stern et al. [29] used Machine Learning to learn a cost threshold for RTE proofs such thatonly proofs with cost lower than this threshold are valid. Thus, solving an RTE problem (i.e., determining whether a giventext entails a given hypothesis) becomes a bounded-cost problem of finding a proof under the learned cost threshold.A bounded-cost search problem can be viewed as a constraint satisfaction problem (CSP), where the desired cost boundis simply a constraint on the solution cost. However, modeling a search problem as a CSP is non-trivial if one does not knowR. Stern et al. / Artificial Intelligence 214 (2014) 1–255the depth of the goal in the search tree.7 Furthermore, many search problems have powerful domain-specific heuristics, andit is not clear if general CSP solvers can use such heuristics. The bounded-cost search algorithm presented in Section 3.3 canuse any given heuristic.Finally, most state-of-the-art CSP solvers use variants of depth-first search. Such algorithms are known to be highly inef-ficient in problems like pathfinding, where there are usually many cycles in the state space. Nonetheless, the potential-basedapproach described in Section 3.3 is somewhat reminiscent of CSP solvers that are based on solution counting and solutiondensity, where assignments estimated to allow the maximal number of solutions are preferred [31].Another topic related to the bounded-cost setting is resource-constrained planning [32,33], where resources are limitedand may be consumed by actions. The task is to find a lowest cost feasible plan, where a feasible plan is one where resourcesare available for all the actions in it. One may view bounded-cost search as a resource-constrained problem with a singleresource – the plan cost. However, in bounded-cost search we do not want to minimize the cost of the plan. Any planunder the cost bound is acceptable. Once such a plan is found, it is wasteful to invest CPU time in improving the cost, andcomputation resources can be diverted elsewhere.3.2. Naïve approaches to bounded-cost searchIt is possible to solve a bounded-cost search problem by running an optimal search algorithm. If the optimal solution costis less than C , return it; otherwise return failure, as no solution of cost less than C exists. One could even use C for pruningpurposes, and prune any node n with f (n) ≥ C . However, this technique for solving the bounded-cost search problem mightbe very inefficient as finding a solution with cost less than C can be much easier than finding an optimal solution.One might be tempted to run any of the bounded-suboptimal search algorithms. However, it is not clear how to tune anyand its variants), as the cost of an optimal solutionof the suboptimal algorithms (for example, which weight to use in WAis not known and therefore the ratio between the cost of the desired solution C and the optimal cost is also unknown.∗A possible direction for solving a bounded-cost search problem is to run any suboptimal best–first search algorithm,e.g., pure heuristic search, and prune node with g + h ≥ C . Once a solution is found, it is guaranteed to have a cost lowerthan C . In fact, using this approach with pure heuristic search was shown to be effective in domain independent planningproblems with non-unit edge costs [34]. The main problem with all these ad-hoc bounded-cost algorithms is, however, thatthe desired goal cost bound is not used to guide the search, i.e., C is not considered when choosing which node to expandnext.Having defined the notion of bounded-cost search and its relation to existing search settings and algorithms, we nextintroduce the PTS algorithm, which is specifically designed to solve such problems.3.3. The Potential Search algorithm (PTS)The Potential Search algorithm (PTS) is specifically designed to focus on solutions with cost less than C , and the firstsolution it finds meets this requirement. PTS is basically a best–first search algorithm that expands the node from OPENwith the largest u(·), where u(·) is defined as follows8:u(n) = C − g(n)h(n)Choosing the node with the highest u(·) can be intuitively understood as selecting the node that is most likely to lead toa solution of cost less than C , as u(n) is a ratio of the “budget” that is left to find a solution under C (this is C − g(n)) andthe estimate of the cost between n and the goal (this is h(n)). In Sections 3.4 and 4.3 we discuss two analytical derivationsof the u(·) evaluation function.(cid:6)The complete pseudo-code of PTS is provided in Algorithm 1. The input to PTS, and in general to any bounded-costsearch algorithm, is the initial state s from which the search begins, and the cost bound C . In every iteration, the nodewith the highest u(·), denoted as n, is expanded from OPEN (line 3). For every generated node n, duplicate detection is(cid:6))if it exists in OPEN or CLOSED with smaller or equal g value (line 7). Otherwise, the value of g(nperformed, ignoring n(cid:6)) ≥ Cis updated (line 9). If the heuristic function h(·) is admissible, then PTS prunes any node n(line 12). This is because these nodes can never contribute to a solution of cost smaller than C . If h(·) is not admissible,(cid:6)) ≥ C . Any bounded-cost search should perform this pruning, and indeed in our experimentsthen nwe implemented this for all of the competing algorithms. If nis not pruned and it is a goal, the search halts. Otherwise,nis inserted into OPEN and the search continues.is pruned only if g(nfor which g(n(cid:6)) + h(n(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)3.4. The potentialPTS is based on the novel u(·) evaluation function. Next, we provide the first analytical derivation of u(n), relating it tothe probability that n leads to a goal of cost smaller than C . We call this probability the potential of a node.7 Note that even if the cost bound is C , the search tree might be much deeper if there are edges of cost smaller than one (e.g., zero cost edges).8 For cases where h(n) = 0, we define u(n) to be ∞, causing such nodes to be expanded first.6R. Stern et al. / Artificial Intelligence 214 (2014) 1–25Algorithm 1: Potential search.Input: C , the cost boundInput: s, the initial staten ← argmaxn∈OPEN u(n) // pop the node with the highest u(n)foreach successor nof n do(cid:6)// Duplicate detection and updating g(nif n(cid:6))(cid:6)) thenis in OPEN or CLOSED and g(nContinue to the next successor of n (i.e., go to line 4)(cid:6)) ≤ g(n) + c(n, n(cid:6)) ← g(n) + c(n, nend(cid:6))g(n// Prune nodes over the boundif g(n(cid:6)) + h(n(cid:6)) ≥ C (if h is inadmissible, check instead if g(nContinue to the next successor of n (i.e., go to line 4)(cid:6)) ≥ C ) thenend// If found a solution below the bound - return itif n(cid:6)is a goal node thenreturn the best path to the goal(cid:6)1 OPEN ← s2 while OPEN is not empty do34567891011121314151617181920212223end// Add nif nInsert nelseend(cid:6)(cid:6)to OPEN(cid:6) to OPEN or update its locationis in OPEN thenUpdate the key of n(cid:6)in OPEN using the new g(n(cid:6))24end25 end26 return None // no solution exists that is under the cost bound CFig. 1. An example of an expansion dilemma.To motivate the concept of the potential of a node, consider the graph presented in Fig. 1. Assume that we are searchingfor a path from s to g. After expanding s, the search algorithm needs to decide which node to expand next: node aor node b. If the task is to find an optimal path from s to g, then clearly b should be expanded first, since there maybe a path from s to g that passes through b whose cost is lower than the cost of the path that passes through a (asf (b) = g(b) + h(b) = 100 < f (a) = g(a) + h(a) = 103).If, however, the task is to find a path of cost less than 120 (C = 120), then expanding b is not necessarily the bestoption. For example, it might be better to expand a, which is probably very close to a goal of cost less than 120 (ash(a) = 3). Informally, we may say that a has more potential to lead to a solution of cost lower than C than b. Next, wedefine the notion of potential, and show its relation to u(·).The potential of a node n is defined as the probability that a node with h value equal to h(n) has a path to a goal with acost smaller than C − g(n). For clarity, we omit here the mathematical prerequisites for defining probabilities in this contextand provide them later (see Definition 4).Definition 2 (Potential). Given a heuristic function h and a cost bound C , we define thepotential of node n, denoted P T h,C (n),as(cid:2)PTh,C (n) = Prg(n) + h∗(n) < C(cid:3)(cid:4)(cid:3) h(n)∗(·)). In some domains, the relation between h and hClearly, the potential of a node depends on the relation between the heuristic function that is used (h(·)) and the valueit estimates (his a known property of h (e.g., a precision parameterof a sensor). In other domains, it is possible to evaluate how close h is to husing attributes of the domain. In general, one∗(n) if h(n) is small. For example, consider a shortest path problem in a map, using thewould expect h(n) to be closer to hair distance as a heuristic. If the air distance between two nodes is very large, it is more likely that obstacles exist betweenthem. More obstacles imply a greater difference between the air distance and the real shortest path.∗∗R. Stern et al. / Artificial Intelligence 214 (2014) 1–257Fig. 2. MD heuristic vs. true distance for the 15-puzzle domain.Consider the case where for a node n there is a linear stochastic relation between h(n) and h∗(n) = h(n) · Xn,where Xn ∼ X is a random variable drawn from a probability distribution X . We assume that the distribution X may beunknown, but that all Xn (for every node n) are independent and identically distributed (i.i.d.) according to X . We denoteas the linear-relative assumption.9 Assuming the linear-relativethese assumptions about the relation between h and hassumption, the potential of a node n is given by:∗(n), i.e., h∗(cid:2)Pr∗g(n) + h(cid:2)= Pr(n) < C(cid:3)(cid:4)(cid:3) h(n)(cid:2)= Pr(cid:4)Xn · h(n) < C − g(n)= Prg(n) + h(n) · Xn < C(cid:6)(cid:5)Xn <C − g(n)h(n)(cid:4)(cid:2)= Pr(cid:4)Xn < u(n)If we do not know the distribution X that Xn is drawn from, the potential of a node cannot be explicitly calculated.However, given any two nodes n1 and n2, we can determine which node has a higher potential by comparing their u(·)values. This is true because Xn1 and Xn2 are i.i.d. ( Xn1 , Xn2∼ X ), and therefore:u(n1) ≥ u(n2) ⇔ Pr(cid:2)(cid:4)Xn1 < u(n1)(cid:2)≥ Pr(cid:4)Xn2 < u(n2)This idea is summarized in Lemma 1 below.Lemma 1. Under the linear-relative assumption, for any pair of nodes n1 and n2, we have that u(n1) ≥ u(n2) iff n1’s potential is greaterthan or equal to n2’s potential.Consequently, for any problem where the linear-relative assumption holds, a BFS that expands the node with the highestu(·) in OPEN (≡ PTS) will expand nodes exactly according to their potential. This result is summarized in Theorem 1:Theorem 1. Under the linear-relative assumption, PTS always expands the node with the highest potential.It might be hard to find a domain where the linear-relative assumption holds exactly. However, this assumption holds ap-proximately for many domains. For example, consider the 15-puzzle, a well-known search benchmark. We solved optimallyeach of the 1000 standard random instances [36]. For each of these instances we considered all the states on the optimalpath, to a total of 52 523 states. Each of these states was assigned a 2-dimensional point, where the x value denotes theManhattan Distance (MD) heuristic of the state and the y value denotes its optimal cost to the goal. The plot of these pointsis presented in Fig. 2. The dashed line indicates the best linear fit for the plot, which is the line y = 1.31 · x − 2.19. It is easyto observe that a linear fit is very close, suggesting that the linear-relative assumption approximately holds in this domain.Appendix A shows two other domains where this also occurs. In Section 6 we generalize PTS to handle cases where thelinear-relative assumption does not hold.9 This model is reminiscent of the constant relative error [35], where h∗(n) ≤ T · h(n) for some constant T .8R. Stern et al. / Artificial Intelligence 214 (2014) 1–253.5. Limitations of PTSLater in this paper (Section 5) we provide experimental results on five domains showing that PTS is effective and robustin practice. However, we would also like to point out two limitations of PTS.3.5.1. Memory requirementsPTS is a best–first search, storing all the nodes visited during the search in OPEN and CLOSED. Thus, the memory requiredfor PTS to solve a problem is, in the worst case, exponential in the depth of the search. This prevents running PTS to solveproblems in large domains such as the 24-puzzle for close to optimal cost bounds. One might consider running an iterative[2]) with the potential utility function u(·). This would be problematic as u(·) is a non-integerdeepening scheme (like IDAnumber and thus setting the thresholds of the iterative deepening procedure would be non-trivial (although there aremethods to cope with that [37,38]).∗3.5.2. Distance vs. cost heuristicsIn some domains, the cost of reaching the goal and the distance (number of steps) to reach the goal are not corre-lated [39]. Effective search algorithms for such domains employ two types of heuristics – one that estimates the cost ofreaching a goal, denoted by h(·), and one that estimates the number of steps required to reach a goal, denoted by d(·) [20].The PTS evaluation function u(·) considers only h(·). Thus PTS may be less effective in domains where d(·) and h(·) are verydifferent. Work on combining h(·) and d(·) for bounded-cost search showed promising results [40].Resolving these two problems is beyond the scope of this paper and remains as a challenge for future work. Next, wedescribe APTS/ANA, which is a non-parametric anytime search algorithm using the PTS evaluation function u(·).∗∗4. Anytime Non-Parametric Aand Anytime Potential SearchIn this section we present a framework for constructing a non-parametric anytime search algorithm by solving a sequenceof bounded-cost search problems. As an instance of this framework, we present Anytime Potential Search (APTS), which usesPTS to solve these bounded-cost search problems. Then, in Section 4.3 we present a different analytical derivation of APTSas a non-parametric modification of the ARAanytime search algorithm. The result of this derivation is known as Anytime∗Non-Parametric Ato reflect its dual origin.(ANAand APTS are the same algorithm, which we call APTS/ANA) [9]. ANA∗∗∗∗4.1. Rationale for a non-parametric anytime search algorithmIn general, the need for non-parametric algorithms is prevalent in many fields of computer science and AI [41–43, interalia]. The main reason is that algorithms with parameters require some method of selecting the values for this parameter,i.e., a method for parameter tuning. Parameter tuning are often:• Time consuming. Parameter tuning are commonly done by running the parametric algorithm several times on a rangeof instances and parameter values.• Crucial for a successful implementation. Different parameter values can have great impact on the performance ofparametric algorithms. This is known to occur in parametric search algorithms [5] and we observe this as well in ourexperimental results (given later in the paper).As a result, non-parametric algorithms are more accessible to practitioners. Thus, the need for a non-parametric anytimesearch algorithm is great.4.2. A greedy non-parametric anytime searchAlgorithm 2 presents a high-level view of an anytime search algorithm. It consists of iteratively calling the Improve-Solution procedure (line 4), which searches for a solution that is better than the incumbent solution (named “Incumbent”in Algorithm 2), whose cost is denoted by cost(Incumbent) and maintained in the variable G. Initially, there is no incumbentsolution, so G is set to ∞ (line 1). When there is no solution better than G, then G is proven to be the optimal solutioncost and the search can halt (line 9).10 Alternatively, the search may be halted earlier, in which case Incumbent is returned(line 12).Different anytime algorithms vary by the implementation of the ImproveSolution procedure (line 4). For example, onecan apply a depth first search for ImproveSolution. If every call to ImproveSolution resumes the same depth-first search,∗then this is identical to DFBnB. Many efficient anytime search algorithms, such as AWA[24],[22], ARAimplement ImproveSolution as different variants of WA-based anytime search algorithms require one or moreparameters to set the w for WA’s f w evaluation function. Tuning these parameters is often non-trivial.∗[6] and RWA. These WA∗∗∗∗10 Some anytime search algorithms cannot guarantee that no better solution is found. We do not discuss such algorithms in this paper.R. Stern et al. / Artificial Intelligence 214 (2014) 1–259Algorithm 2: General anytime search algorithm.1 G ← ∞2 Incumbent← ∅3 while search not halted do4567NewSolution←ImproveSolution // Seek a solution of cost < Gif NewSolution was found thenG ← cost(NewSolution)Incumbent← NewSolution8910elseendReturn Incumbent (which is optimal)11 end12 return IncumbentIt is sometimes possible to intelligently customize the parameters of an anytime search algorithm. For example, if onedoes know beforehand exactly when the search will be halted, it is possible to employ Deadline-Aware Search [44], whichestimates during the search which paths to the goal will be achievable before the search is halted. Another example iswhen there exists a known utility tradeoff between computation time and solution quality. In this case, it is possible to useBest–First Utility-Guided Search [45], which tries to optimize this tradeoff.In this paper we do not assume any prior knowledge on the termination time of the search, nor do we assume a givenutility function that trades off computation for solution quality. In the absence of these, we propose the following greedyapproach to anytime search. In every call to ImproveSolution, try to find a solution with cost lower than G as fast aspossible. It is easy to see that every such call to ImproveSolution is exactly a bounded-cost search problem, where thecost-bound C is set to be the cost of the incumbent solution (G). Thus, we can use PTS in every call to ImproveSolution(line 4) with cost bound G. The resulting anytime search algorithm does not require parameter tuning (e.g., of w) andis shown empirically to be superior to other anytime search algorithms on a wide range of domains (see Section 5). Thisanytime search algorithm, which uses PTS for its Improve Solution part, is called Anytime Potential Search (APTS). As statedabove, we refer to it as APTS/ANAto emphasize its second derivation, described later in Section 4.3.∗Because initially there is no incumbent solution, the purpose of the first iteration of APTS/ANAfast as possible, without any bound on its cost. Thus, C = ∞ and as a result the PTS evaluation function u(n) = C−g(n)h(n)also equal to ∞ for all the nodes in OPEN, making them indistinguishable.However, as C approaches infinity, the node in OPEN with the highest u(n) = C−g(n)h(n)is actually the node with the lowesth(n). Thus, as C approaches infinity, PTS converges to pure heuristic search. Therefore, we define the first ImproveSolutioncall of APTS/ANAto run pure heuristic search until the first solution is found.11is to find a solution asis∗∗4.2.1. Reusing information between PTS callsThere are several known approaches for using knowledge from previous calls to ImproveSolution. In some cases it isbest to ignore it completely [24] and restart the search from the initial state. In other cases, a more sophisticated mechanismalgorithm its name). For a comprehensive surveycalled repairing is preferred [6] (this is what gave the Anytime Repairing Aand empirical evaluation of the different ways to consider knowledge from previous calls to ImproveSolution, see [27].No approach has dominated the others in all domains. For simplicity, we chose to implement all anytime algorithms in thispaper such that OPEN is passed between calls to ImproveSolution. However, modifying APTS/ANAto use any of the otherapproaches is trivial.∗∗Consequently, when PTS is called with a new cost bound (which is the cost of the solution found by the previous call toPTS), it does not start from the initial node. Instead, PTS will expand nodes from OPEN of the previous PTS call. However,this incurs an overhead, as all the nodes in OPEN need to be reordered according to u(·), as the cost of the incumbentsolution has changed., as a non-parametric improvement of the ARAanytime search algo-∗Next, we give a different derivation of APTS/ANArithm.∗4.3. APTS/ANAas an improved Anytime Repairing A∗∗∗ARA[6] is a well-known anytime search algorithm shown to be effective in many domains [27]. For completeness,is a special case of the high-level anytimea simplified version of the ARA∗-ImproveSolution,algorithm described in Algorithm 2. It repeatedly calls its version of ImproveSolution, called here ARAwhich aims to find a solution that is w-suboptimal. Initially, w = w 0, and it is decreased by a fixed amount (cid:2)w after everycall to ARA∗algorithm is listed in Algorithms 3 and 4. ARA∗-ImproveSolution (line 11 in Algorithm 3).∗11 An alternative approach is to use the function uincreasing C to infinity results in an elegant convergence to pure heuristic search.(cid:6)(n) = 1 − h(n)C−g(n)instead of u(n). It is easy to see it achieves the same node ordering, but there10R. Stern et al. / Artificial Intelligence 214 (2014) 1–25Algorithm 3: Simplified anytime repairing A∗(ARA∗).Input: s, the initial stateInput: w 0, the initial wInput: (cid:2)w, the amount by which w is decreased in every iteration1 G ← ∞; w ← w 0; OPEN ← ∅; Incumbent← ∅2 Insert s into OPEN3 while OPEN is not empty do4567NewSolution ← ARAif NewSolution is not None thenG ← cost(NewSolution)Incumbent← NewSolution∗-ImproveSolution(OPEN, w, G)89101112elsereturn Incumbentendw ← w − (cid:2)wUpdate keys in OPEN and prune nodes with g(·) + h(·) ≥ G13 end14 return IncumbentAlgorithm 4: ARA∗-ImproveSolution.Input: OPEN, the open listInput: w, the weight of hInput: G, the cost of the incumbent solutionn ← argminn∈OPEN f w (n) // pop the node with the lowest g + whif G ≤ f w (n) thenreturn None // G is proven to be w-admissibleendforeach successor n1 while OPEN is not empty do234567891011(cid:6)(cid:6) /∈ OPEN or g(n) + c(n, n(cid:6))(cid:6)) ← g(n) + c(n, ng(nif g(nif nInsert n(cid:6)) + h(nof n doif n(cid:6)(cid:6)) < G then(cid:6)) < g(n(cid:6)) thenis a goal then return the best path to the goal;(cid:6) ∈ OPEN)to OPEN (or update its position if n(cid:6)121314endendend15 end16 return None // no solution better than G existsARA∗-ImproveSolution,∗, expanding the node n ∈ OPEN with minimalis a variant of WAf w (n) = g(n) + w · h(n). It terminates either when an improved solution is found (line 10 in Algorithm 4), or whenG ≤ minn∈OPEN{ f w (n)} (line 4 in Algorithm 4), in which case the incumbent solution is proven to be w-suboptimal [6].∗An open challenge that we address next is how to set the value of ARA’s parameters (w 0 and (cid:2)w) intelligently.listed in Algorithm 4,A property of a good anytime algorithm is that it finds an initial solution as soon as possible, so that a solution can bereturned even if little time is available. In general, the higher w is, the greedier the search is and the sooner a solutionwill be found. Therefore, ideally, w 0 would be set to ∞. However, setting w 0 = ∞ is not possible in ARA, as w is laterdecreased with finite steps (line 11 in Algorithm 3). For that reason, in ARAw is initialized with a finite value w 0.∗∗A second desirable property of an anytime algorithm is to reduce the time spent between improvements of the solu-tion, such that when the incumbent solution is requested, the least amount of time has been spent in vain. The amount(cid:2)w by which w is decreased should therefore be as small as possible (this is also argued in [6]). However, if w is de-∗-ImproveSolution might not expand a single node. This is becausecreased by too little, the subsequent iteration of ARA∗-ImproveSolution returns when minn∈OPEN{ f w (n)} > G (line 4 in Algorithm 4). If w is hardly decreased in the nextARAiteration, it might still be the case that minn∈OPEN{ f w (n)} > G.So, what is the maximal value of w for which at least one node can be expanded? That is whenw = maxn∈OPEN(cid:7)(cid:8)G − g(n)h(n)(cid:9)(cid:10)u(n)= maxn∈OPEN(1)which follows from the fact thatf w (n) ≤ G ⇐⇒ g(n) + w · h(n) ≤ G ⇐⇒ w ≤ G − g(n)h(n)= u(n)The one node that can then be expanded is indeed the node n ∈ OPEN with a maximal value of u(n). This is precisely thenode that APTS/ANAexpands.∗R. Stern et al. / Artificial Intelligence 214 (2014) 1–2511∗∗One could imagine an adapted version of ARAthat uses Eq. (1) to set w after each iteration of ARAis not maximally greedy to find an improved solution, as explained next. Assume that ARA∗-ImproveSolution.This would also allow initializing w to ∞ for the first iteration, as is done in APTS/ANA. However, even such a variation∗-ImproveSolution isof ARAcalled with w = maxn∈OPEN{u(n)}, and let ˆw denote this specific value of w. In ARA, the value of w is fixed throughout∗-ImproveSolution call a node n might be generated for whicha call to ARAf ˆw (n) < G. If f ˆw (n) < G, then node n could have been expanded if w was increased even further (up to u(n)). A higher wcorresponds to a greedier search, so instead one could always maximize w such that there is at least one node n ∈ OPEN forwhich f w (n) ≤ G. This is equivalent to what APTS/ANAdoes, by continually expanding the node n ∈ OPEN with a maximalvalue of u(n). Thus, APTS/ANAcan be derived as non-parametric tuning of w, such that the search is as greedy as possible,but still has nodes that can be expanded with f w smaller than G.∗-ImproveSolution. However, during an ARA∗∗∗∗Additionally, every time w is changed in ARA, all the nodes in OPEN must be reordered to account for the new w value(line 12 in Algorithm 3). w is updated not only when a new solution is found, but also when the incumbent solution isproven to be w-suboptimal (line 4 in Algorithm 4). Reordering all the nodes in OPEN takes O (|OPEN|) time, which can bevery large.12 Thus, an additional benefit of APTS/ANAis that OPEN needs to be reordered only when a newover ARAsolution is found.∗∗∗4.4. Suboptimality bounds of APTS/ANA∗Consider the case where h is an admissible heuristic. In this case there is a strong relation between the u-value of theand the suboptimality bound of the incumbent solution: each time a node n is selected for, u(n) bounds the suboptimality of the incumbent solution. We prove this theorem below. We use∗(n) denotes thenode expanded by APTS/ANAexpansion by APTS/ANAto denote the cost of an optimal solution, so GGcost of an optimal path between the start state and n.G∗ is the true suboptimality of the incumbent solution. g∗∗∗Theorem 2. If h(n) is admissible then maxn∈OPEN{u(n)} ≥ Gu(n) is an upper bound on the suboptimality of the current solution.G∗ . In other words, if a node n is selected by APTS/ANA∗for expansion, thenProof. APTS/ANA∗prunes any node n with g(n) + h(n) ≥ G. Thus, for every node n in OPEN it holds that:g(n) + h(n) < G ⇒ 1 <G − g(n)h(n)= u(n)Hence, all the nodes in OPEN have u(n) ≥ 1. Thus, Theorem 2 holds trivially if the current solution is optimal. If an optimal(cid:6) ∈ OPEN that is on an optimal path to a goal and whose g valuesolution has not yet been found, there must be a node nis optimal, i.e., g(nison an optimal path to a goal. As the heuristic is admissible, h(n(cid:6)) (see Lemma 1 in [1]). The minimal cost to move from n(cid:6)(cid:6)). Therefore:to the goal is G(cid:6)), since n(cid:6)) ≤ G(cid:6)) = g∗ − g∗ − g∗(n∗(n∗(n(cid:6)(cid:4)(cid:2)n(cid:6)u(cid:6))= G − g(nh(n(cid:6))∗(n= G − gh(n(cid:6))(cid:6))where the last inequality follows as G > G(cid:9)(cid:10)u(n)(cid:4)(cid:2)n(cid:6)≥ u≥ GG∗(cid:2)maxn∈OPEN∗(n≥ G − g(cid:6))G∗ − g∗(n(cid:6))∗(n∗ ≥ g≥ GG∗(cid:6)) ≥ 0. As a result,∗Theorem 2 provides an interesting view on how APTS/ANAbehaves. The suboptimality bound is given by the maximumvalue of u(·), and APTS/ANAcan be viewed as an informed effort to graduallydecrease the suboptimality bound of the incumbent solution. Of course, the children of the expanded node n may have alarger u(·) value than n, in which case maxn∈OPEN{u(n)} may even increase, resulting in a worse bound than before the nodeexpansion. This can be overcome by maintaining the best (i.e., the lowest) suboptimality bound seen so far.always expands that node. Thus, APTS/ANA∗∗Note that this suboptimality bound is available when running APTS/ANAwith almost no additional overhead. Previousapproaches to provide a suboptimality bound to an anytime search algorithm used f min = minn∈OPEN g(n) + h(n). Given fminthe suboptimality of the incumbent solution is at most. While this bound can be shown to be tighter than the boundprovided by u(·), calculating it required maintaining fmin, which requires an additional priority queue that is ordered byg(n) + h(n), while APTS/ANAuses only a single priority queue.13Gfmin∗∗12 In fact, reordering OPEN requires O (|OPEN|log|OPEN|) in general. However, it might be possible to use bucket sort to achieve an O (|OPEN|) runtime.13 Note that maintaining f min requires more than simply storing the lowest f value seen in the search, since f min increases during the search when thenode with f value of f min is expanded. This requires going over OPEN to find the node with the minimalf value, or maintaining an additional priorityqueue as mentioned above.12R. Stern et al. / Artificial Intelligence 214 (2014) 1–25159481213261014371115148125913261014371115Fig. 3. The 15-puzzle goal state (left) and a state two moves from the goal (right).∗∗improves on ARAin five ways: (1) APTS/ANAis maximally greedy to find an initial solution; (3) APTS/ANAdoes not require parameters to be set;is maximally greedy to improve the in-only needs to update the keys of the nodes in OPEN when an improved solution is found;∗∗∗makes an informed effort to gradually decrease the suboptimality bound.In summary, APTS/ANA∗(2) APTS/ANAcumbent solution; (4) APTS/ANAand (5) APTS/ANA∗4.5. Limitations of APTS/ANA∗While APTS/ANA∗has all the attractive properties listed above, it also has some limitations. Since APTS/ANA∗. In addition, APTS/ANA∗runs a∗sequence of PTS calls, all the limitations described for PTS in Section 3.5 apply also to APTS/ANAhas two further limitations:4.5.1. Finding the initial solutionIf the heuristic is inaccurate and there are not many goals, finding even a single, unbounded solution can be hard.∗would beAs defined above, until the first solution is found, APTS/ANAinefficient in domains where pure heuristic search is inefficient. For example, in domains where there is a distance-to-goheuristic (d(n)), a much more effective way to find a solution fast is to search according to d(n) rather than h(n) [46,39].runs a pure heuristic search. Thus, APTS/ANA∗4.5.2. Finding too many solutions∗Every time a better solution is found, APTS/ANAis required to re-sort all the nodes in OPEN (Algorithm 2) to accountfor the new incumbent solution (the u(·) values change). Thus, if there are many solutions, each slightly better than theprevious, then APTS/ANAwould suffer from the overhead of re-sorting OPEN every time a new, better, solution is found.∗There are ad hoc solutions to these limitations. Instead of using APTS/ANAto find the first solution, it is possible to useanother algorithm (e.g., Speedy search [46]) to find the first solution and provide it to APTS/ANAas an initial incumbentsolution. Additionally, the bound of the next PTS can be set to be lower than the incumbent solution by some (cid:2), to avoidfinding too many solutions. Such a (cid:2), however, would be a parameter of the algorithm and setting it raises the parametertuning problem we aim to avoid.∗∗5. Experimental resultsasIn this section we empirically evaluate the performance of PTS as a bounded-cost search algorithm, and APTS/ANAan anytime search algorithm. This is done over a range of domains: 15-puzzle, KPP-COM, robot arm, grid world planningand multiple sequence alignment (MSA). Next, we describe the domains used in our experiments.∗5.1. DomainsFor every domain, we provide the domain details (what is a state etc.), the heuristic function used, and how the probleminstances were generated.5.1.1. The 15-puzzleThe 15-puzzle is a very well-known puzzle that consists of 15 numbered tiles that can be moved in a 4 × 4 grid. There isone blank location in the grid. The blank can be swapped with an adjacent tile. The left part of Fig. 3 shows the goal statethat we used for the 15-puzzle while the right part shows a state created from the goal state by applying two operators,namely swapping the blank with tile 1 and then swapping it with tile 5. The number of states reachable from any givenstate is (42)!/2 [47]. The task is to find a short path from a given starting state to the goal state. The 15-puzzle is a commonsearch benchmark [2,15,36,48,49].There are many advanced heuristics for the 15-puzzle. In the experiments below we chose the simple Manhattan Dis-tance heuristic (MD) because our goal is to compare search algorithms and not different heuristics. The experiments wereperformed on Korf’s standard 100 random 15-puzzle instances [2].5.1.2. Key Player Problem in Communication (KPP-COM)The Key Player Problem in Communication (KPP-COM) is the problem of finding a set of k nodes in a graph with thehighest Group Betweenness Centrality (GBC). GBC is a metric for centrality of a group of nodes [50]. It is a generalizationof the betweenness metric, which measures the centrality of a node with respect to the number of shortest paths that passthrough it [51]. Formally, the betweenness of a node n is Cb(n) =, where σst is the number of shortest(cid:11)s,t∈V s,t(cid:15)=nσst (n)σstR. Stern et al. / Artificial Intelligence 214 (2014) 1–2513Fig. 4. Example of the motion of a 6 DoF (left) and 20 DoF (right) robot arm [6].paths between s and t and σst(n) is the number of shortest paths between s and t that pass through n. The betweennessof a group of nodes A, termed group betweenness, is defined as Cb( A) =, where σst( A) is the number ofshortest paths between s and t that pass through at least one of the nodes in A.σst ( A)σsts,t∈V \ A(cid:11)KPP-COM is known to be NP-Hard [52]. It has important network security applications, such as optimizing the deploy-ment of intrusion detection devices [53]. KPP-COM can be solved as a search problem. Let G = (V , E) be the input graphin which we are searching for a group of k vertices with the highest GBC. A state in the search space consists of a set ofvertices N ⊆ V , |N| ≤ k. N is considered as a candidate to be the group of vertices with the highest GBC. The initial stateof the search is an empty set, and each child of a state corresponds to adding a single vertex to the set of vertices of theparent state. Every state has a value, which is the GBC of the set of vertices it contains. While the goal in the previousdomain (the 15-puzzle) is to find a solution of minimal cost, the goal in KPP-COM is to find a solution with maximum value.We call problems of the former type MAX problems and problems of the latter type MIN problems. An admissible heuristicfor MAX problems is required to be an upper bound on the optimal value. Similarly, a suboptimal solution is one with asmaller value than the optimal solution.A number of efficient admissible (overestimating) heuristics for this problem exist [52] and in our experiments we usedthe best one, calculated as follows. Consider a state consisting of a set of m vertices V m. First, the contribution of everyindividual vertex v ∈ V \ V m is calculated. This is the Cb(V m ∪ {v}) − Cb(V m). Then, the contribution of the topmost k − mvertices is summed and used as an admissible heuristic, where k is the total number of vertices that needs to be selected(see [52] for a more detailed discussion about this heuristic).Since the main motivation for the KPP-COM problem is in communication network domains, all our experiments wereperformed on graphs generated by the Barabási–Albert model [54]. This random graph model is a well-used model ofInternet topology and the web graph, which accepts two parameters: the number of vertices in the graph and a densityfactor. We have experimented with a variety of graph sizes and density factor values, and present the average results over25 graphs with 600 vertices with a density factor of 2. Additionally, we have limited the size of the searched group ofvertices to be 20 (i.e., k = 20).5.1.3. Robot armThe robot arm domain is taken from Maxim Likhachev’s publicly available SBPL library (http://www.sbpl.net). This prob-lem illustrates the performance of the proposed algorithms in a domain with a high branching factor and few duplicatestates.We consider both a 6 degrees of freedom (DoF) arm and a 20 DoF arm with a fixed base in a 2D environment withobstacles, shown in Fig. 4. The objective is to move the end-effector from its initial location to a goal location while avoidingobstacles. An action is defined as a change of the global angle of any particular joint (i.e., the angle with respect to a fixedinitial point) having the next joint further along the arm rotate in the opposite direction to maintain the global angle of theremaining joints. All actions have the same cost.The environment is discretized into a 50 × 50 2D grid. The heuristic is calculated as the shortest distance from thecurrent location of the end-effector to the goal location that avoids obstacles. To avoid having the heuristic overestimatetrue costs, joint angles are discretized so as to never move the end-effector by more than one cell on the 50 × 50 grid ina single action. Note that the size of the state space for this domain is 109 states for the 6 DoF robot arm and more than1026 states for the 20 DoF robot arm.5.1.4. Gridworld planningThe next domain we considered is that of two planar gridworld path-planning problems with different sizes and numbersof obstacles, also taken from Likhachev’s SBPL library. This problem illustrates the performance of the algorithms in a domain14R. Stern et al. / Artificial Intelligence 214 (2014) 1–25Fig. 5. An example of aligning 8 DNA sequences.Table 1Competing algorithms for each domain.Algorithms∗AWA∗ARADFBnBKPP-COM√–√15-Puzzle√––Robot armGridworld–√––√–MSA–√–with many transpositions and a relatively small branching factor. We set the start state as the cell at the top left corner,and the goal state at the bottom right cell. The first gridworld problem is a 100 × 1200 8-connected grid with obstacles,with unit cost to move between adjacent obstacle-free cells. The second gridworld problem is a 5000 × 5000 4-connectedgrid in which each transition between adjacent cells is assigned a random cost between 1 and 1000. For the 5000 × 50004-connected grid problem with non-unit edge cost, we considered two cases, one with obstacles and one without.5.1.5. Multiple sequence alignment (MSA)Our final domain is the MSA problem. The uniqueness of this domain (in comparison to the domains above) is its highbranching factor and non-uniform edge costs (i.e., costs of different edges may vary).MSA is a central problem for computational molecular biology when attempting to measure similarity between a set ofsequences [55]. The input to MSA is a set of sequences of items (e.g., gene or protein sequences). Every sequence is mappedto an array, while possibly leaving empty spaces. This mapping is referred to as an alignment. Fig. 5 shows an example ofan alignment of 8 sequences. Alignments have a cost, according to a biologically motivated interpretation of the alignment.We used the sum-of-pairs cost function, used by many previous works [56,57,55, inter alia]. According to this cost functionthe alignment cost of k sequences is the sum of the alignment costs of allpairs of sequences. The alignment cost ofa pair of sequences x and y considers the number of matches, gaps and substitutions in the alignment. A match occurs whentwo identical items (e.g., the same protein) are mapped to the same array index. A gap occurs when only a single sequenceis using an index. A substitution occurs when different items are mapped to the same index. The alignment cost we usedassigned to every match, gap and substitution a cost of zero, one and two, respectively.k2(cid:4)(cid:2)MSA can be formalized as a shortest-path problem in an n-dimensional lattice, where n is the number of sequences tobe aligned [58]. A state is a (possibly partial) alignment represented by the items aligned so far from each sequence. A goalis reached when all the characters in all the sequences are aligned. A move in the search space assigns a specific index toan item in one or more sequences. The cost of a move is computed as the cost of the partial alignment. The MSA probleminstances we experimented with consist of five dissimilar protein sequences obtained from [59] and [60]. The heuristic isbased on summing the optimal pairwise alignments, which were precomputed by dynamic programming [60].5.2. Bounded-cost experimentsIn this section we empirically evaluate the performance of PTS. In every experiment, the cost bound C was set, and PTSand the competing algorithms were run until a solution with cost lower than C was found. This was repeated for a rangeof cost bounds (i.e., a range of C values). In domains where instances could be solved optimally in reasonable time, wechose the range of C values to cover bounds close to the average optimal solution as well as substantially higher bounds. Indomains where solving instances optimally was not feasible, we chose the cost bounds that were solvable by the comparedalgorithms in reasonable time. The performance of the various algorithms was measured in runtime.We compared PTS against a range of existing anytime search algorithms: AWA[6] and DFBnB [23]. To makethe comparison to PTS fair, we also modified these anytime algorithms to prune every node n with g(n) + h(n) larger thanthe cost bound, as is done for PTS (line 12 in Algorithm 1). Thus, DFBnB can also be viewed as a depth-first search withnode pruning, where nodes with g(n) + h(n) larger than the cost bound are pruned.[22], ARADifferent anytime search algorithms performed differently, and in the rest of this section we only show results of thebest performing anytime search algorithms for every domain. Table 1 lists the best performing algorithms for every do-and DFBnB. The effectiveness of DFBnB in KPP-COM was not surprising, as DFBnB ismain. For KPP-COM, these were AWA∗∗∗R. Stern et al. / Artificial Intelligence 214 (2014) 1–2515Table 2∗15-puzzle bounded-cost results. The % values are the average % of nodes expanded by A. The values in brackets are runtimes in milliseconds.C5560657075808590PTS%36%11%7%5%5%4%4%4AWA∗-1.5∗AWA-2.0AWA∗-2.5∗AWA-3.0(955)(389)(370)(353)(351)(346)(342)(345)%21%12%12%12%12%12%12%12(482)(389)(389)(388)(387)(389)(387)(392)%48%11%7%6%6%6%6%6(751)(418)(362)(354)(357)(355)(357)(360)%86%33%13%6%5%5%5%5(1068)(643)(430)(360)(347)(348)(347)(347)%124%66%67%17%8%4%4%4(1651)(1144)(735)(464)(385)(350)(343)(340)Table 3KPP-COM bounded-cost results. Values are the average runtime in seconds.CPTSDFBnB∗AWA∗AWA∗AWA∗A-0.7-0.8-0.9320 000310 000300 000290 000280 0001194111711381391271372297277357519721850438955656256975815284118408422424580115527293293473364387961750∗known to be effective when the depth of the solution is known in advance (in KPP-COM this is k, the size of the searchedgroup) [61,62]. This was also confirmed in our KPP-COM experiments and in previous work [52]. DFBnB is less effective inandother domains, where the depth of the search tree varies and there are many cycles. The relative performance of AWAin the 15-puzzle (previous workARA∗areshowed this in the 8-puzzle domain [22]), while ARAparametric algorithms. We experimented with a range of parameters and show the results of the best performing parametersettings we found.performed better in all other domains.14 Both ARAvaries between domains. Our experiments showed that AWAoutperformed ARAand AWA∗∗∗∗∗Table 2 displays the results for the 15-puzzle domain. Results in this domain are traditionally shown in terms of nodesexpanded, to avoid comparing implementation details. Therefore, in addition to comparing the runtime of each algorithmwe also measured the number of nodes expanded. The number of nodes expanded is given in Table 2 as the percentage of∗until an optimal solution is found. Runtime is shownnodes expanded with respect to the number of nodes expanded by Ain the same table in brackets, and measured in milliseconds. The best performing algorithm for every cost bound is markedin bold.Results clearly show a drastic reduction in the size of the searched state space (yielding a substantial speedup) overtrying to find an optimal solution. For example, PTS can find a solution under a cost bound of 70 by expanding on averageonly 5% of the nodes that will be expanded by Ato find an optimal solution.In addition, we see that PTS performs best for the vast majority of cost bounds. PTS also performs relatively well evenfor the few cost bounds where it is not the best performing algorithm. We can also see the large impact of the w parameterwith w = 3 performed more than 9 times worse thanon the performance of AWAAWAwith w = 2. This emphasizes the robustness of PTS, which does not require any parameter.. For example, for cost bound 65, AWA∗∗∗∗Due to implementation details, there was not a perfect correlation between the number of nodes expanded by an al-gorithm and its runtime, as part of the runtime is used to allocate memory for the required data structures and otheralgorithm initialization processes. Nonetheless, similar trends as those noted above can also be seen for runtime (these arethe values in brackets in Table 2).Deeper inspection of the results shows that for the lowest cost bound (55), PTS is outperformed by AWAwith w = 1.5.The average cost of an optimal solution for the 15-puzzle instances we experimented with is 52. This suggests that PTS-likemight be less effective for cost bounds that are close to the optimal solution cost. In such cases, a more conservative Ais tuned to find an optimal solution. Wewith w close to one, might be beneficial, as Abehavior, exhibited by AWAobserved a similar trend in some of the other domains we experimented with.∗∗∗∗Next, consider the results for KPP-COM, shown in Table 3. Values are runtime in seconds until a solution below thecost bound C was found. Similar trends are observed in this domain: PTS performs best for most cost bounds and the wparameter greatly influences the performance of AWA∗.The differences in performance of PTS, AWA-0.7 and DFBnB are relatively small in this domain. This is because DFBnB-0.7,is known to be very efficient in this domain [52]. Hence, PTS could not substantially improve over DFBnB. As for AWAbehaves like uniform cost search, a best–first search usingconsider the case where w reaches zero. In such a case, AWAonly g to evaluate nodes. In MAX problems with non-negative edge costs, as is the case for KPP-COM, a uniform cost search∗∗∗14 For some of the results of the other algorithms, see http://goldberg.berkeley.edu/ana/ANA-techReport-v7.pdf.16R. Stern et al. / Artificial Intelligence 214 (2014) 1–25Table 4Robot arm bounded-cost results. Values are the average runtime in seconds.(a) 6 DoF Robot ArmCost bounds(b) 20 DoF Robot ArmCost boundsCPTS∗ARA612764647633695653161671861691431CPTSARA∗801014082842185162188821Table 5Gridworld planning results. Values are the average runtime in seconds.(a) 100 × 1200, unit edge costsCPTS∗ARA10504.8478.010554.5478.0(b) 5000 × 5000, with obstaclesCPTSARA∗44001.5036.2044101.4020.1044301.391.8244500.681.38(c) 5000 × 5000, without obstaclesCPTS∗ARA255015.630129.50026004.8788.95527000.4965.47628000.2654.64929000.0933.38410603.78.144700.591.3830000.0723.167Table 6Multiple sequence alignment results. Values are the average runtime in seconds.CPTS∗ARA1585108.7789.4159069.0736.1159526.4635.316007.4427.416050.7186.916100.10.0behaves like DFBnB. Thus, decreasing w towards zero results in AWAconverging to DFBnB when w = 0. This explains the similar performance of AWA∗-0.7 and DFBnB.behaving more and more like DFBnB, until eventually∗Results for the robot arm, gridworld planning, and multiple sequence alignment domains are shown in Tables 4, 5 and 6,respectively. PTS’s favorable behavior can be viewed across all domains. For example, in the 100 × 1200 gridworld planningdomain, PTS is two orders of magnitude faster than ARAfor a cost bound of 1050. Following all the bounded-cost resultsshown above, we conclude that PTS outperforms the best performing anytime search algorithm for almost all cost boundsand across the entire range of domains we used. Furthermore, PTS exhibits the most robust performance, without anyparameter tuning required.∗5.2.1. The effect of w in MAX problems∗∗The KPP-COM results highlight an interesting question – how does the w parameter affect the performance of AWAin our KPP-COM experiments used w = 0.7, the lowest w wefor MAX problems? The best performing instance of AWAexperimented with. Thus, one might think that decreasing w has an equivalent effect to increasing w in MIN problems.Indeed, decreasing w for w > 1 in MAX problems is similar to increasing w for w < 1 in MIN problems – making anadmissible heuristic more informed and the search more efficient. In the limit, however, decreasing w in MAX problemsand increasing w in MIN problems have completely different effects. As mentioned above, for MAX problems setting w = 0results in AWAbehaving like pure heuristicsearch. Pure heuristic search is expected to find solutions fast but of low quality,15 while uniform cost search ignores theheuristic completely and is therefore expected to be slower than a search that uses a heuristic. Exploring the effect of w inMAX problems is left for future work.behaving like uniform cost search. For MIN problems, w = ∞ results in AWA∗∗5.3. Anytime experimentsNext, we present experimental results to evaluate the performance of APTS/ANAon the same range of domains de-scribed in Section 5.1. In every experiment, we ran APTS/ANAand the best-performing anytime search algorithms (differentfor each domain), and recorded the suboptimality of the incumbent solution as a function of the runtime. In the followingfigures, ARAusing w 0 = X (w 0 is the initial value of w used by ARA∗( X) will denote ARA; see Section 2.3).∗∗∗∗15 This is a general guideline [6], but deeper study of the effect of w in MIN problems is needed [39].R. Stern et al. / Artificial Intelligence 214 (2014) 1–2517Fig. 6. Anytime experiments for the robot arm domain. Time (x-axis) is in seconds.Fig. 7. # instances where each algorithm found the best (lowest cost) solution.∗∗in this domain are very clear. APTS/ANAFirst, consider the results for the 6 DoF robot arm experiments, shown in Fig. 6(a). The y-axis shows the reportedsuboptimality, where 1 corresponds to a solution that is optimal. The x-axis shows the runtime in seconds. The benefits ofdominates all other algorithms throughout the search. Although notAPTS/ANAvisible in the figure, we also report that APTS/ANA∗Next, consider the performance of APTS/ANA∗APTS/ANAof better quality. However, the rapid convergence of APTS/ANAsuboptimality are very clear in this domain, demonstrating the anytime behavior of APTS/ANAin this domain too APTS/ANAin the 20 DoF robot arm experiments, shown in Fig. 6(b). In this domainis able to find solutionstowards an optimal solution and consistent decrease in. As in the 6 DoF experiments,is not always the best performing algorithm. For some weights and time ranges, ARA∗found an initial solution faster than ARAfound an initial solution faster than all other algorithms.∗∗∗∗∗.The above robot arm results are for a single but representative instance. We also experimented on a set of randomlygenerated 6 DoF and 20 DoF robot arm instances (20 instances each) showing, in general, very similar trends. As an aggre-with respect to the other algorithms, we also analyzedgated view showing the relative anytime performance of APTS/ANAwhich was the most effective algorithm throughout the search. This was measured by counting for every algorithm A andevery millisecond t, the number of problem instance where the incumbent solution found by A after running t millisecondsis smaller than or equal to the incumbent solution found by all other algorithms after running t milliseconds. This measuresthe number of instances where algorithm A was the best algorithm if halted after t milliseconds. Fig. 7 shows the resultsof this analysis, where the x-axis is the runtime (in milliseconds) and the y-axis is the number of instances where eachis the best performingalgorithm was best. For both 20 DoF (left) and 6 DoF (right), the results clearly show that APTS/ANAalgorithm throughout the search for the majority of problem instances.∗∗The results for the MSA domain, shown in Fig. 8, show that APTS/ANA(as in the 6 DoF robot arm) dominates all otherhas the largest number of steps inalgorithms throughout the search. For both robot arm and MSA experiments, APTS/ANAits decrease to a lower suboptimality. Correspondingly, the time between solution improvements is smaller. For example, in∗,the MSA experiments, APTS/ANAspent an average of 18 s between solution improvements, while in the best run of ARA∗∗∗18R. Stern et al. / Artificial Intelligence 214 (2014) 1–25Fig. 8. MSA, 5 sequences. Time (x-axis) is in seconds.Fig. 9. 100 × 1200, unit edge cost with obstacles. Time (x-axis) is in seconds.it took 200 s on average to find a better solution. As discussed in Section 4, this is intuitively a desirable property of ananytime algorithm.Next, consider the results for the gridworld domain, given in Figs. 9 and 10. For the 100 × 1200 grid with unit edge cost∗experiments (Fig. 9) and the 5000 × 5000 grid with random edge cost experiments (Fig. 10(a)), APTS/ANAdominates allother algorithms throughout the search. However, the results for the 5000 × 5000 domain with obstacles (Fig. 10(b)) showwith w 0 = 500 returned solutions of lower cost than the solutionsa different behavior: after 30 seconds of runtime, ARAreturned by APTS. While not shown in the figure, we report that APTS/ANArequired an additional 193 s to find a solution∗of the same cost as this ARA∗∗Note that the performance of ARAvaried greatly with the value of w 0 in all the domains we experimented with. Forthe 5000 × 5000 gridworld with no obstacles, w 0 = 30 is the best w 0 value of those tested, while for the 5000 × 5000∗gridworld with obstacles w 0 = 500 is the best w 0 value. The challenge of tuning w 0 in ARAis especially evident in the100 × 1200 gridworld experiment (seen in Fig. 9). The disparity in the ARAresults for different values of w 0 illustrates∗a non-linear relationship between w 0 and ARA’s performance. This emphasizes that setting this value is non-trivial, asa higher or lower w 0 value does not necessarily guarantee better or worse performance. Thus, even if for some problem∗instances ARAstill has the benefit of not depending onany parameter.with some parameter settings outperforms APTS/ANA, APTS/ANA∗∗∗Next, consider the results for the KPP-COM domain, seen in Fig. 11(a). The y-axis denotes the suboptimality of theincumbent solution as a function of the computation time, shown on the x-axis. Since KPP-COM is a MAX problem, thesuboptimality starts very close to zero and converges to one from below when an optimal solution is found.instance.∗R. Stern et al. / Artificial Intelligence 214 (2014) 1–2519Fig. 10. Anytime experiments for 5000 × 5000 gridworld. Time (x-axis) is in seconds.Fig. 11. Anytime experiments for KPP-COM and 15-puzzle domains.∗The results in Fig. 11(a) clearly show that in this domain as well, APTS/ANAperforms consistently no worse and oftenbetter than the other algorithms. As discussed in Section 5.2, DFBnB is known to be highly effective in this domain [52].Indeed, the results of APTS/ANAwhen the runtimewas more than 5 seconds.and DFBnB are almost identical, with a slight advantage for APTS/ANA∗∗∗Negative results for APTS/ANAwere obtained for the 15-puzzle domain, shown in Fig. 11(b). Running APTS/ANAwith a tuned w value (w = 2). This is because, as explained in Section 4, APTS/ANAyieldedruns pureworse results than AWAheuristic search until it finds the initial solution. In many domains, including all those described above, this results infinding an initial solution very fast. With proper tie-breaking, this is also the case for the 15-puzzle domain. The quality ofwastes a significant amount of time improving solutions thatthis initial solution, however, is very poor. Thus, APTS/ANAwithhave very high suboptimality, until it converges to an optimal solution. By contrast, the initial solution found by AWAw = 2 (AWA-2.0 in Fig. 11(b)) has a suboptimality of at most 2, and can be found relatively easily in this domain.∗∗∗∗∗∗As a partial remedy for this problem, we tried first running WAwith different weights and then giving APTS/ANA∗thevariant performed the same as∗initial solution, after which it continues to run as usual. Results show that this APTS/ANAthe best performing anytime search algorithm for this domain.To summarize, on all the domains except the 15-puzzle, APTS/ANAwas competitive, and in most cases significantly bet-improvester than existing anytime search algorithms in that: (1) APTS/ANA∗the incumbent solution faster and more often, and (3) APTS/ANAconverges faster to solutions of higher quality. Moreover,in all of the domains we experimented with, we found that the performance of existing parametric anytime search algo-finds an initial solution faster, (2) APTS/ANA∗∗∗∗20R. Stern et al. / Artificial Intelligence 214 (2014) 1–25∗rithms is greatly affected by the parameter values. By contrast, APTS/ANAstill manages to outperform existing anytime algorithms.does not require any parameters to be set, and6. Generalized Potential Search (GPTS)In Section 3 we presented the PTS algorithm, and showed that under the linear-relative assumption PTS always expandsthe node with the highest potential (Theorem 1). In this section we generalize PTS to cases where this assumption does nothold. We call the resulting algorithm General Potential Search (GPTS) – a search algorithm that always expands the nodewith the highest potential.GPTS can be implemented as a BFS with an evaluation function that orders nodes according to their potential (denotedearlier in this paper as P Th,C ). We call such an evaluation function a Potential Ordering Function (POF).Definition 3 (Potential Ordering Function (POF)). A function F is called a Potential Ordering Function (POF) if for any pair ofnodes n1 and n2, we have thatF (n1) ≥ F (n2)iffP T h,C (n1) ≥ P T h,C (n2)Of course, P Th,C itself is a trivial POF. Calculating PTh,C , however, may be non-trivial. Next, we propose practical POFsfor a wide range of domains that do not require calculating PTh,C for any node. This suggests the applicability of GPTS.As a preliminary, we provide a more rigorous definition of the potential than given in Definition 2. Let S be the searchedstate space, and let D be a probability distribution over the nodes in S. S denotes a random variable corresponding to a∗(S) = X | h(S) = Y ) the probability that X isstate from S randomly drawn according to distribution D. We denote by Pr(hthe cost of the lowest cost path to a goal from a random state S with heuristic value Y . The potential of a node n is definedas the probability that a random state S with the same h value as node n will have a path to a goal of cost lower thanC − g(n). We next define this formally.Definition 4 (Potential). Given a heuristic function h and a cost bound C , we define the potential of node n, denoted PTh,C (n),as(cid:2)PTh,C (n) = Prg(n) + h∗(S) < C(cid:3)(cid:4)(cid:3) h(S) = h(n)The potential of a node, as defined above, depends on the relation between h(·) and h∗(·). We formalize this h-to-hrelation by introducing the notion of a heuristic model, or h-model in short. An h-model of a heuristic function is a functionthat captures the probabilistic relation between a heuristic and the lowest cost path to the goal that it estimates.∗Definition 5 (h-Model). A function e(·) is said to be an h-model of a heuristic function h, if for every h-value v of theheuristic function, and every h(cid:3)(cid:3) h(S) = v-value K of a state in the state space,(cid:4)(cid:2)= Pre(v) < K(cid:2)hPr(S) < K(cid:4)∗∗Domains with the linear-relative assumption (described in Section 3) are simply domains with an h-model e(v) = X · v,where X is a random independent identically distributed (i.i.d.) variable. Correspondingly, we call this type of h-model thelinear-relative h-model. Using this notation, Lemma 1 (given in Section 3) states that the PTS evaluation function u(n) =C−g(n)h(n)is a POF for the linear-relative h-model. Next, we describe POFs for other h-models.6.1. Additive h-modelConsider the following h-model: e(v) = v + X , where X is an i.i.d. random variable. This does not imply that the distri-bution of X is uniform, but just that the additive error of every node is taken from the same distribution (independently).We call such an h-model an additive h-model.16If the distribution of X is known, no non-trivial POF is required, as the potential can be easily calculated:∗g(n) + h∗(cid:2)PTh,C (n) = Pr(S) < C(cid:2)(S) < C − g(n)= Prh(cid:2)(cid:4)h(n) + X < C − g(n)= Pr(cid:2)(cid:4)X < C − g(n) − h(n)= Pr(cid:3)(cid:4)(cid:3) h(S) = h(n)(cid:3)(cid:4)(cid:3) h(S) = h(n)16 This is reminiscent of the bounded constant absolute error model described by Pearl [35] where the difference between h and h(i.e., h∗(n) ≤ h(n) + K ). Here, K is the largest value for X .∗is bounded by a constantR. Stern et al. / Artificial Intelligence 214 (2014) 1–2521For example, in the special case where X is a constant K , the potential of a node is a simple binary function:(cid:7)PTh,C (n) =1 g(n) + h(n) + K ≤ C0 otherwiseIf the distribution of X is not known, then directly computing PTh,C is impossible. Next, we show that even if the distributionof X is unknown, it is still possible to have a POF. Corollary 1 presents a theoretical POF that applies to any given h-model.Corollary 1. F C (n) = Pr(e(h(n)) < C − g(n)) is a POF.Proof. For any pair of nodes n1, n2, if PTh,C (n1) ≥ P Th,C (n2) then:∗(S) < C(S) < C − g(n1)(cid:2)g(n1) + hPr(cid:2)∗hPr(cid:2)(cid:2)(cid:4)h(n1)PreF C (n1) ≥ F C (n2)(cid:4)< C − g(n1)(cid:3)(cid:4)(cid:3) h(S) = h(n1)(cid:3)(cid:4)(cid:3) h(S) = h(n1)(cid:2)≥ Pre(cid:2)≥ Pr(cid:2)≥ Prh(cid:2)(cid:4)h(n2)g(n2) + h∗(S) < C(S) < C − g(n2)(cid:4)< C − g(n2)∗[Definition 5](cid:3)(cid:4)(cid:3) h(S) = h(n2)(cid:3)(cid:4)(cid:3) h(S) = h(n2)Proving the reverse direction is straightforward, and thus F C is a POF. (cid:2)Using the POF given in Corollary 1 requires calculating F C (n) = Pr(e(h(n)) < C − g(n)). For an additive h-model, F C (n)still depends on X , since e(h(n)) = h(n) + X . Theorem 3 provides an applicable POF that does not depend on X .Theorem 3. If the h-model is additive then − f (n) = −(g(n) + h(n)) is a POF.(cid:2)(cid:4)h(n1)Proof. For any pair of nodes n1, n2, if P Th,C (n1) ≥ P Th,C (n2) then:(cid:2)(cid:2)(cid:2)(cid:4)(cid:4)[Corollary 1]≥ Pr< C − g(n1)h(n2)eePr(cid:2)(cid:2)(cid:4)(cid:4)h(n2) + X < C − g(n2)≥ Prh(n1) + X < C − g(n1)Pr(cid:2)(cid:2)(cid:4)(cid:4)X < C − g(n2) − h(n2)≥ PrX < C − g(n1) − h(n1)PrC − g(n1) − h(n1) ≥ C − g(n2) − h(n2)− f (n1) = −g(n1) − h(n1) ≥ −g(n2) − h(n2) = − f (n2)(cid:4)< C − g(n2)[X is i.i.d.][additive h-model]The reverse direction is straightforward. (cid:2)A direct result of Theorem 3 is that for an additive h-model, GPTS and A∗expand nodes in the same order.6.2. General h-modelConsider the more general case, where the h-model e(v) is an algebraic combination of v and a random i.i.d. variable X .We overload the function e to describe this algebraic combination, and write e(v) = e(v, X). Note that this model generalizesthe previously discussed h-models. Let er be the inverse function of e such that er(e(v), v) = X . We denote an h-model asinvertible if such an inverse function er exists. Theorem 4 shows that if the h-model is invertible and er is monotonic, thenP gen(n) = er(C − g(n), h(n)) is a POF.Theorem 4. For any i.i.d. random variable X and invertible h-model e(v) = e(v, X), if er is monotonic then P gen is a POF.(cid:2)Pre(cid:2)Pre(cid:2)Pr(cid:2)(cid:4)< C − g(n1)(cid:4)(cid:2)(cid:4)h(n1)(cid:2)h(n1), X(cid:2)Proof. For any pair of nodes n1, n2, if P Th,C (n1) ≥ P Th,C (n2) then according to Corollary 1:(cid:2)(cid:2)(cid:4)≥ Prh(n2)e(cid:2)(cid:2)(cid:4)(cid:4)≥ Pr< C − g(n1)< C − g(n2)h(n2), Xe(cid:2)≥ PrC − g(n1), h(n1)C − g(n2), h(n2)X < erX < er(cid:2)(cid:4)(cid:4)C − g(n2), h(n1)C − g(n1), h(n1)erP gen(n1) ≥ P gen(n2)(cid:2)(cid:12)(cid:4)h(n)e[h-model is invertible](cid:4)< C − g(n2)(cid:4)X i.i.d., er monotone(cid:2)h(n), X≥ er= e(cid:4)(cid:4)(cid:4)(cid:4)(cid:4)(cid:13)(cid:2)(cid:13)(cid:12)The reverse direction is straightforward. (cid:2)22R. Stern et al. / Artificial Intelligence 214 (2014) 1–25Table 7h models and their corresponding functions.h-model (e(v))v + X (additive)v · X (linear relative)v Xer (e(v), v)e(v) − ve(v)vlogv (e(v))P gen(n) = er (C − g(n), h(n))C − g(n) − h(n)C−g(n)h(n)logh(n)(C − g(n))Notice that Lemma 1 and Theorem 3 are special cases of Theorem 4. Table 7 presents a few examples of how Theorem 4can be used to obtain corresponding POFs for various h-models.The exact h-model is domain and heuristic dependent. Analyzing a heuristic in a given domain and identifying itsh-model may be done analytically in some domains with explicit knowledge about the domain. Another option for identify-ing an h-model is to add a preprocessing stage in which a set of problem instances are solved optimally, and the h-model isdiscovered using curve fitting methods. In our experiments, we found the linear-relative h-model to be sufficiently accurateand saw no justification for using more complex h-models. This option is given since such cases may theoretically exist.7. Conclusions and future workThis paper discussed two search problems: bounded-cost search, and anytime search. In a bounded-cost search, once asolution of cost lower than a given cost is found, the search can halt. In an anytime search, the search continues, returningbetter and better solutions until the search is either halted by the user, or until an optimal solution has been found. Bothtypes of problems have important applications and this paper presents PTS and APTS/ANAto solve them.∗We showed that an efficient bounded-cost search algorithm can be easily converted to an efficient anytime search algo-rithm. This is done by running the bounded-cost search algorithm iteratively, giving the bounded-cost search algorithm alower cost bound in every iteration. An attractive property of the resulting algorithm is that there is no need for parametertuning, in contrast to most common anytime search algorithms.The relation between bounded-cost and anytime search problems emphasizes the need for an efficient bounded-costsearch algorithm. In this paper we propose such an algorithm, called PTS. PTS is a best–first search that expands nodesin order of their potential, which is the probability that a node will lead to a solution under the cost bound. The relationbetween a given heuristic and the optimal cost is used to develop a cost function that can order the nodes in OPENapproximately according to their potential, without actually calculating it. Both PTS and its corresponding anytime algorithmAPTS/ANAoutperform competitive algorithms on a wide range of domains.∗7.1. BEES, BEEPS, AEES, and incorporating distance estimatesThe heuristic h(·) estimates the minimum cost of reaching a goal. Recent work has shown that in domains with non-unitedge cost, h(·) may not be correlated with the number of actions needed to reach a goal [39]. In such cases, prior work hasshown that it is very beneficial to incorporate into the search algorithm an additional heuristic that estimates the minimumactions needed to reaching a goal [46]. Such a “distance” heuristic, commonly denoted as d(·), together with an onlinelearned inadmissible heuristic ˆh(·), has been used in a new suboptimal search algorithm called EES [20], a new anytimesearch algorithm called AEES [63] and a new bounded-cost search algorithm called BEES [40].BEES was shown to outperform PTS in domains with non-unit edge costs, including “Zenotravel” and “Elevators”, twodomains from the International Planning Competition (IPC) that were solved with a domain independent planner. Followup work showed that in several other IPC benchmarks with non-unit edge cost, PTS can even be outperformed by a pureheuristic search [34]. Similar results appear when comparing AEES to APTS/ANA[63].∗However, PTS is competitive with BEES in domains with unit edge costs. See the results for the Tiles domain (whichis the 15-puzzle) [40] and Tinybot domain [34], which were the only unit edge-cost domains they experimented with.17When PTS is as good as BEES, one would probably prefer using PTS since implementing it is much simpler: BEES requiresmaintaining at least two open lists as well as online learning an improved heuristic, while PTS is a simple best–first searchalgorithm with an easy to compute evaluation function. Similar reasoning applies for comparing APTS/ANAand AEES.∗This emphasizes the need for PTS to consider d(·) in domains with non-unit edge cost. A first attempt to do so wasin the BEEPS algorithm [63], which is equivalent to BEES except for using the PTS evaluation function when all nodes inOPEN are estimated to be above the bound. Empirically, this combination of BEES and PTS performed almost exactly likeBEES. Thus, incorporating d(·) into PTS in an effective manner is still an open challenge. A possible direction for doing this∗(n). For example, one could apply machineis by considering explicitly the probabilistic relation between h(n), d(n) and hlearning techniques to learn this relation from past experience.17 Further experimental results for other domain-independent planning domains with unit edge-cost are needed to provide a conclusive statement aboutthe performance of PTS in domain-independent planning.R. Stern et al. / Artificial Intelligence 214 (2014) 1–2523Fig. 12. Optimal solution vs. heuristic for the KPP-COM and blocksworld domains.7.2. Expected search effort instead of potentialPTS aims at expanding the node with the highest probability to lead to a solution under the bound. The task in abounded-cost search is, however, to find such a solution as fast as possible. Thus, we might also consider the expectedeffort of finding such a solution, and not just the probability that such a solution exists. Estimating search effort may bedone with search effort prediction formulas and algorithms [64–66]. Future work will investigate how to incorporate suchestimates, in addition to the potential of a node. For example, a node that is very close to a goal might be preferred to anode that has a slightly higher potential but is farther from a goal.This paper combines results from two research groups who independently discovered APTS/ANA. One group derived∗the anytime search algorithm APTS by studying bounded-cost search problems [7,8]. The other research group derived ANAmotivated by a desire to avoid parameter tuning [9]. Both groups had papers under review simultaneously and subsequentlypublished in 2011. We thank Wheeler Ruml for pointing out this relationship.∗AcknowledgementsThis research was supported by the Israel Science Foundation (ISF) under grant number 417/13 to Ariel Felner. This workwas supported in part (for Goldberg and van den Berg) by the US National Science Foundation under Award IIS-1227536.∗We thank Maxim Likhachev for making his implementation of ARA.Our implementation of ANAis freely available in his Search-based Planning Library (SBPL) at: http://www.sbpl.net.available to us, as well as publishing the code for ANA∗∗Appendix A. Domains and their h-modelsIn this appendix we show the h-models of two domains and heuristics. These models were obtained by optimally solving∗a set of problem instances. Then we backtracked from the goal to the start, and for every node on that path plotted its hvalue versus its heuristic value (according to the selected heuristic).A.1. Key Player Problem in Communication (KPP-COM)Fig. 12(a) shows the h-to-hrelation for 100 KPP-COM problem instances. See Section 5.1.2 for details on this domainand the heuristic we used for it. Each problem instance is a graph, randomly generated according to the Barabási–Albertmodel [54] (the choice of this type of graphs is motivated in Section 5.1), having 700 nodes and a density factor of 3.∗The dashed black line in Fig. 12(a) is a linear fit of the data. As can be seen, a slight curve (e.g., a logarithmic model)would fit nicely. However, the linear fit is simpler and is also quite accurate.A.2. Blocks world∗Next, we analyzed the h-to-hrelation for the blocks world domain, which is one of the well-known planning domains.We used the Fast Downward planner [67] with the admissible LM-cut heuristic [68]. Fig. 12(b) shows the h-to-hrelationfor all the blocks world problem instances from the International Planning Competition ’06, which are publicly available inthe Fast Downward software suite. Again, the dashed black line is a linear fit of the data. As can be seen, this heuristic inthis domain also exhibits a clear linear relative h-model.∗24ReferencesR. Stern et al. / Artificial Intelligence 214 (2014) 1–25[1] P.E. Hart, N.J. Nilsson, B. Raphael, A formal basis for the heuristic determination of minimum cost paths, IEEE Trans. Syst. Sci. Cybern. SSC-4 (2) (1968)100–107.[2] R.E. Korf, Depth-first iterative-deepening: an optimal admissible tree search, Artif. Intell. 27 (1) (1985) 97–109.[3] M. Helmert, G. Röger, How good is almost perfect? in: AAAI, 2008, pp. 944–949.[4] S. Zilberstein, Using anytime algorithms in intelligent systems, AI Mag. 17 (3) (1996) 73–83.[5] R.A. Valenzano, N.R. Sturtevant, J. Schaeffer, K. Buro, A. Kishimoto, Simultaneously searching with multiple settings: an alternative to parameter tuningfor suboptimal single-agent search algorithms, in: ICAPS, 2010, pp. 177–184.∗[6] M. Likhachev, G.J. Gordon, S. Thrun, ARA[7] R. Stern, R. Puzis, A. Felner, Potential search: a new greedy anytime heuristic search, in: SoCS, 2010, pp. 119–120.[8] R. Stern, R. Puzis, A. Felner, Potential search: a bounded-cost search algorithm, in: ICAPS, 2011, pp. 234–241.[9] J. van den Berg, R. Shah, A. Huang, K.Y. Goldberg, Anytime nonparametric Awith provable bounds on sub-optimality, in: NIPS, 2003., in: AAAI, 2011, pp. 105–111.: anytime A∗∗[10] S. Russell, P. Norvig, Artificial Intelligence: A Modern Approach, 3rd edition, Prentice-Hall, Englewood Cliffs, NJ, 2010.[11] R. Stern, T. Kulberis, A. Felner, R. Holte, Using lookaheads with optimal best–first search, in: AAAI, 2010, pp. 185–190.[12] E.W. Dijkstra, A note on two problems in connexion with graphs, Numer. Math. 1 (1959) 269–271.[13] A. Felner, Position paper: Dijkstra’s algorithm versus uniform cost search or a case against Dijkstra’s algorithm, in: SOCS, 2011, pp. 47–51.[14] T.H. Cormen, C.E. Leiserson, R.L. Rivest, C. Stein, Introduction to Algorithms, 2nd edition, The MIT Press, 2001.[15] R.E. Korf, Linear-space best–first search, Artif. Intell. 62 (1) (1993) 41–78.[16] I. Pohl, Heuristic search viewed as path finding in a graph, Artif. Intell. 1 (3–4) (1970) 193–204.[17] I. Pohl, The avoidance of (relative) catastrophe, heuristic competence, genuine dynamic weighting and computational issues in heuristic problemsolving, in: IJCAI, 1973, pp. 12–17.[18] J. Pearl, J. Kim, Studies in semi-admissible heuristics, IEEE Trans. Pattern Anal. Mach. Intell. 4 (4) (1982) 392–400.∗[19] J.T. Thayer, W. Ruml, Faster than weighted A[20] J.T. Thayer, W. Ruml, Bounded suboptimal search: a direct approach using inadmissible estimates, in: IJCAI, 2011, pp. 674–679.[21] D. Furcy, S. Koenig, Limited discrepancy beam search, in: IJCAI, 2005, pp. 125–131.[22] E.A. Hansen, R. Zhou, Anytime heuristic search, J. Artif. Intell. Res. 28 (2007) 267–297.[23] E. Balas, P. Toth, Branch and bound methods, in: E.L. Lawler, J.K. Lenstra, A.H.G. Rinnooy Kan, D.B. Shwoys (Eds.), Traveling Salesman Problem: A Guided: an optimistic approach to bounded suboptimal search, in: ICAPS, 2008, pp. 355–362.Tour of Combinatorial Optimization, Wiley, Chichester, 1985.∗– a window constrained anytime heuristic search algorithm, in: IJCAI, 2007, pp. 2250–2255.[24] S. Richter, J.T. Thayer, W. Ruml, The joy of forgetting: faster anytime search via restarting, in: ICAPS, 2010, pp. 137–144.[25] S. Aine, P.P. Chakrabarti, R. Kumar, AWA[26] R. Zhou, E.A. Hansen, Beam-stack search: integrating backtracking with beam search, in: ICAPS, 2005, pp. 90–98.[27] J.T. Thayer, W. Ruml, Anytime heuristic search: frameworks and algorithms, in: SOCS, 2010, pp. 121–128.[28] R. Taig, R.I. Brafman, Compiling conformant probabilistic planning problems into classical planning, in: ICAPS, 2013, pp. 197–205.[29] A. Stern, I. Dagan, A confidence model for syntactically-motivated entailment proofs, in: RANLP, 2011, pp. 455–462.[30] A. Stern, R. Stern, I. Dagan, A. Felner, Efficient search for transformation-based inference, in: ACL, 2012, pp. 283–291.[31] A. Zanarini, G. Pesant, Solution counting algorithms for constraint-centered search heuristics, Constraints 14 (2009) 392–413.[32] P. Haslum, H. Geffner, Heuristic planning with time and resources, in: European Conference on Planning (ECP), vol. 1, 2001, pp. 121–132.[33] H. Nakhost, J. Hoffmann, M. Müller, Improving local search for resource-constrained planning, in: SOCS, 2010, pp. 81–82.[34] P. Haslum, Heuristics for bounded-cost search, in: ICAPS, 2013, pp. 312–316.[35] J. Pearl, Heuristics: Intelligent Search Strategies for Computer Problem Solving, Addison-Wesley Pub. Co., Inc., Reading, MA, 1984.[36] A. Felner, R.E. Korf, S. Hanan, Additive pattern database heuristics, J. Artif. Intell. Res. 22 (2004) 279–318.[37] U. Sarkar, P. Chakrabarti, S. Ghose, S. De Sarkar, Reducing reexpansions in iterative-deepening search by controlling cutoff bounds, Artif. Intell. 50 (2)(1991) 207–221.[38] E. Burns, W. Ruml, Iterative-deepening search with on-line tree size prediction, in: LION, 2012, pp. 1–15.∗[39] C.M. Wilt, W. Ruml, When does weighted A[40] J.T. Thayer, R. Stern, W. Ruml, A. Felner, Faster bounded-cost search using inadmissible estimates, in: ICAPS, 2012, pp. 270–278.[41] M. Boullé, A parameter-free classification method for large scale learning, J. Mach. Learn. Res. 10 (2009) 1367–1385.[42] G.R. Harik, F.G. Lobo, A parameter-less genetic algorithm, in: GECCO, vol. 99, 1999, pp. 258–267.[43] A. Foss, O.R. Zaïane, A parameterless method for efficiently discovering clusters of arbitrary shape in large datasets, in: International Conference onfail? in: SOCS, 2012, pp. 137–144.Data Mining (ICDM), IEEE, 2002, pp. 179–186.[44] A.J. Dionne, J.T. Thayer, W. Ruml, Deadline-aware search using on-line measures of behavior, in: SOCS, 2011, pp. 39–46.[45] W. Ruml, M.B. Do, Best-first utility-guided search, in: IJCAI, 2007, pp. 2378–2384.[46] J.T. Thayer, W. Ruml, Using distance estimates in heuristic search, in: ICAPS, 2009, pp. 382–385.[47] W.E. Story, Notes on the “15” puzzle, Am. J. Math. 2 (4) (1879) 397–404.[48] R.C. Holte, A. Felner, J. Newton, R. Meshulam, D. Furcy, Maximizing over multiple pattern databases speeds up heuristic search, Artif. Intell. 170 (16–17)(2006) 1123–1136.[49] U. Zahavi, A. Felner, R.C. Holte, J. Schaeffer, Duality in permutation state spaces and the dual search algorithm, Artif. Intell. 172 (4–5) (2008) 514–540.[50] M.G. Everett, S.P. Borgatti, The centrality of groups and classes, J. Math. Sociol. 23 (3) (1999) 181–201.[51] L.C. Freeman, A set of measures of centrality based on betweenness, Sociometry 40 (1) (1977) 35–41.[52] R. Puzis, Y. Elovici, S. Dolev, Finding the most prominent group in complex networks, AI Commun. 20 (4) (2007) 287–296.[53] S. Dolev, Y. Elovici, R. Puzis, P. Zilberman, Incremental deployment of network monitors based on group betweenness centrality, Inf. Process. Lett.109 (20) (2009) 1172–1176.[54] A.L. Barabási, R. Albert, Emergence of scaling in random networks, Science 286 (5439) (1999) 509–512.[55] D.J. Lipman, S.F. Altschul, J.D. Kececioglu, A tool for multiple sequence alignment, Proc. Natl. Acad. Sci. USA 86 (12) (1989) 4412–4415.[56] T. Ikeda, H. Imai, Enhanced Aalgorithms for multiple alignments: optimal alignments for several sequences and k-opt approximate alignments for∗large cases, Theor. Comput. Sci. 210 (2) (1999) 341–374.[57] A.S. Konagurthu, P.J. Stuckey, Optimal sum-of-pairs multiple sequence alignment using incremental Carrillo and Lipman bounds, J. Comput. Biol. 13 (3)(2006) 668–685.∗[58] T. Yoshizumi, T. Miura, T. Ishida, A[59] T. Ikeda, H. Imai, Fast A[60] H. Kobayashi, H. Imai, Improvement of the A[61] W. Zhang, R.E. Korf, Performance of linear-space search algorithms, Artif. Intell. 79 (2) (1995) 241–292.[62] W. Zhang, Depth-first branch-and-bound versus local search: a case study, in: AAAI/IAAI, 2000, pp. 930–935.∗∗algorithms for multiple sequence alignment, in: Workshop on Genome Informatics, 1994, pp. 90–99.with partial expansion for large branching factor problems, in: AAAI, 2000, pp. 923–929.algorithm for multiple sequence alignment, in: Genome Informatics Series, 1998, pp. 120–130.R. Stern et al. / Artificial Intelligence 214 (2014) 1–2525[63] J.T. Thayer, J. Benton, M. Helmert, Better parameter-free anytime search by minimizing time between solutions, in: SOCS, 2012, pp. 120–128.[64] L.H.S. Lelis, S. Zilles, R.C. Holte, Predicting the size of IDA[65] L. Lelis, R. Stern, A. Felner, S. Zilles, R.C. Holte, Predicting optimal solution cost with bidirectional stratified sampling, in: ICAPS, 2012, pp. 155–163.∗[66] R.E. Korf, M. Reid, S. Edelkamp, Time complexity of iterative-deepening-A[67] M. Helmert, The fast downward planning system, J. Artif. Intell. Res. 26 (2006) 191–246.[68] M. Helmert, C. Domshlak, Landmarks, critical paths and abstractions: what’s the difference anyway? in: ICAPS, 2009, pp. 162–169.’s search tree, Artif. Intell. 196 (2013) 53–76., Artif. Intell. 129 (1–2) (2001) 199–218.∗