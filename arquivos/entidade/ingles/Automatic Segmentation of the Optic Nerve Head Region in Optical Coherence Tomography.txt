Computer Methods and Programs in Biomedicine 220 (2022) 106801 Contents lists available at ScienceDirect Computer Methods and Programs in Biomedicine journal homepage: www.elsevier.com/locate/cmpb Automatic Segmentation of the Optic Nerve Head Region in Optical Coherence Tomography: A Methodological Review Rita Marques a , b , Danilo Andrade De Jesus b , ∗, João Barbosa-Breda c , e , f , Jan Van Eijgen c , d , Ingeborg Stalmans c , d , Theo van Walsum b , Stefan Klein b , Pedro G. Vaz a , Luisa Sánchez Brea b a Laboratory for Instrumentation, Biomedical Engineering and Radiation Physics (LIBPhys-UC), Department of Physics, University of Coimbra, Coimbra, Portugal b Biomedical Imaging Group Rotterdam, Department of Radiology & Nuclear Medicine, Erasmus MC, Rotterdam, Netherlands c Research Group Ophthalmology, Department of Neurosciences, KU Leuven, Leuven, Belgium d Department of Ophthalmology, University Hospitals UZ Leuven, Leuven, Belgium e Cardiovascular R&D Center, Faculty of Medicine of the University of Porto, Porto, Portugal f Ophthalmology Department, São João Universitary Hospital Center, Porto, Portugal a r t i c l e i n f o a b s t r a c t Article history: Received 15 September 2021 Revised 7 March 2022 Accepted 1 April 2022 Keywords: Optical Coherence Tomography Segmentation Optic Nerve Head Lamina Cribrosa Review The optic nerve head (ONH) represents the intraocular section of the optic nerve, which is prone to dam- age by intraocular pressure (IOP). The advent of optical coherence tomography (OCT) has enabled the evaluation of novel ONH parameters, namely the depth and curvature of the lamina cribrosa (LC). To- gether with the Bruch’s membrane minimum-rim-width (BMO-MRW), these seem to be promising ONH parameters for diagnosis and monitoring of retinal diseases such as glaucoma. Nonetheless, these OCT derived biomarkers are mostly extracted through manual segmentation, which is time-consuming and prone to bias, thus limiting their usability in clinical practice. The automatic segmentation of ONH in OCT scans could further improve the current clinical management of glaucoma and other diseases. This review summarizes the current state-of-the-art in automatic segmentation of the ONH in OCT. PubMed and Scopus were used to perform a systematic review. Additional works from other databases (IEEE, Google Scholar and ARVO IOVS) were also included, resulting in a total of 29 reviewed studies. For each algorithm, the methods, the size and type of dataset used for validation, and the respective results were carefully analysed. The results show a lack of consensus regarding the definition of segmented regions, extracted parameters and validation approaches, highlighting the importance and need of standardized methodologies for ONH segmentation. Only with a concrete set of guidelines, these automatic segmenta- tion algorithms will build trust in data-driven segmentation models and be able to enter clinical practice. © 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) 1. Introduction OCT is an imaging technique that enables noninvasive cross- sectional imaging of tissue using low-coherence interferometry. Among its many applications, one of the most common is the analysis of the human retina where, given its high resolution and three-dimensional nature, OCT can assist in the diagnosis and prognosis of several diseases. One example of such diseases is glaucoma, which is the main cause of irreversible blindness worldwide, and which has elevated ∗ Corresponding author. E-mail address: d.andradedejesus@erasmusmc.nl (D. Andrade De Jesus). IOP as primary risk factor for its development [1] . It starts to man- ifest through damage to the retinal ganglion cell (RGC) axons as they exit the eye at the ONH [2] , and is associated with complex 3D structural modifications in the ONH, such as thinning of the retinal nerve fiber layer (RNFL), changes in the BMO-MRW and in the LC depth, thickness and curvature [2–6] . Evidence suggests that the ONH surface depression occurs before the RNFL thinning [7] , making it more relevant for early diagnosis. Even though ONH structural changes have been mostly stud- ied in a context of glaucoma diagnosis, they are also represen- tative of non-ophthalmic diseases such as idiopathic intracranial hypertension (IIH), optic neuritis (ON), multiple sclerosis (MS) or neuromyelitis optica spectrum disorders (NMOSD) [8] , Alzheimer [9,10] , and Parkinson’s disease [11] . https://doi.org/10.1016/j.cmpb.2022.106801 0169-2607/© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) R. Marques, D. Andrade De Jesus, J. Barbosa-Breda et al. Computer Methods and Programs in Biomedicine 220 (2022) 106801 Fig. 1. Flowchart of the collected data. The LC is a mesh-like structure that fills the posterior scleral foramen where unmyelinated RGC axons pass through before exit- ing the eye [2] . Up until recently, it has been difficult to study this region of the ONH, given its deep location. The OCT signal is highly attenuated when reaching deeper structures, and the shadow of the blood vessels, which merge at the ONH, can limit the correct identification of the LC and other ONH structures [8] . However, it is now possible to overcome some of these problems thanks to ad- vances in imaging technologies such as enhanced depth imaging (EDI) [12] , swept-source optical coherence tomography (SS-OCT) [13] and adaptive compensation [14] . Given the diagnostic potential of biomarkers extracted from the ONH, and particularly from the LC [15] , an accurate segmentation of this region is becoming increasingly important for improving clinical diagnosis and follow-up, and also for contributing to a bet- ter understanding of several ophthalmic and non-ophthalmic dis- eases. The need for an automatic segmentation arises from the fact that manual segmentation is time consuming, prone to bias, and unsuitable for a clinical environment [16] since it requires exten- sive training and expertise. Even if some commercial OCT devices already have an in-built proprietary segmentation software, they can segment some, but not all, ONH tissues, and they still require frequent manual corrections [17] . The democratization and emergence of OCT as the clinical gold- standard for in vivo structural ophthalmic examinations [18] has encouraged the entry of new manufacturers to the market as well. It will soon become practically infeasible to perform manual seg- mentations for all OCT brands, device models, generations, and applications [17] . From this arises the urgent need for device- independent automatic segmentation algorithms. This review summarizes the current state-of-the-art in auto- matic segmentation of the ONH in OCT. 2. Methods A literature search was conducted in MEDLINE (Pubmed) and Scopus bibliographic databases on December 8th, 2021. The search query (PubMed) was: (imag ∗ AND processing OR segmentation) AND (optic AND (disc OR disk) OR lamina) AND (optical AND co- herence AND tomography) NOT (fundus OR angiography). Addi- tional works which were not found by Pubmed and Scopus, but were cited in the bibliography, and could be found by Google Scholar, IEEE or ARVO bibliographic databases, were also added. Only articles published in English with a detailed description of the method used were considered, and no publication date restric- tion was added. The exclusion criteria were: (i) no description of a novel segmentation algorithm; (ii) no segmentation of the ONH; (iii) only used en-face images; (iv) review article; (v) case report; (vi) comparative study; (vii) clinical trial; or (viii) not an article (abstracts, book chapters, editorials, and notes). 3. Results The systematic search led to a total of 727 references after re- moving the duplicates, which were narrowed down to 33 after ti- tle/abstract screening, and finally to 29 after a full-text screening ( Fig. 1 ). The 29 included studies provided the description of a fully automatic segmentation of ONH centered OCT B-scans and/or vol- umes, and described how its performance was evaluated. All algorithms for automatic segmentation of the ONH were analyzed, and the studies were separated in two categories: tra- ditional methods, which use non-learning based image process- ing techniques only and machine-learning methods (alone or as a re nement/post-process step after traditional methods), and deep learning methods. The results show that, from all the included studies, 41% use traditional image processing methods and 59% machine learning methods. Within the machine learning methods, 47% are based on standard machine learning and 53% use deep learning techniques. Fig. 2 further refines these categories. The table in the Appendix gives a complete overview of all in- cluded studies and their characteristics. The distribution of the pa- pers over the three different categories and the size of the dataset used from ophthalmic and non-ophthalmic patients and healthy subjects in all studies can be found in Fig. 3 . Analysing Fig. 3 it is possible to observe that, overall, deep learning methods use larger datasets. 2 R. Marques, D. Andrade De Jesus, J. Barbosa-Breda et al. Computer Methods and Programs in Biomedicine 220 (2022) 106801 Fig. 2. Categorization of the reviewed methods. The percentage of studies that use each method is displayed next to each category. Fig. 3. Distribution of the reviewed articles organized by method (deep learning, standard machine learning, and traditional image processing) and the type of data used for developing the algorithm (healthy subjects, patients with ophthalmic diseases, and patients with non-ophthalmic diseases). The height of the boxes is proportional the dataset size. Most of the reviewed works evaluated the proposed algorithms in pathological data. The only exceptions were [19] , which val- idated their method on 40 healthy eyes, and [20] , which does not specify if the dataset consists of healthy or pathological data. Both authors compare parameters measured in the automatic ap- proaches with manual quantifications. Among the rest of the works, glaucoma is the most studied pathology. There are only two works that validate their approaches in pathologies other than glaucoma, [8] and [21] , whom applied their method in data from healthy subjects and patients suffering from IIH, MS, NMOSD, and ON. 3.1. Structures of interest Depending on the aim of the work, different regions or points of interest are segmented in the images. To define these points, two manual segmentations of the ONH region in OCT images can be found in Fig.s 4 and 5 (boundary- and region-based, respec- tively). Specifically, Fig. 4 shows the inner limiting membrane (ILM) anterior surface, the retinal pigment epithelium (RPE) layer and its endpoints, the Bruch’s membrane (BM) and its opening points, and the LC anterior surface. The vitrealretinal boundary is equivalent to the anterior surface of the ILM layer (shown in yellow). Fig. 5 shows the lower boundary of the RNFL, and the LC. More- over, it depicts the choroid boundaries. The outer limits of the ONH match the retinal-choroidal boundary endpoints. In the following subsections, a detailed analysis on the ap- proach used by each algorithm to segment the ONH is provided. 3 Fig. 4. OCT B-scan (Heidelberg Engineering, Germany) showing a manual boundary-based segmentation of the ONH. In yellow, the ILM anterior surface; in light blue, the RPE layer; in dark blue, the RPE endpoints; in red, the Bruch’s mem- brane; in orange, the Bruch’s membrane opening points; in green, the LC anterior surface. R. Marques, D. Andrade De Jesus, J. Barbosa-Breda et al. Computer Methods and Programs in Biomedicine 220 (2022) 106801 constraint, that models a priori knowledge about the expected out- come of a successful segmentation, was introduced. On most im- ages, below the retinal-vitreal boundary there are two strong dark- to-light edges that can be used to identify outer limits of the ONH. These contrasts were used by a Markov model [28] to extract the full retinal-choroidal boundary. Also based on edge detection, are the works by Ko et al. [20] and Mao et al. [29] , that used a Canny edge detector as a start- ing point. In [20] , Canny edge filter was used to segment the ONH surface. After smoothing the surface with a robust version of the local regression, using weighted linear least squares and a second degree polynomial model, each B-scan was re-mapped into a 3D Cartesian domain where the ONH and Bruch’s membrane opening (BMO) surface profiles were fitted with an existing surface mod- eling tool [30,31] . In [29] , 2D and 3D Canny edge detectors were applied to the interpolated 3D volume. They used a minimum- cost-path approach, where the cost map was derived from the edge map and the weighted intensity gradients (based on previ- ous knowledge of the LC anatomy). The locations with large values of intensity gradient yield the detection the LC border. 3.2.3. Active contours In active contours methods, an object is segmented by an energy-minimizing contour guided by the surrounding pixels. The internal energy comes from the continuity and smoothness of a curve, and the external energy is derived from the edge map of an image [32] . Three of the reviewed works are in this category, two of which [8,21] applied Chan-Vese level set approach [33] as a final step of the method. In [8] , active contours were used to upgrade their pre- vious 2D segmentation [34] into a robust 3D segmentation of the ONH. They represented the 3D ONH shape using triangulated mesh surfaces of the ILM, RPE and BMO points. The identification of the RPE lower boundary employs a two-stage thin-plate spline fitting that preserves the retinal natural curvature. Finally, the ILM was detected with the Chan-Vese level set approach. The method pre- sented by Gawlik et al. [21] presents an extended version of [8] by adding a local intensity fitting energy step in order to handle in- homogeneous image intensities. The third approach based on active contours is the method pro- posed by Syga et al. [35] , which automatically segmented the LC in 3D. Otsu thresholding, morphological operators and interpolation were used to estimate the 3D region of interest in fundus pho- tographs. The obtained information was used to define the elliptic cylindrical region of interest along the z-axis of a cuboid made of B-scans. After ILM and BM segmentation, in each OCT scan, active contours were used to reconstruct the 3D segmentation and find the LC. 3.2.4. Graph based methods Graph based methods represent images as a weighted graph, with the pixels of an image as nodes and the relation between the pixels as the arcs or edges of the graph [36] . Hussain et al. [37] introduced the approximate location of three bench mark reference (TBMR) layers and layers veto (a weight based on the layers pattern) as a parameter of the graph weight function. The goal of their work was to segment the ONH and com- pute the BMO-MRW for glaucoma diagnosis. The TBMR layers are the three most reflective layers of the retina corresponding to the RNFL, the outer neural layer, and the RPE and were detected to limit the search space. Belghith et al. [38] proposed a new method to segment the an- terior LC surface that is able to include prior knowledge in the in- ference model. They used the Markov Random Field (MRF) class of Bayesian methods. For segmentation, the LC surface was itera- tively refined following a perturbation-based approach inspired by Fig. 5. OCT B-scan (Heidelberg Engineering, Germany) showing a manual region- based segmentation of the ONH. In red, the RNFL; in green, all retinal layers be- tween the ganglion cell and the photore- ceptor layers; in dark blue, the RPE; in light blue, the choriocapillaris and choroid; and in yellow, the LC. 3.2. Traditional Traditional methods are unsupervised segmentation techniques that rely on image processing methods such as thresholding, edge detection and morphological operations. 3.2.1. Thresholding Thresholding algorithms segment the image based on quantifi- able features like image intensity or gradient magnitude, and di- vide the pixels according to a defined threshold. Ramzan et al. in [22] and [23] , and Khalil et al. [24] proposed methods to extract the cup to disc ratio (CDR) through the seg- mentation of the ILM using intensity thresholds. In [22] , the ILM was extracted using a global intensity based threshold applied to a set of images, followed by interpolation to fill in the gaps. Next, the RPE was obtained with Otsu thresholding applied to each im- age. Additionally, a distance thresholding approach was introduced. This approach computes the distance to all the centroids of all the objects to remove the extended cup region. In [23] only the ILM was used to calculate the CDR. Again, a global intensity based threshold applied to a set of images was used to detect the ILM, defining its anterior surface as the first non-zero layer. Interpo- lation was applied to fill the gaps of the extracted layer. Finally, Khalil et al. [24] proposed a method to calculate the CDR from the ILM segmentation based on a set of global intensity thresholds ap- plied to each image, with a refinement that included interpolation of missing points, outliers removal, low quality image and RPE fea- ture analysis. Mokhtari et al. [19] used a different approach, applying ridgelet transform [25] for RPE detection and, subsequently, a threshold (1.4 times of the Otsu threshold) to determine the RPE boundary location on each B-scan. 3.2.2. Edge detection Edge detection methods find discontinuities points on an image - the edges - where the brightness varies sharply. Boyer et al. [26] proposed an extension of the Markov model in- troduced by Koozekanani, et al [27] . First, the vitreal-retinal bound- ary was found through an edge based threshold. A smoothness 4 R. Marques, D. Andrade De Jesus, J. Barbosa-Breda et al. Computer Methods and Programs in Biomedicine 220 (2022) 106801 the Biased and Filtered Point Sampling method [39] according to a non-local MRF energy function. 3.3. Machine Learning Machine-learning methods train the algorithm to find patterns and features in large amounts of data in order to make decisions and predictions based on new data. Such features can be, for ex- ample, the local binary pattern, the histogram of gradient [40] , tex- ture features extracted by the Oriented Brief algorithm [41,42] , the neighborhood intensity profile, and the steerable Gaussian deriva- tives [43] . These methods are usually applied after, or in combina- tion with, traditional methods. Several methods in this section use machine learning after a graph search approach. That is the case of the approach followed by Lee et al. [44,45] , who developed a fast multiscale extension of 3D graph search to detect four intra-retinal surfaces in ONH cen- tered OCT volumes. The authors used a k-nearest neighbor (NN) classifier combined with hull fitting, to segment the ONH cup and neuroretinal rim while preserving their shape. The method assigns one of three labels (background, cup, rim) to each column within the OCT scan. Then, a set of 15 features was calculated for each voxel column in the volume, and used as input for the k-NN clas- sifier. Antony et al. [46] , Miri et al. [43] , and Yu et al. [41] all used a random forest classifier [47] in combination with the graph search approach. In [46] , an existing graph theoretic approach [48] was adapted for simultaneous segmentation of multiple continuous surfaces, in order to make it able to identify the ONH boundary in 3D. An it- erative method finds the optimal set of feasible surfaces for each estimate of the ONH boundary columns by solving a minimum- closure problem in a graph. The random forest classifier was then trained to find the neural canal opening boundary points, based on the previously learned textural features. However, the continuation of the iterative search on the border of the BM was a common mis- take that lead to a wrong placement of the BMO and, consequently, of the borders of the ONH. This limitation was addressed in [43] by eliminating the iteration phase. The new method, instead of using a mathematical model for the BMO points, computes the likelihood of each voxel being a BMO point using the random forest classifier. The method described in [41] includes locally adaptive con- straints for a more accurate ONH region detection. The ONH region was first detected by random forest method on polar-transformed images with features representing both textural and structural information. Then two layer segmentation methods with locally adaptive constraints, Otsu segmentation guided graph search and shared-hole graph search, were proposed for the segmentation of nine surfaces. The three remaining papers of this section proposed all differ- ent approaches. Fu et al. [49] detects the optic disc (OD) through the segmentation of the RPE. A low-rank dictionary based on in- tensity features and local binary patterns was learned and used to reconstruct the layer on the candidate region. The resulting error curves, that represent the deviations from the smooth geometri- cal structure, allowed for the boundaries of the OD to be detected. Paul et al. [50] performed a segmentation of the retinal and vit- real boundary from OCT ONH centered images by incorporating a Gaussian mixture model (GMM) [51] clustering into a kernel. Fi- nally, Wu et al. [40] started by using a multi-scale 3D graph search approach to segment the RPE, followed by a search patch method to segment the ONH. A support vector machine (SVM) classifier was trained with the purpose of finding the most likely patch cen- tered at the neural canal opening. The features extracted for patch description were the local binary pattern and histogram of gradi- ent. 3.3.1. Deep Learning Deep learning methods are an advanced type of machine- learning algorithms that have been gaining visibility in the last decade. Following computational developments, they are capable of extracting and classifying features automatically when a large amount of training data is given [52] . The most commonly used architectures for medical image segmentation are based on the U- net [53] . Belghith et al. [54] addressed the segmentation problem by im- proving an existing machine learning based method by Lee et al. [45] . In [45] , the estimation of the layers highly depends on the accuracy of the estimated gradient-based transitions, which can be a major drawback for low quality and noisy images, particularly in the BMO area. To overcome this, the authors proposed the use of a artificial neural network (ANN) and principal component analysis (PCA) [55] . That way, the elliptical shape of the BM curve can be modeled, obtaining a more accurate estimate of the ONH size. Among the authors that used a U-net as a basis for their algo- rithm are Chen et al. [56] , who proposed a method consisting of three steps. First, a coarse detection based on the RPE layer and ONH segmentation in 2D projection image was applied. Then, a U-net was used to improve the accuracy of the coarse detection. Finally, a post processing algorithm removes the outliers. The loss function was a combination of Dice loss with an area bias and the mean square error loss. In [57] , the aim was to segment the BMO. To that end, three deep learning based approaches were used and compared while evaluating the effect of the input size: an artificial neural network (ANN) where the input is an A-scan, a patch based convolutional neural network (CNN) method where the input is a group of con- secutive A-scans and a U-net where the input is a B-scan. The approach proposed by [58] includes an optic disc detection network, a retinal layers detection network and a fusion module. They use a multi-scale GCN-assisted U-shape network (MGU-Net) to address the multi-scale features and exploit existing anatomical knowledge, and to segment the retinal layers and the optic disc region. In [59] , the aim was to segment the BMO termination points and the LC anterior surface to extract clinically relevant parameters such as the LC depth, the LC curvature, and the LC curvature index. For this purpose, they had an object detection mechanism which used the YOLOv3 based Darknet-53 model [60] and a semantic segmentation consisting of an attention U-Net model. Finally, post- processing is performed by applying a polynomial regression curve that estimates the curve of the anterior LC boundary, based on the acquired BMO and LC information from the model. In [61] , the aim was layer segmentation. The proposed method, a semi-supervised generative adversarial network (GAN) [62] , al- lowed for the training of the network with smaller datasets while taking advantage of unlabeled scans. Additionally, a Faster Region CNN [63] was used to segment the BMO from the volumes. The last three deep learning approaches, all developed by De- valla et al. [17,64,65] , present different architectures for segmen- tation. The aim in [64] was to segment six neural and connec- tive tissue structures in OCT images of the ONH: the RNFL and the prelamina, the RPE, the set of remaining retinal layers, the choroid, the peripapillary sclera, and the LC. After pre-processing all B-scans with adaptive compensation [66] , they used a two di- mensional CNN that was trained with manually segmented images. This approach does not offer a precise separation between the LC and the sclera. This drawback was tackled in [65] , which proposes an architecture combining a U-net and residual blocks. The goal is to extract the same six regions of the ONH by capturing both the contextual and local information while taking advantage of resid- ual connections to improve the flow of the gradient information through the network. When compared to [64] , the results showed 5 R. Marques, D. Andrade De Jesus, J. Barbosa-Breda et al. Computer Methods and Programs in Biomedicine 220 (2022) 106801 that the new architecture performed better for all the tissues ex- cept for theRPE, where they performed similarly. Finally, the work in [17] attempted to address one of the main obstacles for the automatic segmentation of the ONH in the clini- cal environment: the lack of device-independent segmentation al- gorithms. One of the key elements of the proposed framework was a pre-processing enhancement step, which makes use of a deep learning network to improve the quality of OCT B-scans and to har- monize image characteristics across OCT devices. The authors [17] found that the use of 3D CNNs could further improve the reliability of the automatic segmentation by consider- ing depth-wise spatial information from adjacent images. The pro- posed architecture combined three segmentation CNNs based on the 3D U-net. Each of the three 3D CNNs offered an equally plau- sible segmentation. However, the segmentation of ambiguous re- gions, such as the sclera and the LC, can differ considerably be- tween networks with different structures. Therefore, an ensembler was used to combine the predictions from the three networks, giv- ing a more robust segmentation in the end. 3.4. Evaluation and validation A summary of the most representative results of the reviewed works can be found in Tables 1 and 2 . Several outcomes can be used to evaluate a segmentation. These outcomes can be either a segmented tissue, such as the ILM, the LC, the RNFL, the RPE, the other retinal layers and the choroid, or it can be a biomarker re- lated to a segmented tissue, such as the BMO and optic cup de- tection, the BMO-MRW, the CDR and the ONH surface depth. For each of these outcomes the metrics used for their evaluation and the quantitative results reported are presented. One of the metrics mentioned in table 1 is the failure rate. This metric was proposed by Belghith et al. [38,54] and it compares the automatic segmentation with the ground truth. A failure rate of 0 is obtained when the mean difference < 3 pixels, of 1 when the mean difference < 5 pixels and of 2 when the mean difference > 5 pixels. Even though three works reported a region segmentation of the LC [17,65,67] , no values are reported in Table 2 . Given the sub- jectivity in the visibility of the posterior LC boundary, the groups were only able to do a qualitative assessment of the segmentation of the LC. From the analysed pool, two of the works studied not only eval- uate if the qualify of the segmentation was good, but also if the parameters obtained from the automatic segmentation were able to correctly classify data from the different groups. Ramzan et al. [22] evaluated the performance of the computed CDR in separating healthy from glaucomatous eyes, and it showed an average sensi- tivity of 87%, specificity of 73%, and accuracy of 79%. Syga et al. [35] validated their model on a dataset from 255 subjects, obtained a 68% accuracy and 0.66 area under the curve (AUC) in distinguish- ing primary open angle glaucoma (POAG) patients from controls (p-value < 0.001), 64% and 0.585 between suspects with glaucoma- tous ONH appearence (GODA) and controls (p-value < 0.015), and 56% and 0.561 between patients and suspects (p-value = 0.333) based on the mean LC index (total shape of the LC parameteriza- tion based on the fourth-order polynomial fit). 4. Discussion The present review collects and summarizes the existing auto- matic algorithms for the segmentation of the ONH in OCT scans. It shows that improvements are necessary in the field since there is a limited number of studies, with great diversity in the size and type of datasets used, segmented regions and validation methods, which precludes a comparison between studies. Boundary segmen- tation was the starting point for the detection of the ONH and its layers. However, as methods developed, region segmentation has also been proposed. Traditional methods focused mainly on segmenting boundaries, through the detection of BMO points, the ILM and the RPE limits. For the LC, only the anterior surface could be detected, which lim- ited the parameters that could be extracted with these methods. In medical imaging segmentation tasks, it is often assumed that the surfaces are continuous, which is not the case for the ONH in which surfaces converge to a hole. This can be a problem when segmenting structures with multiple interacting surfaces, such as in OCT volumes of the ONH. Since machine-learning methods were mostly applied after tra- ditional methods, they were often able to address segmentation problems that had remained unanswered with prior methods. Par- ticularly, for accurately identifying the optic cup, for which pattern recognition played an important role. Miri et al. [43] were able to improve the unsigned border error of BMO-MRW from previous methods by at least 4 μm (26.65 ± 13.27 μm and 22.22 ± 5.99 μm). Deep learning methods have been gaining visibility for their success in other medical imaging processing and analysis, and can be the future of research in this field [68] . Using deep learning, [56] was able to outperform the mean error of previous BMO seg- mentation by at least 7 μm. Moreover, only deep learning based algorithms have been able to perform a region segmentation of several tissues of the ONH. Devalla et al. were able to accurately segment almost all connective and neural tissues with sensitivi- ties and specificities around or above 90%, except for the LC, that despite improvements, remains a challenge due to low signal-to- noise ratio. Most of the deep learning based methods analysed in this review were improvements on the U-net network that were compared with other deep learning architectures to reflect the ad- vantages of the methods [56–58,65] . For example, Devalla et al. [17] improved the segmentation of 2D U-net network expanding to a 3D U-net network by considering depth-wise spatial informa- tion from adjacent B-scans. However, in most cases, the available OCT data is limited and labels of the different structures are lack- ing. Therefore, as shown by Devalla et al. [17] , the segmentation of ambiguous regions, such as the sclera and the LC, can be improved by further expanding the U-net and combining the output of dif- ferent networks, giving a more robust segmentation in the end. One of the main purposes of automatic segmentation algo- rithms is the extraction of biomarkers, obtained by measuring the different segmented tissues. An extensive review of proposed biomarkers is out of the scope of this review, since several works compute these biomarkers in a manual or semi-automatic way, so the articles selected, focused on the automatic segmentation of the OHN, do not represent the whole picture. Still, in the con- text of OCT images of the OHN, the majority of biomarkers are related with the diagnosis and/or progression of ocular diseases like myopia [69] , central vein occlusion [70] , and glaucoma [71] . Some studies tackling the characterization of healthy individuals [72] also exist. Regarding the main structures measured, the LC has gained much interest in recent years, with extensive applications in many ophthalmic and non ophthalmic diseases [15] , and also healthy populations [72] . The LC load-bearing connective tissue compo- nents comprise about 40% of the tissue volume in the laminar re- gion of the ONH [73] . Adding to its anatomical location, the LC be- comes a weak spot with the conflicting tasks of providing struc- tural and nutrient support to the axons while withstanding me- chanical strain [73] . When compressed above a certain point, the LC can be deformed, compromising axonal transport and tissue remodeling by reactive astrocytes [4] , as well as the diffusion of 6 R. Marques, D. Andrade De Jesus, J. Barbosa-Breda et al. Computer Methods and Programs in Biomedicine 220 (2022) 106801 Table 1 Results from the boundary based segmentations. Outcome Metrics Results BMO Correlation with ground truth Error compared with ground truth Mean unsigned error Mean signed error Dice similarity coefficient Failure rate Mean average precision Manhattan distance Euclidean distance Accuracy F1 score Dice coefficient Mean unsigned error BMO-MRW Mean signed error; Optic Cup CDR ILM LC RMSE Correlation with ground truth Error compared with ground truth Mean unsigned error Dice similarity coefficient Error compared with ground truth Sensitivity Specificity Accuracy Mean unsigned error Mean Dice coefficient Error compared with ground truth Mean Euclidean distance error Failure rate Accuracy Difference Hausdorff distance 0.93 [26] 32.03 ± 58.68 μm [19] 12.4 ± 12.1 pixels [49] 2.8 pixels (normal) and 3.1 pixels (glaucoma) [50] 54.18 ± 53.74 μm [37] 60.00 ± 42.00 μm [40] 49.28 ± 16.78 μm [43] 42.38 ± 18.33 μm [56] . 61.86 ± 61.97 μm (x axis) and 12.40 ± 11.24 μm (z axis) [8] 49.53 ± 30.41 μm (x axis) and 31.58 ± 21.06 μm (z axis) [46] 37.98 ± 14.91 μm (x axis) and 22.28 ± 8.58 μm (z axis) [43] 9.80 ± 31.90 μm [57] 0.023 mm [44] 0.026 mm [45] -7.69 ± 87.27 μm (x axis) and.41 ± 16.69 μm (z axis) [8] 26.49 ± 40.22 μm (x axis) and 25.45 m 14.37 μm (z axis) [46] -9.49 ± 24.58 μm (x axis) and 8.33 ± 17.72 μm (z axis) [43] 0.925 ± 0.030 [41] 0.959 ± 0.032 [57] 0.65 ± 0.14 [45] 0 in 92.5% of the scans [54] 0.8547 for glaucoma and 0.9567 for control subjects [61] . 39.23 ± 40.54 μm [59] 31.46 ± 30.95 μm [59] 98% [69] 99% [59] 25% [59] 58.62 ± 43.12 μm [37] 26.65 ± 13.27 μm [46] 22.22 ± 5.99 μm [43] 6.61 ± 18.59 μm [46] -0.30 ± 12.44 μm [43] 17.99 ± 8.15 μm [46] 11.62 ± 4.63 μm [43] 0.80 [26] 3.4 pixels (normal) and 3.6 pixels (glaucoma) [50] 0.009 mm [44] 0.038 mm [45] 0.85 ± 0.06 [45] 0.045 ± 0.033 [40] 86.2 ± 7.1% [24] 86.2 ± 9.8% [24] 85.5 ± 5.2% [24] 5.38 ± 4.23 μm [41] 0.97 [61] 4.80 μm [21] 7.08 ± 3.7 pixels [22] 7.03 ± 3.72 pixels [23] 0 in 73.7% of the scans [38] 90.6% [29] 8.35 ± 3.73 μm [59] 92.89 ± 78.74 μm [59] ONH surface depth Error compared with ground truth 0.7 ± 1.0 % [41] . nutrients from the capillaries [74] . The most extracted biomark- ers correspond to the LC depth (LCD), LC thickness (LCT), global shape index and LC curvature index (LCCI) [15] . However, other features such as the LC pore pathways were also studied [71] as possible biomarkers for glaucoma. In the latter, they found that pores of glaucoma eyes present more tortuous paths, when com- pared with healthy eyes. Moreover, being significantly different be- tween healthy patients and ocular and systemic pathologies while being patient-specific features [15] , LC features are seen as increas- ingly promising for patient follow-up as well. As an example, LC changes with increasing disease severity [75] and after IOP lower- ing surgery [76] have become a hot topic of research. Therefore, the current lack of accuracy in detecting the LC can affect diagno- sis and follow-up and automatic accurate methods are warranted in routine clinical practice. The clinical relevance of the BMO-MRW has also been reported to have an important role in the assessment of glaucoma [77] and myopia [69] . In the latter, authors have found that the BMO area 7 R. Marques, D. Andrade De Jesus, J. Barbosa-Breda et al. Computer Methods and Programs in Biomedicine 220 (2022) 106801 Table 2 Results from the region based segmentation. Outcome Metrics Results RNFL + prelamina RPE Other retinal layers Choroid Optic disc Dice coefficient 0.82 ± 0.05 [21] Sensitivity Specificity 0.92 ± 0.05 (healthy) and 0.92 ± 0.03 (glaucoma) [20] 0.89 ± 0.04 [21] 0.99 [21] 0.99 [20] . 0.93 ± 0.02 [21] Accuracy Dice coefficient 0.84 ± 0.02 [21] Sensitivity Specificity 0.83 ± 0.04 (healthy) and 0.84 ± 0.03 (glaucoma) [20] Mean for all tissues: Sensitivity: 0.94 ± 0.02 (Spectralis), 0.93 ±0.02 (Cirrus) and 0.93 ± 0.02 (RTVue) [19] . Specificity: 0.99 for 0.90 ± 0.03 [21] Spectralis, Cirrus and RTVue [19] . 0.99 [21] 0.99 [20] 0.93 ± 0.02 [21] Accuracy Dice score 82.6 ± 0.1 % [51] Dice coefficient 0.86 ± 0.03 [21] Sensitivity Specificity 0.95 ± 0.01 for healthy and 0.96 ± 0.03 for glaucoma [20] 0.98 ± 0.02 [21] 0.99 [21] 0.99 [20] Accuracy 0.98 ± 0.01 [21] Dice coefficient 0.85 ± 0.02 [21] Sensitivity Specificity Accuracy Dice score Dice score Pixel accuracy 0.90 ± 0.03 for healthy and 0.91 ± 0.05 for glaucoma [20] 0.91 ± 0.02 [21] 0.99 [21] 0.99 [20] 0.93 ± 0.01 [21] 89.2 ± 0.2 % [51] 86.1 ± 1.2 % [51] 82.1 ± 0.7 % [51] is larger in myopic children compared to non-myopic children. Regarding glaucoma, BMO-MRW has shown a similar diagnostic yield when compared to the ”traditional” RNFL, with a higher AUC achieved when combining both [78] , being that authors have also already shown this through a neural network [79] . Moreover, BMO- MRW seems to be increasingly useful to distinguish glaucoma from anterior ischemic optic neuropathy (AION) [80] , which sometimes poses a diagnostic dillema and a situation where RNFL has many pitfalls. The OHN OCT segmentation can also be used in combination with other imaging modalities to obtain multi-modal biomarkers. Such is the case in Mokhtari et al. [81] , where the cup to disc ra- tio was determined in right and left eyes in healthy and diseased subjects using fundus images and OCT B-scans. The authors pro- posed the use of a volumetric local CDR symmetry analysis as a new biomaker for glaucoma detection. Further following the idea of characterizing the shape of the structures, Panda et al. [82] propose to describe the structural phe- notype of the glaucomatous optic nerve head using an autoencoder to learn features from the previously segmented OCT ONH images. They have found that by using a number of latent variables up to the size of 54, a diagnotics accuracy of 94% was achieved. These ar- tificial intelligence biomarkers were further reduced to a 2D space using uniform manifold approximation and projection, to provide the able to capture the structural changes of the ONH region in a low dimensional latent space. Altogether, the values of the parameters extracted from the seg- mentations showed significant differences between healthy and pathological groups. Methods such as the ones developed by Ramzan et al. [22] and Syga et al. [35] already achieved sensitiv- ities of 87% and 81% in distinguishing healthy from pathological groups. This summary of used biomarkers provide insight over the im- plications of imprecise automatic segmentation methods. Some of the determined biomarkers, like the BMO, rely on the correct de- termination of very few points. When segmentation fails, an in- correct value for the biomarker could be determined leading to a mislead diagnosis. Datasets with data from less than 40 patients were often used. Even though a lot of imaging data are being acquired in clini- cal practice, these data are rarely labelled and/or publicly avail- able. The time consuming process of manual labelling by ex- perts, combined with the scarcity of publicly available segmented datasets, may cause further delays in technology development, since time is lost in repeating steps that have already been done and validated by previous groups. This is particularly problem- atic for supervised deep learning methods since they need more data to yield accurate results. However, future work may focus on label-free/unsupervised learning since it will ease the burden of manual labelling (however, it will not solve the lack of OCT data itself). Therefore, efforts to make more clinical data avail- able and create sharing practices/protocols between groups could further accelerate research, allowing more studies to be done more effectively, which will close the gap to automation in the clinic. One limitation of this review is that, since the liter- ature search was made on MEDLINE (Pubmed) and Sco- pus bibliographic databases only, some technical studies might have been missed. By considering only articles with de- tailed descriptions on the algorithm used, the number of in- cluded articles was shortened since otherwise a review of the method would not be possible. Moreover, studies which were solely published as congress abstracts were excluded from this review. 8 Table 3 Characteristics of the reviewed studies Category Authors Dataset Regions Segmented Validation Results Technique Device Comparison with the ground truth. High correlation between automatic and manual cup and disk limits. - OCT 3000 from Zeiss- Humphrey Conventional [26] 59 glaucoma B-scans Conventional [37] 13 glaucoma scans Retinal-vitreal boundary, limits of the OD, retinal-choroid boundaries. ILM, BMO, HRC, RNFL, RPE, OD boundary Conventional [38] 50 healthy scans and 50 glaucoma scans LC anterior surface Comparison with ground truth and existing method. Confusion matrix based metrics. Distance metrics. Comparison with ground truth. Statistical tests. Conventional [20] no info ILM, BMO Comparison with ground truth. Conventional [19] 40 healthy scans RPE break points, RPE boundary Comparison with ground truth. Robust segmentation over noise and pathology. SD-OCT Spectralis High similarity between manual and automatic segmentation. Significant correlation between changes in IOP and the position of the LC. Accurate segmentation of the ONH structure. Not sensitive to the differentiation of blood vessels from the ONH surface. Accurate segmentation of the OD boundary. EDI SD-OCT Spectralis SD-OCT Spectralis no info SD-OCT Topcon model of 3D-1000 unit Spectralis Conventional [21] 9Conventional [24] 71 healthy scans and 345 pathological scans (31 IIH + 60 NMOSD + 252 MS) 22 healthy scans and 28 glaucoma scans ILM ILM and RPE Statistical tests. Comparison with segmentation from a device. Distance metrics. Visual evaluation. Robust segmentations over variations in ONH topology. Outperforms device segmentation. Comparison with ground truth. Comparison with computed generated values. Comparison with existing methods [83–85] . Comparison with ground truth. Distance metrics. Outperforms existing methods and computer generated values. SD-OCT no info Successfully captures the differences between pathological groups. SD-OCT Spectralis RPE, BMO Points, ILM and BMO. Conventional [8] Conventional [22] Conventional Conventional [23] [35] 71 healthy scans and 177 pathological scans (31 IIH + 146 autoimmune central nervous system disorders) 50 scans from healthy and glaucoma patients 50 scans from healthy and glaucoma patients 86 healthy scans and 169 glaucoma scans ILM and RPE ILM ILM, BM points and LC Comparison with ground truth. comparison with computer generated values. Confusion matrix based metrics. Comparison with ground truth. Distance metrics. Visual evaluation. Statistical tests. Confusion matrix based metrics. Conventional [29] 72 glaucoma scans LC anterior surface Comparison with ground truth. Visual evaluation. High correlation with ground truth. Outperforms existing techniques. TOPCON’S 3D OCT-1000 Accurate segmentation. SD-OCT Topcon Statiscally significant differences between glaucoma patients (POAG and GODA) and healthy controls. The mean LC shapes for POAG and GODA were not significantly different. Segmentation accuracy is significantly higher when a deep learning noise reduction algorithm is used than in raw images. EDI OCT Spectralis SS-OCT Topcon ( continued on next page ) R.Marques,D.AndradeDeJesus,J.Barbosa-Bredaetal.ComputerMethodsandPrograms inBiomedicine220(2022)106801          Table 3 ( continued ) Category Authors Dataset Regions Segmented Validation Results Standard Machine learning Standard Machine learning Standard Machine learning Standard Machine learning Standard Machine learning Standard Machine learning Standard Machine learning Standard Machine learning [44] 30 glaucoma scans 3 intraretinal surfaces, OD boundary Comparison with ground truth. Distance metrics. [45] 27 glaucoma scans 4 intraretinal surfaces, OD boundary Comparison with the ground truth. Distance metrics. Confusion matrix based metrics. [46] 44 glaucoma scans BM, intraretinal surfaces, ONH hole [40] 42 glaucoma scans ILM, RPE [49] [50] [43] [41] 48 healthy scans ILM, RPE, OD boundary 25 glaucoma B-scans 69 glaucoma scans Retinal layers, OD boundary ILM, (IS/OS), BM 30 healthy scans and 35 glaucoma scans 100 healthy scans and 105 glaucoma scans RNFL, retinal layers, RPE/Bruchs complex and OD boundary BM Comparison with ground truth and existing methods. Distance metrics. Confusion matrix based metrics. Comparison with ground truth and existing method. Distance metrics. Confusion matrix based metrics. Comparison with ground truth and other methods. Comparison with ground truth. Comparison with ground truth and existing methods. Distance metrics. Statistical tests. Comparison with ground truth and existing methods. Confusion matrix based metrics. Distance metrics. Comparison with ground truth, values from the device and other methods. Statistical tests. Confusion matrix based metrics. Statistical tests. Deep learning [54] 10No signifficant differences between the unsigned errors of the optic cup and disk, before and after feature selection. Contextual 9-k-NN outperforms the regular k-NN classifier when no post processing is applied. Performance of 9-k-NN classifier is significantly better with post processing. Outperforms existing methods [45,86] . Technique HD-OCT Device Cirrus HD-OCT Cirrus SD-OCT Cirrus Outperforms existing methods [45] . SD-OCT Cirrus Outperforms existing methods [26] . SD-OCT Topcon Correct segmentation in normal and glaucoma affected images. Outperforms existing methods [46] . no info no info HD-OCT Cirrus Outperforms existing methods [87,88] . SD-OCT Topcon High correlation with ground truth and built-in software of the device. Significant differences between glaucoma and healthy eyes. Good performance for all tissues in glaucoma and healthy images. Performs better with compensated images. EDI SD-OCT Cirrus and Spectralis EDI SD-OCT Spectralis Deep learning [67] 40 healthy scans and 60 glaucoma scans Deep learning [65] 40 healthy scans and 60 glaucoma scans Deep learning Deep learning [56] [61] 30 glaucoma scans 42 healthy scans and 80 glaucoma scans Deep learning [17] 225 healthy scans and 225 glaucoma scans Deep learning Deep learning [57] [58] Deep learning [59] 102 healthy scans and 223 glaucoma scans 122 scans (myopia, peripapillary atrophy and cataract) 600 scans (healthy and glaucoma) RNFL and the prelamina; RPE; all other retinal layers; the choroid; the peripapillary sclera and the LC; RNFL and the prelamina; RPE; all other retinal layers; choroid; peripapillary sclera; LC; OD boundary, RPE, BMO points ILM, RNFL, BM, choroid-sclera boundary; BMO points RNFL and prelamina; ganglion cell complex; all other retinal layers; RPE; choroid; LC BMO RNFL, GCL, IPL, INL, OPL, ONL, IS/OS, RPE, choroid, and ONH BMO points and LC anterior surface Confusion matrix based metrics. Comparison with the ground truth and with existing methods. Comparison with ground truth. Confusion matrix based metrics. Statistical tests. Confusion matrix based metrics. Visual evaluation. Statistical tests. Comparison with ground truth. Confusion matrix based metrics. Distance metrics. Comparison with existing methods [53,65,89] . Consusion matrix based metrics. Comparison with ground truth. Confusion matrix based metrics. Distance metrics. Good performance for all tissues in glaucoma and healthy images. No significant differences in segmentation performances with compensated and uncompensated images. Outperforms existing methods [37,40,43] . No statistically significant difference between BMO segmentation and ground truth. Thickness parameters were highly correlated. Networks trained in any of the devices, successfully segmented images from other devices with high performances in all tissues. U-net like architecture with B-scans as input had the best performance. Improved retinal tissues segmentation. EDI OCT Spectralis SD-OCT Topcon SS-OCT SD-OCT custom-built OCT Spectralis, Cirrus and RTVue SD-OCT Spectralis SD-OCT Topcon High correlation with ground truth. SD-OCT Spectralis R.Marques,D.AndradeDeJesus,J.Barbosa-Bredaetal.ComputerMethodsandPrograms inBiomedicine220(2022)106801          R. Marques, D. Andrade De Jesus, J. Barbosa-Breda et al. Computer Methods and Programs in Biomedicine 220 (2022) 106801 5. Conclusion References Manual segmentation of OCT images is a time consuming and user dependent procedure which is often necessary to retrieve im- portant biomarkers for disease diagnosis and/or progression. This is particularly important in the ONH due to the growing interest in biomarkers in this region, which can be now computed due to the technical improvements of OCT devices in the last years. This review highlights algorithms that automatically segment several structures and boundaries from ONH centered OCT scans. From these automatic segmentations, several parameters can be automatically extracted which may be relevant for clinical prac- tice. In this scope, standard machine learning and deep learning algorithms have the upper hand. In a global perspective over this field, there is not a clear con- sensus on the methodology that must be followed to segment the OHN, including which images to acquire and how to manu- ally label them, resulting in weak conclusions over which method should be used to segment OCT images from the ONH. This is caused, for example, by the diversity of OCT devices, each with their unique image patterns due to different hardware, different image reconstruction, and different post-processing algorithms ap- plied. Another sources of variation are the different studied dis- eases, each with their unique morphological changes, the regions that are manually segmented which may be defined differently depending on their importance for the studied disease, and the methods used for validation. All these factors make direct compar- ison between studies difficult. In order to standardize the studies and reach an endpoint, re- searchers should converge to a set of guidelines to increase the methodological coherence of future works. For example, any new segmentation algorithm should be tested in sufficient healthy and diseased subjects; multiple graders should be used to minimize human error; inter-operator variability should be studied; the val- idation methods should eliminate the effect of data selection (for example cross-validation); larger datasets should be used for train- ing and validation in order to increase the study applicability; at- tention to, and description of, the image acquisition settings and the processing algorithms used in the acquisition devices must be provided. Only by following a pre-defined set of rules it will be possible to compare studies and increase the trust in these data- driven models, which will possibly result in their embrace for clin- ical practice, which can only happen when OCT software easily provide trustworthy metrics, such as the currently used RNFL and BMO-MRW. This could allow a more accurate follow up patients and pre/post surgical evaluations, since the LC is one of the loca- tions more prone to change after IOP reduction. Declaration of Competing Interest The authors have no relevant financial interests in this article and no potential conflicts of interest to disclose. On behalf of all co-authors, I confirm this work is original and has not been published nor is it currently under consideration for publication elsewhere. We also would like to declare that we have no conflicts of interest to disclose. Acknowledgments This work was supported by the Horizon 2020 Research and In- novation Programme (grant agreement no. 780989: Multi-modal, multi-scale retinal imaging project) and by Portuguese National Funds through the FCT, Funda Ⱥ o Para a Ci Ȭ ncia e a Tecnologia, I.P., in the scope of the project UIDB/04559/2020. [1] I.A. Sigal , J.G. Flanagan , C.R. Ethier , Factors influencing optic nerve head biome- chanics, Investigative Ophthalmology and Visual Science 46 (2005) 4189–4199 . [2] N.Y. Tan , V. Koh , M.J. Girard , C.Y. Cheng , Imaging of the lamina cribrosa and its role in glaucoma: a review, Clinical and Experimental Ophthalmology 46 (2018) 177–188 . [3] A. Bekkers , N. Borren , V. Ederveen , E. Fokkinga , D. Andrade De Jesus , L. Sánchez Brea , S. Klein , T. van Walsum , J. Barbosa-Breda , I. Stalmans , Microvascular dam- age assessed by optical coherence tomography angiography for glaucoma diag- nosis: a systematic review of the most discriminative regions, Acta ophthalmo- logica 98 (2020) 537–558 . [4] S.H. Lee , T.W. Kim , E.J. Lee , M.J. Girard , J.M. Mari , Diagnostic power of lamina cribrosa depth and curvature in glaucoma, Investigative Ophthalmology and Visual Science 58 (2017) 755–762 . [5] D.A. De Jesus , L.S. Brea , J.B. Breda , E. Fokkinga , V. Ederveen , N. Borren , A. Bekkers , M. Pircher , I. Stalmans , S. Klein , et al. , Octa multilayer and mul- tisector peripapillary microvascular modeling for diagnosing and staging of glaucoma, Translational Vision Science & Technology 9 (2020) . 58–58 [6] D.A. Jesus , J.B. Breda , K. Van Keer , A .R. Sousa , L.A . Pinto , I. Stalmans , Quanti- tative automated circumpapillary microvascular density measurements: a new angiooct-based methodology, Eye 33 (2019) 320–326 . [7] G. Xu , R.N. Weinreb , C.K. Leung , Optic nerve head deformation in glaucoma: The temporal relationship between optic nerve head surface depression and retinal nerve fiber layer thinning, Ophthalmology 121 (2014) 2362–2370 . [8] S.K. Yadav , E.M. Kadas , S. Motamedi , K. Polthier , F. Haußer , K. Gawlik , F. Paul , A. Brandt , Optic nerve head three-dimensional shape analysis, Journal of biomedical optics 23 (2018) 106004 . [9] D. Cabrera DeBuc , M. Gaca-Wysocka , A. Grzybowski , P. Kanclerz , Identifica- tion of retinal biomarkers in alzheimer’s disease using optical coherence to- mography: Recent insights, challenges, and opportunities, Journal of Clinical Medicine 8 (2019) 996 . [10] S. Lemmens , T. Van Craenendonck , J. Van Eijgen , L. De Groef , R. Bruffaerts , D.A. de Jesus , W. Charle , M. Jayapala , G. Sunaric-Mégevand , A. Standaert , et al. , Combination of snapshot hyperspectral retinal imaging and optical coherence tomography to identify alzheimers disease patients, Alzheimer’s research & therapy 12 (2020) 1–13 . [11] M. Eraslan , E. Cerman , S. Yildiz Balci , H. Celiker , O. Sahin , A. Temel , D. Suer , N. Tuncer Elmaci , The choroid and lamina cribrosa is affected in patients with parkinson’s disease: Enhanced depth imaging optical coherence tomography study, Acta Ophthalmologica 94 (2016) e68–e75 . [12] H.Y.L. Park , S.H. Jeon , C.K. Park , Enhanced depth imaging detects lam- ina cribrosa thickness differences in normal tension glaucoma and primary open-angle glaucoma, Ophthalmology 119 (2012) 10–20 . [13] H.L. Takusagawa , A. Hoguet , A.K. Junk , K. Nouri-Mahdavi , S. Radhakrish- nan , T.C. Chen , Swept-source OCT for evaluating the lamina cribrosa: A re- port by the american academy of ophthalmology, Ophthalmology 126 (2019) 1315–1323 . [14] J.M. Mari , N.G. Strouthidis , S.C. Park , M.J. Girard , Enhancement of lamina cribrosa visibility in optical coherence tomography images using adaptive compensation, Investigative Ophthalmology and Visual Science 54 (2013b) 2238–2247 . [15] A. Paulo , P.G. Vaz , D. Andrade De Jesus , L. Sánchez Brea , J. Van Eijgen , J. Car- doso , T. van Walsum , S. Klein , I. Stalmans , J. Barbosa Breda , Optical coherence tomography imaging of the lamina cribrosa: Structural biomarkers in nonglau- comatous diseases, Journal of Ophthalmology 2021 (2021) . [16] A . Lang , A . Carass , M. Hauser , E.S. Sotirchos , P.A. Calabresi , H.S. Ying , J.L. Prince , Retinal layer segmentation of macular OCT images using boundary classifica- tion, Biomedical Optics Express 4 (2013) 1133 . [17] S.K. Devalla, T.H. Pham, S.K. Panda, L. Zhang, G. Subramanian, A. Swaminathan, C.Z. Yun, M. Rajan, S. Mohan, R. Krishnadas, V. Senthil, J.M.S. de Leon, T.A. Tun, C.Y. Cheng, L. Schmetterer, S. Perera, T. Aung, A.H. Thiéry, M.J. Girard, Towards label-free 3d segmentation of optical coherence tomography images of the op- tic nerve head using deep learning, arXiv:2002.09635 11 (2020) 6356–6378. [18] J. Fujimoto , E. Swanson , The development, commercialization, and impact of optical coherence tomography, Investigative Ophthalmology and Visual Science 57 (2016) OCT1–OCT13 . [19] M. Mokhtari, H. Rabbani, A. Mehri-Dehnavi, R. Kafieh, Exact localization of breakpoints of retinal pigment epithelium in optical coherence tomography of optic nerve head, IEEE, 2017. 2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), 1505–1508 [20] M.W. Ko , C.K. Leung , T.Y. Yuen , Automated segmentation of optic nerve head for the topological assessment, 2016 Global Medical Engineering Physics Ex- changes/Pan American Health Care Exchanges, GMEPE/PAHCE 2016 (2016) 4–7 . [21] K. Gawlik , F. Hausser , F. Paul , A.U. Brandt , E.M. Kadas , Active contour method for ILM segmentation in ONH volume scans in retinal OCT, Biomedical Optics Express 9 (2018) 6497 . [22] A. Ramzan , M.U. Akram , A. Shaukat , S.G. Khawaja , U.U. Yasin , Automated glau- coma detection using retinal layers segmentation and optic cup to disc ratio in OCT images, IET Image Processing 13 (2018) 2–14 . [23] A. Ramzan , M.U. Akram , J. Ramzan , Q.U.A. Mubarak , A .A . Salam , U.U. Yasin , Automated inner limiting membrane segmentation in OCT retinal images for glaucoma detection, 857, Springer International Publishing, 2019 . [24] T. Khalil , M.U. Akram , H. Raja , A. Jameel , I. Basit , Detection of glaucoma using cup to disc ratio from spectral domain optical coherence tomography images, IEEE Access 6 (2018) 4560–4576 . 11 R. Marques, D. Andrade De Jesus, J. Barbosa-Breda et al. Computer Methods and Programs in Biomedicine 220 (2022) 106801 [25] E.J. Candès , D.L. Donoho , Ridgelets: A key to higher-dimensional intermittency? Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 357 (1999) 2495–2509 . [26] K.L. Boyer , A. Herzog , C. Roberts , Automatic recovery of the optic nerve- head geometry in optical coherence tomography, IEEE Transactions on Medical Imaging 25 (2006) 553–570 . [27] D. Koozekanani , K. Boyer , C. Roberts , Retinal thickness measurements from op- tical coherence tomography using a markov boundary model, IEEE transactions on medical imaging 20 (2001a) 900–916 . [28] D. Koozekanani , S. Member , K. Boyer , S. Member , C. Roberts , Coherence tomog- raphy using a markov boundary model, IEEE transactions on medical imaging 20 (2001b) 900–916 . [29] Z. Mao , A. Miki , S. Mei , Y. Dong , K. Maruyama , R. Kawasaki , S. Usui , K. Mat- sushita , K. Nishida , K. Chan , Deep learning based noise reduction method for automatic 3d segmentation of the anterior of lamina cribrosa in optical coher- ence tomography volumetric scans, Biomedical Optics Express 10 (2019) 5832 . [30] J.R.D. Errico , Understanding gridfit the mechanical and philosophical underpin- nings, Methodology 1 (2006) 1–6 . [31] J. D’Errico, Surface fitting using gridfit matlab central file ex- https://www.mathworks.com/matlabcentral/fileexchange/ change, 8998- surface- fitting- using- gridfit , Retrieved March 16, 2021. 2021, [32] K. Cheng , T. Xiao , Q. Chen , Y. Wang , Image segmentation using active con- tours with modified convolutional virtual electric field external force with an edge-stopping function, PLoS ONE 15 (2020) 1–14 . [33] T.F. Chan , L.A. Vese , Active contours without edges, IEEE Transactions on Image Processing 10 (2001) 266–277 . [34] E.M. Kadas , F. Kaufhold , C. Schulz , F. Paul , K. Polthier , A.U. Brandt , 3d optic nerve head segmentation in idiopathic intracranial hypertension, Informatik aktuell (2012) 262–267 . [35] P. Syga , C. Sieluzycki , P. Krzyzanowska-Berkowska , D.R. Iskander , A fully auto- mated 3d in-vivo delineation and shape parameterization of the human lam- ina cribrosa in optical coherence tomography, IEEE Transactions on Biomedical Engineering 66 (2019) 1422–1428 . [36] P. Singhal, A. Verma, A review on graph based segmentation techniques, IEEE, 2016. 2016 10th International Conference on Intelligent Systems and Control (ISCO), 1–6 [37] M.A . Hussain, A . Bhuiyan, K. Ramamohanarao, Disc segmentation and bmo- mrw measurement from sd-oct image using graph search and tracing of three bench mark reference layers of retina, IEEE, 2015. 2015 IEEE International Con- ference on Image Processing (ICIP), 4087–4091 [38] A. Belghith , C. Bowd , F.A. Medeiros , R.N. Weinreb , L.M. Zangwill , Automated segmentation of anterior lamina cribrosa surface: How the lamina cribrosa re- sponds to intraocular pressure change in glaucoma eyes? Proceedings - Inter- national Symposium on Biomedical Imaging 2015-July (2015) 222–225 . [39] J. Chang, J.W. Fisher, Efficient mcmc sampling with implicit shape representa- tions, IEEE, 2011. CVPR 2011, 2081–2088 [40] M. Wu , T. Leng , L. de Sisternes , D.L. Rubin , Q. Chen , Automated segmen- tation of optic disc in SD-OCT images and cup-to-disc ratios quantification by patch searching-based neural canal opening detection, Optics Express 23 (2015) 31216 . [41] K. Yu , F. Shi , E. Gao , W. Zhu , H. Chen , X. Chen , Shared-hole graph search with adaptive constraints for 3d optic nerve head optical coherence tomography im- age segmentation, Biomedical Optics Express 9 (2018) 962 . [42] E. Rublee, V. Rabaud, K. Konolige, G. Bradski, Orb: An efficient alternative to sift or surf, Ieee, 2011. 2011 International conference on computer vision, 2564–2571 [43] M.S. Miri , M.D. Abramoff, Y.H. Kwon , M. Sonka , M.K. Garvin , A machine-learn- ing graph-based approach for 3d segmentation of bruchs membrane open- ing from glaucomatous SD-OCT volumes, Medical Image Analysis 39 (2017) 206–217 . [44] K. Lee , M. Niemeijer , M.K. Garvin , Y.H. Kwon , M. Sonka , M.D. Abràmoff, 3-d segmentation of the rim and cup in spectral-domain optical coherence to- mography volumes of the optic nerve head, Medical Imaging 2009: Biomed- ical Applications in Molecular, Structural, and Functional Imaging 7262 (2009) 72622D . [45] K. Lee , S. Member , M. Niemeijer , M.K. Garvin , Y.H. Kwon , M. Sonka , M.D. Abrà- moff, Segmentation of the optic disc in 3-d OCT scans of the optic nerve head, IEEE transactions on medical imaging 29 (2010) 159–168 . [46] B.J. Antony, M.S. Miri, M.D. Abràmoff, Y.H. Kwon, M.K. Garvin, Automated 3d segmentation of multiple surfaces with a shared hole: segmentation of the neural canal opening in sd-oct volumes, Springer, 2014. International Confer- ence on Medical Image Computing and Computer-Assisted Intervention, 739–746, [47] L. Breiman , Random forests, Machine Learning 45 (2001) 532 . [48] M.K. Garvin , M.D. Abràmoff, X. Wu , S. Member , S.R. Russell , T.L. Burns , M. Sonka , Automated 3-d intraretinal layer segmentation of macular spectral–domain optical coherence tomography images, IEEE Trans Med Imaging 28 (2009) 1436–1447 . [49] H. Fu , D. Xu , S. Lin , D.W.K. Wong , J. Liu , Automatic optic disc detection in OCT slices via low-rank reconstruction, IEEE Transactions on Biomedical Engineer- ing 62 (2015) 1151–1158 . [50] D. Paul, S. Priya, T.A. Kumar, Gmm clustering based segmentation and optic nervehead geometry detection from oct nervehead images, IEEE, 2015. 2015 Global Conference on Communication Technologies (GCCT), 376–379 [51] D.A. Reynolds , Gaussian mixture models, Encyclopedia of biometrics 741 (2009) 659–663 . 12 [52] H. Seo , M. Badiei Khuzani , V. Vasudevan , C. Huang , H. Ren , R. Xiao , X. Jia , L. Xing , Machine learning techniques for biomedical image segmentation: An overview of technical aspects and introduction to state-of-art applications, Medical physics 47 (2020) e148–e167 . [53] O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for biomed- ical image segmentation, Springer, 2015. International Conference on Medical image computing and computer-assisted intervention, 234–241, [54] A. Belghith, C. Bowd, R.N. Weinreb, L.M. Zangwill, A hierarchical framework for estimating neuroretinal rim area using 3d spectral domain optical coherence tomography (sd-oct) optic nerve head (onh) images of healthy and glaucoma eyes, IEEE, 2014. 2014 36th Annual International Conference of the IEEE Engi- neering in Medicine and Biology Society, 3869–3872, [55] M.J. Kirby , R. Miranda , Circular nodes in neural networks, Neural Computation 8 (1996) 390–402 . [56] Z. Chen , P. Peng , H. Shen , H. Wei , P. Ouyang , X. Duan , Region-segmentation strategy for bruch’s membrane opening detection in spectral domain optical coherence tomography images, Biomedical Optics Express 10 (2019) 526 . [57] D. Sułot , D. Alonso-Caneiro , D.R. Iskander , M.J. Collins , Deep learning ap- proaches for segmenting bruch’s membrane opening from oct volumes, OSA Continuum 3 (2020) 3351–3364 . [58] J. Li , P. Jin , J. Zhu , H. Zou , X. Xu , M. Tang , M. Zhou , Y. Gan , J. He , Y. Ling , et al. , Multi-scale gcn-assisted two-stage network for joint segmentation of retinal layers and discs in peripapillary oct images, Biomedical Optics Express 12 (2021) 2204–2220 . [59] M.H. Rahman , H.W. Jeong , N.R. Kim , D.Y. Kim , Automatic quantification of anterior lamina cribrosa structures in optical coherence tomography using a two-stage cnn framework, Sensors 21 (2021) 5383 . [60] J. Redmon, A. Farhadi, Yolov3: An incremental improvement, arXiv preprint arXiv:1804.02767(2018). [61] M. Heisler , M. Bhalla , J. Lo , Z. Mammo , S. Lee , M.J. Ju , M.F. Beg , M.V. Sarunic , Semi-supervised deep learning based 3d analysis of the peripapillary region, Biomedical Optics Express 11 (2020) 3843 . [62] P. Isola , J.Y. Zhu , T. Zhou , A .A . Efros , Image-to-image translation with condi- tional adversarial networks, in: Proceedings of the IEEE conference on com- puter vision and pattern recognition, 2017, pp. 1125–1134 . [63] S. Ren , K. He , R. Girshick , J. Sun , Faster r-cnn: Towards real-time object de- tection with region proposal networks, in: C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, R. Garnett (Eds.), Advances in Neural Information Processing Sys- tems, Curran Associates, Inc., 2015 . [64] S.K. Devalla, K.S. Chin, J.m. Mari, T.A. Tun, G. Nicholas, J.A. Girard, T. Aung, A.H. Thi, A deep learning approach to digitally stain optical coherence tomography images of the optic nerve head, Invest Ophthalmol Vis Sci. [65] S.K. Devalla, P.K. Renukanand, B.K. Sreedhar, S. Perera, J.M. Mari, K.S. Chin, T.A. Tun, N.G. Strouthidis, T. Aung, A.H. Thiéry, M.J. Girard, DRUNET: A dilated- residual u-net deep learning network to digitally stain optic nerve head tissues in optical coherence tomography images, arXiv:1803.00232 9(2018a) 575–584. [66] J.M. Mari , N.G. Strouthidis , S.C. Park , J.A. Girard , Enhancement of lamina cribrosa visibility in optical coherence tomography images using adaptive com- pensation, Invest Ophthalmol Vis Sci. (2013a) 2238–2247 . [67] S.K. Devalla, G. Subramanian, T.H. Pham, X. Wang, S. Perera, T.A. Tun, T. Aung, L. Schmetterer, A.H. Thiéry, M.J. Girard, A deep learning approach to denoise optical coherence tomography images of the optic nerve head, arXiv (2018b). [68] I. Rizwan I Haque , J. Neubert , Deep learning approaches to biomedical image segmentation, Informatics in Medicine Unlocked 18 (2020) 100297 . [69] A. Jnawali , H. Mirhajianmoghadam , G. Musial , J. Porter , L.A. Ostrin , The optic nerve head, lamina cribrosa, and nerve fiber layer in non-myopic and myopic children, Experimental Eye Research 195 (2020) 108041 . [70] S.K. Adiyeke , N. Kutlu , H. Aytogan , B. Aras , G. Yoyler , G. Ture , E. Talay , G.T. Dayangac , Thicknesses of sclera and lamina cribrosa in patients with cen- tral retinal vein occlusion, Retina 40 (2020) 2050–2054 . [71] B. Wang , K.A. Lucy , J.S. Schuman , I.A. Sigal , R.A. Bilonick , C. Lu , J. Liu , I. Grulkowski , Z. Nadler , H. Ishikawa , et al. , Tortuous pore path through the glaucomatous lamina cribrosa, Scientific reports 8 (2018) 1–7 . [72] S.G. Thakku , Y.C. Tham , M. Baskaran , J.M. Mari , N.G. Strouthidis , T. Aung , C.Y. Cheng , M.J. Girard , A global shape index to characterize anterior lamina cribrosa morphology and its determinants in healthy indian eyes, Investigative ophthalmology & visual science 56 (2015) 3604–3614 . [73] J.C. Downs , C.A. Girkin , Lamina cribrosa in glaucoma, Current Opinion in Oph- thalmology 28 (2017) 113–119 . [74] C.F. Burgoyne , J. Crawford Downs , A.J. Bellezza , J.K. Francis Suh , R.T. Hart , The optic nerve head as a biomechanical structure: A new paradigm for under- standing the role of IOP-related stress and strain in the pathophysiology of glaucomatous optic nerve head damage, Progress in Retinal and Eye Research 24 (2005) 39–73 . [75] N.Y. Tan , Y.C. Tham , S.G. Thakku , X. Wang , M. Baskaran , M.C. Tan , J.M. Mari , N.G. Strouthidis , T. Aung , M.J. Girard , et al. , Changes in the anterior lamina cribrosa morphology with glaucoma severity, Scientific reports 9 (2019) 1–7 . [76] E.J. Lee , T.W. Kim , Lamina cribrosa reversal after trabeculectomy and the rate of progressive retinal nerve fiber layer thinning, Ophthalmology 122 (2015) 2234–2242 . [77] P. Enders , W. Adler , D. Kiessling , V. Weber , F. Schaub , M.M. Hermann , T. Di- etlein , C. Cursiefen , L.M. Heindl , Evaluation of two-dimensional bruch’s mem- brane opening minimum rim area for glaucoma diagnostics in a large patient cohort, Acta Ophthalmologica 97 (2019) 60–67 . [78] J.M. Gmeiner , W.A. Schrems , C.Y. Mardin , R. Laemmer , F.E. Kruse , L.M. Schrem- s-Hoesl , Comparison of bruch’s membrane opening minimum rim width and R. Marques, D. Andrade De Jesus, J. Barbosa-Breda et al. Computer Methods and Programs in Biomedicine 220 (2022) 106801 peripapillary retinal nerve fiber layer thickness in early glaucoma assessment, Investigative Ophthalmology & visual science 57 (2016) OCT575–OCT584 . [79] K. Park , J. Kim , J. Lee , The relationship between bruch’s membrane open- ing-minimum rim width and retinal nerve fiber layer thickness and a new index using a neural network, Translational Vision Science & Technology 7 (2018) . 14–14 [80] J.C. Leaney , V. Nguyen , E. Miranda , Y. Barnett , K. Ahmad , S. Wong , M. Lawlor , Bruch’s membrane opening minimum rim width provides objective differenti- ation between glaucoma and nonglaucomatous optic neuropathies, American Journal of Ophthalmology 218 (2020) 164–172 . [81] M. Mokhtari , H. Rabbani , A. Mehri-Dehnavi , R. Kafieh , M.R. Akhlaghi , M. Pourazizi , L. Fang , Local comparison of cup to disc ratio in right and left eyes based on fusion of color fundus images and oct b-scans, Information Fu- sion 51 (2019) 30–41 . [82] S.K. Panda , H. Cheong , T.A. Tun , S.K. Devella , V. Senthil , R. Krishnadas , M.L. Buist , S. Perera , C.Y. Cheng , T. Aung , et al. , Describing the structural phenotype of the glaucomatous optic nerve head using artificial intelligence, American journal of ophthalmology 236 (2022) 172–182 . [83] Y.p. Wang, Q. Chen, S.t. Lu, Quantitative assessments of cup-to-disk ratios in spectral domain optical coherence tomography images for glaucoma diagnosis, IEEE, 2013. 2013 6th International Conference on Biomedical Engineering and Informatics, 160–165 [84] R. Nithya , N. Venkateswaran , Analysis of segmentation algorithms in colour fundus and oct images for glaucoma detection, Indian Journal of Science and Technology 8 (2015) 1 . [85] T. Babu , S. Devi , R. Venkatesh , et al. , Optic nerve head segmentation using fun- dus images and optical coherence tomography images for glaucoma detection, Biomedical Papers 159 (2015) 607–615 . [86] Z. Hu , M.D. Abràmoff, Y.H. Kwon , K. Lee , M.K. Garvin , Automated segmentation of neural canal opening and optic cup in 3d spectral optical coherence tomog- raphy volumes of the optic nerve head, Investigative ophthalmology & visual science 51 (2010) 5708–5717 . [87] Z. Hu , M. Niemeijer , K. Lee , M.D. Abràmoff, M. Sonka , M.K. Garvin , Automated segmentation of the optic disc margin in 3-d optical coherence tomography images using a graph-theoretic approach, Medical Imaging 2009: Biomedi- cal Applications in Molecular, Structural, and Functional Imaging 7262 (2009) 72620U . [88] P. Zang , S.S. Gao , T.S. Hwang , C.J. Flaxel , D.J. Wilson , J.C. Morrison , D. Huang , D. Li , Y. Jia , Automated boundary detection of the optic disc and layer seg- mentation of the peripapillary retina in volumetric structural and angiographic optical coherence tomography, Biomedical optics express 8 (2017) 1306–1318 . [89] A.G. Roy , S. Conjeti , S.P.K. Karri , D. Sheet , A. Katouzian , C. Wachinger , N. Navab , Relaynet: retinal layer and fluid segmentation of macular optical coherence tomography using fully convolutional networks, Biomedical optics express 8 (2017) 3627–3642 . 13 