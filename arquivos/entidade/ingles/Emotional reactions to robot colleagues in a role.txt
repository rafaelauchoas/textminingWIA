Contents lists available at ScienceDirect International Journal of Information Management journal homepage: www.elsevier.com/locate/ijinfomgt Research Article Emotional reactions to robot colleagues in a role-playing experiment Nina Savela a,*, Atte Oksanen a, Max Pellert b, c,d, David Garcia b,c, d a Faculty of Social Sciences, Tampere University b Institute of Interactive Systems and Data Science, Department of Computer Science and Biomedical Engineering, Graz University of Technology c Complexity Science Hub Vienna d Center for Medical Statistics, Informatics and Intelligent Systems, Medical University of Vienna  A R T I C L E I N F O  A B S T R A C T  Keywords: Robot Work Sentiment Role-play Experiment We investigated how people react emotionally to working with robots in three scenario-based role-playing survey experiments collected in 2019 and 2020 from the United States (Study 1: N = 1003; Study 2: N = 969, Study 3: N = 1059). Participants were randomly assigned to groups and asked to write a short post about a scenario in which we manipulated the number of robot teammates or the size of the social group (work team vs. organi-zation). Emotional content of the corpora was measured using six sentiment analysis tools, and socio- demographic and other factors were assessed through survey questions and LIWC lexicons and further analyzed in Study 4. The results showed that people are less enthusiastic about working with robots than with humans. Our findings suggest these more negative reactions stem from feelings of oddity in an unusual situation and the lack of social interaction.  1. Introduction People have been using automation and working with robots in in-dustry fields such as manufacturing for many years. Researchers suggest that the exceptional situation caused by COVID-19 and social distancing guidelines will further increase the use of advanced information sys-tems, such as robots, at work (Coombs, 2020; He, Zhang, & Li, 2021). Due to the development of more interactive, collaborative, and social robots, people are more likely to be in situations in which they must work and interact with robots as coworkers or teammates (Dwivedi et al., 2021; Haidegger et al., 2013; M¨ortl et al., 2012). As a result, new-generation robots will create new social and psychological chal-lenges that could impact work life profoundly. There is a sufficient body of evidence confirming that social psy-chological processes such as attitudes and trust are essential factors in successful collaboration with robots and ultimately accepting them in everyday life (Hancock et al., 2011; Schaefer, Straub, Chen, Putney, & Evans, 2017; Sheridan, 2016; Yusif, Soar, & Hafeez-Baig, 2016). In addition to these extensively researched factors, robotization is likely to arouse both positive and negative emotional reactions in human workers. Introducing advanced technology such as social robots as co-workers in the same organization or work team presents human workers with a new situation. Adapting to this could be more challenging to some workers than others, causing negative attitudes and emotions that could have an unwanted effect on emotional well-being. In addition to examining acceptance of robots through attitudes and trust, researchers have investigated emotional attachment to companion robots (Friedman, Kahn, & Hagman, 2003); emotional reactions to ill-treatment of robots (Rosenthal-von der Pütten, Kr¨amer, Hoffmann, Sobieraj, & Eimler, 2013); and the connection between negative emo-tions, such as anxiety, and negative attitudes (Nomura, Kanda, & Suzuki, 2006). Even though working closely with robots has been argued to arouse negative attitudinal and emotional reactions in human workers (Groom & Nass, 2007), we do not currently know how people would respond emotionally to working with robots on the same work team or in the workplace community with robots. In addition to explicit methods of measuring attitudes and emotions, such as surveys, emotional and attitudinal reactions toward robot co-workers can be investigated through more implicit means such as examining textual data collected from role-playing scenarios. Computer- aided analysis methods have generated the massive new field of affec-tive computing, which offers fast and quantitative means of analyzing large amounts of text with the help of emotional lexicons (Piryani, Madhavi, & Singh, 2017). Our study was designed to fill the research gap through analysis of textual data collected from three role-playing experiments that involved * Corresponding author at: Faculty of Social Sciences, 33014 Tampere University, Tampere, Finland. E-mail address: nina.savela@tuni.fi (N. Savela). https://doi.org/10.1016/j.ijinfomgt.2021.102361 Received 5 August 2020; Received in revised form 6 May 2021; Accepted 7 May 2021  InternationalJournalofInformationManagement60(2021)102361Availableonline23May20210268-4012/©2021TheAuthor(s).PublishedbyElsevierLtd.ThisisanopenaccessarticleundertheCCBY-NC-NDlicense(http://creativecommons.org/licenses/by-nc-nd/4.0/).Konstanzer Online-Publikations-System (KOPS) URL: http://nbn-resolving.de/urn:nbn:de:bsz:352-2-1cnionttcewjv7N. Savela et al.                                                                                                                 introduction of robots as work team members or as coworkers within a workplace. We focused on emotional reactions to the hypothetical sit-uations, as identified via sentiment analysis, in three studies and further investigated the associated factors in a fourth study. Computational social scientific analysis methods combined with an experimental design and online role-playing data collection method generated a unique multi-methodological approach that has not previously been utilized to investigate the acceptance of robots. 2. Literature review The concept of emotion has a long and complex history in philosophy and psychology, and it has traditionally been used as a metaconcept that combines different words describing feelings and attitudes (Dixon, 2012). One empirical study considered emotion as an intense mental state with hedonic content (Cabanac, 2002). There is no consensus on the definition, process, or hierarchical levels of emotion among multiple emotion theories, but most support some form of connection between emotion and cognitive appraisal (Barnard & Teasdale, 1991; Moors, 2009). Theories of attitudes often include both cognitive and emotional perspectives, and this is specifically manifested in a multicomponent model of attitude (Zanna & Rempel, 2008). In the context of technology, researchers have investigated possible connections between cognitive and emotional constructs in the framework of the technology acceptance model (TAM) and its extensions (Kulviwat, Bruner, Kumar, Nasco, & Clark, 2007; Lee, Xiong, & Hu, 2012; Saad´e & Kira, 2006; Venkatesh, 2000). For example, in a model called consumer acceptance of tech-nology, affective and cognitive attitude dimensions explain the behav-ioral attitude toward adoption, which then predicts adoption intention (Kulviwat et al., 2007). According to a literature review about the his-tory of TAM (Maranguni´c & Grani´c, 2015), further integration of emo-tions into TAM is still needed. In research focused on the advanced technology of robots specif-ically, attitudes and emotions have often overlapped, especially in research measuring and focusing on negative emotions, such as anxiety, and negative attitudes (Nomura et al., 2006). TAM and its extensions have also been used in research on human–robot interaction and user studies, but some researchers have stressed caution when applying it to interactive technology such as robots (Young, Hawkins, Sharlin, & Igarashi, 2009). For this reason and because this research area is an emerging field, the tools used to measure different social and psycho-logical constructs have varied. Because emotion is linked to attitudes and behavior (Gursoy, Chi, Lu, & Nunkoo, 2019; Kulviwat et al., 2007), and because the cognitive measures of attitude have their weaknesses (Peters & Slovic, 2007), investigating emotional responses in acceptance of emerging technologies such as robots is an important research avenue. Evidence that humans can feel empathy and get emotionally attached to artificial beings confirms that artificial entities such as ro-bots can arouse emotional reactions (Kr¨amer, Eimler, von der Pütten, & Payr, 2011; Rosenthal-von der Pütten et al., 2013). Other researchers suggested that even imagined contact with a robot can affect emotions toward robots (Wullenkord, Fraune, Eyssel, & ˇSabanovi´c, 2016). The examination of emotions toward robots is essential because they affect social processes such as identification and play an important role in human behavior (DeSteno, Dasgupta, Bartlett, & Cajdric, 2004; DeS-teno, Petty, Rucker, Wegener, & Braverman, 2004). This has conse-quences for the intended use and possible benefits gained from larger utilization of robots in work life. Emotional detection literature offers different ways to examine emotions from facial expressions, speech, and writing (Cowie & Cor-nelius, 2003; Russell, Bachorowski, & Fern´andez-Dols, 2003). For example, females and older people are more likely to express positivity in writing (Pennebaker & Stone, 2003; Thelwall, Wilkinson, & Uppal, 2010), neurotic people are likely to use negative language, and extraverted and agreeable people are more likely to use positive words (Yarkoni, 2010). However, different associations could emerge in the context of robots. The more traditional research literature on robot acceptance gives some information about the expected associations and factors to consider when studying emotional expressions in written re-actions toward robots. Some literature has suggested a difference in attitudes toward robots based on age and gender, with young individuals and males being more willing to accept robots (Flandorfer, 2012). However, some research reports conflicting findings, and some researchers have argued that these sociodemographic findings will be invalidated after controlling for other factors such as prior experience using or interacting with robots (Flandorfer, 2012). The positive effect of prior experience reported in human–robot interaction research (e.g., Bartneck, Suzuki, Kanda, & Nomura, 2007) is also in line with familiarity principle (Reis, Maniaci, Caprariello, Eastwick, & Finkel, 2011) and mere-exposure effect (Zajonc, 1968). It should be noted, however, that not all researchers have found a difference between users and non-users of robots (Rose-nthal-von der Pütten et al., 2013) and that negative encounters could also have an opposite effect (Ebbesen, Kjos, & Koneˇcni, 1976). Besides socio-demographic background and previous encounters with robots, emotional reactions toward robots could be affected by general attitude toward robots and perceived suitability of robots to a specific context. Furthermore, previous user experience and general attitude toward robots have been found to positively correlate with the intention to use robots and technology in general, therefore potentially impacting the implementation and desired benefits (Heerink, Kr¨ose, Wielinga, & Evers, 2008; Ivanov, Webster, & Garenko, 2018; Venkatesh & Davis, 2000). For these reasons, prior experience with technology and robots and general attitudes toward robots should be measured to con-trol for the confounding effect with socio-demographic factors. Though some critique of the measure exists (Zillig, Hemenover, & Dienstbier, 2002), personality traits have long been measured via the Big Five personality inquiry, which is considered robust for assessing personality in occupational psychology, among other fields (Hurtz & Donovan, 2000). There is a limited number of studies exploring different personality factors behind attitudinal and emotional responses toward robots in general and especially regarding working with robots. How-ever, in one literature review, Robert (2018) searched for personality assessments in human–robot interaction studies and found some evi-dence for extraverts being more likely and neurotic people being less likely to accept robots. Evidence related to other personality traits ap-pears to be insufficient to support any conclusions (Robert, 2018). Finally, negative emotions detected in written texts could also be the result of other factors, such as negativity toward the lack or quality of social interaction (Taipale, Luca, Sarrica, & Fortunati, 2015) or anxiety about new technology (Sinha, Singh, Gupta, & Singh, 2020). Investi-gation of emotional reactions is important in understanding imple-mentation of technology and the new situations created by the use of novel technologies. Emotional reactions people express in everyday life and on social media may have further consequences on wider societal attitudes toward robotics. 3. Theoretical background and hypotheses development In the current four studies, we utilized an experimental design, role- playing data collection, and computational social scientific analysis methods to examine linguistic positivity toward robot colleagues. The main theoretical framework of our research is based on social psycho-logical theories of prejudice, which define prejudice as a negative atti-tude or emotion toward a person or a thing (Allport, Clark, & Pettigrew, 1954; Brown, 2011). Theorists argue that prejudice is not based on or develops before personal experiences and decreases with frequent favorable interaction with the target (Allport et al., 1954; Paluck, Green, & Green, 2019). This is in line with a more general notion of fear of the unknown (Carleton, 2016), which could reasonably apply to emerging InternationalJournalofInformationManagement60(2021)1023612N. Savela et al.                                                                                                                 technology such as robots. According to the integrated threat theory, negativity can stem from realistic or symbolic threats (Stephan & Ste-phan, 2000; Stephan, Renfro, & Davis, 2008). Drawing on argumenta-tion that realistic (e.g., robots steal our jobs) and symbolic (e.g., human identity is endangered) threats may provoke prejudice (Vanman & Kappas, 2019), we investigated if robot coworkers had a negative impact on the linguistic positivity of human workers’ written reactions. H1. People write less positively about working with robots than about working with other people. We further investigated the impact of subgroup status on reactions to robot colleagues by manipulating the number of subgroup members (robots and humans). Thus, we designed the work team compositions so that humans had either a minority or majority status in the group. Drawing on integrated threat theory about intergroup anxiety and the potential negative effect of mere numerical minority status in a group posing an identity threat (Brown, 2011; Carton & Cummings, 2012; Stephan & Stephan, 2000), we expected the positivity of the written language to decrease when more robot teammates and fewer human teammates are presented. H2. People write less positively about working with robots when humans are a minority than when robots are a minority in a work group. An identity threat inside a work team could cause distrust toward the other group members, prevent a formation of a collective identity, and reduce the desire to work closely with other subgroup members (Carton & Cummings, 2012). If robot colleagues pose an identity threat to human workers (Vanman & Kappas, 2019), the idea of having robot colleagues in small and intimate teams compared with large groups, such as entire organizations, could arouse less positive reactions. Thus, we investigated the impact of conceptualization of the shared group (a teammate vs. a coworker in the same organization) and expected the written language to be less positive when robots are presented as part of a more intimate in-group, such as a team, compared to perceiving them as members of a larger group of coworkers. H3. People write less positively about working with robots when the mutual ingroup is small and requires more interaction (a team vs. an organization). In addition, we analyzed individual factors associated with the emotions expressed toward robots in the experiments. Based on previous research and theories on technology acceptance, we expected in-dividuals’ positive general attitude toward robots to be connected to positivity of the written reactions (Venkatesh & Davis, 2000). Other factors from the context of robots and technology included perceived robot suitability to one’s own field of work, prior experience in using or interacting with robots, and having education in the field of technology or engineering (Heerink et al., 2008; Ivanov et al., 2018; Venkatesh & Davis, 2000). Personality traits and the sociodemographic factors age and gender were also treated as control variables. According to previous research, females and older people are more likely to express positivity in text (Pennebaker & Stone, 2003; Thelwall, Buckley, Paltoglou, Cai, & Kappas, 2010), but based on some findings (Flandorfer, 2012), they are also more likely to have negative attitudes toward robots. Considering personality differences, negative language is more likely to be used by people with neurotic personalities, and positive vocabulary by extra-verted and agreeable people (Yarkoni, 2010). In addition, as humans have a social need to relate to others (Baumeister & Leary, 1995; Ryan & Deci, 2000), we expected writings that use social vocabulary to express less positivity in reactions to robot coworkers. H4. People with a positive attitude toward robots in general write more positively about working with robots We investigated these hypotheses in four studies that were designed to investigate the difference in reactions to robot colleagues compared to human colleagues. Study 1 was designed to analyze if being the only human on a team otherwise consisting of robots (no other humans on the team) differs from having only one robot as a teammate (other humans on the team). Study 2 tested further the significance of majority or mi-nority status in the group (3 robots & 1 human teammate). Study 3 was designed to analyze the significance of group conceptualization (team-mate vs. coworker in the same organization). In addition to testing the connection between general attitude toward robots and the responses to the presented situation, Study 4 explored other influencing factors behind the reactions. 4. Study 1 The aim of Study 1 was to investigate via a role-playing survey experiment if people use more positive language when writing about their first day at a new job working in a team with people compared to working in a team that includes robots (H1) and if the positivity of the written language differs depending on the number of robots on the team (H2). 4.1. Method 4.1.1. Participants and procedure We recruited participants (N = 1003, 48.16 % male, Mage = 37.36 years, SDage = 11.80, range 19–78 years) in January 2019 from Ama-zon’s Mechanical Turk. They lived in the United States and represented 47 of the 50 states (38.83 % South, 21.89 % West, 21.10 % Midwest, 18.18 % Northeast). This distribution closely resembles that of the 2019 U.S. census data (38.26 % South, 23.87 % West, 20.82 % Midwest, 17.06 % Northeast; U.S. Census Bureau (n.d.), 2021). Respondents (Mdnage = 35 years; 27.40 % 15–29-year-olds; 48.16 % male) were younger but fairly representative in terms of gender when compared to the current U.S. census data of citizens 15-years and older (Mdnage = 38 years; 24.80 % 15–29-year-olds; 48.55 % male) (U.S. Census Bureau, 2019). We collected the data through a role-playing method involving short imaginary writings, which has been defined more precisely as a non-active or passive role-playing method or method of empathy-based stories (Greenberg & Eskew, 1993; Wallin, Koro-Ljungberg, & Eskola, 2019). In this paper, the term role-playing is used in reference to the nonactive role-playing data collection method, which relies on the ability of humans to engage in an imaginary situation and presumes a connection between imagined behavior or feelings and actual behavior or feelings in given circumstances (Sage, 2003). In line with guidelines by Greenberg and Eskew (1993), we asked participants to imagine themselves rather than someone else in the situation and offered them non-restrictive open answer fields. When examining judgmental or cognitive processes in contrast to behavior, minimal contextual infor-mation should be used to allow a relatively neutral background and uncontaminated results (Greenberg & Eskew, 1993). To answer the research questions, we designed a role-playing experiment in which participants were randomly assigned to one of three groups (Atzmüller & Steiner, 2010). We asked the participants to first imagine they had just started their first day at a new job under conditions we described to them and then asked them to write about it on their favorite social media site (max. 160 characters). The only manipulation between randomly assigned groups was the number of human and robot members on the associated work team. The first group of participants was told that they would work in a team with robots as the other four teammates; the second group was primed with one robot and three human teammates; and the third group was told they would have four other teammates, with no mention of robots. Hence the last group of participants was the control group of the study. The purpose of the different experimental conditions was to see if the participants would express higher positivity of sentiments in the written social media posts in experimental groups with a higher number of robot teammates. The randomization was judged to be successful based on the InternationalJournalofInformationManagement60(2021)1023613N. Savela et al.                                                                                                                 lack of significant differences among the experimental groups in gender, age, and presence of a degree in technology and engineering. The local Academic Ethics Committee approved our research. 4.1.2. Measures All Study 1 variables are presented in Table 1. We measured the dependent variable, the sentiments of the written social media posts, using six different sentiment tools: the WKB lexicon, Vader compound score (Hutto & Gilbert, 2014), positive and negative measures of Sen-tiStrength (Thelwall, Buckley et al., 2010), and positive and negative emotion lexicons of LIWC (Tausczik & Pennebaker, 2010). From the WKB lexicon (Warriner, Kuperman, & Brysbaert, 2013), we used the measure for valence (pleasantness). The independent variable was the experimental group, indicating which hypothetical condition the participant was introduced to before writing the social media post. The control group was not primed with robots and was given a value of 0. The group of participants assigned one robot and four human teammates was given a value of 1, and a value of 2 was given to the group assigned four robot teammates. 4.1.3. Analysis We used Kruskal-Wallis H test, Dunn’s pairwise multiple comparison 2 ) post hoc test with Bonferroni corrections, and eta square effect sizes (ηHin addition to reporting descriptive statistics. Sample sizes were equal between the experimental groups, and variance was equal in measures of WKB valence (χ2[2] = .27, p = .874) and positive lexicon of SentiS-trength (χ2[2] = .04, p = .982). However, based on Bartlett’s test for equal variances, variance was not equal in measures of negative Sen-tiStrength (χ2[2] = 27.37, p < .001) and Vader compound score (χ2[2] = 29.18, p < .001). Because the normality was violated in some of the dependent variables, we report the results using nonparametric methods. The results did not differ from the results of a statistically more powerful one-way ANOVA. We performed all statistical analyses with Stata 16 software and used a Stata package dunntest programmed by Alexis Dinno (2015) to perform Dunn’s pairwise multiple comparisons. Eta square sizes for the Kruskal-Wallis H test were calculated using Barry Cohen’s formula (Cohen, 2008). 4.2. Results The results of Study 1 are presented in Table 2. A Kruskal-Wallis H test was performed to explore the sentiment scores of social media posts among role-playing experimental groups. There were statistically sig-nificant differences between the sentiments in the three groups in the Vader compound score (χ2 with ties [2, N = 1003] = 91.33, p < .001, 2 = .09), WKB valence score (χ2 with ties [2, N = 991] = 49.66, p <ηH2 = .05), SentiStrength positive sentiment score (χ2 with ties [2, .001, ηH2 = .05), SentiStrength negative senti-N = 1003] = 48.88, p < .001, ηHment score (χ2 with ties [2, N = 1003] = 30.52, p < .001, ηH2 = .03), LIWC positive emotion (χ2 with ties [2, N = 1003] = 53.24, p < .001, 2 = .05), and LIWC negative emotion ηH[2, 2 = .04). The effect size was small in N = 1003] = 42.48, p < .001, ηH(χ2 with ties Table 1 Descriptive Statistics of Study 1 Variables (N = 1003). Measure n % M SD Range Vader: Compound WKB: Valence SentiStrength: Positive SentiStrength: Negative LIWC: Positive emotion LIWC: Negative emotion Experimental group 0 = No robots 1 = One robot 2 = Four robots 1003 991 1003 1003 1003 1003 1003   333 358 312 33.20  35.69  31.11   .44 6.23 2.41 (cid:0) 1.23 7.05 .86 .40 .36 .93 .61 5.86 2.57 (cid:0) .77 to .98 4.20–7.25 1–5 (cid:0) 4 to (cid:0) 1 0–33.33 0–33.33 negative scores of SentiStrength and intermediate in all other measures (Cohen, 1988). The results of Dunn’s multiple nonparametric pairwise post hoc test with Bonferroni correction showed significant differences between all the sentiment scores and experimental groups, except in the SentiS-trength negative sentiments between the control group and the group primed with one robot. Overall, the results showed that having more robots on the team resulted in less positive written posts. However, there was only a significant difference in negativity between the group primed with four robot teammates and the other groups. We found no statisti-cally significant difference in negativity between the control group and the group primed with one robot. 5. Study 2 In Study 2, we aimed to replicate the findings from Study 1 (H1–H2). The only difference from the research design in Study 1 was the number of robots in one of the experimental groups (three instead of one). Hence, in Study 2, we introduced the other experimental group to the idea of working in a team with one human and three robots, which could elicit different results now that the participant is not the only human on the team. 5.1. Method 5.1.1. Participants and procedure We recruited participants for the second sample (N = 969, 48.09 % male, Mage = 37.15 years, SDage = 11.35 years, range 15–94 years) from Amazon’s Mechanical Turk in April 2019. The second sample did not include the same participants as in Study 1 to guarantee the validity of the data and avoid problems caused by nonnaive respondents (Chandler, Mueller, & Paolacci, 2014; Chandler, Paolacci, Peer, Mueller, & Ratliff, 2015). They lived in 48 states in the United States (40.34 % South, 16.88 % West, 20.81 % Midwest, 21.97 % Northeast), while the distribution based on the 2019 U.S. census data is: 38.26 % South, 23.87 % West, 20.82 % Midwest, 17.06 % Northeast (U.S. Census Bureau (n.d.), 2021). The study participants (Mdnage = 34 years; 28.07 % 15–29-year-olds, 48.09 % male) were younger but similarly distributed by gender compared to U.S. citizens based on the U.S. census data of 15-year-olds and older (Mdnage = 38 years; 24.80 % 15–29-year-olds; 48.55 % male) (U.S. Census Bureau, 2019). The procedure was similar to Study 1. The control group involved only human teammates and one of the experimental groups was intro-duced to a hypothetical work team with four robot teammates. In contrast to Study 1, we told the other experimental group that their work team consisted of three robots and one human. We found no significant differences between the three randomly assigned groups in terms of gender, age, and or presence of technology degree; thus, randomization was also successful in Study 2. 5.1.2. Measures Study 2 variables are shown in Table 3. Dependent variables were measured using the same sentiment analysis tools as in Study 1. The experimental group again functioned as the independent variable. Un-like in Study 1, in the second study, we assigned the value of 1 to the group primed with three robots and one human. 5.1.3. Analysis Study 2 utilized similar analyses methods as Study 1. Sample sizes of the experimental groups were equal, and variance was equal in the positive lexicon of SentiStrength but not in negative SentiStrength (χ2[2] = 81.96, p < .001) and the Vader compound (χ2[2] = 19.54, p <.001), based on Bartlett’s test for equal variances. To take into account the violations of normality, we report the nonparametric Kruskal-Wallis test results. The results did not differ from the statistically more powerful one-way ANOVA results. As in Study 1, statistical analyses InternationalJournalofInformationManagement60(2021)1023614N. Savela et al.                                                                                                                 Table 2 Study 1 Analysis of Variance Results: Mean Rank Differences (N = 1003). Dependent variable Experimental group Vader: Compound WKB: Valence SentiStrength: Positive SentiStrength: Negative LIWC: Positive emotion LIWC: Negative emotion 0. No robots 1. One robot 2. Four robots 0. No robots 1. One robot 2. Four robots 0. No robots 1. One robot 2. Four robots 0. No robots 1. One robot 2. Four robots 0. No robots 1. Three robots 2. Four robots 0. No robots 1. Three robots 2. Four robots n 333 358 312 328 355 308 333 358 312 333 358 312 333 358 312 333 358 312 M .59 .43 .29 6.33 6.23 6.13 2.65 2.40 2.16 (cid:0) 1.15 (cid:0) 1.20 (cid:0) 1.35 8.69 6.75 5.62 .45 .66 1.53 SD .33 .37 .45 .35 .36 .35 .92 .92 .90 .52 .57 .71 5.79 6.01 5.32 2.02 1.95 3.44 Rank Sum 0. 1. 205273.00  172897.00 125336.00 189174.50  173883.50 128478.00 191962.00  179020.00 132524.00 177587.00  183334.00 142585.00 196851.00  172414.50 134240.50 155032.50  175620.00 172853.50 (cid:0) 6.07***  (cid:0) 9.43*** (cid:0) 3.97***  (cid:0) 7.03*** (cid:0) 3.64***  (cid:0) 6.99*** (cid:0) 1.54  (cid:0) 5.36*** (cid:0) 4.92***  (cid:0) 7.07*** 1.85  6.34*** (cid:0) 3.63*** (cid:0) 3.26** (cid:0) 3.53*** (cid:0) 3.94*** (cid:0) 2.36* 4.63*** Note: Reported statistics: Frequencies (n), Means (M), Standard Deviations (SD), Rank Sums, and results for the Dunn’s multiple Comparison Test with Bonferroni Corrections. *p < .05; **p < .01; ***p < .001. Table 3 Descriptive Statistics of the Study 2 Variables (N = 969). either experimental group and the control group was significant in all dependent sentiment measures. Measure n % M SD Range 6. Study 3 Vader: Compound WKB: Valence SentiStrength: Positive SentiStrength: Negative LIWC: Positive emotion LIWC: Negative emotion Experimental group 0 = No robots 1 = Three robots 2 = Four robots 969 952 969 969 969 969 969   351 292 326 36.22  30.13  33.64   .40 6.20 2.30 (cid:0) 1.27 7.46 1.04 .42 .43 .95 .68 9.14 2.73 (cid:0) .74 to .97 3.72–7.89 1–5 (cid:0) 5 to (cid:0) 1 0–100 0–20 were performed with Stata 16 software and the Stata package dunntest programmed by Alexis Dinno (2015), and eta square sizes for the Kruskal-Wallis H test results with Barry Cohen’s formula (Cohen, 2008). 5.2. Results The main results are presented in Table 4. We performed a Kruskal- Wallis H test to explore the sentiment scores of social media posts among role-playing experimental groups. There was a statistically significant difference between the three groups in sentiments according to the Vader compound score (χ2 with ties [2, N = 969] = 140.29, p < .001, 2 = .14), WKB valence score (χ2 with ties [2, N = 952] = 94.58, p <ηH2 = .10), SentiStrength positive sentiment score (χ2 with ties [2, N .001, ηH2 = .09), SentiStrength negative sentiment = 969] = 88.27, p < .001, ηHscore (χ2 with ties [2, N = 969] = 30.17, p < .001, ηH2 = .03), LIWC positive emotion (χ2 with ties [2, N = 969] = 110.18, p < .001, 2 = .11), and LIWC negative emotion (χ2 with ties [2, N =ηH969] = 41.21, p < .001, ηH2 = .04). The results of the Dunn’s multiple nonparametric pairwise post hoc test with Bonferroni correction showed no differences between experi-mental groups primed with three or four robot teammates based on multiple sentiment analysis scores. Only SentiStrength negative scores demonstrated that a higher number of robots on the team slightly increased the negativity of the written posts. The difference between In Study 3 we aimed to confirm that the main finding in Studies 1 and 2 (H1) can also be found when robots are introduced as coworkers of the same workplace instead of members of the same small work team. Thus, in Study 3 we were manipulating the size of the social group rather than the number of teammates. In addition, we tested the difference in re-sponses to different framing of the group members within social group, as coworkers or as teammates (H3). 6.1. Method 6.1.1. Participants and procedure We recruited participants in the third sample (N = 1059, 48.29 % male, Mage = 37.97 years, SDage = 11.75 years, range 18–79 years) from Amazon’s Mechanical Turk in April 2020. Participants in the third sample lived in the United States and represented 48 states (36.24 % South, 29.05 % West, 17.93 % Midwest, 16.78 % Northeast). This distribution was similar to the 2019 U.S. census data: 38.26 % South, 23.87 % West, 20.82 % Midwest, 17.06 % Northeast (U.S. Census Bureau (n.d.)). Age and gender distribution of the respondents (Mdnage = 35 years; 25.19 % 15–29-year-olds; 48.29 % male) was fairly close to U.S. citizens based on the U.S. census data of 15-year-olds and older (Mdnage = 38 years; 24.80 % 15–29-year-olds; 48.55 % male; U.S. Census Bureau, 2019). In Study 3, we randomly assigned the participants into four groups. Different to Studies 1 and 2, this time we manipulated the framing of the social group as either team members (as in Studies 1 and 2) or just co-workers starting their jobs at the same time. Thus, one group was primed with four teammates, and another group with four coworkers. Both groups had equivalent control group priming, without mention of robots. 6.1.2. Measures Table 5 shows the variables used in Study 3. We measured the dependent variable with the same six sentiment analysis tool measures InternationalJournalofInformationManagement60(2021)1023615N. Savela et al.                                                                                                                 Table 4 Study 2 Analysis of Variance Results: Mean Rank Differences (N = 969). Dependent variable Experimental group Vader: Compound WKB: Valence SentiStrength: Positive SentiStrength: Negative LIWC: Positive emotion LIWC: Negative emotion 0. No robots 1. Three robots 2. Four robots 0. No robots 1. Three robots 2. Four robots 0. No robots 1. Three robots 2. Four robots 0. No robots 1. Three robots 2. Four robots 0. No robots 1. Three robots 2. Four robots 0. No robots 1. Three robots 2. Four robots n 351 292 326 348 289 315 351 292 326 351 292 326 351 292 326 351 292 326 M .60 .29 .28 6.37 6.13 6.09 2.66 2.10 2.08 (cid:0) 1.14 (cid:0) 1.27 (cid:0) 1.41 9.81 6.24 6.02 .31 1.35 1.56 SD .34 .41 .42 .39 .40 .45 .89 .92 .91 .48 .67 .82 6.88 10.08 9.87 1.18 3.18 3.27 Rank Sum 0. 1. 219683.00  118972.50 131309.50 205308.50  122466.50 125853.00 207798.00  124355.00 137812.00 183504.50  141416.00 145044.50 213638.00  122766.00 133561.00 153412.50  145799.50 170753.00 (cid:0) 9.88***  (cid:0) 10.39*** (cid:0) 7.60***  (cid:0) 8.91*** (cid:0) 7.85***  (cid:0) 8.23*** (cid:0) 2.64*  (cid:0) 5.49*** (cid:0) 8.60***  (cid:0) 9.35*** 4.33***  6.21*** (cid:0) .21 (cid:0) 1.08 (cid:0) .15 (cid:0) 2.65* (cid:0) .48 1.67 Note: Reported statistics: Frequencies (n), Means (M), Standard Deviations (SD), Rank Sums, and results for the Dunn’s multiple Comparison Test with Bonferroni Corrections. *p < .05; **p < .01; ***p < .001. Table 5 Descriptive Statistics of Study 3 Variables (N = 1059). Measure n % M SD Range Vader: Compound WKB: Valence SentiStrength: Positive SentiStrength: Negative LIWC: Positive emotion LIWC: Negative emotion Experimental group 0 = No robot coworkers 1 = No robot teammates 2 = Four robot coworkers 3 = Four robot teammates 1059 1044 1059 1059 1059 1059 1059   268 242 290 259 25.31  22.85  27.38  24.46   .47 6.13 2.50 (cid:0) 1.26 9.21 .84 .40 .42 .98 .64 12.21 2.34 (cid:0) .86 to .98 4.82–8.48 1–5 (cid:0) 5 to (cid:0) 1 0–100 0–33.33 as in Studies 1 and 2. The experimental group functioned as the inde-pendent variable, which refers to the first and second control groups with values of 0 and 1, and to the group primed with four robot co-workers and four robot teammates with values of 2 and 3, respectively. 6.1.3. Analysis As in Studies 1 and 2, in Study 3 we utilized the same methods and performed the calculations with Stata 16 software, the Stata package dunntest (Dinno, 2015), and Barry Cohen’s formula (Cohen, 2008). The results were similar to the results of a statistically more powerful one-way ANOVA. 6.2. Results Sentiment analysis results for all Study 3 experimental groups are presented in Table 6. Compared to four human teammates, four robot teammates received more negative emotional reactions, as in Studies 1 and 2. In Study 3, similar results were found for the two other experi-mental groups for which the role-play scenario had no mention of team membership, thus measuring emotional reactions toward coworkers in general. Besides negative measures, four robot coworkers received less positive reactions than four human coworkers, the difference being statistically significant but slightly weaker than when comparing robot and human teammates: the Vader compound score (χ2 with ties [1, 2 = .03), WKB valence score (χ2 with ties N = 558] = 16.65, p < .001, ηH2 = .03), SentiStrength positive senti-[1, N = 551] = 16.39, p < .001, ηHment score (χ2 with ties [1, N = 558] = 9.54, p = .002, ηH2 = .02), and LIWC positive emotion (χ2 with ties [1, N = 558] = 16.17, p < .001, 2 = .03). ηHIn the pairwise comparison of all groups, the differences between coworkers in general and teammates were small and nonsignificant, both when primed with robots and when primed with humans. How-ever, when comparing only two groups, the small difference of robot teammates receiving less positive reactions than robot coworkers became statistically significant in the Vader compound score (χ2 with 2 = .01), the WKB valence score (χ2 ties [1, N = 549] = 4.77, p = .029, ηH2 = .01), and SentiStrength with ties [1, N = 539] = 4.37, p = .037, ηHpositive score (χ2 with ties [1, N = 549] = 4.31, p = .038, ηH2 = .01). This was not found in the case of the two control groups. 7. Study 4 In Study 4, we further investigated the factors behind the positivity of texts written in the three role-play experiments reported in Studies 1–3 (H4). Specifically, we were interested in the reasons for the lower positivity toward working with robots found in the experimental groups, and thus did not consider the control groups in Study 4. In addition, we analyzed the debatable observations done in previous studies more closely: the difference between a work team of four robots or three ro-bots and one human (Study 2) and the difference between robots as coworkers of the same workplace or as members of the same work team (Study 3). 7.1. Method 7.1.1. Participants For Study 4, we utilized the three samples from the previous studies, excluding the control groups (N = 1837, 48.01 % male, Mage = 37.46 years, SDage = 11.60 years, range 15–78 years). The participants in the final sample lived in the United States, representing 49 of the 50 states (38.71 % South, 21.84 % West, 20.34 % Midwest, 19.12 % Northeast). InternationalJournalofInformationManagement60(2021)1023616N. Savela et al.                                                                                                                 Table 6 Study 3 Analysis of Variance Results: Mean Rank Differences (N = 1059). Dependent variable Experimental group Vader: Compound WKB: Valence SentiStrength: Positive SentiStrength: Negative LIWC: Positive emotion LIWC: Negative emotion 0. No robot coworkers 1. No robot teammates 2. Four robot coworkers 3. Four robot teammates 0. No robot coworkers 1. No robot teammates 2. Four robot coworkers 3. Four robot teammates 0. No robot coworkers 1. No robot teammates 2. Four robot coworkers 3. Four robot teammates 0. No robot coworkers 1. No robot teammates 2. Four robot coworkers 3. Four robot teammates 0. No robot coworkers 1. No robot teammates 2. Four robot coworkers 3. Four robot teammates 0. No robot coworkers 1. No robot teammates 2. Four robot coworkers 3. Four robot teammates n 268 242 290 259 265 240 286 253 268 242 290 259 268 242 290 259 268 242 290 259 268 242 290 259 M .56 .54 .43 .35 6.21 6.18 6.10 6.03 2.67 2.67 2.42 2.27 (cid:0) 1.25 (cid:0) 1.21 (cid:0) 1.25 (cid:0) 1.31 1.75 1.76 1.46 1.31 .15 .13 .19 .24 SD .38 .38 .41 .41 .43 .37 .43 .43 .92 1.02 .96 .97 .64 .62 .60 .68 1.33 1.34 1.26 1.19 .41 .45 .44 .50 Rank Sum 0. 1. 2. 161352.50   142483.50 143813.00 113621.00 157938.50   137095.50 140141.00 110315.00 156073.00   140119.50 147086.00 117991.50 143851.00   132845.50 152217.00 132356.50 153970.00   138869.50 146590.00 121840.50 139218.00   120681.50 156455.50 144915.00 (cid:0) .49  (cid:0) 4.10*** (cid:0) 6.14*** (cid:0) .92  (cid:0) 4.12*** (cid:0) 6.04*** (cid:0) .13  (cid:0) 3.04** (cid:0) 4.99*** .69  (cid:0) .70 (cid:0) 1.48 (cid:0) 1.22  (cid:0) 4.06*** (cid:0) 5.46*** (cid:0) 1.34  1.46 2.37 (cid:0) 3.49**  (cid:0) 5.50*** (cid:0) 2.19 (cid:0) 3.08**  (cid:0) 4.98*** (cid:0) 2.07 (cid:0) 2.83*  (cid:0) 4.73*** (cid:0) 2.07 (cid:0) 1.39  (cid:0) 2.13 (cid:0) .81 (cid:0) 2.71*  (cid:0) 4.11*** (cid:0) 1.54 2.78*  3.64*** .97 Note: Reported statistics: Frequencies (n), Means (M), Standard Deviations (SD), Rank Sums, and results for the Dunn’s multiple Comparison Test with Bonferroni Corrections. *p < .05. **p < .01. ***p < .001. 7.1.2. Measures Study 4 variables are presented in Appendix A. The dependent var-iable used in this study was Vader compound score, which can have values from –1 to 1 based on the direction and intensity of emotional content on the analyzed text. The first independent variable was the experimental group. In this study, we excluded the control groups because those participants were not primed with robots. The experimental group variable included all other conditions: four robot coworkers (Study 3), four robot teammates (Studies 1 and 2), three robot teammates (Study 3), and one robot teammate (Study 1). Experimental group was treated as a categorical variable in the regression analyses with four robot teammates as the reference group. Control variables included age, gender, presence of a degree in technology or engineering, and personality traits, which we measured with the short 15-item Big Five Inventory (BFI-S). The BFI-S includes statements on neuroticism, extraversion, openness, agreeableness, and conscientiousness on a 7-point Likert scale (Lang, John, Lüdtke, Schupp, & Wagner, 2011). We used a three-item mean sum variable for each trait: neuroticism (α = .84–.81), extraversion (α = .86–.78), openness (α = .80–.82), agreeableness (α = .61–.58), and conscientiousness (α = .70–.68). In the first survey, perceived attitude toward robots was measured with one item on a 7-point Likert scale (1 = very negative to 7 = very positive). In the following surveys, perceived attitude toward robots was also measured with affective, cognitive, and behavioral attitude ques-tions, two items each. The items were self-generated based on theoret-ical assumptions of multicomponent theory of attitude (Zanna & Rempel, 2008) and applied to the context of acceptance of robots. All items were measured on a scale from 1 to 7 (1 = very negative to 7 = very positive; 1 = strongly disagree to 7 = strongly agree; see Appendix B). To consider the influence of occupational differences, we also measured perceived suitability of robots to one’s own field of work with one item on a 7-point Likert scale. Last, we measured prior interactional experience with robots by asking participants whether they had used or interacted with a robot. We used a binary dummy variable (1 = yes, 0 =no/don’t know) in the analysis. In addition to survey measures, we utilized six different LIWC lexicon categories for the OLS regression analyses: social, negate, negative emotion, anxiety, anger, and sad. Social and negate categories were used together as a proxy to measure whether participants were writing about the absence of social contact. This measured the occurrences of social relations and interaction vocabulary, provided the negation was present in the same text. The four negative-affect LIWC categories were used to test which type of negativity best explained the lower positivity of Vader compound sentiment scores. Even though the other three lexicons are included in the LIWC negative emotions category, it also includes negative words not included in the other categories. We ran the LIWC score results using LIWC 2015 software (Tausczik & Pennebaker, 2010). 7.1.3. Analysis In Study 4, we utilized word clouds for descriptive analyses, followed by ordinary least squares (OLS) regression analysis. We report unstan-dardized regression coefficients (B) and their standard errors (B SE), standardized beta coefficients (β), and p values for the different mea-sures, in addition to model goodness of fit measure (R2), model test (F), and the p value of the model. We did not detect problematic multi-collinearity or heteroscedasticity of residuals in the regression models. Multicollinearity criteria were violated only in the case of an interaction term, which is a cross-product term and thus acceptable. OLS regression analyses were performed with Stata 16 software. For word clouds, we utilized Python WordCloud Generator and the Python module for Stata 16. The first word cloud (Fig. 1) was generated from the role-play text corpus after excluding texts categorized as positive or neutral with Vader compound scores greater than (cid:0) .05, resulting in a word count of 5353. The second word cloud (Fig. 2) was formed by further excluding all other words except adjectives using the LIWC adj category, resulting in 362 adjectives. Minimum font size was InternationalJournalofInformationManagement60(2021)1023617N. Savela et al.                                                                                                                 Fig. 1. Word cloud generated from experimental condition participants’ negative texts. Note: Texts: n = 253, word count: 5353. Fig. 2. Word cloud generated from all the adjectives used in experimental condition participants’ negative texts. Note: Texts: n = 253, word count: 362. set to 10, maximum words to 50, and the relative scaling to 0.5. In Fig. 2, the smallest font size was assigned to words occurring only once, such as upset; in Fig. 1, the lowest frequency was observed for the word felt (n = 9). frequently used words and collocations also repeated the vocabulary used in the scenario introductions, the word cloud in Fig. 2, which in-cludes only the adjectives from the same texts, gives a more informative overview on the participants’ own descriptions of the situation. 7.2. Results 7.2.1. Word cloud analysis Experimental group participants’ written posts categorized as negative addressed the issue of working with robots with feelings of skepticism in the face of an unfamiliar situation. For example, one participant wrote, “My first day at work was very strange, I only worked with robots and this made communication very weird.” There were also texts suggesting some degree of nervousness or uneasiness: “Worked with a bunch of robots today. Literally didn’t talk to a human all day. Send help.” Some participants also wrote about the lack of familiar human interaction, as evident in the previous example and in an example addressing the issue of humor: “I’m not sure how I feel about telling jokes to robots at work all day. No one ever groans. But they never laugh either…” Similar observations can be drawn from the results of the word cloud analyses (see Figs. 1 and 2). First, Fig. 1 demonstrates that the more frequently used words and collocations in negative texts written by the experimental condition groups mainly addressed the key concepts of the designated role-play scenarios: working (83/5353), with (158/5353), and robot (215/5353). In addition, dealing with nonhumans such as robots elicits an emphasis on the category of human. Because the most Besides from new (89/362), which was the only adjective used in the scenario introductions, weird (40/362) and strange (35/362) were the adjectives most frequently used by the participants. Being faced with an unusual hypothetical situation can also be seen from other words expressing novelty (different, unique, unexpected, surprised: 7/362). To some extent, participants seemed to use adjectives indicating anxiety (nervous, anxious, scary: 16/362) and insecurity (hard, difficult: 7/362). In addition, the use of the words alone, personal, and talkative (11/362) could indicate that social factors are involved in the negative reactions. Considering the negations combined with lexicons, such as social, could give a better picture of the associated factors. 7.2.2. Regression analysis Results of the regression analyses for Vader compound scores are presented in Table 7. Based on OLS regression in Model 1, participants primed with four robot coworkers starting the job at the same time expressed higher positivity than those primed with being assigned to a team with four robot teammates (β = .09, p < .001). This gives more support to the weak finding in Study 3 pointing to participants reacting slightly less positively when they were supposed to work more closely with robots. OLS regression analysis also confirmed the finding from Study 2 that no differences could be found between experimental groups primed with four robot teammates or a team with three robots and one InternationalJournalofInformationManagement60(2021)1023618N. Savela et al.                                                                                                                 Table 7 Regression Analyses of Study 4 Variables (N = 1837).  Measure Experimental group 4 robot coworkers 4 robot teammates 3 robot teammates 1 robot teammate Attitude to robots Suitability of robots to one’s own field Prior robot experience Degree in technology Age Female gender Neuroticism Extraversion Openness Agreeableness Conscientiousness LIWC social LIWC negate x LIWC social  Age x Degree in technology  Model R2 Model F Model p Model 1 (n = 1814) Model 2 (n = 1814) Model 3 (n = 1155) B SE B β B SE B β B SE B β .10 ref. (cid:0) .00 .13 .05 .02 (cid:0) .05 .07 (cid:0) .00 .07 .00 .00 (cid:0) .00 .02 .01 (cid:0) .00 .03 ref. .03 .03 .01 .01 .02 .02 .00 .02 .01 .01 .01 .01 .01 .00 .08  10.82  ***  .09*** ref. (cid:0) .00 .13*** .16*** .09** (cid:0) .05* .07** (cid:0) .07** .08** .02 .02 (cid:0) .01 .05 .02 (cid:0) .01 .10 ref. (cid:0) .02 .12 .05 .02 (cid:0) .05 .30 (cid:0) .00 .07 .00 .00 (cid:0) .01 .02 .01 .00 (cid:0) .00 (cid:0) .01 .03 ref. .03 .03 .01 .01 .02 .07 .00 .02 .01 .01 .01 .01 .01 .00 .00 .00 .11  13.16  ***  .09*** ref. (cid:0) .02 .12***  .16*** .09** (cid:0) .05* .32*** (cid:0) .01 .08** .02 .01 (cid:0) .02 .05 .02 .02 (cid:0) .16*** (cid:0) .26*** .10 ref. (cid:0) .01 .07 .01 (cid:0) .04 .38 (cid:0) .00 .10 (cid:0) .00 .00 (cid:0) .01 .01 .01 (cid:0) .00 (cid:0) .00 (cid:0) .01 .10** ref. (cid:0) .01 .22*** .06 (cid:0) .05 .43*** (cid:0) .05 .11*** (cid:0) .00 .01 (cid:0) .03 .04 .02 (cid:0) .02 (cid:0) .13*** (cid:0) .31** .03 ref. .03 .01 .01 .03 .08 .00 .03 .01 .01 .01 .01 .01 .00 .01 .00 .14 11.68 *** Note: Dependent variable: Vader compound score. Model 2: Two interaction terms added (age x technology degree, LIWC negate x LIWC social). Model 3: General attitude toward robots measured with 7-item measure instead of 1-item measure. *p < .05; **p < .01; ***p < .001. human (β = – .00, p = .861). As in Study 1, people reacted more posi-tively when primed with one robot teammate than four robot teammates (β = .13, p < .001). These results did not change across the models. General positive attitude toward robots was a strong predictor of positive sentiment when measured with one item in Models 1 and 2 (β = .16, p < .001) and as a 7-item measure in Model 3 (β = .22, p <.001). The models were also controlled with perceived robot suitability to one’s own field of work and prior interactional experience with ro-bots. Suitability of robots to one’s own field predicted higher positivity in Models 1 and 2 (β = .09, p = .001) but became nonsignificant in Model 3 (β = .06, p = .092). Previous encounters with robots had a weak but statistically significant connection to less positive sentiment in Models 1–2 (β = – .05, p = .027–.020), which became nonsignificant in Model 3 (β = – .05, p = .109). This indicates that general attitude toward robots is a stronger factor behind reactions to working with robots than occupational suitability or prior experience with robots. Having a technology degree was a small predictor in Model 1 (β = .07, p = .004), but became a strong predictor in Models 2 and 3 (β =.32–.43, p < .001). We discovered a strong interaction between age and technology education that canceled out the negative effect of age found in the first model. The interaction term added to Models 2 and 3 was negative (β = –.26 to (cid:0) .31, p = .001), indicating that older participants with technology education reacted more negatively to working with robots. This means that technologically educated younger participants were much more likely to write positive texts. Female gender was associated with higher positivity in the role-play texts across models (β = .08–.11, p = .001 – p < .001). We found no interaction effect for gender. Aside from the case of agreeableness, we found no evidence that personality traits were connected to the positivity of written texts in a role-play across different regression models. A weak association be-tween agreeable personalities and positive reactions was statistically significant only in Model 2 (β = .05, p = .047), but not in Model 1 (β =.05, p = .061) or Model 3 (β = .04, p = .245). The personality traits were left in the models as control variables, but they did not change the results for other factors in the models. Finally, LIWC social lexicon was not associated with the outcome on its own, but it had a moderate connection to negative reactions to working with robots when combined with LIWC negate lexicon as an interaction term in Models 2 and 3 (β = (cid:0) .16 to (cid:0) .13, p < .001). Thus, those experimental groups’ participants, who used more vocabulary dealing with social relations and interaction (provided that negations were also present), were also the ones whose texts scored more nega-tively. Besides age and technology education, and LIWC social and LIWC negate, no other interaction effects were found. Model 3 explained 14 % of the variance of the Vader compound score. Even though LIWC anxiety score assumably overlaps with the Vader compound score because they measure similar phenomena, we added four different LIWC negative lexicons to the last model to determine whether anxiety explained the sentiment results of Vader compound scores better than other types of negativity scores (see Model 4, Ap-pendix C). LIWC categories anger and sad had no connection to the outcome, LIWC anxiety had a small but nonsignificant negative associ-ation with the outcome (β = (cid:0) .05, p = .094), and LIWC negative emotion explained the negative sentiments best compared to the other three negative sentiment scores (β = (cid:0) .32, p < .001). This finding im-plies that negativity toward working with robots is not based on anxiety, as suggested by the word cloud analysis, or anger or sadness, but on other negative affects included in the LIWC negative emotions lexicon, such as weird, strange, and crazy. Combined with the word cloud anal-ysis, the results suggest the negativity toward working with robots stems from the negativity toward unexpected and unfamiliar situations. 8. Discussion Our series of role-playing experiments investigated emotional re-actions to robot colleagues. The main finding of our studies was that people reacted more positively to working with humans than working with robots. In addition to finding positive expressions influenced by minority status, group size, and individual differences, we discovered that the negative reactions to robot colleagues could be explained by feelings of oddity and lack of social interaction. Our results confirmed that introducing robots as colleagues decreased the positivity of the writings about the first day at the imag-ined new job (H1). Respondents wrote less positively about robot teammates (Studies 1–3) and robot colleagues in the same organization (Study 3) compared to human teammates and colleagues. Reservations about working with robots were also seen in the content of the writings InternationalJournalofInformationManagement60(2021)1023619N. Savela et al.                                                                                                                 (Study 4). The results confirmed Groom and Nass’s (2007) suspicion that working with robots could arouse negative reactions in human workers. In line with Vanman and Kappas (2019), our findings suggest that robots pose a threat to and elicit prejudice in human workers. Our results complement the literature regarding attitudinal and emotional reactions toward robots (Friedman et al., 2003; Nomura et al., 2006) and verify that even imagined work-context interaction with a robot can affect emotions toward robots (Wullenkord et al., 2016). The results also confirmed our second hypothesis regarding a mi-nority status (H2). The writings were less positive when the team had four robot members compared to a team with one robot and three human teammates (Study 1). Thus, the emotional language differed significantly between a robot-majority team and having just one robot on an otherwise human team. Compared to a team consisting of three robots and one human, adding another robot to a work team that already had a robot majority did not affect the emotional reactions as much as introducing participants to a team with only human coworkers (Study 2). The finding is in line with the integrated threat theory about inter-group anxiety and with the notion that a mere numerical minority status in a group might pose an identity threat and have negative effects (Brown, 2011; Carton & Cummings, 2012; Stephan & Stephan, 2000). We also found support for the third hypothesis regarding the size and closeness of the shared group (H3). The emotional reactions to human coworkers and human teammates did not differ, but we found that people reacted slightly more positively to robot coworkers in general than to sharing a small work team with robots (Studies 3–4). This was in line with the argument that robot colleagues could pose an identity threat to human workers (Vanman & Kappas, 2019), and workers whose identity is being threatened by another subgroup are reluctant to work closely with those subgroup members (Carton & Cummings, 2012). Our results show that people might react more negatively to robot coworkers if they have to share small teams with them, as opposed to merely being in the same organization where working as closely as teammates would is not required. By further examining the factors behind the positivity in the texts about working with robots (Study 4), we found that people with positive attitude toward robots in general reacted more positively toward working with robots, providing support for H4. In line with previous research and theories on technology acceptance (Ivanov et al., 2018; Venkatesh & Davis, 2000), general attitude toward a technology is connected to attitudinal and behavioral reactions to a more specific situation regarding that technology. Accordingly, a generally positive attitude toward robots was strongly associated with positive reactions to working with robots, and it explained the sentiment outcome better than the perceived suitability of robots to one’s own occupational field. From other factors examined in Study 4, the results regarding prior interaction experience with robots were not significant in some models. In contrast to previous literature, those who had used or interacted with robots before did not express more positivity toward working with robot teammates; weak evidence from our findings even suggests a reverse connection. This contradicts the familiarity principle (Reis et al., 2011) and mere-exposure effect (Zajonc, 1968) and previous research on ro-bots (Flandorfer, 2012). A possible explanation for this could be that people who are familiar with certain existing robots express less posi-tivity because they are not convinced about working with these robots and considering them teammates or coworkers. Previous interaction encounters might also have been negative for some participants, which would lead to greater dislike of the target stimulus (Ebbesen et al., 1976). On the other hand, the results could also be promising for those working on new robot innovations, because people who have no expe-rience interacting with robots would be more positive and open to the possibility of working and collaborating with robots. Education in technology predicted positive sentiments, which is in line with previous evidence on technology use in general (Flandorfer, 2012). It was also a strong predictor of positive sentiments among youth, but the effect was opposite for older participants. Older age on its own was not associated with sentiments; thus, older people were not more positive in their sentiments as suggested by research on emotional lan-guage (Pennebaker & Stone, 2003; Thelwall, Buckley et al., 2010). This could be due to the robot-specific context and the conflicting effect of older age on attitudes toward robots (Flandorfer, 2012). We found that females reacted more positively toward working with robots. This was in line with research on emotional language in general, as sentiments in texts written by females tend to be more positive (Pennebaker & Stone, 2003; Thelwall, Buckley et al., 2010). We found no differences among personality traits, other than weak evidence of slightly higher positivity in writing about robot teammates by agreeable persons who tend to seek social harmony. This suggests that highly agreeable people express more positivity toward working with robots, which would be in line with the literature on personality differences in emotional language in a more general context (Yarkoni, 2010). Surprisingly, we did not find consistent results regarding the positive relationship between positive sentiments and extraversion or emotional stability, even though the existence of this relationship has been suggested by previous research on personality in general (Yarkoni, 2010) and by research on human–robot interaction (Robert, 2018). Finally, Study 4 provided further insight into the reasons behind the negativity toward robot coworkers found in the experiments. Our find-ings suggest that people’s reaction to working with robots may be less positive because of feelings of oddity in an unfamiliar situation and the lack of social interaction. Based on descriptive word cloud analysis and regression analysis on different types of negative lexicons, people react less positively to working with robots because of feelings of strangeness in a situation that is unusual and differs vastly from the situations they are familiar with. This finding is somewhat in line with the more general notion of fear of the unknown (Carleton, 2016), although we did not find evidence on anxiety specifically, which would have been more closely related to fear. It could be argued that our findings would be better described as discomfort or even disgust in the face of the unknown, a feeling which Plutchik (2001) places opposite trust and acceptance. The results from our multimethod analyses in Study 4 suggest that negativity also stems from the lack of social relations and interaction, which is in line with previous research on robots in social life domains (Taipale et al., 2015). Table 8 shows a summary of the findings of all four studies. 8.1. Theoretical contributions and implications Our findings expand on the existing theoretical frameworks used to research negativity, such as fear and anxiety toward robots. In line with the integrated threat theory, robots positioned as social actors may bring Table 8 Summary of All Four Studies’ Results. Hypotheses H1: Prejudice: Negative sentiments about working with robots Prejudice increases if…   H2: Minority status (more robots than humans in a group) H3: Close group (team vs. organization)  H4: Negative attitude toward robots in general  Study 1 supported Study 2 supported supported supported  Study 3 supported supported Study 4 supported supported supported InternationalJournalofInformationManagement60(2021)10236110N. Savela et al.                                                                                                                 forth realistic and symbolic threats (Stephan & Stephan, 2000; Stephan et al., 2008). Our studies did not directly pose a realistic threat to respondent’ economic capital, such as being replaced by robot workers or losing income, but it did pose a threat to individuals’ work life social capital, as it introduced a threat of losing human coworkers and there-fore the possibility for familiar human interaction. The realistic threat of loss or deteriorated social interaction shows that it cannot be taken for granted that people will accept social robots as social actors designed to fill their social need to relate to others (Baumeister & Leary, 1995; Ryan & Deci, 2000). Our studies also support the notion that antipathy toward robots arises from a symbolic threat, wherein the identity of being a human is threatened by replacing humans with technology and giving them equal positions in the social hierarchy (Vanman & Kappas, 2019). We found that specific group processes such as minority anxiety can take place with nonhuman social actors such as robots. The positivity of the written reactions decreased due to a mere numerical minority status in a group, suggesting that robot coworkers pose an identity threat for human workers (Brown, 2011; Carton & Cummings, 2012; Stephan & Stephan, 2000). The small evidence found regarding the closeness of the in-group also implies that an intimate work team requiring closer interaction poses a greater threat to people than a loose mutual in-group member-ship on an organizational level. In addition to threat caused by preju-dice, it could be argued that the negative reactions toward robots are due to fear of the unknown (Carleton, 2016), or speciesism which has been noted to be an obstacle to robot adoption (Schmitt, 2020). The results also support the link between a general attitude and a situation-specific reaction in technology acceptance (Venkatesh & Davis, 2000). The strong connection of the multicomponent survey measure of attitude with our sentiment analysis results also suggests that sentiment analysis tools capture information closely related to cogni-tively oriented opinions, as well as the emotional spectrum and even interactional attitudes and intentions. Measuring the emotional char-acteristics of written texts avoids the risk pertaining to cognitively ori-ented survey measures potentially having a stronger relationship with each other, as has been noted regarding some personality measures (e.g., openness and agreeableness; Zillig et al., 2002). The methodological contribution of our research was to use senti-ment analysis on texts collected via a role-playing experiment, extend-ing the means through which we can investigate issues such as emerging technology acceptance. Our findings also highlight the significance of language and the representations associated with different concepts. Our results point in the direction that robot coworkers and robot teammates are associated with negative representations or schemas (de Groot, 1989; Wagner et al., 1999), which should be taken into account both in research and practice. 8.2. Implications for practice Our findings provide information on whether and with what condi-tions people would be willing to interact or collaborate with robots at work. This has critical consequences for the gains envisioned in intro-ducing robots to workplaces as teammates or coworkers. The results imply that when introducing new and advanced technology in a work-place context, it is preferable to familiarize people with one robot instead of surrounding them with multiple unfamiliar entities at once. We recommend ensuring that the majority of the workforce around a human worker consists of other humans, rather than humans being the minority in an otherwise machine-dominated workplace. Our results also imply that people hold reserved expectations of ro-bots as coworkers, particularly when they are introduced as members of a work team. Smaller teams suggest coherent social groups that work more intimately with each other than mere coworkers of the same or-ganization do. Therefore, if robots are introduced as coworkers, it is not advisable to instruct the human workers that they will be working closely with the robots and sharing the same small work group. These results highlight the significance of social representations and the language used in the workplace context. The same robot product could be received differently depending on the social status and group membership it is assigned when introduced to the human workers. Management should be aware not only of the potential resistance caused by unfamiliar technology and situations, but also about the mental im-ages and expectations they convey when choosing to call robots as co-workers or teammates instead of calling them as tools or assistance. Using the concepts of coworkers and team members gives technology equal status and level of power with human workers. Calling technology assistants on the other hand leaves higher power status to humans and implies enhancing human capabilities rather than replacing them (Coombs et al., 2021). The concepts of coworker and teammate also hold social interaction expectations on the part of human workers who work closely with each other, such as discussing the workday or office rumors. Unfamiliar technology combined with the expectancies of communication in the workplace that people are used to might raise concerns about whether technology can substitute for the need for social interaction. Manage-ment should make sure that new-generation social robots are not intended as substitutes for human coworkers especially in cases where people are not used to working alone. In addition to productivity, workers have social functions in the work community that are sensitive to individual preferences and group dynamics. The potential disadvan-tages of framing robots as social actors should be carefully considered, because even autonomous and human-like artificial intelligences could be introduced as assistants (Hu, Lu, Pan, Gong, & Yang, 2021). 8.3. Limitations and future research direction Even though our samples closely correspond to the population of the United States in terms of sociodemographic factors such as gender, and there is some evidence in favor of the generalizability of survey exper-iment results using Mechanical Turk convenience samples (Coppock, 2019), our research does not attempt to make statements about the representativeness of the data or generalizability of the results to all humans from different cultural backgrounds. Rather, we aim to demonstrate a sociopsychological and linguistic mechanism between priming of a hypothetical robot teammate or coworker and emotional response in written language during a role-play experiment. Our experimental design and convenience samples were chosen because they were appropriate methods to fulfill this aim, but they are limited in their potential to produce hard evidence for other populations and cross-cultural contexts. Our samples included participants from 49 states of the United States and people from different types of communities ranging from rural areas to cities. We also estimated our samples based on level of education, occupational field, income level, employment status, marital status, and race, and concluded that the samples’ diversity was good and matched closely with the adult population of the United States. In addition to the diversity of the samples, we considered the sample size. To maximize the power of our analyses, we altered the stimuli of the experimental design with the number of robots and the size of the framed social group to validate the results from Study 1. Considering sufficient sample sizes, with a margin of error of 5% and confidence level of 99 %, a sample size of at least 664 was considered appropriate. Thus, we collected samples of 1003, 969, and 1059 participants to account for possible data loss and subgroups. We also reported effect sizes to validate and maximize the power of our findings. Our findings were statistically significant often at the level of p < .001, and the effect sizes ranged from small to inter-mediate (Cohen, 1988). Our results provide insights about the emotional and attitudinal processes taking place when robots are introduced as coworkers, but the hypothetical study design has limitations compared to real-life situa-tions. Role-play tasks in survey experiments rely on humans’ ability to imagine a hypothetical situation (Armstrong, 2001; Rungtusanatham, InternationalJournalofInformationManagement60(2021)10236111N. Savela et al.                                                                                                                 Wallin, & Eckerd, 2011). The linguistic data that they result in is not comparable to literal descriptions of reality, but it offers insights on potential scenarios (Wallin et al., 2019). It is argued to be suitable for research on sociocultural representations, mental images, values, per-ceptions, and expectations of emerging phenomena (Wallin et al., 2019). Although the value of role-playing in predicting behavior has gained some support (Armstrong, 2001; Rungtusanatham et al., 2011), the in-terest in comparing reactions between randomly assigned roles makes the use of role-playing more valid than just trying to produce the precise behavior of the individual under circumstances similar to the simulation (Sage, 2003). Our study design choices regarding group compositions were guided by theory and empirical findings of majority or minority status effects on group processes (Brown, 2011; Carton & Cummings, 2012; Stephan & Stephan, 2000). However, future studies could consider including one balanced team of two robots and two human coworkers as another experimental group. Although lacking a specific robot type, the strength of this research is in the establishment of general emotional tendencies toward robots as coworkers that is not dependent on constantly evolving technological products. Because general attitude toward robots has been found to predict behavior and attitudes toward specific robot types and in specific contexts (Heerink et al., 2008; Ivanov et al., 2018), general attitudinal and emotional tendencies are important subjects of basic research. Our findings should be further investigated in longitudinal research examining the effect of the contact hypothesis (Paluck et al., 2019). Future studies should further examine the extent and quality of bias toward social robots in a workplace context. If similar findings are made in longitudinal studies including exposure to robots, research on the ethical perspective should aim to establish guidelines for technology operating as social actors. 9. Conclusions This prejudice is further enhanced by minority status of the humans in a group, small in-group requiring more interaction, and negative general attitudes toward robots. Our findings suggest that the reason for the negative reactions lies in the threat stemming from feelings of unease in an anomalous situation and uncertainties surrounding social interaction with robots. Our results imply that the same robot product could be received differently depending on the social status and group member-ship it is given. To minimize prejudice, it is advisable to avoid intro-ducing robots as social actors of a social status equal to or higher than that of the human workers. Our results extend the existing research evidence on the impact of language on expectations, attitudes, and emotions relating to the new phenomenon of robotization. Our study is also the first to use sentiment analysis tools in a role-playing experiment, thus providing a new methodological opening to the field. Funding This research received funding from the Finnish Cultural Foundation (Robots and Us Project, 2018–2019, PIs Jari Hietanen, Atte Oksanen, and Veikko Sariola), Kone Foundation (UrbanAI project, 2021–2023, PI Atte Oksanen, grant 202011325), and the Vienna Science and Tech-nology Fund (grant VRG16-005, funding Max Pellert and David Garcia). CRediT authorship contribution statement Nina Savela: Conceptualization, Methodology, Investigation, Data curation, Formal analysis, Visualization, Writing - original draft, Writing - review & editing. Atte Oksanen: Project administration, Funding acquisition, Supervision, Conceptualization, Methodology, Investiga-tion, Resources, Data curation, Formal analysis, Writing - review & editing. Max Pellert: Software, Validation, Formal analysis, Writing - review & editing. David Garcia: Methodology, Software, Formal anal-ysis, Resources, Writing - review & editing, Supervision. Our studies showed that people are less enthusiastic about working with robots than with humans, suggesting that robot coworkers pose a threat to human workers and might generate prejudice against robots. Declaration of Competing Interest None of the authors has a conflict of interest to declare. Appendix A. Descriptive Statistics of Study 4 Variables (N ¼ 1837) Categorical variables n %   Experimental group    Four robot coworkers Four robot teammates Three robot teammates One robot teammate Prior robot experience 1 = Yes 0 = No/Maybe Degree in technology 1 = Yes 0 = No Age Gender 1 = Female 0 = Male 897 290 292 358 1837   555 1282 1837   510 1327 1834   1817   935 882 48.83   15.79   15.90   19.49   30.21   69.79   27.76   72.24   51.46   48.54    Continuous variables Age General attitude toward robots Perceived robot suitability to one’s own field of work Neuroticism Extraversion Openness Agreeableness n 1834 1837 1837 1837 1837 1837 1837 M 37.46 4.89 3.81 3.66 3.81 5.19 5.14 SD 11.60 1.40 1.86 1.69 1.54 1.27 1.19 Range 15–78  1–7  1–7  1–7 1–7 1–7 1–7 n of items α 3 3 3 3 .84 .86 .80 .61 (continued on next page) InternationalJournalofInformationManagement60(2021)10236112N. Savela et al.                                                                                                                 (continued ) Continuous variables Conscientiousness LIWC social LIWC negate LIWC negative emotion LIWC anxiety LIWC anger LIWC sad n 1837 1837 1837 1837 1837 1837 1837 M 5.44 8.54 1.65 1.19 .25 .10 .10 SD 1.12 8.40 6.70 2.91 1.38 .81 .86 Range 1.33–7 0–100  0–100  0–33.33  0–33.33  0–16.67  0–16.67  n of items 3 α .70 Appendix B. Study 4 items used to measure attitude toward robots: General, affective, cognitive, and behavioral attitude questions How positive or negative is 1 … your view on robots in general? 2 … your view on robots if you think about your gut feeling? 3 … your view on robots if you think about the facts you know about robots? 4 … your view on robots if you think about using or interacting with a robot? 5 I would interact with a robot, if given the opportunity. 6 I feel excited when I think about robots of the future. 7 Based on my knowledge about robots, I think they are a necessary part of the future. Appendix C. Regression Analysis for Study 4 Variables (N ¼ 1837)  Measure Experimental group 4 robot coworkers 4 robot teammates 3 robot teammates Attitude toward robots Suitability of robots to one’s own field Prior robot experience Degree in technology Age Female gender Neuroticism Extraversion Openness Agreeableness Conscientiousness LIWC social LIWC negate x social Age x Technology degree LIWC negative emotion LIWC anxiety LIWC anger LIWC sadness Model R2 Model F Model p B .07 ref. (cid:0) .01 .05 .01 (cid:0) .04 .33 (cid:0) .00 .07 .00 (cid:0) .00 (cid:0) .01 .01 .01 (cid:0) .00 (cid:0) .00 (cid:0) .01 (cid:0) .05 (cid:0) .02 (cid:0) .02 (cid:0) .01 Model 4 (n = 1155) SE B .03 ref. .03 .01 .01 .02 .08 .00 .02 .01 .01 .01 .01 .01 .00 .00 .00 .00 .00 .00 .00 .26 20.04 ***  β .08** ref. (cid:0) .01 .22*** .06* (cid:0) .05 .37*** (cid:0) .05 .09** .01 (cid:0) .01 (cid:0) .02 .04 .03 (cid:0) .02 (cid:0) .09** (cid:0) .30** (cid:0) .32*** (cid:0) .05 (cid:0) .03 (cid:0) .02 Note: Dependent variable: Vader compound score. New independent variables added to Model 3: four LIWC negative lexicons (negative emotion, anxiety, anger, and sadness). *p < .05; **p < .01; ***p < .001. References Allport, G. W., Clark, K., & Pettigrew, T. (1954). The nature of prejudice. Addison-Wesley. Armstrong, J. S. (2001). Role playing: A method to forecast decisions. In J. S. Armstrong (Ed.), Principles of forecasting (pp. 15–30). Springer. Atzmüller, C., & Steiner, P. M. (2010). Experimental vignette studies in survey research. Methodology: European Journal of Research Methods for the Behavioral and Social Sciences, 6(3), 128–138. https://doi.org/10.1027/1614-2241/a000014. Barnard, P. J., & Teasdale, J. D. (1991). Interacting cognitive subsystems: A systemic approach to cognitive–affective interaction and change. Cognition & Emotion, 5(1), 1–39. https://doi.org/10.1080/02699939108411021. Bartneck, C., Suzuki, T., Kanda, T., & Nomura, T. (2007). The influence of people’s culture and prior experiences with Aibo on their attitude towards robots. AI & Society, 21(1–2), 217–230. https://doi.org/10.1007/s00146-006-0052-7. Baumeister, R. F., & Leary, M. R. (1995). The need to belong: Desire for interpersonal attachments as a fundamental human motivation. Psychological Bulletin, 117(3), 497–529. https://doi.org/10.1037/0033-2909.117.3.497. Brown, R. (2011). Prejudice: Its social psychology. John Wiley & Sons. Cabanac, M. (2002). What is emotion? Behavioural Processes, 60(2), 69–83. https://doi. org/10.1016/S0376-6357(02)00078-5. Carleton, R. N. (2016). Fear of the unknown: One fear to rule them all? Journal of Anxiety Disorders, 41, 5–21. https://doi.org/10.1016/j.janxdis.2016.03.011. Carton, A. M., & Cummings, J. N. (2012). A theory of subgroups in work teams. The Academy of Management Review, 37(3), 441–470. https://doi.org/10.5465/ amr.2009.0322. Chandler, J., Paolacci, G., Peer, E., Mueller, P., & Ratliff, K. A. (2015). Using nonnaïve participants can reduce effect sizes. Psychological Science, 26(7), 1131–1139. https:// doi.org/10.1177/0956797615585115. InternationalJournalofInformationManagement60(2021)10236113N. Savela et al.                                                                                                                 Chandler, J., Mueller, P., & Paolacci, G. (2014). Nonnaïvet´e among Amazon Mechanical Turk workers: Consequences and solutions for behavioral researchers. Behavior Research Methods, 46(1), 112–130. https://doi.org/10.3758/s13428-013-0365-7. Cohen, B. H. (2008). Explaining psychological statistics. John Wiley & Sons. Cohen, J. (1988). Statistical power analysis for the behavioral sciences. Routledge. https:// doi.org/10.4324/9780203771587. Coombs, C. (2020). Will COVID-19 be the tipping point for the intelligent automation of work? A review of the debate and implications for research. International Journal of Information Management, 55, 102182. https://doi.org/10.1016/j. ijinfomgt.2020.102182. Coombs, C., Stacey, P., Kawalek, P., Simeonova, B., Becker, J., Bergener, K., … Trautmann, H. (2021). What is it about humanity that we can’t give away to intelligent machines? A European perspective. International Journal of Information Management, 58, Article 102311. https://doi.org/10.1016/j.ijinfomgt.2021.102311. Coppock, A. (2019). Generalizing from survey experiments conducted on Mechanical Turk: A replication approach. Political Science Research and Methods, 7(3), 613–628. https://doi.org/10.1017/psrm.2018.10. Cowie, R., & Cornelius, R. R. (2003). Describing the emotional states that are expressed in speech. Speech Communication, 40(1–2), 5–32. https://doi.org/10.1016/S0167- 6393(02)00071-7. de Groot, A. M. (1989). Representational aspects of word imageability and word frequency as assessed through word association. Journal of Experimental Psychology Learning, Memory, and Cognition, 15(5), 824–845. https://doi.org/10.1037/0278- 7393.15.5.824. DeSteno, D., Dasgupta, N., Bartlett, M. Y., & Cajdric, A. (2004). Prejudice from thin air: The effect of emotion on automatic intergroup attitudes. Psychological Science, 15(5), 319–324. https://doi.org/10.1111/j.0956-7976.2004.00676.x. DeSteno, D., Petty, R. E., Rucker, D. D., Wegener, D. T., & Braverman, J. (2004). Discrete emotions and persuasion: The role of emotion-induced expectancies. Journal of Personality and Social Psychology, 86(1), 43–56. https://doi.org/10.1037/0022- 3514.86.1.43. Dinno, A. (2015). Nonparametric pairwise multiple comparisons in independent groups using Dunn’s test. The Stata Journal, 15(1), 292–300. https://doi.org/10.1177/ 1536867X1501500117. Dixon, T. (2012). “Emotion”: The history of a keyword in crisis. Emotion Review, 4(4), 338–344. https://doi.org/10.1177/1754073912445814. Dwivedi, Y. K., Hughes, L., Ismagilova, E., Aarts, G., Coombs, C., Crick, T., Duan, Y., Dwivedi, R., Edwards, J., Eirug, A., Galanos, V., Ilavarasan, P., V, Janssen, M., Jones, P., Kar, A. K., Kizgin, H., Kronemann, B., Lal, B., Lucini, B., & Williams, M. D. (2021). Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy. International Journal of Information Management, 57, Article 101994. https://doi.org/10.1016/j. ijinfomgt.2019.08.002. Ebbesen, E. B., Kjos, G. L., & Koneˇcni, V. J. (1976). Spatial ecology: Its effects on the choice of friends and enemies. Journal of Experimental Social Psychology, 12(6), 505–518. https://doi.org/10.1016/0022-1031(76)90030-5. Flandorfer, P. (2012). Population ageing and socially assistive robots for elderly persons: The importance of sociodemographic factors for user acceptance. International Journal of Population Research. , Article 829835. https://doi.org/10.1155/2012/ 829835. Friedman, B., Kahn, P. H., Jr, & Hagman, J. (2003). Hardware companions? What online AIBO discussion forums reveal about the human–robotic relationship. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (pp. 273–280). https://doi.org/10.1145/642611.642660. Greenberg, J., & Eskew, D. E. (1993). The role of role playing in organizational research. Journal of Management, 19(2), 221–241. https://doi.org/10.1016/0149-2063(93) 90053-P. Groom, V., & Nass, C. (2007). Can robots be teammates? Benchmarks in human–robot teams. Interaction Studies, 8(3), 483–500. https://doi.org/10.1075/is.8.3.10gro. Gursoy, D., Chi, O. H., Lu, L., & Nunkoo, R. (2019). Consumers acceptance of artificially intelligent (AI) device use in service delivery. International Journal of Information Management, 49, 157–169. https://doi.org/10.1016/j.ijinfomgt.2019.03.008. Haidegger, T., Barreto, M., Gonçalves, P., Habib, M. K., Ragacan, S. K. V., Li, H., … Prestes, E. (2013). Applied ontologies and standards for service robots. Robotics and Autonomous Systems, 61(11), 1215–1223. https://doi.org/10.1016/j. robot.2013.05.008. Conference on Web and Social Media, 8, 1 https://ojs.aaai.org/index.php/ICWSM/arti cle/view/14550. Ivanov, S., Webster, C., & Garenko, A. (2018). Young Russian adults’ attitudes towards the potential use of robots in hotels. Technology in Society, 55, 24–32. https://doi. org/10.1016/j.techsoc.2018.06.004. Kr¨amer, N. C., Eimler, S., von der Pütten, A., & Payr, S. (2011). Theory of companions: What can theoretical models contribute to applications and understanding of human–robot interaction? Applied Artificial Intelligence, 25(6), 474–502. https://doi. org/10.1080/08839514.2011.587153. Kulviwat, S., Bruner, G. C., Kumar, A., II, Nasco, S. A., & Clark, T. (2007). Toward a unified theory of consumer acceptance technology. Psychology & Marketing, 24(12), 1059–1084. https://doi.org/10.1002/mar.20196. Lang, F. R., John, D., Lüdtke, O., Schupp, J., & Wagner, G. G. (2011). Short assessment of the Big five: Robust across survey methods except telephone interviewing. Behavior Research Methods, 43(2), 548–567. https://doi.org/10.3758/s13428-011-0066-z. Lee, W., Xiong, L., & Hu, C. (2012). The effect of Facebook users’ arousal and valence on intention to go to the festival: Applying an extension of the technology acceptance model. International Journal of Hospitality Management, 31(3), 819–827. https://doi. org/10.1016/j.ijhm.2011.09.018. Maranguni´c, N., & Grani´c, A. (2015). Technology acceptance model: A literature review from 1986 to 2013. Universal Access in the Information Society, 14(1), 81–95. https:// doi.org/10.1007/s10209-014-0348-1. Moors, A. (2009). Theories of emotion causation: A review. Cognition & Emotion, 23(4), 625–662. https://doi.org/10.1080/02699930802645739. M¨ortl, A., Lawitzky, M., Kucukyilmaz, A., Sezgin, M., Basdogan, C., & Hirche, S. (2012). The role of roles: Physical cooperation between humans and robots. The International Journal of Robotics Research, 31(13), 1656–1674. https://doi.org/10.1177/ 0278364912455366. Nomura, T., Kanda, T., & Suzuki, T. (2006). Experimental investigation into influence of negative attitudes toward robots on human–robot interaction. AI & Society, 20(2), 138–150. https://doi.org/10.1007/s00146-005-0012-7. Paluck, E. L., Green, S. A., & Green, D. P. (2019). The contact hypothesis re-evaluated. Behavioural Public Policy, 3(2), 129–158. https://doi.org/10.1017/bpp.2018.25. Pennebaker, J. W., & Stone, L. D. (2003). Words of wisdom: Language use over the life span. Journal of Personality and Social Psychology, 85(2), 291–301. https://doi.org/ 10.1037/0022-3514.85.2.291. Peters, E., & Slovic, P. (2007). Affective asynchrony and the measurement of the affective attitude component. Cognition & Emotion, 21(2), 300–329. https://doi.org/10.1080/ 02699930600911440. Piryani, R., Madhavi, D., & Singh, V. K. (2017). Analytical mapping of opinion mining and sentiment analysis research during 2000–2015. Information Processing & Management, 53(1), 122–150. https://doi.org/10.1016/j.ipm.2016.07.001. Plutchik, R. (2001). The nature of emotions: Human emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice. American Scientist, 89(4), 344–350. Retrieved from www.jstor.org/stable/27857503. Reis, H. T., Maniaci, M. R., Caprariello, P. A., Eastwick, P. W., & Finkel, E. J. (2011). Familiarity does indeed promote attraction in live interaction. Journal of Personality and Social Psychology, 101(3), 557–570. https://doi.org/10.1037/a0022885. Robert, L. P. (2018). Personality in the human–robot interaction literature: A review and brief critique. Proceedings of the 24th Americas Conference on Information Systems. http ://aisel.aisnet.org/amcis2018/DataScience/Presentations/24/. Rosenthal-von der Pütten, A. M., Kr¨amer, N. C., Hoffmann, L., Sobieraj, S., & Eimler, S. C. (2013). An experimental study on emotional reactions towards a robot. International Journal of Social Robotics, 5(1), 17–34. https://doi.org/10.1007/s12369-012-0173-8. Rungtusanatham, M., Wallin, C., & Eckerd, S. (2011). The vignette in a scenario-based role-playing experiment. The Journal of Supply Chain Management, 47(3), 9–16. https://doi.org/10.1111/j.1745-493X.2011.03232.x. Russell, J. A., Bachorowski, J. A., & Fern´andez-Dols, J. M. (2003). Facial and vocal expressions of emotion. Annual Review of Psychology, 54(1), 329–349. https://doi. org/10.1146/annurev.psych.54.101601.145102. Ryan, R. M., & Deci, E. L. (2000). Self-determination theory and the facilitation of intrinsic motivation, social development, and well-being. The American Psychologist, 55(1). https://doi.org/10.1037/0003-066X.55.1.68, 68. Saad´e, R. G., & Kira, D. (2006). The emotional state of technology acceptance. In Issues in informing science & information technology, 3 pp. 529–540). https://doi.org/ 10.28945/913. Hancock, P. A., Billings, D. R., Schaefer, K. E., Chen, J. Y., De Visser, E. J., & Sage. (2003). Role playing. In M. Lewis-Beck, A. E. Bryman, & T. F. Liao (Eds.), The sage Parasuraman, R. (2011). A meta-analysis of factors affecting trust in human–robot interaction. Human Factors, 53(5), 517–527. https://doi.org/10.1177/ 0018720811417254. He, W., Zhang, Z. J., & Li, W. (2021). Information technology solutions, challenges, and suggestions for tackling the COVID-19 pandemic. International Journal of Information Management, 57, 102287. https://doi.org/10.1016/j.ijinfomgt.2020.102287. Heerink, M., Kr¨ose, B., Wielinga, B., & Evers, V. (2008). Enjoyment intention to use and actual use of a conversational robot by elderly people. Proceedings of the 3rd ACM/ IEEE International Conference on Human–Robot Interaction, 113–120. https://doi.org/ 10.1145/1349822.1349838. Hu, Q., Lu, Y., Pan, Z., Gong, Y., & Yang, Z. (2021). Can AI artifacts influence human cognition? The effects of artificial autonomy in intelligent personal assistants. International Journal of Information Management, 56, Article 102250. https://doi.org/ 10.1016/j.ijinfomgt.2020.102250. Hurtz, G. M., & Donovan, J. J. (2000). Personality and job performance: The big five revisited. The Journal of Applied Psychology, 85(6), 869–879. https://doi.org/ 10.1037/0021-9010.85.6.869. Hutto, C. J., & Gilbert, E. (2014). VADER: A parsimonious rule-based model for sentiment analysis of social media text. In Proceedings of the International AAAI encyclopedia of social science research methods. Schaefer, K. E., Straub, E. R., Chen, J. Y., Putney, J., & Evans, A. W., III (2017). Communicating intent to develop shared situation awareness and engender trust in human-agent teams. Cognitive Systems Research, 46, 26–39. https://doi.org/10.1016/ j.cogsys.2017.02.002. Schmitt, B. (2020). Speciesism: An obstacle to AI and robot adoption. Marketing Letters, 31(1), 3–6. https://doi.org/10.1007/s11002-019-09499-3. Sheridan, T. B. (2016). Human–Robot interaction: Status and challenges. Human Factors, 58(4), 525–532. https://doi.org/10.1177/0018720816644364. Sinha, N., Singh, P., Gupta, M., & Singh, P. (2020). Robotics at workplace: An integrated Twitter analytics–SEM based approach for behavioral intention to accept. International Journal of Information Management, 55, Article 102210. https://doi.org/ 10.1016/j.ijinfomgt.2020.102210. Stephan, W. G., & Stephan, C. W. (2000). An integrated threat theory of prejudice. In S. Oskamp (Ed.), Reducing prejudice and discrimination (pp. 23–46). Erlbaum. Stephan, W. G., Renfro, C., & Davis, M. D. (2008). The role of threat in intergroup relations. In U. Wagner, L. R. Tropp, G. Finchilescu, & C. Tredoux (Eds.), Social issues and interventions. Improving intergroup relations: Building on the legacy of Thomas F. Pettigrew (pp. 55–72). Blackwell. https://doi.org/10.1002/9781444303117. ch5. InternationalJournalofInformationManagement60(2021)10236114N. Savela et al.                                                                                                                 Taipale, S., Luca, F. D., Sarrica, M., & Fortunati, L. (2015). Robot shift from industrial production to social reproduction. In J. Vincent, S. Taipale, B. Sapio, G. Lugano, & L. Fortunati (Eds.), Social robots from a human perspective (pp. 11–24). Springer. https://doi.org/10.1007/978-3-319-15672-9_2. Tausczik, Y. R., & Pennebaker, J. W. (2010). The psychological meaning of words: LIWC and computerized text analysis methods. Journal of Language and Social Psychology, 29(1), 24–54. https://doi.org/10.1177/0261927X09351676. Thelwall, M., Buckley, K., Paltoglou, G., Cai, D., & Kappas, A. (2010). Sentiment strength detection in short informal text. Journal of the American Society for Information Science and Technology, 61(12), 2544–2558. https://doi.org/10.1002/asi.21416. Thelwall, M., Wilkinson, D., & Uppal, S. (2010). Data mining emotion in social network communication: Gender differences in MySpace. Journal of the American Society for Information Science and Technology, 61(1), 190–199. https://doi.org/10.1002/ asi.21180. U.S. Census Bureau. (2019). Age and sex composition in the, 2019. United States: U.S. Department of Commerce https://www.census.gov/topics/population/age-and-s ex/data/tables.2019.html. U.S. Census Bureau (n.d.). U.S. and World Population Clock. U.S. Department of Commerce. Retrieved February 20, 2021, from https://www.census.gov/popclock/. Vanman, E. J., & Kappas, A. (2019). “Danger, Will Robinson!” the challenges of social robots for intergroup relations. Social and Personality Psychology Compass, 13(8), e12489. https://doi.org/10.1111/spc3.12489. Venkatesh, V. (2000). Determinants of perceived ease of use: Integrating control, intrinsic motivation, and emotion into the technology acceptance model. Information Systems Research, 11(4), 342–365. https://doi.org/10.1287/isre.11.4.342.11872. Venkatesh, V., & Davis, F. D. (2000). A theoretical extension of the technology acceptance model: Four longitudinal field studies. Management Science, 46(2), 186–204. https://doi.org/10.1287/mnsc.46.2.186.11926. Wagner, W., Duveen, G., Farr, R., Jovchelovitch, S., Lorenzi-Cioldi, F., Markov´a, I., … Rose, D. (1999). Theory and method of social representations. Asian Journal of Social Psychology, 2(1), 95–125. https://doi.org/10.1111/1467-839X.00028. Wallin, A., Koro-Ljungberg, M., & Eskola, J. (2019). The method of empathy-based stories. International Journal of Research & Method in Education, 42(5), 525–535. https://doi.org/10.1080/1743727X.2018.1533937. Warriner, A. B., Kuperman, V., & Brysbaert, M. (2013). Norms of valence, arousal, and dominance for 13,915 English lemmas. Behavior Research Methods, 45(4), 1191–1207. https://doi.org/10.3758/s13428-012-0314-x. Wullenkord, R., Fraune, M. R., Eyssel, F., & ˇSabanovi´c, S. (2016). Getting in touch: How imagined, actual, and physical contact affect evaluations of robots. In 2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), 980–985. https://doi.org/10.1109/ROMAN.2016.7745228. Yarkoni, T. (2010). Personality in 100,000 words: A large-scale analysis of personality and word use among bloggers. Journal of Research in Personality, 44(3), 363–373. https://doi.org/10.1016/j.jrp.2010.04.001. Young, J. E., Hawkins, R., Sharlin, E., & Igarashi, T. (2009). Toward acceptable domestic robots: Applying insights from social psychology. International Journal of Social Robotics, 1(1), 95–108. https://doi.org/10.1007/s12369-008-0006-y. Yusif, S., Soar, J., & Hafeez-Baig, A. (2016). Older people, assistive technologies, and the barriers to adoption: A systematic review. International Journal of Medical Informatics, 94, 112–116. https://doi.org/10.1016/j.ijmedinf.2016.07.004. Zajonc, R. B. (1968). Attitudinal effects of mere exposure. Journal of Personality and Social Psychology, 9(2, Pt. 2), 1–27. https://doi.org/10.1037/h0025848. Zanna, M. P., & Rempel, J. K. (2008). Attitudes: A new look at an old concept. In R. H. Fazio, & R. E. Petty (Eds.), Key readings in social psychology. Attitudes: Their structure, function, and consequences (pp. 7–15). Psychology Press. Zillig, L. M. P., Hemenover, S. H., & Dienstbier, R. A. (2002). What do we assess when we assess a big 5 trait? A content analysis of the affective, behavioral, and cognitive processes represented in big 5 personality inventories. Personality & Social Psychology Bulletin, 28(6), 847–858. https://doi.org/10.1177/0146167202289013. InternationalJournalofInformationManagement60(2021)10236115