ELSEVIER Artificial Intelligence 83 (1996) 75-141 Artificial Intelligence Qualitative system identification: deriving structure from behavior A.C. Cem Say*, Selahattin Kuru Department of Computer Engineering, BogaziGi University, Bebek 80815, Istanbul, Turkey Received August 1993; revised December 1994 Abstract comparative (which perform simulation, it using a library of model fragments and input them. System identification their behaviors. We present Qualitative reasoning programs analysis, data interpretation, etc.) either take the model of the physical system to be considered as input, or compose about how to combine is the task of creating models of systems, using data algorithm QSI, about the qualitative which takes as input a set of qualitative behaviors of a physical system, and produces as its input output a constraint model of the system. QSI’s output when simulated. Furthermore, “deep” in the input behaviors. Various aspects of parameters of the system which do not appear QSI and its applicability are discussed. to produce the QSI-made models usually contain meaningful to diagnosis, as well as the model fragment formulation problem, is guaranteed identification information system 1. Introduction Research in in qualitative reasoning many programs designed being produced. These the underlying mechanism of the system under consideration as part of their input and analyze or predict reasoning about physical systems [36] has resulted to achieve various reasoners in one of a variety of ways. take a “deep” model of tasks of commonsense its behavior Before performing any kind of model-based reasoning, one has to have a model of the system which will be reasoned about. The model composition methods used large amounts of by some current or information issue of initial mechanisms about physical that can be used the various kinds of components to build systems, overlook require possession of reasoners, which laws and the * Corresponding author. 0004-3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved SSDZ 0004-3702(95)00016-X 76 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 it is in these cases that the modeling creation of model fragments with which the complete system models are built. When faced with a novel situation, or a new mechanism whose description is not in the library, reasoners employing such an approach may be unable to available task is the achieve modeling, even though most important and interesting. Leaving the preparation of the models completely to the “user”, on the other hand, is clearly not a way out, from the point of view of artificial intelligence, which aims to automate human behavior. When one examines what humans do in similar situations, mental model of the “laws” of the system under consideration after a period of observation “algorithm” whose input is the behavior of the system, and whose output system model. This is essentially does. quantitative, it is seen that a can be formed, the system’s behavior, which suggests an is the the reverse of what simulation, qualitative or of This task of behavior-based model construction mature field, named system identification. As a result of extensive research field, widespread in the numerical domain have been produced. identification program which performs Qualitative System Identification, representation, physical system, and its output is a constraint model of that system. algorithms which perform is the subject of an already in this system In this paper, QSI, a using the qualitative is presented. QSI’s input is a set of qualitative behaviors of a of efficient applications reasoning and algorithm, which we have borrowed The outline of the paper is as follows: Section 2 is an overview of the aspects of relevant to the modeling problem. The device- views of modeling are briefly examined. The QSIM in the construc- system the of The for QSI, is discussion on the to diagnosis as to other work in the field. Section 7 is issues, and contain several qualitative physical centered and process-centered [19, 221 representation tion of QSI, are summarized. Section 3 puts QSI identification algorithm, qualitative noise filtering method, designed to serve as a preprocessor presented strengths and weaknesses of the QSI algorithm, well as model formulation, a conclusion. The appendices cover some technical examples of the program into a detailed and correctness in Section 5. Section 6 contains a comprehensive Section 4 contains its complexity perspective. and analyses of the broader explanation its applicability and its relation properties. in action. 2. Qualitative physical reasoning: an overview This section is an overview of the technique of qualitative simulation; the major approaches will be briefly discussed in chronological order. De Kleer and Brown [7] established the foundations of the qualitative calculus. by a finite their signs. The time derivatives of each quantity The basic idea is that real (continuous) quantities are represented number of qualitative values: is are similarly represented. The fact that a quantity represented by its derivative having the value +. A mechanistic world view is adopted; every system to be simulated is assumed to be a mechanism composed of is increasing, for instance, A.C.C. Say, S. Kuru ! Artijicial Intelligence 83 (1996) 75-141 77 is supposed if the program in the simulator’s component input system models are formed by connecting com- simple components. The library (which obviously has to be ponent models large to deal with a large variety of to be able systems), according to the device topology of the system. Each component has its own “law”, an equation relating the variables involved with it. The laws of all the this means that they can be components the qualitative values of all the solved as a system of equations variables to to determine which transitions other syslem states, where certain variables have qualitatively different values, are possible. A graph of system states, each path through which represents a different prediction to determine in them. The derivatives are examined for the behavior of the simulated system, is thus constructed. of a mechanism have to be satisfied; the constraints use of a process their configuration, library reasons) is the process-centered as discussed. An alternative in the considered active. A process reflecting Since time derivative The method of de Kleer and Brown embodies a component-centered scene are determined is something which causes changes; approach approach of to modeling, the relationships holding among the qualitative process theory [13]. In this theory, that are by the processes quantities currently like heating, cooling, boiling, stretching, etc. Given information about the values, individuals, (which should be as big as and possible, again for the above-mentioned is made to come up with the system m’odel, properly composed of various model fragments contributed by the the system active processes, quantities it is possible t’o determine which quantity is nearing which landmark. (A landmark is a a point value which is significant for the purposes of the symbol the set of active processes, change model.) The system state and, sometimes, when a quantity crosses a landmark value. A state graph, similar to the one mentioned states to successor states determined an of qualitative simulation. The method of transition ordering, which can be used to determine which of a group of related quantities in the system will change qualitative value earlier, was first presented in [38]. Williams focused his work on the domain of electrical circuits, where the need for tutoring, design, and diagnosis aids which can explain the workings of the circuits in terms of causal explanations based on the simple component is constructed by linking predecessor in this manner. role is also kept for quantities, in the previous paragraph, laws is evident. the perfection [38] played representing impose on information important Williams they that in The QSIM algorithm [19] is in many ways the most advanced qualitative of qualitative models in our simulator. We chose to adopt QSIM’s representation research. QSIM leaves the modeling task entirely system model has to be written explain in detail, before simulation can begin. in the qualitative to the user; a correct and complete format, which we will now Each ODE (Ordinary Differential Equation) obeying certain restrictions can be that is, a to a corresponding QDE (Qualitative Differential Equation), translated set of qzulitative constraints, which describes are time-invariant relationships between the same system. These constraints func- the parameters (continuous-valued 78 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 7.5-141 Table 1 The qualitative constraint types Constraint ADD(X, Y, Z) DERIV(X, Y) M+ (X, Y) M-(X, Y) MINUS(X, Y) MULT(X, Y, Z) Explanation Z(C) = X(t) + Y(t) dXldt = Y X(t) =f(Y(t)), wheref’ > 0 throughout X(t) =f(Y(t)), wheref’ <O throughout x(t) = -Y(t) z(t) = X(t) * Y(t) (except tions of time) comprising the system. There are six types of constraints Each constraint type) may possess those of corresponding values (CVs) of particular values of the parameters manner, additional be represented. QDEs are formed of instances of constraints parameters. A system may have several operating regions, each corresponding cases in which it is governed by a different QDE, as exemplified below. (Table 1). tuples of it binds; in this information about the relation embodied by the constraint can linking the system to the DERIV As a classic [22] example that will also be used later in the discussion, consider how a simple U-tube (Fig. 1) is modeled. The U-tube, state, is made of two tanks connected by a pipe. The QDEs for the cases where tank A or regions to tank B are burst will also be considered. So one has three operating model: NORMAL, A-BURST, and B BURST. in its “healthy” After a lot of simplifying assumpt&ts, of the system are identified as in Table 2. (A quantity space is an ordered set of the landmarks of a -co, 0 and CQ are members of every quantity space.) parameter. The landmarks There are also the invariants that the amount and pressure parameters are never negative. the parameters The constraints and the following for operating tables describing QDEs, region NORMAL are listed in Table 3. In this the “natural” CVs of the arithmetic Fig. 1. U-tube in operating region NORMAL. Table 2 Parameters of the U-tube system Parameter amount A amount B flow-A6 flow_BA pressure-A pressure-B p_diff_AB Quantity space {-m, 0, AMAX, m} {-a, 0, BMAX, m} i-m, 0, m> 1-m, 0, m) {-? 0, m) I-m, 0, m> 0, m> I-? Remarks is maximum capacity is maximum capacity AMAX BMAX flow from A to B flow from B to A pressure at bottom of A pressure at bottom of B - pressure-B pressure-A A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 79 Table 3 U-tube constraints Constraint in region NORMAL pressure-A) , pressure-B) M+(amoun_A, M+ (amourlt_B DERIV(amount_A, DERIV(amount_B, ADD(pressure_B, M+ (p_diff__AB , flow_AB) MINUS(flow_AB, flow_BA) flow_AB) flow_BA) p_diff_AB, pressure-A) cvs (0,O) and (a, m) (0,O) and (Y m) (0,O) and (m, m) constraints shown need not appear for any M+ constraint. (like (0, 0) for MINUS) are not shown; note that the ones that are tank bursts. that when an amount parameter Suppose corresponding constraints The changes are caused by the fact that amount-B region. The QDE for A-BURST for the ensuing operating If B exceeds BMAX exceeds region, B-BURST, its maximum capacity, in region NORMAL, the the are then as in Table 4. is fixed at 0 in this operating Consider is similar. the state where some water has been instantly poured tank B is empty. This point state, which can be completed by propagation using QSIM’s knowledge of constraints, values from shown in Table 5. to tank A, and of is this initial information Note for parameter shown as landmarks or intervals between consecutive the qualitative representation states: the magnitudes are landmarks, and the sign of Table 4 U-tube constraints Constraint in region B-BURST M+ (amoun_A, pressure-A) M+ (amount_B , pressure-B) DERIV(amount_A, ADD(presz.ure_B M+(p_diff_AB, MINUS(flow_AB, flow_BA) flow_BA) , p_diff_AB , pressure-A) flow_AB) cvs (0,O) and (m, m) (0,O) and (a, 9 (0,O)andkm) Table 5 Initial state of U-tube system Parameter amount-A amount-B flow_AB flow_BA pressure-A pressure-B p_diff_AB Value ((0, AMAX), dec) (0, inc) ((0, 9, dec) ((-a, O), inc) ((0, 9, dec) (0, inc) ((0, 9, dec) ?99emit0r$)4>ot(o[F’c\b$e$R%?z3;;L51t),twr(0t1temit)ced,9,0(()ced)z,!Is3)cni,9,0(()dts,BP()cni,0()ced,9)ced,00,0((,0(()cni,)O)cni,)O,m-f(,m-f()dts,AP()dts,0()ced)ced,9,9,0((,0(()dts,0(BA_ffid_pB-erusserpA-erusserpAB_wolfBA_wolf)cni,)XAMB,0((B-tnuoma)cni,0()dts,BweN(.}m,XAMA,AweN.}m,XAMB,BweN,0,0,m-{:A-tnuoma,m--{:B-tnuoma.}m,AP.}m,BP,0,0,a-{,00-{:A-erusserp:B-erusserp)ced)ced,)XAMA,)XAMA,0,0(((()dts,AweN(A_tnuomafofofofoecapsecapsecapsecapsytitnauQytitnauQytitnauQytitnauQebut-Uehtfol#roivaheB6elbaTebut-Uehtfo2#roivaheB7elbaTBA_ffid_pB-erusserpA-erusserpABwoABA_woIiB_tnuoma)ced)ced,9,9,0((,0(()dts,0()cni,9,0(()dts,BP()cni,0()ced)ced,9,9,0((,0(()cni,)O)cni,10,m-((,m-(()dts,AP()dts,0()ced)ced,9,9,0((,0(()dts,0()dts,XAMB()cni,)XAMB)cni,0(,0(()ced)ced,)XAMA,)XAMA,0((,0(()dts,AweN(A_tnuoma.}m,XAMA,AweN,0,m-{.}m,AP,0,oo- -{.}m,BP,0,m--{:A-tnuoma:A-erusserp:B-erusserpfofofoecapsecapsecapsytitnauQytitnauQytitnauQ                                                                                                                    A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 81 is part of its qualitative state: inc, std, and the time derivative of each parameter dec mean +, 0, and -, is used for time as well, a qualitative behavior of the system will be a sequence of its states at t,, (to, tl), respectively. Since the point-interval representation t2), etc. t,, (tl, from the root (i.e. time is “advanced”) QSIM builds a tree of system states whose root is the initial state. Each path in to a leaf is a predicted behavior of the system. The this tree as follows: All the successors of each node are created system states comprising of all the possible qualitative states that each parameter can take on in the next time point or interval (obeying continuity) are implicitly there are only four “next” states that a quantity whose created. current state is ((a, b), inc) can take on: ((a, b), inc) again, (b, inc), (b, std), or (x, std) , where x is a new landmark between a and b.) Of these system states, in the QDE hold are acceptable as only the ones in which all the constraints possible “next” states of the system, i.e. successors of the current node. In this manner, is guaranteed. the prediction of all the possible future behaviors of the system (For example, The three behaviors that QSIM predicts for the input of Tables 3 and 5 (tank A contains liquid, tank B is empty) seen in Tables 6-8, are: l behavior #l: the amounts stabilize at landmarks below the maximum capacities; l behavior #2: amount B stabilizes just at BMAX, narrowly avoiding a burst; the the liquid l behavior #3: in tank A drains away from tank B bursts, “hole”. The quantity spaces of parameters landmarks have been discovered are listed below the tables. As can be seen, simulation stops when all parameters have the qualitative direction std, a heuristic lets the reasoner assume that the system has reached equilibrium for which new in such cases. region transition the is set to zero. Discontinuous During in Table 8, amount_:B changes are also seen in the values of and each p_diff_AB, and the flows, which are linked to amount-B pressure-B, other by constraints. For this run of QSIM, the state tree produced has the shape shown in Fig. 2. The point states are shown as circles in that figure, and the time from NORMAL to B-BURST Fig. 2. State tree for U-tube simulation (time values shown). w8LSw$jRa22Lh),t,,r()ced,),DweN,t)ced)ced)ced)ced,,DweN(,DweN((),t.*r(21,r)ced,)DweN,0(()ced,DweN()dts,0(BA_ffid_pB-erusserpA-erusserpAB_wolf,9,9,0((,0((,DweN()cni,)a)cni,0((,VI()cni,0()ced,)m)ced,)a,0((,0(()ced,AP()cni,)O)cni,)O)cni,RweN(,m-((,m-(()ced)ced)ced,FweN()cni,XAMB(BA_woIt,)m,9,0((,0(()cni,)XAMB)cni,0(,0(()ced)ced,)XAMA,0((,)XAMA,0((B_tnuomaA-tnuomaebut-Uehtfo3#roivaheB8elbaT)wonsruccoTSRUB-BotLAMRONmorfegnahcnoigergnitarepO()dts)dts)dts)dts)dts,0(,0(,0(,0(,0()ced,)AP,0(()cni,)RweN)ced,AP()cni,,RweN(,,RweN(()ced,),FweN)ced,,FweN(,FweN(()ced)ced,)AP,0((,)AP&(()dts,0()cni,)0,RweN(()ced,)FweN,0(()cni,RweN()ced,FweN()dts,0()dts,0(.}m,XAMA,AweN,0,m-{.)0~,,FweN,FweN,0,m--{)dts)dts)dts)dts)dts,0(,0(,0(,0(,0(:A-tnuoma:BA_wolf._---.}m,,DweN,DweN,0.}m.}m,AP,BP,0,0,m--{,m--{,m--{:Berusserp:A-erusserp:kA_ffid_p.}a,0,RweN,,RweN,m-{:AB_wolf)ced)ced)ced,)AweN,)AweN,)AweN,0((,0((,0((fofofofofofoecapsecapsecapsecapsecapsecaps)dts,0(ytitnauQytitnauQytitnauQytitnauQytitnauQytitnauQ)ced)ced,AweN(,AweN(                                                                                                                       A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 83 Fig. 3. Spring/block system. value corresponding the same first two states is obvious from the figure. to each level is indicated. The reason why all behaviors have For some inputs, qualitative simulation programs predict spurious behaviors, inherent [34], which is actually the one we incorporated some of which cannot be exhibited by any system with that model. Although these spurious predictions are results of the manner in which corresponding value tuples are kept in the original QSIM algorithm, and can be eliminated by using an improved version into QSI, an even by this improved important class of spurious behaviors the qualitative algorithm. The information system representation in [19] of Fi.g. 3, the QDE of which can be seen in Table 9, spurious behaviors for which instance. the horizontal position, velocity, and acceleration of the block.) Kuipers [19] points out that this problem can be overcome by providing a deeper and is needed. QSI is a step in this therefore work in the realm of model preparation direction. thle block stops at a different point at each period are produced, the nature of In the case of the spring/block (The parameters X, V, and A are, respectively, remain undetected in is the cause of this problem. to the simulator, system model loss 3. QSI as system identification First of all, a potentially confusing difference things we call parameters The system “conventional” constants which appear main concern tion, a constant can be described, landmark. is to identify identification in the equations in terminology will be clarified. in this paper are generally called variables in the parameters are the system, and the In SI literature, (models) describing (SI). their values precisely. if necessary, In the qualitative as a parameter representa- “stuck” at a Generally, there are two kinds of variables input variables can be controlled by “us”, and changing in SI: input and output variables. to task. An SI experiment consists of their values the system properly is an important The “excite” Table 9 QDE of spring/block Constraint DERIV(X, V) DERIV(V, A) M-(A,X) system cvs (0, 0) 84 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 time points. As a complicating is usually present, and has to be taken the first thing to do is to determine this excitation and the recording of the variable values for some time. Almost are real-valued and are made at (usually equidistant) always, the measurements discrete these into account. Once the data are values, collected, that is the form of the equation being searched. This model structure determination problem is still an important issue of SI [26], which involves the following questions: What should the equation “look like”, how should it “link” the variables together so that it is an acceptable description of the physical system? What should be its basic parameterization? factor, noise, which may corrupt Once a model structure has been decided, the parameters in that equation are estimated, using statistics-based values which, when “inserted” variable values seen in the experiment. algorithms. The aim is to find the parameter the to their places in the model, will predict The model which emerges as a result of this procedure tested, and accepted only if it seems to describe the system at hand appropriately. Otherwise, one has to go back to the parameter estimation, structure determination, or even the experiment stages, to try it with new decisions all over again. is then The most extensively step. Elaborate researched and accomplished part of SI is the parameter for this task have been de- algorithms numerical estimation veloped . There has been some work [40] on performing SI with fuzzy values and models, aimed at handling cases where the available information is incomplete. QSI’s input is a set of QSIM behaviors of the system to be identified, and its to also has in the system. Apart the adoption of the QSIM representation is a QSIM-style QDE describing information, that QSI fits naturally reasoning output handle incomplete the advantage the qualitative to the “modeling” gap, discussed above, its ability repertory. from QSI does not cover the experiment design and execution stages of SI: It starts input and output it has no distinction of them); note that, in this sense. Various with ready parameters in the QSIM representation, are “equal” issues that arise about QSI’s input will be discussed later. (qualitative) in the same manner (actually, the behaviors. all parameters data about It treats The QSI algorithm may be viewed as a way of finding better and better model as will be explained shortly. QSI has the ability of postulating deep structures, variables of the system, which are not visible in its input. The model testing stage is also a part of QSI, but the “testing” here has a different meaning than that of it does not need SI: QSI tests its models to see whether the models are to test whether created they are “deep” enough; the input behaviors, because in such a way that they are provably correct, see Section 4.9. they really describe Although the qualitative representation noise filters, based on simple observations into QSI. been designed for incorporation itself is resilient to noise, qualitative about the nature of noise, have also QSI’s relation their quantitative unknown) useful results through much simpler computation. information, keep the qualitatively to SI is similar to those of other qualitative reasoning methods counterparts: The qualitative methods suppress to (or important distinctions, and arrive at irrelevant A.C.C. Say, S. Kuru I Art@cial Intelligence 83 (1996) 75-141 85 The actual algorithm that QSI uses to generate the models is fundamentally different from anything that SI uses. This underlines AI progr,ams, which make symbolic computation, which perform numeric computation. QSI performs models; since the building blocks of the equation already known and are finite “operators” combinations until the correct one is found can be developed. the traditional difference of programs, from “non-AI” in the space of the system are the and a well-defined method of trying out all the that describes are are the constraints), (the “operands” the parameters a search 4. The QSI algorithm To avoid conceptual cluttering, the preprocessors, which are used for convert- input to qualitative form and qualitative noise filtering, ing the possibly numerical will not be explained until a later section. This section will be devoted to the “core” of QSI, the basic algorithm [31-331 which constructs system models from their behaviors. The requirements on the input, the formats of input and output, examples, detailed discussions of the algorithm’s individual stages, and complexity and correctness analyses will be presented. 4.1. Input and output The input it may be the case that only some of the parameters to QSI consists of one or more behaviors of the system to be seen in these behaviors. As identified!, and the quantity spaces of the parameters that would mentioned before, appear in a deep model of the system are easily observable, and therefore “at first sight”, one may think that the system consists only of these parameters. For this reason, QSI allows the possibility that its input does not contain all the system and tries to find the deeper parameters by itself. On the other hand, parameters, as the for each possible initial state which appears to find an appropriately input should contain as many qualitatively that would be expected/observed in the input should be present), (in fact, all the behaviors distinct system behaviors if QSI is expected deep model. Since a QSIM model that produces it will be looked for, the input should be generable by QSIM, i.e., there should be a QSIM input set (unknown, of course, at this stage) that would cause QSIM to produce it as output. This means that the input behaviors cannot be just any sequence of qualitative states: Definition 4.1. A behavior rules of [‘19] throughout the behavior. is T-legal if all the parameters in it obey the transition The QSIM transition rules embody all kinds of change that a continuous-valued quantity can undergo. Barring operating that are dealt with in this domain obey these rules. All “real” systems behave like this (at least, at the commonsense scale in which one is viewing them). All QSIM outputs which do not contain operating region changes are, by construction, T-legal. region changes, all quantities 86 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 QSI requires only be “shown” a single operating feeding QSI by the system behaviors at different operating regions can be obtained. all the operating that its input behaviors are T-legal, so in a single run, it should runs, by the QDEs of region of a system. In consecutive regions, Apart from operating region changes, another source of T-illegal behaviors is the following: Suppose one is monitoring a system, as in [9]. Because of one’s measurement in the actual qualitative behavior of the parameter being measured. This may lead to constructed as a result of the measure- discontinuous ment . intervals, one may “jump” over some states changes in the “behavior” that appear Actually, the constraint determination well for T-illegal and T-legal behaviors, parameters extension stages requires in the input behaviors, but the nature of the model depth the T-legality assumption, as will be seen. stage (Section 4.4) of QSI works equally i.e., it finds all constraints valid on the test and To represent output, QSI employs may appear after each input behavior. Their meanings are as follows: some properties of behaviors in its the input marker symbols EQU and CYC. These markers that QSIM is able to indicate l EQU requires that in the last state of the behavior it precedes, all qualitative directions are std, and means that the system is quiescent from that time on. (This conclusion is heuristic, of course, see Section 2.) l CYC requires that the last state of the behavior it precedes has appeared before in that behavior, and means that the rest of the behavior landmarks discovered during simulation can be distinguished The is cyclic. from other ones specified “disclm” in QSIM’s output, and QSI also requires in the input quantity spaces, by preceding (standing for “discovered landmark”). the that such landmarks be their names by the string Note that none of these requirements about the input violates the “spirit” of to: things, and a the system identification Equilibrium simple method of understanding which observed behavior becomes behavior. std for some and lets the algorithm know more than it is “allowed” and cyclic behavior are generally easily observable landmarks are discovered during is to designate all nonzero values at which the parameter in that time as that parameter’s discovered landmarks Actually, QSI starts execution with much less information that it is “entitled” to: It has no idea at all about what the parameters are; unit (or even, dimension) information on the parameters, which goes without saying in SI, is nonexistent, the most natural and even are never cannot be used. The fact that QSI is still able to find the models, as negative”) will be demonstrated, shows the algorithm’s potential strength. invariant knowledge (like “amounts QSI’s input may also contain an integer representing iterations allowed this item is absent, for the algorithm. When assumed to be infinite. The allowable number of excess behaviors is also an input item. (See Section 4.6 for explanations.) the maximum number of the number is in depth testing Finally, selectors if he wishes, and search mode in the input; these specify certain restrictions on the model search that include postulation the user may A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 87 will be performed, additional explained. information and can be utilized for efficiency reasons, especially when (“hints”) about the sought model is available, as will be QSI’s output consists of one or more constraint sets, which are models of the is deeper (i.e. the input behaviors. Each QDE in this sequence than its predecessors, with the last system exhibiting has more (constraints and invisible parameters) one being an appropriate description of the system. 4.2. The algorithm deep or not. The algorithm starts with a stage of constraint determination on the input it is behaviors. The QDE obtained as a result of this stage is tested to see whether found. appropriately to contain new Otherwise, parameters, is made on this set, followed by a new test. This loop is exited when a “good” model is found. The model is enhanced by in the arithmetic constraints, and making use of dimension language: the algorithm information terminates. Here is the algorithm and constraint determination the behaviors) are extended the model (and, therefore, the model has been in a pseudo-high-level If it passes inherent test, the BS := set of system behaviors perform Constraint Determination from input on BS, resulting in system QDE loop: print the QDE if the QDE passes the Depth Test then blockbegin impose Dimension Consistency on the QDE, resulting in final model print final model terminate blockend (* Depth Test not passed *) pos#tulate new parameters; EBS := BS U {the new parameter behaviors} on the EBS, perform Constraint Determination resulting in the extended system QDE BS := set of system behaviors involving parameters that appear in the QDE go to loop stage finds all determination The constraint the It considers all possible constraints behaviors given to it, using a simple method. it holds on the given set of parameters, found in throughout this manner that are not algebraic consequences of already existing ones are added to the model. test stage uses a slightly modified version of the QSIM the sequence of input states. However, not every constraint is included in the resulting QDE; only the “useful” constraints and controls each of them to see whether The model depth the constraints valid in 88 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 to make is then examined. Since its decision. The QDE produced by the previous stage is algorithm in QSI’s input. The simulated by QSIM for each distinct initial state appearing output of QSIM stage performs correct system identification on its input, QSIM’s output in this stage is in Section 4.9.) bound What is the number of QSIM behaviors level (see discussion extension terminates after the dimension consistency stage. that do not appear in the QSI input. If these are above an “acceptable” is deemed “loose”, and model and the algorithm is accepted to contain all of QSI’s input behaviors. is really checked in this stage of the algorithm the constraint determination is performed. Otherwise, the QDE the QDE in Section 4.6), (This is proven The model extension stage involves adding new variables sums, squares, etc. of the old parameters. the system. These new parameters are obtained derivatives, which may tighten QSIM simulation by constraint determination, the model; i.e. they are “discovered” by QSI. the involved parameters into the equation of from the old ones; they are the relationships in this extended set of parameters are found added to are permanently If interesting The dimension consistency stage converts where the discovered dimension rules imposed by the constraints on their parameters and MINUS constraints’ requirement have been satisfied by the postulation of possible “buffer” parameters constraints. the obtained model to a “real” one relationships among the quantities still hold, but the simple (such as the ADD that their parameters have the same units) and M After an example which illustrates these concepts, each stage will be discussed in detail. 4.3. An example the U-tube (in operating As an example to the operation of QSI, appear as parameters region NORMAL) of Section 2 will be considered again. Since the QDE of this system is. Of has already been seen, one has an idea of what the underlying model course, QSI has no such information when it starts. Suppose that only the amount in the input. (It is very likely that only these two would be parameters recognized of this system after a “shallow” observation.) Two behaviors of this system are input: One of them starts with amount-A decreasing and amount-B the opposite case. (To keep the example as simple as possible, the maximum capacity limits of the tanks are not considered at all. The algorithm would work equally correctly in the case they are included, and the following discussion would still apply. The where number of input behaviors would rise in that case, to cover the various ordinal that the amounts could have with their maximum landmarks at the end relations of the behavior region.) So the input behaviors are as in Tables 10 and 11. zero and increasing; the other describes in this operating The constraint determination stage tries out all constraints syntactically possible on amount-A is tried, but it fails in the very first state in the input, so it is discarded. The only and amount-B. For example, DERIV(amount A, amount-B) A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 89 Table 10 U-tube identification, input behavior #l amount A ((0, 9, dl:c) ((0, m), dl:c) (disclmA, std) amount B (0, inc) ((0, 9, (disclmB, std) inc) EQU time constraint that is satisfied throughout it forms the initial QDE on its own. the input is M-(amount-A, amount-B), so inversely proportional simple reflection about that no such constraint appears the system confirms in the operating in the U-tube model of Section 2. Note in the that the amounts However, region NORMAL. The tanks are indeed (That the M-. human who wrote the system.) On the other hand, QSI, which is model still adequately describes has designed not to miss any significant constraints on the known parameters, found it. (The “human” aspects of modeling versus QSI will be discussed further in Section 6.) the QDE of Section 2 chose not to include is simulated This single constraint model test stage from both the model cannot pass the test; it is too initial states in the input. As expected, shallow. The single constraint cannot represent the inner mechanism which causes the system to arrive at equilibrium. Among the behaviors generated by QSIM at this stags are those where one amount starts increasing from zero, while the other one arrives at, and even goes below, zero. So a model extension in the depth is necessary. (The extent of postulation The model extension stage begins with the computation of the behaviors of the newly p’ostulated parameters. can be modified. For certain problems, more efficient solutions with less postulation are possible; see in full Appendix B for a complete to the old postulation mode.) Since the new parameters are linked by constraints their values at each state can be ones, whose values are already known, calculated. Possible ambiguities are resolved using certain heuristics. (See Section say, and Px and Py, which are 4.5.) Fo:r example, consider and the sum of the two amounts, defined ‘to be the time derivative of amount-A, respectively. The defining constraints of these parameters are therefore list of new behaviors two new parameters, this example for DERIV(amount_A, Px) , ADD(amount_A, amount-B, Py) . Table 11 U-tube identification, input behavior #2 amount A ((0, inc)) ((0, 9, irlc) std) (disclmA, amount B ((0, 9, dec) ((0, 9, dec) (disclmB, std) EOU time t ll (to> t,) f1 90 A.C.C. Say, S. Kuru / Artificial Intelligence 83 (1996) 75-141 Table 12 U-tube identification. behaviors of two of the oostulated narameters System behavior #1 amount A amount B p, . p, ((0, 9, dec) ((0, 9, dec) ((0, m), inc) std) (dischA, (0, inc) (&clmB, std) 1 : (C-m, 01, inc) ((-m,O), inc) (0, std) 1 1 : (nlm, std) (An, std) (nlm, std) : : : EQU System behavior #2 time to (to> tl) t1 amount-A amount B - PX . . PY . . . time (0, inc) ((0, 9, inc) std) (disclmA, dec) ((0, 9, ((0, 9, dec) std) (disclmB, 1 1 1 ((0, 9, dec) ,“dj dec) 150, ,S 1 1 (nlm, std) (nlm, std) (nlm, std) : : 1 to (to7 t,) t1 Quantity space of PY: I--m, 0, nlm, m}. EQU By the use of the heuristics, which basically say that “things change as infrequent- ly as possible”, and the system to include them, as shown in Table 12. Already another behaviors are augmented important relationship has been discovered: The sum of the amounts is fixed, i.e. mass is conserved. behaviors are calculated, the new parameter Constraint determination on these larger behaviors in two or more constraints which do not algebraically is more involved. Parame- imply ters which appear involving them are made each other are added to the model, and the constraints in the behaviors of Table 12, the constraint part of the QDE. For instance, is seen to be satisfied. Parameter Px's defining Px, amount-B) ADD(amount_A, Px) is (of course) also satisfied, because of the way constraint DERIV(amount_A, we assigned the values for Px. These in the two constraints are “independent” from the other one by algebraic sense that neither one of them can be obtained no matter how many additional assumptions are made. (In fact, if manipulation, one considers the the dimensions that the parameters two constraints are inconsistent; we handle this issue in the dimension consistency to the system model at this point. stage.) So QSI would add these two constraints Note if a new of its defining con- parameter this constraint de- straint, termination, to be implied by others already tuple by tuple, which is good for efficiency. that not all defining constraints need end up in the final model; in any constraint a lot of constraints which can be proven in the model are not even checked it will not be incorporated involved have to possess, in the QDE. During does not appear independent The U-tube QDE found after one iteration of model extension search mode and fed to the depth in derivative postulation/half in Table 13. The simulation of this model from the initial states predicts only the input behaviors, so an acceptable model has been obtained. test module is presented A.C.C. Say, S. Kuru / Artificial Intelligence 83 (1996) 75-141 91 Table 13 Constraint:; found in the U-tube identification Constraint M-(amoun_A, DERIV(amount_A, DERIV(amount_B, ADD(amount_A, P,, amount-B) ADD(amount_B, P,, amount-A) amount-B) P,) P2) The A.DD constraints three buffer parameters the valuable ADD relation, in this model involve the addition of a quantity with its time derivative, which is arithmetically not legal. To legalize the situation, while for the arguments of keeping to each ADlD are postulated. The buffer parameters are linked by M+ constraints as the the ADD arguments, in operating corresponding ADD argument. The resulting model of the U-tube region NORMAL slightly the model of Section 2, a correct and deep description of the different system. The newly postulated parameters are seen to correspond to the following actual quantities: in Table 14, which is, although and each has the same quantity is the one shown space structure than Flow into tank A. Flow into tank B. P,: P2: P3, ip,: Pressure at the bottom of tank A. PS) P& Pressure at the bottom of tank B. P4: P7: The pressure difference between The pressure difference between tank B and tank A. tank A and tank B. The method’s power of hinting at meaningful deep parameters is thus demon- ((See Section 6 for deep parameters which are not so meaningful, and an strated. interpretation for them.) Various more detailed features and some problems will be discussed in further Table 14 Final U-tube model after identification Constraint cvs amount-B) P,) P2) M-(amount_A, DERIV(amount_A, DERIV(amount_B, M+(amount_A, Ps) M+(J’,> PJ M+(amount_B, P5) ADD@‘,, iD4> P5) M+(amount_B, P6) M+P,, p,) M+(amount_A, P,) ADD@‘,, 14, P,) (0, O), (m, m), (-m, (0, O), (m, m), (-m> -00) (0, O), (Y 97 (-m, -a) -9 (0, O), (Y 9, (0, O), (Y 9, (0, O), (m, 9, -m) (-m, (-m> -9 (-m, -m) 92 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 examples follows. in the text. An in-depth discussion of each of the individual stages now 4.4. Constraint determination The constraint determination language algorithm below. Remember and the output is a set of constraints. where system identification model in some way or another. itself is performed, process is summarized in the pseudo-high-level that the input is a set of system behaviors, In this sense, this stage is the part of QSI the others deal with improving the for each constraint type CT do for each tuple ARG of parameters that can be arguments to CT do if existing constraints do not contradict CT(ARG) then if CT(ARG) then is a consequence of existing constraints write (CT(ARG)) else blockbegin for each qualitative state in the input do if CT(ARG) does not hold then break out and go to blockend {At this point, CT(ARG) out the input} write (CT(ARG)) add CT(ARG) to the QDE of the system is a novel constraint valid through- blockend In the algorithm above, an accumulation and control of possible CVs of the CT is also part of the check about whether is added to the QDE, any discovered CVs go with it. it “holds” or not. When CT(ARG) How many different qualitative constraints can be written on p parameters? for every types, and all of them have to be considered There are six constraint combination of parameters. M+ has to be checked on all pairs of parameters. However, is commutative, M+(Y, X) need not be checked if M+(X, Y) has already been checked. The same applies for M- and MINUS. (MINUS is a special case of M- anyway.) For each of these types, the number of constraints that will be checked is thus since M+ P 0 =P.(P-l)_P’-P 2 2 2 . (4.1) DERIV is not commutative, so twice as many of those have to be considered as any one of the above-discussed ones, that is, A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 93 DERIVs will be checked. (4.2) among relationships ADD and MULT are commutative, (Not all “additive” or “multiplicative” so that their first two arguments can be the interchang,ed. are noticed at this stage: Note that any addition or multiplication of parameters than two operands can be expressed as a set of three-argument ADD or more is MULT constraints as defined the first {A, B, C, D} and the relationship A + B + C = D holds among representing this equation constraint determination to write them in the QSIM to the QDE, since an additional parameter are of constraints format: ADD(A, B, P), ADD(P, C, D). Such “cascades” discovered1 later in the model extension stage; see Section 4.5.) The formula for the number of controls of ADD and MULT constraints on three different parameters does not add the constraints is required in Section 2. If one’s initial set of parameters is thus these, 3 * (!I) = 3. P.(P-~(P-~) 6 =P’-~P~+~P 2 ’ (4.3) since this is a matter of choosing will be the third argument. three parameters, and deciding which of these Have all the possibilities been exhausted? There is still one more meaningful relationship which can exist between parameters, in the present vocabulary. The parameter X can be the square of parameter Y, that is, MULT(Y, Y, X) may be valid. Since this is a noncommutative like DERIV, p2 -p. be express,ed as ADD(Y, Y, X). Since this is qualitatively equivalent X), and a:lso not very common binary relationship is again (The reader may note that there is also a “twice” relationship which can to M+(Y, that will be tried in this manner this combination The total number of possible constraints on p parameters and which is expressible the number of MULTs is not checked.) in practice, is therefore the sum (4.4) of the above, i.e, 2p3i-p2-3p 2 for p 2 3, and only 7 for p = 2. But the actual number of constraints that get checked against the input states is usually much less than that, since the semantics of the constraints can be used to the following decide on most of them without checking any values. Consider scenario: Constraint generation and testing has been going on for some time. The constraint M+(A, B) has been found to be valid. Now, the constraint MINUS(A, B) is considered. The algorithm can decide to skip this possibility immediately, since the MINUS has no hope of being satisfied, given the M+. This feature, represented by the first if statement is called the contradiction check. in the description of the algorithm, The M constraints’ defining properties can be used extensively to detect 94 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 constraints which are logical consequences of already discovered constraints, well. For example, need to check M+(A, C) against interestingly many rules like this one; proofs, are listed in Appendix A. as is no it is valid. There are the ones QSI uses, together with their if M+(A, B) and M+(B, C) are already known, the input behaviors; there Consequence constraints like the one mentioned above are written out, but not included in the QDE that is fed to QSIM for the model depth test. The reason for this is twofold: First, consequence in the QSIM output if their antecedents are already in the input (this is a result of their are linear in the number being consequences), of constraints, considerably, without contributing constraints do not change anything second, QSIM’s time requirements inclusion slows down execution anything. so their The consequence detection check, which has just been explained, speeds up the in later constraint determinations, made after model exten- large, and the number of values to be checked can be algorithm especially sion, when p is relatively big. (See Sections 4.5 and 4.8.) QSI also checks each parameter to see whether all the input behaviors at this stage. If such a parameter throughout invariant Later versions of QSIM have a unary constraint named CONSTANT parameters, it is fixed at the same landmark is found, to the model. for fixed indicating that it is a constant see [15], for instance. is incorporated information 4.5. Model extension on a particular has been performed After constraint determination in these behaviors, since constraint determination set of behaviors, no new constraints, other than those already found, can be written on the set of parameters appearing is exhaustive. So if the model at hand is found to be too loose by the depth test stage (Section 4.6) and has to be extended by the addition of new constraints, one so that constraints has involving is all that QSI knows about the system, it is used in the postulation of the new parameters. Each of an existing parameter. Two newly postulated in the same constraint. Parameter parameters postulation are neighbors is then seen to be composed of two steps: for. Since the set of behaviors new system parameters them can be searched is a “neighbor” if they appear the model, parameter introduce to to (1) postulation of a new constraint which links one or two “old” (i.e. known) to a new one; this will be called the dejining constraint of the parameters new parameter; (2) calculation of the behavior of this parameter from its defining constraint and the values of its neighbors. Both of these steps give rise to important issues, which will now be described. To make QSI search as wide an area of the “space” of models mentioned before as possible, virtually all neighbors of the known parameters have to be postulated. the them, one is faced with the possibility of failing to find a good system contains If some neighbors are left out, and the “real” equation describing A.C.C. Say, S. Kuru / Artificial Intelligence 83 (19%) 75-141 95 is an expensive process (Section the solution can be obtained to this in Appendix B.) Because of this, QSI has been made flexible about and can be run in any one of a number of “postulation model. On the other hand, parameter postulation 4.8) and a number of QSI problems, where efficiently with the postulation of only some neighbors, exist. (Examples are presented the extent of postulation, modes”. The following analysis response neighbors are created, in the actual model, virtually all the the full postulation mode, where, to the lack of any “hints” about i.e. the worst case. is about Full postulation mode involves the generation of the following neighbors: l the derivative of every non-constant parameter, l the sum and differences of every pair of parameters, l the product and, if possible, ratios of every pair of parameters, l the negative of every parameter, l the square of every parameter. As can Ibe seen, all types of constraints, except the MS, are utilized as defining constraints. The reason for the fact that not all syntactically possible neighbors are that is, the created will be clear when the second step of parameter postulation, behavior calculation procedure, QSI decides that a parameter is discussed. is constant when all its values are seen, or can be assumed, LO have the direction std, and all its magnitudes are the same landmark. the The discovery proliferation of QSIM outputs, and are conceptually helpful in modeling, as will be further discussed. Derivatives of constants need, of course, not be postulated, since values fixed at zero can be eliminated (A “lonely” zero on one side of an equation can always be handled by using ADD and/or MINUS constraints.) of such constants from equations. they greatly is desirable, since limit Neighbors whose defining constraints are already in the QDE (found by previous constraint determinations) will also not be postulated. are there? Assuming How many neighbors of p parameters reducing conditions above apply, one has that none of the l p derivatives, l p negatives, l p squares, l (5) sums, l 2 - (3 11 differences, l (3) products, and l 2. (3) ratios. Therefore, throughout the input (which is unlikely). the worst-case number for the full postulation mode is the sum of these, that is, 3p2 new parameters will be created, provided all old parameters are nonzero If a parameter X does have the magnitude zero even once, no ratios of the form Y/X (where Y is another old so the above number In cases parameter) in the “derivative postu- where is acceptable, lation mode,” where only the derivatives of the existing parameters are created, less. the number of neighbors, and the time required, are of course accordingly are postulated, limited postulation is usually not reached. for example, 96 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 Table 15 Behavior of amount-A amount A - (0, m), dec) ((0, ml, dec) (dischA, std) EQU time to (4D t1) t, To perform extended constraint determination on the new set of parameters, QSI must assign behaviors to each of the newly postulated parameters. The values of the old parameters at each state and the defining constraint are known, value the sequences transition is an infinite number of legal behaviors of rules can be found. The problem the constraint in most cases, there that may be assigned to the new parameter. the new parameter which satisfy both is that, and To see this, one behavior of the parameter amount-A examined more closely (Table 15). If the derivative of amount-A, where DERIV(amount_A, alone yields the information known that Px will have magnitude zero after t,. from Section 4.3 will be that is, Px, is being postulated, knowledge of the constraint in [to, tr]. It is also in Table 16 about Px’s behavior Px), Knowledge of the transition rules lets one conclude that Px’s direction should be inc just before t,, and it should be std at t, and after it. But this still leaves an infinite number of possibilities for the behavior of Px, is nothing wrong in Tables 17-19 being among them. There that the number of states that occur, so by adding new to a system, one always faces the possibility that the description of its the ones depicted about the length of the behavior in a behavior parameters is just a measure of the changes in Table 19; remember time Table 16 Behavior P” of Px in [to, tJ (a negative I; nyative landmark landmark or interval,?) or interval,?) ,7 Table 17 Possible behavior for P, PX (t-m, 01, inc) EQU time to kw t,) t, A.C.C. Say, S. Kuru / Artificial Intelligence 83 (1996) 75-141 97 Table 18 Another possible behavior for Px PX (lml, std) ((lml, 0), inc) (0, std) time t0 (to3 t1) t1 EQU Quantity space of Px: {-m, lml, 0, m}. Table 19 Yet another possible behavior for Px P, ((lml, 0), dxec) 0), ds:c) ((lml, std) (lml, ((lml, 0), inc) (0, std) time Cl (to> 4) 4 (t,, 4) t, EQU Quantity spalce of Px: {-m, lml, 0, a}. behavior lmay get longer indeed has that behavior, will be as shown in Table 20, with the period designated form of the behavior now being described by five states from t, to t,. to reflect the behavior of the system with this parameter the changes in the new parameters. included [to, tr] in the “P,-less” If PX All three behaviors of Px shown in these tables, and, actually, all the infinitely many qualitatively distinct behaviors where Px “wanders” in various ways in negative magnitudes before settling at zero, are physically possible for the input of Table 1.0. The defining constraint’s restrictions are simply unable to help one decide at one of them. ADD and MULT constraints are often faced with the same situation. One might be tempted distinct possibility, as qualitative showing that to design the algorithm to explore each qualitatively reasoners often do, but the previous discussion that there can be an infinite number of possibilities overrules Table 20 Possible systlzm behavior for input of Table 15 amount A _ ((0, m), dec’b ((0, m), decj, ((0, % dec) ((0, m), dec:) (disclmA, stti) amount-B (0, inc) ((0, m), inc) ((0, 4, inc) ((0, m), inc) (disclmB, std) PX (@ml, 01, dec) yi)dec) I?;, m ,s 0), inc) ((lml, (0, std) EOU time t0 (Cl. tJ t* @I? t2) t * 98 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 approach. One has to use rules of heuristic nature able” of its possible behaviors to each new parameter. to assign the most “reason- The heuristics that have been adopted after thorough experimentation are: Prefer behaviors in which the qualitative direction changes the fewest times. and If the parameter can be constant (i.e. std throughout at the same landmark) prefer that behavior and designate the parameter as constant. are times important to assume The more the stronger These rules have many desirable features. They are easy to implement. The correspond to commonsense in more than one way. When there are many alternative explanations the most reasonable that something the simplest. thing to do is to choose (“thing” meaning derivatives as well as values) is not changing, when one does not know whether for a given event, It is simpler and scientific intuition it is changing or not.’ the direction of a parameter the derivative of that parameter changes, is the is driven by an even deeper that suggestion leading to a presumably unnecessarily complicated model. Especially mechanism, and contribute constant parameters the in QSIM models, production of smaller trees. They also usually correspond to important “natural” quantities. The impressive number of examples another in the justification of the heuristics. QSI does the following when postulating a new parameter: the shortest length that the new parameter’s behavior can have (short behaviors can contain fewer changes than longer ones, by definition) and produces all behaviors of that length that the parameter can exhibit, obeying the defining constraint and to choose one of these behaviors and T-legality. The heuristics are then employed assign it to the parameter. to be equally preferable by the heuristics, one is picked randomly. Since system behaviors are if the necessary require more values in their behaviors) as well as being “widened” by the behaviors of the new parameters. If two or more behaviors are indicated input of constraint determination, in which they actually work is (i.e. if the new parameters input behaviors It determines lengthened important factor the are to For more details of the behavior calculation process, see the discussion in Appendix B. In the U-tube example, application of the heuristics results in the behavior of system for the derivative of amount_A, the enlarged Table 17 being selected behaviors in this case would indeed look like those in Table 12. It now becomes clear why it was decided not to postulate, the parameter ZnX, with from any old parameter X, or the square roots of existing (necessarily nonnegative) parame- ters. In the former case, absolutely nothing about the new parameter’s magnitude two alternative possibilities is known, while in the latter case, there are generally the defining constraint DERIV(lnX, X) for example, 1 Note the parallels to Newton’s first law and de Kleer and Brown’s canonicality heuristics [7]. A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 99 for the new parameter’s values, and no hint about which one to choose. The procedure described above can be applied for such neighbors just as easily, but it will always come to a random selection, with no particularly good reason that the behavior selected is the most sensible one. to find behaviors therefore is deferred until they are seen to be “significant” The “bigger” behaviors obtained as a result of parameter postulation have a tentative nature. Not all of the neighbors of the input parameters have to be their permanent addition into the system important parts of the model, description in some manner. is the following: Its addition QSI’s criterion for significance of a model component to a QSIM of some additional input should contribute behavioris. This is reasonable, to eliminate as many behaviors from the output of QSIM. since the whole aim of the model extension stage is that do not appear in the input of QSI as possible the elimination to throughout The diiscovery of significant constraints is made in two stages: Immediately after behavior calculation, only the defining constraints of new parameters which are seen to the to 'be constant indicating their fixedness being included system QDE, with invariant in the QSIM input set. Fixed parameters are significant by the above criterion, since they can have only one possible “next” state at any given time, and will probably help further constrain in subsequent their behaviors are permanently the system behavior their neighbors simulations. information through added tuple. the procedure The constraint determination on the number of tuples that get considered significant constraints efficiency reasons, modified by specifying one of various “search modes”, mentioned postulation modes, tions, input. Half search mode requires at least one old parameter considered the other is then called the new and wider set of system behaviors. For in this process can be similar to the already tries all combina- does when acting on the original in each just as initial constraint determination in the input. Full search mode to appear to find To hinder is included incorporation in the QDE. of constraints that would not “tighten” that holds on the behaviors the simulation, constraint determination at this point also involves an insignificance check, which is mostly similar to the consequence detection check. Not every constraint Insignificant constraints are the ones that can be proven to hold without being tested on all the information. Defining constraints by themselves have this states, using present property; them, and that they hold, because it postulated then calculated the new parameter values so that they hold. Constraints of the form ADD(X, Y, Z), where 2 is any parameter, and MINUS(X, Y) is asserted or can be derived, are also deemed insignificant. Since the qualitative addition of values of opposing sign is ambiguous, such constraints can be satisfied for lots of (nonzero) Zs, which is arithmetically wrong; their generation is just a by-product of QSI’s policy of testing every combination. See Appendix A for the other rules used for determining insignificant constraints. the computer “knows” Significant constraints found by this stage will generally contribute elimination of QSIM behaviors, since the old parameters to the in them now have to 100 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 satisfy more constraints. This usually implies a smaller number of transitions, and (See proof in Section 4.9.) therefore, less behaviors. is found, appearing behaviors When a significant constraint in it are added to the QDE permanently, are permanently new parameter(s) new parameters’ behaviors. Postulated parameters permanent model at the end of constraint determination extended model (now with a greater number of “old” parameters) the model depth test stage, to see whether or not. it and the defining constraint(s) of the and the input and their behaviors which are still out of the and the is again fed to it will produce only the input behaviors the system’s are dropped, “pasted” to If no significant additions the derivatives of all parameters are appended all the same, in the hope of finding a better QDE in a later iteration. the model by can be made this stage, to 4.6. Model depth testing Whether that the purpose the version of the system model at hand is satisfactory for simulation modeling purposes or not is determined by the model depth test stage. It must be emphasized is to obtain a model which produces all, and only, the input behaviors. That the QSI-produced models yield all the input behaviors (See proof in Section 4.9.) To make them produce as few of other is guaranteed. to them. behaviors as possible, the obvious thing to do is to add more constraints To check the intermediate models to see whether they meet the requirements, the obvious approach them using QSIM. is to simulate The model depth test stage starts by preparing Recall is already that QSI assumes the QSIM inputs necessary for formed by the previous constraint de- in a single that region. Initial quantity spaces are prepared by stripping the discovered (if is discov- initial state that into QSIM’s input separately; QSIM will the simulation. The QDE terminations. operating landmarks from QSI’s input, and the quantity spaces of postulated parameters any). Invariant ered earlier, as discussed, and incorporated here. Each different appears run from each of them. specifying which parameters are constant, in the input of QSI is entered its input originates information, Pure QSIM creates (at least, tries to create) the complete state tree for each initial state. In this application, one only wants to see that the model predicts the so one only needs to simulate for the length of these given behaviors correctly, behaviors. Levels of the tree corresponding to events occurring after the end of the input behaviors are not created; is called level limiting. this feature Since QSIM can predict spurious behaviors, and one has no way of knowing whether spurious predictions will appear (or even, have appeared) in a particular simulation or not, the ideal aim of finding a model which will generate only the is not generally reachable. So the model depth test stage must not input behaviors strictly require that the number of QSIM outputs and QSI inputs be equal; an “acceptable” number of “excess” output behaviors have to be allowed. In view of it has been the fact that this number changes widely from problem to problem, A.C.C. Say, S. Kuru 1 Artificial Intelligence 83 (1996) 75-141 decided specified, it is set to zero. lto let the user specify it in the input. If no allowable excess number 101 is A shortcut the simulation. level, simulation is possible during is very easy to implement is cut off, and the current model If the number of predicted behaviors exceeds the allowed limit before the generation of the state tree arrives is deemed at the specified unsatisfactory. This method in the very first model the initial constraint determination. One can always find the testing, just after minimum number of behaviors state tree by simply things are complicated by the fact counting In the that postulated parameters may cause a proliferation of system behaviors. and 2 is a following, example, assume that X and Y are input (old) parameters, new parameter with defining constraint ADD(X, Z, Y). (Obviously, these would is focused on this part normally be part of a bigger, meaningful system. Attention of it, for the sake of the discussion.) Suppose that, X and Y’s input behavior is as in Table 21. implied by an incomplete leafs. In further its present iterations In the model depth test stage, the parameters have the initial values X =: ((0, a), inc) , Y= (((4% dec) , Z= ((O,%dec) , and QSIM creates magnitudle of 2, for the X-Y-Z the behaviors in Table 22, which differ only in the final system. the single If a subsystem Should the model test fail, since three behaviors were obtained when one was wanted? Clearly not, because a closer examination of the QSIM output shows that restricts in the input. So the current model in this example attention (whatever input behavior, when one it a.ctually contains only to the parameters it is) is acceptable. is defined the to be a subset of specification of the model depth test stage may be worded as follows: The model will be labeled satisfactory in the is acceptably close to the number of QSI input behaviors. The QSIM output this number, and the level limiting simulation cutoff mechanism mechanism should keep the “elasticity” of the behaviors in mind when making its decision. if the number of the input subsystem’s behaviors the set of parameters, should check Note that the above-mentioned take less time than a similar number of pure QSIM simulations with the same input model would require. features mean that this stage will generally Table 21 Input behavior of X-Y system X ((0, a), inc:) ((0, m), inc:) ( disclmx, Etd ) Y ((0, 9, dee) ((0, 4, dee) (discZmY, std) EQU 102 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 Table 22 Behaviors of X-Y-Z system X ((O,% inc) ((O,m), inc) (newX, std) Y (64% dec) ((O,m), dec) (newY, std) EQU Quantity space of Z: {-m, 0, newZ, m} X X yK$> “;Y t”“; >m ) mc (64% inc) ((0, 9, inc) (newX, std) Y ((0, =9, dec) (K49, dec) (newY, std) EQU Y ((O,m), dec) (@Am), dec) ((O,% dec) ((O,% dec) (newY, std) EQU Quantity space of Z: {-m, newZ,, 0, m) Z ((0, 9, dec) ;‘o? “z’> ;;;’ new , s Z Z ((0, 9, dec) ((0, 9, dec) (0, dec) (t-m, O), dec) (newZ,, std) is empty, to be tested If the “QDE” fails testing automatically then model is clearly necessary. This without any simulation performed; model extension trivial case may occur only immediately after initial constraint determination. If any non-constant parameter which appears in the input is missing from all of the constraints since an the depth (For examples, see unconstrained parameter would lead to an infinite simulation. Appendix B .) test again fails without simulation, in the QDE, Model testing is automatically the specification for pathologically unrelated parameters in the input. This guarantees in the input. satisfied if the number of iterations has exceeded terminates even that the algorithm 4.7. Dimension consistency relations of model discovered The final stage of QSI is a procedure previously constraints. QSI is totally ignorant about the nature of the input quantities beginning. But when the constraints are found, simple rules of mathematics certain these relations are contradictory, buffer M-t constraints and parameters. the sensible in the imply If the model can be rationalized by the use of relations among the dimensions of the parameters to fit into arithmetically rationalization, where in the constraints. are made If a DERIV(X, Y) exists, for example, this implies that X and Y’s dimensions A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 103 together, in the QDE, it is not acceptable, and is removed are not the same (Y has X’s dimension divided by time), so they cannot appear in additive constraints since ADD and MINUS obviously require all their to have the same dimensions. So if, for instance, ADD(X, Y, Z) also arguments from the model. But appears one does not want to lose the addition relation whose existence in the system has been disc’overed. Therefore, type, which can be viewed as a “dimension converter”, is used. Three new (buffer) parameters B,, B,, and B,, whose quantity space structures are identical to those of X, Y, and Z, are added together with the constraints M+(X, B,), M+(Y, B,), and M+(Z, to the model, B3), which have CVs linking each of B,, B, and B,‘s landmarks to (respectively) X, Y and Z’s landmarks. Since B,, B, and B, will have exactly the same behaviors as X, Y and Z, the constraint discovered among X, Y and Z will exist them too, so ADD(B,, B,, B3) is also added. One now has the same between model (from a simulation point of view), but without the M+ constraint the inconsistency. long) chains of constraints. Suppose, The actual mechanism of this stage is a little more complicated than the one since some inconsistencies can be discovered only by considering just described, in the above case, one did not (possibly have DERIV(X, Y), but the two constraints DERIV(X, P) and DERIV(P, Y). is wrong with ADD(X, Y, Z) would then require Understanding traveling the dimension facet of that the arithmetic constraints may form consistency such chains too. Suppose one has this chain of DERIVs. As another imposing problem, consider that something along DERIV(A, E) , ADD(A, B, C), ADD(C, D, E) . The fact that ADDS and MINUSes which share parameters in this manner form equivalen’ce classes of parameters of the same dimension has to be recognized and handled by the buffering algorithm. consistency always applies Since dimension and constraints created the buffer in this stage usually hint at actual deep model parameters as the example of Section 4.3 showed. As extra constraints which do components, the buffer M+‘s would certainly slow not contnibute down a QSIM simulation of the model, but this is not a problem, since QSI does not make any simulation after their creation. to any behavior pruning, real world, in the The interpretation of what QSI’s output actually means is quite involved, and will be the subject of a later section. 4.8. Corqplexity The computational complexity of QSI will now be determined stage by stage. Most of t.he required analysis has already been done. In the following, s0 is the number of states in the input, p,, is the number of input parameters, si and pi are these numbers in the ith iteration. 104 A.C.C. Say, S. Kuru I Artijicial Intelligence 83 (1996) 7.5-141 4.8.1. Analysis Constraint determination state at the ith iteration then requires O(p:sf) Since worst-case complexity is satisfied for the first si - 1 states, so no shortcut types, grow with si; hence the second si factor in this formula.) is being considered, assume none of the conditions (Section 4.4) which let the algorithm skip testing a constraint are fulfilled. Also assume that each constraint is obtained. The constraint determination time for large pi. (The CV lists, which will have to be checked for each tuple for In most constraint further iterations, pi and, generally, si will increase. Always, si+i = O(s,), since all new parameter behaviors can be expressed simply by replacing (in the worst sequences of case) each interval for interval-point-interval the total number of a second parameters so the second time. Experience shows that only a small fraction determination will take O(p$i) to the model after determination of the new parameters i 3 1, and constraint (especially determinations time. If one considers a (very) pathological case in which all neighbors get added to the model at each iteration, , etc. in successive number. this stage’s time requirement would be on the order of pi, pi, p:, i.e. it would be exponential states. If constraint determination has to be performed on which the algorithm will work, will be O(pi), in the system behavior by three-state in later iterations also require O(p$i) time, and if full postulation mode in half search mode), are actually added pr iteration so pi+1 = O(p,) in the current is active, pl, iterations, for Model depth testing Again assuming that no shortcuts are possible, this stage consists of a number in of QSIM runs with level limiting. QSIM’s worst-case complexity input the number of parameters. As mentioned but the worst-case parameters analysis about the parameter number stated in the above paragraph still stands. in the QSI input parameters, the number of QSIM is exponential is usually above, linear Model extension The points made above about the growing number of parameters apply here, in the number of postulated parameters, is linear time requirement in normally all iterations, but can rise as pi, pi, p:, too. The . . . in the which is O(pz) worst case. Note that this problem can only occur in postulation modes which involve sums, differences, products, or ratios, since only the numbers of these the kinds of neighbors terms. so the number of neighbors “explosion” to the model, which is itself a very rare situation. in the number of the old parameters, involve squared is linear In all other postulation modes, if all the new parameters does not occur even are added The behavior calculation procedure, which is performed is postulated, is generally linear in the number of states version of this task is linear in the length of the for every parameter that the input), but (note that quantitative A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 105 unfortunately, the fact that one calculates all possible behaviors of the minimum length and the ambiguity of qualitative arithmetic mean that pathological cases (involving ADD or MULT time requirement in s can occur. Consider the two parameters X and Y, which have the following values throughout as the defining constraint) the (long) system behavior: is exponential in which the X = ((0, m), inc) , Y = ((--co, 0), dec) . the calculation of all of Z’s behaviors the new parameter 2, whose defining constraint Now consider Clearly, that procedure to s. Each possible value that Z may take at t, is a root. Each transition may undergo is ADD(X, Y, Z). .Z can have any value at any time, only restricted by T-legality. To see this is exponential to the production of several trees whose depths are equal that it is a link between nodes. is equivalent in s, note that The application of the behavior selection heuristics number of alternative behaviors, which can be exponential of the above paragraph. This is another postulation modes for greatly improved efficiency. is linear in both s and the in s, by the reasoning factor which suggests the use of specific The complexity of constraint determination, which is also part of the model extension stage, was discussed earlier. Dimension consistency The last stage of QSI is also the fastest. Since it simply involves scanning the it can in the QDE to find dimension relations among the parameters, in ci, the current number of constraints. Note constraints be completed that ci itself is linear in the current number of parameters in time polynomial in the model. 4.8.2. Remarks The “good news” about the complexity of QSI is that most of the analysis just detection In practice, insignificance checks omit a lot of constraints entailed very pessimistic assumptions. performed the consequence and in constraint that do get checked against states are usually “shot determination. Constraints down” very early in this process. Full postulation mode is not necessary for a wide class of problems, similarly for full search mode. A lot of problems have been solved elegantly using the derivative postulation mode, see Appendix B. p,, and s0 time are usually quite small, so the grim expectations suggested by the determined requirem’ents are not realized. The input sizes generally used in this paper are typical the basic that QSI “sees” only some of the system parameters, which reduces assumption If the in its input compared the number of parameters algorithm will be used to find QDEs for individual model fragments, as currently envisioned, big. Active the input sizes will rarely turn out to be problematically is going on [37] to improve QSIM’s performance on medium and large research in the qualitative also keep reasoners. reasoning literature; in mind to other 106 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 7.5-141 scale systems. The results of such research will certainly be useful for QSI as well, since it uses QSIM as a subroutine. the complexity of QSI is similar Although clearly very high when compared reasoners, and is quite acceptable, considering forms of data processing, qualitative performed. For an idea about the actual performance, the execution implementation. presented. Details can be found in Appendix B. times of some of the problems The section numbers to algorithms dealing with simpler to those of other the nature of the task see Table 23, which lists in Appendix B in the current PC indicate where each problem has been 4.9. Correctness The discussion will begin with the “heart” of the QSI process, namely, the algorithm. The following assumes that full search mode constraint determination has been selected in the input. is significant if: (a) it cannot be proven using already Definition 4.2. A constraint known constraints as axioms, and (b) it is not of the form ADD(A, B, C) where MINUS(A) B) is already known. The reasons for such a distinction between constraints were already discussed; in the following is given here so that it can be invoked the formal definition propositions. Proposition 4.3. All significant constraints valid in the behaviors that constraint determination obtains as input appear in its output. Proof. Assume for the moment that the contradiction, determination and one has a “pure” cance checks are absent, algorithm, as seen below. The proposition will first be proven for this algorithm. consequence and insignifi- constraint Table 23 Execution Problem” U-tube B.1.2 B.1.3 B.1.4 B.1.5 B.1.6 times of QSI case runs Number of states in input Number of parameters in input Number of model extensions 6 3 3 4 5 5 2 1 2 2 3 1 1 1 1 1 1 2 Number of constraints in final QSIM input Number of constraints in final model Execution time (s) 7 5 3 17 6 2 11 9 6 41 13 2 3.25 1.18 0.72 42.51 19.14 1.01 “The derivative postulation and half search modes have been selected in all of the above. A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 107 that the omitted checks were there to improve the efficiency. They will (Note later be incorporated again to show that the proof stands.) for each constraint type CT do for each tuple ARG of parameters that can be arguments to CT do blockbegin for each qualitative state in the input do if CT(ARG) does not hold then break out and go to blockend {At this point, CT(ARG) input} write (CT(ARG)) add CT(ARG) to the QDE of the system is a novel constraint valid throughout the blockend Assume valid throughout “top” of the algorithm by the for statements, generated failed, contradicts determination that the above algorithm has terminated without a constraint C that is the input being written out. C must have been generated at the since all possible constraints are for this input, so pure constraint there (by construction). This means that the check in the innermost in which C does not hold. But is, there the assumption to find all valid constraints. is an input state has been proven that C is valid in the that The consequence written out without being tested; constraints to be missed. and insignificance checks result in certain constraints being their inclusion cannot cause any valid therefore The contradiction check causes constraints rendered impossible by present information to be skipped. The rules that may be used are: M+(A, B) M+(A, B) 4 MINUS(A) B) is impossible . + M- (A, B) is impossible MINUS(A, B) + M+ (A, B) is impossible M-G% B) + M+ (A, B) is impossible . . . NOT(M-(A, B)) + MINUS(A, B) is impossible . These are easily seen to hold, except in the case where both A and B are fixed, which makes it possible for both M+(A, B) and M-(A, B) to be trivially satisfied the special treatment given to fixed parameters by the at the same time. However, algorithm means such constraints will not be necessary for simulation, and it is not sensible to talk about such relations between constants anyway. So the contradic- tion check will eliminate no significant and valid constraints, complete. and the proof Cl is Proposition termination 4.4. No constraint stage’s input appears is not valid that in its output. throughout the constraint de- 108 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 the “pure” constraint determination Proof. Consider constraint C to be written out, the innermost that is, C has to hold in each input state. Therefore, pure version. algorithm again. For any for statement has to be completed; the proposition holds for the The contradiction check does not change the output, to it (see discussion above,) so the proof stands. in particular, add anything it does not Insignificant constraints which do not satisfy of Definition 4.2(b) are not written out by the algorithm. All other constraints which satisfy the in Sections 4.4, 4.5 consequence or insignificance and proofs in Appendix A. This means the incorporation of the checks does not cause is invalid constraint complete. inclusion of any 0 tests are valid; see discussion the requirement the output; the proof the in The previous to statement of the correctness of the constraint determination can be combined two propositions form the procedure: following Proposition 4.5. The constraint determination stage finds all, and only, the valid constraints that hold among the parameters in its input. Although is already strong for it, the fact that QSI there that it finds really really achieves correct system produce It is first shown that there is an (admittedly easy) solution to any system identifica- tion problem. the input behaviors when simulated, will now be formally established. intuitive evidence i.e. the QDEs identification, Proposition 4.6. For any T-legal behavior, a constraint set which will produce when simulated from its initial state, can be found. it Proof. The empty set (0) has this property by the initial state of the behavior, QSIM will produce an infinite branch of which corresponds parameters branches will be the given behavior. for any T-legal behavior. When started tree, each the (Part of) one of the to a qualitatively distinct account of the manner change value, constrained only by continuity. 0 Of course, this is the trivial case. One is really interested in bigger constraint sets. Note that, by the same reasoning as above, a “model” can be found, given any number of behaviors of a system. One should also point out that, given QSI’s lack of knowledge of where its input comes from, there is always the possibility that the “parameters” in which in the input are really unrelated case the empty model is the correct solution. to each other, Proposition 4.7. When the constraint set found by the constraint determination is used as the QSIM input together with the initial states of the input procedure behaviors, all the input behaviors appear in the QSIM output; that is, correct system identification is performed. A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 109 the input behaviors when simulated from their Proof. The model 0 does produce to this model will initial states, as already discussed. The addition of constraints cause the infinite the trees it would produce addition of any constraint C will prune all, and only, the states in which C does not hold, together with their descendants, from each tree. (See QSIM description in [19].) However, holds in every state of the input behaviors (by Proposition 4.4), which means they will not be pruned, and all these behaviors will appear to get smaller. More specifically, found by constraint determination in the simulation output. every constraint Cl Note that by “the input behaviors”, termination procedure operates are meant; input successive iterations of the algorithm. in later iterations. So the above proofs stand for each model found the data on which the constraint de- these will be larger than QSI’s initial in behaviors that a heuristic method for a single parameter to neighbor parameters, In a previous section, it was established is necessary for since there are cases where an behavior assignment exist. This infinite number of alternative among inevitably means that QSI outputs may lack some possible relationships the deep model parameters, if model extension has been performed. The choice of the heuristics was made with this fact in mind, aiming to minimize the number of overlooked Finally, that model extension never produces “shallower” that is, fewness of QSIM models according in model behaviors increase, more and parameters extension, the number of behaviors, but more parameters constraints generally mean more behaviors. The following shows that, after model extension, than those obtained before extension: one never obtains more QSIM behaviors predicted by the model. Note both tend the number of constraints to decrease relationships. it will be proven to QSI’s criterion of model depth, this is not obvious; that that would be Definiti0.n 4.8. The number of behaviors of the input subsystem predicted at the ith execution of the model depth test stage if the behavior count cutoff and empty model controls were absent is called the ith input subsystem behavior count, or ISBC,. If the result of initial constraint determination is the empty model, then ISBC, = m as already mentioned. Proposition 4.9. For any QSI run, in which the model depth test stage is executed more than once, say, n times, ISBCi 2 ISBC,+i, for all i, where i < n. Proof. Assume that an input subsystem behavior predicted at a later execution of depth testing was not predicted at an earlier execution. This means that there was to be filtered out at least one constraint during in the later one. this is impossible, since constraints added to the model at the end of However, the QDE can never get smaller. model extension in the model which caused that behavior testing, and this constraint was not present the earlier are never removed, i.e. 110 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 Therefore, stage, that is, ISBC < ISBC,+I is never the case. all behaviors of the later stage must also be present 0 in the earlier The representing reason why an integer the maximum number of allowed in the input also becomes clear now. We have no proof iterations was included that ISBC, is strictly greater than ISBC,+i for all i. Without this, one cannot prove for all cases (although the examples show that it that the algorithm will terminate does for a lot of useful ones), so an iteration cutoff is necessary to be on the safe side. 5. Qualitative noise filtering at the present (which are not in is Depending on the specifics of the application, time, unlike two preprocessors the core algorithm explained in the preparation of the QSI input. If the robot fully implemented Section 4), may be involved the knowledge about the behavior of the system from actual numerical obtaining measurements, what it originally has is a group of parallel sequences of visible parameter values; with a floating point number for each parameter value at each discrete point of measurement. This (possibly to a (usually much shorter) qualitative behavior by a preprocessor. Whole sequences in only one of measurement direction can be accomplished in the number of measurements. Each qualitative in the input is obtained by a separate run of this simple algorithm. Other behavior qualitative to qualitative systems) also employ similar behavior conversion methods. For detailed discussions of the issues related see [6, 141. in which each parameter to single qualitative value changes states. This operation points are collapsed long) input can be converted (e.g. for tracking monitored reasoners which have to this conversion, this quantitative in time linear to perform it may be corrupted the measurements QSI’s input has to be a correct description of the system’s behaviors reason. Note that the qualitative representation it was designed) if it is to perform successfully. If the input is stemming from measurements of expected by noise. Noise will be defined as the the real world, and the actual parameter values, caused differences between is particularly by any conceivable value suitable (in fact, if the input has fluctuations. Therefore, In some cases, noise has been prepared by a human, maybe even inadvertently. increasing in (0, m), no effect on the qualitative description. Consider a parameter with no known positive landmarks. The measurement of this parameter is being continuously corrupted by noise so that, at each reading, a value of, say, five units than the actual value is presented. The resulting qualitative behavior will more and the noise will have again contain been “in vain”. the value ((0, CQ), inc) for this parameter, the noise may well have been eliminated away unimportant for abstracting Despite these resilient quantitative-to-qualitative features of the representation, behavior conversion preprocessor and the fact that the itself can employ a A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 111 Fig. 4. Actual behavior of X. that this process to demonstrate for “numerical” noise elimination, we have designed a qualitative noise method too has a meaningful filter as well, mainly specified in qualitative counterpart. The filter is aimed at individual parameters, its input. (Because of the particular configuration of the experiment, it may be the case that only some parameters are subject to noise, and others are not.) If QSI fails to find a good model within the allowed (without running this preprocessor) limit, this can lead one to suspect the existence of noise. Possibly noisy iteration parameters can be identified as the ones with an unusually great number of distinguished time points [19] in their behaviors. The filter’s input below) and the names of parameters noisy) parameters. The following is an explanation of its working. is the set of system behaviors, to be filtered. and smaller quantity set of system behaviors its desired sensitivity is a shorter Its output for spaces (see (less the filtered and in this study was restricted as a sequence of independent Many kinds of noise exist, but attention to white identically noise, which can be modeled random variables of zero mean. It is also assumed that, when it exists distributed to at all, the variance of the noise is not very large, so it causes the measurements they normally would, with equal read values “slightly” greater or less than probability. For example, if the plot of the magnitude of parameter X is “really” as shown in Fig. 4, one intuitively expects its noisy version to be as in Fig. 5. By the same reasoning, then one like Fig. 4 as the noiseless (filtered) version. This is the would propose something the early technique, used in, for example, qualitative analog of the convolution lines that will be processing phase of the vision process obtained.. As with all filters, in this technique: real features of the behavior may get wiped out too, if you are too cautious to avoid this, however, you run the risk of leaving actual noise unfiltered. There to this problem, and this kind of noise filters are “heuristic” by their nature. if one sees Fig. 5 and is told that noise is present, If you go too far with the smoothing, is no perfect solution the tradeoff is an inherent [4] to smooth involved there The implementation its of the qualitative noise filter is quite different analog. This is to be expected, since the qualitative noise filter takes from quantitative Fig. 5. Noisy behavior of X. 112 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 qualitative behaviors as input, and the averaging process of convolution cannot be to be averaged. The applied in this format, since there are no ordinary “numbers” qualitative to achieve its aim. filter again uses the ordinal relationships among landmarks An examination of Fig. 5 reveals the undesirable features of the noisy behavior, the great number of distinguished in addition to its being incorrect. A huge number of landmarks have to be kept in this behavior. Note that Fig. 4 requires only two its quantity space to describe landmarks outside the basic set. The noise landmarks cause the behavior to have time points and states. Even an unacceptably worse, it lose the they decrease advantages of qualitativeness. A sequence of parameter states in which the parameter’s direction starts as inc (OY dec) in the first one or more states, becomes std once, and then is dec (or inc) for one or more steps is called a tooth, because of the way it looks in a plot of the parameter, long like Fig. 5. The basic sequences of teeth during which there is a general (or decreasing) of magnitude with single values with direction intelligibility of the behavior and make the filter increasing is to replace inc (or dec). idea behind The sensitivity of the filter is an integer specifying a lower limit for the length of to be smoothed. After all, the behavior of Fig. 4 is a (short) tooth sequences sequence of teeth itself, and one does not want such things to be smoothed. A tooth sequence to be filtered in a given parameter behavior exists are identified. Filtering can be accomplished is determined as follows: Sequences (as long as possible) of states where a zigzag of directions (like { inc, . . . , std, dec, . . . , std, inc, . . .}, where the ellipsis (. . .) means “zero or more of the preceding”) if: (a) the (b) the parameter never has the number of stds is above the filter’s sensitivity, state (Im, std) outside this sequence for any landmark lm for which it has such a (c) the state (0, std) does not appear in the sequence, and state in this sequence, landmarks on which the parameter becomes std in this (d) the odd-numbered sequence the even-numbered are in increasing landmarks. order, and the same applies for (decreasing) If all these conditions hold, this sequence of states is replaced by the state (Mag, Dir) where Mag is the interval in the quantity space of the parameter which is formed after deleting all the landmarks on which it became std during the (d) sequence, above. and Dir is the direction of the ordering determined in condition Conditions (b) and (c) are required to prevent the filter from destroying useful landmarks by mistaking them for products of noise. Condition (d) is the check for the above-mentioned “general increasing (or decreasing) of the magnitude”. Fig. 6 is an example showing how a noisy sequence is smoothed by the filter. Plots of the noisy and filtered versions of this segment of this parameter’s in Fig. 7. One should keep are presented behavior jagged segments could be expected corresponding dec) . in mind that several such to appear in a noisy parameter behavior, each to one actual interval state of the form ((a, b), inc) or ((a, b), A.C.C. Say, S. Kuru I Artificial Intelligence 83 (19%) 75-141 113 ((b,, 41, inc) (4, inc) ((b,, +I, inc) (~1, std) ((L 4, de4 (b2, St4 (b,, inc) (h, inc) ((u,, u3), inc) Fig. 6. Noise filtering of a parameter behavior segment. the parameter filter are updated Parameters and the filterings are over, indicated their states modified by to be noisy by the user are treated one by one in this fashion, in the system behaviors. When the system behaviors may contain sequences of system states that are indistinguishable except for their time values. This is to be expected, to a reduction of the filtered parameters’ distinguished time points by erasing some of their landmarks. the system behaviors by collapsing The preprocessor such sequences of identical system states into single interval states. This reduction in the size of the QSI input is naturally an improvement from the point of view of as well. the time requirement terminates after shortening since the filters contribute u3 u2 b3 Ul b2 bl u3 bl Fig. 7. Plots of noisy and filtered behavior segments. 114 A.C.C. Say, S. Kuru I Arti$cial Intelligence 83 (1996) 7.5-141 Noise filtering of a single parameter can be accomplished in a single pass, i.e. linear time. The same applies for the global behavior shortening. 6. Discussion This section aims to put QSI in perspective: Its relation with existing techniques aspects of its utilization, and ideas about using it for different such as diagnosis, are discussed. QSI and the method of inductive is ex- of modeling, applications, learning are compared. Related work on automatic model acquisition amined. 6.1. QSI as modeling than is the spring/block to QSIM (i.e. system system of Section 2. Recall As well as being a natural counterpart three-constraint model of Table 9, which-although identification to the qualitative Its ability of finding significant deep relationships to produce only a single periodic behavior-leads solutions, because of inherent spurious [19] points out, a more comprehensive model containing energy in that situation does produce formulation problem. the system’s quantities can be used to write the “best” model, given a the that three- the mathematically versus system simulation), QSI also provides a new approach model among system. A striking example where QSI can propose a better model obvious one parameter, to a simulation with adequate problems. As infinite laws Kuipers the single-behavior output, but it is not applying obvious for the user how the model should be formulated in the beginning. Now suppose that the periodic behavior of this system, with the three parameters X, V, and A, has been presented to QSI as input. The initial constraint determination finds the constraint set of Table 9, as expected, plus the constraint MINUS(X, A). (Remember is not imposed until QSI terminates.) The model is found to be unsatisfactory by the depth test stage, since three behaviors (two of which are spurious) are predicted by QSIM. So model extension is performed. Among the new components added to the model by this stage are the parameters Pg and P,, defined by the constraints that dimension consistency representation MULT(X, X, P9) and MULT(V, V, P,,) , and the constraint M-P,> Pi,) . The bigger model is satisfactory, and QSI terminates. Pg and P,, correspond M- constraint among them represents i.e. the total energy, is constant. The relevant “real-world” to the potential and kinetic energies, respectively. The the fact that the sum of these two energies, equation [16] is (6-l) A.C.C. Say, S. Kuru I Arti@cial Intelligence 83 (1996) 75-141 115 Note how constants total energy are “buried” Section 6.1.2. QSI’s usefulness as a modeling The rest of this section QSI’s utilization. like m, the mass of the block, k, the spring constant, and the in the constraints QSI finds; this will be taken up in is comprised of further discussions of some aspects of tool has thus been demonstrated. 6.1 .l. How to prepare QWs input As pointed out in Section 3, the procedures of observation (and possibly, excitation) of the system to obtain the accounts of its behaviors are outside QSI’s that the input has been specification. The algorithm operates with the assumption the corre- obtained sponding expected) that the system can behaviors, exhibit as possible have been included. Both of these conditions may be difficult to meet in practice (a)) and in some cases (see Section 5 in relation automation of the data collection target for future research. so that family of actually exhibited and (b) as many distinct qualitative behaviors correctly describes in design applications, (a) each qualitative behavior task has to be an important to condition (or, future, But before in the foreseeable In all the examples all observable quantities the considerations mentioned in the QSI modeling applications intelligent robot would have to perform above can even arise, one has to to decide (even roughly) what the system is, that is, which observable quantities in this include in a single QSI’s input as shallow parameters. the text, and probably problem will be clearly defined by the user, who knows it is about a tank system, spring, etc. An independent this problem definition by itself. Suppose such a robot enters a big room in, say, a chemical plant, which it is “seeing” for the first time. The room contains many tanks with in them; some of them are connected by pipes, some are not. Most fluids in the room would not be parameters of the probably, same system. Rather, them to a number of task involves many perception and modeling independent to QP theory, some others outside the scope of issues, some of which are related the qualitative Another is QSI’s total disregard of feature which has already been mentioned possibly useful information about the “natures” of the parameters, including their dimensions. Thus, QSI views its input simply as accounts of the changing of some collection of quantities over reflects time. The output that possible relations on these nameless quantities. Humans various mathematically as will soon be like clearly die not “act” information has discussed. See Section 6.3 for an account of how dimensional been used in modeling by other researchers. reasoning area itself, let alone this study. it would be more suitable to partition this when performing modeling, systems. This allocation it produces then 6.1.2. How to interpret QSZ’s output The constraints in QSI’s output provably hold on the set of parameters, as already seen. But the interpretation to obtain a “real-world”, e.g. verbal, model involves some issues arising from the natures of the representa- tion and the algorithm. of these constraints 116 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 The qualitative representation tends to “look over” constants, can usually be modeled are especially useful for this purpose. Take the spring/block well-known for the force on the block are just as tightly without formulae since systems them. The monotonic constraints example again. The F=ma, F=-kx, (6.2) (6.3) directly by which can, if wished, be translated defining parameters and two MULT constraints. But one generally does not do this, and uses instead M-(X, A) with CVs (0,O) as in [19], since it is more sensible from a simulation point of view to choose the smaller of two equally strong models. for all the quantities into the qualitative in the equations, representation PJ, M+(Z’,, B). For an example long chain of MS, for P,), M-(P,, So the M constraints presented by QSI can “hide” other relationships in them which may be interesting to examine if even deeper modeling is desired. Only two very simple examples will be considered. Each M may be the abstraction of an instance, M+(A, B) can mean M+(A, Pr), arbitrarily M+(P,, P2), M-(P,, to such chains of MS in real models, see the water balance mechanism in the human kidney, modeled in [21], and also Section 6.1.4.) M-(X, Y) may have been derived from, say, an equation of the form XY = K (K > 0) among many others. Since the input can be an abstraction of not one, but a family of systems, the output also reflects all of these possibilities. The user can choose the most suitable one from among the alternatives implicit in the output of QSI, in the role of a modeling aid. Another issue that may come up is the “discovery” of some deep parameters in a real-world context, given their and the meanings humans give to their defining neighbors, in the U-tube problem of Section are to those that do not seem meaningful when considered defining constraints, something QSI is unable to do. For example, 4.3, if full postulation among the ones added to the model by the extension stage, in addition already discussed: is used, the following new constraints and parameters MULT(amount_A, amount-B, Pi,) , MULT(amount_A, amount-A, P,,) ADD(P,, , P, 1, amount-A) . is imposed, feature of the U-tube. The very Even after dimension consistency intuitively obvious amounts answer it is mathematically relationship input behaviors. The existence of this coincidental constraint existence of a “system” visualize, compared this relationship does not reflect any the in the tanks by each other, or squaring them, does not make sense. The this need not be part of a model of the U-tube. The is, of course, implied by the is the proof of to physically in which the parameters A and B behave as (which would probably be much harder has been discovered, because idea of multiplying to the U-tube,) A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 117 in the input, and whose QDE specified includes the squares and products of A and B and links them in a “meaningful” way. Again, the user, with his knowledge from of the natures of the quantities, can choose is made, among th.e ones QSI presents. Note that, even if no such selection the i.e. even the the input when simulated, QSI output unintuitive components cannot filter out the input behaviors. the meaningful constraints is still guaranteed to produce 6.1.3. QSI versus modeling by humans Modeling is a tremendously important mental activity, which is very hard to automate. QSI must be viewed as an early step in this direction. It is not known which processes go on in the human mind when one attempts to solve problems of the kind discussed in this paper, but most probably, taken by the brain is not QSI’s method of trying out all the possibilities. Many very “human” among them the use of analogies [12], may come into play. In this capabilities, regard, QSI is taking what Rothenberg to AI: exploiting the computer’s abilities to come up with methods for solving the problems, without caring whether humans solve them in the same way. [30] calls the “engineering” the approach approach to the naive modeling activity, Having said this about QSI’s relation let us briefly compare i.e. the task of it with what can be called “expert modeling”, writing down the algebraic or differential equations describing a system. This task is normally performed by scientifically oriented people, so one might expect there is a more formal way in which it can be described. However, this does not seem to be the case. The modelers use their previous knowledge of laws that may apply in the current situation, and seem to employ “insight” the particular law instances say that “good” models should contain each different like Eqs. (6.2) and (6.3), rather equation, that do apply. A QSI-style search is absent. Iwasaki and Simon [17] law in a different structural than combining to recognize like writing them, mA = -kx (6.4) In the spring/block this manner, modifications for system. in the physical situation which cause different laws to apply can be handled nicely. Note that QSI does not ((and can not) impose such a form on the output models; this would again be the re:sponsibility of the model user, using the guidelines of Section 6.1.2. As Iwasaki and Simon point out in [17], “Establishing for a system is as much an empirical as a formal matter, and certainly not a syntactical exercise.” the structural equations Some computer programs which attempt to automate certain human modeling skills will be examined in Section 6.3. 6.1.4. QSI for diagnosis Kuipers [21, 231 has proposed a medical diagnosis expert system based on a expert “hypothesize-and-match” system with QSIM. Clinical findings are fed to the first-generation to obtain a set of “candidate” diseases. Previously prepared QDEs describing each architecture which combines a first-generation system 118 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 Table 24 Healthv water balance mechanism Constraint P), c(natriuretic hormones, P)) MULT(amt(water, P), c(Na, P), amt(Na, P)) M+(amt(water, M+(c(Na, P), c(ADH, P)) M+(c(natriuretic M+(c(ADH, P), reabsorbed ADD(reabsorbed ADD(netflow(water, DERIV(amt(water, P), netflow(water, out-+ P)) flow(water, U+ P)) hormones, P), flow(water, P+ U)) flow(water, U--+P), netflow(water, P+ U), flow(water, P-U)) P+ U), netBow(water, out-+ P), netflow(water, ingest-+ P)) {amt(Na, P) and netflow(water, All constraints have CVs at the “equilibrium” values.} ingest-P) are fixed at positive landmarks. of the diseased mechanisms are simulated one by one, and the QSIM predictions are compared with the clinical observations, achieved when the observations match the predictions. to QSIM-model-based of MIMIC, a different approach the cycle. Diagnosis (See [9] for a description diagnosis.) completing is approach to the diagnosis problem. When behavior data about a reasonably big subset of the parameters are available for both the healthy mechanism and the present state of the mechanism, of QSI offers an alternative the disease QDE can be both sets of behaviors can be performed. By this method, immediately, without going to the trouble of simulating a lot of non- found If the “QDE answers. The first-generation is present, matching base” of possible diseases mentioned to diagnosis. Even if such a disease its entries with dictionary and contrasting of the models of the healthy and diseased mechanisms may give useful hints to a human expert of the domain about the nature of the problem. expert system is rendered unnecessary. in the above paragraph the QSI output leads is not available, comparison Identifications For example, Tables 24 and 25 contain healthy and diseased models [20,21, 231 of the water balance mechanism (Table 26) of the human kidney, respectively. Table 25 Water balance model with SIADH Constraint P), c(Na, P), amt(Na, P)) P), c(natriuretic hormones, P)) hormones, P), flow(water, P+U)) flow(water, U-P)) MULT(amt(water, M+(amt(water, M+(c(natriuretic M+(c(ADH, P), reabsorbed ADD(reabsorbed ADD(netflow(water, DERIV(amt(water, P), netflow(water, out+ P)) flow(water, U+ P), netBow(water, P+ U), flow(water, P-U)) P+ U), netflow(water, out-+ P), netflow(water, ingest-+ P)) {amt(Na, P) and netflow(water, c(ADH, P) = fixed at a landmark higher than its equilibrium value in Table 24. All constraints have CVs at the “equilibrium” values.} ingest+ P) are fixed at positive landmarks. A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 119 Table 26 Water balance model’s parameters amt(water, P) amt(Na, P) c(Na, P) c(natriuretic hormones, P) c(ADH, P) flow(water, P+ U) reabsorbed netflow(water, P-U) netflow(water, ingest-p) netflow(water, out+ P) flow(water, U+ P) amount of water in plasma amount of sodium in plasma concentration of sodium in plasma concentration of natriuretic hormones concentration of antidiuretic hormone rate of water filtration from plasma into the tubules rate of water reabsorption from tubules back into plasma net rate of water excretion from the blood via the tubules rate of water ingestion net rate of change of water in plasma in plasma in plasma of are also presented AntiDiuretic Hormone the ingestion and excretion the normal and post-SIADH (including most of the parameters; (in This mechanism governs the relationship between in the body. The disease of Table 25 is called SIADH the urine) of water Secretion). A detailed (Syndrome Inappropriate in the normal and abnormal cases, discussion of what goes on in the kidney can be found in [21]. Assume that together with explanations of the parameters, see below) QSI has been shown the behaviors (These of both behaviors in [21], they are quite simple accounts of the variables nearing and settling at the equilibrium values in each case.) As has been proven, the QDEs of Tables 24 and 25 will be presented as outputs. An expert physician will notice that the differences of the diseased model from the healthy to the one (the the ADH ADH the problem more concentration) in the quickly, difference to the trouble. loss of the direct proportionality and on do not appear do not contribute are signs of SIADH, the many other measured and concentrate parameters two models, and presumably of the sodium concentration fixed higher-than-normal in two separate concentration, set of the periods value since runs. the for Of course, the above discussion entailed that all the deep this is a little bit too parameters were already identified and could be measured; optimistic, as has been stressed before. But QSI can also be employed to hint at a deeper structure. Appendix B contains a modest-sized problem about the kidney system in which only the most easily observable parameters are in the input, and the QSI :solution to it in the derivative postulation mode. the basic assumption 6.1 S. QWs limitations In addition to the issues already discussed in this section, some other limitations of the QSI algorithm, and possible ways out, will be briefly repeated here. QSI is very sensitive to possible errors in its input. A single “wrong” state may cause it to fail to find the correct system model, even if all the rest of the input insists that all output behaviors constraints should be satisfied on all the input states. Noise filtering may be useful in eliminating such problematic states, but that process is itself heuristic and may “oversmooth” the algorithm are described the input. correctly, since 120 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (19%) 75-141 The considerable worst case computational complexity of the algorithm in the is another restricting limitation its application (at least, for the current PC implementation) because of the versatility of the representation.) full modes to relatively small scale systems. (Note that: practically a huge number of different systems can even within a limit of a few parameters, Still, as the be considered, in Appendix B illustrate, a sizeable class of QSI problems can be solved examples using the limited postulation and search modes, which reduce the time require- ments significantly. As a general remark, one should point out that deep (i.e. to the invisible) parameters visible ones, which explains in things as acceleration and finding relevant models. For instance, hard-to-visualize variable rate of flow are derivatives of more easily-seen things like displacement and amount of liquid in a container. the success of the derivative postulation mode seem usually to be linked by the derivative relation 6.2. QSI as learning QSI’s relation to well-known machine learning approaches will be examined this section. Ways of modifying QSI so that it fits the classical inductive framework will be explained. in learning Induction knowledge, in machine learning. Here [4] of the inductive concept is the best-known method used is a learning problem: One is trying simplified definition to learn a concept, satisfied by a particular set of patterns, and not satisfied by patterns outside that set. From time to time, one observes different patterns, and is in the set or not. is told (by the “teacher”) whether each pattern one observes to infer a general Using this (ever-increasing) description of the patterns satisfying the concept, which will enable him to classify that is, it may lead a given pattern by himself. This description can be too general, one to believe that a pattern which is actually not in the set is an element. In this to exclude the problematic pattern and its likes. On case, it has to be specialized and exclude some the other hand, one may go too far in this specialization genuine patterns which satisfy the concept this is noticed, again a generalization is necessary. So the description undergoes a kind of “diminishing oscillation” as more information keeps coming in, being general- ized and specialized again and again, becoming more correct after each such update. the description; when the learner is expected from Now consider to perform generalization. less cases) is to add a conjunct disjunct, An obvious way of specializing a logical formula (i.e. letting it be satisfied for to it, while one can remove a conjunct, or add a (There are many other ways of doing these.) of QSI as a form of inductive learning: The observed qualitative states of the system are the patterns. The description QSI is trying to learn is the system model. Each QDE is a conjunction to a model specializes it, i.e. of constraints; adding a conjunct causes it to produce tighter simulations. Removing a constraint would have the opposite effect. (a new constraint) the following interpretation View QSI as starting with the assumption that all possible constraints do hold, A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 121 from implying a description with a great number of conjuncts. That is, QSI overspecial- the input states causes the unsatisfied conjuncts izes in the beginning. Considering test “tells” to be dropped the i.e. generalization. The depth the model, that would predict algorithm whether involving the unwarranted behaviors) or not. If so, the complete set of constraints neighbor parameters again), followed by the checking and probable elimination of the constraints against the extended states the algorithm (generalization terminates. again) and a new depth test. This goes on until to hold (overspecialization it has overgeneralized (obtained a model is assumed instances” (i.e. patterns above. There are no “negative it until it finds a satisfying model. A “general purpose” As can be seen, this is quite a special case of the general learning algorithm that do not in QSI’s input. It takes all of its input in one batch, and works learning the lifetime of the that is running it), and would accept its input items piece by piece, with for requiring all is clearer now: The in the (the model depth test stage) to know the correct presented satisfy the concept) and reworks algorithm1 would generally processor sometimes distinct behaviors of the system completeness of this information sense that it helps the “teacher” answers. run for a very long time (ideally, the “health” of the induction, considerable periods between to appear ensures them. QSI’s reason in the input in the QSI input (actually, a simplification) in the depth test stage. All that is needed This suggests a natural way to convert QSI to an interactive program, using a is a human (the modeler) as the teacher small modification to that stage. The idea is as follows: The mod14 depth test stage simply simulates the proposed QDE from each initial that does state without counting the number of behaviors, presents each behavior this is a genuine not appear behavior of the system or not. Behaviors to the QSI input. The number of the remaining ones is used to decide for or against a new iteration. This modified algorithm, as well as fitting more nicely to the is also very suitable for the concept prospective modeler, since it informs the user of possibly unexpected behaviors of the system the modeling session. Thus, user-friendliness liearning outline by having a distinct teacher, allowing him to form decisions during is gained at the cost of independence. identified as genuine are incorporated to the user, and asks whether in an on-line manner, Allowing the user to actually specify parts of the system model before the search to QSI, which normally starts with no idea at all about the sought model, would be a simple instance of learning by being told, another learning approach. important Inductive learning algorithms have been used by other researchers for quali- tative ma’deling; see the next section for the details. 4.3. Related work Even when one restricts attention from behavior models using the methods mentioned information, as opposed to programs which produce system models them by combining smaller in Section 2 on structural system descrip- to obtaining 122 A.C.C. Say, S. Kuru I Artijicial Intelligence 83 (1996) 75-141 there still remains a remarkable number of studies which deal with the tions, automatic model formulation problem. The primary feature which can be used to compare the approaches adopted by is the amount of information other than the system behaviors these programs required by each to achieve them starting with the knowledge-intensive ones, which require a great deal of such additional information, and go on to the knowledge-weak ones, of which QSI is among the weakest. task. We will examine the modeling Falkenhainer’s PHINEAS program [12] constructs models of systems whose and behavior descriptions is required the “previously behaviors are input by drawing analogies to other models which are remembered to have produced “similar” behaviors. A (preferably big) library of qualitative process models and structure about each of those to work. Input behaviors which (partially) models seen” behaviors cause the relevant parts of the model match to be used in the “target” model. This which generated its correctness: The simulation target model to verify are and possible discrepancies input are compared output and the PHINEAS attempted the previous behavior simulated to be handled by a revision stage. for the program is qualitatively complete behaviors information connection descriptions the model. Doyle and some structural [8] built a program which about information Mozetic’s QuMAS [25] used partial model knowledge and behavior examples to took automatically the considered qualitative systems as input and used a rich library of commonly found device components to hypothesize models for the systems. Amsterdam’s MM [l] takes as input an even greater amount of structural figures and/or in component types, which the user has to specify the type of each appearing quantity. These which are to be selected from a set which includes acceleration, flow rate, torque, momentum and voltage, among others, are used to index into a library consisting rules, written using knowledge of the of several model building/augmenting this energy-based modeling in a multi-step stage, which includes a QSIM simulation manner are analyzed to see if they produce the input behavior after all. MM allows partial specification of parameter values in the input; e.g. the qualitative directions of some parameter states may be missing. framework. The candidate models produced to the qualitative behavior, in the form of geometric in addition in When so much modeling knowledge to generate model fragments ID3 algorithm is not available, one has to turn to other to the use of inductive methods of behavior-based modeling. An early example of algorithms it could Quinlan’s produce discrete event simulation rules. These rules were in the form of nested if the statements “previous” the activities expressions in the then and else parts in which the conditional state, and the statements depend on aspects of indicate for simulation was the incorporation in the package EXPERT-EASE [27], where to be started Several “general purpose” in the “next” state. inductive identification GOLEM learning programs have been used for the from QSIM behaviors: Bratko et al. [3] used to identify a U-tube, starting with an input containing only the amount of QSIM models 123 [lo] A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 7.5-141 learners and obtained a complete and correct model. Dzeroski and flow parameters, reports setup of such the MULT modeling corresponding values feature were left unimplemented would be reasonable. Furthermore, these programs (i.e. unexhibitable behaviors) operation. a. similar experiment with the mFOIL program. The representational the qualitative the whole and constraint so that the execution time require negative examples in addition to the correct system behaviors for their to be particularly In both cases, framework. unsuited seems to Coiera’s GENMODEL id’entification. GENMODEL [5] was the first “special purpose” program for QSIM to what we called the postulation it would terminate with a shallow model if some parameters were omitted it has no parameter basically corresponds stage. Since determination model initial constraint feature, from its input. about relation information information, formulation) [29] and QSI are similar programs in many regards. MISQ has an MISQ implemented optional preprocessor which can convert numerical sensor data to qualitative behaviors. Unlike QSI, it allows partially specified qualitative values (also used by Bhaskar (as described above for MM) and dimension and Nigam [2] for qualitative in its the parameters input. MISQ’s equivalent of the initial constraint determination stage makes use in addition to value checking, during its operation. of this dimension is allowed, MISQ can find an inconsistent Since incomplete value information constraint set at the initial constraint determination. This is handled by erasing problematic constraints. Several alternative models, each obtained by erasing one such constraint, can be created. Dimensional in the constraint set are handl.ed similarly. MISQ deems a model satisfactory when it is consistent and connected, to all other that is, each parameter parameters. Because of this, MISQ would terminate with the shallow single- constraint model M-(amount-A, amount-B), when given the input of Tables 10 and 11. When it obtains an unsatisfactory model at the end of the initial constraint determination, MISQ postulates new variables using a method called relational pathfinding, which to what we call model extension at full postulation half search mode. (Relational pathfinding searches a somewhat smaller number of constraints of this method, MISQ terminates, than our version.) After one application even if the model is still unconnected. is linked by a “chain” of constraints almost equivalent is functionally inconsistencies to indicate The two programs’ respective performances on the two-parameter U-tube input i.e. number of seem that QSI’s criterion simulation behaviors, can lead to better results compared to MISQ’s connected- ness condition. QSI’s deferment of the imposition of dimensional consistency until the very lend helps it output a single model which contains all “model-tightening” relationships discovered during the execution, as explained for model “goodness”, in Section 4. Dzeroski and Todorovski’s QMN [ll] values, and builds a QSIM model directly, without converting qualitative (i.e. the length of the longest DERIVchain new paralmeters takes tuples of quantitative parameter to the the user to explicitly specify the system order the maximum depth of that is the sum of five format. QMN requires (e.g. a new parameter that can appear in the output), its input 124 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 7.5-141 dimensions, is two levels “deeper” and tolerance values used than one which is the sum of only three other parameters of the others), optional parameter to disregard numerical deviations hopefully caused by precision and noise problems. The algorithm first postulates new parameters up to the specified order and depth, on this big set and then performs a numerical version of constraint determination of parameters. Unlike QSI (and, to an extent, MISQ) QMN has no mechanism which lets it terminate without unnecessarily satisfactory model has been found at an intermediate step during the execution. [ 1 l] is a relative of QMN which produces quantitative models in a manner similar these are determined by linear regression. The above comments about the (ODES) as output. The set of “new” parameters to QMN. Significant equations parameters lack of a “depth Ramachandran test” mechanism apply to LAGRANGE et al. [28] have proposed a technique that an input qualitative behavior contains several operating regions. Their method can work in conjunction with any one of the single-region qualitative model induction algorithms described in this section, as well as QSI. of various combinations the output when a for recognizing LAGRANGE complicating is postulated composed as well. of Behavior-based modelers like QSI can be considered like [24]. As Dzeroski and Todorovski to be performing a kind of “discovery” [ll] point out, the fact that they usually ask for additional experimental data during the execution, and their in- requirement should be designated dependent, that distinguish machine discovery programs from the qualitative modelers. the parameters are among the factors as dependent that or 7. Conclusion the task format about in tool; We have presented an algorithm for qualitative system identification; information is a model of model building when incomplete is available. QSI system behavior to various model “composers” which build models by appropriately contrast piecing together already available model fragments, it creates them from scratch, using no information about the particulars of the system domain. The correctness procedure was proven, complexity analyses for of the constraint determination each part of the algorithm were performed, illustrating various aspects of the problem and possible application areas were presented. in the qualitative fragment and several examples formulation QSI embodies a very “mechanical” one may call a brute-force existence of any input parameter values. This research has shown that model structure quite impressive scale is possible even with only this much data. approach, arriving at the models by what search. This is the price paid for not relying on the except accounts of the changing of some identification at a information As well as being used in a stand-alone fashion for automatic model acquisition, QSI may form a part of the basis of a much more involved modeling procedure which combines the many approaches such a setup, QSI’s role would be to prepare to this difficult mental task in the future. In from which initial model proposals, A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 125 stages (as defined in Section 6.3) would prune the the more knowledge-intensive coincidental into what humans actually “do” during the model building task would certainly provide valuable pointers for the construction of such a program. constraints. Research and noninteresting As for more immediate areas of improvement the on new behavior selection heuristics, and the planned (similar to that used in [29]) to the dimension consistency stage, to eliminate of the capability of using optional dimensional knowledge for QSI, one can mention ongoing experimentation incorporation in format unnecessa.ry buffer parameters. Our approach able” parameter topic will certainly be useful for further work on QSI. to the problem of deciding what constitutes an “easily observ- and what does not has been quite intuitive. Research on this Acknowle’dgement Thanks are due to Bradley Richards, Levent Akin, Yorgo Istefanopulos, Kuban Altmel, Necati Aras, Ethem Alpaydm and Nadir Yiicel for their comments on this work. We are grateful for their helpful remarks. Those magnetic media from the authors for research purposes. to the anonymous the PROLOG source code of the QSI program interested may obtain referees in Appendix A. Consequence constraints In Section 4, the consequence and insignificance checks, which are parts of the algorithm, were mentioned. Both these checks are used constraint determination to see whether a particular constraint is already implied by the current knowledge of constraints or not. If it is implied, the process of checking the constraint against task to impart the each input state is unnecessary and is skipped. It is a nontrivial identify total knowledge all consequence constrainls the following that list is complete. Recall that the existence or absence of consequence constraints in the stage’s output affects only the efficiency of the algo- constrain1 determination rithm, not its correctness. See [18] for another application of similar ideas about a symbolic algebra M constraints, system which supports Ql, a qualitative-quantitative hybrid algebra, also de- scribed to it is not claimed the description of MINIMA, in that paper. of qualitative the program, and [39] for required algebra and to In the following, “known” consequences constraints; the left-hand of in the QDE, or previously discovered of those in the QDE. The right-hand sides are the consequences. side of the arrow contains conjunctions these are either M+(A, B), M+(B, C)+M+(A, C) . Proof. Recall that A, B, and C are functions of time. Furthermore, the M+‘s 126 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 that mean G(C(t)) everywhere there exist functions F and G such that A(t) = F(B(t)) and B(t) = (with the proper domains and ranges), and both F’ and G’ are positive in their domains [19]. But this means that A(0 = F(G(C(4)) and since the derivative of the composite and G’, H’ > 0 throughout M+(A, C), and the proof is complete. its domain; A(t) = H(C(t)) 0 function F 0 G = H is the product of F’ is the very definition of A more “qualitative” proof for the same rule is as follows: Consider all the that the parameters may take on. Given qualitative directions the possible direction those of Table A.l. Obviously, M+(A, C) is also in each possibility. (CV information of the consequence constraint “holds” handled by the CVs of the two antecedent constraints, using parameter B as a sort of “bridge.“) the antecedents, tuples are The first two of the following rules have similar proofs as the one above. M+(A, B), M-(B, C) + M-(A, C) . M-(A,B),M-(B,C)+ M+(A,C). ADD(A, B, C), M-(A, C) + M-(A, B) Proof. The proof is again very simple. The antecedents say that A(t) + B(t) = F(A(0) > where F’ is negative. Rearranging, one gets B(t) = -A(t) + F(A(t)) . Clearly, there exists a function G such that B(t) = G(A(t)) and G’ is negative in its domain. This means that M-(B, A). 0 Similarly, ADD(A, B, C), M+(A, B) + M+(A, C) . The fact that the derivative of a constant is zero implies the following rules, where Table A.1 Possible directions of A. B and C A inc dec std B inc dec std c inc dec std A.C.C. Say, S. Kuru / Artificial Intelligence 83 (1996) 75-141 121 K is a parameter already known to be fixed at a landmark: ADD(A, B, K) + M-(A, B) . ADD(A, K, B) + M+(A, B) . Other rules make use of the properties of MINUS and the fact that rearranged equations still “say” the same thing: MINUS(A, B) + M-(A, B) . ADD(A, B, C), MINUS(A, D) + ADD(C, D, B) . ADD(A, B, C), ADD(C, D, A) + MINUS(B, D) . Since al.1 constraints except DERIV are commutative, the left-hand sides of the above rul’es may be changed to reflect this fact; they will still apply. Appendix B. QSI in action illustrate This appendix is comprised of two parts. First, several additional examples which further the working of the QSI algorithm are presented. The common small scale of the inputs is a result of the insistence that these be actually imposes a maximum tested on the computer, and the fact that Turbo PROLOG memory comments about the systems and their models have been added by a human for the benefit the actual input and output of QSI are free of that. The second of the readers; remaining part discusses some detailed difficulties with the method. limit of 640K. Also keep in mind that all the “semantical” features and ways of handling certain B. 1. Examples B. 1.1. U-tube with full postulation As shown in Section 4, most QSI problems, in can be solved easily in the derivative postulation mode. For in the full sake, however, an account of the algorithm’s execution that of the U-tube including region NORMAL, completeness’ postulation mode is presented here. The input is again that of Tables 10 and 11. Since the postulation and search the initial model is again modes do not affect the initial constraint determination, found to be M- l(amount_A, amount-B) , and depth testing fails because of the great number of QSIM behaviors which are predicted. Now, all neighbors of the two visible parameters are postulated and this results in an equivalent of Table B.l being their behaviors are calculated; constructed the names of the new parameters (which are shown understand defined the reader can for example, A’ is the parameter which is to be amount-A’s derivative. The assigned behaviors can be seen to be table, in the leftmost column) are chosen so that their defining constraints, by the program. In that 128 A.C.C. Say, S. Kuru / Artificial Intelligence 83 (19%) 75-141 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) T-141 “sensible” enough, Section B.2 for a discussion on this. though (A - B) and (B - A) can raise a few thoughts, 129 see If half search mode (which is more efficient than full search mode, especially full postulation, where the number of old parameters the new ones) is active, the constraints constraints marked as “consequence” in the checked against the values of Table B.l and they are not added input. in is only a small fraction of listed in Table B.2 are found to hold. The table are not to the QSIM or “insignificant” that appear New parameters in the remaining entries of Table B.2 are made permanent. The fact that (A + B) is fixed is also marked in the QSIM invariants. Simulation with the extended model produces only the dimension consistency stage adds the required buffer parameters and constraints, this system’s model has already been and QSI discussed, that were found in this section. terminates let us concentrate on the additional constraints successfully. Since input behaviors, the Table B.2 U-tube (NORMAL) constraints found after model extension Constrainl: Remark ADD(A, A’, B) M-(A, A’) M+(B, A’) ADD@, B’, A) M+(A, B’) M-Q?, B’) M+(& (-4) ADD(B,( -A), A’) (--B)) (A - B)) (-B), B’) (A -B)) (A -B)) M+(A, ADD(A, M+(A, M-(B, DERIV(B, ADD((A -t B), (A - B), A) ADD@?, (A - E), (A + B)) M+(B, M-(A, DERIV(A., (B - A)) ADD((A ADD(A, ADD((A ADD((A t B), (B - A), B) (B-A), -B), (B-A), A) - B), (B -A), B) (LI -A)) (13 - A)) (A+@) (A*B)) (A*B)) (-A), (-B), (-A), A*) ADD(A, ADD@, ADD(A, ADD((A :K B), A*, A) ADD@, 8(-B), B’) ADD((A :L B), B*, B) consequence consequence consequence consequence consequence consequence consequence consequence consequence consequence see Section B .2 consequence consequence see Section B.2 insignificant insignificant insignificant insignificant insignificant insignificant 130 A.C.C. Say, S. Kuru / Artificial Intelligence 83 (1996) 7.5-141 the equations The last two ADDS, relating the products of amount-A and amount_B with their squares, are coincidental; they do not reflect any fundamental property of the U-tube, but may be the components of another system with similarly behaving quantities, as explained in Section 6.1.2. Another such coincidence has caused the involving (A + B). In fact, these constraints do not make four ADD constraints any arithmetic sense; they survive the contradiction check since there exist trivial though not with the cases where particular values here. They happen the behaviors, and will the output and slowing simula- not cause any negative effects (except cluttering tion), so they have been allowed to stay. By enabling the contradiction check to examine old parameter values, this sort of constraints could be totally eliminated. increasing the relevant model that full it is suggested if an initial approach using the the user’s (already constraints postulation derivative postulation mode proves to be unsuccessful. from among the ones in it. For this reason, should be used as a last resort, imply can be satisfied, to hold throughout As illustrated here, full postulation tends to produce a big output, responsibility of retrieving important) they B.1.2. Single leaking tank In Section 4, it was pointed out that the QDEs of different operating regions of runs of QSI. (Actually, QSI makes regions of the “same” system and of two is an account of how a U-tube, half of which has burst is the same system can be obtained by different no distinction between different systems.) Here (or, equivalently, identified by QSI: a bathtub whose plug has been pulled off after the bath), two operating Assume the only initially recognizable parameter is the amount of water in the tank, and this decreases and stops at zero (Table B.3). No constraints can be defined on a single parameter, which means the initial model is empty. Depth testing fails automatically, and the model extension stage (with derivative postulation mode) is activated, with the single parameter amount’ being postulated (see Table B.4). The constraints determined on this “bigger” behavior are again quite limited: M-(amount, amount’) with CVs (0,O) , MINUS(amount, amount’) , MULT(amount’, amount’, amount) , DERIV(amount’, amount) , Table B.3 Input of bathtub identification amount (init, dec) ((0, init), dec) (0, std) EQU A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 131 Table B.4 Old and oostulated oarameters for bathtub identification amount (init, dec) I($, f;;). dec) ,s amount’ ((-m, O), inc) ((-ma O), inc) (0, std) EQU and, of ‘course, the defining constraint DESRIV(amount, amount’) . Simulation produces the MINUS constraint shown in Table B.5. requires the single input behavior, dimension consistency to be dropped and buffers to be created, so the output is as the square relation is also coincidental. As for an interpretation, is again a coincidental one. The correctly relationships second DERIV describe a leaking tank with no inward flow. The rate of increase of the amount the (its derivative) the amount algorithm. The derivative postulation mode’s usefulness has once again been demonstrated; to it, and the flow ceases when “flow” has been hinted at by is inversely proportional vanishes. The deep parameter the following examples will further underline remaining this. The B.1.3. Bathtub and constant inflow (although as a parameter rate. Assuming Now suppose that a tap exists on top of the bathtub (as is often the case), and inflow is water pours out of it at a constant recognizable the input behavior (Table B.6) will be one in which the amount in the tub (starting from zero) arrives (Again, the possibility of overflow has at equilibrium at some positive landmark. in Section 4.) No constraints are found by the been overlooked; is required. Since inFlow is constant, initial determination, its derivative and extended constraint determination will be performed on the behavior shown in Table B.7. this is not necessary,) and model extension is not postulated, that the constant see discussion Table B.5 Output of bathtub identification Constraint M+(amount, P,) DERIV(P,, P2) M+(f’,, P:J M+(amount, PJ DERIV(P,, P,) M-(amount, P2) M+(P,, Pd M+ (amount, P6) MULVP,, P,, P,) cvs (0, O), (m, 9, (-m, -00) (0, O), P,m), (-9 (0, O), (m, a), (-m, --to) -m) (0, 0) (0, Oh @, =% (--m, -m) -m) (0, O), @, m), (-a, 132 A.C.C. Say, S. Kuru I Artijicial Intelligence 83 (1996) 75-141 Table B.6 Input for filling bathtub inFlow (inF, std) (inF, std) (inF, std) EQU identification amount (0, inc) ((0, % (disclmA , std) inc) Table B.7 Input of the second constraint determination in filling bathtub identification inFlow (inF, std) (inF, std) (inF, std) amount (0, inc) ((0, m), inc) ( disclmA , std) EOU amount’ ((0, m), dec) ((0, m), dec) (0, std) The QDE found (and accepted by the simulation) can be seen in Table B.8. The dimension consistency stage results in the final model of Table B.9. The ADD in the final model represents the fundamental relation netFlow = inFlow - outFlow . As well as the “discovered” between it and the amount parameter is again established. outFlow, the direct proportionality Table B.8 Sufficient QDE for filling bathtub identification Constraint amount’) M-(amount, ADD(amount, DERIV(amount, amount’, inFlow) amount’) Table B.9 Output of filling bathtub identification Constraint DERIV(amount, P,) M-(amount, P,) M+(amount, PJ M+(P,, p3) M+(inFlow, P,) ADD(P,, P3r 41 cvs (0, O), (m, co), (-m> --ml (0, 01, (m, ml, (-m> 4 (0,OL (Y ml, (-m, -ml A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75141 133 Table B.10 First input behavior for water balance identification amt(water, 1”) netFlow(water, I’+ 17) (A*, std) (NF, std) EQU B.1.4. Water balance in kidney Consider the situation in which only the two (supposedly) most easily observ- able parameters of Table 26, namely the amount of water in plasma and the net rate of water excretion, are used to form the input behaviors. One can say right to find the complicated model of Table away that QSI simply cannot be expected 24 from the features of the that the algorithm comes up with a complete system. Still, it will be demonstrated model (which is about all what a human novice can do “at first sight”), and gives some hints about possible deep parameters. tha.t does predict only the specified behaviors is inadequate these data; to uncover input the Of the two input behaviors, one Table B.10 has been obtained by observing the state of things for some time. Both parameters are at their equilibrium “normal” values. The second behavior is rapidly the amount drink. This has caused an immediate quantities gradually returning (Table B.ll) increased by an outside increase to their normal values. is a result of observing what happens when large rate, with both intervention, in the excretion i.e. a sudden Initial constraint determination results simulation shows that this model the derivative postulation mode, in the model of Table B.12, but, as is not deep enough. Again having two new parameters with defining expected, selected constraints Table B.ll Second input behavior for water balance identification amt(water, I’) (A*, 9, dec) netFlow(water, P+ U) (NF, m), dec) EQU Table B.12 Initial model in water balance identification Constraint M+(amt(water, MULT(amt(water, MULT(netFlow(water, P), netFlow(water, P-+ U)) P), amt(water, P), netFlow(water, P-t U)) P+ U), netFlow(water, P+ U), amt(water, P)) 134 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 DERIV(amt(water, P), P,) , DERIV(netFlow(water, P + U), P2) it would at least provide some pointers of the M’s which are found but not included their defining neighbors arrive equilibrium. Extended adds the constraints of Table B.13 to the QDE. are created, both starting at negative and increasing, and settling at zero as the con- same instant when straint determination (Various in the simulation consequences model, and which can be also useful for interpretation, are not presented here because of space considerations.) This model predicts only the two inputs, and is accepted. For the conditions presented in the input, a “robot physician” can use this as the basis of a model of the human water balance system. For a human to physician, is form a deeper model. already known.) For example, of amt(water, P) to netFlow(water, Furthermore, ingest+ P) is constant, which is the case in the table. P+ U) if netFlow(water, The direct proportionality P+ U) also follows from Table 24. All the discovered MULTs are coincidental. For a more specific identification, more parameters, more behaviors, the full postulation and search modes, and a user with some idea of what to expect in the model would be required. the existence of a parameter which is the derivative in Table 24. is such a parameter to start with in an attempt its model of amt(water, P) and netFlow(water, is inversely proportional (Not for this particular system, of course; is implied. There that quantity really really B. 1 S. Heat exchanger The heat exchanger system (Fig. B.l) is from [35]. There is cold water in the bath shown as the box in the figure. Hot liquid enters from one end of the pipe and leaves, cooler because of the heat flow, from the other end. There are three different behaviors, determined by whether the heat flow stops when the unit volume of liquid that we are interested in is in the pipe, in the input are X (position of and if so, where. Supposing to be used in this example that the parameters Table B.13 Constraints Constraint added by second constraint determination in water balance identification amt(water, amt(water, DERIV(amt(water, DERIV(netFlow(water, ADD(amt(water, ADD(amt(water, ADD(P,, ADD(P,, M-(netFlow(water, M-(netFlow(water, MULT(netFlow(water, MULT(netFlow(water, MULT(amt(water, MULT(amt(water, P), PJ P+ U), P,) P), P,, netFlow(water, P), P2, netFlow(water, P), netFlow(water, P), netFlow(water, P+ U), P,) P+ U), P2) P-+ U), P,, P2) P+ II), P,, P,) P), P,, P2) P), P,, P,) P+ U)) u)) P+ P+ U)) P-+ U)) A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 135 hot liquid -A ; I & b I Fig. B.l. The heat exchanger. liquid in the pipe; the entry end is the negative landmark x* and the exit end is is reached, a positive 0), Q (surplus heat of liquid; 0 when thermal equilibrium value at the start) and F (the heat flow in the liquid), the algorithm starts with the three behaviors in Tables B.14-B.16. Initial c’onstraint determination really covers flow, whelreas the fourth one has the equation the heat flow relationships; comes up with the model of Table B.17, which is the definition of the first constraint F=-KQ (where -.K is the thermal conductivity) “embedded” in it. (Even in the case Table B.14 Input behavior #1 for heat exchanger identification X Q Table B.15 Input behavior #2 for heat exchanger identification X inc) (x*, ((I*, 0), inc) (0, inc) Q (q*, dec) Table B.16 Input behavior #3 for heat exchanger identification X inc) (x*, ((x*, 0), inc) ((x*, 01, inc) ((x*, 01, inc) (0, inc) Q (q*, dec) $0, $ dec) (0: :td) (0, std) F (f*, inc) ((f*, 01, inc) (0, std) F inc) (f*, ((f*, O), inc) ((f*, Oh inc) F (f*, inc) (0, std) 136 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 Table B.17 Initial constraints Constraint DERIV( Q, F) DERIV(F, Q) MINUS@ Q) M-F, Q) MULW, F, Q) for heat exchaneer identification cvs (0, 0) the figures in Table 23 reflect where only the longest behavior ered; coincidental. Note, however, discovered pipe was warming instead of cooling. are still discov- are that DERIV(F, Q) is what one would expect to be if those two names were swapped in the input, i.e. if the liquid in the that situation.) The other constraints those relationships is entered, constraint set fails automatically without Depth testing on the above-mentioned In the model in any of the constraints. simulation, because X does not appear since the derivatives extension stage, the derivative of only X will be postulated, of both Q and F are already there. The heuristics lead to a fixed positive value for that parameter is satisfactory, to be determined. The resulting model’s simulation and QSI terminates after the dimension consistency stage. A fixed value for the derivative of X is sensible, since it simply means that the speed of the liquid in the pipe is constant. A justifiable remark about this problem is that instead of the heat and its flow, the temperatures of the liquids would be more appropriate as shallow parameters. See Section B.2 for a discussion. B.1.6. The upward thrown ball This section will be concluded by an account of the execution of QSI when fed thrown the height of an upward (Table B.18) describing a single input behavior ball which rises for a while and then falls back. After an empty initial model, derivative postulation will result in the extended is not for a to be fixed at a negative value and added to the model, which passes the test. From a single account of behavior of Table B.19, but the single DERIV linking the two parameters sufficient for a tight simulation, and model extension has to be performed second permanently time. The derivative of Y’ is decided Table B.18 Behavior of ball height Y (disclmY, ~~,d~.s;lmY), dec) std) A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 137 Table B.19 Innut to second constraint determination in ball svstem identification Y ((0, m) inc) ((0, m) inc]’ (disclmY, $Jd$~‘l’A std) dec) Y' ((0, =% dec) ((0, ml, dec) (0, dec) ((-my 01, dec) (C-m, 0) dec) the height of a thrown object, identified. Two deep parameters been correctly examples of this section. suggested. Consult Table 23 for the “laws” governing representing such bodies have been the velocity and acceleration have times of the the execution B.2. Further issues The behavior calculation procedure, invoked in the model extension stage to (as explained infinitely many alternative behaviors is the only “heuristic” part of the algorithm it comes up with are guaranteed to each postulated assign one of possibly in Section parameter, 4). The behaviors to be mathematically plausible with regard to their neighbors specified in the input, but the extent to which they match the corresponding deep parameters that we give to the system is dependent on the “rules of thumb” of behavior selection embedded in schemes may that procedure, increase the by algorithm. Examples of some such selection will be presented and possible new heuristics and representation into QSI. This means that there is always room for improvement in the semantical interpretation the number of problems issues about behavior that can be solved in this section. satisfactorily Consider the heat exchanger of Section B.1.5 again. This the more the same as and Ti, (the of the unit volume of liquid that one is tracking in the pipe) will be realistic assumption before,) T,,,, (the temperature made. ThLe input behaviors are shown in Tables B.20-B.22. are X (meaning of the cool water bath,) the temperature initial parameters that fixed time, By using our knowledge of the domain, we can “cheat” and write down the the system as we constraints interpret it. The rate of increase of Ti, will have the sign of (T,,,, - Tin); i.e. we expect QSI to find the relations DERIV(T,,, P) and ADD(T,,, P, To,,) along with to find if it is to identify that QSI is “supposed” Table B.20 Input #1 fasr heat exchanger identification (temperature version) Ti” ( Tbcgi, 1 dec) ((O,T,,,,A dec) (disclmT, std) T O”t coo,> std) i ;w,,* std) coo,, std) 138 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 Table B.21 Input #2 for heat exchanger identification (temperature version) i-1” ( Tbegin a dec) ((OJ,,,,A dec) ((0, TbepiA dec) T O”f std) std) ; ;I::: (Tw,,, std) to make a preference: is, three alternative the already seen one about the derivative of X. The trouble for the derivative of Ti, in Table B.21 exist, among which the heuristics behaviors and (1) P negative and fixed, have increasing, (1) will be chosen because of the heuristic which tries to keep the order of the model as small as (2) is the behavior which fits our understanding of the system, possible. However, and the expected model will not be found. and (3) P negative and decreasing. Of these, (2) P negative the motivation the state tree’s structure since it would cause values in several behaviors for the ongoing research for better heuristics. A This illustrates in the input could also provide a way of representing to be identified as a solution, single one, the number of alternatives. Next, some issues that can be resolved by the use of a more flexible representation will be briefly considered. restriction which would probably imposing an additional reduce In the U-tube identification of Section B. 1.1, the difference parameters (A - B) in which they both have the value zero at and (B - A) are assigned behaviors equilibrium. This is a possibility, but two other possibilities corresponding to the cases where either amount-A or amount B is the greater of the two also exist. these possibilities have more than three values in Since the behaviors representing them, It must also be mentioned that QSI takes special care in the behavior calculation of new parameters which are negatives or reciprocals of each other, like P, and P2 defined by ADD(X, P,, Y) and ADD(Y, P,, X) or P3 and P4 defined by MULT(A, P3, B) and MULT(B, P4, A), so that no inconsistency they are not even considered by the algorithm. is allowed between the new behaviors. Finally, consider postulated by QSI. the subsystem of Table B.23. The derivative of X is to be The new parameter’s magnitude clearly has to be zero at the endpoints of the behavior, and positive within it. Once again, there is more than one choice, even when one restricts attention the heuristics to behaviors with seven values and applies (Table B.24). Table B.22 Input #3 for heat exchanger identification (temperature version) X inc) (2, ((x*, 01, inc) ((x*, 01, inc) ((x*, 01, inc) (0, inc) Ti. i ~~~~_~~)dec) (di.sclmT, std) (disclmT, std) (disclmT, std) A.C.C. Say, S. Kuru I Artificial Intelligence 83 (19%) 75-141 139 Table B.23 Behavior of X-Y subsystem X (neglm, std) @4gIn;, 01, inc) , mc inc) ((0, poslm), inc) (posh, (( poslm, maxim), (maxim, sid) inc) Y inc) inc) inc) inc) ((0, 9, ((0, 9, ((0, 9, ((0, 9, (Ylm, std) ((0, Ylm), dec) ((0, Ylm), dec) Table B.24 Two choices for the behavior of X’ X choice #l for X’ choice #2 for X’ (neglm, std) ((neglm, 0), inc) (0, inc) ((0, posh), (poslm, (( poslm, maxim), (maxim, inc) inc) std) inc) (0, inc) ((0, 9, (lml, std) ((0, lml), dec) ((0, lml), dec) ((0, lml), dec) (0, dec) inc) inc) inc) (0, inc) ((0, 9, ((0, 9, ((0, 9, (lml, std) ((0, lml), dec) (0, dec) inc) there Furthermore, is no good reason that the derivative just when another parameter should arrive at its is crossing one of its own landmarks, and landmark the “real” description may well be one with a greater number of qualitative states. All these different possibilities would cause different constraints involving X’ to be found, or not to be found. For example, M+(X’, Y) is found only if choice #2 is selected for X. To deal with such situations so that the chances of scheme for the constraint discovery are maximized, a more flexible representation directions of postulated derivatives has been designed. The idea is to defer the actually stops at its landmark until a decision on when phase. Till then, involving constraint the new parameter it is found in the constraint determination Table B.25 Extended behavior of subsystem X (neglm, std) ((neglm, 011, inc) (0, inc) ((0, poslm), in:) (poslm, ( (poslm, maxim), (maxim, std) inc) inc) Y inc) inc) inc) inc) ((0, 9, ((0, 9, ((0, 9, ((0, 9, (Ylm, std) ((0, Ylm), dec) ((0, Ylm), dec) X’ (0, inc) isd) (CO,% ((O,% isd) ((0, 9, isd) isd) ((O,% ((0,9, isd) (0, dec) 140 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 isd (increasing-steady-decreasing) on its sign. After the postulated parameter’s direction either depending involving In the example, in Table B.25. Consistency the parameter, its behavior checks in the period between its two zeros is set to or dsi (decreasing-steady-increasing), the discovery of the first significant constraint format. the situation at the end of the postulation stage will be as shown into the conventional is translated involving satisfied. When the directions of X’ are updated with std or dec so that it really satisfies the M+; this amounts to the choice #2 in M+(X’, Y) passes the test in this manner, ix, Table B.24 being finally selected. isd or dsi are automatically References 111 PI [31 t41 PI PI [71 PI [91 [lOI t111 [=I iI31 [I41 WI [I61 [I71 [l81 International Workshop on Machine Learning in: Proceedings ZJCAZ-89, Detroit, MI (1989) in: (Morgan Kaufmann, San Introduction to Artificial Intelligence (Addison-Wesley, Read- J. Amsterdam, Automated qualitative modeling of dynamic physical systems, Technical Report, MIT AI Laboratory, Cambridge, MA (1993). R. Bhaskar and A. Nigam, Qualitative physics using dimensional analysis, Artif. Intell. 45 (1990) 73-111. I. Bratko, S. Muggleton and A. Varsek, Learning qualitative models of dynamic systems, Proceedings Eighth Mateo, CA, 1991) 385-388. E. Chamiak and D. McDermott, ing, MA, 1985). E. Coiera, Generating qualitative models from example behaviours, Technical Report 8901, Department of Computer Science, University of New South Wales (1989). D. DeCoste, Dynamic across-time measurement interpretation, Artif. InteN. 51 (1991) 273-341. J. de Kleer and J.S. Brown, A qualitative physics based on conlhtences, Artif. Intell. 24 (1984) 7-83. R.J. Doyle, Reasoning about hidden mechanisms, 1343-1349. D. Dvorak and B. Kuipers, Model-based monitoring of dynamic systems, IJCAI-89, Detroit, MI (1989) 1238-1243. S. Dzeroski, Learning qualitative models with inductive logic programming, (1992) 30-41. S. Dzeroski and L. Todorovski, Discovering dynamics: from inductive machine discovery, J. Intell. Information Syst. (to appear). B. Falkenhainer, A unified approach to explanation and theory formation, Langley, eds., Computational Models of Scientific Discovery and Theory Formation Kaufmann, San Mateo, CA, 1990) Chapter 6. K.D. Forbus, Qualitative process theory, Artif. Zntell. 24 (1984) 85-168. K.D. Forbus, Interpreting observations of physical systems, in: D.S. Weld and J. de Kleer, eds., Readings in Qualitative Reasoning about Physical Systems (Morgan Kaufmann, Los Altos, CA 1990). P. FouchC and B.J. Kuipers, Reasoning about energy in qualitative simulation, IEEE Trans. Syst. Man Cybern. 22 (1992) 47-63. D. Halliday and R. Resnick, Physics (Wiley, New York, 1978). Y. Iwasaki and H.A. Simon, Causality in device behavior, Artif. Intell. 29 (1986) 3-32. B.J. Kuipers, Commonsense Intell. 24 (1984) 169-203. reasoning about causality: deriving behavior from structure, Artif. in: J. Shrager and P. (Morgan logic programming Informatica 16 (4) in: Proceedings to iI91 B.J. Kuipers, Qualitative simulation, Artif. Intell. 29 (1986) 289-338. A.C.C. Say, S. Kuru I ArtijYcial Intelligence 83 (1996) 75-141 141 [20] B.J. Kuipers, Abstraction by time-scale in qualitative simulation, in: Proceedings AAAZ-87, Seattle, WA (1987) 621-625. [21] B.J. Kuipers, Qualitative simulation as causal explanation, IEEE Trans. Syst. Man. Cybern. 17 (1987:) 432-444. [22] B.J. :Kuipers, Qualitative Automatica 25 (1989) 571-585. reasoning: modeling and simulation with incomplete knowledge, [23] B.J. Kuipers, Qualitative reasoning with causal models in diagnosis of complex systems, in: L.E. Widman, K.A. Loparo and N.R. Nielsen, eds., Artificial Intelligence, Simulation and Modeling (Wileyy, New York, 1989). [24] P. Langley, H. Simon, G. Bradshaw and J. Zytkow, Scientific Discovery: Computational Explorations of the Creative Processes (MIT Press, Cambridge, MA, 1987). [25] N. Lavrac and I. Mozetic, Methods for knowledge acquisition and refinement in second generation expert systems, SIGART Newsletter 108 (1989) 63-69. [26] L. Ljung, Issues in system identification, [27] R.M. O’Keefe, The role of artificial intelligence IEEE Control Syst. 11 (1991) 25-29. in discrete-event simulation, K.A. Loparo and N.R. Nielsen, eds., Artificial Intelligence, Simulation and Modeling New York, 1989). in: L.E. Widman, (Wiley, [28] S. Ramachandran, R.J. Mooney and B.J. Kuipers, Learning qualitative models for systems with multiple operating regions, in: Proceedings QR-94 (1994). [29] B.L. Richards, I. Kraan and B.J. Kuipers, Automatic abduction of qualitative models, in: Proceedings AAAI-92, San Jose, CA (1992) 723-728. [3O] J. Rothenberg, The nature of modeling, in: L.E. Widman, K.A. Loparo and N.R. Nielsen, eds., Artificial Intelligence, Simulation and Modeling (Wiley, New York, 1989). [31] A.C.C. Say, Qualitative system identification, Ph.D. Thesis, Bogazici University, Istanbul (1992;1. [32] A.C.C. Say and S. Km-u, Nitel model tamlama, in: Proceedings Bilkon- Bilkent Elekfrik- Elektronik ve Bilgisayar Miihendisligi Konferanst, Ankara, Turkey (1991) 363-366. [33] A.C.C. Say and S. Kuru, An algorithm for qualitative system identification, in: Proceedings Seventh International Symposium on Computer and Information Sciences (ZSCZS VII), Antalya, Turkey (1992) 229-235. [34] A.C.C. Say and S. Kuru, Improved filtering for the QSIM algorithm, IEEE Trans. Pattern Anal. Mach. Intell. 15 (1993) 967-971. [35] D.S. Weld, Comparative analysis, Artif. Zntell. 36 (1988) 333-373. [36] D.S. Weld and J. de Kleer, eds., Readings (Morg,an Kaufmann, Los Altos, CA, 1990). in Qualitative Reasoning about Physical Systems [37] L.E. Widman, K.A. Loparo and N.R. Nielsen, eds., Artificial Intelligence, Simulation and Modeiing (Wiley, New York, 1989). [38] B.C. Williams, Qualitative analysis of MOS circuits, Artif. Intell. 24 (1984) 281-346. [39] B.C. Williams, MINIMA: a symbolic approach to qualitative algebraic reasoning, in: Proceedings AAAI-88, St. Paul, MN (1988) 264-270. [40] C.W. Xu and Y.Z. Lu, Fuzzy model identification and self-learning for dynamical systems, IEEE Trans. Syst. Man Cybern. 17 (1987) 683-689. 