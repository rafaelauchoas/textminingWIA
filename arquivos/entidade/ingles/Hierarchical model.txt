Available online at www.sciencedirect.comRArtificial Intelligence 155 (2004) 147–182www.elsevier.com/locate/artintHierarchical model-based diagnosis based onstructural abstractionLuca Chittaro ∗, Roberto RanonDepartment of Mathematics and Computer Science, University of Udine, via delle Scienze 206,33100 Udine, ItalyReceived 9 December 2002; received in revised form 20 June 2003AbstractAbstraction has been advocated as one of the main remedies for the computational complexityof model-based diagnosis. However, after the seminal work published in the early nineties, littleresearch has been devoted to this topic. In this paper, we consider one of the types of abstractioncommonly used in diagnosis, i.e., structural abstraction, investigating it both from a theoreticaland practical point of view. First, we provide a new formalization for structural abstraction thatgeneralizes and extends previous ones. Then, we present two new different techniques for model-based diagnosis that automatically derive easier-to-diagnose versions of a (hierarchical) diagnosisproblem on the basis of the available observations. The two proposed techniques are formulatedas extensions of the well-known Mozetic’s algorithm [I. Mozetic, Hierarchical diagnosis, in:W.H.L. Console, J. de Kleer (Eds.), Readings in Model-Based Diagnosis, Morgan Kaufmann, SanMateo, CA, 1992, pp. 354–372], and experimentally contrasted with it to evaluate the obtainedefficiency gains. 2003 Elsevier B.V. All rights reserved.Keywords: Model-based diagnosis; Abstraction; Hierarchical reasoning1. IntroductionIn the last decade, Model-Based Diagnosis (MBD) [4,6,9,18] has been a very active areaof research in Artificial Intelligence that has led also to significant industrial projects (e.g.,[16,20,22]).* Corresponding author.E-mail addresses: chittaro@dimi.uniud.it (L. Chittaro), ranon@dimi.uniud.it (R. Ranon).0004-3702/$ – see front matter  2003 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2003.06.003148L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182Computational complexity of multiple fault diagnosis is one of the well-knownproblems that needs to be tackled in order to deploy real-world applications of MBD.Since the late eighties, some researchers (e.g., [10,12,14,19]) advocated abstractionas one of the main remedies for this problem. The proposed approaches are typicallyhierarchical: they represent the problem at multiple levels of detail, and then isolate faultsone level at a time, starting at the most abstract possible level and using the results at onelevel to focus reasoning at more detailed levels, thus reducing the overall computationalcost of diagnosis.Two kind of abstractions are commonly employed in MBD: structural abstraction [5,10], which aggregates components to describe the system at different levels of structuraldetail, and behavioral abstraction [12,14,19], which applies simplification operators todescribe the system at different levels of behavioral detail (e.g., moving from quantitativeto qualitative values in describing the functioning of components).In this paper, we build on seminal work on abstraction in MBD, and investigatestructural abstraction both from a theoretical and practical point of view.First, we provide a new logical formalization for structural abstraction that generalizesand extends previous ones [1,14,19]. Our proposal builds on the well-known consistency-based theory of diagnosis [8] and on a general framework (the semantic theory ofabstraction [15]) for the representation of abstraction between first-order theories. Unlikeprevious formalizations of structural abstraction, our proposal allows one to representcomponents with multiple behavioral modes (e.g., valves). Thus, it can be employedwith a wider class of physical systems. Moreover, the proposed formalization allowsone to easily prove some properties of structural abstraction that are useful in diagnosticreasoning.Second, we present two new techniques for hierarchical model-based diagnosis that areable to automatically derive easier-to-diagnose versions of a given diagnosis problem onthe basis of the available observations. The goal of our research is to move from simplyusing abstraction in diagnosis to using a good abstraction for the situation at hand, i.e.,using context to choose it. Indeed, one limit to the effectiveness of current approachesto hierarchical diagnosis is the fact that a single, pre-set hierarchical representation isemployed, regardless of the currently available diagnostic information. In some cases, thisleads to suboptimal or even counterproductive results in terms of efficiency (some detailedexamples will be illustrated in the paper). Unfortunately, most abstractions are usuallymanually engineered, and thus building a suitable abstract system representation for eachdiagnostic scenario is not a viable solution. We tackle the problem by using the idea ofautomatically tailoring an existing multi-level abstraction hierarchy (that may come fromdesign) to the particular problem at hand. The two techniques (called REARRANGE andBOTTOM-UP) we developed for this purpose:• are based on different strategies, and can be easily combined together to sum up theirrespective advantages;• build on the seminal work on hierarchical diagnosis by Mozetic [14], and are presentedas extensions to that approach.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182149To evaluate the efficiency gains that can be obtained, we present a detailed experimentalevaluation using a set of different hydraulic systems, considering the original Mozetic’sapproach, the two techniques in isolation, and the two techniques in combination.The techniques presented in the paper are general, and can be easily adopted by anymodel-based approach that follows the widely adopted consistency-based paradigm. Thepaper illustrates in detail the algorithms that implement the proposed techniques to allowinterested readers to easily include them and experiment with them in their systems.Finally, this work builds also on previous approaches we proposed in the domain ofFlow-Based Functional Models [3,17] and, more generally, in the context of structuralabstraction [2]. This paper extends and improves the latter in several directions, inparticular:• it proposes a proper theoretical framework, i.e., the formalization for structuralabstraction mentioned above;• it discusses (using also detailed examples) why using the same hierarchical represen-tation regardless of the currently available diagnostic information can limit or eveneliminate the efficiency gains of abstraction;• it refines the REARRANGE technique and proposes a new technique for hierarchicaldiagnosis (i.e., the BOTTOM-UP technique);• it presents a detailed experimental comparison of the proposed techniques and thereference approach of Mozetic.The paper is structured as follows: Section 2 summarizes background work on which webuild; Section 3 defines a formalization of structural abstraction in diagnosis and illustratesits properties, discussing also related work; Section 4 considers the problem of diagnosticreasoning with structural abstraction by illustrating the state of the art, proposing methodsto improve it by automatically tailoring existing abstractions to the situation at hand, andfinally illustrating the experimental activity that has been carried out. Section 5 concludesthe paper by presenting some possibilities for further work.2. BackgroundIn this section, we briefly illustrate those aspects of the consistency-based theory ofdiagnosis [8] and the semantic theory of abstraction [15] that are relevant to illustrateour work, and add some minor extensions to them. Moreover, we clarify the conceptsby introducing detailed examples taken from the hydraulic domain that will be followedthroughout the paper.2.1. Representing diagnosis problemsFollowing [8], a diagnosis problem D in a language L is defined as a triple (SD, OBS,COMPS) where SD and OBS are first-order theories in language L, representing the systemdescription and observations, respectively, and COMPS is a subset of the object constantsof L, i.e., the names of the system components.150L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182In order to explicitly separate structural knowledge (i.e., how components are connectedtogether) from behavioral knowledge (i.e., how components behave), we divide SD in thefollowing way:SD = CD ∪ BD ∪ Γwhere BD (behavioral description) represents the behavior of the components in thesystem, CD (compositional description) represents the structure of the system, and Γrepresents general knowledge (e.g., hydraulic laws) that is not specific to the consideredsystem.1Definition 1 (behavioral description of a component). The behavioral description of acomponent c (denoted BDc) in a diagnosis problem D, is a set of sentences of the form(cid:1)m(c) ⊃ σc( (cid:5)zc)(cid:2)Tc(c, (cid:5)zc) ⊃where• Tc(c, (cid:5)zc) is the component type predicate for c, and (cid:5)zc lists the ports of the component,• m is a predicate identifying one of the behavioral modes of c,• σc( (cid:5)zc) is a first-order formula with free variables (cid:5)zc describing the behavioral mode mof c with respect to its ports.The behavior of a component is thus represented as a set of first-order sentences, eachone corresponding either to a normal or a faulty behavior, which is defined by a predicateover the component ports.Definition 2 (behavioral description). The behavioral description BD of a diagnosisproblem D is the union of the behavioral descriptions of the components in COMPS.Definition 3 (compositional description). The compositional description CD of a diagnosisproblem D = (SD, OBS, COMPS) is a first-order sentence of the form(cid:3) (cid:4)(cid:5)T (S, (cid:5)zS) ≡ ∃z1, z2, . . . , znTc(c, (cid:5)zc)wherec∈COMPS• S is the system’s name,• every variable in (cid:5)zS appears in one of the tuples (cid:5)zc, for any c ∈ COMPS, and othervariables in the tuples are z1, z2, . . . , zn.The right-hand part of compositional description CD contains one component typepredicate for each component in the system. A connection between two components is1 A similar separation of structural and behavioral knowledge was proposed in [1]. Here we extend it tocomponents with multiple behavioral modes.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182151represented by using the same variable name for the two connected ports (one belonging tothe first component, the other to the second one). The left hand part of CD is composed bya component type predicate for the whole system, which lists those component ports whichdo not connect two components, but connect a component to the system’s environment.In general, we assume that observations on the system are taken at component’s ports.We adopt the following standard definitions employed in consistency-based diagnosis.Given a diagnosis problem D, a candidate C is a formula that assigns to each componentof D one of its behavioral modes, while a partial candidate is a formula assigning abehavioral mode only to some components of D. A (partial) candidate C is a (partial)diagnosis if it is logically consistent with both SD and OBS, i.e., there is an assignment Iof values to the ports of the system such thatI |= SD ∧ OBS ∧ CIn this case, we will call I a model of D; similarly, we will say that D is inconsistent if ithas no models. To solve the diagnosis problem, one should find all diagnoses, or a compactcharacterization for them (such as the kernel diagnoses described in [8]).Finally, we will use the notation CANDS(D, B), where B ⊆ COMPS, to denote the setof all (partial) candidates for the diagnosis problem D that can be built using all and onlythe components in set B. The cardinality of CANDS(D, COMPS) depends both on thecardinality of COMPS, and on the number of possible behavioral modes which are definedfor the components in BD. If a component ci of a diagnosis problem has Mi possiblebehavioral modes, then(cid:6)(cid:6)CANDS(D, COMPS)(cid:6)(cid:6) =(cid:7)Mici ∈COMPSresulting in a number of candidates which is exponential in |COMPS|. Considering thesimplest case where each component has only two behavioral modes (ok and faulty), thenumber of candidates is 2n, where n is the number of components. More realistic cases(where there are more than two modes) will lead to larger cardinalities.Example 1. The simple hydraulic system depicted in Fig. 1, called hydraulic case study(hcs) hereinafter, contains 11 components: a volumetric pump pm (delivering a constantflow equal to FK ), pipes p1, p2, p3, p4, p5, p6, valves v1 and v2, and three-way nodes n1and n2. The ports in the system are: t1, . . . , t13 (connecting components together), sv1 andsv2 (allowing one to set the state—open or closed—of valves v1 and v2, respectively).We suppose that each component has one ok behavioral mode, which represents itsnormal behavior. The considered faults are: external leaks (denoted by the predicate leak),which affect pumps, pipes, and valves; stuck-at-closed and stuck-at-open faults (denoted bythe predicates stuckC and stuckO, respectively), which affect valves; low or high deliveredflowrates (denoted by the predicates loF and hiF), which affect pumps.The behavioral descriptions of the components are given in Table 1. For simplicity, wesuppose that three-way nodes cannot be faulty, i.e., they have only a normal behavioralmode. Moreover, we consider two component types: one for three-way nodes with oneintended input and two outputs, called twoOut, and one for three-way nodes with twointended inputs and one output, called twoIn.152L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182Fig. 1. Layout of the hydraulic case study (component names are shown in bold).Table 1Behavioral descriptions for components in the hcsComponentpumpType predicatepump(x, [in, out])pipevalvepipe(x, [in, out])valve(x, [s, in, out])three-way nodetwoOut(x, [in, out1, out2])twoIn(x, [in1, in2, out])Behavioral modesok(x) ⊃ in = out = FKleak(x) ⊃ in > outloF(x) ⊃ in = out < FKhiF(x) ⊃ in = out > FKok(x) ⊃ in = outleak(x) ⊃ in > outok(x) ⊃ [(s = closed ∧ in = out = 0) ∨ (s = open ∧ in = out)]leak(x) ⊃ in > outstuckO(x) ⊃ (s = closed ∧ in = out > 0)stuckC(x) ⊃ (s = open ∧ in = out = 0)ok(x) ⊃ in = out1 + out2ok(x) ⊃ in1 + in2 = outThe compositional description CD for the hcs is the following formula:(cid:1)(cid:8)hcs, [t1, t13, sv1, sv2hydSystem(cid:9)]≡ ∃t2, . . . , t12pump( pm, [t1, t2]) ∧pipe(p1, [t2, t3]) ∧ twoOut(n1, [t3, t4, t5]) ∧ pipe(p2, [t4, t6]) ∧pipe(p3, [t5, t7]) ∧ valve(v1, [sv1, t6, t8]) ∧ valve(v2, [sv2, t7, t9]) ∧pipe(p4, [t8, t10]) ∧ pipe(p5, [t9, t11]) ∧ twoIn(n2, [t10, t11, t12]) ∧pipe(p6, [t12, t13])(cid:2)Finally, for this system, |CANDS(D, COMPS)| = 4 · 26 · 42 = 4096.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–1821532.2. Representing abstractionWe adopt the semantic theory of abstraction [15], viewing abstractions as model levelmappings. From this perspective, abstracting a theory is a two-step process that firstabstracts the intended domain model, and then builds an abstract theory to capture theabstracted domain model. Although there are also other theories that could be used for ourpurposes (see, e.g., [11]), the theory we adopt has the advantage of explicitly representingthe motivation and choices behind a given abstraction.More formally, given U0 and U1, sets of sentences2 in languages L0 and L1, thenan abstraction mapping π is a function that maps models of a (base) theory U0 tocorresponding interpretations of an (abstract) language L1:π : Models(U0) → Interpretations(L1)Given any model M0 of U0, π builds the interpretation π(M0) for L1 by defining:• a formula π∀ (with one free variable, x1), that defines the abstract universe;• for each n-ary relation R in L1, a formula πR ∈ L0 with n free variables x1, . . . , xn,that defines R. Given any model M0 of U0, πR defines an n-ary relation in M0. Thedenotation of R in π(M0) is πR restricted to the universe of π(M0);• similar formulas to specify the denotation of abstract object and function constants(see [15] for more details).U1 is an abstraction of U0, given the abstraction mapping π , if and only if U1 captures allthe abstract models (with respect to π ) of U0. This is captured by the definition of modelincreasing (MI) abstractions:Definition 4 (model increasing abstraction). Let U0 and U1 be sets of sentences inlanguages L0 and L1, respectively. Let π : Models(U0) → Interpretations(L1) be anabstraction mapping. U1 is a Model Increasing (MI) Abstraction of U0 with respect toπ (written U1 <π U0) if for every model M0 of U0, π(M0) is a model of U1.MI abstractions cover various common model level abstractions, such as taking theunion of a set of predicates (see [15] for examples of other MI abstractions).Example 2. Consider the behavioral description for a valve that has been given in Example1. Suppose that we want to build a more abstract description where we want to representonly two fault modes instead of three: one ( faultyO), covers all the faults in the open state,and the other ( faultyC), covers all the faults in the closed state, i.e.:(cid:8)valve(cid:8)valvex, [s, in, out]x, [s, in, out](cid:1)(cid:1)(cid:9)(cid:9)⊃⊃faultyO(x) ⊃ (s = open) ∧ (in > out ∨ in = out = 0)faultyC(x) ⊃ (s = closed) ∧ (in (cid:20)= 0 ∨ out (cid:20)= 0)(cid:2)(cid:2),2 We adopt the convention of using a greater subscript to indicate a more abstract, simpler theory.154L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182The abstraction mapping we must adopt is such that the denotation of predicate faultyO(x)is the union of the denotations of predicates leak (restricted to the cases where s = open)and stuckC, while the denotation of predicate faultyC(x) is the union of the denotations ofpredicates leak (restricted to the cases where s = closed) and stuckO of Example 1, i.e.,(cid:9)(cid:8)faultyO(x) ≡π s = open ∧leak(x) ∨ stuckC(x),(cid:9)faultyC(x) ≡π s = closed ∧ (leak(x) ∨ stuckO(x)Other kind of abstractions, which are not MI, but can be useful in reasoning, can beviewed as MI abstractions in conjunction with simplifying assumptions [15], i.e., U1 is aMI abstraction of U0 under simplifying assumption A if there is a theory UA ⊆ U0 suchthat UA is consistent with A and U1 is a MI abstraction of UA ∪ A.We are interested in the following properties of MI abstractions (see [15] for moredetails):Proposition 1. Let U1 be a MI abstraction of U0. If U1 is inconsistent, then U0 isinconsistent.Proposition 1 implies that to prove the inconsistency of a base theory, it suffices to provethe inconsistency of a (potentially simpler) MI abstraction of that theory (in general, theconverse does not hold).Proposition 2. Let U1 be a MI abstraction of U0 and V1 be a MI abstraction of V0 underthe same interpretation mapping π . Then U1 ∪ V1 is a MI abstraction of U0 ∪ V0 under π .Proposition 2 implies that MI abstractions are compositional, allowing one to buildabstract theories by composing knowledge from different sources.3. Formalizing structural abstractionIn this section, we propose a formalization for the concept of structural abstraction indiagnosis. We will define the structural abstraction of a diagnosis problem D as a (moreabstract) diagnosis problem whose components are: (i) some new (super)components, eachone representing the aggregation of a set of connected components of D, and (ii) thecomponents of D which are not involved in the aggregations. Following the approach ofthe semantic theory of abstraction, we will first define a proper interpretation mapping,i.e., an interpretation mapping that encodes the aggregation of structure and behavior ofcomponents at the model level, and then define the structural abstraction of a diagnosisproblem with respect to that interpretation mapping.As we will see, structural abstraction is a MI abstraction. This will allow us to formalizea correspondence between the solutions of a diagnosis problem and the solutions ofits structural abstraction. This correspondence will be the basis for the exploitation ofstructural abstraction in diagnostic reasoning.At the end of this section, we include a comparison with previous formalizations ofstructural abstraction and highlight relations and improvements.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–1821553.1. Informal definitions and assumptionsSuppose we are given a diagnosis problem D0, and we want to build a more abstractversion of it D1, in which a single (super)component, called sc, replaces a set AGGR ofconnected components of D0.A first desirable requirement is that the parts of D0 which do not refer to the componentsin AGGR remain identical in D1. Thus, in general, we want that:• COMPS1 is composed by sc and those components of COMPS0 that do not belong toAGGR;• the behavioral descriptions BD1 of D1 is composed by the behavioral descriptions(which are the same as in D0) of the components that do not belong to AGGR, and abehavioral description of sc (which must be provided);• the compositional description CD1 of D1 connects the components that do not belongto AGGR as they are connected in CD0 of D0;• OBS1 contains those observations in OBS0 that refer to components that do not belongto AGGR.Moreover, we want to define a relation between the representation of sc and therepresentation of the components in AGGR, which can be then exploited in diagnosis(e.g., knowing that sc is faulty in some way, we want to make hypotheses on the faultsin its subcomponents). We break down this requirement into three parts, which separatelyconsider the behavioral description, the structural description, and the observations.With respect to the behavioral description, we want each behavioral mode of sc tocorrespond to (more precisely, to be an abstraction of) a set of combinations of behavioralmodes of its subcomponents. This denotes the fact that, in real systems, we can knowwhat a supercomponent is doing by checking what the subcomponents are doing, and thencomposing their behaviors.(cid:10)x∈AGGR mi(x) (where each miThe fact that the components in AGGR are behaving in a certain way can be expressedby the formulais a proper mode of the behavioraldescription of x), i.e., a partial candidate for the components in AGGR. The set of allpossible combinations of behaviors for the components belonging to AGGR is the setCANDS(D0, AGGR). We then create a number of sets of partial candidates BM1, . . . , BMlthat partition the set CANDS(D0, AGGR), in such a way that each BMi correspondsto a behavioral mode for the supercomponent, i.e., the supercomponent is in a certainbehavioral mode only if its subcomponents behave consistently with at least one of thepartial candidates in the corresponding BMi set.From the structural point of view, since the supercomponent is supposed to replace thecomponents in AGGR, the ports of the supercomponent will be all and only the ports of thecomponents in AGGR that connect them to other components not in AGGR, i.e., the ports(cid:5)zsc of the subsystem whose compositional description isT (sc, (cid:5)zsc) ≡(cid:4)c∈AGGRTc(c, (cid:5)zc)156L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182where T will be the type of supercomponent sc. The ports that are internal to the subsystemwhich is aggregated will be then neglected in the abstraction.Finally, since the internal ports of the subsystem which is aggregated are not present inD1, observations concerning them will not be included in OBS1.3.2. Formal definitionsWe now formally express the above illustrated requirements using the semantic theoryof Nayak and Levy, i.e., using interpretation mappings to perform the aggregation at themodel level. We begin by defining a basic structural abstraction that aggregates one setof connected components into a supercomponent, and then consider the general case,where more aggregations can be performed. The following definition characterizes theinterpretation mappings for structural abstraction.Definition 5 (interpretation mapping for structural abstraction). Let D0 = (SD0, OBS0,COMPS0) be a diagnosis problem in language L0. Let SA = (cid:21)AGGR, BM1, . . . , BMk(cid:22) be atuple of non-empty sets such that• AGGR ⊆ COMPS0 and |AGGR| = k,• the sets BMi are a partition of the set CANDS(D0, AGGR).Let L1 be the language that will be used to define the abstract diagnosis problem. L1includes sc, the name of the supercomponent that will result from the aggregation of thecomponents in AGGR, Tsc, its type predicate, and m1, . . . , mk the predicates identifying itsbehavioral modes.Let πSA : Models(D0) → Interpretations(L1) be an interpretation mapping for whichπSA∀ ≡ (x1 = x1). π is an interpretation mapping for structural abstraction of D0 if:• Tsc(sc, (cid:5)zsc) ≡πSA∃w1, . . . , wn((cid:11)• mi(sc, (cid:5)z) ≡πSApc∈BMi• in any other case, πSA is the identity function.pc, i = 1, . . . , k,c∈AGGR Tc(c, (cid:5)zc)),(cid:10)The interpretation mapping πSA does not change the domains in which the systemoperates3 (e.g., real numbers for flows in the hydraulic domain, or binary quantities forelectronic systems).The first requirement states that the denotation of the type predicate of sc is therestriction, in the abstract universe, of the compositional description of the subsystemthat is aggregated. This establishes a link between a supercomponent and its underlyingstructure.The second requirement states that the denotation of a given behavioral mode of sc isthe restriction in the abstract universe of the disjunction of the partial candidates contained3 Changing them would require a behavioral abstraction.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182157in a corresponding BM set. This establishes a link between a set of partial candidates forthe subcomponents, and the behavioral mode of the supercomponent that abstracts them.Finally, the last requirement says that the denotation of any other object does not change,i.e., all the parts of D0 which are not involved in the aggregation remain as they are.As one can notice, such interpretation mapping “encodes” into its definition the setsAGGR, BM1, . . . , BMk which are the choices one makes when performing a structuralabstraction in a diagnosis problem.Given the definition above, we now define a basic structural abstraction of a diagnosisproblem.Definition 6 (structural abstraction of a diagnosis problem—basic case). Let D0 =(SD0, OBS0, COMPS0) and D1 = (SD1, OBS1, COMPS1) be two diagnosis problemsin language L0 and L1, respectively, and πSA : Models(D0) → Interpretations(L1) aninterpretation mapping for structural abstraction of D0. D1 is a basic structural abstractionof D0 with respect to πSA if• COMPS1 = (COMPS0 − AGGR) ∪ {sc},• CD1 = T (S, (cid:5)zs ) ≡ ∃z1, . . . , zn(Tsc(sc, (cid:5)zsc) ∧(cid:10)c /∈AGGR Tc(c, (cid:5)zc)) where the typedeclarations for the components not belonging to AGGR are as in CD0,(cid:12)• BD1 = (BD0 −• OBS1 contains only those observations in OBS0 that refer to ports that are present inc∈AGGR BDc) ∪ BDsc,D1.This definition specifies how the formulas of D1 should be constructed. D1 containssc and all the components of D0 which are not involved in the aggregation. The abstractcompositional description CD1 is obtained by simply removing from CD0 the predicatesthat refer to the components in AGGR, and introducing the predicate for sc. Those ports thatare internal to the subsystem AGGR are thus not included in D1. The abstract behavioraldescription BD1 contains the behavioral descriptions in BD0 of the components that arenot in AGGR, and the behavioral description of sc. The behavioral description of sc mustsatisfy the adopted interpretation mapping πSA, i.e., the relation between behavioral modesand BMi sets encoded in πSA. Finally, OBS1 is simply a subset of OBS0, omitting theobservations concerning ports that are not present in D1.Example 3. Consider the diagnosis problem illustrated in Example 1, and suppose we wantto build a structural abstraction by aggregating the components pm and p1 into a singlesupercomponent sc, i.e., AGGR = {pm, p1}. We now define the sets BM1, . . . , BMk whichwill correspond to the behavioral modes of sc. Since there are four behavioral modes forthe pump and two behavioral modes for the pipe, there are eight possible partial candidatesfor pm and p1, which we group in the following four sets:(cid:13)(cid:13)BM1 =BM2 =(cid:14),ok( pm) ∧ ok(p1)ok( pm) ∧ leak(p1), leak( pm) ∧ ok(p1), leak( pm) ∧ leak(p1),loF( pm) ∧ leak(p1), hiF( pm) ∧ leak(p1)(cid:14),158L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182(cid:13)(cid:13)BM3 =BM4 =loF( pm) ∧ ok(p1)hiF( pm) ∧ ok(p1)(cid:14),(cid:14)The first set represents a normal behavior; the second set represents all situations wherethere is a leak; the third and fourth sets correspond to situations where p1 is normal, andpm is delivering a wrong amount of flow (low or high, respectively). The four sets will beabstracted by the behavioral modes of the supercomponent called ok, leak, loF, and hiF,respectively. By Definition 5, we construct an interpretation mapping π in which:ok(sc) ≡π BM1,leak(sc) ≡π BM2,loF(sc) ≡π BM3,hiF(sc) ≡π BM4,(cid:9)(cid:8)sc, [t1, t3]TYPE≡π ∃t2(cid:1)pump( pm, [t1, t2]) ∧ pipe(p1, [t2, t3])(cid:2)In the resulting abstract diagnosis problem, COMPS = {sc, n1, p2, p3, v1, v2, p4, p5,n2, p6}; the behavioral description is the same given in Example 1, except that thebehavioral descriptions for pm and p1 are omitted, and the behavioral description for scis added. Given the adopted interpretation mapping, the type pump can be assigned to sc.Finally, the abstract compositional description is](cid:9)(cid:8)hcs, [t1, t13, sv1, sv2hydSystem(cid:1)pump(sc, [t1, t3)]) ∧twoOut(n1, [t3, t4, t5]) ∧ pipe(p2, [t4, t6]) ∧ pipe(p3, [t5, t7]) ∧valve(v1, [sv1, t6, t8]) ∧ valve(v2, [sv2, t7, t9]) ∧ pipe(p4, [t8, t10]) ∧pipe(p5, [t9, t11]) ∧ twoIn(n2, [t10, t11, t12]) ∧ pipe(p6, [t12, t13])≡ ∃t3, . . . , t12(cid:2)We now define the general case for structural abstraction, where more than onebasic structural abstractions are applied in order to obtain the desired level of structuralcomplexity.Definition 7 (structural abstraction—general case). Let D0 be a diagnosis problem, D1and D2 be (basic) structural abstractions of D0 and D1 with interpretation mappings πAand πB , respectively. Then, D2 is a structural abstraction of D0 with interpretation mappingπB ◦ πA.Typically, one might not want to directly abstract a system with many components into asystem with a few or even one component, but rather wants to have more than one differentstructural abstractions of the same system, for example to be able to choose a proper levelof detail for reasoning on the situation at hand.This is usually accomplished by building a multi-level hierarchy of structural abstrac-tions, i.e., a list of diagnosis problems, each one representing the same system at a dif-ferent level of detail, with the first one (i.e., the bottom level of the hierarchy) being themost detailed one, and every other (i.e., the other levels of the hierarchy) being a structuralabstraction of the previous one.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182159Definition 8 (multi-level hierarchy of structural abstractions). A multi-level hierarchy ofstructural abstractions H is an ordered set of q diagnosis problems {(SDi, OBSi, COMPSi)}with i = 0, . . . , q − 1, where for every j , with j = 0, . . . , q − 2, Dj +1 is a structural ab-straction of Dj with respect to some interpretation mapping πj .Example 4. A multi-level hierarchy of structural abstractions organized in six levels for thehcs is shown in Fig. 2. For each level, the figure illustrates the layout of the componentsand the ports, and highlights the components which have been aggregated.In particular, in level 1 we aggregated pipe p2 and valve v1 into valve sc1, and pipe p3and valve v2 into valve sc2. Both aggregations exploit a similar interpretation mapping: inthe case of sc1, the interpretation mapping π is such that (we omit the definitions of theBMi sets, which can be derived from the right-hand part of the following sentences):ok(sc1) ≡π ok(p2) ∧ ok(v1),leak(sc1) ≡π leak(p2) ∨ leak(v1),stuckO(sc1) ≡π ok(p2) ∧ stuckO(v1),stuckC(sc1) ≡π ok(p2) ∧ stuckC(v1)and TYPE(sc1, [sv1, t4, t8]) ≡π ∃t6[ pipe(p2, [t4, t6]) ∧ valve(v1, [t6, t8])]. In the case ofsc2, the interpretation mapping is the same, but the involved components are p3 and v2.In level 2, we aggregated valve sc1 and pipe p4 into valve sc3, and valve sc2 and pipe p5into valve sc4. Both aggregations are performed using an interpretation mapping analogousto the ones used in the previous level.In level 3, we aggregated valves sc3, sc4 and three-way nodes n1 and n2 into sc5, whichis a valve with two ports for setting the state (sc5 is closed if and only if both sv1 and sv2are set to closed), whose component type predicate is valve2.Its behavioral description is as follows:(cid:8)x, [s1, s2, in, out](cid:9)⊃(cid:1)valve2ok(x) ⊃ ((s1 = closed ∧ s2 = closed ∧in = out = 0) ∨ ((s1 = open ∨ s2 = open) ∧ in = out))(cid:1)(cid:9)(cid:2)(cid:8)x, [s1, s2, in, out](cid:8)x, [s1, s2, in, out](cid:9)valve2valve2⊃⊃(cid:1)leak(x) ⊃ in > outstuckO(x) ⊃,((s1 = closed ∧ s2 = closed) ∧ in = out > 0)(cid:9)(cid:8)x, [s1, s2, in, out]⊃valve2(cid:1)stuckC(x) ⊃ ((s1 = open ∨ s2 = open) ∧ in = out = 0)(cid:2),(cid:2),(cid:2)In level 4, we aggregated pm and p1 into pump sc6 (using an interpretation mappinganalogous to the one used in Example 3), and sc5 and p6 into sc7 (which is a valve withtwo ports for the state as sc5).Finally, in level 5 we aggregated sc6 and sc7 into sc8, which is basically a pump withtwo ports sv1 and sv2 for setting its state, and that delivers a constant flow equal to FK whenat least one port is set to open, and delivers no flow otherwise.160L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182Fig. 2. A hierarchy of structural abstractions of the hcs with 6 levels.3.3. Properties of structural abstractionsIn this section, we examine the properties of structural abstractions that are useful indiagnosis. In particular, given a diagnosis problem D0 and its structural abstraction D1,L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182161we first define the refinement of a candidate of D1 as any candidate of D0 which makesconsistent predictions at a more detailed level. Then, we prove that structural abstractionsare MI abstractions, and consequently have the properties illustrated in Section 2. Usingthese properties, we can prove that if a candidate of any structural abstraction of a diagnosisproblem D is not a diagnosis, then all its refinements are not diagnoses of D.Definition 9 (refinement of a candidate). Let D0, D1 be two diagnosis problems inlanguages L0 and L1, respectively, such that D1 is a structural abstraction of D0 withrespect to an interpretation mapping π . Let AGGR be the set of components of D0 that areaggregated, and let sc ∈ COMPS1 be the name of their supercomponent.Let C1 = P C ∧ msc(sc) be a candidate of D1, where PC is a partial candidate for thecomponents in the set COMPS1 − {sc}. A candidate C0 of D0 is called a refinement of C1if:(cid:10)• C0 =• msc(sc) ≡πc∈AGGR mc(c) ∧ PC,(cid:10)c∈AGGR mc(c) ∨ ∆, where ∆ is a (possibly empty) disjunction of partialcandidates for the components belonging to AGGR.The idea is that a candidate and its refinements contain the same behavioral modesassignments for the components that are not involved in the abstraction, while thebehavioral mode m for the supercomponent is substituted in the refinement with a partialcandidate abstracted by m itself. Note that by definition of structural abstraction everycandidate in an abstract diagnosis problem has at least one refinement (the BMi sets are apartition of the set of all partial candidates, and then each partial candidate is abstractedinto a behavioral mode for the supercomponent).The following theorem states that every structural abstraction is also a MI abstraction.Theorem 3. Let D0, D1 be two diagnosis problems in languages L0 and L1, respectively,such that D1 is a structural abstraction of D0 with respect to an interpretation mappingπ . Then, D1 <π D0, i.e., D1 is a MI abstraction of D0 with respect to π .Proof (outline). Consider any model of D0, which is an assignment I of values to the portsof D0 for which there is at least a candidate C0 of D0 such thatI |= SD0 ∧ OBS0 ∧ C0We must show that π(I ) is a model of D1, i.e., there is a candidate C1 of D1 such thatπ(I ) |= SD1 ∧ OBS1 ∧ C1(1)(2)By definition of structural abstraction, π(I ) and OBS1 are restrictions of I and OBS0,respectively, which assign a value only to the ports that are present in both D0 and D1.Thus,π(I ) |= SD0 ∧ OBS1 ∧ C0(3)One can substitute SD0 with SD1 in (3) because the denotation of CD0 and CD1, BD0and BD1 are the same in the considered restriction of I . Then, we take C1 such that C0162L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182is one of its refinements. The partial candidate contained in C1 that assigns a mode to thecomponents that are shared between D0 and D1 has π(I ) as a model (again, the restrictiondoes not involve the components, observations, etc. that are not aggregated). Finally, bydefinition of refinement, π(I ) is a model also of the partial candidate contained in C1 thatassigns a mode to the aggregations of components in D0. ✷Since structural abstractions are MI, we can prove the following relation between anycandidate of the more abstract diagnosis problem and its refinements:Theorem 4. Let D0, D1 be two diagnosis problems in languages L0 and L1, respectively,such that D1 is a structural abstraction of D0 with respect to the interpretation mappingπ . Let C1 be a candidate of D1 which is not a diagnosis. Then, any refinement C0 of C1 isnot a diagnosis for D0.Proof. Since C1 is not a diagnosis, then C1 ∧ SD1 ∧ OBS1 is inconsistent. Moreover, D1is a structural abstraction of D0, thus SD1 <π SD0 and OBS1 <π OBS0. Finally, C1 <π C0by hypothesis. By compositionality of MI abstractions we can writeC1 ∧ SD1 ∧ OBS1 <π C0 ∧ SD0 ∧ OBS0Since C1 ∧ SD1 ∧ OBS1 is inconsistent, then for property 1 also C0 ∧ SD0 ∧ OBS0 isinconsistent, i.e., C0 is not a diagnosis. ✷This theorem allows one to exclude from the possible solutions of a diagnosis problemD every refinement of an impossible diagnosis. The advantage is that, by eliminating acandidate in a (potentially simpler) abstract diagnosis problem, one can possibly rule outmany candidates in the original diagnosis problem.On the other hand, if we find that an abstract candidate is a diagnosis, we cannotguarantee that its refinements are diagnoses too, as shown by the following example.Example 5. Consider the diagnosis problem for the hcs given in Example 1. Supposethat there is only one observations specifying that flow at port t2 is greater than zero, butbelow FK . In the structural abstraction given in Example 3, port t2 is not present, thus thecandidateok(sc) ∧ ok(n1) ∧ ok(p2) ∧ ok(p3) ∧ ok(v1) ∧ ok(v2) ∧ ok(p4) ∧ ok(p5) ∧ok(n2) ∧ ok(p6)is a diagnosis for the abstract diagnosis problem, while its refinementok( pm) ∧ ok(p1) ∧ ok(n1) ∧ ok(p2) ∧ ok(p3) ∧ ok(v1) ∧ ok(v2) ∧ ok(p4) ∧ok(p5) ∧ ok(n2) ∧ ok(p6)is not a diagnosis, since the considered situation can only be explained by pm delivering alow amount of flow.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–1821633.4. Some remarks on the aggregation of components(cid:15)In general, when aggregating a set of components c1, . . . , ck into a component sc, thenumber of behavioral modes for sc can be (at worst) N =i=1,...,k Mi , where Mi is thenumber of behavioral modes for component ci . The motivation is that, in principle, eachcombination of behavioral modes for the subcomponents could be represented as a distinctbehavioral mode for the supercomponent. In this case, the complexity reduction we wantto obtain with the abstraction vanishes because of the number of supercomponent modesthat have to be considered: since N is exactly the number of partial candidates involvingthe subcomponents, the number of candidates remains equal to the more detailed diagnosisproblem.Therefore, one needs to find suitable aggregations of components that are able to reducethe complexity of reasoning. In some cases, those aggregations are easily found, becausesome combinations of behavioral modes for the subcomponents will not be distinguishablein terms of values at the supercomponent ports, and thus they will be naturally combinedinto the same behavioral mode. In Example 3, the combinations of subcomponent modeshiflow( pm) ∧ leak(p1),ok( pm) ∧ leak(p1)may predict different values for port t3. In the first case, flow at t3 may be greaterthan FK , while in the second case it must be less than FK . However, both sentencespredict that input flow of sc is greater than its output flow, and thus both of them canbe abstracted by a leak mode. However, easy aggregations may not be possible in somesystems: in this case, a possible solution is to forget some combination of modes in theabstraction. This solution can be adopted, for example, when a combination of modesyields a very complex behavior. In such situations, the structural abstraction is not MI(each model of the forgotten combination of behaviors has no corresponding model in themore abstract diagnosis problem). However, it can be viewed as a structural abstractionunder the simplifying assumption that the forgotten combination of modes cannot occur.This has to be taken into account by diagnostic reasoning, which has to consider two cases:one in which the simplifying assumption holds (where the abstract diagnosis problem canbe used), and one in which the simplifying assumption does not hold (where only the moredetailed diagnosis problem can be used). The union of the solutions of the two cases is thesolution of the original diagnosis problem.3.5. Related workFormalizations of structural abstraction have been proposed by Struss [19], Mozetic[14], and more recently, by Autio and Reiter [1]. Genesereth [10] was probably the firstto advocate the use of structural abstraction as a way to reduce the computational costof model-based diagnosis, and to recognize also that loss of information can lead toundiagnosability of the abstract representation.164L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182In [14], structural abstraction is addressed as follows. The representation of a systemis constituted by a mapping m between any state of the system (normal or faulty) tocorresponding input-output observations:4m : x → ywhere x is a state of the system (e.g., a normal state) and y is a tuple of input-outputobservations.The refinement/abstraction operators allow one to start from a mapping m representingthe system and to derive a more abstract mapping m(cid:27) representing the same system withless detail. To relate the two representations, one needs a function h that maps betweenstates in m and states in m(cid:27), and between input-output values in m and m(cid:27). That is, h(x(cid:27), x)maps between a state x of m and a state x(cid:27) of m(cid:27) (and vice versa), and the same functionh(y(cid:27), y) maps between input-output values y of m and input-output values y(cid:27) of m(cid:27) (andvice versa).When the system is composed by components c1, . . . , cn, the representation can bedefined by a composition of mappings in the following way:m(x, y) ← c1(x1, z1), . . . , cn(xn, zn)where c1, . . . , cn are the mappings that define the relation between the states of thecomponents and their input-output observations. One can aggregate some components,e.g., c1, . . . , ck in the representation into a supercomponent c and obtain the followingsimpler system representation:m(cid:27)(x(cid:27), y(cid:27)) ← c(xc, zc), ck+1(xk+1, zk+1), . . . , cn(xn, zn)By repeated applications of abstraction operators, one can obtain a multi-level hierarchy ofrepresentations of the system, each one at a different level of detail.To ensure correctness in diagnostic reasoning, it must be guaranteed that the diagnoseswhich are impossible at an abstract level are impossible at a more detailed level as well.This requirement is formulated by Mozetic in terms of a global consistency condition thatmust be satisfied among the different levels: given two adjacent levels of the hierarchy (mmore detailed, and m(cid:27) more abstract), the consistency condition is expressed as:(cid:8)(cid:9)∀x, ym(x, y) ∧1 h(x(cid:27)⇒ ∃x(cid:27), y(cid:27) m(cid:27)(x(cid:27), y(cid:27)) ∧ h(x(cid:27), x) ∧ h(y(cid:27), y)1, x)∃x(cid:27)(4)which guarantees that (see [14] for a detailed discussion):• given a more detailed mapping m, a state x with an abstraction x(cid:27) cannot be mappedto input-output values y which do not have a corresponding abstract y(cid:27);• if x maps to y (i.e., in state x the possible input-outputs are y), and we haveabstractions x(cid:27) and y(cid:27) for x and y respectively, then x(cid:27) must map to y(cid:27).4 We repeat here the original notation of [14]. Note that letters (such as m and c) may have different meaningsfrom those adopted in the rest of this paper.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182165Our definition of structural abstraction (as shown by Theorem 4) satisfies theconsistency condition. Our definition is slightly stronger in the sense that every partof the detailed representation must be abstracted, while Mozetic’s definition allows forincompleteness in the abstraction process (e.g., some faulty modes could not be abstractedat all). However, as discussed in the previous section, we introduce that possibility by usingsimplifying assumptions.As a consequence, the consistency condition in our approach needs not to be checkedfor each derived abstract level, but is enforced during the abstraction process (i.e., theinterpretation mapping used by each aggregation must satisfy Definition 5). In otherwords, our definition clearly states the rules that each aggregation has to follow in orderto guarantee the consistency condition, while in Mozetic’s formalization the consistencycondition has to be verified globally for each level.In [19], structural abstraction is viewed as one of the possible model relations calledrefinement. Refinement defines structural abstraction for diagnosis problems as follows.Suppose that formula ok(c) represents the correct behavioral mode of a supercomponentsc, and that formulae ok(c1), . . . , ok(ck) represent the correct behavioral modes ofits subcomponents c1, . . . , ck, respectively. Then, ok(sc) (the theory describing thesupercomponent’s behavior) is a structural abstraction of ok(c1), . . . , ok(ck) (the theoriesdescribing the subcomponents’ behavior) ifok(c1) ∧ · · · ∧ ok(ck) ⇒ ok(sc),which expresses the assumption that “If all parts of a system work correctly, thenso does the entire system”. This formalization does not deal with components withmultiple behavioral modes, so it is applicable only to some diagnosis problems. Moreover,the formalization characterizes only the behavioral descriptions of the supercomponent,without dealing at all with the representational changes in structure that are brought bystructural abstraction. Our formalization can be seen as an extension of the one proposedby Struss: if one represents only the normal behavior of components, the requirement onour abstraction mapping becomesok(sc) ≡π(cid:4)ok(ci)ci ∈AGGRwhich is the same definition of structural abstraction given by Struss, but formalized usingthe semantic theory of abstraction.In the approach proposed by [1], a hierarchical representation is composed by multiplesystem descriptions, each one at a different level of structural detail, and a componenthierarchy, which is represented as a tree with nodes corresponding to components atany level of detail. More precisely, the leaves are the components belonging to the mostdetailed description, while interior nodes are abstract components obtained by successiveaggregations starting from the primitive components. The component hierarchy representsthe structural abstractions that have been performed in order to build the hierarchicalrepresentation. Autio and Reiter [1] do not consider components with multiple behavioralmodes, but diagnostic theories where the behavioral description consists only in the correctbehavior of components.166L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182Fig. 3. Layout of a circuit with two inverters.A system (SD(cid:27), COMPS(cid:27)) is defined to be a structural abstraction of a system(SD, COMPS) if for every component c in COMPS(cid:27) there exists a system (SDc, COMPSc)such that its components are components of COMPS, and these subsystems are properlyconnected to form the compositional description of (SD, COMPS). It is required that thestructural abstraction of a set of subcomponents c1, . . . , cm into their supercomponent cmust satisfy the following assumptions:• if a (super)component c is abnormal, then at least one of its subcomponents c1, . . . , cmmust be abnormal as well, i.e., ¬ok(c) ⇒ ¬ok(c1) ∨ · · · ∨ ¬ok(cm),• if a (super)component is normal, then all its subcomponents are normal as well, i.e.,ok(c) ⇒ ok(c1) ∧ · · · ∧ ok(cm).These assumptions are referred to by Autio and Reiter as abnormality axioms. Thefirst abnormality axiom is equivalent to the definition by Struss discussed above. Thesecond abnormality axiom poses serious problems in situations such as fault maskingor fault compensation. For example, consider the well-known logic circuit shown inFig. 3, composed by two inverters I1 and I2. Suppose that the measurements reportA = 1, B = 1, C = 1, indicating that both inverters are faulty (e.g., they are both stuckat 1). We aggregate both inverters into a single component I with input A and output C,as shown by the figure. By looking only at I , we can consider it normal, because the twoassociated observations are not symptoms (this happens because the two faults in invertersI1 and I2 mask each other). By applying the second abnormality axiom, we conclude thatboth I1 and I2 are normal, which is not true. Thus, when fault masking occurs, the secondabnormality axiom can result in wrong conclusions.We critique the second abnormality axiom also from a common-sense point of view. Itsays that “if a system works correctly, then so do all its parts”: an expert would use thisassumption only to focus reasoning first on more evident faults, but then would remove itto consider more subtle faults.Finally, Autio and Reiter prove that structural abstraction in their formalization is sound,in the sense that for every diagnosis D involving a supercomponent c, there is at least acorresponding diagnosis where c is substituted by its subcomponents. They also prove thatstructural abstraction is not complete, in the sense that there is the possibility of rulingout valid diagnoses when reasoning at abstract levels (this is shown also in the circuitexample). This is a serious limitation in reasoning, because it means that one cannotexclude impossible diagnoses by reasoning at an abstract level, and thus, in order to find allpossible diagnoses, one has to reason only with the most detailed representation available.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–1821674. Reasoning with structural abstractionIn this section, we will examine the problem of diagnostic reasoning with structuralabstraction. First, we will consider the well-known Mozetic’s approach [14] to hierarchicaldiagnosis and apply it to multi-level hierarchies of structural abstractions. Then, wewill analyze why,the efficiency of Mozetic’s approach is not asgood as one would expect. In general, this originates from the fact that the samehierarchical representation is used for a system, regardless of the currently availableobservations. Finally, we will propose two novel approaches that, in the case of structuralabstraction, overcome this problem, and we will show the obtained improvements usingthe experimental evaluation we performed.in many cases,4.1. A formalization of Mozetic’s algorithm for multi-level hierarchies of structuralabstractionsIn the following, we provide a procedural formulation of Mozetic’s approach forconsistency-based diagnosis problems, clearly separating the main activities that have tobe performed, namely abstraction of observations and fault diagnosis. Our formalizationof Mozetic’s algorithm will be called Hierarchical Diagnosis (HD) in the remaining partof the paper.The key idea of HD is to apply (in principle) any plain, one-level diagnostic strategy to amulti-level hierarchical representation. The strategy is applied one level at a time, startingfrom the most abstract possible level and then proceeding to lower ones, and the diagnosesthat are found at each level are used to reduce the number of possible diagnoses at lowerlevels.In our formalization, the input given to HD is a multi-level hierarchy of q diagnosisproblems Di = {(SDi, OBSi, COMPSi)}, i = 0, . . . , q − 1. For simplicity, input observa-tions are given at the most detailed level.5We assume that two functions, Abstract and Detailed, which depend on the abstractionsthat have been employed to build the multi-level hierarchy, are available:• Abstract : OBSj → OBSj +1, j = 0, . . . , q − 2, which corresponds to Mozetic’sabstract predicate, mapping the observations at level j to observations at level j + 1,and• Detailed : Cj +1 → Cj , j = 0, . . . , q − 2, which corresponds to Mozetic’s detailedpredicate, mapping a candidate at level j + 1 into its refinements at level j .We formalize HD in Fig. 4, dividing it into two separate procedures. The firstone (Abstract-Observations) associates the available observations to the properabstract levels of the hierarchical representation. Then, the second one (Top-Down-diagnosis) performs the diagnosis.5 Giving observations at any level of the hierarchy would be straightforward: one need only to slightly modifythe Abstract-Observations procedure in Fig. 4 such that the mapping of observations is performed bothupwards and downwards.168L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182Procedure Abstract-Observationsl ← 0;q ← number of levels of the hierarchical representation;WHILE l < q − 1 ∧ OBSl (cid:20)= ∅ DOOBSl+1 ← Abstract(OBSl );l ← l + 1;ENDWHILE;IF OBSl = ∅ THEN CLO ← l − 1;Procedure Top-Down-Diagnosisl ← CLO;Candl ← all candidates at level l;WHILE l (cid:1) 0 DODiagl ← Verify(Dl, Candl );\∗ CandNAl ← all candidates at level l which have no abstraction;IF l < CLO THENDiagl ← Diagl ∪ Verify(Dl, CandNAl); ∗\IF l > 0 THEN Candl−1 ← Detailed(Diagl );l ← l − 1;ENDWHILE;HIERARCHICAL DIAGNOSISAbstract-Observations;Top-down-Diagnosis.Fig. 4. The HD algorithm (i.e., Mozetic’s algorithm for multi-level hierarchies of consistency-based diagnosisproblems). Statements in comments have to be executed only when using structural abstractions with simplifyingassumptions.In particular, Abstract-Observations takes as input the initially availableobservations OBS0 (which refer to level 0 of the hierarchical representation), and, byapplying the Abstract function, determines the available observations (if any) for level 1.The same function is then repeatedly applied to derive the observations for the other levels,until a level with no available observations is reached or all levels have been considered.The number of the Coarsest Level with Observations (hereinafter, CLO) is stored intovariable CLO. Levels from CLO to 0 are then considered by procedure Top-down-Diagnosis in the following way:• First, all the diagnoses that are consistent with the observations at the current levelare determined by using the function Verify (corresponding to the verify predicate inMozetic’s original formulation). Verify takes the diagnosis problem Dl at the currentlevel, and a set Candl which contains the possible diagnoses at the current level (forlevel CLO, all candidates are considered), and returns those elements of Candl whichare diagnoses, i.e., every C ∈ Candl such that SDl ∪ OBSl ∪ C is consistent.6 After theVerify function has been applied, Diagl stores the diagnoses at the current level.6 It must be noted that no assumption is made on the implementation of this function (e.g., it can exploit agenerate-and-test method, a GDE-like reasoner [7,9], or other model-based diagnosis techniques).L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182169• Second, if l is greater than zero (i.e., current the level is not the most detailed one), thealgorithm applies the function Detailed to the obtained diagnoses in order to derivetheir more detailed versions at level l − 1, which will be the possible diagnoses at levell − 1.After level 0 has been considered, the Top-Down-Diagnosis procedure ends, and thefinal diagnoses are found in variable Diag0.If some candidates of the currently considered level have no abstraction at (previouslyconsidered) more abstract levels (i.e., we are using some simplifying assumptions), thenthey must be considered at the current level for the first time. In such case, one has toexecute also the statements provided in comments in Fig. 4: in that way, the algorithmapplies a second time the Verify procedure, but considering only candidates with noabstraction (stored in the variable CandNAl) as possible diagnoses. All found diagnosesare then detailed into candidates for the next level.The correctness and completeness of the algorithm rely on the consistency conditionsdiscussed in the previous section. Since structural abstraction satisfies them, we can applyHD to any multi-level hierarchy of structural abstractions without having to check anyconsistency condition.By taking advantage of the smaller search space at the more abstract levels, in manycases HD is able to outperform diagnostic reasoning applied only to the most detailedlevel. From a theoretical point of view, the speed up that can be achieved in the ideal caseis exponential [14]. Experimental testing performed by Mozetic reported, in one medicalexample involving a four-level qualitative representation of the heart, a speed up by afactor of 20 over one-level diagnosis. Our experimental results with HD confirm similarimprovements in the average case (as illustrated in Section 4.4).4.2. Some remarks on the efficiency of HDIn this section, we use two examples to show that the efficiency of HD depends on boththe chosen multi-level hierarchical representation and the actual observations that are givenas input.Example 6. Using the six-level hierarchical representation of the hcs illustrated in Example4 and Fig. 2, we suppose that the following observation is available: flow at port t7 hasa value that is different from expected. Using the chosen multi-level representation, thisobservation cannot be abstracted to level 1, because t7 is not present at that level. Hence,at the end of the execution of the Abstract-Observations procedure, CLO = 0.Since diagnosis is started at level 0, the efficiency of HD is similar (slightly worse, dueto the extra reasoning activities of the Abstract-Observations procedure) to directdiagnosis of the most detailed representation of the system.Note that by using a different multi-level representation, we can obtain better resultswith HD in Example 6. Consider an alternative six-level representation of the hcs whichdiffers from the one illustrated in Fig. 2 only in levels 1 and 2: in level 1, sc2 is obtainedby aggregating v2 and p5 into sc2 (instead of p3 and v2), and in level 2, sc4 is obtained by170L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182aggregating p3 and sc2 (instead of sc2 and p5). In this case, the observation of Example6 can be abstracted up to level 1, and diagnosis would start from a more abstract problem(CLO = 1).Example 7. Using the six-level hierarchical representation of the hcs illustrated in Example4 and Fig. 2, we suppose that the following observations are available: flow at the port= closed). Using the chosent6 is a > 0, and valve v1 is expected to be closed (i.e., sv1multi-level representation, the observation on t6 cannot be abstracted to level 1, but theobservation on sv1 can be abstracted up to level 5. Hence, CLO is equal to 5. Unfortunately,at this level, the observation on sv1 allows one to exclude only those candidates in whichv1 is stuck at open. Then, reasoning at levels 4, 3, 2, and 1 does not allow to exclude othercandidates. At each of these levels, diagnostic reasoning has to consider a lot of candidateswithout useful results (and thus using the hierarchical algorithm is counterproductive interms of efficiency).More generally, the situations that can heavily limit the effectiveness of HD are thefollowing:• the algorithm cannot use at all some abstract levels (where potentially a lot ofcandidates could be excluded with little effort), since no observations are availablefor them (as Example 6 shows);• only a few of the given observations are available at those abstract levels wherediagnosis can be performed. In this case, diagnosing those levels could be scarcelyeffective in reducing the candidate space, or even be counterproductive, resulting in aloss of efficiency (as Example 7 shows).With structural abstraction, when a component is aggregated all the observations thatrefer only to it become unavailable at the upper levels. Therefore, to avoid the abovementioned situations, one should build the multi-level representation in such a way thatthe relevant diagnostic information (i.e., current observations) is kept as much as possibleavailable at more abstract levels, i.e., diagnosability at abstract levels is preserved. Inprinciple, this implies that for every set of observable ports, one should build a differentmulti-level representation to guarantee efficient hierarchical reasoning.However, building a new hierarchical representation by hand for each possiblediagnostic scenario cannot be a viable approach: multi-level system representations areoften hard to build, and the only one that could be possibly readily available is the onecoming from system design. Moreover, general automatic methods for building multi-levelrepresentations are not available, or are heavily dependent on a particular system or domain(e.g., [3,13]).In a system where the position of measurement sensors is known and does not change,one can think about building only one multi-level representation by using sensors positionto guide the abstraction process, i.e., choosing the aggregations in such a way that the mostabstract levels have always (or at least often) some observation available. However, thissolution: (i) is not applicable to every system and (ii) whenever some sensors do not returnmeasurements (e.g., because they are broken) the chosen hierarchical representation mayL. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182171not be effective anymore, because some abstract levels may not have sufficient observationsavailable.In our research, we do not aim at building the optimal multi-level hierarchy for a givenset of observations, but instead consider any chosen multi-level hierarchical representation,and aim at preserving diagnosability at abstract levels in those situations where the givenobservations do not allow HD to be effective.4.3. Extensions to Mozetic’s approachIn the following, we propose two extensions of HD that tackle the problems highlightedin the previous section.More specifically, the extensions are called REARRANGE (presented in Section 4.3.2)and BOTTOM-UP (presented in Section 4.3.3). The idea behind both extensions is totailor an existing multi-level hierarchical representation in order to obtain a more efficientdiagnosis with the current observations (to this purpose, each extension uses a differentstrategy).Our approach does not exploit any specific system or domain knowledge, and thus it isnot limited to a particular domain or system. Moreover, the two extensions can be easilycombined together in order to sum up their respective advantages.Both extensions exploit an additional data structure, called structural tree, which ispresented in the next section.4.3.1. The structural treeWe associate any multi-level hierarchical representation (built with structural abstrac-tions) H to a data structure ST(H), called a structural tree. In the structural tree, each noderepresents a component of some level of H , and the sons of the node correspond to the sub-components. In the following, given a tree T , we use the function root(T ) with its obviousmeaning; for each node n ∈ T , the function sons(n) returns the set of its sons.Given a multi-level hierarchical representation of a diagnostic problem H = {(SDi,OBSi, COMPSi)}, i = 0, . . . , q − 1, the structural tree ST(H ) is built as follows:• first, for each component c ∈ COMPS0, a leaf c is created;• then, for each aggregation of AGGR ⊆ COMPSi into sc ∈ COMPSi+1 such that eachc ∈ AGGR has already been added as a node of the tree, a node sc is created such thatsons(sc) = AGGR.The root of ST(H ) is associated with the component that represents the whole system, i.e.,root(ST(H )) = c ∈ COMPSq−1.In general, one might not have a most abstract level with only one componentrepresenting the whole system. In this case, the derivation procedure outlined above wouldnot derive a tree but a forest. In the remaining part of the paper, we assume that the mostabstract level always contains just one component. However, multi-level hierarchies wherethis is not true can be still represented by a structural tree by simply adding an additionalabstract level with just one component (representing the whole system) having just one172L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182behavioral mode which abstracts all the candidates of the original most abstract level.Obviously, the newly added level would not bring any efficiency advantage.Since each node c ∈ ST(H ) is a component c ∈ COMPSi for some i = 1, . . . , q − 1,we associate to it the theory SDc ⊆ SDi and the observations OBSc ⊆ OBSi (with OBScpossibly empty).The ST of a multi-level hierarchical representation H can be used to derive new levels(that are not in H ) using the same aggregations that were employed in H . The followingproposition defines the conditions under which a set of nodes in the ST characterizes adiagnosis problem for the considered system.Proposition 5. Given a multi-level hierarchical representation H , any set S of nodesbelonging to ST(H ) such that:• for each node in the set, no descendants or ancestors are included in the set,• the descendants of all nodes in the set include all the leavescharacterizes a diagnosis problem for the considered system, in which COMPS = S.The resulting diagnosis problem can be easily built by retrieving from H all the nec-essary behavioral descriptions and observations, and by deriving a proper compositionaldescription by simple conjunction of the type predicates for the chosen components (theneeded instances of the type predicates are taken from the compositional descriptions ofthe diagnosis problems in H ).Example 8. Consider the multi-level hierarchical representation of the hcs shown in Fig. 2.Fig. 5 shows its structural tree. The diagnosis problem with components sc6, n1, sc3, sc2,p5, n2, and p6 is not in the multi-level representation, but is a diagnosis problem for thehcs.Fig. 5. Structural tree for the hcs derived from the multi-level hierarchical representation of Fig. 2.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–1821734.3.2. The REARRANGE extension to Mozetic’s approachThe extension presented in this section dynamically determines a multi-level hierarchi-cal representation suited to diagnose the specific situation described by the current obser-vations. The derived multi-level hierarchical representation will be built by rearrangingthe levels of a given hierarchical representation H by reasoning with the correspondingST(H ) and the available observations.The idea is to improve HD when it is not able to fully exploit the hierarchicalrepresentation, by providing a new, tailored hierarchical representation consisting of: (i)all levels of the original hierarchical representation which contain observations (i.e., thelevels considered by HD), and (ii) additional, more abstract levels which are not present inthe original hierarchy, and have the same observations of the coarsest level considered byHD.We now show with an example how these additional levels can be built with little effort.Consider the scenario presented in Example 6, where diagnosis is started at level 0 (whichcontains 11 components). An hypothetical diagnosis problem (let us call it Better) withcomponents sc6, n1, sc3, p3, v2, n2, p5, and p6 is more abstract than level 0 and has thesame observations (i.e., flow at t7 is not as expected). The search space of Better is muchsmaller: the diagnosis problem at level 0 has 4096 possible candidates, while Better has512 possible candidates.HD cannot start from Better because this diagnosis problem is not available in the givenhierarchical representation: the only level with observations is level 0.We can derive Better by properly selecting nodes in the structural tree of Fig. 5. Thestructural tree highlights indeed the aggregations used in the hierarchical representation,regardless of the order in which they were performed. One can derive Better by selectinga set of nodes in the structural tree which: (i) represent the full system, (ii) keep the sameobservations that are present at the level where HD starts, (iii) are as abstract as possible.This can be done by starting with a set of nodes which corresponds to HD starting level,and then try to substitute some of them with their parent provided that no observationis lost. Each possible substitution derives a new level (i.e., all requirements imposed byProposition 5 are satisfied), from which the process of searching for more abstract levelscan be repeated.We implemented this strategy as an extension to HD, which we call REARRANGE.More specifically, the additional activity of building new levels is performed between theAbstract-Observations and the Top-Down-Diagnosis procedures, as shownin Fig. 6.The added Rearrange procedure operates as follows:• each observation available at level CLO (which is the same calculated by HD) isassociated to the corresponding nodes in ST(H ) (obtaining the OBSn sets);• then, possible new levels, which are more abstract than CLO, are added to the levels ofH with available observations, deriving a new multi-level hierarchical representationH (cid:27). These new levels are built by:(1) considering the components of the current level (which initially is CLO), whichare assigned to the set NodesToCheck;174L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182Procedure HIERARCHICAL-DIAGNOSISAbstract-Observations;Rearrange;Top-down-diagnosis.Procedure RearrangeIF CLO < g − 1 THENH (cid:27) ← all levels of H from 0 to CLO;FOR each node n of ST(H ) referred by OBSCLOOBSn ← {a = v|a = v ∈ OBSCLO ∧ a is a port of n};NodesToCheck ← COMPSCLO;WHILE NodesToCheck (cid:20)= ∅ DOn ← first(NodesToCheck);c ← father(n);IF sons(c) ⊆ COMPSCLO ∧ (CLO ← CLO + 1;COMPSCLO = (COMPSCLO−1 − sons(c)) ∪ {c};ADD a new level numbered CLO with components COMPSCLO to H (cid:27)NodesToCheck ← COMPSCLO;s∈sons(c) OBSs) = OBSc THEN(cid:12);ELSENodesToCheck ← NodesToCheck − sons(c);ENDIF;ENDWHILE;ENDIF.Fig. 6. The REARRANGE extension to HD.(2) finding a subset of NodesToCheck that contains all and only the sons of a nodec in ST(H ) such that the observations associated to the sons are exactly theobservations associated to c (i.e., by substituting the sons with their father wedo not lose any observation);(3) if such set of components does not exist, the algorithm stops; otherwise, we addto H (cid:27) a new top level obtained from the current level by substituting the sons ofc with c itself. The newly added level is a diagnosis problem for the consideredsystem, since it satisfies the requirements of Proposition 5. Since it is required thatno observation is lost in the substitution, the newly derived level contains exactlythe same observations as the starting one. Then, we go to point 2 considering thenewly added level as the current one.After the execution of the Rearrange procedure, the most abstract level derived byit is the new top level from which diagnosis is started. Note that when Abstract-Observations is already able to reach the most abstractthen theRearrange procedure does nothing, and the whole reasoning process is identical to HD.The computational cost of the Rearrange procedure is polynomial in the number ofnodes of the structural tree: for each newly generated level, at worst all the nodes in thelevel are examined once, and each examination consists of testing whether the node hasin H ,levelL. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182175Table 2Levels employed by HD (HD) and REARRANGE (R) in Example 9. The last two columns indicate whether thecorresponding approach is able or not to exploit the level for top-down diagnosisLevelComponents3210sc6, n1, sc3, p3, v2, p5, n2, p6 (8)pm, p1, n1, sc3, p3, v2, p5, n2, p6 (9)pm, p1, n1, p3, sc1, v2, p4, p5, n2, p6 (10)pm, p1, n1, p3, p2, v1, v2, p4, p5, n2, p6 (11)Candidates512102420484096HDnononoyesRyesyesyesyesa father, whether the observations associated to the father are the same of its sons, andwhether all its sons belong to the current level.We now reconsider the previously illustrated examples, and show how the RE-ARRANGE extension behaves on them.Example 9. Considering the observations given for the hcs in Example 6 (i.e., flow atport t7 is not as expected), the CLO in the original multi-level hierarchy is level 0. TheRearrange procedure is able to derive first a level 1 with components pm, p1, n1, sc1, p3,v2, p4, p5, n2, and p6 (p2 and v1 can be aggregated into sc1 without losing observations).Then, level 2 is derived with components pm, p1, n1, sc3, p3, v2, p5, n2, and p6 (sc1 andp4 can be aggregated into sc3 without losing observations). Finally, the most abstract level(from which diagnosis will start) is derived with components sc6, n1, sc3, p3, v2, p5, n2and p6 (pm and p1 can be aggregated into sc6 without losing observations). The numberof candidates associated to the above candidates levels are shown in Table 2.Example 10. Considering the observations given for the hcs in Example 7 (i.e., flow at portt6 is a > 0, and valve v1 is expected to be closed), since the abstractions of observationsproceeds up to level 5, the Rearrange procedure is not executed (because CLO is themost abstract level of the hierarchy), and the diagnostic reasoning proceeds exactly as inHD.4.3.3. The BOTTOM-UP extension to Mozetic’s approachIn this section, we propose a different strategy that also uses the available observations toreduce the complexity of hierarchical diagnosis. This second extension (called BOTTOM-UP) tries to exploit at a given level the observations that are only available at more detailedlevels, and were forgotten in the abstraction process. The additional diagnostic informationderived is used to eliminate impossible diagnoses, thus reducing the computational cost ofreasoning at more detailed levels.We now show with an example how the strategy works. Consider the scenario presentedin Example 7, where diagnosis is started by HD at level 5. The only information available= closed, which only allows one to eliminate all candidatesat levels 5, 4, 3, 2, and 1 is sv1= open. However, a stuckO fault in valve v1 is easily detectable at level 0in which sv1(since flow at the input of the valve is greater than zero), by running a diagnose procedurethat separately considers only the observed components (i.e., p2 and v1). Thus, all thebehavioral modes of valve v1, with the exception of stuckO, can be removed from itsbehavioral description.176L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182Moreover, since the ok mode is excluded from v1, we can also remove all the behavioralmodes that are abstractions of ok in all its supercomponents. In this way, we can excludealso ok(sc1), ok(sc3), ok(sc5), ok(sc7), ok(sc8). As a result, when reasoning starts at level5, we already know that the system cannot be normal.The BOTTOM-UP strategy extends HD by executing, after the abstraction of observa-tions, a reasoning activity that considers all observed nodes in the ST, and removes fromthe behavioral representation associated to the node every mode which is not consistentwith the associated observations.Moreover, since the additional reasoning activity is performed using the ST in a bottom-up fashion, the diagnostic conclusions reached for the subcomponents can be reused whenconsidering a node: in particular, since each mode m of a component c abstracts a set ofpartial candidates BM for the subcomponents of c, if all partial candidates in BM havebeen previously removed we can remove also m (even if the observations associated to cin isolation would not allow to do it).The BOTTOM-UP extension to HD is illustrated in Fig. 7. The new activities performedby the Bottom-up procedure are:(1) building of a list (recorded into the variable NodesToCheck) of the observed nodes inthe structural tree, and all their ancestors; these nodes are then visited in increasinglevel order (i.e., when a node is visited, all its sons have been already visited);(1) for each node c in the list, we consider each mode m of its behavioral description BDc,and try to eliminate m in the following way:• first, we check if m is actually an abstraction of previously eliminated partialcandidates for the subcomponents of c: we determine with the function DetailedProcedure HIERARCHICAL-DIAGNOSISAbstract-Observations;Bottom-up;Top-Down-Diagnosis.Procedure Bottom-upIF CLO (cid:20)= 0 THENNodesToCheck ← ∅;FOR each node n of ST(H ) referred in OBS0NodesToCheck ← NodesToCheck ∪ {n} ∪ ancestors(n);order NodesToCheck by increasing level;WHILE NodesToCheck (cid:20)= ∅ DOn ← first(NodesToCheck);FOR each mode m of nIF (Detailed(m(n)) = ∅) ∨(OBSn (cid:20)= ∅ ∧ Verify((BDn, OBSn, {n}), {m(n)}) = ∅) THENremove m from BDn;remove n from NodesToCheck;ENDWHILE;ENDIF.Fig. 7. The BOTTOM-UP extension to Mozetic’s algorithm.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182177(defined previously) the partial candidates abstracted by m, and if the result isthe empty set (because previous reasoning on the sons of c eliminated all thosecandidates), then we remove m from the behavioral description of c;• if Detailed(m(c)) is not empty, then using the function Verify (defined previously),we check the consistency of candidate m(c) with the observations on c (i.e., OBSc)and the behavioral description of c (i.e., BDc). If Verify does not return the partialcandidate m(c), then mode m is not consistent with the observations, and is removedfrom the behavioral description of c.The computational cost of the Bottom-up procedure can be characterized as follows.At worst, all nodes of the ST have to be considered. For each node, we have tosolve a diagnosis problem with just one component (which requires to verify a smallnumber of modes and requires no propagation of values). Note that some modes in thesupercomponent may require no verification because all their possible refinements havebeen excluded by reasoning with subcomponents. However, in a worst case scenario thecomputational complexity of the Bottom-up procedure can be characterized as the sumof the costs required to diagnose each node of the ST in isolation.We now reconsider the previously illustrated examples, and show how the BOTTOM-UPextension behaves on them.Example 11. Considering the observations given for the hcs in Example 6 (i.e., flow at portt7 is not as expected), the CLO in the original multi-level hierarchy is level 0. Since themost abstract level with observations is level 0, the Bottom-up procedure is not executed,and reasoning proceeds exactly as in HD.Example 12. Considering the observations given for the hcs in Example 7 (i.e., flow at theport t6 is a > 0, and valve v1 is expected to be closed), level 5 is the CLO. The Bottom-up procedure considers the following nodes (in increasing level order): p2, v1, sc1, sc3,sc5, sc7, and sc8. Diagnosing p2 does not allow one to remove any of its behavioral modes,while diagnosing v1 allows one to remove its ok and stuckC behavioral modes (leak isstill possible, since we do not know anything about the output of v1). Reasoning thenproceeds to sc1. Since its ok and stuckC modes abstract only situations in which its son v1is respectively ok and stuckC, then we can remove these modes also from sc1 even if the= closed. Then, diagnosing sc1 with the remaining modesonly available observation is sv1does not allow to remove any of them. The levels used by HD and by the BOTTOM-UPTable 3Levels and corresponding number of candidates employed by HD and BOTTOM-UP in Example 12LevelNumber of candidates (HD)Number of candidates (BOTTOM-UP)54321061664256102440965832642561024178L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182Procedure HIERARCHICAL-DIAGNOSISAbstract-Observations;Rearrange;Bottom-up;Top-down-diagnosis.Fig. 8. The COMBINED extension to Mozetic’s algorithm.extension with the associated number of components that have to be considered are shownin Table 3. The two algorithms exploit the same levels, but BOTTOM-UP is able to reducethe number of candidates that have to be considered at each level.4.3.4. Combining the two strategiesThe two proposed extensions to HD can be combined together in the following way:first, a tailored structural representation is built using the Rearrange procedure, and thenthe Bottom-up procedure is performed. The procedure that implements both strategies,which we call COMBINED, is shown in Fig. 8. By running this procedure on the previouslyanalyzed diagnostic examples, one obtains all the advantages already described in theprevious two sections.4.4. Experimental evaluationIn this section, we describe the experimental activity that we carried out to evaluate theproposed algorithms. We compared HD, and its three extended versions REARRANGE,BOTTOM-UP, and COMBINED.All algorithms were implemented in SWI Prolog [21] and run on a PowerPC G3 400Mhz (Apple iMac DV) under the LinuxPPC 2000 operating system. The Verify procedureused by all algorithms was implemented as a generate-and-test algorithm, i.e., a procedurethat considers each possible candidate and then verifies its consistency with the systemdescription and the observations. Obviously, this is not an efficient implementation ofthe Verify function, but it has the advantage of giving us a worst case scenario (i.e., theexact size of the considered portion of the search space) for every diagnostic reasoningstrategy we tested. The Top-Down Diagnosis and the Abstract-Observationsprocedures were the same for each algorithm.The experimental comparison of the algorithms was performed with diagnosis problemsof different sizes. We considered hydraulic systems, composed by volumetric pumps,pipes, valves, n-way nodes, sources, and sinks. The considered systems differed in thelayout and in the number of components and ports. More precisely, the simplest system wasthe hcs (11 components and 13 ports), while the most complex system was a Heavy FuelOil Transfer System (HFOTS) (with 27 components and 25 ports) of a modern containership. The layout and functioning of the HFOTS are described in [3].For each hydraulic system, we considered several possible sets of observations. Eachset was composed by a minimum of one observation and a maximum of Nobs observations,withNobs = trunc(0.4 ∗ o)L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182179where o is the number of ports for the considered system (e.g., in systems with 10 ports,each set was composed by a minimum of one and a maximum of four observations). Thejustification for this choice is twofold: first, with only a few observations, the problem ismore difficult (and this is the typical case in which one needs to use abstraction); second,observations in real-world systems are often too few because sensors are too costly and/ortoo unreliable.Each test was generated by first randomly choosing a number m of observations betweenone and Nobs, and then assigning a random value to m observables (randomly selectedamong the available ones). Each generated test was first checked in order to ensure that ithad at least a solution, and then diagnosed using the four algorithms. For each algorithmexecution, we recorded:• total time spent (measured in seconds),• total number of candidates considered for verification.Fig. 9 illustrates the average time we obtained considering 1000 diagnostic scenariosfor each considered hydraulic system. All three extensions perform better than HD: inparticular, REARRANGE is significantly more efficient as the size of the considered systemincreases. This is due to the fact that as the number of components increases, REARRANGEhas more possibilities of deriving additional levels for diagnosis. BOTTOM-UP obtainssmall improvements with respect to HD; as we hypothesized, the improvements obtainedby COMBINED are better than both REARRANGE and BOTTOM-UP.As one can see, for any algorithm the average time becomes very high for smallincreases in the number of components. This is due to the fact that we adopted a generateand test diagnostic strategy.We now consider in more detail the experimentation on the most complex of theconsidered systems, i.e., the HFOTS. Our most detailed representation of the HFOTS wascomposed by one pump, 6 valves, 10 pipes, 1 three-way node, 2 four-way nodes, and 3five-way nodes, with 2,985,984 possible candidates. Moreover, there were 43 ports andthus the number of observations ranged from 1 to 10. We built a hierarchy of structuralFig. 9. Comparison using several hydraulic systems with different number of components.180L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182Table 4Number of candidates verified on the HFOTS considering 1000 diagnostic scenariosCandidatesAverageMaximumMinimumHD238,8782,985,984240REARRANGEBOTTOM-UPCOMBINED117,529947,327240172,3722,985,98418089,234732,183180Table 5Time (in seconds) spent to diagnose the HFOTS considering 1000 diagnostic scenariosTimeAverageMaximumMinimumHD1274127422.13REARRANGEBOTTOM-UPCOMBINED65132642.15107393761.7449628231.77abstractions for the HFOTS organized in 15 levels, where the most abstract level containsjust one component representing the whole HFOTS.Table 4 lists the average, maximum, and minimum number of candidates verified byeach algorithm. Considering the average number of candidates, the value obtained withour extensions is 49% (REARRANGE), 72% (BOTTOM-UP), and 37% (COMBINED), ofthe value obtained with HD. The values of the maximum number of candidates can beexplained as follows. In some cases, HD verifies all candidates at level 0: as we illustratedpreviously, this happens whenever it is not possible to abstract the available observationsto upper levels. For the same reason, BOTTOM-UP exhibits a worst case which is identicalto HD. The value for REARRANGE shows that the extension never reasons with justone level, i.e., it is able to exploit hierarchical reasoning in all considered scenarios.The value for COMBINED shows that, by combining the two extensions, one is able tofurther reduce the maximum number of verified candidates in the considered scenarios.The minimum values of candidates considered refer to situations where the hierarchy isfully exploited: thus, HD and REARRANGE obtain the same result. BOTTOM-UP (andthus COMBINED) is able in this case to slightly reduce the number of candidates that haveto be verified.Table 5 takes into consideration the time spent by each algorithm on the considered testson the HFOTS. The average values show that all three extensions perform better than HDon the HFOTS. In particular, the values obtained by our extensions are respectively 52%(REARRANGE), 77% (BOTTOM-UP), and 39% (COMBINED) of the value obtained withHD.Experimental evaluation on the HFOTS showed also that as the number of observationsincreases, the performance gains of REARRANGE over HD decrease, while those ofBOTTOM-UP increase. This is explained as follows. As the number of observationsincreases, it is more likely that observations can be abstracted to coarser levels: in thosecases, the performance of REARRANGE can only be slightly better than HD. On the otherhand, it is also more likely that BOTTOM-UP is able to exclude more candidates withbottom-up reasoning, and thus to significantly improve performance over HD.L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–1821815. ConclusionsThis paper considered structural abstraction in the context of model-based diagnosis,presented a formalization for it, and proposed an automated approach to the problem ofobtaining effective structural abstractions, i.e., abstractions that are effective for reducingthe computational effort which is required for the situation at hand. The effectiveness ofthe proposed algorithms was shown by experimental comparison with the most cited one inthe literature, i.e., Mozetic’s algorithm [14]. In the following, we outline some limitationsof the experimental activity and directions for improvements.First, the performed experimental evaluation needs to be extended by both consideringother domains (such as electronics) and especially by considering other real-world systems.Moreover, the experimental evaluation needs also to be scaled up to systems with hundredsor thousands of components. In general, there is no reason to suspect that both the generaladvantages of hierarchical reasoning and those introduced by our extensions will not scaleup considerably with the size of the system. Nevertheless, further experimental activityis needed to better evaluate the advantages of the proposed techniques in real-worldsituations.Second, the experimental evaluation was performed by using a generate-and-testapproach for the diagnosis of a single level, which caused generally high running times.Although this choice was taken to give us the exact size of the considered portion ofthe search space, it would be interesting to consider also more efficient approaches todiagnosis (such as the GDE approach). This would allow us to more precisely establish theperformance gains that can be obtained in real-world diagnostic applications.Finally, it must be noted that the tailoring of the hierarchical representation whichis performed by our proposed algorithms may not always be the optimal one, andother criteria for tailoring the hierarchical representation could be tried. In its currentformalization, the REARRANGE extension tries to derive more abstract levels withoutlosing any available observations. Another possible criteria could be to allow losingobservations in exchange for more abstract levels. The choice of which observations tokeep in the abstract levels could be taken by considering the discriminating power of eachobservation, as described in [9].References[1] K. Autio, R. Reiter, Structural abstraction in model-based diagnosis, in: Proceedings of the ThirteenthEuropean Conference on Artificial Intelligence (ECAI-98), Brighton, UK, Wiley, New York, 1998, pp. 269–273.[2] L. Chittaro, R. Ranon, Hierarchical diagnosis guided by observations, in: Proceedings of IJCAI-2001,Seattle, WA, Morgan Kaufmann, San Mateo, CA, 2001, pp. 573–578.[3] L. Chittaro, R. Ranon, A. Soldati, Introducing deviations and multiple abstraction levels in the functionaldiagnosis of fluid transfer systems, Artificial Intelligence in Engineering 12 (1998) 355–373.[4] L. Console, P. Torasso, A spectrum of logical definitions of model-based diagnosis, in: W.H.L. Console, J.de Kleer (Eds.), Readings in Model-Based Diagnosis, Morgan Kaufmann, San Mateo, CA, 1992, pp. 78–87.[5] R. Davis, Diagnostic reasoning based on structure and behavior, Artificial Intelligence 24 (1984) 347–410.[6] R. Davis, W. Hamscher, Model-based reasoning: troubleshooting, in: W.H.L. Console, J. de Kleer (Eds.),Readings in Model-Based Diagnosis, Morgan Kaufmann, San Mateo, CA, 1992, pp. 3–24.182L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182[7] J. de Kleer, Diagnosis with behavioral modes, in: Proceedings of IJCAI-89, Detroit, MI, Morgan Kaufmann,San Mateo, CA, 1989, pp. 104–109.[8] J. de Kleer, A.K. Mackworth, R. Reiter, Characterizing diagnoses and systems, Artificial Intelligence 56(1992) 197–222.[9] J. de Kleer, B.C. Williams, Diagnosing multiple faults, Artificial Intelligence 32 (1987) 97–130.[10] M. Genesereth, The use of design descriptions in automated diagnosis, Artificial Intelligence 24 (1984)411–436.[11] F. Giunchiglia, T. Walsh, A theory of abstraction, Artificial Intelligence 57 (2–3) (1992) 323–389.[12] W.C. Hamscher, Modeling digital circuits for troubleshooting, Artificial Intelligence 51 (1991) 223–271.[13] J. Mauss, M. Sachenbacher, Conflict-driven diagnosis using relational aggregations, in: Proceedings of theTenth International Workshop on Principles of Diagnosis (DX-99), Loch Awe, Scotland, 1999, pp. 174–183.[14] I. Mozetic, Hierarchical diagnosis, in: W.H.L. Console, J. de Kleer (Eds.), Readings in Model-BasedDiagnosis, Morgan Kaufmann, San Mateo, CA, 1992, pp. 354–372.[15] P.P. Nayak, A.Y. Levy, A semantic theory of abstractions, in: Proceedings of IJCAI-95, Montreal, QB,Morgan Kaufmann, San Mateo, CA, 1995, pp. 196–203.[16] C.J. Price, N.S. Taylor, Multiple fault diagnosis using fmea, in: Proceedings of AAAI-97, Providence, RI,AAAI Press, 1997, pp. 1052–1057.[17] R. Ranon, The closure properties of functional flow-based approaches and their relevance to diagnosis, in:Proceedings of the Thirteenth European Conference on Artificial Intelligence (ECAI-98), Brighton, UK,Wiley, New York, 1998, pp. 289–290.[18] R. Reiter, A theory of diagnosis from first principles, in: W.H.L. Console, J. de Kleer (Eds.), Readings inModel-Based Diagnosis, Morgan Kaufmann, San Mateo, CA, 1992, pp. 29–48.[19] P. Struss, What’s in sd? towards a theory of diagnosis, in: W.H.L. Console, J. de Kleer (Eds.), Readings inModel-Based Diagnosis, Morgan Kaufmann, San Mateo, CA, 1992, pp. 419–449.[20] M. Stumptner, F. Wotawa, Guest-editorial special issue on industrial applications of model-based reasoning,AI Comm. 13 (2).[21] Swi prolog, University of Amsterdam, http://www.swi-prolog.org.[22] L. Travé-Massuyés, T. Escobet, R. Milne, Model-based diagnosability and sensor placement application to aframe 6 gas turbine subsystem, in: Proceedings of IJCAI-2001, Seattle, WA, Morgan Kaufmann, San Mateo,CA, 2001, pp. 551–556.