Artificial Intelligence 271 (2019) 74–97Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCooperative games with overlapping coalitions: Charting the tractability frontierYair Zick a,∗a School of Computing, National University of Singapore, Singaporeb School of Electronic and Computer Engineering, Technical University of Crete, Greecec Department of Computer Science, University of Oxford, UKd Department of Informatics, Athens University of Economics and Business, Greece, Georgios Chalkiadakis b, Edith Elkind c, Evangelos Markakis da r t i c l e i n f oa b s t r a c tArticle history:Received 6 July 2016Received in revised form 24 January 2018Accepted 21 November 2018Available online 30 January 2019Keywords:Cooperative gamesOverlapping coalition formationCoreTreewidthArbitration functionsThe framework of cooperative games with overlapping coalitions (OCF games), which was proposed by Chalkiadakis et al. [1], generalizes classic cooperative games to settings where agents may belong to more than one coalition. OCF games can be used to model scenarios where agents distribute resources, such as time or energy, among several tasks, and then divide the payoffs generated by these tasks in a fair and/or stable manner. As the framework of OCF games is very expressive, identifying settings that admit efficient algorithms for computing ‘good’ outcomes of OCF games is a challenging task. In this work, we put forward two approaches that lead to tractability results for OCF games. First, we propose a discretized model of overlapping coalition formation, where each agent i has a weight W i ∈ N and may allocate an integer amount of weight to any task. Within this framework, we focus on the computation of outcomes that are socially optimal and/or stable. We discover that the algorithmic complexity of this task crucially depends on the amount of resources that each agent possesses, the maximum coalition size, and the pattern of communication among the agents. We identify several constraints that lead to tractable subclasses of discrete OCF games, and supplement our tractability results by hardness proofs, which clarify the role of our constraints. Second, we introduce and analyze a natural class of (continuous) OCF games—the Linear Bottleneck Games. We show that such games always admit a stable outcome, even assuming a large space of feasible deviations, and provide an efficient algorithm for computing such outcomes.© 2019 Published by Elsevier B.V.1. IntroductionConsider the following simple market exchange. Two sellers (Alice and Bob) each own a ton of coffee beans (a divisible good), which they would like to sell to two potential buyers (Claire and Dave). Claire and Dave operate in different markets, so Alice and Bob can justifiably offer them different prices. Suppose that having agreed on a transaction schedule and payments, Alice decides that she is unhappy with her revenue from the deal with Claire; she wants to cancel the deal. However, Dave, upon hearing that Alice reneged on her deal with Claire, no longer wishes to work with Alice, canceling * Corresponding author.E-mail addresses: zick@comp.nus.edu.sg (Y. Zick), gehalk@ece.tuc.gr (G. Chalkiadakis), elkind@cs.ox.ac.uk (E. Elkind), markakis@gmail.com (E. Markakis).https://doi.org/10.1016/j.artint.2018.11.0060004-3702/© 2019 Published by Elsevier B.V.Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9775his agreement with her as well. Dave’s motivation for doing so may stem from many reasons, e.g. a potential business partnership with Claire, or market ‘best practices’.This setting features several interesting characteristics. First, an agent may sell resources to several agents, and may also buy from several other agents. In other words, agents may allocate resources to several profit-generating tasks. Second, agents may withdraw some of their resources from some agreements. For example, Alice may wish to sell less coffee to some customer, but not change her interactions with other parties. Finally, when trying to strategically change an agreement, agents must be aware of how their actions affect the contracts they still maintain with other (possibly unaffected) parties.In our example, agents must collaborate in order to generate revenue. Having generated revenue by making an exchange, agents are free to share the profits from the exchange as they see fit. Profit sharing can be done directly, if the agents jointly produce a new good using their resources, sell it, and distribute the revenue among themselves. It can also be indirect: a seller shares the profit from her transaction with a buyer by setting a price for her good. In either case, agents must identify a way to generate profits, and, subsequently, share profits among themselves in a reasonable manner. When sharing profits, agents should account for individuals or groups of agents who feel that they are underpaid. Indeed, a group of agents that can get more money by deviating from the proposed agreement may destabilize the entire market, resulting in a cascade of deviations, which may eventually produce a less desirable state (not to mention the cost of actual deviation). However, what constitutes a profitable deviation strongly depends on how non-deviators respond to the deviators’ actions.Reasoning about this system of incentives and reactions is a significant challenge. While many group interaction scenar-ios can be represented by the framework of transferable utility cooperative games (TU games), with stable profit-sharing schemes captured by the notion of the core (see, e.g., Peleg and Sudhölter [2]), the standard setting of TU games is not expressive enough to deal with agents participating in several collaborative agreements simultaneously. A few years ago, Chalkiadakis et al. [1] proposed a novel approach to modeling scenarios where agents can divide resources among several joint tasks, by introducing the framework of overlapping coalition formation games (OCF games) and defining several vari-ants of the notion of core stability for this model, which capture different reactions to deviations by non-deviating agents; these include the conservative core, the refined core, the optimistic core, and the sensitive core. Following their work, Zick et al. [3] proposed the notion of an arbitration function, which provides a general model for handling deviations in OCF games. These two works offer a comprehensive conceptual model for analyzing stability in settings where agents work on several concurrent projects and may deviate in a complex manner.In contrast, there has been a very limited amount of work on computing solution concepts for OCF games. The theory of OCF games is a generalization of classic cooperative game theory [2], where computational issues are relatively well-understood (see [4] for an overview). However, as Chalkiadakis et al. [1] show, more elaborate reactions to deviation may increase computational complexity: even if a solution concept is easy to compute for classic cooperative games, computing its OCF analogue may be NP-hard. For example, Chalkiadakis et al. [1] study a class of games called threshold task games: these are games where each agent is associated with an integer weight, and the value of a coalition is a piece-wise con-stant function of its total weight. They show that a payoff division in the core of a threshold task game can be found in pseudopolynomial time (i.e. in time polynomial in the number of agents and in the largest agent weight), if one assumes that when a set of agents deviates, no other agent will want to work with agents in this set—a reaction termed conservative, which closely approximates the setting of TU games (as explained by Zick et al. [3]). In contrast, if non-deviators agree to work with the members of the deviating set in coalitions that are unharmed by the deviation (a reaction termed refined), the same problem becomes NP-hard.It follows that, when assessing the computational complexity of finding stable outcomes in OCF games, one needs to consider not only structural properties of the characteristic function (i.e. the way agents generate profits), but also the way agents react to deviations. In our work, we study the influence of these two aspects of OCF games on the complexity of answering stability-related questions in OCF games.1.1. Our contributionThe computational complexity of any given problem depends on how the input is represented. For instance, a general TU game with n agents is represented by 2n real values: we need one number for each subset (coalition) of players. Thus, no algorithm that needs to know the value of each coalition can run in time that is polynomial in the number of agents. This issue is even more prominent for games with overlapping coalitions: to describe an OCF game, we need to specify a number for every partial coalition, i.e., agreement of the form ‘agent 1 contributes an x1 fraction of her resources, . . . , agent n contributes an xn fraction of her resources’, for every possible combination of (real) values x1, . . . , xn ∈ [0, 1]. Thus, a general OCF game cannot be described by a finite list of numbers, and hence one cannot meaningfully reason about the complexity of general OCF games. To mitigate this issue, we explore two different strategies:1. We introduce and study discrete OCF games, which place restrictions on how finely an agent can split her resources (Sections 3 to 6). In these games, each agent i is associated with an integer weight W i ∈ N and can only allocate an integer weight between 0 and W i to each task. By definition, a discrete OCF game can be represented as a finite list of numbers, and thus discrete OCF games are amenable to traditional complexity-theoretic analysis.2. We identify a large class of (standard, i.e., non-discrete) OCF games that can be succinctly represented (Section 7). Specifically, we study a rich and expressive class of games that we term linear bottleneck games (LBGs). A game in this 76Y. Zick et al. / Artificial Intelligence 271 (2019) 74–97class can be described by a list of tasks; the payoff from each task depends on the inherent value of each task and the players’ contributions to it. These games capture interesting combinatorial optimization scenarios where overlapping coalitions can naturally arise.For both of these classes of OCF games, we investigate the complexity of several closely related challenges:1. Given an OCF game, find an optimal coalition structure—i.e. an optimal way for agents to divide into groups and generate profits.2. Given an OCF game, an outcome of this game (i.e. a coalition structure together with a payoff division) and a subset of agents, compute the most that this subset can get by deviating (given how non-deviators are expected to react to deviations).3. Given an OCF game and an outcome of this game, decide whether this outcome is stable, i.e., whether there exists a subset of agents that can benefit from deviating (for a given non-deviators’ reaction).4. Given an OCF game, find a stable outcome if one exists (for a given non-deviators’ reaction).In the first part of the paper, we focus on discrete OCF games. We make no assumptions on how agents generate revenue (i.e. the characteristic function can take any form), and focus instead on the structure of their interaction. In Section 3, we show that, for tractability, we need to bound the size of each coalition, and, moreover, impose a constraint on the overall agent interaction pattern. Specifically, inspired by the work of Myerson [5] and Demange [6], we study settings where agents are connected in a social network (mathematically, an undirected graph), and feasible coalitions correspond to connected subgraphs of this graph. We show that when this social network is acyclic and the maximum coalition size is 2, it becomes possible to find an optimal coalition structure in polynomial time. However, these constraints are insufficient for tractability of stability-related problems: in Section 4 we show that, for these problems to admit efficient algorithms, the non-deviators’ reaction must also be limited in scope, i.e. complex reactions to deviation are a source of computational complexity in and of themselves.We show that, when all of our conditions on agent interaction and the non-deviators’ reaction are satisfied, the stability-related problems we consider admit efficient algorithms. We also show that none of these conditions can be dropped, by providing NP-hardness proofs for settings where they are not satisfied. Our results extend to the case where the social net-work formed by the agents has bounded treewidth (Section 6); our algorithms for this case run in time that is polynomial n and (W max)k, where n is the number of agents, W max is the maximum agent weight, and k is the treewidth of the social network.In the second part of our paper, we consider linear bottleneck games. In these games, there is a set of agents N and a list of tasks (T 1, . . . , Tm). Each task T j is associated with a set of agents A j ⊆ N who are needed to complete it, as well as a value π j ∈ R+. Each agent i ∈ N has a weight ωi ∈ Q, which she can freely distribute among the tasks. If each agent i ∈ A jcontributes xi units of weight to T j , then the payoff that the agents in A j earn from T j is π j · mini∈ A j xi . That is, the payoff from the task is determined by the smallest contribution to it, i.e., the bottleneck.LBGs capture many interesting game-theoretic settings, including, for instance, multicommodity flow games [7,8]. Briefly, in multicommodity flow games pairs of vertices in a network want to send and receive flow, which has to be transmitted by edges of the network. This setting can be modeled by a linear bottleneck game, where both vertices and edges are players. The weight of an edge player is the capacity of his edge, while the weight of a vertex player is the amount of commodity she would like to send or receive. Further examples of settings that can be represented in the framework of LBGs are described in Section 7.It is known that multicommodity flow games admit outcomes that are stable in the sense of classic cooperative game theory [8]. We generalize and strengthen this result, by showing that linear bottleneck games admit stable outcomes even if we assume a very lenient reaction to deviation (in general, as argued by Chalkiadakis et al. [1] and Zick et al. [3], the more lenient non-deviators are, the smaller is the space of stable outcomes). Moreover, we provide a linear programming-based algorithm that finds stable outcomes of LBGs in polynomial time.1.2. Related workOur work expands and builds upon two previous papers on OCF games: the paper of Chalkiadakis et al. [1], which introduced the OCF model, and the more recently published paper by Zick et al. [3]. While the primary focus of Chalkiadakis et al. [1] is not algorithmic, they present some complexity results for threshold task games. For example, Chalkiadakis et al. show that it is possible to find an outcome in the core of a threshold task game in pseudopolynomial time, assuming that the reaction to deviation is conservative; that is, agents in a deviating set do not expect the non-deviators to collaborate with them. As Zick et al. [3] show, this conservative assumption makes stability concepts in OCF games ‘collapse’ to their classic (i.e., non-OCF) equivalents. However, if one assumes a more refined reaction to deviation—namely, that non-deviators will continue collaborating with deviators if they are not affected by the deviation—the problem of finding a core stable outcome for TTGs becomes NP-hard. This work is the first indication that different notions of stability (as captured by arbitration functions) not only lead to different outcomes, but may also have different computational properties. While Zick et al. [3] do not study computational aspects of OCF games, their work presents us with some useful tools for the Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9777design of efficient algorithms for this type of games. In particular, Zick et al. [3] show that certain classes of OCF games are guaranteed to have a non-empty core; however, their proofs rely on balancedness conditions, and are not computational in nature. Thus, even though some games are guaranteed to be stable with respect to some arbitration functions, computing stable outcomes may be hard.The related problem of computing an optimal coalition structure has received plenty of attention in the AI literature, starting with the influential papers of Sandholm et al. [9] and Larson and Sandholm [10]; we point the readers to the surveys of Elkind et al. [11] and Rahwan et al. [12]. Some authors have studied this problem for games with overlapping coalitions as well; we mention the important early paper by Shehory and Kraus [13], as well as the work by Lin and Hu [14]and Zhang et al. [15]. However, these papers operate under a different methodology and objectives. Specifically, they aim to find optimal or approximately optimal coalition structures, but do not consider their stability, whereas we are also interested in computing stable revenue division schemes. Furthermore, these works focus on specific problem domains, whereas our results hold for more general classes of games.Computational issues in classic cooperative games have been an object of extensive study. Early computational results can be attributed to some of the field’s ‘founding fathers’: Mann and Shapley [16,17] study methods to compute the Shapley value (an important solution concept in cooperative game theory) both exactly and approximately. Interestingly, their results, while not phrased in the language of modern computational complexity, are computational in nature. The important early paper of Deng and Papadimitriou [18] was the precursor of several works on the subject; a non-comprehensive list includes papers by Deng et al. [19], Ieong and Shoham [20], Matsui and Matsui [21], Elkind et al. [22], Greco et al. [23] (see the survey by Chalkiadakis et al. [4]). Stability in OCF environments has been recently considered by Zhang et al. [24], who employ the OCF model in order to analyze wireless networks, and show some stability results in this setting; however, their work again focuses on a specific problem formulation, rather than general classes of OCF games. Ackerman and Brânzei [25]study a pairwise collaboration model that is similar to the OCF model studied here; however, their paper studies pairwise equilibria in this model, rather than core stability.Coalitional games where possible interactions among the agents are described by a network were first considered by Myerson [5]; in the literature such networks are called communication graphs. Demange [6] studies cooperative games whose communication graphs are trees; not only do these games have a non-empty core, but for superadditive games a core outcome can be found in polynomial time. Brafman et al. [26] exploit the underlying communication graph structure to derive polynomial-time algorithms for a class of cooperative games that are motivated by planning scenarios. However, the positive algorithmic results of Brafman et al. [26] and Demange [6] do not extend to communication networks of bounded treewidth: there exist classes of coalitional games whose underlying communication network has a bounded treewidth, but for which computing a core-stable outcome is computationally intractable [27]. Nevertheless, games on bounded-treewidth communication networks are more stable, in the sense that their cost of stability (the minimum subsidy to the grand coalition that ensures its stability, see the work of Bachrach et al. [28]) can be bounded in terms of the treewidth of the communication network [29,30]. Recently, Igarashi and Elkind [31] analyzed the complexity of computing stable outcomes in graph-restricted hedonic games, obtaining a number of easiness results for a variety of solution concepts for the case where the communication network is a tree; subsequently, similar results have been derived for another coalition formation task that is known as the group activity selection problem [32–34].2. Preliminaries(cid:2)In what follows, we use uppercase letters to refer to sets, and boldface letters to refer to vectors. Given two vectors x, y ∈ Rn, we write x ≤ y if xi ≤ yi for all i ∈ {1, . . . , n}. Given a set of agents S ⊆ {1, . . . , n} and a vector x ∈ Rn, let x(S) =i∈S xi and let xS be the vector in Rn whose i-th entry is xi if i ∈ S and 0 otherwise. Let eS be the indicator vector of S in Rn, i.e. the i-th entry of eS is 1 if i ∈ S and 0 otherwise.We begin by recalling the definition of a classic cooperative game (see, e.g., [2]). A cooperative game G is a tuple (cid:6)N, u(cid:7), where N = {1, . . . , n} is a set of agents and u : 2N → R+ is a function that assigns a value to every subset of agents S ⊆ N. Subsets of N are also referred to as coalitions. A coalition structure is a partition of agents (cid:4) = {S 1, . . . , Sm} into disjoint j=1 S j = N and for all S j, Sk ∈ (cid:4) with j (cid:9)= k it holds that S j ∩ Sk = ∅. An imputation for (cid:4) is a vector subsets; that is, p = (p1, . . . , pn) that satisfies the following two conditions: (1) pi ≥ u({i}) for all i ∈ N (individual rationality), and (2) p(S j) = u(S j) for all S j ∈ (cid:4) (coalitional efficiency). In words, an imputation is a division of the payoffs generated by the agents forming (cid:4) such that agents are individually incentivized to form a coalition structure, and the payoff from forming a coalition S j is allocated to the members of S j only. An outcome of G is a pair ((cid:4), p), where (cid:4) is a coalition structure and p is an imputation for (cid:4). Observe that in every coalition structure each agent participates in exactly one coalition. While this is a valid assumption in many multi-agent scenarios, it is often the case that agents split their resources among several projects, forming overlapping coalitions.(cid:3)mOverlapping coalition formation (OCF) games [1] lift the assumption that each agent participates in exactly one coalition. An OCF game is also given by a tuple G = (cid:6)N, v(cid:7), where N = {1, . . . , n} is a set of agents and v is the characteristic function. However, in contrast with the classic case, the function v is defined on all vectors of the form [0, 1]n, and assigns a non-negative real value to every partial coalition c = (c1, . . . , cn) ∈ [0, 1]n. The quantity ci is the contribution of agent i to c, and indicates which fraction of her resources is allocated to c. A coalition structure for G is a (possibly infinite) list of partial coalitions CS such that for each i ∈ N it holds that (cid:2)c∈CS ci ≤ 1.78Y. Zick et al. / Artificial Intelligence 271 (2019) 74–97Note that, in the definition above, to fully describe v, we need to specify its value at every real point in [0, 1]n , and a coalition structure may contain infinitely many coalitions. Both of these issues make it difficult to represent OCF games and to reason about them. To overcome these difficulties, we will now introduce a discretized version of OCF games and show how to adapt the existing concepts developed for OCF games to the discrete setting.In what follows, we provide formal definitions of the notions used in this paper, focusing on the discrete model. Conve-niently, many definitions for the continuous model apply without change to the discrete setting; when this is not the case, we provide the definition for the continuous case in brackets (these definitions will be used in the second half of the paper, where we present some algorithmic results for a special class of continuous OCF games).A discrete overlapping coalition formation (dOCF) game is a tuple G = (cid:6)N, W, v(cid:7). Here, N = {1, . . . , n} is the set of agents; each agent i ∈ N has a weight W i , and the agents’ weights are collectively described by the vector W = (W 1, . . . , W n). One can think of W i as the amount of some resource that agent i possesses. Let W = {c ∈ Zn+ | c ≤ W}, or, equivalently,W = {0, . . . , W 1} × · · · × {0, . . . , W n};the set W is the set of all possible ways in which agents can contribute resources to a single task. A vector c ∈ W is called a partial coalition (for succinctness, we will often omit the qualifier ‘partial’ when speaking of such coalitions); ciis the contribution of agent i. If ci = 0 then agent i contributes nothing to completing the associated task, and if ci = W i then all of agent i’s resources are assigned to this task. The characteristic function v : W → R+ receives as input a coalition c ∈ W and outputs a value v(c), describing the profit that this coalition can generate.Given a partial coalition c in W (or, in the continuous setting, in [0, 1]n), we define the support of c to be the set of all agents in N that contribute some of their resources to c: we write supp(c) = {i ∈ N | ci > 0}. Agents in supp(c) are the only ones who may receive a share of the profits made by c, and may therefore be affected by changes to c.A coalition structure for a discrete OCF game is a finite list of coalitions CS = (c1, . . . , cm); we write |CS| to denote the number of coalitions in CS. Since no agent can contribute more than the total amount of resources she possesses, we require that c∈CS ci ≤ W i for all i ∈ N (this is the analogue of the condition c∈CS ci ≤ 1 for the continuous case).(cid:2)(cid:2)Example 2.1. Consider the following three-player game, where players form overlapping coalitions in order to complete a set of tasks. Players’ weights are as follows: W 1 = W 2 = 2; W 3 = 1. There are four types of tasks:• A task of type t1 can be completed by player 1 alone, requires all of her resources, and is worth 5.• A task of type t12 requires 50% of both player 2 and player 1’s resources, and is worth 10.• A task of type T 12 requires all of the resources of players 1 and 2, and is worth 20.• A task of type t23 requires all of player 3’s resources and 50% of player 2’s resources, and is worth 9.Consider coalition structures CS = (c1, c2) and CS(cid:4)(cid:4)(cid:4)(cid:5)(cid:5)(cid:5)c1 =, c2 =110110(cid:13), c1=220.(cid:13) = (c(cid:13)1), whereIt is easy to see that both CS and CStogether and earn a total of 20 (by completing t12 twice or T 12 once), while player 3 makes no profit.maximize the players’ total payoff. Indeed, it is best for players 1 and 2 to work (cid:13)Note that CS is a list rather than a set; this is because some coalitions may form more than once (this corresponds to agents completing several identical tasks). Nevertheless, we use standard set notation to refer to elements of CS. That is, we write y ∈ CS if y is one of the coalitions listed in CS, and we write CSis obtained from CS by removing some of c∈CS v(c). Given a subset of agents S ⊆ N, we write CS(S)its elements. We overload notation and write v(CS) to refer to to denote the set of all coalition structures that can be formed by members of S; that is, CS(S) consists of all coalition structures CS such that supp(c) ⊆ S for all c ∈ CS. We set CS = CS(N). The weight of a coalition structure CS is defined as c∈CS c. We say that CS ∈ CS(S) is efficient for S if all agents in S contribute all of their resources to CS, that is, w(CS) =w(CS) = WS (in the continuous case, this condition becomes w(CS) = eS ).(cid:13) ⊆ CS if CS(cid:2)(cid:2)(cid:13)Given a coalition structure CS ∈ CS and a set S ⊆ N, let CS|S be the coalition structure CS reduced to S, CS|S , i.e. we setCS|S = (y ∈ CS | supp(y) ⊆ S) .The coalition structure CS|S includes all coalitions in CS that are fully controlled by the members of S. If S decides to deviate, the resources used by CS|S are freely available to S. In contrast, any coalition y ∈ CS \ CS|S has non-S members, and any changes to such coalitions may lead to negative repercussions for S.Given a dOCF game G = (cid:6)N, W, v(cid:7) (respectively, an OCF game G = (cid:6)N, v(cid:7)), we define the superadditive cover of v to be the function v∗ : W → R+ (respectively, v∗ : [0, 1]n → R+) such that for every coalition c∗v(c) = sup{v(CS) | w(CS) = c}.Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9779∗(c) is the maximum profit that agents can generate by forming coalitions when their total resources are given Simply put, vby c. We note that in the discrete model, for any c ∈ W there exists a coalition structure CS ∈ CS such that w(CS) = c and ∗(c) = v(CS), i.e. in the expression above ‘sup’ can be replaced with ‘max’; however, in the continuous setting this is not vthe case.Observe that if W i = 1 for all i ∈ N, the resulting game is a classic cooperative game with coalition structures [35].2.1. Payoff divisionHaving formed a coalition structure, agents have to divide the profits generated by their joint work. Given a coalition structure CS = (c1, . . . , cm), an imputation x = (x1, . . . , xm) for CS is a list of |CS| = m vectors in Rn+ (in the continuous case, where the number of coalitions in CS may be infinite, we require that there is a bijection between CS and x). The vector x jdescribes how the profits from the coalition c j are divided among the agents. Given a coalition c ∈ CS and an imputation xfor CS, we denote the division of profits from c by x(c); the payoff to agent i from c is xi(c). We require a division of profits to satisfy the following rules:Coalitional efficiency:No side payments:for all c ∈ CS, the total payoff from x(c) must equal v(c); that is, (cid:2)i∈N xi(c) = v(c).for all c ∈ CS, if i /∈ supp(c) then xi(c) = 0. This condition simply means that agents who did not con-Individual rationality:tribute any resources to the coalition c may not partake in the profits generated by c.(cid:2)c∈CS xi(c) ≥ vi can get by working alone (for the continuous case, the right-hand side of this inequality becomes vfor all i ∈ N, it holds that ∗(Wi), i.e. the total payoff to i is at least the amount that ∗(ei)).(cid:2)The set of all possible imputations for a coalition structure CS is denoted I(CS); an outcome is a pair (CS, x), where CS is a coalition structure and x is an imputation in I(CS). We also define pi(CS, x) to be the total payoff to agent i under (CS, x): c∈CS xi(c). We extend this notation to sets of agents: given a set S ⊆ N, we define p S (CS, x) to be the total pi(CS, x) =payoff to the set S under (CS, x), i.e. p S (CS, x) =i∈S pi(CS, x). Note that the definition of an outcome in an OCF game is a generalization of the respective definition in a classic cooperative game.(cid:2)Example 2.2. Consider the coalition structure CS = (c1, c2) from Example 2.1, and let x = (x1, x2), where x1(c1) = 3, x2(c1) =7, x1(c2) = 8, x2(c2) = 2. That is the payoff from the first copy of t12 is divided so that player 1 gets 3 and player 2 gets 7, whereas the payoff from the second copy of this task is divided so that player 2 gets 8 and player 1 gets 2. Then x is an imputation for CS, and (CS, x) is an outcome of our game. Note that we have p1(CS, x) = 11, p2(CS, x) = 9.2.2. Deviation and arbitration functionsIn a classic cooperative game G = (cid:6)N, u(cid:7), a subset of agents has an incentive to deviate from an outcome ((cid:4), p) when its total payoff p(S) is less than the profits it can generate on its own, i.e. u(S). However, in OCF games, deviation is a much more complicated matter. The classic notion of deviation in cooperative games implicitly assumes that when a set of agents deviates, it does not retain any ties to non-deviators; that is, the deviators measure the desirability of a deviation against the most they can make on their own, and assume that non-deviators will no longer collaborate with them. This is not necessarily the case in the OCF setting: we assume that when a set S ⊆ N deviates from an outcome (CS, x), it may still retain some resources in coalitions with agents in N \ S. Thus, to decide whether retaining connections with non-deviators is worthwhile, agents in S need to know how the non-deviators will react to their deviation. Chalkiadakis et al. [1] were the first to point out this aspect of agents’ behavior, and have shown how different types of non-deviators’ reactions to deviation lead to different notions of stability. Zick et al. [3] suggest a general framework for handling deviation in OCF games, which is based on the concept of arbitration functions.We begin by formally defining a deviation in OCF games. Given an outcome (CS, x) and an agent set S, a deviation of whose coalitions describe the resources that S withdraws from each coalition S from (CS, x) is a coalition structure CSc ∈ CS \ CS|S . We let dCSthat describes the resources that S withdraws from the coalition (cid:13)by a coalition S has to satisfy the c, omitting the CS(cid:13) (c) ≤ eS . The first constraint ensures that no agent in S withdraws more following constraints: (1) dCSresources than it has invested in c, while the second constraint ensures that agents that do not belong to S do not withdraw any resources from c. Note that the formal definition of deviation does not refer to the imputation x.subscript when it is understood from the context. A deviation CS(cid:13) (c) denote the coalition in CS(cid:13) (c) ≤ c and (2) dCS(cid:13)(cid:13)(cid:13)Example 2.3. Consider again the coalition structure CS from Example 2.1 and the imputation x from Example 2.2; recall that (CS, x) is an outcome of our game. Let S = {1} and let CS(cid:5)(cid:13)(cid:13) = (c3, c4), where(cid:5)(cid:4)(cid:4)c3 =, c4 =100100,80Y. Zick et al. / Artificial Intelligence 271 (2019) 74–97(cid:13)(cid:13) (c1) = c3, dCSand dCSher resources from both of her joint projects with player 2. Observe that CSwithdrawn resources.(cid:13)(cid:13) (c2) = c4. The coalition structure CS(cid:13)(cid:13)describes the deviation in which player 1 withdraws all of does not indicate how player 1 will use the (cid:13)(cid:13)Given a deviation by S from the coalition structure CS, the non-deviating agents, i.e. the members of N \ S, have to decide how to react to the deviation. Zick et al. [3] define an arbitration function A to be a mapping whose input is by S from CS. For each c ∈ CS \ CS|S , A outputs a value an outcome (CS, x), a deviating set S ⊆ N, and a deviation CS(cid:13)(cid:13)), which specifies the total payoff that the coalition c offers S as a result of its deviation. A deviation CSαc = αc(CS, x, S, CSis said to be A-profitable if the members of S have a way to form a coalition structure using all resources available to them and then divide the payoffs from that coalition structure as well as the (possibly negative) payoffs provided by (αc)c∈CS\CS|Sso that every agent in S receives a strictly higher payoff compared to what she receives under (CS, x). An outcome (CS, x)is called A-stable if no subset S ⊆ N can A-profitably deviate from (CS, x). A game G is called A-stable if there exists an outcome (CS, x) that is A-stable.(cid:13)Suppose that the vector of resources available to S after it has withdrawn from CS according to CSis given by t; then (cid:13)the total payoff that S can receive from the deviation CS(cid:13)under A is at mostA(CS, x, S, CS(cid:13)) = v∗(t) +αc(CS, x, S, CS(cid:13)).(cid:6)Letc∈CS\CS|SA∗(CS, x, S) = sup{A(CS, x, S, CS(cid:13)(cid:13)) | CSis a deviation of S from (CS, x)};this quantity is a tight upper bound on the payoff that S can earn by deviating. Zick et al. [3] provide a simple characteri-zation of continuous OCF games that are A-stable, which is given in the following theorem; this result remains true in the discrete model.Theorem 2.4. An OCF game G = (cid:6)N, v(cid:7) is A-stable if and only if there exists an outcome (CS, x) such that for all S ⊆ N it holds thatp S (CS, x) ≥ A∗(CS, x, S).Theorem 2.4 implies that, to verify stability, there is no need to look for an explicit coalition structure formed using the resources available to S post-deviation, a division of payoffs from that coalition structure, and a division of payoffs from non-deviators such that all deviators are strictly better off. Instead, it suffices to verify that the total payoff obtained by S is at least as large as the total payoff S can receive by deviating—no matter how it deviates.Before we proceed, let us describe some arbitration functions, which will play an important role in this paper; formal definitions can be found in the work of Zick et al. [3] (Section 3.2).1The Conservative Arbitration Function: under this function, denoted Ac , deviators receive nothing from non-deviators, i.e. αc ≡ 0 for every deviation. When reasoning about the desirability of deviation under Ac , S has no incen-tive to retain any of its resources in coalitions with non-deviators: it will not receive any payments from such coalitions.The Sensitive Arbitration Function: rather than assuming that agents will outright refuse to cooperate with deviators, one can take a slightly more ‘lenient’ approach. Under the sensitive arbitration function, denoted As , if a coalition c is changed by S’s deviation, then all agents in supp(c) refuse to cooperate with the agents in S in other coalitions, i.e., αc(cid:13) = 0 for all cwere affected by the deviation, S retains all of its payoffs from c(cid:13)) ∩ supp(c) (cid:9)= ∅. However, if none of the agents in a coalition cunder (CS, x).with supp(c(cid:13)(cid:13)(cid:13)The Refined Arbitration Function:The Optimistic Arbitration Function:this arbitration function, denoted Ar , assumes an even more lenient reaction to devia-tion. Under Ar , if a coalition c is unchanged by a deviation of a set S, S keeps all its original payoffs from c under (CS, x).this arbitration function, denoted Ao , describes the behavior of agents who are highly flexible concerning changes to their coalitions. Consider a deviation d(c) by a set S from a coalition c ∈ CS \ CS|S ; after S deviates, the value of c is reduced to v(c − d(c)). Under Ao, the payoff to S from c is simply v(c − d(c)) −(cid:2)i∈N\S xi(c). That is, to receive payoff from c, S must cover the loss it caused by withdrawing resources from c; once it ensures that agents in N \ S retain their original payoffs from c, it is free to divide the remaining payoffs from this coalition.The following example highlights the reasoning behind some of the arbitration functions presented above.1 All arbitration functions listed here were introduced by Chalkiadakis et al. [1]. However, Chalkiadakis et al. [1] do not use the term ‘arbitration function’ to describe agents’ reaction to deviation; this term was subsequently introduced by Zick et al. [3].Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9781Example 2.5. Consider a dOCF game with N = {1, 2, 3} and W i = 10 for i = 1, 2, 3. Let CS = (c{1,3}, c{2,3}, c{1,2,3}) be a coalition structure in this game, where for every coalition cS in CS we have supp(cS ) = S; for instance, c{1,3} is a coalition in which players 1 and 3 collaborate. Now, suppose that player 3 wishes to withdraw some of her resources from the coalition c{1,3}. Under the conservative arbitration function, player 3 will receive no payments from c{1,3}, c{2,3} or c{1,2,3}. Under the sensitive arbitration function, player 3 can only expect payoff from c{2,3}: since she changed her contribution to c{1,3}—a coalition containing a player in the support of c{1,2,3}—she cannot expect to receive any payoff from c{1,2,3}. Under the refined arbitration function, she will be able to retain all of her payoff from c{2,3} and c{1,2,3}, as they were unaffected by the deviation. Under the optimistic arbitration function, she will retain her payoffs from c{2,3} and c{1,2,3}, and may even be eligible to keep some payoff from c{1,3}, depending on how much she withdrew from it, and how it affected the value of her joint project with player 1.We observe that the amount that coalition c needs to pay a deviating set S may depend on the effect that S’s deviation has on other coalitions. For example, under the sensitive arbitration function, c may refuse to pay S, even if c was not affected at all by the deviation.In classic cooperative games if a coalition structure (cid:4) can be stabilized (i.e. if there exists an imputation p such that ((cid:4), p) is in the core), then every coalition structure that has the same total payoff as (cid:4) can be stabilized as well. In contrast, in games with overlapping coalitions this is not the case, as illustrated by the following example.Example 2.6. Consider again the game described in Example 2.1 and coalition structures CS and CSconstructed in that example. We claim that CS cannot be stabilized with respect to the refined arbitration function. The reason is that for an outcome (CS, x) to be in the refined core, it must be the case that player 2 gets at least 9 from every coalition in CS: otherwise, player 2 can threaten to deviate to a coalition with player 3, which has value 9. However, this means that player 1 gets at most 2 from working with player 2, while it can get 5 by working alone. On the other hand, let y be (cid:13), y) is in the the imputation for CSrefined core. Notably, CS can be stabilized with respect to the sensitive and the conservative core, again, an even split of the revenue will suffice. Indeed, if player 2 withdraws resources from one of the coalitions in CS, both the sensitive and the conservative arbitration function would deny her any payoffs from the other coalition in CSthat offers an even split of the revenue from T 12 between players 1 and 2. Then (CS.(cid:13)(cid:13)(cid:13)To conclude this section, we remark that, from the perspective of welfare maximization, discrete OCF games can be viewed as games with types [36–39], i.e., games where players are partitioned into k non-overlapping groups so that the agents in each group are interchangeable. Specifically, by replacing a player i with weight W i by W i non-splittable players ni=1 W i players and nand modifying the characteristic function accordingly, we obtain a classic coalitional game with n player types such that there is a natural correspondence between partial coalitions in the original game and (ordinary) coalitions in the new game. This connection can be used to compute an optimal overlapping coalition structure in time that is exponential in n (but not in W max). However, this approach is unlikely to lead to algorithms whose running time is polynomial in n, since the standard assumption in the analysis of games with types is that the number of types is small and therefore algorithms that run in time exponential in the number of types are acceptable. Moreover, the connection breaks down once we consider coalitional stability, for all but the most permissive arbitration functions: for instance, under the conservative arbitration function if player i withdraws a unit of his weight from a given partial coalition, he receives no payoff from other coalitions he contributes to; under our transformation, this would mean that all W i‘avatars’ of player iwill be held responsible for the actions of any one of them, which is very different from the classic model of cooperative games.(cid:2)3. Finding an optimal coalition structureWe now begin our formal computational analysis of discrete OCF games, starting with the fundamental problem of find-ing optimal coalition structures. We assume that the reader is familiar with standard notions of computational complexity and complexity classes (see the classic book of Garey and Johnson [40] for an overview).We start by describing the computational model that we employ. Consider a discrete OCF game G = (cid:6)N, W, v(cid:7) with |N| = n, and let W max = maxi∈N W i . This game G can be described by a list of |W| =i∈N (W i + 1) ≤ (W max + 1)nnon-negative values, one for each possible coalition that the agents may form. From now on, we also assume that the characteristic function takes values in Q+, and for every coalition c ∈ W the number of bits required to represent v(c) is polynomial in n and W max; we also assume that whenever a payoff vector x is part of an input to a computational problem, its entries are rational numbers, and the number of bits required to represent each entry of x is polynomial in n and W max.Since W i ≥ 1 for all i ∈ N, the size of this representation is exponential in n, which is unacceptable for most applications. This issue is not specific to OCF games: it also arises in the context of classic coalitional games, where it is usually tackled by focusing on classes of games that allow for a succinct encoding in a suitable representation formalism (see Chapter 3 in the book of Chalkiadakis et al. [4] and references therein). We will pursue a variant of this approach in our work: specifically, following Shehory and Kraus [41], we will limit our attention to games where there is an apriori bound on the size of a successful coalition.(cid:7)82Y. Zick et al. / Artificial Intelligence 271 (2019) 74–97Definition 3.1 (k-OCF Games). A discrete OCF game G = (cid:6)N, W, v(cid:7) is called a k-OCF game if for all c ∈ W with |supp(c)| > kit holds that v(c) = 0.(cid:8)(cid:9)We note that in k-OCF games the number of coalitions that can have a positive value is bounded by (W max + 1)k. Therefore, if k is a constant, then the characteristic function for a k-OCF game can be represented using a number of bits that is polynomial in n and W max (by omitting all coalitions with value 0). On the other hand, there are several real-life scenarios that can be captured by k-OCF games where k is a small constant: in many market scenarios, transactions involve only a few parties; in social network applications, agents form pairwise coalitions; in many large-scale collaborative projects, small teams are formed to tackle various tasks, as large teams of collaborators tend to be less efficient. Thus, k-OCF games with small k provide a good balance between succinctness and expressivity.In what follows, it will be convenient to use the following notation: given a set of agents {i1, . . . , ik}, we write v i1,...,ik (w i1 , . . . , w ik ) to denote the value of v when agent i1 contributes w i1 , agent i2 contributes w i2 , etc. For exam-ple, if agents i and j embark on a joint project where agent i contributes w i and agent j contributes w j , the value of this collaboration is v i, j(w i, w j).We are now ready to formulate the computational problem that is the focus of this section: computing the superadditive cover for a given resource vector c, i.e. finding an overlapping coalition structure that maximizes the total profit. The decision version of this problem can be stated as follows.nkName: OptValInput:Question:Is v∗(c) ≥ V ?A discrete OCF game G = (cid:6)N, W, v(cid:7), a coalition c ∈ W , and a value V ∈ Q.In the rest of this section, we investigate the complexity of OptVal, aiming to identify the properties of dOCF games that make this problem tractable.3.1. Complexity of OptVal in general k-OCF gamesThe following simple proposition is an important first step in understanding the complexity of our problem.Proposition 3.2. Given a game G = (cid:6)N, W, v(cid:7) and a coalition c ∈ W with |supp(c)| = m, we can compute v1)2m).∗(c) in time O ((W max +Proof. Observe that(cid:10)∗v(c) = maxv(c), max{v∗(c − d) + v(d) | d ≤ c; d (cid:9)= c}(cid:11).(cid:13)) of each coalition cFurther, the number of coalitions d with d ≤ c is at most (W max + 1)m. Using this recurrence, we can compute the value (cid:13) ≤ c by dynamic programming in time O ((W max + 1)m); since there are at most (W max + 1)m∗(cvsuch coalitions, the bound on the running time follows. We can also find a coalition structure CS with w(CS) = c such that v(CS) = v∗(c) using standard dynamic programming techniques. (cid:2)Proposition 3.2 implies that if |supp(c)| is bounded by a constant, then v∗(c) can be computed in time polynomial in n and W max. Therefore, from now on we focus on finding the value of an optimal coalition structure for a large group of players. Note that this problem is non-trivial even if we focus on k-OCF games with a small value of k: we need to distribute the resources of a large group of players over many small (overlapping) coalitions. Indeed, even in the context of non-overlapping coalitions (which corresponds to games with W max = 1 in our model) it is NP-hard to find an optimal coalition structure [9], and this hardness result holds even if all coalitions with positive value have size at most 3 (in our model this corresponds to 3-OCF games). For discrete OCF games we can prove a stronger result: OptVal is NP-hard even for 2-OCF games; moreover, this is true even if W max = 3.Proposition 3.3. OptVal is NP-complete. The hardness result holds even for instances (G, c, V ) such that G is a 2-OCF game with W max = 3.Proof. First, we observe that OptVal is in NP: it suffices to guess a coalition structure CS such that w(CS) = c and check whether v(CS) ≥ V . Note that the size of this coalition structure is at most nW max, which is polynomial in the input size.For the hardness proof, we provide a reduction from Exact Cover by 3-Sets (X3C) [40]. Recall that an instance X = (cid:6) A, S(cid:7)of X3C is given by a finite set A, | A| = 3(cid:6), and a collection of subsets S = {S1, . . . , St} such that S j ⊆ A and |S j| = 3 for all j = 1, . . . , t. It is a “yes”-instance if A admits an exact cover by sets from S; that is, if there exists a subset S (cid:13) ⊆ S such that we have S ∩ T = ∅ (note that this implies |S (cid:13)| = (cid:6)).S∈S(cid:13) S = A, and for any two distinct S, T ∈ S (cid:13)Given an instance X = (cid:6) A, S(cid:7) of X3C, we construct a discrete 2-OCF game G(X ) = (cid:6)N, W, v(cid:7) with W max = 3 as follows. We have an agent ai of weight 1 for every element i ∈ A and an agent aS with weight 3 for every S ∈ S. The characteristic (cid:3)Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9783function is defined as follows. If i ∈ A, S ∈ S and i ∈ S, then the value of the coalition c with supp(c) = {ai, aS } and cai = caS = 1 is 2. Further, if S ∈ S then the value of the coalition c with supp(c) = {aS } and caS = 3 is 5. The value of every other partial coalition in the game G(X ) is 0.Consider a set S = {x, y, z} in S, and the respective set of agents G S = {aS , ax, a y, az}. Collectively, the agents in G Scan earn 6 if aS forms a partial coalition with each of ax, a y , and az, and contributes one unit of weight to each of these coalitions; in any other coalition structure, agents in G S earn at most 5. We will now use this observation to argue that X = (cid:6) A, S(cid:7) admits an exact cover if and only if v∗(W) ≥ 6(cid:6) + 5 (t − (cid:6)) = 5t + (cid:6).Indeed, if X is a “yes”-instance of X3C, then there exists some subset S (cid:13) ⊆ S of size (cid:6) that exactly covers A. In that case,∗v(W) ≥(cid:6)S∈S(cid:13)∗v(WG S ) +(cid:6)S /∈S(cid:13)∗v(WaS ) = 6(cid:6) + 5(t − (cid:6)).∗(W) =Conversely, suppose that X is a “no”-instance of X3C, and consider some coalition structure CS for W such that vv(CS). We say that an agent aS with S ∈ S, S = {x, y, z} is happy in CS if she forms coalitions with each of ax, a y and az, i.e. if CS contains coalitions cx, c y , and cz, where for each ξ ∈ {x, y, z} we have supp(cξ ) = {aS , aξ }, c= 1. Let H(CS)denote the set of all agents who are happy in CS. Since every coalition with a positive value contains an agent aS with S ∈ S, we have= caSξaξξ∗v(W) = v(CS) ≤(cid:6)(cid:6)v(c) +(cid:6)(cid:6)v(c)aS ∈H(CS)c∈CSaS ∈supp(c)aS /∈H(CS)c∈CSaS ∈supp(c)≤ 6|H(CS)| + 5(t − |H(CS)|) = 5t + H(CS).Note that if aS and aT are both happy in CS and S (cid:9)= T , then S and T are disjoint. Since there are at most (cid:6) − 1 pairwise disjoint sets in S, this means that the value of any coalition structure for W does not exceed 5t + (cid:6) − 1 < 5t + (cid:6). (cid:2)We remark that, in contrast, in the non-overlapping setting finding an optimal partition of players into coalitions of size 1 and 2 reduces to the problem of finding a maximum-weight matching, and is therefore polynomial-time solvable [42].Note that Proposition 3.3 is tight with respect to k: for 1-OCF games an optimal coalition structure consists of singletons ∗(ei) for each i ∈ N, which is easy by Proposition 3.2. However, it is not clear and therefore OptVal reduces to computing vif it is tight with respect to W max. Indeed, the case W max = 1 corresponds to the non-overlapping setting, and therefore, by the argument in the previous paragraph OptVal is easy for 2-OCF games with W max = 1. On the other hand, the complexity of OptVal in 2-OCF games with W max = 2 remains an open problem. However, even W max = 3 is a very strong constraint, and therefore it is fair to say that Proposition 3.3 severely limits our prospects of computing optimal coalition structures: even if agents are limited to pairwise interactions, and their weights are small constants, OptVal remains hard. Observe that the hardness of OptVal implies the hardness of most other problems of interest in the study of OCF games, such as computing the most that a set can gain by deviating, determining whether a given outcome of a game is stable, or deciding whether a given game admits a stable outcome. Thus, in order to proceed, we must first identify further constraints that make OptVal computationally tractable.3.2. Constraining communication in OCF gamesDemange [6] shows that if one assumes a hierarchical agent communication structure in a cooperative game, then the core of the game is not empty; moreover, if this game is superadditive, it is possible to find a core imputation in polynomial time. We will now show that this idea can also be used in the context of OCF games. Specifically, we make use of the concept of an agent communication graph [5,6]: this is a graph (cid:8) = (cid:6)N, E(cid:7), where N is the set of agents and the edges in Erepresent valid agent interactions. Given an OCF game G = (cid:6)N, W, v(cid:7) and a communication graph (cid:8) = (cid:6)N, E(cid:7), we define the game G reduced to (cid:8), denoted G|(cid:8) = (cid:6)N, W, v|(cid:8)(cid:7), as follows. For every c ∈ W , if the nodes in supp(c) induce a connected subgraph of (cid:8) then v|(cid:8)(c) = v(c), otherwise v|(cid:8)(c) = 0. We say that a discrete k-OCF game G has tree communication structure if there exists some tree T = (cid:6)N, E(cid:7) such that G = G|T .We will now show that we can compute optimal coalition structures in discrete 2-OCF games with tree communication structure in time polynomial in n and W max, thus overcoming the hardness result of Proposition 3.3. Note that, given a discrete 2-OCF game G, we can easily decide if it has tree communication structure, and identify the corresponding tree in time polynomial in n and W max: we construct (cid:8) by adding an edge {i, j} whenever there is coalition c in G with v(c) (cid:9)= 0, supp(c) = {i, j}, and then checking whether (cid:8) is a tree.Before we present our algorithm, we need to introduce additional notation for games on graphs, which will also be used later in the paper. Given a tree T = (cid:6)N, E(cid:7), pick an arbitrary vertex r ∈ N to be a root. Let T r be the resulting rooted tree; for each player i ∈ N, let T ir be the subtree of T r rooted in i, and let C i(T r) be the children of i in T r . We omit the subscript r from the notation when it is clear from the context. Let N((cid:8)) denote the set of nodes of a graph (cid:8). We can now state our positive result for 2-OCF games on trees.84Y. Zick et al. / Artificial Intelligence 271 (2019) 74–97Theorem 3.4. Given a discrete 2-OCF game G = (cid:6)N, W, v(cid:7) with tree communication structure, we can compute vin time polynomial in n and W max.∗(c) for every c ∈ WProof. It suffices to show how to compute vweights are given by c.∗(W): for an arbitrary c ∈ W we can simply consider the game where agent Let T be the communication graph of G. We choose an arbitrary player r ∈ N to be the root of T , and process the players in N from the leaves up to the root. The key observation used in our proof is that, in order to find an optimal allocation of agents’ resources, we need to decide, for each node in T , how to split its weight among collaborating with its subtree, collaborating with its parent, and working alone. Note that, by Proposition 3.2, for every pair of agents i, j ∈ N and every ∗∗pair of values x ∈ {0, . . . , W i}, y ∈ {0, . . . , W j} the quantities vi, j(x, y) can be computed in time polynomial in i (x) and v∗W max. Given a node i ∈ N, let C i = C i(T ) be the children of i in T , and let vT i (w) be the most that the agents in the subtree T i can make by working together (i.e. not counting the profit from i’s collaboration with its parent) if agent i allocates wunits of weight to working with agents in T i (and W i − w units of weight to working with its parent). We havev∗T i (w) =(cid:2)maxyi +a∈C i wa=w0≤xa≤W a ∀a∈C i⎧⎨⎩v∗i ( yi) +(cid:6)(cid:8)a∈C i∗i,a(wa, xa) + vv(cid:9)∗T a (W a − xa)⎫⎬⎭ .(1)Using this recurrence relation, we obtain the following dynamic programming algorithm for finding an optimal coalition structure.Suppose that we have already computed v∗T a (w) for all a ∈ C i and all w = 0, . . . , W a. Now, let us write C i = {a1, . . . , am}, and for j = 0, . . . , m − 1 let T i, j be the tree obtained from T i by removing the subtrees T a j+1. Observe that T i,0 is ∗the tree obtained from T i by removing all of its subtrees, i.e. the tree comprised of the singleton {i}. Let vT i, j (w) be the maximum revenue that can be generated if agent i invests w units of weight in working with T i, j ., . . . , T am∗T i,0 (w) = v(cid:13) (w) for all j∗i (w), and is therefore easy to compute by Proposition 3.2. Now, suppose that we have already ∗T i, j (w) in time polynomial in (cid:13) = 0, . . . , j − 1 and all w = 0, . . . , W i . Then we can compute vNote that vcomputed vW max as∗T i, j(cid:18)v∗i,a j (x, y) + v∗T i, j−1 (z) + v∗(cid:19)T a j (W a j − y).(2)v∗T i, j (w) = maxx+z=w0≤ y≤W a j∗∗T i,m (w), i.e. for any given value of w ∈ {0, . . . , W i} we can compute vFinally, we have vT i (w) in time polynomial in W max and |C i|. We process all nodes from the leaves to the root in this manner; the value of an optimal coalition structure for w is given by vT i (w) = v∗∗T r (W r). (cid:2)Example 3.5. Consider a discrete 2-OCF game, where N = {1, 2, 3, 4} and the set of edges of the communication graph is{{1, 3}, {2, 3}, {3, 4}}.∗∗Suppose we choose player 4 to be the root. Then our dynamic program first computes the values vand vT 1 (w) for w = 0, . . . , W 1T 2 (w) for w = 0, . . . , W 2, to determine what players 1 and 2 can accomplish on their own, for every possible weight.It then considers player 3. For each w = 0, . . . , W 3, it computes what player 3 can accomplish alone given weight w. Then it considers the tree that consists of players 1 and 3, and for each w = 1, . . . , W 3, it computes the total profit that this tree can generate assuming player 3 allocates w units of weight to it. To do so, it ‘guesses’ how much weight player 3 and player 1 allocate to working together (by going over all (W 1 + 1)(w + 1) possibilities), evaluates the productivity of ∗this collaboration by applying v1,3, looks up how much profit player 1 and player 3 can generate on their own given the remaining resources, and picks one of the (W 1 + 1)(w + 1) possibilities with the highest total profit.Next, the algorithm considers the tree that consists of players 1, 2, and 3. For each w = 0, . . . , W 3, it guesses how much weight each of the players 2 and 3 allocates to their joint project; player 2 allocates the rest of his weight to working alone, and player 3 allocates the rest of her weight to the tree that consists of 1 and 3, and the best such allocations have been computed at earlier steps; again, we choose the best of these (W 2 + 1)(w + 1) possibilities with regard to the total profit.Finally, the algorithm considers player 4. For each w = 0, . . . , W 4, it computes what he can earn on his own given weight w. It then goes over all possible collaborations between player 3 and player 4. For the case where player 3 allocates x units of weight to working with player 4, and player 4 allocates y units of weight to working with player 3, it computes ∗3,4(x, y) to evaluate this collaboration, and looks up (a) what player 4 can accomplish given weight W 4 − y and (b) what vplayers 1, 2, and 3 can accomplish given that player 3 allocates W 3 − x units of weight to working alone or with players 1 and 2, and adds up these three quantities; note that (a) and (b) have been computed by our dynamic program during previous steps. Finally, it chooses the pair (x, y) that maximizes the total profit, and outputs the respective profit.Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9785The reader may wonder if it is necessary to restrict both the structure of the communication graph and the maximum coalition size: indeed, perhaps OptVal is easy for discrete k-OCF games on trees even if k is large? Unfortunately, our next result shows that this is not the case, even for classic coalitional games (i.e. even if W max = 1).Proposition 3.6. OptVal is NP-hard even if the input game G = (cid:6)N, W, v(cid:7) has tree communication structure and W max = 1.Proof. Our reduction is from the Vertex Cover problem [40]. An instance of Vertex Cover is a tuple (cid:6)(cid:8), m(cid:7), where (cid:8) =(cid:6) A, E(cid:7) is a graph and m is an integer. It is a “yes”-instance if (cid:8) admits a vertex cover of size at most m, i.e. there exists a subset of vertices S ⊆ A such that |S| ≤ m and {i, j} ∩ S (cid:9)= ∅ for every {i, j} ∈ E.Given an instance (cid:6)(cid:8), m(cid:7) of Vertex Cover with (cid:8) = (cid:6) A, E(cid:7) and A = {1, . . . , n}, we construct the following instance of OptVal. We set the player set to be N = A ∪ {n + 1}. The communication graph T is a star with center n + 1; all vertices in A are leaves of T . We set W i = 1 for i ∈ N, i.e. our game is equivalent to a classic coalitional game. The characteristic function v is defined as follows. If supp(c) ∩ A is a vertex cover for (cid:8) and cn+1 = 1, then v(c) = n2. If |supp(c)| = 1, then v(c) = 1. For any other coalition c ∈ W we set v(c) = 0. Clearly, an optimal coalition structure in this game consists of a coalition S ∪ {n + 1}, where S is a minimum-size vertex cover for (cid:8), and n − |S| singletons; its value is n2 + (n − |S|). Thus, we have v∗(W) ≥ n2 + n − m if and only if (cid:8) admits a vertex cover of size m. (cid:2)To summarize, Propositions 3.3 and 3.6 indicate that, in order to find an optimal coalition structure in polynomial time, we need to both limit the size of each partial coalition in our coalition structure and impose a structural constraint on the overall communication pattern; dropping either of these two conditions makes our problem computationally hard (however, in Section 6 we will see that we can relax the latter constraint from trees to graphs of bounded treewidth). Note also that, to specify the profits that can be earned by a single agent i in an OCF game, we need to provide W i values, so there is little hope that any of our problems admit an algorithm whose running time is o(W max).In what follows, we only consider k-OCF games with k = 2. Extending our techniques to larger values of k would require us to reason about hypergraphs with far more complex interactions. Indeed, in Theorem 3.4, in order to decide on the best resource allocation for player i, one needs to consider how much i should allocate to its neighbors—i.e. its parent and its children—and to itself. Allowing for interactions beyond one’s neighbors (as is the case for k-OCF games with k > 2) would require us to consider much more complex collaboration patterns. While we conjecture that many of the results in this paper can be generalized to the case k > 2, we leave the formal analysis of this case for future work.4. Computing the profit from a deviationIn Section 3 we identified two key conditions for the computational tractability of finding an optimal coalition structure in an OCF game. The next computational problem that we would like to investigate is computing the maximum profit that a set of agents can obtain by deviating from a given outcome; understanding the complexity of this problem is a prerequisite for the computational analysis of stability in OCF games. Formally, for any given arbitration function A, we consider the following problem.Name: A-ArbValInput:Question:Is A∗(CS, x, S) ≥ V ?A discrete OCF game G = (cid:6)N, W, v(cid:7), a set S ⊆ N, an outcome (CS, x) of G, and a value V ∈ Q.Note that if A is the conservative arbitration function then A-ArbVal is no harder than OptVal: if the deviators obtain no payoffs from their joint projects with non-deviators regardless of the nature of their deviation, then the most they can make by deviating is exactly what they can earn on their own. However, for more complicated arbitration functions, A-ArbValcan be more complex than OptVal: in order to ensure that A-ArbVal can be decided in polynomial time, one must make assumptions not only about the structure of the game G, but also about the properties of the arbitration function A. In particular, the following proposition illustrates that it is not sufficient to require that A is polynomial-time computable.Proposition 4.1. There exists a polynomial-time computable arbitration function A and a family of dOCF games with 2 players such that if there exists an algorithm for A-ArbVal that runs in polynomial time on instances from this family then P = NP.Proof. We will show that if such an algorithm exists, it can be used to solve instances of Set Cover [40]. Recall that an instance of Set Cover is given by a set of elements A, a collection of subsets S = {S 1, . . . , St} ⊆ 2 A and (cid:6) ∈ N; it is a “yes”-instance if A can be covered by at most (cid:6) sets from S.Given an instance (cid:6) A, S, (cid:6)(cid:7) of Set Cover with |S| = t, consider a 2-player discrete OCF game where W 1 = W 2 = t + 2. We define v in the following manner. Either player gets a payoff of 1 for each unit of weight devoted to working alone, i.e. v 1(x) = v 2(x) = x for all x ∈ {0, . . . , t + 2}. We also set v 1,2(1, 1) = 2, and v 1,2(2, 2) = 10(t + 2). All other coalitions have value 0.We construct an outcome (CS, x) as follows. Players 1 and 2 form t + 1 coalitions: both of them allocate one unit of weight each to each of the first t coalitions, and two units of weight to the last coalition. That is, we set 86Y. Zick et al. / Artificial Intelligence 271 (2019) 74–97CS = (c1, . . . , ct, ct+1), where c j = (1, 1) for j = 1, . . . , t, and ct+1 = (2, 2). We define x = (x1, . . . , xt, y) as follows: for j = 1, . . . , t, x j = (0, 2) is the payoff division that corresponds to c j , and y = (5(t + 2), 5(t + 2)) corresponds to ct+1. In other words, we allocate the payoffs from c1, . . . , ct to player 2, and split the payoff from ct+1 equally between the players.We define the arbitration function A as follows. If player 1 wishes to deviate from (CS, x) by withdrawing from coalitions c j1 , . . . , c js , she receives no payoff from coalitions c1, . . . , ct , and only gets to keep her payoff from ct+1 if the collection {S j ∈ S | j /∈ { j1, . . . , js}} is a set cover for A. On all other inputs A behaves as the refined arbitration function. Note that Ais polynomial-time computable. Under this arbitration function, player 1 has two reasonable choices: either not deviate at all or withdraw as much weight as possible from c1, . . . , ct , while ensuring that the coalitions she keeps intact correspond to a set cover of A.We observe that A∗(CS, x, {1}) ≥ 5(t + 2) + t − (cid:6) if and only if (cid:6) A, S, (cid:6)(cid:7) is a “yes”-instance of Set Cover. Indeed, if there is a set cover S(cid:13) ⊆ S such that |S(cid:13)| ≤ (cid:6), then by withdrawing from the coalitions corresponding to S \ S (cid:13), and allocating the withdrawn resources to working alone, player 1 ensures that she receives a payoff of at least 5(t + 2) + t − (cid:6). On the other ensures that the payoff to player 1 is hand, if there exists a collection of coalitions CScorresponds to a set S (cid:13) ⊆ S with |S(cid:13)| ≥ t − (cid:6)at least 5(t + 2) + t − (cid:6), then ct+1 does not appear in CSsuch that S \ S(cid:13)is a set cover of A. (cid:2)(cid:13) ⊆ CS such that withdrawing from CS, and, moreover, CS(cid:13)(cid:13)(cid:13)Remark 4.2. We contrast Proposition 4.1 with Proposition 3.2: computing the most that a set of agents can earn with a given resource vector is computationally much easier than deciding what is the most it stands to gain by deviating. This issue does not arise in classic cooperative games: a set S assesses the desirability of deviation by considering the most it can make on its own, which only requires computing v∗(S).The proof of Proposition 4.1 indicates that the hardness of deciding A-ArbVal stems from the fact that the payoff from a coalition c to a deviating set S may be influenced by how the deviation of S affects other coalitions. Indeed, in the reduction used in Proposition 4.1, the payoff to player 1 from coalition ct+1 was determined by how agent 1 withdraws her weight from other coalitions. In other words, the arbitration function determines the payoff to a deviating set S based on the global behavior of S.This observation motivates the definition of a local arbitration function. Intuitively, an arbitration function A is said to be local if the payoff that the deviating set S receives from a coalition c under A depends only on the effect of S on c, and not on other inputs to A. This intuition is formally captured by the following definition.Definition 4.3. An arbitration function A is local if for every game G = (cid:6)N, W, v(cid:7), every outcome (CS, x) of G, every set S ⊆ N, every coalition c ∈ CS \ CS|S and every pair of deviations CS(cid:13)(cid:13) (c) it holds that αc(CS, x, S, CSof S from CS such that dCS(cid:13)) = αc(CS, x, S, CS(cid:13) (c) = dCS, CS(cid:13)(cid:13)).(cid:13)(cid:13)(cid:13)We note that the conservative, refined and optimistic arbitration functions are local: the payoff from the conservative i∈S xi(c) if d(c) = 0n and is arbitration function is 0 for all inputs; the payment from the refined arbitration function is i /∈S xi(c), 0}. In contrast, the 0 otherwise, and the payment from the optimistic arbitration function is max{v(c − d(c)) −arbitration function used in the proof of Theorem 4.1 is non-local. Another example of a non-local arbitration function is the sensitive arbitration function, as the payoff to a set from a coalition c depends on which agents in the support of c were hurt by the deviation of S from other coalitions.(cid:2)(cid:2)When one is limited to the class of efficiently computable local arbitration functions, it is indeed possible to decide A-ArbVal in time polynomial in |CS| and (W max + 1)r , where r is the size of the deviating set. The next theorem presents an algorithm for the optimization version of this problem.Theorem 4.4. If A is a polynomial-time computable local arbitration function then for any discrete OCF game G = (cid:6)N, W, v(cid:7), an outcome (CS, x) of this game and a set S ⊆ N with |S| = r we can compute A∗(CS, x, S) in time polynomial in r and (W max + 1)r .Proof. Let CS∩be the set of coalitions that involve both S and N \ S, i.e.∩ = {c ∈ CS | supp(c) ∩ S (cid:9)= ∅; supp(c) ∩ (N \ S) (cid:9)= ∅}.CSPlayers in S invest a weight of s = w(CS|S ) in partial coalitions among themselves. If they withdraw an additional weight ∗(s + t), plus the most that S can get from the arbitration function, which of t from CS, their total payoff would then be vdepends on the coalitions affected by this deviation. Thus, in order to determine the most that S can get by deviating from (CS, x), given that it withdraws a total weight of t, we must determine how to best withdraw this weight from CS. We write CS∩ = (c1, . . . , cm); since CS has at most (W max + 1)r coalitions that involve players in S, we have m ≤ (W max + 1)r.and a weight vector z ≤ c, we write αc(z) to denote the payoff from c that is allocated by Ato S if S withdraws z from c; this quantity is polynomial-time computable, and, since A is local, it does not depend on how S’s deviation affects other coalitions. Given a weight vector y with y ≤ WS , let us denote by A(y; (cid:6)) the most that the arbitration function A would give S if it withdraws y from the first (cid:6) coalitions in CS, where (cid:6) = 1, . . . , m; we set A(y; (cid:6)) = −∞ if it is not possible to withdraw y from c1, . . . , c(cid:6). Let AGiven a coalition c ∈ CS∩(y) = A(y; m).∩∩∩Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9787By definition, A(y; 1) = αc1 (y) if y ≤ c1 and A(y; 1) = −∞ otherwise. For (cid:6) > 1 we haveA(y; (cid:6)) = max{ A(z; (cid:6) − 1) + αc(cid:6) (y − z) | z ≥ 0n, z ≤ y, z ≤ c(cid:6)}.This shows that we can compute Amax{v∗(s + t) + A∩(t) | 0n ≤ t ≤ WS − s}, which concludes the proof. (cid:2)∩(y) = A(y; m) in time O(m(W max + 1)r). Finally, A∗(CS, x, S) can be computed as We have argued that it is easy to compute an optimal coalition structure for 2-OCF games where the communication graph is a tree. It turns out that a similar result holds for the problem of computing the maximum amount that a set can get by deviating. Indeed, the proof of Theorem 4.5 (below) builds on that of Theorem 3.4.Theorem 4.5. If A is a polynomial-time computable local arbitration function then A-ArbVal is decidable in time polynomial in nand W max whenever the input game G is a discrete 2-OCF game with a tree communication structure.Proof. Recall that an instance of our problem is given by a discrete 2-OCF game G = (cid:6)N, W, v(cid:7), an outcome (CS, x), a set S, and a value V . Let T be the communication tree associated with G. We can assume without loss of generality that S is connected in T ; indeed, if this is not the case, we can consider each connected component of S separately, find an optimal deviation for it, and add up the resulting payoffs (this argument uses the assumption that our arbitration function is local and every coalition with non-zero value has at most two players in its support).We choose an arbitrary r ∈ S to be the root of the communication tree. Since S is connected, this ensures that the parent of each agent in S \ {r} is also in S. We will now construct a new discrete 2-OCF game G(cid:13) = (cid:6)S, U, u(cid:7) that has S as its set ∗(U) = A∗(CS, x, S); we can then use the algorithm from the proof of Theorem 3.4 to compute of players and satisfies u∗(U). The game G(cid:13)is constructed as follows. For each i ∈ S we set U i = W i . Moreover, for every pair of agents i, j ∈ S and uweights w i, w j with 0 ≤ w i ≤ U i , 0 ≤ w j ≤ U j , we set ui, j(w i, w j) = v i, j(w i, w j). It remains to describe how to compute ui(w i) for i ∈ S; our goal is to define u on such coalitions so as to capture the payoff that an agent in S could earn in G by collaborating with her non-deviating neighbors and working on her own.Consider an agent i, and let D i be the set of non-S neighbors of i in T . Let c1, . . . , cm be the list of coalitions in CS that i(cid:6), let Ai(c(cid:6), z) denote the payoff from c(cid:6) that A allocates to forms with members of D i . For each (cid:6) = 1, . . . , m and 0 ≤ z ≤ cii if i leaves z units of her weight invested in c(cid:6); this quantity is well-defined since A is a local arbitration function. Further, j , let β i( y; (cid:6)) be the maximum payoff that i can obtain under A from c1, . . . , c(cid:6) if she for (cid:6) = 0, . . . , m and 0 ≤ y ≤leaves y units of her weight invested in these coalitions. We have β i (0; 0) = 0 and(cid:2)(cid:6)j=1 ci(cid:19)(cid:18)β i( y − z; (cid:6) − 1) + Ai(c(cid:6), z).(3)β i( y; (cid:6)) =Now, we definemax0≤z≤min{ y,ci(cid:2)(cid:6)(cid:6)−1y−z≤j=1 cij}ui(w) =max0≤ y≤min{w,(cid:2)mj=1 cij(cid:18)β i( y; m) + v(cid:19)∗i (w − y).}By construction, ui(w) is the maximum profit that i can make by keeping w units of her weight invested into collaborating with agents in N \ S and working on her own; in the context of G(cid:13), this is exactly what i can accomplish without interacting with other players in S. Thus, this construction makes each agent in S ‘responsible’ for maximizing its profit from its ∗(U) = A∗(CS, x, S).collaborations with agents in N \ S; it follows that uTo complete the proof, we observe that vβ i( y; m) can be computed in time polynomial in n and W max using the recurrence relation (3). Thus, the game G(cid:13)constructed in time polynomial in n and W max; computing u∗(U) is then easy by Theorem 3.4. (cid:2)∗i (z) can be computed in time polynomial in W max by Proposition 3.2, and can be It is not hard to verify that the proof of Theorem 4.5 goes through even if the overall communication graph is not a tree, as long as the deviating set S is an acyclic subgraph of the communication graph. This is because in 2-OCF games players interact in pairs; thus, if an agent i ∈ S decides to withdraw resources from a coalition c /∈ CS|S , that coalition can contain at most one other agent j, and therefore, no other agent in S is involved in c.5. Computing A-stable outcomesHaving provided efficient procedures for computing optimal coalition structures and deviations in discrete 2-OCF games whose communication graphs are trees, we are ready to analyze the computational complexity of stability in this class of games. Recall that an OCF game is A-stable if there exists some outcome (CS, x) such that no subset of N can profitably deviate from (CS, x) under A, or, equivalently (Theorem 2.4), if for all S ⊆ N we havep S (CS, x) ≥ A∗(CS, x, S).88Y. Zick et al. / Artificial Intelligence 271 (2019) 74–97We will now formulate the computational problem that is associated with checking the stability of a given outcome.Name: A-CheckCoreInput:Question:Is (CS, x) in the A-core of G?A discrete OCF game G = (cid:6)N, W, v(cid:7) and an outcome (CS, x) of G.This problem is closely related to that of computing A∗: an outcome (CS, x) is in the A-core if and only if the excesse(CS, x, S) = A∗(CS, x, S) − p S (CS, x) is non-positive for all coalitions S ⊆ N. Thus, we need to check whether there exists a subset S ⊆ N with e(CS, x, S) > 0.We will now present an algorithm for deciding A-CheckCore in 2-OCF games on trees.Theorem 5.1. If A is a polynomial-time computable local arbitration function then A-CheckCore is decidable in time polynomial in n and W max whenever the input game G is a discrete 2-OCF game with a tree communication structure.Proof. Fix an outcome (CS, x), and set pi = pi(CS, x) for all i ∈ N.Just as in the proof of Theorem 4.5, it suffices to consider deviations by connected coalitions: if e(CS, x, S) > 0 and S is (cid:13)) > 0. Again, we pick an arbitrary r ∈ N as not connected, then some connected component Sa root. We say that a connected subset S ⊆ N is rooted at i ∈ N if i ∈ S and the members of S form a subtree of T i (recall that T i is the subtree of T rooted at i). We observe that every connected set S ⊆ N is rooted at a unique i ∈ N. Given a vertex i, let E i denote the maximum excess of a connected set rooted at i, that is,of S also satisfies e(CS, x, S(cid:13)E i = max {e(CS, x, S) | S is rooted at i} .Clearly, (CS, x) is not A-stable if and only if E i > 0 for some i ∈ N. It remains to show that each E i can be computed in time polynomial in n and W max. As before, we proceed from the leaves to the root, and terminate (and report that (CS, x)is not A-stable) if we discover a vertex i with E i > 0. If E i ≤ 0 for all i ∈ N, we report that (CS, x) is A-stable.Given two agents i, j ∈ N, let w i, j denote the total weight that i assigns to interacting with j under CS, i.e.(cid:6)w i, j =ci.c:supp(c)={i, j}Observe that since G is a 2-OCF game, there is no loss of generality in assuming that the support of every coalition that involves both i and j is exactly {i, j}. We now define two auxiliary quantities. First, given a (non-deviating) neighbor jof i and an integer w, 0 ≤ w ≤ w i, j , we define β i, j(w) to be the most that i can receive from A for her contribution to coalitions that she formed with j in (CS, x) assuming that she keeps a total weight of w in these coalitions. Second, for each w = 0, . . . , W i , we define D i(w) to be the maximum excess of a subset rooted at i if i were to contribute w to T i and receive nothing for whatever collaboration she has with her parent p(i). In this notation,E i =max0≤W i −w≤w i,p(i)(cid:18)(cid:19)D i(w) + β i,p(i)(W i − w);the condition W i − w ≤ w i,p(i) means that we treat p(i) as a non-deviator. By Theorem 4.4, β i,p(i)(W i − w) is computable in time poly(W max). It remains to show how to compute D i(w) in time poly(n, W max) for all i ∈ N and all w with W i −w i,p(i) ≤ w ≤ W i .Consider an agent i with children C i = {i1, . . . , i(cid:6)}, and suppose that we have computed D i j (z) for each i j ∈ C i and each zsuch that W i j − w i j ,i ≤ z ≤ W i j (this encompasses the possibility that i is a leaf, as C i = ∅ in that case). For j = 0, . . . , (cid:6), let T i, j be the tree obtained from T i by removing subtrees rooted at i j+1, . . . , i(cid:6). Let D i(w; j) be the maximum excess of a set rooted at i that is fully contained in T i, j , assuming that i contributes w to T i, j and receives nothing from her collaborations with her parent or her children i j+1, . . . , i(cid:6); we have D i(w) = D i(w; (cid:6)). We will compute D i(w; j) by induction on j.We have D i(w; 0) = v∗i (w) − pi for all w = W i − w i,p(i), . . . , W i . Now, consider j > 0. Agent i can either include i jin the deviating set or deviate (partially or fully) from the coalitions that she forms with i j in (CS, x). Thus, D i(w; j) =max{D1, D2}, where{D i( y; j − 1) + v∗i,i j(w − y, z) + D j(W i j − z)}D1 = max0≤ y≤wi j0≤z≤WandD2 = max0≤z≤wi,i j{D i(w − z; j − 1) + β i,i j (z)}.Since both quantities D1 and D2 can be computed in time polynomial in W max, we can efficiently compute D i(w; j), and hence also D i(w) and E i . (cid:2)Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9789In classic coalitional games, one can use an algorithm for checking whether a given outcome is in the core in order to decide whether a given coalition structure CS can be stabilized. It turns out that one can use this approach for OCF games; however, it can only be applied if the arbitration function satisfies additional constraints.Formally, we consider the following computational problem.Name: A-IsStableCSInput:Question:A discrete OCF game G = (cid:6)N, W, v(cid:7) and a coalition structure CS for G.Is there an imputation x such that (CS, x) in the A-core of G?Consider a coalition structure CS = (c1, . . . , cm). Clearly, (cid:6)G, CS(cid:7) is a “yes”-instance of A-IsStableCS if and only if there exists a collection of vectors x = (x1, . . . , xm) that satisfies the following system of constraints.(cid:6)i∈supp(c j )m(cid:6)(cid:6)i∈Sj=1=xijv(c j)∀ j ∈ {1, . . . , m}≥ A∗xij(CS, x, S) ∀S ⊆ N≥xij0∀ j ∈ {1, . . . , m}; ∀i ∈ N(4)(5)(6)The constraints in (4) are known as the efficiency constraints; together with the non-negativity constraints (6) they ensure that x is indeed a valid imputation. The constraints in (5) are referred to as stability constraints; they ensure that (CS, x) is in the A-core of G. Note that the number of constraints in (5) is exponential in n.In general, A∗(CS, x, S) need not be a linear function of x; however, if it is, the system (4)–(6) consists of linear con-straints, and the algorithm in the proof of Theorem 5.1 can be used to obtain a polynomial-time separation oracle for it. Recall that a separation oracle for a linear program is an algorithm that takes a candidate solution of this linear program as an input; it then reports if this solution satisfies all constraints, and, if not, outputs a violated constraint. It is well-known that we can solve a linear program in polynomial time as long as we have a polynomial-time separation oracle for it [43]. In particular, for the conservative arbitration function Ac constraints (4)–(6) are linear, since A∗∗(S)and hence the right-hand-side of each constraint does not depend on x. Consequently, it follows from Theorem 5.1 that Ac -IsStableCS is decidable in time polynomial in n and W max whenever the input game G is a discrete 2-OCF game with a tree communication structure.c (CS, x, S) = vFor the refined arbitration function Ar the situation is a bit more complicated. The following example shows that r (CS, x, S) is not a linear function of x.A∗Example 5.2. Consider a two-player discrete OCF game G with N = {1, 2}, W 1 = 1, W 2 = 1 and the characteristic func-tion v such that v(1, 1) = 10, v(1, 0) = v(0, 1) = 5, v(0, 0) = 0 (i.e. G is equivalent to a non-overlapping game). Consider an outcome (CS, x), where CS consists of a single coalition (1, 1). Under the refined arbitration function, Player 1 would like to withdraw his contribution to this coalition if and only if x11 < 5 and A∗≥ 5. This behavior is clearly non-linear. Note a subtle difference between the behavior of the conser-vative and refined arbitration functions: under the former agent 1 is punished simply for announcing his desire to deviate, whereas under the latter the arbitration function checks if he actually withdrew any resources from existing coalitions.1 < 5; thus, we have A∗r (CS, x, {1}) = 5 if x1r (CS, x, {1}) = x11 if x11However, for Ar we can obtain an equivalent system of constraints by replacing constraint (5) with a collection of linear constraints, thereby obtaining a linear program. We can then use Theorem 5.1 to obtain a separation oracle for this linear program. To prove this, we will now express A∗r (CS, x, S) as a maximum of a finite collection of linear functions of x.For every CS(cid:13) ⊆ CS \ CS|S , the payoff that S receives under Ar if it withdraws from coalitions in CS(cid:13)(but not from other coalitions with non-deviators), is a linear function of x, which we denote by ρS (CSρS (CS(cid:13)) = v∗(t) +(cid:6)(cid:6)i∈Sc j ∈CS\CS(cid:13)xij,(cid:13)); we havewhere tmaxCS(cid:13)⊆CS\CS|S ρS (CS(cid:13)), and constraintis the vector of resources available to S once they deviate from CS(cid:13). Then we have A∗r (CS, x, S) =(cid:6)m(cid:6)i∈Sj=1xij≥ A∗r (CS, x, S)can be replaced by the collection of constraints90Y. Zick et al. / Artificial Intelligence 271 (2019) 74–97(cid:6)m(cid:6)i∈Sj=1≥ ρS (CS(cid:13)xij) for each CS(cid:13) ⊆ CS \ CS|S .It remains to observe that the algorithm from the proof of Theorem 5.1 can be used to pinpoint which of these new constraints (if any) are violated by a given candidate solution; indeed, using standard dynamic programming techniques we can identify a specific deviation that corresponds to a positive excess.A similar argument applies in the case of the optimistic arbitration function: in the discrete setting A∗o (CS, x, S) can be computed as a maximum of a finite number of linear functions of x.We can summarize these observations as follows.Proposition 5.3. For A ∈ {Ac, Ar, Ao} the problem A-IsStableCS is decidable in time polynomial in n and W max whenever the input game G is a discrete 2-OCF game with a tree communication structure.(cid:13)Proposition 5.3 implies that we can check whether a given discrete 2-OCF game with a tree communication structure admits an A-stable outcome for A ∈ {Ac, Ar, Ao} by going over all possible coalition structures, and, for each of them, checking if this coalition structure can be stabilized; by Proposition 5.3 the latter step can be performed in time polynomial in n and W max. Nevertheless, this solution is likely to be impractical, since the number of possible coalition structures can be huge. We note that, unlike in non-overlapping cooperative games, it is not sufficient to identify an optimal coalition structure: recall that Example 2.6 describes a game G that admits two optimal coalition structures, CS and CS, such that can be paired with an imputation to form an outcome in the refined core, while (CS, x) is not in the refined core of GCSfor any x ∈ I(CS) (the earliest example of this kind is due to Zick et al. [3], Example 5.17).In fact, for A ∈ {Ar, Ao} we are not aware of any efficient algorithms for deciding whether the A-core of an OCF game is not empty, even if the input game is a 2-OCF game with tree communication structure; nor do we have any hardness results for this problem. On the positive side, it is not hard to see that every discrete 2-OCF game with tree communication structure admits an outcome in the conservative core. Indeed, consider the discrete superadditive cover of any such game (as defined by Zick et al. [3]), which is a classic superadditive coalitional game on a tree. Theorem 5.3 of Zick et al. [3] says that the conservative core of an OCF game is not empty if and only if the core of its discrete superadditive cover is not empty. Our claim now follows from the celebrated result of Demange [6] that the core of a coalitional game on a tree is not empty. We also provide a direct proof that the conservative core of every discrete 2-OCF game on a tree is non-empty in the preliminary version of our paper [44].(cid:13)6. Beyond tree communicationsIn previous sections, we have shown that for discrete 2-OCF games with tree communication structure many relevant stability-related questions can be answered in time polynomial in the number of players n, and the maximum player weight W max. We will now show how to extend our algorithms to 2-OCF games whose communication graphs are close to being trees, i.e., have bounded treewidth [45].In what follows, we assume that we are given a 2-OCF game whose communication graph (cid:8) is connected; if this is not the case, we can simply apply our methods to each of the connected components of (cid:8) separately.Given a graph (cid:8) = (cid:6)N, E(cid:7), a tree decomposition of (cid:8) is a tree T whose nodes are subsets of N (we write V (T ) to denote the nodes of T and E(T ) to denote its edges), which satisfies the following two conditions:1. if e ∈ E then there is some node S ∈ V (T ) such that e ⊆ S;2. for every two nodes S, S(cid:13) ∈ V (T ) each vertex in S ∩ S(cid:13)appears in every node on the (unique) path between S and S(cid:13).Given a tree decomposition T of a graph (cid:8), setwidth(T ) = max {|S| | S ∈ V (T )} − 1.The treewidth of a graph (cid:8) is defined astw((cid:8)) = min {width(T ) | T is a tree decomposition of (cid:8)} .The role of −1 in the expression for width(T ) is to ensure that the treewidth of a tree is one; in fact, a graph is a tree if and only if its treewidth is one.We say that a problem is fixed parameter tractable with respect to a parameter k if it can be solved in time f (k)nc , where is a computable function of k and c is a constant independent of k and n. Intuitively, this is the class of problems that fadmit efficient algorithms for small values of k.Treewidth is often used as a parameter in the parameterized complexity analysis of graph-related combinatorial prob-lems; for instance, Courcelle’s theorem [46] states that any graph property that can be formulated using a fairly standard set of operators (monadic second order logic) is fixed parameter tractable with respect to the treewidth of the graph. Treewidth has also been invoked in the study of cooperative games (see Section 1.2).Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9791We now generalize the algorithmic results derived in previous sections to 2-OCF games whose communication graphs have bounded treewidth; more specifically, we provide generalizations of Theorems 3.4, 4.5 and 5.1 to games whose com-munication graphs have a treewidth of k. Importantly, it is known that deciding whether the treewidth of a communication graph (cid:8) = (cid:6)N, E(cid:7) equals k (and finding a tree decomposition of (cid:8) of width at most k with at most k|N| nodes) is fixed parameter tractable with respect to k [47].Throughout this section, we overload notation and write tw(G) to denote the treewidth of the communication graph of a discrete 2-OCF game G.Theorem 6.1. Given a 2-OCF game G = (cid:6)N, W, v(cid:7) and a coalition c we can compute v1)tw(G).∗(c) in time polynomial in n and (W max +Proof. As before, it suffices to consider the case c = W. Let T be a tree decomposition of the communication graph of Gsuch that width(T ) = tw(G). Let us choose some node R ∈ V (T ) to be the root of T . Given a node X ∈ V (T ), we denote by T X the subtree of T rooted at node X ; the parent of X in T is denoted by p( X) (with the convention that p(R) = ∅), and the set of children of X in T is denoted by C X . We process the nodes from the leaves to the root; recall that the number of nodes is bounded by n · tw(G).Consider a node X . By the properties of the tree decomposition, the agents in X who appear in nodes outside of T Xare exactly the agents in X ∩ p( X). These agents need to decide how to split their resources between working with agents who appear in V (T X ) and working with agents who appear outside of V (T X ) (note that agents in X ∩ p( X) belong to both groups; however, we will see that this does not cause any difficulties). To capture this decision, for every vector q with 0 ≤ q ≤ WX∩p( X), we define opt(T X (q)) to be the value of an optimal coalition structure among the agents in ∪V (T X ), with the restriction that each agent i ∈ X ∩ p( X) contributes qi units of resource to this coalition structure. Note that ∗(W) = opt(T R (W)).vWe will now explain how to compute opt(T X (q)) for every node X and every q with 0 ≤ q ≤ W X∩p( X). Order the children of X in T as Y 1, . . . , Ym. We say that a collection of vectors (z1, . . . , zm) is valid with respect to q if 0 ≤ z(cid:6) ≤ WY (cid:6)∩X≤ qi ; we denote the set of all such collections by Z( X, q). for each Y (cid:6) ∈ C X , and for each i ∈ X ∩ p( X) it holds that m(cid:6)=1 zi(cid:6)Then(cid:2)(cid:20)(cid:21)T X (q)=optmax(z1,...,zm)∈Z( X,q),(cid:2)myi ≤qi−(cid:6)=1 zi0≤y≤WX ,(cid:6) for all i∈ X∩p( X)(cid:22)∗v(y) +m(cid:6)(cid:6)=1(cid:20)(cid:21)T Y(cid:6) (z(cid:6))opt(cid:23);note that, since the collection of vectors (z1, . . . , zm) is valid, the set of vectors y satisfying our constraints is non-empty. ∗(y) in time O ((W max + 1)2tw(G)). Observe also that, since |supp(y)| ≤ | X| ≤ tw(G), by Proposition 3.2, we can compute vHowever, the expression above does not yet lead to an efficient algorithm for computing opt(T X (q)), since there are expo-nentially many ways to choose a valid collection of vectors.To deal with this issue, similarly to the proof of Theorem 3.4, we employ dynamic programming. For j = 0, . . . , m, let T X; j be the tree obtained from T X by removing the subtrees rooted at all but the first j children of X , and for each q with 0 ≤ q ≤ W X∩p( X) let opt(T X (q; j)) be the value of the best coalition structure formed by agents in ∪V (T X; j) assuming that ∗(min{WX , q})each agent i ∈ X ∩ p( X) contributes qi units of resource to this coalition structure. Then T X (q; 0) is simply v(where the minimum is taken coordinate-wise), and for j = 1, . . . , m we have(cid:20)(cid:21)T X (q; j)opt(cid:18)(cid:20)(cid:21)(cid:20)(cid:21)(cid:19)=max∩ X ,Y j0≤z≤W0≤y≤q,yi +zi ≤qi for all i∈ X∩p( X)optT X (y; j − 1+ optT Y j (z).Note that opt(T X (q; m)) = opt(T X (q)). Thus, assuming we have computed opt(T Y (z)) for all Y ∈ C X and all z with 0 ≤ z ≤WY ∩X , we can compute opt(T X (q)) in time polynomial in (W max + 1)tw(G) and linear in |C X |. Hence the total running time of our algorithm is polynomial in (W max + 1)tw(G) and linear in n · tw(G). (cid:2)The problem of computing the maximum amount that a set can get by deviating is also fixed parameter tractable with respect to treewidth. To prove this, we use the same approach as in the proof of Theorem 4.5: in order to compute the most that a set S can get by deviating from an outcome (CS, x), we construct an auxiliary game G(cid:13) = (cid:6)S, U, u(cid:7) that satisfies ∗(U) = A∗(CS, x, S) (the algorithm to construct u is given in the proof of Theorem 4.5 and does not U i = W i for i ∈ S and udepend on the structure of the communication graph), and apply the algorithm described in the proof of Theorem 6.1 to this game. Since tw(G(cid:13)) ≤ tw(G), we obtain the following theorem.Theorem 6.2. If A is a polynomial-time computable local arbitration function then A-ArbVal is decidable in time polynomial in nand (W max + 1)tw(G) whenever the input game G is a discrete 2-OCF game.Finally, we provide an algorithm for deciding whether a given outcome is in the A-core of a given 2-OCF game G that runs in time polynomial in n and (W max + 1)tw(G).92Y. Zick et al. / Artificial Intelligence 271 (2019) 74–97Theorem 6.3. If A is a polynomial-time computable local arbitration function then A-CheckCore is decidable in time polynomial in n and (W max + 1)tw(G) whenever the input game G = (cid:6)N, W, v(cid:7) is a discrete 2-OCF game.Proof. Suppose that we are given an outcome (CS, x) of G. Our goal is to decide whether there exists a subset T ⊆ N such that e(CS, x, T ) > 0; as argued in the proof of Theorem 4.5, it suffices to restrict our attention to connected subsets of N. Again, let T be a tree decomposition of the communication graph of G whose width is tw(G), and choose some R ∈ V (T )to be the root of T . For each X ∈ V (G) let T X be the subtree of T rooted at X , and let C X denote the set of children of X . Given a connected subset T ⊆ N, we say that T is rooted at ( X; S), where X ∈ V (G), S ⊆ X if T ⊆ V (T X ), T (cid:2) V (T Y ) for each Y ∈ C X (i.e., X is the deepest node such that T ⊆ V (T X )) and T ∩ X = S. Observe that, since T is connected, the properties of tree decompositions imply that S is not empty. By construction, for each connected subset T of N there is a unique pair ( X; S) with X ∈ V (G), S ⊆ X such that T is rooted at ( X; S); this provides us with a convenient way to systematically go over all connected subsets of agents.Given a node X , a non-empty subset S ⊂ X , a vector q with 0 ≤ q ≤ WS , and a subset T rooted at ( X; S), let A∗q(T )be the maximum payoff that T can earn by deviating from (CS, x) under A with the restriction that post-deviation each agent i ∈ S only allocates qi units of resource to productive work, and receives no payoff for the remaining 1 − qi units of resource. While this definition may seem counterintuitive at first (why would we want an agent to waste her resources?), we need it to explain what happens when an agent in S splits her resources between agents that appear within T X and agents that appear outside of that tree. LetE X;S (q) =maxT is rooted at ( X;S)A∗q(T ).Observe that it suffices to decide whether E X;S (WS ) > 0 for some X ∈ V (T ) and ∅ (cid:9)= S ⊆ X , i.e., to compute at most n · tw(G) · 2tw(G) quantities.Again, we process the nodes from the leaves to the root. Consider a node X and a non-empty subset S ⊆ X , and suppose that we have already computed E Y ;S. Let us order the nodes in C X as Y 1, . . . , Ym, and for j = 1, . . . , m set S j = S ∩ Y j , S j = Y j \ ( X \ S). For j = 0, . . . , m, let T X; j be the tree obtained from T X by removing the subtrees rooted at all but the first j children of X .(cid:13) (cid:9)= ∅ and all z with 0 ≤ z ≤ WS(z) for all Y ∈ C X , all S(cid:13) ⊆ Y with S(cid:13)(cid:13)It follows from the properties of tree decompositions that for every connected set T rooted at ( X; S) we have S j ⊆T ∩ Y j ⊆ S j for each j = 1, . . . , m and the sets S j \ S j are pairwise disjoint. Consequently, for each q with 0 ≤ q ≤ WS we defineE X;S; j(q) =maxT (cid:6) is rooted at S(cid:13)(cid:6)⊆S(cid:6),(cid:6)=1,..., jWe then have E X;S (q) = E X;S;m(q).S(cid:6)⊆S(cid:13)(cid:6)A∗q(∪(cid:6)=1,..., j T (cid:6)).To compute E X;S;0(q), it suffices to determine what is the maximum amount that the agents in S can make when each i ∈ S optimally withdraws her resources from existing collaborations with agents in N \ S so as to invest them into collaborating with other agents in S, given that she has to discard W i − qi units of resource. The algorithm in the proof of Theorem 4.4 can be adapted to compute this quantity in time polynomial in (W max + 1)|S|: specifically, we haveE X;S;0(q) =max0≤s+t≤WS −q∗v(s + t − (WS − q)) + A∩(t)),where s and A∩(t) are defined in the proof of Theorem 4.4.Now, consider computing E X;S; j for j ≥ 1. We need to decide which of the agents in S j \ S j will join the deviating set, how much they should contribute, and how much of S’s resources should be allocated to working with these agents. We (cid:13)| ≤make this decision by considering all available choices (the number of these choices is bounded by 2(W max + 1)3·tw(G)):E X;S; j(q) =E X;S; j−1(y) + E Y j ;S|Y j |(W max + 1)|S|+|Smax(z)(cid:18)(cid:19).(cid:13)S j ⊆S(cid:13)⊆S j ,0≤z≤WS(cid:13)0≤y≤q, yi+zi ≤qi for all i∈SNote that we choose Sdecision for Y j should be consistent with this choice.(cid:13)from S j : by choosing S, we have already decided which of the agents in X are deviators, and our It follows that we can compute E X;S (q) in time polynomial in |C X | and (W max + 1)tw(G); this completes the proof. (cid:2)7. Linear bottleneck games and the optimistic coreIn this section, we move away from the discrete setting considered so far, and shift our attention to the standard model of OCF games, where agents have rational weights. We describe a class of games motivated by fractional combinatorial Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9793optimization scenarios, which we call linear bottleneck games, and show that every game in this class has a non-empty optimistic core, and, moreover, OptVal, ArbVal, CheckCore and IsStableCS admit polynomial-time algorithms.We first show that for linear bottleneck games an optimal coalition structure can be found using linear programming. We then use the dual LP solution to find an imputation in the optimistic core. Our results in this section build on prior work on classic cooperative game theory, where dual solutions have been used to derive payoff divisions that guarantee core stability [19,48,8]; indeed, one interpretation of our results is that linear bottleneck games admit outcomes that are stable not just when the deviators are forced to make all-or-nothing decisions concerning their collaborations with other agents (as in the classic setting), but also when the deviators are given considerably more freedom in reallocating their resources.We start by formally defining the class of games that will be the focus of this section.Definition 7.1. A Linear Bottleneck Game (LBG) is a tuple G = (N, ω, T), where N = {1, . . . , n} is a set of players, ω =(ω1, . . . , ωn) is a list of players’ weights, and T = (T 1, . . . , Tm) is a list of tasks, where each task T j is associated with a set of players A j ⊆ N who are needed to complete it, as well as a value π j ∈ R+. We assume that A j (cid:9)= A j(cid:13) for j (cid:9)= j, and for each i ∈ N there is a task Tk ∈ T with Ak = {i}. The characteristic function of this game is defined as follows: given a partial coalition c ∈ [0, 1]n, we set(cid:13)⎧⎨v(c) =⎩π j · mini∈ A j0ciωiif supp(c) = A j for some j ∈ [m]otherwise.The term ‘bottleneck’ refers to the fact that the value of a coalition is determined by the agent(s) making the smallest contribution; these games are linear in the sense that if each agent increases the amount of weight she contributes to a partial coalition by a factor of α, the value of the coalition would increase by a factor of α. The assumption that A j (cid:9)= A j(cid:13)for j (cid:9)= jensures that the characteristic function is well-defined; that is, each task is associated with a unique set of players that can complete it. Finally, since each player can work on her own (possibly earning a payoff of 0), all resources are used. This assumption will be useful when proving our results, since it allows us to invest unused agent resources in dummy tasks.(cid:13)7.1. ExamplesLBGs can be used to describe a variety of settings; an overview of their descriptive power is provided by Deng et al. [19]. For the sake of exposition, we present three examples below.First, LBGs capture multicommodity flow games [7,8]. We have described these games informally in Section 1; we will now present them in more detail.There are two types of agents in a multicommodity flow game: suppliers and distributors. An instance of the game is described by a directed graph (cid:8) with an edge set E((cid:8)) and a vertex set V ((cid:8)), where each edge e ∈ E((cid:8)) is associated with a distributor and has capacity κ(e) ∈ R+, and a set of suppliers S, where each supplier i ∈ S is described by a pair of nodes (si, ti) ∈ V ((cid:8)) × V ((cid:8)), a demand di ∈ R+ and a per-unit price π i . The commodity owned by i can be transferred from si to ti via a path in (cid:8); thus, each task is associated with a supplier i and a set of distributors that corresponds to a simple si –ti path in (cid:8). The contribution of a supplier to a partial coalition is the amount of her goods that she sends via the respective path; the contribution of a distributor is the capacity he allocates to the respective good. The value of a partial coalition is the minimum contribution of its members times the per-unit price of the respective good. We note that under this description the number of possible tasks may be exponential in the number of agents. However, as discussed by Markakis and Saberi [8], there exist other, more succinct, ways of describing the problem that result in the same solution, and to which our techniques can be applied. We chose to focus on the description above, as it highlights the fact that multicommodity flow games are linear bottleneck games.Linear bottleneck games can also model network routing: again, we have a directed graph (cid:8) = (V ((cid:8)), E((cid:8))) and a set of supplier agents S, where each supplier i is associated with a pair of source-sink destinations (si , ti) ∈ V ((cid:8)) × V ((cid:8)) and per-unit payoff π i . However, now the distributor agents are associated with vertices, with each vertex v ∈ V ((cid:8)) having a processing power κ(v), and each task is associated with a supplier i and a set of nodes on a simple si –ti path in (cid:8); moreover, the demand of each supplier is unlimited, with the only constraint on the value of a partial coalition stemming from limitations on the processing power.Finally, linear bottleneck games provide a simple model of collaborative production. Consider a bipartite graph with parts A and B, where each agent i ∈ A ∪ B is associated with a quantity ωi ∈ R+ and each edge (a, b) ∈ A × B is associated with a value π a,b ∈ R+. Intuitively, there are two types of ingredients (say, dairy and fruit), each agent in A possesses a certain amount of the first ingredient, each agent in B possesses a certain amount of the second ingredient, and one can combine one unit of the first ingredient and one unit of the second ingredient to make a good that can be sold in the market (say, yogurt or ice cream). Moreover, for each pair of agents (a, b) ∈ A × B there is a price π a,b such that one unit of good produced by combining their ingredients can be sold for π a,b (in our example, this price depends on a and b, because some milk producers provide organic milk, while others do not, and fruit growers specialize in different fruits). Note that tasks here correspond to the edges of the graph.94Y. Zick et al. / Artificial Intelligence 271 (2019) 74–977.2. Computing stable outcomes in LBGsWe start by presenting some simple observations on the structure of optimal coalition structures in LBGs.Lemma 7.2. For each linear bottleneck game G = (cid:6)N, ω, T(cid:7), there is an optimal coalition structure CS such that(a) for all c ∈ CS we have ciωi = c jω j for all i, j ∈ supp(c).(b) w i(CS) = 1 for all i ∈ N.(c) For each T j ∈ T the set of players A j forms at most one coalition in CS.Proof. To see that condition (a) holds, observe that if ciωi > c jω j for some partial coalition c and some player i ∈ supp(c), we can obtain a coalition structure with the same or higher value by withdrawing ci ωi − c jω j units of player i’s weight from c and reallocating them to the task that i can perform on her own. Similarly, condition (b) is satisfied because any agent can allocate unused resources to working on her own. Finally, condition (c) is satisfied as we can merge two coalitions with the same support without lowering the value of a coalition structure. (cid:2)Lemma 7.2 implies that an optimal coalition structure can be described by a list ν1, . . . , νm, indicating how much weight is allocated to each task.We can now write a linear program that finds an optimal coalition structure for an LBG G = (cid:6)N, ω, T(cid:7):m(cid:6)max:ν jπ jj=1(cid:6)s.t.j:i∈ A jν j ≤ ωi∀i ∈ Nν j ≥ 0∀ j ∈ [m]The dual of LP (7) isn(cid:6)ωiγ imin:i=1(cid:6)s.t.i∈ A jγ i ≥ π j∀ j ∈ [m](7)(8)γ i ≥ 0∀i ∈ NLet (cid:24)ν1, . . . , (cid:24)νm and (cid:24)γ 1, . . . , (cid:24)γ n be optimal solutions to (7) and (8), respectively. Let CS be the coalition structure that cor-responds to (cid:24)ν1, . . . , (cid:24)νm. We construct a payoff vector x for CS as follows: for every j = 1, . . . , m we set xi= (cid:24)γ i(cid:24)ν j if i ∈ A j , j= 0 otherwise. In words, each player i has some “bargaining power” (cid:24)γ i , and is paid for each task she works on in and xijproportion to her bargaining power. Note that both CS and x can be computed efficiently from the description of the game. We will now show that x is an imputation for CS, and, moreover, (CS, x) is in the optimistic core.Theorem 7.3. Given a linear bottleneck game G = (cid:6)N, ω, T(cid:7), let CS and x be the coalition structure and the payoff vector constructed above. Then x ∈ I(CS) and (CS, x) is in the optimistic core of G.Proof. We will first argue that x ∈ I(CS). To see that x satisfies coalitional efficiency, note that the sum of payoffs from task T j is(cid:6)(cid:6)(cid:6)=xij(cid:24)γ i(cid:24)ν j = (cid:24)ν j(cid:24)γi.i∈ A ji∈ A ji∈ A jAs (cid:24)γ 1, . . . , (cid:24)γ n is an optimal solution to (8), by complementary slackness we have either every task T j with (cid:24)ν j > 0, its total payoff (cid:24)ν jπ j is shared by players in A j only.We now show that the outcome (CS, x) is in the optimistic core. We can assume without loss of generality that CSallocates non-zero weight to the first k tasks T 1, . . . , Tk, k ≤ m, and no weight to the remaining tasks. Consider a deviation from (CS, x) by a set S. This deviation can be described by the list of tasks that S abandons completely, and the amount of weight that players in S withdraw from all other tasks. Assume without loss of generality that the tasks that S abandons completely are T (cid:6)+1, . . . , Tk (this list includes all tasks T j with A j ⊆ S), and for each j = 1, . . . , (cid:6) each member of A j ∩ Swithdraws z j units of weight from T j . Observe that, because of the properties of linear bottleneck games, we can restrict (cid:2)i∈ A j(cid:24)γ i = π j or (cid:24)ν j = 0. Thus, for Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9795ourselves to such ‘uniform’ deviations without loss of generality. When players in S deviate, they lose their payoff from (cid:2)T (cid:6)+1, . . . , Tk, and their payoff from T 1, . . . , T (cid:6) is reduced by (cid:6)j=1 z jπ j .For each i ∈ S, set(cid:6)μi =(cid:6)< j≤k,i∈ A j(cid:24)ν j,Z i =(cid:6)z j;j≤(cid:6),i∈ A jμi is the total amount of weight that i withdraws from tasks T (cid:6)+1, . . . , Tk, while Z i is the total amount of weight that iwithdraws from T 1, . . . , T (cid:6). The profit that S obtains from optimally using the withdrawn resources is given by the following linear program:(cid:6)max:s.t.(cid:6)ν jπ jA j ⊆Sν j ≤ μi + Z i∀i ∈ Sj:i∈ A j , A j ⊆Sν j ≥ 0∀ A j ⊆ SThe dual of LP (9) ismin:s.t.(cid:6)γ i(μi + Z i)i∈S(cid:6)i∈ A jγ i ≥ π j ∀ A j ⊆ Sγ i ≥ 0∀i ∈ S(9)(10)(cid:6)j=1 z jπ j , (recall that Let α be the value of LP (9) (and hence also of LP (10)). Note that the total profit that S gets by deviating equals (cid:2)(cid:6)α −j=1 z jπ j is the total marginal loss that S incurs by partially deviating from T 1, . . . , T (cid:6)). For every optimal solution to (8), its restriction to i ∈ S is a feasible solution to (10): the constraints in (8) are more restrictive than those in (10). Thus, we obtain(cid:2)(cid:6)α ≤(cid:24)γ i(μi + Z i).i∈S(cid:2)i∈SNow, (cid:24)γ iμi is exactly the payoff that S was getting from T (cid:6)+1, . . . , Tk under (CS, x). Further,(cid:6)i∈S(cid:24)γ i Z i =(cid:6)(cid:6)(cid:6)(cid:24)γ i z jj=1i∈S∩ A j⎛⎞(cid:6)(cid:6)=⎝z j(cid:6)⎠ ≤(cid:24)γ i(cid:6)(cid:6)z j⎛⎝(cid:6)⎞⎠ =(cid:24)γ ij=1i∈S∩ A jj=1i∈ A j(cid:6)(cid:6)j=1z jπ j,where the last equality holds because of the complementary slackness; as previously mentioned, the latter expression is the marginal loss that S suffers for withdrawing resources from T 1, . . . , T (cid:6). Thus, the total payoff that S gets from deviating is at most (cid:2)i∈S(cid:24)γ iμi . Further,(cid:6)(cid:6)(cid:6)(cid:24)γ iμi =(cid:24)γ i(cid:24)ν ji∈S(cid:6)< j≤k,i∈ A j(cid:6)(cid:24)ν j(cid:24)γ ij:i∈ A jpi(CS, x) = p S (CS, x).≤=i∈S(cid:6)i∈S(cid:6)i∈STo conclude, the total payoff that S receives by deviating under the optimistic arbitration function does not exceed its payoff in (CS, x). As this holds for every deviation and every S ⊆ N, it follows that (CS, x) is in the optimistic core. (cid:2)An optimal solution of a linear program and its dual can be found in polynomial time. Hence, we obtain the following immediate corollary.96Y. Zick et al. / Artificial Intelligence 271 (2019) 74–97Corollary 7.4. For linear bottleneck games, the problems Ao-OptVal, Ao-ArbVal, and Ao-CheckCore can be decided in polynomial time.Note also that, since the refined core, the sensitive core and the conservative core all contain the optimistic core, we can conclude that linear bottleneck games admit stable solutions with respect to the conservative, sensitive and refined arbitration functions.8. ConclusionsWe have explored two methods of designing efficient algorithms for finding optimal coalition structures and stable outcomes in OCF games. The first method is to consider a discretized version of OCF games and impose constraints on agent communication; the second method is to place no constraints on agent communication, but focus on a specific family of OCF games. Our results for discrete OCF games demonstrate that when the communication network is treelike, many stability-related computational problems become easier. However, this constraint alone is insufficient for tractability, which can be seen as evidence that discrete OCF games form a rich and complex class of games. For Linear Bottleneck Games, the OCF model, and, in particular, the notion of the optimistic core, enable us to formalize the intuition that such games admit outcomes that are strongly resistant to deviation.Our positive results for discrete OCF games rely on the notion of a local arbitration function, which essentially requires agents to be myopic in their behavior. In particular, none of our efficient algorithms can be used to find an outcome in the sensitive core. It would be interesting to identify a class of games where outcomes in the sensitive core can be computed efficiently, as well as to computationally separate the refined core and the sensitive core.AcknowledgementsThis research was supported by National Research Foundation Singapore Research Fellowship 2009-08 (Elkind), European Research Council Starting Grant ACCORD under Grant Agreement 639945 (Elkind) and a SINGA A*STAR scholarship (Zick).References[1] G. Chalkiadakis, E. Elkind, E. Markakis, M. Polukarov, N. Jennings, Cooperative games with overlapping coalitions, J. Artif. Intell. Res. 39 (2010) 179–216.[2] B. Peleg, P. Sudhölter, Introduction to the Theory of Cooperative Games, second edn., Theory and Decision Library, Series C: Game Theory, Mathematical Programming and Operations Research, vol. 34, Springer, Berlin, 2007.[3] Y. Zick, E. Markakis, E. Elkind, Arbitration and stability in cooperative games with overlapping coalitions, J. Artif. Intell. Res. 50 (2014) 847–884.[4] G. Chalkiadakis, E. Elkind, M. Wooldridge, Computational Aspects of Cooperative Game Theory, Morgan and Claypool, 2011.[5] R.B. Myerson, Graphs and cooperation in games, Math. Oper. Res. 2 (3) (1977) 225–229.[6] G. Demange, On group stability in hierarchies and networks, J. Polit. Econ. 112 (4) (2004) 754–778.[7] V. Vazirani, Approximation Algorithms, Springer Verlag, 2001.[8] E. Markakis, A. Saberi, On the core of the multicommodity flow game, Decis. Support Syst. 39 (1) (2005) 3–10.[9] T. Sandholm, K. Larson, M. Andersson, O. Shehory, F. Tohmé, Coalition structure generation with worst case guarantees, Artif. Intell. 111 (1) (1999) 209–238.[10] K. Larson, T. Sandholm, Anytime coalition structure generation: an average case study, J. Exp. Theor. Artif. Intell. 12 (1) (2000) 23–42.[11] E. Elkind, T. Rahwan, N.R. Jennings, Computational coalition formation, in: G. Weiss (Ed.), Multiagent Systems, 2nd edn., MIT Press, 2013, pp. 329–380.[12] T. Rahwan, T.P. Michalak, M. Wooldridge, N.R. Jennings, Coalition structure generation: a survey, Artif. Intell. 229 (2015) 139–174.[13] O. Shehory, S. Kraus, Formation of overlapping coalitions for precedence-ordered task-execution among autonomous agents, in: Proceedings of the 2nd International Conference on Multi-Agent Systems, ICMAS-96, 1996, pp. 330–337.[14] C.F. Lin, S.L. Hu, Multi-task overlapping coalition parallel formation algorithm, in: Proceedings of the 6th International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS-07, 2007, p. 211.[15] G. Zhang, J. Jiang, Z. Su, M. Qi, H. Fang, Searching for overlapping coalitions in multiple virtual organizations, Inf. Sci. 180 (2010) 3140–3156.[16] I. Mann, L. Shapley, Values of Large Games IV: Evaluating the Electoral College by Montecarlo Techniques, Tech. Rep., The RAND Corporation, 1960.[17] I. Mann, L.S. Shapley, Values of Large Games VI: Evaluating the Electoral College Exactly, Tech. Rep., The RAND Corporation, 1962.[18] X. Deng, C. Papadimitriou, On the complexity of cooperative solution concepts, Math. Oper. Res. 19 (2) (1994) 257–266.[19] X. Deng, T. Ibaraki, H. Nagamochi, Algorithmic aspects of the core of combinatorial optimization games, Math. Oper. Res. 24 (3) (1999) 751–766.[20] S. Ieong, Y. Shoham, Marginal contribution nets: a compact representation scheme for coalitional games, in: Proceedings of the 6th ACM conference on electronic commerce, EC-05, ACM, 2005, pp. 193–202.[21] T. Matsui, Y. Matsui, A survey of algorithms for calculating power indices of weighted majority games, J. Oper. Res. Soc. Jpn. 43 (2000) 71–86.[22] E. Elkind, L. Goldberg, P. Goldberg, M. Wooldridge, On the computational complexity of weighted voting games, Ann. Math. Artif. Intell. 56 (2) (2009) 109–131.[23] G. Greco, E. Malizia, L. Palopoli, F. Scarcello, On the complexity of core, kernel, and bargaining set, Artif. Intell. 175 (12–13) (2011) 1877–1910.[24] Z. Zhang, L. Song, Z. Han, W. Saad, Z. Lu, Overlapping coalition formation games for cooperative interference management in small cell networks, in: Wireless Communications and Networking Conference, WCNC-13, IEEE, 2013, pp. 643–648.[25] M. Ackerman, S. Brânzei, The authorship dilemma: alphabetical or contribution? in: Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems, AAMAS-14, 2014, pp. 1487–1488.[26] R. Brafman, C. Domshlak, Y. Engel, M. Tennenholtz, Transferable utility planning games, in: Proceedings of the 24th AAAI Conference on Artificial Intelligence, AAAI-10, 2010, pp. 709–714.Intell. 232 (2016) 76–113.[27] G. Chalkiadakis, G. Greco, E. Markakis, Characteristic function games with restricted agent interactions: core-stability and coalition structures, Artif. [28] Y. Bachrach, E. Elkind, R. Meir, D. Pasechnik, M. Zuckerman, J. Rothe, J. Rosenschein, The cost of stability in coalitional games, in: Proceedings of the 2nd International Symposium on Algorithmic Game Theory, SAGT-09, 2009, pp. 122–134.Y. Zick et al. / Artificial Intelligence 271 (2019) 74–9797[29] R. Meir, Y. Zick, E. Elkind, J.S. Rosenschein, Bounding the cost of stability in games over interaction networks, in: Proceedings of the 27th AAAI [30] N. Bousquet, Z. Li, A. Vetta, Coalition games on interaction graphs: a horticultural perspective, in: Proceedings of the 16th ACM Conference on Eco-Conference on Artificial Intelligence, AAAI-13, 2013, pp. 690–696.nomics and Computation, EC-15, 2015, pp. 95–112.Agents and Multiagent Systems, AAMAS-16, 2016, pp. 242–250.AAAI-17, 2017, pp. 565–571.[31] A. Igarashi, E. Elkind, Hedonic games with graph-restricted communication, in: Proceedings of the 15th International Conference on Autonomous [32] A. Igarashi, D. Peters, E. Elkind, Group activity selection on social networks, in: Proceedings of the 31st AAAI Conference on Artificial Intelligence, [33] A. Igarashi, R. Bredereck, E. Elkind, On parameterized complexity of group activity selection problems on social networks, in: Proceedings of the 16th Conference on Autonomous Agents and Multiagent Systems, AAMAS-17, 2017, pp. 1575–1577.[34] S. Gupta, S. Roy, S. Saurabh, M. Zehavi, Group activity selection on graphs: parameterized analysis, in: Proceedings of the 10th International Symposium on Algorithmic Game Theory, SAGT-17, 2017, pp. 106–118.[35] R. Aumann, J. Drèze, Cooperative games with coalition structures, Int. J. Game Theory 3 (1974) 217–237.[36] T. Shrot, Y. Aumann, S. Kraus, On agent types in coalition formation problems, in: Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems, AAMAS-10, 2010, pp. 757–764.[37] K. Aadithya, T. Michalak, N. Jennings, Representation of Coalitional Games with Algebraic Decision Diagrams, Tech. Rep. UCB/EECS-2011-8, UC Berkeley, 2011.[38] S. Ueda, M. Kitaki, A. Iwasaki, M. Yokoo, Concise characteristic function representations in coalitional games based on agent types, in: Proceedings of the 22nd International Joint Conference on Artificial Intelligence, IJCAI-11, 2011, pp. 393–399.[39] G. Greco, E. Malizia, F. Scarcello, L. Palopoli, Hard and easy k-typed compact coalitional games: the knowledge of player types marks the boundary, in: Proceedings of the 20th European Conference on Artificial Intelligence, ECAI-12, 2012, pp. 372–377.[40] M.R. Garey, D.S. Johnson, Computers and Intractibility, W.H. Freeman and Company, 1979.[41] O. Shehory, S. Kraus, Task allocation via coalition formation among autonomous agents, in: Proceedings of the 14th International Joint Conference on Artificial Intelligence, IJCAI-95, 1995, pp. 655–661.[42] J. Edmonds, Paths, trees, and flowers, Can. J. Math. 17 (1965) 449–467.[43] A. Schrijver, Theory of Linear and Integer Programming, Wiley, Chichester, 1986.[44] Y. Zick, G. Chalkiadakis, E. Elkind, Overlapping coalition formation games: charting the tractability frontier, in: Proceedings of the 11th International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS-12, 2012, pp. 787–794.[45] N. Robertson, P. Seymour, Graph minors, III: planar tree-width, J. Comb. Theory, Ser. A 36 (1) (1984) 49–64.[46] B. Courcelle, The monadic second-order logic of graphs, I: recognizable sets of finite graphs, Inf. Comput. 85 (1990) 12–75.[47] H.L. Bodlaender, A linear-time algorithm for finding tree-decompositions of small treewidth, SIAM J. Sci. Comput. 25 (6) (1996) 1305–1317.[48] K. Jain, M. Mahdian, Cost sharing, in: N. Nisan, T. Rougarden, E. Tardas, V. Vazirani (Eds.), Algorithmic Game Theory, Cambridge University Press, 2007, pp. 383–408, Chap. 15.