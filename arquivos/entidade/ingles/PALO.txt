ELSEVIER Artificial Intelligence 84 (1996) 177-208 Artificial Intelligence PALO: a probabilistic hill-climbing algorithm * Russell Greiner * Siemens Corporate Research, 755 College Road East, Princeton, NJ 08540-6632, USA Received April 1994; revised May 1995 Abstract Many learning systems search through a space of possible performance elements, seeking an element whose expected utility, over the distribution of problems, is high. As the task of finding the globally optimal element is often intractable, many practical learning systems instead hill- climb to a local optimum. Unfortunately, even this is problematic as the learner typically does not know the underlying distribution of problems, which it needs to determine an element’s expected search when the utility utility. This paper addresses function can only be estimated by sampling. We present a general algorithm, PALO, that returns an element find the generality of this algorithm by presenting an element whose efficiency, accuracy or completeness is nearly optimal. These results suggest learning, the multiple extension approaches to solving the utility problem from explanation-based problem from nonmonotonic tradeoff problem from knowledge representation. that is, with provably high probability, essentially a local optimum. We then demonstrate reasoning and the tractability/completeness three distinct applications the task of approximating this hill-climbing that respectively Keywords: Computational learning theory; Hill-climbing; Speed-up learning; Utility problem; Knowledge compilation; Theory revision; Prioritized default theories 1. Introduction Many learning mance elements examples, inductive seeking an element tasks can be viewed as a search through a space of possible perfor- that is optimal, based on some utility measure. As are optimally accurate, systems seek classifiers whose classifications * This paper expands the short article, “Probabilistic hill-climbing: theory and applications” that was awarded the “Artificial Intelligence Journal Best Paper Award” at the Ninth Canadian Conference on Artificial Intelligence (CSCSI-92), in Vancouver, in May 1992. * E-mail: greiner@scr.siemens.com. 0004-3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved KYDI0004-3702(95)00040-2 178 K. Gretner/Artificiurl htelligence 84 (I 996) 177-208 learning that are optimally and many explanation-based solvers used to compare as the expected value of a particular (or goals, queries, problems, samples the different elements efficient [ 30,591. [ 17,601 and chunking 1551 systems seek problem function In each of these cases, the utility is defined of function, averaged over the distribution (e.g., classifiers or problem solvers) scoring .) that will be seen [38,42]. There are at least two problems with implementing to determine which element such a learning system: First, we is optimal; unfor- is usually unknown. There are, of course, standard statistical and techniques. For example, that is, systems have incorporated [78] use these estimates to identify an element information; the needed to estimate these This of samples that use the set of observed samples this information to the second problem: systems approximately need to know the distribution tunately, techniques several classes of learning many “PAC-learning” with high probability, leads ally optimal element, many spaces of elements climbs BACKPROP 1441, genetic algorithms speedup learning methods; guarantee that each hill-climbing ment is not always even superior of elements. Moreover, the learning has reached a point of diminishing fewer systems [30,42]. A common see especially even given towards a lncuf optimum. Many well-known a global optimum. unfortunately, the correct distribution response is intractable the task of identifying the glob- for information, that hill- is to build a system inductive including learning systems, [ 681, use this approach, as do many systems the final ele- in the space to determine when few existing 1281. Unfortunately, step is even an improvement, meaning to the initial one, much less an optimum include a stopping criterion [ 6) and ~4.5 returns. The work presented here draws ideas from both of these themes: in particular, it learning produces a general algorithm, I - 6, &-local optimal. describes using a utility measure 0, PALO efficiently at least incremental the effects of the sample order. Moreover. [ 621, passively gathering element PALO’s hill-climbing, very minor. solve problems to “batched”) the statistics (as opposed relevant over PALO, that hill-climbs to a local optimum, that is estimated by sampling. Given any parameters an element whose expected utility E,C? > is, with probability ’ As PALO processes one sample at a time, learner, which uses statistical it is an tests to mollify this system can often work unobtrusively a performance it needs by simply watching to a user’s applications. Here, the incremental problems, the cost of simply solving performance cost of can be elements. Section 4 then defines the use of “expected utility” as a quality measure Section 2 first compares and contrasts our approach with others from the literature. for comparing the general PALO algorithm, which deals that, with high of the final the statistical is better than the rigorous the generality of our its Section 3 motivates performance sequentially with a series of performance each @;+I is an improvement confidence, O,, is a local optimum the result of a proposed modification tool used to determine whether original performance this version of Minton’s “utility analysis” approach by presenting tool can be viewed as a mathematically . , O,, such the performance elements 01,. over Oi and of the PALO system, each using in the space being searched. [ 591. Section 5 demonstrates three different applications It also describes element; ’ Theorem I below defines both OUT sense of efticiency, and “~-local optimality”. R. Greiner/Art$cial Intelligence 84 (1996) 177-208 179 own set of transformations performance completeness, behavior limitations, paper. in a particular respectively. to find a near-optimal elements, where optimality is defined It also summarizes situation. Section 6 discusses its particular set of element within in terms of efficiency, accuracy or study, to illustrate PALO’S and in the several variations, contains proofs of the claims made an empirical extensions of our approach. The Appendix 2. Related results Finding an element with the best average performance techniques that use statistical [ 581 describe a system There are several other projects element whose average performance must evaluate each of N performance Moore set of elements, meaning explicitly. Their “Hoeffding Race” approach element-sample by removing evaluations that this element will not be the optimum. to find a performance system for each of k training samples. Maron and small, and explicit, can be performed the total number of clear that works when there is a relatively evaluations” to reduce an element as soon as it is statistically In general, each such learning the N x k “element-sample is optimal. elements attempts [ 221 presents a different, more mathematically Fong of reducing ment should deal with each sample. The resulting “Y-W tE system the number of element-sample evaluations, [50]. rigorous, solution to the problem by specifying which single ele- framework extends Kaelbling’s Combinatorial space + hill-climbing These approaches work when there is an explicit representation of all possible perfor- In many cases, however, there are an implicitly defined combinatorial to the set of its neighbors system mance elements. number of elements. Here, it makes sense to impose a “structure” on the space by con- (which form a small subset of the space), necting each element from the “current element” and then use a hill-climbing to one of its neighbors. There are, of course, a huge number of such hill-climbing sys- as well as almost every other field of computer tems used throughout machine element science. Each such system must evaluate is easily against computed. This is not true in our case, as our quality measure is the expected value of the element’s is not known as it depends on the unknown distribution the currently proposed performance “quality” its neighbors. This comparison score on an instance, which to climb successively if each element’s of instances. is trivial learning, classifiers As mentioned is optimal; see for example above, many learning systems attempt to address this challenge, of find- the learning proce- [ 61. [68], neural nets [44] and genetic algorithms the distribution, then to another. Most sys- and heuristically. By contrast, our PALO system performs an is ing an element whose expected behavior dures used by symbolic Each of these systems uses a set of training uses this information tems do this implicitly, explicit statistical superior samples to determine when one element test to determine, with prescribed corzjdence, when one element to estimate is superior to another. 180 R. Grelner/Art@cicrI lntelli~ence 84 (I 996) 177-208 As such, it is very similar samples when hill-climbing. By contrast, PALO will stop and return is in the statistical criteria used: While PALO’s to the COMPOSER system of Gratch, DeJong and Chien element 0 if none of O’s neighbors appears significantly [ 27- 291. COMPOSER differs from PALO in two significant ways. First, COMPOSER will use the all available bet- currently best performance returns”. ter than O-which means PALO will stop on reaching a point of “diminishing test (based on The second difference Hoeffding’s of sam- that the samples are ples, COMPOSER’S is standard, and drawn empirically see Section 6.2. effective system, COMPOSER also Moreover, it does not make PALO’s conserva- makes other simplifying that the errors on successive hill-climbs tive (but mathematically will add. * in the interest of producing an empirically assumptions; necessary) inequality, Eq. (6)) holds for any bounded stationary distribution assumes assumption to be correct; implicitly the COMPOSER from a normal distribution. While test (based on Nadas rule) is often appropriate, it is not guaranteed for example, assumption “Rationality ” Doyle and Patil [ 19J recently argued against to decide amongst different possible performance case analyses advocated using an expected case analysis. This raises to obtain and then, what to do with such information, as embodied in the PALO system, as addressing exactly the distribution information required the standard practice of using worst and instead elements, the obvious questions of how the expected case behavior, once it is available. We view our approach, to determine those questions. Moreover, our PALO exhibits a type of “Type II rationality” element whose expected utility ing only a feasible amount of time similarly motivated by this issue of computational the system can exhibit, given only performance [46], Etzioni the works by Horovitz These other systems, however, either assume available, are immediately for all of the elements above). By contrast, PALO will only estimate reached in the current phase of the hill-climbing the total space of elements, PALO can reach statistically observing manyfewer the utilities of all of the elements; the other algorithms PALO will usually Section 4. or supply statistical methods have finished collecting this allows PALO require a smaller samples (akin the utilities is optimal, subject [26], as it seeks an to the resource constraint of spend- to find such an element. Many other systems are what is the best cf. resources; [ 701. that the utilities of the various elements these utilities to the Hoeffding Race and y-IE framework mentioned effectiveness-i.e., limited computational [21] and Russell, Subramanian for estimating and Parr significant than are required by the other systems for the elements that can be process. As this is a small subset of after conclusions that must estimate long before that in this also means see Note N-PALO5 to begin climbing samples. Moreover, total number of samples; 2 A less major difference is that the COMPOSER system, like the Hoeffding Race and y-IE systems mentioned above, qualifies as a “wrapper” learner 1 10,481. as COMPOSER views each performance element as a black box, whose behavior can be sampled, but whose internals ate unavailable. By contrast, PALO will sometimes examine the internals of the performance elements, and use this structural information to efficiently determine the scores of the neighboring elements; see Section 5. I and I36 I. R. Greiner/Artijicial Intelligence 84 (1996) 177-208 181 Incremental algorithms Many other methods attempt to make effective use of the training samples; cf. re- inforcement learning algorithms [50,76] and systems that address the “bandit prob- lem” [ 3,641. Each of these systems also makes a sequence of decisions, attempting to maximize its total reward. Such systems tend to run continuously, making successive decisions; and they are often evaluated in terms of the number of mistakes they make over their entire learning + performance lifetimes. By contrast, our PALO is evaluated only in terms of the quality of the performance element it returns, provided it returns this answer within a reasonable-“polynomial’‘-amount of time. Like PALO, each of these other incremental learners climbs through a series of differ- ent elements. PALO, however, is probabilistically guaranteed to improve over time: i.e., the performance element produced at the jth hill-climbing step is, with high probability, strictly better than the previous one, produced on the (j - 1)st iteration. As such, it also resembles anytime algorithms [ 4,161, but differs from standard anytime algorithms by terminating on reaching a point of diminishing returns. “Probabilistic hill-climbing” Finally, as the phrase “probabilistic hill-climbing” may suggest “simulated anneal- ing” [53] to many readers, it is worth explicitly distinguishing these different ideas: The general simulated annealing process assumes that the quality measure used to com- pare different elements is accurate; its use of “probabilistic” refers to the stochastic way in which a simulated annealing algorithm probabilistically decides whether to climb “downhill”, in an attempt to avoid local optima. By contrast, our PALO system does not know the quality of each element, and so must estimate these values. Our use of “proba- bilistic” refers to the uncertainty of these estimates, due to possible sampling error. One could, of course, write a PALO-like algorithm that used an annealing process to climb downhill occasionally; however, this system would not satisfy the useful specifications presented in Theorem 1. 3. Framework To illustrate the relevant concepts, consider the following example: A pure PROLOG [ 121. We can form new program will return a set of answers to each query posed programs by rearranging the order of the clauses. While these programs will return the same set of answers, they can require differing amounts of time to find the first answer to each query. Our goal is to determine the “optimally efficient program”; i.e.. the ordering of the clauses that requires the minimal average time to find an answer, over the distribution of queries. In general, we assume as given a (possibly infinite) set of performance elements Se = { Oi}, where each 0 E Se is a system that returns an answer to each given problem (or query or goal) qi E Q, where Q = {ql , q2, . . .} is the set of all possible problems. 3 We 3 We assume that Q is countable for purely pedagogical reasons. There are obvious ways of extending our analysis to handle au uncountably infinite set of problems as well. 182 R. Greiner/Art~&ial Intelligence 84 (1996) 177-208 function c : SC+ x Q t-1 R, where c(O,q) measures how well also use a given utility the clement B does at solving clement 0 corresponds programs, each sample problem to solve y. (Section 5 later defines other classes of performance utility functions.) We insist A = A(c, Q. Se,) E LR+: i.e.. the problem 4. In the PROLOG context, each performance is the set of these PROLOG the time 0 requires samples and range of possible values to an ordering of the clauses, Se is a query, and c( O,q) quantifies that the c( ., ‘) have a bounded elements, V’o E So, V9 6 Q: min(O) < c(O,q) < min(O) + A, (1) where min(@) = min,EQ{c(O,q)} q E Q. (Section 5.1 specifies this A value for the PROLOG case.) is the minimal utility value of 0, over all instances This utility function specifies the score of the performance element @ on an individual instance 4. Our performance problems Q = (4.i). To specify which element the distribution of problems this using a stationary probability the probability performance elements, however, will have to solve an entire ensemble of is best overall, we must therefore consider elements will encounter. We model [0, I], where PV[qj] denotes the expected utility of a that the problem 4, is selected. We then define that our performance in the obvious way: function, Pr element : Q H C(0) 2’ EqQr(C(O,q)] = CPr[qj x c(O,q). (2) 4EQ Our underlying challenge is to find the performance element whose expected utility is above, there are two problems: First, the problem distribution, to determine which element information, is optimal, the task of identifying is usually unknown. Second, even if we is often the optimal element maximal. As mentioned needed knew that distribution intractable. 4. The PALO1 algorithm system, “PALOI”,~ to estimate from a given initial 01 to a performance a local optimum. This section This section presents a Icarning lems by using a set of sample queries efficiently ity, essentially specifies PALOl’s motivation underlying the theorem. functionality, that side-steps the above prob- the distribution, and by hill-climbing that is, with high probabil- element theorem then summarizes PALOt’s code and finally sketches first states the fundamental that the As shown in Fig. 1, PALOI takes as arguments S,j, a collection of possible one performance error and confidence. order of a pair of clauses; e.g., r~,i (0) moves O’s third clause transformations element to another, and parameters E, 6 > 0, that bound an initial performance element 01 E 7 = {r,i}, where each rj : Se H Se maps the allowed the In the context of our PROLOG example, each ri rearranges PALOt uses an oracle that draws samples fixed (but unknown) distribution Pr[ .I. (Here, each sample to the beginning. from & = {qj} at random, according to the is a query, which could 4 “PALO” abbreviates “Probably Approximately Locally Optimal”. Section 6. I explains the “I” subscript. R. Greiner/Artijicial Intelligence 84 (1996) 177-208 183 be posed by the user of the performance specified conditions, to one of 01’s neighbors, 02 to a different 03 = 72(02), returned. PALO~ will climb 02 = Al system; from the given for some 71 E 7, and then possibly see Note N-PALO~ below.) Under element 01 from this is reaching a O,,,, which initial performance (eventually) and so on, until Theorem 1 specifies PALO1 ‘s behavior. It uses I[@] = (7(O) ES@j7E7&7(0)$0} to denote the set of O’s neighbors. (The proof for this theorem appears in the Appendix.) 1. The PALO1 (@,ir, E, 6) process Theorem .formance elements @,02,. and, with probability at least 1 - 6, incrementally produces a series of per- . . , O,, such that each Oj+l = rj( Oj) using some rj E 7 ( 1) the expected utility of each performance element is strictly better than its prede- cessors , i.e., Vl < i <j < m: C(Oj) > C(Oi); (2) the$nal pelformance i.e., element returned by PALO1 , O,,, is an “e-local optimum”- 47 E 7: C(7(0,,)) > C(0,) + E. Moreover, PALO1 will stay at any @j (before either terminating or climbing Oj+l ) for a number of samples and will terminate with probability to a new l/6, A( c, &, Se) and (I[ Oj] (, that is polynomial in l/c, ISe( is finite. 1, provided The PALO1 code, shown mance elements 0,O’ E Se, in Fig. 1, uses two additional terms: For any pair of perfor- A( 0, 0’) = nlEax{C(@” q) - c( 0, q)} - tl$ilI{c(O’, q) - c(0, q)} (3) bounds the range of possible values for c( O’, q) - c( 0, q) over all samples q E Q; and A[@1 = @,~g$“(O,@‘)} for a given 0, over all neighbors 0’ E I[ 01. Notice is the largest such range A [ 01 < 2A for any 0, using To summarize the A specified in Eq. ( 1) . the code: PALO1 examines a sequence of sample queries, one by one. element, On seeing each query, PALO~ computes that value with comparable summed over all of the queries seen so far, and compares (line (L2)). If any neighbor appears to be significantly values for each of 0, ‘s neighbors element 02. PALO~ then compares (L3)), better 02’s performance with that of 02’s neighbors over the next set of samples; and once again, if any of 02’s neighbors appears much better, PALO1 will climb to this apparently appear superior element 03, and so forth. On the other hand, the utility of the given 01 performance if all of @j’s neighbors the new performance it becomes (line (4) that 184 R. G’reiner/Artifciul Intelligence 84 (1996) 177-208 Algorithm PALO~((~,.~,E,~) Forj= I..oodo Let 6,-T. 66 .I_“’ ForEach H’ E 710, I do Let d(@j,R',O) + 0. For i = l..L, do Get sample y, (from oracle ) ForEach C+’ E 7\(z), ) do %o Lj is mux # @samples on jth iterution (LI) 8 Get und process ith query Let d((l)l,@‘,i) - d(t+,,N’.i- I) + [C(W’,y,) -c(@j,qi)] If i < L, ‘If 39 E II@, I Then Then Let @,+l - C-1’ Exit For (inner loop) Else If WI E 7[Hjl: !J(@,.@‘.i) i < E - A(@,,@‘) &I” ~(LJ - l)l7T[@jll / ( 6, 1 Then Return 0, (Exiting both inner and outer For loops) (L2) (L3) (L4) Then Else Let Hj+l - 0’ Exit For (inner loop) Else Return 0, (Exiting both inner and outer For loops) End For (inner loop) End For (outer loop) End PALO~ Fig. I. Code for PALO] algorithm. R. Greiner/A@iciul Intelligence 84 (1996) 177-208 185 comparable to or worse than the current Oj (line (IA)), PALO1 will terminate, returning Oj. If neither of these conditions holds, PALO~ will, in general, simply process the next query, then use this query, in addition to the previous ones, when comparing the current Oj to its neighbors. However, if PALO1 has dealt with this current Oj for a sufficiently large number of queries (Lj, from line (Ll)), PALOI will use easier to satisfy thresholds to decide whether to climb to some @,+I or terminate (line (L5)), and will necessarily perform one of those actions. Notice PALOI climbs from 0 to a new 0’ = T( 0) if 0’ is likely to be better than 0; i.e., if we are highly confident that C(@‘) > C(O), or equivalently, if P Ef C(0’) - C(0) > 0. (5) Unfortunately, as this C( 0’) - C(0) quantity depends on the unknown distribution, we cannot immediately determine if Eq. (5) holds. We can, however, obtain an approxima- tion that usually is good enough. To do this, define the random variable di zf C(O’,qi) -C(O,qi) to be the difference in utility between using @’ to deal with the query qi, versus using 0. As each query qi is selected randomly according to the fixed distribution, these di are independent, identically distributed random variables whose common mean is Eq. (5)‘s P* Now let def 1 Yn = - ’ di n c j=l be the sample mean over n samples. (Notice the A( 0, O’, n) quantity computed on line (L2), corresponds to n x Y,.) From the Law of Large Numbers, we know that this average will tend to the true population mean p as n 4 00; i.e., @ = lim,,, Y,. Hoeffding’s inequality [ 11,451 bounds the probable rate of convergence: the probability that “Y” is more than p + y” goes to 0 exponentially fast as n increases; and, for a fixed n, exponentially as y increases. Formall~,~ Pr[ Y, > p + y] < e-2n(y/A)2, Pr[ Y, < p - y] < e-2n(ylA)2, (6) where n = A(@, 0’) is the range of possible values of c(O’, 4i) - ~(0, qi) defined in Es. (3). The PALOI algorithm uses these equations and the values of A( Oj, O’, i) to determine both how confident we should be that C(0’) > C( Oj) (lines (L3) and (L5)) and whether any “7-neighbor” of Oj (i.e., any Tk(Oj)) is more than E better than @j (lines (L4) and (L5)); see the proof in the Appendix. ’ See [ 5, p. 121. N.b., these inequalities do not require that the underlying distributions be normal; instead. they hold for any arbitrary bounded distribution. 186 K. Greiner/Artijiciul Intelligence 84 (I 996) 177-208 We close algorithm. 6 this section with five general comments on the PALO1 framework and that PALO~ uses may be produced by a user of the Note N-PALO~. The samples performance system, who is simply asking questions is unobtrusively relevant to her current applications; gathering statistics as the user is solving her own problems that both solves performance can be only to simply solve to successive performance the performance elements, element here, PALO] [ 621. This means problems and learns by hill-climbing marginally more than the cost of only running the performance problems. that the total cost of the overall system, PALO uses these user provided samples as its objective is to approximate utility values of the elements, over the distribution element will actually address. This “average case analysis” differs from several other approaches as, for example, we are not assuming of problems will be uniform to any particular collection of “benchmark [25], nor that it will necessarily challenge problems” that this distribution of problems correspond 1521. the average that the performance A “O-local optimum” Note N-PALO~. local optimum; hence our “s-local optimum” local optimality. This means real local optimum elements, 0 and r(O), PALO] will produce a bana fide local optimum. if the difference is always that PALOl’s corresponds exactly to the standard notion of (condition (2) of Theorem I ) generalizes output O,, will (with high probability) be a in utility between every two distinct performance larger than c. Thus, for sufficiently small values of E. Note N-PALO% As I[ O] is the set of distinct, non-degenerate be much smaller other disjoint pairs (7,~‘) such that r(8) = r’(O). l7j. as there can be many r E I than it can r( 0) elements, that map 0 to itself, and many elements Note N-P&04. Our PALO! will formance lines pass. This behavior numbers of samples using later, and therefore better, elements. later per- associated with to is desirable, as it means that the overall system is dealing with larger (L3) and (L4), and indirectly with line (Ll)) the earlier ones, as its tests (directly are increasingly more difficult process more samples using than using (probably) system uses different approach, which we call PALO,tt, will Note N-PALOS. The PALO~ An alternative samples at the start, and use them to (simultaneously) elements-in performance Section 2. In particular, during will have to simultaneously least sets of samples on each climb. set of the utilities of all of the in it will use these estimates when comparing different elements process. If the total space contains N different elements, PALO,11 at suggested by some of the systems discussed to within &e/2, with probability instead obtain a single estimate all N elements I ~- 6; this requires the hill-climbing the manner estimate ‘We will end many sections with such comments. In each case, the casual reader may skip them, and suffer no loss of continuity. R. Greiner/ArtQicial Intelligence 84 (I 996) 177-208 1 Amax ’ Ma,, = - 2 - E/2 ( ) 187 (7) samples, where nrnax = maxj A[@j] elements Oj. is the largest range of values, over all performance In most situations, PALO1 will require fewer samples that PALO1 requires at most Lj samples perform k - 1 climbs, and terminate, using at most to deal with the jth element, meaning than PALOall. To see this, note it can m,,,=~L, = $2(~)21n2’7~~1’ j=l <2 J!!S A ( > 2 k c j=l ln 2j*~*l~[@jll 63 =2(“’ T > ‘2 ( lIl\T[Oj]/ +lIl’z) j=l (8) than Lj samples on its jth element, require far fewer samples this to deal is often far under Amax, and also (2) PALO1 will to its line (L3) and far under PALO,ll’s thanks is usually this maI1 overbound than as (1) A[ Oj] its k elements In practice, PALO1 will usually (L4) branches. Moreover, even samples. with usually use far fewer line Mall. To motivate elements and that different neighborhoods has something observe pessimal general. this empirical observation, assume each neighborhood are effectively disjoint; hence, has b = IT[ Oj] 1 the total space like INI = bK elements, where K is the real “depth” of the space. Now that PALOl’s k will be under K. In fact, as PALO1 may begin with a non- optimum, we expect k << K in element, that Ignoring Eq. (8)‘s “ln(j27r2)/(36)” and also may stop at a non-global terms and Eq. (7)‘s “ln2/6”, notice mall = 2 (%)*$h/l[@j]/ j=l =2 (*)*klnb Given these assumptions, Mall > mall whenever Kln b xs Mall. lny > (kin%). (9) the infrequent Eq. (9) also exposes than PALO~. This can happen when PALOI and so is forced terms will compensate neighborhoods overlapped elements PALOall will estimate situations where PALO] can require more samples bad element, the “ln (r* k*) / (36)” if the the utilities of the several times, which “costs” PALO1 extra samples. By contrast, the expected utility of each element exactly once. the entire space; meaning for the difference between k and K. It can also happen starts with an exceptionally have a large overlap, to explore essentially forcing PALOI to estimate 188 R. Gremer/Arti~ciul Intelligence 84 (I 996) 177-208 Rule Set Fact Set NJ: bt#l(K) Nh: bt#2(K) ‘~5: (Attempt. hr#I(r)) - q C Attempt ht# 2( K) ) - b NS b N7 Fig. 7. “Inference graph” GA, used by &J and @I Hence. that either rn,ll < Mall or mall > M,,,, depending it is possible stances. However, our experimental mungfc~~r than PALO,II, samples always uses well under Lj samples when dealing with the jth element, and PALO~ requires data shows that, in practice, PALO1 for the basic reasons mentioned on circum- requires above: PALO, almost rarely lnh INI iterations before termination. typically 5. Instantiations of the PALO1 algorithm the generality of the PALO~ algorithm by presenting This section demonstrates instantiations elements Se = {Oj}, process, and (3) different of possible performance used in the hill-climbing expected utility. We also present these parameters are summarized begins with a quick simplistic description of its application, describe how to build a more comprehensive of this framework. For each instantiation, we specify the set of transformations (2) the utility function c( ., .) used to specify (The instantiations reasons, each subsection the derived values of A( O’, 0). in Table 2.) For pedagogical and then provides notes that system. three ( 1) the set 7 = {ok} the of 5. I. Improving ejicienq Many derivation processes can be viewed as a satisficing search graph structure. As an example, notice that using the information an answer a search a successful database to the hep(rc) query, for some ground the inference graph GA (formed retrieval.’ A strategy specifies through [ 741 through a given shown in Fig. 2 to find individual K, corresponds naturally to from the given set of rules) seeking the the order in which to perform 7 Here, hep (x) means x has hepatitis, ,y tests positive for blood test #i. This graph traversal situation corresponds j sun(x) means x is jaundiced, badB (x) means x has “bad blood”, immediately and bt#i to Section 3’s PROLOG (x) means situation. R. Greiner/Artifcial Intelligence 84 (1996) 177-208 189 jaun(K)” rule-based reductions the “NO: hep(K)” the al arc reduces subgoal, based on the rule RI) and the database retrievals various “Nl: arc from N1 to N2 corresponds express each strategy as a sequence of GA’S arcs; e.g., the strategy (e.g., to the attempted database retrieval “j aun( K) “). We can goal to the (e.g., the ~22 0 0 = (~1,~2,~3,~4,uS,u6,u7) left-to-right to the obvious depth-first element using corresponds the performance its reductions, 00 reaches success nodes, N2, NS and NT.) There are many other possible various alternative depth-first the success node N2 and so stops with success. or it reaches a “success node”-e.g., this strategy will stop whenever strategies, such as traversal, with the understanding that it has exhausted all of then succeeds, (Fig. 2 doubly boxes GA’S if the u2 retrieval strategies, including 0 1 = (~1,~2,~3.~6,~7,~4,~5), 0 2 = (u3,~4,u5,u6,~7,ul,u2), 0 3 = (~3,~6,~7,~4,~5,~1,~2), as well as many non-depth-first strategies. Each strategy will if one exists. As this find an answer, acceptable [74], which means the costs of the strategies, preferring search, is a satisficing that all strategies are equally the one whose are equally all answers accurate. We therefore consider expected cost is minimal. We use fi E IV, the nonnegative cost of using strategy 0 to find an answer propositions in Fig. 2’s “Fact Set”, cost of traversing the ai, to compute cs (0, q) , the to the query q. For example, given the atomic c,(Oo,hepW)) = fl + f2, = f~ + f2 + f3 + f4 + f5, c,(@o,hep(bl)) c,(f&,hep(bl)) = f3 + f4 + f5. (These different strategies have different costs for a given query as each strategy stops as soon as it has found an answer.) The expected cost, of course, depends on the versus distribution is NP-hard hep(b2), the query posed will be hep(bl), of queries; etc. Moreover, i.e., on how often the task of finding the glob&y optimal strategy [301. This looks like a job for PALO~. ‘TRo = {Tij}, where each Tij maps one strategy under the ui arc to be before Uj and its subgraph. For example, ’ We first define the set of reordering to another by moving transformations the “subgraph” 76,4(@0) = (al, a2, a3,[=[, a4, Q5) = 01 73,1(@0) = ( a3ra4ru5,a6,Q7 ,&,a2) = 02. * Of course, all of the signs in fig. 1 should be flipped, as we are hem measuring cost rather than utility, and the element with minimal, rather than maximal, cost. Note also that we are viewing each strategy as so prefer a performance element. I90 R. C;reiwr/Artt&:iul Intelbgeru 84 (1996) 177-208 PALO, also requires C, f;, the sum of the costs of all of the arcs in the inference graph G. the value of A(@, ~8)): these values are bounded by c(G) = elements to a proposition; (each corresponding In general, each class ot’ performance and N2 corresponds either shown above (in which the antecedent of each rule is but a single Note N-EFF~. is defined with respect to the inference graph G = (N, A, S, f) associated with the given set of rules. In the situation literal), N is a set of nodes to “hep(K)” arcs, each corresponding N1 is based on the rule RI ) or to a database corresponds of N’s “success nodes” in doubled boxes); function perform and A c N x N is a set of the al arc from NO to the Q arc from NI to N2 The set S C N is the subset such as N2 or N5, shown the proof is successful. The cost to f : A ++ 7Zl maps each arc to a nonnegative value that is the cost required this reduction. We earlier retrieval (here, each is an empty disjunction reaching any of these nodes means let J’, refer to the value of f(a;). e.g., the node No corresponds to the attempted database to the empty disjunction), to a rule-based jaun(/c>). reduction retrieval (e.g., (e.g., To deal with more general rules, whose antecedents than , c (X1 “1. we must use directed hyper-graphs, where are conjunctions : - b(X) from one node to a set of children nodes, where the conjunction imply one literal (e.g.. *‘a(X) each hyper-arc descends of these nodes their common parent. We must also define S to be a set logically of subsets of N, where the query processor would have to reach each member of some in s E S for the derivation specifying [ 37, Appendix A] and [ 383. to succeed. This extension leads to additional complications strategies; of more see also It is also trivial to extend these definitions to accommodate more complicated f’( .) cost functions, which can allow the cost of traversing an arc to depend on other factors- e.g., the success or failure of that traversal, which other arcs have already been traversed, etc. elements corresponds to describe operators working Note N-EFF2. This class of performance lem solvers, graphs ference graph corresponds “probabilistic operator, and ns encodes and so forth. bt#l, to many standard prob- including PROLOG [ 121; see also [24]. We can also use these inference in state spaces; here each internal arc of the in- leaf arc to a general the “take some blood” tests positive on experiment”. Using GA, for example, a3 encodes to an operator the experiment that succeeds if the patient and each invocation of the PALO] algorithm In 1361, we discuss how this instantiation learning” basis for Minton’s “utility analysis” fits Note N-EFF3. systems, and show in particular how into the framework of “explanation-based [ 591. We our framework provides a mathematical computes upper and lower also present a more efficient PALO{ system bounds of d( 0, r,,(O), n) based only on information acquired while running 0, and (L2) and (L3), respectively, of the code. N.b., this then uses this information ~ij( @) PALO{ will obtain good estimates of A( 0, T,, (0)) n) without first constructing for each T;, E 7, and executing each such element over all S = {qr} queries. That paper also provides a battery of empirical evidence which demonstrate that PALO{ can work effectively. JuriSica [49] presents an extensive body of related results. that analytically in lines R. Greiner/Arti$cial Inielligence 84 (1996) 177-208 191 Table 1 Average number of samples for each PALO 1 climb (using 00, 6 = 0.05 and various E’S) E 2.0 I.0 0.5 0.1 To 02 22.1 25.1 26.7 34.7 To O3 198.6 218.6 276.1 To terminate 56.5 38.3 82.2 219.7 To illustrate PALOI’S effectiveness, Note N-EFF4. in Fig. 2, and assume each arc has unit cost-i.e., in terms of the (independent) distribution of queries the real-world distribution retrievals; here, suppose again = 1. We can define the graph shown consider fi = f(ai) the probabilities of the various database is Pr[ jaun(K) is in Fact Set 1 query hep( K) is posed] = 0.01, Pr[bt#l( K) is in Fact Set 1 query hep( K) is posed] = 0.60, Pr[ bt#2( K) is in Fact Set 1 query hep( K) is posed] = 0.95. these events are not disjoint.) Given the fact set shown, this would happen (respectively, hep(b21, hep (b6), hep (b7) ) was asked 4% (respectively, if 1%, (Notice hep (bl) 39%, 56%) of the time. We can use these values to compute [ 751: C(Oc) = 5.792, C(Ot) = 5.069, C(O2) = 3.840 and C(O3) = 3.140. Of course, as the learner does not initially know these probability values, it will not know that the optimal strategy the expected costs of the various strategies is 03. We then ran PALO~ with 00 as the starting element, 6 = 0.05, and various settings for to realize is appropriate, sample queries terminated-which required an average of 22.1 samples to 02, and usually (even though step to reach the globally optimal 03. As expected, E. Using E = 2.0, PALO1 climbed it is not the global optimum). Over 100 as this 02 is a 2.0-local optimum then about 56.5 for the first climb, trials, PALO] this strategy was good enough and terminate; hence, additional this total learning process required on average about 78.6 total queries. 9 For the smaller values of E, PALO1 always went from 00 to 02 as before, but then used a second hill- the number of steps required climbing requiring on for each transition were about to reach 02, then an additional 198.6, average 25.1, 26.7, 34.7 samples to decided 218.6,276.1 samples that this 03 was in fact an e-local optimum; to element deal with this final set of samples problems, & PALO1 and doing so at a cost that is only slightly more expensive the 03 performance is the optimal element.) Fig. 3 graphs the element alone, which we know E = 1 .O case; the other cases look very similar, of course. (respectively) to reach 03, and finally 38.3,82.2,219.7 the overall “03 performance relevant, user-supplied, the same for all values of E = 1.0,0.5,0.1, see Table 1. (Notice than simply running the time required is still solving is not wasted: more samples element” learning system 9 In one of these 100 trials, PALO1 continued to climb and reached 83; here it required 16 additional samples to terminate. 192 R. Greiner/Artificiul Intelligence 84 (I 996) 177-208 E PE#O 5.5 7 5 .E l- &4.5 m % a 4 3.5 -. 3L 0 PE#2 50 100 150 200 250 Sample Number Fig. 3. r’ALoI ‘S climbs: initial element 80, E = I .O. 6 = 0.05. in 20 trials. However, in the 400 trials summarized As a final note, the 6 = 0.05 setting means mistake als for each for the the 4 values of E), PALO] never made a mistake-i.e., climbed terminated when an E-better neighbor. This, coupled with similar trials over different inference and values are. that we would allow PALO1 to make 1 100 tri- it never there was thousand other elements tests graphs, and with diverse how overly conservative for I and 8, illustrate results over several initial performance here (involving to an element that was statistical it never inferior, PALOl’s and 5.2. Improving accuracy incompatible to certain queries A default but collectively most) one of these solutions one solution. This representation problems [ 54,571. This subsection initial default to the given correct answer most often. theory can be ambiguous, solutions is correct; we would, of course, extension” as it can produce many individually [ 691. Unfortunately, plausible (at only that like to return only in knowledge problem explanation” to the “bias” and “multiple in statistics this problem by seeking a credulous system, related the that is “optimally is the essence of the “multiple and corresponds [ 42,6 1,7 1,771 and “reference class” problem addresses theory, i.e., which produces [ 4 1,63,69], in machine correct”; learning In more detail, we assume there is a correct answer hence c3( 2 + 2 = X) = Yes [ X H 41. Each correct answer a binding the credulous performance list, as shown here) or “No”. Using O(q) element 0, we can define the utility function to each query q, denoted U(q); is either “Yes” (possibly with the answer returned by to represent R. Greiner/Artijicial Intelligence 84 (1996) 177-208 193 c,(O,q) Ef +l, 0, if O(q) = O(q), if O(q) = IDK, - 1, otherwise, where IDK represents “I don’t know”. (10) We focus on stratified THEORIST-Style where set of facts F’, a set each element 0 = (.F, ‘H, r) [ 691) and a specific priority of allowed hypotheses ordering of the hypotheses. As a specific example, consider @A = (&, 3-10, TA), where lo is a triple, composed of a (consistent) ‘H (each a simple type of default [9,66,67,79], performance elements s(X, gray) :- e(X), IQ(X). & = s(X, white) : - a(X), n,(X) . a(zelda) , e(zelda), . . . { is the fact set; (11) is the hypothesis set, and !P, = (hi, IQ.) is the hypothesis ordering. the color of Cl” holds. @A imagine we want to know To explain how OA would process a query, we want to find a binding nor nA (zelda) for C such that (T =“s(zelda, C> from the factual information Fa alone. This would is either a normal elephant or that she is a normal holds, respectively). @A then considers Zelda-i.e., would first try to prove s (zelda, fail, as we cannot prove that Zelda albino (i.e., neither nE(zelda) using some hypothesis-i.e., ‘Flc if that proposition enables us to reach a conclusion either nE(zelda) gray) or nA (zelda) white). Notice know, as encoded by 30. Unfortunately, we cannot assume both options, as the resulting theory &j U {nE(zelda) of some element of .Fc and if this addition .to the query posed. Here, @A could consider asserting is colored elephant is colored is consistent with everything we and hence albino and hence is both consistent with the known that either of these options, to assert an instantiation is itICOIISiSteIIt. is a “normal” is a “normal” it is allowed individually, that Zelda that Zelda (meaning (meaning facts We must, , nA (zelda)} therefore, decide between ifies the priority of the hypotheses. Here r. = (hi, h2) means priority over hi: nA(X), which means with nE(zelda)-i.e., gray). s(zelda, Gray, encoded by Yes[C I-+ gray], *’ these options. @A’s hypothesis ordering TA spec- takes associated that @A will return that hi: nE( x) the conclusion as & U {nE(zelda)} /== Now consider different priority ordering TB = (hz, hi). As rs considers the OB = (250, H 0 , 2’ ) s e ement, which differs from @A only by using a in the opposite the hypotheses 1 lo Here zelda means ,y’s color is q5. The first two clauses albinos are white. We leave implicit ” This uses the instantiation we will view “q/No” as “yq”. a(zelda, the statements gray) refers to Zelda, a(X) means ,y is an albino, e(,y) means ,y is an elephant, and a(~, 4) in E?q. ( 11) state that normal elephants are gray, and that normal that a (., .) is a function and gray j white. = sczelda, C)/Yea[C H gray]. To simplify our notation, order, it will return Zelda is white. the answer Yes]C + white] to this query; i.e., it would claim that imagine Eq. this, stating Which of these two elements the better C)); is better? If we are only concerned with this single Zelda (read “more accurate”) Oi is the one with the larger value for C)). i.e.. the 0; for which O,(s(zelda, of queries. To to {a(zt > , e (~1) , , , a(ztoc> , that each z; is an albino elephant; and that the queries are of the form (i.e., (i.e., for query, then c,(O;,s(zelda, In general, however, we will have to consider a less trivial distribution illustrate e(ziau)}, “s(z;, how often each “s (z, , C)” query which z, does 0( s (z, , C> ) return Yes(C ++ white] or some other answer). Hence, by plugging Eq. ( 10)‘s c,,( . . .) function system with the larger C,,(. 1 value. to Yes[C H gray], is defined the 0; C)“, for various z;. The best Oi now depends on the distribution of queries the expected accuracy of each system C, (Oi), is posed) and also on the correct answers ( 1 1 )‘s *‘. .” corresponds into Eq. (2); we would C)) = Q(s(zelda, then select as opposed In general, B = (3,X. ?) can include a much larger set of hypotheses 3-t = {ht , . . , h,,}. As before, each ordering based on the permutation queries: Let i be the smallest y,lp, IDK. for some answer r = (/z,,,I ). . i~,.~,j) is a sequence of 7-I’s elements, r : [ I ..N] H 1 I.. N]. 0 uses this information when answering index such that 3~i{h,.,,,} /= this p,. ” If there is no such i, then 0 returns is consistent and 3U{hr(;)} fl,; here 0 returns the priority ordering of queries, which unfortunately that is accurate most often. As before, this is not known a priori; and this optimal ordering of the hypotheses is NP-complete Our goal is to identify depends on the distribution moreover, (and worse, not even approximatable the simplistic situation exactly one hypothesis, the task of identifying [ I] 1, even if we knew the distribution, that we have been considering, where every derivation etc. [ 321. Once again, PALO1 is designed to deal with this situation. We first define transformations before the ust before the.ith IA = {r,,};,,, where each r,i moves the jth given any ordering tern-i.e., term in the ordering /r = (ht , h2,. . , h,), even in involves the set of to just T;,(T) = (h I,..., h ,__l, Il,,k I,..., - /I ,__I. /l,,+I ,..., IIn). We can compute the value of d( rk, 7,, ( Tk), II) for each ri; transformation and each set of queries {qN,}z,=, based on whether 3 U {hi} b” q,,/c3(q,,) for each hypothesis hg. Observe finally that A(@,T(@)) < 2 for all 0 E S@ and all 7 E IA. Note N-Acc~. The motivation underlying tri [73] and others, who also use probabilistic given default rules. Our work differs by providing a way of obtaining tics, rather than assuming static analysis of ground to the research of Shas- to find an ordering of the the relevant statis- that they are known a priori, or can be computed purely from facts in the database. this work is similar information I2 Technically, some binding F’ U {h,.,il/@} our performance element considers adding in some instunfiation of /I,-,;, list 4). and so we are seeking b q/p, for some binding the smallest lists q5 and pi. index i such that F u {hrci,/~} (i.e., h,,(;,/q?~ for is consistent and R. Greiner/Artficial Intelligence 84 (1996) I77-208 195 situations, we may want In many of a set of subhypotheses, which must all collectively Note N-Acc2. the conjunction reach a conclusion. Here, we can view 31 = P[H] subhypotheses H. to be to as the power set of some set of each hypothesis be asserted to consider so far assumes The description In some contexts, Note N-Acc~. meaningful. hypotheses, perhaps based on specificity or some other criteria use PALOI initially is there may already be a meaningful partial ordering of the [ 401. Here, we can still the relative priorities of the the partial ordering, by determining that every ordering of hypotheses incomparable to complete elements. Note N-ACCA As this PALO1 process can require general determine whether 3 U {hi} course need to insist that this process be decidable with probability polytime propositional Horn theories or propositional if the F U {hi} b’ q k computation 1. We can, however, guarantee (e.g., 2-CNF, etc. [ 83 ) . it can be undecidable to guarantee k=’ q/O(q)), is polytime that each of PALOl’s theorem proving to in general. We of (e.g., that PALO1 will terminate iterations will be if we are dealing with Note N-AC& Recall c( ‘Q, q) for each rij in ‘TA. Above, we obtained that, in general, we need to compute the values of C( rij (rl), q) - this information by determining whether FU {hi} k=? q/O(q) efficient ways of estimating to F U {hi}; hypotheses discussed are not independent; in Note N-ACC~ above. holds for each hypothesis hi. In some situations, there can be more these values, perhaps by using some Horn approximation see Section 5.3 below. We can also simplify e.g., if each corresponds the computation to a set of subhypotheses, if the {hj} as This paper considers only one type of transformation by rearranging into another-viz., e.g., by eliminating Note N-Acc6. theory approaches, modifying be viewed as using a set of transformations theories. We can element some of individual the antecedents then consider to convert one the set of hypotheses. There are many other [ 131, or by [65], etc. Each of these approaches can sets of hypotheses inappropriate rules to navigate around a space of interrelated the same objective described above: to identify the in the implied space that has the highest expected accuracy. to identify cf., the PA0 algorithm discussed Here, as above, the expected accuracy score for each element depends on the unknown distribution, meaning we will need to use some sampling process. In some simple cases, the globally optimal element with we may be able in [ 381. In almost all cases, however, high probability; it identification this makes sense that is close this local optimality will be based on the classes of transformations to a local optimum, with high probability. used to define the space of theories, etc.) and not even approximable to identify an element to use a hill-climbing [33]. Here again (an approximation is intractable, (Of course, like PALOI system task to) Note N-Acc~. There are several obvious extensions sumes that each answer general, we can imagine to a query a range of answers is either completely to this task: First, our model as- in than correct or completely false; to a query, some of which are better 196 R. Greiner/Artijicrul Intellipv~ce 84 (1996) 177-208 IDK Fig. 4. Flow diagram of (S, W) addressing X k’! IT. N important; is $2,000 that watch7 is expensive.) e.g., knowing (For example, all of these points the correct answer i.e., a wrong answer We have also assumed that the cost of watch7 for the location of a salt-shaker, or of a stalking to a particular existential query could be a set instantiations. Here, returning 9 of them may be better than returning 0, or I wrong answer. As another situation, we may be able to rank responses is more that all to any query “costs” us the same - 1, tiger. One way the user to specify her own general c( 0, q) the factors, by differentially weighting others. of 10 distinct than returning in terms of their precision: precise than knowing only queries are equally whether we are asking of addressing function, which could incorporate different queries, On a related cost that answer. Within our framework, however, we can consider yet more the user’s tradeoffs between accuracy and system the [ 341. (See also next of obtaining general c( ., .) functions, efficiency, etc. This would allow the user to prefer, for example, a performance that returns correct answer; or even allow subsection.) situations, it to be wrong the different possible answers, etc. that can incorporate than spend a long in some instances the computational IDK in complex has completely this subsection these different time returning is to permit ignored theme, rather 5.3. Improving categoricity if the theory task of determining whether a query The intractable It can, however, be performed [ 181. I3 Selman and Kautz compilation” method: Given a general propositional is a general propositional [ 721 use this observation efficiently is known (assuming P $ NP) to be [ 14,231. only Horn clauses to define a particular “knowledge .Z, their compiler computes theory is entailed by a theory if the theory contains theory theory is a set (conjunction) ” A clausal literals, each either positive or negative. A theory When convenient, we will write each clause as either a disjunction y=a~VnzV~njisequivalenttoy={n~,a~,~cr~}. is Horn if each clause of clauses. where each clause is a set (disjunction) includes at most one positive of atomic literal. of literals, or as a set of literals; e.g., R. Greiner/Art$cial Intelligence 84 (1996) 177-208 197 a pair of “bracketing” Horn theories S and W, with the property S k _Z ‘F W; we call each such S a “Strengthening” of the initial theory 2, and each such W a “Weakening”. Fig. 4 shows how the resulting “compiled system” 0 = (S, W) uses these bracketing theories to determine whether a query (T follows from 2: If W k cr, then 0 terminates with “yes”; otherwise, if S p u, then 0 terminates with “no”. (Notice that these are the correct answers, in that W b (+ guarantees that 2: /= u, and S p u guarantees that 2 b u. Moreover, these tests are linear in the sizes of u and S (respectively, u and W), provided 1u is Horn [ 181. l4 ) Otherwise, if W F u and S k u, 0 returns IDK. Notice this compiled system is usually tractable, I5 yet can deal with an arbitrary propositional theory. However, it may not be completely categoric, as it may return IDK for some queries, rather than either Yes or No. Hence, we have sacrificed completeness for tractability. We of course would like to use an approximation (Si, Wi) that is as categorical as possible; i.e., which minimizes the probability that the associated (Si, Wi) system will return IDK. To state this more precisely: Given any approximation (S, W) and query u, let C,((S?W),U) dzf d(Wu) +(l -d(S,u)), where for any theory T, d(T,u) Ef 1, ifT/=u, 0, otherwise. Hence, cc ( (S, W), a) = 1 if u is “covered” by (S, W), in that either W k u or S F u. Using Eq. (2)) we can then define C,( (S, W)) to be the expected value of c,( (S, W), .). Our goal is to determine the approximation (S, W) with the largest C,( .) value. As before, this task is intractable (see [72 ] ) and depends on the distribution, suggesting yet again that we use the PALOI system. Observe that the set of queries covered by a strengthening and a weakening are for any approximation (S, W), there is no query u such that both W + u disjoint-i.e., and S p u. This means an approximation (Si, W;) is, with probability at least 1 - 6, within e of a local optimum if Si (respectively, Wj) is within E of a locally op- timal strengthening (respectively, weakening) with probability at least 1 - 6/2. We can therefore decouple the task of finding a good strengthening from that of finding a good weakening, and handle each separately. This paper focuses on how to find a good strengthening; Note N-CATI below discusses how to compute a good weaken- ing. Hence, we are seeking a strengthening Sort whose D(S,,,,) value is minimal, where D( &,r) = E[d( S, .) ] is the expected value of d( S, s). (Recall we want S,,, + u to fail for as many queries as possible.) It is easy to see that this S,,, should be a weakest strengthening; i.e., satisfy OptS( 2, S,,,) where I4 We can actually allow the query (T to be a conjunction of “Horn-dual” is a Horn-dual I5 Note N-CATI below explains iff its negation 1~ is Horn. Notice this class of Horn-duals this caveat. propositions, where a proposition u strictly includes CNE 198 R. Gmner/Artijiciul Intelligence 84 (1996) 177-208 OptS(X,S) M S + 2’ & Horn(S) & . ) -br} to be any maximal clause these Opt%: Define a “Horn-strengthening” To compute dq.. Horn-strengthening Here, there are k Horn-strengthenings for some j = I ..k. For example, y E al V a2 V 761 V Tb2 are yl E al V d>~ V 7b2 and y2 = a2 V 161 V Tb2. of the clause Y = {a,, that is a subset of Y and is Horn-i.e., all but one of Y’s positive of this Y, each of the form y, = {aj, 41,. is formed by simply discarding the two Horn-strengthenings of the non-Horn . . , ak, each literals. . , +p} clause subset. Selman and Kautz ,V = Z‘H U 2~. where ZH is the subset of X’s clauses is its non-Horn [72] prove is of the form S,, = 2~ U _‘k, where each Y’ E 2; Now write Z’N = {Yi)f$ strengthening of some Y E .Z,v. By identifying positive we can consider any Horn-strengthened 2-U “{Y.)(,,,Y~,2,..“lY:;,,,, Horn clauses 1,v = {yl, yz} where y1 = al V a:, V -bj V lb2 and y2 = cl V cz V CJ V 41, the (1.3) strengthening would be theory to be a set of the form Scic 1 ),j(*),__,,,(m)) = the theory 2 = 2~ U 2~ with non- literal used (i.e., using y,; of the form shown above, yfi = {LZ;, Tb{, . _ . , -bi,}), that are Horn and that each optimal theory with the “index” of the }. For example. given each Horn-strengthened is a Horn-strengthening WC can navigate about this space ol‘ Horn-strengthened theories by changing the index non-Horn associated with individual F’ = {~L.J},<~Q,,;~<~Q where each 7k.i is a function another by changing S;?,g,. .,1,...,5). (Of course, m is the number of non-Horn number of propositional the “index” of the kth clause variables that maps one strengthening to to be !; e.g., 7k,~(S(3,9,....~~,.,_,~j) = in _Z and II is the total clauses in the theory.) Continuing with the earlier example, clauses: That is, define the set of transformations ?,I (S(1.3)) = S(1.1) = X‘H u a I Cl V lb, v Tb2 V ldl and 71.2(S(l.3)) = S(2.3) = z‘“U a2 v --b, v Tb2 ci V ldl 1. This instantiation of the PALO1 process starts with the given Horn-strengthened theory (perhaps S(l,l, ,,,,) ) and hill-climbs theories, using this set of 7’ transformations. As d(S,, S’,n) depends only on whether S’ b c and S; k LT, it can be answered efficiently, as each S, and S’ are Horn. (In fact, this process can also use the support of u from S; to further its efficiency.) Notice finally that /2(S;, S’) < I for all strengthenings in the space of Horn-strengthened Si and S’. improve Note N-CATS. Selman and Kautz I721 prove that there is a unique optimal weakening, theory. Unfortu- ws, which corresponds theory nately, this w, can be exponentially the as the complexity of w, /= g cost of using to the set of all Horn implicates of the initial larger than the original (S, w,,) to answer queries can be exponential, [ 5 I]. This means R. Greiner/Artificial Intelligence 84 (1996) 177-208 is linear T. (This was not an issue with strengthenings, in Iw,[ = 0(214), where the size (T( of a theory T is the number of clauses Si is “small”, as each strengthening 199 in in fact, l&l < )-Xl.) We avoid this potential blow-up by considering only weakenings of size at most K = K( (Zl), where K( .) is a user-supplied the user’s tradeoffs between efficiency the weakening of this size that is maximally Once again, task of determining which Theorem A.2 in the Appendix. is best, even given to implement (polynomial) and categoricity. Our goal, therefore, function, designed is to find categorical, over the distribution of queries. the see and moreover, intractable; the distribution, is again this best K-sized weakening depends on the distribution, This motivates us to use PALO1 for this subtask as well. The space of transformations to describe, however. Selman and Kautz [72] provide an (expo- this clause, resolvent, after removing all subsumed clauses. Each of our for computing to resolve each Horn clause with each non-Horn the optimal weakening w,. In essence, 7k E Iw performs one such step. There of keeping to remove a clause from the current approximation, the total number of clauses bounded; is, of course, the additional this may force the trans- to make room for each iteratively time) algorithm LUB attempts is more complicated nential algorithm and adds in each successful transformations challenge formations proposed addition. We discuss these in detail transformations that hill-climbs called ADCOMP, (S;, Wj) approximation in both spaces, and a near-optimal weakening. This algorithm in [39], and also present a PALO,-ish algorithm, to find both a near-optimal strengthening in two senses: is tractable The as both Si and W,j are Horn and of bounded to be tractable, basically because ADCOMP never computes 2 j= (T. Instead, ADCOMP theories Si and Wj, together with approximates the neighbors 7( Si) and T( Wj). As there are only a polynomial number of neighbors, and each theory 2 F (T is efficient. is both Horn and of bounded size, the overall computation size; and also each of ADCOMP’S steps is guaranteed admits efficient computation, that approximates this computation it produces using only the current The user-specified K( -) function, used to bound quantifies how much Note N-CAT2 ing, implicitly to answer a query before idea by allowing ci( (S, W), a) quantifies how well the approximation can specify an arbitrary combination and efficiency. On a related (See also the discussion theme:, our current of various factors, in Note N-Acc7 (Si, Wj) system returns the user insisting including above.) time the user will allow the system that it stop and return to specify her own general utility measure the size of the weaken- to spend trying this ci( ., e), where (7, which accuracy, categoricity IDK. We can generalize (S, W) does at solving for this situation-e.g., spend as long as necessary IDK if W F u and S k (+. perhaps 0 should “guess” at an to compute whether 2 k=? (+, this depends on the user’s objectives, which can be incorporated within in the and in their way of handling in parallel with its search for good weakenings then use a PALO-like system function; we could (which differ to climb elements There are many other options answer here, or alternatively etc. Of course, her ci( (S, W), g) utility the space of such performance “W F CT and S + CT” situation), strengthenings; see [ 391. 200 R. Greiner/Arti$ciul lnrelligence 84 (1996) 177-208 [ 7, 15,20,47,56], Note N-CAT% This compilation work is obviously and “approximation” theory into a representation work extends maximally an efficient, autonomous way of computing those results by ( I ) quantifying categorical over the anticipated that admits more efficient, related to the work on “vividization” which also try to transform a given intractable if less categorical, reasoning. Our that is a system the goal of producing distribution of queries; and (2) by providing such an efficient approximation. 6. Conclusion 6.1. Other vuriants of PALO systems specified from PALO] the properties after each sample, 1. The technical note climbing or terminating the PALOMAR of Note N-PALO& for each climb.) Another alternative As suggested by the “1” subscript of “PALOI", there is a family of algorithms in Theorem that [ 311 presents in small, but significant, the simpler instead examines an entire collection of L: samples this PALO~ uses a different batch of each satisfy various other PALOi algorithms, which differ ways. While PALO~ considers “on-line but batched” PALO0 system at a time. (Unlike samples to climb only a bounded number of times, where the bound can be precisely Finally, distribution “barriers” before deciding more likely (There are also PALOON and PALOZN algorithms, which differ from PALO0 and PAL02 assumptions, Notice also that these splits, of PALO0 versus only by making normality PALO1 versus PAL02, and PALOX versus PALOX~, are orthogonal to one another, and also orthogonal in Section 5 above. In particular, any of these PALO, systems can be used to address any of these applications.) is the PALO2 system, which is guaranteed specified. about the world; viz., that the it to use lower is if the data is not really drawn from a normal distribution. the PALOIN system makes stronger assumptions to the set of the applications discussed to climb, or to terminate. Of course, is normal. This allows the samples are drawn the PALOIN system to make mistakes from which We [ 3 I] empirically tested these different PALO; systems that the PALO] system discussed here was usually in several different contexts, the best, in terms of the element, as a function of the empirical sample complexity. in one particular that PALOIN worked effectively and found utility of its final performance More recently, however, we found context; see [35]. 6.2. Limitations is designed (but stationary) The examples discussed PALO objective, of identifying arbitrary system is required computing information, common to handle situation. distribution the versatility in Section 5 illustrate a performance and generality of the element whose expected utility, over an is optimal. Our particular PALO the situations when ( 1) the distribution of samples, which the task of is not known a priori, and (2) of problems, to determine the optimal element based on this quality measure, once given the distribution the expected values, is intractable. The situations presented above illustrate that this is a very R. Greiner/Artijkial Intelligence 84 (1996) 177-208 201 It is worth discussing PALO’s limitations as well, to understand when be applied. PALO expected utility if not, tionary; is best used when is maximal. Notice then even defining if the task the goal is to find a performance first that this implies this expected utility can be problematic. that the distribution is inherently mini-mar: seeking this, imagine 01 requires 0.5 seconds is not useful it is critical the worst possible is as good as possible. For example, return an answer within say 1 second; for taking under 1 second, but an extreme penalty to know PALO worst case performance tem that will always benefit 1 second. Here, can require. To illustrate 02 requires only 0.001 seconds pears only 0.001% of the time, but 02 requires 2 seconds though 02 clearly has a better expected efficiency worse; which means, by the above criterion, we could model for q, and would be infinite, which would prevent PALO ing.) this situation otherwise. Here, however, for all but one extremely that 01 should -cc by defining ~(0, q) = 0 iff 0 it should not element whose is sta- Second, the element whose imagine we need a sys- i.e., there is no additional than for taking any longer element for all samples, while rare query C&d, which ap- for this C&ad. Here, even is (Of course, takes under 1 second time a performance than 01, its worst case efficiency is prefered. the value of Eq. (1)‘s A = h(c, &,&) or terminat- from ever either climbing Another limitation is that PALO may not reach the global optimum, as it is only hill- it may not even find a local optimum, as it is only (probabilistically) climbing. Worse, guaranteed slope”-i.e., 0. As mentioned such non-global This approach, however, sacrifices to find an e-local optimum, which means when O’s neighbors are, at best, only slightly earlier, we could build a PALO-like c-local optima by stochastically descending, the guarantees proven above. it will stop on reaching a “gentle (read “under e”) better than to avoids annealing. that attempts a la simulated system then if there The conditions the global optimum; the weak hill-climbing method are also situations where PALO shouZd not be used. For example, use is a known efficient puting cf., [ 2,781. Here, it is often sufficient the distribution, inappropriate run a standard hill-climbing the actual expected utility, computed directly obvious variants of PALO constrained, sample efficient. above specify situations where PALO will not work effectively. There there is no need to technique for com- to simply estimate let the efficient algorithm use that estimate. PALO can also be initially; here, it is probably better to simply for each element there are is etc.; these variants may be more above.) perhaps by being known (See the PALOIN to be Gaussian, system mentioned algorithm, using as the quality measure rather than estimated. Similarly, that can be used when if the distribution of the samples the distribution is known 6.3. Contributions This paper first poses two of the problems element whose expected utility that can arise is optimal (which is required to determine which element and that finding a globally optimal performance in learning [43,80] that systems : that the distri- is usually element can be intractable. is optimal) an algorithm, PALOI, to approximate that side-steps these shortcomings the distribution, and by hill-climbing by using a to produce a information seek a performance bution unknown, It then presents statistical technique 202 K. Grerner/Arti$ciul Intelligence 84 (1996) 177-20X Table 2 Summary of applications Performance Utility function c( ., ) elements &J Transformations ‘T .I I R, T( f9) I Range Efficiency Accuracy Categoricity satisficing strategies hypothesis orderings computation time reorder arcs < L.(G) (I,(q) =? O(q) reorder priority <? Horn-strengthenings ( WF”Y) sl=‘4 change 1 clause 61 this algorithm and specifying its behavior, we locally optimal element. After detining demonstrate PALOt’s element in three different and different criteria for optimality: These suggest approaches explanation-based ing and the tractability/completeness learning, results generality by showing settings, based on different that it can be used to find a near-optimal elements spaces of performance (See Table 2.) from reason- efficiency, accuracy and categoricity. (respectively) to solving the multiple extension problem the utility problem from nonmonotonic tradeoff problem from knowledge representation. Acknowledgements This work began at the University of Toronto, where for Robotics and Intelligent Systems and by an operating grant from it was supported the Institute National Science and Engineering Research Council of Canada. edge receiving many helpful comments anonymous referees. from William Cohen, Dale Schuurmans in part by the acknowl- and the I gratefully Appendix A. Proofs Theorem 1. The PALOt formance elements @I,&, and, with probability at least 1 - 6, (01. I, F, 6) process , @,,, such that each @j?i+l = 7kj incrementally produces a series of per- ) for some Tk, E 7 <@] (1) the expected utility of each performance cessors , i.e., element is strictly better than its prede- VI < i <j 6 m: C(e),) > C(0;); (2) the$nal pelformance i.e., element returned by PALOt, @,,, is an “e-local optimum”- 47 E 7: C(7(0,,)) 2 C(f9,) + E. Moreover, PALO] will stay at any 0, @,i+l) fora numberof samples that ispolynomial and will terminate with probability 1, provided (before either terminating or climbing l/6, in I/E, IS,,1 is finite. to a new /\(c, Q, Se) and I’;r[Oj] 1, R. Greiner/ArtQicial Intelligence 84 (1996) 177-208 203 Proof. To prove parts ( 1) and (2)) consider when make: it is dealing with Oj. Notice there are four types of mistakes first a single stage of the PALO~ algorithm, that PALO] could i samples (for some i = 1.. Lj - I), PALO1 could i = 1.. Lj - 1) , PALO1 could climb from Oj to be better than Oj (based on the line (L3) i samples After seeing (for some to some 0’ = r( Oj) as 0’ appears test), but in reality, 0’ is not better; or after seeing 0’ = r( Oj) appears test), but there is some 0’ that is much better; or after seeing all Lj samples, PALO1 could climb from Oj to some 0’ = r(Oj) 0’ appears is not better; or After seeing all Lj samples, PALO] could to be more than E better than Oj, but there is some 0’ that is much better. as to be better than Oj (based on the line (L5) test), but in reality, 0’ as no than Oj (based on the line (L4) as no 0’ = r( Oj) appears to be more than E better terminate terminate (A) (B) (C) (D) Using ei(@‘) = A(@j,@'> ( &ln 2(Lj - 1)/7[@jll si 1 i as the “barrier” used to decide whether seeing the respective probabilities i samples, of these events are to climb to the neighboring 0’ = r(Oj) after a> =Pr 30’ E 7[Oj]: jd(O,,B’,i) > Ed and C(H) < C(@j) 9 1 bi = Pr 30’ E ‘T[Oj]: fd(@j,s’,i) < E - &i(O’) and C(0’) > C(Oj) + E I , cj=Pr 30’~7[Oj]: id(O,,O’,Lj) 2; andC(O’) <C(Oj) J , I dj = Pr 30’ E ‘T[Oj]: iA(S,,@‘,Lj) < z and C(Oj> > C(Oj) +E J . 1 Of course, each existential within a Pr[ .] above over elements of I[ Oj] . Moreover, ai is only considering C( 0’) < C( Oj) ; hence using I< = (0’ E I[ Oj] 1 C( 0’) < C( Oj)}, is really a finite disjunction, ranging the subset of O’s for which a$ = Pr v iA(@j,@,i) bEi(O’) 1 and using 7> = (0’ E 7[Oj] ( C(@‘) > C(@j> + E}* ‘A(,, i 0’ ‘, i) 6 E - Ei(@‘) 1 and so on. 204 R. Greiner/Arrificiul Intelligence 84 (1996) 177-208 Now observe that fd(@,.d.i) 3 (C(0’) -C(Oj)) +&j(d) 1 (A.1) > (A.21 6 (7‘ j exp -2i i ( A(@,,@‘) z-z II’/ 6, 2(L, - 1 )l7[@., I/ 1/(2i) In (2tLj - l>l~[@jlllsj) * A(@.,, 0’) ii (A.1 ) f‘ollows -C(@.,) the observation from < 0 implies line C(r(0,)) (using A + B implies Pr[ A] < Pr[ B J, for any events A and B). Line Hoeffding’s the empirical (Eq. (6)) based on the realization that ( l/‘i)d(Oj, distributed average of a set of i independent, (I/i)d(@,j,T(Oj),i) identically inequality (l/i)d(Oj, O’, i) that 3 (C(T(Oj))-C(Oj))+&i(@‘) 3 (A.2) uses i) is r(Oj), random values is C( 0’) - C( Oj), and whose ei(O’) and {c(r(@.,),ql) range of possible values - c(@;JIL));+ is at most il( O,, 0’) whose (common) mean Similarly, 0; < c Pr Ll(H,;.O’.i) /-YE7 i < E-&,(0’) I < fA(O,.@‘.i) < (C(H) -C(Oj)) -pi 1 In a similar manner, we can bound 4 = '7"'2i7[@.j] / (line (A.3) uses the fact that /l( Oj, 0’) < A[ @j] ); and likewise (A.3) R. Greiner/Artificial Intelligence 84 (1996) 177-208 205 Hence, the probability of making any type of mistake at the jth stage is bounded by U; + b$ + Cj + dj L, - I i 1 c i=l sj as ‘F and 7’ are disjoint subsets of 7[Oj], and SO lir<l + (7’1 Q Il[Oj]l. The probability that PALO] will make a mistake (of any kind) on any step is at most as desired. To deal with PALOl’s efficiency: Notice it can stay at any Oj performance at most LJ samples, a quantity 2A(c, Q,So), l/e and l/6. that is clearly polynomial in [7[Oj] element for ( < 171, _4[@j] ,< To show that PALO1 will terminate with probability 1 when I&J is finite, notice the only way that PALO1 can fail to terminate here is if it cycles first that some @ is strictly better time thinking later, thinking that @ is better, switching back. Of course, one of these inequalities necessarily by max{u:,cj}i,j that PALO~ will make such a mistake that PALO] will make < Si/2 < 6/2. The probability than Oj and so switching false; and the probability is bounded this type of that infinitely often: each to it, and is mistake an infinite number of times is therefore (at most) lim,,,,, flz, 6/2 = 0. 0 Definition A.1 (The K-WEAK rusk). Instance: A propositional theory _E (in CNF), a positive integer K, a sample S = {qi}, and an integer f E [ O..K] . Question: Is there a Horn-weakening f of S’s queries? (I.e., 2 /== W, such that ){q E S 1 W k q}) 2 f?) is there a conjunction of 2 of size at most K which covers at least of at most K Horn clauses, W, where Theorem A.2. The K-WJZAK task is NP-complete. is clearly its coverage. To show K-WEAK Proof. K-W&AK confirm task to it [23] : Given any boolean and let K = 2, f = 1 and the set of samples S = {q&lq} and SAT for SAT, let 2 be the set of its clauses, be a single unsatisfiable in NP, as we need only guess a potential weakening, the NP-complete is NP-hard, we reduce formula 206 R. Grevxr/ArtiJlciul Intelligence 84 (I 996) 177-208 If 2 is consistent, proposition. hence has coverage 0; i.e., W /& q&lq. a size 2 weakening of the form {r, v}, whose categoricity that can solve arbitrary Otherwise, consistent, and then it will have is 1. Hence, any algorithm 0 instances of K-WEAK can also solve arbitrary SAT instances. then every weakening W is necessarily if 2 is inconsistent, References [ II S. Arora, C. Lund, R. Motwani, M. Sudan and M. Szegedy, Proof verification and hardness of approximation Science ( 1992) 14-23. problems, in: Proceedings 33rd Annuul IEEE Symposium on Foundations of Computer 12 1 P. Auer, R. Holte and W. Maass. Theory and applications of agnoistic PACtearning with small decision Conference on Muchine Learning, Lake Tahoe, CA ( 199.5). (Chapman and Hall, 13 1 D.A. Berry and B. Fristedt, Bandit Problems: Sequential Allocation trees, in: Proceedings Twelfrh cfExperimen/s International London, 198.5). 14 1 M. Boddy and T. Dean, Solving time dependent planning problems, Tech. Repr., Brown University, Providence, RI ( 1988). [ 5 ] B. Bollobls, Random Gruphs 16 J L. Booker, D. Goldberg and J. Holland, Classifier systems and genetic algorithms, Artif (Academic Press. New York, 1985). Intell. 40 ( 1989) 235-282. 17 I A. Borgida and D. Etherington, Hierarchical knowledge bases and efficient disjunctive reasoning, in: Proceedings KR-89, Toronto, Ont. ( 1989) 33-41. 18 I E. Boros, Y. Crama and t? Hammer, Polynomial-time inference of all valid implications for Horn and formulae, Ann. Moth. ArttJ related G. Brewka, Preferred subtheories: IJCAI-89, Detroit, MI ( 1989) 1043-1048. R. Caruana and D. Freitag, Greedy attribute selection, Intell. 1 ( 1990) 21-32. an extended 191 1101 logical framework for default reasoning, in: Proceedings in: Proceedings Eleventh International Conjkrence on Machine Learning, New Brunswick, NJ ( 1994) 28-36. H. Chemoff. A measure of asymptotic efficiency for rests of a hypothesis IIll based on the stuns of observations, Ann. Math. Stat. 23 ( 1952) 493-507. W.F. Clocksin and C.S. Mellish. Programming W.W. Cohen, Learning textbook knowledge: from 1121 1131 irt Prolog (Springer, New York, I98 I ). a case study, in: Proceeding AAAI-90, Boston, MA I141 I lfil 1161 I171 1181 I191 120 121 122 I23 procedures, of theorem-proving in: Proceedings 3rd ACM Symposium on (1990). S.A. Cook, The complexity the Theory of Computing, New York ( I97 I ) IS I - 158. M. Dalal and D. Etherington, Tractable approximate deduction using limited vocabulary, in: Proceedings Nmth Biennial Conjtirencc ofthr Canadian Society.fi>r Computational Studies oj’lntelligence, Vancouver, BC (1992). T. Dean and M. Boddy, An analysis of time-dependent MN (1988) 49-54. G. DeJong, ed., Proceedings AAAl Wi,rkshop on Explanation-Based W.F. Dowling and J.H. Gallier, Linear time algorithms formula, J. Doyle and R.S. Patil, Two classification, D.W. Etherington, A. Borgida, R.J. Brachman and H. Kautz, Vivid knowledge and tractable preliminary IJCAI-89, Detroit, MI ( 1989) 1146-l 152. j. Logic Program. 3 ( 1984) 267-284. in: Proceedings AAAI-88, St. Paul, the satisfiability of propositional Horn and the utility of representation Intell. 48 (1991) 261-297. theses of knowledge in: Proceedings services, Artif representation: restrictions, for testing taxonomic reasoning: planning, language Learning ( 1988). report, 0. Etzioni. Tractable decision-analytic P Fong, A quantitative on Machine Learning, Lake Tahoe, CA ( 199.5). M.R. Garey and D.S. Johnson. Computers und lntructability: (Freeman, New York, 1979). study of hypothesis selection, control, in: Proceedings KR-89, Toronto, Ont. ( 1989). in: Proceedings Twelffh International Conference A Guide to the Theory of NP-Completeness R. Greiner/Arrijicial Intelligence 84 (1996) 177-208 207 [24] M.R. Genesereth and N.J. Nilsson, Logical Foundations of Artificial Intelligence (Morgan Kaufmann, Los Altos, CA, 1987). [25] A. Goldberg, An average case complexity analysis of the satisfiability problem, in: Proceedings 4th Workshop on Automated DeducGon, Austin, TX (1979) 1-6. [26] I.J. Good, Twenty-seven principles of rationality, in: V.P. Godambe and D.A. Sprott, eds., Foundations of Staristical Inference (Holt, Rinehart and Winston, Toronto, Ont., 197 1) [ 271 J. Gratch, S. Chien and G. DeJong, Improving learning performance through rational resource allocation, in: Proceedings AAAI-94, Seattle, WA ( 1994) 576-58 1. [ 281 J. Gratch and G. DeJong, A hybrid approach to guaranteed effective control strategies, in: Proceedings Intemationnl Workshop on Machine Learning, Evanston, IL ( 199 1) 509-5 13. [ZQ] J. Gratch and G. Dejong, COMPOSER: a probabilistic solution to the utility problem in speed-up learning, in: Proceedings AAAI-92, San Jose, CA ( 1992). [ 30 J R. Greiner, Finding the optimal derivation strategy in a redundant knowledge base, Artif Intell. 50 (1991) 95-116. [ 3 1 ] R. Greiner, PALO algorithms, Tech. Rept., Siemens Corporate Research, Princeton, NJ ( 1993). [ 321 R. Greiner, The challenge of revising impure theories, in: Proceedings Twe@h International Conference on Machine Learning, Lake Tahoe, CA ( 1995). [ 331 R. Greiner, The complexity of theory revision, in: Proceedings IJCAI-95, Montreal, Que. ( 1995). (See also: ftp:/ /scr.siemens.com/pub/learning/Papers/greinerlcomp-tr.ps.) [ 341 R. Greiner and C. Elkan, Measuring and improving the effectiveness of representations, in: Proceedings IJCAI-91, Sydney, Australia (1991) 518-524. [35] R. Greiner and R. Isukapalli, Learning to select useful landmarks, in: M. Dorigo, ed., Special Issue on Learning Approaches to Autonomous Robots Control, IEEE Trans. Syst. Man Cybern.-Parr B 26 (3) ( 1996) 437-449. [36] R. Greiner and I. JuriSica, A statistical approach to solving the EBL utility problem, in: Proceedings AAAI-92, San Jose, CA ( 1992). 1371 R. Greiner and P. Orponen, Probably approximately optimal derivation strategies, in: J. Allen, R. Fikes and E. Sandewall, eds., Proceedings KR-91, Cambridge, MA (Morgan Kaufmann, San Mateo, CA, 1991). [ 381 R. Greiner and P. Orponen, Probably approximately optimal satisficing strategies, Arr$ Inrell. 82 ( 1996) 21-44. [39] R. Greiner and D. Schuurmans, Learning useful Horn approximations, in: B. Nebel, C. Rich and W. Swartout, eds., Proceedings KR-92, Cambridge, MA (Morgan Kaufmann, San Mateo, CA, 1992). 1401 B. Grosof, Generalizing prioritization, in: Proceedings KR-91, Cambridge, MA (1991) 289-300. 1411 S. Hanks and D. McDermott, Default reasoning, nonmonotonic logics, and the frame problem, in: Proceedings AAAI-86, Philadelphia, PA (1986) 328-333. 1421 D. Haussler, Quantifying inductive bias: AI learning algorithms and Valiant’s learning framework, Arrif: Inrell. 36 (1988) 177-221. [ 43) D. Haussler, Decision theoretic generalizations of the PAC model for neural net and other learning applications, Inf: Cornput. 100 (1992) 78-150. [44] G. Hinton, Connectionist learning procedures, A@ [45] W. Ho&ding, Probability inequalities for sums of bounded random variables, J. Am. Star. Assoc. 58 Intell. 40 (1989) 185-234. (301) (1963) 13-30. [46] E.J. Horovitz, Reasoning about beliefs and actions under computational resource constraints, in: Uncertainty in Ar@Szl Inrelligence 3 (North-Holland, Amsterdam, 1987). [47] T. Imielinski, Domain abstraction and limited reasoning, in: Proceedings IJCAI-87, Milan (1987) 997- 1003. [ 48 J G.H. John, R. Kohavi and K. Pfleger, Irrelevant features and the subset selection problem, in: Proceedings Eleventh Internarional Conference on Machine Learning, New Brunswick, NJ (1994) 121-129. 1491 I. JuriSica, Query optimization for knowledge base management systems; a machine learning approach, Master’s Thesis, Department of Computer Science, University of Toronto, Toronto, Ont. ( 1992). 1501 L.P. Kaelbling, Learning in Embedded Systems (MIT Press, Cambridge, MA, 1993). 151 I H. Kautz and B. Selman, Speeding inference by acquiring new concepts, in: Proceedings AAAI-92, San Jose, CA (1992). 208 R. Greiner/Ar$ciul Inrelligence R4 (1996) I77-208 [ 52 1 R.M. Keller, Defining operationality for explanation-based learning, in: Proceedings AAAI-87, Seattle, WA ( 1987) 482-487. 15.7 I S. Kirkpatrick, CD. Gelatt and M.P. Vecchi, Optimization by simulated annealing, Science 220 (1983) 671-680. 1541 H. Kyburg, The reference class, Philos. Ser. 50 ( 1982). 155 I J.E. Laird, A. Newell and P.S. Rosenbloom, SOAR: an architecture of general intelligence, Arti$ Intell. 33 (1987) l-64. I56 1 H. Levesque, Making believers out of computers, Artif: I57 1 K. Loui. Computing reference classes, Intell. 30 (1986) 81-108. in: Proceedings AAAI Workshop on Uncertuing, St. Paul, MN (1988). I58 I 0. Maron and A. Moore, Ho&ding in: Advances function approximation, Los Altos, CA, 1994). races: accelerating model selection in Neural Information Processing Systems 6 (Morgan Kaufmann, search for classification and ( S9 1 S. Minton. Leurning Seurch Control Knou’ledge: An Exphnution-Based Approach (Kluwer Academic Publishers, Hingham, MA, 1988). I60 1 S. Minton, J. Carbonell, C. Knoblock, D. Kuokka, 0. Etzioni and Y. Gil, Explanation-based learning: a problem solving perspective, Arrif Intell. 40 ( 1989) 63- 1 19. ) 61 1 T.M. Mitchell, The need for bias in learning generalizations, Tech. Rept. CBM-TR-117. Laboratory for Computer Science Research ( 1980). [ 62 I T.M. Mitchell. S. Mahadevan and L.I. Steinberg, LEAP: a learning apprentice for VLSI design, in: Proceedings IJCAI-85, Los Angeles, CA ( 1985) S73-580. 163 1 I? Morris, Curing anomalous extensions, 1641 K.S. Narendra and M.A.L. Thathachar, Learning Automata: An Introduction in: Proceedings AAAI-87, Seattle, WA ( 1987) 437-442. (Prentice-Hall, Englewood Cliffs, NJ, 1989). 1651 D. Ourston and R.J. Mooney, Theory refinement combining analytical and empirical methods, Artif Inrell. 66 ( 1994) 273-3 10. I66 ] D. Poole, R. Goebel and R. Aleliunas, Theorist: a logical reasoning system for default and diagnosis, in: semantics of stratified deductive databases of Deductive Databuses und Logic Programming N. Cercone and ii. McCalla, eds., The Knowledge Frontier: Essays in the Representation (Springer, New York, 1987) 33 I-3.52. I67 I T.C. Przymusiriski, On the declarative in: J. Minker, ed.. Found&ions Los Altos, CA, 1987) 193-216. J.R. Quinlan, Cd.5: Programsfor R. Reiter, Nonmonotonic S. Russell, D. Subramanian Chambery, France ( 1993). S.J. Russell and B.N. Grosof, A declarative AAAI-87, Seattle, WA ( 1987) 505-510. B. Selman and H. Kautz, Knowledge compilation using Horn approximations, Anaheim, CA ( I99 1) 904-909. reasoning, Ann. Rev. Cornput. Sci. 2 ( 1987) 147-187. and R. Parr. Provably bounded optimal agents, Muchine burning 168 169 I70 in concept approach learning, to bias i 72 171 in: Proceedings IJCAI-93, in: Proceedings in: Proceedings AAAI-91, of Knowledge and logic programs, (Morgan Kaufmann, (Morgan Kaufman% San Mateo, CA, 1993). 17.11 L. Shastri, Default reasoning in semantic networks: a formalization of recognition and inheritance, Arti$ InteN. 39 ( 1989) 283-355. [ 74 ] H.A. Simon and J.B. Kadane, Optimal problem-solving search: all-or-none solutions, Arlif: Inrell. 6 (1975) 23.5-247. 175 I D.E. Smith, Controlling backward [ 761 R.S. Sutton, ed., Special 1771 P.E. Utgoff, Shift of bias for inductive concept inference, A@ Issue on Reinforcement Learning. Much. Learn. 8 ( 1992). fntell. 39 ( 1989) 145-208. learning, Ph.D. Thesis, Laboratory for Computer Science Research, Rutgers University, New Brunswick, NJ ( 1984) 1781 L.C. Valiant, A theory of the learnable, Commun. ACM 27 ( 1984) 1134-I 142. I79 I F’. van Arragon, Nested default reasoning with priority levels, in: Proceedings Ninth Biennial Conference of the Canadian Society for Computational qf Dependences Based on Empirical Data Studies of Intelligence, Ottawa, Ont. ( 1990) 77-83. (Springer, New York, 1982). I 80 1 V. Vapnik, Estimation 