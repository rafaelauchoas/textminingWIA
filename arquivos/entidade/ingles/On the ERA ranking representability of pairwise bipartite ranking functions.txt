Artificial Intelligence 175 (2011) 1223–1250Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the ERA ranking representability of pairwise bipartite rankingfunctionsWillem Waegeman∗, Bernard De BaetsKERMIT, Department of Applied Mathematics, Biometrics and Process Control, Ghent University, Coupure links 653, B-9000 Ghent, Belgiuma r t i c l ei n f oa b s t r a c tArticle history:Received 31 January 2009Received in revised form 19 June 2010Accepted 19 June 2010Available online 2 December 2010Keywords:Pairwise bipartite rankingReciprocal preference relationCycle transitivityReceiver operating characteristics (ROC)analysisGraph theoryMulti-class classificationDecision theoryMachine learning1. IntroductionIn domains like decision theory and social choice theory it is known for a long timethat stochastic transitivity properties yield necessary and sufficient conditions for theranking or utility representability of reciprocal preference relations. In this article weextend these results for reciprocal preference relations originating from the pairwisecomparison of random vectors in a machine learning context. More specifically, theexpected ranking accuracy (ERA) is such a reciprocal relation that occurs in multi-classclassification problems, when ranking or utility functions are fitted to the data in apairwise manner. We establish necessary and sufficient conditions for which these pairwisebipartite ranking functions can be simplified to a single ranking function such that thepairwise expected ranking accuracies of both models coincide. Similarly as for morecommon reciprocal preference relations, cycle transitivity plays a crucial role in this newsetting. We first consider the finite sample case, for which expected ranking accuracy canbe estimated by means of the area under the ROC curve (AUC), and subsequently, wefurther generalize these results to the underlying distributions. It turns out that the rankingrepresentability of pairwisely compared random vectors can be expressed elegantly in adistribution-independent way by means of a specific type of cycle transitivity, defined by aconjunctor that is closely related to the algebraic product.© 2010 Elsevier B.V. All rights reserved.Multi-class classification and ordinal regression can be seen as two closely related machine learning settings that sharemany properties. Multi-class classification refers to the supervised learning problem of inferring a predictive model capableof classifying data into a finite number of classes. This simply means that the model predicts for new data instances anoutput (also called label or response variable) that takes values in a finite unordered set (for example, class labels red,green, blue). Ordinal regression considers a slightly different setting. Labels here come from a finite ordered set, in whichthe order naturally follows from the semantics of the classes (for example, class labels bad, moderate, good). As a specificcase of preference learning, ordinal regression problems typically arise in situations where humans are involved in the datageneration process, like human experts or internet users expressing preferences on objects w.r.t. characteristics such asquality, beauty, appropriateness, etc.So, the different semantics of the data respectively result in the absence or presence of an order relation on the classesin multi-class classification or ordinal regression. Owing to this important interpretation of the classes, substantially differ-ent methods have been proposed in the past for the two types of learning problems. Briefly summarized, the absence orpresence of an order relation leads to two main differences in assumptions:* Corresponding author. Tel.: +329 264 6018, fax: +329 264 6220.E-mail address: Willem.Waegeman@UGent.be (W. Waegeman).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.0061224W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250(1) Firstly, both models typically differ in the type of performance measure they optimize. If an order relation on theclasses can be assumed, then a performance measure that takes this order into account must be utilized, both foroptimization and evaluation. For example, in ordinal regression, misclassifying an object of class “bad” into class “good”must typically lead to a higher loss than misclassifying the same object into class “moderate”.(2) Secondly, the absence or presence of an order relation on the classes gives rise to a different model structure for thetwo types of problems. The model structure of multi-class classification methods typically consists of an ensemble ofbinary classifiers, such as one-versus-one [26,30] and one-versus-all [41] ensembles, while typically only one globalmodel is considered in ordinal regression. Moreover, this global model always consists of an underlying latent variablethat reflects the order on the classes. Let X denote the set of data objects, then this latent variable serves as a rankingfunction f : X → R that defines a total order on the data objects. The final decision rule is then in the end obtainedby placing a number of thresholds on the ranking function. This is for example the case in traditional statistical ordinalregression algorithms [2,38] and kernel-based methods [6,42].Several authors [27,35,44] empirically analyzed in recent work the relationship between multi-class classification and ordinalregression, in which they primarily aim to improve ordinal regression algorithms by using ideas from multi-class classifica-tion, without considering an underlying ranking function. Conversely, the motivation of this article is to improve multi-classclassification algorithms by using techniques from ordinal regression. Moreover, we will mainly focus on the theoreticalconnections between both problem settings, and to establish such a connection, we will take the ranking function that char-acterizes ordinal regression models as starting point. In this context, expected ranking accuracy (ERA) is a ranking-basedperformance measure that has recently been introduced for bipartite ranking [1] and further extended to ordinal regression[47]. Expected ranking accuracy can be easily considered too in multi-class classification, especially for one-versus-one en-sembles, where the ensemble contains a set of pairwise bipartite ranking functions (i.e. one bipartite ranking function foreach pair of classes). By using concepts from receiver operator characteristics (ROC) analysis, graph theory, decision theoryand preference modeling, we will show that transitivity properties of the reciprocal relation generated by expected rankingaccuracy result in a connection between multi-class classification and ordinal regression models.Roughly speaking, we will investigate the conditions for which a one-versus-one ensemble, containing a set of bipartiteranking functions, can be reduced to an ordinal regression model with only one underlying ranking function, such that bothmodels obtain an identical performance in terms of expected ranking accuracy. We will further refer to this property asERA ranking representability of a one-versus-one ensemble. ERA ranking representability can be interpreted as a naturalextension to the infinite sample case of AUC ranking representability, as previously introduced in [46]. It is well known thatthe area under the ROC curve (AUC) forms an unbiased estimator of the expected ranking accuracy on a finite dataset. Letus as an introductory example in a multi-class classification setting consider the following hypothetical three-class datasetthat contains six objects of each class:21i10 11 12 13 14 15 16 17 189yi C1 C1 C1 C1 C1 C1 C2 C2 C2 C2 C2 C2 C3 C3 C3 C3 C3 C3836754We have for simplicity assigned the indices in such a way that pairwise AUCs can be computed easily for a given ranking.Remark that the AUC simply computes the fraction of (lower class, higher class) couples that are correctly ranked by theclassifier. Let us suppose that the following triplet of bipartite ranking functions is statistically inferred by a one-versus-oneensemble for this small toy problem:iranking for f 12 72 9ranking for f 23 13 7 14 8 9ranking for f 13 13 1 28 14310 11 12610 11 12 15 16 17 1853 14 15 16 17 18 456So, from left to right, the numbers represent the ranking of the indices of the data objects, respectively obtained with theranking functions f 12, f 23 and f 13. For the pairwise AUCs we find:(cid:2)A12( f 12, D) = 20/36,(cid:2)A23( f 23, D) = 25/36,(cid:2)A13( f 13, D) = 15/36.(1)In other words, one finds for instance that 20 of the 36 couples are correctly ranked by the ranking function f 12: objectnumber 1 is ranked before four objects of class C2, as well as object number 2, object number 3 is ranked before threeobjects of class C2, and so on. A more formal definition of the AUC will be given in Section 2.In this example, the triplet of bipartite rankings can still be replaced in different ways by a single ranking of the wholedata set such that the same pairwise AUCs are measured, for exampleranking for global f13 1 2 3 7 8 9 10 11 14 15 16 17 18 4 5 12 6iis such a ranking that results in the same pairwise AUCs. Verification of AUC ranking representability is much more difficultfor larger datasets, since enumerating all global rankings is then computationally infeasible. However, in [46] we have shownW. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501225that AUC ranking representability is strongly linked with a specific type of transitivity that has been called AUC transitivityfor this reason. In Section 4 we will first recapitulate necessary transitivity conditions for AUC ranking representability byexplaining the link between bipartite rankings and collections of dice. The reciprocal relations observed in both problemsexhibit a specific type of transitivity that has been called dice transitivity [15]. Due to a specific requirement imposed forbipartite rankings, dice transitivity does not yield a sufficient condition. Because of that, we also introduced a new type oftransitivity based on graph-theoretic concepts. This condition, which is called AUC transitivity, imposes constraints on thevalues of the pairwise AUCs, and it gives rise to a sufficient transitivity condition for AUC ranking representability. As aresult, AUC transitivity can be verified by solving an integer quadratic program. Moreover, in Sections 5 and 6 a closed-formexpression for the solution of this integer quadratic program will be derived, so that a combinatorial optimization procedurecan be avoided.As shown in the following sections, ERA and AUC ranking representability strongly rely on the notion of a reciprocal rela-tion, because the ERA and the AUC can be considered as specific examples of such relations. Historically, the representabilityof reciprocal relations in terms of a single ranking or utility function has been extensively studied in domains like utilitytheory [22], preference modelling [39], social choice theory [25], fuzzy set theory [4] and mathematical psychology [18,37,45], as a characterization of human preference judgments. Especially for reciprocal preference relations Q : X 2 → [0, 1] ona set X of data objects or alternatives, it has been shown that the notion of transitivity plays a crucial role. We recall thatthe reciprocity property expresses that for all (x1, x2) ∈ X 2 it holds thatQ (x1, x2) + Q (x2, x1) = 1,with the assumption Q (x1, x1) = 1/2. The above-mentioned authors all observed that Q has to satisfy some specific tran-sitivity conditions in order to be representable in terms of a single ranking or utility function f : X → R in the followingsense: for any (x1, x2) ∈ X 2 it holds thatQ (x1, x2) (cid:2) 12⇔ f (x1) (cid:2) f (x2).Reciprocal preference relations for which this representation holds are called weak utility models [37]. The latter provedthat a reciprocal preference relation is a weak utility model if and only if it satisfies weak stochastic transitivity, i.e., for any(x1, x2, x3) ∈ X 3 it holds that(cid:3)Q (x1, x2) (cid:3) 1/2 ∧ Q (x2, x3) (cid:3) 1/2(cid:4)⇒ Q (x1, x3) (cid:3) 1/2.(2)Remark that the pairwise AUCs given in (1) do not satisfy weak stochastic transitivity. Analogous to weak utility models,one can define other, typically stronger, conditions on the relationship between Q and f , leading to stronger transitivityconditions like moderate or strong stochastic transitivity. For the utility representability of fuzzy preference relations, similarforms of transitivity exist by using t-norms [5,10,43]. As shown in the present paper, these types of transitivity and themore general umbrella of cycle transitivity [11] are valuable tools for the analysis of reciprocal preference relations aswell. We will give a short and very incomplete overview of different types of transitivity in Section 3. By exploiting thegraph-theoretic reformulation of the AUC and introducing a new type of transitivity, we were able to derive necessaryand sufficient conditions for AUC ranking representability. Here we further extend these results by considering the infinitesample case instead of the finite sample case. As a result, we will once more introduce a new type of transitivity that canbe categorized in the framework of cycle transitivity. Using this framework, we will also examine the connection with othertypes of transitivity that have been proposed in the context of dice games [15] and the pairwise comparison of randomvariables [12,14,16].This article is organized as follows. In Section 2 the machine learning concepts mentioned in this introduction are moreformally described. Subsequently, in Section 3 different existing forms of transitivity are discussed and the framework ofcycle transitivity is briefly outlined. This allows us to present and extend in Section 4 necessary and sufficient conditions forAUC ranking representability by means of a new type of transitivity with the suitable name of AUC transitivity. In Section 5we then present the most important contribution of this paper: the generalization of transitivity properties to ERA rankingrepresentability. Finally, Section 6 discusses some practical considerations, followed by a general conclusion.2. Expected ranking accuracyIn the last decade, the problem of ranking, i.e., statistically inferring the parameters of a ranking function f : X → Rfrom a finite data set, has grown out to an active and widespread research field that covers applications like informationretrieval, marketing, financial forecasting and more traditional decision making problems (see e.g. [7,9,31,34]). We will inparticular focus on pairwise bipartite ranking in a multi-class setting. Such a setting basically implies that one aims toconstruct a statistical model that describes the relationship between data objects x ∈ X on the one hand and a (usuallysmall) unordered set of r classes Y = {C1, . . . , Cr} on the other hand. Although different methods have been proposed forextending binary classification algorithms (r = 2) to multi-class classification (r > 2), the pairwise approach [26,30] has beenespecially popular due to its simplicity, good performance and generality. This approach in essence fits a binary classifier tothe data for each pair of classes. It is for this reason also called a one-versus-one classification scheme. Since many binary1226W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250classification methods like logistic regression, linear discriminant analysis, neural networks and support vector machinesconstruct internally a latent continuous variable, a set F of bipartite ranking functions fkl : X → R is in this way obtained,with 1 (cid:2) k < l (cid:2) r. These ranking functions can then be further used to generate multi-class probability estimates [48].For a given data set, the ranking returned by each of the pairwise ranking functions is called bipartite, because it can bevisualized by means of a bipartite graph in which the two subsets of nodes correspond to the data instances of the twoclasses and edges indicate the ranking order of two objects of different classes.Ranking can be considered somewhere in the middle between pure discriminative modeling (we want good class pre-dictions) and probability estimation (we want good predictions of class-conditional probabilities). The difference betweenboth approaches is in the first place characterized by the type of loss or error function that is optimized. To this end, [1]introduced for ranking the concept of expected ranking accuracy as loss function. In a multi-class setting it can be formallyintroduced as follows.Definition 2.1. Let D j represent the conditional distribution over X given that the data object belongs to class C j withj = 1, . . . , r. For a set F = { fkl | 1 (cid:2) k < l (cid:2) r} of bipartite ranking functions, we define the pairwise expected rankingaccuracy between classes Ck and Cl for the ranking function fkl as(cid:5)(cid:5)Akl( fkl) = PrXk∼Dk,Xl∼Dl(cid:6)fkl(Xk) < fkl(Xl)+ 12PrXk∼Dk,Xl∼Dl(cid:6)fkl(Xk) = fkl(Xl).For a single ranking function f : X → R, the pairwise expected ranking accuracy is defined as(cid:6)f (Xk) < f (Xl)(cid:6)f (Xk) = f (Xl)Akl( f ) = PrXk∼Dk,Xl∼DlPrXk∼Dk,Xl∼Dl(cid:5)(cid:5).+ 12(3)(4)Here X ∼ D denotes that random vector X has distribution D. Thus, the quality of the model is in essence evaluatedby looking at the probability of correctly ranked couples (Xk, Xl) of random vectors.1 As in this definition, we will furtheralways associate a single random vector X j with each class, and without loss of generality, we may assume that theserandom vectors are independently sampled according to (different) unknown distributions, in which each distribution D jcorresponds to the data of one particular class. These unknown conditional distributions represent the probability of ob-serving a certain input vector, given the class label of that input vector.From a machine learning point of view, the primary concern is not to know the pairwise relationship of classes on afinite training set (represented by the empirical distribution, observed from a finite data sample). Rather, we want to findthe relationship among the unknown underlying distributions D j , or in other words, the relationship between classes ininput space. The r conditional class distributions D j , represented by random vectors X j , generate for each of the bipartiteranking functions fkl two univariate distributions of prediction scores; for any two classes Ck and Cl, two random variablesfkl(Xk) and fkl(Xl) can be distinguished. In essence, we investigate whether the distributions D j allow for an overall repre-sentation of these pairwise prediction score distributions as if they resulted from a single ranking function. Remark that therelationship between classes may not be interpreted here as a statistical dependence between classes, because data fromdifferent classes is of course independently sampled, and as such, the random vectors X j are independent. We rather alludewith the term relationship to the localization of the distributions in input space.It is important to note that we will not require that the distributions of prediction scores generated by a single rankingfunction have to be identical to those generated by a set of bipartite ranking functions, since that would give too strong acondition. We will only enforce that the pairs of prediction score distributions have the same level of separability for bothtypes of models, i.e. we require that the same pairwise expected ranking accuracies are obtained with a set of bipartiteranking functions and a single ranking function. The situation is graphically illustrated in Fig. 1 for a three-class classificationproblem. Three distributions (let’s say D1, D2 and D3) of two-dimensional random vectors are shown (red, green, blue),together with two artificial triplets of pairwise output distributions having the same pairwise expected ranking accuracies:the triplet on top is generated from bipartite ranking functions and the triplet at the bottom from a single ranking function.One can easily verify that both models give rise to the same expected ranking accuracies, and because of that, this tripletof bipartite ranking functions will be called ERA ranking representable (see further).For two classes Ck and Cl, the expected ranking accuracy can be expressed in terms of the joint cumulative distributionfunction F Xk,Xl of the random vectors Xk and Xl:dF Xk,Xl (xi, x j) + 1Akl( fkl) =(cid:7)fkl(xi )< fkl(x j )(cid:7)dF Xk,Xl (xi, x j).2fkl(xi )= fkl(x j )As all random vectors are mutually independent, the joint cumulative distribution function of a couple can obviously bewritten as a product of its marginals.1 For the remainder of our discussion, a restriction to vectorial input spaces is in fact not mandatory. We only make this restriction because randomvector is a statistically more established concept than the more general random data object.W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501227Fig. 1. A hypothetical example of pairwise output score distributions corresponding to an ERA ranking representable set of bipartite ranking functions (ifthe output score distributions originate from the unknown underlying distribution that generates the data) or an AUC ranking representable set of bipartiteranking functions (if the output score distributions originate from the observed empirical distribution on a finite data sample). The distributions obtainedwith a set of bipartite ranking functions are given on top, those obtained with a single ranking function are given at the bottom. For these distributions,both models generate the same triplets of bipartite ranking accuracies, because they have an identical level of separability in terms of ERA or AUC. See theelectronic version of the paper for illustrations in color. (For interpretation of the references to color in this figure, the reader is referred to the web versionof this article.)1228W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250Proposition 2.2. Given the extension flk = − fkl, the pairwise expected ranking accuracies defined by (3) constitute the off-diagonalelements of a reciprocal relation. The same holds for the expected ranking accuracies defined by (4).Proof. For a ranking function fkl, let F Xk,Xl denote the joint cumulative distribution function for the random vectors Xkand Xl. Similarly as in [16], we find(cid:7)(cid:7)(cid:7)Akl( fkl) + Alk( flk) =dF Xk,Xl (xi, x j) +dF Xk,Xl (xi, x j) +dF Xk,Xl (xi, x j) = 1.fkl(xi )< fkl(x j )fkl(xi )= fkl(x j )fkl(xi )> fkl(x j )Proving that (4) represents a reciprocal relation can be done in exactly the same way. (cid:2)Given the definition of expected ranking accuracy, we introduce the concept ERA ranking representability, as illustratedin Fig. 1.Definition 2.3. Let X1, . . . , Xr be r independent random vectors with respective conditional class distributions D1, . . . , Dr .We call a set F of bipartite ranking functions ERA ranking representable on X1, . . . , Xr if there exists a ranking functionf : X → R such that for all 1 (cid:2) k < l (cid:2) r it holds thatAkl( fkl) = Akl( f ).(5)The remainder of this article will be entirely dedicated to the quest for a way to verify ERA ranking representability. Inessence, we are looking for a condition for which the set of bipartite ranking functions can be replaced by a single rankingfunction that gives evidence of the same expected ranking accuracy. We will see at the end that in that case the expectedranking accuracies satisfy a specific type of transitivity. This transitivity property will actually establish a condition on thedistributions D j , but the condition itself will turn out to be distribution-independent, in the sense that the same conditionmust hold for any set of distributions D1, . . . , Dr . The details are given in Section 5, but we will first describe the finitesample case, for which some aspects of our story can be described in a less abstract way. Since the underlying distributionof the data is in general unknown, one obviously cannot compute the expected ranking accuracy, but one can estimate it onthe basis of a finite labeled data sample D = {(x1, y1), . . . , (xn, yn)}. This can be realized by computing the pairwise AUC, anonparametric unbiased estimator of the expected ranking accuracy [1]. Thus, a ROC curve is constructed for each pair ofclasses. The AUC can be formally defined as follows [19,23,40].Definition 2.4. For a set F of bipartite ranking functions, we define the pairwise AUC between classes Ck and Cl for theranking function fkl with 1 (cid:2) k < l (cid:2) r as(cid:2)Akl( fkl, D) = 1nknl(cid:8)(cid:8)yi =Cky j =ClI fkl(xi )< fkl(x j ).For a single ranking function f : X → R, the pairwise AUC is defined as(cid:2)Akl( f , D) = 1nknl(cid:8)(cid:8)yi =Cky j =ClI f (xi )< f (x j ).(6)Remark that I denotes the indicator function that returns one when its argument is true and zero otherwise.For further details on this definition and a general discussion of ROC analysis in multi-class settings, we refer forexample to [20,21,24,28]. Interestingly, it has been shown by [8,29,49] that the binary AUC is equivalent to the Wilcoxon–Mann–Whitney statistic. It measures the expected ranking accuracy on the empirical distribution instead of the unknownunderlying distribution and, by definition, it also satisfies the reciprocity property. Given a finite data sample, the AUC al-lows us to define the following form of ranking representability that can be interpreted as ERA ranking representability ofthe observed empirical distribution.Definition 2.5. We call a set F of bipartite ranking functions AUC ranking representable on D if there exists a rankingfunction f : X → R such that for all 1 (cid:2) k < l (cid:2) r it holds that(cid:2)Akl( fkl, D) = (cid:2)Akl( f , D).(7)In [46], we introduced AUC ranking representability as a relaxation of strict ranking representability, which basicallyassumes that all bipartite ranking functions must be consistent with a global ranking function. We showed that strictranking representability can be easily verified by investigating whether a graph is free of cycles. Unfortunately, strict rankingrepresentability has a very limited applicability, since it is a condition that cannot be satisfied for realistic data samples.W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501229However, from a statistical perspective, such a strong condition is not required and that was our main motivation to relaxthis condition to AUC ranking representability.AUC ranking representability can be illustrated too by Fig. 1, but now the univariate output score distributions aregenerated from empirical multivariate distributions. Consequently, AUC ranking representability can be easily verified forsmall data samples by enumerating all possible rankings of the data and computing for each of them the pairwise AUCs, asshown by the example in the introduction.3. TransitivityIn this section, we give a detailed introduction to the framework of cycle transitivity [11], which has quite recently beenput forward as a unification of fuzzy transitivity on the one hand and stochastic transitivity [37,45] on the other hand. In[10] it was shown that cycle transitivity covers FG-transitivity, a slightly older unifying framework for fuzzy and stochastictransitivity. Moreover, other types than fuzzy or stochastic transitivity can be elegantly expressed in the cycle transitivityframework. We will give a brief overview of some types of cycle transitivity that are relevant for our discussion.3.1. NotationsLet Q : X 2 → [0, 1] be a reciprocal relation defined on a set of data objects X . For any (xi, x j) ∈ X 2, we first introducethe shorthand notation Q i j = Q (xi, x j). For any (x1, x2, x3) ∈ X 3 we defineα123 = min(Q 12, Q 23, Q 31),β123 = median(Q 12, Q 23, Q 31),γ123 = max(Q 12, Q 23, Q 31).3.2. Product transitivityProduct transitivity (further denoted T P-transitivity) can be considered as a specific type of T -transitivity, a popularnotion in fuzzy set theory. Further we will give a formal definition of T -transitivity, but here we briefly mention that theproduct t-norm T P(a, b) = ab gives rise to a type of T -transitivity and it also forms the basis for the introduction of cycletransitivity, as shown in [11]. A reciprocal relation satisfies product transitivity if for any (x1, x2, x3) ∈ X 3 it holds thatQ 12 Q 23 (cid:2) Q 13.(8)Let us now consider a single triplet (x1, x2, x3). When all permutations of this triplet are considered and the reciprocityproperty is taken into account, then (8) gives rise to the following six conditions on Q 12, Q 23, Q 31:Q 12 Q 23 (cid:2) Q 13,Q 23 Q 31 (cid:2) Q 21,Q 31 Q 12 (cid:2) Q 32,Q 13 Q 32 (cid:2) Q 12,Q 21 Q 13 (cid:2) Q 23,Q 32 Q 21 (cid:2) Q 31.De Baets et al. [11] showed that these six inequalities can be reduced to one double inequality, expressed in terms of α,β, γ :β123γ123 (cid:2) α123 + β123 + γ123 − 1 (cid:2) 1 − (1 − α123)(1 − β123).(9)If L(β123, γ123) and U (α123, β123) represent the lower and upper bound in the above expression, then the following identitybetween both bounds is observed:L(β123, γ123) = 1 − U (1 − γ123, 1 − β123).Moreover, the obtained lower and upper bound are indifferent to any permutation of x1, x2 and x3 and the double inequalityholds for both directions of the loop.3.3. Definition of cycle transitivityThe observation made to rewrite T P-transitivity as the double inequality (9) lays the foundation of cycle transitivity.Within the framework of cycle transitivity, the upper bound (and corresponding lower bound) are generalized towardsother bounds than the ones given above. To this end, let us define (cid:5) = {(α, β, γ ) ∈ [0, 1]3 | α (cid:2) β (cid:2) γ } and consider afunction U : (cid:5) → R, then, by analogy with (9), we can call a reciprocal preference relation Q : X 2 → [0, 1] cycle-transitivew.r.t. U if for any (x1, x2, x3) ∈ X 3 it holds that1 − U (1 − γ123, 1 − β123, 1 − α123) (cid:2) α123 + β123 + γ123 − 1 (cid:2) U (α123, β123, γ123).Contrary to the derivation above for T P-transitivity, the upper bound function U takes in general three arguments insteadof two. In case of T P-transitivity, the upper bound function becomesU T P (α, β, γ ) = α + β − αβ.1230W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250The case where U (α, β, γ ) = β turns out to be another form of fuzzy transitivity as discussed in Section 3.4. The doubleinequality leads to two conditions: the lower bound should not exceed the upper bound and the value α + β + γ − 1 shouldbe located between both bounds.Definition 3.1. A function U : (cid:5) → R is called an upper bound function if it satisfies the following properties:(1) U (0, 0, 1) (cid:3) 0 and U (0, 1, 1) (cid:3) 1,(2) for any α, β, γ ∈ (cid:5):U (α, β, γ ) + U (1 − γ , 1 − β, 1 − α) (cid:3) 1.(10)The definition of an upper bound function does not include any monotonicity condition. We define the dual lower boundfunction L : (cid:5) → R of a given upper bound function U asL(α, β, γ ) = 1 − U (1 − γ , 1 − β, 1 − α),implying that L (cid:2) U when (10) holds. These tools allow us to define formally the notion of cycle transitivity.Definition 3.2. A reciprocal relation Q : X 2 → [0, 1] is called cycle-transitive w.r.t. an upper bound function U if for any(x1, x2, x3) ∈ X 3 it holds thatL(α123, β123, γ123) (cid:2) α123 + β123 + γ123 − 1 (cid:2) U (α123, β123, γ123),(11)where L is the dual lower bound function of U .From this construction immediately follows that, as soon as the double inequality is fulfilled for a triplet (x1, x2, x3) ∈ X 3,it is also fulfilled for any permutation of the triplet. Therefore, in practice one only needs to check (11) for a single permu-tation of (x1, x2, x3). Alternatively, due to the same duality, one can also opt to verify only the upper bound, or equivalentlythe lower bound, for two permutations of (x1, x2, x3) that are not cyclic permutations of one another. This is summarizedas follows.Proposition 3.3. (See [11].) A reciprocal relation Q : X 2 → [0, 1] is cycle-transitive w.r.t. an upper bound function U if for any(x1, x2, x3) ∈ X 3 it holds thatα123 + β123 + γ123 − 1 (cid:2) U (α123, β123, γ123).(12)The loosest upper bound one can choose is the constant function U = 2, which means that there is no restriction onthe values the reciprocal relation can take. It will become clear later that the upper bound function represents a verystraightforward way to link different types of transitivity and, in particular, to determine whether a particular form oftransitivity follows from another form of transitivity. For example, given two types of transitivity A and B that can be castedin the framework of cycle transitivity by means of upper bound functions U A and U B such that U A(α, β, γ ) (cid:2) U B (α, β, γ ),we automatically know that type- A transitivity implies type-B transitivity. It is shown in the following sections that thecycle transitivity framework incorporates various types of transitivity.3.4. Fuzzy transitivityT -transitivity is an important notion in the fuzzy set literature and it is a desirable property of fuzzy relations. In thiswork we will only consider the case where fuzzy relations are reciprocal relations, a condition that does not hold in general.The traditional definition given in terms of t-norms can be generalized to the more general class of conjunctors. As shownby [11], we will start with this more general case in order to establish the link with cycle transitivity.Definition 3.4. A binary operation C : [0, 1]2 → [0, 1] is called a conjunctor if it satisfies the following properties:(1) Its restriction to {0, 1}2 coincides with the boolean conjunction.(2) Monotonicity: C is increasing in both variables.This gives us the opportunity to define C -transitivity.Definition 3.5. Let C be a conjunctor. A fuzzy relation R : X 2 → [0, 1] is called C -transitive if for any (x1, x2, x3) ∈ X 3 itholds that(cid:3)(cid:4)R(x1, x2), R(x2, x3)C(cid:2) R(x1, x3).(13)W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501231Two important families of conjunctors are t-norms (neutral element 1, monotonicity, commutativity, associativity) andcopulas (neutral element 1, absorbing element 0, monotonicity, 2-increasingness). The 2-increasingness property is relaxedto the 1-Lipschitz condition for quasi-copulas. A close relationship exists between copulas and t-norms, since t-norms hav-ing the 1-Lipschitz property correspond to associative copulas. Three important t-norms (and copulas) that will appearfurther in this article are the minimum t-norm T M(a, b) = min(a, b), the product t-norm T P(a, b) = ab and the Łukasiewiczt-norm T L(a, b) = max(a + b − 1, 0). Given the restriction to reciprocal relations, the following proposition characterizes thereformulation of C -transitivity in terms of cycle transitivity.Proposition 3.6. (See [11].) Let C be a commutative conjunctor such that C (cid:2) T M. A reciprocal relation Q : X 2 → [0, 1] is C -transitiveif and only if it is cycle-transitive w.r.t. the upper bound function U C defined by(cid:3)U C (α, β, γ ) = min(cid:4)α + β − C(α, β), α + γ − C(α, γ ), β + γ − C(β, γ ).If C is 1-Lipschitz, then the upper bound function can be simplified toU C (α, β, γ ) = α + β − C(α, β).The three t-norms discussed above define the following upper bound functions:U T M (α, β, γ ) = β,U T P (α, β, γ ) = α + β − αβ,U T L (α, β, γ ) = 1.As shown in [46, submitted], T L-transitivity is equivalent to the triangle inequality. We remark that the triangle inequalityis traditionally used for symmetric relations, but it has been considered too by [37] and [36] as a property to characterizereciprocal preference relations.3.5. Stochastic transitivityWe first introduced fuzzy transitivity for its straightforward reformulation in terms of cycle transitivity. On the otherhand, stochastic transitivity is a fairly different framework for characterizing reciprocal relations. Historically, it has playeda more dominant role than fuzzy transitivity. As mentioned in the introduction, stochastic transitivity is closely connectedto ranking representability of reciprocal relations.Definition 3.7. Let g be an increasing [1/2, 1]2 → [0, 1] mapping. A reciprocal relation Q : X 2 → [0, 1] is calledg-stochastically transitive if for any (x1, x2, x3) ∈ X 3 it holds that(cid:3)Q (x1, x2) (cid:3) 1/2 ∧ Q (x2, x3) (cid:3) 1/2(cid:4)⇒ Q (x1, x3) (cid:3) g(cid:3)(cid:4)Q (x1, x2), Q (x2, x3).Many specific types of stochastic transitivity can be found in the literature, such as weak stochastic transitivity (g(a, b) =1/2), moderate stochastic transitivity (g(a, b) = min(a, b)) and strong stochastic transitivity (g(a, b) = max(a, b)).3.6. Product-based upper bound functionsAnother class of interesting upper bound functions is inspired by the upper bound of product transitivity. More specifi-cally, the following three upper bound functions are closely related:(1) strong product transitivity: U T P (α, β, γ ) = α + β − αβ,(2) moderate product transitivity: Ump(α, β, γ ) = α + γ − αγ ,(3) weak product transitivity: U D (α, β, γ ) = β + γ − βγ .The first one characterizes the traditional transitivity w.r.t. the product t-norm, as explained before. The second one hasrecently found an application in the field of partially ordered sets [13]. This upper bound function will reappear at the endof this paper. The third upper bound function characterizes reciprocal relations that are generated by collections of dice[15]. Because of that, this type of transitivity has been called dice transitivity, and we will need it to analyze the rankingrepresentability of bipartite ranking functions. We can also mention for the sake of completeness that dice transitivity sofar found an application in the comparison of independent random variables [16]. Other upper bound functions (based onT L or T M) can be linked to the comonotone or counter-monotone comparison of random variables [14,17].4. AUC ranking representabilityIn order to analyze the relationship between AUC and ERA ranking representability on the one hand and cycle transitivityon the other hand, we first rephrase some important results that have been obtained recently for reciprocal relations thatare generated from collections of dice, in a game-theoretic context [15]. We will for simplicity omit here the discussion on1232W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250the relationship between pairwise AUCs and the reciprocal relations in this game-theoretic setting, but one can easily showthat both types of relations exhibit the same transitivity conditions as necessary conditions. For more details we refer to[46], in which it was shown that an AUC ranking representable set F possesses a specific form of cycle transitivity, namelydice transitivity.Proposition 4.1. (See [15].) The reciprocal relation of pairwise AUCs generated by an AUC ranking representable set F of bipartiteranking functions is dice-transitive.It is important to note that the data set must be identically and independently distributed for this proposition, as oftenassumed in machine learning, and mentioned above.As indicated in the previous section, dice transitivity is stronger than the triangle inequality. Subsequently, the aboveimportant result was extended in [16] for independent random variables. In a nutshell, the same transitivity conditionapplies when independent random variables are compared in a pairwise way, leading to a reciprocal relation that closelyresembles the expected ranking accuracy. The simplest way to see this correspondence is to observe that for independent(cid:9)) are independent random variables as well. Reformulated in the(cid:9)random vectors X and Xcurrent discussion, this yields the following important result., the output scores f (X) and f (XProposition 4.2. (See [16].) Let X1, . . . , Xr be r independent random vectors. The reciprocal relation of pairwise expected rankingaccuracies generated by an ERA ranking representable set F of bipartite ranking functions is dice-transitive.From the first proposition we know that the pairwise AUCs generated from an AUC ranking representable set of bipartiteranking functions give evidence of a particular form of transitivity, stronger than the triangle inequality, but weaker thanT P-transitivity. De Schuymer et al. [15] gave counterexamples to illustrate that the reciprocal relation of pairwise AUCsgenerated from an AUC ranking representable set of bipartite ranking functions not always satisfies T P-transitivity.So, dice transitivity gives rise to a necessary condition for AUC ranking representability, but is it also a sufficient condi-tion? The answer is definitely negative, since even much stronger types of transitivity not necessarily lead to AUC rankingrepresentability. We showed for example that strong stochastic transitivity and even T M-transitivity are not sufficient forAUC ranking representability. However, in Section 5 it will follow from our results that T M-transitivity becomes sufficientfor ERA ranking representability. In order to describe a sufficient condition, we have to introduce a graph-theoretic refor-mulation of AUC ranking representability.Definition 4.3. Let F be a set of bipartite ranking functions. We define GAUC(F , D) as the set of complete directed graphsG = (V , E) with V the set of nodes and E the set of edges, so that the following three properties hold:(1) Each node v i in V is associated with one data object (xi, yi) in D.(2) No cycles occur in the subsets V k = {v i ∈ V | yi = Ck}.(3) For 1 (cid:2) k < l (cid:2) r:(cid:2)Akl( fkl, D) =|{(v i, v j) ∈ E | yi = Ck ∧ y j = Cl}|nknl.(14)Let us try to express this definition in a less formal way. We are in essence looking for all graphs G = (V , E) in which weassociate one data object from the data set with a node such that we obtain r subsets V 1, . . . , V r for r classes. We requirein addition that the nodes within each subset are ordered (which results in an acyclic subgraph for these subsets), and thatthe fraction of edges from subset V k to V l corresponds to (cid:2)Akl( fkl, D). Some examples of such graphs will be presented lateron. In this way, we only consider complete directed graphs. Remark that a complete directed graph is a graph in which eachpair of nodes is connected by exactly one (directed) edge. So, (v, v(cid:9)) ∈ E implies (v(cid:9), v) /∈ E.It follows directly from the definition that GAUC(F , D) cannot be empty. Its cardinality will usually be greater than 1since different graphs satisfying (14) will be found for a given F and D. In the following proposition, AUC ranking repre-sentability is reformulated in terms of these graphs.Definition 4.4. We introduce HAUC(F , D) as the subset of GAUC(F , D) containing only directed acyclic graphs (DAGs).Proposition 4.5. A set F of bipartite ranking functions is AUC ranking representable on D if and only if HAUC(F , D) is not empty.Using the graph-theoretic concepts introduced above, we have a sufficient condition for AUC ranking representability.Nevertheless, this condition cannot be verified for large datasets, since the cardinality of GAUC(F , D) exponentially increaseswith the size of D. Similar to [15], we further examine the three-class case in order to find a sufficient condition that canbe verified more easily. The reason for this restriction is that we will need cycle transitivity (which has so far only beendefined on triplets). The results obtained for three classes can then be further extended to more classes with approximationtechniques. We start with introducing a new type of transitivity.W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501233∗, s)-split, denoted aDefinition 4.6. An (astrictly) positive integers summing up to abounded by t. The set of all (adecreasing vector b∗ = (a∗s−1, . . . , a. An (a∗, s, t)-splits will be denoted S(a∗1). The set of all dual (a∗s , a∗∗∗, s, t)-split is an (a∗1, a∗, s)-split for which each component of a∗2, . . . , a∗ = (a∗s ) of s (not necessarily∗is upper∗, s, t)-split as the∗, s, t). We define the dual b of an (a∗, s, t)-splits will be denoted (cid:9)S(a∗, s, t)., is an increasing ordered list (or vector) aExample 4.7. We give two simple examples to illustrate the above definition:S(10, 4, 3) =(cid:9)S(11, 3, 6) =(cid:5)(cid:6)(1, 3, 3, 3), (2, 2, 3, 3)(cid:5),(cid:6)(6, 5, 0), (6, 4, 1), (6, 3, 2), (5, 5, 1), (5, 4, 2), (5, 3, 3).Definition 4.8. Let (n1, . . . , nr) ∈ Nr and let(cid:10)a ∈ [0, 1](cid:3)(cid:11)(cid:11)(cid:11)∃a(cid:4)∗ ∈ N(cid:3)kl =∗(cid:12)a = anknl(cid:13)(cid:14).The family of functions C jkl : (cid:3) jk × (cid:3)kl → (cid:3) jl is defined by:C jkl(a, b) = 1n jnlfor j, k, l ∈ {1, . . . , r}.∗i− a∗i−1(cid:4)b∗i ,nk(cid:8)(cid:3)ai=1min∗∈S(aa∗∈ (cid:9)S(bb∗,nk,n j )∗,nk,nl)The value C jkl(a, b) is the solution of an integer quadratic program. To illustrate this, let us rewrite the minimization as:mina∗,b∗1n jnlnk(cid:8)(cid:3)ai=1∗i− a∗i−1(cid:4)b∗i⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩subject to(cid:19)a(cid:19)∗,∗,= a= b∗nki=1 ai∗nki=1 bi∗∗i−1, ∀i ∈ {1, . . . , nk},(cid:3) ai∗∗i−1, ∀i ∈ {2, . . . , nk + 1},(cid:2) bbi∗(cid:2) n j, ∀i ∈ {1, . . . , nk},0 (cid:2) ai∗(cid:2) nl, ∀i ∈ {1, . . . , nk},0 (cid:2) bi∗∗∈ N, ∀i ∈ {1, . . . , nk},i , bai∗= 0.= 0,0∗nk+1ba(15)In Fig. 2 the family of functions C jkl is visualized for some (small) n j , nk and nl. The function values were computed byexhaustively verifying all feasible solutions of the integer quadratic program, which can only be done for small values of n j ,nk and nl.Example 4.9. Let us consider the situation: n j = 3, nk = 4, nl = 5, a = 9/12, b = 13/20. The objective is minimized over thefollowing splits:(cid:5)S(9, 4, 3) =(cid:9)S(13, 4, 5) =(cid:6)(0, 3, 3, 3), (1, 2, 3, 3), (2, 2, 2, 3)(cid:5),(5, 5, 3, 0), (5, 5, 2, 1), (5, 4, 4, 0), (5, 4, 3, 1), (5, 4, 2, 2), (5, 3, 3, 2),(cid:6)(4, 4, 4, 1), (4, 4, 3, 2), (4, 3, 3, 3).∗ = (4, 3, 3, 3) such that C jkl(a, b) =The minimum of the objective function is obtained for the splits a11/15. It turns out that for this example (and many other cases) the minimum can be found without computing theobjective function for all splits exhaustively. To understand this, we have to reveal the graph-theoretic interpretation fromwhich the integer quadratic program originates.∗ = (2, 2, 2, 3) and bProposition 4.10. Given the graph-theoretic reformulation of Definition 4.3, we haveC jkl((cid:2)A jk, (cid:2)Akl) =minG∈HAUC(F,D)|{(va, vc) ∈ V j × V l | (∃vb ∈ V k)((va, vb), (vb, vc) ∈ E)}|n jnl.1234W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250Fig. 2. The family of functions C jkl visualized.The proof has been given in [46]. Nonetheless, let us briefly explain in words what this equation means, since the graph-theoretic interpretation leads to a crucial insight for a further understanding of this paper. Given a data set D and a setof bipartite ranking functions F , we examine all couples of nodes (va, vc) ∈ V j × V l in all graphs G ∈ HAUC(F , D). Theproposition states that C jkl equals the minimal number of such couples connected by a path passing through a node oflayer V k over all these graphs. For any graph G ∈ HAUC(F , D), we have that arepresents the number of edges departingfrom a node va of subset V j and ending in a node vb of subset V k. Similarly, brepresents the number of edges departingfrom a node vb of subset V k and arriving in a node vc of subset V l.∗∗In Section 5, examples will be provided to illustrate the graph-theoretic interpretation of the integer quadratic program(see Figs. 6, 7 and 8). Based on this graph-theoretic interpretation, let us introduce a new type of transitivity.Definition 4.11. A reciprocal relation of pairwise AUCs (cid:2)Akl( fkl, D) is called AUC transitive if for all j, k, l ∈ {1, . . . , r} it holdsthatC jkl((cid:2)A jk, (cid:2)Akl) (cid:2) (cid:2)A jl.(16)We emphasize that this type of transitivity in certain sense differs from all existing types of transitivity, since thecondition that a given triplet of values must satisfy depends on their indices.W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501235Proposition 4.12. Let F = { f 12, f 23, f 13} be a triplet of bipartite ranking functions. The corresponding triplet of pairwise AUCs is AUCtransitive on D if and only if HAUC(F , D) is not empty.Corollary 4.13. A triplet F = { f 12, f 23, f 13} of bipartite ranking functions is AUC ranking representable on D if and only if the corre-sponding reciprocal relation of AUCs is AUC transitive.Corollary 4.14. AUC transitivity implies dice transitivity.Briefly summarized, we have in essence proven that AUC transitivity implies dice transitivity, by using a chain of equiv-alences and implications. Firstly, we observed in Proposition 4.12 that the AUC transitivity of pairwise AUCs correspondsto the existence of a DAG in the graph set GAUC(F , D). Secondly, by applying Proposition 4.5, the existence of a DAG inGAUC(F , D) allowed us to conclude that the corresponding set F of bipartite ranking functions is AUC ranking representable.Thirdly, due to the AUC ranking representability of F , we were able to express the pairwise AUCs as a reciprocal relationoriginating from collections of dice. Finally, from Proposition 4.1 it followed that this reciprocal relation is dice-transitive, sothat AUC transitivity implies dice transitivity.Given the results obtained in previous work, we are able to prove in addition a number of new interesting properties forthe family of functions C jkl. In the next section, where the generalization to ERA ranking representability is described, theseproperties will reduce to some well-known characteristics of t-norms.Proposition 4.15. Let (n1, . . . , nr) ∈ Nr . The family of functions C jkl : (cid:3) jk ×(cid:3)kl → (cid:3) jl as in Definition 4.8 has the following properties:(1) ∀ j, k, l ∈ {1, . . . , r}: C jkl is increasing in both variables.(2) ∀ j, k, l ∈ {1, . . . , r}, ∀(a, b) ∈ (cid:3) jk × (cid:3)kl: C jkl(a, b) = Clkj(b, a).(3) ∀ j, k, l ∈ {1, . . . , r}, ∀a ∈ (cid:3) jk: C jkl(a, 0) = 0.(4) ∀ j, k, l ∈ {1, . . . , r}, ∀a ∈ (cid:3) jk: C jkl(a, 1) = 1n j(5) ∀ j, k, l ∈ {1, . . . , r}, ∀(a, b) ∈ (cid:3) jk × (cid:3)kl:(cid:12) ank(cid:13).∗C jkl(a, b) (cid:2) 1n jnl(cid:20)∗ank(cid:21)(cid:20)(cid:21).∗bnk(6) ∀ j, k, l ∈ {1, . . . , r}, ∀(a, b) ∈ (cid:3) jk × (cid:3)kl:n ja ∈ N ∧ nlb ∈ N ⇒ C jkl(a, b) (cid:2) ab,∗/(nknl) and (cid:12)·(cid:13) : R → N the ceiling function that retrieves the closest integer greater than or equal to awith a = agiven real number.∗/(n jnk), b = bProof.. This property directlyProperty 1. The objective function of optimization problem (15) is an increasing function of afollows from the graph-theoretic interpretation of the integer quadratic program. When aincreases, then respectively,the number of incoming or outgoing edges in the layer V k increases. As a consequence, also the minimum of the objectivefunction increases, since the minimum corresponds to the number of connected couples from V j × V l, connected via a nodein V k.and b∗or b∗∗∗Property 2. Let us define bnk+1 = 0. We find:C jkl(a, b) = 1n jnl= 1n jnlnk(cid:8)i=1nk(cid:8)i=1min∗∈S(aa∗∈ (cid:9)S(bb∗,nk,n j )∗,nk,nl)min∗∈S(aa∗∈ (cid:9)S(bb∗,nk,n j )∗,nk,nl)∗i b∗ia−nk(cid:8)i=1∗i−1b∗ia= 1n jnl(cid:3)b∗i∗ia− b∗i+1(cid:4)= 1n jnlmin∗∈S(aa∗∈ (cid:9)S(bb∗,nk,n j )∗,nk,nl)nk(cid:8)min∗∈ (cid:9)S(aa∗∈S(bb∗,nk,n j )∗,nk,nl)i=1nk(cid:8)i=1∗i b∗ia−nk(cid:8)i=1∗i b∗i+1a(cid:3)b∗i∗ia− b∗i−1(cid:4)= Clkj(b, a).Property 3. When we fill in 0 for ais 0.∗∗or bin optimization problem (15), then the solution of the integer quadratic programProperty 4. When b = 1, then b∗i= nl for all i ∈ {1, . . . , n j}. Taking into account that a = a∗/(n jnk), we find:1236W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250C jkl(a, 1) = 1n jnl(cid:20)= 1n jmin∗,nk,n j )∗,nk,nl)∗∈S(aa∗∈ (cid:9)S(bb(cid:21)∗ank.nk(cid:8)(cid:3)ai=1∗i− a∗i−1(cid:4)nl = 1n jmina∗∈S(a∗,nk,n j )nk(cid:8)(cid:3)ai=1∗i− a∗i−1(cid:4)= 1n jmina∗∈S(a∗,n j ,n j )a∗nkProperty 5. To understand this property, again the graph-theoretic interpretation of C jkl(a, b) as established in Proposi-tion 4.10 is needed. Let us consider the following two strategies to draw edges from layer V j to V k and from V k to V l:(1) Strategy 1: Assign the edges in such a way that the number of incoming edges from V j and outgoing edges to V l isas balanced as possible for all nodes of layer V k; this strategy corresponds to choosing the most balanced splits inS(a∗, nk, n j) and (cid:9)S(b∗, nk, nl).(2) Strategy 2: Assign the edges in such a way that the number of incoming edges from V j and outgoing edges to V l is asimbalanced as possible for all nodes of layer V k; this strategy corresponds to choosing the most imbalanced splits inS(a∗, nk, n j) and (cid:9)S(b∗, nk, nl).Here we only need Strategy 1, the other strategy will be used further on in Proposition 5.2, where both strategies will beillustrated with some examples. We show that the quantity(cid:20)(cid:21)(cid:20)(cid:21)1n jnl∗ank∗bnkacts as an upper bound for the objective function in (15) when Strategy 1 is followed, and a fortiori it will also be an upperbound for the minimum of the integer quadratic program. Strategy 1 corresponds to a way of drawing edges from V j to V k(cid:13) nodes of layer V jand from V k to V l such that the third condition in Definition 4.3 is satisfied, because then at most (cid:12) ankhave outgoing edges to V k and at most (cid:12) b(cid:13) connectednkcouples through a node of V k.(cid:13) nodes have incoming edges from V k. So, we have at most (cid:12) ank(cid:13)(cid:12) bnk∗∗∗∗Property 6. This property immediately follows from Property 5 since in this case ank∗∗= (cid:12) ank∗(cid:13) and bnk∗= (cid:12) bnk(cid:13). (cid:2)From these properties it follows that C jkl is a family of discrete conjunctors (the functions are only defined over (cid:3) jk × (cid:3)klinstead of [0, 1]2). It is interesting to look how these functions behave compared to standard t-norms. In Figs. 3–5, we havecompared C jkl to respectively T L, T P and T M for n j = nk = nl = 10. One can see that the function C jkl is always greater thanT L with a peak in the upper triangle. In the region close to (0, 0), it is substantially smaller than T P, while it is similar toT P in the region close to (1, 1). Thirdly, in almost all parts of the input domain, C jkl is smaller than T M.5. ERA ranking representabilitySince AUC transitivity acts as a necessary and sufficient condition for AUC ranking representability, it is able to revealdeeper insights of multi-class classifiers, but it is not of great practical value. The functions C jkl are solutions of an integerquadratic program, which is an NP-hard problem [33], and as a result, the condition can only be exactly verified for smalldata sets. Instead of focussing on intelligent algorithms to solve the integer quadratic program approximately, we willpresent another approach to circumvent this computational bottleneck. Simultaneously, an analytical expression for thesolution of the integer quadratic program is derived.Using the concepts from the previous section, ERA ranking representability naturally follows from AUC ranking repre-sentability by considering the abstraction from a finite sample to the underlying distribution. Let us now introduce a specifictype of C -transitivity.Definition 5.1. A reciprocal relation Q : X 2 → [0, 1] is called ERA-transitive if it is C -transitive w.r.t. the conjunctor CP0defined byCP0(a, b) =(cid:10)0,ab,if a + b (cid:2) 1,if a + b > 1.Remarkably, we can show that ERA transitivity leads to a necessary and sufficient condition for ERA ranking repre-sentability.Proposition 5.2. A triplet F = { f 12, f 23, f 13} of bipartite ranking functions is ERA ranking representable on three independent randomvectors if and only if the corresponding reciprocal relation of expected ranking accuracies is ERA-transitive.W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501237Fig. 3. C jkl compared to T L with n j = nk = nl = 10. (For interpretation of the references to color in this figure, the reader is referred to the web version ofthis article.)1238W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250Fig. 4. C jkl compared to T P with n j = nk = nl = 10. (For interpretation of the references to color in this figure, the reader is referred to the web version ofthis article.)W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501239Fig. 5. C jkl compared to T M with n j = nk = nl = 10. (For interpretation of the references to color in this figure, the reader is referred to the web version ofthis article.)1240W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250Proof. The proof is inspired by the sufficient condition derived for AUC ranking representability in the previous section.Given that expected ranking accuracy is the immediate generalization of the AUC from a finite sample to the underlyingdistribution, we only need to show that C jkl converges in the limit to CP0 : [0, 1]2 → [0, 1]. In order to examine this limitbehavior, we first assume that the ratio of the number of data objects sampled from the respective classes remains un-changed. We will give a formal discussion for the case where n j = nk = nl. For other ratios, a more difficult formal proof canbe formulated. In the second stage, we construct such a formal proof from the insights gained for the case n j = nk = nl.Case 1. n j = nk = nl.In this case, we have to show thatCP0(a, b) = limn j→∞C j j j(a, b),with n j ∈ N. We immediately find that in the limit properties (1)–(4) in Proposition 4.15 respectively reduce to monotonicity,commutativity, absorbing element 0 and neutral element 1. However, CP0 will not be a t-norm since associativity does nothold. To compute the limit of C j j j , we will consider three cases.Subcase 1. (cid:15) an j∗∗(cid:16) + (cid:15) bn j(cid:16) > n j .∗We show that in this case the minimum of the integer quadratic program is found by applying Strategy 1 as describedin the proof of the fifth property in Proposition 4.15. The easiest way to recognize this is by considering the graph-theoretic(cid:16) > n j , always paths will be found from V j to V l that pass through ainterpretation of Proposition 4.10. Given (cid:15) an j∗∗ = (a) considered in Strategy 21, . . . , bnode of V k. The first thing to observe is that the splits for alead to a value of 1 for the objective function, because a node in V k can be found that has incoming edges from all V j -nodes and outgoing edges to all V l-nodes. As a consequence, we connect all couples of nodes from V j × V l in this way.Irrespective the split of athat is chosen, we will always find connected couples. The only chance to end up with asfew connected couples as possible is by constructing as many paths as possible through couples that have to be connectedanyway. This is exactly what is accomplished by Strategy 1, leading to vectors athat are constructed as follows:∗1, . . . , a(cid:16) + (cid:15) bn j∗ = (b) and band band b∗n j∗n j∗∗∗∗∗⎧⎨⎩⎧⎨⎩∗ia=∗ib=∗(cid:15) an j∗(cid:12) an j∗(cid:15) bn j∗(cid:12) bn j(cid:16),(cid:13),(cid:16),(cid:13),if i (cid:2) n j − aif i > n j − a∗∗mod n j,mod n j,if i > bif i (cid:2) b∗∗mod n j,mod n j.∗(cid:13) nodes from V j have outgoing edges to V k. (cid:15) an jLet us now try to derive a closed form for the objective function. By applying Strategy 1, we minimize the number of nodes(cid:16) of these nodes have n jfrom V j with outgoing edges to V k. At least (cid:12) an j∗/n j isoutgoing edges to V k (more precisely, to all elements of V k). Only one node can have less than n j edges (when a(cid:16) of these nodes havenot an integer). Similarly, we find that at least (cid:12) bn j∗/n j is not an integer). Putting everythingn j incoming edges, and the remaining node can have less than n j edges (when btogether, we find that all V j -nodes with outgoing edges to V k and all V l-nodes with incoming edges from V k have tobe connected in this way, except the V j -node and V l-node with less than n j outgoing (respectively incoming) edges. Onemod n j (cid:3) 1. This corresponds to thecan easily verify that these two nodes will also be connected when afollowing value for the objective function:(cid:13) nodes from V l have incoming edges from V k. (cid:15) bn jmod n j + b∗∗∗∗∗⎧⎪⎨τ1 =⎪⎩(cid:13) − 1),∗∗((cid:12) an j∗(cid:12) an j(cid:13)(cid:12) bn j∗(cid:13),(cid:13)(cid:12) bn j1n2j1n2j∗∗if aif amod n j + bmod n j + b∗∗mod n j < 1,mod n j (cid:3) 1.(17)Remark that the −1 corresponds to the couple that is potentially not connected. τ1 reduces in the limit to the followingsimple expressionn j→∞ τ1 = alim∗bn4j∗= ab.Fig. 6 shows the obtained graph when Strategies 1 and 2 are applied to an example that satisfies Subcase 1.Subcase 2. (cid:12) an j∗∗(cid:13) + (cid:12) bn j(cid:13) (cid:2) n j .W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501241We show that in this case the minimum of the integer quadratic program is 0. This minimum is found by applying∗ =Strategy 2, as described in the proof of the fifth property in Proposition 4.15. The vectors a(b∗1, . . . , a∗ = (a) and b∗n j∗1, . . . , b∗n j0,) are now constructed as follows:⎧⎪⎪⎪⎨⎪⎪⎪⎩if i < n j − (cid:15) an j∗if i = n j − (cid:15) an j∗if i > n j − (cid:15) an jmod n j,n j,(cid:16),(cid:16),(cid:16),a∗∗∗ia=and⎧⎪⎪⎪⎨⎪⎪⎪⎩∗ib=n j,∗bmod n j,0,∗if i < (cid:12) bn j∗if i = (cid:12) bn j∗if i > (cid:12) bn j(cid:13),(cid:13),(cid:13),(18)(19)(cid:13) (cid:2) n j , it follows thatwhich of course results in a feasible solution for the integer quadratic program. Given that (cid:12) an j∗ai b∗iFig. 7 shows the obtained graph when Strategies 1 and 2 are applied to an example that satisfies Subcase 2.= 0 for all i = 1, . . . , n j such that the objective function becomes zero.= 0 and a(cid:13) + (cid:12) bn j∗i−1b∗i∗∗Subcase 3. (cid:15) an j∗∗(cid:16) + (cid:15) bn j∗(cid:16) (cid:2) n j < (cid:12) an j∗(cid:13) + (cid:12) bn j(cid:13) (none of the above cases holds).Besides these two cases, normally also a third case has to be distinguished, when none of the above two conditionsholds. However, we do not have to discuss this third case, for which the minimum of the objective function is more difficultto express. Fortunately, this case vanishes in the limit, since(cid:20)limn j→∞(cid:21)(cid:22)−(cid:23)∗an j∗an j= 0,(cid:20)limn j→∞(cid:21)(cid:22)−(cid:23)∗bn j∗bn j= 0.In Subcase 3, both Strategies 1 and 2 can deliver the minimum of the integer quadratic program, yet it depends on theactual values of a and b whether Strategies 1 or 2 should be applied. Fig. 8 shows the obtained graph when Strategies 1and 2 are applied on an example that satisfies Subcase 3. For Strategy 1 one can easily see that Eq. (17) still provides theobtained value for the objective function. For Strategy 2, contrary to Subcase 2, the value for the objective function will nolonger be zero. Given Subcase 3, one will always find exactly one node in the layer V k with incoming and outgoing nodes∗i are respectively given by(this means that aamod n j and b∗i and bmod n j . As a consequence, we obtain by applying Eqs. (18) and (19)∗i are both different from zero for that node). The values of a∗i and b∗∗(cid:3)a∗τ2 =(cid:4)(cid:3)b∗(cid:4),mod n jmod n jas value for the objective function in Subcase 3, when Strategy 2 is employed.General case. n j = nk = nl does not hold.The proof given above for n j = nk = nl can be easily extended to other cases, while still assuming that the ratio of thenumber of data objects sampled from the respective classes remains unchanged when the sample size grows to infinity.Subcase 1. (cid:15) an j∗∗(cid:16) + (cid:15) bnl(cid:16) > nk.We have to apply Strategy 1 to obtain the minimum. It is now given by:⎧⎨τ1 =⎩(cid:13) − 1),∗∗1n jnl1n jnl((cid:12) ank∗(cid:13)(cid:12) bnk(cid:13)(cid:12) bnk∗(cid:13),(cid:12) ank∗∗if aif amod nk + bmod nk + b∗∗mod nk < 1,mod nk (cid:3) 1.(20)Subcase 2. (cid:12) an j∗∗(cid:13) + (cid:12) bnl(cid:13) (cid:2) nk.We have to apply Strategy 2 to obtain the minimum. One can easily see that in this case the minimum of the objectivefunction again becomes zero, since the vectors a∗ = (a∗1, . . . , a∗n j) and b∗ = (b∗1, . . . , b∗n j) are now constructed as follows:1242W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250Fig. 6. An example to illustrate Subcase 1 in the proof of Proposition 5.2. Let us consider n j = nk = nl = 4, a = 13/16 and b = 11/16. So, we have to draw13 edges from layer V j to layer V k and 11 edges from layer V k to layer V l . The graphs obtained by applying Strategy 1 (left) and Strategy 2 (right) areshown, respectively leading to 11 and 16 connected couples of nodes from layer V j to layer V l . One can clearly see that in this example the number ofconnected couples of nodes from V j to V l cannot be lower than 10. We also remark that edges in the opposite direction are left out to simplify the graph,but the graphs are essentially complete graphs, so the 5 edges from V k to V j and the 3 edges from V l to V k are left out.⎧⎪⎪⎪⎨⎪⎪⎪⎩⎧⎪⎪⎨⎪⎪⎩∗ia=∗ib=andn j,nl,∗b0,0,∗amod n j,∗if i < nk − (cid:15) an j∗if i = nk − (cid:15) an j∗if i > nk − (cid:15) an j(cid:16),(cid:16),(cid:16),mod nl,∗if i < (cid:12) bnl∗if i = (cid:12) bnl∗if i > (cid:12) bnl(cid:13),(cid:13),(cid:13).Subcase 3. (cid:15) an j∗∗(cid:16) + (cid:15) bnl∗(cid:16) (cid:2) nk < (cid:12) an j∗(cid:13) + (cid:12) bnl(cid:13) (none of the above cases holds).This case again vanishes in the limit, so that it does not have to be considered further. For the sake of completeness, wealso give here the expression for the minimum of the integer quadratic program. As illustrated in Fig. 8, both Strategies 1and 2 can deliver the minimum of the integer quadratic program. This holds also for the case where n j = nk = nl does nothold. If Strategy 1 is applied, then the objective function takes the value given by Eq. (20). If Strategy 2 is applied, thenagain exactly one node from the layer V k will simultaneously have incoming and outgoing edges for Subcase 3. The valuesof amod nl. Consequently, the value for the objective functionbecomes:∗i are now respectively given by amod n j and b∗i and b∗∗(cid:3)a∗τ2 =(cid:4)(cid:3)b∗(cid:4),mod nlmod n jfor Subcase 3, when Strategy 2 is applied. (cid:2)(21)The conjunctor CP0 is visualized in Fig. 11(a). It can be expressed as a special type of cycle transitivity, by applyingProposition 3.6.Proposition 5.3. A reciprocal relation Q : X 2 → [0, 1] is ERA-transitive if and only if it is cycle-transitive w.r.t. the upper boundfunction(cid:3)U CP0 (α, β, γ ) = min(cid:4)α + β − CP0(α, β), α + γ − CP0(α, γ ), β + γ − CP0(β, γ ).Proposition 5.4. ERA transitivity implies moderate product transitivity and therefore also dice transitivity.Proof. Let us consider a unit square for the couple (β, γ ), as visualized in Fig. 9. From the constraintβ (cid:2) γ ,(22)follows that only the region above the bisector must be considered (i.e., the line given by the identity function). The aboveupper bound function can be expressed as αγ (cid:2) 1 − β. Let us try to make this constraint as tight as possible by choosingα = β. This means that our cycle transitivity property only imposes a constraint when the following inequality holds:W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501243Fig. 7. An example to illustrate Subcase 2 in the proof of Proposition 5.2. Let us consider n j = nk = nl = 4, a = 5/16 and b = 7/16. So, we have to draw 5edges from layer V j to layer V k and 7 edges from layer V k to layer V l . The graphs obtained by applying Strategy 1 (left) and Strategy 2 (right) are shown,respectively leading to 3 and 0 connected couples of nodes from layer V j to layer V l . We also remark that edges in the opposite direction are left out tosimplify the graph, but the graphs are essentially complete graphs, so the 11 edges from V k to V j and the 9 edges from V l to V k are left out.Fig. 8. An example to illustrate Subcase 3 in the proof of Proposition 5.2. Let us consider n j = nk = nl = 4, a = 11/16 and b = 7/16. So, we have to draw 10edges from layer V j to layer V k and 7 edges from layer V k to layer V l . The graphs obtained by applying Strategy 1 (left) and Strategy 2 (right) are shown,respectively leading to 5 and 9 connected couples of nodes from layer V j to layer V l . We also remark that edges in the opposite direction are left outto simplify the graph, but the graphs are essentially complete graphs, so the 6 edges from V k to V j and the 9 edges from V l to V k are left out. For thisexample, Strategy 1 turns out to lead to the minimum of the integer quadratic program, but one can observe that small changes in the values for a and b(such as decreasing b to 5/16) will result in obtaining the minimum with Strategy 2 (3 connected couples versus still 6 with Strategy 1).γ >1 − ββ.(23)Moreover, the upper bound function U (α, β, γ ) = α + γ − αγ neither imposes a constraint when α + γ (cid:2) 1. This corre-sponds to the regionβ + γ (cid:2) 1,(24)because we are already assuming that α = β. Putting everything together, the upper bound function U (α, β, γ ) = α + γ −αγ only imposes a constraint in the subregion of the unit square defined by inequalities (22), (23) and (24). We havevisualized this region in Fig. 9(a) with a gray background color. Obviously, CP0(β, γ ) equals βγ in this part of the unitsquare. ERA transitivity is therefore a stronger type of transitivity than cycle transitivity w.r.t. the upper bound functionU (α, β, γ ) = α + γ − αγ . (cid:2)This proposition mainly confirms that all pieces of the puzzle fit surprisingly well. In the previous sections it was shownhow AUC transitivity induces a sufficient condition for AUC ranking representability, while dice transitivity could only leadto a necessary condition. From this we were able to prove indirectly that the former type of transitivity had to be strongerthan the latter one, but this could not be observed directly from the upper bound functions. Since this relationship betweenboth types of cycle transitivity can be observed very easily in the infinite case, it gives an additional confirmation of thecorrectness of our analysis in the finite case. To draw the attention of the reader to the potentially tight bound betweenAUC transitivity and dice transitivity, Fig. 10 visualizes all considered regions for n j = nk = nl = 10. It is shown that for thischoice of n j , nk, nl the region defined by inequalities (22)–(24) does not overlap with the region where C jkl(β, γ ) exceedsβγ , albeit both regions are located very close to each other.Proposition 5.5. T P-transitivity implies CP0-transitivity.1244W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250Fig. 9. A visualization of the unit square for (β, γ ). The shaded region indicates the zone of the unit square where all three inequalities (22)–(24) hold.Fig. 10. Contour plot of the difference between AUC transitivity and dice transitivity (or cycle transitivity w.r.t. the upper bound function U (α, β, γ ) =α + γ − αγ ), because in the proof the assumption is made that α = β). One can see that AUC transitivity dominates the other two types of transitivity inthe region where all three inequalities (22)–(24) hold (shown for n j = nk = nl = 10).Proof. Immediate since CP0 (cid:2) T P. (cid:2)6. Practical considerations6.1. Verifying ERA or AUC ranking representabilityIn the previous sections an interesting sufficient condition was established for reducing one-versus-one ensembles toranking models by investigating the pairwise AUCs. The sufficient condition for the three-class case can be verified bysolving an integer quadratic program. This class of problems can in general not be solved exactly in polynomial time.However, we have not elaborated on this issue, since we were able to derive a more simple expression for the infinite casewhere a generalization is made from a sample to the underlying distribution. As a consequence, it makes sense to verifyERA transitivity on the pairwise AUCs instead of AUC transitivity, since we are mainly interested in generalizing to out-of-sample data. The conjunctor CP0 is visualized in Fig. 11 and compared to C jkl for n j = nk = nl = 10. Although such a samplesize can be considered as unrealistically small, it turns out that even then CP0 behaves very similarly to C jkl. Thus, theapproximation makes sense. Moreover, in the proof of the previous proposition, we have derived an analytical expressionfor the solution of the integer quadratic program, so that no optimization algorithm is required. This can be summarized asfollows.Corollary 6.1. For any values of n j , nk, nl, a∗∗and b, the solution of integer quadratic program (15) can be expressed as⎧⎪⎪⎪⎨⎪⎪⎪⎩τ =τ1,min(τ1, τ2),0,∗if (cid:15) an j∗if (cid:15) an j∗if (cid:12) an j∗(cid:16) + (cid:15) bnl∗(cid:16) + (cid:15) bnl∗(cid:13) + (cid:12) bnl(cid:16) > nk,(cid:16) (cid:2) nk (cid:2) (cid:12) an j(cid:13) (cid:2) nk,∗∗(cid:13) + (cid:12) bnl(cid:13),with τ1 and τ2 respectively defined by Eqs. (20) and (21).W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501245Fig. 11. C jkl compared to CP0 with n j = nk = nl = 10. (For interpretation of the references to color in this figure, the reader is referred to the web versionof this article.)So, we have obtained a verifiable condition to check whether a one-versus-one ensemble can be reduced to a rankingmodel for the three-class case, but will this approach also work in practice? The answer is not unhesitatingly yes for thefollowing two main reasons:1246W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250Fig. 12. A plot of the first two principal components of the iris data set.Table 1A comparison of the performance obtained on the iris data set by ten-fold cross-validation with various multi-class methods and a simple ranking model.The results of the multi-class methods are duplicated from [32] (OVO = one-versus-one SVM, DAG = directed acyclic graphs, OVA = one-versus-all SVM,W&W = single machine approach of Weston and Watkins, C&S = single machine approach of Crammer and Singer, SVORIM = support vector ordinalregression).MethodAcc.OVO97.333DAG97.333OVA96.000W&W97.333C&S87.333SVORIM98.000(1) The framework of AUC ranking representability only identifies the existence of a single ranking function that yields thesame error in terms of pairwise expected ranking accuracy as a one-versus-one ensemble, but nothing can be said aboutthe complexity of this ranking model. When we minimize a loss function over a hypothesis space of ranking models,no guarantee can be given that the model that we try to find is included in this hypothesis space.(2) Ordinal regression models do not try to optimize accuracy, but a loss function that takes the magnitude of an errorinto account. However, the magnitude of an error has no meaning at all in a multi-class setting, even if we artificiallytry to impose an order on the classes. The optimization of a magnitude-based loss function can harm the performancesignificantly when only accuracy is taken into account as performance measure. This effect can even be observed forordinal regression data sets.These two findings imply that in practice an AUC ranking representable one-versus-one model will not always be beatenby a ranking model. Revealing the situations where a performance gain will be obtained might not be done easily and wouldrequire an experimental validation on numerous data sets. Since most benchmark problems for multi-class classificationconsider more than three classes, first an extension of our approach to more than three classes has to be elaborated. Anobvious generalization could be established by looking at all triplets of classes and simplifying those for which AUC rankingrepresentability is fulfilled, but further research is required to verify whether this idea would work. Hereunder we haveanalyzed two three-class benchmark problems from the UCI repository to illustrate the potential benefits of AUC rankingrepresentability. Both problems have been analyzed by [32] in an experimental comparison of different multi-class schemeswith SVMs as base classifiers. We decided to compare with their results because they describe their experimental setup insuch a way that the experiments could be easily replicated.6.2. Iris dataThe first data set that was analyzed is the well-known iris data set, which is probably one of the most frequently utilizeddata sets to evaluate multi-class classifiers. The first two principal components of the data are visualized in Fig. 12. One cansee that class C2 is sandwiched on the left side by class C1 and class C3 on the right side, thus theoretically we imposethe order C1 < C2 < C3 on the classes if we would fit an ordinal regression model to that data set. In a comparison paperof kernel-based multi-class classification methods, Hsu and Lin [32] report for this data set that a one-versus-one modeloutperforms all other multi-class schemes. Since the iris data does not have an accompanying test set, they draw theirconclusions based on the 10-fold cross-validation error obtained for the best C (cost parameter) and γ (width of RBF-kernel)found during model selection. A short overview of the results is given in Table 1 together with the results obtained by fittingthe kernel-based ordinal regression model of [6] to the data. This method constructs a number of parallel hyperplanes in ahigh-dimensional space for ordinal regression, similar to the SVM for binary classification. In an initial stage, we first fittedW. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501247Table 2A comparison of the performance obtained on the DNA data set (independent test set) with various multi-class methods and a simple ranking model. Theresults of [32] are given in the first row and our results in the second row.MethodAcc.Acc.OVO95.44194.266DAG95.447OVA95.784W&W95.618C&S95.889SVORIM76.560a one-versus-one SVM to the data by using the values of the hyperparameters specified by [32], resulting in the followingpairwise AUCs when the whole data set is used for training2:(cid:2)A12 = 1.0,(cid:2)A23 = 0.995,(cid:2)A13 = 1.0.These pairwise AUCs definitely satisfy CP0-transitivity, so a reduction to a ranking model would make sense theoretically.When we fit an ordinal regression model to the data with the SVORIM-package, then the following pairwise AUCs aremeasured on training data:(cid:2)A12 = 1.0,(cid:2)A23 = 0.998,(cid:2)A13 = 1.0.Thus, the performance on training data increases, but more importantly, a better cross-validated performance in terms ofaccuracy is obtained with the ordinal regression model, using the same experimental setup as [32]. This might be surprisingat first sight, but one must take into account that PCA analysis already identified an ordinal structure of the classes. This isclearly an example where a reduction to a single ranking model can improve the generalization performance.6.3. DNA dataThe second data set that was analyzed is the DNA data set. Contrary to the iris data set, this data set has substantiallymore instances. The data is also relatively high-dimensional (180 features) such that the curse of dimensionality can play arole. Furthermore, the data has been split into a train and test set, so one can avoid the use of cross-validation here. Usingthe methodology of [32], this resulted in the following pairwise AUCs on the training set:(cid:2)A12 = 1.0,(cid:2)A23 = 0.952,(cid:2)A13 = 0.909.This triplet of pairwise AUCs again results in an AUC ranking representable model and suggests the order C1 < C3 < C2 onthe classes. So, let us swap classes C2 and C3, then the following pairwise AUCs on training data are obtained:(cid:2)A12 = 0.909,(cid:2)A23 = 0.952,(cid:2)A13 = 1.0.Subsequently, we tested the one-versus-one SVM and the SVORIM algorithm on the test set. Using the same methodologyas [32], we were not able to achieve exactly the same results for this data set, yet we obtained a similar (but slightly worse)accuracy on the test set. We cannot give any plausible explanation since we adopted exactly the same setup. The results aresummarized in Table 2 and give the impression that the SVORIM algorithm is not able to compete with the other multi-classapproaches. However, nothing is further from the truth, as the opposite conclusion can be drawn from the pairwise AUCsmeasured on the test set. The following values are obtained for the one-versus-one model:(cid:2)A12 = 0.808,(cid:2)A23 = 0.833,(cid:2)A13 = 0.997,while the ordinal regression model yields substantially better pairwise AUCs on the test set:(cid:2)A12 = 0.906,(cid:2)A23 = 0.907,(cid:2)A13 = 0.996.So, how can these surprisingly different trends between accuracy on the one hand and the pairwise AUCs on the otherhand be explained? As discussed above, this is caused by the fact the SVORIM algorithm does not optimize accuracy but amagnitude-based loss function. Fig. 13 gives a good overview of what is going on. On the left side, it shows the first twoprincipal components of the test set with the real labels and on the right side it shows the same test set with the labelspredicted by SVORIM. The ordinal regression algorithm clearly assigns too many instances to the middle class in an attemptto minimize the magnitude of errors. Apparently, that does not affect the performance in terms of pairwise AUCs for theDNA data set. It is therefore definitely recommended to look at this last criterion instead of accuracy in order to comparethe performance of one-versus-one models and single ranking models.2 Remark that we have to train on the whole data set in order to compute pairwise AUCs, since multivariate performance measures cannot be computedunambiguously by means of cross-validation [3].1248W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250Fig. 13. A graphical illustration of the effect of minimizing a magnitude-based loss function with the SVORIM algorithm on the DNA test set. The first twoprincipal components are shown with the real labels on the left side and the predicted labels on the right side. As a result of the transitivity analysis ofthe pairwise AUCs, the labels of classes C2 and C3 were swapped.7. ConclusionIn this article we analyzed the transitivity of expected ranking accuracy, a reciprocal preference relation that can beconstructed in a pairwise multi-class setting. Similar to the utility representability of more common reciprocal prefer-ence relations, this relation naturally led to the concept of ERA ranking representability for bipartite ranking functionsconstructed on couples of random vectors. In order to find necessary and sufficient conditions for this type of repre-sentability, we first recapitulated results obtained for the finite sample case, for which expected ranking accuracy canbe estimated by the AUC. ERA ranking representability then reduces to AUC ranking representability, for which nec-essary and sufficient conditions could be found, based on a graph-theoretic reformulation of the problem and a newtype of transitivity, namely AUC transitivity. In previous work we showed that this new type of transitivity can be ver-ified by solving an integer quadratic program. In this article we proved some interesting properties of AUC transitivity,and we generalized AUC ranking representability to ERA ranking representability by analyzing the limit behavior of AUCtransitivity. In this way, a distribution-independent and easily verifiable condition was obtained for the three-class case.Extensions for more than three classes are currently under development but invoke a strongly increasing complexity tothe problem, as cycle transitivity is only defined on three-element sets at this moment. A generalization of cycle tran-sitivity is therefore the first candidate for future work. Some initial research confirmed that such a generalization isfeasible.From a machine learning point of view, we investigated whether a pairwise multi-class classification model can be sim-plified to a ranking model (an ordinal regression model to be more precise). To this end, we started from the assumptionthat the optimal complexity of a multi-class classifier is problem-specific (data-dependent). Reducing a pairwise multi-class classifier to an ordinal regression model can be seen as a quite drastic application of the bias-variance trade-off:a pairwise multi-class classifier is complex, containing many parameters that result in a low bias and a high varianceof the performance, while an ordinal regression model contains substantially less parameters, leading to a high bias,but a low variance. So, we did not claim that a pairwise multi-class classifier can always be reduced to an ordinal re-gression model, we rather looked for necessary and sufficient conditions that allow for such a reduction, by analyzingthe pairwise expected ranking accuracies. The result that we obtained is in this regard remarkable and important, as itconfirms that the optimal complexity of a multi-class classification model depends on the distribution of the data. Theconditions that we derived are moreover distribution-independent, which means that they hold for any distribution of thedata.ERA ranking representability cannot be verified since the distribution of the data is usually unknown. Nevertheless, byevaluating CP0-transitivity on the pairwise AUCs, we have obtained a verifiable condition to check whether a one-versus-one ensemble can be reduced to an ordinal regression model for the three-class case. This relaxation makes sense, becausethe main interest is a good generalization performance. Simultaneously, we also derived a closed-form expression for thesolution of the integer quadratic program, so that both an approximation or a time consuming combinatorial optimizationcan be avoided.In practice an ERA ranking representable set of bipartite ranking functions will not always be beaten by a singleranking function. To this end, new machine learning algorithms have to be developed. Initial experimental results ontwo toy problems illustrate that the reduction to a single ranking model can improve the performance of an algorithm,definitely in terms of pairwise AUCs, but not necessarily in terms of accuracy. However, this is only the start of fur-ther experimental research on this topic, in which the obvious question of generalizing ranking representability to morethan three classes needs to be tackled. We refer to future work for this extension and an in-depth empirical valida-tion.W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501249AcknowledgementsThe authors would like to thank the anonymous reviewers for their valuable comments. Willem Waegeman would liketo thank Eyke Hüllermeier, Hendrik Blockeel and Hans De Meyer for a fruitful discussion about this work on the occasionof his PhD defence. Willem Waegeman is currently supported by the Research Foundation – Flanders. For a part of thiswork, he has been previously supported by a grant of the Institute for the Promotion of Innovation through Science andTechnology in Flanders (IWT-Vlaanderen).References[1] S. Agarwal, T. Graepel, R. Herbrich, S. Har-Peled, D. Roth, Generalization bounds for the area under the ROC curve, Journal of Machine LearningResearch 6 (2005) 393–425.[2] A. Agresti, Categorical Data Analysis, 2nd version, John Wiley and Sons, 2002.[3] A. Airola, T. Pahikkala, W. Waegeman, B. De Baets, T. Salakoski, An experimental comparison of cross-validation techniques for estimating the areaunder the ROC curve, Computational Statistics and Data Analysis, 2009, submitted for publication.[4] A. Billot, An existence theorem for fuzzy utility functions: A new elementary proof, Fuzzy Sets and Systems 74 (1995) 271–276.[5] U. Bodenhofer, B. De Baets, J. Fodor, A compendium of fuzzy weak orders, Fuzzy Sets and Systems 158 (2007) 811–829.[6] W. Chu, S. Keerthi, Support vector ordinal regression, Neural Computation 19 (3) (2007) 792–815.[7] S. Clémençon, N. Vayatis, Ranking the best instances, Journal of Machine Learning Research 8 (2007) 2671–2699.[8] C. Cortes, M. Mohri, AUC optimization versus error rate minimization, in: Advances in Neural Information Processing Systems 16, Vancouver, Canada,2003, MIT Press, 2003, pp. 313–320.[9] K. Crammer, Y. Singer, Pranking with ranking, in: Proceedings of the Conference on Neural Information Processing Systems, Vancouver, Canada, 2001,pp. 641–647.[10] B. De Baets, H. De Meyer, Transitivity frameworks for reciprocal relations: Cycle-transitivity versus FG-transitivity, Fuzzy Sets and Systems 152 (2005)249–270.[11] B. De Baets, H. De Meyer, B. De Schuymer, S. Jenei, Cyclic evaluation of transitivity of reciprocal relations, Social Choice and Welfare 26 (2006) 217–238.[12] B. De Baets, B. De Schuymer, H. De Meyer, Cycle-transitive comparison of artificially coupled random variables, International Journal of ApproximateReasoning 47 (2008) 306–322.[13] B. De Baets, H. De Meyer, K. De Loof, On the cycle transitivity of the mutual rank probability relation of a poset, Fuzzy Sets and Systems 161 (2010)2695–2708, doi:10.1016/j.fss.2010.05.005.[14] H. De Meyer, B. De Baets, B. De Schuymer, On the transitivity of the comonotonic and countermonotonic comparison of random variables, Journal ofMultivariate Analysis 98 (2007) 177–193.[15] B. De Schuymer, H. De Meyer, B. De Baets, S. Jenei, On the cycle-transitivity of the dice model, Theory and Decision 54 (2003) 261–285.[16] B. De Schuymer, H. De Meyer, B. De Baets, Cycle-transitive comparison of independent random variables, Journal of Multivariate Analysis 96 (2005)352–373.[17] B. De Schuymer, H. De Meyer, B. De Baets, Extreme copulas and the comparison of ordered lists, Theory and Decision 62 (2007) 195–212.[18] J.-P. Doignon, B. Monjardet, M. Roubens, Ph. Vincke, Biorder families, valued relations and preference modelling, Journal of Mathematical Psychology 30(1986) 435–480.[19] T. Fawcett, An introduction to ROC analysis, Pattern Recognition Letters 27 (8) (2006) 861–874.[20] C. Ferri, J. Hernandez-Orallo, M.A. Salido, Volume under ROC surface for multi-class problems, in: Proceedings of the European Conference on MachineLearning, Dubrovnik, Croatia, 2003, pp. 108–120.[21] J. Fieldsend, M. Everson, Formulation and comparison of multi-class ROC surfaces, in: Proceedings of the ICML Workshop on ROC Analysis in MachineLearning, Bonn, Germany, 2005, pp. 49–56.[22] P. Fishburn, Utility Theory for Decision Making, Wiley, 1970.[23] P. Flach, The geometry of ROC space: Understanding machine learning metrics through ROC isometrics, in: Proceedings of the International Conferenceon Machine Learning, Washington, DC, USA, 2003.[24] P. Flach, The many faces of ROC analysis in machine learning, Tutorial Presented at the European Conference on Machine Learning, Valencia, Spain,August 2004.[25] L. Fono, N. Andjiga, Utility function of fuzzy preferences on a countable set under max-∗-transitivity, Social Choice and Welfare 28 (2007) 667–683.[26] J. Fürnkranz, Round robin classification, Journal of Machine Learning Research 2 (2002) 723–747.[27] J. Fürnkranz, E. Hüllermeier, S. Vanderlooy, Binary decomposition methods for multipartite ranking, Lecture Notes in Computer Science 5781 (2009)359–374.[28] D. Hand, R. Till, A simple generalization of the area under the ROC curve for multiple class problems, Machine Learning 45 (2001) 171–186.[29] J. Hanley, B. McNeil, The meaning and use of the area under a receiver operating characteristics curve, Radiology 143 (1982) 29–36.[30] T. Hastie, R. Tibshirani, Classification by pairwise coupling, The Annals of Statistics 26 (2) (1998) 451–471.[31] R. Herbrich, T. Graepel, K. Obermayer, Large margin rank boundaries for ordinal regression, in: A. Smola, P. Bartlett, B. Schölkopf, D. Schuurmans (Eds.),Advances in Large Margin Classifiers, MIT Press, 2000, pp. 115–132.[32] C. Hsu, C. Lin, A comparison of methods for multi-class support vector machines, IEEE Transactions on Neural Networks 13 (2002) 415–425.[33] Z. Hua, B. Zhang, X. Xu, A new variable reduction technique for convex integer quadratic programs, Applied Mathematical Modelling 32 (2008) 224–231.[34] E. Hüllermeier, J. Fürnkranz, Pairwise preference learning and ranking, in: Proceedings of the European Conference on Machine Learning, Dubrovnik,Croatia, 2003, pp. 145–156.[35] E. Hüllermeier, J. Hühn, Is an ordinal class structure useful in classifier learning? International Journal of Data Mining, Modelling and Management 1 (1)(2009) 45–67.[36] M. Koppen, Random utility representation of binary choice probabilities: Critical graphs yielding critical necessary conditions, Journal of MathematicalPsychology 39 (1995) 21–39.[37] R. Luce, P. Suppes, Handbook of Mathematical Psychology, Preference, Utility and Subjective Probability, Wiley, 1965, pp. 249–410.[38] P. McCullagh, Regression models for ordinal data, Journal of the Royal Statistical Society, Series B 42 (2) (1980) 109–142.[39] M. Öztürk, A. Tsoukiàs, Ph. Vincke, Preference modelling, in: J. Figueira, S. Greco, M. Ehrgott (Eds.), Multiple Criteria Decision Analysis. State of the ArtSurveys, Springer-Verlag, 2005, pp. 27–71.[40] F. Provost, T. Fawcett, Robust classification for imprecise environments, Machine Learning 42 (2001) 203–231.[41] R. Rifkin, A. Klautau, In defense of one-versus-all classification, Journal of Machine Learning Research 5 (2004) 101–143.1250W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250[42] A. Shashua, A. Levin, Ranking with large margin principle: Two approaches, in: Advances in Neural Information Processing Systems, vol. 16, Vancouver,Canada, 2003, MIT Press, 2003, pp. 937–944.[43] Z. Switalski, General transitivity conditions for fuzzy reciprocal preference matrices, Fuzzy Sets and Systems 137 (2003) 85–100.[44] V. Torra, J. Domingo-Ferrer, J.M. Mateo-Sanz, M. Ng, Regression for ordinal variables without underlying continuous variables, Information Sciences 176(2006) 465–476.[45] A. Tversky, Preference, Belief and Similarity, MIT Press, 1998.[46] W. Waegeman, B. De Baets, A transitivity analysis of bipartite rankings in pairwise multi-class classification, Information Sciences 180 (2010) 4099–4117.[47] W. Waegeman, B. De Baets, L. Boullart, ROC analysis in ordinal regression learning, Pattern Recognition Letters 29 (2008) 1–9.[48] F. Wu, C. Lin, R. Weng, Probability estimates for multi-class support vector machines by pairwise coupling, Journal of Machine Learning Research 5(2004) 975–1005.[49] L. Yan, R. Dodier, M. Mozer, R. Wolniewiecz, Optimizing classifier performance via an approximation to the Wilcoxon–Mann–Whitney statistic, in:Proceedings of the International Conference on Machine Learning, Washington DC, USA, 2003, pp. 848–855.