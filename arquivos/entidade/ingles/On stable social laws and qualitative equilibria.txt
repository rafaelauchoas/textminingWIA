Artificial Intelligence 102 (1998) l-20 Artificial Intelligence On stable social laws and qualitative equilibria * Moshe Tennenholtz ’ Faculty of Industrial Engineering and Management, Technion-Israel Institute of Technology, Haifa 32000, Israel Received 6 October 1996; received in revised form 1 January 1998 Abstract This paper introduces and investigates the notion of qualitative equilibria, or stable social laws, in tbe context of qualitative decision making. Previous work in qualitative decision theory has used the maximin decision criterion for modelling qualitative decision making. When several decision-makers share a common environment, a corresponding notion of equilibrium can be defined. This notion can be associated with the concept of a stable social law. This paper initiates a basic study of stable social laws; in particular, it discusses the stability benefits one obtains from using social laws rather than simple conventions, the existence of stable social laws under various assumptions, the computation of stable social laws, and the representation of stable social laws in a graph-theoretic framework. 0 1998 Elsevier Science B.V. All rights reserved. Keywords: Social laws; Qualitative decision making 1. Introduction General coordination mechanisms are essential tools for efficient in multi- reasoning issue of study in the fields of are a major agent AI systems. Coordination mechanisms mathemati,cal economics and game theory as well. Much work in these fields concentrates on the notion of an equilibrium. An equilibrium is irrational for each agent to deviate discussed literature refers to agents which are expected utility maximizers. However, much work in AI has been concerned with In particular, work in AI has been more qualitative from that behavior. The notion of an equilibrium is a joint behavior of agents, where it in the game theory and mathematical forms of rational decision making. economics *A preliminary Knowledge Representation version of this paper appears and Reasoning. in the Proceedings of the 5th International Conference on ’ Email: moshet@ie.technion.ac.il. 0004-3702/98/$19.00 PII: SOOO4-3702(98)00033-2 0 1998 Elsevier Science B.V. All rights reserved. 2 M. Tennenholtz /Artijicial Intelligence 102 (1998) I-20 to maximize from a decision-theoretic their worst case payoff. Although, at concerned with agents which attempt it is known perspective, first, this behavior may look questionable in the context of to capture the behavior of risk-averse agents [9,19,38], and it is appropriate qualitative decision in [9] Brafman and Tennenholtz have theory [8,15,19,59]. Moreover, shown general conditions under which an agent can be viewed as if it were a maximin agent notion (i.e., an agent which maximizes of equilibrium this notion and investigate turns out to coincide with later in this paper. For ease of exposition the notion of a stable social law, to be introduced we introduce fashion, as an extension to previous work on artificial social systems. its properties. The concept of qualitative equilibrium the notion of a stable social law in a self-contained its worst case payoff). However, the corresponding has not yet been investigated. In this paper we introduce Some work on multi-agent systems assumes that agents are controlled by a single is in time, while some other work process systems protocols that conform in multi-agent at each point their behavior to agreed-upon rational negotiation in order that irrational negotiation systems agents will protocols, but will conform resolution in decentralized to resolve the agents will systems where no global controller for decentralized multi-agent encounters. The basic exists. A significant [7,17] deals with theme of work on this subject reach states of conflict and appropriate these conflicts. The in AI follow. Work deals. Agents to deals obtained by [20,37,62].2 This differs from work in game- entity which dictates concerned with decentralized part of the theory developed conflict is that negotiation mechanisms would be needed result of the negotiation is a deal has been mostly concerned with agents may not follow following theory [25,48] where a joint strategy is considered unstable from a design perspective) The Artificial Social Systems approach totally centralized basic a social law, resolution of conflicts. consist of various restrictions on the agents’ activities which allow but at the same time constrain particular, a social the system efficiency. Notice of the social law; they will be used in situations where conflicts can’t be prevented advance. it. a to coordination. The called and on-line law may is a set of freedom on one hand, them so that they will not interfere with each other. In improves can serve as part in approach and a totally decentralized idea of the Artificial Social Systems approach from (e.g., [45,57]) exposes a spectrum between (and therefore unsatisfactory to deviate law makes certain conflicts unreachable, the need robots setting, control such a social if an agent has a rational is to add a mechanism, [56]. More generally, for both centralized that will minimize traffic constraints that mechanisms and as a result them enough for example, In a mobile for conflict resolution approach incentive a social law The motivation systems, and as such it assumes multi-agent by the designer. However, laws might be considered systems approach and approaches in multi-agent resolution of conflicts laws, but the theory of artificial social systems has neglected for the theory of artificial social systems has been the design of artificial that the agents will obey the law supplied if each agent then some irrational. Therefore, at the current stage, the artificial social the to conflict resolution are somewhat complementary; theory of social the stability of social laws in is designed by a different designer is part of a more general encounters * See [53] for a detailed discussion of this point. M. Tennenholtz /Artificial Intelligence 102 (1998) l-20 3 encounters. laws for multi-agent In this paper we wish to bridge part of the gap between stable social is a restriction of the set of available actions (in the encounter) the theory multi-agent encounters, in multi-agent of artificial social systems and the theory of conflict resolution encounters. A social law for a multi- by considering to a set of agent encounter from them irrational. Notice socially allowed actions. Stable social laws make deviation that a convention type of a social law; a convention determines a particular joint action for the agents to follow (e.g., keep the right of the road), while a social law is quite allows several such actions and prohibits others. As it turns out, this distinction important and useful. is a particular In particular, is to optimize encounters using a game-theoretic We will discuss social laws for multi-agent frame- in recent in most of this paper we will assume work which is tailored for assumptions made in the AI literature, and especially work on qualitative decision making. that the agents are risk-averse agents, which use the maximin decision criterion. More specifically, given a set of possible behaviors of the other agents, its worst case outcome assuming the aim of the other agents may follow an agent is appropriate where there is some ordinal any of these behaviors. This kind of behavior In such situations all that matters to agents is the order of relation on possible outcomes. is an payoffs and not their exact value. The precise conditions under which such modelling in [9]. Moreover, as we discuss in Section 4, this modeling appropriate: one are discussed to the perspective achievement of a particular user’s specification. We will require that a social law suggested to the agents a certain payoff, and that it will for a particular encounter will guarantee be stable; the agents are risk- there should be no incentive averse agents. Hence, a stable social law corresponds for risk-averse extended agents. In a later stage, we show how our discussion to other basic qualitative decision-making systems, where a payoff corresponds to a notion of qualitative equilibrium is quite natural in many multi-agent to deviate from it assuming and results can be settings. We start by introducing our framework. In particular, in Section 3 we define the notion of the basic framework, study of stable social laws; we formulate systems. Having encounters encounters for which a stable convention for which there is an appropriate stable social laws. In Section 4 we discuss the intuition and formal adequacy of maximin in Section 5 we show that the set in multi-agent exists is a strict subset of the set of multi-agent of multi-agent stable social law; however, we show that there exists situations where no stable social law exists. Then, in Section 6 we initiate a computational problem and show that the general problem of coming up with a stable computational the proof of our result sheds light on the structure of stable social social law :IS intractable; restriction on our framework under which laws; in addition, we point the synthesis of stable social laws is polynomial. We then return back to the question of the existence of stable social laws; in Section 7 we first show how this question can be terms, and then expose a class of encounters where formulated the existence of stable social laws. In Section 8 simple graph-theoretic we discuss how our ideas can be applied in other qualitative decision making contexts, and in Section ‘9 we further discuss the meaning of our study and results and the connection of our work to the existing in standard graph-theoretic the corresponding to an interesting conditions literature. imply 4 M. Tennenholtz /ArtiJicial Intelligence 102 (1998) l-20 2. The basic framework In this section we introduce our basic framework, which is built upon a basic game- theoretic model. 2.1. The basic model In general AI planning systems, agents are assumed plan A conditional action. Conditional strategies model; therefore, we will adopt the term strategy. is a (perhaps partial) plans can be treated as protocols in game-theoretic function from the local state of an agent to perform conditional plans. 3 to terms, or as in distributed systems terms. In the sequel we will make use of a game-theoretic Multi-agent encounters can be represented as a game. In this paper we will consider in an encounter. 4 We will be concerned two-person games, where two agents participate with finite games where each agent has a finite number of strategies. A joint strategy for the agents consists of a pair of strategies, one for each agent. Each joint strategy is associated The with a certain payoff for each of the agents, as determined by their utilityfunctions. above-mentioned terms which capture general multi- agent encounters. terms are classical game-theoretic Formally, we have: Definition 1. A game (or a multi-agent N = { 1,2) is a set of agents, S and T are the sets of strategies available 2 respectively, and lJ1 : S x T -+ IR and Uz : S x T + II% are utility functions and 2, respectively. (N, S, T, U1, Uz), where to agents 1 and for agents 1 encounter) is a tuple One interesting point refers to the knowledge of the agents about the structure of the game. In this work, we assume that agents are familiar with the sets of actions available to the different agents, but an agent might be aware only of its own payoff function. Our results are appropriate both for the case where the payoff functions are common-knowledge among the agents and for the case an agent knows only its individual payoff function. How should agents behave in a multi-agent system’s designer may wish to guarantee crucial for agents who are committed particular modeling of agents as maximin reasoners we show how our results can be extended making. encounter prescribed by a given game? The to the agents a particular payoff. This guarantee is to obtain particular goals and to successfully perform system. This brings us to the in Section 4). In Section 8 (see the discussion to other basic settings of qualitative decision tasks on behalf of their users in a multi-agent Definition 2. Let S and T be the sets of strategies available and let Vi be the utility function of agent i. Define U1 (s, T) = minter Ut (s, t) for s E S, to agent and 2 respectively, 3 Plans with complete information and other forms of plans will be taken as restrictions on the general form of plans considered in this paper; this point will not affect the discussion or results presented in this paper. 4 The concepts defined in this paper can be easily extended to the case of k > 2 agents, where k is a constant. M. Tennenholtz /Artificial Intelligence 102 (1998) I-20 5 and Uz(S, ,Y) = mintEs U2 (t , s) for s E T. The maximin value for agent 1 (respectively 2) is defined by max,,S Ul(s, T) (respectively maxrET Uz(S, t)). A strategy of agent i leading to the corresponding maximin value is called a maximin strategy for agent i . 2.2. Conventions and social laws As we have mentioned an agent may wish to guarantee that a particular specification :requirements are indeed obtained. The achievement or user’s requirements will be associated with a particular payoff. The system designer in certain applications, government applications) can specify a social law that will enable payoffs. One way of capturing such reasonable behavior each agent will be at least t . 5 the system administrator set of (e.g., the or other mediators on other the agents to obtain “reasonable” is by requiring that the payoff for of a particular Given a game and a requirement t, the designer may supply the agents with an appropriate convention: which the utility for both agents is greater than or equal to t. A convention case of a social law. A social law in a multi-agent strategies available particular joint strategy. The role of the designer least one strategy which guarantees a payoff of at least t. that the agents will be able to obtain a payoff of at least a joint strategy for is a special is a restriction on the set of to a one is to select a law that allows each agent at to the agents; a convention will simply restrict the behavior encounter Definition 3. Given a game g = (N, S, T, U1, Uz) and an efficiency parameter t, we define a social law to be a restriction of S to S C S, and of T to 7; C T. The social law is useful if the following hold: there exists s E S such that Ur (s, 7;) 2 t, and there exists k E T such that Clz(S, k) 3 t. A (useful) convention is a (useful) social law where IS] = ITI = 1. and succeed to act individually to the law (see the discussion and the general semantics In general, a useful social law is a restriction on each agent’s activities which enables reasonably well, as long as all the agents each agent in [46,57]). At this point conform the idea of using social laws for coordinating encounter may seem a bit strange; why should we care about social laws if every efficiency degree which can be obtained by a social law can already be obtained by an appropriate simple convention? However, as we will later see, social laws can serve as much more useful entities than simple conventions for agents participating agents’ activities in a multi-agent in a multi-agent encounter. 3. Stable social laws The concept of social laws which has been discussed for the design of multi-agent methodology social laws for multi-agent of the resolution of conflicts, up to date the power of social laws has been illustrated in previous work defines a general In this work we are concerned with that’s a most popular setting for the study in encounters. Although systems. 5 The case where different thresholds are associated with different agents can be treated similarly. 6 M. Tennenholtz /Art@cial Intelligence IO2 (1998) I-20 more complex settings multi-agent encounters as well. [56,57]. As we shall see, social laws may serve as useful tools for Definition 4. Given a game g = (N, S, T, U1 , U2) and an efficiency parameter q, a quasi-stable restricts S is no s’ E S - 3 which satisfies to 3 and T to r, and satisfies and there is no t’ E T - T which satisfies U2(s, t’) > social the following: social Zaw is a useful law (with respect to q) which there > max,,s]Q(s,T)l, &(s’,T) max,,+2@, t)). Indeed, Our definition social law will make a deviation is in the spirit of classical game theory; we require that deviation by one agent will be irrational given that the other agent sticks to the suggested behavior. Notice that irrationality here refers to the notion of maximin behavior. if an agent’s aim to the user of obtaining payoff k, then it the fulfillment of his commitment is to guarantee for him to deviate to a strategy that might risk this guaranteed performance. 6 is irrational Hence, a quasi-stable from the social law irrational as the above definition of stability may not long as the other agent obeys the law. However, an agent has specific goals to encounter be satisfactory obtain, and there is no reason to assume an agent will execute a strategy which yields to to it by another strategy, assuming it a payoff which is lower than the payoff guaranteed it in other terms, given that we talk about a specific the other agent obeys the law. Putting in the set of allowed strategies encounter with specific goals, there is no reason to include a strategy which is (maximin) dominated by another strategy in that set. This requirement is consistent with models of stable social situations discussed in the game theory literature [31]. Therefore we have: In a multi-agent in our context. law is a stable social law if the payoff guaranteed social Definition 5. A quasi-stable of the strategy to the law) it selects, to each of the agents is independent as long as the other agent conforms to the social law (i.e., selects strategies allowed by the law). Namely, given a game g = (N, S, T, lJ1, UT) and an efficiency parameter q, the quasi-stable is a stable tl) = Ul(s2, t2) and social Zaw if: for all ~1, s2 E 3, and tl, t2 E T, we have that Ul(sl, to 3 and T respectively law that restricts (conforming the agents social U2@1, t1) = Uz(s2, t2>. Notice that a stable social law is an equilibrium to associate with the maximin decision criterion. Hence, our study of stable social laws can be in the context of qualitative decision making. Our interpreted as a basic study of equilibria discussion in which to qualitative decision making contexts and results can be extended from maximin. We further discuss the agents adopt decision criteria which are different this point in Section 8. concept which one may wish In the rest of this paper we discuss stable social laws. 7 Given a multi-agent encounter, a stable social law will guarantee to the way a particular payoff can be guaranteed by a simple convention. As it turns out however, the to the agents a particular payoff, similarly 6 See also the discussion in Section 4. 7 Similar results can be obtained when we consider quasi-stable social laws. M. Tennenholtz /Artzjicial Intelligence 102 (1998) I-20 I difference between social laws and conventions more stable than conventions in multi-agent stems from the fact that social laws may be encounters. This will be the topic of Section 5. 4. A perqpective on safety level decisions in Economics. Although is of major importance issue (see [2]), it is the central solution concept discussed this concept in literature. The concept of social laws is quite natural for many domains, [4,5,46,47,57]. We believe however in this paper, should be further discussed is presented. A major concern one may have is in other works The notion of equilibrium is still a mlajor controversial the Economics and has been studied and applied that the concept of stable social laws, defined before a study of some of its properties the applicability Although we believe to the fact it complements it bridges some of the gap between resolution, the study presented of the maximin (safety level) kind of reasoning to multi-agent domains. importance due previous work carried out in game theory and due to the fact the theory of social laws and the theory of conflict in this paper is of considerable the applicability of the related concepts should be also discussed. Assume a system consists of several robots each of which is controlled by a different au- consists of a set of goals/tasks in current Automated Guided Vehicles systems, (as in Stanford’s Gofer project [ 131). Each such authority/programmer thority/programmer may be hired in order to obtain various tasks for different users/companies. A similar situa- tion arises when several software houses compete in a market, where they perform tasks on behalf of their clients. More generally, an agent needs to satisfy a user’s specification for that should be obtained. a product, where the specification in current software This is the situation is required. Assume projects, etc. In such systems a guarantee there are II possible goals one may consider, a contract will specify k < n of them that an agent will (and must) obtain. The payment delivery. The above set of situations exist in many systems and can be best captured by maximin systems. In the related settings one may inter- pret a payoff as the number of goals that the agent obtains when the agents follow particular to obtain strategies. The maximin value is the number of goals that the agent can guarantee and that it will be willing rea- these systems might not be purely soning are rarely used in the related systems, although fashion are indeed competitive. Social laws that restrict agents’ behavior used in the related settings. for the agent is a function of the guaranteed them. Expected value and Bayesian for a particular delivery to commit on achieving reasoning/analysis in a deterministic in multi-agent The above kind of analysis is quite intuitive, but a reader may attack it based on the above, interpretation we give to payoffs. Consider an interpretation as the one mentioned fails of or a similar one (e.g., one may refer to the negation of the number of possible a processor, as the payoff in a certain hardware system, etc.), the payoff function might terms. This concern however can be addressed not capture utility by paying attention theory. Utilities are entities which are to an agent based on its actions. The fundamental work of Savage [54] serves as ascribed the justification for the use of maximal expected utility. In his work Savage supplies a set of conditions on an agent’s choice among actions, under which it can be viewed as if it had for action selection. probabilities, utilities, and it had used expected utility maximization to the foundations of decision in standard economic 8 M. Tennenholtz /Arti$cial Intelligence 102 (1998) l-20 there is no meaning from a formal perspective, to utilities without mentioning Therefore, the decision criterion [9,10] have shown that is used. Indeed, Brafman and Tennenholtz sound and complete conditions under which an agent can be viewed as if it had a utility function under which it used the maximin decision criterion. Hence, one should be careful before dismissing maximin or other decision criteria based on the formal grounds supplied at [lO,l 11). On the other hand, as illustrated above, in previous work (see the discussion intuitive meanings exist for many interesting multi-agent domains. We will elaborate on the use of maximin and safety level decision making for payoffs under which maximin in the discussion is appropriate, reasoning session. 5. Social laws versus conventions of stable social Having a definition laws good for? If we wish to guarantee a certain payoff for the agents, why can not we look for stable conventions, assuming such a strategy exists? i.e., select a joint strategy from which a deviation would be irrational, laws, one may ask: what are these The answer is supplied by the following result: Theorem 6. There exists games for which appropn’ate stable social laws do exist. there are no stable conventions, but where Proof. The proof follows by considering the following game: agent 2 agent 1 A B c D n Assume the designer wishes to guarantee the payoff 1. The fact that no stable convention to perform to perform If the agents are required to perform A) or are required (A, A) (i.e., each (A, B) (i.e., agent 1 is required to perform B), then agent 2 may improve upon its to exists follows by case analysis. agent is required to perform A and agent 2 is required situation by performing D; If the agents are required perform (B, A) then agent 2 can improve its situation by performing C . All other potential conventions are not useful, since at least one of the agents obtains a payoff which is less than 1. On the other hand, if we restrict both agents to perform actions taken from [A, B} If then a payoff of 1 is guaranteed agent 2 performs C (respectively D) then it may lose if agent 1 has chosen to perform A (respectively B). If agent 1 performs C (respectively D) then it may lose if agent 2 has chosen to perform B (respectively A). for both of the agents and no deviation (B, B) or are required is rational. to perform (cid:144)I M. Tennenholtz /Art$cial Intelligence 102 (1998) I-20 9 to a set of allowed actions the fact that the agent’s behavior The above theorem reveals a new contribution of the theory of social laws: restricting rather than to a particular action the activities of the agents encounters. This is due to the fact that social laws is useful even in simple multi-agent the above result is as may be more stable than simple conventions. The intuition behind follows. Although different strategies may lead to similar payoffs, different strategies may block different deviations by the agents. Therefore, is only partially defined may improve that there are two agents, each of which can invest its money using four options, A, B, C, or D. If they will invest only in options A and B then they will get reasonable payoffs. However, if they are told to invest in particular options, e.g., one is told to invest in A and the other is told to invest in B, then one of them may take this opportunity in order to gain more on behalf of the other using option C or D. But, if both C and D yield low payoffs when they are applied against A or B (although not against both of them), such deviation can from among options be preventlzd by telling each agent to choose (nondeterministically) to A and B (i.e., by supplying particular of this situation by considering the social law: “do not use C and D”, rather than pointing investments). The reader may get additional understanding the system efficiency. Assume for example the proof of Theorem 6. We have: shown that social laws are more stable than conventions. We can also show: Theorem ‘7. There exist games for which no stable social laws exist, for any selection of the eficiency parameter: Proof. The proof follows by considering the following game: agent 2 agent 1 7J$j-&J A case .analysis shows that no stable social law exists in the above-mentioned game. If both agents are required to perform A then agent 2 can improve upon its situation by performing B. If both agents are required to perform B then agent 2 can improve upon its situation by performing A. If agent 1 is required to perform B then agent 1 will improve to perform B and agent 2 is required its situation by performing A. Given that all of the payoffs in the matrix are different, it is clear that no law to perform either A or B (i.e., where both actions are allowed) where an agent is required will be stable. Notice that allowing both A and B is not stable, since one of the allowed than the other. ’ actions wi 11 become more desirable to perform A and agent 2 is required its situation by adopting B. If agent 1 is required to perform A then agent 1 will improve Combining the above we get that no stable social law exists. q 8 The question of whether desirable behaviors can be obtained by social laws that are not stable according to OUT definition discussed by Shapley when considering the scope of this paper. The type of stable sets we consider somewhat the notion of block dominance is beyond [55]. resemble the situation 10 M. Tennenholtz /Artijicial Intelligence 102 (1998) I-20 Hence, stable social laws are powerful but do not always exist. Given this observation, may be of interest to supply a procedure for computing when a social law exists. Naturally, in cases where a stable social law exists it may be of interest to compute such a law. In addition, for the existence of stable social laws. These are the topics of the following sections. to characterize conditions it may be of interest it 6. Computing stable social laws In this section we take a look at the computation so, we first need to decide on the representation game-theoretic matrix. representation in which a multi-agent of stable social laws. In order to do of our input. We will use the standard is represented by a game encounter The problem of computing a Stable Social Law (SSLP) is defined as follows: Definition 8 (The Stable Social Law Problem [SSLP]). Given a multi-agent and an efficiency parameter payoff which is greater than or equal to t if such a law exists, and otherwise announce no such law exists. t, find a Stable Social Law which guarantees encounter g, to the agents a that Notice that if we restrict ourselves to simple conventions, easy; however, as we have observed, conventions following theorem shows this does not come without a cost. We are able to show: is are not as useful as social laws. As the the computational problem Theorem 9. The SSLP is NP-complete. is by reduction Proof. The proof that the problem is NP-hard Our reduction will generate a 2-person game g, where the strategies identical. The set of strategies is in NP is straightforward. The proof that the problem from 3-SAT [27]. Let p be a 3-CNP formula with m clauses. for both agents are for each agent is: cf , cf , . . . , cy , di (1 6 i 6 m), where i (there are seven such to clause strategy which is associated with clause t to be equal to 0, and let t’ be a positive real number. each cf is associated with a different assignments), i . We take the efficiency parameter We will show that a stable social law for g exists if and only if cp is satisfiable. and di is an additional distinguished truth assignment We take g to be a symmetric game, and specify the utility function of agent 1: (1) Ul(d;, di) = -t’ for all i, j. (2) U1 (ci , cj) = 0 iff c! and c> correspond to consistent assignments. (3) Ut (c!, c;) = --t’ iff cf and cf correspond to inconsistent assignments. (4) Ut (di, c;) = t’ for all i # j and every k. (5) Ut($, di) = -t’ for all i # j and every k. (6) for every i and every k. (7) U1 (cf , di) = t’ for every i and every k. .Vl (di, cf) = -t’ M. Tennenholtz /Art$cial Intelligence 102 (1998) l-20 11 Now, consider a truth assignment T which satisfies p. We can define a social law which leaves each agent only with the strategies which their corresponding are as determined by T (and with no strategy of the form &). It is easy to see that we get a sta- ble social law; the social law guarantees a payoff of 0 since the agents are left only with “consistent strategy strategies”, and deviations are irrational since there is a representative of the form cb for each clause. assignments If there exists a stable social law then it can not leave the agents with strategies of the form di . This is due to the fact that when such actions are performed a payoff that is lower than 0 might be obtained. In addition, such a law must leave each agent with exactly one strategy for each clause. At least one strategy for each clause is required since otherwise If more than one strategy is allowed for each a deviation clause then the agents may execute “inconsistent (which lead to negative pay- offs). The allowed strategies need to be consistent assignments), allowed strategies (i.e., their corresponding ment. the truth assignments) we get a satisfying assign- since otherwise a payoff lower than 0 is possible. Hence, by combining to some dj will become rational. to their corresponding (with respect strategies” 0 result is complementary first, it supplies an initial The importance of the above theorem study of stable social in is twofold: the proof of this result sheds laws. Second, the computational additional light on the structure of stable social laws. As one can see, we need to restrict the behavior of agents, but still leave them with enough freedom for blocking deviations to the observations made in [46] by the other agents. This observation in about the role of social arti)cial in order that they won’t interfere with one another but leave them with enough freedom for obtaining socially acceptable goals. The setting described encounters and not to general artificial social systems, but augment concept of stability; As we have explained, aspect of the golden-mean the following laws. the discussion with the of stability explores another in is obtained of stable social laws. In [46] the authors refer to the goZden-mean problem the behavior of agents problem. Further understanding section, where we supply a graph-theoretic .social systems, where the designer needs of this structure representation in this paper refers to multi-agent the introduction to restrict represen- Notice that in many situations the system’s in the previous input has a much more succinct theorem. This points result. Indeed, interactions representations [25]. Hence, given than the one discussed it is not straightforward laws in the framework of strategic-form the above kind of representation to the importance of tation to show that the design of the above hardness [46]. Nev- social for modeling many ertheless, it would be of inter- multi-agent est to identify general cases where the problem of coming up with a stable social law (if such a law exists) in- is tractable. One case which is of interest volved are of unequal power. One way of capturing that one this fact is by assuming to it than the other party does. Formally, we party has many more strategies available say that an agent is logarithmically to it is O(log(n)jl where n is the number of strategies available to the other agent. In this case we can show: has been found useful the previous bounded if the number of strategies available is when the parties is intractable theorem, 12 M. Tennenholtz /Artijicial intelligence 102 (1998) I-20 Theorem 10. The SSLP when one of the agents is logarithmically bounded mial. 9 is polyno- let agent 1 be the logarithmically for agent 2 and exclude from them the ones that are dominated bounded agent. We can Proof. Without loss of generality restrictions on its strategies since there are only efficiently enumerate the set of possible r, let us denote the set of polynomially many such possibilities. For each such restriction nonprohibited strategies by St (r). Given SI (r) we can gather the set of strategies of the other agent (i.e., agent 2) which guarantee a payoff greater than or equal to t (where t is the efficiency parameter) by other strategies of that agent (2). Let us denote this set of strategies by &(r). Now, if there are strategies in St (r) or if there exists a strategy in S1 (r) which does not guarantee a payoff oft (given the previously generated set r’ on the strategies of strategies for agent 2) then we should move and try a new restriction of agent 1. If that’s not the case then we need to check whether there is a strategy for one in St (r) and f&(r) respectively, and may yield a better of the agents which is not included payoff for the respective agent than what is guaranteed under St (r) and &(r). If there is then we should try another r’ (if exists) and otherwise we should stop (an such a deviation appropriate in S1 (r) that are better than other strategies in a systematic manner all possible stable social laws restriction on the behavior of agent I is checked, and for each such since each possible the most general restriction on the second agent’s behavior which still may be restriction since agent 1 has only possible O(log(n)) all that we need to do in to compute for every action the worst case payoff which might be obtained these worst case payoffs to the when the other agent obeys the law; then we can compare payoff guaranteed by the law, in order to detect whether a rational deviation exists. q strategies. Checking stability of a given set of restrictions is generated. This enumeration is polynomial; is polynomial procedure law has been found). The above procedure exhausts 7. Graph-theoretic representations of stable social laws In addition, the study of a new equilibrium theorems can supply conditions We can learn about the structure of stable social laws by studying the reduction used concept and of its use can in Theorem 9. More generally, theorems which show what does this concept mean greatly benefit from representation in the context of this particular work, such in terms of known concepts. representation for the existence of stable social laws. The reduction used in the proof of Theorem 9 shows that a special case of the problem of to a well-known problem. This has been useful finding a stable social law is isomorphic the for proving the above-mentionedresult. In particular, general Stable Social Laws concept by means of well-known in this section we make use of graph-theoretic the stable social law concept. terminology. terms in order to characterize However, it would be of interest to characterize 9 The results presented to the case of k 2 2 agents. The technique used in the proof of Theorem 10 can be used also for the case k > 3 if there is only one party which is more powerful section and Theorem 9 can be easily extended than the others. in the previous M. Tennenholtz /Artijicial Intelligence 102 (1998) l-20 13 We will make use of the following standard terms: Definition. 11. Let G = (V, E) be a graph, where V is a set of nodes, and E C V2 is a set of edges. G is undirected if, for all ~1, u2 E V, (~1, ~2) E E iff (~2, ~1) E E, and is directed otherwise. A set V’ C V is an independent set if there are no v’, v” E V’ which satisfy (v’, u”) E E. A set V’ c V is a clique if (u’, v”) E E for all u’, u” E V’. A node u E V is nonisohzted to V’ C V if there is a vertex u’ E V’ such that (v, v’) E E. A set V’ E V is a dominating set if for each node v’ E V - V’ there is a node uN E V’ such that (v’, v”) E E. A node v E V is a sink if there is no u’ such that (u, v’) E E, The graph G is k-colorabl’e if we can color the nodes of the graph with k colors in a way that (v, v’) E E implies that u and u’ have different colors. relative We would now like to make a connection between the above-mentioned graph-theoretic terms and our notion of a stable social law. In the sequel we will be concerned with games where the sets of strategies, S, available to the agents are identical. We will also assume the in the sense that Ut (s, t) = Q(t, s) (i.e., the outcome of the agents is game is symmetric in social laws that are fair, in the sense independent of their names). We will be interested for all agents. For ease that if a strategy for one agent then it is prohibited the value t and no more of exposition we will be concerned with social laws guaranteeing than t. is prohibited t, let Gt = (V, El), G:! = Definition 12. Given a game g and an efficiency parameter (V, E2), G3 = (V, E3) be directed graphs where V is associated with the set of strategies S, and Ei is defined as follows: (s, q) E El iff 171 (s, q) 3 t; (s, q) E E2 iff Ut (s, q) = t; (s, 4) E E3 iff UI (s, 4) < t. Given the above-mentioned graphs which are built based on the game g and the t, we can show the connection between stable social laws and standard efficiency parameter graph-theoretic concepts: t, the corresponding graphs Theorem 13. Given a game g and an efjiciency parameter GI, G2, G3 sutisfy the following: a stable social law for g exists #there is a subset V’ of the nodes of the related graphs, such that V’ is a clique in G 1, a dominating set in G3, and all nodes in V’ are nonisolated, relative to V’, in G2. Proof. Assume prohibiting by the requirement requirement requirement that V’ satisfying the above properties exists; one can easily check that by all strategies in V - V’ we get a stable social law. The efficiency is guaranteed from Gt , and the fact that no deviation is rational from G3. The fact that no allowed action can be ignored from G2. If there exists a stable social law then a payoff greater regardless of the (allowed) actions selected; to t should be guaranteed that the nodes associated with the allowed actions constitute a clique in Gt . Similarly, since no deviation set in G3. In addition, since there is rational than or equal this implies these nodes should correspond to a dominating is guaranteed by the is guaranteed by the 14 At Tennenholtz /Artificial Intelligence 102 (1998) I-20 is no reason to consider behaviors which are inferior that no node which corresponds to an allowed strategy would be isolated in G2. q to others in a stable social law we get The above theorem supplies an additional graph-theoretic theorems refers to games which are a combination of stable social laws. A further look at such representations general existence agent encounters sum games. The importance of such type of games is obvious; to agree and obtain “reasonable payoff” or to “fight” for “high payoff” obtaining “low payoff”. These basic games are formally defined as follows: for stable social laws. One interesting general understanding of the notion enables us to prove additional type of multi- and zero- they allow agents either taking the risk of of pure coordination Definition 14. Assuming without 0, a symmetric game g is a mixed coordination-competition satisfy: loss of generality that the efficiency parameter t equals game, if the utility functions (1) Ur(s,s) =Oforeverys (2) Ur(s, q) > 0 iff Ur (q, s) < 0 for every s, q E S. E S. games is that they can be An interesting point about mixed coordination-competition ,??) the nodes of G = (v, represented by a single graph, 6, which is defined as follows: to the different strategies, and the set of edges l? is defined as follows: (s, t) E I? correspond iff Ul (s, t) < 0. Given this graph structure, we can prove the existence of stable social laws for an interesting class of encounters: Theorem 15. Given a mixed coordination-competition ?? has a sink or is 2-colorable then an appropriate stable social law exists. game g, ifthe corresponding graph (i.e., both agents will be required strategy as Proof. If there is a sink in the graph then we can choose the corresponding strategy). a convention then we can color the graph by red and blue and Otherwise, if the graph is 2-colorable two blue strategies will (for both agents). Clearly, prohibit all (and only) red strategies yield the desired payoff since the graph is 2-colorable. No deviation is rational since the graph has no sinks and neighbors of a red strategy should be blue (i.e., a deviation may result in a negative payoff). q to play only the corresponding to red strategy 8. Other qualitative equilibria The previous decision criterion observations a look at two other basic decision criteria, competitive the context of these decision criteria as well. sections have been concerned with qualitative the is the maximin decision criterion. As we have mentioned before, similar and results do hold for other decision criteria as well. In this section we take the minimax regret decision criterion, and the ratio decision criterion, and show how our previous study can be adapted to equilibria, where h4. Tennenholtz /Artzj?cial Intelligence 102 (1998) I-20 1.5 Definition 16. Let Si be a set of strategies available function of agent i . Given s E St, and q E S2, define to agent i, and let Ui be the utility ul(S,q,Sl)=~~ul(t,q)-ul(s,q). Given q E S1 and s E S2 define u2(4 s, S2) = z=&u2k, t) - u2(q, s>. The minimox regret valuefor agent 1 (respectively 2) is defined by m&S, maxqEs2 u 1 (s, q, Sl) (respectively min,,sZ max+s, to the corre- sponding minimax regret value is called a minimax regret strategy for agent i . uz(q, t, ST)). A strategy of agent i leading the following The mirdmax regret decision criterion for agent criterion idea. Given a set of available [38,41] which is a basic decision i, if the other strategies captures agent, j, would have known the actual strategy to be performed by agent i then it could choose a cclrresponding optimal strategy. The amount of regret of agent j when performing sj a strategy to agent j. For each strategy instead of performing this of agent j one can compute strategy; regret strategy. the maximal The intuition behind this decision rule is that the agent would not like to lose much relative to the case where it would have known the other agent’s action. :sj when agent i performs a strategy si is the lost obtained by performing the maximal regret this agent may have while performing the optimal strategy against si available the strategy which minimizes regret is the minimax A related decision computer [44], is similar theoretical the AI literature we consider obtained by the corresponding these payoffs. the ratio between rule, the competitive science literature ratio decision rule, which [49], and which has been recently discussed regret decision to the minimax the payoff obtained by a particular optimal one, instead of considering rule; in this decision is popular in the in rule strategy to the payoff the difference between The definition of a useful social law remains as in the previous section, but the definition social laws and of stable social laws will be based on minimax regret or of quasi-stable ratio respectively. Hence, an agent may deviate from the prescribed social law competitive regret (or to a competitive ratio) value which is if it has a strategy which leads to a minimax lower than the one obtained by conforming to the law. The rationale of the related settings is that the designer may wish to guarantee a particular payoff for the agents, but an agent may not be risk-averse and might use decision criteria such as the minimax regret or the its action. competitive ratio while selecting As it turns out, social laws are more stable than simple conventions regret or the competitive adopt the minimax of the proof of Theorem 6. If the agents are required minimax regret value for an agent who considers deviating Similar results are obtained whenever each agent is required However, values of both C and D (2) are lower than the maximal we get a stable social law. A similar result can be obtained ratio decision criterion. if the agents are allowed to perform also when the agents the game matrix the action A, then the is obtained by the action C. to stick to a particular action. regret regret values of A and B (l), and for the case of the competitive to perform “only A or B” then the maximal ratio decision rules. Consider 16 M. Tennenholtz /Art$cial Intelligence 102 (1998) I-20 for risk-averse The above discussion to the case of minimax agents, can be obtained shows that the basic results obtained ratio is treated similarly. The payoffs results obtained regret and competitive ratio is the following one. For ease of exposition, we present to the case of minimax to extend Theorem 9 and its proof in the context of qualitative equilibria also in other contexts of qualitative decision-making. As it turns out, the computational in the case of maximin can also be extended ratio. The key idea which enables regret and competitive it for the case of minimax regret; the case of competitive in the t (i.e., high), and -t proof of Theorem 9 can be either 0 (i.e., satisfactory), (i.e., low). In order to have a similar proof in the context of minimax regret we will change the negative payoffs from -t regret of the minimax strategies which are not part of the law mentioned in the proof of Theorem 9 will be at to the law the agents will have a regret of at most t; this least 2t, while by conforming in our modification reduction. The other details of the reduction and proof of Theorem 9 remain as in the case regret of muximin. A modification of the proof of Theorem 10 to the context of minimax is quite straightforward restrictions on the strategies of agent 1, but when collecting careful to gather only the strategies which minimize corresponding can be proved for the case of minimax the strategies of agent 2 we have to be the maximal regret of agent 2 given the restriction on the strategies of agent 1. Having this observation, Theorem 10 as well. In this case we still enumerate the stability of the laws prescribed (i.e., very low). Given in order to guarantee this modification, regret as well. the possible is needed to -2t 9. Discussion In this work we have introduced a theory of stable social laws, or qualitative equilibria, for qualitative decision makers. Our work bridges some of the gap between work on in game theory and AI. Social Artificial Social Systems and work on conflict resolution laws have been shown to be a basic and useful of multi-agent systems [4,5,12,42,45,47,57]. However, the stability of social laws in a system of rational laws for agents has been neglected artificial agent societies by considering so far. This work extends previous work on social stable social laws for multi-agent tool for the coordination encounters. Two major lines of research related to our work are work in the field of game theory and [DAI]. Related work on rational deals work in the field of Distributed Artificial Intelligence to game theory. in DA1 (e.g., [37,51,62]) can be viewed as contributions and negotiations A very interesting property of this work is that it considers deals among rational agents who will not deviate from agreed-upon deals. to In difference to this assumption, our work is concerned with agents who will deviate from agreed-upon deals if they have a rational to incentive computer science. This is also true for its (somewhat systems. In fact, work in software engineering for the imposition in distributed systems [42,43]. The idea in this work is that a desired behavior of protocols the of an agent should be guaranteed regardless of the behavior of other agents (obeying the different specifications which may be satisfied (i.e., the corresponding to do so. The safety level kind of reasoning/analysis has used a social laws paradigm implicit) use in multi-agent is not new of course law). Naturally, lo This is not to say that other assumptions are not treated by the DA1 literature; see, for example [53]. M. Tennenholtz /Artificial Intelligence 102 (1998) l-20 17 incentive A central notion in various settings rational conventions that there is no rational in games; an equilibrium to the AI and DA1 literature systems, can be captured by maximin-like Much work in game theory has been concerned with devising as long as other agents stick to it. The notion of an equilibrium sets of goals/tasks which may be obtained) by each agent might be of different quality, payoffs. In this case the performance guarantee, which can be captured by corresponding analysis. that is a crucial factor in computerized for joint strategy its own situation. More specifically, much work in game for an agent to deviate from the has been (e.g., [61]), as part of a general into the AI context in this regard is the notion of a rational literature. Most work in game theory has a group of rational agents; a rational agent may deviate from a prescribed if this deviation will improve theory [25,38,48] has been devoted to the study of equilibrium will have the property equilibriurn adopted and important attempt to introduce social and organizational metaphors [14,16,18,:21,24,28,35,36,39,58]. agent adopted from the decision/game associated This is not however the usual way a rational agent is viewed in the AI literature, such as in work on conditional planning and reasoning representalion which are different revision on qualitative decision in mainstream game theory in the recent years. Several works, gets increasing [3,6,32,40], solution including in which agents attempt to get closer to a safety level of a game. In the related concepts, work an agent is not able to observe the utility function of the other agents (although he may be familiar with the related strategies). Although one way to address the related issue is by using the theory of types developed by Harsanyi [33], the use of safety level analysis in such settings is a natural approach. Notice that our work may fit nicely also with the assumption [22,29,50,52,60]. Moreover, much of the field of knowledge is concerned with qualitative notions of decision making, this is true for work in belief [30], qualitative physics [23], as well as for work the notion of a rational agent with the notion of expected utility maximization. theory [8,11,15,19,38,59]. Work on safety level reasoning/analysis that each agent knows only its utility function. [1,34], are concerned with long-run from expected utility maximization; and more recently [26], nonmonotonic reasoning attention theory (and equilibria of the utility function ,a direct comparison between in mixed strategies) discussed are different (see the discussion One may wish to explore the connections between the notion of stable social laws and the in game theory. these concepts seems quite problematic. This is for maximin agents and for is Section 4, as well as [lo]). to an agent is notion of mixed strategies However, due to the fact that the interpretations expected utility maximizers Notice thar in our context the actual selection among the strategies available modelled als a nondeterministic refers to parameters which might be unknown which may change from time to time. One may however wish to find some functional connections between mixed strategies and stable social laws, e.g., a stable social law may be the support of a mixed strategy equilibrium. Unfortunately, we were not able to prove or sets of strategies rather disprove such a claim. On the other hand, the idea of considering [31]. than a mixed strategy in equilibrium The restriction rather than to a set of strategies is a basic idea in the work of Minsky on social rules pointing to say that the enforcement of a in the context of software engineering is consistent with the theory of social situations (i.e., prohibiting choice rather than a probabilistic one. The nondeterminism to the designer and to the other agents and to a probabilistic mixture some of the strategies) [42,43]. Needless 18 &I. Tennenholtz /Art$icial Intelligence 102 (1998) l-20 social law is much more practical that coin flippings can not be usually observed by an outside observer. than the enforcement of a mixed strategy, due to the fact Using a game-theoretic terminology, in this work we developed an equilibrium for qualitative decision makers, and in particular theory and results can therefore be interpreted both as an extension Social Laws presented discrete/qualitative between in the AI literature, as well as a contribution for risk-averse decision/game these fields. theory. We hope it can lead to further cross-fertilization agents theory [9,19,38]. Our to the theory of to the foundations of Acknowledgements I wish to thank the participants of the inter-disciplinary systems seminar at the Technion, especially Dov Monderer and Ron Holzman, discussions on the concepts discussed also to Nathan Linial and Amir Pnueli for their comments. game theory and multi-agent for useful in this paper and their interpretation. Special thanks References [l] P. Auer, N. Cesa-Bianchi, Y. Freund, R.E. Schapire, Gambling the adversial multi- in: Proceedings 36th Annual Symposium on Foundations of Computer Science, 1995, in a rigged casino: armed bandit problem, pp. 322-33 1. [2] R. Aumann, Perspectives on bounded rationality, in: Prceeedings 4th Conference on Theoretical Aspects of Reasoning about Knowledge, Pacific Grove, CA, 1991, pp. 108-117. [3] A. Banos, On pseudo games, The Annals of Mathematical Statistics 39 (1968) 1932-1945. [4] 0. Ben-Yitzhak, M. Tennenholtz, On the synthesis of social laws for mobile robots: a study in artificial social systems (Part I), Computers and Artificial Intelligence 14 (1997). [5] 0. Ben-Yitzhak, M. Tennenholtz, On the synthesis of social laws for mobile robots: a study in artificial social systems (Part II), Computers and Artificial Intelligence, to appear. [6] D. Blackwell, An analog of the minimax [7] A.H. Bond, L. Gasser, Readings theorem for vector payoffs, Pacific J. Mathematic 6 (1956) l-8. in Distributed Artificial Intelligence, Ablex Publishing Corporation, Norwood, NJ, 1988. [S] C. Boutilier, Toward a logic for qualitative decision theory, in: Proceedings 4th International Conference on Principles of Knowledge Representation and Reasoning, Bonn, Germany, 1994, pp. 75-86. [9] R. Brafman, M. Tennenholtz, On the foundations of qualitative decision theory, in: Proceedings AAAI-96, Portland, OR, 1996. [IO] R. Brafman, M. Tennenholtz, Axiom systems for qualitative decision criteria, in: Proceedings AAAI-97, Providence, RI, 1997. [ll] R. Brafman, M. Tennenholtz, Modeling agents as qualitative decision-makers, Artificial Intelligence 94 (1997), 217-268. [12] W. Briggs, D. Cook, Flexible social laws, in: Proceedings 14th International Joint Conference on Artificial Intelligence (IJCAI-95), Montreal, Que., 1995, pp. 688-693. [13] P. &loud, W. Choi, J.-C Latombe, C. Le Pape, M. Yim, Indoor automation with many mobile robots, Japan, 1990. IEEE International Workshop on Intelligent Robots and Systems, Tsuchiura, Proceedings in: [14] P.R. Cohen, H.J. Levesque, Teamwork, Nous 25 (4) (1991). [15] A. Darwiche, M. Goldazmidt, On the relation between kappa calculus and probabilistic in: (UAI-94), Seattle, WA, 1994, pp. 145- reasoning, Proceedings 10th Conference on Uncertainty 153. in Artificial Intelligence [16] R. Davis, R.G. Smith, Negotiation as a metaphor for distributed problem solving, Artificial Intelligence 20 (1) (1983) 63-109. hf. Tennenholtz /Artificial Intelligence 102 (1998) I-20 19 [ 171 Y. Demazeau, J.P. Muller, Decentralized AI, North-Holland/Elsevier, [ 181 J. Doyle, A society of mind: multiple perspectives, 1990. Joint Conference on Artificial Intelligence reasoned assumptions, and virtual copies, in: Proceedings (IJCAI-83) Karlsruhe, Germany, 1983, pp. 30% 8th Intemational 314. [19] D. Dubois, H. Prade, Possibility theory as a basis for qualitative decision Intematlonal Joint Conference on Artificial Intelligence theory, (IJCAI-95) Montreal, Que., 1995, pp. 1924-1930. in: Proceedings 14th [20] E.H. Durfee, J. Lee, PJ. Gmytrasiewicz, Overeager reciprocal rationality and mixed strategy equilibiria, in: Proceedings AAAI-93, Washington, DC, 1993, pp. 225-230. [21] E.H. Durfee, V.R. Lesser, D.D. Corkill, Coherent cooperation among communicating problem solvers, IEEE Trans. Comput. 36 (1987) 1275-1291. [22] 0. Etzioni, S. Hanks, D. Weld, D. Draper, N. Lesh, M. Williamson, An approach information, &R-921, Cambridge, MA, 1992, pp. 115-125. in: Proceedings 3rd Conference on Principles of Knowledge Representation to planning with incomplete and Reasoning [23] K.D. Forbus, Qualitative process theory, Artificial Intelligence 24 (1984) 85-168; also in: D. Bobrow (Ed.), Qualitative Reasoning about Physical Systems, The MIT Press, 1985. [24] MS. Fox, An organizational view of distributed systems, IEEE Trans. Systems Man Cybemet. 11 (1981) 70-80. [25] D. Fudenberg, [26] P. Gardcnfors, Belief Revision, Cambridge University Press, 1992. [27] M. Gamy, D. Johnson, Computers and Intractability-A J. Tirole, Game Theory, MIT Press, 1991. Guide to the Theory of NP-Completeness, W.H. Freeman and Company, 1979. [28] L. Gassier, Social knowledge and social action: Heterogeneity Joint Conference on Artificial Intelligence in practice, (IJCAI-93), Chambery, France, 1993, pp. 751-757. in: Proceedings 13th International [29] M.R. Gmenesereth, I.R. Nourbakhsh, Time saving tips for problem solving with incomplete information, in: Proceedings AAAI-93, Washington, DC, 1993. (Ed.), Readings [30] M.L. Ginsberg in Nonmonotonic Reasoning, Morgan Kaufmann, 1987. [31] J. Greenberg, The Theory of Social Situations: An Alternative Game-Theoretic Approach, Cambridge University Press, 1990. [32] J. Hannan, Approximation to bayes risk in repeated play, in: M. Dresher, A.W. Tucker, P. Wolfe (Eds.), to the Theory of Games, Vol. III, Annals of Mathematics Studies 39, Princeton University Contrib~Jtions Press, 1957, pp. 97-139. [33] J.C. Hasanyi, Games with incomplete information played by bayesian players, parts 1, u, m, Management Science 14 (1967) 159-182. [34] S. Hart, A. Mas-Colell, A simple adaptive procedure leading to correlated equilibrium, Discussion paper 126, Center for Rationality and Interactive Decision Theory, Hebrew University, 1997. [35] T. Ishida, M. Yokoo, L. Gasser, An organizational approach to adaptive production systems, in: Proceedings AAAI-90, Boston, MA, pp. 52-58. [36] N.R. Jennings, Controlling cooperative problem solving in industrial multi-agent systems using joint intentions, Artificial Intelligence 75 (1995) 195-240. [37] S. Kraus, J. Wilkenfeld, The function of time in cooperative negotiations, in: Proceedings AAAI-91, Anaheim, CA, pp. 179-184. [38] R.D. Lute, H. Raiffa, Games and Decisions-Introduction and Critical Survey, John Wiley, 1957. [39] T.W. Malone, Modeling coordination in organizations and markets, Management Science 33(10) (1987) 1317-1332. [40] N. Megiddo, On repeated games with incomplete information played by nonbayesian players, Intemat. J. Game Theory 9 (1980) 157-167. [41] J. Milnor, Games against nature, in: R.M. Thrall, C.H. Coombs, R.L. Davis (Eds.), Decision Processes, John Wiley, .1954. [42] N.H. Minsky, The imposition of protocols over open distributed systems, IEEE Trans. Software Engineering 17 (2) (1991) 183-195. [43] N.H. Minsky, Law-governed [4-l] D. Monderer, M. Tennenholtz, Dynamic nonbayesian decision-making, systems, Software Engineering J. (September 1991) 285-302. J. Artif. Intell. Res. 7 (1997) 231- 248. 20 M. Tennenholtz /Art@icial Intelligence 102 (1998) I-20 [45] Y. Moses, M. Tennenholtz, Artificial social systems, Part I: basic principles, Technical Report (X90-12, Weizmann Institute (1990). [46] Y. Moses, M. Tennenholtz, Artificial social systems, Computers and Artificial Intelligence 14 (6) (1995) 533-562. [47] S. Onn, M. Tennenholtz, Determination of social laws for agent mobilization, Artificial Intelligence 95 (1997) 155-167. [48] G. Owen, Game Theory, 2nd ed., Academic Press, 1982. [49] C.H. Papadimitriou, M. Yannakakis, Shortest paths without a map, in: Proceedings 16th International Colloquium on Automata, Languages and Programming, [50] M.A. Peot, D.E. Smith, Conditional nonlinear planning, Planning Systems, 1992, pp. 189-197. 1989, pp. 61&620. in: Proceedings 1st International Conference on Al [51] J.S. Rosenschein, M.R. Genesereth, Deals among rational agents, in: Proceedings 9th International Joint Conference on Artificial Intelligence (IJCAI-85), Los Angeles, CA, 1985, pp. 91-99. [52] S. Safra, M. Tennenholtz, On planning while learning, J. Artif. lntell. Res. 2 (1994) 111-129. [53] T.W. Sandholm, V.R. Lesser, Equilibrium analysis of the possibilities of unenforced exchange Joint Conference on Artificial Intelligence in multiagent (IJCAl-95), Montreal, systems, in: Proceedings 14th International Que., 1995, pp. 694701. [54] L.J. Savage, The Foundations Dover, New York, 1972. of Statistics, John Wiley, New York, 1954. Revised and enlarged edition, [55] L. Shapley, Game theory, Lecture Notes, Mathematics Dept., UCLA, 1990. [56] Y. Shoham, M. Tennenholtz, On traffic Planning Systems (AIPS-92), 1992. laws for mobile robots, in: Proceedings 1st Conference on Al [57] Y. Shoham, M. Tennenholtz, Social laws for artificial agent societies: off-line design, Artificial Intelligence 73 (1995) 231-252. [58] H.A. Simon, The Sciences of the Artificial, The MIT Press, 1981. and evaluation of preferences [59] S.W. Tan, J. Pearl, Specification on Principles of Knowledge Representation International Conference Germany, 1994, pp. 530-539. under uncertainty, 4th and Reasoning &R-94), Bonn, in: Proceedings [60] D.H.D. Warren, Generating conditional plans and programs, in: Proceedings Summer Conference on Al and Simulation of Behavior, Edinburgh, 1976. [61] M.P. Wellman, A market-oriented programming environment and its application to distributed multicom- modity flow problems, J. Artif. lntell. Res. 1 (1993) l-23. J.S. Rosenschein, A domain Joint Conference on Artificial Intelligence [62] G. Zlotkin, International theory for task oriented negotiation, (IJCAI-93), Chambery, France, 1993, pp. 416422. in: Proceedings 13th 