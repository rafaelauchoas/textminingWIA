Artificial Intelligence 117 (2000) 231–253Robust logics ILeslie G. Valiant 1Division of Engineering and Applied Sciences, Harvard University, Cambridge, MA 02138, USAReceived 14 October 1998AbstractSuppose that we wish to learn from examples and counter-examples a criterion for recognizingwhether an assembly of wooden blocks constitutes an arch. Suppose also that we have prepro-grammed recognizers for various relationships, e.g., on-top-of.x; y/, above.x; y/, etc. and believethat some possibly complex expression in terms of these base relationships should suffice to approx-imate the desired notion of an arch. How can we formulate such a relational learning problem soas to exploit the benefits that are demonstrably available in propositional learning, such as attribute-efficient learning by linear separators, and error-resilient learning?We believe that learning in a general setting that allows for multiple objects and relations in thisway is a fundamental key to resolving the following dilemma that arises in the design of intelligentsystems: Mathematical logic is an attractive language of description because it has clear semanticsand sound proof procedures. However, as a basis for large programmed systems it leads to brittlenessbecause, in practice, consistent usage of the various predicate names throughout a system cannotbe guaranteed, except in application areas such as mathematics where the viability of the axiomaticmethod has been demonstrated independently.In this paper we develop the following approach to circumventing this dilemma. We suggest thatbrittleness can be overcome by using a new kind of logic in which each statement is learnable.By allowing the system to learn rules empirically from the environment, relative to any particularprograms it may have for recognizing some base predicates, we enable the system to acquire a setof statements approximately consistent with each other and with the world, without the need for aglobally knowledgeable and consistent programmer.We illustrate this approach by describing a simple logic that has a sound and efficient proofprocedure for reasoning about instances, and that is rendered robust by having the rules learnable.The complexity and accuracy of both learning and deduction are provably polynomial bounded.(cid:211) 2000 Elsevier Science B.V. All rights reserved.I This research was supported in part by grants NSF-CCR-95-04436, NSF-CCR-98-77049, ONR-N00014-96-1-0550, and ARO-DAAL-03-92-G-0115. A preliminary version of this paper appeared in Proc. 31st ACMSymposium on Theory of Computing, Atlanta, GA, May 1999, pp. 642–651.1 Email: valiant@deas.harvard.edu.0004-3702/00/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 0 0 ) 0 0 0 0 2 - 32000 Elsevier Science B.V. All rights reserved.232L.G. Valiant / Artificial Intelligence 117 (2000) 231–253Keywords: Learning; Reasoning; Deduction; Soundness; Robustness; Binding problem; Learning rules;Learning relations; PAC learning; PAC semantics1. IntroductionAccording to Aristotle “every belief comes either through syllogism or from induc-tion” [3]. Computational systems that aspire to exhibit some characteristics of intelligenceneed to manipulate beliefs about the world. It is reasonable to ask, therefore, how usefulAristotle’s dictum is for the construction of such systems. Our purpose here is to arguethat the duality expressed by the dictum is fundamental. In particular, we present a for-mal system that encapsulates this duality and, we believe, offers a vehicle for studying thetheoretical basis of such systems.The history of artificial intelligence can be interpreted as having revolved around thisduality from the beginning. Since the 1950s a dominant paradigm, advocated particularlyby McCarthy [28], has been that knowledge should be programmed into systems in auniform logical language as a set of rules, and that logical inference procedures suchas syllogisms be used to draw new inferences. As far as learning, Turing had alreadyspeculated earlier in 1950 that inductive learning would be used to build machines thatthink [41]. A few years later he pointed out the computational limitations of logicalreasoning alone [42].In the last forty years much progress has been made both in machine learning aswell as in computational logic. Nevertheless, the currently dominant theories of the twophenomena of inductive learning, and of logical reasoning are largely disparate, the notableexception being the area of inductive logic programming [30].The purpose of this paper is to suggest a formal system that reconciles principleddeduction, a characteristic of logic, with robustness, a characteristic of learning. Moregenerally, it encompasses learning and reasoning in a integrated way and retains thesomewhat different but crucial benefits that each has to offer.The particular benefits of mathematical logic that we wish to retain are the existenceof a clearly defined semantics for each statement, and the existence of proof proceduresthat enable new statements to be derived. In particular, the well defined semantics makespossible proof procedures that are sound: new statements that are derived from truestatements are themselves true.The main benefits of learning that need to be retained are that it provides a mechanismby which knowledge can be acquired in fragments that may be incomplete, inconsistent orinaccurate, by a system that has no understanding either of its own current global state ofknowledge, or of a consistent language of description of the world.These benefits of learning are somewhat irreconcilable with standard logics, where therules have to be expressed in terms of a set of predicates with globally consistent meanings.Such enforced global consistency may be achievable in application areas that are knownto be amenable to axiomatization, such as much of mathematics. In other areas, such asthe world of “commonsense” knowledge, where no such axiomatizations have been found,this approach has led to systems that are “brittle”.The minimal requirements for what we shall call a robust logic are the existence of:L.G. Valiant / Artificial Intelligence 117 (2000) 231–253233(i) Rules to encode knowledge that allow for multiple objects and for relations amongthem.(ii) A well defined semantics for the rules.(iii) An inference procedure for applying rules to instances that is sound and polynomialtime.(iv) Polynomial time algorithms for learning the rules from examples.Standard predicate calculus suitably constrained, to Horn clauses, for example, satisfiesthe first three of these requirements. Part (iv) of our definition can be interpreted mostsimply as claiming that one can make a logic robust if one provides a means of evaluatingthe accuracy of any statement in it, independently of others, by an empirical process thathas access to raw data from the world.In this paper we describe one particular such robust logic. It arose from efforts to providetheoretical underpinnings for the neuroidal architecture that is described in a companionpaper [47]. It has some added benefits, therefore, that derive from that architecture:(v) The rules can be implemented on a fixed network that mirrors their modularitiesand dependencies, and the inference procedure can be executed naturally on thatnetwork.(vi) The classes of connective functions that are allowed include a class, namelylinear threshold functions, that has ideal learnability properties: there exist efficientlearning algorithms for it that are both attribute-efficient and also (according toexperimental evidence) error-resilient.The main departure from traditional logic is that the semantics used here is PACsemantics adopted from machine learning. This views inductive learning as a “compu-statistical” phenomenon: observations on the world provide empirical evidence about rulesthat hold generally in the world. The learner chooses from a space of possible rulesaccording to the weight of statistical evidence, while computational constraints makethis choice computationally feasible. This allows robust learning from inaccurate andinconsistent data to be accomplished and to be put on a rigorous foundation. Most basicallyit is assumed that at any instant the system has some set of primitive sensors, and that itsobservations of the world can be regarded as induced by a probability distribution D oversets of sensor readings. This distribution D may be arbitrarily complex, reflecting as it doesthe complexities of the world. In general the system will not need to know the details of Ddirectly. It will, instead, aim to deal with rules that are “simple truths” in the sense that theyhold in D, at least with high probability. A system based on this logic may be given rulesthat are false most of the time, but the system would have the capability of recognizing thisfact by making enough empirical observations.There exist alternative approaches that address aspects of learning and reasoningsimultaneously. We shall discuss some of these briefly in Section 4.The mechanisms that are needed for learning and reasoning in our particular robust logicare computationally efficient. Their complexity depends only polynomially on the numberof object variables, on the number of rules in the system, and on their length even when theyexploit recursion. The only exponential dependence is on the arity of the relations, whichwe shall assume to be bounded by a small constant. We believe that this set of requirements,which our system satisfies, is indispensable for any formal system to be viable as a basisfor computational intelligence.234L.G. Valiant / Artificial Intelligence 117 (2000) 231–2532. ScenesSInformally, the objects in our robust logic should be thought of as referring not directlyto entities in the world but, instead, to representations in an internal image that correspondsto the short-term or working memory of the system. The contents of this image is called ascene.Scenes are defined in terms of a pair .A; e</, where A is a set fa1; : : : ; ang of objects ortokens, and e< is a set of relations f eR1; : : : ; eRt g over the objects. The arity (cid:11).i/ of a relationeRi 2 e< is the number of its arguments. The set of relations in e< that have arity i is callede<i (cid:18) e<. Hence e< D<i where the union is over a set K of nonnegative integer values ofi. For simplicity we shall assume throughout that the sets A, e< and all the arities are finite,and define (cid:11) to be the maximum of the arities (cid:11).i/ for 1 6 i 6 t.A scene (cid:27) is a vector of length L D LA;e< DiDj (cid:0)1iD1tiD1 n(cid:11).i/. The n(cid:11).j / entries after the firstn(cid:11).i/ we regard as the j th group. These give the truth values of the j th relation eRjon each of the n(cid:11).j / combinations of (cid:11).j / objects that can be selected from the n objectsin A as the (cid:11).j / arguments of eRj . Thus if A D fa1; a2; a3g and eR1 has arity two, then thevector will have values for all the 32 D 9 entries eR1.a1; a1/; eR1.a1; a2/; : : : ; eR1.a3; a3/, aswell as for all the corresponding entries for eR2; eR3; : : : ; eRt , etc. Some fixed lexicographicordering is assumed within each group.PPPtiD1 n(cid:11).i/The values in the vector will be from the set f0; 1g. For the first entry in the aboveexample 1 would mean that R1.a1; a1/ is true, and 0 would mean that it is false. The set ofPsuch vectors for .A; e</ we shall denote by (cid:5)A;e< or (cid:5) for short. Clearly j(cid:5)j D 2tiD1 n(cid:11).i/.We also define the set (cid:5) $ of obscured scenes. In these the vector elements can takea third value $ that denotes that the corresponding relationship is obscured. There arej(cid:5) $j D 3such obscured scenes.We assume that the space (cid:5) of scenes for any .A; e</ has an associated a probabilitydistribution DA;e< over (cid:5) . In other words for any scene (cid:27) 2 (cid:5) the distribution specifiesa probability D.(cid:27) / that a scene drawn randomly from (cid:5) will be (cid:27) . Clearly such adistribution defines a probability for any condition on scenes. Thus D. eR1.a1; a2/ D 1/is the probability that a random scene drawn according to D has eR1.a1; a2/ D 1. It alsoeR1.x1; x2/, namely the sum of D.(cid:27) /attaches a probability to conditions such as 9x18x2over all (cid:27) for which this condition holds.When considering learnability it is useful to distinguish distributions D over (cid:5)A;e< thatare unrestricted from those that are symmetric under permutations of A. For any scene (cid:27) 2(cid:5)A;e< there exist nW (cid:0) 1 scenes, not necessarily all distinct, that can be obtained from (cid:27)by permuting the tokens a1; : : : ; an 2 A in some way. We define distribution D over (cid:5)A;e<to be symmetric if any two scenes that can be obtained from each other by permuting thetokens in this way have the same probability. Since our general intention is to regard A asa set of tokens with no structure we shall assume where not otherwise indicated that alldistributions D are symmetric. However, this restriction does not appear to be required forany fundamental purpose and our results apply equally to the asymmetric case, except thatthe bounds for learnability are larger.The interpretation of this general framework is as follows. The distribution D isdefined, in the spirit of PAC (probably approximately correct) learning, as imposed byL.G. Valiant / Artificial Intelligence 117 (2000) 231–253235and specifying a possibly arbitrarily complex world. The intelligent system needs to beable to have strategies or concepts that work in this complex world, but the theory of PAClearning suggests that these strategies or concepts can be often learned from examplesdrawn from D, without the system ever needing to describe D explicitly. The set A oftokens is intended to correspond to representations in an image internal to the system, asdiscussed further in [47].An important general point is that the logic is designed from the start to cope withpartial knowledge. The relation set e< is the space of base relations that the system canrecognize at the time in question. For any one scene the truth values of many of theserelations will not be explicitly available. In a real world room, for example, every object ismade of some material, but in a depiction of the room this information about the materialsmay not be available, or as we shall say, specified. We assume here that D imposes anatural distribution on what knowledge is specified and what is not. Consider the muchdiscussed unary relation that specifies whether an object is a penguin (e.g., [10]). We wantthat (cid:5) distinguish the three cases: true, false and unspecified. For several reasons it isadvantageous that the predicates in our logic have just the two values f0; 1g. In order toallow this in our implementation we expect that the relations are so defined that they encodethe third value “unspecified” using f0; 1g. A natural implementation would be to have twounary predicates penguin( ) and penguin(cid:3)( ) where penguin(cid:3).a1/ D 0 would mean thatthe scene does not specify whether a1 is a penguin. If the scene does specify whether ornot a1 is a penguin then penguin(cid:3).a1/ D 1 would hold and, in that case, penguin.a1/ D 1would denote that a1 is a penguin and penguin.a1/ D 0, that it is not. By having twobinary versions of each primitive predicate in this way an element of (cid:5) can effectivelyencode for each primitive predicate and each binding, whether in the scene it is true, falseor unspecified. Since scenes are drawn from a probability distribution D over this (cid:5) , aprobability distribution is imposed over which relation-binding combinations are specifiedand which are not.In other words it is acknowledged at the start that in natural situations only partialknowledge is usually available. The fact that learning takes place from situations of partialknowledge can then be offered as an explanation of why the results of PAC learning can beapplied effectively to situations of partial knowledge. This provides a principled approachto partial knowledge based on learning as suggested in [45,46]. In practice, it may be thatmost bindings of most base relations have an unspecified value. In that case, for the sakeof succinctness, it is advantageous to represent the scene by listing only those relations andbindings that are specified. This will ensure that the size of descriptions of scenes will beas economical as possible.We note that the notion of obscured vector elements described earlier is orthogonal tothis idea of unspecified vector elements. Once a scene is drawn from D its f0; 1g vectorelements will determine which relations and bindings are specified and which are not. Wecan subsequently for the purposes of analysis obscure or hide some arbitrary subset of thevector elements by replacing them with $ symbols, and so make the scene obscured. Forexample, when the system performs planning and wishes to evaluate the consequence of asituation, the system will construct scenes where the relations describing the situation areunobscured, but those relating to the consequences are obscured. The deduction processwill then evaluate the most likely values of the obscured relations.236L.G. Valiant / Artificial Intelligence 117 (2000) 231–253In the context of deduction we shall also distinguish between vector elements that aredetermined and those that are not. Initially an obscured element will be undetermined. Itbecomes determined once a deduction procedure has deduced a value for it.3. A robust logic3.1. SyntaxA rule is intended as a statement that in a precise sense that we describe below holdswith certainty or some probability for scenes drawn from D. Suppose that scenes aredefined for A D fa1; : : : ; ang and e< D f eR1; : : : ; eRt g. In describing rules we shall definea set of symbolic relations < D fR1; : : : ; Rt g where the arity of Ri is the same as that ofeRi . The role of Ri is to model the actual relation eRi . Thus, if in the rule set there is arule 8x R2.x/ (cid:17) R3.x/, then the intention is that the corresponding statement 8x eR2.x/ (cid:17)eR3.x/ should hold with high probability for scenes drawn from D. Also, suppose that in aparticular scene (cid:27) randomly drawn from D a certain given set of relations from e< hold withcertain bindings. Suppose further that these relations and bindings, when the corresponding< symbols replace the e< symbols, are used as premises for the rule set. We want that if itis deduced using the rules that R3.a2; a4/, for example, holds, then eR3.a2; a4/ should holdwith high probability for a randomly drawn scene for which the given set of relations andbindings hold. In other words we want that deductions made using the rules should leadto conclusions that are semantically true for randomly drawn scenes, at least with highprobability.To define the syntax of the rules, besides < and A we also need a set C of connectives,a set X of object variable names and some standard symbols. The set of connectives C DS1Ci is a set of functions where every f 2 Ci is a Boolean function f : f0; 1gi ! f0; 1g.iD1We shall choose C so as to have good learning properties. In particular there should beefficient error-resilient and attribute-efficient algorithms for learning its members. Linearthreshold functions are a prime example of such a class [4,5,7,26,48]. Attribute-efficiencymeans that the number of examples grows linearly in the number of relevant variables, butonly logarithmically in the irrelevant ones. This is important in the current context in whichwe envision that variables will be generated automatically in large numbers, for example,to represent relations with all possible bindings, but the number of available examples islimited.A rule q is of the form8x1; : : : ; xs 2 A Q.x1; : : : ; xs; (cid:27) / !(cid:2)(cid:0)fe1.Ri1 /; : : : ; e‘.Ri‘ /(cid:1)(cid:17) Ri0.x1; : : : ; xs/(cid:3);where x1; : : : ; xs 2 X; f 2 C‘, and for 0 6 j 6 ‘; Rijis an independently quantified expression (IQE) of the form2 <. Further, for 1 6 j 6 ‘; ej .Rij /41yj;1; : : : ; 4kj yj;kj2 A Rij .zj;1; : : : ; zj;mj /;where mj is the arity (cid:11).ij / of Rij , each 4h 2 f9; 8g for 1 6 h 6 kj , each yj;h 2 X, eachg (cid:18) Xzj;h 2 fx1; : : : ; xsg [ fyj;1; : : : ; yj;kjL.G. Valiant / Artificial Intelligence 117 (2000) 231–253237D yj2;h2 then j1 D j2: Also Q, the precondition, is an arbitrary predicateand if yj1;h1whose value depends on the scene (cid:27) and the binding (cid:25) : fx1; : : : ; xsg ! A in question. Itsvalue will depend on which (relation, binding) pairs have values that are unobscured in theinput (cid:27) , or have been determined by deduction from that input.Allowing the precondition Q adds to the generality of the framework. For example itmay be that we have access to examples of a concept, but only from a certain subdomainthat we can characterize by Q. In that case learning a rule with such a precondition isappropriate, especially if there is reason to believe that the concept has no simple definitionover a broader domain. Much of our analysis is unchanged, however, if we have the totalprecondition Q (cid:17) True, in which case we shall for brevity suppress that precondition.We impose no general restrictions on Q of learnability or representability. Even if thepreconditions are programmed by a human they may have a useful role. Some naturalrestrictions that would aid mechanical use and warrant further investigation are that Q canbe expressed succinctly or computed easily in terms of < and C, that Q be symmetric (i.e.,invariant under permutations on fa1; : : : ; ang/, and that the truth of Q can be derived withina given set of rules.A simple example of a rule is(cid:2)(cid:0)8x1; x2 2 ATh29y1R1.x1; x2; y1/; 9y2R2.x1; y2/; 9y38y4R3.x2; y3; y4/(cid:17) R4.x1; x2/(cid:3);(cid:1)where the total precondition Q (cid:17) True has been suppressed for brevity. The function Th2is the threshold two function of three arguments, defined to be true whenever at least twoof its arguments are true. The expression on the left of the (cid:17) sign is called the left-handside of q, and that on the right the right-hand side. These are sometimes abbreviated toLHS.q/ and RHS.q/.The important constraint in the definition and the example is that the constituentquantified expressions in LHS.q/ are quantified over mutually disjoint sets of variablenames. In the example these sets are: fy1g, fy2g and fy3; y4g. The significance of theseconstraints is that whenever f .e1; : : : ; e‘/ is evaluated on a scene (cid:27) for a binding(cid:25) : fx1; : : : ; xsg ! A, the value of each ei can be evaluated independently of the others—the values of the y variables that make ei true have no bearing on the y variables that makeej true for j 6D i. This notion is equivalent to that realized by connection bindings in [47].This constraint implies, for example, that the relationship expressed by the predicatecalculus statement:(cid:0)(cid:1)grandfather.x; y/ (cid:17) 9zfather.x; z/ ^ parent.z; y/cannot be expressed directly as a single rule if < contains father and parent, but not theirconjunction. The following pair of rules would, however, suffice:8x; y; z 2 A(cid:2)8x; y 2 A(cid:2)(cid:3)father.x; z/ ^ parent.z; y/ (cid:17) grandfather(cid:3).x; y; z/ (cid:17) grandfather.x; y/9z grandfather.x; y; z/(cid:3):(cid:3);The significance of the disjointness constraint is, therefore, the following. For reasonsof computational economy we want to minimize the costs of enumerating bindings. Oneapproach to this is to have relations that use the minimal number of arguments that suffice.238L.G. Valiant / Artificial Intelligence 117 (2000) 231–253The “grandfather” predicate needs only two if whenever we use it in higher level reasoning,knowledge of the identity of the person z from the intermediate generation is irrelevant.On the other hand, in recognizing the occurrence of the grandfather relationship in thefirst place we may need to establish the existence of such an intermediate person. Henceat another level we need a relation having this third argument. The above formulationacknowledges both of these realities as economically as possible.This simple example illustrates that our general approach relies heavily on theassumption that knowledge can be represented with binding modularity in terms ofrelations of small arity. As a second example consider the notion of a dining room. Thismay be defined in terms of chairs and tables and some relationships amongst them. In turn,a chair may be defined in terms of its constituent parts and the relationships among those.Binding modularity asserts that the arity of the relations needed can be kept small becausereferences to the identities of the parts needed to define the lower level notion, the chair,are redundant when describing the higher level notion of a dining room.A further issue regarding variable bindings is whether any inequality constraints areimplied or can be imposed. In particular is it implied that the members of fx1; : : : ; xsgg have to bind to distinct member of A or not? In our formulation anyor fyj;1; : : : ; yj;kjspecific combination of inequality constraints can be made. Thus further notation can beintroduced to specify, for example, that x1 and x2 must map to distinct tokens, but x3 neednot be distinct from either. The only general prohibition is the one stated earlier, that fordistinct values j1; j2 the bindings of corresponding yj1;h1 and yj2;h2 variables can in noway constrain each other.The following observation will be used throughout.Fact 3.1. For any relation R of arity (cid:11) and any independently quantified expression e.R/,the value of e.R/ can be computed in O.n(cid:11)/ steps given the values of R for each of the n(cid:11)bindings of its (cid:11) arguments to A.Proof. If in the definition of e.R/ we have an order of quantification.41y1; 42y2; : : : ; 4(cid:11)y(cid:11)then we construct the following rooted game tree of depth (cid:11). Each node of the tree atdistance i from the root corresponds to a substitution fy1; : : : ; yig ! A. Each such nodehas edges to level i C 1 nodes corresponding to this substitution, but extended by each ofthe possible substitutions of yiC1 into A. Thus the leaves of the tree are all at depth (cid:11) andcorrespond to each of the possible substitutions fy1; : : : ; y(cid:11)g ! A.We now label each leaf by the value of R for the substitution specified by the leaf.We then work up starting from the leaves and attach Boolean values to each node untilthe root is reached. The value attached to the node corresponding to a fixed substitutionfy1; : : : ; yig ! A will be the truth value of4iC1yiC1; : : : ; 4(cid:11)y(cid:11)R. /;where R. / denotes the relation R when the given fixed substitution has been made. It iseasy to verify by induction that to label a node at distance i (cid:0) 1 from the root where 4i D 9,L.G. Valiant / Artificial Intelligence 117 (2000) 231–253239one takes the disjunction of the labels of its son nodes, and where 4i D 8 one takes theconjunction of the labels of its son nodes.Clearly, a similar procedure works if some inequality constraints are imposed such asy2 6D y1.Also, the procedure works if in the definition of e.R/ some arguments have fixed valuesin A, and quantification occurs only on the subset of remaining variables. 2We note that existential quantifications allow the above algorithm to successfully labelthe root node even in some cases when the relation R is not determined for some of thebindings (e.g., it corresponds to an obscured value in the input, and no deduction has yetbeen performed) and the corresponding leaves in the game tree have no labels. We shallsay that e.R/ is determined whenever the procedure succeeds in giving the root node avalid label. We note also that when we discuss deduction in Section 3.4 we shall entertainthe possibility that a fixed R with a fixed binding evaluates to both of the values 0 and 1, inwhich case the value is written as 0=1. The game tree evaluation procedure will be adaptedso that whenever this is the case, it will evaluate the consequences of both a 0 value andalso of a 1 value.To summarize, therefore, a leaf can have one of four values: 0,1, undetermined or 0=1.The labelling procedure can attach any of these four values to internal tree nodes also as itproceeds.When evaluating an expression e by means of the procedure of Fact 3.1 we shalltherefore output(i) undetermined if no value combination of the leaf values determines a 0 or 1 valuefor e,(ii) a 0 value if some combination determines 0, and none determines a 1,(iii) a 1 if some combination determines a 1 and none a 0, and(iv) 0=1 otherwise.An important note is that this process is monotone in the sense that once e is determined,subsequently changing an undetermined input value to determined, or a determined one to0=1 will never make e undetermined.The size of description kqk of a rule q will be the number of occurrences of relationsymbols in its definition. The size of description kSk of a set S of rules will be the sum ofkqk over all q 2 S. The size jSj of S will be the number of rules in S.A rule set S is acyclic if its graph G.S/ is acyclic, where G.S/ is defined in the followingmanner: The graph G.S/ is a directed graph G D .V ; E/ where V , the set of nodes, isthe set <, and E, the set of edges is a subset of < (cid:2) <. In particular, the directed edge.Ri; Rj / 2 E if and only if there is a rule in S that contains Ri on the left-hand side andRj on the right-hand side. We denote the class of acyclic rule sets by (cid:0) , and the class ofarbitrary rule sets by (cid:0) (cid:3). For (cid:11) D 1; 2; : : : we denote by (cid:0)(cid:11) and (cid:0) (cid:3)(cid:11) these classes restrictedto rule sets where the maximum arity of any relation is (cid:11).We allow more than one rule to share the same R 2 < on the right hand side. Thisallows for multiple definitions of R, possibly with different preconditions and dependingon different relation sets on the left hand side. Note that if two rules have the same R onthe right hand side and have some Ri in common on the left hand side then some edge in240L.G. Valiant / Artificial Intelligence 117 (2000) 231–253G.S/ will have arisen from more than one rule. Of course, multiple rules may give rise tomutually contradictory deductions.It will turn out that our results apply equally to general graphs as to acyclic ones. Theimportance of allowing general graphs is that recursive rules can then be expressed. Forexample the earlier expressions given can be adapted to:8x; y; z 2 A(cid:2)8x; y 2 A(cid:2)ancestor.x; z/ ^ parent.z; y/ (cid:17) ancestor(cid:3).x; y; z/(cid:3);9z ancestor(cid:3).x; y; z/ (cid:17) ancestor.x; y/(cid:3):The rules we have defined can be compared with Horn clauses in first order predicatecalculus. The implication sign has been replaced by equality, and conjunctions on theleft hand side have been generalized to wider classes of connectives, including linearthresholds, that can make learning more tractable and robust. On the other hand, forthe sake of controlling computational complexity some restrictions are imposed also.A restriction that is fundamental and shared, for example, with the datalog model fordatabases [43], is that the function symbols of predicate calculus are excluded in orderto prevent the proliferation of the objects that are quantified over. This restriction enablesthe complexity of the binding problem to be controlled. For example, if we had a constant“Napoleon” and a function “parent” then expressions of the form “parenti(Napoleon)”would refer to an unbounded number of individuals, namely the ancestors of Napoleon.Another difference is that instead of having constants to refer to individuals, we instead useunary predicates. Thus instead of the constant “Napoleon”, we have Napoleon.ai/, whichcorresponds to the token ai qualified by a unary relation, representing that individual.3.2. SemanticsIn the previous section we defined the syntax of rules and rule sets in terms of a triple <,A and C where < is a set of relations, A a set of tokens, and C a set of connective functions.Now, for any scene (cid:27) 2 (cid:5)A;e< and any binding (cid:25) : fx1; : : : ; xsg ! A, the rule q(cid:2)f8x1; : : : ; xs Q.x1; : : : ; xs; (cid:27) / !(cid:0)e1.Ri1 /; : : : ; e‘.Ri‘ /(cid:17) Ri0 .x1; : : : ; xs/(cid:1)(cid:3)can be examined for the truth values of each ej .Rij / and hence also of both the left-handside(cid:0)(cid:1)fe1.Ri1 /; : : : ; e‘.Ri‘ /;and the right-hand sideRi0 .x1; : : : ; xs/:We define the f0; 1g-valued functions lhs.q; (cid:27); (cid:25)/ and rhs.q; (cid:27); (cid:25)/ as follows: Theformer function lhs.q; (cid:27); (cid:25)/ D 1 if and only if binding (cid:25) makes f true on (cid:27) after thee< relations are substituted for the < relations. The latter function rhs.q; (cid:27); (cid:25)/ D 1 if andonly if eRi0D 1 on (cid:27) with binding (cid:25) .We can then define the false positive and false negative f0; 1g-valued error functionserr(cid:0).q; (cid:27); (cid:25)/ and errC.q; (cid:27); (cid:25)/ as follows: errC.q; (cid:27); (cid:25)/ D 1 if and only if: Q.(cid:25); (cid:27) / D 1,lhs.q; (cid:27); (cid:25)/ D 1 and rhs.q; (cid:27); (cid:25)/ D 0, and similarly err(cid:0).q; (cid:27); (cid:25)/ D 1 if and only if:L.G. Valiant / Artificial Intelligence 117 (2000) 231–253241Q.(cid:25); (cid:27) / D 1, lhs.q; (cid:27); (cid:25)/ D 0 and rhs.q; (cid:27); (cid:25)/ D 1. Note that since Q depends on thescene (cid:27) and the binding (cid:25) D fx1; : : : ; xsg ! A, we can with only slight abuse of notationexpress Q.x1; : : : ; xs; (cid:27) / as Q.(cid:25); (cid:27) /.Finally, we can define the probability that the rule q will predict false positives or falsenegatives on scenes (cid:27) drawn randomly from (cid:5) D (cid:5)e<;A according to distribution D, asfollows:erD.q/ D max(cid:25)X(cid:0)D.(cid:27) /err(cid:27)C.q; (cid:27); (cid:25)/ C err(cid:0).q; (cid:27); (cid:25)/(cid:1):We note that we are giving each scene (cid:27) its arbitrary probability as defined by D, butrestrict the sum to those (cid:27) that satisfy Q. Also, since we require small error for everybinding, we define the error measure as the maximum of the errors over all the s D n(cid:11).i0/(cid:0)bindings. Note that we can define analogously erD as erD above but omitting theerr(cid:0) and errC term respectively. As a summarizing simple measure of accuracy, however,we use erD and note that in the case that D is symmetric the maximization over (cid:25) in thedefinition can be replaced by the substitution of any fixed (cid:25) .CD, erDefinition. A rule q is "-accurate in D if and only if erD.q/ 6 ".3.3. LearnabilityThe goal of our logic is to provide a framework in which we can reason from knowledgethat is learned. Hence central to it is some minimal notion of learnability for rule sets.This minimal notion will capture the idea that if we have a complete specification of arule except for the identity of the connective f 2 C, then an approximation to f can belearned in the PAC sense from random examples of scenes (cid:27) 2 (cid:5) drawn according todistribution D. Clearly a complete specification requires specifications of the identities ofand the quantifiers for relations Ri0 ; Ri1 ; : : : ; Ri‘ . It also requires specifications for eachof the (cid:11).ih/ argument positions in Rih , if any, of the arguments x1; : : : ; xs of Ri0 that areto be substituted there. The remaining arguments are all distinct for the various values ofh .1 6 h 6 l). There may be additional inequality constraints in the specification.Definition. For a set of rules where each rule q is of the form8x1 : : : ; xs 2 A Q.x1; : : : ; xs; (cid:27) /!(cid:0)e1.Ri1/; : : : ; e‘.Ri‘ /f(cid:2)(cid:1)(cid:17) Ri0 .x1; : : : ; xs/(cid:3)(3.1)over <; C; A, consider learning algorithms that in unit time can obtain for any desiredbinding (cid:25) a scene randomly chosen from the distribution D restricted to scenes that satisfyQ.(cid:25); (cid:27) /. We say that a class of rules is PAC-learnable from scenes if there is a learningalgorithm that for any rule q of the form (3.1), for any " > 0; (cid:14) > 0 and any symmetricD, runs in time a fixed polynomial in 1="; 1=(cid:14); n and the size of description of q, andoutputs with probability at least .1 (cid:0) (cid:14)/ an f 0 2 C that makes the rule "-accurate whenf 0 is instantiated in place of f . [The oracle for Q.(cid:25); (cid:27) / may be called with an arbitraryrequested binding (cid:25) and will return an unobscured (cid:27) randomly chosen according to D242L.G. Valiant / Artificial Intelligence 117 (2000) 231–253from those satisfying Q.(cid:25); (cid:27) /. If Q.(cid:25); (cid:27) / is false for all (cid:27) or for all (cid:27) having non-zeroprobability in D, then an arbitrary f 0 may be returned.]In other words we will be seeking to learn a rule of a fixed form, such as the following:8x1; x2; x3 Q.x1; x2; x3; (cid:27) /(cid:2)!f .9y1R1.x1; x2; y1/; 9y2R2.x2; x3; y2// (cid:17) R1.x1; x2; x3/(cid:3):The algorithm will seek to find an f 0 that when substituted in place of f in this fixed formwill hold with high probability for random examples satisfying Q. Note that the restrictionof f to a fixed form ceases to be a true restriction if the enumeration el; : : : ; c‘ is a completeenumeration of all the base relations with all bindings, as we envisage to be viable if C islearnable attribute-efficiently.In the symmetric case we have the following.Theorem 1. If C is PAC-learnable as a class of Boolean functions by an algorithm Mfor which a number L.‘; "; (cid:14)/ of examples is sufficient to learn C‘ to accuracy " withconfidence 1 (cid:0) (cid:14), then for any < and A, any class of rules with constant arity over C, <and A is PAC-learnable from scenes. Also L.‘; "; (cid:14)/ examples suffice to learn to accuracy" with confidence 1 (cid:0) (cid:14) if D is symmetric.(cid:3)Proof. We assume that we have a rule8x1; : : : ; xs Q.x1; : : : ; xs; (cid:27) / !(cid:2)f(cid:0)e1.Ri1 /; : : : ; e‘.Ri‘ /(cid:1)(cid:17) Ri0 .x1; : : : ; xs/(3.2)and that full descriptions of eh.Rih / for 1 6 h 6 l are known, as is also the identity of Ri0 :Given a set of scenes (cid:27) 2 (cid:5)A;e< drawn according to D, the task of the learning algorithm isto derive an f 0 2 C‘ that when substituted for f in (3.2) will give a rule that with confidence1 (cid:0) (cid:14) is "-accurate. The constant arity bound ensures that, by Fact 3.1, the value of eacheh.Rih/ can be evaluated in polynomial time for any scene.Since D is symmetric it will suffice to learn with one fixed binding, e.g., (cid:25) (cid:3).xi/ D aifor 1 6 i 6 s. We shall assume, as is sufficient for the statement of the Theorem, that thealgorithm has access to a source of examples (cid:27) all of which satisfy Q.(cid:25) (cid:3); (cid:27) / D 1 for thechosen binding (cid:25) (cid:3). For each input scene (cid:27) we shall consider the truth value of eRi0 , and ofeach ej . eRij / for 1 6 j 6 ‘, when the substitution (cid:25) (cid:3) has been made in these expressions.This will give us a vector of l truth values as an input for f , and a Boolean value as output.By assumption the learning algorithm M for C can learn an f 0 2 C that is "-accuratewith confidence 1 (cid:0) (cid:14) from L.‘; "; (cid:14)/ examples in time polynomial in "(cid:0)1; (cid:14)(cid:0)1; ‘; and thesize of description f . But this is equivalent to saying that with confidence 1 (cid:0) (cid:14) the rule q 0that is learned (i.e., rule q with f 0 substituted for f ) has the property that:erD.q 0; (cid:25) (cid:3)/ DX(cid:0)D.(cid:27) /err(cid:27)C.q 0; (cid:27); (cid:25) (cid:3)/ C err(cid:0).q 0; (cid:27); (cid:25) (cid:3)/6 ":(cid:1)Since D is symmetric the quantity erD.q 0; (cid:25) (cid:3)/ is invariant under the choice of (cid:25) (cid:3). SinceeD.q/ is defined in (3.3) to be the maximum of erD.q; (cid:25)/ over all (cid:25) , we conclude thaterD.q 0/ 6 ". 2L.G. Valiant / Artificial Intelligence 117 (2000) 231–253243If D is not symmetric learnability can still be defined and the learning problem is notfundamentally more difficult. However, in general, one would then have to learn a distinctf 0(cid:25) for each distinct(cid:25) : fx1; : : : ; xsg ! A:The oracles for Q.(cid:25); (cid:27) / defined in the definition of PAC-learnability of rules provides forthe source of examples needed for each such (cid:25) . However, the sample complexity wouldpotentially increase by a factor of ns .The following is a brief discussion of the intentions behind the preconditions Q: Clearlypreconditions have a number of valuable uses. For example, it may be that a simplerule for, say, R.x/ exists or is known only for a certain subdomain Q. Alternatively, itmay be that a small number of subdomains cover most of the positive occurrences ofR, and distinguishing these contexts explicitly is the best way of encoding the relevantinformation. How constraining should the preconditions be allowed to be? If we regard thedistribution D as referring to a base domain Q0, then our definitions are intended, in thefirst instance, to refer to the case that the Q for each rule covers a significant part (i.e., atleast inverse polynomial) of D. If that holds then in our definition of PAC-learnability ofrules the assumption that the examples oracle has to produce examples that satisfy Q canbe eliminated, since we could instead simply discard examples that did not satisfy Q. Forany rule set it will be most convenient to define Q0 to be the union of the preconditionsof all the rules in the set, assuming that each rule does have a satisfactory precondition.Philosophically, one can hypothesize a universal precondition Q(cid:3) and a distribution D(cid:3)over that into which every Q0 and D can be embedded. In practice it appears to bepreferable to discuss the minimal Q0 and D that apply to a given rule set, rather thanthe universal Q(cid:3) and D(cid:3).As mentioned in an earlier section, it is an important fact that for C one can choose usefulclasses that are learnable attribute-efficiently: Since the number ‘ of arguments of f willgrow as n(cid:11) if all possible quantified expressions are used as arguments it will be desirablethat the sample complexity be smaller than this quantity. This is possible, for example, if Cis chosen to be Boolean disjunctions with few terms or Boolean functions defined by linearinequalities with small integer coefficients and few terms [26,48].We note that the exact number of possible quantified expressions can be written asfollows, if inequality constraints are not allowed: If Ri0 on the right-hand side has aritys then for any relation of arity (cid:12) 6 (cid:11) the number of expressions in which i arguments arequantified is 2is(cid:12)(cid:0)i. Summing this for i D 0; : : : ; (cid:12) gives .s C 2/(cid:12) .(cid:1)(cid:0)(cid:12)i3.4. Deduction: Soundness and completenessIn this section we discuss algorithms for making deductions about obscured scenes bymeans of a set S of rules that are to be thought of as capturing some relevant knowledge.We restrict ourselves to deduction algorithms that are efficient in the sense that they requireonly polynomial time. The other crucial property that is desired is that the deductionalgorithm be sound, in the sense that any conclusion reached should be true, at least withhigh probability, if the constituent rules were accurate.244L.G. Valiant / Artificial Intelligence 117 (2000) 231–253We shall use the following definitions:Definition. A deduction algorithm takes as input(i) a set S of rules with respect to some <; A, and C,(ii) a relation Ri 2 < that is the right-hand side of some q 2 S,(iii) a binding (cid:25) from the arguments of Ri to A, and(iv) a scene (cid:27) 2 (cid:5) $that of Ri with binding (cid:25) .e<A obscured by the replacement by $ of various values includingThe deduction algorithm outputs either a predicted f0; 1; 0=1g value for Ri on (cid:27) withbinding (cid:25) , or a special “nothing predicted” symbol.Note that this definition allows a deduction algorithm to output “nothing predicted” allthe time. In Section 3.4.3 we shall introduce the notion of completeness that will be usedto disallow misuse of this possibility.Definition. A deduction algorithm is polynomial time if it runs in time bounded by a fixedpolynomial in: the size of description kSk of the rule set S, the size of description of thescene (cid:27) , the size n D jAj of A, and the maximum computational complexity c.S/ of theconnectives from C appearing in S.Definition. A deduction algorithm is "-accurate on a rule set S and distribution D if forany Ri 2 < and (cid:25) , any predicted f0; 1; 0=1g value of Ri on binding (cid:25) is incorrect withprobability at most " on a scene (cid:27) drawn randomly according to D.In order to interpret this definition note that for any Ri and (cid:25) , if (cid:27) is drawn from D thenone of three things can happen:(a) there is a predicted value of Ri and (cid:25) that is incorrect (i.e., a value of 0=1 is alwaystaken as incorrect, while a 0 or 1 value is incorrect if it differs from eRi on (cid:25) and (cid:27) ),(b) there is a predicted 0 or 1 value that is correct, and(c) there is no predicted value.The above definition therefore insists that eventuality (a) occurs with probability at most ".It is instructive to subdivide (c) further into two subcases. In subcase (c1) someprediction would have been made if all the rules had the total precondition, but some of theactual preconditions were too restrictive to apply. In the second subcase (c2) no predictionwould have been made even if all the preconditions had been total. This latter subcase canarise for example, if some needed values are obscured in (cid:27) , or if the rules are such thatthey never have implications for Ri .Definition. A deduction algorithm is PAC-sound if (i) it is polynomial time and (ii) forsome polynomial p. /, for every D, for every " > 0, it is "-accurate for any rule set S inwhich each rule is p."=.kSkjAj//-accurate, where jAj is the number of elements of A, andkSk is the size of description of S.Note that while "-accuracy may be a weak requirement on rule sets S that rarely producepredictions, PAC-soundness when applied to procedures that are complete is a strong one.L.G. Valiant / Artificial Intelligence 117 (2000) 231–2532453.4.1. The acyclic caseWe now define the acyclic deduction algorithm which is to be applied to any acyclic ruleset S with respect to any <; A and C on any scene (cid:27) 2 (cid:5) $e<;A.The algorithm first constructs the graph G.S/ of the rule set, and then renumbers therelations Ri , and associated eRi , so that they are topologically sorted, i.e., for every directededge .Ri; Rj / in G.S/ it is the case that j > i. At each node Rj there is maintained a tablethat contains entries for each of the n(cid:11).j / possible bindings of Rj to A. Each entry has avalue from f0; 1; 0=1; ?g. Initially all the values that are unobscured in (cid:27) are entered as theappropriate 0 or 1 values in these tables. All the remaining entries are made “?”.The algorithm considers in turn the jSj rules in order of increasing j where Rj is theirright hand side, the relative ordering of rules with the same Rj on the right-hand side beingarbitrary:(cid:2)(cid:0)(cid:1)(cid:3):(cid:17) Rj8x1; : : : ; xs 2 A Q.x1; : : : ; xs; (cid:27) / !fWhen considering the current rule with RHS D Rj , the algorithm is in a position to do thefollowing for each of the ns bindings (cid:25) of x1; : : : ; xs to A where s D (cid:11).j /:e1.Ri1 /; : : : ; e‘.Ri‘.j/ /It tests whether Q.x1; : : : ; xs; (cid:27) / D 0 and if that is so it does no update. Otherwise foreach Rih .1 6 h 6 ‘.j //, and for every binding (cid:25) 0 of its y variables (i.e., those argumentsof Rih not bound by (cid:25) ) it takes the value of Rih (which may be determined either by beingunobscured in the input, or by having been evaluated) under the combined binding (cid:25); (cid:25) 0,and hence evaluates eh.Rih / using Fact 3.1. If the values of Rih needed to evaluate someeh.Rih/ include “?” values in such a way that eh cannot be evaluated for this (cid:25) then theentry for (cid:25) at Rj will not be updated. Otherwise substituting these ‘.j / values of the ehinto f gives the deduced value of Rj under the binding (cid:25) : x1; : : : ; xs ! A, and will beentered as the value under (cid:25) in the table at node Rj . If Rj occurs on the right-hand sideof more than one rule then for any one (cid:25) it may acquire a 0 value through one rule, and a1 value through another. In that case the table entry made for it will be 0=1. Now if someRih in the rule under current consideration occurs on the RHS of more than one rule and ithas acquired a 0=1 value thereby for some (cid:25) , then eh may also acquire such a 0=1 valuethrough the execution of the procedure of Fact 3.1. The algorithm will then choose just onef0; 1g‘ vector consistent with the values of the eh, say the lexicographically first one, andevaluates the connective f for just that one vector.When the deduction algorithm terminates it outputs the table entry for the (relation,binding) pair for which a value was requested, and if that value is ? then it outputs “nothingpredicted”.Theorem 2. For any fixed (cid:11) the acyclic deduction algorithm is PAC-sound for acyclic rulesets (cid:0)(cid:11) composed of relations of maximum arity (cid:11).Proof. The algorithm repeats the action described in the last paragraph n(cid:11).q/ times foreach rule q 2 S. Each such action evaluates ‘.q/ values of eh.Rih / for the various h andperforms one evaluation of a connective function. Hence the overall complexity of thealgorithm subsequent to the initialization of the tables is upper bounded by(cid:1);(cid:0)Ev.n; (cid:11)/l.q/ C c.q/n(cid:11).q/Xq246L.G. Valiant / Artificial Intelligence 117 (2000) 231–253Pwhere c.q/ is the complexity of evaluating the connective f in rule q and Ev.n; (cid:11)/ is thecomplexity of evaluating a quantified expression for a relation of arity (cid:11) over an imagewith n object variables. If we let kSk be the length of description of S as defined earlierq .‘.q/ C 1/. Hence if we denote by c.S/ the maximum complexity of thethen kSk Dconnectives in S and use Fact 3.1 to upper bound Ev.n; (cid:11)/ by O.n(cid:11)/, then the runtime ofthe algorithm can be upper bounded by a term linear in the description of the input (cid:27) , plusa term linear inn(cid:11)(cid:0)kSkn(cid:11) C jSjc.S/(cid:1):This establishes that the algorithm is polynomial time if (cid:11) is regarded as a constant.We now show that the algorithm is sound in the sense that if each rule of S is accurateenough over D then any output from the algorithm will be inaccurate with small probabilityon a random scene (cid:27) drawn according to D.Consider an acyclic rule set S and a scene (cid:27) for it. As the algorithm evaluates S itevaluates at most jSj rules and considers them in sequence. When evaluating the connectivef for the rule q for some binding (cid:25) for each constituent Rih on the left-hand side it uses thevalues of Rih for the various different bindings consistent with (cid:25) that had been evaluatedwhen the rules with Rih on the right-hand side had been computed.Now consider the event that (cid:27) drawn randomly according to D has some eRj D 0 forsome binding (cid:25) , but that the deduction algorithm outputs Rj D 1 for that binding, or,alternatively, eRj D 1 but the algorithm outputs Rj D 0. Then it must be that there is a firstrule and binding in the topological ordering that make a mistake, i.e., the deduced values ofevery Rih on the left-hand side do equal the real values eRih but the connective f producesan answer different from the true value of the right-hand side. But the quantityerD.q/ D max(cid:25)X(cid:0)D.(cid:27) /err(cid:27)C.q; (cid:27); (cid:25)/ C err(cid:0).q; (cid:27); (cid:25)/(cid:1)upper bounds the probability that on any (cid:25) a random (cid:27) from D satisfies Q and causesrule q to err. Let us assume, as is sufficient for the definition of PAC-soundness, that thisprobability is at most "=.jSjn(cid:11)/. Then the probability that a random (cid:27) will cause at leastone rule in S to err on at least one binding is no more than jSjn(cid:11) times this quantity, namely". This establishes that the deduction algorithm is PAC-sound. 23.4.2. The general caseWe now describe the general deduction algorithm that can be applied to arbitrary rulesets, not just acyclic ones.For an arbitrary rule set S we define a directed evaluation graph EG.S/ D .V ; E/ asfollows. We assume that the rules are defined in the manner of (3.1) and ordered arbitrarilyj D 1; : : : ; jSj. We denote the right hand side of the j th rule by Rr.j /. More than one rulemay share the same RHS in which case r is not one-to-one. The vertex set V of EG.S/ is:V DjSj[j D1(cid:8)(cid:9).r.j /; (cid:25)/ j (cid:25) : fx1; : : : ; x(cid:11).j /g ! A:In other words, each vertex corresponds to a relation Rr.j / and to a binding of itsarguments to A. Hence certainly jV j 6 jSj (cid:1) n(cid:11).S/. With regard to the edges E of EG.S/L.G. Valiant / Artificial Intelligence 117 (2000) 231–253247each rule j is associated with a (not necessarily disjoint) set of directed edges .vg; vh/where vh D .r.j /; (cid:25)/ for some (cid:25) , and vg D .k; (cid:25) 0/ where, further, Rk appears in LHS.j /.More precisely, the presence of .vg; vh/ in E denotes that in order to evaluate Rr.j / for (cid:25)using LHS.j / the value of Rk for (cid:25) 0 may be needed. For example, suppose that rule j D 5is:(cid:2)(cid:0)(cid:1)(cid:3)f8x1 2 A9y1 R1.x1; y1/; 9y2 R2.y2; x1/(3.3)Also let us denote the binding (cid:25) : fx1; : : : ; xsg ! fa(cid:25).1/; : : : ; a(cid:25).s/g by T(cid:25).1/; : : : ; (cid:25).s/U.Then if vh D .3; T4U/ and vg D .2; T5; 4U/ then the edge .vg; vh/ will be present in E sinceto verify that R3.a4/ D 1 we may need the value of R2.y2; a4/ for every value of y2 2 A,including y2 D a5.(cid:17) R3.x1/:Whether the value of this R2.y2; a4/ is needed in a particular evaluation depends on thedetails of the actual implementation. For example, suppose that the value of R2.a7; a4/has been previously obtained in the course of the evaluation. If its value was 1 then thisdetermined the value of 9y2R2.y2; a4/ already, and hence the value of R2.a5; a4/ wouldno longer be needed. If its value was 0, on the other hand, then the value of R2.a5; a4/ maystill be necessary to determine the value of 9y2R2.y2; a4/:The in-degree of each node is determined very simply from the syntax. In the exampledescribed in expression (3.3) the node .3; TiU/ has 2n predecessors deriving from this rule,a half from nodes .1; Ti; j U/ for 1 6 j 6 n, and the other half from .2; Tk; iU/ for 1 6 k 6 n.If R3 appears as the RHS of other rules then the in-degree would be larger. More formally,the predecessors in EG.S/ of a node .j; (cid:25)/ are the .i; (cid:25) 0/ with the following property: forsome rule with Rj on the right-hand side there occurs Ri on the left-hand side, and for thex variables that occur as common parameters of Rj and Ri in the rule, the bindings (cid:25) and(cid:25) 0 map them to the same a 2 A.We shall regard a deduction algorithm as a procedure that dynamically assigns a labelfrom f0; 1; 0=1; ?g to each node of EG.S/. A node that has one of the first three labels 0,1,0=1 is considered set, while a node labelled ? is considered unset. Initially each node thatcorresponds to a value that is not obscured in the scene (cid:27) is set to the f0; 1g value specifiedby (cid:27) . All other nodes are initially given the unset value ?. The label value of a node v ischanged from ? to 0 or 1 only if the labels of the predecessors of v in EG.S/ are such thatthey fully determine enough arguments of f so as to determine f . In the example describedin (3.3), for (cid:25) : x1 ! a4 both 9y1R1.a4; y1/ and 9y2R2.y2; a4/ need to be determined if, forexample, f is the parity function. Note that 9y1R1.a4; y1/ is determined if either R1.a4; ai/is set to 1 for some ai 2 A, or R1.a4; ai/ is set to 0 for all ai 2 A. When a node in EG.S/ isset we will, for the purposes of the algorithm description, consider that the correspondingvector element in (cid:27) that was originally obscured now has that set value.Clearly, once the label of a node is set to 0 or 1 by virtue of a rule, its label will not befurther changed even if more of the predecessor nodes arising from the same rule are setto f0; 1g values subsequently. However, if the node corresponds to an Ri that occurs on theRHS in more than one rule then a contradiction that tries to set a value of 0 to one alreadyset to 1, or vice versa, may arise. In that case the algorithm will set the value “0=1”. As inthe acyclic case, for each node we shall compute the connective f just the first time thatits value is defined, and if some argument then has a 0=1 label we will choose one of thesearbitrarily.248L.G. Valiant / Artificial Intelligence 117 (2000) 231–253The general deduction algorithm we can now define as follows: The rules are ordered inan arbitrary manner j D 1; : : : ; jSj. The labels of the nodes of EG.S/ that have unobscured0 or 1 values for the given (cid:27) are set to those values. The algorithm then scans the ruleset repeatedly and terminates when a scan of S has been completed in which no updatesoccurred. In each scan it enumerates the rules j D 1; : : : ; jSj and considers each one forupdating. In each such consideration it enumerates all the bindings (cid:25) : fx1; : : : ; x(cid:11).r.j //g !A: For each such binding, if the precondition Q of that rule is satisfied by .(cid:25); (cid:27) /, andif the label for the node .r.j /; (cid:25)/ in EG.S/ should be changed because the rule is nowfully determined by the labels of its predecessors in EG.S/ while this was not the case inthe previous scan, then the algorithm evaluates f and performs the necessary update tothe label. (In the case that a 0 or 1 value would be assigned to a node that has been set acontrary 0 or 1 value previously by virtue of a different rule, the set value will be changedto “0=1”.)When the algorithm terminates it considers the value of the label of the relation Ri forthe binding (cid:25) specified as the deduction task, and outputs that value. If it is ? then it outputs“nothing predicted”.Theorem 3. For any fixed (cid:11) the general deduction algorithm is PAC-sound for rule sets(cid:0) (cid:3)(cid:11) composed of rules of arity upper bounded by (cid:11).Proof. Each (relation, binding) pair .i; (cid:25)/ can partake in at most two updates—when it isfirst set, and when it is changed to 0=1. Since at least one .i; (cid:25)/ pair has an initialized labelat the start, and at least one is updated at each step it follows that there are at most 2tn(cid:11)scans if there are t relations and therefore t choices of i, and there are n(cid:11) choices of (cid:25) .Each scan considers each node .i; (cid:25)/ of EG.S/ as many times as there are rules jwith r.j / D i. Hence it performs at most jSjn(cid:11) such considerations. In each considerationit examines each of the ‘j expressions in the LHS and evaluates it, if necessary, usingEv.n; (cid:11)/ operations, and if all these yield values then it computes the connective f .Hence a first upper bound on the runtime is(cid:0)n(cid:11)kSkEv.n; (cid:11)/ C n(cid:11)jSjc.S/(cid:1):2tn(cid:11)Now it is the case, if one considers the algorithm globally, that the number of timesconnectives need to be evaluated is just the number of (i; (cid:25) ) pairs, or at most jSjn(cid:11). Also,if quantified expressions are evaluated using a game-tree in the manner of Fact 3.1, thena reduced bound on the total work needed can be deduced using global considerations.Suppose we modify the algorithm so that whenever a node .i; (cid:25)/ is updated the internalnodes in all the game trees in which .i; (cid:25)/ occurs as a leaf are also modified, and theireffects followed up towards the root of the game tree. Following the effects of any one leafcosts at most (cid:11) operations, and therefore the accumulated updating done on any one gametree is at most (cid:11)na operations.Using these two global considerations one can reduce this complexity bound to 2(cid:11)tn2(cid:11) CjSjn(cid:11)c.S/.The additional cost of initializing the labels is linear in this quantity also since it is linearin the number of nodes jSjn(cid:11) of EG(S). Hence the algorithm satisfies the polynomial timecriterion if (cid:11) is a constant.L.G. Valiant / Artificial Intelligence 117 (2000) 231–253249For analyzing soundness suppose that each rule is "0-accurate. This means that for anyone binding (cid:25) of its RHS, for a (cid:27) randomly drawn from D it is the case that Q.(cid:27); (cid:25)/ D 1and LHS 6D RHS with probability at most "0.Now in the course of an evaluation the general deduction algorithm performs at mostjSjn(cid:11) label updates. If the output of the algorithm is incorrect for the given (cid:27) then it mustbe that in one of the label updates, say for rule j under binding (cid:25) 0, the arguments ofLHS.j / as computed were correct for (cid:27) , but applying the function f specified in rule jproduced a false value for RHS.j /. However, for any such fixed j and (cid:25) 0 the probabilityof this occurring is at most "0 since the rule is "0-accurate by assumption.Hence the probability that any false conclusions are drawn by the algorithm is at mostjSjn(cid:11)"0. If "0 < "=.jSjn(cid:11)/ then it follows that the output of the general deduction algorithmwill be incorrect with probability at most ", as required. 23.4.3. CompletenessIt seems clear that in the definition of "-accuracy we need to allow for the possibilitythat the deduction algorithm may legitimately output “nothing predicted” quite frequently.It may be that the obscured scene (cid:27) specifies too few values, or it may be that thepreconditions Q of the rules are very constraining. On the other hand, it is not legitimatefor the deduction algorithm to output “nothing predicted” in circumstances when no suchvalid impediment applies, for then the rules would allow a deduction that is "-accurate andsound.To resolve this issue we introduce the following notions.Definition. For any rule set S with respect to any <; A; C, a deduction sequence isa sequence of triples .qj ; (cid:25)j ; bj / for j D 1; : : : ; J; where qj 2 S; (cid:25)jis a bindingf1; : : : ; (cid:11)j g ! A where (cid:11)j is the arity of RHS.qj /, and bj 2 f0; 1g.Definition. A deduction sequence is valid for an input (cid:27) if for every j .1 6 j 6 J / thefollowing is the case: The values val.R; (cid:25)/ for all pairs .R; (cid:25)/ that are unobscured inthe input (cid:27) together with the values bi when taken as the values of val(RHS.qi/; (cid:25)i/ for1 6 i < j have the properties that(i) they satisfy the precondition Qj .(cid:25)j ; (cid:27) / of qj ,(ii) they determine all the expressions in LHS.qj /, and(iii) the value of the connective fj of rule qj at the specified point equals bj .Definition. A deduction algorithm is complete for a class of rule sets S with respect toany <; A; C if and only if the following holds: for any scene (cid:27) 2 (cid:5) $e<;A there exists avalid deduction sequence terminating with .q; (cid:25); b/ for some b 2 f0; 1g if and only if thededuction algorithm on input S; Ri D RHS.q/, (cid:25) , and (cid:27) outputs some predicted valuefrom f0; 1; 0=1g.If remains to observe:Proposition. The acyclic deduction algorithm is complete for acyclic rule sets (cid:0) , and thegeneral deduction algorithm is complete for general rule sets (cid:0) (cid:3).250L.G. Valiant / Artificial Intelligence 117 (2000) 231–253Proof. It is easy to show by induction on J that for the general deduction algorithmafter the J th scan all valid deduction sequences of length J have been followed. In otherwords, if some valid deduction sequence terminates with .qJ ; (cid:25)J ; bJ / then the algorithmwill have given a determined value f0; 1; 0=1g to node .RHS.qJ /; (cid:25)J /. The main pointis that the evaluation process described in Fact 3.1 is monotone, which guarantees thatonce a node in the evaluation graph is determined it can never become undeterminedlater. By similar arguments the acyclic deduction algorithm can be seen to be complete.In that case one shows by induction on J that when RJ , is evaluated by the algorithm,all valid deduction sequences terminating in a qJ with that right-hand side have beenconsidered. 23.4.4. Compound relations and L-expressionsIn defining rules we chose, for the sake of simplicity, to describe each quantified2 <. Clearly, we could have a baseexpression ej as depending on a single relation Rijset <0 of relations and have < consist of combinations of members of that base set. Forexample, if we want < to have arity 4, we can choose a base set <0 of binary relations anddefine < to consist of suitable conjunctions of pairs of these.The following class of such combinations is noteworthy in applications where it isdesirable to reduce the number of bindings that have to be tried in learning or deduction.We define a labelled expression or L-expression as an existentially quantified expression.R.x1; : : : ; xs/R1.x1/R2.x2/ (cid:1) (cid:1) (cid:1) Rs .xs/;where R may be an arbitrary compound expression, but R1; : : : ; Rs are all unary. Theambiguity of a scene (cid:27) for such an L-expression e with s variables is the number of distinctbindings (cid:25) : fx1; : : : ; xsg ! A for which the conjunctionR1.x1/R2.x2/ (cid:1) (cid:1) (cid:1) Rs .xs/is satisfied for (cid:27) . Clearly, if an expression has low ambiguity, say ambiguity 1, withhigh probability for (cid:27) 2 D, then no substantial search over bindings is necessary whenrecognizing its presence. This seems particularly relevant when modelling biologicalneural processes, as was previously discussed in [45]. It also provides for more efficientand accurate deduction. For example, suppose that all the expressions occurring in theLHS of a rule set S are L-expressions that have ambiguity one with probability one inD. Then if each of the kSk such expressions that occurs is regarded as a separate relationin a new < then each of them can have a value 1 for at most one binding, and hencea multiplicative factor of n(cid:11) can be saved in the cost of evaluating these expressions.It will also follow that each individual rule may be allowed to be correspondinglyless accurate, by a factor of about n(cid:11)jSj=kSk, and still guarantee "-accuracy of thededuction.Finally, we observe that the notation described for defining rules can be used to expresscertain relations of higher arity than the maximum arity of the base relations. We can, forexample, have an object, say a7, represent a set and identify the members of the set to bethose ai for which the relation member.a7; ai/ holds. If we have a binary relation adjacent.xj ; xk/ then we can express the relation completely-connected.xi/, to simulate a relationof arity up to n (cid:0) 1, as follows:L.G. Valiant / Artificial Intelligence 117 (2000) 231–2538x1 2 A(cid:2)8x28x3(cid:0):member.x1; x2/ _ :member.x1; x3/ _ adjacent.x2; x3/(cid:17) completely-connected.x1/:(cid:3)251(cid:1)If the relations member. / and adjacent. / are predefined, and the LHS of thisrule is a member of the allowed set of compound relations, then such a rule forcompletely-connected. / can be learned from examples, or evaluated.4. Related workThe framework described here has relationships with work in many other areas.Relational rules and their evaluation are central, for example, to both databases andartificial intelligence, while learning has been studied in numerous settings. Our logicis distinguished by the close way in which it integrates learning and reasoning, and bythe insistence on having the measures of both computational complexity and of accuracybounded by polynomial functions.Among the numerous alternative approaches that are relevant to ours we briefly mentionjust three.Probabilistic logics have been defined to extend predicate calculus to probabilisticphenomena [6]. Some treat the underlying distribution as one over the world, whileothers impose it on a space of beliefs (see [12]). PAC-semantics has aspects of both. Theunderlying distribution is one over the world, but the degree of belief in any rule that thesystem is justified to have at any time may also be quantified, for example, by a confidenceparameter (cid:14).Inductive Logic Programming is concerned with learning rules in predicate calculus,with the standard semantics, often with the additional constraint of a background logicaltheory. The limits of polynomial time learnability have been explored [8,21,30]. Somesystems exist for learning such rules [34]. A discussion of some relationships between thetwo approaches can be found in [20].The Learning to Reason framework [18,19] integrates learning and reasoning in a similarspirit to our approach. Its most basic form is oriented towards maintaining information asa set of examples, and answering each query by processing these examples anew. Robustlogics are based on rules. This allows a system to accept a rule as input and hence to benefitfrom the experience of others, while still permitting it to evaluate or fine-tune the rule onthe basis of further examples and its own experience. Clearly systems based on robustlogics may additionally memorize individual examples, and thereby enjoy whatever addedbenefits may be so gained.5. ConclusionWe have described a formal system for representing knowledge that has a well definedsemantics and an efficient, sound and complete deduction procedure for instances. It alsohas an efficient learning procedure for learning the representation of rules one at a time,if an appropriate class of connectives that is efficiently learnable is used. The class of252L.G. Valiant / Artificial Intelligence 117 (2000) 231–253linear threshold functions appears to be a particular good choice since it offers, in addition,attribute-efficient and error-resilient learning.Clearly there are many directions in which one might attempt extensions. For example,we have restricted the discussion of reasoning here to deductions about single instances. Itwould be interesting to see what can be said about the deduction of new rules. Also, sincePAC-semantics is based on probability theory, all the methods of probabilistic inferencecan be brought to bear (e.g., [32]).There also remain questions of how such a logic can be applied pragmatically whenbuilding computer systems that perform computations of a cognitive nature. The discussionin [47] addresses some of these questions.References[1] J.R. Anderson, Rules of the Mind, Erlbaum, Hillsdale, NJ, 1993.[2] D. Angluin, P. Laird, Learning from noisy examples, Machine Learning 2 (4) (1988) 343–370.[3] Aristotle, Prior Analytics, Book II, Part 23.[4] A. Blum, A. Frieze, R. Kannan, S. Vempala, A polynomial time algorithm for learning noisy linear thresholdfunctions, in: Proc. 37th IEEE Annual Symposium on Foundations of Computer Science (FOCS-96), 1996,pp. 330–338.[5] T. Bylander, Learning linear threshold functions in the presence of classification noise, in: Proc. 7th ACMConference on Computational Learning Theory, 1994, pp. 340–347.[6] R. Carnap, Logical Foundations of Probability, University of Chicago Press, Chicago, IL, 1950.[7] E. Cohen, Learning noisy perceptrons by a perceptron in polynomial time, in: Proc. 38th IEEE Symposiumon Foundation of Computer Science, 1997, pp. 514–523.[8] W.W. Cohen, C.D. Page, Polynomial learnability and inductive logic programming: Methods and results,New Generation Computing 13 (314) (1995) 369–409.[9] A. Ehrenfeucht, D. Haussler, M. Kearns, L. Valiant, A general lower bound on the number of examplesneeded for learning, Inform. and Comput. 82 (3) (1989) 247–266.[10] M.L. Ginsberg, Readings in Nonmonotonic Reasoning, Morgan Kaufmann, Los Altos, CA, 1989.[11] A.R. Golding, D. Roth, Applying Winnow to context-sensitive spelling correction, in: Proc. 13th Internat.Conference on Machine Learning, Bari, Italy, Morgan Kaufmann, San Mateo, CA, 1996, pp. 182–190.[12] J.Y. Halpern, An analysis of first-order logics of probability, Artificial Intelligence 46 (1990) 311–350.[13] D. Haussler, Quantifying inductive bias: AI learning algorithms and Valiant’s learning framework, ArtificialIntelligence 36 (1988) 177–221.[14] M.J. Kearns, Efficient noise-tolerant learning from statistical queries, in: Proc. 25th ACM Symposium onTheory of Computing, ACM Press, New York, 1993, pp. 392–401.[15] M. Kearns, M. Li, Learning in the presence of malicious errors, SIAM J. Comput. 22 (4) (1993) 807–837.[16] M.J. Kearns, U.V. Vazirani, An Introduction to Computational Learning Theory, MIT Press, Cambridge,MA, 1994.[17] R. Khardon, Learning to take actions, in: Proc. AAAI-96, Portland, OR, 1996, pp. 787–792.[18] R. Khardon, D. Roth, Learning to reason with a restricted view, in: Proc. 8th ACM Conference onComputational Learning Theory, 1995, pp. 301–310.[19] R. Khardon, D. Roth, Learning to reason, J. ACM 44 (5) (1997) 697–772.[20] R. Khardon, D. Roth, L.G. Valiant, Relational learning for NLP using linear threshold elements, in: Proc.IJCAI-99, Stockholm, Sweden, Morgan Kaufmann, San Mateo, CA, 1999, pp. 911–917.[21] J.-U. Kietz, S. Dzeroski, Inductive logic programming and learnability, SIGART Bulletin 5 (1) (1994) 22–32.[22] J. Kivinen, M.K. Warmuth, P. Auer, The Perceptron algorithm versus Winnow: Linear versus logarithmicmistake bounds when few input variables are relevant, in: Proc. 8th ACM Conference on ComputationalLearning Theory, 1995, pp. 289–296; also: Artificial Intelligence 97 (1997) 325–343.[23] D. Knuth, The Art of Computer Programming, Vol. 3, Addison Wesley, Reading, MA, 1973.L.G. Valiant / Artificial Intelligence 117 (2000) 231–253253[24] P. Langley, D. Klahr, R. Neches, Production System Models of Learning and Development, MIT Press,Cambridge, MA, 1987.[25] D.B. Lenat et al., CYC: Toward programs with common sense, Comm. ACM 33 (8) (1990) 30–49.[26] N. Littlestone, Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm,Machine Learning 2 (1988) 285–318.[27] N. Littlestone, From on-line to batch learning, in: Proc. 2nd Workshop on Computational Learning Theory,1989, pp. 269–284.[28] J. McCarthy, Programs with commonsense, in: Proc. Teddington Conference on the Mechanization ofThought Processes, London, 1959. HMSO.[29] M. Minsky, S. Papert, Perceptrons, MIT Press, Cambridge, MA, 1969.[30] S. Muggleton, L. De Raedt, Inductive logic programming: Theory and methods, J. Logic Programming 19(1994) 629–679.[31] A. Newell, H.A. Simon, Human Problem Solving, Prentice-Hall, Englewood Cliffs, NJ, 1972.[32] J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, MorganKaufmann, Los Altos, CA, 1988.[33] L. Pitt, L.G. Valiant, Computational limits on learning from examples, J. ACM 35 (1988) 965–984.[34] J.R. Quinlan, Learning logical definitions from relations, Machine Learning 5 (1990) 239–266.[35] R.L. Rivest, Learning decision lists, Machine Learning 2 (3) (1987) 229–246.[36] F. Rosenblatt, Principles of Neurodynamics, Spartan, New York, 1962.[37] D. Roth, Learning to reason: The non-monotonic case, in: Proc. IJCAI-95, Montreal, Quebec, 1995,pp. 1178–1184.[38] D. Roth, A connectionist framework for reasoning: Reasoning with examples, in: Proc. AAAI-96, Portland,OR, 1996, pp. 1256–1261.[39] S. Russell, P. Norvig, Artificial Intelligence, Prentice-Hall, Upper Saddle River, NJ, 1995.[40] D. Schuurmans, R. Greiner, Learning default concepts, in: Proc. 10th Canadian Conference on ArtificialIntelligence, CSCSI-96, Toronto, Ont., 1994, pp. 99–106.[41] A.M. Turing, Computing machinery and intelligence, Mind 59 (1950) 433–460; Reprinted in: D.C. Ince(Ed.), Collected Works of A.M. Turing: Mechanical Intelligence, North-Holland, Amsterdam, 1992.[42] A.M. Turing, Solvable and unsolvable problems, Science News 31 (1954) 7–23; Reprinted in: D.C. Ince(Ed.), Collected Works of A.M. Turing: Mechanical Intelligence, North-Holland, Amsterdam, 1992.[43] J.D. Ullman, Principles of Database and Knowledge-Base Systems, Computer Science Press, 1989.[44] L.G. Valiant, A theory of the learnable, Comm. ACM 27 (11) (1984) 1134–1142.[45] L.G. Valiant, Circuits of the Mind, Oxford University Press, Oxford, 1994.[46] L.G. Valiant, Rationality, in: Proc. 8th Annual Conference on Computational Learning Theory, ACM Press,New York, 1995, pp. 3–14.[47] L.G. Valiant, A neuroidal architecture for cognitive computation, in: Lecture Notes in Computer Science,Vol. 1443, Springer, Berlin, 1998, pp. 642–669; also: J. ACM, to appear.[48] L.G. Valiant, Projection learning, Machine Learning 37 (2) (1999) 115–130.