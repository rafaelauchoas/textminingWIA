Artificial Intelligence 164 (2005) 121–170www.elsevier.com/locate/artintA formal framework for the decentralised diagnosisof large scale discrete event systems and itsapplication to telecommunication networksYannick Pencolé a,∗, Marie-Odile Cordier ba CSL, The Australian National University, ACT 0200, Australiab IRISA/Université de Rennes 1, Campus de Beaulieu, 35000 Rennes, FranceReceived 30 September 2004; accepted 2 January 2005Available online 24 February 2005AbstractWe address the problem of diagnosing large discrete event systems. Given a flow of observationsfrom the system, the goal is to explain these observations on-line by identifying and localising possi-ble failures and their consequences across the system. Model-based diagnosis approaches deal withthis problem but, apart very recent proposals, either they require the computation of a global modelof the system which is not possible with large discrete event systems, or they cannot perform on-line diagnosis. The contribution of this paper is the description and the implementation of a formalframework for the on-line decentralised diagnosis of such systems, framework which is based on the“divide and conquer” principle and does not require the global model computation. This paper finallydescribes the use of this framework in the monitoring of a real telecommunication network. 2005 Elsevier B.V. All rights reserved.Keywords: Model-based diagnosis; Discrete event systems; Decentralised model; Distributed artificialintelligence; Telecommunication networks; Fault propagation* Corresponding author.E-mail addresses: Yannick.Pencole@anu.edu.au (Y. Pencolé), cordier@irisa.fr (M.-O. Cordier).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.01.002122Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–1701. IntroductionThe problem we deal with is the supervision of complex and large discrete eventsystems such as telecommunication networks, electricity distribution network, and moregenerally speaking Immobots [29]. Given a supervision system continuously receiving ob-servations (alarms) sent by the system components, our purpose is to help operators toidentify failures. Two classical approaches in monitoring such systems are knowledge-based techniques that directly associate a diagnosis to a set of symptoms, for exampleexpert systems [17], or chronicle recognition systems [7,9], and model-based techniqueswhich rely on a behavioural model of the system [22]. The main weakness of the first ap-proach is the lack of genericity: as the system changes (new components, new connections,new technologies), a new expertise has to be acquired. Therefore, we focus on model-basedtechniques which are known to be better suited to that kind of system than expertise-basedapproaches.A number of model-based approaches for diagnosing discrete event systems have beenproposed in both the AI and control engineering literature. They cover continuous-variablesystems which, after quantisation, are represented as discrete systems [15], as well as “dis-crete by nature” systems such as communicating processes which exchange messages andalarms. The majority of these approaches are centralised approaches [15,23,26]. For in-stance, the diagnoser approach [26] consists in the compilation of diagnostic informationin a data structure (called diagnoser), which maps observations to failures for on-line diag-nosis. The main drawback of centralised approaches is that they require to explicitly buildthe global model of the system which is unrealistic for large, complex systems such astelecommunication networks.The considered systems are naturally distributed so it is easier to model those systems ina decentralised way. An approach for diagnosing discrete event systems using decentraliseddiagnosers can be found in [8], but the computation of each decentralised diagnoser is stillbased on a global model. There also exist methods relying on a decentralised model [2,6],but these are used off-line to solve a diagnosis problem a posteriori. Recently, due to theneed of solving a diagnosis problem on-line, a monitoring-based approach [13,14] has beendeveloped: this method mixes a diagnoser approach [26] with an extended version of thedecentralised model of [2] by computing on-line only the interesting parts of a centraliseddiagnoser without computing a global model. This method still has the problem that itsystematically uses global states of the system which can be a problem when dealing withlarge discrete event systems.In this paper, we propose a formal framework providing an approach which relies ona decentralised model and computes on-line diagnosis of large discrete event systems.Firstly, we propose a formalism for decentralised models based on communicating au-tomata. This formalism allows us to model behaviours of large discrete event systems in amodular way and to use decentralised algorithms on it thanks to a generic synchronisationoperation.Secondly, we define the diagnosis problem inside this framework and propose an algo-rithm to make on-line diagnosis. To make an on-line diagnosis system, efficiency is thekey issue. The idea is to split the flow of observations into temporal windows. For eachtemporal window, we compute a diagnosis for a subsystem (subsystem diagnosis) and thenY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170123we build a diagnosis of the whole system (global diagnosis) by merging these subsystemdiagnoses. The merging operation is applied thanks to an original strategy which dynami-cally recognises an efficient way to apply the merging operation based on the observationsof the current temporal window.The paper is organised as follows. We first introduce the type of systems that we con-sider, the monitoring problem, and a small example which will be used as an illustrationthroughout the paper (Sections 2 and 3). In Section 4, we present the formalism based oncommunicating automata, which is used to represent in a decentralised way the model ofthe system, and a synchronisation operation which allows us to perform decentralised rea-sonings on any subpart of the system in the same way. Section 5 explains the diagnostictask by defining observations and diagnoses and in Section 6, we formally present the de-centralised diagnosis approach and prove its equivalence with respect to the centralised onein the proposed framework. Section 7 focuses on the choices about the implementation ofthe decentralised diagnosis approach in order to apply the approach on-line. Firstly, partialorder reduction techniques are shown to be well-suited for efficiently representing the diag-noses. Secondly, the merging operation strategy, taking into account the interactions of thesubsystem diagnoses dynamically, is proved to greatly improve the efficiency of the globaldiagnosis computation. In Section 8, the incremental aspect of the diagnosis problem isintroduced and is shown to be essential in the context of dynamical system monitoring.Section 9 presents some results relying on a real case of telecommunication network. Thisstudy has been done in the context of the MAGDA project1 and demonstrates the bene-fits of a decentralised approach. Finally, Section 10 presents related work and Section 11concludes this paper and discusses several perspectives relying on the presented work.2. Monitoring large reactive discrete event systems2.1. System characteristicsA typical system is depicted in Fig. 1: components communicate each other with thehelp of communication channels. A component is an entity that has a finite set of internalstates. The system is event-driven, i.e., it evolves with the occurrence of events on thecomponents.An exogenous event (event from the set Σexo) is an event produced by the environmentof the system. Due to the fact that events are instantaneous (they do not have delay), theprobability that two events produced by the environment occur at the same time is practi-cally null, hence the following hypothesis.Hypothesis 1. Two exogenous events cannot occur at the same time on the system.Such an event may trigger a change of state in one component. During that state change,the affected component may produce communication events (event from the set Σcom) to-1 RNRT project MAGDA: funded by the French Ministère de la Recherche; the other partners of this projectare France Telecom R&D, Alcatel, Ilog, and Paris-Nord University.124Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170Fig. 1. Reactive discrete event system.wards its neighbourhood by emitting messages via its communication channels and alsoproduce observable events (event from the set Σobs) towards the environment of the sys-tem by emitting observable messages. The reception of a message from a communicationchannel is also a communication event and may change the internal state of the compo-nent which receives it. In that case, the component affected by this event may also emitcommunication and observable events.A communication channel respects the following assumption which guarantees that thesystem has a finite set of states.Hypothesis 2. A communication channel between two components is bounded.A communication channel can be of any type: among the channel types, queues areespecially considered, like for example:• instantaneous queue: such a queue has no buffer, the emission of a message from acomponent and the reception of the same message to the destination is the same event;• first in first out queue (FIFO): such a queue has a bounded buffer, the messages con-veyed by this queue are received in the same order they have been emitted;• queue with loss of messages: such a queue is not reliable, conveyed messages can belost due to several types of problems (saturation of the buffer, loss due to the occur-rence of an exogenous event on the channel which affects its behaviour. . . ).2.2. Monitoring of the systemIn order to help the human agent (or supervisor) in charge of managing the system,i.e., detecting failures and deciding reconfiguration/repair actions, a supervision system isY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170125needed: its task is to record observations of the supervised system and to analyse them inorder to produce a concise view of the state and the history of the system for the supervisor.2.2.1. Observability of the systemDefinition 1 (Observation). An observation is the reception, at a given date, by the super-visor, of a message sent by a component of the supervised system.Any observation corresponds to the emission of an observable message by a component.The message of an observation is supposed to contain an information about the componentwhich has emitted it, it follows that the supervisor knows about the component source ofevery observation.Because the system is large, the supervisor may not be located next to the supervisedcomponents. In the majority of cases, an observation channel has to be considered betweenany component which emits observable messages and the supervisor. As a consequence,the emission of an observable message is not necessarily the same event as the receptionof this message by the supervisor.The observation system which is the set of the observation channels respects the fol-lowing hypothesis.Hypothesis 3. The observation system is complete, reliable and efficient.The completeness of the observation system means that for every kind of observablemessage there exists an observation channel which can convey this kind of message. Thereliability of the observation system means that the observation channels do not loose mes-sages. Every message emitted by the components are effectively received by the supervisor.The efficiency means that any message in an observation channel is conveyed efficientlywithout message overtaking. Consequently, in the following, we can assume that any ob-servation channel is an instantaneous or a reliable FIFO bounded queue.2.2.2. Monitoring taskThe purpose of the monitoring task is to detect, localise, and identify problems thatoccur on the system. These problems can be physical (an equipment is down, a cable iscut) or logical (a station is rebooting, a logical connection is down. . . ). Our purpose isnot to explain in details what is happening on the system but only what a supervisor agentneeds to know. In the following, we will consider that a failure is any occurrence of an eventwhich is considered as pertinent for the supervisor in the sense that he wants to trace theoccurrences of this event. For most of the failures on the considered systems, there are someautomatic recovery procedures (recovery events), so failures can disappear (intermittentfailures). A failure that do not have any recovery event is called a permanent failure.One of the main difficulties in the monitoring of large discrete event systems is thatthe occurrence of a primary failure on a component may have effects (called secondaryfailures) on other components. As a consequence, the occurrence of a failure on one com-ponent (or one communication channel) may cause the occurrence of several secondaryfailures in the whole system and the reception of a huge number of observations by thesupervisor. There could be also several failure propagations at the same time which can126Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170Fig. 2. Failure propagations and interferences.interfere and provide a huge number of possible observation sets depending on the way thepropagations interfere with each other. Moreover, it is also possible that a secondary failureoccurs depending on the way the different propagations interfere. Because of those interfer-ences, we need not only to identify the first causes of a problem (the primary failures) butalso the way they interfere to also identify the secondary failures. The recovery events havealso to be diagnosed because they are also part of interferences in the failure propagations.Example 1. In Fig. 2, four different failure propagations are presented. The two figures onthe left describe two single failure propagations inside a system composed of three com-ponents. f11 and f21 are the primary failures and they occur respectively on component 1and component 3. The consequences of f11 are the occurrences of the secondary failuresf12 and f13 and the emissions of the observations o3 o2. The consequences of f21 are theoccurrence of the secondary failure f22 and the emission of the observations o3 o2. In thefigures on the right, f11 and f21 occur both and their respective propagations interfere: itcan happen that the secondary failures are not the same. For example, if f22 occurs then thefailure f12 may not occur even if f11 has occurred. This is due to the nature of f22 and f12(for instance if f22 is “power down of the machine” and f12 is “reboot of the machine”,when the power is down the machine cannot reboot but the power can go down when themachine is rebooting).Another monitoring problem is the fact that the observations that are generally emittedwhen a failure occurs can be masked because of the occurrence of another failure in thepast. The consequence of the masking phenomenon is the fact that it increases the numberof failures that can occur without observable consequences and, therefore, the number ofpossible explanations for a given set of observations.Example 2. In Fig. 2, on the right side, when f13 occurs on the component 3, no observa-tion is emitted like in the other figures. The failure f21 has masked the observation o3 thatshould have been emitted after f13. In that example, if we observe o3 o2, there are threepossible explanations. The single propagations (on the left side) and the multiple failurepropagation of the right side.3. ExampleThis section describes a small example of supervised system that is used as an illustra-tion of the different ideas presented in this paper (see Fig. 3). In the following, this exampleY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170127Fig. 3. Telecommunication network example and its supervision system.is referred as Toynet. This system is composed of three data switches (SW1, SW2, SW3).These switches are in charge of emitting and receiving data in a ring network. Two switchesSWi and SWj communicate each other with the help of the connection cnij. Each switchSWi is managed by a control station CSi.Here is the behaviour description of the supervised system. A switch transmits datathrough two connections: a west connection (for SW1, it is cn12) and an east connection(for SW1, it is cn31). A connection between two switches is considered as a bidirectional128Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170communication channel. This communication channel is not reliable and can be affectedby the cut failure. If the connection is cut (cutCnij), SWi emits an observable event (forexample, if cn12 is cut (cutCn12), SW1 emits the observable event SW1cn12 and if cn31 iscut (cutCn31), SW1 emits the observable event SW1cn31). Then, the switch goes to itswaiting mode. If the connection is reestablished (workCnij), the switch goes back to itsnormal mode. A switch can break down (SW1brk), in this case, an observable event mech-anism informs the supervision system by the emission of the observable event SWidown.Moreover, the control station CSi detects this problem and tries to reinitialise the switchSWi (SWireboot). After a reinitialisation (SWiendreboot), the switch is operational againand emits an observable event SWiok. Two kinds of failures can happen on a control sta-tion. Firstly, the station can hang up (CSioff ) and then recovers a normal mode (CSion).When the station recovers a normal mode, an observable event CSiok is emitted. Thisobservable event is conveyed via the switch SWi, so the observable event is masked if theswitch is not in its normal mode. A station can also reboot (CSireboot) and at the end of thereinitialisation (CSiendreboot), an observable event CSiok is emitted. The communicationchannel between a control station and its switch is considered as reliable and instantaneous.As far as the supervision system is concerned, each switch is connected to it via anobservation channel. In this example, for the sake of simplicity, those observation chan-nels are instantaneous queues, i.e., the emission of an observable message by a switch (anobservable event) corresponds exactly to the reception of this message by the supervisionsystem (the observation).4. Decentralised model of the systemAs said in the introduction, we decided to use model-based approaches which are recog-nised to be better suited to systems that can evolve (new components, new technologies).Due to the great number of components, it is quite unrealistic to rely on a global model ofsuch systems. This section explains how the model of the system is described in a decen-tralised way by means of local models, which describe the behaviours of each componentand each communication channel of the system and a generic synchronisation operationwhich describes the way the local models interact each other.The formalism used to model a system is based on the formalism defined in [24]. In thisformer article, the authors propose to model a component as a communicating automatonwhich represents the way messages are received or emitted via a set of ports belonging tothe component. The model of the system is then represented as a set of communicatingautomata and a set of links. A link is an association between an output port (port fromwhere messages are emitted) and an input port (port where messages are received) whichdefines synchronisation rules between components (the emission and the reception of amessage on a link is synchronised).2 From a practical point of view, this formalism is veryintuitive and allows to model the system in a modular and hierarchical way. For the sake2 A link does not correspond to a communication channel previously described. In the formalism of [24], acommunication channel is represented like a component. See Section 4.2 for details.Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170129Fig. 4. Abstraction of ports, messages and links.of simplicity and without loss of generality,3 we present in this paper an abstraction of thisformalism. In this formalism, the notions of port, message and link are abstracted with thehelp of the notion of event: an event is the reception or the emission of a message via aport. If a port is linked to another port, then the emission of a message from the output portand the reception of the same message by the associated input port is represented in ourformalism by a communication event (see Fig. 4).Although we present the abstracted version of our formalism for the sake of simplicity,in practice we use the non-abstracted version so that we can benefit of the modularity andthe hierarchical way of modelling a system.4.1. Model of a componentA component ci receives two kinds of events:(1) exogenous events Σ i(2) communication events Σ inents of the system (Σ icom_rcv⊆ Σcom).exo, events from the environment (Σ iexo⊆ Σexo);com_rcv, reception of messages coming from other compo-Hypothesis 4. A component ci cannot receive two different events from Σ ithe same time.exo∪ Σ icom_rcv atA component can also emit two kinds of events:(1) observable events Σ i⊆ Σobs);system (Σ iobs(2) communication events Σ isystem (Σ icom_emit⊆ Σcom).obs, emission of messages that can be observed by a supervisioncom_emit, emission of messages to other components of theNote 1. Because of the way the abstraction is defined, a communication event is involvedonly in two components: the sender of the message and the receiver of the message (seeFig. 4).3 The temporal aspects (delays) that are defined in [24], are nevertheless not considered at all in this paper.130Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170Fig. 5. Model of the control-part of SW1 (noted SW1ctl).Definition 2 (Model of a component). The model of the component ci is described by thecommunicating finite state machine:rcv, Σ iemit, Qi, Ei)Γi = (Σ ircv is the set of received events (Σ ircvemit is the set of emitted events (Σ ircv• Σ i• Σ i= ∅;• Σ i• Qi is the set of component states;• Ei ⊆ (Qi × Σ ircv× 2(Σ i∩ Σ iemitemitemit) × Qi) is the set of transitions.= Σ iexo= Σ iobs∪ Σ i∪ Σ icom_rcv);com_emit);t−→ q(cid:7), we will note by rcv(t) the event from Σ iNote 2. For any component transition qrcvwhich triggers the transition t, emit(t) the set of events emitted by t, and among the eventsof emit(t), obs(t) the set of observable events.The model of the control-part of the component SW1 (noted SW1ctl) is depicted onrcv(t)/emit(t)−−−−−−−−→ q(cid:7)). The failure exogenous events are: SW1brkFig. 5 (transitions are noted q(SW1 begins to break down), SW1reboot (SW1 begins to reboot) and SW1endreboot (SW1terminates its reboot). The received communication events are: CS1operational (receptionof a message “the control station becomes operational”) and chgCn12SW1, chgCn31SW1(reception of a message “the status of a connection has changed”). Among the emittedevents, here are the observable ones: SW1down, SW1ok, SW1cn31, SW1cn12 and CS1ok.There is also one emitted communication event: SW1toreboot (emission of a message “theswitch has to reboot”).4.2. Model of a communication channelAs said in Section 2.1, the components are connected by any kinds of bounded com-munication channels. In the case where the channel is not an instantaneous queue betweenY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170131two components (i.e., in the case where the emission and the reception of a message arenot instantaneous) or in the case where the channel is not reliable, we need to model thebehaviour of the channel. In that case, our proposal is to model the communication chan-nel like a component by using a communicating automaton. Every emission of messagefrom a component c1 to a component c2 corresponds to the reception of this message by acommunication channel between c1 and c2 and the reception of the message by the com-ponent c2 corresponds to the emission of the same message by that channel. If a failureoccurs on a channel, that failure changes the internal state of the channel and may disturbthe transmission of messages between components.Example 3. In Toynet, the connection cnij is considered as a component. This componentcan receive two failure events: cutCnij (the connection is cut) and workCnij (the connectionis reestablished). The communication channel between a control station and a switch is notconsidered as a component because this channel is instantaneous and reliable.In the following, without loss of generality, no distinction will be made between com-ponent and communication channel: their model are both based on a communicatingautomaton. The notation ci will refer to the ith component (or channel) of the systemand the notation Γi will refer to the model of ci .4.3. Model of a systemIn this subsection, the decentralised model of a system Γ = {c1, . . . , cn}, where eachbehaviour of component ci is represented by a model Γi , is formally given. Before definingthe model of a supervised system, we formally define the model of one of its subsystems.4.3.1. Model of a subsystemand ij ∈ {1, . . . , n}.A subsystem is a set of k components γ = {ci1, . . . , cik} from the system where k (cid:1) nDefinition 3 (Model of a subsystem). The model of the subsystem γ = {ci1, . . . , cikset of automata {Γi1, . . . , Γik}.} is theBased on the previous definition of a subsystem, several sets of events are introduced.rcv is the set of received events of the subsystem γ :Σ γ(cid:1) (cid:2)(cid:3)(cid:4)(cid:1) (cid:2)Σ γrcv(cid:2)ijrcvΣ(cid:3)Σijemit.j ∈{1,...,k}j ∈{1,...,k}There are two types of received events: Σ γrcv ∩ Σexo) and Σ γin γ (Σ γwhose source is a component which is not in γ (Σ γexo (cid:2) Σ γexo is the set of exogenous events that occurcom_rcv is the set of communication events received by γcom_rcv (cid:2) Σ γrcv \ Σ γexo).Σ γemit is the set of emitted events of the subsystem γ :(cid:1) (cid:2)(cid:3)(cid:4)(cid:1) (cid:2)Σ γemit(cid:2)Σijemitj ∈{1,...,k}j ∈{1,...,k}(cid:3)ijrcvΣ.132Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170In the set of emitted events Σ γemit is included the set Σ γobs of observable events emittedby γ . The emitted events that are not observable correspond to communication eventstowards components that do not belong to the subsystem and are noted Σ γcom_emit.Σ γint is the set of internal events of the subsystem γ :(cid:3)(cid:3)(cid:1) (cid:2)(cid:1) (cid:2)Σ γint(cid:2)Σijemit∩ijrcvΣ.j ∈{1,...,k}j ∈{1,...,k}An internal event in the subsystem γ is a communication event associated to two compo-nents of the subsystem: it belongs to the set of emitted events of the first component and tothe set of the received events of the second one. The set {Σ γ} is a partition ofthe events occurring in γ .emit, Σ γrcv, Σ γint4.3.2. Synchronisation operation in a subsystemThe model of a subsystem represents the propagation of failure events (exogenousevents) inside the subsystem as well as events emitted by components that do not be-long to the subsystem. It is possible to compute the explicit behaviour of the subsystemthanks to a synchronisation operation applied to the component models {Γi1, . . . , Γik} ofthe subsystem.The synchronisation operation is based on a transition system product [1]. As it is donein [1] and for the sake of simplicity in the product definition, some null transitions (notede|{}−→ q) are systematically added to each state q of each communicating automaton.qSuch a transition means that a component may stay on a given state while other com-ponents evolve (asynchronism). Given those transitions, the behaviour of a subsystem canbe exhaustively represented by a synchronised product, even if the subsystem has finiteasynchronous behaviours.Definition 4 (Free product). The free product of m communicating automata Ti =(Ii, Oi, Qi, Ei), i ∈ {1, . . . , m} is the communicating automaton (I, O, Q, E) such that:• I = I1 × · · · × Im;• O = O1 × · · · × Om;• Q = Q1 × · · · × Qm is the set of states;• E = E1 × · · · × Em is the set of transitions(q1, . . . , qm)(t1,...,tm)−−−−−−−−→ (q(cid:7)1, . . . , q(cid:7)m) = (q1t1−→ q(cid:7)1, . . . , qmtm−→ q(cid:7)m).In the following, such a product will be noted by (cid:9)T1, . . . , Tm(cid:10). By definition of this(cid:10) where {j1, . . . , jm} is a permutationproduct, (cid:9)T1, . . . , Tm(cid:10) is isomorphic to (cid:9)Tj1, . . . , Tjmof {1, . . . , m}.Definition 5 (Synchronised transition). Given {Γi1, . . . , Γikγ , the transition qsynchronised iff:t−→ q(cid:7) = (qi1ti1−→ q(cid:7)i1tik−→ q(cid:7)ik, . . . , qik} the model of the subsystem(cid:10) is) of the product (cid:9)Γi1, . . . , ΓikY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170133• tj is null for all j ∈ {i1, . . . , ik}, or• the three following conditions hold:(1) ∃tj , j ∈ {i1, . . . , ik} such that rcv(tj ) ∈ Σ γrcv;(2) card({tj , j ∈ {i1, . . . , ik} | rcv(tj ) ∈ Σ γexo}) (cid:1) 1;(3) for each j of {i1, . . . , ik} such that tj is not null,(a) ∀e ∈ emit(tj ) ∩ Σ γ(b) ∀rcv(tj ) ∈ Σ γint, ∃l ∈ {i1, . . . , ik} | e = rcv(tl);int, ∃l ∈ {i1, . . . , ik} | rcv(tj ) ∈ emit(tl).Condition 1 means a synchronised transition qt−→ q(cid:7) can only be triggered by a set ofreceived events on the subsystem γ . Condition 2 means that, among these events, only onecan be exogenous (event from Σ γexo) in accordance with Hypothesis 1. The conditions 3(a)t−→and 3(b) describe the synchronisation rules for internal events inside γ occurring in qt−→ q(cid:7), an internal event is emitted by an automaton Γj of γ towards anotherq(cid:7). If, in qt−→ q(cid:7) andautomaton Γl of γ , this event has to appear as a received event of Γl in qvice-versa. These conditions represent a propagation of events in the subsystem γ .A synchronised transition qt−→ q(cid:7) is thus associated to the sets of events:(1) Rcv(t) is the set of received events which triggers the transition;(2) Int(t) is the set of internal events that occur in γ when the transition is triggered;(3) Emit(t) is the set of emitted events that are emitted outside γ when the transition istriggered, among them, Obs(t) is the set of observable events.Note 3. In the following, a synchronised transition qfollows:Rcv(t)/Int(t)Emit(t)−−−−−−−−−−→ q(cid:7).qt−→ q(cid:7) will be sometimes written asExample 4. Fig. 6 shows an example of synchronised transitions in the subsystem{CS1, SW1ctl, SW1cn} of Toynet. The event SW1brk is exogenous (the switch breaksdown). When this event occurs, an event SW1toreboot is produced between SW1ctl andFig. 6. Synchronised transition in the subsystem {CS1, SW1ctl, SW1cn}.134Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170CS1 (the control station CS1 knows that the switch SW1 has to reboot). An observableevent SW1down is also emitted. The connection-part of the switch SW1 (called SW1cn)triggers a null transition. The transition on the right is the synchronisation of the threetransitions in the left.Based on this notion of synchronisation, the behaviour of the subsystem γ can be for-mally defined as follows.Definition 6 (Behaviour oftem γ = {ci1, . . . , cik(cid:9)Γi1, . . . , Γikset of synchronised transitions of E.the subsystem). The explicit behaviour of the subsys-} is the finite state machine (I, O, Q(cid:7), E(cid:7)) from the free product(cid:10) = (I, O, Q, E) such that Q(cid:7) ⊆ Q is the set of states and E(cid:7) ⊆ E is the}In the following, the result of the synchronised product of the automata {Γi1, . . . , Γik(cid:13). By extension, we will also denote the explicit behaviour} is the model of γ .will be noted by (cid:13)Γi1, . . . , Γikof every subsystem γ by (cid:13)γ (cid:13) where {Γi1, . . . , ΓikBy definition, the behaviour of a subsystem only composed of one component ci is thecommunicating automaton Γi itself: every transition t of any automaton Γi respects theconditions of a synchronised transition (Rcv(t) = {rcv(t)}, Int(t) = ∅, Emit(t) = emit(t)and Obs(t) = obs(t)), hence Γi = (cid:13)Γi(cid:13) = (cid:13)ci(cid:13).The behaviour (cid:13)γ (cid:13) of any subsystem γ is a communicating automaton and can be thusconsidered like the model of a component. Moreover, a subsystem, being defined by aset of components, can also be defined by a set of subsystems γ1, . . . , γm. Modelling asubsystem by a set of component models or by a set of subsystem behaviours is equivalentbecause of the following property on the automata synchronisation.Theorem 1. Let γ1 and γ2 be two disjoint subsystems, then(cid:13)γ1 ∪ γ2(cid:13) =(cid:5)(cid:5)(cid:13)γ1(cid:13), (cid:13)γ2(cid:13)(cid:5)(cid:5).Proof. See Appendix A. (cid:1)This property shows that the synchronisation is an associative and commutative opera-tion. Considering any partition of the set of components that defines a subsystem γ , eachpartition element is also a subsystem. The behaviour (cid:13)γ (cid:13) can be obtained by synchronisingthe behaviours from every subsystem that the partition defines.In the following, we will also use the notion of path in a subsystem defined as follows.Definition 7 (Transition path). A transition path P in a subsystem γ is a sequence (possi-bly infinite) of consecutive transitions of (cid:13)γ (cid:13).In the following, |P | will denote the length of P if P is finite and the value ∞ otherwise.Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–1701354.3.3. Decentralised model of the systemThe system Γ = {c1, . . . , cn} is a particular subsystem. This subsystem receives onlyevents from the environment and only emits observable events. Here is the definition of itsmodel.Definition 8 (Model of the system). The model of the system Γ is the model of the subsys-tem {c1, . . . , cn} modelled by {Γ1, . . . , Γn}.The behaviour of Γ , noted (cid:13)Γ (cid:13), is called the global model of the system. By definition,every synchronised transition of the global model is triggered by one exogenous event(see conditions 1 and 2 in the synchronised transition definition) and expresses the conse-quences of this event inside the system (emission of observable events, change of internalstate).Example 5. Toynet is modelled by a set of 12 components: one per control-station, one perconnection between switches and two per switches (the control-part of the switch SWictland the connection-part of the switch SWicn). The global model of Toynet is a communi-cating automaton which contains 8000 states and 76000 transitions.5. Diagnosis of the system5.1. Observable behaviourFrom the model, we can define the observable behaviour of any subsystem γ . Infor-mally, the observable behaviour corresponds to the set of all the sequences of observableevents that the subsystem can emit towards the supervision system. Here is the formaldefinition.tm−→ qm+1 · · · a path of tran-Definition 9 (Observable behaviour). Given P = q1sitions from (cid:13)γ (cid:13), the observable behaviour of P (noted Obsγ (P )) is the partially orderedset of observable events produced by P . The corresponding partial order relation is definedas follows:t1−→ · · ·(cid:6)(cid:7)1, . . . , |P |∀i ∈, ∀j ∈ {1, . . . , i − 1}, ∀oj ∈ Obs(tj ), ∀oi ∈ Obs(ti), oj ≺ oi.The observable behaviour of the subsystem γ is the set of observable behaviours fromall the paths of (cid:13)γ (cid:13).By definition, the observable behaviour of the system is the observable behaviour of thesubsystem Γ .Example 6. Fig. 7 presents the observable behaviour corresponding to a path P . In thisexample, the emission of o2 and o3 is not ordered. The observable behaviour correspondsto two possible observable sequences: o1o2o3o4 or o1o3o2o4.136Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170Fig. 7. Observable behaviour of a path P .5.2. Observed behaviourAn observation is the reception by the supervision system of a message emitted bythe system through an observation channel. Thus, every observation corresponds to anobservable event of the system. The problem is that, because of the existence of observationchannels between the supervised system and the supervision system, the order of receptionof messages by the supervision system is not necessarily the order of the emissions of thesemessages by the system. In other words, given the sequence σγ of received observationsfrom any subsystem γ , a set of emission orders are possible, depending on the natureand the number of the observation channels between the subsystem γ and the supervisionsystem.In order to deal with this problem, two solutions are possible. In the first one, the setof observation channels is modelled with the supervised system with the help of commu-nicating automata just as we do for communication channels. In that case, the observablebehaviour of the model corresponds exactly to the observed behaviour, the difference be-tween emission and reception from observation channels being described inside the model.The problem of this solution is that the size of the model can dramatically increase. Thesecond solution consists in guessing the order of emission on-line. In that case, it is notnecessary to model the observation channels. Given their properties (message propagationdelays inside an observation channel, potential synchronisations between two observationchannels, . . . ), it is possible to define a partial order relation between two observations re-ceived from γ so that we know the possible orders of their emission by γ . In the following,such a solution is considered.Definition 10 (Observed behaviour). Given the sequence σγ of received observations fromany subsystem γ , the observed behaviour Oγ = (σγ , ≺γ ) of the subsystem γ is a partiallyordered set composed of the observations of σγ with a partial order relation ≺γ on them.The partial order relation is induced by the characteristics of the observation channelson a subsystem. With the help of Hypothesis 3, if we consider any subsystem γ onlycomposed of one component emitting observable events, then γ is associated with onlyone instantaneous or bounded FIFO observation channel. In that case, Oγ is totally ordered.Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170137Fig. 8. Observed behaviour Oγ .Moreover, the partial order relation on observations has the following properties: given twodisjoint subsystems γ1 and γ2 and their respective relations ≺γ1 and ≺γ2 , given the relation≺γ1∪γ2 on the subsystem γ1 ∪ γ2, we have:∀o, o∀o, o(cid:7) ∈ Oγ1 , o ≺γ1 o(cid:7) ∈ Oγ2 , o ≺γ2 o(cid:7) ⇒ o ≺γ1∪γ2 o(cid:7) ⇒ o ≺γ1∪γ2 o(cid:7)(cid:7).Some new orders can also be defined between observations from γ1 and γ2 by ≺γ1∪γ2 ,expressing characteristics between observation channels from γ1 and γ2.Example 7. Fig. 8 depicts an observed behaviour. In this example, let consider that a sub-system γ is observed with the help of two observation channels. The observation channelsconvey the observations o1 and o2 (for channel 1), and o3 and o4 (for channel 2). Thereceived sequence is σγ = o3o1o2o4. The two observation channels are FIFO so o1 ≺γ o2and o3 ≺γ o4. Moreover, if we know that the maximal propagation delay of channel 1 is dand the times t2 (reception of o2) and t3 (reception of o3) are such that 0 (cid:1) t3 < t2 − d, itfollows that o3 ≺γ o2.5.3. Definition of the diagnosisAs said in Section 2.2.2, the diagnosis problem consists in identifying failure events(modelled as exogenous events) and their propagations (modelled as sets of communica-tion events) which explain the observed behaviour of the system. Such a failure propagationin the system is represented by a path of transitions from (cid:13)Γ (cid:13). A path explains an observedbehaviour if its observable behaviour is compatible with the observed behaviour. This com-patibility is defined below as an operator (cid:17) between two partially ordered sets.Definition 11. Given S1 = (E, ≺1) and S2 = (E, ≺2) two partially ordered sets, the jointset S1 (cid:17) S2 is the partially ordered set (E, ≺12) where ≺12 is recursively defined by∀e1, e2 ∈ E, e1 ≺12 e2 (cid:2)(e1 ≺1 e2 ∨ e1 ≺2 e2) ∨(cid:9)(cid:8)∃e3 ∈ E | e1 (cid:19)= e3 (cid:19)= e2 ∧ (e1 ≺12 e3 ∧ e3 ≺12 e2).The joint set of two sets S1 and S2 contains the same elements as S1 and S2 but the orderrelation is more restrictive. Informally, the joint set is the partially ordered set whose linear138Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170Fig. 9. Joint set Obsγ (P ) (cid:17) Oγ .extensions4 exactly correspond to the intersection of the linear extensions of the observablebehaviour and the observed behaviour.Example 8. Fig. 9 depicts the joint set of Obsγ (P ) from Fig. 7 and Oγ from Fig. 8.Oγ brings a new constraint to Obsγ (P ) (o3 ≺γ o2) so that the joint set Obsγ (P ) (cid:17) Oγrepresents the unique sequence o1o3o2o4.Such a set may not exist. Based on the relations ≺1 and ≺2, the relation ≺12 is notdefined for all ≺1 and ≺2 relations: for example, if e1 ≺1 e2 and e2 ≺2 e1, ≺12 is a relationsuch that e1 ≺12 e2 ∧ e2 ≺12 e1, and as a consequence, the relation ≺12 is not an orderrelation (not antisymmetric). In the case where we cannot define an order relation ≺12, therelations ≺1 and ≺2 are said to be incompatible and S1 (cid:17) S2 does not exist.Example 9. If in Fig. 8, the relation o4 ≺γ o2 is added, then, because o2 ≺ o4 in Obsγ (P ),Oγ and Obsγ (P ) (Fig. 7) are incompatible.With the help of this operator, here is the formal definition of the diagnosis of a system,called global diagnosis.Definition 12 (Global diagnosis). Given the decentralised model of the system Γ , givenOΓ the observed behaviour of the system, the global diagnosis ∆(OΓ ) is the set of pathsP of (cid:13)Γ (cid:13) explaining OΓ , i.e., such that ObsΓ (P ) (cid:17) OΓ exists.This definition expresses the fact that a diagnosis is a set of behaviours constrainedby the observations OΓ . Each path of the diagnosis is a possible explanation of the ob-servations. This explanation contains the sequence of failure events that have potentiallyoccurred on the system and their propagations in the system.5.4. Presentation of the result to the supervisorThe diagnosis, like defined in the previous section, contains the complete and necessaryinformation to understand what has happened in the system. In that sense, a diagnosiscan be seen as a database which is updated on-line. However, this information can betoo complex to be given to the supervisor on-line. When the supervisor is monitoring thesystem, the information he needs can be only the list of primary failures for instance. This4 A linear extension (also called linearisation) of a partially ordered set is a sequence of the elements of the setsuch that if e1 ≺ e2 then e1 is before e2 in the sequence.Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170139information is just an abstraction of the complete diagnosis and can be easily computed atthe same time.Once the supervisor wants to deeply analyse the reason why a particular failure hasoccurred (off-line analysis), he will query for the set of behaviours that could explain thefailure. For example, in the MAGDA project (see Section 9), this query is implementedwith the help of a graphical user interface representing the topology of the supervisednetwork. This interface provides a way to browse the behaviours that are related to theparticular failure and to project them in the topology presented by the interface, so thatthe supervisor is able to see the failure propagations directly on a representation of thetopology of the supervised system. The implementation of such an interface is only basedon simple searches in graphs and does not need the use of complex algorithms.5.5. ConclusionIn the framework of supervision of large discrete event systems the diagnosis infor-mation has to be rich. Not only the identification of the failures is needed but also theirpropagations in the system are important because they can explain every emitted alarm.This is particularly true in applications like the supervision of telecommunication net-works. As a consequence, the diagnosis must summarise those propagation of failures,it is why such a definition is proposed for the diagnosis of a given dynamic system. Thisdefinition, as a set of sequences, can be compared to the definitions given in [2,6].Because the computed diagnosis information is very rich, an ergonomic interface has tobe implemented in order to help the supervisor. The purpose of the interface is to extractpertinent information for on-line analysis (list of failures, . . . ) and to offer the possibilityto deeply analyse off-line the behaviours that are related to the diagnosed failures.Using a centralised approach like [23,25] or any approach which needs the explicitcomputation of the global model (cid:13)Γ (cid:13) [8,27] is problematic. Because (cid:13)Γ (cid:13) is based on aCartesian product, its size is in the worst case exponential to the number of componentsin the system. Computing the global model of a system which contains more than onehundred components is thus impossible with common computer resources. Thus, using acentralised approach for computing the diagnosis of such a system is impossible due to theintractable size of the global model. It is the reason why we propose an approach whichrelies on component models and does not require the explicit computation of the globalmodel (cid:13)Γ (cid:13).6. Decentralised diagnosis approachThe proposed decentralised approach is based on the divide and conquer principle. Be-cause the computation of a diagnosis based on the global model is impossible, the problemis divided so that smaller diagnoses are computed on smaller models (component models).These diagnoses are then progressively merged to obtain subsystem diagnoses and finallythe global diagnosis of the system.140Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–1706.1. Subsystem diagnosisThe subsystem diagnosis definition is a generalisation of the global diagnosis defini-} is to explain the set oftion. The purpose of the subsystem diagnosis of γ = {ci1, . . . , cikobservations emitted by γ using the model of the subsystem γ .Definition 13 (Subsystem diagnosis). Given γ a subsystem, given Oγ the observed be-haviour of this subsystem, the subsystem diagnosis ∆γ (Oγ ) is the set of paths P of (cid:13)γ (cid:13)explaining Oγ , i.e., such that Obsγ (P ) (cid:17) Oγ exists.Every path of the subsystem diagnosis provides an explanation of the observations fromthis subsystem. This explanation is local, in other words, this explanation does not takeinto account the behaviour of the components that do not belong to γ . Each explanationmakes the hypothesis that every message, exchanged with a component that do not belongto γ , is possible. By definition, the diagnosis of the subsystem Γ is the global diagnosisitself.6.2. Merging operationAs said in the previous subsection, the subsystem diagnoses make the hypothesis thatevery message exchange is possible between two subsystems. The purpose of the merg-ing operation is to check if such exchanges are possible or not, according to the globalmodel of the system. This check consists in synchronising every path of a subsystem di-agnosis with every path of the other subsystem diagnoses. The merging operation is basedon Theorem 2. Before presenting this theorem, the notion of path synchronisation is intro-duced.Given γ1, γ2 two disjoint subsystems and P1, P2 two transition paths belonging to(cid:13)γ1(cid:13) and (cid:13)γ2(cid:13) respectively, the notation (cid:13)P1, P2(cid:13) will denote the set of paths resultingfrom the synchronisation of P1 and P2. Formally, (cid:13)P1, P2(cid:13) could be obtained firstly bysynchronising the set of transitions from (cid:13)γ1(cid:13) that occur in P1 with the set of transitionsfrom (cid:13)γ2(cid:13) that occur in P2 and secondly by extracting from this synchronised finite statemachine the set of paths P such that every transition of P1 and P2 is triggered in P inthe same order as in P1 and P2. By construction, every path of (cid:13)P1, P2(cid:13) is a path of(cid:13)(cid:13)γ1(cid:13), (cid:13)γ2(cid:13)(cid:13) = (cid:13)γ1 ∪ γ2(cid:13). Moreover, the set of paths (cid:13)P1, P2(cid:13) may be empty; in this case,the paths P1 and P2 are not synchronisable. The notation is extended to a set of pathsP1, . . . , Pm on a set of disjoint subsystems γ1, . . . , γm: (cid:13)P1, . . . , Pm(cid:13) will denote the set ofpaths resulting from the synchronisation of the paths Pi , the set of paths being obtained inthe same manner as the set (cid:13)P1, P2(cid:13).Theorem 2. Given γ1 and γ2 two disjoint subsystems,P ∈ ∆γ1∪γ2 (Oγ1∪γ2) ⇔∃P1 ∈ ∆γ1 (Oγ1 ) ∧ ∃P2 ∈ ∆γ2(Oγ2 ) ∧ P ∈ (cid:13)P1, P2(cid:13)∧ Obsγ1∪γ2(P ) (cid:17) Oγ1∪γ2 exists.Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170141Proof.(⇐) P1 ∈ ∆γ1 (Oγ1 ) and P2 ∈ ∆γ2 (Oγ2 ) so P1 ∈ (cid:13)γ1(cid:13) and P2 ∈ (cid:13)γ2(cid:13). P ∈ (cid:13)P1, P2(cid:13),so P ∈ (cid:13)γ1 ∪ γ2(cid:13) by construction. Obsγ1∪γ2(P ) (cid:17) Oγ1∪γ2 exists, therefore P ∈∆γ1∪γ2(Oγ1∪γ2 ).(⇒) P ∈ ∆γ1∪γ2 (Oγ1∪γ2) so Obsγ1∪γ2(P ) (cid:17) Oγ1∪γ2 exists. By definition, P is a path from(cid:13)γ1 ∪ γ2(cid:13). This path can be obtained from the synchronised product (cid:13)(cid:13)γ1(cid:13), (cid:13)γ2(cid:13)(cid:13) (seeTheorem 1), thus there are some paths P1 from (cid:13)γ1(cid:13) and P2 from (cid:13)γ2(cid:13) such thatP ∈ (cid:13)P1, P2(cid:13).Suppose for the sake of contradiction that Obsγ1(P1) (cid:17) Oγ1 does not exist. Therefore,P1 explains all the observations of Oγ1 but in an order which is incompatible withthe order of Oγ1 . In other words, there exist at least two different observations o1and o2 such that o1 ≺ o2 in Oγ1 and o2 ≺ o1 in Obsγ1(P1). If o1 ≺ o2 in Oγ1 , theno1 ≺ o2 in Oγ1∪γ2 (Definition 10). Moreover, if o2 ≺ o1 in Obsγ1(P1) then o2 ≺ o1 inObsγ1∪γ2 (P ) (Definition 9). Consequently, Obsγ1∪γ2 (P ) (cid:17) Oγ1∪γ2 does not exist.The existence of Obsγ2(P2) (cid:17) Oγ2 can be shown in the same manner. Finally, theexistence of Obsγ1∪γ2 (P ) (cid:17) Oγ1∪γ2 implies the existence of Obsγ1 (P1) (cid:17) Oγ1 andObsγ2 (P2) (cid:17) Oγ2 , so P1 and P2 respectively belong to ∆γ1 (Oγ1 ) and ∆γ2 (Oγ2 ). (cid:1)Corollary 1. Given {γ1, . . . , γm} a set of subsystems which is a partition of the set ofcomponents of the system Γ :P ∈ ∆Γ (OΓ ) ⇔(cid:10)(cid:12)m(cid:11)i=1∃Pi ∈ ∆γi (Oγi )∧ P ∈ (cid:13)P1, . . . , Pm(cid:13) ∧ ObsΓ (P ) (cid:17) OΓ exists.Proof. Because of Theorem 2,P ∈ ∆Γ (OΓ ) ⇔∃P1,...,l ∈ ∆(cid:13)li=1 γi∧ P ∈ (cid:13)P1,...,l, Pl+1,...,m(cid:13) ∧ ObsΓ (P ) (cid:17) OΓ exists.) ∧ ∃Pl+1,...,m ∈ ∆(cid:13)(O(cid:13)li=1 γimi=l+1 γi (O(cid:13)mi=l+1 γi )The result is obtained by applying recursively the same theorem on P1,...,l and Pl+1,...,mand by noticing that, by construction, if two paths P2 and P3 respectively belong to(cid:13)P4, P5(cid:13) and (cid:13)P6, P7(cid:13) then a path P1 belongs to (cid:13)P2, P3(cid:13) iff the path P1 belongs to(cid:13)P4, P5, P6, P7(cid:13). (cid:1)6.3. SummaryWe have defined a formal framework for the decentralised diagnosis approach (seeFig. 10). The model of the system Γ is represented in a decentralised way as a set ofcommunicating automata {Γ1, . . . , Γn} and a synchronisation operation. The idea is thento compute the diagnosis for each component ci (corresponding to the more basic sub-systems) based on its model Γi and then to progressively merge the results in order toobtain diagnoses on bigger subsystems and finally to obtain the global diagnosis. Within142Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170Fig. 10. Centralised/decentralised approach.this framework, due to the fact that the synchronisation is an associative and commutativeoperation, we have the guarantee that, by merging the subsystem diagnoses in any order,the result is the same and is the global diagnosis (see Corollary 1).7. On-line diagnosis implementationThis section presents the implementation of the decentralised diagnosis approach basedon a decentralised model of the system. In order to make an on-line diagnosis approach,the algorithms must be efficient and based on an efficient representation of the diagnoses.Firstly, partial order reduction techniques are shown to be well-suited for efficiently rep-resenting the diagnoses. Secondly, a merging operation strategy, taking into account theinteractions of the subsystem diagnoses dynamically, is presented.7.1. Diagnosis representation7.1.1. Finite representationIn the framework, the diagnosis ∆γ (Oγ ) is defined as a set of paths of transitions of(cid:13)γ (cid:13). A path may be infinite because of an infinite sequence of silent transitions (in thebehaviour (cid:13)γ (cid:13), such sequences are represented by loops of unobservable transitions). Be-cause of the merging operation, a finite representation of the diagnosis is needed. Thisrepresentation is based on a finite state machine which also represents infinite silent se-quences by loops. Here is the definition of this representation.Let (cid:13)γ (cid:13) = (I, O, Q, E) be the behaviour of the subsystem γ . Let σγ be a finite ob-servation sequence and Oγ = (σγ , ≺γ ) be the corresponding observed behaviour. Con-tm−→ qm+1 · · ·sider every transition path P from ∆γ (Oγ ), P is such that P = q1ti−→ qi+1 ∈ E, i ∈ {1, . . . , m}. Consider a transitionwhere qi ∈ Q, i ∈ {1, . . . , |P |} and qit1−→ · · · ti−1−→ qi the sub-path of P from q1 to qi , the stateqiqi can thus be represented by the state qfiniteγ is the ob-γ is the prefix sequence of σγ such that Obsγ (Pi) (cid:17) Oiserved behaviour (σ iγti−→ qi+1 of P and Pi = q1= (qi, Obsγ (Pi) (cid:17) Oiγ , ≺γ ) where σ iγ ) where Oit1−→ · · ·iY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170143i= (qi+1, Obsγ (Pi+1) (cid:17) Oi+1γ always exists because Obsγ (P ) (cid:17) Oγ exists by defi-expresses the fact that the state qi is a possible current state of (cid:13)γ (cid:13) afterγ . The state qi+1 is then associated to theti−→ qi+1 is thus representedexists. Such a set Obsγ (Pi) (cid:17) Oinition. qfinitethe explanation of the observed behaviour Oistate qfinitei+1by qfiniteiLet Qfinite be the set of states qfinite defined as above for every path from ∆γ (Oγ ), byconstruction Qfinite is a finite set (Qfinite ⊆ Q × P r(Oγ ), where P r(Oγ ) is the set of par-tially ordered sets containing a subset of the elements of Oγ ). Let Efinite be the set of tran-sitions qfinitei+1 defined as above for every path from ∆γ (Oγ ), Efinite is also finiteby construction. Qfinite and Efinite define a finite representation of the diagnosis ∆γ (Oγ ).). The transition qiti−→ qfinitei+1 .ti−→ qfiniteγiDefinition 14 (Finite representation). Let (cid:13)γ (cid:13) = (I, O, Q, E) be the behaviour of the sub-system γ , the finite representation of ∆γ (Oγ ) is the finite state machine ∆finite(Oγ ) =(I, O, Qfinite, Efinite) where Qfinite and Efinite are respectively the set of states and transi-tions defined above.γThe diagnosis of ∆γ (Oγ ) can be represented by ∆finite(Oγ ) (see Fig. 11). The statesqfinite ∈ Qfinite such that qfinite = (q, ∅) are called the initial states of the diagnosis. Accord-ing to the observations, the subsystem γ could have been in one of these states q beforethe emission of any observable event. The states qfinite ∈ Qfinite such that qfinite = (q, O)with |O| = |Oγ | are called the final states of the diagnosis. According to the observations,the subsystem γ is in one of these states q.γNevertheless, the representation has a problem: its size. Each path of ∆finite(Oγ ) rep-resents a path of diagnosis, i.e., a sequence of events. Because of the distributed nature ofthe diagnosed systems, a lot of events (failure events) may occur in a concurrent way, sodealing with sequences means enumerating the sequences where a failure event f1 occursindependently before an event f2 and where f2 occurs before f1. From a diagnosis pointof view, because f1 and f2 are independent, if they occur both, it is not important to knowabout the order. It is the reason why, a reduced representation of the diagnosis has beenintroduced. This reduction is based on a partial order reduction method [18].γ7.1.2. Partial order reductionIn the following, a summary of partial order reduction theory is given. For more details,see [5,16,18]. We will call an action a transition label from any behaviour (cid:13)γ (cid:13) and theset of (cid:13)γ (cid:13) actions will be noted Aγ . We will also note enq the set of actions that can betriggered from the state q in (cid:13)γ (cid:13).Definition 15 (Independence). Two actions t1 and t2 from Aγ are independent in (cid:13)γ (cid:13) =(I, O, Q, E) iff ∀q ∈ Q, if t1, t2 ∈ enq(1) t1 ∈ enq(cid:7) where q(2) ∃q(cid:7), q(cid:7)(cid:7), q(cid:7)(cid:7)(cid:7) such that qt2−→ q(cid:7) ∈ E;t2−→ q(cid:7)t1−→ q(cid:7)(cid:7) ∈ E ∧ qt1−→ q(cid:7)(cid:7)(cid:7)t2−→ q(cid:7)(cid:7) ∈ E.144Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170Fig. 11. Subsystem diagnosis represented by ∆finiteOγ = {CS1ok ≺ SW1cn12 ≺ SW1cn12}.γ(Oγ ) where γ = {Cn12, SW1cn, SW1ctl, CS1} andIntuitively, two actions are independent if the occurrence of one of them does not affectthe occurrence of the other one (condition 1). Moreover, the order in which those actionscan occur does not change the state after both occurrences (condition 2).Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170145Definition 16 (Dependence relation). A dependence relation D is a reflexive, symmetric,binary relation such that ∀(t1, t2) ∈ D, t1 and t2 are not independent.This relation induces an equivalence relation between finite sequences of actions. Giventwo finite sequences v, w of actions from A(cid:6)γ , v is equivalent to w according to the re-lation D iff there exists a set of sequences {u0, . . . , un} such that v = u0, w = un and∀i ∈ {0, . . . , n − 1}, ui = ¯ut1t2 ˆu ∧ ui+1 = ¯ut2t1 ˆu where ¯u, ˆu ∈ A(cid:6)γ and (t1, t2) /∈ D.Example 10. Given v = u0 = t1t2t3t4t5t6, w = u3 = t2t1t3t5t6t4, and (t1, t2), (t4, t5),(t4, t6) /∈ D, we haveu0 = t1t2t3t4t5t6,u1 = t2t1t3t4t5t6 (t1, t2 permutation),u2 = t2t1t3t5t4t6 (t4, t5 permutation),u3 = t2t1t3t5t6t4 (t4, t6 permutation),so v is equivalent to w according to D.This equivalence relation can be extended to infinite sequences. Given two infinite se-γ , v and w are equivalent iff for any finite prefix sequence v(cid:7) of v therequences v, w from A(cid:6)exists a finite prefix sequence w(cid:7) of w such that w(cid:7) is equivalent to v(cid:7) and vice versa. Thisextended relation (for the finite and infinite cases) is called the partially ordered relation.This relation is noted ≡D.Definition 17 (Trace). Given a dependence relation D, a trace is an equivalence class ofsequences defined by the relation ≡D.Thus, a trace represents a set of sequences. Each sequence of the class can be obtainedfrom another one by simply swapping the order of adjacent and independent actions. If sis such a sequence, we note by [s]D the corresponding trace in which s is included.7.1.3. Reduced representationThe principle of the reduced diagnosis representation is the following. The diagnosismust represent a set of action sequences, so the idea is to only keep one sequence of eachtrace that must be represented in a given diagnosis. In order to do that, a dependence rela-tion Dγ between transition labels from (cid:13)γ (cid:13) must be defined. This relation must describewhat the dependence of two labels is.Before giving the definition of Dγ , some notations have to be introduced. Given t ∈ Aγ ,Et (cid:2) Rcv(t) ∪ Emit(t) ∪ Int(t) is the set of events that occur in γ when t is triggered. Givenany subsystem γ (cid:7) disjoint of γ , Cγ (cid:7) (t) (cid:2) {ci ∈ γ (cid:7)|Et ∩ Σ i(cid:19)= ∅} is thercvset of components that are directly affected by the transition t in γ (cid:7).(cid:19)= ∅ ∨ Et ∩ Σ iemitDefinition 18 (Relation Dγ ). Given t1 and t2 in Aγ , (t1, t2) ∈ Dγ iff one of the followingconditions holds:146Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170(1) CΓ \γ (t1) (cid:19)= ∅ ∧ CΓ \γ (t2) (cid:19)= ∅;(2) Cγ (t1) ∩ Cγ (t2) (cid:19)= ∅;(3) (Obs(t1) (cid:19)= ∅ ∨ CΓ \γ (t1) (cid:19)= ∅) ∧ (Obs(t2) (cid:19)= ∅ ∨ CΓ \γ (t2) (cid:19)= ∅) ∧ (Obs(t1) (cid:19)= Obs(t2) ∨CΓ \γ (t1) (cid:19)= ∅ ∨ CΓ \γ (t2) (cid:19)= ∅).Intuitively, the relation Dγ describes the three criteria of dependence between two tran-sition labels t1 and t2. Condition 1 says that if t1 and t2 can affect components from Γ \ γ ,they are dependent because they are part of fault propagations unknown in γ . Condition 2says that t1 and t2 are dependent if they affect common components in γ . Condition 3 isabout the observability of t1 and t2. From a diagnosis point of view, t1 and t2 are also de-pendent, if they are or could be observable (due to future synchronisations with observabletransitions from other subsystems) and the set of emitted observations is not the same.Because the relation Dγ is just a relation based on events, its computation does notdepend on the number of states and transitions of γ , so it is efficient. As a consequence,we can detect on-line if the pair of actions (t1, t2) belongs to Dγ or not.Theorem 3. The relation Dγ is a dependence relation.Proof. By definition, Dγ is symmetric and reflexive. Now, we have to prove that for any(t1, t2) /∈ Dγ , t1 and t2 are independent (see Definition 15). Let q denote a state of (cid:13)γ (cid:13) andt1, t2 be two transitions such that t1, t2 ∈ enq .Condition 1 Suppose that qt2−→ q(cid:7) is a transition of (cid:13)γ (cid:13). Because (t1, t2) /∈ Dγ , it fol-lows that Cγ (t1) ∩ Cγ (t2) = ∅, so t1 affects components in γ different from thecomponents affected by t2. If t2 is triggered from q, the states of the componentsaffected by t1 are thus unchanged. Therefore, t1 ∈ enq(cid:7) .Condition 2 Because Cγ (t1) ∩ Cγ (t2) = ∅, t1 affects components in γ different from thecomponents affected by t2. Thus, the order of activation of t1 and t2 does notchange the final state. (cid:1)Remark 1. The relation Dγ is not the unique dependence relation. There are more accuratedependence relations. Nevertheless, the advantage of Dγ is the low cost for checking thedependency of two actions: the check is only based on communication events and does notrequire a deeper and more expensive on-line analysis of the model.Given the dependence relation Dγ , the reduced representation of the diagnosis of γ isdefined as follows.Definition 19 (Reduced representation). The reduced representation of the diagnosis∆γ (Oγ ) is a finite state machine ∆redγ (Oγ ) = (I, O, Q(cid:7), E(cid:7)) such that:• ∆finite(Oγ ) = (I, O, Q, E);γ• Q(cid:7) ⊆ Q is the set of states;Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170147• E(cid:7) ⊆ E is the set of transitions such that every trace [t1, . . . , tm]Dγ of ∆finitefrom an initial state to a final state is represented by one transition path q0q1 · · · qm−1tm−→ qm in ∆redγ (Oγ ).γ(Oγ )t1−→Remark 2. There are several reduced representations of a diagnosis: it is due to the factthat any sequence of a trace is a good candidate for representing the trace.The notions of initial states and final states in the reduced representation are defined inthe manner as in the finite representation (see Section 7.1.1). The set of final states does notexplicitly represent the set of current states of the subsystem as in the finite representation.However, this set of current states is implicitly represented, each final state representinga set of current states of γ that are equivalent according to the dependence relation. Thisimplicit way of representation is also true in the case of the initial states.Fig. 12 presents the reduced representation of the diagnosis of Fig. 11. The transi-tion t1 = {CS1off }/{}{} and t2 = {CS1reboot}/{}{} are independent from t3 = {cutCn12}/{. . .}{. . .} and t4 = {workCn12}/{. . .}{. . .}. We have (t1, t3), (t2, t3), (t1, t4), (t2, t4) /∈ Dγ .Each path from an initial state to a final state represents a trace of events.7.2. Subsystem diagnosis computationThe first step of the decentralised diagnosis approach consists in computing a set of nsubsystem diagnoses from the n components ci . This computation consists in exploringthe model Γi in order to compute traces that explain the observations Oci . This explorationis possible because of the tractable size of every Γi automaton so that the problem ofthe subsystem diagnosis computation can be solved by using any centralised diagnosisapproach. Moreover, we assume the observation channel between a component and thesupervision system is either instantaneous or a bounded FIFO queue (see Section 2.2.1), itfollows that the computation does not have to take into account the problem of observationovertaking inside the channel. Depending on the system, some components may not beobservable at all, in that case the subsystem diagnosis is isomorphic to the model of thecomponent itself and no computation is needed.In order to be efficient, it is possible to use a diagnoser approach [25]. This data struc-ture is a transition system where each transition is labelled with observations and eachstate contains a pre-compilation of diagnosis information so that it improves the diagnosiscomputation on-line. More details about this approach can be found in [19,21].7.3. Merging algorithmThis section presents the merging operation between two diagnoses ∆redγ1(Oγ2 ) in order to compute ∆red(Oγ1 ) and∆red(Oγ1∪γ2) (see Algorithm 1). The proposed algo-γ2rithm is inspired from the algorithm proposed in [18] which consists in finding runs witha deadlock in a program by checking independences between actions to avoid the state-explosion problem during the search. The proposed algorithm is a decentralised version ofthe previous algorithm, updated to solve diagnosis problems.γ1∪γ2148Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170Fig. 12. A reduced representation of the diagnosis from Fig. 11.Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170149Algorithm 1 (Merging operation).(O1), ∆redγ21 , ∅) ∈ ∆redγ11 , q0(O2), Oγ1∪γ2(O1), (q02 , ∅) ∈ ∆redγ22 ), ∅); sleep(X0) ← ∅; explored(X0) ← ∅; unreliable(X0) ← ∅(O2) two initial states dotraces ← VisitState(X0); PropagateFixedStates(traces)for X ∈ StatesOf (traces) doif Status(X) (cid:19)= fixed then Remove(X, traces) end1: Inputs: ∆redγ12: for Given (q03: X0 = ((q04:5:6:7:end8: ∆red9: end10: Output: ∆redγ1∪γ2(Oγ1∪γ2) ← ∆redγ1∪γ2(Oγ1∪γ2) ∪ tracesγ1∪γ2(Oγ1∪γ2)t ← Remove(trans(X)); explored(X) ← explored(X) ∪ {t}X(cid:7) ← Target(X, t)newSleep ← (sleep(X) ∪ explored(X)) \ (unreliable(X) ∪ dependent(t))if ¬visited(X(cid:7)) thenexplored(X(cid:7)) ← ∅; unreliable(X(cid:7)) ← ∅; sleep(X(cid:7)) ← newSleepopen(X(cid:7)) ← true; paths ← paths ∪ VisitState(X(cid:7))11: Function VisitState(X)12: visited(X) ← true13: trans(X) ← GiveTransitionsFrom(X) \ sleep(X)14: while trans(X) (cid:19)= ∅ do15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:else if ∃t ∈ sleep(X(cid:7)) such that t /∈ newSleep thenexplored(X(cid:7)) ← ∅; unreliable(X(cid:7)) ← ∅;if ¬open(X(cid:7)) thenendif status(X(cid:7)) ∈ {possible, fixed} ∨ open(X(cid:7)) thentrans(X(cid:7)) ← trans(X(cid:7)) \ sleep(X(cid:7))endelsesleep(X(cid:7)) ← sleep(X(cid:7)) ∩ newSleepopen(X(cid:7)) ← true; paths ← paths ∪ VisitState(X(cid:7))paths ← paths ∪ {Xif open(X(cid:7)) then unreliable(X(cid:7)) ← unreliable(X(cid:7)) ∪ {t} endif status(X) (cid:19)= fixed thent−→ X(cid:7)}if status(X(cid:7)) ∈ {possible, fixed} then status(X) ← status(X(cid:7))else status(X) ← possible end31:32:33:34:35:37:38:39: end40: if IsFinal(X) then status(X) ← fixed end41: open(X) ← false42: return pathsendend150Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170The merging operation has two purposes:(1) interaction validation: events between γ1 and γ2 diagnosed by the diagnoses ∆redγ1(Oγ1 )and ∆redγ2(Oγ2 ) have to be checked;(2) reduced diagnosis computation: the result of the merging operation must be a reducedrepresentation of the diagnosis of γ1 ∪ γ2.In order to assure (1), the merging operation must check for any trace (a set of paths)of one diagnosis if this trace can be synchronised with a trace of the other diagnosis (seeSection 6.2). In order to assure (2), every merged path has to represent a trace of (cid:13)γ1 ∪ γ2(cid:13)according to the dependence relation Dγ1∪γ2 .The merging operation assures (2) with the help of the following property.Proposition 1. Given γ and γ (cid:7) two disjoint subsystems, given t1, t2 ∈ Aγ two actions of(cid:13)γ (cid:13), if (t1, t2) /∈ Dγ then we have:∀t(cid:7)1, t(cid:7)2∈ Aγ (cid:7) ,(cid:8)(t1, t(cid:7)1) ∈ Aγ ∪γ (cid:7) ∧ (t2, t(cid:7)2) ∈ Aγ ∪γ (cid:7)(cid:9)⇒(cid:8)(t1, t(cid:7)1), (t2, t(cid:9)(cid:7)2)/∈ Dγ ∪γ (cid:7) .In other words, the defined relation Dγ guarantees that if there are two independentactions t1 and t2 in (cid:13)γ (cid:13), then every couple of actions from (cid:13)γ ∪ γ (cid:7)(cid:13) based on the actionst1 and t2 is also independent. This property is guaranteed by the definition of Dγ (seeDefinition 18). If (t1, t2) are not in Dγ , it means that the actions t1 and t2 do not interactwith actions of γ (cid:7) at all (they are associated to null events from γ (cid:7)). So the way t1 and t2can be enabled in the subsystem γ ∪ γ (cid:7) does not change, they are still independent. On theother hand, some couples (t1, t2) of Dγ may be associated to actions t (cid:7)2 of γ (cid:7) so that((t1, t (cid:7)2)) may be independent in γ ∪ γ (cid:7).1), (t2, t (cid:7)1, t (cid:7)Thanks to Proposition 1, the merging operation does not have to retest independent ac-(Oγ2 ). It has just to detect new independent actionstions computed in ∆redγ1from the subsystem γ1 ∪ γ2 to compute ∆red(Oγ1 ) and ∆redγ2γ1∪γ2(Oγ1∪γ2 ).(O1), ∆redγ2The algorithm is a depth-first search algorithm based on the search space defined by(cid:9)∆red(O2)(cid:10) (see Algorithm 1). Each explored state X is built on the fly byγ1synchronising transitions from ∆red(O2). This synchronisation is done byγ11, q(cid:7)GiveTransitionsFrom (line 13). Formally, given the notations (q1, q2)2),the function GiveTransitionsFrom(X) where X = ((q1, q2), O12) is defined as the set oftransition labels t such that:t=(t1,t2)−−−−−−→ (q(cid:7)(O1) and ∆redγ2(1) (q1, Indγ1 (O12))t1−→ (q(cid:7)1, O(cid:7)1) ∈ ∆redγ1(O1) where Indγ1 (O12) is the partially orderedset induced from O12 which contains all the observations from O12 emitted by γ1;(2) (q2, Indγ2 (O12))t2−→ (q(cid:7)2, O(cid:7)2) ∈ ∆redγ2(O2) where Indγ2 (O12) is the partially orderedset induced from O12 which contains all the observations from O12 emitted by γ2;(3) (q1, q2)t−→ (q(cid:7)1, q(cid:7)2) ∈ (cid:13)γ1 ∪ γ2(cid:13);Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170151(4) there exists O(cid:7)γ1∪γ212such that Obsγ1∪γ2 (P .(q1, q2)where P is a transition path from (q0subset of Oγ1∪γ2 such that ∀o1, o2 ∈ O1 , q0(cid:7)γ1∪γ212(cid:7)γ1∪γ2t−→ (q(cid:7)122 ) to (q1, q2) in (cid:13)γ1 ∪ γ2(cid:13) and O2)) (cid:17) O1, q(cid:7)exists,(cid:7)γ1∪γ2is a12iff o1 ≺ o2 in Oγ1∪γ2 ., o1 ≺ o2 in O(cid:7)γ1∪γ212Conditions 1 and 2 mean that the transition label t effectively results from the productof a transition from ∆redγ1(O1) and a transition from ∆redγ2(O2).Condition 3 means that the result of the synchronisation effectively belongs to the be-haviour of γ1 ∪ γ2. Condition 4 means that t has an observable behaviour compatible witht−→ (q(cid:7)1, q(cid:7)the observations to explain. If conditions 1, 2, 3 and 4 hold then (q1, q2)2)t−→necessarily belongs to a path of the diagnosis ∆γ1∪γ2 (Oγ1∪γ2) and ((q1, q2), O12)((q(cid:7)1, q(cid:7)γ1∪γ2Every explored state X has some associated data structures:12) is a potential candidate for belonging to ∆red(Oγ1∪γ2 ).2), O(cid:7)• explored(X) is the set of actions that have been already explored from the state X;• sleep(X) is the set of actions to avoid when exploring X;• unreliable(X) is the set actions which may be avoided;• status(X) can be fixed (X belongs to a path which represents a trace) or possible (Xmay belong to a path which represents a trace, that will depend on the status of thesuccessors of X), status(X) is initialised with a value different from fixed and possible;• visited(X) is true iff X has been or is being explored;• open(X) is true iff X has to be explored.The computation of the sleep set is based on the independence property of actions. Theset dependent(t) (line 17) is the set of actions that are dependent of t in (cid:13)γ1 ∪ γ2(cid:13) giventhe relation Dγ1∪γ2 on these actions. The principle of the algorithm is to explore actionsthat are not in sleep(X) (line 13). An action t in sleep(X) is such that t has been alreadyexplored from a predecessor X(cid:7) of X and all actions from X(cid:7) to X are independent of t. Ifa trace exists for t from X, this trace has been already computed by exploring t from X(cid:7)(for more details, see [18]). In line 21, a cycle has been detected during the search, if theold sleep set contains an action which is not in the new one, the state has to be revisitedotherwise some traces could be lost.A state X is fixed if X is guaranteed to belong to a trace of ∆redγ1∪γ2(Oγ1∪γ2 ). There existtwo cases for fixing a state X.(1) IsFinal(X) is true (line 40), then the algorithm has detected a path from X0 to X whichis the representative of one trace. Given X = (q, O12) IsFinal(X) is defined by:IsFinal(X) ≡O12 = Oγ1∪γ2∧(cid:8)∃qt (cid:7)−→ q(cid:7) ∈ (cid:13)γ1 ∪ γ2(cid:13) such that Obsγ1∪γ2(qt (cid:7)−→ q(cid:7)) (cid:19)= ∅(cid:9).In other words, X is final if it can explain all the observations and if there exists abehaviour from q in (cid:13)γ1 ∪ γ2(cid:13) which is observable.(2) A successor of X is fixed (line 34).152Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170γ1∪γ2The set paths contains a set of transitions which represents traces from X to final statesof ∆red(Oγ1∪γ2). Once X0 has been visited (line 4), traces contains traces from X0 tofinal states of ∆red(Oγ1∪γ2). Because of cycles, some states in traces are not fixed butonly possible. In order to know if one of these states has to be finally fixed or not, one of itssuccessors in traces must have a fixed status. PropagateFixedStates is in charge of fixingthose states (line 4). Some states might stay with a possible status (they belong to cycleswhich are not part from any traces), they must be eliminated (lines 5–7).γ1∪γ2In the following, this merging operation implemented by Algorithm 1 is noted (cid:25), so wehave:∆redγ1∪γ2(Oγ1∪γ2) = ∆redγ1(Oγ1 ) (cid:25) ∆redγ2(Oγ2 ).As it is said in Remark 2, there are several reduced representations of a diagnosis. Due tothe fact that the (cid:25) is based on a search in a state-space the result can be different dependingon the order of merging. Nevertheless, even if the results are different, they are both areduced representation of the same diagnosis. With (cid:25), we guarantee that the result (a setof traces) is given by using any order of merging the subsystem diagnoses.7.4. Merging strategyThe merging operation is based on a Cartesian product on subsystem diagnoses. As aconsequence, this operation can be very inefficient and has to be used carefully. In orderto be as efficient as possible, the idea is to only apply the merging operation when it isnecessary. It is the reason why a merging strategy is needed. This merging strategy is basedon several criteria defined on the subsystem diagnoses to merge. In this section, we alwaysconsider the reduced representation of a diagnosis, but for the sake of clarity, diagnosisnotations are simplified: ∆γi will refer to ∆redγi(Oγi ).7.4.1. DefinitionsEach subsystem diagnosis ∆γi contains traces which claim that the diagnosed com-ponents from γi have interacted with other components by sending or receiving events(γj ) the set of events of γi that are supposed to havebelonging to Σint. We note by I∆γibeen sent to or received from the components of γj according to the subsystem diagno-sis ∆γi .Definition 20 (Inconsistent traces). A trace in a diagnosis ∆γi is inconsistent iff thereexists a transition in the trace representative which assumes the emission or the receptionof an event e ∈ I∆γi(γi).(γj ) such that e /∈ I∆γjA diagnosis ∆γi may claim that an event e belongs to I∆γi(γj ) whereas ∆γj may claimthat e is not in I∆γj(γi). Traces of ∆γi that claim the occurrence of e are said to be incon-sistent: they will not participate to the global diagnosis and can be immediately discardedfrom the diagnosis.In the following, we call purged diagnosis of γi , the set of traces of ∆γi from whichinconsistent traces have been eliminated and note it by ∆(cid:7)γi.Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170153Definition 21 (Matchable subsystems). γi and γj are matchable subsystems iffI∆γi(γj ) ∩ I∆γj(γi) (cid:19)= ∅.From this definition, it can be deduced that γi and γj are matchable iff their purged(γi) (cid:19)= ∅. In the follow-(γi) = I∆γidiagnoses are such that I∆(cid:7)γiing, we will say that γi and γj are k-matchable subsystems iff they are matchable and|I∆(cid:7)(γi)| = k.γiThe purpose of the strategy is to detect and compute subsystem diagnoses that claim no(γj )| = |I∆(cid:7)γj(γj ) = I∆(cid:7)γj(γi)| = |I∆γi(γj ) ∩ I∆γj(γj ) ∩ I∆γjinteraction with other subsystems.Definition 22 (Independent diagnosis). A subsystem diagnosis ∆γ is independent iffI∆γ (Γ \ γ ) = ∅.In an independent diagnosis, every trace is a complete explanation of the observationsof the consider subsystem: for the set of observations of the system, it is impossible to findan explanation where the subsystem has interacted with other subsystems. Every trace ofan independent diagnosis shows that any observation from another disjoint subsystem isnot caused by a reaction of this subsystem. If an independent diagnosis is detected then it isuseless to perform any merging operation on it, the set of interactions to check being empty.Therefore, the global diagnosis is totally and easily represented by a set of independentdiagnoses, each diagnosis based on a subsystem disjoined from the others. In the worstcase, there is only one independent diagnosis: the global diagnosis.7.4.2. Principles and algorithmTo improve the efficiency of the merging operation, we apply the two following princi-ples (see Algorithm 2) based on the previous definitions..(1) Detecting and eliminating inconsistent traces. Inconsistent traces uselessly increasethe cost of the merging operation. The first principle consists in detecting and elimi-nating them before performing any merging operation (lines 5–12). Given a diagnosis∆γi of the current diagnoses set, the events that are sources of inconsistent traces aredetermined and the elimination is then performed in order to finally obtain the purgeddiagnosis ∆(cid:7)γi(2) Giving priority to the most matchable subsystems. The merging of two diagnoses al-lows to eliminate some traces by checking the interactions which are claimed by them.Thus, merging two diagnoses which do not claim any interaction between their respec-tive components is not really interesting: the second principle consists in avoiding thisuseless computation and in giving priority to the most matchable subsystems. Thus,the second stage of the algorithm consists of the computation of sets kInter(γi) (lines14–17). Each element of kInter(γi) is a couple (γj , |I∆(cid:7)(γj )|) meaning that γi and γjγi(γj )|. The merging strategy then builds partition ofare k-matchable where k = |I∆(cid:7)γidiagnoses (with ChoosePartition line 20) such that:154Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170• a part has two diagnoses at the most;• selected diagnoses are such that the set of exchanged events claimed by those diag-noses is as big as possible.Once a partition of diagnoses is chosen, the diagnoses of each element of the partition(only elements which contain two diagnoses) are merged (line 21), this operation canbe done in a parallel way. A new set of diagnoses is obtained where one diagnosis isassociated to each element of the partition. The set of possible exchanged events isupdated according to the new diagnoses set. Then, the algorithm iteratively proceedsby eliminating new inconsistent traces in the new diagnoses set and then by buildingthe best new partition of diagnoses and merging it. The last stage of the algorithmproduces a set of independent diagnoses. The traces of every diagnosis of the resultedset participate to a global trace. In other words, the global diagnosis can be explic-itly built by applying new merging operations on this set, but every trace from anyindependent diagnosis is synchronisable with any trace from any other independentdiagnosis.Algorithm 2 (Merging strategy).)}}(γi))∆(cid:7)γi, I∆γi← ∆γi(γj ) \ I∆γj← ElimInconsTraces(∆(cid:7)γiendReplace(D, ∆γi , ∆(cid:7)γi∆(cid:7)γifor j ∈ {1, . . . , l}, j (cid:19)= i do{We note D = {∆γ1 , . . . , ∆γl1—Inconsistent trace eliminationfor i ∈ {1, . . . , l} do1: Input: Decentralised model {Γ1, . . . , Γn} of the system {c1, . . . , cn}2: Input: Subsystem diagnoses {∆ci , i ∈ {1, . . . , n}}3: D ← {∆ci , i ∈ {1, . . . , n}}4: do5:6:7:8:9:10:11:12:13:14:15:16:17: M ← {kInter(γi), i ∈ {1, . . . , l}}18:19:20:21:22:end23: while M (cid:19)= ∅24: { The set D is a set of independent diagnoses }25: Output: D3—Applying the merging operationπD ← ChoosePartition(D, M)(cid:25) ∆(cid:7)D ← {∆(cid:7)γjγiend2—Looking for matchable subsystemsfor i ∈ {1, . . . , l} dokInter(γi) ← {(γj , |I∆(cid:7)γi} ∈ πD} ∪ {∆(cid:7)γi(γj )|), I∆(cid:7)γiif M (cid:19)= ∅ then(γj ) (cid:19)= ∅}} ∈ πD}, {∆(cid:7)γi, {∆(cid:7)γi, ∆(cid:7)γjendY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–1701558. IncrementalityIn on-line diagnosis approaches, the purpose is to follow the observed behaviour andto provide a diagnosis as often as possible. Given a time t1 when a diagnosis has beenprovided, it is interesting to take into account this diagnosis in order to provide anotherdiagnosis at time t2 (t1 < t2), given a new set of observations that occur between t1 andt2. This section focuses on this topic. The idea is to propose an incremental diagnosisalgorithm by extending and updating the diagnosis of time t1 in order to compute the diag-nosis of time t2 as efficiently as possible. This problematic is called incremental diagnosis(see [20]).8.1. Principles and difficultiesIncremental diagnosis is based on two basic concepts.Definition 23 (Breakpoint). A breakpoint tj is a date from the supervision system clock.Definition 24 (Temporal window). A temporal window Wj is the delay between two con-secutive breakpoints tj and tj +1.The flow of observations belongs to a set of consecutive temporal windows Wj , j ∈{1, . . . , m} (see Fig. 13). Given a temporal window Wj , the set of received observationsin Wj is noted in the following OWj and the set of observations received before Wj isnoted Oj −1. The incremental diagnosis is then the problem of computing the diagnosis∆j explaining the observations Oj given the diagnosis ∆j −1 (which explains Oj −1) andthe observations OWj .Fig. 13. Temporal windows and breakpoints.156Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170As already mentioned, the supervision system receives a flow of observations duringone temporal window Wj . The problem is that there are some delays between the emissionof the messages in the observation channels and their receptions in the supervision system(see Fig. 13). Consequently, some messages emitted during Wj may not be received duringWj . Another more problematic consequence is that at the end of Wj there is no guaranteethat the supervision system has received enough observations to make a diagnosis. In fact,some messages may not have been received whereas they have been emitted before otherreceived messages; this situation is possible if the unreceived messages are conveyed byobservation channels with important delays of transmission.The choice of the temporal windows is, therefore, fundamental. The update of a di-agnosis ∆j −1 strongly depends on the nature of the chosen temporal window Wj . In thefollowing subsections, two incremental algorithms are discussed, based on some propertiesabout the chosen temporal windows.8.2. Sound temporal windowsIn this approach, the solution consists in choosing sound temporal windows.Definition 25 (Sound window). A breakpoint tj is sound iff every message emitted beforetj is received before tj . A temporal window Wj is sound iff tj and tj +1 are sound.A sound breakpoint is interesting because it guarantees that the set of messages emittedbefore this point is effectively received by the supervisor (see Fig. 14). In other words, asound breakpoint guarantees that ∀o ∈ Oj −1, ∀o(cid:7) ∈ Oj \ Oj −1, o ≺ o(cid:7). As a consequence,any update of the diagnosis ∆j −1, taking into account the observations Oj , is only basedon its final states.A sound breakpoint can be detected by taking into account the properties of the obser-vation channels and the date of reception of an observation by the supervisor. For instance,Fig. 14. Sound breakpoint.Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170157knowing a maximum delay Dmax of message propagation inside the observation channels,a sound breakpoint tj is detected if the first observation after this breakpoint is received bythe supervision system at time t such that t > tj + Dmax (see Fig. 14).In the following, an algorithm which computes the update of the diagnosis is presented(see Algorithm 3).Algorithm 3 (Incremental diagnosis on sound temporal windows).1: Input: BSWj −12: Input: OWj3: for i ∈ {1, . . . , n} do4:5: end6: {∆γ1 , . . . , ∆γpinitial(ci) ← ExtractStates(BSWj −1, ci)} ← ApplyMergingStrategy(∆c1 (initial(c1), OWjcn ), BSWj −1)∆cn (initial(cn), O}7: Output: ∆Wj = {∆γ1 , . . . , ∆γp8: Output: BSWj ← FinalStates(∆γ1 , . . . , ∆γp , BSWj −1)Wjc1 ), . . . ,The notation BSWj represents the belief state of the system.5 Such a belief state rep-resents the set of global states in which the system could be after the observations OWj .Given BSWj −1 , a set initial(ck) corresponding to the possible initial states of the componentck at breakpoint tj is computed by extracting them from BSWj −1 . Then, the diagnosis ofWjck explaining the observations emitted by ck and received during Wj (noted Ock ) fromWjthe states initial(ck) is computed (this diagnosis is noted ∆ck (initial(ck), Ock )). Then themerging operation is applied and a set of independent diagnoses is computed. This mergingoperation is applied according to the strategy defined in Section 7.4.2 and depends on thecurrent belief state BSWj −1 . Once the diagnosis ∆Wj is computed, all the observations Ojare explained and we can extract from the new set of diagnoses the new belief state BSWjwhich will be used for the next temporal window.Once the diagnosis ∆Wjis computed, all the observations Oj are explained. Nev-ertheless, the diagnosis ∆j is not totally computed. The explanation of OWj may haveinvalidated some traces in ∆Wj −1 (it may be impossible to find an explanation of the newobservations from a given final state of ∆Wj −1 ) and therefore in ∆j −1. In order to explicitlyobtain ∆j , given ∆j −1 and ∆Wj , we must eliminate from ∆j −1 all the traces that have nofuture in ∆Wj and append ∆Wj to the new ∆j −1 (see [20] for more details). This operationis made by a refinement operation noted ⊕. So we have:∆j = ∆j −1 ⊕ ∆Wj .From a practical point of view, ∆Wj is the interesting information in a context of moni-toring; the supervising agent wants to know what have just happened in the system. Thus,5 The computation of the belief state is not the topic of this paper. For efficiency purposes, its representation issymbolic and uses binary decision diagrams [4].158Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170applying the refinement operation during the on-line diagnosis is not necessary. Refine-ment operation is only required when a deeper analysis of the diagnosis is performed, sothis operation can be applied off-line (see Section 5.4).8.3. General caseIn the treated example which derives from a real application (see Section 9), the hy-pothesis of sound windows can be applied without loss of generality. In this application,the alarms are instantaneously emitted and received when a problem occur. A problemcauses a large packet of alarms at a given time, so it is easy to define a sound temporalwindow that surrounds this packet. So the algorithm previously defined can be used tosolve the problem. Nevertheless, in theory, sound windows may not exist and this sectiondescribes this general case where the given temporal windows are arbitrarily chosen (see[20] for more details).The purpose of the incremental diagnosis is to always provide a diagnosis for a giventemporal window, thus the method in the general case must take into account two kinds ofobservations:(1) the observations that have effectively been received;(2) the observations that have been emitted but are not received yet.If Algorithm 3 is used on an unsound temporal window, some explanations in the result-ing diagnosis may be missing. In fact, the merging operation assumes that every emissionof message in the observation channels is effectively received, so explanations that requirethe emission of observable events which have not been received yet, are not computed.In the worst case, it is possible that the only explanations of a given set of observationsare based on the fact that messages are still in the observation channels, in that case, thealgorithm 3 is unable to provide any explanation. In the general case, in order to providea diagnosis for each temporal window, the unreceived messages must be guessed, someobservations have to be supposed uncertain [12]. In this context, a new diagnosis structuremust be defined that allows to represent traces under the hypothesis of emitted but un-received observations. This structure is called extended diagnosis. Basically, an extendeddiagnosis has the same representation of a diagnosis except that an extended diagnosis stateX is formed as a couple (q, O) where O may contain unreceived observations that are alsoexplained. The set of final states of an extended diagnosis, which corresponds to the ex-Wj⊆ O. The computationext , is composed of states (q, O) where OWjtended belief state BSof an extended diagnosis needs the following hypothesis.Hypothesis 5. Every observation channel from a component to the supervision system isbounded by a known number “capacity”.In fact, if the size of the channel was unknown, an extended diagnosis would have toguess an unknown number of unreceived observations.The incremental diagnosis algorithm in the case of unsound temporal window is ob-tained by replacing in Algorithm 3 the use of diagnoses (resp. belief states) by the useY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170159of extended diagnoses (resp. extended belief states). There are two main differences. Onedifference is on the computation of the initial(ck) sets (line 4). Instead of extracting statesof ck from every state of the previous extended belief state, we have to only extract themfrom a subset of it: the interesting states are only the ones which are compatible with thenew set of received observations (observations that have been supposed to be received andthat have been effectively received). The second difference is on the computation of theWjextended diagnoses of components (line 6). For some ck, some observations of Ock havebeen already explained in the previous temporal window, it follows that it is not necessaryto do it again, secondly, some assumptions must have been made about possible unreceivedobservations at the end of Wj in order to achieve the extended diagnosis computation.As far as the refinement operation is concerned, the operator is the same and we have:∆jext= ∆j −1ext⊕ ∆Wjext .8.4. Relation between diagnosis and extended diagnosisWith the help of the extended diagnosis notion, it is still possible to provide a diag-nosis for any temporal window. The extended diagnosis also assures that no explanationis missing. In fact, by definition, an extended diagnosis represents a set of explanationsthat explain not only the received observations but also a set of possible unreceived ob-servations. If there is an explanation of the received observations which does not requireassumptions about unreceived observations, then this explanation is contained in the ex-tended diagnosis. As a consequence, it can be easily shown that, for any breakpoint tj , wehave:∆j ⊆ ∆jext.Moreover, if we have the guarantee that, after a given temporal window Wj , the breakpointtj +1 is sound then no assumption about unreceived events is required. In that case, it canbe shown that:∆j = ∆jext.This is especially the case when tj +1 is the date when the supervised system stops working.9. Experimental resultsFor testing the approach above, we have used a model of a telecommunication networkcoming from the project MAGDA. This model is based on a real SDH network (Synchro-nous Data Hierarchy) and it has been defined during the collaboration between academicand industrial partners of the MAGDA project.9.1. SDH networkThe studied network is a ring of 4 ADM multiplexers (ADM: Add and Drop Multi-plexer) (see Fig. 15). Each multiplexer is located in a different town of the area Ile de160Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170Fig. 15. Topology of the SDH network: a ring of 4 ADMs.Fig. 16. Montrouge add and drop multiplexer.France: Aubervilliers, Gentilly, Montrouge, and St Ouen. Whereas the Aubervilliers ADMonly transmits data from Gentilly to St Ouen and vice versa, the other ADMs have connec-tions with clients of the network via PDH and STM1 connections.This network is managed with the help of managed objects which are defined in theSDH norms. Each object corresponds to a functionality of a part of a multiplexer. Fig. 16presents the 23 managed objects associated to the multiplexer of Montrouge. These objectstake into account that the SDH protocol is hierarchical (from SPI (Synchronous PhysicalInterface) to LOP (Low Order Path)). Globally, the network is composed of 72 managedobjects, each object behaviour is modelled by a communicating automaton; the globalY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170161Fig. 17. Montrouge: model of the component au3CTP.centralised model, if it was explicitly built by the free product of these automata, wouldhave about 5.6 × 1047 states.Each managed object can emit some alarms if it detects a problem. It can also emitalarms if it receives messages from other managed objects. In particular, if an object froma ADM x detects a problem, it emits a message to the same objects from the other ADMsy and z where y and z are the neighbours of x. Fig. 17 shows the model which describesthe au3CTP component on the Montrouge site. The problems that can occur on this com-ponent are modelled by AisFail, AisBack (problem of alarm indication signal), LopFail,LopBack (loss of pointer). Such problems can also occur on other sites, the componentdetects those problems by the reception of messages from the msTTP neighbour such asauAIS, auAISclrd, auAISinhib. This information is propagated to tu12CTP with the helpof events like tuAIS, tuAISclrd. The observations emitted by this component (in bold) areDbled (Disabled), Ebled (Enabled), auAIS and LOP.9.2. ResultsDuring the MAGDA project, 8 scenarios of faults have been defined. A scenario con-sists of a set of failures that occur in the network and the set of alarms that are observedin reaction of these failures. These scenarios have been defined in order to characterisetypical faulty situations, in particular, some scenarios contain multiple faults and masking162Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170phenomena (scenarios S5 and S8). We have experimented our approach by diagnosing eachscenario from each set of alarms using our diagnostic tool DDyp [21]. For these experi-ments, we have considered that the set of observed alarms corresponds to a sound temporalwindow.9.2.1. Results on the merging strategyTable 1 presents the time of computation needed for diagnosing the different scenarios ifwe use a unique machine (Pentium III 1 Ghz) (computation of the subsystem diagnoses andthe global diagnosis, no parallel computation has been used in this experiments for bettercomparisons, see [21] for details on parallel computations). Based on the set of receivedalarms, for each scenario, our approach finds the failures defined in the scenario but also itfinds out other failure scenarios that can explain the same observations.In order to show that the strategy we propose is fundamental in a decentralised ap-proach, Table 1 presents a comparison between the results from 4 different strategies. Thefirst strategy is the one computed with the help of Algorithm 2. The second strategy isthe same as the first one, except that the merging order is such that two non-matchablediagnoses are merged. The third strategy consists in merging like in strategy 1 but withouteliminating incompatible traces before the merging. The fourth strategy is like the strat-egy 2 but without eliminating incompatible traces before the merging.Strategy 1 shows that the on-line diagnosis computation is possible on the SDH networkwhen we are dealing with typical diagnosis situation (single and multiple failures). Strategy2 shows the choice in the merging ordering is important and has to take into account inter-actions between subsystem diagnoses. For better comparisons, strategy 2 merges the samediagnoses as strategy 1 but in a different order. Therefore, strategy 2 is defined according tostrategy 1. In practice, if we do not care about interactions at all, such a strategy is unable todetermine independent diagnoses so the time of computation can strongly increase becauseTable 1Diagnosed scenarios with different strategies of mergingScenariosS1: Laser failure(St Ouen)S2: AU3 failure(Aubervilliers)S3: Laser failure(Gentilly)S4: RS failure(Aubervilliers)S5: Multiple failures(S3 with S4)S6: BER failure(Aubervilliers)S7: RS failure(Gentilly)S8: Multiple failures(S6 and S7)ObservedalarmsStrategy 1Strategy 2Strategy 3Strategy 42442614361114213 s 590 ms4 s 200 ms16s 540 ms>5 mn1 s 300 ms1 s 300 ms1 mn 53 s>5 mn1 s 780 ms1 s 910 ms>5 mn1 s 600 ms2 s 30 ms49 s>5 mn>5 mn2 s 620 ms5 s 500 ms5 s 430 ms3 mn 45 s1s 780 ms2 s 320 ms24 s 240 ms57 s 440 ms1s 480 ms1s 700 ms2 mn 55 s>5 mn1 s 830 ms3s 90 ms3 s 30 ms>5 mnY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170163the result of the strategy will be only one diagnosis. Strategy 3 shows the elimination ofthe traces a priori has a big impact on the performance of the merging operation. Strategy4 is very time-consuming. The merging of diagnoses that are not matchable correspondsto the Cartesian product. Moreover, incompatible traces are uselessly computed and theninvalidated by the merging with another diagnoses in future steps. Strategy 4 shows thattrajectory elimination and good ordering strategy have cumulative and benefit effects onthe merging operation.9.2.2. Characteristics of the computed diagnosesTable 2 presents some characteristics of the computed diagnoses by the strategy 1 forthe scenarios defined in Table 1. The characteristics are the following.• Involved comps. max: the maximal number of components that are involved in a faultpropagation.• Indep. diagnoses: the number of independent diagnoses.• Red. states max: the number of states in the biggest independent reduced diagnosis.• Red. trans. max: the number of transitions in the biggest independent reduced diagno-sis.• States max: the number of states in the biggest independent unreduced diagnosis fol-lowed by the reduction rate.• Trans. max: the number of transitions in the biggest independent unreduced diagnosisfollowed by the reduction rate.• Strategy 1 overhead: the overhead time needed by Strategy 1 to compute the diagnoseswithout any reduction.The first significant result of Table 2 is the fact that for each analysed scenario our diag-nosis system was able to detect several independent diagnoses. This is due to the fact thatthe propagation of a failure does not generally involve the whole system but only a subpartof it (the biggest involved subsystem is composed of 40 components over 72 in scenario5), the other parts behaving independently from the occurrence of the diagnosed failures.The second result presented in Table 2 is about the reduction of the diagnoses. Strategy1 has been applied to merge diagnoses without any reduction techniques in order to analyseTable 2Diagnosis characteristics: comparison of the reduced/unreduced representationsScenariosInvolved comps.maxIndep.diagnoses maxRed. statesRed. trans.maxStatesmaxTrans.maxStrategy 1overheadS1S2S3S4S5S6S7S8362328404036283626282729252727258131015361961782210143618516210/61% 609/87% 34%0%2/0%3/0%7%81/63%38/74%35/57%18%62/77%190/81% 515/93% 76%0%29/34%1%9/33%8%35/51%45/60%11/54%53/70%164Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170the impact of the reduction of the diagnoses. The reduction percentages are important andshow that the set of components of the system have a high degree of concurrency (inde-pendent behaviours) that are detected by our dependence relation. Moreover, the mergingof the reduced diagnoses is more efficient than the merging of the non-reduced ones. Themain reasons are that, firstly, the merge of two unreduced diagnoses needs to explore abigger state-space and, secondly, the computation of the dependence relation is efficientenough. It results that the overhead for reducing is neglectable.9.3. Complexity discussionResults about the efficiency merging operation have been presented relying on a realand complex large system. The merging operation is efficient in this example because itbenefits from different approaches that are combined and well-suited. In this section, aninformal discussion about the complexity of the merging operation is presented.Firstly, the merging operation is based on the divide and conquer paradigm and exploitsits efficiency. In this case, this paradigm is efficient because the set of behaviours diag-nosed locally is usually very small compared to the number of possible local behaviours.This fact is true if the diagnosed system has good observability properties (lot of differ-ent observation types, very few unobservable components) and the temporal windows aresmall enough. Moreover, with good observability properties in the system, we expect thatthe global diagnosis is exponentially smaller that the global behaviour.The second reason of the merging operation efficiency is the strategy. The purpose ofthe strategy is to minimise the computations by avoiding the merging of independent di-agnoses that is complex (Cartesian product) and useless. The representation of the globaldiagnosis thanks to the set of independent diagnoses is exponentially smaller (relativelyto the number of independent diagnoses) than the representation of the global diagnosisas a unique finite-state machine. In large systems, independent diagnoses exist because afailure does not usually propagate its consequences on all the components of the systembut on a subpart of it.The third reason of its efficiency is the use of partial order techniques. Those tech-niques are well-known in model-checking to exponentially reduce the complexity of aspace search algorithm in the good cases. A good case is a system with a lot of indepen-dent events in it which is typically the case of the systems we consider. The partial-ordertechniques are efficient if a trade-off is found between the amount of detected independentevents during the search and the complexity of the algorithm to detect these independences.In our case, the independence are detected in a local and incremental manner (during eachmerging operation) with a detection algorithm which is constant and does not consequentlycreate any overhead in the merging algorithm.10. Related workThere are several works which propose a framework for the decentralised diagnosisof discrete event systems. In [8], the authors propose a monitoring system based on thefact that the supervised system is observed by a set of sensors. The framework consistsY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170165of a set of diagnosers [25,26], each diagnoser aiming at explaining the observations fromone site. When an observation occurs on a sensor, the corresponding diagnoser updatesits diagnosis. Because the diagnoser is computed from a global model of the system, thediagnosis proposed by the diagnoser is a global diagnosis. The merge operation consistshere in exchanging messages between diagnosers in order to make a consensus of thediagnosis proposed by each diagnoser. This approach is well-suited for monitoring becausethe diagnoser approach is efficient. Nevertheless, using this approach for large discreteevent systems is not possible due to the impossibility of computing the global model of thesystem.The authors of [2] propose the framework for the diagnosis of active systems. In thisframework, based also on communicating finite state machines and communication chan-nels, the diagnosis computation consists in unfolding the set of automata given the set ofobservations. The purpose of the approach is to compute the global diagnosis (also calledactive space) as an automaton giving all the explanations. The main difference with ourwork is about the efficiency of the approach, the active space approach being an off-linetechnique: the set of observations is thus considered as complete (no incremental diagnosisproblem) and the efficiency of the method is not crucial. To compute the global diagnosis,the authors propose a modular reconstruction based on the topology of the system by firstlybuilding subsystem diagnoses and secondly merging the set of diagnoses in a hierarchicalmanner [3]. The merging strategy we propose is based on the same idea. Nevertheless, themain difference with our merging strategy is that the reconstruction plan builds, in anycases, the global diagnosis of the system. No reduction techniques are used to compute anefficient representation of the global diagnosis moreover the modular reconstruction doesnot manage the fact that some subsystems may have independent diagnosed behaviours andthat the merging of them is useless. This work has been extended for integrating synchro-nous and asynchronous behaviours in the same model in the framework of polymorphicsystems [14].Very recently, in [13], a new technique, called Continuous Diagnosis, has been proposedin order to extend the active system approach for monitoring purposes. In this approach,the authors propose to mix the diagnoser approach (well-suited for monitoring) and theactive space approach (well-suited for diagnosing large scale discrete-event systems). Themain idea is to compute on-line, from the model, the state of a finite-state machine calleda monitor that currently gives the diagnosis of the system (failure localisation). In the con-tinuous diagnosis approach, the temporal windows only consist of one observation and issupposed to be sound (like in the classical diagnoser approach [25,26]). Given a tempo-ral window, the belief state (augmented with a diagnosis information) is represented bythe current state of the monitor. When an observation occurs, the computation consists insearching for observable transitions in the model that match the observation and in com-puting the unobservable behaviour that could occur after the reception of the observation(called the silent closure in the paper). This approach assumes that the global unobservablebehaviour occuring after an observation is computable on-line. Our merging strategy withthe help of the partial reduction techniques can contribute to increase the efficiency of thesilent closure computation.Another set of works have also been proposed to monitor stochastic systems. The ideaconsists in using probability in order to only compute a set of preferred explanations (the166Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170most likely explanations generally) among the set of all explanations. As an example, in theLivingstone project [28], the system is modeled as a set of transition systems and a globalprobability distribution which rules the triggering of the transitions in the modeled system.In this framework, the purpose is to compute a belief state (the set of the most likely statesof the system) by monitoring a sequence of observations. This work has been extendedin [11] to compute also the most likely behaviours (called trajectories in the cited paper).A more recent approach is also proposed in [10]. The framework is based on a set of sto-chastic diagnoser agents which are in charge of computing the most likely local diagnosesfor the set of global observations. An agent only knows about the behaviour of one subsys-tem. The merging operation is implemented by message exchanges between several agentsin order to check diagnosis interactions but also to check if the result is likely or not. In thisframework, the idea is to never compute a global diagnosis, the local diagnoses are checkedbut in order to compute failure propagation, another computation is needed (association oflocal diagnosis). In our framework, such local diagnoses are obtained by projecting theset of independent diagnoses to the given subsystem. The approaches based on stochasticsystems are more efficient (only a subset of the complete diagnosis is computed) but theyhave also several problems. Firstly, a probability information is necessary and is difficultto acquire from a real application (the expertise is generally poor and automatic trainingmethods have to be used). Secondly, the most likely explanations of a sequence of obser-vations are not necessary the most interesting ones: the occurrence of a serious failure isgenerally unlikely. Finally, the monitoring of a system can be very inefficient due to thefact that a likely explanation for one temporal window can become very unlikely in thenext window and a backtrack is then necessary.11. Conclusion and perspectivesIn the paper we propose a framework for the on-line diagnosis of large scale discreteevent systems. Dealing with large discrete event systems implies that the use of a globalmodel is impossible. The proposed formal framework allows to model large discrete eventsystems in a modular way. Moreover, thanks to the properties of the synchronisation oper-ation (associativity and commutativity), any decentralised reasoning can be performed onthe system, following the divide and conquer paradigm.Given that framework, we then propose an on-line decentralised diagnosis approach.Because the system emits observations from several subsystems, we can divide the di-agnosis problem into several diagnosis subproblems based on a set of subsystems. Then,once those diagnoses are established, a merge operation, based on the synchronisation op-eration, is necessary to obtain the global diagnosis. The purpose of the merge operationis to build the missing information which is in the global model: interaction checking. Inorder to make an on-line diagnosis, this operation has to be efficient. For this reason, sev-eral ideas have been developed in this paper. Firstly, the diagnosis representation has to beefficient. Representation problem efficiency is due to the concurrency of the system. Ourproposal is to use partial order reduction techniques to solve the problem. The second pointis the proposal of a merging strategy. This strategy dynamically computes an efficient wayto merge the diagnoses. The basic idea is to dynamically recognise diagnostic problemsY. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170167that are independent from each other and benefit from this dynamic independence. Thisrecognition does not result from an a priori analysis, as it is usually done in the literature,but from a analysis based on observed interactions which provides more accurate results.Finally, in the context of system monitoring, being efficient also means being incremen-tal. To achieve that, we define the incremental diagnosis problem which takes advantagefrom the diagnosis previously computed to compute the new diagnosis given a new flow ofobservations.This framework has been implemented for the monitoring of telecommunication net-works [21] and has been integrated and validated in the context of the MAGDA project.The purpose of this project was to provide a complete supervision chain from the modelingof the system to the ergonomic view of failure propagations to a supervisor. The presentedframework proposes a way to model a large discrete event system, to provide, on-line,a complete diagnosis of the system. The diagnosis being exhaustive can be presented inseveral ways to a supervisor agent depending on his needs (on-line analysis, deep off-lineanalysis, . . . ) at a given time. The studied network is a real case and the promising resultsof this study have been reported in this paper.The perspective of this work are numerous. Firstly, the described framework can beused to solve the diagnosability problem. Previous works on that problem needs the com-putation of a global model, so there is no known algorithm for dealing with large scalediscrete event systems. One challenge is to propose a solution to this problem inside theproposed framework. Another problem to deal with is the reconfiguration of systems. Inthis problem, not only the diagnosis system has to deal with observations but also with on-line evolution of the system (connection reconfiguration in the case of telecommunicationnetworks). Finally, this framework could be extended to model large scale autonomoussystems by mixing diagnosis and planning approaches [28].AcknowledgementsWe thank the anonymous reviewers for their fruitful comments.Appendix A. Proof of Theorem 1Theorem 1. Let γ1 and γ2 be two disjoint subsystems, then(cid:13)γ1 ∪ γ2(cid:13) =(cid:5)(cid:5)(cid:13)γ1(cid:13), (cid:13)γ2(cid:13)(cid:5)(cid:5).Proof. Let γ1 and γ2 denote two disjoint subsystems with {Γi1, . . . , Γik}} and {Γj1 , . . . , Γjlthe respective component sets of γ1 and γ2. The behaviour of the subsystem γ1 ∪ γ2 is afinite state machine (cid:13)γ1 ∪ γ2(cid:13) = (I, O, Q, E) included in the free product(cid:9)Γi1, . . . , Γik , Γj1 , . . . , Γjl(cid:10).(cid:13)γ1(cid:13) is included in the free product (cid:9)Γi1 , . . . , Γikuct (cid:9)Γj1 , . . . , Γjl(cid:10) and (cid:13)γ2(cid:13) is included in the free prod-(cid:10). Therefore, the behaviour of the subsystem composed of the automata168Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170{(cid:13)γ1(cid:13), (cid:13)γ2(cid:13)} is by definition a finite state machine (I (cid:7), O(cid:7), Q(cid:7), E(cid:7)) included in the freeproduct:= (cid:9)Γi1, . . . , Γik , Γj1, . . . , Γjl(cid:10).(cid:14)(cid:15)(cid:10), (cid:9)Γj1 , . . . , Γjl(cid:10)Consequently, I = I (cid:7), O = O(cid:7) and(cid:9)Γi1, . . . , Γik(cid:16)Q, Q(cid:7) ⊆Qp.p∈{i1,...,ik,j1,...,jl }To prove the result, it suffices now to show that E = E(cid:7).(E(cid:7) ⊆ E) E is the set of synchronised transitions from (cid:9)Γi1, . . . , Γik , Γj1 , . . . , Γjlis the set of synchronised transitions from (cid:9)Γi1, . . . , Γik , Γj1 , . . . , Γjlproduct of transitions from (cid:13)γ1(cid:13) and (cid:13)γ2(cid:13). Therefore, E(cid:7) is necessarily contained in E.(cid:10). E(cid:7)(cid:10) resulting from the(E ⊆ E(cid:7)) Every transition T of E is as follows:tj1−→ qtik−→ qti1−→ qT = (qi1, . . . , qik, qj1(cid:7)ik(cid:7)i1, . . . , qjltjl−→ q(cid:7)jl)(cid:7)j1) a transition from (cid:9)Γi1, . . . , Γik(cid:10) and (qj1tj1−→ q(cid:7)j1, . . . ,with (qi1tjl−→ q(cid:7)jl, . . . , qiktik−→ q(cid:7)ti1−→ q(cid:7)iki1) a transition from (cid:9)Γj1, . . . , Γjl(cid:10). The transition T is synchronised. If theqjl(tj )j ∈{i1,...,ik} or the (tj )j ∈{j1,...,jl } are null, then by definition the corresponding transitionsfrom (cid:9)Γi1, . . . , Γik(cid:10) are synchronised and T is in E(cid:7).(cid:10) and (cid:9)Γj1 , . . . , ΓjlOtherwise, we have card({tj , j ∈ {i1, . . . , ik, j1, . . . , jl} | rcv(tj ) ∈ Σ γ1∪γ2exo}) (cid:1) 1. Con-sequently, we obtain(cid:8)(cid:6)(cid:8)(cid:6)cardtj , j ∈ {i1, . . . , ik} | rcv(tj ) ∈ Σ γ1exotj , j ∈ {j1, . . . , jl} | rcv(tj ) ∈ Σ γ2exoFor each non-null tj , j ∈ {i1, . . . , ik, j1, . . . , jl}, we also have:(cid:1) 1,(cid:1) 1.card(cid:7)(cid:9)(cid:7)(cid:9)(1) ∀e ∈ emit(tj ) ∩ Σ γ1∪γ2(2) ∀rcv(tj ) ∈ Σ γ1∪γ2, ∃r ∈ {i1, . . . , ik, j1, . . . , jl}, e = rcv(tr );int, ∃r ∈ {i1, . . . , ik, j1, . . . , jl} | rcv(tj ) ∈ emit(tr ).intIf j ∈ {i1, . . . , ik}, then, from (1), we obtainint, ∃r ∈ {i1, . . . , ik, j1, . . . , jl}, e = rcv(tr ).∀e ∈ emit(tj ) ∩ Σ γ1Because γ1 and γ2 are disjoint, Σ γ1Σ γ1int∩ (∀e ∈ emit(tj ) ∩ Σ γ1(cid:13)r∈{j1,...,jl } rcv(tr )) = ∅. Finally, from (1), we haveint, ∃r ∈ {i1, . . . , ik}, e = rcv(tr ).Using the same way of reasoning, the property (2) implies:∀rcv(tj ) ∈ Σ γ1Finally, we know that:int, ∃r ∈ {i1, . . . , ik} | rcv(tj ) ∈ emit(tr ).∃j ∈ {i1, . . . , ik, j1, . . . , jl} | rcv(tj ) ∈ Σ γ1∪γ2rcv.Two cases hold.int does not contain any events from the subsystem γ2, so((cid:6))((cid:6)(cid:6))Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170169(1) If j ∈ {i1, . . . , ik} then ∃j ∈ {i1, . . . , ik} | rcv(tj ) ∈ Σ γ1rcv.(2) If j /∈ {i1, . . . , ik}, suppose for the sake of contradiction that ∀j ∈ {i1, . . . , ik} |rcv(tj ) ∈ Σ γ1int. With the help of ((cid:6)) and ((cid:6)(cid:6)), it follows that the transition (tj )j ∈{i1,...,ik}represents a cyclic instantaneous propagation of events in γ1, which is impossible be-cause of Hypothesis 4, hence ∃j ∈ {i1, . . . , ik} | rcv(tj ) ∈ Σ γ1rcv.tik−→ q(cid:7)Therefore, (qi1iktjl−→ q(cid:7)(cid:13)γ1(cid:13). The fact that (qj1) is a synchronised transition and belongsjlto (cid:13)γ2(cid:13), is shown in the same manner. The transition T is thus in E(cid:7), hence the result. (cid:1)ti1−→ q(cid:7)i1tj1−→ q(cid:7)j1) is a synchronised transition and belongs to, . . . , qik, . . . , qjlReferences[1] A. Arnold, Transition systems and concurrent processes, in: G. Mirkowska, H. Rasiowa (Eds.), MathematicalProblems in Computation Theory, Banach Center, Warsaw, 1987, pp. 9–21.[2] P. Baroni, G. Lamperti, P. Pogliano, M. Zanella, Diagnosis of large active systems, Artificial Intelligence 110(1999) 135–183.[3] P. Baroni, G. Lamperti, P. Pogliano, M. Zanella, Diagnosis of a class of distributed discrete-event systems,IEEE Trans. Systems Man Cybernet. A 30 (6) (2000) 731–752.[4] R.E. Bryant, Graph-based algorithms for Boolean function manipulation, IEEE Trans. Comput. 35 (8) (1986)677–691.[5] E.M. Clarke, O. Grumberg, D. Peled, Model Checking, MIT Press, Cambridge, MA, 1999.[6] L. Console, C. Picardi, M. Ribaudo, Process algebra for systems diagnosis, Artificial Intelligence 142 (2002)19–51.[7] M.-O. Cordier, C. Dousson, Alarm driven monitoring based on chronicles, in: Proceedings of Safe-process’2000, Budapest, Hungary, 2000, pp. 286–291.[8] R. Debouk, S. Lafortune, D. Teneketzis, Coordinated decentralized protocols for failure diagnosis of discreteevent systems, J. Discrete-Event Dynamic Syst. 10 (1–2) (2000) 33–86.[9] C. Dousson, P. Gaborit, M. Ghallab, Situation recognition: representation and algorithms, in: Proceedings ofthe International Joint Conference on Artificial Intelligence (IJCAI-93), Chambéry, France, 1993, pp. 166–172.[10] E. Fabre, A. Benveniste, C. Jard, Distributed diagnosis for large discrete event dynamic systems, in: Pro-ceedings of the IFAC World Congress, Barcelona, Spain, 2002.[11] J. Kurien, P.P. Nayak, Back to the future for consistency-based trajectory tracking, in: Proceedings ofAAAI/IAAI, 2000, pp. 370–377.[12] G. Lamperti, M. Zanella, Diagnosis of discrete-event systems from uncertain temporal observations, Artifi-cial Intelligence 137 (1–2) (2002) 91–163.[13] G. Lamperti, M. Zanella, Continuous diagnosis of discrete-event systems, in: Proceedings of the Interna-tional Workshop on Principles of Diagnosis (DX’03), Washington, DC, 2003, pp. 105–111.[14] G. Lamperti, M. Zanella, Diagnosis of Active Systems, Kluwer Academic, Dordrecht, 2003.[15] J. Lunze, Discrete-event modelling and diagnosis of quantized dynamical systems, in: Proceedings of theInternational Workshop on Principles of Diagnosis (DX-99), Loch Awe, United Kingdom, 1999, pp. 147–154.[16] A. Mazurkiewicz, Basic notions of trace theory, in: J.W. de Bakker, W.-P. de Roever, G. Rozenberg (Eds.),Proceedings of the School/Workshop on Linear Time, Branching Time and Partial Order in Logics andModels for Concurrency, in: Lecture Notes in Computer Science, vol. 354, Springer, New York, 1988,pp. 364–397.[17] D. Niebur, Expert systems for power system control in western Europe, in: Proceedings of the IEEE Sym-posium on Intelligent Control, Philadelphia, USA, 1990, pp. 112–119.170Y. Pencolé, M.-O. Cordier / Artificial Intelligence 164 (2005) 121–170[18] D. Peled, All from one, one for all: on model checking using representatives, in: C. Courcoubetis (Ed.),Computer-Aided Verification, in: Lecture Notes in Computer Science, vol. 697, Springer, New York, 1993,pp. 409–423.[19] Y. Pencolé, Decentralized diagnoser approach: application to telecommunication networks, in: Proceedingsof the International Workshop on Principles of Diagnosis (DX-00), Morelia, Mexico, 2000, pp. 185–192.[20] Y. Pencolé, M.-O. Cordier, L. Rozé, Incremental decentralized diagnosis approach for the supervision ofa telecommunication network, in: Proceedings of the International Workshop on Principles of Diagnosis(DX-01), San Sicario, Italy, 2001, pp. 151–158.[21] Y. Pencolé, M.-O. Cordier, L. Rozé, A decentralized model-based diagnostic tool for complex systems,Internat. J. Artificial Intelligence Tools 11 (3) (2002) 327–346.[22] M. Riese, Diagnosis of extended finite automata as a dynamic constraint satisfaction problem, in: Proceed-ings of the International Workshop on Principles of Diagnosis (DX-93), Aberystwyth, United Kingdom,1993, pp. 60–73.[23] L. Rozé, M.-O. Cordier, Diagnosing discrete event systems: An experiment in telecommunication networks,in: Proceedings of the Workshop on Discrete Event Systems (WODES-98), Cagliari, Italy, 1998, pp. 130–137.[24] L. Rozé, M.-O. Cordier, Diagnosing discrete-event systems: extending the “diagnoser approach” to deal withtelecommunication networks, J. Discrete-Event Dynamic Syst. 12 (1) (2002) 43–81; errata 14 (1) (2004)131.[25] M. Sampath, R. Sengupta, S. Lafortune, K. Sinnamohideen, D. Teneketzis, Diagnosability of discrete eventsystem, IEEE Trans. Automatic Control 40 (9) (1995) 1555–1575.[26] M. Sampath, R. Sengupta, S. Lafortune, K. Sinnamohideen, D. Teneketzis, Active diagnosis of discrete-event systems, IEEE Trans. Automatic Control 43 (7) (1998) 908–929.[27] R. Sengupta, Diagnosis and communication in distributed systems, in: Proceedings of the Workshop onDiscrete Event Systems (WODES-98), Cagliari, Italy, 1998, pp. 144–151.[28] B.C. Williams, P.P. Nayak, A model-based approach to reactive self-configuring systems, in: Proceedings ofAAAI-96, Portland, OR, 1996, pp. 971–978.[29] B.C. Williams, P.P. Nayak, Immobile robots—AI in the new millenium, AI Magazine 17 (3) (1996) 17–34.