Kent Academic RepositoryRizzi Raymundo, Caroline, Johnson, Colin G., Fabris, Fabio and Vargas, Patricia A. (2016) A Situation-Aware Fear Learning (SAFEL) Model for Robots. Neurocomputing, 221 . pp. 32-47. ISSN 0925-2312. Downloaded fromhttps://kar.kent.ac.uk/58076/ The University of Kent's Academic Repository KAR The version of record is available fromhttps://doi.org/10.1016/j.neucom.2016.09.035This document versionAuthor's Accepted ManuscriptDOI for this versionLicence for this versionCC BY-NC-ND (Attribution-NonCommercial-NoDerivatives)Additional informationVersions of research worksVersions of RecordIf this version is the version of record, it is the same as the published version available on the publisher's web site. Cite as the published version. Author Accepted ManuscriptsIf this document is identified as the Author Accepted Manuscript it is the version after peer review but before type setting, copy editing or publisher branding. Cite as Surname, Initial. (Year) 'Title of article'. To be published in Title of Journal , Volume and issue numbers peer-reviewed accepted version. Available at: DOI or URL (Accessed: date). EnquiriesIf you have questions about this document contact ResearchSupport@kent.ac.uk. Please include the URL of the record in KAR. If you believe that your, or a third party's rights have been compromised through this document please see our Take Down policy (available from https://www.kent.ac.uk/guides/kar-the-kent-academic-repository#policies). Author’s Accepted ManuscriptA Situation-Aware Fear Learning (SAFEL) Modelfor RobotsCaroline Rizzi, Colin G. Johnson, Fabio Fabris,Patricia A. Vargaswww.elsevier.com/locate/neucomPII:DOI:Reference:S0925-2312(16)31052-9http://dx.doi.org/10.1016/j.neucom.2016.09.035NEUCOM17564To appear in: NeurocomputingReceived date: 18 December 2015Revised date: 13 July 2016Accepted date: 14 September 2016Cite this article as: Caroline Rizzi, Colin G. Johnson, Fabio Fabris and PatriciaA. Vargas, A Situation-Aware Fear Learning (SAFEL) Model for Robots,Neurocomputing, http://dx.doi.org/10.1016/j.neucom.2016.09.035This is a PDF file of an unedited manuscript that has been accepted forpublication. As a service to our customers we are providing this early version ofthe manuscript. The manuscript will undergo copyediting, typesetting, andreview of the resulting galley proof before it is published in its final citable form.Please note that during the production process errors may be discovered whichcould affect the content, and all legal disclaimers that apply to the journal pertain.A Situation-Aware Fear Learning (SAFEL) Model for RobotsCaroline Rizzia,∗, Colin G. Johnsona, Fabio Fabrisa, Patricia A. VargasbaSchool of Computing, University of Kent, Canterbury, UKbRobotics Laboratory, School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh, UKAbstractThis work proposes a novel Situation-Aware FEar Learning (SAFEL) model for robots. SAFEL combines conceptsof situation-aware expert systems with well-known neuroscientific findings on the brain fear-learning mechanismto allow companion robots to predict undesirable or threatening situations based on past experiences. One of themain objectives is to allow robots to learn complex temporal patterns of sensed environmental stimuli and create arepresentation of these patterns. This memory can be later associated with a negative or positive “emotion”, analogousto fear and confidence. Experiments with a real robot demonstrated SAFEL’s success in generating contextual fearconditioning behaviour with predictive capabilities based on situational information.Keywords: Contextual Fear Conditioning, Brain Emotional Learning, Temporal Pattern, Affective Computing,Autonomous Robotics, Amygdala and Hippocampus Modelling1. IntroductionLearning to fear unpleasant or harmful stimuli fromthe environment is ubiquitous in nature. Fear can bedefined as a brain’s mechanism for automatic learningand memorization of potential threats to one’s survival.It offers exceptional advantages over conscious-rationalthinking during critical situations due to its involun-tary and automatic responses, leading to faster decision-making and reaction in the face of danger [1, 2], as wellas increased focus and attention [3]. Fear learning isalso an important ally for environmental adaptation asthe brain constantly associates fear with newly experi-enced dangers. Hence, it assists animals to learn andreact to the new patterns and threats of unfamiliar envi-ronments.Fear learning supports not only survival and environ-mental adaptation, but also social adaptation (i.e., one’sability of adjusting its behaviour to the rules of its ownsociety). The concept of society applies to many animalspecies, where individuals feel an instinctive need to beaccepted by others of its kind. As belonging to a com-munity can highly increase one’s chances of survival,∗Corresponding authorEmail addresses: cr519@kent.ac.uk (Caroline Rizzi),C.G.Johnson@kent.ac.uk (Colin G. Johnson),ff79@kent.ac.uk (Fabio Fabris), p.a.vargas@hw.ac.uk(Patricia A. Vargas)the brain of many animal species evolved to processsocial rejection as an aversive environmental stimulus.Consequently, the brain triggers fear learning when anindividual observes disapproval from others towards itsactions.By being real agents that inhabit the physical worldand interact with human beings, autonomous robots arealso susceptible to environmental threats and to socialadaptation. Hence, autonomous robots could also takeadvantage of a mechanism inspired by fear learning.Robot companions [4–7], for instance, are gaining morespace in our society as social entities and have showna great potential for applications in many areas (e.g.,healthcare [8]). However, a common issue with long-term robot companions is the rapid loss of interest fromtheir users, who get frustrated and lose motivation overtime as companions continue to perform pre-definedand repetitive behaviours [5]. This poses a challenge tothe broad development and practical use of robot com-panions.From the HRI (Human-Robot Interaction) point ofview, robots’ social interaction becomes more believ-able and natural as they become more adaptable and re-sponsive to environmental cues [4, 6, 9]. As humans,we expect others to be able to identify environmentalfactors that can represent unpleasantness or danger tothemselves and act accordingly. Therefore, being ableto properly express fear responses could highly increasePreprint submitted to NeurocomputingSeptember 19, 2016the believability of a long-term robot companion [9].world threatening situations.Fear learning has been a strong source of inspirationfor developing more flexible and adaptive artificial in-telligence [10–13]. The potential of artificial intelli-gence based on fear-learning models is demonstrated byits successful contribution to a variety of engineeringand robotic applications [14–29]. Despite its advances,research on artificial fear-learning is still in its infancyand has several aspects with margin for improvement,among which we can highlight situation appraisal.In the real world, people react not only to individualenvironmental stimuli (e.g. pain, smells, noises, loca-tion, light levels, etc.), but also to contextual variationover time, also known as situation, which is character-ized by the temporal order and intensity variation of allappraised stimuli in a given period of time (e.g., beingin a forest at night, with impaired visibility, and hear-ing animals’ noises). Here, we define the emotionaloutcome and evaluation of a situation as situation ap-praisal.To the best of our knowledge, artificial fear-learningmodels proposed to date do not substantially address sit-uation appraisal, which is a significant part of the brain’sfear-learning system, and essential for a organism topredict outcomes and adapt to threats and environmen-tal changes [30].This paper proposes a novel hybrid computationalmodel, named SAFEL (Situation-Aware FEar Learn-ing), which is based on the brain’s fear-learning sys-tem and incorporates the concept of situation aware-ness from expert systems. SAFEL builds on our fear-learning model, proposed in [31], which is inspired bythree brain regions essential in fear learning: the sen-sory system, the amygdala and the hippocampus, alongwith a cognitive function of the brain known as theworking memory [2]. Here, we discuss the implemen-tation of SAFEL’s hippocampus and working memorymodules, which are responsible for simulating situa-tion appraisal regarding fear. Experiments with a NAOrobot demonstrate that SAFEL has successfully gener-ated fear-conditioning behaviour with predictive capa-bilities based on situational information.The main contributions of this work as compared tothe state of the art are:1. Integration of a fear learning model with the con-cept of temporal context. SAFEL performs threatpredictions based on complex temporal and con-textual information. Existing fear memory mod-els either focus in the contextual or the temporalaspect, overlooking the need of both skills for anartificial intelligent agent to properly react to real-22. SAFEL is focused on real-world applications forartificial and autonomous intelligence in robotics.Many existing fear-learning models that are in-spired by the real mechanisms of the brain focus onproviding a close-to-real emulation of brain func-tions without addressing the practical usage of themodel for artificial intelligence.3. The successfulintegration of a symbolic rule-based platform for situation management with aclassification algorithm for memorizing and pre-dicting threats based on complex temporal context.This paper is organised as follows: Section 2 dis-cusses related work. Section 3 summarizes the biolog-ical background and neuroscientific findings that haveinspired SAFEL. Section 4 presents SAFEL’s modellingand implementation. Experimental methodology andresults are discussed in Sections 5 and 6, respectively.The paper concludes with Section 8, and also suggestsfuture work.2. Previous Models of Contextual Fear ConditioningThe idea of using models of emotion for improvingautonomous learning in artificial systems started withPicard’s research in 1995 [32, 33]. Picard’s work origi-nated one of the most recent branches of computer sci-ence: affective computing. According to Picard [33],affective computing tackles three aspects of artificial in-telligence: (1) the ability of machines to recognize andexpress emotions, (2) the ability of machines to respondintelligently to human emotion, and (3) the capability ofmachines to regulate and utilize emotions in order to be-have more intelligently and effectively. In this work, wefocus on the latter aspect of affective computing, thoughall the three aspects are indirectly addressed.A large range of approaches have been proposed forsimulating emotions in artificial agents, such as affec-tive space models [34, 35], motivation-driven models[13], neuro-inspired models [10, 12, 36–38], hormonalor homoeostatic systems [39–42], among others [43, 44](for a broader review on the varied approaches and chal-lenges of affective computing, we refer the reader to[45]). Here, we are particularly interested in approachesaddressing the temporal properties of context applied tofear conditioning for providing robots with fast, efficientand flexible decision-making.One of the most influential works in artificial fearconditioning is the brain emotionallearning (BEL)model, proposed by Mor´en and Balkenius [10]. Theirmodel (Fig. 1) consists of interconnected modules ofartificial neural networks (ANNs) that simulate the roleof neural circuitries involved in fear learning. It receivestwo types of inputs – environmental neutral stimuli anda reward signal – that are processed by four simulatedneural regions:the thalamus, the sensory cortex, theamygdala and the orbitofrontal cortex.The thalamus and sensory cortex simply relay in-put information to the orbitofrontal cortex and amyg-dala and, together, compose the “low and high roads”to the amygdala, respectively [2]. The sensory cortexreceives information from the thalamus, which in turnreceives information directly from the environment. Asthe thalamic pathway is shorter, it provides the amyg-dala with low latency information about environmen-tal stimuli. On the other hand, information projectedthrough the thalamic-cortical pathway takes longer toreach the amygdala, but provides a higher-level andmore accurate representation of the sensed world.The amygdala is responsible for assessing and pre-dicting the emotional value of stimuli, based on the sig-nificance of the accompanied reward. Finally, the or-bitofrontal cortex is responsible for inhibiting emotionalassociations of the amygdala that are no longer valid.This model has been tested for the most basic effects ofclassical conditioning – such as fear acquisition, fearextinction, blocking, habituation and spontaneous re-covery – showing satisfactory results.The BEL model was later improved in [46], with theaddition of a module that simulates the contextual pro-cessing performed by the brain’s hippocampal regions.BEL’s hippocampus module has four main components:Figure 1: Fear-learning model proposed by Mor´en and Balkenius [10].Each component of their model represents an ANN. Circles representindividual ANNs internal to the respective component.3the Bind subsystem, the Mem system, the Match sys-tem and the Context system. The Bind subsystem is re-sponsible for binding stimuli that are simultaneously de-tected. The Mem system generates expectations aboutstimuli manifestation at specific locations. These ex-pectations are later compared with the actual stimuli inthe Match system. Lastly, the Context system combinesinformation from the Match and Bind systems to gen-erate a contextual code that feeds the amygdala and or-bitofrontal cortex.With the aid of the hippocampal module, BEL is ableto express fear responses based on contextual informa-tion. For example, one of the experiments performed in[46] consisted on presenting two different stimuli, CS0and CS1, sometimes separately and sometimes together.All single presentations of either CS0 or CS1 were fol-lowed by a reinforcing signal, whereas all simultane-ous presentations were followed by nothing. The modelgradually learned to differentiate between single andjoint stimulus presentation. Further experiments in [46]with other patterns of stimulus presentation and locationwere also successful.Despite BEL’s success in discriminating sets of si-multaneously presented stimuli, a few important ques-tions were left unanswered. For instance, what wouldhappen if the reinforcing signal was presented only afterCS0 was followed by CS1 (represented by CS0→CS1)?Would the model understand that CS1→CS0 is differ-ent from CS0→CS1? According to Mor´en [46], con-text “can be either an abstract sequence of stimuli or aplace defined by a number of stimuli at different loca-tions around the animal”. It is clear that temporal fac-tors are not considered in Mor´en’s conceptualization ofcontext, which is possibly the reason why the temporalorder of stimulus presentation is never evaluated in hisexperiments.The simplest version of the BEL model (i.e., the ver-sion proposed in [10], which has no hippocampus mod-ule) became more popular among researchers. Basedon the BEL model [10], Lucas, Shahmirzadi and Sheik-holeslami [11] proposed a Brain Emotional LearningBased Intelligent Controller (BELBIC), which was laterapplied (somewhat adapted) to a large range of indus-trial [14–18], engineering [19–23] and robotics [24–29] applications. Most of these works have comparedtheir BELBIC controllers with conventional controllerapproaches (e.g. PID, MLP, ANFIS and LLNF) and ob-served meaningful improvements in varied performanceaspects when using BELBIC.In 2010, Beheshti and Hashim [47] published a re-view on BELBIC systems and demonstrated its per-formance for engineering ends. They compared BEL-BIC with a range of conventional controller approaches(such as PID, ANFIS and feedback linearization con-troller) for several engineering applications (such as mi-cro heat exchanger, intelligent control of washing ma-chine, dynamic power management, intelligent predic-tor for geomagnetic activity, and speed and flux controlof an induction motor). Their analysis concluded thatBELBIC showed better performance and results thanthe tested conventional approaches for real time controland decision systems.BELBIC’s popularity and performance improvementover traditional approaches in several application areasdemonstrates its great potential as a controller. We be-lieve that such success could be even greater if BELBICwas based on the improved version of BEL [46], as wellas if it considered the temporal aspects of context.Rudy and O’Reilly [36] have also proposed a contex-tual fear-conditioning model that relies on a theoreticalframework [48] based on the cortical and hippocampalregions of the brain. In their model, the cortex repre-sents context as a set of independent features, whereasthe hippocampus binds these features into an unitaryrepresentation. Rudy and O’Reilly have implementedtheir framework on an artificial neural network model,which was evaluated on a scenario that simulates a con-text fear-conditioning experiment performed with rats.The experiment aimed at evaluating the model regard-ing is capability to (1) enhance fear conditioning viapre-exposure to context and (2) induce pattern comple-tion (when a subset of a learned pattern can recover theentire pattern).Although successful in reproducing many fear condi-tioning effects, the contextual fear-conditioning modelof Rudy and O’Reilly [36] also disregards the temporalproperties of context. According to Rudy and O’Reilly[36], “either context can be represented as a set of in-dependent features (the features representation view) orthese features can be bound into an unitary encodingthat represents their co-occurrence (the conjunctive rep-resentation view)”. This implies that their unitary rep-resentation of context considers features that co-occuronly, which excludes a large range of temporal possi-bilities between distinct features that are essential for athorough contextual perception.A model that considers temporal sequences has beendesigned by Harrison et al. [30]. Their study aimed atevaluating hippocampal responses to changes in prob-abilistic context by submitting subjects to a first-orderMarkov sequence, where the current event Et is con-ditionally dependent on the previous event Et−1, andthe probability of transition between them is given byp(Et|Et−1). To model the task, they assumed that the4subject was an ideal Bayesian observer, who starts withthe belief that all events are equally likely and consec-utive events are independent. As samples of events aresequentially presented, this ideal observer constructs atransition matrix consisting of the probabilities of tran-sition between consecutive events.Their model is similar to ours in the sense that learn-ing and prediction are based on the temporal relation-ship of events. However, the design of the task given totheir subjects, which reflects on their model of an idealobserver, considers that every event consists of only onestimulus. Although sufficient for the purpose of theirexperiment, which is analysing hippocampal responsesto temporal context, this simplistic design does not re-flect real world situations, in which events may consistof many simultaneous stimuli.Among recent research, we highlight the work ofSubagdja and Tan [37]. They propose a model forepisodic memory, which is a type of long-term declara-tive memory mainly processed by the hippocampus, us-ing an extended adaptive resonance theory (ART) net-work. They argue that the accuracy of memory retrievaldepends on the order and latency between memory cues,which matches the conceptual foundation of our work.They evaluate their approach on a transitive inferenceproblem, which is a classical logical problem of com-paring the value of things (e.g., given that A weighsmore than B and B weighs more than C, than it can beinferred that A weighs more than C).Amongst the related work, Subagdja and Tan [37]may be the most similar to our proposed model withregards to temporal context. For instance, their defini-tion of situation (which they call an episode) is equalto ours. However, our approaches differ in the final pur-pose of temporal context. We are mostly concerned withpredicting aversive events by creating a link between the“feeling of fear” and the events that preceded an aver-sive stimulus in a past experience. This would providerobots with the chance to react and prevent unpleasant(possibly harmful) situations, as well as to increase theiradaptation capabilities. On the other hand, the work ofSubagdja and Tan addresses neither fear conditioning,nor danger prediction/prevention. In their work, events’order is not associated with any emotion. Their main fo-cus is to facilitate retrieval, creation and update of neu-tral (non-aversive) contextual memory.3. Biological BackgroundThis section discusses the main biological conceptsbehind SAFEL’s model. We begin introducing SAFEL’sinspiration: fear conditioning, the phenomenon behindfear learning. Next we discuss the brain mechanism re-sponsible for fear learning and memory, based on themodel proposed by LeDoux [2, 49].3.1. Fear ConditioningIn classical fear conditioning [50], associative learn-ing is induced by repeatedly pairing a neutral stimulus(NS) with an aversive unconditioned stimulus (US). Anaversive US is any stimulus that naturally elicits fear oranxiety in the animal. In other words, the animal is bornwith the knowledge that such stimulus is aversive, likea “hard-coded” knowledge. Some examples of aversiveUS are pain, hunger, sensory impairment (such as losingvisibility in dark places), aggressive facial expression ofother animals, etc.By pairing a NS and an aversive US (i.e., by present-ing these stimuli simultaneously to the animal), the NSacquires emotional value and becomes able to triggerfear reactions by itself, even in the absence of the US.Since the NS did not trigger fear reactions before, wesay that the animal has learned to fear it through a con-ditioning procedure. As consequence, the NS becomesa conditioned stimulus (CS).The classical foot-shock experiment with rats demon-strates this phenomenon.In the experiment, a rat isplaced into an apparatus and receives auditory cuespaired with electrical shock in its feet. The shock nat-urally elicits fear in the rat, which freezes in response.After repeating this procedure a few times, the rat asso-ciates the stimuli and starts to freeze in response to theauditory cue even in the absence of an electrical shock.Because the CS did not elicit the defensive response be-fore, it is said to be a conditioned emotional response.Nevertheless, in this experiment, fear expression hasbeen observed not only in response to the auditory cue,but also to the background context, which in this case isthe apparatus where the shock was induced. The phe-nomenon of expressing defensive responses in the pres-ence of a specific combination of stimuli (e.g., a situ-ation or place) under which a US has been previouslyinduced is known as contextual fear conditioning [51].Although both types of conditioning lead to the samefear responses, their perception and processing mecha-nisms in the brain are very different. In classical fearconditioning, the CS is restricted to an individual stim-ulus that belongs to a specific sensory modality (smell,touch, taste, hearing or vision), whereas in contextualfear conditioning, the CS is composed of a collection ofstimuli, which may belong to different sensory modal-ities [51]. This set of stimuli is bound into an unitaryrepresentation of context that depicts not the stimuli perse, but the relationship between them [2].3.2. Fear Learning in the BrainConsiderable evidence points the amygdala as themain brain region involved in fear learning and memory[2, 49, 51, 52]. Although the amygdala is essential forboth classical and contextual fear conditioning [51], itis in the hippocampus where context processing mainlytakes place [2, 53], including the association of eventsacross time [54]. Research has shown that lesions tothe amygdala interfere with fear responses to both typesof fear conditioning, while lesions to the hippocampusinterfere with fear responses in contextual fear condi-tioning only [51, 55].These findings reinforce the model of the brain’s fear-learning process proposed by LeDoux [2, 49]. Accord-ing to LeDoux, fear learning relies mainly on three brainregions: the sensory system, the amygdala and the hip-pocampus, as well as a cognitive function known as theworking memory.The sensory system, composed by the thalamic andcortical pathways,is responsible for providing theamygdala with information on different levels of ab-straction and accuracy. The amygdala, in turn, pro-cesses the emotional significance of sensed stimuli. Inother words, it is the brain region responsible for fearappraisal.It is also where classical fear conditioningtakes place, i.e., where neutral stimuli are associatedwith aversive stimuli during the conditioning process.The hippocampus is where we begin to leave thepurely perceptual reasoning about the world and enterthe conceptual domain of the brain. In the hippocam-pus, sensory information is put together in order to forman unitary representation of the current state of affairs.Unlike information processed in the amygdala, repre-sentations formed in the hippocampus are not just vi-sual, auditory or olfactory, but all of these at once, andincludes the way these sensations relate to each otherboth in intensity and temporal order.The amygdala and hippocampal systems work in par-allel, forming what LeDoux calls, respectively, as emo-tional memory and memory of emotion [2]. When youremember a traumatic situation, in addition to the stateof affairs, the hippocampus will also remember you as acold fact that you were afraid at that time, providing youwith an unemotional memory of emotion. The amyg-dala, in turn, will trigger bodily and brain responses(muscles’ tense up, increased heart rate, hormone re-lease, etc.) that allow you to re-experience the fear feltduring the trauma, thus providing you with an emotionalmemory of the episode.Exposure to stimuli that were present during thetrauma activates both the amygdala and hippocampal5systems, which work in parallel to retrieve emotionaland contextual memory about the event, respectively.Because these two memories are simultaneously recov-ered in response to the same stimuli, they are experi-enced as if they were one single memory.These two memories are fused and consciously ex-perienced in the working memory. LeDoux [49] de-fines the working memory as “a serially organized men-tal workspace where things can be compared and con-trasted and mentally manipulated”. A variety of stud-ies indicate pre-frontal cortex areas and the anteriorcingulate region as involved in working memory func-tions [49, 56, 57]. Newly sensed stimuli and storedhippocampal representations are integrated in workingmemory through interactions between pre-frontal andhippocampal areas.In the case of an aversive stimu-lus, similar interactions are triggered, which inform theworking memory of the fact that the amygdala has acti-vated fear responses. In other words, the working mem-ory allows the association of explicit contextual mem-ory formed in the hippocampus with implicit emotionalmemory formed in the amygdala.4. SAFEL: A Situation-Aware Fear Learning ModelSAFEL is a situation-aware computational systemcapable of endowing a companion robot to learn andpredict threatening situations to itself through a fear-conditioning–like procedure. Nevertheless, we empha-sise that, although we have chosen robotics as our mainapplication, SAFEL has the potential for being used inany other areas that require machine learning and adap-tation.This work is based on the fear-learning model of thehuman brain and contemplates part of a more ambitiousfear-learning architecture proposed in [31]. This archi-tecture is inspired by the LeDoux model [2, 49], dis-cussed in Section 3.2. SAFEL’s complete architecture[31] is divided into four hybrid modules that work inan integrated and parallel manner: the sensory system,the amygdala system, the hippocampal system and theworking memory.Fig. 2 depicts the complete model proposed in [31],illustrating how the four main modules of the archi-tecture are interconnected. The sensory system pre-processes environmental stimuli detected by the robot(e.g., by means of sensors’ input or direct user input),which is relayed to the amygdala and hippocampal sys-tems. The amygdala system is responsible for predict-ing and associating environmental stimuli to imminentdanger. It also provides emotional feedback to the hip-In parallel, the hippocampal sys-pocampal system.Figure 2: The complete model of the fear-learning architecture pro-posed in [31]. Dashed boxes represent the modules of the architecturethat we have not yet implemented. White boxes represent areas of thebrain, whereas grey boxes represent cognitive functions of the brain.The system receives neutral and aversive stimuli as input, and outputsthe corresponding emotional response.tem generates complex contextual representations of theenvironment based on the processed sensory informa-tion projected by the cortex. Finally, implicit memoriesfrom the amygdala system and explicit memories fromthe hippocampal system meet in the working memory,where contextual information is associated with emo-tional information to produce emotional responses.Note that this model does not attempt to capture allthe real neural circuits involved in the brain’s fear learn-ing system, which are far more complex and have notyet been completely understood by neuroscientists. Italso does not attempt to perfectly mimic all aspects ofthe real fear learning. The proposed model seeks to cap-ture the aspects of the fear learning system that are rel-evant for improving a robot’s learning, adaptation andbelievability competencies.In this paper, we model, implement and evaluate thehippocampus and working memory modules. The im-plementation of the sensory and amygdala systems arepart of our future work.4.1. Hippocampus ModuleIn the following, we present both theoretical andpractical foundations for implementing situation aware-ness in the hippocampus module of SAFEL.The hippocampus module is responsible for SAFEL’scontextual processing and is based on the concepts of6situation-awareness proposed by Dey [58], which is dis-cussed in Section 4.1.1. In order to address Dey’s defi-nition of situation awareness, we have modelled and im-plemented SAFEL’s hippocampus module on the JBossDrools rule engine and CEP (Complex Event Process-ing) platform [59], which we introduce in Section 4.1.2.Finally, Section 4.1.3 presents the design of the hip-pocampus module.4.1.1. Situation AwarenessContext has many definitions among different areas ofstudy. Dey [58] was one of the first to propose a contextdefinition from the perspective of expert systems. Ac-cording to Dey, “context is any information that can beused to characterise the situation of an entity. An entityis a person, place, or object that is considered relevantto the interaction between a user and an application, in-cluding the user and application themselves” [58].Dey’s definition of context, however, does not incor-porate temporal properties. This is because, accordingto Dey, the temporal aspects associated with the statusof an entity are part of an extended conceptualizationof context called situation. A situation describes a col-lection of states of relevant entities, where each statedepicts those entities’ context in a given point in time.In this sense, the term situation awareness could be un-derstood as the act of being aware of the variations in anentity’s context during a particular period of time.To the merge of situation-awareness with emotionalevaluation we give the name of situation appraisal.Here, we define situation appraisal as one’s capabilityof not only being situation aware, but also being able tomake emotional evaluations and associations over per-ceived situations. This is not to be confused with the ap-praisal approach of emotion, in which emotional statesare usually defined by rule-based techniques on a set ofappraisal variables [12, 60]. Although the hippocam-pus module is based on rules and event management,the link between situations and emotional states is notdefined through rules, and is performed in the workingmemory module, as we explain later in Section 4.2.The hippocampus module of SAFEL is based onDey’s conceptualization of situation awareness for com-puting. In other words, the hippocampus module is re-sponsible for collecting, understanding and managingthe states of the robot over time, so that other modules ofSAFEL, such as the working memory, can make properuse of this information at a higher level of abstraction.4.1.2. Underlying TechnologyRule-based languages are based on the model of hu-man cognitive process of conscious decision-making,which is guided by the rules and facts learned during anindividual’s life [61]. This makes rule-based techniquessuitable for simulating the hippocampal functions in thebrain.The hippocampus module of SAFEL is based onJBoss Drools [59], which is a robust rule managementplatform. Drools also provides CEP (Complex EventProcessing) management and greatly fulfils the designrequirements of the hippocampus module.Drools has its own rule-based language, the DRL(Drools Rule Language), consisting of a set of when-then statements that can be applied to a set of facts.Facts, in turn, are information representing immutableentities of the world. For example, “John”, “Mike” and“Mary” are instances of the fact “person”, which canhave “age” as an attribute. An example of a rule (in nat-ural language) would be “when a person older than 60years enters the bus, then apply ticket discount”. Code 1shows a simple example of how this rule could be writ-ten in DRL.Drools’ inference engine (or rule engine), is responsi-ble for evaluating facts against rules’ patterns through aprocess known as pattern matching. When one or morefacts satisfy a rule’s condition (the when part), the in-ference engine executes the actions defined in the rule’sthen part and we say that the rule has been fired. Whena rule is fired, the execution of its actions may fire otherrules, leading to a cascade effect.Drools also has an embedded CEP platform, whichallows for the detection and management of events.Events are defined as records of significant changes inthe domain’s state at a given point in time [59]. Someexamples of events are “A person has entered the bus”,“Mary has left the room”, etc. Besides facts, an eventcan also consist of other events, when it is said to be acomplex event.Because events have intrinsic temporal properties,they can be compared with each other by means oftemporal operations. Drools implements all 13 tempo-ral operators defined by Allen [62, 63]. Some exam-ples are “before”, “after”, “during”, “finished by”, etc.Code 1: Example of Drools rule.rule "Ticket Discount" // rule namewhen // conditionperson : Person(age > 60)then // actionBusSystem.applyTicketDisccount();end1234567An example of rule using a temporal operation wouldbe “when a person enters the meeting room before themeeting time, then ask to wait outside”.While events represent punctual changes in the stateof affairs, such as “Mary has entered the room”, situa-tions represent changes in the state of affairs that haveduration and can be either current (e.g., “Mary has beenin the room since 6AM”) or past (e.g. “Mary was inthe room for 5 hours”). SAFEL is inspired by SCENE’ssituation management modelling [64, 65] to implementsituation-awareness. According to SCENE’s conceptu-alization, situations are “composite entities whose con-stituents are other entities, their properties and the rela-tions in which they are involved” [64].In SCENE, general characteristics of situations aredefined by their situation type. For example, “John is inthe meeting room” and “Mary is in the living room” areexamples of instances of the situation type “Person is inthe room”. A situation instance is activated when en-tities whose properties satisfy the restrictions of the re-spective situation type are detected. A situation instanceis said to be a current situation while these restrictionsare satisfied. The situation instance is deactivated whenits type restrictions are no longer satisfied, and it is saidto be a past situation. Situation duration is the period oftime between the activation and deactivation of a situa-tion. Therefore, only inactive situations (i.e., past situa-tions) can have a closed duration.Our situation management differs from SCENE’s ap-proach regarding the moment of situation detection, i.e.,the moment when the system becomes aware of the ex-istence of the situation. According to SCENE, situa-tions are always detected at their activation time. How-ever, SAFEL’s design requires certain types of situationto be detectable at or after their deactivation time. Thereason for this design decision is explained next, in Sec-tion 4.1.3.4.1.3. Hippocampus ModelThe hippocampus module receives two input types:neutral stimulus and adrenaline signal. Neutral stim-uli are real values representing environmental stimulidetected by the robot’s sensors that, initially, have noemotional meaning for the robot. On the other hand, theadrenaline signal is a value in the range [0, 1] represent-ing the system’s level of fear based on the detection ofaversive unconditioned stimulus (US).Analogously to aversive US in the brain, an aversiveUS for SAFEL is any stimulus that is known to be harm-ful to the robot and, thus, can be hard-coded as aver-sive US in the robot’s fear-learning system. In the samesense that animals are born with knowledge about aver-sive US, robots should also start their life-cycle witha set of well-known aversive US (e.g., collision, lowlight/visibility level, low battery, etc.), which are pre-configured parameters of SAFEL.In the complete architecture of SAFEL (Fig. 2),the amygdala module is responsible for assessing theemotional value of sensed stimuli and outputting anadrenaline signal. The adrenaline informs the hip-pocampus about the presence or not of aversive stimuli.However, as previously mentioned, the amygdala mod-ule has not yet been implemented in the current versionof SAFEL. To deal with the absence of the amygdala,we simplify the process of adrenaline management bysetting it high whenever a pre-defined aversive stimulus(i.e., an US) is detected, and setting it low otherwise.This solution, though, is temporary and has the onlypurpose of evaluating the hippocampus and workingmemory modules. Thus, it is not intended to replace theamygdala module. The amygdala is an important mod-ule in SAFEL’s architecture, which performs essentialtasks other than managing adrenaline levels. For exam-ple, the amygdala is also responsible for detecting andmemorizing new potential aversive stimuli that are notUS (i.e., are not pre-defined), which may have been neu-tral in the past, but became dangerous in a currently newenvironment.Situation management in the hippocampus module isbased on the following definitions:Definition 1. An event et is a collection of all stimulidetected by the robot’s sensors at time t, so that et =, st{sti is a normalized real value12∈ [0, 1] representing the intensity of stimulus of type istidetected at time t.| n ∈ N}, where st, ..., stnDefinition 2. A situation S is composed of the sequenceof events occurring during its active period, so thatS j = {eaj| a j < d j, [a j, d j] ∈ [N, N]}, wherea j and d j are, respectively, the times of activation anddeactivation of situation j., eaj+1, ..., edjWe have defined four situation types in the hippocam-pus module: aversive, predictive, safe and unknown.The rules under which these situations are instantiatedare defined in a DRL file and are constantly matchedagainst the current adrenaline signal and existing sit-uations instances in Drools’ memory. When informa-tion in Drools’ memory satisfies the constraints of theserules, new situations are instantiated, whose type de-pends on which rule was executed.Code 2 shows the rule responsible for instantiatingnew aversive situations, whose conditions are defined in8the when block (lines 3 to 5). This rule is satisfied whenthe last adrenaline signal received (line 3) has levelabove a given threshold (line 4) and there is no aver-sive situation currently active (line 5). If these condi-tions are satisfied, the actions listed in the then block areexecuted, which in this case is creating a new instanceof aversive situation and insert it into Drools’ memory(line 7). The properties of events (e.g. Adrenaline) andsituations (e.g. AversiveSituation) are defined in Javaobjects.It is also possible to perform temporal operations be-tween situations. Code 3 shows a snippet of the ruleresponsible for instantiating predictive situations. Ob-serve in the conditions of this rule, keywords such asbefore and after (lines 5 and 6). These keywords repre-sent temporal operations and allow creating conditionsbased on the temporal order of situations’ activation anddeactivation.The properties and constraints of each situation typein the hippocampus can be summarized as follows:• Aversive situation: An aversive situation indicatesthe periods of time in which the system was (or is,if it is a current situation) exposed to aversive stim-12345678123456Code 2: Drools rule for instantiating an aversive situation.rule "Aversive Situation"whenadrenaline : Adrenaline() overwindow:length(1)Adrenaline(this == adrenaline, level >=adrThreshold)not AversiveSituation()theninsert(new AversiveSituation());endCode 3: Example of temporal operation.rule "Predictive Situation"when(...)aversive : AversiveSituation ()unknown : UnknownSituation(this beforeaversive)not (exists UnknownSituation(this afterunknown, this before aversive))78910(...)then(...)end9uli. It is activated when the adrenaline signal risesabove a given threshold (meaning that the robot hasdetected an aversive stimulus), and is deactivatedwhen the adrenaline signal returns to normal lev-els (meaning that the aversive stimulus is no longerpresent).• Predictive situation: Predictive situations are thosethat precede aversive situations. Because they havepreceded an aversive situation once, if they reoc-cur, it is probable that they will precede a sim-ilar aversive situation again. By recognizing thepattern of predictive situations, the robot increasesits chances to predict the imminent exposure toaversive stimuli. Because predictive situations canonly be detected on the activation of the respectiveaversive situation, i.e., after their own deactivation,they are always past situations (see Section 4.1.2)for the system.• Safe situation: Safe situations are those that do notprecede or co-occur with aversive or predictive sit-uations. This means that the robot is not being ex-posed to aversive stimuli at the current moment,and has no expectations to be exposed to aversivestimuli in the near future. The only way to ensurethat a given situation is safe is to look at the situa-tions occurring right after it in order to confirm thatthey are neither aversive nor predictive. Hence,like predictive situations, safe situations can onlybe detected when they are already past situations.• Unknown situation: An unknown situation is anysituation that is not aversive, and cannot yet be con-sidered safe or predictive (since these can only bedetected after their deactivation). Unknown situa-tions can become either safe or predictive in the fu-ture, depending on the events occurring in a giventime interval after their deactivation.Fig. 3 shows an example of situations’ life-cycle overtime, where Fig. 3a shows the adrenaline signal overtime, and Fig. 3b, 3c and 3d show situations’ statusin the system at time t10, t13 and t14, respectively.InFig. 3b, for instance, situation S 1 has activation timea1 = t1 and deactivation time d1 = t5, situation S 2 hasactivation time a2 = t2 and deactivation time d2 = t6,and so on. Analogously, S 1 = [et1, et5 ], S 2 =[et2, et3Observe that situations can overlap each other. Forexample, situation S 2 is activated while situation S 1 isactive; situation S 3 is activated while situations S 1 andS 2 are active, etc. Consequently, two or more situations, et6 ], and so on., et3, et2, et4, et5, et4a)Detection of Aversive USc)Adrenaline ThresholdAdrenaline SignalS 5S 4S 9S 8S 3S 7S 2S 1S 6S 5S 9S 12S 11S 10t1t2t3t4t5t6t7t8t9 t10 t11 t12 t13 t14t1t2t3t4t5t6t7t8t9 t10 t11 t12 t13b)S 5S 4ΔaS 3S 2S 1S 6S 5S 8S 7S 9S 9d)S 5S 4S 3S 2S 1S 6S 5S 8S 7S 9S 9S 13S 12S 13S 11S 10t1t2t3t4t5t6t7t8t9 t10t1t2t3t4t5t6t7t8t9 t10 t11 t12 t13 t14pastsafepastpredictivepastunknowncurrentunknownFigure 3: Example of situations’ status over time. In Fig. (b), (c) and (d), the horizontal axis indicates the time step, and overlapping situations aredisposed vertically, for the sake of readability. (a) Behaviour of adrenaline signal over time. In this example, the adrenaline is below the pre-definedthreshold, and instantly goes above it when an aversive US is detected. (b) Status of situations’ type at time t10. At this moment, all situations arestill considered unknown. (c) Status of situations’ type at time t13. At this moment, situation S 1 can no longer become a predictive or aversivesituation. As consequence, it leaves the status of unknown situation and becomes a safe situation. (d) Status of situations’ type at time t14. At thismoment an aversive US is detected and, consequently, adrenaline levels rise above the pre-defined threshold (see Fig. a). Because situation S 9 isthe last unknown situation to happen before the elevation of the adrenaline signal, it becomes a predictive situation.can contain the same event. For instance, event et4 be-longs to situations S 1, S 2, S 3 and S 4.A new unknown situation is activated every Δa timesteps (Fig. 3b), where Δa is a parameter of SAFEL,called situation detection delay, that defines the periodof time between the activation of a given situation andthe activation of its predecessor situation. Unknown sit-uations can be either current or past. For instance, inFig. 3b, situations from S 1 to S 6 are past because theyhave already finished by time t10, while situations S 7, S 8and S 9 are current because they are still occurring attime t10.Unknown situations may become safe or predictive inthe future, but only if certain constraints are satisfied atthe current moment, otherwise they continue to be con-sidered unknown. For instance, all situations detectedin Fig. 3b are still unknown, since nothing can be saidabout them at time t10. To be considered safe, a situationmust be past and be followed by at least two consecu-tive past unknown situations. This is to ensure it willnever precede or co-occur with any predictive or aver-sive situation. To be considered predictive, a situationmust precede a peak in the adrenaline level. Consid-ering that at moment t10 none of these conditions havebeen matched, all situations are still unknown at thatmoment.At moment t13 in Fig. 3c, however, the conditions fordetecting safe situations are satisfied by the current sta-tus of situation S 1. At time t13, situation S 1 is past and isfollowed by a past situation (S 5) that, at this point, canno longer become predictive. Thus, at time t13, situationS 1 leaves the status of unknown and becomes a safe sit-uation. Similarly, the conditions for detecting predictivesituations are also satisfied by the current status of situ-ation S 9 at time t14 in Fig. 3d, when the adrenaline levelrises above the specified threshold (as seen in Fig. 3a).Because S 9 is the last past unknown situation before theraise of adrenaline, it leaves the status of unknown situ-ation and becomes a predictive situation.Safe and predictive situations are immediately sentto the working memory module at their detection time,while unknown situations are sent at their deactivation10time. Consequently, every factually safe and predic-tive situation is sent twice to the working memory: firstwhen it has just finished and is still unknown; and thenagain a few time steps later, when the hippocampus isable to determine whether it is actually safe or predic-tive. In the example of Fig. 3, for instance, situationS 1 is sent to the working memory at time t5 as unknownand at time t13 as safe. Analogously, situation S 9 is sentto the working memory at time t13 as unknown and attime t14 as predictive. The dual submission of the samesituation instance, but with different situation types, isessential for the working memory to perform its task,which is discussed in the next section.4.2. Working Memory ModuleThe working memory is the place where emotionalmemory (formed in the amygdala) and contextual mem-ory (formed in the hippocampus) are fused to create“emotional contextual memories”. The goal is to pro-vide the robot with the capability to recover fear memo-ries and predict an imminent unpleasant event by expe-riencing again a situation that preceded that unpleasantevent in the past.In this section we discuss the working memory mod-ule regarding the main algorithm behind its associa-tive learning (Section 4.2.1) and its modelling (Section4.2.2).4.2.1. Underlying TechnologyThe working memory’s associative learning is im-plemented using MATLAB’s binary classification tree[66], which is used to classify situation patterns intosafe or predictive. In a binary classification tree, eachnode corresponds to a binary predicate on one attribute,where one branch from the node represents positive in-stances of the predicate and the other branch representsnegative instances. Each leaf node is labelled by a class.To predict the type of an input situation pattern, a pathto a leaf from the root is found depending on the valueof the predicate at each node that is visited.MATLAB creates a classification tree by firstanalysing the training dataset and examining all possi-ble binary splits on every attribute. Then, the first nodeis split according to its impurity gain, which is calcu-lated using the Gini Diversity Index (GDI), also knownas Gini Impurity Criterion [67]. The GDI of a node isgiven by(cid:2)1 −p2(i),i(1)has Gini index 0; otherwise the Gini index is positive.To split the node, MATLAB selects the attribute vari-able that maximizes the impurity gain (i.e., that maxi-mizes the purity of the node). This process is recursivelyrepeated for the child nodes, stopping when it finds apure node or when it reaches a stopping criteria, such asa maximum number of splits or maximum tree depth.The following design reasons led us to adopt the bi-nary classification tree:• Interpretable: classification trees are white box al-gorithms, thus allowing one to easily interpret thelogic behind the robot’s learning and emotional re-sponse to stimuli.• Insensitive to outliers: classification trees are builtby dynamically selecting the most informative fea-tures, and ignoring information that is irrelevantfor the predictions. This is an essential featurefor the working memory module, because in mostcases only a subset of the robot’s sensors will pro-vide valuable information about the pattern of aspecific situation. For instance, a robot may re-quire a camera, face recognition algorithms andsonar sensors to detect that a person is nearby, butmany other sensor information (e.g., internal tem-perature, accelerometer and battery level) wouldnot give valuable information in this case. It is es-sential that the classifier of the working memorymodule be able to ignore information that is irrele-vant for characterizing the pattern of predictive sit-uations.• Fast training and classification: classification treeis an algorithm well known by its fast training andclassification processes [68]. This is important be-cause SAFEL’s emotional learning greatly relieson constantly retraining the classifier of the work-ing memory module. The slower the re-trainingand classification processes are, the more time therobot would take to present an emotional reaction.• Non-parametric:classification trees are non-parametric algorithms, meaning that they do notrequire specifying parameters that depend on thedistribution of data. One of SAFEL’s goals is to beof general purpose. To be applicable to a varietyof environmental characteristics, SAFEL’s learn-ing must be independent of data shape.4.2.2. Working Memory Modelwhere p(i) is the proportion of cases of class j at the re-spective node. A node with just one class (a pure node)In the working memory module, situation instancescoming from the hippocampus module pass through a11feature extraction process in order to generate com-pacted versions of situational information. This phaseconsists of extracting relevant information that charac-terizes the fluctuation pattern of each stimulus over thesituations’ duration.From Definitions 1 and 2, and supposing that a j = 1and d j = m, and that the robot has n sensory inputs, wehave that:S j =⎞⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠⎛⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝e1e2...em=⎛⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝s11s21...sm1s12s22...sm2· · ·· · ·. . .· · ·⎞⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠s1ns2n...smn.From Eq. 2 we can say thatS j = [s1, s2, ..., sn],(2)(3)where si = [s1imation S (cid:5), ..., smi ]T . Then, the new situation infor-j generated from S j is given byS (cid:5)j= [s1, ..., sn, γ1, ..., γn, η1, ..., ηn],(4)where si, γi and ηi are, respectively, the mean, skewnessand number of local maxima of si (Eq. 3). The meanvalue provides the average intensity of each sensedstimulus along the situation’s duration. The skewnessprovides the approximate time interval when each stim-ulus was more intense during the respective situation.Finally, the number of local maxima provides the detec-tion frequency of each stimulus during the situation.The main goal of performing this feature extractionprocedure is to create approximated representations ofsituation instances that aid on the generalization aspect,thus preventing overfitting of situation patterns. Thenew piece of information generated by this process isanalogous to the unitary representation of context cre-ated in the brain, discussed in Section 3.2.This feature extraction phase is also useful for datacompression, since it can reduce the volume of infor-mation about situation j from a matrix S j of size n × mto a vector S (cid:5)j of size 3n. This is especially efficientwhen m (cid:6) n, which is in fact the most common case,as the number m of time steps in a situation is usuallymuch larger than the number n of sensory inputs a robotmay offer.As mentioned in Section 4.1, every factually safe andpredictive situation is sent in two time-steps from thehippocampus to the working memory: first when it isstill unknown and later when it is either factually safeor predictive. Therefore, at time d j (i.e., when situa-tion j has just been deactivated), S j will be sent as an12unknown situation to the working memory, where it istransformed into S (cid:5)j and submitted to the binary tree forclassification. The tree will classify that situation intosafe or predictive based on past situation experiencesof the robot. Then, at time tn, where tn > d j, situa-tion information S j will be sent to the working memoryonce again, but this time labelled as either safe of pre-dictive. The generated situation pattern S (cid:5)j and its type(safe or predictive) will now be used for retraining theclassification tree, providing it with one more situationexperience where to base its future predictions.For example, in Fig.3b, situation S 1 is sent tothe working memory as an unknown situation at timed1 = t5. Then, the working memory compacts S 1 intoS (cid:5)1, which is later classified as either safe or predictive.At time t13 in Fig. 3c, the same situation S 1 is sub-mitted again to the working memory, but now as a safesituation. This time, S (cid:5)1 is used for retraining the classi-fication tree, thus reinforcing that the pattern of S (cid:5)1 rep-resents a safe situation and indicates that no aversivestimulus is expected to occur in the near future.Similarly, situation S 9 is sent as unknown for pre-diction to the working memory at time d9 = t13 (Fig.3c). If the robot has experienced other situations that aresimilar to S 9 in the past, then the binary tree will verylikely classify S (cid:5)9 as a predictive situation, meaning thatan aversive stimulus is about to occur. Knowing at timet13 that something “bad” is about to occur is advanta-geous, as the system can use this information to preventor minimize the outcome of the aversive stimulus occur-ring at time t14, if possible. Then at time t14 (Fig. 3d),when the aversive stimulus occurs (making it possible toaffirm that S 9 is indeed a predictive situation), situationS 9 is sent again to the working memory and is used forretraining the classification tree to recognize the patternof S (cid:5)9 as a predictive situation.The dataset used to train the decision tree startsempty, with no knowledge about the current environ-ment. As the robot explores the environment and expe-riences new aversive situations, the dataset grows andthe tree is retrained. Therefore, the robot’s capabilityto predict imminent aversive events improves with ex-In addition,perience, as it explores the environment.because the tree is constantly retrained, the robot canadapt itself even when it is moved from one environ-ment to another. If a particular situation that was safein a previous environment is now predictive in the newenvironment, the classification tree will be constantlyretrained in this new environment to recognize that sit-uation as predictive, consequently gradually forgettingthe previous association of that situation with safety.5. Experiments with a Humanoid RobotIn terms of predictive performance, we understandthat comparing BEL [10] and SAFEL with focus ontemporal reasoning would be unfair, because unlikeSAFEL, BEL is not designed to process temporal se-quences of events. Although BEL has similarities withSAFEL, these are mostly conceptual, such as being in-spired by real brain mechanisms. Instead, we focus onexperiments showing the efficacy of SAFEL for predict-ing aversive events based on temporal context.The experiments have been conducted using a NAOhumanoid robot, model T14 (Fig. 4). NAO is one ofthe most widely used robots in the HRI field of research[69]. By using NAO, we hope to facilitate the reproduc-tion of our work, as well as the implementation of futurecomparative studies.In addition, by using a physical robot in this experi-ment, we aim at exposing SAFEL to noises and readingfailures characteristic of real robot sensors. In a virtu-ally simulated environment, the quality of sensor read-ing could be greatly improved in comparison to real sen-sors, providing smoother data and possibly facilitatingSAFEL’s predictions. As the goal of SAFEL is to be ofpractical use in real world scenarios, we decided to testit with data collected through real robot sensors. Forthis reason, all sensor noises and detection failures werepreserved during this experiment, so to analyse how itwould affect SAFEL’s prediction performance.We have used four types of sensor readings to repre-sent NAO’s perception of environmental stimuli, whichare:• s1: light level,• s2: number of human faces detected,• s3:identification of NAOmarks, which are land-mark images with specific patterns that NAOrobots can recognize and identify (Fig. 5),• s4: sound detection confidence, which is a numberin the range [0,1] depicting NAO’s confidence thata particular detected sound is real.In this experiment, the aversive stimulus is repre-sented by darkness, which is an analogy to the naturalfear and stress that most animals experience when theybecome unable to see. Hence, before running the ex-periment, SAFEL was configured to increase adrenalinelevels whenever NAO detected low light levels. The re-maining environmental stimuli (i.e., human faces, NAO-marks and sound detection) were initially neutral.We highlight that this experiment focuses on ob-serving the robot’s emotional response rather than itsbehavioural response.In fear conditioning, the be-havioural response of an individual is a reflex of its emo-tional response. The emotional response, in turn, is themost important feedback in order to verify that the in-dividual is under fear, as well as to evaluate the suc-cess of fear learning. Thus, in this experiment we focuson studying the robot’s emotional response to differentstimulation in order to verify that it can in fact learn andpredict aversive events based on situational information.In future work (Section 8), we plan to perform a robustcase study which will evaluate the behavioural responseof the robot, as well as how it affects the robot successinto accomplishing a given task.In order to create a controlled test environment,where we could analyse the influence of the same setFigure 4: The NAO robot used in the experiment. mark 64 mark 68Figure 5: Examples of NAOmark.13of situations under different parameter settings, we haveseparated the experiment into three phases. First we col-lected data, by repeatedly presenting the above-listedstimuli to NAO and then storing NAO’s sensor read-ings. In the second phase, we assembled the collecteddata in a specific time line, creating a dataset that wasreproduced for different parameters and configurations.Lastly, we ran SAFEL on each dataset independently,during which the instances of the datasets were pre-sented sequentially to SAFEL, as if it was being exe-cuted in the robot at real time. In this section, we de-scribe the first two phases in detail. The third phase isaddressed in Section 6.5.1. Data CollectionIn SAFEL, a situation pattern is the set of main tem-poral aspects (such as average time delay and temporalsequence among stimuli) that characterizes a given sit-uation. Hence, situation instance is the instantiation ofa situation pattern, and must have all the properties thata) NAOmark followed byface followed by darkness b) Face followed by NAOmarkcharacterize that pattern (e.g., a specific order of stimu-lus detection).We have collected data respecting six distinct situa-tion patterns. Fig. 6 shows examples of NAO’s sensorreadings for each of the six situation patterns inducedin the experiment. For example, the pattern of the sit-uation observed in Fig. 6b is characterized by the de-tection of a human face followed by the detection of aNAOmark. To collect data of situation instances withthis pattern, we first presented a human face to the robotfor about five seconds, after which we hid this face andpresented a NAOmark to the robot for about five sec-onds. This procedure has been performed at good lightconditions, so the robot could easily detect both humanfaces and NAOmarks. The same procedure was then in-dependently repeated several times in order to collectmany different instances of this same situation pattern.Analogously, to collect instances like the one seen inFig. 6c, we presented the NAOmark and a human faceat the same time to the robot at good light conditionsfor about five seconds, and then hid both. Again, werepeated this procedure several times in order to col-lect many different instances of this same pattern. Thesame sequence of steps was performed for collecting in-stances of the remaining situation patterns in Fig. 6.Fig. 6a depicts an example of predictive situationfollowed by an aversive stimulus, which in this casec) Face and NAOmarkd) Face only(cid:54)(cid:87)(cid:76)(cid:80)(cid:88)(cid:79)(cid:76)(cid:51)(cid:85)(cid:72)(cid:86)(cid:72)(cid:81)(cid:87)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)e) NAOmark onlyf) No stimulus presented050100150050100150NAOmark idFace recog.Darkness level(cid:36)(cid:89)(cid:72)(cid:85)(cid:86)(cid:76)(cid:89)(cid:72)(cid:72)(cid:89)(cid:72)(cid:81)(cid:87)Figure 6: Example of situation instances for each of the six situationpatterns induced in the experiment. Vertical axis depicts NAO’s sen-sor input after normalization. Horizontal axis depicts the time linecounted in numbers of events.Figure 7: Procedure for presenting the aversive event to the robot. (a)Lights are kept on, while a specific NAOmark is presented to NAO forabout 5 seconds. (2) With lights still on, the NAOmark is hidden, andthen a human face is presented to the robot for about 5 seconds. (3)Both human face and NAOmark are hidden. Light is turned off.1410.80.60.40.2010.80.60.40.2010.80.60.40.20(cid:54)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:51)(cid:68)(cid:87)(cid:87)(cid:72)(cid:85)(cid:81)(cid:3)(cid:20)(cid:41)(cid:68)(cid:70)(cid:72)(cid:3)(cid:73)(cid:82)(cid:79)(cid:79)(cid:82)(cid:90)(cid:72)(cid:71)(cid:3)(cid:69)(cid:92)(cid:3)(cid:49)(cid:36)(cid:50)(cid:80)(cid:68)(cid:85)(cid:78)(cid:11)(cid:26)(cid:3)(cid:76)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:86)(cid:12)(cid:54)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:51)(cid:68)(cid:87)(cid:87)(cid:72)(cid:85)(cid:81)(cid:3)(cid:21)(cid:41)(cid:68)(cid:70)(cid:72)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:49)(cid:36)(cid:50)(cid:80)(cid:68)(cid:85)(cid:78)(cid:3)(cid:86)(cid:76)(cid:80)(cid:88)(cid:79)(cid:87)(cid:68)(cid:81)(cid:72)(cid:82)(cid:88)(cid:86)(cid:79)(cid:92)(cid:11)(cid:28)(cid:3)(cid:76)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:86)(cid:12)(cid:54)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:51)(cid:68)(cid:87)(cid:87)(cid:72)(cid:85)(cid:81)(cid:3)(cid:22)(cid:41)(cid:68)(cid:70)(cid:72)(cid:3)(cid:82)(cid:81)(cid:79)(cid:92)(cid:11)(cid:21)(cid:19)(cid:3)(cid:76)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:86)(cid:12)(cid:54)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:51)(cid:68)(cid:87)(cid:87)(cid:72)(cid:85)(cid:81)(cid:3)(cid:23)(cid:49)(cid:36)(cid:50)(cid:80)(cid:68)(cid:85)(cid:78)(cid:3)(cid:82)(cid:81)(cid:79)(cid:92)(cid:11)(cid:20)(cid:28)(cid:3)(cid:76)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:86)(cid:12)(cid:54)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:51)(cid:68)(cid:87)(cid:87)(cid:72)(cid:85)(cid:81)(cid:3)(cid:24)(cid:49)(cid:82)(cid:3)(cid:86)(cid:87)(cid:76)(cid:80)(cid:88)(cid:79)(cid:88)(cid:86)(cid:11)(cid:25)(cid:24)(cid:3)(cid:76)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:86)(cid:15)(cid:3)(cid:90)(cid:75)(cid:76)(cid:70)(cid:75)(cid:3)(cid:80)(cid:68)(cid:92)(cid:3)(cid:69)(cid:72)(cid:3)(cid:85)(cid:72)(cid:83)(cid:72)(cid:68)(cid:87)(cid:72)(cid:71)(cid:3)(cid:76)(cid:81)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:86)(cid:68)(cid:80)(cid:72)(cid:3)(cid:71)(cid:68)(cid:87)(cid:68)(cid:86)(cid:72)(cid:87)(cid:12)(cid:54)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:51)(cid:68)(cid:87)(cid:87)(cid:72)(cid:85)(cid:81)(cid:3)(cid:25)(cid:3)(cid:11)(cid:83)(cid:85)(cid:72)(cid:71)(cid:17)(cid:12)(cid:49)(cid:36)(cid:50)(cid:80)(cid:68)(cid:85)(cid:78)(cid:3)(cid:73)(cid:82)(cid:79)(cid:79)(cid:82)(cid:90)(cid:72)(cid:71)(cid:3)(cid:69)(cid:92)(cid:3)(cid:41)(cid:68)(cid:70)(cid:72)(cid:15)(cid:3)(cid:73)(cid:82)(cid:79)(cid:79)(cid:82)(cid:90)(cid:72)(cid:71)(cid:3)(cid:69)(cid:92)(cid:3)(cid:71)(cid:68)(cid:85)(cid:78)(cid:81)(cid:72)(cid:86)(cid:86)(cid:11)(cid:21)(cid:27)(cid:3)(cid:76)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:86)(cid:12)(cid:53)(cid:68)(cid:81)(cid:71)(cid:82)(cid:80)(cid:79)(cid:92)(cid:3)(cid:54)(cid:72)(cid:79)(cid:72)(cid:70)(cid:87)(cid:3)(cid:68)(cid:3)(cid:54)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:44)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:3)(cid:73)(cid:85)(cid:82)(cid:80)(cid:3)(cid:54)(cid:51)(cid:21)(cid:53)(cid:68)(cid:81)(cid:71)(cid:82)(cid:80)(cid:79)(cid:92)(cid:3)(cid:54)(cid:72)(cid:79)(cid:72)(cid:70)(cid:87)(cid:3)(cid:68)(cid:3)(cid:54)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:44)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:3)(cid:73)(cid:85)(cid:82)(cid:80)(cid:3)(cid:54)(cid:51)(cid:20)(cid:53)(cid:68)(cid:81)(cid:71)(cid:82)(cid:80)(cid:79)(cid:92)(cid:3)(cid:54)(cid:72)(cid:79)(cid:72)(cid:70)(cid:87)(cid:3)(cid:68)(cid:3)(cid:54)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:44)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:3)(cid:73)(cid:85)(cid:82)(cid:80)(cid:3)(cid:54)(cid:51)(cid:25)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:22)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:20)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:25)(cid:54)(cid:51)(cid:24)(cid:44)(cid:71)(cid:72)(cid:81)(cid:87)(cid:76)(cid:70)(cid:68)(cid:79)(cid:3)(cid:86)(cid:72)(cid:84)(cid:88)(cid:72)(cid:81)(cid:70)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:86)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:83)(cid:68)(cid:87)(cid:87)(cid:72)(cid:85)(cid:81)(cid:86)(cid:3)(cid:68)(cid:80)(cid:82)(cid:81)(cid:74)(cid:3)(cid:71)(cid:68)(cid:87)(cid:68)(cid:86)(cid:72)(cid:87)(cid:86)(cid:86)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:22)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:20)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:25)(cid:54)(cid:51)(cid:24)(cid:54)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:20)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)(cid:54)(cid:51)(cid:21)(cid:54)(cid:51)(cid:23)(cid:54)(cid:51)(cid:24)(cid:39)(cid:68)(cid:87)(cid:68)(cid:86)(cid:72)(cid:87)(cid:3)(cid:20)(cid:54)(cid:51)(cid:21)(cid:54)(cid:51)(cid:23)(cid:54)(cid:51)(cid:24)(cid:39)(cid:68)(cid:87)(cid:68)(cid:86)(cid:72)(cid:87)(cid:3)(cid:21)(cid:24)(cid:22)(cid:54)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:24)(cid:24)(cid:22)(cid:17)(cid:17)(cid:17)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:22)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:20)(cid:54)(cid:51)(cid:24)(cid:54)(cid:51)(cid:25)(cid:54)(cid:51)(cid:24)(cid:17)(cid:17)(cid:17)(cid:54)(cid:51)(cid:21)(cid:54)(cid:51)(cid:23)(cid:54)(cid:51)(cid:24)(cid:39)(cid:68)(cid:87)(cid:68)(cid:86)(cid:72)(cid:87)(cid:3)(cid:20)(cid:19)(cid:86)(cid:72)(cid:87)(cid:3)(cid:82)(cid:73)(cid:3)(cid:86)(cid:68)(cid:73)(cid:72)(cid:3)(cid:86)(cid:76)(cid:87)(cid:88)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:11)(cid:76)(cid:81)(cid:87)(cid:72)(cid:85)(cid:89)(cid:68)(cid:79)(cid:3)(cid:89)(cid:68)(cid:85)(cid:76)(cid:72)(cid:86)(cid:3)(cid:73)(cid:85)(cid:82)(cid:80)(cid:3)(cid:21)(cid:3)(cid:87)(cid:82)(cid:3)(cid:21)(cid:24)(cid:3)(cid:80)(cid:76)(cid:81)(cid:12)(cid:19)(cid:97)(cid:22)(cid:19)(cid:86)(cid:72)(cid:70)(cid:55)(cid:76)(cid:80)(cid:72)(cid:97)(cid:23)(cid:17)(cid:24)(cid:75)Figure 8: Dataset generation process. First, we individually collected a number of situation instances for each of the 6 situation patterns inducedin this experiment. Then, for each pattern in the chosen sequence of situation patterns, we randomly select a situation instance of that pattern andconcatenate it to the dataset. This procedure is repeated 10 times, so to generate 10 distinct datasets with the same temporal order of situationpatterns.is darkness. The predictive situation is characterizedby the presentation of the NAOmark at good light con-ditions, followed by the presentation of a human face(demonstrated in Fig. 7). Because this pattern is alwaysfollowed by the presentation of an aversive stimulus, itis then considered to be the pattern of a predictive situa-tion. On the other hand, all the other patterns (Fig. 6b to6f) represent safe situations, because they never precedeany aversive event.Observe that some situation patterns, such as the onesin Fig. 6b and 6c, are similar to the pattern of the pre-dictive situation in Fig. 6a. This is because we desireto verify SAFEL’s capability to effectively differentiatesafe situations from predictive situations, even when thepatterns of these situations are similar.Although exposition duration and delay of each stim-ulus was similar among data collections, it was not rig-orously timed, as it is part of the experiment to evalu-ate SAFEL’s generalisation capability. Besides, in realworld cases, situation instances of the same situationpattern may have similar temporal delays, but rarelyequal.5.2. Dataset GenerationFig. 8 demonstrates the process for generating thedatasets used in this experiment. We have generated10 different datasets, which are composed of the situ-ation instances collected through the process explainedin Section 5.1. The individually collected situation in-stances were arranged in the datasets according to a spe-cific temporal sequence of situation patterns, which isidentical for all the 10 datasets.To generate a dataset, we randomly selected a situa-tion instance matching the first situation pattern of thechosen temporal sequence and concatenated this situ-ation instance to the dataset. Then we repeated thesesteps for all the remaining situation patterns in the cho-sen temporal sequence (Fig. 8). Because all sensornoise and failures have been preserved during data col-lection, a few situation instances may present incom-plete of fragmented data. To prevent the temporal po-sitioning of a problematic situation instance influencingthe result, we generated 10 datasets in total using theabove-mentioned method.Only situation instances with no stimulus presenta-tion (with the pattern of Fig. 6f) were reused in the samedataset. Since they are basically the absence of stimula-15tion, situation instances of this pattern are highly similarto each other, and so they can be reused without affect-ing the integrity of the experiment. Situation instancesof the remaining patterns (Fig. 6a to 6e) were not reusedin the same dataset.Each dataset is equivalent to about 4.5 hours testingand contains 28 aversive situations (and, consequently,28 predictive situations), which are separated by inter-vals varying from 2 to 25 minutes representing the set ofsafe situations, which may comprise any of the situationpatterns from Fig. 6b to 6f.5.3. Validation MethodologyThe generated datasets have been evaluated accord-ing to three factors. The first factor evaluates SAFEL’sperformance under different pre-defined situation dura-tions. SAFEL has been analysed for three situation du-rations: 20 seconds (Δa = 4 sec), 30 seconds (Δa = 6sec) and 40 seconds (Δa = 8 sec).The second factor evaluates SAFEL’s capability toignore sensory inputs that are not relevant for predict-ing the occurrence of aversive stimuli. In this regard,we evaluated SAFEL on two versions of each generateddataset, one with and another without sound sensor in-put. Since there are no particular patterns in the soundinformation detected by NAO, it should have small in-fluence in the final prediction. Thus, SAFEL’s outcomeshould be similar for both dataset versions.Finally, the third factor evaluates the impact of differ-ent values of inter stimulus interval (ISI) on SAFEL’sperformance. Inter stimulus interval, is the time inter-val between the offset of the predictive situation and theonset of the aversive event. For example, in this experi-ment, the ISI is the time interval starting right after thepresentation of the NAOmark followed by a human face,and ending right before increasing the darkness level ofthe environment.We have tested three values of ISI: 5, 10 and 15seconds. The goal of testing different ISIs is to anal-yse whether the temporal position of relevant events inthe predictive situation can influence SAFEL’s perfor-mance.Considering all dataset generations (10 datasets, 3ISIs and 2 sets of stimuli input, with and without soundreadings) and the 3 situation durations tested, this ex-periment contains 180 dataset samples in total.6. ResultsAll 180 generated datasets were tested indepen-dently, and their instances were presented sequentiallyto SAFEL, as if it was being executed in the robot atreal time. For each run, we started measuring predictiveperformance after the classifier had processed the initial20% of the respective dataset. This decision was madebecause we assume that the classifier would not haveenough samples from each situation type (safe and pre-dictive) to create a differentiation among them withoutlearning the initial 20% of the datasets.We have used the f-measure as performance metricto evaluate SAFEL’s efficacy for classifying unknownsituations into safe or predictive. The f-measure, alsoknown as f-score, is the harmonic mean between preci-sion and recall.Fig. 9 shows SAFEL’s performance regarding thethree factors mentioned in Section 5.3, which are (1)situation duration, (2) input set and (3) ISIs. The gen-erated dataset samples have been divided into groupswithin each factor that reflect the features under whichthey are being evaluated.The first factor evaluates the influence of differentvalues of the situation duration parameter on the clas-sification performance. It has been divided into threegroups of 60 samples (Fig. 9a). The first group com-prises all dataset samples with situation duration equals20 seconds, the second group comprises all sampleswith situation duration equals 30 seconds, and the thirdgroup comprises all samples with situation durationequals 40 seconds.The second factor evaluates SAFEL’s capability to ig-S D = 20secS D = 30secS D = 40secw/o soundw/ soundISI = 5 secISI = 10 secISI = 15 seca)b)c)00.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.91Classification PerformanceFigure 9: Average classification performance (f-measure) amongdataset samples per group, where error bars show the 95% confidenceinterval of the respective group. Each graphic shows the results forone of the evaluated factors, which are (a) situation duration (SD), (b)input set (with or without sound input) and (c) ISI.16nore sensory information that is irrelevant for the pre-diction. This factor is divided into two groups of 90samples (Fig. 9b). The first group comprises all datasetsamples without input from the sound sensor and thesecond group comprises all dataset samples with inputfrom the sound sensor.The third factor evaluates the influence of differentvalues of ISI on the classification performance. It is di-vided into three groups of 60 samples (Fig. 9c). Thefirst group contains all datasets with Δp = 5 seconds,the second group contains all datasets with Δp = 10seconds, and the third group contains all datasets withΔp = 15 seconds.In order to study the effects of these three factorson SAFEL’s classification performance, we have usedthe factorial analysis of variance (factorial ANOVA),where the null hypothesis states that there is no statis-tically significant difference in the classification perfor-mance among groups within a given factor, and is re-jected when p ≤ 0.05.Through the ANOVA test, we have analysed the sig-nificance of the main effects (i.e., the three factors in-dependently) and of the two-way interactions betweenfactors on the classification performance. The ANOVAtest has not found statistically significant interaction be-tween factors. The test also found no statistically sig-nificant difference between groups within the first andsecond factors, which are situation duration and inputset, respectively.This result indicates that there is no significant dif-ference in the classification performance when varyingthe situation duration from 20 to 40 seconds, which re-inforces the robustness of SAFEL for situation predic-tion.It also indicates that there is no significant dif-ference in classification performance between datasetswith and without sound sensor input. This demonstratesthat SAFEL managed to mostly ignore sound informa-tion, as expected. Because sound input had no particularpatterns regarding the presentation of aversive stimuli,if SAFEL had significantly considered it for classifyingsituations into safe or predictive, the second group ofdatasets in Fig. 9b could present much lower predictiveperformance.On the other hand, the ANOVA test has found sta-tistically significant difference in the classification per-formance among groups within the third factor (p =0.0001), which evaluates the variation of the ISI. How-ever, even though the ANOVA test has found statisti-cally significant difference among groups, we can ob-serve through the confidence intervals shown in Fig. 9cthat such difference is minimal. We can assert with 95%confidence level that the (true) performance mean of the17three groups in Fig. 9c are, respectively, within the in-tervals [0.66, 0.7], [0.68, 0.72] and [0.62, 0.66]. Thecloseness of the confidence intervals indicates that, al-though the ISI can influence the classification perfor-mance, such effect is not substantial.7. DiscussionIn this section, we investigate how the positioningof the events of interest in the predictive situation caninfluence the classification performance. This has po-tentially led to the result observed in Fig. 9c. Wealso discuss SAFEL’s performance over time, aimingat analysing how the prediction of aversive events im-proves as the robot enriches its knowledge about thesurrounding environment.7.1. Influence of the Events of InterestEvents of interest are those events that persistentlyprecede aversive events, but are consistently absent insafe situations. Hence, events of interest are the set ofevents that can provide the most valuable information todifferentiate a safe situation from a predictive situation.The proper detection and management of this informa-tion is, therefore, essential for consistently training theclassification tree.Fig. 10 demonstrates how a particular configurationof ISI and situation duration can affect the classificationperformance. In the performed experiment, the eventsof interest for predicting the aversive event are the pre-sentation of a NAOmark for about 5 seconds (red linesin Fig. 10) followed by the presentation of a human facefor about 5 seconds (blue lines in Fig. 10). The ISI isrepresented by dotted black lines, which may have 5,10 or 15 seconds (Fig. 10a, 10b and 10c, respectively).Green lines represent the three tested durations of pre-dictive situations, which are 20, 30 and 40 seconds.Observe in Fig. 10 that predictive situations alwayscontain all events of interest, except when Δp = 15seconds and the situation duration is 20 seconds long(Fig. 10c). In this case, the first 5 seconds of the eventsof interest (i.e., the presentation of the NAOmark) areleft out of the predictive situation. As consequence, anincorrect pattern of predictive situation is used to trainthe classification tree. Instead of NAOmark followed byface recognition (Fig. 6a), the tree is trained to recog-nized situations with face recognition only (Fig. 6d) aspredictive. The problem is aggravated by the fact thatsome safe situations have the same pattern. As conse-quence, the tree is trained with inconsistent information,in which the same situation pattern is sometimes pre-sented as safe and sometimes presented as predictive.Aversive EventΔp = 5FaceNAOmarkdur = 20sNAOmarkFaceΔp = 10dur = 20sdur = 30sdur = 30sNAOmarkdur = 30sΔp = 15Facedur = 20sa)dur = 40sb)dur = 40sc)dur = 40secnamrofreP10.80.60.40.200.740.680.670.750.680.690.680.630.63ISI = 5 secISI = 10 secISI = 15 secSituation Duration:20sec30sec40sec510201525Time in Seconds303540Figure 11: Mean classification performance (f-measure) amongdatasets generated without sound information, grouped by their sit-uation duration and ISI.Figure 10: Time positioning of the events of interest during predic-tive situations. The diagram shows the possible scenarios consideringall combinations of situation duration and ISI used in the experiment.Green lines depict the different situation durations (20, 30 and 40 sec-onds). The different values of ISI are represented by black dottedlines, which are (a) 5 seconds, (b) 10 seconds and (c) 15 seconds.Events of interest are depicted by red and blue lines, which representthe presentation of NAOmark and human face to the robot, respec-tively.This could explain the difference in classification per-formance observed in Fig. 9c.Fig. 11 shows the average performance for all eval-uated datasets without sound input. Note that SAFELhas consistently demonstrated better performance fordatasets where the situation duration is 20 seconds, ex-cept when Δp = 15 seconds, case in which we can ob-serve the largest performance decay of the graphic. Theresult of Fig. 11 supports the explanation given above,indicating that the problem demonstrated by Fig. 10c isindeed the main reason for the discrepancy observed inFig. 9c.In addition, the higher performance obtained whensituation duration equals 20 seconds (in comparisonwith the other situation durations tested) shows thatkeeping the length of the situation duration as close aspossible to the length of the events of interest leads tobetter results (as long as it manages to cover all theevents of interest). One can speculate that if the situ-ation duration is too large, the classifier may start con-sidering noise from other events (having happened longbefore the aversive event) that are not part of the eventsof interest.In conclusion, the situation duration should not be tooshort, neither too large. The ideal scenario is to have thesituation duration just large enough to cover the eventsof interest. A way of tackling this problem is to create amechanism that allows SAFEL to automatically adjustthe duration of situations, which is an improvement thatwe will perform in future work (Section 8).7.2. Performance Over TimeThrough SAFEL, the robot learns continuously dur-ing its life cycle, thus improving its predictive capabil-ities with each newly detected stimulus. Fig. 12 showsthe classification outcome and its performance over timefor two of the 180 datasets tested with SAFEL. Fig. 12adepicts the most common result among the evaluateddatasets and Fig. 12b depicts the worst-case scenario.We have generated similar graphics for each of the 180datasets evaluated, which are available online1.Since situations can partially overlap each other (asseen in Fig. 3), part of the events of interest for detectingan aversive event may be in more than one situation.Thus, it is reasonable that the working memory startsto predict an aversive event a few situations before theactual predictive situation. To take into account suchcases, we have considered as true positive any situationclassified as predictive that is in a range of five situationsbefore the actual predictive situation.Observe in Fig. 12a that performance increases as thenumber of processed situations increases. Classifica-tion recall is low for the first third of the detected situa-tions because SAFEL did not predict any of the aversiveevents happening during that period. Recall improved1https://www.cs.kent.ac.uk/people/rpg/cr519/safel18classespredictions.fissalCecnamrofrePnoisicerPllaceR10.5010.5010.5001,0002,0003,000Number of Situations(a) Performance over time for the dataset without sound input,situation duration equals 30 seconds and prediction prece-dence equals 10 seconds.classespredictions.fissalCecnamrofrePnoisicerPllaceR10.5010.5010.5001,0002,0003,000Number of Situations(b) Performance over time for the dataset without sound input,situation duration equals 20 seconds and prediction prece-dence equals 15 seconds.Figure 12: SAFEL’s performance over time for two of the 180datasets. Figure (a) and (b) show four graphics each. The first graphicpresents the result of SAFEL’s classification: read-line peaks indicatethe occurrence of aversive events over time and blue-line peaks indi-cate SAFEL’s predictions for aversive events. The last three graphicsshow the f-measure, precision and recall of SAFEL’s classificationover time, respectively. These graphics show two types of over-timemeasurement: the first, depicted by the blue line, is the cumulativeperformance over the integral test; the second, depicted by the bars,is a more “instantaneous” over-time measurement. In this case, theperformance is cumulative only in the interval comprised by the re-spective bar. About 20% of each dataset was used exclusively fortraining, so the performance values shown in the last three graphicscontemplate only the remaining 80% of the respective dataset.for the second third of the detected situations, but pre-cision was affected because SAFEL misclassified a fewsafe situations during that period. However, towards theend, both precision and recall improved as a result ofSAFEL correctly classifying most situations in the finalthird of the dataset.This demonstrates that SAFEL’s predictions get moreaccurate over time. The classification tree starts empty,with no knowledge aboutthe current environment,which explains the low predictive performance in thebeginning of the dataset. As the robot experiences dif-ferent situations, the tree is fed with information aboutthe environment and becomes able to provide better pre-dictions. The more experience the robot gains about theenvironment, the higher the accuracy of SAFEL’s pre-dictions.The learning process described above is ubiquitous innature. For example, most animals that have never seenor touched fire before could, by curiosity, naively try tointeract with it. After touching it for the first or sec-ond time, they would be afraid of fire and would avoidtouching it in the future. However, it is important to no-tice that “being afraid” of fire is only possible after theanimal acquires the knowledge that fire can be harmful.And the more experiences the animal has with fire, thebigger its confidence that fire is indeed dangerous.This learning pattern, in which prediction accuracyimproves over time, is reflected in the majority of the ex-periments that we have performed with SAFEL, and thespeed with which performance improves varies amongdatasets. The exception is the case described in Section7.1, in which the classification tree is fed with incorrectpatterns of predictive situations.Fig. 12b shows an example of the performance overtime when predictive situations happen to miss part ofthe events of interest (in our case, when the situationduration is 20 seconds and the ISI is 15 seconds). Fig.12b shows a slow and modest performance improve-ment over time, which decays after 2000 situations. Inaddition, classification precision is poor from the begin-ning to the end of the experiment due to the large num-ber of safe situations classified as predictive. As previ-ously mentioned, this is because the tree is being trainedwith inconsistent information, where the same situationpattern is sometimes presented as safe and sometimespresented as predictive. Therefore, in this case, the clas-sification tree has no basis for providing an accurate pre-diction.7.3. Final ConsiderationsThe experiments have demonstrated that, as long asall events of interest are captured by the predictive sit-19uations, the actual duration of these situations, as wellas their ISI, do not meaningfully influence the classifi-cation performance. This means that SAFEL is capableof adapting to different temporal characteristics with-out performance decay. In addition, Fig. 9 shows that,although all sensor noises and detection failures havebeen preserved, SAFEL was capable of predicting aver-sive events based on situational information with 67%of classification performance (f-measure) on average.8. ConclusionIn this paper we have proposed SAFEL, a situation-aware computational model capable of learning andpredicting threatening situationsthrough a fear-conditioning-like procedure. SAFEL is based on thefear-learning model of the human brain. Experimentswith a NAO humanoid robot have been performed,which aimed at evaluating SAFEL regarding its capa-bility to:• identify events’ temporal order;• identify and differentiate patterns of situations;• associate a particular situation pattern with the im-minent occurrence of an aversive event;• ignore environmental stimuli that are irrelevant forpredicting aversive events; and• adapt to varied temporal characteristics, such asdifferent situation durations.Experiment results were positive in all evaluatedaspects, corroborating the potential of artificial fear-learning models when combined with concepts of situa-tion awareness to improve a robot’s adaptive behaviour.Future work involves expanding SAFEL with addi-tional modules. As mentioned in Section 4, the workdiscussed here implements part of a larger architec-ture [31], which includes an amygdala module in ad-dition to the hippocampus and working memory. Next,we will implement an amygdala module, which wouldbe responsible for accessing the emotional significanceof stimuli (i.e., whether it is aversive). The amygdalamodule will then create associations between individ-ual stimuli and signal its fear perception to other brainareas, such as the hippocampus.We will also improve the existing hippocampus mod-ule. As mentioned in Section 7.1, the duration of situa-tions may affect the classification performance if it is soshort that part of the events of interest are left out of the20active period of predictive situations. In the same sense,very large situation durations may also lead the workingmemory to start considering events that are actually ir-relevant for predicting aversive events. This could leadto low classification performance.To address this issue, we will extend the current ver-sion of SAFEL by implementing either a search mech-anism [70] or an evolutionary robotics approach [71]that would automatically adjust the duration of situa-tions based on the values that yielded best classificationperformance in the past. This would reduce the set ofpre-configured parameters of the system and consider-ably improve the prediction performance.In addition, we expect to increase the believability ofthe robot’s response by tuning the misclassification costof predictive situations in the working memory mod-ule. Most animals that are capable to fear have evolvedto overestimate danger, as the cost of underestimatinga danger is usually much higher than overestimating it[2]. The same rule applies to real companion robots,since they inhabit the same world as us.In order tomake SAFEL’s fear responses more biologically plau-sible, we intend to mimic nature’s tendency to overesti-mate danger, by increasing the misclassification cost ofpredictive situations in the working memory.Finally, the experiments performed so far have evalu-ated SAFEL in relation to its main goal of simulatingfear learning and predicting aversive events based onsituational information. However, there are other as-pects of SAFEL that we will also evaluate in furtherexperiments. These include, but are not restricted to,SAFEL’s capability to: associate multiple situation pat-terns with the same aversive event, associate multipletypes of aversive events, and identify not only stimulitemporal order, but also intensity.We will also perform a robust case study, in whichthe robot’s success in accomplishing a complex task willgreatly depend on its emotional learning skills, as wellas its capability to predict threats and adapt to environ-mental changes.AcknowledgementThe first and third authors are financially supportedby CAPES, a Brazilian research-support agency (pro-cess numbers 0648/13-2 and 0653-13-6, respectively).We also thank Dr. Owen Lyne, from the School ofMathematics, Statistics and Actuarial Science in theUniversity of Kent (England, UK), for the advice onthe statistical analysis. Finally, we thank the RoboticsLaboratory of the Heriot-Watt University (Edinburgh,UK) for providing the resources necessary for the ex-periments.References[1] A. Damasio, Descartes’ Error: Emotion, Reason and the HumanBrain, Avon Books, New York, 1994.[2] J. LeDoux, The Emotional Brain: The Mysterious Underpin-nings of Emotional Life, Phoenix, London, 1999.[3] N. Fragopanagos, J. Taylor, Modelling the interaction of at-tention and emotion, Neurocomputing 69 (1618) (2006) 1977–1983. doi:10.1016/j.neucom.2005.11.016.[4] K. Dautenhahn, The Art of Designing Socially IntelligentAgents - Science, Fiction and the Human in the Loop,Applied Artificial(1998) 573–617.Intelligence 12 (7-8)doi:10.1080/088395198117550.[5] W. C. Ho, K. Dautenhahn, M. Y. Lim, P. Vargas, R. Aylett,S. Enz, An Initial Memory Model for Virtual and Robot Com-panions Supporting Migration and Long-Term Interaction, in:The 18th IEEE International Symposium on Robot and Hu-man Interactive Communication (RO-MAN), 2009, pp. 277–284. doi:10.1109/ROMAN.2009.5326204.[6] P. A. Vargas, Y. Fernaeus, M. Y. Lim, S. Enz, W. C. Ho, M. Ja-cobsson, R. Ayllet, Advocating an ethical memory model forartificial companions from a human-centred perspective, AI &Society 26 (4) (2011) 329–337. doi:10.1007/s00146-010-0313-3.[7] S. Enz, M. Diruf, C. Spielhagen, C. Zoll, P. A. Vargas, The So-cial Role of Robots in the Future - Explorative Measurement ofHopes and Fears, International Journal of Social Robotics 3 (3)(2011) 263–271. doi:10.1007/s12369-011-0094-y.[8] J. Kim, G. Gu, P. Heo, Robotics for healthcare, in: H. Jo, H. Jun,J. Shin, S. Lee (Eds.), Biomedical Engineering: Frontier Re-search and Converging Technologies, Vol. 9 of Biosystems &Biorobotics, Springer International Publishing, 2016, pp. 489–509. doi:10.1007/978-3-319-21813-7 21.[9] N. Lazzeri, D. Mazzei, A. Zaraki, D. De Rossi, Towards abelievable social robot, in: N. Lepora, A. Mura, H. Krapp,P. Verschure, T. Prescott (Eds.), Biomimetic and Biohybrid Sys-tems, Vol. 8064 of Lecture Notes in Computer Science, SpringerBerlin Heidelberg, 2013, pp. 393–395. doi:10.1007/978-3-642-39802-5 45.[10] J. Mor´en, C. Balkenius, Emotional Learning: A ComputationalModel of the Amygdala, Cybernetics and Systems 32 (6) (2001)611–636. doi:10.1080/01969720118947.[11] C. Lucas, D. Shahmirzadi, N. Sheikholeslami, Introducing Bel-bic: Brain Emotional Learning Based Intelligent Controller, In-telligent Automation & Soft Computing 10 (1) (2004) 11–21.doi:10.1080/10798587.2004.10642862.[12] E. Lotfi, M.-R. Akbarzadeh-T.,emotionalneural networks, Neural Networks 59 (2014) 61–72.doi:10.1016/j.neunet.2014.06.012.Practical[13] M. A. Salichs, M. Malfaz, A New Approach to Modeling Emo-tions and Their Use on a Decision-Making System for ArtificialAgents, IEEE Transactions on Affective Computing 3 (1) (2012)56–68. doi:10.1109/T-AFFC.2011.32.[14] T. Babaie, R. Karimizandi, C. Lucas, Learning based brainemotional intelligence as a new aspect for development ofan alarm system, Soft Computing 12 (9) (2007) 857–873.doi:10.1007/s00500-007-0258-8.[15] C. Lucas, R. M. Milasi, B. N. Araabi, Intelligent Model-ing and Control of Washing Machine Using Locally LinearNeuro-Fuzzy (LLNF) Modeling and Modified Brain Emotional21Learning Based Intelligent Controller (BELBIC), Asian Jour-doi:10.1111/j.1934-nal of Control 8 (4) (2006) 393–400.6093.2006.tb00290.x.[16] M. R. Jamali, M. Dehyadegari, A. Arami, C. Lucas, Z. Nav-abi, Real-time embedded emotional controller, Neural Comput-ing and Applications 19 (1) (2009) 13–19. doi:10.1007/s00521-008-0227-x.[17] R. Ravi, S. Mija, Design of Brain Emotional Learning Based In-telligent Controller (BELBIC) for Uncertain Systems, in: 2014International Conference on Advanced Communication Con-trol and Computing Technologies (ICACCCT), 2014, pp. 1089–1093. doi:10.1109/ICACCCT.2014.7019265.[18] M. K. Sharma, A. Kumar, Performance Comparison of BrainEmotional Learning-Based Intelligent Controller (BELBIC) andPI Controller for Continually Stirred Tank Heater (CSTH),in: K. Maharatna, K. G. Dalapati, K. P. Banerjee, K. A.Mallick, M. Mukherjee (Eds.), Computational Advancementin Communication Circuits and Systems: Proceedings of IC-CACCS 2014, Springer India, New Delhi, 2015, pp. 293–301.doi:10.1007/978-81-322-2274-3 32.[19] M. Azizur Rahman, R. Milasi, C. Lucas, B. Araabi, T. Rad-wan,Implementation of Emotional Controller for InteriorPermanent-Magnet Synchronous Motor Drive, IEEE Trans-actions on Industry Applications 44 (5) (2008) 1466–1476.doi:10.1109/TIA.2008.2002206.Speed and Flux Control of[20] G. Markadeh, E. Daryabeigi, C. Lucas, M. Azizur Rah-Induction Motorsman,Using EmotionalIEEE Transac-Intelligent Controller,tions on Industry Applications 47 (3) (2011) 1126–1135.doi:10.1109/TIA.2011.2125710.[21] E. Daryabeigi, N. Abjadi, G. Arab Markadeh, Automaticspeed control of an asymmetrical six-phase induction motor us-ing emotional controller (BELBIC), Journal of Intelligent andFuzzy Systems 26 (4) (2014) 1879–1892. doi:10.3233/IFS-130867.[22] E. Lotfi, M.-R. Akbarzadeh-T., Adaptive brain emotionaldecayed learning for online prediction of geomagneticactivity indices, Neurocomputing 126 (2014) 188–196.doi:10.1016/j.neucom.2013.02.040.[23] A. M. El-Garhy, M. E. El-Shimy, BELBIC for MRAS withhighly non-linear process, Alexandria Engineering Journal54 (1) (2015) 7–16. doi:10.1016/j.aej.2014.12.001.[24] A. R. Mehrabian, C. Lucas,J. Roshanian, Aerospacelaunch vehicle control:an intelligent adaptive approach,Aerospace Science and Technology 10 (2) (2006) 149–155.doi:10.1016/j.ast.2005.11.002.[25] M. Jafari, A. Shahri, S. Shouraki, Attitude Control of a Quadro-tor Using Brain Emotional Learning Based Intelligent Con-troller, in: 2013 13th Iranian Conference on Fuzzy Systems(IFSC), 2013, pp. 1–5. doi:10.1109/IFSC.2013.6675672.[26] C. Kim, R. Langari, Target Tracking Control of a MobileRobot Using a Brain Limbic System Based Control Strat-IEEE/RSJ International Conference on Intelligentegy,Robots and Systems, 2009. IROS 2009, 2009, pp. 5059–5064.doi:10.1109/IROS.2009.5354280.in:[27] S. Jafarzadeh, R. Mirheidari, M. Motlagh, M. Barkhordari, De-signing PID and BELBIC Controllers in Path Tracking andCollision Problem in Automated Highway Systems, in: 10thInternational Conference on Control, Automation, Roboticsand Vision, 2008. ICARCV 2008, 2008, pp. 1562–1566.doi:10.1109/ICARCV.2008.4795757.[28] M. Sharbafi, C. Lucas, R. Daneshvar, Motion Control of Omni-Directional Three-Wheel Robots by Brain-Emotional-Learning-Based Intelligent Controller, IEEE Transactions on Systems,Man, and Cybernetics, Part C: Applications and Reviews 40 (6)(2010) 630–638. doi:10.1109/TSMCC.2010.2049104.445–455. doi:10.1016/j.neunet.2005.03.003.[29] N. Garmsiri, F. Najafi, M. Saadat, A New Intelligent Ap-proach to Patient-Cooperative Control of Rehabilitation Robots,International Journal of Engineering 27 (3)(2013) 467.doi:10.5829/idosi.ije.2014.27.03c.15.[30] L. Harrison, A. Duggins, K. Friston, Encoding uncertainty inthe hippocampus, Neural Networks 19 (5) (2006) 535–546.doi:10.1016/j.neunet.2005.11.002.[31] C. Rizzi Raymundo, C. G. Johnson, P. A. Vargas, Anarchitecture for emotional and context-aware associativelearning for2015 24th IEEEInternational Symposium on Robot and Human Interac-tive Communication (RO-MAN), IEEE, 2015, pp. 31–36.doi:10.1109/ROMAN.2015.7333699.robot companions,in:[32] R. W. Picard, Affective Computing, Tech. Rep. 321, Mas-sachusetts Institute of Technology, Cambridge (1995).[33] R. W. Picard, Affective Computing, MIT Press, Cambridge,2000.[34] C. Breazeal, R. Brooks, Robot emotion: A functional perspec-tive, in: J.-M. Fellous, M. A. Arbib (Eds.), Who needs emo-tions? The Brain Meets the Robot, Affective Science, OxfordUniversity Press, 2005, pp. 271–310.[35] G. Hollinger, Y. Georgiev, A. Manfredi, B. A. Maxwell,Z. Pezzementi, B. Mitchell, et al., Design of a SocialMobile Robot Using Emotion-Based Decision Mechanisms,in: 2006 IEEE/RSJ International Conference on IntelligentRobots and Systems, IEEE, Beijing, 2006, pp. 3093–3098.doi:10.1109/IROS.2006.282327.[36] J. W. Rudy, R. C. O’Reilly, Conjunctive representations, thehippocampus, and contextual fear conditioning, Cognitive,Affective, & Behavioral Neuroscience 1 (1) (2001) 66–82.doi:10.3758/CABN.1.1.66.[37] B. Subagdja, A.-H. Tan, Neural modeling of sequential in-ferences and learning over episodic memory, Neurocomputing161 (C) (2015) 229–242. doi:10.1016/j.neucom.2015.02.038.[38] B. Kiumarsi, F. L. Lewis, D. S. Levine, Optimal control of non-linear discrete time-varying systems using a new neural networkapproximation structure, Neurocomputing 156 (2015) 157–165.doi:10.1016/j.neucom.2014.12.067.[39] J. Timmis, M. Neal, J. Thorniley, An Adaptive Neuro-EndocrineSystem for Robotic Systems, in: IEEE Workshop on Robotic In-telligence in Informationally Structured Space, Nashville, 2009,pp. 129–136. doi:10.1109/RIISS.2009.4937917.[40] M. Neal, J. Timmis, Timidity: A Useful Emotional Mechanismfor Robot Control?, Informatica 27 (2) (2003) 197–204.[41] P. Vargas, R. Moioli, L. N. Castro, J. Timmis, M. Neal, F. J. V.Zuben, Artificial Homeostatic System: A Novel Approach, in:M. S. Capcarr`ere, A. A. Freitas, P. J. Bentley, C. G. Johnson,J. Timmis (Eds.), Advances in Artificial Life, no. 3630 in Lec-ture Notes in Computer Science, Springer Berlin Heidelberg,Berlin, 2005, pp. 754–764. doi:10.1007/11553090 76.[42] R. Valverde Ibanez, M. Keysermann, P. Vargas, EmotionalMemories in Autonomous Robots, in: 2014 RO-MAN: The23rd IEEE International Symposium on Robot and Human In-teractive Communication, IEEE, Edinburgh, 2014, pp. 405–410.doi:10.1109/ROMAN.2014.6926286.[43] R. Ventura, C. Pinto-Ferreira, Responding efficiently toagentarchi-an(2009) 2923–2930.relevanttecture, Neurocomputing 72 (1315)doi:10.1016/j.neucom.2008.09.019.emotion-basedstimuliusing[44] D. Ren, P. Wang, H. Qiao, S. Zheng, A biologically inspiredmodel of emotion eliciting from visual stimuli, Neurocomputing121 (2013) 328–336. doi:10.1016/j.neucom.2013.05.026.[45] L. Ca˜namero, Emotion understanding from the perspective ofautonomous robots research, Neural Networks 18 (4) (2005)22[46] J. Mor´en, Emotion and Learning - A Computational Model ofthe Amygdala, dissertation, Lund University (2002).[47] Z. Beheshti, S. Z. M. Hashim, A Review of Emotional Learningand It’s Utilization in Control Engineering, International Jour-nal of Advances in Soft Computing and Its Applications 2 (2)(2010) 191–208.[48] R. C. O’Reilly, J. W. Rudy, Conjunctive Representations inLearning and Memory: Principles of Cortical and Hippocam-pal Function, Psychological Review 108 (2) (2001) 311–345.doi:10.1037/0033-295X.108.2.311.[49] J. LeDoux, The Emotional Brain, Fear, and the Amygdala, Cel-lular and Molecular Neurobiology 23 (4-5) (2003) 727–738.doi:10.1023/a:1025048802629.[50] I. P. Pavlov, Conditioned Reflexes: An Investigation of the Phys-iological Activity of the Cerebral Cortex, Oxford UniversityPress, 1927.[51] R. Phillips, J. E. LeDoux, Differential Contribution of Amyg-dala and Hippocampus to Cued and Contextual Fear Con-ditioning, Behavioral Neuroscience 106 (2) (1992) 274–285.doi:10.1037/0735-7044.106.2.274.[52] C. Herry, J. P. Johansen, Encoding of fear learning and mem-ory in distributed neuronal circuits, Nature Neuroscience 17 (12)(2014) 1644–1654. doi:10.1038/nn.3869.[53] J. W. Rudy, N. C. Huff, P. Matus-Amat, Understanding contex-tual fear conditioning: insights from a two-process model, Neu-roscience and Biobehavioral Reviews 28 (7) (2004) 675–685.doi:10.1016/j.neubiorev.2004.09.004.[54] N. J. Fortin, K. L. Agster, H. B. Eichenbaum, Critical role of thehippocampus in memory for sequences of events, Nature Neu-roscience 5 (5) (2002) 458. doi:10.1038/nn834.[55] J. W. Rudy, R. M. Barrientos, R. C. O’Reilly, Hippocampal For-mation Supports Conditioning to Memory of a Context, Behav-ioral Neuroscience 116 (4) (2002) 530–538. doi:10.1037/0735-7044.116.4.530.[56] A. Krause-Utz, B. M. Elzinga, N. Y. L. Oei, C. Paret, I. Niedt-feld, P. Spinhoven, M. Bohus, C. Schmahl, Amygdala and dor-sal anterior cingulate connectivity during an emotional work-ing memory task in borderline personality disorder patients withinterpersonal trauma history, Frontiers in Human Neuroscience8 (848). doi:10.3389/fnhum.2014.00848.[57] T. Spellman, M. Rigotti, S. E. Ahmari, S. Fusi, J. A. Gogos,J. A. Gordon, Hippocampal-prefrontal input supports spatial en-coding in working memory, Nature 522 (7556) (2015) 309–314.doi:10.1038/nature14445.[58] A. K. Dey, Understanding and Using Context, Personal Ubiqui-tous Comput. 5 (1) (2001) 4–7. doi:10.1007/s007790170019.[59] M. Bali, Drools JBoss Rules 5.X Developer’s Guide, Packt Pub-lishing, 2013.[60] S. C. Marsella, J. Gratch, P. Petta, Computational Models ofEmotion, in: K. Scherer, T. B¨anziger, E. Roesch (Eds.), ABlueprint for Affective Computing: A Sourcebook and Manual,Affective Science, OUP Oxford, 2010.[61] J. Anderson, The Architecture of Cognition, Cognitive Science,Lawrence Erlbaum Associates, New Jersey, 1996.[62] J. F. Allen, An Interval-Based Representation of TemporalKnowledge, in: Proceedings of the 7th International Joint Con-ference on Artificial Intelligence, IJCAI’81, Morgan KaufmannPublishers Inc., San Francisco, 1981, pp. 221–226.[63] J. F. Allen, Maintaining Knowledge About Temporal Inter-vals, Communications of the ACM 26 (11) (1983) 832–843.doi:10.1145/182.358434.[64] I. Pereira, P. Costa, J. Almeida, A Rule-Based Platform forSituation Management,in: 2013 IEEE International Multi-Disciplinary Conference on Cognitive Methods in SituationFabio Fabris received his bachelor(2010) and masters (2013) degreesin Computer Science from the Fed-eral University of Esp´ırito Santo,Brazil. Before starting his Ph.D.he has worked in research projectsaimed at solving real-world prob-lems using data-mining and opti-mization techniques: finding fraudulent electricity con-sumers, classifying faults in oil-rig motor pumps andoptimizing samples sizes for statistical analysis. He iscurrently pursuing his Ph.D. in Computer Science in theUniversity of Kent, United Kingdom. His main interestis the application of data-mining and optimization al-gorithms to solve real-world problems, in particular theclassification of ageing-related proteins.Patricia A. Vargas received herPhD. on Computer Engineeringfrom the University of Campinas,SheUnicamp (Brazil) in 2005.is the Founder Director oftheRobotics Laboratory and AssociateProfessor/Reader in Computer Sci-ence and Robotics at the School ofMathematical and Computer Sci-ence at HeriotWatt University (Edinburgh, UK). Sheis an executive member of the Edinburgh Centre forRobotics. She worked at the Centre for Computa-tional Neuroscience and Robotics, University of Sussex(England, UK) for 3 years. Her research interests in-clude Evolutionary and Bio-inspired Robotics, Compu-tational Neuroscience, Data Mining, Machine Learning,Biologically-inspired algorithms, Human-Robot Inter-action and Rehabilitation Robotics.Awareness and Decision Support (CogSIMA), 2013, pp. 83–90.doi:10.1109/CogSIMA.2013.6523827.[65] C. Rizzi Raymundo, P. Dockhorn Costa, J. Almeida, I. Pereira,An Infrastructure for Distributed Rule-Based Situation Man-agement,Inter-DisciplinaryConference on Cognitive Methods in Situation Awarenessand Decision Support(CogSIMA), 2014, pp. 202–208.doi:10.1109/CogSIMA.2014.6816563.2014 IEEE Internationalin:[66] MATLAB, version 8.4.0.150421 (R2014b), The MathWorksInc., Natick, Massachusetts, 2014.[67] L. Breiman, J. Friedman, R. Olshen, C. Stone, Classification andRegression Trees, Wadsworth International Group, Belmont,California, U.S.A., 1984.[68] T.-S. Lim, W.-Y. Loh, Y.-S. Shih, A comparison of predictionaccuracy, complexity, and training time of thirty-three old andnew classification algorithms, Machine Learning 40 (3) (2000)203–228. doi:10.1023/A:1007608224229.[69] A. Weiss, C. Bartneck, Meta Analysis Of The Usage OfThe Godspeed Questionnaire Series,in: 2015 24th IEEEInternational Symposium on Robot and Human Interac-tive Communication (RO-MAN), IEEE, 2015, pp. 381–388.doi:10.1109/ROMAN.2015.7333568.[70] S. Koziel, X. Yang, Computational Optimization, Methodsand Algorithms, Vol. 356, Springer Berlin Heidelberg, 2011.doi:10.1007/978-3-642-20859-1.[71] P. A. Vargas, E. A. Di Paolo, I. Harvey, P. Husbands, The Hori-zons of Evolutionary Robotics, MIT Press, 2014.receivedCaroline RizziherBachelorand Masters degreesin Computer Science from theFederal University of Esp´ıritoSanto (Brazil) in 2010 and 2013,respectively. During her masters,she worked with the modellingof distributed situation-aware sys-tems. She is currently pursuing herPh.D. in Computer Science in the University of Kent(England, UK). Her research interests include compu-tational neuroscience, machine learning, autonomousaffective computing and situation-awarerobotics,systems.Colin G. Johnson received hisPhD from the University of Kent(England, UK) in 2003. He is aReader in the School of Comput-ing and Associate Dean of the Fac-ulty of Sciences at the Universityof Kent. His research interests in-clude program synthesis, machinelearning and meta-heuristics, and their application to awide variety of areas including robotics, medicine, en-gineering and digital humanities.23