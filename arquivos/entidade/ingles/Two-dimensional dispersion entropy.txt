Two-dimensional dispersion entropy: aninformation-theoretic method for irregularity analysis ofimagesHamed Azami, L.E.V. da Silva, A.C.M. Omoto, Anne Humeau-HeurtierTo cite this version:Hamed Azami, L.E.V. da Silva, A.C.M. Omoto, Anne Humeau-Heurtier. Two-dimensional dispersionentropy: an information-theoretic method for irregularity analysis of images. Signal Processing: ImageCommunication, 2019, 75, pp.178-187. ￿hal-02171545￿HAL Id: hal-02171545https://hal.science/hal-02171545Submitted on 22 Oct 2021HAL is a multi-disciplinary open accessarchive for the deposit and dissemination of sci-entific research documents, whether they are pub-lished or not. The documents may come fromteaching and research institutions in France orabroad, or from public or private research centers.L’archive ouverte pluridisciplinaire HAL, estdestinée au dépôt et à la diffusion de documentsscientifiques de niveau recherche, publiés ou non,émanant des établissements d’enseignement et derecherche français ou étrangers, des laboratoirespublics ou privés.Distributed under a Creative Commons Attribution - NonCommercial| 4.0 InternationalLicenseVersion of Record: https://www.sciencedirect.com/science/article/pii/S0923596519300682Manuscript_9327dab9f663c5fdaaf251847648ffc1Two-dimensional dispersion entropy:an information-theoretic methodfor irregularity analysis of imagesHamed Azamia, Luiz Eduardo Virgilio da Silvab, Ana Carolina MiekoOmotob, Anne Humeau-Heurtierc,∗aDepartment of Neurology and Massachusetts General Hospital, Harvard University,Boston, USAbDepartment of Physiology, School of Medicine of Ribeirao Preto, University of SaoPaulo, Ribeirao Preto, SP, BrazilcUniv Angers, LARIS - Laboratoire Angevin de Recherche en Ing´enierie des Syst`emes,62 avenue Notre-Dame du Lac, 49000 Angers, FranceAbstractTwo-dimensional sample entropy (SampEn2D) is a recently developed methodin the field of information theory for evaluating the regularity or predictabil-ity of images. SampEn2D, though powerful, has two key limitations: 1)SampEn2D values are undefined for small-sized images; and 2) SampEn2Dis computationally expensive for several real-world applications. To over-come these drawbacks, we introduce the two-dimensional dispersion en-tropy (DispEn2D) measure. To evaluate the ability of DispEn2D, in com-parison with SampEn2D, we use various synthetic and real datasets. Theresults demonstrate that DispEn2D distinguishes different amounts of whiteGaussian and salt and pepper noise. The periodic images, compared withtheir corresponding synthesized ones, have lower DispEn2D values. The re-sults for Kylberg texture dataset show the ability of DispEn2D to differentiatevarious textures. Although the results based on DispEn2D and SampEn2Dfor both the synthetic and real datasets are consistent in that they lead tosimilar findings about the irregularity of images, DispEn2D has three mainadvantages over SampEn2D: 1) DispEn2D, unlike SampEn2D, does not leadto undefined values; 2) DispEn2D is noticeably quicker; and 3) The coeffi-∗Corresponding author:Email address: anne.humeau@univ-angers.fr (Anne Humeau-Heurtier)Preprint submitted to Signal Processing: Image CommunicationApril 12, 2019© 2019 published by Elsevier. This manuscript is made available under the CC BY NC user licensehttps://creativecommons.org/licenses/by-nc/4.0/cient of variations and Mann-Whitney U test-based p-values for DispEn2Dare considerably smaller, showing the more stability of the DispEn2D results.Overall, thanks to its successful performance and low computational time,DispEn2D opens up a new way to analyze the uncertainty of images.Keywords:Biomedical image processing, texture analysis, irregularity, two-dimensionaldispersion entropy, two-dimensional sample entropy1. IntroductionIn the field of signal and image processing, information theory providestools for information representation and manipulation [1, 2]. Entropy, asa prominent concept in information theory, is a measure of the uncertaintyor irregularity of a system or data [2, 3]. Following the concept of entropyintroduced by Shannon, several methods, such as one-dimensional approx-imate entropy (ApEn1D) [4], sample entropy (SampEn1D) [3], permutationentropy (PerEn1D) [5], distribution entropy (DistrEn1D) [6], and dispersionentropy (DispEn1D) [7] have been introduced.ApEn1D was proposed in 1991 to estimate the irregularity of time se-ries [4]. ApEn1D is based on the negative average natural logarithm of theconditional probability that two sequences that are similar for m points re-main similar, within a tolerance r, at the next point. SampEn1D overcomesthe problem of counting self-similar patterns in ApEn1D, leading to more re-liable estimations [3]. SampEn1D has been widely employed in many biomed-ical signal processing applications [8, 9, 10, 11].Nevertheless, SampEn1D is not fast enough for long time series and itsvalues may be undefined for short signals [7]. PerEn1D is on the basis ofpermutations defined by the order relations among values of a signal [5].PerEn1D has been broadly used in many signal processing analyses and cog-nitive neuroscience studies to detect different dynamics of various signals [12].PerEn1D is computationally fast (computation cost of O(N )) [26]. Neverthe-less, it has three key deficiencies: i) when a time series is symbolized based onits permutation patterns, only the order of the amplitude values is consideredand some information about the amplitude values is ignored [12, 13], ii) theeffect of equal amplitude values in each embedding vector was not addressedin PerEn [12, 13]; and iii) the most important shortcoming of PerEn is itshigh sensitivity to noise. This occurs because a small change in amplitude2value may vary the order relations among amplitudes [13], even when thesignal-to-noise ratio (SNR) of a signal is high (for more information, pleasesee Figure 9 in [13]).To overcome the shortcomings of PerEn1D and SampEn1D, DispEn1D hasbeen very recently introduced as a fast and powerful technique to quantifythe irregularity of signals [7]. The dependency of DispEn1D on a number ofstraightforward signal processing concepts via a set of synthetic time seriesand three real publicly-available datasets was previously evaluated. The re-sults showed that the DispEn1D technique noticeably outperforms PerEn1D interms of detection of dynamics of signals [7]. Also, the results demonstratedthat DispEn1D is sensitive to changes in frequency, simultaneous amplitudeand frequency, noise power, and noise bandwidth. Moreover, the computa-tional time for DispEn1D is considerably lower than that for SampEn1D [7].It was also found that DispEn1D, compared with PerEn1D and SampEn1D, isthe most consistent technique to discriminate young from elderly children’sstride-to-stride recordings, and the salt-sensitive from salt protected rats’blood pressure data [13].Some of the above-mentioned entropy measures for the analysis of signalshave recently been extended to their corresponding bi-dimensional cases toprocess images. Thus, multi-dimensional ApEn was introduced and appliedto the biomedical field [18, 19, 20]. Two-dimensional SampEn (SampEn2D),as an extension of SampEn1D, has been recently proposed to take into ac-count the predictability of patterns within images [21, 22].It has beendemonstrated that SampEn2D, as a powerful tool for the feature extractionof images, follows SampEn1D for different straight-forward concepts in signaland image processing such as noise, nonlinearity, and randomness, and canbe considered as an irregularity measure of images [22]. Another advantageof SampEn2D is its invariance to rotation and translation [22]. Moreover,two-dimensional PerEn (PerEn2D) was also proposed as an extension of itsone-dimensional entropy counterpart [23, 24, 25]. Thus, a generalization ofthe complexity-entropy causality plane to 2D maps was developed. PerEn2Dwas able to detect different kinds of two-dimensional patterns [23].To take advantages of the performance of DispEn1D over SampEn1D andPerEn1D [7], we introduce here two-dimensional DispEn (DispEn2D), as anIn this paper, we evaluate DispEn2D on syntheticextension of DispEn1D.images and Brodatz and Kylberg publicly-available texture datasets, aswell as on a real dataset of histological cardiac images. We show thati) DispEn2D, unlikethe main advantages of the proposed DispEn2D are:3SampEn2D, does not result in undefined values for small images; ii) DispEn2Dis noticeably faster than SampEn2D; and iii) DispEn2D leads to more stableresults than SampEn2D.We have very recently introduced the bi-dimensional version of thedistribution entropy (DistrEn2D) [27]. In spite of its interesting results, wewill not compare DispEn2D with DistrEn2D because DistrEn2D is interestingmainly for small-sized textures [27], whereas DispEn2D can take into accountboth small and large images. Furthermore, randomly shuffling an image doesnot change considerably the value of DistrEn2D. However, the correlationsamong the image pixels are destroyed in shuffles, and the irregularity of theimage surrogates should be higher than that of the original image (except2-D random images). Moreover, due to the drawbacks of PerEn1D mentionedabove, we do not compare DispEn2D with PerEn2D. DispEn2D is also notcompared to the bi-dimensional version of multiscale SampEn2D [28] as thelatter relies on a multiscale approach and is therefore a measure of imagecomplexity, whereas DispEn2D is a single-scale approach.The remaining of the paper is organized as follows. Section 2 detailsDispEn1D and SampEn2D. The datasets used to evaluate DispEn2D are de-scribed in Section 3. In Section 4, the results for DispEn2D, in comparisonof SampEn2D, are shown and discussed. We finally end with a conclusion.2. Two-dimensional Dispersion Entropy and Sample Entropy Mea-sures2.1. The Proposed Algorithm: Two-dimensional Dispersion EntropyDispEn2D is an extension of DispEn1D for two-dimensional data. Assumei=1,2,... ,h , defined on a domain R2.we have an image of size h × w: U = {ui,j}j=1,2,... ,wDispEn2D of U is defined as follows:1) First, ui,j are mapped to c classes with integer indices from 1 to c.To this aim, there are a number of linear and nonlinear mapping approachesused in the DispEn-based methods [13]. Some linear and nonlinear algorithmscan be used to map the original image to the classified image. The simplestand fastest algorithm is the linear mapping. However, when maximum orminimum values are noticeably larger or smaller than the mean/median valueof the signal, the majority of values are mapped to only a few classes [13]. Onthe other hand, a large number of natural processes show a progression from4small beginnings that accelerates and approaches a climax over time (e.g.,a sigmoid function) [14, 15]. When there is not a detailed description, asigmoid function is frequently used [16, 15, 17]. Thus, we take the normalcumulative distribution function (NCDF) of pixels to map the image into theclasses, as this function naturally raises in a sigmoidal shape. NCDF mapsU into Y = {yi,j}j=1,2,... ,wi=1,2,... ,h from 0 to 1 as followsyi,j =1√2πσxi,j(cid:90)−∞−(t−µ)22σ2 dt,e(1)where µ and σ are the average and standard deviation of U, respectively.Next, we use a linear algorithm to assign each yi,j to an integer from 1 toi,j = round(c × yi,j + 0.5), where zcc. To this end, for each xi,j, we use zci,jshows the (i, j)th pixel of the classified image and rounding involves eitherincreasing or decreasing a number to the next digit.2) zm,caccording tok,l are made with the embedding dimension vector m = [mh, mw]k,l+1, ..., zck,l, zck+1,l+1, ..., zczm,ck,l = {zck+1,l, zczck+(mh−1),l+1, ..., zck,l+(mw−1),k+1,l+(mw−1), ...,k+(mh−1),l+(mw−1)},k+(mh−1),l, zczc(2)is mapped to a dispersion pattern πv0v1...vmh×mw −1, where zcwhere k = 1, 2, . . . , w − (mw − 1) and l = 1, 2, . . . , h − (mh − 1). Eachmatrix zm,ck,l = v0,k,lk,l+1 = v1,. . . , zczck+(mh−1),l+(mw−1) = vmh×mw−1. The number of possibledispersion patterns that can be assigned to each matrix zm,cis equal tok,lcmh×mw, since the matrix z has mh × mw members and each member can beone of the integers from 1 to c [7].3) For each cmh×mw potential dispersion patterns πv0...vmh×mw −1, relativefrequency is obtained as follows#{k, l(cid:12)(cid:12)(cid:12)(cid:12)k ≤ h − (mh − 1)l ≤ w − (mw − 1)p(πv0...vmh×mw −1) =, zm,ck,l has type πv0...vmh.mw −1 }(3).(h − (mh − 1))(w − (mw − 1))In fact, p(πv0...vmh.mw −1) shows the number of dispersion patterns ofk,l , divided by the total number of em-πv0...vmh.mw −1 that is assigned to zm,cbedded vectors with embedding dimension m.54) Finally, based on Shannon’s definition of entropy, DispEn2D is com-puted as followsDispEn2D(U, m, c) =cmw ×mh(cid:88)−π=1p(πv0...vmw ×mh−1) × ln(cid:16)(cid:17)p(πv0...vmw ×mh−1).(4)When all possible two-dimensional dispersion patterns of an image haveequal probability value, the highest value of DispEn2D is reached, which hasa value of ln(cmh×mw). However, if there is only one p(πv0...vmh×mw −1) differentfrom zero, showing a completely regular and certain image, the smallest valueof DispEn2D is obtained.As for DispEn1D [7], the number of classes for DispEn2D can be chosenfrom 3 to 9. The number of classes (c) in DispEn algorithms is inverselyrelated to the threshold value r used in the SampEn approaches [13]. Thus,when the signal-to-noise ratio (SNR) is high, it is recommended to choose alarge value of c, while a small c is more appropriate for signals with low SNR.Nevertheless, for convenience, we can set c = 5 for all images according to [7].To work with reliable statistics to calculate DispEn2D, it is recommendedthat the number of potential patterns (cmh×mw) is smaller than the numberof patterns of an image ((h − (mh − 1)) × (w − (mw − 1))).2.2. Two-dimensional Sample EntropyAssume an image of size h × w: U = {ui,j}j=1,2,... ,wi=1,2,... ,h , defined on a domainR2. To compute SampEn2D, first all two-dimensional matrices Xmk,l (k =1, 2, ..., h − (mh − 1) and l = 1, 2, ..., w − (mw − 1)) with size mh × mw, namedtemplate matrices, are created asuk,luk+1,l...Xmk,l =uk,l+1uk+1,l+1...uk+(mh−1),l uk+(mh−1),l+1. . .uk,l+(mw−1)uk+1,l+(mw−1).... . ..... . . uk+(mh−1),l+(mw−1),(5)where m = [mh, mw] is the embedding dimension vector [22].Then, the number of element pairs in template matrices of size mh × mwhaving d[Xmk,l, Xma,b] ≤ r is computed as6φmk,l(r) =[# of Xma,b | d[ Xm(h − mh)(w − mw) − 1k,l, Xma,b] ≤ r],(6)where a and b respectively change from 1 to h − mh and w − mw ((a, b) (cid:54)=(k, l)), d[Xma,b] denotes the greatest element of the absolute differencesbetween Xma,b, and r is the predefined threshold (tolerance factor)[22].Next, φm(r) is calculated ask,l, Xmk,l and Xmφm(r) =1(h − mh)(w − mw)k=h−mh(cid:88)l=w−mw(cid:88)k=1l=1φmk,l(r).(7)Then, φm+1(r) is computed in the same way, increasing m to m + 1 wherem + 1 = [mh + 1, mw + 1] and φm+1k,l(r) is as followsφm+1k,l(r) =[# of Xm+1a,b| d[ Xm+1, Xm+1a,b(h − mh)(w − mw) − 1k,l] ≤ r].Finally, SampEn2D is defined as follows [22]SampEn2D(U, m, r) = − lnφm+1(r)φm(r).(8)(9)The parameter m indicates the size of the matrices which are analyzed orcompared along images. In previous studies [22, 21], m was chosen to obtainsquared template matrices, i.e. mh = mw.The parameter r is chosen to balance the quality of the logarithmic likeli-hood estimates with the loss of signals’ or images’ information. When r istoo small (smaller than 0.1 of the standard deviation of an image), poor con-ditional probability estimates are achieved. Furthermore, to avoid the effectof noise on data, larger r is recommended. In contrast, for r values largerthan 0.4 of the standard deviation, too much detailed data information islost. Therefore, a trade-off between large and small r values is needed. Fora deeper discussion on the effect of those parameters in SampEn2D, pleaserefer to [22].7Figure 1: Example of a reference image, sized 256 × 256 pixels, on which different levelsof WGN2D and SPN2D were added.3. Synthetic and Real Image DatasetsIn this section, the synthetic and real images used to evaluate the perfor-mance of DispEn2D are described.3.1. Synthetic Datasets3.1.1. Texture Image with Additive NoiseTo evaluate the dependency of DispEn2D on two-dimensional white Gaus-sian noise (WGN2D) and salt and pepper noise (SPN2D; sparsely occurringwhite and black pixels), we employed Lenna as a standard widely-used im-age, sized 256 × 256 pixels, shown in Figure 1. After normalizing the imagein the range 0 to 1, we added different levels of uniform WGN2D with mean(variance) equals to 0.01 (0.01), 0.05 (0.05), and 0.09 (0.09). We also addedSPN2D with different noise density values of 0.01, 0.05, and 0.09 to the ref-erence normalized image.3.1.2. Artificial Periodic and Synthesized TexturesTo show how DispEn2D changes when a periodic texture image turns intoits synthesized one, we used four pairs of periodic and their correspondingsynthesized textures from [29]. The original and their synthesized textures,sized 256 × 256 pixels, are depicted in Figure 2(a) to (d), and Figure 2(e) to(h), in that order. The synthesis algorithm, which is based on Markov ran-dom field texture models, generated textures through a deterministic searchprocess [30]. Note that each local region of the synthesized texture based onthis algorithm is similar to another region from the input (original periodic)texture.8Figure 2: Texture synthesis examples: (a), (b), (c), and (d) periodic textures and (e),(f), (g), and (h) their corresponding synthesized textures [29]. All images have a size of256×256 pixels.3.1.3. Two-dimensional MIX Process (MIX2D)We also compare the performance of DispEn2D and SampEn2D using theMIX processes. For the one-dimensional case, MIX(p) is a family of processesthat interleave samples of a sine wave and sample of independent identicallydistributed (i.i.d.) uniform random variables. The variable p can vary from0 to 1 and intuitively the process becomes more irregular as p increases [32].MIX(p) is defined as [32]MIX(p)j = (1 − zj)xj + zjyj,(10)√2 × sin( 2πj3,12 ) for all j, and yj = i.i.d. uniform random variableswhere xj =√√3]. zj is a binary variable where zj = 1 with probability p andon [−zj = 0 with probability 1−p. The appellation MIX indicates that the processis a mixture of deterministic and stochastic components. For the 2D case, weuse the MIX2D(p) process [22]. The latter is based on the one-dimensionaldefinition [22](11)MIX2D(p)i,j = (1 − zi,j)xi,j + zi,jyi,j,12 ) + sin( 2πjwhere xi,j = sin( 2πi12 ) is a sinusoidal image, and Y = {yi,j} is3]. zi,j = 1an image containing uniform white noise in the range [−with probability p and zi,j = 0 with probability 1 − p. Depending on thep value, the resulting image presents a specific degree of spatial regularity:when p = 1, MIX2D(p) is a purely random function (highly irregular image);when p = 0, we obtain a bi-dimensional sine function (a perfectly regularperiodic image), as it is the case for the one-dimensional case; see examplesof such images in Figure 3. In our work, various realizations of MIX2D images√√3,9(a)(b)(c)(d)(e)(f)(g)(h)Figure 3: Examples of MIX2D images for different p values.Figure 4: One sample of each of the ten selected groups from Kylberg textures [31]. Allimages have a size of 576×576 pixels.of size 256 × 256 pixels were generated and analyzed (one MIX2D per set ofparameter values).3.2. Real Datasets3.2.1. Kylberg Texture DatasetWe also used a subset of the Kylberg texture dataset. We selected 10 groupsof images, each one includes 1000 samples, representing fabrics and surfacesof rotated images, namely floor1, floor2, scarf1, scarf2, rug1, rice1, screen1,ceiling1, blanket1, and canvas1 [31]. One sample, sized 576 × 576 pixels,of each of them is depicted in Figure 4. The dataset is publicly availableat http://www.cb.uu.se/~gustaf/texture. For more information, pleaserefer to [31].10blanket1canvas1ceiling1floor1floor2rice1rug1scarf1scarf2screen1Figure 5: The Brodatz image dataset used. Each image is 128 × 128 pixels.3.2.2. Brodatz Image DatasetThe DispEn2D method was also compared with SampEn2D on the Brodatzgrayscale texture album [33]. This dataset is composed of 112 grayscaleimages representing a large variety of natural textures. This album is nowwidely used in the literature (see, e.g., [34, 35, 36]). From this album weextracted 9 groups of images, as already performed in another study dealingwith SampEn2D [22]. From each group, we used one arbitrary sample imagesized 128 × 128 pixels, as shown in Figure 5.3.2.3. Cardiac Histological Images from RatsWe also evaluated DispEn2D and SampEn2D in a biomedical application.Thus, cardiac histological images from rats were processed. The acquisitionprocedure is described below.Myocardial Infarction in Rats:. Fourteen male Wistar rats (280-300 g) weresubmitted to myocardial infarction (MI group; 8 rats) or sham surgery pro-cedures (SHAM group; 6 rats). Myocardial infarction was produced by amethod similar to the one described in [37]. Briefly, the rats were anes-thetized with ketamine (50 mg/kg, intraperitoneal) and xilazine (10 mg/kg,11intraperitoneal), endotracheally intubated and mechanically ventilated withroom air. A left thoracotomy was performed at the fifth intercostal spaceand the left anterior descending coronary artery was ligated between the pul-monary artery outflow tract and the left atrium with a polyester suture. Thethorax was immediately closed after coronary ligation. Control (SHAM) ratswere submitted to the same operative procedures as MI rats with exceptionof the coronary artery ligation. Experimental protocol was reviewed andapproved by the Committee of Ethics in Animal Research of the School ofMedicine of Ribeirao Preto, University of Sao Paulo, SP, Brazil (Protocol#165/2016).Morphological Analysis:. After four weeks of MI or SHAM surgeries, ratswere euthanized with an overdose of anesthetic (tribomoethanol, 250 mg/kg,intraperitoneal). The hearts were withdrawn from the thoracic cavity, cuttransversely, fixed in phosphate-buffered 10% formalin and submitted toparaffin inclusion for histological study. Sections of 7 µm thick were cut andstained with Masson’s trichrome stain to identify and quantify interstitialcollagen fibers which plays an important role in the structural organizationof the heart. Stained cross-sections were captured using light microscopy(Leica DM5500B; Leica Microsystem, Wetzlar, Germany) at ×40 magnifica-tion. For each heart, one image from the septum of the left ventricle wasselected for posterior analysis.During images acquisition, it was observed that histological tissue process-ing was deficient, which resulted in poor quality images. This fact makesthis dataset particularly interesting to the present study, creating a scenariowhere it is possible to evaluate the performance of the two-dimensional en-tropy measures (DispEn2D and SampEn2D) for the classification of low qual-ity images obtained from different sources, i.e. pathological (MI) and nonpathological (SHAM) groups.All the histological images were originally sized 2048 × 1536 pixels andRGB-colored. To reduce the computational time, the entire dataset wasdownsampled to 1024 × 768 pixels with a linear interpolation and convertedto a 8-bit grayscale representation prior to the analyzes. Figure 6 shows onerepresentative image from each group (SHAM and MI).Comparisons of entropy values between groups in the cardiac histologicalimage dataset were performed with Mann-Whitney rank sum test due to thesmall sample size. Significance was set at P < 0.05.12Figure 6: Representative examples of cardiac histological image dataset used in this study,obtained from SHAM (upper image) and myocardial infarction (lower image) groups. Allimages have a size of 1024×768 pixels.4. Results and DiscussionIn this Section, we assess the ability of DispEn2D to characterize differentkinds of synthetic and real datasets described in Section 3. Note that forsimplicity, we set m = [2, 2] and c = 5 for DispEn2D in all simulations below,even though the ranges 3 ≤ c ≤ 8 and [1, 1] ≤ [m, m] ≤ [5, 5] lead to similarfindings (data not shown).4.1. Synthetic Datasets4.1.1. Texture Image with Additive NoiseThe two-dimensional entropy values obtained from the Lenna image withdifferent amounts of WGN2D and SPN2D are shown in Table 1. They revealthat the addition of WGN2D of larger mean and variance leads to higherentropy values for both the DispEn2D and SampEn2D methods. There isan overlap between the SampEn2D values with mean and variance 0.05 and13Table 1: Mean value and standard deviation (40 realizations) of DispEn2D and SampEn2Dcomputed from the reference image (Lenna, Figure 1) on which different levels of bi-dimensional white Gaussian noise (WGN2D) and salt and pepper noise (SPN2D) wereadded. We used m = [2, 2] for and c = 5 for DispEn2D. The parameters were set tom = [2, 2] for both the methods, c = 5 for DispEn2D and r = 0.24 of image standarddeviation for SampEn2D.Type of noiseWGN2DWGN2DWGN2DSPN2DSPN2DSPN2DLevel addedmean and variance 0.01mean and variance 0.05mean and variance 0.09density 0.01density 0.05density 0.09DispEn2D5.0555±0.00745.9766±0.00756.1006±0.00493.2805±0.00453.6846±0.01004.0077±0.0107SampEn2D6.5653±0.02048.1864±0.05678.2703±0.10200.7715±0.00571.1095±0.01461.4911±0.0229those for mean and variance 0.09. However, there is no overlap between anytwo groups for DispEn2D, demonstrating its advantage over SampEn2D.Likewise, adding SPN2D with larger noise density results in higher entropyvalues. Both evidence that DispEn2D can detect different levels of WGN2Dand SPN2D, where the greater the amount of noise, the higher the DispEn2Dvalue. For SPN with density d, the noise is applied to d multiplied by thenumber of pixels of an image. However, for the WGN case, the noise is addedto almost every pixel of an image. Thus, the DispEn2D and SampEn2D valuesfor WGN, compared with their counterparts for SPN, are larger. It is worthnoting that the results for various images lead to similar findings as well (forbriefness reasons, we do not show them here).4.1.2. Artificial Periodic and Synthesized TexturesTable 2 shows that the DispEn2D, like SampEn2D, of a periodic textureimage is lower than that of its corresponding synthesized one. This fact sug-gests that DispEn2D and SampEn2D can be considered as metrics to quantifythe regularity or predictability of images.4.1.3. Two-dimensional MIX Process (MIX2D)Figure 7 shows the entropy of MIX2D process using DispEn2D (c = 5) andSampEn2D (r = 0.24) for m = {[1, 1], [2, 2], [3, 3]}. The parameters used forSampEn2D were chosen according to [22]. The MIX2D process goes from theabsolutely regular (p = 0) to the completely random (p = 1) and one expects14Table 2: DispEn2D and SampEn2D of (a), (b), (c), and (d) periodic textures and their(e), (f), (g), and (h) synthesized corresponding textures; see Figure 2. The parameterswere set to m = [2, 2] for both the methods, c = 5 for DispEn2D and r = 0.24 of imagestandard deviation for SampEn2D.Texture (a) Texture (b) Texture (c) Texture (d)DispEn2D1.0181.1102.4454.124Texture (e) Texture (f) Texture (g) Texture (h)DispEn2D1.0881.2032.6644.305Texture (a) Texture (b) Texture (c) Texture (d)SampEn2D0.08850.18180.16470.1187Texture (e) Texture (f) Texture (g) Texture (h)SampEn2D0.10250.18270.31230.1310entropy to increase for increasing p. This is the case for both evaluated mea-surements, except for DispEn2D with m = [1, 1]. Since dispersion patternsshould have at least two elements, the embedding dimension for DispEn2Dhas to be set at least to [2, 2]. For this reason, the DispEn2D values form = [1, 1] are almost constant. According to Gonzalez [38], “a pattern isessentially an arrangement and it is characterized by the order of the ele-ments of which it is made”. Thus, it is highly recommended to have at leasttwo elements in a pattern, as suggested to set m > 1 for DispEn1D [7, 13].The reason behind the constant value is that ln(cmh×mw) = ln(5) = 1.6094is the maximum DispEn2D value for m = [1, 1]. In addition, SampEn2D form = [3, 3] and p = 0.5 shows instability. The curve for SampEn2D withm = [3, 3] is not a monotonic increase for p > 0.5 and there is a missingvalue at p = 0.95. This is explained by the fact that patterns become harderto find in SampEn2D as m increases [22]. Therefore, SampEn2D becomespoorly estimated for increasing m, especially for small images.4.2. Real Datasets4.2.1. Kylberg Texture DatasetTo assess the ability of DispEn2D to be used as a feature extraction methodfor images or textures, we used the popular publicly-available Kylberg Tex-ture Dataset. The DispEn2D values for the selected Kylberg texture groupsare demonstrated in Table 3. The results illustrate that there are no overlapsbetween entropy values of the ten selected groups, showing that DispEn2Dmay be a useful metric to distinguish different patterns of fabrics and sur-15Figure 7: DispEn2D (left panel) and SampEn2D (right panel) calculated from MIX2Dprocesses of size 256 × 256 pixels. The parameters were set to m = {[1, 1], [2, 2], [3, 3]}for both the methods, c = 5 for DispEn2D and r = 0.24 of image standard deviation forSampEn2D.faces.1600.20.40.60.81024681012pDispEn2D m = [3,3]m = [2,2]m = [1,1]00.20.40.60.81024681012pSampEn2D m = [3,3]m = [2,2]m = [1,1]4931.0±2806.53580.0±9609.42401.0±8116.45331.0±2180.41760.0±9548.38341.0±8655.30590.0±2912.32241.0±3159.28760.0±2715.23821.0±0550.2seulavehT.4erugiFees;noitaiveddradnats±naemsanwohssecafrusderutxetfospuorgtnereffidnetfoD2nEpsiD:3elbaT.noitatupmocehtrofnesohcerew5=cdna]2,2[=m2roofl1savnac1teknalb1gniliec1neercs1ecir1gur1fracs1roofl2fracs17Figure 8: DispEn2D (left panel) and SampEn2D (right panel) calculated from the Brodatzdataset presented in Figure 5. The parameters were set to m = {[1, 1], [2, 2], [3, 3]} for bothmethods, c = 5 for DispEn2D and r = 0.24 of image standard deviation for SampEn2D.For SampEn2D and data 93 at m = [3, 3] the computation leads to infinite value.4.2.2. Brodatz Image Dataseti.e.c = 5 (DispEn2D) and r = 0.24 ofResults for the Brodatz dataset are depicted in Figure 8. The pa-rameters values for both the entropy approaches are equal to those pre-viously used,image stan-dard deviation (SampEn2D).Interestingly, the orders of the entropy val-ues obtained by DispEn2D and SampEn2D of the images are quite sim-ilar. The difference between DispEn2D and SampEn2D was found onlyfor the orders assigned with the three lowest entropy values. More-over, both measurements show relative consistency.Relative consis-if SampEn2D(m1, r1)(S) > SampEn2D(m1, r1)(T ),tency implies that,then SampEn2D(m2, r2)(S) > SampEn2D(m2, r2)(T ).ifDispEn2D(m1, c1)(S) > DispEn2D(m1, c1)(T ), then DispEn2D(m2, c2)(S) >DispEn2D(m2, c2)(T ) [3].Likewise,It is worth pointing out that DispEn2D and SampEn2D are based on dif-ferent concept in entropy. While SampEn2D is a conditional entropy, i.e.estimates the conditional probability that similar m-size patterns will stillbe similar for m + 1, DispEn2D is based on the definition of Shannon’s en-tropy, and takes into account only the matches of patterns of size m. Theinconsistencies found for DispEn2D for m = [1, 1] might be the result of theentropy estimation method, which is based only on the single pixels distri-butions, whereas SampEn2D, even for m = [1, 1], takes into account someinformation on patterns with m = [2, 2].18[1,1][2,2][3,3]0246810mDispEn2D 515303645759395102[1,1][2,2][3,3]0246810mSampEn2D 515303645759395102Figure 9: DispEn2D (top panels) and SampEn2D (bottom panels) calculated from thecardiac histological images from rats. The median value of the entropy for each group ispresented here, as well as the 25th and 75th percentiles. ∗ means P < 0.05. Parameterswere set to m = {[1, 1], [2, 2], [3, 3]} for both methods, c = 5 for DispEn2D and r = 0.24 ofimage standard deviation for SampEn2D.4.2.3. Cardiac Histological Images from RatsThe results obtained by DispEn2D and SampEn2D for the cardiac histolog-ical image dataset are depicted in Figure 9. In general, the pixel patterns ofcardiac fibers from SHAM animals present more irregularity (higher entropy)when compared to MI animals. The SampEn2D of the SHAM animals pre-sented a tendency to higher values compared to the MI, although no statisti-cal significance was found for m = [1, 1], m = [2, 2], or m = [3, 3]. DispEn2Dled to higher values for the SHAM compared to the MI for m = [2, 2] andm = [3, 3]. The lack of difference for m = [1, 1] is not surprising as m = [1, 1]was identified not to be a good choice for DispEn2D. Therefore, we can saythat DispEn2D is a valuable measurement to distinguish the SHAM to MI.Even though the DispEn2D curves of the SHAM and MI are closer comparedto the respective SampEn2D curves, one must be aware that DispEn2D has amuch lower standard deviation (or CV, see Tables 5 and 6). Therefore, thescaling of DispEn2D and SampEn2D are different and must not be directlycompared.The Hedges’ g effect size [40] was also employed to quantify the differences19 SHAMMI 1.541.551.561.571.581.59DispEn2Dm = [1,1] SHAMMI 4.64.74.84.955.1DispEn2Dm = [2,2] SHAMMI 99.510DispEn2Dm = [3,3] SHAMMI 22.533.5SampEn2Dm = [1,1] SHAMMI 2.533.54SampEn2Dm = [2,2] SHAMMI 1.522.533.5SampEn2Dm = [3,3]   P = 0.41 *  P = 0.043 *  P = 0.043   P = 0.081   P = 0.059   P = 0.081Table 4: Differences between the DispEn2D and SampEn2D results for the cardiac histo-logical images from SHAM vs. MI rats based on the Hedges’ g effect size.Method m = [1, 1] m = [2, 2] m = [3, 3]DispEn2D0.66671.18961.3015SampEn2D11.18361.2051between the results for SHAM vs. MI. The Hedges’ g test shows the differencebetween the means of two groups, divided by the weighted average of stan-dard deviations for these two groups. The differences, illustrated in Table 4,show that the highest effect size is obtained by DispEn2D with m = [3, 3],suggesting the advantage of this method over SampEn2D.Results with the cardiac histological dataset give strength to the assump-tion that irregularity may be a valuable source of information to distinguishthe dynamics of images [22]. Even if the present dataset includes low qualityimages, DispEn2D was able to differentiate pathological from non pathologicalconditions. This opens new possibilities for application of two-dimensionalentropy measurements, even for noisy and corrupted images.4.3. Sensitivity of DispEn2D and SampEn2D to Image SizesTo evaluate the sensitivity of DispEn2D and SampEn2D to the size of im-ages, we created 40 different WGN2D and 40 MIX2D(0.5) with sizes vary-ing from 10 × 10 to 200 × 200 pixels. The Parameters c and r were re-spectively 5 and 0.24 of the standard deviation of images and m varied in{[1, 1], [2, 2], [3, 3]}. The mean and standard deviation values of the resultsfor WGN2D and MIX2D(0.5) are shown in Figure 10.k,l, Xm,da,b ] ≤ r.As mentioned before, SampEn2D counts element pairs in template matri-ces having d[Xm, dIn case the size of an image is small, theprobability for this number of being equal to zero is higher, leading to un-defined values. Accordingly, the entropy values for small-sized images usingSampEn2D with m = [2, 2] and all values for SampEn2D with m = [3, 3] areundefined, as can be seen in Figure 10. In contrast, the DispEn2D-based val-ues are always defined, showing an advantage of DispEn2D over SampEn2D.As mentioned previously, to obtain reliable statistics to calculate DispEn2D,the number of patterns in an image, i.e. (h − (mh − 1)) × (w − (mw − 1)), hasto be greater than the number of potential patterns (cmh×mw). In Figure 10,for m = [2, 2] and for image sizes varying from 40 × 40 to 200 × 200 pixels, we20Figure 10: Mean and standard deviation for DispEn2D (c = 5) and SampEn2D (r = 0.24×standard deviation of the image) with embedding dimensions [1,1], [2,2], and [3,3] asfunctions of image size changing from 10 × 10 to 200 × 200 pixels computed from 40different WGN2D and MIX2D(0.5). SampEn2D values for image sizes of 10 × 10 pixels and20 × 20 pixels with m = [2, 2] and all SampEn2D values for m = [3, 3] are undefined.have between 1521 and 39601 patterns in the images, respectively, with 625potential patterns defined in DispEn2D. The statistics obtained can thereforebe considered as reliable. However, for m = [3, 3], we have between 1444 (foran image size of 40 × 40 pixels) and 39204 (for an image size of 200 × 200pixels) patterns in the images, with 1953125 potential patterns in DispEn2D.The number of potential dispersion patterns is therefore much larger than thenumber of patterns extracted from the image. This explains why DispEn2Dvalues for m = [3, 3] shows a different behavior for image sizes larger than40 × 40 pixels. The maximum DispEn2D value is ln(cmh×mw). For c = 5 andm = [2, 2] this gives a maximum entropy value of 6.43 (value nearly observedin Figure 10 for m = [2, 2] and image sizes larger than 40 × 40 pixels). Forc = 5 and m = [3, 3], the maximum entropy value is 14.48. For c = 5 andm = [3, 3], we may need images larger than 1400 × 1400 pixels to reach thismaximum value.To compare the stability of the results obtained by DispEn2D andSampEn2D, we used the coefficient of variation (CV) defined as the standarddeviation divided by the mean. The CV permits comparison of variability es-timates regardless of the magnitude values [39]. The CV values of the resultsfor sizes 50 × 50, 100 × 100, 150 × 150, and 200 × 200 pixels using WGN2Dand MIX2D(0.5) are shown in Tables 5 and 6, respectively. Forty realizations21050100150200Image Size246810DispEn2DTwo-dimensional WGNm=[3,3]m=[2,2]m=[1,1]050100150200Image Size468SampEn2DTwo-dimensional WGN050100150200Image Size246810DispEn2DTwo-dimensional MIX(0.5)m=[3,3]m=[2,2]m=[1,1]050100150200Image Size468SampEn2DTwo-dimensional MIX(0.5)Table 5: Coefficient of variation (CV) values for the DispEn2D and SampEn2D for differentsizes of WGN2D for 40 realizations of each size. r and c were respectively 0.24 of thestandard deviation of images and 5.50×5023e-05140e-05Methods1e-05DispEn2D with m = [1, 1]6e-05DispEn2D with m = [2, 2]6e-05DispEn2D with m = [3, 3] 9.9535e-05280e-05SampEn2D with m = [1, 1]990e-05SampEn2D with m = [2, 2] 3460e-05340e-05SampEn2D with m = [3, 3] undefined undefined undefined undefined100×100 150×150 200×2002e-0512e-056e-05420e-05630e-054e-0532e-056e-055000e-05790e-05Table 6: Coefficient of variation (CV) values for the DispEn2D and SampEn2D for differentsizes of MIX2D(p = 0.5) (40 realizations of each size). r and c were respectively 0.24 ofthe standard deviation of images and 5.MethodsDispEn2D with m = [1, 1]DispEn2D with m = [2, 2]DispEn2D with m = [3, 3]SampEn2D with m = [1, 1]SampEn2D with m = [2, 2]SampEn2D with m = [3, 3] undefined undefined undefined undefined100×100 150×150 200×2000.00260.00430.00170.00910.001450×500.00210.00540.00110.08720.01350.00070.00170.00040.02800.00660.00080.00120.00040.00940.0008of each type of synthetic image were used. DispEn2D (c = 5) and SampEn2D(r = 0.24 of images standard deviation) were calculated for different valuesof m. Generally, for WGN2D, the larger the image size, the smaller the CVvalue for both DispEn2D and SampEn2D. For both WGN2D and MIX2D(0.5),the CV values obtained with DispEn2D are noticeably smaller than thoseobtained with SampEn2D. Moreover, the CVs for SampEn2D with m = [3, 3]are undefined.4.4. Computational TimeFigure 11 shows the computational time (in seconds) to calculate DispEn2Dand SampEn2D in the Brodatz dataset, as a function of c or r, and differ-ent values of m. The time to compute DispEn2D increases exponentiallywith c and is very sensitive to m. In contrast, the computational time ofSampEn2D increases linearly with r and is much less sensitive to m. How-ever, the time required to calculate DispEn2D is markedly lower than the22Figure 11: Computational time for DispEn2D (left panels) and SampEn2D (right panels)calculated using the Brodatz dataset (images sized 128 × 128 pixels), for different valuesof parameters m, c and r.time required to compute SampEn2D. In the conditions of Figure 8, in casem = [3, 3], the computation of DispEn2D (c = 5) takes around 45 s, whereasthat of SampEn2D (r = 0.24) takes from roughly 250 to 500 s (approximately8 times higher computational time). The computational time is an impor-tant limitation of SampEn2D that DispEn2D notably outperforms. Moreover,Figure 11 shows that there is no major difference in the computational timesusing DispEn2D for different images. However, in SampEn2D, because thereis a difference in the number of patterns considered as similar in each image,the computational time depends on the image processed.DispEn2D and SampEn2D have the following advantages as image process-ing tools: 1) they are entropy measurements that take into account thespatial properties of pixels; 2) they are not very sensitive to noise; and 3)they are insensitive to translation and rotation. DispEn2D and SampEn2Dmay be helpful in several applications of image processing field, such as pat-2324681012c00.20.40.60.8Time for DispEn2D (s)m = [1,1]24681012c00.20.40.60.8Time for DispEn2D (s)m = [2,2]1.522.533.544.555.5c010203040Time for DispEn2D (s)m = [3,3]5153036457593951020.10.20.30.40.5r300400500600700Time for SampEn2D (s)m = [1,1]0.10.20.30.40.5r300400500600700Time for SampEn2D (s)m = [2,2]0.10.20.30.40.5r300400500600700Time for SampEn2D (s)m = [3,3]tern recognition, segmentation and event detection, considering that the one-dimensional version of those methods have been successfully applied in suchproblems [41, 42]. DispEn2D is much faster than SampEn2D and will neverreturn an undefined entropy value.We have very recently introduced the bi-dimensional distribution entropy(DistrEn2D) for small-sized images [27].In spite of its interesting results,as can be seen in Table 5 in [27] compared with Figure 11, DispEn2D isconsiderably faster than DistrEn2D. Additionally, as the total number ofelements in distance matrix D is about h2w2, the computation of DistrEn2Dfor large-sized images requires the storage of a huge number of elements. Itis one reason that we stressed the importance of DistrEn2D for only small-sized textures [27], whereas DispEn2D can take into account both small andlarge images. More importantly, according to the DistrEn2D algorithm, newimages created simply by random permutations of an original image haveDistrEn2D values close to the original image. For instance, if the elementsof MIX2D(0.5) are sorted, its DistrEn2D value is not changed considerably.However, as expected theoretically, sorting leads to a lower entropy value.5. ConclusionThe aim of this study was to develop DispEn2D based on Shannon’s def-inition of entropy and the recently introduced dispersion patterns to quan-tify the irregularity or uncertainty of images. We evaluated the DispEn2Dmethod on synthetic and real datasets. The study done here has the follow-ing implications for the estimation of images’ irregularity. First, DispEn2Ddistinguished different amounts of WGN2D and SPN2D and discriminatedthe periodic images from their corresponding synthesized ones. Moreover,DispEn2D was found to be a powerful feature extraction method to detectthe patterns of images from different kinds of Kylberg textures. Further-more, DispEn2D detected different degrees of irregularity of MIX2D. Also,the results from the Brodatz dataset showed the stability of DispEn2D-basedresults. In addition, DispEn2D, unlike SampEn2D, significantly discriminatedthe pathological from non pathological conditions in a dataset composedof low quality images. Finally, DispEn2D has three key advantages overSampEn2D: 1) DispEn2D, unlike SampEn2D, does not result in undefinedvalues; 2) DispEn2D is noticeably faster; and 3) DispEn2D-based values arenoticeably more stable than those obtained by SampEn2D based on the co-efficient of variation test.24Overall, due to its ability to detect different kinds of dynamics of images,DispEn2D has a great potential to analyze various images with low compu-tational time.References[1] R. C. Gonzalez and R. E. Woods, “Image processing”, Digital ImageProcessing, vol. 2, 2007.[2] C. E. Shannon, “A mathematical theory of communication,” ACM SIG-MOBILE Mobile Computing and Communications Review, vol. 5, no. 1,pp. 3–55, 2001.[3] J. S. Richman and J. R. Moorman, “Physiological time-series analysisusing approximate entropy and sample entropy,” American Journal ofPhysiology-Heart and Circulatory Physiology, vol. 278, no. 6, pp. H2039–H2049, 2000.[4] S. M. Pincus, “Approximate entropy as a measure of system complex-ity,” Proceedings of the National Academy of Sciences, vol. 88, no. 6,pp. 2297–2301, 1991.[5] C. Bandt and B. Pompe, “Permutation entropy: a natural complex-ity measure for time series,” Physical Review Letters, vol. 88, no. 17,p. 174102, 2002.[6] P. Li, C. Liu, K. Li, D. Zheng, C. Liu, and Y. Hou, “Assessing the com-plexity of short-term heartbeat interval series by distribution entropy”,Medical and Biological Engineering and Computing, vol. 53, pp. 77–87,2015.[7] M. Rostaghi and H. Azami, “Dispersion entropy: A measure for timeseries analysis”, IEEE Signal Processing Letters, vol. 23, no. 5, pp. 610–614, 2016.[8] M. M. Platisa and V. Gal, “Dependence of heart rate variability on heartperiod in disease and aging”, Physiological Measurement, vol. 27, no. 10,p. 989, 2006.25[9] D. Ab´asolo, R. Hornero, P. Espino, D. Alvarez, and J. Poza, “En-tropy analysis of the EEG background activity in Alzheimer’s diseasepatients”, Physiological Measurement, vol. 27, no. 3, p. 241, 2006.[10] M. O. Sokunbi, “Sample entropy reveals high discriminative power be-tween young and elderly adults in short fMRI data sets”, Information-based Methods for Neuroimaging: Analyzing Structure, Function andDynamics, vol. 8, pp. 1–12, 2015.[11] A. Humeau, F. Chapeau-Blondeau, D. Rousseau, P. Rousseau,W. Trzepizur, and P. Abraham, “Multifractality, sample entropy, andwavelet analyses for age-related changes in the peripheral cardiovascularsystem: Preliminary results”, Medical Physics, vol. 35, no. 2, pp. 717–723, 2008.[12] M. Zanin, L. Zunino, O. A. Rosso, and D. Papo, “Permutation entropyand its main biomedical and econophysics applications: a review”, En-tropy, vol. 14, no. 8, pp. 1553–1577, 2012.[13] H. Azami and J. Escudero, “Amplitude-and fluctuation-based dispersionentropy”, Entropy, vol. 20, no. 3, article id. 210, 2018.[14] S. Tuff´ery, Data mining and statistics for decision making (Vol. 2).Chichester: Wiley, 2011.[15] G. Baranwal and D. P. Vidyarthi, “Admission control in cloud comput-ing using game theory”, The Journal of Supercomputing, vol. 72(1), pp.317-346, 2016.[16] M. N. Gibbs and D. J. MacKay, “Variational Gaussian process classi-fiers”, IEEE Transactions on Neural Networks, vol. 11(6), pp. 1458-1464,2000.[17] W. Duch, “Uncertainty of data, fuzzy membership functions, and multi-layer perceptrons”, IEEE Transactions on Neural Networks, vol. 16(1),pp. 10-23, 2005.[18] T. Marchant, M. Murphy, G. Madden, and C. Moore, “Quantifyingstructure regularity in fluorescence microscopy cell images using a novelmulti-dimensional approximate entropy metric”, in Image Processing26(ICIP), 2011 18th IEEE International Conference on, pp. 3085–3088,IEEE, 2011.[19] C. J. Moore, “A threshold structure metric for medical image inter-rogation: The 2D extension of approximate entropy”, in InformationVisualisation (IV), 2016 20th International Conference, pp. 336–341,2016.[20] C. Moore and T. Marchant, “The approximate entropy concept ex-tended to three dimensions for calibrated, single parameter structuralcomplexity interrogation of volumetric images”, Physics in Medicine andBiology, vol. 62 pp. 6092–6107, 2017.[21] L. E. V. da Silva, A. C. da Silva Senra Filho, V. P. S. Fazan, J. C.Felipe, and L. O. Murta, “Two-dimensional sample entropy analysis ofrat sural nerve aging”, Engineering in Medicine and Biology Society(EMBC), 36th Annual International Conference of the IEEE, pp. 3345–3348, 2014.[22] L. Silva, A. Senra Filho, V. Fazan, J. Felipe, and L. M. Junior, “Two-dimensional sample entropy: assessing image texture through irregular-ity”, Biomedical Physics & Engineering Express, vol. 2, no. 4, p. 045002,2016.[23] H. V. Ribeiro, L. Zunino, E. K. Lenzi, P. A. Santoro, and R. S. Mendes,“Complexity-entropy causality plane as a complexity measure for two-dimensional patterns”, PLoS ONE, vol. 7, no. 8, p. e40689, 2012.[24] L. Zunino and H. V. Ribeiro, “Discriminating image textures with themultiscale two-dimensional complexity-entropy causality plane”, Chaos,Solitons & Fractals, vol. 91, pp. 679-688, 2016.[25] H. Y. Sigaki, M. Perc, and H. V. Ribeiro, “History of art paintingsthrough the lens of entropy and complexity”, Proceedings of the NationalAcademy of Sciences, vol. 115(37), pp. E8585-E8594, 2018.[26] S. D. Wu, C. W. Wu, and A. Humeau-Heurtier, “Refined scale-dependent permutation entropy to analyze systems complexity,” Phys-ica A: Statistical Mechanics and its Applications, vol. 450, pp. 454-461,2016.27[27] H. Azami, J. Escudero, and A. Humeau-Heurtier, “Bidimensional distri-bution entropy to analyze the irregularity of small-sized textures”, IEEESignal Processing Letters, vol. 24, pp. 1338–1342, 2017.[28] L. E. Silva, J. J. Duque, J. C. Felipe, L. O. Murta Jr, A. Humeau-Heurtier, “Two-dimensional multiscale entropy analysis: Applicationsto image texture evaluation”, Signal Processing, vol. 147, pp. 224–232,2018.[29] https://graphics.stanford.edu/projects/texture/demo/synthesis_eero.html.[30] L. Y. Wei and M. Levoy, Fast texture synthesis using tree-structuredvector quantization. In Proceedings of the 27th annual conference onComputer graphics and interactive techniques (pp. 479-488). ACMPress/Addison-Wesley Publishing Co., (2000, July).[31] G. Kylberg, Kylberg Texture Dataset v. 1.0. Centre for Image Analy-sis, Swedish University of Agricultural Sciences and Uppsala University,2011.[32] S. M. Pincus and A. L. Goldberger, “Physiological time-series analy-sis: what does regularity quantify?”, American Journal of Physiology,vol. 266, pp. H1643–H1656, 1994.[33] P. Brodatz, Textures: a photographic album for artist & designers. NewYork, USA: Dover; 1966, 1966.[34] W. L. Lee and K. S. Hsieh, “A robust algorithm for the fractal dimensionof images and its applications to the classification of natural images andultrasonic liver images”, Signal Processing, vol. 90, pp. 1894–1904, 2010.[35] J. B. Florindo and O. M. Bruno, “Fractal descriptors based on Fourierspectrum applied to texture analysis”, Physica A, vol. 391, pp. 4909–4922, 2012.[36] R. Davarzani, S. Mozaffari, and K. Yaghmaie, “Scale- and rotation-invariant texture description with improved local binary pattern fea-tures”, Signal Processing, vol. 111, pp. 274–293, 2015.28[37] M. A. Pfeffer, J. M. Pfeffer, M. C. Fishbein, P. J. Fletcher, J. Spadaro, R.A. Kloner, and E. Braunwald, “Myocardial infarct size and ventricularfunction in rats”, Circulation Research, vol. 44, pp. 503–512, 1979.[38] R. C. Gonzalez, Object Recognition, in Digital image processing, 3rded. Pearson, August 2008, pp. 861-909.[39] G. F. Reed, F. Lynn, and B. D. Meade, “Use of coefficient of variationin assessing variability of quantitative assays,” Clinical and Vaccine Im-munology, vol. 9, no. 6, pp. 1235–1239, 2002.[40] R. Rosenthal, H. Cooper, and L. Hedges, “Parametric measures of effectsize,” The Handbook of Research Synthesis, vol. 621, pp. 231–244, 1994.[41] P. Mic´o, M. Mora, D. Cuesta-Frau, and M. Aboy, “Automatic segmen-tation of long-term ecg signals corrupted with broadband noise basedon sample entropy”, Computer Methods and Programs in Biomedicine,vol. 98, no. 2, pp. 118–129, 2010.[42] H. Azami and J. Escudero, “Amplitude-aware permutation entropy: Il-lustration in spike detection and signal segmentation”, Computer Meth-ods and Programs in Biomedicine, vol. 128, pp. 40–51, 2016.29