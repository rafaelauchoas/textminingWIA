Information Fusion 16 (2014) 3–17Contents lists available at SciVerse ScienceDirectInformation Fusionj o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / i n f f u sA survey of multiple classifier systems as hybrid systemsMichał Woz´ niak a,⇑, Manuel Graña b, Emilio Corchado ca Department of Systems and Computer Networks, Wroclaw University of Technology, Wroclaw, Polandb Computational Intelligence Group, University of the Basque Country, San Sebastian, Spainc Departamento de Informática y Automática, University of Salamanca, Salamanca, Spaina r t i c l ei n f oa b s t r a c tArticle history:Available online 29 April 2013Keywords:Combined classifierMultiple classifier systemClassifier ensembleClassifier fusionHybrid classifierA current focus of intense research in pattern classification is the combination of several classifier sys-tems, which can be built following either the same or different models and/or datasets buildingapproaches. These systems perform information fusion of classification decisions at different levels over-coming limitations of traditional approaches based on single classifiers. This paper presents an up-to-date survey on multiple classifier system (MCS) from the point of view of Hybrid Intelligent Systems.The article discusses major issues, such as diversity and decision fusion methods, providing a vision ofthe spectrum of applications that are currently being developed.(cid:2) 2013 Elsevier B.V. All rights reserved.1. IntroductionHybrid Intelligent Systems offer many alternatives for unortho-dox handling of realistic increasingly complex problems, involvingambiguity, uncertainty and high-dimensionality of data. They al-low to use both a priori knowledge and raw data to compose inno-vative solutions. Therefore, there is growing attention to thismultidisciplinary research field in the computer engineering re-search community. Hybridization appears in many domains of hu-man activity. It has an immediate natural inspiration in the humanbiological systems, such as the Central Nervous System, which is ade facto hybrid composition of many diverse computational units,as discussed since the early days of computer science, e.g., byvon Neumann [1] or Newell [2]. Hybrid approaches seek to exploitthe strengths of the individual components, obtaining enhancedperformance by their combination. The famous ‘‘no free lunch’’ the-orem [3] stated by Wolpert may be extrapolated to the point ofsaying that there is no single computational view that solves allproblems. Fig. 1 is a rough representation of the computational do-mains covered by the Hybrid Intelligent System approach. Some ofthem deal with the uncertainty and ambiguity in the data by prob-abilistic or fuzzy representations and feature extraction. Othersdeal with optimization problems appearing in many facets of the⇑ Corresponding author.E-mail addresses: michal.wozniak@pwr.wroc.pl (M. Woz´ niak), ccpgrrom@g-mail.com (M. Graña), escorchado@usal.es (E. Corchado).1566-2535/$ - see front matter (cid:2) 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.inffus.2013.04.006intelligent system design and problem solving, either following anature inspired or a stochastic process approach. Finally, classifiersimplementing the intelligent decision process are also subject tohybridization by various forms of combination. In this paper, wefocus in this specific domain, which is in an extraordinary efferves-cence nowadays, under the heading of Multi-Classifier Systems(MCS). Referring to classification problems, Wolpert’s theoremhas an specific lecture: there is not a single classifier modeling ap-proach which is optimal for all pattern recognition tasks, sinceeach has its own domain of competence. For a given classificationtask, we expect the MCS to exploit the strengths of the individualclassifier models at our disposal to produce the high quality com-pound recognition system overcoming the performance of individ-ual classifiers. Summarizing:(cid:2) Hybrid Intelligent Systems (HIS) are free combinations of compu-tational intelligence techniques to solve a given problem, cover-ing al computational phases from data normalization up to finaldecision making. Specifically, they mix heterogeneous funda-mental views blending them into one effective working system.(cid:2) Information Fusion covers the ways to combine informationsources in a view providing new properties that may allow tosolve better or more efficiently the proposed problem. Informa-tion sources can be the result of additional computationalprocesses.(cid:2) Multi-Classifier Systems (MCS) focus on the combination ofclassifiers form heterogenous or homogeneous modeling back-grounds to give the final decision. MCS are therefore a subcate-gory of HIS.4M. Woz´niak et al. / Information Fusion 16 (2014) 3–17Fig. 1. Domains of hybrid intelligent systems.on three well known academic search sites. The growth in the num-ber of publications has an exponential trend. The last entry of theHistorical perspective. The concept of MCS was first presented byChow [4], who gave conditions for optimality of the joint decision1of independent binary classifiers with appropriately defined weights.In 1979 Dasarathy and Sheela combined a linear classifier and one k-NN classifier [6], suggesting to identify the region of the featurespace where the classifiers disagree. The k-NN classifier gives the an-swer of the MCS for the objects coming from the conflictive regionand by the linear one for the remaining objects. Such strategy signif-icantly decreases the exploitation cost of whole classifier system.This was the first work introducing a classifier selection concept,however the same idea was developed independently in 1981 byRastrigin and Erenstein [7] performing first a feature space partition-ing and, second, assigning to each partition region an individual clas-sifier that achieves the best classification accuracy over it. Otherearly relevant works formulated conclusions regarding MCS ’s classi-fication quality, such as [8] who considered a neural network ensem-ble, [9] with majority voting applied to handwriting recognition,Turner in 1996 [10] showed that averaging outputs of an infinitenumber of unbiased and independent classifiers can lead to the sameresponse as the optimal Bayes classifier, Ho [11] underlined that adecision combination function must receive useful representationof each classifier’s decision. Specifically, they considered severalmethod based on decision ranks, such as Borda count. Finally, thelandmark works devoted introducing bagging [12] and boosting[13,14] which are able to produce strong classifiers [15], in the (Prob-ably Approximately Correct) theory [16] sense, on the basis of theweak one. Nowadays MCS, are highlighted by review articles as ahot topic and promising trend in pattern recognition [17–21]. Thesereviews include the books by Kuncheva [22], Rokach [23], Seni andEdler [24], and Baruque and Corchado [25]. Even leading-edge gen-eral machine learning handbooks such as [26–28] include extensivepresentations of MCS concepts and architectures. The popularity ofthis approach is confirmed by the growing trend in the number ofpublications shown in Fig. 2. The figure reproduces the evolutionof the number of references retrieved by the application of specifickeywords related to MCS since 1990. The experiment was repeated1 We can retrace decision combination long way back in history. Perhaps the firstworthy reference is the Greek democracy (meaning government of the people) rulingthat full citizens have an equal say in any decision that affects their life. Greeksbelieved in the community wisdom, meaning that the rule of the majority willproduce the optimal joint decision. In 1785 Condorcet formulated the Jury Theoremabout the misclassification probability of a group ofindependent voters [5]],providing the first result measuring the quality of classifier committee.Fig. 2. Evolution of the number of publications per year ranges retrieved from thekeywords specified in the plot legend. Each plot corresponds to searching site: thetop to Google Scholar; the center to the Web of Knowledge, the bottom to Scopus.The first entry of the plots is for publications prior to 1990. The last entry is only forthe last 2 years.M. Woz´niak et al. / Information Fusion 16 (2014) 3–175plots corresponds to the last 2 years, and some of the keywords giveas many references as in the previous 5 years.Advantages. Dietterich [29] summarized the benefits of MCS: (a)allowing to filter out hypothesis that, though accurate, might beincorrect due to a small training set, (b) combining classifierstrained starting from different initial conditions could overcomethe local optima problem, and (c) the true function may be impos-sible to be modeled by any single hypothesis, but combinations ofhypotheses may expand the space of representable functions.Rephrasing it, there is widespread acknowledgment of the follow-ing advantages of MCS:(cid:2) MCS behave well in the two extreme cases of data availability:when we have very scarce data samples for learning, and whenwe have a huge amount of them at our disposal. In the scarcitycase, MCS can exploit bootstrapping methods, such as baggingor boosting. Intuitive reasoning justifies that the worst classifierwould be out of the selection by this method [30], e.g., by indi-vidual classifier output averaging [31]. In the event of availabil-ity of a huge amount of learning data samples, MCS allow totrain classifiers on dataset’s partitions and merge their decisionusing appropriate combination rule [20].(cid:2) Combined classifier can outperform the best individual classi-fier [32]. Under some conditions (e.g., majority voting by agroup of independent classifiers) this improvement has beenproven analytically [10].(cid:2) Many machine learning algorithms are de facto heuristic searchalgorithms. For example the popular decision tree inductionmethod C4.5 [33] uses a greedy search approach, choosing thesearch direction according to an heuristic attribute evaluationfunction. Such an approach does not assure an optimal solution.Thus, the combined algorithm, which could start its work fromdifferent initial points of the search space, is equivalent to amulti-start local random search which increases the probabilityof finding an optimal model.[34]. Another(cid:2) MCS can easily be implemented in efficient computing environ-ments such as parallel and multithreaded computer architec-turesimplementationsolutions is distributed computing systems (i.e.: P2P, Grid orCloud computing) [35,36], especially when a database is parti-tioned for privacy reasons [37] so that partial solutions mustbe computed on each partition and only the final decision isavailable as the combination of the networked decision.attractivearea of(cid:2) Wolpert stated that each classifier has its specific competencedomain [3], where they overcome other competing algorithms,thus it is not possible to design a single classifier which outper-forms another ones for each classification tasks. MCS try toselect always the local optimal model from the available poolof trained classifiers.System structure. The general structure of MCS is depicted inFig. 3 following a classical pattern recognition [38] applicationstructure. The most informative or discriminant features describ-ing the objects are input to the classifier ensemble, formed by aset of complementary and diverse classifiers. An appropriate fusionmethod combines the individual classifier outputs optimally toprovide the system decision. According to Ho [39], two mainMCS design approaches can be distinguished. On one hand, theso-called coverage optimization approach tries to cover the spaceof possible models by the generation of a set of mutually comple-mentary classifiers whose combination provides optimal accuracy.On the other hand, the so-called decision optimization approachconcentrates on designing and training an appropriate decisioncombination function over a set of individual classifier given in ad-vance [40].The main issues in MCS design are:(cid:2) System topology: How to interconnect individual classifiers.(cid:2) Ensemble design: How to drive the generation and selection of apool of valuable classifiers.(cid:2) Fuser design: How to build a decision combination function(fuser) which can exploit the strengths of the selected classifiersand combine them optimally.2. System topologyFig. 4 illustrates the two canonical topologies employed in MCSdesign. The overwhelming majority of MCS reported in the litera-ture is structured in a parallel topology [22]. In this architecture,each classifier is feed the same input data, so that the final decisionof the combined classifier output is made on the basis of the out-puts of the individual classifiers obtained independently. Alterna-tively, in the serial (or conditional) topology, individual classifiersare applied in sequence, implying some kind of ranking or orderingover them. When the primary classifier cannot be trusted to clas-sify a given object, e.g., because of the low support/confidence inits result, then the data is feed to a secondary classifier [41,42],and so on, adding classifiers in sequence. This topology is adequatewhen the cost of classifier exploitation is important, so that the pri-mary classifier is the computationally cheapest one, and secondaryclassifiers have higher exploitation cost [43]. This model can be ap-plied to classifiers with the so-called reject option as well [44]. In[45] the first classifier in the pipeline gives an estimation of thecertainty of the classification, so that uncertain data samples aresent to a second classifier, specialized in difficult instances. We no-tice the similarity of such approach to the ordered set of rules [46]or decision list [47], when we consider each rule as the classifier.A very special case of sequential topology is the Adaboost intro-duced by Freund and Schapire in 1995 [48], widely applied in dataFig. 3. Overview of multiple classifier system.6M. Woz´niak et al. / Information Fusion 16 (2014) 3–17Fig. 4. The canonical topologies of MCSs: parallel (top) and serial (bottom).mining problems [49]. The goal of boosting is to enhance the accu-racy of any given learning algorithm, even weak learning algo-rithms with an accuracy slightly better than chance. Shapire [50]showed that weak learners can be boosted into a strong learningalgorithm by sequentially focusing on the subset of the trainingdata that is hardest to classify. The algorithms performs trainingof the weak learner multiple times, each time presenting it withan updated distribution over the training examples. The distribu-tion is altered so that hard parts of the feature space have higherprobability, i.e. trying to achieve a hard margin distribution. Thedecisions generated by the weak learners are combined into a finalsingle decision. The novelty of Adaboost lies in the adaptability ofthe successive distributions to the results of the previous weaklearners, thus the name AdaptiveBoost. In the words of Kivinenet al. [51], AdaBoost finds a new distribution that is closest to theold one but taking into consideration the restriction that the newdistribution must be orthogonal to the mistake vector of the cur-rent weak learner.3. Ensemble designViewing MCS as a case of robust software [52–55], diversityarises as the guiding measure of the design process. Classifierensemble design aims to include mutually complementary individ-ual classifiers which are characterized by high diversity and accu-racy [56]. The emphasis from the Hybrid Intelligent System pointof view is in building MCS from components following differentkinds of modeling and learning approaches, expecting an increasein diversity and a decrease in classifier output correlation [57].Unfortunately, the problem of how to measure classifier diversityis still an open research topic. Brown et al. [58] notice that wecan ensure diversity using implicit or explicit approaches. Implicitapproaches include techniques of independent generation of indi-vidual classifiers, often based on random techniques, while explicitapproaches focus on the optimization of a diversity metric over agiven ensemble line-up. In this second kind of approaches, individ-ual classifier training is performed conditional to the previous clas-sifiers with the aim of exploiting the strengths of valuablemembers of classifier pool. This section discusses some diversitymeasures, and the procedures followed to ensure diversity in theensemble.3.1. Diversity measuresFor regression problems, the variance of the outputs of ensem-ble members is a convenient diversity measure, because it wasproved that the error of a compound model based on a weightedaveraging of individual model outputs can be reduced accordingto increasing diversity [56,59]. Brown et al. [60] showed a func-tional relation between diversity and individual regressor accu-racy, allowing to control the bias-variance tradeoff systematically.For classification problems such theoretical results have notbeen proved yet, however many diversity measures have been pro-posed till now. On the one hand, it is intuitive that increasingdiversity should lead to the better accuracy of the combined sys-tem, but there is no formal proof of this dependency [61], as con-firmed by the wide range of experimental results presented, e.g.,in [62]. In [53] authors decomposed the error of the classificationby majority voting into individual accuracy, good and bad diversi-ties. The good diversity has positive impact on ensemble errorreduction, whereas the bad diversity has the opposite effect. Shark-ley et al. [55] proposed a hierarchy of four levels of diversityaccording to the answer of the majority rule, coincident failures,and possibility of at least one correct answer of ensemble mem-bers. Brown et al. [58] argue that this hierarchy is not appropriatewhen the ensemble diversity varies between feature subspaces.They formulated the following taxonomy of diversity measures:(cid:2) Pairwise measures averaging a measure between each classifierpair in an ensemble, such as Q-statistic [58], kappa-statistics[63], disagreement [64] and double-fault measure [61,65].(cid:2) Non-pairwise diversity measures comparing outputs of a givenclassifier and the entire ensemble, such as Kohavi–Wolpert var-iance [66], a measure of inter-rater (inter-classifier) reliability[67], the entropy measure [68], the measure of difficulty [8],generalized diversity [52], and coincident failure diversity [69].The analysis of several diversity measures [70] relating them tothe concept of classifiers’ margin, showed their limitations and thesource of confusing empirical results. They relate the classifier selec-tion to a NP-complete matrix cover problem, implying that ensem-ble design in fact a quite difficult combinatorial problem. Diversitymeasures usually employ the most valuable sub-ensemble inensemble pruning processes [71]. To deal with the high computa-tional complexity of ensemble pruning, several hybrid approacheshave been proposed such as heuristic techniques [72,73], evolution-ary algorithms [74,75], reinforcement learning [76], and competi-tive cross-validation techniques [77]. For classification tasks, thecost of acquiring feature values (which could be interpreted as theprice for examination or time required to collect the data for deci-sion making) can be critical. Some authors take it into considerationduring the component classifier selection step [78,79].M. Woz´niak et al. / Information Fusion 16 (2014) 3–1773.2. Ensuring diversityAccording to [22,38] we can enforce the diversity of a classifierpool by the manipulation of either individual classifier inputs, out-puts, or models.3.2.1. Diversifying input dataThis diversification strategy assumes that classifiers trained ondifferent (disjoint) input subspaces become complementary. Threegeneral strategies are identified:1. Using different data partitions.2. Using different sets of features.3. Taking into consideration the local specialization of individualclassifiers.Data partitions They may be compelled by several reasons, suchas data privacy, or the need to learn over distributed data chunksstored in different databases [80–82]. Regarding data privacy, weshould notice that using distributed data may come up against le-gal or commercial constraints which do not allow sharing rawdatasets and merging them into a common repository [37]. To en-sure privacy we can train individual classifiers on each databaseindependently and merge their outputs using hybrid classifierprinciples [83]. The distributed data paradigm is strongly con-nected with the big data analysis problem [84]. A huge databasemay impede to deliver trained classifiers under specified time con-straints, imposing to resort to sampling techniques to obtain man-ageable dataset partitions. A well known approach is cross-validated committee which requires to minimize overlapping ofdataset partitions [56]. Providing individualized train datasets foreach classifier is convenient in the case of shortage of learningexamples. Most popular techniques, such as bagging [12] or boost-ing [14,19,64,85], have their origin in bootstrapping [13]. Thesemethods try to ascertain if a set of weak classifier may produce astrong one. Bagging applies sampling with replacement to obtainindependent training datasets for each individual classifier. Boost-ing modifies the input data distribution perceived by each classifierfrom the results of classifiers trained before, focusing on difficultsamples, making the final decision by a weighted voting rule.Data features May be selected to ensure diversity training of apool of classifiers. The Random Subspace [86,87] was employedfor several types of the individual classifiers such as decision tree(Random Forest) [88], linear classifiers [89], or minimal distanceclassifier [90,91]. It is worth pointing out the interesting proposi-tions dedicated one-class classifier presented by Nanni [92] or anhierarchical method of ensemble forming, based on feature spacesplitting and then assigning two-class classifiers (i.e. Support Vec-tor Machines) locally presented in [93,94]. Attribute Bagging [95] isa wrapper method that establishes the appropriate size of a featuresubset, and then creates random projections of a given training setby random selection of feature subsets. The classifier ensemble aretrain on the basis of the obtained set.Local specialization It is assumed for classifier selection, select-ing the best single classifier from a pool of classifiers trained overeach partition of the feature space. It gives the MCS answer for allobjects included in the partition [7]. Some proposals assume clas-sifier local specialization, providing only locally optimal solutions[38,96–98,72], while others divide the feature space, selecting (ortraining) a classifier for each partition. Static and dynamic ap-proaches are distinguished:fier for each cluster according to its local accuracy. AdaptiveSplitting and Selection algorithm in [101] partitions the featurespace and assigns classifiers to each partition into one inte-grated process. The main advantage of AdaSS is that the trainingalgorithm considers an area contour to determine the classifiercontent and, conversely, that the region shapes adapt to thecompetencies of the classifiers. Additionally, the majority vot-ing or more sophisticated rules are proposed as combinationmethod of area classifiers [102]. Lee et al. [103] used the fuzzyentropy measure to partition the feature space and select therelevant features with good separability for each of them.(cid:2) Dynamic classifier selection: the competencies of the individualclassifiers are calculated during classification operation [104–107]. There are several interesting proposals which extend thisconcept, e.g., by using preselected committee of the individualclassifier and making the final decision on the basis of a votingrule [108]. In [109,110] authors propose dynamic ensembleselection based on the original competence measure using clas-sification of so-called random reference classifier.Both static [111–113] and dynamic [114–116] classifier special-ization are widely used for data stream classification.3.2.2. Diversifying outputsMCS diversity can be enforced by the manipulation of the indi-vidual classifier outputs, so that an individual classifier is designedto classify only some classes in the problem.The combination method should restore the whole class labelset, e.g., a multi-class classification problem can be decomposedinto a set of binary classification problems [117,118]. The mostpopular propositions of two-class classifier combinations are:OAO (one-against-one) and OAA (one-against-all)[119], where atleast one predictor relates to each class. The model that a given ob-ject belongs to a chosen class is tested against the alternative of thefeature vector belonging to any other class. In the OAA method, aclassifier is trained to separate a chosen class from the remainingones. OAA returns class with maximum support. In more generalapproaches, the combination of individual outputs is made by find-ing the closest class, in some sense, to the code given by the out-puts of the individual classifiers. ECOC (Error Correcting OutputCodes) model was proposed by Dieterich and Bakiri [118], who as-sumed that a set of classifiers produces sequence of bits which isrelated to code-words during training. The ECOC points at the classwith the smallest Hamming distance to its codeword. Passeriniet al. showed advantages of this method over traditional ones forthe ensemble of support vector machines [120].Recently several interesting propositions on how to combinethe binary classifiers were proposed. Wu et al. [121] used pairwisecoupling, Friedman employed Max-Win rule [122], Hüllermeierproposed the adaptive weighted voting procedure [123]. A com-prehensive recent survey of binary classifier ensembles is [124].It worth mentioning the one-class classification model which isthe special case of binary classifier trained in the absence of coun-terexamples. Its main goal is to model normality in order to detectanomaly or outliers from the target class [125]. To combine suchclassifiers the typical methods developed for binary ones are used[126] but it is worth mention the work by Wilk and Wozniakwhere authors restored multi-class classification task using a poolof one-class classifiers and the fuzzy inference system [127]. Thecombination methods dedicated the one-class classifiers still awaita proper attention [128].(cid:2) Static classifier selection [99]: the relation between region ofcompetence and assigned classifier is fixed. Kuncheva’s Cluster-ing and Selection algorithm [100] partitions the feature spaceby a clustering algorithm, and selects the best individual classi-3.2.3. Diversifying modelsEnsembles with individual classifiers based on different classifi-cation models take advantage of the different biases of each classi-fier model [3]. However, the combination rule should be carefully8M. Woz´niak et al. / Information Fusion 16 (2014) 3–17chosen. We can combine the class labels but in the case of contin-uous outputs we have to normalize them, e.g., using fuzzy ap-proach [127]. We could use the different versions of the samemodel as well, because many machine learning algorithms do notguarantee to find the optimal classifier. Combining the results ofvarious initializations may give good results. Alternatively, a poolof classifiers can be produced by noise injection. Regarding neuralnetworks [129] it is easy to train pools of networks where each ofthem is trained starting from randomly chosen initial weights.Regarding decisions tree we can choose randomly the test for a gi-ven node among the possible tests according to the value of a split-ting criterion.4. Fuser designSome works consider the answers from a given Oracle as thereference combination model [130]. The Oracle is an abstract com-bination model, built such that if at least one of the individual clas-sifiers provides the correct answer, then the MCS committeeoutputs the correct class too. Some researches used the Oracle incomparative experiments to provide a performance upper boundfor classifier committee [10] or information fusion methods[131]. A simple example shows the risks of the Oracle model: as-sume we have two classifiers for a binary class problem, a randomone and the other that always returns the opposite decision; hencethe Oracle will always return the correct answer. As a consequencethe Oracle model does not fit in the Bayesian paradigm. Raudys[132] noticed that Oracle is a kind of quality measure of a givenindividual classifier pool. Let us systematize methods of classifierfusion, which on the one hand could use class labels or supportfunction, on the other hand combination rules could be given orbe the results of training. The taxonomy of decision fusion strate-gies is depicted in Fig. 5.4.1. Class label fusionEarly algorithms performing fusion of classifier responses[9,10,61] only implemented majority voting schemes in three mainversions [22]:Fig. 5. A taxonomy of fusing strategies for the combination of MCS individualdecisions.(cid:2) unanimous voting, so that the answer requires that all classifi-ers agree,(cid:2) simple majority, so that the answer is given if majority isgreater than half the pool of classifiers,(cid:2) majority voting, taking the answer with the highest number ofvotes.The expected error of majority voting (for independent classifi-ers with the same quality) was estimated in 1794 according to Ber-noulli’s equation, proven as the Condorcet Jury Theorem [5]. Laterworks focused on the analytically derived classification perfor-mance of combined classifiers hold only when strong conditionsare met [8] so that they are not useful from practical point of view.Alternative voting methods weight differently the decisions com-ing from different committee members [22,133]. The typical archi-tecture of combined classifier based on class labels is presented inthe left diagram of Fig. 6. In [134] authors distinguished the typesof weighted voting according to the classifier, both to the classifierand the class, and, finally, to features values, the classifier and theclass. Anyway, no one of these models can improve over the Oracle.To achieve that we need additional information, such as the featurevalues [132,135,136] as depicted in the right diagram of Fig. 6.4.2. Support function fusionSupport function fusion system architecture is depicted inFig. 7. Support functions provide a score for the decision takenby an individual classifier. The value of a support function is theestimated likelihood of a class, computed either as a neural net-work output, a posteriori probability, or fuzzy membership func-tion. First to be mentioned, the Borda count [11] computes anscore for each class on the basis of its ranking by each individualclassifier. The most popular form of support function is the a pos-teriori probability [26], produced by the probabilistic modelsembodied by the classifiers [137–139]. There are many works fol-lowing this approach, such as the optimal projective fuser of [140],the combination of neural networks outputs according to theiraccuracy [141], and Naïve Bayes as the MCS combination method[142].Some analytical properties and experimental evaluations ofaggregating methods were presented in [10,31,143,144]. Theaggregating methods use simple operators such as supremum orthe mean value. They do not involve learning. However, they havelittle practical applicability because of the hard conditions imposedby them [145]. The main aggregating advantage is that it counter-acts over-fitting of individual classifiers. According to [134], thefollowing types of weighted aggregation can be identified depend-ing on: (a) only the classifier id, (b) the classifier and the featurevector, (c) on the classifier and the class, and (d) on the classifier,the class, and the feature vector. For two-class recognition prob-lems only the last two types of aggregation allow to produce com-pound classifier which may improve the Oracle. For many-classproblems, it is possible to improve the Oracle [131] using any ofthese aggregation methods. Finally, another salient approach isthe mixture of experts [146,147] which combines classifier outputsusing so-called input dependent gating function. Tresp and Tanig-uchi [148] proposed a linear function for this fuser model, andCheeseman [149] proposed a mixture of Gaussian.4.3. Trainable FuserFuser weight selection can be treated as a specific learning pro-cess [31,136]. Shlien [150] used Dempster and Shafer’s theory toreach a consensus on the weights to combine decision trees. Woz-niak [151] trained the fuser using perceptron-like learning, evolu-tionary algorithm [152,153]. Zheng used data envelopmentM. Woz´niak et al. / Information Fusion 16 (2014) 3–179Fig. 6. Architecture of the MCS making decision on the basis of class label fusion only (left diagram). The right diagram corresponds to a MCS using additional informationfrom the feature values.Fig. 7. Architecture of the MCS which computes the decision on the basis of support function combination.analysis [154]. Other fuser trainable methods may be strictly re-lated to ensemble pruning methods, when authors use some heu-ristic search algorithm to select the classifier ensemble, as [72,141]according to the chosen fuser.We have to mention the group of combination methods builtfrom pools of heterogenous classifiers, i.e. using different classifica-tion models, such as stacking [155]. This method trains combina-tion block using individual classifier outputs presented duringclassification of the whole training set. Most of the combinationmethods do not take into consideration possible relations amongindividual classifiers. Huang and Suen [156] proposed Behavior-Knowledge Space method which aggregates the individual classifi-ers decision on the basis of the statistical approach.5. Concept DriftBefore entering the discussion of practical applications we con-sider a very specific topic of real life relevance which is known asConcept Drift in knowledge engineering domains, or non-station-ary processes in signal processing and statistics domains. Most ofthe conventional classifiers do not take into consideration this phe-nomenon. Concept Drift means that the statistical dependenciesbetween object features and its classification may change in time,so that future data may be badly processed if we maintain thesame classification, because the object category or its propertieswill be changing. Concept drift occurs frequently in reallife[157]. MCS are specially well suited to deal with Concept Drift.Machine learning methods in security applications (like spamfilters or IDS/IPS) [158] or decision support systems for marketingdepartments [159] require to take into account new training datawith potentially different statistical properties [116]. The occur-rence of Concept Drift decreases the true classification accuracydramatically. The most popular approaches are the StreamingEnsemble Algorithm (SEA) [111] and the Accuracy WeightedEnsemble (AWE) [160]. Incoming data are collected in data chunks,which are used to train new models. The individual classifiers eval-uation is done on their accuracy on the new data. The best per-forming classifiers are selected to constitute the MCS committeein the next time epoch. As the decision rule, the SEA uses a major-ity voting, whereas the AWE uses a weighted voting strategy. Ko-tler et al. presentthe Dynamic Weighted Majority (DWM)algorithm [114] which modifies the decision combination weightsand updates the ensemble according to number of incorrect deci-sions made by individual classifiers. When a classifier weight istoo small, then it is removed from the ensemble, a new classifieris trained and added to the ensemble in its place.A difficult problem is drift detection, which is the problem ofdeciding that the Concept Drift has taken place. The current re-search direction is to propose an additional binary classifier giv-ing the decision to rebuild the classifiers. The drift detector canbe based on changes in the probability distribution of the in-stances [161–163] or classification accuracy [164,165]. Not allclassification algorithms dealing with concept drift require driftdetection, because they can adjust the model to incoming data[166][?].6. ApplicationsReported applications of classifier ensembles have grownastoundingly in the recent years due to the increase in computa-tional power allowing training of large collections of classifiers inpractical application time constraints. A recent review appears in[18]. Sometimes the works combine diverse kinds of classifiers,so-called heterogeneous MCS. Homogeneous MCS, such as RandomForest (RF), are composed of classifiers of the same kind. In theworks revised below, basic classifiers are Multi-Layer Perceptron(MLP), k-Nearest Neighbor (kNN), Radial Basis Function (RBF), Sup-port Vector Machines (SVM), Probabilistic Neural Networks(PNNs), and Maximum Likelihood (ML) classifiers.10M. Woz´niak et al. / Information Fusion 16 (2014) 3–17We review in this section recent applications to remote sensingdata, computer security, financial risk assessment, fraud detection,recommender systems, and medical computer aided diagnosis.6.1. Remote sensingThe main problems addressed by MCS in remote sensing do-mains are the land cover mapping and change detection. Land cov-er mapping consists in the identification of materials that are in thesurface of the area being covered. Depending on the application, afew general classes may be identified, i.e. vegetation, water, build-ings, roads, or a more precise classification can be required, i.e.identifying tree or crop types. Applications include agriculture, for-estry, geology, urban planning, infrastructure degradation assess-ment. Change detection consists in the identification of placeswhere the land cover has changed in time, it implies the computa-tion over time series of images. Change detection may or may notbe based on previous or separate land cover maps. Remote sensingclassification can be done on a variety of data sources, sometimesperforming fusion of different data modalities. Optical data hasbetter interpretability by humans, but land is easily occluded byweather conditions, i.e. cloud formations. Hyperspectral sensingprovides high-dimensional data at each image pixel, with highspectral resolution. Synthetic Aperture Radar (SAR) is not affectedby weather or other atmospheric conditions, so that observationsare better suited for continuous monitoring of seasonally changingland covers. SAR can provide also multivariate data from varyingradar frequencies. Other data sources are elevation maps, andother ancillary information, such as the measurements of environ-mental sensors.6.1.1. Land cover mappingEarly application of MCS to land cover mapping consisted inoverproducing a large set of classifiers and searching for the opti-mal subset [38,65,167]. To avoid the combinatorial complexity,the approach performs clustering of classifier error, aggregatingsimilar classifiers. The approach was proven to be optimal undersome conditions on the classifiers. Interestingly, testing was per-formed on multi-source data, composing the pixel’s feature vectorof joining multi-spectral with radar data channels, to compute theland cover map. The MCS was heterogenous, composed of MLP,RBF, and PNN.The application of RF to processing remote sensing data hasbeen abundant in the literature. It has been applied to estimateland cover on Landsat data over Granada, Spain [168] and multi-source data in a Colorado mountainous area [169]. Specifically,Landsat Multi-Spectral, elevation, slope and aspect data are usedas input features. The RF approach is able to successfully fuse theseinhomogeneous informations. Works on hyperspectral images ac-quired by the HyMap sensor have been addressed to build vegeta-tion thematic maps [170], comparing RF and decision tree-basedAdaboost, as well as two feature selection methods: the out-of-bag and a best-first search wrapper feature subset selection meth-od. Diverse feature subsets are tested, and the general conclusion isthat tree ecotopes are better discriminated than grass ecotopes.Further work with RF has been done assessing the uncertainty inmodeling the distribution of vegetation types [171], performingclassification on the basis of environmental variables, in an ap-proach that combines spatial distribution modeling by spatialinterpolation, using sequential Gaussian simulation and the clus-tering of species into vegetation types. Dealing with labeled datascarcity, there are methods [172] based on the combination of RFand the enrichment of the training dataset with artificially gener-ated samples in order to increase classifier diversity, which is ap-plied to Landsat multispectral data. Artificial data is generatedfrom the Gaussian modeling of the data distribution. The applica-tion of RF to SAR multitemporal data aims to achieve season invari-ant detection of several classes of land cover, i.e. grassland, ceral,forest, etc. [173]. RF performed best, with lowest spatial variability.Images were coregistered and some model portability was tested,where the model trained on one SAR image was applied on otherSAR images of the same site obtained at different times. The suc-cess of RF for remote sensing images has prompted the proposalof an specific computational environment [174].Ensambles of SVM have been also applied to land cover map. In-deed, the ground truth data scarcity has been attacked by an activelearning approach to semi-supervised SVM training [175]. The ac-tive learning approach is based on the clustering of the unlabeleddata samples according to the clustering of the SVM outputs onthe current training dataset. Samples with higher membershipcoefficient are added to the corresponding class data, and the clas-sifier is retrained in an iterative process. These semi-supervisedSVM are combined in a majority voting ensemble and applied tothe classification SPOT and Landsat optical data. Land cover classi-fication in the specific context of shallow waters has the additionaldifficulties of the scattering, refraction and reflection effects intro-duced by the water cover. A robust process combines a parallel anda serial architecture [176], where initial classification results ob-tained by SVM are refined in a second SVM classifier and the finalresult is given by a linear combination of two ensembles of SVMclassifiers and a minimum distance classifier. Besides, the systemestimates the water depth by a bathymetry estimation process.The approach is applied to Landsat images for the estimation ofcoral population in coastal waters. Polarimetric SAR data used forthe classification of Boreal forests require an ensemble of SVM[177]. Each of the SVM is specifically tuned to a class, with specificfeature selection process. Best results are obtained when multi-temporal data is used, joining two images from two different sea-sons (summer and winter) and performing the feature selectionand training on the joint data vectors.6.1.2. Change detectionEarly application of MCS to land cover change detection wasbased on non-parametric algorithms, specifically MLP, k-NN, RBF,and ML classifiers [178,179], where classifier fusion was performedeither by majority voting, Bayesian average and maximum a poste-riori probability. Testing data were Thematic Mapper multispectralimages, and the Synthetic Aperture Radar (SAR) of Landsat 5 satel-lite. Recent works on change detection in panchromatic imageswith MCS follow three different decision fuser strategies: majorityvoting, Dempster-Shafer evidence theory, and the Fuzzy Integral[180]. The sequential process of the images previous to classifica-tion includes pan-sharpening of the multi-temporal images, co-registration, raw radiometric change detection by image subtrac-tion and automatic thresholding, and a final MCS decision com-puted on the multi-spectral data and the change detection dataobtained from the various pan-sharpening approaches.6.2. Computer securityComputer security is at the core of most critical services nowa-days, from universities, banking, companies, communication. Se-cure information processing is a growing concern, and themachine learning approaches are trying to provide predictive solu-tions that may allow to avoid the negative impact of such attacks.Here we introduce some of the problems, with current solutionsproposed from the MCS paradigm.6.2.1. Distributed denial of serviceDistributed denial of service (DDoS) are among the most threat-ening attacks that an Internet Service Provider may face. Distrib-uted service providers, such as military applications, e-healthcareM. Woz´niak et al. / Information Fusion 16 (2014) 3–1711and e-governance can be very sensitive to this type of attacks,which can produce network performance degradation, serviceunavailability, and revenue loss. There is a need for intelligent sys-tems able to discriminate legitimate flash crowds from an attack. Ageneral architecture for automatic detection of DDoS attacks isneeded where the attack detection may be performed by a MCS.The MCS constituent classifiers may be ANNs trained with robustlearning algorithms, i.e. Resilient Back Propagation (RBP). Specifi-cally, a boosting strategy is defined on the ensemble of RBP trainedANNs, and a Neyman Pearson approach is used to make the finaldecision [181]. This architecture may be based on Sugeno AdaptiveNeuro-Fuzzy Inference Systems (ANFIS) [182]. A critical issue ofthe approach is the need to report validation results, which canonly be based on recorded real life DDoS attacks. There are somepublic available datasets to perform and report these results. How-ever, results reported on these datasets may not be informative ofthe system performance on new attacks which may have quite dif-ferent features. This is a pervasive concern in all security applica-tions of machine learning algorithms.6.2.2. MalwareMalicious code, such as trojans, virus, spyware, detection byanti-virus approaches can only be performed after some instanceof the code has been analyzed finding some kind of signature,therefore some degree of damage has already been done. Predic-tive approaches based on Machine Learning techniques may al-low anticipative detection at the cost of some false positives.Classifiers learn patterns in the known malicious codes extrapo-lating to yet unseen codes. A taxonomy of such approaches is gi-ven in [183]. describing the basic code representation by byteand opcode n-grams, strings, and others like portable executablefeatures. Feature selection processes, such as the Fisher score,are applied to find the most informative features. Finally, classi-fiers tested in this problem include a wide variety of MCS com-bining diverse base classifiers with all standard fuser designs.Results have been reported that MCS overcome other ap-proaches, are better suitable for active learning needed to keepthe classifiers updated and tuned to the changing malicious codeversions.6.2.3. Intrusion detectionIntrusion Detection and Intrusion Prevention deal with theidentification of intruder code in a networked environment viathe monitoring of communication patterns. Intruder detection per-formed as an anomaly detection process allows to detect previ-ously unseen patterns, at the cost of false alarms, contrary tosignature based approaches. The problem is attacked by modularMCS whose compounding base classifiers are one-class classifiersbuilt by the Parzen window probability density estimation ap-proach [128]. Each module is specialized in a specific protocol ornetwork service, so that different thresholds can be tuned for eachmodule allowing some optimization of the false alarm rate. On theother hand, Intrusion Prevention tries to impede the execution ofthe intruder code by fail-safe semantics, automatic response andadaptive enforcement. An approach relies on the fact that Instruc-tion Set Randomization prevents code injection attacks, so that de-tected injected code can be used for adaptation of the anomalyclassifier and the signature-based filtering [184]. Clustering of n-grams is performed to obtain a model of the normal communica-tion behavior which is accurate allowing zero-day detection ofworm infection even in the case of low payload or slow penetration[185]. The interesting proposed hybrid intrusion detection waspresented in [186], where decision trees and support vector ma-chines are combined as a hierarchical hybrid intelligent systemmodel.6.2.4. Wireless sensor networksWireless sensor networks (WSNs) are collections of inexpen-sive, low power devices deployed over a geographical space formonitoring, measuring and event detection. Anomalies in theWSN can be due to failures in software or hardware, or to mali-cious attacks compelling the sensors to bias or drop their informa-tion and measurements. Anomaly detection in WSN is performedusing an ensemble of binary classifiers, each tuned on diverseparameters and built following a different approach (Average,autorregresive, neural network, ANFIS). The decision is made by aweighted combination of the classifiers outputs [187].6.3. Banking, credit risk, fraud detectionIn the current economical situation, the intelligent processing offinancial information, the assessing of financial or credit risks, andrelated issues have become a prime concern for society and for thecomputational intelligence community. Developing new tools mayallow to avoid in the future the dire problems faced today by soci-ety. In this section we review some of the most important issues,gathering current attempts to the deal with them.6.3.1. Fraud detectionFraud detection involves identifying fraud as soon as possibleafter it has been perpetrated. Fraud detection [188] is big area ofresearch and applications of machine learning, which has providedtechniques to counteract fraudsters in credit card fraud, moneylaundering, telecommunications fraud, and computer intrusion.MCS have been also applied successfully in this domain. A key taskis modeling the normal behavior in order to be able to establishsuspicion scores for outliers. Probabilistic networks are specificone-class classifiers that are well suited to this task, and baggingof probabilistic networks has been proposed as a general tool forfraud detection because the MCS approach improves the robust-ness of the normal behavior modeling [189].6.3.2. Credit card fraudSpecific works on credit card fraud detection use real-life dataof transactions from an international creditcard operation [190].The exploration of the sensitivity to the ratio of fraud to non-fraudof the random undersampling approach to deal with unbalancedclass sizes is required to validate the approaches. Comparing RFagainst SVM and logisti regression [190], RF was the best per-former in all experimental conditions as measured by almost allperformance measurements. Other approaches to this problem in-clude a bagged ensemble of SVM tested on a british card applica-tion approval dataset [191].6.3.3. Stock marketTrade based stock market manipulation try to influence thestock values simply by buying and then selling. It is difficult to de-tect because rules for detection quickly become outdated. An inno-vative research track is the use of peer-group analysis for tradestock manipulation detection, based on the detection of outlierswhose dynamic behavior separates from that of the previouslysimilar stock values, its peers [192]. Dynamic clustering allows totrack in time the evolution of the community of peers related tothe stocks under observation, and outlier detection techniquesare required to detect the manipulation events.6.3.4. Credit riskCredit risk prediction models seek to predict whether an indi-vidual will default on a loan or not. It is greatly affected by theunavailability, scarcity and incompleteness of data. The applicationof machine learning to this problem includes the evaluation of bag-ging, boosting, stacking as well as other conventional classifiers12M. Woz´niak et al. / Information Fusion 16 (2014) 3–17over three benchmarking datasets, including sensitivity to noiseadded to the attributes [193]. Another approach for this problemis the Error Trimmed Boosting (ETB) [194] which has been testedover a privative dataset provided by a company. ETB consists inthe iterative selection of subsets of samples based on their errorunder the current classifier. An special case of credit risk is enter-prise risk assessment which has a strong economic effect due tothe financial magnitude of the entities involved. To deal with thisproblem a combination of bagging and random subspace featureselection using SVM as the base classifier has been developedand tested. The resulting method has increased diversity improv-ing results over a dataset provided by the Bank of China [195].Bankruptcy prediction is a dramatic special case of credit risk.Ensemble systems with diversity ensured by genetic algorithmbased selection of component classifiers is proposed in [196] forbankruptcy prediction in South Korean firms. The prediction of fail-ure of dotcom companies has been a matter of research since thebubble explosion after the year 2000. Tuning a hybrid of PNN,MLP and genetic programming classifiers over a set of features se-lected applying a t-test and F-test for relevance to the categoricalvariable has given some solutions [197]. The same approach is re-ported in [198] to detect fraud in the financial statement of bigcompanies.6.3.5. Financial risksUncertainty in the financial operations is identified with thefinancial risks such as credit, business, investment, and operationalrisks. Financial distress can be detected by clustering and MCS infour different combination models. Clustering is performed byclassical SOM and k-means algorithms and used to partition thedata space prior to MCS training [199]. Experimental frameworkfor the evaluation of financial risk assessment models, giving a spe-cific performance measures allow the exploration of computationalsolutions to these problems [200]. Several conventional classifiersand MCS have been tested in this framework using a large pool ofdatasets. Bank performance and bankruptcy prediction is ad-dressed using a widely heterogenous MCS including PNN,RBF,MLP, SVM, CART trees, and a fuzzy rule system. The effect of PCAinitial dimensionality reduction is also tested [201]. The effect offeature construction from previous experience and a priori infor-mation in the efficiency of classifiers for early warning of bank fail-ures is reported in [202].6.3.6. New fraud trendsPrescription fraud has been identified as a cause of substantialmonetary loss in health care systems, it consists in the prescriptionof unnecessary medicaments. The research works need to real lifedata from a large multi-center medical prescription database [203].The authors use a novel distance based on data-mining approach ina system which is capable of self-learning by regular updates. Thesystem is designed to perform on-line risky prescription detectionfollowed by off-line expert evaluation.A new brand of frauds appear in the online gaming and lotter-ies, i.e. intended for money laundering, whose detection is dealtwith a mixture of supervised and unsupervised classifiers [204].To be adaptive to fraudster evolving strategies, it is required toemphasize online learning, and online cluster detection. Fraud intelecommunication systems involving usage beyond contract spec-ifications is dealt with in [205] by a preprocessing, clustering andclassification pipeline. Clustering has been found to improve clas-sification performance, and boosted trees are the best performingapproach. The analysis of social networks by means of MCS may al-low the detection of fraud in automobile insurance, consisting instaging traffic accidents and issuing fake insurance claims to theirgeneral or vehicle insurance company [206].6.4. MedicineMedicine is a big area of application of any innovative compu-tational approach, dealing with massive amounts of data in someinstances, and with very imprecise or ambiguous data in other sit-uations. The range of applications is quite big, so here we only givea scrap of all the current problems and approaches related with theMCS paradigm. In Medicine, a specific research area since theinception of Artificial Intelligence is the construction of ComputerAided Diagnosis (CAD) systems or Clinical Decision Support Sys-tems (CDSS) [207], which involve as the final step some kind ofclassifier predicting the subject’s disease or normal status. In CDSSdevelopment, there are several steps such as the definition of thesensor providing the data, the preprocessing of the data to normal-ize it and remove noise, the selection of features, and the finalselection of the classifier.6.4.1. Coronary diseasesA recent instance of CDSS is the application to cardiovasculardisease diagnosis of an heterogenous collection of classifiers, com-posed of SVM, bayesian networks and ANN [208] finding ten newbiomarkers. In this AptaCDSS-E process starts with the use of anaptamer biochip scanning protein expression levels which is theinput to physician taking the decisions afterwards. Feature selec-tion is performed by an ANOVA analysis. Doctor decisions arestored for system retraining. Classifier combination is done bymajority voting or hierarchical fusion. Many CAD systems relatedwith coronary diseases are based on the information provided bythe electrocardiogram (ECG), so that many of them rely on the fea-tures extracted from them. Coronary artery disease is a broad termthat encompasses any condition that affects the heart. It is achronic disease in which the coronary arteries gradually hardenand narrow, there have approaches to provide CAD for this condi-tion, such as the use of a mixture of three ANNs for the predictionof coronary artery disease [209]. The dysfunction or abnormality ofone or more of the heart four valves is called valvular heart disease.Its diagnosis is performed by neural network ensembles in[209,210] over features selected by a correlation analysis withthe categorical variable. Two separate ANNs are trained to identifyinfarction on training sets with different statisticsmyocardialregarding the percentage of patients in [211]. The network special-ized in healthy controls is applied to the new data, if the output isbelow a threshold the subject is deemed healthy, otherwise thedisease-specific network is applied to decide.6.4.2. ProteomicsProteins are said to have a common fold if they have the samemajor secondary structure in the same arrangement and with thesame topology. Machine learning techniques have been proposedfor three-dimensional protein structure prediction. Early ap-proaches consisted in hybrid systems, such as the ANN, statisticalclassifier and case base reasoning classifier combined by majorityvoting of [212]. For instance, an ensemble of K-local hyperplanesbased on random subspace and feature selection has been tested[213], where feature selection is done according to distance tothe class centroids. A recent approach is the MarFold [214] com-bining by majority voting three margin-based classifiers for proteinfold recognition: the adaptive local hyperplane (ALH), the k-neigh-borhood ALH and the SVM.6.4.3. NeuroscienceIn the field of Neurosciences, the machine learning approach isgaining widespread acceptation. It is used for the classification ofimage data searching for predictive non-invasive biomarkers thatmay allow early or prodromal diagnosis of a number of degenera-tive diseases which have increasing impact in the society due toM. Woz´niak et al. / Information Fusion 16 (2014) 3–1713the aging of populations around the world. Diverse MCS ap-proaches have been applied to structural MRI data, specificallyfor the classification of Alzheimer disease patients, such as anRVM based two stage pipeline [45], variations of Adaboost [215],hybridizations of kernel and Dendritic Computing approaches[216]. Classifier Ensembles have been applied to the classificationof fMRI data [217,218] and its visual decoding [219], which is thereconstruction of the visual stimuli from the fMRI data.6.5. Recommender systemsNowadays, recommender systems are the focus of intense re-search [220]. They try to help consumers to select the product thatmay be interesting for them based on their previous searches andtransactions, but such systems are expanding beyond typical sales.They are used to predict which mobile telephone subscribers are inrisk of switching to another provider, or to advice conference orga-nizers about assigning papers to peer reviewers [221]. Burke [222]proposed hybrid recommender systems combining two or morerecommendation techniques to improve performance avoidingthe drawbacks of an individual recommender. Similar observationswere confirmed by Balabanovic et al. [223] and Pazzani [224] whodemonstrated that hybrid method recommentations improve col-laborative and content-based approaches.There are several interesting works which apply the hybrid andcombined approach to recommender systems. Jahrer and Töscher[225] demonstrated the advantage of ensemble learning appliedto the combination of different collaborative filtering algorithmson the Netix Prize dataset. Porcel et al. [226] developed an hybridfuzzy recommender system to help disseminate information aboutresearch resources in the field of interest of a user. Claypool et al.[227] performed a linear combination of the ratings obtained fromindividual recommender systems into one final recommendation,while Pazzani proposed to use a voting scheme [224]. Billsus andPazzani [228] selected the best recommendation on the basis of arecommendation quality metric as the level of confidence whileTran and Cohen [229] preferred an individual which is the mostconsistent with the previous ratings of the user. Kunaver et al.[230] proposed Combined Collaborative Recommender based onthree different collaborative recommender techniques. Goksedefand Gundoz-Oguducu [231] combined the results of several rec-ommender techniques based on Web usage mining.7. Final remarksWe have summarized the main research streams on multipleclassifier systems, also known in the literature as combined classi-fier or classifier ensemble. Such hybrid systems are the focus of in-tense research recently, so fruitful that our review could not beexhaustive. Key issues related to the problem under considerationare classifier diversity and methods of classifier combination.The diversity is believed to provide improved accuracy and clas-sifier performance. Most works try to obtain maximum diversityby different means: introducing classifier heterogeneity, boot-strapping the training data, randomizing feature selection, ran-domizing subspace projections, boosting the data weights, andmany combinations ofthe diversityhypothesis has not been fully proven, either theoretically or empir-ically. However, the fact is that MCSs show in most instances im-proved performance, resilience and robustness to high datadimensionality and diverse forms of noise, such as labeling noise.The there are several propositions how to combine the classifieroutputs, what was presented in this work, nonetheless we pointout that classifier combination is not the only way to produce hy-these ideas. Nowadays,brid classifier systems. We envisage further possibilities of hybrid-ization such as:(cid:2) Merging the raw data from different sources into one repositoryand then train the classifier.(cid:2) Merging the raw data and a prior expert knowledge (e.g., learn-ing sets and human expert rules to improve rules on the basis ofincoming data).(cid:2) Merging a prior expert knowledge and classification modelsreturned by machine learning procedures.For such a problem we have to take into consideration issues re-lated to data privacy, computational and memory efficiency.AcknowledgmentsWe would like to thank the anonymous reviewers for their dil-igent work and efficient efforts. We are also grateful to the Editor-in-Chief, Prof. Belur V. Dasarathy, who encouraged us to write thissurvey for this prestigious journal.MichałWoz´ niak was supported by The Polish National ScienceCentre under the Grant No. N519 576638 which is being realizedin years 2010–2013.References[1] J. Neumann, The Computer and the Brain, Yale University Press, New Haven,CT, USA, 1958.[2] A. Newell, Intellectual issues in the history of artificial intelligence, in: F.Machlup, U. Mansfield (Eds.), The Study of Information: InterdisciplinaryMessages, John Wiley & Sons Inc., New York, NY, USA, 1983, pp. 187–294.[3] D. Wolpert, The supervised learning no-free-lunch theorems, in: Proceedingsof the 6th Online World Conference on Soft Computing in IndustrialApplications, 2001, pp. 25–42.[4] C.K. Chow,Statisticalindependenceand threshold functions,IEEETransactions on Electronic Computers EC-14 (1) (1965) 66–68.[5] L. Shapley, B. Grofman, Optimizing group judgmental accuracy in thepresence of interdependencies, Public Choice 43 (3) (1984) 329–333.[6] B.V. Dasarathy, B.V. Sheela, A composite classifier system design: conceptsand methodology, Proceedings of the IEEE 67 (5) (1979) 708–713.[7] L. Rastrigin, R.H. Erenstein, Method of Collective Recognition, Energoizdat,Moscow, 1981.[8] L. Hansen, P. Salamon, Neural network ensembles, IEEE Transactions onPattern Analysis and Machine Intelligence 12 (10) (1990) 993–1001, http://dx.doi.org/10.1109/34.58871.[9] L. Xu, A. Krzyzak, C. Suen, Methods of combining multiple classifiers and theirapplications to handwriting recognition, IEEE Transactions on Systems, Manand Cybernetics 22 (3) (1992) 418–435.[10] K. Tumer, J. Ghosh, Analysis of decision boundaries in linearly combinedneural classifiers, Pattern Recognition 29 (2) (1996) 341–348.[11] T. Ho, J.J. Hull, S. Srihari, Decision combination in multiple classifier systems,IEEE Transactions on Pattern Analysis and Machine Intelligence 16 (1) (1994)66–75.[12] L. Breiman, Bagging predictors, Machine Learning 24 (2) (1996) 123–140.[13] R. Schapire, The strength of weak learnability, Machine Learning 5 (2) (1990)197–227.[14] Y. Freund, Boosting a weak learning algorithm by majority, InformationComputing 121 (2) (1995) 256–285.[15] M. Kearns, U. Vazirani, An Introduction to Computational Learning Theory,MIT Press, Cambridge, MA, USA, 1994.[16] D. Angluin, Queries and concept learning, Machine Learning 2 (4) (1988) 319–342.[17] A. Jain, R. Duin, M. Jianchang, Statistical pattern recognition: a review, IEEETransactions on Pattern Analysis and Machine Intelligence 22 (1) (2000) 4–37.[18] N. Oza, K. Tumer, Classifier ensembles: select real-world applications,Information Fusion 9 (1) (2008) 4–20.[19] R. Polikar, Ensemble based systems in decision making, IEEE Circuits andSystems Magazine 6 (3) (2006) 21–45.[20] R. Polikar, Ensemble learning, Scholarpedia 3 (12) (2008) 2776.[21] L. Rokach, Taxonomy for characterizing ensemble methods in classificationtasks: a review and annotated bibliography, Computational Statistics andData Analysis 53 (12) (2009) 4046–4072.[22] L. Kuncheva, Combining Pattern Classifiers: Methods and Algorithms, Wiley-Interscience, 2004.[23] L. Rokach, Pattern Classification Using Ensemble Methods, Series in MachinePerception and Artificial Intelligence, World Scientific, 2010.14M. Woz´niak et al. / Information Fusion 16 (2014) 3–17[24] G. Seni, J. Elder, Ensemble Methods in Data Mining: Improving AccuracyThrough Combining Predictions, Morgan and Claypool Publishers, 2010.[25] B. Baruque, E. Corchado, Fusion Methods for Unsupervised LearningEnsembles, Springer Verlag New York, Inc., 2011.[57] G. Zenobi, P. Cunningham, Using diversity in preparing ensembles ofclassifiers based on different feature subsets to minimize generalizationerror, Machine Learning: ECML 2001 (2001) 576–587.[58] G. Brown, J. Wyatt, R. Harris, X. Yao, Diversity creation methods: a survey and[26] R. Duda, P. Hart, D. Stork, Pattern Classification, second ed., Wiley, New York,categorisation, Information Fusion 6 (1) (2005) 5–20.2001.[27] E. Alpaydin, Introduction to Machine Learning, second ed., The MIT Press,2010.[28] C. Bishop, Pattern Recognition and Machine Learning (Information Scienceand Statistics), Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006.[29] T. Dietterich, Ensemble methods in machine learning, in: Multiple ClassifierSystems, Lecture Notes in Computer Science, vol. 1857, Springer, Berlin,Heidelberg, 2000, pp. 1–15.[30] G. Marcialis, F. Roli, Fusion of face recognition algorithms for video-basedsurveillance systems, in: G.L. Foresti, C. Regazzoni, P. Varshney (Eds.), 2003,pp. 235–250.[31] S. Hashem, Optimal linear combinations of neural networks, Neural Networks10 (4) (1997) 599–614.[32] R. Clemen, Combining forecasts: a review and annotated bibliography,International Journal of Forecasting 5 (4) (1989) 559–583.[33] J. Quinlan, C4.5: Programs for Machine Learning, Morgan Kaufmann Series inMachine Learning, Morgan Kaufman Publishers, 1993.[34] T. Wilk, M. Wozniak, Complexity and multithreaded implementation analysisof one class-classifiers fuzzy combiner, in: E. Corchado, M. Kurzynski, M.Wozniak (Eds.), Hybrid ArtificialIntelligent Systems, Lecture Notes inComputer Science, vol. 6679, Springer, Berlin/Heidelberg, 2011, pp. 237–244.[35] T. Kacprzak, K. Walkowiak, M. Wozniak, Optimization of overlay distributedcomputing systems for multiple classifier system – heuristic approach, LogicJournal of IGPL, doi:10.1093/jigpal/jzr020.[36] K. Walkowiak, Anycasting in connection-oriented computer networks:of Appliedmodels,Journaland results,Mathematics and Computer Sciences 20 (1) (2010) 207–220.Internationalalgorithms[37] R. Agrawal, R. Srikant, Privacy-preserving data mining, SIGMOD Records 29(2) (2000) 439–450.[38] G. Giacinto, F. Roli, G. Fumera, Design of effective multiple classifier systemsin: Proceedings of the 15th Internationalby clustering of classifiers,Conference on Pattern Recognition, 2000, vol. 2, 2000, pp. 160–163.[39] T. Ho, Complexity of classification problems and comparative advantages ofcombined classifiers, in: Proceedings of the First International Workshop onMultiple Classifier Systems, MCS ’00, Springer-Verlag, London, UK, 2000, pp.97–106.[40] F. Roli, G. Giacinto, Design of Multiple Classifier Systems, World ScientificPublishing, 2002.[41] L. Lam, Classifier combinations: implementations and theoretical issues, in:Proceedings of the First International Workshop on Multiple ClassifierSystems, MCS ’00, Springer-Verlag, London, UK, 2000, pp. 77–86.[42] A.F.R. Rahman, M.C. Fairhurst, Serial combination of multiple experts: aunified evaluation, Pattern Analysis and Applications 2 (1999) 292–311.[43] G. Fumera, I. Pillai, F. Roli, A two-stage classifier with reject option for textcategorisation, 5th International Workshop on Statistical Techniques inPattern Recognition (SPR 2004), vol. 3138, Springer, Lisbon, Portugal, 2004,pp. 771–779.[44] P. Bartlett, M. Wegkamp, Classification with a reject option using a hinge loss,Journal of Machine Learning Research 9 (2008) 1823–1840.[45] M. Termenon, M. Graña, A two stage sequential ensemble applied to theclassification of alzheimer’s disease based on MRI features, Neural ProcessingLetters 35 (1) (2012) 1–12.[46] P. Clark, T. Niblett, The CN2 induction algorithm, Machine Learning 3 (4)(1989) 261–283.[47] R. Rivest, Learning decision lists, Machine Learning 2 (3) (1987) 229–246.[48] Y. Freund, R. Schapire, A decision-theoretic generalization of on-line learningand an application to boosting, Journal of Computer and System Sciences 55(1) (1997) 119–139, http://dx.doi.org/10.1006/jcss.1997.1504.[49] X. Wu, V. Kumar, J.R. Quinlan, J. Ghosh, Q. Yang, H. Motoda, G.J. McLachlan, A.Ng, B. Liu, P.S. Yu, Z.-H. Zhou, M. Steinbach, D.J. Hand, D. Steinberg, Top 10algorithms in data mining, Knowledge and Information Systems 14 (1) (2008)1–37, http://dx.doi.org/10.1007/s10115-007-0114-2.[50] R. Schapire, The strength of weak learnability, Machine Learning 5 (2) (1990)197–227, http://dx.doi.org/10.1023/A:1022648800760.[51] J. Kivinen, M.K. Warmuth, Boosting as entropy projection, in: Proceedings ofthe Twelfth Annual Conference on Computational Learning Theory, 1999.<http://dl.acm.org/citation.cfm?id=307424>.[52] D. Partridge, W. Krzanowski, Software diversity: practical statistics for itsmeasurement and exploitation, Information and Software Technology 39 (10)(1997) 707–717.[53] G. Brown, L. Kuncheva,‘‘good’’ And ‘‘bad’’ diversity in majority voteensembles, in: Proceedings MCS 2010, pp. 124–133.[54] M. Smetek, B. Trawinski, Selection of heterogeneous fuzzy model ensemblesusing self-adaptive genetic algorithms, New Generation Computing 29 (2011)309–327.[55] A.J.C. Sharkey, N. Sharkey, Combining diverse neural nets, KnowledgeEngineering Review 12 (3) (1997) 231–247.[56] A. Krogh, J. Vedelsby, Neural network ensembles, cross validation, and activelearning, Advances in Neural Information Processing Systems 7 (1995) 231–238.[59] N. Ueda, R. Nakano, Generalization error of ensemble estimators,in:IEEE International Conference on Neural Networks,Proceedings ofWashington, USA, 1996, pp. 90–95.[60] G. Brown, J. Wyatt, P. Tinˇ o, Managing diversity in regression ensembles,Journal of Machine Learning Research 6 (2005) 1621–1650.[61] L. Kuncheva, C. Whitaker, C. Shipp, R. Duin, Limits on the majority voteaccuracy in classifier fusion, Pattern Analysis and Applications 6 (2003) 22–31.[62] Y. Bi, The impact of diversity on the accuracy of evidential classifierensembles, International Journal of Approximate Reasoning 53 (4) (2012)584–607.[63] D. Margineantu, T. Dietterich, Pruning adaptive boosting, in: Proceedings ofthe Fourteenth International Conference on Machine Learning, ICML ’97,Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1997, pp. 211–218.[64] D. Skalak, The sources of increased accuracy for two proposed boostingalgorithms, in: Proceedings of the American Association for Arti Intelligence,AAAI-96, Integrating Multiple Learned Models Workshop, 1996, pp. 120–125.[65] G. Giacinto, F. Roli, Design of effective neural network ensembles for imageclassification purposes, Image Vision Computing 19 (9-10) (2001) 699–707.[66] R. Kohavi, D. Wolpert, Bias plus variance decomposition for zero-one lossfunctions, in: ICML-96, 1996.[67] J. Fleiss,J. Cuzick, The reliability of dichotomous judgments: unequalnumbers of judgments per subject, Applied Psychological Measurement 4(3) (1979) 537–542.[68] P. Cunningham, J. Carney, Diversity versus quality in classification ensemblesbased on feature selection, in: Proceedings of the 11th European Conferenceon Machine Learning, ECML ’00, Springer-Verlag, London, UK, 2000, pp. 109–116.[69] C. Shipp, L. Kuncheva, Relationships between combination methods andmeasures of diversity in combining classifiers, Information Fusion 3 (2)(2002) 135–148.[70] E.K. Tang, P.N. Suganthan, X. Yao, An analysis of diversity measures, MachineLearning 65 (1) (2006) 247–271.[71] G. Martinez-Mu/ noz, D. Hern/’andez-Lobato, A. Suarez, An analysis ofensemble pruning techniques based on ordered aggregation,IEEETransactions on Pattern Analysis and Machine Intelligence 31 (2) (2009)245–259.[72] D. Ruta, B. Gabrys, Classifier selection for majority voting, Information Fusion6 (1) (2005) 63–81.[73] R. Banfield, L. Hall, K. Bowyer, W. Kegelmeyer, Ensemble diversity measuresand their application to thinning, Information Fusion 6 (1) (2005) 49–62.[74] Z.-H. Zhou, J. Wu, W. Tang, Ensembling neural networks: many could bebetter than all, Artificial Intelligence 137 (1-2) (2002) 239–263.[75] B. Gabrys, D. Ruta, Genetic algorithms in classifier fusion, Applied SoftComputing 6 (4) (2006) 337–347.[76] I. Partalas, G. Tsoumakas, I. Vlahavas, Pruning an ensemble of classifiers viareinforcement learning, Neurocomputing 72 (7–9) (2009) 1900–1909.[77] Q. Dai, A competitive ensemble pruning approach based on cross-validationtechnique, Knowledge-Based Systems (0) (2012), http://dx.doi.org/10.1016/j.knosys.2012.08.024.[78] Y. Peng, Q. Huang, P. Jiang, J. Jiang, Cost-sensitive ensemble of support vectormachines for effective detection of microcalcification in breast cancerdiagnosis,Jin (Eds.), Fuzzy Systems and KnowledgeDiscovery, Lecture Notes in Computer Science, vol. 3614, Springer, Berlin/Heidelberg, 2005, pp. 483–493.in: L. Wang, Y.[79] K. Jackowski, B. Krawczyk, M. Woniak, Cost-sensitive splitting and selectionmethod for medical decision support system, in: H. Yin, J.A. Costa, G. Barreto(Eds.), Intelligent Data Engineering and Automated Learning – IDEAL 2012,Lecture Notes in Computer Science, vol. 7435, Springer, Berlin Heidelberg,2012, pp. 850–857.[80] W. Du, Z. Zhan, Building decision tree classifier on private data,in:Proceedings of the IEEE International Conference on Privacy, Security andData Mining – Volume 14, CRPIT ’14, Australian Computer Society, Inc.,Darlinghurst, Australia, 2002, pp. 1–8.[81] B. Krawczyk, M. Wozniak, Privacy preserving models of k-NN algorithm, in:R. Burduk, M. Kurzynski, M. Wozniak, A. Zolnierek (Eds.), ComputerRecognition Systems 4, Advances in Intelligent and Soft Computing, vol. 95,Springer, Berlin/Heidelberg, 2011, pp. 207–217.[82] Y. Lindell, B. Pinkas, Secure multiparty computation for privacy-preservingdata mining, IACR Cryptology ePrint Archive 2008 (2008) 197.[83] K. Walkowiak, S. Sztajer, M. Wozniak, Decentralized distributed computingsystem for privacy-preserving combined classifiers – modeling andoptimization, in: B. Murgante, O. Gervasi, A. Iglesias, D. Taniar, B. Apduhan(Eds.), Computational Science and Its Applications – ICCSA 2011, LectureNotes in Computer Science, Vol. 6782, Springer, Berlin/Heidelberg, 2011, pp.512–525.[84] A. Pavlo, E. Paulson, A. Rasin, D. Abadi, D. DeWitt, S. Madden, M. Stonebraker,A comparison of approaches to large-scale data analysis, in: Proceedings ofthe 2009 ACM SIGMOD International Conference on Management of Data,SIGMOD ’09, ACM, New York, NY, USA, 2009, pp. 165–178.M. Woz´niak et al. / Information Fusion 16 (2014) 3–1715[85] R.E. Schapire, The boosting approach to machine learning: an overview, in:MSRI Workshop on Nonlinear Estimation and Classification, Berkeley, CA,USA, 2001.[86] T. Ho, Random decision forests, in: Proceedings of the Third InternationalConference on Document Analysis and Recognition (Volume 1)–Volume 1,ICDAR ’95, IEEE Computer Society, Washington, DC, USA, 1995, pp. 278–.[87] T. Ho, The random subspace method for constructing decision forests, IEEETransactions on Pattern Analysis and Machine Intelligence 20 (1998) 832–844.[88] L. Breiman, Random forests, Machine Learning 45 (1) (2001) 5–32.[89] M. Skurichina, R. Duin, Bagging, boosting and the random subspace methodfor linear classifiers, Pattern Analysis and Applications 5 (2) (2002) 121–135.[90] G. Tremblay, R. Sabourin, P. Maupin, Optimizing nearest neighbour in randomsubspaces using a multi-objective genetic algorithm, in: Proceedings of thePattern Recognition, 17th International Conference on (ICPR’04) Volume 1–Volume 01, ICPR ’04, IEEE Computer Society, Washington, DC, USA, 2004, pp.208–.[91] S. Bay, Nearest neighbor classification from multiple feature subsets,Intelligent Data Analysis 3 (3) (1999) 191–209.[92] L. Nanni, Letters: Experimental comparison of one-class classifiers for onlinesignature verification, Neurocomputing 69 (7–9) (2006) 869–873.[93] D. Tao, X. Tang, X. Li, X. Wu, Asymmetric bagging and random subspace forsupport vector machines-based relevance feedback in image retrieval, IEEETransactions on Pattern Analysis Machine Intelligence 28 (7) (2006) 1088–1099.[94] K. Ting, J. Wells, S. Tan, S. Teng, G. Webb, Feature-subspace aggregating:ensembles for stable and unstable learners, Machine Learning 82 (2011) 375–397.[95] R. Bryll, R. Gutierrez-Osuna, F. Quek, Attribute bagging: improving accuracyof classifier ensembles by using random feature subsets, Pattern Recognition36 (6) (2003) 1291–1302.[96] Y. Baram, Partial classification: the benefit of deferred decision,IEEETransactions on Pattern Analysis and Machine Intelligence 20 (8) (1998)769–776.[97] L. Cordella, P. Foggia, C. Sansone, F. Tortorella, M. Vento, A cascaded multipleexpert system for verification, in: Multiple Classifier Systems, Lecture Notesin Computer Science, vol. 1857, Springer, Berlin/Heidelberg, 2000, pp. 330–339.[98] K. Goebel, W. Yan, Choosing classifiers for decision fusion, in: Proceedings ofthe Seventh International Conference on Information Fusion, 2004, pp. 563–568.[99] B. Baruque, S. Porras, E. Corchado, Hybrid classification ensemble usingtopology-preserving clustering, New Generation Computing 29 (2011) 329–344.[100] L. Kuncheva, Clustering-and-selection model for classifier combination, in:Proceedings of the Fourth International Conference on Knowledge-BasedIntelligent Engineering Systems and Allied Technologies, 2000, vol. 1, 2000,pp. 185–188.[101] K. Jackowski, M. Wozniak, Algorithm of designing compound recognitionsystem on the basis of combining classifiers with simultaneous splittingfeature space into competence areas, Pattern Analysis and Applications 12 (4)(2009) 415–425.[102] M. Wozniak, B. Krawczyk, Combined classifier based on feature spacepartitioning, International Journal of Applied Mathematics and ComputerSciences 22 (4) (2012) 855–866.[103] H. Lee, C. Chen, J. Chen, Y. Jou, An efficient fuzzy classifier with featureselection based on fuzzy entropy, IEEE Transactions on Systems, Man, andCybernetics, Part B: Cybernetics 31 (3) (2001) 426–432.[104] J. Hong, J. Min, U. Cho, S. Cho, Fingerprint classification using one-vs-allsupport vector machines dynamically ordered with naïve bayes classifiers,Pattern Recognition 41 (2008) 662–671.[105] A.R. Ko, R. Sabourin, A. Britto, From dynamic classifier selection to dynamicensemble selection, Pattern Recognition 41 (5) (2008) 1735–1748.[106] L. Didaci, G. Giacinto, F. Roli, G. Marcialis, A study on the performances ofdynamic classifier selection based on local accuracy estimation, PatternRecognition 38 (11) (2005) 2188–2191.Conference on Knowledge Discovery and Data Mining, KDD ’03, ACM, NewYork, NY, USA, 2003, pp. 226–235.[113] Y. Zhang, X. Jin, An automatic construction and organization strategy forensemble learning on data streams, SIGMOD Record 35 (3) (2006) 28–33.[114] J. Kolter, M. Maloof, Dynamic weighted majority: a new ensemble method fortracking concept drift, in: ICDM 2003, Third IEEE International Conference onData Mining, 2003, 2003, pp. 123–130.[115] A. Tsymbal, M. Pechenizkiy, P. Cunningham, S. Puuronen, Dynamicintegration of classifiers for handling concept drift, Information Fusion 9(1) (2008) 56–68.[116] X. Zhu, X. Wu, Y. Yang, Effective classification of noisy data streams withattribute-oriented dynamic classifier selection, Knowledge InformationSystems 9 (3) (2006) 339–363.[117] D. Tax, R. Duin, Using two-class classifiers for multiclass classification, in:Proceedings of the 16th International Conference on Pattern Recognition,2002, vol. 2, 2002, pp. 124 –127.[118] T. Dietterich, G. Bakiri, Solving multiclass learning problems via error-correcting output codes, Journal of Artificial Intelligence Research 2 (1995)263–286.[119] K. Duan, S. Keerthi, W. Chu, S. Shevade, A. Poo, Multi-category classificationby soft-max combination of binary classifiers, in: Proceedings of the 4thInternational Conference on Multiple Classifier Systems, MCS’03, Springer-Verlag, Berlin, Heidelberg, 2003, pp. 125–134.[120] A. Passerini, M. Pontil, P. Frasconi, New results on error correcting outputcodes of kernel machines, IEEE Transactions on Neural Networks 15 (1)(2004) 45–54.[121] T. Wu, C. Lin, R. Weng, Probability estimates for multi-class classification bypairwise coupling, Journal of Machine Learning Research 5 (2004) 975–1005.[122] J. Friedman, Another Approach to Polychotomous Classification, Tech. rep.,Department of Statistics, Stanford University, 1996.[123] E. Hüllermeier,in pairwiseclassification: an optimal adaptive voting strategy and its relation toweighted voting, Pattern Recognition 43 (1) (2010) 128–142.S. Vanderlooy, Combining predictions[124] M. Galar, A. Fernandez, E. Barrenechea, H. Bustince, F. Herrera, An overview ofin multi-class problems:for binary classifiersschemes, Patternstudy on one-vs-one and one-vs-allensemble methodsExperimentalRecognition 44 (8) (2011) 1761–1776.[125] D. Tax, R.P.W. Duin, Characterizing one-class datasets, in: Proceedings of theSixteenth Annual Symposium of the Pattern Recognition Association of SouthAfrica, 2005, pp. 21–26.[126] D. Tax, R. Duin, Combining one-class classifiers, in: Proceedings of the SecondInternational Workshop on Multiple Classifier Systems, MCS ’01, Springer-Verlag, London, UK, 2001, pp. 299–308.[127] T. Wilk, M. Wozniak, Soft computing methods applied to combination of one-class classifiers, Neurocomputing 75 (2012) 185–193.[128] G. Giacinto, R. Perdisci, M. Del Rio, F. Roli, Intrusion detection in computernetworks by a modular ensemble of one-class classifiers, Information Fusion9 (2008) 69–82.[129] Y. Hu, Handbook of Neural Network Signal Processing, 1st ed., CRC Press, Inc.,Boca Raton, FL, USA, 2000.[130] K. Woods, W.P. Kegelmeyer Jr., K. Bowyer, Combination of multiple classifiersusing local accuracy estimates, IEEE Transactions on Pattern Analysis andMachine Intelligence 19 (4) (1997) 405–410.[131] M. Wozniak, M. Zmyslony, Combining classifiers using trained fuser –analytical and experimental results, Neural Network World 13 (7) (2010)925–934.[132] S. Raudys, Trainable fusion rules. I. Large sample size case, Neural Networks19 (10) (2006) 1506–1516.[133] M. van Erp, L. Vuurpijl, L. Schomaker, An overview and comparison of votingmethods for pattern recognition, in: Proceedings of the Eighth InternationalWorkshop on Frontiers in Handwriting Recognition, 2002, 2002, pp. 195–200.[134] M. Wozniak, K. Jackowski, Some remarks on chosen methods of classifierfusion based on weighted voting, in: E. Corchado, X. Wu, E. Oja, A. Herrero, B.Baruque (Eds.), Hybrid ArtificialIntelligence Systems, Lecture Notes inComputer Science, vol. 5572, Springer, Berlin/Heidelberg, 2009, pp. 541–548.II. Small sample-size effects, Neural[135] S. Raudys, Trainable fusion rules.[107] G. Giacinto, F. Roli, Dynamic classifier selection based on multiple classifierNetworks 19 (10) (2006) 1517–1527.behavior, Pattern Recognition 34 (9) (2001) 1879–1881.[108] M. de Souto, R. Soares, A. Santana, A. Canuto, Empirical comparison ofdynamic classifier selection methods based on diversity and accuracy forbuilding ensembles, in: IJCNN 2008, IEEE International Joint Conference onNeural Networks, 2008, IEEE World Congress on Computational Intelligence,2008, pp. 1480–1487.[136] H. Inoue, H. Narihisa, Optimizing a multiple classifier system, in: M. Ishizuka,A. Sattar (Eds.), PRICAI 2002: Trends in Artificial Intelligence, Lecture Notes inComputer Science, vol. 2417, Springer, Berlin/Heidelberg, 2002, pp. 1–16.[137] L. Alexandre, A. Campilho, M. Kamel, Combining independent and unbiasedclassifiers using weighted average., in: Proceedings ICPR 2000, 2000, pp.2495–2498.[109] T. Woloszynski, M. Kurzynski, A probabilistic model of classifier competencefor dynamic ensemble selection, Pattern Recognition 44 (1011) (2011) 2656–2668.[138] B. Biggio, G. Fumera, F. Roli, Bayesian analysis of linear combiners, in:Proceedings of the 7th International Conference on Multiple ClassifierSystems, MCS ’07, Springer-Verlag, Berlin, Heidelberg, 2007, pp. 292–301.[110] T. Woloszynski, M. Kurzynski, P. Podsiadlo, G. Stachowiak, A measure ofcompetence based on random classification for dynamic ensemble selection,Information Fusion 13 (3) (2012) 207–213.[111] W. Street, Y. Kim, A streaming ensemble algorithm (sea) for large-scaleclassification, in: Proceedings of the Seventh ACM SIGKDD InternationalConference on Knowledge Discovery and Data Mining, KDD ’01, ACM, NewYork, NY, USA, 2001, pp. 377–382.[112] H. Wang, W. Fan, P. Yu, J. Han, Mining concept-drifting data streams usingensemble classifiers, in: Proceedings of the Ninth ACM SIGKDD International[139] J. Kittler, F. Alkoot, Sum versus vote fusion in multiple classifier systems, IEEETransactions on Pattern Analysis and Machine Intelligence 25 (1) (2003)110–115.[140] N. Rao, A generic sensor fusion problem: classification and functionestimation,J. Kittler, T. Windeatt (Eds.), Multiple ClassifierSystems, Lecture Notes in Computer Science, vol. 3077, Springer, 2004, pp.16–30.in: F. Roli,[141] D. Opitz, J. Shavlik, Generating accurate and diverse members of a neural-network ensemble, in: NIPS, 1995, pp. 535–541.16M. Woz´niak et al. / Information Fusion 16 (2014) 3–17[142] L. Rokach, O. Maimon, Feature set decomposition for decision trees,Intelligent Data Analysis 9 (2) (2005) 131–158.[143] G. Fumera, F. Roli, A theoretical and experimental analysis oflinearcombiners for multiple classifier systems,IEEE Transactions on PatternAnalysis and Machine Intelligence 27 (6) (2005) 942–956, http://dx.doi.org/10.1109/TPAMI.2005.109.[144] M. Wozniak, Experiments on linear combiners, in: E. Pietka, J. Kawa (Eds.),Information Technologies in Biomedicine, Advances in Soft Computing, vol.47, Springer, Berlin/Heidelberg, 2008, pp. 445–452.[145] R. Duin, The combining classifier: to train or not to train? in: Proceedings ofthe 16th International Conference on Pattern Recognition, 2002, vol. 2, 2002,pp. 765–770.[146] R. Jacobs, M. Jordan, S. Nowlan, G. Hinton, Adaptive mixtures of local experts,Neural Computation 3 (1991) 79–87.[147] R. Jacobs, Methods for combining experts’ probability assessments, NeuralComputation 7 (5) (1995) 867–888.[148] V. Tresp, M. Taniguchi, Combining estimators using non-constant weightingfunctions, Advances in Neural Information Processing Systems, vol. 7, MITPress, 1995, pp. 419–426.[149] P. Cheeseman, M. Self, J. Kelly, J. Stutz, W. Taylor, D. Freeman, AutoClass: aBayesian classification system, in: Machine Learning: Proceedings of the FifthInternational Workshop, Morgan Kaufman, 1988.[150] S. Shlien, Multiple binary decision tree classifiers, Pattern Recognition 23 (7)(1990) 757–763.[151] M. Wozniak, Experiments with trained and untrained fusers, in: E. Corchado,J. Corchado, A. Abraham (Eds.), Innovations in Hybrid Intelligent Systems,Advances in Soft Computing, vol. 44, Springer, Berlin/Heidelberg, 2007, pp.144–150.[152] M. Wozniak, Evolutionary approach to produce classifier ensemble based onweighted voting, in: NaBIC 2009, World Congress on Nature & BiologicallyInspired Computing, 2009, IEEE, 2009, pp. 648–653.[153] L. Lin, X. Wang, B. Liu, Combining multiple classifiers based on statisticalmethod for handwritten chinese character recognition, in: Proceedings of the2002 International Conference on Machine Learning and Cybernetics, 2002,vol. 1, 2002, pp. 252–255.[154] Z. Zheng, B. Padmanabhan, Constructing ensembles from data envelopmentanalysis, INFORMS Journal on Computing 19 (4) (2007) 486–496.[155] D. Wolpert, Stacked generalization, Neural Networks 5 (1992) 241–259.[156] Y. Huang, C. Suen, A method of combining multiple experts for therecognition of unconstrained handwritten numerals, IEEE Transactions onPattern Analysis and Machine Intelligence 17 (1) (1995) 90–94.[157] M.M. Gaber, A. Zaslavsky, S. Krishnaswamy, Mining data streams: a review,SIGMOD Record 34 (2) (2005) 18–26.[158] A. Patcha, J.-M. Park, An overview of anomaly detection techniques: existingsolutions and latest technological trends, Computer Network 51 (12) (2007)3448–3470.[159] M.M. Black, R.J. Hickey, Classification of customer call data in the presence ofconcept drift and noise, in: Proceedings of the First International Conferenceon Computing in an Imperfect World, Soft-Ware 2002, Springer-Verlag,London, UK, 2002, pp. 74–87.[160] H. Wang, W. Fan, P.S. Yu, J. Han, Mining concept-drifting data streams usingensemble classifiers, in: Proceedings of the Ninth ACM SIGKDD InternationalConference on Knowledge Discovery and Data Mining, KDD ’03, ACM, NewYork, NY, USA, 2003, pp. 226–235.[161] M.M. Gaber, P.S. Yu, Classification of changes in evolving data streams usingonline clustering result deviation, in: Proc. Of International Workshop onKnowledge Discovery in Data Streams, 2006.[171] J. Peters, N. Verhoest, R. Samson, M. Meirvenne, L. Cockx, B. Baets,Uncertainty propagation in vegetation distribution models based onensemble classifiers, Ecological Modelling 220 (6) (2009) 791–804.[172] M. Han, X. Zhu, W. Yao, Remote sensing image classification based on neuralnetwork ensemble algorithm, Neurocomputing 78 (1) (2012) 133–138.[173] B. Waske, M. Braun, Classifier ensembles for land cover mapping usingmultitemporal SAR imagery, ISPRS Journal of Photogrammetry and RemoteSensing 64 (5) (2009) 450–457 (theme Issue: Mapping with SAR: Techniquesand Applications).[174] B. Waske, S. van der Linden, C. Oldenburg, B. Jakimow, A. Rabe, P. Hostert,imageRF – a user-oriented implementation for remote sensing image analysiswith random forests, Environmental Modelling & Software 35 (0) (2012)192–193.[175] U. Maulik, D. Chakraborty, A self-trained ensemble with semisupervisedSVM: an application to pixel classification of remote sensing imagery, PatternRecognition 44 (3) (2011) 615–623.[176] A. Henriques, A. Doria-Neto, R. Amaral, Classification of multispectral imagesensembles,environmentsclassifierofin coralhybridNeurocomputing 73 (7–9) (2010) 1256–1264.usinga[177] Y. Maghsoudi, M. Collins, D. Leckie, Polarimetric classification of boreal forestusing nonparametric feature selection and multiple classifiers, InternationalJournal of Applied Earth Observation and Geoinformation 19 (0) (2012) 139–150.[178] L. Bruzzone, R. Cossu, G. Vernazza, Combining parametric and non-for a partially unsupervised classification ofInformation Fusion 3 (4) (2002)parametric algorithmsmultitemporal remote-sensing images,289–297.[179] L. Bruzzone, R. Cossu, G. Vernazza, Detection of land-cover transitions bycombining multidate classifiers, Pattern Recognition Letters 25 (13) (2004)1491–1500.[180] P. Du, S. Liu, J. Xia, Y. Zhao, Information fusion techniques for changedetection from multi-temporal remote sensing images, Information Fusion14 (1) (2013) 19–27.[181] P. Arun-Raj-Kumar, S. Selvakumar, Distributed denial of service attackComputerclassifier,neuralofdetectionanCommunications 34 (11) (2011) 1328–1341.ensembleusing[182] P. Kumar, S. Selvakumar, Detection of distributed denial of service attacksusing an ensemble of adaptive and hybrid neuro-fuzzy systems, ComputerCommunications (0) (2012).[183] A. Shabtai, R. Moskovitch, Y. Elovici, C. Glezer, Detection of malicious code byapplying machine learning classifiers on static features: a state-of-the-artsurvey, Information Security Technical Report 14 (1) (2009) 16–29.[184] M. Locasto, K. Wang, A. Keromytis, S. Stolfo, Flips: hybrid adaptive intrusionprevention, in: Proceedings of the 8th International Conference on RecentAdvancesSpringer-Verlag, Berlin,Heidelberg, 2006, pp. 82–101.in Intrusion Detection, RAID’05,[185] K. Wang, G. Cretu, S. Stolfo, Anomalous payload-based worm detection andsignature generation, in: Proceedings of the 8th International Conference onRecent Advances in Intrusion Detection, RAID’05, Springer-Verlag, Berlin,Heidelberg, 2006, pp. 227–246.[186] S. Peddabachigari, A. Abraham, C. Grosan, J. Thomas, Modeling intrusiondetection system using hybrid intelligent systems, Journal of Network andComputer Applications 30 (1) (2007) 114–132.[187] D.-I. Curiac, C. Volosencu, Ensemble based sensing anomaly detection inwireless sensor networks, Expert Systems with Applications 39 (10) (2012)9087–9096.[188] R.J. Bolton, D.J. Hand, Statistical fraud detection: a review, Statistical Science[162] M. Markou, S. Singh, Novelty detection: a review – Part 1: Statistical17 (3) (2002) 235–255.approaches, Signal Process 83 (12) (2003) 2481–2497.[163] M. Salganicoff, Density-adaptive learning and forgetting,in: MachineLearning: Proceedings of the Tenth Annual Conference, Morgan Kaufmann,San Francisco, CA, 1993.[164] R. Klinkenberg, T. Joachims, Detecting concept drift with support vectormachines, in: Proceedings of the Seventeenth International Conference onMachine Learning, ICML ’00, Morgan Kaufmann Publishers Inc., San Francisco,CA, USA, 2000, pp. 487–494.[165] M. Baena-Garcı´ a, J. del Campo-Ávila, R. Fidalgo, A. Bifet, R. Gavaldá, R.in: Fourth InternationalMorales-Bueno, Early drift detection method,Workshop on Knowledge Discovery from Data Streams, 2006.[166] I. Zliobaite, Change with delayed labeling: when is it detectable?,in:Proceedings of the 2010 IEEE International Conference on Data MiningWorkshops, ICD-MW ’10, IEEE Computer Society, Washington, DC, USA, 2010,pp 843–850.[167] G. Giacinto, F. Roli, L. Bruzzone, Combination of neural and statisticalalgorithms for supervised classification of remote-sensing images, PatternRecognition Letters 21 (5) (2000) 385–397.[168] V. Rodriguez-Galiano, B. Ghimire, J. Rogan, M. Chica-Olmo, J. Rigol-Sanchez,An assessment of the effectiveness of a random forest classifier for land-coverclassification, ISPRS Journal of Photogrammetry and Remote Sensing 67 (0)(2012) 93–104.[169] P. Gislason, J. Benediktsson, J. Sveinsson, Random forests for land coverclassification, Pattern Recognition Letters 27 (4) (2006) 294–300.[170] J.-W. Chan, D. Paelinckx, Evaluation of random forest and Adaboost tree-based ensemble classification and spectral band selection for ecotopeimagery, Remote Sensing ofmapping using airborne hyperspectralEnvironment 112 (6) (2008) 2999–3011.[189] F. Louzada, A. Ara, Bagging k-dependence probabilistic networks: analternative powerful fraud detection tool, Expert Systems with Applications39 (14) (2012) 11583–11592.[190] S. Bhattacharyya, S. Jha, K. Tharakunnel, J. Westland, Data mining for creditcard fraud: a comparative study, Decision Support Systems 50 (3) (2011)602–613.[191] L. Yu, W. Yue, S. Wang, K. Lai, Support vector machine based multiagentrisk evaluation, Expert Systems withensemble learning for creditApplications 37 (2) (2010) 1351–1360.[192] Y. Kim, S. Sohn, Stock fraud detection using peer group analysis, ExpertSystems with Applications 39 (10) (2012) 8986–8992.[193] B. Twala, Multiple classifier application to credit risk assessment, ExpertSystems with Applications 37 (4) (2010) 3326–3336.[194] S. Finlay, Multiple classifier architectures and their application to credit riskassessment, European Journal of Operational Research 210 (2) (2011) 368–378.[195] G. Wang, J. Ma, A hybrid ensemble approach for enterprise credit riskassessment based on support vector machine, Expert Systems withApplications 39 (5) (2012) 5325–5331.[196] M. Kim, D. Kang, Classifiers selection in ensembles using genetic algorithmsfor bankruptcy prediction, Expert Systems with Applications 39 (10) (2012)9308–9314.[197] P. Ravisankar, V. Ravi, I. Bose, Failure prediction of dotcom companies usingneural network–genetic programming hybrids, Information Sciences 180 (8)(2010) 1257–1267.[198] P. Ravisankar, V. Ravi, G. Rao, I. Bose, Detection of financial statement fraudand feature selection using data mining techniques, Decision SupportSystems 50 (2) (2011) 491–500.M. Woz´niak et al. / Information Fusion 16 (2014) 3–1717[199] C. Tsai, Combining cluster analysis with classifier ensembles to predictfinancial distress, Information Fusion (0) (2011).[200] Y. Peng, G. Wang, G. Kou, Y. Shi, An empirical study of classification algorithmevaluation for financial risk prediction, Applied Soft Computing 11 (2) (2011)2906–2915.[201] V. Ravi, H. Kurniawan, P. Nwee-Kok-Thai, P. Ravi-Kumar, Soft computingsystem for bank performance prediction, Applied Soft Computing 8 (1) (2008)305–315.[202] H. Zhao, A. Sinha, W. Ge, Effects of feature construction on classificationperformance: an empirical study in bank failure prediction, Expert Systemswith Applications 36 (2, Part 2) (2009) 2633–2644.[203] K. Aral, H. Guvenir, I. Sabuncuoglu, A. Akar, A prescription fraud detectionmodel, Computer Methods and Programs in Biomedicine 106 (1) (2012) 37–46.[204] I. Christou, M. Bakopoulos, T. Dimitriou, E. Amolochitis, S. Tsekeridou, C.Dimitriadis, Detecting fraud in online games of chance and lotteries, ExpertSystems with Applications 38 (10) (2011) 13158–13169.[205] H. Farvaresh, M. Sepehri, A data mining framework for detecting subscriptionEngineering Applications of Artificialfraud in telecommunication,Intelligence 24 (1) (2011) 182–194.[206] L. Subelj, S. Furlan, M. Bajec, An expert system for detecting automobileinsurance fraud using social network analysis, Expert Systems withApplications 38 (1) (2011) 1039–1052.[207] A.X. Garg, N.K.J. Adhikari, H. McDonald, M.P. Rosas-Arellano, P.J. Devereaux, J.Beyene, J. Sam, R.B. Haynes, Effects of computerized clinical decision supportsystems on practitioner performance and patient outcomes: a systematicreview, Journal of the American Medical Association 293 (10) (2005) 1223–1238.[208] J. Eom, S. Kim, B. Zhang, AptaCDSS-E: a classifier ensemble-based clinicaldecision support system for cardiovascular disease level prediction, ExpertSystems with Applications 34 (4) (2008) 2465–2479.[209] R. Das, I. Turkoglu, A. Sengur, Effective diagnosis of heart disease throughneural networks ensembles, Expert Systems with Applications 36 (4) (2009)7675–7680.[210] R. Das, I. Turkoglu, A. Sengur, Diagnosis of valvular heart disease throughinensembles, Computer Methodsand Programsneural networksBiomedicine 93 (2) (2009) 185–191.[215] A. Savio, M. Garcia-Sebastian, D. Chyzyk, C. Hernandez, M. Graña, A. Sistiaga,A.L. de Munain, J. Villanua, Neurocognitive disorder detection based onfeature vectors extracted from VBM analysis of structural MRI, Computers inBiology and Medicine 41 (8) (2011) 600–610.[216] D. Chyzhyk, M. Graña, A. Savio, J. Maiora, Hybrid dendritic computing withkernel-LICA applied to alzheimer’s disease detection in MRI, Neurocomputing75 (1) (2012) 72–77.[217] L. Kuncheva, J. Rodriguez, Classifier ensembles for fMRI data analysis: anexperiment, Magnetic Resonance Imaging 28 (4) (2010) 583–593.[218] C. Plumpton, L. Kuncheva, N. Oosterhof, S. Johnston, Naive random subspaceensemble with linear classifiers for real-time classification of fMRI data,Pattern Recognition 45 (6) (2012) 2101–2108.[219] C. Cabral, M. Silveira, P. Figueiredo, Decoding visual brain states from fMRIusing an ensemble of classifiers, Pattern Recognition 45 (6) (2012) 2064–2074.[220] G. Adomavicius, R. Sankaranarayanan, S. Sen, A. Tuzhilin, Incorporatingcontextual information in recommender systems using a multidimensionalapproach, ACM Transactions Information Systems 23 (1) (2005) 103–145.[221] J. Konstan, J. Riedl, How online merchants predict your preferences and prodyou to purchase, IEEE Spectrum 49 (10) (2012) 48–56.[222] R. Burke, Hybrid recommender systems: survey and experiments, UserModeling and User-Adapted Interaction 12 (4) (2002) 331–370.[223] M.Balabanovic´ ,Y.Shoham,Fab:content-based,collaborativerecommendation, Communications of the ACM 40 (3) (1997) 66–72.[224] M.J. Pazzani, A framework for collaborative, content-based and demographicfiltering, Artificial Intelligence Review 13 (5–6) (1999) 393–408.[225] M. Jahrer, A. Töscher, R. Legenstein, Combining predictions for accuratethe 16th ACM SIGKDDrecommenderInternational Conference on Knowledge Discovery and Data Mining, KDD’10, ACM, New York, NY, USA, 2010, pp. 693–702.in: Proceedings ofsystems,[226] C. Porcel, A. Tejeda-Lorente, M. Martı´ nez, E. Herrera-Viedma, A hybridrecommender system for the selective dissemination of research resources ina technology transfer office, Information Sciences 184 (1) (2012) 1–19.[227] M. Claypool, A. Gokhale, T. Miranda, P. Murnikov, D. Netes, M. Sartin,Combining content-based and collaborative filters in an online newspaper,in: Proceedings of the ACM SIGIR ’99 Workshop on Recommender Systems:Algorithms and Evaluation, ACM, 1999.[211] W. Baxt,Improving the accuracy of an artificial neural network usingmultiple differently trained networks, Neural Computation 4 (5) (1992) 772–780.[212] X. Zhang, J. Mesirov, D. Waltz, Hybrid system for protein secondary structureprediction, Journal of Molecular Biology 225 (4) (1992) 1049–1063.[228] D. Billsus, M. Pazzani, User modeling for adaptive news access, User Modelingand User-Adapted Interaction 10 (2–3) (2000) 147–180.[229] T. Tran, R. Cohen, Hybrid recommender systems for electronic commerce, in:Knowledge-Based Electronic Markets, Papers from the AAAI Workshop, AAAITechnical Report WS-00-04, AAAI Press, Menlo Park, CA, 2000, pp. 78–83.[213] L. Nanni,classifiersNeurocomputing 69 (7) (2006) 850–853.Ensembleof[214] T. Yang, V. Kecman, L. Cao, C. Zhang, J.Z. Huang, Margin-based ensembleclassifier for protein fold recognition, Expert Systems with Applications 38(10) (2011) 12348–12355.collaborative recommenderElectronics and Communications 61 (7) (2007) 433–443.systems, AEU – InternationalJ. Tasic, Optimisation of combinedJournal of[231] M. Goksedef, S. Gundoz-Oguducu, Combination of web page recommendersystems, Expert Systems with Applications 37 (4) (2010) 2911–2922.forproteinfoldrecognition,[230] M. Kunaver, T. Pozrl, M. Pogacnik,