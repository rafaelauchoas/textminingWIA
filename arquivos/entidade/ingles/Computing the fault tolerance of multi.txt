Artificial Intelligence 173 (2009) 437–465Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComputing the fault tolerance of multi-agent deployment ✩Yingqian Zhang a,∗, Efrat Manisterski b, Sarit Kraus b,c, V.S. Subrahmanian c, David Peleg da Faculty of Electrical Engineering, Mathematics, and Computer Science, Delft University of Technology, 2628 CD Delft, The Netherlandsb Department of Computer Science, Bar-Ilan University, Ramat Gan, 52900 Israelc Department of Computer Science & UMIACS, University of Maryland, College Park, MD 20742, USAd Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot 76100, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 11 June 2007Received in revised form 12 November 2008Accepted 14 November 2008Available online 25 November 2008Keywords:Multi-agent deploymentFault toleranceAlgorithmsReplicationA deployment of a multi-agent system on a network refers to the placement of oneor more copies of each agent on network hosts, in such a manner that the memoryconstraints of each node are satisfied. Finding the deployment that is most likely totolerate faults (i.e. have at least one copy of each agent functioning and in communicationwith other agents) is a challenge.In this paper, we address the problem of findingthe probability of survival of a deployment (i.e. the probability that a deployment willtolerate faults), under the assumption that node failures are independent. We show thatthe problem of computing the survival probability of a deployment is at least NP-hard.Moreover, it is hard to approximate. We produce two algorithms to accurately compute theprobability of survival of a deployment—these algorithms are expectedly exponential. Wealso produce five heuristic algorithms to estimate survival probabilities—these algorithmswork in acceptable time frames. We report on a detailed set of experiments to determinethe conditions under which some of these algorithms perform better than the others.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThere have been tremendous advances in the last decade in the theory and implementation of massive multi-agent sys-tems. However, one major obstacle to the wider deployment of multi-agent systems (MASs) is their capability of toleratingfailures. MASs that are deployed across a network can quickly “go down” due to external factors such as power failures,network outages, malicious attacks, and other system issues. Protection against such unexpected failures that disable a nodeis critical if agents are to be used as the backbone for real world applications.Clearly, ensuring that MASs are safe and protected involves a vast range of technologies that must authenticate users andagents, ensure secure communications, identify vulnerabilities, and identify and quarantine attacks. Our goal in this paperis far more modest, and concerns the way replication can form the basis of one tool (amongst many that are needed) toprevent a MAS from succumbing to failure. By replicating agents, we hope to improve the fault tolerance of a multi-agentsystem. The faults considered in this paper are those that cause disconnection (or crash) of the nodes in the network where✩This article is the extended version of the paper which appeared in the Second IEEE Symposium on Multi-Agent Security and Survivability [Y. Zhang,E. Manister, S. Kraus, V.S. Subrahmanian, Approximation results for probabilistic survivability, in: Second IEEE Symposium on Multi-Agent Security andSurvivability, Philadelphia, USA, 2005, pp. 1–10]. This research was supported in part by the Technology Foundation STW, applied science division of NWO,and the Ministry of Economic Affairs of the Netherlands, by grant N6133906C0149, in part by ARO grant DAAD190310202, AFOSR grants FA95500610405,FA95500510298, NSF grant 0540216, NSF grant 0705587, and ISF grant 1685/07.* Corresponding author.E-mail addresses: yingqian.zhang@tudelft.nl (Y. Zhang), manister@macs.biu.ac.il (E. Manisterski), sarit@macs.biu.ac.il (S. Kraus), vs@cs.umd.edu(V.S. Subrahmanian), david.peleg@weizmann.ac.il (D. Peleg).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.11.007438Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465the MAS application resides. The fault model that we consider is one where the failure of each node in the network isrepresented by a probability. Given such a fault model, agents that locate on the nodes have different probabilities to beunavailable, and therefore the multi-agent system as a whole has some probability of being out of function. The idea ofusing replication as a fault tolerance method in our work is thus that, when facing failures, at least one copy of each agentwill continue to reside on a connected, working host computer (node), so that the MAS as a whole can function as a unifiedapplication. Furthermore, in this paper, we focus on the problem of measuring the probability that a multi-agent system willtolerate the node failure. We call this probability the survivability1 of a MAS system.For example, consider the CoAX [2,35] Coalition Agent Experiment in which a large, multinational team2 of universities,companies and government labs pieced together an experimental multi-agent application in which a set of sensory agentsdeployed in an ocean tracked enemy submarines. These sensory agents fed data to prediction agents that predicted when,where, and with what probability the submarine would be in a given location. Thereafter a whole set of decision making andvisualization agents assisted a decision maker in determining how best to proceed. All these agents were supported, in turn,by other agents such as agents assessing trustworthiness of a source, database agents, resource discovery agents, and thelike. In applications such as CoAX, it is quite likely that some nodes will “go down” or “get disconnected” from the network.Any enemy sophisticated enough to use jamming technology would also make efforts to jam the network, effectively causingsome agents to have no connectivity. Thus, critical agents such as the prediction agents and the decision making agents needto be appropriately located and replicated so that the whole multi-agent system has a high probability of functioning. Ofcourse, it is assumed that the physical hardware (sensors) are already replicated to support sensor failures—this paper doesnot address how to replicate physical devices.Likewise, consider the exhaustive set of deployed multi-agent applications listed in [36]. According to their description,Skoda—a branch of Volkswagen—deployed an agent based production planning tool for manufacturing car engines. Theirmulti-agent solution looked both at low level planning and high level planning. High levels plans are examined by a set oflow level planning agents that try to achieve a part of the high level plan and flag conflicts and inconsistencies in the highlevel plan. A back and forth process ensures, once a consensus is achieved, the production plans are sent to higher levelagents who use resource allocation mechanisms to execute these plans on the production line. It is clear that in criticalapplications such as these, any node “going down” (for whatever reason) has the potential to cause the production line tocome to a grinding halt, leading to a loss of revenue for the company.Tichy et al. [42] describe a multi-agent system for the control of several components of a ship so as to reduce man-power requirements, while still ensuring highly reliable and survivable operation of the ship. They develop a hierarchicalmulti-agent architecture in which agents are embedded within hardware controllers and higher level agents coordinate andmonitor the activities of groups of agent-enhanced hardware controllers. The agents are continuously engaged within a plancreation, plan commitment, and plan execution cycle. Here too, it is clear that when agents are in control of a physicalenvironment (the ship in this case) there is high potential that the overall environment being controlled by the MAS canbe adversely affected whenever an agent “goes down”. In any situation where hardware components exist (and certainly onships), there is a possibility that hardware components will fail—for simple reasons or for more complex reasons such asthe actual physical movement of the ship and/or the oceanographic and climactic conditions with which the ship is forcedto contend. Thus, mechanisms are needed so that MASs can be deployed in a survivable manner even if some agents godown. Furthermore, it is important to calculate the guaranteed probability that the system will survive.Fault tolerance and replication techniques have been extensively studied in distributed computing systems [4,10,20,31,43],but much less so in the multi-agent systems domain [5,16,29,33]. Building a fault tolerant distributed system is notoriouslyhard. The autonomy of agents in multi-agent systems such as CoAX makes this task even more difficult. In this paper, webuild upon the framework of [27], which defined the probability that a given deployment of a MAS3 will survive, consideredthe basic problem of deployment survivability, and proposed methods for finding most survival deployments. Zhang et al. [45]also consider the complexity of the problem of finding the most survivable deployment. That is, the complexity of finding thedeployment with the highest survival probability, given a MAS deployment.The model of [27] assumes ignorance about the dependencies between node failures. However, this assumption is notalways valid. For example, an attack on Cornell’s web site is—in all likelihood—independent of the Israeli Defence Ministry’sweb site going down. The framework proposed in [27] cannot handle this. The algorithm developed in [27] for finding themost survivable deployment of agents on the network only works under the ignorance assumption and has two components.The first component is an algorithm for solving the deployment survivability problem, i.e., computing the survival probabilityof a given deployment of the MAS, while the second component uses the first component to find the most survivabledeployment. The algorithm provided in [27] for the first problem is exponential, while the second is doubly exponential.In this paper, we only focus on the first problem, of deployment survivability; the algorithm for the second componentin [27] can be used directly. Moreover, instead of studying the problem under the assumption of ignorance, we assumeindependence between node failures.1 A more formal definition of survivability is given in Definition 4. See Section 6.2 for a discussion on different notations of the survivability.2 The team included companies such as Lockheed Martin, BBN, Qinetiq, as well as universities such as Univ. of Maryland, Univ. of Texas, Univ. of Edin-burgh, and many others.3 We will define deployment formally later in Definition 1. For now, a deployment is simply a function that associates with each node in the network, aset of agents to be placed on that node.Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465439The following contributions are included in this paper:(1) In Section 2, we provide an abstract formal model to study the survival probability of a given deployment under theassumption of independence of node failures. We further show that even assuming independence, the deployment surviv-(where |V | is theability problem is at least NP-hard. Moreover, it is also hard to approximate up to a factor of 2number of the nodes in the network).|V |1−(cid:2)(2) We show that the complexity of finding the most survivable deployment problem, even assuming independence, is atleast NP-hard. We also show that for any polynomial approximation to find a sub-optimal deployment, there will beinstances in which the survival probability of the most survival deployment is 1 but the algorithm returns a deploymentwith a survival probability of 0. Thus, any polynomial approximation algorithm is guaranteed to find at least one terriblesolution.(3) In Section 3, we introduce two centralized algorithms to accurately compute the probability that a given deploymentwill survive. Both algorithms take exponential time.(4) In Section 4, we develop five different approximation algorithms to compute the probability of survival of a givendeployment.(5) About half the paper (Section 5) is devoted to a detailed comparison of the performance of the different algorithmsproposed in this paper. These experiments try to identify the conditions under which one algorithm is preferable toanother so that MAS applications have some foundation upon which to base a decision about which algorithm to use.(6) Section 6 compares our algorithms with related work. We conclude by discussing the main strengths and weaknessesof the paper in Section 7.This paper is related to three prior papers of the authors. Kraus et al. [27], as mentioned above, develop the basic MASsurvivability upon which this paper is based, but do so in a setting where the relationship between failure of nodes is com-pletely unknown. It provides a centralized algorithm to find an optimal deployment (i.e. one that maximizes the probabilityof survival). Our subsequent paper [41] provides a protocol by which multiple agents can dynamically re-deploy across anetwork when information is received that one or more nodes have gone down. Both these papers provide algorithms to ac-tually find optimal and, when complexity does not allow so, suboptimal deployment (statically and in a centralized mannerin the first case, dynamically and in a distributed manner in the second). However, when finding an optimal deployment,a common problem in both cases is to find the probability of survival of a deployment. This is a precursor to finding thedeployment with the highest survival probability. It is also necessary when MAS is applied in mission critical domains. Thecomputed survival probability can be used, for example, in deciding on whether the system is safe enough, whether to addresources and whether it is necessary to look for a new deployment (in a dynamic environment). Zhang et al. [45] takes afirst step at addressing this problem. The problem presented in our work is a far more detailed and extended version of theproblem described in [45].2. An abstract probabilistic fault tolerance framework2.1. Survivability functionsConsider a multi-agent system M consisting of a finite set of agents providing one or more services. We are not con-cerned with the framework in which the agents in M are encoded. For example, they could be implemented within the BDIframework or within the IMPACT [40] or some other framework or in a mix of frameworks as was the case of CoAX [2,35].We also make no assumptions about the services provided by these agents, or the communication language they provide.We assume that M is deployed over a fully connected overlay network4 N = (V , V × V ), where V is the set of nodes in thenetwork. Since N is a fully connected network, for simplicity we denote it by its sets of vertices V . Each node n ∈ V hassome fixed amount of resources, denoted space(n), that it makes available to hosting agents in a given multi-agent system.Let space(a) denote the resource requirements of an agent a, and let space(M) =a∈M space(a). We define a deploymentw.r.t. M, V as follows.(cid:2)Definition 1 (Deployment μ). A deployment μ w.r.t. M, V is a mapping from V to 2such that μ(n) is the set ofagents in M that are deployed at node n in the network. The deployment μ must satisfy the resource constraint, namely,(cid:2)a∈μ(n) space(a) (cid:2) space(n) for each n ∈ V .We say that μ is a valid deployment w.r.t. M, V if for each a ∈ M there is a node n ∈ V such that a ∈ μ(n).MThroughout the rest of this paper, we assume that M is an arbitrary but fixed MAS and that V is an arbitrary but fixedset of nodes. As a consequence, we simply say “deployment μ” instead of “deployment μ w.r.t. M, V ”.4 This is a reasonable assumption as we do not require full connectivity of the underlying physical network (merely all nodes in the physical networkneed to be reachable—perhaps through multiple physical links—from all other nodes).440Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465Example 1. Consider a fully connected network with V = {n1, n2, n3} where space(n1) = 6 and space(n2) = space(n3) = 3,and a MAS M = {a1, a2, a3} where space(ai) = 4 − i for i = 1, 2, 3. A possible valid deployment μ is given by μ(n1) ={a1, a2, a3}, μ(n2) = {a1}, μ(n3) = {a2, a3}.In a network V , any node of V can “go down” or somehow get “disconnected” from the network. In this paper, we donot go into details on for example causes of failures, failure detection method or failure rate.5 Instead, we adopt an abstractrepresentation on the fault model that the multi-agent system will tolerant, i.e., we assume each node has some probabilityof being unavailable (or out of function), due to its disconnection (or crash) from the network. We define the probability ofbeing unavailable of a node by a disconnect probability function.Definition 2 (disconnect probability function dp). A disconnect probability function (dp for short) is a mapping of dp : V → [0, 1]that assigns the probability of being disconnected to each node n ∈ V .In the context of the CoAX application [2,35], the disconnect probability function specifies the probability that a nodewill somehow fall off the network—such a disconnect probability function might assign a high disconnect probability tosensory nodes deployed in the ocean, a lower disconnect probability to nodes in more secure locations in the area, and aneven lower disconnect probability to highly secure nodes back in the US or Europe. In the case of Tichy’s [42] application,the disconnect probabilities of agents embedded in a controller might be higher than higher level agents because of morefrequent failures of hardware components. The same may be the case with the Skoda application [36].It is important to note that the failure of a node can be permanent or temporary. Moreover, its disconnect probabilitydp(n) can be defined in terms of time. For example, we may have a family of auxiliary functions dpt(n) that assesses theprobability that node n will get disconnected in exactly t units of time. One may then derive dp(n) in many ways fromthese dpt(n) functions. For instance, dp(n) might be assumed to be the average of dpt(n)’s for t ranging from 0 to somefixed upper bound.It is also important to note that disconnect probabilities can be computed in many standard ways that are used innetworking. One way is through the use of round trip times (RTTs) used frequently in networking. RTTs describe the timerequired for a packet to go from one node to another. An RTT graph looks exactly like the network itself except that eachedge is labeled with the round trip time between the nodes in question. RTT(0) can be initialized in any number of ways(e.g. by setting all nodes to have some fixed probability of disconnect, or by assigning such probabilities based on some apriori knowledge of the network). If RTT(t) depicts the RTT graph for a given network at time t, we can compute disconnectprobabilities by identifying how RTT(t) differ from RTT(t − 1), RTT(t − 2), . . . , and so on. If a large proportion of edgesassociated with a node n have an increased RTT in RTT(t) as compared to RTT(t − 1), then the disconnect probability ofnode n increases.(cid:5)A future failure event F may cause the disconnection of a set of nodes V F . Such a failure event will give rise to the partialcan possiblyget disconnected). The, denoted by(cid:5) = V \ V F . Clearly, given the possibility of node disconnections, a partial network V(cid:5) ⊆ V (in case of a failure event F in which the nodes V F = V \ Vwill materialize is referred to as the occurrence probability of network V(cid:5)(cid:5)(cid:5)(cid:5), where Vnetwork Vmaterialize in the future for any Vprobability that the future network Vpoccur(V , V(cid:5), dp).6Consider a failure event F , and consider the deployment μ restricted to the future network Vμ still satisfies the resource constraint. However, the deployment μ may no longer be valid w.r.t. VM may not be deployed in any node of Vwe have the following definition.). We say that the future network V(cid:5) = V \ V F . Clearly,(i.e., some agents inis valid if this does not happen. Formally,for V(cid:5)(cid:5)(cid:5)(cid:5)Definition 3 (Valid future network). Given a deployment μ and a network V , a possible future network V i is valid if and onlyif μ is a valid deployment w.r.t. V i , i.e., for each agent a ∈ μ, {n | a ∈ μ(n)} ∩ V i (cid:8)= ∅.The set of possible valid future networks of a network V is defined by ValidV (μ) = {V i | V i ⊆ V and μ is valid withWe say that the system (M, V , dp, μ) survives the failure event F (where the set of nodes V F gets disconnected) if therespect to V i}.remaining V(cid:5) = V \ V F is a valid network.We are ready to define an abstract notion of the survivability function as given below.Definition 4 (Survivability function). Consider a fixed multi-agent system M and a network V . A survivability functionSF(M, V , dp, μ) maps a deployment μ and a disconnect probability function dp to the probability that the system(M, V , dp, μ) will survive. When M, V and dp are clear from the context, we may denote the survivability simply asSF(μ).5 See Section 6.4 for a more detailed discussion on the failure mode.6 Whenever V and dp are clear from the context, we denote the occurrence probability of V(cid:5)simply by poccur(V(cid:5)).The survival probability of μ is obtained by summing up the occurrence probabilities of all its possible valid futureY. Zhang et al. / Artificial Intelligence 173 (2009) 437–465441networks.SF(M, V , dp, μ) =(cid:3)V i ∈ValidV (μ)poccur(V , V i, dp).We call the survival probability of a given deployment μ, SF(μ), the survivability of deployment μ.(1)(cid:5)Kraus et al. [27] use a linear programming model to define the survival probability of a MAS under the ignorance as-sumption, i.e., assuming we are completely ignorant about node failure dependencies. However, this assumption may not bevalid for many multi-agent applications, where the hosts are geographically distributed, as there can be simple or complexdependencies (or independence) between failures of different hosts. For example, the failure of a node in Australia is likelyto be independent of the failure of a node in Maryland, in which case the independence assumption may be more appropri-ate than the ignorance assumption. In the case of the CoAX application, for example, if a node n goes down, the probabilitythat a node nare both in the area of the underwater sensorarray, then the failure of n is likely to be positively correlated with the failure of n. However, if n is in the region of theunderwater sensor array, and nis in the UK, the failures of these nodes will probably be independent. It is therefore ap-parent that there is a wide array of possible ways in which the failure of a node is related to the failure of another node.Likewise, in the case of the Skoda multi-agent application, it may well be the case that the failure of agents associated withplanning are independent of failures of agents associated with the monitoring and execution process as the latter are likelyto directly control (or sense) physical devices, while the former do not. The same could be the case for Tichy’s ship control[42] application.will go down depends on various factors. For instance, if n, n(cid:5)(cid:5)(cid:5)Kraus et al. [27] study one extreme—where there is complete ignorance of the relationship between node failures. Thisignorance assumption causes all survival probabilities to be extraordinarily pessimistic (low). In addition, they [27] showthat the most survivable deployment problem (namely, finding a deployment μ∗which maximizes SF(M, V , dp, μ) forgiven M, V , dp) is intractable under the ignorance assumption.Since there are many cases where the independence assumption is valid (as in the example mentioned above), through-out this paper, we develop the survivability algorithms under the following independent assumption:Assumption 1 (Failure independence assumption). Given a network V , node failures are independent of one another.Later in the paper, we will discuss how the techniques in this paper can be extended in order to remove the indepen-dence assumption.Example 2. Consider the network and deployment given in Example 1, and suppose the disconnect probability function dpis given by dp(n1) = 0.7, dp(n2) = 0.6, dp(n3) = 0.4. The possible valid future networks are V 1 = {n1}, V 2 = {n2, n3}, V 3 ={n1, n2, n3}, V 4 = {n1, n2}, V 5 = {n1, n3}. The occurrence probability of V 1 is poccur(V 1) = 0.3 · 0.6 · 0.4 = 0.072, and similarly,poccur(V 2) = 0.168, poccur(V 3) = 0.072, poccur(V 4) = 0.048 and poccur(V 5) = 0.108. The survivability of the deployment isgiven by SF(M, V , dp, μ) = 0.072 + 0.168 + 0.072 + 0.048 + 0.108 = 0.468.2.2. Complexity results for survivabilityIn this section, we investigate the complexity of the deployment survivability problem (namely, we compute the surviv-ability of a given MAS deployment) by replacing the ignorance assumption [27] with the failure independent Assumption 1.Given a network V , a multi-agent application M, a disconnect probability dp and a deployment μ, the occurrenceprobability of network V(cid:5)poccur(V , V(cid:5), dp) =(cid:6)(cid:5)1 − dp(np)·dp(nq).(under the independence assumption) can be calculated by the following equation:(cid:4)(cid:4)np ∈V (cid:5)nq∈V \V (cid:5)One might expect that the deployment survivability problem would be easier with the assumption of independence.However, the following result shows that this problem is at least NP-hard even under the independence assumption, and|V |1−(cid:2)moreover, it is also hard to approximate up to a factor of 2.Theorem 5. Computing the survivability SF(M, V , dp, μ) of a given deployment μ is at least NP-hard, and it is also hard to approxi-mate up to a factor of 2|V |1−(cid:2).Proof. By a reduction from the problem of finding the number of satisfying truth assignments of a given monotone CNFformula ϕ. An instance of this problem is a formula ϕ in (monotone) CNF form over K Boolean variables x1 . . . xK , namely,a conjunction of M clauses, ϕ = C1 ∩ · · · ∩ C M , where each clause Ci = (xi1 , . . . , xil ) is a disjunction of literals, and all literalsare nonnegated. Given such an instance ϕ, we create an instance of the deployment survivability problem as follows. Foreach clause C j we create an agent a j . For each logical variable xi we create a node ni . An agent a j is deployed on all nodes442Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465corresponding to literals that occur in C j , i.e., a j ∈ μ(ni) if xi appears in C j . The disconnect probability of each node n ∈ Vis set to dp(n) = 0.5.if and only if there are Z truth assignments of the (monotone) CNFIt is easy to see that the survivability of μ is Z /2formula ϕ.|V |It is well-known that counting the number of satisfying truth assignments of a given monotone CNF formula is NP-hard.It is even NP-hard to approximate this number up to a factor of 2K 1−(cid:2), where K is the number of variables. This is true evenif each clause of the formula contains two variables [38]. Consequently, the deployment survivability problem is NP-hard,. (cid:2)and it is also hard to approximate up to a factor of 2|V |1−(cid:2)Next we show that the most survivable deployment problem, namely, finding a deployment μ∗which maximizesSF(M, V , dp, μ) for given M, V , dp, is at least NP-hard. Consequently, it may be interesting to look for a polynomial timeheuristic algorithm that is guaranteed to output a deployment with a survival probability within (cid:2) of the optimal deploy-ment μ∗, for some (cid:2) > 0. Unfortunately, the following theorem also states that the best (cid:2) is 1 (under the assumption thatP (cid:8)= NP).Theorem 6. (1) Finding an optimal (most survival) deployment μ∗dence assumption.for a given M, V , dp is at least NP-hard even under the indepen-(2) If P (cid:8)= NP, then for every polynomial approximation to find a sub-optimal deployment there are instances in which the survivalprobability of μ∗is 1 but the algorithm returns a deployment with a survival probability of 0.Proof. It is suffice to prove claim (2), since claim (1) follows immediately from it. Suppose that claim (2) is false. Then apolynomial algorithm AL exists such that it always returns a deployment with a survival probability larger than 0, whenthe survival probability of the optimal deployment is 1. We will use AL in order to obtain a polynomial time algorithm forsolving the (NP-complete) “subset sum” problem. This problem requires one to decide, given a finite set S ⊂ N and a targetinteger K ∈ N, whether there exists a subset S(cid:5) ⊆ S whose elements sum up to K [9].Given a set S = {s1, . . . , sn} and a target K , construct the following 2-node network NS,K . Each member of the set s ∈ Sis represented by an agent as, whose space requirement is s, space(as) = s. The two nodes n1 and n2 have space(n1) = Kand space(n2) =s∈S s − K . Assume the network is reliable, i.e., the disconnect probabilities are dp(ni) = 0 for i = 1, 2. It iseasy to see that the survivability of the optimal deployment μ∗(cid:7)(cid:2)SF(M, NS,K , dp, μ∗) =1, ∃ a subset S0, otherwise.(cid:5) ⊆ S s.t.(cid:2)s(cid:5)∈S(cid:5) sis(cid:5) = K ,Therefore the following algorithm solves the subset sum problem:• For given S and K , build the network NS,K as described above.• Run algorithm AL on NS,K .• If AL returns a deployment with a survival probability greater than 0, then return Yes, else return No. (cid:2)3. Algorithms for computing exact deployment survivabilityThis section describes two algorithms for computing the survivability of a given deployment. Algorithm SF1n is a “naive”algorithm which is exponential in the number of nodes (and is therefore suitable for use when |V | is small), while AlgorithmSF1a is exponential in the number of agents (and hence is suitable when |M| is small).3.1. The naive Algorithm SF1nThis algorithm uses the definition of Eq. (1) directly in order to calculate the survivability of μ. More explicitly, itenumerates all possible valid future networks V i , and computes their occurrence probabilities. Finally, it returns the survivalprobability of μ, namely, the sum of the occurrence probabilities of all possible valid future networks.3.2. The agent-based Algorithm SF1aGiven a deployment μ, let Aai be the event that all the nodes that agent ai is deployed on are disconnected. Let Ad be theevent that at least one of the Aai events occurs. The probability that event Aai will occur is given by Pr( Aai ) =ai ∈μ(n) dp(n).In order for μ to survive, none of the Aai events should occur. Unfortunately, the Aai events are not mutually exclusive. Thus,in order to compute the survivability of μ using Aai we need to calculate the probability of the disjunction of non-mutuallyexclusive events using the inclusion–exclusion formula as presented below.(cid:8)Definition 7. Suppose μ is a deployment w.r.t. an overlay network V and suppose the node disconnect probabilities areindependent. ThenSF1a(M, V , dp, μ) = 1 − Pr( Ad)(2)whereY. Zhang et al. / Artificial Intelligence 173 (2009) 437–465Pr( Ad) = Pr( Aa1=(cid:3)∨ Aa2Pr( Aai ) −∨ · · · ∨ Aa|M| )(cid:3)Pr( Aai∧ Aa j ) + · · · + (−1)|M|+1Pr( Aa1∧ · · · ∧ Aa|M| ).443(3)ai ∈Mai (cid:8)=a j , ai ,a j ∈MAlgorithm SF1a calculates the probabilities of all the Aai events and then computes the above formula and returns itsresult.Example 3. Consider the network and deployment given in Example 1 and consider the disconnect probability functiongiven in Example 2. Agent a1 is located on nodes n1 and n2, and the probability that both will get disconnected is∧Pr( Aa1 ) = dp(n1)dp(n2) = 0.7 × 0.6 = 0.42. Similarly, Pr( Aa2 ) = Pr( Aa3 ) = dp(n1)dp(n3) = 0.28; Pr( Aa1∧ Aa3 ) = 0.28; Pr( Aa1Aa3 ) = dp(n1)dp(n2)dp(n3) = 0.168; Pr( Aa2∧ Aa2 ) = Pr( Aa1∧ Aa3 ) = 0.168.∧ Aa2Thus, the survivability of the deployment is given bySF1a(M, V , dp, μ) = 1 −(cid:6)(cid:5)Pr( Aa1 ) + Pr( Aa2 ) + Pr( Aa3 )∧ Aa3 ) = 0.468.∧ Aa2− Pr( Aa1(cid:5)Pr( Aa1+∧ Aa2 ) + Pr( Aa1∧ Aa3 ) + Pr( Aa2(cid:6)∧ Aa3 )Efficiency can be improved by using the idea presented in [27] to reduce the number of agents and nodes without anyloss of accuracy. For this purpose, denote the nodes in which an agent ai is located by Loc(ai). In [27], Kraus et al. provethat the survivability of a deployment is unaffected if we eliminate irrelevant agents—an agent a is irrelevant if any other(cid:5)) ⊆ Loc(a). Throughoutagent athis paper, when computing survivability with any algorithm, we always apply this method first to eliminate the irrelevantagents, and then carry out the computation on the simplified deployments.7 The following example gives the reader a quickidea of how the elimination idea works.exists such that it is deployed in a subset of nodes in which a is deployed, that is, Loc(a(cid:5)Example 4. Consider the network, deployment and the disconnect probability function given in Example 3. We haveLoc(a1) = {n1, n2}, Loc(a2) = {n1, n3}, and Loc(a3) = {n1, n3}. As Loc(a3) ⊆ Loc(a2), we may remove a3 from the deploy-ment μ and update μ as follows: μ(cid:5)(n1) = {a1, a2}, μ(cid:5)(n2) = {a1}, and μ(cid:5)(n3) = {a2}. We compute the survivability of μ(cid:5)byAlgorithm SF1a asSF1a(cid:5)M \ {a3}, V , dp, μ(cid:5)(cid:6)(cid:5)Pr( Aa1 ) + Pr( Aa2 )Clearly, SF1a(M \ {a3}, V , dp, μ(cid:5)) = SF1a(M, V , dp, μ).= 1 −(cid:6)+ Pr( Aa1∧ Aa2 ) = 1 − (0.42 + 0.28) + 0.168 = 0.468.3.3. An upper bound of the survivabilityAs Algorithms SF1a and SF1n both take exponential time, we now establish an upper bound for the survivability of μbased on Algorithm SF1a. This upper bound can be used to evaluate heuristics proposed later in the paper.As mentioned above, Ad is the event that all nodes on which some agent is located get disconnected. We are thereforeinterested in the complement of event Ad. Finding a lower bound for Pr( Ad) and subtracting it from 1 yields an upperbound on the survivability of μ. Given Eq. (3), the Bonferroni inequalities [18] state that if the sum on the right is truncatedafter k terms (k < |M|), then the truncated sum is an upper bound of Pr( Ad) if k is odd and is a lower bound of Pr( Ad) if k(cid:2)∧ Aa j ) (where |M| (cid:3) 2) is a lower boundis even. For example, it is easy to see thatfor Pr( Ad). This lower bound can be calculated incrementally until we run out of a predefined maximal running time or thedifference between what we add to the expression (an odd term) and what we subtract from the expression (an even term)is very small. We can then take the maximum of all the lower bounds that we computed. Subtracting this value from 1 willgive us an upper bound on the survivability of μ. The following algorithm8 explains the way to find an upper bound of thesurvivability of μ.ai (cid:8)=a j , ai ,a j ∈M Pr( Aaiai ∈M Pr( Aai ) −(cid:2)Algorithm 1 (UB(M, V , dp, μ, D, TM)).(∗ Input: a predefined value D and a maximum running time TM ∗)7 Another simplification of the deployments presented in this paper is that we assume the number of copies of an agent on one node is at most one.Note in our model, the survivability of a deployment, where more than one copy of the same agents exist on the same nodes, is equal to the survivabilityof the simplified deployment.8 All our algorithms receive a set of agents M, a set of nodes V , a disconnect probability function dp and a MAS deployment μ as input. For convenience,in the input part of each algorithm we will describe only the additional input parameters.444Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465(∗ Output: an upper bound on the survivability of μ ∗)(1) start timer T , k = 1; (* k specifies the number of elements in the subsets *)(2) value = 0, valueo = 1;(3) p = 0, minub = 1, maxlb = 0;(4) while ((|value − valueo| (cid:3) D) and (T < MT))(a) valueo = value;(b) value = ksubset(μ, k); (* returns the sum of the probability of k-subsets *)(c) if k is odd, then sign = 1;else sign = −1;(d) p = p + sign × value;(e) if (sign = 1)if p < minub, then minub = p;(f) elseif p > maxlb, then maxlb = p;(g) k = k + 1;(5) return (1 − maxlb).Proposition 8. Given a deployment μ and a network V , Algorithm UB yields an upper bound on the survivability of μ.Proof. Since Algorithm SF1a(M, V , dp, μ) returns the exact survivability of μ, we still need to show that UB(M, V , dp,μ, D, TM) (cid:3) SF1a(M, V , dp, μ). Define S1 =∧ · · · ∧i< j Pr( Aaiinequalities [18], we have SF1a(M, V , dp, μ) = 1 −AaikPr() for 2 < k (cid:2) |M|. Based on Eqs. (2), (3) and Bonferroni(cid:9)|M|i=1 Aai ) (cid:2) 1 −j=1(−1) j+1 S j (for even k (cid:3) 2) (cid:2) 1 − maxlb = UB(M, V , dp, μ, D, TM). (cid:2)i=1 Pr( Aai ), S2 =∧ Aa j ), and Sk =i1<i2<···<ikPr( Aai1(cid:2)|M|(cid:2)k(cid:2)(cid:2)4. Heuristic algorithms for computing survivabilityAs Algorithms SF1n and SF1a are too expensive for real-world applications, we now propose several heuristics to computethe survivabilities of deployments. We are interested in finding lower bounds for SF(μ), which will allow us to guaranteethat a given deployment μ has a survival probability that exceeds some threshold.4.1. An anytime Algorithm SF2(cid:2)Algorithm SF1a can be turned into an anytime algorithm using the same idea used to compute the upper bound. If wefind an upper bound for Pr( Ad) and subtract it from 1, then we attain a lower bound on the survivability of μ. Again,ai ∈M Pr( Aai ) is an upper bound for Pr( Ad). Any odd number of terms of Eq. (3) provides an upperlooking at Eq. (3),bound. An anytime algorithm can iteratively add terms until we exceed a time deadline or the ratio between the maximumamong the lower bounds and the minimum among the upper bounds is smaller than a specified ratio r. The algorithm issimilar to Algorithm 1 except that the anytime algorithm returns (1 − minub) as the lower bound on the survivability of thedeployment.Algorithm 2 (Algorithm SF2(M, V , dp, μ, R, TM)).(∗ Input: a predefined ratio R and a maximum running time TM ∗)(∗ Output: a lower bound on SF(μ) ∗)(1) start timer T , k = 1; (* k specifies the number of elements in the subsets *)(2) p = 0, minub = 1, maxlb = 0;(3) while ( maxlbminub(cid:3) R) and (t < M T )(a) value = ksubset(μ, k); (* returns the sum of the probability of k-subsets *)(b) if k is odd, then sign = 1;else sign = −1;(c) p = p + sign × value;(d) if (sign = 1)if p < minub, then minub = p;(e) elseif p > maxlb, then maxlb = p;(f) k = k + 1(4) return (1 − minub).Proposition 9. Given a deployment μ and a network V , the anytime Algorithm SF2 returns a lower bound on SF(μ).Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465445Proof. The proof is similar to that of Proposition 8, except here we need to show that SF2(M, V , dp, μ, R, TM) (cid:2)) for 2 < k (cid:2) |M|. Based on Eqs. (2), (3) and Bonfer-SF1a(M, V , dp, μ). Again, define Sk =Pr( Aai 1j=1(−1) j+1 S j (for odd k (cid:3) 1) (cid:3) 1 − minub =roni inequalities [18], we have SF1a(M, V , dp, μ) = 1 − Pr(SF2(M, V , dp, μ, R, TM). (cid:2)∧ · · · ∧ Aaik(cid:9)|M|i=1 Aai ) (cid:3) 1 −i1<i2<···<ik(cid:2)k(cid:2)4.2. A tree-based Algorithm SF3Algorithm SF3 is a heuristic which provides a lower bound on SF(μ). Algorithm SF1n computes the survivability of μby summing up the occurrence probabilities of all possible valid future networks V i . The high complexity of AlgorithmSF1n is therefore caused by the fact that it enumerates and checks an exponential number of possible future networks. Incontrast, Algorithm SF3 attempts to check only a bounded number of V i ’s. This immediately implies that SF3(M, V , dp, μ) (cid:2)SF(M, V , dp, μ), that is, Algorithm SF3 yields a lower bound on SF(μ). Obviously, in order to make this lower bound asclose as possible to SF(μ), the selection process should try to pick the future networks V i whose occurrence probability isas large as possible.Algorithm SF3 does this via a tree search in which every vertex is labeled with a subset of V . The algorithm starts fromthe root of the tree, labels it with V and computes V ’s occurrence probability. For every n ∈ V , there is a vertex labeledV \ {n} in the second level of the tree. For each label Vis valid and computesits occurrence probability. However, only the α vertices with the highest occurrence probabilities on the second level of thetree are further expanded in the same way. If a vertex labeled V i is expanded, its children will be labeled by V i \ {n} forn ∈ V i . Again, only α vertices on each tree level will be expanded. The algorithm stops when there are no more verticesto expand, and returns the sum of the occurrence probabilities of all the valid future networks occurring as labels in thesearch tree.of such a vertex, the algorithm checks if V(cid:5)(cid:5)If α is polynomial in the size of the input, then Algorithm SF3 considers only a polynomial number of future networks.Therefore it may return poor results if there is a large number of nodes. For example assume that the disconnect probabilityof nodes is distributed uniformly in [0, 0.5]. The output of Algorithm SF3 is bounded from above by the number of subsetsconsidered multiplied by the largest occurrence probability. The largest occurrence probability in this case is bounded by(cid:8), which isn∈V (1 − dp(n)). Therefore the survivability estimate given by Algorithm SF3 is usually no greater than α0.9|V |smaller than 10− |V |22 .Since the performance of Algorithm SF3 could be very poor, we propose two heuristics to improve its value.Disjoint removal heuristic: The first heuristic is that prior to running Algorithm SF3, we check for each agent a ∈ Mdenote the set of such agentsa∈M(cid:5) (1 −a∈μ(n),n∈V dp(n)).. At the end of the algorithm, we multiply the returnedwhether the nodes in Loc(a) are disjoint from those in Loc(awith disjoint sets. We can compute the survivability of M(cid:5)(cid:5)aWe then apply Algorithm SF3 on the remaining agents M \ M(cid:5)value by SF(M(cid:5), V , dp, μ), i.e., SF3(M, V , dp, μ) = SF(M(cid:5), V , dp, μ) · SF3(M \ M(cid:5), V , dp, μ).(cid:5)) for any other agent a. Let M(cid:5)directly by SF(M(cid:5), V , dp, μ) =(cid:8)(cid:8)(cid:5)Node removal heuristic: The second heuristic is based on the idea that if the number of nodes involved in Algorithm SF3is larger than some predefined constant Kb (i.e. |V | > Kb), then we may reduce it by removing some nodes which contribute(cid:10)1 − dp(n), where ρ denotes the number of agentsless to the survival of the μ. We sort the nodes in ascending order of ρon node n. The first Kr nodes can be deleted from the deployment. The intuition behind this formula is to remove nodeswhose disconnect probability is relatively higher, since the occurrence probabilities of networks that include these nodesare relatively low. In addition we want to remove nodes that are deployed with a relatively small number of agents, sincethe disconnection of these nodes influences fewer agents (compared to nodes that are deployed with a larger number of(cid:10)1 − dp(n) increases, since 1 − dp(n)agents). Note that as dp(n) increases ρis a fraction. The first Kr nodes can be deleted from the deployment. Note that after the removal action, it may be possibleto eliminate more irrelevant agents by applying the idea presented in [27] (see Example 4) in order to further simplify thecomputation.(cid:10)1 − dp(n) decreases. In addition as ρ increases ρAlgorithm SF3 is presented below.Algorithm 3 (Algorithm SF3(M, V , dp, μ, α, Kb, Kr)).(∗ Input: (1) the predefined number of selected vertices α ∗)(∗ (2, 3) the predefined constants Kb and Kr ∗)(∗ Output: a lower bound on SF(μ) ∗)(1) disjointsur v= rmvdisjoint(μ, V , M, dp);∗((2) if |V | > Kb, thenV = rmvnodes(μ, V , M, dp, Kr);remove the agents with disjoint locations, return the survivability of the removed agent set as described above∗)(* remove Kr nodes, and update the network as described above *)446Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465(3) bestval =(cid:8)n∈V (1 − dp(n));(* compute the occurrence probability of the network V *)(4) temp = {V }, done = false, flag = false;(5) while (¬done ), do(cid:5) = ∅;(a) X(b) while (temp (cid:8)= ∅)(i) X = headof (temp), temp = temp \ X ;(cid:5) ∪ { X \ {xi} | xi ∈ X};(cid:5) = X(ii) X(c) Svalid = ∅;(d) while ( X(i) V(ii) if V(cid:5)), X(cid:5) /∈ Svalid and V(cid:5)Svalid = Svalid ∪ V(e) if (¬flag), then done = true;(cid:5) = X(cid:5);(cid:5) ∈ ValidV (μ), then, flag = true;(cid:5) = headof ( X(cid:5) \ V(cid:5) (cid:8)= ∅), do (* remove invalid sets and repetitive sets in X(cid:5)*)else, do(i) for each (V i ∈ Svalid)(cid:8)poccur V i =n∈V ibestval = bestval + poccur V i ;(ii) Svalid = sort(Svalid, poccur V i);(1 − dp(n)) ·(cid:8)n∈V \V idp(n);(* sort sets in Svalid in descending order according to their occurrence probabilities *)(iii) for ( j = 0, j < α, j + +) (* keep the first α of sets *)• temp = temp ∪ headof (Svalid);• Svalid = Svalid \ headof (Svalid);(iv) flag = false;(6) return (bestval × disjointsurv).In the algorithm, the function rmvdisjoint(μ, V , M, dp) implements the disjoint removal heuristic described earlierwhich removes agents whose set of locations is disjoint from the set of locations of any other agent. The functionrmvnodes(μ, V , M, dp, Kr) implements the node removal heuristic, which reduces the number of the nodes by removingKr nodes which contribute less to the survival of the deployment.The following proposition states that Algorithm SF3 is a correct polynomial time approximation of SF(μ).Proposition 10. (1) For any α > 0, the value returned by Algorithm SF3 is a lower bound for SF(μ).(2) Suppose α is fixed. Then the time complexity of Algorithm SF3 is O(α|V |2 log(α|V |) + α|V |2|M|), i.e., the algorithm is poly-nomial if α is polynomial in the size of the input.A sketch of the proof of the above proposition is given below.(cid:5)of size |V(cid:5)| = |V | − i. In the next level of the tree, level i + 1, z has |VProof. Suppose the search starts from the root in level 0 of the tree, labeled by the set of nodes V . Consider a vertex z in(cid:5)| children, eachlevel i of the tree, labeled by a set V. Only the α valid sets with the highest occurrenceof whose labels are generated by removing exactly one node from Vprobabilities in level i are used to generate the next level. Thus the total number of vertices at level i + 1 is α(|V | − i). Foreach generated set of nodes, the occurrence probability of a set can be computed in O(1)9 time, and checking if the set isvalid (i.e., if it contains all agents) can be done in O(|M|) time. In addition, for each level, sorting the sets of the nodestakes O(α|V | log(α|V |)). As the maximum depth generated in the tree is |V |, the time complexity of Algorithm SF3 is:(cid:5)α|V |(cid:5)(cid:5)α|V ||M| + |V |α|V | logα|V |(cid:5)α|V |2 log= O+ α|V |2|M|(cid:5)|V |(cid:6).(cid:6)(cid:6)(cid:6)O(cid:6)(cid:5)Since the survivability of μ is the sum of the occurrence probabilities of all the valid subsets while Algorithm SF3only considers a subset of all valid subsets, clearly SF3(M, V , dp, μ, α, Kb, Kr) (cid:2) SF(M, V , dp, μ) for any value of α, Kband Kr . (cid:2)Example 5. Consider the network and the updated deployment of Example 4, where μ(n1) = {a1, a2}, μ(n2) = {a1}, andμ(n3) = {a2}. Suppose α = 1, Kb = 20 and Kr = 3. The root is V = {n1, n2, n3}. Thus Xs0 = {n1, n2, n3}, and poccur( Xs0) =(1 − dp(n1))(1 − dp(n2))(1 − dp(n3)) = 0.072.In the next level of the graph, three subsets are generated by removing one node from V :9 This can be done by using the occurrence probability of the parent’s vertex. This is due to the fact that the difference between a vertex in the treelabeled V \ {n} and its parent’s vertex in the tree labeled network V is that in V \ {n}, a node n doesn’t survive while in V a node n survives. Thereforepoccur(V \ {n}) = poccur (V )1−dp(n)× dp(n).Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465447Xs11 = {n2, n3},Xs12 = {n1, n3},Xs13 = {n1, n2},and poccur( Xs11) = (1 − 0.6)(1 − 0.4)(0.7) = 0.168;and poccur( Xs12) = (1 − 0.7)(1 − 0.4)(0.6) = 0.108;and poccur( Xs13) = (1 − 0.7)(1 − 0.6)(0.4) = 0.048.As α = 1, we use the set Xs11 to generate subsets in the next level. Xs21 = {n2} and Xs22 = {n3} are both removed becausethey are invalid. The search terminates because no more valid subsets can be created. The survivability estimate computedby Algorithm SF3 for the deployment is SF3(M, V , dp, μ, α, Kb, Kr) = 0.396. Hence Algorithm SF3 lower bounds SF(μ),which is 0.468, as shown in Example 4.4.3. A disjoint based Algorithm SF4Algorithm SF4 calculates survival probabilities while relying on the requirement that every agent must survive some-where in the network, and using information on the locations of each agent. For each agent ai ∈ M in the multi-agentapplication, let Loc(ai) = {ni} be the set of nodes where ai is located. Let E ij willsurvive. Then the event that at least one copy of ai will keep functioning is denoted by E i = E ik. The probability1of the event E i can be computed byj be the event that the node ni∨ · · · ∨ E i1, . . . , nik(cid:5)(cid:6)PE i= 1 − dp(cid:5)ni1(cid:6)dp(cid:5)ni2(cid:6)(cid:5)ni. . . dpk(cid:6).We can now define the event that a MAS deployment μ will survive:E(M, V , dp, μ) =(cid:5)E 11∨ · · · ∨ E 1k1(cid:6)∧ · · · ∧(cid:5)|M|1E∨ · · · ∨ E(cid:6).|M|k|M|The probability of the event E(M, V , dp, μ) represents the survivability of the deployment μ. Unfortunately, the E i sare not mutually exclusive. However, Algorithm SF4 computes a lower bound of E(μ) by assuming that the eventsE 1, E 2, . . . , Eare pairwise disjoint. The SF4 algorithm is defined by the following formula:|M|SF4(M, V , dp, μ) = P(cid:5)(cid:6)(cid:5)PE 1E 2(cid:6)· · · P(cid:6)|M|(cid:5)E=(cid:5)(cid:5)1 − dpn11(cid:6)(cid:5)· · · dpn1k(cid:6)(cid:6)× · · · ×(cid:5)(cid:5)1 − dpn(cid:6)(cid:5)· · · dpn(cid:6)(cid:6).|M|r|M|1Proposition 11. Algorithm SF4 provides a lower bound on SF(μ).The following example illustrates the operation of Algorithm SF4.Example 6. Consider the updated deployment μ(cid:5)V(cid:5) = {n1, n3}, respectively. Thus(cid:6)(cid:6)(cid:5)(cid:5)PPE 1E 2= 1 − dp(n1)dp(n2) = 1 − 0.42 = 0.58;= 1 − dp(n1)dp(n3) = 1 − 0.28 = 0.72.of Example 4. Agents a1 and a2 are located at nodes V = {n1, n2} andSo the survivability of μ is computed by SF4(M, V , dp, μ) = P (E 1)P (E 2) = 0.4176.Algorithm SF4 returns a lower bound on SF(μ) (i.e., 0.468). In this example, compared with the value returned byAlgorithm SF3 (0.396, see Example 5), Algorithm SF4 provides the better solution. However, as shown later in the sectionon experiments, there are some other cases where Algorithm SF4 returns lower survivabilities than Algorithm SF3.4.4. A group based Algorithm SF4gAlgorithm SF4 computes each agent’s survival probability and then returns the product of these survival probabilities.If no node contains more than one agent, then Algorithm SF4 returns the exact answer. However, in general, when the numberof agents is large and there is a large number of nodes in which many agents are located, Algorithm SF4 may return avery low approximation ratio. To improve this, if there are agents in a deployment that coexist in various nodes, we wouldconsider these agents as a group and compute the group’s survivability. We divide all agents into several such groups, andthen take the product of the survival probabilities of all groups as the survivability of the deployment. An intuitive way togroup agents is to consider an agent a that has the lowest survivability. We group a with other agents that have the mostcommon nodes with it. When we compute the survivability of each agent group, we use Algorithm SF1a. As Algorithm SF1atakes exponential time in the number of agents, we limit the size of each group.Algorithm 4 (Algorithm SF4g(M, V , dp, μ, s)).(∗ Input: the number of agents in one group, s ∗)(∗ Output: a lower bound on SF(μ) ∗)448Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465(1) agents = M, surv = 1;(2) for each agent ai ∈ agents, do(cid:8)P (E i) = 1 −(3) while (agents (cid:8)= NULL), don∈Loc(ai ) dp(n);• ai = arg minai ∈M P (E i); (* choose the agent with the lowest survivability *)• A(cid:5) = group(ai, s, μ, V , agents);(* group at most s − 1 agents who have the most common locations with ai into one group A(cid:5), V , dp, μ); (* use Algorithm SF1a to compute the survivability of A*)(cid:5)(cid:5)*)• value = SF1a( A• surv = surv × value;(cid:5)• agents = agents \ A.(4) return surv.In this algorithm, the function group(a, s, μ, V , agents) takes as input, an agent a, the predefined number of membersin one group s, the deployment μ, a set of agents denoted agents and a set of nodes V . For each agent, it computes thenumber of common locations with agent a, selects the first s − 1 agents who have the most common nodes (if two agentshave the same number of common nodes it chooses one of them arbitrarily), groups these s − 1 agents together with agenta into one group A, and then returns A.(cid:5)(cid:5)The following example demonstrates the grouping idea applied in Algorithm SF4g .Example 7. Consider a network with six nodes V = {n1, n2, n3, n4, n5, n6} and a multi-agent application M = {a1, a2, a3, a4}.Suppose the disconnect probabilities are:dp(n1) = 0.7,dp(n2) = 0.6,dp(n3) = 0.4,dp(n4) = 0.3,dp(n5) = 0.2,dp(n6) = 0.1.Consider the current deployment μ:μ(n1) = {a1, a2}, μ(n2) = {a1}, μ(n3) = {a2}, μ(n4) = {a3}, μ(n5) = {a3, a4}, μ(n6) = {a4}.We set the number of agents per group to 2. Algorithm SF4g first computes the survivability of each agent based on thenodes in which the agent is located:(cid:6)(cid:6)(cid:5)(cid:5)PPE 1E 3= 1 − dp(n1)dp(n2) = 0.58,= 1 − dp(n4)dp(n5) = 0.94,(cid:6)(cid:6)(cid:5)(cid:5)PPE 2E 4= 1 − dp(n1)dp(n3) = 0.72,= 1 − dp(n5)dp(n6) = 0.98.Since agent a1 is most likely to fail, we select a1 to form the first group g1. We then group agent a2 and a1 together sincea2 has the most number of common nodes with agent a1. Thus we have g1 = {a1, a2}. Algorithm SF1a is applied to groupg1 to compute its survivability:SF(g1, V , dp, μ) = SF1a(g1, V , dp, μ) = 1 −(cid:6)(cid:5)Pr( Aa1 ) + Pr( Aa2 )(cid:6)(cid:5)dp(n1)dp(n2) + dp(n1)dp(n3)+ Pr( Aa1+ dp(n1)dp(n2)dp(n3) = 0.468.∧ Aa2 )= 1 −Similarly, the remaining agents, a3 and a4, form the second group g2 = {a3, a4}.SF(g2, V , dp, μ) = SF1a(g2, V , dp, μ) = 1 −(cid:6)(cid:5)Pr( Aa3 ) + Pr( Aa4 )(cid:6)(cid:5)dp(n4)dp(n5) + dp(n5)dp(n6)+ Pr( Aa3+ dp(n4)dp(n5)dp(n6) = 0.914.∧ Aa4 )= 1 −Thus, the estimated survivability given by the algorithm is: SF4g(μ, V , dp, μ, 2) = SF(g1, V , dp, μ)SF(g2, V , dp, μ) = 0.42775.Using Algorithm SF1a on M, we know the survivability of μ is SF(μ) = 0.42775. Clearly, in this case, Algorithm SF4greturns the actual survivability since there is no overlap whatsoever between the locations of two groups (g1 = {a1, a2} andg2 = {a3, a4}). However, this may not necessarily happen with other deployments.4.5. A split Algorithm SF5Given a specific node, n ∈ V , we can consider two possible disjoint events. The first, E 1, is the event that the networksurvives given that node n remains connected. Alternatively, E 2 is the event that the network survives given that node nbecomes disconnected. If n remains connected, all the agents that are deployed on it survive. Thus the survivability of thenetwork, in this case, depends on the survivability of the rest of the agents, which are not located on n. If n is disconnected,then the survivability of the network depends on the rest of the nodes, i.e., V \ {n}. The survivability of the original networkis thus (1 − dp(n))Pr(E1) + dp(n)Pr(E2). In both cases, the problem of computing the survival probability is smaller than theoriginal problem. This leads to a recursive approach for solving the problem. The subproblems usually become even smallerwhen we remove the irrelevant agents according to the idea presented in [27]. There are several stopping rules that arespecified in the first three lines of the pseudocode shown below. The first two rules refer to situations in which it is possibleY. Zhang et al. / Artificial Intelligence 173 (2009) 437–465449to compute the exact survival probability of the future network. The third stopping rule has to do with future networks thathave a very small survival probability (computing through recursion using p; p = 1 the first time Algorithm SF5 is called).For these very low probability future networks, Algorithm SF4 is applied to obtain a lower bound of the survivability.Algorithm 5 (Algorithm SF5(M, V , dp, μ, p, (cid:2))).(∗ Input: (1) survivability of the known nodes during split p; initially p = 1 ∗)(∗(∗ Output:(2) a predefined threshold (cid:2) ∗)a lower bound on SF(μ) ∗)(1) if M = ∅, return 1;(cid:8)then returnelse, if p < (cid:2),else, if the agents of M are located on disjoint sets of nodes,(cid:8)a∈M(1 −a∈μ(n) dp(n));then return SF4(M, V , dp, μ).(cid:5)(cid:5) = V(cid:5) = V \ {n};else, choose a node n ∈ V with the largest set of agents,(a) V(b) μ(cid:5) = μ; M(cid:5) = M \ {a | a ∈ μ(n)};(c) get rid of irrelevant agents in M and M(cid:5)(cid:5)(cid:5)(d) adjust μ and V(e) return dp(n) × SF5(M, Vw.r.t. M and μ(cid:5)according to the idea in [27];w.r.t M(cid:5)(cid:5), dp, μ, dp(n)p, (cid:2)) + (1 − dp(n)) × SF5(M(cid:5), Vand V;(cid:5)(cid:5)(cid:5), dp, μ(cid:5), (1 − dp(n))p, (cid:2)).Proposition 12. Algorithm SF5 yields a lower bound on SF(μ).Proof. Algorithm SF5 is recursive, with three termination conditions. If the termination conditions are not met, the algo-rithm generates a (smaller) subproblem; if the algorithm terminates, there are three possible cases as follows.If the algorithm terminates by the first termination condition, i.e., M = ∅ (line 1 of the pseudocode in Algorithm 5), thesubnetwork of the subproblem does not contain any agents. Thus we cannot simplify the problem any further. The resultreturned by the algorithm is the exact solution for the original problem.(cid:8)If the second termination condition applies, i.e., the agents of M are located on disjoint sets of nodes, returna∈M(1 −a∈μ(n) dp(n)) (lines 2, 3 of the pseudocode in Algorithm 5), the subproblem is easily computed by multiplying each agent’ssurvivability. Since the agents in this condition are located in disjointed nodes, the solution is the exact same solution asfor the original problem.Finally, if Algorithm SF5 terminates by the third condition, i.e., if p < (cid:2), then return SF4(M, V , dp, μ) (lines 4, 5 of thepseudocode in Algorithm 5). Since Algorithm SF4 provides a lower bound on SF(μ), the result returned by Algorithm SF4 isa lower bound for the subproblem of Algorithm SF5.(cid:8)In conclusion, Algorithm SF5 also provides a lower bound on SF(μ). (cid:2)The following example illustrates how Algorithm SF5 works.Example 8. Consider the network and the updated deployment of Example 4, where μ(n1) = {a1, a2}, μ(n2) = {a1}, andμ(n3) = {a2}, and (cid:2) = 0.001. The heuristics we use to choose the node to split is the number of agents deployed on thatnode. Since node n1 has the largest number of agents of all the nodes, n1 is selected. There are two cases which refer to thesplitting operation w.r.t. n1: The first event E1 is where the network will survive given that node n1 will remain connected.In this case we have:V 1 = {n2, n3}, M1 = ∅, ∀n ∈ V 1, μ1(n) = ∅,p1 = 1 − dp(n1) = 0.3;The second event E2 is where the network will survive given that node n1 will be disconnected. In this case we have:V 2 = {n2, n3}, M2 = {a1, a2}, μ2(n2) = {a1}, μ2(n3) = {a2},p2 = dp(n1) = 0.7;We now call Algorithm SF5 with the updated parameters.As M1 = ∅, we have Pr(E1) = 1. In M2, the agents a1 and a2 are located on disjoint nodes, thus, we returnPr(E2) =(cid:5)1 − dp(n1)(cid:6)(cid:5)(cid:6)1 − dp(n2)= (1 − 0.4)(1 − 0.6) = 0.24;Therefore, we stop the split operation and return the survivability of the original deployment by:SF5(M, V , dp, μ, 1, 0.001) = p1 × Pr(E1) + p2 × Pr(E2) = 0.468.Note that in this case, Algorithm SF5 outputs the exact survivability (0.468, as shown in Example 4). However, this is notnecessarily true for other cases.450Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–4655. ExperimentsThe survivability algorithms we shall compare in this section are:• anytime algorithm SF2: where the threshold of the approximation ratio is set to 0.9 and the time limit on the main partof the algorithm is set to 5 seconds;• tree-based algorithm SF3, where the constant α is set to the number of nodes in the network, and the constants Kb andKr are set to 20 and 6, respectively;• disjoint based algorithm SF4;• group algorithm SF4g , where the number of agents in each group is set to 4;• split algorithm SF5, where the threshold (cid:2) in the stopping rules is predefined as 0.005.The performance measures we used are: (1) computation time, and (2) solution quality. We evaluate the solution qualityas follows.• Exact optimal solutions: For small cases where the number of nodes or the number of agents are small (less than 16),we obtain the exact survivability S E by using the naive algorithm SF1n when there are more agents than nodes, or byusing SF1a when there are more nodes than agents. The solutions provided by the heuristic algorithms S H are thencompared. The solution quality (or approximation ratio), is computed as: S HS E• Upper bounds on optimal solutions: For large cases where computing optimal solutions is not feasible, we compute theupper bounds of the exact survivabilities UB using the upper bound algorithm and compare them with the values S Hreturned by the heuristics. Thus, the solution quality (or approximation ratio) is evaluated by: S HUB ..We considered various experimental settings. In this paper, we consider instances taken from a (fictitious) company thatuses local servers, personal computers, and some web servers to locate and run multi-agent applications. As we know, webservers and personal computers have high probabilities of going down, while local servers usually have lower disconnectprobabilities. In the next section, we describe the variations of the settings we used in our experiments. We use the termnumber ratio to refer to the ratio of the number of agents to the number of nodes. Space ratio describes the ratio of the totalamount of resources available on the nodes to the total resource requirements of the agents. In addition, the problem size isthe sum of the number of agents and nodes in the settings.5.1. Environmental settingsWe used various environmental settings in the experiments. Suppose a multi-agent application M includes many agentsbut only a relatively small number of servers (or nodes) is available. We set the number ratio of agents and nodes to 5/3.We then considered the following two environments:s1: A network consisting of a small number of web servers N w which constitute 30% of the involved servers, and manylocal servers Nl, which constitute 70% of the involved servers. The disconnect probabilities of the web servers arevery high—above 0.9 (i.e., dp(n) (cid:3) 0.9, ∀n ∈ N w ), while the disconnect probabilities of the local servers are verylow—below 0.1 (i.e., dp(n) (cid:2) 0.1, ∀n ∈ Nl). The space ratio of nodes and agents is between 2 and 3.s3: A network consisting of local servers only. Suppose some of these servers are new, while the others are old. Thedisconnect probabilities of these servers are between 0 and 0.4, where higher disconnect probabilities have a higherprobability to appear (there are more older computers than new ones). The space ratio of nodes and agents is 4.Consider another multi-agent application M(cid:5)which consists of a small number of agents. The company intends to deployon many personal computers and local servers since the available resources on each server or PC are limited. We setM(cid:5)the number ratio of agents to nodes at 3/5. The following environments are specified:s2: Personal computers (30%) are employed, with disconnect probabilities over 0.9; they also use local servers (70%)which have low disconnect probabilities (less than 0.1). The space ratio of nodes to agents is around 2–3.s4: Only local servers of different agents are used to host M(cid:5). The disconnect probability of the servers is distributed asin setting s3. The space ratio of nodes to agents is around 4.We apply an existing MAS application from the IMPACT system [40] with 31 agents to determine the resource distributionof agents (in the range of 0 to 250 KB) in our experiments.10 We use the environments s1–s4 described above to test thesurvivability algorithms.10 We do not distinguish the criticality between agents in a multi-agent system when computing its survivability. Therefore, other factor such as roles (orworkloads) of different agents does not play a role in the experiments, and thus not reported here.Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465451Table 1Experiment 1: Upper bounds and approximation ratios of the different algorithms with setting s1.Problemsizen18, a30n24, a40n30, a50Deploymethodnode-basedagent-basedrandom-basednode-basedagent-basedrandom-basednode-basedagent-basedrandom-basedUpperbound0.4354120.3493910.0022810.3556590.3066980.0001660.4290620.3318210.000006Anytime(SF2)0.9514750.930565–0.851970.861461–0.8993240.811792–Tree-based(SF3)0.9989190.972725–0.9640370.881713–0.9371450.851059–Disjoint(SF4)0.8793770.879446–0.8368560.796948–0.7759340.731787–Split(SF5)0.9995150.973295–0.9658130.889531–0.9398650.852492–Group-based(SF4g )0.9486440.947005–0.9236820.859259–0.8934120.827303–5.2. Agent deployment methodsThe method used to generate deployment is important since different survivability algorithms may work well withdifferent types of deployments. In this paper, we generate deployments by the heuristics proposed in [27], namely node-based and agent-based heuristics. In addition, we use a random-based method to represent other possible deployments. Thedeployment methods work as follows.Node-based: This heuristic is based on the knapsack problem. We first sort nodes in ascending order according to theirdisconnect probabilities. We then place agents, starting from the one with the smallest ID in our implementation, on thesorted nodes starting from the node with the lowest dp. We put as many agents as possible on this node, then go to nodeswith the second lowest dp and so on.Agent-based: This is based on the idea that we should first deal with agents with high resource requirements. We sortagents in ascending order according to resource requirements, deploy the first agent, then choose the agent with the secondhighest resource requirement, and so on until no more space is left for placing agents. When we deploy an agent, we alwayschoose the node with the lowest dp of the nodes capable of storing the said agent.Random-based: First we randomly choose a node, and then randomly select and place agents on it, subject to spaceconstraints. We make sure the deployment uses all the available resources on the nodes.In the experiments, we also wanted to investigate the performance of the survivability algorithms on different de-ployments returned by various deployment methods, and to check whether the algorithms have preferences for particulardeployments.5.3. Experimental resultsWe are now ready to present the experimental results. All the algorithms in this paper were implemented on a Linux PCrunning on a 1000 MHz CPU machine with 512 MB RAM. Running times of all algorithms are reported in microseconds. Everyrecorded observation was averaged over 50 runs. The algorithms were compared on various deployments (node-based,agent-based, and random-based) with different environment settings s1–s4. In all the experiments, we varied the problemsize, i.e., the total number of agents and nodes. We present the results of the following experiments: Experiment 1 wascarried out in setting s1; Experiment 2 in setting s2; Experiment 3 in setting s3; Experiment 4 in setting s4; Experiment 5compared different algorithms in setting s1 but with a larger space ratio.In order to ensure that the survivability computed by the upper bound algorithm is close enough to the actual value,for each deployment, we estimated its survivability by simulating the node failures on the network a thousand times.The results show that the upper bounds are pretty close to the simulation survivabilities. The average relative error, e.g.,upper bound-simulation resultsimulation result, is within 0.5%.The approximation ratio of the algorithm reported in the experimental result is the solution quality described on page 450,which is computed by either S HS Eor S HU B , depending on the problem size.Experiment 1In Experiment 1, we ran and compared five algorithms in setting s1 where the space ratio of nodes to agents wasbetween 2 and 3 and the disconnect probabilities were distributed either in 0–0.1 or in 0.9–1. The problem size varied from48, 64 to 80. Table 1 illustrates the results of upper bounds on the survivability and approximation ratios by the differentalgorithms, where n18, a30 refers to a MAS of 30 agents deployed over 18 nodes.As can be seen from the upper bounds in Table 1, the deployments achieved by the node-based deployment methodhave a higher survivability than the agent-based deployments. Undoubtedly, when the disconnect probabilities of the nodesvary dramatically, the MAS is better off if the highly surviving nodes are considered first when deploying agents. Therefore,it is not surprising that the node-based deployments result in the best survivabilities of all the methods, and the randombased deployment method returns very poor survivabilities (all below 0.005 according to the upper bounds in the table).452Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465Table 2Experiment 1: Computation time (in microseconds) using the different algorithms with setting s1.Problemsizen18, a30n24, a40n30, a50Deploymethodnode-basedagent-basednode-basedagent-basednode-basedagent-basedAnytime(SF2)65179756351237829123763251059164302199Tree-based(SF3)Disjoint-based(SF4)5999387428779751015650397597119Split(SF5)260942207555172519547318771481Group-based(SF4g )9277101527106622311707Table 3ANOVA on the results of five algorithms in Experiment 1 with agent-based deployments and a problem size of 64. The level of significance required is setto 0.05.Between algorithmsResidualTotalSum ofsquares (SS)0.164830.362750.52758Degrees offreedom (df)49599Mean square(MS)0.041210.00382F valuep-valueF crit10.791462.9689E–072.46749Table 4ANOVA on the results of SF3 and SF5 in Experiment 1 with agent-based deployments and a problem size of 64. The level of significance required is setto 0.05.Between algorithmsResidualTotalSum ofsquares (SS)1.0266E–061.3158E–051.4185E–05Degrees offreedom (df)13839Mean square(MS)1.0266E–063.4627E–07F valuep-valueF crit2.96470.093234.09817In Table 1, we exclude the random based deployments (due to their very low survivabilities) and discuss the approxima-tion ratios returned by the various algorithms only on agent-based and node-based deployments. Of all the heuristics, thetree based algorithm, SF3, and the split algorithm, SF5, return the best solutions. SF5 attains the best result, although thedifference between its results and those of SF3 is very small. SF3 always achieves higher accuracy than the disjoint basedalgorithm SF4, the anytime algorithm SF2 and the group algorithm SF4g . The reason for this is twofold.(1) First, when searching for the valid future networks, in each level of the tree, SF3 always keeps the networks whichhave higher survivabilities, and removes those more likely to fail. Thus, in the s1 setting where the disconnectprobabilities are either very high or very low, SF3 will select the valid future networks where most nodes have lowdisconnect probabilities, i.e., dp < 0.1. Since the valid future networks with low survival nodes (dp > 0.9) do notgreatly contribute to the survivability of the deployment, SF3 can make good approximations.(2) Second, the space ratio of nodes to agents is small (i.e., 2–3) in the s1 setting, which implies that since the nodescannot accommodate many agents due to resource constraints, the number of valid future networks is limited to arelatively small number. As SF3 keeps the fixed α best networks in each level of the tree search, it is very likelythat SF3 will keep most of the “important” valid future networks which have a relatively high survivability. Thus,SF3 works very well with setting s1.Statistical significance. In order to discover whether there are significant differences in the performances of the algo-rithms, we performed a One-way Analysis of Variance, or one-way ANOVA11 [12], on the solution of each round returned bythe different algorithms. Table 3 shows the results of the ANOVA applied to the data achieved in setting s1 on the agent-based deployments when the problem size is 64. The level of significance required in ANOVA is set to 0.05. In the table, thecalculated F value (F = 10.79146) exceeds the critical value of F (2.46749) and the probability (p-value) that the calculated Fvalue would be obtained by change is nearly zero. Therefore, the difference in performance of the five algorithms is signifi-cant. We then performed the ANOVA only on the tree based algorithm SF3 and the split algorithm SF5. Since the computedF value (F = 2.9647) is smaller than the critical value of F (4.09817) as shown in Table 4, we can conclude that there is nosignificant difference between the performance of SF3 and SF5.11 In one-way ANOVA, the number of degrees of freedom (df) associated with “between algorithms” is one less than the number of algorithms; the df for“residual” is the total number of samples of the algorithms minus the total number of algorithms. The F value is simply the ratio of the variance estimatesof “between algorithms” and “residual”. The critical values (F crit) are presented in an F table. Using the F, we can compute the p-value, which is theprobability of the obtained result occurring due to chance. For a more detailed discussion on one-way ANOVA, see [12].Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465453Table 5Experiment 2: Upper bounds and approximation ratios of the different algorithms with setting s2.Problemsizen30, a18n40, a24n50, a30Deploymethodnode-basedagent-basedrandom-basednode-basedagent-basedrandom-basednode-basedagent-basedrandom-basedUpperbound0.5205570.4105920.0014060.4365220.3420720.0018080.3984110.3179060.001918Anytime(SF2)0.9283530.939275–0.8807720.907723–0.9237070.910653–Tree-based(SF3)0.9903340.996562–0.9808320.968986–0.9812280.972855–Disjoint(SF4)0.9747060.973966–0.9525440.941974–0.9587110.900914–Table 6Experiment 2: Computation time (in microseconds) using the different algorithms with setting s2.Problemsizen30, a18n40, a24n50, a30Deploymethodnode-basedagent-basednode-basedagent-basednode-basedagent-basedAnytime(SF2)590429781558062254113648161822433Tree-based(SF3)2654613251769351183110975411842Disjoint-based(SF4)871181511Split(SF5)0.999610.999569–0.988560.991491–0.9735210.976648–Split(SF5)198421404339496329448681174323Group-based(SF4g )0.9891890.998401–0.9792020.988068–0.966280.967943–Group-based(SF4g )1361586211199830961676Table 7ANOVA on the results of SF3 and SF5 in Experiment 2 with agent-based deployments and a problem size of 64. The level of significance required is setto 0.05.Between algorithmsResidualTotalSum ofsquares (SS)0.000480.002650.00313Degrees offreedom (df)16465Mean square(MS)0.000484.1477E–05F valuep-valueF crit11.540030.00123.99092Computation time. Table 2 shows the computation time taken by the different algorithms. From the results, we cansee that SF3 needs much less computation time than the split algorithm and the anytime algorithm on both node andagent-based deployments. The disjoint based algorithm is the fastest of all, taking only several microseconds to computethe survivability of a given deployment. The time needed by the group algorithm SF4g is close to that of the tree basedalgorithm SF3.Conclusion. Overall, in experimental setting s1, when taking both the approximation ratio and the computation timeinto account, the tree based algorithm SF3 outperforms the other algorithms.Experiment 2Tables 5 and 6 present the results of the performances of the different algorithms in experimental setting s2 in whichthere are more nodes than agents (with a ratio of 5/3), the space ratio of nodes to agents is 2–3, and the dp’s are distributeddramatically. Concerning the upper bounds of the deployments returned by the different types of methods, the node-based method results in the highest survivability. Again, the random based method does not work well in this setting withdramatically varying dp’s over the network.In terms of solution quality, the split algorithm SF5 is the best, followed by the tree based algorithm SF3, which out-performs the group algorithm SF4g both on the node-based deployments with problem sizes of 48, 64, 80, and on theagent-based deployments with a size of 80. The disjoint algorithm SF4 gives a pretty good approximation (with a ratio ofover 0.9), regardless of the fact that it returns the poorest measurements of all algorithms. The performance of both SF4and SF4g is significantly better than in Experiment 1. In the deployments achieved with setting s2, the average number ofagents located on each node is smaller compared to setting s1 since there are more nodes than agents in s2, but the spaceratio is the same as in s1. As there is less overlap in the locations of agents, SF4 and SF4g work better in this experimentthan they did in Experiment 1.Statistical significance. In addition, we performed a statistical significance test for the algorithms SF3 and SF5. Table 7shows that the calculated F value (F = 11.54003) is greater than the critical value of F (3.99092) with a very small p value(p = 0.0012). Hence, we conclude that in this setting, the performance of algorithms SF3 and SF5 in terms of solutionquality are significantly different.454Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465Table 8Experiment 3: Upper bounds on the actual survivability of the different deployments with setting s3.node-basedagent-basedrandom-basedn12, a200.9282310.9359440.657132n18, a300.8890230.8674880.474367n24, a400.8760900.8369070.349565n30, a500.8588440.8317100.302506n36, a600.8131990.8036830.186378Computation time. In terms of computation time taken by different heuristics on the agent-based deployments, theresults are similar to those in Experiment 1, i.e., the split algorithm SF5 and the anytime algorithm SF2 take much moretime than the other three heuristics. If we look at the time taken for computing the node-based deployments, it is clearthat the tree based heuristic SF3 needs the longest time. As we have shown in Section 4.2, the complexity to computeSF3 is dependent on α|V |2 log(α|V |). Therefore, although the problem size remains the same in setting s2 as in s1, SF3needs longer time to terminate compared to s1 since the ratio of nodes to agents is higher. However, note that this is notthe case for SF3 on the agent-based deployments, where SF3 completes the search fast, but the survivabilities it returnsare comparable with those on the node-based deployments, as depicted in Tables 5 and 6. Apparently with setting s2,when applying SF3 on the agent-based deployments, the number of valid future networks in each level converges fast withthe tree search. Consequently, SF3 may terminate early. Thus, the results suggest that in settings like s2, the tree basedalgorithm SF3 leads to better performance in terms of computation time for the agent-based deployments compared to thenode-based ones.Conclusion. Overall, in experimental setting s2, the split algorithm SF5 is the preferred algorithm if both the solutionquality and the running time are taken into account.Experiment 3Experiment 3 was performed in setting s3, where the disconnect probability of nodes was distributed between 0–0.4and higher disconnect probabilities had a higher probability to appear. From the results in Table 8, we notice that this typeof disconnect probability distribution immediately increases the survivability of the deployments, compared with the upperbounds shown in Experiments 1 and 2. Even randomly deploying agents could result in better deployments with highersurvivability than those in Experiments 1 and 2. The node-based method still seems to find better surviving deploymentsthan the other two methods.Figs. 1 and 2 present the approximation ratios and the computation time of the various algorithms, respectively. In bothfigures, the x-axis represents the problem size, varying from 32 to 98 in steps of 16. Note that we did not include theresults of the tree based algorithm SF3 since its approximation ratio was much lower (below 0.8) than the others in settings3. Since in s3 the disconnect probabilities of the nodes do not vary dramatically, the values of all the valid future networksdo not greatly vary. Therefore, the bad approximation of SF3 is due to the fact that it excludes the survivabilities of manynetworks which also significantly contribute to the overall survivability.Fig. 1 demonstrates the advantage of the split heuristic SF5, which gives the best approximation ratio no matter whatkind of deployments it employs. As described in Section 4.5, SF5 is a recursive algorithm and after each recursion the sub-problem becomes smaller. Moreover, when a node is chosen during computation, the whole network could be updated byremoving the irrelevant agents, which further reduces the size of the subproblems. The algorithm terminates only eitherwhen the future subnetwork (or subproblem) can be accurately computed, or when the survivability of the future sub-network becomes small enough to be roughly estimated—the threshold is set to 0.005 in the experiments. Thus it is notsurprising that SF5 yields a very good approximation. According to the experiments in this paper the split algorithm SF5always provides a good approximation ratio regardless of the environment settings.Furthermore, all the algorithms achieve high approximation ratios (over 0.96) on the node-based deployments. As for theagent-based deployments, all the algorithms return approximation ratios of over 0.90 with a problem size no larger than 80.Only the ratio of SF4 drops to 0.86 when the problem size rises to 96. All the algorithms excluding the anytime algorithmreach above a 95% accuracy on the random-based deployments. Seemingly the SF4 and the SF4g do significantly better onnode-based deployments than on agent-based ones.Statistical significance. Table 9 shows the ANOVA test result on algorithms SF2, SF4g and SF5. The calculated F value(20.17751) is greater than the critical value of F (3.96347). Thus the performances of these three algorithms are significantlydifferent. However, Table 10 implies that there may not be a great difference between SF2 and SF5, since the calculated Fvalue (2.45835) is smaller than the critical value (3.96347).Computation time. As far as the computation time is concerned (shown in Fig. 2 in a logarithmic scale), the anytimealgorithm is the time consuming one. The disjoint-based SF4 is the fastest algorithm of all the algorithms. The three graphsshow that the computation times of the disjoint based, the group based, and the split algorithms are barely affected by thedeployment methods they employ. However, the anytime algorithm converges much faster on the node-based deploymentsthan the agent-based deployments—the computation time taken on the latter is approximately 100 times more when theproblem size is over 48.Conclusion. In setting s3, the split algorithm SF5 and the anytime algorithm SF2 outperform other algorithms in termsof solution quality. However, SF5 is preferable to SF2 since SF5 converges to a solution much faster than SF2.Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465455Fig. 1. Experiment 3: Approximation ratios of the different algorithms with setting s3. The x-axis represents the problem size and the y-axis represents theapproximation ratio.Experiment 4Experiment 4 was carried out with environment setting s4, where there are more nodes than agents (with a ratio of5/3), and dp’s are distributed as in s3. Table 11 contains the results of the upper bounds and approximation ratios by thevarious algorithms. With this setting, even the random based deployments achieve survivabilities over 0.5 for problem sizesbelow 80. Using the agent and node-based methods to deploy agents both result in deployments with upper survivabilitybounds exceeding 0.97. Moreover, for the first time, the agent-based method seems to result in better deployments than thenode-based method, although the differences are quite small (within 0.01). Since the upper bounds are high, we can assumethat the real survivability of the deployments are high—which suggests that in the deployments, every agent is deployed onmost of nodes in the network; and/or at least one of the valid future networks has a very high survivability.As far as the accuracy of the various algorithms is concerned, all the algorithms exhibited excellent accuracies whichalways exceed 0.97. In particular, the disjoint-based algorithm SF4, the split and the group algorithms (SF5 and SF4g ) wereable to always achieve approximation ratios over 0.998. This is due to the fact that when there are more nodes than agents,the resources available in each node decreases compared with that in Experiment 3. Thus most of the agents are disjointfrom the others w.r.t. their locations, which enables the algorithms, especially the disjoint and the group algorithms, toperform very well.Statistical significance. Since all four algorithms displayed a very good solution quality, we performed the ANOVA testin order to assess statistical significance. The test revealed a significant difference as depicted in the results reported inTable 12, where the calculated F value (10.9514) is greater than the critical value of F (2.6625). We did the test again on thesame data but only for the anytime algorithm SF2, the group-based algorithm SF4g , and the split algorithm SF5. In Table 13we notice that there is no significant difference in the performances between these 3 algorithms since the calculated F value(2.16635) is smaller than the critical value (3.07376).456Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465Fig. 2. Experiment 3: Computation time of the different algorithms with setting s3. The x-axis represents the problem size and the y-axis is the computationtime (in a logarithmic scale).Table 9ANOVA on the results of 3 algorithms: SF2, SF5, and SF4g in Experiment 3, with agent-based deployments and a problem size of 64. The level of significancerequired is set to 0.05.Between algorithmsResidualTotalSum ofsquares (SS)0.023160.089530.11269Degrees offreedom (df)17879Mean square(MS)0.023160.00115F valuep-valueF crit20.177512.412E–053.96347Table 10ANOVA on the results of 2 algorithms: SF2 and SF5 in Experiment 3, with agent-based deployments and a problem size of 64. The level of significancerequired is set to 0.05.Between algorithmsResidualTotalSum ofsquares (SS)0.001890.059980.06187Degrees offreedom (df)17879Mean square(MS)0.001890.00077F valuep-valueF crit2.458350.120953.96347Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465457Fig. 3. Experiment 4: computation time of the different algorithms with setting s4. The x-axis represents the problem size and the y-axis is the computationtime (in a logarithmic scale).Table 11Experiment 4: Upper bounds and approximation ratios of the different algorithms with setting s4.Problemsizen20, a12n30, a18n40, a24n50, a30n60, a36Deploymethodnode-basedagent-basedrandom-basednode-basedagent-basedrandom-basednode-basedagent-basedrandom-basednode-basedagent-basedrandom-basednode-basedagent-basedrandom-basedUpperbound0.9720450.9808110.7741730.9735430.9872560.7532710.9790590.9891460.6093910.9717180.9885690.5355320.9785910.9839520.427743Anytime(SF2)0.999880.9998450.9917240.9999220.999790.9916220.9997230.9995880.9912550.9996610.9993980.9905890.9996810.9992170.976279Disjoint(SF4)0.9999710.999810.9998370.9999650.9995350.9999180.9999690.9992690.9996390.9999680.9991360.9996550.9999230.9981050.998948Split(SF5)0.9999960.999960.9999980.9999830.9998520.9999850.9999850.9997290.9998950.999890.9996490.9997750.9999570.9993440.999663Group-based(SF4g )0.9999960.999940.9999990.9999880.9998230.9999830.9999830.9996810.9998890.9998950.9996380.9997870.9999710.9990970.999713458Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465Table 12ANOVA on the results of 4 algorithms SF2, SF4, SF5, and SF4g in Experiment 4, with agent-based deployments and a problem size of 64. The level ofsignificance required is set to 0.05.Between algorithmsResidualTotalSum ofsquares (SS)5.15015E–062.44542E–052.96043E–05Degrees offreedom (df)3156159Mean square(MS)1.71672E–061.56758E–07F valuep-valueF crit10.95141.4427E–062.6625Table 13ANOVA on the results of 3 algorithms: SF2, SF5, and SF4g in Experiment 4, with agent-based deployments and a problem size of 64. The level of significancerequired is set to 0.05.Between algorithmsResidualTotalSum ofsquares (SS)4.09349E–071.10541E–051.14634E–05Degrees offreedom (df)2117119Mean square(MS)2.04675E–079.44791E–08F valuep-valueF crit2.166350.119173.07376Table 14Experiment 5: Upper bounds and approximation ratios of the different algorithms in setting s1 but with a larger space ratio (3–4).Problemsizen18, a30n24, a40n30, a50Deploymethodnode-basedagent-basedrandom-basednode-basedagent-basedrandom-basednode-basedagent-basedrandom-basedUpperbound0.9732110.9760320.0942530.9806870.9808550.0425010.9832940.9827770.070558Anytime(SF2)0.9810610.973769–0.9790520.980291–0.983260.981894–Tree-based(SF3)0.986470.986316–0.9917920.992817–0.9755020.975746–Disjoint(SF4)0.968550.964855–0.9785240.976784–0.9827230.978989–Split(SF5)0.9989560.999059–0.998660.998752–0.9981310.997898–Group-based(SF4g )0.987070.988083–0.9948610.99174–0.9943580.994035–Computation time. We show the computation times in Fig. 3, where unlike those shown in Experiment 3, the anytimealgorithm SF2 in Experiment 4 converges pretty fast no matter what type of deployment employed. As explained above, inthe resulting deployments in Experiment 4, the locations of many agents in the network are independent of one another.Consequently, we suppose that in Eq. (2), the importance of the sum of each term k (k = 1, . . . , |M|) for the value of Eq. (2)quickly decreases with the increase of k. Therefore, the anytime algorithm can converge faster in Experiment 4 than it didin Experiment 3. Again, the disjoint based algorithm SF4 was found to be the most efficient one.Conclusion. We can conclude that for settings like s4, where there is relatively little overlap between the agents’ loca-tions in deployments, the disjoint-based algorithm SF4 is the best algorithm since it does very well on approximation andalways returns solutions very fast.Experiment 5Experiment 5 repeats Experiment 1 with setting s1 but with an increased space ratio of nodes to agents from 2–3to 3–4. We report the survivability results in Table 14. Compared with the results in Experiment 1 (see Table 1), the firstnoticeable difference in these results is in agent-based and in node-based deployments. In particular, there is a large increasein the upper bounds of the actual survivabilities from 0.3–0.44 (Table 1) to 0.97 (Table 14). Again, we did not include thesurvivabilities returned by the random based deployments in this table since they are relatively very low. Another noticeablechange with the current setting is that the tree based algorithm SF3 is no longer the favorite—it returns lower survivabilitiesthan the split and the group algorithms. Moreover, its accuracy is even lower than the disjoint based algorithm SF4 whenthe problem size is 80.When more resources can be used to accommodate agents on the nodes, there are more valid future networks in thedeployments compared to those in Experiment 1. Consequently, more valid future networks which have high survivabilitiesmay not be included for the computation of SF3. Thus, SF3 in this set of experiments does not perform as well as it did inExperiment 1.Statistical significance. Again we performed ANOVA on the results of each round of the different algorithms. Table 15suggests that the differences of performances w.r.t. solution qualities of the different algorithms are significant since the Fvalue (46.9782) is greater than the critical F value (2.41796).Computation Time. Table 16 shows that SF3 is the most time-consuming algorithm with the problem size of 80 whereit needs 100 times more computation time than the split and the group algorithms.Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465459Table 15ANOVA on the results of five algorithms in Experiment 5 with agent-based deployments and a problem size of 64. The level of significance required is setto 0.05.Between algorithmsResidualTotalSum ofsquares (SS)0.003250.003370.00662Degrees offreedom (df)4195199Mean square(MS)0.000811.730E–05F valuep-valueF crit46.97821.303E–272.41796Table 16Experiment 5: Computation time (in microseconds) using different algorithms in setting s1 but with a larger space ratio (3–4).Problemsizen18, a30n24, a40n30, a50Deploymethodnode-basedagent-basednode-basedagent-basednode-basedagent-basedAnytime(SF2)3367433253117114224809284858143220Tree-based(SF3)Disjoint-based(SF4)1951019460146123148476838123839241171524203024Split(SF5)237222244844457691778744Group-based(SF4g )173415162800247642993481Table 17Recommendations on the selection of the algorithms in different settings and with different criteria.Settings1s4s2, s3, s5s2, s3, s4, s5Resultingdeploymentmany overlaps betweenagents’ locationsfew overlaps betweenagents’ locationsmany or few overlapsbetween agents’ locationsnot many overlapsbetween agents’ locationsSolution requirementRecommendedalgorithmquality and timequality and timequality and timetime is critical, much moreimportant than qualitySF3SF4SF5SF4Conclusion. Compared to the results of Experiment 1, in Experiment 5 the tree based algorithm SF3 is no longer the mostfavorite algorithm. Instead, the split algorithm SF5 outperforms others since it returns high quality solutions in relativelyshort computation time.5.4. Summary and discussionWe provide recommendations for the choice of the algorithms in Table 17,12 assuming either the node-based or theagent-based deployment methods are applied.We show that in settings like s1, where node failures are distributed dramatically and the resources available in thenetwork are very limited, the tree based algorithm SF3 performs extremely well.However as in the case of setting s4 where the node failures are not distributed dramatically, and the deployments arethose where most agents have disjoint locations w.r.t. other agents, the disjoint based algorithm SF4 is the best algorithm.Moreover, SF4 is recommended for applications where fast computation time is the most critical requirement, as long asthe deployments will not result in too many overlaps between agents’ locations (e.g. those generated in setting s1).The group based algorithm SF4g is an improvement of SF4. As a result, SF4g returns a higher survivability than SF4 while ittakes longer time. As in the case of SF4, this algorithm can be applied to environments where agents have disjoint locationson the nodes.The anytime algorithm SF2 can be applied to applications which require flexible adjustments between the solution qualityand the computation time—the solution returned by SF2 can be as accurate as possible as long as the time is affordable.The split algorithm SF5 seems to be a general heuristic algorithm which provides good approximations. However whentime is critical it may be preferable to use a faster heuristic algorithm like SF4.12 We made these recommendations based on the observations of the experimental results. It is possible that they may be inaccurate for some deploy-ments.460Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–4656. Related workWe have introduced a probabilistic survivability model with various algorithms based upon the idea of replication. Inthis section, we first briefly review the work on fault tolerance (and particularly replication) in distributed systems andmulti-agent survivability. We then discuss more replication based approaches in multi-agent systems.6.1. Fault tolerance in distributed systemsFault tolerance is the ability of a system to behave correctly even under the presence of faults. It aims to increase thedependability of a system, i.e., the ability of a system to perform the service that can be justifiably trusted [4] ([3] fordetailed comparison). Fault tolerance has been extensively studied in distributed systems, and it is usually considered as aproperty of the system. Research in fault-tolerant distributed computing aims at making distributed systems more reliableby handling faults in complex computing environments [19]. In order to build a fault tolerant system, the first step is tospecify the faults that the system may be subject to and thus must be tolerant to. Fault detection techniques identify thepresence of an error. Fault handling methods are used for diagnosing faults and eliminating them from the system state. Thechoice of different techniques is strongly dependent upon the underlying fault assumption. We refer to [10,19] for detailedintroductions on fault tolerance techniques in distributed systems.An important characteristic which distinguishes multi-agent systems from traditional distributed systems is autonomy.Autonomy makes MASs more robust. Consequently, fault tolerance techniques that are designed for distributed systems maybe difficult to directly apply to multi-agent systems. Furthermore, it is notoriously difficult to design fault tolerant systems[10], not to mention fault tolerant multi-agent systems due to their autonomy.Replication is a well-known fault tolerance method for distributed systems. Wiesmann et al. [43] review several replica-tion approaches in distributed systems according to (1) failure transparency for clients, and (2) server determinism. Servicesare implemented by multiple replicas on multiple servers. There are mainly three types of replication protocols: activereplication, passive replication, and semi-active replication. The key concept of active replication is that all replicas receiveand process every incoming request from a client concurrently. The replicas are deterministic. Therefore, failures are trans-parent to the clients, since if a replica fails, the others will still process the requests. In contrast to active replication, inpassive replication, only one replica, called a primary replica, is contacted by the clients. The primary replica processes therequests from clients and then sends update messages to all other replicas. The passive replication is able to tolerate thenon-deterministic servers. And it requires less computation resources than the active approach. However, it suffers fromlonger recovery delays when the primary replica fails. Semi-active replication does not involve the determinism problembecause every time replicas need to make a non-deterministic decision, a leader replica makes the choice and sends it tothe others. The selection of the replication protocol is dependent on the environment, such as the failure rate, and theapplication requirements. We refer to [20,43] for more details on replication in distributed systems.The traditional replication based fault tolerant approaches in distributed systems usually define the replication protocolsexplicitly and statically at design time. Recently, dynamic data replication techniques have been investigated. Lin et al. [31]propose a centralized dynamic object replication algorithm which guarantees that at least t copies of the objects exist ina distributed system. Their goal is to minimize the total service cost of all the incoming requests. The t-availability is alsoguaranteed at any time instant as reported by Wolfson et al. in [44].The focus of replication techniques in distributed computing is mainly on replication protocols and algorithms. Our workdiffers from theirs mainly because: (1) we do not develop the replication protocol but introduce a method to measurethe quality of replications; and (2) we require and measure an entire set of agents to survive, rather than consider themindividually as in the approaches of fault tolerant distributed systems.6.2. Multi-agent survivabilityThe concept of survivability was introduced as a means of protecting critical systems. In earlier work, Ellison et al. [13]define survivability as the capability of a system to fulfill its mission, in a timely manner, in the presence of attacks, failures, oraccidents. Knight et al. [25,26] give a more precise definition of survivability based on specification: a system is survivable if itcomplies with its survivability specification. Their definition requires a complete, well designed survivability specification whichcontains six elements. However, there are some major open challenges in applying their definition to multiagent systemssince it is very difficult to define some of the elements in their specification (e.g. such as enumerating all the states thatthe multiagent system might encounter in an open Internet style environment).Survivability has been investigated in the context of multiagent systems recently by the UltraLog project [1,6,7,22]. Ul-traLog aims at ensuring the survivability of military logistics applications which are deployed on a large-scale distributedmulti-agent system in dynamic and hostile environments. In their approach, a set of measures of performance have been usedto determine the overall success of the system, which include, for instance, performance, availability, and integrity. They applya hierarchy of control loops to guide survivability. Their efforts focus on architectural issues. As their survivability solutionsare built on the Cougaar (Cognitive Agent Architecture) framework, in order to apply their approach to survivability, onemust also develop the multi-agent applications on Cougaar and its UltraLog extensions and tools.Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465461As an emerging discipline, survivability builds on related topics, such as fault tolerance, security, reliability, performance,verification and testing. There are multiple dimensions to the survivability of different systems and applications. Thus, theprecise definition of the goals and the measurements of whether or not an application is a “success” or is “survivable”highly depends on the applications. Our approach to multi-agent survivability is distinguished from theirs as follows:• We study survivability in the context of multi-agent systems. We propose a general and intuitive way to define thesurvivability of a multi-agent application.• We developed several survivability algorithms that are able to provide precise measurements of how well multi-agentapplications will survive under different environments.• In contrast to the UltraLog approach where applicability is limited to a specific agent platform, our survivability modelcan be widely and easily applied to various multi-agent applications, independently of the agent’s development plat-form.6.3. Agent replication approachesIntroducing redundant agents into a multi-agent system is an efficient way to improve the survivability of the MAS.Kumar et al. [29] propose an adaptive multi-brokered agent system, which applies replication to a broker agent (or middleagent). As the reduced number of brokers may degrade the system’s performance, they hypothesize that a broker teamcommits to maintain a specified minimum number of brokers. Thus, the system is robust to broker unavailability. However,the number of brokers in their system must be predefined by the broker teams without the guidance of any algorithms. Inaddition, they only consider the potential failures of brokers but ignore the possible faults of the regular agents.Cloning and merging agents to support load balancing is discussed in [11,39]. Fan [14] furnishes each local agent with thecapability of load-balancing. He proposes a BDI mechanism to formally model agent cloning for balancing agent workloads.These agent-cloning approaches mainly target the agent’s overload problem, while we aim to optimally deploy agents sothat the survivability of the multi-agent system can be maximized.In the context of mobile agent systems, survivability focuses on how to avoid the loss of agents during execution. Mishraand Huang [34] introduce a Dependable Mobile Agent System to recover from node and communication failures. Middle agentsare distributed on every node in the network, which monitor the movement of agents and ensure that agents can arriveat their destinations reliably. Their approach deploys the agent replica on each node in the network. However, replicationis expensive. Furthermore, they do not take into account the resource availability on the network. We propose varioussurvivability algorithms to measure the quality of the deployments. Thus, it is possible to guide the agent replication basedon probabilistic notions of node failures—something they do not consider.Marin et al. [32,33] develop a Dynamic Agent Replication framework to design reliable distributed applications. Everyagent in the MAS has a group of replicas, and a replication scheme is applied to each agent. At runtime, each agent cantune its internal parameters such as the number of its replicas. In their framework, the replication costs are assessedby simulations. Fedoruk and Deters [16,17] hide agent replication methods inside each agent. They propose a transparentreplication technique, which makes the group proxy act as an interface between the replicas and the rest of the multi-agentsystem. In this manner, the proxies make the group appear to be a single entity and they control execution and statemanagement of a replicate group. In [33] and [16,17], the importance of replicating agents optimally have been realized andthey intend to minimize the additional complexity and system loads that are introduced by the use of replication. However,due to the lack of quality measurement of replication, in their approaches, it is the MAS designer’s responsibility to decidein advance for each agent, which, how many and where to deploy them.The automatic and adaptive replication methods have been addressed in [5,8,21]. Briot et al. [8,21] propose a replicationframework that allows adaptive control of the replication method, i.e. which and how many copies of agent to replicate,based on the criticality of each agent. In order to measure the criticality of each agent, the authors propose several strategies,such as an agent’s degree of dependence on other agents, the roles in the organization, its plan, etc. After estimating thecriticality of all the agents, the number of replicas of each agent is then computed taking into account the criticality ofagents, the minimum required replicas, and the current available resources. Similarly, Bora et al. [5] decide on the numberof replicas in the system by measuring the agent’s importance. The feedback control theory is used to dynamically evaluatethe criticality of agents, based on the information of failure rates and the agents’ roles. After receiving the criticality valuefrom the feedback control mechanism, each agent in the organization calculates the desired number of replicas and thenstarts to clone or to kill its replicas subject to the available resources. The approaches of [5,8,21] identify the criticality ofeach single agent in the system in order to deploy the agent replicas. However, there is a lack of quality measurement of theresulting deployments as a team of agents. Our approach focuses more on the “application level”, i.e. given a task of MAS,we measure the survivability of this team of agents which work cooperatively to perform the task based on the informationof the possible failures of the hosting nodes. It will be interesting to integrate the information of each agent’s criticality ina MAS into our approach of computing the survivability of the system.In peer-to-peer applications, in order to maintain desired availability, Ranganathan et al. [37] deal with the issues ofdetermining the number of replicas of any file and the location for new replicas. Similar to our model, they express theaverage probability of a node remaining operative, i.e. stability, which includes node failures, communication failures, andthe disconnection of the node from the network. They compute the probability of replicas for each file being unavailable in462Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465the same manner as we calculate the single agent’s survivability. Such computation problem is polynomial solvable. Theydo not study the availability or unavailability of the application which consists of multiple agents or files.6.4. DiscussionIn this paper, we have introduced an abstract probabilistic failure model, by using a disconnect probability function torepresent the probability of the physical failure of a node which may result in the malfunction of its deployed multi-agentapplication. Our assumptions for this failure model are (1) the independence of failures between nodes, and (2) the fullyconnected network. We do not make any further assumptions, such as cause of failures, failure detection method, failurerate, and calculation of the disconnection probability. These, however, can be detailed in the failure model when it is ap-plied to specific applications. For instance, the disconnect probability of a node may be estimated from the statistical data,or be measured by round trip time between this node and others. It may also take into account time in the probabilisticfailure model, as that of [23]. We have shown in Section 2.1 the possible ways to specify the disconnection probability inthe context of the CoAX application, the Skoda application, and Tichy’s ship control application. Furthermore, the second as-sumption about fully connected networks assumed in this paper can be relaxed in some way. For example, given a partiallyconnected agent system, the disconnection of a node can be considered as the event that this node becomes unreachable inthe system. In this way, the model can be used to represent different environments where the MAS application is deployedand works.Our goal in this paper was not to develop a replication scheme for multi-agent systems. Instead, we assume that thedeployment (of replicas) is already given, and we introduce various algorithms to measure the survival level of the deploy-ment. Hence, our approach does not make any hypotheses about the replication protocol and its implementation, such asactive or passive replication, deployment methods, etc. However, we could select and use the existing replication protocolsor deployment methods described in related work for specific applications. For instance, for disaster management or mili-tary applications where a fast recovery delay is critical, the active replication protocol can be chosen, and a fast survivabilityalgorithm can be used to estimate whether the current deployment meets the minimal survival requirement. Another ex-ample is a multi-agent application consisting of highly heterogeneous agents, for which we can apply the methods in [5,8]to deploy replicas subject to the importance of agents. By selecting a proper survivability algorithm, together with thesedeployment methods, we are able to find a high quality multi-agent deployment. Therefore, the contribution of our workis the ability to guide the replication by assessing the resulting deployments associated with the current condition of thefailure model.Likewise, there are many different ways of maintaining consistency amongst multiple replicas of a piece of data orsoftware. In databases, there is a long history of methods [43,44] used to maintain consistency amongst multiple replicas.These are done primarily through the use of checkpointing methods—timestamps adorn changes to the data and consistencyis maintained by using these timestamps to update replicas to maintain consistency. Many papers on MASs distinguishbetween a state that the agent has at a given point in time and the behavior of the agent that is often encoded via certaintypes of rules [40]. In such cases, the state can be stored in a relational database. The rules do not change as the agentoperates and hence, we only need to ensure that the states of different agents are synchronized. The numerous techniquesto synchronize replicated relational databases can now be applied here.Another relevant problem that has been extensively studied is that of understanding when nodes in a network go down[15,28]. Our framework can be used in conjunction with any existing method to determine when a network node goesdown.7. ConclusionKraus et al. [27] were the first to propose a probabilistic notion of fault tolerance of a multi-agent system based uponreplication principles. Their algorithms for solving the most survivable deployment problem (finding a deployment that hasthe highest survival probability) include two elements:(1) An algorithm to solve the deployment survivability problem (measuring the survival probability of a given deploy-ment) under the assumption that we are ignorant about the relationships between node failures in a network and(2) An algorithm that uses the previous algorithm to find the deployment that has the highest probability of survival.In this paper, we have focused on the deployment survivability problem, and we have studied this problem under theassumption of independence of node failures. We have made the following contributions.(1) We have proven that the deployment survivability problem is at least NP-hard (under the independence assumption)and hard to approximate up to a factor of 2|V |1−(cid:2).(2) We have proven that the most survivable deployment problem is at least NP-hard (under the independence assump-tion). Moreover, we have proven that any polynomial-time approximation algorithm is bound to provide maximallybad answers in some cases unless P = NP.Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465463(3) We then presented two algorithms to accurately compute the probability of survival of a given deployment. One ofthese algorithms is exponential in the number of agents, while the other is exponential in the number of nodes inthe network. Thus, if one of these quantities is small, we can use this algorithm to accurately compute the survivalprobability of a deployment.(4) We then presented a set of five different heuristic algorithms to compute the survival probability of a deployment.(5) Finally we have compared the performance of our algorithms according to the quality of the solution found (i.e.how close the solution found by the heuristic is to either the correct solution or to a bound on the solution incases where the solution cannot be accurately computed) and in terms of computation time. In all cases, we triedto use statistical significance tests to determine if our inferences had statistical significance. We did this under fivedifferent environmental settings. Our results show that the performance of most of the algorithms, namely the tree-based algorithm SF3, the disjoint based algorithm SF4, the group based algorithm SF4g , and the anytime algorithmSF2, vary greatly with the environment settings—that is, each of these algorithms is appropriate for certain settings,but not for others. In contrast, the split algorithm SF5 has demonstrated a relatively stable performance in terms ofquality. Nonetheless its running time is dependent on the setting and the problem size.In addition, we believe some existing MAS replication frameworks may benefit from the proposed algorithms in orderto compute the survival level of the resulting deployments, and thus result in better fault tolerant multi-agent systems.Integrating the proposed method into existing replication frameworks would be interesting to address in future work.One problem with the approach described in this paper is that it is static in the sense that it does not adapt to changesthat affect the survivability of the MAS. However, it provides a basis for the development of an adaptive approach. Anadaptive approach cannot be built without learning how to compute the survival probability of a candidate deployment.For instance, if there is any change or failure in the network, the algorithms proposed in this paper could be used to firstquickly check if the survivability of the current deployment is too low (or invalid). If this is the case, the algorithms thencalculate a better new deployment according to the new environment parameters, and agents could be re-deployed to newlocations accordingly. In this manner, we would be able to ensure maximal survivability of an agent application in dynamic,changing environments.A second problem of the developed survivability algorithms is that they are centralized. So even though the agents aredistributed across the network, the survivability algorithm itself resides on a single node. One solution to this problemcould be distributed algorithms which are built on top of the centralized survivability algorithm. We are currently workingon such an extended distributed, adaptive approach, based on our previous work [41].A third major topic for future work would be to use a mixture of assumptions when computing the probability of sur-vival of a MAS. As this paper shows through the CoAX example, the Skoda example, and the ship onboard control example,in many applications, there is a mixture of assumptions about node failures that can be used. For example, in the CoAXexample, node failures in the UK and US may be independent of node failures of sensor nodes. However, there may bedependencies between failures of sensor nodes. One way to do this would be to adapt probabilistic conjunction strategies(PCSs) proposed in [30] as an extension of the notion of a triangular norm [24]. PCSs are functions satisfying certain axiomsthat provide methods to compute the tightest probability interval of an event (e1 ∧ e2) given a probability interval for eachof e1, e2. Lakshmanan et al. [30] propose a set of axioms that PCSs must obey. They show that the ignorance (of node fail-ures) assumption used in [27] and the independence assumption used in this paper are both special cases of PCSs. Futurework could examine how to replace disconnect probability functions proposed in this paper with an extended disconnectprobability function epd that expresses statements such as edp(n1) = 0.3 denoting that n1’s disconnect probability is 0.3,epd(n1 ∧ n2) = epd(n1) ⊗ epd(n2) where ⊗ is a conjunction strategy. Thus, the syntax used to represent epd’s would allowjoint probabilities to be specified. A disconnect probability specification would then be a set of equations of the form men-tioned above. A major challenge would be to extend the methods and results of this paper when a disconnect probabilityspecification of this type is used.There are many other interesting directions for future work that are related to this topic. In many real-world applica-tions, it is essential to maintain a minimal level of survival. Thus, one variant of the current approach would be to developalgorithms for deployments that meet such minimal survival requirements. Another topic would be to study the survivabil-ity of a dynamically changing multi-agent system, instead of a fixed one. This could be useful for multi-agent applicationswhere agents are connected intermittently. Another issue is the trade-off between the survivability of a multi-agent systemand its performance. Ensuring survivability could be costly due to, for example, state synchronization among replicas andcomputing survivability. Consequently this comes at the cost of actually providing the services the multi-agent system issupposed to provide. Such problems are significant for multi-agent applications with scarce resources. Thus, it would beworthwhile to study how these two concerns could be balanced.Yet another important issue is “gaming” the system. For example, suppose the methods described in this paper are usedto implement MAS security for an application. A user who knows that the techniques of this paper are used in the systemcan try to utilize this knowledge in order to break security. This leads to a game theoretic framework whereby we needto reason about how an adversary would make use of such knowledge in order to break the system. The root node of thegame tree consists of the state of the system. The children of the node refer to the possible states resulting from an actionthat an adversary could take. The system then needs to make a “move” in order to determine how best to respond to theuser’s action. This is an important area which we plan to study in the future.464Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465References[1] Ultralog program site, http://www.ultralog.net.[2] D. Allsop, P. Beautement, M. Kirton, J. Bradshaw, N. Suri, E. Durfee, C. Knoblock, A. Tate, C.W. Thompson, Coalitions agent experiment: Multiagentcooperation in International Coalitions, IEEE Intelligent Systems 17 (3) (2002) 26–35.[3] A. Avizienis, J. Laprie, B. Randell, Fundamental concepts of dependability, in: Proceedings of the Third International Workshop on Information Security,ISW, 2000.[4] A. Avizienis, J.-C. Laprie, B. Randell, C. Landwehr, Basic concepts and taxonomy of dependable and secure computing, IEEE Transactions on Dependableand Secure Computing 01 (1) (2004) 11–33.[5] S. Bora, O. Dikenelli, Applying feedback control in adaptive replication mechanisms in fault tolerant multi-agent organizations, in: SELMAS ’06: Pro-ceedings of the 2006 International Workshop on Software Engineering for Large-Scale Multi-Agent Systems, New York, NY, USA, ACM, 2006, pp. 5–12.[6] M. Brinn, J. Berliner, A. Helsinger, T. Wright, M. Dyson, S. Rho, D. Wells, Extending the limits of DMAS survivability: The ultralog project, IEEE IntelligentSystems 19 (5) (2004) 53–61.[7] M. Brinn, M. Greaves, Leveraging agent properties to assure survivability of distributed multi-agent systems, in: AAMAS ’03: Proceedings of the SecondInternational Joint Conference on Autonomous Agents and Multiagent Systems, New York, NY, USA, ACM, 2003, pp. 946–947.[8] J.-P. Briot, Z. Guessoum, S. Aknine, A.L. Almeida, J. Malenfant, O. Marin, P. Sens, N. Faci, M. Gatti, C. Lucena, Experience and prospects for variouscontrol strategies for self-replicating multi-agent systems, in: SEAMS ’06: Proceedings of the 2006 International Workshop on Self-Adaptation andSelf-Managing Systems, New York, NY, USA, ACM, 2006, pp. 37–43.[9] T.H. Cormen, C.E. Leiserson, R.L. Rivest, Introduction to Algorithms, MIT Press, New York, 1990.[10] F. Cristian, Understanding fault-tolerant distributed systems, Communications of the ACM 34 (2) (1991) 56–78.[11] K. Decker, K.P. Sycara, M. Williamson, Cloning in intelligent, adaptive information agents, in: C. Zhang, D. Lukose (Eds.), Multi-Agent Systems: Method-ologies and Applications, Springer-Verlag, 1997, pp. 63–75.[12] J.L. Devore, Probability and Statistics for Engineering and the Sciences, 4th edition, Wadsworth Publishing, 1995.[13] R.J. Ellison, D.A. Fisher, R.C. Linger, H.F. Lipson, T.A. Longstaff, N.R. Mead, Survivability: Protecting your critical systems, IEEE Internet Computing 3 (6)(1999) 55–63.[14] X. Fan, On splitting and cloning agents, Technical Report 407, Turku Center for Computer Science, Turku, Finland, 2001.[15] F. Feather, D. Siewiorek, R. Maxion, Fault detection in an Ethernet network using anomaly signature matching, in: Proceedings of the InternationalConference on Communications architectures, protocols and applications, September 13–17, 1993, San Francisco, CA, USA, pp. 279-288.[16] A. Fedoruk, R. Deters, Improving fault-tolerance by replicating agents, in: C. Castelfranchi, W.L. Johnson (Eds.), Proceedings of First International JointConference on Autonomous Agents and Multi-Agent Systems, Bologna, Italy, ACM Press, 2002, pp. 737–744.[17] A. Fedoruk, R. Deters, Using dynamic proxy agent replicate groups to improve fault-tolerance in multi-agent systems, in: AAMAS ’03: Proceedings ofthe Second International Joint Conference on Autonomous Agents and Multiagent Systems, New York, NY, USA, ACM, 2003, pp. 990–991.[18] J. Galambos, I. Simonelli, Bonferroni-type Inequalities with Applications. Probability and its Applications, Springer-Verlag, 1996.[19] F.C. Gartner, Fundamentals of fault-tolerant distributed computing in asynchronous environments, ACM Computing Surveys 31 (1) (1999) 1–26.[20] R. Guerraoui, A. Schiper, Software-based replication for fault tolerance, IEEE Computer 30 (4) (April 1997) 68–74.[21] Z. Guessoum, N. Faci, J.-P. Briot, Adaptive replication of large-scale multi-agent systems: towards a fault-tolerant multi-agent platform, SIGSOFT Softw.Eng. Notes 30 (4) (2005) 1–6.[22] A. Helsinger, K. Kleinmann, M. Brinn, Framework to control emergent survivability of multi-agent systems, in: AAMAS ’04: Proceedings of the ThirdInternational Joint Conference on Autonomous Agents and Multiagent Systems, Washington, DC, USA, IEEE Computer Society, 2004, pp. 28–35.[23] F. Klein, M. Tichy, Building reliable systems based on self-organizing multi-agent systems, in: SELMAS ’06: Proceedings of the 2006 InternationalWorkshop on Software Engineering for Large-Scale Multi-Agent Systems, Shanghai, China, ACM, 2006, pp. 51–58.[24] E.P. Klement, R. Mesiar, E. Pap, Triangular Norms, Kluwer Academic Publishers, ISBN 0-7923-6416-3, 2000.[25] J.C. Knight, E.A. Strunk, Achieving critical system survivability through software architectures, in: Architecting Dependable Systems II, in: Lecture Notesin Computer Science, vol. 3069, Springer, 2004, pp. 51–78.[26] J.C. Knight, K.J. Sullivan, M.C. Elder, C. Wang, Survivability architectures: Issues and approaches, in: DARPA Information Survivability Conference andExposition, Los Alamitos, CA, IEEE Computer Society Press, 2000, pp. 157–171.[27] S. Kraus, V.S. Subrahmanian, N.C. Tacs, Probabilistically survivable MASs, in: G. Gottlob, T. Walsh (Eds.), IJCAI-03, Proceedings of the Eighteenth Inter-national Joint Conference on Artificial Intelligence, Acapulco, Mexico, August 9–15, 2003, Morgan Kaufmann, 2003, pp. 789–795.[28] B. Krishnamurthy, S. Sen, Y. Zhang, Y. Chen, Sketch based change detection: Methods, evaluation and application, in: Proc. 3rd ACM SIGCOMM Confer-ence on Internet Measurement. Miami Beach, FL, 2003, pp. 233–247.[29] S. Kumar, P.R. Cohen, H.J. Levesque, The adaptive agent architecture: Achieving fault-tolerance using persistent broker teams, in: E. Durfee (Ed.), TheFourth International Conference on Multi-Agent Systems (ICMAS 2000), IEEE Press, 2000, pp. 159–166.[30] V.S. Lakshmanan, N. Leone, R. Ross, V.S. Subrahmanian, Probview: A flexible probabilistic database system, ACM Transactions on Database Sys-tems 22 (3) (1997) 419–469.[31] W.J. Lin, B. Veeravalli, A dynamic object allocation and replication algorithm for distributed systems with centralized control, Int. J. Comput. Appl. 28 (1)(2006) 26–34.[32] O. Marin, M. Bertier, P. Sens, DARX—a framework for the fault-tolerant support of agent software, in: ISSRE ’03: Proceedings of the 14th InternationalSymposium on Software Reliability Engineering, Washington, DC, USA, IEEE Computer Society, 2003, pp. 406–418.[33] O. Marin, P. Sens, J.-P. Briot, Z. Guessoum, Towards adaptive fault tolerance for distributed multi-agent systems, in: Proceedings of the 3rd EuropeanResearch Seminar on Advanced Distributed Systems (ERSADS’2001), 2001, pp. 195–201.[34] S. Mishra, Y. Huang, Fault tolerance in agent-based computing systems, in: Proceedings of the 13th ISCA International Conference on Parallel andDistributed Computing Systems, 2000, pp. 413–426.[35] R. Mittu, R. Ross, Building upon the coalitions agent experiment (coax)—integration of multimedia information in gccs-m using impact, in: Proceedingsof the 9th International Workshop on Multimedia Information Systems Ischia, Italy, pp. 35–44.[36] M. Pechoucek, V. Marik, Review of industrial deployment of multi-agent systems, Technical Report, Gerstner Laboratory, Agent Technology Group,Department of Cybernetics, Czech Technical University in Prague, Czech Republic and Rockwell Automation Research Center, Prague, Czech Republic,http://agents.felk.cvut.cz/teaching/33ui2/on-applications.pdf.[37] K. Ranganathan, A. Iamnitchi, I. Foster, Improving data availability through dynamic model-driven replication in large peer-to-peer communities, in:CCGRID ’02: Proceedings of the 2nd IEEE/ACM International Symposium on Cluster Computing and the Grid, Washington, DC, USA, IEEE ComputerSociety, 2002, p. 376.[38] D. Roth, On the hardness of approximate reasoning, Artificial Intelligence 82 (1–2) (1996) 273–302.[39] O. Shehory, K.P. Sycara, P. Chalasani, S. Jha, Increasing resource utilization and task performance by agent cloning, in: ATAL ’98: Proceedings of the 5thInternational Workshop on Intelligent Agents V, Agent Theories, Architectures, and Languages, London, UK, Springer-Verlag, 1999, pp. 413–426.[40] V.S. Subrahmanian, P. Bonatti, J. Dix, T. Eiter, S. Kraus, F. Ozcan, R. Ross, Heterogeneous Agent Systems, MIT Press, Cambridge, MA, 2000.Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465465[41] V.S. Subrahmanian, S. Kraus, Y. Zhang, Distributed algorithms for dynamic survivability of multiagent systems, in: Proc. Computational Logic in Multi-Agent Systems: 4th International Workshop, CLIMA IV, in: Lecture Notes in Computer Science, vol. 3259, Springer-Verlag, 2004, pp. 1–15.[42] P. Tichy, P. Slechta, F. Maturana, S. Balasubramanian, Industrial MAS for Planning and Control, Lecture Notes in Computer Science, vol. 2322, Springer-Verlag.[43] M. Wiesmann, F. Pedone, A. Schiper, B. Kemme, G. Alonso, Understanding replication in databases and distributed systems, in: T.-H. Lai (Ed.), Proceed-ings of 20th International Conference on Distributed Computing Systems (ICDCS’2000), IEEE Computer Society Technical Committee on DistributedProcessing, 2000, pp. 264–274.[44] O. Wolfson, S. Jajodia, An algorithm for dynamic data distribution, in: Workshop on the Management of Replicated Data, 1992, pp. 62–65.[45] Y. Zhang, E. Manister, S. Kraus, V.S. Subrahmanian, Approximation results for probabilistic survivability, in: Second IEEE Symposium on Multi-AgentSecurity and Survivability, Philadelphia, USA, 2005, pp. 1–10.