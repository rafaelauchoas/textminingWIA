Artificial Intelligence 172 (2008) 1429–1469Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMaintenance goals of agents in a dynamic environment: Formulation andpolicy construction ✩Chitta Baral a,∗, Thomas Eiter c, Marcus Bjäreland b, Mutsumi Nakamura aa Department of Computer Science and Engineering, Arizona State University, Tempe, AZ 85287, USAb AstraZeneca R&D, S-43183 Mölndal, Swedenc Institute of Information Systems, Vienna University of Technology, A-1040 Vienna, Austriaa r t i c l ei n f oa b s t r a c tArticle history:Received 25 September 2005Received in revised form 3 March 2008Accepted 18 March 2008Available online 3 April 2008Keywords:Maintenance goalsk-maintainabilityAgent controlComputational complexity of agent designAnswer set programmingHorn theoriesSAT solvingDiscrete event dynamic systemsSelf-stabilizationThe notion of maintenance often appears in the AI literature in the context of agentbehavior and planning. In this paper, we argue that earlier characterizations of the notionof maintenance are not intuitive to characterize the maintenance behavior of certain agentsin a dynamic environment. We propose a different characterization of maintenance anddistinguish it from earlier notions such as stabilizability. Our notion of maintenance is moresensitive to a good-natured agent which struggles with an “adversary” environment, whichhinders her by unforeseeable events to reach her goals (not in principle, but in case). It hasa parameter k, referring to the length of non-interference (from exogenous events) neededto maintain a goal; we refer to this notion as k-maintainability. We demonstrate the notionon examples, and address the important but non-trivial issue of efficient constructionof maintainability control functions. We present an algorithm which in polynomial timeconstructs a k-maintainable control function, if one exists, or tells that no such controlis possible. Our algorithm is based on SAT Solving, and employs a suitable formulationof the existence of k-maintainable control in a fragment of SAT which is tractable. Forsmall k (bounded by a constant), our algorithm is linear time. We then give a logicprogramming implementation of our algorithm and use it to give a standard proceduralalgorithm, and analyze the complexity of constructing k-maintainable controls, underdifferent assumptions such as k = 1, and states described by variables. On the one hand,our work provides new concepts and algorithms for maintenance in dynamic environment,and on the other hand, a very fruitful application of computational logic tools. We compareour work with earlier works on control synthesis from temporal logic specification andrelate our work to Dijkstra’s notion of self-stabilization and related notions in distributedcomputing.© 2008 Elsevier B.V. All rights reserved.✩A preliminary version of the formulation part, entitled “A formal characterization of maintenance goals”, has been presented at AAAI’00, and apreliminary version of the algorithm part entitled “A polynomial time algorithm for constructing k-maintainable policies” has been presented at ICAPS’04.The current version revises and combines both of them with additional elaborations, examples, results, and proofs. The major part of the algorithms wasdone when Chitta Baral was visiting Vienna University of Technology in 2003. Marcus Bjäreland carried out the major part of his work while he was withthe Department of Computer and Information Science of Linkoping University.* Corresponding author.E-mail addresses: chitta@asu.edu (C. Baral), eiter@kr.tuwien.ac.at (T. Eiter), marcus.bjareland@astrazeneca.com (M. Bjäreland), mutsumi@asu.edu(M. Nakamura).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.03.0051430C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691. Introduction and motivationFor an agent situated in a static environment, the goal is often to reach one out of several states where certain conditionsare satisfied. Such a goal is usually expressed by a formula in propositional or first-order logic. Sometimes the goal requiresconstraining the path taken to reach one of the states. In that case, the goal can be expressed by a formula in temporallogic [3,7,54].Our concern in this paper is about agents in a dynamic environment. In that case, things are more complex since thestate of the world can change through both actions of the agent and of the environment. The agent’s goal in a dynamicenvironment is then often more than just achieving a desired state, as after the agent has successfully acted to reach adesired state, the environment may change that state. In such a case, a common goal of an agent is to ‘maintain’ rather thanjust ‘achieve’ certain conditions. The goal of maintaining certain conditions (or a set of states that satisfy these conditions)is referred to as maintenance goals. Maintenance goals are well-known in the AI literature, e.g., [3,27,41,55,67], and havecounterparts in other areas such as in stability theory of discrete event dynamic systems [56,58,61,62,66] and in activedatabases [17,51]. However, as we argue in this paper, earlier characterizations of maintenance goals are not adequate underall circumstances.To see what is wrong with earlier definition of maintenance goals, suppose an agent’s goal is to maintain a fluent f ,i.e., the proposition f should be true. A straightforward attempt1 to express it using temporal operators is the formula(cid:2) f , where (cid:2) is the temporal operator “Always” and (cid:2) f means that fis true in all the future states of the world. This istoo strong a condition, as maintaining inherently means that things go out of shape and they have to be maintained backto shape. A better temporal logic representation of this goal is thus the formula (cid:2)(cid:3) f , where (cid:3) is the temporal operator“Eventually”. Intuitively, the formula (cid:2)(cid:3) fis satisfied by an infinite trajectory of states of the form s0, s1, s2, . . . , if at anystage i (cid:2) 0, there exists some stage j (cid:2) i such that fis true in s j . An agent’s control is said to satisfy (cid:2)(cid:3) f if all trajectoriesthat characterize the evolution of the world due to the environment and the agent’s control satisfy (cid:2)(cid:3) f . At first glance the formula(cid:2)(cid:3) f seems to express the goal of maintaining f , as it encodes that if f becomes f alse in any state in the trajectory thenit becomes true in a later state.We consider (cid:2)(cid:3) f to be also too strong a specification—in many situations—to express the intuitive notion of ‘main-taining f ’, if we take on a more refined view of the (sometimes nasty) part which the environment might play, which weillustrate by some examples. Suppose f denotes the condition that the Inbox of a customer service department be empty.Here the environment makes f false by adding new requests to the Inbox while the agent tries to make f true by process-ing the messages in the Inbox and removing them from it. If the agent is diligent in processing the message in the Inboxand makes it empty every chance the agent gets, we would then like to say that agent maintains the Inbox empty. But sucha control does not satisfy the formula (cid:2)(cid:3) f under all circumstances, because there will be trajectories where the agent isoverwhelmed by the environment (flooding the Inbox) and f never becomes true.Another example in support of our intuition behind maintainability is the notion of maintaining the consistency of adatabase [17,51,68]. When direct updates are made to a database, maintaining the consistency of the database entails thetriggering of additional updates that may bring about additional changes to the database so that in the final state (after thetriggering is done) the database reaches a consistent state. This does not mean that the database will reach consistency ifcontinuous updates are made to it and it is not given a chance to recover. In fact, if continuous update requests are madewe may have something similar to denial of service attacks. In this case we can not fault the triggers saying that they donot maintain the consistency of the database. They do. It is just that they need to be given a window of opportunity or arespite from continuous harassment from the environment to bring about the additional changes which are necessary torestore database consistency. The same holds for maintaining a room clean; we can not fault the cleaning person if he orshe is continually sent away because the room is being continuously used.Another example is a mobile robot [15,47] which is asked to ‘maintain’ a state where there are no obstacles in front of it.Here, if there is a belligerent adversary that keeps on putting an obstacle in front of the robot, there is no way for the robotto reach a state with no obstacle in front of it. But often we will be satisfied if the robot avoids obstacles in its front whenit is not continually harassed. Of course, we would rather have the robot take a path that does not have such an adversary,but in the absence of such a path, it would be acceptable if it takes an available path and ‘maintains’ states where there areno obstacles in front.The inadequacy of the expression (cid:2)(cid:3) fis defined ontrajectories which do not distinguish between transitions due to agent actions and environment actions. Thus we can notdistinguish the casesin expressing our intuition about ‘maintaining f ’ is because (cid:2)(cid:3) f(i) where the agent does its best to maintain f (and is sometimes thwarted by the environment) and can indeed make ftrue in some (say, k) steps if there is no interference from the environment during those steps; and(ii) where the agent really does not even try.1 All through the paper we consider the evaluation of linear temporal formulas with respect to all ‘valid’ trajectories. An alternative approach would beto use a variation of the branching time quantifier A, such as the operator Aπ from [9], before the linear temporal formulas. Another alternative approach,referred to as boolean task specification, is used in [27,28,69].C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691431We refer to (i) as k-maintainability in this paper. The expression (cid:2)(cid:3) f can not express the idea of a window of opportunity(or window of non-interference) during which an agent can perform the actions necessary for maintaining. In fact, none ofthe standard notions of temporal logics [20,48], which are defined on trajectories that do not distinguish between the causebehind the transitions (whether they are due to agent’s actions or due to the environment),2 can express the idea behindk-maintainability.The main contributions of this paper can be summarized as follows.1. We introduce and formally define the notion of k-maintainability, and distinguish it from earlier notions of maintain-ability, in particular the specification (cid:2)(cid:3) f and the similar notion of stabilizability from discrete event dynamic systems.2. We provide polynomial time algorithms that can construct k-maintainable control policies, if one exists. (In the restof the paper we will refer to ‘control policy’ simply by ‘control’.) Our algorithm is based on SAT Solving, and employsa suitable formulation of the existence of k-maintainable control in a tractable fragment of SAT. We then give a logicprogramming implementation of this method, and finally distill from it a standard procedural algorithm. We brieflydiscuss earlier approaches to controller synthesis [1,10,19,41,49,60] with respect to temporal logic specifications andcompare their complexity with that of our algorithms.3. We analyze the computational complexity of constructing k-maintainable controls, under different settings of the en-vironment and the windows of opportunity open to the agent, as well as under different forms of representation. Weshow that the problem is complete for PTIME in the standard setting, where the possible states are enumerated, andcomplete for EXPTIME in a STRIPS-style setting where states are given by value assignments to fluents. Furthermore,we elucidate the impact of the different factors and show, by our proofs of the hardness results, that the full problemcomplexity is inherent already to certain restricted cases.Overall, our work not only provides new concepts and algorithms for realizing maintenance of an agent in dynamicenvironment, but also illustrates a very fruitful application of computational logic tools.The rest of this paper is organized as follows. In Section 2 we present the background definitions of a system with anagent in an environment and define the notions of stability and stabilizability. In Section 3 we describe an example of asystem with two buffers. We use this example for illustrating the concepts of stabilizability and k-maintainability, whichis formally defined in Section 4. In Section 5 we present our algorithms for constructing k-maintaining controls, based onSAT Solving as well as a genuine algorithm extracted from it. In Section 6 we present an encoding for computing a controlfunction using a logic programming engine and devote Section 7 to complexity analysis. Finally, in Section 8 we presentsome experimental results, discuss related work, and outline some future directions.2. Background: Systems, goals, control, stability and stabilizabilityIn this paper, we are concerned with goal-directed agents in a dynamic world. Such agents can perform actions thatchange the state of the world. Because of the dynamic nature of the world, certain changes can happen to the state of theworld beyond the control of an agent. The agent’s job is thus to make the world evolve in a way coherent with a goalassigned to it. As for the agent control, we adopt here that an agent follows a Markovian control policy to do its job; thatis, its control is a function from the set of states to the set of actions, detailed as follows.Definition 1 (System). A system is a quadruple A = (S, A, Φ, poss), where• S is a finite set of system states;• A is a finite set of actions, which is the union of the set of agents actions, Aag, and the set of environmental actions,Aenv;S• Φ : S × A → 2to actions; and• poss : S → 2Ais a non-deterministic transition function that specifies how the state of the world changes in responseis a function that describes which actions are possible to take in which states.The above notion of system is used in the discrete event dynamic systems community, for instance in [56,58,61,62,66].In practice, the functions Φ and poss are required to be effectively (and efficiently) computable, and they may often bespecified in a representation language such as in [32,34,63]. The possibility of an action has different meaning dependingon whether it is an agent’s action or whether it is an environmental action. In case of an agent’s action, it is often dictatedby the policy followed by the agent. For environmental actions, it encodes the various possibilities that are being accountedfor in the model. We tacitly assume here that possible actions lead always to some successor state, i.e., the axiom thatΦ(s, a) (cid:4)= ∅ whenever a ∈ poss(s) holds for any state s and action a, is satisfied by any system.2 If one distinguishes the cause behind transitions, then temporal logic can indeed be used to express maintainability. We discuss this further in Sec-tion 4.1.1432C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469Fig. 1. S = {b, c, d, f , g, h}, A = {a, a(cid:7), e}, Aag = {a, a(cid:7)}, Aenv = {e}, Φ is as shown.An example of a system A = (S, A, Φ, poss), where S = {b, c, d, f , g, h}, A = {a, ashown in Fig. 1, where sleaving s. Notice that in this example, Φ(s, a) is deterministic, i.e., Φ(s, a) is a singleton if nonempty.The evolution of the world with respect to a system is characterized by the following definition.(cid:7) ∈ Φ(s, a) iff an arc s → s(cid:7)(cid:7), e}, and the transition function Φ islabeled with a is present and poss(s) are all actions that label arcsDefinition 2 (Trajectory). Given a system A = (S, A, Φ, poss), an alternating infinite sequence of states and actionss0, a1, s1, a2, . . . , sk, ak+1, sk+1, . . . is said to be a trajectory consistent with A, if sk+1 ∈ Φ(sk, ak+1), and ak+1 ∈ poss(sk).The above notion of trajectory does not require that agent actions and environment actions be interleaved as is donein formulations of games. It allows one agent action to be followed by multiple environment actions and vice-versa, as inreal worlds we do not have an arbiter who can enforce the alternation of the agent and environment actions. The notionassumes that the time points are fine enough that at any point only one action can occur. Thus, it does not allow explicitoccurrence of agent and environment actions at the same time.A common restriction on how the world evolves is defined using the notion of stability. The following definition ofstability is adapted from [56] and has its origin in control theory and discrete event dynamic systems [56,58,61,62].Definition 3 (Stable state 1). Given a system A = (S, A, Φ, poss) and a set of states E, a state s is said to be stable in A w.r.t.E if all trajectories consistent with A and starting from s visit E infinitely often. A set of states S is stable with respect toE if all states in S are stable with respect to E.We say A = (S, A, Φ, poss) is a stable system, if all states in S are stable in A with respect to E.Although the above definition of stability is with respect to a set of states E, it can be easily adapted to a propositionalformula ϕ that can be evaluated at the states of system A. In that case E = {s ∈ S | A, s |(cid:8) ϕ}, where A, s |(cid:8) ϕ denotes thats in A satisfies (in the propositional logic sense) ϕ. Thus, E is the set of states s at which ϕ is satisfied.An alternative approach to characterize the evolution of states is through temporal operators. Some of the importanttemporal operators talking about the future are (cf. [30,48]): Next ((cid:9)), Always ((cid:2)), Eventually ((cid:3)), and Until (U ). Theirmeaning with respect a trajectory τ = s0, a1, s1, . . . , sk, ak+1, sk+1, . . . is defined as follows.Let (τ , j), for j (cid:2) 0, denote the remainder of τ starting at s j ; then• (τ , j) |(cid:8) p iff p is true in s j , for any proposition p;• (τ , j) |(cid:8) (cid:9)φ iff (τ , j + 1) |(cid:8) φ;• (τ , j) |(cid:8) (cid:2)φ iff (τ , k) |(cid:8) φ, for all k (cid:2) j.• (τ , j) |(cid:8) (cid:3)φ iff (τ , k) |(cid:8) φ, for some k (cid:2) j.• (τ , j) |(cid:8) φ1 U φ2 iff there exists k (cid:2) j such that (τ , k) |(cid:8) φ2 and for all i, j (cid:3) i < k, (τ , i) |(cid:8) φ1.The standard Boolean connectives ∧, ∨, and ¬ are defined as usual. An alternative definition of stability can then begiven as follows:Definition 4 (Stable state 2). Given a system A = (S, A, Φ, poss) and an objective formula ϕ (i.e., without temporal oper-ators), let Eφ = {s ∈ S | A, s |(cid:8) φ}. A state s is then said to be stable in A w.r.t. E if for all trajectories τ of the formτ = s0, a1, s1, . . . , sk, ak+1, sk+1, . . . (where s0 = s) consistent with A, it holds that (τ , 0) |(cid:8) (cid:2)(cid:3)ϕ.In fact, this definition is equivalent to Definition 3. The advantage of using temporal operators, as in the above definition,instead of Definition 3 is that the former allows us to specify a larger class of goals and build on top of the notion ofstability. For example, a notion similar to stability, referred to as a response property [48], is of the form (cid:2)(p → (cid:3)q).C. Baral et al. / Artificial Intelligence 172 (2008) 1429–146914332.1. StabilizabilityThe notion of stability is defined with respect to a system and the evolution of the world consistent with the system.When we focus on an agent and its ability to make a system stable, we need a notion of stabilizability which intuitivelymeans that there exists a control policy which the agent can use to fashion a stable system.Given a system A = (S, A, Φ, poss), when discussing stabilizability of the system, we need to consider the followingadditional aspects:• the set of actions Aag which the agent is capable of executing in principle (where Aag ⊆ A);• the set of exogenous actions that may occur in the state s, beyond the agent’s control, modeled by a function exo : S →Aenv , where exo(s) ⊆ poss(s) for each state s (recall that Aenv are the environmental actions). We call any such exo an2exogenous function.Intuitively, given a system A = (S, A, Φ, poss), Aag, exo, and E, a state s is stabilizable with respect to E, if we are able tofind a policy or control function such that it makes the resulting system stable and the agent starting from s following thatpolicy will not reach a state where no further actions are possible.The last condition is referred to as aliveness. It is formally defined by the following two definitions, the first of whichdefines the set R( A, s) of states that can be reached from s in the system A.Definition 5 (Closure). Given a system A = (S, A, Φ, poss) and a state s, R( A, s) ⊆ S is the smallest set of states thatsatisfying the following conditions:1. s ∈ R( A, s),2. If s(cid:7) ∈ R( A, s), and a ∈ poss(s(cid:7)), then Φ(s(cid:7), a) ⊆ R( A, s).For any set of states S ⊆ S, the closure of A w.r.t. S is defined byClosure(S, A) =(cid:2)s∈SR( A, s).Example 1. In the system A in Fig. 1, we have that R( A, d) = {d, h} and R( A, f ) = { f , g, h}, and therefore Closure({d, f }, A)= {d, f , g, h}. This is illustrated in Fig. 2.Note that Closure(S, A) satisfies the Kuratowski closure axioms [43], that is, Closure(∅, A) = ∅; S ⊆ Closure(S, A);Closure(Closure(S, A), A) = Closure(S, A); and, moreover, Closure(S1 ∪ S2, A) = Closure(S1, A) ∪ Closure(S2, A). Furthermore,Φ(s, a) ⊆ Closure(S, A) holds for each state s ∈ Closure(S, A) and a ∈ poss(s).Definition 6 (Aliveness). Given a system A = (S, A, Φ, poss) and a state s, we say s is alive if poss(sWe say A = (S, A, Φ, poss) is alive if all states in S are alive.(cid:7)) (cid:4)= ∅, for all s(cid:7) ∈ R( A, s).The notion of control function is formally defined as follows.Fig. 2. R( A, d) = {d, h} and R( A, f ) = { f , g, h}, and Closure({d, f }, A) = {d, f , g, h}.1434C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469Fig. 3. Policy K is doing a in states b, c, d and f ; poss(b) = {a, a(cid:7)}; possK ,exo(b) = {a}; Closure({b, c}, A) = {b, c, d, f , g, h}; Closure({b, c}, A K ,exo) = {b, c, d, h}.Definition 7 (Control). Given a system A = (S, A, Φ, poss) and a set Aag ⊆ A of agent actions, a control function for A w.r.t.Aag is a partial functionK : S → Aag,such that K (s) ∈ poss(s) whenever K (s) is defined.3We are now ready to formally define the notion of stabilizability.Definition 8 (Stabilizability). Given a system A = (S, A, Φ, poss), a set Aag ⊆ A, a function exo as above, and a set of statesE, we say that s ∈ S is stabilizable with respect to E, if there exists a control function K : S → Aag for A w.r.t. Aag with thefollowing properties:1. s is stable with respect to E in the system A K ,exo = (S, A, Φ, possK ,exo), where, for any state sexo(s(cid:7)); and2. s is alive in A K ,exo.(cid:7), possK ,exo(s(cid:7)) = {K (s(cid:7))} ∪A set of states S ⊆ S is stabilizable with respect to E, if there is a control function K for A w.r.t. Aag such that every states ∈ S is stabilizable with respect to E witnessed by K .Having provided this definition, we shall illustrate it on an elaborated example in the next section, where we describean intuitive control function for the management of two finite buffers.Before closing this section, we introduce for later use the notion of a non-deterministic control.Definition 9 (Non-deterministic control). Given a system A = (S, A, Φ, poss) and a set Aag ⊆ A of agent actions, a partialAag such that K (s) ⊆ poss(s) and K (s) (cid:4)= ∅ whenever K (s) is defined, is called non-deterministic controlfunction K : S → 2for A w.r.t. Aag.Informally, a non-deterministic control leaves the agent a choice to execute one out of several actions. It is an envelopefor multiple control functions, which result by refining K to some arbitrary action in K (s) whenever K (s) is defined; the(cid:7)) =notion of stabilizability is defined similar as for control functions, with the only change that in A K ,exo, we set possK ,exo(sK (s(cid:7))} ∪ exo(s(cid:7)) = {K (s(cid:7)).(cid:7)) ∪ exo(s(cid:7)) in place of possK ,exo(sThe following proposition is immediate.Proposition 1. Given a system A = (S, A, Φ, poss), a set Aag ⊆ A, and a function exo, a set of states S ⊆ S is stabilizable w.r.t. aset of states E ⊆ S under a control function K for A w.r.t. Aag iff S is stabilizable w.r.t. E under a non-deterministic control Kfor A+(s) and K (s) is defined+w.r.t. Aag. Furthermore, each such K is a refinement of some Kiff Kwith this property (i.e., for each s, K (s) ∈ Kis a control function witnessing stabilizability of S w.r.t. E.+(s) is defined), and each refinement K of K++3. Example scenario: Two finite buffersIn this section, we introduce an example which we will use in illustrating the notion of stabilizability and also otherconcepts in some of the later sections of the paper.3 In the planning literature, in Markov Decision Planning a control function is also called a (control) policy, which is usually assumed to be a totalfunction [35]; in Model-Based Planning, [18], it is called a deterministic state-action table, and non-deterministic controls (introduced below) are called(non-deterministic) state-action tables; [35] refers to them also as (non-deterministic) plans or policies, respectively.C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691435We imagine a system with two finite buffers, b1 and b2, where objects are added to b1 in an uncontrollable way. Anagent moves objects from b1 to b2 and processes them there. When an object has been processed, it is automaticallyremoved from b2. This is a slight modification of a finite buffer example from [58] and generalizes problems such as ftpagents maintaining a clean ftp area by moving submitted files to other directories, or robots moving physical objects fromone location to another.In our framework, we shall describe a system Ab which models this scenario. For simplicity, we assume that the agenthas three control actions M12 that moves an object from b1 to b2 (if such an object exists), the opposite action, M21 thatmoves an object from b2 to b1, and Proc that processes and removes an object in b2. There is one exogenous action, Ins,that inserts an object into buffer b1. The capacities of b1 and b2 are assumed to be equal.Let us assume that the control goal of this system is to keep b1 empty. Then, the system is not stabilizable, since objectscan be continually inserted before the agent has a chance to empty the buffer. However, if no insertions are performed fora certain window of non-interference, the agent can always empty b1. This implies that the system is maintainable but notstabilizable. We now make the above argument explicit by using a concrete instance of Ab.Example 2 (Buffer example). We assume that the maximum capacity of the buffers b1 and b2 is 3. The components ofAb = (Sb, Ab, Φb, possb) are then as follows.• We model every state by the current number of objects in b1 and b2. That is, a state s is identified by a pair of integers(cid:14)i, j(cid:15) where i denotes the number of objects in b1 and j the number of objects in b2. With the maximum capacity of3, the set of states, Sb, consists of 4 × 4 = 16 states and is given bySb = {0, 1, 2, 3} × {0, 1, 2, 3}.• The set of actions is Ab = {M12, M21, Proc, Ins}.• We assume that the transition function Φb is deterministic, i.e., |Φb(s, a)| (cid:3) 1, defined as follows, where we write(cid:7)}. For every i, j ∈ {0, . . . , 3}, letfor Φb(s, a) = {s(cid:4)(cid:7)ΦbΦb(s, a) = s(cid:3)(cid:14)i, j(cid:15), M12(cid:3)(cid:14)i, j(cid:15), M21(cid:3)(cid:14)i, j(cid:15), Proc(cid:4)(cid:3)(cid:14)i, j(cid:15), InsΦbΦbΦb(cid:4)= (cid:14)i − 1, j + 1(cid:15),= (cid:14)i + 1, j − 1(cid:15),(cid:4)= (cid:14)i, j − 1(cid:15),= (cid:14)i + 1, j(cid:15),where addition and subtraction are modulo 3, and in all other cases Φb(s, a) = ∅.• The enabling function, possb, is defined by(cid:4)(cid:3)M12 ∈ possb(cid:14)i, j(cid:15)(cid:4)(cid:3)M21 ∈ possb(cid:14)i, j(cid:15)(cid:4)(cid:3)(cid:14)i, j(cid:15)Proc ∈ possb(cid:4)(cid:3)(cid:14)i, j(cid:15)Ins ∈ possbiffiffi (cid:2) 1 and j (cid:3) 2,i (cid:3) 2 and j (cid:2) 1,iffj (cid:2) 1,iffi (cid:3) 2.It is easy to see that for S = {(cid:14)0, 0(cid:15)} (no objects in the buffers) and E = {(cid:14)0, 0(cid:15), (cid:14)0, 1(cid:15), (cid:14)0, 2(cid:15), (cid:14)0, 3(cid:15)} (that is, we want tokeep b1 empty) S is not stabilizable w.r.t. E, since the exogenous action Ins can always interfere in the task of bringing thesystem back to E. For example, consider the control Kb defined as follows:(cid:4)(cid:3)(cid:14)i, j(cid:15)(cid:3)(cid:4)(cid:14)i, j(cid:15)KbKb= M12 when i (cid:2) 1 and j < 3, and= Proc when (i = 0 and j (cid:2) 1) or j = 3.Intuitively, the above control directs the transfer of objects from buffer 1 to 2 whenever possible, and if that is not possibleit directs processing of objects in buffer 2 if that is possible. In Fig. 4, which shows the transition diagram between states,the transitions by the control Kb are marked with M12 and Proc.Consider the following trajectory consistent with the control system A K ,exo = (Sb, Ab, Φb, possb Kb ,exo ):τ = (cid:14)0, 0(cid:15), Ins, (cid:14)1, 0(cid:15), Ins, (cid:14)2, 0(cid:15), M12, (cid:14)1, 1(cid:15), Ins, (cid:14)2, 1(cid:15), M12, (cid:14)1, 2(cid:15), Ins, (cid:14)2, 2(cid:15), M12, (cid:14)1, 3(cid:15), Proc.It consists of a prefix (cid:14)0, 0(cid:15), Ins, . . . , M12 and a cycle (cid:14)1, 2(cid:15), . . . , Proc. In τ , no state in E is ever reached after the startingstate (cid:14)0, 0(cid:15). Similar trajectories can be found for any control and hence S is not stabilizable with respect to E.On the other hand, S = {(cid:14)0, 0(cid:15)} is stabilizable w.r.t. Eobjects in b1 at any time): Following Kb we can go from any of the states in Sb \ Ethe execution of at most two control actions, while no exogenous actions are possible for those states.(cid:7) = {0, 1, 2} × {0, 1, 2, 3} (that is, we want to have at most twowith(cid:7) = {(cid:14)3, 0(cid:15), (cid:14)3, 1(cid:15), (cid:14)3, 2(cid:15), (cid:14)3, 3(cid:15)} to E(cid:7)1436C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469Fig. 4. The transition diagram of the buffer system Ab for the concrete instance (buffer capacity 3).4. Limited interference and k-maintainabilityAs we mentioned in Section 1, our main intuition behind the notion of maintainability is that maintenance becomespossible only if there is a window of non-interference from the environment during which maintenance is performed bythe agent. In other words, an agent k-maintains a condition c if its control (or its reaction) is such that if we allow it tomake the controlling actions without interference from the environment for at least k steps, then it gets to a state thatsatisfies c within those k steps.Our definition of maintainability has the following parameters:(i) a system A = (S, A, Φ, poss),(ii) a set of initial states S that the system may be initially in,(iii) a set of desired states E that we want to maintain,(iv) a set Aag ⊆ A of agent actions,Aenv detailing exogenous actions, such that exo(s) ⊆ poss(s), and(v) a function exo : S → 2(vi) a control function K (mapping a relevant part of S to Aag) such that K (s) ∈ poss(s).The next step is to formulate when the control K maintains E assuming that the system is initially in one of the statesin S. For that, we require that if in the system A K ,exo = (S, A, Φ, possK ,exo), where possK ,exo(s) = {K (s)} ∪ exo(s) restricts theagent actions to the control K , the agent is in a state s that has been reached from any state in S (i.e., s ∈ Closure(S, A K ,exo)),then given a window of non-interference from exogenous actions, it must get into some desired state during that window.One of the importance of using the notion of closure here is that one can focus only on a possibly smaller set of states, rather than allthe states, thus limiting the possibility of an exponential blow-up—as warned in [36]—of the number of control rules.Now a next question might be: Suppose the above condition of maintainability is satisfied, and while the control isleading the system towards a desired state, an exogenous action happens and takes the system off that path. What then?The answer is that the state the system will reach after the exogenous action will be a state from the closure. Thus, if thesystem is then left alone (without interference from exogenous actions) it will be again on its way to a desired state. Soin our notion of maintainability, the control is always taking the system towards a desired state, and after any disturbancefrom an exogenous action, the control again puts the system back on a path to a desired state.We define the notion of unfolding a control as follows.Definition 10 (Unfoldk(s, A, K )). Let A = (S, A, Φ, poss) be a system,Unfoldk(s, A, K ) is the set of all sequences σ = s0, s1, . . . , sl where l (cid:3) k and s0 = s such that K (s j) is defined for alls j+1 ∈ Φ(s j, K (s j)), and if l<k, then K (sl) is undefined.let s ∈ S, and let K be a control for A. Thenj < l,Intuitively, an element of Unfoldk(s, A, K ) is a sequence of states of length at most k + 1 that the system may go throughif it follows the control K starting from the state s. If the length of the sequence is less than k + 1, it means that at the laststate of the sequence K is undefined and thus the sequence can not unfold further.Fig. 5 illustrates this.The above definition of Unfoldk(s, A, K ) is easily extended to the case when K is a non-deterministic control, meaning∗) =K (s) is a set of actions instead of a single action. In that case, we overload Φ and for any set of actions a(cid:5), define Φ(s, a∗a∈a∗ Φ(s, a).C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691437Fig. 5. Let K be the policy of doing action a in states b, c, d and f . Unfold3(b, A, K ) = {(cid:14)b, c, d, h(cid:15), (cid:14)b, g(cid:15)} and Unfold3(c, A, K ) = {(cid:14)c, d, h(cid:15)}.Fig. 6. Let S = {b} and E = {h}. A 3-maintainable policy with respect to them will be to do a in states b, c and d.We now define the notion of k-maintainability, which can be used to verify the correctness of a control.Definition 11 (k-maintainability). Given a system A = (S, A, Φ, poss), a set of agents action Aag ⊆ A, and a specification ofexogenous action occurrence exo, we say that a control4 K for A w.r.t. Aag k-maintains S ⊆ S with respect to E ⊆ S, wherek (cid:2) 0, if for each state s ∈ Closure(S, A K ,exo) and each sequence σ = s0, s1, . . . , sl in Unfoldk(s, A, K ) with s0 = s, it holds that{s0, . . . , sl} ∩ E (cid:4)= ∅.We say that a set of states S ⊆ S (resp. A, if S = S) is k-maintainable, k (cid:2) 0, with respect to a set of states E ⊆ S, ifthere exists a control K which k-maintains S w.r.t. E. K is then referred to as the witnessing control function. Furthermore,S (resp. A) is called maintainable w.r.t E, if S (resp. A) is k-maintainable w.r.t. E for some k (cid:2) 0.In the following we will omit explicit mention of Aag, S, and E for control functions and maintainability if they are clearfrom the context.Intuitively, the condition {s0, s1, . . . , sl} ∩ E (cid:4)= ∅ above means that we can get from a state s0 outside E to a state inE within at most k transitions—where each transition is dictated by the control K —if the world were to unfold as ins0, s1, . . . , sl, where s0 = s. In particular, 0-maintainability means that the agent has nothing to do: after any exogenousaction happening, the system will be in a state from E. Therefore, a trivial control K will do which is undefined on everystate.Note that in the above definition we no longer require aliveness. If a non-alive state is reached while unfolding, theunfolding stops there and the definition of k-maintainability requires that a goal state (from E) is reached by then.(cid:7)}, that exo(s) = {e} iff s = f and that exo(s) = ∅Example 3. Reconsider the system A in Fig. 1. Let us assume that Aag = {a, aotherwise. Suppose now that we want a 3-maintainable control policy for S = {b} w.r.t. E = {h}. Clearly, such a control policyK is to take a in b, c, and d. Indeed, Closure({b}, A K ,exo) = {b, c, d, h} and Unfold3(b, A, K ) = {(cid:14)b, c, d, h(cid:15)}, Unfold3(c, A, K ) ={(cid:14)c, d, h(cid:15)}, and Unfold3(d, A, K ) = {(cid:14)d, h(cid:15)}; furthermore, each sequence contains h. See Fig. 6.Suppose now, as shown in Fig. 7, there is an exogenous action e that can take from c to f . Then, no k-maintainablecontrol policy for S = {b} w.r.t. E = {h} exists for any k (cid:2) 0. Indeed, the agent can always end up in the dead-end g. If,(cid:7) ∈ poss(g), a 3-maintainable control policy K is K (s) = a for s ∈ {b, c, d, f } andhowever, in addition Φ(g, aK (g) = a(cid:7)) = { f , h} and a.(cid:7)4 Note that here only K (s) for s ∈ Closure(S, A K ,exo) is of relevance. For all other s, K (s) can be arbitrary or undefined.1438C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469Fig. 7. Let S = {b} and E = {h}. No 3-maintainable policy with respect to them exists.Example 4 (Buffer example (cont’d)). Earlier we showed that in Ab, S = {(cid:14)0, 0(cid:15)} is not stabilizable w.r.t. E = {(cid:14)0, 0(cid:15), (cid:14)0, 1(cid:15), (cid:14)0, 2(cid:15),(cid:14)0, 3(cid:15)}. Thus, we might ask whether S is at least maintainable w.r.t. E? The answer is positive: For the worst case systemstate, (cid:14)3, 3(cid:15), a control can move the system to (cid:14)3, 0(cid:15) (by three transitions executing Proc) without interfering occurrencesof exogenous actions. If there then are three further transitions without interference, the control can apply M12 three timesand effect the state (cid:14)0, 3(cid:15). This implies that S is 6-maintainable w.r.t. E. We can, with a similar argument show that A is9-maintainable w.r.t. {(cid:14)0, 0(cid:15)}. A similar argument can be made with respect to the control Kb of Example 2.However, we have that A is not maintainable w.r.t., for example, {(cid:14)0, 3(cid:15)} (Since we cannot go from, for example, {(cid:14)0, 0(cid:15)},to {(cid:14)0, 3(cid:15)} with control actions only).As the above example points out, it is possible that S is maintainable but not stabilizable with respect to E. The converseis also possible. In other words, in certain cases we may have a system where a given S is stabilizable with respect to a setE, but yet is not maintainable. This happens when every path between a state in S and a state in E involves at least oneexogenous action. In that case the agent, who does not have control over the exogenous actions, can not on its own makethe transition from a state in S to a state in E. However, often for each exogenous action there are equivalent (in terms ofeffects) agent actions. In that case, any stabilizable system is also maintainable.We note the following monotonicity property of k-maintainability, which is an easy consequence of the definition:Proposition 2. Suppose that for a system A = (S, A, Φ, poss), a set of agents action Aag ⊆ A, and a specification of exogenous action(cid:7) ⊆ Closure(S, A K ,exo) withoccurrence exo, the control function K k-maintains S ⊆ S w.r.t. E ⊆ S. Then, K also k-maintains any set Srespect to any set E(cid:7) ⊇ E.4.1. An alternative characterization of k-maintainabilityThe characterization of stability and stabilizability in Section 2 is based on imposing conditions on trajectories obtainedfrom the transition graph of a system. Such a characterization has the advantage that it is amenable to developing temporaloperators that can express more general conditions.In contrast, the definition of maintainability in Definition 11 is not based on trajectories. Nonetheless, one can give analternative characterization based on trajectories, which we do next. To bridge from finite trajectories (which are relevantwith respect to maintainability), to infinite ones as in Definition 2, we consider for each system A = (S, A, Φ, poss) an, for each state s we haveextension, AΦ(s, anop) = {s} and anop ∈ poss(s) if poss(s) = ∅ in A. Informally, A, which results by adding a fresh environmental action anop such that in Aadds infinite loops to halting states of A.∞∞∞Proposition 3. Given a system A = (S, A, Φ, poss), a set of agents action Aag ⊆ A, a specification of exogenous action occurrenceexo, and a set of states E, a set of states S is k-maintainable with respect to E, k (cid:2) 0, if and only if there exists a control K for A∞w.r.t. Aag such that for each state s in S and every trajectory of form τ = s0, a1, s1, a2, . . . , a j, s j, a j+1, . . . consistent with AK ,exo ands0 = s, it holds that {ai+1, . . . , ai+k} ⊆ Aag or ai+k = anop for some i (cid:2) 0 implies that {si, . . . , si+k} ∩ E (cid:4)= ∅.Proof. For the only if direction, suppose that S is k-maintainable w.r.t. E, witnessed by the control function K . Let s ∈ S∞K ,exo such that s0 = s and {ai+1, . . . , ai+k} ⊆ Aag or ai+k = anop,and τ = s0, a1, s1, a2, . . . , a j, s j, a j+1, . . . be consistent with A∞for some i (cid:2) 0. Then, we have si ∈ Closure(S, AK ,exo). If k = 0, then since K is a witnessing control, we have si ∈ E, and thus{si, si+1, . . . , si+k} ∩ E (cid:4)= ∅ holds. Consider thus k > 0. If ai+k ∈ Aag (which implies {ai+1, . . . , ai+k} ⊆ Aag), then the sequencesi, si+1, . . . , si+k belongs to Unfoldk(si, A, K ). Since K is a witnessing control function, we again have {si, si+1, . . . , si+k} ∩ E (cid:4)=∞∅. Otherwise, if ai+k = anop, let l (cid:2) 1 be the least index such that al = anop. By definition of AK ,exo, we have that K (sl−1) isundefined. Hence, the sequence σ = sl−1 belongs to Unfoldk(sl−1, A, K ). Since K is a control, it follows that sl−1 ∈ E. Sinces j = sl−1 for each j (cid:2) l, and in particular si+k = sl−1, it follows again that {si, si+1, . . . , si+k} ∩ E (cid:4)= ∅. This proves the only ifdirection.C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691439Conversely, suppose K is a control for A w.r.t. Aag such that for each s ∈ S and trajectory τ = s0, a1, s1, a2, . . . , a j, s j,∞K ,exo and s0 = s, it holds that {ai+1, . . . , ai+k} ⊆ Aag or ai+k = anop for some i (cid:2) 0 impliesa j+1, . . . consistent with Athat {si, si+1, . . . , si+k} ∩ E (cid:4)= ∅. We claim that K witnesses k-maintainability of S w.r.t. E. Towards a contradiction, sup-∞K ,exo, that there is some state s ∈ S and trajectory τ =pose the contrary. Hence, it follows from the definition of A∞s0, a1, s1, a2, . . . , a j, s j, a j+1, . . . consistent with AK ,exo)and s j, s j+1, . . . , s j+l is in Unfoldk(s j, A, K ), where l (cid:3) k, but E ∩ {s j, . . . , s j+l} = ∅.∞K ,exo and s0 = s, such that for some j (cid:2) 0 we have s j ∈ Closure(S, ABy definition of Unfoldk(s j, A, K ), we have that {a j+1, . . . , a j+l−1} ⊆ Aag and that a j+l = a j+l+1 = · · · = a j+k = anop.By hypothesis, E ∩ {s j, . . . , s j+k} (cid:4)= ∅ holds. Thus, we conclude that E ∩ {s j+l+1, . . . , s j+k} (cid:4)= ∅ must hold, and hence l < k.However, by definition of Φ(s, anop) we have s j+l = s j+l+1 = · · · = s j+k. This implies that E ∩ {s j, . . . , s j+l} (cid:4)= ∅, which is acontradiction.This proves that K witnesses k-maintainability of S w.r.t. E. (cid:2)While this result shows that we could equally well have developed our notion of k-maintainability on the basis oftrajectories, in the rest of this paper we shall stick to the setting which uses closure and unfolding. We find the latter moreintuitive, as well as more convenient for designing algorithms and for proofs. Furthermore, this setting requires no specialhandling of possible finite trajectories, which complicates matters as becomes apparent from Proposition 3.This alternative characterization suggests how to express the notion of k-maintainability using existing temporal logicswhen a distinction can be made5 between states that are reached through an agent’s actions and states that are reached byan exogenous action. To make this distinction, let us assume that the latter kind of states have the fluent interfered as trueand the former have it as false. Now, let Step[k](φ) be a shorthand for the formulaφ ∨ (cid:9)φ ∨ (cid:9) (cid:9) φ ∨ · · · ∨ (cid:9) · · · (cid:9)(cid:6) (cid:7)(cid:8) (cid:9)φkwhere the last subformula involves k consecutive (cid:9)’s. Intuitively, the formula Step[k](φ) means that φ is true within ksteps. Now the last part of Proposition 3, ignoring the issue of anop actions (for simplicity), is as follows:for each state s in S and every trajectory of form τ = s0, a1, s1, a2, . . . , a j, s j, a j+1, . . . consistent with A{ai+1, . . . , ai+k} ⊆ Aag for some i (cid:2) 0 implies that {si, . . . , si+k} ∩ E (cid:4)= ∅.∞K ,exo and s0 = s,This can be expressed in LTL as φS ⇒ (cid:2)(¬Step[k](interfered) ⇒ Step[k](φE )), or equivalently φS ⇒ (cid:2)(Step[k](interfered ∨φE )), where φS and φE are propositional formulas which described the states in S and E, respectively.Using the above formula, k-maintainability can be written as follows:There exists a control K for A w.r.t. Aag such that for each state s in S and every trajectory ofs0, a1, s1, a2, . . . , a j, s j, a j+1, . . . consistent with A((cid:2)Step[k](interfered ∨ φE )).form τ =∞K ,exo and s0 = s, the trajectory satisfies the temporal formula φS ⇒To capture the complete definition by a temporal formula, one needs branching time temporal operators akin to A, likethe operator Aπ in [9] meaning that “for all paths following the policy under consideration”. In that case, the specificationwould be Aπ ((cid:2)(φS ⇒ (cid:2)(Step[k](interfered ∨ φE )))). Note that here we need (cid:2) in between Aπ and φS to indirectly accountfor the phrase “for each state s in S”.In upcoming sections, we discuss the above characterization in the context of general control generation algorithms thatwork with arbitrary temporal specifications. However, we use the characterization of k-maintainability in Definition 11 asit matches more closely with our algorithms, and does not necessitate defining a compilation that eliminates exogenousactions and introduces the new fluent interfered and proving the equivalence of that compilation.5. Polynomial time methods to construct k-maintainable controlsNow that we have defined the notion of k-maintainability, our next step is to show how some k-maintainable control canbe constructed in an automated way. We start with some historical background. In the program specification and synthesisliterature, there have been a number of works, e.g., [19,49,59,60] to automatically synthesize programs similar to our controlpolicies from given temporal logic specifications. Although these algorithms can accept richer goals, they all either alludeto worst case exponential nature of their algorithms or prove that the complexity is exponential or even higher. None ofthem study special classes of specifications with lower complexity of constructing control. We discuss these papers andtheir complexity results in Section 8.2.5 Such distinctions can be made by compiling a system, a set of agent actions, a specification of exogenous action occurrence, a set of goal states and aset of initial states to an automata that eliminates transitions due to exogenous actions but records their presence through the fluent interfered. We discusssuch a compilation in Section 8.2.1.1440C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469There has been extensive use of situation control rules [26] and reactive control in the AI literature. But there have beenless efforts in the AI literature to define correctness of such control rules [8],6 and to automatically construct correct controlrules for general goals [10,37,41].7 In [42], it is suggested that in a control rule of the form: “if condition c is satisfied thendo action a”, the action a is the action that leads to the goal from any state where the condition c is satisfied. In [8] a formalmeaning of “leads to” is given as: for all states s that satisfy c, a is the first action of a minimal cost plan from s to the goal.Using this definition, an algorithm is presented in [52] to construct k-maintainable controls. This algorithm is sound but notcomplete, in the sense that it generates correct controls only, but there is no guarantee that it will find always a control ifone exists.In [10,41], an algorithm to construct control with respect to linear temporal logic goals is given. This algorithm is basedon progressing linear temporal formulas. The worst case complexity of the algorithm is given as double exponential withrespect to the number of subformulas of the goal specification f , assuming a fixed number of states. Note that the temporalrepresentation of k-maintainability will have subformulas with k nested operators (cid:9). However, no studies regarding thecomplexity of specific goal specifications were done earlier. With the help of one of the authors of [10,41] we explored howwell the algorithms in [10,41] will do with respect to our goal and found that by the using the algorithm as given in [10,41]the complexity will be exponential in the size of k. In Section 8.2.1 we will discuss this in more detail.In the following, we overcome the problems one faces in the above mentioned approaches and give a sound and completepolynomial time algorithm for constructing k-maintainable control policies. In fact, the algorithm works in linear time fork bounded by a constant, and can be adapted to a linear time algorithm for maintainability, i.e., where k is arbitrary butfinite.We provide it in two steps: First we consider the case when the transition function Φ is deterministic, and then wegeneralize to the case where Φ may be non-deterministic. In each case, we present different methods, which illustrates ourdiscovery process and also gives a better grasp of the final algorithm. We first present an encoding of our problem as apropositional theory and appeal to propositional SAT solvers to construct the control. As it turns out, this encoding is ina tractable fragment of SAT, for which specialized solvers (in particular, Horn SAT solvers) can be used easily. Finally, wepresent a direct algorithm distilled from the previous methods.The reasoning behind this line of presentation is the following:(i) It illustrates the methodology of using SAT and Horn SAT encodings to solve problems;(ii) the encodings allow us to quickly implement and test algorithms;(iii) the proof of correctness mimics the encodings; and(iv) we can exploit known complexity results for Horn SAT to determine the complexity of our algorithm, and in particularlyto establish tractability.As for (ii), we can make use of answer set solvers such as DLV [29,45] or Smodels [53,65] which extend Horn logicprograms by non-monotonic negation. These solvers allow efficient computation of the least model and some maximalmodels of a Horn theory, and can be exploited to construct robust or “small” controls, respectively.Just for clarification, our approach of going from a SAT encoding to a Horn SAT encoding to a procedural algorithm isnot to suggest that one is better or more efficient. Rather, it shows the usefulness of the general methodology to go froma logical specification (i.e., a SAT encoding in this case) to a procedural algorithm via transformations (Horn SAT encoding)that help us to prove the polynomial nature of the algorithm.The problem we want to solve, which we refer to as k-Maintain, has the following input and output:Input: An input I is a system A = (S, A, Φ, poss), sets of states E ⊆ S and S ⊆ S, a set Aag ⊆ A, a function exo, andan integer k (cid:2) 0.Output: A control K such that S is k-maintainable with respect to E (using the control K ), if such a control exists.Otherwise the output is the answer that no such control exists.We assume here that the functions poss(s) and exo(s) can be efficiently evaluated; e.g., when both functions are givenby their graphs (i.e., in a table).5.1. Deterministic transition function Φ(s, a)We start with the case of deterministic transitions, i.e., Φ(s, a) is a singleton set {snotation, we simply will write Φ(s, a) = s(cid:7)in this case.(cid:7)} whenever nonempty. In abuse of6 Here we exclude the works related to MDPs as it is not known how to express the kind of goal we are interested in—such as k-maintenance goals—usingreward functions.7 In recent years, some planning algorithms and systems have been developed [13,14,18,39,40,44] that generate control rules for particular classes ofgoals.C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691441Our first algorithm to solve k-Maintain will be based on a reduction to propositional SAT solving. Given an input I fork-Maintain, we construct a SAT instance sat(I) in polynomial time such that sat(I) is satisfiable if and only if the input Iallows for a k-maintainable control, and that the satisfying assignments for sat(I) encode possible such controls.In our encoding, we shall use for each state s ∈ S propositional variables s0, s1, . . . , sk. Intuitively, si will denote thatthere is a path from state s to some state in E using only agent actions and at most i of them, to which we refer as “thereis an a-path from s to E of length at most i”.The encoding sat(I) contains the following formulas:(0) For all s ∈ S, and for all j, 0 (cid:3) j < k:s j ⇒ s j+1(1) For all s ∈ E ∩ S:s0(2) For any two states s, s(cid:7)sk ⇒ sk(cid:7) ∈ S such that Φ(a, s) = s(cid:7)for some action a ∈ exo(s):(3) For any state s ∈ S \ E and all i, 1 (cid:3) i (cid:3) k:(cid:7)i−1,si ⇒(cid:10)ss(cid:7)∈PS(s)where PS(s) = {s(4) For all s ∈ S \ E:(cid:7) ∈ S | ∃a ∈ Aag ∩ poss(s): s(cid:7) = Φ(a, s)};sk(5) For all s ∈ S \ E:¬s0(cid:7)The intuition behind the above encoding is as follows. The clauses in (0) state that if there is an a-path from s to E oflength at most j then, logically, there is also an a-path of length at most j + 1. The clauses in (1) say that for states s inS ∩ E, there is an a-path of length 0 from s to E. Next, (4) states that for any starting state s in S outside E, there is ana-path from s to E of length at most k, and (5) states that for any state s outside E, there is no a-path from s to E of length0. The clauses in (3) state that if, for any state s, there is an a-path from s to E of length at most i, then for some possibleto E of length at most i − 1. When looking foragent action a and successor state sk-maintainable controls the clauses in (2) take into account the possibility that s may be in the closure. If indeed s is inthe closure and there is an a-path from s to E of length at most k, then the same must be true with respect to the states(cid:7)sreachable from s using exogenous actions. When looking for non-deterministic control they play a role in computingmaximal non-deterministic controls. The role of each of the above clauses become more clear when relating the models ofsat(I) with controls that k-maintain.= Φ(a, s), there is an a-path from sGiven any model M of sat(I), we can extract a desired control K from it by defining K (s) = a for all s outside E with skis closer to E than s is. In case of multiple(cid:7) = Φ(s, a) and strue in M, where a is a possible agent action in s such that spossible a and s, one a can be arbitrarily picked. Otherwise, K (s) is left undefined.In particular, for k = 0, only the clauses from (1), (2), (4) and (5) do exist. As easily seen, sat(I) is satisfiable in this caseif and only if S ⊆ E and no exogenous action leads outside E, i.e., the closure of S under exogenous actions is containedin E. This means that no actions of the agent are required at any point in time, and we thus obtain the trivial 0-control Kwhich is undefined on all states, as desired.(cid:7)(cid:7)(cid:7)The next result states that the SAT encoding works properly in general.Proposition 4. Let I consist of a system A = (S, A, Φ, poss) where Φ is deterministic, a set Aag ⊆ A, sets of states E ⊆ S and S ⊆ S,an exogenous function exo, and an integer k. For any model M of sat(I), let C M = {s ∈ S | M |(cid:8) sk}, and for any state s ∈ C M let (cid:8)M (s)denote the smallest index j such that M |(cid:8) s j (i.e., s0, s1, . . . , s j−1 are f alse and s j is true), which we call the level of s w.r.t. M. Then,(i) S is k-maintainable w.r.t. E iff sat(I) is satisfiable.(ii) Given any model M of sat(I), the partial function K(cid:11)a ∈ Aag ∩ poss(s) | Φ(s, a) = s, sis a valid non-deterministic control for A w.r.t. Aag;+M (s) =K(cid:7)+M: S → 2(cid:7) ∈ C M , (cid:8)M (sAag defined on C M \ E such that(cid:12)) < (cid:8)M (s),(cid:7)(iii) any control K which refines K+M for some model M of sat(I) k-maintains S w.r.t. E.The proof of this proposition can be easily obtained by adapting the proof of Proposition 6.1442C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14695.1.1. Horn SAT encodingWhile sat(I) is constructible in polynomial time from I , we can not automatically infer that solving k-Maintain is poly-nomial, since SAT is a canonical NP-hard problem. However, a closer look at the structure of the clauses in sat(I) revealsthat this instance is solvable in polynomial time. Indeed, it is a reverse Horn theory; i.e., by reversing the propositions, weobtain a Horn theory. Let us use propositions si whose intuitive meaning is converse of the meaning of si . Then the Horntheory corresponding to sat(I), denoted sat(I), is as follows:(0) For all s ∈ S and j, 0 (cid:3) j < k:s j+1 ⇒ s j.(1) For all s ∈ E ∩ S:s0 ⇒ ⊥.(2) For any states s, s(cid:7) ∈ S such that s(cid:7) = Φ(a, s) for some action a ∈ exo(s):(cid:7)sk⇒ sk.(3) For any state s ∈ S \ E, and for all i, 1 (cid:3) i (cid:3) k:(cid:13) (cid:14)(cid:15)s(cid:7)i−1⇒ si,s(cid:7)∈PS(s)(cid:7) ∈ S | ∃a ∈ Aag ∩ poss(s): s(cid:7) = Φ(a, s)}.where PS(s) = {s(4) For all s ∈ S \ E:sk ⇒ ⊥.(5) For all s ∈ S \ E:s0.Here, ⊥ denotes falsity. We then obtain a result similar to Proposition 4, and the models M of sat(I) lead to k-maintainablecontrols, which we can construct similarly; just replace in part (ii) C M with C M = {s ∈ S | M (cid:4)|(cid:8) sk}. Notice that C M coincideswith the set of states C M for the model M of sat(I) such that M |(cid:8) p iff M (cid:4)|(cid:8) p, for each atom p.We now illustrate the above Horn encoding with respect to an example.Example 5. Consider the system A = (S, A, Φ, poss), where S = {b, c, d, f , g, h}, A = {a, asition function Φ was shown in Fig. 1, where Φ(s, a) = sactions that label arcs leaving s.iff an arc s → s(cid:7)(cid:7)(cid:7), e}, and the (deterministic) tran-labeled with a is present and poss(s) are allFor A = {a, a(cid:7)} and exo(s) = {e} iff s = f and exo(s) = ∅ otherwise, this leads for S = {b}, E = {h}, and k = 3 to thefollowing Horn encoding sat(I):(From 0)(From 1)(From 2)(From 3)b1 ⇒ b0.d1 ⇒ d0.g1 ⇒ g0.b2 ⇒ b1.d2 ⇒ d1.g2 ⇒ g1.b3 ⇒ b2.d3 ⇒ d2.g3 ⇒ g2.c1 ⇒ c0.f 1 ⇒ f 0.h1 ⇒ h0.c2 ⇒ c1.f 2 ⇒ f 1.h2 ⇒ h1.c3 ⇒ c2.f 3 ⇒ f 2.h3 ⇒ h2.g3 ⇒ f 3.c0 ∧ f 0 ⇒ b1.d0 ⇒ c1.h0 ⇒ d1.h0 ⇒ f 1.g1.c1 ∧ f 1 ⇒ b2.d1 ⇒ c2.h1 ⇒ d2.h1 ⇒ f 2.g2.c2 ∧ f 2 ⇒ b3.d2 ⇒ c3.h2 ⇒ d3.h2 ⇒ f 3.g3.(From 4)(From 5)b3 ⇒ ⊥.b0.c0.d0.f 0.g0.C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691443Fig. 8. Computing the least model: [6] From 5 we get b0, c0, d0, f 0, g0; [7] From 3 we get g1, g2, g3; [8] From 6 and 3 we get b1, c1; [9] From 7 and 2 weget f 3; [10] From 0 and 9 we get f 2; [11] From 0 and 10 we get f 1; [12] From 3, 8 and 11 we get b2.This theory has the least modelM = {g3, g2, g1, g0, f 3, f 2, f 1, f 0, b2, b1, b0, c1, c0, d0};Hence, C M = {b, c, d, h}, which gives rise to the non-deterministic control K+(s) is undefined for s ∈ { f , g, h}. In this case, there is a single control K refining K+(s) = {a} for s ∈ {b, c, d} and, which has K (s) = a for s ∈ {b, c, d}Kand is undefined otherwise. This is intuitive: The agent must reach h, and has to avoid taking ain b since then it mightarrive at the no-good state g. Thus, she has to take a in b and, as the only choice, in the subsequent states c and d. Also, wemight not add any state apart from b, c, and d without losing 3-maintainability. In this particular case, M is also maximalon the propositions s3, where s ∈ S \ E = {b, c, d, f , g}: By (4), we can not add b3, and by (0) and the clauses c2 ∧ f 2 ⇒ b3and d1 ⇒ c2 in (3) then also neither c3 nor d3. Thus, the above control K is also smallest and, in fact, the only one possiblefor 3-maintainability.such that K++(cid:7)As computing a model of a Horn theory is a well-known polynomial problem [25], we thus obtain the following result.Theorem 5. Under deterministic state transitions, problem k-Maintain is solvable in polynomial time. (cid:2)An interesting aspect of the above is that, as well-known, each satisfiable Horn theory T has the least model, M T ,which is given by the intersection of all its models. Moreover, the least model is computable in linear time, cf. [25,50].This model not only leads to a k-maintainable control, but also leads to a maximal control, in the sense that the control is. Thisdefined on a greatest set of states outside E among all possible k-maintainable controls for Sgives a clear picture of which other states may be added to S while k-maintainability is preserved; namely, any states inC M T . Furthermore, any control K computed from M T applying the method in Proposition 4 (using C M T ) works for such anextension of S as well.w.r.t. E such that S ⊆ S(cid:7)(cid:7)On the other hand, intuitively a k-maintainable control constructed from some maximal model of sat(I) with respect tothe propositions sk is undefined to a largest extent, and works merely for a smallest extension. We may generate, startingfrom M T , such a maximal model of T by trying to flip first, step by step all propositions sk which are f alse to true, as wellas other propositions entailed. In this way, we can generate a maximal model of T on {sk | s ∈ S \ E} in polynomial time,from which a “lean” control can also be computed in polynomial time.5.2. Non-deterministic transition function Φ(s, a)We now generalize our method for constructing k-maintainable controls to the case in which transitions due to Φ maybe non-deterministic. As before, we first present a general propositional SAT encoding, and then rewrite to a propositionalHorn SAT encoding. To explain some of the notations, we need the following definition, which generalizes the notion of ana-path to the non-deterministic setting.Definition 12 (a-path). We say that there exists an a-path of length at most k (cid:2) 0 from a state s to a set of states Seither s ∈ S, or s /∈ Sof length at most k − 1 from s, k > 0 and there is some action a ∈ Aag ∩ poss(s) such that for every s, if(cid:7) ∈ Φ(s, a) there exists an a-pathto S.(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)In the following encoding of an instance I of problem k-Maintain to SAT, referred to as sat(cid:7)(I), si will again intuitivelydenote that there is an a-path from s to E of length at most i. The proposition s_ai , i > 0, will denote that for such s there(cid:7)(I) has again groups (0)–(5)is an a-path from s to E of length at most i starting with action a (∈ poss(s)). The encoding satof clauses as follows:1444C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469(0), (1), (4) and (5) are the same as in sat(I).(2) For any state s ∈ S and ssuch that s(cid:7)(cid:7) ∈ Φ(a, s) for some action a ∈ exo(s):(cid:7)sk ⇒ sk(cid:16)(3) For every state s ∈ S \ E and for all i, 1 (cid:3) i (cid:3) k:a∈Aag∩poss(s) s_ai ;(3.1) si ⇒(3.2) for every a ∈ Aag ∩ poss(s) and s(cid:7)i−1(3.3) for every a ∈ Aag ∩ poss(s), if i < k:s_ai ⇒ s(cid:7) ∈ Φ(s, a):;s_ai ⇒ s_ai+1.Group (2) above is very similar to group (2) of sat(I) in the previous subsection. The only change is that we now have(cid:7) = Φ(a, s). The main difference is in group (3). We now explain those clauses. The clauses in (3.1)(cid:7) ∈ Φ(a, s) instead of ssand (3.2) together state that if there is an a-path from s to E of length at most i, then there is some possible action a forthe agent, such that for each state sto E of lengthat most i − 1. The clauses s_ai ⇒ s_ai+1 in (3.3) say that on a longer a-path from s the agent must be able to pick a also.Notice that there are no formulas in satin the same state s, and thus wehave a non-deterministic control; however, we can always refine it easily to a control.(cid:7)(I) which forbid to pick different actions a and athat potentially results by taking a in s, there must be an a-path from s(cid:7)(cid:7)(cid:7)Proposition 6. Let I consist of a system A = (S, A, Φ, poss), a set Aag ⊆ A, sets of states E, S ⊆ S, an exogenous function exo, and(cid:7)(I), let C M = {s ∈ S | M |(cid:8) sk}, and for any state s ∈ C M \ E let (cid:8)M (s) denote the smallest index jan integer k. For any model M of satsuch that M |(cid:8) s_a j for some action a ∈ Aag ∩ poss(s), which we call the a-level of s w.r.t. M. Then,(i) S is k-maintainable w.r.t. E iff sat(ii) given any model M of sat(cid:7)(I) is satisfiable;(cid:7)(I), the partial function K+M: S → 2Aag which is defined on C M \ E byK+M (s) = {a | M |(cid:8) s_a(cid:8)M (s)}is a valid non-deterministic control; and(iii) any control K which refines K+M for some model M of sat(cid:7)(I) k-maintains S w.r.t. E.Proof. Since the if direction of (i) follows from (ii) and (iii), it is sufficient to show the only if direction of (i) and both (ii)and (iii).As for the only if direction of (i), suppose S is k-maintainable w.r.t. E. Then there exists a control K such that for eachstate s ∈ Closure(S, A K ,exo), and for each sequence σ = s(0), s(1), . . . , s(l) in Unfoldk(s, A, K ) where s(0) = s, {s(0), . . . , s(l)} ∩ E (cid:4)=∅. We now construct an interpretation M for sat(cid:7)(I) as follows.For each s ∈ Closure(S, A K ,exo), and each sequence σ = s(0), s(1), . . . , s(l) in Unfoldk(s, A, K ) with s = s(0), let iσ ((cid:2) 0) bethe smallest index i such that s(i) ∈ E, and let iis the length of the longestpath in the tree with root s where each node n not in E is sprouted by taking the control action K (n) and adding each state∗ > 0, to s_ai∗ , s_ai∗+1, . . . , s_ak, where K (s) = a. Allin Φ(n, K (n)) as a child. Then, we assign true to si∗ , si∗+1,. . . , sk and, if iother propositions are assigned f alse in M. We now argue that M is a model of sat(I).be the maximum over all iσ for s. Intuitively, i∗∗(cid:7)k generated in (2). If sk is true, then s ∈ Closure(S, A K ,exo) by construction. In this case, for any sIt is straightforward to see that M satisfies the formulas generated by (0), (1), (4) and (5). Now consider the formulas(cid:7) ∈ Φ(a, s) of ansk ⇒ s(cid:7)(cid:7) ∈ Closure(S, A K ,exo), and since K k-maintains S w.r.t. E, si is true in M for some i (cid:3) k whichexogenous action a, we have s(cid:7)implies, by construction, that sk is assigned true in M. Let us finally consider the formulas generated in (3). If si , wheres ∈ S \ E, is assigned true in M for some i ∈ {1 (cid:3) i (cid:3) k}, then s ∈ Closure(S, A, K exo) holds by construction of M. Since K isa k-maintaining control and s /∈ E, we must have K (s) defined and thus, by construction of M, we have s_K (s)i assignedtrue in M. Since K (s) ∈ Aag ∩ poss(s), the clause (3.1) is thus satisfied. Furthermore, each clause in (3.2) is satisfied whena (cid:4)= K (s), since then saiis true in M and thus, by construction, also(cid:7) ∈ Φ(s, a) belongs to Closure(S, A, Kexo). Let, for each sequence σ (cid:7) = s(0),si . Since K is k-maintaining control, every state s(cid:7)s(1), . . . , s(l) in Unfoldk(s, A, K ) such that s(0) = s, the sequence P (σ ) = s(0), s(1), . . . , s(i) be the shortest prefix of σ suchthat s(i) ∈ E (notice that i < k). Then, the sequence s, P (σ ) is a prefix of some sequence in Unfold(s, A, K ). Hence, it followsthat in the construction of M, the number i. Thus, by construction of M, it follows thatfor s is larger than the one for s(cid:7)si−1 is assigned true in M. This means that the formulas in (3.2) are satisfied in M. Finally, the clauses (3.3) are clearlysatisfied in M by construction of M. Thus, M is a model of satis assigned f alse in M. For a = K (s), proposition sai(cid:7)(I), which means that sat(cid:7)(I) is satisfiable.∗(cid:7)To show (ii), let us assume that saton C M \ E by KBy clause (3.1), and the definition of C M , (cid:8)M , and K+M (s) = {a | M |(cid:8) s_a(cid:8)M (s)}. We thus have to show that K+M this is immediate.(cid:7)(I) has a model M, and consider the partial function K: S → 2+M (s) (cid:4)= ∅ when K+M (s) ⊆ poss(s) and KAag which is defined+M (s) is defined.+MC. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691445To show (iii), let K be any control which refines K(cid:7)(I). Let the distance dK (s, S) of a state sfrom the set of states S be as in the proof of Proposition 4, i.e., the minimum number of transitions—through exogenousactions and/or control actions dictated by the control K —needed to reach s from any state in S.+M for some model M of satWe will show, by using induction on d(s, S) (cid:2) 0, that for every state s ∈ Closure(S, A K ,exo) and every sequence σ =s(0), s(1), . . . , s(l) with s = s(0) in Unfoldk(s, A, K ), the set {s(0), . . . , s(l)} intersects with E and that M |(cid:8) sk (i.e., s ∈ C M ). Thisproves that K k-maintains S w.r.t. E.The base case, d(s, S) = 0, is about states s ∈ S. From the formulas in (0), (1), and (4) we have M |(cid:8) sk for every suchstate s. Consider any sequence σ = s(0), s(1), . . . , s(l) in Unfoldk(s, A, K ) such that s = s(0). If s ∈ E, then we must have l = 0,and {s(0), . . . , s(l)} ∩ E (cid:4)= ∅. Otherwise, M |(cid:8) sak where a = K (s). We then have s(1) ∈ Φ(s, a), and thus by our construction(l)of K and the clauses in (3.2) we have that M |(cid:8) sk−l are allassigned true in M. If k = l, it follows from the clauses in (5) that s(l) ∈ E. Otherwise, if l < k, then K must be undefined ons(l); by the clauses (1), this again means s(l) ∈ E. Hence, {s(0), . . . , s(l)} ∩ E (cid:4)= ∅.(1)k−1. Repeating this argument, we can infer that s(1)k−1, . . . , s(0)k , sThus the statement holds in the base case. Now for the induction step, let us assume that it holds for every state s ∈(cid:7), S) =Closure(S, A K ,exo) at distance d(s, S) = d (cid:2) 0 from S. Let us now consider a state s ∈ Closure(S, A K ,exo) at distance d(s(cid:7)) or (ii)d + 1 from S. Then there is a state s(cid:7)a ∈ K (sk, and we can conclude M |(cid:8) sk from the clauses in(2) in case (i) and from our construction of K and the clauses in (3.2), (1), and (0) in case (ii), respectively. Furthermore, bysimilar argumentation as in the case d = 0 above, we obtain that for each sequence σ = s(0), s(1), . . . , s(l) in Unfoldk(s, A, K )with s = s(0) it holds that {s(0), . . . , s(l)} ∩ E (cid:4)= ∅. This concludes the induction and the proof of (iii). (cid:2)(cid:7)). In both cases, we have by the induction hypothesis that M |(cid:8) sat distance d(s, S) = d from S such that s ∈ Φ(a, s(cid:7)) and either (i) a ∈ exo(s(cid:7)One advantage of the encoding sat(cid:7)(I) over the encoding sat(I) for deterministic transition function Φ above is that itdirectly gives us the possibility to read off a suitable control from the s_ai propositions, a ∈ poss(s), which are true in anymodel M that we have computed, without looking at the transition function Φ(s, a) again. On the other hand, the encoding(cid:7)(I) is benign foris more involved, and uses a larger set of propositions. Nonetheless, the structure of the formulas in satcomputation and allows us to compute a model, and from it a k-maintainable control in polynomial time.5.2.1. Horn SAT encoding (general case)The encoding sat(cid:7)(I)by reversing the propositions, where the intuitive meaning of si and s_ai is the converse of the meaning of si and s_airespectively. The encoding sat(cid:7)(I) is, like sat(I), a reverse Horn theory. We thus can rewrite sat(cid:7)(I) similarly to a Horn theory, sat(cid:7)(I) is as follows:(0), (1), (4) and (5) are as in sat(I)(2) For every states s, s(cid:7) ∈ S such that s(cid:7) ∈ Φ(a, s) for some action a ∈ exo(s):(cid:7)sk⇒ sk.(3) For every state s ∈ S \ E and for all i, 1 (cid:3) i (cid:3) k:(cid:17)a∈Aag∩poss(s) s_ai) ⇒ si ;(3.1) ((3.2) for every a ∈ Aag ∩ poss(s) and s(cid:7) ∈ Φ(s, a):s(cid:7)i−1⇒ s_ai;(3.3) for every a ∈ Aag ∩ poss(s), if i < k:s_ai+1 ⇒ s_ai.We obtain from Proposition 6 easily the following result, which is the main result of this section so far.Theorem 7. Let I consist of a system A = (S, A, Φ, poss), a set Aag ⊆ A, sets of states E, S ⊆ S, an exogenous function exo, and an(cid:7)(I), C M = {s | M (cid:4)|(cid:8) sk}, and let (cid:8)M (s) = min{ j | M (cid:4)|(cid:8) s_a j , a ∈ Aag ∩ poss(s)} for every s ∈ S.integer k. Let, for any model M of satThen,(i) S is k-maintainable w.r.t. E iff the Horn SAT instance sat(ii) Given any model M of sat(cid:7)(I), every control K such that K (s) is defined iff s ∈ C M \ E and(cid:12)(cid:11)a ∈ Aag ∩ poss(s) | M (cid:4)|(cid:8) s_a j, j = (cid:8)M (s),K (s) ∈(cid:7)(I) is satisfiable;k-maintains S w.r.t. E.Corollary 8. Problem k-Maintain is solvable in polynomial time. More precisely, it is solvable in time O (k(cid:22)I(cid:22)), where (cid:22)I(cid:22) denotes thesize of input I .1446C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469(cid:7)(I), measured by the number of atoms in it, is O (k(|S| + |Φ| +Proof. A straightforward analysis yields that the size of sat|poss|)), if Aag, S, E, Φ, poss and exo are stored in a standard way as bitmaps, i.e., a (multi-dimensional) array with value(cid:7)(I) can be easily generated within the samerange {0,1} (thus, (cid:22)I(cid:22) = O (|S|2|A| + log k)). Furthermore, the clauses in sattime bound. Since the least model of any Horn theory T is computable in time O (|T |) where |T | is the number of atoms(cid:7)(I) is feasible in O (k(cid:22)I(cid:22)) time. Furthermore, C Min it [25,50], deciding satisfiability and computing some model M of satand {(s, (cid:8)M (s)) | s ∈ S} are computable from M in linear time in the number of atoms, using suitable data structures, andfrom this a control K as in Theorem 7(ii) in the same time. Hence, a k-maintaining control for S w.r.t. E is computable inO (k(cid:22)I(cid:22)) time.Note that a more economic representation stores S, E, Aag as sets (i.e., lists) and Φ, poss, and exo by their graphs intables, i.e., sets of tuples {(cid:14)s, a, Φ(s, a)(cid:15) | s ∈ S, a ∈ A}, {(cid:14)s, poss(s)(cid:15) | s ∈ S}, and {(cid:14)s, exo(s)(cid:15) | s ∈ S}. Also under this rep-resentation, and if moreover tuples where Φ(s, a) = ∅ (resp., poss(s) = ∅ and exo(s) = ∅) are not stored (which is of the(cid:7) ∈ Φ(a, s)}, {(cid:14)s, a(cid:15) | a ∈ poss(s)}, {(cid:14)s, a(cid:15) | a ∈ exo(s)}), the O (k(cid:22)I(cid:22)) timesame order as storing the sets of tuples {(cid:14)s, a, sbound holds. Indeed, arrays storing S, E, and Aag for lookup in O (1) time are constructible in time O (|S| + |A|). Then,= {(cid:14)s, a(cid:15) ∈ poss | a ∈ Aag} storing Aag ∩ poss(s) for all s is constructible in O (|poss|) time. From this, all clauses ofpossag|)). The clauses (2) and (3.2) can be easilysat(cid:7)(cid:15) ∈ Φ | a ∈ poss(s)} in time O (|Φexo|) and O (k|Φposs|),constructed from Φexo = {(cid:14)s, a, srespectively. The sets Φexo and Φposs can be generated from Φ and exo in time O (|Φ| + |exo| + poss|), using an auxiliary(cid:7)(I)array aux[A, S] to enable random access to Φ(a, s); notice that aux[a, s] needs not be defined if Φ(a, s) = ∅. In total, satis constructible in O (|A| + |exo| + k(|S| + |Φ| + |poss|)) = O (k(cid:22)I(cid:22)) time. (cid:2)(cid:7)(I) except (2) and (3.2) can be readily generated in time O (k(|S| + |possag(cid:7)(cid:15) ∈ Φ | a ∈ exo(s)} and Φposs = {(cid:14)s, a, s(cid:7)(cid:15) | sThus in particular, finding a maintaining control under a small window of opportunity for maintenance, i.e., a k-maintaining control for k bounded by a constant, is feasible in linear time in the size of the input.Similar as in Section 5.1.1, the least model of the theory given by sat(cid:7)(I), Msat(cid:7)(I), leads to a maximal control in thesense that the pre-image of K outside E, i.e., the states outside E in which K is defined, is greatest among all possiblek-maintaining controls which include S. Furthermore, a smallest k-maintaining control can be similarly computed from any(cid:7)(I) with respect to the propositions sk where s is outside E, which can be generated from Msat(cid:7)(I) bymaximal model of satstepwise maximization. Again, both maximal and smallest controls can be computed in polynomial time.Example 6. Reconsider the system A = (S, A, Φ, poss) from Example 5. Let us modify the transition function Φ such thatΦ(c, a) = {d, f } instead of Φ(c, a) = {d}. Then, for the respective modified instance I of 3-Maintain, denoted I1, the encod-ing sat(cid:7)(I1) looks as follows.(0), (1), (2), (4), and (5) are as in sat(I1) in Example 5;(3.1): b_a1 ∧ b_ab_a2 ∧ b_ab_a3 ∧ b_a(cid:7)⇒ b1.1c_a1 ⇒ c1.d_a1 ⇒ d1.f _a1 ⇒ f 1.g1.(cid:7)⇒ b2.2c_a2 ⇒ c2.d_a2 ⇒ d2.f _a2 ⇒ f 2.g2.(cid:7)⇒ b3.3c_a3 ⇒ c3.d_a3 ⇒ d3.f _a3 ⇒ f 3.g3.(3.2): h0 ⇒ d_a1.d0 ⇒ c_a1.c0 ⇒ b_a1.h1 ⇒ d_a2.d1 ⇒ c_a2.c1 ⇒ b_a2.h2 ⇒ d_a3.d2 ⇒ c_a3.c2 ⇒ b_a3.h0 ⇒ f _a1.f 0 ⇒ c_a1.(cid:7)f 0 ⇒ b_a1.h1 ⇒ f _a2.f 1 ⇒ c_a2.(cid:7)f 1 ⇒ b_a2.h2 ⇒ f _a3.f 2 ⇒ c_a3.(cid:7)f 2 ⇒ b_a3.(3.3): d_a2 ⇒ d_a1.c_a3 ⇒ c_a2.d_a3 ⇒ d_a2.b_a2 ⇒ b_a1.f _a2 ⇒ f _a1.b_a3 ⇒ b_a2.f _a3 ⇒ f _a2.b(cid:7)_a2 ⇒ b(cid:7)_a1.c_a2 ⇒ c_a1.b(cid:7)_a3 ⇒ b(cid:7)_a2.It turns out that sat(cid:7)(I) has no models: From g3, the clause g3 ⇒ f 3 in (2), and clauses in (0), we obtain that f i ,(cid:7)(cid:7)(I1). Hence, by the clause f 2 ⇒ b_a3 in (3.2), also b_ai ∈ {0, . . . , 3}, is true in every model M of sat3 is true in M. On theother hand, from the formula f 1 ⇒ c_a2 in (3.2), we obtain that c_a2 must be true in M, and thus by the clauses c_a2 ⇒ c2⇒ b3 thus implies that b3 is true in M.in (3.1) and c2 ⇒ b_a3 in (3.2) that b_a3 is true in M. The clause b_a3 ∧ b_a(cid:7)(I1) can exist, which by Theorem 7However, by the formula b3 ⇒ ⊥ in (4), b3 must be false in M. Thus, no model M of satmeans that there is no 3-maintaining control for S = {b} w.r.t E = {h}. Indeed, regardless of whether a control function Kin state b, within at most 2 steps from b the state f might be reached, from which the exogenous functionselects a or amight move the system to the no-good state g.(cid:7)3(cid:7)Suppose now again that Φ(c, a) = {d, f } and that the agent can take a{ f , h} and a(cid:7) ∈ poss(g)). Then the Horn encoding sat(cid:7)(I1) changes as follows:(cid:7)in g, which results in either h or f (i.e., Φ(g, a(cid:7)) =In (3.1), the facts gi , i ∈ {1, 2, 3}, are replaced by g_ai ⇒ gi ; In (3.2.), the clauses for a(cid:7)and f , h are added, i ∈ {1, 2, 3}:C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691447f 0 ⇒ g_a(cid:7)1.(cid:7)2.f 2 ⇒ g_a(cid:7)3.h0 ⇒ g_a(cid:7)1.h1 ⇒ g_a(cid:7)2.h2 ⇒ g_a(cid:7)3.f 1 ⇒ g_a(cid:7)In (3.3), the clauses for aand g are added:g_a(cid:7)2⇒ g_a(cid:7)3(cid:7)2.g_a⇒ g_a(cid:7)1.(cid:7)(I2) of the modified instance I2, we no longer have a fact g3 in (3.1) and thus the above derivation of a(cid:7)(I2) is satisfiable, and its least(cid:7)(I2) is not applicable. In fact, satIn this encoding satcontradiction for the truth value of b3 in any model of satmodel isM = {b0, c0, d0 f 0, g0, b_a1, c_a1, b_a(cid:7)1, g_a(cid:7)1, b1, c1, g1, b_a2}.Then, we have C M = {b, c, d, f , g, h}, (cid:8)M (b) = (cid:8)M (c) = (cid:8)M (g) = 2 and (cid:8)M (d) = (cid:8)M ( f ) = 1, which leads to a single 3-maintaining control K such that K (s) = a for s ∈ {b, c, d, f } and K (g) = a. Note that since K is defined on every stateexcept h, it 3-maintains every set S w.r.t. every E which includes h. As for S = {b}, K (c) and K (d) could remain undefined,since they are not in the closure of b (which can be easily detected) at the price of losing robustness with respect to en-larging S. There is an alternative solution in which K (b) = ainstead of K (b) = a. Here K (s) can not be made undefined onany s (cid:4)= h.(cid:7)(cid:7)5.3. Genuine algorithmFrom the encoding to Horn SAT above, we can distill a direct algorithm to construct a k-maintainable control, if one(cid:7)(I). It uses counters c[s] and c[s_a]exists. The algorithm mimics the steps which a SAT solver might take in order to solve satfor each state s ∈ S and possible agent action a in state s, which range over {−1, 0, . . . , k} and {0, 1, . . . , k}, respectively.Intuitively, value i of counter c[s] (at a particular step in the computation) represents that so far s0, . . . , si are assigned true,and that at least i + 1 steps are needed from s to reach E; in particular, i = −1 represents that no si is assigned true yet.Similarly, value i for c[s_a] (at a particular step in the computation) represents that so far s_a1, . . . , s_ai are assigned true(in particular, i = 0 that no s_ai is assigned true yet), and that at least i + 1 steps are needed from s to reach E startingwith a.Starting from an initialization, the algorithm updates by demand of the clauses in sat(cid:7)(I) the counters (i.e., sets proposi-tions true) using a command upd(c, i) which is short for “if c < i then c := i,” towards a fixpoint. If a counter violation isdetected, corresponding to violation of a clause s0 → ⊥ for s ∈ S ∩ E in (1) or sk → ⊥ for s ∈ S \ E in (4), then no control ispossible. Otherwise, a control is constructed from the counters.The detailed algorithm is shown in Fig. 9.It can be easily adjusted if we simply want to output a non-deterministic control such that each of its refinements is ak-maintainable control, leaving a choice about the refinement to the user. Alternatively, we can implement in Step 4 sucha choice based on preference information. The following proposition states that the algorithm works correctly and runs inpolynomial time.Proposition 9. Algorithm k-Control solves problem k-Maintain, and terminates for any input I in polynomial time. Furthermore, itcan be implemented to run in O (k(cid:22)I(cid:22)) time.Algorithm k-ControlInput:Output:A system A = (S, A, Φ, poss), a set Aag ⊆ A of agent actions, sets of states E, S ⊆ S, an exogenous function exo, and an integer k (cid:2) 0.A control K which k-maintains S with respect to E, if any such control exists. Otherwise, output that no such control exists.(Step 1) Initialization(cid:7)(cid:15) | s ∈ S, a ∈ exo(s), s(cid:7) ∈ Φ(s, a)}, Φ Eposs= {(cid:14)s, a, s(cid:7)(cid:15) | s ∈ S \ E, a ∈ poss(s), s(cid:7) ∈ Φ(s, a)}, and for every s ∈ S, possag(s) =(i) Set Φexo = {(cid:14)s, a, sAag ∩ poss(s).(ii) For every s in E, set c[s] := −1.(iii) For every s in S \ E, set c[s] := k if possag(s) = ∅; otherwise, set c[s] := 0.(iv) For every s in S \ E and a ∈ possag(s), set c[s_a] := 0.(Step 2) Repeat the following steps until there is no change or c[s] = k for some s ∈ S \ E or c[s](cid:2)0 for some s ∈ S ∩ E:(cid:7)] = k do upd(c[s], k).(cid:7)] = i:(i) For any (cid:14)s, a, s(ii) For any (cid:14)s, a, s(cid:7)(cid:15) ∈ Φexo such that c[s(cid:7)(cid:15) ∈ Φ Eposs such that c[sif 0 (cid:3) i < k then do upd(c[s_a], i + 1), elseif i = k then do upd(c[s_a], k).(iii) For any state s ∈ S \ E such that possag(s) (cid:4)= ∅ and i = min(c[s_a] | a ∈ possag(s)) do upd(c[s], i).(Step 3) If c[s] = k for some s ∈ S \ E or c[s] (cid:2) 0 for some s ∈ S ∩ E, then output that S is not k-maintainable w.r.t. E and halt.(Step 4) Output any control K : S \ E → Aag defined on all states s ∈ S \ E with c[s] < k and such that K (s) ∈ {a ∈ possag(s) | c[s_a] =minb∈possag (s) c[s_b] < k}.Fig. 9. Algorithm for problem k-Maintain.1448C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469Proof. The correctness of the algorithm follows from Theorem 7 and the fact that k-Control mimics, starting from facts in(cid:7)(I) by a standard fix-point computation. As for the polynomial time(5) and (3.1), the computation of the least model of satcomplexity, since counters are only increased, and the loop in Step 2 is reentered only if at least one counter has increasedin the latest run, it follows that the number of iterations is polynomially bounded. Since the body of Step 2 and each otherstep is polynomial, it follows that k-Control runs in polynomial time.For the more detailed account, note that bitmaps for S, E and A (if not available in the input) can be generated in timeposs can be constructed in time O (|Φ| + |exo|) and O (|Φ| + |poss| + |S|),O (|S| + |A|). In (i) of Step 1, the sets Φexo and Φ Erespectively, using an auxiliary array for random access to Φ(a, s) in case if the functions are given by their graphs (cf.proof of Corollary 8). Constructing possag(s) for all s ∈ S takes O (|poss|) time, and (ii)–(iv) of Step 1 is feasible in timeO (|S| + |poss|).Using flags to signal changes to counters c[s], c[sa], and auxiliary counters for min(c[s_a] | a ∈ possag(s)), the number ofcalls of upd in Step 2 is O (k(|Φexo| + |Φposs| + |S|)), and each call takes O (1) time. The loop condition can be checked inO (m) time where m is the number of changes in the loop. Hence, the total time for Step 2 is O (k(cid:22)I(cid:22)). Step 3 is O (1) ifa flag is set in Step 2 indicating the reason for the loop exit. Finally, in Step 4, a control K can be easily output in timeO (|poss|). In total, the time is O (k(cid:22)I(cid:22)). (cid:2)Thus, for k bounded by a constant, k-Control can be implemented to run in linear time. We remark that further improve-ments are possible. For example, states may be eliminated beforehand which will not be reachable from any state in S underany control that is eventually constructed. This can be done efficiently by computing an upper bound of Closure(S, K A,exo)in which all possible actions at any state are merged into a single action. Similarly, we can efficiently prune all states whichcan not reach E within k steps in linear time. This can e.g. be achieved by a slight extension of algorithm K -Control,in which flags final[s] and final[s_a] for the states s and actions a ∈ possag(s) signal whether the counters c[s] and c[s_a]correspond to the shortest distance to E, and in Step 2 (ii) and (iii) we chose next always some s_a (respectively s) suchthat its final flag can be switched from false to true and c[s_a] (resp. c[s]) is smaller than k. We leave further discussionand refinements for future work.5.4. Generic maintaining controlsBy the results in the previous subsections, we can solve problem Maintain, which is analogous to k-Maintain but k isnot in the input and can be arbitrarily chosen, in time O (|S|(cid:22)I(cid:22)), that is, in time quadratic in the size of the input. Thisfollows from the fact that k-maintainability of S w.r.t. E for some arbitrary but finite k (cid:2) 0 is equivalent to k-maintainabilityof S w.r.t. E where k = |S| is the number of states.However, we can take advantage of the property that the exact number of steps to reach E does not matter (as long as itis finite), and design a more efficient (linear time) algorithm, which proceeds in two phases. In the first phase, those statess are determined from which E is reachable by an a-path of arbitrary length, and all other states are pruned. In the secondphase, those states are iteratively pruned which are taken by some exogenous action to a state without such an a-path, orwhere each action a leads to a pruned state.We can obtain a genuine linear-time algorithm for solving problem Maintain by adapting the algorithm k-Control suchthat it implements the two phases, where the counters c[s] and c[s_a] only range over a fixed domain independent of k.However, we skip the discovery process and go straight to a simple algorithm, which is shown in Fig. 10. We refer to thisalgorithm as ω-control or ω-maintaining control.It implements the phases 1 and 2 in the steps 2 and 3, respectively. If in Step 4 a maintaining control is found to exist,Step 5 extracts such a control from the data structures. Like for k-maintainability, this requires some care since a naïveextraction does not work (in particular, cycles may cause problems). The following result, whose proof is omitted, statesthat the algorithm works properly.Proposition 10. Algorithm ω-Control solves problem Maintain, and terminates for any input I in polynomial time. Furthermore, itcan be implemented to run in time O ((cid:22)I(cid:22)), i.e., in linear time.6. Encoding k-maintainability for an answer set solverIn this section, we use the results of the previous section to show how computing a k-maintainable control can be en-coded as finding answer sets of a non-monotonic logic program. More precisely, we describe an encoding to non-monotoniclogic programs under the Answer Set Semantics [33], which can be executed on one of the available answer set solvers suchas DLV [29,45] or Smodels [53,65]. These solvers support the computation of answer sets (models) of a given program, fromwhich solutions (in our case, k-maintaining controls) can be extracted.The encoding is generic, i.e., given by a fixed program which is evaluated over the instance I represented by input factsF (I). It makes use of the fact that non-monotonic logic programs can have multiple models, which correspond to differentsolutions, i.e., different k-maintainable controls.C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691449Algorithm ω-ControlInput:Output:A system A = (S, A, Φ, poss), a set Aag ⊆ A of agent actions, sets of states E, S ⊆ S, an exogenous function exo.A control K which maintains S with respect to E, if any such control exists. Otherwise, output that no such control exists.(Step 1) X := E.(Step 2) Repeat until there is no change to X :X := X ∪ {s | ∃a ∈ Aag: ∀s(cid:7)(cid:7) ∈ Φ(s, a), s(cid:7) ∈ X}., s(Step 3) Repeat until there is no change to X :X := X \ {s | ∃a ∈ exo(s): ∃s(cid:7)(cid:7) ∈ Φ(s, a), s(cid:7), s/∈ X};X := X \ {s | ∀a ∈ Aag: ∃s(cid:7), s(cid:7) ∈ Φ(s, a), s(cid:7) /∈ X}.(Step 4) If S \ X (cid:4)= ∅ then output that S is not maintainable w.r.t. E and halt.(Step 5) Construct the control going backwards from the goal states in the following manner.(i) Initialize counters: for all s ∈ X and a ∈ Aag do c[s_a] := |Φ(s, a)|.(ii) For every state s ∈ E do put (s, nop) in a queue Q .(iii) While Q is not empty doPop an element (s, x) from Q ;if s /∈ E then K (s) := x;for all transitions (s(cid:7)c[s_a] := c[sif c[s(cid:7), a, s) such that s ∈ Φ(s(cid:7)_a] − 1;_a] = 0 and K (s(cid:7)(cid:7)a) and s(cid:7) ∈ X do(cid:7)) is undefined then put (s(cid:7), a) in Q .Fig. 10. Algorithm for problem Maintain.In the following, we first describe how a system is represented in a logic program, and then we develop the logicprograms for both deterministic and general, non-deterministic domains. We shall follow here the syntax of the DLV system;the changes needed to adapt the programs to other answer set solvers such as Smodels are minor.6.1. Input representationThe input I of problem k-Maintain, can be represented by facts F (I) as follows.• The system A = (S, A, Φ, poss) can be represented using predicates state, transition, and poss by the followingfacts:– state(s), for each s ∈ S;– action(a), for each a ∈ A;(cid:7)), for each s, s– transition(s,a,s– poss(s,a), for each s ∈ S and a ∈ A such that a ∈ poss(s).(cid:7) ∈ S and a ∈ A such that s(cid:7) ∈ Φ(s, a);• the set Aag⊆A of agent actions is represented using a predicate agent by facts agent(a), for each a ∈ Aag;• the set of states S is represented by using a predicate start by facts start(s), for each s ∈ S;• the set of states E is represented by using a predicate goals by facts goal(s), for each s ∈ E;• the exogenous function exo is represented by using a predicate exo by facts exo(s,a) for each s ∈ S and a ∈ exo(s);The integer k is represented as constant k.Example 7. Coming back to Example 3, the input I is represented as follows:state(b). state(c). state(d). state(f). state(g). state(h).action(a). action(a1). action(e).trans(b,a,c). trans(b,a1,f). trans(c,a,d). trans(d,a,h).trans(f,a,h). trans(f,e,g).poss(b,a). poss(b,a1). poss(f,a). poss(f,e).poss(c,a). poss(d,a).agent(a). agent(a1).start(b). goal(h).exo(f,e).const k=3.1450C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14696.2. Deterministic transition function ΦThe following is a program, executable on the DLV engine, for deciding the existence of a k-control. In addition to thepredicates for the input facts F (I), it employs a predicate n_path(X,I), which intuitively corresponds to X I , and furtherauxiliary predicates.% Define range of 0,1,...,\(k\) for stages.range(0..k).% Rule for (0).n_path(X,I) :- state(X), range(I), I < k, n_path(X,J), J = I+1.% Rule for (1).:- n_path(X,0), goal(X), start(X).% Rule for (2)n_path(X,k) :- trans(X,A,Y), exo(X,A), n_path(Y,k).% Rules for (3)n_path(X,I) :- state(X), not goal(X), range(I),I>0, not some_pass(X,I).\smallskipsome_pass(X,I) :- range(I), I>0, trans(X,A,Y), agent(A),poss(X,A), not n_path(Y,J), I=J+1.% Rule for (4):- n_path(X,k), start(X), not goal(X).% Rule for (5)n_path(X,0) :- state(X), not goal(X).The predicate range(I) specifies the index range from 0 to k, given by the input limit(k). The rules encoding theclause groups (0)–(2) and (4), (5) are straightforward and self explanatory. For (3), we need to encode rules with bodies ofdifferent size depending on the transition function Φ, which itself is part of the input. We use that the antecedent of any(cid:7) ∈ PS(s), is false; to assess this,implication (3) is true if it is not falsified, where falsification means that some atom swe use the auxiliary predicate some_pass(X,I).To compute the non-deterministic control K, we may add the rule:(cid:7)i−1, s+% Define ¯C_Mcbar(X) :- state(X), not n_path(X,k).%Define state level Llevel(X,I) :- cbar(X), not n_path(X,I), I > 0, n_path(X,J), I=J+1.level(X,0) :- cbar(X), not n_path(X,0).% Define non-deterministic control k_plusk_plus(X,A) :- agent(A), trans(X,A,Y), poss(X,A), level(X,I),level(Y,J), J<I, not goal(X).In cbar(X), we compute the states in C M , and in level(X,I) the level (cid:8)M (s) of each state s ∈ C M (= C M for thecorresponding model M of sat(I)). The non-deterministic control K+M is then computed in k_plus(X,A).Finally, by the following rules we can non-deterministically generate any control which refines K% Selecting a control from k_plus.control(X,Y) :- k_plus(X,Y), not exclude_k_plus(X,Y).exclude_k_plus(X,Y) :- k_plus(X,Y), control(X,Z), Y<>Z.+M :The first rule enforces that any possible choice for K (s) must be taken unless it is excluded, which by the second ruleis the case if some other choice has been made. In combination the two rules effect that one and only one element fromK+M (s) is chosen for K (s).C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691451Example 8. If the input representation of Example 5 is in a file exa3.dlv and the above program, denoted by Πdet , in afile det.dlv, the DLV engine can be invoked e.g. bydlv exa3.dlv det.dlv -N=3 -filter=controlwhich outputs the controls; here -N=3 sets the range of integers dynamically supported by the engine to 3, and -filter=control effects that the answer sets are clipped to the predicate control. In the particular case, the output onthe call is (apart from system version information){control(b,a), control(c,a), control(d,a)}yielding the unique control which exists in this case. If we would add a further agent action a2 to the action set, and extendthe transition function by Φ(b, a2) = c, then a call of DLV for the respective representation would yield{control(b,a2), control(c,a), control(d,a)}{control(b,a), control(c,a), control(d,a)}corresponding to the two alternative controls which emerge, since the agent can take either action a or action a2 in state a.6.3. Non-deterministic transition function ΦAs for deciding the existence of a k-maintaining control, the only change in the code for the deterministic case affectsStep (3). The modified code is as follows, where n_apath(X,A,I) intuitively corresponds to X_ A I .% Rules for (3); different from above% (3.1)n_path(X,I) :- state(X), not goal(X), range(I), I>0, not some_apass(X,I).some_apass(X,I) :- range(I), I>0, agent(A), poss(X,A), not n_apath(X,A,I),not goal(X).% (3.2)n_apath(X,A,I) :- agent(A), trans(X,A,Y), poss(X,A), range(I), I>0,n_path(Y,J), I=J+1, not goal(X).% (3.3)n_apath(X,A,I) :- agent(A), poss(X,A), range(I), I>0, I<k,n_apath(X,A,J), J=I+1, not goal(X).Here, some_apass(X,A,I) plays for encoding (3.1) a similar role as some_pass(X,I) for encoding (3) in the deter-ministic encoding.To compute the non-deterministic control K+M , we may then add the following rules:% Define ¯C_Mcbar(X) :- state(X), not n_path(X,K), limit(K).% Define state action level, alevel (>=1)alevel(X,I) :- alevel_leq(X,I), I=J+1, range(J), not level_leq(X,J).alevel_leq(X,I) :- cbar(X), not goal(X), poss(X,A), agent(A), I>0,range(I), not n_apath(X,A,I).% Define non-deterministic control k_plusk_plus(X,A) :- agent(A), alevel(X,I), poss(X,A), not n_apath(X,A,I).Here, the value of (cid:8)M (s) is computed in alevel(X,I), using the auxiliary predicate alevel_leq(X,I) which intuitivelymeans that (cid:8)M ( X) (cid:3) I .+M , we can add the two rules for selecting a control from k_plus from the programFor computing the controls refining Kfor the deterministic case.Example 9. Let us revisit the instance I1 in Example 6. We get the DLV representation oftrans(c,a,f). to the representation for I . Assuming that it is in a file exa4.dlv and the program Πndetndet.dlv, a callI1 by adding the factin a filedlv exa4.dlv ndet.dlv -N=3 -filter=control1452C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469yields no output (apart from some system version print), which is correct. On the other hand, if we consider the input I2for the variant of Example 6 (with agent action a(cid:7)) = { f , h}), then the output ispossible in g and Φ(g, a(cid:7){control(b,a1), control(c,a), control(d,a), control(f,a), control(g,a1)}(where a1 encodes a(cid:7)). Again, this is a correct result.6.4. Layered use of negationAn important note at this point is that the programs Πdet and Πndet do not necessarily have models which corre-(cid:7)(I), respectively. The reason is that the use of negation notspond to the least models of the Horn theories sat(I) and satsome_pass(X,I) and resp. not some_apass(X,I) may lead through cycles in recursion. Thus, not each control com-puted is necessarily maximal (even though the maximal controls will be computed in some models). Furthermore, becauseof cyclic negation it is not a priori clear that the part of the program deciding the existence of a control is evaluated by DLV(cid:7)(I) has ain polynomial time. However, consistency (i.e., existence of an answer set) is guaranteed whenever sat(I) resp. satmodel.It is possible to modify Πdet such that the use of negation in recursion cycles is eliminated, by using standard codingmethods to evaluate the body of the rule in (3). Namely, introduce for Πdet a predicate all_true and replace notsome_pass(X,I) in the code for (3) with all_true(X,I), which is defined such that all_true(s, i) represents thatevery s(cid:7)i−1 ∈ PS(s) is assigned true, which can be checked using a linear ordering (cid:3) on PS(s). However, we refrain from thishere.Notice that in the case where PS(s) has size bounded by a constant c, we can use a predicate ps of arity c + 1 torepresent PS(s) = {s(1), . . . , s(l)} by a single fact ps(s, s(1), . . . , s(l), . . . , s(l)) where s(l) is reduplicated if l < c. It is then easyto express the clause (3).We can similarly modify Πndet such that the use of negation in recursion cycles is eliminated, where we use a linearordering on Aag ∩ poss(s) (or simply on Aag, assuming that there are not many agent actions overall). Finally, we can alsouse for the program Πdet simply an ordering of Aag, since the deterministic transformation Φ(s, a) is a (partial) surjectivemapping of A onto PS(s), which guarantees that via A ∩ poss(s) each s(cid:7) ∈ PS(s) can be accessed through Φ.The modified programs use negation only in a stratified manner, and thus will be evaluated by DLV in guaranteedpolynomial time in the size of the DLV representation of sat(I) and sat6.5. State descriptions by variables(cid:7)(I), respectively.In many cases, states of a system are described by a vector of values for parameters which are variable over time.It is easy to incorporate such state descriptions into the LP encoding from above, and to evaluate them on answer setsolvers provided that the variables range over finite domains. In fact, if any state s is given by a (unique) vector s =(cid:14)s1, . . . , sm(cid:15) m > 0, of values si , 1 (cid:3) i (cid:3) m, for variables Xi ranging over nonempty domains, then we can represent s asfact state(v i) and use a vector X1,...,Xm of state variables in the DLV code, in place of a single variable, X. Nofurther change of the programs from above is needed.1, . . . , v iriSimilarly, we can easily accommodate actions a(P 1, P 2, . . . , Pm) with parameters P 1, . . . , Pm (which is important) froma finite set if desired. However, here the rule defining exclude_k_plus(X,Y) should be replaced by all rules emergingif the atom Y <> Z in the body is replaced by Yi <> Zi, i ∈ {1,...,m} (assuming that Y and Z are replaced byY1,...,Ym and Z1,...,Zm, respectively).Another possibility to handle state descriptions by variables would be to implement a coding scheme, which maps eachvector s = (cid:14)s1, . . . , sm(cid:15) into an integer i(s), represented by fact code(i(s), s1, . . . , sm).Furthermore, we point out that the input need not consist merely of facts, but may also involve rules to define thepredicates of the input representation more compactly. Finally, the facts for action can be dropped, since they are notreferenced by any rule in programs Πdet and Πndet.For illustration, we consider the buffer example from Section 3.Example 10. Recall that states in the buffer example are given by pairs of integers (cid:14)i, j(cid:15) where i and j are the numbers ofobjects in buffer b1 and b2, respectively. We thus use variables X1,X2 and Y1,Y2 in place of X and Y, respectively.For buffer capacity of 3, S = {(cid:14)0, 0(cid:15)}, E = {(cid:14)0, j(cid:15) | 1 (cid:3) j (cid:3) 3}, and k = 6, the input can be represented as follows:state(X1,X2) :- #int(X1), #int(X2), X1 <= 3, X2 <= 3.start(0,0).goal(0,X2) :- state(0,X2).trans(X1,X2,m_12,Y1,Y2) :- state(X1,X2), state(Y1,Y2), X1=Y1+1, Y2=X2+1.C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691453trans(X1,X2,m_21,Y1,Y2) :- state(X1,X2), state(Y1,Y2), Y1=X1+1, X2=Y2+1.trans(X,X2,proc,X,Y2) :- state(X,X2), state(X,Y2), X2=Y2+1.trans(X1,X,ins,Y1,X) :- state(X1,X), state(Y1,X), Y1=X1+1.poss(X1,X2,m_12) :- state(X1,X2), 1 <= X1, X2 <= 2.poss(X1,X2,m_21) :- state(X1,X2), 1 <= X2, X1 <= 2.poss(X1,X2,proc) :- state(X1,X2), 1 <= X2.poss(X1,X2,ins) :- state(X1,X2), X1 <= 2.agent(m_12). agent(m_21). agent(proc). exo(ins).const k = 6.Here, equalities X1=0 for X1,X2 in the rule defining goal and X1=Y1 in the definition of trans(X,X2,proc,X,Y2)etc are pushed through.Invoking DLV, assuming the representation is stored in file exa-buffer.dlv and the expanded version of Πdet in afile det2.dlv, withdlv exa-buffer.dlv det2.dlv -N=6 -filter=controlyields 13 models, of which encode different controls. Among the maximal controls is{control(1,0,m_12), control(1,1,m_12), control(1,2,m_12), control(1,3,proc),control(2,0,m_12), control(2,1,m_12), control(2,2,proc), control(2,3,proc),control(3,0,m_12), control(3,1,proc), control(3,2,proc),control(3,3,proc)}which is defined on all states outside E, and thus constitutes a 6-maintaining control for the whole system.7. Computational complexityIn this section, we consider the complexity of constructing k-maintainable controls under various assumptions. To thisend, we first describe the problems analyzed and give an overview of the complexity results. After that, the results areestablished in a separate subsection; the reader who is not interested in the technical proofs might safely skip it.7.1. Problems considered and overview of resultsFollowing the common practice, we consider here the decision problem associated with k-Maintain, which we referto as k-Maintainability: Given a system A = (S, A, Φ, poss), a set Aag ⊆ A of agent actions, sets of states E, S ⊆ S, anexogenous function exo, and an integer k (cid:2) 0, decide whether S is k-maintainable with respect to E in A. Furthermore, wealso consider Maintainability, which has the same input except k and asks whether S is maintainable with respect to E inA.We consider the problems in two different input settings, in line with the previous sections:Enumerative representation: The constituents of an instance I are explicitly given, i.e., the sets (A, S, Aag, S, and E) inenumerative form and the functions (Φ(a, s), poss(s), and exo) by their graphs in tables.State variables representation: A system state s is represented by a vector s = (v 1, . . . , vm) of values for variables f 1, . . . , fmranging over given finite domains D1, . . . , Dm, while A and Aag are given in enumerative form. We assume thatpolynomial-time procedures for evaluating the following predicates are available:(cid:7)), in_poss(s, a), and in_exo(s, a) for deciding s• in_Phi(s, a, s• in_S(s) and in_E(s) for deciding whether s ∈ S and s ∈ E, respectively.(cid:7) ∈ Φ(s, a), a ∈ poss(s), and a ∈ exo(s), respectively.Orthogonal to this, we also consider (1) general k versus constant k, in order to highlight the complexity of smallwindows of opportunity for maintenance; (2) absence of exogenous actions, to see what cost intuitively is caused by anadversary; and (3) non-deterministic versus deterministic actions.The results of the complexity analysis are compactly summarized in Tables 1 and 2, in which unless stated otherwise,the entries stand for completeness results under logspace reductions. We assume that the reader is familiar with the classesP (polynomial time), EXP (exponential time), L (logarithmic workspace), NL (non-deterministic logarithmic work space),co-NP (co-non-deterministic polynomial time), and PSPACE (polynomial space) appearing in the tables, and refer to [57]and references therein for further background on complexity. By LH we denote the logarithmic time hierarchy [11,38],which is given by LH =i(cid:2)0 Σ logi, where Σ logidenotes the decision problems solvable on an alternating Turing machine in(cid:5)1454C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469Table 1Complexity of deciding (k-)Maintainability under enumerative representation (logspace completeness)+/− exogenous actionsdeterministicnon-deterministick-Maintainabilitygiven kP / NL (Th. 11/15)P (Th. 11/13)constant k (cid:2) 1P / in LH (⊂ L) (Th. 11/16)P / in LH (⊂ L) (Th. 11/16)MaintainabilityP / NL (Co. 12/Th. 15)P (Co. 12/Th. 13)Table 2Complexity of deciding (k-)Maintainability under state variables representation (logspace completeness)+/− exogenous actionsdeterministicnon-deterministick-Maintainabilitygiven kEXP / PSPACE (Th. 18/21)EXP (Th. 18/20)constant k (cid:2) 1EXP / co-NP (Th. 18/22)EXP / co-NP (Th. 18/22)MaintainabilityEXP / PSPACE (Co. 19/Th. 21)EXP (Co. 19/Th. 20)logarithmic time with at most i−1 alternations between existential and universal states, starting in an existential state. Notethat LH is strictly included in L. A more refined complexity assessment is given in Section 7.2. However, we refrain herefrom providing a sharp complexity characterization of the problems classified within LH in terms of completeness under asuitable notion of reduction, since they are not central to the maintainability issue under an “adversarial” environment.Under enumerative representation (Table 1), (k-)Maintainability has the same complexity as Horn SAT, which is P-complete [57]. In fact, this holds also for the case of constant k = 1 and the restriction that all actions are deterministic andthat there is a single exogenous action. Thus, even in the simplest setting with an adversary according to the dimensionsabove, the problem already harbors its full complexity; excluding non-deterministic actions and/or fixing k does not makethe problems simpler. Intuitively, this is because with the help of exogenous actions, one can simulate non-determinism andsplit sequences of agent maintenance actions into small segments.On the other hand, when exogenous actions are excluded (listed under “-”), (k-)Maintainability is always easier whenthe actions are deterministic or the maintenance window is small (k is constant). In summary, the results show that exoge-nous actions can not be compiled efficiently away (with reasonable complexity) to an instance of maintainability under asmall maintenance window, and that non-deterministic actions are indispensable for such a compilation.The reason is that in absence of exogenous actions, k- Maintainability is akin to a graph reachability resp. planningproblem (for the latter, see Section 8.3). Indeed, define for a fixed system A = (S, A, Φ, poss), a set of agent action Aag ⊆ A,and sets E, S ⊆ S of states the predicates ri(s), i (cid:2) 0, on s ∈ S inductively byr0(s) = s ∈ E,ri+1(s) = s ∈ E ∨ ∃a ∈ Aag ∩ poss(s)∀s(cid:7) ∈ S(cid:3)s(cid:7) ∈ Φ(s, a) ⇒ ri(s(cid:7)(cid:4)),for i (cid:2) 0.(1)Informally, ri(s) expresses that some state in E can be reached from s within i agent actions, and it holds that S is k-maintainable with respect to E, exactly if rk(s) holds for every s in S (as proved in Lemma 1 below). The predicate rk(s)is definable in first-order predicate logic with a suitable relational vocabulary (using the predicates given for enumerativerepresentation). As well-known, the first-order definable properties are those which can be decided in LH [11,38]. Since LHis considered to contain problems which have much lower complexity than hard problems in P, the effect of exogenousactions is drastic in complexity terms.Under state variables representation (Table 2), the complexity of the problems, with few exceptions increases by anexponential. This increase is intuitively explained by the fact that state variables permit in general an exponentially smallerinput representation, which must be unpacked for solving the problem. The exception for constant k in absence of exogenousfunctions, where the complexity increases from within LH to co-NP, is intuitively explained by the fact that the quantifier(cid:7) ∈ S”, ranges over a polynomial set of values (in the input size), and“∃a ∈ Aag ∩ poss(s)” in Eq. (1), as opposed to “∀sthus can be deterministically eliminated. Exogenous actions cannot be compiled efficiently away in the same cases as underenumerative representation.For practical concerns, we can draw from the results above the following conclusions. While k-Maintainability istractable under enumerative representation, it is because of its P-completeness not amenable to efficient parallel com-putation and not solvable within poly-logarithmic workspace under widely believed complexity hypotheses. However, ifexogenous actions are absent and the maintenance window has size bounded by a constant, the problem can be solved inconstant time using a polynomial number of processors as follows from membership in LH (see [38]).The EXP-completeness results for state variables representation imply that the problems are provably intractable, andthat exponential time and, by current methods, also exponential workspace is needed to solve them. Thus, a polynomial-time reduction to popular propositional logic engines such as SAT/UNSAT or QBF solvers (see http://www.satcompetition.org/,http://www.qbflib.org/ for state-of-the-art systems) is infeasible in general. Only in the “cheapest” cases (where the size ofC. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691455the maintenance window is bounded by a constant and exogenous actions are absent), a polynomial-time reduction of k-Maintainability to SAT/UNSAT solvers is feasible; a polynomial-time reduction of (k-)Maintainability to QBF solvers is onlyfeasible in deterministic domains and in absence of exogenous actions. When exogenous actions are possible, the full com-plexity shows up and one has to resort to more expressive engines such as answer set solvers (as discussed in Section 6.5)for instance. We remind, however, that the results in Table 2 are worst-case complexity results, and that under furtherconstraints the problems may be solvable with polynomial resources. A detailed study of this issue remains for future work.7.2. Enumerative representationWe start with the case of enumerative representation. Our first result is the following.Theorem 11 (Problem k-Maintainability is P-complete (under logspace reductions)). The P-hardness holds under the restriction thatk = f ( A, S, E) is any function of A, S, and E such that f ( A, S, E) (cid:2) 1 (in particular, for fixed k (cid:2) 1), even if in addition all actions aredeterministic and there is only one exogenous action.Proof. The membership of k-Maintainability in P follows from Corollary 8.We prove P-hardness under the stated restriction by a reduction from deciding logical entailment π |(cid:8) q of a proposi-tional atom q from a propositional Horn logic program (PHLP) π , which is a set of rules of the formb0 ← b1, . . . , bn, n (cid:2) 0,(2)and each bi is a propositional atom from an underlying atom set At; b0 is the head and b1, . . . , bn is the body of the rule.←As well-known, π |(cid:8) q holds iff there is a sequence of rules r1, r2, . . . , rm, m (cid:2) 1, from π where ri is of form bi0bi1 , . . . , bin , such that {bi1 , . . . , bin= q, called aproof of q from π . Informally, q is derived by successive application of the rules r1, . . . , rm, where ri “fires” after all previousrules r1, . . . , ri−1 have fired.}, for all i ∈ {1, . . . , m} (thus in particular, 1n = 0) and bm0} ⊆ {b10 , . . . , bi−10A natural idea is to represent backward rule application rm, rm−1, . . . , r1 through agent actions; for a rule r of form (2),there is an agent action a_r which applied to a state sb0 representing b0, brings the agent non-deterministically to any statesbi representing bi , i ∈ {1, . . . , n}. Given a state sq encoding q, S = {sq} is maintainable w.r.t. a set of states E encoding thefacts in π if q has a proof from π . However, this does not account for the restriction that k = f ( A, S, E) for any such f . Thekey for this is to establish the result for the extremal case where k = 1 is constant (i.e., for 1-maintainability) and then toextend it to the general case.Using a constrained rule format in π and an exogenous action, we can emulate non-deterministic agent actions andsequences of agent actions with some coding tricks by alternating sequences of deterministic agent and exogenous actions,such that provability of q from π corresponds to 1-maintainability of S w.r.t. a set E in a system A constructible inlogarithmic workspace from q and π .Without loss of generality, we assume that each rule has either zero or two atoms in the body (i.e., n = 0 or n = 2 in(2)). We construct from π and q a system A = (S, A, Φ, poss), sets of states S and E, a set Aag ⊆ A, and a function exo asfollows:1. S: For each atom f in π and rule r ∈ π , f 0, . . . , f m and r1, . . . , rm are states in S. Furthermore, if the body of r is u, vthen (u, v)0, . . . , (u, v)m−1 are states in S.2. A = {a_r | r ∈ π } ∪ {e}.3. Φ: For any rule r ∈ π with head f , Φ(a_r, f i) = {ri} for i ∈ {1, . . . , m} and Φ(a_r, ( f , v)i) = {ri}, for ( f , v)i ∈ S, i ∈{1, . . . , m − 1}. If moreover r has body u, v, then Φ(e, ri) = {(u, v)i−1}, and Φ(e, (u, v)i−1) = {v i−1}, for i ∈ {1, . . . , m − 1}.In all other cases, Φ(a, s) = ∅.4. poss: For each state s, poss(s) = {a ∈ A | Φ(a, s) (cid:4)= ∅}.5. E = {r1, . . . , rm | r ∈ π }.6. S = {qm}.7. Aag = A \ {e}.8. exo: for all rules r ∈ π of form f ← u, v, exo(ri) = {e} for i ∈ {1, . . . , m} and exo((u, v) j) = {e} for j ∈ {1, . . . , m − 1}. Forall other states s, exo(s) = ∅.The transition diagram for the system constructed for π = {a ← b, c; b ←; c ←} is shown in Fig. 11. Intuitively, the statef i encodes that f can be derived from π with a proof of length at most i. This is propagated in backward rule application.Each agent action a_r selects a rule r to prove an atom f ; if the rule has a body u, v, the exogenous action pushes theagent to prove both u (from (u, v)) and v within decreased recursion depth.We claim that π |(cid:8) q iff there exists some 1-maintaining control K for S with respect to E in A.Suppose first that π |(cid:8) q. We then construct a 1-maintaining control K for S with respect to E as follows. Let P =r1, . . . , rk be a proof of q from π such that, without loss of generality, all rules ri have different heads. Set D = {qm} anditerate the following until D remains unchanged: For each f i ∈ D resp. (u, v)i ∈ D, i (cid:2) 0, let r j be the rule with head f1456C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469Fig. 11. Transition diagram of the system for π = {a ← b, c; b ←; c ←} and q = a (S and E encircled).(cid:7)i−1resp. u in P . Define K ( f i) = {a_r j} resp. K ((u, v)i) = {a_r j}, and add, if r j has body uto D. Since P is a proof of q from π , the rule r j always exists, and for each state s in Closure(S, A K ,exo) \ E (=D), K (s) isdefined and Φ(K (s), s) yields some state in E. Hence, K is a 1-maintaining control for S with respect to E in A.the states (u, v)i−1 and v(cid:7), v(cid:7)Conversely, suppose K is a 1-maintaining control for S with respect to E in A. Without loss of generality, K (s) isundefined for all states s ∈ E. An easy induction on i (cid:2) 1 shows that for each f i ∈ Closure(S, A K ,exo) resp. (u, v)i ∈Closure(S, A K ,exo), it holds that π |(cid:8) f resp. π |(cid:8) u and π |(cid:8) v. For i = 1, suppose first K ( f 1) = a_r. Rule r must haveform f ← ; otherwise, some states (u, v)0, v 0 would be in Closure(S, A K ,exo), which contradicts that K is a 1-maintainingcontrol. Hence, π |(cid:8) f . Next suppose K ((u, v)1) = a_r. Then, for similar reasons, r must be of form u ←, hence π |(cid:8) u.Furthermore, v 1 ∈ Closure(S, A,exo) and as already established π |(cid:8) v. For i > 1, suppose K ( f i) = a_r. Then either r is ofform f ← and thus π |(cid:8) f , or of form f ← u, v. In the latter case, (u, v)i−1 ∈ Closure(S, A K ,exo) and hence, by the inductionhypothesis, π |(cid:8) u and π |(cid:8) v. Consequently, π |(cid:8) f . Similarly, if K ((u, v)i) = a_r, then either r is of form u ← or of formu ← u, thus π |(cid:8) u.Since v i ∈ Closure(S, A K ,exo), as already established π |(cid:8) v. Consequently, π |(cid:8) f . This proves the statement for i > 1, andconcludes the induction. Since qm ∈ Closure(S, A K ,exo), we have π |(cid:8) q. This proves our claim.(cid:7))i−1 ∈ Closure(S, A K ,exo), which by the induction hypothesis implies π |(cid:8) uand π |(cid:8) vand (u(cid:7), v(cid:7), v(cid:7)(cid:7)(cid:7)Notice that A, S and E can be constructed in logarithmic workspace from π and q. This proves P-hardness of 1-Maintaintability. An easy observation is that every agent action in the system A leads to some state in the set E described.Hence, S is 1-maintainable with respect to E in A iff S is k-maintainable with respect to E in A for any f ( A, S, E) suchthat f ( A, S, E) (cid:2) 1. Hence, P-hardness under the stated restriction follows. (cid:2)The following result is immediate from this result and the fact that maintainability is equivalent to k-maintainabilitywhere k = |S| is the number of states.Corollary 12. Maintainability is P-complete. The P-hardness holds even if all actions are deterministic and there is only one exogenousaction.The following result states a further P-complete restriction of the above problems.Theorem 13. k-Maintainability and Maintainability with no exogenous actions are P-complete.Proof. Membership in P was established above. The P-hardness follows from Theorem 11 by merging the (single) exogenousaction e into the agent actions as follows: For each state s such that e ∈ exo(s), redefine every action a ∈ poss(s) ∩ Aag byΦ(s, a) := Φ(s, a) ∪ Φ(s, e). It is easy to see that given S and E, S is |S|-maintainable w.r.t. E in the resulting system AiffS is |S|-maintainable w.r.t. E in A. Furthermore, Ais computable in logspace from A. This implies the result. (cid:2)(cid:7)(cid:7)The hardness results above are at the border of the hardness frontier, in the sense that in the absence of exogenousactions and, in case of Maintainability also non-determinism, the problems are no longer P-hard. The following lemmagives a useful characterization of k-maintainability for this purpose.Lemma 14. Given a system A = (S, A, Φ, poss), a set of agents action Aag ⊆ A, and a set of states E, a set of states S is k-maintainablewith respect to E in absence of exogenous actions (i.e., exo is void), k (cid:2) 0, iff rk(s) as in (1) holds for all s ∈ S.Proof. For the only if direction, consider any 1-maintaining control K which without loss of generality is undefined onevery s ∈ E. For every state s ∈ Closure(S, A K ,exo) = Closure(S, A K ), let ds be the distance of s from E under K , i.e., theC. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691457largest i such that σ = s0, s1, . . . , si ∈ Unfoldk(s, A, K ) where s0 = s. By an easy induction on ds (cid:2) 0, we obtain using K (s) aswitness for a in (1), that rds (s), rds+1(s), . . . , rk(s) must hold for s. Hence, rk(s) holds for every s ∈ S.Conversely, let for each s ∈ S be is the least integer i such that ri(s) holds. If is > 0, then define K (s) := a for somearbitrary action a ∈ Aag ∩ poss(s) witnessing (1) for i + 1 = is, otherwise (i.e., if is = 0 or ri(s) does not hold for any i (cid:2) 0)let K (s) undefined. Then, K is a k-maintaining control for S with respect to E, since by definition of the relations ri , foreach s ∈ Closure(S, A K ), and σ = s0, s1, . . . , sl ∈ Unfoldk(s, A, K ) such that s0 = s it holds that l (cid:3) k and sl ∈ E (recall that, astacitly assumed, Φ(a, s) (cid:4)= ∅ for each a ∈ poss(a)). Hence, S is k-maintainable with respect to E. (cid:2)We then establish the following result.Theorem 15. k-Maintainability and Maintainability for systems with only deterministic actions and no exogenous actionsare NL-complete.(cid:7) = Φ(s, a) can beProof. In this case, deciding ri(s) for given s ∈ S and i (cid:2) 0 is in NL: If s /∈ E, a proper a in (1) and s(cid:7)) established, maintaining a counter i. This is feasible in logarithmic workspace in theguessed and, recursively, rk−1(srepresentation size of A. By looping through all s ∈ S, it thus follows from Lemma 14 that deciding whether S is k-maintainable with respect to E, where k (cid:3) |S|, is non-deterministically feasible in logarithmic workspace. This impliesNL-membership of k-Maintainability and Maintainability. The hardness follows from a simple reduction of the well-knownNL-complete Reachability problem [57] to k-resp. Maintainability: Given a directed graph G = (V , E) and nodes s, t ∈ V ,decide whether there is a directed path from s to t in G. Define A = (S, A, Φ, poss) such that S = A = V , Φ(v, w) = w,and poss(v) = {w | v → w ∈ E}. Then, for Aag = A, S = {s} is |V |-maintainable w.r.t. E = {t} in A iff there is a directed pathfrom s to t in G. Clearly, A is constructible in logarithmic workspace from G. This shows the NL-hardness. (cid:2)In case of constant k, Eq. (1) is decidable by a straightforward deterministic recursive procedure in logarithmic workspace,even under non-determinism, since the recursion depth is bounded by a constant and each recursion level requires onlylogarithmic work space. Hence, k-Maintainability is decidable in logarithmic space. A finer grained analysis that it is withinthe class Π logk+1 of the logarithmic time hierarchy, which is a much better upper bound and makes completeness for logspace(under suitable reductions) fairly unlikely.We assume that the input I of k-Maintainability for fixed k, is a relational structure MI with universe U (MI ) = S ∪ A,(cid:7)), in_poss(s, a), in_exo(s, a), in_S(s) and in_E(s) from above, andand relations over U (MI ) for the predicates in_Phi(s, a, srelations for the additional predicates ag_act(a), in_S(s), and in_A(a) representing membership a ∈ Aag, s ∈ S and a ∈ Afor each s, a ∈ U (M ), respectively. The structure MI is encoded in a standard way by a bit-string [38].Theorem 16. Problem k-Maintainability for systems without exogenous actions is in Π log2k+1 (= co-Σ log2k+1), if k (cid:2) 0 is constant.Proof. Any first-order formula ψ1 ∨ Q xψ2 (resp. ψ1 ∧ Q xψ2) such that ψ1 has no free variables and Q ∈ {∃, ∀}, is logicallyequivalent to Q x(ψ1 ∨ ψ2) (resp. Q x(ψ1 ∧ ψ2)). Exploiting this, rk(s) in (1) can be written, using the vocabulary from above,as a first-order formula φk(x) in prenex form ∃x1∀x2∃x3 · · · Q kxkψ(x1, . . . , xk, x) where ψ(x1, . . . , xk, x) is quantifier-free, suchthat for any element s ∈ U (MI ) of an input structure M, the sentence in_S(s) ∧ φk(s) is true on M iff rk(s) holds. Hence,by Lemma 14, k-maintainability of S w.r.t. E in A is definable by a Πk+1 prenex sentence ∀x0∃x1 · · · Q kxkψ (cid:7)(x0, x1, . . . , xk),where ψ (cid:7)(x0, x1, . . . , xk) is quantifier-free, on the above vocabulary. Whether a fixed such sentence is false on a givenstructure MI can be decided by an alternating Turing machine, starting in an existential state, in logarithmic time using kalternations [11,38]. Hence, the problem is in co-Σ log2k+1. (cid:2)k+1= Π logWe remark that the hardness results in this section can be further strengthened to the case where only 2 agent actionsare available, but leave a proof of this to the interested reader.7.3. State variablesThe following is an easy lemma, which in combination with the results in the previous subsection implies most upperbounds in Table 2.Lemma 17. For any instance of k-Maintainability resp., Maintainability in which states are represented by variables, the corre-sponding instance in ordinary (enumerative) form can be generated in polynomial workspace.Using this lemma, we then prove the following result.Theorem 18. Under state representation by variables, k-Maintainability is EXP-complete. The EXP-hardness holds under the restric-tion that k = f ( A, S, E) is any function of A, S, and E such that f ( A, S, E) (cid:2) 1 (in particular, for fixed k (cid:2) 1), even if in addition allactions are deterministic and there is only one exogenous action.1458C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469Proof. Membership in EXP follows easily from Lemma 17 and Theorem 11. The EXP-hardness is shown by a reduction fromdeciding inference π |(cid:8) p(t) of a ground atom p(c) from a function-free Horn logic program π with variables (i.e., a datalogprogram), which consists of rules of the formp0(t0) ← p1(t1), . . . , pn(tn), n (cid:2) 0,(3)where each pi is the name of a predicate of arity ai (cid:2) 0 and ti = ti,1, . . . , ti,n is a list of constants and variables ti, j ; p0(t0)is the head and p1(t1), . . . , pn(tn) the body of the rule.It holds that π |(cid:8) p(c) iff there is a sequence rules ri of the form pi0 (ti0 ) ← pi1 (ti1 ), . . . , pin (tin ) and substitutions θifor ri , i.e., a mappings from the variables in ri to the set of constants Cπ in π , such that {pi1 (ti1 θi), . . . , pin (tin θi)} ⊆{p10 (t10 θ1), . . . , pi−10 (ti−10 θi−1)}, for all i ∈ {1, . . . , m} (thus in particular, 1n = 0) and pm0 (tm0 θm) = p(c), called a proof ofp(c) from π . Informally, p(c) is derived by successive application of the rule instances r1θ1, . . . , rmθm, like in a propositionallogic program.Deciding whether π |(cid:8) p(t) is well-known to be EXP-complete, cf. [22]. The construction is similar in spirit to the onein proof of Theorem 11 but more involved.To prove EXP-hardness of k-Maintainability under the given restriction, we first focus on 1-Maintainability, and wedescribe how to reduce π |(cid:8) p(c) in logarithmic workspace to deciding 1-maintainability of a set of states S w.r.t. a set ofstates E in an agent system A.Without loss of generality, we make the following assumptions on π and p(c):• The set of constants occurring in π , Cπ , is {0, 1};• each rule r in π has either zero or two atoms in the body;• all rules in r are safe, i.e., each variable X occurring in the head of a rule r also occurs in the body;• π uses only one predicate, p;• c = (0, 0, . . . , 0).Any problem π |(cid:8) p(c) can be transformed to an equivalent one of this form in logarithmic workspace.Similar as in the propositional case, the idea is to represent a reversed proof rm, θm, . . . , r1θ1 of p(c) from π throughagent actions, and model backward rule applications through agent actions; note that m ranges from 1 to 2ap , where apis the arity of p (thus m requires ap bits). The problem here which makes this more complex is the fact that we must,for each rule ri , also take θi into account. If ri has a nonempty body, the candidates for θi are systematically generated byalternating agent and exogenous actions. For each possible such θi , the derivation of the body atoms p(ti2 θi) and p(ti2 θi) isthen explored.More precisely, for each ground atom p(c), and m ∈ {0, . . . , 2pa }, we have a state (c, m, prove) outside E which intuitivelysays that p(c) is derivable within m (0 (cid:3) m (cid:3) 2pa ) steps. For each rule r in π , there is an agent action ar , which is possibleon (c, m, prove) if m > 0 and p(c) unifies with the head p(t) of r, and it results in the state (c, m, r, apply), which is in E.For r of form p(t) ← p(t1), p(t2), two phases are now established: (1) the selection of a substitution θ for the variables Xin r, and (2) the generation of states (c1, m−1, prove) and (c1, m−1, prove), where c1 = θ1 and c2 = θ2, for the recursivetest.As for 1) an exogenous action e pushes the agent from (c, m, r, apply) to a state (c, m, (0, 0, . . . , 0), r, sel_θ). Here(0, 0, . . . , 0) is the substitution θ : X1 = 0, . . . , Xk = 0 to all variables in r. By executing an agent action incθ on thisstate, this vector is incremented to (0, 0, . . . , 0, 1), resulting in a state (c, m, (0, 0, . . . , 0, 1), r, incθ ) in E, from which epushes the agent to a state (c, m, (0, 0, . . . , 1), r, sel_θ), where Xn = 1 in θ . Here again incθ is possible, leading to a state(c, m, (0, 0, . . . , 1, 0), r, incθ ) in E from which e pushes the agent to the state (m−1, t, (0, 0, . . . , 1, 0), r, sel_θ). Here againan inc action is possible for the agent etc.In each state (c, m, θ, r, sel_θ) such that p(tθ) = c, the agent might alternatively take the action choose, which bringsher to the state (c, m, θ, r, chosenθ ) in E, which closes phase 1. The exogenous action e pushes the agent from this state tothe state (m, t1θ, t2θ, do_split) out of E. From this state, e pushes the agent further to the state (t1θ, m−1, prove), and theagent must take at (m, t1θ, t2θ, do_split) the action split, which brings her to the state (t2θ, m−1, goto_prove) in E, fromwhich e pushes the agent to (t2θ, m−1, prove). Fig. 12 gives a summary of the steps in graphical form.Fig. 12. Schematic transition diagram for backward application of rule r : p(t) ← p(t1), p(t2) with substitution θ to prove p(c).C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691459In this way, the derivation of p(0, 0, . . . , 0) from π is encoded to deciding 1-maintainability of S = {(2d, (0, 0, . . . , 0),prove)} with respect to the set of states E described above. Note that to prove p(c) from π via rule r, only one instanceof rθ must be chosen; the 1-maintaining control has to single out this θ , by proper placement of the action chosenθ . Theproof of correctness is along the lines of the respective one in Theorem 11.Given the regular structure of the states and the easy checks and manipulations that need to be done for determiningapplicability of actions and determining the successor state, respectively, it is not difficult to see that a representation of theabove 1-Maintainability instance using state variables can be compiled from π and p(0, 0, . . . , 0) in logarithmic work space(cid:7)), in_poss(s, a),(in particular, that the polynomial-time procedures for deciding the membership predicates in_Phi(s, a, sin_exo(s, a) in_S(s), and in_E(s) can be provided in polynomial time). Note that this instance employs only deterministicactions, and there is a single exogenous action. This establishes EXP-hardness for 1-Maintainability.Furthermore, for A and E as constructed, each agent action results in a state in E. Thus, k-maintainability of S w.r.t. E inA, for any k = f ( A, S, E) such that f ( A, S, E) (cid:2) 1, is equivalent to 1-maintainability of S w.r.t. E in A. Hence, the reductionshows EXP-hardness of k-Maintainability under the stated restriction. (cid:2)Corollary 19. Under state representation by variables, Maintainability is EXP-complete. The EXP-hardness holds even if all actionsare deterministic and there is only one exogenous action.Using Theorem 18 instead of Theorem 11, we can prove the following result similarly as Theorem 13:Theorem 20. Under state representation by variables and in absence of exogenous actions, k-Maintainability and Maintainabilityare EXP-complete.For the case without exogenous actions and with only deterministic actions, we have lower complexity:Theorem 21. Under state representation by variables, k- Maintainability and Maintainability for systems with only deterministicactions and no exogenous actions are PSPACE-complete.Proof. By well-known standard methods, a computation composed of a PSPACE computation A piped into an NL computa-tion B (which is NPSPACE in the size of the input for A) can be redesigned as an NPSPACE computation. Since NPSPACE =PSPACE, membership of the problems in PSPACE thus follows from Lemma 17 and Theorem 15.The PSPACE-hardness can be shown e.g. by a straightforward reduction from propositional STRIPS planning [16]. Ratherthan to introduce STRIPS here, we give for completeness sake a simple reduction from Succinct Reachability [57], whichis the version of Reachability where G = (V , E) is such that the nodes v are given by the binary vectors v = (v 1, . . . , vn),n (cid:2) 1, on {0, 1} and the problem input consists of a Boolean circuit C G with 2n inputs v 1, . . . , vn, w 1, . . . , wn which outputstrue iff v → w ∈ E, and s = (0, 0, . . . , 0) and t = (1, 1, . . . , 1). We construct from this an instance of k-Maintainability resp.Maintainability as follows: S = V × V , described by 2n binary variables f 1, . . . , f 2n; A = {inc, arc} = Aag; Φ(v × w, inc) =(cid:7) = w + 1 modulo 2n, and Φ(v × w, arc) = w × (0, 0, . . . , 0) if v → w in G and Φ(v × w, arc) = v × wv × wotherwise; poss(s) = A, for each state s. Then, the state s = (1, 1, . . . , 1) × (0, 0, . . . , 0) is |S|-maintainable with respect toE = {(1, 1, . . . , 1) × (1, 1, . . . , 1)} in A iff (1, 1, . . . , 1) is reachable from (0, 0, . . . , 0) in G. A state variable representation ofA can be easily generated from the circuit C G in logarithmic workspace. This implies PSPACE-hardness of the problems. (cid:2)such that w(cid:7)If the maintenance window is bounded by a constant, the problem is easier.Theorem 22. Under state representation by variables, k-Maintainability for systems without exogenous actions and constant k (cid:2) 0is co-NP-complete.Proof. For a given s ∈ S, falsity of rk(s) can be proved by exhibiting (assuming s /∈ E), for each a ∈ Aag ∩ poss(s) a witnessw(s, a) ∈ S such that w(s, a) ∈ Φ(s, a) and rk−1(w(s, a)) is false, which in recursion can be proved similarly. For constantk, this leads to O (|Aag|k) many guesses w(s, a), which is polynomial in the size of the input. By Lemma 14, it thus followsthat deciding the complement of k-Maintainability is in NP. This proves membership in co-NP.The co-NP-hardness, for every k (cid:2) 0, is a simple consequence that under representation by state variables, decidingwhether S ⊆ E is co-NP-complete (this can be shown, e.g., by a simple reduction from propositional unsatisfiability). (cid:2)8. Discussion and conclusionIn this paper, we gave a formal characterization of maintenance goals and distinguished it from the notions of stabi-lizability and temporal goals of the form (cid:2)(cid:3) f (over all valid trajectories). We present several motivating examples thatillustrate the need for our notion of maintainability. The basic idea being that for certain kinds of maintenance it is im-portant that the maintaining agent be given a window of non-interference from the environment so that it can do the1460C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469maintenance. To formalize this we need to distinguish between the agent’s actions and the environment’s actions. In ourformalization we define the notion of k-maintainability, where k refers to the maximum window of opportunity necessaryfor the maintenance. We then gave polynomial time algorithms to compute k-maintainable controls, which are linear-timefor small k, and we analyzed the complexity of determining k-maintainability under various assumptions. One interestingaspect of our polynomial time algorithm is the approach that led to its finding: the use of a SAT encoding, and complexityresults regarding the special Horn sub-class of propositional logic.We next report on some experiments which we have carried out, and we then discuss related work, before we conclude.8.1. Experimental resultsThe different methods for constructing k-maintaining controls in the previous sections have been implemented, in orderto compare them on an experimental basis. More specifically, programs generating the SAT encoding and the Horn SATencoding, the latter written as a propositional logic program, have been implemented in Java, and also the algorithm k-Control. For SAT solving, zChaff has been employed and for evaluating the Horn SAT instances the answer set solvers DLVand Smodels plus its preprocessor Lparse. The logic programs with variables given in Section 6 are ready for use in DLV asdescribed, and only minor adjustments are needed for Smodels. The encodings and implementations are, together with thedescriptions of the domains, available at http://www.public.asu.edu/~jzhao6/k-maintain/.To evaluate the performance of the implementations, we conducted experiments on the buffer domain described inSection 3, varying the size of the buffers, max, and the number k for a maintaining control. In all experiments, there was asingle goal state, (0, 0) (i.e., both buffers are empty), and a single initial state, which in was either (1, 1) or (3, 5); note thatin both cases, the smallest k for which a k-maintaining control exists is k = 2∗ max +1.The results of the experiments are shown in Table 3. They were collected on a Dell desktop with an Intel Pentium 4(2.53 GHz), 512 MB main memory, and 753 MB swap space, under Slackware 11.0 including Linux kernel 2.4.33.3. We useda pre-release (beta-version) of DLV version 2007-10-11,8 Lparse 1.0.17, and Smodels 2.32. In the table, the leftmost columnshows the buffer size max and the parameter k; the rightmost column tells whether a solution exists or not. The timesreported are for deciding whether a k-maintaining control exists, i.e., computing a model, from which a control can beefficiently extracted (in fact, in linear time); also for the genuine algorithm, output of a control in Step 4 is fast.For the SAT and the Horn SAT encodings, the column “instance” shows the timings for generating the respective instancesin Section 6.3 from the input representation in Section 6.1, and the other columns show the timings for solving the instancesusing a respective solver; the numbers in parentheses is the total of instance generation and solving. Since Lparse, thepreprocessor of Smodels, already solves the Horn SAT instances, the call of Smodels has actually been omitted. The column“genuine algorithm” shows the results for the implementation of Algorithm k-Control, and the columns right of it theresults for the logic programming encodings, both the one for deterministic and for non-deterministic transition function.Here the problem input was not in explicit form by facts but described by rules as in Section 6.5. However, generating thefactual representation takes only short time (between 14 and 115 ms for larger problem size) and is negligible compared tothe time required for solving the instance.The experiments show some interesting results. Among the SAT and Horn SAT solving methods, the logic programmingengines perform overall better than the SAT solver. This is explained by the fact that generating the SAT instance for thesolver takes much longer than generating the corresponding Horn logic program. One possible reason is that the inputformat of the SAT solver requires that strings are mapped to integers which represent propositional variables. This has beendone using a hashmap with vectors; a better design of the data structure may save some time on this translation. On theother hand, the SAT solver needs less time to solve an instance than the LP engines. We remind, though, that the latter arecommitted to compute a special model, while the SAT solver may compute an arbitrary model of the instance.The SAT solver scales reasonably well on the instances, and similarly DLV which is within a small factor in most cases.Moreover, DLV also scales well regarding the overall time, while Smodels showed some weakness here. Both SAT solving andHorn logic programs have limitations when the constructed instances become larger, since the memory may be exhausted(however, as for memory the experimental setting was modest).The genuine algorithm is faster than the SAT solving method on larger instances, but slower than Horn SAT solving. Thelatter may be explained by the fact that the internal Java data structures used (vectors and maps) are not optimal. However,the implementation scales well with respect to k.The logic programming encodings with variables behave similar to the Horn SAT encodings, and apart from one case thetimings for the non-deterministic LP encoding in Lparse+Smodels are comparable to those for the Horn SAT method usingDLV. The non-deterministic LP encoding in DLV is in many cases faster than the one of Lparse+smodels, but shows a lesssmooth scaling in some cases. This discrepancy may be explained by the different heuristics which is used by the systemsin the model search. The deterministic encodings are, in both cases, faster than the non-deterministic counterparts, but thespeedup is limited by a small factor (between 2 and 3).We remark that extracting an actual control out of the model computed an LP engine, by adding the rules in Section 6.2to the program does not scale well for large k in general. The reason is that the rule for k_plus has, for each single8 Kindly provided by the DLV team. The official release 2007-10-11 behaves similarly.C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691461Table 3Experimental results for deciding k-maintainability in the Buffer Domain (times in secs)start state (1,1), goal state (0,0)Problemmax, kSAT encodinginstance (zChaff)Horn SATinstance (Lparse + Smodels)10,510,1010,1510,2010,2110,2510,3010,3510,4010,4520,520,1020,1520,2020,2520,3020,3520,4020,4520,5020,5520,600.648 0.0211.439 0.0623.320 0.0796.543 0.1007.421 0.20912.335 0.27619.467 0.34626.236 0.39835.321 0.41745.195 0.463(0.669)(1.501)(3.399)(6.643)(7.630)(12.611)(19.813)(26.634)(35.738)(45.658)(8.054)7.933 0.121(35.221)35.043 0.178(88.978)88.729 0.249(164.540)164.208 0.332(264.032)263.623 0.409(397.537)397.0180.519(564.703)564.108 0.595(685.489)684.858 0.631852.107 1.990(854.097)1073.237 2.315 (1075.552)2.526 (1326.045)1323.5191630.561 3.448 (1634.009)start state (3,5), goal state (0,0)20,520,1020,1520,2020,2520,3020,3520,4020,4520,5020,5520,6030,530,1030,1530,2030,2530,3030,3530,4030,4530,5030,5530,6030,6530,70(7.771)7.646 0.125(33.988)33.814 0.174(86.507)86.259 0.248(158.415)158.087 0.328(252.753)252.355 0.398(383.609)383.1410.468(525.977)525.430 0.547(697.157)696.5140.643893.684 3.417(897.101)1072.981 2.831 (1075.812)1327.165 2.541 (1329.706)1601.926 3.335 (1605.261)51.410(51.629)0.219(206.995)206.631 0.364(496.586)496.045 0.541866.907 0.723(867.630)1388.404 0.880 (1389.284)1971.139 1.065 (1972.204)1.267 (2686.884)2685.6173408.562 1.663 (3410.225)4272.727 1.818 (4274.545)out of memoryout of memoryout of memoryout of memoryout of memory0.4650.5330.6130.6500.6650.6880.7610.8010.8510.8832.3472.5322.7352.9333.2073.2503.5233.6913.7583.8894.0714.3532.4832.5642.7672.9833.1133.3073.4443.6073.8393.9383.9814.32710.17610.56910.75411.15311.59512.30612.52213.25218.47631.1910.4350.8421.2111.6761.6061.7701.6561.8092.0342.1111.6023.1964.2406.2997.9819.70911.13812.75713.11913.65013.92328.8181.6393.1464.6616.2527.7819.24210.85313.34213.78113.25013.54715.091(0.900)(1.375)(1.824)(2.326)(2.271)(2.458)(2.417)(2.610)(2.885)(2.994)(3.949)(5.728)(6.975)(9.232)(11.188)(12.959)(14.661)(16.448)(16.877)(17.539)(17.994)(33.171)(4.122)(5.710)(7.428)(9.235)(10.894)(12.549)(14.297)(16.949)(17.620)(17.188)(17.528)(19.418)(13.733)3.557(17.482)6.913(20.861)10.107(24.941)13.788(38.341)26.746(37.625)25.319(137.047)124.525665.565(678.817)681.040 (699.516)(624.709)593.518out of memoryout of memoryout of memoryout of memory(DLV)0.1180.2030.2710.3800.5990.7430.8651.0071.2201.4550.4250.8141.1521.6241.9552.3593.1663.5608.3537.8858.2478.7950.4320.8601.2061.6561.9252.3193.1153.3887.7217.5527.6818.0550.8671.8623.0253.6684.6647.6377.3337.6758.4219.450GenuineAlgorithmDLVdetLparse + Smodelsndetdetndetsolutionyes/no(0.583)(0.736)(0.884)(1.030)(1.264)(1.431)(1.626)(1.808)(2.071)(2.338)(2.772)(3.346)(3.887)(4.557)(5.162)(5.609)(6.689)(7.251)(12.111)(11.774)(12.318)(13.148)(2.915)(3.424)(3.973)(4.639)(5.038)(5.626)(6.559)(6.995)(11.560)(11.490)(11.662)(12.382)1.8193.1274.2695.5765.5986.2355.4405.4125.4225.41823.17743.56967.77082.192102.264120.628144.418151.763162.128172.677193.645152.91122.73441.95659.22878.78495.766115.793132.549150.920161.092172.896185.470153.073125.925(11.043)235.732(12.431)332.056(13.779)444.367(14.821)(16.259)535.193(19.943) 646.284742.747(19.855)863.109(20.927)(26.897)940.408(40.641) 1065.3521155.3661262.5941319.1281387.4230.1570.0940.3080.1710.4850.2270.6070.2820.8660.3991.7710.5234.4442.0226.6642.9164.31010.9355.481 14.7870.2570.3650.4860.6150.7690.9711.1411.2841.4451.6280.4050.6910.9551.2451.5361.6191.9292.2262.5342.8310.6550.3341.5310.9341.3630.6232.7651.5952.0460.9154.0222.2292.8781.1925.2942.8623.7521.5616.5733.5694.7041.8447.8484.1875.9322.2744.8569.1082.7246.4895.536 10.3813.907 14.9547.523 12.22424.345 22.8288.309 13.6559.398 15.08348.505 35.54379.994 55.327 10.496 16.5300.3550.6420.6231.3490.9322.0121.2202.8031.5963.5921.8974.5882.2475.8346.2852.6533.593 13.75211.786 23.13220.229 38.76733.750 62.340 10.4151.0471.5331.6112.7902.2494.0262.8965.3443.5736.6714.2107.9444.8509.10610.3635.6197.393 12.2167.548 13.6558.924 15.04716.5583.9042.6281.4240.8714.4287.2153.0031.7326.323 10.3955.5932.7186.7848.228 13.6934.0909.013 10.308 17.0573.9294.71812.072 20.49812.4135.846 14.634 13.823 23.9277.185 16.401 16.230 27.3478.269 19.305 17.985 30.79819.646 34.2789.656 21.91437.81611.058 25.889 21.51741.14613.481 31.304 23.91917.987 53.466 29.790 56.08443.161 89.959 32.501 80.523nonononoyesyesyesyesyesyesnonononononononoyesyesyesyesnonononononononoyesyesyesyesnonononononononononononoyesyes(cid:7)), i.e., s, s(cid:7) ∈ Φ(s, a), quadratically many ground instances in k.possible transition (s,a,sAlthough only a single such instance is relevant, the solver can not predetermine it in the grounding phase. However, thisproblem can be easily circumvented by keeping the additional rules in a separate post-processing program, and feeding intoit the model computed by the main program. Then, a control is quickly output, in time which is largely dominated by thetime for model computation (in the worst case, in a few seconds).(cid:7) ∈ S and a ∈ A ∩ poss(s) such that sω-maintaining controls: We have also conducted some experiments with different methods for deciding the existence ofan ω-maintaining control. More specifically, following the two-phase approach in Section 5.4, we have considered proposi-tional logic programs, a genuine algorithm, and logic programs with variables; note that a SAT encoding for the two phasesis not straightforward, since we need to compute transitive closure in both phases and phase 2 accesses the complementof the output of phase 1; a simple realization requires layered use of negation for that, which is done in all logic program-ming encodings (for generic programs with variables, unstratified negation is avoided using the method in Section 6.4).1462C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469Table 4Experimental results for deciding maintainability in the Buffer Domain (times in secs)s; g sol method/max102030405060708090100(1,1); yes propositional DLVgenuine algorithm(0,0)Lparse+SmodelsDLVpropositional Lparse 0.333+0.056 1.192+0.186 4.578+0.362 10.182+0.677 23.992+1.041 52.712+2.148 102.632+3.717 181.020+5.801 297.172+9.154 446.141+13.3990.333+0.018 1.192+0.104 4.578+0.270 10.182+0.439 23.992+0.693 52.712+1.054 102.632+1.134 181.020+1.694 297.172+2.134 446.141+2.535–42.43223.7704576.0976.2065.7811835.1643.2784.0719762.17610.9498.770629.9251.5221.815152.9180.6310.92220.2660.2260.398–28.30417.687–17.91912.8321.0340.0440.124propositional Lparse 0.342+0.094 1.174+0.224 4.975+0.496 10.765+0.675 25.335+1.237 55.492+2.154 102.401+3.672 180.949+5.808 301.249+8.514 445.678+12.074(9,1); yes propositional DLV 0.342+0.065 1.174+0.136 4.975+0.330 10.765+0.456 25.335+0.672 55.492+0.984 102.401+1.172 180.949+1.534 301.249+2.103 445.678+2.446–(5,5)43.86823.106genuine algorithmLparse+SmodelsDLV2813.4347.1405.6565097.60610.9098.6531315.8403.2343.626553.8061.4971.725127.6460.6100.903–28.93217.505–19.64712.04815.8980.2000.3880.7380.0480.056(3,2); no propositional DLVgenuine algorithm(4,4)Lparse+SmodelsDLVpropositional Lparse 0.357+0.072 1.184+0.213 4.647+0.376 10.191+0.630 23.965+1.054 52.574+2.074 102.743+3.640 180.601+6.251 302.436+8.869 445.867+12.0190.357+0.017 1.184+0.129 4.647+0.222 10.191+0.316 23.965+0.507 52.574+0.807 102.743+1.006 180.601+1.282 302.436+2.392 445.867+2.177–43.15917.8038973.39211.1226.2862772.3596.5534.0351281.0643.3842.414125.8480.5910.617542.2731.5031.322–28.78713.152–18.3439.29215.7020.1800.2590.6980.0490.040(1,9); no propositional DLVgenuine algorithm(7,4)Lparse+SmodelsDLVpropositional Lparse 0.345+0.090 1.101+0.217 4.588+0.374 10.173+0.688 24.085+1.162 52.655+2.092 102.092+3.633 180.900+5.771 298.540+8.529 446.833+11.9690.345+0.017 1.101+0.093 4.588+0.196 10.173+0.297 24.085+0.497 52.655+0.800 102.092+1.013 180.900+1.291 298.540+1.844 446.833+2.170–43.26018.4423943.0096.3254.0051523.8823.5122.3778735.72411.1946.219498.5340.5031.280112.6530.6070.581–28.86212.922–18.3519.19012.5190.1840.2140.5110.0510.066Phase 2 is, in fact, realized in the logic programs via computing first the set of all states which must be pruned, and thencomplementing it.The results of our experiments are summarized in Table 4. There, s is the single start state and g the single goal state.For each propositional LP program, both the times for creating it from the factual representation and for solving it areshown (in ms); a dash “–” means timeout after 10,000 seconds. The first two instances have a solution, while the latter twoare not. As can be seen, the LP encodings with variables scale well, with a linear time trend (note that the instance sizeof the problem is quadratic in the buffer size). Unsurprisingly, the propositional LP encodings are evaluated faster than theLP encodings with variables, but a lot of time is needed to construct the respective programs; in total, using non-groundprograms is much faster. The implementation of the genuine algorithm does not scale well, and is way slower than the LPencodings. However, similar as in the case of k-maintainability, the implementation does not use optimal data and storagestructures and therefore has room for improvement.We remark that the propositional LP encoding can be constructed faster (in the experiments, up to almost four times), ifone exploits that the domain is deterministic. Furthermore, a variant of the DLV encoding with variables, in which pruningin phase 2 is focused to the states having an a-path to the goal set (determined in phase 1), shows very similar performance.With respect to our methodological approach, we can observe the following. Using SAT solving and logic programmingto construct k-maintaining and ω-maintaining controls is, at least in this example, not only of theoretical interest, but alsoshows value to obtain some quick implementations which perform reasonably well. Genuine algorithms that are extractedfrom SAT or logic programming solutions have potential, but they require implementation and optimization efforts in orderto become highly efficient and significantly faster then the first shot methods. In particular, if the state space is not toolarge and the maintenance window small, a logic programming based approach is attractive, where we may keep in mindthat further preferences or constraints may be imposed on solutions in a declarative manner.8.2. Relation with earlier work on control synthesisIn this section, we compare our work with earlier work on control synthesis [1,10,19,41,49,60]. We start with the papersby Barbeau et al. [10] and Kabanza et al. [41] from the AI literature.8.2.1. Relation with Barbeau et al.’s and Kabanza et al.’s workBarbeau et al. [10] and Kabanza et al. [41] present a method to synthesize reactive plans9 based on progressing for-mulas in a linear temporal logic, called Metric Temporal Logic (MTL), which allows to specify durations in the temporaloperators. If we ignore the durations of the operator then their specification language is the linear temporal logic LTL withoperators (cid:9), (cid:2), (cid:3) and U . Similar to ours, they allow actions to have non-deterministic transitions. However, [41] does notallow exogenous actions. Although [10] allows exogenous actions, it requires that exogenous actions and agent actions beinterleaved. Thus to use their formulation one has to translate our formalism to theirs. For example one can compile away9 Their notion of reactive plans are slightly different from our notion of control functions; in their case a state, which they call a world state, may havemany associated plan states. For our type of goal, control functions in our sense can however be easily extracted from their “reactive plans” without ablowup.C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691463exogenous actions10 from our formulation and, as mentioned earlier, introduce a fluent interfered to remember that a transi-tion was made immediately made due to an exogenous action. The resulting transition function will have non-deterministictransitions and thus would need the specification Aπ ((cid:2)(φS ⇒ (cid:2)(Step[k](interfered ∨ φE )))) in the language of [9] to expressk-maintainability. However, the control generation algorithm in [10,41] is able to construct a control for all goals of the formAπ f , where fis an LTL formula and the algorithm focuses on f .Their algorithm is based on progressing an LTL formula. The intuition behind progression is that given a sequence ofstates σ = s0, s1 . . . and an LTL formula f , the progression of f with respect to a state si satisfies the property: (σ , i) |(cid:8) fiff (σ , i + 1) |(cid:8) progression( f , si).A partial definition of progression, as needed for our illustration, is as follows:• for a proposition p, progression(p, s) is true if p is true in s else is false.• progression(¬ f , s) = ¬progression( f , s)• progression( f ∧ g, s) = progression( f , s) ∧ progression(g, s)• progression( f ∨ g, s) = progression( f , s) ∨ progression(g, s)• progression((cid:2) f , s) = progression( f , s) ∧ (cid:2) f• progression((cid:9) f , s) = f .To illustrate how their algorithm works, we consider an important fragment of the LTL part of our goal: (cid:2)(Step[k](interfered ∨ φE )). To simplify further, let ϕ denote interfered ∨ φE , and let sϕ denote a state where ϕ is true and s¬ϕ denote astate where ϕ is not true. In the following, let progression( f , s1, s2, . . . , sn) denote progression(progression(. . . progression( f , s1),. . .), sn). We now illustrate how progression works with respect to the above goal:• progression((cid:2)Step[k](ϕ), sϕ) = (cid:2)Step[k](ϕ) = Step[k](ϕ) ∧ (cid:9)(cid:2)Step[k](ϕ)• progression((cid:2)Step[k](ϕ), s¬ϕ) = Step[k−1](ϕ) ∧ (cid:2)Step[k](ϕ) = Step[k−1](ϕ) ∧ (cid:9)(cid:2)Step[k](ϕ)• progression((cid:2)Step[k](ϕ), s¬ϕ, s¬ϕ) = Step[k−2](ϕ) ∧ (cid:9)(cid:2)Step[k](ϕ)• progression((cid:2)Step[k](ϕ), s¬ϕ, s¬ϕ, s¬ϕ) = Step[k−3](ϕ) ∧ (cid:9)(cid:2)Step[k](ϕ)and so on. As evident from the above the progression may lead to k different formulas. The general algorithm in [10,41]introduces decomposition due to the ∨ connective in Step[k](ϕ) and can have 2k formulas labeling a state, leading to asearch space of 2k × |I|. Since one does not need to worry about cycles, one can avoid double exponential search.However, noticing that our goal specification does not have unbounded eventualities, one can also modify the algorithmto avoid decomposition and thus restrict to a search space of k × |I|. After that one needs to do an efficient search in thissearch space as the search algorithm given in [10,41] does not seem to do efficient backtracking.In conclusion, although the algorithm in [10,41] as presented does not find a k-maintainable control in polynomial time,certain modifications make that algorithm more efficient. This illustrates the importance of the work [10,41]. It suggests theresearch direction of exploring various sub-classes of LTL goal specifications and identifying appropriate modifications orsimplifications of the algorithms in [10,41] so that they lead to a more efficient control finding method. In slight contrast,our approach has been to find an efficient algorithm for a specific goal through logical manipulations. It led us to findingefficient and different algorithms for other goal specifications such as strong planning, strong cyclic planning and weakplanning, which we discuss in [4].8.2.2. Relation with other work on control synthesisMost of the other works on control synthesis dates back earlier, around the time when various temporal logics wereproposed for program specification purposes.Clarke and Emerson [19] consider specifications in the branching time temporal logic CTL and present an algorithm toconstruct synchronization skeletons of concurrent programs from scratch. The algorithm constructs a finite model of theformula using a tableau-based procedure, and factors the control skeletons of the individual processes out from the globalflow graph defined by the model. There is no complexity analysis given, but the authors mention that the algorithm ispotentially exponential. Furthermore, the algorithm assumes a closed system, in which neither environment actions nor10 One compilation involves the following: (i) For each state s a new state called sint is created. The states s and sint are equivalent with respect to allfluents except the newly introduced fluent interfered, which is false in the former and true in the later. (ii) All edges in the original transition diagram duedue to an agent action a in the original transition diagram, then a transition from sint toto agent actions are kept. (iii) If there is a transition from s to s(cid:7)to s dues(cid:7)to an agent action a, then a transition from sint is introduced. (v) The set of initial states is enlarged as follows: If s is an initial state and there is atransition from s to s(cid:7)int is made an initial state.However, the complexity results in Table 1, and the following discussions suggest that such a compilation has a high worst-case effort, and is not doabledue to agent action a is introduced. (iv) For all transitions between s and sdue to a series of exogenous actions, if there is an edge from sdue to a series of exogenous actions then sto s(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)in non-deterministic logspace. This remains true with respect to any other compilation where the new k depends only on the old k.It may be noted that with respect to our buffer example the above compilation is not linear in the size of the input; indeed, the original transition hasO (n2) many nodes and arcs (where n is the buffer size), while the compiled one has O (n2) many nodes but (cid:14)(n3) many arcs, which come in throughtransitive closure of exogenous actions. Thus, in that example doing the compilation and then solving the LTL planning problem, to solve k-maintainability(for a fixed k), is not a linear time algorithm.1464C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469specific agent actions (which constrains the model building) are respected. However, this is crucial for the construction ofa k-maintaining control; applied to the CTL specification of such a control for S w.r.t. E, the algorithm may return, e.g., amodel which has only states corresponding to states outside S.Independently, Manna and Wolper [49] consider the construction of the synchronization part of communicating processesfrom specifications in the linear time temporal logic PTL. As they mention, the main differences between their approachand [19] is the usage of PTL instead of CTL, and that [19] synthesizes shared memory programs. Manna and Wolper’ssynthesis method employs a tableau-style satisfiability algorithm, which is essentially the one in [12] restricted to lineartime operators and modified to their assumption that in each state exactly one atomic proposition is true. The algorithmeither declares the specification to be unsatisfiable or constructs a “model graph” from which all possible models of the PTLspecification can be extracted. In the construction, PTL formulas are decomposed using the identities(cid:2) f ≡ f ∧ (cid:9)(cid:2) f , (cid:3) f ≡ f ∨ (cid:9)(cid:3) f ,andf 1 ∪ f 2 ≡ f 2 ∨ ( f 1 ∧ (cid:9) f 1U f 2),which enables to model a flow graph by talking about the current and the follow up state in an execution. As Manna andWolper argue, the size of the model graph is at most exponential in the size of the specification formula. In a final step,the control code is generated from the model graph. Special care is here applied to so called eventuality conditions, whichare conditions of the form (cid:3) f whose satisfaction must not be indefinitely postponed (this aspect was not addressed indetail in [19]). Since like [19], the method assumes a closed system without an environment, it is not readily applicable forconstructing a k-maintainable control.Pnueli and Rosner [60] give an algorithm to synthesize a reactive module with input x from and output y to an environ-ment, where the values are from a finite domain, specified by a linear temporal formula ϕ(x, y). The running time of thealgorithm, which is constructed using automata-theoretic results, is at most double exponential in the length of the givenspecification; by its nature, it is difficult to say how it would perform for the construction of a k-maintaining control.Abadi et al. [1] introduce a notion of realizability which is somewhat more general than the notion of implementability in[60], since it also considers an environment whose behavior is restricted. They distinguish environment and agent activityin changes to the environment, and define specifications at an abstract level as sets of behaviors, which are alternatingsequences of states and active parties (which is either the environment, the agent, or none of them), satisfying someconditions. Realizability is given if a subset of the behaviors can be generated by the runs of a “computer”, which is arestricted (possibly non-recursive) partial function from prefixes of behaviors to states; as noted, realizability is a necessarybut not sufficient condition for the existence of a real implementation. A weaker notion of realizability, which takes intoaccount that the implementor knows exactly how the environment behaves (in a deterministic manner), is considered andshown to be equivalent to realizability for an important class of specifications. Finally, the issue of realizability for finite-state transition systems P t (represented by automata) equipped with a further restriction on the infinite behaviors of thesystems, given by a (finite-state) Büchi automaton P i , is considered. As pointed out, this is different from consistency of thebehaviors of P t and P i . Applying, like Rosner and Pnueli, automata-theoretic results, it is argued that deciding realizabilityis in EXPTIME and PSPACE-hard under logspace reductions. An important note is that for realizability, Abadi et al. viewnon-deterministic transitions as optional outcomes of actions from which an implementor of a realization can choose anarbitrary subset. For our notion of control, it would be required that if an particular agent action is chosen at a state, thenall outcomes of that action are chosen. Since a realization must merely be compatible with the infinite behaviors, but neednot manifest all of them, enforcing such a choice via the infinite behaviors is infeasible. Hence, the method of [1] seems notalways applicable for constructing a k-maintaining control in our setting.Recently there have been some works in developing polynomial time control generation algorithms (in the size of thestate space) for particular classes of LTL goals. In particular, the paper [59] presents a cubic algorithm in the size of thestate space to automatically construct controls for GR(1) goals which are of the form ((cid:2)(cid:3)p1 ∧ · · · ∧ (cid:2)(cid:3)pm) ⇒ ((cid:2)(cid:3)q1 ∧· · · ∧ (cid:2)(cid:3)qn), where pi s and q j s are propositional formulas. This complexity is still higher than our algorithm; however, itremains open to find out if our approach can lead to a more efficient algorithm for GR(1) goals.8.3. Other related workBesides the related works we already mentioned such as stabilizability and temporal logic, the notion of maintenance hasappeared in AI in many other papers. For example, in [55], Ortiz discusses maintenance actions. His notion of maintenanceis stronger than both the notion of stabilizability and our notion as he requires the formula that is maintained to betrue throughout. The notion of maintenance is also related to the notion of ‘execution monitoring’ which is studied inthe context of robot programs in [23]. In ‘execution monitoring’ the world is monitored and if a discrepancy is foundbetween the prediction made by the agent and the real world, then new plans are made to recover from the discrepancy.A deliberative architecture for maintenance can be extrapolated from the notions in [5], where an agent executes a cycle ofobserve; assimilate; (re)plan_from_current_situation; execute_part_of _the_plan.In a series of papers [27,28,69], Wooldridge and Dunne have formalized the problem of constructing agent control func-tions and analyzed its complexity in a rich framework, for various kinds of tasks such as ‘achievement’ tasks (where theagent has to bring about a certain goal condition), ‘maintenance’ tasks (where the agent has to avoid that some goal con-dition is ever satisfied during execution), and combinations thereof [27]. Their notion of boolean task specification allowsa seamless combination of ‘achievement’ and ‘maintenance’ goals. In their notion a goal specification is a propositionalC. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691465formula where each proposition corresponds to a set of states. The intuitive meaning of a goal specification p would beto reach for sure one of the states corresponding to p. This corresponds to an achievement goal, while a specification ¬pintuitively means that the agent should avoid any state in p. They refer to the later as a ‘maintenance task with bad states’.Thus their notion of ‘maintenance’ differs from ours. While we are concerned with the hindrance posed by the adversaryexplicitly, and take into account the number of steps when the adversary is not interfering, they do not take exogenousactions into account explicitly. They allow non-deterministic effect of actions, and although one can partially take exoge-nous actions into account by a straightforward compilation, keeping the count of the window of non-interference is notstraightforward. Their control policies are richer than ours. In their framework, action effects and the selection of the agentaction by the control may depend on the history of the execution. Under restriction to history-independent state transitionsand reactive agents, finding controls for achievement tasks in their framework corresponds to finding maintaining controlswith an unbounded window of opportunity in our framework. In [27] they do a comprehensive complexity analysis ofagent design in their framework. There is a natural correspondence between some of our complexity results and theirs. Inparticular, our Theorems 15 and 21 correspond to the respective results in [27].In AI planning, the seminal STRIPS approach [32] has been one of the most influential approaches. We briefly recall thatin STRIPS, states are modeled as sets of propositional atoms and actions as operators which, given that a precondition interms of a conjunction of literals is true on the current state, transform it to a successor state by removing atoms from adelete list and adding atoms from an add list. A plan for achieving a goal, described by a conjunction of atoms γ , froman initial state S0 is a sequence of operators op1, . . . , opn which takes the agent from S0 to a state where γ holds. STRIPSplanning has been generalized in several directions, such as conditional effects, non-deterministic actions, or planning underincomplete information and partial observability using conditional and conformant plans, respectively, and a number ofpapers has considered the computation and complexity of planning in such settings, e.g., [6,16,18,31,64].However, like in the framework of Wooldridge and Dunne, in none of these works agent actions and exogenous actionsare viewed separately, and thus they are best compared to our framework in absence of exogenous functions. Furthermore,plans per se are conceived as action strategies (cf. [64]) in which, in principle, different actions might be taken by the agentif during plan execution the same state is entered again; however, such looping is a priori excluded if the goal must beachieved under all contingencies.Daniele et al. [21] introduce the notion of strong cyclic planning which has some similarity with our notion of main-tainability. In particular, both accept the possibility that an environment can sometimes be belligerent and in that case oneneeds to differentiate between an agent that is trying and an agent that is not. However, they encode the environmentalinterference through non-determinism while we allow explicit representation of environmental actions. Daniele et al. andlater Cimatti et al. [18] consider constructing universal plans akin to our policies, with different semantics (weak, strong andstrong cyclic) for goal achievement, based on OBDD methods and algorithms. In particular, in absence of exogenous actionsour maintaining controls correspond to what they call strong solutions for a planning problem. For further discussion, werefer to [4].As for complexity, Theorem 21, corresponds to the classical result of Bylander [16] that deciding plan existence in propo-sitional STRIPS is PSPACE-complete, while Theorem 20 corresponds to Littman’s result that conditional planning for STRIPSwith non-deterministic actions is EXPTIME-complete [46,64]. In conditional planning, via conditions on the current statebranching to subplans is possible, such that an appropriate plan is followed depending on the state evolution. Branchingmight be modeled by actions and the conditional planning problem, with loops disregarded, as the problem of constructinga maintaining control.In other related work, Jensen et al. [39,40] consider the somewhat dual problem of developing policies that achieve agiven goal while there are interferences from the environment. In their model, environment actions and actions of multipleagents are combined to a joint action, by which the system is transferred from the current state to one out of a set of pos-sible successor states. With such non-deterministic transitions, Jensen et al. aim at modeling both an adversial environmentand infrequent errors which make an otherwise deterministic action non-deterministic. In [39], they consider construct-ing policies coping with arbitrarily many interferences of the environment (but without action failure) by an extension ofOBDD-based universal planning, and in [40] they consider generating policies which tolerate up to a given number n of er-rors modeled as “secondary action effects” (caused by improper action execution or environment interference), by reducingit to a so called strong planning problem, which is solved using OBDD based methods. For arbitrarily many environmentinterferences as in [39], the problem is basically very similar to our problem of unbounded maintainability, but interfer-ence in goal states has different significance and goal achievement is not guaranteed because of possible loops. A formalconnection between k-maintainable controls and n-fault tolerant policies, if any, remains open. Intuitively, n-fault tolerantplans are easier to construct, since the number of errors that have occurred can be recorded in plan construction and whenthe limit n is reached, the problem boils down to an ordinary planning problem. For k-maintaining controls, however, eachenvironment interference (even at a goal state) causes a restart which pushes the agent to a new initial state.Outside of AI, our notion of k-maintenance is very closely related to the notion of self-stabilization in [24] which is usedin characterizing fault-tolerant systems. There the concern is about proving correctness of (hand developed) self-stabilizationprotocols and achieving self-stabilization for various distributed algorithms such as mutual exclusion. Our algorithm here canbe thought of as an algorithm that automatically generates a self-stabilization protocol. Although, this is a new dimensionto the existing work on self-stabilization, further research is needed to compare assumptions made in our formulation andthe ones in the self-stabilization literature, and overcome them. In particular, often in the self-stabilization literature the1466C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469global states are composed of local states of various distributed elements and a particular element does not have the accessto the complete global state. In those cases one can not directly use the kind of global policies generated by the algorithmin this paper. We elaborate more on this in Appendix A.8.4. Further work and open issuesThere are several directions for further research extending the work of this paper. One direction concerns other classesof goal specifications, apart from k-maintainability and maintainability, for which controls can be synthesized in polynomialtime. Another direction are more general execution models, for instance by taking action duration into account. In such ascenario, the maintenance goal may be formulated as requirement that the agent reaches some desired state always withina given time frame, if she is not disturbed by the environment. Preliminary investigations suggest that the results in thispaper can be extended to handle this setting, and that alternatively the algorithm of Barbeau et al. [10] and Kabanza et al.[41] can be used for efficient computation, as long as durations are not long (binary number representation may lead to anincrease in complexity).The intractability results for the problems under state variable representations challenges methods and techniques forhandling the problem in practice. Suitable heuristics may therefore be researched that allow to solve the problems inmany cases in polynomial time, and, in a refined complexity analysis, meaningful tractable cases should be singled out.Furthermore, the issue of computing optimal k-maintenance controls efficiently, in the sense that k is as small as possible(which is trivially polynomially solvable in the enumerative setting), is an interesting issue for variable state representation.Another issue concerns investigating computational transformations between maintenance and planning. By the com-plexity results in [46] and this paper, transformations between k-Maintainability and conditional planning are feasible inpolynomial time. It would be interesting to study different transformations, and to assess possible benefits of these trans-formations for solving k-Maintainability and planning by cross-utilizing different algorithms and implementations (e.g. [18]for planning in non-deterministic domains). In particular a transformation similar to the one in the proof of Theorem 13,with an additional parameter that counts the number of agent actions since the last exogenous action, can11 be used tocompile out exogenous actions and transform finding k-maintainable policies to finding strong cyclic plans [18]. On theother hand, encodings similar to the one in Section 5.2 for obtaining strong cyclic plans through linear-time Horn logicprogramming can be designed. For more details and results on the latter, we refer to [4].AcknowledgementsThis work was partially supported by FWF (Austrian Science Fund) projects P-16536-N04 and Z29-N04, the EuropeanCommission under grant IST 2001-37004 WASP, the NSF (National Science Foundation of USA) grant numbers 0070463, and0412000, NASA grant number NCC2-1232, and contracts from ARDA and DTO. We would like to acknowledge W. Cushingfor his feedback on an earlier draft and S. Gupta and M. Gouda for their clarifications on self-stabilization. Furthermore,we acknowledge comments by J. Rintanen on the ICAPS’04 paper and are grateful for his pointers to related work. We owespecial thanks to F. Kabanza for helping us understand his co-authored papers [10,41] and making observations regardinghow the algorithms in those papers could be modified to make them more efficient for specific goal specifications. Wefurthermore appreciate the constructive comments of the reviewers to improve the presentation, the suggestion of an LTLformulation in Section 4.1 and the suggestion of a linear time algorithm for generic maintainability. Finally, we are indebtedto J. Zhao for implementing some of the algorithms and running the experiments, and appreciate the support of the DLVteam.Appendix A. Self-stabilization and related notions in distributed computingEarlier we remarked that our notion of maintainability has similarities with Dijkstra’s notion of self-stabilization [24]. Inthis appendix, we elaborate on the relationship between our notions and Dijkstra’s as well as similar notions in distributedcomputing [2].A.1. Dijkstra’s notion of self-stabilizationDijkstra considers in [24] a connected graph (in which a majority of edges are missing) with a finite state machine placedat each node; machines placed in directed connected nodes are called each other’s neighbors. For each node (or machine),a Boolean function over the state of the machine and the states of its neighbors, called a “privilege”, is defined. There is acentral daemon that can select one of the “privileges” (over the whole graph) that is true. The machine whose privilege isselected can move its state to another state based on a policy which is a function from the state of the machine and itsneighbor’s states to a move that results in a state transition in the machine under consideration. If for such a machine morethan one privilege is present, the new state may also depend on the privilege selected.11 This transformation increases the number of states by k times. It is unknown if there exist a transformation that can eliminate exogenous actionswithout increasing the number of states, and yet is able to model the notion of k-maintainability.C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691467There is a global criterion, telling whether the system as a whole is in a “legitimate” state. It is required that(i) in each legitimate state one or more privileges will be present;(ii) in each legitimate state each possible move will bring the system to a legitimate state;(iii) each privilege must be present in at least one legitimate state; and(iv) for any pair of legitimate states there exists a sequence of moves transferring the system from one to the other.The system is called “self-stabilizing” if and only if, regardless of the initial state and the privilege selected each time forthe next move, at least one privilege will always be present and the system is guaranteed to find itself in a legitimate stateafter a finite number of moves.Comparison to our notion of maintainability Our notion of a state corresponds to Dijkstra’s global state (which is composedof the local states), and our goal states are his legitimate states. Analogous to our actions are his “moves”, and analogousto our policies are his selections of privileges that are present. Our policies select an action that is to be executed based onthe current state. In Dijkstra’s model, although “moves” are selected based on the current global state, the selection is finer;one of the privileges that are present is selected. The transition due to moves is similar to our transition between states dueto action. But Dijkstra’s transition is also finer grained because the changes happen only to the local state of the machinewhose privilege is selected, and this change depends on the local state (prior to the move) of the machine, the local state ofthe neighbors, and the privilege selected. We have a specific set of initial states and we use exogenous actions to compute aclosure of states that may be reached. In Dijkstra’s definition of self-stabilization all states are possible initial states. This isthe same as having the closure to be the set of all states. Modulo the above differences, Dijkstra’s notion of self-stabilizationis the same as our notion of finite maintainability.If one thinks in terms of global states, then essentially self-stabilization is the same as finite maintainability. Our majorcontribution is that, unlike research in the area of self-stabilization protocols, where such protocols are invented by peopleand self-stabilizability of systems using those protocols is proven, we give a method to automatically come up with theprotocols (or “policies” in our terms). Nonetheless, a large body of research in self-stabilization is with respect to distributedsystems where one does not have access to the global state in deciding what action to take. Thus a direction for futureresearch is to find algorithms similar to ours that can generate protocols (policies) in the distributed domain.A.2. Arora and Gouda’s notion of closure, convergence, and fault-toleranceArora and Gouda’s abstraction [2] is more closer to ours than Dijkstra’s. We start with their definitions and terminology.• A program consists of a set of variables and a set of processes.• Each process consists of a set of condition-statement pairs (B, st), where B is a Boolean expression over programvariables, and st updates zero or more program variables and always terminates upon execution.• A state of a program p is defined by the value for each variable of p.• For any process of a program p, using the set of condition-statement pairs we can construct a mapping from states tosets of statements, where s maps to a set containing st iff there is a (B, st) in the process such that B evaluates to truein s. This mapping is referred to as the policy corresponding to that process. If a program has a single process, then thepolicy corresponding to that process is also referred to as the policy of that program.• A state predicate of p is a Boolean expression over the variables of p.• A condition-statement pair (B, st) is enabled at a state iff B evaluates to true at that state.• A process is said to be enabled at a state iff some pair (B, st) of that process is enabled at that state.• Closure: A state predicate S is closed in a program p iff for each pair (B, st) in each process of p, executing st startingfrom a state where B ∧ S holds results in a state where S holds.• A computation of p is a sequence of states that satisfies the following three conditions:(i) for each pair of consecutive states c, d in the sequence, there exists a pair (B, st) in some process of p such that Bholds at c and executing st starting from c results in d;(ii) the sequence is maximal, i.e., the sequence is either infinite or it is finite and no condition-statement pair is enabledin the last state; and(iii) if any process j of p is continuously enabled along the sequence, then eventually some action of j is chosen forexecution.• Convergence: Let S and T be state predicates of p. T is said to converge to S in p iff(a) S and T are closed in p and(b) in each computation of p starting at any state where T holds, there exists a state where S holds.• Fault-tolerance: Let S be a closed state predicate of p and let F be a set of condition-statement pairs on variables of p.Then p is F -tolerant of S iff there exists a state predicate T of p such that:(a) T holds at every state where S holds;(b) for each pair (B, st) in F , executing st starting from a state where B ∧ T holds results in a state where T holds; and(c) T converges to S in p.1468C. Baral et al. / Artificial Intelligence 172 (2008) 1429–1469The notions of closure, convergence, and fault tolerance of Arora and Gouda are very close to similar notions in ourdefinition of maintainability. We now compare their notions to ours more in detail.Comparison to our notions Arora and Gouda’s notion of states is similar to our notion of states, and their notion of statementsis similar to our notion of actions, except that statements cause deterministic transition between states and are executablein all states, while actions can have non-deterministic effects and are executable in some states only. Their notion of aprocess (consisting of a set of condition-statement pairs) is similar to our policy, and their notion of a program consists ofa set of variables (that define the states) and a set of processes. Their notion of closure is the same as our notion of closurewhen we assume the absence of exogenous actions and the presence of a single process. (We assume the presence of asingle process in the rest of our comparison.) Their notion of a computation is similar to our notion of a sequence of statesobtained using the Unfold function, except that we have no fairness condition, which we do not need since we have only asingle policy under consideration) and that policy dictates the execution of only one action in any state.Arora and Gouda’s notion of “T converges to S” (when there is a single process) is similar to finite maintainability (in theabsence of exogenous actions), where T and S correspond to the closure of our initial and final states, respectively. In theirnotion of fault tolerance, captured by “p is F -tolerant of S,” the fault set F corresponds to our exogenous actions and whenthey can occur, S corresponds to the set of final states, and p reflects the state-space and the policy under consideration. InArora and Gouda’s definition of fault tolerance, T corresponds to our closure of a set of initial states, but has the additionalrequirement that the set of final states S is a subset of T . Thus “p is F -tolerant of S” corresponds to our notion of thepolicy of p maintaining a set of initial states (whose closure contains S) with respect to S in presence of exogenous actionsdescribed by F .While our notion of maintainability is similar to the notion of tolerance under a class of faults in [2], Arora and Goudado not give an algorithm to automatically construct a policy (or process in their terms) that will result in the tolerance,while we give algorithms which generate policies, if such policies exist, that guarantee maintainability.References[1] M. Abadi, L. Lamport, P. Wolper, Realizable and unrealizable specifications of reactive systems, in: Proc. 16th International Conference on Automata,Languages, and Programming (ICALP 89), in: LNCS, vol. 372, Springer, 1989, pp. 1–17.[2] A. Arora, M.G. Gouda, Closure and convergence: A foundation of fault-tolerant computing, IEEE Transactions on Software Engineering 19 (11) (1993)1015–1027.[3] F. Bacchus, F. Kabanza, Planning for temporally extended goals, Annals of Mathematics and Artificial Intelligence 22 (1998) 5–27.[4] C. Baral, T. Eiter, J. Zhao, Using SAT and LP to design polynomial-time algorithms for planning in non-deterministic domains, in: Proc. 20th NationalConference on Artificial Intelligence (AAAI ’05), AAAI Press, 2005, pp. 578–583.[5] C. Baral, M. Gelfond, A. Provetti, Representing actions: Laws, observations, and hypothesis, Journal of Logic Programming 31 (1997) 201–243.[6] C. Baral, V. Kreinovich, R. Trejo, Computational complexity of planning and approximate planning in the presence of incompleteness, Artificial Intelli-gence 122 (1-2) (2000) 241–267.[7] C. Baral, V. Kreinovich, R. Trejo, Computational complexity of planning with temporal goals, in: B. Nebel (Ed.), Proc. 17th International Joint Conferenceon Artificial Intelligence (IJCAI-01), Morgan Kaufmann, 2001, pp. 509–514.[8] C. Baral, T. Son, Relating theories of actions and reactive control, Electronic Transactions on Artificial Intelligence 2 (3-4) (1998) 211–271.[9] C. Baral, J. Zhao, Goal specification in presence of non-deterministic actions, in: R.L. de Mántaras, L. Saitta (Eds.), Proc. 16th European Conference onArtificial Intelligence (ECAI 2004), IOS Press, 2004, pp. 273–277.[10] M. Barbeau, F. Kabanza, R. St-Denis, Synthesizing plan controllers using real-time goals, in: Proc. 14th International Joint Conference on ArtificialIntelligence (IJCAI-95), 1995, pp. 791–800.[11] D. Barrington, N. Immerman, H. Straubing, On uniformity within NC 1, Journal of Computer and System Sciences 41 (1990) 274–306.[12] M. Ben-Ari, Z. Manna, A. Puneli, The temporal logic of branching time, in: Proc. 8th Symposium on Principles of Programming Languages, 1981, pp.164–176.[13] P. Bertoli, A. Cimatti, M. Pistore, Strong cyclic planning under partial observability, in: ECAI, 2006, pp. 580–584.[14] P. Bertoli, M. Pistore, Planning with extended goals and partial observability, in: S. Zilberstein, J. Koehler, S. Koenig (Eds.), ICAPS, 2004, pp. 270–278.[15] R. Brooks, A robust layered control system for a mobile robot, IEEE Journal of Robotics and Automation 2 (1) (1986) 14–23.[16] T. Bylander, The computational complexity of propositional strips planning, Artificial Intelligence 69 (1994) 165–204.[17] S. Ceri, J. Widom, Deriving production rules for constraint maintenance, in: P.M.G. Apers, G. Wiederhold (Eds.), Proc. 15th International Conference onVery Large Data Bases (VLDB-90), 1990, pp. 566–577.[18] A. Cimatti, M. Pistore, M. Roveri, P. Traverso, Weak, strong, and strong cyclic planning via symbolic model checking, Artificial Intelligence 147 (1–2)(2003) 35–84.[19] E. Clarke, E. Emerson, Design and synthesis of synchronization skeletons using branching-time temporal logic, in: Proc. Workshop on Logic of Programs,in: LNCS, vol. 131, Springer, 1981, pp. 52–71.[20] E. Clarke, E. Emerson, A. Sistla, Automatic verification of finite-state concurrent systems using temporal logic specifications, ACM Transactions onProgramming Languages and Systems 8 (2) (1986) 244–263.[21] M. Daniele, P. Traverso, M. Vardi, Strong cyclic planning revisited, in: Proc. 5th European Conference on Planning (ECP’99), in: LNCS/LNAI, vol. 1809,Springer, 1999, pp. 35–48.[22] E. Dantsin, T. Eiter, G. Gottlob, A. Voronkov, Complexity and expressive power of logic programming, ACM Computing Surveys 33 (3) (2001) 374–425.[23] G. De Giacomo, R. Reiter, M. Soutchanski, Execution monitoring of high-level robot programs, in: Proc. Sixth Conference on Principles of KnowledgeRepresentation and Reasoning (KR-98), 1998, pp. 453–465.[24] E.W. Dijkstra, Self-stabilizing systems in spite of distributed control, CACM 17 (11) (1974) 644–843.[25] W. Dowling, J.H. Gallier, Linear-time algorithms for testing the satisfiability of propositional Horn theories, Journal of Logic Programming 3 (1984)267–284.[26] M. Drummond, Situation control rules, in: Proc. First International Conference on Principles of Knowledge Representation and Reasoning (KR-89), 1989,pp. 103–113.C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691469[27] P. Dunne, M. Laurence, M. Wooldridge, Complexity results for agent design problems, Annals of Mathematics, Computing & Teleinformatics 1 (1) (2003)19–36.[28] P. Dunne, M. Wooldridge, Optimistic and disjunctive agent design problems, in: C. Castelfranchi, Y. Lespéranceand (Eds.), Proc. 7th International Work-shop on Intelligent Agents (ATAL VII), in: LNCS, vol. 1986, Springer, 2001, pp. 1–14.[29] T. Eiter, W. Faber, N. Leone, G. Pfeifer, Declarative problem-solving using the DLV system, in: J. Minker (Ed.), Logic-Based Artificial Intelligence, Kluwer,2000, pp. 79–103.[30] E. Emerson, Temporal and modal logics, in: J. van Leeuwen (Ed.), Handbook of Theoretical Computer Science, vol. B, Elsevier, 1990, Chapter 16.[31] K. Erol, V. Subrahmanian, D. Nau, Complexity, decidability and undecidability results for domain-independent planning, Artificial Intelligence 76 (1995)75–88.[32] R.E. Fikes, N.J. Nilsson, Strips: A new approach to the application of theorem proving to problem solving, Artificial Intelligence 2 (3–4) (1971) 189–208.[33] M. Gelfond, V. Lifschitz, Classical negation in logic programs and disjunctive databases, New Generation Computing 9 (1991) 365–385.[34] M. Gelfond, V. Lifschitz, Representing action in extended logic programs, in: Proc. Joint International Conference and Symposium on Logic Programming(JICSLP’92), MIT Press, 1992, pp. 559–573.[35] M. Ghallab, D. Nau, P. Traverso, Automated Planning—Theory and Practice, Morgan Kaufmann, 2004.[36] M.L. Ginsberg, Universal planning: An (almost) universally bad idea, AI Magazine 10 (4) (1989) 40–44.[37] A. Harding, M. Ryan, P.-Y. Schobbens, A new algorithm for strategy synthesis in ltl games, in: N. Halbwachs, L.D. Zuck (Eds.), TACAS, in: LNCS, vol. 3440,Springer, 2005, pp. 477–492.[38] N. Immerman, Descriptive Complexity, Springer, 1999.[39] R.M. Jensen, M.M. Veloso, M.H. Bowling, OBDD-based optimistic and strong cyclic adversarial planning, in: Proc. 6th European Conference on Planning(ECP-01), 2001.[40] R.M. Jensen, M.M. Veloso, R.E. Bryant, Fault tolerant planning: Toward probabilistic uncertainty models in symbolic non-deterministic planning, in:S. Zilberstein, J. Koehler, S. Koenig (Eds.), Proc. 14th International Conference on Automated Planning and Scheduling (ICAPS 2004), 2004, pp. 335–344.[41] F. Kabanza, M. Barbeau, R. St-Denis, Planning control rules for reactive agents, Artificial Intelligence 95 (1) (1997) 67–113.[42] L.P. Kaelbling, S.J. Rosenschein, Action and planning in embedded agents, in: Maes [47], pp. 35–48.[43] C. Kuratowski, Topology I, Academic Press, New York, 1966.[44] U.D. Lago, M. Pistore, P. Traverso, Planning with a language for extended goals, in: AAAI/IAAI, 2002, pp. 447–454.[45] N. Leone, G. Pfeifer, W. Faber, T. Eiter, G. Gottlob, S. Perri, F. Scarcello, The DLV system for knowledge representation and reasoning, ACM Transactionson Computational Logic 7 (3) (2006) 499–562.[46] M.L. Littman, Probabilistic propositional planning: Representations and complexity, in: Proc. 14th National Conference on Artificial Intelligence and 9thInnovative Applications of Artificial Intelligence Conference (AAAI/IAAI 1997), 1997, pp. 748–754.[47] P. Maes (Ed.), Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back, MIT Press, 1990.[48] Z. Manna, A. Pnueli, The Temporal Logic of Reactive and Concurrent Systems Specification, Springer, 1992.[49] Z. Manna, P. Wolper, Synthesis of communicating processes from temporal logic specifications, ACM Transactions on Programming Languages andSystems 6 (1) (1984) 68–93.[50] M. Minoux, LTUR: A simplified linear time unit resolution for Horn formulae and computer implementation, Information Processing Letters 29 (1988)1–12.[51] M. Nakamura, C. Baral, Invariance, maintenance and other declarative objectives of triggers—a formal characterization of active databases, in: J. Lloydetal. (Ed.), Proc. First International Conference on Computational Logic (CL 2000), in: LNAI, vol. 1861, Springer, 2000, pp. 1210–1224.[52] M. Nakamura, C. Baral, M. Bjæreland, Maintainability: A weaker stabilizability like notion for high level control, in: Proc. 17th National Conference onArtificial Intelligence and Twelfth Conference on Innovative Applications of Artificial Intelligence (AAAI/IAAI 2000), AAAI Press, 2000, pp. 62–67.[53] I. Niemelä, P. Simons, T. Syrjänen, Smodels: A system for answer set programming, in: C. Baral, M. Truszczy ´nski (Eds.), Proc. 8th International Workshopon Non-Monotonic Reasoning (NMR’2000), 2000, available at http://xxx.lanl.gov/abs/cs.AI/0003033.[54] R. Niyogi, S. Sarkar, Logical specification of goals, in: R.K. Ghosh, D. Misraand (Eds.), Proc. 3rd International Conference on Information Technology (CIT2001), Tata McGraw-Hill, 2000, pp. 77–82.[55] C. Ortiz, A commonsense language for reasoning about causation and rational action, Artificial Intelligence 111 (2) (1999) 73–130.[56] O. Ozveren, A. Willsky, P. Antsaklis, Stability and stabilizability of discrete event dynamic systems, Journal of ACM 38 (3) (1991) 730–752.[57] C.H. Papadimitriou, Computational Complexity, Addison-Wesley, 1994.[58] K. Passino, K. Burgess, Stability Analysis of Discrete Event Systems, John Wiley and Sons, 1998.[59] N. Piterman, A. Pnueli, Y. Sa’ar, Synthesis of reactive(1) designs, in: VMCAI, 2006, pp. 364–380.[60] A. Pnueli, R. Rosner, On the synthesis of a reactive module, in: Proc. 16th Annual ACM Symposium on Principles of Programming Languages (POPL1989), 1989, pp. 179–190.[61] P. Ramadge, W. Wonham, Modular feedback logic for discrete event systems, SIAM Journal of Control and Optimization 25 (5) (1987) 1202–1217.[62] P. Ramadge, W. Wonham, Supervisory control of a class of discrete event process, SIAM Journal of Control and Optimization 25 (1) (1987) 206–230.[63] R. Reiter, Knowledge in Action: Logical Foundation for Describing and Implementing Dynamical Systems, MIT Press, 2001.[64] J. Rintanen, Complexity of planning with partial observability, in: S. Zilberstein, J. Koehler, S. Koenig, (Eds.), Proc. 14th International Conference onAutomated Planning and Scheduling (ICAPS 2004), 2004, pp. 345–354.[65] P. Simons, I. Niemelä, T. Soininen, Extending and implementing the stable model semantics, Artificial Intelligence 138 (2002) 181–234.[66] E. Sontag, Stability and stabilization: Discontinuities and the effect of disturbances, in: F. Clarke, R. Sternand (Eds.), Proc. NATO Advanced Study Institute,Kluwer, 1998, pp. 551–598.[67] D. Weld, O. Etzioni, The first law of robotics (a call to arms), in: Proc. Twelfth National Conference on Artificial Intelligence (AAAI-94), AAAI Press,1994, pp. 1042–1047.[68] J. Widom, S. Ceri (Eds.), Active Database Systems: Triggers and Rules For Advanced Database Processing, Morgan Kaufmann, 1996.[69] M. Wooldridge, The computational complexity of agent design problems, in: Proc. Fourth International Conference on Multi-Agent Systems (ICMAS2000), IEEE Press, 2000, pp. 341–348.