Time-efficient sparse analysis of histopathological WholeSlide ImagesChao-Hui Huang, Antoine Veillard, Nicolas Lomenie, Daniel Racoceanu,Ludovic RouxTo cite this version:Chao-Hui Huang, Antoine Veillard, Nicolas Lomenie, Daniel Racoceanu, Ludovic Roux. Time-efficientsparse analysis of histopathological Whole Slide Images. Computerized Medical Imaging and Graphics,2010, pp.5. ￿hal-00553877￿HAL Id: hal-00553877https://hal.science/hal-00553877Submitted on 10 Jan 2011HAL is a multi-disciplinary open accessarchive for the deposit and dissemination of sci-entific research documents, whether they are pub-lished or not. The documents may come fromteaching and research institutions in France orabroad, or from public or private research centers.L’archive ouverte pluridisciplinaire HAL, estdestinée au dépôt et à la diffusion de documentsscientifiques de niveau recherche, publiés ou non,émanant des établissements d’enseignement et derecherche français ou étrangers, des laboratoirespublics ou privés.Time-efficient sparse analysis of histopathological Whole Slide ImagesChao-Hui Huangb,c, Antoine Veillardb,c, Nicolas Lom´eniea,b, Daniel Racoceanua,b,c,d, Ludovic Rouxb,e,∗aCentre National de la Recherche Scientifique (CNRS), Paris, FrancebIPAL (Image & Pervasive Access Lab), International Mixed Research Unit UMI CNRS 2955 (CNRS, NUS, I2R/A*STAR, UJF),Singapore (http://ipal.i2r.a-star.edu.sg/)cNational University of Singapore, SingaporedUniversity of Franche-Comt´e, Besan¸con, FranceeUniversity Joseph Fourier, Grenoble, FranceAbstractHistopathological examination is a powerful method for the prognosis of critical diseases. But, despite significantadvances in high-speed and high-resolution scanning devices or in virtual exploration capabilities, the clinical analysisof Whole Slide Images (WSI) largely remains the work of human experts. We propose an innovative platform in whichmulti-scale computer vision algorithms perform fast analysis of a histopathological WSI. It relies on specific high andgeneric low resolution image analysis algorithms embedded in a multi-scale framework to rapidly identify the high powerfields of interest used by the pathologist to assess a global grading. GPU technologies as well speed up the globaltime-efficiency of the system.In terms ofvalidation, we are designing a computer-aided breast biopsy analysis application based on histopathology images anddesigned in collaboration with a pathology department. The current ground truth slides correspond to about 36,000high magnification (40X) high power fields. The time processing to achieve automatic WSI analysis is on a par with thepathologist’s performance (about ten minutes a WSI), which constitutes by itself a major contribution of the proposedmethodology.In a sense, sparse coding and sampling is the keystone of our approach.Keywords: Histopathology, breast cancer, Whole Slide Image, multi-scale analysis, dynamic sampling, virtualmicroscope, Graphics Processing Unit1. IntroductionHistopathology is widely accepted as a powerful goldstandard for prognosis in critical diseases such as breast,prostate, kidney and lung cancers, allowing to narrow bor-derline diagnosis issued from standard macroscopic non-invasive analysis such as mammography and ultrasonog-raphy. At the molecular/genetic scale as well challengingmethods recently emerged for clinical diagnosis purposes.However, histomorphology as operated in hospitals is andwill remain the basis for most cancer classification.The histopathological image analysis process has largelyremained the work of human experts so far. At the hos-pital level, the task consists in the daily examination ofhundreds of slides, directly impacting critical diagnosisand treatment decisions. According to pathologists’ opin-ion [1], such a tedious manual work is often inconsistentand subjective, lacking traceability and computer assistedIn addition,analysis/annotation/grading support tools.hospitals will have to manage a shortage of expert pathol-ogists keen at doing this kind of unrewarding tasks.A few image analysis algorithms and automated grad-ing systems dedicated to breast histopathology images have∗Corresponding authorEmail address: vislr@i2r.a-star.edu.sg (Ludovic Roux)already been studied. Est´evez et al.[2] and Schnorren-ber et al.[3] worked on Fine Needle Aspiration (FNA)biopsies. FNA images are relatively easier to analyze thanWSIs since such an examination has limited diagnostic op-tions and produces mostly well separated cells over a well-contrasted background. Petushi et al.[4, 5] introduceda system able to label several histological and cytologicalmicrostructures in high resolution frames, including differ-ent grades of epithelial cells, fat cells and stroma. Doyleet al. [6, 7] proposed a method based on geometrical fea-tures, to distinguish between healthy tissue, low grade andhigh grade cancer. Tutac et al. [8] initiated an innovativeknowledge guided approach relying on the prior modelingof medical knowledge using ontology designed accordingto the clinical standard called Nottingham Grading Sys-tem [9]. An extension to this work involving multi-scaleapproaches was proposed by Dalle et al. [10].In close collaboration with a histopathology depart-ment, we built up a high-speed WSI analysis platform ableto detect scale-dependent meaningful regions of interest inmicroscopic biopsy images. This platform is dedicated tothe grading of breast cancer for prognosis purposes butthe methodology we present here is quite generic. Weuse a standard optical microscope that can be found inmost of the analysis laboratories in pathology or bacteri-Preprint submitted to Computerized Medical Imaging and GraphicsMay 27, 2010ology (in our case, an optical microscope Olympus BX51,with 4X/10X/40X/60X/100X possible magnifications, PriorH101A ProScanII motorized X/Y stage and Z focus with atravel range of 114mm×75mm and a minimum step size of0.02μm, and a 1280×1024 pixels digital camera MediaCy-bernetics “EvolutionLC color” IEEE1394 MegaPixel). Weuse a MediaCybernetics controller connected to the micro-scope to perform an acquisition of high power fields/frames(in our study at 40X magnification according to the requestof the pathologist for the high resolution analysis). Theacquired 40X high power fields are stitched together in or-der to obtain the WSI.To the best of our knowledge, most of the previousresearch works focused on the analysis of individual highresolution frames [11] and/or proposed solutions too com-putationally expensive to be applied at the WSI level [12].A few notable exceptions [13] rely on the analysis of lowerresolution images for the selection of regions of interest.Unfortunately, there is little correlation between low res-olution images and the actual levels of nuclear pleomor-phism observable at high resolution for instance. There-fore, even such methods proved to be inefficient for theparticular issue of nuclear pleomorphism assessment onfull biopsy slides. As a consequence, the time-efficiencyproblem posed by the extremely large scale of biopsy im-ages (several thousands of frames) still lacks a practicalsolution.In this work, we propose solutions to improve efficiencyof such a microscopic platform both in terms of speed andprecision, in particular with a multi-scale dynamic sam-pling approach and the use of GPU programming. Theprocessing of a WSI starts by the detection of invasiveregions of interest (ROI) at low resolution level (1.2X).This method relies on a bio-inspired visual informationparadigm related to sparse coding and Graphics Process-ing Unit (GPU) implementation to dramatically speed-up the processing line. This part will be detailed in Sec-tion 2. Once the ROIs are detected, a map of local can-cer grades is established using a new generic multi-scale,computational geometry-based dynamic sampling methodcombined with high-resolution application specific imageanalysis algorithms. Then, this map is used to analyze theWSI within an operational time frame compatible with thepathology department’s needs and on a par with the pro-cessing time of an experimented pathologist. This part willbe detailed in Section 3. Finally, Section 4 elaborates onthe results and validation issues and Section 5 is dedicatedto conclusions, future research directions and challenges.2. Low Resolution Analysis and Sparse CodingRegion of interest (ROI) detection is a fundamentalphase of breast cancer grading for histopathological im-ages. Pathologists identify ROIs to efficiently select themost important invasive areas for the grading process.Since neither pathologists nor computers are able to ex-plore every details at high magnification within a reason-able time, the effective and efficient choice of the ROI isthus a critical step.In this study, ROI detection is casted as as a classifica-tion problem. The low magnification analysis will deter-mine if a given region is an invasive area in a similar man-ner as a pathologist would do when evaluating a biopsy. Inorder to mimic this behaviour, we exploit the relationshipbetween human vision and neuroscience [14].In the visual system, a set of opponent photo-receptorsforms a Receptive Field (RF). These photoreceptors forma field which is called ganglion RF since they collect vi-sual information and send neural spikes to a ganglion cell.Eventually, the ganglion cells produce various stimulationsand send them to the primary visual cortex [15].In the primary visual cortex, there are two major kindsof cells: simple- and complex-cells. Generally speaking,these cells produce two kinds of visual features: first- andsecond-order features [16]. The first-order feature containsthe information of intensities of various color channels, andthe second-order feature includes spatial variance of visualsignal [17, 18].In this study, we simulate some mechanisms of the hu-man visual system, generate the first- and second- orderfeatures as the mechanisms in the human visual system.However, the human visual system and the brain is rathercomplex. Until now, it is not possible to simulate all ofthe function of the brain. Thus, in this study, we considera classification algorithm for distinguishing the differencebetween the invasive area and normal tissue base on thevisual information. Meanwhile, in order to accelerate thistask, we make use of GPU technology. That is, the possi-bilities of the parallelization is also considered. As a result,we are able to use the proposing algorithm in practice.2.1. Parallel Computing with GPUA Graphics Processing Unit (GPU), has been involvedin this study in order to achieve the goal of efficient perfor-mance. GPU is a specialized processor that offloads graph-ics rendering from the microprocessor. The highly parallelstructure of the GPU makes the computing more effectivethan general-purpose CPUs for a range of complex algo-rithms. In a personal computer, a GPU can be present on avideo card. The GPU were coined by NVIDIA marketingin 1999. Currently, most of the new desktop and note-book computers have integrated GPUs, which are usuallyfar less powerful than those on a dedicated video card.NVIDIA GPU comes with many streaming multipro-cessors (SMs), each with many scalar cores (SPs) (seeFig. 1). Threads running on the cores within an SM cancommunicate with each other using shared memory. Theunit of thread execution on the SP is a kernel and this isexecuted in concert with many other threads that form ablock. Many blocks can be scheduled on the GPU, how-ever a block is assigned only to one SM and as the results,threads across blocks should not rely on communicationswith each other. Blocks are scheduled by the GPU as andwhen the SMs have resources available to control them.2SP…SPSP10.90.80.70.60.50.40.30.20.1)dezilamron(esnopserdevice global memorySMyromemderahsSP…SPSPSMyromemderahs…SP…SPSPSMyromemderahsSP…SPSPSMyromemderahsFigure 1: The architecture of GPU.−3x 103.5)mn2m/*rs/w(ecnadari32.521.510.56507007500350400450500550wavelength (nm)6006507007500350400450500550wavelength (nm)600(a) Cone-cell sensitivities for var-ious wavelengths of light.(b) Spectrum of a typical CRTscreen.Figure 2: Retina and screen coefficients.2.1.1. Compute Unified Device ArchitectureCompute Unified Device Architecture (CUDA) is thecomputing engine in NVIDIA GPU that is accessible tosoftware developers through industry standard program-ming languages.CUDA Basic Linear Algebra Subprograms (CUBLAS)is an implementation of basic linear algebra subprogramson the top of the CUDA driver. It allows access to thecomputational resources of NVIDIA GPU. The library isself-contained at the API level. Thus, no direct interactionwith the CUDA driver is necessary.Although the CUDA and CUBLAS provide various ad-vantages on the development. However, the algorithms inthe proposed model is not that trivial since the limitationsof the parallel processing architecture. For example, in themost recent version of CUDA, the version 3.0, some fre-quently used matrix operations, such as matrix inversion,is not included. Thus, for the sake of implementing thealgorithms in the proposed model, some alternate mathe-matical matrix operations are required.2.2. Color RepresentationIn this section, we aim at discovering the relationshipbetween the contents on the screen displaying a breastbiopsy image and the decision-making procedure which isperformed when a pathologist is analyzing the image onthe screen.In order to extract the related visual reactions of hu-man visual system, we need some parameters. First, thesensitivity of the photoreceptors in the visible spectrum.A well-known cone-cell sensitivity factor in visible spec-trum is presented in Fig. 2a [19, 20]. Second, the radiancefactor in the visible spectrum of the screen is required inorder to evaluate the energy which might be received bythe human visual system. Fig. 2b shows a radiance fac-tor in the visible spectrum of a typical CRT screen. Mostmodern screens provide Gamma correction, Gamma Dis-play Functions (GDC) of the screen are also required toevaluate the radiance emitted by the screen based on thefollowing transformation:⎡⎡⎤⎤⎣lms⎦ = a · T ·⎣Γred(r)Γgreen(g)Γblue(b)⎦ ,(1)where r, g, b are the colors of the pixel, Γred(·), Γgreen(·),and Γblue(·) are GDC functions used to reconstruct theGamma correction, s is a necessary scale in order to nor-malize the input values, T is a 3 × 3 matrix which is thelinear combination of the cone-cell sensitivity factor andl, m, and s rep-the radiance factor in visible spectrum.resent the neural activities of various cone cells. Furtherdetails can be found in [19, 20, 21].There are many arguments that compare the pros andcons among various color spaces. According to Geusebroeket al., the opponent color theory can be applied to com-puter vision and implemented as the Gaussian color model[22, 23, 24, 25]. In a Gaussian color model, the opponentcolors can be obtained by:ured = log(l),ublue = log(s),ugreen = log(m), and2 (l + m)).uyellow = log( 1(2)Here (ured, ugreen) and (ublue, uyellow) are used to describethe opponent colors: Red-Green (RG), Blue-Yellow (BY),and Luminance (L):⎧⎨⎩vRG = ured − ugreenvBY = ublue − uyellowvL = 23 (ured + ugreen + ublue) − 1(3)Those color pairs and the luminance information can beused to describe the visual signal of the human visual sys-tem [15, 22, 21].Based on these color information, the human visualsystem is able to extract such features from images.Inour method, these feature extraction algorithms includeintensity, color and texture perception.2.3. First Order Feature2.3.1. Receptive FieldIn the human visual system, the Receptive Field (RF)of a ganglion is considered as the fundamental element[15].In the first order extraction, the RF is defined asIdeally, wea set of pixels sampled over a specific area.should compute all of the pixels in this area. However, inorder to reduce the computational cost, only some pixels in3   2.4. Second Order FeatureSecond-order features cannot be detected by mecha-nisms only sensitive to intensity changes. It is ubiquitousin visual scenes, but the neuronal mechanisms mediatingperception of such stimuli are not well understood [27, 28].Most research works agree that the second-order fea-ture includes spatial variance of visual signal [17, 18]. Inorder to extract the basis, various methods were proposed.Generally speaking, most of them invoke one or severalbasis analysing algorithms. Those algorithms include Ga-bor filtering, Principal Component Analysis (PCA), Inde-pendent Component Analysis (ICA), Sparse Coding, etc.Advantages and disadvantages of each of them have beenactively compared. Olsausen et al. introduced the sparsecoding for natural images in [29] assessing its performancesin comparison with the PCA approaches (see Fig. 1 in[29]). They concluded that the principal components donot arise as a result of the oriented structures in whitenednatural images. Karklin et al. in [30] and Willmore et al.in [31] compared more thoroughly various methods includ-ing sparse coding, Gabor filtering, PCA, and ICA in termsof cost and performance.In this work, we propose a model based on sparse cod-ing, similar to Karklin’s model [32]. First, the basis vectorsof various channels are extracted by sparse coding. Next,the related coefficients of these basis vectors for variousimages can be obtained. Third, the Gaussian distributionof these coefficients can be generated. Finally, the parame-ters μ and σ are obtained and are considered as the secondorder features.This model has the following advantages:it uses thesame color space as the first order feature extraction. Asa result, the computation time of the algorithm can bereduced. Another benefit is that some components in thesystem can be reused in this model. [33], Hyv¨arinen et al.indicated the similarity between the ICA and the sparsecoding as well. Since the sparse coding has been provensuitable for implementation in GPU [34], this approachconstitutes a definite, practical asset in order to increasethe time-efficiency of the system.The sparse coding is described as follows: assume animage of a natural scene contains k pixels. Each imageis stacked as a vector xi. Sparse coding [29, 35] suggeststhat m natural scenes defined by x1 . . . xm ∈ Rk can be de-scribed in terms of a linear combination of n basis vectorsb1 . . . bn ∈ Rk and coefficients s1 . . . sm ∈ Rn with:xi ≈(cid:9)jbjsj,i ,i = 1 . . . m,(7)where si = [s1,i . . . sn,i]. The basis set can be over-complete(n > k) if the maximum k exists.Basis vectors b1 . . . bn and coefficients s1 . . . sn are ob-tained using a training set x1 . . . xm. Thus, the optimiza-tion problem for b and s corresponds to the minimizationFigure 3: An example of breast biopsy (histopathology)image from our virtual microscopic platform. The resolu-tion of the image is 8.3μm/pixel at 1.2X (12 times) mag-nification. One point (the black cross) is chosen by userclick. For the first order feature, a number of points (theblue dots) are obtained based on multivariate Gaussiandistribution. For the second order feature, a number ofpatches (the green rectangles) are obtained in a similarway. The covariances are Σ11 = Σ22 = 1000 pixels andΣ12 = Σ21 = 0.this area are selected according to a sampling distribution.The sampling distribution ps(l) is based on a multivariateGaussian distribution such thatps(l) (cid:2) N (µs, Σs),(4)where l = (l1 . . . li . . . lm), li ∈ R2 is a set of locations ofs = [x, y]T is the mean of the Gaussian dis-data points, µtribution, (x, y) is the location of the sampling point, andΣs is the covariance matrix.2.3.2. First Order Feature ExtractionWhen a RF is chosen, a set of pixel locations l =(l1 . . . li . . . lm), li ∈ R2 is generated. We obtain the Her-ing’s opponent color space: Red-Green (RG), Blue-Yellow(BY), and the Luminance (L) information as follows:vi = [vRG(li), vBY(li), vL(li)], i = 1 . . . m.(5)According to Geusebroek et al., the opponent color the-ory can be applied to computer vision and implemented asthe Gaussian color model [22, 23, 24, 25]. Thus, all vi canbe used to generate a multivariate Gaussian distributionusing a fast parallelized Expectation Maximization accel-erated by GPU [26]:p1(v) (cid:2) N (µ1, Σ1).(6)The mean µtained. In our study, µorder features.1 and the covariance matrix Σ1, can be ob-1 and Σ1 are defined as the first4of:m(cid:10)n(cid:10)12σ2 (cid:4)xi −bjsj,i(cid:4)2 + βi=1j=1with (cid:4)bj(cid:4)2 ≤ c, j = 1 . . . n,m(cid:10)n(cid:10)i=1j=1φ(sj,i),(8)where σ2 is the variance of the noise, φ(·) a sparsity func-tion, and β a constant.Many methods can solve this optimization problem. Apopular method is to consider one of the parameters in(8) as a convex function, and the other as the coefficient.By using an iteration loop, the minimization of (8) can beworked out. For example, first, hold the b and optimizethe s. Then, hold the new s and optimize the b. Theiteration continues until the cost function (8) is minimized.It can be implemented on GPU by the following algorithmproposed by Madhavan [34]:• Parallelized coordinate descent algorithm: hold theB in (8), and evaluate the S. Thus, (8) becomes thefollowing minimization problem:where d = [n1, n2]T and I represents a channel obtainedfrom the input image, −N ≤ n1 < N , and −N ≤ n2 < N ,and N indicates the size of the patches.In the exper-iments, N = 10 pixels. Since all patches x1 . . . xm arecaptured from the same region, they share the same fea-tures. Thus, the texture can be encoded by coefficients sj,iin (7) and (8) with a set of basis vectors bj, which need tobe obtained previously. All sj,i of RG: sRGj,i, BY: sBYj,i,and L: sLj,i constructcj,i = [sRGj,i(li), sBYj,i(li), sLj,i(li)], andi = 1 . . . m and j = 1 . . . n.(16)All cj,i generate a multivariate Gaussian probability dis-tribution using a fast parallel expectation maximizationaccelerated by GPU [26]:p2(c) (cid:2) N (µ2, Σ2).Like the first order feature, the mean µmatrix Σ2 are obtained.defined as the second order features.In our study, µ2 and the covariance2 and Σ2 are(17)minxf (x) =12||y − Ax||2 + γ||x||1.(9)2.5. ClassificationThus, for each optimal xj, the x∗by:j can be obtained⎧⎪⎨⎪⎩x∗j =0,yT a(j)−γa(j)T a(j) ,yT a(j)+γa(j)T a(j) ,if | − yT a(j)| < γif (−yT a(j)) < −γif (−yT a(j)) > γ(10)• Learning bases using projected gradient descent: holdthe S in (8), and evaluate the B. Thus, (8) becomesthe following minimization problem:minx||X − BS||2F ,(11)The optimal B can be obtained by projected gradientdescent:B := B − η (cid:6)B ||X − BS||2F ,(12)constrained at each step by scaling B down suchthat:k(cid:9)i=1B2i,j ≤ c, ∀j = 1, . . . , m.(13)where(cid:6)B||X − BS||2F = −2(X − BS)ST .(14)We described how to generate the first- and second- or-der features the same way as the mechanisms in the humanvisual system do it. For a pathologist, this kind of infor-mation is processed based on his/her knowledge, memory,and experience (the mental database). However, we sim-plify this issue and use a classification method to distin-guish the invasive areas based on the visual information.Once again, we make use of GPU technology by leverag-ing the possibilities of parallelization to speed up againthe analysis performance and provide a practical systemfor the end user in terms of time response.The Support Vector Machine (SVM) is defined as fol-lowing. A set of training data vectors xi ∈ Rn, i = 1, . . . , mis given. Each xi includes the first and second order fea-tures µ2, and Σ2. This set of data vectors is classi-fied into two classes and is labeled by a vector y such thatyi ∈ {1, −1}, i = 1, . . . , m. Training a SVM as a classifieris equivalent to solve the following primal problem:1,Σ1, µminw,b,ξ12 wT w + Cm(cid:9)ξi,i=1subject to yi(wT φ(xi) + b) ≥ 1 − ξi,(18)where ξi ≥ 0, i = 1, . . . , m. The dual form of (18) isminα12 αT Qα −(cid:9)αi,isubject to yT α = 0,(19)Receptive FieldFirst, following (4), a set of data point locations l1 . . . lm ∈R2 are generated. Let li be the center of an image patch,from which a set of patches x1 . . . xm can be obtained:where 0 ≤ αi ≤ C, i = 1, . . . , m, Qij = yiyjK(xi, xj),and K(xi, xj) ≡ φ(xi)T φ(xj). The SVM is implementedon GPU based on Carpenter’s work [36]. In this method,K(xi, xj) is defined as a Gaussian kernel :xi = I(li − d),(15)5e−λ||xi−xj ||2.(20)Figure 4: 400 basis vectors on 20×20 pixels image patches,extracted from digitized breast cancer biopsies (virtual mi-croscope).With a trained SVM, the hyper-plane is obtained as:H(x) =m(cid:9)i=1yiαiφ(xi)T φ(x) + b,(21)and the classification is performed according to:sign(H(x)).(22)Note that |H(x)| is considered as the confidence degree ofthe classification.2.6. Training and TestingIn the training phase, the pathologist provided digi-tized breast biopsies with annotated regions of invasive in-terest area. Then, the basis vectors for sparse coding weregenerated from these annotated samples. In the system, aGPU-based sparse coding was used in order to acceleratethe process. We obtained 400 basis vectors on 20×20 pix-els image patches, extracted from all channels (red-green,blue-yellow, and luminance) of the digitized breast cancerbiopsies. The basis vectors of the luminance channel arepresented in Fig. 4. Next, under the supervision of thepathologist, receptive fields (RFs) were selected by userclick for both the first and second order features. TheseRFs included invasive and non-invasive areas validated bythe pathologist (see Fig. 5a). The RFs are the trainingpatterns of the GPU-based SVM [37].In the testing phase, a set of RFs were selected onan input image based on a hexagonal arrangement (seeFig. 5b). The first and second order features of these RFswere classified by the trained GPU-based SVM [37] achiev-ing an average 17-fold speed up for the detection of invasiveareas over the WSIs in comparison with a standard imple-mentation. However, since only few regions were selectedfor classification in order to reduce computation time, aninterpolation with a low-pass Gaussian filtering is appliedto the SVM classification results (see Fig. 5c). The thresh-old for the invasive ROI detection is set to zero in Fig. 5d.Last, morphological opening and closing filters are appliedon the results of the thresholding operation.6(a)(b)Figure 6: (a-b) Examples of segmented critical cell nuclei.3. Multi-scale Analysis and Sparse SamplingThe Nottingham Grading System (NGS) [9] is basedon an assessment of nuclear pleomorphism, mitotic countsand tubule formation. However, as for now the goal ofthe current study is not the clinical consistency but thetime efficiency. Besides, for the grading assessment, weare on the process of building up a public image databasewith the corresponding clinical scores given by a groupof expert pathologists. As for now, we trained the high-resolution algorithm at the level of the frame on a semi-consistent image database of clinical cases that need to beconsolidated in the near future. The global grading of theWSIs was given by one expert pathologist and still needto be confirmed by at least two other ones.3.1. Nuclear Pleomorphism DetectionOne important criterion of the NGS is the score of thenuclear pleomorphism which is assessed on segmented cellnuclei. Several methods have been proposed for the seg-mentation of cell nuclei in histological images [6, 38, 39,40, 41, 42, 43, 44]. These methods are based on traditionalalgorithms such as thresholding, watershed, morphologicaloperations or active contours. The performance of thesemethods relies on the accurate segmentation of cell nuclei.This is computationally expensive when used to detect allthe cells. In contrast, at least for nuclear pleomorphismscoring (one of the key component in NGS), according tothe pathologist’s knowledge and our experimental results,it is not necessary to segment all the cell nuclei but onlycritical cell nuclei affecting the score.We refer the reader to [45] for more details about thehigh-resolution method that is based on cell segmentationusing critical cell detection algorithm.It includes threedistinctive stages: detection of the cell nuclei, followed bysegmentation, and finally scoring of a population of cellnuclei (Fig. 6) at the frame level.Then, the classification of the population of segmentedcell nuclei is based on medical knowledge used by pathol-ogists when scoring nuclear pleomorphism. Size, round-ness and texture information of a population are extractedand used to build a Gaussian distribution that is com-pared to Gaussian models generated from training data(a)(c)(b)(d)Figure 5: An example of ROI construction.(a) Ground truth provided by pathologists over the input image. Usually the ground truth contains two regions: invasiveand not invasive areas.(b) Result of feature extraction and classification method on a set of equally distributed testing sites. The results areshown as circles. The red-circles indicate positive areas, and the blue-circles are negative areas. Note that the size ofthe circles is related to the hyper-plane H(·).(c) Low-pass filtering in order to estimate the characteristics on the areas between the testing points.(d) The region of interest is obtained by thresholding.for each score. The score of the population of cell nu-clei is assessed by choosing the closest Gaussian Model tothe Gaussian distribution representing the current popula-tion. Once again, the final clinical assessment of this scoreis still to be done. Only, assessment on a clinically semi-consistent database of frames has been performed so far.In particular, the final setting of the parameters weightingsize, roundness and texture information for the computa-tion of the local score still needs to be learned based onthe database that is currently being built up for publicrelease.At the computer-aided diagnosis system level, the scor-ing of the nuclear pleomorphism can be used in two ways:• after the ROI detection step(Section 2), to completeannotation of the frames included in the invasive areaand build a systematic semantic indexing of thoseframes;• as a component of the multi-scale WSI grading ap-proach presented in following Section 3.2.Since our frame-level, high-resolution grading algorithm,although selective, is still too slow to aggregate over oneWSI in order to give a global score in a realistic time re-sponse, we designed a generic multi-scale analysis methodable to further accelerate the WSI grading in additionto the GPU-based ROI detection step. This correspondsmore or less to the pathologist’s way of processing the WSIby picking up about ten frames by a semi-informed cogni-tive sampling, but we do it here in a more systematic wayusing computational efficiency.3.2. Nuclear Pleomorphism Scoring using Multi-Scale Dy-namic SamplingThe next step of the process requires the computa-tion of a score for the nuclear pleomorphism over the se-lected ROIs and not only at the frame level. The scoreis computed out of the frame scores having the highestgrade computed by our high-resolution nuclear pleomor-phism scoring algorithm [45] applied over the whole ROI.However, a single ROI can be potentially very large, up toseveral thousands of high-resolution frames in some cases,making such exhaustive analysis intractable . Whereas thecurrent research effort in histopathology image analysis fo-cuses essentially on processing high-resolution frames and7does not consider the problem at the WSI level, we makean attempt to develop an innovative method to rapidlyidentify the frames of interest necessary for the nuclearpleomorphism scoring.Our algorithm aims at drawing a map of the nuclearpleomorphism levels encountered within the individual ROIs.In practice, the scoring is performed by the pathologistbased on a few frames of interest picked up because po-tentially exhibiting the highest grade of cancer in the slide.Usually, the most cancerous areas can be identified withthe regions having the highest degree of nuclear pleomor-phism. It is the best indicator to obtain a global map ofthe cancer because it can be assessed locally (framewise)and is precisely quantifiable in a wide, continuous range(although the Nottingham grading system discretizes it).In comparison, mitoses are too sparse to be a good local in-dicator and tubular formations do not distinguish betweendifferent advanced cancers where tubules are absent.A time-efficient exploration of every ROI is performedwith an original technique that can be described as a multi-scale dynamic sampling of the frames. The algorithmprogressively identifies and focuses on regions showing ahigher pleomorphism while discarding the rest. By avoid-ing an exhaustive analysis,it reduces the computationtime by a factor 27 on average as shown by the experi-mental results in Section 4.Let I be a specific ROI from the WSI identified withthe ROI selection algorithm described in Section 2.Itcomprises a large number of rectangular frames x ∈ I.For every frame x, the local nuclear pleomorhpism S(x)(referred as “score”) can be computed using the algorithmintroduced in Section 3.1. The algorithm progressivelyidentifies and focuses on interesting regions (with a highS(x)) while discarding the rest.The following is a basic outline of this dynamic sam-pling algorithm (more details are available in [46]):Step 1. First, the dynamic sampling algorithm is initial-ized using between 3 to 10 frames selected within the ROI.Then, the score S(x) is computed for these initial samples.The selection is made using a simple low resolution analy-sis identifying the main histological components. This im-proves the robustness of the algorithm over an arbitraryselection of initial frames that is prone to miss entire com-ponents.Step 2. Then, additional samples are dynamically selectedand scored one-by-one in order to provide the most infor-mation at every step. The most informative samples arethose which are both:1. most distant from previous samples2. within areas with a relatively higher pleomorphismComputational geometry tools are used to efficientlyidentify samples verifying condition 1. At each iteration,given E the frames already sampled in the ROI I, we con-struct the Voronoi diagram of the centroids of the frames8Figure 7: Multi-Scale Dynamic Sampling flowchart.(a)(b)(c)(d)Figure 8: Dynamic sampling method applied over a WSIbased on the ROI extraction. The incrementally con-structed Voronoi diagrams are shown in black. Each cellcontains a single sample at its center. The maps result-ing from the interpolation are shown in colors. Hot colorsrepresent higher pleomorphism values.(a) After 50 samples: the whole ROI is being explored. Noarea seems favored.(b) After 150 samples: the algorithm converges towards ahigh pleomorphism values area.(c) After 400 samples: the sampling is very dense aroundthis area and remains sparse in others.(d) For illustration, the highest grading area obtained fromthe resulting map has been superimposed over a low reso-lution image of the ROI. Score for nuclear pleomorphismwill be performed with frames picked from within this area.in E denoted as Vor E. Vor E is a collection of Voronoicells {νx|x ∈ E}, defined by νx = {p ∈ I|∀y ∈ I −{x}, dist(p, x) ≤ dist(p, y)}. The set of Voronoi vertices,later referred as VE are the vertices of the planar graphrepresentation of Vor E. Voronoi vertices share the propri-ety to be locally the farthest position from their nearestneighbor in E, therefore in the case of our algorithm fromalready sampled frames.Condition 2 is realized by selecting our next sample xout of VE such that the score MaxScore(x) of its highestscoring neighbor in E is higher that p×maxE where maxEis the currently observed maximal score among E and p ∈[0, 1] is a preset parameter defining the selectivity of thealgorithm.In practice, we also impose that the distance betweentwo samples must be larger than a theshold d effectivelydefining the coarseness of the sampling. Both parametersp and d are dynamically adapted during the whole processto progressively increase the selectiveness and the finenessof the sampling. A pseudo-code for one iteration of thesampling algorithm is given in Algorithm 9.Input: current samples E, Vor E, p, d, maxEOutput: updated values of E, Vor E, maxE1: compute VE2: sort VE according to decreasing distance to E3: for every x ∈ VE do4:if dist(x, E) ≥ d thenif MaxScore(x) ≥ p × maxE then5:6:7:8:9:10:11:12:E = E ∪ {x}update Vor EmaxE = max(S(x), maxE)beak loopend ifelsebeak loopend if13:14: end forFigure 9: One iteration of the dynamic sampling algorithmStep 3. Finally, the graded samples are used in order tointerpolate the grade of all the frames in the ROI. The re-sulting map precisely details the regions showing the high-est levels of nuclear pleomorphism which is sufficient tosupport an accurate global grading of the ROI. Frames ofinterest are selected from these regions and a scoring isperformed with the algorithm described in Section 3.1.Fig. 7 shows the proposed flowchart and Fig. 8 illus-trates the algorithm output at different stages. It can beseen that the algorithm first has an exploratory behav-ior over the whole ROI, then converges towards areas withthe highest pleomorphism, to finally refine the map aroundthese areas.The time complexity of our algorithm is equivalent tothe cost of analyzing the sample frames. Indeed, as proved9ROC curverROC curveFalse NegativeTrue Positive (Sensibility))False PositivePARTEST GRAPH10.80.60.40.2onitroporpsretemaraP10.80.60.40.2yt)ivitisneS(etarevitisopeurT000.20.40.60.8)1000.20.40.60.81Subjects proportion(a) The Receiver Operat-ing Characteristic (ROC)curve.(b) The Clinical Test Per-formance.Figure 10: Performance of our system. The AUC is 0.9186.by Ohya et al.in [47] the incremental construction ofa Voronoi diagram has a constant average cost for everynew added vertex (corresponding to our samples) and isnegligible compared to the cost of analyzing a sample athigh resolution.4. Results and DiscussionAlthough application oriented, any microscopic WSIbased system can leverage the ideas developed and as-sessed in this work to achieve interactive time applica-tions. This section presents an experimental validation ofthe proposed time-efficient WSI analysis framework basedon two major features of the breast cancer grading plat-form:• the invasive area detection based on a GPU imple-mentation and spare coding paradigm;• the nuclear pleomorphism scoring map based on asparse dynamic sampling algorithm.The ground truth is provided by the pathology depart-ment from the National University Hospital, Singapore fornine breast cancer slides, with the annotation of the rele-vant invasive ROIs (the whole area covered by ROIs wasoutlined) and a global score s ∈ {1, 2, 3} for the nuclearpleomorphism criterion. One slide is made up of about4, 000 high power fields (representing the high resolutionframes) of size 1024×1024 pixels, acquired at 40X, with aresolution of 0.25μm/pixel, using Aperio ScanScope R(cid:3) CSfast scanner. This represents about 8 gigabytes of dataper slide.The microscope we presented in the introduction isused to design the high-resolution algorithm and to set upour own platform as well.But the ground truth must comefrom the digitized histopathological images acquired at thehospital. In practice, the pathologist is not able to analyzeall the frames. Instead, he/she identifies the invasive areasat low resolution, before focusing on specific high resolu-tion frames using his/her experience and his/her mental    Table 1: Examples of ROIs detected by our system and their corresponding quantitative assessmentSourceLearned MapFinal ROIROC/AUCROC curveP3.1P3.2P12.110.80.60.40.2)ytivitisneS(etarevitisopeurT0010.80.60.40.2)ytivitisneS(etarevitisopeurT0010.80.60.40.2)ytivitisneS(etarevitisopeurT000.20.8False positive rate (1−Specificity)0.40.60.91518ROC curve0.20.8False positive rate (1−Specificity)0.40.60.89279ROC curve0.20.8False positive rate (1−Specificity)0.40.61110.96631database. The grading is then performed based on theseframes with, in a typical case, the examination of aboutonly 10 to 40 high power fields.The following results show that our system is able toprovide a global score within an operational time frame ofabout ten minutes.4.1. Invasive area detectionFifteen ROIs were annotated out of nine digitized breastbiopsy slides. Two of the ROIs are used as the trainingpatterns. The global Receiver Operating Characteristic(ROC) curve and the Clinical Test Performance are shownin Fig. 10. The global Area Under the Curve (AUC) is0.9186. We also computed the difference of ROIs betweenthe results of ROI detection and the ground truth by thestandard Jaccard index:c =R ∩ GR ∪ G,(23)where R is our result, and G is the ground truth providedby the pathologist, and c ∈ (0, 1) is the covering rate.It should be noticed that the labeling of these ROIs bythe pathologist was rather coarse and the delineation ofthese regions can be assessed as not accurate (see Table1, left column). Anyway, due to the difficulty of such atask over a WSI we considered it as a first step towards aglobal assessment of our system. Despite this limitation,the average of all of the testing results is c = 0.7077 whichcan be considered as a robust score according to the qualityof the ground truth. Results1 are presented in Table 1 withfrom left to right the original slide, the first map issuedby the learning process, the interpolated ROI to smooththe final result and the quantitative assessment by ROCcurves.In the design of our system, the results are determinedby the sign of the hyper plane H(·) which has been pro-duced by the SVM-based classification. However, the testperformance suggested that the optimal cut point be −1.1348corresponding to the equal sensitivity/specificity cut-offpoint on the ROC curve. Although almost validated froma clinical point of view, the main objective of this studyis to assess the methodology from a time-efficient point ofview, which is actually the critical issue for WSI analysis.In this perspective, the performance of GPU accelera-tion is presented in Table 2. The overall speed-up gain(sparse coding and SVM) is about 24-fold faster. Themodel of the GPU is GeForce 9400M from NVIDIA. Thecomputer is Apple Macbook with Intel CPU Core 2 Duowith 4 gigabytes of memory. With a pre-trained kernel,the processing time allocated for the low resolution imageROI detection module is about 120 seconds a WSI. Once1The full image set can be obtained from IPAL web site http://ipal.i2r.a-star.edu.sg/project_MICO.htm10        Table 2: The performance of GPU acceleration.Sparse codingSVMECMCPU1406.75992.26526.314GPU56.2975.4272.58Speed-up Factorabout × 25about × 17about × 10these ROIs are detected in a reasonable time frame and atlow resolution, a high-resolution but time-efficient analysisover these ROIs can be triggered by the dynamic samplingalgorithm.4.2. Multi-Scale Dynamic SamplingIn order to improve the precision of the sampling pro-cess, individual high resolution frames are split into four512 × 512 pixel smaller frames. The map created by ouralgorithm is used to retrieve the frames corresponding tothe highest pleomorphism scores. Therefore, we tested itsperformances for the retrieval of the set Relf of frames inthe ROI having a pleomorphism value of at least 0.9 × maxwhere max is the global maximum pleomorphism value inthe ROI. Retf refers to the set of frames actually retrievedby our method for having an interpolated score of at least0.9×max according to the map. We compute the precisionand the recall defined by:prec =|Retf ∩ Relf ||Retf |rec =|Retf ∩ Relf ||Relf |(24)For the sake of comparison, we also generate mapsbased on identical numbers of samples which were ran-domly selected. Comprehensive benchmark results for thenine slides can be found in Table 3 (the threshold valuefor the amount of selected samples is set to 500). Figuresgiven in the case of random sampling are average valuesover 40 experiments. Note that the amount of “framesselected as samples” in Table 3 is the amount of framesselected by the dynamic sampling algorithm to create themap of the ROI and not the amount of high grade framesthat are subsequently retrieved from the map.Results show ideal overall performances of our algo-rithm with a consistent 100.0% precision, which meansthat frames selected by our algorithm are systematicallyrepresentative of the highest pleomorphism values in theROI. Nevertheless, we are conscious that these figures donot represent the real error risk in terms of precision dueto the limited number of slides. As a matter of fact, un-like other medical imaging fields like mammography, inhistopathology, no database is yet publicly available. Inaddition, fueled by the recent availability of instrumentsfor digitizing microscope slides, the working group 26 ofthe Digital Imaging and Communications in Medicine22http://medical.nema.org/11(DICOM) standard is about to release the supplement 145“Whole Slide Microscopic Image IOD and SOP Classes”.This explains that validation of systems dealing with WSIis still quite limited.The recall rate fluctuates between 25.0% and 100.0%for an average value of 51.6% which is in any case suf-ficient to compute a robust nuclear pleomorphism on alarge enough number of high grade frames. This meansthat the dynamic sampling method is a valid alternativeto an exhaustive analysis in terms of quality of the scoring.These figures compare to the 45.8% precision and 4.0% re-call averages obtained with a map generated from randomsampling.We also achieved a significant overall speedup: the pro-portion of analyzed frames ranges from 0.8% to 9.0% withan average of 3.3% of the ROI. Therefore, our method pro-duced a clinically semi-consistent nuclear pleomorphisnmscoring requiring only 3.3% (on average) of the time re-quired for an exhaustive analysis of the whole slide. Asfor now, a more dedicated local scoring must be designedframewise in order to achieve clinical consistency. How-ever, the global time response will not be dramaticallyaffected due to the generecity of the method in which anysophisticated local scoring function can be plugged in.4.3. Overall speed-up performanceProcessing the whole set of WSI high power fields wouldrequire several dozens of hours. For example,in [12],a multiscale stochastic texture-based algorithm classifiesspecific biological elements for virtual slide analysis of ovar-ian carcinoma cases in 100 to 300 hours on one processor ofa 3 gigahertz Xeon quadriprocessor. This is prohibitive forclinical daily use ( but also for large scale biological mod-elling as needed for the Virtual Human Physiology efoortscurrently carried out worldwide). Usually, a pathologistanalyzes a breast biopsy slide in about ten minutes.We implemented several mechanisms to speed-up WSIautomatic processing and, regardless the accuracy perfor-mance, time required by our system to score a slide is on apar with pathologists’ analysis time. In any case, improv-ing accuracy performance should not degrade significantlythe processing time performance achieved so far. The keyidea is to mimic the pathologist’s routine when he has tograde a slide. First of all, the most important point is toreduce dramatically the number of high power fields to beprocessed in detail. To reach this goal, in a first step, weperform ROI detection at low resolution (by using GPU,we achieve a speed-up factor of about 24-fold). In a secondstep, a multi-scale dynamic sampling selects a small num-ber of high power fields with the highest concentration ofpleomorphic cells. Precise cell detection and feature com-putation for scoring the slide, the most time consumingpart of the scoring, is applied only to this small number ofselected relevant high power fields. Only 3.3% of the highpower fields of a slide are thoroughly analyzed on average.Case id. Amount of framesSelected as samples Analyzed fractionTable 3: Experimental results.P1P2P3P4P5P6P7P8P9840022889804374455442275214628141121014831311842288500500500275793.7%5.2%4.3%2.4%9.0%2.2%3.4%1.9%0.8%Dynamic samplingRandom samplingprecision1.0001.0001.0001.0001.0001.0001.0001.0001.000recall rate0.6840.4000.8570.2500.3840.5460.2680.2501.000precision0.5400.3400.7200.0801.0000.3000.9600.1600.020recall rate0.0360.0760.0510.0250.0910.0160.0380.0230.0045. ConclusionFrom now, it is a great challenge to propose automated,time-efficient microscopic WSI analysis systems. The dig-ital pathology world experiences the same overwhelmingquality and quantity of data to be processed as the satel-lite world does. Not only has the system to be clinicallypertinent, but it also has to provide results within reason-able time frame. This work has focused on the latter issueso far. However, to some extent, it has been proven clin-ically compliant. The Nottingham Grading System hasnot yet been fully implemented and only nuclear pleomor-phism was tested. We proposed two solutions to speed upthe overall time response of the system: the sparse cod-ing paradigm embedded in a GPU framework for the pre-attentive part and the dynamic sampling algorithm to im-plement the informed picking up of frames operated by thepathologists. The assessment of our pleomorphism scoringshowed room for improvement of our system from a clini-cal accuracy point of view but the overall architecture ofthe system has proven to yield preliminary clinical insightswithin a time frame on a par with the pathologists’ one. Asthe nuclear pleomorphism scoring will get more accurate,the global clinical consistency of our system will improvewithout undermining much the overall time-efficiency ofthe proposed architecture within which a histopathologi-cal WSI is automatically analyzed in about ten minutes .All in all, this architecture can be applied to any micro-scopic WSI analysis systems regarding the multi-scale andGPU approaches and then tailored to every specific clinicalor biological applications at the high-resolution level.Acknowledgmentto thank Dr. Jacques Klossa from TRIBVN company,Paris, France5 for his valuable expertise and support dur-ing this study. We would like to thank Mr. Xiong Wei fromA*STAR/I2R for his contribution during the initial stageof the project. We also would like to thank Dr. KarklinYan from New York University for the fruitful discussionsabout sparse coding and its implementation.References[1] T. Ming, The challenges and pitfalls of Biomedical imaging —Perspectives of a Pathologist, in: SFBI’06, First Singaporean-French Biomedical Imaging Workshop, 2006.[2] J. Est´evez, S. Alay´on, L. Moreno, R. Aguilar, J. Sigut, Cytolog-ical breast fine needle aspirate images analysis with a geneticfuzzy finite state machine, in: Proceedings of the 15th IEEESymposium on Computer-Based Medical Systems, 21–26, 2002.[3] F. Schnorrenberg, C. Pattichis, K. Kyriacou, V. M. Schizas,C. Schizas, Computer-aided classification of breast cancer nu-clei, Technology & Health Care 4 (1996) 147–161.[4] S. Petushi, C. Katsinis, C.and Coward, F. Garcia, A. Toz-eren, Automated identification of microstructures on histologyslides, in: Proceedings of the IEEE International Symposiumon Biomedical Imaging: Nano to Macro, vol. 1, 424–427, 2004.[5] S. Petushi, F. U. Garcia, M. M. Haber, C. Katsinis, A. Tozeren,Large-scale computations on histology images reveal grade-differentiating parameters for breast cancer, BioMed CentralMedical Imaging 6 (2006) 1–14.[6] S. Doyle, M. Hwang, K. Shah, A. Madabhushi, M. Feldman,J. Tomaszeweski, Automated grading of prostate cancer usingarchitectural and textural image features, in: Proceedings ofthe 5th IEEE International Symposium on Biomedical Imaging:From Nano to Macro, 1284–1287, 2007.[7] S. Doyle,S. Agner, A. Madabhushi, M. Feldman,J. Tomaszewski, Automated gradingcancerhistopathology using spectral clustering with textural andarchitectural image features, in: Proceedings of the 5th IEEEInternational Symposium on Biomedical Imaging: From Nanoto Macro, 496–499, 2008.of breastThis study has been partially supported by the MMed-Web3 grant A*STAR SERC 052 101 0103 (NUS R-252-000-319-305) and by the ONCO-MEDIA4. We would like3MMedWeb A*STAR/SERC: http://ipal.i2r.a-star.edu.sg/[8] A. E. Tutac, D. Racoceanu, T. Putti, W. Xiong, W. K. Leow,V. Cretu, Knowledge-Guided Semantic Indexing of Breast Can-cer Histopathology Images, in: Y. Peng, Y. Zhang (Eds.), Pro-ceedings of BioMedical Engineering and Informatics: New De-velopment and the Future, vol. 2, 107–112, 2008.[9] F. A. Tavassoli, P. Devilee (Eds.), World Health OrganizationClassification of Tumours, Pathology & Genetics, Tumours ofprojects.htm4ONCO-MEDIA,onco-media.comICT Asiaprogramme:http://www.5TRIBVN: http://www.tribvn.com/12the Breast and Female Genital Organs, IARC Press, Interna-tional Agency for Research on Cancer, 2003.[10] J.-R. Dalle, W.-K. Leow, D. Racoceanu, A. E. Tutac, T. C.Putti, Automatic breast cancer grading of histopathological im-ages, in: Proceedings of the 30th International Conference of theIEEE Engineering in Medicine and Biology Society, Vancouver,BC, Canada, 3052–3055, 2008.[11] V. Ta, O. Lezoray, A. Elmoataz, S. Schupp, Graph-based Toolsfor Microscopic Cellular Image Segmentation, Pattern Recog-nition 42 (6) (2009) 1113–1125, special Issue on Digital ImageProcessing and Pattern Recognition Techniques for the Detec-tion of Cancer.[12] N. Signolle, B. Plancoulaine, P. Herlin, M. Revenu, Texture-Based Multiscale Segmentation: Application to Stromal Com-partment Characterization on Ovarian Carcinoma VirtualSlides, in: Proceedings of the International Conference on Imageand Signal Processing, 173–182, 2008.[13] M. Oger, P. Belhomme, J. Klossa, J.-J. Michels, A. Elmoataz,Automated region of interest retrieval and classification usingspectral analysis, in: New trends in digital pathology: Proceed-ings of the 9th European Congress on Telepathology and 3rdInternational Congress on Virtual Microscopy, vol. 3, 2008.[14] R. Miikkulainen, J. A. Bednar, Y. Choe, J. Sirosh, Computa-tional Maps in the Visual Cortex, Springer, Berlin, 2005.[15] D. H. Hubel, Eye, brain, and vision, W. H. Freeman, 1988.[16] G. Rhodes, Looking at faces: First-order and second-order fea-tures as determinants of facial appearance, Perception 17 (1)(1988) 43–63.[17] I. A. Shevelev, Second-order features extraction in the cat vi-sual cortex: Selective and invariant sensitivity of neurons to theshape and orientation of crosses and corners, Biosystems 48 (1)(1998) 195–204.[18] C. C. Pack, B. R. Conway, R. T. Born, M. S. Livingstone, Spa-tiotemporal Structure of Nonlinear Subunits in Macaque VisualCortex, The Journal of Neuroscience 26 (3) (2006) 893–907.[19] CIE, An analytical model for describing the influence of light-ing parameters upon visual performance — vol. 1, Tech. Rep.,Technical Foundations, CIE 19/2.1, Technical Committee 3.1 1,1981.[20] X.Zhang,S-CIELAB:toL*a*b* DeltaE Color Difference Metric,ExtensionSpatialAthe CIEhttp://white.stanford.edu/ brian/scielab/, ????[21] C. H. Huang, C. T. Lin, Bio-inspired computer fovea modelbased on hexagonal-type cellular neural network, IEEE Trans-actions on Circuits and Systems – I 54 (1) (2007) 35–47.[22] J. M. Geusebroek, R. v. d. Boomgaard, A. W. M. Smeulders,H. Geerts, Color invariance, IEEE Transactions on PatternAnalysis and Machine Intelligence 23 (12) (2001) 1338–1350.[23] J.-M. Geusebroek, R. v. d. Boomgaard, A. W. M. Smeulders,T. Gevers, Color constancy from physical principles, PatternRecognition Letters: special issue on colour image processingand analysis 24 (11) (2003) 1653–1662.[24] M. A. Hoang, J.-M. Geusebroek, A. W. M. Smeulders, Colortexture measurement and segmentation, Signal Processing: spe-cial issue on content based image and video retrieval 85 (2)(2005) 265–275.[25] H. M¨uller, N. Michoux, D. Bandon, A. Geissbuhler, A review ofcontent-based image retrieval systems in medical applications— Clinical benefits and future directions, International Journalof Medical Informatics 73 (1) (2004) 1–23.[26] N. S. L. P. Kumar, S. Satoor, I. Buck, Publisher, Fast Par-allel Expectation Maximization for Gaussian Mixture Modelson GPUs Using CUDA, in: Proceedings of the 11th IEEE In-ternational Conference on High Performance Computing andCommunications, IEEE Computer, 103–109, 2009.[27] J. Larsson, M. S. Landy, D. J. Heeger, Orientation-SelectiveAdaptation to First- and Second-Order Patterns in Human Vi-sual Cortex, Journal of Neurophysiology 95 (2006) 862–881.[28] H.-P. Frey, P. K¨onig, W. Einh¨auser, The role of first- andsecond-order stimulus features for human overt attention, Per-ception & Psychophysics 69 (2) (2007) 153–161.13[29] B. A. Olshausen, D. J. Field, Emergence of simple-cell receptivefield properties by learning a sparse code for nature images,Nature 381 (13) (1996) 607–609.[30] Y. Karklin, Hierarchical statistical models of computation inthe visual cortex .[31] B. Willmore, D. J. Tolhurst, Characterizing the sparsenessof neural codes, Network: Computational Neural Systems 12(2001) 255–270.[32] Y. Karklin, M. S. Lewicki, Emergence of complex cell propertiesby learning to generalize in natural scenes, Nature 457 (2009)83–86.[33] A. Hyv¨arinen, P. O. Hoyer, A two-layer sparse coding modellearns simple and complex cell receptive fields and topographyfrom natural images, Vision Research 41 (18) (2001) 2413–2423.[34] A. Madhavan, Using GPUs to speedup sparse coding algorithmsapplied to self-taught learning problems, Tech. Rep., StanfordUniversity, 2008.[35] H. Lee, A. Battle, R. Raina, A. Y. Ng, Efficient sparse codingalgorithms, in: Natural Information Processing Systems Con-ference, 801–808, 2007.Carpenter,support[36] A.ofhttp://patternsonascreen.net/cuSVMDesc.pdf, 2009.implementationregression,classificationcuSVM:CUDAvectoranda[37] B. C. Catanzaro, N. Sundaram, K. Keutzer, Fast Support Vec-tor Machine Training and Classification on Graphics Processors,Tech. Rep., University of California at Berkeley, 2008.[38] E. Cosatto, M. Miller, H. P. Graf, J. S. Meyer, Grading nuclearpleomorphism in histopathological micrographs, in: Proceed-ings of the International Conference on Pattern Recognition,2008.[39] Y. Hatanaka, K. Hashizume, Y. Kamihara, H. Itoh, H. Tsuda,R. Y. Osamura, Y. Tani, Quantitative immunohistochemicalevaluation of HER2/neu expression with HercepTest in breastcarcinoma by image analysis, Pathology International 51 (1)(2001) 33–36.[40] A. S. Jadhav, P. Banarjee, K. Chaudhuri, J. Chatterjee, Quan-titative analysis of histopathological features of precancerouslesion and condition using image processing techniques,in:Proceedings of the 19th IEEE International Symposium onComputer-Based Medical Systems, 231–236, 2006.[41] H. Masmoudi, S. M. Hewitt, N. Petrick, K. J. Myers, M. A.Gavrielides, Automated quantitative assessment of HER-2/neuimmunohistochemical expression in breast cancer, IEEE Trans-actions on Medical Imaging 28 (6) (2009) 916–925.[42] K. A. Matkowskyj, D. Schonfeld, R. V. Benya, Quantitative Im-munochemistry by Measuring Cumulative Signal Strength Us-ing Commercially Available Software Photoshop and Matlab,Journal of Histochemistry & Cytochemistry 48 (2) (2000) 303–311.[43] H. Soltanian-Zadeh, K. Jafari-Khouzani, Multiwavelet gradingof prostate pathological images, IEEE Transactions on Biomed-ical Engineering 50 (2003) 697–704.[44] W. Xiong, S. Ong, C. Kang, J. Lim, J. Lui, D. Racoceanu,K. Foong, Cell Clumping Quantification and Automatic AreaClassification in Peripheral Blood Smear Images, in: The 2ndInternational Conference on BioMedical Engineering and Infor-matics – BMEI’09, Tianjin, China, 2009.[45] J.-R. Dalle, H. Li, C.-H. Huang, W.-K. Leow, D. Racoceanu,T. C. Putti, Nuclear Pleomorphism Scoring by Selective CellNuclei Detection, in: IEEE Workshop on Applications of Com-puter Vision, Snowbird, Utah, USA, 2009.[46] A. Veillard, N. Lom´enie, D. Racoceanu, An Exploration Schemefor Large Images: Application to Breast Cancer Grading, Pro-ceedings of the 20th International Conference on Patern Recog-nition .[47] T. Ohya, M. Miri, K. Murota, Improvements of the incrementalmethod for the Voronoi diagram with computational compari-son of various algorithms, Journal of the Operational ResearchSociety of Japan 27 (1984) 306–336.image analysis, in particular for the exploration of hugehistopathological images.Daniel Racoceanu. He received M.Eng. degree in Mecha-tronics from the Politehnica University of Timisoara in1992, M.Sc. degree in Automatics and Industrial Informat-ics from the University of Technology of Belfort-Montb´eliard(UTBM), France in 1993, Ph.D. degree in 1997 and Habil-Dr. degree in 2006 in Control and Computer Sciences fromthe University of Besan¸con, France. Daniel Racoceanu wasProject Manager at General Electric Energy Products -Europe, Belfort, France before joining, in 1999 a chair ofAssociate Professor at the Faculty of Sciences of the Uni-versity of Besan¸con, France, where he coursed until 2005in the field of artificial intelligence, computer vision, in-dustrial informatics, automation, control science and pro-duction systems. Senior Scientist at the French NationalResearch Center (CNRS), Daniel RACOCEANU is the Di-rector (France) of Image & Pervasive Access Lab (IPAL),the International Joint Research Unit (UMI CNRS 2955)created in Singapore between the CNRS, the National Uni-versity of Singapore (NUS), the Institute for InfocommResearch (I2R) of the Singaporean Agency for Science,Technology and Research (A*STAR) and the UniversityJoseph Fourier of Grenoble, France (UJF). From 1999 to2005, Daniel Racoceanu was with FEMTO-ST/AS2M labof Besan¸con, France, working in Diagnosis/Prognosis areausing Artificial Intelligent Techniques (Dynamic NeuralNetworks; Fuzzy Logic, Neuro-Fuzzy Systems). DanielRacoceanu’s actual researches in IPAL focus on Intelli-gent Diagnosis/Prognosis Assistance using Medical Imageand Knowledge-Based Reasoning Systems, Content andContext Based Medical Image Retrieval and Medical Mul-timedia Fusion.Ludovic Roux. He received his Ph.D. degree in ComputerScience from Paul Sabatier University, Toulouse, France in1997. He has been a Research Fellow with Japan AerospaceExploration Agency (JAXA), Tokyo, Japan, from 1997to 1999, then a Software Engineer at Thales Communi-cations, Massy, France. He is currently Research Fellowat IPAL (joint NUS/I2R/A*STAR/CNRS laboratory) inSingapore. His research interests are in image processing,soft computing and machine learning.Chao-Hui Huang. He received his M.Sc. degree in com-puter science and information engineering from Chung-Hua University, Taiwan, in 2001, and His Ph.D. degreein electrical and control engineering from National Chiao-Tung University, Taiwan, in 2007, respectively. He is cur-rently a research fellow in Image & Pervasive Access Lab(French National Research Center, CNRS UMI 2955) andSchool of Computing, National University of Singapore,(2008-2010). During his Ph.D. preparation, he was invitedto serve as a visiting student scholar in University Califor-nia, Berkeley, (2005-2006). He also has several years expe-rience of project management, system analysis, and devel-opment in various world-class software and hardware com-panies, including International Business Machines (IBM),Taiwan-Hsinchu Office. Until 2010, he has published morethan 20 technical papers in journals and conferences, andhave been awarded a US patent and co-owned a copyrightpatent. The National Science Council, Taiwan, also hasawarded him a potential young researcher scholarship in2005. His current research interest is the bio-inspired com-puter vision and machine learning, including the fields ofparallel computing, soft computing, computational neuro-science, visual psychology, neurobiology, and cognitive sci-ence, etc. He is also interesting on the software/hardwaredevelopment for the bio-inspired computer vision and ma-chine learning.Antoine Veillard.. He received a M.Eng. degree fromthe Ecole Polytechique, Palaiseau, France in 2009 with adouble major in computer science. He is currently pursu-ing his Ph.D. degree in computer science at the NationalUniversity of Singapore in collaboration with IPAL (jointNUS/I2R/ASTAR/CNRS lab) in Singapore. His currentresearch interests are about computer vision, computa-tional geometry, computer algebra and machine learningin general.Nicolas Lom´enie. He received his M.Eng. degree in Telecom-munication from the French Institute for Telecommunica-tions, Paris, in 1997, M.Sc. degree in Artificial Intelli-gence, Pattern recognition and Applications from the Uni-versity of Paris 6, France the same year and Ph.D. degreein Computer Sciences from University Paris 5, France,in 2001. He is currently Associate Professor at Univer-sity Paris Descartes and research fellow at IPAL (jointNUS/I2R/ASTAR/CNRS lab) in Singapore. His researchinterests are about image analysis, pattern recognition andcomputer vision in general. He has worked so far on ob-ject recognition issues in VHR satellite images, medicalimage screening and stereoscopic point set analysis andfrom a more theoretical point of view has developed origi-nal morphological mesh operators . He has been responsi-ble for the image analysis and computer vision part of twoANR granted projects (REVES project - RIAM programand VISAVI project - RNTL program). For now, his cur-rent research topics include also knowledge-driven medical14