Artificial Intelligence 209 (2014) 11–28Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConcept drift detection via competence modelsNing Lu, Guangquan Zhang∗, Jie LuDecision Systems & e-Service Intelligence (DeSI) Lab, Centre for Quantum Computation & Intelligent Systems (QCIS), Faculty of Engineeringand Information Technology, University of Technology, Sydney, PO Box 123, Broadway, NSW 2007, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 1 November 2012Received in revised form 16 October 2013Accepted 9 January 2014Available online 10 January 2014Keywords:Concept driftCompetence modelCase-base maintenanceIncremental supervised learningClassificationDetecting changes of concepts, such as a change of customer preference for telecomservices, is very important in terms of prediction and decision applications in dynamicenvironments. In particular, for case-based reasoning systems, it is important to knowwhen and how concept drift can effectively assist decision makers to perform smartermaintenance operations at an appropriate time. This paper presents a novel method fordetecting concept drift in a case-based reasoning system. Rather than measuring the actualcase distribution, we introduce a new competence model that detects differences throughchanges in competence. Our competence-based concept detection method requires no priorknowledge of case distribution and provides statistical guarantees on the reliability of thechanges detected, as well as meaningful descriptions and quantification of these changes.This research concludes that changes in data distribution do reflect upon competence.Eight sets of experiments under three categories demonstrate that our method effectivelydetects concept drift and highlights drifting competence areas accurately. These resultsdirectly contribute to the research that tackles concept drift in case-based reasoning, andto competence model studies.© 2014 Elsevier B.V. All rights reserved.1. IntroductionLearning under concept drift poses an additional challenge to existing learning algorithms. Instead of considering all thepast training data, or making a stationary distribution assumption [1–3], an effective learner should be able to track thesechanges and quickly adapt to them [4]. Otherwise, as concept drifts, the induced pattern may not be relevant to the newdata [5,6], which may result in an increasing number of errors [7].The issue of concept drift refers to the change of distribution underlying the data [4,8]. More formally, the problem canbe framed as follows. If we denote the feature vector as x and the class label as y, then the data stream will be an infinitesequence of (x, y). If the concept drifts, it means the distribution of p(x, y) is changing between the current data chunk andthe yet-to-come data. If we decompose p(x, y) into the following two parts as p(x, y) = p(x) × p( y|x), we could say thereare two sources of concept drift: one is p(x), which evolves with time t, and can also be written as p(x|t), and the other isp( y|x), the conditional probability of feature x [2].Concept drift can be categorized into two basic types: virtual concept drift (or drift in data distribution), and real conceptdrift (or drift in decision concepts) [8]. Other kinds of concept drift have also been defined and discussed; for example, basedon the extent of drift, Stanley [9] mentioned three kinds of drift: sudden drift, moderate drift and slow drift. Based on classdistribution, Forman [10] classified concept drift into three categories: shifting class distribution – shifting the distributionamong categories but remaining stable within a given class; shifting sub-class distribution – shifting distribution sub-classes* Corresponding author.E-mail addresses: Ning.Lu@uts.edu.au (N. Lu), Guangquan.Zhang@uts.edu.au (G. Zhang), Jie.Lu@uts.edu.au (J. Lu).0004-3702/$ – see front matter © 2014 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2014.01.00112N. Lu et al. / Artificial Intelligence 209 (2014) 11–28within a category, but remaining stable within a given sub-class; and fickle concept drift – individual cases may take ondifferent ground truth labels at different times. Zhang et al. [2] defined and analyzed two kinds of concept drift in theirstudies: loose concept drifting, in which the genuine concepts remain relatively stable, whereas the vision of the drift ismainly caused by the biased observation of instances; and rigorous concept drifting, in which the genuine concepts undergocontinuous change, although such changes can worsen in the face of biased observation. Tsymbal et al. [11] discusseda special scenario of concept drift called local concept drift, by which they mean that the change of concept or datadistribution occurs only in some regions of the instance space.Based on the literature, many learning algorithms have been used as base models to handle concept drift. These includerule-based learning [4,8,12], decision trees and their incremental versions [5,13,14], info-fuzzy networks [15], clustering[16], support vector machines [17], and case-based reasoning (CBR) [11,18–20]. Among them, the CBR method has threereported advantages for handling the concept drift problem [21]. First, CBR performs well with disjointed concepts. Second,CBR, as a lazy learner, is easy to update. Third, CBR allows easy sharing of knowledge for particular types of problems,making it easier to maintain multiple distributed case-bases. Therefore, this study focuses on concept drift detection forCBR.According to a literature review [22], the first attempt to handle concept drift with the case-based technique was IB3[20], which discards noisy and outdated cases by monitoring each case’s accuracy and retrieval frequency. IB3 has beencriticized for being suitable only for gradual concept drift, and for its costly adaptation process [4]. The Locally WeightedForgetting (LWF) algorithm [23], which reduces the weights of the k-nearest neighbors of a new case and discards a case ifits weight falls below a threshold θ , was believed to be one of the best adaptive learning algorithms of its time. Klinkenberg[17] later showed in his experiments that instance weighting techniques tend to overfit the data and perform more poorlythan analogous instance selection techniques. Elwell and Polikar [24] presented an ensemble learning algorithm for non-stationary environments (Learn++.NSE) that assumes data are incrementally acquired in batches. For each incoming datasetDt , their algorithm trains an independent base classifier ht which is forced to emphasize misclassified data by adjusteddata weighting. Then, a weight is assigned to each base classifier based on its performance on the latest dataset. The finalclassification result is determined by weighted majority voting of all base classifiers. Recent research and development incase-base maintenance (CBM) provides a number of methods for updating all knowledge containers [25] of a CBR system.Among them, the competence-based CBM methods [19,26–30] and case-base mining technologies [31] have been empiri-cally shown to be capable of preserving the competency of a CBR system while removing noisy and redundant cases. Fewstudies, however, discussed when to trigger maintenance operations, which is also an important consideration, according toWilson and Leake’s CBM framework [32]. In addition, current methods are incapable of distinguishing between noisy casesand cases representing a new concept. Knowing whether concept drift happens could help to recognize obsolete cases thatconflict with current concepts and distinguish noise cases from novel cases. Moreover, developing a detection method thatis able to explain where and how concept drifts could facilitate further decision capabilities and be suitable for handlinglocal concept drift problems [11].Motivated by these issues, we propose a new method of concept drift detection for CBR systems, which compares thecase distributions of existing cases with newly available cases. The proposed method requires no prior knowledge about thecase distribution, but estimates the probability distribution and detects change via a competence model. Besides determiningwhether there is a concept drift, our method also quantifies and describes the detected change in terms of the competencemodel. To the best of our knowledge, no literature has reported any research that uses a competence model for conceptdrift detection purposes.Compared with other famous non-parametric methods, our detection method demonstrates the following advantages:1) it can be easily adopted in multi-dimensional data while maintaining similar results in one-dimensional data; 2) it ismore stable and achieves better results as shown in experiments, especially for small samples, because data can sharedistribution contributions among related competence areas, rather than splitting strictly by cutting edges, which makes itmore tolerable to sample bias; 3) it is able to describe the detected changes by highlighting some competence areas, whichis testified by a real world application.The novelty and main contribution of this paper lie in the endeavor to discover the difference between the inner natureof the competence group model and our proposed competence closure model. The detailed definitions and theorems affordother researchers an inside view of case-base competence, which has never been discussed in the literature. The theoreticalstudy provided in this paper also reveals the essential differences between the two competence models, and identifies threeimportant aspects of the competence closure model which the competence group model does not possess. Compared withour previous work on competence-based concept drift detection [33], which aims to investigate the impact of concept drifton case-base competence and assert to the possibility of detecting change via competence models, this paper additionallyconducts a tremendous number of experiments to thoroughly evaluate our proposed concept drift detection approach.This paper is organized as follows. Section 2 discusses related works. Section 3 proposes the new competence model anddiscusses the relationship between our model and current competence models. Section 4 presents the competence-basedchange detection method. Section 5 determines the critical region and provides a statistical guarantee for the proposeddetection method. Section 6 outlines the results of the experimental evaluation. Section 7 concludes this study, with adiscussion of future work.N. Lu et al. / Artificial Intelligence 209 (2014) 11–28132. Related workThis section formally presents the problem of concept drift detection (Section 2.1), and analyzes the pros and cons ofestablished literature with regard to concept drift detection (Section 2.2).2.1. Problem description: Concept drift detectionConcept drift detection can be formulated as follows. Suppose there is a CBR system listening to a data stream whereeach new observation is represented by ci = (xi, yi), where xi = (xi1 , xi2 , . . . , xin ) ∈ X is the feature vector, yi ∈ Y is thetarget label. As it is unrealistic to store the full history of the stream, we base our concept drift detection algorithm on atwo-sliding-window paradigm. Both windows contain a number of successive data points. We assume data points withineach window are independent random samples taken from two unknown, multi-dimensional, non-parametric distributionsare identical. The goal is toF and Fdesign a proper statistical test that is able to not only refuse H 0, if it is not true, but also highlight some local regions ofthe problem space where H0 does not hold and quantify the difference between F and F. When H0 is true, the probabilityare different when in fact they are not) should be, at most, α, whereof making an error (where the test says that F and Fα is a user-supplied parameter., respectively. We then define the null hypothesis H 0, which asserts that F and F(cid:4)(cid:4)(cid:4)(cid:4)A real world scenario for the application of our method would be spam filtering. As is well-known, one of the challengesin the spam filtering domain is to handle concept drift problems. In a case-based spam filtering system where emails arecontinuously classified, the problem arises of how we can benefit from the available feedback (new cases) and improvethe accuracy of the system. Treating the newest emails as an independent training set, e.g., emails received during thelast month, we can detect whether there is a concept drift between our existing case-base that is assumed to follow an. The correctunknown distribution Fmaintenance can accordingly be carried out when a drift has been reported., and the most recent emails, which are assumed to follow an unknown distribution F(cid:4)(cid:4)2.2. Change detection methodsThe most popular trigger technique for learner adaptivity is change detection, which is often implicitly related to asudden drift [34]. This is usually conducted by a statistical test that monitors the raw data distribution [35–38], the outputs(error) of learners [39–42], or the parameters of the learners [43].2.2.1. Detecting concept drift by data distributionWhen comparing two samples and determining whether these samples are drawn from the same distribution, theWilcoxon test [44] and the Kolmogorov–Smirnov test [45,46] are the most famous non-parametric methods. We do notassume that the data follows any particular parametric distribution (Section 2.1), since in real world applications, the datathat one typically encounters may not arise from any standard distribution, which makes non-parametric tests more practi-cal. However, the Wilcoxon test and the Kolmogorov–Smirnov test are initially designed for data with only one dimensionand cannot be easily extended to multi-dimensional data, which limits their scalability [36]. In this sense, we intentionallyomit methods that are designed for one-dimensional data [37,38].Kifer, Ben-David and Gehrke [35] proposed a modification of the Kolmogorov–Smirnov test that, in principle, comparesthe cumulative distribution functions of two samples with all possible orderings and takes the largest resulting test statistics.They employed a notation of A -distance as their test statistic, which in fact is a relaxation of the total variation distance.Their method reported several advantages, including being able to control the rate of false alarm (false positive) and misseddetection (false negative), and to describe and quantify the detected change. Some technical challenges remain, however,which need to be overcome before putting their work into practice, such as how to determine an interesting class of sets Ain higher dimensions.Dasu et al. [36] suggested an information-theoretic approach for change detection in data streams, which resorts to theKullback–Leibler divergence to measure the difference between two given distributions. They further estimated whether theirmeasurement is statistically significant through the Percentile Bootstrap method [47]. By partitioning the problem space usinga kdq-tree, their method also exhibited the capability of identifying the regions of greatest difference. However, the kdq-treedoes not guarantee that a partition will coincide with the real interesting concepts. This means that the detected regionsmay not be easily explained and understood.2.2.2. Detecting concept drift by learner outputsGama et al. [39] presented a Drift Detection Method (DDM) that traces and controls the online error-rate of the learningalgorithm. Treating the error of a set of examples as a random variable from Bernoulli trails, the probability for the numberof errors in a sample of n examples can be generalized as Binomial distribution. A significant increase in the error of thealgorithm suggests that the class distribution is changing. Their method declares a new concept if the error reaches thewarning level, and a new model is learnt when the drift level is exceeded. Although being independent of the learningalgorithm, their method is more suitable for rebuilding models rather than updating an existing model, since it assesses a14N. Lu et al. / Artificial Intelligence 209 (2014) 11–28learner through its overall error rate. In addition, their method is criticized for having difficulties when the change is slowlygradual [40].Baena-García et al. [40] proposed the Early Drift Detection Method (EDDM) to improve the detection in the presence ofgradual concept drift. Their EDDM, which is different to DDM, considers the distance between two consecutive erroneousclassifications instead of the error rate. They assume that a significant decrease in the distance suggests that the concept(cid:4)is changing. With the calculated average distance between two errors (pi ), they defined twothresholds α for a warning level and β for a drift level. When β (cid:2) (p(cid:4)max are stored(p(cid:4)i reaches its maximum, the examples will be stored in case of a possible change of context; whenvalue when p(cid:4)+2×si )max) < β, a new model is learnt using the examples stored since the warning level was triggered. The values for(cid:4)+2×s(p(cid:4)p‘EDDM performs well for gradual changes; however, it is not good at detecting drift in noisymax and sexamples’ [48].(cid:4)i ) and its standard deviation (s(cid:4)i )max) < α, where p(cid:4)(cid:4)max are reset.(cid:4)max and s+ 2 × s+2×s+2×s(p(cid:4)max(cid:4)max(cid:4)i(cid:4)i(cid:4)iYasumura, Kitani and Uehara [41] developed a sensitive detection method for concept drift that measures the numberof instances classified differently by two successive ensemble classifiers and determines whether the difference is signifi-cant. To suppress the influence caused by noise, they weighted the instances by taking the inverse weights generated bythe AdaBoost algorithm [49], but their method requires building a new classifier each time a new chunk arrives. This isapparently not suitable for all non-ensemble based algorithms to handle concept drift.Li et al. [42] also suggested tracking the error rate of classification in a chunked data stream. Considering the observederror rate of the latest data chunk ¯e f as a historical classification result, they fitted the estimated error rate of currentchunk ¯es into Hoeffding’s inequality to provide a statistical guarantee for the detection. Nevertheless, they still experiencedthe same problem as occurred in Gama’s work [39].2.2.3. Detecting concept drift by parametersTo the best of our knowledge, the only attempt to model concept drift as a change of parameters was made by Su, Shenand Xu [43]. In their framework, a dynamic probabilistic model is framed as p(Ck|xt) = f (wt) + v, where wt is an optimalparameter vector inferred continuously by the extended Kalman filter [50]; and v is a random variable that represents theuncertainty in the posterior distribution p(Ck|xt). Assuming the expectation of parameter wt−1 will be the same as wtwhen there is no concept drift, they model the concept drift as a change of parameter vector wt = wt−1 + s, where s isthe uncertainty caused by concept drift. For simplicity, they assume that s and v follow zero mean normal distributionswith isotropic covariance, s ∼ N(0, aI), v ∼ N(0, r), where I is the identity matrix and a is a single value which controls thevariance of the parameter vector w; r is the noise variance. In the implementation of their model, the degree of conceptdrift aI and the noise variance r need to be estimated from data.Their framework for modelling concept drift is creative and can be easily applied to many learning models, such asSupport Vector Machines (SVM), Regression or Artificial Neural Networks (ANN), however, it is not suitable for a knowledge-based learner like CBR. In addition, an optimal parameter vector may not be organized in a user-understandable way, whichprohibits concept drift interpretation.In this section, we have summarized existing concept drift detection methods into three categories. As shown in latersections, our proposed method will belong to the first category. There is also research on learning methods in outlier andanomaly detection [51,52]. The difference here is that outlier detection is concerned with finding exceptional observations,whereas concept drift detection deals with identifying a shift in the underlying data distribution [53].3. A new competence modelThis study aims to provide an innovative solution for concept drift detection, which compares the data distributionthrough competence measurement instead of the feature space.Competence is a measurement of how well a CBR system fulfills its goals. As CBR is a problem-solving methodology,competence is usually taken to be the proportion of problems at hand that can be solved successfully [54]. Because thecompetence measures the problem-solving capabilities of a CBR system, the probability distribution change of its casesshould also reflect upon its competence. This inspired our research to detect concept drift through a competence model. Thekey idea is to measure the distribution change of cases with regard to their competencies instead of their real distributions.Smyth and McKenna [26,28,55] proposed a series of models to measure the competence of a CBR system. The definitionsare shown as follows.Definition 1. (See [26].) For a case base CB = {c1, c2, . . . , cn}, given a case c ∈ CB, CoverageSet(c) = {cwhere Solves(c, c(cid:4)) means that c can be retrieved and adapted to solve c.(cid:4)(cid:4) ∈ CB: Solves(c, c(cid:4))},Definition 2. (See [26].) ReachibilitySet(c) = {c(cid:4) ∈ CB: Solves(c(cid:4), c)}.Definition 3. (See [55].) RelatedSet(c) = CoverageSet(c) ∪ ReachibilitySet(c).N. Lu et al. / Artificial Intelligence 209 (2014) 11–28Definition 4. (See [55].) For c1, c2 ∈ CB, SharedCoverage(c1, c2) iff(cid:2)(cid:3)RelatedSet(c1) ∩ RelatedSet(c2)(cid:8)= φ.15(1)Definition 5. (See [55].) Let G = {c1, c2, . . . , cm} ⊆ CB, we say that G has the property CompetenceGroup(G) iff for any ci ∈ G,there exists c j ∈ G − {ci} so that SharedCoverage(ci, c j) holds; and for any ck ∈ CB − G, there does not exist cl ∈ G, so thatSharedCoverage(ck, cl) holds.In their competence model, coverage of a case is the set of problems that this case can solve; conversely, reachability isthe set of all cases that can solve this case. A cluster of cases, called a competence group, is formed using their reachabilityand coverage sets. Based on these definitions, we put forward the following propositions:Proposition 1. For any G ⊆ CB if G has property CompetenceGroup(G) then |G| > 1.Proof. Obvious. (cid:2)This makes it difficult for the competence group model to measure and detect noise cases that are distinguished fromtheir close neighbors; thus noise cases tend to solve and be solved only by themselves.Proposition 2. Given G 1, G 2 ⊆ CB, if G 1 and G 2 are with property CompetenceGroup(G 1) and CompetenceGroup(G 2) respectively,then G 1 ∪ G 2 has property CompetenceGroup(G 1 ∪ G 2).Proof. For any ci ∈ G 1 ∪ G 2, ci ∈ G 1 or ci ∈ G 2. Without loss of generality, we suppose ci ∈ G 1. Since G 1 has propertyCompetenceGroup(G 1), there must exist ck ∈ G 1 ⊆ G 1 ∪ G 2 and ck (cid:8)= ci , so that SharedCoverage(ck, ci) holds. And for anyc j ∈ CB − {G 1 ∪ G 2} ⊆ CB − G 1, there does not exist cm ∈ G 1, so that SharedCoverage(c j, cm) holds. If there exists cm ∈ G 2 andc j ∈ CB − {G 1 ∪ G 2} ⊆ CB − G 2, we have a contradiction where G 2 has property CompetenceGroup(G 2). Therefore G 1 ∪ G 2 hasproperty CompetenceGroup(G 1 ∪ G 2). (cid:2)Proposition 3. Given G 1, G 2 ⊆ CB, G 1 ∩ G 2 (cid:8)= φ, if G 1 and G 2 are with property CompetenceGroup(G 1) and CompetenceGroup(G 2)respectively, then G 1 ∩ G 2 has property CompetenceGroup(G 1 ∩ G 2).Proof. For any ci ∈ G 1 ∩ G 2, ci ∈ G 1 and ci ∈ G 2. Since G 1 has property CompetenceGroup(G 1), then there must exist ck ∈ G 1and ck (cid:8)= ci , so that SharedCoverage(ck, ci) holds. If ck /∈ G 2, as ci ∈ G 2, we have a contradiction where G 2 has propertyCompetenceGroup(G 2). For any c j ∈ CB − G 1 ∩ G 2, c j ∈ CB − G 1 or c j ∈ CB − G 2. Without loss of generality, we suppose c j ∈CB − G 1. Since G 1 has property CompetenceGroup(G 1), then does not exist cm ∈ G 1 ∩ G 2 ⊆ G 1, so that SharedCoverage(c j, cm)holds. Therefore G 1 ∩ G 2 has property CompetenceGroup(G 1 ∩ G 2). (cid:2)Through Proposition 2 and Proposition 3, we prove that the competence group model cannot fulfill the claim that “com-petence groups individually make an independent contribution to global competence” [56]. To be precise, the competencegroup model provides a dichotomous partition of the case-base, G and CB − G, so that cases of each partition togethermake a collectively independent contribution to overall case-base competence. The competence group model is useful foranalyzing a competence independent sub-set of the case-base, but it is still inadequate and deficient. First, the competencegroup model does not guarantee a complete splitting of the case-base into several competence groups (inadequacy); in otherwords, CB − G is not necessarily a competence group, e.g., it contains a disjointed case that is not related to any case. Sec-ond, although each competence group may be further split to find more independent partitions, which may finally lead toseveral smaller independent competence groups, the competence group model does not guarantee that any two competencegroups are mutually independent (deficiency). As a result, the competence group model is inappropriate for analyzing thecompetence of the case-base, which may be composed of several disjointed partitions.We therefore propose two new competence models – Competence Closure and Related Closure [33], because current com-petence models are not sufficient for concept drift detection purposes, although, with existing competence models, one cantransfer the infinite case domain into a finite domain of related sets, which solves one difficulty of measuring the statisticaldistance between two case samples. We will demonstrate how our models are superior to existing models by the compar-isons shown later in this section. We intentionally omit other proposed competence models such as the LiabilitySet [19] andthe Complexity model [29,30], since they do not provide a measurement of what is solved in the problem space, but onlyhow well or how surely the problems are solved.Definition 6. (See [33].) For G = {c1, c2, . . . , cm} ⊆ CB, G (cid:8)= φ, we say that G has the property CompetenceClosure(G) if, andonly if, for any ci, c j ∈ G, ci (cid:8)= c j , there exist {ci1 , ci2 , . . . , cik} ⊆ G so that SharedCoverage(ci j , ci j+1 ) ( j = 0, . . . , k) holds, whereci = ci0 , c j = cik+1 , and for any ck ∈ CB − G, there does not exist cl ∈ G, so that SharedCoverage(ck, cl) holds.16N. Lu et al. / Artificial Intelligence 209 (2014) 11–28In other words a competence closure is a group of cases that can connect to one another through a series of Shared-Coverage relations, while a case not in this competence closure cannot have a SharedCoverage relation with cases in thiscompetence closure.Proposition 4. For G ∈ CB, |G| > 1, if G has property CompetenceClosure(G) then G has property CompetenceGroup(G).Proof. Obvious. (cid:2)Remark. In Proposition 4, the condition of |G| > 1 is essential. When |G| = 1, G is a single case set G = {c1}, which hasproperty CompetenceClosure(G) if there does not exist ck ∈ CB − G, so that SharedCoverage(c1, ck) holds. However, G cannothave property CompetenceGroup(G), since we cannot find an element other than c1 in G.Proposition 4 shows that the competence closure model is fully compatible with the competence group model becauseany competence closure with at least two cases also has the CompetenceGroup property, and is also a competence group.A single case point can never be modeled by the competence group model. Proposition 4 ensures that any method thatadopts the competence group model can also be fitted with the competence closure model.Theorem 1. For G 1, G 2, . . . , Gn ⊆ CB,(cid:4)ni=1 G i).CompetenceGroup(|G i| > 1,if G i has property CompetenceClosure(G i) then(cid:4)ni=1 G i has propertyProof. As for Proposition 2 and Proposition 4. (cid:2)Theorem 2. For G 1, G 2 ⊆ CB, G 1 (cid:8)= G 2, i f G 1 and G 2 have properties CompetenceClosure(G 1) and CompetenceClosure(G 2) thenG 1 ∩ G 2 = φ.Proof. As G 1 (cid:8)= G 2, without loss of generality, we suppose there exists c1 ∈ G 1 and c1 /∈ G 2.If G 1 ∩ G 2 (cid:8)= φ, then} ⊆ G 1, so thatlet c0 ∈ G 1 ∩ G 2 ⊂ G 1. Since G 1 has property CompetenceClosure(G 1), then there exists {ci1 , ci2 , . . . , cikSharedCoverage(ci j , ci j+1 ) ( j = 0, . . . , k) holds, where c0 = ci0 , c1 = cik+1 . As c1 ∈ G 1 and c1 /∈ G 2 and c0 ∈ G 2, there mustexist cim , cim+1 (0 (cid:2) m (cid:2) k), cim∈ G 1, so that SharedCoverage(cim , cim+1 ) holds. However, this conflictswith the condition of G 2, which has the property CompetenceClosure(G 2). (cid:2)∈ G 2, cim+1 /∈ G 2, cim+1Compared with the competence group model, our competence closure model does not permit sharing competence coveragebetween competence closures and truly makes an independent contribution to global competence. We claim that this is animportant characteristic because partitioning the space independently assists in the estimation of empirical probability, e.g.,P ( A) + P (B) = P ( A ∪ B), when A and B are mutually exclusive.Corollary 1. For G 1 ⊆ CB, if G 1 has property CompetenceClosure(G 1) then there does not exist G2 ⊆ CB, G 1 ⊂ G 2 so that G 2 hasproperty CompetenceClosure(G 2).Proof. As for Theorem 2. (cid:2)Corollary 1 proves the later claim that ‘a competence closure is a maximal set of cases, which are competence related’.Proposition 5. For G ⊆ CB, G 1 ⊆ G, G has property CompetenceGroup(G) and G 1 has property CompetenceClosure(G 1). Let G 2 =G − G 1, if G 2 (cid:8)= φ, then G 2 has property CompetenceGroup(G 2).Proof. For any ci ∈ G 2 = G − G 1, as G has property CompetenceGroup(G), there exists c j ∈ G, so that SharedCoverage(ci, c j)holds. As G = G 1 ∪ G 2 and G 1 ∩ G 2 = φ, we have c j ∈ G 1 or c j ∈ G 2. If c j ∈ G 1, this conflicts with G 1, which has propertyCompetenceClosure(G 1). Therefore, c j ∈ G 2, that is for any ci ∈ G 2, there exists c j ∈ G 2, so that SharedCoverage(ci, c j) holds.For any c j ∈ CB − G 2 = (CB − G) ∪ G 1, c j ∈ CB − G or c j ∈ G 1. If c j ∈ CB − G, since G has property CompetenceGroup(G),there does not exist cm ∈ G 2 ⊂ G, so that SharedCoverage(c j, cm) holds. Or, if c j ∈ G 1, there exists cm ∈ G 2 = G − G 1, so thatSharedCoverage(c j, cm) holds. This will conflict with G 1, which has property CompetenceClosure(G 1). (cid:2)Theorem 3. For G ⊆ CB, if G has property CompetenceGroup(G) and G does not have property CompetenceClosure(G), then thereexistsi=1 G i = G, so that G i has property CompetenceClosure(G i).(cid:4)nProof. For any ci ∈ G, since G has property CompetenceGroup(G), but does not have property CompetenceClosure(G), thenthere must exist c j ∈ G, so that we cannot find {ci1 , ci2 , . . . , cik} ⊆ G so that SharedCoverage(ci j , ci j+1 ) ( j = 0, . . . , k) holds,where ci = ci0 , c j = cik+1 . We continuously remove c j from G until we cannot find a c j , to construct a G 1 ⊂ G. Since G hasN. Lu et al. / Artificial Intelligence 209 (2014) 11–2817Fig. 1. Competence closure vs. competence group.property CompetenceGroup(G), there at least exist ci, ck ∈ G 1, so that SharedCoverage(ci, ck) holds, and we have G 1 (cid:8)= φ.Then, for any cm /∈ G 1, if there exists cl ∈ G 1, so that SharedCoverage(cm, cl) holds, then for any ci ∈ G 1 we can find{ci1 , ci2 , . . . , cik} ⊆ G 1 so that SharedCoverage(ci j , ci j+1 ) ( j = 0, . . . , k) holds where cm = ci0 , cl = ci1 , ci = cik+1 . Therefore,cm ∈ G 1, which conflicts with cm /∈ G 1. So, for any cm /∈ G 1, there does not exist cl ∈ G 1, so that SharedCoverage(cm, cl) holds.We then conclude G 1 ⊂ G, and G 1 has property CompetenceClosure(G 1). Let Ghasi=1 G i , m = 1, 2, . . . , n − 1,property CompetenceGroup(Guntil Gm+1 = G −(cid:4) (cid:8)= φ. We can construct Gm+1 continuously from Gi=1 G i , and Gm+1 has property CompetenceClosure(Gm+1). (cid:2)(cid:4) = G − G 1, according to Proposition 5, G(cid:4) = G −(cid:4)) if G(cid:4)(cid:4)mm(cid:4)As the entire case-base can be viewed as a competence group, Theorem 3 certifies that any case-base can be split into aset of competence closures.To sum up, the competence closure model outweighs the competence group model because of its features, as follows:First, the competence closure model is able to uniquely model the entire case-base. Considering the whole case-base as acompetence group, according to Theorem 3, the case-base can be modeled into a set of competence closures. A suspicious case,which differs from its neighbors and solves nothing and can only be solved by itself, cannot be modeled by the competencegroup model. This is important because suspicious cases are more likely to behave like noisy or novel cases [57].Second, the competence closure model provides a smaller granularity than the competence group model (Theorem 1 andTheorem 3). This is essential for competence-guided case discovery [56], in which the competence holes are believed toexist between neighbor competence groups.Third, competence closure is the maximum set concerning a series of related problems (Corollary 1) and two competenceclosures are said to be independent in terms of the related set (Theorem 2). This facilitates the narrowing of the analysiswithin any interesting sub-problem space represented by one or more competence closures.We also show the differences between our competence closure model and the existing competence group model in Fig. 1.It can be seen that the competence closure is defined as the maximal set of cases linked through their related sets, where acompetence group is the union of competence closures or any competence closure with more than one case.In Smyth and McKenna’s [26,28,55] competence model, the competence contributed by a certain case is modeled byits coverage set (Definition 1). Meanwhile, the existence of a case could also be a support for those cases that solve it: inother words, its reachability set (Definition 2). The related set provides a measurement of related competence for each singlecase. Intuitively, the related set highlights a set of interesting target problems related to a case. However, since the relatedset overlaps, the related set of a certain case may not be the only measurement of problem space that relates to this case.In this sense, we propose another competence model – related closure (Definition 7) to represent the problem space withrelation to a certain case or a group of cases, in terms of related sets.Definition 7. (See [33].) For c ∈ CB, denote the RelatedSet(c) with regard to CB as RCB(c), and we define the Related Closureof c with regard to CB as(cid:11)CB(c) =(cid:5)(cid:6)RCB(ci): ∀ci ∈ CB, ∃RCB(ci) s.t. c ∈ RCB(ci)For a group of cases S ⊆ CB, we define theRelated Closure of S with regard to CB as(cid:7)(cid:11)CB(S) =(cid:11)CB(c)(2)(3)c∈SExample 1. Let CB = {c1, c2, c3, c4}, RCB(c1) = {c1, c2}, RCB(c2) = {c1, c2, c3, c4}, RCB(c3) = RCB(c4) = {c2, c3, c4}. The re-lated closure of c3 is the set of all related sets, with regard to CB, which contain the case c3. That is (cid:11)CB(c3) ={{c1, c2, c3, c4}, {c2, c3, c4}}.We have now proposed a new competence model. We have not only discussed in more detail the properties of Smythand McKenna’s [26,28,55] competence model, but we have also shown, theoretically, how our competence model is more18N. Lu et al. / Artificial Intelligence 209 (2014) 11–28suitable for change detection purposes. In the following section, we introduce a metric that measures the distance betweencase chunks, and based on this metric, we develop our change detection method.4. Competence-base empirical distanceWhen mining concept drifting data, a common assumption is that the up-to-date data chunk and the yet-to-come datachunk share identical, or considerably close distributions [1]. This means that the newly available cases represent the con-cept that we may be interested in, in the future. In CBR, considering cases in the existing case base and the newly availablecases as two samples drawn from two probability distributions, we are able to identify whether there is a concept drift bydetecting a possible distribution change between the existing case base and the newly available case chunk. This sectionproposes a weighted approach to measure the difference between case chunks that weight the related sets differently, ac-cording to the distribution of cases. The competence-based empirical distance between two case chunks is defined throughthose weights.Given a case base CB, and two case sample sets S1, S2 ⊆ CB, we obtain two related closures, (cid:11)CB(S1) and (cid:11)CB(S2). In-tuitively, we measure the difference between (cid:11)CB(S1) and (cid:11)CB(S2) as the distance between S1 and S2. However, it willonly represent the distance between the competencies covered by these two samples. The relative distribution discrepancywithin the competence is missing. This introduces a problem when we compare two case samples that solve similar prob-lems, but with dramatically different distributions. To address this problem, we assign a weight for each element in (cid:11)CB(S1)and (cid:11)CB(S2) to represent the relative density of the cases distributed over their related closures.Definition 8. Let (cid:11)CB(S) = {rCBn (S)}, (cid:11)CBi (S) = {rCBi (S)}, we define the density of rCBi (S) with regard to S as∗w(cid:8)(cid:9)rCBi (S)= 1|S|×1 (S), rCB(cid:10)|(cid:11)CB2 (S), . . . , rCBi (S) ∩ (cid:11)CB(c j)||(cid:11)CB(c j)|c j ∈S(4)Example 2. Let S = {c1, c4} be a case sample set taken from the case base in Example 1. Therelated closure of S is the setof all related sets that contain at least one element in S. We have(cid:11)CB(c1) =(cid:5){c1, c2}, {c1, c2, c3, c4}(cid:6)and (cid:11)CB(c4) =(cid:5){c2, c3, c4}, {c1, c2, c3, c4}(cid:6)thus (cid:11)CB(S) = {{c1, c2}, {c2, c3, c4}, {c1, c2, c3, c4}}. Let (cid:11)CB(cid:11)(cid:8)(cid:11)(cid:11)(cid:11) +(cid:11)(cid:11)CB(cid:11)(cid:11)CB(c1)(cid:11)(cid:11)/1 (S) ∩ (cid:11)CB(c1)1 (S) = {c1, c2}, the weight of {c1, c2} with regard to S is(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)CB(c4)(cid:11)(cid:11)/1 (S) ∩ (cid:11)CB(c4)= 1/2 ×{c1, c2}(cid:11)(cid:11)(cid:11)CB= 1/4w(cid:9)(cid:8)(cid:9)∗Theorem 4. The sum of the densities of all elements in (cid:11)CB(S) equals 1.|(cid:11)CB(S)|(cid:10)i=1∗w(cid:8)(cid:9)rCBi (S)= 1Proof. Substitute Eq. (4) into Eq. (5), we have the left side as:×1|S||(cid:11)CB(S)|(cid:10)(cid:10)i=1c j ∈S|(cid:11)CBi (S) ∩ (cid:11)CB(c j)||(cid:11)CB(c j)|= 1|S|×(cid:10)|(cid:11)CB(S)|(cid:10)c j ∈Si=1|(cid:11)CBi (S) ∩ (cid:11)CB(c j)|(cid:11)CB(c j)(5)(6)As (cid:11)CBi (S) ∩ (cid:11)CBj (S) = φ (i (cid:8)= j), (cid:11)CB(S) =(cid:11)CB(c j) ⊆ (cid:11)CB(S), therefore we have:(cid:4)|(cid:11)CB(S)|i=1(cid:11)CBi (S) and according to the definition of related closure (Definition 4),|(cid:11)CB(S)|(cid:10)i=1|(cid:11)CBi (S) ∩ (cid:11)CB(c j)||(cid:11)CB(c j)|=|(cid:11)CB(S) ∩ (cid:11)CB(c j)||(cid:11)CB(c j)|= 1Substitute Eq. (7) into Eq. (6); the left side equals the right side. (cid:2)(7)From a practical point of view, this means that all cases in sample S are equally important with regard to the contributionto the density of elements in (cid:11)CB(S), no matter what their related sets are.The density weights each related set in a related closure by the degree to which the sample cases are distributed. Wethen define the competence-based empirical weight of a case sample with regard to a certain interesting sub-problem space(Definition 9).N. Lu et al. / Artificial Intelligence 209 (2014) 11–2819Definition 9. Given a case base CB, and a case sample set S ⊆ CB, denote the power set of (cid:11)CB(CB) as ℘ ((cid:11)CB(CB)). Consid-ering ℘ ((cid:11)CB(CB)) as the measurable space A, for A ∈ A, we define thecompetence-based empirical weight of S with regardto A over CB asS CB( A) =(cid:12)| A∩(cid:11)CB(S)|i=1, rCBw∗(rCBi (S))i (S)∈ A∩(cid:11)CB(S)(cid:12)|(cid:11)CB(S)|i=1w∗(rCBi (S))| A∩(cid:11)CB(S)|(cid:10)=∗w(cid:8)(cid:9)rCBi (S)i=1i (S)∈ A∩(cid:11)CB(S)rCB(8)For any case sample set S, the competence-based empirical weight provides a reference to the degree of case distributionon a competence area represented by A – a sub-set of (cid:11)CB(CB). The higher the weight is, the larger is the proportion ofcases in S that support the selected competence area.Definition 10. For two case sample sets S1, S2 ⊆ CB, we define the competence-based empirical distance between S 1 and S2asdCB(S1, S2) = 2 × supA∈A(cid:11)(cid:11)S CB1 ( A) − S CB(cid:11)(cid:11)2 ( A)Proposition 6. Given a case base of finite size CB and a case sample set S ⊆ CB, (cid:11)CB(S) is a finite set.Proof. Since each case c in CB corresponds to a related set – RCB(c) (whereas several cases may correspond to the samerelated set) the size of (cid:11)CB(CB) must be less, or equal to, the size of the case base. Again, according to the definition ofrelated closure (Definition 7), for any case sample set S ⊆ CB, (cid:11)CB(S) ⊆ (cid:11)CB(CB), we have |(cid:11)CB(S)| (cid:2) |(cid:11)CB(CB)| (cid:2) |CB|. As thesize of the case base is finite, (cid:11)CB(S) must be a finite set. (cid:2)Remark. This ensures that a solution A ∈ A exists in the defined competence-based empirical distance, since A is also a finitea set.Theorem 5. Given a case base of finite size CB, the competence-based empirical distance in the case sample S ⊆ CB, is a normalizedquasi-distance function dCB : S × S → [0, 1], which satisfies the following conditions for all S 1, S2, S3 ⊆ CB.1. 0 (cid:2) dCB(S1, S2) (cid:2) 12. dCB(S1, S2) = 0 if S1 = S23. dCB(S1, S2) = dCB(S2, S1)4. dCB(S1, S3) (cid:2) dCB(S1, S2) + dCB(S2, S3).Proof. Condition 1, 2 and 3 are obvious. For condition 4, assume there exists A1 ∈ A where, for any Ai ∈ A , we have(10)3 ( A1)| (the existence of A1 can be proven through Proposition 6). Again, we have(cid:11)(cid:11)S CB1 ( A1) − S CB(cid:11)(cid:11) (cid:3)3 ( A1)(cid:11)(cid:11)3 ( Ai)(cid:11)(cid:11)S CB1 ( Ai) − S CB1 ( A1) − S CBWe say dCB(S1, S3) = 2 × |S CBA2, A3 ∈ A , that for any Ai ∈ A(cid:11)(cid:11)S CB(cid:11)(cid:11)S CB1 ( A2) − S CB2 ( A3) − S CBClearly we have dCB(S1, S2) (cid:3) 2 × |S CBdCB(S1, S2) = 2 ×dCB(S2, S3) = 2 ×(cid:11)(cid:11) (cid:3) 2 ×2 ( A2)(cid:11)(cid:11) (cid:3) 2 ×3 ( A3)1 ( A1) − S CB(cid:11)(cid:11)S CB(cid:11)(cid:11)S CB1 ( Ai) − S CB2 ( Ai) − S CB(cid:11)(cid:11)2 ( Ai)(cid:11)(cid:11)3 ( Ai)dCB(S1, S2) + dCB(S2, S3)(cid:8)(cid:11)(cid:11)S CB1 ( A1) − S CB(cid:11)(cid:11)S CB1 ( A1) − S CB(cid:3) 2 ×(cid:3) 2 ×(cid:11)(cid:11)(cid:11) +(cid:11)S CB2 ( A1)(cid:11)(cid:11) = dCB(S1, S3)3 ( A1)(cid:11)(cid:9)(cid:11)2 ( A1) − S CB3 ( A1)(cid:2)(9)(11)(12)(13)2 ( A1)| and dCB(S2, S3) (cid:3) 2 × |S CB2 ( A1) − S CB3 ( A1)|, so we haveNote that S1 = S2 is only a sufficient condition for dCB(S1, S2) = 0, since the competence-based empirical distance comparesthe distance between two case sets through their competencies, rather than their real distribution. Any pair of case sets thatexhibit identical distribution with regard to the competence will result in a distance of zero. This can be easily proven byconstructing sample sets with paired cases, which are different but of the same related set.We say that there is a concept drift when the competence-based empirical distance between the current case base andthe newly available case chunk is greater than ε. Similar to Kifer, Ben-David and Gehrke’s work [35], the set A depicts alocal competence area, in which the largest distribution discrepancy lies between two samples, which helps to explain thedetected change. The determination of ε and the statistical guarantee of the detection method will be discussed in Section 5.20N. Lu et al. / Artificial Intelligence 209 (2014) 11–285. Statistical guaranteeThe choice of distance function used to determine change is only one aspect of the concept drift detection method;another is to provide statistical significance of the detected change. Given an observation of two case samples, we achievethis by answering the question “How likely is it that the observation could have been obtained under the null hypothesisH0 (in our case, that no concept drift occurs)?”. The smaller this value (the so-called “p-value”), the stronger the evidenceagainst H0.This work resorts to the two-sample non-parametric permutation test method [47] to provide a statistical guarantee for thedetected change. The permutation test is easy to implement and free of mathematical assumptions, and is commonly usedwhen the theoretical distribution of the test statistic is complicated or unknown, which suits our situation.5.1. Permutation testRecall the problem description in Section 2.1, where we have two case sets CB and CB, representing two unknowndistributions F CB and F CB(cid:4) , respectively. We would like to perform a hypothesis test and determine whether F CB and F CB(cid:4)are identical. In Section 4, we defined a notation of distance as test statistic, and for simplicity we denote the test statisticas ˆθ .Once an observation ˆθ is made (in our case, the calculation of the distance between the current case base and theincoming new case samples), the achieved significance level (ASL), or the p-value of the test, is defined as the probability ofobserving at least as extreme as the observed ˆθ , assuming that the null hypothesis is true,(cid:4)ASL = P H0(cid:5)ˆθ∗ (cid:3) ˆθ(cid:6)has the null hypothesis distribution, the distri-(14)where the quantity ˆθ is fixed at its observed value; the random variable ˆθ ∗bution of ˆθ if H0 is true [47].The permutation test is a clever way of approximating an ASL for the null hypothesis F CB = F CB(cid:4) , which works as follows:Given a case base of n cases and an incoming new case sample of m cases, under the null hypothesis, any observed casecould have come equally well from either of the case sets. We therefore combine all the m + n cases, then take a sampleof size n without replacement to represent the case base; the remaining m cases constitute the incoming case sample. Wecompute the test statistic for each permutation and repeat the process a large number of times (N). Finally, we estimate theASL of the permutation test through the Monte Carlo approach [58].ASLperm ≈ AˆSLperm = #{ ˆθ ∗ (cid:3) ˆθ}N(15)Once we fix a desired significance level α, we compare α with the permutation ASL. We say that there is a concept driftwhen ASLperm < α. For example, when choosing α to be 0.05, we reject the null hypothesis at a 5% level, correspondingrespectively to a 5% chance of rejecting the null hypothesis when it is true (false positive). In fact, any permutation test thatrelies on sampling rather than full enumeration will yield an actual significance level larger than α, due to the Monte Carloerror [59,60].5.2. Permutation sample sizeIn real world applications, obtaining an exact ASL of a permutation test via full enumeration quickly becomes unfeasibleas the permutation sample space increases. This raises the question of how many permutation replications (N) are required.As illustrated by Efron and Tibshirani [47] and Opdyke [60], N × ˆA follows a binomial distribution of Bi(N, A), whereˆA = AˆSLperm and A = ASLperm. Using the normal approximation to Bi(N, A), the 95% confidence interval of ˆA is approximated2 is the standard deviation of ˆA. If we do not want the Monte Carlo error toby A ± (1.96 × σ ), where σ = [ A(1 − A)/N] 1affect our estimation by more than 30% (σ / A (cid:2) 0.3), that gives N (cid:3) 100 when A = 0.1. The precision can be improved withlarger N (Fig. 2).6. Experimental evaluationOur evaluation of the proposed competence-based concept drift detection method consists of three sections, througheight experiments; all source code can be downloaded from http://decide.it.uts.edu.au/Philip/index.php:1. We evaluate the competence-based empirical distance and compare it to the test statistics of the two-sampleKolmogorov–Smirnov test (Experiments 1–3).2. We compare our change detection method to Dasu et al. [36]. We choose synthetic datasets for the first two parts, sincewe need to know the change in the generated distribution in advance. In addition, with simulated data, we are ableto control the change more easily and to see how our detection method performs against different types of changes(Experiments 4–7).N. Lu et al. / Artificial Intelligence 209 (2014) 11–2821Fig. 2. Monte Carlo error vs. permutation replication size.Fig. 3. Competence-based empirical distance between normal distributed data that varies μ.Fig. 4. Cumulated competence-based empirical distance between normal data that varies μ.3. We perform a case-base editing method based on the results of our detection and compare our results on two realdatasets against those from the original author [18], as our detection method aims not only to identify a change, butalso to describe it (Experiment 8).6.1. Evaluating the competence-based empirical distanceIn Section 4, we proposed a competence-based empirical distance to measure the difference between one distributionand another. To establish how it varies according to the change between generated distributions, we ran three experimentswith generated artificial datasets following 1D normal distributions and compared the results with the test statistics of thetwo-sample Kolmogorov–Smirnov test. Two cases are considered to be able to mutually solve each other, if their Euclideandistance is smaller than a threshold dε . All results are calculated as the mean of 100 independent tests.Experiment 1 (Varying the mean μ). In this experiment, we compared distances between data samples, both of size 100,drawn from 11 normal distributions of fixed standard deviation σ = 0.2, but with a moving mean value μ = 0.2 + 0.06 ×(i − 1) for the ith distribution, i = 1, 2, . . . , 11. When t = 2 × i − 1 we compared two samples, both drawn from the ithdistribution; when t = 2 × i we compared two samples drawn from the ith and (i + 1)st distribution. Fig. 3 shows how thecompetence-based empirical distance changes as the distributions vary. Since the extent of the difference depends only onthe mean values, we find a similar height on all peaks for each series (Fig. 3). We also tried fixing one data sample whilemoving the other, in order to show how the distance increases as the difference between the means increases (Fig. 4). Itis worth noting that the test statistics of the two sample K-S test seems to be more sensitive to the change, as the marginbetween the peaks and valleys is larger (Fig. 3), and it also increases faster as the difference accumulates (Fig. 4). Thisis because our competence-based empirical distance eliminates any change that happened within a problem space where22N. Lu et al. / Artificial Intelligence 209 (2014) 11–28Fig. 5. Competence-based empirical distance between normal data of difference size.Fig. 6. Competence-based empirical distance between normal distributed data that varies σ .cases are considered to be similar in CBR. In return, our detection method is more reliable for small samples, as shown inExperiment 2.Experiment 2 (Varying the sample size). In this experiment, we compared distances between two data samples drawn fromN(0.2, 0.2) and N(0.44, 0.2), respectively. We increased the sample size from 100 to 1000. As shown in Fig. 5, the teststatistics of the two sample K-S test shrinks as the sample size increases, while our competence-based empirical distancesremain relatively steady. Also, it can be seen that, when the sample size is larger than 800, the distance remains the samefor all series.Experiment 3 (Varying σ ). In this experiment, we fixed the mean at μ = 0.5, but varied the standard deviation σ = 0.1 +0.02 × (i − 1) for the ith distribution, i = 1, 2, . . . , 11. Again, when t = 2 × i − 1 we compared two samples drawn from theith distribution; when t = 2 × i we compared two samples drawn from the ith and (i + 1)st distribution. The sample sizewas set at 1000. As shown in Fig. 6, the competence-based empirical distances have a larger margin between peaks andvalleys, which means that our method is more sensitive to smaller changes than the K-S test, but the amount of changeshrinks as σ increases compared with Experiment 1. Intuitively, this is because the distribution becomes less concentrated,so the relative distance is smaller.6.2. Evaluating the competence-based change detection methodIn the above experiments, we have demonstrated how the competence-based empirical distance fluctuates as the un-derlying distribution changes. In order to determine whether a given measurement is statistically sufficiently significant toqualify as a concept drift, we plug in the permutation test to estimate the ASL, as described in Section 5. Given a desiredsignificance level α, we say that there is a concept drift when ASLperm < α. In the following experiment, we aim to compareour change detection results with Dasu et al. [36]. There are two main reasons for us to choose their method for compar-ison. First, we both resort to a similar approach for concept drift detection: that is, adopting a distance metric and thenperforming a hypothesis test. Second, compared with other error-rate based detection methods, our methods do not dependon a classifier and, therefore, have a broader application scope.To make a fair comparison with Dasu et al. [36], we set up the same experimental environments, which includes thefollowing three features: strategy, data source and parameter. For strategy, we also adopt the fix-sliding windows model:that is, keeping a fixed reference window if no concept drift is reported, or else moving both windows. Also, we say thata detection is late when it is reported after moving two or more windows, since the actual window contains the change.For the data source, we implement the same artificial datasets used in Dasu et al. [36]. The detailed information of eachartificial data source is described in the experiment setup section. We keep all parameters the same for the permutationtest when comparing, which includes the desired significance level α = 1% and the permutation size of N = 500. We do notN. Lu et al. / Artificial Intelligence 209 (2014) 11–2823Table 1Change detection results on different 2D normal data streams. The detection results of Dasu et al. [36] are shown in brackets.StreamM(0.05)M(0.02)C(0.1)C(0.15)C(0.15)C(0.2)Window size (n)10,00010,00010,00010,00050005000Detected97 (97)86 (70)56 (43)91 (83)84 (68)96 (93)Late0 (1)6 (20)8 (18)2 (10)7 (14)1 (5)False4 (4)5 (4)4 (3)5 (4)11 (17)10 (15)Table 2Change detection results on different 2D Poisson distributed data streams. The detection results of Dasu et al. [36] are shown in brackets.Step size ((cid:9))Window size (n)0.10.210,00010,000Detected88 (67)99 (98)Late2 (17)0 (1)False4 (1)5 (5)Missed2 (1)7 (9)35 (38)6 (6)8 (17)2 (1)Missed9 (15)0 (0)evaluate changed parameters because their effects have already been shown and proved in Section 5. For all experimentsin this section, the parameter dε , which is used to construct the competence model, is chosen empirically to have a similarpartition size to the kdq-tree as in Dasu et al. [36]. A more practical solution for constructing competence models in realworld applications is described and used in Section 6.3.Experiment 4 (Normal distributions). This experiment implements two artificial datasets used in Dasu et al. [36]: the M((cid:9))stream – varying the mean μ1 and μ2 independently in [0.2, 0.8] with a step size chosen randomly in [−(cid:9), −(cid:9)/2] ∪[(cid:9)/2, (cid:9)] and the C((cid:9)) stream – varying ρ, which starts at 0 and then randomly walks within [−1, 1], with step sizechosen randomly in [−(cid:9), −(cid:9)/2] ∪ [(cid:9)/2, (cid:9)]. Each stream consists of 5,000,000 two-dimensional normal distributed points,which are further divided into groups of 50,000, giving 99 changes in total. To construct the competence model, dε is set to0.05.From the results shown in Table 1, we can see that our method out-performs Dasu et al. [36]. Both methods achievesimilar results for the M(0.05) and C(0.2) stream, however ours performs significantly better for the other streams, whichmeans our method is more sensitive to smaller changes, compared to Dasu et al. [36]. As we expected, the overall detectionaccuracy increases when the window size increases. Our method results in a dramatic decrease in the number of latedetections as the window size increases. This is probably because our proposed competence-based empirical distance allowsdifferent, but related cases to share their distribution contributions with regard to our competence model, rather than beingcut exclusively by regions, thus improving its robustness to smaller samples. The number of false detections is almost thesame as Dasu et al. [36]. In fact, the false detection rate largely depends on the desired significance level α due to thenature of the permutation test. Our detection method also depends on the appropriateness of the competence model. Inreal world scenarios, one possible way of constructing the competence model is to use the leave-one-out strategy (shownin Section 6.3), or resort to other available information such as reasoning history or experts.Experiment 5 (Poisson distributions). In this experiment, we compare the detection results on 2D (discrete) Poisson distribu-tions, with data streams generated according to ( X, Y ) ∼ Poisson(500(1 − ρ), 500(1 − ρ), 500ρ), where ρ starts at 0.5 andthen performs a random walk between 0 and 1 with step size (cid:9) = 0.2, 0.1, in the same manner as in Experiment 4. Wegenerated the bivariate Poisson using Trivariate Reduction [61]. To construct the competence model, dε is set to 10.Experiment 6 (Higher dimensions). To test the scalability and performance of our scheme in high dimensions, we alsotake the C(0.2) stream and extend it to d-dimensional streams by adding dimensions in which the data distributions (alsoGaussian with σ = 0.2) do not change. We keep the same standard deviation of all added dimensions as the C streams inorder to maintain the marginal distribution of all dimensions, so that the overall distance between cases contributed byeach dimension is equally important. In fact, since our competence model depends on the distance between cases, largemarginal stable distributions will dominate calculation of the distance between cases and cause failure of our detectionmethod. However, this issue can be easily solved by adopting a weighted distance calculation. To construct the competencemodel, dε is set to 0.15 for 4-dimensional, 0.3 for 6-dimensional and 0.5 for 10-dimensional; recall that dε is chosen to havea similar partition size as the kdq-tree.The experimental results for different dimensions are listed in Table 3. As we expected, with more stationary dimensionsadded, it becomes harder to detect the real changes. However, our detection method preserves much of its power as thenumber of dimensions increase. This again is another proof that our detection method is more sensitive to smaller changes.Also, we have less late detection because of the robustness of the smaller sample of our method.24N. Lu et al. / Artificial Intelligence 209 (2014) 11–28Table 3Change detection results on d-dimensional streams. The detection results of Dasu et al. [36] are shown in brackets.D4610Window size (n)10,00010,00010,000Detected93 (89)91 (84)75 (65)Late0 (1)5 (10)5 (12)False4 (7)4( 8)5 (6)Missed6 (9)3 (5)21 (22)Table 4Running time with different dimensions and window sizes.Dimension (d)Window size (n)Competence (s)kdq-tree (s)6810102010,00010,00010,00020,00050,0000.0210.0250.0250.0420.1170.0210.0290.0350.0370.069Experiment 7 (Efficiency). The nature of our detection method consists of three parts: space partition, calculating test statis-tics and determining the critical region. We, and Dasu et al. [36] are able to compute the test statistics directly, and we bothadopt the permutation test to determine critical region. We only compare the cost of the first part, which is maintenance ofthe competence model in our case vs. updating the kdq-tree in Dasu’s case. We use the standard approach for updating thecompetence model for case addition [62]. These running times were obtained from our unoptimized C# code on a laptopPC with a 2.3 GHz Intel i5 processor and 4 GB memory.The efficiency of the competence-based concept drift detection algorithm is little affected by the number of dimensions,but directly related to the window size. While the window size increases, the time grows linearly. In fact, the maintenancecost was proven to be estimated by O (n), because each time a new case is added to the current case-base, it must becompared to every case in this case-base to determine which cases can solve it and which cases it can solve [62]. To thecontrary, the updating cost of the kdq-tree is little affected by the window size, but exhibits a linear relationship with thedimension. This is because the updating cost of the kdq-tree has been proven to be O (d log 1δ ) [36].6.3. Evaluating the description of the competence-based change detection methodIn order to show how our method will help in real world scenarios, we apply our detection method to two real worldconcept drift datasets that are available from http://decide.it.uts.edu.au/Philip/index.php. Each dataset consists of more than10,000 emails collected over a period of approximately one year by an individual. A training set of 1000 cases, including thelast 500 spam emails and 500 legitimate emails, is set up for each dataset. The remaining data is used to test our algorithmover time. We perform real-time change detection for every incoming new email, and trigger maintenance operations in thecompetence areas that are identified to be undergoing changes. For more detailed information of the concept drift datasets,please refer to Section 5 of Delany et al. [18].Experiment 8. We compare our results with the original author of this dataset [18] and a recent work on concept drift [24].In order to compare fairly with Delany et al. [18], we choose the same classifier, that is the k-nearest neighbor with k = 3using unanimous voting. Again, we also weight all features equally and the similarity between two cases is measured bythe proportion of matched features. The related set is constructed using leave-one-out classification. That is, any case ci isconsidered to be solved by the actually retrieved cases that successfully solve ci bounded by the closest case c j that failsto solve to ci . For Learn++.NSE [24], we build a new case-base every month using the same criteria described above as thebase classifier, and choose the same parameter values that are suggested in their paper, i.e., a = 0.5, b = 10. We are awarethat it may not be fair to choose the same parameter values for a different dataset; however, a method for determiningthese parameters was not provided and these values are reported to work well on all the scenarios attempted.Our spam filtering algorithm starts with the provided training set. After each classification, we perform the competence-based change detection algorithm. A maintenance operation is triggered when a concept drift is detected; therefore, thesystem can adapt quickly to the new concept and tune for future detections. Our tuning mechanism is a hybrid of PECS [23]and BBNR [19], which is specifically adopted to enhance PECS. On one hand, when there is no concept drift, BBNR preventsa noisy case from inclusion; on the other hand, when there is indeed concept drift, from all the areas that are reported tobe changing, which in fact are measured by the set A (Definition 10), we identify and remove cases that conflict with thenew case. The idea behind this tuning strategy is that, when there is no concept drift in the data stream, old cases can helpto identify noise and improve accuracy; however, when there is indeed concept drift, new instances are more representativeof the novel concept, while old cases that conflict may not help.N. Lu et al. / Artificial Intelligence 209 (2014) 11–2825Fig. 7. Results of concept drift dataset 1.As the CBE method described in Delany et al. [18] considers both competence enhancement and competence preserva-tion, we also plugin a redundancy removal operation, which removes cases uniformly in the competence space and ensuresall removed cases can still be correctly solved. We keep 1500 cases for dataset 1 and 2500 cases for dataset 2. This limitis determined according to Delany et al. [18], which reports that ‘the resulting size of the case-base after all the data hasbeen applied (i.e. after 10 months for dataset 1 and 12 months for dataset 2) is 1512 and 2518, respectively’. We do notincorporate any redundancy removal operation for Learn++.NSE, because: 1) we intend to retain their original methods;2) each base classifier in Learn++.NSE is relatively small, which meets the speed and storage requirements.Since error rate is not a good metric for skewed datasets, the most common performance metrics [63] for spam filteringN , and the LegitimateTN+FN , where FP means legitimate emails that are incorrectly classified as spam; FN meansare used here to evaluate performance, where the Legitimate Recall (LR) is defined as LR = TNPrecision (LP) is defined as LP = TNspam emails that are incorrectly classified as legitimate.= TNTN+FPThe classification results of each month for both datasets are shown, respectively, in Fig. 7 and Fig. 8.26N. Lu et al. / Artificial Intelligence 209 (2014) 11–28Fig. 8. Results of concept drift dataset 2.These results clearly demonstrate that our strategy effectively improved the results on both LR and LP for both datasets.Our approach mainly improves LP. This is because we are using k-NN with unanimous voting. As a result, mistakenlyretaining one or two noisy spam emails in the same competence area will not affect the classification result for a legitimateemail; however, mistakenly retaining a legitimate email will dramatically affect the classification result for a spam email.Compared with CBE, the improvement on LP is statistically significant for both datasets, by paired t-test, at 94% confidencelevel. This shows that our method can accurately catch the concept drift and perform well on targeted reactions. We alsoobserved that Learn++.NSE was the worst on most months, which was principally for the following two reasons: 1. Theensemble approach adopted in Learn++.NSE performed a postponed updating schema, i.e., a new base classifier was trainedmonthly. As a result, the system could not take advantage of the up-to-date feedback and make a timely adaptation. Itwould appear that an online learning schema is more suitable for the spam filtering domain where the feature space islarge and sparse, and concept drift changes rapidly. 2. The weight of each base classifier is calculated by a log operatorwhich may generate an unlimited figure. As a result, a single base classifier can dominate the final prediction result. In ourexperiments at time t, the base classifier ht trained with the latest dataset Dt always achieved the best performance onDt . Note that the weight of each base classifier is assigned based on its behavior on Dt ; however, when concept drifts, theN. Lu et al. / Artificial Intelligence 209 (2014) 11–2827incoming dataset Dt+1 may follow a different distribution of Dt . Unfortunately, Learn++. NSE does not incorporate any driftdetection mechanism to cope with this situation.7. Conclusions and further studiesThe competence group model is inadequate and deficient. We have consequently proposed and defined a competenceclosure model. This study conducts a theoretical study on the competence group model, and finds that it does not guaranteea complete splitting of the case-base into several competence groups (inadequacy), nor does it guarantee that any twocompetence groups are mutually independent (deficiency). This research defines a competence closure model to overcomethese problems and reveals the essential differences between these two models. It also identifies three important aspectsof the competence closure model which the competence group model does not possess: 1) the competence closure modelis able to uniquely model the entire case-base; 2) the competence closure model provides a smaller granularity than thecompetence group model; 3) competence closure is the maximum set concerning a series of related problems and twocompetence closures are said to be independent in terms of the related set.Concept drift can also reflect on competence measurement. We have presented a method to detect concept drift viacompetence models which requires no prior knowledge of distribution but measures it through a competence model. Thecompetence-based change detection method can be applied to CBR systems, where new cases are available sequentially overtime. Empirical experiments report three advantages of our proposed competence-based change detection method: 1) a highachieved detection rate, 2) robustness on small sample size, and 3) ability to quantify and describe the changes it detects,which makes it highly suitable for handling local concept drift problems.We have found that the competence-based empirical weight provides a rough estimation of the competence distribution ofthe cases. Our next attempt will aim to provide a more reliable competence distribution through fuzzy probability theory.Another improvement may be achieved by drawing a sample that contains no duplicates in the permutation test, as provenby Opdyke [60]. Finally, this paper is part of our work in handling concept drift problems in CBR. Successive case baseediting methods and metric learning methods that take advantage of change detection are needed to improve the finallearning performance.AcknowledgementsThe work presented in this paper was supported by the Australian Research Council (ARC) under Discovery ProjectDP110103733. We also wish to thank the anonymous reviewers for their helpful comments.References[1] J. Gao, W. Fan, J. Han, On appropriate assumptions to mine data streams: analysis and practice, in: Proceedings of the Seventh IEEE InternationalConference on Data Mining, Omaha, October 28–31, 2007, pp. 143–152.[2] P. Zhang, X. Zhu, Y. Shi, Categorizing and mining concept drifting data streams, in: Proceedings of the Fourteenth ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining, Las Vegas, Nevada, USA, August 24–27, 2008, pp. 812–820.[3] Z. Ouyang, M. Zhou, T. Wang, Q. Wu, Mining concept-drifting and noisy data streams using ensemble classifiers, in: Proceedings of the InternationalConference on Artificial Intelligence and Computational Intelligence (AICI), China, November 7–8, 2009, pp. 360–364.[4] G. Widmer, M. Kubat, Learning in the presence of concept drift and hidden contexts, Mach. Learn. 23 (1996) 69–101.[5] G. Hulten, L. Spencer, P. Domingos, Mining time-changing data streams, in: Proceedings of the Seventh ACM SIGKDD International Conference onKnowledge Discovery and Data Mining, San Francisco, California, August 26–29, 2001, pp. 97–106.[6] L. Cohen, G. Avrahami, M. Last, A. Kandel, Info-fuzzy algorithms for mining dynamic data streams, Appl. Soft Comput. 8 (2008) 1283–1294.[7] C.-P. Wei, I.T. Chiu, Turning telecommunications call details to churn prediction: a data mining approach, Expert Syst. Appl. 23 (2002) 103–112.[8] G. Widmer, M. Kubat, Effective learning in dynamic environments by explicit context tracking, in: Proceedings of the European Conference on MachineLearning (ECML-93), Vienna, Austria, April 5–7, 1993, in: Lecture Notes on Artificial Intelligence, Springer, 1993, pp. 227–243.[9] K.O. Stanley, Learning concept drift with a committee of decision trees, 2003, UT-AI-TR-03-302.[10] G. Forman, Tackling concept drift by temporal inductive transfer, in: Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference onResearch and Development in Information Retrieval, Seattle, Washington, USA, August 6–11, 2006, pp. 252–259.[11] A. Tsymbal, M. Pechenizkiy, P. Cunningham, S. Puuronen, Dynamic integration of classifiers for handling concept drift, Inf. Fusion 9 (2008) 56–68.[12] M.A. Maloof, R.S. Michalski, Incremental learning with partial instance memory, Artif. Intell. 154 (2004) 95–126.[13] W.N. Street, Y. Kim, A streaming ensemble algorithm (SEA) for large-scale classification, in: Proceedings of the Seventh ACM SIGKDD InternationalConference on Knowledge Discovery and Data Mining, San Francisco, California, August 26–29, 2001, pp. 377–382.[14] H. Wang, W. Fan, P.S. Yu, J. Han, Mining concept-drifting data streams using ensemble classifiers, in: Proceedings of the Ninth ACM SIGKDD Interna-tional Conference on Knowledge Discovery and Data Mining, Washington, D.C., August 24–27, 2003, pp. 226–235.[15] M. Last, Online classification of nonstationary data streams, Intell. Data Anal. 6 (2002) 129–147.[16] W.-F. Hsiao, T.-M. Chang, An incremental cluster-based approach to spam filtering, Expert Syst. Appl. 34 (2008) 1599–1608.[17] R. Klinkenberg, Learning drifting concepts: Example selection vs. example weighting, Intell. Data Anal. 8 (2004) 281–300.[18] S.J. Delany, P. Cunningham, A. Tsymbal, L. Coyle, A case-based technique for tracking concept drift in spam filtering, Knowl.-Based Syst. 18 (2005)187–195.[19] S.J. Delany, P. Cunningham, An analysis of case-base editing in a spam filtering system, in: Proceedings of the Seventh European Conference in Case-Based Reasoning, Madrid, Spain, August/September, 2004, pp. 128–141.[20] D.W. Aha, D. Kibler, M.K. Albert, Instance-based learning algorithms, Mach. Learn. 6 (1991) 37–66.[21] P. Cunningham, N. Nowlan, S.J. Delany, M. Haahr, A case-based approach to spam filtering that can track concept drift, in: Proceedings of the ICCBR’03Workshop on Long-Lived CBR Systems, Trondheim, Norway, June 2003.28N. Lu et al. / Artificial Intelligence 209 (2014) 11–28[22] A. Tsymbal, The problem of concept drift: Definitions and related work, Department of Computer Science, Trinity College Dublin, Ireland, April 2004,TCD-CS-2004-15.[23] M. Salganicoff, Tolerating concept and sampling shift in lazy learning using prediction error context switching, Artif. Intell. Rev. 11 (1997) 133–155.[24] R. Elwell, R. Polikar, Incremental learning of concept drift in nonstationary environments, IEEE Trans. Neural Netw. 22 (2011) 1517–1531.[25] M.M. Richter, Introduction, in: M. Lenz, et al. (Eds.), Case-Based Reasoning Technology: From Foundations to Applications, Springer, Heidelberg, 1998,pp. 1–15.[26] B. Smyth, M.T. Keane, Remembering to forget: A competence-preserving case deletion policy for case-based reasoning systems, in: Proceedings of theFourteenth International Joint Conference on Artificial Intelligence, San Francisco, August 20–25, Morgan Kaufmann, 1995, pp. 377–382.[27] J. Zhu, Q. Yang, Remembering to add: Competence-preserving case-addition policies for case-base maintenance, in: Proceedings of the Sixteenth Inter-national Joint Conference in Artificial Intelligence (IJCAI), Stockholm, Sweden, July 31–August 6, 1999, pp. 234–241.[28] B. Smyth, E. McKenna, Competence models and the maintenance problem, Comput. Intell. 17 (2001) 235–249.[29] S. Massie, S. Craw, N. Wiratunga, Complexity profiling for informed case-base editing, in: Proceedings of the Eighth European Conference (ECCBR),Fethiye, Turkey, September 4–7, 2006, pp. 325–339.[30] S. Craw, S. Massie, N. Wiratunga, Informed case base maintenance: a complexity profiling approach, in: Proceedings of the Twenty-Second NationalConference on Artificial Intelligence, vol. 2, Vancouver, British Columbia, Canada, July 22–26, 2007, pp. 1618–1621.[31] R. Pan, Q. Yang, S.J. Pan, Mining competent case bases for case-based reasoning, Artif. Intell. 171 (2007) 1039–1068.[32] D.C. Wilson, D.B. Leake, Maintaining case-based reasoners: Dimensions and directions, Comput. Intell. 17 (2001) 196–213.[33] N. Lu, G. Zhang, J. Lu, Detecting Change via Competence Model, in: Proceedings of the Eighteenth International Conference on Case-Based ReasoningResearch and Development, Alessandria, Italy, July 19–22, 2010, pp. 201–212.[34] I. Žliobait ˙e, Adaptive training set formation, PhD thesis, Vilnius University, Vilnius, 2010.[35] D. Kifer, S. Ben-David, J. Gehrke, Detecting change in data streams, in: Proceedings of the Thirtieth International Conference on Very Large Databases,vol. 30, Toronto, Canada, August 31–September 3, 2004, pp. 180–191.[36] T. Dasu, S. Krishnan, S. Venkatasubramanian, K. Yi, An information-theoretic approach to detecting changes in multi-dimensional data streams, in: Pro-ceedings of the Thirty-Eighth Symposium on the Interface of Statistics, Computing Science and Applications (Interface ’06), Pasadena, CA, May 24–27,2006, pp. 1–24.[37] J.P. Patist, Optimal window change detection, in: Proceedings of the Seventh IEEE International Conference on Data Mining Workshops (ICDMW ’07),Omaha, NE, USA, Oct 28–31, 2007, pp. 557–562.[38] A. Bifet, R. Gavaldà, Learning from time-changing data with adaptive windowing, in: Proceedings of the Seventh SIAM International Conference onData Mining (SDM’07), Minneapolis, MN, USA, Apr. 26–28, 2007, pp. 443–448.[39] J. Gama, P. Medas, G. Castillo, P. Rodrigues, Learning with drift detection, in: Proceedings of the Seventeenth Brazilian Symposium on Artificial Intelli-gence, Sao Luis, Maranhao, Brazil, September 29–October 1, 2004, pp. 286–295.[40] M. Baena-García, J. Campo-Ávila, R. Fidalgo, A. Bifet, R. Gavaldà, R. Morales-Bueno, Early drift detection method, in: ECML/PKDD 2006, Workshop onKnowledge Discovery from Data Streams, Berlin, Germany, Sep. 18, 2006, pp. 77–86.[41] Y. Yasumura, N. Kitani, K. Uehara, Quick adaptation to changing concepts by sensitive detection, in: Proceedings of the Twentieth International Confer-ence on Industrial, Engineering, and Other Applications of Applied Intelligent Systems, Kyoto, June 26–29, 2007, pp. 855–864.[42] P. Li, X. Hu, Q. Liang, Y. Gao, Concept drifting detection on noisy streaming data in random ensemble decision trees, in: Proceedings of the SixthInternational Conference on Machine Learning and Data Mining in Pattern Recognition, Leipzig, July 23–25, 2009, pp. 236–250.[43] B. Su, Y.D. Shen, W. Xu, Modeling concept drift from the perspective of classifiers, in: IEEE Conference on Cybernetics and Intelligent Systems (CIS ’08),Chengdu, China, Sep. 21–24, 2008, pp. 1055–1060.[44] F. Wilcoxon, Individual comparisons by ranking methods, Biom. Bull. 1 (1945) 80–83.[45] A. Kolmogoroff, Confidence limits for an unknown distribution function, Ann. Math. Stat. 12 (1941) 461–463.[46] N.V. Smirnov, Approximate laws of distribution of random variables from empirical data, Usp. Mat. Nauk 10 (1944) 179–206.[47] B. Efron, R.J. Tibshirani, An Introduction to the Bootstrap, Chapman and Hall, New York, 1993.[48] K. Nishida, K. Yamauchi, Detecting concept drift using statistical testing, in: Proceedings of the Tenth International Conference on Discovery Science(DS ’07), Sendai, Japan, Oct. 1–4, 2007, pp. 264–269.[49] Y. Freund, R.E. Schapire, A decision-theoretic generalization of on-line learning and an application to boosting, J. Comput. Syst. Sci. 55 (2007) 119–139.[50] G. Welch, G. Bishop, An introduction to the Kalman filter, Technical Report TR-95-041, University of North Carolina, 1995.[51] C. Englund, A. Verikas, A hybrid approach to outlier detection in the offset lithographic printing process, Eng. Appl. Artif. Intell. 18 (2005) 759–768.[52] F. Angiulli, R.B.-E. Zohary, L. Palopoli, Outlier detection using default reasoning, Artif. Intell. 172 (2008) 1837–1872.[53] A. Dries, U. Rückert, Adaptive concept drift detection, Stat. Anal. Data Min. 2 (2009) 311–327.[54] S. Massie, S. Craw, N. Wiratunga, What is CBR competence? BCS-SGAI Expert Update 8 (2005) 7–10.[55] B. Smyth, E. McKenna, Modelling the competence of case-bases, in: Proceedings of the Fourth European Workshop on Advances in Case-Based Reason-ing, Dublin, Ireland, September 1998, pp. 208–220.[56] E. McKenna, B. Smyth, Competence-guided case discovery, in: Proceedings of the Twenty-First SGES International Conference on Knowledge BasedSystems and Applied Artificial Intelligence, Cambridge UK, December 10–12, 2001, pp. 97–108.[57] H. Brighton, C. Mellish, Advances in instance selection for instance-based learning algorithms, Data Min. Knowl. Discov. 6 (2002) 153–172.[58] E. Koehler, E. Brown, S.J.-P.A. Haneuse, On the assessment of Monte Carlo error in simulation-based statistical analyses, Am. Stat. 63 (2009) 155–162.[59] K.J. Berry, P.W. Mielke, Moment approximations as an alternative to the F test in analysis of variance, Br. J. Math. Stat. Psychol. 36 (1983) 202–206.[60] J.D. Opdyke, Fast permutation tests that maximize power under conventional Monte Carlo sampling for pairwise and multiple comparisons, J. Mod.Appl. Stat. Methods 2 (2004) 27–49.[61] K.V. Mardia, Families of Bivariate Distributions, Griffin, London, 1970.[62] B. Smyth, E. McKenna, An efficient and effective procedure for updating a competence model for case-based reasoners, in: Proceedings of EleventhEuropean Conference on Machine Learning (ECML ’00), Barcelona, Catalonia, Spain, May 31–June 2, 2000, pp. 357–368.[63] K.R. Gee, Using latent semantic indexing to filter spam, in: Proceedings of Eighteenth Annual ACM Symposium on Applied Computing (SAC ’03),Melbourne, FL, USA, Mar. 9–12, 2003, pp. 460–464.