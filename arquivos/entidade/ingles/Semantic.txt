Artificial Intelligence 244 (2017) 143–165Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSemantic-based regularization for learning and inferenceMichelangelo Diligenti∗, Marco Gori, Claudio SaccàDepartment of Information Engineering and Mathematics, University of Siena, Via Roma 56, Siena, Italya r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 13 August 2015Accepted 26 August 2015Available online 1 September 2015Keywords:Learning with constraintsKernel machinesFOLThis paper proposes a unified approach to learning from constraints, which integrates the ability of classical machine learning techniques to learn from continuous feature-based representations with the ability of reasoning using higher-level semantic knowledge typical of Statistical Relational Learning. Learning tasks are modeled in the general framework of multi-objective optimization, where a set of constraints must be satisfied in addition to the traditional smoothness regularization term. The constraints translate First Order Logic formulas, which can express learning-from-example supervisions and general prior knowledge about the environment by using fuzzy logic. By enforcing the constraints also on the test set, this paper presents a natural extension of the framework to perform collective classification. Interestingly, the theory holds for both the case of data represented by feature vectors and the case of data simply expressed by pattern identifiers, thus extending classic kernel machines and graph regularization, respectively. This paper also proposes a probabilistic interpretation of the proposed learning scheme, and highlights intriguing connections with probabilistic approaches like Markov Logic Networks. Experimental results on classic benchmarks provide clear evidence of the remarkable improvements that are obtained with respect to related approaches.© 2015 Elsevier B.V. All rights reserved.1. IntroductionThis paper presents Semantic Based Regularization (SBR), a unified framework for inference and learning that is centered around the notion of a constraint and of the parsimony principle. Semantic Based Regularization bridges the ability of machine learning techniques to learn from continuous feature-based representations with the ability of modeling arbitrary pattern relationships, typically used in Statistical Relational Learning (SRL) to model and learn from high-level semantic knowledge. In order to provide a unified context for manipulating perceptual data and prior knowledge, we propose to use the unifying concept of a constraint, which is sufficiently general to represent different kinds of sensorial data along with their relations, as well as to express abstract knowledge on the tasks. We unify continuous and discrete computational mechanisms, so as to accommodate in the same framework very different stimuli. In this paper, we focus on the kernel machine mathematical and algorithmic apparatus to learn from feature-based pattern representations and on constraints resulting from a fuzzy translation of First Order Logic (FOL) formulas, expressing the prior knowledge about the learning task at hand.More specifically, SBR builds a multi-layer architecture having kernel machines at the input layer. The output of the kernel machines is fed to the higher layers implementing a fuzzy generalization of the FOL knowledge. Thanks to the * Corresponding author.E-mail addresses: diligmic@diism.unisi.it (M. Diligenti), marco@diism.unisi.it (M. Gori), sacc@unisi.it (C. Saccà).http://dx.doi.org/10.1016/j.artint.2015.08.0110004-3702/© 2015 Elsevier B.V. All rights reserved.144M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165basic properties of fuzzy FOL and kernel machines, the resulting model is continuous with respect to the feature values. Therefore, the high-level semantic inference provided by the logic can be back-propagated down to the kernel machines using any gradient-based schema. This process can be iterated during training until convergence. This is an extremely powerful technique to get advantage of the available unsupervised data, as the inference process performed on this data via the logic knowledge can be used to correct the output of the kernel machines.We substantially extend earlier studies in Diligenti et al. [10] by showing that SBR enables new fundamental tasks of learning and inference that rely on the joint informative evidence coming from real-valued features and simple pattern identifiers, along with the corresponding relations. In particular, the paper gives the following new main results, which are of fundamental importance to gain an overall view of theory and, especially, to enable a large set of applications in statistical relational learning domains:variable dimension domains and null inputs We extend the SBR framework [10] to truly hybrid domains, where real-valued feature pattern representations are integrated with pure symbolic entities (e.g. pattern identifiers). Indeed, in complex relational classification tasks, it is often the case that the entities are naturally representable by pat-tern spaces of different dimensions, including the remarkable case of “void patterns” in which only relational information is available.collective classification In this paper we propose a novel collective classification method to enforce the constraints on the test set, thus exploiting the full expressiveness of FOL, like in other statistical relational learning (SRL) ap-proaches. Once again, the distinctive feature of the solution proposed in this paper arises when considering that the collective computational scheme also naturally exploits real-valued feature pattern representations.probabilistic links We extend studies on the probabilistic interpretation of regularization networks [38] to our case of learning from constraints. From one side, this highlights connections with Markov Logic Networks (MLNs) [40], while from the other side, this interpretation clearly shows the natural integration of real-valued features and object identifiers in SBR.Furthermore, the paper presents how plain SVM, Transductive, and Laplacian SVMs can be derived as special cases of the proposed SBR framework. The paper also introduces new heuristics, connected to the ones employed in constraint satisfaction programming, to improve the quality of the found solutions. Finally, we present experimental results to show the effectiveness and generality of the approach.The paper is organized as follows: in the next section previous work in the field is reviewed. Section 3 introduces First Order Logic and its fuzzy extensions, while Section 4 discusses learning from constraints with kernel machines. Section 5presents how SBR generalizes several models commonly used in relational and transductive learning. Details on how training is performed in the SBR framework is presented in Section 6. In Section 7 a collective classification approach for SBR is presented and Section 8 presents connections between SBR and probabilistic models like Markov Logic Networks. The experimental evaluation of SBR is presented in Section 9 and, finally, Section 10 draws some conclusions.2. Previous workStatistical Relational Learning (SRL) combines robust parameter estimation in the presence of noise with learning complex relational structures. Probabilistic Relational Models (PRMs) [13] are an early SRL approach that learns a statistical model from a relational database. PRMs build a probability distribution over the attributes of the objects as an instance of a schema. A Bayesian network with one node for each attribute is built and parameters are estimated from the data. Relational Dependency Networks [34] learn a (local) conditional probability distribution for each node given its Markov blanket by using a conditional learner (like logistic regression or decision trees).Markov Logic Networks (MLNs) [40] have received a lot of attention in the SRL community and have been extensively applied in many fields like bioinformatics [28] and computer vision [46]. Markov Logic Networks generalize and combine first-order logic and probabilistic graphical models. Thanks to their flexibility, MLNs have been used to tackle all the SRL main tasks: collective classification, link prediction, link-based clustering, social network modeling, and object identification. Many papers have also studied how to learn the structure of Markov Logic Networks from data without requiring an expert to express the structure in terms of prior knowledge [23,22]. Hybrid Markov Logic Networks (HMLNs) [49] extend MLNs to deal with continuous variables.Probabilistic Soft Logic (PSL) [5] is another SRL approach, which relaxes MLNs to continuous fuzzy values in the [0, 1]interval and restricts the considered FOL formulas to the ones with conjunctive body and a single literal head. PSL weight training can be solved via a convex optimization problem, but it can face only a small subset of the tasks that are potentially solved by a MLN.One disadvantage of both MLNs and PSL in real-world applications is how they deal with entities that are associated to complex feature-based representations. Let’s take as an example the common scenario of a multi-class classification task where the patterns are represented by large vectors of numeric features. In order to perform learning and inference in this domain using classical SRL techniques, different approaches are possible:M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165145• the value of a feature can be correlated with one output class using one specific rule. For example, let x be a generic pattern in the domain and f be a binary feature, it is possible to express the rule HasTrueValue( f , x) ∧ BelongsTo(x, c)for each category c. The training process will estimate a weight modeling the strength of this correlation. MLNs can capture a logistic regression model using this approach [11,12]. The advantage of this solution is that it employs a coherent framework for dealing with the pattern representations and the higher-level semantic knowledge. However, it requires to deal with a large number of weights and groundings. Furthermore, only very simple correlations between features and classes can be captured as more complex models would be too large to be tractable.• Another approach is to pre-train an arbitrary classifier working on the low-level feature representations and let a SRL layer use the classifier as a prior for the assignments. The SRL layer will assign a proper weight to this prior during training and then the predictions of the base classifier can be refined during the prediction step. This approach uses standard machine learning techniques to learn from the low level data. Complex feature dependencies can be efficiently captured by, for example changing the employed kernel when using a kernel machine as the base classifier. The main disadvantage of this approach is that the two layers are sequentially trained in a greedy fashion. This means that the high level semantic inference is stacked up on top of a pre-trained frozen layer, which processes the pattern repre-sentations. This does not allow to use the output of the inference process performed at the higher level to improve the predictions of the base classifier. This is a huge limitation whenever a large number of unsupervised patterns is available and the decision made by the semantic layer could be used as additional supervisions at the lower level.SBR encodes a multi-layer architecture having kernel machines at the input layer, which provides the input to the higher-level layers implementing a fuzzy generalization of the FOL knowledge. Since the fuzzy FOL generalization of the knowledge is continuous with respect to the values coming from the input layer, information can flow in both directions in this ar-chitecture. This allows to back-propagate the information from the high-level inference performed by the logic knowledge down to the kernel machines using a simple gradient-based schema. This allows SBR to preserve the compactness and effi-ciency of kernel machines to deal with the feature space representations at the input level, while exploiting the full power of FOL to express the higher-level semantics.As it will be discussed later in the paper, keeping two separate but communicating layers one dedicated to processing the feature space and one to performing the higher conceptual reasoning allows to devise more efficient training techniques breaking the complexity of learning. SBR optimization tasks are very similar to the nested optimization problems studied by bilevel programming [2]. Unfortunately, the results obtained in the context of bilevel programming are not easy to reuse for SBR training, as the outer SBR optimization problem is generally neither quadratic nor linear.Other SRL approaches have focused on high level cognitive decision processes with no native integration with learning in the presence of continuous high dimensional data representations. Integration between logic and learning has been traditionally hard to achieve because of the barriers erected by the different mathematical models classically used to handle logical reasoning and learning from examples with real numbers. Connections between logic and kernel machines have been studied in the context of finding relationships between symbolic and sub-symbolic models in AI [21], with particular emphasis on hybrid models. When restricting to kernel machines, a rich analysis of the literature can be found in the survey [26], while a broader coverage of the field with emphasis on the connections with inductive logic programming can be found in DeRaedt at al. [39].Convolution kernels in discrete structures [20] have been one of the main sources of inspiration for exploring connections of kernel machines with logic. Feature Description Logic (FDL) is introduced to support learning in relational domains [8,9]. The paradigm provides a natural solution to the problem of learning and representing relational data and extends and unifies several lines of works in machine learning. Muggleton et al. [33] presents support vector machines based on a kernel that is an inner product in the feature space spanned by a given set of first-order hypothesized formulas. The inductive logic programming system FOIL is combined with kernel methods in Landwehr et al. [24]. The resulting model (kFOIL) implements a dynamic propositionalization approach allowing to perform both classification and regression tasks. Landwehr et al. [25] presents a general theoretical framework for statistical logical learning based on dynamic propositionalization, where structure learning corresponds to inferring a suitable kernel on logical objects, and parameter learning corresponds to function learning in the resulting reproducing kernel Hilbert space. In the context of multi-task learning, functions can be coupled via dependencies induced by the structure of special multi-task kernels [6].Quite a different approach is based on imposing constraints in the perceptual space [14,15,27], where the prior knowl-edge is incorporated in the form of constraints into a support vector machine classifier.Most of the reviewed papers have already proposed different frameworks for incorporating prior knowledge expressed by logic formalisms into kernel machines. However, the integration seems to be shallow, being based on asking the kernel to play the additional role of incorporating logic structures, instead of primarily measuring the smoothness of the solution according to the Occam’s razor. While this is a very interesting idea, the remarkable residual degree of freedom on the way the logic structures can be incorporated suggests that we are only partially addressing the inherent limitation of kernel methods.In the presented framework, the adoption of T-norms allows to simply express most classic logic formalisms by con-straints on real-valued functions. Therefore, the general and unified notion of constraint employed in this paper seems to be most natural and straightforward extension of the classic statistical framework of learning from examples, since they are just another special instance of a constraint.146M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–1653. First order fuzzy logicThe term fuzzy logic was firstly used by L.A. Zadeh in 1965 [51]. Classical logic works with variables assuming a binary truth value. Fuzzy Logic, instead, is a form of many-values logic or probabilistic logic. It deals with reasoning that is ap-proximate rather than exact [18], where variables have a truth degree that ranges in [0, 1]: zero and one meaning that the variable is false and true with certainty, respectively. A fuzzy generalization of FOL has been first proposed by Novak [36].T-norm and residuum A t-norm is a function t : [0, 1] × [0, 1] → [0, 1], which is continuous, commutative, associative, mono-tone, and featuring a neutral element 1 (i.e. t(a, 1) = a). A strict t-norm is also strictly monotone. A t-norm fuzzy logic is defined by its t-norm t(a1, a2) that models the logical AND. Given a variable ¯a with continuous generalization a in [0, 1], its negation ¬¯a corresponds to 1 − a. Once the t-norm functions corresponding to the logical AND and NOT are defined, they can be composed to convert any arbitrary logic proposition into a continuous function. A t-norm expression behaves as classical logic when the variables assume the crisp values 0 (false) or 1 (true). Many different t-norm fuzzy logics have been proposed in the literature. For example, given two Boolean values ¯a1, ¯a2 and their continuous generalizations a1, a2 in the [0, 1] range, the product t-norm is defined as:(¯a1 ∧ ¯a2) −→ t(a1, a2) = a1 · a2The ∨ operator is then consequently defined by using the De Morgan rule:(¯a1 ∨ ¯a2) ≡ ¬(¬¯a1 ∧ ¬¯a2) −→ t(a1, a2) = 1 − (1 − a1) · (1 − a2)Another commonly used t-norm is the minimum t-norm defined as:(¯a1 ∧ ¯a2) −→ t(a1, a2) = min(a1, a2)from which it follows:(¯a1 ∨ ¯a2) −→ t(a1, a2) = max(a1, a2)The equivalence ¯a1 ⇒ ¯a2 ≡ ¬¯a1 ∨ ¯a2 is used in classic logic to represent implications (modus ponens). However, this equivalence is not appropriate to perform deductions with fuzzy variable values. Any t-norm has a corresponding binary operator ⇒ called residuum, which is used in fuzzy logic to generalize implications when dealing with continuous variables. A t-norm residuum provides a natural way to express human fuzzy reasoning, while being equivalent to modus ponens when fuzzy variable values approach the extremes of the [0, 1] range.In particular, the residuum converting an implication for the minimum t-norm is defined as:(cid:2)(¯a1 ⇒ ¯a2) −→ t(a1, a2) =a1 ≤ a21a2 a1 > a2while for the product t-norm the residuum is defined as:(cid:2)(¯a1 ⇒ ¯a2) −→ t(a1, a2) =1a2a1a1 ≤ a2a1 > a2The residuum allows to relax the condition of satisfaction for the implication, which is satisfied as soon as the t-norm expression of the head has a higher truth degree than the t-norm expression of the formula body.Quantifiers With no loss of generality, we restrict our attention to FOL formulas in the Prenex Normal Form (PNF) form, where all the quantifiers (∀, ∃) and their associated quantified variables are placed at the beginning of the expression. For example:Quantifiers(cid:3) (cid:4)(cid:5) (cid:6)∀x1∀x2Quantifier-free expression(cid:6)(cid:4)(cid:5)(cid:3)A(x1) ∧ B(x2) ⇒ C(x1)(1)Please note that, since we are dealing with variables ranging in [0, 1], the quantifier-free part of the expression is equiv-alent to an assertion in fuzzy propositional logic once all the quantified variables are grounded. Hence, a t-norm fuzzy logic can be used to convert it into a continuous function.Let’s consider a FOL formula with variables x1, x2, . . . assuming values in the finite sets X1, X2, . . . . P = {p1, p2, . . .} is = X j1 ×X j2 ×. . . . In case of an unary predicate j ) indicate the set of possible groundings for the j-th predicate, and P(X ) indicate all possible grounded the vector of predicates, where the j-th n-ary predicate is grounded from X ◦jX ◦jpredicates, such that P(X ) = p1(X ◦= X j1. Let p j(X ◦Assuming that the atoms P(X ) are generalized to assume real values in [0, 1], the degree of truth of a formula con-taining an expression E with a universally quantified variable xi is defined as the minimum of t E (·) obtained as the t-norm generalization of E when grounding xi over Xi :1 ) ∪ p2(X ◦2 ) ∪ . . . .M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165147(cid:7)(cid:8)P(X )∀xi E−→ (cid:2)∀(cid:7)(cid:8)P(X )(cid:7)(cid:8)P(X )t E= minxi ∈XiFor the existential quantifier, the truth degree is instead defined as the maximum of the t-norm expression over the domain of the quantified variable:(cid:7)(cid:8)P(X )∃xi E−→ (cid:2)∃(cid:7)(cid:8)P(X )(cid:7)(cid:8)P(X )t E= maxxi ∈XiThe two above generalizations correspond to the conjunction and disjunction of the minimum t-norm expressions of the propositional formula computed over all the groundings, respectively.When multiple universally or existentially quantified variables are present, the conversion is performed recursively from the outer to the inner variables. Please note that any fuzzy FOL formula returns a value in the [0, 1] range. The fuzzy formula expression is continuous and differentiable (except that over a set of points with null measure) with respect to the fuzzy value of a predicate.A small modification to classic Fuzzy FOL has been used in this paper, in particular the universal quantifier is generalized as:(cid:7)(cid:8)P(X )∀xi E−→ (cid:2)∀(P(cid:7)(cid:8)X )= 1|Xi|(cid:9)xi ∈Xi(cid:7)(cid:8)P(X )t Ewhere the min operator over the t-norm values has been replaced by the average over the set. This definition allows faster convergence during the training of the model: the classical Fuzzy FOL formulation directly depends only on one item over the set of groundings (the argmin element), whereas the average depends on all elements and allows parallel optimization during training. Obviously, the Fuzzy FOL expression in this new formulation is perfectly verified (e.g. it assumes the value 1) iff the same atom assignments would make the old formulation be verified, so the two formulations are consistent.Example 3.1. The formula ∀x1∃x2 A(x1) ∧ B(x2), using a product t-norm for the quantifier-free part conversion corresponds to the following continuous generalization:(cid:2)(P(X )) = 1|X1|(cid:9)x1∈X1maxx2∈X2A(x1) · B(x2)where A(x1), B(x2) are the fuzzy truth values of the two predicates A and B grounded with x1 and x2.As commonly done in description logic [1], a different operator called n-existential quantifier, indicated as ∃n , can be defined to express a property that should hold true for at least n objects. The fuzzy generalization of this quantifier is defined as∃nxi E(cid:7)(cid:8)P(X )−→ (cid:2)∃n (P(cid:7)(cid:8)X )= 1n(cid:9)(cid:7)(cid:8)P(X )t Exi ∈Mn(t E ,P,Xi ,X )where Mn(t E , P, Xi, X ) is the set of groundings of xi ∈ Xi corresponding to the n maximum values for t E. The conversion of this quantifier collapses into the universal quantifier conversion as n → |Xi| and into the existential quantifier as n → 1.It is interesting to note that this translation is computationally more approachable than what can be done in most other SRL approaches. MLNs, for example, replace the existential quantifier by a disjunction over all the groundings. The ∃nquantifier can be expressed as n nested existential quantifiers in a MLN, but the number of groundings of the formula would scale as |G|n, where |G| is the number of groundings of the considered variable. In SBR, the ∃n corresponds to selecting the n groundings that are the best candidates to satisfy the formula. This candidate selection can be done with complexity O (|G| log n) by using a heap data structure.4. Semantic based regularization(cid:8)(cid:7)P(X )Consider a multi-task learning problem, where a set of T functions must be estimated (query or unknown functions) and functions (evidence or given functions) are known a priori. Let f = { f 1, . . . , f T , f T +1, . . . , f T +T (cid:14) } indicate the vector (cid:14)another Tof functions.We assume that a set of H functional constraints in the form 1 − (cid:2)h( f ) = 0, 0 ≤ (cid:2)h( f ) ≤ 1, h = 1, . . . , H are provided in order to describe how the query functions should behave. Functionals can express a property of a single function or correlate multiple functions, so that learning can be helped by exploiting these correlations.Let Hk be the functional space where the k-th function lives. Following the classical penalty approach for constrained optimization, the constraint satisfaction can be enforced by adding a term that penalizes their violation. The resulting cost function to be minimized is:148M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165C[ f ] =T(cid:9)k=1|| fk||2Hk+H(cid:9)h=1λh (1 − (cid:2)h( f )) ,where the first term penalizes non-smooth solutions and λh is the weight for the h-th constraint. A higher value of λhmakes it more costly not respecting the constraint, and the constraint becomes hard as λh → ∞.The learning problem is relaxed by assuming that the constraints are enforced only over a finite sample of the input patterns. Typically, each pattern is represented as a vector of real-valued features, but we will see also cases where the patterns are simply represented by a unique identifier. In particular, the j-th function is associated to a set X ◦j of pattern representations x j . It is possible that multiple functions share the same sample of patterns (e.g. X ◦i (cid:16)= j). Since some functions may express relations across multiple patterns, the pattern representations associated to a function can be generally expressed as the combination of the patterns from a set of finite domains: X ◦= X j1 × X j2 × . . . .k) indicate the vector of values obtained by applying the function fk to the set of patterns X ◦k and f (X ) =2) ∪ . . . collects the groundings for all functions. Enforcing the constraints only over the samples of data, 1) ∪ f 2(X ◦Let fk(X ◦= X ◦ijjf 1(X ◦yields the following cost function:Ce[ f (X )] =T(cid:9)k=1|| fk||2Hk+H(cid:9)h=1λh (1 − (cid:2)h( f (X ))) .(2)Please note that for the sake of simplicity (and with abuse of notation), the same symbol (cid:2) was used to refer to both the exact and empirical approximation functionals.The solution to the optimization task defined by the objective function in Equation (2) is a kernel expansion in the form:∗k (x) = βk +f|X ◦|(cid:9)ki=1w(cid:5)ki Kk(xki, x) ,(3)where βk is a bias and Kk(·, ·) is the reproducing kernel associated to the space Hk. The proof [10] is a straightforward extension of the Representer Theorem for plain kernel machines [42]. The bias βk is added to specify the default value of a function. The weights of the k-th function are indicated as w k = {wk1, . . . , wk|X ◦|}. Plugging Equation (3) into (2), we get an expression that can be minimized by optimizing the wk by gradient descent:kT(cid:9)Ce[ f (X )] =w Tk Gk wk +H(cid:9)(cid:10)1 − (cid:2)h(cid:7)λh(cid:8)(cid:11)f (X )(4)k=1where f (X ) = {G 1 w 1, . . . , G T w T , f T +1(X ◦T +T (cid:14) )} and G k is the Gram matrix for the k-th function, whose (i, j) element is equal to Kk(xki, xkj). For the sake of simplicity, we have not explicitly added the vector of bias values as input to (cid:2)h( f (X )).T +1), . . . , f T +T (cid:14) (X ◦h=14.1. Logic and constraintsLet us assume that a knowledge base KB, consisting of a set of FOL formulas and a set of groundings for the variables, is provided to express some domain knowledge. Some of the predicates are unknown and must be estimated. The j-th unknown predicate is approximated by the function σ ( f j(·)) where f j is the function that must be learned, and σ (·) is a sigmoidal function mapping the functions’ outputs onto the [0, 1] range, on which the t-norms are defined. In the remainder of the paper we drop the σ to not overload the notation. The variables in the KB that are input to any f j are replaced with the feature-based representation of the object grounded by the variables. We will indicate as xi the representation of the object grounded by xi , where ρ(xi) = xi is a function mapping a pattern representation into its object identifier. The groundings Xi of the i-th variable are therefore replaced by the set X i , indicating the set of feature-based representations of the groundings. One constraint 1 − (cid:2)i(·) = 0 for each formula F i in the knowledge base is built by taking the fuzzy FOL generalization of the formula (cid:2)i(·), where the unknown predicates are replaced by the learned functions, and the variables input to the learned functions are replaced by their duals iterating over the feature-based representations of the groundings.Example 4.1. Let’s suppose to have a text categorization task, where the documents must be assigned to the categories A, B, C, D. Let d be a generic document to be classified and A(d), B(d), C(d), D(d) be the unknown indicator functions for the classes. We indicate with d the feature representation for d, which would typically be its bag-of-word TF or TF-IDF representation. The functions f A(d), f B (d), f C (d), f D (d) must be estimated to approximate respectively the unknown A(d), B(d), C(d), D(d). We will assume that the variable d will be grounded with two documents {d1, d2}, having as bag-of-word representations: D = {d1, d2}, respectively. We will use this simple learning task as running example for the rest of the paper.M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165149The fuzzy FOL generalization of the knowledge base provides a continuous and differentiable surrogate of the initial logic formulas such that 0 ≤ (cid:2)i(·) ≤ 1. Therefore, the resulting constraints 1 − (cid:2)i(·) = 0 are continuous and differentiable as well, and this will allow to train the query functions using any gradient-based learning schema.The form of the constraints depends on which t-norm has been used to generalize the FOL rules. Whereas it is always true that all t-norms are consistent with classical logic when variables assume crisp values (0, 1), the behavior of the various t-norms differs for the intermediate values, ultimately leading to different constraints. Similarly to the selection of the right kernel for kernel machines, the choice of a t-norm is always a matter of context, and it depends on the problem which is modeled [17]. For example, the minimum t-norm can be a better choice than a product t-norm when performing inference in presence of long conjunctive chains, where the value of the conjunction would vanish exponentially in the number of terms when using a product t-norm. The product t-norm is correct in this case as well, since it behaves consistently to its probabilistic-independence assumption, but training may be too slow. The t-norm selection should not have a strong impact in most applications, and it did not provide any significant change in all the experiments presented in this paper.Example 4.2. Continuing the text categorization example, we can assume to have some external knowledge about the categories: ∀d A(d) ∨ B(d) expressing that any document must belong to class A or B. The constraint resulting from the fuzzy FOL generalization of the formula after substituting the query predicates with the unknown functions and the two document representations is:1 − (cid:2)({ f A(D), f B (D)}) = 1 − 12= 1 − 12= 0(cid:9)(cid:3)maxt( f A (d), f B (d))(cid:4)(cid:5)(cid:7)(cid:6)(cid:8)f A(d), f B (d)d∈D(cid:7)max(cid:7)(cid:8)f A(d1), f B (d1)(cid:7)+ max(cid:8)(cid:8)f A(d2), f B (d2)where t(·) is the minimum t-norm representation for the propositional part of the formula. This constraint can be directly plugged into Equation (4) for optimization.4.2. Nodes with no feature vector representationIt is common to have query predicates for which the input arguments (their groundings) have no associated feature representation. Most Statistical Relational Learning approaches are indeed assuming this case. In this case, the inputs can simply be listed as a sequence of unique identifiers. Equation (4) can still be used as generic expression of the cost function by setting the Gram matrix to be the identity matrix for all predicates that have no vectorial input e.g. G k = I . In this case the vector of weights becomes the vector of values of the function over the inputs as fk(X ◦k) = Gk wk = I wk = wk. These unknown values must be directly estimated without generalizing over the input space (which is null).Obviously, an interesting case is when some functions have inputs represented as vectors of features and others don’t. The experimental section will present some experiments in this mixed setting.4.3. SBR as a multi-layer architectureGiven an arbitrary KB, the procedure described in the previous section can be generally encoded by a multi-layer network with the following structure:• input layer: computation of the atoms, this is performed by computing the query and evidence function values for all possible groundings;• propositional layer: the value of the t-norm expression of the propositional part of each formula is computed for each compatible combination of atoms;• quantifier layers: the t-norm values computed at the previous layer are aggregated by the average or max operator for the universal and existential quantifiers, respectively. Please note that the number of quantifier layers is not fixed, as the aggregation of the outputs is recursively nested according to the number of quantifiers in the FOL formula. The output of this layer is a score in [0, 1] expressing how strongly the FOL formula is respected.• output layer: accumulation by summation of the contributions coming from the single formulas.Learning and inference are intractable in large domains, because of the exponential growth of the number of groundings with respect to the number of nested quantifiers. However, in most applications, a large portion of the ground clauses are trivially satisfied or not satisfied by the known evidence atoms regardless of unknown assignments. These groundings can be discarded without introducing any approximation in the training or inference process. In the context of MLNs, many heuristics and algorithms like FROG preprocessing [43], Tuffy [35] or LazySAT [44] have been proposed to detect and discard these non-informative groundings. Since the grounding process of MLNs and SBR is essentially the same, these algorithms 150M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165can be directly reused in SBR. In particular, FROG preprocessing has been used in the presented experiments to prune the encoded network in the input and propositional layers, whenever the grounding of the evidence predicates makes the formula always holding true or false, independently on the values assumed by the query predicates. In this case the contribution to the cost function of the grounding is constant and it has no effect on the learning process. Therefore, it is useless to instantiate this grounding in the encoded network. A common case where the pruning process can be applied is when dealing with a FOL formula in the following form: R(x) ⇒ A(x) where R(x) is an evidence predicate. When it holds that R(p) = false given the grounding x = p, the rule is verified regardless of the value of the query predicate A(p). Therefore the grounded predicates R(p), A(p) can be safely discarded from the encoding network during training, unless appearing in another FOL formula.To summarize, the network encoded by SBR for a given KB can be defined as in the following.Definition 4.3 (SBR network). Assume a FOL KB composed by rules and predicates, which are grounded by a set of constants. Let x represent the feature vector associated to a grounding x. We indicate with f i(·) the function implemented by a Kernel Machine, approximating the i-th unknown predicate pi , where f i(·) takes as input the feature vector representations of the constants grounding the predicate. SBR builds a multi-layer network N computing the fuzzy FOL approximation of the KB, where the value f i(x) replaces a grounded unknown predicate pi(x).Some examples of KB and relative network encodings will be shown in the remainder of the paper.5. Some special cases of SBRThis section will show how SBR can reproduce standard and Transductive SVMs, manifold and graph regularization. At the same time all these learning schemas can be mixed and extended arbitrarily with the full expressiveness of FOL.5.1. Case 1: SVMsLet X +k be the sets of positive and negative examples for the k-th unknown predicate pk, (X ◦k= X +k∪ X −k ). The following logic formula expresses the fact that pk is constrained on the values assumed over the supervised data:k , X −(cid:7)(cid:8)P k(x) ∧ pk(x)(cid:7)(cid:8)¬P k(x) ∧ ¬pk(x)∨∀xwhere x ∈ Xk and the predicate P k(x) is an evidence function holding true iff x is a positive example for the query predicate pk (e.g. x ∈ X +k ). Using the minimum t-norm and replacing pk with its approximation fk, this corresponds to the following constraint:1 − (cid:2)(cid:7){P k(X ◦k ), fk(X ◦k)}(cid:8)= 1 − 1|X ◦k|(cid:9)(cid:10)maxmin(cid:7)(cid:8)P k(ρ(x)), fk(x), min(cid:7)1 − P k(ρ(x)), 1 − fk(x)(cid:8)(cid:11)x∈X ◦k(cid:10) (cid:9)x∈X +k= 1 − 1|X ◦k(cid:10) (cid:9)|= 1|X ◦kmax|x∈X +k(cid:7)(cid:8)1, fk(x)+min(cid:9)(cid:7)1, 1 − fk(x)(cid:8)(cid:11)min(cid:7)(cid:8)0, 1 − fk(x)+x∈X −k(cid:9)x∈X −k(cid:7)(cid:8)(cid:11)max0, fk(x)= 0where max(0, 1 − fk(x)) is the hinge loss used by regular SVM. The same hinge loss would appear for negative supervisions if using the −1 value for negative supervisions instead of the 0 used here. Therefore, plugging the previous constraint into Equation (4) shows that classical SVMs are a special case in our framework, when expressing the fitting of the supervised data as logic knowledge. Please note that the constraints resulting from the supervised data fitting are a special case of a constraint that is convex and relatively easy to optimize. We will discuss this point into more details in the following section.When unsupervised data is also available, it is possible to express the supervisions using two evidence predicates. In ∪k ). The learned function is constrained in terms of the assumed values on the supervised data by specifying the following k be the available positive, negative and unsupervised examples for task k (e.g. X ◦k , X −= X +k∪ X −kk , X ukparticular, let X +X ulogic formulas F p, Fn:F p : ∀x P k(x) ⇒ pk(x)Fn : ∀x Nk(x) ⇒ ¬pk(x)where P k(x) and Nk(x) are evidence functions holding true iff x is a positive or negative example for the query predicate pk, respectively. Also this formulation corresponds to the learning task solved by standard SVM training (patterns that are M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165151Fig. 1. Network encoded from a knowledge base containing the F formula as see in the figure, which implements the SVM supervised training, and that has been grounded with the constants (patterns) C = {d1, d2}.neither positive nor negative supervised do not contribute to the cost function) and it will be used as base step for solving more complicated learning tasks, where unsupervised data plays a role, in the remainder of the paper.Example 5.1. In our text categorization example, let us assume that d1 belongs to class A and d2 does not. This can be expressed by stating that d1 is a positive supervised example: P A(d1) = true, while P A(d2) = false. We can then express the rule: ∀d (P A(d) ∧ A(d)) ∨ (¬P A(d) ∧ ¬ A(d)) to incorporate the labeled data into the learning task. The following constraint results from the fuzzy FOL generalization of the formulas using the minimum t-norm and after substituting the document identifiers with their feature representations and the query predicates with the corresponding functions to estimate:1 − (cid:2)(cid:7)(cid:8)f A(D)= 12(cid:7)(cid:8)max(0, 1 − f A(d1)) + max(0, f A(d2))= 0 ,Fig. 1 shows the network which is encoded when performing this simple learning task.5.2. Case 2: manifold regularizationManifold Regularization [3] assumes that the learned function should be regular over the input manifold, which is repre-sented as a graph, whose edges connect the input patterns. The graph can be directly built over the input data distribution, or built from external knowledge like html hyperlinks in a web page classification problem. Laplacian SVM (LSVM) [31] is an effective semi-supervised approach to train SVMs under the manifold regularization assumption.Manifold Regularization is a special case of SBR, where there are rules forcing the fitting of the supervised examples, as previously described, and an additional rule expressing the manifold assumption. In particular, let R(x, y) be a given (evidence) relation expressing whether x, y are connected on the manifold. The manifold assumption in a logic setting for a predicate p is expressed by the following FOL formula, asserting that two connected points should either be both true or both false:∀x ∀ y R(x, y) ⇒ (p(x) ∧ p( y)) ∨ (¬p(x) ∧ ¬p( y)) .Example 5.2. Let us assume that, in the previously considered text categorization task, d1 links to d2 via a hyperlink R(d1, d2) = 1, while no links are available between the other documents. Manifold regularization in this domain is ex-pressed for the category A by a formula F R , whose fuzzy FOL generalization (cid:2)F R is obtained by substituting the query predicate A with the unknown function f A and using the minimum t-norm. This yields the following constraint:1 − (cid:2)F R(cid:7)(cid:8)f A(D)(cid:10)= 1 − 143 + max(cid:7)(cid:8)min( f A(d1), f A(d2)), min(1 − f A(d1), 1 − f A(d2))= 0152M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165Fig. 2. Multi-layer network that is encoded by SBR for the KB = {F , F R } where F R implements manifold regularization and F supervised learning for the positive supervisions. The KB has been grounded with the constants (patterns) C = {d1, d2}.where the first contribution comes from the 3 groundings for which the R predicate is false and the rule trivially verified. This contribution does not affect the training process and can be dropped. This constraint can be plugged into Equation (4)to get the cost function to optimize. Fig. 2 shows the encoded network after FROG-preprocessing for this learning task with also added one positive supervision expressed by a formula indicated as F . This rule is in the form that can also account for any unsupervised data as previously described. FROG-preprocessing keeps in the network only the groundings for which either P A or R are true, as the rules F and F R are always verified based on the evidence predicates otherwise. Similar rules could be added to express manifold regularization for the other classes B, C, D.5.3. Case 3: hierarchical classificationComplex classification tasks often involve a large number of classes organized into a hierarchy. Typically, a hierarchy can be represented as a Directed Ordered Acyclic Graph (DOAG), where each node corresponds to a class. A single root node is provided as starting point of the classification process, from where all other nodes can be reached. The classification process explores a set of paths on the graph, where each path ends with a leaf node. A two level-hierarchical classification with nclasses at the first level can be expressed by the rules:∀x p1(x) ∨ . . . ∨ pn(x)∀x pi(x) ⇒ pci1(x) ∨ . . . ∨ pcini(x) i = 1, . . . , nwhere pi, i = 1, . . . , n are the father classes at the first level of the hierarchy, ni is the number of child classes of class pii j, j = 1, . . . , ni are the child classes of pi . Class priors for each category can also be expressed via the rules:and pc∃mi x pi(x)∃mi j x pci j(x)i = 1, . . . , ni = 1, . . . , n j = 1, . . . , niwhere mi and mi j can estimated from the supervised data. This schema can be recursively generalized to taxonomies of arbitrary depth.Example 5.3. For the text categorization example, we assume that C is the only child class of A in the taxonomy. Therefore, the formula F T := ∀d A(d) ⇒ C(d) expresses the taxonomical information that any document belonging to class A belongs also to class C . The resulting constraint obtained from the fuzzy FOL generalization (cid:2)F T of the formula over the set D of available documents is:M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–1651531 − (cid:2)F T(cid:7){ f A(D), f C (D)}(cid:8)= 1 − 12(cid:9)d∈D(cid:3)(cid:2)tT ( f A (d), f C (d))(cid:4)(cid:5)(cid:6)f C (d) ≥ f A(d)f C (d) < f A(d)1f C (d)= 0where tT is the fuzzy generalization of the formula F T using the residuum of the minimum t-norm.5.4. Case 4: transductive SVMsTransductive SVMs (TSVMs) [48] extend SVMs by finding a hyperplane with maximum separation margin for the labeled data and the labeling of the unsupervised data induced by the hyperplane itself. Therefore, Transductive SVMs tend to place the separating hyperplane on low density regions of the input space.TSVMs can be expressed in SBR by adding a FOL formula forcing all pattern classifications to be either true of false:∀x pk(x) ∨ ¬pk(x)where pk(x) is the k-th query predicate that returns true iff a pattern x belongs to a given class. While the above formula is always trivially verified in standard FOL, the same does not apply to the fuzzy generalizations of FOL, where the classification scores can be anywhere in the [0, 1] range.As in Transductive SVMs, trivial solutions are avoided by forcing the balancing between the number of unlabeled patterns to be positively or negatively classified using a prior determined over the supervised data:∃nk x pk(x)∃mk x ¬pk(x) ,where, given the sample Xk of the variable x, nk, mk (nk + mk = |Xk|) are the expected numbers of patterns in the sample for which the unknown predicate should hold true and false, respectively.5.5. Case 5: graph regularizationGraph regularization [52] is a transductive learning task where all generalization happens during training. All the data patterns are arranged as nodes of a graph, whose edges are associated to the weights expressing the degree of similarity of the connected patterns. Some graph nodes are supervised and, therefore, associated with a target value. The learning task consists in assigning a value to all the nodes in the graph, while being smooth over similar (connected) nodes. No feature representation is available in any node and generalization happens at a purely topological level.In SBR, the supervisions for a Graph Regularization task are expressed using the same logic formulas described in Section 5.1. Like for manifold regularization, let R(x, y) be a known relation expressing whether two patterns are con-nected, then the following rule can be used to express the smoothness over the graph connections: ∀x ∀ y R(x, y) ⇒(pk(x) ∧ pk( y)) ∨ (¬pk(x) ∧ ¬pk( y)), for the k-th query predicate pk. The encoded network has the same structure as the example presented in Fig. 2, but with void input representations in the first layer and functions implemented via the special kernel discussed in Section 4.2.6. TrainingTraining in SBR means to determine the weights of the kernel machines in the input layer or, directly, the outputs for the functions with null feature-based inputs. The weights are optimized via gradient descent using a back-propagation schema, where the output layer computes the derivative with respect to each constraint: ∂ Ce. In the quantifier layers, the derivative ∂(cid:2)kof a constraint with respect to each predicate grounding is computed: ∂(cid:2)k. At the propositional level the derivatives with ∂t(cid:2)krespect to the single functions are computed: ∂t(cid:2)k∂ f iare computed: ∂ f i= K i(x j, ·).∂ w i j. At the input level the derivatives with respect to the single parameters The overall derivative of the cost function with respect to the j-th weight of the i-th function w i j is:∂ Ce∂ w i j=(cid:9)k∂ Ce∂(cid:2)k· ∂(cid:2)k∂ w i j=(cid:9)k∂ Ce∂(cid:2)k⎛⎝·(cid:9)t(cid:2)k∂(cid:2)k∂t(cid:2)k·∂t(cid:2)k∂ f i· ∂ f i∂ w i j⎞⎠ .(5)When no input feature representation is provided, the weight is the function value itself w i j = f i j , and no back-propagation over the function weights is needed. Resilient gradient descent using a custom learning rate for each parameter was empirically found to converge very quickly and was therefore used in all the presented experiments.154M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–1656.1. Logic formulas and complexity in optimizationNot all FOL formulas are translated into a constraint which is well suited for optimization. Indeed, this section will show that the general intractability of FOL inference is directly translated into a SBR cost function that is plagued by many local minima.Let’s consider universally quantified FOL formulas in DNF form:∀x1 . . . ∀xnminterm 1(cid:4)(cid:5)(cid:3)(cid:7)n11 P 1(x1) ∧ . . . ∧ n1n P n(xn)) ∨ . . . ∨(cid:6)minterm k(cid:6)(cid:4)(cid:5)(cid:3)(nk1 P 1(x1) ∧ . . . ∧ nkn P n(xn)(cid:8)where ni j determines whether the j-th variable in the i-th minterm is negated or not. Applying a double negation and using the DeMorgan rule, yields the following expression for each grounding:(cid:10)¬¬(cid:8)(cid:7)n11 P 1(x1) ∧ . . . ∧ n1n P n(xn)(cid:7)nk1 P 1(x1) ∧ . . . ∧ nkn P n(xn)∧ . . . ∧ ¬(cid:8)(cid:11)Now converting the above propositional expression using the product t-norm, and assuming to generalize the atoms in the [0, 1] range using the unknown function approximations, we get the constraint:1 − (cid:2)(cid:7)(cid:8)f (X )=1(cid:16)ni=1|X i|(cid:9)(cid:9)k(cid:17)(cid:10). . .x1xn−1r=11 −(cid:17)i∈ Apr(cid:17)(cid:11)(1 − f j(x j))= 0f i(xi)j∈ Anrpr and Anpr(cid:16)(cid:16)i∈ Aj∈ Anrf i(xi) where A1 are the set of non-negated and negated atoms in the r-th minterm and, as in the rest of the paper, we have omitted the squashing function σ (·) in front of each f i(·) which keeps the values in the [0, 1] range. An assignment (1 − f j(x j)) = 1. Therefore, a null contribution will result from verifying the r-th minterm will result in any assignment verifying one minterm when summing over all the groundings. Since all minterms are by construction different and the polynomial equation is continuous and assuming values greater or equal to zero as guaranteed by any t-norm, the resulting expression has as many local minima as the number of true configurations in the truth table for the grounded propositional formula (e.g. this number is by construction equal to the number of minterms in the initial DNF). Therefore, there is a perfect duality between the number of possible assignments of the atoms verifying the FOL formula for a given grounding of the variables, and the number of local minima introduced into the constraint resulting from generalizing the formula to a continuous domain. Not surprisingly, this shows that optimization in the continuous domain is as hard as finding the correct assignments in the original FOL formulation. It is clear that formulas with a single minterm correspond to a convex constraint and have a single minimum, we will see examples of this special case in the following paragraph. While the product t-norm was used in this paragraph, because it is simple to study the solutions of the resulting polynomial, this result can be extended to any strict t-norm, since all strict t-norms are isomorphic to the product t-norm [45].6.2. Stage-based learningAs shown in the previous sections, the cost function is plagued by many local minima when dealing with a non-trivial knowledge base. This section will discuss a heuristic, which has been experimentally proved to allow to successfully train models on large scale datasets.In constraint satisfaction programming [41], picking up the variable with the smallest number of admissible values remaining in its domain is one of the most commonly used heuristics to select the next variable to assign during search [16]. As explained by Haralick and Elliot [19], this heuristic minimizes the depth of the search tree. Following the standard notation used in Rossi et al. [41], we will refer to this heuristic as dom. In the context of SBR, the dom heuristic corresponds to force earlier the formulas with a lower number of possible valid (e.g. verifying the formula) assignments to the atoms to be learned, once the evidence predicates have been grounded. As explained in the previous section, these formulas introduce a lower number of local minima into the cost function.For example, let’s consider the following KB:1 ∀x (P 1(x) ∧ p1(x)) ∨ (¬P 1(x) ∧ ¬p1(x))2 ∀x P 1(x) ⇒ p1(x) ∨ p2(x)3 ∀x p1(x) ∨ p2(x) ∨ p3(x)where the predicates p1, p2, p3 must be learned. The first rule has the same form of the one presented in Section 5.1 to express the fitting of the supervised examples. This rule has the minimum possible degree of freedom as there is only one possible assignment to the atom p1(x) for each evidence grounding of P 1(x). Therefore, this rule should always be the first to be used in training according to the dom heuristic. Not surprisingly, the previous section showed that rules with one single degree of freedom are convex when translated into a continuous constraint using t-norms. Rule 2 has M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165155three and four possible assignments when the evidence grounded predicate P 1(x) holds true and false, respectively. Rule 3has seven possible different assignments of the query predicates. Therefore, the rule 2 should be added to the training process before than the last one, as it has less degrees of freedom. Since the assignments verifying a rule depend on the evidence predicate assignments, we usually use the average over all possible evidence groundings for a rule (in the example the average is 3.5 for rule 2). We leave for further studies how to improve this simple schema. For example, it would be possible to compute the expected number of possible assignments of the query predicates from the distribution of the observed evidence groundings in the training data.The dom heuristic applied to SBR has connections with research in deep learning that has shifted the attention on teaching plans in a more systematic way [4], but also at a more generic level with studies in the field of developmental psychology, since it is well-known that many animals experiment stage-based learning [37]. The experimental results will show that it is indeed beneficial to split the optimization problem into multiple stages, where the constraints are introduced in order of complexity as dictated by dom.7. Collective classificationCollective Classification is the task of performing inference over a set of instances that are connected among each other via a set of relationships. Collective classification is often an easier task than independent pattern classification, because the relationships can be exploited to enforce classification consistency.Collective classification in SBR assumes to have available some FOL knowledge, which is converted into a set of con-straints using the previously described methodology. Given a test set composed of a set of groundings, the collective classification process will force the test set classification assignments to respect the constraints.In particular, let fk(X (cid:14)k) indicate the vector of values obtained by evaluating the kernel machine function fk over the data points of the test set X (cid:14)T ). If no kernel machine has been trained for fk (no examples or no feature representations were available during training), fk(X (cid:14)k)is assumed to be just filled with default values equal to 0.5.k. The set of vectors will be compactly referred to as: f (X (cid:14)) = f 1(X (cid:14)1) ∪ . . . ∪ f T (X (cid:14)Collective classification searches for the values ¯f (X (cid:14)) = ¯f 1(X (cid:14)1) ∪ . . . ∪ ¯fT (X (cid:14)T ) respecting the FOL formulas on the test data, while being close to the prior values established by the kernel machines over the test data:Ccc[ ¯f (X (cid:14)), f (X (cid:14))] = 12T(cid:9)k=1| ¯fk(X (cid:14)k) − fk(X (cid:14)k)|2 +(cid:9)(cid:10)(cid:7)(cid:8)(cid:11))¯f (X (cid:14)1 − (cid:2)hh∂ Ccc[ ¯f (X (cid:14)), f (X (cid:14))]∂ ¯fk(X (cid:14))Optimization can be performed via gradient descend by computing the derivative with respect to the function values:(cid:7)(cid:8)¯f (X (cid:14))∂ ¯fk(X (cid:14))As shown in Equation (6), SBR collective classification reuses the same schema to compute the gradients of the con-as shown in Equation (5). However, whereas the gradient was computed with respect to the functions’ weights straints ∂(cid:2)h∂ ¯fkin the training phase, only the first terms of the chain rule have to be taken into account during collective classification:) − fk(X (cid:14)= ¯fk(X (cid:14)∂(cid:2)h) −(cid:9)(6)(cid:18)(cid:19)h∂(cid:2)h∂ ¯fk=(cid:9)t(cid:2)h∂(cid:2)k∂t(cid:2)h·∂t(cid:2)h∂ ¯fk.Indeed, since the input weights are now fixed, no back-propagation of the derivative of the error down to the weights is needed. This provides an elegant solution to collective classification, which employs the same back-propagation routines used in training with no additional complexity in the implementation.8. SBR as a probabilistic modelIn this section we highlight some probabilistic interpretations of the solutions found by SBR. Given the constraints (cid:2) = {(cid:2)1, . . . , (cid:2)H } computed over the data X , the probability distribution P (V = f |X , (cid:2)) of the possible assignments to the functions f is assumed to follow an exponential model as:P (V = f |X , (cid:2)) = 1Z= 1Z· φpr( f ) · φ(cid:18)(cid:9)exp−(cid:7)(cid:8)f (X ), (cid:2)|| f k||2 +(cid:9)(cid:7)(cid:8)f (X )λh(cid:2)h(cid:19),(cid:7)kf (X ), (cid:2)(cid:8)hwhere Z is a normalization factor, φmeasures how well f respects the constraints and φpr( f ) penalizes irregular solutions. The prior is the expression of the classical Tikhonov regularization in terms of prior probabilities [50] when assuming a Gaussian prior: P pr( f ) ∝ φpr( f ) = exp(− ||2). Therefore,(cid:20)k|| f k156M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165log P (V = f |X , (cid:2)) = − log Z −(cid:9)k|| fk||2 +(cid:9)(cid:7)(cid:8)f (X ).λh(cid:2)hh(7)This result provides a probabilistic interpretation of the SBR formulation given in Equation (2) (the change of sign is due to the fact that the probability is maximized, where in Equation (2) the cost is minimized). In the special case of a constraint representing a formula with only universal quantifiers, it holds that:⎛⎞P (V = f |X , (cid:2)) = 1Z⎝−exp(cid:9)k|| fk||2 +(cid:9)(cid:9)(cid:14)λh(cid:7)(cid:8)f (xih )⎠ ,t(cid:2)hhih(8)where ih iterates over the Gh possible groundings of the h formula Fh, having t(cid:2)h (·) as its the t-norm conversion, xih is the set of pattern representations of the i-th grounding of Fh, f (xih ) indicates the set of values returned by the functions when computed on xih and λ(cid:14)= λhh|Gh| .8.1. SBR and Markov logic networksA Markov network is a model for the joint distribution of a set of variables V and it is composed of an undirected graph expressing the variable dependencies and a set of potential functions. The graph has a node for each variable, and the model has a potential function for each clique in the graph. A potential function is a non-negative function of the state of the corresponding clique. The joint distribution represented by a Markov network is given byP (V = v) = 1Z(cid:17)k(cid:2)(v{k})where v{k} is the state of the variables that appear in that clique and Z is the partition function. Markov networks are often represented as log-linear models, where each clique potential is replaced by an exponentiated weighted sum of features of the state:P (V = v) = 1Z(cid:9)expw j f j(v)jA Markov Logic Network (MLN) [40] is a set of pairs (Fh, λh), where Fh is a formula in first-order logic and λh is a real number. Given a finite set of constants Ch, defining the groundings of all the variables appearing in the Fh , a Markov network MLN is defined as:1. an MLN contains one node for each possible grounding of each predicate, the value of the node is 1 iff the atom is true.2. an MLN contains one feature for each possible grounding of each formula Fh . The value of this feature is equal to 1 iff the ground formula is true. The weight of the feature is λh .The probability distribution over possible assignments v specified by the ground Markov network MLN is given byP (V = v) = 1Zexp(cid:19)λhnh(v)(cid:18)(cid:9)hwhere nh(v) is the number of true groundings of Fh in v.Definition 8.1. A Markov Fuzzy Logic Network (MFLN) is a set of pairs (Fh, λh), where Fh is a formula in first-order logic and λh is a real number. Together with a finite set of constants Ch , defining the groundings of all the variables appearing in the Fh, it defines a Markov network MFLN as follows:1. an MFLN contains one node for each possible grounding of each predicate, the value of the node is the degree of truth of the atom.2. an MFLN contains one feature for each possible grounding of each formula Fh . The value of this feature is equal to the degree of truth of the formula computed via a fuzzy FOL generalization of Fh . The weight of the feature is λh.The resulting network will contain one clique for each grounded formula. An MFLN extends an MLN allowing non-binary features and a continuous degree of truth for the predicates. While a MLN counts the number of true groundings of a formula in the world, an MFLN computes the sum of the degrees of satisfaction of the formula computed via a t-norm.Let’s assume that the unknown predicates are approximated with the output of the kernel machines f applied over the groundings. Let xih be the set of pattern representations associated to the i-th grounding of Fh and f (xih ) be the set of M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165157values returned by the functions when computed over the xih . The value of the feature associated to this grounding is the t-norm value t(cid:2)hTherefore,(cid:8)f (xih )(cid:7).P (cid:2)(V = f ) = 1Zexp⎛⎝(cid:9)(cid:9)λhhih⎞(cid:7)(cid:8)f (xih )⎠ .t(cid:2)h(9)By comparing Equations (8) and (9), it emerges that SBR can be seen as a MLN where the FOL formulas and node values are replaced by their fuzzy generalization with the node values computed by kernel machines.8.2. DiscussionA fundamental difference among MLNs and SBR is that MLNs either in their standard or hybrid version [49] cannotincorporate the feature-based pattern representations if not associating a rule and weight to each feature: for example see how text categorization with MLNs is performed by Domingos and Summer [12]. On the other hand, SBR implements a multi-layer architecture where pattern representations can be dealt using kernel machines at the first layer. This has various advantages in terms of training and flexibility. Indeed, MLNs see all the weights (defining the input and higher level inference) at the same level, while SBR can employ more appropriate and efficient learning schema for the input level, or it can even perform different training phases like the simple strategy employed described in Section 6.2. Unlike MLNs, SBR can deal with continuous, high-dimensional and highly correlated feature vectors. Furthermore, SBR can be defined in cases where the input representation is not vectorial or even unknown, as only the kernel values over the inputs are needed in order to perform training and inference.The connections that have been enlighten in this paragraph between MLNs and SBR suggest that it is possible to reuse the MLN training mechanism to learn the rule weights λh in the output layer of SBR using Equation (9). Like in MLNs this would require to compute the partition function, which often leads to inefficiency and approximations. However, the experimental results show that learning the input layer weights in SBRs is often more effective than solving the MLN learning task in many contexts.9. Experimental resultsThe proposed framework has been the subject of a large experimental analysis that was carried out by using the SBR software package.19.1. Transductive learning: text categorization on the CORA datasetThe CORA research paper dataset is a relational dataset containing information about papers and associated authors [30]. The CORA dataset collects papers classified into a topic hierarchy of 80 classes with 10 classes at the first level.2 In addition, authors have been classified into a set of 10 classes depending on their major topic of research interest. A random sample of 2000 papers belonging to at least one of the 10 top level classes was extracted together with the 3928 authors having at least one publication in the selected sample of papers. Each paper was associated with a vectorial representation containing the title represented as bag-of-words with TF-IDF weights. There is no profile of authors, being symbolic entities without feature representation. The learning task consists of predicting the category of the papers and the author research area. This is a multi-label dataset, since authors can be associated to multiple categories. Papers have been split into three sets: published before the year 1995, papers published in year 1995 and all later papers. The resulting sets contain 949 papers and 2272 authors, 316 papers and 605 authors, and 735 papers and 1051 authors, respectively. The three sets form the pools from which the training, validation and test datasets are sampled from, respectively. This simulates a real world scenario, where the training process is performed at a certain time and testing is expected to involve new incoming papers. In particular, five folds have been generated by randomly selecting n% of the papers and n% of authors (n = 10, 20, 30, 40, 50)for which supervisions are kept in the first and second sets as training and validation data. Experiments have been carried out in a transductive context, where the test data is available as unsupervised data during training, and by averaging over 5folds.Knowledge base The available prior knowledge is modeled in terms of FOL predicates. Let B := {false, true} and let us denote the paper and author domains by P and A, respectively. Notice that while P ∈ Rd, A is simply a set of author identifiers. Let us define the following predicates according to the relational representation in Fig. 3:1 The SBR package can be downloaded at https :/ /sites .google .com /site /semanticbasedregularization /home /software.2 The data base can be downloaded at http://people.cs.umass.edu/~mccallum/data.html.158M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165Fig. 3. Relational representation of the CORA Research Paper Dataset.Ci(·) : P → B, Ci(x) = true ⇔ x is of category i = 1, . . . , 10ACi(·) : A → B, ACi(x) = true ⇔ x is of category i = 1, . . . , 10CoAuthor(·, ·) : A2 → B, CoAuthor(x, y) = true ⇔ x, y are co-authorsAuthorOf (·, ·) : A × P, AuthorOf (x, y) = true ⇔ x is author of yCite(·, ·) : P 2 → B2, Cite(x, y) = true ⇔ x cites yWhen considering all the categories i = 1, . . . , 10, the knowledge base (KB) that we use to represent the learning task is composed of 52 rules:0 ∀x P i(x) ⇒ Ck(x) , ∀x Ni(x) ⇒ ¬Ck(x)i ∀x∀ y Cite(x, y) ⇒ (Ci(x) ∧ Ci( y)) ∨ (¬Ci(x) ∧ ¬Ci( y))ii ∀x∀ y CoAuthor(x, y) ⇒ (ACi(x) ∧ ACi( y)) ∨ (¬ACi(x) ∧ ¬ACi( y))iii ∀x∀ y AuthorOf (x, y) ⇒ (ACi(x) ∧ Ci( y)) ∨ (¬ACi(x) ∧ ¬Ci( y))iv ∀x10(cid:21)(cid:7)i=1(cid:8)[¬]i(cid:16)=1C1(x) ∧ [¬]i(cid:16)=2C2(x) ∧ · · · ∧ [¬]i(cid:16)=10C10(x)v ∀x AC1(x) ∨ AC2(x) ∨ . . . ∨ AC10(x)The 0 formulas express the supervised data. The 10 i formulas state that papers tend to cite other papers of the same category, while the ii ones state that co-authors belong to the same research area. The iii formulas enforce the coherence of the categories given to papers and authors. iv is a formula in Disjunctive Normal Form stating the exclusive classification assumption ([¬]i(cid:16)= j adds a negation in front of each predicate excluding the j-th), such that each paper is assigned to one and only one of the 10 classes. Finally, v states the close-world assumption forcing each author to be assigned to at least one of the 10 classes.Results and discussion In a first experiment we validated the dom heuristic proposed in Section 6.2. In particular, SBR was tested using the following configurations:• (0, i, ii, iii, iv, v): introducing all the constraints together at the beginning of training;• (0), (i, ii, iii, iv, v): learning from the supervised data first and, after the training data has been learned, introducing all the other constraints. In particular, the second group of constraints is added when the gradient module becomes small, which was empirically observed to happen after around 30 iterations of gradient decent in this experiment;• (0), (i, ii, iii), (iv), (v): splitting the training into multiple stages, where the constraints are sequentially introduced according to the dom heuristic by looking at the degree of freedom in the assignments of each formula. A new set of constraints is added when the gradient module becomes small. The formulas in the sets (i, ii, iii) have the same degree of freedom (possible different assignments to the query predicates verifying the formula) and are introduced together.Table 1 reports the classification scores for the 3 different learning schemas, obtained on the test set for patterns in the paper and research area domains. Since each pattern in the paper domain belongs to a single class (single-label classification task), standard classification accuracy has been used as metric for this task. The F1 metric has been used for the research area domain, since this is a multi-label multi-class classification task. For all configurations, SBR used the minimum t-norm and the linear kernel with meta-parameters selected to maximize the classification accuracy for the paper category on the validation set of the considered fold. It is clear from the results that the dom heuristic effectively breaks the learning complexity, allowing to find better solutions. As shown by the smaller gains from moving from the (0), (i, ii, iii, iv, v) to the (0), (i, ii, iii), (iv), (v) learning schema, a significant portion of the gains comes from introducing higher level semantic rules after the predicates have been approximated by fitting the supervised data.M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165159Table 1Results on the CORA dataset (average over the 5 available folds) using different Semantic Based Regularization models, trained using a variable number of supervised patterns and different heuristics controlling the sequence of incorporation of the FOL rules in the training process.Papers (accuracy)SBR (0,i,ii,iii,iv,v)SBR (0), (i,ii,iii, iv,v)SBR (0), (i,ii,iii), (iv), (v)Research areas (F1)SBR (0,i,ii,iii,iv,v)SBR (0), (i,ii,iii,iv,v)SBR (0), (i,ii,iii), (iv), (v)10%0.4790.4920.51110%0.4640.4710.48220%0.5380.5540.56520%0.5110.5200.52630%0.5840.5990.61230%0.5510.5650.56140%0.6160.6300.63840%0.5770.5900.59550%0.6230.6470.65650%0.5850.6060.610A comparison against Markov Logic Networks both in their discrete (MLN) and hybrid versions (HMLN) has been carried out by using the implementation provided by the Alchemy software package3 using discriminative weight training optimized via rescaled conjugate gradient, which provided the best results on this task. MLNs have been trained using the same knowledge base previously employed by SBR, where rules iv and v has been added as hard constraints. Furthermore, the following formulas have been added to take care of the bag-of-words representation of the page by linking the words to the document categories in the MLN rule definitions:HasWord(+word, x) ⇒ C(x, +class) ,where x is a variable spanning over all the papers and, following the Alchemy syntax, the “+” means that one rule is added for each (word, class) pair. This follows the experimental set up for text categorization suggested in Domingos et al. [12]. In the case of Hybrid Markov Logic Networks, the TF-IDF score is used to associate a numeric feature to each ground clause for the previous rule. In particular, any TF-IDF score below 1 has been gaussian decayed using Alchemy soft equality penalty function.In order to compare against Probabilistic Soft Logic (PSL), some modifications to the KB have been required, since PSL can process only rules with conjunctive bodies and single-literal head (e.g. any propositional formula obtained after the evaluation of the grounded predicates must be a Horn Clause). Therefore, each formula, creating a manifold structure over the authors or papers, has been split into two corresponding formulas for the PSL evaluation, such that the new formulas can be processed by PSL and the logical AND of them is equivalent to the original formulation. For example the first manifold rule in SBR has been replaced by the pair of formulas:∀x∀ y Cite(x, y) ∧ Ci(x) ⇒ Ci( y)∀x∀ y Cite(x, y) ∧ ¬Ci(x) ⇒ ¬Ci( y)The same procedure has been performed for the formulas expressing the manifold with respect to the CoAuthor and Authorpredicates. The formulas implementing the logic OR operation over the classes cannot be implemented in PSL. Unlike SBR, PSL has no direct integration with an SVM processing the input pattern representations. However, like done in the Bröcheler et al. [5] for their Wikipedia Category Prediction experiment, PSL can employ the output of a previously trained feature-based classifier as a prior for its assignments. This was done by reusing the same SVMs previously trained and then adding the following rules to the PSL learning task definition:∀x SVMCategory(x, i) ⇒ Ci(x)∀x ¬SVMCategory(x, i) ⇒ ¬Ci(x)where SVMCategory(x, i) is an evidence predicate holding a true value iff the SVM assigns the tag i to the pattern x (e.g. the SVM trained for the tag i provides an output greater than 0 when processing as input the pattern x). PSL formula weights have been learned over the validation set using the LazyMaxLikelihoodMPE algorithm (Most Probable Explanation Max likelihood), which provided the best results on the task and is also the employed training algorithm in all the examples provided with the PSL software package.SBR has also been compared against standard, Structured and Transductive SVMs for the paper classification task. Struc-tured SVMs have been used to perform native multi-class classification as explained by Tsochantaridis et al. [47]. Like for SBR, a linear kernel with meta-parameters selected to maximize the accuracy and F1 scores on the validation set have been used for all SVM experiments. The libSVM software package4 was used as implementation for plain SVMs, while the SVMlight software package5 was used for Transductive and Structured SVM. Since authors are not associated with a 3 http :/ /alchemy.cs .washington .edu/.4 http :/ /www.csie .ntu .edu .tw /~cjlin /libsvm/.5 http :/ /svmlight .joachims .org/.160M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165Table 2Accuracy and F1 scores (average over the 5 available folds) on the CORA dataset for patterns in the paper and research area domains, respectively. Papers have been classified using plain SVMs (SVM), Structured SVMs (SSVM), Transductive SVMs (TSVM), Semantic Based Regularization (SBR), plain (MLN) and Hybrid (HMLN) Markov Logic Networks and PSL using SVM (PSL-SVM) or Transductive SVM (PSL-TSVM) as base classifier providing the classification priors. The classification has been performed for different numbers of supervised patterns. Research area classification has been carried out using only SRL methods (SBR, and the different MLN and PSL versions), which can process patterns not associated to a vectorial feature representation.Papers (accuracy)SVMSSVMTSVMMLNHMLNPSL-SVMPSL-TSVMSBRResearch areas (F1)MLNHMLNPSL-SVMPSL-TSVMSBR10%0.2110.3520.3570.2720.2570.2580.3960.51110%0.2780.2750.2320.3650.48220%0.2740.3850.3960.3360.3280.3670.4250.56520%0.3350.3220.3040.3940.52630%0.3170.4100.4190.3820.3750.4040.4420.61230%0.3720.3750.3450.4190.56140%0.3480.4190.4360.4070.4070.4430.4600.63840%0.3860.3950.3850.4340.59550%0.3760.4300.4530.4350.4260.4600.4720.65650%0.4170.4040.4030.4470.610feature representation, they can only be classified by a purely relational approach and no comparison against SVM-based classification schemas was possible.PSL has been tested using either SVM or Transductive SVM as base classifier providing a prior for the classification. These two versions will been indicated as PSL-SVM and PSL-TSVM, respectively.Table 2 reports the accuracy and F1 scores on the test set for patterns representing papers and authors, respectively. Since some methods do not allow to express exclusive classification via an explicit rule in the KB, the output class for these methods has been selected as the class associated to the highest value among the classification outputs for each pattern.Metrics in bold represent statistically significant gains (95%) over all the other classifiers. Since this is a transductive learning task, it is no surprise that Transductive SVMs are the best performers among the non-relational classifiers. Both PSL-SVM and PSL-TSVM outperform the corresponding base non-relational classifiers, and PSL-TSVM outperforms PSL-SVM because of the better performing base classifier. The SBR model outperforms all the non-relational classifiers, since it can integrate a much richer prior knowledge. The large improvement of SBR over the tested SRL models is due to two important factors. First, SBR provides a larger flexibility in designing the KB: some rules had to be dropped or modified in the PSL definitions, not having a conjunctive body and single head. Secondly, SBR integrates the processing of the input feature representations and of the higher level logic knowledge. This means that SBR natively back-propagates the output of the in-ference process performed during learning using the KB to the underlying SVMs, significantly improving their performances when little supervised data is available. PSL uses a frozen SVM as prior for its classifications and has no ability to improve the underlying classifier using the unsupervised data. This is huge advantage for SBR in a transductive context with a large portion of unsupervised data.9.2. Collective classification in WebKBThis experiment evaluates the proposed collective classification approach on the WebKB benchmark. The WebKB dataset is a relational dataset which consists of labeled web pages from the computer science departments of 4 universities. We used the version of the dataset from Craven and Slattery [7], used also in many other following papers [29,32], which features about 4100 webpages and 10 000 hyperlinks. Each webpage is associated with a vectorial representation of its content represented as bag-of-words, while each link is associated with its anchor text. Each webpage belongs to at least one of the 5 categories: person, course, department, researchproject, other. In addition, the anchor’s links belong at least one of the 5 classes: toPerson, toCourse, toDepartment, toResearchProject, toOther, depending on the category of the pointed webpage. The goal of the benchmark is to predict the categories of the webpages and of the links from the given data.Each university represents an independent world, therefore a 4-fold crossvalidation is the most natural evaluation pro-cedure to evaluate the performance of classification. 4 folds are generated by keeping the data of one university out as test set, then selecting the first two other remaining universities as training set and the last one as validation data.Knowledge base Let us assume that W and A denote the set of web pages and anchor text identifiers, respectively. B rep-resents a Boolean value. We consider the following predicates, following the relational representation shown in Fig. 4Ci(·) : W → B, Ci(x) = true ⇔ x is of category i = 1, . . . , 5M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165161Fig. 4. Relational representation of the WebKB Dataset.LCi(·) : A → B, LCi(x) = true ⇔ x is of category i = 1, . . . , 5Link(·, ·) : W 2 → B Link(x, y) = true ⇔ x is linked to yLinkTo(·, ·) : A × W → B Link(x, y) = true ⇔ x is linked to yThe following KB was used for the task:0 ∀x P i(x) ⇒ Ck(x) , ∀x Ni(x) ⇒ ¬Ck(x)i ∀x∀ y Link(x, y) ⇒ (Ci(x) ∧ C j( y)) ∨ (¬Ci(x) ∧ ¬C j( y))ii ∀x∀ y LinkTo(x, y) ⇒ (LCi(x) ∧ Ci( y)) ∨ (¬LCi(x) ∧ ¬Ci( y))iii ∀x C1(x) ∨ C2(x) ∨ C3(x) ∨ C4(x) ∨ C5(x)iv ∀x LC1(x) ∨ LC2(x) ∨ LC3(x) ∨ LC4(x) ∨ LC5(x)The 0 formulas express the fitting of the supervised data. The i formulas state that linked pages tend to be of the same class (manifold regularization), while the ii ones dictate classification consistency among the predicted class for pages and anchors. Formulas iii and iv impose the close-world assumption, forcing each web page and anchor to belong to at least one of the 5 classes in the corresponding domain. The overall knowledge base consists of 42 rules.The following formulas representing how words are correlated to webpage and link categories have also been added to the MLN rule definitions:HasWord(+word, page) ⇒ Category(page, +class) ,HasWord(+word, anchor) ⇒ AnchorCategory(anchor, +anchorclass) ,where the “+” is used to define one rule for each (word, class) and (word, anchorclass) pairs, respectively. The rules iii, ivhave been added as hard constraints in the MLN experiments as they should be always verified.For the PSL experimental comparison, the same procedure described in the previous experiment has been used to express the manifolds built by the Link and LinkTo predicates. The input pattern representations have been embedded into the PSL classification by adding a set of rules expressing the consistency between PSL and SVM class assignments, where one SVM has been previously trained for each class. PSL formula weights have been learned over the validation set using the LazyMaxLikelihoodMPE algorithm.Results and discussion Since the training set for each single fold is completely supervised, one SBR classifier per fold has been trained using the 0 rules converted via the minimum t-norm (e.g. a plain kernel machine with a linear kernel). Classification performance on the validation set was used to select the optimal regularization parameter for each fold. The output of the learned functions has been used to initialize the collective classification step for the validation and test sets. In particular, collective classification was performed separately on the validation set of each fold using different λc parameters, then selecting the ¯λc value providing the best results for each fold. Finally, collective classification was performed on the test set of each fold, using λc = ¯λc , as selected at the previous step. The results obtained by Semantic Based Regularization using the minimum t-norm and collective classification (SBR-CC) have been compared against a plain SVM and Markov Logic Network (MLN). We used the Alchemy software implementation of MLNs, using discriminative weight training optimized via rescaled conjugate gradient. The libSVM software package was used to implement plain SVMs using a linear kernel. The SVM C parameter (trade off between model complexity and fitting of the supervised data) was selected to maximize the classification metrics on the validation set.Table 3 shows the F1 and AUC scores obtained on the test set for the webpage and anchor link categories as an average over the 4 folds. SVM classification metrics are very good for webpages, where the rich feature-based representations allow to well discriminate the patterns. SVM performances are much worse for anchors, where the anchor text represented in the feature vector is small, noisy and often not very representative. MLNs perform slightly worse than SVMs on the webpage classification task, because MLNs do not get full advantage of the information available in the feature vectors. On the other hand, MLNs can get advantage of the available KB to improve the classification of the anchors with respect to SVMs. PSL162M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165Table 3F1 and AUC scores on the test set for the webpage and anchor link categories of the WebKB Dataset using a plain SVM (SVM), PSL, Markov Logic Networks (MLN) and Semantic Based Regularization with collective classification (SBR-CC) as an average over the 4 WebKB folds.SVMMLNPSLSBR-CCF1Webpage0.7680.7300.7770.810Anchors0.3190.5640.5100.700AUCWebpage0.8610.6700.7630.895Anchors0.6340.7630.7530.775performs quite well on the webpage classification task thanks to the good performance of its base classifier. However, the less rich additional KB that can be integrated in PSL limits its performance on the anchor patterns. SBR-CC is the best performer on both domains (even if with a small margin over the best competitor for each separate domains): it can fully get advantage of the feature-based representations, plus it can perform inference over the anchor domain using the entire KB.9.3. ArnetminerThe Arnetminer Movie benchmark6 is a relational dataset containing information about movies and associated directors, writers and actors. The Arnetminer dataset assigns a set of tags to each movie. We selected all the movies with at least one tag containing one of the 12 most common keywords: horror, drama, comedy, television, teen, musical, adventure, western, mystery, thriller and biographical. Each of these tags was assumed to correspond to an underlying genre that we want to predict. The goal of this experiment is to predict the movie genres by looking at the movie title, represented as bag-of-words. Please note that this is a multi-label dataset, since movies can be associated to multiple genres. The movies have been split into three sets: one set composed by the movies released up to the year 1979, another by the movies from 1980 to 1997 and, finally, and all later movies have been added to the last set. The resulting datasets contain 7567, 4234 and 5653 movies, respectively.The first, second and third sets form the pools from which the training, validation and test data are selected for the single experiments, respectively. This is to simulate a real world scenario, where training is performed at some point in time over some available previous data and then the trained model is used to perform predictions over newly received data. A variable percentage of supervised labels from the movies in the first and second sets has been kept for training to evaluate how the performance is affected by the amount of labeled data. The remaining unlabeled patterns are still provided in the training set as unsupervised data. 5 different folds have been generated by performing different samples for each percentage of labels that are kept available in the training and validation sets.Together with the rules expressing the fitting of the supervised data, the following rules have been added as prior knowledge for each tag Ci of the dataset:(cid:7)∀x∀ y SameDirector(x, y) ⇒∀x∀ y SameProducer(x, y) ⇒∀x∀ y SameWriter(x, y) ⇒(cid:8)Ci(x) ∧ Ci( y)(cid:8)Ci(x) ∧ Ci( y)(cid:8)Ci(x) ∧ Ci( y)(cid:7)(cid:7)(cid:7)(cid:8)¬Ci(x) ∧ ¬Ci( y)(cid:8)¬Ci(x) ∧ ¬Ci( y)(cid:8)¬Ci(x) ∧ ¬Ci( y)∨∨∨(cid:7)(cid:7)to express the fact that movies sharing the same director, producer or writer tend to belong to the same genres. The following two rules for each tag Ci express the Transductive SVM assumption:∀x Ci(x) ∨ ¬Ci(x)∃nx Ci(x) ∧ ∃m x ¬Ci(x) : n + m = Nwhere N is the overall number of available movies in the considered dataset and n, m are estimated looking at the distri-bution of Ci, ¬Ci in the training data of each fold, respectively.After training the SBR models using the minimum t-norm and the linear kernel for different λc meta-parameters, the best model has been selected on the validation set. Finally, Semantic Based Regularization collective classification (SBR-CC) has been performed over the test set using the selected model. The SBR-CC results have been compared against Semantic Based Regularization (SBR), where no collective classification is performed on the test set, but the trained kernel machines are directly used to perform the predictions. Furthermore, SBR-CC was compared against standard SVM (using only supervised labels), Transductive SVM (TSVM), Laplacian SVM (LSVM) using the same director, producer or writer rules to build the manifold of data and Probabilistic Soft Logic using SVM (PSL-SVM) and TSVM classifiers as priors (PSL-TSVM). One separate binary classifier for each class has been built for SVM, LSVM, TSVM. In particular, the same software simulator used for 6 It can be downloaded at http :/ /arnetminer.org /lab-datasets /soinf.M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165163Fig. 5. F1 scores as average over 5 folds on the Arnetminer dataset obtained using SVM, TSVM, LSVM, PSL using SVM (PSL-SVM) or Transductive SVM (PSL-TSVM) as base classifier providing the classification priors, SBR and SBR with collective classification (SBR-CC) varying the number of supervised patterns.the experiments in Melacci and Belkin [31] was used as implementation of Laplacian SVMs. The same software simulators used in the previous experiments have been employed as implementations of SVMs and TSVMs. All SVM-based classifiers employed a linear kernel and the models have been trained using different meta-parameters. The best model has been fold-by-fold selected by cross validation on the validation set.Similarly to the previous experiments, each formula, creating a manifold structure over the movies, has been split into two corresponding formulas for the PSL evaluation. For example the first manifold rule in SBR has been replaced by the pair of formulas in the PSL rule definitions:∀x∀ y SameDirector(x, y) ∧ Ci(x) ⇒ Ci( y)∀x∀ y SameDirector(x, y) ∧ ¬Ci(x) ⇒ ¬Ci( y)The same procedure has been performed for the formulas expressing the manifold with respect to the SameProducer and SameWriter predicates. The formulas implementing the Transductive SVM assumption cannot be expressed in PSL and have been not used for this experimental comparison. Like for the previous experiments, the rules expressing the consistency be-tween PSL class assignments and the output of the SVMs trained for each class have been added to the PSL rule definitions. PSL formula weights have been learned over the validation set using the LazyMaxLikelihoodMPE algorithm, which provided the best results on this task. Finally, the PSL collective classification step using the rule weights learned in training has been performed over the test set. The output of the collective classification step has been used to determine PSL classification performances.Fig. 5 reports the classification results as an average over the 5 folds. SVMs are, as expected, the worst performers on this task, as they are the only tested model that cannot benefit from the unsupervised data seen in training. PSL, TSVM and LSVM perform similarly, but they are outperformed by SBR. PSL-TSVM takes advantage of the better performing base classifier and outperforms PSL-SVM. Both PSL versions perform worse than SBR in this task, because PSL cannot get advantage of the unsupervised data to improve the underlying classifiers that it uses as classification priors. Finally, SBR with collective classification (SBR-CC) slightly improves over SBR in all tested configurations by enforcing the rules also over the test set.10. ConclusionsIn this paper we have proposed a semantic-based regularization approach for learning and inference that generalizes both different kernel machine models, processing real-valued features, and statistical relational learning approaches working on symbolic identifiers and domain knowledge expressed in term of FOL formulas. The resulting inference mechanism also involves a novel collective classification schema that exploits real-valued features. As shown in the experimental results, this is useful whenever the feature representation is relatively poor, so as the involvement of the constraints at the time of test significantly improves the performance. This paper significantly extends the theoretical results previously published by presenting intriguing connections with probabilistic models and proposing novel heuristics allowing to tackle more complex learning tasks.164M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165AcknowledgementsThis research was partially supported by the research grant 2009LNP494 from the PRIN2009 program of the Italian MURST.ReferencesRes. 7 (2006) 2434.gence, UAI, 2010, pp. 73–82.Springer, 2003, pp. 32–47.2003, pp. 107–114.Learning, 2004, pp. 49–54.[1] F. Baader, The Description Logic Handbook: Theory, Implementation, and Applications, Cambridge University Press, 2003.[2] J.F. Bard, Practical Bilevel Optimization: Algorithms and Applications, Nonconvex Optimization and Its Applications, vol. 30, Springer, 1998.[3] M. Belkin, P. Niyogi, V. Sindhwani, Manifold regularization: a geometric framework for learning from labeled and unlabeled examples, J. Mach. Learn. [4] Y. Bengio, Curriculum learning, in: Proceedings of the 26th Annual International Conference on Machine Learning, ICML0, 2009, pp. 41–48.[5] M. Broecheler, L. Mihalkova, L. Getoor, Probabilistic similarity logic, in: Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelli-[6] A. Caponnetto, C.A. Micchelli, M. Pontil, Y. Ying, Universal multi-task kernels, J. Mach. Learn. Res. 9 (2008) 1615–1646.[7] M. Craven, S. Slattery, Relational learning with statistical predicate invention: better models for hypertext, Mach. Learn. (2001) 97–119.[8] C. Cumby, D. Roth, Learning with feature description logics, in: Proceedings of the 12th International Conference on Inductive Logic Programming, [9] C. Cumby, D. Roth, On kernel methods for relational learning, in: Proceedings of the Twentieth International Conference on Machine Learning, ICML, [10] M. Diligenti, M. Gori, M. Maggini, L. Rigutini, Bridging logic and kernel machines, Mach. Learn. 86 (2012) 57–88.[11] P. Domingos, M. Richardson, Markov logic: a unifying framework for statistical relational learning, in: ICML-2004 Workshop on Statistical Relational [12] P. Domingos, M. Sumner, The alchemy tutorial, http://alchemy.cs.washington.edu/tutorial/tutorial.pdf, 2010.[13] N. Friedman, L. Getoor, D. Koller, A. Pfeffer, Learning probabilistic relational models, in: Proceedings of the International Joint Conference on Artificial [14] G.M. Fung, O.L. Mangasarian, J.W. Shavlik, Knowledge-based support vector machine classifiers, in: Advances in Neural Information Processing Systems, [15] G.M. Fung, O.L. Mangasarian, J.W. Shavlik, Knowledge-based nonlinear kernel classifiers, in: Learning Theory and Kernel Machines, Springer, 2003, Intelligence, IJCAI, 1999, pp. 1300–1309.2002, pp. 521–528.pp. 102–113.[16] S.W. Golomb, L.D. Baumert, Backtrack programming, J. ACM 12 (1965) 516–524.[17] M. Gupta, J. Qi, Theory of t-norms and fuzzy inference methods, Fuzzy Sets Syst. 40 (1991) 431–450.[18] P. Hajek, The Metamathematics of Fuzzy Logic, Kluwer, 1998.[19] R.M. Haralick, G.L. Elliott, Increasing tree search efficiency for constraint satisfaction problems, Artif. Intell. 14 (1980) 263–313.[20] D. Haussler, Convolution kernels on discrete structures, Technical report, Department of Computer Science, University of California at Santa Cruz, 1999.[21] P. Hitzler, S. Holldobler, A.K. Sedab, Logic programs and connectionist networks, J. Appl. Log. 2 (2004) 245–272.[22] T.N. Huynh, R.J. Mooney, Discriminative structure and parameter learning for Markov logic networks, in: Proceedings of the 25th International Confer-ence on Machine Learning, ICML, ACM, 2008, pp. 416–423.[23] S. Kok, P. Domingos, Learning the structure of Markov logic networks, in: Proceedings of the 22nd International Conference on Machine Learning, ICML, ACM, 2005, pp. 441–448.Intelligence, 2006, pp. 389–394.[24] N. Landwehr, A. Passerini, L. De Raedt, P. Frasconi, kfoil: learning simple relational kernels, in: Proceedings of the AAAI Conference on Artificial [25] N. Landwehr, A. Passerini, L. Raedt, P. Frasconi, Fast learning of relational kernels, Mach. Learn. (2010).[26] F. Laurer, G. Bloch, Incorporating prior knowledge in support vector machines for classification: a review, Neurocomputing 71 (2009) 1578–1594.[27] Q.V. Le, A.J. Smola, T. Gärtner, Simpler knowledge-based support vector machines, in: Proceedings of the 23rd International Conference on Machine [28] M. Lippi, P. Frasconi, Prediction of protein β-residue contacts by Markov logic networks with grounding-specific weights, Bioinformatics 25 (2009) Learning, ICML, ACM, 2006, pp. 521–528.2326–2333.[29] D. Lowd, P. Domingos, Efficient weight learning for Markov logic networks, in: Proceedings of the Eleventh European Conference on Principles and Practice of Knowledge Discovery in Databases, 2007, pp. 200–211.[30] A. McCallum, K. Nigam, J. Rennie, K. Seymore, Automating the construction of Internet portals with machine learning, Inf. Retr. 3 (2000) 127–163.[31] S. Melacci, M. Belkin, Laplacian support vector machines trained in the primal, J. Mach. Learn. Res. 12 (2011) 1149–1184.[32] L. Mihalkova, R.J. Mooney, Bottom-up learning of Markov logic network structure, in: Proceedings of the 24th International Conference on Machine Learning, ACM, New York, NY, USA, 2007, pp. 625–632.[33] S. Muggleton, H. Lodhi, A. Amini, M.J. Sternberg, Support vector inductive logic programming, in: Discovery Science, Springer, 2005, pp. 163–175.[34] J. Neville, D. Jensen, Relational dependency networks, J. Mach. Learn. Res. 8 (2007) 653–692.[35] F. Niu, C. Ré, A. Doan, J. Shavlik, Tuffy: scaling up statistical inference in Markov logic networks using an RDBMS, in: Proceedings of the VLDB, 2011, pp. 373–384.[36] V. Novák, First-order fuzzy logic, Stud. Log. 46 (1987) 87–109.[37] J. Piaget, La psychologie de l’intelligence, Armand Colin, Paris, 1961.[38] T. Poggio, F. Girosi, A theory of networks for approximation and learning, Technical report, MIT, 1989.[39] L.D. Raedt, P. Frasconi, K.S.M. Kersting (Eds.), Probabilistic Inductive Logic Programming, Lecture Notes in Artificial Intelligence, vol. 4911, Springer, 2008.[40] M. Richardson, P. Domingos, Markov logic networks, Mach. Learn. 62 (2006) 107–136.[41] F. Rossi, P. Van Beek, T. Walsh, Handbook of Constraint Programming, Elsevier, 2006.[42] B. Scholkopf, A.J. Smola, Learning with Kernels, MIT Press, Cambridge, MA, USA, 2001.[43] J.W. Shavlik, S. Natarajan, Speeding up inference in Markov logic networks by preprocessing to reduce the size of the resulting grounded network, in: Proceedings of the International Joint Conference on Artificial Intelligence, IJCAI, 2009, pp. 1951–1956.[44] P. Singla, P. Domingos, Memory-efficient inference in relational domains, in: Proceedings of the 21st AAAI Conference on Artificial Intelligence, AAAI [45] J.T. Starczewski, Advanced Concepts in Fuzzy Logic and Systems with Membership Uncertainty, Springer, 2012.[46] S.D. Tran, L.S. Davis, Event modeling and recognition using Markov logic networks, in: Proceedings of the European Conference of Computer Vision, Press, 2006, pp. 488–493.ECCV, Springer, 2008, pp. 610–623.M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165165[47] I. Tsochantaridis, T. Joachims, T. Hofmann, Y. Altun, Large margin methods for structured and interdependent output variables, J. Mach. Learn. Res. (2005) 1453–1484.[48] V. Vapnik, The Nature of Statistical Learning Theory, 2nd edn., Springer Verlag, 2000.[49] J. Wang, P. Domingos, Hybrid Markov logic networks, in: Proceedings of the 23-rd AAAI Conference on Artificial Intelligence, 2008, pp. 1106–1111.[50] P.M. Williams, Bayesian regularization and pruning using a Laplace prior, Neural Comput. 7 (1995) 117–143.[51] L.A. Zadeh, Fuzzy sets, Inf. Control 8 (1965) 338–353.[52] D. Zhou, B. Schölkopf, Regularization on discrete spaces, Pattern Recognit. (2005) 361–368.