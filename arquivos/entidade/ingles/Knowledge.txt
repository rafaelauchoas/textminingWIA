Artificial Intelligence 115 (1999) 65–105Knowledge-based proof planningErica Melis (cid:3), Jörg Siekmann 1Universität des Saarlandes, Fachbereich Informatik and DFKI, D-66041 Saarbrücken, GermanyReceived 1 February 1999AbstractKnowledge-based proof planning is a new paradigm in automated theorem proving (ATP) whichswings the motivational pendulum back to its AI origins in that it employs and further develops manyAI principles and techniques such as hierarchical planning, knowledge representation in frames andcontrol-rules, constraint solving, tactical and meta-level reasoning. It differs from traditional search-based techniques in ATP not least with respect to its level of abstraction: the proof of a theoremis planned at an abstract level and an outline of the proof is found. This outline, i.e., the abstractproof plan, can be recursively expanded and it will thus construct a proof within a logical calculus.The plan operators represent mathematical techniques familiar to a working mathematician. Whilethe knowledge of a domain is specific to the mathematical field, the representational techniquesand reasoning procedures are general-purpose. The general-purpose planner makes use of thismathematical domain knowledge and of the guidance provided by declaratively represented control-rules which correspond to mathematical intuition about how to prove a theorem in a particularsituation. These rules provide a basis for meta-level reasoning and goal-directed behaviour. Wedemonstrate our approach for the mathematical domain of limit theorems, which was proposed as achallenge to automated theorem proving by the late Woody Bledsoe. Using the proof planner of the(cid:127)MEGA system we were able to solve all the well known challenge theorems including those thatcannot be solved by any of the existing traditional systems. (cid:211) 1999 Elsevier Science B.V. All rightsreserved.Keywords: Theorem proving; Planning; Automated proof planning; Meta-level reasoning; Integrating constraintsolvers(cid:3)Corresponding author. Email: melis@cs.uni-sb.de.1 Email: siekmann@dfki.de.0004-3702/99/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 9 9 ) 0 0 0 7 6 - 41999 Elsevier Science B.V. All rights reserved.66E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105Automated theorem proving : : : is not the beautiful processwe know as mathematics. This is ‘cover your eyes withblinders and hunt through a cornfield for a diamond-shapedgrain of corn’. Mathematicians have given us a great dealof direction over the last two or three millennia. Let us payattention to it.Woody Bledsoe, 19861. IntroductionSince the early days of artificial intelligence (AI) research, two schools have existed inautomated theorem proving, the logic-oriented approaches and the rather psychologicallyoriented approaches which try to simulate people. For example, atthe DartmouthConference in 1956, two systems found wide attention and are considered ‘classic’ today:Martin Davis’ decision procedure based on Presburger’s Arithmetic [30] which is the grandancestor of logic-oriented systems and the now seminal Logic Theorist [97] that pioneeredthe second category. In 1954, Davis’ system was the first system ever to prove a theoremwith a computer (“The sum of two even numbers is even”.) and about a year later, AlanNewell and Herb Simon finished their joint system, later called the Logic Theorist, whichsucceeded in proving many theorems from Principia Mathematica [106] and sparked offthe field of artificial intelligence.Since Hao Wang’s work [121] and with the development of the resolution principle in1965 [104], the logic-oriented, search-based paradigm has by and large dominated the field,and by far the strongest systems were built within this train of thought.Other ideas were, however, never fully absent. Woody Bledsoe, among others [5,19,103], advocated automated theorem proving based on mathematical knowledge andpractice [13]. Bledsoe’s beautiful quotation above shows his scepticism for purely search-based theorem proving, and in fact he never believed that it would succeed in provingdifficult theorems even in mathematically well-understood domains. He developed a visionof the concepts and procedures necessary for automated theorem proving since he thoughtof himself as “one of the researchers working on resolution type systems who ‘made theswitch’: : : and became convinced that we were on the wrong track” [12].Traditional automated theorem proving is based on general-purpose machine-orientedlogical calculi such as the resolution calculus [104], the tableaux- [114], or the matrixmethods [3,11]. The inference rules of such a calculus span the search space and morethan thirty years of research led to a battery of refinements and strategies to traversethese large (billions of nodes) spaces. In spite of many attempts to the contrary (e.g., thehyperresolution rule), the inference steps defined by these calculi are rather small and low-level when compared with the proof steps of a trained mathematician.Traditional systems such as the MKRP system [33], OTTER [80], SETHEO [72], orSPASS [119] are essentially black boxes; after the input of a theorem and of (hopefully)exactly those axioms necessary for the proof of the theorem and after setting theappropriate parameters, the system searches blindly for a sequence of logic rules thatproves the theorem from the axioms. The search is supported by some general-purposeE. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10567control, called strategies or refinements [75], that is purely syntactic in nature and hardlyreflects mathematical ways of discovering a proof.Now this approach, although far from any mathematical practice and often under attackfrom the more AI-oriented community [45,46], is not entirely unreasonable as, e.g., thechess program Deep Blue has demonstrated which also derives its strength from searchtechniques. Recent success with blind SAT-techniques seems to corroborate even morethe advantages of blind but fast and simple mechanisms over domain-dependent AI-techniques.Just like automated chess and other areas, traditional ATP systems benefit from thetechnological development of faster computers with larger storage—they can now store andsearch billions of clauses and indeed, they do. 2 Due to this improvement and to varioustechnical advances in representational techniques (see for indexing [42]), systems havegained considerable strength and they can prove nontrivial open mathematical problems,such as the Robbins Algebra Conjecture [79], whose proofs are often unintuitive andtherefore tricky for humans. In general, however, most proofs of genuinely mathematicalproblems even in well-understood domains are very much beyond the capabilities of anyof today’s systems. So, after forty years of research the time is ripe again to ask WoodyBledsoe’s question: are we on the wrong track?It appears that this situation is not unique just for automated theorem proving.Over time we become trapped in our shared vision of appropriate ways to tackleproblems, and even more trapped by our funding sources where we must constantlyjustify ourselves by making incremental progress. Sometimes it is worthwhilestepping back and taking an entirely new (or perhaps very old) look at some problemsand to think about solving them in new ways. This takes courage as we may beleading ourselves into different sorts of solutions that will for many years have poorerperformance than existing solutions. With years of perseverance we may be able toovercome initial problems with the new approaches and eventually leapfrog to betterperformance. Or we may turn out to be totally wrong. That is where the couragecomes in.(Rodney Brooks, AAAI-96)1.1. The psychology of mathematical inventionWhy can a mathematician cope with long and complex proofs and what are her strategiesfor avoiding less promising proof paths?Given the current state of knowledge about our human formal reasoning capacity, wedo not know the answer. However, at least the following three observations are generally2 The first theorem prover implemented by the second author in the mid seventies was not untypical for itsgeneration; it could search spaces of several 100,000 clauses, to generate proofs of the length of a dozen steps.Our MKRP system that was under development for almost fifteen years could search spaces of several millionclauses by the end of the eighties to find proofs of about a hundred steps. Todays systems, such as SPASS andOTTER search spaces well in the billions: “Clauses generated: about 3,000,000,000. At the end of the search,about 400,000 clauses were in use. This took 314 hours and used 433 Megabyte of RAM. I guess, for a successfulsearch the search space would be 1/4 as big”. Bill McCune on OTTER’s figures for large search spaces for anopen problem in combinatory logic. Personal communication.68E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105accepted: first, a mathematician’s reasoning is more often than not based on some vividand concrete representation of the problem at hand [43,118]. Secondly, difficult theoremsare not shown from scratch but usually with some known proof technique such as proofby induction, the pigeon hole principle, proof by diagonalization, and so on. In fact, agood mathematician has at least several dozen (but presumably less than a thousand)proof techniques for her particular field at her disposal. Also, there surely are thousands(but probably less than a million) minor tricks of the trade such as when and how toapply a homomorphism, when to differentiate, or how to reformulate a given problem.In hindsight it seems preposterous to assume that all of this can be achieved just by blindsearch. For very difficult and open mathematical problems—usually they are open exactlybecause none of the standard attacks yields a solution—there is the need to combineand reshuffle these standard techniques and so, thirdly and finally, there is empiricalevidence [66,101] which suggests that mathematicians plan a proof at various levelsof abstraction in the proof discovery process. The following quotation taken from aninterview with the German mathematician Faltings, who proved Mordell’s Conjecture,beautifully illustrates the case in point. 3 When asked how he proved the famous problemhe said [34]Man hat Erfahrungen, dass bestimmte Schlüsse unter bestimmten Voraussetzungenfunktionieren: : : Man überlegt sich also im Groben: Wenn ich das habe, könnte ichdas zeigen und das nächste. Hinterher muss man die Details einfügen und sieht, obman es auch wirklich so machen kann.To translate freely into English, “We know from experience that certain inferences are usu-ally successful under certain prerequisites. So first we ponder about any reasonable wayhow to proceed. In other words, we roughly plan; if we would have a certain result the nextresult may follow and then the next, etc. Afterwards we have to fill in the details, and tocheck whether the plan really works.”Proof plans seem to have a cognitive reality of their own and in the following twosections we like to mention two areas of research that also benefit from the new way ofseeing things, i.e., from the fact that there is a well defined concrete representational levelabove the level of a logical calculus.1.2. Proofs by analogyTheorem proving by analogy is a small subarea of ATP which has been plagued by anotorious problem, namely that we often find two proofs analogous although it is hard toestablish a one to one mapping from the syntactic representation of the source proof to thetarget—and hence, the techniques based upon such mappings often fail (see, e.g., [81]). Inparticular, the proof idea may be the same while the details of source and target proof may3 In the early 1980s Gerd Faltings solved Mordell’s Conjecture which says “Algebraic curves of order 2 or morehave finitely many rational points”. Mordell’s Conjecture has been considered a hard mathematical problem andit took over 60 years to solve it. Last but not least it derives its significance from being a close relative of Fermat’sfamous conjecture. Faltings received the field medal for this work.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10569differ considerably. For instance, not every detail of the proof of LIM+ (the limit of sumof two functions equals the sum of their limits) can be transferred to a proof of LIM* (thelimit of the product of two functions equals the product of their limits) although, surely, thetheorems are very similar and a mapping between them can be established. Furthermore,applying the same inference rule in the source and target situations does not necessarilylead to subgoals that match, e.g., even if the multiplication function is identically mapped,the procedure decomposing a natural number into a product of primes may lead to differentnumbers of factors in source and target.So, how do we fix the right level of abstraction, if it is not the calculus level? Proofplans are more abstract than the calculus-level proofs and often capture the “essentialidea” of a proof explicitly. In [82] we have shown how this new representation leads toa much improved analogical transfer using derivational analogy as introduced by JaimeCarbonell [24]. Analogy-driven proof plan construction [82] was first implemented forproofs by mathematical induction [93] and later also used to solve an open challengeproblem of Woody Bledsoe in [84].1.3. Proof presentationThe output of a successful run of a traditional system is notoriously unreadable let aloneintuitively understandable in the way mathematicians communicate. Take, for instance, thefollowing theorem.Theorem. Let K be an ordered field. If a 2 K, then 1 < a implies 0 < a(cid:0)1 < 1 (and viceversa).The proof generated by the prover OTTER, looks as follows.1 [] x=x.2 [] -(x<y)| -(0<z)|x*z<y*z.3 [] -(x<y)| -(y<z)|x<z.4 [] -(x<y)| -(y<x).5 [] x=0| -(0<x)|0<inv(x).7 [factor,4,1,2] -(x<x).8 [] -(0<inv(a))| -(inv(a)<1).9 [] 0<1.10 [] x=0|x*inv(x)=1.12,11 [] 1*x=x.13 [] 1<a.19 [hyper,3,9,13] 0<a.27 [para_into,19.1.2,5.1.1,unit_del,7,19] 0<inv(a).48,47 [para_from,10.1.1,19.1.2,unit_del,7] a*inv(a)=1.60 [hyper,2,13,27,demod,12,48] inv(a)<1.65 [hyper,8,27,60] F.While the textbook proof taken from [76] reads.70E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105Proof. Let 1 < a. According to Lemma 1.10 we have a(cid:0)1 > 0. Therefore a(cid:0)1 D 1a(cid:0)1 <aa(cid:0)1 D 1. 2This huge discrepancy is more than the annoying technical problem of translating amachine found proof into natural language (see [55]). Obviously the human readable formof the above proof is at a very different level of abstraction and gives an “outline”, where thedetails and possibly a translation into a calculus-level proof could in principle be providedby an experienced mathematician.In addition, for more difficult proofs, a proof in mathematics is both, a means tounderstand and communicate why some result holds and secondly a means to achieveprecision [77]. Alan Robinson coined the formula [104]Proof D Guarantee C Explanation:As to a ‘guarantee’, we have the proof in the logical calculus that could be checked bya proof checking program, however, it is a logician’s folly to assume that this is also anexplanation. The logical proof provides a ‘justification’, rather than an ’explanation’. AlanRobinson [105] suggests that the proof-as-explanation aspect is both (far) more importantand (far) more interesting than the mere logical guarantee.For a comprehensible communication, an explanation at a more abstract level isrequired. Such an explanation can, however, not be generated directly from a calculus-level proof. We shall argue that the presentation of a textbook proof is based not on thecalculus-level expansion but, depending on the intended reader, on a proof plan at one ofthe possible levels of abstraction.1.4. An alternative: Proof planningProof planning was originally conceived as a mere extension of tactical theorem proving(see LCF [41], NuPrl [28], or Isabelle [99] for tactical theorem proving). Tactical theoremproving is based on the notion of a tactic which encapsulates repeatedly occurringsequences of inference steps into macro-steps. These tactics are realized by programs,i.e., executing a tactic yields a sequence of calculus-level proof steps and thus relievesthe user from applying too many single inference rules in a row in interactive theoremproving.The idea of proof planning is as follows. The representation of a proof, at least whileit is developed, consists of a sequence of complex operators, such as the applicationof a homomorphism, the expansion of a definition, the application of a lemma, somesimplification, or the differentiation of a function. Each of these operators, called methods,can in principle be expanded into a sequence of inference steps, say, of a natural deduction(ND) calculus by a tactic. Now if an individual tactic of this kind, is augmented by pre- andpostconditions, we can plan such a sequence of tactics. This marriage of planning operatorswith tactics was Alan Bundy’s key idea [20] for proof planning.More recently, another type of methods with schematic expansions, has been de-fined [54]. Hence, methods are not necessarily restricted to its tactical origins but can bedefined more generally as proof planning operators [91], i.e., any building blocks for proofplans, that can be recursively expanded into a calculus-level proof.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10571Proof planning searches for a plan,i.e., for a sequence of methods, where thepreconditions of a method match a postcondition of a predecessor in that sequence.This well-known view of a plan [35] leads naturally to a new engine for automatedtheorem proving; a planner can be used to plan a sequence of methods that transforms theproof assumptions into the theorem. Standard heuristics and techniques from the planningliterature can now be employed.Moreover, proof planning provides means of global search control that correspond wellto mathematical intuition, as opposed to the local and syntactic search heuristics which arecommonly used for search control in traditional automated theorem proving [75].The first proof planner, CLAM[21], was designed to prove theorems by mathe-matical induction. CLAM employs the rippling search heuristic for difference reduc-tion [22,56]. Rippling is based on an annotated logic calculus that handles anno-tated terms and uses annotated matching. More specifically, a skeleton annotation in-dicates the commonalities between the induction hypothesis and the induction conclu-sion (the ‘skeleton’) and a context annotation indicates the difference between the in-duction hypothesis and the induction conclusion (the ‘context’), and rippling is es-sentially a context-reducing rewriting that preserves the skeleton, i.e., the common-alities. Such a difference reduction works in particular for equational proofs andproofs by mathematical induction. However, there are many theorems that are dif-ficult or impossible to prove by CLAM (for instance, the limit theorem LIM*) be-cause(i) for many problems, the means of control are insufficient and not flexible enough,(ii) no domain-specific methods are used, and(iii) the need to construct mathematical objects with certain theory-specific propertiesis not supported.To extend proof planning, this article introduces knowledge-based proof planning. Firstit shows which knowledge is available in mathematics and how it can be represented.Section three describes how a general-purpose proof planner makes use of mathematicaldomain knowledge including methods, control-rules, and external reasoners. Severaltechniques that restrict the search in proof planning are introduced, in particular meta-levelreasoning in Section 3.2 and constraint solving in Section 3.3.3. In Section 4 we showhow we proved limit theorems using the knowledge-based proof planner of the (cid:127)MEGAsystem [10] and thereby show that knowledge-based proof planning is not only possible inprinciple but can be used to solve problems that cannot be solved by other general-purposesystems. Finally, Section 5 argues that proof plans provide a representational abstractionof a proof that is also well-suited for the communication with a user.(cid:127)MEGA is a complex theorem proving system for interactive and automated proofdevelopment whose distributed architecture integrates various (mathematical) services,such as the proof planner, traditional automated theorem provers, the knowledge base,computer algebra systems, a proof verbalization component, and a graphical user interface.In the following, we shall restrict our presentation of (cid:127)MEGA to those aspects thatare directly relevant for knowledge-based proof planning, the (cid:127)MEGA system itself isdocumented inter alia in [10,110,111].72E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–1052. Principles of proof planningWe shall now briefly review the basic notions from the field of planning in AI andsubsequently introduce proof planning within this terminology. Our extensions that led toknowledge-based proof planning are then presented in Section 3. We use (cid:27) for substitutionsand abbreviate the result of applying (cid:27) to F by F (cid:27) .2.1. Basics of planningA planning problem consists of an initial state describing some initial situation and ofgoals to be achieved. A planning domain is defined by operators that usually representactions. The operators have specifications to be used in the planning process. In STRIPSnotation [35] these specifications are called preconditions and effects. Preconditionsspecify the conditions of the planning state that have to be satisfied for the operatorto be applicable, whereas effects describe the potential changes of the planning statecaused by an operator application. In STRIPS representation, effects are representedby add-lists ((cid:8)) and delete-lists ((cid:9)), i.e., lists of literals that are added or deleted byan operator application. Note that preconditions and effects are usually formulated asexpressions in a restricted first-order logical object-level language such as (on A B)or (arm-holds X). However, some planners, e.g., Prodigy [96], allow for additionalpreconditions formulated in a meta-level language which restrict the instantiation ofparameters. They are called application conditions in the following.A partial plan is a partially ordered set of steps, i.e., of (partially) instantiated operators,with additional instantiation constraints and auxiliary constraints [62]. A partial plan can beseen as an implicit representation of a set of sequences (set of potential solutions) consistentwith the ordering, instantiation, and auxiliary constraints. A solution of a planning problem,a complete plan, is a fully instantiated linearization of a partial plan that transforms theinitial state into a goal state, i.e., a state in which the goals hold.The operation of a planner repeatedly refines a partial plan, i.e., it adds steps andconstraints and thus restricts its set of potential solutions until a solution can be pickedfrom its set of potential solutions [61]. Table 1 shows a simplified backward planningalgorithm (not handling goal interactions). Planning starts with a partial plan (cid:25)0 definedby the problem to be solved, where (cid:25)0 consists of steps t0 and t1 that are instantiations ofthe dummy operators start and finish. They have the initial state as (cid:8)-effects and thegoals as preconditions, respectively. (cid:25)0 also represents the order constraint t0 (cid:30) t1. Theintroduction of a step into a partial plan removes an open goal g from the goal agenda Gand may introduce new open subgoals and constraints. This refinement is continued untilno open goals are left and a solution is found or until no operator is applicable anymore.Search is involved in each of the planning algorithms, and hence, the process of planningconsists of a sequence of choices that leads to a complete plan. These decisions include tochoose which open goal to solve next, which planning operator to use in order to attain thisgoal, and which instantiations to choose. These decisions influence the way the searchspace is traversed or restricted. Some planners use explicit declarative control-rules toguide the search.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10573Table 1Outline for backward planningBackwards-Refine-Plan((cid:25) , G)Termination: if goal agenda G empty, then Solution.if no operator applicable, then Fail.Goal Selection: Choose open goal g 2 G.Operator Selection:(cid:15) For each operator Mfor each (cid:8)-effect e of Mlet (cid:27) be the matcher e(cid:27) D gif application-conditions(M(cid:27) / D true,then M is applicable.(cid:15) Choose one applicable M (backtracking point)(cid:0) insert M into (cid:25)(cid:0) insert constraints into (cid:25)(cid:0) update G.Recursion: Call Backwards-Refine-Plan on the refined partial plan (cid:25) .A diversity of planning approaches has been developed, among them two kinds ofhierarchical planning techniques, precondition abstraction [107] and operator abstractionplanning [116], also called hierarchical task network (HTN) planning. Preconditionabstraction first searches in an abstract space by ignoring certain preconditions ofoperators. These ignored goals are considered later at a lower hierarchical level of planningonly. Operator abstraction employs complex (as opposed to primitive) operators thatrepresent complex actions. A complex operator can be expanded to a partial (sub)planaccording to a schema. Since only primitive actions can be executed, all complex operatorshave to be expanded in order to obtain an executable plan.After this brief review of classical AI planning we shall now describe how this transfersto proof planning. Search problems in proof planning and extensions of proof planning tocope with the large search space are addressed afterwards in Section 3.2.2. Proof planningProof planning considers a proof problem as a planning problem and hence it isan application of planning techniques to mathematics. This domain exhibits seriouslycomplex problems and potentially infinitely branching search spaces. However, thenotorious problem of goal interaction is typically not present in this domain. The particularplanning algorithm we are actually using is not really important for a general article as this(in (cid:127)MEGA we experiment with two different algorithms) hence we just refer to a simpleproof planner for backward and forward planning, extended by hierarchical planning.The initial state in proof planning is a collection of sequents, 4 the proof assumptions,and the goal is the sequent to be proven. A proof planning domain consists of methods,of control-rules, and theory-specific reasoners. A partial proof plan is a partially ordered4 A sequent is an object ((cid:1) ‘ F ) with a set of formulae (cid:1) and a formula F which means that F is derived from(cid:1).74E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105InductionBase-caseSymbolic evaluationSimplificationTautology checkingStep-caseRewritingFertilizationFig. 1. Proof pattern for mathematical induction, where fertilization is the application of the induction hypothesis.set of instantiated methods and a complete, i.e., fully expanded proof plan is a sequenceof instantiated primitive methods that transfers the initial state into a goal state. Thus acomplete plan is a solution of a problem, in other words, a proof of the theorem.The beauty of this approach is that methods represent familiar mathematical prooftechniques or frequently occurring mathematical formula manipulations. In particular,methods should capture(1) common patterns in proofs, that is, a common structure such as in proofs bymathematical induction (see Fig. 1) or(2) common proof procedures such as term simplifications or, for example,theapplication of the Hauptsatz of Number Theory (each natural number can beuniquely represented as the product of prime numbers).Examples for methods that encode a common proof structure are Diagonaliza-tion [25], Induction [21], and the theory-specific ComplexEstimate [85] whichis an estimation method used for planning limit theorems as presented in Section 4. Meth-ods that encode common procedures, i.e., methods that have some control encoded, areamong others ComputeIntegral, Optimise [110], or SimplifyTerm.The intuitive mathematical counterpart of methods is reflected in good textbooks. Forinstance, the first chapter of the textbook Elements of the Theory of Computation [73],by Lewis and Papadimitriou introduces the common proof techniques of MathematicalInduction, the Pigeonhole Principle, and the Diagonalization Principle as the main tools tobe used throughout the book. The textbook Computability, Complexity, and Languages [31]describes the following common pattern in diagonalization proofs (see Fig. 2).(cid:15) A certain set E is enumerated in a suitable fashion.(cid:15) It is possible, with the help of the enumeration, to define an object d that is differentfrom every object in the enumeration.(cid:15) The definition of d is such that d must belong to E, contradicting the assertion thatwe began with an enumeration of all the elements in E.From this description, a planning method for diagonalization proofs was used to prove wellknown and mathematically difficult theorems by diagonalization [25].E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10575Find enumeration of EDefine object dd different from every e in Eand d in EDerive contradictionFig. 2. Proof pattern of diagonalization proofs.Let us now make these general ideas more concrete. The initial state in proof planningis a collection of proof assumptions formalized by logical sequents of an object-levellanguage 5 and the goal is the sequent to be proven. For instance, for proving the theoremLIM+ the goal is; ‘ limx!af .x/ C g.x/ D L1 C L2and the initial state consists of the proof assumptions(1); ‘ limx!a; ‘ limx!af .x/ D L1;g.x/ D L2and of axioms and definitions of the theory R of real numbers.Proof planning now starts with the partial plan (cid:25)0 defined by the proof assumptions andthe theorem to be proven and searches for a solution of the problem, i.e., a sequence ofinstantiated methods that transforms the initial state into a goal state. (cid:127)MEGA’s plannersearches by backward planning from the goal and by goal-oriented forward planning fromthe assumptions.(cid:127)MEGA uses both hierarchical planning techniques, operator abstraction and precondi-tion abstraction as introduced above. As a generalization of operator abstraction planning,complex methods can be expanded recursively into primitive methods that represent infer-ence steps at the calculus level of a natural deduction calculus. Each of these expansionsis stored in the hierarchically organized proof plan data structure (PDS) [10] as shown inFig. 3. A PDS is used to represent the various levels of proof abstraction; the initial PDSconsists of the initial partial plan (cid:25)0 and as (cid:25)0 is refined by planning, more nodes are intro-duced into the PDS. The expansion of nodes takes a method and expands it into a subplanat the next lower level of abstraction.In the figure, three abstraction levels are depicted. The left hand side of Fig. 3 sketchesthe correspondence between calculus-level rules that are composed into schemata orcombined by tactics as specified by methods. The expansion of high-level methods intolower-level plans until finally the level of the ND-calculus is reached, is indicated on theright hand side. A fully expanded plan, i.e., an ND-proof, can be checked for correctnessby a proof checker at the end of the planning process. This is necessary because not every5 (cid:127)MEGA’s object-level language, POST, is based on Church’s simply typed (cid:21)-calculus [26].76E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105Fig. 3. Proof plan data structure with expansions.instantiated method is guaranteed to be correct in the sense that it yields a correct proof ofthe conclusion from the premises.Depending on whether a method encodes a particular proof structure or a proof proce-dure, the expansion of a non-primitive method is realized schematically or procedurally.A schematic expansion defines a proof tree that may contain meta-variables. 63. Knowledge-based proof planningMathematicians have accumulated mathematical problem solving knowledge overhundreds of years and a mathematician is an expert in a highly specialized mathematicalfield rather than a universal expert. That is, domain-specific knowledge is a key for successwhile, of course, some general techniques and mathematical knowledge are important too.In this section, we shall see which knowledge is available, how it can be represented,how it can be used, and how the architecture of a system makes this knowledge accessiblefor proof planning.3.1. MethodsWoody Bledsoe remarks in [14] that central in mathematical knowledge are “: : :methods, procedures, and tricks of the trade, which have been used successfully by thegreat mathematicians over the years, also diagrams, constructions, figures, and examples”.They play a key role in proof discovery. Accordingly, the design of methods which capturethese techniques is essential also for a successful proof planning.6 Meta-variables are place holders for syntactic objects of the underlying logical calculus, i.e., for first-orderformulae.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10577Now there existtheory-dependent and theory-independent methods; for instance,decomposition tricks to be used for estimations in "-(cid:14)-proofs or the computation ofintegrals can be considered theory-specific (for the real numbers) and also proof byinduction or the abstract consistency property presuppose some minimal mathematicalstructure and content. On the other hand, a case-split is theory-independent and thereforecorresponds to primitive theory-independent methods usually captured in natural deductioncalculi [39,102].How can we discover methods? One heuristic for knowledge acquisition not only frommathematical (text)books is the following: The importance of a method is more oftenthan not indicated by naming it. Named mathematical methods are, for instance, a proofby diagonalization or by induction, the application of an important theorem such as theHauptsatz of Linear Algebra (each n-dimensional vector space has a basis of n linearlyindependent vectors), the Hauptsatz of Number Theory, etc. The mathematical monographIntroduction to Real Analysis [7] introduces mathematical methods by referring, forexample, to the Supremum Property, to the Monotone Convergence Theorem, etc. It statesas a didactic help or hint for the reader: “The next two results will be used later as methodsof proof” (p. 32), “We shall make frequent and essential use of this property (the SupremumProperty of R)” (p. 45), or “the method we introduce in this section (associated with theMonotone Convergence Theorem): : : applies to sequences that are monotone: : :” (p. 88).How can methods be represented? Methods consist of declarative specifications to beused in the planning process and of an expansion function that realizes an expansionof the method into a partial proof plan. We distinguish object-level and meta-levelspecifications. The object-level specifications correspond to the usual preconditions andeffects in planning. That is, they specify the sequents that match open goals to be satisfiedby the method (backward planning), the sequents that have to be in the planning statewhen the method is applied (i.e., the subgoals produced by the method during backwardplanning), the sequents that match with assumptions in the planning state, and those thatare produced as new assumptions when the method is used in forward planning.The meta-level specifications capture in a meta-language the local conditions of themethod’s application, i.e., properties and relations that must hold for the sequents to beprocessed by the method. 7 The meta-level specification of a method expresses legalconditions for the method’s application, in particular, restrictions of the instantiation ofthe method’s parameters.In (cid:127)MEGA methods are represented as frame-like data structures with slots, slot names,and fillers. The slot names are premises, conclusions, application conditions, and proofschema. The premises and conclusions constitute a logical specification, in the sense thatthe conclusions are supposed to follow logically from the premises. Their ((cid:8))- and ((cid:9))-annotations indicate object-level specifications, with the semantics that a (cid:9)-conclusion isdeleted as an open goal, a (cid:8)-premise is added as a new open goal, a (cid:9)-premise is deletedas an assumption, and a (cid:8)-conclusion is added as an assumption when the methods areinserted into the partial plan. These specifications are matched with the current goals andassumptions respectively and then the output of the method’s application is computed fromthe instantiated specifications.7 For example, subform.G; A/ expresses the fact that G is a subformula of A.78E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105Table 2Method: PeanoInductionpremises(cid:8)L1, (cid:8)L2conclusions(cid:9)L3appl.condsort(n) = Natproof schemaL1.L2.L3.‘ P .0/‘ P .k/ ! P .k C 1/‘ 8n:P .n/(baseCase)(stepCase)(IndAxiom;L1,L2)For example, the method PeanoInduction (Table 2) has the object-level specifica-tion (cid:8)L1, (cid:8)L2, and (cid:9)L3, where L1 is an abbreviation for the sequent in proof line L1in the proof schema. The annotations mean, the sequent in L3 is deleted as a goal and thesequents in L1 and L2 are added as new subgoals.This representation of preconditions and effects is somewhat more involved than theusual object-level preconditions and effects because we have forward planning (planningnew assumptions from existing ones) as well as backward planning (reducing a goal tosubgoals) and, therefore, assumptions and open goals are both included into the planningstate; the potential changes of the goals and the assumptions have to be represented.The application conditions (appl.cond) are formulated in a meta-language usingdecidable meta-predicates. They specify local and legal conditions for the method’sapplication. For instance, in the above PeanoInduction, the application conditionsrequire that n is a natural number.The slot proof schema provides the information for the schematic expansion of themethod and thereby captures the semantics of this method, i.e., the schematic expansionintroduces a partial plan into the PDS that is defined by this proof schema. The justificationsfor each line, the right most entries of the proof lines, can be tactics, methods (includingND-rules), a call to an external reasoning system, or OPEN. For instance, in the lineL1:‘ P .0/.baseCase/of PeanoInduction (Table 2) the line-justification is the tactic baseCase that issupposed to prove P for the number 0. A line likeL2: (cid:1)‘ jkj 6 M .OPEN/(from the ComplexEstimate method of Table 6) means that line L with the sequent(cid:1) ‘ jkj 6 M open, i.e., there is currently no justification for (cid:1) entails jkj 6 M. The lineL6: ;‘ b D k (cid:3) a(cid:27) C l.CASI L5/(from the ComplexEstimate method of Table 6) means that the computer algebrasystem CAS is expected to justify the formula b D k (cid:3) a(cid:27) C l in line L6 with the helpof the formula in line L5. Similarly an automated theorem prover or a decision procedurecould be specified here.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105793.2. Meta-level reasoningAlthough most methods encapsulate a chunk of calculus-level proofs, and therefore,proof plans are generally much shorter than the corresponding expansions into a calculus-level proof, the potential search spaces are still prohibitively large. The reason is that alarge number of alternative methods is usually applicable at each choice point and also,more seriously, the search space for mathematical proofs is potentially infinite. That is tosay, even for a finite number of operators, there may be infinitely many branches at eachchoice point, for example, when existentially quantified variables have to be instantiated orwhen a lemma has to be introduced. 8 Hence, special techniques for reducing and guidingthe search are needed in proof planning.Informed search is superior in domains, where control knowledge exists and mathemat-ics is surely a field where such knowledge has been accumulated. The good news is that,since methods represent mathematically meaningful steps, control knowledge can expressmathematical ‘intuition’ rather than just syntactical information such as an order or a num-ber restriction on literals as in traditional ATP. The bad news is that it can be difficult toextract this knowledge and to represent it appropriately.Our representation of control knowledge depends on the kind of the knowledge, inparticular on whether it expresses legal or heuristic, local or global knowledge. As opposedto ‘local’ knowledge as defined above, ‘global’ means that its evaluation procedure mayhave to inspect the whole PDS and its history (i.e., the failed proof attempts etc.) as wellas time resources, the user model, and other global settings such as the theory withinwhich the problem is stated and the typical examples of this theory. While legal and localknowledge is appropriately encoded into the application conditions of methods, heuristicknowledge should be encoded into control-rules. They can then be used for meta-levelreasoning which is known to be extremely important in mathematics [108].We prefer an explicit and modular representation of heuristic control knowledge indeclarative control-rules rather than the previous representation hardwired into the planneror the methods. This is useful because the same method can be used in different theorycontexts with different control. Consider, e.g., a method that translates a goal into astatement about natural numbers, i.e., into a goal that can then be shown by PeanoInduction. The function that determines the natural number is a parameter of a very general‘translation’ method. In many completeness proofs for logic calculi this natural numberis either the excess literal number [1], the length of clauses, or the number of literaloccurrences. In other theories the choice of this number may be different, e.g., the lengthof a derivation, the complexity of a formula, the number of grammar rule applications etc.Now, the method that finds this natural number is very general and applicable in manymathematical domains, whereas the control knowledge that determines the possible rangeof the parameter (the function) is specific and thus usually different in different domains.8 This is a problem well known, e.g., in induction and verification. The ultimate reason for infinite branching isthat the cut rule, i.e., the rule(cid:0); B ‘ A (cid:0) ‘ B(cid:0) ‘ Athat is applied backward, cannot generally be avoided in mathematics. For an analysis see [67].80E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105Other well known reasons for using control-rules are: Modularly implemented anddeclaratively represented control-rules ease the modification and extension of the controlknowledge. For instance, when new control information is required for new cases ofproblem solving, the existing control-rules can be modified or new control-rules can beintroduced easily, as opposed to a re-implementation of the procedurally implementedcontrol component of a planner. In particular, when the control is changed or generalizedor when new methods are introduced into the domain, no re-implementation of the affectedmethods is necessary. Moreover, the declarative representation of control information byrules can be a basis for automatically learning control-rules, as realized in some planningsystems, e.g., in [17,70,95].In (cid:127)MEGA, a control unit evaluates the control-rules and guides the proof planner in itschoice between several candidates, similar to an expert system, where the list of candidatesrules is reduced to a smaller list. Control-rules have an antecedent and a consequent. Theantecedent specifies the overall context within which this control-rule is applicable; itsevaluation determines whether the control-rule is rejected or not. Currently, the consequentof a rule encodes the advice to select a specified subset of the available candidates, toreject, or to prefer one candidate over another candidate. The first two types of rulesprune the search space, while prefer-rules change the default order without excluding otheralternatives.Corresponding to the type of the choices of the planner we have the following classes ofcontrol-rules in (cid:127)MEGA:(cid:15) method-choice for choosing among several methods, this may come with bindingchoices,(cid:15) sequent-choice for choosing among goals (in backward planning) or amongassumptions (in forward planning),(cid:15) strategy-choice for choosing a refinement strategy (not discussed in this article,but see [88]).the planning history (e.g., last-method),The rules are formulated in an expressive meta-language. The decidable meta-predicatesin the antecedents of control-rules inspect the PDS and the planning state (e.g., goal-matches),the constraint state (e.g.,unique-value), the available resources, the user model, the theory in which to plan,including typical models of the theory(e.g., invalid-in-typical). For example, thefollowing rule case-analysis-intro which is a reconstruction of a critic in CLAMexpresses the heuristic that if the method Rewrite whose parameter is instantiated by arule (C -> R) is not applicable because the formula C is not trivially provable, then aCaseSplit method should be introduced into the plan.(control-rule case-analysis-intro(kind method-choice)(IF (last-method (Rewrite (?C -> ?R))) AND(failure-condition (trivial ?C)))(THEN (select (CaseSplit (?C or not ?C)))))For instance, if Rewrite((cid:30)) was tried in the last planning step with the instantiation of(cid:30) (cid:17) x 6D a !f .x/ (cid:0) f .a/x (cid:0) a0D f.a/E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10581Table 3Outline for controlled backward planningBackwards-Refine-PlanC((cid:25) , G)Termination: if goal agenda G empty, then Solution.if no operator applicable, then Fail.Goal Selection: Evaluating control-rules (for goals) returns G0with G0 (cid:18) G.Choose open goal g 2 G0.Operator Selection:(cid:15) Evaluating control-rules (for operators) returns O0 (cid:18) O.(cid:15) For each operator op 2 O0for each (cid:8)-effect e of oplet (cid:27) be the matcher e(cid:27) D gif application-conditions(op(cid:27) / D true,then op is applicable.(cid:15) Choose one applicable M (backtracking point)(cid:0) insert M into (cid:25)(cid:0) insert constraints into (cid:25)(cid:0) update G.Recursion: Call Backwards-Refine-PlanC on the refined partial plan (cid:25) .but this failed because x 6D a does not hold, then a CaseSplit on .x 6D a _ x D a/ ischosen next in order to enable Rewrite((cid:8)) in one of the case-split branches.The use of control-rules gives rise to an extended planning algorithm as shown in Table 3(see Table 1 for comparison).3.3. Integrating external reasoning systemsIn many mathematical proofs, logical steps are naturally combined with some formof specialized reasoning or effective computation such as computing integrals, solvingequations, or solving inequalities (see [23] for an overview). This specialized reasoningdoes not work too well with traditional ATP systems whereas theory-specific systems andalgorithms can perform such services more efficiently because they represent objects suchas rational and real numbers [50] by specialized data types that can be efficiently handledand because they rely on efficient special-purpose algorithms called background reasoningin [23].Proof planning provides a natural framework for integrating such external reasoningsystems as follows. Suppose we have an algorithm for the computation of the greatestcommon divisor, GCD, whose computation implicitly uses axioms and theorems forintegers. This computation can be first included into the proof plan by wrapping the call ofthe GCD-algorithm into a method whose tactic computes the output of the method. In casethis computation cannot be trusted, 9 or in either case we prefer a sequence of calculus-level steps for the proof anyway, the computation has to be expanded into a proof thatis a subproof of the overall calculus-level proof. Therefore, in (cid:127)MEGA this expansion is9 For example, a computation may not check whether the divisor is zero.82E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105possible in principle. However, generating a proof plan from a system’s trace is expensiveand hence the plan generation mode is called on demand only.In the following, we shall briefly mention the external reasoning systems integrated into(cid:127)MEGA and then concentrate just on those aspects that are relevant for this article.3.3.1. Traditional automated theorem provers and decision proceduresThe first systems that were integrated into (cid:127)MEGA are the MKRP system [33] andOTTER [80]. Currently, more provers are integrated, e.g., SPASS [119], PROTEIN [8],Bliksem [98], EQP [78], and Waldmeister [47]. The ultimate goal of this integration isthis: once we have an abstract proof plan there may be many gaps in the overall proof thatcould easily be solved by a call of one of these ATP systems. The nontrivial aspects ofthis integration is to spot the right gaps and secondly to translate the resulting proof into asequence of ND-rules which is the chosen base calculus of (cid:127)MEGA. The second problem issolved in (cid:127)MEGA [53] and other systems [2,74,94,100] while the first problem is currentlycircumvented by interactively calling the ATPs.3.3.2. Computer algebra systemsIn order to execute symbolic computations more efficiently, (cid:127)MEGA integrates severalcomputer algebra systems including (cid:22)CAS [63], an experimental CAS, to simplifyalgebraic expressions and to compute terms in the proof planning process.The call of a computer algebra system is wrapped into a method or in a function that isinvoked when evaluating a method’s application conditions. The computer algebra systemreturns a simplified expression or a newly computed term. A node in the proof plan that isjustified by CAS can be expanded recursively into an ND-proof that can be proof checked.For this expansion, (cid:22)CAS runs in a plan-generation mode which returns the protocolinformation from which a proof plan justifying its computation can be re-constructed. Thisplan can then be recursively expanded into an ND-proof (see [63]).3.3.3. Constraint solversMany proofs require the construction of an object with theory-specific properties. Thisis usually indicated by an existentially quantified variable in the problem. In traditionaltheorem proving this construction is carried out by the unification algorithm.Our solution to this problem is to delay this instantiation as much as possible and tointegrate an external constraint solver that incrementally restricts the possible object values,essentially as in constraint logic programming (CLP) [58]. This process is essential for thepurpose of this paper and, as we shall see, the use of constraint solvers differs from that ofa CAS or an ATP as it requires the permanent presence during the planning process andthe collection and propagation of many constraints by the constraint solver (see [92]).Our external constraint solver uses the notation and functionalities common to CLP.These are outlined next followed by a description of a generic interface with proofplanning. The common theory of CLP [59] defines a constraint domain (D; L) for a givensignature (cid:6) that includes the symbol = . D is a (cid:6)-structure, i.e., an interpretation for (cid:6)which interprets = as the identity, and L is a class of first-order (cid:6)-formulae (constraints)that is closed under variable renaming, conjunction, and existential quantification. Forinstance, the (cid:6)-structure R is the constraint domain of arithmetic over the real numbersE. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10583for (cid:6) D .0; 1; C; (cid:3); D; <; 6/, where C; (cid:3) are interpreted as the usual addition andmultiplication function and <; 6 are interpreted as the less-than and less-than-or-equalrelations on reals, respectively.Basic constraints are those for which satisfiability can be decided directly, e.g., .X < a/.Non-basic constraints have only incomplete decisions, e.g., X C Y D Z when only onevariable is known. Conditional constraints have the form (if c then A1 else A2), for aconstraint c [113].Jaffar and Maher [59] introduce an operational semantics for CLP systems as statetransition systems. In order to implement the abstract operational model, the followingfunctions have to be realized:(cid:15) Initialization of the constraint state,(cid:15) Consistency check,(cid:15) Entailment check,(cid:15) Propagation of constraints, including simplification,(cid:15) Reflection of the constraint state,(cid:15) Search for the instantiation of variables.The interface functions tell and ask can pass constraints to the solver. The operationtell(c) passes a constraint c to the constraint solver and then propagates the constraintin case c is consistent with the constraint store. In this case, it returns true and the newconstraint state. Otherwise it returns fail. The operation ask passes a conditional constraint(if c then A1 else A2) to the constraint solver for testing entailment of c from the constraintstore. It returns A1, if c is entailed and A2 otherwise. For instance, ask (if 0 6 x thentell jxj D x) checks whether .0 6 x/ is entailed by the constraint store, and if so, then.jxj D x/ is told to the constraint solver.The integration of a constraint solver into proof planning serves several purposes: First,it is used in the process of proof planning to determine whether a certain method can belegally applied, secondly the constraint state can be reflected onto an answer constraintC, and thirdly the constraint solver searches for instantiations of implicitly existentiallyquantified variables.Fig. 4 summarizes the integration of a constraint solver into proof planning. Somemethods that are available to the planner are interfaced with the constraint solver by thefunctions tell or ask that are called when the application conditions are evaluated: theconstraint solver may compute a reflection C of the constraint state. When the plan iscompleted, an instantiation function instantiates the meta-variable C by the formulaC at each occurrence in the PDS [86].A method interfacing proof planning with the constraint solver CS is Solve-b that isshown in Table 4. The b in the method’s name indicate that it is employed in backwardplanning and CS is the parameter determining the particular constraint solver. CS standsfor any constraint solver and can be instantiated by, e.g., a constraint solver for lineararithmetic in the real numbers, for finite domains, or for set theory.c is the constraint goal that is closed by Solve-b. The proof schema of Solve-bcontains a meta-variable C for the answer constraint of CS. The instantiation of C is relevantfor line L2 in the proof schema that suggests that the constraint can logically be derivedfrom the (yet unknown) answer constraint. Hence, the value for C is used in the recursiveexpansion of Solve steps. The proof schema of Solve-b contains a line with the line-84E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105Fig. 4. Integration of a constraint solver into proof planning.Table 4Method: Solve-b(c,CS)premiseconclusionsappl.condL1(cid:9)L2constraint(c,CS) ANDIF var-in(c) THEN tell(c)ELSE ask (if c then true else fail)proof schemaCL1.L2. (cid:1); C‘ C‘ c(HYP)(solvCS)justification solvCS which names the method that derives c from the instantiation of themeta-variable C by eliminating conjunctions repeatedly.The application conditions of the Solve-b method determine whether a constraintgoal is handled by tell or by ask. The access of the constraint solver via tell ischosen when the constraint at hand contains an implicitly existentially quantified variable.Otherwise, ask is chosen. The reason is that new constraint goals that contain onlyconstants and universally quantified variables cannot be introduced into the constraintstore without loss of generality, whereas constraints with implicitly existentially quantifiedvariables can. 10 The application conditions are satisfied if ask returns true, i.e., c isentailed by the current constraint store, or if tell returns true, i.e., the constraint storeis consistent with c. This gives an account on how the constraint solver is involved inchecking the legal applicability of a Solve method.The second task of the constraint solver, reflecting the constraint state onto ananswer constraint, is currently performed with the final constraint state. The resulting10 The introduction of a constraint assumption into the constraint store by forward planning works differentlybecause proof assumptions can always be introduced.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10585Table 5Method: InitializeCS(T )premisesconclusionsappl.condproof schema(cid:8) L1(cid:9) L4L1. (cid:1); CL2. (cid:1)L3. (cid:1); TL4. (cid:1); T‘ thm‘ C ! thm‘ C‘ thm(OPEN).!I;L1)(OPEN)(!E;L2,L3)answer constraint formula C is an assertion about the value restrictions of the implicitlyexistentially quantified variables.Why is it necessary to introduce C anyway? Suppose, we collect restrictions by backwardplanning and these are condensed in an answer constraint formula C. In a formal proofconsisting of forward inference steps, C is stated at the beginning and subsequent proofsteps have to refer to C as an hypothesis, i.e., the hypothesis must occur in goals beforeit is actually known. Hence, in order to obtain a correct ND-level proof after the recursiveexpansion, a meta-variable C is introduced as a place holder for the formula C. Thisis realized in backward planning by the InitializeCS(Th) method (Table 5) thatreduces a goal(cid:1) ‘ thmto the subgoals(cid:1); C ‘ thm;(cid:1); Th ‘ C;InitializeCS combines the ND-rules !I and !E. 11where Th is the theory of the constraint solver and where C holds the place for a formula C.It contributes to thehierarchization of proof planning since—as a form of precondition abstraction—L3 isvisible as a subgoal only after the method’s expansion because it does not occur in thepremises. Only when the instantiation of C; C, can also be proven, is the proof completed.The parameter T in InitializeCS stands for a theory T for which a particularconstraint solver CST is employed, e.g., set theory or linear arithmetic in R.3.4. Extension of (mathematical) theoriesIn knowledge-based proof planning the mathematical domain knowledge consistsnot only of axioms, definitions, and theorems but also of methods, control-rules, anddomain-specific external reasoners. This knowledge is hierarchically organized and storedin theories. (cid:127)MEGA’s general-purpose proof planner can access a theory base, calledMBase [37], that contains domains such as Base, Set Theory, Calculus and that is currentlyextended to further mathematical theories as well.11 !I(ntroduction) is (cid:1);F ‘G(cid:1)‘F !G . !E(limination) is (cid:1)‘F !G;(cid:1)‘F(cid:1)‘G.86E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–1054. A case study: Proof planning of limit theoremsWe shall now demonstrate knowledge-based proof planning in operation, using the limittheorems as our domain. These theorems are formulated and proved in the theory R of thereal numbers.In the remainder, =; (cid:3); C; (cid:0); jj denote the division, multiplication, addition, subtraction,and the absolute value function in R, respectively. Prolog notation is used for constants andvariables.Limit theorems claim something about the limit limx!acontinuity. Since the formal definition of limx!a(cid:0)f .x/ is(cid:0)0 < " ! 9(cid:14)8"0 < (cid:14) ^ 8x.x 6D a ^ jx (cid:0) aj < (cid:14) ^ x 6D a ! jf .x/ (cid:0) lj < "/f .x/ for a function f or about(cid:1)(cid:1);(2)the standard proofs of these theorems are often called "-(cid:14)-proofs, i.e., proofs that postulatethe existence of a (cid:14) such that a conjecture of the form : : : jXj < " can be proven underassumptions of the form : : : jY j < (cid:14). The class of limit theorems includes the theoremLIM+ that states that the limit of the sum of two functions is the sum of their limits. Thefollowing sequent formalizes LIM+ 12limx!af .x/ D l1 ^ limx!ag.x/ D l2 ‘ limx!a.f .x/ C g.x// D l1 C l2;and after expanding, the definition of limx!a, becomes(cid:0)(cid:0)(cid:0)8"18"2‘ 8"0 < "1 ! 9(cid:14)10 < (cid:14)1 ^ 8x1.x1 6D a ^ jx1 (cid:0) aj < (cid:14)1 ! jf .x1/ (cid:0) l1j < "1/0 < (cid:14)2 ^ 8x2.x2 6D a ^ jx2 (cid:0) aj < (cid:14)2 ! jg.x2/ (cid:0) l2j < "2/0 < "2 ! 9(cid:14)2(cid:0)(cid:0)0 < (cid:14) ^ 8x.x 6D a ^ jx (cid:0) aj < (cid:14)0 < " ! 9(cid:14)(cid:0)! j.f .x/ C g.x// (cid:0) .l1 C l2/j < "(cid:1)(cid:1):(3)^(cid:1)(cid:1)(cid:1)(cid:1)Similar theorems in this class are LIM– and LIM* for the difference and productof limits; the theorem ContinuousComp states that the composition of two continuousfunctions is continuous; 13 Continuous+ states that the sum of two continuous functionsis continuous and similarly Continuous* and Continuous–, and finally there is a myriad oftheorems about the limits of polynomial functions like limx!ax2 D a2.In 1990, Woody Bledsoe [15] proposed several versions of LIM+ as a challenge problemfor automated theorem proving. The simplest versions of LIM+ (Problems 1 and 2 in [15])are at the edge of what traditional automated theorem provers can prove today (see thecomparison in Section 4.4) but, certainly, LIM* is well beyond their capabilities.One reason why these proofs are difficult for a system is due to the alternating quantifierswhich require the construction of a (cid:14) dependent on a variable " such that certain estimationshold. This is a nontrivial thing to do and difficult for a student as reported, e.g., in [71].12 Alternatively LIM+ can be formalized by the assumptions limx!alimx!a13 The definition of the relation continuous.f / at a point a builds on limx!a.f .x/ C g.x// D l1 C l2.f .x/.f .x/ D l1 and limx!ag.x/ D l2 and the goalE. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10587In most textbooks, the intelligent instantiation of (cid:14) comes out of the blue which is, ofcourse, puzzling for a freshman. The typical way a mathematician goes about to discoverthe proof of such a theorem is to (incrementally) restrict the possible values of (cid:14) as e.g.,recorded in the textbook of Bartle and Sherbert Introduction to Real Analysis [7]. The twoauthors give a recipe on how to proceed, namely an incremental restriction of a naturalnumber k when proving a theorem about the products of limits of sequences .xn/ and .yn/,where the definition of limn!10 < k ^ 8n.n > k ! jxn (cid:0) xj < "/(cid:0)0 < " ! 9k.xn/ D x is:8"(4)(cid:1)(cid:1)(cid:0):The natural number k in this definition (4) corresponds to the real number (cid:14) in thedefinition (2) of limits of functions. In the proof for products of the limits x and y of thesequences .xn/ and .yn/ respectively, Bartle and Sherbert introduce the auxiliary variablesM1 and M upon which K depends: “According to Theorem : : : there exists a real numberM1 > 0 such that jxnj 6 M1 for all n 2 N and we set M D supfM1; jyjg. Hence, we havethe estimatejxn (cid:3) yn (cid:0) x (cid:3) yj 6 M (cid:3) jyn (cid:0) yj C M (cid:3) jxn (cid:0) xj:From the convergence of .xn/ and .yn/ we conclude that if " > 0 is given, then there existnatural numbers k1 and k2 such that if k1 6 n, then jxn (cid:0) xj < "=2M, and if k2 6 n, thenjyn (cid:0) yj < "=2M. Now let k."/ D supfk1; k2g, then if k."/ 6 n we infer thatjxn (cid:3) yn (cid:0) x (cid:3) yj 6 M (cid:3) ."=2 (cid:3) M/ C M (cid:3) ."=2 (cid:3) M/ D ":Since " is arbitrary, this proves that the sequence X (cid:3) Y converges to x (cid:3) y” [7].Inspired by a similar mathematical idea, Bledsoe et al. implemented the limit heuristicfor their special-purpose theorem prover, IMPLY [16] which proves formulae of the formjAj < "1 ! jBj < " by representing B as a linear combination B D k (cid:3) A C l, and byproving the simpler formulae jkj < M, jAj < "=2 (cid:3) M, and jlj < "=2, containing a newvariable M. We shall reconstruct this trick in one of our methods, ComplexEstimate<,below.4.1. Methods for "-(cid:14)-proofsIn proving limit theorems, frequently the magnitude of a term has to be estimated, thatis, we need estimation methods. One of them is ComplexEstimate<, a method forestimating the magnitude of the absolute value of complex terms such as .f .x/ C g.x// (cid:0).l1 C l2/. Table 6 is the frame representation of this method.This method reduces a goal that is a difficult estimation by three simpler estimation goalsin case there is an assumption matching the formula of line L1 in the planning state. EachComplexEstimate< step reduces a goal matching the formula of line L17 to subgoalsthat are instances of the formulae in lines L2, L3, and L4, respectively.Each application of ComplexEstimate< suggests the existence of a real number Mwhose value is restricted by the inequalities in line L2 and L3. This M is then used topropagate the given value restrictions from the implicitly universally quantified variablesto implicitly existentially quantified variables as described in Section 4.3 below.88E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105Table 6Method: ComplexEstimate<.a; b; e1; "/premisesL1, (cid:8)L2,(cid:8)L3, (cid:8)L4conclusions(cid:9) L17appl.cond9(cid:27) GetSubst.a; b/ D (cid:27) AND9k; l CASsplit.a(cid:27); b/ D .k; l/proof schemaL1. (cid:1)L2. (cid:1)L3.L4. (cid:1)L5.L6.L7.L17. (cid:1)‘ jaj < e1‘ jkj 6 M‘ ja(cid:27) j < "=.2 (cid:3) M/‘ jlj < "=2‘ b D b‘ b D k (cid:3) a(cid:27) C l‘ 0 < M‘ jbj < "()(OPEN)(OPEN)(OPEN)(Ax)(CAS;L5)(OPEN)(fix;L6,L7,L1,L2,L3,L4)The application condition evaluates to true if there is a substitution (cid:27) and terms k and lsuch that b can be represented as a linear combination of a(cid:27) , b D k (cid:3) a(cid:27) C l, where a is theterm of line (0) that is in the current planning state. In this case, ComplexEstimate< isapplicable.The proof schema contains a schematic proof of (cid:1) ‘ jbj < " from b D k (cid:3) a(cid:27) C l and 0 <M, and from the formulae in lines L1, L2, L3, and L4, respectively. The line-justificationin L6 CAS, denotes the application of a CAS that has to verify the equation b D k (cid:3) a(cid:27) C l.Note that the line L7 does not occur in the (cid:8)-premises although its justification is OPEN,i.e., it does not have an actual justification yet and, thus, its satisfaction is postponed. Inthe line-justification of L17, ‘fix’ abbreviates a whole subproof that employs, among otherthings, the Triangle Inequality jX C Y j 6 jXj C jY j. An explicit proof schema that details‘fix’ is in Table 7, where ‘triang’ means an application of the Triangle Inequality, ‘trans’means an application of the transitivity theorem, etc.The planner handles the method ComplexEstimate< as follows.(cid:15) If an open goal matches the formula of L17 and if an assumption that matchesthe formula in line L1 is in the planning state, then the parameters a; b; e1, " ofComplexEstimate< are instantiated by this matcher.(cid:15) Now the application conditions are evaluated, that is, first the function GetSubst.a; b/is invoked which returns, if successful, a substitution (cid:27) . In case GetSubst has beensuccessfully executed, the function CASsplit calls a computer algebra system with thearguments a(cid:27) and b and may return two terms k and l such that b D k (cid:3) a(cid:27) C l. Ifsuccessful, the result instantiates the variables k and l and the application conditionsevaluate to true. Then the method is applicable(cid:15) When applicable, the planner inserts ComplexEstimate< into the PDS, the goalL17 is deleted from the planning state, and the new goals corresponding to lines L2,L3, and L4 are added to the planning state.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10589Table 7Detail proof schema of ComplexEstimateLineHyps(cid:1)(cid:1)(cid:1)(cid:1)L1.L2.L3.L4.L5.L6.L7.L8.L9.L10. (cid:1)L11. (cid:1)L12. (cid:1)L13. (cid:1)L14. (cid:1)L15. (cid:1)L16. (cid:1)L17. (cid:1)Formulajaj < e1jkj 6 Mja(cid:27) j < "=.2 (cid:3) M/jlj < "=2b D bb D k (cid:3) a(cid:27) C l0 < Mjbj 6 jk (cid:3) a(cid:27) j C jljjbj 6 jkj (cid:3) ja(cid:27) j C jljjkj (cid:3) ja(cid:27) j C jlj 6 M (cid:3) ja(cid:27) j C jljjbj 6 M (cid:3) ja(cid:27) j C jlj‘‘‘‘‘‘‘‘‘‘‘‘ M (cid:3) ja(cid:27) j < M (cid:3) "=.2 (cid:3) M/‘ M (cid:3) ja(cid:27) j C jlj < M (cid:3) "=.2 (cid:3) M/ C jlj‘jbj < M (cid:3) "=.2 (cid:3) M/ C jljReason(assumption)(OPEN)(OPEN;L1)(OPEN)(Ax)(CAS)(OPEN)(triang;L6)(Mval;L8)(mult6;L2)(trans6;L9,L10)(mult<;L3)(add<;L12)(trans<;L11,L13)‘ M (cid:3) "=.2 (cid:3) M/ C jlj < M (cid:3) "=.2 (cid:3) M/ C "=2(add<;L4)‘‘jbj < M (cid:3) "=.2 (cid:3) M/ C "=2jbj < "(trans<;L14,L15)(simpl;L16)(cid:15) When later on the method is expanded, the proof schema gets inserted into the PDS,and now this expansion postulates the formula 0 < M as a new open subgoal. That is,line L7 becomes an open subgoal in the next lower planning level which is one way tobenefit from a hierarchical planning process. Further recursive expansion of line L6with the justification CAS, will call the computer algebra system (cid:22)CAS which runsin plan-generation mode and returns a proof plan for the justification of line L6.In planning LIM+, at some point the goal (cid:1) ‘ jf .x/ C g.x/ (cid:0) .l1 C l2/j < " is tobe proven when the assumption (cid:1) ‘ jf .X1/ (cid:0) l1j < E1 is available. In this sequent,(cid:1) is a set of assumptions and X1; E1 are implicitly existentially quantified variables.When the application conditions are evaluated GetSubst returns the substitution Tx=X1Uand CASsplit returns the list .1; .g.x/ (cid:0) l2// since the parameter a is instantiated by.f .X1/ (cid:0) l1/ and the parameter b is instantiated by .f .x/ C g.x/ (cid:0) .l1 C l2//. Now thegoal (cid:1) ‘ jf .x/ C g.x/ (cid:0) .l1 C l2/j < " is replaced by the new goals.1/ (cid:1) ‘ j1j 6 M;.2/ (cid:1) ‘ jf .X1/ (cid:0) l1j < "=.2 (cid:3) M/;.3/ (cid:1) ‘ jg.x/ (cid:0) l2j < "=2:The attentive reader will have noticed that the numerous axioms and the theorems of thedomain theory, such as the Triangle Inequality and others, are conspicuously absent; they90E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105are invisible at the planning level! Only when a method such as ComplexEstimate< isexpanded and the proof schema is inserted into the proof plan, are the appropriate axiomsimported from a theory. This is a very natural way to prove a theorem and it is a means toavoid the common paradoxical situation of traditional automated theorem proving, whereexactly those axioms, definitions, and theorems that are needed in the particular proof haveto be stated beforehand, i.e., before we even know the proof. It also avoids many otherproblems that plague traditional systems: the active axioms are kept at a minimum and theproblem that certain axioms such as commutativity or associativity seduce the system intosenseless behaviour (called semantic noise or trashing [4,109]) as we use the axiom nowin a goal-directed way only for a special well defined purpose.While ComplexEstimate< proves inequalities by decomposition, other methodssuch as Solve-b, Solve-f (see Section 4.3), and Solve* treat (in)equalities moredirectly. Solve* is a method that first reduces a goal t1 < t2 with the help of an assumptiont 01 are unifiable by a substitution (cid:27) , to a subgoal t2(cid:27) 0 < t2(cid:27) and then1 < t 0tries to remove t2(cid:27) 0 < t2(cid:27) by a Solve-b method.2, where t1 and t 0UnwrapHyp, a method used in forward planning, highlights a subformula of anassumption by the Focus method, and then it applies various other methods (e.g.,AndElimination, ImpliesElimination) in order to extract the highlightedsubformula as a single assumption. In other words, this method ‘unwraps’ this subformulaout of the original assumption. The ultimate goal of this method in proving limittheorems is to prepare an assumption such that it can be used as the L1 assumption inComplexEstimate<.The method RemoveFocus removes a focus which was set by Focus beforehand, themethod Normalize specifies a tactic that calls submethods such as ImpliesIntro-duction and AndIntroduction. All in all, we have less than two dozen methods forthis (small) mathematical area that by and large correspond to what a student would haveto learn in order to master the field.4.2. Control-rulesEven the most appropriate methods do not imply that a plan can be found automatically.In fact, our planner cannot find a plan for LIM+ without additional control knowledge. Forthis reason, we manually extracted mathematical problem solving behaviour typically usedfor proving limit theorems and translated it into control knowledge explicitly representedby control-rules. We demonstrate this for the following very simple problem solvingbehaviour. (More complicated meta-reasoning is necessary, e.g., for finding proofs bycontradiction. This is, however, beyond the scope of this paper.)(cid:15) Linear inequalities can be shown by a direct estimation or by a decomposition of theterm to be estimated. For the latter, often a proof assumption has to be refered to.This can be translated into the following—verbally expressed—control knowledge forproof planning,(cid:15) Linear inequality goals can be removed by one of the methods Solve-b, Solve*,or by ComplexEstimate<. The latter requires some preparation by UnwrapHypwhich extracts a subformula s from an assumption. Afterwards ComplexEstima-te< can use the assumption s.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10591In turn, this knowledge can be formally encoded into the control-rule(control-rule prove-inequalities(kind method-choice)(IF (goal-matches (?goal (?x < ?y))))(THEN (prefer ((Solve-b ?goal)(Solve* ?goal)(ComplexEstimate< ?goal)(UnwrapHyp ?goal)))))This rule together with the following control-rules were sufficient to successfully plan allthe above mentioned limit theorems.(control-rule CS-Introduction(kind method-choice)(IF (last-method Skolemize))(THEN(prefer (InitializeCS))))(control-rule Solve-f-first(kind method-choice)(IF (inequality-assumption ?assumption))(THEN(prefer (Solve-f ?assumption))))The latter ensures that any (in)equality assumption is passed to the constraint solver assoon as possible.4.3. Computer algebra and constraint solvingAs described above, a computer algebra system computes instantiations of certainterms when the application conditions of ComplexEstimate< are evaluated. Any suchinstantiation has to be verified later on, when the node justified by CAS is expanded into acheckable ND-proof.Our propagation-based constraint solver COSIE works for the constraint domain Rwhich has been extended by the interpreted absolute value function (cid:21)x jxj and the divisionfunction (cid:21)x(cid:21)y x=y. Constraints are (in)equalities, i.e., formulae of the form x < y, x 6 y,or x D y. The constraint store is represented by sets of intervals described by sets of lowerand upper bounds. A new constraint is introduced into the store, simplified, and propagated,if it is consistent with the current constraint store.The purpose of the methods Solve-b (Solve-f) is to remove a simple (in)equalitygoal (to employ a constraint assumption (by adding it to the constraint store or by checkingentailment. See Section 3)).Solve-b is a candidate method as soon as there is an (in)equality goal. It is applicableif no implicitly existentially quantified variable occurs in the goal and the goal is entailedby the current constraint store or if an implicitly existentially quantified variable occurs92E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105in the goal, and if this constraint goal is consistent with the constraint store. The latter ischecked by tell. All of this information is represented in appl.cond.For instance, while planning LIM+, Solve-b.0 < (cid:14)1/ is applicable because noimplicitly existentially quantified variable occurs in this goal and .0 < (cid:14)1/ is entailed bythe constraints .0 < D/ and .D 6 (cid:14)1/ from the constraint store. Furthermore, Solve-b isapplicable to the subgoal (j1j 6 M) because the implicitly existentially quantified variableM occurs in the goal and .j1j 6 M) is consistent with the constraint store.The method Solve-f handles constraint assumptions in forward planning. Forexample, while planning LIM+, Solve-f introduced .0 < D/ into the constraint storeas a constraint hypothesis.To summarize, while planning the proof of the LIM+ theorem, the Solve steps(Solve-b and Solve-f) tell the following sequence of constraints to the constraintsolverj1j 6 M;0 < D;0 < ";x D X1; E2 6 "=2; x D X2; D 6 (cid:14)2;D 6 (cid:14)1;0 < E2;0 < E1;0 < (cid:14)1;0 < (cid:14)2;0 < M; E1 6 "=.2 (cid:3) M/;where the variables D; E1; E2 and the (Eigen)variables (cid:14)1; (cid:14)2; " are those of the originalplanning problem and M is the auxiliary variable introduced by ComplexEstimate<.Now the upper bound "=2 for E1 is propagated from the constraints 1 6 M and E1 6"=.2 (cid:3) M/. This leads to final constraint store shown in Table 8.In other words, we have that a lower bound for E2 is 0 and an upper bound for E2 is"=2; a lower bound for D is 0 and the upper bounds are (cid:14)1; (cid:14)2, etc, and the attentive readerfamiliar with "-(cid:14)-proofs will no doubt have noticed that this is exactly the sequence ofevents a good student would have to go through in a maths class.At the end of the session, a reflection of the final constraint store removes redundantbounds such as "=.2 (cid:3) M/. The reflection favours numeric constants and symbolic termswithout variables and the answer constraint (with respect to the variables E1; E2; D)resulting from the reflection isC.D; E1; E2/: E1 6 "=2 ^ E2 6 "=2 ^ D 6 (cid:14)1 ^ D 6 (cid:14)2:Table 8000000<<<<<<(cid:14)1(cid:14)2"E2DE11 6(cid:0)1 <MX1 D x D X2<<<C1;C1;C1;6 "=2;6 (cid:14)2; (cid:14)1I6 "=.2 (cid:3) M/; "=2;6 "=.2 (cid:3) E1/IC1<E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10593Fig. 5. Unexpanded proof plan for LIM+.The planner instantiates the meta-variable C by C. Later the constraint solver searches forterms to instantiate D; E1; E2, and M, respectively and then the planner can instantiatethese variables everywhere in the proof plan. For LIM+ the instantiation of the implicitlyexistentially quantified variables is [D=(cid:14) D min.(cid:14)1; (cid:14)2/], [E1="1 D "=2], [E2="2 D "=2].4.4. ResultsWe successfully planned all the challenge problems of Woody Bledsoe, i.e., thethe theorems ContinuousComp, Continuous+,c D c, and many theorems about limits oflimx!alimitContinuous–, Continuous*, limx!atheorems LIM+, LIM–, LIM*,x D a;x2 D a2.polynomial functions like limx!aA high-level proof plan for LIM+ is shown in Fig. 5, where the dashed parts representthose methods/subplans that are planned later at a lower hierarchical level. Some ofthe subgoals (and corresponding methods) are hidden in the method UnwrapHyp thatproduced subgoals for the next lower level, in particular several inequalities that aresatisfied by Solve-b or Solve*. In the end the expanded plan has 215 nodes.Among the proven theorems are several that are beyond the capabilities of traditionalsystems, e.g., LIM* and ContIfDeriv. One reason why LIM* is more complicated to provethan LIM+ becomes clear from its plan in Fig. 6. The method ComplexEstimate< isapplied once only in the plan for LIM+, whereas for LIM* this trick has to be applied threetimes because the linear decomposition of the term f .x/ (cid:3) g.x/ (cid:0) .l1 (cid:3) l2/ yields morecomplicated subgoals than the decomposition of f .x/ C g.x/ (cid:0) .l1 C l2/. Fig. 6 showsa screen dump of the plan for LIM* that was automatically generated by the (cid:127)MEGA94E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105Fig. 6. LIM* proof plan as presented by the (cid:127)MEGA interface.Table 9Theorem(cid:127)MEGA (matching attempts)OTTER (generated clauses)/modeLIM+LIM+LIM*ContIfDeriv3463464674903650 /spec heuristic for LIM+– / auto mode– / any– / anysystem. The circles indicate nodes of the plan containing methods and subgoals, the squaresindicate coreferences, and the triangles indicate assumptions and hypotheses in the proof(they are differentiated by colors, hence not visible in this black and white print); each iconcan be clicked on to display the formula and method it stands for.A comparison of the search spaces of our proof planning system and the automatedtheorem prover, OTTER, shows some interesting characteristics (Table 9).For a simple version of LIM+ and with a particular strategy, OTTER generates a searchspace of 3650 clauses and keeps 1418 clauses. 14 This strategy is tailored to LIM+ anddoes not work for LIM* or other limit theorems. In auto mode, OTTER generates up to437, 706, 898 clauses and does not succeed in proving LIM+. In comparison, the searchspace of our planner is about 350 matching attempts for LIM+. 1514 Using Bill McCune’s specific input file.15 This plan can still be optimized.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10595Currently, we are looking at all the theorems, examples, and exercises in two chaptersof [7] about limits of sequences and of functions and about continuity. So far we havefound that even more theorems can be proved with the methods and control-rules decribedabove, e.g., the theorem that says: if f .x/ converges to zero and the magnitude of g.x/f .x/ D 0 ^ 9y:jg.x/j <has an upper bound, then f .x/ (cid:3) g.x/ converges to zero ( limx!af .x/ (cid:3) g.x/ D 0) or the Squeeze Theorem (for sequences .xn/; .yn/, and .zn/y ! limx!aof real numbers with xn 6 yn 6 zn for all n 2 N holds that if lim.xn/ D lim.zn/,then .yn/ is convergent and lim.xn/ D lim.yn/ D lim.zn/ (Theorem 3.2.7 in [7])). Forsome other examples we need additional facts about the particular functions involved,e.g., for trigonometric functions we need to know the laws of trigonometry. Of course,in order to find proof plans for all the theorems, examples, and exercises in the twochapters, we have to introduce some general methods like Indirect and a few moremethods for estimation, e.g., FactorialEstimate, EnvironmentEstimate, andComplexEstimate>. The latter method is needed, for instance, for proving the theoremLIMdiv and the theorem about the uniqueness of a limit. 16 This indicates that a coupleof dozen methods and control rules really will capture all the mathematical knowledgethat appears to be necessary to master this albeit small branch of mathematics. With newmethods the control knowledge has to be extended too.Some of the examples of these two chapter of [7] cannot be proof planned automaticallywith our current repertoire of techniques, e.g., Theorem 4.1.8, Exercise 4.1(3), andExercise 4.1(12). The reason is that they would need a strategy for eagerly instantiatingvariables that is flexibly controlled. In addition, with the progress in a textbook, moremethods become available that employ the theorems already proved. For instance, theapplication of the actual limit theorems LIM+, LIM*, etc. can greatly facilitate the solutionof examples and exercises in the chapters as compared with "-(cid:14)-proofs. This means thatwe need to plan with different sets of methods. These problems gave rise to further developour proof planning approach to a multi-strategy planning [88,90].Currently, the planner, the domain, and (cid:22)CAS are implemented in Common LISP(CLOS) while the Lovely (cid:127) User Interface, L(cid:127)UI, as well as the constraint solver areimplemented in the concurrent logic programming language Mozart–Oz [112].5. The use of proof plans for proof presentationWell known from paradigm shifts [68] in physics, for example, is that problems that arepuzzling at best or outright unsolvable in the old paradigm, suddenly fall into place likein a beautiful jigsaw puzzle. In the case of proof planning, this seems to apply at least toproof presentation and proof by analogy as well.The output of traditional automated theorem proving systems lists a sequence ofcalculus-level steps, such as resolution and paramodulation. These ‘proofs’ are hardlyreadable, let alone intuitively understandable as a mathematical proof. A comprehensibleexplanation is essential, however, at least for interactive and (semi)automated theoremproving systems that could possibly provide a basis for a tutor or assistant system.16 This theorem is formalized by: limx!af .x/ D l1 ^ limx!af .x/ D l2 ! l1 D l2:96E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105This problem was recognized long ago inter alia by Peter Andrews [2], FrankPfenning [100], Dale Miller [94], Christoph Lingenfelder [74], Alan Robinson [105],Huang and Siekmann [52] and others and several attempts have been made to produceproof presentations based on ND-rules. In fact, proof presentation became a researchtopic in its own right [36]. More recently, the presentation of proofs (found by traditionalautomated theorem proving systems) in natural language has been realized in ILF [29],Theorema [18], and PROVERB [51]. ILF provides a schematic verbalization, whereasPROVERB abstracts the calculus-level proof first to the so-called assertion level 17 and thenemploys linguistic knowledge in order to combine single assertion level steps into a morecoherent natural language presentation.Nevertheless, there was no satisfying general approach to a comprehensible proofpresentation so far. We think that this is due to the fact that all automated proof presentationup to now is based on representations of proofs found by traditional theorem provingsystems whose level of abstraction is too low and too far removed from the mathematicaltheory and structures the proof is formulated in. Even the verbalization at the somewhatabstract assertion level is not necessarily the most natural and best way to communicatea proof to mathematicians or students. Verbalized proof steps can be far more abstractthan assertion-level steps and may contain explanations too. For example, proofs of limittheorems in Bartle and Sherbert’s book [7] contain phrases like “We need to estimate themagnitude of : : :” and there may also be explanations on why a certain step was chosen inthe proof.Now, the abstraction level(s) contained in proof plans provide the basis for a trulyhierarchical presentation and the design of domain-dependent and -independent methodsleads naturally to the design of verbalization schemes that reflect mathematical practiceand standard. Furthermore, the subproofs contributed by domain-specific reasoners suchas constraint solvers can be easily isolated and then represented separately in the finalpresentation.A full, still abstract, verbalization of the LIM+ plan that uses a schematic verbalizationof methods, is the following. 18To show that f .x/ C g.x/ converges to L1 C L2..(cid:3)/ Let (cid:14) be smaller than (cid:14)1; (cid:14) be smaller than (cid:14)2, and "1; "2 be smaller than "=2.(1) We need to estimate the magnitude of(cid:12)(cid:12)(cid:12).f .x/ (cid:0) L1/ C .g.x/ (cid:0) L2/(cid:12) D(cid:12)(cid:12)f .x/ C g.x/ (cid:0) .L1 C L2/(cid:12)(cid:12):(2) To do this, we use the Triangle Inequality and obtain(cid:12)(cid:12)(cid:12)g.x/ (cid:0) L2(cid:12) C(cid:12)(cid:12)f .x/ C g.x/ (cid:0) .L1 C L2/(cid:12)(cid:12)f .x/ (cid:0) L1(cid:12)(cid:12) 6(cid:12)(cid:12):This goal can be shown in three steps:(cid:15) There exists an M such that j1j 6 M, and(cid:15) jf .x/ (cid:0) L1j < "=.2 (cid:3) M/, and17 An assertion is an axiom or definition the proof refers to.18 The occurrence of M is due to the more general presentation needed for other limit theorems. It is, strictlyspeaking, not necessary for the LIM+ verbalization. The itemization would not occur in a textbook but is usedhere to show the correspondence between verbalization and proof plan.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10597(cid:15) jg.x/ (cid:0) L2j < "=2.(3) For a real number 1 6 M(4) by hypothesis, if "=.2 (cid:3) M/ > 0, there exists (cid:14)1 such that for all x, if jx (cid:0) aj < (cid:14)1(5) by hypothesis if "=2 > 0, there exists (cid:14)2 such that for all x, if jx (cid:0) aj < (cid:14)2, thenthen jf .x/ (cid:0) L1j < "=.2 (cid:3) M/jg.x/ (cid:0) L2j < "=2.(6) From .(cid:3)/ follows that(7) if jx (cid:0) aj < D, then(cid:12)(cid:12)f .x/ C g.x/ (cid:0) .L1 C L2/(cid:12)(cid:12) 6 M (cid:3) jf .x/ (cid:0) L1j C jg.x/ (cid:0) L2j< M (cid:3) "=.2 (cid:3) M/ C "=2 D "and therefore jf .x/ C g.x/ (cid:0) .L1 C L2/j < ".(8) Since " > 0 is arbitrary,(9) the theorem is proven.Every item in the above verbalization corresponds directly to (parts of) one of themethods in Fig. 5. Not every method is verbalized and ComplexEstimate has severalverbalization parts. In more detail, the steps (1), (2), and (7) above are generated asa verbalization of ComplexEstimate<; steps (3), (4), and (5) verbalize subproofsof ComplexEstimate<’s subgoals, and step .(cid:3)/ verbalizes InitializeCS by theanswer constraint formula.Fig. 7. Screen shot of (cid:127)MEGA showing a proof plan of LIM+ and a local verbalization.98E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105Currently, the verbalization of single methods and of whole proof plans is automaticallygenerated and presented in a hypertext window of (cid:127)MEGA’s interface L(cid:127)UI [87,89] asshown in Fig. 7 in the bottom right window. The local hypertext verbalization, i.e., theverbalization of a method, corresponds to the nodes (methods) in the plan that are clickedon. Proofs of subgoals produced by the method are linked by hyperlinks. The globalverbalization of a whole plan can still be improved considerably. Linguistic knowledge hasto be employed and for combining the verbalization of several methods into a nice linearpresentation of the whole proof plan as in the automatic verbalization of the assertion-levelproofs [51] discussed above.6. ConclusionThis article introduces knowledge-based proof planning that borrows techniques andformalisms from many branches of AI, such as hierarchical planning, knowledgerepresentation in frames and explicitly represented control-rules, constraint solving,search-based deduction systems as well as tactical and meta-level reasoning. We use ageneral-purpose planner and we encode the mathematical domain knowledge, as we mayfind it in a graduate textbook on mathematics, into methods, theory-specific reasoners, andcontrol-rules.Control-rules make the control far more flexible and considerably extend the meta-levelreasoning facilities of proof planning that are used for global guidance. This declarativelyrepresented control knowledge can express conditions for a decision that depends on thecurrent planning state, the planning history, failed proof attempts, the current partial proofplan, the constraint state, the available resources, the user model, the theory in which toplan, typical models of the theory, etc. and the solution of the more difficult problemswould have been impossible without it.In contrast to conventional planning domains, a proof planning domain is representedby mathematical theories, such as group theory or calculus, that contain as usual axioms,definitions, theorems, and lemmata but also operators, control-rules, and domain-specificexternal reasoners. The operators, called methods, represent natural mathematical proofsteps and the control-rules encode mathematical knowledge on how to proceed whensearching for a proof.For a well known mathematical domain, the limit theorems which we used as an exampleto serve the need of demonstration, we have collected the relevant mathematical knowledgeand represented it in methods and control rules, and also used existing representations ofa constraint solver and a computer algebra system. Based on this knowledge, (cid:127)MEGA’sgeneral-purpose proof planner was able to prove more difficult than other current proofplanners and than traditional theorem proving systems.Todays traditional theorem proving systems, such as OTTER or SPASS can searchspaces of several billion clauses. The maximal proof length that can be found that way isaround several hundred resolution or paramodulation steps. With proof planning we couldpotentially find a plan of several hundred steps that could then be expanded into a calculus-level proof of several thousand steps. Proofs of that length are not uncommon for difficultmathematical theorems but also arise in industrial applications, e.g., in program verificationE. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10599tasks. For instance, the VSE verification system [57], which is now routinely used forindustrial applications in the German Centre for Artificial Intelligence Research (DFKI)in Saarbrücken, interactively synthesized proofs of up to 8,000 and 10,000 steps for somedifficult assertions in the verification of a television and radio switching program. Theseproofs which often represent several weeks of labor with the system, are, by their verylength, one or two orders of magnitude beyond fully automated methods but could comeinto the range of possibilities, if the proof planning paradigm turns out to be successful inthese settings as well.However, our main interest right now is more in everyday mathematics. Sacrificing thehope that a traditional theorem proving engine based on search at the calculus-level canever evolve into a mathematical assistant system, gives way to an alternative within whichtraditional automated theorem proving is a rather small but still useful subtask.Using the well known albeit exiguous mathematical field of limit theorems, we havebeen able to show that realistic mathematics can indeed be carried out on a machine.Metaphorically speaking, we have shown the atom can be split and indeed it gives offenergy—but as a show case for a generally useful device and its everyday application thetest case is still little representative.Therefore, several Ph.D. students are currently extending our knowledge needed in proofplanning to fields such as linear algebra, analysis, and finite group theory. In particular,we are planning to set up a distinguished international consortium of mathematicians,computer scientists, and some interested companies to encode significantly broad areasof mathematics into MBase and to use this knowledge for proof planning with (cid:127)MEGA.We believe that the extraction and explicit representation of the knowledge of widemathematical fields will—just like the motivation for CYC—ultimately be useful not onlyfor computer-supported mathematics but also for mathematical education systems.6.1. Related workThis work has been deeply influenced by the work of Woody Bledsoe. The knowledgeacquisition for the design of methods for limit proof plans is similar to the ideas in thespecial-purpose theorem prover IMPLY [16] and to Beeson’s work [9] whose bias is,however, more towards special-purpose provers. Beeson’s "-(cid:14)-proofs with the Mathpertand Weierstrass systems were developed in parallel to our’s [83].More generally, our approach has the use of theory-specific knowledge in common withother special-purpose theorem provers, such as a system for monoids [38], for geometry,or for set theory [48].Closest to our work, is the proof planning approach developed by Alan Bundy for theCLAM system. As opposed to our (domain-dependent) control knowledge represented incontrol-rules, CLAM uses rippling, a domain-independent difference reduction heuristicwhich is encoded in the preconditions of methods. LIM+ was proved in CLAM with coloredrippling [117], an extension of rippling but LIM* and other theorems turned out to be toodifficult for CLAM.As for the integration of external reasoners into automated theorem proving systems,several attempts have recently been made for integrating CAS’s (cf. [6,27,44,63]) and fewattempts of integrating constraint solving [115] into ATP.100E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105Our work relates to research in planning, e.g., in Prodigy [96], that uses control-rules.Weld [122] and Veloso et al. [120] discuss the superiority of knowledge-based searchwith a production system of forward-chaining rules over implicitly encoded control, e.g.,by functional rating. Such control-rules were first explored in SOAR [69] and then inProdigy [96]. Gerberding and Noltemeier [40] formulate program-like rules for strategiesin theorem proving by mathematical induction.Very recently, there has been a related approach for presenting proofs that verbalizesproofs manually found with the tactical prover Nuprl [49]. It also verbalizes proofs at amore abstract level.Last but not least, the presented work owes to other developments in the (cid:127)MEGA group,in particular, the design of methods [54], the integration of computer algebra systems [63],and analogy-driven proof plan construction [82,93].AcknowledgementThis work builds upon the paradigm change in the work of the (cid:127)MEGA group inSaarbrücken and the discussion over many years that led to it are gratefully acknowledged.Last but not least, the implementation builds upon the (cid:127)MEGA system whose developmentwas supported by many people [10].Furthermore we would like to thank Bob Boyer for his help with the IMPLY prover whenour project started, and in particular Alan Bundy and the DREAM group in Edinburghfor many discussions and their influence. We thank Jaime Carbonell and Manuela Velosofor discussions about control-rules and Martin Müller for his help to getting started withconstraint solving. Last but not least we thank my students Carsten Ullrich and JürgenZimmer who implemented much of the knowledge-based proof planning and kept abreastof the many changes of the (cid:127)MEGA system while this work lasted.References[1] R. Anderson, W.W. Bledsoe, A linear proof format for resolution with merging and a new technique forestablishing completeness, J. ACM 17 (3) (1970) 525–534.[2] P.B. Andrews, Transforming matings into natural deduction proofs, in: Proc. 5th International Conferenceon Automated Deduction, Springer, Berlin, 1980, pp. 281–292.[3] P.B. Andrews, Theorem proving via general matings, J. ACM 28 (1981) 193–214.[4] F. Baader, J. Siekmann, Handbook of Logic in Artificial Intelligence, Oxford University Press, Oxford,1997, Chapter “Unification Theory”.[5] A.M. Ballantyne, W.W. Bledsoe, Automatic proofs of theorems in analysis using non-standard techniques,J. ACM 24 (1977) 353–374.[6] C. Ballarin, K. Homann, J. Calmet, Theorems and algorithms: An interface between Isabelle and Maple, in:A.H.M. Levelt (Ed.), Proc. International Symposium on Symbolic and Algebraic Computation (ISSAC’95),Berkeley, CA, USA, ACM Press, New York, 1995, pp. 150–157.[7] R.G. Bartle, D.R. Sherbert, Introduction to Real Analysis, Wiley, New York, 1982.[8] P. Baumgartner, U. Furbach, PROTEIN: A prover with a theory extension interface, in: A. Bundy (Ed.),Proc. 12th International Conference on Automated Deduction (CADE-12), Nancy, France, Lecture Noteson Artificial Intelligence, Vol. 814, Springer, Berlin, 1994, pp. 769–773.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105101[9] M. Beeson, Automatic generation of epsilon-delta proofs of continuity, in: J. Calment, J. Plaza (Eds.),Artificial Intelligence and Symbolic Computation, Lecture Notes on Artificial Intelligence, Vol. 1476,Springer, Berlin, 1998, pp. 67–83.[10] C. Benzmueller, L. Cheikhrouhou, D. Fehrer, A. Fiedler, X. Huang, M. Kerber, M. Kohlhase, K. Konrad,A. Meier, E. Melis, W. Schaarschmidt, J. Siekmann, V. Sorge, OMEGA: Towards a mathematicalassistant, in: W. McCune (Ed.), Proc. 14th International Conference on Automated Deduction (CADE-14),Townsville, Springer, Berlin, 1997, pp. 252–255.[11] W. Bibel, On matrices with connections, J. ACM 28 (1981) 633–645.[12] W.W. Bledsoe, Non-resolution theorem proving, Artificial Intelligence 9 (1977) 1–35.[13] W.W. Bledsoe, Some thoughts on proof discovery, in: Proc. IEEE Symposium on Logic Programming, SaltLake City, UT, 1986, pp. 2–10.[14] W.W. Bledsoe, The use of analogy in automatic proof discovery, Technical Report AI-158-86, Microelec-tronics and Computer Technology Corporation, Austin, TX, 1986.[15] W.W. Bledsoe, Challenge problems in elementary analysis, J. Automat. Reason. 6 (1990) 341–359.[16] W.W. Bledsoe, R.S. Boyer, W.H. Henneman, Computer proofs of limit theorems, Artificial Intelli-gence 3 (1) (1972) 27–60.[17] D. Borrajo, M. Veloso, Lazy incremental learning of control knowledge for efficiently obtaining qualityplans, AI Review J. (Special Issue on Lazy Learning) 10 (1996) 1–34.[18] B. Buchberger, T. Jebelean, F. Kriftner, M. Marin, E. Tomuta, D. Vasaru, An overview of the theoremaproject, in: Proc. International Symposium on Symbolic and Algebraic Computation (ISSAC’97), 1997.[19] A. Bundy, Doing arithmetic with diagrams, in: Adv. Papers IJCAI-73, Stanford, CA, 1973, pp. 130–138.[20] A. Bundy, The use of explicit plans to guide inductive proofs, in: E. Lusk, R. Overbeek (Eds.), Proc. 9thInternational Conference on Automated Deduction (CADE-9), Argonne, IL, Lecture Notes in ComputerScience, Vol. 310, Springer, Berlin, 1988, pp. 111–120.[21] A. Bundy, F. van Harmelen, J. Hesketh, A. Smaill, Experiments with proof plans for induction, J. Automat.Reason. 7 (1991) 303–324.[22] A. Bundy, F. van Harmelen, A. Ireland, A. Smaill, Extensions to the rippling-out tactic for guiding inductiveproofs, in: M.E. Stickel (Ed.), Proc. 10th International Conference on Automated Deduction (CADE-10),Lecture Notes in Computer Science, Vol. 449, Springer, Berlin, 1990.[23] H.-J. Bürckert, A resolution principle for constrained logics, Artificial Intelligence 66 (2) (1994) 235–271.[24] J.G. Carbonell, Derivational analogy: A theory of reconstructive problem solving and expertise acquisition,in: R.S. Michalsky, J.G. Carbonell, T.M. Mitchell (Eds.), Machine Learning: An Artificial IntelligenceApproach, Morgan Kaufmann, Los Altos, CA, 1986, pp. 371–392.[25] L. Cheikhrouhou, J. Siekmann, Planning diagonalization proofs, in: Proc. 8th International Conferenceon Artificial Intelligence: Methodology, Systems, Applications (AIMSA’98), Sozopol, Bulgaria, LectureNotes on Artificial Intelligence, Vol. 1480, Springer, Berlin, 1998.[26] A. Church, A formulation of the simple theory of types, J. Symbolic Logic 5 (1940) 56–68.[27] E. Clarke, X. Zhao, Analytica-A Theorem Prover in Mathematica, in: Proc. 11th Conference on AutomatedDeduction (CADE-11), Springer, Berlin, 1992, pp. 761–763.[28] R.L. Constable, S.F. Allen, H.M. Bromley, W.R. Cleaveland, J.F. Cremer, R.W. Harper, D.J. Howe, T.B.Knoblock, N.P. Mendler, P. Panagaden, J.T. Sasaki, S.F. Smith, Implementing Mathematics with the NuprlProof Development System, Prentice-Hall, Englewood Cliffs, NJ, 1986.[29] B.I. Dahn, A. Wolf, Natural language presentation and combination of automatically generated proofs, in:Proc. FroCos’96, Kluwer, Dordrecht, 1996, pp. 175–192.[30] M. Davis, A computer program for Presburger’s algorithm, in: A. Robinson (Ed.), Proving Theorems (asdone by Man, Logician, or Machine), Cornell University, Ithaca, NY, 1957, pp. 215–233. Summary oftalks presented at the 1957 Summer Institute for Symbolic Logic.[31] M.D. Davis, R. Sigal, E.J. Weyuker, Computability, Complexity, and Languages: Fundamentals ofTheoretical Computer Science, 2nd ed., Academic Press, New York, 1994.[32] W. Davis, H. Porta, J. Uhl, Calculus & Mathematica, Addison-Wesley, Reading, MA, 1994.[33] N. Eisinger, H.J. Ohlbach, The Markgraf Karl Refutation Procedure (MKRP), in: J. Siekmann (Ed.), Proc.8th International Conference on Automated Deduction (CADE-8), Lecture Notes in Computer Science,Vol. 230, Springer, Berlin, 1986, pp. 681–682.102E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105[34] G. Faltings, U. Deker, Interview: Die Neugier, etwas ganz genau wissen zu wollen, Bild der Wissenschaft,(10) (1983) 169–182.[35] R.E. Fikes, N.J. Nilsson, STRIPS: A new approach to the application of theorem proving to problemsolving, Artificial Intelligence 2 (1971) 189–208.[36] First International Workshop on Proof Transformation and Presentation, Dagstuhl, 1997.[37] A. Franke, M. Kohlhase, MBase: Representing mathematical knowledge in a relational database, in:A. Armando, T. Jebelean (Eds.), Calculemus’99, 1999, pp. 135–152.[38] H. Ganzinger, U. Waldmann, Theorem proving in cancellative abelian monoids, in: M.A. McRobbie, J.K.Slaney (Eds.), Proc. 13th Conference on Automated Deduction (CADE-13), Lecture Notes on ArtificialIntelligence, Vol. 1104, Springer, Berlin, 1996, pp. 388–402.[39] G. Gentzen, Untersuchungen über das logische Schließen I & II, Math. Zeitschrift (39) (1935) 572–595.[40] S. Gerberding, A. Noltemeier, Incremental proof-planning by meta-rules, in: Proc. 10th Florida Interna-tional AI Conference (FLAIRS-97), Dayton Beach, FL, 1997.[41] M. Gordon, R. Milner, C.P. Wadsworth, Edinburgh LCF: A mechanized logic of computation, LectureNotes in Computer Science, Vol. 78, Springer, Berlin, 1979.[42] P. Graf, Term indexing, Lecture Notes on Artificial Intelligence, Vol. 1053, Springer, Berlin, 1996.[43] J. Hadamard, The Psychology of Invention in the Mathematical Field, Princeton Univ. Press, Princeton,1945.[44] J. Harrison, L. Théry, Reasoning about the reals: The marriage of HOL and Maple, in: A. Voronkov(Ed.), Proc. 4th International Conference on Logic Programming and Automated Reasoning (LPAR’93),St. Petersburg, Lecture Notes on Artificial Intelligence, Vol. 698, Springer, Berlin, 1993, pp. 351–353.[45] P. Hayes, D.B. Anderson, An arraignment of theorem-proving; or, the logician’s folly, Memo 54,Department Computational Logic, Edinburgh University, 1972.[46] C. Hewitt, Description and theoretical analysis of PLANNER, Technical Report, 1972.[47] T. Hillenbrand, A. Buch, Waldmeister: Development of a high performance completion-based theoremprover, Seki Report SR-96-01, Universität Kaiserslautern, 1996.[48] L.M. Hines, Str+ve(cid:26): The stri+ve-based subset prover, in: Proc. 10th Conference on Automated Deduction(CADE-10), 1990.[49] A.M. Holland-Minkley, R. Barzilay, R.L. Constable, Verbalization of high-level formal proofs, in: Proc.AAAI-99, Orlando, FL, 1999.[50] Ch. Holzbaur, OFAIclp.q; r/ manual, Technical Report TR-95-09, Austrian Institute for ArtificialIntelligence, Wien, 1995.[51] X. Huang, A. Fiedler, Proof verbalization as an application of nlg, in: Proc. AAAI-97, Providence, RI,Morgan Kaufmann, CA, 1997, pp. 965–970.[52] X. Huang, J.Siekmann, Proof Presentation, Springer, to appear.[53] X. Huang, M. Kerber, M. Kohlhase, E. Melis, D. Nesmith, J. Richts, J. Siekmann, Omega-MKRP: A proofdevelopment environment, in: Proc. 12th International Conference on Automated Deduction (CADE-12),Nancy, France, 1994.[54] X. Huang, M. Kerber, M. Kohlhase, J. Richts, Methods—the basic units for planning and verifying proofs,in: Proc. Jahrestagung für Künstliche Intelligenz KI-94, Saarbrücken, Springer, Berlin, 1994.[55] X. Huang, Human Oriented Proof Presentation: A Reconstructive Approach, INFIX Publ. Comp., 1996.[56] D. Hutter, Guiding inductive proofs, in: M.E. Stickel (Ed.), Proc. 10th International Conference onAutomated Deduction (CADE-10), Lecture Notes in Artificial Intelligence, Vol. 449, Springer, Berlin,1990.[57] D. Hutter, B. Langenstein, C. Sengler, J.H. Siekmann, W. Stephan, A. Wolpers, Deduction in theverification support environment (VSE), in: M.-C. Gaudel, J. Woodcock (Eds.), Proc. 3rd InternationalSymposium of Formal Methods Europe, Oxford, England, 1996, pp. 268–286.[58] J. Jaffar, J.-L. Lassez, Constraint logic programming, in: Proc. 14th ACM Symposium on Principles ofProgramming Languages, 1987, pp. 111–119.[59] J. Jaffar, M.J. Maher, Constraint logic programming: A survey, J. Logic Programming 19 (20) (1994)503–581.[60] J. Jaffar, S. Michaylow, P. Stuckey, R. Yap, The CLP(R) language and system, ACM Trans. ProgrammingLanguages 14 (3) (1992) 339–395.E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105103[61] S. Kambhampati, Refinement planning: Status and prospectus, in: Proc. AAAI-96, Portland, OR, MorganKaufmann, San Mateo, CA, 1996, pp. 1331–1336.[62] S. Kambhampati, B. Srivastava, Universal classical planner: An algorithm for unifying state-space andplan-space planning, in: M. Ghallab, A. Milani (Eds.), New Directions in AI Planning, IOS Press,Amsterdam, 1996, pp. 61–78.[63] M. Kerber, M. Kohlhase, V. Sorge, Integrating computer algebra into proof planning, J. Automat. Reason.,to appear.[64] M. Kerber, E. Melis, Using exemplary knowledge for justified analogical reasoning, in: M. De Glas,Z. Pawlak (Eds.), WOCFAI’95—Proc. Second World Conference on the Fundamentals of ArtificialIntelligence, Paris, France, 1995, pp. 157–168.[65] M. Kerber, E. Melis, J. Siekmann, Reasoning with assertions and examples, in: Proc. AAAI SpringSymposium on Artificial Intelligence and Creativity, 1993, pp. 61–66.[66] K.R. Koedinger, J.R. Anderson, Abstract planning and perceptual chunks: Elements of expertise ingeometry, Cognitive Sci. 14 (1990) 511–550.[67] G. Kreisel, Mathematical logic, in: T. Saaty (Ed.), Lectures on Modern Mathematics, Vol. 3, Wiley, NewYork, 1965, pp. 95–195.[68] T.S. Kuhn, Die Struktur Wissenschaftlicher Revolutionen, Suhrkamp in German, Frankfurt/M., 1976.[69] J. Laird, A. Newell, P. Rosenbloom, SOAR: An architecture for general intelligence, Artificial Intelli-gence 33 (1) (1987) 1–64.[70] C. Leckie, I. Zukerman, Inductive learning of search control rules for planning, Artificial Intelli-gence 101 (1–2) (1998) 63–98.[71] U. Leron, Heuristic presentations: The role of structuring, For the Learning of Mathematics 5 (3) (1985)7–13.[72] R. Letz, J. Schumann, S. Bayerl, W. Bibel, SETHEO: A high performance theorem prover, J. Automat.Reason. 8 (2) (1992) 183–212.[73] H.R. Lewis, C.H. Papadimitriou, Elements of the Theory of Computation, Prentice-Hall, Englewood Cliffs,NJ, 1981.[74] Ch. Lingenfelder, Transformation and structuring of computer generated proofs, Ph.D. Thesis, UniversityKaiserslautern, 1990.[75] D. Loveland, Automated Theorem Proving: A Logical Basis, North-Holland, New York, 1978.[76] H. Lüneburg, Vorlesungen über Analysis, BI Wissenschaftsverlag, 1981.[77] S. MacLane, Mathematics: Form and Function, Springer, Berlin, 1986.[78] W. McCune, 33 basic test problems: A practical evaluation of some paramodulation strategies, in: R. Veroff(Ed.), Automated Reasoning and its Applications: Essays in Honor of Larry Wos, MIT Press, Cambridge,MA, 1997, Chapter 5, pp. 71–114.[79] W. McCune, Solution of the Robbins problem, J. Automat. Reason. 19 (3) (1997) 263–276.[80] W.W. McCune, Otter 2.0 users guide, Technical Report ANL-90/9, Argonne National Laboratory, Mathsand CS Division, Argonne, IL, 1990.[81] E. Melis, Analogies between proofs—A case study, SEKI-Report SR-93-12, University of Saarbrücken,Saarbrücken, 1993.[82] E. Melis, A model of analogy-driven proof-plan construction, in: Proc. IJCAI-95, Montreal, Quebec, 1995,pp. 182–189.[83] E. Melis, Progress in proof planning: Planning limit theorems automatically, Technical Report SR-97-08,Fachbereich Informatik, Universität des Saarlandes, Saarbrücken, 1997.[84] E. Melis, The Heine–Borel challenge problem: In honor of Woody Bledsoe, J. Automat. Reason. 20 (3)(1998) 255–282.[85] E. Melis, The “limit” domain, in: R. Simmons, M. Veloso, S. Smith (Eds.), Proc. 4th InternationalConference on Artificial Intelligence in Planning Systems (AIPS-98), 1998, pp. 199–206.[86] E. Melis, AI-techniques in proof planning, in: Proc. 13th European Conference on Artificial Intelligence(ECAI-98), Kluwer, Dordrecht, 1998, pp. 494–498.[87] E. Melis, Proof presentation based on proof plans, SEKI Report SR-98-08, Universität des Saarlandes, FBInformatik, Saarbrücken, 1998.[88] E. Melis, Proof planning with multiple strategies, in: CADE-15 Workshop: Strategies in AutomatedDeduction, 1998.104E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105[89] E. Melis, U. Leron, A proof presentation suitable for teaching proofs, in: S.P. Lajoie, M. Vivet (Eds.),Proc. 9th International Conference on Artificial Intelligence in Education, IOS Press, Amsterdam, 1999,pp. 483–490.[90] E. Melis, A. Meier, Proof planning with multiple strategies II, in: B. Gramlich, H. Kirchner, F. Pfenning(Eds.), FLoC’99 Workshop on Strategies in Automated Deduction, 1999.[91] E. Melis, J.H. Siekmann, Concepts in proof planning, in: Intellectics and Computational Logic. Papers inHonor of Wolfgang Bibel, Kluwer, Dordrecht, 1999, pp. 249–264.[92] E. Melis, V. Sorge, Employing external reasoners in proof planning, in: A. Armando, T. Jebelean (Eds.),Calculemus’99, 1999, pp. 123–134.[93] E. Melis, J. Whittle, Analogy in inductive theorem proving, J. Automat. Reason. 22 (2) (1999) 117–147.[94] D. Miller, Proofs in higher order logic, Ph.D. Thesis, Carnegie Mellon University, Pittsburgh, PA, 1983.[95] S. Minton, Explanation-based learning: A problem solving perspective, Artificial Intelligence 40 (1989)63–118.[96] S. Minton, C. Knoblock, D. Koukka, Y. Gil, R. Joseph, J. Carbonell, PRODIGY 2.0: The Manual andTutorial, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, 1989. CMU-CS-89-146.[97] A. Newell, J.C. Shaw, H.A. Simon, Empirical exploration with the logic theory machine, in: Proc. WesternJoint Computer Conference, Vol. 15, 1957, pp. 218–239.[98] H. De Nivelle, Bliksem User Manual, Delft University of Technology, 1998.[99] L.C. Paulson, Isabelle: The next 700 theorem provers, in: P. Odifreddi (Ed.), Logic and Computer Science,Academic Press, New York, 1990, pp. 361–368.[100] F. Pfenning, Proof transformation in higher order logic, Ph.D. Thesis, Carnegie Mellon University,Pittsburgh, PA, 1987.[101] G. Polya, How to Solve it, Princeton University Press, Princeton, 1945.[102] D. Prawitz, Natural Deduction—A Proof Theoretical Study, Almquist and Wiksell, Stockholm, 1965.[103] R. Reiter, A semantically guided deductive system for automatic theorem proving, in: Proc. ThirdInternational Joint Conference on Artificial Intelligence (IJCAI-73), Stanford, CA, 1973, pp. 41–46.[104] J.A. Robinson, A machine-oriented logic based on the resolution principle, J. ACM 12 (1965) 25–41.[105] J.A. Robinson, Proof = Guarantee + Explanation, in: Intellectics and Computational Logic, Papers in Honorof Wolfgang Bibel, Kluwer, Dordrecht, 1998.[106] Russell and Whitehead, Principia Mathematica.[107] E.D. Sacerdoti, Planning in a hierarchy of abstraction spaces, Artificial Intelligence 5 (2) (1974) 115–135.[108] A.H. Schoenfeld, Mathematical Problem Solving, Academic Press, New York, 1985.[109] J. Siekmann, Unification theory: A survey, Symbolic Computation 3,4 (7) (1989).[110] J.H. Siekmann, M. Kohlhase, E. Melis, Omega: Ein mathematisches Assistenzsystem, Kognitionswis-senschaft 7 (3) (1998) 101–105.[111] J. Siekmann, S. Hess, Ch. Benzmüller, L. Cheikhrouhou, A. Fiedler, H. Horacek, M. Kohlhase, K. Konrad,A. Meier, E. Melis, V. Sorge, L(cid:127)U I: Lovely (cid:127)MEGAuser interface, Formal Aspects of Computing 3(1999) 1–18.[112] G. Smolka, An Oz Primer, Programming System Lab, DFKI Saarbrücken, 1995.[113] G. Smolka, The Oz programming language, in: J. van Leeuwen (Ed.), Computer Science Today, LectureNotes in Computer Science, Vol. 1000, Springer, Berlin, 1995, pp. 324–343.[114] R.M. Smullyan, First-Order Logic, Springer, Berlin, 1968.[115] F. Stolzenburg, Membership constraints and complexity in logic programming with sets, in: F. Baader,U. Schulz (Eds.), Frontiers in Combining Systems, Kluwer Academic, Dordrecht, The Netherlands, 1996,pp. 285–302.[116] A. Tate, Generating project networks, in: Proc. IJCAI-77, Cambridge, MA, Morgan Kaufmann, San Mateo,CA, 1977, pp. 888–893.[117] Y. Tetsuya, A. Bundy, I. Green, T. Walsh, D. Basin, Coloured rippling: An extension of a theorem provingheuristic, in: A.G. Cohn (Ed.), Proc. 11th European Conference on Artificial Intelligence (ECAI-94),Wiley, New York, 1994, pp. 85–89.[118] B.L. van der Waerden, Wie der Beweis der Vermutung von Baudet gefunden wurde, Abh. Math. Sem. Univ.Hamburg 28 (1964).E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105105[119] Ch. Weidenbach, Spass: Version 0.49, J. Automat. Reason. (Special Issue on the CADE-13 AutomatedTheorem Proving System Competition) 18 (2) (1997) 247–252.[120] M. Veloso, J. Carbonell, M.A. Pérez, D. Borrajo, E. Fink, J. Blythe, Integrating planning and learning: ThePRODIGY architecture, J. Experiment. Theoret. Artificial Intelligence (1995) 81–120.[121] H. Wang, Toward mechanical mathematics, IBM J. Res. Develop. 4 (1960) 2–22.[122] D.S. Weld, An introduction to least committment planning, AI Magazine 15 (4) (1994) 27–61.