Artificial Intelligence 80 ( 1996) 243-308 Artificial Intelligence ,4 logic of time, chance, and action for representing plans Department of Electrical Engineering and Computer Science, University of Wisconsin-Milwaukee, Peter Haddawy * Milwaukee, WI 53201, USA Received November 1992; revised September 1994 Abstract language approaches This paper to the representation notions about time, chance, and action central logical and probabilistic a first-order integrates problems by developing explicit and precise commonsense problem. We then develop a logic, the semantics of which incorporates The logical over time points, probability values, and domain operator The can represelnt distinguishes the logic and show how the logic can be used to describe actions descriptions of planning logic of time, chance, and action. We start by making to the planning these intuitive properties. integrates both modal and probabilistic constructs and allows quantification is treated as a sentential in the language, so it can be arbitrarily nested and combined with other logical operators. It the chance the future. The model of action between action feasibility, executability, and effects. We present a proof theory for in such a way that the action to infer properties of plans via the proof theory. that facts hold and events occur at various that actions and other events affect language can represent individuals. Probability can be composed the chance times. 1. Introduction Most AI planning systems to represent planning to date [ 7,18,47,55] knowledge. This has limited as well as to deal with uncertainty have used variations of situation to represent in the planning domain. Re- their ability in AI have used temporal [ 1,20,40,45,50] logics to formalize and they have developed probability the temporal aspects of planning logics for representing [ 3,24,26]. But little work has been done toward developing lan- in the context of planning. a formal these two representational capabilities calculus temporal knowledge searchers problems uncertainty guage that integrates * E-mail: haddawy@cs.uwm.edu. 0004-3702/96/$15.00 SSD10004-3702(94)00070-O @J 1996 Elsevier Science B.V. All rights reserved 244 P Huddawy/Art@cial Intelligence 80 (1996) 243-308 temporal and probabilistic This paper presents a logic for representing representations integrating represent aspects of planning problems that cannot be represented separately. We exploit one of the advantages of using a logical commonsense commonsense a language planning realistic domains. time, chance, and action. We show that by formalism we can if the two are treated language by building theory, Thus from the semantics of the language. Since such of for more notions of time, chance, and action directly inferences can be used follow directly to analyze planning a significant problems and prove step toward building planners algorithms, ’ into the model the correctness in a common it represents In the present work, planning is viewed as the process of formulating and choosing a set of actions which when executed will likely achieve a desirable outcome. Actions in a plan may be performed agent, to affect the state of the world, or simply for their own sake. The present work focuses on the last two types of action. To choose appropriate courses of such action, an agent in the world that his actions can must reason about influence and the extent in the world that influence his actions and the extent of that influence. to affect the state of knowledge of the performing the state of the world, conditions them, and, conversely, conditions to which he can influence Many aspects of the world are inherently for reason- in the world as well as in the effects of actions and events. For example, smoking does not deter- lung factors can influence a smoker’s chance of contracting ing about plans must be able to express chances of conditions indeterminacy ministically cancer. Uncertain cancer as can uncertainty cause lung cancer; environmental increases one’s chance of contracting so a representation it only greatly stochastic, Reasoning about plans requires to reason about time. Facts tend to be true for periods of time, and actions and events occur at particular a plan may occur sequentially not the past. Chance evolves with time: same now as it will be tonight. Ambiguities a fair coin is flipped landed heads or it certainly did not. This paper presents a first-order or concurrently. Actions and events affect the future, but the chance of rain tomorrow may not be the in the world are resolved with time: before the chance of heads is 50% but after it is flipped it either certainly logic of time, chance, and action times. Actions comprising is represented about plans. The developed Possibility relation over the world-histories. Chance and reasoning world-histories. an accessibility eralized Kripke structures By integrating resent and distinguish quantification is treated as a sentential operator combined with other logical operators. The probability so it can capture between possibility, probability, the dynamic nature of chance. both modal and probabilistic over time points, probability in terms of probability in the language, constructs, logic represents in terms Kripke structures time for representing in terms of possible [34] by defining is represented by defining gen- distributions over the world-histories. values, and domain the logical language can rep- and truth. The language allows individuals. Probability so it can be arbitrarily nested and indexed is temporally operator ’ Haddawy ( 2 I 1 uses the logic presented here to analyze and prove correct components of a construction planning system. in the effects of smoking. the ability I! Haddawy/Art@cial Intelligence 80 (1996) 243-308 245 Our modlel of possibility is similar to that presented by Pelavin of our logic is similar time is based on that of van Fraassen [26] probability to Halpem’s [43]. Our model of [57]. The logic & in the context of branching chance probabilistic to Bacchus’ logic of staged probabilities. component [ 31 logic of propositional probabilities, and to Haddawy and Frisch’s [ 241 1.1. Temporal logic Temporal logics represent change by specifying what is true in the world at various logic in logics which associate a time interval with each temporal the use of intervals, actions, events, and facts can have temporal extent. actions as the action. For this in this paper uses time intervals times. They can be classified as being either interval- or point-based. A point-based associates a time point with each temporal object. Most work on plan representation AI has use’d interval-based object. Through This means well as conditions reason, as well. the logic of time, chance, and action developed languages can represent plans with concurrent the execution of an action that these temporal that influence during Temporal logics logics can be further classified as being either linear or branching. Linear [ 1,2] model only that an the actual world and thus can only time event actually occurs at a given model all possible worlds and thus can represent whether or not an event can possibly occur, as well as its various possible in thought of as a degree of possibility, we will representing use a branching over the branching is modeled by defining probability distributions times of occurrence. Since we are interested chance, which can be roughly time. In contrast, branching time logic. Chance time structure. time logics [20,40,45] represent 1.2. Probalnlity school Semantic a logical relationship The logical to represent [ 58,591, and subjectivist into [ 37,46,48]. between a given hypothesis theories of probability may be classified three main schools: theory the subjective fcundation. But while subjective probability logi- cal [ 5,321, frequentist takes probabilitie,s and given evidence. The frequentist view identifies probability with some suitably defined relative the degrees of belief frequency. The subjectivist takes probability has the most solid of a rational agent. Of the three views, interpretation theory dictates how degrees of semantic for structuring knowl- belief should be represented, about the effects of actions edge about the world. Since we are interested to account for of uncertainty on the state of the world, we would like our representation theories some aspects of probabilistic of objective chance constraints on beliefs The current work builds upon van Fraassen’s model of objective chance. it does not provide us with guidance for causality by imposing causality. Subjectivists some additional have proposed that account in reasoning to represent [39,53,57]. subjective But probability plans. Probability tification provides great representational theory alone is not representationally theory does not include a notion of quantification. about First-order quan- economy by allowing us to describe properties for reasoning adequate lifting action shared by general classes of actions, events, and facts. For example, to define a different of lifting actions, where the object being more, probability representing p. 5701. We would planning problems. This paper addresses both these limitations. rather than having the class lifted is left as a quantified variable. Further- [ 60, for describing planning problems features of for each possible object, we can describe theory provides no vocabulary like a language that facilitates the salient 1.3. Use of the logic We show in Section 4 that the logic of time, chance, and action the logic problems. Even So we do not foresee building to be useful. Rather, and analysis of planning problems axiomatizable. means of solving planning too inefficient representation us to design planning algorithms the data structures and assumptions of a planner the meaning of the knowledge we can analyze what is entailed by this knowledge without algorithm correct. is intended involving for these problems itself. We can in the planning then refer embodied to this formal semantics a theorem prover if this were possible, is not completely for the logic as a likely be it would to be used as a tool in the time and chance. It enables in a principled manner. Representing in our logic makes explicit and precise in such a way that algorithm reference to prove to the planning the algorithm 1.4. Organization of the paper Section 2 presents the ontology of the logic. It discusses the desired properties of level, without the concepts discussed intuitive properties. Section 4 presents a proof illustrating to logical recourse in the ontology by presenting are imposed on the semantic model fo~alism. time, chance, and action at an intuitive the syntax Section 3 formalizes in order to and semantics of the logic. Constraints theory for the logic the desired obtain the use of the proof theory. Numerous and derives several useful in the ontology. axioms and theorems are statements of the intuitive properties discussed to describe properties of actions and Section 5 discusses how the logic can be used plans. We show that the logic captures relation between cause and effect. Section 6 shows how the logic can be used to describe and reason about planning problems. We describe them to reason about related work, and Section 8 draws conclusions. the overall problem. Section 7 discusses of a planning problem and compose the natural com~nents individual theorems temporal 2. Ontology In this section we seek to sharpen the reader’s intuitions concerning pects of the world described by the logic: chance. time, facts/events, actions, possibility, those as- and I? Haddawy/Arr@cial Intelligence 80 (1996) 243-308 241 clean 2.1. Time Fig. I. A temporal tree. is modeled that branches each of which form a tree structure time. At any given point Time chronology or history of events the world-histories will naturally histories to the time “now”, so the temporal in time. Fig. 1 shows the structure of a typical concerned with future-branching state of the world at times after their occurrence. That is to say, at each point the past is fixed-no in time agent’s actions as well as by other events. So relative possible past exists, but numerous possible is one possible as a collection of world-histories, throughout in time, some of share a common past up to that time. Thus the world- is given to each point tree. The present work is only the in time, in the world will cause it to change. But at each point in any number of ways, which are influenced by the in time, only one into the future. No special status into the future relative occurrences the future might unfold time because actions and events can only affect futures exist. * tree branches to any point temporal 2.2. Facts and events they hold or occur The world is described in the various world-histories. and if a fact holds over an interval of that interval. So, for example, my car may be alternately in terms of facts and events. Facts tend to hold and events tend to occur over intervals of time. So facts and events are associated with the time intervals over which Facts are distinguished from events on the basis of their intervals in any given world-history over all subintervals and dirty over several different clean over a period of time, then it is clean throughout temporal properties. A fact may hold over several it holds clean and if my car is Events are somewhat more complex event types and event tokens. An event token instance of an event type, and the brown vase in my office breaking at 9:00 am is an event type. So event types are sets of event tokens. Event interval over which an event that time. See Fig. 1. than facts. First, one must distinguish between type is a general class of events and an event is an event type. For example, a vase breaking token of that in a given world-history interval containing tokens are unique individuals-the is the unique token occurs time periods is a specific the event then * For a more thorough discussion of why a future-branching [4 I I. see the article by Mellor time model is appropriate for representing effects 248 I? Haddawy/Artificial Intelligence 80 (1996) 243-308 Fig. 2. Action representation. there is no smaller period of time during which the event If a vase breaks token and an event token can occur at most once in any world-history. token during a time period, tokens of the vase breaking can be said to have occurred. On the other hand, numerous two different of a given event type may occur during a particular type occurs over an interval, vases can break concurrently. but it is not it is possible necessary as it is in the case of facts. The present work deals with event types, which for brevity are simply token of that type to occur over a subinterval, So if a token of an event interval. For example, for another referred The fact/event dichotomy [50] has shown, there are many different temporal properties. Although Shoham’s is a simplification of the true situation. As types of facts and events, character- refined categories of fact types to as events. just described a more useful and accurate picture of the world than the simple fact/event the fact/event categorization will be used for simplicity of exposition. Ex- the work to encompass Shoham’s categories is completely straightforward. Shoham ized by their constitute dichotomy, tending 2.3. Actions Actions are similar to events but are distinguished agent. From this perspective, only the planning from events by the fact that an action is brought about by an agent. We view the planning problem from the perspective of the planning acts; all other actions appear as events. An action attempts an action and, the action will have certain effects. Likewise, the action does not result situation action occurs failure will have is also a function of chance. agent’s own actions are the agent of are such that the attempt of if conditions the attempt will have other effects. 3 The in Fig. 2. Once an agent attempts an action, whether or not the furthermore, what effects the action’s success or the action occurs. The occurrence is initiated by an attempt: is a function of chance; in its occurrence, if conditions is depicted are right, Distinguishing the attempt of an action from its occurrence inferences. First, it facilitates are going skiing or eating at one’s favorite are interested in its occurrence. in finding circumstances reasoning facilitates several useful about actions as goals. Examples of such goals for such goals, we under which the attempt of the action will result In planning restaurant. Second, separating the attempt of an action from its occurrence allows us to distinguish from effects due to the attempt. For example, between effects due to the occurrence that lifting an object will result in the agent’s holding is too heavy may result in the agent straining his back. One advantage of being able to it but attempting to lift an object 3 In the Al literature the effects of the action’s occurrence are typically called intended @ects. I? Haddawy/Artijiciul Intelligence 80 (1996) 243-308 249 Generative Event ’ Generated Event I Fig. 3. Relative times of generative and generated events. is that we can distinguish between a plan achieving a goal through make this distinction its occurrence and a plan achieving a goal as a side-effect of its attempt. the separation time, allowing us to reason about conditions facilitates temporal Third, can span the amount of time required to vary, depending on conditions. for an action reasoning about actions. Action occurrences during an action. Furthermore, to occur once it is attempted can be allowed action types. Action type:5 are analogous As with events, we distinguish [ 191 theory of action individuation tokens and action to event tokens and event types. Our representation tokens and of action in which he defines a that holds between certain actions. An act token A generates an act the light that action tokens is based on Goldman’s generation relation token A’ if it can be said that A’ was done by doing A. For example, “flipping switch” and “turning on the light” are related by generation. So rather than saying the two are different descriptions different actions, Goldman generation. Generally A and A’ will be causally possible. Goldman as generation. says that they are two different actions but are related by are also that he classifies related but other relationships relationships of the same action or that they are two completely [ 19, Chapter 21 details four different We define an action token to be composed of a generative event token, representing the action’$, attempt and a generated event token, representing the successful occurrence of the action. The two event tokens are related by generation: the agent brings about about by the generative event token. Take the example action token of starting my car. This might consist of the generative event token turn-key and the generated event token car-starts. An action type is simply a set of action types and will refer to them simply as actions. tokens. We will be primarily concerned with action the event associated with the generated event token by bringing We impose constraints on the temporal the generated event of an action must coincide with the beginning generative relation between events and token. The beginning event time of the generated event and the end time of the the generative time of the generative event must not occur after the end time of the generated event. See Fig. 3. 2.4. Possibility the present work is concerned with representing Because the kind of possibility we are interested the world, possible is objectively Something the future. So possibility is taken relative actions and. events can only affect the future, conditions to a given true or inevitably time are either inevitably false. if it either was true in the past or could be true in tree. Since in the present and past relative to a point in time in the temporal in describing is objective possibility. actions that affect the state of 250 R Haddawy/Artijciai Intelligence 80 (1996) 243-308 2.5. Chance is taken relative is objective, as opposed over the tree of possible that the past is inevitably futures. Like of the in time. As a consequence false and the fact that inevitability is introduced by defining probabilities chance Chance possibility, to a given point true or inevitably property implies probability one, it follows that the chance of the past is either zero or one. In this of future facts and events. way, actions and other events can only affect the probabilities the past can This type of probability I may be uncertain but objectively be uncertain stock rose or fell yesterday, but objectively it either certainly do now to change chance be completely chance is a function not only of the state of the world but also of the epistemic agent. I can is that the time. So objective is purely a function of the state of the world. In contrast, subjective probability it is completely determined. For example, subjectively rose or it certainly did not and, furthermore, by the history up to the current imposed on objective chance as to whether my company’s to subjective. Subjectively that. The other property there is nothing state of an determined this reason for distinguishing and chance. It is between possibility the case. The problem is a subtle to think that possibility There tempting is non-zero but is not sample space possible events can have probability a real number it will be picked is zero, yet it is possible this distinction will become essential when we discuss action Possibility and chance are related by the fact that impossibility and inevitability could just be represented by saying that the probability infinite zero. For example, suppose you pick that to make in Section 5. zero feasibility implies probability that it will be picked. The ability [0, 11. For each number is that in an uncountably implies probability one. in the interval the probability randomly 2.4. Planning Within the ontological the present in which the goal condition framework to the future along a temporal just outlined, planning becomes the task of nav- to attain a is satisfied. But an agent has only partial con- action effects are tree in an effort the tree: the state of the world is uncertain, and external events may influence the path of the agent. from igating world-history trol over its path through not necessarily deterministic, For example, consider tree shown the temporal that the temperature in worlds WI and w2 and above freezing freezing 70% chance is turned when the temperature car will start given that the key is turned when the temperature by turning the key, the agent can only partially control in Fig. 4. The temperature is below in the rest of the worlds. So there is a to start if the key that the is below freezing. Thus, the tree. its path through is above freezing but there is only 57% chance is below freezing. The car is certain 3. The logic of time, chance, and action To formalize the concepts discussed the logic of time, chance, and action, in the ontology, we now define the language of for f,:,,. First to provide a vocabulary in order I? Haddawy/ArtQicial Intelligence 80 (19%) 243-308 251 dum-key ~Car-sWts w3 Fig. 4. Navigating the temporal tree. language with modal operators is treated as a sentential operator, to the elements of our ontology, we specify referring language of .Li,, is a first-order chance. Since chance it can be combined other logical operators. The language allows quantification over probabilities, and domain similar temporal component temporal the syntax of the language. The and to express possibility freely with time points, is and the syntax of the [43] individuals. The syntax of the probabilistic of the logic is based on both Shoham’s component of the language [ 31 logic of propositional to that of Bacchus’ [ 501 and Pelavin’s probabilities logics. 3.1. Syntax of L,, contains in time, language the language The occurring fact FA holds over the time interval EV occurs during subscripted, denote probability the interval to denote values. The language contains A is attempted beginning the interval during In addition tA to t>. to the usual first-order contains four predicates. To refer to facts and event types two predicates: HOu)S( FA, tl , t2) is true if t2) is true if event t, possibly tl to t2, and OCCURS(EYtl, tl to t2. Henceforth we will use the symbol time points; 4, $, and y to denote formulas; and LY and /3 to two predicates to describe actions: AZT( A, tA) is true if action is true if action A occurs tA,tL) tA, and OCC(A, at time inevitability, possibility, logical operators, the language contains three modal and chance. The operators are subscripted to say that 4 is possibly in time. We write O,(4) inevitability, to the ontology, possibility, and chance are true to denote in the object is treated as a sentential operator operator can be arbitrarily nested and combined with the true at time t. We write P, (#) that c~5 is inevitably to indicate of 4 at time t. Probability to a point operators to express with a time since, according taken relative at time t and OI (4) the probability language. So the probability inevitability and possibility operators, allowing us to write complex sentences like: Such a treatment probability is useful for writing of 4 given $ is traditionally sentences defined as about conditional probability. The 252 R Huddawy/Artijiciai Intelligence 80 (1996) 243-308 prob($ I 9) =prob(4 A ti,)lprobt$,). If the probability of the conditioning is undefined. can be assigned neither new conditional probability sentences about conditional the value In this case, a conditional probability sentence like prob(4 sentence I/ is zero, then the conditional probability true nor the value false. Rather than operator and dealing with this truth assignment probability can simply be written in the form 1 I,/?) = a a introducing problem, Note that this sentence probability notation will be used to syntactically is true for all values of (Y if P,($) = 0. The standard conditional denote a sentence of the above form: Definition 1 (c-prob) . The language of L,, contains three types of terms: ordinary domain object temporal relations, event relations, and action relations. terms, and probability terms and four types of relations: numeric terms, fact relations, lexicon of the language The symbols: consists of the following disjoint sets of non-logical l C a set of object constant symbols; l TC, a set of time constant symbols; l NC, a set of numeric constant symbols; l V, a set of object variables; l TV, a set of temporal variables; l PV, a set of probability l FCT, a set of object function l NFCT, a set of numeric l PFCT, a set of probability l FR, a set of fact relation symbols; l ER, a set of event relation symbols; l AR, a set of action relation symbols; and l NR, the set { <, <, =, 2, >} of numeric variables; symbols, symbols; function function symbols including +, -, ., /; for representing distribution functions; relation symbols. Note that we will use the symbols <, <, =, 2, > to denote numeric the object and the meta-language. It will be clear from context which meant. relations interpretation in both is The set of well-formed formulas combining the logical and non-logical symbols is recursively defined as follows. ( I ) The set of object terms (o-terms) as well as all terms of the form otrml,..., otrm, are o-terms. contains members of C, all members of V, f E FCT and f(otrml ,...,otrm,,), where (2) The set of temporal contains all members of TC, all members of TV, as well as all terms of the form f( ttrml , . . . , ttm,,), where f E NFCT and ttrml , . . . , ttrm, are t-terms. terms (t-terms) P. Haddawy/Art@cial Intelligence 80 (1996) 243-308 253 for 6, =, 2, >. then ttrml < ttrm2 is a wff, and (3) The set of probability terms (p-terms) (4) (5) (6) (7) (8) trml , . . . , trm, are o-terms or t-terms, and fr is then HOLDScfr( h-ml,. . . , trm,), ttrml , ttrm2) is contains all members of NC, all members of PV, all terms of the form f( trml, . . . , trm,), where f E PFCT U NFCT and trml,. . . , trm, are t-terms or p-terms, as well as all terms of the form P,,, (qb), where 4 is a wff and ttrm is a t-term. If trml and trm2 are both t-terms or p-terms similarly If ttrmt and ttrrn2 are t-terms, an n-ary symbol fact relation a wfF. If ttrml and ttrm2 are t-terms, an n-ary event relation symbol is a ,wff. If ttrml is a t-term, action relation symbol If ttrml and ttrm2 are t-terms, an n-ary action a wff. If ohm] and otrmz are o-terms If 41 and 42 are wffs then so are ~$1, $1 A 42, 41 V 42, and 41 -+ 42. If+isawffandzEVUTVUPVthenVz4and3z4arewffs. then Cl,, trml, . . . , trm, are o-terms or t-terms, and er is then OCCURS( er( trml , . . . , trm,) , ttrml , ttrm2) trml, . . . , trm, are o-terms or t-terms, and ar is then OCC(ur( trml , . . . , b-m,,), ttrm] , ttrm;!) is (9) (IO) (II) ( 12) If 4 is a wff and ttrm is a t-term We use the symbol = to denote equality between object (4) and O,,, (4) are wffs. terms, probability trml , . . . , trm,, are o-terms or t-terms, and ar is an n-ary then ATT(ar( trm] , . . . , trm,) , ttrml ) is a wff. then otrml = otrm2 is a wff. relation symbol terms, and temporal Notice terms. The meaning will be clear from the context. that the syntax of the language is restricted to disallow sentences be meaninglefss sentence used as a time point: in the intended is not well-formed because interpretation of the language. For example it does not make sense for a probability that would the following term to be 3. I. 1. Examples of representing planning knowledge Now that we have defined can represent various sentences that describe: the syntax of the language, we can see how the language knowledge. The language allows us to write types of planning l Uncertai-nty in the state of the world: there is a 60% chance of a power glitch between noon and 5:OO. P,,,(Itl, t2 (noon < tl < tf < 5:00) A OCCURS(power-glitch, t], t2)) = 0.6. l Uncertainty of action effects: there is a 50% chance that the coin will land heads when flipped. Yt, rl, t2 (t < tl) -+ Pr(3t3 OCCURS(land(coin,heads), t2, tg) ) OCC(flip(coin), tl, t2)) = 0.5. 2.54 I? Haddawy/Art@cial Intelligence 80 (1996) 243-308 l Conditions during an action increases constant the likelihood that influence its effects: holding the oven temperature that the souffle will turn out right. Vt,tl.t2 (t < tl) ---f Pt(3tg HOLDS(done-right(souffle),tz,ts) 1 OCClJRS( bake( souffle), tl , t2) A 3xHOLDS(temp(oven,x),ti,t~)) > P, ( 3t3 HOLDS( done-right (souffle), t2, tl ) 1 OCCURS( bake( souffle), tl , t2) ) . l Conditions not influenced by an action: the chance of rain is independent of my clapping my hands. ~t,tl,t2vt3,t4 (tl < t3) + P, (HOLDS( raining, tg , t4) 1 OCC( clap, tl , t2) ) = P, (HOLDS( raining, tg , t4) ) . l Concurrent actions: it is not possible for me to raise and lower my arm at the same time. Vt, ti, t2, tg, t4 Cl, [OCC(raise(arm), tl, t2) A OCC(lower(arm), t3, t4) -+ (t2 < t3) v (t4 < t1>1. l External events: there is a 90% chance that the computer will crash if a power glitch occurs. tltl, t2 P,,,(33, t4 (tl < tj 6 t2) A OCCURS(crash(computer), t3, t4) 1 OCCURS(power-glitch, tl , t2) ) = 0.9. l Temporally qualified goals: be at the bank before 5:OOpm. 3ti, t2 (tl < 5:OO) A HOLDS( loc( me,bank) , tl , t2). Furthermore, the language allows us to write sentences that there is a 50% chance l Combine possibility and chance: that by noon a train crash will inevitably occur between 3:00 and 5:OO. P,,,(3t, (tl < noon) A cl,, (32, t3 (3:OO < t2 q tg < 5:OO)A OCClJRS(crash(train), t2, tg))) = 0.5. l Distinguish between truth and chance: I won the lottery even though it was unlikely. (to < tl < t2 < now) A P,,(OCCURS(win-lottery, tl, t2)) = 0.0001 A OCCURS( win-lottery, tI , t2). l Express information normally distributed about probability about noon. distributions: the arrival time of the train is ‘dt P,,,,( 3t’ OCCURS( arrive, t, t’) ) = N( t, noon, 1 Omin) , l? Huddawy/Artijicial Intelligence 80 (1996) 243-308 255 where N( t, noon, noon and variance IOmin) IOmin. is a normal distribution over the variable t with mean 3.2. Semantics identified to these sentences. This the use of model-theoretic to tlhe elements So far we have only specified a formal way of writing down sentences of &I. We need some way of assigning meaning through closely world-histories is created by defining then defined with respect probability ontology model in the language is done semantics. The elements of the model correspond in the ontology. The models contain a set of possible tree structure is Possibility in terms of in the on the models. A relation over the world-histories. relation. Chance are obtained by placing a number of semantic constraints as well as sets of facts, events, and actions. The temporal tree. The desired properties to this accessibility over the temporal an accessibility distributions is a ltuple is defined identified (LY D, FN, NFN, PFN, FRL, ERL, ARL, NRL, FA, EVENTS, EV, ACTS, ACTIONS, R, X, PR, F), where: called worlds. l W is the set of possible world-histories, l D is the non-empty domain of individuals. l FN is I:he set of object functions: Dk -+ D. l NFN is the set of numeric l PFN is the set of probability functions: Bk + IR. l FRL is the set of fact relations: Dk --+ 2(wxllp)xw. l ERL is the set of event relations: Dk --f 2(“llp) xw. l ARL is the set of action relations: Dk -+ 2ACTS. functions: Rk -+ IR. l NRL is the set of numeric l FA is the set of facts, a subset of 2 (wxR)xw. A fact is a set of (temporal relations, a subset of 2@. interval, world) pairs: {((tl, then fa holds throughout t{),w~), . . . , ((tn, tL),w,,)}. Iffa is a fact and ((t,, tz), w) l fa (tl , t2) in world-history w. is the set of event tokens, a subset of (Iw x R) x W. An event token is a interval l EVENTS single (temporal interval, world) pair. l EV is I:he set of event tokens: {((tl, then ev occurs during t;), WI), . . . , ((tn, t;), w,)}. types, a subset of 2EVENTS. An event type is a set of event If ev is an event and ((tl, tz), w) E ev interval (tl , t2) in world-history w. l ACTS is the set of action tokens, a subset of 2 EVx EV. An action token is an ordered pair consisting of a generative event token and a generated event token: (gev, Gev). in order to pick We will find it useful out the generative event token of act and Gen(act) is the generated event token of act. to define two functions in the meta-language is the generative tokens: gen(act) and generated event l ACTIONS is the set of action types, a subset of 2ACrs. An action of actison tokens: { (gevl , Gev I), (gevz, Gevz), . . .}. For example, tion might be represented tl, tz), (car-starts, as {((turn-key, type is a set the start-car ac- t1, tg)), . . .}. Note that 2% P: Huddawy/Arti$cial Intelligence 80 (1996) 243-308 type, event action, event, and fact, respectively. type, and fact corresponding to the empty set denote the time t disallows relation defined on Rx W x W. R( t, WI, WZ) means that world- time t. Making worlds i.e. there must be the occurrence of an event and its effects. If R( t, WI, ~2) we t. The set of all world- from w at time t will be designated Rr. For each time t, the up to and including instantaneous from wt at time effects, into sets of equivalence classes indistinguishable . through the action impossible R is an accessibility histories WI and w2 are indistinguishable indistinguishable some time between say a world-history w;? is R-accessible histories R-accessible R;’ partition up to t. X language, PR is a probability history w E W a countably F is the denotation as well as all R-equivalence assignment the world-histories is a a-algebra over W,4 containing function all the sets corresponding to wffs in the classes of world-histories. that assigns to each time t E iR and world- additive probability distribution &” defined over X. function, defined as follows: C -+ D, NC--+@& TC -+ Iw, FCT -+ FN, NFCT --+ NFN, PFCT + PFN, FR --+ FRL, ER -+ ERL, NR -+ NRL. The reader will note that constants, Henceforth, M will be used to refer a model with the eighteen components named above. to functions, the logic to time since it would result in could the fact both time and world-history. Rigidity with respect somewhat and could be relaxed without much effort. Non-rigidity with respect seems undesirable denote that my car is blue from 24 to ts. tt a term like Blue(car) the fact that my car is blue from to to tg and at time t2 it could denote and relations are rigid with respect incompatible with the current like the following. At time to world-history to be basically interpretations framework simplifies 3.2.1. Semantic constraints In Section 2 the ontology of the logic was discussed In the desired intuitive properties, a number of constraints must be imposed in the following from an intuitive are presented standpoint. (Cl)-(C8) labeled order to obtain on the models. These constraints, discussion. 4 A v-algebra over W is a class of subsets that contains W and is closed under complement and countable union. l? Haddawy/ArtiJicial Intelligence 80 (1996) 243-308 257 t1 t2 I 13 Fig. 5. Structure imposed by the R-accessibility relation The future-branching histories. To capture if two world-histories up to any earlier time: temporal the property are indistinguishable tree is defined that time does not branch in terms of the R-relation over world- into the past, we say that up to time f2 then they are indistinguishable (Cl) If tt < t2 and R(~~,wI,w~) then R(tt,wt,w2). Since R just represents time R is an equivalence (C2) R(r, w, w). the indistinguishability relation, i.e., reflexive, symmetric, of histories up to a time and transitive: t, for a fixed If R(t,wt,w~) If R(t,wt,w:!) then R(t,w:!,wt). and R(?,w:!,w~) then R(t,wt,ws). Fig. 5 illustrates the temporal that the R-relation tree structure discussed ties together in Section 2. the different world-histories to form As mentisoned earlier, facts and events differ tinction interval, is captured by the following it holds over all subintervals, two semantic constraints. except possibly at the endpoints: in their temporal properties. This dis- If a fact holds over an (C3) If tt <t:! < ts G t4, tt Z ts, t2 + t4,fuE FA and ((t,,td),w) then ((t2, t3), w) cfu. cfa An event token occurs only once in each world-history: (C4) If evt E EVENTS, then tl = tg and t2 = t4. ((tl, tz), w) E evt, and ((tg, tq), w) E evt up to a time then they must share a common past If two worlds are indistinguishable up to that time. And if they share a common past up to a given time, they must agree this relationship, we impose on all facts and events up to that time. To enforce the at time t, they must agree on all constraint are R-accessible that hold (occur) over intervals ending before or at the same time as t: facts (events) that if two world-histories (C5) If to < tI < t2 and R(t2, WI, w2) then ((to, tl), w1) E A iff ((to, tl), w;?) E A, where A is a fact or event. 258 l? Hudduwy/Art@ciai Intelligence 80 (1996) 243-308 Section 2 mentions that the probability The second desired characteristic be either zero or one. These two properties two constraints: operator. The first is two desired characteristics at a time t be completely determined by the history up to that time. of the present and past should from the following follow as meta-theorems is that the probability of the probability (C6) For all X E X, t 6 t’, and W, W’ such that R( t, w, w’), ,u;(R;‘) > 0 --+ &Y’(X) = ,$‘(X 1 R$). (C7) #(R;) > 0. Meta-Theorem 2. The probability of the present and past is either zero or one. &‘( RF) = 1. Proof. 1. &‘(RP) >0 (C7) 2. ,$(I?:) = &‘( Ry 1 RF) Modus Ponens: (C6), I 3. &‘(R,“) = 1 def of conditional probability, Defining the probabilities meaning of R. Rr designates respect to w at time likely with respect in this way makes good intuitive the set of world-histories if we look at the that are objectively possible with sense t. It is natural that the set of world-histories to w at time t should be a subset of the ones that are possible. that are objectively Theorem 3. If two worlds are indistinguishable up to time t then they have identical probability distributions at that time. If R(t, w, w’) then fir’(X) = p;(X) Proof. 1. &(Ry’) >0 2. ~~(R~‘) =&(X 1 Rf) (C7) (C2), Modus Ponens: (C6), 1 3. 4. 5. ,$‘(X / Rf) =p;(X 1 RP) (C2) ,u;(Rr) = 1 p:‘(x) = p:(x) Meta-Theorem 2 definition of conditional probability. The following temporal constraint relation between generative that actions can actually occur, by requiring on actions performs two functions. First, the it that the generative and generated it enforces tokens. Second, event and generated desired guarantees event tokens of an action token occur in the same world-histo~. (C8) If act E ACTS and ((tr , t.~), WI} = gen(act) and ((~3, rq), wa) = Gen(act) then tl = tg, t2 < t4, and WI = ~2. I? Haddawy/Art@cial Inrelligence 80 (1996) 243-308 259 3.2.2. Semantic definitions Given relative are assigned of individuals to expressions for the well-formed the semantic definitions for- to a model, to the models described above, mulas can now be defined. Denotations a world-history within the model, and an assignment variables. The denotation of an expression 4 relative w, and a variable assignment g is designated by [[q!~]~“““. The variable assignment tion g maps each temporal and probability variable the assignm’ent of values exception formed sentences is not true it is false. to a model M and a world-history func- to a real number and each object In the definitions below, the expression g[ d/z ] denotes to assignment g with the possible for the well- under which logic, if a sentence to variable z. The semantic definitions the conditions specify true. Since we have a two-valued are given below. The definitions that element d is assigned that is identical in the domain are assigned to a domain to variables individual. the value formulas variable ( 1) If M is a variable (2) (3) If G( is a non-logical If7=f(WWq,... then [[u]~,“*~ = g(u) . constant then [cz]~~“‘,” = F(cr). , trrn,) is a o-term, t-term, or p-term then urn JWW = ufn”,““( [Itrm,JJ”‘W’fi,. . . , [trm,]M*“*g), (4) (5) [trmj < trm2Jj”+sg [[trrrt~ = tm2jM+.” = true iff [trmljjM+‘,g < [tmt2jpw5 true iff [trmljM*W,g = pm2jpW,g. = (6) [HOLDS(rf(trm~,...,trm,),ttrm~,ttrm;!)] M*w’R = true iff ( ( nttm, 1 M,*b’,g , l[ttrm2nM+“g), W) E F(ti (Utr4ll M.w.x , . . . , [trmn]M*W~g). (7) [OCCURS( re( trml , . . . , trm,) , ttrml , ttrm2)]“‘“vK = true iff ((ptnn,py uttm2pwy, W) E e for some e E F( re) ( [trml]M*wvR,. . . , pTmnnM+,q. (8) [A7T( ra( trml , . . . , trm,), ttrml )I]“*“” = true iff 3act E F(ra) ( [trml]M’W*R,. . . , utnn,jpy such that 3tgen(act) = (([Ittrml]“‘“‘R,t),~). (9) [0CC(ra(trm~,...,trm,),ttrm~,ttrm2)] M’w’fZ = true iff hct E F( ra) ( [trm, j”+,R, . , . , Utrmn]M*“‘g) such that 3 gen(act) = (([ttrml]“*“TK, t), W) and Gen( act) = (([to-m, JjMs”‘*#, [ttm2]Mg”*R), w). ( IO) u+n”,“vg = true iff ~~~~~~~~ $ true. ( 1 1) [I& A &]“+‘,” = true iff [[&n”+,’ = true and [&]“+‘VK = true. (12) I[V~ +I”+” = true iff z E V and [+]“+‘VR’d’Z1 = true for all d E D or z, E 7’V U PV and [[4] M’w’R’d’z ’ = true for all d E JR. 260 I? Haddawy/Artificial Intelligence 80 (1996) 243-308 a ; iy now lob 11:oo ncon 3:oo 5:OO Fig. 6. Model for train crash example. ( I 3) [II,‘, ( +)jM9”” = true iff [+Jj M’W”R = true for every w’ such that R( [ttrWzjj”‘W”fi, w, w’). ( 14) UP,,, ($9 I] M+‘Sfi = $,mlM,“.S ( { W’ E R;,mlM.W,8 : u+n Mdg = true) > . The logical operators V, +, and 3 are defined in terms of 1, A, and V in the usual way. The numeric relations <, =, 2, > are defined in terms of <, e.g., (A < B) = +B < A). Possibility definitions w at a time time t. Definition t is the probability in terms of inevitability 0 is defined are the last two. Definition The interesting in a world from w up to and including (14) says that the probability of a sentence 4 in a world w at a time ( 13) says that a sentence t iff it is true in all worlds as Ot( 4) E 1 Cl, (-4). indistinguishable is inevitable of those accessible worlds in which q?~ is true. A sentence 4 is satisfied by a model M at a world w if it is assigned the value true is valid if it is satisfied by every model at every since by to the truth value of a sentence by that model and world. A sentence world. The value assignment definition g is irrelevant sentences contain no free variables. 3.3. Example To illustrate the correspondence between the syntax and semantics of C,, we show a possible model for one of the example sentences presented earlier: l There is a 50% chance that by noon a train crash will inevitably occur between 3:00 and 5:OO. ~now(~t1 (fl < noon)/\ cl,, (3t2, tg (3:OO < t2 < t3 < TOO) A OCCURS(crash(train), t2, tg))) = 0.5. R Haddawy/Arfijicial Intelligence 80 (1996) 243-308 261 is shown is satisfied for this sentence is one. The sentence in Fig. 6. The sentence One possible model is not satisfied in world wa since there the chance that a crash between 390 and 5:00 is inevitable by noon in worlds WI-W-]. In worlds WI and wz a crash between 3:00 and 5:00 is inevitable at 10:OOam. In each of the worlds ws-ws a crash at 1l:OOam. The chance of worlds WI-wg is 50%. between 3:00 and 5:OO is inevitable In worlds wf, and w7 a crash is inevitable but it does not necessarily occur between 3:00 and 5:O0. In worlds WI-w7 there is a 70% chance of a crash occurring between 3:00 than the chance of a crash inevitably occurring between 3:00 and 5:O0. This that there is at least a that it follows and 5:O0. Notice 50% chance an agent controlling from the above logical sentence to avoid a crash after noon. the train can do nothing is higher 4. Proof theory to prove numerous later in reasoning tization be useful with the logic, straints properties described Before presenting fact fallows imposed on the models In this section we present a partial axiomatization theorems about actions and plans. In addition for Lt,,. We then use the axioma- that illustrate properties of the logic and that will reasoning to facilitating in this section show that the con- intuitive to capture the desired in Section 3 are sufficient the axioms and theorems presented in the ontology. the axioms we first note that C rca is not completely axiomatizable. [26]. Halpern presents a first-order values and domain logic with the addition first-order over real probability to Halpern from a result due logic Cz that allows quantification This probability individuals. The language of Cz is that of ordinary of the probability single distribution are not recursively argument operator P. Probability over possible worlds. Halpern enumerable the non-axiomatizability that this entails Sentences of C2 can be translated as a probability is translated are translated as instantaneous HOLDS( on t: A, B) , to, to). So, for example, at a given in models in terms of a shows that the valid formulas of Cz and hence the logic is not completely axiomatizable. The for 132 is defined of L,,, is given below. to sentences of C,, as follows. Halpern’s P operator fixed time, say to: Pt,. All atomic formulas facts at that same fixed time, e.g., on(A, B) becomes the C2 sentence ‘dxP(flyQ(x,y) A P(Vz R(z)) =0.7) =0.2 would be translated as VxP,,(3yHOLDS(Q(x,y),to,to) A Pt,(VzHOLDS(R(z),to,to)) =0.7) =0.2. is a translation of an Lz sentence if the corresponding Cz sentence Now an J&., sentence which and only formulas of Le, were recursively Since L,,, cannot be either. Hence L,, the valid formulas of L:2 are not recursively is not completely enumerable is valid in Halpem’s is valid in our logic if logic. So if the valid so would be the valid formulas of Cz. the valid formulas of The lack of existence of a complete axiomatization drawback for two reasons. First, the logic is intended to be used is not seen as a serious in the design and enumerable, axiomatizable. for L,, 262 I? Huddawy/Art@cial Intelligence 80 (1996) 243-308 analysis of planning complete with respect rules of inference considered in this paper. algorithms that are sound with respect to the logic and possibly to a subset of the logic. Second, a sound set of axioms and to allow us to make all inferences that are rich enough are provided 4.1. Axioms into classes. First there are six basic classes The axioms presented below are divided six types of reasoning: describing (1) (2) (3) (4) first-order to describe first-order axioms with equality and the rules of Modus Ponens and Universal Generalization axioms of real closed fields to describe numeric S5 axioms and the rule of necessitation probability probabilistic temporal axioms and the rule of probability for reasoning about inevitability, reasoning, logic axioms of logical equivalents logical reasoning, to describe reasoning, reasoning, to describe and (5) (6) an action axiom for reasoning temporal about action. that relate some of the basic classes: Following these are three sets of axioms and equality axiom, l the inevitability l axioms describing l axioms relating the temporal properties of inevitability, and logics. The first-order axioms and rules of inference in the literature as parts of axiomati- from are taken inevitability and probability. Subsets of the axioms have appeared elsewhere zations of other [ 30, Chapter 11 and appear originally are taken from and axioms The field axioms and the probability the axiomatization of the probability originally the appendix. in [ 631. The S5 axioms and rule of necessitation the rule of necessitation, ITI-IT4 [30, Chapter 31. The S5 axioms, are part of the axiomatization IE, logic. axioms Pl, P2, and PE have appeared as parts of [ 31, The field axioms appear logics in [49]. Soundness proofs for the less commonly known axioms are given in [43] planning in [ 171 and of Pelavin’s axiom First-order axioms with equality FOLl. (t$v$) -4. FOL2. cc, -+ (q!~ v@). FOL3. (4 v $) --+ (@ v 4). FOL4. (fi -Y) -+ ((+V+) --f (+VY)). FOL5. ‘dx+ -+ qS(x/tm), where trm is substitutable5 for x in 4. s Roughly, trm is substitutable for x in C$ if 4 does not contain a quantifier that could capture trm. P Haddawy/Artificial Intelligence 80 (1996) 243-308 263 EQl. trm = trm, where trm is any term. (trml = trm2) + EQ2. trml in zero or more places by trm2. (4 -+ 4’)) where C$ is atomic and q5’ is obtained by replacing First-order rules of inference MoPo. Modus Ponens: From q5 and q3 + $ infer 4. UG. Universal Generalization: free in ~5. Axioms of real closed fields From C$ 4 J+ infer 4 --+ Vx@, where x does not occur These axioms capture numeric reasoning over the reals. The variables range over time points and probability values. F-1. V’xyz ((x+y)+Z =X+(Y+z))* F2. V’x(x t 0 =x). F3. Vx (x-k (-1 .x) =O). F4. tlxy (x+y=y+x). F5. Vxyz ((x.y).z=x.(y.z)). F6. vx (x. 1 =x). F7. Vx (x ~$0 -+ 3y(x.y = 1)). F8. ‘dxy (x.y=y.x). F9. Vxyz (x.(y+z) =(X*Y)+(x’z)). FlO. 0 # 1. Fll. Vx (-1(x < x)). F12. b’xyz ((X<Y)Ao’<Z) --+(x<z))* F13. Vxy ((x < y) V (x = y) V (y < x)). F14. Vxyz ((x<y) -((x+z) <(Y+Z)))- F15. Vxy (((O<x)A(O<y))+(O<x.Y)). 264 P: Haddawy/Art@cial Intelligence 80 (1996) 243-308 F16. vx ((O<x) +Ely(y.y=x)). F17. Every polynomial degree 3 is of odd degree has a root, e.g., the axiom for a polynomial of S5 axioms These axioms capture the fact that for a fixed time, inevitability is an S5 type modal operator. Il. q ,c$ -+ c#A 14. O,$ -+ q ,O,+. Rule of necessitation NEC. From 4 conclude 0‘4. Probability axioms These axioms capture describe probability probability over time. the probabilistic at a fixed time, while component of the logic. The first two axioms the behavior of the third axiom describes Pl. Non-negativity: P!(4) 2 0. P2. Additivity: P,(4) = P,(qb A @) + P,(+ A -@). P3. Miller’s principle: (ti < t2) -+ P,,(r$ 1 P,,($) 3 a) 2 a. Axioms Pl and P2 are variants of two of the three well-known earlier, variants of these axioms have appeared [33]. As mentioned Those axiomatizations also contain et al. as P,( true) = 1 and by Bacchus as P,(4) + P,(+) our logic as a consequence validity of the third axiom of probability of other axioms describing the third axiom of probability, axioms of probability in [ 171 and [3]. represented by Fagin in and probability. The = 1. These axioms follow inevitability is proven as Theorem 7 in the next section. Axiom P3 is called Miller’s principle and several nontemporal variants of it were first [52] as possible constraints on higher-order probabilities. suggested by Brian Skyrms Miller’s principle relation between chance at various one fair coin and one with a 70% chance of heads and that I am going coin and flip it. What is the chance now of heads given is useful for two reasons. First, it formalizes our intuitions about the that I have two coins, to choose one the biased times. For example, suppose that I will choose P Huddawy/Artijicial Intelligence 80 (1996) 243-308 265 coin? By intuition and Miller’s principle 21 has pointed out, if we have a sentence coin-is-chosen conditional higher-order probability have such fsentences readily available. The second useful consequence and appropriate [ 52, Appendix to the-biased- such statements with simple probabilities. But we may not always it is 70%. Notice that, as Skyrms in the language corresponding probabilities we can always represent at a given to be inferred of Miller’s principle the current the time. the two coins above. There is a 50% that the chosen coin will have a 70% chance of landing heads and a 50% chance it follows chance of facts and events probability Suppose chance that the coin will have a 50% chance of landing heads. By Miller’s principle, that there is now a 60% chance time is the expected value of the probability from the chances of their future chances: that the coin flip will result in heads. to choose at random between is that it allows at any future I am going Probabilio of logical equivalents rule This inference rule is valid since if two sentences are logically equivalent then they hold in exactly the same possible worlds. PE. From 4 c-t I/, infer P,(4) = PI(@). Temporal logic axioms These axioms capture the temporal axioms are needed captured by the field axioms above. for reasoning component relations of the logic. No specific among intervals time since temporal this is about TLl. Facts; hold over their subintervals, except possibly at the endpoints. (tlQt2Qtl~t4)A(tl#t3)A(t2#t4)~ [H#OLDS(FA,tl,ta) +HOLDS(FA,t:!,tj)]. TL2. HOLDS(FA,tl,t;!) + (tl < t2). TL3. OCCURS(EV, cl, t2) -+ (tl < t2). TL4. OCC(A,tl,tz) --f (tl < t2). Action axiom This axi’om is valid since OCC is true iff both the generative and generated event tokens of the action occur, while ATT is true iff the generative event token occurs. ACTl. OCC(A, tA, t’.J ---f AZ7’(A, tA). Inevitability and equality axiom This axiom is valid because the interpretation of the equality predicate is rigid across worlds. IE. Equality is inevitable: Of(trml = trmz) -+ q ,(trml = trmz). 266 P. Huddawy/Artijicial Intelligence 80 (1996) 243-308 Inevitability temporal axioms relates This set of axioms the inevitability of the logic. The first axiom is valid since the set of accessible worlds becomes smaller as of relations we move into the future. The second axiom is valid since the interpretation that axioms capture among the present and past are determined. They are valid since is defined over worlds that are indistinguishable operator and the temporal component is rigid. The remaining the intuitive property up to and including the inevitability a given time. time points operator ITl. Inevitability persists. (?I < t2) + (Q,dJ -+ Q,4J). IT2. Temporal relations are inevitable. Ot(ll < t2) --$ q (tl < t2). IT3. Present and past facts are inevitable. (II < t2) --+ [ q ,,HULDS(FA, to, tl > V q ,,+ZOLDS(FA, to, tj ) I. IT4. Present and past events are inevitable. (t, < t2) -+ [ci,,OCCUl?Is(EV,to,t,) vO,*lOCCURS(EYto,tl)]. ITS. Present and past action occurrences are inevitable. (tl < t2) --t [O,,OCC(A,to,tl) V0,2+CC(A,to,t1)l. IT6. Present and past action attempts are inevitable. (to < tl) --+ [O,,AWA, to> V q ,,lAWA, to)]. Axioms relating inevitability and probability IPl. Inevitability implies certainty: q & ---f P,( 4) = 1. IP2. Current chance is inevitable: 01[ Pt( 4) 2 cr] + 0, [ P,( 4) > a]. 4.2. Theorems theorems In this section we present that will either be useful later or help to illustrate properties of the logic. For illustrative purposes, we provide proofs of a few of the less axiom obvious rule is followed by or inference a list of the axioms and/or two theorems the rule was applied. We first present rule in the right column. A reference that will be used in later derivations. theorems. Proofs are presented format with the justifying steps to which to an inference in two-column Theorem 4. From cf~ -+ $ and @ + y infer q5 -t y. Theorem 5. 4 --+ O,q5. P. Haddawy/Art@cial Intelligence 80 (1996) 243-308 261 4.2.1. Field theorems We show the derivation of the following the use of the field and e’quality axioms. Henceforth we will simply cite the field and equality axioms to justify multiple derivation steps using them. to illustrate theorem simple Theorem ii. (trml = trm2 + s - s) --+ (ttml = trm2). Proof. 1. 2. 3. 4. 5. 6. 7. s+(-1 *S) =o [s+ (-1 .S) =O] + [(tm =trm+s-s) +(trml =trm;!+O)] (trml = trm2 +s - s) + (trml = trm2 +0) trm2 + 0 = trm2 [trW+O=trm:!l + [(trml =trm2+0) + (trm, =trm2)] (trml = trm2 + 0) -+ (trml = trm2) (trml = trm2 + s - s) --f (trml = trm2) F3 EQ2 MoPo: F2 I, 2 EQ2 MoPo: 4, 5 MoPo: 3, 6 4.2.2. Probability theorems If we think of probability one as analogous to inevitability than zero as analogous seen as probabilistic to possibility, analogues of theorems describing then several of the theorems inevitability and probability greater in this section can be and possibility. Theorem ‘1. From q5 infer P, (4) = 1. This is the third Kolmogorov ‘of inevitability properties axiom of probability mentioned above. It follows from and the relation between probability and inevitability: Proof. I. qi 2. Cl& Hypothesis NEC 3. El,4 + Pt(Cj> = 1 IPl 4. F;(4) = 1 MoPo. Theorem 8. P,(4) + P,(+) = 1. Theorem !L P,(q5 V qb/> = P[(+) + Pt(@) - Pr(d A 9). Theorem IO. Stronger sentences have lower probability. From C$ -+ fi infer P, ($) < Pt($)* Theorem Il. P,(4) = 1 + P,(4A+) = P,(e). 268 i? Haddawy/Artificial Intelligence 80 (1996) 243-308 Theorem 12. Chance is the expected value offuture chance. (tl < t2) -+ [P,,(P,?(4) 2 a) 2 P -+ Pt,(d) a a.Pl Proof. P3 P2 definition of c-prob: 2 [Pt,(Pt,(4) Pr, (4) > LY . p + P,, ( C#J A -Pt2 (4) 2 a) ] 3 a) 3 P --+ Field axioms, EQ2: 1, 3 5. (tl < t2) -+ [Pt,(Pt*(4) > a) > P + P,,(4) a a-PI Field axioms Theorem 13. Certainly later certainty implies truth. (tl 6 t2) + Pt,(P,z(4J) = 1 + 4) = 1. This is the probabilistic analogue of axiom II. Proof. 1. 2. (tl < t2) + pt,c+ I Pt,(4> = 1) = 1 P3 (fl < t2) + P,, (4 A Pr2 ( 4) = 1) = P,, ( Pf2 (#) = 1) definition of c-prob Let A E q3 and B = Pf2 (4) = 1. Then 3. (tl < t2) -+ P,, (A A B) = P,,(B) 4. P,,(B+A)=P,,(dl)+Pt,(A)-P,,(d?AA) 5. Pt,(B-+A)=l-P,,(B)+P,,(A)-P,,(GJAA) 6. (tl < t2) -+ ---f A) = P,,(B 1 -P,,(AAB) +Pt,(A) -P,,(+AA) 7. 8. 9. (tl < t2) ----t Pt,(B + A) = 1 - P,,(A) + P,,(A) (tl < t2) + P,,(B + A) = 1 cti < t2) ---) P,,(P,,(4) = 1 + 4) = 1 Theorem 9 Theorem8 EQ2: 3, 5 F’Z EQ2 Theorem 6 substituting back Theorem 14. Certainty certainly persists. (to G tl G t2) -+ P,“(P,,($) = 1 + P,*(4) = 1) = 1. R Haddawy/Artifcial Intelligence 80 (1996) 243-308 269 This is the probabilistic analogue of axiom ITl. Note that it is not valid that certainty simply persists worlds of positive probability. since semantic constraint (C6) only applies to equivalence classes of Theorem 15. Facts have higher chance of holding over their subintervals. (tl < t2 6 t3 G t4) A (t1 $h) A (tt $t4) --+ P,(HOLDS(FA,t;!,t3)) 2 P,(HOLDS(FA,tl,t4)). 4.2.3. Inevitability of the past Theorem 116. Possibility persists into the past. (t1 < 1’2) -+ CO& -+ 0,,+1. Theorem 17. Present and past inevitability are inevitable. (tl < (12) + (O,, Q, (b + Q, a,, 4). Theorem 18. Present and past possibility are inevitable. (t1 G l2) -+ CO,, o,, 4 -+ at, o,, 4). Theorem 19. Present and past chance are inevitable. Proof. (II < t2) -+ OtJ't,(4) 2 a -+ Ot,Pt,(4,) 3 a '&m-em 16 I. 2. Or,P,,(4> 2 a -+ q t,Pt,(#J) 2 a! 3. (II 6 t2) -+ Q,P,,(#) > cy -+ &P,,(4) IP2 3 a IT1 4. (II < t2) --+ O,zP,,(+) k cr -+ &P,,(4) > (Y Theorem 4: l-3 4.2.4. Certainty of the present and past By axiom IPl that inevitability implies certainty, the following theorems that the past is certain follow directly from the corresponding axioms and theorems for inevitability. Theorem Z!O. Present and past facts are certain. (t, < t2) -+ [P,,(HOLDS(FA,to,tl)) = 1 v P,,(HOLDS(FA,to,t,)) =O]. Similar theorems hold for OCCURS, OCC, and ATT. Theorem ;!l. Present and past inevitability is certain. (tl G t2) ---) (P,,(Q,+) > 0 4 P,,(Q,#) = 1). 270 F? Haddawy/Artij?cial Intelligence 80 (1996) 243-308 Theorem 22. Present and past possibility is certain. (tl G t2) -+ (pt,(ot,+s) > 0 --f Pf?(Ol,$) = 1). Theorem 23. Present and past chance is certain. (tl < 12) + (P,?(P,,($) z a> > 0 + Pt,(Pt,(4) > a> = 1). 4.2.5. Modal operators and quantijers The following theorems modal operators. These theorems hold because from world to world. capture the relationships between the the domain of individuals does not vary the quantifiers and Theorem 24 (Barcan formula). Vx 0, 4 --f QV’x$, where x does not occur free in t. Theorem 25 (Converse Barcan formula). q ,Vx$ -+ Yx Cl, 4, where x does not occur free in t. Theorem 26 (Probabilistic converse Barcan formula). P,(Vn4> = CY + VxP,(Cp) b a. Proof. I. ‘Jxr$+cp 2. P,(Vx# + 4) = 1 FOL4 Theorem 7 3. P,(Vx$ --t 4) = 1 + Pt(+ AVx4) = cy Theorem 11 4. P,(f)bAVx$b) =a 5. P,(4) B a MoPo: 2, 3 Theorem 10 Note that the probabilistic analogue of the Barcan formula vx P,(4) = 1 ---f P,(Vx 4) = 1 the antecedent can be satisfied by a model in which each x is true is not valid because in almost all worlds. 4.2.6. Actions Theorem 27. Attempted acts are feasible. 6 ATT(A,tA) -+ FEAS(A,t*). 6 The definition of feasibility is given in Section 5.1 t? Huddawy/Artifiog6) 243-308 271 Proof. I. AZYA, fA) - O,,ATT(A. t, (t G TV) + (O,,A~(A,~A)) Theorem 5 Theorem 16 vt (t < tA) - (Ot,&TA,~A)) UG vt of,, An(A.tA) + l(t d tA) ] FOL axioms 2. 3. 4. 5. ATT(A,tA) - [vl (t d IA) FOL axioms, MoPo 6. ATT(A, tA) - FEAS(A, tA) definition of FEAS Theorem 28. Past and presenf feasiE (tA < t) - COPEAS(A,tA) - [. 4.3. Examples In this Se&On Cm in The first the logic Shpk be uSed eXmElogiC to distinguish the use of exampkSl]uStr~te in which balls are t Suppose that an agent cannot &ey are inevitable and factors influence because thekndent of his available actions. tl you two Urns_ In box 1 both two reasoning about actions. between factors the agent cannot Consider a game will randomly be given one of three tning urns contain all red balls. In box 2 thh r& and white balls and the in the two urns are identica, contains all red balls and the proportions other contains all white balls. At time lose one of the urns from the the urn to me ts she is then to choose a box you are given and give from that urn. What ball at random the chance that she will draw a red ball? The situation ,y the fOIlowing is tl can influence that at Sentences: time (now<t, <t2<tg<tq), P,,ow (Q, OCCUZW red-picked, t3, Pn,,,u ( P,, ( OCCUFW red-picked, t3, Vx Pf2 ( OCCURS( red-picked:k( X), t2, t3 ) ) = PI2 ( OCCURS( red-picked (11 (21 (3) One model Since inevitability in which these sentences are,rlds is shown (axiom from sentence it follows persists 10) (Theorem IT1 tences have lower probability in Fig_ 7. P,,,,w (Cl,, OCCURS{ red-picked, t3, t4 Since Inevitability implies certainty (axis from (4) that P,,, ( Pt2 ( OCCUZ?S( red-picked, t3, t4 By Theorem 11, (4) (5) 272 F? Haddawy/Artijiicial 1243-308 Red Fig. 7. Possiblh. Prz (OCCVRS( red-picked, t3, t4) ) P,, (OCCVRS( red-picked, t3, t,p t2 3 t3 ) > = Pt,(OCC(pick(x),tz,ts)). By inference rule UG and Theorem 7 I) that P,,,,( Pt2 (OCCVRS( red-picked, tz ‘dx Pt2 (OCCVRS(red-pickpick t t2, t3) ) = P,,(OCC(pick(x),t:!,t, Theorem 11 applied to (5) and (7) y P,,,,w ( PI2 ( OCCVRS( red-picked, t ‘dx P,? ( OCCVRS( red-pickIPick( x ), t2 7 t3 ) ) = Pt,(OCC(pick(x),t2,~ And by the definition of conditional 1 P,,,,,,( Pt, (OCCVRS( red-picked, i Vx P,> ( OCCVRS( red-picl/Pick(x) 9 t2 1 t3 > ) = Ptz (OCCVRS( red-pi&. Finally by axiom ~2, sentences (3) Cnbined to yield (6) (7) (8) (9) P,,,,,,,(~x P,? (OCCVRS( red-picyick(x) v t2, t3 ) ) = Pt2 (OCCVRS( red-pi& (10) SO there picking a red ball. is at most a l/3 chance $nce the chance of your partner I? Haddawy/Arttj?cial Intelligence 80 (1996) 243-308 273 1 HOLDS(icy,tl,$) I I I . 5 i -HOLDS(icy,tt,t3) I “ObV I t1 : I : I : I : I I tz b Fig. 8. Possible model for carry example. The next example is a modified version of an example presented by Pelavin It illustrates how the ability of the logic to represent both probability and possibility can be that I am going used to reason about the chance In shopping most cases it is not possible to carry two bags if it is icy out. There is a 50% chance that it will be icy out this evening. What is the chance that carrying both bags simultaneously will not be a possible course of action? The situation can be described by the following three sentences. this evening and want to carry two grocery bags to the car simultaneously. the terms now, tt, t2, and tg are time constants. that two actions can co-occur. Suppose In these sentences, [43]. vt,t’ (now< t < t’) ---f P,,d~O, [OCC(caq(h),t,t’) AOCC(carry(b2),t,t’)l I HOLDS(icy, t, t’) ) = 0.8, p,,,,(HOLDS(icy,tl,t3)) = 0.5, (now < t1 < t:! < t3). We would like to know the probability of ~0,~ [OCC(caq(h),tl,t:!) AOCC(CW(~~),~I,~~)I. (11) (12) (13) One possible model in which the sentences Fig. 8. The labels “CO” and “-CO” designate of the two actions, respectively. Note that in worlds wt-w4 we have are satisfied the co-occurrence in every world is shown and non-co-occurrence in ~0,~ [OCC(cq4h),t19t2) ~OCC(carry(b~),t~,t;!)l and in ws and +j we have 214 I? Haddawy/Artifcial Intelligence 80 (I 996) 243-308 The property rem 14) together with sentences ( 12) and ( 13) entail that that facts have higher chance of holding over their subintervals P,,,,,,(HOLNicy, r~, f2)) 3 0.5. By axioms FOL5 and MoPo it follows from sentences (11) and (13) that P,,,,w(~0,, [~wc~y(h~,tl,t2) ~OCC(carry(b:!),tl,t2)1 1 HOLDS( icy,tt ,t2)) = 0.8. By axiom P2 it follows from sentences (14) and (15) that (Theo- (14) ~now(~Or, [OCC(carqf(h),h,t2) A OCC(carry(b2),21,t2)1) 2 0.4. So there is at least a 40% chance possible. that carrying both bags simultaneously will not be Furthermore, an upper bound on the current probability two actions can be calculated. Since inevitability implies certainty of the co-occurrence IPl), (axiom of the Pnow(Pr,(OCC(carry(bl),tl,t2)) AOCC(carry(b2),tl,t2)) =O) 3 0.4 and since chance is the expected value of future chance (Theorem 12)) 5. Describing properties of actions The representation of actions contained in terms of whether describe actions bring about their occurrence, This next section details how actions can be described. If an action can be attempted we say it is feasible. in our logic is highly expressive. We can their attempt will and what effects their attempts and occurrences will have. they can be attempted, whether that If an action occurs when attempted, the chance of certain in terms of its feasibility, influences the action the chance If an action and its effects. in the world may I can only attempt we say is executable. conditions, we call these its effects. An action will be described its executability, Conditions For example, are called feasibility conditions that the action will occur. For example, in starting conditions. And finally conditions may influence certain effects. For example, chance The following aspects of actions. influence that an action can be attempted. to start my car if I am at the location of the car. Such the chance to start my car I will succeed are called executability that an action will achieve if I start my car with the garage door closed there is a good three sections discuss how C tCa can be used to describe conditions. Further conditions may influence that I will be asphyxiated. Such conditions if there is gas in the tank. Such conditions conditions. these different are called ramification if I attempt the chance it only P. Haddawy/ArIijicial Intellifience 80 (1996) 243-308 21s 5.1. Feasibility Sometimes it may not be possible generative that the a&on event cannot always occur. If it is not possible is infeasible. Three types of infeasibility can be distinguished. to attempt an action. This is the case if an action’s to attempt an action, we say ( 1) It rnay not be possible to attempt a single action under certain conditions: I in the direction of the wind at the same time unless (2) cannot attempt It rnay not be possible current actions under certain conditions: drive north. (3) A compound action consisting to go from home to the office if I am not at home. action consisting to attempt a compound ’ I cannot attempt to two con- to drive north and the wind is blowing attempt under any circumstances: arm1 simultaneously under any conditions. I cannot attempt to two concurrent actions may not be possible to to raise and lower my left If an action can be attempted we say that it is feasible. event to attempt the state of affairs of the world, The attampt of an action is something is consistent with the action and, hence, that an action token’s generative event token is instantaneous. the agent chooses to do. As long as an action’s the agent can generative is feasible. We make the simplifying choose ’ 7 9 Since the assumption agent may or may not choose to attempt an action, for an action to be feasible under this token is assumption possible at an infinitesimal persists possibility token whose generative event the time of the event token. Since possibility that there be some action instant before this can be captured by defining the time of the attempt: at all times before the action it suffices (Theorem feasibility the past into 16) as Definition 29. An action A is feasible at a time tA, written FEAS(A, tA) iff v(t < tA) O,An(A,tA). This definition of feasibility tions come to mind more immediately. First, one might be tempted seems a bit complex and two simpler alternative defini- to define feasibility ’ One could make the assumption that individual actions are always feasible but, as this example shows, once we compose actions into plans we run into the problem that the plans may not be feasible. So we may as well be completely general and not assume individual actions to be feasible. ’ We can think of a generative event token that spans time tA rk as a set of sequential instantaneous actions A;. An action is then feasible if each part of the action attempt is feasible in the context of the earlier parts of the action attempt. The chance of feasibility can be represented as where ATT( Pl.T-,n, 1A ) designates the occurrence of the portion of the generative event token from time tA up to time n. ‘) Notice that had we only represented action occurrences and not attempts, we would have been forced to apply this assumption to occurrences with the result that we could not reason about actions that span time. 276 P Haddawy/Art@ial Intelligence 80 (1996) 243-308 Fig. 9. Chance of feasibility. this (axiom tA) and the past and present are inevitable more simply as the possibility of the attempt at the time of the attempt: O,,ATT( A, tA). IT6) But because from this that q l,,AV(A, for feasibility. Second, within to be a probabilistic framework, V( 2 < tA) P,(AZT( A, tA)) it infinite would rule out models which contain a uniform distribution over an uncountably in only a finite number of the number of worlds and in which worlds. In such models, the action would be zero, yet it would be possible is far too strong a condition a more natural definition > 0. But this definition of feasibility might seem is too restrictive. the probability the action. of attempting In particular, is attempted to attempt the action it follows In general, there will be a certain chance that in the world are consistent with the occurrence of the generative event. The conditions chance at time t that an action A is feasible at time tA is P,(F’EAS( A, tA)). that an action is feasible-the chance Consider again the action of starting my car and suppose that the chance is 0.8, i.e., P,,,,(FEAS(start-car, feasible shown the key occur. So in both WI and w2 we have +EAS(start-car, ws-& to choose in Fig. 9. In neither world wt nor world w2 does the generative event of turning tA). But in worlds that it will be within my power is possible at time tA. So the chance tA)) = 0.8. One possible model the attempt to attempt the action is 80%. that it is for this is 5.2. Executability Once an agent attempts an action, whether or not the action occurs is no longer directly within the agent’s control-it is a function of chance. Definition 30. The chance it occurs given that it is attempted: that an action A is executable at time tA is the chance that F! Haddawy/Art@cial intelligence 80 (1996) 243-308 211 5.3. Effects One of the objectives of the present work is to capture some of the natural that exist between described and how some natural properties of effects follow directly chance and possibility. relations actions and effects. We show how various kinds of effects can be from the models of An effect is a condition, the chance of a condition, the chance, it is called a negative effect. Depending it is called a positive the chance of which is influenced by an action. If an action if the action on the nature of the in one of two ways. If we are not of actions, we may simply describe effects of action efSect and problem, we may wish to describe effects about the occurrence In this case, the chance of the effect will be represented as increases decreases planning concerned attempts. P,(EFF 1 AZT(A, t,z,)). More expressive power can be gained by describing In between effects of a successful action and effects of a failed are represented by an expression of the effects of action occurrences. this case, we distinguish action. The effects of an action’s occurrence form and the effects of a failed action are represented as P,(EFFIATT(A,tA) A4t:,OCC(A,t,&). Three conditions are necessary for EFF to be a positive” effect of the occurrence of an act A: ” (i) Since actions can only succeed temporal temporal influence the action of saying to the effect of reciting the future, EFF cannot of A. But EFF need not necessarily temporally precede completely the the occurrence relation between action occurrence of A. Fig. 10 shows the necessary relations between actions and their effects that and effect. The possible are allowed by this constraint are shown in Fig. 11. An effect may begin before the time of an action: the word “seven” at the right time the Gettysburg address. An effect may persist conu-ibutes the effect of the hockey puck sliding across the ice after the time of an action: it terminates. An effect may begin exactly persists after the action of pushing is over: the effect of the glass being empty begins exactly once once the action all lthe water the effect of the box sliding across the floor ends once it hits the wall, even though is still occurring. Finally, an effect may begin some time after the push action an action is over: the effect of the bomb exploding occurs some time after the action of setting If an action has no chance of occurring effects at that time. So A must have a positive chance of occurring. is poured out. An effect may end before it cannot have at a particular the action the timer. is over: time, (ii) “’ Negative eflects are described similarly. ’ ’ Note that these three conditions are similar to Suppes’ [ 54 1 prima facie causality conditions. 278 P. Haddawy/Artificial Intelligence 80 (1996) 243-308 “i , tEFF t 'EFF t’A Fig. 10. Relative times of an action and its effect. I recite Gettysburg address I , push hockey puck , I puck slides across ice I I glass empty I box hits wall , set timeron bomb ,~ bombexplod~s , Fig. 1 I. Possible temporal relations between actions and effects. (iii) An effect is a condition influenced by an action, so the occurrence of A must positively the chance of EFF. These conditions are fundamental properties of effects of any kind-effects influence effects of events, even effects of facts. They will arise again conditions that influence actions since the feasibility, executability, are in a sense effects of such conditions. of actions, in of the discussion and effects of actions Suppose act A occurs occurrence: HOLDS( H, the conditions Then in the interval tEFF, t&), tA to tA’ and let EFF be a fact, event, or action tEFF, t&F), of occ( A, t.WF, t&?) . occuRs(Ev, (i)-(iii) can be stated in the logic as: I? Haddawy/Artifcial Intelligence 80 (1996) 243-308 219 tA < t&, ( 1) temporal non-succession: (2) positive chance of occurrence: PtA (OCC( A, tA, ta) ) > 0, I2 ( 3) positive Due to tlhe way the semantics of &, has been defined, condition its proper 1 OCC( A, t,z, , tA’ ) ) > PfA (EFF) . is expanded out into If condition inJ%dfluenCe: P,, (2). (3) (EFF (3) entails conditions form in the logic it ( 1) and becomes: P,,(EFFAOCC(A,tA,t:,)) > P,,(EFF) -P,,(OCC(A,tA,t;)). (2) is false, i.e., P,, (OCC(A, If condition since both sides of the inequality is false then t& < tA. Since the present and past are certain is false tA, ta)) = 0, then the above sentence are zero. So if (3) holds, (2) must hold. Next, if ( 1) (Theorem 2O), P,, (EFF) = 0 v Pr, (EFF) = 1. Either case contradicts condition (3). So if (3) holds, (1) must also hold. can only affect future conditions. As a consequence This result shows that the models have captured the natural actions and effects-actions result, if we use condition then actions after the time of the goal cannot contribute to represent and distinguish The ability of the logic to define what is necessary (3) possibility define actual effects as potential effects that actually occur: allows us to distinguish temporal relation between of this for a plan to achieve a goal the goal. truth, probability, to achieving between and between potential effects and actual effects. We can EFF r\P,,(EFF 1 OCC(A,t,&) > P,,(EFF). 5.4. Conditions that influence actions Conditions in the world may influence actions. Such conditions conditions, ramification those for effects, ramification are called respectively. that are necessary condition of an action. the feasibility, conditions, executability, executability feasibility In this section we present conditions, for something to be a feasibility, and effects of and conditions, to or similar executability, 5.4.1. Feasibility conditions Certain conditions may have a positive they are called negative feasibility here; negative conditions otherwise conditions influence influence feasibility conditions aCtiOn OCCllrrenCe: As in our discussion condition feasibility HOmS(m, of effects, t&), tFC, three conditions occuRs(Ev, for action A at time tA: the chance they are called positive feasibility that an action will be feasible. conditions. We discuss positive If the conditions and feasibility are similar. Let FC be a fact, event, or Or OCC( A, tFc, t&) . tFC, t&>, are necessary for FC to be a positive that this I2 Note to saying that the action has a positive chance of being executable, P,,, (OCC( A, tA, ?a) 1 A7T( A, tA)) > 0. The equivalence follows from the fact that f,,, (OCC( A, tA, la)) > 0 entails that P,,, (ATT( A, IA)) > 0. is equivalent 280 I? Huddawy/Art$icial Intelligence 80 (1996) 243-308 tFC t’Fc Fig. 12. Relative times of feasibility condition and action attempt. (1) temporal non-succession: (2) positive chance of the condition: PtFc (FC) > 0, (3) positive injkence: Pr,( FEAS(A, tA) 1 FC) > Pt,(FEAS(A, condition rFc < tA is depicted The temporal non-succession t,CC < tA, tA) ). As was the case for action effects, condition The argument entails (1) that (3) entails (2) is exactly is slightly more complicated. Suppose in Fig. 12. (3) entails both conditions (1) and (2). the same as for effects. The proof that (3) (1) that condition is false: 1. (tA<tFC)--’ [O,,FEAS(A,tA) 2. P,,(FEAS(A, 4 Q,FEWA,tA)l tA)) > 0 ---f O,,FEAS(A, Theorem 28 t,z,) IPl 3. &.&%‘tS(A, tA) + P,,(FE‘iS(A, tA)) = 1 IPl 4. 5. (tA < tFC) ---f [P,,(FEMA,tA)) > 0 + P,,(FEAS(A, tA)) = 11 Theorem 4: l-3 (tA < tFC) + [P,,(FEAS(A,tA)) P,,(FEAS(A,tA)) =ov = 11 definition of +. Both P,,( FEAS( A, tA)) = 0 and P,,( FEAS( A, t.4)) = 1 contradict condition if (3) holds, ( 1) must hold. So again the models have captured a fundamental relation: a condition that action. that succeeds an action’s attempt cannot (3). So temporal the feasibility of influence 5.4.2. Executability conditions Certain conditions may influence the chance that an action is executable. Conditions influence are called positive executability conditions and conditions with influence are called negative executability conditions. Let EC be a fact, event, are necessary with a positive a negative or action occurrence with associated for EC to be a positive executability ( 1) temporal non-succession: (2) positive chance of attempt and condition: P,,(AZT(A, (3) positive in.uence: tEc. the. Three conditions for action A at time tA: interval condition tA) A EC) > 0, tEc < ta, P,,:,(OCC(A, tA, t;) 1 An(A, tA) A J=) > p,,;,(OCC(A,W;) lAn(A,ttt)). Negative executability again, condition conditions are represented by negating (3) entails both conditions (1) and (2). The proofs are similar the occurrence of A. Once to the P: Haddawy/Artifcial Intelligence 80 (1996) 243-308 281 tEC t’J?c Fig. 13. Relative times of executability condition and action occurrence. earlier proofs showing action. that the effects of an action cannot occur prior to the time of the condition tEc < ta is depicted in Fig. 13. It just says The temporal non-succession the success of A, it cannot be a constraint on the that in order for EC to influence state of the world after the time of the action. This makes good intuitive sense because of an conditions executability action but they should they should be worth bringing about. For example, consider a condition chance now that the action will be executable. Suppose I start my car the engine the that typically 15 minutes after should not just provide evidence after the time of the action the executability. Hence, for the executability that increases is warm: influence P,,,,,I:OCC(start(car), TV, f2) A7T( start( car), ti > A I 3t HOLDS( warm( engine( car) ), t:! + 15min, t) ) > P,,,,,,(OCC(start(car),ti,t2) 1 ATT(start(car),ti)). We would not want condition order to make my car start now. to call 3 HOLDS(warm(engine), t2 + lSmin, t) an executability for starting my car and to generate a plan to warm up my car in the future in 5.4.3. Rami$cation conditions into a positive If the conditions in the world may influence on the effect, influence have a positive the chance of an action’s positive Certain conditions they are or negative effects. they are called negative ramification called pos,itive ramijcation conditions and otherwise conditions. In some cases a positive turn a negative condition may even ramification conditions. Let effect for negative RAM be a fact, event, or action occurrence with associated (tR*M, thM). Since interval we will primarily be concerned with the effects of the occurrences of successful actions, for failed we will dIescribe ramification actions and for simple action attempts are similar. Three conditions for to effect EFF for action A at RAM to be a positive time tA: this context. The definitions condition with respect effect, and conversely conditions within are necessary ramification ramification (1) Telmporal non-succession: (2) Positive chance of occurrence and condition: PfRA,( OCC( A, tA, ta) A RAM) > 0, (3) Positive injhence: tRAM < tkFF, P,,,,(EFF ) OCC(A, tA, t;) A RAM) > P,,,(EFFI OCC(A,~A,&)). 282 k? Haddawy/Art@cial Intelligence 80 (1996) 243-308 t'A I t'RAM t k4M Fig. 14. Relative times an action, its effect, and ramification condition. Negative ramification (3) entails both conditions ( 1) and (2). conditions are represented by negating EFF. Once again, condition The temporal relations between in Fig. 14. The temporal non-succession are depicted for RAM to influence EFF, the time of the effect. Note, however, because the effect of the action can be delayed. the action, the effect, and the ramification condition just says that in order condition it cannot be a constraint on the state of the world after that RAM can occur after the time of the action 5.5. Properties of plans In general we will be interested A plan is simply a set of actions attempted at particular of the attempts within concurrent reason about the set of actions composing about plans rather than single actions. the times and in a homogeneous manner. To reason about plans, we will simply the plan, we can represent plans containing times. By specifying both sequential in reasoning actions them. 5.5.1. Feasibility of plans Plan feasibility is a more complex concept than action feasibility. Attempting a plan action attempts. A plan is feasible means attempting all the actions composing of the individual actions composing incorrect ways of defining that has the desired properties. Consider ordering of the attempts. First, we might be tempted is feasible simply as the chance it can be attempted. We first examine the chance of plan feasibility that each action is feasible: the plan, so a plan attempt is the conjunction if it can be attempted, two superficially i.e., if all the appealing but and then present a definition the plan ATT( AI, t,+ ) AA7T( A2, t,+ ), with any that this plan to define the chance But this expression gives us too high a chance for plan feasibility because FEAS( Al, tA, ) A FEAS(A2, attempted Second, by analogy the plan is feasible as to action feasibility we might be tempted in some world but there is no world where they are both attempted t,+) could be satisfied by a model to define the chance in which each action is together. that the statement f? Haddawy/Artificial Intelligence 80 (1996) 243-308 283 k tAl t.42 Fig. 15. Example of plan feasibility. for feasibility to the attempt of the single more complex action. But suppose If tA, = tA2 this is the correct expression and A2 is equivalent tA, < t,+ and consider but the chance that Al can both be attempted high a value for plan feasibility. the joint attempt of Al that is 0.8, that A2 is feasible given the plan is only 0.8 .0.14 = 0.11. Hence this expression also gives us too in Fig. 15. The chance of the above sentence is only 0.14. So the chance that the actions composing that action AI is feasible is 0.8 while the chance is attempted the model since Each action in a plan must be feasible in the plan since we wish to attempt actions above plan is feasible is in the context of the attempts of the earlier that the the entire plan. So the chance P,(F~~S(Az,t.+) 1 Ap(AI,tA,)) *P,(FEAS(AI,~A,)). If tA, = t,+ this is also a valid expression for plan feasibility. So when t.4, = t& we have Pr(FEAS(Az,tA,) 1 An(Al,tA,)) *&(FJ=%AI,~A,)) = P,(FE’AS({AI,A2},tA,)), where FEAS({At,Az},rA,) = vt (t ‘: tA,) -+ Or[An(AI,tA,) AA~(ht,+)l. Finally consider f&. The chance the plan AZT(Al, that this plan isfeasible t,+) AA’IT(A2, is t&) AAZT(A3, tA3), where rA, = tA2 < P,(=‘A%AS,tA,) 1 Am(AIvtA,) AAm(&,tAz)) .P~(~EAS(AZ,~A~) 1 An(Al,tA,)) *f’t(FEA%A~,ttt,)) or equivalently, Definition 31. In general, attetIIptS Al’T(Ai, t,+) with t,+ < t,.+ the chance < that the plan consisting is . . iS feasible . 6 tA,, of the set of n action 284 I? Huddawy/Artijicial Intelligence 80 (1996) 243-308 FEAS(Ai,fA,) 1 /\AZ’T(Aj,fAj) .jci 5.5.2. Executability of plans The chance that a plan is executable is represented by an expression of the form \i i / Just as with individual actions, plans may have executability conditions. 5.5.3. Effects of plans The chance of the effect of a successful plan is represented by an expression of the form Pt EFF 1 A OCC(Ai, tAi, tai) \ i / Effects of plan attempts individual actions, plans may have ramification conditions. and of failed plans are represented similarly. Just as with 6. Describing and reasoning about planning problems framework In this section we present a general The purpose of the framework C tea . The main purpose of describing the generation descriptions from the properties of the component in which Cc,,, can be used to specify such a description. Many alternatives problems. planning in the use of the rich language is to use the description in the framework, we focus on in the sense that properties of a plan may be inferred actions and the environment. We present one way are possible. problems and evaluation of plans. So in developing is to provide guidance planning that are compositional, for describing 6.1. Representing the planning problem the chance In this section we show how C,,, can be used to describe planning problems that a plan will achieve a given goal. Since we can reason about knowledge we have about chance lem all probabilities will be taken relative described cations, and (iv) [ 431, we call the world within which planning Since we are working can include chances of facts and events action specifications with associated is the chance now, in describing to the present (ii) time. A planning problem the individual so that the best the planning prob- is action specifi- the goal description. Following Pelavin environment. the planning the description of the planning environment that hold or occur at any time. The individual and effects conditions, the goal for each action. Although in terms of (i) the action feasibility conditions in a temporal setting, the planning environment, executability takes place interactions, in principle ramification conditions, describe (iii) P Haddawy/Artijicial Intelligence 80 (1996) 243-308 285 relations. Due description may be any sentence of Ctca, in practice we restrict the goal description any non-probabilistic and temporal the present planning problem. Throughout to be sentence of L tea involving only HOLDS and OCCURS predicates in to a given this section, we will be concerned with deriving a lower bound on the lower bounds on all that a plan achieves a goal. So it will suffice interactions will be specific complex nature of action the description of action to the potential framework, interactions to specify chance probability values. 61.1. The planning environment The planning environment is described in terms of the chances that facts hold and events occur: pn,,w(.~OLDS(FA, tF, t;,) 2 a, p,,,,,v ( ~OCCURS( EV, tE, t;) ) b a, as well as temporal constraints relating the times of facts and events: (now ,< tF < tE) . 6. I .2. Feasibility conditions feasibility Action conditions FC are described by sentences of the form pm,,(lWWA,tA) 1 FC) 2 a, where Feasibilil:y tFC is the earliest conditions the following time associated with FC and tFC < tA. to represent can be used interference that action A2 is not feasible as long as Al says sentence actions. For is between example, being perfo’rmed. P,,,,JI’EAS(A:!, tA2) 1 OCC(AI 9 tA, 7 t:, > A (tA, < fA2 < t;, )) = 0. 6.1.3. Executability Executability conditions conditions EC are described by sentences of the form P,,,((JCC(A, tA, t;) 1 An(A, tA) A EC) > ff, where the earliest are assumed time associated with EC is tEC, and tEC < tk. Executability of the action with which they are associated: to be independent (16) conditions 1x41. Pn,,,(ECI ATT(A,tA)) = P,m(EC). So a lower bound for the chance that the action is executable can be expressed in terms of the executability specification (16) and the chance of the executability condition: P,,,,(OCC(A,tA,t;) IAu(A,tA)) > P,,,,(OCC(A,tA,t;) IAn(A,tA) AEC) . P,w,(EC). Assumption IA1 reduces the complexity of inference and is reasonable in most cases. 286 P. Huddawy/Artijcial Intelligence 80 (1996) 243-308 6.1.4. Effects and ramijcation conditions We describe positive action effects by sentences of the form: P ,,,,I ,(EFF 1 OWA, tA, t;, A RAW 2 a, (17) where RAM represents time associated with EFF GRAM < tkFF Ramification they are associated: which the ramification conditions the WkSt iS tEFF, conditions are assumed for effect EFF of action A, the latest time associated with RAM is tRAM, and of the action with to be independent IA2. P,,,,(RAM 1 OCC(A, t,z,, t;)) = P,,,,(RAM). So a lower bound for the chance of the action’s positive effects can be expressed the chance of the ramification (17) and in terms of the positive effect specification condition: P,,,,,dEFF 1 OCCCA, tA, t:, 1 2 P,,,,,v(EFF 1 OCC(A, t.4, t;) A RAM) . P,,,,(RAM). 6.1.5. The goal description The goal description is any non-probabilistic sentence of L,,, and OCCURS predicates and temporal bank by 5:OOpm may be represented as relations. For example, involving only HOLDS to the the goal of getting Elfi, t2 (tl < 5:OO) A HOLDS( loc(me,bank), tl , t2). 61.6. The probability of goal achievement In order that trying a plan since if the plan is not feasible attempts attempt the goal and that the plan is feasible: the chance to compare alternative plans, we will be interested to attempt a given plan achieves a given goal. We speak of trying to attempt it cannot be attempted. For a plan with n action to that the attempt of the plan brings about such that tA, < tA2 6 . . . < tA,, a lower bound on the chance the plan achieves goal G is the chance in inferring that trying I3 FEAS(AittA;) I /\An(AjvtA,) j<i (18) This is only a lower bound since the goal may come about even if some of the actions are not attempted. I3 Haddawy 12 1 1 derives this expression from an expression for the expected utility of trying to attempt an action. I-! Huddawy/Artifcial Intelligence 80 (1996) 243-308 287 If the failed attempt of a plan has no chance of achieving our goal, we can provide to attempt the goal by the plan achieves the plan achieves both the occurrence of that the plan attempt brings about both for the chance a precise expression focusing on the chance that trying the plan and the goal. This is just the plan occurrence that trying to attempt the chance and the goal multiplied by the chance that the plan is feasible: FEAS(Ai,tA,) 1 AAn(AjvtAj) . .j<i (19) and effects of actions the probability of a goal from action specijications the feasibility, executability, if these descriptions 6.1.7. Infertkg Describing ning purposes achieve a given goal. We show here how these descriptions the chance given goal being achieved. For plans consisting of multiple actions we need additional the plan. Since numer- information the interactions of the actions composing later of ous types of action performing is only useful for plan- that a plan will to infer and in a can be combined in the action occurring are possible, we will give a specific example a single action will result for a more complex plan. to infer the chance can be combined that attempting such inference interactions concerning Suppose we wish to achieve goal G and suppose that G is an effect of action A. The chance that trying to attempt A results in A occurring and achieves G is P,,,,,(GAOCC(&tA,t;, IAn(A,tA)) -Pnow(FEf4S(A,t~)). By the definition of c-prob the first term can be written as By axiom ACTI, So the chance of achieving goal G can be expressed cutability, and effects of A: in terms of the feasibility, exe- f’n,,w(~~OCC(A,t~,t:,) IAn(A,tA)) ~P,,,w(F~~~(A,~A)) = p,,ow(G ( OCC(A, tA* t;>) * Pnow(OCC(A, tA, t;> 1 An(A, tA)) . Pn,,w(FE~S(A, tA) ). If action A has ramification, then by independence assumptions executability, and feasibility IA1 and IA2 we have conditions associated with it 288 l? Haddawy/Art$icial Intelligence 80 (1996) 243-308 P,,,,,(GAOCC(A,t,,t:,) IAn(A,tA)) .P,,,w(FEAS(A,~A)) 3 f’i,,,,(G 1 OCC(A, tA, t;> A RAW . p,,,w(OCC(A, tA, t;> 1 Ap(A, tA) A EC) . f’n,,dFEAS(A, tA) t FC) . PmdRAM) . PmdEC) . PmndFC). 6.2. Planning example about plans. Suppose This section presents a detailed example of the use of the representational framework like to go to my favorite I am at home and would for dinner. The restaurant does not take reservations. Under normal circum- I can get a table within fifteen minutes but if a theater performance has ended the chance in is that my car is above freezing. The and effects for the two and environment, in reasoning restaurant stances, in the last hour, the wait could be much longer. We would like to determine that the plan consisting having dinner without having is fairly unreliable problem actions, the desired goal. to wait too long. A further complication to start if the temperature likely the feasibility, executability, is described by specifying the interactions between of starting my car and driving to the restaurant will result the state of the planning and is only the actions, start (car) Executability. am trying to start it. I can usually start my car if the temperature is above freezing while I vt,v (t, > now) --+ pmv(owst~t(c~), ATT(start(car),t,) t,, ts + 1) I AHOLDS((temp> 32),t,,t,+ 1)) 20.95. (20) Feasibility. as the car. I can attempt to start my car if I have the keys and am at the same location vt,y,t’,X (ts > now) + P,,,(FEAS(start(car), ts) I HOZBS( have( keys), t’, ts) A HOLDS(loc(me, n), t’, ts) A HOLDS(loc(car,x),t’,t,)) = 1. drive( home,restaurant) (21) Effects. There is at least an 80% chance table within 15 minutes, as long as no theater performance arrival at the restaurant. that if I drive to the restaurant I will get a ended within an hour of my F! Haddawy/Artijicial Intelligence 80 (1996) 243-308 289 Vtd, tii P,,,,“( 3, t’ (t& < t < ti + 15) A OCCURS( get(table), t, t’) 1 OCC( drive( home,restaurant), td, t:) A dt,,, t;, (t;, < t; 6 t;, + 60) A Executability. that the executability I can successfully condition is the occurrence of the action of starting my car. OCCURS( performance, t,, , t;, ) ) 3 0.8. (22) drive to the restaurant if I can first start my car. Notice Vt, t,f (td > now) -+ P,,,,,( OCC( drive( home,restaurant) , td, td + 10) 1 A7T( drive( home,restaurant) , td) A OCC( start( car), t, td) ) = 1. (23) Feasibility. at home. I can attempt to drive from home to the restaurant if both I and my car are V’t, td (td > now) -+ I’,,,,,( FEAS( drive( home,restaurant), td) 1 HOLDS(loc(me,home) , t, td) A HOLDS( loc( car,home) , t, td ) ) = 1. Action interactions We assume that the actions of starting the car and driving influence one another. This is represented by the following to start the car does not negatively influence the feasibility of driving the to the restaurant do not three sentences. negatively Attempting car at a later time. (24) ~hf,t.,,x,y (ts < &I) -+ p,,,(FEAS(drive(x,y),td) IATT(start(car),t,)) b p,,,(FEAS(drive(x,y),td)). (25) the car does not negatively Starting a later time. influence the effects of driving to the restaurant at P,,,,,,,(3t,t’ (ti < t < tL+ 15) ~OCCURS(get(table),t,t’) 1 OCC( drive( home,restaurant), td, t>) A OCC( start( car), t,, t:) ) 2 P,,,,,,,(3t, t’ (r:, < t < ti + IS) A OCCURS(get(table), OCC( drive( home,restaurant) , td, ti) ) . t, t’) I (26) Attempting starting the car at an earlier time. to drive to the restaurant does not negatively influence the executability of 290 Pr Haddawy/Artificial Inrelligence 80 (1996) 243-308 VtdJsJ: 0: <&I) -+ P,,,(OCC(staNcar), A7T( start (car), I t:) t,, ts) A A’IT( drive( home,restaurant) , td) ) > P,,,,(OCC(start(car), tS, t:> 1 AZT(start(car), tS)). (27) Planning environment We have the following time line. (now < to < t1). There is an 80% the temperature will be above freezing this evening. P,,,,,,,(HULDS((temp > 32),tl,tl + 120)) =0.8. I am certain to have my keys this evening. P,,,,~,(HOLDS(have(keys), to, tl)) = 1. I am certain to be at home this evening. I4 P,l,,w(HOLDS(loc(me,home),to,tl + 1)) = 1. My car is likely to be at home this evening. P,,,(HOLDS(loc(car,home), to, tl + 1)) 2 0.95. There is no theater performance this evening. P,,),(Zlt, t’ (t’ 6 tl + 120) A OCCURS(performance, t, t’)) = 0. Goal My goal is to get a table within thirty minutes of tl. 3tG, td (tl < tc < tl + 30) A OCCURS(get(table), tG, th). (28) (29) (30) (31) (32) (33) The derivation We want and driving to derive to the restaurant at time tl + 1 will occur and achieve that the plan consisting the chance the goal: of starting my car at time tl I4 Since my location is essentially within my control, this would more accurately be represented with a stay-at-location action: Vx,n,tP,,,(OCC(stayy(x,n),r,r+n) Vx,n,tP,,~(HOLDS(loc(me,x),r,t+n) 1 ATT(stay(x,n),t))= 1, 1 UCC(stay(n,n),t,r+n))= I, where stay(x, n) means that I stay at location x for n time units. For simplicity of exposition we have omitted this action from the plan. P. Haddawy/Art#icial Intelligence 80 (1996) 243-308 291 Pnd!3tc,t~ (tG d tl i-30) r\OCCU~&s(get(table),tG,&)A OCC(drive( home,restaurant), tl + 1, tl + 11) A OCC( start(car), tl , tl + 1) 1 AV(drive(home,restaurant), tl + 1) r\ATT(start(car), rl)) . P,,,,J: FEAS(drive(home,restaurant), tl + 1) 1 ATT(start(car), tl )) . Z’,,,,,J: FEAS( start(car), tl )). (34) (35) (36) We calculate a lower bound on the chance of each of the terms (34)) (35)) and (36). Calculation of (36) By axiom FOL5 and (21) , p,,,,(lCEAS(start(car), TV ) 1 iYOZDS( have( keys), to, tl ) A IfOLDS(loc(me,home),ro,tl) AHOLDS(loc(car,home),to,t~)) = 1. (37) By Theorem 11 and (30), (31), and (32) it follows that P,,,,,(jYOLDS(have(keys), to, tl ) A HOZ_DS(loc(me,home), to, rl ) A IYOLDS(loc(car,home),to,tl)) 2 0.95. By the definition of c-prob and Theorem 10 applied to (37) and (38), P,,,,,(t:EAS(start(car),tl)) Z 0.95. Calculation of (35) By axiom FOL5 and (24), P,,,,,( RZAS(drive(home,restaurant), tl + 1) 1 IYOLDS(loc(me,home) , to, tl + 1) A ifOLDS(loc(car,home),to,tl + 1)) = 1. By Theorem 11 and (31) and (32), P,,,,,(IYOLDS(loc(me,home), to, tl + 1) A IYOLDS(loc(car,home), to, tl + 1)) 2 0.95. By the definition of c-prob and Theorem 10 applied to (40) and (41)) P,,,,( IXAS( drive( home,restaurant), tl + 1) ) > 0.95. By FOL5 and the field axioms applied to (42) and (25), (38) (39) (40) (41) (42) P,,,,,,,( FEAS( drive( home,restaurant) , tl + 1) I AZT( start( car), tl ) ) 2 0.95. (43) 292 P: Haddawy/Artijicial Intelligence 80 (1996) 243-308 Calculation of (34) By the definition of c-prob and axiom ACTl, term (34) may be rewritten as P,,,,(3tc, t; (tG < t1 + 30) A OCCURS(get(table), tG, td) A OCC( drive( home,restaurant) , tl + 1, tl + 11) A OCC( start( car), tl , tl + I ) 1 ATT(drive(home,restaurant), tl + 1) A ATT( start( car), tl ) ) = p,,,,v( 3tG, t; (tG < t] + 30) A OCCURS(get(table), tG, td) ) OCC(drive(home,restaurant), tt + 1, tl + 11) A OCC( start( car), tl , tl + 1) ) I’,,,,,“( OCC( drive( home,restaurant) , tl + 1, tl + 11) A UCC(start(car), tl, tl + 1) / AT;r( drive( home,restaurant), tl + 1) A ATT(start(car), tl)). (44) (45) Since (tl + 11 < tc < tl f26) inequality for term (44). --) (tG < tl+30), by Theorem 10 we have the following P,,,,,+(gtG, r; (to 6 tl + 30) A OCCURS(get(table), tG, t&) 1 OCC(drive(home,restaurant), tl + I, tl + II) A OCC(start(car),tl,tl + 1)) 2 P,,,,(%, t; (tt i- 11 6 to 6 tl -I- 26) A OCCURS(get(table), tG, td) 1 OCC(drive(home,restaurant), tl + 1, tl + 11) A OCC(start(car),tl,tl + 1)). By assumption (26) and axiom FOL.5, we have ~tow(~tG, t; (tt + 11 6 to 6 tl + 26) A OCCURS(get(table), tG, td) 1 OCC( drive( home,restaurant) , t] + 1, tl + 11) A OCC(start(car), tl, tl + 1)) > ~l,,,v(%, td (tl + 11 6 k 6 tl + 26) A OCCURS(get(table), tc, t;) 1 OCC( drive( home,restaurant) , t 1 + 1, t 1 + 11) ) . By the definition of c-prob, term (45) may be written as (46) (47) (48) I’,,,,,,,(OCC( drive( home,restaurant), tl + 1, tl + 1 1) 1 ATT(drive(home,restaurant), tI + 1) A OCC(start(car), tl, tl + 1)) (49) . ~~,,,“(OCC(start(car), tl, ti + 1) I AZ? start(car) , tl > A A7T( drive( home,restaurant) , tl + 1) ) . (50) P. Haddawy/Artifcial Intelligence 80 (1996) 243-308 293 By assumption (27) and axiom FOL5, we have the following inequality for term (50). P,,,,(OCC(start(car), tl, TV + 1) I AIT( start( car), tl ) A AIT( drive( home,restaurant) , tl + 1) ) > P,,,,,(OCC(start(car), TV, TV + I > 1 AIT(start(car), tt )) (51) So we have the following inequality for term (34). P,,,,,,(qtc, t; (tc 6 tt + 30) A OCCURS(get(table), tc, td) A OCC(drive(home,restaurant), tl + 1, tl + 11) A OCC(start(car), t1, t1 + 1) 1 ATT(drive(home,restaurant),tt + 1) AAi’T(start(car),tl)) > flld3tG, th (tl + 11 < to Q ti + 26) A OCCURS(get(table), tG, td) 1 OCC(drive(home,restaurant), tl + 1, tl + 11)) P,,,,( OCC( drive( home,restaurant) , tl + 1, tl + 11) I AZT( drive( home,restaurant), tl + 1) A OCC(start(car), tl, tl + 1) + P,I,,,(OCC(start(car), tl, tl + 1) I ATT(start(car), tl)). (52) (53) (54) Now we derive numerical bound for the terms for term (52). By axiom FOL5 and (22), bounds (52), (53), (54). First we derive a I’,,,,,,,( 3t, t’ (tt + 11 < t 6 tI + 26) A OCCURS(get(table), t, t’) I OCC(drive(home,restaurant), tl + 1, tt + 11) A dt,,,t; (t; < tl + 11 < t; +60) A OCCURS(performance, t,, ti,)) 2 0.8. (55) By Theorem 10 and (33), P,,,,,,( 13, t’ (t’ < tl + 11 < t’ + 60) A OCCURS(performance, t, t’)) = 1. (56) So by the a,ssumption rence, the dafinition of c-prob, and (55) and (56), that ramification conditions are independent of the action occur- P,low(3, t’ (tl + 11 < t < tl + 26) A OCCURS(get(table), t, t’) I OCC(drive(home,restaurant), tl + 1, tl + 11)) 2 0.8. (57) Next we derive a value for term (53). By axiom FOL5 and (23), P,,,, ( OCC( drive( home,restaurant) , tl + 1, t 1 + 11) I ATT( drive( home,restaurant) , tI + 1) A OCC(start(car),tl,tl + 1)) = 1. (58) 294 R Huddawy/Art@cial Intelligence 80 (I 996) 243-308 Finally we derive a bound for term (54). By axiom FOL5 and (20)) p,,,,,(OCC(start(car), TV, TV + 1) I ATT( start( car), tl ) A HOLDS( (temp > 32)) tl , tl + 1) ) 3 0.95. By Theorem 15 and (29), P,,,,,(HOLDS((temp > 32),tt,tt + 1)) 2 0.8. (59) (60) So by the assumption the definition of c-prob, and (59) and (60)) that executability conditions are independent of the action attempt, P,ro~v(OCC(start(car), 21, TV + I> I ATT(start(car), tt )) > (0.8) (0.95) = 0.76. (61) From (56), (57), and (61) we obtain a lower bound on the probability of term (34) Of 0.8. I . 0.76 = 0.60. (62) Finally, combining the probability values from (39), (43), and (62) we obtain the lower bound on the chance that the plan achieves the goal: p,,,,,,,( Ito, t; (to 6 tt + 30) A OCCURS( get(table), to, t;, A OCC( drive( home,restaurant), tl + 1, tl + 11) A OCC(start(car),tt,tt + 1) 1 ATT( drive( home,restaurant) , tl + 1) A ATT( start( car), t] ) ) . Pnoly( FEAS(drive(home,restaurant), tl + 1) 1 ATT( start(car), rl ) ) . P,,,,( FEAS(start(car), tt )) > 0.60. 0.95 ’ 0.95 = 0.54. (63) 6.3. The quali$cation, frame, and ramijcation problems address exceptions Probabilistic representations to the qualification that my car [42]. For example, we can reason about the chance summarize will start given the car from that I turn the key, even though many events may prevent starting. We simply say that the probability my car will start given that I turn the key is, the fact that low likelihood events, say, 0.98. This probability like a potato the car from starting. We can also say that the being stuck in my tailpipe, can prevent that I turn the key and that a potato is stuck in that my car will start given probability problem by allowing one summarizes F! Haddawy/Art$cial Intelligence 80 (1996) 243-308 295 appropriate to our the tailpipe state of knowledge would The reader will notice is zero, without contradiction. The conditional probability then be used at inference the persistence of facts by formulating time. that in the previous planning example we have avoided reason- in such a way the planning problem ing about just when they are needed The current work does not that actions bring about conditions propose solutions In fact, the problems are magnified by the fact that actions and events may occur concurrently. So frame axioms would need to be predicated on the lack of occurrence of actions or events which could to say that the color of my car does not change over negate a condition. For example, an interval during which to either the frame or ramification problems. it is not painted, we might write v’to, t19 t29 x Pn,nv(3t3 HOLDS( color( car,x) , t2, t3) 1 HOLDS(color(car, x>,to, tl) A -4XC( paint( car), tl , t2) ) = 1. Several [ 121 present an approach the problem of projecting researchers have addressed is modeled with conditional framework. Dean and Kanazawa time that a proposition P is true at time t conditioned and plans in a probabilistic projection using a Bayesian network model. I5 The tendency of propositions true over probability true at the previous or false occurred a node time points. Projection Bayesian networks. the effects of actions to to remain the on whether or not P was to make P true is created which contains and event of interest at every one of a set of discrete for time point and whether or not an event known in the interim. A Bayesian network model is performed using one of the standard for each proposition inference algorithms probability statements indicate that Hanks to change in terms of probabilities [28] presents an approach to reasoning about projection is modeled with causal rules that describe state as a result of an event and with persistence in which knowledge are true at various that propositions at every time point as in Dean and Kanazawa’s approach. the tendency of that rules state over an interval during which no to occur. The projector answers queries of the form “is of the worl’d is represented time points, but not necessarily The dynamics of the world a proposition describe causally the probability distinguished to the query and by making only relevant distinctions when projecting in time. In contrast, Dean and Kanazawa’s proposition is particularly relevant effects forward of every by its efficiency, which it gains by searching only for past evidence that 4 will hold at time t greater than 7 ?” The algorithm the chance relevant event is known approach computes that a proposition at every point the probability in time. changes More recent work in this area has discussed appropriate ways to structure Bayesian networks reason about projection in order [ 8,9]. to obtain a compact representation that is sufficiently expressive to Is The framework is also described by Dean and Wellman I 131. 296 P. Huddawy/Artijicial Intelligence 80 (1996) 243-308 7. Related work 7.1. Theories of objective chance Three outstanding than Lewis’ model which subjective [ 571, Lewis [ 391, and Skyrms constrained in van Fraassen’s model, chance has more Skyrms’ models. Since van Fraassen’s a temporal chance theories of objective chance are those of van Fraassen is more [ 521. Van Fraassen’s model of objective chance than Skyrms’ model. Thus, than in either Lewis’ or theory is the only one of the three that is cast in for the mode1 of objective it was used as the point of departure is more constrained inherent properties framework, in f&. Van Fraassen presents a semantic theory jective chance, using a future-branching mode1 of time points. Van Fraassen places constraints on objective chance: that models subjective probability and ob- two ( 1) The chance of a past is either 0 or 1, depending on whether or not it actually occurred. (2) Chance at a time is completely determined by the history of the world up to that time. From these assumptions, and objective chance he shows the following relation between subjective probability Pt(X I Y) = EY[G(X)l9 where P, is the subjective probability is the expected value given Y, and provided up to t. This relation entails a version of Miller’s principle chance. A similar and objective times, but van Fraassen does not demonstrate chance can change with time but, in contrast He does not provide a logical at time t, C, is the objective chance at time t, Ey the truth of Y depends only on the history relating subjective probability relation holds between objective chances at different this. In van Fraassen’s models, objective to the present work, truth values cannot. for his theory. language 7.2. Temporal probability logics literature contains The focus of these logics several examples of logics [ 27,29,38]. programs and distributed between different that can rep- is on reasoning systems. The logics do not attempt to model types of temporal objects such as facts and The theory of computing resent both time and probability about probabilistic causality or to distinguish events; hence, Kanazawa quantification P operator for representing language cannot represent does not allow nesting of probability operators. Like f&,, L,, contains numeric for representing the tendency of facts differs they are not suitable [ 311 presents a logic, C,,, of time and probability. The language allows otherwise. The language contains a over time points but is propositional indexed so the the language functions focus is on representing of facts and events true tends time, his representation that once the change of probability over time. Furthermore, through a fact as “something for reasoning about actions and plans. distributions. Because Kanazawa’s probability. The P operator from ours. He describes is not temporally it becomes probability to persist P: Haddawy/Art@cial Intelligence 80 (1996) 243-308 297 to stay true for some place instantaneously types of events: persistence persistence are facts that stay true for only an instant. L,, represents actions as events. time”. Facts are associated with temporal and are associated with a single time point. He distinguishes events are associated with a fact becoming take three true; false; point events events are associated with a fact becoming intervals. Events termination causation Like the models for .f&, Kanazawa’s models contain a collection of world-histories. He does not impose a branching P operator are defined tokens and event in terms of probability tokens are equated with (temporal time structure on the histories. The semantics of the Fact over world-histories. distributions interval, world) pairs. Dean and Wellman [ 131 present a propositional logic similar to [50] propositional operator. The probability freely with other logical operators. The probability operator Kanazawa’s. They extend Shoham’s a probability combined indexed. A model contains of a universe of time points, a set of possible binary The models differ from those for C,, by not imposing a branching lines nor other constraints on the elements of the models. time lines, a relation over time points, and a discrete probability measure over the time lines. structure on the time operator cannot be nested but can otherwise be logic by introducing is not temporally temporal probability temporal 7.3. Tempo)ral logics of actions and plans time Shoham the notion logic is defined and action. Knowledge [51] presents a branching the fact that actions cannot that actions can only be performed under certain conditions. the relation between that formalizes in the standard way for modal logic to make choices among sets of world-histories. The logic does not capture [ 43,441 develops a future-branching involving time, knowledge, and actions are defined as the ability model formalizes Shoham’s Pelavin problems linear temporal respectively. and IFTRIED, that associates INEV the attempt of an action with the truth of a sentence. The semantics of the operator are based on Stalnaker’s the temporal action cannot affect the state of the world at any time preceding about planning [ l] it with two modal operators, ZNEV logic of time intervals and extends to reason about relation of action and effect-an its attempt. actions and external events. He starts with Allen’s is exactly our 0 operator. theories of counterfactuals. time and action effects, time logic for reasoning IFTRIED captures is a counterfactual future-branching and Lewis’ concurrent IFTRZED the past. influence operator Pelavin instances represents instances”. A plan actions and plans uniformly as “plan instances and a set of event is attempted and is an ordered pair: a set of basic action about by the basic actions. An action it occurs and plan instance action instance instances of the same plan to occur in a world-history, Pelavin cre,ates these different names by allowing plan instance e.g. pi@Z . This is to be interpreted as saying during instance instances, brought instances occur all occur. Since a if its basic action is a single ordered pair and the times associated with the event and basic a plan two they must have different names. to be associated with a that plan instance pi occurs for the @ operator interval 1. But he does not provide a semantic definition are fixed and all terms than once in the language in a world-history. are rigid designators, cannot occur more if its basic action If we want an interval its event to allow instances instances 298 I? Haddawy/Artijicial Intelligence 80 (1996) 243-308 to formalize occurrences plan occur. the intuitive of the same plan he has no way of saying interpretation. Furthermore, by using different names for two that two instances of the same is used In Pelavin’s in this paper Conditional chance to represent effects. Since chance can be the effects of a wide variety of different logic, IFTRIED only associates effects with action attempts, so conditioned on any sentence, C,,, can represent phenomena. effects of genera1 events cannot be represented. The use of conditional the need for a separate counterfactual measure over worlds. Furthermore, appealing Such an assumption the basic action and moving, chance eliminates the similarity of actions has a more intuitively that actions are always feasible. since it is hard to imagine what it would mean for still like concurrently semantics. Unlike Pelavin, we do not assume operator and its semantic counterpart: instances of two inconsistent our representation is unacceptable remaining actions, counterfactual inferences. Consider in Pelavin’s in some undesirable from home logic by nesting for going results stay at home all day, then if I were to attempt in walking I would succeed represented the executability the sentence to go to the store at noon are incompatible. to be true in the intended attempting feasible, and hence going one was staying home all day. interpretation condition is true in his logic. But attempting to go the store at noon are incompatible, from home operator to represent action effects to the sentence “If I were to attempt to walk from home to the store at noon, to the store at noon.” This sentence can be is two IFTRZED operators. to the store, Pelavin points out that to stay home all day and attempting for this sentence to stay home all day and so their conjunction would not be that So it seems unreasonable If being at home to the store would have zero chance of occurring given I6 In C,,, attempting . to all occur. Pelavin’s use of a Stalnaker/Lewis an elegant probabilistic chance [52, Chapter Skyrms provides notion of objective probability conditionals ditionals can lead to more intuitive als. [52, Appendix 31. He shows that the iterated probability account of counterfactuals IIA] and discusses based on the the semantics of iterated con- condition- inferences than iterated Stalnaker/Lewis 7.4. Decision-theoretic planners A number of researchers have recently been working on the problem of building into two main schools. sytems. This work can be classified and to apply that planning from classical AI planning framework. The second school assumes to take techniques as Markov processes and attempts to formulate efficient and decision-theoretic planning The first school attempts them within a decision-theoretic problems flexible algorithms Kushmerick are describable for solving them. et al. [ 35,361 present bilistic version of the SNLP planning distribution a probability over propositions the BURIDAN algorithm. They characterize planner, which is roughly a proba- the world in terms of from one in terms of transitions and actions I6 One might think that the sentence should be correct because going to the store is clipping staying at home, but the same problem arises if the temporal order of the actions is reversed. t? Haddawy/Artifcial Intelligence 80 (1996) 243-308 299 distribution a probability the algorithm to another. The BURIDAN planner generates a plan that achieves a goal with threshold. Draper et al. [ 151 have extended actions. no less than a user-specified to handle gathering and contingent information Haddawy and Suwandi (DRIPS). ‘The DRIPS planner probability utility function. well as metric DRIPS reasons of plans. Haddawy planner. [ 251 present a decision-theoretic refinement planning finds optimal plans for problems described system in terms of a DRIPS can reason about both discrete and continuous function over world states, a probabilistic model of actions, and a temporal as hierarchy. classes the time. Action descriptions efficiently to prune away suboptimal the theory of abstraction into an abstraction [23] describe are organized the hierarchy and Doan attributes, by using used by system [ 61,621 eliminates classes of suboptimal only to reasoning Wellman’s SUDO-PLANNER those classes of plans which about tradeoffs. Planning knowledge plans in domains characterized by partially satisfiable goals and actions with uncertain effects. it can prove are dominated without It eliminates in the form of resorting to actions. The qualitative probabilistic and dominance planner works by cycling between network proving. h/lode1 construction involves using from a more general knowledge base for the domain. Dominance proving knowledge: about the effects of actions and the relative desirability of outcomes to derive facts abou: from observations the processes of model construction networks. Plans are functions a qualitative probabilistic is represented constructing involves Drummond [ 161 present an algorithm in stochastic the dynamics of the domain as a discrete Markov for generating plans represent temporal domains. They process, where actions and exogenous events are characterized by transition probabilities. Goals are temporally single path that satisfies outcomes, probability by elaborating a this path the system explores only likely those of low probability. This produces a plan with a lower bound can be increased sentences. The algorithm works by first projecting the plan with additional paths that satisfy ignoring of achieving the goal. The probability the goal. In generating of goal satisfaction qualified the preferred plan. and Bresina algorithm by reward sound probabilistic Dean et al. [ II] build upon the work of Drummond basic plamling algorithm with theoretically a planning of a finite set of states; actions are represented by transition probabilities goals are represented specify what action for a simplified world model. It then iteratively expands the optimal policy improve a:s a function of computation time after the initial policy paper, Dean et al. [IO] discuss decision-theoretic methods to policy generation their foundations. They present in which the world is modeled as a stochastic automaton consisting between states; that in each state. The algorithm starts by generating a policy the world model and generates for each expanded model. The expected values of generated plans at any the best policy so far. In a second time for allocating processor functions over the states; and plans are policies time and the algorithm can be consulted and world model expansion in time-critical domains. is generated to perform to obtain Boutilier and Dearden [ 141 investigate planning as Markov decision processes. They search depth and using a heuristic executed a.s the plan is being constructed. function in time-critical trade optimality to estimate represented for inference speed by limiting the values of states. Actions are In a second paper [4] they present a method domains the goal. and Bresina by providing 300 R Haddawy/Artijicial Intelligence 80 (I 996) 243-308 the state space of a Markov decision process for abstracting optimal policies can be constructed. They prove bounds on the loss of optimality due to the use of the abstraction. so that approximately Cassandra et al. [ 61 show how to formulate a planning problem information has incomplete Markov decision process. They present an algorithm empirically more efficient than existing algorithms. about the state of the environment in which the agent as a partially observable for solving these problems that is Thiebaux et al. [56] represent planning problems using probabilistic logic and use to construct Markov models of plans from this representation. They the models to determine the expected value of each plan. exhaustive then evaluate search 8. Conclusion 8.1. Contributions a framework for representing planning problems that inte- approaches. By drawing on the strength of previous work This paper has presented grates logical and probabilistic in both areas, we have been able to create a novel synthesis of the traditional planning paradigm under each approach. The contributions made by this work fall into three main areas: planning problems, properties, and the extension of the probabilistic may not be feasible. of a vocabulary theory that captures desired for describing intuitive that the development the development to accommodate that addresses of a semantic framework limitations actions 8.1.1. Vocabulary it can influence influence involving capability feasibility, that influence its executability the extent is an important in the world can and cannot be influenced. time and in the and effects. We can for describing planning problems the chance of temporally qualified conditions executability, since a planner must be able to which the extent and temporal aspects of plans such as concurrent We have provided a vocabulary chance. The language can express world as well as the chance of action to which conditions represent This conditions represent action actions and events. This distinction control over than over events. The language its actions action attempts and action occurrences. This distinction as a function action feasibility, first-order quantification produces a language with great representational over domain points we can describe points. No other currently existing chance, and action. to reason about what it can them. We can actions and conditions during an between since an agent has much more direct between to vary the notion of the importance of which will be discussed below. The language allows individuals. This individuals we can describe classes of actions and by quantifying over time that are valid at each of some range of time these aspects of time, further distinguishes allows action duration and effects. The language distinguishes economy. For example, by quantifying time points, probabilities, it allows us to define language can represent in the world and states-of-affairs of conditions and domain is important logical over l The property (Theorem probability. l The property P Haddawy/Artifcial Intelligence 80 (1996) 243-308 301 8.1.2. Semantic theory the logic on the model logic is desirable We have specified a set of constraints theory that assigns meaning to language. A constrained for several reasons. First, the more the logical the model theory, the greater the predictive power of the logic. In the extreme constrained thus giving us complete to allow only one model, case, we could constrain knowledge. But we do not want to overconstrain the logic so that we eliminate models that are consistent with our conception of reality in the intended domains of applicability. Second, constraints provide guidance important would inferences, The constraints we have imposed on the models capture numerous properties of time and chance from constraints. as possible yet does not produce unwarranted intuitive follow directly of the in such a way that natural the following properties to sentences. This is an task. So one inferences are a consequence like: a logic that is as constrained the semantics. For example, in assigning probabilities the assigning of priors is a notoriously function difficult since that facts have higher chance of holding over their subintervals, 1.5)) is a consequence of semantic constraint (C3) and the definition of that the past cannot be influenced (axioms IT3-IT6 (Cl ) and (C2) on the accessibility relation to facts and events, and constraints and Theorems 17- relation, constraint (C6) 23) follows from constraints (C5) and (C7) on probability. relating the accessibility l Miller’s principle constraints have lthe property (C6) and (C7). Furthermore, (axiom P3), which relates chance over time is a consequence of as a consequence of Miller’s principle we (Theorem 12). (axiom IPI ) follows from semantic is the expected value of future chance implies certainty l The property constraints that chance that inevitability (C6) and (C7). 8.1.3. Feasibility The integration of both chance and possibility in f&, allowed us to define the notion of the chance of feasibility of an action or plan. This concept was then used to define the chance is important action descriptions actions. Since actions may involving multiple in such a way that their composition may not be feasible, we must be able to interfere reason about the effects of possibly to attempt an action will achieve a given goal. This definition about plans because that trying in reasoning it enables us to compose infeasible plans. into descriptions individual of plans Appendix A. Soundness proofs We prove the soundness of the more intersting in section 4. The first few proofs we present axioms presented less formally. Il. !J,q5 ---f qb. and less commonly known of the in detail. The remaining proofs are 302 l? Haddawy/ArtijiciuI Intelligence X0 (1996) 243-308 Proof. We prove this sentence valid by showing M, world w, and assignment function g[d/t] that it is satisfied by an arbitrary model . By the semantic definitions, [ln’q$ -+ q5]“‘w’R’d”’ = true [I_ (?, 41 ~~~~~t4’l = true or iff [[@I M+3,Rl’U’l = true. The first disjunct is true iff for some w’ such that R(d, w, w’) [$]““V”a’rl”’ = false. If this is not the case then 4 is true in all worlds w’ such that R(d, w, w’). And since by (C2) R(d, w, w), that q5 is true in w. 0 it follows 12. q (4 + ‘b> 4 CM --+ O/Q). Proof. By the semantic definitions, [0,(4 --+ #) -+ (0’4 -+ (cid:144)t~)nM,w,gldl’l = true iff [I7 0, (4 4 fi)n”+pfitd”l = true or [[Or4 --+ (cid:144)’~n”~W.gtd”t = true. By the semantic definitions, this is true iff [O,$ ; ;$~~~V’fd”’ = false or ’ ‘(’ [0,4] uaen M,vxId/'l = true = true or If the first disjunct world 4 is false or $ is true. If 4 is false in some world, the second disjunct and we’re done. Otherwise, Cc, must be true in every world, disjunct is not the case then in every world we have -4 V fi. So in every is satisfied in which case the third is satisfied. 0 Proof. By the semantic definitions, [O,f$ ;kCII;; uw ~‘~’ +nM+‘,@“l = true iff = false or [Cl, Cl, ,,q”,w,gtd”l = true. is not the case then q5 is true in all worlds w’ such that R(d, w, w’). If the first disjunct Now for all w” such U41 M.w,g[rl/tl uu 0, +n M~w~Rldlrl = true iff u+nMw4[4'I = true that R(d, w’, w”) and R(d, w, w’). But by (C2) this is true iff = true for all w’ such that R(d, w, w’). Cl 14. O,+ + 0, 0, 6 Proof. By the semantic definitions and the definition of possibility, I? Huddawy/Artijicial Intelligence 80 (I 996) 243-308 303 [O,f$ + Cl, Ot e!~]~‘~“‘~“’ = true iff M,w,,Vl d/r1 [l&41 = true or [IO, Ot +]MYw*R’d’r’ = true. If the first disjunct is not the case then 4 is true in some world w” such that R(d, w, w’). Now [O, 0, c#‘~“~‘~” = true iff for every world w’ such that R(d, w, w’) there exists a world w” such that R(d, w, w”) and [dJJ”‘w’R’d’t’ = true. But by (C2) R(d, w, w”) and R(d, w, w’) implies R(d, w’, w”). So w” is the required world w”. q NEC. Rule of necessitation: from e!~ infer q ,+. Proof. DWJI M,w4 = true iff I[d] M, w’, g[ d/t] = true for all w’ such that R(d, w, w’). By definition, M, w,g. Cl if 4 is valid then [e5]“+‘” =true for all P3. Miller’s principle: (ti 3 12) + P,, (4 1 Pt,(qb) 2 a) 2 a. Proof. We first prove an expected value property principle. Let t and t’ be two time points of worlds at time t’. Let the variable r range over these equivalence a partition of IV, so the probability partition: and then use it to prove Miller’s classes the R-equivalence classes. The r form of a set X can be written as the integral over this t < t’ and consider pu)“(x, = .I rcw $(X I y>pUp (dr). the history up to time t’ determines the probability at time t’, this can be written Since as /_&Y‘(X) = s rcw /-4(X),4 (dr) 9 where & denotes at a given probability the probability at time t’ in equivalence class Y. Since the probability time is assumed at a given time is the expected value of the probability to be constant over all worlds in an R-equivalence at any future class, the time: ,uu:‘(X) = ,u;‘(X)pr (dw’). J W Next we show that Miller’s principle is valid in the probability models. By the expected value property, pu:“(Xrl {w’ : p;‘(x) = a}) = J ,uf’(Xn W {w’ : /L;‘(X) = a})& (dw”). 304 P. Huddawy/Artificial Intelligence 80 (1996) 243-308 Fig. A. I. Model for the proof that inevitability persists. Now, by semantic constraints (C6) and (C7) it follows that Vww{w’:&X)=cw}, &({w’:&X)=cr})=l Vw@{w’: &Y’(X) = cu}, /!q({w’ : p?‘(X) = cx}) =o. So we can restrict the integral to the set {w’ : p;‘(X) = a}: = &“(xn {d : &‘(X) = LY}),u; (dw”). s {H.‘:/_$‘(X)=a} And by the above property again ,I& ( X rl {w’ : ~7’ (X) = a}) = a, so =a. s /_L; (dw”), {w’:p;,‘(X)=n} =cY.pcL:y({w’:/&X) =a},. By the semantic definitions it follows that P,(q5 A P,,(4) = a) = a-Pr(P,J(d) = a). And by a slight generalization of the proof it follows that V(tit’) P,(dAP,f(d) 3a) ba.Pt(Pt,(4) >a). 13 TLl. Facts hold over their subintervals. (fl 5 12 5 ts 5 t4) A (fl $t3) A (t2 $t4) --+ [HOLDS(FA,tl,t4) -+ HOLDS(FA,t2,t3)]. Proof. This follows directly from constraint (C3). 0 ITl. Inevitability persists. (rl 5 t2) + co,,+ + &$I. P Haddawy/Ar@cial Intelligence 80 (1996) 243-308 305 Proof. The model described in the proof is shown in Fig. A.l. [[a,, ((b)II Md,~~dIl~I,d2/f21 = true iff for all u.’ such that R(dt, w, w’) M,lr’,RIdlltl,d2/rzI = true n44 Now suppose Then by (Cl), R( dl , w, w”). This is a contradiction. that for some w” such that R(&, w, w”), ~~~“~~“.B’di’t’.d2’t2’ = false. So for all w” such that R(d2, w, w”), ~~~“‘W”‘p’d”r”d2’t2’ = true. 0 IT3. Past facts are inevitable. (to 5 [I 5 t2) + [&HOLDS(Q,to,t,) VO,,+OLDS(Q,to,tl)] Proof. [Ot~H’OfDS( Q, to, tl ) V q tz-JfOLDS( Q, to, tt )I]“~w~~‘dn’ro~d~‘r~~d~‘rz’ [HOL~S( Q, to, t, )nM,w’,RIdo/to,dl/tl.d2/tzl = true = true iff for all w’ sluch that R(d2, w, w’) or JIHOLDS( Q, to, t, )nM.~‘,~ldolto,dl/tI,dz/rzl = false for all w’ such that R(d2, w, w’). This is the case iff ((do,dl), w’) E F(Q) for all w’ such that R(dz,w, w’) or ((do,dl), w’) $s’ F’(Q) for all w’ such that R(d2, w, w’). This last statment follows directly from ((3). 0 IPl. Inevitability implies certainty: 0, (4) --+ Pt (4) = 1. Proof. We prove this sentence valid by showing M, world VV, and assignment function g[d/t] that it is satisfied by an arbitrary model . By the semantic definitions, [Elt( q5) -+ Pt(+) = lj”,w,Rldlfl = true uotwn M,w,ddlrl =true or p,(4) = I~~wWl =true. iff The first disjunct holds if for some w’ such that R(d, w, w’) [4n”‘w”“d’r’= false. is not the case If this R; c {w’ : ~~nM,w.sIdlrl = true}. But by Meta-Theorem [+]“‘w”“d”‘= then true for all w’ such that R(d, w, w’). So 2, ,uz(Rz) = 1. So ,u~<{w’ : = true}) = 1. And from the semantic definitions it follows that u+n M.W'&I dltl [P,(4) = ln”++,gldltl = true. 0 306 I? Hudduwy/Arrijiciul Intelligence 80 (I 996) 243-308 Fig. A.2. Model for the proof that current chance is inevitable. IP2. Current chance is inevitable: O,P,(q5) > cy -+ q ,P,($) > (Y. Proof. The model described in the proof is shown in Fig. A.2. [O,P,( q5) > #,w,x’d’r’ = true iff UP!< 4) 3 ojj”‘w’g’d’f’ = true for some w’ such true}) > that R(d,w,w'). This is the case iff ,$‘({w” (Y for some w’ such that R(d, w, w'). Choose an arbitrary w” such : [q%]“*w”*pid’r’ = that R(d,w,w"). By (C2), R(d,w',wO). Hence by (C6), p$(({w” true}) 3 cy. Cl : ~c$~“~~“~~‘~“’ = Acknowledgements This paper is a greatly truncated and slightly revised version of my Ph.D. dissertation, in August 1991 at the University of Illinois. The dissertation [ 221. In that work the logic is developed and presented also appears as in the full context completed a monograph of decision I would theory. to like thank my thesis advisor Alan Frisch reading the subtleties of decision me his time and ideas and for carefully for guiding me through Maher through my proofs. Any remaining reading other members of my dissertation Marianne Winslett anonymous reviewer for their many helpful comments for comments on an earlier draft. for generously sharing with through many drafts. I thank Patrick theory and for painstakingly errors are my responsibility. Thanks committee: Caroline Hayes, George Monahan, and discussions. Thanks to the and to an This work was partially supported by the author’s Shell doctoral dissertation of Illinois) and by NSF grant RI-9207262 (University ship (University Milwaukee). References fellow- of Wisconsin- [ I 1 J.F. Allen, Towards a general theory of action and time, Arri~T Infell. 23 (2) ( 1984) 123-154. 12 ( J.F. Allen and J.A. Koomen, Planning using a temporal world model, in: Proceedings IJCAI-83, Karlsrnhe, Germany (1983) 741-747. 13 ( E Bacchus, Represenfing and Reasoning with Probubilisfic Knowledge (MIT Press, Cambridge, MA, 1990). 14 I C. Boutilier and R. Dearden, Using abstractions for decision-theoretic planning with time constraints, in: Proceedings AAAI-94, Seattle, WA ( 1994) 1016-1022. P Haddawy/Art$cial Intelligence 80 (1996) 243-308 307 I S I R. Carnap, Logical Foundations of Probability 16 I A.R. Cassandra, L.P. Kaelbling (University of Chicago Press, Chicago, IL, 19.50). and M.L. Littman, Acting optimally in partially observable stochastic domains, in: Proceedings AAAI-94, Seattle, WA ( 1994) 1023-1028. 17 I D. Chapmlan, Planning I 8 1 A. Darwic he and M. Goldszmidt, Action networks: a framework for conjunctive goals, Artif: Intell. 32 (3) in: Proceedings Tenth Conference on Uncertainty ( 1987) 333-377. for reasoning about actions and change Seattle, Intelligence, in Artijcial under uncertainty, WA (1994) 136-144. [ 9 I R. Davidssan and M.R. Fehling, A structured, probabilistic representation of action, in: Proceedings Tenth Conferem e on Uncertuinty in Artificial Intelligence, Seattle, WA ( 1994) 154- I6 I, I 101 T.L. Dean, L.P. Kaelbling, sequential decision making, Washington, DC ( 1993) 309-3 16. _I. Kirman in: Proceedings Ninth Conference on Uncertainty and A. Nicholson, Deliberation scheduling for time-critical in Arti’cial Intelligence. I I I I T.L. Dean, L.P. Kaelbling, J. Kirman and A. Nicholson, Planning with deadlines in stochastic domains, in: Proce~*din,qs AAAI-93, Washington, DC ( 1993) 574-579. I 12 I T.L. Dean and K. Kanazawa, A model for reasoning about persistence and causation, Comput. Intell. 5 (3) (1989) 142-150. I I3 I T.L. Dean and M.P. Wellman, Planning and Control I I4 I R. Deal-den and C. Boutilier, Integrating planning and execution (Morgan Kaufmann, San Mateo, CA, I99 I ). in stochastic domains, in: Proceedings Terlth Confkrence on Uncertainty in Art@cial Intelligence, Seattle, WA ( 1994) 162- 169. ( IS 1 D. Draper, S. Hanks and D.S. Weld, Probabilistic planning with information gathering and contingent in: Proceedings Second International Conference on Arti$cial Intelligence Planning Systems, execution. Chicago, 1 161 M. Drummond satisfaction, IL (1994) 31-36. and J. Bresina, Anytime synthetic projection: maximizing the probability of goal in: Proceedings AAAI-90, Boston, MA (1990) 138-144. I I7 I R. Fagin, J.Y. Halpem and N. Megiddo, A logic for reasoning about probabilities, Tech. Rept. RJ 6190 (60900). IBM Almaden Research Center ( 1988). I I8 I R.E. Fikes and N.J. Nilsson, STRIPS: a new approach to the application of theorem proving to problem solving, Al-# fntell. 2 ( 1971) 189-208. I I9 I A.I. Goldman, A Theory of Human Action I20 I A.R. Haas, Possible events, actual events, and robots, Comput. 12 I I F’. Haddawy, Representing plans under uncertainty: (Prentice Hall, Englewood Cliffs, NJ, 1970). Intell. 1 ( 1985) 59-70. a logic of time, chance, and action, Ph.D. Thesis, Report No. UIUCDCS-R-91-17 19, University of Illinois, Urbana, I 22 I P. Haddawy, Representing Plans under Uncertainty: A Logic of ‘lime, Chance, und Action, Lecture Notes IL ( 199 1). Intelligence 770 ( Springer-Verlag, Berlin, 1994). and A.H. Doan, Abstracting probabilistic actions, Seattle, WA ( 1994) 270-277; in: Proceedings Tenth Conjkrence on available via anonymous FTP from logics of higher-order probability, in Artificial Intelligence in: R.D. Shachter T.S. Levitt, 4 (Elsevier Science Publishers, in Artifici,ll [ 23 I P. Haddawy Uncertainty pub/tecbleports I24 I P. Haddawy in Artificial Intelligence, at ftp.cs.uwm.edu. and A.M. Frisch, Modal J.F. Lemmer and L.N. Kanal, eds., Uncertainty Amsterdaln, I25 I P. Haddawy 1990) 133- 148. and M. Suwandi, Decision-theoretic Proceedings Second anonymous FfP International from pub/techreports in: Conference on Al Planning Systems ( 1994) 266-27 I : available via refinement planning using abstraction, inheritance at f tp . cs . mm. edu. logics of probability, Arf$ I26 I J.Y. Halpcm, An analysis of first-order [ 27 I J.Y. Halpcrn and M.R. Tuttle, Knowledge, probability, Intell. 46 ( 1991) 31 l-350. and adversaries, in: Proceedings Eighth Annual ACM Symposium on Principles of Distributed Computing ( 1989) 103-I 18. I28 I S. Hanks and D. McDermott, Modeling a dynamic and uncertain world I: symbolic and probabilistic reasoning about change, Artif: I29 I S. Hart and M. Shair, Probabilistic Intelf. 66 ( I ) ( 1994) logics temporal l-55. for finite and bounded models, in: Proceedings Sixteenth ACM Symposium on the Theory of Computing, Washington, DC ( 1984) 1- 13. I30 I G.E. Hughes and M.J. Cresswell, An Introduction I 3 I I K. Kanaz,awa, A logic and time nets for probabilistic to Modal Logic inference, (1991) 360-365. [ 32 I J. Keynes, A Treatise on Probability (MacMillan, London, 1921). (Methuen, London, 1968). in: Proceedings AAAI-91, Anaheim, CA 308 I? Haddawy/Art@cial Intelligence 80 (1996) 243-308 I 33 I A. Kolmogorov, Foundations of the Theory of Probability (Chelsea, New York, 1950). 1% 1 s. Kripke, Semantical considerations on modal logic, Acta fhilos. Fenn. 16 ( 1963) 83-94 (Proceedings of a Colloquium on Modal and Many-Valued Logics, Helsinki, Finland, 1962). I35 I N. Kushmerick, S. Hanks and D.S. Weld, An algorithm for probabilistic planning, Art$ Intell. 76 ( 1995) 239-286. I36 I N. Kushmerick, S. Hanks and D.S. Weld, An algorithm for probabilistic Proceedings of the Twelfth National Conference on Artificial Intelligence, least-commitment Seattle ( 1994) planning, IO73- 1078. in: I 37 I H. Kyburg Jr and H. Smokier, eds., Studies I38 I D. Lehmann and S. Shelah, Reasoning with time and chance, I39 I D. Lewis, A subjectivist’s to objective chance, guide Inform. Control 53 ( 1982) 165-198. in: W. Harper, R. Stalnaker and G. Pearce, eds., in Subjective Probability (Wiley, New York, 1964). &y (Reidel, Dordrecht, Netherlands, 1980) 267-298. I40 I D.V. McDermott, A temporal logic for reasoning about processes and plans, Cognitive Sci. 6 ( 1982) 101-155. 141 I D.H. Mellor, Fixed past, unfixed future, in: B.M. Taylor, ed., Michael Dummett (Martinus Nijhoff, Dordrecht, Netherlands, 1987) 166-186. I42 I J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference (Morgan Kaufmann, San Mateo, CA, 1988). I43 I R.N. Pelavin, A formal logic for planning with concurrent University of Rochester, Department of Computer Science, Rochester, NY ( 1988). actions and external events, Ph.D. Thesis, 1441 R.N. Pelavin, Planning with simultaneous actions and external (Morgan Kaufmann, San Mateo, CA, 1991) Chapter 3, 128-211. events, in: Reasoning about Plans 1451 R.N. Pelavin and J.F. Allen, A formal logic of plans in temporally rich domains, Proc. the EEE 74 (IO) (1986) 1364-1382. 1461 F.P. Ramsey, Truth and probability, Highlands, NJ, 1926) Chapter 3, 58-100 in: D.H. Mellor, ed., Foundations (Collection published 1978). (Humanities Press, Atlantic I47 I E.D. Sacerdoti, A structure I 48 1 L.J. Savage, The Foundations of Statistics I49 I J.R. Shoenfield, Mathematical ISOl Y. Shoham, Reasoning about Change 15 1 1 Y. Shoham, Time for action: on the relationship between Lqic (Addison-Wesley, Reading, MA, 1967). (MIT Press, Cambridge, MA, 1987). for plans and behavior, Technical Note 109, SRI, Menlo Park, CA ( 1975). (Wiley, New York, 1954, 2nd rev. ed., 1972). time, knowledge, and action, in: Proceedings IJCAI-89, Detroit, MI ( 1989) 954-959. IS2 I B. Skyrms, Causal Necessity I S3 I B. Skyrms, Higher order degrees of belief, in: D.H. Mellor, ed., Prospects for Pragmatism (Yale University Press, New Haven, CT, 1980). (Cambridge University Press, Cambridge, 1980) Chapter 6, 109-137. [ 54 I I? Suppes, A Probabilistic Theory of Causality, Acta Philosophica Fennica, Fast. XXIV (North-Holland, Amsterdam, 1970). [ 55 I G.J. Sussman, A Computer Model of Skill Acquisition IS6 I S. Thiebaux, J. Hertzberg, W. Shoaff and M. Schneider, A stochastic model of actions and plans for (American Elsevier, New York, 1975). anytime planning under uncertainty, Internat. J. fntelligent Systems ( 1994). I 57 I B.C. van Fraassen, A temporal framework for conditionals and chance, in: W. Harper, R. Stalnaker and G. Pearce, eds., & (Reidel, Dordrecht, Netherlands, 1980) 323-340. I 58 ) J. Venn, The Logic of Chance (MacMillan, London, 1866); new paperback edition: Chelsea, New York, 1962. IS9 I R. von Mises, Probability, I60 I D. von Winterfeldt and W. Edwards, Decision Analysis and Behavioral Research (Cambridge University Statistics and Truth (Allen and Unwin, London, 1957). Press, Cambridge, 1986). I 6 I I M.P Wellman, Formulation of Tradeoflk I62 I M.P. Wellman, Qualitative probabilistic Pearl, eds., Readings 71 l-722. in Uncerfain Reasoning in Planning Under networks (Incertainty for planning under uncertainty, in: G. Shafer and J. (Morgan Kaufmann, San Mateo, CA, 1990) Chapter 9, (Pitman, London, 1990). I63 I A.N. Whitehead and B.A.W. Russell, Principia Mathematics (Cambridge University Press, Cambridge, 1910). 