Artificial Intelligence 97 (1997) 83-136 Artificial Intelligence Speeding up inferences using relevance reasoning: a formalism and algorithms Alon Y. Levy a,*, Richard E. Fikes b~l, Yehoshua Sagiv cV2 B AT&T Bell Laboratories, 180 Park Ave., Room A283, Florham Park, NJ 07932, USA b KSL, Stanford University, Stanford, CA 94305, USA c Department of Computer Science, Hebrew University, Jerusalem, Israel Received September 1995; revised May 1996 Abstract reasoning Irrelevance to a specific query. Aside from its importance refers to the process in which a system reasons about which parts of in its knowledge are relevant (or irrelevant) speeding up inferences from large knowledge bases, relevance reasoning is crucial in advanced applications such as modeling complex physical devices and information gathering in distributed heterogeneous systems. This article presents a novel framework for studying the various kinds of irrelevance that arise in inference and efficient algorithms for relevance reasoning. We present a proof-theoretic framework for analyzing definitions of irrelevance. The framework makes the necessary distinctions between different notions of irrelevance that are important when using them for speeding up inferences. We describe the query-tree algorithm which is a sound, complete and efficient algorithm for automatically deriving certain kinds of irrelevance claims for Horn-rule knowledge bases and several extensions. Finally, we describe experimental results that show that significant speedups (often orders of magnitude) are obtained by employing the query-tree in inference. @ 1997 Elsevier Science B.V. Keywords: Relevance representation reasoning; Meta-level reasoning; Static analysis; Horn rules; Constraints; Knowledge author. Email: * Corresponding ’ Email: fikes@cs.stanford.edu. 2 Email: sagiv@cs.huji.ac.il. levy@research.att.com. 0004-3702/97/$17.00 PII SOOO4-3702( @ 1997 Elsevier Science B.V. All rights reserved. 97)00049-O base formance of inference knowledge irrelevant - Irrelevant engine query. Consequently, information: 84 A.L Levy et al./ArtiJicial Intelligence 97 (1997) 83-136 1. Introduction Many the inability future applications large amounts of knowledge. it is essential or task. In fact, is a major obstacle process (or base or by exploiting is a specific knowledge about in the knowledge Irrelevance the domain. irrelevant) in which the system explicit form of meta-level of Artificial In order for a system to perform efficiently Intelligence (AI) will be in domains having in such a domain to any given query is relevant that it be able to determine which knowledge of current AI systems to ignore irrelevant information in scaling up such systems. Irrelevance reasoning reasons about which parts of its knowledge to a specific query, either by automatically inspecting refers to the are relevant the knowledge reasoning irrelevance-claims given by a user. Irrelevance reasoning base, as opposed reasoning [ 37,45,54], to using in which we reason about the the knowledge base to reason is important in several contexts: a Speeding up inferences in large knowledge bases: It is well known that the per- in AI systems degrades quickly as the size of the to are due increases. Two of the major sources of inefficiency engines facts in the knowledge base: In its search for a solution, in the knowledge considers many facts base the inference it spends significant - Irrelevant distinctions in the representation: A knowledge a variety of tasks. Therefore, accommodate must be detailed enough relations, objects, etc.). As a result, the representation for any given for all those task, thereby to inefficient tasks (i.e., leading reasoning. that are irrelevant to the effort pursuing useless solution paths. to is designed of the domain refined is likely to be too complex its conceptualization it must include many base l Modeling complex physical devices: Tasks such as diagnosis, design and simulation require a model of a given physical device a model depends heavily on the task for which with the most detailed model of the system would be intractable. Therefore, important (e.g.,[ 2,32,46] system are relevant the adequacy of directly it is create a model that is suited for a given query that we determine which aspects of the ), and doing so requires to a given query. to be able to automatically it is used, and reasoning [ 11,221. However, l Large scale distributed information systems: Current communications to many enables accessing the Internet) easy access this information (e.g., At the moment, body of work in AI has the goal of designing sources of information high thereby 3 1,33,38,5 1,60,65,90]. is the ability a given query posed by a user. to automatically and providing determine which A key issue that needs technology remote sources of information. can be mostly by browsing. A growing for integrating multiple them, [4, to be addressed by these systems to architectures level querying sources are relevant facilities over information sources freeing a user from the need to know about specific information Irrelevance reasoning also plays an important 711, belief revision using applications relevance reasoning of relevance [ 351 and learning (e.g., to speed up inferences role in nonmonotonic [ 7,36, [ 30,66,74] > . The focus of this paper is on in large knowledge bases. The other reasoning reasoning are discussed briefly in Section 6. A.Y Levy et al. /Art$cial Intelligence 97 (1997) 83-136 8.5 In order for relevance reasoning to be a viable method for controlling inference, issues need that are irrelevant detecting parts of a knowledge base to be addressed. First, we must develop eficient for to a query. The to these algorithms may vary; it could consist of certain parts (e.g., the rules) of on facts in the knowledge base) and, possibly, some irrelevance claims supplied irrelevant knowledge reasoning two questions, we need a formal several automatically input the knowledge base, some meta-claims the ground by the user. Second, we must and the tradeoff between meta-level about understanding about relevance and base-level these of the possible meanings of irrelevance reasoning for addressing the domain. As a basis about other parts (e.g., the utility of removing integrity constraints investigate algorithms claims. in research in many contexts The notion of irrelevance has appeared in AI and related fields. However, most of the time researchers use the term informally. Formal analyses of [ 47 J >, 1950 irrelevance have been discussed by philosophers [ 161) and 1978 (Gardenfors (Catnap thrust of these analyses was notions of irrelevance by a formal definition. Most to try to capture our common-sense of the work focuses on formulating and finding properties of the notion of irrelevance the work has not been concerned that satisfy definitions with how to use irrelevance detecting for speeding up inference or how to design algorithms those properties. Consequently, as early as 1921 (Keynes [ 341). The main irrelevance. for Within AI, the notion of irrelevance was investigated [53], [21,23,70] and used there to control reasoning In the context of logical knowledge bases, Subramanian several meyer of automatically irrelevance left largely open, and consequently effective way. investigated deriving inference claims and the utility of irrelevance relevance reasoning formal definitions of irrelevance. However, in the context of probabilistic in Bayesian belief networks. [ 881, and more recently Lake- the issues reasoning were in any has not been applied This article presents a framework studied. We present efficient algorithms and we describe the results of experiments In particular, we make the following contributions. in which various definitions of irrelevance irrelevance for automatically that validate the utility of relevance deriving can be claims, reasoning. deriving framework distinctions for analyzing the necessary l We present the definitions of irrelevance, a proof-theoretic between irrelevance claims vary as we move in the space. The framework encompasses definitions for the notion. We describe how properties of yielding a space of possible definitions irrelevance and sheds new light on previous definitions of irrelevance. We show that the framework makes the problem of automatically irrelevant facts. l We consider the problem of automatically knowledge bases and several extensions, tree, for that purpose. We identify and show that the query-tree provides a sound and complete irrelevance for such claims. Strong strongly often especially useful irrelevance claims for Horn-rule and present a novel tool, called the query- claims inference procedure that removing (and it in practice. First, irrelevance claims are derived by inspecting only facts is guaranteed not to slow down an inference engine the important class of strong-irrelevance claims and the utility of removing The query-tree has two properties claims also have the property it up significantly). to address that make irrelevant to speed deriving needed 86 A. E Levy et al. /Artijicial Intelligence 97 (1997) 83-136 irrelevance the semantics of interpreted predicates appearing in deriving facts). Second, a small part of the knowledge base (e.g., inspecting and not the ground considers (e.g., order predicates, key role in many applications, query-tree programs it provides predicates. l We describe but is distinguished sort predicates, completeness experimental that show this is an important the rules in the knowledge base claims, the query-tree in the knowledge base interpreted predicates play a feature of the query-tree. The logic from previous work in that area in that can also be viewed as a tool for partial evaluation of constraint [ 15,67,85], in the presence of recursive rules and interpreted etc.). Since speedups also results that significant (often or- in inference. The it is used to determine which facts are ir- to a query. Based on that determination, we create specialized database to a class of facts that are (possibly) that see only for the given class, we can then use these the query-tree relevant indices inference, facts during thereby significantly the ground from are obtained by employing is used in two ways. First, is based on the observation and database ders of magnitude) query-tree relevant indices queries. Given a query fetching ground The second use of the query-tree which sequences of rule applications to the query. Therefore, we use the query-tree follow only such sequences. The experiments query-tree ligible compared size of the knowledge should be noted that thogonal rule and subgoal ordering bined with tabulation) validation presented here does not follow from experiments methods. to the savings achieved. Furthermore, that develop optimal strategies achieved by employing the KB (to create and preprocessing and methods base grows, the savings to methods the search indicating [ 42,841) to prune speeding up inference. that it tells us exactly can yield solutions lookups engine the specialized to guide our inference show that the cost of building to the is neg- indices) the savings grow as the that our methods will scale up. It are or- the space (e.g., (com- the experimental that use run-time bindings the query-tree for searching [ 8,9,93]. Therefore, validating these other Organization of the paper is organized deriving The paper the space of definitions as follows. Section 2 describes and compares properties of various definitions. Section 3 considers of irrelevance the prob- the query-tree lem of automatically algorithm. Section 5 describes how the query-tree can be used to speed up inferences and results. Section 6 briefly describes other applications of our framework, the experimental such as automatic in- formation remarks. related work, and Section 8 contains concluding claims, and Section 4 describes systems. Section 7 discusses database query optimization creation of abstractions, and global irrelevance 2. Analyzing irrelevance In this section, we consider what it means for a fact to be irrelevant to a query. We begin by introducing the terminology used throughout the paper. A.YS Levy et al./Art$cial Intelligence 97 (1997) 83-136 87 2. I. Preliminaries In our discussion, we assume that the theory of the domain is represented by a formulas formulas, that the inference mechanism in first-order predicate calculus. tuples of variables inference letters for variables and bars to employs a letters for predicate names, upper-case (e.g. x) . We assume knowledge base A of facts which are closed We use lower-case denote set of sound of closed (pi E A, cri is a logical axiom, or LYE is the result of applying an inference elements subgoals of ai. The set of formulas base of the derivation, set” for $ connected rules. A derivation D of a closed formula Cc, from A is a sequence LYI , . . . , a,, such that (Y, = #, and for each i ( 1 < i < n), either rule to some to (pi. The formulas ai,, . . . , air are said to be the represents a “support in which every oi is denoted by Base( 0). The set Base(D) base. We consider only derivations in the knowledge to J/J through in D that do not have any subgoals , . . . , ai, that appear prior the subgoal is called relation. ~yj, A query is represented by a formula I,/J( J?), where _? is the tuple of free variables formula free variables, the query $(R) and, hence, _% is the empty just as #. When q(R) tuple), omit 8 and denote (i.e., has no free variables is true if there is a derivation of e(R) is the is false. from the free in A, such that the resulting closed formulas are to a set of $; we sometimes a closed answer When +( ri’) contains variables derivable for each answer. The query + may have several derivations containing one derivation base, and we denote the set of those derivations by D@ (A) from a given knowledge is a set of sets of derivations, where each (when then @(A) for each answer of #). By a slight abuse of set D E D@ (d) contains one derivation notation, we sometimes denote De (A) simply as @. into the constants mentioned from A; 3 in this case, the phrase “a derivation of the query” from A; otherwise, is the set of assignments rl, has free variables, the answer the answer refers 2.2. De$ning irrelevance Our goal is to express, claims of the form “@ is irrelevant A”. To do so, it is essential the subject of the irrelevance fact or set of facts. Other refinements Broadly, we can of predicates take derive claims, irrelevance reason with and automatically i.e., to the query + with respect to the knowledge base that we give such claims a formal definition. 4b is called the case in which @ is a claim. In this paper, we consider and in [ 561. irrelevance. The first is to In that it [ 16,34,47]), notion of irrelevance with a formal definition. of irrelevance such as objects, in Section 6 and in more detail irrelevance subjects, are discussed briefly two possible and check whether relation arguments to analyzing approaches (e.g., approach, which has been pursued by several philosophers try to capture our common-sense approach, we would consider a formal definition definitions ’ Alternative return unknown just the firsf variable binding Note that since is finite. query are also possible. For example, if neither 4 nor -w$ is derivable; in the case of a closed-formula query, one might in the case of a query with free variables, one might return these distinctions do not affect our discussion. that satisfies the query. However, the number of possible assignments for the free variables is finite, the set of answers to a 88 A.E Levy et al. /ArtQicial Intelligence 97 (I 997) 83-136 for our intuitive notion of irrelevance. In that we consider natural satisfies properties this article, we pursue a second approach arises in problem (and specifically solving interested inference methods irrelevance changes, and the utility of removing these properties. that utilize claims can be automatically in properties of definitions of irrelevance that are informative irrelevance. For example, we are interested that focuses on analyzing in inference). how irrelevance In this approach, we are most in designing in whether the KB derived, how the claims change when irrelevant facts. The following example illustrates Example 1. Consider courses the following knowledge they can serve as teaching assistants. in which base do, describing students and the Yi : attendClass( x, Y) =+ pass( x, Y). r2 : passExam ( X, Y) =+ pass( X, Y) . t-3 : pass( X, Y) A tookGrudCourse( X) + canTA (X, Y) . r4 : pass(X, Y) A (Y 2 300) =+ tookGrudCourse(X). gl : attendCluss(Fred, 101). g:! : passExam(Fred, 101). g3 : passExam (Fred, 20 1) . g4 : passExam ( Fred, 30 1) . Suppose we want teaching assistant, to find all the lOO-level classes i.e., the query is q(Y) = cunTA( Fred, Y) A (Y < 200). in which Fred is qualified to be a For the given ground facts, the only answer for each one, the answer is Y = 101 and, so, we to the query q(Y) shall use q to denote the query canTA (Fred, 101) . The query q can be derived either by using gt, g4 and the rules r-1, r3 and r4, or by using gz, g4 and the rules r2, r-3 and r4. Hence, each of the ground atoms gi , g2 and gs is irrelevant alone, because there are differences between derivation 200 < Y < 300, can be added to or retracted to the query. As for gi and g2, even though of them, both. To summarize, of an answer still be derived without to the query when considered it. However, claims. Specifically, gs is not used in any facts of the form passExam( Fred, Y), where the answers from the KB without changing the query can be derived without either one remove they are not part of any derivation to the query, while some other facts are irrelevant because all answers can it cannot be derived without both of them and, therefore, we cannot to the query can be derived without some facts are irrelevant because of the query. More generally, these irrelevance those facts. to the query, because is not part of any derivation of an answer There are, however, other variants of relevance and irrelevance. For one, even though to q, we the ground atom canTA( Fred, 301) it is always entailed by the facts and it relevant may still consider rules used in any derivation of q. To see another the query canTA (Fred, 30 1) . The atom passExum( Fred, 302) can be part of a derivation of an (if it were in the KB), but such a derivation would not be minimal, answer (i.e., in the sense since g4 must be used, along with the rules r2, r3 and r4, there is no need to use any other ground the atom passExum( Fred, 302) may be deemed irrelevant. that the set of ground atoms that it uses from the KB is not minimal fact from the KB) . Hence, type of irrelevance, to this query consider A.Y Levy et al/Artificial Intelligence 97 (1997) 83-136 89 Finally, rules may also be irrelevant. For example, if we add the rule passExam(X,Y) A (Y 2 300) =+ canTA(X,Y), irrelevant, inference mechanisms, it would be considered for some ference, used. since 0 fewer rule applications may be needed since answers can be derived without it. However, it may be the case that this rule will speed up in- if this rule is to derive answers Clearly, the two approaches we described it in our framework will provide a way of using notion of the concept, and the definitions we examine mirror the analysis of irrelevance of each other. On the one hand, by our common-sense various ways. On the other hand, given a formalization irrelevance, up inference. However, intended captures to be evaluated on its usefulness intuitive notions of irrelevance. As illustrated by the above example, it should be emphasized analyzing to analyzing that we consider irrelevance are not independent is inspired it in notion of it for speeding is that the approach we have for speeding up inference, not on how well it of the common-sense taken there is no single best definition of irrelevance. to $ if there is some derivation and the properties of various definitions within this space. Our space is based on a For example, we can define a formula 4 to be irrelevant of q that does not contain 4, or alternatively, we can require contains 4. Therefore, we describe a space of possible definitions of irrelevance, investigate proof-theoretic a can participate meta-theoretic in the KB, not the possible derivations of the query. Consequently, we are able to make finer distinctions framework. A more detailed comparison with Subramanian’s work appears analysis of irrelevance, in derivations account of irrelevance. Her framework considers only the formulas i.e., on investigating of the query. In contrast, Subramanian than those made in Subramanian’s the ways in which formulas [88] described in Section 7. that no derivation of 1+5 2.3. A space of dejinitions In this section, we assume that the given query $ is a closed formula. Extending the definitions of this section to a query with free variables is straightforward. Definitions in the space vary along derivation ways of defining derivation D of the query predicate DZ( 4, D). The following irrelevance, (CI. Derivation two axes. In the first axis, we consider different to a single a binary of a subject 4 is given by defining irrelevance irrelevance i.e., are a few examples of how DZ can be defined: l DZl(+, D) l DI2(4,D) l DIx(+, D) l DI4(4,D) if 4 $ Base(D). if d, # D. if Base(D) if Base(D) #r,b. #C#I and&se(D) v-4 Definition DI, requires DI2 is stronger and requires and requires requires definitions that 4 not be in the support set of the derivation D. Definition in D. Definition DZ3 is even stronger that e5 not be anywhere that 4 not be a logical consequence of the formulas that -r$ not be a logical consequence of DZ can, therefore, be summarized either. The relationship as follows: in Buse( D) , and DZ4 these between 90 A.E Levy et al./Art@cial Intelligence 97 (1997) 83-136 Proposition 2. D&(4, D) + D&(4, D) * D&(4, D) * D11(4, D). Requiring that DI(qS, D) holds for all possible derivations of the query may be too restrictive. Therefore, of the query for which we require DZ( r$, D) all possible derivations of $ from A, we consider a subset @(A) of D@(A) to hold. Formally, given the set V*(A) of (which in the second axis, we consider different subsets of the derivations and require DZ( qb, D) may be D$ (A) itself), For example, we can require DZ(qS,, D) for a derivation). As of $ (in Section 3, we consider another example, we can consider only the set of derivations bounded by some resource constraint. in Dt (A). to hold only for the set of minimal derivations several definitions of minimality to hold only for derivations Given a choice for DI and Vi (A), we give two definitions of irrelevance, depending on whether DI is required to hold for all derivations in @(A) or for some derivation in 27: (A). 4 Formally, a definition of irrelevance in our space is given as follows: Definition 3. Suppose we are given: ( 1) A knowledge base A (i.e., a set of formulas). (2) A closed (3) A closed-formula (4) A predicate DZ( T, D) specifying when a formula 7 is irrelevant formula 4 (the subject of irrelevance). $ (the query). to a derivation D of the query. (5) A subset Dt (A) of the set D@(A) (of all possible derivations of (/I from A). By a slight abuse of notation, we usually denote 27$(A) as 2&(A) or simply as DO. to A, DI The formula C#J is said to be weakly to the query Cc, with respect irrelevant and DO, denoted by WZ( I#J, $, A, DI, VO), if DZ( C#J, D) holds for some D E Do(A). The formula I$ is said to be strongly irrelevant to the query # with respect to A, DI and DO, denoted by SI( 4, @, A, DI, DO), if DZ(qb, D) holds for every D E D,-J( A). If De (A) and strongly is empty irrelevant (i.e., $ is not derivable to $. from A), the formula 4 is both weakly In our discussion, we want to refer to irrelevance of a set of formulas. Formally, we by extending of a set of formulas the definition irrelevance of DI: define Definition 4. 4i E @. If C#J is a set of formulas, DZ(@, D) holds if DZ(4i, D) holds for every The definitions of strong and weak claims It will also be remain unchanged. that hold for a set of knowledge bases. For example, to state irrelevance useful in the context of Horn-rule knowledge bases, we may want to know whether a rule is (but may irrelevant with respect to all the knowledge bases that have the same rules irrelevance 4 We can also consider other ways of quantifying over the set ‘D$ (A), such as requiring that DI( 4, D) holds over I$( A) could be in D$ (A). In fact, different ways of quantifying a third axis in the space. Here, we consider only universal and existential quantification. for some percent of the derivations considered A. E Levy et al. /Artificial Intelligence 97 (1997) 83-136 91 Set of derivations to consider Minimal derivations support Minimal derivations (no loops) All derivations Not used in any derivation DI1 DI, DI, D14 Not used derivation in some of the query. Derivation-irrelevance: w.r.t. a single derivation, DI. Irrelevance I. A space of definitions Fig. irrelevance. The second irrelevance differ of irrelevance. The first axis consists of different definitions of derivation and strong considered. Weak irrelevance axis consists of the set of derivations in the way we quantify 01; over the derivations chosen in the second axis. have different ground atoms). We extend follows: the definitions to sets of knowledge bases as Definition to Cc, with respect with respect that Da is a function The definition 5. Let 2 be a set of knowledge bases. We say that 4 is weakly to 2, denoted by WZ( 4, $, 2, DI, DO), if 4 is weakly irrelevant to (/I irrelevant to every KB in 2; i.e., if WZ(4,@, A,Dl,Vo) holds for every A E .Z (note that given a KB A E 2 returns a subset of the derivations D* (A) ) . for strong irrelevance is extended likewise. The space of definitions is summarized lOl), see different kinds of irrelevance q = canTA(Fred, g2 instead). Consequently, WZ( gl , q, do, 012, P(A) The atom gs is strongly Consequently, SZ(gs, q, do, DI2, P(A)) irrelevant since there is a derivation of q that does not use gt (i.e., claims. The atom gr is weakly in Fig. 1. Going back to Example 1, we can to the query it uses for the atom g2. of q uses it. ) holds. Similarly irrelevant to q, because none of the derivations holds. is strongly if we consider derivation to q if we consider derivation irrelevance based on DI3, to q, since the formulas used to derive q can also irrelevant The atom q1 = cunTA(F’red, 301) irrelevance based on DI2. However, the atom q1 is not strongly be used to derive 41. Finally, suppose irrelevant that q1 is the query. If we consider the atom passExam( Fred, 302) would not be strongly in the KB), since it can be used in a derivation of q1 (to derive tookGradCourse( Fred) ) . there is However, the set of all derivations of 91, then to the query (had it been irrelevant if we consider only derivations in which Buse( D) is minimal (i.e., 92 A. L Levy et al. /Artificial intelligence 97 (I 997) 83-136 that is enough to derive the query), then passExam( Fred, 302) no subset of Buse( 0) would not be part of any derivation of q1 and, therefore, would be strongly irrelevant to the query 41. 2.4. Properties of definitions in the space When investigating irrelevance claims, several potential properties are of interest; the actual properties, however, vary quite a bit as we move from one definition in the space to another. One key property is whether irrelevance claims can be derived automatically. Sections 3 and 4 discuss this property in the context of several definitions of irrelevance. Below we summarize and explain the significance of some other properties of irrelevance claims that are of practical interest in speeding up inference. The proofs are given in Appendix A. Theorem 6. Properties AO-A8 (listed below) hold, given the following notation. l $ denotes a query. a 4, ~$1, and 42 denote formulas. a @, @I, and @2 denote sets of formulas. l A denotes a knowledge base. l 2, 21, and .X2 denote sets of knowledge bases. l Vo, D,, and 272 denote functions that given a KB A and a query JI return a subset of D+(A). l DI, DI', and DI” denote definitions of derivation irrelevance. l Dll , 012, DI3, and D14 are the definitions of derivation irrelevance from the beginning of Section 2.3. AO. If WI(4, $, A, DI1, I?@ (A) ) holds, then the formula 4 can be removed from A without changing the answer to @. That is, if C$ E A and A - C$ denotes the set of formulas in A except for q5, then Al. If DI’(@, D) + DI”(@, D) for all derivations D E TJJ, then SI(@, i,k, 2, DIr,Vo) + SIC@,@, 2, DI”,Do) WI(@, i,k, 2, DI’,Do) =+ WI(@,+, 2, DI”, ‘Do) A2. If Dl (A) c 272 (A) for all knowledge bases A E 2, then SIC@,t,kZDI,D2!) =+ SI(@,@,ZDI,DI) WI(@,t,kZDI,Ih) =+ W@,t+kZ,DI,~2) A3. The following is always true. SI(@,$_,ZDI,Vo) =+ WI(@,qhZDI,Vo) A.E Levy er al./Art$cial Inrelligence 97 (1997) 83-136 93 SI(@,J,~Z~,DI,~~O) WI(@,$,Z2,DI,Do) * * SI(@,$,&,DI,Vo) W@,qk&,DI,Do) AS. If the inference rules are complete, 41 z 42, and DI is either Dt, or 014, then W~~,$~~,DI,~O~ * W42,@,ZDI,‘Dol SIC~I,#,ZDI,‘DO~ * W42~~9ZDI,~o~ A6. If the inference rules are complete, then WI~~,ccI,ZD~~,~o~ * wI(-&$,&Db,vo) sI(~,$,~:,Db,‘Do) =+ W+,9,.XDb,~o> A7. If DI(@l, D) A DI(&, D) 3 DI(@l u 02, D) for all derivations D E VO, then SI~Qi~,~cI,ZDI,~o~ ~WQi2,~,~,DI,‘Do~ * SIC@1 U@2,1cI,ZDI,Do) SI(@I,~,ZDI,DO> ~W@2,~,ZDI,~o~ =+ W@I U@2,~,k&DI,~oj AS. If A k r and A is consistent, then SIWP,V~A,DI~,~~(A)) @ SI(~,~,AU7,DI2,V~(A)) Property A0 guarantees that we can remove an irrelevant fact without changing the answer claims to the query. Properties Al-A4 is affected as a result of changing show how the relative strength of irrelevance some of the parameters of these claims. In general, irrelevance claims for a common-sense appropriate when analyzing subject, query, or knowledge considered natural not necessarily inferences. Property A5 identifies under equivalence. claims are closed under negation. Property A6 is similar base. Although preservation in our space are not preserved under equivalence of the has been that it is for the purpose of speeding up some cases in which irrelevance claims are preserved irrelevance notion of irrelevance irrelevance that it shows when under equivalence [ 341, we believe in the sense to determine whether Property A7 shows when irrelevance claims can be added up. This property it can use all the irrelevance is impor- it tant when a system needs claims has or whether using certain ones will falsify others. The same property does not hold for weak irrelevance. to the knowledge base may cause relevant or vice versa. In particular, weak irrel- a formula that was irrelevant of evance claims can change even when the knowledge base. In contrast, as property A8 shows, strong irrelevance claims do not change when we reason with existing knowledge. For weak irrelevance from right to left in A8 does not hold. the added formulas are logical consequences In general, adding new formulas the implication to become Utility of removing irrelevant facts For any of the definitions in our space, an irrelevant fact can be removed knowledge base without affecting the answer to the query (property AO). However, from the the 94 A.K Levy et al./Art@cial Intelligence 97 (1997) 83-136 an irrelevant utility of removing only weakly systems framework, would be considered weakly a subject of ongoing irrelevant may not speed up inference. the opposite; [69] do exactly research (e.g., [ 28,30,44,68] savings are guaranteed ). fact is a more subtle issue. Removing a fact that is that is, they add redundant In fact, explanation based learning in our irrelevant). The utility of adding such rules is rules (which, irrelevance, For strong for many cases. For example, claim SZ( @, @, d, DZ2, D* ) holds (i.e., all derivations of the query are considered), deriving + from d - @ costs no more than deriving such if we consider if the then it from A. This property also holds is always a set of derivations D$ (A), that the inference engine base is in doing database facts at the outset signifi- guaranteed sections, we will show the facts significant savings that are strongly to find one of the derivations in Z$ (A) before that in some situations it is possible it finds others. In subsequent to efficiently determine such facts yields irrelevant to a query and in practice. These savings come from several sources: facts prunes branches of the search space. that removing l Removing irrelevant l Much of the cost of reasoning in a large knowledge lookups. Removing cantly l If updates reduces a large number of irrelevant ground the cost of each lookup operation. that involve only irrelevant facts are made to the KB, then the answer to a query need not be recomputed. 2.5. Encompassing previous defhitions in our space An important contribution of irrelevance comparisons previously discussed them. We mention among of our space of definitions is that it encompasses definitions in the literature and, therefore, enables us to make several of these comparisons below. Subramanian investigates several definitions of irrelevance. are instances of weak irrelevance. The main definition In our framework, all these in [88] investigated definitions is the following: Definition 7. Let 4 be a fact, @ be a query, and A be a knowledge base. The fact 4 is said to be irrelevant if there exists a subset Al of A such that Al # C#J and Al b t,b. to I$, denoted by WI1 (4, +, A), This definition can be couched in our framework as follows: Observation 8. For a complete set of inference rules S, Proof. Suppose WZl(q5, I+%, A) holds. Therefore, Al k ti, Al # 4, and there is some derivation D of @ from Al. Clearly, Base(D) and, consequently, WZ( q5, @, A, DZ3, De) holds. there is some subset Al of A such that # 4 Conversely, assume that WZ( qb, $, A, DZ3, ‘D* ) holds. Consequently, there derivation D of 9 from A such that Base(D) subset of A and does not entail 4. Consequently, WI, (4, qb, A) holds. # q5. The KB consisting of Base(D) 0 is some is a A.Y Levy et al./Artij?cial Intelligence 97 (1997) 83-136 95 A variation of this definition, which is described space as WZ( 4, $, A, DI4, D@ ). Couching Subramanian’s shows how other definitions initions. irrelevant ity and adding-up hold (property A7). In particular, our space facts leads to speeding up inferences in the space overcome irrelevance identifies in [87], can be formulated definitions some of the limitations in our in our framework of her def- that removing and for which some forms of monotonic- definitions such An important contribution of our framework is that it sheds light on the problem of In [63], we show that [ 10,261. is independent of an update as the problem of detecting weak of a query detecting when a query the problem of independence formulated cally, detecting WZ( ~5, +, A, DZ1, @) on this problem based on detecting this relationship dence, based on algorithms details). 5 revealed strong has led to the development for determining that the algorithms proposed irrelevance, which irrelevance ) . However, a close from a deletion update can be equivalently (specifi- of previous work independence were in our framework inspection for detecting is a more restricted condition. of novel algorithms strong and weak irrelevance for detecting Identifying indepen- (see [63] for A definition of irrelevance is equivalent is described by Srivastava and Ramakrishnan to strong irrelevance when DZ2 is used for derivation in [ 861. Their irrelevance is applied to the set of all derivations definition and equivalent Sagiv the set of all minimal derivations of the query. resolution in [ 611 can be couched to SZ( 4,1,4, A, DZ2, @). strategies Finally, several of the query; is discussed by Levy and in our framework as SI( 4, $, A, DI2, ‘D,,), where Dn, is The notion of irrelevance that is, their definition example, when using refutation to be strongly shown irrelevant removed. Tautologies irrelevant can be shown 27” ) and, therefore, are removed by the tautology elimination resolution, (with to be weakly respect are based on removing clauses containing clauses. For irrelevant can be pure to DZl and V$) and, therefore, can be (with respect to DZl and strategy literals6 [ 391. 3. Automatically deriving irrelevance claims A key question that we address in this article is how (and under what conditions) Specifically, we are interested claims can be derived automatically. irrelevance problems. First, given a knowledge base, a query, and a specific definition of irrelevance, we want query. Second, given an irrelevance that logically pertaining to the claims the first problem. Later, we show how results facts in the knowledge base are irrelevant irrelevance to the first problem can be used to solve the second. claim, we want to derive other to find automatically which follow. We focus on solving in two We examine edge bases the question of automatically that consist of a set of Horn deriving rules P and a set of ground atomic irrelevance claims for Horn knowl- facts 5 As shown in Section A.2, there is a close connection between weak irrelevance and the problem of query containment. Using updates, also a complete characterization this relationship we obtain, in addition of independence to the characterization of insertion updates. of independence of deletion 6 A literal is pure if and only if it has no instance that is complementary to an instance of another literal in the knowledge base [ 391. 96 A.K Levy et al./Artijicial Intelligence 97 (1997) 83-136 G. We distinguish EDB predicates) those that appear pear in the consequents predicates P are safe, tecedent. two sets of predicates and derived predicates in the ground in the KB: base predicates (IDB predicates). facts of G. The derived predicates of the rules. For syntactic convenience, we assume are those The base predicates (often called are that ap- that base in appears also in the an- the rules that do not appear in i.e., any variable the consequents that appears of rules. We assume in the consequent Determining that a fact is irrelevant (or all) possible derivations of some particular, may be more expensive goal of relevance consider small and stable) portion of the knowledge base. the problem of deriving than answering irrelevance reasoning. In order for our algorithms to a query requires of the query. This is usually that we establish properties and, in impractical the query; hence, it defeats the original interest, we to be of practical claims by examining only a (preferably In many applications the rules of the KB. Therefore, we address problem the irrelevance facts. Specifically, we address involving Horn-rule knowledge bases, the bulk of the KB consists the ground facts are much more prone to frequent changes for a set of of ground facts and, moreover, than the following knowledge bases that differ only on ground question. Let P be a set of rules, and let & be the set of knowledge bases of the form P U G, where G is a set of ground atomic facts for the base predicates. The subjects of irrelevance we consider are either a rule in the knowledge base or a set of atomic facts, and the query 1+4 will be an atom, possibly with free variables. Note that ground queries can be expressed by simply conjunctive to the knowledge base. adding The question we address to the set of knowledge bases 2~. to a query Cc, with respect is whether 4 is irrelevant queries and disjunctions and the corresponding the appropriate of conjunctive predicates rules between that distinguishing rules and ground It should be emphasized some base predicates may have small and stable extensions one way to distinguish example, one may want derived predicates may appear decide not to include treated as base predicates). The results and algorithms we describe straightforwardly facts is only between known and unknown parts of a knowledge base. For therefore, some rules and, so, one may those predicates would be in this article extend in every KB of _Zp. Alternatively, those rules in the KBs of 2p of numerous (instead, in the consequents those extensions to such cases. to include and, 3.1. Interpreted predicates A final key point about our analysis rules in a knowledge base can be deduced by considering is the treatment of interpreted predicates. Many the (=, # , that appear in them, such as order predicates in Example 1, g3 was deemed strongly the semantics can be viewed as part of the ground in our analysis entails their semantics claims base of the form P U G such that G is a set of ground irrelevant of the interpreted facts in the knowledge base. However, that that we derive facts of the predicate <. The extensions irrelevance between of the interactions semantics of interpreted predicates <, <) or sort predicates. For instance, by considering predicates enforcing hold for any knowledge that satisfies the semantics of the interpreted predicates. A.Z Levy et al./Arr@cial Intelligence 97 (1997) 83-136 91 even is a sort predicate whose extension c in the language L, with free variables XI,. a subset of the base predicates is a formula literals of constraint formula that involves (i.e., A, V, 7). For example only Formally, we distinguish constraints if the predicate as constraint predicates. A constraint expressing cal connectives is a constraint 100) even numbers. A formula also be viewed is the set of all the unary denotes note the variables ventions. The standard Xl,. c(F), where P = Y,,... IsiGn. as describing tuples that Xi corresponds relation to which a constraint , Y, will denote containing satisfying . . ,X, (note a (possibly infinite) the constraints all the even formula form of a constraint formula the formula in in some predicates the knowledge base language L for logi- and cl = even(X) A (X > is the . . ,X,,, can relation R,( X1, . . . , X,, ) , which expressed by c. For example, R,, than 100. To de- integers greater con- are c will be that its variables applies, we use the following ith argument to the the formula c after substituting of R,). The expression x for Xi, for We assume the following properties of our constraint predicates: formulas cl and ~2, it is possible Closure: Given that express: - The join of R,, and R,,. _ A projection of R,., (i.e., a relation consisting of only a subset of the arguments to effectively construct formulas of R,,).7 - A selection consisting ai=j R,, , where i and j are some columns of R,, (i.e., a relation of only tuples of R,, in which columns i and j are equal). - A selection ui=cRc,, where i is some column of R,, and c is a constant in the formulas cl and ~2, it is decidable whether R,, = R,,. language 13. Equivalence: Given Satisfiability: Given a formula c, it is decidable whether R, is nonempty. * Finiteness: Let C be a finite set of constants finite set of formulas fixed n) and only constants in the Closure property) nonequivalent in the language C that have at most n free variables of the operators in the language L, and let F be a (for some (discussed in F may create only a finite number of formulas over n (or fewer) from C. Then applications free variables. to formulas The Closure condition guarantees that we can perform (i.e., conjunction, language. The second and third conditions constraints. The Finiteness and variables we only create a finite number of nonequivalent the case in which the Finiteness constraint guarantees that with a given set of (we constraints condition does not hold). The procedures the basic manipulations on selection) within our identify that we can projection, guarantee the relations denoted by formulas constraint two equivalent constants later discuss to compute needed be given. Typically, constraints over dense domains, the closure operations, equivalence, and satisfiability these procedures are efficient. For example, are assumed to for conjunctive order in the number of variables testing equivalence is cubic ’ Note that this property corresponds to closure under existential quantification of the corresponding logical formula. x Note that if we have a formula FALSE in our language denoting the empty relation, then the Satisfiability property will follow from the Equivalence property. 98 A.E Levy et al./Art$cial Intelligence 97 (1997) 83-136 [ 891 (but over integers or when disjunctive hard; see [25] for a discussion of some of these issues). constraints are allowd the problem is NP- The properties we require are satisfied by a wide class of interpreted predicates. For example: Order constraints: The language consisting of the predicates =, Z, <, <, and the connectives A and V. Sort constraints: A constraint connectives A, V, and 1. In particular, sumption Finite, given relation: Often, a given relation be best viewed as a constraint. Any given finite relation satisfies we require. small and stable can that language based on a finite sort hierarchy, [ 6,12,72] that is relatively can be viewed as a sort language logic with decidable any description the properties the sub- (e.g. and ) . Hereafter, a constraint will refer to a constraint formula in some constraint language 15 3.2. Decidability of irrelevance In our analysis, we consider definitions based on DI2 (because is a fact of a derived predicate, DZ1 is trivially and DZ2 are equivalent when the subject of the irrelevance and when the subject several sets of possible derivations. Recall and it can be viewed as a tree formed by the subgoal all derivations of the query, Dti (A), we consider based on the following definitions of derivation minimality: that a derivation in Horn-rule KBs, DZ, claim is a rule or a base fact, true). We consider is a sequence LYE, . . . , a,, to the set of relation. In addition two other choices of sets of derivations l A derivation D is minimal Ck!i is an ancestor of ffj. if does not have two identical facts ai and a,i such that l A derivation D is a minimal support derivation if there is no other derivation of the query, D’, such that Base(D’) 5 Base(D) # Base(D). in their antecedents. The important observation becomes undecidable whenever in Appendix A). A summary of the decidability decidable literals irrelevance in Lemma A.1 in Table 1. The is that weak (shown shown the rules contain negated the table recursion (efficiently) forms of negation. Allowing undecidability tion symbols. on base predicates, constraints. However, allowing cidable. 9 It should be noted stratified semantics ble shows as opposed that slight variations of strong irrelevance, If we allow negation then strong for a larger class of languages, arbitrary function symbols but only if there in the function-free irrelevance remains decidable stratified negation causes strong that when rules contain to classical in defining first order semantics the minimality and Base(D’) to deriving claims irrelevance is that go beyond Horn rules, where from the rules contain irrelevance In contrast, including in strong recursion is and some to leads the func- through case but only allow negation in the presence of to be unde- stratified negation, we consider the ta- can cause even irrelevance of derivations [89]. Finally, is recursion the Horn rules table also considers results pertaining cases 9 Rules are said to be stratified predicates from p to 4 if p appears in the KB. The dependency [ 891 if there are no dependency the graph of the KB has one node for every predicate and there is an arc is 4. that involve negations between cycles in the antecedent of a rule whose consequent A.Y Levy et al./Artifcial Intelligence 97 (1997) 83-136 99 Table I Decidability Language of deriving irrelevance claims Strong irrelevance Weak irrelevance Horn rules with no recursion or constraints Decidable I Follows from [ 48 ] I Non-recursive Horn with constraints Recursive Horn, no constraints function-free Decidable Section 4 Decidable (datalog) Section 4 1 1611 Decidable Follows from [ 78 1 Decidable Follows from [ 49 1 Undecidable 1 I551 Lemma A.1 Function-free Horn with constraints Decidable Undecidable Section 4 1 If-511 [551 Lemma A. 1 Arbitrary Horn rules Undecidable Follows from 111 Function-free Horn with Stratified Negation Function-free Horn with negated base predicates Datalog with unary base predicates Undecidable Lemma A.2 Decidable Section 4 + [ 591 [551 I551 Lemma A. 1 Undecidable 1 Lemma A.1 Decidable [591 the decidability significantly. of strong irrelevance with respect to minimal derivations to change In this article, we focus on the algorithm for deciding strong irrelevance. In the next section we present deriving strong irrelevance a sound, complete, claims procedure for the decidable for the undecidable cases. the query-tree, which is a tool for automatically and efficiently claims for a variety of languages. The query-tree will provide irrelevance inference in the table, and will provide a sound cases denoted for deriving procedure inference strong and efficient 4. The query-tree strong claims Deriving irrelevance requires irrelevance, that we meet several challenges. First, as implied by the definition of strong irrel- evant to a query q, we need to establish properties of the set of all possible derivations of q, which may even be an infinite set. Furthermore, we have restricted our algorithm to look only at the rules consider the KB. Finally, we required in the rules. to facts in the semantics of the interpreted predicates that may arise for any set of possible ground in the knowledge base, and therefore, in order to deem a fact f strongly the possible derivations the algorithm needs that we enforce 100 A.1 Levy et al. /Artificial Intelligence 97 (1997) 83-136 The knowledge base d consists of the following rules: rl : badPoint( X) A path( X, Y) A goodPoinr( Y) * goodPath( X, Y) r2 : link(X,Y) =Spath(X,Y). rj : link(X, Z) Apa#z(Z,Y) + path(X, Y). r4 : step(X,Y) * t-5 : bigSrep( X, Y) * link(X,Y). link( X, Y). The following constraints are given on the ground facts: =S 100 < X < 200. badPoinf(X) sfep(X, Y) * X < Y. goodPoint( X) =k 150 < X < 170. bigStep(X, Y) =+ X < 100 A Y > 200. goodParh( X, Y) I rl {lOO< X<Y< 17O,Y> 150) badPoint / {lOO< x< 170) I parh(X, Y) (100 < x < Y< 17O,Y> 150) L goodPoinr( Y) {150< Y< 170) {lOO<X<Y< 17O,Y> 150) r2 1 link(X*Y) { 100 < x,; z< 170) link(X Z) Apartz(Z {loo<z<Y<;7o,Y> 150) Y) ~0~~4 r4 I srep(X, Y) mp(!X,Z) {lOO<X< Z< 170) {lOO<X<Y< 17O,Y> 150) Fig. 2. An example query-tree. Note that expanding the node link( X, Y) with the rule r5 would result in an inconsistent label, and is therefore not expanded. The expanded equivalent of the node parh( Z, Y) is parh(X,Y). This section presents a novel tool, the query-tree, that provides the set of all derivations of the query that satisfy a compact repre- the semantics predicates. can be established the query-tree we can check whether a certain of the query, and (See the example by simply examining in Fig. 2.) Properties of this set of the query-tree. For example, by fact can be part of some to the irrelevant therefore decide whether it is strongly sentation of precisely of the interpreted derivations inspecting derivation query. Informally, the query-tree is a symbolic AND-OR tree consisting of goal nodes and rule nodes. The root of the tree is a goal node labeled with the query. A goal-node g unifies with g, and the actual child is the has a child for every rule whose consequent rule resulting child for every a ZabeE to each conjunct from the unification with g. A rule-node has a goal-node is made finite by attaching in its antecedent. The query-tree A.I! Levy et al. /Artificial Intelligence 97 (1997) 83-136 101 in the tree, and expanding node labels. The label of a node contains facts generated the rules and the constraints the KB. in that node. The label is inferred by the constraint known about the possible ground only one goal-node the tightest constraint from every equivalence class of that needs to be satisfied by literals appearing in facts that may appear in We begin in Section 4.1 by explaining the correspondence between derivations and the complexity encodes a set of symbolic for constructing the query-tree, the query-tree. The query-tree and how the query-tree symbolic derivations, the algorithm Section 4.2 describes of building discusses describe here, is an instance of a general method for encoding Intuitively, sets of derivations to encode various irrelevance for deriving other strong encodings possible by the query-tree. and Section 4.3 as we algorithm, [ 551. sets of derivations it can be designed and therefore, used In Section 4.4, we briefly mention other (e.g., minimal derivations), claims. the contents of node labels in the query-tree, by changing derivations. 4. I. Derivations and symbolic derivations containing of goal-nodes and rule-nodes In the context of Horn-rule knowledge bases, a derivation of a ground atom can be (see Fig. 3 (a) ) . The root of the query atom. If a goal-node g was derived using of a rule r, then r is in the child rule-node of g and its children are the in our proofs, of r. To simplify some of the arguments are ordered in the antecedent of r. The leaves of a derivation facts from the knowledge base that were used in the derivation. viewed as a tree consisting the tree is a goal-node an instantiation instantiations we assume without from left to right as they are ordered are the ground atomic For reasons interpreted predicates. that will become clearer shortly, we do not include nodes that the children of the rule-node loss of generality. of the antecedents in the tree for Since that appear (see Fig. 3(b,c)) the query-tree will be built based only on the rules in the knowledge base, it is except that the constants are replaced by variables, and it includes only in the query or in the rules. The root of a symbolic derivation of the query predicate. The child of a goal-node g is a rule-node will actually encode symbolic derivations. A symbolic derivation like a derivation constants tree is a goal-node a rule whose consequent containing for every conjunct child goal-node goal-node is the corresponding leaves of a symbolic derivation rule-node 0 is a mapping rule ro. has a the contents of each such of the rule with g. The atoms of the base predicates. A a renaming O(Q) of a rule ro in the knowledge base, where the actual unifies with the goal-node. The rule-node in its antecedent, and in the unification of r-0. The expression &e(r) conjunct tree contain r is formally the variables symbolic denotes on A symbolic derivation represents constants to its variables signing the rules are satisfied. A symbolic derivation least one such variable assignment. For example, derivation by the set of instances of all satisfiable and (c) is a satisfiable symbolic is not. The set of all derivations of the query is therefore represented in Fig. 3, (b) symbolic derivations. the set of derivations such that the literals of the interpreted predicates that can be obtained by as- in tree is said to be satisfiable if there is at 102 A.I! Levy et al. /Artificial Intelligence 97 (1997) 83-136 goodPath( 140,160) I goodPath(X, Y) I badPoint( 140) A path( 140,160) goodPoint( 160) badPoint( X) A parh(X, Y) goodPoint( Y) I r2 I link( 140,160) I r4 I step( 140,160) (a) {150< Y< 170) {100<x<200} {X < YI I r2 I lit&(X, Y) I r4 I step(X, Y) @I goodParh( X, Y) I f-1 badPoint( X) a goodPoint( Y) { 100 < x < 200} j2 (150 < Y< 170) I lit&(X, Y) I r5 {X < 100A Y> 200) bigStef!(X,Y) (c) Fig. 3. (a) is a ground derivation. (b) is a satisfiable symbolic derivation and (c) is an unsatisfiable symbolic derivation. The query-tree is an AND-OR tree encoding a set of symbolic derivations. Its root is to a symbolic derivation tree, children, each for one of the containing a goal-node the atom of the query. In contrast a goal-node g (an OR node) may have several rule-node rules whose consequent When rules contain unifies with g. recursion, there will be an infinite number of symbolic derivations. in the tree. The label describes all the constraints in order to encode an infinite number of derivations by a finite structure, we Therefore, in the query-tree. To decide which nodes to expand, expand only part of the goal-nodes that we attach ZubeZs to every node relation need to be satisfied by instances of that node. The labels induce an equivalence from on nodes every equivalence labels, and gt was the one expanded, we call gt the expanded equivalent of g2, denoted Eq(g;?). As we will see, of the computed during labels cannot be completely these computation tree, and we will need a bottom-up and in our construction, we only expand one goal-node class. If nodes gt and g2 have equivalent the top-down phase. in the query-tree, the top-down construction to precede Based on expanded equivalents, we can now define how the query-tree encodes a symbolic derivation: A.E Dvy et al. /Artijicial Intelligence 97 (1997) 83-136 103 Definition 9. A symbolic derivation d is encoded by the query-tree T if there exists a mapping Cc, from the nodes of d to the nodes of T that satisfies the following conditions: EO. If g,, . . . , g, are the children goal-nodes of the rule-node r in d, then $(gt ) , . . . , r,G (g, ) are the children of e(r) in T, respectively. El. For every rule-node r E d, the rule in G(r) is the same as the rule in r; i.e., rule(r) = ruZe($(r)). ) is the root of the query-tree. E2. The node #(root(d) E3. If r is a child of the goal-node g in d, then: is expanded is not expanded If $(g) If $(g) in T, then q(r) in T, then $(r) (1) (2) is a child of cc/(g). is a child of its expanded equivalent, Q(@(g) ). In the next section we describe how to construct the query-tree. The main challenge in the construction tree will encode precisely is to compute the labels of the nodes in the tree such that the resulting the set of satisfiable symbolic derivations of the query. 4.2. Constructing the query-tree The input l A set of rules 7’. We assume without to our algorithm is the following: loss of generality interpreted position. equality predicates (All constants in the rules contain and all equalities a distinct variable between arguments literals.) Note that this implies that all unifications will be trivial. that all literals of non- in every argument are expressed as l Constraints on the base relations. For every base relation e, we are given a constraint to hold for facts then c, = TRUE. that are known c, on the arguments of e that describes conditions of e in any given knowledge base. If there are no such constraints, We assume that ce is given in its standard form. l A query, which we assume is of the form q( X1, . . . , X, ) A cy, where X1, . . , X, are n distinct variables and cq is a constraint on XI, . . . , X,. A key difficulty in building the query-tree stems from the observation in a single the label of a node cannot be built because cannot be determined must be known the problem in order is to precede construction top-down in the tree may depend on its descendents top-down construction. However, beginning from in a single to decide whether or not to expand the node. The solution the top-down construction by a bottom-up phase. the root. This that the tree is and therefore the label of a node to The query-tree algorithm consists of two steps: Bottom-up phase. adorned predicate p” is intended the tuples satisfying rules, where a predicate greater In this step we compute a set of adorned predicates and a set of is a predicate of the form pc, where p is a rules, P,. An adorned predicate in the KB and c is a constraint on the arguments of p. Intuitively, to represent the constraint the original predicates the predicate the subset of the extension of the predicate p which includes of the original are replaced by adorned predicates. Note that since in Pt , the number of rules in ‘PI may be c. The adorned rules are specializations in P may have several adornments than the number of rules in P. 104 A. E Levy et al. /Artijicial intelligence 97 (1997) 83-136 We begin with the predicates on facts of e (as given eC*, where e is a base predicate is the given in the input). We compute new adorned predicates and c, the rules in the KEI as follows. Suppose r E P is a rule of the form constraint using r:q,(X,)A.. +&JGL) AC, *p(X) a predicate where cr is the conjunction computed c=c,(Xr)A... 8. If c is satisfiable, rule to PI: adorned of interpreted that we have 27 for each predicate qi, 1 6 i 6 m. Let c be the constraint A c,(X,,) A err and let ch be the projection of c on the head variables then we create the adorned predicate pc” and we add the following in r, and suppose literals r’ : q;‘(R,) A-.. Aqz(xnnr) Ac+p”“(x). Note that the rule Y may be recursive, and therefore we may use one adornment the predicate p in order no new adornments language guarantees to compute a new adornment. We apply are computed. Note that the Finiteness that this phase will terminate. of the rules of P until property of the constraint the adorned In this step, we construct a forest of trees Top-down construction of the query-tree. using rules PI. We attach to every node g in the forest a label, denoted by L(g) , We begin by inserting a node for each adorned predicate of the query predicate q of P, i.e., a node for each predicate of the form 4, where qc E PI, when c A cq is satisfiable. The label of the node is c A cq. We proceed to build the forest as follows. A goal-node g for a predicate pc can be unified only with adorned has the predicate pc, i.e., of the form: rules whose consequent r: qT(x1) A-.. A qz&) A c, + p”(x). If L(g) A c, is satisfiable, g, is a rule-node of rule r and its label a child goal-node of gr for every literal predicate. The L( g,) onto based on the following the variables that appear then we create a new rule-node gr as a child of g, where is L(gr) = L(g) A c,.; moreover, we also create in the antecedent of r that has a non-interpreted label of the child goal-node corresponding to qfi is the projection in q;. The termination of the top-down phase of is conditions: We do not expand goal-nodes of base predicates. We do not expand a goal-node g if the resulting label. We do not expand a goal-node of the form p(X) p(P) an isomorphism and L(p(P)).” between Up(X)) details of the top-down phase are given in Fig. 4. in the forest such that the isomorphism mapping The rule-node will have an unsatisfiable if there exists an expanded node the variables X to p is also Example 10. Consider bottom-up phase begins with the adorned predicates the application of the algorithm to the example in Fig. 2. The “’ Note that p(y) can be any node in the forest, not necessarily an ancestor of p( T?). A.Y: Levy et al./Artijicial Intelligence 97 (1997) 83-136 105 procedure build-fore&( P, , q( 2) A c4) begin /* Creating a forest of trees T for the adorned for all nodes g in the tree, Eq(g) = g unless otherwise stated. for every predicate of the form qc E P, such that c A cq is satisfiable, rules Pt and query q(x) A cq. */ Let P = Yt, . . . , G be II new variables Insert a goal-node qc( F) that do not appear into T with label (c A cy) (P). in T. repeat Let g = p” (81) be a leaf in T of a derived predicate with label L(g). if there is an expanded goal-node gt = pc (x2) in T, such that 4 is the isomorphism from 81 to X2 and q5( L(g)) is equivalent to L(gt ) then Set Q(g) = gl. else for each rule r E PI with consequent predicate p” do that maps the consequent of r to g, that don’t appear in T. Let 13 be a l-l variable mapping and the other variables of Y to new variables is satisfiable if O(c,) A L(g) Create a child rule-node of g, containing with label 0(c,) A L(g). for every literal gi of non interpreted predicate then the rule e(r), in the antecedent of e(r), Create a child goal-node gi for the rule-node, where L(gi) is the projection of 0( c,) A L(g) on the variables of gt . until no changes are made Remove all adornments return T. end build-forest. to T. from predicates in nodes of T. Fig. 4. Top-down creation of the query-tree. bigStep% < 100,&>200, <‘OO g00dPOintt5O<Xl.XI<I70. x,<xz step badP~int’OO<‘l,‘l , With rule r-4, we create rule rg, we create linkcz, where c2 = {Xt < 100,X2 > 200). the adorned predicate link”‘, where cl = {Xt < X2); and with Substituting link”’ in r2 results in pathcl, and similarly any new adornments r3 does not produce for the first subgoal and pathc’ combinations result where cs = { 100 < X1, Xt < X2, X2 < 170, X2 > 150). Note that trying for path. For example, in path”‘. Finally, in pathc’, while for the second results substituting path”’ in r1 we compute goodpath”, to substitute therefore we do not create label for goodpath, in r-1 will yield an unsatisfiable for linkcz and pathc2. Rule substituting link”’ the other three path” additional adornments of goodpath. The bottom-up phase creates the following adorned rules (omitting adornments of predicates with a single adornment): 106 A. E Levy et al. /Artificial Intelligence 97 (1997) 83-136 t-1 : badPoint( X) ApathC’ (X, Y) A goodPoint( Y) A (X > 100) A (X < Y) A (Y< 170) A (Y> 150) * g00dPuthC3(X,Y). r-i : linK’(X,Y) A (X< Y) *pa&‘(X,Y). r: : lidP(X,Y) r: : linkc’(X,Z) r-i : lirP(X,Z) Aputhc’(Z,Y) A (X < 100) A (Y> 200) +pathc2(X,Y). Aputhc’(Z,Y) A (X < Z) A (Z< Y) +puW(X,Y). A (X < 100) A (Z> 200) A (Z-C Y) + path”2 ( x, Y) . rz : linP(X,Z) AputhC2(Z,Y) A (X< Z) A (Z< 100) A (Y> 200) j. puthC2 ( x, Y ) . r4 : step(X,Y) r-5 : bigStep(X,Y) A (X < Y) + linkc’(X,Y). A (X< 100) A (Y> 200) =+ limV2(X,Y). The result of the top-down phase is shown in Fig. 2. Note that the predicates puthC2 cannot be used in derivations tree. The expanded equivalent of the node puth( Z, Y) is puth( X, Y). of goodPuthc3, and therefore link@ and rule r-5 is not in the The following strongly irrelevant theorem to the query: shows that the query-tree tells us exactly which facts are Theorem 11. Let P be a set of Horn rules with interpreted predicates Closure, Equivalence, created for the and Finiteness properties. Let T be the query-tree the rules P and the query of the form q(X) A cq. Sutisfiubility, that satisfy (1) Afuctp(ul,... respect holds), the label L(g) of g. , a,) (i.e., to any instance qo of q( 8) A cq with claim SZ(p( al, . . . , a,), qo, J5p, DI2, D@ ) to &I, if and only if there is no node g of p in T, such that al, . . . , a, satisfies is strongly the irrelevance irrelevant (2) A rule r is strongly irrelevunt to any instance qo of q(8) AC, with respect to & if and only if r does claim SZ( r, qo, .Cp, D12, IDgo) holds) the irrelevance (i.e., not appear in T. to emphasize It is important in the query-tree that the labels the theorem provides not only a sufficient condition and therefore but also a necessary Returning it does not appear atomic facts of step( X, Y) for which X < 100 or Y 3 170 are strongly query. condition. The proof of the theorem in Fig. 2, the rule rs is strongly in the query-tree. Using to the example is given irrelevant the query-tree, we can also derive in Appendix A. to goodPath because that the to the irrelevant are as tight as possible, for strong irrelevance, 4.3. Complexity The time taken to build the query-tree (and therefore to decide strong irrelevance) in the number of rules is linear arity of the predicates. To see this, let 1 be the number of non-equivalent adornments a predicate in the bottom-up or labels in the KB, and let e be the number of time units needed to check equivalence in the knowledge base and may be exponential in the top-down phase) that can be generated in the (i.e., for labels A. E Levy et al. /Artijicial Intelligence 97 (I 997) 83-136 107 literals the refined (i.e., creating number non-interpreted phase of the algorithm that we check the satisfiability rules) to the maximum number of refined rules that can be created. in the antecedent of a rule, and R of two labels. The bottom-up can take time proportional If b is the maximum is the number of rules in the KES, then we can create at most Rib refined rules. Creating in the a refined the bottom-up rule, and time to build in the top-down phase will be 0( IT/e), where ITI is the number of goal-nodes class is expanded, is the number of derived predicates the query-tree Rb grand-children). in the tree is at most ZP, where P in internal node can be expanded with R rules and in the query-tree. However, since only one goal-node of every equivalence is at most ZPRb (each Therefore, rule requires therefore the forest take at most ReZb time units. The the number of internal goal-nodes in the KB. Consequently, the number of leaves the time to construct is 0( RPeblb) . of the resulting the query-tree phase will constraint The value of I (the number of different adornments) and e (the time to check equiv- In the case of (and constants and disjunction), (with conjunction language under consideration. 1 is at worst doubly exponential on the ordering of the arguments of the relation in the KB. This is because a label essentially describes alence of labels) depends on the constraint order constraints in a&y of the predicates constraint in the rules). There are an exponential therefore number of non-equivalent a doubly exponential describes a set of possible orderings). The time to check equivalence of two labels is at worst exponential It is important some that appear number of total orderings of the variables, and (each constraint constraints is only in the number of rules (and, of course, does not depend on the number of ground only in the arity of the predicates. This is an important frame systems employ tend to be small the algorithms will scale up to knowledge bases number in pathological theorem shows to do much better than we have with the query-tree. Specifically, because arities of predicates and therefore, linear facts!), and possibly exponential distinction mostly binary predicates), with many of labels occurs only that we cannot expect it shows detecting in the arity (and polynomial to emphasize that once we introduce irrelevance strong the lower bound on the problem of facts. Moreover, we believe f, in the arity. labels are allowed). that the complexity cases. Furthermore, that an exponential if only conjunctive rules and ground the query-tree is exponential the following the predicate of building (e.g., Theorem 12. Given a set of rules P, a query schema q(x) A cq, and a rule r E P, time if the rules may deciding SZ( I, q( X) A cq, Zp, D12, IY) contain is hard for exponential the predicate #. The proof, given in Appendix A, is based on reducing the acceptance problem of strong to the problem of detecting a linear-space irrelevance of rules. alternating Turing machine (ATM) 4.4. Extensions of the query-tree The query-tree method. The query-tree of a general method for encoding a possibly [ 55,59,61,64]. The method algorithm, as described above, is one instance infinite set of derivations via a finite structure an infinite number of derivations is based on encoding 108 A.Z Levy et al./Artijicial Intelligence 97 (1997) 83-136 a labeling by identifying construction exactly a desired set of derivations. scheme, of the tree based on label equivalence guarantees i.e., a finite set of labels, such that terminating the that the query-tree encodes In the previous section, to be satisfied by facts generated that needs exactly the set of satisfiable have been used to encode different they yield algorithms the label of a node described formula encoded symbolic derivations. Several other instances of this method and are of interest here because the tightest constraint at the node, and the query-tree sets of derivations, for other types of strong-irrelevance claims (see Table 1) : (1) Tag labels. The label of a node also includes information on the ancestry of that node. As a result, [61]. of the query the query-tree encodes exactly the set of minimal derivations (2) EDB-labels. The label of a node includes information tree. Using that can appear in the derivation on negative and positive these labels, we encode ex- literals actly the set of satisfiable derivations when rules include negated base predicates in the antecedents IC-labels. The label of a node straints tion tree. Using classes of Horn instantiations con- that are satisfied by the deriva- for some schemes we can decide strong irrelevance includes partial literals) (i.e., clauses with only negative this labeling theories integrity constraints that include of integrity [ 641. [59]. (3) language Relaxing the finiteness property. The most stringent constraint a finite number projection. When may not hold. For example consider of labels on the rules contain both function the predicates, the rules: is the Finiteness property, which requires requirement we imposed on the that we can only generate and this property of join, symbols and recursion, selection, using operations $1 : (X = 0) * s2 : integer(X) + integer( X + 1) . integer(X). As shown in Fig. 5(a), a top-down expansion of a tree for these rules will result an infinite number of labels of the form {Zi = X - i} for every integer i. Therefore, construction of the query-tree will not terminate. in the in the goal-node, To build a query-tree c18, we return a member goal-node, we proceed by the following in such cases, we choose a finite set of labels C to assign to in the query-tree. When we project a constraint on a rule-node onto its father (or c and a strategy. Given a constraint in C which if there is no label that cl1 k cl, cl of C such c2 E C such that c2 k cl and cI~ k CZ. The cl can be viewed as the best approximation to cIB out of the finite number the nodes children) subset of its variables X that appear describes the exact projection and such that there is no other constraint constraint of labels C. Consequently, tightest ones possible, and therefore, for strong of the nodes to choose such a finite set of labels C is to not allow new terms labels example, the query-tree provides only a sufficient condition that a ground atomic fact which does not match any irrelevant, but not vice versa. One simple method in the in our to be created (or to allow a maximum of k new terms, where k is fixed). For instance, if we do not allow new terms, we get the query-tree irrelevance. That means in the tree is strongly shown in Fig. 5 (b) . in the query-tree the resulting are weaker labels than A.E Levy et al./Artificial Intelligence 97 (1997) 83-136 109 integer(X) 0 s, A I x=0 s2 I infeger( Y) {Y=X- 1) SI A 32 I Y=O I integer(Z) {Z=X-2) infeger(X) {} s, A .Q x=0 ’ inreg?r(Y) {) (a) (b) Fig. 5. Query-tree with function symbols. claim claims deriving that even irrelevance irrelevance irrelevance, irrelevance from external from for strong sources. As stated earlier, that are given by a user. In [55,62], is undecidable can be used as a sound Inferring claims claims can either be derived solely based on inspecting or can be inferred shown from a given ever, the query-tree Specifically, query-tree f is the set of facts of a predicate p that satisfy a constraint as an integrity of the query evant) will also not appear in [55]. irrelevance (parts of) the knowledge base, it is that follow theories. How- claims. to the query, we build a f. If lc constraint on p). As a result, facts that can only be parts of derivations irrel- in the query-tree. The details of the algorithm are described irrelevant f (if f is a rule, we build the query-tree without all the irrelevance in function-free Horn-rule f (and are therefore strongly if we are told that a fact f that does not contain inference procedure if f is strongly for irrelevance c, we simply that contain is strongly irrelevant impose claims 5. Using the query-tree to speed up inferences indices irrelevant In the first, the query-tree In this section, we explore two ways in which the query-tree can be used to speed up is used to decide which ground facts and rules are inferences. to a given class of queries. Based on that determination, we create strongly specialized database relevant to a class of queries. Given a query from the given class, we can then use these indices speeding up inference. facts during for fetching ground that the tree also encodes The second use of the query-tree all the possible in lookups derivations the search of a backward chainer inference, is based on the observation and database of the query. We can therefore use the query-tree to follow only these sequences. sequences of rule applications facts that are (possibly) thereby significantly that can result that see only the ground to guide Although it is clear from theoretical analysis that ignoring paths can yield speedups, on various factors is unclear. Such factors include the impact of these savings irrelevant facts and solution in practice and their dependence (versus the indices the cost of building 110 A.Z Levy et al. /Artijicial Intelligence 97 (1997) 83-136 from utilizing the the savings achieved size of the knowledge base and variations on the form of the rules. This section presents an empirical validation of the savings achieved by using the query-tree and an empirical analysis of the significance the percent of facts deemed of the factors affecting the speedups. irrelevant, them), 5.1. Two uses of the query-tree The first use of the query-tree irrelevant if and only if and only to the query to a given set of queries are irrelevant irrelevant strongly tree with which facts can be ignored. Recall and ground ground in the KB. For instance, the rule ~5 can be ignored. Similarly, { 100 < X < Y < 170) can also be ignored. facts if it does not satisfy a rule (Theorem if it does not appear is based on the fact that it tells us exactly which facts is strongly 11) . Specifically, fact is in the the query, these rules of the is independent in Fig. 2)) (repeated that do not satisfy in the tree. A ground the label of any goai-node that this determination facts of the relation in the good&h example step it can be unified. Consequently, when answering We can use this property of the query-tree to speed up inferences because the query-tree the specialized frequently. Given that occur create specialized in the set. The cost of preprocessing cost of building build significant can be drastically is retrieved, constraint lookups will be many unbound. Using that every fact that does not satisfy guaranteed ately cost of doing all the useless large. ’ ’ label of some node the specialized (by checking indices o&y on the facts that are not strongly such a set of queries, we build a query-tree irrelevant in such a way involves the knowledge base and the cost of one pass over the knowledge base indices. However, the payoff of removing irrelevant the size of the space that an inference mechanism reduced. Specifically, it is guaranteed the fact may be part of a derivation in the query-tree. This that every of the query since is especially are made with some unbound variables. For instance, in our example, lookups of the form step(a, Y), where a is some constant index on the facts of the predicate fact retrieved will satisfy { 100 < Y < 170). In contrast, this constraint can generate a whole search subtree to be useless. Note that even if the reasoning mechanism constraints) that the retrieved the available detects fact is irrelevant, immedi- the lookups and checking the constraints can be arbitrarily for sets of queries for it and to queries the to facts can be to search fact the significant when there and Y is needs time a ground it satisfies step guarantees retrieving a that is The second use of the query-tree the sequences of rule applications of the query. We can use this observation consider the following example. is based on the observation and database that the tree also encodes in derivations that can result to further control our search. To illustrate, lookups Example 13. Consider following rules. Its query-tree a knowledge is shown base defining in Fig. 6. a relation dessertMeal with the I’ Moreover, note that in order to always be able to detect irrelevant facts immediately, the reasoning mecha- nism must propagate the constraints in the same fashion done in creating the query-tree. A. E Levy et al. /ArtiJicial Intelligence 97 (1997) 83-136 III dessertMeal( DI, WI, D2. W2) {beef(D~),dessert(Dz)} I {beef( 01)) cheapMeal( DI, WI) A expensiveMeal( D2. W2) {dessert( 02)) I I {beef(Dl),Z < 15) dish(D1,Z) A compatible( Dl, WI ) A dish( D2, ZI) {dessert( 02). ZI > 15) compatible( D2. W2) 1 I A beef( DI ) redWine( WI ) A dessert( 02) sweetWine( W2) Fig. 6. Avoiding search paths using the query-tree r-1 : cheapMeal( D1, WI) A meat( 01) A expensiveMeal( D2, W2) A dessert( 02) + dessetiMeal( DI, WI, Dz, W2) r2 : dish( X, Z) A (Z 6 15) A compatible( X, Y) =$ cheapMeal( X, Y) r3 : dish( X, Z) A (Z > 15) A compatibZe( X, Y) + expensiveMeal( X, Y) r4 : beef(X) A redWine( Y) + cornpatible( X, Y) rg : dessert(X) A sweetWine( Y) * compatibZe( X, Y) The predicates meat, beeA and dessert are sort predicates (dessert is disjoint from of a wine and a two pairs for dessert), is given compatible dishes and wines two). The relation that more attention represents pairs consisting (one pair for the main dish and another the available dishes and their prices. Consider the other dish that are compatible with each other. The relation dessertMeal identifies of compatible such represents fact dish(X,Y) may be relevant respectively). satisfy constraint to a subgoal of r2, and not of r3 (and vice versa for rs) . facts of dish that the first constraint, whereas as a subgoal of 13, only facts that satisfy the second shows that rule r4 can only be applied to the dessert part of the meal. The relation dish facts of the relation dish. Any (beef(X) A Y < 15) or (dessert(X) A Y > 15) that satisfies either to the query dessertMeal (because of the rules r-2 & r4 and r-3 & r-5 However, as a subgoal of r2, we need only consider are needed. Moreover, the query-tree (as opposed To exploit this additional control knowledge, we create specialized to an index for every relation leaf in the query-tree the inference mechanism to follow only example, we create one index for beef dishes under $15 and another over $15. To follow the query-tree during search a node in the query-tree 4(g). We start by assigning to the query. At every step, base predicate), we perform we expand g only with the rules for every in the KE3) , and modify In our for dessert dishes inference, we attach to every subgoal g in our the root of the query-tree . Otherwise, that are children of the expanded equivalent of 4(g) the paths permitted by the query-tree. the lookup using the specialized if g is a database (i.e., a subgoal of a lookup subgoal index of 4(g) indices 112 A.k: Levy et al. /Artijicial Intelligence 97 (1997) 83-136 (which may be the node 4(g) subgoals of the rule-node only the paths encoded by the query-tree, ground facts that can be used in derivations itself). We assign in the query-tree. As a result, and in every database in the current path. to the subgoals of g the appropriate follows engine it retrieves only the inference lookup 5.2. Experimental results and analysis for q(z) We tested the impact of the savings achieved by using the query-tree using a depth first search backward chainer on Horn rules. l2 Given a knowledge base A and a query schema q(x), we built a query-tree and two sets of indices on ground facts in A. The first set Zi included an index on every relation that includes only the facts that were deemed not strongly a ground in the index for the relation e in 21 if al,. . . , a,, satisfies fact e(al,..., I3 The second set the constraint of indices 12 included one index in the query-tree. We measured the running backward chainer, all of which returned a,,) is included label of some leaf of the predicate e in the query-tree. leaf of a base predicate times and number of nodes expanded of three versions of the to q(X) by the query-tree. Specifically, for every irrelevant l BCI-the l BC2-the backward chainer on A using backward chainer on A using the same answers: the original the indices 11, i.e., ignoring indices in the KB. strongly irrel- evant facts. l BCS-A backward allowed by the query-tree. chainer that uses the indices 12 and only follows the paths We tested over 20 query schemas ( 1) A travel domain using a fragment of a database of real airline data describing taken from the following four domains: flight times between cities (2) A wine domain consisting in the U.S. (examples 3-6 in the tables). of a knowledge base of 50 rules describing between them (based in part on various [ 751) wines and dishes and compatibilities (examples 7-8). (3) A student-advisor graduates, including domain using a knowledge base about computer science Ph.D advisor, school and graduation dates (examples 9- 10). (4) The goodPath example, using The first and fourth domains usually yield deep recursive the rules in Example 2 (examples search 1-2). the number of rules but bushy have a low branching Table 2 presents (i.e., is small. The second domain factor) search large branching factor (which was from student is non-recursive trees. In the third domain, to advisor). all solutions KEI). In the table, Filtering Time includes to a query the results of the experiments for (e.g., find all X, Y such that goodPath( X, Y) is entailed by the and taken for the case where we are looking the query-tree the time to build trees, even though and yields shallow trees search chainer of Epikit attained by removing l2 The speedups the backward [76] ) and with Quintus Prolog. The speedups attained were even better than those reported here. However, we could not use these tools for testing In the experiments, we tested several BC3 because we could not modify for the best results consistently rule and goal orderings. The results are shown for the ordering (the ratio of BCl to BC2) were also tested using the control of the backward chainers. facts implementation (a commercial that yielded irrelevant of MRS all three versions of the backward chainer. is Note that the original knowledge base had an index for each base relation. A.Z Levy et al./Artificial Intelligence 97 (1997) 83-136 113 Table 2 Experimental results: finding all solutions Ex. # KB size Filtering time (set ) Percent irrelevant Solution time (set) Nodes expanded Facts Rules BCI BC2 BClfBC2 BC3 BCi/BC3 BCi/BC2 BCl/BC3 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 350 350 200 200 200 200 1300 1300 150 150 6 6 18 18 18 18 47 47 17 17 1.8 1.8 6.5 5.6 20.7 14.7 25 11.6 0.8 0.6 63 63 69 69 64 68 59 60 59 59 2780 618 372 25 3975 1278 8740 50 35 2.8 182 231 14 5.5 205 41 8720 42 7.5 0.4 15 2.7 27 4.5 19 31 1 1.2 4.6 1.6 183 233 8.6 4.5 13 1.1 363 11 7.5 0.4 15 2.1 43 5.6 306 1190 24 4.5 4.6 7.6 10.5 2.5 22 4.1 17 31 1 1.2 4.5 4.8 10.5 2.5 28 6 295 1630 14 2.8 4.5 4.8 create all the indices in the knowledge base that were deemed strongly in the indices Zt ). The next columns the query. The respective ratios of running expanded by BC2 and BC3 compared times. The last two columns to BCI. (both Zt and 12). Percent irrelevant is the percent of ground facts (and therefore not included irrelevant to find all the solutions show the time taken to times of BCI, BC2, and BC3 are shown, as well as the show the ratios of the number of nodes running The results show significant speedups for both BC2 and BC3. For BC2, the speedups 10.4). The results the average speedup for BC2 example 6). The results the query-tree to the query, building the query-tree using BC3, we often get additional improvements. in excess of 5, ranging up to 1190 (mean: in excess of a factor of 3, ranging up to 31 (mean: were usually show that by following The speedups of BC3 over BCI were usually example 6). l4 In terms of nodes expanded, 41 excluding was 10, while the average speedup clearly show that if we are looking and the specialized indices will yield significant Table 3 shows that similar results are obtained for BC3 was 37 (excluding for all solutions to answer ground queries or to find thejrst to find the first binding solution savings. in cases in which we use the query-tree to a query for goodPath( X, Y) and the query for X and Y). The for ground to the query. to the after which the the shows for the next solution) the queries. The last column time and the time to find solutions (i.e., or we are trying the query-tree was built built for a query schema with free variables is goodPath( 130,160), second and third columns queries. The next columns The next column compares query. It shows the number of calls (each looking preprocessing number of solutions pays off after a very small number of solutions and therefore query-tree found for the query. The results indicate even in cases when we are searching the preprocessing time equals to answer the time show the ratios of the number of nodes expanded show the node ratios of finding the first solution that often the preprocessing it is beneficial to build a for few solutions. I4 Example 6 was excluded example, the resulting query-tree was empty, showing that there cannot be answers to the query. from the mean because the speedups it yielded were exceptionally high. In this 1. 2. 3. 4. 5. 6. I. 8. 9. 10. Table 4 Changing Percent irrelevant 114 A.I: Levy et al. /Artificial Intelligence 97 (1997) 83-136 Table 3 Experimental results: ground queries and finding the first solution Example Ground queries Find first solution BCl/BC2 BCi/BC3 BCi/BC2 BCi/BCS 5.8 1.8 33 4.4 15 33 1 1.1 1.3 1 6.1 1.8 74 7 290 1550 2 1.4 1.3 1 85 4.5 2.5 6.1 31 1.4 1.6 123 4.8 85 4.5 2.6 6.2 1630 25 4.5 123 4.8 Solutions needed to break even Number of solutions 1 1 1 6 1 1 115 81 2 1 187 187 49 37 12 0 41000 420 353 0 the percent of irrelevant facts Example 1 Example 3 Example 9 Solution time Percent irrelevant Solution time Percent irrelevant Solution time BC1iBC2 BCI/BC3 BCi/BC2 BCI./BCS BCI/BC2 BCI/BCS 45 63 79 92 5 15 101 1250 5 15 101 1240 21 45 69 92 1.8 4.5 21 381 3.1 7.6 43 447 4 15 59 82 1.1 1.3 4.6 23.5 1.1 1.3 4.6 23.5 The experiments showed that the savings achieved by using the query-tree are affected by several factors which we discuss below. 5.2.1. Percent of irrelevant facts The analysis of the algorithm suggests that the speedups obtained will be significantly affected by the percent of facts in the knowledge base that are found the query. To test this effect, we ran several variants of each example in the constants irrelevant as the percent of irrelevant to be strongly irrelevant, we get speedups greater in the rules appearing (which had the effect of varying than a factor of 100. facts). The results, shown in Table 4, show that the speedups grow significantly to be irrelevant to that differed only the percent of facts increases. For example, when 90% of the facts are found facts. For example, of the query schema, and thereby It is important levels of generality irrelevant goodPath( X, Y) , we can build one for goodPath( 120, Y). Doing so will result ing additional However, the indices queries. Consequently, accurate characterizations to note that we have the flexibility of building a query-tree at different to achieve varying percents of for the query schema in deem- this case). set of the most this query-tree will be usable the query-tree one should attempt for a smaller to identify created by in using for 100 < X < 120 in of frequently occurring instead of building (e.g., step(X, Y) sets of queries. a query-tree irrelevant facts A.I: Levy et al. /Artijicial Intelligence 97 (1997) 83-136 115 Table 5 Changing the size of the database Example 1 Example 3 Example 7 KB size Solution time KB size Solution time KB size Solution time BCl/BC2 BCl/BC3 BCi/BC2 BCi/BC3 BCi/BCP BCl/BC3 250 350 550 12.6 15 20 12.4 15 20 100 200 300 23 27 35 31 43 58 540 930 1300 1.3 1 1 11.3 20 24 5.2.2. The number of ground facts factor The second in the knowledge base that affects the speedups that was suggested by the initial in Table 5, show that the speedups results facts in the original knowledge base. To test this effect, we ran a different number of ground facts. The increased as the size of the databases the same. The growth can in the than linear is more some constant percent of facts will the overall number of facts is greater. These results are significant in that our methods will scale up to large knowledge bases and be even of is the number of ground each of the examples with databases containing results, shown grew, even if the percent of irrelevant roughly be explained by the fact that the cost of backward chaining number of facts. Therefore, be greater when that they suggest there. more effective the number of ground that the cost of building the effect of removing (Recall facts.) facts remained is independent the query-tree 5.2.3. Placement of interpreted literals in the rules A final factor affecting the speedups achieved from using the query-tree the interpreted rules defining country subject literals are placed the existence of a flight (perhaps with stops) between in the rules. To illustrate, consider the following two cities to time constraints (given by the constants SO and ea): is the way set of in the ur : p(X,I:$,El) A (SO 6 Sl) A (eo 3 El) =S timelyConnect(X,Y) u2 :$(X,xxE) 3 p(X,I:S,E) u3 :$(XZ,S,T) A (T 6 Tl) AP(.ZETI,E) + p(XI:S,E) To describe such paths, the rules can also be written as follows: ur : p( X, I: S1, El ) * timelyConnect( X, Y) u2 :P(XI:S,E) A (S 2 so) A (E G eo> * p(X,Z:S,E) u3 :JE(X,Z,S,T) A (T 6 7’1) A (S > SO) A (T < eo) AP(Z,I:TI,E) * P(XI:SE) The difference between the two sets of rules is that the second set is crafted to exploit Specifically, on timelyconnect. constraints entailed by the interpreted the constraints whenever we retrieve a flight fact that violates begins before SO), we will immediately of rules, we will compute of the derivation. Consequently, when using backtrack. the constraints In contrast, when using the constraints (i.e., ends later than ea or the first set in the last step irrelevant the first set of rules, a strongly all possible paths and check 116 A. L Levy et al. /Artificial Intelligence 97 (1997) 83-136 the second set, no fact may be the root of an arbitrarily facts will have a such tree will be generated. As a result, greater effect for a set of rules like the first one. The experimental this observation. The example pairs 1 & 2 and 3 & 4 are instances of rules differing exactly in this fashion. large tree, whereas when using irrelevant results confirm removing strongly Several points should be noted with respect l Although the speedups are significantly to this issue: bigger using pair, we still achieve significant such that the constraints savings even when are used to control the search. the first set of rules in each the rules are carefully crafted l Writing rules with such built-in control has many disadvantages (see extremely difficult Consequently, we expect rules would usually be written without such crafting. in practice and is a very error-prone to write such rules [ 191). It is task. that includes for every rule-node l Crafting a set of rules with such built-in control can however be done easily using can create a the query-tree. Specifically, set new rule to the query predicate of rules will be equivalent facts). (i.e., will produce However, using the new set, the tightest constraints will be enforced on the bindings immediately when in the query-tree,we in the label of that node. The resulting regardless of the database of ground the same answer set with respect to the original the constraints they appear. 5.3. Discussion It is clear from analysis in cases for using that the methods to identify the query-tree will find irrelevant the experiments and from the theoretical the query-tree will be most useful when we are able of rules. As shown that occur in which predicates play a role. The experiments we frequently. Moreover, interpreted described classes of queries facts only described deal with knowledge bases with large number of ground is small number linear the algorithms will scale up to cases with large number of rules. It should be noted that he indices computed by the query can be used in conjunction with existing the indices computed by the query-tree the semantics considerations are tailored of the interpreted (e.g., selectivity). for a specific class of queries and take into consideration facts and relatively the query-tree indices can be refined using other in Section 4, the time in the number of rules; indexing methods. predicates. These In particular, therefore, to build The experiments inference mechanism. However, described above were done with a depth first search backward chain- to a ing wide range of reasoning mechanisms. The first use of the tree, the removal of strongly the query-tree irrelevant can also be integrated that nodes order in which in the search space be associated with nodes in the query-tree. The particular into any reasoning mechanism. The only requirement facts, is independent easily the techniques we described scheme used. Following the space is searched of the reasoning can be applied is There are several possible schemes and the indices with search for the solution with building independent of the query. Second, the query-tree. First, in order to minimize the construction of the query-tree the overhead associated phase of building the bottom-up in the top-down phase, we can create a specialized the query-tree is is unimportant. for integrating A.X Levy et al./Art$cial Intelligence 97 (1997) 83-136 117 referenced in the search. This way one can for a relation only if it is actually that will not be used. ” indices index avoid creating Finally, it should be emphasized that the optimizations obtained by using to those achieved by methods that derive optimal the query- rule and goal or methods [ 8,9,93]. Whereas [42,84] the search tree are orthogonal orderings to prune the space, solutions and is independent validation the experimental from using such methods. obtained the query-tree that use run-time bindings (combined with tabulation) these methods look for optimal ways to search identifies parts of the space that are guaranteed not to contain of any run-time bindings. Therefore, in of the query-tree do not follow from other savings usually the results obtained 6. Other applications of relevance reasoning So far we have focussed on how to use relevance to speed up inferences. In this section we briefly describe how our algorithms can be used in other applications of relevance reasoning. reasoning for reasoning and constraint theorem proving a set of predicates levels of abstraction [40,73] some detail [ 50,771, is obtained by removing is an in complex domains, and has been used in several fields satisfaction the representation, Automatic creation of abstractions. Reasoning with multiple effective method (e.g., planning of AI [27] ). An abstraction such as collapsing arguments of relations. An abstraction will be useful to the particular original one as well. Otherwise representations. this paper, where we consider different relations and distinctions automatically by automatically their union or projecting out is irrelevant in the the system will have to backtrack between different in such as arguments of to suited for a given class of queries, between predicates. We also show how to use the query-tree of the framework discussed claims about such subjects. i.e., any answer obtained subjects of irrelevance, if the detail removed [56] we describe create abstractions that are especially into one denoting a generalization in the abstract theory holds irrelevance deriving query, from In savings fashion, reasoning is extremely in database systems. in database systems. Relevance in a bottom-up substantial i.e., by evaluating are achieved by pruning Query optimization for query optimization proceeds Therefore, tuples that cannot contribute optimization the database are guaranteed to the database can also be combined with other optimization methods algorithms based on message-passing important In most database systems, query evaluation itself. as early as possible database to the solution of the query. The query-tree can be used for in therefore, we can apply a filter the query-tree [ 8,9] and to the query; as a first step in query evaluation. Moreover, such as magic-sets subqueries before It tells us which to be irrelevant and deductive in relational of queries the query systems. relations tuples [ 911. I5 Theoretically, we can interleave never perform worse than twice the optimal search. steps of reasoning with steps of building the query-tree, and in that way 118 A.E Levy et al. /Artificial Intelligence 97 (1997) 83-136 A novel query optimization algorithm is described in [ 581. The predicate move-around that deals with additional functional dependencies, I6 algorithm for SQL queries, predicate move-around, based is an features of SQL such as aggregate and negation. The predicate move- for in existing query optimizers. The useful support queries. Such queries are usually and interpreted constraints play a major role in of previous predicate push-down to incorporate are especially techniques algorithm is a generalization queries and is very easy obtained by the predicate move-around application from many sub-queries), area of decision on the query-tree extension of the query-tree queries (Min, Max, Avg), around algorithm optimizing optimizations in the growing (built complex them. sources of multiple heterogeneous is the integration gathering of relevance sources contain data relevant it must be able, given a query, in distributed reasoning on the property of data they contain). environments. An information important sources So called mediator systems provide access to a large number of in- (such as databases, knowledge bases and text files). The mediator sources to to efficiently decide which to the query. Since the main cost in answering Information application [ 4,3 1,38,60,90]. formation makes use of descriptions of the contents and the capabilities of the information (e.g., constraints answer queries effectively, information queries access), application [ 651 as in the TSIMMIS ing how to combine information provide to determine which base relations therefore which in time or monetary cost of sources as possible. The in [ 651. In is described [ 901, a mediator contains a set of Horn rules describ- the from the various sources. and their descriptions on these relations. Given a query, we use the query-tree to the query, and that the system access as few information to such a setting sources are viewed as containing sources need to be accessed. In order for such a system system information is the cost of communication In such an architecture, the base relations, of our framework in such a setting that are relevant and algorithms it is crucial are contain information constraints integrity (either tuples 7. Related work 7.1. Analysis of irrelevance As mentioned earlier, [ 16,34,47], literature notion of irrelevance logic community formal logics is to modify can be made. However, devising tractable underlying clean and inference the notion of irrelevance has been studied but the thrust of these works was to analyze in the philosophy the common-sense and not its computational in the is relevance logics (e.g., [ 3,5,24] ) . The key idea in relevance rules such that only relevant implications is largely open the logic and the inference issues are still uses. A related concept discussed this field. The first two in intuitive for these for them. In contrast, our analysis of irrelevance logics, and semantics the second is providing assumes that the logic remains unchanged. ” In SQL terminology a predicate refers to a constraint in the query. A.1 Levy et al. /Artificial Intelligence 97 (1997) 83-136 119 Within AI, the notion of irrelevance was used rather [ 411 and compositional modeling such as RLL extensively text, irrelevance has a natural definition based on the notion of conditional which does not carry over to the context of logical knowledge bases. in various works, [ 321. Irrelevance was also investigated in that con- in the context of probabilistic [ 2 1,23,70]. However, independence informally reasoning lead in addition reformulating are formulated The work most related [ 87,881. Subramanian’s motivations to more efficient in our framework the utility of doing to enable one to analyze so. Our framework to considering that an inference mechanism nian namely, fore ficient distinctions and where derivations considers also defined manian leads to computational claims. Our class of strong irrelevance claims. is given. However, computational tecting KBs and require answering tension of the algorithm graph. This graph shows only simple dependency KB is p, ), and therefore does not enable tests. irrelevance It should be noted satisfying instances irrelevance. However, (i.e., a predicate irrelevance. relevance to ours for analyzing is the analysis of irrelevance irrelevance given by Subrama- to ours; are similar the knowledge base to create one that is simpler and will there- suf- inference. However, her framework does not provide claims of hers, the possible that she irrelevance. Subra- claims whose exploitation the issues of deriving can be viewed as a refinement the form of the KB, we also consider can pursue. The specific definitions a class of computational-irrelevance as variations of weak irrelevance savings, but only gave some straightforward examples of such is a prime example of computational- [ 871, a definition of strong-irrelevance claims that in this definition are not necessarily Finally, Subramanian these algorithms the query as part of the algorithm. She considers focus on the case of propositional several algorithms discusses to the first order case, using the concept of a dejnability instances of for de- logic an ex- p1 depends on p2 if p2 appears relations between predicates in the in a rule whose consequent reachability simple beyond reasoning 7.2. Static analysis of rules Several other authors have considered static analysis of rules for different purposes, based reasoning such as explanation 67,851, automated also used graph-like connection graphs graphs learning [ 29,811, partial evaluation of logic programs [ 14,521, and deductive databases representations of the rules, such as problem [52], compilation graphs [ 141, tree-automata [ 15, [ 86,891. Some have [ 291, space graphs [92] and rule/goal in their analysis. [ 891. Others have used rule folding/unfolding idea is to evaluate In all these works, the common [ 201, i.e., to evaluate to terminate of possible domain the application tation of the domain descriptions when of the graph). The query-tree criterion based on considering rules. Moreover, the query-tree rules followed by a backward the exception of [ 861, only elements. The key issue common of the rules interpre- the rules over an abstract the rules over a domain consisting of abstract is the the creation termination it gives a well motivated to these works to terminate (i.e., when in that is novel that appear in the the semantics of interpreted predicates algorithm combines a forward chaining evaluation of the evaluation of refined rules. Consequently, with chaining than the query-tree to be complete can be shown in more 120 A.E Levy et aL/Art$cial Intelligence 97 (1997) 83-136 straightforward call that completeness derivations. cases (i.e., in the presence of recursion and interpreted predicates). Re- that the query-tree encodes precisely the set of desired guarantees A completeness result closely related to Theorem 11 was obtained [ 861. They describe an algorithm in which in the rules. Their and does not extend by the most independently that uses fold/unfold tight constraint only applies is technique to to encoding other sets of for rules with negated for the result of their algorithm these rules from the query- rule set. languages (such as minimal derivations and satisfiable derivations they do not characterize the constraint to be complete. Finally, to generate has several advantages over their transformed the tree tells us how facts can be used in derivations, therefore enabling relevant sequences of (see Example 13). As seen in Section 5, such speedups. This finer level of control cannot be achieved using by following for every interpreted set of rules Furthermore, and Ramakrishnan to obtain a rewritten relation mentioned predicates, Srivastava transformations computed Horn rules with derivations base predicates). which their algorithm is a new set of rules. While tree, the query-tree Most notably, us to further focus the search of a backward-chainer rule applications control their rules. it is straightforward leads to significant and database representation is guaranteed lookups Connection graphs [ 521 were also developed prover by precomputing in a component clause appears the negation of the query, it can be removed However, connection clauses. Specifically, but say nothing about the relationship graph. Other work However, encoded of interpreted predicates. these walks are not guaranteed [ 18,831 has considered all the possible pairs of resolvable clauses. Clearly, for the purpose of focusing a theorem if a certain of to the component of the graph that is not connected graphs only capture a subset of the possible dependencies they only show that two clauses connected irrelevant). between to a link are unifiable, from the KB (i.e., it is strongly in the query-tree. Work on connection graphs has also not considered between clauses connected via longer paths in the following only certain walks on the graph. as are the paths semantics to encode valid derivations, identifying [ 42,43,84]. these methods The query-tree encodes exactly in two ways. First, by delimiting to speeding up inference a given space should search, thereby approach searching extend be searched, some search paths can be eliminated the optimal search strategy. Second, [42] query-tree provides in a principled way, unlike can be used as a basis atoms. interpreted about such a representation which require a graph-like the representations that an inference the space of derivations is finding optimal strategies that was considered The query-tree engine parts of the space that can be safely ignored. Another for and to for [ 841 and Greiner of the possible derivations of the query. The atoms it that are currently used. Consequently, from consideration when looking the methods described by Smith the actual space that needs to fully incorporate knowledge such techniques treats recursion and interpreted to complement for extending can be used representation The goal of Explanation Based Learning [69] is also to speed up inferences. new rules are added a single Adding to the knowledge base that compress sequences of inference rule. The key issue [30,68]. too many rules may have the inverse effect of slowing down inference. Etzioni is the utility of the added rules in this approach In EBL, into A.Z Levy et al. /Artijicial Intelligence 97 (1997) 83-136 121 space graph representation that much of the speedups obtained by EBL can be obtained by merely [ 291 has shown doing static analysis of the rules in the knowledge base. Using a tree-like of the rules how to glean from it new rules that were more effective EBL techniques. The problem in the knowledge base, called a Problem Space Graph (PSG) , he showed than those learned by standard not consider termination renaming of one of its ancestors. A key difference between is that the decision whether itself but also on its ancestry. As a result, number of rules, whereas of the predicates. it does in the rules. It also uses a very simple if it is a variable the PSG and the query-tree to expand a node in the PSG depends not only on the node in the the size of the query-tree may be exponential only in the arity the size of the PSG can be exponential to the query-tree. However, the semantics of interpreted in principle literals in the case of recursion; a node is not expanded is similar condition 8. Conclusions and ignore irrelevant is a key to identify information that it is possible The ability of a system about relevance of knowledge based systems. As a basis a formal in scaling up knowledge based systems and to future knowledge based applications. This article showed in to reason effectively a principled manner, and that such reasoning of knowledge relevance on a proof-theoretic properties of different definitions in the literature. Within discussed strong claims claims can be efficiently derived automatically inference. the performance regarding irrelevance based the analysis of the notion. The framework enabled us to compare that has two desirable properties; namely, impact the key questions the space of definitions, we identified and shed light on previous definitions for exploring framework the class of irrelevance reasoning, we presented and are guaranteed to lead to savings can significantly of irrelevance for analyzing irrelevance strong in We investigated in detail the problem of automatically deriving irrelevance deriving reasoning irrelevance of changes parts. We considered claims by considering the problem of automatically to be practical, we must derive that were based only on the rules in the KB and were independent Horn-rule knowledge bases. Our analysis was based on the observation relevance only a small and stable part of the knowledge base, while not assuming anything about irrelevance the unexamined claims of the ground facts. As a result, our algorithms were efficient, and the irrelevance claims derived were independent for automatically that encodes precisely which the basis for a sound and complete irrelevance semantics detection of additional general tool, the query-tree, is a finite structure tells us exactly the set of derivations of the query, and therefore of the query, thus providing for several classes of strong the is that it considers in the rules, which often enables the is a the query-tree facts. We described a novel claims. The query-tree claims. One of the key aspects of the query-tree in derivations procedure that can be used to compute several variants of strong the rules. Furthermore, rules and ground of the interpreted facts can appear to the ground that appear irrelevance. interactions irrelevance technique inference between deriving literals strong claims for that in order for 122 A.I: Levy et ul. /Artijicial Intelligence 97 (1997) 83-136 Finally, we presented filter out irrelevant building results knowledge bases. showed the query-tree experimental to facts often yields speedups of orders of magnitude, while the cost of results which showed the query-tree that using is negligible. Both the theoretical analysis and the experimental that our methods will scale up and be even more effective in larger There are several ways to extend in inference. A second direction important extension i.e., claims stating some probability. A clear understanding needed as well as algorithms them the query-tree. One particular the tree when rules contain is no termination there to find it is important captures most irrelevance [ 13,79,80] may be helpful condition limited cases recursion claims encountered in this context. is to incorporate probabilistic that some fact in the knowledge base is irrelevant this work. We mention only a couple here. One into the framework, to a query with is of the meaning of such irrelevance irrelevance claims claims for automatically deriving them and methods for exploiting for future research issue is to consider how to terminate is to consider extensions of of in general, of the query-tree, the construction function symbols. Although, completeness it does, and to find cases in which it through that will guarantee in which in practice. Recent work on termination Acknowledgements The authors would like to thank Ed Feigenbaum, Michael Genesereth, Matt Ginsberg in this paper. in is due to Jim Rice, without whom the experimental the material presented for many discussions results described about and Pandu Nayak Special this paper would not be possible or meaningful. thanks Appendix A. Proofs A. I. Properties of irrelevance The properties of irrelevance given in Theorem 6 are proved as follows. Proof of AO. This is an immediate corollary of the definitions. 0 Proof of Al. Suppose SI(@, 1+4,2, DIi, DO) holds and let A E 2. Therefore, ery derivation D E DCJ( A), DZi(@, D) holds and therefore, by the assumption claim, DZj(@, D) holds. Consequently, DZj(@, D) holds for every D E Do(A), SZ(@, +, 2, DZj, ‘DO) holds. The proof for WI is similar. 0 for ev- of the and so Proof of A2. The part about strong DZ(@, D) holds derivations D E 231 (A). For weak irrelevance, that if a property holds for some derivation derivation in D2 (A). 0 for all derivations D E D2( A), irrelevance follows from that if then DZ(@, D) holds also for all the observation the claim follows from the observation in Q (A), it will obviously hold for some A.E Levy et al. /Artijicial Intelligence 97 (1997) 83-136 123 Proof of A3, A4. These are immediate consequences of the definitions. Cl Proof of AS. This follows implies Base(D) # 42. 0 from the observation that if 41 E 42, then Base(D) # c5t Proof of A6. This follows immediately from the definitions. 0 Proof of A7. Suppose SZ( @r , t,b, 2, DZ, Do) r\SZ( @2, $, 2, DZ, Do) holds, and let A E 2, in Du( A). Since both DZ( @I, D) and DZ( @2, D) hold, also and D be a derivation and A E 2, DZ( @I U @2, D) holds. Because then for any D E Do(A) is similar. We simply SZ( @i u @2, +, 2, DZ, DO) holds. The proof for the second claim consider 0 the derivation D for which DZ( @2, D) holds, and DZ( @p1 U@2, D) will hold. this holds of $ from right from A U r such to left is immediate. For the other direction, that SZ( @, @, A, DZ2, V* (A) ) holds and suppose Proof of AS. The implication suppose derivation that r E D’. The only modification D’ of @ from A such appearance of r as a leaf in the proof tree by the derivation of r from A. The result a derivation of 9 from A that includes 4. Consequently, not hold. that 4 E D and 4 E @. We create a derivation to D is to replace every is SZ( a, $, A, DZ2, De (A) ) does in contradiction that D is a 0 A.2. Decidability of irrelevance The following rules (i.e., datalog) : shows that weak irrelevance is undecidable even for function-free Horn Lemma A.1. Let P be a set of function-free Horn rules and $ be an atomic query. Determining whether WZ( 4, +, 2:p, DZ2, @) holds when c$ is either a rule or a ground atomic fact even if the rules have no interpreted predicates. is undecidable in P facts derivable in P. An analogous Proof. We say that a rule r is redundant set of ground atomic from {P - r} U G. Let r E P and $ be a query. We prove ing that the claim WZ( r, @, 2p, 012, V*), when r is a rule, holds redundant for the case fact. In proof, suppose A E &, WZ( r, +, A, DZ2, De) holds. Therefore, is one that does not use r. Consequently, ing to $, redundant. Conversely, derivable, holds. facts G, the if, for any set of ground from P U G is the the same as the set derivable the lemma by show- if r is if and only that r#~ is a ground then for any knowledge base if there is a derivation of @, then there from P without chang- r is if G is that doesn’t contain r. Therefore, WZ( r, +, & , DZ2,D”’ ) r can be removed facts that means in the KB, and that for every A E &, that WZ( r, $, &J, DZ2, CD* ) holds, regardless if r is redundant, proof can be given there is a derivation of the ground the answer therefore, However, for datalog undecidable. it follows [82] theories even without from 0 that determining interpreted predicates. Therefore, weak irrelevance redundancy is undecidable of rules is 124 A.E Levy et al. /Artificial Intelligence 97 (1997) 83-136 The next lemma shows that strong is undecidable when we allow the rules In our discussion, we assume perfect model semantics of the irrelevance to have stratified negation. rules (cf. [89]).17 Lemma A.2. Let P be a set of function-free Horn rules with stratified negation and r E P. Determining whether SI( r, #, Sp, DI2,@) is undecidable, even if P has no interpreted predicates. if, for any given set of ground atomic in Pi and P2 respectively. A set of rules Pi Proof. Let PI and P2 be sets of function-free Horn rules and let p1 and p2 be distin- is said to contain guished query predicates a set of rules P2 (denoted by Pi > P2) facts G the set of tuples derived for the base predicates, in the relation the set of tuples derived to equivalent if Pi 2 P2 and P2 > Pi. Testing equivalence of rules is undecidable problem of a rule is an algorithm stratified negation equivalence in the relation p1 from Pt UG contains for p2 from P2UG. The two sets of rules are said sets to the irrelevance i.e., we show that if there set of rules P with for testing for deciding whether a rule r in a function-free in a set of rules with stratified negation, then we can design an algorithm of two sets of function-free the equivalence problem [ 821. We will reduce of two function-free is strongly irrelevant, rules. Let Pi and P2 be two sets of rules with query-predicates that Pi and P2 have distinct loss of sets of derived predicates. To to test whether Pt _> P2 and P2 > Pt. Let Q be the set p1 and ~2. Without generality we can assume test equivalence, of rules containing it is enough the rules of Pt and P2 and the rule r : PI (Xl A 72(X) * q(x) to q if and only where q is the query predicate of Q and it appears nowhere in Pi or P2. Note that Q is a stratified set of rules, since r is the only rule containing negation. Clearly, r is strongly irrelevant if and only fact is a member of p1 and if there is some set of ground not of ~2. In a similar fashion, we can create a set of rules with a rule r’ which will be is decidable strongly for rules with stratified negation, rules will be decidable. if P2 > Pi, since r will be used in a derivation if and only if Pi > P2. Consequently, facts in which some ground of sets of function-free if rule irrelevance then equivalence irrelevant 0 A.3. Proof of Theorem 11 In the proof we assume without loss of generality where 8 is a tuple of distinct variables. formula cy, we simply add a rule: 4(X) A cq * 4’Go and query q’(x). If the query originally that the query is of the form q(x) a constraint contained , I7 The perfect model of a set of rules is the one computed in a bottom-up fashion, stratum by stratum. A.E Levy et al. /Artificial Intelligence 97 (1997) 83-136 125 We will prove the theorem by considering encoded by the query-tree. Every derivation of the query can be viewed as a pair (d, 0)) where d is a symbolic derivation tree represents variables constraints that can be obtained by an assignment in the rules, and the interpreted on the base relations. Formally, to the variables of d. A symbolic derivation literals these constraints to its the integrity the symbolic derivations and 8 is an assignment all the derivation are the following: that satisfies trees (2) (1) that includes be the conjunction Let d be a symbolic derivation of the literals of interpreted , . . , r,, and let ci( Ui) ri. Let , Zk( &) be the leaves of d, and ici be the integrity constraints on the relation the set of derivations obtained formula, cd: tree d therefore satisfying the rule-nodes predicates 11(X,),... in Ii. A symbolic derivation by assignments the following constraint in the rule-node to its variables represents rl Cd=C,(U,) A.. .Ac,(ii,,) Aic,(X1) A...AiCk(Xk). We denote the relation represented for every node g E d by a formula expressing in g. We denote Note restriction of 8 to the variables of a node g in d will satisfy L,,(g) of symbolic derivation by the formula cd by Rd. We can define a label the projection of Rd onto the variables the the set that given an instance of d, (d, 0)) such that cd is satisfiable by l7,,,. this label by L,,(g). . We denote trees of q(X) Our proof will be based on showing of II,,,. The correspondence in II,,,, derivations symbolic derivations that T encodes precisely shown II,,,. that the query-tree encodes exactly the symbolic between in the lemma below, entails the derivations of the query and the that it suffices to show Lemma A.3. (1) A groundfact p(al,. . . , a,) can appear in a derivation of an instance of the if and only query q(X) Cfrom some set of ground facts for the base predicates) if there is some node g = p( X1 , . . . , X,,) in a symbolic derivation d E IL,,, such that al,. . . , a, satisjies L,,(g) . (2) A rule r E P can appear in a derivation of an instance of the query q(X) if and only if some symbolic derivation d E II,,, includes a rule-node containing the rule r. derivation ( 1), suppose Proof. To prove there exists a symbolic of cd on the variables XI,. i.e., the projection there a, satisfies L,,,(g), g. Therefore, tree d E IT,,, and . . , X, of al,..., the goal-node is some mapping 8 of the variables of d to con- stants such that 0(X,) = ai, for 1 < i < n, and such that applying B to d will satisfy facts for the base predicates, Go, ob- the constraint of 19 to d will yield a derivation tained by applying an instance the ground suppose a set of ground if g is the node facts Go. Conversely, from (d, S), and . . , u, will satisfy 8 to the leaves of d. Applying from that uses p( al, . . . , a,) as a pair facts G. The derivation do can be represented is a derivation do of an instance of q(X) that uses p(al , . . . ,a,) the set of ground to p(aj , . . . , a,), in d corresponding cd. Consider then at,. of q(X) there L,+(g). (2) follows from same rules as its ground derivation the observation that a symbolic derivation will have exactly the instances. (cid:144)i 126 A.Y Levy et al. /Artijicial Intelligence 97 (1997) 83-136 To show that T encodes precisely the derivations nsa,, we proceed in a two phase fashion we show that given a symbolic derivation be computed We then show that the construction all symbolic derivation the following procedure pressions cs( g) , cb (g) , and cf (g) denote constraint in the node g). (bottom-up applied of the query-tree exactly mimics trees (Observation A.5 and Lemma A.6). Specifically, to the nodes of a symbolic derivation followed by top-down) in two steps. First, tree d, the labels L,,,(g) of a node g in d can (Lemma A.4). for consider tree d (the ex- formulas on the variables appearing this computation (1) Initialize: Compute co(g) as follows: ca(l;) =ici(Xi) fortheleaves if g is an internal goal-node if r is the rule-node ri then co(r) = c,. (2) Bottom-up: Compute cb(g) as follows: Zi(X1),...,Zk(Xk) then co(g) = TRUE. ofd. if g is a leaf goal-node in d then cb(g) = co(g). if r is a rule-node with children gt , . . . , g, then cb(r) = CO(r) ACb(gl) A”‘ACb(&h. if g is an internal goal-node with child rule-node r then cb( g) = Projection of cb( r) on the variables of g. (3) Top-down: Compute cf(g) = Cb(root(d)). as follows: cf(root(d)) if r is a rule-node with father goal-node g and children gl, . . . , g, then cf(r) = cf(g) A Cb(r). for 1 6 i < m, cf(gi) = Projection of cf( r) on the variables of gi. Lemma A.4 Let d be a symbolic derivation tree, For every node g E d, cf (g) = Ls&g). the constraint formula c has one to refer to the relations themselves. The formulas, cl and c2 is represented by the join of their corresponding to the formulas by the constraint of two constraints the tuples satisfying in c. In the proof it is more convenient rather Proof. The relation R, representing for every variable attribute represented conjunction relations, denoted by R,, w R,,. Recall Closure property, we can express a join of two relations, on a subset of its variables by co(g),cb(g) and cf(g) projection projection of R on the attributes appearing in fZ. We denote and Rf(g) as a sentence by Ro(g),Rb(g) that since the constraint in the node g. than respectively. We denote of a relation R on a subset of its attributes R by RI,. RI, denotes the the language L satisfies the and a projection of a relation represented the relations Let rl, . . . , rl be the top-down ordering of the rule-nodes thattheglobalconstraintondiscd=co(rl)A...Aco(rr)Aco(ll)A.../\co(lk), top-down phase of the computation Recall or in notation of relations, Rd = Ro(rl) W ... w Ro(rl) W Ro(ll) W ... W Ro(lk). we define a sequence of relations SO,. . . , Sl as follows: in d that was used in the of the cf labels, and 11, . _ . , lk be the leaves of d. l SO = Rb(root(d)) 0 Si=Si_l W Rb(li) A. E L.evy et al. /Art@cial Intelligence 97 (1997) 83-136 127 We prove that the following properties hold for the sequence: Dl . Sl = Rd, i.e., the final relation in the sequence is the same as the global constraint on d. that appear in Si, then D2. If _%i is the set of variables D2.1. Si+tlz, = Si, and D2.2. $1,; = Rf(rj). This means the sequence, attributes does not change. that once a set of attributes appears the projection of the subsequent in an intermediate in in the sequence on these relation relations The lemma follows from properties Dl and D2 as follows. Let _%i be the variables that Rf( ri) = SIIz,, and is is the way L,,,(ri) ri E d. It follows from D2 that Sl = Rd. Therefore, Rf(ri) = RdlRi holds which the rule-node in that appear by Dl, defined. Proof of Dl. Note obtained that Sl = Rb(r1) w . . . w Rb( rl) (i.e., in the bottom-up phase). Therefore, it is enough . w Rb (rl) . To show this we prove that for every rule-node the join of the constraints to show that Rd = &,( t-1) w r in the tree and goal-node g the following hold: > Rdlr, &(g) (a) R,(r) C: Ro(r), Rb(g) L Ro(g), and (b) &(r) For each j, 1 < j < k there exists an i, 1 < i 6 1 such that ri is the father of Zj and since Rd = Ro(r1) w +.. WI Ro(rl) W Ro(Zl) W the properties of the join operation and therefore Rb(ri)l[, C Ro(lj). Therefore, . . . w Ro (Zk) , (a) gives us that Sl c Rd. From 2 R&. from (b) we get $ > Rd. Hence, $ = Rd. for the leaves of d. Furthermore, Note that (a) and (b) hold trivially if g is the father first goal-node of r, then the second parts of (a) and (b) for r on the parts, since the relation variables in d, and we do so by induction on the elements of t-1,. . . , r[ in reverse order (i.e., the bottom-up order). for g is the projection of the corresponding follow from their respective to prove the claim for the rule-nodes in g. Therefore, it is enough relation all the rule nodes whose children are all leaves, follows The base case, including from the definitions. immediately Assume (a) and (b) hold for all rule nodes ri+t , . . . , q. We need to show that it (a) holds because Rb(Q) holds for ri. Claim (specifically, children of ri. By the induction definition of &, Ro(ri) > Rdlri. Therefore, the bottom-up is the join of Ro(ri) with other relations labels of its children). To prove (b) , let gl , . . . , g,, be the assumption, Rb(gi) > Rdlg, for each gi. Clearly, by the since Rb(ri) =Ro(Q) w R&t) w ... w &(g,), it follows that Rb(ri) > Rdl,.,. 0 Proof of D2. By induction on i. For the base case i = 0, we note Rb( root( d)) Moreover, is the projection of Rb( r-1) on since Rf( r-1 ) = Rb( t-1 ), D2.2 holds too. that RI is simply Rb( t-1 ). Therefore, the the variables of root(d), D2.1 holds. since 128 A. Z Levy et al. /Art@cial Intelligence 97 (1997) 83-136 We assume D2 holds for all j < i, and prove D2.2. Let g be the father of ri+t and ri,, be the father of g (where assumption, &,, 1 r,. = Rf( rio ), and Si 1 r,O = Rf (rio ) . Therefore, inductive for the goal node g, i.e., Sils = Rf(g). Moreover, that it holds for i + 1. We first prove io < i). By the the same holds However, since the variables common commute, the projection i.e., to ri+t and to Si are only those in g, the join and Equivalently, the variables appearing because of D2.2, it Rf(ri+l) = (& w Rb(ri+l))Ir;+l =&+llr,+r To show D2.1, it is enough to show that SJs = Si+t Is, since in g are the only ones common suffices to show to Si and &,(ri+t). Rj(ri+l) IK = Rj(g). The proof is based on the following property of relational algebra: If A = RI,, and B C A then (R w B) Ix = B. In our case, Rb(g) = Rb(ri+l) lg. (A.11 (A.2) Clearly, Rf(r) C: Rb(r) and Rb(r) jg C Rb(g), and therefore, since Rf(g) = Rf(r) follows that lg it Rj(d C h(g). Finally, recall that Rf(ri+~) = Rf(g) w &(ri+t). Therefore, tails (A.l). the above observation 0 (A.3) (A.4) together with Eqs. (A.2)) (A.3) and (A.4) en- The importance of Lemma A.4 is that we can now show that the construction exactly mimics that in the bottom-up query-tree vation shows predicates we compute are all the possible tion trees. The observation symbolic derivation tree d: the two phase computation phase of constructing of the of labels. The following obser- the adorned labels of the form cb (g) in symbolic deriva- in a induction on the nodes the query-tree follows by a simple bottom-up Observation A.5. Let d be a satisfiable symbolic derivation. l For every goal-node g E d, of the predicate p, where c is the standard form of cb(g) (using the arguments of p) , pc is an adorned predicate in Pl. A.E Levy et al. /Arr$cial Inrelligence 97 (I 997) 83-136 129 l Suppose r is a rule-node in d containing the rule 4,(X,) A*. . A qm(~“t) A cr * P(X). Suppose r’s father is g and children are gl , . . . , g,, , then the following rule is in 73: r’ : #(“I) (j$ ) /j . . . A q$R”“(~nl) A q,(r) + pCbcg)(x). Note that r and r’ difSer only in predicate names, but have the same variable pattern. Given this observation, exactly the derivations the following encodes in n,,,. Theorem 11 follows from this lemma and Lemma A.3. lemma will show that the query-tree Lemma A.6 A node g with label L,,,(g) appears in some symbolic derivation tree if and only if there exists a node gl in the query-tree T and an isomolphism is equivalent -+ Variables(gl ), such that 4(g) = gl and +( L,,(g)) in n,, 4 : Variables(g) to the label of g] in T. Proof. d E II,,, conditions (ifl To show the if direction, we show that every symbolic derivation is encoded by T using an encoding mapping @,, such that in addition of Definition 9, 1/1 is also label-preserving, i.e., tree to the l If 8 is the variable isomorphism between g and cc/(g),18 L(q(g)) = O(L,,,(g)) for every node g E d. Let d be a symbolic derivation tree by mimicking mappings $ of the nodes as we go along. the execution of procedure build-forest. We construct tree in I7,,,. We show that d is encoded by the query- the encoding that qc is one of the adorned predicates We begin with the root of d and its child rule-node r. Let c = cb( root( d) ) . Observa- in Pl, and that there is a rule r] tion A.5 entails is Q. Therefore, procedure in PI that is a refinement of the rule in r, and its consequent build-forest will create a node g of the form Q(8) with label c, and it will expand the child goal-nodes gl , . . . , g,. The label of the rule-node g with the rule r-1, creating will be cb( r] ), and the labels of gl , . . . , g,, will be the respective projections of cb (r] ) on the variables in gi’s. We define + to map root(d) to g, to map r to the child of g formed by the expansion with rl , and to map the children of r to the respective Since L,,( root(d)) = cb( root(d)) for root(d), label preserving in exactly also for the children of r (because the same way as the label of their image and similarly and L(g) = c, the mapping @ is label preserving for its child rule-node. By Lemma A.4 it follows that Cc, is children of e(r) , gl , . . . , g,,,. the label of its children in T). is computed in d, r-1,. . . , r,. We Ic, for all encoding mapping We proceed by induction on a top-down ordering of rule-nodes that we have built a label-preserving r] , . . . , ri_1, and their children goal-nodes. Furthermore, our induction that all literals in rules have distinct variables in every argument position. Therefore, 0 between the variables in g and 1+5(g). such that @l(g) = B(g). assume by induction the rule-nodes ‘s Recall that we assumed there is an isomorphism 130 A.k: Levy et al. /Artificial Intelligence 97 (1997) 83-136 also states that the goal-node $(g) the adornments are removed in the query-tree is a node of the predicate in the end of procedure build-forest). Note assumption P ‘b(R) (before that this assumption Let g be the father of ri in d, and assume holds for the base case. is a node of the predicate pCb@). Consider that g is a node of the predicate p. By first the case It would have been expanded with the in the query-tree. assumption, the inductive in which $(g) was expanded rule t/l(g) r’ : q:‘(Xl) A. ’ ’ A 4% (Xn,) A Cb( Ti) * pcbcg) (X) rule-node the resulting ri to the node . . , c,, are the bottom-up in li. Denote condition EO of Definition 9). Note that after removing the rule in li will be exactly where cl,. of the rule 1+4 will map satisfying nodes in the query-tree, by condition El ) . Furthermore, 1+4 will be label-preserving of L,, (r-i) and its children. Finally, note that if g is a child of mimics Ti and is a node of the predicate p, then +(g) will be a node of the predicate pCb(R), as required by our inductive labels of the children of g, and r’ is a refinement in the query-tree by r. The mapping r and the subgoals of ri to the subgoals of Y (therefore from the same as in $( ri) (as required condition E3 is also satisfied by @. As in the base case, of L($( ri)) on ri and its children because the computation the computation the adornments assumption. the previous case, except of the same if, We prove In the case that refined predicate), they are goal-nodes ti( g) was not expanded to the children of Y. Because L( 9 (g) ) is isomorphic it would be because in the query-tree, In that case, r would be a child of Eq( (/I( g) ) , and the children of to L( Eq( $ (g) ) ) the its Eq( Cc, (g) ) is expanded. Yi will be mapped (and same way as in definition. embeddings of symbolic (only image of an encoding derivations mapping can be constructed as follows. We begin with one of the roots in the forest. For every goal-node of a derived predicate (if it was expanded) in the embedding, we choose either one of its child rule-nodes or one of the children of its expanded rule-node, we choose children (if it was not expanded). For every remain without this part by considering the query-tree T. An embedding its children. Only goal-nodes of base predicates for some symbolic derivations. Every embedding follows second clause the possible is a possible that E3 is satisfied in an embedding. the proof equivalent in in in Therefore, to prove the claim, we show that for every embedding d’ in T, there exists encoding the symbolic derivation the same structure as d’ (i.e., the same structure of rules). Following a symbolic derivation d E 17,,, such that d’ is the image of a label-preserving mapping $ from d to T. To see that this holds, simply consider d that has exactly the proof of the if-direction will show that d is encoded by the query-tree, image unsatisfiable and that its does not contain nodes with labels, d must be a symbolic derivation is precisely d’. Furthermore, the query-tree in n,,,. since [7 A.4. Proof of Theorem 12 The theorem is proved by reducing (ATM) nating Turing machine [ 171 to the problem of finding irrelevance the acceptance problem of a linear-space alter- of rules. A. Y Levy et al. /Artijicial Intelligence 97 (1997) 83-136 131 the state of the machine is similar of an ATM The execution id’s, each describing i.e., the contents of the input chine. An ATM gives a pair of moves ery state state q leads q is an or-state, leads successors the successors of an and-state states. to a Turing machine, is described by a sequence of instantaneous except at consecutive descriptions, stages of the execution, tape, the location of the head and the state of the ma- function ev- then an id having to acceptance. If if either one of its that are or-states, and the successors of an or-state are and- of state and symbol. Furthermore, If q is an and-state, its successors state q leads to acceptance in the sense its transition alternate lead that of the input to acceptance then an to acceptance. The states of the machine id having if both is either an and-state or an or-state. for each combination descriptions an alphabet Instantaneous (id’s) are represented by a symbol for every cell on the (s, 6) symbol tape. The symbol can either be a symbol id, all cells including that is on the tape in that state, and the cell on but one contain which the alphabet symbol in that cell and the internal state of the machine. The union of the alphabet symbols and composite symbol 6 and a state of the machine in the alphabet, or a composite the head is placed contains symbol containing s. In a legal the alphabet a composite symbols symbol is denoted by B. is based on representing tape, input the size of the id’s as tuples of a predicate in IZ. Each cell the id, whose arity by a id is represented of size IBI. The variable X appears to the symbol appearing of B). All other columns id is 1 BI n. The in the block in the position in the cell (we assume some arbitrary ordering the arity to denote blocks of variables the variable W. Thus contain tuples Xi are used to one cell. The tuple Ui denotes a block of variables representing a i, (i.e., X appears in the position of i in B and all other positions The reduction in is linear block of variables corresponding on the elements of the predicate corresponding cell with the symbol are W). emulates from the accepting Intuitively, we construct a set of rules, whose bottom-up computation of M backward id to the initial one. The atom id(X) from the rules if and only if X describes a legal id and leads to acceptance. a set of rules as follows. First states. For example, suppose is in state is states the head then for every i (1 < i < n) and every input symbol b, computation is derivable Given an ATM, M, and an input Xinit, we construct we need rules representing 6( c, q) = { (dl, ~1, R) , (d2, ~2, L)} q and the symbol c is under obtained by writing to the right. If q is an or-state, we have the following the head of the tape, then one of the successor to state st and moving is a transition of M, that is, if the machine the symbol dl on the tape, moving transitions between consecutive rules: the id(X1,...,Xi-l,Udl,U(sl,b),Xi+2,...,Xn) id(X1,...,Xi-l,U(c,cl),Ub,Xi+2,...,Xn) id(Xl,..., Xi--2~U(S~,b)~Ud~~Xi+l~...~Xn) id(Xl,..., Xi-29 ub, U(c,q), Xi+1 7. . ., Xn) * * If q is an and-state the theory contains then for every i, (1 < i < n) and every pair of input symbols bt, b2, the following rule: 132 A. Y Levy et al. /Arhjicial Intelligence 97 (I 997) 83-136 id(X1,..., xi-23 ubi 9 udlv U(sl,bz) I xi+2*. . , 3 Xn) A id(X1,...,Xi-2,U~S2,bl)‘Ud2’UbZ’Xi+2,...,Xn) * id(Xl,. . ., Xi-29 ubl, U(c,q) , ub2 1 Xi+23 * . * > Xn 1. To complete the set of rules, a few more rules are necessary. Denote by Xfinal the id (which we can assume, without and by Xinit the tuple representing the initial id. Rl places loss of generality the initial state tuple representing M’s accepting is unique), as a subgoal of the query: RI: id(Xinir) + p(X, W) R2 and R3 will lead from the accepting EDB predicate. state to an EDB node. Note that e is the only R2: a(X, W) =s id(Xfinal) R3: (X # W) A e(X, W) + a(X, W) We denote the reduction. the set of rules by P. The following theorem establishes the correctness of Theorem A.7. SZ( RI, p, 2p , D12, Dp ) holds if and only if M does not accept its input with the initial state Xinip from include if both instance a ground is obtained the ground two constants. to X and W. Furthermore, the fact that in all rules, all variables appearing that any derivation of p (X, W) will contain only the only constants since a derivation must instance of an id subgoal can be unified with the same in the body of the in the derivation will be those the rule R3, these if x the head id (i.e., x for X and w for W). the ground (or if one of them does not contain exactly it will force X and W to unify. l9 Therefore, because of the Proof. We first note This follows rule appear in the head too. Therefore, assigned constants must be distinct. We will refer to them as x and w hereafter. Moreover, and w are distinct, of a rule only instance the ground This can be seen by considering instance one occurrence way the transition descriptions is the node describing possible an EDB subgoal accepting there is execution of M that will accept Xinit. a to get to because rules R2 and R3, every derivation of p must describe an then if p has some derivation, the subgoals of any id node are the instantaneous in a derivation if the top id goal-node then every partial derivation of p describes of its successor states. Consequently, tree of the ATM M. Therefore, in a position of the X variable from the head by substituting trace of M. Therefore, in the id. If it differs and the head represent rules are written, the only way each block is through the initial execution execution of X), state, there from then Conversely, suppose M accepts will produce a symbolic-derivation its input. A simple of p(X, W) which must contain RI. trace of the machine’s 0 execution ly This assumes each block is at least of size 3. If this does not hold, we simply add another dummy column to each block, and leave it unchanged in all the rules. to implement l-15. logic A. E Levy et ul. /Artificial Intelligence 97 (1997) 83-136 133 References [ I ] S. Abiteboul and R. Hull, Data functions, datalog and negation, in: Proceedings ACM SIGMOD 1988 International Conference on Management of Data (1988). [2 ] S. Addanki, R. Cremonini and J. Penberthy, Reasoning about assumptions in graphs of models, in: Proceedings IJCAI-89, Detroit, Ml ( 1989). [ 31 A.R. Anderson [ 41 Y. Arens, CA. Knoblock and N.D. Belnap, Entailment (Princeton University Press, Princeton, NJ, 1975). and W.-M. Shen, Query reformulation for dynamic information integration, Internat. J. Intelligent and Cooperative information Systems 6 (2/3) (1996) 99-130. [ 51 A. Avron, Whither 161 F. Baader and B. Hollunder, A terminological logic?, J. Philos. Logic 21 (1992) 243-281. knowledge representation relevance inference in: Proceedings Workshop on Processing Declarative Knowledge, PDK-91, Lecture Notes in system with complete algorithm, Artificial Intelligence (Springer, Berlin, 1991) 67-86. [7 J E Bacchus, A.J. Grove, J.Y. Halpem and D. Koller, Statistical foundations for default reasoning, in: Proceedings IJCAI-93, Chambery, France ( 1993). 18 1 E Bancilhon, D. Maier, Y. Sagiv and J. Ullman, Magic sets and other strange ways programs, in: Proceedings 5th ACM Symposium on Principles of Database Systems ( 1986) [9] C. Beeri and R. Ramakrishnan, On the power of magic, in: Proceedings 6th ACM Symposium on Principles of Database Systems ( 1987) 269-283. 1 lo] J.A. Blakeley, N. Cobum and PA. Larson, Updating derived relations: Detecting irrelevant and autonomously computable updates, Trans. Database Systems 14 (3) ( 1989) 369-400. [II] D. Bobrow, ed., Qualitative Reasoning about Physical Systems (North-Holland, Amsterdam, 1 12 1 A. Borgida and P Patel-Schneider, A semantics and complete algorithm for subsumption in the CLASSIC 1984). description logic, J. Art$ Intell. Res. 1 ( 1994) 277-308. [ 131 A. Brodsky and Y. Sagiv, On termination of datalog programs, in: J.M. Nicolas W. Kim and S. Nishio, eds., Deductive and Object-oriented Databases (North-Holland, Amsterdam, 1990) 47-64. [ 141 M. Bruynooghe, D. De Schreye and B. Krekels, Compiling control, J. Logic Programming 6 ( 1989) 135-162. [ 15 ] M. Bruynooghe, D. De Schreye and B. Martens, A general criterion infinite unfolding during in: Proceedings International Symposium on Logic Programming, for avoiding partial deduction of logic programs, 117-131. Paris (1991) 1161 R. Carnap, Logical Foundations of Probability (University of Chicago Press, Chicago, 1171 A. Chandra, D. Kozen and L. Stockmeyer, Alternation, [ 181 CL. Chang, Resolution plans in theorem proving, 1 191 W.J. Clancey, The advantages of abstract control knowledge in expert system design, J. ACM 28 (1) (1981) 114-133. in: Proceedings IJCAI-79, Tokyo (1979) 143-148. IL, 1950). in: Proceedings AAAI-83, Washington, DC (Morgan Kaufmann, Los Altos, CA, 1983) 74-78. 1201 P. Cousot and R. Cousot, Abstract interpretation and application to logic programs, J. Logic Programming 13 (2-3) (1992) 103-179. I21 ] A. Darwiche, A logical notion of conditional independence, Arf$cial Intelligence 97 ( 1997) 45-82 (this issue). [ 221 R. Davis, Diagnostic 410. reasoning based on structure and behavior, Artificial Intelligence 24 ( 1984) 347- [ 231 D.L. Draper, Relevance measures of the AAAI Fall Symposium on Relevance (November 1241 M. Dunn, Relevance logic and entailment, for localized partial evaluation of belief networks, 1994). in: D. Gabbay and E Guenthner, in: Working Notes eds., Handbook of Philosophical Logic, Vol. III. Alternatives to Classical Logic (Reidel, Dordrecht, The Netherlands, 1986) 117-224. [ 251 C. Elkan, A decision procedure for conjunctive query disjointness, in: Proceedings 8th ACM Symposium on Principles of Database Systems ( 1989). [26] C. Elkan, Independence of logic database queries and updates, in: Proceedings 9th ACM Symposium on Principles of Database Systems ( 1990) 154- 160. symmetry, 127 I T. Ellman, Abstraction via approximate in: Proceedings IJCAI-93, Chambery, France (1993) 916-921. 128 1 0. Etzioni, Why PRODIGY/EBL works, in: Proceedings AAAI-90, Boston, MA ( 1990). 134 A. E Levy et al. /Artificial Intelligence 97 (1997) 83-136 search-control 1291 0. Etzioni, Acquiring [30] 0. Etzioni and S. Minton, Why EBL produces overly-specific knowledge via static analysis, Arti$cial Intelligence 62 ( 1993). knowledge: a critique of the PRODIGY approaches, in: Proceedings Machine Learning Conference, Aberdeen, Scotland interface to the intemet, Comm. ACM 37 (7) (1994) 72-76. ( 1992). 1311 0. Etzioni and D. Weld, A softbot-based [ 321 B. Falkenhainer and K. Forbus, Compositional modeling: finding the right mode1 for the job, ArtQicial Intelligence 51 (1991) 95-143. [33] R. Fikes, M. Cutkosky, T. Gruber and .I. Van Baalen, Knowledge sharing technology, project overview, Knowledge Systems Laboratory Tech. Rept. No. KSL 91-71, Stanford, CA (1991). [ 341 P GZirdenfors, On the logic of relevance, Sythese 37 (1978) 351-367. 1351 P Gtidenfors, Knowledge in Flux: Modeling the Dynamics of Epistemic Srates (MIT Press, Cambridge, MA, 1988). 1361 H. Geffner and J. Pearl, A framework in: H.E. Kyburg, R. Loui and G Carlson, eds., Knowledge Representation and Defeasible Reasoning (Academic Press, Dordrecht, The Netherlands, for reasoning with defaults, 1990). [37] M.R. Genesereth, An overview of metalevel architectures, (Morgan Kaufmann, Los Altos, CA, 1983) 119-123. in: Proceedings AAAI-83, Washington, DC [38] M.R. Genesereth, An agent-based framework for software interoperability, in: Proceedings Software Technology Conference, Los Angeles, CA ( 1992). [ 39 ] M.R. Genesereth and NJ. Nilsson, Logical Foundations of Artificial Infelligence (Morgan Kaufmann, Los Altos, CA, 1987). [40] E Giunchiglia [ 411 R. Greiner, RLL-1: a representation language 80-9 (Working Paper), Stanford, CA ( 1980). and T. Walsh, A theory of abstraction, Artificial Intelligence 56 (3) (1992). language, Stanford Heuristic Programming Project, HPP- 142 1 R. Greiner, Finding optimal derivation (1991) 95-116. 50 (I) strategies in a redundant knowledge base, Artijicial Intelligence [ 43 ] R. Greiner, Learning efficient query processing strategies, in: Proceedings I1 th ACM SIGACT-SIGMOD- SIGART Symposium on Principles of Database Systems, San Diego, CA ( 1992). 1441 R. Greiner and I. JuriSica, A statistical AAAI-92, San Jose, CA ( 1992). approach to solving the EBL utility problem, in: Proceedings 1451 P.J. Hayes, Computation and deduction, in: Proceedings 1973 Mathematical Foundations of Computer Science Symposium (Czechoslovakian Academy of Sciences, 1973). [ 461 Y. Iwasaki and A.Y. Levy, Automated mode1 selection for simulation, in: Proceedings AAAI-94, Seattle, WA (1994) 1183-l 190. [47] J.M. Keynes, A Treatise on Probability (Macmillan, London, 1921). [ 481 M. Kifer, On safety, domain and capturability independence International Conference on Data and Knowledge Bases, Jerusalem [49] A. Klug, On conjunctive queries containing [ 501 CA. Knoblock, Learning abstraction hierarchies inequalities, of database ( 1988). J. ACM 35 ( 1) (1988) 146-160. queries, in: Proceedings for problem solving, in: Proceedings AAAI-90, Boston, MA (Morgan Kaufmann, Los Altos, CA, 1990). [ 5 1 ] C.A. Knoblock Gathering Intelligence, 1995). and A.Y. Levy, eds., Working Notes of the AAAI Spring Symposium on Information from Heterogeneous Distributed Environments (American Association for Artificial [52] R. Kowalski, A proof procedure using connection graphs, J. ACM 22 (4) [ 531 G. Lakemeyer, A logical account of relevance, in: Proceedings IJCAI-95, Montreal, Que. (1995) 853- (1975) 572-595. 859. 1541 D.B. Lenat, R. Davis, J. Doyle and M.R. Genesereth, Reasoning in: E Hayes-Roth, D.A. Waterman and D.B. Lenat, eds., Building Expert Systems (Addison Wesley, Reading, MA, 1983). systems, Ph.D. Thesis, Stanford University, [ 551 A.Y. Levy, about reasoning, in knowledge reasoning based Irrelevance Stanford, CA ( 1993). [ 561 A.Y. Levy, Creating ( 1994) 588-594. abstractions using relevance reasoning, in: Proceedings AAAI-94, Seattle, WA [ 571 A.Y. Levy, R.E. Fikes and Y. Sagiv, A proof-theoretic irrelevance: in: Working Notes of the AAAI Fall Symposium on Relevance (November applications, approach to foundations 1994). and A. Z Levy et al. /Arttficial Intelligence 97 (1997) 83-136 135 158 1 A.Y. Levy, I. Singh Mumick and Y. Sagiv, Query optimization by predicate move-around, in: Proceedings 20th VLDB Conference, Santiago, Chile ( 1994) 96-107. I59 1 A.Y. Levy, I. Singh Mumick, Y. Sagiv and 0. Shmueli, Equivalence, query-reachability and satisfiabihty in datalog extensions, of Database Systems, Washington, DC (1993) 109-122. in: Proceedings 12th ACM SIGACT-SIGMOD-SIGART Symposium on Principles [ 601 A.Y. Levy, A. Rajaraman and J.J. Ordille, Query answering algorithms for information agents, in: Proceedings AAAI-96, Portland, OR ( 1996) 40-47. [ 611 A.Y. Levy and Y. Sagiv, Constraints and redundancy in Datalog, in: Proceedings Zlth ACM SIGACT- SIGMOD-SIGART Symposium on Principles of Database Systems, San Diego, CA ( 1992) 67-80. [62] A.Y. Levy and Y. Sagiv, Exploiting IJCAI-93, Chambery, France (1993) [ 631 A.Y. Levy and Y. Sagiv, Queries irrelevance 138-144. reasoning to guide problem solving, in: Proceedings independent of updates, in: Proceedings 19th VLDB Conference, Dublin, Ireland (1993) 171-181. [ 641 A.Y. Levy and Y. Sagiv, Semantic query optimization in: Proceedings 14th ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, San Jose, CA ( 1995) 163- 173. in datalog programs, [ 651 A.Y. Levy, D. Srivastava and T. Kirk, Data model and query evaluation in global information systems, J. Intelligent Information Systems (Special (2) (1995). Issue on Networked Information Discovery and Retrieval) 5 1661 N. Limestone, Learning quickly when irrelevant attributes abound: a new linear-threshold algorithm, Machine Learning 2 (1988) 285-318. [67] J.W. Lloyd and J.C. Shepherdson, Partial evaluation in logic programming, J. Logic Programming 1 I (1991) 217-242. [ 681 S. Minton, Quantitative results concerning the utility of explanation based learning, in: Proceedings AAAI-88, St. Paul, MN (1988). [ 69 1 S. Minton, J. Carbonell, C. Knoblock, D. Kuokka, 0. Etzioni and Y. Gil, Explanation based learning: a problem solving perspective, Artijicial Intelligence 40 ( 1989) 63-l 18. [ 701 J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference (Morgan Kaufmann, San Mateo, CA, 1988). [ 7 I ] J. Pearl, System Z: a natural ordering of defaults with tractable applications reasoning, in: M.Y. Vardi, ed., Theoretical Aspects of Reasoning about Knowledge (Morgan Kaufmann, Los Altos, CA, 1990) 121-135. to nonmonotic [72] C. Petalson, The BACK system: an overview, 1731 D. Plaisted, Theorem proving with abstraction, Artificial Intelligence 16 (1981) 47-108. [ 741 R.B. Rao, R. Greiner and T. Hancock, Exploiting in: Proc. SIGART Bull. 2 (3) the absence of irrelevant (1991) 114-119. information: what you don’t know can help you, in: Working Notes of the AAAI Fall Symposium on Relevance (November 1994). 1751 I.S. Rombauer 1761 S. Russell, The complete and M. Rombauer-Becker, Joy of Cooking (Merrill, New York, 1975). guide to MRS, Tech. Rept. KSL-85-12, Knowledge Systems Laboratory, Department of Computer Science, Stanford University, CA ( 1985). [77] E.D. Sacerdoti, Planning [ 781 Y. Sagiv and M. Yannakakis, Equivalence ( 1981) 633-655. J. ACM 27 (4) operators, in a hierarchy of abstraction among spaces, Artificial Intelligence 5 ( 1974) 115-135. relational expressions with the union and difference testing effective [791 Y. Sagiv, On in: C. Delobel, M. Kifer and Y. Masunaga, eds., Proceedings 2nd International Conference on Deductive and Object-Oriented Databases, Munich, Germany [SO] Y. Sagiv, A termination in: V. Saraswat and K. Ueda, eds., Proceedings 1991 test for logic programs, of magic programs, (1991) 244-262. computability International Symposium on Logic Programming (MIT Press, Cambridge, MA, 1991) 518-532. [ 8 I] A. Segre and C. Elkan, A high-performance explanation-based learning algorithm, Artificial Intelligence 69 (1994) I-50. [82] 0. Shmueli, Equivalence [ 83 1 S. Sickel, A search technique of datalog queries for clause is undecidable, interconnectivity J. Logic Programming 15 ( 1993) 231-241. ( 1976) graphs, IEEE Trans. Comput. 25 (8) 823-835. [ 84 I D. Smith, Controlling inference, Ph.D. Thesis, Stanford University, Stanford, CA ( 1986). 136 A.1 Levy et al. /Artificial Intelligence 97 (1997) 83-136 1851 D.A. Smith and T.J. Hickey, Partial evaluation of a CLP language, in: Proceedings lnternafional Symposium on Logic Programming ( 1990) 119- 138. [ 861 D. Srivastava and R. Ramakrishnan, Pushing constraint selections, J. Logic Programming 16 (3-4) (1993) 361-414. 187 ] D. Submmanian and M.R. Genesereth, The relevance of irrelevance, in: Proceedings IJCAI-87, Milan, Italy (Morgan Kaufmann, Los Altos, CA, 1987). [SS] D. Subramanian, A theory of justified reformulations, Ph.D. Thesis, Stanford University, Stanford, CA (1989). [ 891 J.D. Ullman, Principles of Database and Knowledge-base Sysrems, Vols. I and II (Computer Science Press, Rockville, MD, 1989). [ 901 J.D. Ullman, Database Theory Information (1997). integration using logical views, in: Proceedings Infernational Conference on [91] A. Van Gelder, A message passing framework for logical query evaluation, in: Proceedings ACM SIGMOD Internutional Conference on Management of Data ( 1986) 155-165. [92] M.Y. Vardi, Automata theory ofDatabase Systems (PODS) for database (March 1989) 83-92. theoreticians, in: Proceedings 8th Symposium on Principles 1931 L. Vieille, Recursive query processing: the power of logic, Theoret. Comput. Sci. 69 ( 1989) l-53. 