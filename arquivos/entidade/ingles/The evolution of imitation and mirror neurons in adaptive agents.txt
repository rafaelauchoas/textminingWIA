The Evolution of Imitation and MirrorNeurons in Adaptive AgentsElhanan Borenstein a,∗ Eytan Ruppin a,baSchool of Computer Science, Tel Aviv University, Tel-Aviv 69978, IsraelbSchool of Medicine, Tel Aviv University, Tel-Aviv 69978, IsraelAbstractImitation is a highly complex cognitive process, involving vision, perception, repre-sentation, memory and motor control. The underlying mechanisms that give rise toimitative behavior have attracted a lot of attention in recent years and have been thesubject of research in various disciplines, from neuroscience to animal behavior andhuman psychology. In particular, studies in monkeys and humans have discovered aneural mirror system that demonstrates an internal correlation between the repre-sentations of perceptual and motor functionalities. In contradistinction to previousengineering-based approaches, we focus on the evolutionary origins of imitation andpresent a novel framework for studying the evolution of imitative behavior. We suc-cessfully develop evolutionary adaptive agents that demonstrate imitative learning,facilitating a comprehensive study of the emerging underlying neural mechanisms.Interestingly, these agents are found to include a neural “mirror” device analogousto those identified in biological systems. Further analysis of these agents’ networksreveals complex dynamics, combining innate perceptual-motor coupling with ac-quired context-action associations, to accomplish the required task. These findingsmay suggest a universal and fundamental link between the ability to replicate theactions of other (imitation) and the capacity to represent and match others’ actions(mirroring).Key words: Mirror-neurons, Imitation, Evolution, Agents, Context-basedimitation∗ Corresponding author.Email address: borens@post.tau.ac.il (Elhanan Borenstein).URL: http://www.cs.tau.ac.il/~borens/ (Elhanan Borenstein).Preprint submitted to Elsevier Science28 November 20041 Introduction1.1 Imitation and Mirror NeuronsThe past twenty years have seen a renewed interest in imitation in variousfields of research (Prinz and Meltzoff, 2002) such as developmental psychol-ogy (Meltzoff, 1996), experimental studies of adult social cognition (Bargh,1997), and most relevant to our work, neurophysiology and neuropsychology(Rizzolatti et al., 1996, 2002). Research in this last field had led to the excit-ing discovery of mirror neurons. These neurons were originally found in theventral premotor cortex (area F5) in monkeys, an area which is characterizedby neurons that code goal-related motor acts (e.g. hand or mouth grasping).Some of the neurons in this area, which have been termed mirror neurons,discharge both when the monkey performs an action and when it observesanother individual making a similar action (Gallese et al., 1996; Rizzolattiet al., 2002). Most mirror neurons exhibit a marked similarity in their re-sponse to action observation and execution, and in some cases this similarityis extremely strict (Rizzolatti et al., 2001). An analogous mechanism, wherebycortical motor regions are activated during movement observations was alsodemonstrated in humans using TMS (Fadiga et al., 1995), MEG (Hari et al.,1998), EEG (Cochin et al., 1998) and fMRI (Iacoboni et al., 1999; Buccinoet al., 2001). Mirror neurons are thus the first identified neural mechanism thatdemonstrates a direct matching between the visual perception of an action andits execution. The ability to match the actions of self and other may have afunctional role in fundamental cognitive processes, such as understanding theactions of others, language and mind reading (Rizzolatti et al., 2001). In par-ticular, imitation of motor skills requires the capacity to match the visualperception of a demonstrator’s action to the execution of a motor command.The neural mirror system, demonstrating such an internal correlation betweenthe representations of perceptual and motor functionalities, may form one ofthe underlying mechanisms of imitative ability.1.2 Context-Based ImitationLearning by imitation, like any cognitive process, must be considered an intrin-sically embodied process, wherein the interaction between the neural system,the body and the environment cannot be ignored (Keijzer, 2002; Dautenhahnand Nehaniv, 2002a). In particular, every action, either observed or performed,occurs within a certain context. A context can represent the time or place inwhich the action is made, various properties of the environment, the state ofthe individual performing the action or the social interaction partners (see,2for example, Dautenhahn, 1995). Clearly, there is no sense in learning a novelbehavior by imitating another’s actions if you do not know the context inwhich these actions are made – a certain action can be extremely beneficialin one context, but have no effect (or even be deleterious) in a different con-text. Discussing an agent-based perspective on imitation, Dautenhahn andNehaniv (2002a) consider the problem of imitating the right behavior in theappropriate context, i.e., “when to imitate”, as one of the five central ques-tions (“Big Five”) in designing experiments and research on imitation. Wehence use the term context-based imitation in the sense of being able to re-produce another’s observed action whenever the context in which the actionwas originally observed, recurs. 1 For example, an infant observing his parentsmay learn by imitation to pick up the phone (action) whenever the phone isringing (context).Context-based imitation can thus be conceived as constructing a set of associ-ations from contexts to actions, based on observations of a demonstrator per-forming different actions within various contexts. These associations shouldcomply with those that govern the demonstrator’s behavior, and should belearned (memorized) so that each context stimulates the production of theproper motor action even when the demonstrator is no longer visible. It shouldbe noted however, that “action” is an abstract notion, and in reality, an imitat-ing individual (agent) should also be capable of matching a visual perceptionof the demonstrator’s action to the corresponding motor command that acti-vates this action. 2 The key objective of this study is to gain a comprehensiveunderstanding of the mechanisms that govern such context-based imitativelearning and to examine the nature of the associations between visual percep-tion, motor control and contexts that are being formed in the process.1.3 Evolving Imitating AgentsImitation is an effective and robust way to learn new traits by utilizing theknowledge already possessed by others and it has already been applied by re-searchers in the fields of artificial intelligence and robotics. Hayes and Demiris(1994) presented a model of imitative learning to develop a robot controller.Billard and Dautenhahn (1999) studied the benefits of social interactions andimitative behavior for grounding and use of communication in autonomous1 Animal behavior and human psychology literature introduces a wide range of def-initions of imitation, focusing on what can constitute true imitation vs. other formsof social learning (Zentall, 2001; Nehaniv and Dautenhahn, 2002). Our definitionaddresses the importance of the observed action’s context for a successful behavior.2 In this study we focus on visually based imitation. However, it should be notedthat other forms of imitation, such as vocal imitation, need not involve visual modal-ity (see, for example, Nehaniv and Dautenhahn, 2002; Herman, 2002).3robotic agents. Borenstein and Ruppin (2003) employed learning by imita-tion to enhance the evolutionary process of autonomous agents. For an up-to-date introduction to work on imitation in both animals and artifacts seethe cross-disciplinary collection (Dautenhahn and Nehaniv, 2002b). Further-more, some researchers, motivated by the recent discovery of a neural mirrorsystem, have implemented various models for imitative learning, employingneurophysiologically inspired mechanisms. Billard (2000) presented a modelof a biologically inspired connectionist architecture for learning motor skills byimitation. The architecture was validated through a mechanical simulation oftwo humanoid avatars, learning several types of movements sequences. Demirisand Hayes (2002) and Demiris and Johnson (2003) developed a mirror-neuronbased computational architecture of imitation inspired by Meltzoff’s ActiveIntermodal Matching mechanism (Meltzoff and Moore, 1997) and combined itwith an “active” distributed imitation architecture. They have demonstratedthat this dual-route architecture is capable of imitating and acquiring a varietyof movements including unknown, partially known, and fully known sequencesof movements. Oztop and Arbib (2002), focusing on the grasp-related mirrorsystem, argued that mirror neurons first evolved to provide visual feedback onone’s own “handstate” and were later generalized to understanding the actionsof others. They have conducted a range of simulation experiments, based ona schema design implementation of that system, providing both a high-levelview of the mirror system and interesting predictions for future neurophysi-ological testing. Other researchers (Marom et al., 2002; Kozima et al., 2002)claimed that the mirror system structure can be acquired during life throughinteraction with the physical or social environment and demonstrated mod-els whereby perceptual and motor associations are built up from experienceduring a learning phase.The studies cited above, however, assume that the agents’ basic ability and mo-tivation to imitate are innate, explicitly introducing the underlying function-ality, structure or dynamics of the imitation mechanism into the experimentalsystem. In contrast to this engineering-based approach, we wish tostudy the neuronal mechanisms and processes underlying imitationfrom an evolutionary standpoint, and to demonstrate how imita-tive learning per se can evolve and prevail. Evolutionary autonomousagents form an intuitively appealing approach for modelling and studyingthe evolution of biological neural mechanisms (Ruppin, 2002). Using a simu-lated environment, wherein agents evolve to perform a simple imitative task,facilitates a thorough examination of the resulting mechanism in “ideal con-ditions”: Full control of the environment and experimental setup, and perfectknowledge of the agents’ behavior and neural dynamics. Clearly, acknowledg-ing the evolutionary origins of imitation and examining the emerging (ratherthan engineered) device can shed light on the common fundamental principlesthat give rise to imitative behavior. It is important to note, however, that ourkey goal in this model is not to simulate the neural mechanism that under-4lie imitative behavior in the human or primate brain nor to incorporate thefull range of social skills required for imitative learning (e.g. extraction of thecontext from the environment or coping with a different embodiment). Themodel described in this paper is clearly a simplified conceptual model anddoes not presume to encapsulate many of the well established biological andneuronal data on imitation. Rather, the aim of such evolutionary autonomousagents model is to examine generic and universal properties of complex liv-ing systems (the “life as it could be” paradigm (Langton, 1988, 1995)). Thekey point in this study is thus to examine the emerging characteristics of themechanism evolved to support imitation in a system where no constraints onthe underlying mechanisms or representations were explicitly encoded.In this study, we thus set out to pursue two objectives: We first presenta novel experimental framework for evolving context-based imita-tive learning in evolutionary adaptive autonomous agents (Ruppin,2002; Floreano and Urzelai, 2000). We demonstrate the evolution of imitat-ing agents that comprise a simple mechanism of imitative behavior. We thenturn to systematically analyze the structure and dynamics of the re-sulting neurocontrollers. This analysis reveals neural devices analogous tothose found in biological systems, including clear examples of internal couplingbetween observed and executed actions. Further analysis of the network adap-tation dynamics reveals a hybrid mechanism, combining innate perceptual-motor coupling with acquired context-action associations. We conclude witha discussion of the implications of our findings for imitation theory and adescription of future work.2 The Experimental Setup2.1 The EnvironmentThe agents in our simulation inhabit a world that can be in one of severalworld states {s1, s2, . . . , sn}. In each time step, the world state is randomlyselected from {s1, s2, . . . , sn} with a uniform distribution. These states canrepresent, for example, the presence of certain food items or the size of anobserved object and hence form the context in which actions are observedand performed. The world state, however, is not visible in every time stepand is seen (i.e. included in the agent’s sensory input) only in 60% of thetime steps. An additional set, {a1, a2, . . . , am}, represents the repertoire ofmotor actions that can be performed by the agent or by the demonstrator.A state-action injective mapping is also defined, assigning a certain action asthe proper action for each world state si. Within the simulations describedbelow, both n and m are set to 4, allowing 4! = 24 different state-action5mappings. Regularly performing the proper action assigned to the currentstate of the world is deemed a successful behavior and confers a positive fitness.Similarly, when the world state is not visible, a successful agent should notperform any action. It is assumed that the environment is also inhabited bya demonstrator (teacher), successfully performing the proper action in eachtime step. The demonstrator’s action is visible (i.e. included in the agent’ssensory input) only in 20% of the time steps. The partial visibility of the worldstate and demonstrator ensures that during the agent’s life it will encounterboth scenarios wherein the demonstrator is not visible, forcing the agent to“memorizing” the proper state-action mapping, and scenarios wherein theworld state is not visible, in which a successful agent should “observe” thedemonstrator’s action but not perform any action. The specific visibility valuesdefined above have no significant effect on the resulting agent, but ratherprovide a good blend of the various visibility scenarios during the agents’ life,facilitating the examination of the agents’ neurocontroller in these scenarios.Furthermore, the above mapping, from world states to actions, israndomly selected anew in the beginning of each agent’s run inthe world. The motivation for this state-action mapping shuffle is twofold.First, it prevents such a mapping from becoming genetically determined. Todemonstrate a successful behavior, agents must learn the proper mappingby observing the demonstrator, promoting an imitation based mechanism toevolve. Second, it represents a scenario of a changing environment, whereinnovel world states appear over time (new food sources, other species, etc.),making prior state-action mappings obsolete.2.2 The AgentFigure 1 illustrates the structure of the agent’s sensorimotor system and neu-rocontroller. The agent’s sensory input in each time step comprises 8 binaryvalues, including the current world state (if visible) and a 4-cell retinal “im-age” of the demonstrator’s action (if visible). The retinal image is determinedaccording to a predefined mapping from actions to retinal binary patternswhich remains fixed throughout the simulation. 3 In time steps wherein theworld state or demonstrator are not visible, the corresponding input neuronsare set to 0. Each of the agent’s output neurons represents a motor actioncommand, determining which actions (if any) will be executed by the agent.The output neurons (as well as the hidden neurons) are continuous neurons3 The selected retinal representation is of no specific significance, however, we usethe representation illustrated in Figure 1 (wherein each action is represented by amulti-bit configuration) rather than a trivial one (wherein each action is representedby a single bit) to examine the emergence of internal localized representation ofcomplex input patterns.6Fig. 1. The agent’s sensorimotor system and neurocontroller. The sensory input isbinary and includes the current world state and a retinal “image” of the demon-strator’s action (when visible). The retinal image for each possible demonstrator’saction and a retinal input example for action a4 are illustrated. The motor out-put determines which actions are executed by the agent. The network synapses areadaptive and their connection strength may change during life according to thespecified learning rules.ranging from 0 to 1, and can thus be perceived as indicating the probabilityof activating each motor action. A successful agent should thus produce ineach time step an activation level close or equal to 1 in the motor neuron thatcorresponds to the appropriate action, and values close or equal to 0 in therest of the motor neurons. In time steps where the world state is not visible(and thus, no action should be performed by the agent), a successful agentshould produce activity level close or equal to 0 in all motor neurons.Considering the agent’s task and the environment it inhabits, the architec-ture of the agent’s neurocontroller should encompass several characteristics.Clearly, it should be capable of acquiring new behaviors during the agent’s lifeto allow imitative learning. However, to support complex dynamics which mayemploy both a fixed component and a learned behavior, the neurocontrollershould also allow a combination of innate and acquired elements. Moreover, theprecise blend of innate and acquired properties should be determined throughgenetic evolution. An interesting architecture that satisfies these requirementshas been proposed by Floreano and Urzelai (2000), and is applied with a fewmodifications in the model described below.Each agent employs a simple feed-forward neural network as a neurocontroller(i.e. the agent cannot perceive its own actions). These networks however areadaptive, whereby the genotype of each individual encodes not only the initial7synaptic weights but also a Hebbian learning rule and learning rate for eachsynapse (Floreano and Urzelai, 2000). In particular, each synapse in the net-work, (i, j), connecting neuron j to neuron i, is encoded by 4 genes, definingthe following properties:(i) w0ij - the initial connection strength of the synapse (real value in therange [0, 1]).(ii) sij - the connection sign (1 or -1).(iii) ηij - the learning rate (real value in the range [0, 1]).(iv) ∆wij - the learning rule applied to this synapse.Each synaptic weight wij is initialized with w0ij at the beginning of the agent’slife and is updated after every time step (a sensory-motor cycle) according to:wtij = wt−1ij + ηij∆wij.∆wij encodes one of five learning (modification) rules (here, oj and oi denotethe activity of the presynaptic neuron and postsynaptic neuron respectively):(1) No learning: ∆wij = 0 .(2) Plain Hebb rule: ∆wij = (1 − wij)ojoi(3) Postsynaptic rule: ∆wij = wij(−1 + oj)oi + (1 − wij)ojoi(4) Presynaptic rule: ∆wij = wijoj(−1 + oi) + (1 − wij)ojoi(5) Covariance rule:...∆wij =(1 − wij)F(oj, oi) if F(oj, oi) > 0(wij)F(oj, oi)otherwisewhere F(oj, oi) = tanh(4(1− | oj − oi |) − 2).These rules have been selected based on neurophysiological findings (i.e. theyencapsulate some of the common mechanisms of local synaptic adaptationfound in biological nervous systems) and were modified to satisfy some com-putational constraints (e.g. in this adaptation process synapses cannot changesign and their strength is kept in the range [0, 1]). For a detailed descriptionof these adaptation dynamics see Floreano and Urzelai (2000). The networktopology is static throughout the process and for the purpose of our simulationwas set to 8-7-4 (i.e., 8 input neurons, a hidden layer with 7 neurons, and 4output neurons), with an additional threshold unit in each layer. Such evo-lutionary adaptive autonomous agents, inspired by those presented in Toddand Miller (1991) and Floreano and Urzelai (2000), demonstrate a learningprocess that is supervised only indirectly, through natural selection.82.3 The Evolutionary ProcessA population of the agents described above evolve to successfully behave inthe environment. Each agent lives in the world for 500 time steps. Fitnessis evaluated according to the agent’s success in performing the proper actionassigned to the current world state (i.e. activating only the appropriate motorneuron), according to the state-action mapping, in each time step. An agentshould perform an action only if the world state is visible and regardless ofthe demonstrator’s visibility. We use the Mean-Square Error (MSE) measureto calculate the distance between the agent’s motor output (continuous valuesranging from 0 to 1) and the desired output (a value of 1 for the appropriatemotor neuron and 0 for the rest), averaged over the agent’s life. A MSE valueof 0 thus indicates a perfectly behaving agent. The agent performance duringthe first 100 time steps is not evaluated (infancy phase). Fitness value is thencalculated as (1−MSE) and averaged over 20 trial runs in the world.The initial population is composed of 200 individuals, each assigned a ran-domly selected haploid genome (i.e. each individual holds one copy of thegenome), encoding the initial connection weights, learning rules and learn-ing rates. Each new generation is created by randomly selecting agents fromthe previous generation and allowing them to reproduce. Agents are selectedaccording to their fitness, using linear scaling and a roulette wheel selectionscheme (Mitchell, 1996). During reproduction, 2% of the genes are mutated.Connection strength genes and learning rate genes are mutated by adding arandomly selected value from the interval [−0.3, 0.3], connection sign genesare mutated by flipping the sign and learning rule genes are mutated by ran-domly selecting one of the available rules. The genomes of the top 20% ofindividuals are copied to the next generation without mutation. Variations inthese parameter values have no significant effect on the resulting agents.3 Results3.1 The Evolution of ImitationWithin the settings described in the previous section the proper action as-signed to each world state is randomly selected anew at the beginning of theagent’s life. The appropriate state-action associations can thus be inferred onlyfrom the demonstrator’s observed actions. Agents cannot rely on geneticallycoded behavior and must incorporate some sort of imitation-based learningstrategy in order to demonstrate a successful behavior. Although no suchlearning strategy was explicitly introduced into the system, examining the fit-9Fig. 2. The fitness of the best agent in the population and the population averagefitness as a function of generation.ness of the best agent in the population as a function of generation clearlydemonstrates that such imitating agents have evolved (Figure 2). Evidently,after approximately 2000 generations, the evolved agents successfully masterthe behavioral task, regularly executing the proper action in each world state.Having successfully evolved imitating agents, we turned to examine the struc-ture, dynamics and neural mechanisms that these agents employ. We have per-formed numerous evolutionary simulation runs, of which approximately halfresulted in near-optimal imitating agents (exhibiting an evolutionary dynam-ics similar to those shown in Figure 2). Unsuccessful simulation runs seemedto stem from early convergence of the population to sub-optimal solutions(wherein agents did not produce a distinct motor action in each time step). Inthe remainder of this paper we focus on analyzing one such successful agent– the best agent in the last generation of a specific evolutionary simulationrun. Other successful agents, from various evolutionary runs, were analyzedand demonstrated similar dynamics.Direct evidence of the agent’s successful imitative behavior and the resultinglearning dynamics are demonstrated in Figure 3, depicting the activity of oneof the motor neurons (m2) in different states of the world. In this specificsimulation run, the state-action mapping was arbitrarily set so that a2 is theproper action in world state s4 and not in any other state. In the beginningof its life, the agent activates motor m2 (i.e., performs action a2) wheneverthe world state is visible. However, after only a few demonstrations of theappropriate behavior, the proper state-action mapping is learned and this10500100015002000250030000.50.60.70.80.91GenerationFitness ValueBest agentPopulation AverageFig. 3. The activation level of one motor neuron (m2) during the first 150 timesteps. The different shapes indicate whether the world state was s4 and whether itwas visible. The triangles at the bottom further represent time steps in which thedemonstrator was visible.motor is activated only when the world state is s4, as expected. In fact, asdemonstrated in Figure 4, the ability to learn by imitation the appropriatestate-action mapping remains active during the agent’s life, allowing the agentto learn a new mapping when necessary. In this experiment, the state-actionmapping was initially set, as before, so that a2 is the proper action in worldstate s4. However, in the middle of the agent’s life (time step 250) the state-action mapping, and accordingly the demonstrator’s behavior, was changed sothat a2 is the proper action in world state s2. Evidently, although the agentlearned a certain mapping in the beginning of its life, it can quickly adapt toa new mapping after observing a few demonstrations of the new appropriatebehavior.Fig. 4. The activation level of motor neuron m2 during the agent’s life, demonstrat-ing the agent’s ability to learn new behaviors. In this simulation run the state-actionmapping was modified in step 250, making a2 the proper action in world state s2rather than s4 as it was initially set. The triangles at the bottom further representtime steps in which the demonstrator was visible.112040608010012014000.20.40.60.81Time StepNeuron ActivityWorld state = s4World state ≠ s4World state not visibleDemonstrator visible5010015020025030035040045050000.20.40.60.81Time StepNeuron ActivityWorld state = s4World state = s2World state ≠ s4,s2World state not visibleDemonstrator visible3.2 The Emergence of Mirror NeuronsExamining the network hidden layer reveals an interesting phenomenon withregard to the internal representation of actions. As stated above, to supportimitative learning, wherein associations from contexts to motor commandsshould be inferred from observations of the demonstrator’s actions, an agentshould be capable of matching the visual perception of an observed action tothe motor command that generates the corresponding action. Figure 5, de-picting the activation level of 3 hidden neurons, attests to the emergence ofsuch inherent perceptual-motor coupling. Apparently, various neurons in thehidden layer are active both when the agent performs a certain action andwhen it observes the demonstrator making a similar action, forming inter-nal mirror neurons analogous to those found in biological systems.For the purpose of this study, we thus define mirror neurons as neurons thatshow a neural activation level significantly higher than 0 for both observationand execution of a certain action, and are not active in any other scenario. Al-though other definitions may be applied, the above definition forms a suitableanalogy to the characteristics of biological neural mirroring. Interestingly, asseen in Figure 5, the activation level of mirror neurons during action obser-vation is typically lower than the activation level during action execution. Ananalogous phenomenon can also be detected in neuronal recording data in theliterature, and should be further investigated. However, in our simulation, therelatively small number of hidden neurons and mainly, the feed-forward na-ture of the network may account for this phenomenon, forcing mirror neuronsto participate also in motor excitation. 4 These constraining properties of theartificial network, a direct consequence of several computational limitations,may also induce some constraints on the biological implications of this model,including, for example, the lack of clear distinction between active and pas-sive perception. Such mirror neurons were found in most of the agents thatevolved in our simulation environment. However, typically, not all actions inthe repertoire were associated with a corresponding mirror neuron, and therehave been a few cases where successful agents did not seem to incorporateany clear neural mirroring matching our above definition. There was also noevident correlation between the initial conditions or the simulation parametersand the emergence of mirror neurons.The functional characteristics of the emerging mirror neurons were furtherexamined through a set of intervention experiments, wherein hidden neurons4 Furthermore, the relatively small number of hidden neurons may form a bottle-neck that promotes the use of these neurons for both action perception and actionexecution and consequently the formation of mirror neurons. However, the fact thatthe same single neuron is activated in the observation and activation of the samespecific action, the essence of mirroring, is surprising.12(a) Neuron h4(b) Neuron h5(c) Neuron h6Fig. 5. The activation level of 3 hidden neurons (h4, h5 and h6) during time steps100-200 with an indication of the executed or observed action. Circles, squares,diamonds and triangles represent actions a1, a2, a3, a4 respectively. An empty shapeindicates that the action was only observed but not executed, a filled shape indicatesthat the action was executed by the agent (stimulated by a visible world state) butnot observed, and a dotted shape indicates time steps in which the action was bothobserved and executed.were externally activated (stimulated) or inactivated (lesioned). These ex-periments confirmed that the detected mirror neurons convey the requiredinformation about the action to be performed. For example, when the worldstate is not visible (a scenario that would usually result in no action beingperformed) an ‘artificial’ stimulus of a mirror neuron resulted in the agent’sperformance of the action associated with that mirror neuron. Similarly, in-activating a mirror neuron inhibits the production of the associated action1310011012013014015016017018019020000.51Time StepNeuron Activity10011012013014015016017018019020000.51Time StepNeuron Activity10011012013014015016017018019020000.51Time StepNeuron Activityand in some cases resulted in the production of the wrong action. 5 Further-more, applying multiple neurons activation/inactivation settings, it has beenshown that even actions that could not be associated with a fully localizedrepresentation (i.e. a single mirror neuron) are still represented in the hiddenlayer through a distributed configuration of neurons. These findings also ac-count for the cases mentioned above wherein successful agents did not seemto incorporate any clear localized mirror neurons.3.3 The Developmental DynamicsWe finally turn to examine the ontogenic, developmental aspects of the re-sulting neurocontroller. Our main objective is to identify which componentsin the neural mechanism are innate and which are acquired during the agent’slife. We first determine which synapses play a significant role in the learningprocess. Clearly, variation in the synapse strength during life or the geneticallycoded learning rate are not appropriate indicators as they cannot differenti-ate between learning processes that genuinely adapt the agent to the worldand unrelated self-organization processes. We thus measure the variance inthe connection strength at the end of the agent’s life across 1000 simulationruns (i.e. the particular agent that was analyzed above, living 1000 differentlifetimes). A low variance value indicates that the synapse dynamics are inde-pendent of the world characteristics (e.g. the state-action mapping), and thuscannot contribute to the learning process that adapt the agent to the world. Asdemonstrated in Figure 6a, this measure highlights the acquired nature of thesynapses connecting the world state neurons (input neurons 1-4), with the mir-ror neurons we have identified (hidden neurons 4-6). Clearly, the acquiredstate-action associations are induced by these synapses. The markedlylower variance values in other synapses from this layer and in synapses con-necting hidden layer neurons to motor neurons (not illustrated here), suggestthat these synapses do not play an important part in the learning processand encompass the innate properties of the network. We then turned to de-termining the overall contribution of each synapses to the agent’s successfulbehavior, either learned or innate. Examining the effect of numerous mul-tiple lesion configurations, we have utilized the Multi-perturbation Shapley5 Recent reversible inactivation studies (Fogassi et al., 2001) demonstrated a dis-tinction between two sectors in area F5 in monkeys: Mirror neurons are located insector F5 convexity. Canonical neurons (neurons that respond to the presentationof three-dimensional objects of different size and shape) are located in sector F5bank. While inactivation of area F5 bank produced a severe deficit of the requiredactions, inactivation of the cortical convexity determined only a motor slowing, pre-serving the appropriate action production. Clearly, within our simple model, suchdistinction between canonical and mirror neurons could not have developed and themirror neurons that have emerged play a crucial role in the visuomotor pathway.14(a)(b)Fig. 6. An illustration of the connection strength variance (a) and the overall con-tribution (b) of the synapses connecting the sensory input layer (presynaptic) tothe hidden layer (postsynaptic). Neurons 1-4 of the presynaptic input layer rep-resent the world state while neurons 5-8 are the retinal neurons, representing theobserved demonstrator’s action. Neurons 4-6 of the hidden postsynaptic layer havebeen identified as mirror neurons.value Analysis (MSA), a rigorous way to determine the importance of systemelements (Keinan et al., 2004). In each configuration, a set of synapses arecancelled out by setting both their initial strength and learning rate to 0. Theresulting contribution of each synapse connecting the input layer to the hiddenlayer is illustrated in Figure 6b. Evidently, the synapses that have been iden-tified above as participating in the learning process possess a non-negligiblecontribution value. However, the most important synapses are among thoseconnecting the retinal neurons (input neurons 5-8), representing the observedaction, with the mirror neurons (hidden neurons 4-6). These connectionsmanifest the strong innate associations between the visual percep-tion of observed actions and the internal representation of theseactions, developed during the evolutionary process.Based on the findings described above, a simple model of the mechanism thatevolved in our settings to support imitative behavior can be inferred (Fig-ure 7). Notably, the required perceptual-motor coupling was not explicitlyengineered into the agents, but rather emerged through evolution as an in-nate property. Furthermore, to support an effective mechanism of imitation,visually perceived actions are linked to the corresponding motor commandsvia fully localized internal elements, representing each action, in the form ofmirror neurons. The acquired context-action stimuli can then be constructedthrough a simple mechanism of Hebbian learning without external supervisionor reinforcement signals.1512345678123456700.050.10.150.2PostsynapticneuronPresynapticneuronVariance12345678123456700.020.04PostsynapticneuronPresynapticneuronContributionFig. 7. A simple model of context-based imitation. Solid arrows represents innateassociations, while dashed arrows represents associations that are acquired duringthe agent’s life via Hebbian learning.4 DiscussionThis study presents an experimental framework for studying the evolutionand dynamics of imitation in evolutionary autonomous agents. This frame-work provides a fully accessible, distilled model for imitation and can serve asa vehicle to study the mechanisms that underlie imitation in biological sys-tems. As stated in Section 1.3, our experimental setup employs a simplifiedmodel that is not presumed to encapsulate many of the well established bio-logical and neuronal data on imitation, nor to simulate a fully realistic sociallearning scenario. Rather, the aim of this model is to examine the generic anduniversal properties of imitative learning mechanisms. Our confidence in thisframework is based on two observations: First, being an evolutionary devel-oped mechanism, rather than an engineered one, we believe it is likely to sharethe same fundamental principles driving natural systems. Second, our analy-sis of the resulting mechanism reveals phenomena analogous to those found inbiological neural mechanisms.The key point in our findings is that while creating a system inwhich only the evolution of imitation is solicited, a neural mirroringsystem had emerged. That is, even though no constraints on the underlyingmechanisms or representations were explicitly encoded into the system, suchmirror neurons have been demonstrated. These findings imply a fundamentaland essential link between the ability to imitate and a mirror system.In fact, in this regard, we believe that the simplicity of our model is one of itskey assets: The emergence of neuronal mirroring to support imitation even in16such a simple model, may suggests a universal and fundamental link betweenthe ability to replicate the actions of other (imitation) and the capacity torepresent and match others’ actions (mirroring).It is also important to note, that although it has been hypothesized thatmirror neurons underlie imitative learning functionality, the precise role ofthe mirror system remains unknown (Rizzolatti et al., 2001). The linkagebetween imitation and mirroring demonstrated in our study corroborates thishypothesis and may prove to be interesting for understanding the mechanismsthat give rise to social cognitive skills. Moreover, the mirror neurons thatemerged in our model, being a clear instance of shared internal representationbetween observed and executed actions, also provide interesting insights thatmay be applied to artificial intelligence and robotic research. Although the useof internal representation is prevalent in engineered systems, the existence ofsuch a representation in evolved systems has been challenged (Cliff and Noble,1997). The model presented in this paper, promoting the use of observedactions of “others” for learning proper motor actions of “self”, provides asimple example of evolved internal representation.Clearly, the simple model presented in this paper cannot account for the fullrange of imitative behaviors found in nature (e.g. recognition of novel or com-pound actions). However, focusing on low-level, innate imitation, this modeladdresses the essential questions concerning the mechanism underlying im-itative behavior. It successfully demonstrates how the required associationsbetween perceived actions, motor commands and contexts can be constructedwithin a hybrid adaptation process, combining evolution and lifetime learning.The framework presented in this paper can be further enhanced to examinecentral issues concerning the development of imitation in animals and arti-facts and the functional role of the neural mirror system. We wish to use thisbasic model to determine the physical and social environmental conditionsthat promote the emergence of mirror neurons. In particular, our frameworkcan be enhanced to simulate a more realistic scenario of social learning. Forexample, we wish to examine how an extension of the agent’s sensory input,and a complex social environment inhabited by demonstrators with varyinglevels of success, affect the resulting imitation strategy. Questions concerningthe dependencies between observed and executed actions and the formation ofneural mirroring are especially of great interest: How will the representation ofactions that cannot be executed by the observer (e.g. due to different embodi-ment) differ from those of imitated actions? How will a hierarchical repertoireof actions affect the emerging representation? Another intriguing possibilitywould be to utilize this framework to explore the role of mirror neurons in theevolution of communication (Rizzolatti and Arbib, 1998; Arbib, 2002) and inpredicting the actions of others (Ramnani and Miall, 2004). We hope that fur-ther extensions of this basic model will allow us to obtain testable predictions17regarding imitative behavior in humans and primates, and shed new light onsome of the key issues concerning perception, mirroring and cognition.AcknowledgementsE.B. is supported by the Yeshaya Horowitz Association through the Centerfor Complexity Science. We would like to thank the anonymous reviewers fortheir insightful recommendations for improving this paper.ReferencesArbib, M., 2002. The mirror system, imitation, and the evolution of language.In: Dautenhahn, K., Nehaniv, C. (Eds.), Imitation in Animals and Artifacts.The MIT Press.Bargh, J., 1997. The automaticity of everyday life. In: R.S. Wyer, J. (Ed.),The automaticity of everyday life: Advances in social cognition. Erlbaum,Mahwah, NJ, pp. 1–61.Billard, A., 2000. Learning motor skills by imitation: a biologically inspiredrobotic model. Cybernetics & Systems 32, 155–193.Billard, A., Dautenhahn, K., 1999. Experiments in learning by imitation:grounding and use of communication in robotic agents. Adaptive Behav-ior 7 (3/4), 411–434.Borenstein, E., Ruppin, E., 2003. Enhancing autonomous agents evolutionwith learning by imitation. Journal of Artificial Intelligence and the Simu-lation of Behavior 1 (4), 335–347.Buccino, G., Binkofski, F., Fink, G., Fadiga, L., Fogassi, L., Gallese, V., Seitz,R., Zilles, K., Rizzolatti, G., Freund, H.-J., 2001. Action observation acti-vates premotor and parietal areas in a somatotopic manner: an fMRI study.European Journal of Neuroscience 13, 400.Cliff, D., Noble, J., 1997. Knowledge-based vision and simple visual machines.Philosophical Transactions of the Royal Society: Biological Sciences 352,1165–1175.Cochin, S., Barthlmy, C., Lejeune, B., Roux, S., Martineau, J., 1998. Percep-tion of motion and qEEG activity in human adults. ElectroencephalographyAnd Clinical Neurophysiology 107, 287–295.Dautenhahn, K., 1995. Getting to know each other–artificial social intelligencefor autonomous robots. Robotics and Autonomous Systems 16, 333–356.Dautenhahn, K., Nehaniv, C., 2002a. The agent-based perspective on imita-tion. In: Dautenhahn, K., Nehaniv, C. (Eds.), Imitation in Animals andArtifacts. The MIT Press.18Dautenhahn, K., Nehaniv, C. (Eds.), 2002b. Imitation in Animals and Arti-facts. MIT Press, Cambridge, Mass., USA.Demiris, Y., Hayes, G., 2002. Imitation as a dual-route process featuringpredictive and learning components: a biologically plausible computationalmodel. In: Dautenhahn, K., Nehaniv, C. (Eds.), Imitation in Animals andArtifacts. The MIT Press.Demiris, Y., Johnson, M., 2003. Distributed, predictive perception of actions:a biologically inspired robotics architecture for imitation and learning. Con-nection Science Journal 15 (4), 231–243.Fadiga, L., Fogassi, L., Pavesi, G., Rizzolatti, G., 1995. Motor facilitationduring action observation: a magnetic stimulation study. Journal of Neuro-physiology 73, 2608–2611.Floreano, D., Urzelai, J., 2000. Evolutionary robots with on-line self-organization and behavioral fitness. Neural Networks 13, 431–443.Fogassi, L., Gallese, V., Buccino, G., Craighero, L., Fadiga, L., Rizzolatti, G.,2001. Cortical mechanism for the visual guidance of hand grasping move-ments in the monkey: A reversible inactivation study. Brain 124, 571–586.Gallese, V., Fadiga, L., Fogassi, L., Rizzolatti, G., 1996. Action recognition inthe premotor cortex. Brain 119, 593–609.Hari, R., Forss, N., Avikainen, S., Kirveskari, E., Salenius, S., Rizzolatti, G.,1998. Activation of human primary motor cortex during action observation:A neuromagnetic study. Proceedings of the National Academy of SciencesUSA 95, 15061–15065.Hayes, G., Demiris, J., 1994. A robot controller using learning by imitation.In: Proceedings of the 2nd International Symposium on Intelligent RoboticSystems.Herman, L., 2002. Vocal, social, and self imitation by bottlenosed dolphins. In:Dautenhahn, K., Nehaniv, C. (Eds.), Imitation in Animals and Artifacts.The MIT Press.Iacoboni, M., Woods, R., Brass, M., Bekkering, H., Mazziotta, J., Rizzolatti,G., 1999. Cortical mechanisms of human imitation. Science 286, 2526–2528.Keijzer, F., 2002. Representation in dynamical and embodied cognition. Cog-nitive Systems Research 3, 275–288.Keinan, A., Hilgetag, C., Meilijson, I., Ruppin, E., 2004. Causal localizationof neural function: The Shapley value method. Neurocomputing to appear.Kozima, H., Nakagawa, C., Yano, H., 2002. Emergence of imitation mediatedby objects. In: Prince, C., Demiris, Y., Marom, Y., Kozima, H., Balke-nius, C. (Eds.), Proceedings Second International Workshop on EpigeneticRobotics: Modeling Cognitive Development in Robotic Systems. Vol. 94.Edinburgh, Scotland, pp. 59–61.Langton, C., 1988. Artificial life. In: Langton, C. (Ed.), Artificial Life, volumeVI of Santa Fe Institute Studies in the Sciences of Complexity. Addison-Wesley, Reading, MA, pp. 1–47.Langton, C., 1995. Artificial Life: An Introduction. MIT Press, Boston, MA.Marom, Y., Maistros, G., Hayes, G., 2002. Toward a mirror system for the19development of socially-mediated skills. In: Prince, C., Demiris, Y., Marom,Y., Kozima, H., Balkenius, C. (Eds.), Proceedings Second InternationalWorkshop on Epigenetic Robotics: Modeling Cognitive Development inRobotic Systems. Vol. 94. Edinburgh, Scotland.Meltzoff, A., 1996. The human infant as imitative generalist: a 20-year progressreport on infant imitation with implications for comparative psychology.In: Hayes, C., Galef, B. (Eds.), Social Learning in Animals; The Roots ofCulture. New York Academic Press.Meltzoff, A., Moore, K., 1997. Explaining facial imitation: a theoretical model.Early Development and Parenting 6, 179–192.Mitchell, M., 1996. An introduction to genetic algorithms. MIT Press.Nehaniv, C., Dautenhahn, K., 2002. The correspondence problem. In: Daut-enhahn, K., Nehaniv, C. (Eds.), Imitation in Animals and Artifacts. TheMIT Press.Oztop, E., Arbib, M., 2002. Schema design and implementation of the grasp-related mirror neuron system. Biological Cybernetics 87, 116–140.Prinz, W., Meltzoff, A., 2002. An introduction to the imitative mind andbrain. In: Meltzoff, A., Prinz, W. (Eds.), The imitative mind: Development,evolution and brain bases. Cambridge University Press, Cambridge, MA,pp. 1–15.Ramnani, N., Miall, R., 2004. A system in the human brain for predicting theactions of others. Nature Neuroscience 7, 85 – 90.Rizzolatti, G., Arbib, M., 1998. Language within our grasp. Trends in Neuro-sciences 21, 188–194.Rizzolatti, G., Fadiga, L., Fogassi, L., Gallese, V., 2002. From mirror neuronsto imitation: Facts and speculations. In: Meltzoff, A., Prinz, W. (Eds.),The imitative mind: Development, evolution and brain bases. CambridgeUniversity Press, Cambridge, MA, pp. 247–266.Rizzolatti, G., Fadiga, L., Gallese, V., Fogassi, L., 1996. Premotor cortex andthe recognition of motor actions. Cognitive Brain Research 3, 131–141.Rizzolatti, G., Fogassi, L., Gallese, V., 2001. Neurophysiological mechanismsunderlying the understanding and imitation of action. Nature Reviews Neu-roscience 2, 661–670.Ruppin, E., 2002. Evolutionary autonomous agents: A neuroscience perspec-tive. Nature Reviews Neuroscience 3 (2), 132–141.Todd, P., Miller, G., 1991. Exploring adaptive agency II: Simulating the evo-lution of associative learning. In: Meyer, J., Wilson, S. (Eds.), From animalsto animats: Proceedings of the First International Conference on Simulationof Adaptive Behavior. MIT Press, Cambridge, MA., pp. 306–315.Zentall, T., 2001. Imitation in animals: evidence, function, and mechanisms.Cybernetics and Systems 32 (1-2), 53–96.20