Artificial Intelligence 94 (1997) 79-97 Artificial Intelligence Negotiation and cooperation in multi-agent environments * Sarit Kraus a,bJ a Department of Mathematics and Computer Science, Bar Ilan University Ramat Can, 52900 Israel b hstith!te for Advanced Computer Studies, University of Maryland, College Park, MD 20742, USA Abstract Automatic intel~gent agents i~abiting a shared environment must coordinate their activities. improve the performance of the individual agents or Cooperation-not merely coordination-may the overall behavior of the system they form. Research in Distributed Artificial Intelligence (DAI) addresses the problem of designing automated intelligent systems which interact effectively. DA1 is not the only field to take on the challenge of understanding cooperation and coordination. There are a variety of other multi-entity environments in which the entities coordinate their activity and cooperate. Among them are groups of people, animals, particles, and computers. We argue that in order to address the challenge of building coo~nated intelligent agents, it is beneficial to combine AI techniques with methods and techniques from a range of muIti-entity fields, such as game theory, operations research, physics and philosophy. To support this claim, we describe some of our projects, where we have successfully taken an interdisciplinary approach. the benefits in applying multi-entity methodologies and show the adaptations, We demomtrate modifications and extensions necessary for solving the DA1 problems. @ 1997 Elsevier Science B.V. and collabom~d ~ey~ur~~~ Dis~buted Artificial Intelligence; Multi-agent systems; Cooperation; Negotiation 1. Introduction One of the greatest challenges can work together. The integration of automated for computer science is building computer systems that systems has always been a challenge, *This is an extended version of a lecture presented upon receipt of the Computers and Thought Award at the 14th International Joint Conference on Artificial Intelligence in Montreal, Canada, August 1995. ’ Email: sa.rit@cs.biu.ac.il or sarit@umiacs.umd.edu. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PIISOOO4-3702(97)00025-S 80 S. Kraus/Artijicial Intelligence 94 (1997) 79-97 have become more sophisticated, but as computers cooperation printers, disks, and CPUs, but also high-level and cooperate. have become more critical. the demands for coordination It is not only basic level components and such as complex systems that need to coordinate Examples of such intelligent l automated agents l teams of robotic systems acting l computational l distributed l intelligent for whom systems include: that monitor electricity transformation in hostile environments networks [5]; [ 321; that facilitate distributed design and engineering agents transportation agents that negotiate over meeting scheduling options on behalf of people they work [67]; and and planning [ 25,561; systems [ 541; l Internet agents In these environments, the performance form. that collaborate to provide updated information to their users. even when coordination agents or the overall behavior of the system is not required, cooperation may improve they of the individual Problems of coordination and cooperation are not unique systems, but their in a wide range of populations. People pursue and cooperation with other people or machines. Ani- cooperate with each other, and form communities. to computer language), (with limited levels of activity exist at multiple own goals through communication mals interact Particles of matter. Although most computers interaction them is generally among gotiation or other sophisticated the levels of negotiation, acterize natural coordinating research Recent interact with each other and compose different act in multicomputer types of material and phases the currently restricted, and they interact under strict rules. Ne- In general, that char- rarely occur among computers. environments, interactions interactions bidding, voting, and other sophisticated systems are absent. in Distributed Artificial power, efficiency, and flexibility of intelligent ing sophisticated techniques research, ligent agents by combining AI techniques with methods and techniques fields that study multi-entity the challenge of building coordinated for communication I have addressed behavior. Intelligence automated (DAI) systems and cooperation aims (agents) among to increase the by develop- In my intel- from various them. and collaborated is beneficial for the development of coordi- I argue that an interdisciplinary intelligent approach agents. Because is quite the contrary. nated and cooperative these fields, which study multi-entity behavior, are not concerned with agent design, one might think that they are not relevant It is true that these fields do not solve AI for DAI. Our experience problems, but they have thought about a wide range of issues that are important to the design of intelligent sometimes with proven proper- that are useful to adopt for designing agents. DAI ties or methods for their needs; researchers however, the advantages they do not need to start from scratch. In this paper, we show by example still have a lot of work left in order to adapt these methods and the challenges of building on other work. agents, and they provide for proving properties techniques, The amount of work done in the related fields is overwhelming. in taking an interdisciplinary approach is determining which technique Thus, a major to use. for techniques that influence the choice of the appropriate challenge There are several parameters a DAI application: S. Kraus/Artificial Intelligence 94 (1997) 79-97 81 (1) (2) (3) (4) (5) Lie level of cooperation among the agents: cooperative agents which work to- ward satisfying the same goal versus agents which are self-motivate and try to maximize their own benefits. ’ There are intermediary cases where self-motivated agents join together to work toward a joint goal. Regulations and protocols: environments where the designers of the agents can agree on regulations and protocols for the agents’ interaction versus situations with no pre-defined regulations and protocols. Number of agents: a very large number of agents (hundred or more) versus a few agents which communicate and coordinate their actions. Type of agents: systems of automated agents versus systems composed of people and automated agents. C~~~~ni~at~on and computation costs: the availability and cost of communica- tion among the agents and their computation capabilities and costs. Any DA1 task can be characterized according to these dimensions. This characteriza- tion guides the choice of the multi-entity technique that can be applied to the specific task. Consider the deveIopment of automated agents for buying and selling items on the Web, such as clothes and furniture. Suppose there are several enterprises, each with several kinds of goods which they sell to users or to other enterprises. Each enterprise has intelligent seller and buyer agents. The job of the seller agent is to sell the enterprise’s goods to other enterprises through their buyer agents or to users. The job of a buyer agent is to obtain from other enterprises the goods that are missing ffom the stock of its enterprise. Several different DA1 problems may arise in such a fr~ework: in the interaction between two automated agents belonging to different enter- prises, the agents are self-motivated, but may benefit from cooperation. The designers of the agents may agree upon regulations for the interaction, the num- ber of agents of each interaction is limited, and they can communicate and have computation capabilities. A seller agent of an enterprise may try to sell some goods to a person. In this case, the person will prefer a non-structured interaction, and it is more difficult to set regulations and protocols for the interaction in advance. Two agents of the same enterprise may work together toward the same goal: increasing the benefits of their enterprise. In this case, the agents are cooperative, regulations and protocols can be set in advance, the number of agents is limited, they are automated, and they can communicate. In each of these three cases, there is a different multi-entity technique that should be applied. In this paper, we will examine different DAI tasks and will discuss the application of game-theoretic techniques (Section 2), physics models (Section 3), operations research methods (Section 4)) and informal models of cooperation and coordination (Section 5) to DAI environments. 2 Research in DAI is divided into two basic classes: distributes Problem Solving (DPS) and belts-Agent Systems (M.4) [ 61. Cooperative agents belong to the DPS class, while self-motivated agents belong to the MA class. 82 S. Kraus/Art@ial Intelligence 94 (1997) 79-97 2. The application of game-theoretic techniques to multi-agent environments agents which represent different Researchers in DA1 have considered problems sharing where the agents are self-motivated, o situations where airplanes belonging related to task allocation as in the following examples: and resource to different airlines need to share the limited that will give to find a mechanism resources of the same airport, and it is necessary [ 611; to planes with less fuel on board priority o an electronic market populated with automated and buy and sell (e.g., [8,17,74]); enterprises o transportation centers that deliver packages and may cooperate to reduce expenses [641; o info~ation o intelligent for whom servers that form coalitions for answering queries [ 361; and agents that negotiate over meeting scheduling options on behalf of people they work [67]. in the Introduction that in these examples the five criteria presented these examples, Using we observe and try to maximize their own benefits. The designers of the agents may agree in advance on regulations and protocols usually small communicate than a dozen agents) ; there are only automated capabilities. for the agents’ (less and have computational is agents which can the agents are self-motivated the number of agents In each interaction to characterize interaction, In such situations we recommend the application of game-theoretic individuals who have different goals or preferences theory studies mathematical models of conflict and cooperation models of game theory are highly abstract representations that involve in all game-theoretic models main types: “noncooperative” models, players are primitives, actions of groups of players are primitive and “cooperative” models, in which [53]. is a player. Game-theoretic models are divided in which the sets of possible actions of individual joint the sets of possible techniques. Game between people. The of classes of real life situations [49] _ The active entity two into in- that theory in game framework are self-motivated, in which each individual The abstract models of game theory can be used as a basis the designers of the agents agree for the application that groups of agents work the players these techniques agent acts by itself teraction protocols, when in a DAI agents Since it is assumed the agents be in the environments where both situations calling require erative models. In is only a handful of agents, and, to a few dozens of agents. The use of game-theoretic and, communication tial computations, the beginning amples described in are cases where applying these criteria, satisfy researchers erative gee-th~retic here. for the agents’ to use them. Automated can be modeled by players of game-theoretic models. so should are applied. DA1 addresses thus [17,61,67]), tasks for coop- there theory may be applied substan- are also usually needed. The ex- that by DA1 and coop- these attempts (e.g., the first case, game-theoretic models are appropriate when the second case, game of noncooperative models, together should be considered. We have applied both noncooperative to DA1 situations. We briefly describe capabilities of the section, as well as other situations and situations game-theoretic thus calling techniques techniques in which [ 36,641)) requires models (e.g., in S. Kraus/Ar@cial Intelligence 94 (1997) 79-97 83 2.1. Use of a strategic model of negotiation for resource sharing and task distribution We first consider situations where a small number of self-motivated task distribution. from or can benefit agents need to can be enhanced using negotiation strategies their respective desires and to compromise In these situations, that enable agents inter-agent to commu- in order to reach mutually beneficial share resources cooperation nicate agreements. The game-theoretic strategic approach such capabilities in systems. for designing are moves in a noncooperative [ 301 is expressed by using foundation ating maneuvers the negotiators goal in this research was to define an acceptable protocol strategies agents and to identify in the following example. methods are applicable for the agents p~icipating to the bargaining problem3 game, and the rationality provides a useful In this approach, agents’ negoti- assumption of the Nash Equilibrium concept. 4 Our main the for the interactions in the negotiation. These among than two) information in its area. In response in a different g~graphical Example 1 (Data allocation in multi-agent environments). There (more communication receives queries back information from that server. 5 The information servers network. Each server from clients stored locally or information is a set of several by a area and to a client’s query, a server sends stored in another server, which it retrieves in the environment which are connected is located is clustered When a set of new datasets arrives, each new dataset has to be allocated to one among all of them. However, each server has its its own utility, and thus the servers may be in the servers have no interest and no central controller which can be used to resolve such conflicts. In particular, we the passage of time during of the servers by mutual agreement own conflict concerning where to locate common We propose propose a strategic negotiation model process the negotiation that takes into account itself in order to solve this problem. these conflicts will be resolved via negotiations. the new datasets. Furthermore, in datasets. 6 to maximize and wants interests that Our negotiation protocol is a process that may include several iterations. We assume in the negotiation t, will suggest a possible allocation that servers can take actions (0, I, 2,. . .} that are fixed in advance and ordered (randomly). if the neg~~tiation has not terminated at time the other servers may either accept If an offer is accepted by all the servers, implemented. server has opted out, but at least one of the servers has rejected the offer or reject then the negotiation only at certain in the set Time = times In each period t E Time, earlier, a server whose turn it is to make an offer and each of for all the datasets considered, ends, and this offer is ends. If no the offer, the negotiation If at least one of the servers opts out, then the negotiation it or opt out of the negotiation. 3 Introductory books on game theory that discuss approaches to bargaining include [21,47,49,53]. 4A pair of strategies (CT, T) is a Nash Equilibrium if, given 7, no strategy of Agent 1 results in an outcome that Agent 1 prefers to the outcome generated by (CT, T), and similarly for Agent 2, given (T. 5A specific example of such a distributed knowledge system is the Data and information System component of the Earth Observing System (EOSDJS) of NASA [50]. It is a distributed system which supports the archiving and dis~bution of data at multiple and inde~ndent data centers. 4 A dataset corresponds to a clusrer in information retrieval, and to afile in the file allocation problem. 84 S. Kraus/Artijkial Intelligence 94 (1997) 79-97 proceeds to period t + 1, and the next server makes a counter-offer, the other servers respond, and so on. Using this negotiation mechanism, we showed that the servers have simple and stable negotiation strategies that result in efficient agreements without delays. We have proved that our methods yield better results than the static allocation policy currently used for data allocation for servers in distributed systems. The main question is, in general, what is the advantage of using game-theoretic models for such problems, and what must be done in order to adapt them to DAI environments. The strategic bargaining theory provides general frameworks for modeling negotiation, but to apply them to the design of agents, we needed to address five problems: choosing a strategic bargaining model which is applicable for the specific DAI problem; matching the DAI scenarios with the game-theoretic definitions of the chosen model; identifying equilibrium strategies; developing low complexity techniques for searching for appropriate strategies; and providing utility functions. For example, for the data allocation problem described in Example 1, we have chosen Rubinstein’s model of Alternative Offers [ 621. 7 The main property of this model is that it takes into consideration the passage of time during the negotiation. This is useful for environments of Example 1 since for a server participating in the negotiation process, the time when an agreement is reached is very important. ’ The model of Alternative Offers provides formal definitions of players, possible agreements, the protocol of alternative offers, and the notion of strategies. In order to apply these concepts to the data allocation problem, we had to match the world state and formal definitions and modify them. For example, in the data allocation scenario, a player is a server and an agreement is a distribution of datasets to information servers. Game theory proposes different notions of equilibria that capture different aspects of stability. Given specific assumptions about the environments, game theory researchers identify strategies that are in equilibrium. In order to address the third need mentioned above, when applying game-theoretic techniques to DA1 environments, we formalized the assumptions that are appropriate for our environments. For example, in the data allocation scenario, all agents sustain a loss over time, there is a finite (but large) set of agreements, and there are some agreements which are better for all agents than opting out of the negotiations. In most of the cases, these assumptions are different from the assumptions that are considered in game theory, and therefore we needed to identify the equilibrium strategies under the DA1 assumptions. The third problem mentioned above arises in DAI situations where the designer of the system cannot provide the automated agent with a negotiation strategy in advance. For example, in the data allocation scenario, finding possible dataset allocations can be done only after the specifications of the datasets are known to the agents and thus cannot ’ See [ 521 for a detailed review of the bargaining game of Alternative Offers. 8 There are two reasons for this. Fit, there is the cost of communication and computation time spent on the negoti~ion. Second, there is the loss of unused info~ation: until an agreement is reached, new documents cannot be used. Thus, the servers wish to reach an agreement as soon as possible, since they receive payment for answering queries. S. KraudArtificial Intelligence 94 (1997) 79-97 8.5 be supplied in advance by the designers. Construction of the strategies which are in ~uilib~urn can rely on theorems proven in advance, but can be done only when the set of possible agreements can be defined. For such situations, there is a need to develop low complexity computational techniques for searching for appropriate strategies by the automated negotiators. The issue of the complexity involved in finding strategies is not discussed in the game theory literature. Another issue that is rarely discussed in game theory is the source of a utility function or a set of preferences that is needed for any decision-making. In game theory, one aspect of a definition of a game is the players’ utility functions or preferences, and it is assumed that each player knows its utility function (and has some knowledge of the utility function of its opponents). A designer of an automated agent is required to the agents with a utility function or a preference relation. Without doing so, the provide techniques cannot be used for automats agents. In the data allocation game-theoretic scenario, we have developed a complex utility function which takes into consideration factors su’ch as storage costs, retrieval costs, distances between servers, etc. Only then can we apply game-theoretic techniques. More details on our work on the strategic model of negotiation and the definition of utility functions can be found in [39,44,45,65]. In the process of developing and specifying the strategic model of negotiation, we have examined bilateral negotiations, as well as multi-agent environments (more than two agents), single encounters and multiple encounters, situations characterized both by complete and incomplete information, and the differing impact of time on the payoffs of the participants [ 39,451. Recently, we have also considered problems where there are two attributes to the agr~ments 1651. While some combinations of these factors can result in minor delays in reaching an agreement, the model nevertheless reveals an important capacity for reaching agreement in early periods of the negotiation.9 By creating coalitions that allow them to share resources and cooperate on task execution, autonomous agents may be able to increase their benefits. Cooperative game- theoretic models can be used to do this for self-motivated agents, each of which has tasks it must fulfill and resources it needs to complete these tasks. though the agents can act and reach goals by themselves, it may be advantageous to join together. For example, taxi drivers may own different types of cabs and therefore may have different costs, different transportation capabilities, and different resulting payoffs. Each taxi driver would like to increase his own benefits, but it may be in the driver’s interest to cooperate and form coalitions in order to achieve greater and more complex trans- portation capabilities. Game-theoretic coalition fo~ation theories can be used in the development of automated agents that represent these drivers as they form coalitions. Game theory [ 11,28,34,5 1,571 provides a good framework with concepts of a coali- tion and coalitional value and different notions of stability, but to use it, we have had 9 In 1441, it was shown how the strategic model can be used in appfications such as a hostage crisis simulation. 86 S. Kraus/Artificial Intelligence 94 (1997) 79-97 the development of algorithms three tasks: the development into account communication to address agents; taking time. Most of the work in game theory does not treat these issues, but only predicts how the players will distribute of explicit protocols for coalition the benefits, given a coalition configuration. formation; while simultaneously costs and limited computation for interaction among the In [68,72] we addressed the three tasks mentioned above and presented algorithms formation for coalition a low complexity Kernel-oriented of this algorithm were examined increases formations provide more benefits and payoff distribution [ 121 coalition via simulations. These have shown in general environments. We focused on algorithm. The properties that the model time period, and more coalition formation the benefits of the agents within a reasonable to the agents. 3. Applying classical mechanics to large scale agent systems There are situations where cooperation is needed. For example, autonomous mobile devices more) users and is still growing. Another example inexpensive air, and underwater together agree in advance on regulations and coalition for environments with a relatively toward satisfying The negotiation environments among a large number of agents the World Wide Web (WWW) is the employment (hundred or consists of millions of of hundreds of simple, to achieve military and civilian goals in ground, the agents work a large set of joint goals, and the designers of the agents can [ 221. In such situations [ 3 1,731, and protocols for the agents’ formation methods presented interaction. in the previous section are small number of agents. But, in very large com- too computationally these negotiation methods are typically Furthermore, with hundreds of agents, direct communication suitable agent-communities, plex and time-consuming. connections between all of the agents may be impossible or too costly to establish. have proved useful in such settings. They use Physical models of particle-dynamics formulation either the properties to describe or to predict states of matter. In particular, we developed efficient mathematical and evolution for coop- of different eration among hundreds of agents by adopting methods of classical mechanics used by physicists among many to tackle particles. Although systems, we have shown enables putational applied example that the approach has a low com- of such systems. We have that the classical mechanics in very large agent-systems; the properties of interaction between particles the problem of finding there are many differences the classical mechanics-based methods approach yields a model feasible cooperation complexity, which for the functioning and computational to the following transportation [ 16,63,75]. techniques is crucial freight system). transportation (e.g., messengers Example 2 (Freight con- to the same sists of many carriers that is company, operating given in units of volume and has a given location. The tasks that the carriers must fulfill that should be are freight transportation transportation moved from various tasks. We deal here with freight (e.g., packages) to other locations. There are many freight The system of freight on motorcycles) which belong in a big city. Each carrier has a freight carrying capability transportation locations S. KraudArtijicial Intelligence 94 (1997) 79-97 87 tasks to perform, and the carriers would like to perform them as soon as possible, while at the same time minimi~ng the company’s expenses. In the above example and in the other DA1 environments that we consider, there is a large set of agents and a large set of goals they need to satisfy. Each agent has capabilities and should move toward satisfying goals. The first step in applying the classical lnechani~s model to DA1 is the match between particles and their properties, agents and their capabilities, and goals and their properties. The next step is to identify the state of matter for modeling a community of agents and goals. The mathematical formulation that is used by physicists either to describe or to predict the properties and evolution of particles in these states of matter serve as the basis for the development of algorithms for the agents. However, several modifications of the classical mechanics model are necessary to provide an efficient algorithm for automated agents. In the physical world, mutual attraction between particles causes motion. The reac- tion of a particle to the field of potential will yield a change in its coordinates and energies. The change in the state of the particle is a result of the influence of the po- tential. For DAI, the agents calculate the attraction and move according to the results of these calculations. That means, in our model, that each agent calculates the effect of the potential field on itself by solving a set of differential equations. According to the results of these calculations, it moves to a new state in the goal-domain. If it reaches a goal, it will proceed to a goal-satisfaction process. In cases where too many agents fit the requirements of the same goal, some are prevented from reaching the goal, through the property of mutual rejection between dynamic particles. We model the goal-satisfaction process by a collision of dynamic particles with static particles. Because the properties of particle collisions are different from the properties of goal- satisfaction, several adjustments were made to develop efficient algorithms for agent systems. For example, in the freight ~~s~~ation system of Example 2 each piece of freight is modeled by a static particle and each carrier is modeled by a dynamic particle, since carriers move toward the task’s location. The volume of carriers’ freight carrying capabilities and the volume of each piece of freight are modeled by particle masses, and their locations by particle locations. The interaction between a carrier and a piece of freight is modeled by the mutual potential function of the modeling particles. It is calculated with respect to the distance between them. The potential functions derivatives yield forces which act on a dynamic particle and direct it. That is, the advancement towards a piece of freight is modeled by the movement of a dynamic particle towards a static particle. Repulsion between two dynamic particles which model two different carriers will influence the freight- task distribution among the carriers and will prevent two carriers from proceeding to a piece of freight which can be moved by one carrier. The performance of a freight- transportation task is modeled by the collision between a static particle, which models the task, and a dynamic particle, which models the agent. In [70], we provide a detailed algorithm to be used by a single agent within the system. The algorithm leads to agent-goal allocation, and it converges to a solution where the fulfillment of goals is accomplished either by single agents or by groups of agents 88 S, Kraus/Art$cial Intelligence 94 (1997) 79-97 via cooperation. The computational In addition necessary. relatively close to the optimum. performs complexity to these properties, we have proven is low, and no explicit communication is that the algorithm we provide techniques can rely on theoretical from physics. According for their validity either by a formal proof or by simulations, The physics approach has several advantages. While common DA1 algorithms must the models results the in the same manner as a the complexity of the model. In that promises emergent the properties of the system as a whole of such the properties of its be checked that are based on physics that are already known evolution of the modeled agent-system, physical corresponding global behavior of the system, assure a low computational very large-scale cooperative goal-satisfaction can be analyzed, using concepts concepts enables us to derive components. it will evolve system. The local interactions, which enable one to derive from statistical mechanics. The employment to these results, one can predict this approach provides a model the properties of a system activity. In addition, and experimental agent-systems, through since 4. Applying operations research techniques situations of cooperative together on fulfilling tasks automated agents: [ 481, multi-agent Many DA1 researchers have considered several workstations working for example, for integration of design, manufacturing erative shipping companies the satisfaction advance, protocols and the agents can communicate of a joint goal; for cooperation between We recommend, in such situations, [ 181. In such situations, all the agents work together and shop floor control activities [ 41, and coop- toward in the agents; the number of agents is not large; agents can develop, the designer of the automated and have computation capabilities. the consideration of operations research techniques. in operations research seek to determine how best to design and operate an system, usually under conditions of scarce resources Autonomous agents working in DPS environments system, and thus algorithms research may be applied that were developed nizational in operations to DAI environments. vironments with a few dozen agents with large computation research techniques computational efficiency decreases with the size of the organization complexity of the operations [ 761. can be considered as an orga- for human organizations for en- This is suitable capabilities, the is usually high, and their because to which they are applied. Researchers organizational for the set We have applied operations research problems techniques which were developed for coalition formation and set partitioning in DPS environments a set of agents and a set of tasks which the task. An example section. The company covering [ 69,711. Given consider situations where each task should be attached perform previous lift trucks, cranes, boats, and planes. The drivers belong benefits equally, and thus try to maximize be occasions In such cases, cooperation to satisfy, we to a group of agents which will in the services via a number of trucks, to a cooperative and share the the overall benefits of the company. There may task by itself. is necessary. Therefore, several drivers will form groups, and in which one vehicle cannot perform a given transportation company, similar is a transportation to the example transportation they have supplies S. Kraus/Artificial Intelligence 94 (1997) 79-97 89 each gr0u.p will fulfill a transportation task cooperatively. If the transportation company has many drivers, a dist~but~ task allocation m~hanism may be advantageous. As we mentioned above, task allocation among agents may be approached as a problem of assigning groups of agents to tasks, and, therefore, the partition of the agents into subgroups becomes the main issue, and our problem becomes similar to the Set Partitioning Problem (SPP). Set partitioning entails the partition of a set into subsets, and the set petitioning problem is finding such a partition that has a minimal cost. lo The SPP has been dealt with widely in the context of NP-hard problems 1231, and apptoximation algorithms were developed in operations research [ 2,3,9,10,24]. Among them we can find the algorithm of Chvatal [lo], which has a logarithmic ratio bound. ” The details of the algorithm that we developed, which is based on the operations research methods for the SPP is specified in [69]. Although the general task allocation problem is computationally exponential, the algorithm above is polynomial and yields results which are close to the optimal results and bounded by a logarithmic ratio bound. Another advantage of the algorithm, which is crucial in the case of a distributed system, is the distribution of the algorithm. We distribute the calculations in a natural way. That is, the dis~bution is an outcome of the algorithm ch~acte~stics, since each agent performs mostly those calculations that are required for its own actions during the process. In addition, our distribution method prevents most of the possibly overlapping calculations, thus saving unnecessary computational operations. The algorithm is an anytime algorithm. If halted before normal termination, it still provides the system with severai coalitions that have already formed. Since the first coalitions to be formed are the better ones, the results, when halted, are still of good quality. The anytime property of such an algorithm is important for dynamic environ- ments, wherein the time-period for negotiation and coalition formation processes may be changed during the process. In another paper [SS], we considered the problem of dis~ibut~ dynamic task allo- cation by 3 set of cooperative agents. We modeled the agents, using a stochastic closed queueing network, which is a well known operations research technique. In both cases, we have developed polynomial algorithms that provide near optimal results. From our experience, we realized that in order to apply operations research techniques to DA& there are several steps that must be taken. First, there is the need to find a problem that was considered in operations research which is close to the DAI problem and to make a detailed match between the problems. For example, in the coalition formation problem described above, we realized that it is close to the SPP or SCP problems. Then, there is the need to adjust the operations research algorithm to the DAI environment. In particular, most of the operations research algorithms are centralized, and, since we deal with autonomous agents, we seek distribute algorithms. In addition, there is the need to develop utility functions that can be used by the agents. In operations research it is assumed that cost function is provided as part of formation where coalitions may overlap cau be approached lo Coalition Ii An approximation the optimal cost and the approximated algorithm cost. for a problem has a ratio bound p(n) if p(n) as a Set Covering Problem (SCP) _ is smaller than the ratio between 90 S. Kraus/Artifcial Intelligence 94 (1997) 79-97 (as in game techniques the problem efficient to develop to provide a distributed is different depends on the coalitional from Although adjusting effort, we determined techniques environment. theory). In our model, we need to provide to calculate them (see also [ 641) . For example, the agents with in [ 69,7 1 ] we had and value value, since here the value the cost function and coalitional values in the context of task allocation algorithm to compute the notion of game-theoretic configuration them. This notion of coalitional coalitional and on the task allocation. the operations that the benefits research techniques from using to DA1 situations required some these well-developed methods, and for the DA1 for evaluating them, may help in reaching efficient algorithms 5. The application of informal models of behavioral and social sciences to automated agents agents need for example, an information There are situations where automated environments; document in negotiation non-structured a multi-media train people [ 81. In such situations, need to interact with people. The number of agents in the environment communication in server which works to form that help that sell goods on the World Wide Web the automated agents is not large, and a complex query of a user, agents to interact with other agents the agents are self-motivated, [ 441, and agents for answering and usually is possible. that formalizing In such situations, we found informal models of behavioral and social sciences can be beneficial. Behavioral and social sciences study hu- man cooperation and communities ments, heuristics successful human cooperation and develop frameworks and models of organizations environ- agents, based on and coordination (e.g., for cooperation ) . In non-structured among automated and implementing and unpredictable and coordination and interaction [ 20,46,59,60] We have applied informal models discuss one of them below. Applying to different informal models (a) using the informal models as motivation techniques, may be useful. types of environments, and we will to DA1 can be done in two ways: for of heuristics for the development (b) the informal models (e.g., using logic) and then applying them to a activities of the automated agents; the cooperative formalizing DA1 environment. since the informal models usually do not formally analyze In both cases, there is a need to carry out simulations of the techniques, of the systems. The main advantage and expertise experience interactions, success [ 41,421, the performance the behavior is that we build upon type of in the specific from scratch and using only our own experience. Our in particular automated negotiators these models the years that were developed over of specific applications, in the developments in order to evaluate than starting this claim. in using supports rather There are two main approaches to the development of theorems to negotiation. The first approach, which we used in Section 2.1, is the formal approach provides clear analyses of the strategy a negotiator should choose. relating theory of bargaining. This formal game-theoretic various situations and precise results concerning in the social sciences S. ~raus/~~~cia~ lnre~f~gence 94 (1997) 79-97 91 However, it requires making restrictive assumptions, and the agents need to follow strict negotiation protocols which are not possible in some real world environments. The second approach, which we refer to as the negotiation guides approach, comprises informal theories which attempt to identify possible strategies for a negotiator and to These assist him in achieving good results (see, for example, [ 13,19,29,33,35]). negotiatmn guides do not accept the strong restrictions and assumptions presented in the game-theoretic models. Applying these methods to DA1 is more difficult than using the first approach, since there is no formal theory nor strategies that can be used. However, these methods can be used in domains where people interact with each other and with automated agents, and situations where automated agents interact in environments without pre defined regulations. These informal models can serve as guides for the development of negotiation heuristics [41] or as a basis for the development of a logical model of negotiation [ 421. In [ 37,411, we developed a general structure for a self-motivated negotiating Au- tomated Agent acting in environments where cooperation between the agents may be beneficial., but where conflicts among the agents can arise. There are no strict regula- tions and protocols for the negotiation, there is no mediator, and central controllers do not exist. Thus agreements are not enforced, and agents may break their promises, The agents have incomplete information concerning the other agents’ goals and tasks, and an agent can provide the other agents with false information. As a testbed, a specific domain was chosen, the ~i~lorn~cy game, which is rich enough to include most aspects of negotiation. I2 Given a (restricted version of) natural language which covers this domain, our agent, Diplomat, was confronted with human agents and even demonstrated an advantage over its human negotiation partners. The framework of Diplomat consists of five modules: the Prime Minister, that directs the Diplomat’s activities; the Ministry of Defense, that is responsible for the planning; the Foreign O&e, that negotiates with the other players; the Headquarters that exe- cutes the basic tasks of Diplomat; and the ~~teZZigence Agency, that is responsible for collecting information about the environment and the other players. These modules are implemented by a dynamic set of local agents that work together, communicate, and exchange messages to achieve the common general tasks of Diplomat. In the design of Diplomat and in choosing the negotiation heuristics it uses, we used different general informal negotiation guides. For example, as we mentioned above, Diplomat consists of different modules for planning-i.e., and negotiations-i.e., the Foreign Office. The development of different modules for negotiation and planning is a characteristic of a good negotiator, according to Fisher and Ury’s mod.el [ 191. They suggest that a good negotiator should do much “inventing”, that is, find out new ideas that are not already among the negotiation issues. The separation of the planning and negotiation into two modules enables the Ministry of Defense to find as many solutions to the problem as possible, without taking into account whether or not they are acceptable to the other side. The ideas will not be conveyed to the other the Ministry of Defense- I2 Diplomacy years just prior of the game. is a board game marketed by Avaton Hill Company and played on the map of Europe during to World War I. Coalitions and agreements among the players significantly affect the the course 92 S. Kraus/Artijicial Intelligence 94 (1997) 79-97 the Foreign Office decides side until Ministry of Defense can do no harm. to do so. Therefore, their consideration by the There are several heuristics that Diplomat uses to decide how to make suggestions agreement with another the that will be a basis for the agreement. Since a negotiator wants to “win”, one and choosing that will guide him while comparing strategies and compares a cooperation to choose them several possible that the only criterion strategies will be his own benefits derived to another agent. For example, when considering agent, Diplomat designs strategy may suspect between from has been suggested by the literature on human negotiation, reason beneficial to all parties reach a more appealing same reason, Diplomat agreement. In order even without the other partner should be convinced [ 191); otherwise he will suspect in order involved. Otherwise, agreement, that phenomena is that (see for to test Diplomat, we arranged that Diplomat played well [41] ) show for the agreement a neglected partner may be tempted the strategies. However, as this is not the case. The it should be to that to that the negotiator will later break the informing that the agreement the negotiator. For is profitable to last, in the games several Diplomacy games, and our findings it participated. techniques we theories in which of the heuristic informal of negotiator agents and well developed is due to the integration (see We believe developed of negotiation, t3 that its success for the construction 6. Conclusions techniques, several attempts such as game theory and to apply methodologies that we in Table 1. The last column uses the pa- techniques the problems to characterize that we considered. in environments where the agents are automated that the agents will follow some agreed-upon pro- that classical mechanics models are (Section 3). We agents In this paper we argue that applying multi-entity in DAI is given to DAI, but it is possible in the introduction is beneficial. We described physics, from diverse fields to DA1 problems. A summary of the multi-entity used and their application rameters presented For example, we applied game theory and self-motivated, tocols useful applied operations among a relatively social science models of cooperation when operation demonstrated SharedPlans (Sections for task distribution research small set of cooperative agents 2.1 and 2.2). We demonstrated in very techniques that ideas drawn from philosophy among agents (Section 5), or when communication was not possible such as queueing networks large sets of cooperative [ 26,271. there were no strict protocols for task distribution (Section 4). We used the less formal for the co- [ 15,431. Further, we of can be the basis for the development I3 We have applied other forms a basis based negotiator models of cooperative work together &helling [ 58,661, informal models for the development to DA1 situations. of a formal axiomatization that of a logic- [ 141 based on persuasion models informal [7] teams composed of people and computers plan and a shared goal. In [ 15,431, we used the notion of focal point introduced by In [42], we developed a formal system and the implementation [ I]. In [ 26,271, we have applied philosophical activity toward satisfying for situations where logic for multi-agent cooperation without communication. S. Kraus/Art$cial Intelligence 94 (1997) 79-97 93 Table 1 Summary of multi-entity techniques and their application in DAL In the last column, SMA stands for self- motivated agents, and CA indicates cooperative agents which work toward satisfying the same goal (see Section 1) . R&P indicates that the designers can agree on regulations and protocols for agents interaction. s#, m# and I# srands for environments with small (handful), medium (few dozen), or large number (hundreds) of agents, respectively. AUTO indicates environments with only automated agents, and AUTO&PE stands for systems composed of people and automated agents. That communication is possible is indicated by COMU. Multi-en&v techniaues DA1 Paoers Characterization Game theory Strategic bargaining models Negotiation for task distribution & Resource allocation in MA Theories of coalition Coalition formation in MA formation ~inciple-~lgent models Con~cting tasks in MA 144,451 L391 168,721 138,401 SMA, s#, R&P, AUTO, COMU SMA, m#, R&P, AUTO, COMU SMA, s#, R&P, AUTO, COMU Goal satisfaction in very Iarge DPS environments [701 CA, I#, R&P, AUTO Physics Classical mechanics Operations research SPP & SCP Coalition formation in DPS 169,711 Queueing networks Task allocation in DPS [551 Behavioral sciences Negotiation guides Diplomatic negotiation Persuasion models (logic) Argumentation Focal points (logic & decision theory) Cooperation without communication 137,411 [ 14,421 [ 15,431 Philosophy (logic) Collaborative plans 126,273 CA, m#, R&P, AUTO, COMU CA, m#, R&P, AUTO, COMU SMA, m#, AUTO&PE, COMU SMA, s#, AUTO&P& COMU CA, m#, AUTO, R&P CA&WA, m#, AUTO&PE, COMU There are two main aspects of a multi-entity environment that determine its usefulness to a DA1 problem and its effect on the amount of work required techniques between fo~aIizati(~n for it to the DAI problems. The first criterion and that is used by researchers of the multi-entity developed the entities agents. The second criterion the automated domains. for the adaptation of is the similarity is the level of For example, people are more similar to automats agents than are particles. Therefore, the multi-entity in all was not difficult multi-agent can model automated mechanics framework model goal-satisfaction. to match domains. For example, the entities techniques that were developed for humans environments, in the environment and the participants it in the it is clear that players in game-theoretic It is Iess clear which types of particles for agents and that collisions frameworks in the cIassica1 are a good way to agents. serve as models 94 S. Kraus/Artificial Intelligence 94 (I 997) 79-97 than techniques from formal multi-entity models The second criterion has to do with the fact that we need to provide our automated algorithms. With respect to this, it is easier to use agents with formal and well-designed techniques that were not formalized by their developers. For example, even though people and automated agents have much for to cooperation, in common, with respect ideas, procedures, and rules that are presented by agent cooperation based on the informal social scientists and philosophers. Much effort is required to formalize and rules and the other hand, after going using a classical mechanics mechanics adjust procedure agents. On of agents techniques of classical and to the formal through framework, is not so difficult. There the process of modeling the usage of the formal to develop an algorithm the formal procedures but there is no need is a need to modify for the automated it is quite difficult to the multi-agent an implementable these procedures from scratch. a community requirement, to produce algorithm to create them Acknowledgments I would like to thank the many people who, over the years, have collaborated with me: C. Bat-al, E. Blake, P. Bonatti, E. Ephrati, A. Evenchik, D. Etherington, M. Fenster, B. Grosz, M. Harris, J. Hendler, K. Holley, J. Horty, D. Lehmann, G. Lemel, M. Magidor, J. Rosenschein, A. Schwartz, 0. Shehory, J. Minker, M. Nirkh, D. Perlis, T. Plotkin, and G. Zlotkin. Our Y. Shoham, S. Subrahmanian, K. Sycara, B. Thomas, J. Wilkenfeld, and coordination. joint work influenced my thinking on cooperation I would like Shehory and Orna Schechter, the Computers was preparing Shifra Hochberg for editorial assistance. to thank Barbara Grosz, Martha Pollack, each of whom also provided help and support while lecture and this paper. Special and Thought Jonathan Wilkenfeld, Onn I to Dr. thanks This work was supported by the NSF under Grants No. IRI-9423967 and IRI-9311988 and the Israeli Ministry of Science, Grants No. 6288 and 4210. References [ I ] H. Abelson, Persuasion (Springer, New York, 1959). [2] E. Balas and M. Padberg, On the set covering problem, Oper. Res. 20 (1972) 1152-l 161. [ 31 E. Balas and M. Padberg, On the set covering problem: an algorithm for set partitioning, Oper. Res. 23 (1975) 74-90. [4] S. Balasubramanian and shop-floor 3-19. and D. Norrie, A multi-agent intelligent design system in: Proceedings 1st International Conference on Multiagent Systems ( 1995) integrating manufacturing control, 151 T. Balch and R.C. Arkin, Motor schema-based formation control for multiagent robot teams, in: Proceedings 1st International Conference on Multiagent Systems (1995) 10-16. [6] A.H. Bond and L. Gasser, An analysis of problems and research in DAI, in: A.H. Bond and L. Gasser, eds., Readings in Distributed Artificial Intelligence (Morgan Kaufmann, San Mateo, CA, 1988) 3-35. [71 M.E. Bratman, Shared cooperative [ 81 A. Chavez and P Maes, Kasbah: an agent marketplace activity, Philosophical Review 101 (1992) 327-341. in: Proceedings 1st International Conference on the Practical Application of Intelligent Agents and Multi Agents Technology, London for buying and selling goods, (1996)75-90. S. Kraus/Artijicial Intelligence 94 (1997) 79-97 95 [9] N. Christofides and S. Korman, A computational survey of methods for the set covering problem, Math. Oper. Res. 21 (1975) 591-599. [ lo] V. Chvatal, A greedy heuristic [ 1 l] M.S.Y. Chwe, Farsighted [ 121 M. Davis and M. Maschler, The kernel of a cooperative game, Naval Res. Logist. Quart. 12 (1965) for the set-covering problem, Math. Oper. Res. 4 ( 1979) 233-235. stability, J Economic Theory 63 (1994) 299-325. coalitional 223-2.59. [ 131 D. Dnrckman, Negotiations (Sage, Beverly Hills, CA, 1977). [ 141 A. Evenchik, Inference system for argumentation in negotiation between automatic agents, M.Sc. Thesis, Department of Mathematics and Computer Science, Bar-&n University, Ramat Gan, Israel ( 1995). [ 151 M. Fenster, S. Kraus and J. Rosenschein, Coordination without communication: experimental validation in: Proceedings Jst International Conference on Multiagent Systems ( 1995) of focal point techniques, 102-l 16. [ 161 K. Fischer and N. Kuhn, A DA1 approach 93-25, Deutsches Forschungszentrum fiir Kiinstliche to modeling the transportation Intelligenz GMBh domain, Technical Report RR (1993). [ 171 K. Fischer, J.P. Milller, I. Heimig and A. Scheer, Intelligent agents in virtual enterprises, in: Proceedings 1st In!ernational Conference on the Practical Application of Intelligent Agents and Multi Agents Technology. London, 1996. [ 181 K. Fischer, J.P. Milller, M. Pischel and D. Schier, A model for cooperative transportation scheduling, in: Proceedings 1st International Conference on Multiagent Systems ( 1995) 109-l 16. [ 191 R. Fisher and W. Ury, Getting to Yes: Negotiating Agreement without Giving in (Houghton Mifllin, Boston, MA, 1981). [20] R.C. Ford, R.B. Armandi and CF? Heaton, Organization Theory: An Integrative Approach (Harper and Row, New York, 1988). [ 211 D. Fudenberg [22] D.W. Gage, Command [23] M.R. Garey and D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-Completeness and J. Tirole, Game Theory (MIT Press, Cambridge, MA, 1991). systems, Unmanned Systems (Fall, 1992) 28-34. for many-robot control (Freeman, New York, 1979. [24] R.S. Garfinkel and G.L. Nemhouser, The set-partitioning problem: set covering with equality constraints, Oper. .Res. 17 (1969) 848-856. [25] L. Glicoe, R. Staats and M. Huhns, A multi-agent environment for department of defense distribution, in: Proceedings IJCAI-95 Workshop on Intelligent Systems, Montreal, Que. ( 1995). [26] B. Grclsz and S. Kraus, Collaborative (1993) 367-373. France plans for group activities, in: Proceedings IJCAI-93, Chambery, [27] B.J. Grosz and S. Kraus, Collaborative plans for complex group activities, Artificial Intelligence 86 (1996, 269-357. [ 281 S. Gui;lsu and M. Malitza, Coalition and Connection in Games (Pergamon, Oxford, 1980). [ 291 Lavinia Hall, ed., Negotiation: Strategies for Mutual Gain (Sage, Beverly Hills, CA, 1993). 1301 J.C. Harsanyi, Rational Behavior and Bargaining Equilibrium in Games and Social Situations (Cambridge University Press, Cambridge, 1977). [ 311 T. Hogg, Social dilemmas in computational Montreal, Que. (Morgan Kaufmann, San Mateo, CA, 1995) 711-718. ecosystems, in: C.S. Mellish, ed., Proceedings IJCAI-95, [32] N.R. Jennings, Controlling cooperative problem solving in industrial multi-agent systems using joint intentions, Artificial Intelligence 75 (1995) l-46. [ 331 R. Johnson, Negotiation Basics (Sage, Beverly Hills, CA, 1993). [ 341 J.P. Kahan and A. Rapoport, Theories of Coalition Formation (Lawrence Erlbaum, Hillsdale, NJ, 1984). [35] C.L K..urass, The Negotiating Game: How to Get What You Want (Thomas Crowell Company, New York, 1970). [ 361 M. Klusch and 0. Shehory, A polynomial kernel-oriented information agents, [37] S. Kraus, Planning and communication in: Proceedings ICMAS-96, Kyoto, Japan coalition ( 1996). formation algorithm for rational in a multi-agent environment, Ph.D. Thesis, Hebrew University, Jerusalem, 1988 (written largely [38] S. Kraus, Agents contracting in Hebrew). tasks in non-collaborative Washington, DC ( 1993) 243-248. environments, in: Proceedings AAAI-93, S. Kraus/Arttjicial Intelligence 94 (1997) 79-97 96 [391 1401 1411 1421 I431 [441 [451 [461 among autonomous 132-171. information in multiple encounter negotiations S. Kraus, Beliefs, time and incomplete agents, Ann. Math. Artif: Intell. ( 1997). S. Kraus, An overview of incentive contracting, Artificial Intelligence 83 (1996) 297-346. S. Kraus and D. Lehmann, Designing (1995) S. Kraus, N. Nirkhe and K.P Sycara, Reaching agreements Proceedings DAI-93 ( 1993). S. Kraus and J.S. Rosenschein, The role of representation alternative (Elsevier, Amsterdam, S. Kraus and J. Wilkenfeld, A strategic negotiations model with applications and building a negotiating in interaction: discovering through argumentation: 1992) 147-165. automated solutions, focal points among in: E. Werner and Y. Demazeau, eds., Decentralized Art$cial Intelligence, Vol. 3 agent, Comput. Intell. 11 to an international crisis, a logical model, in: J. Wilkenfeld and Cl. Zlotkin, Multiagent IEEE Trans. Systems Man Cybernet. 23 (1993) 313-323. S. Kraus, Intelligence 75 (1995) 297-345. W.A. Kraus, Collaboration in Organizations: Alternatives to Hierarchy (Human Sciences Press, New York, 1984). R.D. Lute and H. Raiffa, Games and Decisions (John Wiley and Sons, New York, 1957). time constraints, Artificial negotiation under [471 [48] T.W. Malone, R.E. Fikes, K.R. Grant and M.T. Howard, Enterprise: for ed., The Ecology of Computation (North- task schedule a marketlike distributed computing Holland, Amsterdam, environments, 1988) 177-205. in: B.A. Huberman, 1996. [49] R. Myerson, Game Theory (Harvard University, 1991). [50] NASA, EOSDIS home page, http://www-vOims.gsfc.nasa.gov/vOims/index.html, 1511 1996). (submitted, for cooperative aid, in: Proceedings 3rd ( 1994). task allocation in: Proceedings ARPI Annual Meeting, Tucson, AZ ( 1994). J. von Neumann and 0. Morgenstem, Theory of Games and Economic Behavior (Princeton University Press, Princeton, NJ, 1947). M.J. Osborne and A. Rubinstein, Bargaining and Markets (Academic Press, San Diego, CA, 1990). M.J. Osborne and A. Rubinstein, A Course in Game Theory (MIT Press, Cambridge, MA, 1994). C. Petrie, M. Cutlosky and H. Park, Design space navigation as a collaborative International Conference on Artificial Intelligence in Design, Lausanne T. Plotkin and S. Kraus, A queueing network approach to distributed agents M. Pollack, T. Znati, E. Ephrati, D. Joslin, S. Lauzac, A. Nunes, N. Onder, Y. Ronen and S. Ur, The dipart project, A. Rapoport, N-Person Game Theory (University of Michigan, Ann Arbor, MI, 1970). E. Rasmusen, Games and Information (Basil Blackwell Ltd., Cambridge, MA, 1989). M.1. Reed, The Sociology of Organisations: Themes, Perspectives and Prospects (Harvester Wheatsheaf, New York, 1992). S.P Robbins, Organization Theory (Prentice Hall, Englewood Cliffs, NJ, 1990). J.S. Rosenschein Among Computers (MIT Press, Boston, MA, 1994). A. Rubinstein, Perfect equilibrium T. Sandholm, An implementation Proceedings AAAI-93, Washington, DC (1993) 256-262. T.W. Sandholm and V.R. Lesser, Coalitions among computationally 94 (1997) 99-137 0. Schechter, Sharing Ban University, Ramat-Gan, T.C. Schelling, The Strategy of Conflict (Oxford University Press, New York, 1963). S. Sen and E.H. Durfee, A formal study of distributed meeting Negotiation Support Systems ( 1997). 0. Shehory and S. Kraus, Coalition From Reactions to Cognition (Springer, Berlin, 1995) 57-72. in a bargaining model, Economefrica 50 (1982) 97-109. of the contract net protocol based on marginal cost calculations, and G. Zlotkin, Rules of Encounter: Designing Conventions for Automated Negotiation bounded agents, Artificial Intelligence environments, Master’s Thesis, Bar- agents: strategies and complexity, formation among autonomous (this issue). resources in: Group Decision and through negotiation Israel ( 1996). in multi-agent scheduling, in: in: 1521 L531 [541 [551 [561 [571 1581 1591 [601 [611 [621 I631 [641 [651 [661 [671 [681 [69] 0. Shehory and S. Kraus, Task allocation Proceedings IJCAI-95, Montreal, Que. (1995) 655-661. via coalition formation among autonomous agents, in: S. Kraus/Arti&ial Intelligence 94 (1997) 79-97 97 [70] 0. Shehory and S. Kraus, Emergent cooperative goal-satisfaction in large scale automated-agent systems, in: Proceedings ECAI-96, Budapest ( 1996) 544-548. and S. Kraus, Formation of overlapping [ 711 0. Shehory coalitions for precedence-ordered task-execution among autonomous agents, in: Proceedings ICMAS-96 ( 1996) 330-337. [72] 0. Shehory and S. Kraus, A kernel-oriented model for coalition-formation in general environments: Implementation and results, in: Proceedings AAAI-96, Portland, OR (1996) 134-140. [73] Y. Shoham the emergence simulations, Artificial Intelligence 94 ( 1997) 139-166 and M. Tennenholtz, On [74] M.B. Tsvetovatyy and M. Gini, Toward of social conventions: modeling, (this issue). a virtual marketplace: architectures and analysis and strategies, in: Proceedings 1st International Conference on the Practical Application of Intelligent Agents and Multi Agem Technology. London (1996) 597-614. [75] MI? Wellman, A market-oriented programming environment and its application to distributed multicommodity flow problems, J. Artif: Intell. Res. 1 (1993) l-23. [ 761 W.L. Winston, Operations Research: Applications and Algorithms ( PWS-Kent Publishing Company, Boston, MA, 1987). 