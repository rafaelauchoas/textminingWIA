Artificial Intelligence 175 (2011) 648–672Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMechanism design for the truthful elicitation of costly probabilisticestimates in distributed information systemsAthanasios Papakonstantinou, Alex Rogers∗, Enrico H. Gerding, Nicholas R. JenningsSchool of Electronics and Computer Science, University of Southampton, Southampton, SO17 1BJ, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 27 October 2009Received in revised form 8 October 2010Accepted 20 October 2010Available online 23 October 2010Keywords:Multiagent systemsScoring rulesAuction theoryMechanism designThis paper reports on the design of a novel two-stage mechanism, based on strictly properscoring rules, that allows a centre to acquire a costly forecast of a future event (such asa meteorological phenomenon) or a probabilistic estimate of a specific parameter (suchas the quality of an expected service), with a specified minimum precision, from oneor more agents. In the first stage, the centre elicits the agents’ true costs and identifiesthe agent that can provide an estimate of the specified precision at the lowest cost.Then, in the second stage, the centre uses an appropriately scaled strictly proper scoringrule to incentivise this agent to generate the estimate with the required precision, andto truthfully report it. In particular, this is the first mechanism that can be applied tosettings in which the centre has no knowledge about the actual costs involved in thegeneration an agents’ estimates and also has no external means of evaluating the qualityand accuracy of the estimates it receives. En route to this mechanism, we first considera setting in which any single agent can provide an estimate of the required precision,and the centre can evaluate this estimate by comparing it with the outcome which isobserved at a later stage. This mechanism is then extended, so that it can be applied ina setting where the agents’ different capabilities are reflected in the maximum precisionof the estimates that they can provide, potentially requiring the centre to select multipleagents and combine their individual results in order to obtain an estimate of the requiredprecision. For all three mechanisms (the original and the two extensions), we provetheir economic properties (i.e. incentive compatibility and individual rationality) and thenperform a number of numerical simulations. For the single agent mechanism we comparethe quadratic, spherical and logarithmic scoring rules with a parametric family of scoringrules. We show that although the logarithmic scoring rule minimises both the mean andvariance of the centre’s total payments, using this rule means that an agent may face anunbounded penalty if it provides an estimate of extremely poor quality. We show thatthis is not the case for the parametric family, and thus, we suggest that the parametricscoring rule is the best candidate in our setting. Furthermore, we show that the ‘multipleagent’ extension describes a family of possible approaches to select agents in the firststage of our mechanism, and we show empirically and prove analytically that there isone approach that dominates all others. Finally, we compare our mechanism to the peerprediction mechanism introduced by Miller et al. (2007) [29] and show that the centre’stotal expected payment is the same in both mechanisms (and is equal to total expectedpayment in the case that the estimates can be compared to the actual outcome), while thevariance in these payments is significantly reduced within our mechanism.© 2010 Elsevier B.V. All rights reserved.* Corresponding author. Tel.: +44 0 23 8059 7681; fax: +44 0 23 8059 2865.E-mail address: acr@ecs.soton.ac.uk (A. Rogers).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.10.007A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–6726491. IntroductionReal-time information about the state of the world is increasingly being made available through distributed online sys-tems that are owned by different stakeholders and accessed by multiple users. In such systems, it is important to developprocesses that can evaluate the information provided to users and provide some guarantees to its quality. This is partic-ularly so in cases where the information in question is an imprecise probabilistic estimate or forecast whose generationinvolves some cost. Examples include forecasts of future events such as weather conditions [41], where the costs are thoseof running a large scale weather prediction model, or probabilistic estimates of the quality of service within a reputationsystem [18] where such costs represent the computational task of accessing and evaluating previous interactions records. Insuch settings, it is reasonable to assume that the providers of such information are rational self-interested agents, and assuch, may have an incentive to misreport their estimates, or to allocate less costly resources to their generation, if they canincrease their own utility by doing so (e.g. by being rewarded for a more precise estimate than is actually provided or byclaiming to expend more resources than was actually done).1 Thus, an information buyer must present the providers witha payment scheme that incentives the agents to commit resources to generating their estimates, and to truthfully reportthem.A number of researchers have proposed the use of strictly proper scoring rules to address these challenges [25,36]. Mech-anisms using these rules reward accurate estimates or forecasts by making a payment to agents based on the differencebetween an event’s predicted and actual outcome (observed at some later stage). Such mechanisms have been shown toincentivise agents to truthfully report their estimates in order to maximise their expected payment [37]. This principle canbe demonstrated through a meteorological scenario, which uses a logarithmic scoring rule. Specifically, we consider that arisk-neutral agent is asked to provide a probabilistic prediction of whether it will rain or not the following day. The agent’strue estimate of the probability of rain tomorrow is denoted by p, and the prediction that it actually reports to the centreis denoted by (cid:2)p.We first consider the perfectly plausible sounding rule that the agent should be rewarded in proportion to how confi-dently it predicted the actual outcome. That is:S((cid:2)p|x = rain) = (cid:2)p and S((cid:2)p|x = no rain) = 1 − (cid:2)pwhere x is the actual outcome verified the next day. In this case, the agent’s expected utility is given by:U (p,(cid:2)p) = p(cid:2)p + (1 − p)(1 − (cid:2)p)(1)(2)Now, for any particular true belief, p, the agent will seek to report a value of (cid:2)p which will maximise its expected utility. Inthis case, we note that ∂ U (p,(cid:2)p)/∂(cid:2)p = 2p − 1, which is independent of (cid:2)p. Thus, we must consider the boundary conditionsand find that if p < 1/2, then the agent maximises its expected reward by reporting (cid:2)p = 0, and if p > 1/2, then the agentmaximises its expected reward by reporting (cid:2)p = 1. Clearly, under this scoring rule the agent will misreport its true beliefs,and thus, the centre will not receive a true estimate of the probability of rain tomorrow.In contrast, consider the case when the logarithmic scoring rule is used such that the agent is now rewarded in propor-tion to the logarithm of the probability with which it predicted the actual outcome; that is:S((cid:2)p|x = rain) = ln(cid:2)p and S((cid:2)p|x = no rain) = ln(1 − (cid:2)p)In this case, the agent’s expected utility is given by:U (p,(cid:2)p) = p ln(cid:2)p + (1 − p) ln(1 − (cid:2)p)and its derivative is given by:∂ U (p,(cid:2)p)∂(cid:2)p= p − (cid:2)p(cid:2)p(1 − (cid:2)p)(3)(4)(5)Now, solving ∂ U (p,(cid:2)p)/∂(cid:2)p = 0 gives (cid:2)p = p, and thus, the agent will truthfully report its true belief regarding the probabilityof the outcome.Due to the attractive property outlined above, strictly proper scoring rules have recently been used in computer scienceto promote the honest exchange of beliefs between agents [44], and within reputation systems to promote truthful reportingof feedback regarding the quality of a service experienced [19–21]. Furthermore, Miller et al. [29,28] have exploited the factthat any affine transform of a strictly proper scoring rule is also a strictly proper scoring rule, and have shown how anappropriately scaled strictly proper scoring rule can be used induce agents to commit costly resources to generate theirestimates.21 Note that problems of this type are often categorised as principal-agent problems [11,35] since there is an asymmetry of information between thecontractor and contractee.2 We shall describe their approach in detail in Section 3 since our results build upon their setting.650A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672While these approaches are effective in the specific cases that they consider, they all rely on the fact that the cost ofthe agent providing the estimate or forecast is known by the centre. This is not the case in our scenario where these costsrepresent private information known only to each individual agent (since they are dependent on the specific computationalresources available to the agent). In this paper, we use techniques from mechanism design [24], and specifically auction theory[23], to address this challenge. In particular, through the use of an auction protocol that uses strictly proper scoring rules todetermine the payments to the agents, we incentivise the agents to truthfully reveal their costs to the centre and to generateand truthfully report an estimate at a required precision. In more detail, we introduce a novel two-stage mechanism. In thefirst stage, the centre elicits the agents’ true costs and identifies the agent that can provide an estimate of the specifiedprecision at the lowest cost. Then, in the second stage, the centre uses an appropriately scaled strictly proper scoring ruleto incentivise this agent to generate the estimate with the required precision, and to truthfully report it.We then go on to extend this mechanism in two ways. First, we relax the assumption that the selected agent can alwaysprovide an estimate as precise as the centre requires. Although this assumption is made in all the aforementioned workin this area, we believe it is unrealistic as often agents may have to deal with restrictions such as the lack of previousrecords for the reputation systems or the physical limits of making probabilistic predictions of real-world events, whichsubsequently enforce limitations on the precisions of the estimates they can provide. Hence, we extend the mechanism toconsider the case where multiple suppliers can provide estimates, but due to their limited precisions, the centre may haveto combine several of them in order to obtain the desired degree of accuracy. In doing so, we provide a non-trivial extensionof the initial mechanism in which a centre in the first stage asks N agents to report their costs and then pre-selects M ofthem, while in the second stage it asks those pre-selected agents to reveal their maximum precision and then to generatean estimate at that precision until it achieves its required precision.Second, we relax the assumption that the centre has knowledge of the actual outcome of the event some time inthe future after it receives the agents’ estimates (in order that it can calculate the payments to the agents). Whilst thisassumption is common in the strictly proper scoring rule literature, it is restrictive since in practice the centre may notalways be able to observe the outcome. This may happen when reputation models are unable to monitor the constantchanges in dynamic systems, such as markets, and hence the quality of a provided service cannot be verified, or whenthe agents’ estimates relate to physical measurement from sensors deployed in hostile environment (such as floods [43],glaciers [15] or volcanoes [39]), where it is impossible to ascertain the ‘ground truth’ through external means. Mechanismsthat operate under this regime are termed self-verifying by Goel et al. [9],3 and thus, we provide a third mechanism in whichthe centre uses the pre-selected agents’ fused reported estimates, instead of the outcome, when calculating the payments.Now, Miller et al. [29] address this issue by evaluating an agent directly against each one of the other agents in turn, andhence, calculate the average payment due to each agent. However, we show that under their mechanism the payment thatany agent receives is highly dependent on the accuracy of the other agents’ reports. This results in an increase in both thevariance in the payments received by each agent, and the variance in the total payment made by the centre. Thus, boththe agents and the centre are more uncertain about the payments that they expect to receive and make. In contrast, ourapproach, which uses the fused estimates of all other agents, results in much lower variance in these payments.In summing up, in this paper we contribute to the state of the art in the following ways:• We introduce the first mechanism that elicits both effort and honest reporting of a single agent’s estimate, in a settingwhere the centre has no information about the agents’ costs involved in the generation of that estimate. We empiricallyevaluate our mechanism by comparing the standard quadratic, spherical and logarithmic scoring rules with a parametricfamily of scoring rules, and show that for certain values of the parameter, the resulting payment is similar to the loga-rithmic (optimal scoring rule) but also has finite lower bounds (as opposed to the logarithmic rule, which is potentiallyunbounded).• In extending our initial mechanism, we present the first class of mechanisms that elicit estimates from multiple agentsin a setting where the centre may have to combine several estimates of low precision due to agents’ restrictions in thequality of the estimates they provide. We empirically compare several approaches to perform the pre-selection, hencethe class of mechanisms, and identify one that minimises the centre’s expected total payment.• In extending the above mechanism we introduce a novel mechanism, in which the centre does not rely on knowledgeof the realised outcome when calculating payments to the agents reporting their estimates. Furthermore, we modifystrictly proper scoring rules accordingly so they can motivate agents to truthfully report their estimates, under theknowledge that they will be evaluated based on the other agents’ reports.• We compare the two extensions with the peer prediction mechanism [29] and identify the differences between fusionand peer prediction. We show that the agents derive the same payment in all three mechanisms, hence the centrederives no additional penalty as a result of the lack of knowledge. However, we also note that the fusion mechanism3 Note that Goel et al. [9] present a self-verifying mechanism which incentivises agents to truthfully reveal their subjective expectations regarding aphysical parameter by scoring each individual agent’s report against those of the other agents. Our approach is similar in that we score each agent againstthe fused reports of the other agents. However, Goel et al.’s mechanism operates in a very different setting in which the agents do not have to strategiesover the precision of the measurement that they make, there is a common prior known to all agents, and there is no notion of a required minimumprecision or a cost. Rather, the goal is to find the budget-balanced payments to be exchanged between the agents in order to ensure that they all truthfulreport.A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672651results in payments of significantly smaller variance than the peer prediction, therefore it has more reliable and robustpayments.• We show that all three mechanisms are incentive compatible, in both costs and estimates revealed, and individuallyrational.The rest of this paper is organised as follows: In Section 2 we present our problem formalisation, and in Section 3we provide some necessary background on scoring rules. Based on this, in Section 4, we describe and analyse the singleagent two-stage mechanism with unknown costs. In Section 5 we extend our mechanism so multiple agents can provideestimates of limited precisions, while in Section 6 we further extend our mechanism so the centre does not have to rely onknowledge of the actual outcome when calculating payments. Finally, we discuss related work in Section 7 and we concludeand discuss future work in Section 8.2. The information elicitation problemWe now describe in detail the information elicitation problem outlined in the introduction. We consider the case ofa centre that wants to acquire a probabilistic forecast or estimate of some event characterised by a continuously valuedparameter (e.g. a forecast of tomorrow’s temperature, or a prediction of the latency of some online computational service),the unknown true value of which is denoted by x0. The centre requires this estimate to have a minimum precision, denotedby θ0. It derives no utility from an estimate whose precision is less than θ0, and derives no additional benefit if the estimateis of precision greater than θ0. We assume that the centre is capable of paying an unbounded amount for this estimate, butit would clearly prefer to acquire an estimate of at least the minimum precision, at the minimum cost possible.There are N (cid:2) 2 rational, risk neutral agents, that can potentially provide the centre with this estimate. Each of theseagents is capable of committing a variable amount of some costly resource in order to generate an independent noisy es-timate of the parameter in question. As is common within the data fusion literature (see for example Gregory [10] andDeGroot and Schervish [8]), we model the estimates of the agents as Gaussian distributions with mean, xi and precision θi ,and we assume that these estimates are unbiased such that xi is a random sample from the Gaussian distribution repre-sented by N (x0, 1/θi). Note that this assumption does not actually constrain the results such that they are only valid forGaussian distributions. If we only know the mean and variance of a distribution, and nothing more, then the least constrain-ing assumption to work with is that it is a Gaussian distribution (i.e. within the Bayesian framework, for any specific valueof mean and variance, the Gaussian distribution is the distribution that exhibits the greatest Shannon entropy). It wouldbe possible to extend the model to other general distributions (for example, using a beta distribution if the parameter isconstrained to lie between 0 and 1, or a gamma distribution if it were just constrained to be positive). However, in general,working with Gaussian distributions is both widely applicable and also analytically tractable (since both the fusion andsummation of two Gaussian distributions results in another Gaussian distribution).We assume that the greater the resources committed by the agent, the greater the precision, θi , of the estimate that itgenerates and the greater the cost that it incurs. These costs are private to the agent and are described by the function(cid:3)(cid:3)i (θ) (cid:2) 0), and note that this is a realisticci(θi). We assume that this cost function is double differentiable and convex (i.e. cassumption in all cases where there are diminishing returns as more resources are committed. Finally, we do not assumethat all agents use the same cost function, but we do demand that the costs of different agents and their derivatives do notcross (i.e. the ordering of the agents’ costs and their derivatives is the same over all precisions) in order to prove incentivecompatibility and individual rationality of the mechanisms that we derive.4 In the examples that we provide in this paperwe shall assume that cost functions are in fact linear, such that ci(θi) = ciθi , and we note that this corresponds to thecontinuous limit of the case where an agent make n independent estimates with fixed precision, (cid:4)θi and cost (cid:4)ci , andforms its final estimate by fusing these together such that θi = n(cid:4)θi and ci(θi) = ( (cid:4)ci(cid:4)θi)θi .Given this setting, our challenge is then to design a mechanism that enables the centre to identify the agent that canprovide the required estimate at the lowest cost, and to provide a payment to this agent such that it is incentivised togenerate an estimate with a precision at least equal to that required and to report it truthfully. This payment is conditionedon the true value of the parameter, x0, which is revealed to both the centre and the agents at some time after the estimateis required.We then extend this initial setting to consider the case that the precision of the estimates that any agent can generate isconstrained such that θi (cid:3) θ ci . As before, the maximum precision that any agent can generate, θ ci , is the private informationof the individual agent. Finally, we also relax the constraint that the value of x0 is revealed to the centre and agents beforethe payments must be made. Thus, the centre can now only condition the payment to any agent on the estimates that werereceived from the other agents (and not from the true parameter value).4 In Corollary 1 and Lemma 1, we prove that these assumptions regarding the cost functions and their derivatives are necessary.652A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672Table 1Comparison of quadratic, spherical, logarithmic and parametric scoring rules.Scoring rule:QuadraticS(x0;(cid:2)x,(cid:2)θ)S(θ)(cid:3)(θ)αβSScoring rule:S(x0;(cid:2)x,(cid:2)θ)S(θ)(cid:3)(θ)SαβWhere N (x0;(cid:2)x,(cid:2)θ) =(cid:3)2N (x0;(cid:2)x, 1/(cid:2)θ ) − 1(cid:3)212θπ√1√π θ4(cid:3)(θ0)π θ04cc(θ0) − 2θ0c(cid:3)(θ0)(cid:3)(cid:2)θπSpherical(cid:5) 1(cid:4)4 N (x0;(cid:2)x, 1/(cid:2)θ )(cid:5) 14(cid:4)4π(cid:2)θθ4π(cid:4)(cid:5) 141414π θ 3(cid:3)(θ0)(4π θ 30 )4c(cid:3)(θ0)c(θ0) − 4θ0c14LogarithmicParametriclog N (x0;(cid:2)x, 1/(cid:2)θ )(cid:5)θ2π− 12(cid:4)12 log12θ(cid:3)(θ0)θ02cc(θ0) − 2c(cid:3)(θ0)θ0(cid:4)(cid:4)12 logθ02π(cid:5)− 12(cid:5)(cid:2)θ2π exp((cid:2)θ ((cid:2)x−x0)22).(cid:5) 1−k2(cid:4)2π(cid:2)θk(cid:4)2πθ(cid:4)(cid:5) 1−k2(cid:5) 1−k2kN (x0;(cid:2)x, θ)(k−1) − k−1√1√kk−12π√θ2θk√(cid:3)(θ0)θ0k2ck−1c(θ0) − 2θ0θ02π(cid:3)(θ0)k−1 c(cid:5) 1−k2(cid:4)3. Strictly proper scoring rulesGiven the problem setting described above, we now describe the use of strictly proper scoring rules to incentivise theagents to make and truthfully report their estimates to the centre in the conventional case where the costs of the agentsare assumed to be known.3.1. BackgroundAs seen in the introduction, scoring rules incentivise a risk neutral forecaster to truthfully report its forecast by max-imising its expected reward. As such, this approach has been widely used as a statistical tool for eliciting personal beliefsand expectations regarding a future event [4,16,36]. In particular, if an agent actually has an estimate represented by theprobability density function Q (x), but reports an estimate to the centre denoted by R(x) and then receives a payment con-ditioned on this reported estimate and the true value revealed sometime later, S(x0|R(x)), then the agent’s expected scorewill be denoted as follows:∞(cid:6)S(R, Q ) =Q (x)S−∞(cid:4)(cid:5)x|R(x)dx(6)A scoring rule is defined as strictly proper if the agent’s expected score is maximised when it reports the truth i.e. R = Q ⇔S(Q , Q ) > S(R, Q ). In this case the agent has an incentive to report the truth in order to maximise its expected utility.Against this background, much of the literature on strictly proper scoring rules concerns three specific rules (quadratic,spherical and logarithmic) and a parametric family of rules known as the power rule family or k-power scoring rules [37].These four strictly proper scoring rules are defined in the following way:1. Quadratic:(cid:4)(cid:5)x0, R(x)S∞(cid:6)= 2R(x0) −R(x)2 dx2. Spherical:3. Logarithmic:4. Parametric:(cid:4)(cid:5)x0, R(x)S(cid:4)(cid:4)(cid:5)x0, R(x)(cid:5)x0, R(x)SS−∞(cid:7)(cid:8)(cid:9)(cid:9)(cid:9)(cid:10)∞(cid:6)R(x)2 dx= R(x0)−∞= log R(x0)∞(cid:6)= kR(x0)(k−1) − (k − 1)R(x)k dx−∞where k ∈ (1, 3), and when k = 2 the parametric rule takes the form of the quadratic rule.A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672653Given that in our setting we are considering estimates in the form of Gaussian distributions, we can re-derive thesescoring rules for this specific case.5 Table 1 shows each of the four strictly proper scoring rules, S(x0;(cid:2)x,(cid:2)θ), in the case thatthe agent reports its estimate as a Gaussian distribution with mean (cid:2)x and precision (cid:2)θ . By integrating over this expression,we can also derive the score that the agent expects to derive, S(θ), given that it has generated and truthfully reported (asit is incentivised to do) an estimate of precision θ .3.2. Eliciting effort when costs are knownNow, although eliciting truthful reports (incentive compatibility) is one very desirable property of the strictly properscoring rules, it is certainly not the only one. In our setting, agents may decide to commit less than the required resourcesinto the generation of the probabilistic estimate if they expect to increase their utility functions by doing so. To combat this,Miller et al. [29] elicit effort through the use of appropriate scaling parameters, noting that any affine transformation of astrictly proper scoring rule does not affect its incentive compatibility property. Given knowledge of an agent’s costs, theyshow that it is possible to induce an agent to make and truthfully report an estimate with a specified precision, θ0. In thiscase, the payment that an agent expects to receive, P (θ), is given by:P (θ) = α S(θ) + βwhere α and β are the scaling parameters, and the expected utility of the agent is given by:U (θ) = α S(θ) + β − c(θ)(7)(8)The centre can now choose the value of α such that the agent’s utility (its payment minus its costs) is maximised when itproduces and truthfully reports an estimate of the required precision, θ0. To do so, it solves dUdθ= 0 to give:|θ0α = c(cid:3)(θ0)S(cid:3)(θ0)(9)In Table 1 we present this result, and the derivative of the expected score, Sthe four strictly proper scoring rules presented earlier.(cid:3)(θ), that is required to calculate it, for each ofHaving defined the α parameter of the affine transformation that elicits effort and honest reporting, we calculate param-eter β which motivates agents to participate in the mechanism by ensuring that their expected utility is always positive. Inmore detail, we now note that in order for a self-interested agent to incur the cost of producing a forecast, it must expect toderive positive utility from doing so. Thus, the centre can use the constant β to ensure that it makes the minimum paymentto the agent, hence ensuring that the mechanism is individually rational. When costs are known, the centre can do so bymaking the agents indifferent between producing the forecast or not, by setting U (θ0) = 0, thus giving:β = c(θ0) − c(cid:3)(θ0)S(cid:3)(θ0)S(θ0)(10)Again, cells β in Table 1 show this result for each of the four scoring rules.Finally, it should be noted that the expected score of the quadratic, spherical and logarithmic scoring rules, as a functionof the precision θ (expressed as S(θ) in Table 1) is strictly concave, strictly increasing and twice differentiable. While we willshow that this property of the expected scores is important to guarantee certain economic properties of the mechanism, itdoes not hold for all strictly proper scoring rules. For example, in the parametric scoring rule for k > 3 the second derivativeof the expected score (denoted by Eq. (11)) becomes positive and therefore the expected score convex, which in turn, aswe will show in the following section, results in a payment that fails to incentivise an agent to produce an estimate at therequired precision, θ0.(cid:3)(cid:3)S(θ) = (1 − k)(3 − k)4θ 2√k(cid:12) 1−k2(cid:11)2πθ(11)Therefore, and in order to guarantee the concavity of the expected score we will restrict the parameter k to the space (1, 3).4. A mechanism for dealing with unknown costsWe now consider the setting where the costs involved in the generation of a probabilistic estimate are unknown to thecentre, and the centre wants to select a single agent to procure the estimate of the required precision at the lowest cost.As described in Section 2, we assume that there are multiple agents, all of which are capable of producing an estimate ofat least the required precision (we shall relax this assumption in Section 5 where we consider agents that have a limitationon the maximum precision of the estimate they produce).5 Note that although we provide analytical results for the specific case of Gaussian distributions, equivalent results could be derived for any continuousdistribution used.654A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–6724.1. The mechanismWe address the above mentioned challenges by designing a two-stage mechanism (Mechanism 1). In the first stage,the centre elicits the agents’ true costs and identifies the agent that can provide an estimate of the specified precision atthe lowest cost. Then, in the second stage, the centre uses an appropriately scaled strictly proper scoring rule in order toincentivise this agent to generate the estimate with the required precision, and to truthfully report it. At first glance it mightseem that this mechanism is akin to a reverse second-price or Vickrey auction [38], where the agents’ rewards are equalto the second-lowest reported costs. This is indeed the case, however here the selected agent’s reward in the second stageis determined by scaling the scoring rule using the second lowest cost identified in the first stage (rather than using theselected agent’s reported costs).Mechanism 1 The mechanism for dealing with unknown costs:1. First Stage1.1 The centre announces that it needs an estimate of required precision θ0, and asks all agents i ∈ {1, . . . , N}, where N (cid:2) 2, to report their costfunctions (cid:2)ci (θ).61.2 The centre assigns the estimate to the agent who reported the lowest cost at the required precision,mink∈{1,...,N}(cid:2)ck(θ0).i.e., agent i such that (cid:2)ci (θ0) =2. Second Stage2.1 The centre announces a scoring rule α S(x0;(cid:2)x,(cid:2)θ ) + β, where:(i) S(x0;(cid:2)x,(cid:2)θ ) is a strictly proper scoring rule,(ii) S(θ) is strictly concave as a function of precision θ ,7 and(iii) α and β are determined using Eqs. (9) and (10) respectively, but now based on the second-lowest reported cost functions (i.e. (cid:2)c j (θ) such that(cid:2)c j(θ0) = mink(cid:8)=i(cid:2)ck(θ0)).2.2 The agent selected in the first stage produces an estimate with mean x and precision θ , and reports (cid:2)x and (cid:2)θ to the centre.2.3 Once the actual outcome has been observed, the centre then gives the following payment to the agent:P (x0;(cid:2)x,(cid:2)θ ) = α S(x0;(cid:2)x,(cid:2)θ) + β(12)4.2. Economic properties of the mechanismHaving detailed the mechanism, in the next section we identify and prove its economic properties. Specifically, in thissection we show that:1. The mechanism outlined above is incentive compatible in the first stage regarding the costs. In particularly, truthfulrevelation of the agents’ cost functions is a weakly dominant strategy.2. The mechanism is incentive compatible regarding the selected agent’s reported measurement and precision in the sec-ond stage.3. There can be no incentive compatible mechanism regarding the agents’ cost functions revealed when the cost functionsoverlap.4. The mechanism is individually rational.5. The centre motivates the selected agent to make an estimate with a precision which is at least as high as θ0, the preci-sion required by the centre. We refer to the actual precision produced as the ‘optimal precision’ (from the perspectiveof the agent) θ ∗, since for this precision the expected payment is maximised.In this section, with prove the economic properties of the mechanism. Initially, we derive two lemmas which are thenused in the proofs of the theorems that follow. The first of these lemmas shows that if the true costs of the agent performingthe estimate are greater than the costs which are used to scale the scoring rule, then the agent’s utility will always benegative, regardless of the precision.Lemma 1. If ct(θ) and cs(θ) are convex functions with ct(θ) > cs(θ), ctrue cost function, cs(θ) is the cost function used to scale the scoring function and cU (θ) < 0 for any θ .(cid:3)t(θ) > c(cid:3)s(θ) and ct(0) = cs(0) = 0, where ct(θ) is the agent’s(cid:3)s(θ) their respective derivatives, then(cid:3)t(θ) and cProof. Concavity of the expected score S(θ) implies:(cid:3)S(θ0)(θ − θ0) (cid:2) S(θ) − S(θ0)(13)6 We note that in practice the centre only requires (cid:2)ci (θ0) and cagents to reveal their entire cost function.(cid:3)i (θ0), and not the entire functions. However, for notational convenience we request the7 We note that the quadratic, spherical, logarithmic and parametric scoring rules satisfy both of these properties (see row 2 of Table 1).A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672Similarly, convexity of the cost function cs(θ) gives:(cid:3)s(θ0)(θ − θ0) (cid:3) cs(θ) − cs(θ0)c655(14)Given that by definition S(θ) and cs(θ) are strictly increasing (as stated in the model description in Section 2), dividing with(cid:3)(θ0) and cS(cid:3)s(θ0) maintains the sign in inequalities (13) and (14). Therefore, from:(θ − θ0) (cid:2) S(θ) − S(θ0)S(cid:3)(θ0)and(θ − θ0) (cid:3) cs(θ) − cs(θ0)(cid:3)s(θ0)cit follows that:S(θ) − S(θ0)S(cid:3)(θ0)(cid:3) cs(θ) − cs(θ0)(cid:3)s(θ0)cor(cid:3)s(θ0)cS(cid:3)(θ0)(cid:4)(cid:5)S(θ) − S(θ0)+ cs(θ0) − cs(θ) (cid:3) 0(15)Now, the expected utility, is given by U (θ) = α S(θ) + β − c(θ) (Eq. (8)), with the scaling parameters α and β already definedusing Eqs. (9) and (10) as α = cS(θ0). Therefore, an agent’s expected utility is given by:and β = c(θ0) − c(cid:3)(θ0)S(cid:3)(θ0)(cid:5)S(θ) − S(θ0)(cid:3)(θ0)S(cid:3)(θ0)(cid:5)(cid:4)cs(θ0) − ct(θ)+U (θ) = c(cid:3)s(θ0)S(cid:3)(θ0)(cid:4)(16)Therefore, since ct(θ) > cs(θ), for any θ the following holds:(cid:3)s(θ0)cS(cid:3)(θ0)(cid:3)s(θ0)cS(cid:3)(θ0)(cid:4)(cid:5)S(θ) − S(θ0)(cid:4)(cid:5)S(θ) − S(θ0)+ cs(θ0) − cs(θ) (cid:3) 0 ⇒+ cs(θ0) − ct(θ) < 0 ⇒orU (θ) = c(cid:3)s(θ0)S(cid:3)(θ0)(cid:4)(cid:5)S(θ) − S(θ0)+ cs(θ0) − ct(θ) < 0(cid:2)The next lemma shows that if the true costs of the agent performing the estimate are less than the costs used to scalethe scoring rule, then the optimal precision θ ∗will be greater than θ0.Lemma 2. If ct(θ) and cs(θ) are convex functions with ct(θ) < cs(θ), ctrue cost function, cs(θ) is the cost function used to scale the scoring function and cθ ∗ > θ0.(cid:3)t(θ) < c(cid:3)s(θ) and ct(0) = cs(0) = 0, where ct(θ) is the agent’s(cid:3)s(θ) their respective derivatives, then(cid:3)t(θ) and cProof. The agent’s optimal precision, θ ∗with U(cid:3)(θ ∗) = 0. Now, the agent’s expected utility is already defined by Eq. (16) as:, which maximises its expected utility is formally denoted by θ ∗ = argmaxθ U (θ),(cid:4)U (θ) = c(cid:5)S(θ) − S(θ0)(cid:3)s(θ0)S(cid:3)(θ0)Given that the optimal precision, θ ∗θ ∗(cid:5)(cid:4)cs(θ0) − ct(θ)+, maximises the expected score, we have U(cid:3)(θ ∗) = 0, and hence, after replacing θ withand calculating the derivative of the expected utility (Eq. (16)):(cid:3)∗∗(cid:3)tS(cid:5)(cid:4)(cid:4)(cid:5)θθ− c= 0 ⇔ S(cid:3)s(θ0)cS(cid:3)(θ0)Let f (θ) = Stiable, then fthe same ordering, without overlapping for all θ , then since c(cid:3)(θ ∗)S(cid:3)(θ0)(cid:3)(θ)/S(cid:3)s(θ0). Now, since S(θ) is (strictly) concave, strictly increasing and twice differen-(cid:3)(θ) (cid:3) 0 for all θ0. Furthermore, since we also assume that the cost functions, and their derivatives, maintain(cid:3)s(θ) (cid:2) 0 (since(cid:3)(cid:3)t (θ) (cid:2) 0 (due to the convexity of the cost) and ct(θ ∗)= c(cid:3)s(θ0)c(cid:3)(θ0) and g(θ) = c(cid:3)t(θ)/c(17)(cid:3)656A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672cost functions are strictly increasing), then gg(θ) is strictly increasing and f (θ0) = 1, then f (θ) and g(θ) must cross (i.e. f (θ ∗) = g(θ ∗)) at θ ∗ > θ0. (cid:2)(cid:3)(θ) (cid:2) 0 for all θ , and since c(cid:3)t(θ) < c(cid:3)s(θ) for all θ , then g(θ0) < 1. Finally, sinceBased on these two key lemmas, we now proceed to prove the four economic properties of our mechanism.Theorem 1. Truthful revelation of the agents’ cost functions in the first stage of the mechanism is a weakly dominant strategy.Proof. We prove this by contradiction. Let ct(θ) and (cid:2)c(θ) denote an agent’s true and reported cost functions respectively.Furthermore, let cs(θ) denote the cost function used to scale the scoring function if the agent wins (i.e. if (cid:2)c(θ0) < cs(θ0)).First, suppose that the agent misreports, but this does not affect whether it wins or not. In this case, since the costs arebased on the second-lowest costs, this does not affect the scoring rule if the agent wins. Moreover, if the agent loses, thepayoff is always zero. Therefore, there is no incentive to misreport.Second, suppose that the agent’s misreporting affects whether that agent is pre-selected or not. There are now two cases:1. The agent wins by misreporting, but would have lost when truthful.2. The agent loses by misreporting, but would have won when truthful.In this context:• Case (1) can be formally denoted as ct(θ0) > cs(θ0) and (cid:2)c(θ0) < cs(θ0). Now, since the true cost ct(θ0) > cs(θ0), it followsdirectly from Lemma 1 that the expected utility U (θ) is strictly negative, irrespective of θ . Therefore, the agent coulddo strictly better by reporting truthfully in which case the expected utility is zero.• Case (2) can be formally denoted as ct(θ0) < cs(θ0) and (cid:2)c(θ0) > cs(θ0). In this case the agent would have won by beingtruthful, but now receives a utility of zero. To show that this type of misreporting is suboptimal, we need to show that,when ct(θ0) < cs(θ0), an agent benefits from being selected and generating the (optimal) estimate (i.e. U (θ ∗) > 0 whenct(θ0) < cs(θ0)). Now, since θ ∗is optimal by definition, then U (θ ∗) (cid:2) U (θ0). From the expected utility in Eq. (16), wehave U (θ0) = cs(θ0) − ct(θ0) > 0 when ct(θ0) < cs(θ0), and hence U (θ ∗) > 0 at true costs reporting. (cid:2)Corollary 1. Incentive compatibility with respect to agents’ reported costs and precisions does not hold if the agents’ cost functionscross at θ (cid:3).Proof. The proof regarding the agents’ reported costs comes directly from the above theorem, as we need to show only oneexample where an agent is incentivised to misreport its cost function. Following the same notation as above, let ct(θ) and(cid:2)c(θ) denote an agent’s true and reported cost functions respectively, while cs(θ) denotes the cost function used to scalethe scoring function and θ (cid:3)is the point where two cost functions (suppose cs(θ) and ct(θ)) intersect. In this context, weintend to show that an agent can do better by misreporting and losing, rather than by reporting truthfully and winning.In more detail, since cs(θ) and ct(θ) overlap at θ (cid:3). Therefore, according to Lemma 1, theexpected utility will be strictly negative. If the agent misreports its cost function so it is not selected, its utility will be zero.Therefore, the mechanism is no longer incentive compatible with respect to reported cost functions., cs(θ) < ct(θ), for every θ > θ (cid:3)Now, regarding the agent’s reported precision, if at θ (cid:3)0. Given that this agent is the cheapest one, at least for θ (cid:3) θ (cid:3)even if it makes an estimate with precision greater than θ (cid:3)Therefore, the mechanism is no longer incentive compatible with respect to reported precision. (cid:2)ct(θ) and cs(θ) intersect then ct(θ (cid:3)) > cs(θ (cid:3)) and therefore U (θ (cid:3)) <it is in its best interest to report a precision lower that θ (cid:3), while θ > θ (cid:3)., in order to maintain positive utility. That is, (cid:2)θ < θ (cid:3)Theorem 2. The mechanism is incentive compatible regarding the agent’s reported forecast and precision in the second stage.Proof. The proof for this theorem follows directly from the definition of the strictly proper scoring rules (see Section 3). (cid:2)Theorem 3. The two-stage mechanism is individually rational.Proof. Having shown in Theorem 1 that the true reporting of cost functions in the first stage is a weakly dominant strategy,we only have to examine whether the selected agent is incentivised to participate into the second stage of the mechanismand report its estimate and its precision to the centre. Since agents that do not win in the first stage receive zero utility,we only consider the case of the selected agent. For that agent, its true cost function is less than or equal to the costfunction used for the scaling of the expected score (i.e. ct(θ) (cid:3) cs(θ)). Given that the selected agent’s expected utility, U (θ),(S(θ) − S(θ0)) + cs(θ0) − ct(θ) (Eq. (16)), it follows that U (θ0) = cs(θ0) − ct(θ0) (cid:2) 0. In Lemma 2, we have shownis:that the agent will produce an estimate θ ∗ > θ0. By definition, U (θ ∗) (cid:2) U (θ0), and thus, U (θ ∗) (cid:2) 0. (cid:2)(cid:3)s(θ0)cS(cid:3)(θ0)Theorem 4. For the agent selected in the first stage of the mechanism, it is optimal to produce an estimate with a precision equal to orhigher than the precision required by the centre, i.e., θ ∗ (cid:2) θ0.A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672657Fig. 1. Selected agent’s expected payment and optimal precision.Proof. This proof follows directly from Lemma 2 where we show that there is an optimal precision, θ ∗if ct(θ) and cs(θ) are convex functions with ct(θ) < cs(θ), cincentive compatible in costs, then all these conditions hold, and thus, θ ∗ (cid:2) θ0. (cid:2), such that θ ∗ (cid:2) θ0(cid:3)s(θ) and ct(0) = cs(0) = 0. Given that the mechanism is(cid:3)t(θ) < cNote that these proofs indicate that the two stages of the mechanism are inextricably linked and cannot be considered inisolation of one another. Indeed, apparently small changes to the second stage of the mechanism can destroy the incentivecompatibility property of the first stage. For example, it is important to note that our mechanism is more precisely knownas interim individually rational [24], since the utility is positive in expectation. In any specific instance, the payment couldactually be negative if the prediction turns out to be far from the actual outcome. An alternative choice for the secondstage of the mechanism would be to set β such that the payments are always positive, thus making the mechanism ex-post individually rational. However, this would then violate the incentive-compatibility property since the agents could thenreceive positive pay-offs by misreporting their cost functions. Likewise, it might be tempting to imagine that the centrecould use the revealed costs of the agents in order to request a lower precision, confident in the knowledge that theselected agent will actually produce an estimate of the required precision. However, by effectively using the lowest revealedcost within the payment rule in this way, the incentive-compatibility property of the mechanism would again be destroyed.4.3. Numerical simulationsHaving proven the economic properties of the mechanism in the general case with any convex cost function, we nowconsider a specific scenario in which costs are linear functions, given by ci(θ) = ciθ , where the value of ci is drawn from auniform distribution ci ∼ U (1, 2) and θ0 = 1. Note that while we can derive analytical expressions for the expected paymentthat the centre will make in any specific instance of this case (i.e. when the lowest and second-lowest cost functions areknown), we cannot do so in the general case where these cost functions are drawn from some distribution since this requiresthat we integrate over the joint probability distribution of the first and second agent’s costs, and the mean and varianceof the estimate that the agent with the lowest cost actually generates. Performing this integration numerically is alsoproblematic as expressing this joint probability distributions becomes increasingly complex as the mechanisms describedin this paper become more complex. Thus, instead we effectively draw independent samples from this joint probabilitydistribution by actually simulating the processes of the mechanism (i.e. the revelation of the agents’ costs, the selection ofthe agent with the lowest cost in the first stage of the mechanism, the choice of precision that this agent makes given thescoring rule presented to it, its generation of an estimate, and finally the score that it receives after the true unknown valueis revealed). To this end, for a range from 2 to 20 agents participating in the first stage, we simulate the mechanism 106times and, for each iteration, record the payment made to the agent that provided the forecast and the precision of thisforecast. Due to the number of iterations that we perform, the standard error in the mean values plotted are much smallerthan the symbol size shown in the plot, and thus for clarity, we omit them.The payment the agent expects to derive, P , and its actual precision, θ ∗, for every value of N ∈ [2, 20] are shown inFig. 1. As expected, as the number of agents increases, the mean payment, shown in Fig. 1(a), decreases toward the lowerlimit of the uniform distribution from which the costs were drawn. Furthermore, note that there is a fixed ordering overthe entire range, with the payment resulting from the quadratic scoring rule being the highest, and that of the logarithmicscoring rule being the lowest. The reason for this can be seen in Fig. 1(b) where the precision of the forecasts that wereactually made are shown. Note that the logarithmic scoring rule induces agents to produce forecasts closer to the requiredprecision than both the spherical and the quadratic scoring rules.658A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672Table 2Analytical calculation of the expected payment, optimal precision and lower bound on the payment for quadratic, spherical, logarithmic and parametricscoring rules with linear cost functions for an instance of the mechanism.SR:P (θ0)θ ∗−P(cid:14)− 1Quadratic(cid:13)2 c2c2θ0c1(cid:5)(cid:4)2θ0c2c1(cid:13)1 + 2 c2−c2θ0c1(cid:14)(cid:14)(cid:5) 13 − 3Spherical(cid:13)(cid:4)4(cid:5) 4c2c2θ0c1(cid:4)c23 θ0c1−3c2θ0Logarithmic(cid:13)(cid:4)1 + logc2θ0(cid:5)(cid:4)c2c1−∞θ0(cid:5)(cid:14)c2c1Parametric(cid:13)(cid:4)c22c1(cid:5) 23−k θ0(cid:13)1 − 2k−1c2θ0k−1(cid:4)c2c1c2θ0(cid:5) k−1(cid:14)2 + k − 3(cid:14)k−13−k− 2( c2c1)Costs are given by linear functions, c(θ) = cθ , and c1 and c2 are the lowest and second lowest costs.Fig. 1(a) also shows the mean of the lowest and second lowest costs evaluated at the required precision θ0 (denoted byc1θ0 and c2θ0 respectively). The first cost represents the minimum payment that could have been made if the costs of theagents were known to the centre. The second represents the payment that would have been made, had the agent produceda forecast of the required precision θ0 rather than its own optimal precision θ ∗. The gap between c1θ0 and c2θ0 is theextra amount that must be paid as a result of the costs being unknown and is the same regardless the scoring rule used.On the other hand, the gap between c2θ0 and the mean payment of any particular scoring rule, depends on the choice ofthe scoring rule as it represents the loss that the centre has to cover, as a result of the agent producing an estimate at itsoptimal precision, θ ∗(rather than one at the minimum precision required, θ0). The goal in selecting scoring rules is clearlyto minimise this gap, and it can be seen that the logarithmic scoring rule is closest to achieving this goal.We also derive the analytical expressions of the expected payment, P , and the optimal precision, θ ∗, as a function of therequired precision, θ0, for a single run of the mechanism in this specific setting where cost functions are represented bylinear functions, and the costs of the cheapest and second cheapest agents (denoted by c1 and c2) are known. These resultsare represented in the first two rows of Table 2, and show that the pattern observed in the empirical evaluation (where weeffectively average over the distribution of the first and second lowest costs) is shown in the individual analytical results.That is, when the payment is based on the logarithmic scoring rule, the agent’s expected payment is less than the othertwo scoring rules, and the precision that the agent actually reports is closest to that requested.Furthermore, in Fig. 2 we also apply the parametric scoring rule to the case where N = 10, and compare it to the threefixed scoring rules. Note that in the case of the parametric scoring rule, as k → 1, the expected payment of the centre,and its variance, is asymptotically equal to that of the logarithmic scoring rule. Likewise, for k = 2, the parametric scoringrule is exactly the quadratic scoring rule (since it takes the same mathematical form). For k = 1.5, the expected paymentof the parametric scoring rule is equal to that of the spherical rule, but the variance in the payments is not. From theseplots, it would appear that the logarithmic scoring rule would be the optimum choice for the centre since it will minimisethe amount that must be paid to the agents. It also displays the minimum variance in this payment which is an importantcriteria since it reflects the uncertainty in the payment that the agent is expecting to receive. However, further analysisin the next section indicates that the parametric scoring rule has a significant advantage over the logarithmic; that is, theexistence of a finite lower bound on the payment.4.4. Analysis of payment lower boundIn more detail, row 3 of Table 2 shows the analytically calculated lower bound of the scaled payment, P, based onthe principle that the lower bound is derived from the scoring rule S(x0;(cid:2)x,(cid:2)θ), when the value of the probability densityfunction describing the actual outcome is 0 (i.e. N (x0;(cid:2)x, 1/(cid:2)θ) = 0). Note that the logarithmic scoring rule does not have afinite lower bound. Thus, if the agent’s estimate is far from the actual outcome, then a payment based on the logarithmicscoring rule will go to −∞, and the agent will actually be required to pay an unbounded penalty to the centre. Likewise, inthe limit as k → 1, the payment based on the scaled parametric scoring rule also has no finite lower bound.8 However, forvalues of k (cid:8)= 1, the parametric scoring rule is bounded, and the appropriate choice of the parameter, k, allows the overallperformance of the scoring rule (in terms of the expected total payment of the centre and the variance in this payment) tobe traded-off against the value of this bound.−In Fig. 3 we plot the lower bound of the payments based on the quadratic, spherical and parametric scoring rules (weomit the logarithmic scoring rule as it goes to −∞); noting that the lower bound occurs when c1 = 1 and c2 = 2 (the lowerand upper support of the cost function distribution). Note that for some values of k, the lower bound of the parametricscoring rule is greater than that of the quadratic rule, but it is always less than that of the spherical rule. Based on thisresult, we select k to be equal to 1.2 in our future experiments. This value results in an expected payment and variancethat is close to the logarithmic scoring rule, whilst not penalising the agent excessively in the worst case. The choice ofparameter value here is somewhat arbitrary, and in practice, it will depend on the details of the particular applicationdomain.8 In this case, this is due to the scaling parameters being unbounded. The score has a finite lower bound for all values of k.A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672659Fig. 2. The mean and variance of the centre’s payment.Fig. 3. Calculated lower bound of the payment, Pci ∼ U (1, 2) and θ0 = 1.4.5. Discussion−, for linear functions, given by ci (θ) = ci θ , where the value of ci is drawn from a uniform distributionIn this section we introduced a two-stage mechanism based on strictly proper scoring rules that motivates self-interestedrational agents to make a costly forecast of a specified precision and report it truthfully to a centre. The mechanism wasapplied in a setting in which a centre is faced with multiple agents but has no knowledge about the costs involved in thegeneration of the probabilistic estimates. We first proved that the mechanism was incentive compatible and individuallyrational. Then we empirically evaluated the mechanism by comparing the quadratic, spherical, logarithmic and parametricscoring rules, and showed that the logarithmic and the parametric (for k → 1) rules minimise the centre’s expected payment,the variance in this payment, and the selected agent’s optimal precision. However, given that payments derived from thelogarithmic scoring rule payment have no finite lower bound, the parametric scoring rule is a more appropriate choice fora centre that does not want to severely punish agents that inadvertently provide inaccurate observations. Hence, we will beusing it for the numerical evaluations of the mechanisms we develop in the remainder of this paper.5. A mechanism for dealing with multiple agents that have a limited degree of precisionIn the previous section we considered the case where any single agent is able to generate an estimate of the requiredprecision. Now, as already mentioned in Section 1, this may not always be the case in situations where agents have limitedresources with which to produce these estimates, and thus, the centre may have to procure estimates from multiple agentsand fuse them together in order to achieve a sufficiently high precision. To this end, we revise the mechanism in theprevious section by relaxing the assumption that any single agent is capable of producing the required estimate. In doingso, we propose a parametrised iterative mechanism (Mechanism 2), which is similar to the previous mechanism (i.e. twostages, first stage to elicit costs, second to calculate payments), but that uses a significantly different process to elicit thosecosts and calculate the payments. In more detail, in the first stage the centre pre-selects M from N agents through a seriesof selection steps which elicits their costs. In the second stage, it elicits the pre-selected agents’ probabilistic estimates,after sequentially approaching them in a random order. As with the previous mechanism, we formally prove that thisnovel mechanism is incentive compatible regarding the costs, maximum precisions and estimates, and that it is individuallyrational. Finally, we introduce a family of processes by which the centre may pre-select M from N agents and show both660A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672empirically and analytically that the centre will minimise its expected payments by forming a single group of agents in thefirst stage of the mechanism.5.1. Eliciting information from multiple sourcesAs described in Section 2, we consider the same model as in the previous section, however we additionally assume thatthere is a limit in the maximum precisions of the agents’ estimates, denoted by θ ci . Thus, agents can produce estimatesof any precision up to and including this maximum value (i.e. 0 (cid:3) θi (cid:3) θ ci ). Given this limit, the centre may not be ableto rely on a single agent to achieve its required precision, and may have to combine estimates from multiple agents, inorder to achieve the desired degree of accuracy, and thus, must fuse k conditionally independent and unbiased probabilisticestimates, {(cid:2)x1, . . . ,(cid:2)xk} of possibly different precisions {(cid:2)θ1, . . . ,(cid:2)θk}, into a single estimate with mean x and precision θ . To doso, the centre uses the standard result (see DeGroot and Schervish [8]) for fusing independent Gaussian distributions suchthat:xθ =k(cid:15)(cid:2)xi(cid:2)θii=1and θ =k(cid:15)i=1(cid:2)θi(18)By fusing the agents’ precisions, the centre manages to acquire an estimate of higher precision than the precision of anyof the individual agents. Indeed, it can be seen that θ (cid:2) θi for any agent i. Note that for this fusion to be appropriate,agents must be incentivised to truthfully report both the means and precisions of their estimates. Now, given this model,the challenge is to design a mechanism in which the centre will be able to initially identify those agents that can providetheir estimates at the lowest cost, then motivate these agents to truthfully report their maximum precisions and finallygenerate and truthfully report their estimates with precisions equal to their reported maximum precisions.5.2. The mechanismIn Mechanism 2 we extend the mechanism discussed in the previous section by relaxing the assumption that the centrecan select a single agent that can provide the estimate at the required precisions. The centre can now elicit estimates frommultiple agents which have limited precisions in the estimates they can provide. In order to address this issue, the centrein the first stage, iteratively pre-selects M of the N available agents based on their reported costs. There are a number ofways in which this may be done; most generally, by dividing all the available agents, N, into groups of n (cid:3) N agents andthen by sequentially asking the agents of each group to reveal their costs. The centre then selects the m cheapest agents,with m < n. We shall shortly show that one combination of n and m dominates all others.In the second stage, the centre then sequentially asks the M pre-selected agents to reveal their private maximum pre-cision, in a random order that is independent of their reported costs, until it achieves its required precision, θ0, at whichpoint it discards the remaining pre-selected agents. Then, those that are not discarded are provided with a payment rulethat incentivises them to generate estimates at their reported maximum precisions and to truthfully report these estimatesto the centre.We now proceed to prove that this mechanism leads the agents to truthfully reveal their costs in the first stage (so thatthose which can produce the estimate at the lowest cost can be identified), and that the M pre-selected agents are incen-tivised to truthfully report their maximum precisions to the centre and subsequently make and truthfully report estimatesof these precisions in the second stage. These properties are not obvious, and as in the single agent section, they dependrather subtly on the details of the mechanism. For example, we note that if after asking all M agents for their maximumprecisions, the centre does not achieve its required precision, the mechanism must proceed to the payment phase (step 5in second stage). That is, the centre must commit to paying all pre-selected agents for their estimates at their reportedmaximum precisions, even if it does not acquire its required precision. Failure to observe this policy would lead agents toover-report their maximum precision, in order that some payment was received, and thus, the mechanism would no longerbe incentive compatible in terms of maximum precisions.Furthermore, note that in step 2 of the first stage, the centre chooses the m agents with the lowest reported costs, anddiscards the remaining n − m agents. If these agents were not discarded, but were placed back into the pool of availableagents, then the mechanism would no longer be incentive compatible in terms of costs; agents would have an incentiveto over-report their costs, such that when they are eventually pre-selected, their payment rule will be calculated using ahigher cost. Finally, in step 2 of the second stage, the centre must randomly ask the pre-selected agents to report their max-imum precisions using an ordering which is independent of their reported costs. Failing to do so will undermine incentivecompatibility in terms of costs of the first stage of the mechanism, thereby illustrating how the two stages interact. Even inthe case where only one agent participates in the second stage, as a result of the available agents being two (N = 2) or thenumber of the pre-selected agents being set to one by the centre (M = 1), the incentive compatibility is maintained. In thiscase, the agent with the higher reported cost will not be asked for its precision in the second stage since, since the N − Magents are discarded in the first stage.A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672661Mechanism 2 The mechanism for dealing with multiple agents that can provide estimates of a limited precision:1. First Stage1.1 The centre selects n (cid:2) 2 agents from the available N and asks them to report their cost functions (cid:2)ci (θ) with i ∈ {1, . . . , n}.1.2 The centre selects the m (1 (cid:3) m < n), agents with the lowest costs, associates the (m + 1)th cost with these agents and discards the remainingn − m agents.1.3 The centre repeats the above two steps until it has asked all N agents to report their cost functions. Note that when N is not exactly divisibleby n and we have a single remainder, it is discarded. Otherwise in the final round the centre modifies n and m such that n = N mod n andm = min(m, n − 1).1.4 We denote the total number of the agents pre-selected in this stage as M and note that its value depends on N, n and m.2. Second Stage2.1 The centre sets its required precision θr equal to θ0.2.2 The centre randomly selects one of the pre-selected agents and asks it to report its maximum precision (cid:2)θ c2.3 The centre asks the agent j to produce an estimate of this precision and presents this agent with a scaled strictly proper scoring rule. Thescaling parameters α and β are determined using Eqs. (9) and (10). However, within these expressions (cid:2)θ cis used instead of θ0, and cs (the costassociated with this agent in the preceding stage – (m + 1)th cost in the group from which it was selected) is used instead of ct . Hence, thescaling parameters are given by:s((cid:2)θ cj )cS(cid:3)((cid:2)θ cj )j , with j ∈ {1, . . . , M}.s((cid:2)θ cj )cS(cid:3)((cid:2)θ cj )and β j = cs(cid:4)(cid:2)θ c(cid:4)(cid:2)θ cα j =(19)−(cid:5)(cid:5)S(cid:3)(cid:3)jjj2.4 The centre sets θr = θr − min(θr ,(cid:2)θ c2.5 The agents that were asked to do so, produce an estimate x j with precision θ j and report (cid:2)x j and (cid:2)θ j to the centre,9 which after observing thej ) and if θr > 0 it repeats step two of the second stage.actual outcome, x0, issues the following payments:P j(x0;(cid:2)x j,(cid:2)θ j) = α j S j(x0;(cid:2)x j,(cid:2)θ j) + β jwith α and β being already determined in step two of the second stage.5.3. Economic properties of the mechanism(20)Having detailed the mechanism, we now identify and provide its economic properties. Specifically, we show that:1. The mechanism is incentive compatible with respect to the pre-selected agents’ reported maximum precisions andreported estimates.2. The mechanism is incentive compatible with respect to the agents’ reported costs.3. The mechanism is individually rational.Theorem 5. The mechanism is incentive compatible with respect to the pre-selected agents’ reported maximum precisions and reportedestimates.Proof. Given the mechanism described above, when the agent reports its estimate, it must do so with the precision that itclaimed was its maximum. Thus, (cid:2)θ = (cid:2)θ c . Now, given the scaling of the scoring rules described in step 2 in the second stageof the mechanism, the expected utility of the agent, if it reports its maximum precision as (cid:2)θ c , and subsequently producesan estimate of precision θ , which it reports with precision (cid:2)θ c , is denoted by U (θ,(cid:2)θ c), and is given by:(cid:4)Uθ,(cid:2)θ c(cid:5)= cs((cid:2)θ c)(cid:3)S(cid:3)((cid:2)θ c)(cid:4)(cid:4)Sθ,(cid:2)θ c(cid:5)(cid:5)(cid:5)(cid:4)(cid:2)θ c− S(cid:5)(cid:4)(cid:2)θ c+ cs− ct(θ)(21)where S(θ,(cid:2)θ c) is the agent’s expected score for producing an estimate of precision θ and reporting its precision as (cid:2)θ c .Furthermore, S((cid:2)θ c) is the agent’s expected score for producing and truthfully reporting an estimate of precision (cid:2)θ c , ct(.)is the true cost function of the agent, and cs(.) is the cost function used to produce the scoring rule (i.e. the (m + 1)thlowest revealed cost in the group from which the agent was pre-selected). Taking the first derivative of this expression withrespect to (cid:2)θ c gives:dU (θ,(cid:2)θ c)d(cid:2)θ c= dd(cid:2)θ c(cid:11)(cid:12)s((cid:2)θ c)(cid:3)cS(cid:3)((cid:2)θ c)(cid:4)(cid:4)Sθ,(cid:2)θ c(cid:5)(cid:5)(cid:5)(cid:4)(cid:2)θ c− S+ cs((cid:2)θ c)(cid:3)S(cid:3)((cid:2)θ c)(cid:4)(cid:3)Sθ,(cid:2)θ c(cid:5)(22)Now, since S is a strictly proper scoring rule, then S(θ,(cid:2)θ c) = S((cid:2)θ c) and S(cid:3)(θ,(cid:2)θ c) = 0 when θ = (cid:2)θ c . Hence:9 Note that we could restrict agents to report their estimates with precision (cid:2)θ cagents are automatically incentivise to report (cid:2)θ j = (cid:2)θ cj anyway.j . However, as we shall show in Section 5.3, under this mechanism the662A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672dU (θ,(cid:2)θ c)d(cid:2)θ c(cid:16)(cid:16)(cid:16)(cid:16)(cid:2)θ c=θ= 0(23)and thus, the utility of the agent is maximised when it reveals as its maximum precision, the precision of the estimate thatit subsequently produces.10We now show that it will actually produce an estimate of precision equal to its reported maximum precision. To thisend, we note that when (cid:2)θ c = θ , the expected utility of the agent is given by:U (θ) = cs(θ) − ct(θ)(25)Since cs(.) and ct(.) do not cross or overlap, and c(cid:3)t(θ), then U (θ) is a strictly increasing function. Thus theagent will maximise its expected utility by producing an estimate at its maximum precision, and thus, θ = θ c , and hence,(cid:2)θ c = (cid:2)θ = θ c , as required. (cid:2)(cid:3)s(θ) > cTheorem 6. The mechanism is incentive compatible with respect to the agents’ reported costs.Proof. We prove this by contradiction and consider two cases depending on whether or not an agent is pre-selected inthe first stage of the mechanism as a result of its misreporting. Let ct(.) and (cid:2)c(.) denote an agents’ true and reported costfunctions respectively. Furthermore, let cs(.) denote the cost function used to scale the scoring rule if that agent is amongthe m agents with the lowest reported costs in its group of n agents in the first stage of the mechanism (i.e. cs(.) is the(m + 1)th cost of that group).First, suppose that the agent’s misreporting does not affect whether it is pre-selected or not. In this case, had the agentbeen pre-selected, its payment would have been based on the (m + 1)th cost of its group and therefore independent of itsown report. Conversely, had the agent not been pre-selected, it would have received zero utility, since the remaining n − magents, of a group of initially n agents, that are not pre-selected are discarded. Hence, there is no incentive to misreport.Second, suppose that the agent’s misreporting affects whether that agent is pre-selected or not. There are now twocases: (1) the agent is pre-selected by misreporting but would have not been if it was truthful (i.e. ct((cid:2)θ c) > cs((cid:2)θ c) and(cid:2)c((cid:2)θ c) < cs((cid:2)θ c)), and (2) the agent is not pre-selected by misreporting but would have been if truthful (i.e. ct((cid:2)θ c) < cs((cid:2)θ c)and (cid:2)c((cid:2)θ c) > cs((cid:2)θ c)).Case (1). Since the true cost ct((cid:2)θ c) > cs((cid:2)θ c), it follows directly from Theorem 5 that the expected utility U (θ) = cs(θ) −ct(θ) is strictly negative, irrespective of θ . Therefore, the agent could do strictly better by reporting truthfully in which casethe expected utility is zero.Case (2). In this case the agent would have been pre-selected if it was truthful, but now receives a utility of zero sinceit has not been pre-selected due to its misreporting. To show that this type of misreporting is suboptimal, we need toshow that, when ct((cid:2)θ c) < cs((cid:2)θ c), an agent benefits from being pre-selected, since it may then be asked to generate anestimate at its reported maximum precision, (cid:2)θ c . It follows directly from Theorem 5 that U ((cid:2)θ c) = cs((cid:2)θ c) − ct((cid:2)θ c) > 0 whenct((cid:2)θ c) < cs((cid:2)θ c), and therefore there is no incentive for an agent that would have been pre-selected to misreport its costfunction. (cid:2)Theorem 7. The mechanism is interim individually rational.Proof. Due to Theorem 6, we can assume that all agents, and consequently those pre-selected, will report their true costfunctions, and therefore ct(θ) (cid:3) cs(θ). In Theorem 5, we show that the expected utility U (θ) = cs(θ) − ct(θ) is strictly non-negative, irrespective of θ . Therefore, the expected utility of a pre-selected agent that generates an estimate of precisionequal to its reported maximum precision (cid:2)θ c , is strictly non-negative (i.e. U ((cid:2)θ c) (cid:2) 0), and hence the mechanism is interimindividually rational. (cid:2)5.4. Numerical simulationsHaving proven the economic properties of the mechanism, we present empirical results for a specific scenario in orderto explore the effect that the parameters n and m have on the centre’s total payments, and on the probability of achievingits required precision. In more detail, as before, the cost functions are represented by linear functions, given by ci(θ) = ciθ ,where ci are independently drawn from a uniform distribution ci ∼ U (1, 2). The maximum precisions of the selected agents,10 For completeness, we confirm that the second derivative is negative at θ = (cid:2)θ c . To this end, the second derivative is given by:s((cid:2)θ c)(cid:3)S(cid:3)((cid:2)θ c)d2U (θ,(cid:2)θ c)d((cid:2)θ c)2s((cid:2)θ c)(cid:3)S(cid:3)((cid:2)θ c)(cid:4)(cid:2)θ c = θ(cid:4)θ,(cid:2)θ c(cid:4)(cid:2)θ c(cid:4)(cid:2)θ c= c+ c− c(cid:3)(cid:3)s(cid:5)(cid:5)(cid:5)(cid:5)SS(cid:3)(cid:3)(cid:3)(cid:3)(24)Now, the first term of Eq. (24) is negative because S is strictly proper, and this implies that Ss ((cid:2)θ c) is(cid:3)(cid:3)((cid:2)θ c) is negative assuming concavity of the scoring rule. Hence, the second derivative is negative(cid:3)(cid:3)(θ,(cid:2)θ c ) is negative at θ = (cid:2)θ c . Furthermore, c(cid:3)(cid:3)positive, assuming convexity of the cost function, and Sat (cid:2)θ c = θ .A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672663Fig. 4. Centre’s probability of achieving the required precision and the mean total payment it has to issue.∼ U (0, 1) and finally the centre’s required precision, θ0, isθ ci , is independently drawn from another uniform distribution θ cequal to 1.7 in order to generate representative results whereby the probability of achieving the required precision, P (θ0),covers a broad range of values in [0, 1]. Finally, we restrict our analysis to the use of the parametric scoring rule for k = 1.2as we have shown in Section 4.4, that among the common rules and for various values of the parameter k, this rule is agood choice for a centre intending to issue low payments with low variance, that still remain bounded.iGiven this, and for N = 7, we explore all possible combinations of n and m given the constraints that 2 (cid:3) n < N and1 (cid:3) m < n. For each combination, we simulate the mechanisms 107 times and for each iteration we record whether thecentre was successful in acquiring an estimate at its required precision, and the sum of all the payments it issued to thoseagents that were asked to produce an estimate. In Fig. 4 we plot, for each possible combination of n and m, the probabilityof acquiring the required precision against the total payment made by the centre. We note that again the standard error ofthe mean values are much smaller than the plotted symbols, and thus, for clarity we omit it.With regard to this figure, the squares indicates the case where the centre has full information of the agents’ costs, andtherefore represents an upper bound for the mechanism. It results in significantly lower total payments to the agents sincethe centre is able to select those agents with the lowest costs to generate the estimates and it use payment rules that arescaled using the known costs of these agents. The circles depict the results for all possible combinations of n and m, exceptwhere n = N and m = M, which is indicated by a diamond (the reason for this will become clear shortly). We first note thatmany possible combinations of n and m give rise to the same value of P (θ0), and thus the family of possible pre-selectionmethods fall into 6 distinct columns. This is because this probability depends only on the number of agents that are pre-selected (denoted by M) and many of these combinations result in the same number of agents being pre-selected (e.g. ifN = 7, both n = 4, m = 2 and n = 5, m = 3 result in M = 4). Second, note that for each possible value of M, the case wheren = N and m = M dominates all other combinations of n and m (i.e. it results in the lowest mean total payment). This casecorresponds to a single selection stage in which M agents are pre-selected directly from the original N in a single step. Wemore formally analyse these two observations in the following section.5.5. Analysis of pre-selection schemesWith regard to the observation above that the probability of achieving θ0 is dependent on the number of agents pre-selected, we can see that this is so since within our mechanism the maximum precisions of the pre-selected agents areindependent of their costs. In the numerical simulations described above we have M independent and uniformly distributed∼ U (0, 1) which denote the agents’ maximum precisions. If we denote the sum of these as Θ such thatrandom variables θ ciΘ =Mi=1 θ ci , then its cumulative probability distribution allows us to calculate P (Θ (cid:2) θ0) as follows:(cid:17)P (Θ (cid:2) θ0) =(cid:18)1 − 1M!0(cid:17)(cid:12)θ0(cid:13)i=0 (−1)i(cid:5)(cid:4)Mi(θ0 − i)M 0 (cid:3) θ0 (cid:3) Mθ0 > M(26)Although not immediately obvious from its analytical form, this is an increasing function in M as demonstrated in thenumerical simulations.The second observation is that a single selection stage in which M agents are pre-selected directly from the original Nin a single step dominates all other selection schemes. This is perhaps more surprising and for this reason we provide aformal proof for the case where costs are linear functions of precision below.664A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672Theorem 8. In a setting with linear cost functions, where agents’ costs and maximum precisions are independently drawn from uniformdistributions, for a given probability of achieving θ0, the centre minimises its expected total payment when n = N and m = M.Proof. Given the mechanism and setting described above, we first note that when the costs of the agents are represented(cid:3)by linear functions, then ci(θ) = ciθ , and hence, ci(θ) = ci . Using this result within the scaling parameters of the paymentrule described in step 2.4, gives the result:α j = csS(cid:3)((cid:2)θ cj )and β j = cs(cid:2)θ cj− csS(cid:3)((cid:2)θ cj )(cid:5)(cid:4)(cid:2)θ cjS(27)Thus, both α and β are proportional to cs, and hence the payment to any agent is also proportional to the cost used inthe calculation of the scaling parameters. Secondly, we note that due to the random selection of agents within the secondstage of the mechanism, the precision of the estimate generated by any agent is independent of the cost used to generateits payment rule. Hence, the expected total payment to the agents is proportional to the mean cost used to generate theirpayment rules.Now, the costs used to generate the payment rule of any agent is the (m + 1)th lowest reported cost when m agentsare pre-selected from n. Thus, in order to show that setting n = N and m = M minimises the expected total payment ofthe centre, we must simply show that the expected value of the (M + 1)th cost when pre-selecting M agents from N, islower than any other combination. To do so, we note that if the costs of the agents are i.i.d. from the standard uniformdistribution,11 and the agents report truthfully (as they are incentivised to do), then the density function that describes the(m + 1)th cost, denoted by Cm+1:n, is given by:cm+1:n(u) =n!m!(n − m − 1)! um(1 − u)n−m−1, 0 (cid:3) u (cid:3) 1(28)and Arnold et al. [2] show that cm+1:n(u) ∼ B(m + 1, n − m) and therefore the mean of this distribution is simply m+1n+1 .Thus, we now prove that the (M + 1)th cost when pre-selecting all M agents directly from N is less than the expectedcost that results from first pre-selecting m agents from n and then pre-selecting the remaining M − m agents from N − n.Therefore, and given that cM+1:N (u) ∼ B(M + 1, N − M) and cM−m+1:N−n(u) ∼ B(M − m + 1, N − n − M + m), we must provethe inequality:(cid:11)M + 1N + 1M − m + 1N − n + 1+ M − mMm + 1n + 1(cid:3) mM(29)(cid:11)(cid:11)(cid:12)(cid:12)(cid:12)subject to the constraints that M < N, m < n and N − n > M − m, and we note that if it holds in this case, then it holds forall possible combinations of n and m.A first step towards the proof of Eq. (29), is performing the following substitutions:a = m,b = M − m,c = n,d = N − nsuch that Eq. (29) now takes the following form:(a + b)(a + b + 1)c + d + 1(cid:3) a(a + 1)c + 1with a, b, c, d (cid:2) 0, a < c, and b < d.+ b(b + 1)d + 1(30)Now, by multiplying all fractions in Eq. (30) to obtain a common denominator, (c + 1)(d + 1)(c + d + 1), and noting thatthis denominator is positive, translates Eq. (30) into the following condition:(a + b)(a + b + 1)(c + 1)(d + 1) − a(a + 1)(c + d + 1)(d + 1) − b(b + 1)(c + d + 1)(c + 1) (cid:3) 0We can rearrange this expression into the form:F 1(a, b, c, d) + F 2(a, b, c, d) + F 3(a, b, c, d) (cid:3) 0where:F 1(a, b, c, d) = −(d · a − b · c)2F 2(a, b, c, d) = −b(c − a)2 − b2(c − a) − a(d − b)2 − a2(d − b)F 3(a, b, c, d) = a(b − d) + b(a − c)(35)Now, it is easy to verify that F 1, F 2, and F 3 are all negative given the initial constraints that a, b, c, d (cid:2) 0, a < c and b < d.Hence, it follows that Eq. (32) is negative. (cid:2)(31)(32)(33)(34)11 For notational simplicity we shall assume that the costs are drawn from U (0, 1), but we note that the proof is valid for a uniform distribution of anysupport.A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–6726655.6. DiscussionIn this section, we extended our original two-stage mechanism by relaxing the assumption that a single agent canprovide an estimate of infinite precision and have introduced limitations on the agents’ maximum precisions. As a result ofthis, an agent might not be able to generate estimates of a sufficient precision to individually meet the centre’s needs, henceleaving the centre no option but to combine multiple such estimates and fuse them into a more accurate one. In additionto that, the centre now needs to elicit the maximum precision from the agents. In order to address these challenges, in thisextended mechanism a centre pre-selects M from the N available agents by eliciting their cost functions in the first stage.Then, in the second stage, it approaches some of these M agents and asks them to report their maximum precision andmake a costly probabilistic estimate or forecast of that precision. We proved that this mechanism is incentive compatibleand individually rational, and we empirically evaluated the mechanism for various values of the parameters m and n andshowed that for a given probability, P (θ0), the centre minimises its mean total payment if it pre-selects M agents directlyfrom a single group of N agents. These results showed that while it is always preferable to set n = N (i.e. no agents shouldbe excluded from the mechanism), the choice of the value of m is determined by the trade-off between the total paymentmade by the centre and the probability of it acquiring an estimate of its required precision. If the distributions of costand maximum precisions are known, this can be evaluated prior to running the mechanism through simulation. However,if these distributions are unknown, setting m = N − 1 ensures that the probability of acquiring the required precision ismaximised (but doing so will also incur the greatest expected payment).6. A mechanism addressing the centre’s lack of access to knowledge of the outcomeSo far, in both mechanisms we have considered, we have assumed that the centre has access to the actual outcomeof the estimated event in order to calculate the payment to the agents in the second stage. In this section we removethis assumption. This means that in the second stage the centre must now calculate the score of each individual agentbased upon the reports of the other agents. To do so, we have to modify the standard strictly proper scoring rules because,as we will show, to use them directly results in a scoring rule which no longer motivates agents to truthfully reportthe precision of their estimates (as we have seen in the last section, failing to truthfully report the precision means thatmultiple independent estimates cannot be correctly fused). In particular, we show that our ensuing mechanism is incentivecompatible with respect to maximum precisions and estimates, and that it is individually rational. We empirically evaluateour mechanism and compare it with the one we introduced in the previous section, in which the centre has access tothe actual outcome and with a modified version of the ‘peer prediction mechanism’ proposed by Miller et al. [29]. Weshow both analytically and empirically that for all the mechanisms we simulate, the agents expect to derive the samepayment, which means the centre incurs no additional cost as a result of its lack of knowledge of the outcome. However,we identify a significant difference between the fusion and the peer prediction methods, by showing that in our mechanismthe variance of the total payment issued to the selected agents by the centre (and thus the variance of the individualpayments) is significantly lower than the total payment’s variance in the peer prediction mechanism for M > 2 (althoughboth are greater than the case where the outcome is known). This is important since this variance represents the uncertaintyin the payments of both the centre and the individual agents (i.e. although the expected payments may be calculated beforehand, the actual payments will depend on the individual reports of the agents).6.1. Evaluating information without knowledge of the outcomeAs described in Section 2, here we consider the same model as in the previous section, however we additionally assumethat the centre will have no access to any knowledge of the outcome of the estimated event at the time at which is mustmake the payments to the agents. In doing so, the centre now has to rely solely on the estimates that it receives from theagents in order to scale the scoring rule, and is has two options is doing so: peer prediction or fusion.In more detail, in the peer prediction mechanism [29] the centre scores each agent’s estimate directly against each of theother agents’ estimates and then calculates its payment by averaging the resulting scaled scores. However, in the mechanismwe introduce in this section, the centre uses the fused reported estimates of all the other agents (excluding from the fusionprocess the agent that is currently receiving the payment), and repeats this process for each individual agent. The exclusionof the agent that is receiving the payment from the fusion process is important, otherwise agents would have an incentiveto exaggerate the precision of their estimates in order that the fused estimate corresponds more closely with their ownreport.To this end, when there are K (cid:2) 2 available agents, the centre calculates the payment to agent i, after fusing theagents’ conditionally independent and unbiased probabilistic estimates with mean {(cid:2)x1, . . . ,(cid:2)xi−1,(cid:2)xi+1, . . . ,(cid:2)xk} and precision{(cid:2)θ1, . . . ,(cid:2)θi−1,(cid:2)θi+1, . . . ,(cid:2)θk}, into one estimate with mean x and precision θ by using the standard result (see DeGroot andSchervish [8]):x−iθ −i =(cid:15)j∈K−i(cid:2)x j(cid:2)θ jand θ −i =(cid:15)j∈K−i(cid:2)θ j(36)666A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672where K−i = {1, . . . , i − 1, i + 1, . . . , k} is the set that contains all k agents besides agent i, which is the agent that is receivingthe payment from the centre.In this case, it is in a selected agent’s best interest to consider its belief about the fused observations of all the otheragents when reporting its precision. Now, this means that agent i’s expected score S(x; xi, θi) is maximised not at (cid:2)θi = θibut at (cid:2)θi = θi + θ −i . Indeed, if N(x−i; xi, 1/θi + 1/θ −i) and N (xi;(cid:2)xi, 1/(cid:2)θi) are Gaussian distributions with mean and variance(xi, 1/θi + 1/θ −i) and ((cid:2)xi, 1/(cid:2)θi), which represent agent i’s true and reported estimate’s distributions, agent i’s expected score,which is given by:∞(cid:6)S(x−i;(cid:2)xi,(cid:2)θi) =N (x−i; xi, 1/θi + 1/θ −i)S(cid:4)(cid:5)x−i|N (xi;(cid:2)xi, 1/(cid:2)θi)dx−i−∞(37)will be maximised at (cid:2)θi = θi + θ −i , since for that value of the reported precision, (cid:2)θi , the two distributions become identical.Subsequently, an agent wanting to maximise its expected score (Eq. (37)), will have to report θi + θ −i instead of θi , whichis impossible since it does not have access to other agents’ precisions (θ −i ). However, given that the centre, when calculatingthe payments, has access to both θi and θ −i , it can modify the strictly proper scoring rule such that the agent is onlyrequired to report θi but the payment is calculating using θi + θ −i . Therefore, within our mechanism we use this modifiedmodified strictly proper scoring rule, S(x−i;(cid:2)xi,(cid:2)θi + θ −i) and in Section 6.3 we prove that payments based on this modifiedscoring rule result (when scaled appropriately) in truthful revelation of an agent’s estimate being a Nash equilibrium, sincethe agent will maximise its expected payment if it reports truthfully, assuming that all other agents also report their trueestimates.6.2. The mechanismHaving defined our modified strictly proper scoring rules, in this section, we describe how we extend the two-stage mech-anism introduced in Section 5.2 for the setting in which the centre will not have access to the actual outcome whencalculating the payments to the pre-selected agents (Mechanism 3). To this end, in the first stage the centre pre-selects Mout of N agents and identifies their cost functions, while in the second stage it calculates their payments. Although thefirst stage is identical to the previous mechanism, in the second stage the centre fuses the pre-selected agents’ reports intoa single estimate (excluding the agent for which the payment is being calculated) and then uses an appropriately scaledmodified scoring rule to calculate each agent’s payment.Mechanism 3 The mechanism for dealing with the case where the centre does not have access to the actual outcome:1. First Stage1 Identical to Stage 1 of Mechanism 2.2. Second Stage2.1 and 2.2 are identical to steps 2.1 and 2.2 of Mechanism 2.2.3 The centre asks the agent j to produce an estimate of this precision and presents this agent with a scaled strictly proper scoring rule. Scalingj , θ − j ), and its derivative. The parameters are givenparameters α j and β j are now based on the expected value of the modified scoring rule, S((cid:2)θ cby:α j =(cid:3)cS(cid:3)((cid:2)θ cs((cid:2)θ cj )j , θ − j)and β j = cs(cid:5)(cid:4)(cid:2)θ cj−(cid:3)cS(cid:3)((cid:2)θ cs((cid:2)θ cj )j , θ − j)(cid:5)(cid:4)(cid:2)θ cj , θ − jS(38)where, cs is the cost associated with this agent in the first stage and θ − j is the fused precisions12 of all the agents that are asked to produce anestimate except agent j and is defined in Eq. (36).2.4 Identical to step 2.4 of Mechanism 2.2.5 The agents that were asked to do so, produce an estimate with mean x j and precision θ j , and report (cid:2)x j and (cid:2)θ j to the centre, which in turn issuesthe following payment:P j(x− j;(cid:2)x j,(cid:2)θ j + θ − j) = α j S j(x− j;(cid:2)x j,(cid:2)θ j + θ − j) + β j(39)where x− j and θ − j are the fused estimates and precisions of all the selected agents except agent j as defined in Eq. (36).6.3. Economic properties of the mechanismHaving detailed the mechanism we now prove that truthful reporting of the preselected agents’ maximum precisions andestimates is a Nash equilibrium. Note that truthful reporting of agents’ cost functions in the first stage is still a dominantstrategy and that this mechanism is also individually rational, like in all the previous mechanisms in this paper, and given12 However, it is important to note that whilst the scoring rule can be described at this point in the mechanism, the value of some of these precisions isstill unknown, and is only known after the final iteration of the mechanism.A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672667that the proofs are identical to those of Theorems 6 and 7 respectively we refrain from re-writing them here. However, wenow formally prove that truthful reporting of the agents’ estimates is a Nash equilibrium when using our modified strictlyproper scoring rule, and that truthful reporting of the agents’ maximum precisions and estimates is a Nash equilibriumunder our mechanism.Theorem 9. Truthful revelation of an agent’s estimate and precision is a Nash Equilibrium under our modified strictly proper scoringrule.Proof. Given that an agent i’s estimate is represented by the Gaussian distribution N (x0; x, 1/θ), under the modified strictlyproper scoring rules, the score it expects to derive, is the following:S(x−i;(cid:2)xi,(cid:2)θi + θ −i) =N (x−i; xi, 1/θi + 1/θ −i)S∞(cid:6)(cid:4)(cid:5)x−i|N (xi;(cid:2)xi, 1/(cid:2)θi + 1/θ −i)dx−i(40)−∞where N (x−i; xi, 1/θi + 1/θ −i) and N (xi;(cid:2)xi, 1/(cid:2)θi + 1/θ −i) are Gaussian distributions with mean and variance (xi, 1/θi +1/θ −i) and ((cid:2)xi, 1/(cid:2)θi + 1/θ −i) respectively, which will be denoted as Q and R respectively. Now Eq. (40) takes the followingform:∞(cid:6)S =Q (x−i)S−∞(cid:4)(cid:5)x−i|R(x−i)dx−i(41)Since S is a strictly scoring rule, as defined by Hendrickson and Buehler [16] and Savage [36], its expected value ismaximised when Q = R. Furthermore, given the definition of Q and R, for (cid:2)xi = xi and (cid:2)θi = θi ⇒ Q = R. Therefore, for(cid:2)xi = xi and (cid:2)θi = θi , a payment based on the modified strictly scoring rule, S(x−i;(cid:2)xi,(cid:2)θi + θ −i), is incentive compatible, sincean agent will maximise its expected payment if it reports truthfully its estimate, assuming that all other agents also reporttheir true estimates. The latter makes truthful reporting a Nash equilibrium since an agent will maximise its utility, thusmaking this strategy the optimal, if all other agents report truthfully their estimates too. (cid:2)Theorem 10. Truthful reporting of the maximum precisions and estimates is a Nash equilibrium under our mechanism.Proof. In the mechanism described above, when agent j reports its estimate, its reported precision, (cid:2)θ j , is equal to itsj . Indeed, (cid:2)θ j > (cid:2)θ creported maximum precision, (cid:2)θ cis not possible given that the centre is already informed of the agent’smaximum precision, and (cid:2)θ j < (cid:2)θ cj would not be in the agent’s best interest since under-reporting its precision would lead toa smaller payment. Therefore, (cid:2)θ j = (cid:2)θ cj . Now, given the scaling of the scoring rules described in step 3 in the second stage ofthe mechanism, the expected utility of the agent, if it reports its maximum precision as (cid:2)θ cj , and subsequently produces anestimate of precision θ j , which it reports with precision (cid:2)θ cj , is denoted by U j(θ j,(cid:2)θ cj ), and given by:j(cid:4)U jθ j,(cid:2)θ cj(cid:5)=S(cid:3)s((cid:2)θ cj )cf , j((cid:2)θ cj , θ − j)(cid:3)(cid:4)(cid:4)S f , jθ j,(cid:2)θ cj , θ − j(cid:5)− S f , j(cid:5)(cid:5)(cid:4)(cid:2)θ cj , θ − j(cid:5)(cid:4)(cid:2)θ cj+ cs(cid:5)(cid:4)(cid:2)θ cj− ct(42)where S f , j(θ j,(cid:2)θ cj , θ − j) is agent j’s expected score for producing an estimate of precision θ and reporting to the centre, (cid:2)θ cand S f , j((cid:2)θ cj , θ − j) is agent j’s expected score for producing and truthfully reporting an estimate of precision (cid:2)θ cj . Furthermore,ct(.) is the true cost function of the agent, and cs(.) is the cost function used to produce the scoring rule (i.e. the (m + 1)thlowest revealed cost in the group from which the agent was pre-selected).Note that S f , j is the expected value of the modified scoring rule S(x− j;(cid:2)x j,(cid:2)θ j + θ − j), already defined in Theorem 9:S(x− j;(cid:2)x j,(cid:2)θ j + θ − j) =N (x− j; x j, 1/θ j + 1/θ − j)S∞(cid:6)(cid:4)(cid:5)x− j|N (x j;(cid:2)x j, 1/(cid:2)θ j + 1/θ − j)dx− j−∞Now, taking the first derivative of expected utility (Eq. (42)) with respect to (cid:2)θ cj gives:dU j(θ j,(cid:2)θ cj )d(cid:2)θ cj= dd(cid:2)θ cj(cid:11)(cid:3)(cid:3)Ss((cid:2)θ cj )cf , j((cid:2)θ cj , θ − j)s((cid:2)θ cj )cf , j((cid:2)θ cj , θ − j)S(cid:3)+S(cid:3)(cid:4)θ j,(cid:2)θ cj , θ − j(cid:5)(cid:3)f , j(cid:12)(cid:4)(cid:4)S f , jθ j,(cid:2)θ cj , θ − j(cid:5)− S f , j(cid:5)(cid:5)(cid:4)(cid:2)θ cj , θ − j(43)(44)668A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672We have already shown that truthful revelation is a Nash equilibrium for the modified scoring rule, S f , j (Theorem 9). Hence,when θ j = (cid:2)θ cj :(cid:4)θ j,(cid:2)θ cθ j,(cid:2)θ cand S= S f , j= 0(cid:4)(cid:2)θ cj , θ − jj , θ − jj , θ − jS f , j(cid:3)f , j(cid:5)(cid:4)(cid:5)(cid:5)and subsequently:dU j(θ j,(cid:2)θ cj )d(cid:2)θ cj(cid:16)(cid:16)(cid:16)(cid:16)(cid:2)θ cj= 0=θ j(45)Therefore, a preselected agent’s expected utility is maximised when it reveals as its maximum precision, the precision ofthe estimate that it subsequently produces, given that all other agents do the same.We now show that it will actually produce an estimate of precision equal to its reported maximum precision. To thisend, we note that when (cid:2)θ cj= θ j , the expected utility of the agent is given by:U j(θ) = cs(θ j) − ct(θ j)(46)Since cs(.) and ct(.) do not cross or overlap, and c(cid:3)s(θ j) > cagent will maximise its expected utility by producing an estimate at its maximum precision, and thus, θ j = θ c(cid:2)θ c(cid:3)t(θ j), then U j(θ j) is a strictly increasing function. Thus thej , and hence,= (cid:2)θ j = θ cj , as required. (cid:2)j6.4. Numerical simulationsHaving introduced our mechanism and proven its economic properties, we present empirical results for a specific sce-nario. We do so in order to compare our mechanism (that uses the fused outcome of all the other agents to score eachindividual agent) with Miller et al.’s peer prediction mechanism (which calculates the average of pairwise comparisons).As in the previous simulations, the cost functions are represented by linear functions, given by ci(θ) = ciθ , where ci areindependently drawn from a uniform distribution ci ∼ U (1, 2). Also, the maximum precisions of the selected agents, θ ci , are∼ U (0, 1) and, as before, the centre’s required precision, θ0, isindependently drawn from another uniform distribution θ ciequal to 1.7. Finally, as before, we use the parametric family of scoring rules and set the parameter equal to 1.2.For the purposes of this analysis, the peer prediction mechanism had to be slightly modified in order to eliminate theassumption that the centre has knowledge of the agents’ costs. Hence, we transform the peer prediction mechanism to atwo-stage peer prediction mechanism, in which the centre in the first stage asks all agents, N, to report their cost functionsand then pre-selects M of them, while in the second it allocates the payments to the agents providing the estimates. Thefirst stage is identical to the first stage of the mechanism presented in Section 5.2, while in the second stage the centrecalculates the payment to an agent not by using the fused reported estimates, but by scoring that agent against each one ofthe remaining M − 1 agents and then by averaging over the M − 1 respective payments.To this end, for N = 7, we evaluate our mechanisms (both that from Section 5 which assumes access to the real outcome,and that from this section which does not) against the two-stage peer prediction mechanism. As before, we define theupper bound on the performance of the mechanism as that in which the centre has access to the agents’ cost functions(denoted as the ‘full information’ case) and thus can optimally allocate the estimate to the agent it needs in order toachieve the required precision. We simulate the mechanisms 106 times and for each iteration we record whether the centrewas successful in acquiring its required precision, and the sum of the payments issued to the selected agents. In Fig. 5(a)we show for M ∈ {1, 2, 3, 4, 5, 6}, the probability with which the centre has achieved the required precision and the totalpayment made by the centre (again we omit error bars since, given the number of the iterations, the standard error in theplotted values is smaller than the symbol size), while in Fig. 5(b) we show the variance of the total payment the centreissues to the selected agents.Considering Fig. 5(a), we note that for every value of M, the sum of the expected payment for each of the three mecha-nisms is the same. This means that the centre expects to derive no additional penalties as a result of its lack of knowledgeof the actual outcome. Effectively this result shows that the uncertainty that has been introduced in our setting due to thelack of knowledge of the actual outcome has no impact on the expected payments. The explanation of this result lies withinthe properties of the mechanism itself and we provide a formal proof in the next section, where we calculate the totalexpected payment for the three evaluated mechanisms for the general case of any convex cost function and show that theyare all equal.However, Fig. 5(b) shows that lack of knowledge about the actual outcome does impact the variance in the total paymentthat the centre makes. In all cases, the variance of total payments is lowest when the centre has access to the actualoutcome. Furthermore, for M = 2 the variance of the payments is the same in both mechanisms since our mechanismbecomes identical with the peer prediction mechanism in this case. However, for M > 2 the variance of the payments thecentre issues in the peer prediction mechanism is much greater than the variance of payments in our mechanism. Thisresults from the peer predictions methods increased sensitivity to agents whose estimates diverge from the consensus.In the peer prediction method the impact of such an outlier is somewhat minimised by averaging over all the pair-wiseA. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672669Fig. 5. Centre’s probability of achieving the required precision and the mean total payment, and the total payment’s variance.calculated scores. However, as we show here, the impact is further minimised in our approach where all the estimates,apart from that of the agent whose payment is being calculated, are fused together prior to applying the scoring rule.6.5. Analysis of expected total paymentIn the discussion above, we noted that the expected total payment of the centre under all three mechanisms is equal, andis not affected by the lack of knowledge of the actual outcome. To see why this is so, we first note that the mechanism bywhich an agent is selected to produce an estimate is identical in each case, and thus, we need only show that the expectedpayment of any of the selected agents is identical in each mechanism. Thus, to this end, we first consider the mechanismin which the centre has access to the actual outcome. In this case, the payment agent j expects to derive, after the centreobserves the actual outcome, is given by:(cid:4)P jθ j,(cid:2)θ cj(cid:5)=cS(cid:3)s((cid:2)θ cj )j((cid:2)θ cj )(cid:3)(cid:4)(cid:4)S jθ j,(cid:2)θ cj(cid:5)(cid:5)(cid:5)(cid:4)(cid:2)θ cj(cid:5)(cid:4)(cid:2)θ cj+ cs− S j(47)In this context, given that agents produce estimates with precisions equal to their reported maximum precisions (Theo-rem 5), θ j = (cid:2)θ cj . Thus, agent j’s expected payment is:P j(θ j) = cs(θ j)(48)where cs(θ j) is the scaling cost used for in the calculation of agent j’s payment.Now, in the mechanism presented in this section in which the centre has no access to the actual outcome, the payment(cid:4)(cid:5)the selected agent j expects to derive is given by:s((cid:2)θ cj )cf , j((cid:2)θ cj , θ − j)Thus, the payment agent j expects to derive, given that θ j = (cid:2)θ c− S f , jθ j,(cid:2)θ cθ j,(cid:2)θ cj , θ − jS f , jP j=(cid:5)(cid:4)(cid:4)S(cid:3)(cid:3)j(cid:4)(cid:2)θ cj , θ − j(cid:5)(cid:5)(cid:5)(cid:4)(cid:2)θ cj+ csj , is again given by:Pfj (θ j) = cs(θ j)(49)(50)Finally, in the peer prediction mechanism the centre scores agent j against every other agent in pairs, and then calculatesits payment after averaging over the M − 1 payments that correspond to each one of the selected agents. Hence, the paymentagent j expects to derive in the peer prediction mechanism is the following:s((cid:2)θ cj )cp, j((cid:2)θ cj , θ i)(cid:4)(cid:2)θ cj , θ i= 1− S p, jθ j,(cid:2)θ cθ j,(cid:2)θ cM − 1(cid:4)(cid:2)θ c+ csj , θ iS p, j(51)(cid:15)P j(cid:5)(cid:5)(cid:4)(cid:5)(cid:5)(cid:4)(cid:4)(cid:5)S(cid:3)(cid:3)jji∈Miwhere S p, j is the expected score of our modified scoring rule S(xi;(cid:2)x j,(cid:2)θ j + θ i) which scores agent j against the estimateof agent i (unlike our approach which would score agent j against the fused estimate of all other agents). Miller et al. [29]670A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672have shown that this scoring rule is incentive compatible, therefore S p, j(θ j,(cid:2)θ cpayment agent j expects to derive is:j , θ i) = S p, j((cid:2)θ cj , θ i) when θ j = (cid:2)θ cj . Hence, thePpj (θ j) = 1M − 1(cid:15)i∈M− jcs(θ j) = cs(θ j)(52)In each of the three mechanisms, the agents are incentivised to truthfully report their estimates, and we find that allthree payments are equal, P j(θ j) = Pfj (θ j) = Ppj (θ j) = cs(θ j), as required.6.6. DiscussionIn this section, we provided a non-trivial extension to our previous mechanism by eliminating the assumption thatthe centre has access to the realised outcome of the estimated event when calculating the payments to the pre-selectedagents. As a result of this, now the centre uses the fused reported estimates of the selected agents when calculating itspayment. We modified the existing strictly proper scoring rules so they can incentivise agents to truthfully report theirestimate, given that they will be scored against all other agents’ fused reported estimates and proved that in our mechanism,truthful reporting of the maximum precisions and the estimates is a Nash equilibrium. Finally we empirically evaluatedour mechanism for various values of M and compared it with a modified peer prediction mechanism, while using themechanism which assumes knowledge of the actual outcome as a benchmark. We showed that the centre’s total meanpayment is the same among all three mechanisms and that for the two mechanisms that do not rely on knowledge ofthe actual outcome, the variance of the centre’s total payment is minimised when it calculates payments using the fusedreported agents’ estimates. This result indicates that the increase of uncertainty in the system, due to lack of knowledge ofthe realised outcome, restricts its impact only to the variance of the payments, and does not affect the payments that theagents expect to derive.7. Related workThe main scoring rules literature has already been described in Sections 1 and 2, so here we only review other ap-proaches for addressing the problems described within this paper. We first consider mechanism design, and in particularlythe VCG mechanism which has been widely used to incentivise truth-telling in dominant strategies when allocating goodsor tasks [38,5,12,23]. If we first consider the setting in which any selected agent is capable of providing the centre with therequested estimate, then we can see the two stage mechanism that we introduce as an extension of the VCG mechanism(or more precisely, a second price reverse auction in this case) in which the payments are not directly determined by thetypes of the agents, but are conditioned on the actual outcome, such that the agents are incentivised to actually commitresources to generating the estimate.The case is more complex in the second two mechanisms since procuring estimates from multiple agents results in aninterdependent valuation setting, with so-called allocative externalities, for which it has been shown that no standard mech-anism exists which is both efficient and incentive compatible [17]. This has been addressed to a certain degree by Mezzetti[26,27] who shows that efficiency can be achieved in a two-stage mechanism, where in the first stage the final outcome isdetermined (i.e. the allocation of some goods or tasks), while in the second stage the agents and the centre observe theirutilities, and hence receive the final transfers from the centre. Such two stage mechanisms have also been demonstrated ininterdependent valuation settings by Klein et al. [22] who present an application for allocating communication bandwidth,by Porter et al. [32] for a task allocation setting where agents have some fixed probability of completing a task which thecentre must elicit, and Ramchurn et al. [34] who extend the previous setting by allowing agents to report on the probabilitywith which other agents may be able to complete the requested tasks.However, these settings depart from the one considered here in one important way. In our setting the agents are ableto manipulate the resources that they can commit to generate their estimates. In the setting described above, this is notpossible. In the mechanisms of Mezzetti [26] and Klein et al. [22] fixed goods are being allocated. While in those of Porteret al. [32] and Ramchurn et al. [34], the probability that a task is completed is fixed and is not under the control of theagent. Thus, agents in our setting are able to manipulate their utility by misreporting the precision of their estimates.Crucially, this misreporting cannot be observed by the centre, and it is dependent on the type (their cost function andmaximum precision) that they would report to the centre within the VCG mechanism.13 For this reason, the two stagemechanisms described address do not fully address the challenges of our domain, and thus, rather than seeking an efficientand incentive-compatible mechanism, we settle for an in-efficient mechanism which is still incentive-compatible.At this point, it should be noted that scoring rules have found other applications not always directly relevant to mech-anism design. In more detail, there are many similarities between the logarithmic scoring rule, used in this research, andthe market scoring rules [14,13] used in prediction markets [3,40]. In such systems, agents trade information on probabilistic13 Note that in the case of the mechanism that selects a single agent, this manipulation is independent of the agents’ types (since their types now onlyconstitute their cost functions), and thus, an efficient mechanism is still possible.A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672671events and receive pay-offs which depend on the outcome of these events. In another line of research, strictly proper scoringrules are not used as stand alone payments, but in conjunction with prediction markets [9]. Although their contribution issignificant, since they merge prediction markets and strictly proper scoring rules, in their setting they assume knowledge ofthe common prior of the agents’ subjective beliefs on the estimated parameter. This issue is addressed by Prelec [33] whopropose a mechanism which does not depend on knowledge of the common prior but only on its existence.However, in all these applications (i.e. market scoring rules and strictly proper scoring rules prediction markets), agentscan change their initial reported prediction, if they have new evidence, and their payments also have to be adjusted in orderto take into consideration the difference in the agents’ reports. This constant flow of information makes these approachesparticularly appealing in dynamic systems with rich interactions among the participating agents. Although we are interestedin a similar setting where there is also a lack of knowledge about the state of the world, we adopted a less complexapproach, in which agents communicate their estimates to a centre and then receive their payments. We believe that ourapproach is more appropriate for a setting in which a centre wants to acquire a single estimate of a probabilistic event, sinceit only has to calculate the agents’ payments in a single round simply by comparing it with the fused reported estimatesor the outcome (if that knowledge is available), instead of implementing the more dynamic and complex process describedabove.More importantly, these approaches fail to account for the costs of the agents, since they do not explicitly model the casethat agents must invest resources to generate their estimates. This is a key assumption within our setting, and thus, it isdifficult to see how these mechanisms can be applied in this setting, since any agent that commits resources to generatingan estimate in order to participate within the mechanism must expect to receive at least this amount in payment in orderto ensure individual rationality. Extending such mechanisms to address this challenge would certainly be an interestingcontribution, but it is outside of the scope of this paper.8. Conclusions and future workIn this paper we contributed to the state of the art by introducing the first mechanism that elicits costly probabilisticestimates from multiple agents in a setting where the centre has no knowledge of the costs involved in the generationof these estimates or the outcome of the estimated event. We achieved this by gradually relaxing the assumptions in twomore specific mechanisms. In the first mechanism, the agents faced no restrictions on the precision of the estimates theycould provide, while in the second the agents had limitations on the maximum precisions of their estimates. In the both thefirst and second mechanisms the payment could be conditioned on the actual outcome, whereas in the third mechanismthe agents’ payments are conditioned on the reports of the other agents. However, it should be noted that although thethird mechanism is a generalisation of the first two, both preliminary mechanisms are contributions in their own right andwould be used in preference to the more general one in specific settings. Indeed, the first mechanism is the optimal choicein a setting where all agents can provide estimates of precisions that are higher than the required by the centre (with outnecessarily being infinite), and therefore the centre does not have to acquire multiple estimates. Moreover, for the secondmechanism truthful reporting is a stronger solution concept (i.e. dominant strategy) when compared to the final mechanism,and the payments are more robust since their variance is minimised.For all three mechanisms we provided both theoretical and empirical results. Specifically, we proved that the first twomechanisms are incentive compatible with respect to all the reported parameters (including costs, estimates and precisions).Moreover, we further modified the strictly proper scoring rules so that they incentivise agents to truthfully report theirestimates when they are scored against the fused reports of all the other agents, and we proved that truthful reporting isa Nash equilibrium in this case. In addition, we thoroughly compared the quadratic, spherical and logarithmic scoring ruleswith a parametric family of strictly proper scoring rules, both analytically and empirically, and provided criteria for thechoice of the parameter k. Our final contribution was to show that the increase of uncertainty in our model, as introducedby the centre’s lack of knowledge of the realised outcome, did not have an impact on the centre’s expected total payment,but it was restricted only to the total payment’s variance.Our future work will address two of the current limitations of our mechanisms. In particular, first we would like toinvestigate the vulnerability of the mechanisms to collusion among the pre-selected agents in the second stage of themechanism. Jurca and Faltings [21] describe a number of potential manipulations of mechanisms whereby all the agents, ora sub-group of the agents, agree on a specific strategy, or where agents deploy ‘pseudo-agents’ which they can control andimpose their strategies (commonly referred to false-name bidding). A number of authors have described auction mechanismwhich are resistant to collusion and/or false-naming bidding [7,42], and in general these operate by imposing additionalconstraints on the payments made to the agents. However, such constraints change the economic properties of the auction(for example, the core-selecting package auctions designed by Day and Milgrom [7] reduce opportunities for bidders tocollude but render it only approximately incentive-compatible), and their use in our setting must be carefully evaluated.Second, we would like to extend our model and mechanism to cases where the cost functions and the exchangedinformation cannot be modelled by continuous distributions. This will allow us to address a wider set of problems wherethe exchanged information can be represented by not only continuous but also discrete probability distributions; as usedwithin the task allocation problems of Czumaj and Ronen [6], or for rating and ranking of information in recommendersystems by Adomavicius and Tuzhilin [1]. However, several of the assumptions we make regarding the order of the cost672A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672functions and their derivatives will not hold in the case of discrete probability distributions, and thus, it is not obvious thatan incentive compatible and individually rational mechanism can still be derived.AcknowledgementsPreliminary versions of this work appear in Papakonstantinou et al. [30,31]. This research was undertaken as part ofthe EPSRC funded project on Market-Based Control (GR/T10664/01), a collaborative project involving the Universities ofBirmingham, Liverpool and Southampton and BAE Systems, BT and HP. Finally, we would like to thank the anonymousreviewers of an earlier draft of this article for their insightful and useful comments.References[1] G. Adomavicius, A. Tuzhilin, Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions, IEEETransactions on Knowledge and Data Engineering 17 (6) (2005) 734–749.[2] B.C. Arnold, N. Balakrishnan, H.N. Nagaraja, A First Course in Order Statistics, SIAM, 2008.[3] J.E. Berg, T.A. Rietz, Prediction markets as decision support systems, Information Systems Frontiers 5 (1) (2003) 79–93.[4] G.W. Brier, Verification of forecasts expressed in terms of probability, Monthly Weather Review 78 (1950) 1–3.[5] E. Clarke, Multipart pricing of public goods, Public Choice 11 (1) (1971) 17–33.[6] A. Czumaj, A. Ronen, On the expected payment of mechanisms for task allocation, in: Proceedings of the Twenty-Third Annual ACM Symposium onPrinciples of Distributed Computing, 2004, pp. 98–106.[7] R. Day, P. Milgrom, Core-selecting package auctions, International Journal of Game Theory 36 (3) (2008) 393–407.[8] M.H. DeGroot, M.J. Schervish, Probability and Statistics, Addison–Wesley, 2002.[9] S. Goel, D.M. Reeves, D.M. Pennock, Collective revelation: A mechanism for self-verified, weighted, and truthful predictions, in: Proceedings of the ACMConference on Electronic Commerce, Stanford, California, USA, 2009, pp. 265–274.[10] P.C. Gregory, Bayesian Logical Data Analysis for the Physical Sciences: A Comparative Approach with Mathematica Support, Cambridge Univ. Press,2005.[11] S.J. Grossman, O.D. Hart, An analysis of the principal-agent problem, Econometrica 51 (1) (1983) 7–45.[12] T. Groves, Incentives in teams, Econometrica 41 (4) (1973) 617–631.[13] R. Hanson, Logarithmic market scoring rules for modular combinatorial information aggregation, The Journal of Prediction Markets 1 (1) (2007) 3–15.[14] R. Hanson, Combinatorial information market design, Information Systems Frontiers 5 (1) (2003) 107–119.[15] J.K. Hart, K. Martinez, Environmental sensor networks: A revolution in the earth system science?, Earth-Science Reviews 78 (2006) 177–191.[16] A.D. Hendrickson, R.J. Buehler, Proper scores for probability forecasters, The Annals of Mathematical Statistics 42 (6) (1971) 1916–1921.[17] P. Jehiel, B. Moldovanu, Efficient design with interdependent valuations, Econometrica 69 (5) (2001) 1237–1259.[18] A. Jøsang, R. Ismail, A. Boydb, A survey of trust and reputation systems for online service provision, Decision Support Systems 43 (2) (2007) 618–644.[19] R. Jurca, B. Faltings, Reputation-based service level agreements for web services, in: Service Oriented Computing, in: Lecture Notes in Computer Science,vol. 3826, Springer, Berlin/Heidelberg, 2005, pp. 396–409.[20] R. Jurca, B. Faltings, Minimum payments that reward honest reputation feedback, in: Proceedings of the ACM Conference on Electronic Commerce, AnnArbor, Michigan, USA, 2006, pp. 190–199.[21] R. Jurca, B. Faltings, Collusion resistant, incentive compatible feedback payments, in: Proceedings of the ACM Conference on Electronic Commerce, SanDiego, California, USA, 2007, pp. 200–209.[22] M. Klein, G.A. Moreno, D.C. Parkes, D. Plakosh, S. Seuken, K. Wallnau, Handling interdependent values in an auction mechanism for enhanced bandwidthallocation in tactical data networks, in: Proceedings of the 3rd International Workshop on Economics of Networked Systems, NetEcon 2008, New York,USA, 2008, pp. 73–78.[23] V. Krishna, Auction Theory, Academic Press, 2002.[24] A. Mas-Colell, M.D. Whinston, J.R. Green, Microeconomic Theory, Oxford University Press, 1995.[25] J.E. Matheson, R.L. Winkler, Scoring rules for continuous probability distributions, Management Science 22 (10) (1976) 1087–1096.[26] C. Mezzetti, Mechanism design with interdependent valuations: Efficiency, Econometrica 72 (5) (2004) 1617–1626.[27] C. Mezzetti, Mechanism design with interdependent valuations: Surplus extraction, Economic Theory 31 (3) (2007) 473–488.[28] N.H. Miller, J.W. Pratt, R.J. Zeckhauser, S. Johnson, Mechanism design with multidimensional, continuous types and interdependent valuations, Journalof Economic Theory 136 (2007) 476–496.[29] N.H. Miller, P. Resnick, R.J. Zeckhauser, Eliciting honest feedback: The peer prediction method, Management Science 51 (9) (2007) 1359–1373.[30] A. Papakonstantinou, A. Rogers, E.H. Gerding, N.R. Jennings, A truthful two-stage mechanism for eliciting probabilistic estimates with unknown costs,in: Proceedings of the Eighteenth European Conference on Artificial Intelligence, Patras, Greece, 2008, pp. 448–452.[31] A. Papakonstantinou, A. Rogers, E.H. Gerding, N.R. Jennings, Mechanism design for eliciting probabilistic estimates from multiple suppliers with un-known costs and limited precision, in: Proceedings of the Eleventh Worhshop in Agent Mediated Electronic Commerce, Budapest, Hungary, 2009,pp. 111–124.[32] R. Porter, A. Ronen, Y. Shoham, M. Tennenholtz, Fault tolerant mechanism design, Artificial Intelligence 172 (15) (2008) 1783–1799.[33] D. Prelec, A Bayesian truth serum for subjective data, Science 306 (5695) (2004) 462–466.[34] S.D. Ramchurn, C. Mezzetti, A. Giovannucci, J.A. Rodriguez, R.K. Dash, N.R. Jennings, Trust-based mechanisms for robust and efficient task allocation inthe presence of execution uncertainty, Journal of Artificial Intelligence Research 35 (2009) 119–159.[35] W.P. Rogerson, The first-order approach to principal-agent problems, Econometrica 53 (6) (1985) 1357–1367.[36] L.J. Savage, Elicitation of personal probabilities and expectations, Journal of the American Statistical Association 66 (336) (1971) 783–801.[37] R. Selten, Axiomatic characterization of the quadratic scoring rule, Experimental Economics 1 (1) (1998) 43–61.[38] W. Vickrey, Counterspeculation, auctions and competitive sealed tenders, The Journal of Finance 16 (1) (1961) 8–37.[39] G. Werner-Allen, J. Johnson, M. Ruiz, J. Lees, M. Welsh, Monitoring volcanic eruptions with a wireless sensor network, in: Proceedings of the SecondEuropean Workshop on Wireless Sensor Networks, Instanbul, Turkey, 2005, pp. 108–120.[40] J. Wolfers, E. Zitzewitz, Prediction markets, Journal of Economic Perspectives 18 (2) (2004) 107–126.[41] M. Xue, D. Wang, J. Gao, K. Brewster, The advanced regional prediction system (ARPS): Storm-scale numerical weather prediction and data assimilation,Meteorology and Atmospheric Physics 82 (1–4) (2004) 139–170.[42] M. Yokoo, Y. Sakurai, S. Matsubara, The effect of false-name bids in combinatorial auctions: New fraud in internet auctions, Games and EconomicBehavior 46 (1) (2004) 174–188.[43] J. Zhou, D. De Roure, FloodNet: Coupling adaptive sampling with energy aware routing in a flood warning system, Journal of Computer Science andTechnology 22 (1) (2007) 121–130.[44] A. Zohar, J.S. Rosenschein, Mechanisms for information elicitation, Artificial Intelligence 172 (16–17) (2008) 1917–1939.