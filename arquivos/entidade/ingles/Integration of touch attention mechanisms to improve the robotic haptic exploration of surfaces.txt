Neurocomputing 222 (2017) 204–216Contents lists available at ScienceDirectNeurocomputingjournal homepage: www.elsevier.com/locate/neucomIntegration of touch attention mechanisms to improve the robotic hapticexploration of surfacesRicardo Martinsa,b,⁎, João Filipe Ferreiraa, Miguel Castelo-Brancob, Jorge Diasa,ca ISR-UC, Institute of Systems and Robotics, Department of Electrical and Computer Engineering - University of Coimbra Polo II, 3030-290 Coimbra,Portugalb IBILI-UC, Institute for Biomedical Imaging and Life Sciences, Faculty of Medicine, University of Coimbra, Coimbra, Portugalc Robotics Institute, Khalifa University, Abu Dhabi, UAEcrossmarkA R T I C L E I N F OA B S T R A C TCommunicated by Grana ManuelKeywords:Touch attentionArtificial perceptionBayesian modellingPath planningHaptic explorationProbabilistic grid mapsThis text presents the integration of touch attention mechanisms to improve the efficiency of the action-perception loop, typically involved in active haptic exploration tasks of surfaces by robotic hands. Theprogressive inference of regions of the workspace that should be probed by the robotic system uses informationrelated with haptic saliency extracted from the perceived haptic stimulus map (exploitation) and a “curiosity”-inducing prioritisation based on the reconstruction's inherent uncertainty and inhibition-of-return mechanisms(exploration), modulated by top-down influences stemming from current task objectives, updated at eachexploration iteration. This work also extends the scope of the top-down modulation of information presented ina previous work, by integrating in the decision process the influence of shape cues of the current explorationpath. The Bayesian framework proposed in this work was tested in a simulation environment. A scenario madeof three different materials was explored autonomously by a robotic system. The experimental results show thatthe system was able to perform three different haptic discontinuity following tasks with a good structuralaccuracy, demonstrating the selectivity and generalization capability of the attention mechanisms. Theseexperiments confirmed the fundamental contribution of the haptic saliency cues to the success and accuracy ofthe execution of the tasks.1. IntroductionIn an attempt to capitalise on the same advantages that havinghands benefit human beings, researchers have recently put a lot ofeffort into the development of dexterous robotic hands, due to themechanical (high number of degrees-of-freedom) and sensory (tactile,force, torque, heat) capabilities that they provide. These devices allowrobotic platforms to perform precise manipulation of objects (reaching,grasping, transportation, in-hand reorientation) [1], as well as hapticexploration of surfaces using different patterns of movements (lateralmotion, press-and-release, static contact),thereby promoting theextraction and integration of different haptic properties (contours,texture, compliance, temperature) of the materials these surfaces arecomposed of [2].The contributions presented in this work are related with therobotic haptic exploration of surfaces, following three essential as-sumptions: (1) no other type of sensors are used besides haptics (i.e.exploration is “blind”); (2) exploration paths are not predefined; (3) thesurface geometry is unknown to the robot. The objectives of theexploration tasks concern haptic discontinuity/contour following.Haptic discontinuities are defined by the transition/border regionsbetween surfaces with different haptic properties. During hapticexploration, the interaction of the robotic platform with the probedsurface provides multiple simultaneous streams of data over itsgeometry and the properties of its composing materials relayed by anensemble of haptic sensors. This data is potentially uncertain due tosensor noise and the unknown nature of the surface.To tackle these challenges, we propose a Bayesian framework toimplement autonomous haptic exploration of surfaces that implementsan action-perception loop architecture. The Bayesian formalism pro-vides a principled way of implementing the integration of the multi-modal sensory data supplied by the haptics ensemble while properlydealing with their inherent uncertainty. The proposed action-percep-tion loop architecture integrates touch attention mechanisms (i.e.stimulus-driven processes modulated by task-relevant top-down influ-ences) to optimise the exploration strategy. This in turn promotes⁎ Corresponding author at: University of Coimbra Polo II, Department of Electrical and Computer Engineering, ISR-UC, Institute of Systems and Robotics, 3030-290 Coimbra,Portugal.E-mail addresses: rmartins@isr.uc.pt (R. Martins), jfilipe@isr.uc.pt (J.F. Ferreira), mcbranco@fmed.uc.pt (M. Castelo-Branco), jorge@isr.uc.pt (J. Dias).http://dx.doi.org/10.1016/j.neucom.2016.10.027Received 21 February 2016; Received in revised form 11 July 2016; Accepted 17 October 2016Available online 26 October 20160925-2312/ © 2016 Elsevier B.V. All rights reserved.R. Martins et al.Neurocomputing 222 (2017) 204–216adaptive behaviour due to the exploration and exploitation traits ofsuch mechanisms.The haptic exploration of surfaces plays a fundamental role inreduced visibility scenarios (i.e.: underwater robotic manipulation,smoky and foggy disaster environments, partial or complete occlusionof elements in the scenario). Although this work only addresses theimplementation of haptic exploration strategies, the proposed Bayesianframework allows the integration of additional sensory sources such asvision (depth, color) and laser to infer the robotic exploration path. Theapproach proposed in this work can be used to complement methodsalready available to explore surfaces using exclusively non-hapticsensory inputs [4–6].The structure of the manuscript and an overview of the Bayesianmodels proposed in this work are presented in Section 1.1.1.1. Problem formulation and approach overviewIn the application scenarios used in this work, the exploration taskis performed on top of a table – a workspace defined by a planarsurface – and using a generic robotic system with manipulationcapability. The internal structure and configuration of the workspaceis unknown a priori to the robotic system. The solution to the hapticexploration task is described in two-dimensional Cartesian space,progressively unfolding a sequence of regions of the workspace to beprobed by the robotic platform during task execution.As in previous reported work, the 2D-Cartesian space is partitionedusing a planar isometric 2D grid (square cells), as represented in Fig. 1b). Each cell vk has a side of length ε and is described by a 2D Cartesianlocation (x,y) expressed in the inertial world referential {}. Thesetesselations of space have been used extensively in robotics as inferencegrids in many applications [9].The methods presented follow the principles and architecture of thehuman somatosensory processing pipeline and human cognition. Aconceptual overview of our solution is presented in Fig. 2; thecorresponding detailed diagram is given in Fig. 3, including a repre-sentation of data flow. Haptic sensory inputs are acquired during thelocal interaction of the robotic exploratory elements with the environ-ment at region vk. Haptic features such as texture, compliance,temperature are extracted from the haptic sensory inputs. Thesefeatures are integrated and used to discriminate the different classesof materials in the workspace. These processes are modelled by theBayesian model πper presented in Section 3.Next in the sensory processing pipeline, the robotic system uses theupdated perceptual representation of the workspace to infer the nextregion that should be explored. The mechanisms involved in thisprocess are implemented by the Bayesian model πtar and described inSection 5. Touch attention is modelled by integrating the following:(cid:129) Stimulus-driven processes – concurrent mechanisms that pro-Fig. 2. Conceptual representation of the action-perception loop [7] involved in thehaptic exploration of surfaces [8]. In this work, the objectives of the task andcorresponding solution is represented in two levels: symbolic and mid-level.mote both exploitation behaviour concerning perceptual represen-tations of stimuli in the form of haptic saliency and shape cues(determined by the Bayesian model πobj, Section 4), and explora-tion behaviours fuelled by spatial distribution of perceptual uncer-tainty and also inhibition-of-return mechanisms.(cid:129) Goal-directed modulation – mechanisms that influence theweights of stimulus-driven processes through top-down influencesinformed by current task objectives.The experimental setup used in this work is described in Section 6.The impact of the integration of the touch attention mechanisms in theaction-perception loop and generalization capability of the explorationstrategies inferred from the proposed Bayesian models are tested insimulation environment, Section 6. The main conclusions of this workand formulation of the main guidelines for future developments of thisapproach are presented in Section 7.1.2. Path planning of the global haptic exploration strategyThe framework conceptually represented in Fig. 2 and detailed inFig. 3 implements a haptic exploration path planning method, whichinfers a series of global via-points in the workspace that should beFig. 1. a) Results from a previous work [3], demonstrating a haptic discontinuity following task: straight line geometry. In this work, the haptic exploration tasks are more challenging:three materials and discontinuities with other geometries than straight lines. b) Illustration of a 2D isometric grid partitioning a real world workspace area. Each cell v has a dimension εand is described by position (x,y) expressed in {}.205R. Martins et al.Neurocomputing 222 (2017) 204–216Fig. 3. Detailed diagram of the architecture of the proposed system. The main contributions of this work are identified in the diagram as main block (local perception of haptic stimulus,recognition of the shapes of discontinuities, progressive determination of the exploration path). The variables of the system are summarised in Table 1.probed by the robotic system.This work does not address the low-level control loop involved inphysical interaction of the fingers with the surface and the ability tomove the fingers along the surface by keeping contact. In other words,the low-level modelling and control of local contact interaction (eg:force, impedance, position control) and processing of haptic sensorydata are not discussed by this work. These processes are implementedin Fig. 3 by the module Low-Level Control and Signal Processing andinner loop labelled Actuation and Sensing Feedback.Our solution assumes that algorithms (dependent of specific roboticdevice and sensing apparatus) implemented by other works (eg: [10])extract different haptic features and control the local movementsduring the haptic exploration of a region vk. The integration betweenthese lower level control models (dashed boxes) and the globalexploration path planning method (bold boxes) proposed by this workis detailed in Fig. 3.2. Related worksThe robotic exploration of surfaces using haptic inputs has been aresearch topic pursued for a long time, with seminal works by [23–25]and [26].A group of approaches described in the literature implementshaptic exploration by attempting to achieve a single categorisation ofsurfaces or objects (Table 2). The exploration is performed locally in aspecific region, considering that it is representative of the whole surfaceby assuming that the latter is either homogeneous or uniform in termsof the haptic features under analysis. The discrimination between thedifferent classes of surfaces is performed by extracting distinct butcomplementary types of haptic features such as surface curvature [11],texture [12,10,13,14], compliance [10,15], stickiness [16] and thermalconductivity [10,17] from the haptic sensory signals. The formalisationof the descriptors of the haptic features depends on the type of roboticplatform and type of sensing apparatus involved in the explorationtask, specifically the modelling of the contact interaction and thecharacteristics of the sensory signals produced during that interaction.However, each type of haptic feature is extracted using the sameexploration movement patterns across the different works.The work presented in this manuscript contributes to this group ofapproaches by introducing a Bayesian model that allows the discrimi-nation different categories of materials through the integration ofcompliance and texture features. The formulation of haptic featuresabstracts the contact interaction models between the exploratoryelement and the surface.A second group of approaches (Table 2), while integrating sensing,perception and local exploration mechanisms similarly to the previousgroup, expands the exploration strategy to large and heterogenoussurfaces in the haptic feature domain under analysis. The globalperceptual map of the surface can be constructed following differentstrategies. In many proposed solutions, the global exploration path isfixed and defined a-priori. For example, in Ref. [18], haptic explorationis performed using pre-defined exploration paths to build a stiffnessmap of biological tissues. As long as the perception of the hapticstimulus of the surface occurs, it does not influence the explorationmovement. In Ref. [19], Braille symbols are explored and recognised bya robotic system. The exploration speed is adjusted depending on therecognition uncertainty, nevertheless the exploration path is also pre-defined.Although exploration strategies defined a-priori can be successfulwhen substantial information about the structure of the environment isavailable, in most of the scenarios identified considering the motivationbehind this work, the structure of the environment is initially unknown206R. Martins et al.Neurocomputing 222 (2017) 204–216Table 2Comparison between the contributions of this work and the related works.StudyApparatusaLocal Haptic PerceptionGlobal Exploration of the workspaceThis Work[11][12][10][13][14][15][16][17][18][19][20][21][22][20]HSHSHSHSHSHSHSHSHSHSHSHSHS, VSHSHSApproachbPDDPPDPPDDDPPPDFeaturescT, COCTCO, T, TCTTCSC, TCCOROCTOROCI, CRApproachdTaskeStrategyfWorkspacegP––––––––DPDPDDM: E, F: E––––––––M: CF: TF:CM: EM: E, F: EFAE––––––––PDPDAEAEAEAEGD:2D––––––––CS:2D––GD:2DGD:2DCS:3Da HS- haptic sensing; VS- visual sensing.b P- probabilistic; D- deterministic.c T- texture; CO- compliance; C- curvature; TC- thermal conductivity; S- stickiness; RO- raw sensory output; CI- contact intensity; CR- contact orientation.d P- probabilistic; D- deterministic.e M: E- mapping edge; M: C - mapping compliance; F- following; F: E- following edge; F: T- following texture; F:C: following curvature.f AC- active exploration; PD- pre-defined exploration path.g GD:2D - bi-dimensional grid; CS:2D- bi-dimensional Cartesian space points; CS:3D- tri-dimensional Cartesian space points.(partially or completely). Thus, the exploration strategy should intro-duce an active behaviour to progressively integrate and analyse thelocal perceptual representation of the environment (perception foraction) and estimate what should be the next global region to exploreand perceive (action for perception), as proposed in Ref. [27]. Activeexploration of a scene represented by a occupancy grid was proposedby [21]. An initial estimation of the scene structure is made usingstereovision data and projected in a 2D occupancy grid. The explora-tion strategy is dependent of that initial representation and hapticinputs (lateral contact/non-contact) are used to confirm and update theoccupancy grid of the map.In other works, the active exploration task is started without anyknowledge about scene structure. For example, [22] proposes a methodto perform active contour following of objects by performing tapmovements using a robotic fingertip equipped with a tactile array.The reaction of the system is formulated based on the contact profilebetween the haptic stimulus and the tactile sensing array and specificdeterministic rules defined beforehand by the human operator. [20]presents a generic formulation of a control framework for differenttypes of tasks that require tactile servoing (eg: tracking a touchedobject, tactile object active exploration). Different behaviours areobtained by adjusting a few matrix parameters and selecting thecorresponding haptic primitives extracted from a tactile array.This work adds to the contributions of this class of approaches byproposing a formulation of Bayesian models implementing touchattention mechanisms involved in the active haptic exploration ofunknown surfaces by generic robotic hands and sensory apparatus.Once this work assumes that the workspace is unknown a-priori to thesystem (blind exploration), the exploration path is adapted actively bythe touch attention mechanisms, as long as the exploration progresses.The definition of the architecture of the Bayesian models follows theprinciples on how humans manage uncertainty to make motor deci-sions from percepts [7], and extends the architecture proposed in aprevious work [3]. The work presented in this manuscript expands thetop-down modulation of information, by integrating an additionalBayesian model in the decision process, representing the influence ofthe shape of the current exploration path (detailed in Section 4). In Ref.[3] the experimental results were focused on testing extensively thecapability of the system to discriminate different type of materials. Inthe current work, a completely new set of experiments is designed totest the selectivity (different types of discontinuities) and robustness(different path shapes) of the touch attention mechanisms during threehaptic discontinuity following tasks. The new experimental design wasalso used to evaluate the contributions of the different types of cuesmodelled by the Bayesian models to the performance of the roboticsystem.3. Local perception of haptic stimulus map3.1. Random variables of the modelThe type of material describing workspace region v is representedby the discrete random variable M v k( , ), defined as follows:Mv k( , )∈ {Material, …,1Material}.10(1)During local exploration of region v of the workspace at timeiteration step k, the robotic system acquires haptic sensory datarepresented by variable h v k( , ). The categories of materials are discrimi-nated according to different properties of texture and compliance,hence haptic sensory inputs h v k( , ) are used to determine the category ofmaterial describing the cell v of the workspace. Haptic sensingmeasurements h v k( , ) are transformed using function g into a compliancecharacterization of the explored surface, and using function f into atexture characterization of the surface. This work considers the samethe work [10]. The texture andoperator functions f and g ofcompliance characteristics of the region v of the workspace are“Texturedescribed by the continuous random variables, Echaracterization of v”, and C“Compliance characterization of v”,respectively, according to the following expressions:≡v k( , )≡v k( , )Ev k( , )f= (hv k( , )),Ev k( , )∈ ,Cv k( , )g= (hv k( , )),Cv k( , )∈ .(2)3.2. Inference of the haptic stimulus categoryThe Bayesian model πper allowing the estimation of surfacematerial given haptic sensory inputs (Fig. 4) was extensively tested inprevious work [3],in which it was used to discriminate betweendifferent classes of materials (the same set of 10 different classes usedin the work presented in Ref. [10], more specifically acrylic, brick,207R. Martins et al.Neurocomputing 222 (2017) 204–216Fig. 5. Representation of P E((vi k, )M(vi k, ),πper)(a)) and P C((vi k, )M(vi k, ),πper)(b)) learnedfor 10 reference materials. Data extracted from [10].3.3. Determination of P E M(v k( , )v k( , ),πper)and P C M(v k( , )v k( , ),πper),)())πv k( , ), σ M(EThe parameters μ M(, σ M()Cprobability, μ M()Cthe Normalof the GaussianEdistributionsfunctions modellingP E M,are estimated during experi-v k( , )mental learning sessions using a maximum-likelihood procedure. Asdescribed in Ref. [10], during the learning period, standard localexploration procedures are performed for each of the n=10 referencematerials.and P C M(v k( , )v k( , )perperπ)E), σ M(EAfter the pre-determined number of standard local explorations,the free parameters μ M(of the Normal ())distributions are determined by calculating the averages μ andstandard deviations σ of E and C for each reference material. Theresulting P E Mand P C M(are represented inFig. 5 a) and b), extracting the data available from the manuscript ofthe work [10]., μ M(C, σ M(Cv k( , )v k( , )v k( , )v k( , )perperππ))()),,4. Recognition of the shape of the global exploration path4.1. Random variables of the modelAs the haptic exploration of the workspace progresses, the explora-tion path is described by the set of regions of the two-dimensionalworkspace grid probed by the robotic system. The shape of theexploration path provides cues that can be recognised by the hapticexploration framework.The category of the shape of the exploration path is represented bydiscrete random variable Rk, defined as follows:Rk∈ {Shape, …,1ShapeΘ}.(4)Fig. 4. Bayesian model πper: “Local perception of haptic stimulus”. a) Graphicalrepresentation. b) Description of the Bayesian program.copper, damp sponge, feather, rough foam, plush toy, silicone, softfoam, wood) with an average recognition rate higher than 90%, evenwhen sensory samples were corrupted with Gaussian white noise.These categories of materials are characterised by different propertiesof texture, compliance and thermal conductivity that were extractedusing BioTac biomimetic tactile sensor raw data (contact intensity,vibration, heat flow). In our work, we only consider texture andcompliance properties of the materials.CM,v k( , )The conditional independence relations between random variablesE,( , ) are expressed in Fig. 4a). Based on these assumptions,v kv k( , )the joint probability distribution function P Eisdecomposed as described in Fig. 4b), with respective parametric forms.the probability distribution functionAtP M edescribing the probability of the surface at vcorresponding to each material category is inferred using the observeddata e( , ) extracted from the samples acquired by the sensoryv kapparatus of the robotic system:each timeπcv k( , )step,)M πv k( , ),v k( , ),v k( , )c,v k( , )v k( , )v k( , )Cperper()(,,⎛⎜⎝,cv k( , ),πper) =P M ev k( , )(v k( , )(P c Mv k( , )P e Mv k( , ),v k( , )πperv k( , )).π,perP M().v k( , )⎞⎟⎠,πper)(⎛⎜⎝∑Mv k( , )(P c Mv k( , )P e Mv k( , ),v k( , )π(perv k( , )).π,perP M().v k( , )⎞⎟⎠,πper)Each class of shape described by discrete random variable Rk isassociated with a template, represented by a set of points templatei,(3)∀iΘ∈{1, …, }〈“Shapei”,templatei〉.(5)This work assumes that the robotic system is able to recognize208R. Martins et al.Neurocomputing 222 (2017) 204–216Θ = 2 categories of shapes: a rectangle and a triangle, respectively.through the following equation:(ok)−1The sequence of regions of the workspace explored by the roboticsystem until time step k( − 1) is described by the set of workspacelocations  o o, …,,(Section 5). The categorisation process con-10)sists of establishing a match between the points−1explored by the robotic system until time step k( − 1) and each of thetemplates templatei, representative of each category of structure ofdiscontinuity. The normalised matching error between each templateand the current exploration path is described by the continuousrandom variable Li, defined as follows: o o, …,,10ok([iL Υ,i] =fICP(( o o, …,,10ok),−1templatei),iL∈ [0, 1](6)The matching between the two sets of points  o o, …,,10−1 andtemplatei is determined using the Iterative Closest Point (ICP) method[28], as described in Eq. (6).ok)(Besides matching error Li, the ICP function fICP returns theestimation of the geometrical transformation Υi between the two setsof points. This transformation can be used to determine a new set ofpoints template′i which results from the registration of the templateipoints in the structure described by the set of points  o o, …,,10)−1 .ok(1P R l, …,(k kΘlk,πobj) =1P l R πk(,1P l R πkobj,k(k∑Rk). ….obj,(ΘP l R πobjkkΘP l R π,)… (kk).obj)objP R π(kP R π(k)obj)(8)4.3. Determination of P l R π(,k)objikThe probability distribution functions P l R πobj are described bybeta probability distribution functions L with the constant parameters. All Θ probability distribution functions areα = 1.0Lassumed identical.and β = 4.5L)(,kikk,,((The typical profile ofthe probability distribution functionis represented in Fig. 8b). The profile proposed foriP l R π)objkiP l R π)obj attributes higher probabilities to lower levels of normal-kised matching errors lik.This promotes the selection of categories of the structure Rk that have atemplate similar to the current exploration path  o o, …,,10k and lower probabilities to higher values of li)−1 .ok(kThis relation can be described by the geometrical transformationrepresented in the following equation,5. Integration of touch attention mechanisms in theinference of the global exploration path(7)5.1. Random variables of the model′ = .Υ templatetemplateiii,as used in Section 5.4.2. Inference of category of shapeΘL R,kkThe graphical representation of Bayesian model πobj presented inFig. 6 a) expresses the conditional independence relations between1random variables L. According to these relations, the joint, …,k1probability distribution function P Lcan be factored as, …,)(kpresented in Fig. 6 b). The probability distribution function followed byeach of those factors is also presented in Fig. 6 b).step,the probability distribution functionis inferred using the Bayesian program of Fig. 6each timeπobjAt1P R l, …,(k kL R π,ΘlkΘkobj),kAfter the local exploration of the region v of the workspace isconcluded, the perceptual representation of the workspace is updatedwith the sensory measurements acquired at v (update mechanismspresented in Section 3), and the robotic system has to decide whichregion v of the workspace grid should be explored next (path planningof global exploration strategy).The next exploration target is represented by the discrete randomvariable Ok, defined asOk1v v∈ { ,2,v3, …,vθ},(9)in which θ is the total number of cells in the grid representation of theworkspace, and vi is a compact representation of the cell identifier.Robotic platforms have been endowed with attentional mechanismsimplemented in different sensory domains in order to deal with sensoryoverload, prioritisation and dynamic environments [29].)(ok o o, …,,10The sequence of workspace regions−1 previouslyexplored by robotic system, can provide cues about the shape of theis being followed and indirectly influence thediscontinuity thatestimation of ok . The cues are provided by matching the currentstructure of the exploration path, with representations of typical shapesstored in the memory of the robotic system. As presented in Section5.3, unexplored regions of the workspace that are coincident with thestructure of the shape templates will be more likely to be explored.The selection of Ok is also conditioned by inhibition-of-returnmechanisms. The inhibition levelimposed this mechanism to theoverall attention process is implemented by the continuous random“Inhibition level for cell v” as follows:variable I=v k( , )Iv k( , )= 1 −Θdα−1d(1 − )1−β,Iv k( , )∈ [0, 1](10)Due to the characteristics of the haptic exploration procedurespresented in Section 1, at time step k + 1 the inhibition-of-returnprocess promotes the exploration of regions of the workspace differentfrom the current position of the end-effector of the robotic system(ok−1), therefore avoiding deadlocks. However, simultaneously, theinhibition-of-return process inhibits the exploration of regions toodistant from ok−1, to avoid breaks during the discontinuity followingtask. The inhibition levels I v k( , ) for each cell v are defined in Eq. (10),considering α = 1.01 and β = 9 (corresponding plot presented in Fig. 8(a)). Parameter d is given by d= /k max, where dk expresses theEuclidean distance between ok and ok−1, and dmax is a constantrepresenting the maximum possible distance between ok and ok−1 ford dFig. 6. Bayesian model πobj: “Recognition of the shapes of discontinuities.”. a)Graphical representation. b) Description of the Bayesian program.209R. Martins et al.Neurocomputing 222 (2017) 204–216d( )the workspace dimensions. Θ is a normalisation constant. The values ofIindicating that the inhibition-v k( , )of-return mechanism applies no inhibition to cell v, and I= 1signalling full inhibition of cell v.range from 0 to 1, with I= 0v k( , )v k( , )The selection of the region Ok of the workspace is also dependenton mechanisms that prevent returning to regions already explored andperceived with low uncertainty. In a nutshell, these mechanisms areformulated to promote the “curiosity”, and are represented by thefor cell v”,continuous random variable U=v k( , )described as“Uncertainty levelUv k( , )=max(M(v k( , )M()v k( , ),))Uv k( , )∈ [0, 1],(11)in which the operator  determines the information entropy [30] ofthe discrete random variable M v k( , ).Another factor conditioning the determination of Ok is the saliencyof the haptic stimulus for region v as comparing to its surroundings.Besides depending on the perceived haptic stimulus M v k( , ) map, theformulation of the saliency of haptic stimuli is also modulated by thecurrent objectives of the exploration task. The objectives of the taskbeing executed by the robotic platform are represented by the discreterandom variable T = “Task objective.”, given that T. Duringan experimental run the value of T=t is considered constant through-out. Φ expresses the total number of different tasks that can beexecuted by the robotic platform.T∈ { , …,1T}ΦBased on these considerations, the saliency of the haptic stimulus atv is denoted by continuous random variable S v k( , ), and is dependent onthe class of tasks T=“Search and follow of discontinuities betweenregions of surfaces with Materiala and Materialb.”. S v k( , ) is related by asoft evidence relation with the perceived haptic stimulus M v k( , ) char-acterization of the workspace (detailed description in Ref. [3]) given bymax(Sv k( , )=sy,sxsnorm,sz),Sv k( , )∈ [0, 1](12),=sxd( )sobelxThe parameterssareydetermined using a 3 × 3 edge detector Gsobel (3 × 3 kernel around v)following an approach described in Refs. [3,31]. High values of S v k( , )correspond to regions around v expressing a haptic discontinuitybetween Materiala and Materialb.andsobelysobelzd( )d( )==sz5.2. Inference of the next exploration targetFig. 7. Bayesianl model πtar:“Selection of the next exploration target”. a) Graphicalrepresentation. b) Description of the Bayesian program.Based on the conditional independence relations between randomvariables Ok, I v k( , ), U v k( , ), R Skv k( , ), T, presented in Fig. 7 a), the jointprobability distribution function P O T SUforthis model πtar, is decomposed as summarised in Fig. 7b), includingparametric forms corresponding to each factor. The final estimate forthe next exploration target ok is given using a Maximum a Posteriori(MAP) decision rule, given a specific task T=t, as followsR πkIv k( , ),v k( , ),v k( , )tar(),,,kok= arg maxokP O t sk(,v k( , ),iv k( , ),uv k( , ),Rk,πtar) ⇔ = arg maxokok⎛⎜⎜⎜⎝∑RkP t π(P s(tarv k( , )).O πP i,().tarkv k( , )O t πP u().,,tarP R O π,(kkktarv k( , ))P O π(kO π,k).tar).tar⎞⎟⎟⎟⎠(13)The determination ofthe probability distribution functions)in-, P R O πktartar)(),kv k( , )O T π,P SO π, P I,((kvolved in Eq. (13) is described in detail next., P U(O π,kv k( , )v k( , )tartar),k()Utartartar))v k( , )v k( , )v k( , )O π,kO π,kO π,kFollowing an analogous approach, P Uis represented in Fig. 8b). The selected profile forP I(attributes higher probabilities to lower levels of I v k( , )P I(and lower probabilities to higher values of I v k( , ) in order to promote theselection of regions of the workspace with low values of inhibition level.is described by abeta probability distribution function U (Fig. 8b)) with the constantparameters α = 4attributes higher prob-ability values to regions of the workspace perceived with higheruncertainty U v k( , ), promoting the curiosity of the system.P S,(is described by a beta probability distribution func-tion R defined by α = 3and β = 1(Fig. 8 b)), assigning higherRprobability values to workspace regions v with higher values of saliencyS v k( , ), promoting the exploration of regions of the workspace withrelevant haptic stimulus for the task under execution.The probability distribution function P R O π)is defined as aand β = 1U(Gaussian Mixture Model (GMM), as followsO T π,. P U(O π,kv k( , )v k( , )tartartar))R,kkk5.3. Determination of P S(, P R O πP U(kO π,kv k( , )tar(),kv k( , ))tarO T π,,ktar), P I(v k( , )O π,ktar),P R( = “kObject O π”|j,ktar) =∑′jtemplatei∈w g O μ Σk(.,iii)(14)As presented in Fig. 7 b), P I(is described by a betav k( , )probability distribution function I characterised by the constants. The profile of the probability distribution functionα = 1Iand β = 2.5IO π,ktar)The Gaussians gi of the GMM are centred at the locations μi of theworkspace, with a covariance matrix Σ. Assuming a 2-D structure of theworkspace, each Gaussian function gi is defined as follows:210R. Martins et al.Neurocomputing 222 (2017) 204–216WlWu, Y = 0 mX = 0.30 m. Each cell (square) has a sidedimension of ε = 0.01 m. This work considers that all the regions of theworkspace are reachable by a robotic exploratory element., Y = 0.60 mWuAs detailed previously in Section 1.2, this work does not address thelow-level (motor and sensing) controlloop involved in physicalinteraction between robotic fingers and surface. In the computationalsimulation, the sensory features modelling the haptic properties,texture (E v k( , )) and compliance (C v k( , )), of materials Material7,Material8, Material10, were extracted from a previous work [10], asdetailed in Section 3.6.2. Autonomous exploration of the workspaceThis work assumes that at each time iteration step k of the systemillustrated in Fig. 3, an exploratory element of a robotic hand probes aworkspace region v. The sensory samples modelling texture e v k( , ) andcompliance c v k( , ) are artificially synthesised from the respective prob-ability distribution functions P E),v k( , )given the known ground truth material m v k( , ) for that region of theworkspace, as defined in Fig. 9. Following the architecture of thesensory processing pipeline represented in Fig. 3, the sensory featuressamples e v k( , ), c v k( , ) are integrated by the Bayesian models to infer thenext region (via point) of the workspace that should be probed by arobotic system.and P Cv k( , )v k( , )v k( , )mmperperππ((),,In this scenario, the exploratory element of the robotic systeminitialized (k=0) at random locations ofthe bi-dimensional gridrepresenting the workspace region. The full-list of initialization loca-tions for the 100 runs, is available online at http://www.rmartins.net/j2016a. Unlike in previous work [3], these cells of the grid are not onlylocated on a haptic discontinuity between the different materials of thescenario; they can be located on homogeneous regions. This provides acompletely blind and unbiased initialization of the exploration task foreach exploration run.During each exploration task, the workspace presented in the Fig. 9was explored during 100 runs (100 different initial locations of theexploratory element). For each run, the exploration procedures lasts100 iterations (emulating time steps in realistic conditions) k = 0…99.6.2.1. Exploration tasksTo evaluate the specificity and robustness of the Bayesian modelsimplementing the touch attention mechanisms proposed in this work,the autonomous exploration of the workspace was performed usingthree different tasks (T1, T2,T3). The objectives are the followingT1=“search and follow of discontinuities between Material7 andremaining materials”; T2=“search and follow of discontinuities betweenMaterial8 and remaining materials”; T3=“search and follow of dis-continuities between Material10 and remaining materials”;.O π,ktar),(15)O π,ktar), P U(v k( , )Fig. 8. Graphical representation of: a) I v k( , ). b) P I(P S(O T π,i, P l R πkobj .)v k( , )tar)(kk,,v k( , )g O μ Σki(,i) =1(3/2)π2|Σ|− 12expO μ Σ( − )ki−1O μ( − )ki.The centers μi of the Gaussians correspond to the points belongingj, which are determined as presented in detail into the set Template′Section 4.6. Experimental results6.1. Computational simulationThe path planning method proposed by this work, supporting theglobal haptic exploration strategy, was simulated computationallyusing MATLAB. The simulation scenario consists on a planar 2Dprobabilistic grid representing the workspace placed in front of ahypothetical robotic platform, as represented in Fig. 9. Three differentmaterials were used: wood (Material10, brown cells),silicone(Material8, blue cells) and flush (Material7, green cells). The spatialdistribution of the three materials intends to simulate an hypotheticalreal world scenario shown in Fig. 9. The workspace grid has therespectively X = 0 mfollowing lower and upper dimensions,Wl2116.2.2. Performance metricAlthough the internal structure and configuration of the hapticstimulus disposed in the workspace is unknown a-priori to the roboticsystem, the ground truth describing the target locations (grid cells) ofthe workspace that should be probed by the robotic platform duringtask execution can be defined by a human operator for benchmarking2. Thepurposes, and is denoted as = { ,1set of workspace regions actually probed by the robotic platform duringtask execution, on the other hand, is denoted as v v vv= { ,, …, }k,321v = ( ,ib b b2b, …, }l,3b = ( ,x yx y) ∈) ∈2.,,iThe performance of the autonomous execution of the task by therobotic platform during an experimental run can be evaluated by thefollowing error metric:l∑Γ=i=1∥bi−vnearest∥,given that ∀v∈i∃vnearest:∥bi−vnearest∥ ≤ ∥biv− ∥,i(16)R. Martins et al.Neurocomputing 222 (2017) 204–216Fig. 9. Scenario: a) Real world representation of the scenario. b) Schematic representation of configuration of the haptic stimulus placed in the workspace. The materials wood(Material10), silicone (Material8) and flush (Material7) are represented in brown, blue, green respectively. c) Representation of the workspace in the virtual environment. Tasks: a)Ground truth exploration path for the respective task. b)-f) Heat map of the exploration paths after 100 exploration runs with a duration of 100 time iterations each. Differentexploration behaviours by integrating different configurations of the Bayesian model πtar: b) full-model c) removing shape cues Rk d) removing haptic saliency S v k( , ) e) removinginhibition-of-return mechanisms I v k( , ) f) removing uncertainty cues U v k( , ). (For interpretation of the references to color in this figure legend, the reader is referred to the web version ofthis article.)212R. Martins et al.Neurocomputing 222 (2017) 204–216where ∥…∥ represents the Euclidean distance operator. This metricdetermines the total Euclidean distance between each ground truthpoint and the nearest point belonging the exploration path executed bythe robotic platform. According to this approach, better autonomousexploration strategies provide lower values of Γ.6.3. Discussion of the experimental resultsinhibition-of-return) ofThe impact of the different components (discontinuity shape cues,uncertainty, haptic saliency,the Bayesianmodels implementing the touch attention mechanisms was evaluatedby comparing the exploration performance after discarding specificcomponents of the Bayesian model πtar: shape cues Rk, haptic saliencyS v k( , ), inhibition-of-return mechanisms I v k( , ), uncertainty cues U v k( , ). Theinfluence of those components was discarded by assuming that each ofthose random variables is described by a uniform probability distribu-tion throughout the respective experimental runs.Animated representations (time lapse) of the probability distribu-tion functions during 100 time iterations involved in the progressiveinference by the Bayesian model πtar of the workspace region thatshould be explored next, are available online at http://www.rmartins.net/j2016a, and an example is illustrated in Fig. 11.The ground truth exploration paths for the objectives of theexploration tasks T1, T2 and T3 are illustrated in Fig. 9 representingthe borders of the Material7, Material8 and Material10 with theremaining materials in the workspace, respectively.By performing a qualitative comparison between the ground truthexploration paths and the heat maps resulting from the explorationbehaviour inferred by the full Bayesian model πtar in the Fig. 9, onefinds that there is a high correspondence between the spatial structureof the most explored regions and the spatial structure of the groundtruth exploration paths. The performance metric presented in Fig. 10also shows that the full model always provides a good result. The touchattention mechanisms implemented by the Bayesian model πtar havepromoted the exploration of regions corresponding to the disconti-nuities described in the objectives of the tasks T1, T2, T3, ignoring othertypes of haptic discontinuities (Fig. 11).The structural correspondence is higher for T1 and T2. This betterperformance is justified by the better perceptual discrimination cap-ability of this system concerning Material7 and Material8 relatively toMaterial10 (extensive study in Ref. [3]).The analysis of the results of discarding the influence of specificcomponents of the Bayesian model πtar (Fig. 9), shows that thedegradation of performance of the exploration behaviour is significant(Fig. 10) when the effect of the haptic saliency S v k( , ) is not considered.This causes the system to explore randomly the workspace, not takinginto consideration any information about task relevance concerning thesensed haptic stimulus.the perceptualrepresentation ofthe information aboutBy neutralising the integration oftheuncertainty ofthe workspace(Fig. 9), the robotic system fails to have an exploration strategy thatproduces results similar to the ground truth. Although the Bayesianmodel πtar implements inhibition-of-return mechanisms, their effect istransient, and therefore, after some time elapses, the system tends toreturn to the same regions of the workspace that have been exploredpreviously and were perceived with low uncertainty, thus providing ahigh saliency score for the task being executed. The plot of theperformance metric Γ for those conditions, shows that the degradationof performance of the exploration behaviour is considerable (Fig. 10).By disabling the integration of the effects of the inhibition-of-returnmechanisms, exploration task execution performance is less degraded.The plots of the Γ metric, presented in Fig. 10, support this evidence byshowing a performance of the system at the same level as the full-model condition. The removal of the transient effect of the inhibition-of-return mechanisms is compensated by the integration of informa-tion of mechanisms related with the uncertainty of the perceptualFig. 10. Temporal evolution (from k=0 to k=100 ) of mean value (average for the 100runs; shaded colors represent SEM: standard error of mean ) of performance metric Γ byintegrating different configurations of Bayesian model πtar: full-model, removing shapecues Rk, removing haptic saliency S v k( , ), removing inhibition-of-return mechanisms I v k( , ),removing uncertainty cues U v k( , ). a) Task T1. b) Task T2. c) Task T3.213R. Martins et al.Neurocomputing 222 (2017) 204–216Fig. 11. Representation of the P I(v k( , )O π,ktar), P S(v k( , )O T π,,ktar), P U(v k( , )O π,ktar), P R O πk(k,tar , P O t r()k,,v k( , )i,v k( , )uv k( , ),r π,ktar)probability distribution functions and theexploration behaviour during the execution of the task T2 search and follow of discontinuities between Material8 and remaining materials, run 18. Dark colors represent lowervalues. Light colors represent higher values. Animated versions of this type of representations for autonomous exploration tasks T1,T2 and T3, are available on-line www.rmartins.net/j2016a.214R. Martins et al.Neurocomputing 222 (2017) 204–216Table 1Summary of the relevant variables of this work.VariableDescriptionDomainvkRktemplateiLikM v k( , )E v k( , )C v k( , )h v k( , )OkI v k( , )U v k( , )S v k( , )TCell of the workspace grid.Time / exploration iteration.Category of the structure of thediscontinuity.Set of points defining the template of eachcategory of structure.Matching error between the explorationpath and templatei.Material category of vTexture characterization of v.Compliance characterization of v.Raw haptic sensing data acquired on v.Next workspace region to be explored.Inhibition level for cell v.Uncertainty level for cell v.Saliency of the perceived haptic stimulusin region v.Objective of the haptic exploration task.”, “Shape2”}20{“Shape12[0,1]Material}10Material, …,{1 *nv[0, 1][0, 1][0, 1]T T T}{ ,321,representation of the workspace, which naturally correspond to lessexplored regions, if all surfaces in the workspace remain static/rigid.These regions tend to be avoided by the system, even without theinfluence of the inhibition-of-return mechanisms. The inhibition-of-return mechanisms may play a more relevant role in more ambiguousscenarios made of materials that the system can only perceive with highuncertainty, even after considerable exploration.Discarding the effects provided by the integration of shape cues(Fig. 9), does not have a strong influence in the performance of theexploration behaviour of the system (Fig. 10). The weak contribution ofthe shape cues oftheperformance of the robotic system was caused by the low number ofshape primitives recognised in this work (only two: rectangle andtriangle) and by the high number of points that were used to describeeach of the templates (around 50 points).the discontinuity to the improvement of7. Conclusions and future workThe integration of touch attention mechanisms in the exploration ofsurfaces by robotic hands proved to be effective to search and followhaptic discontinuities based on noisy sensory data describing unknownscenes. The updated perceptual representation of the workspace,provided by the Bayesian model πper, together with shape cues aboutthe structure of the discontinuity being followed provided by theBayesian model πobj (extension of previous work [3]), are integratedby the Bayesian model πtar to perform perceptual inference and drivethe decision process to determine the region that should be explored inthe subsequent time step.The Bayesian models were tested in a simulated scenario includingthree different materials during three different haptic exploration tasks.The results presented in Section 6.2, have demonstrated that theproposed approach provides the robotic system with a useful frame-work to define and generalise exploration behaviours. As in [22], thesystem was able to deal with severe changes in the slope of thediscontinuities. In all the tasks, the robotic system was able to followhaptic discontinuities with progressive inversions in the slope of thediscontinuity, what clearly demonstrates the generalization capabilityof the proposed approach. The emergent behaviour displayed by thesystem offers an improvement on the results presented in Ref. [22].Testing the system with slope variations in discontinuities other thanright angles (90 degrees) was suggested by [22] as a relevant futurecourse of work. The touch attention mechanisms proposed in this workalso showed high specificity. The robotic system followed the hapticdiscontinuities between the materials of interest for each task, ignoringother haptic discontinuities.According with the results presented in Section 6.2, the perfor-mance of the robotic system during the haptic exploration tasks isheavily dependent on the integration by the Bayesian model πtar ofinformation about the haptic saliency S v k( , ) and uncertainty U v k( , ) of theperceptual representation of the workspace. The formulation of thecontributions of the inhibition-of-return mechanisms I v k( , ) and shapecues of the haptic discontinuities Rk is going to be studied extensivelyin future work, in order to improve and optimise the contributions ofthese components of the Bayesian model to the performance of therobotic system. In future developments of this work, elementary shapeprimitives should be recognised by the system and alternativesmethods to ICP should be tested. This will allow the system torecognize earlier the tendencies in the shape of the discontinuity,matching the current exploration path with the shape templates morerobustly (noise, scale, orientation). The future developments of thisthe automaticwork will also investigate the implementation ofcomputational optimization of the parameters defining the profile ofBeta distribution functions. Currently, the selection of parameters ismade empirically, testing different sets of values and analysing thebehaviour of the system (Table 1).In this work, the space used to formulate the solution of the globalhaptic exploration path planning consists in a 2D grid. The nextdevelopments of the proposed approach will study the extension ofthis space to a 3D grid. The operators and functions defined in 2Dspace during the formulation of the Bayesian models can be easilyadjusted to 3D spaces (eg: exploration path matching with shapetemples; Sobel operators involved in the formulation of haptic saliency;assignment of inhibition levels).AcknowledgementsThis research work was financially supported by an individual Ph.D.scholarship (SFRH/BD/65990/2009)funded by the PortugueseScience Agency FCT - Fundação para a Ciência e a Tecnologia(Foundation for Science and Technology).References[1] R.S. Johansson, J.R. Flanagan, Coding and use of tactile signals from the fingertipsin object manipulation tasks, Nat. Rev. Neurosci. 10 (2009) 345–359.[2] S.J. Lederman, The intelligent hand an experimental approach to human objectrecognition and implications for robotics and AI, AI Mag. 15 (1994) 774–785.[3] R. Martins, J.F. Ferreira, J. Dias, Touch attention bayesian models for roboticactive haptic exploration of heterogeneous surfaces, in: Proceedings of 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2014),IEEE, Chicago, USA, 2014, pp. 1208–1215. http://dx.doi.org/10.1109/IROS.2014.6942711 URL 〈http://rmartins.net/iros2014a〉.[4] F. Meng, B. Guo, M. Song, X. Zhang, Image fusion with saliency map and interestpoints, Neurocomputing 177 (2016) 1–8.[5] S.-W. Ban, M. Lee, Selective attention-based novelty scene detection in dynamicenvironments, Neurocomputing 69 (1315) (2006) 1723–1727 [blind SourceSeparation and Independent Component AnalysisSelected papers from the {ICA][2004 meeting, Granada, SpainBlind Source Separation and IndependentComponent Analysis].[6] R.B. Gomes, B.M. de Carvalho, L.M.G. Gonalves, Visual attention guided featuresselection with foveated images, Neurocomputing 120 (2013) 34–44 [image FeatureDetection and Description].[7] M.O. Ernst, H.H. Bulthoff, Merging the senses into a robust percept, Trends Cogn.Sci. 8 (2004) 162–169.[8] E. Wacker, Tactile feature processing and attentional modulation in the humansomatosensory system, [Ph.D. thesis] TU Berlin.[9] J.F. Ferreira, J. Dias, Probabilistic Approaches to Robotic Perception, Vol. 91 ofSpringer Tracts in Advanced Robotics, Springer, 2014.[10] D. Xu, G.E. Loeb, J.A. Fishel, Tactile identification of objects using bayesianexploration, in: ICRA 2013, 2013.[11] A.M. Okamura, M.R. Cutkosky, Feature detection for haptic exploration withrobotic fingers, Int. J. Robot. Res. 20 (12) (2001) 925–938.[12] C.M. Oddo, M. Controzzi, L. Beccai, C. Cipriani, M.C. Carrozza, Roughnessencoding for discrimination of surfaces in artificial active-touch, IEEE Trans.Robot. 27 (3) (2011) 522–533.[13] J.A. Fishel, G.E. Loeb, Bayesian exploration for intelligent identification of textures,Frontiers Neurorobotics 6.[14] D. Chathuranga, V. Ho, S. Hirai, Investigation of a biomimetic fingertip’s ability to215R. Martins et al.Neurocomputing 222 (2017) 204–216João Filipe Ferreira received the B.Sc., M.Sc., and Ph.D.degrees in electrical engineering and computers from theUniversity of Coimbra (UC), in 2000, 2005, and 2011,respectively. He has been an Invited Assistant Professor atthe UC since 2011. He has also been a researcher at theInstitute of Systems and Robotics, UC, since 1999 (inte-grated member since 2011), where he is currently managerof the Artificial Perception for Intelligent Robots andSystems (AP4ISR) team. His main research interests areartificial cognition, probabilistic modelling, and autono-focusing in particular in human-robotmous systems,interaction. Dr. Ferreira is a member ofthe IEEERobotics and Automation Society (RAS) since 2012 (mem-ber of the IEEE RAS Technical Committee on Cognitive Robotics since 2015), the IEEELife Sciences Community since 2013, the IEEE Systems, Man, and Cybernetics Societysince 2015 and the IEEE Computational Intelligence Society since 2015.Miguel de Sá e Sousa Castelo-Branco received theM.D. degree from the University of Coimbra (UC), Portugalin 1991, and the Ph.D. degree from the Max-PlanckInstitute fur Hirn- forschung, Frankfurt, and the UC, in1998. He is currently an Assistant Professor at the UC. Heis also the Director of IBILI-UC (Institute for BiomedicalResearch on Light and Image) and ICNAS-UC (Institute ofNuclear Sciences Applied to Health). He has made con-tributions in the fields of ophthalmology, neurology, visualneuroscience, human psychophysics, functional brain ima-ging and human and animal neurophysiology.Jorge Dias received the Ph.D. degree in electrical en-gineering with specialization in control and instrumenta-tion from the University of Coimbra (UC) in 1994. He holdshis research activities at the Institute of Systems andRobotics (ISR), UC, and also at the Khalifa University ofScience, Technology and Research , UAE. His currentresearch areas are robot vision and autonomous robotics,with activities and contributions in these fields since 1984.He has been the scientific coordinator in several projectssupported by EU and by the Portuguese Foundation forScience and Technology (FCT).discriminate fabrics based on surface textures, in: International ConferenceAdvanced Intelligent Mechatronics, 2013, pp. 1667–1674. http://dx.doi.org/10.1109/AIM.2013.6584336.[15] R. Martins, D. Faria, J. Dias, Representation framework of perceived objectsoftness characteristics for active robotic hand exploration, in: HRI2012, USA,2012.[16] H. Liu, X. Song, J. Bimbo, L. Seneviratne, K. Althoefer, Surface material recognitionthrough haptic exploration using an intelligent contact sensing finger, in: IROS2012, IEEE, 2012, pp. 52–57.[17] F. Castelli, An integrated tactile-thermal robot sensor with capacitive tactile array,IEEE T. Ind. Appl. 38 (1) (2002) 85–90. http://dx.doi.org/10.1109/28.980361.[18] H. Liu, D.P. Noonan, B.J. Challacombe, P. Dasgupta, L.D. Seneviratne,K. Althoefer, Rolling mechanical imaging for tissue abnormality localization duringminimally invasive surgery, IEEE Trans. Biomed. Eng. 57 (2) (2010) 404–414.[19] L.L. Bologna, J. Pinoteau, J.-B. Passot, J.A. Garrido, J. Vogel, E.R. Vidal, A. Arleo,A closed-loop neurobotic system for fine touch sensing, Journal of NeuralEngineering 10 (4).[20] Q. Li, C. Schurmann, R. Haschke, H. Ritter, A control framework for tactileservoing, in: Proceedings of RSS, 2013.[21] J. Bohg, M. Johnson-Roberson, M. Bjoandrkman, D. Kragic, Strategies for multi-modal scene exploration, in: Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International Conference on, 2010, pp. 4509 –4515.[22] U. Martinez-Hernandez, T. Dodd, L. Natale, G. Metta, T. Prescott, N. Lepora, Activecontour following to explore object shape with robot touch, in: World Haptics 2013,2013, pp. 341–346.[23] L.D. Harmon, Automated tactile sensing, Int. J. Robot. Res. 1 (2) (1982) 3–32.[24] R.L. Klatzky, S.J. Lederman, V.A. Metzger, Identifying objects by touch an expertsystem, Percept. Psychophys. 37 (4) (1985) 299–302.[25] P. Dario, D. De Rossi, Tactile sensors and the gripping challenge increasing theperformance of sensors over a wide range of force is a first step toward robotry thatcan hold and manipulate objects as humans do, IEEE Spectr. 22 (8) (1985) 46–53.http://dx.doi.org/10.1109/MSPEC.1985.6370785.[26] H.R. Nicholls, M.H. Lee, A survey of robot tactile sensing technology, Int. J. Robot.Res. 8 (3) (1989) 3–30.[27] R.S. Dahiya, G. Metta, M. Valle, G. Sandini, Tactile sensing - from humans tohumanoids, IEEE Trans. Robot. 26 (1) (2010) 1–20.[28] Z. Zhang, Iterative point matching for registration of free-form curves and surfaces,International journal of computer vision.[29] J.F. Ferreira, J. Dias, Attentional mechanisms for socially interactive robots - asurvey, IEEE Trans. Auton. Ment. Dev., Spec. Issue Behav. Underst. Dev. Robot.(2014) 1–18 [in press].[30] C.E. Shannon, A mathematical theory of communication, SIGMOBILE Mob.Comput. Commun. Rev. 5 (1) (2001) 3–55.[31] P. Bhattacharya, D. Wild, A new edge detector for gray volumetric data, Computersin Biology and Medicine, 26(4).Ricardo Martins received his MSc degree in BiomedicalEngineering from the University of Coimbra (UC) in 2008.Since 2010, Ricardo Martins is a PhD student at Institute ofSystems and Robotics, UC. His PhD research interests arerelated with the modelling of the (haptic) artificial percep-tion and action mechanisms involved in the dexterousrobotic manipulation and exploration of objects and sur-faces, inspired by the Human cognition and perceptionprocesses.216