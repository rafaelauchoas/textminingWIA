Artificial Intelligence 244 (2017) 48–69Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSkypattern mining: From pattern condensed representations to dynamic constraint satisfaction problemsWilly Ugarte a, Patrice Boizumault a, Bruno Crémilleux a,∗Samir Loudni a, Marc Plantevit c, Chedy Raïssi d, Arnaud Soulet ea GREYC (CNRS UMR 6072), University of Caen, F-14032 Caen, Franceb CERMN (UPRES EA 4258 – FR CNRS 3038 INC3M), University of Caen, F-14032 Caen, Francec Université de Lyon, CNRS, Université Lyon 1, LIRIS (UMR5205), F-69622, Franced INRIA Nancy Grand-Est, Francee LI (EA 2101), Université François Rabelais de Tours, F-41029 Blois, France, Alban Lepailleur b, a r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 7 April 2015Accepted 14 April 2015Available online 28 April 2015Keywords:SkypatternsPattern miningConstraint programmingDynamic CSPUser preferencesData mining is the study of how to extract information from data and express it as useful knowledge. One of its most important subfields, pattern mining, involves searching and enumerating interesting patterns in data. Various aspects of pattern mining are studied in the theory of computation and statistics. In the last decade, the pattern mining community has witnessed a sharp shift from efficiency-based approaches to methods which can extract more meaningful patterns. Recently, new methods adapting results from studies of economic efficiency and multi-criteria decision analyses such as Pareto efficiency, or skylines, have been studied. Within pattern mining, this novel line of research allows the easy expression of preferences according to a dominance relation. This approach is useful from a user-preference point of view and tends to promote the use of pattern mining algorithms for non-experts. We present a significant extension of our previous work [1,2] on the discovery of skyline patterns (or “skypatterns”) based on the theoretical relationships with condensed representations of patterns. We show how these relationships facilitate the computation of skypatterns and we exploit them to propose a flexible and efficient approach to mine skypatterns using a dynamic constraint satisfaction problems (CSP) framework.We present a unified methodology of our different approaches towards the same goal. This work is supported by an extensive experimental study allowing us to illustrate the strengths and weaknesses of each approach.© 2015 Elsevier B.V. All rights reserved.1. IntroductionThe process of extracting useful patterns from data, called pattern mining, is an important subfield of data mining, and has been used in a wide range of applications and domains such as bioinformatics [3], chemoinformatics [4], social network analysis [5], web mining [6] and network intrusion detection [7]. Since the key papers of Agrawal et al. [8], Mannila et al. [9], a considerable number of patterns, such as itemsets, strings, sequences, trees and graphs, have been studied and * Corresponding author.E-mail address: bruno.cremilleux@unicaen.fr (B. Crémilleux).http://dx.doi.org/10.1016/j.artint.2015.04.0030004-3702/© 2015 Elsevier B.V. All rights reserved.W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6949used in real-world applications. Nowadays, many pattern extraction problems like subgroup discovery [10], discriminative pattern mining [11], and tiling [12] are understood from both theoretical and computational perspectives.Most existing pattern mining approaches enumerate patterns with respect to a given set of constraints that range from simple to complex. For instance, given a transaction database, a well-known pattern mining task is to enumerate all itemsets (i.e. sets of items) that appear in at least s transactions. However, the output of pattern mining operations can be extremely large even for moderately sized datasets. For instance, in the worst case, the number of frequent itemsets is exponential in the number of the items in the dataset.So far, the community has expended much effort on developing sophisticated algorithms which push the constraints deep into the mining process [13]. But also in on compression (i.e. reduction) techniques to limit the number of output patterns depending on the application contexts [14–16]. The pattern mining community, however, has paid less attention to combining mining constraints. In practice, many constraints entail choosing threshold values such as the well-used minimal frequency. This notion of “thresholding” has serious drawbacks. Unless specific domain knowledge is available, the choice is often arbitrary and may lead to a very large number of extracted patterns which can reduce the success of any subsequent data analysis. This drawback is even more pronounced when several thresholds have to be combined. A second drawback is the stringent enumeration aspect: a pattern is either above or below a threshold. But what about patterns that respect only some thresholds? Should they be discarded? It is often very difficult to apply subtle selection mechanisms. There are very few works such as [17,18] which propose to introduce a softness criterion into the mining process. Other studies attempt to integrate user preferences into the mining task in order to limit the number of extracted patterns such as the top-k pattern mining approaches [19,20]. By associating each pattern with a rank score, this approach returns an ordered list of the k patterns with the highest score to the user. However, combining several measures in a single scoring function is difficult and the performance of top-k approaches is often sensitive to the size of the datasets and to the threshold value, k.We present a unified methodology of two approaches that aim to make the results of pattern mining useful from a user-preference point of view. To this end, we integrate into the pattern discovery process the idea of skyline queries [21] in order to mine skyline patterns in a threshold-free manner. Such queries have attracted considerable attention due to their impor-tance in multi-criteria decision making and economics where they are usually called “Pareto efficiency or optimality queries”. Briefly, in a multidimensional space where a preference is defined for each dimension, a point a dominates another point b if a is better (i.e. more preferred) than b in at least one dimension, and a is not worse than b on every other dimen-sion. For example, a user selecting a set of patterns may prefer a pattern with a high frequency, a large length and a high confidence. In this case, we say that pattern a dominates another pattern b if a.frequency ≥ b.frequency, a.length ≥ b.length, a.confidence ≥ b.confidence, where at least one strict inequality holds. Given a set of patterns, the skyline set contains the patterns that are not dominated by any other pattern.Skyline pattern mining is interesting for several reasons. First, skyline processing does not require any threshold se-lection. In addition, for many pattern mining applications it is often difficult (or impossible) to find a reasonable global ranking function. Thus the idea of finding all optimal solutions in the pattern space with respect to multiple preferences is appealing. Second, the formal property of dominance satisfied by the skyline pattern defines a global interestingness measure with semantics easily understood by the user. These semantics are discussed at length in the economics literature, where the Pareto efficiency is applied to the selection of alternatives in resource distributions. However, while this notion of skylines has been extensively developed in engineering and database applications, it has remained unused for data mining purposes until recently [1]. Thirdly, skyline pattern mining is appealing from an efficiency and usability point of view. The authors of [22] established a loose upper-bound on the average number of skyline tuples O ((ln n)d−1) (with n tuples and |I|) (where |I| represents the d dimensions) which contrasts with the usual worst-case number of possible itemsets O (2cardinality of the set of items).Contributions and roadmap We present significant extensions of our recent papers [1,2] on the discovery of skyline patterns, or “skypatterns”. First, we detail a static method (called Aetheris) based on the theoretical relationships with condensed rep-resentations of patterns (representations which return a subset of the patterns having the same expressiveness as the whole set of patterns [23]). Second, we describe a dynamic method (called CP+Sky) which involves a continuous re-finement of the skyline constraints based on the extracted patterns. This is achieved through a dynamic CSP (Constraint Satisfaction Problems) framework (denoted by DynCSP). Third, the key notion of “skylineability” which constitutes the cor-nerstone of our two methods is explained in more detail. Finally, we present an extensive empirical study which includes a wide range of datasets and comparisons of our techniques. This enables us to draw some lessons about the strengths and weaknesses of each method and to better understand the advantages/weaknesses of the CSP machinery (see Sections 7.1.2and 7.1.3).The rest of this paper is organized as follows. Section 2 surveys the works related to skyline pattern analysis. Section 3introduces some basic definitions, the formal problem statement and an overview of our work. The key notion of sky-lineability is then studied in Section 4. Section 5 discusses the computation of condensed representation of patterns for skypattern queries. Section 6 discusses skylineability but within a DynCSP framework. We report an empirical study on several datasets and a case study from the chemoinformatics domain in Section 7. Finally, Section 8 discusses the learnt lessons.50W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–692. Related work2.1. Pattern miningFrequent itemset mining was first described in [8]. The problem can be defined as follows: a transaction is a subset of a given set of items I, and a transaction database, denoted T , is a set of such transactions. A subset x of I is a frequent itemset in T if the number of transactions containing x exceeds a given threshold, denoted by σ . One of the earliest findings in the data mining literature was that a mining process usually produces large collections of patterns. Many researchers have proposed methods to reduce the size of the output. These include the constraint-based pattern mining framework [24], the condensed representations [23] and the compression of the dataset by exploiting Minimum Description Length Principle [25], to name a few. A general observation is that patterns represent “fragmented knowledge”, and often there is no clear view of how these knowledge fragments interact and combine to produce a global model. Recent approaches have therefore used schemes such as pattern teams [26], constraint-based pattern set mining [27] and pattern selection strategies [28] that aim to minimize the redundancy and the number of patterns. A common theme in these studies is to select patterns from the initial large set of patterns on the basis of their usefulness in a given context. This approach falls into the general trend to produce pattern sets i.e. sets of patterns satisfying properties on the whole set of patterns [27]. Other approaches take advantage of closed patterns to maximize a specific measure such as the growth rate for emerging patterns [29] and the area for tiling [30,12]. Often, these methods focus on optimizing a global measure on the discovered pattern set and neglect the relationships between patterns. Moreover, these approaches suffer from a lack of flexibility to express the queries requested by the analyst. For each method, the user has to understand its semantics and express queries satisfying its algorithmic properties and constraints.Another class of techniques considers statistical significance of patterns. The objective is to extract patterns for which a given characteristic (usually the frequency) deviates so much from its expected value under a null model that it is unlikely to have been generated by it. The frequency of a pattern is then considered as a random variable, whose distribution under the null hypothesis has to be calculated or approximated, and the significance of the pattern is assessed through a statistical test that compares the expected frequency under the null model to the observed frequency. A number of works have explored various notions of statistical significance for itemsets and have proposed novel and efficient methods for their extraction [31–34].Pattern mining and Constraint Programming. Pattern mining benefits from the recent cross-fertilization between data min-ing and Constraint Programming [35–37,18]. Constraint Programming is a general declarative methodology for solving constraint satisfaction problems. Within this framework, the user specifies in a declarative way what the problem is by using constraints rather than a method dedicated to solve the problem. Then a general solver provides the complete set of solutions satisfying all the constraints. The approach is very expressive and allows to combine a wide range of mining constraints [36].2.2. SkylineThe skyline points can be viewed as compromise points with respect to a given set of criteria. Skyline computation is strongly related to mathematical and microeconomics problems such as maximum vectors [38], Pareto set [39], and multi-objective optimization [40]. Since its rediscovery within the database community by Börzsönyi et al. [21], many methods have been developed for answering skyline queries that can handle various constraints in different computational environ-ments [41,42]. Skyline queries focus on the extraction of tuples from a given dataset and assume that all the elements are in the dataset, while the skypattern mining task consists of extracting patterns which are elements of the frontier defined by the given measures. The skypattern problem is clearly harder because the search space for skypatterns is much larger than the search space for skylines (cf. Section 3.2). Few studies focus on skypattern mining for several pattern domains (e.g., graphs and subgroups). The published approaches are designed for particular types of patterns and consider a very limited number of measures to compute the skyline of patterns. Among them, two proposals address graph analysis. In [43], the authors compute the skyline of subgraphs according to the number of vertices and the edge connectivity. Similarly, in [44], the authors adapt the framework of the “Subdue” method [45] to compute the patterns that are dominant according to three measures (e.g., frequency, number of nodes and density). In [46], the authors introduce the skypattern mining problem in the context of subgroups. Their approach aims at discovering subgroups that maximize a quality measure and a diversity measure. The notion of dominance is at the core of the skyline processing. In [47], the notion of dominance is used to propose a novel algebra extending relational algebras towards pattern mining. It leads to a generic method for mining sev-eral kinds of patterns (including the skypatterns) according to a preorder associated to the dominance relation. The solving part in [47] is performed by using Constraint Programming with a principle similar as the technique used in our CP+Skymethod (cf. Section 6.2). The key idea is to use constraints on the dominance relation, which are dynamically added during the mining process. These constraints avoid producing solutions dominated by the solutions already extracted. In [47], the dynamically added constraints ensure that a candidate solution (i) is not dominated according to the preorder corresponding to the algebra or (ii) is equivalent to a solution already found. This last condition is required since the Pareto-dominance is a strict and partial order whereas a preorder is a reflexive relation. In CP+Sky, the dynamically added constraints stem from the dominance relation (i.e. a candidate solution is not dominated by the previous solutions). Finally, [47] does not W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6951Table 1Example of a toy dataset and measures.TidItemst1t2t3t4t5t6AAAABBBDDDCCCFFEEE(a) A toy data set TItemsABCDEFval105570301525Nameareameanbondaconfgr1p-value(b) Some measures of M2Definitionx (cid:4)→ freq(x) × length(x)x (cid:4)→ min(x.val)+max(x.val))x (cid:4)→ freq(x)freq∨(x)x (cid:4)→ freq(x)x (cid:4)→ |T2|x (cid:4)→ −binomial(prod(x.supp), freq(x))|T1| × freq(x,T1)freq(x,T2)max(x.freq)deal with the skylineability notion which is introduced in our work. As we will see, the skylineability allows to reduce the number of measures that have to be considered in the mining process and thus decreasing the runtime. Skylineability is associated to the theoretical relationships that we establish between the skymining problem and condensed representations of patterns. Another option for preference-based processing is the top-k procedure [19,20]. A ranking function fr is applied to patterns, and the k best patterns with the highest score with respect to fr are returned. As previously mentioned, this approach suffers from some limitations. The choice of k is not trivial (i.e. the horizon problem). A low value may miss useful patterns and too high a value introduces redundancy within the produced patterns (i.e. highly similar patterns). This limita-tion is the main motivation for the notion of the “most informative patterns” (MIP) that were proposed in [48]. MIPs can be seen as patterns that locally dominate other patterns according to a scoring function. This approach shares a similar spirit to ours as it also limits the number of enumerated patterns to a more manageable level. However, in contrast to our approach, work on MIPs includes a notion of dominance that is local and specific only to subsets of patterns.3. Problem statement and overview of the unified methodologyWe introduce in this section some basic definitions and the formal problem statement. We also give an overview of the two methods Aetheris and CP+Sky we propose. These methods fully exploit an adequate representation of patterns dedicated to user-preferences [49]. Our study is interesting for several reasons. By carefully selecting patterns that are “the best available” for a given set of preferences, we greatly reduce the output and we limit the curse of “pattern explosion”. The user is guaranteed that only the best patterns w.r.t. his criteria are present in the final result. Last but not least, our approach is threshold-free.1 Only the preferences and the dataset are required as an input.3.1. Preliminary definitionsAlthough the problem can be formulated for any kind of pattern, for the sake of simplicity, we will illustrate our defini-tions using the itemset pattern domain. Section 8 discusses the computational and theoretical aspects associated with the problem when extracting more sophisticated kinds of patterns.Let I be a set of distinct literals called items, an itemset (or pattern) corresponds to a non-empty subset of I. These I \∅. A transactional dataset T is a multi-set of patterns of L. Each patterns are gathered together in the language L: L = 2element of T , named transaction, is a database entry. Table 1a presents a transactional dataset T where 6 transactions denoted by t1, . . . , t6 are described by 6 items denoted by A, . . . , F .All the measures discussed in this study are based on the set of primitive-based measures M that were defined in the context of constraint-based pattern mining [50]. Table 2 presents some general definitions of measures and Table 1b gives some specific examples (gr denotes the growth rate [11], freq∨ the disjunctive support, measures such as bond and aconfare detailed in [51]). Interestingly, our methodology is suitable for recent mining techniques utilizing statistical significance of patterns as discussed in related work. For instance, the p-value under the null model which considers all items to be independent random variables is rewritable as a primitive-based measure (see the definition of the p-value in Table 1a). As claimed in [50], M encompasses a very large set of interesting measures.1 Thresholds are entirely optional, depending on the analyst’s needs and do not depend on the algorithm.52W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–69Table 2A subset of the primitive-based measures.Measure m ∈ Mm1θm2θ(s)θ(s.val)Constant r ∈ (cid:9)+Syntactic expression s ∈ Ss1θ s2θ(s)Variable x ∈ LConstant l ∈ LPrimitive(s)θ ∈ {+, −, ×, /, binomial}θ ∈ {freq, freq∨, length}θ ∈ {sum, max, min, prod}–Primitive(s)θ ∈ {∪, ∩, \}θ ∈ { f , g}––Operand(s)(m1, m2) ∈ M2s ∈ Ss ∈ S–Operand(s)(s1, s2) ∈ S 2s ∈ S––In addition to the classical operators of (cid:9)+(i.e. +, −, ×, /) and L (i.e. ∪, ∩, \), the function freq denotes the frequency of a pattern (i.e. freq(x, T ) = |{t ∈ T | x ⊆ t}|), and length its cardinality. The disjunctive support is freq∨(x) = |{t ∈ T | ∃i ∈x : i ∈ t}|. More atypical primitives also fit the primitive-based framework like binomial(p, i) =Given a function val : I → R+, we extend it to a pattern x and denote by x.val the multi-set {val(i) | i ∈ x}. This kind of function is used with the usual SQL-like primitives sum, min and max. For instance, sum(x.val) is the sum of val for each item of x. Note that prod is a slightly different aggregate function due to val : I → [0, 1] (e.g., the support of each item in p-value definition). Finally, fis the intension i.e. f (T ) = {i ∈ I | ∀t ∈ T , i ∈ t}, and g is the extension i.e. g(x) = {t ∈ Tid | x ⊆ t}.pk(1 − p)n−k.(cid:2)nk=i(cid:3)nk(cid:4)This large variety of measures allows for more flexibility to formulate new or well-known interestingness measures that match the data analyst’s objectives. Rather than using a ranking function for combining these measures and then maximizing it, we propose to use the Pareto composition:Definition 1 ((Pareto)-dominance). Given a set of measures M ⊆ M, a pattern x dominates another pattern y with respect to M, denoted by x (cid:15)M y, iff for any measure m ∈ M, m(x) ≥ m( y) and there exists m ∈ M such that m(x) > m( y). Two patterns x and y are said to be indistinct with respect to M, denoted by x =M y, iff m(x) equals m( y) for any measure m ∈ M (if M = ∅, then x =∅ y). Finally, x (cid:16)M y denotes that (x (cid:15)M y) ∨ (x =M y).Note that we define the Pareto dominance only with the greater than symbol (i.e. >) assuming that the end-user wants to maximize a set of measures. The case of a minimization of a measure m is equivalent to maximizing the measure m(cid:17) = −m (this case is illustrated with the definition of p-value which contains a minus).Consider our running example using the data set T in Table 1a and suppose that M = {freq, area}, then the pattern ABCDEF dominates ABC because freq(ABC) = freq(ABCDEF) = 2 and area(ABCDEF) > area(ABC). Note in this case that ABCDEFis indistinct to ABC with respect to {freq}. Similarly, suppose that M = {freq, mean, length}, the pattern AC dominates ABbecause freq(AC) = freq(AB) = 3, |AB| = |AC| = 2 and mean(AC) > mean(AB).3.2. The skypattern mining problemGiven a set of measures M, if a pattern is dominated by another according to all measures of M, it is irrelevant and should be discarded in the output. The notion of skyline pattern, skypattern for short, formalizes this intuition.Definition 2 (Skypattern operator). Given a pattern set P ⊆ L and a set of measures M ⊆ M, a skypattern of P with respect to M is a pattern not dominated by any pattern in P with respect to M. The skypattern operator Sky(P , M) returns all the skypatterns of P with respect to M:Sky(P , M) = {x ∈ P | (cid:18) ∃ y ∈ P : y (cid:15)M x}Then, the skypattern problem can be stated:Problem 1. Given a set of measures M ⊆ M, the skypattern mining problem is to evaluate the query Sky(L, M).For instance, from the running data set (cf. Table 1a), Sky(L, {freq, length}) = {ABCDEF, AB, AC, A}, as illustrated in Fig. 1.In the general case, the skypattern mining problem is challenging because of the very high number of candidate patterns (i.e. |L|). Indeed, a naive enumeration of L is not feasible. For example, with 1000 items a naive approach will need to compute (21000 − 1) × |M| measures and then compare them. A less naive approach based on heuristics (such as the anti-monotonicity of some measures) may give some results. However, the performance will be closely tied to the underlying properties of the data sets. For instance, in the case of the frequency measure, the density of the data set plays a major role in the performance and some algorithms are not able to extract frequent patterns at very low thresholds. Nevertheless, considering the following property provides new insights into an efficient computation of skypattern queries.W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6953Fig. 1. Example of skypatterns for the set of measures M = {freq, length} (all the other patterns are in the dominated area).Property 1. Given a set of measures M ⊆ M, Sky(L, M) = Sky(P , M) for any pattern set P such that Sky(L, M) ⊆ P ,(∀P ⊆ L)(Sky(L, M) ⊆ P ⇒ Sky(L, M) = Sky(P , M))Proof. Let P be a set of patterns such that Sky(L, M) ⊆ P ⊆ L. First, let x be a pattern in Sky(L, M). Then there is no y (cid:18)= xin L such that y (cid:15)M x. In particular, there is no y (cid:18)= x in P such that y (cid:15)M x. Note that x belongs to P which is a superset (cid:17) (cid:18)= x in L \ Pof Sky(L, M). Thus, x is a pattern in Sky(P , M). Suppose now that x is not in Sky(L, M): then there exists ynot in P would such that yhave to be in Sky(L, M). (cid:2)(cid:17)(cid:17) (cid:18)(cid:15)M x. By induction, any yor another pattern dominating y(cid:17)(cid:17) ∈ P , there is y(cid:17) (cid:15)M x and ∀ y(cid:17)(cid:17)As Sky(L, M) ⊆ P ⊆ L and |P | ≤ |L|, we argue that evaluating Sky(P , M) is generally much less costly than evaluating Sky(L, M) since the cost of Sky(x, M) generally decreases with the cardinality of x. Consequently, we aim to reduce the cost of evaluating Sky(P , M) by finding a small but relevant set P (i.e. that includes Sky(L, M)) by means of 1) condensed representations of patterns or 2) dynamic pruning.Condensed representations of patterns In many pattern mining tasks (e.g., association rule mining or clustering), condensed representations of patterns significantly reduce the mining effort without loss of precision. Could we use this principle in the case of skypattern mining? A direct approach would be to compute a concise representation for each measure m ∈ M, but this is generally not possible because some measures, such as area or length, are not condensable (i.e., the condensed representation is equal to |L|). Therefore, our problem can be reformulated as follows: given a set of measures M, how to identify a smaller set of measures Mwhich allows the computation of a concise representation on the patterns (i.e. the pattern set P ) without loss of skypatterns? In addition, how can one use this set of measures to extract efficiently the skypatterns without redundancies? We address this problem in the next sections.(cid:17)Dynamic pruning Instead of extracting the whole condensed representation of patterns and then applying the Sky operator. One may consider the use of the Sky operator locally during the extraction. Indeed, as soon as a pattern is a candidate skypattern, the search space dominated by this pattern can be directly eliminated. In other words, each new candidate skypattern adds a constraint allowing to safely prune the remaining search space. These new constraints prevent the enu-meration of unnecessary patterns. Section 6 describes how CSP can be used to update constraints during the extraction and thus reduce the search space.3.3. Unified methodology for the two methods(cid:17)To clarify our methodology, we illustrate in Fig. 2 the different processes of the two methods Aetheris and CP+Sky we propose. These two methods share the same overall methodology and mainly differ in the specific step of the computation of representative patterns of the skypatterns.After the user’s preferences selection, in a common first step, Aetheris and CP+Sky automatically identify a smaller set which allows for the computation of a concise representation on the patterns thanks to the use of convertersof measures M(cid:17)for Aetheris and CP+Sky) aims at computing an as small as possible (cf. Section 4). The second step (respectively 2 and 2superset that enables the retrieval of all skypatterns. For that purpose, Aetheris builds a static set of representative patterns , which is based on the notion of converting the initial set of preference M (cf. Section 5). CP+Skyaccording to the set Mbuilds dynamically a more concise set by pruning unpromising patterns (the set of representative patterns of CP+Sky is included in the set of representative patterns of Aetheris) (cf. Section 6). The third step filters the set of representative patterns with the Sky operator. This step remains efficient because the number of representative patterns is much smaller than the number of possible skypatterns. Finally, this step provides a concise representation of the skypatterns. The end-user can either output this concise representation or the entire list of skypatterns as a final step depending on the application (cid:17)54W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–69Fig. 2. Unified view of skypattern mining with Aetheris and CP+Sky.needs. Our methodology revolves around the simple idea that to be able to efficiently extract and analyze skypatterns, one needs to be able to (statically or dynamically) exhibit a concise representation of the skypatterns that will be used as an input to the skyline operator.4. SkylineabilityThe set of skypatterns has no good property like downward closure or convexity. Conventional techniques used to prune the pattern search space like anti-monotone properties are thus ineffective. However, using Property 1, an efficient computa-tion of the set of representative patterns of skypatterns becomes possible. To do so, we introduce the notion of skylineability which aims at computing a reduced collection of representative patterns of the skypatterns (cf. the end of the previous sec-tion). This efficient computation is carried out using either free [16] or closed patterns [14].4.1. Skylineability of a set of measuresIntuitively, skylineability refers to the notion of local extrema in the search space. The local extrema in this case are the maximal values for each preference selected by the end-user. By definition, only these extrema may therefore be skypatterns. Thus there is no need, while mining, to take into account the other patterns which are necessarily dominated by these : x =M(cid:17) y. If yextrema. Assume any two patterns x and y, such that x ⊂ y, have the same value for each measure of Malways dominates x for a given set of measures M ⊆ M, then M is said to be maximally M-skylineable. This information is extremely important as it allows the discarding of non-maximal patterns (here, x) which are dominated by maximal patterns (here, y). This notion of skylineability can be seen as a way of mapping domination between two different sets of measures M and M.(cid:17)(cid:17)(cid:17)(cid:17)Fig. 3 (top) depicts the benefit of skylineability in the general case where it becomes possible to focus only on a subset of patterns and measures (i.e. M) and have a formal guarantee that these patterns will not be dominated in the full set of measures (i.e. M). We illustrate now this notion of skylineability on our running example. Let us consider patterns from Tthat maximize the frequency and area measures: M = {freq, area}. In our example (cf. Table 1a), the patterns B and AB have (cid:17) = {freq}, B =M(cid:17) AB and AB (cid:15)M B because the area of AB is the same frequency (see Fig. 3 (bottom)). Thus, if we define Mgreater than that of B. In fact, for any two patterns x ⊂ y such that x =freq y, we have y (cid:15)M x and M = {freq, area} is thus said maximally {freq}-skylineable. The mining process can focus on only extracting patterns based on the frequency measure (i.e. M) without having to take into account the area measure that is present in M.(cid:17)In practice, local extrema are not necessarily the longest patterns (i.e. the closed patterns which are the maximal patterns of equivalence classes) but can also be the shortest patterns (i.e. the free patterns which are the minimal patterns of equivalence classes). Thus, the concept of skylineability is defined in a dual manner:Definition 3 (Minimal skylineability). Given a set of measures Mminimally M-skylineable iff for any patterns x and y such that x ⊂ y and x =M(cid:17) y, one has x (cid:16)M y (respectively x (cid:15)M y).(cid:17) ⊆ M, a set of measures M ⊆ M is said to be (strictly) (cid:17)W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6955Fig. 3. Use of skylineability in the general case (cf. Fig. 3a, top) and in our running example (cf. Fig. 3b bottom) in which AB =freq B: we directly knows that AB (cid:15)M B without considering area (length(AB) > length(B)).Definition 4 (Maximal skylineability). Given a set of measures Mmaximally M-skylineable iff for any patterns x and y such that x ⊂ y and x =M(cid:17) y, one has y (cid:16)M x (respectively y (cid:15)M x).(cid:17) ⊆ M, a set of measures M ⊆ M is said to be (strictly) (cid:17)From the previous definitions, given a set of measures M which is maximally M-skylineable, if x =M(cid:17) y and x ⊃ y, it is clear that x cannot be dominated by y on M. For instance, M = {freq, area} is strictly maximally {freq}-skylineable because area(x) strictly increases with the cardinality of x (when the frequency remains constant). Hence, in Fig. 3 (bottom), we can deduce that ABCDEF dominates the patterns ABCDE, ABCD, . . . , DEF without considering the full set of measures M but (cid:17). Notice that {freq} is (weakly) maximally (or minimally) {freq}-skylineable and that {length(x)} is strictly maximally only M∅-skylineable.(cid:17)Property 2. Given a set of measures M ⊆ M, there is at least one set M(cid:17) ⊆ M such that M is minimally and maximally M(cid:17)-skylineable.Proof. Let M ⊆ M be a set of measures. Let Mpatterns such that x =M(cid:17) y. Let m ∈ M. As x =m(cid:17) y for any primitive mx =m y. We conclude that x =M y and then, x (cid:16)M y and y (cid:16)M x. (cid:2)(cid:17) ⊆ M be the set of all unary primitives defined on L. Let x and y be two and m is composed of such primitives, thus (cid:17) ∈ M(cid:17)Property 2 is a very important result as it means that a set of measures is always skylineable (due to the fact that M is at least M-skylineable). Obviously, for a set of measures M, the smaller2 M-skylineability. For instance, {freq}-skylineability is more interesting than {freq, area}-skylineability because area is not a condensable function [49]: there is no pair of distinct patterns x and y such that x ={freq,area} y. How to choose automatically a subset M, the stronger its Mis discussed next.(cid:17)(cid:17)(cid:17)4.2. Minimal and maximal skylineable convertersOne of the disadvantages of skylineability is that it depends on a set of measures Meffectively reduce the search space. We propose two operators to automatically build MBasically, the construction of Mwhose choice is essential to given the initial set of measures M. consists in identifying primitives that must remain constant in order that minimal or (cid:17)(cid:17)(cid:17)2 In the sense of cardinality.56W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–69Table 3Definition of the minimal and maximal skylineable converters c and c.Expr. ee1θ e2e1θ e2Constantd(x)i(x)d(e1)i(e1)Primitive(s)θ ∈ {+, ×, ∪}θ ∈ {−, /, binomial, ∩}–d ∈ {freq, min, g, prod}i ∈ {length, max, sum, freq∨, f }d ∈ {freq, min, g, prod}i ∈ {length, max, sum, freq∨, f }c(e)c(e1) ∪ c(e2)c(e1) ∪ c(e2)∅∅{i(x)}c(e1)c(e1)c(e)c(e1) ∪ c(e2)c(e1) ∪ c(e2)∅{d(x)}∅c(e1)c(e1)Table 4Applying the minimal and maximal converters.Meas. mareameanbondaconfgr1p-valuec(m){length(x)}{max(x.val)}∅∅{freq(x, T2)}{prod(x.supp)}c(m){freq(x)}{min(x.val)}{freq(x), freq∨(x)}{freq(x), max(x.val)}{freq(x, T1)}{freq(x)}(a) Individual measuresc({freq(x), area(x)})c(freq(x))c(freq(x) × length(x))c(freq(x))c(length(x))(b) A set of measures M = {freq(x), area(x)}(cid:17)(cid:17)(cid:17)-skylineability of m, has to be added to Mmaximal patterns are always dominant patterns. Intuitively, any primitive p that is part of the measure m ∈ M that hinders . For instance, it is easy to see that the frequency decreases the area the Mbecause the frequency decreases with the specialization. In order that the closed patterns maximize the area, the frequency has to belong to M. More generally, it is essential to take into account the monotone behavior of primitives: decreasing or increasing. For instance, the length increases with x while the frequency decreases. It is also necessary to consider the operations that combine these primitives. The result of a multiplication increases when one of its operands increases. However, the result of a division decreases with its second operand. For this purpose, we define two operators denoted cand c (see Table 3).Given a primitive-based measure m ∈ M, the minimal skylineable converter returns a set of measures M(cid:17) = c(m) guar-anteeing that for any pattern x ⊂ y, if x =M(cid:17) y then m(x) ≥ m( y). In other words, x dominates y with respect to m. Dually, the maximal converter c guarantees that m(x) ≤ m( y) for any pattern x ⊂ y such that x =c(m) y.Let us illustrate c and c on the area measure. The area is defined as a product of the frequency and length. Thus, we use the first definition in Table 3. c(area) = c(freq(x)) ∪ c(length(x)) = ∅ ∪ {length(x)} = {length(x)}. Symmetrically, c(area) =c(freq(x)) ∪ c(length(x)) = {freq(x)} ∪ ∅ = {freq(x)}. The skylineable converters enable us to automatically find optimization techniques already known for specific measures such as area [30,12], p-value [32] or growth-rate [29] (see Table 4a). We can observe that many measures are maximized by the closed itemsets according to frequency which may explain the success of closed pattern mining. But, in this work, we generalize this principle to optimize any primitive-based measures. Note that when the converter c returns no measure (e.g., bond or aconf ), it means that the measure decreases with respect to the specialization. Dually, c(m) = ∅ means that m increases with respect to the specialization.In practice, as the skypatterns are computed for a set of measures, we extend the minimal and maximal converters:Definition 5 (Minimal and maximal skylineable converters). The minimal and maximal skylineable converters defined by Table 3for any primitive-based measure are naturally extended to a set of primitive-based measures M ⊆ M: c(M) =m∈M c(m)and c(M) =(cid:5)(cid:5)m∈M c(m).For instance, c({freq(x), area(x)}) = c(freq(x)) ∪ c(area(x)) = {freq(x)} and c({freq(x), area(x)}) = c(freq(x)) ∪ c(area(x)) ={length(x)}. c({freq(x), area(x)}) = {freq(x)} means that the most specific patterns (when the frequency remains unchanged) maximize the measures {freq(x), area(x)}. The following property formalizes this observation:Property 3. A set of primitive-based measures M ⊆ M is minimally c(M)-skylineable and maximally c(M)-skylineable.W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6957Proof. The key idea relies on the monotonous property according to each variable of a primitive. The operators c((cid:2)) and c((cid:2))are recursively applied to return the set of primitives which must be constant in order to respectively minimize or maximize the measure. Two cases arise to be sure that an expression p(h1, . . . , hk) is minimized with x. For each i ∈ {1, . . . , k}, if the primitive p increases according to the ith variable (while the other ones remain unchanged), it is necessary to return the primitives such that hiis also minimized according to x. For this purpose, the minimal skylineable converter is applied again. Otherwise, the primitive p decreases with the ith variable and we return the primitives such that hi is maximized by applying the maximal skylineable converter. The dual approach is used to maximize a measure. (cid:2)In our implementation, the set of measures M is parsed through a syntax tree. Following this step, the minimal and maximal skylineable converters are recursively applied to automatically compute c(M) and c(M) (an example is provided in Table 4b for M = {freq(x), area(x)}). This process is illustrated in Fig. 2 with the edge labeled 1. From now on, the set of measures Mrefers to c(M) or c(M).(cid:17)5. Condensed representations of patterns for static mining of skypatternsThis section presents our static method called Aetheris based on the theoretical relationships between condensed rep-resentations of patterns and skypatterns. Aetheris follows a two-step process (cf. Section 3.3): first, a set of representative patterns is extracted and then the Sky operator is applied on these patterns. The technique is said to be static because the extraction of a representative pattern does not depend on the patterns already extracted, contrary to the CP+Sky method presented in the next section.A major issue is how to extract representative patterns for a group of skypatterns. In the previous section, we remarked (e.g. B ={freq} AB). This observation that some skypatterns share exactly the same values on the whole set of measures Menables us to properly answer the question: instead of directly evaluating the skypattern query on L, we can compute the skypatterns on a condensed representation of L and then generate the entire set of skypatterns. To this end, we introduce the distinct operator which is at the core of the construction of a condensed representation adequate to M:(cid:17)(cid:17)and Definition 6 (Distinct operator). Given a set of measures Mθ ∈ {⊂, ⊃} returns all the patterns x of P such that their generalizations (or specializations) are distinct from x with respect to M(cid:17) ⊆ M, the distinct operator for P ⊆ L with respect to M:(cid:17)(cid:17)(cid:17)Disθ (P , Mwhere θ ∈ {⊂, ⊃}.) = {x ∈ P | ∀ y θ x : x (cid:18)=M(cid:17) y}Given a set of measures M(cid:17), the set of free (respectively closed) patterns adequate to Mcorresponds exactly to (cid:17))). For instance, from our running example, Dis⊂(L, {freq}) = { A, B, C, D, E, F , AD, AE,(cid:17)Dis⊂(L, MBC, BD, BE, CD, CE, DE} and Dis⊃(L, {freq}) = { A, D, E, AB, AC, ABCDEF}.(cid:17)) (respectively Dis⊃(L, MWe now introduce the indistinct operator that enables the retrieval of all the indistinct patterns from their representatives:Definition 7 (Indistinct operator). Given a set of measures M(cid:17)with at least one pattern in P .indistinct with respect to M(cid:17) ⊆ M, the indistinct operator returns all the patterns of L being Ind(L, M(cid:17), P ) = {x ∈ L | ∃ y ∈ P : x =M(cid:17) y}For instance, from Table 1a, the set of patterns that have exactly the same frequency as patterns B or C is Ind(L, {freq}, {AB, AC}) = {B, C, AB, AC}.Preserving functions express a property of compression and are at the core of Property 4. A preserving function is a condensable primitive (many functions are preserving: freq, freq∨, count, min, max, sum, etc., see more details in [49]).Property 4. Given a set of preserving functions M, Disθ (P , MInd(P , M)) = P(cid:17)(cid:17)(cid:17), one has the following relation for any P ⊆ L and θ ∈ {⊂, ⊃}:In other words, the indistinct operator is the inverse function for the distinct operator. For instance, Ind(L, {freq},Dis⊃({B, C, AB, AC}, {freq})) = {B, C, AB, AC}.These operators are the basis of an efficient technique to compute skypatterns. The key principle is to confront only distinct patterns together instead of individually comparing each pattern. Indeed, the computation of skypatterns with respect to M = {freq, area} can be limited to Dis⊃(L, {freq}) because maximal {freq}-skylineability guarantees us that the other patterns are not dominant patterns. For instance, as AB =freq B, the {freq}-skylineability of M gives AB (cid:15)M B and (cid:17))), M) = Sky(L, M) from Property 4. B cannot be a skypattern. More formally, we know that Sky(Ind(L, MTheorem 1 now proves that the skypattern operator can be pushed into the indistinct operator:(cid:17), Disθ (L, M58W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–69Fig. 4. Computing the skypatterns with respect to {freq; area} from the running example.Theorem 1 (Operational equivalence). If a set of measures M is Mthen one has:Sky(L, M) = Ind(L, M, Sky(Disθ (L, M(cid:17)), M))(cid:17)-skylineable with respect to θ ∈ {⊂, ⊃} and M(cid:17)is a set of measures, Proof. Let M be a set of measures M(cid:17)-skylineable with θ ∈ {⊂, ⊃}.1. Sky(L, M) ⊇ Ind(L, M, Sky(Disθ (L, MLet x ∈ Ind(L, M, Sky(Disθ (L, M(cid:17)) such that y(cid:17) =M(cid:17) y and yDisθ (L, Mdominated by any pattern of Disθ (L, Mbecause x(cid:17) =M x and y(cid:17) (cid:16)M y.(cid:17)), M)).(cid:17)), M)) and y ∈ L. There exist x(cid:17)(cid:17) ∈(cid:17) =M x and y(cid:17)), M), it cannot be (cid:17) (cid:18)(cid:15)M x. Thus, x is not dominated by y (i.e. x is a skyline of L with respect to M) (cid:17) (cid:16)M y (i.e. M(cid:17)): ybelongs to Sky(Disθ (L, M(cid:17)-skylineability). As x(cid:17) ∈ Sky(Disθ (L, M(cid:17)), M) such that x2. Sky(L, M) ⊆ Ind(L, M, Sky(Disθ (L, M(cid:17)), M)) such that yand thus, yy, y belongs to Ind(L, M, Sky(Disθ (L, M(cid:17) =M y. Furthermore, no pattern of Disθ (L, M(cid:17)), M)). (cid:2)(cid:17) =M(cid:17) y and y(cid:17)) dominates y nor y(cid:17) (cid:16)M y. As y is a skypattern, one has y (cid:16)M x(cid:17)(cid:17) =M(cid:17)(cid:17)), M). Finally, as y(cid:17) ∈ Sky(Disθ (L, M: yThe skypatterns of Sky(Disθ (L, M(cid:17)) or Dis⊃(L, Madequate condensed representations (i.e. Dis⊂(L, MThus, we have achieved our objective as mentioned in Section 3.2.(cid:17)), M) form a condensed representation of Sky(L, M). It is well-known that the size of (cid:17))) is smaller than the whole collection of patterns [23]. The technique is even more efficient if the set of measures is strictly M(cid:17)-skylineable. In this case, the Ind operator can be skipped and Theorem 1 is reduced to the following relation: Sky(L, M) = Sky(Disθ (L, M(cid:17)), M) (with θ ∈ {⊂, ⊃}).Fig. 4 illustrates the computation of the skypatterns with our method Aetheris. Suppose that M = {freq, area}, the first step applies the maximal skylineable converter on M. Then, the distinct operator preserves the closed itemsets (Step 2). The skyline operator selects the dominant patterns at Step 3 by removing D and E which are dominated by AB (i.e. area(D) =area(E) = 3 < area(AB) = 6). Finally, the last step computes the indistinct patterns of skypatterns. Note that this step in this example is unnecessary because the area is strictly {freq}-skylineable.6. Mining skypatterns using dynamic CSPThis section describes how the skypattern mining problem can be modeled and solved by using DynCSP [52,53]. A major advantage of this method is that it improves the mining step during the process thanks to constraints dynamically arising from the current set of candidate skypatterns. These constraints avoid producing new solutions dominated by the current skypatterns and thus reduce the search space. More precisely, each time a solution is found, a new constraint is dynamically posted. The process stops when we cannot enlarge the dominated area further (cf. Fig. 1). The set of obtained representative patterns is a subset of the set of representative patterns extracted with Aetheris (cf. Section 3.3). The completeness of our CP+Sky method is insured by the completeness of the CSP solver. The implementation has been carried out in Gecode.3The rest of this section is organized as follows. Section 6.1 recalls some general background on CSP and DynCSP. Sec-tion 6.2 describes how skypattern mining can be modeled using DynCSP. Section 6.3 presents the pattern encoding as well as the filtering that is achieved. Sections 6.4 and 6.5 are devoted to closedness constraints and freeness constraints. Finally, Section 6.6 provides an example.6.1. CSP and DynCSPConstraint Satisfaction Problem A CSP [54,55] P = (X , D, C) is defined by a finite set of variables X = {x1, x2, . . . , xk}, a set of domains D which maps every variable xi ∈ X to a finite set of values D(xi) and a finite set of constraints C.Algorithm 1 provides a general overview of a CSP solver. Dom and Store denote respectively the current domains and the current set of constraints. Essentially, a CSP solver consists of a depth-first search algorithm. At each node of the search tree, procedure Constraint-Search selects an unassigned variable (line 5) according to user-defined heuristics4 and assigns 3 http://www.gecode.org/.4 For our implementation, we used the most constrained variable order heuristics, which branches over the variable contained in most constraints; this order is dynamic (updated during the search).W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6959return failure;Algorithm 1: Constraint-Search(Dom).1 Dom ← Filtering(Dom, Store);2 if there exists xi ∈ X s.t. Dom(xi ) is empty then34 if there exists xi ∈ X s.t. |Dom(xi )| > 1 thenSelect xi ∈ X s.t. |Dom(xi )| > 1;5forall the v ∈ Dom(xi ) do67Constraint-Search(Dom ∪ {xi → {v}});8 else910output solution Dom;Store ← Store ∪ {φ(X )};it a value (line 6). After that assignment, procedure Constraint-Search is called recursively (line 7). It backtracks when a constraint cannot be satisfied, i.e. when at least one domain is empty (line 2). A solution is obtained (line 9) when each domain Dom(xi) is reduced to a singleton and all constraints are satisfied.The main concept used to speed-up the search is the constraint propagation by Filtering method. This method reduces the domains of variables such that they remain locally consistent. Constraint propagation operates on an individual constraint. To maintain local consistency for individual constraints, propagation rules are used. Given a constraint and the current domains of the variables in its scope, a propagator removes domain values that do not satisfy the constraint. Since variables usually participate in several constraints, the updated domains are propagated to the other constraints, whose propagators are in turn activated. This process of constraint propagation is repeated for all constraints until no more domain values can be removed or a domain becomes empty.Dynamic CSP A DynCSP [52,53] is a sequence P 1, P 2, . . . , P n of CSPs, each one resulting from some changes in the definition of the previous one. These changes may affect every component in the problem definition: variables (additions or removals), domains (value additions or removals), constraints (additions or removals).6.2. DynCSP-based method for mining skypatternsThis section provides our CSP-based method CP+Sky for mining skypatterns. As before, the representative patterns are searched according to Musing the skylineability principle. The key idea is to use constraints on the dominance relation, which are dynamically added during the mining process. These constraints avoid producing solutions dominated by the solutions already extracted and thus reduce the search space. We start by highlighting the way we handle DynCSP and then we provide our encoding.(cid:17)For our approach, changes between CSP P i and CSP P i+1 are only performed by adding new constraints without any removal of constraints. Additions are handled in a straightforward way with the help of filtering. Solving such a DynCSP involves solving a single CSP with additional constraints posted during search. These constraints will survive backtracking and state that next solutions should verify both the current set of constraints as well as the added ones. Each time a new solution is found, new constraints φ(X ) are imposed. Such constraints state that next solutions should verify both the current set of constraints Store and φ(X ) (cf. line 10 of Algorithm 1).Variable x will denote the (unknown) skypattern we are looking for. We consider the sequence P 1, P 2, . . . , P n of CSP where each P i = ({x}, L, qi(x)) and:q1(x) = disθ (x) where disθ (x) denotes the representative pattern x.qi+1(x) = qi(x) ∧ φi(x) where si is the first solution to query qi(x).First, the constraint disθ (x) states that x must be either a closed pattern w.r.t. M(i.e. disθ (x) = closedM(cid:17) (x)) or a free (i.e. disθ (x) = freeM(cid:17) (x)). Then, the constraint φi(x) ≡ (si (cid:18)(cid:15)M x) states that the next solution (which is pattern w.r.t. Msearched for) will not be dominated by si . Using a short induction proof, we can easily argue that query qi+1(x) looks for a pattern x that will not be dominated by any of the patterns s1, s2, . . ., si .(cid:17)Each time the first solution si to query qi(x) is output by Algorithm 1, we dynamically post a new constraint φi(x) (see (cid:17)line 10) leading to a reduction of the search space. For skypatterns, φi(x) states that (si (cid:18)(cid:15)M x):(cid:6)(cid:7)(cid:8)(cid:6)(cid:9)(cid:8)φi(x) ≡m(si) < m(x)∨m(si) = m(x)m∈Mm∈MThis process stops when we cannot enlarge the dominated area further, i.e. there exists n s.t. query qn+1(x) has no solution. The dominated area cannot be extended and is fully established.But, the n extracted patterns s1, s2, . . ., sn are not necessarily all skypatterns. Some of them could only be “intermediate” patterns simply used to enlarge the dominated area. A post processing step must be performed to filter all candidate 60W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–69patterns si that are not skypatterns, i.e. for which there exists s j (1 ≤ i < j ≤ n) s.t. s j dominates si . So mining skypatterns is achieved in a two-step approach:1. Compute the set S = {s1, s2, . . . , sn} of candidates using DynCSP.2. Filter all patterns si ∈ S that are not skypatterns.While the number of candidates (n) could be very large, it remains reasonably-sized in practice for the experiments we conducted (see Section 7).However, the order in which candidates are produced in the first step influences the way the dominated area is enlarged, and therefore the effectiveness of CP+Sky. One way to enhance the efficiency would be to select the most beneficial order in which candidates are generated. In the case of a single measure m, we can always derive an optimal order that guarantees that any solution produced in step 1 is a skypattern, thus avoiding the need for post-processing. It suffices to generate the patterns from the largest values of m to the lowest values of m (cf. Definition 1). But in the general case where several measures are involved, finding such an optimal order is often impossible and post-processing is required.6.3. Pattern encoding and filteringWe now introduce the modeling of a pattern that can be provided to the constraint programming system. Let d—be the 0/1 matrix where, for each transaction t and each item i, (dt,i = 1) iff (i ∈ t). Pattern variables are set variables represented by their characteristic function with Boolean variables. [35] and [36] model an unknown pattern x and its associated dataset T by introducing two sets of Boolean variables:• item variables { Xi | i ∈ I} where ( Xi = 1) iff (i ∈ x),• transaction variables {Tt | t ∈ T } where (Tt = 1) iff (x ⊆ t).Each set of Boolean variables aims to represent the characteristic function of the unknown pattern.The relationship between x and T is modeled by posting reified constraints stating that, for each transaction t, (Tt = 1)iff x is a subset of t:∀t ∈ T , (Tt = 1) ⇔(cid:10)i∈IXi × (1 − dt,i) = 0(1)A reified constraint associates a 0/1 variable to a constraint reflecting whether the constraint is satisfied (value 1) or not (value 0). Such constraints are useful for expressing propositional formulas over constraints and for expressing that a certain number of constraints hold. Reified constraints do not enjoy the same level of propagation as simple constraints, but if the solver deduces Tt = 1 (resp. Tt = 0), then the sum must be equal to 0 (resp. must be different from 0).The propagation is also performed in the same way from the sum constraint towards the equality constraint. For example, when an item variable Xi is set, the following propagation is applied to the reified constraints described by Eq. (1) (see [35]for more details):• if for some t, • if for some t, (cid:2)(cid:2)i∈I (min D( Xi)) × (1 − dt,i) > 0 then remove 1 from D(Tt ),i∈I (min D( Xi)) × (1 − dt,i) = 0 then remove 0 from D(Tt ).(cid:2)Finally, using the Boolean encoding, it is worth noting that some measures are easy to encode: freq(x) =length(x) =(cid:2)t∈T Tt and i∈I Xi . So, the minimal frequency constraint freq(x) ≥ θ (where θ is a threshold) is encoded by the constraint t∈T Tt ≥ θ . In the same way, the maximal size constraint length(x) ≤ α (where α is a threshold) is encoded by the (cid:2)(cid:2)constraint i∈I Xi ≤ α.6.4. Closedness constraintsThis section describes how to encode closedM(cid:17) (x). As an illustration, we provide the examples of M(cid:17) ={freq}. Recalling that thanks to skylineability, these measures also allow to handle measures such as mean, area, growth-rate, etc. In practice, these two examples are enough for running the experiments given in Section 7.(cid:17) = {min} and M(cid:17) = {min} and val( j) a function that associates an attribute value to each item j. If item i belongs to x, then its value must be greater than or equal to the min. Conversely, if this value is greater than or equal to the min, then i must belong to x (if not, x would not be maximal for inclusion). Item i belongs to x is encoded as ( Xi = 1). So, x is a closed pattern for the measure min iff:Let M∀i ∈ I, (Xi = 1) ⇔ val(i) ≥ min{val( j) |(2)(cid:17) = {freq}, the closedness constraint ensures that a pattern has no superset with the same frequency. If item ibelongs to x, it is obvious that freq(x ∪ {i}) = freq(x). Conversely, if freq(x ∪ {i}) = freq(x), then i must belong to x (if not, xj ∈ x}Let MW. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6961would not be maximal for inclusion). freq(x) is encoded as the constraint closedM(cid:17) (x) is encoded using Eqs. (1) and (3).∀i ∈ I, (Xi = 1) ⇔(cid:10)t∈TTt × (1 − dt,i) = 06.5. Freeness constraints(cid:2)t∈T Tt and freq(x ∪ {i}) is encoded as (cid:2)t∈T Tt × dt,i . Finally, (3)Similar to the closedness constraint, we now give two examples of encoding of the freeness constraint. Following our (cid:17) = {max} because principle of dealing with measures used in the experiments, we give the examples of Mapplying the minimal converter c on mean gives max (cf. Table 4).(cid:17) = {freq} and M(cid:17) = {max} and val( j) a function that associates an attribute value to each item j. If item i does not belong to x, then its value must be greater than or equal to the min. Conversely, if this value is greater than or equal to the min, then i cannot belong to x (if i belongs to x, x would not be minimal for inclusion). Item i does not belong to x is encoded as ( Xi = 0). So, x is a free pattern for the measure max iff:Let M∀i ∈ I, (Xi = 0) ⇔ val(i) ≤ max{val( j) |j ∈ x}(4)Let M(cid:17) = {freq}, the freeness constraint ensures that a pattern has no subset with the same frequency. If item i does not belong to x, it is obvious that freq(x \ {i}) = freq(x). Conversely, if freq(x \ {i}) = freq(x), then i must not belong to x (if ibelongs to x, x would not be minimal for inclusion).In order to encode freq(x \ {i}), we introduce Boolean variables T(cid:17)t,i such that the relationship between x \ {i} and T is modeled by posting reified constraints stating that, for each transaction t, (T= 1) iff x \ {i} is a subset of t:(cid:17)t,i∀t ∈ T , (T(cid:17)t,i= 1) ⇔(cid:10)j∈I\{i}X j × (1 − dt, j) = 0freq(x) is encoded as (cid:2)t∈T Tt and freq(x \ {i}) is encoded as (cid:10)∀i ∈ I, (Xi = 0) ⇔(Tt − T(cid:17)t,i) = 0(cid:2)t∈T T(cid:17)t,i . So freeM(cid:17) (x) is modeled using Eqs. (1) and (6).(5)(6)t∈T6.6. Solving the running example using DynCSPWe now illustrate CP+Sky on the running example in Table 1a with M = {freq, area}. We use the maximal converter cand thus the closedness constraint. As c(area) = freq, we get M(cid:17) = {freq}. Fig. 5 depicts the various steps of the resolution.Let P 1 be the associated DynCSP (see Section 6.2). P 1 = ({x}, L, q1(x)) where query q1(x) = closedM(cid:17) (x). Its first solution is pattern s1 = ABCDEF (with freq(s1) = 2 and area(s1) = 12), cf. Fig. 5a. So, we consider query q2(x) = closedM(cid:17) (x) ∧ (s1 (cid:18)(cid:15)M x)stating that we are looking for a closed pattern x not dominated by s1 = ABCDEF. Its first solution is pattern s2 = AB (with freq(s2) = 3 and area(s2) = 6), cf. Fig. 5b. Then, the next query is q3(x) = closedM(cid:17) (x) ∧ (s1 (cid:18)(cid:15)M x) ∧ (s2 (cid:18)(cid:15)M x) stating that we are looking for a closed pattern x neither dominated by s1 nor s2. Its first solution is pattern s3 = AC (with freq(s3) = 3and area(s3) = 6), cf. Fig. 5c. The next query is q4(x) = q3(x) ∧ (s3 (cid:18)(cid:15)M x) whose first solution is s4 = A (cf. Fig. 5d) and then query q5(x) = q4(x) ∧ (s4 (cid:18)(cid:15)M x). q5(x) has no solution since the dominated area cannot be enlarged further and the process ends at n = 5.In this example, note that all extracted patterns are skypatterns (i.e. there are no intermediate patterns). The CSP system did not generate solutions that do not satisfy the dominance relation. Experiments in the next section provide examples with intermediate patterns.7. ExperimentsWe first report an experimental study on several UCI benchmarks (see Section 7.1). We then discuss the practical use of skypatterns in a chemoinformatics case study (see Section 7.2). All experiments were conducted on a personal computer running a Linux operating system with an i3 core processor with a clock speed of 2.13 GHz and 4 GB of RAM. The imple-mentation of Aetheris refers to [1]. The implementation of CP+Sky was carried out in Gecode. All source codes and data sets are publicly available at https://forge.greyc.fr/projects/skymining/files.Note that it was shown in [1] that Aetheris always outperforms a baseline approach by at least a factor of 10. In addition, the collection of skypatterns is always much smaller than the collection of patterns returned by an optimal constraint-basedapproach (i.e. assuming that an ideal end-user is able to perfectly set the thresholds and then run a usual constraint-based mining method). Therefore, this empirical study focuses on the comparison between Aetheris and CP+Sky.62W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–69Fig. 5. Solving the running example using DynCSP.7.1. Experiments on UCI benchmarks7.1.1. Experimental protocolWe focused on 23 different (in terms of dimensions and density5) datasets (see the left column in Table 5) from the UCI6 repository. We considered the set of measures M = {freq, max, area, mean, growth-rate} and selected 6 subsets: M1 = {freq, area, mean, growth-rate}, M2 = {freq, max, area, growth-rate}, M3 = {freq, max, area, mean}, M4 = {freq, max, mean,growth-rate}, M5 = {max, area, mean, growth-rate} and M6 = M. Measures using numeric values, like mean or max, were applied to randomly generated attribute values (within the range [0, 1]).For each method, we report the CPU-time and the number of skypatterns for every query on the selected set of measures. and then applies the Sky operator on the extracted Note that Aetheris first computes the set of closed patterns7 w.r.t. Mcollection. On the other hand, CP+Sky does not mine closed patterns as a first step but instead computes a small set of candidates using DynCSP and then applies the Sky operator. For each method, the reported CPU-times include the different and the number of processing steps. We also report for each dataset the size of the condensed representation w.r.t. Mcandidates to respectively analyze the behaviors of Aetheris and CP+Sky.(cid:17)(cid:17)7.1.2. Performance analysisA general overview Table 5 provides the results of CPU-times for CP+Sky and Aetheris for 138 skypattern queries (23 × 6). We report for each dataset and for every collection of measures8:• the number of skypatterns (the largest output is 478),• with CP+Sky: the number of candidates and the associated CPU-time,• with Aetheris: the number of closed patterns and the associated CPU-time.Table 5 indicates that CP+Sky and Aetheris run within the same order of magnitude. On 16 datasets out of 23, CPU times for both CP+Sky and Aetheris are very small (less than 30 seconds). The results of the 7 remaining data sets are analyzed in more detail to highlight the differences and limitations of our proposed methods.(cid:2)5 The density of a dataset is 6 http://www.ics.uci.edu/~mlearn/MLRepository.html.7 We use an absolute minimal frequency threshold of 1.8 Reported values in columns (6–9) are associated to M6. But, reported values in columns (10–14) represent average values over M1, M2, M3, M4 and M5.t∈T |t|/(|T | × |I|).W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6963Table 5Comparing the two methods on 23 UCI datasets (a detailed summary).DatasetM6 = {freq, max, area, mean, growth rate}#items#transactionsabaloneannealaustralbreastclevecmccrxgermanglasshearthepatichorsehypoirislymphmushroomnew-thyroidpagepimatic-tac-toevehiclewinezoo2868554343285976343845754715591192135262958454341777986902863031473690100021627015530031631501428124215941768958846178101density0.3210.1950.2720.2310.3250.3570.2690.2760.2950.3680.4210.2350.3890.3330.3220.1930.2870.3140.3460.3440.3270.3110.394#ofskypatterns7618717238976214330852154237634787161176159253822804356CP+SkyAetheris#ofcandidates525513,90349,379231119,37012,76078,327347,957263316,96041,09628,275221,0328626,20014,5992004482140011,206164,15277804654Time(s)2512241812444261610274691711861831117221#ofclosedpatterns994735,152243,156772177,20325,649349,7213,662,911716572,618222,333191,1771,604,86493116,0301,153,22928821,12112,55943,318745,35336,67114,431Averages over {M1, M2, M3, M4, M5}#CP+SkyAetherisTime(s)132018155652183147893126548121313841ofskypatterns43.2080.6077.0023.6051.8036.0059.40121.8031.8073.60103.2034.20204.805.8064.0075.4012.0049.0032.4051.20126.2025.4034.20#ofcandidates3393.206748.2019,626.801374.2011,215.807702.8031,482.80148,255.401587.809118.0016,156.2012,609.60145,359.4072.4012,532.405767.60151.802576.00943.807867.4073,390.604538.602642.60Time(s)6618159192491441630314113716396921#ofclosedpatterns9808.8030,606.00228,115.207369.2074,670.8025,408.60317,090.203,525,072.406920.8070,124.20206,742.00182,982.201565,797.2091.80105,260.00995,808.40285.0020,207.8012,439.4042,902.20689,937.8034,397.0012,851.20Time(s)11131412730514132348111122111128421A more detailed analysis Fig. 6 depicts a scatter plot of CPU-times for CP+Sky and Aetheris. Each point represents a sky-pattern query for one of the 7 selected datasets: its x-value (log-scale) is the CPU-time obtained with CP+Sky, its y-value (log scale) the CPU-time with Aetheris. A specific color is associated to each dataset. The line y = x draws the case where Aetheris and CP+Sky have the same CPU-times. Most of the points are above this line, which means a longer runtime for Aetheris. With all the measures (i.e. M6), the speed-up is 1.9 (resp. 1.53) on hypo (resp. german). The only exception is the mushroom dataset.Another interesting result provided by Table 5 is the number of closed patterns extracted by Aetheris in comparison with the number of candidates generated by CP+Sky. The number of candidates remains small (in the thousands) compared to the number of closed patterns (in millions). Fig. 7 illustrates this particular result for the selected datasets. It reports for each set of measures Mi (i ∈ [1, 6]) and the 7 datasets investigated in Fig. 6, the number of closed patterns, the number of candidate patterns and the number of skypatterns (both methods). This figure highlights the discrepancy between the methods with the distinct lower number of representative patterns required by CP+Sky in comparison to the Aetheris method.Table 6 shows an in-depth comparison of the CPU-times for the two steps performed by CP+Sky and Aetheris for the set of measures M6. The second (i.e. the post-processing) step is the same for both methods and is performed using the same classical algorithm: the BNL approach [21]. The time complexity of this approach is O(n2) where n is the number of representative patterns generated in the first step. These results clearly show that CP+Sky takes less time than Aetheris to generate the representative patterns. This is in part explained by the huge number of closed patterns that Aetheris needs to post-process. This drawback does not exist for CP+Sky because the number of candidates remains small and thus, the post-processing step is negligible. The only exception is for the mushroom dataset, where Aetheris is very efficient.7.1.3. SummaryNo method is constantly better on all datasets. CP+Sky usually generates a low number of candidates compared to Aetheris. The numbers of candidates and closed patterns seem to provide an appropriate explanation of the performances of the two methods. However, they only constitute simple indicators and do not take into account other evidence. For instance the results on the mushroom dataset may seem surprising and counter-intuitive. Even if the number of candidates (14,599) is low compared to the number of closed patterns extracted from this dataset (1,153,229), Aetheris is more efficient than CP+Sky.The mushroom dataset (which is the largest UCI dataset both in terms of transactions and items) has the lowest density (around 18%), which implies that its number of closed patterns is small w.r.t. its size. The same reasoning also applies for 64W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–69Fig. 6. Comparing CPU times on the 7 selected datasets for Mi , i ∈ [1..6].Fig. 7. Comparing # of patterns on the 7 selected datasets for M1, . . . , M6.the number of candidates. In this case, the size of the set of constraints is important, as there are as many reified constraints as transactions (cf. Section 6.3). So, filtering takes much more time to generate the candidates. For this dataset, it is more efficient to compute the closed patterns and filter them, even if they are more numerous.Following the mushroom dataset analysis, we investigated the notion of density and its impact on the performances of our two methods by generating several datasets and varying their density from 0.15 to 0.65 (we kept the numbers of W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6965Table 6Comparing the CPU times for the two steps on the 7 selected datasets for M6.Dataset# of skypatterns# of candidates patternscrxgermanhepatichorsehypomushroomvehicle1433082376347817628078,327347,95741,09628,275221,03214,599164,152CPU-times (seconds)Step 14442510264681186171Step 20101101Total4442610274691186172# of closed patterns349,7213,662,911722,333191,1771,604,8641,153,229745,353CPU-times (seconds)Step 1405112333812497111Step 215141814835127Total556523147893548138Fig. 8. Measuring the impact of the density for the two methods.items and transactions similar to the mushroom dataset). Fig. 8 shows the evolution of CPU-times according to the density for both methods. As the items in the data are randomly generated to provide the density value, the number of closed patterns increases according to the density. Thus, the running time of Aetheris also increases according to this parameter. The behavior of CP+Sky is more complex due to the dynamic pruning. Having more candidate skypatterns is a benefit if these patterns are able to prune significantly the search space. The experimental study shows a good trade-off with a density close to 0.5 (note that in practice there are very few real-world datasets with a density higher than 0.5).We also performed experiments on other data sets from the UCI repository, such as the chess (75 items, 3196 transac-tions, density 0.49) and the connect data sets (129 items, 67,557 transactions, density 0.33). However, we were not able to complete the skypattern mining process. Aetheris was not able to complete the closed pattern mining step on either data set. For CP+Sky, the first step of candidates generation took approximatively 20 hours and generated more than 40 mil-lion candidates for the chess dataset. The application of the sky operator failed because of the quadratic complexity (i.e. O(n2)) of the BNL method. The experiments on the connect dataset with CP+Sky were aborted after more than 24 hours of computation.7.2. Case study: discovering toxicophoresA major issue in chemoinformatics is to establish relationships between chemicals and their activity in (eco)toxicity. Chemical fragments9 which cause toxicity are called toxicophores and their discovery is at the core of prediction models in (eco)toxicity [56]. The aim of this study, which is part of a larger research collaboration with the CERMN Lab, is to investigate the use of skypatterns for discovering toxicophores.9 A fragment denotes a connected part of a chemical structure having at least one chemical bond.66W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–69Table 7Skypattern mining on ECB dataset.Skypatterns# of skypatternsCP+SkyM1 = {growth-rate, freq}M2 = {growth-rate, aromaticity}M3 = {freq, aromaticity}M4 = {growth-rate, freq, aromaticity}852217.2.1. Experimental protocol# of candidates613140456869CPU-time18m:34s15m:32s16m:45s17m:49sAetheris# of closed patterns41,88753,201157,91169,827CPU-time19m:20s21m:33s21m:16s21m:40sThe dataset was collected from the ECB web site.10 For each chemical, the chemists have associated it with hazard statement codes (HSC) in 3 categories: H400 (very toxic, CL50 ≤ 1 mg/L), H401 (toxic, 1 mg/L < CL50 ≤ 10 mg/L), and H402 (harmful, 10 mg/L < CL50 ≤ 100 mg/L). We focus on the H400 and H402 classes. The dataset T consists of 567 chemicals (transactions), 372 from the H400 class and 195 from the H402 class. The chemicals are encoded using 1450 frequent closed subgraphs (items) previously extracted11 with a 1% relative frequency threshold. Therefore, the extracted skypatterns correspond to sets of chemical fragments, which are represented by frequent closed subgraphs [57].Discovering candidate toxicophores is similar to supervised descriptive rule discovery [11], and or learning classification rules, and we therefore use growth rate as a contrast measure. Indeed, when a pattern’s frequency strongly increases from class H402 to class H400, it can be considered a potential structural alert related to toxicity. If a compound includes several such fragments in its graph structure, it is more likely to be toxic. Emerging patterns model this idea using the growth rate measure. On the other hand, real-world datasets are often noisy and patterns with low frequency may be artefacts. We also use the frequency measure to ensure the representativeness of the patterns (i.e. the higher the frequency, the better).The skypattern framework makes it possible to integrate measures coming from the background domain. In ecotoxicity, chemists know that the aromaticity measure is a chemical property that favors toxicity since their metabolites can lead to very reactive species which can interact with biomacromolecules in a harmful way (the higher the aromaticity, the higher the toxicity hypothesis). The chemical knowledge provides the aromaticity of the chemical fragments and we compute the aromaticity of pattern as the mean of the aromaticity of its chemical fragments.We tested several combinations of measures: M1 = {growth-rate, freq}, M2 = {growth-rate, aromaticity}, M3 = {freq,aromaticity} and M4 = {growth-rate, freq, aromaticity}.7.2.2. Performance analysisTable 7 reports, for each set of measures Mi ∈ [1..4]: (i) the number of skypatterns, (ii) for CP+Sky, the number of candidates and the associated CPU-time and (iii) for Aetheris, the number of closed patterns and the associated CPU-time. CP+Sky outperforms Aetheris in term of CPU-times. Moreover, the number of candidates for CP+Sky is drastically smaller than the number of closed patterns computed by Aetheris. It clearly shows the usefulness of filtering via the dynamically posted constraints.7.2.3. Qualitative analysisWe now analyze the skypatterns qualitatively by comparing them with well-known environmental toxicophores [58]. With the growth rate and frequency measures (i.e. M1), only 8 skypatterns are found, among those we have emphasized 3 well-known toxicophores. Fig. 9a depicts these skypatterns denoted P i , one of them is on the y-axis. Two of them are components of widespread pesticides, namely the chloro-substituted aromatic ring ( P 1: {Clc}) and organo-phosphorus moiety ( P 3: {OP, OP=S}). The third one, the phenol ring ( P 2: {c1(ccccc1)O}) is related to hydrophobocity and formation of free radicals [59].The most interesting results follow from the addition of the background knowledge. Indeed, adding the aromaticity measure leads to skypatterns with novel chemical characteristics. We discuss the results obtained with the growth rate, frequency and aromaticity measures (i.e. M4). Once again, the whole set of skypatterns remains small and can lends itself to straight-forward analysis. 21 skypatterns are mined (see Fig. 9b). To simplify the picture, the S i denote sets of skypat-terns sharing a common chemical feature. The figure emphasizes several environmentally hazardous chemical fragments: the phenol ring (S4), the chloro-substituted aromatic ring (S3), the alkyl-substituted benzene (S2), and the organophospho-rus moiety ( P 1). Besides, information dealing with nitrogen aromatic compounds is also extracted (S 1). The comparison of this list of patterns with jumping emerging fragments (JEF) extracted from previous experiments [60] highlights the gener-alization potency of the skypatterns. As an example, the organophosphorus moiety skypattern is a generalization of around 90 JEFs and can be seen as a kind of maximum common structure (i.e. consensus structure) of these fragments.The main result of the study concerns the chemical interpretation of the outputs. Indeed, the generalization capability of the skypatterns leads to a reduced list of potential toxicophores easily interpretable by the chemists (cf. Fig. 10). Even if the skypattern process is complete with respect to the user preferences and the dataset, the proposed list of toxicophores 10 European Chemicals Bureau: http://echa.europa.eu/.11 A chemical Ch contains an item A if Ch supports A, and A is a frequent subgraph of T .W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6967Fig. 9. Analyzing the skypatterns.Fig. 10. Examples of environmentally hazardous compounds related to skypatterns S4, S3, S2, P1, and S1.depends on the composition of the used dataset and the measures. We cannot hope to discover all the ecotoxicological structural alerts in one pass, because we cannot expect that all the structural alerts are present in a single dataset. But any progress in the discovery of potential toxicophores is a valuable step. The method can suggest new compounds as toxicophores, i.e. toxicophores which were previously unknown. Further in vitro experiments are required to validate such candidate toxicophores.Note that adding the p-value as a measure in order to provide a statistical significance in the skypatterns does not change the results in this experiment. Indeed, p-value is maximized by the closed patterns adequate to frequency and with the set of measures M5 = {growth-rate, freq, aromaticity, p-value} only the aromaticity leads to another closed patterns. Out of curiosity, we ran the experiment with M5 and we get 28 skypatterns instead of 21 with M4 (the 21 skypatterns extracted with M4 are still skypatterns with M5). There are no significant new insights from a chemical point of view.8. Conclusion and perspectivesIn this paper, we investigate in detail the skyline pattern mining problem by studying the theoretical relationships between condensed representations of patterns and skypatterns. Based on the concept of skylineability, we have devised the static method Aetheris and the dynamic method CP+Sky. Aetheris exploits the condensed representations of patterns to provide a proper superset of skypatterns on which to apply the Sky operator. CP+Sky iteratively refines the skyline constraints using the extracted patterns. This leads to better pruning of the search space. Our approach generates the complete set of skypatterns in a generic manner (i.e. with a large set of measures that includes statistical assessments such as the p-value). The practical goal is to make the result of pattern mining useful from a user-preference point of view. One strength of the approach lies in the fact that no threshold has to be set, the end-user only needs to specify as input the dataset and the set of measures she is interested in.An extensive empirical study as well as a case study from chemoinformatics show the efficiency and effectiveness of our two algorithms according to both quantitative and qualitative aspects. Despite the gain in generality brought by the CSP framework and the fact that Aetheris benefits from the pruning strategies based on the anti-monotonicity to extract patterns, CP+Sky competes with Aetheris and even outperforms it in some cases. However, with CP+Sky, the search order of the patterns may significantly impact the efficiency of the CSP solver. Investigating the most beneficial order in which patterns are enumerated is a promising research direction to maximize the effectiveness of the strategy of dynamically posting constraints.68W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–69Skypattern mining can generally be applied to a wide range of problems by adapting either the language or the domi-nance relation. For instance, the language of sequences or graphs can also produce skypatterns. The dominance relation can be changed or extended to take into account different other criteria for user-preferences. We sketch now these two issues.Language Our formalization, and especially the skylineability notion, is general enough to be applied to a large set of languages (sequences, trees and graph for instance). However, a change in the language can impact the efficiency of the extraction methods. Regarding Aetheris, the efficiency of the approach is based on Theorem 1 involving the distinct and indistinct operators. As aforementioned, with itemset patterns and the frequency measure, the distinct operator corresponds to the well-known closed or free condensed representations of frequent patterns. Consequently, the efficient extraction of skypatterns for more complex languages (i.e. skyline sequential patterns or skyline graph patterns) is strongly tied to the advances and progress on complex condensed representations of patterns.Evaluating the distinct operator on more complex patterns efficiently such as sequences, trees and graphs implies addi-tional challenges. To cite one, in the case of sequences, convenient properties such as the free patterns apriori property [61], which implies effective search space pruning, cannot be used. However, there are already many methods of extraction ded-icated to closed sequential patterns, closed graphs and so on. Extending CP+Sky to other languages is a challenging task due to the difficulty of modeling complex patterns. To the best of our knowledge, only certain types of pattern in sequence mining have been successfully studied [62,63].Dominance relation The dominance relation contains two components: the measures for which basic preferences are ex-pressed (e.g., frequency, area) and the combination of these basic preferences (here, the Pareto composition). Primitive-based measures are flexible enough to allow the user to express a wide variety of criteria. Indeed, classical interestingness mea-sures for pattern mining (such as frequency, growth rate), utility functions and measures of statistical significance (like the p-value) fall within this framework. Of course, Aetheris, as mentioned above, depends again on condensed representa-tions that are well-adapted for the desired measures. Conversely, all interestingness measures are easily expressible with CP+Sky. Through its declarative nature, CP+Sky offers via CSP a very flexible way to change the dominance relationship. For instance the strict dominance (i.e. a pattern is dominated by another pattern when the latter has a better value for all measures in M), is easily configurable with CSP and this relaxation of the dominance relation leads to the mining of soft-skypatterns [2].Exploratory skypattern mining We think that the skypattern mining is particularly well suited to exploratory research. In-deed, a strength of our approach is to propose a reduced collection of patterns to the data expert who can quickly analyze it. It would be interesting to integrate the user feedbacks to make skypattern mining more iterative and more exploratory. An interesting avenue is to offer an interactive way to refine the preference criteria by computing the skypattern cube according to all possible subsets of measures [64] and then assist the user with an intuitive navigation. We claim that the skypattern cube exploration will provide a better understanding of the impact of the measures on the problem at hand. Other kinds of interactions are also possible, such as discarding a skypattern to reveal patterns that were previously dominated and could become interesting.AcknowledgementsThis work is partly supported by the ANR (French Research National Agency) funded projects FiCoLoFo ANR-10-BLA-0214 and Hybride ANR-11-BS002-002.References[1] A. Soulet, C. Raïssi, M. Plantevit, B. Crémilleux, Mining dominant patterns in the sky, in: ICDM, IEEE Computer Society, 2011, pp. 655–664.[2] W. Ugarte, P. Boizumault, S. Loudni, B. Crémilleux, A. Lepailleur, Mining (soft-) skypatterns using dynamic CSP, in: CPAIOR, in: LNCS, vol. 8451, Springer, [3] M.J. Zaki, K. Sequeira, Data mining in computational biology, in: S. Aluru (Ed.), Handbook of Computational Molecular Biology, in: Computer and Information Science Series, Chapman & Hall/CRC Press, 2006, pp. 1–26, Ch. 38.[4] J. Gasteiger, T. Engel, Chemoinformatics: A Textbook, Wiley VCH, Weinheim, 2003.[5] L. Backstrom, D.P. Huttenlocher, J.M. Kleinberg, X. Lan, Group formation in large social networks: membership, growth, and evolution, in: SIGKDD, [6] L. Backstrom, J.M. Kleinberg, R. Kumar, Optimizing web traffic via the media scheduling problem, in: SIGKDD, ACM, 2009, pp. 89–98.[7] W. Fan, M. Miller, S.J. Stolfo, W. Lee, P.K. Chan, Using artificial anomalies to detect unknown and known network intrusions, in: ICDM, IEEE Computer 2014, pp. 71–87.ACM, 2006, pp. 44–54.Society, 2001, pp. 123–130.[8] R. Agrawal, T. Imielinski, A.N. Swami, Mining association rules between sets of items in large databases, in: SIGMOD, ACM Press, 1993, pp. 207–216.[9] H. Mannila, H. Toivonen, Levelwise search and borders of theories in knowledge discovery, Data Min. Knowl. Discov. 1 (3) (1997) 241–258.[10] S. Wrobel, An algorithm for multi-relational discovery of subgroups, in: PKDD, in: LNCS, vol. 1263, Springer, 1997, pp. 78–87.[11] P.K. Novak, N. Lavrac, G.I. Webb, Supervised descriptive rule discovery: a unifying survey of contrast set, emerging pattern and subgroup mining, [12] F. Geerts, B. Goethals, T. Mielikäinen, Tiling databases, in: DS, in: LNCS, vol. 3245, Springer, 2004, pp. 278–289.[13] F. Bonchi, F. Giannotti, C. Lucchese, S. Orlando, R. Perego, R. Trasarti, A constraint-based querying system for exploratory pattern discovery, Inf. Syst. J. Mach. Learn. Res. 10 (2009) 377–403.34 (1) (2009) 3–27.[14] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal, Efficient mining of association rules using closed itemset lattices, Inf. Syst. 24 (1) (1999) 25–46.W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6969[15] T. Calders, B. Goethals, Non-derivable itemset mining, Data Min. Knowl. Discov. 14 (1) (2007) 171–206.[16] J. Boulicaut, A. Bykowski, C. Rigotti, Free-sets: a condensed representation of boolean data for the approximation of frequency queries, Data Min. Knowl. Discov. 7 (1) (2003) 5–22.graphs, J. Intell. Inf. Syst. (2013) 1–29.[17] S. Bistarelli, F. Bonchi, Soft constraint based pattern mining, Data Knowl. Eng. 62 (1) (2007) 118–137.[18] W. Ugarte, P. Boizumault, S. Loudni, B. Crémilleux, A. Lepailleur, Extracting and summarizing the frequent emerging graph patterns from a dataset of [19] Y. Ke, J. Cheng, J.X. Yu, Top-k correlative graph mining, in: SDM, SIAM, 2009, pp. 1038–1049.[20] J. Wang, J. Han, Y. Lu, P. Tzvetkov, TFP: an efficient algorithm for mining top-k frequent closed itemsets, IEEE Trans. Knowl. Data Eng. 17 (5) (2005) 652–664.[21] S. Börzsönyi, D. Kossmann, K. Stocker, The skyline operator, in: ICDE, IEEE Computer Society, 2001, pp. 421–430.[22] J.L. Bentley, H.T. Kung, M. Schkolnick, C.D. Thompson, On the average number of maxima in a set of vectors and applications, J. ACM 25 (4) (1978) [23] T. Calders, C. Rigotti, J. Boulicaut, A survey on condensed representations for frequent sets, in: Constraint-Based Mining and Inductive Databases, in: [24] R.T. Ng, L.V.S. Lakshmanan, J. Han, A. Pang, Exploratory mining and pruning optimizations of constrained association rules, in: SIGMOD, 1998, LNCS, vol. 3848, Springer, 2005, pp. 64–80.536–543.pp. 13–24.[25] A. Siebes, J. Vreeken, M. van Leeuwen, Item sets that compress, in: SDM, SIAM, 2006, pp. 395–406.[26] A.J. Knobbe, E.K.Y. Ho, Pattern teams, in: ECML/PKDD, in: LNCS, vol. 4213, Springer, 2006, pp. 577–584.[27] L.D. Raedt, A. Zimmermann, Constraint-based pattern set mining, in: SDM, SIAM, 2007, pp. 237–248.[28] B. Bringmann, A. Zimmermann, The chosen few: on identifying valuable patterns, in: ICDM, IEEE Computer Society, 2007, pp. 63–72.[29] G.C. Garriga, P. Kralj, N. Lavrac, Closed sets for labeled data, J. Mach. Learn. Res. 9 (2008) 559–580.[30] K. Kontonasios, T.D. Bie, An information-theoretic approach to finding informative noisy tiles in binary databases, in: SDM, SIAM, 2010, pp. 153–164.[31] W. Hämäläinen, M. Nykänen, Efficient discovery of statistically significant association rules, in: ICDM, IEEE Computer Society, 2008, pp. 203–212.[32] A. Gallo, T.D. Bie, N. Cristianini, MINI: mining informative non-redundant itemsets, in: PKDD, in: LNCS, vol. 4702, Springer, 2007, pp. 438–445.[33] A. Gionis, H. Mannila, T. Mielikäinen, P. Tsaparas, Assessing data mining results via swap randomization, in: SIGKDD, ACM, 2006, pp. 167–176.[34] M. Mampaey, N. Tatti, J. Vreeken, Tell me what I need to know: succinctly summarizing data with itemsets, in: SIGKDD, ACM, 2011, pp. 573–581.[35] T. Guns, S. Nijssen, L.D. Raedt, Itemset mining: a constraint programming perspective, Artif. Intell. 175 (12–13) (2011) 1951–1983.[36] L.D. Raedt, T. Guns, S. Nijssen, Constraint programming for itemset mining, in: SIGKDD, ACM, 2008, pp. 204–212.[37] M. Khiari, P. Boizumault, B. Crémilleux, Constraint programming for mining n-ary patterns, in: CP, in: LNCS, vol. 6308, Springer, 2010, pp. 552–567.[38] H.T. Kung, F. Luccio, F.P. Preparata, On finding the maxima of a set of vectors, J. ACM 22 (4) (1975) 469–476.[39] J. Matousek, Computing dominances in eˆn, Inf. Process. Lett. 38 (5) (1991) 277–278.[40] R.E. Steuer, Multiple Criteria Optimization: Theory, Computation and Application, John Wiley, 1986, 546 pp.[41] D. Papadias, Y. Tao, G. Fu, B. Seeger, Progressive skyline computation in database systems, ACM Trans. Database Syst. 30 (1) (2005) 41–82.[42] K. Tan, P. Eng, B.C. Ooi, Efficient progressive skyline computation, in: VLDB, Morgan Kaufmann, 2001, pp. 301–310.[43] A.N. Papadopoulos, A. Lyritsis, Y. Manolopoulos, Skygraph: an algorithm for important subgraph discovery in relational graphs, Data Min. Knowl. Discov. 17 (1) (2008) 57–76.Syst. 34 (1) (2013) 75–108.[44] P. Shelokar, A. Quirin, O. Cordón, Mosubdue: a Pareto dominance-based multiobjective subdue algorithm for frequent subgraph mining, Knowl. Inf. [45] D.J. Cook, L.B. Holder, Graph-based data mining, IEEE Intell. Syst. 15 (2) (2000) 32–41.[46] M. van Leeuwen, A. Ukkonen, Discovering skylines of subgroup sets, in: ECML/PKDD, in: LNCS, vol. 8190, Springer, 2013, pp. 272–287.[47] B. Négrevergne, A. Dries, T. Guns, S. Nijssen, Dominance programming for itemset mining, in: ICDM, IEEE Computer Society, 2013, pp. 557–566.[48] F. Pennerath, A. Napoli, The model of most informative patterns and its application to knowledge extraction from graph databases, in: ECML/PKDD, in: LNCS, vol. 5782, Springer, 2009, pp. 205–220.[49] A. Soulet, B. Crémilleux, Adequate condensed representations of patterns, Data Min. Knowl. Discov. 17 (1) (2008) 94–110.[50] A. Soulet, B. Crémilleux, Mining constraint-based patterns using automatic relaxation, Intell. Data Anal. 13 (1) (2009) 109–133.[51] E. Omiecinski, Alternative interest measures for mining associations in databases, IEEE Trans. Knowl. Data Eng. 15 (1) (2003) 57–69.[52] R. Dechter, A. Dechter, Belief maintenance in dynamic constraint networks, in: AAAI, AAAI Press/The MIT Press, 1988, pp. 37–42.[53] G. Verfaillie, N. Jussien, Constraint solving in uncertain and dynamic environments: a survey, Constraints 10 (3) (2005) 253–281.[54] C. Lecoutre, Constraint Networks: Targeting Simplicity for Techniques and Algorithms, Wiley-ISTE, 2009.[55] F. Rossi, P. van Beek, T. Walsh (Eds.), Handbook of Constraint Programming, Elsevier, 2006.[56] A. Lepailleur, G. Poezevara, R. Bureau, Automated detection of structural alerts (chemical fragments) in (eco)toxicology, Comput. Struct. Biotech. J. 5 [57] B. Cuissart, G. Poezevara, B. Crémilleux, A. Lepailleur, R. Bureau, Emerging patterns as structural alerts for computational toxicology, in: Contrast Data Mining: Concepts, Algorithms, and Applications, CRC Press, 2013, pp. 269–282.[58] I. Sushko, E. Salmina, V. Potemkin, G. Poda, I.V. Tetko, Toxalerts: a web server of structural alerts for toxic chemicals and compounds with potential adverse reactions, J. Chem. Inf. Model. 52 (8) (2012) 2310–2316.[59] C. Hansch, S. McCarns, C. Smith, D. Dodittle, Comparative QSAR evidence for a free-radical mechanism of phenol-induced toxicity, Chem.-Biol. Interact. (2013) e201302013.127 (2000) 61–72.[60] S. Lozano, G. Poezevara, M. Halm-Lemeille, E. Lescot-Fontaine, A. Lepailleur, R. Bissell-Siders, B. Crémilleux, S. Rault, B. Cuissart, R. Bureau, Introduction of jumping fragments in combination with QSARs for the assessment of classification in ecotoxicology, J. Chem. Inf. Model. 50 (8) (2010) 1330–1339.[61] D. Lo, S. Khoo, J. Li, Mining and ranking generators of sequential patterns, in: SDM, SIAM, 2008, pp. 553–564.[62] E. Coquery, S. Jabbour, L. Saïs, Y. Salhi, A SAT-based approach for discovering frequent, closed and maximal patterns in a sequence, in: ECAI, in: Frontiers in Artificial Intelligence and Applications, vol. 242, IOS Press, 2012, pp. 258–263.[63] A. Kemmar, W. Ugarte, S. Loudni, T. Charnois, Y. Lebbah, P. Boizumault, B. Crémilleux, Mining relevant sequence patterns with CP-based framework, in: [64] W. Ugarte, P. Boizumault, S. Loudni, B. Crémilleux, Computing skypattern cubes, in: ECAI, in: Frontiers in Artificial Intelligence and Applications, ICTAI, IEEE Computer Society, 2014, pp. 552–559.vol. 263, IOS Press, 2014, pp. 903–908.