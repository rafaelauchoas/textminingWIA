Artiticial Intelligence 106 (1998) 267-334 Artificial Intelligence The logical foundations of goal-regression planning in autonomous agents * John L. Pollock ’ Department of Philosoph)! Univer.si~ of Arizona, PO Box 210027, Tucson, AZ 85721. USA Received 1 April 1998; received in revised form 17 August 1998 Abstract planning planning in autonomous This paper addresses the logical foundations of goal-regression rational It focuses mainly on three problems. The lirst is that goals and subgoals will often be to a conjunction we usually have to plan the resulting subplans. A logical problem arises interfere with each other. This problem has been there is satisfied. This assumption pertains to the computability agents. and to apply goal-regression conjunctions, separately for the conjuncts and then combine from the fact that the subplans may destructively partially solved in the AI literature (e.g., in SNLP and UCPOP), but the solutions proposed work only when a restrictive assumption of threats. It is argued that this assumption may fail for an autonomous complex environment. Relaxing this assumption is formulated precisely and an implementation is that goal-regression in a leads to a theory of defeasible planning. The theory that runs afoul of the Frame Problem. It is argued that a previously proposed solution to the Frame Problem legitimizes goal-regression that some restrictions must be imposed on the logical form of goals and subgoals amenable have to do with temporal-projectibility. planning, but also has the consequence to such planning. These restrictions in the OSCAR architecture rational agent operating in terms of reasoning The second problem planning proceeds is discussed. these restrictions The third problem is that the theory of goal-regression planning found in the AI literature imposes restrictive syntactical constraints on goals and subgoals and on the relation of logical consequence. leads to a generalization of the notion of a threat, related to collective Relaxing that the previously reasoning. Relaxing defeat in defeasible adequate definition of “expectable-result” no longer guarantees closure under logical consequence, rule for goal- and must be revised accordingly. That in turn leads to the need for an additional regression planning. Roughly, the rule allows us to plan for the achievement of a goal by searching for plans that will achieve states that “cause” the goal. Such a rule was not previously necessary, but becomes necessary when the syntactical constraints are relaxed. the restrictions also has the consequence ’ This work was supported by NSF grant no. IRI-9634106 ’ Email: pollock@tizona.edu. 00043702/98/$ PII: SOOO4-3702(98)00100-3 - see front matter 0 1998 Elsevier Science B.V. All rights reserved 268 J.L. Pdlock /Art&id Intdligmcr 106 (I 998) 267-334 The final result is a general semantics for goal-regression planning and a set of procedures that is It is shown that this semantics can easily handle concurrent actions, and effects, creation and destruction of objects, and causal connections provably sound and complete. quantified preconditions embodying complex temporal relationships. 0 1998 Elsevier Science B.V. All rights reserved. Keywords: Autonomous agents; Defeasible reasoning; Goal regression: OSCAR: Planning 1. Introduction as the theory develops. interested to construct for autonomous This paper addresses some logical problems theory of rational cognition is concerned with what to believe, and practical cognition that arise in the course of formulating in realistically rational agents operating a theory of plan construction is to understand how truly intelligent agents complex environments. My ultimate objective as part of the theory of plan construction in the real world. I approach can get around an attempt in such agents. Within a general rational cognition we can distinguish between epistemic cognition and practical cognition. is concerned Epistemic cognition into four parts: with what to do. We can think of practical cognition as dividing (4) plan execution. Viewing (1) goal adoption, turns out to impose constraints plan construction logical problems not satisfied by standard planning some for a theory of plan construction, to them. The focus of this paper will of those problems precisely and propose solutions in the OSCAR be theoretical, however, architecture to date. I will say more about implementation intent for rational agents. 2 This has been partially accomplished systems. These constraints generate and the purpose of this paper from this somewhat broader perspective (2) plan construction, (3) plan adoption, is to implement is to formulate the ultimate the theory roughly in constructing In this paper, I am not particularly a theory of human rational agents that we cognition. However, humans are the most successful autonomous useful to reflect upon how humans solve some know about, and so it will be occasionally is rational agents. Human plan construction that face all autonomous of the problems generally based on goal-regression planning. The basic idea is a simple one, going back at least to Aristotle. To achieve a goal, we consider an action that would achieve it under in those some specified circumstances, in circumstances those circumstances from the goal that are already achieved. The resulting through subgoals until we arrive at subgoals sequence of actions constitutes in this paper is to provide precise logical foundations becomes a subgoal. The idea is to work backwards and then try to find a way of putting ourselves in order to achieve the goal by performing the goal. My ultimate objective the action. Rutting ourselves a plan for achieving for goal-regression planning. Much work in AI has been directed at the task of formalizing regression planning. This forms the basis of a large part of AI planning result is what I will refer to as the “conventional” Section 2 I will give a precise formulation of the conventional in that section will mostly be familiar, although which I have combined and automating goal- theory, and the In planning. theory. The ideas developed in the way in them into a logically precise theory. there may be some novelty theory of goal-regression ideas and developed familiar * Pollock [34]. J.L. Polkock /Artificial Intelligence 106 (I 998) 267-334 269 theory, ra- to implement theory proposes it. In a sense to In effect, the conventional in quite the way the conventional the basic correctness of the conventional rather than by running a semi-decidable cannot in general perform goal-regression In Section 3 I will argue that, assuming tional agents situated in a complex environment planning be explained, planning must be done defeasibly algorithm. Section 4 will describe how that can be done. In Section 5 I will argue that, theory turns upon an indefen- even given the modifications of Section 4, the conventional sible assumption. In in light of Section 5. Section 6 1 will show how the conventional In Sections 7 and 8 I will suggest further modifications constraints logical consequence. The final result is a general semantics and a set of procedures illustrate tions, quantified preconditions connections planning that is provably sound and complete. The short closing sections ac- and effects, creation and destruction of objects, and causal theory imposes on goals and subgoals and on the relation of theory runs afoul of the Frame Problem. the power of this semantics by showing that it can easily handle concurrent theory must be modified temporal relationships for goal-regression aimed at relaxing and metric time. the conventional the syntactical embodying complex 2. The conventional theory of goal-regression planning planning as “(A/C) Goal-regression is based upon conditionals l G”. I will refer to C as the precondirion to the effect that if an action A I will write such a is performed under circumstances C, the goal G will be achieved. conditional of the conditional, A as the action, and G as the goal. For the time being, I will not attempt to be more precise about the logical form of these conditionals. That is a topic to which I will return in Section 5. planning, human beings make I will call these planning-connirional. explicit appeal theory into the actions from which follows the lead of STRIPS the plans are constructed in a separate reasons explicitly. Allowing database of background multiple planning-conditionals to employing plan operators with conditional [lo] in building (the “plan operators”) By contrast, most work in AI planning the same action is equivalent to planning-conditionals. from which a planner instead of storing In goal-regression these conditionals information concerning effects. ’ them Goal-regression planning aims to construct a plan for achieving a goal. But what exactly out of plan-steps, which prescribe actions. Plan-steps is a plan? Plans are constructed the same action may be cannot be identified with the actions prescribed by more than one step in a single plan. The plan-steps must be executed in a proper order, so I will take a plan to include both the set of plan-steps and the ordering of the plan-steps. they prescribe, because in a plan for the purpose of achieving In constructing step is included ultimate goal of the plan). Subgoals, subgoals step). Causal-links, mechanism a plan, we must keep track of the purpose of each plan-step. A plan- (or the in turn, are adopted for the purpose of achieving other (or the ultimate goal) 6~ performing a specific action (executing a specific plan- [24], provide a convenient introduced by McAllester these purposes. In the simplest case, I will take a causal-link some particular and Rosenblitt for recording subgoal to 3 Conditional effects are discussed by Pednault 1271. and were first implemented in UCPOP [28J 270 J L. Pollock /Artijiciul Intelligence 106 (I 998) 267-334 explanatory. the information that step 1z1 is intended structure is useful both in constructing the plan if, in the course of plan execution, its objective. fails to achieve have the form “no -+ subgoal + n2 + goal”, where II I and n2 are plan-steps. This causal- to achieve subgoal, whose purpose link encodes is to (partially) enable step n2 to achieve goal. The function of the set of causal-links in It keeps track of why the plan was built in the way it a plan is essentially the plan in the first place and was. This explanatory i.e., in repairing a plan-step to -+ ... + subgoal,, -+ n2 --+ goal1 -+ ... + goal,,,, where have the form nl + subgoal, . . . , goal,,, are finite sequences of subgoals and goals. subgoal,, A sublink of the form goal1 + goal2 in a causal-link in goal2 without a further action being required. For now there will be just one establishing and goal1 one of its conjuncts. way in which this happens. goal2 can be a conjunction In Section 7, other possibilities will be introduced. These causal-links are more complex like SNLP [24] or UCPOP [28], which just have than those employed for their use in the form nl -+ subgoal, is unnecessary constructing theorems about plans. In the general case, I will allow causal-links -+ n2. The additional complexity it for the purpose of proving things do not go as planned, plans, but it is convenient . . , subgoal,, and goal,, that goal, participates in familiar planners to include signifies to record and subgoals, to add a “dummy the purposes of plan-steps In order to use causal-links two special cases must be accommodated. A subgoal might already be true, in which case it is not established by any step of the plan. In order to record this with a causal-link, it is convenient plan and does not itself prescribe an action. We can then have causal-links step” * start*, which precedes all other steps in the of the form . + goal,. The other special is the ultimate goal of the plan. In that case there is no step to record the purpose of . . -+ *$nish* -+ goal,. For technical reasons that will be discussed below, we do not to succeed all other plan-steps. A plan will be allowed to contain “extra” *start* + subgoal1 + case occurs when the subgoal n2 for use in a causal-link. To enable ourselves n 1, we add another dummy step *finish* and then add a causal-link n 1 + goal1 + goal, + require *jnish* plan-steps . . . -+ subgoal,, + n 1 + goal1 + in the achievement of its goal. to use a causal-link that do not participate In light of the preceding considerations, to represent a plan as an ordered it is convenient (plan-steps, causal-links, ordering, goal). Useful plans can be formulated using some In this paper aimed at quadruple this representation, of our most sophisticated planning. I will confine my attention constructing plans that can be represented to the logical structure of goal-regression in this way. although this may be too simple a representation this in the final section. to accommodate I will discuss planning Goal-regression planning proceeds by performing constitutes a description several different kinds of operations. of the logical structure of goal- these operations Describing regression planning. 2.1. Null-plans The simplest case of goal-regression goal to be achieved A null-plan is already for the goal goal planning case in which true, and hence nothing needs to be done to achieve is a plan with no plan-steps and the single causal-link is the degenerate the it. J.L. Pollock /Art$cial Intelligence 106 (1998) 267-334 211 *start* -+ goal -+ *$nish* --+ goal. The degenerate case of goal-regression be regarded as proceeding in accordance with the following operation: planning can PROPOSE-NULL-PLAN Given an interest null-plan for achieving goal. in finding a plan for achieving goal, if goal is already true, propose a Note that the action prescribed by this operation consists of proposing a plan rather than it. To propose a plan is adopting a plan. To adopt a plan is to form the intention of executing simply to make it a candidate for adoption. Not all candidates are adopted. Multiple plans may be found for a single goal, and some may be better than others. Typically only the best plan found is adopted. 2.2. Goal regression The core of GOAL-REGRESSION planning consists of an operation “GOAL-REGRESSION". Regarding formulated as follows: this as an operation that proposes a plan, that I will call it can be GOAL-REGRESSION Given an interest conditionals adopt an interest in finding a plan for achieving C. If a plan subplan is proposed for achieving C, construct a plan by ti G having G as their consequent. Given such a conditional, in finding a plan for achieving G, adopt interest in finding planning- (A/C) (1) adding a new step to the end of subplan where the new step prescribes the action A, (2) ordering (3) adjusting the new step after all steps of subplan, and the causal-links Propose the new plan as a plan for achieving G. appropriately. 2.3. Splitting conjunctive goals The operations PROPOSE-NULL-PLAN and GOAL-REGRESSION do notbythemselves that I could do so by lighting a match provided by applying GOAL-REGRESSION once more to such a conjunctive planning. The subgoals generated by constitute a complete description of goal-regression if my goal is to light a For example, GOAL-REGRESSION will usually be conjunctions. I have a match and fire, I may observe 1 have tinder. GOAL-REGRESSION will thus generate I have a match and I have tinder. We will generally be unable to make further progress in our plan subgoal construction of the form (SGr & SG2). To do so would require our having a planning-conditional (A/C) N (SGI & SG2). But it is rare that we will have a single planning-conditional like subgoal. The most we can generally this that will achieve both conjuncts of a conjunctive (A I /Cl) N SGl and (AZ/ C2) l SG2, hope for is to have two separate planning-conditionals which will allow us to construct conjuncts. Given for the individual subplans for achieving each conjunct, we can then attempt to construct a plan for achieving the plans for the conjuncts. Given two plans plan1 and plan2, the conjunction separate subplans the conjunctive by merging subgoal 272 J.L. Pollock /Artz@d Intelligence 106 (199X) 267-334 of each, with the following exception. Where Gt is the goal for the plan-steps, causal-links, n 1 -+ goal, + .. . + G2 + -+ GI + *jinish* -+ G2 in plan, + plan,, we add causal-links that results be the plan from combining let plant +plun2 and ordering-constraints plan, and G2 is the goal for plan2, for each causal-link *finish* --+ G1 of plan, nT + goal: + of plan2, nl + goal, + G2 -+ (G 1 & G2) + using the following operation: these causal-links jGl-,(G1&G2)-,*~nish*-,(Gl&G2)andnT~goal;...-, instead of including and causal-link ... *jinish* -+ (G 1 & G2). Then we can plan for conjunctive goals by SPLIT-CONJUNCTIVE-GOAL Given an interest interest propose plan, +plan2 as a plan for (G 1 & G2). in finding plans plan, in finding a plan for achieving a conjunctive goal (Gt & Gz), adopt for Gt and plan2 for Gz. If such plans are proposed, There is, however, a well-recognized logical problem for planning for conjunctive goals using SPLIT-CONJUNCTIVE-GOAL. The difficulty individual conjuncts can produce plans that destructively sense that although isolation, the nature of such destructive the consequences planning about conjunctive goals. for the interfere with each other, in the their goals in to achieve both goals [6]. I will explore shortly, but before doing that let us consider has for goal-regression the separate subplans can each be expected the merged plan cannot be expected that the possibility is that planning of destructive interference interference to achieve separately The fact that plan, + plan2 cannot automatically be expected to achieve (Gt & G2) that the operation suggests goalsis not SPLIT-CONJUNCTIVE-GOAL butrather: that should actually be employed in planning for conjunctive SPLIT-CONJUNCTIVE-GOAL-SAFELY Given an interest interest in finding plans plan, in finding a plan for achieving a conjunctive goal (Gt & G2), adopt for G 1 and plan2 for G2. If such plans are proposed inte$ere with each other, propose plan, + plan2 as a plan for and do not destructively (Gt 8~ G2). Conventional AI planning algorithms work in this way, ruling out the possibility of internal that this conventional AI approach defects before proposing plans. cannot work for general-purpose rational agents, but before doing that I must lay some additional groundwork. I will argue below goal-regression in autonomous planning to withdraw Thedifferencebetween SPLIT-CONJUNCTIVE-GOAL and SPLIT-CONJUNCTIVE-GOAL- SAFELY is that the former must be viewed as a defeasible rule of practical reasoning. That is, if a plan is proposed on the basis of SPLIT-CONJUNCTIVE-GOAL, the planning agent must be prepared is subsequently discovered. then be supplemented with additional principles on the basis of plan, + plan2 planning but avoiding to base goal-regression on SPLIT-CONJUNCTIVE-GOAL-SAFELY, that principle must be made more complicated by building interference, producing something in the additional principles like the following: new plans constructed it is proposed aimed at proposing the interference. SPLIT-CONJUNCTIVE-GOAL must that aim to repair the destructive if destructive the proposal interference If instead J.L. Pollock /Art$cial Intelligence 106 (1998) 267-334 213 SPLIT-CONJUNCTIVE-GOAL-SAFELY in finding plans plan, Given an interest interest and do not destructively (G 1 & G2). If the plans do destructively of repairing plan, + plan2 so as to avoid the interference in finding a plan for achieving a conjunctive goal (GI & G2), adopt for Gz. If such plans are proposed interfere with each other, propose planl + plan, as a plan for interfere with each other, then search for a way and propose that instead. for G 1 and plun2 This is vague about how to repair plans exhibiting destructive below how to make that precise. interference, but we will see In discussing the principles that the principles SPLIT-CONJUNCTIVE-GOAL ratherthanaddendato the logical structure of plan repair, I will formulate supplementsto GOAL-SAFELY, because be clear in Section 3, however, defeasibly, using SPLIT-CONJUNCTIVE-GOAL, rather CONJUNCTIVE-GOAL-SAFELY. A planner using SPLIT-CONJUNCTIVE-GOAL to reason system of defeasible defeasibly reasoning. can be stated more simply can be used goal-regression using about plans has been constructed I will refer to it as the OSCAR planner. 4 as the principles SPLIT-CONJUNCT~VE- that way. It should in either way. I will argue planning must be done to be described that general-purpose than nondefeasibly, the OSCAR using SPLIT- 2.4. Partial-order plans Plansproducedbytheexclusiveuseof PROPOSE-NULL-PLAN, and GOAL-REGRESSION linearly, because when a plan-step will automatically order their plan-steps GOAL-REGRESSION it is ordered after all the previously a plan independent constraints unordered with respect to plan-steps is added by plan-steps. Such is a linear plan. However, when SPLIT-CONJUNCTIVE-GOAL is used to merge the ordering- from one of the subplans from the other. Such a plan is called a partial-order plan plan, + plan2 simply combines and plun2. This can plans, of plan, leave plan-steps the resulting constructed plan. It might be supposed the plan-steps, in AI planning theory, planning plans. 5 If a planner that a partial-order plan is not yet a complete plan. Before we so it seems to can execute a plan, we must decide in what order to execute that an executable plan must be linear. But there are two reasons why it is useful produce partial-order plans in the course of goal-regression recognized to produce partial-order when SPLIT-CONJUNCTIVE-GOAL is employed ordering-constraints reason planning proceeds and the merged plan (with the arbitrary additional ordering-constraints) is extended by GOAL-REGRESSION, it may then have to be merged with other plans by additional applications of SPLIT-CONJUNCTIVE-GOAL. At that point, the arbitrarily chosen interference between merged subplans, while ordering-constraints may cause destructive planning. First, as is generally is made more efficient by allowing planners linear plans, then and plun2, additional would have to be added arbitrarily. There will not in general be any over another. However, as to choose one set of additional ordering-constraints to merge plan, to produce is required ’ An experimental version of the OSCAR planner can be downloaded from http://www.u.axizona.edu/-pollock. 5 For a discussion of partial-order planning, see Weld [2X]. The matter of efficiency is addressed by Barrett and Weld 121. 274 J.L. Pollock /Artijciul Intelligence 106 (1998) 267-334 would have avoided that. The planner will thus to wait and not It is more efficient until we have to. This has become known as “least- a different choice of ordering-constraints have to backtrack and try other ordering-constraints. impose additional ordering-constraints commitment planning” There is another, If it is inessential then it may be best to wait until the time of execution [45]. less familiar reason partial-order plans are to be preferred over linear plans produced by adding arbitrary ordering-constraints. This has to do with plan execution rather than plan construction. to the structure of a plan in what order the plan-steps are executed, to decide the steps in one order rather than another which step to execute first. The cost of executing may depend upon factors not known at the time of plan construction. For example, a plan for baking bread may call for turning on the oven and for retrieving the flour from the kitchen cabinet, but leave it undetermined which to do first. If we find ourselves standing next to the oven, it may best to turn on the oven first, but if we find ourselves standing next to the cabinet it may instead be best to retrieve the flour first. Thus we may lower the cost of plan execution by adopting partial-order plans rather than linear plans. 2.5. Achieving goals Thus far I have relied on little more than common sense and introspection in describing the structure of goal-regression planning. To make further progress, and to make the notion interference precise, we must consider what the objective of goal-regression of destructive planning is supposed to be. If we can make that precise, we can use it to evaluate proposals for how to perform goal-regression planning. Presumably, the objective of goal-regression planning is to produce plans that will theory is based upon a particular achieve their goals. Under what circumstances will a plan achieve its goal? Contemporary AI planning to this question. First consider partial-order plans. A linear-ization of a partial-order plan is a linear plan that results from to linearly order the plan-steps preceding adding additional ordering-constraints its various linearizations. *jinish*. To adopt a partial-order plan is to be indifferent between Accordingly, we should define: sufficient answer A partial-order plan will achieve its goal iff every linearization goal. of it will achieve its Under what circumstances will a linear plan achieve its goal? The standard answer’ this question proceeds in terms of the technical notion of a “result of an action-sequence”. To make the standard answer work, we must also make some assumptions. The assump- of literals, and (2) that in a tions are (1) that goals are always of liter- planning-conditional als. The relaxation of these assumptions will be discussed in Section 6. Where P is atomic, it will be convenient to identify QN P with P, so that the negation of a literal is a literal. (A/C) w P, C and P are either literals or finite conjunctions or conjunctions literals7 to Let us take an action-sequence to be a linear sequence of actions. Given an action- sequence (A 1, . . , A,), define: 6 This is implicit in both the situation calculus 7 A literal is either an atomic formula or the negation of an atomic formula [25] and ADL 1271. J. L. Pollock /Artificial Intelligence 106 (I 998) 267-334 21.5 (RI) Where start-state is a set of planning- conditionals, P is a result of (AI, . . . A,,) relative to start-state and conditionals iff either: is a state of affairs and conditionals (i) n = 0 and P is true in start-state; or (ii) n > 0 and conditionals contains a conditional (A,/C) l P such that C is a (iii) n > 0, P is a result of (Al, resultof(Al,...,A,_1);8 or . conditional of the form (A,/C) ofPandCisaresultof(Al,...,A,_i);or , A,,_l), and conditionals does not contain a l -Q such that Q is either P or a conjunct (iv) n > 0 and P is a conjunction whose conjuncts are results of (A 1, . . , A,). P is a result of an action-sequence In other words, step of the action-sequence is a result of the preceding subsequence of the action-sequence, or an initial segment of the action-sequence makes P true and subsequent actions in the sequence do not reverse that. Let us define: in accordance with a planning-conditional iff either P is made true by the final whose precondition A plan is sound relative to a state start-state and a set of planning-conditionals every linearization of the plan its goal is a result of the sequence of actions prescribed by all of its plan-steps between *start* and *Jinish*, relative to start-state and the set of planning-conditionals. iff for Conventional AI planning theory makes the following assumption: Soundness Assumption. A linear plan will achieve its goal relative iff it is sound relative to start-state and the set of all true planning-conditionals. to a state start-state in assuming this. I will return to the let us follow AI planning For the moment, evaluation of the Soundness Assumption provides The Soundness Assumption theory in Section 4. the mathematical to correspond basis for a complete theory of planning. As I will now show, it enables us to prove the correctness of a of plans that will achieve their goals. The steps of the recursion used in goal-regression goal-regression recursive characterization are formulated planning. The end result in accordance with certain rules, the plans it produces will achieve their goals, and if there is a plan that will achieve a particular goal, some such plan will be found by following these rules of goal-regression proof for goal-regression plannin g. So this will be a kind of soundness and completeness planning. is a proof that when goal-regression to procedures of plan construction is performed planning Let us define: A plan is presumptively-sound and a state start-state (1) where goal subgoal, iff is the goal of the plan, the plan contains a causal-link nl -+ -_, . . . -+ subgoal,, + goal + *jinish* + goal, and relative to a set conditionals of planning-conditionals s I assume here if (A/C) l (P & Q) is in of 216 J. L. Pollock / Artijicial Intelligence 106 (I 998) 267-334 (2) for every causal-link IZ 1 + subgoall -_, . -+ suhgoul, + n2 + goal, -+ -+ goal, of the plan: (a) if II # 1, then for each i such that 1 < i < n, subgoali+, subgoali subgouq + is a conjunction, is one of its conjuncts, and the plan also contains a causal-link nT + . ’ + subgoal, + n; + . . . + snbgoaq + subgOUli+l + goal, + . . . + goal, where subgoal; (b) if m # 1, then for each i such that 1 < i c m, goali+, is one of its conjuncts, and goali nT + subgoal, + ... + subgoal,, -+ nz + goal; -F is the other conjunct of sUbgouli+, ; is a conjunction, a causal-link ... --+ ... + goal; the plan also contains ~ goali+, ~ ’ ’ ’ -+ goal, where goal; is the other conjunct of goali+, ; (c) if nl = *start* then subgoal, (d) if n2 # *finish* then if A is the action of n2, “(Alsnbgoul,) is true in start-state; N goal,” is a member of conditionals; (e) if n 1 N *start* then the plan contains a causal-link nx --+ subgoal? -+ . . + subgoal$ + nq -+ goal; + . -+ goa& + subgoal, ; and (f) n 1 is ordered before n2 by the ordering-constraints of the plan. is just to say that its causal-links then every linearization of the plan satisfies conditions encode a To say that a plan is presumptively-sound If a plan causal structure derived from the set of planning-conditionals (i), (ii), and is presumptively-sound its goal because (iv) of the definition of “result”. However, of the condition -+ . . ’ + subgoal,, + n2 -+ goal, -+ plan in which, for some causal-link n 1 -+ subgoal, . . + goal, 3 subgoal,, is a result of the sequence of actions prescribed by the plan-steps up through n1, but some step n occurs between nl and n2 which makes subgoal,., false again before it can be “used’ by n2 to achieve goal,. Let us define: In other words, there may be a linearization the plan may fail to achieve (iii) may not be satisfied. and the start-state. A plan-step n of a plan -+ n2 -+ goal, -+ .. . + goal,, to subgoul, + iff . there the plan -+ is a linearization of the plan in which n occurs between n 1 and n2 and either - subgoal, is a result of the sequence of actions or the negation of a conjunct of subgoal, prescribed by the plan-steps *start*, . . . n in the linearization to the set of all true planning-conditionals. relative I will also say that the plan itself undermines one of its causal-links does so relative to that plan. Let us define: if one of its plan-steps is causally-sound A plan planning-conditionals iff it is presumptively-sound relative to a set of true and the plan does not undermine any of its own causal-links. It is possible to prove the following theorems: Theorem 1. If a plan is causally-sound then it is sound. Theorem 2. If a goal is a result oj’ an uction-sequence causally-sound Al,....A, that goal some inthutorder plan for linearization of which prescribes (Al, . . , A,,), then there is a the actions J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 211 The proofs are in Appendix A. It is easily verified that plans produced by reasoning COAL-REGRESSION, NULL-PLAN, sound. However, because they may undermine plans, we must add some procedures if SPLIT-CONJUNCTIVE-GOAL some of their own causal-links. Thus for reasoning that find and, if possible, repair underminings. is used the plans may fail to be sound about and SPLIT-CONJUNCTIVE-GOAL in accordance with PROPOSE- are presumptively- 2.6. Searching,fi>r underminings and repairing them in essentially There are essentially is to search for underminings two ways to go about finding and repairing underminings. in a manner consistent with the plan. The subplan undermines The most straightforward the same way we search for plans. A plan is undermined by a subplan, consisting of a subset of the plan-steps of the plan the plan ordered by achieving a goal -g which is the negation of some subgoal, and doing so between the time g is achieved and the time it is used. The subplan must be sound, i.e., it must really in the context of the larger plan. achieve -g. But more is required. It must achieve -g the subplan. This is captured by adding That is, the larger plan cannot, the rest of the steps of the original plan into the subplan, even though they are not used, and requiring that the resulting plan still achieves -g. The result of adding the unused steps to the subplan is an embellishment of the original plan, which is defined as follows: in turn undermine plan0 is an embellishment plan-steps of plan, and (2) any ordering than *finish* is also imposed by plan,. of plan iff (1) the plan-steps of plan0 are the same as the imposed by plan on plan-steps of plan0 other If it does The intent of this definition not, then the definition of soundness given above ignores all plan-steps succeeding *finish*. The penultimate before *finish* in some linearization of the plan. It can then be proven: is that *finish* need not occur at the end of plaq,. steps of a plan are those occurring immediately Theorem 3. A plan-step n of a plan undermines a causal-link n 1 + subgoal, + ... + goal,* of plan subgoal,, embellishment plan0 of plan whose goal is either -subgoal, of subgoal,, and is a presumptively-sound or the negation of a conjunct -+ n2 + goal, + there . . -+ if ( 1) n is the single penultimate plan-step of planO, (2) there is a linearization of plan consistent with the ordering imposed by plan0 in which n occurs between n 1 and n2, and (3) plan, is sound. An immediate corollary of Theorems 1-3 is: Theorem 4. A plan-step n of a plan undermines a causal-link n 1 + subgoal, subgoal,, embellishment plan0 of plan whose goal is either -subgoal, of subgoal,, and of plan zff there is a presumptively-sound or the negation of a conjunct . ’ . + goal, goal, + 4 . . 4 nz 4 4 (1) n is the single penultimate plan-step ofplan”, 278 (21 (3) J.L. Pollock/Arti$ciaE Intelligence 106 (1998) 267-334 there is a linearization of plan consistent with the ordering imposed by plan0 in which n occurs between nl and n2, and plan, does not undermine any of its own causal-links. The only plan-steps of plan0 that are relevant are those not succeeding n2. We can always make plan0 linear, so Theorem 4 constitutes a recursive characterization Underminings of undermining. are produced by embellishments, to undermining the causal-link the same way we search for plans-using in essentially CONJUNCTIVE-GOAL, and an analogue of GOAL-REGRESSION plan rather Section 4. than building new plan-steps. I will postpone and we can search for embellishments PROPOSE-NULL-PLAN, that takes plan-steps the discussion SPLIT- from of this until its goal in to Once an undermined link is found, we know that the plan will not achieve ’ But it may be possible encoded in its causal-links. literature recognizes [24]. If a plan-step the causal-link n 1 + subgoal + n2 + goal, but it is consistent with of plan that n not occur between n 1 and n2, then the undermining accordance with the causal-structure modify the plan so as to avoid the undermining. The current planning is by adding ordering-constraints two ways of doing this. The simplest n of plan undermines the ordering-constraints can be avoided by adding to plan the ordering-constraint systems do this by “promoting” no. Most AI planning either before n1 or after n2. However, the constraint that n not occur between n 1 and n2, without specifying whether it occurs before n 1 or after n2. The latter decision can be left to be determined either by subsequent planning reasoning lo This suggests adopting or during plan execution. or “demoting” n, i.e., ordering impose that n not occur between n 1 and it it is also possible reasoning-schema: the following to simply ADD-ORDERING-CONSTRAINT Given an interest in finding a plan for achieving a conjunctive goal (gl & g2), and plans for gl and plan2 for g2, if plan & is a putative plan for (gl & g2) constructed by plan, merging plans plan1 and plan2 (and possibly other plans), but a plan-step n of plan & undermines one of its own causal-links . . . --+ subgoal,, + n:! + n1 -+ subgoal1 + construct a plan plan+ by adding the ordering-constraint . . + goal,, goal, + not occur between n 1 and n2 (if this can be done consistently) plan for (gr 8~ g2). that n and propose plan+ as a ADD-ORDERING-CONSTRAINT plun& might undermine more than one of its causal-links these. The other underminings would also have to be repaired, one at a time. to make a defeasible proposal, because repairs just one of must be taken and plan+ 9 The plan might still achieve its goal fortuitously, because of other planning-conditionals that might relate its plan-steps appropriately without being encoded in the causal-links. lo The OSCAR planner works this way. Adding the constraint that one node not occur between two others is equivalent to adding the disjunctive constraint that the node occur either before the earlier node or after the later node, and adding that to a partial ordering is equivalent to adopting a disjunction of partial orderings. Another planner that works this way is DESCARTES 1181. J.L. Pollock /Art$cial Intelligence 106 (1998) 267-334 219 The other recognized way of repairing underminings is called “confrontation”, due to Penberthy and Weld [28]. ” This consists of adding plan-steps way that the embellishment for the undermining responsible itself becomes undermined: and is to plan in such a CONFRONTATION .. . + goal, one of its own causal-links for gt and plan2 for g2, if plan& by virtue of there being an embellishment Given an interest in finding a plan for achieving a conjunctive goal (gl & gz), and plans is a putative plan for (gt & g2) constructed plunl by merging plans plan1 and plan2 (and possibly other plans), but a plan-step 12 of n 1 + subgoal, L+ . . + subgoal,, --+ plan & undermines that n2 -+ goal1 + or the negation of a conjunct of subgoalI, achieves P, where P is either -subgoal, -+ n + P of pZuno, adopt interest then for each causal-link for each conjunct of in finding a plan for achieving G 1, adopt interest If a plan repair-plan is proposed new plan plan+ by adding links of repair-plan, with the following form n* + SG1 + n* -+ SG1 + consistent, propose plan+ as a plan for achieving -Gt in finding a plan for achieving . . . -+ SG, + n2 --+ SG, and order n* before n. If this ordering . . . + SG, -+ *$nish* --f SG,, in repair-plan by the causal-link construct a and causal- of the or the negation of one of its conjuncts, is a conjunction, its negation). exception. Replace each causal-link the plan-steps, ordering-constraints, “Gl to plan& (gl & 82). I2 for achieving no + G1 + (or if Gl . . a -+ G, plan0 is Just as for ADD-ORDERING-CONSTRAINT, defeasible proposal. CONFRONTATION must be taken to make a I have formulated ADD-ORDERING-CONSTRAINT to SPLIT-CONJUNCTIVE-GOAL, but ments CONJUNCTIVE-GOAL-SAFELY by rewriting the latter roughly as follows: and CONFRONTATION as supple- they could instead be built into SPLIT- SPLIT-CONJUNCTIVE-GOAL-SAFELY in finding plans plan, Given an interest interest plan, + plan2 does not undermine any of its causal-links, plan for (Gl & G2). If the plan1 +pZun2 does undermine search for a way of repairing plan1 + plan, by adding ordering-constraints confrontation in finding a plan for achieving a conjunctive goal (Gt & Gz), adopt for G 1 and plan2 for G2. If such plans are proposed and propose plan1 + plan2 as a then and/or using and propose the resulting plan instead. to avoid the interference, some of its causal-links, 2.7. Searching for threats and resolving them The OSCAR planner works systems work somewhat differently. for “threats”. Let us define: in the manner just described, Instead of searching but most AI planning they search for underminings, A plan-step s of a plan plan threatens a causal-link subgoal,, + n2 -+ goal1 + ... + goal,,, of plan relative n I + subgoal1 -+ . . . + to a set conditionals of ’ ’ They actually called the technique “separation”, but it was renamed “confrontation” l2 This rule of confrontation differs from that of Penberthy and Weld in that theirs is formulated by Weld [45]. in terms of threats rather than undermining. See below. 280 J.L. Pollock /Art$cial Intelligence 106 (1998) 267-334 planning-conditionals nt and n2, and (2) there is a conditional “(A/C) the action of s and P is either subgoal, or a conjunct of subgoal,. iff (1) there is a linearization of plan in which s occurs between in conditionals where A is l -P” ignores threats result threats unless if there is a linearization like SNLP, UCPOP, or PRODIGY, or using confrontation. from conditional an embellishment making C true at the time s is executed. The they are real. By contrast, most AI planning take all threats seriously and try to resolve it effects of to be real, Threats are “potential underminings”. A threat is “real” only of plan that constitutes OSCAR planner systems, them by either adding ordering-constraints makes a difference whether actions. If a threat is produced by an unconditional the preconditional because is produced by a for the threatening conditional for some other effect of that same action established, and then the threat may not turn be real. effects, so all threats are real, but in UCPOP and In SNLP, actions have only unconditional it seems likely that in a domain of real-world PRODIGY complexity, effects. That is, the actions can, under some circumstances, the only way the action can get into the plan is by having if a threat effect already established. However, effect, then the action can get into the plan by having that is not true. Parenthetically, all effects of actions are conditional or unconditional effect, then it is guaranteed be performed without having those effects. In this connection, the precondition If a threat that is not real is resolved by adding ordering-constraints, this can lead to later in the planning unnecessary ordering-constraints, process and can also make plan execution more costly than it need be. In other words, this violates the spirit of least-commitment and that in turn can cause trouble planning. suffices for achieving It may seem that resolving steps to a plan and will be computationally a threat that is not real by using confrontation will add costly, but in fact that need not unnecessary be true. If the threat is not real then plan never makes the precondition Gt true, in which case a null-plan and resolving threats to them, etc., and failing to find it. So in fact, if the is exactly as costly as searching searches are done optimally, resolving by confrontation will not add extra plan-steps. are equally costly. The former may add extra causal-links further null-plans and resolving threats to it by constructing and repairing underminings The process of finding threats by confrontation for an undermining to a plan, but it the null-plan -Gt 2.8. Completeness A planning system is complete if, given all true relevant planning-conditionals, it can always find a plan for achieving a goal if there is one. More precisely: A planning will achieve the goal relative planning-conditionals system is complete iff for every goal and start-state, to the start-state, if there is a plan that true then when given all the relevant the planning system will find some such plan. It can be proven that a planning system that searches for plans using PROPOSE-NULL- PLAN, GOAL-REGRESSION, underminings or threats and and SPLIT-CONJUNCTIVE-GOAL, in response to finding then searches for either them modifies plans by adding J.L. Pollock /Artijcial Intelligence 106 (1998) 267-334 281 or using confrontation, ordering-constraints a complete basis result presupposes based upon the Soundness Assumption. These assumptions will be examined critically Section 4. l3 In other words, this constitutes that this and is in It should be noted, however, constraints on goals and planning-conditionals, for goal-regression the syntactical is complete. planning. 3. R.e. planning and defeasible planning Contemporary AI planning planning problem, an r.e. planner runs a program that systematically possible plans until it returns one that purports about such a planner is that it executes an effective computation. Defining to solve the problem. What is important this precisely: theory is based upon what I will call be. planners. Given a searches the space of A planner recursively enumerable. is r.e. iff the set of pairs (problem, solution) that characterize the planner is planners goal-regression are based upon is, however, an insuperable the three operations In effect, contemporary PROPOSE-NULL-PLAN, GOAL-REGRESSION, and SPLIT-CONJUNCTIVE-GOAL-SAFELY. to perform general- logical problem There purpose goal-regression such an in an autonomous algorithm. The difficulty derives from the fact that any such algorithm must use some variant of SPLIT-CONJUNCTIVE-GOAL-SAFELY to handle conjunctive that SPLIT-CONJUNCTIVE-GOAL-SAFELY wasformulatedasfollows: for attempting rational agent by running goals. Recall planning SPLIT-CONJUNCTIVE-GOAL-SAFELY in finding a plan for achieving a conjunctive goal (Gt & G2), adopt in finding plans plan1 for Gl and plan2 for G2. If such plans are proposed interfere with each other, propose pZanl + plan2 as a plan for interfere with each other, then search for a way to Given an interest interest and do not destructively (G 1 & G2). If the plans do destructively of repairing plan1 + plan2 by adding ordering-constraints avoid the interference, and propose the resulting plan instead. and/or using confrontation Destructive interference was cashed out in terms of either underminings or threats. is a goal-regression planner their conjuncts and merging if the set of destructive that works as above by splitting an the plans for the conjuncts, interferences is effectively is not effectively i.e., recursive. the planner will not be able to use SPLIT-CONJUNCTIVE-GOAL-SAFELY to If the set of destructive interferences two plans can be merged or, when there is destructive interference, Assuming that a planner goals into conjunctive r.e. planner will only be possible computable, computable, determine whether whether it can be repaired. In order for destructive to be computable, a particular (the negation of a precondition consequence of an action under specifiable circumstances. Standard AI planning it must be computable whether is a of one of the plan-steps) systems interference condition ” The proof is essentially the same as the proof of the completeness of UCPOP given by Penberthy and Weld [28]. Alternatively, see Section 4. 282 J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 this by assuming that all relevant planning-conditionals accomplish database at the time planning begins, and hence determined by simply no reasoning or very little reasoning about the consequences precompiled knowledge built into the plan operators. I4 are contained in a of actions can be the consequences them up in a table (using unification). Such planners do instead on of actions, relying looking to formalize and automate the planning of an autonomous theory has had a number of practical applications, It is useful to make a distinction between applied planning systems and planning systems rational agent and theory in which the goals are fixed and all then to the planner. The planner that are intended (e.g., a human being). AI planning is one of the success stories of AI. However, practical applications of AI planning have been largely confined to well behaved domains the relevant that searches the space of possible plans (relative to the given information) runs a program to achieve the goals. In such “applied until it finds a plan whose execution planning”, a planner is a tool used by a human being, and in order to use the tool effectively the human must prepare the ground very carefully, being sure to give the planner all the knowledge needed to solve the planning problem. can be precompiled is guaranteed and supplied information One of the ideals to which AI aspires rational through a complex, variable, and often uncooperative is the construction of autonomous ingredient the knowledge agent has exactly agent must build is that, in sharp contrast Planning will be an essential faced by such an agent contrasts that is solved by current AI planning to applied planning, agents capable of maneuvering in any such agent. However, the environment. in important ways with the kind of planning problem technology. The most applied planning problem it cannot be assumed obvious difference it needs to solve a planning problem. that a planning An autonomous its own knowledge base. The system designer can get things started by providing background knowledge, but the agent must be provided its knowledge base to grow and evolve as it gains with cognitive machinery and reasons about the experience of its environment, the more consequences I have the autonomous function distinguished between practical cognition and epistemic cognition. The principal of epistemic cognition needed for practical cognition. As such, the course of epistemic is driven by practical to the planning problem equipped with all the knowledge interests. Rather than coming required for its solution, focusing epistemic endeavors on the pursuit of information in solving current planning problems. it already holds. The more complex agent will have to be self-sufficient itself directs epistemic cognition, the planning problem senses its immediate that will be helpful agent is to provide in an autonomous the environment, the information for knowledge surroundings, acquisition. of beliefs cognition enabling among Paramount is knowledge this information if certain the agent already knows what actions are taken under certain circumstances. will happen, but often it has to figure it out. At the very least this will require reasoning the empirical acquisition of new from current knowledge. from what is already known. For knowledge agent may have to find out what time example, in order to construct a plan the planning In many cases it will require about what will happen that cannot be obtained just by reasoning Sometimes I4 This originated with STRIPS [IO], which built the requisite planning-conditionals into the plan operators themselves. Subsequent AI planners have followed suit. J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 283 if destructive in realistically it is impossible complex environments that it acquire all the than general epistemic is a matter of engaging their planning by implementing the world in some way (e.g., it planning algorithms of the sort described are carried out by performing to perform it is, and it may be able to do that only by examining such empirical In general, may have to go into the next room and look at the clock). actions (not just by reasoning). Figuring out investigations in further planning. The agent acquires what actions and then plans for how to accomplish the epistemic goal of acquiring certain information, that. So planning drives epistemic investigation which may in turn drive further planning. It follows that an essential characteristic of planning agents is that planning and epistemic to require of a planning cognition are interleaved. Unlike applied planning, agent capable of functioning requisite knowledge before beginning the plan search. Now let us apply this to the question whether human beings (and other rational agents) in is computable, interference that the consequences of actions be computable. As we have seen, agents cannot rely on precompiled knowledge. They must engage of actions, and we should not expect that about the consequences epistemic at best AT. l5 But even the set of is recursively enumerable. Even for such an interference will not be computable- can perform Section 2. As I have argued, that is only possible which in turn requires planning autonomous in genuine reasoning to be any simpler reasoning reasoning must be defeasible, which makes the set of conclusions if we could construct an agent that did only first-order deductive conclusions unrealistically the set of destructive algorithm whether find any particular destructive destructive that there is none simply on the grounds algorithm will bog down at this point and will never be able to produce for the conjunctive goal. I6 interference there will be no point at which the planner can draw the conclusion that none has been found. Thus the planning the merged plan that when the planning goal and then considers the reasoning is not computable, how can a planner get away with dividing conjunctive goals into separate conjuncts and planning for each conjunct separately? The key to this problem emerges from considering how human beings solve it. Humans assume interfere with one another, and so defeasibly infer defeasibly goal. In other is based on SPLIT-CONJUNCTIVE-GOAL rather words, human goal-regression planning than SPLIT-CONJUNCTIVE-GOAL-SAFELY. Having made this defeasible inference, human that would defeat it, but they do not regard planners to long, and if there is no that the merged plan is a good plan for the conjunctive interferences will be only r.e. This means that the separate plans do not destructively they can be merged without destructive of a conjunctive interference, interference may take indefinitely is not effectively computable-it then look for destructive reasoning. Realistically, planner, destructive for the conjuncts computes plans oversimplified If destructive interference, interference reasoning, required ” A2 sets are sometimes called “trial and error sets”. R.e. sets can be “approximated algorithm that systematically sets can only be approximated members, but doesn’t always get them right and may have to remove members this, see Pollock [34, Chapter 31. adds members without ever having “from above and below simultaneously”, from below” by an to take any out of the set. By contrast, A2 that systematically adds later. For further discussion of by an algorithm I6 Notice that a similar problem arises in applying PROPOSE-NULL-PLAN, which may require an indeterminate is already true. If the requisite reasoning that the subgoal is not at least r.e., to determine amount of reasoning then the planning cannot be r.e. 284 J.L. Pollock/Artijcial Intelligence 106 (1998) 267-334 interference to establish interference. interference makes is to begin, no destructive that there is no destructive that there is no destructive it as essential inference. And if, at the time plan execution been discovered, have not proven conclusively before they make the has interference then we humans go ahead and execute the plan despite the fact that we interference. However, that logically that there is no destructive One may be tempted to suppose that human beings are making an unreasonable leap of faith here, and that a more rational agent would postpone plan execution until it has been established the logic of the epistemic search for destructive impossible. Given a logically complex knowledge base, there will not, in general, be a point at which an agent can conclude with certainty interference within a plan, so an agent that required such certainty would be unable to complete and execute any of its plans. planners that employ SPLIT-CONJUNCTIVE-GOAL-SAFELY to reason about conjunctive goals. Might we some other kind of r.e. planner? Erol et be able to circumvent the problem of finding al. [7] prove that for a wide variety of STRIPS planning domains, in such domains. a plan is at least semi-decidable, (or equivalently, However, in which we may planning-conditionals). have to discover new planning-conditionals In fact, the following I have posed for ce. planners: and hence r.e. planners are possible this result assumes a fixed (finite) set of STRIPS operators the quite different situation in order to solve the planning problem. simple theorem shows there is no way around the problem I have raised is specifically this problem by employing that there is no destructive My point concerns for goal-regression The problem a problem Theorem 5. If the set of planning-conditionals sound solution-pairs (problem, solution) is not ze. is Ee. but not recursive, then the set qf The upshot of this is that a rational agent operating in a realistically in the course of its planning, later if subsequent epistemic complex and then be reasoning defeats in planning must be a In other words, the reasoning involved environment must make defeasible assumptions prepared to change those defeasible assumptions. species of defeasible cannot be done by an rze. planner. I’ its planning decisions reasoning. Planning by autonomous agents in complex environments 4. Reasoning defeasibly about plans The general way goal-regression goal regression, planning must work in autonomous splitting conjunctive goals into for them separately, and then merging the plans for the individual their conjuncts rational agents and conjuncts is by performing planning " Ferguson and Allen [9] describe a different use of defeasible [ 121 explores an idea related to the defeasible approach. He considers planners reasoning as a way of avoiding in [38]. Ginsberg that “almost always work”, and shows that under certain circumstances merged to form plans for conjunctions is done in the interest of planning efficiency. By contrast, accommodate in planning. They use defeasible reasoning the ramification problem. I propose my own solution to the ramification problem that find plans plans for the individual conjuncts can be incomplete planning, and to the defeasible approach described here is intended that “almost always work”. This accommodates incomplete knowledge. J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 285 interest inference such interference goal. The planning and then lead to a defeasible reasoner makes a defeasible planning becomes a form of epistemic reasoning it must adopt in finding destructive should lead the agent to try various ways of repairing the plan that the repaired plan is that the the interference, to the planning problem. The tentative conclusion being adopted agent will infer defeasibly to the planning problem. A defeater for this defeasible interference. Whenever in finding interference. into a combined plan for the conjunctive that the merged plan is a solution that the plan contains destructive inference consists of discovering inference, a defeasible defeaters, so in this case the agent will adopt interest Finding to eliminate is a solution plan will achieve its goal. Goal-regression to the effect that if a plan is executed (in any way consistent with the ordering) defeasibly GOAL-REGRESSION,SPLIT-CONJUNCTIVE-GOAL,ADD-ORDERING-CONSTRAINTS, to epistemic conclusions. CONFRONTATION, into epistemic operations inference-schemes. words, they are epistemic rules conclusions it produces deductively from the premises that follow only defeasibly. For instance, pEan, + plan2 is internally to conclude discovered (Gt & G2)shouldbewithdrawn. work similarly. then it is to expect the goal to be achieved. This turns PROPOSE-NULL-PLAN, and In other leading GOAL-REGRESSION differs from the other follow it reasonable if it is subsequently that it will achieve and CONFRONTATION is internally defective, then the conclusion ADD-ORDERING-CONSTRAINTS to which it appeals. The other rules produce conclusions defective, SPLIT-CONJUNCTIVE-GOAL makes in the absence of any reason for thinking that plunl + plan2 will achieve the Soundness Assumption) (Cl & Gz), but that plant +pkq that (given reasonable in that that This way of understanding to proceed non-defeasibly goal-regression planning contrasts sharply with conventional a variant instead of SPLIT-CONJUNCTIVE-GOAL, but as theory of goal- contexts in which the and does not have to It can only work in narrowly circumscribed from the beginning cannot work as a general by employing to planning theory, which attempts AI planning of SPLIT-CONJUNCTIVE-GOAL-SAFELY I have argued, such an approach regression planning. planner can be given all relevant knowledge engage in epistemic I will assume the general reasoning embodied theory of defeasible [34], discussed below will be based upon the implemented OSCAR in OSCAR consists of the construction of natural-deduction-style and the implementation architecture. Reasoning arguments, using both deductive Premises are input to the reasoner (either as background knowledge or as new percepts), and queries are passed to the reasoner. OSCAR performs bidirectional reasoning. The reasoner reasons forwards from the premises and backwards from the queries. The queries are “epistemic interests”, and backwards reasoning can be viewed as deriving interests from interests. rules and defeasible reason-schemas. in OSCAR inference reasoning during the course of the planning. The complete set of inference-schemes required for this approach to goal-regression planning can be formulated as follows: PROPOSE-NULL-PLAN Given an interest defeasibly that a null-plan will achieve goal. in finding a plan for achieving goal, if goal is already true, infer non- GOAL-REGRESSION Given an interest in finding a plan for achieving G, adopt interest in finding planning- 286 J. L. Pollock /Artificial Intelligence IO6 (I 998) 267-334 in finding a plan for achieving C. If it is concluded (A/C) w G having G as their consequent. Given such a conditional, adopt conditionals an interest that a plan subplun will achieve C, construct a plan by (1) adding a new step to the end of subplan where the the new step after all steps of subplun, new step prescribes and (3) adjusting that the new plan will achieve G. the action A, (2) ordering appropriately. Infer nondefeasibly the causal-links SPLIT-CONJUNCTIVE-GOAL Given an interest interest in finding plans plan, for G 1 and plan2 for Gz. If such plans are proposed, defeasibly in finding a plan for achieving a conjunctive goal (Gr & G2), adopt infer that plan, +plun2 will achieve (G 1 & G2). ADD-ORDERING-CONSTRAINT Given an interest in finding a plan for achieving a conjunctive goal (gi & g2), and plans plan1 for gr and plan2 for g2, if plan & is a putative plan for (gi & g2) constructed by merging plans plan1 and plan, (and possibly other plans), but a plan-step n of plan& undermines -+ n2 -+ that n that n 1 -+ subgoal, + construct a plan plan+ by adding the ordering-constraint goal1 + not occur between nr and n2 (if this can be done consistently) plan+ will achieve (gr & ~2). one of its own causal-links and infer defeasibly . . -+ subgoal, . . . + goal,, CONFRONTATION n1 -+ subgoal, for gr and plan2 one of its own causal-links a conjunctive is a putative plan in finding a plan for achieving for g2, if plan& goal (gi & g2), and Given an interest plans plan1 for (gr & 82) constructed by merging plans plan1 and plan2 (and possibly other plans), but a plan- -+ . . + step n of plan & undermines . . . + goal,,, by virtue of there being an embellishment subgoal,, -+ n2 + goal1 + or the negation of a conjunct . . . + G, + n + P of piano, for each If a plan or the negation of one of its conjuncts, that achieves P, where P is either -subgoal, no --+ G1 + -Gr in finding a plan for achieving plan0 of subgoalI, adopt interest conjunct of Gr, adopt interest then for each causal-link in finding a plan for achieving repair-plan construct a new plan plan+ by adding and causal-links of repair-plan, with the following exception. Replace each causal-link in repair-plan by the causal-link of the form n* -+ SG, -+ . . . + SG, *finish* --+ SG, . . . -+ SG, + n + SG, and order n* between no and n. If this ordering n* --+ SG] + infer defeasibly is consistent, (or if Gi is a conjunction, its negation). the plan-steps, ordering-constraints, that plan+ will achieve (g 1 & g2). -Gi to plan& for achieving is proposed UNDERMINE-CAUSAL-LINKS Givenaninferenceinaccordancewith CONSTRAINT, or CONFRONTATION to the conclusion adopt interest in establishing determined conclusion that it does undermine one of its own causal-links, that plan & will achieve (G 1 & G2) to be defeated. that plan & undermines one of its own causal-links. take the inference thatplan& will achieve (Gi & G2), If it is to the SPLIT-CONJUNCTIVE-GOAL, ADD-ORDERING- Let us say that a plan achieves all its penultimate its goal between two plan-steps its goal and the two plan-steps. Similarly, a plan achieves iff it achieves steps are ordered between J.L. Pollock /Ari$cial Intelligence 106 (1998) 267-334 287 its goal before a plan-step before the plan-step. UNDERMINE-CAUSAL-LINK iff it achieves its goal and all its penultimate steps are ordered in establishing that plan& undermines Given an interest for each causal-link nt -+ subgoal1 -+ . . . + subgoal,, + n2 -+ goal1 + of plan&, plan0 of plan& -g between nl and n2 consistent with the ordering-constraints either subgoal1 or a conjunct of subgoalI. Given plan,,, infer nondefeasibly undermines one of its own causal-links. one of its own causal-links, . . . + goal, that achieves of plan&, where g is that plan & in finding an embellishment adopt interest The search for embellishments schemes used in searching for plans in the first place, with the difference use only the plan-steps of plan &. They start with plan & stripped of its causal-links, simply add causal-links can be performed using analogues of the inference- that the analogues and and ordering-constraints. EMBEDDED-GOAL-REGRESSION in finding an embellishment (A/C) l G having G as their consequent after nl) consistent with a set of ordering-constraints of plan that achieves G before n2 (and Given an interest order, adopt interest optionally in finding planning-conditionals for which there is a plan-step n of plan such that (1) the action prescribed by n is A, and (2) it after nr ). Given such a is consistent with order that n occur before n2 (and optionally conditional and plan-step, that n occur before n2 (and optionally after n I), Adopt an interest in finding an embellishment of plan that achieves C before n consistent with order+. proposed for achieving C before n consistent with order+, construct an embellishment plan+ by adding a causal-link ordering-constraints plan that achieves G before n2 (and optionally after nl) consistent with order. to record the achievement of G by n and adjusting is an embellishment that plan+ let order+ be the result of adding to order the constraint If an embellishment Infer defeasibly accordingly. plan0 is the of in EMBEDDED-GOAL-REGRESSION, EMBEDDED-GOAL-REGRESSION, cause mined by other plan-steps link root and the causal-link no plan-steps causal-link is accomplished by the following variant of UNDERMINE-CAUSAL-LINKS: unlike GOAL-REGRESSION, is defeasible. This is be- achieving G may be under- the causal- ordered between target. In GOAL-REGRESSION, on the other hand, there are the the causal-link in plan that can be consistently target. The defeat of EMBEDDED-GOAL-REGRESSION in the plan so far constructed that can be consistently root and the causal-link ordered between UNDERMINE-EMBEDDED-CAUSAL-LINKS EMBEDDED-GOAL-REGRESSION,ADD-EMBED- Givenaninferenceinaccordancewith DED-ORDERING-CONSTRAINT, that plan+ is an embellishment n 1) consistent with order, adopt interest in establishing If it is determined own causal-links. take the inference to the conclusion G before 9~2 (and optionally after IZ 1) consistent with order to be defeated. or EMBEDDED-CONFRONTATION of plan that achieves G before n2 (and optionally after that plan+ undermines one of its that it does undermine one of its own causal-links, of plun that achieves is an embellishment to the conclusion that plan+ 288 J. L. Pollock /Artificial Intelligence 106 (I 998) 267-334 EMBEDDED-GOAL-REGRESSION terminates with goals that are already established: EMBEDDED-NULL-PLAN Given an interest in finding an embellishment of plan that will achieve goal before plan- step n consistent with order, if goal is already true, construct plan0 by (1) letting its plan- steps be the plan-steps of plun, (2) letting the ordering-constraints of plan0 be order, and (3) taking the only causal-link to be *start* + goal -+ *finish* --+ goal. From the truth of goal infer nondefeasibly that plan, is an embellishment of plan that will achieve goal before plan-step n consistent with order. SPLIT-EMBEDDED-CONJUNCTIVE-GOAL Given an interest in finding an embellishment of plan that will achieve a conjunctive goal (GI & Gz) before plan-step n consistent with order, adopt interest in finding embellishments plan1 and plan, that will achieve G 1 and Gz, respectively, before plan- step n consistent with order. If such embellishments are proposed, infer nondefeasibly that plunl + plan2 (G 1 & G2) before plan-step II consistent with order. is an embellishment of plan that will achieve a conjunctive goal Note that unlike SPLIT-CONJUNCTIVE-GOAL, SPLIT-EMBEDDED-CONJUNCTIVE-GOAL is not defeasible. This is because plan, + plan2 has the same plan-steps as both plan, both ptun2, so if a causal-link of either plan* or plan, is undermined by plan1 + plun2, it will already be undermined in plunl or plan2 itseif when it is constructed by EMBEDDED- GOAL-REGRESSION. We can try to repair embellishments that undermine their own causal-links by either adding ordering-constraints or confrontation: ADD-EMBEDDED-ORDERING-CONSTRAINT Given an interest in finding an embellishment of plan that achieves G before n2 (and optionally after nl ) consistent with a set of ordering-constraints order, if plan+ is a putative such embellishment but a plan-step n of plan+ undermines own causal-links construct a plan plan++ n 1 --+ subgoal, + by adding . . . --+ subgoal, the ordering-constraint -+ n2 -+ goal, + that n not occur between its one of . . -+ goal,,, , n1 and n2 (if this can be done consistently) and infer defeasibly embellishment of plan that achieves G before n2 (and optionally that plan++ after n 1) consistent is an with a set of ordering-constraints order. EMBEDDED-CONFRONTATION Given an interest in finding an embellishment after n 1) consistent with a set of ordering-constraints optionally of plan that achieves G before n2 (and order, if plan+ is a putative such embellishment causal-links n1 + subgoal, + virtue of there being an embellishment but a plan-step n of plan+ undermines one of its own .. . --+ subgoul, + n2 -+ goal1 -+ . . . -+ goal,,, by that achieves P, where P is plan0 of plan+ either --subgoal, or the negation of a conjunct of subgoal,, then for each causal-link no+ GI + .‘. -+ G, + n + P of plan@, adopt interest in finding an embellishment plan++ of plan+ of one conjunct that achieves of Gt ) between -GI (or if Gt is a conjunction, achieves the negation no and n. If such an embellishment repair-plan is J.L. P&lock /ArtiJicial Inrelligmce 106 (1998) 267-334 289 plan++ of plan by adding to plan+ found, construct a new embellishment the ordering- constraints and causal-links of repair-plan, with the following exception. Replace each causal-link of the form n* + SGl -+ . . . + SG, 3 *$nish* + SC,, in repair-plan by . . -+ SG, + n + SC, and order n* between no and n. the causal-link n* + SG1 + If this ordering of plan is consistent, after n 1) consistent with a set of ordering- that achieves G before n2 (and optionally constraints order. is an embellishment infer defeasibly that plan++ As before, ADD-EMBEDDED-ORDERING-CONSTRAINT TION repair underminings inferences with UNDERMINE-EMBEDDED-CAUSAL-LINKS. in accordance with these two inference-schemes and EMBEDDED-CONFRONTA- are defeasible so the in accordance one at a time. Further underminings may remain, 4.1. Evaluating a defeasible planner An r.e. planner is evaluated by asking whether it is sound and complete. It is sound if if it finds a is justiJied that it will be ‘* every plan it proposes for achieving a goal is a sound plan, and it is complete sound plan for achieving a goal whenever one exists. But how can we evaluate a defeasible planner? find unsound plans. Hopefully, it will retract them later. It will inevitably A distinction can be made between the conclusions that a defeasible reasoner sound solutions to planning-problems. is that it will eventually draw warranted conclusions in holding at the limit, when all possible relevant reasoning has been performed. in holding, at any given stage of its reasoning, and the warranted conclusions justified What we want of a defeasible planner that constitute Let us call the plans endorsed by warranted conclusions warranted plans. A first pass at a criterion of adequacy would require there is a sound plan for achieving a goal there will be a sound warranted plan. However, this criterion of adequacy in taking an unsound plan to be sound is still too strong. The reasoner might be warranted that some relevant fact about is unable to draw the conclusion simply because the reasoner the world is a fact or that some relevant consequence of an action is a consequence of that action. For the same reason it may be unable to find some sound plan. that warranted plans are always sound, and whenever We can usefully separate the plan-reasoning is inadequate. This separation can be achieved by noting from the reasoning aimed at finding factual knowledge of use in the planning. The reason-schemas used in planning may be beyond reproach, but the reasoner may still find unsound plans and fail to find sound ones because its factual reasoning that the concept of a sound plan was defined conditionals. A plan is sound relative for every linearization by its plan-steps planning, relevant set of planning-conditionals can then define defeasible planner to the set of warranted conclusions of the plan its goal is a result of the sequence of actions prescribed In defeasible and the We to be sound iff all its warranted plans are sound relative and it is complete and warranted planning-conditionals, relative to the start-state and the set of planning-conditionals. the relevant start-state consists of the set of all warranted conclusions, to be relative to a start-state and set of planning-conditionals is the set of all warranted planning-conditionals. to a start-state and a set of planning- iff ” This i( made more precise in Chapter 3 ot’ Pollock [34] 290 J. L. Pollock /Artificial Intelligence 106 (I 99X) 267-334 iff whenever warranted conclusions some such plan. there is a plan for achieving a goal that is sound relative the planner and warranted planning-conditionals, to the set of its is able to find We can evaluate the soundness and completeness of a defeasible planner by simply giv- it is always able to find a sound plan for (including knowledge of planning-conditionals) the problem, and then asking whether under those circumstances ing the reasoner all the factual knowledge that is relevant to solving all its warranted plans are sound and whether achieving a goal when there is a one. Giving the reasoner all the relevant factual knowledge has the effect of turning into an r.e. planner. Search for planning- or goals true in the start-state will terminate after a single step, so for each conditionals to be plan there will be a determinate point at which there is no more relevant reasoning done. We can take the planner in conclud- ing that the plan will achieve its goal. Because all the relevant reasoning has been done, the plan will be warranted at that point. the plan iff at that point it is justified the defeasible planner iff the reasoner that conclusion in drawing to “return” is justified The r.e. planner that is generated above can be shown to be sound and complete by appealing this purpose we need the assumption searches the space of potential schemes have the effect of systematically undermining inferences systematically. expanding in this way by the defeasible plan reasoning described to Theorems 1 and 4. For reasoner It then follows that the inference- the recursive characterization that the control structure for the defeasible provided by Theorem 4. The result is: of Theorem 6. If OSCAR searches OSCAR planner is sound. Theorem 7. If OSCAR searches OSCAR planner is complete. the space of potential inferences systematically then the the space of potential inferences systematically then the 5. Planning and the Frame Problem theory. In particular, planning I have presented a tentative account of the logical structure of goal-regression agents. This account differs from in autonomous rational theory, but it also makes heavy reliance on certain aspects of conventional AI planning to the conventional iff the goal is a result of the which a linear plan achieves a goal relative relative to the start-state and the set of all sequence of actions prescribed by the plan-steps true planning-conditionals, is a technical concept that was defined by (Rl). To evaluate the Soundness Assumption we must consider more carefully what it means. It seems to say the following: it turns on the Soundness Assumption, important ways where “result” to a start-state according in some Necessarily, a linear plan will achieve a goal G when executed from a start-state G is a result of the sequence of actions prescribed by its plan-steps start-state and the set of all true planning-conditionals relative iff to the J.L. Pollock /Art$cial Intelligence 106 (1998) 267-334 291 the Soundness Assumption But so interpreted, in AI agrees). The difficulty concerns clause (iii) of (Rl). Clause (iii) asserts that once a true unless some later step of the plan makes subgoal has been established, it will remain changing place. It is certainly not a necessary it false. The world is a dynamic, continually truth that subgoals established by earlier steps of a plan will not be made false by events extraneous to the plan before the subgoals can be used in establishing false (as, I think, everyone further goals. is obviously In AI it is often claimed that goal-regression planning according to which nothing changes assumption” of executing a step of the plan. l9 But such an assumption in goal-regression STRIPS assumption cannot provide the logical basis for our planning. planning all the time without believing relies upon the so-called “STRIPS in the world unless it does so as a result silly. We engage so the the STRIPS assumption, is obviously We do not expect that nothing will change in the world unless we change it, but we do expect our plan to work. This means that we have a limited expectation, not that nothing will change, but that the particular subgoals established by initial steps of the plan will not change unless executing later steps of the plan causes them to change. We certainly do not believe that plans will never be disrupted by extraneous events, but we do expect that not to be proven wrong. to happen In other words, our expectation is defeasible. We know that things change, but there is a presumptior Providing against it in any particular case. the logical foundations in any particular case. We are, however, always prepared for such a defeasible expectation of reasoning reconstruction to be a practical It quickly became apparent how things change, but also a much in AI to give a logical tried doing so by axiomatizing ProbZem. Early attempts the domain and then reasoning consequences of actions that such an approach required not only about it deductively. axioms describing larger set of “frame axioms” describing when things don’t change. 2o Getting such axioms right in a complex domain seems the deductive and even task would be made infeasible by the huge number of frame axioms required. reasoning the problem of finding some feasible way of reasoning about The Frame Problem became both change and non-change. *’ That is precisely facing us here. In goal- regression planning we want to be able to assume defeasibly that the truth values of our to change them, and we want to use that subgoals will not change until we do something assumption for which the subgoals are the preconditions. in reasoning about what will change as a result of executing if we had such axioms the plan-steps impossibility, the problem Al researchers quickly gave up the attempt instead that there is a defeasible presumption and proposed thinking was that given such a defeasible presumption, need are causal principles overriding recently explored ways of making OSCAR system of defeasible the defeasible presumption this reasoning precise (and implementing reasoning, and I will summarize my results here. 23 in specific cases. ** I have it) within the to solve the Frame Problem deductively, that things don’t change. The the only substantive principles we I9 See Allen [I] and Lifschitz [23]. 2o McCarthy and Hayes [25]. ” There is a lot of disagreement interpretation of it. see Pollock [38]. about what the Frame Problem really is. For historical substantiation of my 22 McCarthy and Hayes [2S]. 2.1 Pollock [36,38]. is just the Frame the about 292 J. L. Pollock /ArtiJicial Intelligence 106 (I 998) 267-334 5. I. Temporal projection As a first approximation, we can formulate a defeasible presumption against change as follows: If to < tl , believing P-at-to is a defeasible the strength of the reason being a monotonic decreasing reason for the agent to believe P-at-t], function of tl - to. 24 (11 Principle to P-at-t2 It amounts to a presumption is high that it will continue is defeated, but an inference (1) is a principle of temporal projection. gives us a stronger reason for expecting WP-at-t2, because that P’s is one such that if it holds at being true is a stable property of a time. A stable property one time, the probability to hold at a later time. Some such principle seems to be presupposed by much of our reasoning about the world. 25 However, (1) is too strong. A constraint must be imposed on P. This is as formulated, principle best demonstrated with an example, diagrammed in Fig. 1. 26 Let P and Q be unrelated propositions. Suppose we know that P is true at to, and false at the later time tl . Consider a third time t2 later than tl P-at-to gives us a defeasible reason for expecting P-at-t2, but (t2 - tl) -c (t2 - to). -P-at-t1 Thus an inference is undefeated. This infer (P v Q)-at-to. Without is as it should be. However, from P-at-to we can deductively any restrictions on the proposition variable (P v Q)-at-to gives us a defeasible we can then infer Q-at-t2. symbolize deductive from multiple premises. The “fuzzy” arrow symbolizes a defeat relation. In this inference- graph, the conclusion Q-at-t2 is undefeated. But this is unreasonable. Q-at-t2 is inferred from (P v Q)-at-t2. and it was only true at to because P was true at to. This makes it reasonable (P v Q)-at-t2 only insofar as it is reasonable illustrates clearly This example In particular, all propositions. is not closed under disjunction. Let us label those propositions temporally-projectible. A principle of temporal projection must be restricted to temporally- projectible propositions: to believe to believe P-at-t2, but the latter is defeated. that temporal projection does not work equally well for for which temporal projection works it does work for which the inference in Fig. 1, the solid arrows is In diagramming inferences, and bars connecting (P v Q)-at-t2. Given these inferences to be true at t2 only because in temporal projection, the set of propositions (P v Q) is expected that the inference arrows indicate it was true at to, for expecting to “P-ut-t2, to ^r P-at-t2 reason TEMPORAL-PROJECTION If P is temporally-projectible the agent to believe P-at-t1 , the strength of the reason being a monotonic decreasing function of tl - to. and to < tl, believing P-at-to is a defeasible reason for What are called “projectibility epistemology. Goodman well for all properties-that problems” arise in a number of places in philosophical reasoning does not work equally In [ 141 first showed that inductive principles of induction require a projectibility constraint. 24 For a discussion of reason-strength, ‘5 For arguments 26 An example with the same structure see Pollock [34]. to the effect that such reasoning is pervasive, see Pollock 1361 is presented by Myers and Smith [2h]. J.L. Pollock /Art&id Intelligence 106 (1998) 267-334 293 -Patt2 Q at t2 Fig. 1. The need for a temporal projectibility constraint [32] I showed that many projectibility problems result from attempting with respect to disjunctions. other contexts-the of these contexts, disjunctions must be drawn for temporal projection. create major difficulties. Apparently, In [33] I showed that similar projectibility statistical syllogism, direct inference, and statistical to employ induction problems arise in In all induction. the same conclusion The need for a projectibility constraint is clear, but the exact content of the constraint problems, but they are not the only culprits. It propositions create projectibility of temporally-projectible If we have an undefeated so the negations of temporally-projectible reason for believing P-at-t1 and an undefeated This is clear for the negations of logically complex is not. Disjunctions are temporally- is easy to see that conjunctions reason projectible. so the latter inference for believing Q-at-tl, then we can infer (P & Q)-at-t1 deductively, is equivalent cannot be problematic. On the other hand, the negation of a conjunction are not automatically disjunction, temporally- temporally-projectible. (however projectible propositions, exactly to objects will generally be projectible, but the negations of such ascriptions need not be. For instance, to “X is red” would seem to be temporally-projectible. “x is blue or green or yellow or orange or. . .“, and as such it would seem a disjunction about to be temporally-unprojectible. temporal- We can make many such observations projectibility, but I do not have a general criterion of temporal-projectibility to propose. The literature contains no good theories of projectibility such a theory is at this time an unsolved philosophical problem. this is to be understood). The ascriptions of “simple” properties in any of its guises. 27 Constructing to be true for atomic propositions But “x is not red” is equivalent but it also seems propositions to a 5.2. The Frame Problem resurrected TEMPORAL-PROJECTION was originally proposed as a solution However, TEMPORAL-PROJECTION shown by Hanks and McDermott to the Frame Problem. turns out to be only part of the solution, as was first than theirs), (with a different example [15]. To illustrate 27 See Stalker [43] for a compendium of work on projectibility. 294 J.L. Pollock /Art$cial Intelligence 106 (1998) 267-334 t0 match is dry tl -+ match is dry match is struck t 2 match is lit match is not lit ) match is not lit Fig. 2. The Yale Match-Lighting Problem. there is a causal law to the effect that if a match is dry and it is struck then it suppose to be dry, at time to. Shortly will bum. Suppose we have a match that is initially known that it will light at some thereafter, at time tl , it is struck. We want to be able to conclude time tz (> tl). It may seem that TEMPORAL-PROJECTION allows us to make this inference. to be dry at to, so TEMPORAL-PROJECTION gives us a reason for The match was known it to still be dry at tl . Then on the basis of the law we can infer that the match will expecting bum at some time t:! > 11. However, as Hanks and McDermott observed, we also know that the match is not burning at time to, and so (assuming TEMPORAL- it will not be burning at time t2. This conflicts PROJECTION gives us a reason for thinking that it will bum at time t2. Thus TEMPORAL-PROJECTION does not with the conclusion that the match will favor either the conclusion not bum. This is diagrammed that the match will still be dry at tl and hence will bum at t2. Thus TEMPORAL-PROJECTION does not solve the Frame Problem. 28 in Fig. 2. But, intuitively, we want to conclude defeasibly that the match will bum or the conclusion temporal-projectibility) to this problem lies in performing the temporal projections There is a kind of consensus among researchers dealing with the Frame Problem that the solution in temporal order. 29 We first use TEMPORAL-PROJECTION to infer that the match is still dry at time tl . At that point, nothing has yet happened to block the application of TEMPORAL-PROJECTION, so we make this inference. From this we can infer that the match will bum at t2. At time t2, we can also try to use TEMPORAL-PROJECTION to infer that the match will not bum, (the match was struck while dry) to block but this time something has already happened the projection, and so we do not infer that the match will not burn. This general idea was endorsed by Hanks and McDermott first suggested by Shoham [40], and subsequently this chronological [16], Lifschitz minimalization Attempts [22], and others. I will follow the literature (changes are minimized chronological minimalization in chronological order). to formalize in calling largely, I think, because they were based upon inadequate In addition, Kautz that [19] proposed a troublesome is something wrong with the fundamental there have met with mixed success, reasoning. theories of defeasible counterexample which seems to show idea underlying chronological in Pollock [38]. 28 This is formulated more precisely theory 2y See Hanks and McDermott in its full there is a different kind of consensus, namely, that we should avoid trying to solve the Frame Problem generality and just run a program for both the STRIPS and ADL representation of actions. But one of the points of this paper is that it is worth taking the Frame Problem seriously [ 161. A number of more recent papers explore this same idea. In planning in order to avoid some of the limitations of those representations. that gets around it. That was a large part of the motivation J. L. Pollock / Artijicial Intelligence 106 (I 998) 267-334 295 lot minimahzation. Modifying his example slightly, suppose I leave my car in a parking at time to. I return at time t3 to find it missing. Suppose that it was stolen either at time tl or time t2, where to < tl < t2 < t3. Intuitively, there should be no reason to favor one of these times over the other as the time the car was stolen. However, first at tl to conclude chronological minimalization would have us use temporal projection that the car was still in the lot, and then because the car was stolen at either tl or t2, we can conclude that the car was stolen at t2. This seems completely unreasonable. I know somehow gives trying the cases The difference between this precise and implementing the propositions being projected. in which chronological minimalization In [35,36,38] I suggested a way of making the intuitively correct answer and the cases in which it does not seems to be that in the former there is a set of temporal projections inconsistent by a causal connection that are rendered between In the latter case, there is also a set of temporal projections not all of which can be correct, but the inconsistency causal connection. So, for example, does not result from a the match case is causal, but the stolen car case is not. the reasoning. For present purposes, most of the details of that account are irrelevant. It is useful, however, to consider one aspect of the account given there. Thus far, I have talked about “planning- these are. It is clear, conditionals”, without however, that to make goal-regression planning work, they must express the kind of causal- connections to the Frame Problem. My proposal is that the requisite causal connection generalizations philosophy but might have been false. For example, suppose been just one green-eyed mathematician another one. Suppose Bartholemew disliked coffee. Then it is true that every green-eyed mathematician true, named “Bartholemew” and is not a law of nature. Accidental generalizations For example, renaming a green-eyed mathematician dislike coffee. in to be true in all the history of the world there has and there will never be that reflect the ultimate causal structure of the world. It is customary these with “accidental generalizations”, which happen do not support causal connections. “Bartholemew” will not cause him to is that expressed by a law qfnature. These are exceptionless dislikes coffee. But this is only accidentally to say just what kind of conditionals named “Bartholemew”, that are involved in the solution to contrast generalizations, Laws of nature entail ordinary universal counts as a law of nature. There is an extensive philosophical but not every universal generalization literature on the topic of laws of nature, but this is not the place to review it. I will simply assume the account given in [33]. Laws of nature can be formulated using nomic generalizations. These relate predicates and relations, and can be expressed a B”. Where cp and B are open formulas, we can write the nomic generalization would be a 8” as “C+O =+ 0”. ‘=$’ is a variable-binding of variables possibility” with the set of all true nomic generalizations, to be an S5 modal operator. Let XI, and H. It can be shown that if 0P3xt,. If Op3xt, operator, binding all free occurrences of “physical in (p and 0. Let us define and “physical necessity” by taking O/, P to mean that P is logically consistent turns out in cp in the form “‘Any A would be “Any cp , xn be the variables having free occurrences . . . ,x,(q 1 t3).j” In cp =+ 8 is said to be “non-counterlegal”. the modal operators Op and 0, then cp =+ Q iff q ,Vxt, . , x,cp holds, the generalization and 0, P to mean --0,-P. . , x,q ‘0,’ X0 This is all shown in [33] 296 J. L. Pollock / Artijicial Intelligence 106 (I 998) 267-334 generalizations, in generalizations in non-counterlegal What appears to be crucial planning, we are only interested interested because we are only concerning goals and subgoals that could actually be achieved. that can be used for the kind temporal in p and 8 and q is about earlier times than 0. xl This is required for us to be able order. In of causal reasoning references to do the causal reasoning by performing [38], I explored the logical structure of causal reasoning employing nomic generalizations of the form to the nomic generalizations in the Frame Problem is that there are built-in temporal projections in chronological that occurs {(A-at-t & C-at-t) =+ (3S)G-thr-oughout-(t + E, t + E + S]}.” ((3 This says that performing A when C is true is causally sufficient for making G true after an interval E. (CS) takes account of the fact that causation can take time, a fact that has that E = 0.) The been heretofore interval (t + E, t + E + 61 is open on the left and closed on the right. 33 Consequently, (CS) does not allow us to infer deductively that it is true at some time succeeding in this paper. (In effect, I have been assuming t + E. However, if G is temporally-projectible, that G is true at any particular time--only TEMPORAL- ignored allows us to go on to infer defeasibly PROJECTION t + E. I will take planning-conditionals (A/SG) ws G. When E = 0, I will omit it, writing just ‘w’. that G is true at any time succeeding to have the form of (CS), abbreviating (CS) as depends upon temporal projection, in a plan-step. Rather than just writing To make it clear how planning reference explicit temporal I will write it as “A-at-t”, where variable. Then I will take the ordering-constraints the time designators the planning-conditionals causal-link A-at-t1 -+ SG-at-t2 --+ A*-at-t2 + G-at-t3, beaddedtotheplanare{tl+&<q,q+&*<t3). I will make the the plan-step as “A”, a time) or a on in a plan to be ordering-constraints themselves. So, for instance, when we use (A/C) l E SG and (AL/SC) N,* G to construct a plan with a that must t is either a real number rather than the plan-steps the ordering-constraints (designating is to find premises The solution to a planning problem such that causal reasoning of the sort involved is a set of actions and constraints on the times in the Yale that the goal will be true at the those actions are performed Match-Lighting Problem will enable us to infer defeasibly desired time. In effect, a plan corresponds problem the desired goal will be true. Note that the argument corresponding mentions plan is an artifact of the way in which we go about finding appropriate premises argument. Finding solve that problem by introducing plans as structures and reasoning about them. 34 to a defeasible causal argument, and the planning that to the plan nowhere is just about actions and their consequences. The for the is a difficult problem, and standard planning procedures from which we can infer defeasibly the plan itself. The argument for such an argument the premises Thus far I have been assuming that an action A is performed at an instant t, and that a planning conditional will require C to be true at that same instant. However, realistically, most actions must be performed over an interval rather than at an instant. Performing the 31 See Pollock [36,38] for more detail about the exact form of these temporal references. 32 G-thmuglzout-[t, t*] is defined to mean (Vx)[t -C x = t* > G-at-t]. 33 That is, it is the set of real numbers x such that t + E c x < t + 6 + 6. j4 SATPLAN to this. See the discussion of SATPLAN [20] is an exception in Section 12. J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 291 point in action is a process that takes time, and C may be required at some intermediate that process rather than at the beginning of the process. For instance, the ball in tennis. One must first throw the ball into the air so that it will arrive at a point x at a time t. Then one swings the tennis racket so that it will hit the ball at point x at time t. But one must begin the swing earlier than time t. So the ball’s being at point x is required rather at the beginning. This can be midway having the logical form accommodated by employing more complex planning-conditionals through the performance of the swing-action think of serving { (A*-at-t & SG-at-t +(Y) =+ (36)G-throughout-(t + E. t + F + 61). {tl + F < t2, t;! = t3 + a, t3 + E* < t4}. To avoid unnecessary this in place of (A*/SG) w,* G in the above planning example will produce Employing a plan with the causal-link A-at-t1 + SG-at-t2 -+ A*-at-t3 -+ G-at-t4 and the ordering- for constraints the bulk of this paper I will not consider planning with these more complex planning- conditionals, E = 0. However, conditionals, of the form (CS) with these more complex and I will return to this topic briefly in Section 11 and discuss how to do it. confining myself to the use of planning-conditionals the theory can be readily extended complexity, to handle 6. Planning and temporal-projectibility The conventional theory of goal-regression planning as developed upon the Soundness Assumption, which was formulated as follows: in Section 2 was based Soundness Assumption. A linear plan will achieve a goal G relative to a state start-state relative to start-state iff G is a result of the sequence of actions prescribed by its plan-steps and the set of all true planning-conditionals. This employs To make the temporal reference explicit, let us rewrite (Rl) as follows: the concept of a result of a sequence of actions, which was defined in (Rl). (RI) Where start-state is a state of affairs, conditionals is a set of planning-conditionals, I . -c t,+ 1 is a sequence of times, P-at-t,,+ 1 is a result of (A 1 -at-t1 , . . , and to < AR-at-t,,) relative to start-state and conditionals (i) n = 0 and P-at-to is true in start-state; or (ii) n > 0 and conditionals contains a conditional iff either: (A,/C) F P such that C-at-t,, is a result of (Al-at-t], . . . , A,-I-at-t,_I); or (iii) n > 0, P-at-t,, is a result of (AI-at-t1 , . . _ , A,_ 1 -at-t,_ I), and conditionals of the form (A,z/C) l k Q such that Q is does not contain a conditional either P or a conjunct of P and C-at-t,, is a result of (A 1 -at-t1 , . . . , A,_, -at- 6-l ); or (iv) n > 0 and P-at-t,+1 is a conjunction whose conjuncts are results of (AI-at-t], . , An-at-t,). The observations of Section 5 require modifications to both the Soundness Assumption itself and to the definition rules of goal-regression of “result”, and these in turn require modifications to the that are based upon the Soundness Assumption. First, planning 298 J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 the definition of “result” are only defeasible the inferences underlying upon TEMPORAL-PROJECTION. As such, the term “result” characterizing what will definitely happen just characterizing what can be reasonably precisely, we are characterizing Section 4. So it would be better the inferences projectibility these constraints. constraints. We must make some changes (and defeasibly) expected the set of warranted expectations, to use the term “expectable-result”. inferences, based is a misnomer. We are not is performed. We are to happen. More in the sense of Second, because to temporal- to accommodate are based upon TEMPORAL-PROJECTION, they are subject if the action-sequence to the definition Clause (i) tells us to expect P-at-t1 to be true if P-at-to is true. This is just an instance of TEMPORAL-PROJECTION. Accordingly, constraint on P: it requires the addition of a temporal-projectibility (i) n = 0, P is temporally-projectible, and P-at-to is true in start-state. It follows that PROPOSE-NULL-PLAN also requires a temporal-projectibility constraint: PROPOSE-NULL-PLAN Given an interest to < t, infer defeasibly in finding a plan for achieving goal-at-t, that a null-plan will achieve goal-ut-t if goal-at-to is true where Note that PROPOSE-NULL-PLAN becomes a defeasible anapplicationof TEMPORAL-PROJECTION. Clause (iv) requires no modification to accommodate relations between expectable-results only concerns ward to the appropriate TEMPORAL-PROJECTION. However, clauses constraints, times, and hence does not presuppose temporal-projectibility, that have already been projected because it for- any new application of temporal-projectibility (ii) and (iii) require inference-rule, because it builds in 6. I. Goul regression A,_,-at-&I), Clause (ii) describes causal evant. If we can expect C-at-t, (Al-at-tl,..., some time t” between If P is temporally-projectible, true at tn+l . For this reasoning (ii): inferences of the sort to which the Frame Problem to be achieved by executing then given the conditional is rel- the sequence of actions (An/C) w P we can infer that for . that P will still be constraint must be added to clause we can then infer by temporal projection to work, a projectibility tn and &+I, and P-at-t* will be made true by performing A,-at-t,, (ii) n > 0, P is temporally-projectible, and condition& (An/C) N P such that C-at-t,, tn_l) and tn+l > t,,. is an expectable-result contains of (Al-at-tl, a conditional . . . , A,_!-ut- GOAL-REGRESSION is based directly on clause (ii), so it must contain a corresponding constraint, and it becomes defeasible: GOAL-REGRESSION Given an interest adopt interest in finding planning-conditionals Given such a conditional, in finding a plan for achieving G-at-t, if G is temporally-projectible, adopt an interest in finding a plan for achieving C-at-t*. If it is (A/C) l G having G as their consequent. J.L. Pollock /Artijcial Intelligence 106 (1998) 267-334 299 concluded step to the end of subplan where the new step prescribes the constraint causal-links that a plan subplan will achieve C-at-t*, construct a plan by (1) adding a new (2) adding the that the new plan will achieve G-at-t. (t* < t) to the ordering-constraints of subplan, and (3) adjusting the action A-at-t’, Infer defeasibly appropriately. Similar constraints NULL-PLAN. are required in EMBEDDED-GOAL-REGRESSION and EMBEDDED- 6.2. Undermining causal-links as follows: (iii) n > 0, P-at-t,, A,_I-ut-&_I), Clause (iii) is, in effect, a statement of an action-sequence, of TEMPORAL-PROJECTION to the together with the statement of a defeater for the applied reasonable . . . , A,_,-at-t,_, for this defeasible that P be temporally-projectible. to be applicable, if it is defeasibly to expect P to be true after executing Al-at-tl, to expect P to remain expectation expectable-results application of TEMPORAL-PROJECTION. For TEMPORAL-PROJECTION we must require Given that constraint, , then it reasonable as well. is defeasibly that A defeater reasonable to expect C to be true P-at-t,, will not be true. Given after executing A 1 -at-t1 , . . . , A,,_1 -at-t,_, in accordance with the preceding discussion to expect (A,/ C) l -Q, Q to become false at some time t* after executing A,-at-t,, where t* > t,,. If Q’s being false requires P to be false, then as in the Yale Match-Lighting this defeats that P will still be true at t,,+l. Note that the temporal projection this reasoning does not require So (iii) should be be temporally-projectible. reformulated true after executing An-at-t, consists of having a reason for thinking to the conclusion that -Q that, given the conditional that it is defeasibly it is defeasibly , it follows reasonable Problem, (An/C) result of (A, -at-t1 , . . . , A,_l-at-&-l), is a temporally-projectible . . . , of the form does not contain l - Q such that Q is either P or a conjunct of P, C-at-t,, is an expectable- and conditionals expectable-result a conditional of (Al-at-tl, and &+I > t,,. the defeat of SPLIT-CONJUNCTIVE-GOAL by finding one of its own causal-links. that the that in the search for must be observed as in the original It follows the same projectibility-constraints Clause (iii) underlies merged plan undermines embellishments, search for plans. CONFRONTATION, but CONFRONTATION (iii) also underlies Clause formulated. The observation that in clause (iii) -Q need not be temporally- previously projectible is an important one. In CONFRONTATION, we search for a plan for --subgoal (or for the negation of a conjunct of subgoal). We know that subgoal will be temporally- projectible, but there is no reason to expect its negation is correct as to be. Combining these observations, we are led to the following definition of “expectable- result”: (R2) Where start-state is a state of affairs, conditionals is a set of planning-conditionals, and to < . . . -c tn+l is a sequence of times, P-at-t,,+1 (A1 -at-t1 , . . , A,,-at-t,,) relative to start-state and conditionals is an expectable-result of iff either: (i) n = 0, P is temporally-projectible, and P-ar-to is true in start-state; or 300 J. L. Pollock /Artificial Intelligence 106 (I 998) 267-334 (ii) n > 0, P is temporally-projectible, (A,,/C) N P such that C-at-t, at-&_I) and &+I > tn; or and conditionals contains a conditional is an expectable-result of (A I-at-t1 , . . . , A,_ t - (iii) n > 0, P-at-t, is a temporally-projectible of (A 1 -at-t1 , . , A,_1 -at-t,z_l ), and conditionals does not contain a conditional of the form is an such that Q is either P or a conjunct of P, C-at-t,, expectable-result ’ -Q (An/C) expectable-result (iv) n > 0 and P-at-tll+l of (Al-at-tl, . , A,,_,-at-&_I), and tn+t > tn; or is a conjunction whose conjuncts are expectable-results of (Al-at-t{, . . . , A,-at-t,). The Soundness Assumption must now be reinterpreted as giving us merely a defeasible expectation that a plan will achieve its goal: Soundness Assumption. Executing a linear plan can be defeasibly expected to achieve a goal G relative to a state start-state of the sequence of actions prescribed by the plan-steps of the plan relative to start-state and the set of all warranted planning-conditionals. iff G is an expectable-result 6.3. The importance of the temporal-projectibility constraints to illustrate It is of some interest impacts on goal-regression the importance of the temporal-projectibility con- planning. Suppose Cl, Cz, C3, straints. They have significant are true, and and Dt are temporally-projectible, we are given (A2/C3) N GI, (A3/D1) w G2 and (A3/Dl) w -Cl. Suppose our goal is (Gl & G2)-at-t. We can con- struct plan #1 (Fig. 3) for G 1 -at-t, and plan #2 (Fig. 4) for Gz-at-t: To construct a plan for the conjunctive goal (G 1 & G2)-at-t, we merge plans #I and #2 to produce plan #3 (Fig. 5). (Al/Cl) N C2, (A2/C2) N Gl, that Cl-at-to and Dl-at-to the planning-conditionals we know We must then investigate whether plan #3 undermines Because we also have the planning-conditional one of its own causal-links. (A3/Dl) w -42, we find that plan-step Plan #l PLAN-STEPS: (1) A@-t, causal-links: ‘start* + C, -at-t, + (1) + C,-at-t, (2) h-at-4 causal-links: (1) + &-at-t, + (2) + G, -at-t ordering-constraints: {cd GOAL: G, -at-t established by: (2) + G, -at-t Fig. 3. Plan #l *start* (C,-at-$) 4 1. Al-at-t, 4 ($-at-t2 1 4 2. A fat-t2 4 (G,-at-t ) J.L. Pollock /Arti$cial Intelligence 106 (1998) 267-334 301 Plan #2 PLAN-STEPS: (3) A,-at-t, causal-links: ‘start’ + D, -at-t. -) (3) + G,-at-t GOAL: G2 -at-t established by: (3) + G2 at-t Fig. 4. Plan #2. Plan #3 PLAN-STEPS: (1) \-at-t, causal-links: ‘start’ + C, at-t, -+ (1) + C,-at-f, (2) A,-at-4 causal-links: (1) + C,-at-t, + (2) + G, -at-t ordering-constraints: (3) A,-Ls;:2 causal-links: ‘start’ + 0, -at-t, -) (3) + Gz -at-t GOAL: (G, & GJ -at-t established by: (2) -+ G, -at-t (3) -+ G2 -at-t Fig. 5. Plan #3. (II,-a’-$) i 3. A3-at-t3 4 (%-at-t ) *smt* J 4 (C,-a’-$) A, -a&t, 3. A3-at-t 3 4 ($-at-t ) 4 (cq-‘* ) + A2-a’42 4 @,-at-t ) \r / (G, & %)-at-t (3), which is not ordered with respect link (1) + Cl-at-t2 + constraint step (2), producing plan #4 (Fig. 6). requiring plan-step to plan-steps the causal- (2) --+ Gl-at-t. The plan can be repaired by adding an ordering- (1) or after plan- (3) to be executed either before plan-step (1) and (2), undermines the temporal-projectibility Now, suppose we ignore constraints. From (Al/Cl) N C2 l (C2 v C3), and from (A2/C2) l GI and (A2/C3) l Cl we (Al/Cl) the conditional we can deduce (A2/(C2 v C3)) l G1. 35 Without can deduce constraints, we could construct plan #5 (Fig. 7) for Cl-at-t: To construct a plan for the conjunctive goal (Gl & G2)-at-t, we merge plans #5 and #2 to produce plan #6 (Fig. 8). Note that plans #5 and #6 differ from plans #l and #3 only in their causal-links. They in the same order. Now when we investigate whether plan #6 the temporal-projectibility the same actions prescribe x5 This planning-conditional violates the syntactical constraint that the precondition be a conjunction of literals, but such syntactical equivalent can always be circumvented to (C, v Cg). The relaxation of the syntactical constraints will he explored a new atomic in the next section. introducing by simply constraints formula 302 J.L. Pollock /Arti&ial Intelligence 106 (1998) 267-334 Pfan #4 PLAN-STEPS: (1) 4-at-4 causal-finks: *start* + C, -at-t, --) (1) + C,-at-t, (2) 4-at-4 causal-finks: (1) + C,-at-t, --) (2) + G, -at-t ordering-constraints: (3) *,-:tyz causal-finks: ‘start* + 0, -at-t, --) (3) --) G, -at-t ordering-constraints: 4 c t, or t, c t3 (G, & G2) GOAL: established by: GOAL: (G, & G2) -at-t established by: (2) + G, -at-t (3) --) G* -at-t Fig. 6. Plan #4. Plan #5 PLAN-STEPS: (1) A causal-links: *start* + C; -at-t, + (1) + (C, v CJ -at-t, (2) 4 causal-finks: (C, v CJ-at-t, -) (2) + G, -at-t (1) + ordering-constraints: J<d GOAL: G, established by: (2) + G, -at-t Fig. 7. Plan #5 *start’ J\ ($-at-t ) / (G, & %)-at-t *start* i CC,) 4 1. A, 4 (qJ C3) 4 2. A2 4 (G,) the conditional (A3/Dt) l WC:! does not entail undermines one of its own causal-links, we find that, unlike plan #3, it does not. This is because (A3/Dt) l --(C2 v C3). Thus without the projectibility-constraints, we would be led to adopt plan #6, whose execution is the same as plan #3. But as we have seen, plan #3 cannot be expected to achieve its goal. If step (3) is executed between steps (1) and (2), the plan will fail. The execution of plan #6 is precisely the same as the execution of plan #3, so it cannot be expected to achieve its goal either, but this is not revealed by looking for undermined causal-links. J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 303 Plan #6 PLAN-STEPS: (1) 4 causal-links: *start* + C, -at-t, --) (1) + (C, V C&at-t, (2) 4 causal-links: (I) + (c, v Q-at-t, ordering-constraints: + (2) --t G, -at-f 4<d (3) A, causal-links: *start* + 0, -at-r, -* (3) -) Gz -at-t GOAL: (G, & GJ -af-t established by: (2) + G, -at-t (3) + G2 -al-t Fig. 8. Plan #6. 7. Relaxing the syntactical constraints *stati* \ J cc,, 4 1. 14, 4 (C2” C3) I + 2. A2 4 (G1) \r / (G, & 4, @,I 4 (0 Once the account of Section 2 is modified as indicated satisfy the syntactical of literals. But now it is time to re-examine both that constraint in Section 6, it constitutes planning provided all goals and planning- that goals and subgoals must be literals or and the theory of goal-regression constraint a provably correct conditionals conjunctions definition of “expectable-result”. There is something artificial about the definition (R2) of “expectable-result”. are expectable-results. It ought This to be the case that logical consequences the previous definition suggests revising of expectable-results (R2) as follows: (R3) Where start-state and to < (AI-at-tl,..., is a state of affairs, conditionals . . K tn+l is a sequence of times, P-at-t,,+] is a set of planning-conditionals, is an expectable-result of relative to start-state and conditionals iff either: An-at-t,,) (i) IZ = 0, P is temporally-projectible, (ii) n > 0, P is temporally-projectible, (A,/C) > P such that C-at-t, at-t,_l) and tn+l > tn; or (iii) n > 0, P-at-t,, is a temporally-projectible and P-at-to is true in start-state; or and conditionals contains a conditional , A,_,- of (Al-at-tl, is an expectable-result . A,,_, -at-&_I), l -Q (4/C) expectable-result (iv) n > 0 and P-at-t,+1 (A1-at-tl, . . , An-at-t,). of (A 1 -at-t1 , . . , and conditionals does not contain a conditional of the form is an such that Q is either P or a conjunct of P, C-at-t, expectable-result of (AI-ut-tl, . . , A,_1-at-t,_~), is a logical consequence and tn+l > tn; or of expectable-results of 304 J.L. Pollock /Artificial Intelligence 106 (199X) 267-334 If we assume that the compactness (as it does, e.g., in first-order written equivalently as follows: theorem 36 holds for the logical consequence relation logic), this definition can be logic, but not in second-order (R4) Where start-state is a state of affairs, conditionals is a set of planning-conditionals, and to < . . . < &+I is a sequence of times, P-at-t,+1 (A1 -at-tl, relative to start-state and conditionals is an expectable-result of iff either: . . , An-at-t,) (i) II = 0, P is temporally-projectible, (ii) II > 0, P is temporally-projectible, and P-at-to is true in start-state; or and conditionals contains a conditional (A,/C) at-t,_l) (iii) IZ > 0, P-at-t, A,,_, -at-t,- l -Q (An/C) expectable-result (iv) n > 0 and P-at-t,+1 l P such that C-at-t,, is an expectable-result and tn+l > tn; or of (A1 -at-tl, . . . , A,_, - is a temporally-projectible of (A 1 -at-t1 , . . . , I), and conditionals does not contain a conditional of the form is an such that Q is either P or a conjunct of P, C-at-t,, expectable-result of (Al-at-tl, . , A,_,-at-t,_l), and tn+l > tn; or is a conjunction whose conjuncts are expectable-results of (Al-at-tl, . . , A,-at-t,); or (v) n > 0 and P-at-t,+1 is a logical consequence of some expectable-result of (Al-at-tl, .. . , An-at-t,). that even if the logical consequence It is worth noting these two definitions will give rise to the same planning because, presumably, we can only plan for finitely many subgoals in the course of any planning problem. For this reason, I will focus on the latter definition of “expectable-result”. is not compact, relation relation with first-order consequence, Thus far we have required goals and subgoals to be conjunctions of literals. If we identify and we restrict our attention the logical consequence (R2), (R3), and (R4) are all equivalent. This to conjunctions is a justification theory of goal-regression planning, and it carries over to using (R2) in the present theory. However, we can reasonably object of logical consequence with both to these syntactical constraints first-order consequence. of literals, then the definitions for the using (Rl) in the “conventional” and to the identification 7.1. Problems with liter& First, consider the syntactical constraints. the temporal-projectibility Initially, constraint. Unfortunately, it may seem that they constitute a way this simple approach of incorporating to the problem does not work, for several reasons: l The fact that something it is projectible. Anything can be symbolized is symbolized by an atomic formula does not imply anything as an atomic formula, logical compounds. We might try to get around this by about whether including wildly unprojectible requiring not everyone agrees that this notion makes sense. It is often alleged that logical form belongs only to sentences, not propositions. that atomic formulas express “logically simple” propositions. Unfortunately, 36 The compactness logical consequence of some finite subset of X. theorem says that if a formula is a logical consequence of a set X of formulas, it is also a J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 305 l Even if the notion of a logically simple proposition does make sense, it is doubtful that all logically simple propositions will be temporally-projectible. For example, “the time is now 3 PM” might plausibly be regarded as logically simple, but its being true now is no reason to think it will still be true an hour from now. the restriction that atomic formulas logically simple propositions. That, however, does not that the negation of an atomic formula will be temporally-projectible. We l We might build into the semantics of our language express temporally-projectible guarantee have seen that negations of temporally-projectible temporally-projectible, propositions. The example given above was “X is red’. Thus no guarantee seem to preclude our being able to express temporally-unprojectible propositions that literals will be temporally-projectible. like “the time is now 3 PM”. and that is true even for what are presumably propositions logically simple there will still be this would logically simple are not automatically Furthermore, l Not all logically complex propositions goals and subgoals be conjunctions propositions This will be illustrated that, intuitively, in the next paragraph. are temporally-unprojectible. rule out of literals will logically Requiring that complex planning. are perfectly fine objects of goal-regression It must be concluded be eliminated. Temporal-projectibility syntax alone. that the restriction to conjunctions of literals is artificial and should is a semantical notion and cannot be captured by 7.2. Problems withjrst-order consequence formulas illustrates Logical consequence simple example of this, which simultaneously that are logically complex. Nomic generalizations cannot be identified with first-order consequence. Let us consider the importance of cannot truth value as time passes. They are fixed features of the world. Thus they are whose Thus it follows from (R4) of any action-sequence. Now (but is not j Gx)] entails Ga, but this is If a particularly temporally-projectible change temporally-projectible. consequents that any true nomic generalization consider a non-counterlegal entailed by) (Vx)(Fx > Gx). Consequently, implication implication. not a first-order our goal is Ga, one way to achieve that goal is to achieve the subgoal Fa. are the negations of true nomic generalizations. there cannot be true planning-conditionals It can, however, be an important (Fx + Gx). This entails is an expectable-result nomic generalization for planning. Furthermore, [Fa & (Fx More generally, let us define: P nomicully r U (P} entails Q. implies Q iff there is a set r of true nomic generalizations such that If the logical-consequence entailments employed is an expectable-result the warranted conclusion It will be syntactically warranted conclusion relation in (R4) is construed sufficiently broadly in the definition of nomic implication, of an action-sequence that P nomically and the planning implies Q, then Q is also an expectable-result. convenient that P nomically to abbreviate “the planning agent is able to reason to the imply Q”, implies Q” as “P is known to nomically to include the it follows as above that if P to agent is able to reason 306 J.L. Pollock /Arti$ciaE Intelligence 106 (1998) 267-334 but it must be acknowledge (R4) equivalently as follows: that this is not a literal use of “known”. Then we can express (R5) Where start-state is a state of affairs, conditionals is a set of planning-conditionals, and to < . < tn+l is a sequence of times, P-at-t,+, (Al -at-tl, relative to start-state and conditionals . . , An-at-t,) iff either: is an expectable-result of (i) n = 0, P is temporally-projectible, (ii) n > 0, P is temporally-projectible, (A,/ C) l P such that C-at-t, at-t,_l) and tn+l > tn; or and P-at-to is true in start-state; or and conditionals contains a conditional is an expectable-result of (A 1 -at-t1 , . . . , A,,_ I- (iii) II > 0, P-at-t, A,_,-at-t,_,), l -Q (L/C) expectable-result (iv) n > 0 and P-at-t,,+, of (A 1 -at-t1 , . . . , is a temporally-projectible and conditionals does not contain a conditional of the form is an such that Q is either P or a conjunct of P, C-at-t, expectable-result of (Al-at-tl, . . . , A,_,-at-&_I), and &+I > tn; or is a conjunction whose conjuncts are expectable-results of (Al-at-tl, . ., A,-&-&); or (v) n > 0 and P-at-t,+1 is a logical consequence of some expectable-result of (Al-at-tl.. . , An-at-t,); or (vi) n > 0 and P-at-t,+1 result of (A 1 -at-tl, is known . , A,-&-&,). to be nomically implied by some expectable- Logical consequence in (R5), but it will be useful to keep it in the definition. 37 is the limiting case of nomic implication, so clause (v) is redundant 7.3. Collective undermining Should constraints the syntactical has the effect of making clause (R5) be adopted as our final definition of “expectable-result”? No, because relaxing (iii) unreasonable. Clause (iii) plays a double role. It tells us that we can defeasibly project an expectable- result P forwards through the plan, and it tells us when the structure of the plan blocks that to clause (iii), the projection becomes unreasonable only when later projection. According steps of the plan can be expected to make P false (i.e., undermine it). However, having now allowed planning-conditionals arises that the consequent of a planning-conditional -( P1 & resolving these previously expectable-results will not obtain. But we have no way of determining which it is that will not obtain, so we should be agnostic and refrain from concluding of any of them that it will obtain. 38 In other words, they all cease to be expectable-results. This is a kind of collective undermining. logical form, the possibility might be the negation of a conjunction, In accordance with the reasoning . . & P,), of previously the Frame Problem, we can infer that the consequent to have consequents of arbitrary is true, and hence one of expectable-results. This point can be made logically more are expectable-results of (A1 -at-tl, rigorous . . , A,z_l-at-t,_l), as follows. Suppose PI, . , Pn but we have a planning-con- 37 1 assume that the set of warranted conclusions to known logical consequences. restricted in the logic of defeasible 38 Technically, reasoning is closed under logical consequence. so clause (v) need not be this is a case of collective defeat. J.L. Pollock /Artificial Intelligence 1 ffi ( 1998) 267-334 307 (A,/C) ditional (A,-at-tl, result of (Al-at-tl, of (Al-at-~,..., an expectable-result expectable-result, F -(PI & . . A,_l-at-&_I). . & P,) such By clause (ii), that C-at-t, -(PI & is an expectable-result of . . & Pn) is an expectable- that each Pi is an expectable-result , A,-&-&). We can infer . A,-&-&), and then by clause of (A I -c&t], . . , A,-at-t,,). (iv) we get that (PI & So we have a contradiction ... & Pn) is being an and then by clause (v), everything becomes an expectable-result. (R5) must be revised. We do not want (PI & . . . & P,) to be an expectable-result . . . , A,2-ut-t,), of (Al-at-t], expectable-results by our having the planning conditional expectable-result undermining. and the only way to deny that is to deny that the Pi’s are . , A,, -at-t,). The projection of the Pi’s must be blocked (A,, /C) w -(PI & . & P,), where C-at-t, is an of (A 1 -u&t I . . . . , A,? _ 1 -a?-r,, _ 1). In other words, we must have collective of (A 1 -at-t], This suggests revising clause (iii) as follows (where LrX is the conjunction of a set X of propositions): is a temporally-projectible IZ > 0. P-at-t, at-t,_ I), and conditionals does not contain a conditional of the form (A,, / C) k -l7X such expectable-result is a temporally-projectible A,_ 1 -ut-t,z_l ), tn+l > t,,, and X is a set of temporally-projectible of (Al-at-t], of (Al-at-~, expectable-results one of which is P. . . . , A,_l-at-t,_l), expectable-result that C-at-t, of (A 1 -at-t1 , . . . , A,_ I- . . , that if (A,/C) This will not quite do, however. The difficulty generalizations you can always weaken the consequent of a nomic generalization (iii), as revised above, would result in every previously expectable-result any is. To avoid this we must require that X be a minimal conjunction of expectable-results: is that it follows from the logic of nomic then for any P. (A,/C) w -n(X U {PI). That is, by adding disjuncts. Thus being defeated if l -l7X expectable-result is a temporally-projectible and if conditionals contains a conditional of the form (An/C) N -l7X of (A1 -at-t1 , . expectable-results (iii) n > 0, P-at-t, at-t,_]), such that C-at-t,, is a temporally-projectible A,_1 -at-&_I), &+I > tn, X is a set of temporally-projectible of (Al-at-t], -l7Xo result of (A 1 -at-t], . . . . A,_l-ut-t,z_l). and P E X, then there is a conditional is a temporally-projectible X0 2 X, and P +! X0. such that C*-at-t, . . , A,_]-at-t,_l), expectable-result in conditionals (An/C*) w expectable- of (A 1 -at-t1 , . , A,_ I- , With this change, we can produce what seems to be an adequate definition of “expectable- result”: (R6) Where start-state is a state of affairs, conditionals is a set of planning-conditionals, and to -=z . . . < tn+l is a sequence of times, P-at-t,+1 (Al-at-tl,..., relative to start-state and conditionals is an expectable-result of iff either: A,-at-t,) (i) n = 0, P is temporally-projectible, (ii) n > 0, P is temporally-projectible, (A,/C) N P such A,_]-at-t,_]) that C-at-t, and tn+l > tn; or and P-at-to is true in start-state; or and conditionals contains a conditional is an expectable-result of (A1 -at-t], . . . , (iii) n > 0, P-at-t,, is a temporally-projectible expectable-result A,_1 -at-t,_] ), and t&/C) l -I7X if conditionals such that C-at-t, contains a conditional is a temporally-projectibie of (A 1 -at-t] , . , the form expectable- of 308 J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 expectable-results result of (A 1 -at-t1 , projectible then there is a conditional t,, is a temporally-projectible &-l), X0 2 X, and P $ X0; or II > 0 and P-at-t,+1 of (Al-at-tl, n > 0 and P-at-t,+] (Al-at-tl, n > 0 and P-at-t,+1 result of (AI-at-tl, is known . . . . A,-at-t,). . . . , An-at-t,); or . . , A,-&-&); or (iv> (v> (vi> . . , A,_ 1 -at-t,- of (A1 -at-t] , . I), tn+l > t,, , X is a set of temporally- , A,_1 -at-t,_ I), and P E X, in conditionals such that C*-at- of (A 1 -at-t], . . . , A,_, -at- expectable-result (A,/C*) N -l7Xo is a conjunction whose conjuncts are expectable-results is a logical consequence of some expectable-result of implied by some expectable- to be nomically 8. Revised rules for goal-regression planning If we add to (R6) the following definition of “expectable-result” for partial-order plans: P is an expectable-result linearization of the plan. of a partial-order plan iff it is an expectable-result of every This provides a semantics for goal-regression planning. We can then look for a set of proce- dures for constructing plans and attempt to prove the soundness and completeness of the set two and five provide the starting point of procedures. The procedures described in sections for goal-regression planning. for the construction of a sound and complete set of procedures the differences between (R6) and (R2). They must be modified somewhat to accommodate 8. I. Planning for implacandu (R2) and (R6)-(R6) first. (R2) recognized being derived logically Let us focus on the latter difference introduces that are logically or nomically There are two differences between mining, and it includes expectable-results expectable-results. of expectable-results case in which a conjunction tions were recorded in plans by including multiple goals and subgoals can extend the use of causal-links by allowing causal-links of the form n t + subgoal, + . . . -+ subgoal,, -+ n:! + goal, + . . -+ goal,, where the relationship between subgoal, implication. and subgoali+, or goali and godi+ l is one of logical entailment or nomic planning, To accommodate PROPOSE-NULL-PLAN, GOAL-REGRESSION, and SPLIT-CONJUNCTIVE-GOAL. To these we add one new rule: collective under- implied by other just one case That was the its conjuncts. Such logical deriva- in a causal-link. We this, we can begin with the three basic rules of goal-regression from other expectable-results. is achieved by achieving PLAN-FOR-IMPLICANDAx9 Given an interest subgoal + goal, adopt an interest in finding a plan for achieving goal, and given a nomic implication in finding a plan for achieving subgoal. If a plan 38 In traditional logic, if P implies Q. P is the impficam and Q the impficandum. J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 309 is proposed for achieving -+ subplan causal-link n + subgoal, subgoal of .subplan by the causal-link n -+ subgoal, goal, + achieve goal. each subgoal, construct a new plan by replacing . + subgoal,, -+ *jnish* + goal, -+ . . . + goal, + . + subgoal, + *$nish* + that the new plan will -+ subgoal + goal. Infer defeasibly . + goal, -+ is a logical entailment. nightmare. A special case of this rule occurs when the nomic implication As formulated, PLAN-FOR-IMPLICANDA planning much more difficult. However, rule can be eliminated. This can be seen by reflecting on the causal-link that result from its use. Consider It makes it turns out that all but one special case of this structure of plans the following cases: is a computational We never need a structure of the form L Qfl (P&Q)-, R+ S-n 2 of nomic implication, it can always be replaced by the because, due to the transitivity simpler structure L Q” (P&Q)+ S-+ n2 Similarly, where A is the action prescribed by n2, we never need a structure of the form IJ > Q (P&Q)-+ S+n2+ R because can build a plan with the simpler structure if (P & Q) =+- S and (A & S) =+ R, we also have (A & (P & Q)) 3 R, and so c4 Q” (P&Q)* n2+ R We never need a structure of the form % Q” V&QhR s> (R&S)+ n2+ G because if (P & Q) + R and (A & (R & S)) + G, we also have (A & ((P & Q) & S)) + G, and so can build a plan with the simpler structure P ; P&Q), Q ,,((P&Q)&S)+ n2-’ G We never need a structure of the form 310 J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 because if (A & P) + Q and Q + R then (A & P) + R, and so we can build a plan with the simpler structure P+nz-+R We never need a structure of the form *start* --+ Q + R if Q is true and Q =+ R then R is true, and hence we can build a plan with the because simpler structure *start* -+ R Only one case remains. Where goal is the ultimate goal of the planning exercise (not just a subgoal generated in the course of the planning), a structure of the form n1-, P > 0’ & Q)+goal n2+ Q cannot be eliminated. allowing So a restriction its use only as the first step of the plan search. can be imposed on PLAN-FOR-IMPLICANDA It is clear that further restrictions must be imposed on PLAN-FOR-IMPLICANDA its application efficient. For example, given an interest we do not want to automatically the form (G & P) for arbitrary P. However, I will not pursue this point here. to make in finding a plan for achieving G, adopt interest in finding plans for achieving every goal of 8.2. Collective undermining As before, an application of SPLIT-CONJUNCTIVE-GOAL produces a plan which may some of its own causal-links. We must adopt rules to search for underminings undermine becomes more complicated them and repair because relaxing out the logical details of this, let us revise follows: if possible. Now, however, undermining the syntactical constraints gives rise to collective undermining. To work as the definition of presumptive-soundness relative to a set conditionals of planning-conditionals A plan is presumptively-sound and a state start-state (1) where goal subgoal1 -+ iff is the goal of the plan, the plan contains a causal-link nl + . + subgoal,, + goal + *finish* + goal, and (2) for every causal-link n1 -+ subgoal1 + . . . + subgoal, -+ n2 + goal1 + . . . -+ goal, of the plan: (a) if n # 1, then for each i such that 1 < i < n, either: is a conjunction, (i) subgoali+l subgoali plan also contains a causal-link subgoali+l subgoaq nT + subgoae;’ + . . --+ subgoal,, + n$ + goal, -+ is the other conjunct of subgoali+, ; or -+ (ii) subgoali+ 1 is nomically implied by subgoali ; is one of its conjunct& and the . . . -+ subgoaq + . . + goal,, where J. L. Pollock /Ar@cial Intelligence 106 (1998) 267-334 311 (b) if m # 1, then for each i such that 1 6 i -e m, either: (i) goa~~+~ is a conjunction, goali is one of its conjuncts, also contains a causal-link nT + subgoal1 + and the plan . . . -+ subgoal,, --+ nz + . . . -+ . . . --f goal; + goa&+, + goaq + the other conjunct of goali+ 1; or (ii) goaZi+l is nomically implied by goali ; . . + goal,,, where goaq is (c) if n, = *start* (d) if n2 # *$nish* then subgoal1 is true in start-state; then if A is the action of n2, “(A/subgoal,) l goal,” is a member of conditionals; (e) if 121 # *start* subgoal$ then the plan contains a causal-link ng -+ subgoal;f + . . -+ goal*,, -+ subgoalI; -+ n4 + goal; + . + (f) n 1 is ordered before n2 by the ordering-constraints (g) subgoal,, is temporally-projectible. of the plan; and To accommodate collective undermining, let us define: IZ of a plan collectively undermines A plan-step . . . -+ subgoal,, + n2 -+ goal, + such that: (i) n occurs between n1 and n2, (ii) there is a set X of temporally-projectible nl + subgoal1 -+ . . . + goal,,, iff there is a linearization of the plan a causal-link expectable-results of the sequence of actions prescribed by the plan-steps preceding n in the linearization (a) subgoal1 E X; (b) -I7X is an expectable-result of the sequence of actions prescribed by the such that: plan-steps *start*, . , n in the linearization; (c) there is no X0 such that X0 c X, subgoal, +! X0, and -I7Xo is an expectable- result of the sequence of actions prescribed by the plan-steps *start*, . . , n in the linearization. Given a causal-link nl + subgoal1 -+ . . -+ subgoal,, -+ n2 + goal1 + . . . + goal,, let n 1 be its root, n2 its target, and subgoal1 its initialsubgoal. The most manageable case of collective undermining Let us define: occurs when the set X is a set of initial subgoals of causal-links. A plan-step s of a plan collectively undermines a set C of causal-links linearization of the plan such that: iff there is a (i) s occurs between (ii) the initial-subgoal (iii) the negation of the conjunction an expectable-result *start*, . , s in the linearization; the root and the target of each member of C; of each member of L: is temporally-projectible; of the initial-subgoals of members of C is of the sequence of actions prescribed by the plan-steps (iv) there is no set ~5* of causal-links of the conjunction result of the sequence of actions prescribed by the plan-steps *start*, . . , s in the linearization. of the initial-subgoals of plan such that C* c C and the negation of members of L* is an expectable- 312 J.L. Pollock/Artificial Intelligence 106 (199X) 267-334 the plan -+ throw-ball the ball and hitting the target. The causal-links -+ hit-target,start* To illustrate with a contrived example, consider a game in which you throw a ball at a target mounted on a wall, and then the ball falls into one of two buckets. I am a good enough pitcher to be able to hit the target reliably, but not good enough to be able to determine the buckets are initially empty, and the goal into which bucket the ball will fall. Suppose is to hit the target and have the buckets both empty. Consider to accomplish of this plan have this by throwing the form start* + have-ball -+ both-buckets-empty + *jinish* + both-buckets-empty, + both-buckets-empty + ynish* + both-buckets-empty. plan, because although in the target being hit, the ball will not both be empty after all. Given of the plan will fall, no causal-link set of causal-links consisting finish* -+ both-buckets-empty, jinish* + both-buckets-empty each member of that set is collectively undermined. This is obviously not a good the ball will result then fall into one of the buckets and they will the ball in the sense of Section 2, but the + both-buckets-empty +* -+* in the above sense, and hence that 1 cannot predict is undermined of start* + bucket-#l-empty and start* -+ bucket-#2-empty + both-buckets-empty is collectively undermined the buckets are initially empty and throwing and start* + bucket-#2-empty into which bucket -+ bucket-#l-empty Unfortunately, the ball and hitting the target. In this case the plan has just to hit the target and have bucket#l empty. Again, consider not all cases of collective undermining set of causal-links. Suppose mining a pre-existing is simply by throwing links, *start* -+ have-ball + *$nish* + bucket-#l-empty. fall into bucket #l. But now the collective undermining bucket-#l-empty + *finish* + bucket-#l-empty mining a set of causal-links. expectable-results subgoal of a causal-link result from collectively under- that in the preceding example my goal the plan to do that two causal- throw-ball + hit-target and start* -+ bucket-#l-empty + the ball might The plan is still not a good plan, because of the causal-link start* -+ does not result from collectively under- the set of two only one of which is an initial- Instead, it results from collectively undermining and bucket-#2-empty, bucket-#l-empty in the plan. Let us revise the definition of causal-soundness to appeal to collective undermining: is causally-sound iff it is presumptively-sound relative and the plan does not collectively undermine A plan planning-conditionals causal-links. to a set of true any of its own We can then prove Theorems 1 and 2 much as before. Let us also define: plana of plan. presumptively undermines a set of causal-links L: An embellishment of plan iff ( 1) plan0 is presumptively-sound, (2) the goal of plan0 is the negation of the conjunction of the initial-subgoals of members of L, (3) play, has a single penultimate plan-step s, and (4) there is a linearization of plan0 in which s occurs between the root and the target of every member of C. As illustrated above, the collective undermining undermining of a set of causal-links, because some of the expectable-results of a causal-link need not result from the in involved J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 313 the plan by adding causal-links the collective undermining may not be involved to extend the goal and subgoal of the causal-link), the collective undermining extended plan. That produces an embellishment to those expectable-results in the plan. However, it is always possible them both so that of the of a set of causal-links (making and adding attendant ordering-constraints, of the plan. We can then prove: does consist of a undermining Theorem 8. A plan plan collectively embellishment presumptively-undermines C, and plan+ of plan and a set C of causal-links qf plan+ undermines its causal-link L iff there is an such that plan+ (1) LEL (2) plan-t (3) there is no embellishment plan0 of plan+ and set L* of causal-links ofplan+ is causally-sound, and such that (a) plan0 presumptively-undermines (b) C* cl Lc, (c) L $ C*, and (d) plan0 is causally-sound. C*, An immediate corollary of Theorems 1 and 8 is: Theorem 9. A plan plan collectively undermines is a presumptiv- ely-sound embellishment plan+ of plan and a set G qf causal-links of plan+ such that plan+ presumptively-undermines its causal-link L #there C, and (1) LEG (2) there is no presumptively-sound links of plun+ such that (a) plan0 presumptively-undermines C*, embellishment plan0 of plan+ and set L* of causal- (b) .c* c Cc, (c) L 4 L*, and (d) piano does not collectively undermine any of its causal-links. Translating Theorem 9 into a set of rules for defeating applications of SPLIT-CONJUNCT- for defeaters will consist of finding an IVE-GOAL is a bit complicated. The search appropriate planning-conditional (A/C) N -L7X, such that ( I ) A is the action prescribed by some plan-step s, (2) the initial-subgoal of some causal-link L is in X, (3) the ordering of the plan-steps can be extended so that s occurs between the root and target of L, (4) an embellishment achieving C can be constructed in such a way that all the plan- steps precede s, and (5) embellishments can be constructed with the original embellishment target of every link that establishes one of these members of X. that achieve the other members of X and merged the root and in such a way that s occurs between The defeater produced subset X0 of X that satisfies (l), (4) and (5) but not (2). in this way is itself defeasible, being defeated by finding a proper 314 J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 We canimplementthis by replacing UNDERMINE-CAUSAL-LINKS and UNDERMINE- CAUSAL-LINK by the following triple of rules: COLLECTIVELY-UNDERMINE-CAUSAL-LINKS accordancewith Givenaninferencein CONSTRAINT, or CONFRONTATION to the conclusion at-t, adopt interest in establishing causal-links. links, take the inference defeated. If it is determined to the conclusion SPLIT-CONJUNCTIVE-GOAL, ADD-ORDERING- thatplun & will achieve (Gt & G2)- that plun & collectively undermines one of its own that it does collectively undermine one of its own causal- to be that plan & will achieve (G 1 & G&at-t UNDERMINE-CAUSAL-LINK in establishing that plan& collectively for each causal-link n 1 + subgoal1 + adopt interest in finding an embellishment between nt and n2 consistent with the ordering-constraints one of its own . . . + subgoal,, -+ n2 + goal, + plan0 of plan& Given an interest causal-links, . . -_, goal,,, of plan&, that achieves -subgoal1 of plan &. Given plunO, infer nondefeasibly its own causal-links. that plan & collectively undermines one of undermines COLLECTIVELY-UNDERMINE-CAUSAL-LINK in establishing that plan& collectively for each causal-link nl + subgoal, of plan&, one of its own Given an interest -+ . . . + subgoal,, + n2 --+ goal, -+ causal-links, . . . -+ goal, plan0 of plan & such that (1) plan0 achieves -(subgoal, & g) between n I and n2 consistent with plan* of plan0 the ordering-constraints that achieves g before some penultimate infer nondefeasibly that plan & collectively undermines one of its own causal-links. node of pluno. Given plan0 and plan*, in finding a g and an embellishment and (2) there is an embellishment adopt interest undermines of plan&, Here g is ZI(X - (subgoal,)). The defeasibility of the defeat results from the defeasibility of the inference that plan* will achieve g. to the conclusion UNDERMINE-EMBEDDED-CAUSAL-LINKS and UNDERMINE-EMBEDDED-CAUSAL- LINK are replaced by an analogous triple of rules. There are two ways of repairing plans that collectively undermine some of their own causal-links: ADD-ORDERING-CONSTRAINT a conjunctive in finding a plan for achieving for gl-at-t and plan2 for g2-at-t, by merging plans plunl and plan, Given an interest and plans plan, (gt & g2)-at-t, constructed plans), but a plan-step n of plan& links n 1 + subgoal1 -+ . . . -+ subgoal,, + n2 + goal, + undermining constraint of C (if this can be done consistently) goal (gt & g2)-at-t, if plan& is a putative plan for (and possibly other one of its own causal- . . . + goal, by collectively a set of causal-links L, construct a plan plan+ by adding an ordering- the root and target of some member that plan+ will achieve to the effect that that n not occur between and infer defeasibly collectively undermines (g1 & gzw-t. J. L. Pollock /Art$ciai Intelligence 106 (I 998) 267-334 315 undermines collectively a conjunctive if plan& and plan2 a set of causal-links L by virtue of there being an embellishment in finding a plan for achieving for gl-at-t, and plan2 for g2-at-t, by merging plans plan, constructed CONFRONTATION Given an interest goal (gt & g2)-at-t, and plans plan, is a putative plan for (gl & gz)-at-t (and possibly other plans), but a plan-step n of plan& one of its own causal- links II 1 -+ subgoal1 -+ . . . -+ subgoal,, + n2 --+ goal1 + . . . -+ goal, by collectively undermining plan, that achieves P, where P is the negation of the initial subgoal of some member of C, then for each causal-link no --+ G 1 + in . . . + G, -G 1, I. If a plan repair-plan finding a plan for achieving construct a new plan plan+ and causal-links of repair-plan, with the following exception. Replace each causal-link in repair-plan by the causal- of the form n* + SGl --f . . . -+ SG, -+ *jinish* --f SG, link n* + SG, + . . . -+ SG, --+ n -+ SG,, and order n* between no and n. If this ordering -+ n + P of piano, adopt interest is proposed for achieving the plan-steps, ordering-constraints, that plan+ will achieve (~1 & g2)-at-t. infer defeasibly is consistent, by adding to plan& -G that collectively undermines CONFRONTATION works by undermining the causal-link of the original plan. Note, however, that CONFRONTATION requires outright undermining, leave open the not collective undermining. Collective undermining would possibility the causal-link of the original plan) in some cases even if does not do so in all cases. that the embellishment will achieve its goal (and undermine the embellishment Similar modifications are required to ADD-EMBEDDED-• RDERING-CONSTRAINT and EMBEDDED-CONFRONTATION. This set of rules for goal-regression planning the set of rules of Section 4 was sound and complete successfully the syntactical constraints of Section 2. removed is sound and complete, for the same reason to (Rl). Thus we have relative Implementation. With the exception of PLAN-FOR-IMPLICANS, described above have been implemented an implemented CAR’s macro REGRESSION is implemented by defining: defeasible planner. The implementation of inference-schemes. for the construction in the OSCAR defeasible language the inference-schemes reasoner is straightforward to produce using OS- For example, GOAL- (def-backwards-reason GOAL-REGRESSION :conclusions “(plan-for plan goal)” :condition (interest-variable plan) : backwards-premises “((precondition & action) => goal)” (:condition “(plan-for “(define plan (extend-plan action goal subplan))” (:condition (temporally-projectible subplan precondition new-goals nodes nodes-used (not (null plan))) precondition)) links)” :variables precondition action goal plan subplan) where EXTEND-PLAN is defined by a piece of LISP code. The details of this implementa- tion are described report and the imple- mented planner can be downloaded from my website (http:Nwww.u.arizona.edu/-pollock). report [37], and both the technical in a technical 316 J. L. Pdlock /Arti$cial Intelligence IO6 (I 998) 267-334 inference illustration is applied to planning of this is that the planning are based on special-purpose to planning. The OSCAR planner reasoner. The reasoner that concern plans, but the structure of the reasoner engines is based instead on a general- it with by providing itself remains rules need not mention that is all handled automatically by the defeasible causal than adopting it easy for and Simple extensions. Most planners dedicated exclusively purpose defeasible reasoning-schemas unchanged. A simple unification or variable binding, because reasoner. One of the consequences information a special action about other matters with its planning, the OSCAR planner rules to accommodate more complex planning it makes considerations that are beyond the scope of most planners. The next three sections illustrate this by showing how the OSCAR planner can reason about concurrent actions, quantified preconditions in which objects are created and destroyed, and causal connections in terms of conditionals, like STRIPS or ADL. This makes about actions very simply language is that we can represent temporal relationships. and effects, domains involving complex it easy to extend of this approach representation the planning to combine reasoning rather 9. Concurrent actions results” and Chapman It is often observed that either the STRIPS or ADL representation actions can conspire actions. Pednault instead the results of concurrent actions, because concurrent that are not results of the individual actions and construct plans this, we simply allow A in the planning-conditional of actions precludes to produce the possibility of concurrent [27] gives the “cooperative [6] gives the example example of lifting both sides of a table simultaneously, the of pressing down on both sides of a Lego die. It is perhaps of interest that representing makes it quite easy to both results of actions in terms of planning-conditionals that use those results. To describe l G to be either accomplish Then we can describe an action or a conjunction like ((lift the cooperative right side of table at time t & E$t Left side of table at time t)ltable weighs less than 100 pounds) w (table suspended above Jloor at time t*)). Where A and A* are conjunctions I will write A & A* iff every conjunct of A is a conjunct of A*. 40 Because of actions, if A 2 A* and (A/C) w G, it follows that planning-conditionals are nomic generalizations, results. (A*/ C) N G, so adding conjuncts can only give rise to new results-not To accommodate concurrent actions in our definition of expectable-result, we allow each to be either a single action or a conjunction of actions, and modify results of concurrent actions by employing planning conditionals of actions performed simultaneously. conflicting (A/C) Ai in an action-sequence clauses (ii) and (iii) accordingly: (R7) Where start-state and to < (A 1 -at-t1 , . . . , A,-at-t,) is a state of affairs, conditionals . < tn+l is a sequence of times, P-at-t,+1 relative to start-state and conditionals iff either: is a set of planning-conditionals, is an expectable-result of (i) n = 0, P is temporally-projectible, and P-at-to is true in start-state; or 4” If A is not a coniunction, I take it to be its own only conjunct. J. L. Pollock /Artificial Intelligence 106 (1998) 267-334 317 (ii) IZ > 0, P is temporally-projectible, and for some A,* C An, conditionals (AE/C) w P such that C-at-t,, is an expectable-result contains a conditional of (Al-at-tl,..., (iii) n > 0, P-at-t, A,_l-ut-t,l_l) and tn+t > tn; or is a temporally-projectible expectable-result of (Al-at-tl, . . , of (A,-at-t], A,_, -at-t,_*), and if for some AZ C A,, conditionals contains a conditional of the form (A,/C) N -l7X expectable-result of temporally-projectible and P E X, then for some A,* C A,, conditionals (AZ/C*) k -l7X0 result of (Al-at-tl, is a set tn+l > tn, X of (A 1 -at-t] , . . , A,_ 1 -at-t,_ I), is a temporally-projectible X0 C X, and P # X0; or contains a conditional expectable- such that C*-at-t, . . . , A,,_)-at-t,,_l), such that C-at-t, . .., A,_,-ut-t,_l), is a temporally-projectible expectable-results (iv) IZ > 0 and P-at-t,+* is a conjunction whose conjuncts are expectable-results of (Al-at-tl, . . , A,-at-c,); or (v) IZ > 0 and P-at-t,+1 is a logical consequence of some expectable-result of (Al-at-tl, . . . , A,-at-t,); or (vi) n > 0 and P-at-t,+, is known to be nomically implied by some expectable- result of (Al-at-tl, . . , AR-at-t,,). TO construct plans with this semantics, we record each conjunct of a conjunctive in a separate plan-node REGRESSION as follows: action (but all with the same time reference). Then we modify GOAL- GOAL-REGRESSION Given an interest adopt interest in finding planning-conditionals Given such a conditional, is concluded in finding a plan for achieving G-at-t, if G is temporally-projectible, adopt an interest in finding a plan for achieving C-at-t*. If it (A/C) N G having G as their consequent. that a plan subplan will achieve C-at-t*, construct a plan by (1) adding new steps to the end of subplun where each new step prescribes an action Ai-at-t* where Ai is a conjunct of A, (2) adding the constraint (3) adjusting the causal-links (t* < t) to the ordering-constraints of subplan, and appropriately. Infer defeasibly that the new plan will achieve G-at-t. In ADD-ORDERING-CONSTRAINT, EMBEDDED-GOAL-REGRESSION required. undermining undermined the possibility of concurrent actions, step not occur between causal-link was previously must be modified the requirement similarly. Only one other change t of the the tl and t2 of the root and target of the taken to mean that either t -c tI or t2 -c t. Given time that the times it must mean instead that either t < rl or t2 < t. 10. Quantifiers, creation and destruction The preconditions and consequents of planning-conditionals often involve quantihca- tion. A standard example for putting block A on block B is that there isn’t already a block on block B. Thus in order to put block A on block B, if block C is already on block B, GOAL-REGRESSION will lead us to try to find a plan for removing [45] is that a precondition 318 J.L. Pollock /Art@&1 Intelligence 106 (1998) 267-334 it. There are two radically different ways of doing this. We might put block C elsewhere, or we might zap it with a block-destroying ray gun. ADL makes the assumption executing a plan, thus precluding [27, p. 691. Accordingly, to expand universally disjunctions that nothing the second way of solving is created or destroyed the standard way of handling quantification in the course of the above planning problem is or in planning finite conjunctions into or existentially quantified formulas ranging over all the actual objects in the fixed planning domain [45]. Given the semantics for planning provided by (R7), there is no need to restrict planning to either fixed or finite domains. Let E!(x, t) mean “x exists at time t”. Then to (Vx)[E!(x, t) > pat-t]. A planning-conditional problems [(Vx)@]-at-t governing putting one block on another is: is taken to be equivalent (put A on B at t/-(3x)(x on B)-at-t) l (A on B at t*). The goal of having A on B at time t will then produce the subgoal of having -(3x)(x on B)-at-q for some tt < r . Suppose that C is the only block on B at the start-time to: (Vx)[(x on B) ZE x = Cl-at-to. (10.3) logically entails (Vx)[(x OIZ B) > x = Cl-at-to. Assuming temporal-projectibility, we can infer defeasibly: (Vx)[(x OIZ B) > x = Cl-at-q. (10.5) conjoined with either -(C OIZ B)-at-t1 or --E!(C, t1) 10.1) 10.2) (10.3) (10.4) (10.5) (10.6) (10.6*) logically entails as subgoals PROPOSE-NULL-PLAN). We can achieve (10.6) by moving C to another can achieve (10.6*) by zapping C. (10.2). Thus PLAN-FOR-IMPLICANDA gives rise to (10.6) and (10.6*) (conjoined with (10.5) which also becomes a subgoal but is achieved by location, or we into conjunctions and the creation or This example illustrates that the expansion of quantified formulas involving the expansion can foil a planning problem by making solutions disjunctions destruction of objects unavailable. But sometimes to correct. If my goal is to have all the lights in the room turned on, it would be perverse them. The try to achieve this by either removing all the lights from the room or destroying problem is that the English formulation of the goal as “make it the case that all of the lights in the room are turned on” is ambiguous between “make it that case that (Vx) (X is a light in the room at t > x is turned on at r)” and “make it the case that (Vx)(x is a light in the room at to > x is turned on at t)“. The former goal can be achieved by removing or destroying lights, but the latter goal can only be achieved by turning on all the lights currently seems to be intuitively in the J.L. Pollock /ArtQicial Intelligence 106 (1998) 267-334 319 room. However, none of this is a problem goal is formulated precisely to distinguish between these two readings. for the OSCAR planning system as long as the requirement that the expansion of quantified formulas assumes a finite domain. It is worth noting in the OSCAR But there is no finiteness system of planning. The above example did assume that there are only finitely many things on B, but that is just a feature of that particular example. there were infinitely many blocks on B, but we had a block-zapper destroy all the blocks atop a given block, then we could solve the planning problem even more simply and without using (10.4). for planning with quantified that would simultaneously If instead formulas 11. Accommodating complex temporal relationships equivalent to the situation calculus Most current planners employ a STRIPS or ADL representation of actions. As Pednault [25]. In particular, [27] shows, ADL is expressively time is represented by discrete this paper I have been implicitly time points. Throughout assuming metric time, times being represented by real numbers, but none of the planning rules simple ordering of times. However, connections between relationships temporal ball illustrated is a I remarked at the end of Section 5 that the causal actions, preconditions, involve more complex and effects, can than those symbolized using ‘>‘. The example of serving a tennis the use of a nomic conditional of the form so far in this paper that, because ‘N’ requires turn upon formulated all { (A*-at-t & SG-at-t + a) =+ (36)G-throughout-(t + E, t + E + S]}, where the time of the action involved reasoning in planning can employ conditionals of the form is the time at which it begins. More generally, the causal ((A*-at-t & (SGI-throughout-[t +a~, t +j+] &...& SG,-throughout-[t + (Y,, t + pm])) =+ (36)G-throughout-(t + F, t + 6 + 61). I will abbreviate this as (A/SGl, . ‘E&b . , SGd . G where SG, CZ!, and ,L?I are finite sequences. ,...., more If j3 is a sequence of zeros, I (AI=) will omit it. If cx is a sequence of zeros as well, I will omit both. If E = 0 too, I will omit all three subscripts. can be used in planning, planner. to see how these more complex planning-conditionals and to show that they present no serious obstacle to the OSCAR It is of interest simply +&.(a a,),(p pm) ,...., G, as or to accommodate We must generalize our semantics in terms of the concept of an expectable-result, the use of these conditionals. That semantics proceeds but that can no longer be defined using the kind of definition exemplified by (R2)-(R7) which recourses on the in action sequence of actions. The problem is that time delays A,_, -at-t,_1 making P true, but only after t,,. We can instead define the expectable- interval over which P can be defeasibly expected the actions in the sequence. Even this is complicated, because conditionals to a single action, with the result that the single action can first to be true as a result of performing there can be multiple planning- in causation may result appealing 320 .l L. Pollock /Artijicial Intelligence 106 (1998) 267-334 make P true and later make it false. For example, eating dinner early may make me not hungry an hour from now but hungry again 3 hours from now. To handle all of this we consider the sequence of all times at which the expectable-intervals may change as a result recursively on the basis of that of something happening, and define the expectable-intervals sequence. This sequence of times is characterized as follows: Given a set of planning-conditionals . ..( A,-at-t,,), to together with all times conditional and a starting-time ti + conditionals, an action-sequence to, the sequence of associated-times (A 1 -at-t1 , consists of E such that 1 < i < n and conditionals contains some (Ai /C) N~.~,B P. The sequence of associated-times is ordered by ‘ 6 ’ . (W Where conditionals is a set of planning-conditionals, of times, and (Al-at-tl, sequence of associated interval Z( P, (to, . . , ti)) is an action-sequence, . . . , An-at-t,,) times. For each temporally-projectible is defined recursively as follows: to -c . . -c tn+l is a sequence , rk) be the P, the expectuble- let (to, if P-at-to otherwise, is true, ifi >O zO(P, (TO> . ’ I(P, ‘3 ri)) (to, . . ti-1)) U (r;, 00) if for some AZ C A,, conditionals contains a conditional (AZ/C) •E.(I,~ P such that for each Ci in C, [ti+LYi-&E,~i+Bi-El~Z(Cj,(tO,...,~i-_l)); = (TO,. . , Tii-I)) - (ti, ~0) if for some AX C A,, conditionals I(P, contains a conditional [ti+~i-E,ri++i-E]EZ(Cj,(to and there is no A,+ c A, such that conditionals contains a conditional (AZ/C*) (AZ/C) w~,~,J -l7X ,..., such that for each CT in C*, ri_])), PEX, •J,~,A -l7Xa such that for each Cj in C, [ti + yi - 8, ri + h; - 61 C Z(CT, (ro, . . , r;_t)), Xo s X, and P 6 X0; < Z(P, (to,. . , Ti _ I)) otherwise. Z(P, (to, . ., ri )I =u(nc &(Q, (re, . , ti)) 1 Q E X} 1 I7X is known to nomically imply P I P-at-t is an expectable-result of (A 1 -at-t1 , . . , An-at-t,) iff t E Z( P, (to, . . . , ti)). P-throughout-[t, t*] isanexpectuble-resultof (Al-at-t], . . , An-at-t,) iff [t, t*] s z(P, (50,. . , ti)). there are three ways the expectable-interval To explain, there may be a conditional (A,*/(T) •E,(Y,~ P that makes P expectably This results in our adding (ri , co) to the previous expectable-interval Second, there may be a conditional true from ri forwards. This results in our deleting , s;-1 )). I assume Z( P, (~0, . expectable-interval for P can be altered at ri. First, true from ri forwards. . . , zi- I)). Z( P, (to, •F,OI,~ -l7X making P no longer expectably the times in (ti , CO) from the previous that these first two cases are mutually (AZ/C) J.L. Pollock /Artijicial Intelligence 106 (1998) 267-334 321 resulting in P and -P implied by by other expectably exclusive. There cannot be true causal connections caused at the same time. Zo(P, (TO, . , ti)) from planning-conditionals by being nomically X of propositions whenever that are known all members of X are expectably is the expectable-interval governing P. However, P can also be made expectably both being that results directly true true propositions. Given any set true include that are imply P, so we take Z( P, (~0, . , t;)) to be the union of all implies P, Zo(P, (to, . . . , xi)) 2 directly affecting P, true. So I( P, (to, . . . , ti)) must if there are no planning-conditionals imply P, P is expectably nczo(Q, known such intersections. Note that because Z(P, t )) I Q E X). This holds for every set X of propositions to jointly nomically to jointly nomically , ti)). Furthermore, IT{ P} nomically (to,. . , i (TO, Zo(P, (to, . f. 1 Ti)) =Z(P, (to. . . . . s;-I)). so z(Pt (W,. ., ti-1)) C z(P, (TO, .* ri)). To illustrate at the starting time to, and suppose we have the planning-conditionals this complex definition with a simple example, suppose Ct and C4 are true (Al/Cl) w~,,~, C2, +Zj. Suppose actions A 1 and A2 are performed at (A2/C2) times tt and t2, where to < tl < tl + 011 < tl + ~1 < t2 < t2 + ~22 < t2 + ~2 c t2 + a3 < t:!+&g.Thentheassociatedtimesarero=to.tl The expectable-intervals =tl +~l,t2=t2+~2,andt3=t2+~3. then evolve as follows: ‘e2,0rz c3, (A2/C4) ‘q,q Expectable-intervals relative to (TO) : to TO Cl [ro........................................................................~) c2 C3 c4 [50........................................................................~) Expectable-intervals relative to (to, 51): A1 to t1 t1 +a1 t1 +El TO Tl Cl [to........................................................................~) c2 c3 (t1..........................................................00) c4 [to........................................................................~) 322 J.L. Pdock /Arti$cial Intelligence 106 (1998) 267-334 Expectable-intervals relative to (to, tl, ~2): A1 A2 to t1 t1 +cr1 t] +&I t2 t2+c!2 t2+&2 to Tl t2 Cl [~O........................................................................~ c2 C3 (q.. ...................................................... (q ........................................ c4 [ro........................................................................~ Expectable-intervals relative to (to, tl, ~2, ~3): Al A2 to t1 tl + al t1 + El t2 t2 + %2 t2 + F2 t2 + a3 t2 + Ej TO Tl 52 tg ) ..oo) cm) ) Cl [TO. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ., . . . . .co) c2 C.1 (t1..........................................................00) (t2.. . . . . . . . ,531 c4 [to. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .ca) NOW consider how this altered semantics affects the rules for planning. The changes are minor. First, the ordering-constraints imposed by GOAL-REGRESSION must be adjusted: interest GOAL-REGRESSION Given an interest adopt consequent. Given such a conditional, the conjunction concluded plan by of the Ci-at-ti’s in finding a plan for achieving G-at-t, if G is temporally-projectible, in finding planning-conditionals adopt an interest (A/C) w~,~.B G having G as their in finding a plan for achieving that a plan subplun will achieve the conjunction for Ci in C (where each ti is a new variable). If it is of the Ci -at-ti ‘s, construct a (1) adding new steps to the end of subplun where each new step prescribes an action Aj-at-t* where Aj is a conjunct of A, (2) adding the constraint (t* +e -c t) and the constraints (ti -c t* +ai) to the ordering- constraints of subplan, and (3) adjusting the causal-links appropriately. Infer defeasibly that the new plan will achieve G-at-t. EMBEDDED-GOAL-REGRESSION must be modified similarly. The other changes required concern undermining causal-links. Consider a causal-link nl -+ subgod, + ... + subgoal,, + n2 + goal, + + goal, established using the J. L. Pollock / Artijiciul Intelligence 106 ( 1998) 267-334 323 (Al/subgoall) Furthermore, the time tt that ~11 is executed l E,(Y,~ goal, and (Az/goal,) WS.~,~ G. There will be planning-conditionals a time-lag E between of subgoal,. t2 that n2 is executed target-offset of the causal-link. Let us record these offsets by rewriting the form n 1 -fg subgoal, revise UNDERMINE-CAUSAL-LINK follows: (A 1 is performed) and the achievement true not just until the time and k the the causal-link in . . . + goal,,, . Then we as subgoal1 will be required (A2 is performed), but until to remain t2 + A. E is the root-ofiet and COLLECTIVELY-UNDERMINE-CAUSAL-LINK . -+ subgoal, + n2 +A. goal, + -+ UNDERMINE-CAUSAL-LINK interest that plan& Given an own causal-links, in establishing for each causal-link its . + subgoal,, -+ n2 +A -+ goal,,, ofplan &, where tl is the time of IZ 1 and t2 is the time of n2, adopt between of plan &. Given planO, infer goal, -+ interest tl + E and t2 + h consistent with the ordering-constraints nondefeasibly that plan & collectively undermines one of its own causal-links. plan0 of plan & that achieves -subgoal, in finding an embellishment nl +E subgoal, collectively undermines one of -+ COLLECTIVELY-UNDERMINE-CAUSAL-LINK Given an own causal-links, interest in establishing that plan& collectively one of its for each causal-link ~11 -+E subgoal, + in finding a g and an embellishment --+ n2 -+A . . + goal, of plan &, where tl is the time of n 1 and t2 is the time of n2, plan0 of plan & such that (1) plan0 tl + E and t2 + h consistent with the ordering- plan* of plan0 that achieves goal1 + adopt interest achieves constraints of plan&, g before some penultimate node of plaq. Given plan0 and plan*, that plan & collectively undermines one of its own causal-links. & g) between and (2) there is an embellishment infer nondefeasibly -(subgoal, undermines . + subgoal, and COLLECTIVELY-UNDERMINE-EMBEDDED- UNDERMINE-EMBEDDED-CAUSAL-LINK CAUSAL-LINK are modified analogously. The rules for finding embellishments must be modified constraints. The ordering-constraints FRONTATION, ADD-EMBEDDED-• RDERING-CONSTRAINT, and EMBEDDED-CONFRON- TATION must also be modified in the obvious way to take account of the causal-link offsets. added by ADD-ORDERING-CONSTRAINT, these slightly more complex ordering- in the obvious way to accommodate CON- 12. Conclusions Goal-regression planning is aimed at the construction to which a plan a set of ordering-constraints, adopted a certain conception of a plan, according quadruple consisting of a set of plan-steps, links, and a goal. The definition to which we can prove regression planning described goal-regression environments. planning applicable the soundness (R6) of “expectable-result” and completeness to planning by autonomous constitutes a semantics, of plans. In this paper I have is identified with a a set of causal- relative of the set of rules for goal- for rational agents in complex in Section 8. This provides a secure logical foundation 324 J.L. Pollock /Ar@icial Intelligence 106 (1998) 267-334 The theory of goal-regression planning developed in this paper draws heavily on agent embedded aimed at providing is that the planner proposed here is not an r.e. planner. in a complex environment must information theory, but there are also important differences. One important It has been argued interleave planning and this Instead, planning must be done defeasibly. conventional AI planning difference that a planning with epistemic cognition makes r.e. planning To accomplish taking goal-regression epistemic cognition whose purpose is to generate defeasibly form “plan p would achieve order consistent with its ordering-constraints”. implemented using the OSCAR system of defeasible to be a species of reasonable conclusions of the in any that plans in this way has been its goal if the prescribed plan-steps were executed logically this I have proposed needed for planning, impossible. reasoning. A system planning Viewing planning approach adopts the definition for planning. The conventional to prove the soundness and completeness foundation and then attempts concept of “result” is intended be as a result of executing defeasible expectations apparent instead be based upon the epistemic concept of an “expectable-result”. as an epistemic endeavor generates a different kind of semantical (RI) of “result”, of a planning algorithm. This the way the world will is based upon it becomes is possible. The semantics of planning must that planning results of actions, to be an objective concept describing rather than objectively determinate that no such definition of “result” the plan. But once it is recognized It has been argued here that goal-regression planning presupposes to the Frame Problem, and this generates the second important difference a certain kind of from theory. The solution in the process of inferring to the Frame Problem uses TEMPORAL- that a plan can be expected constraints and on the subgoals generated by GOAL-REGRESSION the imposition of temporal-projectibility to in theory imposes syntactical constraints on goals and planning- that, upon reflection, seem unreasonable. Once these constraints are relaxed, in various (R2) of “expectable-result” of failure of (R2) is that the logical and nomic consequences that the definition is inadequate are not automatically expectable-results. these shortcomings It also fails to accommodate (R6). leads to the final definition planning described The system of defeasible goal-regression in section eight and based in the OSCAR planner, which is based upon the OSCAR upon (R6) has been implemented system of defeasible reasoning. The resulting planner should, however, be viewed more as a proof of concept than as a serious attempt at building a practical planner. There has been to make it work. Much of the research no attempt to that has been directed at making classical planners more efficient the OSCAR planner, and can in principle be applied to the prioritization of the reasoning underlying the plan search. However, that is a matter for further research. to make it particularly is equally applicable efficient-just One feature of the OSCAR planner requires particular mention in this connection. “Standard’ partial order planners regress backwards achieve unachieved contrast, like SNLP and UCPOP produce partial plans as they from the goal, and extend the partial plans by either adding new steps to to resolve threats. By the OSCAR planner produces only complete plans, starting with short complete subgoals or adding steps or ordering-constraints solution conventional AI planning at crucial points PROJECTION achieve its goal, and that requires the definition of “expectable-result” and SPLIT-CONJUNCTIVE-GOAL. Conventional AI planning conditionals it becomes apparent ways. The most obvious expectable-results collective undermining. Correcting J.L. Pollock /Artificial Intelligence 106 (1998) 267-334 325 interests produced as entities them to build a complete plan for the final goal. plans for subgoals and then extending in Partial plans are, in effect, represented by the structure of epistemic the course of the plan reasoning, but they are not actually constructed to be reasoned about. A side effect of this is that the search for threats (or underminings) must be postponed until the plans are produced. There is much recent work on the issue of the (i.e., adding plan-steps) and threat resolution should occur order in which plan construction is Pollack et al. [31] and Gerevini to make a planner efficient. Of particular that and Schubert is otherwise it many cases it is best to postpone complete. (and Pollack et al. concur) In explaining that many threats will disappear during the course of planning as new ordering constraints them until and variable bindings are adopted, and so planning effort is saved by ignoring for postponing we know that they will not disappear. Note that this is also an argument threat resolution until we know that a threat is real, i.e., an undermining, which is just what the OSCAR planner does. So it is unclear whether this feature of the OSCAR planner is an advantage or a deficit. This is also matter for further research. [ 111. 41 Both papers produce substantial empirical evidence suggesting threat resolution until plan construction this, Gerevini and Schubert observe importance about system I expect reasoner. resistance A planning inefficiencies”, run more slowly that constructs plans by reasoning to the planning problem, and my proposed changes undermine In light of these “built-in to the proposal to this objection to a different problem. factual knowledge them defeasibly will than an r.e. planner because of the greater overhead of there to be that we should base planners on the semantics semantics provided by (Rl). Traditional researchers may insist that classical planning algorithms provide an efficient that inefficiency. of necessity the defeasible considerable provided by (R6) rather than the more traditional AI planning solution The proper answer efficient solution of the relevant projectibility expressing propositions, be satisfied by careful tailoring of the formalism, better solution based upon problem of understanding Classical planning The second with a complex and unpredictable indefensible. must be based upon (R6) and engage in defeasible planning. Classical planning algorithms are inapplicable. than a defeasible planner based upon (R6). (R6) and the defeasible planner to two ot‘her problems. The first is the theoretical in its full generality. algorithms based upon (R2) cannot provide such an understanding. provide an in which (1) all (2) temporal- to avoid and (3) the syntactical can then classical planning algorithms are a is that classical planning In an applied planning from tailoring agent that can deal (l)-(3) are in an uncooperative world, it is the problem of building a truly autonomous planning situation the start, the formalism If we want such an agent to behave rationally environment. For such an agent, assumptions can be avoided by carefully the logic of goal-reduction it are instead solutions temporally-unprojectible can be compiled-in constraints algorithms problems planning There has been much recent excitement [3,41 and SATPLAN Graphplan outperform traditional planners without using classical planning [201. On many problems, these planners dramatically like UCPOP and PRODIGY, and they appear to do so ideas like goal regression and threat-resolution. Does this about two new “non-traditional” planners- 4’ See also Peat and Smith [301, Joslin and Pollack [17], Srinivasan and Howe [42], and Williamson and Hanks [4f51. 326 J.L. Pdock /Artificial Intelligence 106 (1998) 267-334 encoding ideas irrelevant? to make the classical that the success of SATPLAN threaten I don’t think so, for at least two reasons. First, it is not clear why Graphplan and SATPLAN perform so well. For example, Brafman is attributable more to its use et al. [5] provide evidence from of stochastic search than to the propositional classical planning classical ideas. They construct a hybrid planner LSPS that combines ideas with stochastic search and find that in many cases it outperforms SATPLAN. planning Second, Graphplan that we have including knowledge of all existent objects complete knowledge of the planning domain, that assumption, and all effects of actions. The planners agent operating but that assumption in a complex for applied planning problems environment. in well controlled domains, but unable required by an rational agent. autonomous for an autonomous So these planners may prove very useful and SATPLAN make essential use of the assumption literally cannot function without that makes it part company is unreasonable the planning to provide resources foundation it possible is restricted (R6) makes in this paper the nomic generalizations to provide a firm logical the lit match under some kindling. One causal connection in autonomous agents. However, this work all presupposes are expressed by nomic generalizations. It can reasonably be objected that human that underlie they employ in planning. For example, suppose I plan to start a fire for goal- The definition regression planning the concept of a plan described above. This concept does not capture all of our planning endeavors. to “causal as discussed First, and most obviously, planning planning”, wherein the connections between actions and the goals and subgoals they aim at achieving is a causal one. Such causal connections This is a very strict notion of a causal connection. planning agents are rarely in a position of knowing the causal connections by striking a match and holding I am relying upon in this plan is that between striking a match and its lighting. certain conditions must be sufficient oxygen, list of conditions sufficient may seem to constitute a serious logical obstacle to applying I am above, but fortunately, that there is a condition C (possibly a long conjunction) which (1) when added confident and (2) C describes to the conditions conditions conditions” of a sort that can be expected to hold in virtually any case in which we try to light a match by striking it. and Thus, even without knowing what C is, we can take it to be established by a null-plan, we can assume that it is not undermined by subsequent plan-steps. This means, in effect, that C can be safely ignored I know of for the match to light-the match must be dry, there it must not be too windy, etc. But I cannot enumerate a complete imply that the match will light when struck. This to nomically rules formulated the planning that actually hold, and are very general “background I know will generate a true planning-conditional, fill out the list of conditions, it is not. Although 1 cannot that are required to achieve it is guaranteed In causal planning, do not fail. In this sense, to achieve its goal, because TEMPORAL- if the temporal its goal PROJECTION is defeasible. But projections to be correct, is guaranteed although presupposed persistences may fail. In this respect, causal planning contrasts with planning, probabilistic the actions and their effects are rather causal. Perhaps most cases of probabilistic planning can be reduced to probabilistic cases in which there are nomic generalizations as above, but the condition C is not known to be true. All we know is that C has a certain probability of being true, and that probability in light of the execution of some of the plan-steps. Probabilistic may change in which the connection between the causal structure planning is in planning. the plan is not guaranteed J.L. Pollock / Art$cial Intelligence 106 (I 998) 267-334 327 find ourselves for required in which we must plan, but lack the kind of causal knowledge a complicated matter, 42 but sometimes in situations causal planning. However, the investigation of such probabilistic goal-regression is beyond The the scope of this paper. theory of goal-regression it is unavoidable. We sometimes planning as well. This is most easily seen by reconsidering developed here has some more mundane the role of disjunctions shortcomings in planning. Once the syntactical constraints of Section 2 were relaxed, planning-conditionals introducing rules for goal-regression the rules of Section 8 still fall short of constituting planning. Those rules are complete for plans as thus far defined, but planning-conditionals with disjunctive consequents the possibility of with disjunctive consequents made everything more complicated by Section 8 showed how to construct collective undermining. However, the possibility of collective undermining. that accommodate in our concept of a plan. theory of goal-regression a complete planning planning reveal an inadequacy to think briefly about the source of disjunctive It is useful source of disjunctive to be two ways in which planning-conditionals The most straightforward It follows then [A/(P v Q)] N (R v S). Such planning-conditionals unprojectible preconditions, Section 8. from the logic of nomic generalizations with disjunctive consequents consequents. There seem can arise. consequents is disjunctive antecedents. that if (A/P) N R and (A/Q) N S will normally have temporally- and hence will be useless in planning according to the rules of indicated by a disjunctive consequent the indeterminacy built into the action. Real agents (e.g., human beings) are limited results instead from Sometimes indeterminacy in the precision with which they can perform actions. This limited precision can produce different consequences when the same action is repeated in essentially the same circumstances. For think of throwing a tennis ball “straight up” over the net of a tennis court. We instance, in throwing never really succeed the ball will land in one in the other court, and we cannot predict which. This can produce a court and sometimes with a disjunctive consequent even though there is no indeterminacy planning-conditional proposed in the precondition. Such planning-conditionals plans, but will be of limited use in planning because their temporally-unprojectible by GOAL-REGRESSION to produce a multi-step plan. in accordance with the rules of Section 8 together can play a role in undermining it straight up, so sometimes their being strung consequents preclude However, in real goal-regression planning, planning-conditionals with disjunctive an- are not useless. Disjunctions are often accurate representations tecedents and consequents in which an action may be performed. We may not of our knowledge of the circumstances is or will be true, and we must be able to plan in the face of such know which disjunct in planning? Suppose P, Q, ignorance. How can we make use of disjunctive we know P to be true, our goal is G, and we have the and R are temporally-projectible, planning conditionals b (Q v R). (AZ/Q) N G, and (Aj/R) N G. We know that if we perform A 1, either Q or R will result, but we cannot be sure which. We cannot plan the next step of a plan, but what by projecting to the time we perform If A1 produces we can do is consider in time, perform A?, and thereby achieve G. If instead Q. we can project results of the first step separately. (Q v R) forwards the two possible that forwards information (Al/P) 42 See. for example, BURIDAN, as described in Kushmerick et al. [Zll. 328 J.L. Pollock /Art@ial Intelligence 106 (1998) 267-334 that forwards At produces R, we can project in time, perform A3, and thereby achieve G. We cannot be sure which disjunct will result from performing A 1, but we can plan for each contingency to execute when we see what actually happens as a result of performing A I. This is an example of contingency planning. separately Disjunctions for the possibil- are handled ity of each disjunct and then letting the initial steps of the plan determine what subsequent in contingency planning by planning the results of executing separately and then decide which subplan steps are executed. 43 What distinguishes contingency planning is that plan-steps can have conditionality built are than the simple plans produced by the system described in this paper. This illustrates into them, and they may “call” different subplans depending upon what conditions satisfied. Such plans are logically more complicated that the theory of goal-regression planning planning developed here is only complete for the rather simple conception of plans assumes. Specifically, such plans consist of a set of plan-steps, a set of ordering-constraints, a set of causal-links the concept of a plan to add additional to the theory of goal-regression a goal, and nothing more. Enriching logical structure will require further modifications (expressing nomic connections), planning. it Appendix A. Proofs of theorems Lemma A.l. If a plan is causally-sound, so are its linearizations. Lemma A.2. If a linear plan is causally-sound, then it is sound. Proof. By induction on the length of a plan (i.e., the number of steps in the plan). Base case. If a null-plan is causally-sound then it is presumptively-sound, goal is true in the start-state. Hence by clause (i) of the definition of “result”, result of the null-sequence of actions. So the plan is sound. and then its its goal is a . . + goul+ Induction case. Suppose the lemma holds for plans of length < n. Suppose plan is a plan of length n. Let s 1, . . . , s, be the plan-steps of plan, and goal its goal. Let C be the set of all causal-links of plan having goal as their final-goal and having *finish* as their target. For *$nish* + goal, construct each L in C, if L is the causal-link Sk + gL + are st , . . . , Sk, whose ordering- a linear-plan planL whose goal is gL, whose plan-steps are those of plan constraints are those of plan restricted restricted planL to *start*, ~1, . . . , Sk, together with the causal-link Sk -+ gL --f *jinish* -+ go. is presumptively-sound removed any causal-links pertaining planL is planL itself, so if planL contained a causal-link undermined by one of its plan-steps ~1, sl would have to occur between some Q that is either -subgoal result of the sequence of actions prescribed by s 1. . , s[ . But then so would also undermine in plan. By hypothesis, plan is causally-sound this same causal-link and we have not of --+ sj -+ . . . .ri and Sj, and for or the negation of a conjunct of subgoal, Q would be a to the plan-steps of planL. The only linearization to planL, and whose causal-links is presumptively-sound and hence does not si -+ subgoal + because plan . 4.1 For work on contingency Boddy [ 131, and Pryor and Collins 1391. planning, see Warren [44], Etzioni et al. 181. Peot and Smith 1291, Goldman and J.L. Pollock /Arrijicial Intelligence 106 (1998) 267-334 329 undermine Therefore planL any of its own causal-links, is causally-sound. so there can be no such undermining in L either. that planL , Sk. By hypothesis, is sound and hence go is a If k < n, it follows by the induction hypothesis result of the sequence of actions prescribed by ~1, Sk + gL +’ . . -+ goal + *finish* -+ goal is not undermined by plan, so by clause (ii) of . , s,, the definition of “result”, go is a result of the sequence of actions prescribed by $1, it has a For at least one L in ,!Z, k = n. In that case, as plan is presumptively-sound, . -+ goal. As above, we causal-link of the form s -+ sg, -+ can construct a plan of length < n for sgl, and as its causal-links are not undermined by plan, sgt is a result of the sequence of actions prescribed by s) , . . . , s,. Then by clause (ii) of the definition of “result”, gL is a result of the sequence of actions prescribed by si....,sn. . . + sgl + s,, -+ gL + the causal-link Thus all of the gL (for L in C) are results of the sequence of actions prescribed by st , . , sn. goal is either the only gL (if there is just one) or the conjunction of the gL’s. In the former case goal is a result of the sequence of actions prescribed by sr , . . s,, and in the latter case, by clause (iv) of the definition of “result”, goal is a result of the sequence of actions prescribed by si , . . , s,. Hence plan is sound. q Theorem 1. If a plan is causally-sound then it is sound. Proof. Suppose plan causally-sound. By Lemma A.2, all of its linearizations [? of soundness for partial-order plans, plan is sound. is causally-sound. By Lemma A.l, all of its linearizations are are sound. So by the definition Theorem 2. If a goal causally-sound Al,...,A, inthatorder plan for is a result of an action-sequence that goal some linearization (Al, . . , A,), of which prescribes then there is a the actions Proof. By induction on the length of the action sequence. Just let the plan be linear, and put in causal-links each time a planning-conditional is used to get a result. IJ Theorem 3. A plan-step n of a plan undermines a causal-link n 1 -+ subgoal1 + subgoal,, embellishment plan0 of plan whose goal is either -subgoal, of subgoalI, and is a presumptively-sound or the negation of a conjunct -+ n:! + goal1 -+ .. -+ goal, i# there of plan . . . + ( 1) n is the single penultimate plan-step of plaq,, (2) there is a linearization of plan consistent with the ordering imposed by plan0 in which n occurs between n 1 and n2, and (3) plan0 is sound. is immediate by clause Proof. From right-to-left undermines definition, is a result of the sequence of actions prescribed by the plan-steps *start*, . . . , n in the linearization, where g is either subgoal, or a conjunct of subgoal,. By Theorem 2, there is a suppose n . .. + goal,. By . .. + subgoal,, of plan in which n occurs between n1 and n2 and -g nl -+ subgoal1 + there is a linearization (iii) of (Rl). Conversely, -+ n2 -+ goal, + 330 J.L. Pollock/Artz$cial intelligence 106 (1998) 267-334 *start* / k C ----)l.AdG* -G -(-G&G*) Fig. A. 1. Test plan plan for -g having start*, causally-sound adding the rest of the steps of plan to the end of that linearization, plan. Those additional steps succeed 12 and so are not relevant Theorem 1, plan0 is sound, and by the definition of causal-soundness sound. . , n as a linearization. Let plan0 be the result of in the order prescribed by to the soundness. Hence by it is presumptively- u Theorem 4. A plan-step n of a plan undermines a causal-link n 1 -+ subgoal1 + . . -+ subgoal,, --+ n2 -+ goal, -+ .. + goal,,, of plan iff there is a presumptively-sound embellishment plan0 of plan whose goal is either -subgoal, or the negation of a conjunct of subgoalI, and (1) n is the single penultimate plan-step of plan,,, (2) there is a linearization of plan consistent with the ordering imposed by plan0 in which n occurs between n 1 and n2, and (3) plan0 does not undermine any of its own causal-links. Proof. From linearization, undermine so by Theorem 1 it is sound. q any of its causal-links left-to-right, so replace plan0 by that linearization. From right-to-left, if plan0 is sound, by Theorem 2 it has a causally-sound if plan0 does not and it is presumptively-sound then it is causally-sound, Theorem 5. If the set of planning-conditionals is re. but not recursive, then the set of sound solution-pairs (problem, solution) is not re. the set of planning-conditionals is r.e. and the set of (problem, solution) Proof. Suppose pairs is r.e. It will be shown that that it is then decidable whether a planning conditional (C/A) l G is in the set of planning-conditionals, and hence that set is recursive. To decide this, construct a planning problem by letting the start state consist of (C, -G} and taking (C/A) l G* to the set of planning- the goal to be (-G & G*), and add the conditional is still ce. but not recursive unless conditionals. The resulting set of planning-conditionals in Fig. A.l. This plan the original set was recursive. Consider the causal-link is a solution *start* + -G + the set of planning-conditionals. can discover algorithm generating plan is produced conditionals the set of planning-conditionals (WC & G*) + *finish*, which in turn holds iff (C/A) w G is not in Thus if the set of (problem, solution) pairs is r.e., we an the (problem, solution) pairs and waiting and seeing that the above for this planning problem. Thus the complement of the set of planning- that (C/A) l G is not in the set of planning-conditionals iff plan-step 1 does not undermine the set of planning-conditionals the test plan diagrammed to the planning problem is r.e., so it follows that is r.e. By assumption, is recursive. q by running J.L. Pollock /Artijicial Intelligence 106 (1998) 267-334 331 Let us say that a presumptively-sound or ordering-constraints sound plans are defined analogously. The following will render plan is minimal iff the removal of any causal-links it no longer presumptively-sound. Minimal causally- three lemmas are obvious: Lemma A.3. OSCAR canjnd any minimal presumptively-sound PROPOSE-NULL-PLAN,GOAL-REDUCTION, and SPLIT-CONJUNCTIVE-GOAL. plan by repeated uses of Lemma A.4 OSCAR canjnd any minimal presumptively-sound ed-uses of EMBEDDED-NULL-PLAN, BEDDED-CONJUNCTIVE-GOAL. EMBEDDED-GOAL-REGRESSION, embellishment by repeat- and SPLIT-EM- Lemma A.5 OSCAR returns only presumptively-soundplans. Theorem 6. If OSCAR searches the space of potential OSCAR planner is sound. inferences systematically then the Proof. Let the proof-repair-depth of undermining the plan. We prove by induction on the proof-repair-depth it then it is sound. of a plan returned by the OSCAR planner be the number that OSCAR finds and repairs in the course of constructing of a plan that if OSCAR returns embellishments Suppose OSCAR returns a plan of proof-repair-depth vely-sound. By Lemma A.4, there are no undermining 1 the plan is sound. 0. By Lemma A.5 it is presumpti- and so by Theorem embellishments, n + 1. By Lemma AS, 1, there must be a minimal undermining-embellishment. Suppose the theorem holds for all plans of proof-repair-depth a plan of proof-repair-depth not sound, by Theorem embellishment repair it. The only way the plan can fail to be sound is if the repair is unsuccessful, OSCAR constructs an unsound will be < n, so by the induction hypothesis, sound. q < n, and OSCAR returns If it is The so by Lemma A.4 OSCAR will find it and try to i.e., it cannot be unsound. Thus the plan must be repair plan. But the proof-repair-depth it is presumptively-sound. is presumptively-sound, of the repair-plan Theorem 7. If OSCAR searches OSCAR planner is complete. the space of potential inferences systematically then the are either in question causally-sound Proof. A minimal for the same goal. The causally-sound presumptively-sound pairs to repair-plans plans generated ending with ments, the repair-plans semantical-repair-depth that must be repaired in constructing the minimal repairs plan contains a minimal presumptively-sound plan can then be generated from plan by finding causal-underminings and repairing to the presumptively-sound plan plan the minimal them. The re- itself or repairs the set of all plan and to repair the presumptively-sound used in this way, starting with the minimal presumptively-sound the undermining plan, plan. Consider including causally-sound and their repair-plans, of the plan to be the minimal number of causal-underminings it out of the presumptively-sound in this set, define etc. For any plan embellish- plan. Then we the 332 J.L. Pollock /Arti$cial Intelligence 106 (1998) 267-334 on the semantical-repair-depth prove by induction nates earlier by finding a different causally-sound ber II less than or equal by repeated to the semantical-repair-depth of ADD-ORDERING-CONSTRAINT, application that unless OSCAR’s termi- plan for that goal, for every num- plan, of the causally-sound search CONFRONTATION, ADD- EMBEDDED-• RDERING-CONSTRAINT, find every plan in the set with semantical-repair-depth bellishments. and EMBEDDED-CONFRONTATION, OSCARwill IZ, along with any undermining em- The only plan in the set with semantical-repair-depth 0 is the minimal presumptively- sound plan, and by Lemma A.3, OSCAR can find it. Suppose the theorem holds for all plans in the set of semantical-repair-depth < n, and n + 1. This plan is constructed by repairing so that of the plan or by n, either by adding an ordering-constraint is not an embellishment consider a plan of semantical-repair-depth a subplan of semantical-repair-depth the undermining adding a repair-plan hypothesis, OSCAR can find the undermined and the repair-plan, embellishment of the subplan that undermines the undermining embellishment. By the induction embellishment, the undermining so OSCAR can find the plan of semantical-repair-depth n + 1. plan regardless of its causally-sound If there is a sound plan for the goal, by Theorem 2 there is is plan, and then there is a minimal causally-sound plan. So OSCAR subplan, that OSCAR can find any minimal It follows semantical-repair-depth. a causally-sound 0 complete. Theorem 8. A plan plan collectively embellishment presumptively-undermines L, and plan+ of plan and a set L of causal-links of plan+ undermines its causal-link L iff there is an such that plan+ (1) LEL, (2) plan+ (3) there is no embellishment plan0 of plan+ and set C* of causal-links of plan+ such is causally-sound, and that (a) plan0 presumptively-undermines (b) C* C C, (c) L $ C”, and (d) plan0 is causally-sound. L*, Proof. Analogous to Theorem 2. 0 Theorem 9. A plan plan collectively undermines ely-sound embellishment plan+ of plan and a set C of causal-links of plan+ such that plan+ presumptively-undermines its causal-link L iff there is a presumptiv- C, and embellishment plan0 ofplan+ and set C* of cuusal- (1) L EL, (2) there is no presumptively-sound links of plan+ such that (a) plan0 presumptively-undermines (b) C* C Cc, (c) L 6 L*, and (d) plan0 does not collectively-undermine C*, any of its causal-links. J.L. Pollock /Artijicial Intelligence 106 (1998) 267-334 333 Proof. Analogous to Theorem 3. q References [ 11 J. Allen, Formal models of planning, Kaufmann, Los Altos, CA, 1987. in: J. Allen, J. Hendler, A. Tate (Eds.), Readings in Planning, Morgan [2] A. Barrett, D. Weld, Partial order planning: evaluating possible efficiency gains, Artificial Intelligence 67 (1994)71-112. [3] A. Blum, M.L. Furst, Fast planning through planning graph analysis, in: Proc. IJCAI-95, Montreal, Quebec, 1995, pp. 16361642. [4] A. Blum, M.L. Furst. Fast planning through planning graph analysis, Artificial Intelligence 90 (1997) 281- 300. [S] RI. Brafman, H. Hoos, C. Boutilier, LPSP: a linear plan-level stochastic FC 98-06, Department //www.cs.ubc.ca/spider/cebly/craig.html, 1998. of Math and Computer Science, Ben-Gurion University; planner, Technical Report from http: available [6] D. Chapman, Planning for conjunctive goals, Artificial [7] K. Erol, D.S. Nau, VS. Subrahmanian, Complexity, decidability independent planning, Artificial Intelligence 76 (1975) 75-88. Intelligence 32 (1987) 333-377. and undecidability results for domain- [8] 0. Etzioni, S. Hanks, D. Weld, D. Draper, N. Lesh, M. Williamson, An approach information, Reasoning, Cambridge, MA, 1992. pp. 1155125. in: Proc. 3rd International Conference on the Principles of Knowledge Representation to planning with incomplete and [9] G. Ferguson, J. Allen, Arguing about plans: plan representation and reasoning for mixed-initiative planning, in: Proc. 2nd International Conference on AI Planning Systems, 1994. [ 101 R.E. Fikes, N.J. Nilsson, STRIPS: a new approach to the application of theorem proving to problem solving, Artificial Intelligence 2 (1971) 189-208. [ 1 I ] A. Gerevini, L. Schubert, Accelerating partial-order planners: some techniques for effective search control and pruning, _I. Artificial Intelligence Res. 5 (1996) 95-137. [ 121 M. Ginsberg, Approximate planning, Artiticial [ 131 R.P. Goldman, M.S. Boddy, Conditional Intelligence 76 (1995) 89-124. linear planning, in: Proc. 2nd International Conference on Artificial Intelligence Planning Systems, 1994, pp. 80-85. [ 141 N. Goodman, Fact, Fiction, and Forecast, Harvard University Press, Cambridge, MA, 1955. [ 151 S. Hanks, D. McDermott, Default reasoning, nonmonotonic logics, and the Frame Problem, in: Proc. AAAI- 86. Philadelphia, PA, 1986. [ 161 S. Hanks, D. McDermott, Nonmonotonic logic and temporal projection, Artificial Intelligence 33 (1987) 379412. [ 171 D. Joslin. M. Pollack, Least-cost flaw repair: a plan-refinement strategy for partial-order planning, in: Proc. AAAI-94, Seatle, WA, 1994, pp. 1004-1009. [ 181 D. Joslin, M. Pollack, Passive and active decision postponement in plan generation, in: Proc. 3rd European Workshop and Planning, 1995. [19] H.A. Kautz, The logic of persistence, 1201 H.A. Kautz, B. Selman, Pushing in: Proc. AAAI-86, Philadelphia, PA, 1986, pp. 401405. the envelope: planning, propositional logic, and stochastic search, in: Proc. AAAI-96, Portland, OR, 1996, pp. 1194-1201. [21] N. Kushmerick, S. Hanks, D.S. Weld, An algorithm for probabilistic planning. Artificial Intelligence 76 ( 1995) 239-286. 1221 V. Lifschitz, Formal theories of action, in: F. Brown (Ed.). The Frame Problem in Artificial Intelligence, Proc. 1987 Workshop, Morgan Kaufmann, Los Altos. CA, 1987. 1231 V. Lifschitz, On the semantics of STRIPS, in: M. Georgeff, A. Lansky (Eds.). Reasoning about Actions and Plans. Morgan Kaufmann, Los Altos, CA, 1987. 1241 D. McAllester. D. Rosenblitt. Systematic nonlinear planning, in: Proc. AAAI-91, Anaheim. CA, 1991, pp. 634639. [25] J. McCarthy, P. Hayes, Some philosophical problems B. Meltzer, D. Michie (Eds.), Machine Intelligence 4. Edinburgh University Press, Edinburgh, 1969. the standpoint of artificial intelligence, from in: 334 J.L. Pollock /Ar@cial Intelligence 106 (1998) 267-334 [26] K. Myers, D. Smith, The persistence of derived information, in: Proc. AAAI-88, St. Paul, MN, 1988, pp. 496500. [27] E.P. Pednault, Toward a mathematical [28] J.S. Penberthy, D. Weld, UCPOP: International Conference on the Principles of Knowledge Representation 1992, pp. 103-l 14. theory of plan synthesis, Ph.D. Thesis, Stanford University, 1987. a sound, complete, partial order planner for ADL, in: Proc. 3rd and Reasoning, Cambridge, MA, [29] M.A. Peot, D. Smith, Conditional nonlinear planning, Intelligence Planning Systems, 1992, pp. 189-197. in: Proc. 1st International Conference on Artificial [30] M.A. Peot, D. Smith, Threat removal strategies for partial-order planning, in: Proc. AAAI-93, Washington, DC, 1993, pp. 492499. [31] M. Pollack, D. Joslin, M. Paolucci, Flaw selection strategies for partial-ordering planning, .I. Artificial Intelligence Res. 6 (1997) 223-262. [32] J. Pollock, The logic of projectibility, Philosophy of Science 39 (1972) 302-314. [33] J. Pollock, Nomic Probability and the Foundations of Induction, Oxford University Press, 1990. [34] J. Pollock, Cognitive Carpentry, MIT Press, Cambridge, MA, 1995. [35] J. Pollock, Reason in a changing world, in: D.M. Gabbay, H.J. Ohlbach (Eds.), Practical Reasoning, Springer, Berlin, 1996, pp. 495-509; available from http: //www.u.atizona.edu/-pollock/. [36] J. Pollock, Reasoning about change and persistence: a solution to the Frame Problem, Nous 3 1 (1997) 143- 169. [37] J. Pollock, Reasoning defeasibly about plans, Technical Report of the OSCAR Project, 1998; available from http: //www.u.atizona.edu/-pollocW. [38] J. Pollock, Perceiving and reasoning about a changing world, Computational Intelligence 14 (1998) 498- 562. [39] L. Pryor, G. Collins, Planning for contingencies: a decision-based approach, J. Artificial Intelligence Res. 4 (1996) 287-339. [40] Y. Shoham, Time and causation from the standpoint of artificial intelligence, Computer Science Research Report No. 507, Yale University, New Haven, CT, 1986. [41] Y. Shoham, Reasoning about Change, MIT Press, Cambridge, MA, 1987. 1421 R. Srinivasan, A.E. Howe, Comparison of methods for improving search efficiency in a partial-order planner, in: Proc. IJCAI-95, Montreal, Quebec, 1995, pp. 162&1626. [43] D. Stalker, Gore! The New Riddle of Induction, Open Court, 1994. conditional [44] D. Warren, Generating Intelligence and the Simulation of Behavior, 1976, pp. 344-354. plans and programs, in: Proc. Summer Conference on Artificial [45] D. Weld, An introduction [46] M. Williamson, S. Hanks, Flaw selection strategies to least commitment planning, AI Magazine 15 (1994) 2762. for value-directed planning, in: Proc. 3rd International Conference on Artificial Intelligence Planning Systems, 1996, pp. 237-244 