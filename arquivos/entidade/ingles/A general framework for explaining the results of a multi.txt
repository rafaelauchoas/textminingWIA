Artificial Intelligence 175 (2011) 1410–1448Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA general framework for explaining the results of a multi-attributepreference modelChristophe LabreucheThales Research & Technology, RD128, 91767 Palaiseau cedex, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 27 February 2009Received in revised form 13 August 2010Accepted 13 August 2010Available online 1 December 2010Keywords:PreferencesDecision theoryArgumentationWeight1. IntroductionThe automatic generation of an explanation of the prescription made by a multi-attributedecision model is crucial in many applications, such as recommender systems. This task iscomplex since the quantitative models are not designed to be easily explainable. The majorlimitation of the previous research is that there is no formal justification of the argumentsthat are selected in the explanation. The goal of this paper is to define a general frameworkto justify which arguments shall be selected, in the case where the decision model is basedon weights assigned to the attributes. Due to the complexity of explaining a preferencemodel based on utility theory, several explanation reasonings are necessary to cover allcases – ranging from situations where the prescription is trivial to situations where theprescription is much more tight. The set of selected arguments is, in this framework, anon-dominated element of a combinatorial structure in the sense of an order relation.Our general approach is instantiated precisely on three models: the probabilistic expectedutility model, the qualitative pessimistic minmax model and the concordance rule, whichare all constructed from a weight vector.© 2010 Elsevier B.V. All rights reserved.In decision making under uncertainty, social choice and multi-criteria decision making, which are the three main domainsof decision theory [40,48], explicit analytical models are constructed to represent the preferences of a decision makerregarding how to combine various dimensions, which are the states of nature, the voters and the criteria respectively.Decision theory mainly focuses on specifying how a rational agent should behave, which results in the justification, throughaxiomatic characterizations, of the decision models that should be used [54,51,37,41]. Another well-developed researcharea in decision theory concerns the elicitation of the decision maker preferences, and has led to the design of elaborateelicitation methods.Decision models are traditionally mainly quantitative, which is the case for instance of the expected utility model [54,51]. More recently, qualitative models have been developed in AI in order to overcome the difficulty of the elicitation of theinformation necessary for these models [24,19,12,20]. A wide class of quantitative and qualitative models are parameterizedby a weight vector where a weight is assigned to each dimension [26,49]. We are interested in these models in this paper.The final part of the decision process, after the model has been elicited, is usually not studied in decision theory. It isgenerally reduced to the application of the decision model on the options of interest. If an individual constructs his decisionmodel and is convinced about its relevance, then it is not necessary to explain to him the result of the application of thedecision model. However there are many practical situations in which the decision needs to be justified to some actorswho did not participate to its construction. These actors are not interested in the technicality of the decision model. On theE-mail address: christophe.labreuche@thalesgroup.com.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.008C. Labreuche / Artificial Intelligence 175 (2011) 1410–14481411contrary, they wish to have a synthetic explanation of the decision. It shall be automatically generated. According to Klein[35], such an explanation should be intuitive, comprehensive and persuasive.The automatic generation of an explanation of the outcome of a decision model is not an easy task since the modelsfrom decision theory are not designed to provide the reasons that support the recommendation [35]. By contrast, decisionframeworks from AI have, by construction, the ability to naturally provide such an explanation. This is for instance the caseof the belief–desire–intention representation architecture [11], argumentation [25] and conditional preference networks [9].In [18,3,2], an argumentation-based framework for making and explaining a decision is proposed. A preference relation overthe candidate options is derived from the positive and negative acceptable arguments that support each option and from anordering on the arguments. Another extension of argumentation to incorporate preferences can be found in [42].In the context of multi-criteria decision making and more specifically multi-attribute value theory (MAVT) [26,34,30],there are a few works which aim at generating an explanation of the outcome of the decision model [35,14,43]. The gener-ation process is split into two parts: the selection of the arguments (i.e. the criteria) to be presented, and the structurationand expression of the selected arguments in natural language. The second part is well-developed in Ref. [14]. One can notethat the expression of a selected content in natural language has been extensively studied in the literature – see for instance[13,27] to cite a few. Concerning the selection part, the three previously mentioned works [35,14,43] use the same idea.It consists in selecting the k (where k is a parameter) criteria that have the largest contribution to the overall utility. Thisapproach is not satisfactory for the following reasons. First of all, the textual explanation does not mention the weights ofthe criteria [14]. This is a major drawback since the weights are essential in the MAVT model. Secondly, there is no formaljustification of the arguments that are selected, and in particular of the choice of the k parameter.The aim of this paper is to develop a formal framework that justifies the selection of the arguments. This work isespecially dedicated to situations in which the recipient of the explanation is not the individual who has designed thedecision model. This general framework is designed for any decision model based on weights. It adapts itself automaticallyto the complexity of the decision. The easier the decision, the simpler the explanation. Premises of this work can be foundin two conference papers [38,39].Section 2 describes weighted decision models. We introduce three particular models that will be used to validate ourframework: the expected utility model [54,51], the weighted minmax model [22] and the weighted majority model [44].The general explanation framework is presented in Section 3. In order to adapt to the complexity of the situation, severalargumentation reasonings are introduced. They are called anchors by analogy to the concept of anchor defined by Grize torefer to some implicit information used to convince an audience [32]. A subset of criteria can be selected for the explanationif these criteria are decisive in some sense depending on the anchor. Such a subset is called an explanation set. The set ofthese explanation sets forms a combinatorial structure. One then aims at finding the non-dominated explanation sets inthis structure, in the sense of an order relation expressing the simplicity of the explanation set. In the following Sections 4through 7, this general framework is thoroughly developed on each anchor and each of the three weighted decision models.From the properties satisfied by the non-dominated explanation sets, we show that the explanation to be generated can bederived. A method or algorithm to compute a non-dominated explanation set is given in each case. We will not deal withthe expression of the selected arguments in natural language. However, examples of texts that can be generated will bepresented. Some experimental results are presented in Section 8. The proofs of the results are given in Section 10.2. Decision models based on a weight vectorDecision theory [40,48] is interested in preference representation and gathers different domains such as Multi-CriteriaDecision Making (MCDM) [49,28,10], Decision Making under Uncertainty (DMU) [36,51] and Social Choice (SC) [6,29]. Thetypical decision problem studied in decision theory consists in selecting one alternative among a set X of candidate options,where the alternatives are described by several dimensions. This selection is obtained by the construction of a preferencerelation over X . The set of finite dimensions is denoted by N = {1, . . . , n}, and the alternatives are characterized on eachdimension i ∈ N by a value in a set Xi . In MCDM, N is the set of decision criteria, Xi is the attribute representing criterion i,and each alternative is characterized by a value on each attribute, that is X = X1 × · · · × Xn. The criteria are often conflicting[49]. As an example, one may have cost criteria and performance criteria, which cannot be met at the same time. The maindifficulty is then to find a good compromise between the criteria. In DMU, the elements of N are the states representing thepossible situations, X1 = · · · = Xn =: C is the set of possible consequences, and an alternative (also called act) is a mappingfrom N to C , that is X = C N . The consequence of selecting a particular alternative depends on which state of nature willoccur. Moreover the attitude of the decision maker (DM) towards uncertainty influences his choice strategy [51]. In SC, N isthe set of voters, X1 = · · · = Xn =: C is the set of candidates, and the alternatives are also the candidates, that is X = C . Thedifficulty is to find a fair consensus among the opinions of the voters [5].The preference relation over the alternatives in X is usually constructed from a preference relation (cid:3)i over each set Xi .We denote by (cid:4)i and ∼i the asymmetric and symmetric parts of (cid:3)i . In MCDM, (cid:3)i represents the preferences of the DMover the elements of attribute Xi ; in DMU, (cid:3)1 = · · · = (cid:3)n depict the preferences of the DM over the set C of consequences;in SC, (cid:3)i models the preferences of voter i over the set C of candidates. There exist many preference models in which theoverall preference of an alternative y ∈ X over another alternative x ∈ X is obtained by weighing up the pros and the cons=( y, x) = {i ∈ N, yi ∼i xi}regarding this preference. The sets Aare the positive, negative and null arguments respectively concerning the preference of y over x on all dimensions N. The−( y, x) = {i ∈ N, xi (cid:4)i yi} and A+( y, x) = {i ∈ N, yi (cid:4)i xi}, A1412C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448+( y, x) and A−( y, x) is often based on the priorities allotted to the dimensions. This is quantified byarbitrage between Aa weight w i assigned to each i ∈ N together with an aggregation function depending on w = (w 1, . . . , wn) [26,49,51]. Thesemantics of the weights depends on the method used. Basically, w i is interpreted as the importance of criterion i in MCDM,as the probability or possibility of the state of nature i in DMU, and as the power of voter i in SC. The weight vector w isnormalized in some sense depending on each method used. We denote hereafter by ∧ and ∨ the min and max operatorsrespectively.We are interested in several families of preference relations characterized by a weight vector w = (w 1, . . . , wn). For agiven family F of preference models, the set of weights is denoted by W(F ), and the corresponding preference relation isw , for w ∈ W(F ). We denote by (cid:4)Fdenoted by (cid:3)Fw . We are interestedin the models derived from an aggregated value:w the asymmetric and symmetric parts of (cid:3)Fw and ∼F∀x, y ∈ X y (cid:3)FFw ( y, x) (cid:2) 0.A classical representation is to summarize each option x ∈ X by an overall utility hFw (x).hw x ⇐⇒ HFw (x). This gives HFw ( y, x) = hFw ( y) −(cid:2)w (x) =There exist accurate elicitation methods to construct the quantitative model hEUThe most well-known family corresponds to the expected-utility model (labelled “EU” hereafter) of von Neumann andi∈N w i ui(xi), where w i ∈ [0, 1] and ui : Xi → [0, 1] is a value function mea-Morgenstern [54] and Savage [51]: hEUsuring the attractiveness of the elements of Xi . The value function ui quantifies the preference relation (cid:3)i : for a, b ∈ Xi ,a (cid:3)i b ⇐⇒ ui(a) (cid:2) ui(b). In MCDM, this model is the Multi-Attribute Value Theory Model [26,34]. One has W(EU) = [0, 1]n.w [7,50]. The main drawback of thesemethods is their complexity, which does not fit with all applications. Qualitative decision theory has been defined in AIto overcome this difficulty [24,19,12,20]. A pessimistic weighted extension (labelled “Pess” hereafter) of the Wald minmaxi∈N (ui(xi) ∨ (1 − w i)), where w is interpreted as a possibility distributionfunction [56] has been defined in [22]: hPessin DMU [23]. This model has been also used in MCDM. One has W(Pess) = [0, 1]n. For simplicity, we consider the interval[0, 1] also for the Pess model but any linearly ordered scale with top and bottom elements can be used as well.w (x) =The EU and Pess models both require the existence of a value representation for each (cid:3)i and commensurateness betweenthe preference scale and the weight/uncertainty scale, which is usually not easy to satisfy in practice. The majority rule(labelled “Maj” hereafter) defined in SC [44] gets rid of these two assumptions. It has also been studied in AI in a moregeneral framework [20]. It reads H Maji∈ A−( y,x) w i . This model has some limitations due to theArrow’s theorem [5]. The majority rule is known in MCDM under the name concordance rule [49]. One has W(Maj) = Rn+.i∈ A+( y,x) w i −w ( y, x) =(cid:2)(cid:2)(cid:3)Despite some limitations, the three models EU, Pess and Maj that we have just described are used in many applicationscovering very different domains. For this reason, we will focus on these models.(cid:4)(cid:2)i∈N w i = 1 and thus W(Pess) = {w ∈ [0, 1]n:i∈N w i = 1}. Let us mention that, for the EU model, the normalization conditionThe set of normalized weights w.r.t. a model F is denoted by W(F ). For the EU and Maj models, we have W(EU) =W(Maj) = {w ∈ [0, 1]n:i∈N w i = 1 isw (α, . . . , α) = α for all α ∈ [0, 1] [31]. The weights are normalized for the modelequivalent to the idempotency property hEUi∈N w i = 1} [22]. For each of the three above models, there existsPess ifthat is characterized by the property that the dimensions are symmetric in thea particular normalized weight vector wFn . These are the weights that one will apply in the absence of information.aggregation process. Therefore wThey results from the application of the principles of insufficient reason, maximum entropy and minimum specificity. In theBayesian approach, the lack of information is represented by the uniform probability w, and in MCDM and SC, all criteriaand voters are assigned to the same weight when there is no reason to proceed differently. The vector wwill thus becalled reference weight vector. For models Maj and EU, we obtain for all i ∈ NF= · · · = wF1(cid:2)(cid:4)FFw Maji= w EUi= 1n.(1)(cid:3)Maj(cid:2)wMaj corresponds to a Condorcet majority rule, and hEUi∈N w i = 1, the value w Maj= w EUi= 1wEU is the arithmetic mean. Let w ∈ W(EU) or w ∈ W(Maj). Sincen corresponds to the mean importance of a dimension in w. Hence relation w i > 1nn and thus can be(resp. w i < 1said to be an important (resp. unimportant) dimension.n ) means that dimension i is more important (resp. less important) than the average value 1iFor model Pess, one has for all i ∈ N= 1(2)w Pessiand hPesswPess is the min operator.3. General explanation framework3.1. Why generating automatically an explanation?From now on, we assume that F ∈ {EU, Pess, Maj} is a fixed family of models, and the weight vector v ∈ W(F ) hasalready been specified. Let(cid:5)D(F) =(x, y, v) ∈ X × X × W(F): y (cid:4)F(cid:6)v x.C. Labreuche / Artificial Intelligence 175 (2011) 1410–14481413We consider two options x, y ∈ X and we assume that (x, y, v) ∈ D(F ). We aim at explaining why y is strictly preferred tox according to the model.If an individual constructs his decision model (cid:4)Fv and is convinced about its relevance, then it is not necessary to explainv x. This is no more true when several actors are involved in the decision process, as shown into him the comparison y (cid:4)Fthe following examples.(i) The individual that is referred to as decision maker (DM) is usually the person who is responsible for the decision. Heoften has to explain his decision to other actors – for instance, his chief, his executive board or his shareholders. Theseactors are not interested in the technicality of the decision model. In order to convince them on the merits of thedecision, a synthetic explanation needs to be given.(ii) A decision support system usually generates an ordered list of recommended options from which the user of thesystem decides which one to choose. Since the user is not the expert from whom the decision model has been elicited,the recommendation shall be explained. Moreover, the user is not necessarily highly qualified, and there may be timeconstraints under which the operator needs to make the decisions. Hence the explanation shall be non-technical, simpleand fast to understand for the user. An example of this is the multi-criteria decision function that recommends theassignment of priorities to the radar tasks in radar management [8].(iii) There are many situations in AI in which several (artificial) agents have their own preferences and thus their owndecision models. This is for instance the case in negotiation. In negotiation protocols, an offer is made by an actorat each iteration of the protocol, and the other actors give their feedback [45,1]. They do not reveal their preferencemodels to the other actors since they want to keep their models private. Each actor only provides to the other onessome clues on why the offer is, for instance, not satisfactory to him.In the previous examples, an explanation of the recommendations produced by the decision model must be generated.According to Klein [35], the explanation cannot be simply that, for the EU model, “ y is preferred to x since the overall score(cid:2)i∈N v i xi of x” since it does not appeal to intuition and it does not compare thei∈N v i yi of y is larger than the overall score(cid:2)alternatives explicitly.Yet, in the examples (ii) and (iii) above, a synthetic explanation needs to be automatically generated and it cannot beproduced by a human. When the number of criteria is relatively large, the cognitive load to interpret the figures x, y andv is relatively high. This load is too high for the situations in which the decision activity is very repetitive, as it is the casein the radar management example (ii) in which the operator has to perform the same activity for several hours in a raw. Inexample (iii), the values of v cannot be sent to the other agents for privacy reasons, and a synthetic explanation must begenerated by the artificial agent.The arguments of this explanation are the elements of N. The explanation will be based on the satisfaction degrees ui(x)and ui( y) of x and y on each dimension (for the models EU and Pess for which value functions ui exist). Hence the preciseform and expression of the value functions ui will not matter. As a result, for the sake of simplicity in the notation, wewill assume throughout the paper that the value functions ui are the identity function. Hence one can set X = [0, 1]n forthe models EU and Pess. Our framework will apply on the three domains MCDM, DMU and SC. However, for the sake ofconciseness, we now restrict to MCDM for the interpretations of the results. In particular, from now on, N will correspondto decision criteria. For x ∈ X , xi is the mark or score of x on criterion i. For the models EU and Pess, xi ∈ [0, 1] is interpretedas a satisfaction degree, where value 1 is perfectly satisfactory on the criterion and value 0 is unacceptable. Our explanationframework can be transposed to DMU and SC.3.2. Notation and definitions:= +1 if i ∈ A+( y, x), sgniFor F ∈ {EU, Pess}, we have X = [0, 1]n and we define (cid:3) ∈ Rn by (cid:3)i = yi − xi for all i ∈ N. For F = Maj, we define−( y, x). For S ⊆ N andsgn ∈ {−1, 0, 1}N by sgniS : {1, . . . , s} → S, with s = |S|, by Zπ ZZ ∈ RN , we define π ZS (s). Throughout this paper, we will apply thisS (1)definition to the vectors (cid:3), x, y, v leading to π (cid:3)S ,π vS respectively. Let Π(S) be the set of all permutations on acoalition S ⊆ N. For π ∈ Π(N) and w ∈ W(F ), π ◦ w is the weight vector defined by (π ◦ w)i = wπ (i) for all i ∈ N. For(cid:14)N\S )i = w i if i ∈ S, andw, w(w S , wLet(cid:14) ∈ W(F ) and S ⊆ N, we define the compound weight vector (w S , w(cid:14)N\S ) ∈ W(F ) by (w S , w=( y, x) and sgni(cid:14)i otherwise.:= −1 if i ∈ A(cid:3) · · · (cid:3) Zπ Z:= 0 if i ∈ A(cid:14)N\S )i = wS , π yS , π x(cid:5)Ex ={ A1, . . . , A p}: p ∈ N, ∅ (cid:16)= A1, . . . , A p ⊆ N and Ai ∩ A j = ∅ for all i (cid:16)= j(cid:6).if for every A ∈ A, there exists A(cid:14) ∈ A(cid:14)such that A ⊆ A(cid:14). We write A ⊆ A(cid:14)if for everyFor A, A(cid:14) ∈ Ex, we write A (cid:18) A(cid:14)A ∈ A, we have A ∈ A(cid:14).For any permutation π ∈ Π(N), one can determine the finest partition (in the sense of (cid:18)) A(π ) := { A1, . . . , A p} of Nsuch that all Ai are invariant under π (i.e. π ( Ai) = Ai ). For all i ∈ {1, . . . , p}, one can write1414C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448k2 = π (k1),k3 = π (k2),. . . ,kqi= π (kqi −1) and k1 = π (kqi )where Ai = {k1, . . . , kqi} and qi = | Ai|. By abuse of language, Ai is thus called a cycle of π .One can give a taxonomy of the arguments from their sign and strength. The sign of an argument follows from that ofn (for the EU and Maj models): an argument(cid:3)i (see Section 2). The strength of an argument is related to the sign of v i − 1n , v i ≈ 1is strong, medium and weak if v i (cid:19) 1n and v i (cid:21) 1n respectively.3.3. Motivation of the approach on the EU modelTo give the general idea of our approach, let us first focus on the EU model.Ideally, one would like to produce an argumentation of the relation y (cid:4)EUv x. There are many difficulties to extendargumentation to a quantitative setting. In logic-based argumentation, an argument is a pair (cid:22)H, h(cid:23) where h is the conclusionand H contains the minimal elements of the knowledge base that logically entails h (i.e. H (cid:24) h) [52]. Here one would liketo construct such an argument where h is the statement y (cid:4)EUv x and H ⊆ N is a subset of criteria. Intuitively, the criteria Hexplain the decision if the decision remains unchanged whatever the values of x and y on the criteria in N \ H . It writesH (cid:24)(cid:7)(cid:8)v xy (cid:4)EU(cid:14)⇐⇒ ∀xN\H , y(cid:14)N\H∈ [0, 1]N\H(cid:9)y H , y(cid:14)N\H(cid:9)(cid:10)(cid:4)EUv(cid:14)xH , xN\H(cid:10).This is equivalent to ( y H , 0N\H ) (cid:4)EU(xH , 1N\H ). This condition is too strong as it is often satisfied only when H is almostvequal to N. The reason is that all criteria compensate each other in the EU model (see Section 2) and it is rare that acriterion is completely useless in the decision. The difficulty mentioned earlier is also expressed by the fallacy of composi-tion/division which applies on divisible objects defined as the concatenation of smaller parts [33]. Quantitative models areindeed characterized by the presence of several concatenation operators. From a measurement standpoint, the value func-tions ui are obtained from a quantitative scale, and this latter can be constructed from a concatenation operator over Xiand a preference relation [37]. The aggregation of the marks by hEUalso results from a concatenation materialized by anvarithmetic operator.Let π ∈ Π(N) such thatvπ (1)|(cid:3)π (1)| (cid:3) · · · (cid:3) vπ (n)|(cid:3)π (n)|.The explanations of the preference y (cid:4)EUv x proposed in [35,14,43] are similar and consist in displaying to the user thecriteria {π (q), π (q + 1), . . . , π (n)} (where q ∈ {1, . . . , n} is a parameter). This idea of simplifying the explanation reasoning by:= v i|(cid:3)i|focusing only on a subset of the arguments is originated from the theory of argumentation. The quantity compelimeasuring the contribution of criterion i in the overall evaluation H EUv ( y, x) is called compellingness by Klein [35]. There aretwo main limitations of this approach. Firstly, there is no formal justification why selecting these particular criteria in theexplanation. Secondly, the textual explanation that is generated does not refer to the weight vector v. Yet the behaviour ofthe decision model is highly influenced by its weight vector v, and thus the explanation of the preference y (cid:4)Fv x shouldmention the weights.The weights play a central role in our approach. However, as shown in the following example, there are circumstancesin which it is not necessary to mention the specificity of the weights in the explanation.Example 1. The most simple situation arises when y is strictly better than x on all criteria. There is no negative and nullargument. Clearly y (cid:4)Fv x for all F ∈ {EU, Pess, Maj} and all v ∈ W(F ). There is no need in this trivial situation to mentionthe weights v in the explanation.In Example 1, any w ∈ W(F ) yields the same comparison of y and x. This suggests to look, in the general case, at theset V F ( y, x) of weights w ∈ W(F ) for which y is strictly preferred to x. In the following lemma, we restrict ourselves tothe EU model.+w x}. Let (cid:3)i−= (cid:3)i ∨ 0 and (cid:3)i= (−(cid:3)i) ∨ 0 for all i ∈ N. If A+( y, x) (cid:16)= ∅ andLemma 1. Let V EU( y, x) := {w ∈ W(EU): y (cid:4)EUA−( y, x) (cid:16)= ∅, then:(cid:11)(cid:11)(cid:11) A(cid:11) > 1 then ∀i ∈ A( y, x)(cid:11)(cid:11)(cid:11) A(cid:11) = 1 then ∀i ∈ A( y, x)IfIf++++( y, x)( y, x)(cid:5)(cid:5)(cid:6)w i, w ∈ V EU( y, x)(cid:6)w i, w ∈ V EU( y, x)== [0, 1],(cid:12)∀ j ∈ A−( y, x)(cid:5)(cid:6)w j, w ∈ V EU( y, x)=(cid:14)0, maxi∈ A+( y,x)(cid:3)+(cid:3)i+ (cid:3)+i−j−(cid:3)j+ (cid:3)+i−j(cid:3)(cid:13), 1,minj∈ A−( y,x)(cid:15).C. Labreuche / Artificial Intelligence 175 (2011) 1410–14481415It is not easy to construct from the intervals obtained in Lemma 1 a general explanation, except for some very particularcases.As said in Section 3.1, the recipient of the explanation we wish to generate is supposed to have no prior on the speci-ficities of the decision model and thus on the weight vector v. Anyway, if the recipient wishes to have a prior idea of thedecision only from x and y, he will consciously or unconsciously use the less specific weights – i.e. the reference weightw EU – on the options x and y. Hence if x has much better marks than y on average, i.e. x is much preferred to y accordingto (cid:3)EUwEU , then the recipient would a priori expect that x is preferred to y. He may thus be surprised by the relation y (cid:4)EUv x.Hence the explanation shall focus on explaining why the weights v and w EU yield opposite decisions.Example 2. Assume that x = (0.7, 0.7, 0.5), y = (1, 0, 0.5) and v = (0.7, 0.2, 0.1), which gives y (cid:4)EUwEU y. Hence,the weights v play here an important role in the outcome y (cid:4)EUv x. One feels that since x is better than y on average but yis preferred to x with the weight vector v, then the criteria for which y is better than x are important and the criteria forn (resp. v i < 1which x is better than y are not important. Recall that a criterion i is important (resp. unimportant) if v i > 1n ).=( y, x) = {3}. The weight vector v is important on the positive argumentOne has A(the first criterion) and is not important on the negative argument (the second criterion). The conjunction of these twophenomena actually explains the decision. Finally, the third criterion has no impact on the decision and can be removedfrom the explanation.−( y, x) = {2} and A+( y, x) = {1}, Av x and x (cid:3)EUIn Lemma 1, we have studied how much one can change the weight vector v while maintaining the same preferencebetween x and y. We keep the same idea but instantiate it in a different manner. We look at some changes in the weightsthat yield a switch of preference between x and y.FFollowing Example 2, a possible reasoning to select the arguments consists in understanding why the use of the referenceweight vector wleads to the opposite comparison of x and y, compare to the weight vector v. This switch of preferenceFnecessarily comes from the criteria for which v i is (significantly) different from wifor some i ∈ N, while y remains preferred to x, then the specificity of criterion i may not be necessary in the explanationso that i may discarded from the explanation. If the wording “x is on average at least as good as y” is contained in thegenerated explanation, then there is no mistake in the reasoning consisting in not mentioning explicitly these criteria in theexplanation.. If it is possible to change v i by wFiWe will compare v to other weights in the following example.+( y, x) = {1, 3} and AExample 3. Assume that x = (0, 1, 0.6), y = (1, 0, 1) and v = (0.4, 0.2, 0.4), which yields y (cid:4)EUv x. We notice that y is on−( y, x) = {2}. One feels that the explanation can be theaverage strictly better than x. One has Asame as in the previous example: the weight on the first criterion which is a positive argument is important, and theweight on the second criterion which is a negative argument is not important. Even though the last criterion is positive,it can be discarded from the explanation. The intuition is that the first criterion is a sufficiently positive argument since(cid:3)1 = 1 > (cid:3)3 = 0.4 and v 1 = 0.4 = v 3. How can we justify more formally that the last criterion can be removed fromthe explanation? Here is a possible justification. The weight vector v could have been assigned to the three criteria ina different manner. If v 1 were assigned to the second criterion, v 2 were assigned to the first criterion – leading to thev(cid:14) y. The inversion of the preferencesweight vbetween x and y comes from a switch of the weight of criteria 1 and 2, and criterion 3 has not played any role in thisinversion of preference.(cid:14) = (0.2, 0.4, 0.4) – then the decision would have been the opposite since x (cid:3)EUThe explanation will be based on the identification of the decisive criteria. As suggested by Example 3, one simple way todetermine whether a set of criteria are decisive is to look at the influence of permuting their weights. If the positioning ofthese weights is very crucial, then a permutation will invert the decision. Our last example shows that several explanationscan be generated for a given choice y (cid:4)EUv x.−( y, x) = {3}. One can proceed as in Example 3. If one switches the weights of criteria 1 and 3 – leading to v+( y, x) = {1, 2}Example 4. Assume that x = (0.5, 0.5, 1), y = (1, 1, 0) and v = (0.4, 0.4, 0.2), which gives y (cid:4)EU(cid:14) =and A(0.2, 0.4, 0.4) – we obtain x (cid:3)EUv x could be that y is better than x on criterion 1 whichis important and x is better than y on criterion 3 which is not important. Another explanation can be generated. One couldindeed switch criteria 2 and 3, and thus the explanation could focus as well on criteria 2 and 3.v(cid:14) y. Hence the explanation of y (cid:4)EUv x. One has A3.4. Description of the general frameworkBased on the previous Examples 1 through 4, the following points can be raised.• First of all, three different types of explanation reasonings have been made in the previous examples: one for Example 1,one for Example 2 and one for the two Examples 3 and 4. The presentation of each type of explanation to the userrequires a different reasoning. This latter is based on some implicit information and is thus related to the concept of an1416C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448anchor. In argumentation, an anchor refers to admitted facts, knowledge of the world or common sense rules [55,32,46].The anchor corresponds to some implicit reasoning rules that are not explicitly quoted in an argumentation [55]. Themissing causal relations in the argumentation are then drawn automatically by the audience. In our case, we will usethe term anchor to denote a generic way of reasoning in the explanation. The set of all anchors is denoted by Ψ .An anchor cannot be used in all situations, that is for any value of x, y and v. We denote by D(F , ψ) the set of valuesof (x, y, v) ∈ D(F ) for which anchor ψ can be applied.• Secondly, in Examples 3 and 4, the explanation concerns a permutation of the weights of two criteria. In more complexsituations, several cycles may be necessary. In this case, the explanation is composed of a set of disjoint coalitionsof criteria, and is thus an element of Ex. Each coalition of criteria in this set is called an elementary argument. LetEx(x, y, v, F , ψ) ⊆ Ex be the set of explanation sets allowed with anchor ψ ∈ Ψ to explain the preference y (cid:4)Fv x. Wehave Ex(x, y, v, F , ψ) = ∅ when (x, y, v) /∈ D(F , ψ).Definition 1. For (x, y, v) ∈ D(F ), an explanation set of the prescription y (cid:4)Fv x is an element of the following setEx(x, y, v, F) =(cid:5)(cid:6)(ψ, A): ψ ∈ Ψ and A ∈ Ex(x, y, v, F, ψ).For (ψ, A) ∈ Ex(x, y, v, F ), A ∩ Arespectively used in the explanation, where A :=may be absent from the explanation. This means that A is not necessarily equal to N.−( y, x) are the positive, null and negative argumentsS∈A S. In Examples 2, 3 and 4, we have seen that some arguments=( y, x) and A ∩ A+( y, x), A ∩ A(cid:16)We describe in this paragraph the formalism we will use to justify the selection of some arguments in the explanationand the removal of the other ones.The set Ex(x, y, v, F ) is a combinatorial structure composed of many elements. In order to select the simplest explanationset, we define an order relation (cid:2) over Ex. Relation ex (cid:2) exmeans that the explanation set ex is not more complex to(cid:14). The anchors are more or less simple to understand. There is thus an order relation (cid:2) over Ψ . Weunderstand than exdenote by (cid:3) the asymmetric part of (cid:2) and by ≡ the symmetric part of (cid:2). One prefers unconditionally an explanation setusing a simple anchor than any explanation set using a more complex anchor. The order relation (cid:2) over Ex(x, y, v, F ) isthus defined as follows: (ψ, A) (cid:2) (ψ (cid:14), A(cid:14)) if one of the following two conditions is met(cid:14)• ψ (cid:3) ψ (cid:14)• ψ ≡ ψ (cid:14),, A (cid:18) A(cid:14)(i.e. A is simpler than A(cid:14)).We are interested in the simplest explanation sets of y (cid:4)Fof (cid:2).v x, that is the minimal elements of Ex(x, y, v, F ) in the senseThe set Ex forms a combinatorial structure. The number of partitions of k blocks in a set of p elements is the Stirlingnumber Skp of the second kind defined by [4](cid:12)(cid:15)Skp:= 1k!k(cid:17)i=0(−1)k−ikii p.Hence the cardinality of Ex isn(cid:17)p(cid:17)p=1k=1Skp.The exploration of Ex to find the simplest explanation set is expected to be complex.3.5. Descriptions of the anchorsThere remains to describe the anchors. Generalizing Examples 1, 2, 3 and 4, the set Ψ is composed of four anchorsΨ = {ψALL, ψNOA, ψIVT, ψRMG}.• Anchor “all” ψALL (generalization of Example 1). When y is preferred to x on all criteria (i.e. A−( y, x) = A=( y, x) = ∅),y is preferred to x according to any preference model (see Example 1).D(F, ψALL) =(cid:5)(x, y, v) ∈ D(F): A+( y, x) = N(cid:6).No specificity of (cid:3)Fgrand coalition {N}: Ex(x, y, v, F , ψALL) = {{N}}.v needs to be quoted in the explanation. There is thus only one elementary argument which is theC. Labreuche / Artificial Intelligence 175 (2011) 1410–14481417• Anchor “not on average” ψNOA (generalization of Example 2). We are interested here in the case where the referenceFweight wv x whereas x (cid:3)Fleads to the opposite decision (see Example 2), that is y (cid:4)FFact as an anchor since the recipient of the explanation may think of w. HencewF y. The reference weights wFD(F, ψNOA) =(cid:5)(x, y, v) ∈ D(F): x (cid:3)FwF y(cid:6)., while y remains preferred to x, are discardedFollowing Example 2, the criteria i for which v i can be replaced by wFfrom the explanation. Therefore, for an explanation set A, y is strictly preferred to x with the weights (vA, wN\A).N\A) may not be normalized, but this does not matter. The criteria in N \ A are not decisiveNote that weights (vA, win the sense that their weights are either not influencing the decision or close to the reference weight. If the criteria Aare described in the explanation, then N \ A may not be mentioned in the explanation.The set of elementary arguments is the coalition structure (cid:22)N(cid:23) composed of the singletons of N. Hence if x (cid:3)FdefinewF y, weFFiEx(x, y, v, F, ψNOA) :=(cid:5)A ⊆ (cid:22)N(cid:23): y (cid:4)F(vA,w(cid:6)xFN\A)and otherwise we set Ex(x, y, v, F , ψNOA) := ∅.• Anchor “invert” ψIVT (generalization of Examples 3 and 4). The idea of this anchor is to say that the decision wouldnot have been the same if some weights of v were switched. Hence we set(cid:5)(cid:6).D(F, ψIVT) =(x, y, v) ∈ D(F): ∃π ∈ Π(N) x (cid:3)Fπ ◦v yThe elementary arguments are the cycles of π . In the explanation that is generated, an implicit justification of whysome arguments are discarded shall be given. In Examples 3 and 4, the criteria that are not used in the explanationkeep their original weight v. We denote by A the explanation set. The preference between x and y is switched whenthe weights assigned to the criteria A are π ◦ v and the remaining criteria N \ A keep their original weight v. The setA must be a union of cycles of π , and thus A ⊆ A(π ). Therefore, we defineEx(x, y, v, F, ψIVT) :=(cid:5)A: ∃π ∈ Π(N) with x (cid:3)F(cid:6)(π ◦vA,v N\A) y and A ⊆ A(π ).The analysis of the situations in which a different assignment of the weights to the criteria yields an inversion ofpreference between x and y helps to understand what are the decisive criteria.• Anchor “remaining” ψRMG. This case occurs when none of the previous anchors applies. Hence(cid:6)π ◦v x(cid:5)(x, y, v) ∈ D(F): AwF x and ∀π ∈ Π(N), y (cid:4)F( y, x) (cid:16)= N, y (cid:4)FD(F, ψRMG) =+.As we will see in Section 7, there is only one elementary argument which is the grand coalition {N}: Ex(x, y, v, F ,ψRMG) = {{N}}.All the previous anchors are ordered according to their intrinsic complexity:ψALL (cid:3) ψNOA (cid:3) ψIVT (cid:3) ψRMG.The four anchors are derived from the previous examples. In the rest of the paper, we prove that the intuition given inthe examples of Section 3.3 on the EU model holds in all situations of x, y and v, and that this intuition also generalizesto the other models Pess and Maj. More precisely, we first derive the important properties of the minimal elements ofEx(x, y, v, F ). From these properties we show that convincing explanations can be generated in all cases. Sections 4, 5, 6and 7 study the anchors ψALL, ψNOA, ψIVT and ψRMG respectively. In each section, the three decision models EU, Maj andPess are analysed.4. Anchor “all”+( y, x) = N, the fact that y (cid:4)FWhen AThe following sentence can be generated to explain y (cid:4)Fv x for this anchor.v x is trivial since y is preferred to x according to any decision model.y is preferred to x since y is better than x on ALL criteria.5. Anchor “not on average”We assume throughout this section that the anchor “not on average” holds and thus y (cid:27)Fis obtained from the understanding of why the weight vectors v and wFwF x. The explanation synthesisyield different decisions regarding x and y, where1418C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448Fis a representation of the priors of the recipient of the explanation on the weights. Our approach identifies the minimal, so that ywset of criteria that need to keep their original weight, while the other criteria can take the weight value of wremains preferred to x.FFor the sake of simplicity in the notation, (cid:22)N(cid:23) is assimilated to N in this section. Hence the elements of Ex(x, y, v, F ,ψNOA) are assimilated to coalitions of N. The minimal explanation sets with anchor ψNOA according to (cid:2) are exactly theminimal coalitions of Ex(x, y, v, F , ψNOA) according to ⊆.Lemma 2. A coalition S ⊆ N is minimal in Ex(x, y, v, F , ψNOA) if and only ifS ∈ Ex(x, y, v, F, ψNOA) and ∀k ∈ S,S \ {k} /∈ Ex(x, y, v, F, ψNOA).(3)Note that N ∈ Ex(x, y, v, F , ψNOA) and ∅ /∈ Ex(x, y, v, F , ψNOA).5.1. Expected utility modelProposition 1. Let S ∈ Ex(x, y, v, EU, ψNOA) be minimal in the sense of ⊆. Then necessarily one has vk (cid:16)= 1A−( y, x). Moreover, for all k ∈ S,+( y, x) ∪ An for all k ∈ S and S ⊆+k ∈ A( y, x) ⇔ vk >−k ∈ A( y, x) ⇔ vk <1n1n,.−( y, x) are weak (i.e. their importance is lower than 1+( y, x) are strong (i.e. their importance is larger than the mean weight 1Interpretation 1. From Proposition 1, the selected criteria S are clearly decisive since S contains no null argument, thepositive arguments S ∩ An ) and the negativearguments S ∩ An ). We have thus shown that the intuition of Example 2is true in the general case. Hence the arguments that are selected can be presented in a very natural way to the recipient.If the set S ⊆ N is selected, the reason why the other criteria are not mentioned is that the outcome would have been thesame if these criteria had a medium importance. Hence a general sentence about the situation of the criteria in N \ S isenough and one needs only to show the specificity of the criteria in S.We are now interested in the generation of an explanation to the user. The explanation that is automatically generatedwEU x) that is disproved, followed byv x) and the list S ∈ Ex(x, y, v, EU, ψNOA) (with S minimal) of arguments. ThiswEU x means that x is better than y on average. The followingcan take the following structure: a concession to the reverse preference (namely y (cid:27)EUa statement of the preference (namely y (cid:4)EUstructure is classical in argumentation [17]. Relation y (cid:27)EUsentence can thus be generated to explain y (cid:4)EUv x:Even though x is better than y on average, y is preferred to x since y is better+( y, x) that are important whereas y is worse than x onthan x on the criteria S ∩ Athe criteria S ∩ A−( y, x) that are not important.The following additional sentence can be added if(cid:2)i∈N\S v i(cid:3)i > 0Moreover, y is on average better than x on the other criteria.This explanation aims at convincing an audience that would a priori think that x is preferred to y (because x is betteron average), that the opposite preference holds. This is illustrated in Section 8.2.1 on several examples. Section 8.2.1 alsopresents a comparison of our approach with the Klein method.Let us now give a simple method to compute a minimal element of Ex(x, y, v, EU, ψNOA). Let π ∈ Π(N) such that(cid:15)(cid:12)vπ (1) − 1n(cid:3)π (1) (cid:3) · · · (cid:3)(cid:12)vπ (n) − 1n(cid:15)(cid:3)π (n).Proposition 2. Let p be the largest integer in {1, . . . , n} such that {π (p), . . . , π (n)} ∈ Ex(x, y, v, EU, ψNOA). Then {π (p), . . . , π (n)}is minimal in Ex(x, y, v, EU, ψNOA). Moreover, there is no minimal coalition of Ex(x, y, v, EU, ψNOA) with a strictly smaller cardinalitythan {π (p), . . . , π (n)}.C. Labreuche / Artificial Intelligence 175 (2011) 1410–144814195.2. Weighted majority modelProposition 3. Let S ∈ Ex(x, y, v, Maj, ψNOA) be minimal. Then necessarily one has vk (cid:16)= 1Moreover, for all k ∈ S,n for all k ∈ S, and S ⊆ A+( y, x) ∪ A−( y, x).+k ∈ A( y, x) ⇔ vk >−k ∈ A( y, x) ⇔ vk <1n1n,.From Proposition 3, for any minimal explanation set, the positive arguments are strong and the negative arguments areweak. This is similar to Interpretation 1.The explanation of the preference of y over x follows the same structure as in Section 5.1. Relation y (cid:27)MajwMaj x means thatthere are more criteria for which x is preferred to y than criteria for which y is preferred to x. The following sentence canbe generated to explain y (cid:4)Majx:vEven though there are more criteria for which x is preferred to y than criteriafor which y is preferred to x, y is nevertheless preferred to x since the criteria−( y, x)+( y, x) for which y is better than x are important whereas the criteria S ∩ AS ∩ Afor which x is better than y are not important.Let us now give a simple method to compute a minimal element of Ex(x, y, v, Maj, ψNOA). Let π ∈ Π(N) such that(cid:12)(cid:15)vπ (1) − 1nsgnπ (1)(cid:3) · · · (cid:3)(cid:12)(cid:15)vπ (n) − 1nsgnπ (n) .Proposition 4. Let p be the largest element of {1, . . . , n} such that {π (p), . . . , π (n)} ∈ Ex(x, y, v, Maj, ψNOA). Then {π (p), . . . , π (n)}is minimal in Ex(x, y, v, Maj, ψNOA). Moreover, there is no minimal coalition of Ex(x, y, v, Maj, ψNOA) with a strictly smaller cardi-nality than {π (p), . . . , π (n)}.5.3. Pessimistic qualitative model(cid:3)Let hPess,Sw(z) =i∈S (zi ∨ (1 − w i)), with S ⊆ N. In the weighted minimum aggregation function hPess(x), the contributionof a criterion i ∈ N is xi ∨ (1 − v i). The value of 1 − v i is small when criterion i is important. Hence a bad score on animportant criterion cannot be saved by the other criteria, and the overall score is necessarily bad. On the contrary, a badscore on an unimportant criterion is saved by its small weight.vProposition 5. Let S ∈ Ex(x, y, v, Pess, ψNOA) be minimal. Then S ⊆ A(cid:18)(cid:18)(cid:18)hPess,Sv(x) (cid:2) hPess,Sv( y) >xiandyi >xi.i∈N\Si∈N\Si∈N\S−( y, x) ∪ A=( y, x) and for all k ∈ S, yk < 1 − vk. Moreover,Finally, we have hPess,Sv(x) (cid:2) hPess,Sv( y) > hPess,N\Sv(x) and hPess,N\Sv( y) > hPess,N\Sv(x).Relation yk < 1 − vk for k ∈ S means that the weight of criterion k hides the bad score yk. Hence S consists only inweak negative or null arguments. This proposition also shows that the worse mark of x on the remaining criteria (i.e. N \ S)is lower than any score of y in N \ S and is also lower than the aggregated score of y in S. Moreover, hPess(x) is attained inN \ S.vA positive argument cannot be selected in Ex(x, y, v, Pess, ψNOA) since this set only consists of negative or null argu-ments. The following proposition shows that some criteria not in S (for S ∈ Ex(x, y, v, Pess, ψNOA)) might be advantageouslybe added in the explanation.Proposition 6. Assume that hPessvLet M := {k ∈ N, yk (cid:3) hPess(x) is attained at kx ∈ N: hPess(x) = xkx ∨ (1 − vkx ). Then kx ∈ A(x)}. For every S ∈ Ex(x, y, v, Pess, ψNOA) minimal, we have S ⊆ M. Moreover, 1− vk > xkx ∨(1− vkx )+( y, x) and ykx > 1 − vkx .vvfor every k ∈ M.Interpretation 2. Thanks to Propositions 5 and 6, this anchor is relatively simple. The set of arguments can indeed bedivided into parts. On the one hand, the selected arguments S are negative and weak arguments. On these criteria, y has aworse score than x but this is saved by the relatively small value of the weight (since yk < 1 − vk). The value of the weightis thus crucial for these criteria. On the other hand, the non-selected arguments N \ S are criteria for which the value of1420C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448vthe weight is either not decisive or close to the reference weight 1. The only really decisive criteria in N \ S is kx for whichthe overall score hPess(x) of x is attained. This criterion is sufficiently important so that it does not hide the score of x (seeconditions on 1 − vk in Proposition 6). The remaining criteria N \ (S ∪ {kx}) may not be mentioned. If one wishes to provide(x)} =a comprehensive explanation, one may add that the bad evaluation of y on the criteria in MM \ S is saved by their relatively small importance. Indeed, from Proposition 6, we have 1 − vk > xkx ∨ (1 − vkx ) for allk ∈ Mmay contain negative or null arguments eventhough this set will be most of the time composed of only positive arguments. Finally, y is relatively good on the remainingcriteria N \ (S ∪ M∗ := {k ∈ N \ S, yk (cid:3) hPessare relatively unimportant. Note that M, and thus, the criteria in M∗ ∪ {kx}).∗∗∗vThe following sentences can be generated to explain y (cid:4)Pessvx:Even though the worst score of y is worse than that of x, y is nevertheless preferredto x since the relatively bad scores of y compared to that of x on criteria S aresaved by their relatively small importance.The overall score of x is attained at criterion kx for which x is worse than y andthe relatively large importance does not save x.On the criteria M∗, the bad evaluation of y is saved by the relatively smallimportance of these criteria. Finally, y is sufficiently good on the remainingcriteria N \ (S ∪ M∗ ∪ {kx}).The last sentence means that the score of y on the criteria N \ (S ∪ Mof x. An illustration is proposed in Example 7 in Section 8.2.2.∗ ∪ {kx}) needs just to be larger than the overall scoreThe following proposition provides a simple way to compute a minimal explanation set.Proposition 7. Let p be the smallest integer of {1, . . . , n} such that {π yis defined in the beginning of Section 3. Then {π yN (1), . . . , π yN (p)} is minimal in Ex(x, y, v, Pess, ψNOA).N (1), . . . , π yN (p)} ∈ Ex(x, y, v, Pess, ψNOA), where π yN∈ Π(N)It might seem surprising that x is not taken into account in the permutation used to compute a minimal explanation set.=( y, x) ∪ A−( y, x).i /∈S yi , it is clear that π yN (1) ∈ Ai /∈S xi <In fact, since(cid:3)(cid:3)6. Anchor “invert”We assume in this section that there exists π ∈ Π(N) such that y (cid:27)Fπ ◦v x. We aim at determining the arguments ex-π ◦v x. The minimal arguments with anchor ψIVT are exactly the minimal elements ofplaining why y (cid:4)FEx(x, y, v, F , ψIVT) in the sense of (cid:18).v x even though y (cid:27)FProposition 8. Let A ∈ Ex(x, y, v, F , ψIVT) be minimal in the sense of (cid:18). Then for every S ∈ A, |S| (cid:2) 2.6.1. Expected utility modelWe need the following result.Lemma 3. Let S ⊆ N and s = |S|. Then maxπ ∈Π(S)all j ∈ S. Moreover, minπ ∈Π(S)(cid:2)i∈S vπ (i)(cid:3)i is attained at π S ∈ Π(S) defined by π S ( j) = π vS (s − (π (cid:3)S )−1( j) + 1) for all j ∈ S.i∈S vπ (i)(cid:3)i is attained at π S ∈ Π(S) defined by π S ( j) = π vS ((π (cid:3)S )−1( j)) for(cid:2)The minimal explanation sets are characterized in the next proposition.Proposition 9. Let A ∈ Ex(x, y, v, EU, ψIVT) be minimal in the sense of (cid:18). Let π ∈ Π(N) such that x (cid:3)EUWe can choose π such that π (i) = i for all i ∈ N \ A.Let S ∈ A. Then for all k, j ∈ S with j (cid:16)= k we have (cid:3)k (cid:16)= (cid:3) j , vπ ( j) (cid:16)= vπ (k) and(π ◦vA,v N\A) y and A ⊆ A(π ).Moreover, (cid:3)π (cid:3)(vπ ( j) − vπ (k)) × ((cid:3)k − (cid:3) j) > 0.S (2) < · · · < (cid:3)π (cid:3)S (2) > · · · > vπ ◦π (cid:3)S (1) < (cid:3)π (cid:3)S (1) > vπ ◦π (cid:3)Hence for all j ∈ S, π ( j) = π S ( j). Finally,(cid:17)vπ ◦π (cid:3)(cid:17)S (|S|), andS (|S|).v j(cid:3) j >vπ S ( j)(cid:3) j.j∈Sj∈S(4)(5)C. Labreuche / Artificial Intelligence 175 (2011) 1410–14481421From the relation (cid:3)π (cid:3)S (|S|), there is at most one null argument in every S ∈ A. Moreover, sinceπ = π S over each S ∈ A, the allocation of the weights to the criteria according to π is the most favourable one relativelyto an inversion of the comparison between x and y.S (2) < · · · < (cid:3)π (cid:3)S (1) < (cid:3)π (cid:3)We are now interested in the generation of the explanation to the user. Let A ∈ Ex(x, y, v, F , ψIVT) be minimal in thesense of (cid:18). Relation (5) means that, among each cycle S of π , the ordering π assigns the largest weights to the mostnegative criteria (i.e. to the criteria that have the smallest value of (cid:3)) and the smallest weights to the most positive criteria.Proposition 9 shows that if the weights are assigned differently in a cycle S, then the preference between x and y is notreversed. According to Proposition 9, we have∀i, j ∈ Sif (cid:3)i < (cid:3) j,then vπ (i) > vπ ( j).We have y (cid:4)EUthe weight v j assigned to criterion j. The explanation can thus focus on the following pairs:v x since there exist i, j ∈ S with (cid:3)i < (cid:3) j such that the weight v i assigned to criterion i is not larger than(cid:5)R S :=(i, j) ∈ S 2: (cid:3)i < (cid:3) j and v i < v j(cid:6).For R ⊂ S 2, if R is seen as a binary relation, we define the transitive closure R of R as the smallest subset of S 2 such thatR ⊆ R, and(cid:7)(i, j) ∈ R and ( j, k) ∈ R⇒ (i, k) ∈ R.(cid:8)The set R S is stable under the transitive closure. Let us denote by RFor the explanation, we can restrict ourselves to the pairs in Rtransitivity. Let R∗ =(cid:16)S∈A R∗S .∗S∗S since the other pairs R S \ R⊆ R S the smallest subset R of S 2 such that R = R S .∗S by∗S can be deduced from R∗The explanation does not consist of a concatenation of an elementary text for each pair in R. We organize the argumentsinto four sets of arguments CPS (positive and strong), CPRS (positive and relatively strong), CNW (negative and weak),∗.in RCNRW (negative and relatively weak), and a set of pairs of arguments CPN (a positive and a negative argument). Let (i, j) ∈ RWe have three cases.∗(ii) i, j ∈ A(i) j ∈ A+( y, x), i ∈ A−( y, x) and v i < v j . This situation is illustrated by Example 10 in Section 8.3.1. The strength of thepositive argument j is larger than that of the negative argument i. If v j (cid:2) 1n , then j is added in CPS and iis added in CNW. If the previous condition does not hold but v i (cid:21) v j then the pair (i, j) is added in CPN. Finally, if theprevious conditions do not hold, then j is added in CPS when v j (cid:2) 1n . Note thatone of the previous two cases necessarily holds.n and i is added in CNW when v i (cid:3) 1n and v i (cid:3) 1+( y, x), (cid:3) j > (cid:3)i and v i < v j . This situation is illustrated by Example 10 in Section 8.3.1. The fact that the pair(i, j) is selected emphasises the fact that criterion j is stronger and more positive than i. If criterion j had the smallerweight v i of criterion i and if criterion i had the larger weight v j , then the decision would have been the opposite.Criterion i is present in the selected pair (i, j) only as a comparison to the situation of criterion j. Hence, criterion i isnot mentioned in the explanation. Therefore, if v j (cid:2) 1n , then j is added in CPS, otherwise j is added in CPRS.−( y, x), (cid:3) j > (cid:3)i and v i < v j . The situation is dual to (ii). Likewise, the most striking criterion is i since it ismore negative and weaker than j. Criterion j is present only to emphasis this difference and is thus not mentioned.Therefore, if v j (cid:3) 1n , then i is added in CNW, otherwise i is added in CNRW.(iii) i, j ∈ AInterpretation 3. In anchor ψIVT, there are more positive reasons regarding option y compared to the situation of the anchorψNOA since y is here better on average than x. We are looking for the permutations in the assignment of the weights tothe criteria, that invert the decision. These permutations are used to identify the decisive criteria. More precisely, fromProposition 9, the permutation π that is selected assigns in each cycle of π , the largest weights to the most negativecriteria and the smallest weights to the most positive criteria. Hence a criterion for which this property is satisfied withoutthe permutation, cannot be selected. The criteria that are likely to be selected are thus the positive arguments that arestrong and the negative ones that are weak. Yet the selection process in ψIVT can be seen as a relaxation of that in ψNOA asone may now consider a positive criterion which weight is lower than 1n , and a negative criterion which weight is greaterthan 1n .The arguments that are displayed among the elements of R∗are contained in C = (cid:22)CPS, CPRS, CNW, CNRW, CPN(cid:23). Severalexamples of the computation of C are given in Section 8.3.1. The explanation can be the following one:y is preferred to x since y is better than x on the criteria CPS that are importantand on the criteria CPRS that are relatively important, x is better than y on thecriteria CNW that are not important and on the criteria CNRW that are not reallyimportant, and [criterion j for which y is better than x is more important thancriterion i for which y is worse than x]for all (i, j)∈CPN .The argument in the brackets is repeated for all (i, j) ∈ CPN.1422C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448In the weight (π ◦ vA, v N\A), the weights remain the same for the non-selected criteria N \ A. In this case, unlikeanchor ψNOA, there is no property of the non-selected criteria. It is then possible to consider all minimal explanation sets Awith the smallest number of elements and to concatenate the explanation for these sets. This is illustrated in Example 15in Section 8.4.We now wish to compute a minimal element A of Ex(x, y, v, EU, ψIVT). First of all, one can search for A without search-ing for a permutation π . Proposition 9 shows indeed that, for A minimal, the restriction of π on S is equal to π S for allS ∈ A, and π (i) = i for all i ∈ N \ A. Let us define for S ⊆ NDEUS:=(cid:17)j∈Sv j(cid:3) j − minπ ∈Π (S)(cid:17)j∈Svπ ( j)(cid:3) j.By Lemma 3, DEUScandidate coalitions for A. We set=(cid:2)j∈S (v j − vπ S ( j))(cid:3) j . By Proposition 9, DEUS > 0 for S ∈ A. The subsets S for which DEUS= 0 are not(cid:5)S =S ⊆ N: DEUS > 0 and A(π S ) = {S}(cid:6).If A(π S ) (cid:4) {S}, then the coalition structure A(π S ) =: {S1, . . . , Sr} can be decomposed in sub-coalitions S1, . . . , Sr of S., coalition S can be replaced by the simpler coalitions {S1, . . . , Sr}, and thus S is discarded. ThisSince DEUSexplains the condition A(π S ) = {S} in the definition of S.The elements of S are labelled in the following order+ · · · + DEUSr= DEUS1S = {T 1, T 2, . . . , T p}with p = |S|, T 1 (cid:2)lexi T 2 (cid:2)lexi · · · (cid:2)lexi T p , and (cid:2)lexi is defined byS (cid:2)lexi T ⇐⇒ either|S| < |T | or(cid:7)|S| = |T | and DEUS(cid:8).(cid:2) DEUTThis is a lexicographic ordering where one looks first at the cardinality and then at the value of DEU. It can be interpretedin terms of the simplicity of presenting a coalition in the explanation. This order relation can be extended to explanationsets. We define (cid:4)discri over Ex as follows: For { A1, . . . , Aq}, {B1, . . . , Br} ∈ Ex with A1 (cid:2)lexi · · · (cid:2)lexi Aq and B1 (cid:2)lexi · · · (cid:2)lexi Br ,we have { A1, . . . , Aq} (cid:4)∗{B1, . . . , Br} ifdiscri(cid:7)∃k ∈ {1, . . . , t} | Aq| = |Br|, . . . , | Aq−k+1| = |Br−k+1| and | Aq−k| < |Br−k|(cid:8)(cid:7)| Aq| = |Br|, . . . , q < r and | A1| = |Br−q+1|(cid:8)orwhere t = q ∧ r, and we have { A1, . . . , Aq} (cid:4)discri {B1, . . . , Br} if { A1, . . . , Aq} (cid:4)∗discri{B1, . . . , Br} orq = rand | A1| = |B1|, . . . , | Aq| = |Bq|and ∃k ∈ {1, . . . , t} D A1= D B1 , . . . , D Ak−1= D Bk−1and D Ak > D Bk .In the explanation set { A1, . . . , Aq}, all coalitions will be explained to the user and Aq is the most complex coalition ofthis set. Hence when comparing two explanation sets, we compare the most complex coalition of the first explanation setwith that of the second one, then, in case of equality, do the same with the second most complex coalition, and so on.This is described by (cid:4)∗discri. When the two explanations sets have coalitions of the same cardinality, one then looks atthe value of D. This is depicted in (cid:4)discri. We define ≡discri over Ex as follows: with the same notation as before, we set{ A1, . . . , Aq} ≡discri {B1, . . . , Br} ifq = rand | A1| = |B1|, . . . , | Aq| = |Bq| and D A1= D B1 , . . . , D Aq= D Bq .Finally, we define (cid:18)discri by A (cid:18)discri B if either A (cid:4)discri B or A ≡discri B. The order (cid:18)discri is a complete order that refines(cid:18) in the sense that [21]:(i) A (cid:4) B ⇒ A (cid:4)discri B,(ii) ∃A, B ∈ Ex, A (cid:16)(cid:4) B, B (cid:16)(cid:4) A and A (cid:4)discri B.We define Algorithm Algo-EU (see Table 1) to determine a minimal explanation set A. In this algorithm, B contains thebest explanation set (in the sense of the complete order (cid:18)discri) found so far.Proposition 10. Algorithm Algo-EU always returns a non-empty explanation set. Moreover, the outcome of Algorithm Algo-EU is anelement of Ex(x, y, v, EU, ψIVT) that is minimal in the sense of (cid:18). Finally, the outcome of Algorithm Algo-EU is a minimal argumenta-tion set in Ex(x, y, v, EU, ψIVT) in the sense of (cid:18)discri.C. Labreuche / Artificial Intelligence 175 (2011) 1410–14481423Table 1Algorithm for the determination of A.Algorithm Algo-EU:For i = k + 1, . . . , p:If T i ∩ A = ∅:(cid:2)If• The algorithm returns the output of Algo(∅, ∅, 0).• Algo(A, B, k):L1:L2:L3:L4:L5:L6:L7:L8:L9:L10:L11:(cid:2) H EU+ D EUS∈A D EUT iSthen C ← A ∪ {{T i }},else // Branching:return ∅.C ← Algo(A ∪ {{T i }}, B, i).// Updating the best explanation set:If C (cid:16)= ∅ and [B = ∅ or C (cid:2)discri B] then B ← C.// Bounding:If B (cid:16)= ∅ and A ∪ {{T i }} (cid:16)(cid:2)discri B then return B.v ( y, x)To end this section, we show that Algorithm Algo-EU can be easily modified to generate all minimal explanation setsin the sense of the partial order (cid:4)∗discri. As said earlier, when one wish to enrich the generated text by considering severalexplanation sets, all these sets shall be minimal elements of Ex(x, y, v, EU, ψIVT) in the sense of (cid:4)∗discri. To this end, (cid:4)discriis replaced by (cid:4)∗discri in the algorithm. Moreover, the output B of the algorithm is no more a unique explanation set buta collection of explanation sets. Accordingly, B is now a collection of explanation sets. Then the line L8 is replaced by thefollowing two lines:If C (cid:16)= ∅ and B = ∅ then B ← {C}.If C (cid:16)= ∅ and B (cid:16)= ∅ and (cid:2)D ∈ B: D (cid:4)∗C then B ← (B \ {D ∈ B: C (cid:4)∗discriD}) ∪ {C}.discriMoreover, line L10 is replaced by:If B (cid:16)= ∅ and [∀D ∈ B: D (cid:4)∗A ∪ {{T i}}] then return B.discriExtending Proposition 10, we obtain that the modified Algorithm Algo-EU returns the minimal elements of Ex(x, y, v, EU,ψIVT) in the sense of (cid:4)∗discri.6.2. Weighted majority modelProposition 11. Let A ∈ Ex(x, y, v, Maj, ψIVT) be minimal in the sense of (cid:18). Let π ∈ Π(N) such that x (cid:3)EUA(π ). Let S ∈ A. Then 2 (cid:3) |S| (cid:3) 3. For all k, j ∈ S, with k (cid:16)= j, k and j cannot belong to the same set AMoreover, we have+( y, x), A(π ◦vA,v N\A) y and A ⊆−( y, x).=( y, x) or A• If [ j ∈ A• If [k ∈ A+( y, x) and k ∈ A+( y, x) and j ∈ A−( y, x)] or [ j ∈ A−( y, x)] or [k ∈ A+( y, x) and k ∈ A+( y, x) and j ∈ A=( y, x)] or [ j ∈ A=( y, x)] or [k ∈ A=( y, x) and k ∈ A=( y, x) and j ∈ A−( y, x)], then vπ (k) > vπ ( j).−( y, x)], then vπ (k) < vπ ( j).+( y, x), i= ∈ AFrom Proposition 11, following the permutation π , the largest weights among the coalition S are assigned to the negativearguments, and the smallest weights are assigned to the positive arguments. When |S| = 3, with S = {i+, i=, i−}, i+ ∈−( y, x). The idea is that, among criteria S, the largest weight is not assigned to theAnegative argument i− and the smallest weight is not assigned to the positive argument i+. The explanation can be thesame as in the previous section. First, the set Ris computed. Then the five sets of arguments CPS, CPRS, CNW, CNRW andCPN are constructed. The generated text is similar to that in the previous section.=( y, x) and i− ∈ A∗Algorithm Algo-EU described in Section 6.1 can be adapted with minor changes to determine a minimal explanation setwith the Maj model. One only needs to change DEU(cid:17)DMajS:=v j sgn j− minπ ∈Π (S)(cid:17)j∈Sj∈S(cid:2)vπ ( j) sgn j=(v j − vπ S ( j)) sgn jS by(cid:17)j∈Sand conditionS∈B DEUS+ DEUS i(cid:2) H EUv ( y, x) by(cid:2)S∈B DMajS+ DMajS i(cid:2) HMajv( y, x).6.3. Pessimistic qualitative modelProposition 12. Let A ∈ Ex(x, y, v, Pess, ψIVT) be minimal in the sense of (cid:18). Let π ∈ Π(N) such that x (cid:3)PessA(π ).For every S ∈ A, there exist K S ⊆ ( A+( y, x) ∪ A=( y, x)) ∩ S and J S ⊆ A−( y, x) ∩ S such that(π ◦vA,v N\A) y and A ⊆1424C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448(cid:5)vπ (i): i ∈(cid:9)−A( y, x) ∩ S(cid:10)(cid:6)\ J S> {vπ (k): k ∈ K S } (cid:2) {vπ ( j): j ∈ J S }(cid:10)+>( y, x)A( y, x) ∪ Avπ (i): i ∈(cid:9)(cid:9)(cid:5)=(cid:10)∩ S(cid:6).\ K SThe sets K S and J S , for S ∈ A, satisfy the following properties:• There exists at most a subset S ∈ A such that K S (cid:16)= ∅. For this coalition S, one has |K S | = 1.• For all S ∈ A, J S = ∅ whenever K S = ∅.• If S = N, then K S ∪ J S (cid:16)= N.Let S ∈ A. If K S (cid:16)= ∅ and K S = {k}, thenPess,N\{k}π ◦vh(x) = hPess,N\( J S ∪{k})π ◦v(x).The last relation in Proposition 12 means that criteria J S do not count in the overall evaluations of x and y.Interpretation 4. Without the permutation π , we are not in the situation described in Proposition 12. Hence the largestweights among a coalition S ∈ A are not assigned to the negative arguments (except for J S ), and the smallest weights arenot assigned to the positive arguments (except for K S ). The idea is that, among the selected criteria, the positive argumentshave a larger weight than the negative ones, which is quite easy to understand.As in Section 8.3.1, one may compute Rthe pair ( A S , B S ) (with A S = (S ∩ Anegative, j is positive or null, and v i < v j . The explanation can thus be the following one:−( y, x)) \ J S and B S = [S ∩ ( A+( y, x) ∪ A∗and C = (cid:22)CPS, CPRS, CNW, CNRW, CPN(cid:23). More precisely, for all S ∈ A, we define−( y, x))] \ K S ) such that ∀i ∈ A S , ∀ j ∈ B S , i isy is preferred to x since [criteria A S for which y is better than x are more importantthan criteria B S for which y is worse than x]for all S∈A.When K S ∪ J S = S, another explanation must be given. From the inequalities contained in (17) (see the proof of Propo-sition 12), the marks of x and y on the positive argument k are bad but are saved by the small weight of criterion k, since1 − vπ ( j) is relatively large for all j ∈ S \ {k}. Moreover, the marks of x and y on the negative arguments J S are good. Fromthe last relation in Proposition 12, the relatively bad overall utility of x is not attained in S but in the other criteria. Theexplanation can thus be the following one:. . . [the bad scores of x and y on the positive argument k are saved by its smallweight, the marks of x and y on the other criteria of S are good, and the relativelybad overall utility of x compared to y is due to the criteria not in S]S .Let us turn now to the computation of a minimal element of Ex(x, y, v, Pess, ψIVT). It is not necessary to explore thiscombinatorial structure. We use the characterization of the situation of the anchor ψRMG described in Proposition 19 givenin Section 7.3. According to this proposition, if there exists a permutation that inverts the preference between x and y, thenone of the three conditions (i), (ii) or (iii) in Proposition 19 is violated.Proposition 20 gives an equivalent condition for the satisfaction of (i). This condition can be easily checked. In the proofof this proposition, a permutation π (cid:8)1 is constructed when (i) is violated. In this case, we have y (cid:27)Pessπ (cid:8)1x by construction.Condition (ii) in Proposition 19 can be easily checked in practice. When it is violated, a permutation π (cid:8)2 is constructedin the proof of this proposition. It satisfies y (cid:27)Pessπ (cid:8)2x by construction.Condition (iii) in Proposition 19 is equivalent to relation (12) according to Proposition 21. Condition (12) can be easilychecked in practice. This condition is the conjunction of two conditions. When the first part of (12) is violated, one hasy (cid:27)Pessx,π (cid:8)3where π (cid:8)3 is defined in the proof of Proposition 21. When the second part of (12) is violated, one has y (cid:27)Pessπ (cid:8)4x, where π (cid:8)4 is defined in the proof of Proposition 21.A permutation that ensures the switch of preferences is thus easily constructed in all cases. One can refine these permu-tations to obtain cycles with the smallest cardinality. This provides a minimal element of Ex(x, y, v, Pess, ψIVT).7. Anchor “remaining case”We assume in this section that the anchor ψRMG applies, and thus+A( y, x) (cid:16)= N,y (cid:4)FwF x and ∀π ∈ Π(N),y (cid:4)Fπ ◦v x.The following result shows that the last relation in (6) implies that the middle relation in (6) also holds.(6)C. Labreuche / Artificial Intelligence 175 (2011) 1410–14481425Lemma 4. For all three models (namely (cid:3)Majw , (cid:3)Pessw and (cid:3)EUw ), one has∀π ∈ Π(N),y (cid:4)Fπ ◦v x "⇒ y (cid:4)FwF x.It proves that when anchor “invert” does not apply, the decision would be the same with the reference weights. Further-more, the preference of y over x is probably strong with the reference weights.7.1. Expected utility modelBy Lemma 3, if there does not exist π ∈ Π(N) such that H EUπ ◦v ( y, x) (cid:3) 0, then0 < minπ ∈Π (N)π ◦v ( y, x) = H EUH EUπ N ◦v ( y, x).A necessary and sufficient condition for the anchor ψRMG to be applied is that+A( y, x) (cid:16)= N and H EUπ N ◦v ( y, x) > 0.Lemma 5. One has for any v ∈ W(EU) and any z ∈ [0, 1]nw EU (z) = 1hEUn!(cid:17)π ∈Π (N)hEUπ ◦v (z).There is a geometrical interpretation of this result. The set of weights π ◦ v where π can be any permutation forms thevertices of a polyhedron (interpreted as a set of normalized weights). The arithmetic mean is the centre of gravity of thesevertices.Proposition 13. We haveπ N ◦v ( y, x) (cid:3) H EUH EUw EU ( y, x).Moreover, assume that∃i, j ∈ N, (cid:3)i (cid:16)= (cid:3) j.π N ◦v ( y, x) = H EUThen H EUwEU ( y, x) if and only if for all i ∈ N, v i = 1n .(7)Lemma 4 when F = EU follows from the first part of Proposition 13.When anchor ψRMG applies, there are both positive and negative arguments. Hence (7) holds. Proposition 13 suggeststhat there are basically two cases to explain why y remains preferred to x even when the weights are switched. The firstcase occurs when the weights are more or less the same (hence v ≈ w EU). A permutation of the weights has indeed noimpact on the comparison of x and y. In the other case, the weights are significantly different. Hence, since y remainspreferred to x for every permutation of the weights, y is expected to be much better than x on average. We need thefollowing two propositions to understand the separation between the previous two cases. More precisely, they establish arelationship between the closeness of v to the reference weight w EU, and the closeness of H EUwEU ( y, x) to H EUπ N ◦v ( y, x).Proposition 14. If (7) is satisfied and v ∈ W(EU) is different from w EU, thenw EU ( y, x) − minπ ∈Π (N) H EUH EUmaxπ ∈Π (N) H EUπ ◦v ( y, x)π ◦v ( y, x) − minπ ∈Π (N) H EUπ ◦v ( y, x)(cid:2) 1n.Moreover this inequality is sharp in the sense that one can find x, y, v such that the previous relation is satisfied with an equality.Proposition 15. We setν := maxi∈NThen(cid:11)(cid:11)(cid:11)v i − 1(cid:11)n(cid:11)(cid:11)(cid:11)(cid:11),δ := maxi, j|(cid:3)i − (cid:3) j| and χ EU :=(cid:11)(cid:11)H EUw EU ( y, x) − H EU(cid:11)(cid:11).π N ◦v ( y, x)ν (cid:3) (n − 1)nπ N ◦v ( y, x) − H EUH EUπ N ◦v ( y, x)δand ν (cid:3) (n − 1)χ EUδ.Moreover, these inequalities are sharp.1426C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448Following Propositions 14 and 15, we have two cases.• ν ≈ 0 (say ν (cid:3) εν in practice, where εν is a parameter).Interpretation 5. The weights v of the criteria are neutral in the sense that there is no specificity that could favoura criterion or disfavour another criterion. Hence H EUwEU . This means thatvy (cid:4)EUis almost equal to the arithmetic mean H EUwEU x. This latter relation is easy to understand and to be checked by the user.v x follows from the relation y (cid:4)EUThe explanation can thus be the following one:y is preferred to x since y is on average better than x and all the criteria havealmost the same weights.• ν (cid:16)≈ 0 (say ν > εν in practice).Interpretation 6. When the weights of the criteria are very different, the large weights can be assigned indifferently onthe positive and negative arguments, without inverting the preference of y over x. One feels intuitively that this comesfrom the fact that the value of (cid:3) on A+( y, x) is on average much larger than the value of (cid:3) on A−( y, x).χ EUδFrom Proposition 15, when ν > εν , quantityis not small. In this ratio, the denominator δ acts as a normalization.We do not focus on the absolute values of the difference between H EU( y, x), since a small value ofχ EU does not necessarily mean that the comparison of x and y is obvious. It may indeed result from the fact that thetwo options x and y have relatively close marks.Here H EUwEU ( y, x) is significantly larger than H EUwEU ( y, x) is significantly larger than zerovπ Nmeans that the positive arguments in favour of y are on average significantly larger than the negative arguments. Weconsider two subcases.Firstly, we consider the case when ν is relatively small (say εν < ν < εν in practice, where εν is a parameter). Theexplanation can thus be the following one:( y, x) > 0. The fact that H EUwEU ( y, x) and H EUvπ Ny is preferred to x since the intensity of preference y over x on Asignificantly larger than the intensity of preference of x over y on Aand all the criteria have more or less the same weights.+( y, x) is−( y, x),There remains to consider the case when ν is large (say ν (cid:2) εν in practice). Then from Proposition 15, quantitylarge. The explanation can thus be the following one:χ EUδisy is preferred to x since the intensity of preference y over x on Alarger than the intensity of preference of x over y on A−( y, x).+( y, x) is much7.2. Weighted majority modelLemma 6. One has for any v ∈ W(Maj)w Maj ( y, x) = 1H Majn!(cid:17)π ∈Π (N)H Majπ ◦v ( y, x).Proposition 16. Consider two alternatives x, y ∈ X . We haveHMajw Maj ( y, x) (cid:2) HMajπ N ◦v ( y, x).Assume that+A( y, x) (cid:16)= N,−A( y, x) (cid:16)= N and A=( y, x) (cid:16)= N.Then, HMajπ N ◦v ( y, x) = HMajwMaj ( y, x) if and only if v = w Maj.(8)Condition (8) means that x does not dominates strictly y on all criteria, y does not dominates strictly x on all criteria,and x is not identical to y on all criteria.A necessary and sufficient condition for the anchor ψRMG to be applied is thatC. Labreuche / Artificial Intelligence 175 (2011) 1410–14481427+A( y, x) (cid:16)= N and H Majπ N ◦v ( y, x) > 0.Lemma 4 when F = Maj follows from the first part of Proposition 16.Proposition 17. Let χ Maj := |H(cid:11)(cid:11)(cid:11)(cid:11) (cid:3) 4n(n − 1)χ Maj.(cid:11)(cid:11)(cid:11)v i − 1(cid:11)nMajwMaj (x, y) − HMajvπ N(x, y)|. Then for all i ∈ NThe explanation that can be generated is more or less similar to Section 7.1. We have the following cases.• ν ≈ 0 (say ν (cid:3) εν in practice). Hence H EUvis almost equal to the arithmetic mean H EUwEU . This means that y (cid:4)Majvx followsfrom the relation y (cid:4)MajwEU x. The explanation can thus be the following one:y is preferred to x since there are more criteria for which y is better than xthan criteria for which x is better than y, and the aggregation model is almostthe majority rule.• ν (cid:16)≈ 0 (say ν > εν in practice). Proposition 17, quantity χ Maj is not small. Hence H EUwMaj ( y, x) is significantly larger thanMajπ N ◦v ( y, x). Hence the decision made by the majority rule is very strong. The explanation tells just a little bit of theHspecificities of x and y, namelyy is preferred to x since the criteria for which y is better than x are ON AVERAGEMUCH stronger than the criteria for which x is better than y.7.3. Pessimistic qualitative modelLemma 4 when F = Pess follows from the following proposition.Proposition 18. Let v ∈ W(Pess). If for every permutation π ∈ Π(N), hPessπ ◦v ( y) > hPessπ ◦v (x) thenn(cid:18)i=1n(cid:18)yi >xi.i=1For w ∈ W(Pess), we have hPess(z) ∧ hw (z) = hanchor ψRMG for the Pess model through the following three propositions.(z) ∧ hPess, AwPess, Aw+( y,x)=( y,x)−( y,x)Pess, Aw(z). We now give a characterization ofProposition 19. Let(cid:5)E := {1} ∪xi: i ∈ A+(cid:6)( y, x)∪(cid:5)1 − vπ vN ( j): j ∈(cid:5)(cid:11)(cid:11) A+(cid:11)(cid:11)( y, x)(cid:6)(cid:6).1, . . . ,Let e be the median value of the discrete set E.We have∀π ∈ Π(N) hPess, Aπ ◦v+( y,x)(x) (cid:3) e.Moreover, H Pessπ ◦v ( y, x) > 0 for every π ∈ Π(N) if and only if the following three propositions hold:Pess, A(i) ∀π ∈ Π(N), hπ ◦v−( y, x) ∪ A(ii) ∀i ∈ A(iii) ∀π ∈ Π(N), hPess+( y,x)( y) > h=( y, x), yi > e,Pess, Aπ ◦vπ ◦v (x) < h−( y,x)Pess, Aπ ◦v+( y,x)(x),Pess, Aπ ◦v=( y,x)(x).(x) ∧ h(cid:3)Proposition 20. Let iV i+ (cid:16)= ∅) such that 1 − vk+ =(cid:3)k∈V i+ ∈ A+( y, x) such thati∈ A+( y,x) yi = yi+ . Let V i+ = {k ∈ N: 1 − vk (cid:2) yi+ }, and k+ (1 − vk). The following two propositions are equivalent:Pess, A(i) ∀π ∈ Π(N), hπ ◦v(ii) either V i+ = ∅ or(cid:11)(cid:5)(cid:11)|V i+ | <+( y,x)( y) > hPess, Aπ ◦v+( y,x)(x),+( y, x): x j < 1 − vk+(cid:6)(cid:11)(cid:11).j ∈ A(9)+ ∈ V i+ (defined when(10)1428C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448Proposition 21. Let j(cid:5)I =+i ∈ A( y, x): xi < x j+.+ ∈ A−( y, x) ∪ A=( y, x) such that x j+ =(cid:3)j∈ A−( y,x)∪ A=( y,x) x j . Let(cid:6)Then the following relations are equivalent:∀π ∈ Π(N): hPessπ ◦v (x) < hPess, Aπ ◦v−( y,x)(x) ∧ hPess, Aπ ◦v=( y,x)(x)andI (cid:16)= ∅ and(cid:11)(cid:11){k ∈ N: 1 − vk (cid:2) x j+ }(cid:11)(cid:11) < |I|.(11)(12)A necessary and sufficient condition for having y (cid:4)Pessπ ◦v x for all π ∈ Π(N) is the satisfaction of both condition (ii) inProposition 19, condition (ii) in Proposition 20 and relation (12) in Proposition 21. From these properties, one can easilycheck whether anchor ψRMG can be applied.We are now interested in the generation of the explanation to the user. From Proposition 19, the three conditions (i), (ii)and (iii) hold. According to Proposition 20, one has either V i+ = ∅ or (10).Assume first that V i+ = ∅. The worse scores of x on A+( y, x) are clearly smaller than yi+ . When V i+ = ∅, there is no+( y, x) and the even worse score of x. Thisweight that can hide the difference between the worst score yi+ of y on Ameans that all the weights are large enough, and thus that the aggregation function is close to the minimum. The first partof the explanation can thus be as follows:y is preferred to x since there is no weight that can hide the worse score of xcompared to y on Athat y is strictly better than x on A+( y, x). [The aggregation function is almost the Minimum.] Recall+( y, x). . . .+( y, x) for which x hasThe other case is when (10) holds. The set L := { j ∈ A+( y, x). If |V i+ | < |L|, thena very bad score. The set V i+ gathers all the weights that can hide the worst score yi+ of y on Athere is at least one weight for which the worse score of x compared to y cannot be saved. The first part of the explanationcan thus be as follows:+( y, x): x j < 1 − vk+ } contains the criteria in Ay is preferred to x since there is at least a weight that cannot hide the worse+( y, x). [The aggregation function is close to thescores of x compared to y on AMinimum.] Recall that y is strictly better than x on A+( y, x). . . .The mid-part of the explanation concerns the point (ii) in Proposition 19. The overall score of x is lower than e. Thus y=( y, x). The next part of the explanation can thus be the following−( y, x) ∪ Ais better than the overall utility of x, over Aone:. . . y is better than the overall score of x, on the criteria A=( y, x). . . .that y is not better than x on the criteria A−( y, x) ∪ A−( y, x) ∪ A=( y, x). RecallThe last part of the explanation concerns the point (iii) in Proposition 19, and Proposition 21. From relation I (cid:16)= ∅, the+( y, x). From relation |{k ∈ N: 1 − vk (cid:2) x j+ }| < |I|, there is at least one weight for which=( y, x). The end of the explanation+( y, x) cannot be saved up to the scores of x on A−( y, x) ∪ Aworse scores of x are attained in Athe worse scores of x in Acan thus be as follows:. . . Finally, the worse scores of x are attained in Aweight for which the worse scores of x in Aof x on A−( y, x) ∪ A=( y, x). [The aggregation function is close to the Minimum.]+( y, x) cannot be saved up to the scores+( y, x). There is at least one8. Illustration and experimental resultsThe aim of this section is threefold. Firstly, the process for generating the explanation is summarized in Section 8.1.Secondly, we wish to show that our approach helps the user to better understand the decision than when he tries todo it on his own. The anchors can be seen as meta-explanations or explanation schemas [57]. It aims at selecting thedecisive criteria in the comparison y (cid:4)Fv x. The decisive criteria are the most influencing criteria in the decision, and theirdetermination helps the user to better understand the decision and also to take actions on the decision such as improvementactions. We illustrate how the anchors behave on several examples.The illustrations focus on the two models EU and Pess. The reason why the model Maj is not considered is that the Majmodel can be seen as a particular case of the EU model applied to binary alternatives. Indeed, we haveC. Labreuche / Artificial Intelligence 175 (2011) 1410–14481429y (cid:4)Majvx ⇐⇒ y∗ (cid:4)EU∗v x∗iand y∗where xy∗are defined from x and y by the relations xi∗= 0 otherwise.Sections 8.2 and 8.3 discuss the two anchors ψNOA and ψIVT respectively, and show several illustrative examples. Wedo not consider specifically the two other anchors ψALL and ψRMG since their interpretation is more straightforward and inparticular they do not require the selection of a subset of criteria. Moreover, Section 8.4 presents a comparative study ofseveral explanations on the three anchors ψNOA, ψIVT and ψRMG for the EU model.∗= 1 if xi (cid:2) yi and xi= 0 otherwise, and y= 1 if yi (cid:2) xi and∗iThe third aim of this section is to present some experimental results concerning the practical determination of theexplanation (see Section 8.5).8.1. Generation process of the explanationsThe generation of the explanation for a given instance (x, y, v) ∈ D(F ) is obtained as follows. One aims at determininga non-dominated element of Ex(x, y, v, F ) w.r.t. (cid:2).Due to the lexicographic structure of (cid:2) over Ex(x, y, v, F ), one first identifies the anchor to be applied. The conditionsunder which each anchor can be applied have been presented throughout this paper. More precisely, these are, for everyψ ∈ Ψ , necessity and sufficient conditions on (x, y, v) to have (x, y, v) ∈ D(F , ψ). We identify the most preferred anchor ˆψin the set {ψ ∈ Ψ : (x, y, v) ∈ D(F , ψ)} according to (cid:2).Then we compute a non-dominated explanation setˆA in Ex(x, y, v, F , ˆψ) for this anchor ˆψ . This was presented in theprevious sections. Considering the EU model, it is trivial for the ψALL and ψRMG anchors, it requires to sort a vector for theψNOA anchor, and it is solved by Algorithm Algo-EU for the anchor ψIVT.Finally, from ( ˆψ, ˆA), the corresponding textual explanation is generated. Examples of text have been presented earlier inthe paper.8.2. Illustration of the anchor “not on average”8.2.1. Model EULet us first compare the Klein [35] approach with our. In our approach, a selected criterion i for anchor ψNOA necessarilyfulfils (v i − 1n )(cid:3)i > 0 (see Proposition 1). A criterion is likely to be selected if it is a negative and weak argument, or if itis a positive and strong argument. On the other hand, in the Klein approach, the criteria for which |(cid:3)i| ≈ 0 and v i ≈ 0 areunlikely to be selected.There are three main situations in which the two approaches give different results. The first two ones are not specific tothe anchor ψNOA while the third one is specific to this anchor. In the first one, criterion i is a weak and negative argument. Itis very intuitive to show such a criterion. Our approach selects this criterion while Klein’s approach usually does not. In thesecond situation, criterion i is a strong and negative argument. Klein’s approach selects this criterion while ours does not.This non-decisive criterion is compensated by positive arguments since y is after all preferred to x. Hence, it is not necessaryat all to show this criterion to the user in a synthesis. In the last situation, criterion i is a medium argument (v i ≈ 1n ) with|(cid:3)i| (cid:19) 0. Klein’s approach often selects this criterion while ours usually does not. The strength of the argument correspondsto the reference weight 1n that one might have in mind. Since it is not different from the prior, it is not useful to show itexplicitly to the user. It is better to focus on the criteria that have less standard weights (very small or large).We now give several examples to illustrate the main properties of our approach. As shown in Example 5, our approachselects very few arguments (only one in Example 5) when the decision is clear cut. On the opposite side, when the decisionis very tight, more criteria are selected with our approach (see Example 6). It is indeed intuitive that the tighter the decision,the more arguments are selected. This does not occur with the Klein approach (see Examples 5 and 6). Other examples withmore criteria can be found in Section 8.4Example 5 (The decision is relatively clear-cut, and the two approaches select opposite arguments). Consider the situation wherex = (0.42, 0.66, 0.66, 0.57), y = (0.54, 0.04, 0.89, 0.76) and v = (0.41, 0.06, 0.24, 0.29). Then (cid:3) = (0.12, −0.62, 0.23, 0.19).y is significantly preferred to x since hEUv ( y) = 0.66 and hEUv (x) = 0.54.Criteria(v i − 1compelin ) × (cid:3)i= v i |(cid:3)i |120.0190.0490.1180.0373−0.0020.05540.0080.055The Klein approach selects most of the arguments in this case – namely criteria 1, 3 and 4 – even though the decision isrelatively clear-cut. On the other hand, our approach selects only one argument – namely criterion 2 – which is enough inthis example. Looking at the example, criterion 2 is indeed the main argument why x is better on average than y but y ispreferred to x with the decision model.1430C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448Example 6 (The decision is tight and our approach returns almost all arguments). Let us consider x = (0.95, 0.67, 0.64, 0.27, 0.39),y = (0.3, 0.37, 0.41, 0.94, 0.49) and v = (0.18, 0.11, 0.12, 0.24, 0.35). Then (cid:3) = (−0.65, −0.3, −0.23, 0.67, 0.1). y is justslightly preferred to x since hEUv ( y) = 0.54 and hEUv (x) = 0.52.Criteria(v i − 1compelin ) × (cid:3)i123450.0130.1170.0270.0330.0180.0280.0270.1610.0150.035The Klein approach selects criteria 1 and 4. On the other hand, in our approach, criteria 2, 3, 4, 5 are selected.8.2.2. Model PessSeveral examples are given. Example 7 illustrates the case when Mclear-cut, the number of selected criteria is small. The more general case M∗ = ∅. This example shows that when the decision is∗ (cid:16)= ∅ is represented by Example 8.Example 7 (Clear-cut decision with 10 criteria). Consider the following values of x, y and v.y = (0.1, 0., 0.66, 0.97, 0.45, 0.71, 0.57, 0.77, 0.09, 0.69),x = (0.14, 0.46, 0.26, 0.8, 0.69, 0.64, 0.07, 0.17, 0.94, 0.45),v = (0.13, 0.53, 0.45, 0.12, 0.83, 0.57, 1.0, 0.19, 0.58, 0.23).vv(x) = 0.07, hPess( y) = 0.42 and y (cid:4)Pessx. The selected criterion is 2. Moreover, criterion kx = 7 is decisive sinceWe have hPess∗ = ∅. Thethe worse score of x is reached on this criterion, it is a positive and strong argument. We have M = {2} and Mgeneric text can be generated from S, kx and M. The last sentence in this generic explanation text is: “ y is sufficiently goodon the remaining criteria 1, 3, 4, 5, 6, 8, 9 and 10”. We remark that the scores of y on the two criteria 1 and 9 are not good (0.1(x) = 0.07 of x. The decision would not have changed if the weightand 0.09) but they are larger than the over score hPess= 1 were assigned to the criteria 1 and 9. It turns out that these two criteria have a medium importance, whichw Pessiimplies that the overall score of y is much larger than that of x. But it is not necessary to show this in the explanation.∗vvExample 8 (Tight decision with 10 criteria). Consider the following values of x, y and v.y = (0.36, 0.01, 0.22, 0.11, 0.61, 0.4, 0.06, 0.07, 0.43, 0.61),x = (0.25, 0.21, 0.14, 0.08, 0.53, 0.15, 0.2, 0.53, 0.87, 0.75),v = (1.0, 0.02, 0.86, 0.23, 0.91, 0.53, 0.36, 0.17, 0.26, 0.53).We have hPessMv(x) = 0.14, hPess( y) = 0.22 and y (cid:4)Pessx. The selected criteria are 2, 7, 8. Moreover, kx = 3, M = {2, 4, 7, 8} and∗ = {4}. Indeed, the worse score of x is reached on this criterion 4, which is a positive and strong argument.vv8.3. Illustration of the anchor “invert”8.3.1. Model EUIn most of the cases that we have encountered, the cycles of a minimal permutation are of cardinality 2. A cycle of size 3is presented in Example 9. The second example contains 10 criteria. It is also possible to consider all the explanation setsof minimal cardinality in order to generate the textual explanation (see Example 15 later).Example 9 (Permutation between three criteria). Let x = (0.89, 0.03, 0.07, 0.32, 0.38), y = (0.36, 0.76, 0.6, 0.25, 0.75) andv = (0.06, 0.11, 0.21, 0.29, 0.33). Then we have (cid:3) = (−0.53, 0.73, 0.53, −0.07, 0.37). We have compel = (0.031, 0.08, 0.111,0.02, 0.122). The Klein approach selects criteria 5 and 3. On the other hand, the minimal element in Ex(x, y, v, EU, ψIVT) is{{1, 3, 5}}. For the associated permutation π , the score of criteria 1, 5 and 3 are assigned to the weight of criteria 5, 3 and 1respectively (i.e. π (5) = 1, π (3) = 5 and π (1) = 3). We note that π is the most disfavourable permutation for y on {1, 3, 5}.∗ = {(1, 3), (1, 5)}. Finally, CPS = {3, 5}, CNW = {1}, and the other sets of the tuple C are empty (seeIt is easy to see that RSection 6.1).Example 10 (Example with 10 criteria). Lety = (0.45, 0.64, 0.86, 0.76, 0.87, 0.54, 0.17, 0.04, 0.55, 0.05),x = (0.61, 0.28, 0.08, 0.02, 0.81, 0.15, 0.16, 0.38, 0.24, 0.75),(cid:3) = (−0.16, 0.36, 0.78, 0.74, 0.06, 0.39, 0.01, −0.34, 0.31, −0.7),v = (0.13, 0.04, 0.12, 0.1, 0.07, 0.19, 0.15, 0.03, 0.01, 0.16).C. Labreuche / Artificial Intelligence 175 (2011) 1410–14481431We have compel = (0.021, 0.014, 0.094, 0.074, 0.004, 0.074, 0.001, 0.01, 0.003, 0.112). The Klein approach selects criteria10, 3, 6 and 4. On the other hand, in our approach, the explanation set is {{6, 8}, {3, 9}}. Regarding the pair {6, 8}, criterion 6is positive and important and criterion 8 is negative and not important. Regarding the pair {3, 9}, both criteria are positivearguments, and criterion 3 is more positive and more important than criterion 9. Criterion 9 is not mentioned. Finally,CPS = {3, 6}, CNW = {8}, and the other sets of the tuple C are empty.8.3.2. Model PessThe following examples illustrate different situations regarding the size of the minimal explanation sets: the minimalexplanation set is composed of one subset of cardinality 3 in Example 11, and of two subsets of cardinality 2 in Example 12.Example 11 (A selected set of cardinality 3). Let y = (0.83, 0.66, 0.19, 0.55, 0.94, 0.75), x = (0.63, 0.0, 0.15, 0.98, 0.97, 0.81)and v = (0.82, 0.8, 1.0, 0.1, 0.28, 0.26). We have y (cid:4)Pessx. The minimum selected coalitions in Ex(x, y, v, Pess, ψIVT) are ofcardinality 3: {{2, 3, 4}}, {{2, 3, 5}} and {{2, 3, 6}}. We note that criteria 2 and 3 are present in all three selected sets. Thesetwo criteria are positive arguments with a large weight. The overall score of x and y is attained at criterion 3 that has avery large importance. The other criteria 4, 5 and 6 that appear in the selected criteria are negative arguments with a smallweight.vExample 12 (Example with 9 criteria). Consider the following values of x, y and v.y = (0.43, 0.57, 0.28, 0.5, 0.46, 0.3, 0.6, 0.48, 0.83),x = (0.05, 0.89, 0.22, 0.0, 0.82, 0.74, 0.86, 0.17, 0.76),v = (1.0, 0.7, 0.67, 0.29, 0.27, 0.29, 0.78, 0.87, 0.67).vWe have y (cid:4)Pessx. The selected set is composed of two cycles: {{1, 2}, {6, 8}}. In the cycle {1, 2}, criterion 1 is a positiveargument with a very large importance, and criterion 2 is a negative argument with an importance lower than that ofcriterion 1. Moreover, the overall score of x is attained at the very important criterion 1 for which x has a very small score.Concerning the cycle {6, 8}, criterion 6 is a negative argument with a small weight and criterion 8 is a positive argumentwith a large weight. The explanation says that criterion 1 that is a positive argument is more important than criterion 2that is a negative argument, and criterion 8 that is a positive argument is more important than criterion 6 that is a negativeargument. Finally, on the remaining criteria, y has rather good evaluations.8.4. Comparison of several anchors on the EU modelIn order to compare the anchors, we fix the two vectors x and y, and we will consider different values of the weight v.Clearly, if anchor ψALL holds for one weight vector v, then this anchor also holds for any other value of v. Hence, we focuson the three other anchors ψNOA, ψIVT and ψRMG. We consider the following values of x and yy = (0.99, 0.35, 0.31, 0.51, 0.62, 0.57, 0.52),x = (0.5, 0.06, 0.03, 0.95, 0.87, 0.2, 0.95).Option y is on average better than x. The following examples of v are given.Example 13 (Anchor ψNOA). Let v = (0.06, 0.11, 0.19, 0.11, 0.31, 0.08, 0.14). Option x is preferred to y. The Klein approachselects the criteria 5 and 7. The selected criteria for this anchor are the criteria 1 and 5. Criterion 1 is a weak and negativeargument, and criterion 5 is a positive and strong argument. The other criteria are not explicitly mentioned since theirimportance are relatively close to the mean importance 1n .Example 14 (Anchor ψNOA). Let v = (0.14, 0.05, 0.17, 0.23, 0.17, 0.11, 0.13). Option x is preferred to y. The Klein approachhighlights the criteria 4 and 1. Our approach selects the criteria 2 and 4. Criterion 2 is a weak and negative argument, andcriterion 4 is a positive and strong argument. The other criteria have, as in the previous case, an importance that is close tothe mean importance 1n , and are thus not explicitly mentioned.Example 15 (Anchor ψIVT). Let v = (0.11, 0.14, 0.13, 0.02, 0.27, 0.25, 0.08). Option y is preferred to x. The Klein approachhighlights the criteria 6 and 5. There are two elements of Ex(x, y, v, EU, ψIVT) of cardinality 2: {{4, 6}} and {{6, 7}}. In theselection {4, 6}, criterion 6 is a positive and strong argument, and criterion 4 is a very weak and negative argument. Wenote that criterion 6 also belongs to the second selection and that criterion 7 in the second selection is a weak and negativeargument. At the end, the three criteria 4, 6 and 7 are displayed in the explanation.1432C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448Fig. 1. Results of the experimental study. The columns “occur.” show the percentage of occurrence of each anchor. The mean computation time is presentedin the column “mean execut. time”. The mean percentage of the tree that is explored during the search appears in the column “perc. tree explor.”. Finally,the column “1st coalition expl. set” corresponds to the percentage of times the algorithm terminates at the very first step.Example 16 (Anchor ψIVT). Let v = (0.24, 0.2, 0.25, 0.06, 0.02, 0.19, 0.04). Option y is preferred to x. The Klein approachhighlights the criteria 1 and 6. The preferred explanation set in Ex(x, y, v, EU, ψIVT) is {{1, 7}, {3, 4}}. In the pair {1, 7},criterion 1 is a positive and strong argument, and criterion 7 is a weak and negative argument. In the pair {3, 4}, criterion3 is a positive and strong argument, and criterion 4 is a weak and negative argument. The four criteria 1, 3, 4 and 7 aredisplayed in the explanation.Example 17 (Anchor ψRMG). Let v = (0.16, 0.14, 0.15, 0.1, 0.16, 0.15, 0.14). Option y is preferred to x. The Klein approachselects the criteria 1 and 7. We are in the situation of Interpretation 6: the intensity of preference of y over x on thepositive criteria 1, 2, 3 and 6 is significantly larger than the intensity of preference of x over y on the negative criteria 4, 5and 7. Moreover, all the criteria have more or less the same weights.Example 18 (Anchor ψRMG). Let v = (0.12, 0.16, 0.15, 0.16, 0.15, 0.14, 0.12). Option y is preferred to x. The Klein approachselects the criteria 4 and 1. We are in the situation of Interpretation 5. Compared to the previous situation, the weights arecloser to the arithmetic mean. Even though y is on average significantly better than x, we do not need to use this argumenthere.We have seen that the three anchors are triggered for different values of v. The seven criteria have been selected in theprevious examples for the anchors ψNOA and ψIVT. This shows the influence of the weights on the selection process.8.5. Experimental resultsWe present in this section the results of experimentations conducted on our approach. The tests are mainly concernedwith the computational performance of the determination of a non-dominated explanation set. Among the three models EU,Maj and Pess, we restrict ourselves to the case of the EU model. We have seen that the methods and algorithms that selectan explanation set are very similar for the two models EU and Maj. Hence it is not necessary to perform an experiment onboth models. Moreover, the determination of a non-dominated explanation set can be almost done by hand for the modelPess (see the end of Section 6.3), and requires thus less computation time.The computation that is necessary to determine a non-dominated explanation set is not time consuming for the anchorsψALL, ψNOA and ψRMG since one needs at most to sort a vector of n components. By contrast, Algorithm Algo-EU used inanchor ψIVT requires the search of the explanation among a large tree. The computation time is thus shown only for theanchor ψIVT.Our approach has been implemented in Java and tested on an Intel Pentium Core 2 computer with 2.66 GHz. Theexperimentations are performed on randomly generated instances from the set D(EU). Fig. 1 shows the percentage ofoccurrence of each anchor in the experiment. Concerning Algorithm Algo-EU, the mean execution time is given. To analysethe efficiency of the branching strategy of this algorithm, Fig. 1 also indicates the mean percentage of the tree that isexplored during the search. We have noticed that the algorithm often terminates at the first iteration. This situation ariseswhen {T 1} is an explanation set, where T 1 is the smallest element of S according to (cid:2)lexi. Fig. 1 presents the results forvalues of n between 4 and 20. These are the most commonly encountered values for the number of attributes, in practice.According to Fig. 1, the algorithm terminates at the very first coalition in S, in at least one case over two. This shows thatthe strategy that was chosen for the ranking of the coalitions of S according to (cid:2)lexi is efficient. Moreover, the percentageof the search tree that is explored by the algorithm decreases very rapidly with n. The worse scenario in Algorithm Algo-EUoccurs when the only explanation set is the grand coalition N, that is for a permutation π such that A(π ) = {N}. In thiscase, the 2subsets of S, where |S| (cid:3) 2n − 1, are explored before finding the explanation set.|S|C. Labreuche / Artificial Intelligence 175 (2011) 1410–14481433For small values of n, the two anchors that occur most likely are ψIVT and ψRMG. The probability of occurrence for anchor2n−1 and thus decreases very rapidly with n. For larger values of n, the preponderant case becomes anchor ψIVT.1ψALL isIf ν > 1n , the weight vector v is clearly not close to the reference weight w EU. Concerning the anchor ψRMG, we haveobtained a good separation of the three sub-cases on this anchor with the values εν = 0.15nand εν = 0.3n .9. ConclusionWe propose an approach to select the arguments to be used in the explanation of the prescription made by a multi-attribute decision model parameterized by weights assigned to the criteria. It is based on the analysis of the values of theweights together with the relative scores of the options to be compared. The general approach is applied on three decisionmodels: the expected utility model (EU), the weighted majority model (Maj) and the weighted minmax model (Pess). Thesethree models are the most well-known weight-based models in decision theory. Moreover, they represent very differentvisions of decision theory.The idea of our approach is to look for some changes in the weight vector v that yield an inversion of the prescriptionmade by the decision model. The explanation focuses then on the criteria for which the weight vector has changed. Theremaining criteria do not play any role in the inversion of the prescription and are thus not mentioned in the explanation.Not any change of the weights can be used since this change shall be explainable to the user. In this paper, two strategies for, and a permutation ofthe modification of the weights are considered: the replacement of v by some reference weights wthe weights v among the criteria. These two strategies lead to two different explanation strategies. They are called anchorsψNOA and ψIVT respectively.FThere are several possible changes of the weights compatible to each anchor. All these admissible changes can be repre-sented in a single combinatorial structure Ex(x, y, v, F ) containing all explanation sets. Since one is interested in the simplestexplanation, the simplest changes are sought. In the structure Ex(x, y, v, F ), this is expressed by an order relation (cid:18). Onethen looks at the non-dominated elements of Ex(x, y, v, F ), in the sense of (cid:18).The properties of the non-dominated explanation sets have been studied for the two anchors ψNOA and ψIVT. Concerninganchor ψNOA, we have shown, for the three models EU, Maj and Pess, that the positive selected arguments turn out tobe strong and the negative selected arguments are weak. Moreover, the selected arguments for the qualitative Pess modelare necessarily negative. This comes from the fact that the min operator expresses the principle of elimination among thecriteria. An explanation can then easily be generated from these properties. The computation of a particular non-dominatedexplanation set is easy since one needs only to rank a vector. Concerning anchor ψIVT, we obtain roughly the same idea butin a weaker form. More precisely, the allocation of the weights to the criteria is not the most unfavourable one relatively toan inversion of the prescription, for the models EU and Maj. This implies that the positive arguments have more importantweights than the negative arguments. A branch and bound algorithm has been proposed to compute a particular non-dominated explanation set. The underlying combinatorial structure is large since it is isomorphic to the set of coalitionstructures. In the algorithm, the coalition structures with coalitions of small cardinality are explored first. Experimentaltests have shown that this strategy enables to find very quickly the explanation set in most of the cases.The two anchors ψNOA and ψIVT do not cover all cases of (x, y, v) ∈ D(F ). Another case, which is the simplest one (ψALL),occurs when there is only positive arguments. The explanation does not need to mention the specificities of the decisionmodel in this trivial situation. The last case (ψRMG) gathers all the situations not covered by the other anchors. Interestinglyenough, we were able to divide D(F , ψIVT) in very few typical sub-cases. For instance, for the EU model, either the weightsare close to the reference weights, or there are clearly more positive arguments than negative ones.We have shown through numerous illustrative examples, that the explanation that is generated really helps to understandthe decision. This comes from the fact that our approach selects the decisive criteria, that is the criteria for which a givenchange in the weight switches the decision. The type of relevant change is dependant on the anchor.This work could benefit from several extensions. First of all, our framework could be applied to other weight-baseddecision models. An example of such model is the weighted maxmin function [22]. This model is the optimistic counterpartof the weighted minmax function hPess. Some preliminary results were given in [39] and suggest that the extension ofour approach is possible for this model. Secondly, the approach could also be extended to models using more complexparameters than a simple weight assigned to each criterion. One may think of the Choquet and Sugeno integrals whichextend the EU and Pess models respectively [15,53]. The parameters of these discrete integrals correspond to the concept ofa capacity, which contains 2n coefficients [15]. The generation of an explanation for the Choquet integral w.r.t. a particularcase of a capacity were already addressed but it needs to be further studied [38,43].In this paper, we have not put our attention in this paper to the structuration and expression of the selected arguments.The textual explanations that we proposed throughout this paper were given only to show the type of explanation that eachanchor yields. This can be improved by incorporating dedicated techniques for the generation of natural language.The explanations resulting from our approach aim at finding the very arguments that are at the root of the prescription.The explanation that we produce is more complex than that generated in [14,35,43], but our explanation reasoning is moresound. We analyse more deeply the specificity of the model and deduce from that the set of selected arguments. For thisreason, our approach is more suited to applications where a high added-value of the decision model is expected. Thismeans that the recipients of this approach are more domain experts than simple users of the Internet. To cite an exampleof application, one can mention the decision aid for the selection of candidate architectural options in the design of complex1434C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448systems, which requires elaborate decision models [47]. However, we have shown that the explanation that is generated isfar from being complex for the EU and Maj models. An interesting property of our framework is indeed that the explanationadapts itself automatically to the complexity of the prescription. On the other hand, the explanation is more complex for thePess model. The min and max binary operators are extensions of the Boolean AND and OR operator on non-Boolean spaces.The weighted minmax can thus be seen as a complex condition combining many AND and OR operators. This indicateswhy the explanation is complex and needs many arguments. An extension of this work could be to generate a simplifiedexplanation for this model.10. Proofs10.1. Proof of Section 3Proof of Lemma 1. In order to compute the maximum and minimum values of each component of the elements of thepolytope V EU( y, x), it is enough to consider its vertices since V EU( y, x) is a polytope [16]. First of all, the following set(cid:5)w ∈ W(EU): ∀i ∈ A−( y, x) ∪ A=(cid:6)is included in V EU( y, x). Hence, when | A[0, 1] interval.( y, x) w i = 0+( y, x)| > 1, the set admissible values of the weight w i , with i ∈ A+( y, x), is the(cid:2)For ε > 0, let U ε be the set of w ∈ Rn defined by n + 1 inequalities w 1 (cid:2) 0, . . . , wn (cid:2) 0 andk∈N (cid:3)k wk (cid:2) ε, and oneε>0 U ε . A point w ∈ U ε is a vertex of U ε if and only if n − 1 inequalities areequalityreplaced by the corresponding equalities [16, Theorem 18.1]. Let {i, j} ⊆ {1, . . . , n + 1} be the index of the two inequalitiesthat are not transformed into equalities.k∈N wk = 1. Then V EU( y, x) =(cid:16)The first case is when {i, j} ⊆ {1, . . . , n}. For ε small enough, one necessarily has i ∈ A+( y, x) and j ∈ A−( y, x). From the(cid:2)relations (cid:3)−+j w j = ε and w i + w j = 1, we obtaini w i − (cid:3)−+(cid:3)(cid:3)ji++ii+ ε−+ (cid:3)j− ε−+ (cid:3)jw j =(cid:3)(cid:3),w i =and ∀k ∈ N \ {i, j} wk = 0.The second case arises when j = n + 1. We obtain+i ∈ A( y, x),w i = 1 and ∀k ∈ N \ {i} wk = 0.Assume that A+( y, x) (cid:16)= ∅ and A−( y, x) (cid:16)= ∅. Hence w i ∈ [min j∈ A−( y,x), 1]for alli ∈ A+( y, x), and w j ∈(cid:3)−( y, x). The lemma is shown since this relations hold for all ε > 0. By construction, the[0, maxi∈ A+( y,x)boundaries of the intervals are reached so that the intervals are sharp. (cid:5)] for all j ∈ A+(cid:3)i+(cid:3)i−ε−+(cid:3)j−+ε(cid:3)j−++(cid:3)ji10.2. Proofs of Section 5Proof of Lemma 2. The only if part of the lemma is clear. Let us show the if part. Consider thus S ∈ Ex(x, y, v, F , ψNOA),and assume thus that (3) holds.When F = EU, we show in the proof of Proposition 1 that if (3) holds, then we have (vk − 1n )(cid:3)k > 0 for all k ∈ S. LetT ⊆ S with T (cid:16)= S. For k ∈ S \ T , we have from (13)H EU(v T ,w EUN\T )( y, x) = H EU(v S\{k},w EU(N\S)∪{k})( y, x) −(cid:12)(cid:17)i∈S\(T ∪{k})(cid:15)(cid:3)i.v i − 1nBy (3), H EU(v S\{k},wEU(N\S)∪{k})( y, x) (cid:3) 0. We conclude that H EU(v T ,wEUN\T )( y, x) < 0 and thus T /∈ Ex(x, y, v, EU, ψNOA). This proves thatthe coalitions satisfying (3) are necessary minimal in Ex(x, y, v, EU, ψNOA).The proof is similar when F = Maj, thanks to the relation (14) given below.Lastly, considerthe case when F = Pess. Let T ⊆ S with T (cid:16)= S. From (3), we have hPess(v S\{k},wMaj(N\S)∪{k})(x) (cid:2)( y) for all k ∈ S \ T . Lemma 7 (shown below) holds with the strict inequalities are replaced by non-stricthPess(v S\{k},wMaj(N\S)∪{k})inequalities. We obtain thus(cid:18)k∈S\TFor every z ∈ X ,hPess(v S\{k},w(x) (cid:2)Maj(N\S)∪{k})(cid:18)k∈S\ThPess(v S\{k},wMaj(N\S)∪{k})( y).C. Labreuche / Artificial Intelligence 175 (2011) 1410–14481435(cid:18)k∈S\ThPess(v S\{k},wMaj(N\S)∪{k})(z) ==(cid:18)(cid:9)i∈T(cid:18)(cid:9)(cid:10)zi ∨ (1 − v i)∧(cid:10)zi ∨ (1 − v i)∧i∈T= hPess(v T ,w(z).MajN\T )(cid:18)i /∈S(cid:18)i /∈Szi ∧zi ∧(cid:18)(cid:7)(cid:9)(cid:10)zk ∨ (1 − vk)∧ zk(cid:8)k∈S\T(cid:18)k∈S\TzkHence we conclude thathPess(v T ,wMajN\T )(x) (cid:2) hPess(v T ,w( y).MajN\T )This proves that T /∈ Ex(x, y, v, Pess, ψNOA). (cid:5)Proof of Proposition 1. Let S ∈ Ex(x, y, v, EU, ψNOA) be minimal, and k ∈ S. Clearly, (3) is satisfied. Hence H EU(v S ,wEUN\S )and H EU(v S\{k},wEU(N\S)∪{k})( y, x) (cid:3) 0, which gives H EU(v S ,wEUN\S )(cid:12)( y, x) − H EU(cid:15)(v S\{k},wEU(N\S)∪{k})H EU(v S ,w EUN\S )( y, x) − H EU(v S\{k},w EU(N\S)∪{k})( y, x) =vk − 1n(cid:3)k( y, x) > 0. From the relation( y, x) > 0(13)we can infer that (vk − 1n )(cid:3)k > 0. This concludes the proof. (cid:5)Proof of Proposition 2. The integer p as defined in Proposition 2 exists since N ∈ Ex(x, y, v, EU, ψNOA) and ∅ /∈ Ex(x, y, v,EU, ψNOA). We set S = {π (p), . . . , π (n)}. Let k ∈ S. We writevk − 1nvπ (p) − 1nsince π −1(k) (cid:2) p( y, x) = H EU(cid:3)k by (13)( y, x) −( y, x) −(v S\{k},w EU(cid:3) H EU(N\S)∪{k})(cid:3)π (p)(v S ,w EU(v S ,w EUH EUN\S )N\S )(cid:12)(cid:12)(cid:15)(cid:15)= H EU(v S\{π (p)},w EU(cid:12)(N\S)∪{π (p)})( y, x)+H EU(v S ,w EUN\S )( y, x) − H EU(v S\{π (p)},w EU(N\S)∪{π (p)})( y, x) −(cid:12)vπ (p) − 1n(cid:15)(cid:15)(cid:3)π (p)= H EU(v S\{π (p)},w EU(N\S)∪{π (p)})( y, x) by (13)(cid:3) 0since S \ {π (p)} /∈ Ex(x, y, v, EU, ψNOA). Hence S is minimal in Ex(x, y, v, EU, ψNOA).By (13), we have for every S ⊆ NH EU(v S ,w EUN\S )( y, x) = H EUw EU ( y, x) +(cid:12)(cid:17)k∈Svk − 1n(cid:15)(cid:3)k.k∈S (vk − 1By definition of p, it is clear that S is the set with the smallest cardinality for whichthere is no minimal element of Ex(x, y, v, EU, ψNOA) with a strictly lower cardinality than S. (cid:5)n )(cid:3)k > −H EUwEU ( y, x). Hence(cid:2)Proof of Proposition 3. Let S ∈ Ex(x, y, v, Maj, ψNOA) be minimal and k ∈ S. We haveH Maj(v S ,wMajN\S )( y, x) − H Maj(v S\{k},wMaj(N\S)∪{k})( y, x) =Hence the result is shown thanks to (3). (cid:5)(cid:12)(cid:15)vk − 1nsgnk .(14)Proof of Proposition 4. Thanks to (14), the proof is similar to that of Proposition 2. (cid:5)(cid:3)Proof of Proposition 5. Let S ∈ Ex(x, y, v, Pess, ψNOA) be minimal. Let k ∈ S. We set a =b =i /∈S xi . We obtain by (3)i∈S\{k}(xi ∨ (1 − v i)) ∧(cid:3)(cid:9)(cid:10)yk ∨ (1 − vk)a ∧a ∧ yk (cid:3) b ∧ xk.> b ∧(cid:9)(cid:10)xk ∨ (1 − vk),(cid:3)i∈S\{k}( yi ∨ (1 − v i)) ∧(cid:3)i /∈S yi and1436C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448We wish to infer inequality relations among a, b, xk, yk, 1 − vk for the previous two relations. It is possible to do it bya standard reasoning on the inequalities. However, it is tedious, lengthy and not always easy. We propose rather to makea systematic check of all possible cases of comparison between the variables a, b, xk, yk, 1 − vk. Since the previous tworelations contain only the min and max operators, their analysis does not depend on the numerical values of a, b, xk,yk, 1 − vk, but only on their relative ordering. Hence, this can be performed by a computer. As a result, we generate bycomputer all possible comparisons (lower, equal or greater) among the variables a, b, xk, yk, 1 − vk, and see whether theprevious two inequalities are satisfied. At the end, for every pair of variables, we analyse which comparisons between thesetwo variables are compatible with the two inequalities. Considering for instance the two variables a and b, the outcome iseither no relation between a and b, or one of the following comparisons: a < b, a (cid:3) b, a = b, a (cid:2) b or a > b. This approachhas been also used in the proof of Proposition 12. We obtain the following invariant comparisonsyk (cid:3) b < {a, 1 − vk} and yk (cid:3) xkwhere the notation b < {a, 1 − vk} means that b < a and b < 1 − vk.Hence k ∈ A−( y, x) ∪ A=( y, x). Applying this relation for all k ∈ S, we obtain S ⊆ A−( y, x) ∪ A=( y, x). Since yk < 1 − vk,k is a weak negative argument.We have two cases:(i) S is of cardinality 1: S = {k}. Thenyk ∨ (1 − vk) (cid:2) 1 − vk > b =(cid:18)(cid:18)yi = a > b =xi.i /∈Si /∈S(cid:18)i /∈Sxi,(ii) S is of cardinality at least 2. Since a > b, one has(cid:18)(cid:9)(cid:10)yi ∨ (1 − v i)∧i∈S\{k}(cid:18)i /∈S(cid:18)(cid:9)(cid:10)xi ∨ (1 − v i)∧yi >i∈S\{k}(cid:18)i /∈Sxi.Since yi (cid:3) xi for all i ∈ S, one has (see Lemma 7)(cid:18)(cid:9)(cid:10)yi ∨ (1 − v i)(cid:3)(cid:18)(cid:9)(cid:10)xi ∨ (1 − v i).i∈S\{k}i∈S\{k}Hence for all k ∈ S(cid:18)(cid:18)xi <yiandi /∈Si /∈S(cid:18)i /∈S(cid:18)(cid:9)(cid:10)yi ∨ (1 − v i).xi <i∈S\{k}This gives(cid:18)(cid:18)(cid:18)(cid:9)(cid:10)yi ∨ (1 − v i)=xi <i /∈Sk∈Si∈S\{k}(cid:10)yi ∨ (1 − v i).(cid:18)(cid:9)i∈SIn both cases, we have(cid:18)i /∈Sxi <(cid:18)i /∈Syiand(cid:18)i /∈Sxi <(cid:18)(cid:9)i∈S(cid:10)yi ∨ (1 − v i).(cid:5)Proof of Proposition 6. Assume that hPessvkx ) > xkx ∨ (1 − vkx ). We obtain a contradiction if ykx (cid:3) 1 − vkx . Hence ykx > 1 − vkx . Furthermore, ykx > xkx .(x) is attained at kx ∈ N. Since hPess(x), we have in particular ykx ∨ (1 −( y) > hPessvvvMoreover, for k ∈ M, we have yk ∨ (1 − vk) > xkx ∨ (1 − vkx ) and thus 1 − vk > xkx ∨ (1 − vkx ).Let S ∈ Ex(x, y, v, Pess, ψNOA) be minimal, and assume that S \ M (cid:16)= ∅. Let k ∈ S \ M. Then yk > hPesshPess(v S ,wPess(v S\{k},wPessN\S )minimal, by Proposition 5, hPess( y) = hPess(N\S)∪{k})( y) ∧ yk. Since S ∈ Ex(x, y, v, Pess, ψNOA), we have hPess(v S ,wPessN\S )(cid:3)i∈N\S xi . Hencei∈N\S xi , and yk > hPessPess,N\Sv( y) > hPess(x) = h(x) =(x) (cid:2)(cid:3)v(v S ,wPessN\S )v(x). We have(x). Since S ishPess(v S\{k},w Pess(N\S)∪{k})Since k ∈ A−( y, x) ∪ A(v S ,wPessN\S )(cid:18)( y) >xi.i∈N\S=( y, x), xk (cid:2) yk >(cid:3)i∈N\S xi , we have(cid:3)i∈N\S xi =(cid:3)i∈(N\S)∪{k} xi . ThereforeC. Labreuche / Artificial Intelligence 175 (2011) 1410–14481437hPess(v S\{k},w Pess(N\S)∪{k})( y) >(cid:18)i∈(N\S)∪{k}xi (cid:2) hPess(v S\{k},w Pess(N\S)∪{k})(x).Hence S \ {k} ∈ Ex(x, y, v, Pess, ψNOA), which contradicts the fact that S is minimal. We conclude that S ⊆ M. (cid:5)Proof of Proposition 7. By definition S := {π yEx(x, y, v, Pess, ψNOA). To show that S is minimal, we need to show that for every i ∈ {1, . . . , p − 2}, D := S \ {π yEx(x, y, v, Pess, ψNOA).(cid:3)N (p)} ∈ Ex(x, y, v, Pess, ψNOA) and {π y(cid:14) = D \ C . One has C /∈ Ex(x, y, v, Pess, ψNOA). Moreover,N (p − 1)} /∈N (i)} /∈N (1), . . . , π yN (1), . . . , π yN (1), . . . , π yN (i − 1)}, CLet i ∈ {1, . . . , p − 2}. Set C = {π yj∈N\C y j = yπ yN (i) and thus(cid:9)(cid:18)hPess(v C ,w PessN\C )( y) =(cid:10)y j ∨ (1 − v j)∧ yπ yN (i)j∈C(cid:18)(cid:9)j∈CandHencehPess(v D ,w PessN\D )( y) =(cid:10)y j ∨ (1 − v j)∧ yπ yN (i)∧(cid:10)y j ∨ (1 − v j).(cid:18)(cid:9)j∈C (cid:14)hPess(v C ,w PessN\C )( y) (cid:2) hPess(v D ,w PessN\D )( y).Furthermore for any option z, relation C ⊆ D implies the following inequalityhPess(v C ,w PessN\C )(z) (cid:3) hPess(v D ,w PessN\D )(z).Applying that to z = y, we conclude thathPess(v C ,w PessN\C )( y) = hPess(v D ,w PessN\D )( y).Since C /∈ Ex(x, y, v, Pess, ψNOA), and by (15) applied to x, we gethPess(v D ,w PessN\D )(x) (cid:2) hPess(v C ,w PessN\C )(cid:2) hPess(v C ,w PessN\C )(x)( y)= hPess(v D ,w PessN\D )( y).(15)Hence D /∈ Ex(x, y, v, Pess, ψNOA). This proves that {π yN (1), . . . , π yN (p)} is minimal in Ex(x, y, v, Pess, ψNOA). (cid:5)10.3. Proofs of Section 6Proof of Proposition 8. Let A ∈ Ex(x, y, v, F , ψIVT) be minimal in the sense of (cid:18). Let π ∈ Π(N) such that A ⊆ A(π ). Thenx (cid:3)F(π ◦vA,v N\A) y. Assume by contradiction that there exists S ∈ A with |S| = 1. The condition |S| = 1 implies that π (i) = ifor i ∈ S. Hence x (cid:3)F(π ◦vA\{S},v(N\A\{S}) y. This contradicts the minimality of A since A \ {S} (cid:4) A and A \ {S} ⊆ A(π ). (cid:5)Proof of Lemma 3. The proof is done by induction on s = |S|. Let H SwWhen s = 2, we have(cid:2):=i∈S w i(cid:3)i for w ∈ W(EU).H Sπ S ◦vπ S ◦v− H SS (1)(cid:3)π (cid:3)S (1)S (2) − vπ vHence the result is proved when s = 2.= (vπ v= (vπ vS (2)(cid:3)π (cid:3)+ vπ vS (1)) × ((cid:3)π (cid:3)S (2)) − (vπ v− (cid:3)π (cid:3)S (2)S (1)) (cid:2) 0.S (2)(cid:3)π (cid:3)S (1)+ vπ vS (1)(cid:3)π (cid:3)S (2))Assume that the result is shown for all subsets of cardinality strictly lower than s. Let S ⊆ N with |S| = s.Let π ∈ Π(S). Define σ = π ◦ (π S )−1, k = π (cid:3)S (s) and k(cid:14) = π vS (s) = π S (k). Value (cid:3)k is the largest number in the set(cid:14)), and(cid:14)) = k, σ (cid:14)(σ −1(k(cid:14))) = σ (k(cid:14){(cid:3)i: i ∈ S}, and vk(cid:14) is the largest number in the set {v i: i ∈ S}. Define σ (cid:14) ∈ Π(S) by σ (cid:14)(kσ (cid:14)(i) = σ (i) for all i ∈ S \ {k(cid:14))} (see Fig. 2). Set π (cid:14) = σ (cid:14) ◦ π S ∈ Π(S).(cid:14), σ −1(k1438C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448Fig. 2. Description of σ and σ (cid:14).Fig. 3. Description of π and π (cid:14).(cid:17)vσ ◦π S (i)(cid:3)i =(cid:17)i∈Si∈{1,...,s}(cid:14))). Hencevσ ◦π vS (i)(cid:3)π (cid:3)S (i).Let i1 = (π v(cid:14)) = s and i2 = (π vS )−1(σ −1(kOne has(cid:17)H Sπ ◦v=vπ (i)(cid:3)i =i∈SS )−1(k− H SH Sπ (cid:14)◦vπ ◦vS (i1)(cid:3)π (cid:3)= vσ (cid:14)◦π v+ vσ (cid:14)◦π v= (vk(cid:14) − vσ (k(cid:14))) × ((cid:3)k − (cid:3)π (cid:3)S (i1)S (i2)(cid:3)π (cid:3)S (i2)S (i2)) (cid:2) 0− vσ ◦π vS (i1)(cid:3)π (cid:3)S (i1)− vσ ◦π vS (i2)(cid:3)π (cid:3)S (i2)by definition of k and k(cid:14).Moreover, H Sinduction assumption, Hπ S ◦v and H SS\{k}π S ◦vπ (cid:14)◦v have the same value vk(cid:14) (cid:3)k on criterion k. Hence H Sπ S ◦v− H Sπ (cid:14)◦v= HS\{k}π S ◦v− HS\{k}π (cid:14)◦v . By the(cid:2) HS\{k}π (cid:14)◦v . Hence we have shown thatH Sπ S ◦v(cid:2) H Sπ (cid:14)◦v(cid:2) H Sπ ◦v .Similarly, one can show that H Sπ S ◦v(cid:3) H Sπ ◦v . Hence the induction assumption holds at s. (cid:5)Proof of Proposition 9. Let A ∈ Ex(x, y, v, EU, ψIVT) be minimal in the sense of (cid:18). Let π ∈ Π(N) such that x (cid:3)EUand A ⊆ A(π ). Since x (cid:3)EUv N\A) = π ◦ v.(π ◦vA,v N\A) y(π ◦vA,v N\A) y, one can choose π in such a way that for all i ∈ N \ A, π (i) = i. Hence (π ◦ vA,Let S ∈ A. By Proposition 8, we have |S| (cid:2) 2.Let k, j ∈ S with k (cid:16)= j. Let π (cid:14) ∈ Π(N) be defined by π (cid:14)( j) = π (k), π (cid:14)(k) = π ( j) and π (cid:14)(l) = π (l) for l ∈ N \ {k, j} (seeFig. 3).Clearly, A(π (cid:14)) (cid:4) A(π ). Let A(cid:14) = (A \ {S}) ∪ {Sare the cycles of π (cid:14)a minimal element, one shall have A(cid:14) /∈ Ex(x, y, v, EU, ψIVT). Hence, we have either y (cid:4)EUA = A(cid:14) and π (cid:14)(l) = l for all l ∈ N \ A = N \ A(cid:14), we have π (cid:14) ◦ v = (π (cid:14) ◦ vA(cid:14) , v N\A(cid:14) ). Hence in both case, we have y (cid:4)EUTo sum-up, we have(cid:14)(cid:14) = {k, π (cid:14)(k), π (cid:14) ◦ π (cid:14)(k), . . .}containing j and k respectively. One clearly has A(cid:14) (cid:4) A and A(cid:14) ⊆ A(π (cid:14)). Hence in order that A isN\A(cid:14) ) x. Sinceπ (cid:14)◦v x.(cid:14) = { j, π (cid:14)( j), π (cid:14) ◦ π (cid:14)( j), . . .} and Sπ (cid:14)◦v x or y (cid:4)EU(cid:14)(cid:14)} where S(π (cid:14)◦vA(cid:14) ,v(cid:14), Sx (cid:3)EUπ ◦v y and y (cid:4)EUπ (cid:14)◦v x.We obtain from (16)(16)0 < H EUπ (cid:14)◦v ( y, x) − H EUπ ◦v ( y, x) = (vπ ( j) − vπ (k)) × ((cid:3)k − (cid:3) j).Therefore (4) holds.From (4), (cid:3)π (cid:3)S (l)that vπ ◦π (cid:3)π ( j) = π S ( j) for all j ∈ S.S (l) > vπ ◦π (cid:3)S (l+1), for all l ∈ {1, . . . , |S| − 1}. Hence (cid:3)π (cid:3)(cid:16)= (cid:3)π (cid:3)S (l+1), for all l ∈ {1, . . . , |S| − 1}. Hence (5) holds. We have vπ vS (l) < (cid:3)π (cid:3)S (l+1). By (4), the previous relation impliesS (|S|). We conclude thatS (1) (cid:3) · · · (cid:3) vπ vFinally, the last inequality in the proposition follows from relation (5) and Lemma 3. (cid:5)C. Labreuche / Artificial Intelligence 175 (2011) 1410–14481439(cid:2)Proof of Proposition 10. Assume by contradiction that the algorithm ends without returning an explanation set. HenceB = ∅ at every step of the search. This implies that the search tree is never pruned (step “Bounding”) and thus all thesubsets of elements of S are explored in the search. This means that there does not exist A ∈ Ex composed of elements ofS such thatπ ◦v ( y, x) (cid:3) 0. This contradicts the(cid:2) H EUbasic assumption made at the beginning of Section 6.v ( y, x). Hence there does not exist π ∈ Π(N) such that H EUS∈A DEUSWhen the bounding condition is triggered in Algo-EU, we have A ∪ {T i} (cid:16)(cid:4)discri B. Since (cid:18)discri is a complete order, weconclude that B (cid:18)discri A ∪ {T i}. In the combinatorial structure Ex endowed with (cid:18)discri, the whole sub-tree under the nodeA ∪ {T i} in the search (in Algo(A, B, k) after iteration i) can indeed be pruned since the elements of Ex in the sub-tree areof the form A ∪ {T i1}, with m (cid:2) 1 and T i (cid:2)discri T i1 . By the relation} ∪ · · · ∪ {T imB (cid:18)discri A ∪ {T i} (cid:4)discri A ∪ {T i} ∪ {T i1} ∪ · · · ∪ {T im}one sees that there is no way a strictly better argumentation set in Ex can be found under the node A ∪ {T i}. We haveshown that the bounding condition is justified in the algorithm.Assume that the algorithm terminates and returns B. We define π ∈ Π(N) as π (i) = π S (i) for all i ∈ S and all S ∈ B,and π (i) = i for all i ∈ N \ B. We have(cid:17)π ◦v ( y, x) = H EUH EUv ( y, x) −DEUS(cid:3) 0.S∈BHence B ∈ Ex(x, y, v, EU, ψIVT). All the elements of Ex that are strictly better than B are explored by Algorithm Algo-EU atthe previous steps. Since the algorithm did not terminate earlier, this means that there is no C ∈ Ex(x, y, v, EU, ψIVT) withC (cid:4)discri B. Hence B is minimal in the sense of (cid:4)discri. The explanation set B is also minimal in the sense of (cid:4) since (cid:4)discriis a refinement of (cid:4). (cid:5)Proof of Proposition 11. The proof follows that of Proposition 9. In particular, from k, j ∈ S with k (cid:16)= j, we define π (cid:14). Hence0 < H Majπ (cid:14)◦v ( y, x) − H MajOne necessarily has sgnkmost one element of S in each of the three sets Aand vπ ( j) in the statement of the proposition follow from the previous inequality. (cid:5)π ◦v ( y, x) = (vπ ( j) − vπ (k)) × (sgnk(cid:16)= sgn j . Hence k and j cannot belong to the same set A+( y, x), A=( y, x) or A− sgn j).−( y, x). There is at=( y, x) or A−( y, x). Hence |S| (cid:3) 3. The relations between vπ (k)+( y, x), AProof of Proposition 12. We proceed as in the proof of Proposition 9. In particular, from k, j ∈ S with k (cid:16)= j, we define π (cid:14)Let.a := hPess,N\{ j,k}π ◦v( y) and b := hPess,N\{ j,k}π ◦v(x).Proceeding as in the proof of Proposition 9, we obtain the relations y (cid:4)Pess(cid:9)(cid:9)π (cid:14)◦v x and y (cid:27)Pessπ ◦v x (see (16)). Henceα1 := a ∧> b ∧α2 := a ∧(cid:3) b ∧(cid:10)y j ∨ (1 − vπ (k))(cid:10)x j ∨ (1 − vπ (k))(cid:10)y j ∨ (1 − vπ ( j))(cid:10)x j ∨ (1 − vπ ( j))(cid:9)(cid:9)(cid:9)∧∧∧∧(cid:9)(cid:10)yk ∨ (1 − vπ ( j))(cid:10)=: β1,xk ∨ (1 − vπ ( j))(cid:10)(cid:9)yk ∨ (1 − vπ (k))(cid:10)xk ∨ (1 − vπ (k))=: β2.(cid:9)We are interested only to the case where k ∈ A+( y, x) ∪ A=( y, x) and j ∈ A−( y, x). We have two cases.The first case is when 1 − vπ (k) > 1 − vπ ( j). The larger weight among vπ (k) and vπ ( j) is assigned to the negativeargument, and the smaller one is assigned to the positive argument.The second case is when 1 − vπ (k) (cid:3) 1 − vπ ( j). We proceed exactly as in the proof of Proposition 5. We perform a sys-tematic check of all possible cases of comparison between the variables {a, b, xk, x j, yk, y j, 1 − vπ ( j), 1 − vπ (k)} to determinewhether some comparisons between some of these variables always hold. We obtainPess,N\{ j,k}xk (cid:3) yk (cid:3) hπ ◦v1 − vπ (k) (cid:3) hPess,N\{ j,k}π ◦v(x),(x),hhPess,N\{ j,k}π ◦vPess,N\{ j,k}π ◦vPess,N\{ j,k}π ◦v(x) < y j < x j,Pess,N\{ j,k}(x) < hπ ◦v(x) < 1 − vπ ( j).( y),Let K S and J S be the sets of the indices k and j respectively, satisfying (17). Let us show that(cid:14), jby contradiction that there exist two pairs (k, j) and (kand (k(cid:14) ∈ N \ { j, k}, we obtain hkyk(cid:14) ∨ (1 − vπ (k(cid:14))) < h(cid:14)) ∈ K S(cid:14) × J S(cid:14) (with S, SPess,N\{ j,k}π ◦v(cid:14),kPess,N\{ jπ ◦v(cid:14)}( y) (cid:3) yk ∨ (1 − vπ (k)). Hence a contradiction is raised.h(17)S∈A |K S | (cid:3) 1. Assume−( y, x) with (k, j) ∈ K S × J S(cid:14)) in ( APess,N\{ j,k}(cid:14) ∈ A) satisfying (17), with k (cid:16)= k(cid:14)( y). Sinceπ ◦v( y) (cid:3) yk(cid:14) ∨ (1 − vπ (k(cid:14))) and thus yk ∨ (1 − vπ (k)) < yk(cid:14) ∨ (1 − vπ (k(cid:14))). Similarly, we have+( y, x) ∪ A=( y, x)) × A. From (17), yk ∨ (1 − vπ (k)) < h(cid:14), j(cid:2)1440C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448We assume that K S (cid:16)= ∅. We set K S = {k}. Assume that S = N. Assume by contradiction that J S = N \ {k}. Let j ∈ J S suchPess, J S \{ j}(x) = xi ∨ (1 − vπ (i)). From (17) applied on the pairπ ◦vPess, J Sπ ◦vthat h(k, j), we have xi ∨ (1 − vπ (i)) = h(x) = x j ∨ (1 − vπ ( j)). Let i ∈ J S \ { j} such that hPess,N\{k, j}π ◦v(x) < 1 − vπ ( j) and thus1 − vπ (i) < 1 − vπ ( j).From (17) applied on the pair (k, i), we have x j ∨ (1 − vπ ( j)) = hPess,N\{k,i}π ◦v(x) < 1 − vπ (i) and thus1 − vπ ( j) < 1 − vπ (i).The previous two relations are clearly contradictory. Hence J S (cid:16)= N \ {k}.Pess,N\{k}Using previous argument, one can easily show in all cases that hπ ◦v(x) = xi ∨ (1 − vπ (i)) for some i ∈ N \ ( J S ∪ {k}).HencePess,N\{k}π ◦vh(x) = hPess,N\( J S ∪{k})π ◦v(x).−( y, x), or if i ∈ K S and j ∈Let S ∈ A. To sum-up, we have vπ ( j) > vπ (i) if i ∈ ( A−( y, x) \ J S . Moreover, vπ ( j) (cid:3) vπ (i) if i ∈ K S and j ∈ J S . The weights assigned to the positive arguments are the smallestAones, except for criterion K S :=( y, x)) \ K S and j ∈ A+( y, x) ∪ A(cid:5)vπ (i): i ∈(cid:9)−A( y, x) ∩ S(cid:10)(cid:6)\ J S> {vπ (k): k ∈ K S } (cid:2) {vπ ( j): j ∈ J S }(cid:10)+>( y, x)A( y, x) ∪ Avπ (i): i ∈(cid:9)(cid:9)(cid:5)=(cid:10)∩ S(cid:6).\ K S(cid:5)10.4. Proofs of Section 7Proof of Lemma 5. Clearly, for every z ∈ [0, 1]n1n!(cid:17)π ∈Π (N)π ◦v (z) =hEU(cid:12)n(cid:17)i=11n(cid:17)k∈N(cid:15)vkzi =n(cid:17)i=11nzi = hEUw EU (z).(cid:5)Proof of Proposition 13. By definition of π N , for all permutations π ∈ Π(N),π N ◦v ( y, x) (cid:3) H EUH EUπ ◦v ( y, x).Hence from Lemma 5, H EUproved.wEU ( y, x) (cid:2) 1n!(cid:2)π ∈Π(N) H EUπ N ◦v ( y, x) = H EUπ N ◦v ( y, x). Consequently, the first part of the lemma is(18)The if part of the second part of the lemma is obvious. Let us show the only if part. Assume thus that H EUwEU ( y, x). From (18) and Lemma 5, the previous relation implies for every permutation π , H EUπ N ◦v ( y, x) = H EUπ N ◦v ( y, x) =π ◦v ( y, x). ThusH EUfor every permutation π ∈ Π(N),H EUv ( y, x) = H EUπ ◦v ( y, x).Let i (cid:16)= j in N, and π ∈ Π(N) the permutation permuting i and j and leaving the other elements of N. Previous relationapplied on π gives v i(cid:3)i + v j(cid:3) j = v j(cid:3)i + v i(cid:3) j . Hence(v i − v j) × ((cid:3)i − (cid:3) j) = 0.(19)Assume that (7) holds. Let k ∈ N, and Ak = {i ∈ N, (cid:3)i = (cid:3)k}. Thus N \ Ak (cid:16)= ∅. For all i ∈ Ak and j ∈ N \ Ak, one has (cid:3)i (cid:16)= (cid:3) jand thus v i = v j by (19). We conclude that all v i have the same value. Since the weights are normalized, we obtained thewished result. (cid:5)Proof of Proposition 14. LetHEU1:=infx∈Rn, y∈Rn, v∈Rn+: v1+···+vn=1w EU ( y, x) − minπ ∈Π (N) H EUH EUmaxπ ∈Π (N) H EUπ ◦v ( y, x)π ◦v ( y, x) − minπ ∈Π (N) H EUπ ◦v ( y, x).Since H EUv ( y, x) = hEUv ((cid:3)), we obtainHEU1=(cid:3)∈Rn, v∈Rninf+: v1+···+vn=1Let (cid:3) ∈ Rn, andw EU ((cid:3)) − minπ ∈Π (N) hEUhEUmaxπ ∈Π (N) hEUπ ◦v ((cid:3))π ◦v ((cid:3)) − minπ ∈Π (N) hEUπ ◦v ((cid:3)).C. Labreuche / Artificial Intelligence 175 (2011) 1410–14481441α =1maxπ ∈Π (N) hEUπ ◦v ((cid:3)) − minπ ∈Π (N) hEUπ ◦v ((cid:3)),β = −α mini∈N(cid:3)i.Let (cid:3)(cid:14) := α(cid:3)+β. By definition of β, (cid:3)(cid:14) ∈ Rnπ ◦v ((cid:3)(cid:14)) − minπ ∈Π(N) hEUβ) [31], maxπ ∈Π(N) hEU+. Since hEUπ ◦v ((cid:3)(cid:14)) = 1. Hencew is stable under affine transformations (i.e. hEUw (α(cid:3)+β) = αhEUw ((cid:3))+HEU1=inf(cid:3)∈Rn+, v∈Rn+: v1+···+vn=1, maxπ ∈Π(N) hEUπ ◦v ((cid:3))−minπ ∈Π(N) hEUπ ◦v ((cid:3))=1(cid:19)w EU ((cid:3)) − minhEUπ ∈Π (N)(cid:20)hEUπ ◦v ((cid:3)).Without loss of generality, one can assume thatv 1 (cid:3) · · · (cid:3) vn,(cid:3)1 (cid:3) · · · (cid:3) (cid:3)n.Then by Lemma 3minπ ∈Π (N)π ◦v ((cid:3)) =hEUmaxπ ∈Π (N)π ◦v ((cid:3)) =hEUn(cid:17)i=1n(cid:17)i=1vn−i+1(cid:3)i,v i(cid:3)iandHEU1=(cid:3)∈Rn+, v∈Rn+: v1(cid:3)···(cid:3)vn, (cid:3)1(cid:3)···(cid:3)(cid:3)n, v1+···+vn=1,inf(cid:2)ni=1(v i −vn−i+1)(cid:3)i =1(cid:15)− vn−i+1(cid:3)i.(cid:12)n(cid:17)i=11nFrom Assertions 1 and 2 below, HEU1= 1n .Assertion 1. For v ∈ W(EU) \ {w EU} such that v 1 (cid:3) · · · (cid:3) vn,(cid:3)∈Rn+: (cid:3)1(cid:3)···(cid:3)(cid:3)n,i=1(v i −vn−i+1)(cid:3)i =1inf(cid:2)ni=1(cid:12)n(cid:17)1n(cid:15)− vn−i+1(cid:3)i = mink∈{2,...,n}(cid:2)n(cid:2)nn− vn−i+1)i=k( 1i=k(v i − vn−i+1)where the numerator and the denominator are positive.Proof. Let(cid:21)U =(cid:3) ∈ Rn, 0 (cid:3) (cid:3)1, (cid:3)1 (cid:3) (cid:3)2, . . . , (cid:3)n−1 (cid:3) (cid:3)n andn(cid:17)(v i − vn−i+1)(cid:3)i = 1(cid:22).i=1From [16, Theorem 18.1], (cid:3) is a vertex of U iff n − 1 inequalities among the n inequalities of U are transformed intoequalities. Let k ∈ {1, . . . , n} be the index of the inequality that is not transformed into an equality. One cannot have k = 1sincei=1(v i − vn−i+1) = 0. Hence k ∈ {2, . . . , n}. Then 0 = (cid:3)1 = · · · = (cid:3)k−1 < (cid:3)k = · · · = (cid:3)n =: αk. One has(cid:2)nn(cid:17)(v i − vn−i+1)(cid:3)i = αk1 =i=1n(cid:17)(v i − vn−i+1).i=kFrom the normalization condition, we obtainαk =1i=k(v i − vn−i+1)Hence the relation of the assertion is proved.(cid:2)n.We havew EU ((cid:3)) − minhEUπ ∈Π (N)π ◦v ((cid:3)) =hEU(cid:15)− vn−i+1,(cid:12)n(cid:17)i=k1nmaxπ ∈Π (N)π ◦v ((cid:3)) − minhEUπ ∈Π (N)π ◦v ((cid:3)) =hEUn(cid:17)(v i − vn−i+1)i=kwhere (cid:3) is defined above. The signs of numerator and denominator follow from Proposition 13. (cid:5)1442C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448Assertion 2.infv∈W(EU)\{w EU}: v1(cid:3)···(cid:3)vnmink∈{2,...,n}(cid:2)n(cid:2)nn− vn−i+1)i=k( 1i=k(v i − vn−i+1)= 1n.Proof. Let HEU2 be the left hand side in the expression of the lemma. ThenHEU2=v∈Rn+: v1(cid:3)···(cid:3)vn, v1+···+vn=1infmink∈{2,...,n}(cid:2)(cid:2)ni=k( 1n(cid:2)nj∈N v j − vn−i+1).i=k(v i − vn−i+1)We notice that the ratio is homogeneous in v in the previous relation. Hence constraint v 1 + · · · + vn = 1 can be removed:HEU2=infv∈Rn+: v1(cid:3)···(cid:3)vnmink∈{2,...,n}(cid:2)(cid:2)ni=k( 1n(cid:2)nj∈N v j − vn−i+1).i=k(v i − vn−i+1)We are interested in v different from the arithmetic mean. From Lemma 1 the denominator is strictly positive in this case.Hence one can arbitrarily set it to value 1:v∈Rn+: v1(cid:3)···(cid:3)vn,i=k(v i −vn−i+1)=1inf(cid:2)n(cid:12)n(cid:17)mink∈{2,...,n}i=k1n(cid:17)j∈N(cid:15)v j − vn−i+1.HEU2=One hasn(cid:17)(v i − vn−i+1) =n(cid:17)(v i − vn−i+1)i=k(cid:14) = max(k, n − k + 1).i=k(cid:14)(cid:21)with kLetU =v ∈ Rn, 0 (cid:3) v 1, v 1 (cid:3) v 2, . . . , vn−1 (cid:3) vn andn(cid:17)(cid:22)(v i − vn−i+1) = 1.i=k(cid:14)From [16, Theorem 18.1], v is a vertex of U iff n − 1 inequalities of U are transformed into equalities. Let p ∈ {1, . . . , n} bethe index of the inequality that is not transformed into an equality. One cannot have p = 1 since, otherwise, the equalityconstraint in U would not be satisfied. Hence p ∈ {2, . . . , n}. Then 0 = v 1 = · · · = v p−1 < v p = · · · = vn =: αp . One has(cid:12)n(cid:17)i=k1n(cid:17)j∈N(cid:15)v j − vn−i+1=(cid:12)n−k+1(cid:17)i=1n − p + 1n(cid:15)αp − v i=: F .There are two cases:• p (cid:2) n − k + 1. Hence the functional F isF = (n − p + 1)(n − k + 1)αpnwheren(cid:17)(v i − vn−i+1) =1 =i=k(cid:14)n(cid:17)i=k(cid:14)(cid:9)n − max(cid:9)(cid:10)(cid:14)(cid:10)+ 1p, kv i =× αp.Hence F is always greater or equal to 1n . The minimal value 1n is attained for p = k = n.• p < n − k + 1. The functional F isF = (n − p + 1)(n − k + 1)n(cid:7)αp −(n − k + 1) − p + 1(cid:8)αpwithn(cid:17)(v i − vn−i+1) =1 =(cid:9)n − k(cid:14) + 1(cid:10)αp −(cid:7)(cid:9)n − k(cid:14) + 1(cid:10)(cid:8)αp = pαp.− pi=k(cid:14)Hence the functional isC. Labreuche / Artificial Intelligence 175 (2011) 1410–14481443F = pn(cid:7)(cid:8)(n − p + 1)(n − k + 1) − n(n − k − p + 2)(cid:7)(p − 1)k + 1(cid:8)= pn(cid:2) 1n.The minimal value is 1n . (cid:5)The proof of Proposition 14 is now completed. (cid:5)Proof of Proposition 15. Let λEU := H EUπ N ◦v ( y, x) − H EUπ N ◦v ( y, x). For every π , π (cid:14) ∈ Π(N)(cid:11)(cid:11)H EUπ ◦v ( y, x) − H EU(cid:11)(cid:11) (cid:3) λEU.π (cid:14)◦v ( y, x)(20)Let i(cid:8), i(cid:8), j(cid:8), j(cid:8) ∈ N such that mini∈N (cid:3)i = (cid:3)i(cid:8) , maxi∈N (cid:3)i = (cid:3)i(cid:8) , min j∈N v j = v j(cid:8) and max j∈N v j = v j(cid:8) . Define π , π (cid:14) ∈ Π(N)such that π (i(cid:8)) = j(cid:8), π (i(cid:8)) = j(cid:8), π (cid:14)(i(cid:8)) = j(cid:8), π (cid:14)(i(cid:8)) = j(cid:8) and π (i) = π (cid:14)(i) for all i ∈ N \ {i(cid:8), i(cid:8)}. From (20), we obtain(cid:11)(cid:11)(cid:11)(v j(cid:8) (cid:3)i(cid:8) + v j(cid:8) (cid:3)i(cid:8) ) − (v j(cid:8) (cid:3)i(cid:8) + v j(cid:8) (cid:3)i(cid:8) )(cid:11) (cid:3) λEU.Hence|v j(cid:8) − v j(cid:8)||(cid:3)i(cid:8) − (cid:3)i(cid:8)| (cid:3) λEU.By the definition of i(cid:8) and i(cid:8), (cid:3)i(cid:8) − (cid:3)i(cid:8)= δ. This proves that|v j(cid:8) − v j(cid:8)| (cid:3) λEUδ.By the definition of j(cid:8) and j(cid:8), we have for all i, j ∈ N|v i − v j| (cid:3) |v j(cid:8) − v j(cid:8)| (cid:3) λEUδ.Finally for any i ∈ N(cid:11)(cid:11)(cid:11)v i − 1(cid:11)n(cid:11)(cid:11)(cid:11)v i − 1(cid:11)n(cid:11)(cid:11)(cid:11)(cid:11) =(cid:11)(cid:11)(cid:11) = 1(cid:11)n(cid:11)(cid:11)(cid:11)(cid:11)v j(cid:17)j∈N(cid:17)(cid:11)(cid:11)(cid:11)(v j − v i)j∈N\{i}(cid:11) (cid:3) n − 1nλEUδ.By Proposition 14, λEU (cid:3) nχ EU. Hence the two inequalities in Proposition 15 are proved. These inequalities are reached withx = (0, . . . , 0), y = (0, . . . , 0, 1), v = (0, . . . , 0, 1) since we obtain ν = n−1n , δ = 1, λEU = 1 and χ EU = 1n . (cid:5)Proof of Lemma 6. One has(cid:17)(cid:17)H Majπ ◦v ( y, x) =1n!π ∈Π (N)i∈ A+( y,x)(cid:17)i∈ A+( y,x)=π ∈Π (N)(cid:17)−i∈ A−( y,x)1n(cid:17)vπ (i) −(cid:17)i∈ A−( y,x)1n!(cid:17)π ∈Π (N)vπ (i)= HMajw Maj ( y, x).(cid:5)1n!1nProof of Proposition 16. For all π ∈ Π(N), H MajwMaj ( y, x) (cid:2) H MajThe if part of the second part of the lemma is obvious. Let us show the only if part. Assume thus that HH MajwMaj ( y, x). Then for all π ∈ Π(N), H Majj and leaving the other criteria. We haveπ N ◦v ( y, x) =( y, x). Let i (cid:16)= j in N, and let π be the permutation permuting i andπ N ◦v ( y, x). Hence, by Lemma 6, H Majπ ◦v ( y, x) (cid:2) H Majπ ◦v ( y, x) (cid:2) H Majπ N ◦v ( y, x).Majvπ ◦v ( y, x)=( y, x) − H MajH Majv⎧⎪⎪⎪⎨⎪⎪⎪⎩02(v i − v j)2(v j − v i)v i − v jv j − v i+( y, x) ∪ A−( y, x) (cid:16)= ∅. If ABy (8), AHence v i = v j for all i, j ∈ N. Now if AHence v i = v j for all i, j ∈ N. (cid:5)+( y, x) or i, j ∈ A−( y, x) or i, j ∈ A=( y, x),if i, j ∈ Aif i ∈ Aif i ∈ Aif [i ∈ Aif [i ∈ A+( y, x), j ∈ A−( y, x), j ∈ A+( y, x), j ∈ A=( y, x), j ∈ A−( y, x),+( y, x),=( y, x)] or [i ∈ A+( y, x)] or [i ∈ A=( y, x), j ∈ A−( y, x), j ∈ A−( y, x)],=( y, x)].+( y, x) (cid:16)= ∅, then we obtain v i = v j for all i ∈ A−( y, x) (cid:16)= ∅, then we obtain v i = v j for all i ∈ A+( y, x) and all j ∈ A−( y, x) and all j ∈ A−( y, x) ∪ A+( y, x) ∪ A=( y, x).=( y, x).1444C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448Proof of Proposition 17. We want to have a lower bound ofHMaj := minx, y: (8)minv∈W(Maj)\w MajOne has thatHMajw Maj ( y, x) − minπ ∈Π (N) Hmaxπ ∈Π (N) HMajπ ◦v ( y, x) − minπ ∈Π (N) HMajπ ◦v ( y, x)Majπ ◦v ( y, x).maxx, y: (8)maxv∈W(Maj)\w Majmaxπ ∈Π (N)HMajπ ◦v ( y, x) = 1,minx, y: (8)minv∈W(Maj)\w Majminπ ∈Π (N)H Majπ ◦v ( y, x) = −1are attained with v 1 = 1 and v i = 0 for i (cid:16)= 1, and Arelation). Hence+( y, x) = {1} (for the first relation) and A−( y, x) = {1} (for the second(cid:19)maxx, y: (8)maxv∈W(Maj)\w Majmaxπ ∈Π (N)H Majπ ◦v ( y, x) − minπ ∈Π (N)(cid:20)π ◦v ( y, x)H Maj(cid:3) 2,andHMaj (cid:2) 12minx, y: (8)Setting L v ( A+, A−) =minv∈W(Maj)\w Maj(cid:2)(cid:2)i∈ A+ v i −(cid:19)HMajw Maj ( y, x) − minπ ∈Π (N)H(cid:20)Majπ ◦v ( y, x).HMaj (cid:2) 12min( A+, A−)∈Q(N): (8)minv∈W(Maj)\w MajL w Maj(cid:9)+A, A(cid:10)−− minπ ∈Π (N)Lπ ◦v(cid:10)(cid:20)(cid:9)+A, A−i∈ A− v i , we have(cid:19)where Q(N) = {( A+, A−) ∈ 2N × 2N : A+ ∩ A− = ∅}. Without loss of generality, one can assume thatv 1 (cid:3) · · · (cid:3) vn,+ = {1, . . . , p} and AA− = {q, . . . , n}where p < q are in {0, . . . , n + 1}. Then the following two relations hold(cid:10)(cid:9)+AL w Maj−, A(cid:9)minπ ∈Π (N)Lπ ◦vA= p − (n − q + 1)n,(cid:10)−+, A= (v 1 + · · · + v p) − (vq + · · · + vn).Condition (8) becomesp < q,p < n,q > 1 and [p (cid:2) 1 or q (cid:3) n].(21)HenceHMaj (cid:2) 12minp,q: (21)minv∈W(Maj)\w Maj: v1(cid:3)···(cid:3)vnFwhere F := p−(n−q+1)n− [(v 1 + · · · + v p) − (vq + · · · + vn)]. We writeHMaj (cid:2) 12minp,q: (21)minv: 0(cid:3)v1(cid:3)···(cid:3)vn and v1+···+vn=1F .Proceeding exactly as in the proof of Proposition 14, the minimum is necessarily attained on a vertex of the polytope(cid:21)U =v ∈ Rn, 0 (cid:3) v 1 (cid:3) · · · (cid:3) vn and(cid:22)v i = 1.n(cid:17)i=1A vector v ∈ U is a vertex of U iff there exists r ∈ {1, . . . , n} such thatv 1 = · · · = vr−1 = 0,vr = · · · = vn =: α.Since v is normalized, one has α = 1n−r+1 . One has r (cid:2) 2 since v is different from w Maj. One hasC. Labreuche / Artificial Intelligence 175 (2011) 1410–14481445(cid:27)(cid:27)v 1 + · · · + v p =vq + · · · + vn =if p < r,0(p − r + 1)α if p (cid:2) r,(n − q + 1)α if q (cid:2) r,(n − r + 1)α if q < r.We have the following cases:1. p < r, q (cid:2) r. We haveF = p − (n − q + 1)n+ n − q + 1n − r + 1= pn+ (n − q + 1)(r − 1)n(n − r + 1)(cid:2)1n(n − 1)for p = 0, r = 2 and q = n.2. p < r, q < r. We haveF = p − (n − q + 1)n+ n − r + 1n − r + 1= p + q − 1n(cid:2) 1n.3. p (cid:2) r, q (cid:2) r. We haveF = p − (n − q + 1)n− (p − r + 1) − (n − q + 1)n − r + 1= (r − 1)(n − p − q + 2)n − r + 1(cid:2) 1n.4. p (cid:2) r, q < r. This situation is impossible since q > r.(cid:2) θ :=12n(n − 1).Majπ ◦v ( y, x)We have shown thatχ Majmaxπ ∈Π (N) HThen |HMajπ ◦v ( y, x) − HMajπ ◦v ( y, x) − minπ ∈Π (N) Hπ (cid:14)◦v ( y, x)| (cid:3) χ MajMajθtion 15. If i, j are not in the same set among Aall i, j ∈ N, |v i − v j| (cid:3) 2χ Maj(cid:11)(cid:11)(cid:11) = 1(cid:11)n. Therefore(cid:11)(cid:11)(cid:11)(v j − v i)(cid:11)(cid:11)(cid:11)v i − 1(cid:11)n(cid:11) (cid:3) n − 1(cid:11)(cid:17)(cid:11)(cid:11)(cid:11)2χ Majθnθj(cid:16)=i(cid:3) 2χ Majθ.(cid:5)for every π , π (cid:14) ∈ Π(N). Let i, j ∈ N. Define π and π (cid:14)as in the proof of Proposi-+( y, x), A−( y, x) and A=( y, x), then we obtain |v i − v j| (cid:3) χ Majθ. Hence forFor the proof of Proposition 18, we need the following result.Lemma 7. Let p ∈ N and a, b ∈ Rp . If ai > bi for all i ∈ {1, . . . , p}, thenp(cid:18)i=1p(cid:18)ai >bi.i=1Proof. By associativity of the operator ∧, it is enough to prove the lemma for p = 2. One has then a1 > b1 (cid:2) b1 ∧ b2 anda2 > b2 (cid:2) b1 ∧ b2. Hence a1 ∧ a2 > b1 ∧ b2, which proves the result. (cid:5)Proof of Proposition 18. One has for any π ∈ Π(N)(cid:10)yi ∨ (1 − vπ (i))>n(cid:18)(cid:9)i=1(cid:10)xi ∨ (1 − vπ (i)).n(cid:18)(cid:9)i=1By Lemma 7,(cid:18)(cid:28)n(cid:18)(cid:9)(cid:10)yi ∨ (1 − vπ (i))(cid:29)>(cid:18)(cid:28)n(cid:18)(cid:9)(cid:10)xi ∨ (1 − vπ (i))(cid:29).π ∈Π (N)i=1π ∈Π (N)i=1Hence(cid:14) (cid:18)n(cid:18)(cid:9)(cid:10)yi ∨ (1 − vπ (i))(cid:13)(cid:14) (cid:18)n(cid:18)>(cid:9)(cid:10)xi ∨ (1 − vπ (i))(cid:13)i=1π ∈Π (N)i=1π ∈Π (N)1446andC. Labreuche / Artificial Intelligence 175 (2011) 1410–1448(cid:28)n(cid:18)n(cid:18)(cid:9)i=1j=1(cid:10)yi ∨ (1 − v j)(cid:29)(cid:28)n(cid:18)n(cid:18)(cid:9)>i=1j=1(cid:10)yi ∨ (1 − v j)(cid:29).Since there exists k such that vk = 1, one has(cid:10)yi ∨ (1 − v j)= yi.n(cid:18)(cid:9)j=1This givesn(cid:18)i=1n(cid:18)yi >xi.i=1(cid:5)Proof of Proposition 19. Let t ∈ E with t > e. The cardinality of the set E is 2| Aelements of E \ {1} greater than or equal to t. Hence(cid:11)(cid:11){i ∈ N: 1 − v i (cid:2) t}α ∈ E \ {1}: α (cid:2) t( y, x): xi (cid:2) t(cid:6)(cid:11)(cid:11) +(cid:11)(cid:11) =i ∈ A(cid:11)(cid:5)(cid:11)(cid:11)(cid:5)(cid:11)+(cid:6)(cid:11)(cid:11) <(cid:11)(cid:11) A+(cid:11)(cid:11).( y, x)+( y, x)| + 1. There are at most | A+( y, x)| − 1Therefore there does not exist π ∈ Π(N) such that+( y,x)Pess, Aπ ◦vh(x) (cid:2) t.Hence (9) holds.Only if part of the proposition: We assume that H Pess=( y,x)By the definition of A(x) and h−( y,x)Pess, Aπ ◦vPess, Ahπ ◦vπ ◦v ( y) (cid:3) hhPessPess, Aπ ◦v( y) ∧ h=( y, x) and A+( y, x), A−( y,x)( y) (cid:3) h=( y,x)−( y,x)Pess, Aπ ◦v( y) (cid:3) hPessPess, Aπ ◦vπ ◦v ( y, x) > 0 for every π ∈ Π(N).−( y, x), we have h+( y,x)Pess, Aπ ◦v(x). If we assume that hPessπ ◦v (x) = h( y) (cid:2) hPess, Aπ ◦vPess, Aπ ◦v−( y,x)+( y,x)(x), h(x) ∧ hPess, Aπ ◦vPess, Aπ ◦v=( y,x)=( y,x)( y) =(x), thenπ ◦v (x), which contradicts H Pessπ ◦v ( y, x) > 0. Henceπ ◦v (x) = hhPesshPessπ ◦v (x) < hPess, Aπ ◦vPess, Aπ ◦v+( y,x)−( y,x)(x),(x) ∧ hPess, Aπ ◦v=( y,x)(x).+( y,x)Pess, Aπ ◦v( y) = hPess, Aπ ◦v+( y,x)(x), then H Pessπ ◦v ( y, x) (cid:3) 0 and a contradiction is raised.Hence (iii) holds. If we assume that hHence (i) holds.Let L(cid:14) := {i ∈ A−( y, x) ∪ Asuch that vm = 1. Consider then π (cid:8)2+( y, x). In the permutation π (cid:8)i ∈ Aprecisely, for every i ∈ A=( y, x): yi (cid:3) e}. Assume by contradiction that L(cid:14) (cid:16)= ∅. Since v is normalized, there exists m ∈ NA+( y,x))−1(i) for all2 , the largest values of 1 − v are assigned to the smallest values of x and vice versa. More2 (k) = m for some k ∈ L∈ Π(N) such that π (cid:8)2 (i) = π v, and π (cid:8)◦ (π xN(cid:14)+( y, x), either xi (cid:2) e or 1 − vπ (cid:8)2 (i) (cid:2) e. Hencemaxπ ∈Π (N)+( y,x)Pess, Aπ ◦vh(x) = hPess, A◦vπ (cid:8)2+( y,x)(x) = e.Since π (cid:8)2 (k) = m for some k ∈ L(cid:14), we have−( y,x)hPess, A◦vπ (cid:8)2( y) ∧ hPess, A◦vπ (cid:8)2=( y,x)( y) (cid:3) e = h+( y,x)Pess, A◦vπ (cid:8)2(x) = hPessπ (cid:8)2◦v (x).This contradicts H Pessπ (cid:8)2◦v ( y, x) > 0. Hence L(cid:14) = ∅.If part of the proof: Assume that (i), (ii) and (iii) hold. Let π ∈ Π(N). Then hπ ◦v (x) (by (9) and (iii)). By (ii), h(x) = hPess( y) ∧ hPess, Aπ ◦vPess, Aπ ◦vPess, Aπ ◦v+( y,x)−( y,x)and e (cid:2) h+( y,x)Pess, Aπ ◦v=( y,x)( y) > h( y) > e. Hence hPessPess, Aπ ◦v+( y,x)(x) = hPessπ ◦v (x)π ◦v (x). (cid:5)π ◦v ( y) > hPessProof of Proposition 20. Assume that either V i+ = ∅ or (10) holds. Let π ∈ Π(N). When π (i+( y,x)Pess, Ahπ ◦v(x) since yi+ > xi+ and yi+ > 1 − vπ (i+).( y) = yi+ > xi+ ∨ (1 − vπ (i+)) (cid:2) h+( y,x)Pess, Aπ ◦v+) ∈ V i+ (hence V i+ (cid:16)= ∅). Then, by (10),Suppose now that π (i(cid:5)Lπ :=+j ∈ A( y, x): x j < 1 − vk+ and 1 − vπ ( j) < yi+(cid:6)(cid:16)= ∅.+) /∈ V i+ , we haveFor all j ∈ Lπ , 1− vπ ( j) < yi+ (cid:3) y j and thus y j ∨(1− vπ ( j)) = y j > x j ∨(1− vπ ( j)). Moreover, for all j ∈ Lπ , x j ∨(1− vπ ( j)) <1 − vk+ since x j < 1 − vk+ and 1 − vπ ( j) < yi+ (cid:3) 1 − vk+ . HenceC. Labreuche / Artificial Intelligence 175 (2011) 1410–14481447+( y, x) \ Lπ , either y j > x j (cid:2) 1 − vk+ or 1 − vπ ( j) (cid:2) yi+ (and thus 1 − vπ ( j) (cid:2) 1 − vk+ ).hPess,Lππ ◦v( y) > hPess,LπOn the other hand, for allHence hPess, Aπ ◦v+( y,x)\Lππ ◦vπ ◦v(x) and hPess,Lπj ∈ A( y) (cid:2) 1 − vk+ and( y) (cid:2) (1 − vk+ ) ∧ hPess,Lπ(x) < 1 − vk+ .+( y,x)Pess, Aπ ◦vh(x).π ◦vConversely, assume that V i+ (cid:16)= ∅ and that (10) is not satisfied. We have iπ ◦v( y) > hPess,Lπ(x) (cid:2) hPess, Aπ ◦v+( y,x)xi+ < yi+ (cid:3) 1 − vk+ . Since |V i+ | (cid:2) |L|, there exists π (cid:8)1, hPess,Lthus 1 − vπ (cid:8)π (cid:8)11 (i) (cid:2) 1 − vk+ ). Since π (cid:8)1 (i+( y,x)\L( y) (cid:2) 1 − vk+ and h+( y, x) \ L, we have h+) = kA+Pess, A◦vπ (cid:8)1Pess, A◦vπ (cid:8)1+ ∈ L := { j ∈ A+( y, x): x j < 1 − vk+ } since1 (i) (cid:2) yi+ (andand for all i ∈ L, 1 − vπ (cid:8)∈ Π(N), such that π (cid:8)1 (i◦v ( y) = 1 − vk+ and hPess,L◦v (x) = 1 − vk+ . Since yi > xi (cid:2) 1 − vk+ for all i ∈+( y,x)\L(x). (cid:5)(x) (cid:2) 1 − vk+ . Hence h( y) = h+) = k+( y,x)+( y,x)π (cid:8)1+Pess, A◦vπ (cid:8)1Pess, A◦vπ (cid:8)1Proof of Proposition 21.• Assume that I = ∅. Since v is normalized, there exists m ∈ N such that vm = 1. Let π (cid:8)3(cid:3)∈ Π(N) such that π (cid:8)3 ( j+) = m.Sincei∈N xi = x j+ , we get hPessπ (cid:8)3◦v (x) = x j+ , which contradicts (11).∈ Π(N) such that for all i ∈ I , 1 − vπ (cid:8)• Assume that I (cid:16)= ∅ but |{k ∈ N: 1 − vk (cid:2) x j+ }| (cid:2) |I|. Then there exists π (cid:8)4Pess, A(x) ∧ h◦vπ (cid:8)4+) = m. We obtain h(x) (cid:2) x j+ and hPess, A◦vπ (cid:8)4Pess, A◦vπ (cid:8)4and π (cid:8)+( y,x)−( y,x)=( y,x)4 ( j4 (i) (cid:2) x j+(x) = x j+ . This contradicts (11).+( y,x)• Assume that (12) holds. Then for all π ∈ Π(N), there exists i ∈ I such that 1 − vπ (i) < x j+ . Hence h=( y,x)−( y,x)xi ∨ (1 − vπ (i)) < x j+ and hPess, Aπ ◦v(x) ∧ hPess, Aπ ◦v(x) (cid:2) x j+ . Hence (11) holds. (cid:5)Pess, Aπ ◦v(x) (cid:3)References[1] L. Amgoud, S. Belabbes, H. Prade, Towards a formal framework for the search of a consensus between autonomous agents, in: 4th International JointConference on Autonomous Agents and Multiagent Systems (AAMAS), Utrecht, 2005, pp. 537–543.[2] L. Amgoud, J.-F. Bonnefon, H. Prade, An argumentation-based approach to multiple criteria decision, in: 8th European Conference on Symbolic andQuantitative Approaches to Reasoning with Uncertainty (ECSQARU’2005), Barcelona, 2005, pp. 269–280.[3] L. Amgoud, H. Prade, Using arguments for making and explaining decisions, Artificial Intelligence 173 (2009) 413–436.[4] G.E. Andrews, The Theory of Partitions, Encyclopedia of Mathematics and Its Applications, 2nd edition, Addison-Wesley, 1976.[5] K. Arrow, Social Choice and Individual Values, 2nd edition, Wiley, 1963.[6] K.J. Arrow, A.K. Sen, K. Suzumura, Handbook of Social Choice and Welfare, Handbooks in Economics, Elsevier, 2002.[7] C.A. Bana e Costa, J.C. Vansnick, A theoretical framework for Measuring Attractiveness by a Categorical Based Evaluation TecHnique (MACBETH), in:Proc. XIth Int. Conf. on MultiCriteria Decision Making, Coimbra, Portugal, August 1994, pp. 15–24.[8] F. Barbaresco, J.C. Deltour, G. Desodt, B. Durand, T. Guenais, Ch. Labreuche, Intelligent M3R radar time resources management: Advanced cognition,agility & autonomy capabilities, in: International Radar Conference, Bordeaux, France, October 12–16, 2009.[9] C. Boutilier, R. Brafman, C. Domshlak, H. Hoos, D. Poole, CP-nets: a tool for representing and reasoning with conditional Ceteris Paribus preferencestatements, Journal of Artificial Intelligence Research 21 (2004) 135–191.[10] D. Bouyssou, T. Marchant, M. Pirlot, A. Tsoukiàs, Ph. Vincke, Evaluation and Decision Models with Multiple Criteria: Stepping Stones for the Analyst,International Series in Operations Research and Management Science, Springer, 2006.[11] R. Brafman, Intentions, Plans and Practical Reason, Harvard University Press, Massachusetts, 1987.[12] R. Brafman, M. Tennenholtz, An axiomatic treatment of three qualitative decision criteria, J. ACM 47 (2000) 452–482.[13] C.B. Callaway, J.C. Lester, Narrative prose generation, Artificial Intelligence 139 (2002) 213–252.[14] G. Carenini, J.D. Moore, Generating and evaluating evaluative arguments, Artificial Intelligence 170 (2006) 925–952.[15] G. Choquet, Theory of capacities, Annales de l’Institut Fourier 5 (1953) 131–295.[16] V. Chvatal, Linear Programming, W.H. Freeman and Company, New York, 1983.[17] E.P. Corbett, R.J. Connors, Classical Rhetoric for the Modern Student, Oxford University Press, Oxford, 1999.[18] Y. Dimopoulos, P. Moraitis, L. Amgoud, Theoretical and computational properties of preference-based argumentation, in: 18th European Conference onArtificial Intelligence (ECAI’08), Patras, Greece, 2008, pp. 463–467.[19] J. Doyle, R. Thomason, Background to qualitative decision theory, The AI Magazine 20 (1999) 55–68.[20] D. Dubois, H. Fargier, P. Perny, Qualitative decision theory with preference relations and comparative uncertainty: An axiomatic approach, ArtificialIntelligence 148 (2003) 219–260.[21] D. Dubois, H. Fargier, H. Prade, Refinements of the maximin approach to decision-making in a fuzzy environment, Fuzzy Sets and Systems 81 (1996)103–122.[22] D. Dubois, H. Prade, Weighted minimum and maximum operations in fuzzy set theory, Information Sciences 39 (1986) 205–210.[23] D. Dubois, H. Prade, Possibility Theory: An Approach to Computerized Processing of Uncertainty, Plenum Press, New York, 1988.[24] D. Dubois, H. Prade, Possibility theory as a basis for qualitative decision theory, in: Proc. Int. Joint Conf. in AI (IJCAI’95), Montreal, Canada, August 1995,pp. 19–25.[25] P. Dung, On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games, ArtificialIntelligence 77 (1995) 321–357.[26] W. Edwards, J.R. Newman, Multiattribute Evaluation, Sage Publications, Cambridge, 1983.[27] M. Elhadad, Using argumentation in text generation, Journal of Pragmatics 24 (1995) 189–220.[28] J. Figueira, S. Greco, M. Ehrgott (Eds.), Multiple Criteria Decision Analysis: State of the Art Surveys, Kluwer Academic Publishers, 2005.[29] P. Fishburn, The Theory of Social Choice, Princeton University Press, 1973.[30] P. Fishburn, Semiorders and choice functions, Econometrica 43 (1975) 975–977.[31] J. Fodor, M. Roubens, Fuzzy Preference Modelling and Multi-Criteria Decision Aid, Kluwer Academic Publishers, 1994.[32] J.B. Grize, Matériaux pour une logique naturelle, Technical report, Travaux du Centre de Recherche Semiologique, No. 29, Université de Neuchâtel,Suisse, 1976.1448C. Labreuche / Artificial Intelligence 175 (2011) 1410–1448[33] C.L. Hamblin, Fallacies, Methuen, London, 1970.[34] R.L. Keeney, H. Raiffa, Decision with Multiple Objectives, Wiley, New York, 1976.[35] D.A. Klein, Decision Analytic Intelligent Systems: Automated Explanation and Knowledge Acquisition, Lawrence Erlbaum Associates, 1994.[36] F.H. Knight, Risk, Uncertainty, and Profit, Houghton Mifflin, Boston, New York, 1921.[37] D.H. Krantz, R.D. Luce, P. Suppes, A. Tversky, Foundations of Measurement, vol. 1, Additive and Polynomial Representations, Academic Press, 1971.[38] Ch. Labreuche, Argumentation of the results of a multi-criteria evaluation model in individual and group decision aiding, in: Int. Conf. of the EuroSociety for Fuzzy Logic and Technology (EUSFLAT), Barcelona, Spain, September 7–9, 2005, pp. 482–487.[39] Ch. Labreuche, Argumentation of the decision made by several aggregation operators based on weights, in: Int. Conf. on Information Processing andManagement of Uncertainty in Knowledge-Based Systems (IPMU), Paris, France, July 2–7, 2006, pp. 683–691.[40] R.D. Luce, H. Raiffa, Games and Decisions, Wiley, New York, 1957.[41] Th. Marchant, Towards a theory of MCDM: Stepping away from social choice theory, Mathematical Social Choice 45 (2003) 343–363.[42] S. Modgil, Reasoning about preferences in argumentation frameworks, Artificial Intelligence 173 (2009) 901–934.[43] J. Montmain, G. Mauris, A. Akharraz, Elucidation and decisional risk in a multi criteria decision based on a Choquet integral aggregation: A cyberneticframework, International Journal of Multi-Criteria Decision Analysis 13 (2005) 239–258.[44] H. Moulin, Axioms of Cooperative Decision Making, Cambridge University Press, 1988.[45] S.D. Parsons, N.R. Jennings, Negotiation through argumentation – a preliminary report, in: Proc. 2nd Int. Conf. on Multi-Agent Systems (ICMAS), Kyoto,Japan, 1996, pp. 267–274.[46] C. Perelman, L. Olbrechts-Tyteca, Traité de l’Argumentation, PUF, Paris, 1958.[47] J.P. Pignon, Ch. Labreuche, A methodological approach for operational and technical experimentation based evaluation of systems of systems architec-tures, in: Int. Conference on Software & Systems Engineering and Their Applications (ICSSEA), Paris, France, December 4–6, 2007.[48] A. Rapoport, Decision Theory and Decision Behaviour, Kluwer Academic Publishers, Dordrecht, 1989.[49] B. Roy, Multicriteria Methodology for Decision Aiding, Kluwer Academic Publishers, Dordrecht, 1996.[50] T.L. Saaty, A scaling method for priorities in hierarchical structures, J. Math. Psychology 15 (1977) 234–281.[51] L.J. Savage, The Foundations of Statistics, 2nd edition, Dover, 1972.[52] M. Schroeder, R. Schweimeier, Notions of attack and justified arguments for extended logic programs, in: F. van Harmelen (Ed.), Proceedings of theEuropean Conference on Artificial Intelligence (ECAI02), Amsterdam, 2002, pp. 536–540.[53] M. Sugeno, Theory of fuzzy integrals and its applications, PhD thesis, Tokyo Institute of Technology, 1974.[54] J. Von Neumann, O. Morgenstern, Theory of Games and Economic Behavior, Princeton University Press, 1944.[55] W.A. Wagenaar, P.J. van Koppen, H.F.M. Crombag, Anchored Narratives. The Psychology of Criminal Evidence, St. Martin’s Press, New York, 1993.[56] A. Wald, Statistical Decision Functions, Wiley, New York, 1950.[57] D. Walton, Argumentation Schemes for Presumptive Reasoning, Erlbaum, Mahwah, NJ, 1996.