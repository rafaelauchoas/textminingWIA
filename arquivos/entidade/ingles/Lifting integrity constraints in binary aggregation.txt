Artificial Intelligence 199–200 (2013) 45–66Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLifting integrity constraints in binary aggregationUmberto Grandi∗, Ulle EndrissInstitute for Logic, Language and Computation, University of Amsterdam, Postbus 94242, 1090 GE Amsterdam, The Netherlandsa r t i c l ei n f oa b s t r a c tWe consider problems in which several individuals each need to make a yes/no choiceregarding a number of issues and these choices then need to be aggregated into a collectivechoice. Depending on the application at hand, different combinations of yes/no may beconsidered rational. We describe rationality assumptions as integrity constraints using asimple propositional language and we explore the question of whether or not a givenaggregation procedure willlift a given integrity constraint from the individual to thecollective level, i.e., whether the collective choice will be rational whenever all individualchoices are.© 2013 Elsevier B.V. All rights reserved.Article history:Received 25 April 2012Received in revised form 24 April 2013Accepted 3 May 2013Available online 6 May 2013Keywords:Collective decision makingComputational social choiceMulti-issue domainsCombinatorial voteJudgment aggregation1. IntroductionSocial Choice Theory (SCT) is the study of mathematical models for collective decision making. In recent times, this disci-pline has received increasing attention in Artificial Intelligence (AI), as testified by a large number of papers on social choiceat the major AI conferences and by the creation of an entirely new research agenda under the name of Computational SocialChoice [6]. There are several good reasons for this trend. On the one hand, a number of methods developed in AI and, moregenerally, in Computer Science have turned out to be useful to deepen our understanding of social choice and, in somecases, can even suggest an entirely new perspective on classical problems. Examples include the complexity-theoretic analy-sis of optimisation problems arising in social choice [15,16] and the creation of new choice procedures inspired by classicaltechniques in knowledge representation [27]. On the other hand, methods from SCT have natural important applications inAI. They can, e.g., be employed to achieve consensus amongst the autonomous software agents in a multiagent system [39],to aggregate the output of several search engines [2], or to inform the design of online recommender systems [34]. Oneparticular problem of interest for AI is the case of social choice in combinatorial domains, in which the space of alternativesfrom which the individuals have to choose has a multi-attribute structure [26,7]. Classical examples include voting in mul-tiple referenda, where we have to decide which of a set of propositions to accept, or electing a committee, where we haveto decide how to fill each seat. There have been several attempts to tackle the high complexity that arises in this context byusing tools from AI, such as methods for modelling preferences inspired by knowledge representation [28,38]. Finally, SCTprovides tools for the analysis of collective choices of groups of agents, and as such is of immediate relevance to the studyof multiagent systems.A central problem in SCT, and, in view of our previous discussion, in all its applications to AI, is the problem of ag-gregation: Suppose a group of agents each supply a particular piece of information regarding a common problem and wewant to aggregate this information into a collective view to obtain a summary of the individual views provided. A classical* Corresponding author at: Department of Mathematics, University of Padova, Via Trieste 63, 35121 Padova, Italy. Tel.: +39 (0) 498271357; fax: +39 (0)498271499.E-mail addresses: umberto.uni@gmail.com (U. Grandi), ulle.endriss@uva.nl (U. Endriss).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.05.00146U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66example is that of preferences [3]: each agent declares their individual preferences over a set of alternatives by providingan ordering over this set, and we are asked to amalgamate this information into a collective ranking that represents theindividual preferences provided. The same methodology has also been applied more recently to a number of other types ofinformation, such as beliefs [23,24] and judgments [29].One of the main features of the study of aggregation is the problem of collective rationality: given a rationality assumptionthat bounds the choices of the individuals, we ask whether the output of an aggregator still satisfies the same rationalityassumption. To understand this problem better, consider the following example: three autonomous agents need to decideon whether to perform a collective action. This action is performed if two parameters are estimated to exceed a certainthreshold. We can model the choice situation with a multi-attribute domain in which there are three issues at stake: “thefirst parameter is above the threshold” (T 1), “the second parameter is above the threshold” (T 2), and “the action should beperformed” ( A). The rationality assumption that links the three issues together can be modelled using a simple propositionalformula, namely T 1 ∧ T 2 → A. The individual views on the three issues are then aggregated using the majority rule, whichaccepts an issue if a majority of the individual agents do. Consider now the following situation:Agent 1Agent 2Agent 3MajorityT 1YesNoYesYesT 2YesYesNoYesAYesNoNoNoIn the situation described above the collective action A is not performed, even though a majority of the individuals thinkthat the first parameter exceeds the threshold and a (different) majority agree that also the second parameter exceeds thethreshold. Situations like the one above are considered paradoxical: even if each individual agent is rational (i.e., each ofthem satisfies the rationality assumption), the collective view derived using the majority rule is not. That is, the majorityrule fails to lift the integrity constraint T 1 ∧ T 2 → A from the individual to the collective level. This example shows thatthe majority rule violates collective rationality in certain specific cases. Similar examples can be devised for a number ofdifferent situations ranging from voting to rank aggregation, to the development of a collective judgment in court cases.Classical work in SCT was restricted to particular studies of collective rationality in a given aggregation situation and fora given class of aggregation procedures. Dokow and Holzman [11], for instance, characterise binary domains of aggregationover which every procedure that satisfies certain desirable axiomatic properties, namely, independence and unanimity, isdictatorial (see Section 8). This is a good example for the use of the axiomatic method in economic theory: the aim is toidentify the appropriate set of axiomatic properties (e.g., to model real-world economies, specific moral ideals, etc.) andthen to prove a characterisation (or impossibility) result for those axioms. Given the wide variety of potential applicationsin AI, on the other hand, in this context we require instead a systematic study that, depending on the situation at hand,can give answers to the problem of collective rationality. With every new application the principles underlying a systemmay change; so we may be more interested in devising languages for expressing a range of different axiomatic propertiesrather than identifying the “right” set of axioms; and we may be more interested in developing methods that will help usto understand the dynamics of a range of different social choice scenarios rather than in technical results for a specific suchscenario.In this paper we put forward a general framework that encompasses most of the classical studies of collective rationalityin SCT, and that can prove useful to diverse research areas in AI. We base our framework on binary aggregation, in whichindividuals are required to choose from a multi-issue domain where issues represent different binary choices. Classicalframeworks for the study of aggregation, such as preference and judgment aggregation, can be embedded in this framework.We model rationality assumptions using a simple propositional language, and we give a precise definition of collectiverationality with respect to a given rationality assumption. We classify rationality assumptions with respect to their syntacticproperties, and we give a systematic treatment of the question of how to relate collective rationality with respect to asyntactically defined sublanguage to classical axiomatic properties from SCT. For instance, we have already seen that themajority rule is not collectively rational with respect to the integrity constraint T 1 ∧ T 2 → A. It is also not collectivelyrational with respect to the 3-clause T 1 ∨ T 2 ∨ A: to see this, consider a scenario with three agents, where each agentaccepts exactly one issue, and no two agents accept the same issue. On the other hand, as we shall see, any 2-clause willalways be lifted, i.e., the majority rule is collectively rational with respect to the language of 2-clauses. We will then beable to describe the majority rule in terms of classical axioms (see Proposition 2) or in terms of the subset of integrityconstraints it lifts (see Theorem 28). It is results of this kind that we shall explore in depth in this paper, establishing a linkbetween standard axiomatic requirements from SCT and collective rationality with respect to fragments of the propositionallanguage.This paper expands our initial work on this topic [20], complementing it with further results from previous work [21,19,18].The paper is organised as follows. We begin by defining the basic notions that constitute the framework of binaryaggregation with integrity constraints in Section 2. In this section, we give the crucial definition of collective rationality withrespect to an integrity constraint expressed in a suitable propositional language, and we list several axiomatic propertiesU. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–6647adapted from the literature on SCT. We also provide several examples of aggregation problems that can be modelled inbinary aggregation with integrity constraints, such as multi-issue elections, preference aggregation, judgment aggregation,and the problem of choosing from a set of candidates. In Section 3 we define the notion of language for integrity constraints,and we prove this to be the correct definition for the study of collective rationality (see Lemma 6). We then define classesof aggregation procedures both in terms of collective rationality and by using classical axiomatic requirements. We studythe properties of these two means of defining classes of procedures, developing a theoretical machinery that enables usto provide a systematic treatment of the relation between propositional languages for integrity constraints and axiomaticproperties. This is done in the two following sections. In Section 4 we characterise in axiomatic terms, for several fragmentsof the propositional language, the class of collectively rational procedures with respect to formulas in this fragment. InSection 5 we start from classical axiomatic properties, and we explore to what extent classes of aggregation proceduresdefined in these terms can be characterised as classes of collectively rational procedures for a given language. We providenegative results for three important axioms taken from the literature on SCT. These three axioms can be combined to obtainan interesting class of procedures known as quota rules, defined by the choice of an acceptance quota for every issue. InSection 6 we concentrate on this particular class. We give precise bounds on the acceptance quotas to guarantee collectiverationality with respect to integrity constraints that belong to given languages of clauses, i.e., disjunctions of literals. Thisincludes a characterisation of the set of integrity constraints that are lifted by the majority rule (see Theorem 28). Wediscuss the significance of our results and their relation to classical frameworks of aggregation in Section 7. Related work isdiscussed in Section 8 and Section 9 concludes.2. Basic definitionsIn this section we give the basic definitions that constitute the framework of binary aggregation with integrity con-straints. First, we review the classical setting of binary aggregation, based on work by Wilson [40] and Dokow and Holzman[11], to which we add the notion of integrity constraint as a mean of specifying the set of individual ballots to be consid-ered rational. We then present a list of examples from both practical applications and classical frameworks of aggregationthat can be modelled in our framework. Finally, we state the crucial definition of collective rationality and we review theclassical axiomatic method for binary aggregation procedures. We conclude by axiomatising the class of quota rules and themajority rule over binary combinatorial domains.2.1. Binary aggregation with integrity constraintsLet I = {1, . . . , m} be a finite set of issues, and let D = D1 × · · · × Dm be a boolean combinatorial domain, i.e., |D i| = 2for all i ∈ I (we assume D i = {0, 1}). Let N = {1, . . . , n} be a finite set of individuals and we assume |N | > 1. A ballot Bis an element of D. A profile B = (B1, . . . , Bn) is a vector of ballots, one for each individual in N . We write b j for the jthelement of a ballot B, and bi, j for the jth element of ballot B i within a profile B = (B1, . . . , Bn).Definition 1. Given a finite set of issues I and a finite set of individuals N , an aggregation procedure is a functionF : DN → D, mapping each profile of binary ballots to an element of D.1Let F (B) j denote the result of the aggregation on issue j. Note that we do not put any restriction on the domain onwhich aggregation procedures are defined, i.e., Definition 1 includes a requirement known as universal domain.If I is a set of m issues, let PS = {p1, . . . , pm} be a set of propositional symbols, one for each issue, and let LPS be thepropositional language constructed by closing PS under propositional connectives. For any formula ϕ ∈ LPS, let Mod(ϕ) bethe set of assignments that satisfy ϕ. For example, Mod(p1 ∧ ¬p2) = {(1, 0, 0), (1, 0, 1)} if PS = {p1, p2, p3}.Definition 2. An integrity constraint is any formula ic ∈ LPS.Integrity constraints can be used to define what tuples in D we consider rational choices. Any ballot B ∈ D is an as-signment to the variables p1, . . . , pm, and we call B a rational ballot if it satisfies the integrity constraint ic, i.e., if B isan element of Mod(ic). A rational profile will be therefore an element of Mod(ic)N. In the sequel we shall use the terms“integrity constraints” and “rationality assumptions” interchangeably.2.2. ExamplesIn line with the example presented in the introduction, let us consider several other aggregation problems that can bemodelled in binary aggregation by devising a suitable integrity constraint:1 In this definition we represent profiles as functions from the set of individuals N to the domain D, indicating the set of all profiles with DN. Giventhat in this paper the set of individuals is finite, profiles can also be represented as tuples of binary ballots. However, we decided to use the functionalnotation to facilitate an eventual generalisation of the framework to allow for infinite sets of individuals.48U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66Table 1A rational profile for pU ∧ p S → pC .i1i2i3U011S101C001Example 1 (Multi-issue elections under constraints). A committee N has to decide on each of the three following issues:(U ) financing a new university building, (S) financing a sports centre, (C ) increasing catering facilities. As an approval ofboth a new university building and a sports centre would bring an unsustainable demand on current catering facilities, itis considered irrational to approve both of the first two issues and to reject the third one. We can model this situationwith a set of three issues I = {U , S, C}. The integrity constraint representing this rationality assumption is the followingformula: pU ∧ p S → pC . To see an example of a rational profile, consider the situation described in Table 1 for the case ofa committee with three members. All individuals are rational, the only irrational ballot being B = (1, 1, 0).Example 2 (Preference aggregation). A set N of individuals has to agree on a ranking of three alternatives a, b and c. Eachindividual submits its own ranking of the alternatives from the most preferred to the least preferred, e.g., b > a > c. Wecan model this situation using a binary issue for every pair of alternatives: issue ab stands for “alternative a is preferred toalternative b”. The set of issues is therefore I = {aa, bb, cc, ab, ba, bc, cb, ac, ca}. However, not every binary evaluation overthis set of issues corresponds to a ranking. An integrity constraint needs to be devised to encode the correct properties ofthe binary relation: transitivity, completeness and irreflexivity. This can be done by considering the following set of integrityconstraints ic<:Irreflexivity: ¬pxx for all x ∈ {a, b, c}Completeness: pxy ∨ p yx for all x, y ∈ {a, b, c} distinctTransitivity: pxy ∧ p yz → pxz for x, y, z ∈ {a, b, c} pairwise distinctThese formulas can be easily modified to account for different representations of preferences that are closer to applicationsin AI, e.g., partially ordered preferences [36].Example 3 (Judgment aggregation). A court composed of three judges has to decide on the liability of a defendant under thecharge of breach of contract. According to the law, the individual is liable if there was a valid contract and her behaviour wassuch as to be considered a breach of the contract.2 The court takes three majority decisions on the following statements:there was a valid contract (α), the individual broke the contract (β), the defendant is liable (α ∧ β). We can model thissituation using a set of six issues I = {α, ¬α, β,¬β, α ∧ β, ¬(α ∧ β)} to model the decision of a judge on the three issuesat stake, and create a set of integrity constraints that reflect the consistency of a possible verdict by explicitly ruling outevery inconsistent set that can be created using issues in I:Inconsistent sets of size 2: ¬(px ∧ p¬x) for all x ∈ {α, β, α ∧ β}, ¬(pα∧β ∧ p¬α) and ¬(pα∧β ∧ p¬β )Inconsistent set of size 3: ¬(p¬(α∧β) ∧ pα ∧ pβ )Situations like the one described in this example are the subject of a wide literature in SCT under the name of judgmentaggregation [29]. We refer to our previous work [21,18] for more details about the correspondence between judgmentaggregation and our framework of binary aggregation with integrity constraints.Example 4 (Choosing from a set of candidates). A winning candidate has to be chosen from a set C = {1, . . . , m} by an electorateN . Let the set of issues be I = C . If we are using an aggregation procedure like approval voting [4], in which individualsare submitting a set of candidates they approve of, then we can model the situation without any integrity constraint, sinceevery binary ballot over I corresponds to a set of candidates. If instead we want to consider more restrictive ballots, likein the case of the plurality rule in which each individual submits only its favourite candidate, then we need to devise anintegrity constraint that forces each individual to approve a single candidate in the list. This can be done by taking thedisjunction of all possible ballots:(p1 ∨ ¬p2 ∧ · · · ∧ ¬pm) ∨ (¬p1 ∧ p2 ∧ · · · ∧ ¬pm) ∨ · · · ∨ (¬p1 ∧ · · · ∧ ¬pm−1 ∧ pm)The voting rule known as k-approval voting, in which individuals submit a set of k approved candidates, can be modelledin a similar fashion.2 This example is due to Kornhauser and Sager [25].U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66492.3. Collective rationalityConsider the situation introduced in Example 1: There are three issues at stake, and the integrity constraint is rep-resented by the formula ic = pU ∧ p S → pC . Suppose there are three individuals, choosing ballots (0, 1, 0), (1, 0, 0) and(1, 1, 1), as in Table 1. Their choices are rational (they all satisfy ic). Assume now we accept an issue j if a majority ofindividuals do, employing what we will call the majority rule. We would then obtain as an outcome of this profile the ballot(1, 1, 0), which fails to be rational. This kind of observation, like the one presented in the introduction, is often referred toas a paradox.In the literature on SCT, situations like the one above are ruled out by requiring aggregation procedures to satisfy aproperty called collective rationality, which forces the output of an aggregation procedure to be of the same form of theinput, i.e., a rational ballot. In preference aggregation, for instance, the output of an aggregation procedure is required tobe a linear (or weak) order over a set of alternatives [3]. In judgment aggregation the output is required to be a consistentjudgment over a set of propositional formulas [29]. Here we give a general definition of collective rationality depending onthe integrity constraint at hand:Definition 3. Given an integrity constraint ic ∈ LPS, an aggregation procedure F : DN → D is called collectively rational (CR)with respect to ic, if for all rational profiles B ∈ Mod(ic)Nwe have that F (B) ∈ Mod(ic).Thus, F is CR if it lifts the rationality assumptions given by ic from the individual to the collective level. An aggregationprocedure that is CR with respect to ic cannot generate a paradox with ic as integrity constraint.Inspired by Definition 3, we can give a general definition of paradoxical behaviour of an aggregation procedure in termsof the violation of certain rationality assumptions:Definition 4. A paradox is a triple (F , B, ic), where F : DN →D is an aggregation procedure, B is a profile in DNintegrity constraint in LPS, and B i ∈ Mod(ic) for all i ∈ N but F (B) /∈ Mod(ic)., ic is anThis notion of paradox encompasses many of the classical paradoxes of aggregation studied in SCT. A shown by theexamples presented in the previous section, preference and judgment aggregation, as well as other frameworks for collectivedecision making, can be modelled in binary aggregation by devising suitable integrity constraints. In previous work [19] webring this correspondence one step further by showing how paradoxical situations traditionally studied in SCT, such as theCondorcet paradox in preference aggregation [3] and the discursive dilemma in judgment aggregation [29], can be viewedas particular instances of our Definition 4.2.4. The axiomatic methodAggregation procedures are traditionally studied using the axiomatic method. Axioms are used to express desirable prop-erties of a procedure, depending on the application at hand. In this section, we adapt the most important axioms familiarfrom standard SCT, and more specifically from judgment aggregation [29] and binary aggregation [11], to our setting. LetX ⊆ DNbe a subset of the set of all profiles. We start with four common axioms:Unanimity (U): For any profile B ∈ X and any x ∈ {0, 1}, if bi, j = x for all i ∈ N , then F (B) j = x.Issue-neutrality (N(cid:8) ∈ I and any profile B ∈ X , if for all i ∈ N we have that bi, j = bi, j(cid:8) , then): For any two issues j, jIF (B) j = F (B) j(cid:8) .Independence (I): For any issue j ∈ I and any two profiles B, BAnonymity (A): For any profile B ∈ X and any permutation σ : N → N , we have that F (B 1, . . . , Bn) = F (Bσ (1), . . . , Bσ (n)).(cid:8)i, j for all i ∈ N , then F (B) j = F (B(cid:8) ∈ X , if bi, j = b(cid:8)) j .Unanimity postulates that, if all individuals agree on issue j, then the aggregation procedure should implement that choicefor j. Anonymity requires the procedure to be symmetric with respect to individuals. Issue-neutrality (a variant of thestandard axiom of neutrality introduced in the literature on judgment aggregation) asks that the procedure be symmetricwith respect to issues. Finally, independence requires the outcome of aggregation on a certain issue j to depend only onthe individual choices regarding that issue.It is important to remark that all axioms are domain-dependent, as testified by the domain restriction given by X . Forinstance, many aggregation procedures, such as the majority rule, are independent over the full set of profiles X = DN,while others, such as the one presented in the next example, are not. With two issues, let ic = (p2 → p1) and let F beequal to the majority rule on the first issue, and accept the second issue only if the first one was accepted and the secondone has the support of a majority of the individuals. This procedure is not independent on the full domain, but it is easy tosee that it satisfies independence when restricted to X = Mod(ic)N. As in the previous example, in the following sectionswe will specify restrictions on the domain of aggregation by means of propositional formulas.As a generalisation of the axiom of neutrality introduced by May [31], we introduce the following axiom:50U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66Domain-neutrality (N): For any two issues j, jDF (B) j = 1 − F (B) j(cid:8) .(cid:8) ∈ I and any profile B ∈ X ,if bi, j = 1 − bi, j(cid:8)for alli ∈ N , thenThe two notions of neutrality are uncorrelated but dual: issue-neutrality requires the outcome on two issues to be the sameif all individuals agree on these issues; domain-neutrality requires it to be reversed if all the individuals make oppositechoices on the two issues.We now introduce two axioms of monotonicity. The first, which we call independence-monotonicity, is often calledpositive responsiveness and is formulated as an (inter-profile) axiom for independent aggregation procedures. The secondversion of monotonicity is designed for neutral procedures, and it was introduced in our previous work [14]:I-monotonicity (MI): For any j ∈ I and any two profiles B and B(cid:8)in X , if bi, j = 1 entails b(cid:8)i, j= 1 for all i ∈ N , and forsome s ∈ N we have that bs, j = 0 and b(cid:8)s, j= 1, then F (B) j = 1 entails F (B(cid:8)) j = 1.N-monotonicity (MN): For any j, j(cid:8) ∈ I and profile B ∈ X , if for all i ∈ N we have that bi, j = 1 entails bi, j(cid:8) = 1 and forsome s ∈ N we have that bs, j = 0 and bs, j(cid:8) = 1, then F (B) j = 1 entails F (B) j(cid:8) = 1.That is, MI expresses that if an issue j is collectively accepted and receives additional support (from an individual i),isthen it should continue to be collectively accepted. Axiom MN says that if issue j is collectively accepted and issue jaccepted by a strict superset of the individuals accepting j, then jshould also be collectively accepted.(cid:8)(cid:8)The last property for aggregation procedures that we are going to introduce is traditionally considered a negative one.We choose not to state it as an axiom, but rather as a property defining a class of functions: An aggregation procedure iscalled a dictatorship if it copies the ballot of the same individual in every profile. This notion is in clear contrast with theaxiom of anonymity previously introduced. In Definition 9 we will generalise this notion by defining the class of generaliseddictatorships as those procedures that copy the ballot of a possibly different individual in every profile.2.5. Quota rulesAn aggregation procedure F for n individuals is a quota rule if for every issue j there exists a quota 0 (cid:2) q j (cid:2) n + 1 such| (cid:3) q j . The class of quota rules, which we denotethat, if we denote by N BjQR, was introduced by Dietrich and List [10] in the framework of judgment aggregation. Adapting a result by Dietrich andList [10, Theorem 1] we obtain the following axiomatisation of the class of quota rules3:= {i | B i, j = 1}, then F (B) j = 1 if and only if |N BjProposition 1. An aggregation procedure F satisfies A, I, and MI on the full domain DNif and only if it is a quota rule.A quota rule is called uniform if the quota is the same for all issues. By adding the axiom of issue-neutrality to Proposi-tion 1 we immediately get an axiomatisation of this class.A particular quota rule, which we study in detail in Section 6.2, is the majority rule. This rule, in case the number ofindividuals is odd, is the uniform quota rule with quota q = n+12 . It is interesting to link these results with May’s Theorem[31] on the axiomatic characterisation of the majority rule in voting theory. We can complement his result (which deals withthe case of a single issue) by adding the axioms of domain-neutrality and issue-neutrality to Proposition 1 and consideringthe case of multiple binary issues. Under these assumptions, by issue-neutrality the quota must be the same for all issues,and by domain-neutrality the two sets N Bj must be treated symmetrically. Hence, the only possibility is to havea uniform quota of n+12 .j and N \ N BProposition 2. If the number of individuals is odd and |I| (cid:3) 2, an aggregation procedure F satisfies A, Ndomain DNif and only if it is the majority rule.ID, N, I and MI on the full3. Classes of aggregation proceduresIn this section we introduce two definitions for classes of aggregation procedures on binary combinatorial domains.Given a restriction on the propositional language in which integrity constraints can be expressed, we first define the classof procedures that are collectively rational with respect to all integrity constraints in the given restricted language. Onthe other hand, we consider a list of classical axiomatic properties and define the class of procedures that satisfy suchaxioms on domains defined by formulas in the given language. We study the properties of these two definitions, preparingthe ground for characterisation results that will establish a strong link between requirements of collective rationality andclassical axiomatic properties.3 Detailed proofs of Proposition 1 and Proposition 2 can be found in our previous work [18].U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66513.1. Collective rationality and axiomatic propertiesRecall that a binary aggregation problem is given by a set of agents N having to take a decision on which combinationof binary issues in I to choose. Depending on the situation at hand, a subset of such combinations is designated as the setof rational choices, and this is specified by means of a propositional formula in the language LPS associated with I. We calllanguage any subset L of LPS. Examples include the set of atoms PS, or the set of formulas of a given size, as well as moreclassical fragments obtained by restricting the set of connectives that can be employed in the construction of formulas, likethe set of clauses obtained from the set of literals using only disjunctions. In Section 2.3 we called an aggregation procedurecollectively rational with respect to a formula ic ∈ LPS if the outcome on every rational profile satisfies the same integrityconstraint ic. We now extend this definition to collectively rational procedures with respect to a given language L:Definition 5. Given a language L ⊆ LPS, call CR[L] the class of aggregation procedures that lift all ic ∈ L:(cid:2)CR[L] :=F : DN → D(cid:3)(cid:3) N is finite and F is CR for all ic ∈ L(cid:4)Note that in this definition we do not fix the number of individuals, making I the only parameter that is fixed inadvance. This choice is arguably a natural one, as a decision problem is usually defined before specifying the number ofindividuals that are going to take part in the decision process. However, its appeal does not only reside in its practical use;rather it is a mathematical assumption that allows us to gain more clarity in some of the results that follow.4The next step is to introduce notation for defining classes of aggregation procedures in terms of classical axioms like theones we listed in Section 2.4. Recall from Section 2.4 that an axiom may be satisfied on a specific subdomain of interestX , but not on the full domain DN. Here, we are interested in domains defined by means of integrity constraints (i.e.,propositional formulas), as this is interpreted as the domain of rational ballots. We therefore need some notation to identifyprocedures that satisfy an axiom on the subdomain Mod(ic)Ninduced by a given integrity constraint ic. We give thefollowing definition:Definition 6. An aggregation procedure F satisfies a set of axioms AX wrt. a language L ⊆ LPS, if F satisfies the axioms inAX on Mod(ic)Nfor all constraints ic ∈ L. This defines the following class:(cid:2)(cid:3)(cid:3) N is finite and F satisfies AX on Mod(ic)NF : DN → D(cid:4)for all ic ∈ LFL[AX] :=In particular, F = {F : DN → D | N is finite} is the class of all aggregation procedures for a given set of issues I. In thesequel we shall omit mentioning explicitly that N is finite, keeping it as a general underlying assumption.3.2. Languages for integrity constraintsIn this section we study the behaviour of the classes defined in the previous section with respect to set-theoretic andlogical operations performed on the languages and on the axioms. In particular, we give a definition of language for integrityconstraints that is specific to the study of collectively rational procedures.Let L be a language. Define L∧to be the closure of L under conjunction, i.e., the set of finite conjunctions of formu-las in L. We now prove that the class of collectively rational procedures is invariant under closing the language underconjunction, i.e., that the set of collectively rational procedures for L and for L∧coincide:Lemma 3. CR[L∧] = CR[L] for all L ⊆ LPS.Proof. CR[L∧] is clearly included in CR[L], since L ⊆ L∧procedure F lifts every constraint in L, then it lifts any conjunction of formulas in L. (cid:2).5 It is then straightforward to observe that if an aggregationThis lemma entails that different languages for integrity constraints can define the same class of CR procedures. For in-stance, we have that the language of cubes (conjunctions of literals) generates the same class as the language of literals, i.e.,CR[cubes] = CR[literals], since the former is obtained from the latter by closing it under conjunction. Another interestingfact is that procedures that are CR with respect to clauses (disjunctions of literals) are CR with respect to any integrityconstraint in LPS, i.e., CR[clauses] = CR[LPS]. This holds because every propositional formula is equivalent to a formula inconjunctive normal form (CNF), where it is expressed precisely as a conjunction of clauses.We have just proven that the class CR[L] is invariant under closing the language under conjunction. Another suchproperty is the closure under logical equivalence. Recall that two formulas are logically equivalent when they share the same4 Many of our results, e.g. Theorems 10 and Corollary 20, still hold if we fix the number of individuals in Definition 5, as shown in our previous work[20].5 This fact will be later formalised in Lemma 7.52U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66set of models. Let us indicate with L≡the set of formulas in LPS that are equivalent to a formula in L. It is important tostress the fact that we consider logical equivalence inside the language LPS, not allowing the use of additional propositionalvariables. We have the following lemma:Lemma 4. CR[L≡] = CR[L] for all L ⊆ LPS.The proof of the lemma is straightforward from our definitions. It is sufficient to observe that an equivalent formulationof our definition of collective rationality can be given by substituting formulas with the set of rational ballots given by theirmodels. Two formulas that are logically equivalent have the same set of models, giving rise to the same requirement ofcollective rationality.6Bringing together the results of Lemmas 3 and 4, we can now give the following definition:Definition 7. A language for integrity constraints L is a subset of LPS that is closed under conjunction and logical equivalence.In the following sections we characterise languages for integrity constraints by means of syntactic properties, withoutmentioning explicitly the closure under conjunction and logical equivalence. For instance, the language of 2-clauses (i.e.,disjunctions of size at most two) denotes the language of formulas that are equivalent to a conjunction of clauses of size atmost two.7 The language of literals and that of cubes coincide, as well as the language of clauses and the full language LPS,as we have previously remarked.Tautologies and contradictions play a special role in languages for integrity constraints. First, observe that if a languageL includes a tautology (or a contradiction, respectively), then by closure under logical equivalence L contains all tautologies(all contradictions, respectively). Thus, we indicate with (cid:10) ∈ L the fact that L contains all tautologies, and with ⊥ ∈ Lthe fact that L contains all contradictions. Second, not all languages for integrity constraints include both tautologies andcontradictions, or either of them. For instance, the language of literals includes the contradiction p ∧ ¬p but it does notcontain any tautology. On the other hand, the language of positive clauses, consisting of clauses in which all literals occurpositively, does not include either tautologies or contradictions.Nevertheless, it is easy to see that collective rationality with respect to tautologies and contradictions corresponds to avacuous requirement: In the first case, the outcome of a procedure will always satisfy a tautology, and in the second casethe set of rational ballots is empty. These remarks constitute a proof of the following lemma.Lemma 5. CR[L ∪ {(cid:10)}] = CR[L ∪ {⊥}] = CR[L] for all L ⊆ LPS.We now move to answering the question of whether the operations that we have included in Definition 7 are all theoperations that we can perform on L leaving the set CR[L] invariant. The following result provides a positive answer tothis question, provided that a language include tautologies and contradictions:Lemma 6. Given two languages for integrity constraints L1 and L2 containing (cid:10) and ⊥, if it is the case that L1 (cid:13)= L2, then CR[L1] (cid:13)=CR[L2].Proof. As the two languages both contain tautologies and contradictions, they must differ on a contingent formula ϕ.Without loss of generality we can consider a formula ϕ ∈ L2 such that ϕ /∈ L1. We want to prove that there exists anaggregation procedure F ∈ CR[L1] that is not CR with respect to ϕ. This in turn implies that F is not in CR[L2], and thatthe two classes CR[L1] and CR[L2] are different.Let |N | = n where n = |Mod(ϕ)| and let F be a procedure in CR[L1] defined for N .8 We claim that it is possible tothat is still CR with respect tomodify the behaviour of F on a single profile B in order to create another procedure FL1 but sends the profile B of ϕ-rational ballots to an outcome that does not satisfy ϕ. To do so it is sufficient to find aprofile B = (B1, . . . , Bn) of models of ϕ and a ballot Bc outside Mod(ϕ) such that whenever each of B 1, . . . , Bn satisfies any(cid:8)) for allformula ψ ∈ L1 then also Bc |(cid:14) ψ . If we can find such a B and Bc , then by setting Fremaining B(cid:8) (cid:13)= B we obtain an aggregation procedure that is in CR[L1] but not in CR[L2].(cid:8)(B) = Bc and F(cid:8)) = F (B(cid:8)(B(cid:8)Suppose for the sake of contradiction that such a profile does not exist, i.e., that for every choice of n ballots in Mod(ϕ)and ballot Bc outside Mod(ϕ), there is a formula ψ ∈ L1 that separates them: for all i we have that B i |(cid:14) ψ but Bc (cid:13)|(cid:14) ψ .Note that |Mod(ϕ)| = n, as well as the size of the profile B we are looking for. This entails that we can construct a profileBϕ that contains all distinct models of ϕ, and that for every Bc (cid:13)|(cid:14) ϕ there is a formula in L1, that we shall call ψc , thatseparates the set Mod(ϕ) from Bc .6 This is the standard approach in the literature on binary aggregation (see, e.g., [11]). Our choice of using formulas rather than sets is motivated by thecompactness of this representation and by the possibility of using syntax to classify rationality assumptions.7 The language of 2-clauses can be equivalently defined by closing the set of 2-CNF under logical equivalence.8 In Section 4 we prove that CR[L] can never be empty for any language L and any set of agents N (see Theorem 16). For the sake of this proof it issufficient to consider a dictatorship of the first individual.U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–6653Fig. 1. The operators CR[−] and LF[−].(cid:5)ψc for Bc (cid:13)|(cid:14) ϕ. We claim that ϕ ≡We have assumed that ϕ /∈ L1, i.e., ϕ is not equivalent to a conjunction of formulas in L1. Let us now consider theψc , in contradiction with our assumption, since all ψc are in L1. Byψc), as all models of ϕ are individual ballots in the profile Bϕ . We needψc) \ Mod(ϕ). By(cid:5)ψc . Butconjunctionconstruction we know that Mod(ϕ) ⊆ Mod(to prove the other inclusion. Assume for the sake of contradiction that there exists a B∗ in Mod(construction, there exists a formula ψ∗ ∈ L1 that separates B∗ from Mod(ϕ), and this formula is included inby construction B∗ (cid:13)|(cid:14) ψ∗, therefore it cannot be included in Mod((cid:5)(cid:5)(cid:5)(cid:5)ψc).The proof is now concluded: it is possible to modify F on the profile B that contains all models of ϕ to output aso defined is in CR[L1] but not inballot that is not a model of ϕ but respects all integrity constraints in L1. That is, FCR[ϕ]. (cid:2)(cid:8)We conclude this section by establishing some easy properties of CR[L] and of FL[AX] that shall be useful in the nextsections. Let L1 and L2 be languages for integrity constraints.Lemma 7. The following facts hold:(i) If L1 ⊆ L2, then CR[L1] ⊇ CR[L2];(ii) CR[L1 ∪ L2] = CR[L1] ∩ CR[L2] for all L1, L2 ⊆ LPS.The proof is straightforward from our definitions. Lemma 7 still holds if L1 and L2 are arbitrary sets of propositionalformulas (e.g., in the proof of Lemma 3 we are implicitly making use of point (i) of Lemma 7). Similar properties can beproved for classes of procedures defined in terms of axioms. We write F [AX] as a shorthand for F{(cid:10)}[AX], the class ofprocedures that satisfy the axioms in AX over the full domain D. It is easy to see that the following lemma holds:Lemma 8. The following facts hold:(i) if L1 ⊆ L2 then FL1(ii) in particular, if (cid:10) ∈ L, then F [AX] ⊇ FL[AX];(iii) FL[AX1, AX2] = FL[AX1] ∩ FL[AX2].[AX] ⊇ FL2[AX];Observe that for most axioms an additional fact holds: if the axiomatic property AX is satisfied on the full domain D,then AX is also satisfied on every subdomain of D. This is true in particular for all the axioms we considered in Section 2.4.Thus, for most axioms AX the following additional property holds: F [AX] ⊆ FL[AX] for all L ⊆ LPS. By (ii) of Lemma 8 thisentails that if (cid:10) ∈ L then F [AX] = FL[AX] for all L ⊆ LPS. This observation will allow us in Section 5 to obtain strongercharacterisation results by dropping the subscript in the definition of the class FL[AX].3.3. From aggregation procedures to integrity constraints and backIn the first part of Section 3 we have associated with any language for integrity constraints L a class of aggregationprocedures that are collectively rational with respect to all formulas in L. Once a set of issues I is fixed, CR[−] cantherefore be viewed as an operator from the set of languages for integrity constraints (i.e., subsets of LPS closed underconjunction and logical equivalence and containing (cid:10) and ⊥) to subsets of the class F of all aggregation procedures for I.In this section we introduce an inverse operation, that we shall call LF [−], which, given a class of procedures, outputs theset of integrity constraints that are lifted by all procedures in that class. As we will see, LF is the left inverse of CR, buton the other hand the two operators do not commute. The relation between the two operators is shown in Fig. 1.Definition 8. Given a class of aggregation procedures G ⊆ F , call LF [G] the set of integrity constraints that are lifted by allF ∈ G:LF[G] := {ϕ ∈ LPS | F is CR wrt. ϕ for all F ∈ G}LF [G] is the intersection of all LF [{F }] for F ∈ G. We now prove the following:54U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66Proposition 9. Let I be a set of issues, L a language for integrity constraints containing (cid:10) and ⊥, and G ⊆ F a class of aggregationprocedures on I. Then the following facts are true:(i) LF [CR[L]] = L;(ii) CR[LF [G]] ⊇ G and this inclusion is strict for some classes.Proof. (i) We start by proving that LF is a left inverse of CR. A direct consequence of our definitions is that L ⊆LF [CR[L]], and we now prove the other inclusion. We want to show that if an integrity constraint ϕ is lifted by allprocedures that are CR with respect to L, then ϕ belongs to L. This is a straightforward consequence of Lemma 6. Assumefor the sake of contradiction that ϕ /∈ L. By Lemma 6, there exists a procedure F which is collectively rational for L but notfor ϕ, in contradiction to our assumption that all procedures in CR[L] are CR with respect to ϕ. Therefore ϕ is in L.(ii) It is straightforward from our definitions that CR[LF [G]] ⊇ G. Recall that a generalised dictatorship is a procedurethat copies the ballot of a possibly different individual in every profile. It can be easily observed that such a procedure iscollectively rational for every integrity constraint, and in Section 2.2 we will give a formal proof of this fact (cf. Theorem 16).Let us therefore consider a class of procedures G not containing any generalised dictatorship. In view of our previousobservation we know that all generalised dictatorships are contained in CR[LF [G]], as they are collectively rational for anyintegrity constraint. As we assumed that G does not contain any generalised dictatorship, we infer that CR[LF [G]] (cid:2) G. (cid:2)4. Characterisation results for propositional languagesOnce a language for integrity constraints is fixed, e.g., by means of a syntactic restriction on the integrity constraints, wemay be interested in the problem of how to guarantee collective rationality with respect to all the integrity constraints thatcan be expressed in the given language. The aim of this section is to explore the relationship between the two definitionsof classes of aggregation procedures introduced in Section 3: collectively rational procedures on one side, and proceduresdefined by axiomatic requirements on the other. In particular, we look for results of the following form:CR[L] = FL[AX],for languages L and axioms AX. We call such findings characterisation results: they provide necessary and sufficient axiomaticconditions for an aggregation procedure to be collectively rational with respect to a language for integrity constraints. Giventhe importance of collective rationality in many classical studies of aggregation and for a number of practical applications,such results are central to our study.The focus of this section is on languages: We provide complete characterisation for some basic classes of languagesdefined in a syntactic fashion, proving the correspondence with some of the main classical axioms from the literature onSCT. We shift the focus to axioms in Section 5.Definitions of all the axiomatic properties we refer to in this section can be found in Section 2.4. Axioms will be denotedwith the capital letter associated with them, e.g., we will write U for unanimity and I for independence.4.1. Characterisation resultsRecall that a procedure is unanimous if it shares the view of the individuals in case they all agree, either all accepting orrejecting a certain issue. The first characterisation result shows that the set of aggregation procedures that lift all rationalityconstraints expressible in terms of literals is precisely the class of unanimous procedures:Theorem 10. CR[literals] = Fliterals[U].Proof. The first direction (⊇) is easy: If X := Mod((cid:7)) is a domain defined by a literal (cid:7), then every individual ballot mustagree with it, either positively or negatively depending on its sign. This entails, by unanimity, that the collective outcomeagrees with the individual ballots. Thus, F is collectively rational for (cid:7).For the other direction (⊆), suppose that F ∈ CR[literals]. Fix an issue j ∈ I. Pick a profile B ∈ Dn such that bi, j = 1(or ¬p j , respectively). Since F is collectively rational for every literal, including(or 0) for all i ∈ N . That is, B ∈ Mod(p j)Np j and ¬p j , it must be the case that F (B) j = 1 (or 0, respectively), proving unanimity of the aggregator. (cid:2)As remarked in Section 3, the language generated from literals is the same as the language of cubes, i.e., finite conjunc-tions of literals. We can therefore state the following corollary:Corollary 11. CR[cubes] = Fcubes[U].An equivalence is a bi-implication of literals where the literals are both positive (or both negative, which amounts to thesame thing). Call L↔ the language for integrity constraints generated by equivalences, i.e., the set {p j ↔ pk | p j, pk ∈ PS}U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–6655closed under conjunctions and logical equivalence. This language allows us to characterise issue-neutral aggregators, i.e.,procedures that treat distinct issues in the same way:Theorem 12. CR[L↔] = FL↔ [NI ].Proof. To prove the first inclusion (⊇), pick an equivalence p j ↔ pk. This defines a domain in which issues j and k sharethe same pattern of acceptance/rejection, and since the procedure is neutral over issues, we get F (B) j = F (B)k. Therefore,the constraint given by the initial equivalence is lifted.For the other direction (⊆), suppose that a profile B is such that bi, j = bi,k for every i ∈ N . This implies that B ∈, and since F is in CR[L↔], F (B) j must be equal to F (B)k. This holds for every such B, proving that F isMod(p j ↔ pk)Nneutral over issues. (cid:2)With an analogous proof we can obtain a characterisation result involving the axiom of domain-neutrality. Recall thata procedure is domain-neutral if it symmetric with respect to any two issues. An XOR formula is a bi-implication of onenegative and one positive literal. Call LXOR the language for integrity constraints generated from {p j ↔ ¬pk | p j, pk ∈ PS}.Theorem 13. CR[LXOR] = FLXOR[ND].Proof. The first inclusion (⊇) is straightforward: When every individual ballot in a profile satisfies the same XOR formula,then this means that there are two issues the behaviour of which is symmetrical. By domain-neutrality, the outcome of theaggregation is also symmetrical, and therefore the constraint is lifted.To prove the remaining inclusion (⊆), suppose that a profile B is such that bi, j = 1 − bi,k for every i ∈ N . This implies. As before, since F is in CR[LXOR], it must be the case that F (B) j = 1 − F (B)k and F isthat B ∈ Mod(p j ↔ ¬pk)Ndomain-neutral. (cid:2)Consider now the language L+→ of positive implications, generated from formulas of the form p j → pk, or, equivalently,I ]. Therefore, a characterisa-¬p j → ¬pk, for p j, pk ∈ PS. Since L+tion of the language of positive implications must involve the axiom of neutrality in combination with others. The rightcombination is the following:→ ⊇ L↔, we know that CR[L+→] ⊆ CR[L↔] = FL↔ [NTheorem 14. CR[L+→] = FL+→[NI , MN].Proof. (⊇) Let us first consider the case of individual ballots all satisfying a certain positive implication p j → pk. We wantto prove that F lifts this integrity constraint. We note that if an individual accepts issue j then she also accepts issue k.Therefore, the first part of the antecedent forming the axiom of N-monotonicity is satisfied. We now have to consider twocases: if for all i ∈ N we have that bi, j = bi,k = 1, then by issue-neutrality we have that F (B) j = F (B)k. The constraint istherefore satisfied, as the only way to falsify it is by accepting j and rejecting k. If on the other hand there is an individual isuch that bi, j = 0 while bi,k = 1, then B fully satisfies the antecedent of MN and therefore the constraint will be lifted.For the remaining inclusion (⊆), suppose that a profile B is such that whenever bi, j = 1 then bi,k = 1 for every i ∈ N .This implies that B ∈ Mod(p j → pk)N→], F (B) j = 1 entails F (B)k = 1, for the initialconstraint has to be lifted. Therefore F is N-monotonic. We have already remarked that, due to Proposition 12, all proceduresin CR[L+. Since we assumed F to be in CR[L+→] are also issue-neutral. (cid:2)This last result seems to suggest that a characterisation of the language of negative implications (i.e., when exactly one ofthe two literals is negative) might be proved by considering the axiom of domain-neutrality combined with N-monotonicity.Unfortunately, in the absence of a suitable richness condition on the profile this characterisation does not hold. A partialcharacterisation result for this class, i.e., a list of sufficient axiomatic conditions for collective rationality with respect tonegative implications, involves the axiom of independence, and can be found in our previous work [18].We conclude this section by characterising the classes of collectively rational procedures for languages at the extremesof the spectrum: the full language LPS, the language of tautologies, and that of contradictions. For the last two classes thecharacterisation is straightforward. Recall that F = {F : DN → D} is the class of all aggregation procedures (for fixed I). Wehave already stated in Lemma 5 that tautologies and contradictions are vacuous requirements for what concerns collectiverationality, and here we use these arguments to give a characterisation result for this trivial class of formulas. Let {(cid:10)} bethe language of all tautologies, and {⊥} be the language of all contradictions:Proposition 15. CR[{(cid:10)}] = CR[{⊥}] = F .56U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66If on the other hand we turn to study the class of procedures that lift any integrity constraint in LPS we discover aninteresting class of procedures. Let us give the following definition, which generalises the notion of dictatorship9:Definition 9. An aggregation procedure F : Dthat F (B) = B g(B) for every B ∈ DN.N → D is a generalised dictatorship, if there exists a map g : DN → N suchThat is, a generalised dictatorship copies the ballot of a (possibly different) individual in every profile. Call this classGDIC. This class fully characterises the class of collectively rational aggregators for the full propositional language LPS:Theorem 16. CR[LPS] = GDIC.Proof. Clearly, every generalised dictatorship lifts any arbitrary integrity constraint ic ∈ LPS. To prove the other direction,suppose that F /∈ F [GDIC]. Hence, there exists a profile B ∈ DNsuch that F (B) (cid:13)= B i for all i ∈ N . This means that for(cid:13)= bi, ji . We now want to build a propositional formula that is satisfied byevery i there exists an issue ji such that F (B) jiall individuals and not by the collective outcome, proving that F is not CR with respect to the full propositional language.= 1, and to ¬p ji otherwise. Consider as integrity constraint ic the followingDefine a literal (cid:7) ji to be equal to p jii (cid:7) ji . Clearly, B i |(cid:14) ic for every i ∈ N , i.e., B is a rational profile for the integrity constraint ic. But by construction,formula:F (B) (cid:13)|(cid:14) ic, as F (B) differs from the individual ballots on all literals in ic. Therefore, F is not collectively rational for ic anddoes not belong to the class CR[LPS]. (cid:2)if bi, ji(cid:6)As a concluding remark, recall that the language generated by clauses coincides with the full propositional language, asevery propositional formula is equivalent to a conjunction of clauses by taking its conjunctive normal form. We thereforeobtain the following:Corollary 17. CR[clauses] = GDIC.We analyse restricted languages of clauses in Section 6.4.2. How to combine characterisation resultsMost of the characterisation results presented thus far characterise a class of procedures determined by a single axiomand by a uniform description of the language. We now briefly explain to what extent such results can be combined to allowus to make predictions regarding the collective rationality of procedures satisfying several such axioms, or in the case wherethe integrity constraints can be chosen from a more complex language.Consider the case of two characterisation results CR[L1] = FL1[AX2]. By part (ii) of Lemma 7[AX1] and CR[L2] = FL2and by FL1∪L2[AX1, AX2] ⊆ FL1[AX1] ∩ FL2[AX2] we can infer that:FL1∪L2[AX1, AX2] ⊆ CR[L1 ∪ L2](But note that the other inclusion is not always true.) This entails that if we express constraints in the language L1 ∪ L2 orin any of its sublanguages, then picking procedures from FL1∪L2[AX1, AX2] is a sufficient condition for collective rationality.If, instead, we start from a class of procedures satisfying axioms AX1 and AX2 on the language L1 ∪ L2 then we can inferthat these procedures lift any language L ⊆ L1 ∪ L2, since as we previously observed FL1∪L2[AX1, AX2] is included inCR[L1 ∪ L2], which in turn is included in CR[L].5. Characterisation results for classical axiomsIn the previous section we proved several characterisation results for various simple fragments of the propositionallanguage associated with an aggregation problem. In this section we shift our focus from syntactic descriptions of languagesto axiomatic properties of aggregation procedures, having the axioms as variables when exploring the possibility for acharacterisation result. We first show that for most characterisation results proved in the previous section the domainrestriction given by the language L can be dropped, thus obtaining characterisation results for classical axioms from SCT.Then, we prove a negative result involving the axioms of anonymity, independence, and both forms of monotonicity, showingthat a characterisation result cannot be proved for these axioms.9 An analogous definition was given by Cariani et al. [5] in the context of judgment aggregation, under the name of rolling dictatorships.U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66575.1. Characterisation of axiomsConsider the class F [AX], dropping the subscript L, as representing the class of procedures that defines an axiom. Forevery domain restriction, we know that F [AX] ⊆ FL[AX]. As anticipated at the end of Section 3.2, most of the characterisa-tion results presented in the previous section can be proved without the restriction on L on the right-hand side, becomingtherefore characterisations of classical axioms:Corollary 18. The following equivalences hold:(i) F [U] = CR[literals].I ] = CR[L↔].(ii) F [ND] = CR[LXOR].(iii) F [NProof. Refer to Theorems 10, 12 and 13. For all three classes we prove that FL[AX] = F [AX], for the relevant axiom andlanguage. This can be seen by observing that, in the three cases under consideration, the condition required by the axiom isa vacuous requirement outside domains defined by formulas in L. Therefore, if a procedure satisfies an axiom on domainsdefined by L then it also satisfies the same axiom on the full domain. (cid:2)5.2. Negative resultsResults such as the one proved in the previous section cannot be proved for other important axioms, for which it isnot possible to obtain a characterisation result. In this section we prove a negative result for the axioms of independence,anonymity and both formulations of monotonicity. We first prove the following proposition. Recall that LF [G] is the setof integrity constraints lifted by all the aggregation procedures in G, and let L(cid:10),⊥ be the language for integrity constraintsgenerated by {(cid:10), ⊥}.Proposition 19. The following hold:(cid:7)(cid:8)F[I](cid:7)(cid:8)F[A]= LFLF= LF(cid:8)(cid:8)(cid:7)F(cid:7)MI= LF(cid:8)(cid:8)(cid:7)F(cid:7)MN= L(cid:10),⊥Proof. We prove this proposition by constructing for any contingent formula ϕ (i.e., such that both ϕ and ¬ϕ are satisfiable)an independent, anonymous and monotonic procedure that is not collectively rational with respect to ϕ. Let ϕ be such aformula, and let B(cid:8) ∈ D be a ballot such that B(cid:8) (cid:13)|(cid:14) ϕ. Consider now the constant procedure F (B) = B(cid:8) for all profiles B:this procedure is independent, anonymous and monotonic, but it is not collectively rational with respect to ϕ. (cid:2)An immediate corollary of this result is that it is not possible to obtain a characterisation of these axioms in terms ofcollective rationality:Corollary 20. There is no language for integrity constraints L ⊆ LPS such that CR[L] = F [I]. The same holds for F [A], F [MI] andF [MN].Proof. By Proposition 9, in the presence of a characterisation result the set of integrity constraints lifted by a class of proce-dures is uniquely determined. Suppose then that CR[L] = F [AX] for AX ∈ {I, A, MI, MN} and for a certain L. Proposition 19forces L to be equal to L(cid:10),⊥, but we have already proven that this class characterises the whole set of procedures F (cf.Proposition 15 combined with Lemma 7). Therefore, such a characterisation cannot exist. (cid:2)Note that this argument can be generalised to prove that the class FL[I] (and the same holds for A, MI and MN) cannotbe characterised for any restriction given by a language L. It is sufficient to note that the constant procedure employed inthe proof of Proposition 19 is defined regardless of the domain restriction.Our interest in these axioms does not cease here. On the contrary, the last two results showed that the classes ofmonotone, independent and anonymous procedures behave in the same way as the full class F of all aggregation proceduresfor what concerns collective rationality. This suggests that interesting characterisations can be studied inside those classes,replacing the set F with, e.g., the class F [I]. We are going to pursue a similar approach in the following section by focusingon the class F [A, I, MI], i.e., the class of quota rules.6. Quota rules and languages of clausesThis section is devoted to a thorough exploration of the classes of collectively rational procedures for several languagesof clauses inside the class of quota rules. In Section 6.1 we begin by characterising quota rules that are collectively rationalwith respect to positive or negative clauses, i.e., clauses in which literals are either all positive or all negative. Then in58U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66Section 6.2 we focus on arbitrary clauses of size 2, showing that this class coincides with the set of integrity constraintsthat are lifted by the majority rule. Finally, in Section 6.3 we provide a general result which characterises quota rules thatare collectively rational with respect to an arbitrary clause of a given size.We introduced quota rules in Section 2.5 as procedures assigning a quota q j to every issue j so that F (B) j = 1 ⇔ |{i |bi, j = 1}| (cid:3) q j . In the same section we also proved that quota rules are axiomatised as the class of independent, anonymousand monotone procedures. If we denote with QR the set of quota rules, then we can write QR = F [A, I, MI]. Recall that if|N | = n, quotas q j are integers between 0 and n + 1, the two extreme cases of q j = 0 and q j = n + 1 being the two constantrules that output, respectively, 1 and 0.There are several reasons why the choice of quota rules and languages of clauses constitutes an interesting combina-tion. First, since we have proven in Section 5 that no characterisation result is possible neither for independent, nor foranonymous, nor for monotonic procedures, it is important to explore classes of collectively rational procedures inside thoseclasses. As remarked earlier, by combining all three axioms together we obtain the set of quota rules. Second, languages ofclauses are the most expressive ones, ranging from literals, to implications, to the full expressivity of LPS. By Corollary 17we know that to obtain interesting results it is necessary to limit either the size or the shape of the clauses that build upa language for integrity constraints. In this section we concentrate on languages defined by bounding the size of clauses,and quota rules seem a perfect candidate to deal with such restrictions, as they allow us to play with quotas and constrainthem with equations. Clauses of limited size are of interest in the modelling of several applications, e.g., for limiting clustersize in graph aggregation [13], or for bounding the number of premises in Horn formulas.We will assume for the rest of this section that the number of issues is always strictly bigger than the limitation on thesize of a clause. This is because in case the number of issues is smaller or equal than the bound on clauses this limitationis fictitious. For k (cid:3) 1, we define an exact k-clause as a clause of length k, i.e., a clause in which exactly k propositionalsymbols occur either positively or negatively but not both.10 A k-clause is a clause of size at most k. A k-pclause is apositive k-clause, i.e., a disjunction where all literals are positive, and a k-nclause is a negative k-clause, where all literalsare negative. Given a clause ϕ = (cid:7)1 ∨ · · · ∨ (cid:7)k, we say that an issue j occurs in ϕ if one and only one of p j and ¬p j is one ofthe literals of ϕ. For instance, the following formula p ∨ q ∨ ¬p ∨ ¬r ∨ ¬r is a 2-clause in which two propositional symbolsq and r occur, while p occurs in a spurious way and does not add to the length of the clause.6.1. Positive and negative clausesWe start by studying the special case of positive and negative clauses of arbitrary size, obtaining necessary and sufficientconditions for quota rules to lift such constraints, and exploring characterisation results inside these classes.Proposition 21. A quota rule is CR for an exact k-pclause ic if and only ifand n being the number of individuals, or q j = 0 for at least one issue j that occurs in ic.j q j < n + k, with j ranging over all issues that occur in ic(cid:9)Proof. Suppose ic = p1 ∨ · · · ∨ pk and call i1, . . . , ik the corresponding issues. Given that ic is a positive clause, the only wayto generate a paradox is by rejecting all issues i1, . . . , ik. It is easy to see that this cannot occur if the quota for one of theseissues is 0. We can therefore assume that all quotas are positive.Suppose now that we can create a paradoxical profile B. Every individual ballot B i must accept at least one issue tosatisfy the integrity constraint; therefore the profile B contains at least n acceptances concerning issues i1, . . . , ik. On theother hand, since F (B) j = 0 for all j = 1, . . . , k, we have that the number of individuals accepting an issue j is strictly lowerthan q j . As previously remarked, there are at least n acceptances on the profile B and the maximal number of acceptances(cid:9)that allows rejection on all issues isj aredistinct, thus we can construct a paradox with our ic if and only if this inequality holds. By taking the contrapositive weobtain the statement of Proposition 21. (cid:2)j(q j − 1). This is equivalent to n + k (cid:2)j(q j − 1). Hence n (cid:2)jq j , since all(cid:9)(cid:9)With a similar proof we get an analogous result for negative clauses. Both Propositions 21 and 22 can be obtained ascorollaries of a general result we shall prove in Section 6.3 (see Theorem 30). For a more detailed proof of the followingproposition we refer to our previous work [18].Proposition 22. A quota rule is CR for an exact k-nclause ic if and only ifin ic and n being the number of individuals, or q j = n + 1 for at least one issue j that occurs in ic.j q j > (k − 1)n, with j ranging over all issues that occur(cid:9)In case k = 1, i.e., the case of aggregators lifting both literals p j and ¬p j , we obtain q j < n + 1 from Proposition 21 andq j > 0 from Proposition 22, thus forcing the rule to be unanimous on issue j (quota rules satisfying 1 (cid:2) q j (cid:2) n for all j areunanimous). This is consistent with our Theorem 10.We now want to turn these results into characterisation results in the line of those proved in Section 4. We first have todefine languages of clauses from our definition of clauses of a limited size. Let k-pclauses and k-nclauses denote, respectively,10 This is to exclude from the count redundant subformulas of a clause like p j ∨ p j or p j ∨ ¬p j .U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–6659the language for integrity constraints generated from positive (negative) clauses of size (cid:2) k. Denote by QRe(q j ) the set ofquota rules such that all quotas q j for j ∈ I satisfy the equation in the subscript. The function (cid:19)x(cid:20) is defined as the smallestinteger greater than or equal than x. We prove the following corollary of Propositions 21 and 22:Corollary 23. The following inclusions are true:(i) QR(ii) QRq j (cid:2)(cid:19) nkq j (cid:3)n−(cid:19) nk(cid:20) ⊆ CR[k-pclauses].⊆ CR[k-nclauses].(cid:20)+1Proof. The first result is a consequence of Proposition 21 and the fact that (cid:19) nk(cid:19) nsubset of k issues that might occur in a k-pclause we have thatkj q j (cid:2)(cid:9)(cid:9)j(cid:20) < n(cid:9)k(cid:20) <(cid:9)Analogously, referring this time to Proposition 22, we have that for any set of k issuesj(n − n− 1 + 1) = (k − 1)n. (cid:2)k+ 1. If all quotas q j (cid:2) (cid:19) nk+ 1) = n + k.j( n(cid:9)j q j (cid:3)(cid:9)k(cid:20) then for anyj(n − (cid:19) nk(cid:20) + 1) >The significance of the previous result resides in the fact that the bounds given by those equations are the lowest uniformbounds we can give to quotas to guarantee collective rationality, as we prove in the following corollary:Corollary 24. A uniform quota rule is CR with respect to:(i) a k-pclause if and only if q (cid:2) (cid:19) nk(ii) a k-nclause if and only if q (cid:3) n − (cid:19) nk(cid:20);(cid:20) + 1.(cid:9)Proof. (i) In the case of uniform quota rules the equation in Proposition 21 takes the following form:This holds if and only if q < nk+ 1, which is equivalent, as remarked in the proof of the previous corollary, to q (cid:2) (cid:19) n(cid:20).k(ii) In the same way, using a single quota in the equation of Proposition 22 we obtain kq > (k − 1)n, i.e., q > n − nk whichj q = kq < n + k.is equivalent to q (cid:3) n − (cid:19) nk(cid:20) + 1. (cid:2)Note that the two equations in the previous proposition are incompatible, except for the cases of k = 1, as observed after2 . This proves that no uniform quota rule is collectively2 . ThisProposition 22, and k = 2 with n being odd, in which case q = n+1rational on both positive and negative clauses of a given size larger than 2, except for the case of n odd and q = n+1quota rule is known as the majority rule, and it is now time to study this procedure in more detail.6.2. Clauses of size 2: the majority ruleThe majority rule is the uniform quota rule that accepts an issue whenever there are more individuals accepting theissue than rejecting it. The majority rule is perhaps one of the most natural aggregation rules. It is arguably the one that isused most in practical applications, but as we noted in Section 1, it also generates a plethora of paradoxical situations thathave been widely studied in the literature.In case the number of individuals is odd, the majority rule has a unique definition by setting the quota to q = n+12 . AsIwe have seen in Section 2.5, in this case the majority rule is axiomatised by A, I, MI, Nfor the case of more thantwo issues. The case of an even number of individuals is more problematic, to account for profiles in which exactly halfof the individuals accept an issue and exactly half reject it. We give two different definitions. The weak majority rule withquota q = n2 accepts an issue if and only if at least half of the individuals accepts it. The strict majority rule accept an issueif and only if a strict majority of the individuals accept it, i.e., it is the uniform quota rule with quota q = n+22 . The first rulefavours acceptance, while the second favours rejection of an issue. In the following sections we will characterise for each ofthe two cases the set of integrity constraints that are lifted by the corresponding definition of the majority rule.and ND6.2.1. Odd number of individuals: the majority ruleIn this section we make the assumption that the number of individuals is odd, and we indicate with Maj the uniform2 . We make the additional assumption that there are at least 3 individuals. The majority rulequota rule with quota q = n+1in the case of 1 individual is the identity function that outputs the ballot received by the only individual.Let us begin with a base-line result that proves collective rationality of the majority rule in case the integrity constraintis equivalent to a conjunction of 2-clauses:Proposition 25. The majority rule is in CR[2-clauses].Proof. Let us first consider the case of a single 2-clause ic = (cid:7) j ∨ (cid:7)k, where (cid:7) j and (cid:7)k are two literals, i.e., atoms ornegated atoms. A paradoxical profile for the majority rule with respect to this integrity constraint features a first majority of60U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66individuals not satisfying literal (cid:7) j , and a second majority of individuals not satisfying literal (cid:7)k. By the pigeonhole principlethese two majorities must have a non-empty intersection, i.e., there exists one individual that does not satisfy both literals(cid:7) j and (cid:7)k, but this is incompatible with the requirement that all individual ballots satisfy ic. To conclude the proof, it issufficient to observe that if ic is equivalent to a conjunction of two clauses, then all individuals satisfy each of these clauses,and by the previous discussion all these clauses will also be satisfied by the outcome of the majority rule. (cid:2)An easy corollary of this proposition covers the case of just 2 issues:Corollary 26. If |I| (cid:2) 2, then the majority rule is in CR[LPS].Proof. This follows immediately from Proposition 25 and Lemma 3. Every given ic for two issues can be put in conjunctivenormal form. Since the domain features at most two issues there are only two propositional symbols in the propositionallanguage and thus the normal form consists of a conjunction of clauses of size at most 2. (cid:2)Many of the classical paradoxes involving the majority rule can be formalised in our framework by means of an integrityconstraint that consists of (or is equivalent to) one or more clauses with size bigger than two [19]. As an example, considerthe requirement of transitivity in preference aggregation, that in our framework is the integrity constraint pab ∧ pbc → pac ,which is equivalent to a clause of size 3. The paradoxical situation we described in the introduction constitutes anotherexample, in which by using an exact 3-clause ¬T 1 ∨ ¬T 2 ∨ A as a rationality assumption we derived a paradoxical situationusing the majority rule. We now generalise this observation to a theorem that completes the characterisation of the integrityconstraints lifted by the majority rule, proving that these are all and only those formulas that are expressible as conjunctionsof 2-clauses. We need some preliminary definitions and a lemma.Call a minimally falsifying partial assignment (mifap-assignment) for an integrity constraint ic an assignment to some ofthe propositional variables that cannot be extended to a satisfying assignment, although each of its proper subsets can.We first prove a crucial lemma about mifap-assignments. Given a propositional formula ϕ, associate with each mifap-assignment ρ for ϕ a conjunction Cρ = (cid:7)1 ∧ · · · ∧ (cid:7)k, where (cid:7)i = pi if ρ(pi) = 1 and (cid:7)i = ¬pi if ρ(pi) = 0 for all propositionalsymbols pi on which ρ is defined. The conjunction Cρ represents the mifap-assignment ρ and it is clearly inconsistentwith ϕ.11Lemma 27. Every non-tautological formula ϕ is equivalent to ((cid:5)ρ¬Cρ ) with ρ ranging over all mifap-assignments of ϕ.Proof. Let A be a total assignment for ϕ. Suppose A (cid:13)|(cid:14) ϕ, i.e., A is a falsifying assignment for ϕ. Since ϕ is not a tautologythere exists at least one such A. By sequentially deleting propositional symbols from the domain of A we eventually find amifap-assignment ρ A for ϕ included in A. Hence, A falsifies the conjunct associated with ρ A , and thus the whole formula(cid:5)(¬Cρ ). Then there exists a ρ such that A |(cid:14) Cρ . This implies that ρ ⊆ A, as Cρ is aconjunction. Since ρ is a mifap-assignment for ϕ, i.e., it is a falsifying assignment for ϕ, this contradicts the assumptionthat A |(cid:14) ϕ. (cid:2)ρ¬Cρ ).ρAssume now A |(cid:14) ϕ but A (cid:13)|(cid:14) ((cid:5)We are now able to provide a full characterisation of the set of integrity constraints that are lifted by the majority rulein case the set of individuals is odd12:Theorem 28. LF[Maj] = 2-clauses.Proof. One direction is entailed by Proposition 25: the majority rule is CR with respect to conjunctions of 2-clauses.For the opposite direction assume that ic /∈ 2-clauses, i.e., that ic is not equivalent to a conjunction of 2-clauses. We now¬Cρ ofhas size > 2, for otherwise icbuild a paradoxical profile for the majority rule. By Lemma 27 we know that ic is equivalent to the conjunctionall mifap-assignments ρ for ic. We can therefore infer that at least one mifap-assignment ρ∗would be equivalent to a conjunction of 2-clauses.Consider now the following profile. Let y1, y2, y3 be three propositional variables that are fixed by ρ∗. Assume that thereare at least 3 individuals. Let the first individual i1 accept the issue associated with y1 if ρ( y1) = 0, and reject it otherwise,on the remaining propositional variables. By minimality of ρ∗i.e., let b1,1 = 1 − ρ∗( y1). Furthermore, let i1 agree with ρ∗,(cid:5)ρ11 The notion of mifap-assignment corresponds to what are called minimally inconsistent sets in the judgment aggregation literature [29]. For a detaileddiscussion of the relationship between binary aggregation and judgment aggregation, we refer to our previous work [21,18]. Formulas ¬Cρ associated withmifap-assignments ρ for ic are also known as the prime implicates of ic [30]. Lemma 27 is a reformulation of the known result that a formula is equivalentto the conjunction of its prime implicates.12 This result may be considered a “syntactic counterpart” of a result by Nehring and Puppe [32], in which it is proved that in the framework of judgmentaggregation the majority rule will output a consistent outcome if and only if the set of formulas under consideration satisfies what is called the medianproperty, i.e., that no minimally inconsistent subsets of size (cid:3) 3 can be constructed from such formulas.U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–6661Table 2A paradoxical profile for the majority rule.i1i2i3Majy11-ρ∗( y1)ρ∗( y1)ρ∗( y1)ρ∗( y1)y2ρ∗( y2)1-ρ∗( y2)ρ∗( y2)ρ∗( y2)y3ρ∗( y3)ρ∗( y3)1-ρ∗( y3)ρ∗( y3)this partial assignment can be extended to a satisfying assignment for ic, and let B i1 be such an assignment. Repeat thesame construction for individual i2, this time changing the value of ρ∗on y2 and extending it to a satisfying assignment toobtain B i2 . The same construction for i3, changing the value of ρ∗on issue y3 and extending it to a satisfying assignmentB i3 . If there are other individuals in N , let individuals i3s+1 have the same ballot B i1 , individuals i3s+2 ballot B i2 andindividuals i3s+3 ballot B i3 . The basic profile for 3 issues and 3 individuals is shown in Table 2.As can be seen from the table, and easily generalised to the case of more than 3 individuals, there is a majority support-is a mifap-assignment and therefore cannot be extended to aning ρ∗assignment satisfying ic, the majority rule in this profile is not collectively rational with respect to ic. (cid:2)on every variable on which ρ∗is defined. Since ρ∗Recall that this result does not give rise to a characterisation result, i.e., it does not imply that CR[2-clauses] = {Maj} (cf.Proposition 9). On the contrary, the class CR[2-clauses] includes all generalised dictatorships. We will provide a characteri-sation of this class inside the class of quota rules in Section 6.3.6.2.2. Even number of individuals: weak majority and strict majorityIf the aggregation problem features an even number of individuals the majority rule can take two forms, as we haveobserved at the beginning of Section 6.2. Recall that the weak majority rule (W-Maj) is the uniform quota rule with quota2 while the strict majority rule (S-Maj) has quota q = n+2q = n2 .The main difference to an odd number of individuals is that both the weak and the strict majority rule do not satisfy.13 For what concerns the behaviour with respect to collective rationality, we can proveDthe axiom of domain-neutrality Nthe following proposition:Proposition 29. W-Maj and S-Maj are CR with respect to L+W-Maj is CR with respect to 2-pclauses. S-Maj is CR with respect to 2-nclauses.→ (i.e., 2-clauses in which one literal is negative and one is positive).Proof. A closer inspection of the proof of Proposition 25 reveals that the case for mixed clauses is also applicable for aneven number of individuals. Equivalently, we could get the same result from Theorem 14, since both W-Maj and S-Maj satisfyissue-neutrality and neutrality-monotonicity. The second part of the proposition is a direct consequence of Corollary 24. (cid:2)Unfortunately, a result analogous to Theorem 28 for the case of an even number of individuals cannot be proved. Wetherefore refer to the more general result about uniform quota rules proved in the following section (Corollary 31).6.3. General clausesIn this section we present a general result for the collective rationality of an arbitrary quota rule with respect to anarbitrary k-clause. This result generalises our previous results concerning positive and negative clauses, and clauses of size 2.At the end of the section we prove some conclusive characterisations for collectively rational procedures inside the class ofquota rules. We prove the following general result for arbitrary k-clauses14:Theorem 30. A quota rule is CR with respect to an exact k-clause ic if and only if(cid:10)(cid:10)q j +j negativej positive(n − q j + 1) > n(k − 1)(1)for issues j that occur positively or negatively in ic, or q j = 0 for some issue j that occurs positively in ic, or q j=n + 1 for issue j thatoccurs negatively in ic.Proof. The case of quota rules being constant on one of the issues (i.e., the case q j = 0, n + 1) is straightforward. We cantherefore assume that all quotas are 0 < q j < n + 1. Suppose now that we can generate a paradoxical profile B for the13 Since they are both uniform quota rules, they still satisfy I, A, Nand MI.14 This proposition corresponds to a result proved by Dietrich and List [10, Theorem 2c] for quota rules in the framework of judgment aggregation.I62U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66Table 3A paradoxical profile for general clauses.i1i2...inFj1CW...WWj2WW...CW. . .. . .. . .. . .. . .jkWC...WWk-clause ic. The only way to falsify the integrity constraint is to output an assignment F (B) that rejects all issues thatoccur positively in ic and accepts all the ones that are negative. We therefore concentrate our attention to the subprofile Bkdefined by restricting the individual ballots to the k issues occurring in ic.Since individual ballots are rational, there are at least n “correct” symbols in this subprofile, i.e., a 1 for a positive issue ora 0 for a negative one. We refer to such entries with a C in Table 3. We now want to count how many “wrong” symbols arepresent in this subprofile. As B is a paradoxical profile, all issues that occur negatively in ic have to be accepted. Therefore,for each of those issues at least q j individuals have the wrong symbol, in this case a 1. For the same reason, every issuethat occurs positively in ic is rejected, so the profile Bk contains at least n − q j + 1 individuals rejecting such issue.Summing up, since the number of cells in this subprofile is nk, we can generate a paradoxical profile if and only ifthere are enough cells in Bk to account for the minimal number of correct and wrong symbols to generate a paradox. Thisturns into the equation n +j neg q j (cid:2) nk. By taking the contrapositive of the last statement we getEq. (1). (cid:2)j pos(n − q j + 1) +(cid:9)(cid:9)It is easy to see that the special cases of positive and negative clauses, i.e., our Propositions 21 and 22, can be obtainedas corollaries of Theorem 30. The special case of uniform quota rules is particularly interesting:Corollary 31. A uniform quota rule with q (cid:13)= 0, n + 1 is CR with respect to a k-clause ic if and only if(k2 − k1)q > n(k2 − 1) − k1where k1 (respectively k2) is the number of positive (negative) issues in ic.(2)Our Corollary 24 can be proved as the special case of k1 = k and k1 = 0, respectively. The other special case of k1 = k2leads to a satisfiable equation only in case of k = 2, proving two important facts: First, every uniform quota rule lifts a2-clause in which one issue is positive and the other is negative, for the equation in this case is always true (it reducesto 0 > −1). More importantly, it implies that CR[k-clauses] does not contain any uniform quota rule for k > 3 when thenumber of issues is even, since this language includes also k-clauses where exactly half of the issues are negative and halfare positive, in which case the equation does not have any solutions.We are now ready to prove a characterisation analogous to that of Theorem 28 for uniform (non-constant) quota rules:Proposition 32. Let q be different from 0, n + 1, and let Fq be the corresponding uniform quota rule. Then, LF [Fq] is the language forintegrity constraints generated from all k-clauses that satisfy Eq. (2).(cid:5)Proof. Let ic be an integrity constraint. By Lemma 27, ic is equivalent to the conjunction of the negation of its mifap-¬Cρ . Hence, Fq is CR with respect to ic if and only if Fq lifts each clause Cρ , and by Corollary 31 thisassignmentsholds if and only if each Cρ satisfies Eq. (2). Thus, Fq is CR with respect to ic if and only if ic is equivalent to a conjunctionof clauses satisfying Eq. (2). (cid:2)ρUsing the equations introduced in this section we are able to prove some interesting results about the characterisationof collectively rational procedures inside the class of quota rules. We have already seen some partial inclusion in Section 6.1for the language of positive and negative clauses, and we can now prove the following:Proposition 33. If the number of individuals is odd, then CR[2-clauses] ∩ QR = {Maj}.Proof. Let q1 and q2 be two quotas for two distinct issues. Since we assume that every 2-clause is lifted, these two quotassatisfy the following system of equations, obtained by instantiating Eq. (1) to the case of positive, negative, and mixed2-clauses:q1 + q2 < n + 2U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–6663q1 + q2 > nq1 + n − q2 + 1 > nq2 + n − q1 + 1 > nFrom the first two equations we obtain q1 + q2 = n + 1, since quotas are integers. From the other equations we obtain(cid:20), thus obtaining the|q1 − q2| < 1, which for integer values entails q1 = q2. We can then conclude that q1 = q2 = (cid:19) n+1majority rule. (cid:2)2We end this section by proving an expected negative result for the characterisation of general languages of clauses insidethe class of quota rules:Proposition 34. CR[k-clauses] ∩ QR = ∅ for all k > 2.Proof. A quota rule in CR[k-clauses] must be CR with respect to both positive and negative clauses, therefore both equationsin Propositions 21 and 22 have to be satisfied. But these are unsolvable for k > 2. To see this, consider the first equation,q j > (k − 1)n on thewhich forcessame subsets. These two equations are compatible only if (k − 1)n < n + k, from which we obtain n < kk−2 . This in turn istrue only if n < 3, in contradiction to our assumption that there are at least 3 individuals. (cid:2)q j < n + k for any subsets of issues of size k, and the second equation requiring(cid:9)(cid:9)Observe that the equations involved in this proof do not assume that clauses have size strictly smaller than k, hence thisresult can be strengthened to the language of clauses of size exactly k.7. DiscussionIn this section we shall discuss the impact of the results of the present paper on both SCT and AI, summarising alsosome of the results presented in our previous work [21,19,18].Preference aggregation [3] and judgment aggregation [29] are amongst the main frameworks for aggregation that arestudied in SCT and AI, and the relation between these two frameworks is the object of study of several publications [9,22,37]. As previously shown in Examples 1 and 2, both frameworks can be interpreted as instances of binary aggregationby devising suitable integrity constraints. This fact already constitutes a contribution in itself, showing that our setting is atruly general framework for the study of collective rationality in aggregation theory.Classical studies in these frameworks have focused on the observation of paradoxical situations and on proving so-calledimpossibility results, aimed at showing the impossibility of non-paradoxical aggregation under seemingly natural axiomaticconditions. It can be easily seen that classical paradoxes, such as the Condorcet paradox in preference aggregation andthe discursive dilemma in judgment aggregation [25], can be viewed as instances of our Definition 4, which stands out as ageneral definition of paradox in aggregation theory [19]. Moreover, as we shall explain next, the generality of our frameworkenables us to develop a new proof method for (im)possibility results in SCT. Classical work in SCT studies the existence ofaggregation procedures in a given framework for aggregation, once a set of desirable conditions have been identified in alist of axiomatic properties. By translating such aggregation problems into binary aggregation, we are able to identify thesource of impossibilities in a clash between the integrity constraint that defines the framework and the axiomatic propertiesthat are being required, making use of characterisation results such as those we presented in this paper. The results that canbe obtained by using this proof method may share similarities or may be weaker than known results from the literature onSCT, especially for the case of independent aggregation rules. However, the focus is not on the novelty or strength of specificresults, but rather on the generality and flexibility of the proof method we put forward. By unifying proofs in aggregationtheory we gain a deeper understanding of the common problem behind many classical results: impossibilities arise fromclashes between axiomatic properties and requirements of collective rationality.We provided several examples of the use of this method in previous work [21,18], and we now sketch one such findingfor the case of preference aggregation. Recall that aggregation procedures in preference aggregation are called social welfarefunctions [3], and that they associate a collective preference with every profile of individual orders over a set of alternativesX . Axiomatic properties such as those presented in Section 2.4 can be devised for social welfare functions, and we refer tothe relevant literature for their precise definition [17]. We call a social welfare function imposed if for some pair of distinctalternatives a and b we have that a is always collectively preferred to b in every profile. We show the following proposition(a more detailed proof can be found in our previous work [21,18]):Proposition 35. If |X | (cid:3) 3 and |N | (cid:3) 2, then any anonymous, independent and monotonic social welfare function for X and N isimposed.Proof. The first step is to move from preference aggregation to binary aggregation, as outlined in our Example 2 of Sec-tion 2.2. This embedding can be extended to aggregation procedures: every anonymous, independent and monotonic social64U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66welfare function corresponds to a binary aggregation procedure that is collectively rational for ic< and that satisfies A, Iand MI. Recall that by Proposition 1, every aggregation procedure satisfying A, I and MI is a quota rule.The second step consists in checking whether the axiomatic requirements clash with the integrity constraint underconsideration. In this case the answer is positive: by exploiting some of the characterisation results proved in Section 6 wenow prove that, if a quota rule is collectively rational for ic<, then it is imposed, i.e., at least one of the quotas qab is equalto 0. Suppose, for the sake of contradiction, that every quota qab > 0. For any three alternatives a, b, c ∈ X , the integrityconstraints corresponding to transitivity can be shown to be equivalent to pba ∨ pcb ∨ pac and pab ∨ pbc ∨ pca. These arepositive clauses of size 3; thus, by Proposition 21 we obtain the following inequalities on quotas: qba + qcb + qac < n + 3 andqab + qbc + qca < n + 3. Furthermore, the requirements of completeness and antisymmetry of linear orders force the quotasto satisfy the following additional equations: qab + qba = n + 1, qbc + qcb = n + 1 and qac + qca = n + 1. Now, adding the twoa,b∈X qab = 3n + 3. The twoa,b∈X qab < 2n + 6 and adding the three equalities we obtaininequalities we obtain thatconstraints together admit a solution only if n < 3. Thus, it remains to analyse the case of 2 individuals; but it is easy to seethat our constraints do not admit a solution in positive integers for n = 2. This shows that there must be a quota qab = 0for certain distinct a and b as soon as n (cid:3) 2; hence, the quota rule is imposed.(cid:9)(cid:9)Finally, going back to the initial problem, we can conclude that every anonymous, independent and monotonic socialwelfare function for more than 3 alternatives and 2 individuals is imposed. (cid:2)Similar results can be obtained in the framework of judgment aggregation. In previous work we were able to strengthena known characterisation of safe agendas [14] by moving to the realm of binary aggregation and by developing syntacticanalogues of the conditions that guarantee consistent aggregation of judgments on a given set of propositional formulas[21,18].One further reason supporting the use of binary aggregation with integrity constraints in applications related to AI hasto do with considerations of computational complexity. In recent years the framework of judgment aggregation has receivedincreasing attention in the AI community, especially in its applications to the modelling of multiagent systems. In previouswork we presented a preliminary comparison of the computational complexity of both frameworks for a number of basictasks, showing that binary aggregation is at most as hard as classical judgment aggregation, and it is significantly easierin some situations [18]. The most simple example is the problem of checking the rationality of a given ballot: While forbinary aggregation this problem can be solved in polynomial time using model checking, in judgment aggregation the sameproblem corresponds to the satisfiability of the set of propositional formulas accepted by one of the agents, a much harderproblem which is known to be NP-complete.Another interesting application is suggested by our Theorem 16. This result identifies an attractive class of aggregationprocedures in the class of generalised dictatorships, obtaining procedures that lift all integrity constraints expressible in thelanguage of propositional logic. Interesting procedures can therefore be defined by deciding which of the individual ballotsbest represent the ballots submitted in a given profile. Inspired by related work in the literature on belief merging [23], inprevious work we introduced a new aggregation rule which given a profile B selects those individual ballots that minimisethe sum of the Hamming distances from the other individual ballots in B. Formally, theaverage-voter rule 15 (AVR) is thefollowing non-resolute16 aggregation procedure:(cid:10)H(B i, B i(cid:8) )AVR(B) = argmin{B i |i∈N }(cid:9)i(cid:8)∈Nj∈I |b j − b(cid:8)j(cid:8)) =| is the Hamming distance between binary ballots. Besides being collectively rational forwhere H(B, Bevery rationality assumption, this rule also enjoys interesting axiomatic and computational properties [21,18]. This ruleadds to a growing literature on the development of aggregation procedures for binary and judgment aggregation inspiredby AI techniques [35,27].8. Related workWhile the framework of binary aggregation is well-known in the literature on SCT, this paper is the first systematic studyof collective rationality with respect to languages for integrity constraints in this setting. Moreover, classical approachesconcentrate on Arrovian aggregation procedures, i.e., procedures that are both unanimous and independent, while most ofour characterisation results do not make such restrictive assumptions. As we have argued before, while the restriction toArrovian aggregators is in line with standard assumptions in economics, those assumptions are not always justified in AIapplications. In this section we review some of the classical approaches to the problem of collective rationality that can befound in the literature.Wilson [40] has been the first to define and study the framework of binary aggregation, in order to obtain an impossi-bility result for independent aggregation procedures that generalises the more famous result by Arrow [3]. This setting has15 This rule is called distance-based generalised dictatorship in our previous work [21].16 That is, it associates with every profile a set of binary ballots rather than a single one. Non-resolute aggregators can be made resolute by the introductionof a tie-breaking rule, e.g., a lexicographic ordering over the domain D.U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–6665been investigated more recently by Dokow and Holzman [11] and Nehring and Puppe [33]. In the former work, the authorsstudy the existence of independent, unanimous and non-dictatorial procedures that are collectively rational with respectto certain domain restrictions. As we have remarked at the beginning of this section, our work differs in that we do notconcentrate on independent aggregation procedures. Moreover, we exploit our representation of constraints as propositionalformulas by defining languages for integrity constraints in a syntactic way, while Nehring and Puppe [11] use a model-basedapproach: they assume that the set of rational ballots is specified explicitly.Results in line with our work of Section 6 can be obtained by restricting the set of aggregation procedures to independentrules alone, focusing on the study of winning coalitions, i.e., those subsets of N that can force acceptance on a given issue.Results in this setting have been proven in the case of judgment aggregation by Nehring and Puppe [32] and generalised byDietrich and List [10], giving conditions on the structure of winning coalitions to guarantee collective rationality.As we already remarked in several places throughout the paper, many of the results on quota rules proved in Section 6are analogous to those proved by Dietrich and List [10] in the framework of judgment aggregation. The use of integrityconstraints, however, enables us to use syntax to analyse possible sources of impossibility, resulting in a flexible frameworkthat is arguably easier to implement.A related field of research is that of belief merging [23,24], in which sets of propositional formulas are aggregated into acollective set. The two frameworks share interesting features, but study different (although related) problems. While binaryaggregation imposes an integrity constraint as a rationality assumption for both individual and collective outcomes, in beliefmerging integrity constraints are enforced only on the outcome. This reflects the view that the integrity constraint is afeasibility requirement rather than a rationality assumption, and should not be enforced on individual preferences or beliefs.Nevertheless, exploring possible ways of combining the two settings constitutes an interesting direction for future work.9. Conclusions and perspectivesIn this paper we have presented a general framework for the study of collective rationality in aggregation theory. Ourframework is based on binary aggregation, in which a group of individuals each express a ballot in a binary multi-issuedomain, and these ballots are then aggregated into a collective one. The generality of this setting allowed us to modelimportant problems in multiagent systems such as multi-issue elections, preference aggregation, judgment aggregation, andthe problem of choosing from a set of candidates. We have formalised rationality assumptions using a simple propositionallanguage, which enables us to classify such formulas in a syntactic way. Depending on the syntactic properties of therationality assumptions at hand we have then investigated the problem of collective rationality: how can we guarantee,by means of classical axiomatic properties, that the outcome of the aggregation satisfies the same rationality assumptionas the individual ballots? We have also studied the opposite problem: we have characterised, given a classical axiomaticrequirement for aggregation procedures, the set of integrity constraints that are lifted by all procedures satisfying suchproperties. In the last part of the paper we have concentrated on quota rules, i.e., procedures defined by means of acceptancequotas for every issue, and especially on the majority rule, obtaining complete characterisations of the set of integrityconstraints lifted by such procedures. Our results provide a systematic answer to the question of recognising domains ofaggregation over which paradoxes can be avoided, reducing this problem to the syntactical analysis of the propositionalformulas that define rationality assumptions. Not only does this allow for a uniform analysis of such diverse problemsas preference aggregation, judgment aggregation and multi-issue elections in general, but it also has the advantage ofexpressing properties in a computation-friendly language such as propositional logic.This paper constitutes a first step towards a general application-oriented theory of aggregation, a topic that is crucial tothe development of several AI applications and, above all, to the design of multiagent systems. The main achievements ofthis paper are twofold: First, this work constitutes the first systematic study of collective rationality for non-independentaggregation procedures in binary aggregation. While the literature in SCT has traditionally focused on independent aggre-gation procedures for preferences or judgments, we provided a truly general setting in which classical frameworks can beinterpreted and new results can be provided. Second, to achieve these results we introduced the novel concept of languagesfor integrity constraints. By developing a complex theoretical machinery around this notion we were able to build a linkbetween classical axiomatic properties and collective rationality, proving interesting characterisations and laying the basisfor further investigations of aggregation theory.We conclude by pointing out at some possible directions for future work. The framework we developed in this papercan be employed to deepen the current analysis of voting in multi-issue domains, e.g., by developing new voting methodsbased on preferential dependencies. In this respect, partial achievements have been made by Lang and Xia [28], Conitzeret al. [8], Xia et al. [41] and, in a similar setting, in our previous work [1]. The generality of the framework we proposedin this paper may also suggest that the aggregation of logical structures represents a promising area for future work. Wehave recently made an initial step in this direction by providing a first study of graph aggregation [13]. A similar problemis that of extending our definitions to cover the case of non-binary issues, e.g. by allowing individuals to abstain on certainissues. Related work has been done in this respect by Dokow and Holzman [12]. The results proved in the present papershould not be interpreted as limiting the possibility of consistent aggregation, but rather as specifying for each applicationat hand the right conditions that make it possible. Perhaps the most intriguing direction for future research is to employthe machinery developed in this paper to design collectively rational aggregation procedures to tackle complex problems ofaggregation that occur in AI applications.66U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66AcknowledgementsWe wish to thank Daniele Porello and the whole COMSOC group at the University of Amsterdam for fruitful and en-thusiastic discussions. We would also like to thank the anonymous reviewers for AAAI-2010, IJCAI-2011 and the ArtificialIntelligence journal, as well as the audiences of workshop and seminar talks we have given in Amsterdam, Bucharest,Dagstuhl, Delft, Estoril, Freudenstadt, Groningen, Kraków, Milan, Paris and Venice for their useful comments.References[1] S. Airiau, U. Endriss, U. Grandi, D. Porello, J. Uckelman, Aggregating dependency graphs into voting agendas in multi-issue elections, in: Proceedings ofthe 22nd International Joint Conference on Artificial Intelligence (IJCAI-2011), 2011.[2] A. Altman, M. Tennenholtz, Axiomatic foundations for ranking systems, Journal of Artificial Intelligence Research 31 (2008) 473–495.[3] K.J. Arrow, Social Choice and Individual Values, 2nd edition, John Wiley & Sons, 1963.[4] S.J. Brams, P.C. Fishburn, Approval Voting, 2nd edition, Springer, 2007.[5] F. Cariani, M. Pauly, J. Snyder, Decision framing in judgment aggregation, Synthese 163 (2008) 1–24.[6] Y. Chevaleyre, U. Endriss, J. Lang, N. Maudet, A short introduction to computational social choice, in: Proceedings of the 33rd Conference on CurrentTrends in Theory and Practice of Computer Science (SOFSEM-2007), 2007.[7] Y. Chevaleyre, U. Endriss, J. Lang, N. Maudet, Preference handling in combinatorial domains: From AI to social choice, AI Magazine 29 (2008) 37–46.[8] V. Conitzer, J. Lang, L. Xia, Hypercubewise preference aggregation in multi-issue domains, in: Proceedings of the 22nd International Joint Conferenceon Artificial Intelligence (IJCAI-2011), 2011.[9] F. Dietrich, C. List, Arrow’s theorem in judgment aggregation, Social Choice and Welfare 29 (2007) 19–33.[10] F. Dietrich, C. List, Judgment aggregation by quota rules: Majority voting generalized, Journal of Theoretical Politics 19 (2007) 391–424.[11] E. Dokow, R. Holzman, Aggregation of binary evaluations, Journal of Economic Theory 145 (2010) 495–511.[12] E. Dokow, R. Holzman, Aggregation of binary evaluations with abstentions, Journal of Economic Theory 145 (2010) 544–561.[13] U. Endriss, U. Grandi, Graph aggregation, in: Proceedings of the 4th International Workshop on Computational Social Choice (COMSOC-2012), 2012.[14] U. Endriss, U. Grandi, D. Porello, Complexity of judgment aggregation: Safety of the agenda, in: Proceedings of the 9th International Joint Conferenceon Autonomous Agents and Multiagent Systems (AAMAS-2010), 2010.[15] P. Faliszewski, E. Hemaspaandra, L.A. Hemaspaandra, J. Rothe, A richer understanding of the complexity of election systems, in: S. Ravi, S. Shukla (Eds.),Fundamental Problems in Computing: Essays in Honor of Professor Daniel J. Rosenkrantz, Springer, 2009.[16] P. Faliszewski, A.D. Procaccia, AI’s war on manipulation: Are we winning?, AI Magazine 31 (2010) 53–64.[17] W. Gaertner, A Primer in Social Choice Theory, Oxford University Press, 2006.[18] U. Grandi, Binary aggregation with integrity constraints, PhD thesis, ILLC, University of Amsterdam, 2012.[19] U. Grandi, The common structure of paradoxes in aggregation theory, in: Proceedings of the 4th International Workshop on Computational SocialChoice (COMSOC-2012), 2012.[20] U. Grandi, U. Endriss, Lifting rationality assumptions in binary aggregation, in: Proceedings of the 24th AAAI Conference on Artificial Intelligence(AAAI-2010), 2010.[21] U. Grandi, U. Endriss, Binary aggregation with integrity constraints, in: Proceedings of the 22nd International Joint Conference on Artificial Intelligence(IJCAI-2011), 2011.[22] D. Grossi, Unifying preference and judgment aggregation, in: Proceedings of the 8th International Joint Conference on Autonomous Agents and Multi-agent Systems (AAMAS-2009), 2009.[23] S. Konieczny, R. Pino Pérez, Merging information under constraints: A logical framework, Journal of Logic and Computation 12 (2002) 773–808.[24] S. Konieczny, R. Pino Pérez, Logic based merging, Journal of Philosophical Logic 40 (2011) 239–270.[25] L.A. Kornhauser, L.G. Sager, Unpacking the court, Yale Law Journal 96 (1986) 82–117.[26] J. Lang, Logical preference representation and combinatorial vote, Annals of Mathematics and Artificial Intelligence 42 (2004) 37–71.[27] J. Lang, G. Pigozzi, M. Slavkovik, L. van der Torre, Judgment aggregation rules based on minimization, in: Proceedings of the 13th Conference onTheoretical Aspects of Rationality and Knowledge (TARK-2011), 2011.[28] J. Lang, L. Xia, Sequential composition of voting rules in multi-issue domains, Mathematical Social Sciences 57 (2009) 304–324.[29] C. List, C. Puppe, Judgment aggregation: A survey, in: Handbook of Rational and Social Choice, Oxford University Press, 2009.[30] P. Marquis, Consequence finding algorithms, in: D. Gabbay, P. Smets (Eds.), Handbook on Defeasible Reasoning and Uncertainty Management Systems,Kluwer Academic Publishers, Dordrecht, 2000.[31] K.O. May, A set of independent necessary and sufficient conditions for simple majority decision, Econometrica 20 (1952) 680–684.[32] K. Nehring, C. Puppe, The structure of strategy-proof social choice. Part I: General characterization and possibility results on median spaces, Journal ofEconomic Theory 135 (2007) 269–305.[33] K.D. Nehring, C. Puppe, Abstract Arrowian aggregation, Journal of Economic Theory 145 (2010) 467–494.[34] D.M. Pennock, E. Horvitz, C.L. Giles, Social choice theory and recommender systems: Analysis of the axiomatic foundations of collaborative filtering, in:Proceedings of the 17th National Conference on Artificial Intelligence (AAAI-2000), 2000.[35] G. Pigozzi, M. Slavkovik, L. van der Torre, A complete conclusion-based procedure for judgment aggregation, in: Proceedings of the First InternationalConference on Algorithmic Decision Theory (ADT-2009), 2009.[36] M.S. Pini, F. Rossi, K.B. Venable, T. Walsh, Aggregating partially ordered preferences, Journal of Logic and Computation 19 (2009) 475–502.[37] D. Porello, Ranking judgments in Arrow’s setting, Synthese 173 (2010) 199–210.[38] F. Rossi, K. Venable, T. Walsh, mCP Nets: Representing and reasoning with preferences of multiple agents, in: Proceedings of the 19th AAAI Conferenceon Artificial Intelligence (AAAI-2004), 2004.[39] Y. Shoham, K. Leyton-Brown, Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations, Cambridge University Press, 2009.[40] R.B. Wilson, On the theory of aggregation, Journal of Economic Theory 10 (1975) 89–99.[41] L. Xia, V. Conitzer, J. Lang, Strategic sequential voting in multi-issue domains and multiple-election paradoxes, in: Proceedings of the 12th ACMConference on Electronic Commerce (EC-2011), 2011.