Artificial Intelligence 302 (2022) 103602Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAnalyzing Differentiable Fuzzy Logic OperatorsEmile van Krieken a,∗a Vrije Universiteit Amsterdam, Netherlandsb Civic AI Lab, Amsterdam, Netherlands, Erman Acar a,b, Frank van Harmelen aa r t i c l e i n f oa b s t r a c tArticle history:Received 10 June 2020Received in revised form 27 September 2021Accepted 28 September 2021Available online 7 October 2021Keywords:Fuzzy logicNeural-symbolic AILearning with constraintsThe AI community is increasingly putting its attention towards combining symbolic and neural approaches, as it is often argued that the strengths and weaknesses of these approaches are complementary. One recent trend in the literature is weakly supervised learning techniques that employ operators from fuzzy logics. In particular, these use prior background knowledge described in such logics to help the training of a neural network from unlabeled and noisy data. By interpreting logical symbols using neural networks, this background knowledge can be added to regular loss functions, hence making reasoning a part of learning.We study, both formally and empirically, how a large collection of logical operators from the fuzzy logic literature behave in a differentiable learning setting. We find that many of these operators, including some of the most well-known, are highly unsuitable in this setting. A further finding concerns the treatment of implication in these fuzzy logics, and shows a strong imbalance between gradients driven by the antecedent and the consequent of the implication. Furthermore, we introduce a new family of fuzzy implications (called sigmoidal implications) to tackle this phenomenon. Finally, we empirically show that it is possible to use Differentiable Fuzzy Logics for semi-supervised learning, and compare how different operators behave in practice. We find that, to achieve the largest performance improvement over a supervised baseline, we have to resort to non-standard combinations of logical operators which perform well in learning, but no longer satisfy the usual logical laws.© 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionIn recent years, integrating symbolic and statistical approaches to Artificial Intelligence (AI) gained considerable attention [22,6]. This research line has gained further traction due to recent influential critiques on purely statistical deep learning [47,59], which has been the focus of the AI community in the last decade. While deep learning has brought many important breakthroughs in computer vision [8], natural language processing [61] and reinforcement learning [68], the concern is that progress will be halted if its shortcomings are not dealt with. Among these is the massive amounts of data that deep learning models need to learn even a simple concept. In contrast, symbolic AI can easily reuse concepts and can express domain knowledge using only a single logical statement. Finally, it is much easier to integrate background knowledge using symbolic AI.* Corresponding author.E-mail addresses: e.van.krieken@vu.nl (E. van Krieken), erman.acar@vu.nl (E. Acar), Frank.van.Harmelen@vu.nl (F. van Harmelen).https://doi.org/10.1016/j.artint.2021.1036020004-3702/© 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602However, symbolic AI has issues with scalability: dealing with large amounts of data while performing complex reasoning task, and is not able to deal with the noise and ambiguity of e.g. sensory data. The latter is related to the well-known symbol grounding problem which Harnad [30] defines as how “the semantic interpretation of a formal symbol system can be made intrinsic to the system, rather than just parasitic on the meanings in our heads”. In particular, symbols refer to concepts that have an intrinsic meaning to us humans, but computers manipulating these symbols cannot understand (or ground) this meaning. On the other hand, a properly trained deep learning model excels at modeling complex sensory data. These models could bridge the gap between symbolic systems and the real world. Therefore, several recent approaches [18,23,67,46,20]aim at interpreting symbols that are used in logic-based systems using deep learning models. These are among the first systems to implement “a hybrid nonsymbolic/symbolic system (...) in which the elementary symbols are grounded in (...) non-symbolic representations that pick out, from their proximal sensory projections, the distal object categories to which the elementary symbols refer.” Harnad [30].1.1. Reasoning and learning using gradient descentWe introduce Differentiable Fuzzy Logics (DFL) which aims to integrate reasoning and learning by using logical formulas expressing background knowledge. The symbols in these formulas are interpreted using a deep learning model of which the parameters are to be learned. DFL constructs differentiable loss functions based on these formulas that can be minimized using gradient descent. This ensures that the deep learning model acts in a manner that is consistent with the background knowledge as we can backpropagate towards the parameters of the deep learning model.To ensure loss functions are differentiable, DFL uses fuzzy logic semantics [41]. Predicates, functions and constants are interpreted using the deep learning model. By maximizing the degree of truth of the background knowledge using gradient descent, both learning and reasoning are performed in parallel. We can apply the loss functions constructed using DFL for more challenging machine learning tasks than purely supervised learning. These methods fall under the umbrella of weakly supervised learning [76]. For example, it can be used for semi-supervised learning [74,32] or to detect noisy or inaccurate supervision [19]. For such problems, DFL corrects the predictions of the deep learning model when it is logically inconsistent with the background knowledge.To further our understanding of such losses, we present in this paper an analysis of the choice of operators used to com-pute the logical connectives in DFL. For example, functions called t-norms are used to connect two fuzzy propositions [41]. Because they return the degree of truth of the event that both propositions are true, such t-norms generalize the classical conjunction. Similarly, a fuzzy implication generalizes the classical implication. Most of these operators are differentiable, which enable their use in DFL. Interestingly, the derivatives of these operators determine how DFL corrects the deep learn-ing model when its predictions are inconsistent with the background knowledge. We show that the qualitative properties of these derivatives are integral to both the theory and practice of DFL. We approach this problem both from the view of symbolic and of statistical approaches to AI, to bridge the conceptual gap between those views. This provides insights that otherwise would be overlooked.1.2. ContributionsThe main contribution of this article is to answer the following question: “What fuzzy logic operators for existential quan-tification, universal quantification, conjunction, disjunction and implication have convenient theoretical properties when using them in gradient descent?” We analyze both theoretically and empirically the effect of the choice of operators used to compute the logical connectives in Differentiable Fuzzy Logics on the learning behavior of a DFL system. To this end,• We introduce Differentiable Fuzzy Logics (Section 4) which combines fuzzy logic and gradient-based learning, and analyze its behavior over different choices of fuzzy logic operators (Section 3).• We analyze the theoretical properties of aggregation functions, which are used to compute the universal quantifier ∀and the existential quantifier ∃, t-norms and t-conorms which are used to compute the connectives ∧ and ∨, and fuzzy implications which are used to compute the connective →.• We introduce a new family of fuzzy implications called sigmoidal implications (Section 5) using the insights from these analyses.• We perform experiments to compare fuzzy logic operators in a semi-supervised experiment (Section 9).• We give several recommendations for choices of operators.2. Differentiable LogicsLoss functions are real-valued functions that represent a cost and must be minimized. Differentiable Logics (DL) are logics for which differentiable loss functions are constructed that compute the truth value of given formulas using the semantics of the logic. These logics use background knowledge to deduce the truth value of statements in unlabeled or poorly labeled data, allowing us to use such data during learning, possibly together with normal labeled data. This can be beneficial as unlabeled, poorly labeled and partially labeled data is cheaper and easier to come by. This approach differs from Inductive Logic Programming [54] which derives formulas from data. DL instead informs what the data could have been.2E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 1. In this running example, we have an image with two objects on it, o1 and o2.We motivate the use of DL with the following classification scenario we consider throughout our analysis. Assume we have an agent A whose goal is to describe the scene on an image. It gets feedback from a supervisor S, who does not have an exact description of these images available. However, S does have a background knowledge base K about the concepts contained on the images. The intuition behind Differentiable Logics is that S can correct A’s descriptions of scenes when they are not consistent with the knowledge base K.Example 1. We illustrate this idea with the following example. Agent A has to describe image I in Fig. 1 that contains objects o1 and o2. A and the supervisor S consider the unary class predicates {chair, cushion, armRest} and the binary predicate {partOf}. Since S does not have a description of I , it will have to correct A based on the knowledge base K. A describes the image by using a confidence value in [0, 1] for each observation. For instance, p(chair(o1)) indicates the confidence A assigns to chair(o1), i.e., whether o1 is a chair or not.p(chair(o1)) = 0.9p(cushion(o1)) = 0.05p(armRest(o1)) = 0.05p(partOf(o1, o1)) = 0.001p(partOf(o1, o2)) = 0.01p(chair(o2)) = 0.4p(cushion(o2)) = 0.5p(armRest(o2)) = 0.1p(partOf(o2, o2)) = 0.001p(partOf(o2, o1)) = 0.95Suppose that K contains the following logic formula which says parts of a chair are either cushions or armrests:∀x, y chair(x) ∧ partOf( y, x) → cushion( y) ∨ armRest( y).S might reason that since A is relatively confident of chair(o1) and partOf(o2, o1) that the antecedent of this formula is satisfied, and either cushion(o2) or armRest(o2) has to hold. Since p(cushion(o2)) > p(armRest(o2)), a possible correction would be to tell A to increase its degree of belief in cushion(o2).We would like to automate the kind of supervision S performs in the previous example. To this end, we study what we call as Differentiable Fuzzy Logics (DFL), a family of Differentiable Logics in the literature based on fuzzy logic. Here, the term “Differentiable Logics” refers to a logic together with a translation scheme from logical expressions to differentiable loss functions. Then, “Differentiable Fuzzy Logics” stands for the case where the logic is a fuzzy logic and the translation scheme applies to logical expressions which include fuzzy operators. Note that due to its numerical character, fuzzy logic is an obvious candidate for a differentiable logic. Therefore, in DFL, truth values of ground atoms are numbers in [0, 1], and logical connectives are interpreted using some function over these truth values. Examples of logics in this family are Logic Tensor Networks [67], the similarly named Deep Fuzzy Logic [50], and the logics underlying Semantic Based Regularization [18], LYRICS [48] and KALE [26], which we compare in Section 11.1. This family stands orthogonal to the well-studied mathematical classification of the fuzzy logics landscape [12]. Instead, in our analysis, we use a variety of individual T-norms with different properties combined with a variety of aggregation functions.3. BackgroundWe assume basic familiarity on the syntax and the semantics of first-order logic. We shall denote predicates using the sans serif font (e.g., cushion), a set V of variables denoted by x, y, z, . . . or x1, x2, x3, . . ., and a set O of domain objects denoted by o1, o2, . . ., and constants a, b, c, . . .. We limit ourselves to function-free formulas in prenex normal form that start with quantifiers followed by a quantifier-free subformula. An example of a formula in prenex form is ∀x, y P(x, y) ∧ Q(x) →R( y). An atom is P(t1, ..., tm) where t1, ..., tm are terms. If t1, ..., tm are all constants, we say it is a ground atom.3E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Table 1The t-norms of interest.NameGödel (minimum)ProductŁukasiewiczT-normT G (a, b) = min(a, b)T P (a, b) = a · bT L K (a, b) = max(a + b − 1, 0)(cid:2)Drastic productT D (a, b) =Nilpotent minimumTnM (a, b) =min(a, b),0,(cid:2)if a = 1 or b = 1otherwiseif a + b ≤ 10,min(a, b), otherwisePropertiesidempotent, continuousstrictcontinuousleft-continuousYagerT Y (a, b) = max(1 − ((1 − a)p + (1 − b)p )1p , 0), p ≥ 1continuousTable 2The t-conorms of interest.NameGödel (maximum)Product (probabilistic sum)ŁukasiewiczT-conormS G (a, b) = max(a, b)S P (a, b) = a + b − a · bS L K (a, b) = min(a + b, 1)(cid:2)Propertiesidempotent, continuousstrictcontinuousDrastic sumNilpotent maximumYagerS D (a, b) =SnM (a, b) =max(a, b),1,(cid:2)if a = 0 or b = 0otherwiseif a + b ≥ 11,max(a, b), otherwise1p , 1), p ≥ 1S Y (a, b) = min((ap + b p )right-continuouscontinuousTable 3Some common aggregation operators.NameGeneralizesMinimumProductŁukasiewiczMaximumProbabilistic sumBounded sumT GT PT L KS GS GS L KAggregation operatorA T G (x1, ..., xn) = min(x1, ..., xn)(cid:3)A T P (x1, ..., xn) =ni=1 xi(cid:4)A T L K (x1, ..., xn) = max(nE S G (x1, ..., xn) = max(x1, ..., xn)(cid:3)i=1(1 − xi )E S P (x1, ..., xn) = 1 −n(cid:6)(cid:5)(cid:4)E S L K (x1, ..., xn) = minni=1 xi , 1i=1 xi − (n − 1), 0)Fuzzy logic is a many-valued logic where truth values are real numbers in [0, 1] where 0 denotes completely false and 1 denotes completely true. It is often used to model reasoning in the presence of vagueness i.e., without sharp boundaries or to imprecisely classify concepts such as a tall person or a small number [28,56]. We will look at predicate fuzzy logics in particular, which extend propositional fuzzy logics with universal and existential quantification. For a brief background on fuzzy logic operators, see Appendix A, and for an extensive treatment on mathematical fuzzy logic we refer the reader to standard textbooks which include [28], [56] and [12].In this paper we exclusively use the strong negation N(a) = 1 − a. Conjunctions a ∧ b are generalized using T-norms, which are any function T : [0, 1]2 → [0, 1] that is commutative, associative, monotonic, and has T (1, a) = a. In fuzzy logic, conjunctions using the t-norm are often denoted on the logical formula level as a ⊗ b. However, on the semantic level (i.e. T (a, b)), a and b will refer to the truth values of the corresponding logical formulas a and b. An overview of the most common T-norms is given in Table 1 alongside common properties that are defined in Appendix A.3. T-conormsgeneralize disjunctions and are often denoted a ⊕ b in fuzzy logic literature. They are formed from a t-norm T using S(a, b) = 1 − T (1 − a, 1 − b), following DeMorgans law a ⊕ b = ¬(¬a ⊗ ¬b). The most common t-conorms are given in Table 2.Universal and existential quantification are generalized using increasing aggregation operators A, E ∈[0, 1]n →[0, 1], where A(1, ..., 1) = E(1, ..., 1) = 1 and A(0, ..., 0) = E(0, ..., 0) = 0 [10]. Universal aggregators can be constructed from a t-norm T and existential aggregators from a t-conorm S:n∈N(cid:7)A T () = 1E S () = 0A T (x1, ..., xn) = T (x1, A T (x2, ..., xn))E S (x1, ..., xn) = S(x1, E S (x2, ..., xn))(1)(2)An overview of common aggregation operators is given in Table 3. A formal introduction is in Appendix A.4.Finally, implications are generalized using fuzzy implications [38], which are functions I : [0, 1]2 → [0, 1] that are in-creasing with respect to the first argument, and decreasing with respect to the second. Furthermore, we assume boundary conditions I(0, 0) = I(1, 1) = 1, and I(1, 0) = 0, which follows from the classical implication. Fuzzy implications can have additional properties that we discuss in Appendix A.5. We will discuss two classes of fuzzy implications. The first is S-implications (Appendix A.5.1, examples in Table 4), which are formed using a t-conorm by generalizing the material impli-4E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Table 4S-implications formed from ¬a ⊕ c with the common t-conorms from Table 2.NameT-conormGödel (Kleene-Dienes)Product (Reichenbach)ŁukasiewiczDubouis-PradeS GS PS L KS DS-implicationI K D (a, c) = max(1 − a, c)I RC (a, c) = 1 − a + a · cI L K (a, c) = min(1 − a + c, 1)⎧⎪⎨if a = 1c,1 − a,if c = 01,otherwiseI D P (a, c) =⎪⎩(cid:2)Nilpotent (Fodor)S NmI F D (a, c) =1,max(1 − a, c), otherwiseif a ≤ cTable 5The R-implications constructed using the t-norms from Table 1.PropertiesAll but IPAll but IPAllAllAllNameGödelproduct (Goguen)ŁukasiewiczWeberT-normT GT PT L KT D(cid:2)I G (a, c) =I G G (a, c) =R-implicationif a ≤ c1,c, otherwise(cid:2)if a ≤ c1,ca , otherwiseI L K (a, c) = min(1 − a + c, 1)(cid:2)1,if a < 1c, otherwiseI W B (a, c) =(cid:2)PropertiesLN, EP, IPLN, EP, IPAllLN, EP, IPNilpotent (Fodor)T NmI F D (a, c) =1,max(1 − a, c), otherwiseif a ≤ cAllcation a → c = ¬a ⊕ c using I S (a, c) = S(N(a), c). The second is R-implications, which is the standard choice in t-norm fuzzy logics (Appendix A.5.2, examples in Table 5). These are constructed from t-norms using I T (a, c) = supb∈[0,1] T (a, b) ≤ c.4. Differentiable Fuzzy LogicsAs mentioned earlier, Differentiable Fuzzy Logics (DFL) are Differentiable Logics based on fuzzy logic. Truth values of ground atoms are continuous, and logical connectives are interpreted using differentiable fuzzy operators. In principle, DFL can handle both predicates and functions. To ease the discussion, we will not analyze functions and constants and leave them out of the discussion.14.1. SemanticsDFL defines a new semantics using vector embeddings and functions on such vectors in place of classical semantics. In classical logic, a structure consists of a domain of discourse and an interpretation function, and is used to give meaning to the predicates. DFL defines structures using embedded interpretations2 instead:Definition 1. A Differentiable Fuzzy Logics structure is a tuple S = (cid:13)O , η, θ(cid:14), where O is a finite but unbounded set called domain of discourse and every o ∈ O is a d-dimensional3 vector, η : P × RW → (O m → [0, 1]) is an (embedded) interpretation, and θ ∈ RW are parameters. η maps predicate symbols P ∈ P with arity m to a function of m objects to a truth value [0, 1]. That is, η(P, θ) : O m → [0, 1]. We will use the notation ηθ (P) to denote η(P, θ).To address the symbol grounding problem [30], objects in the domain of discourse are d-dimensional vectors of reals. Their semantics come from the underlying semantics of the vector space as terms are interpreted in a real (valued) world [67]. Predicates are interpreted as functions mapping these vectors to a fuzzy truth value. Embedded interpretations can be implemented using neural network models4 with trainable network parameters θ . Note that different values for the parameters θ will produce different DFL structures. Next, we define the truth values of formulas in DFL.1 Functions and constants are modeled in [67] and [48].2 Serafini and Garcez [67] uses the term “(semantic) grounding” or “symbol grounding” [51] instead of ‘embedded interpretation’, “to emphasize the fact that L is interpreted in a ‘real world’ ” but we find this potentially confusing as this could also refer to groundings in Herbrand semantics. Furthermore, by using the word ‘interpretation’ we highlight the parallel with classical logical interpretations.3 Without loss of generality we fix the dimensionality of the vectors representing the objects. Extensions to a varying number of dimensions are straight-forward by introducing types, such as done in [2].4 We use ‘models’ to refer to deep learning models like neural networks, and not to models from model theory.5E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Definition 2. Let S = (cid:13)O , η, θ (cid:14) be a DFL structure, N a fuzzy negation, T a t-norm, S a t-conorm, I a fuzzy implication, and Aand E universal and existential aggregators respectively. Furthermore, let μ : V → O be a variable assignment, where we use (cid:15))(cid:15)) = μ(xμ[x : o] to refer to the new assignment where x is mapped to domain object o, that is, μ[x : o](x) = o and μ[x : o](x(cid:15). Then we say that S satisfies the formula ϕ ∈ L w.r.t. μ (i.e., S, μ |= ϕ) in the degree of eθ (ϕ) (i.e., the truth for x (cid:16)= xvalue of ϕ) where eθ : (V → O ) × L → [0, 1] is the valuation function defined inductively on the structure of ϕ as follows:eθ (μ, P(x1, ..., xm)) = ηθ (P) (μ(x1), ..., μ(xm))eθ (μ, ¬φ) = N(eθ (μ, φ))eθ (μ, φ ⊗ ψ) = T (eθ (μ, φ), eθ (μ, ψ))eθ (μ, φ ⊕ ψ) = S(eθ (μ, φ), eθ (μ, ψ))eθ (μ, φ → ψ) = I(eθ (μ, φ), eθ (μ, ψ))eθ (μ, ∀x φ) = Aeθ (μ, ∃x φ) = Eo∈Oo∈Oeθ (μ[x : o], φ)eθ (μ[x : o], φ)(3)(4)(5)(6)(7)(8)(9)Equation (3) defines the fuzzy truth value of an atomic formula. μ assigns objects to the terms x1, ..., xm resulting in a list of d-dimensional vectors. These are the inputs to the interpretation ηθ of the predicate symbol P (i.e., ηθ (P)) to get a fuzzy truth value. Equations (4) - (7) define the truth values of the connectives using the operators N, T , S and I . Equations (8) and (9) define the truth value of universally quantified formulas ∀x φ and existentially quantified formulas ∃x φ. This is done by enumerating the domain of discourse o ∈ O , evaluating the truth value of φ with o assigned to x in μ, and combining the truth values using aggregation operators A and E.Note that our assumption on the finiteness of the domain is pragmatic: It reflects the finiteness of the data in machine learning settings. Hence, many fundamental results in the realm of mathematical (fuzzy) logic will not hold in general for the logic we defined [12].4.2. Relaxing quantifiersFor infinite domains, or for domains that are so large that we cannot compute the full semantics of the ∀ and ∃ quanti-fiers, we can choose to sample a batch b of objects from O to approximate the computation of the valuation. This can be done by replacing Equation (8) witheθ (μ, ∀x φ) =bAi=1eθ (μ[x : oi], φ),o1, ..., ob chosen from O .(10)Choosing the batch of objects can be done in several ways. One approach would be to sample from a real-world distri-bution over the domain of discourse O , if available. For example, the domain of discourse might be the natural images, and the real-world distribution would be the distribution over natural images. A more common approach is to assume access to a dataset D of independent samples from such a distribution [25](p.109) and to choose minibatches from this dataset. Note that by relaxing quantifiers using sampling we lose the soundness of our computation, as different batches will have different truth values for the formulas.4.3. Learning using fuzzy maximum satisfiabilityIn DFL, fuzzy maximum satisfiability [19] is the problem of finding parameters θ that maximize the valuation of the knowledge base K.Definition 3. Let K be a knowledge base of formulas, S a DFL structure for K and eθ a valuation function. Then the Differentiable Fuzzy Logics loss LD F L of a knowledge base of formulas K is computed usingLD F L(S, K) = LD F L((cid:13)O, η, θ (cid:14), K) = −(cid:12)ϕ∈Keθ ({}, ϕ).The fuzzy maximum satisfiability problem is the problem of finding parameters θ ∗that minimize Equation (11):θ ∗ = argminθLD F L(S, K).6(11)(12)E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602This optimization problem can be solved using a gradient descent method. If the operators N, T , S, I, A and E are all differentiable, we can repeatedly apply the chain rule, i.e. reverse-mode differentiation, on the DFL loss LD F L(S, K). This ∂LD F L (S,K)procedure finds the derivative with respect to the truth values of the ground atoms ∂ηθ (P)(o1,...,om) . We can use these partial derivatives to update the parameter θ n at iteration n of the optimization process again using the chain rule, resulting in a different embedded interpretation ηθ n+1 . This procedure is computed as follows for the ith parameter:· ∂ηθ (P)(o1, ..., om)∂θ n,iθ n+1,i = θ n,i − (cid:8) · ∂LD F L(Sn, K)∂LD F L(Sn, K)∂ηθ (P)(o1, ..., om)= θ n,i − (cid:8) ·∂θ n,i(13)(cid:12),P(o1,...,om)where (cid:8) is the learning rate. Note that the parameters θ n are implicitly passed to L through the structure Sn = (cid:13)O , η, θ n(cid:14). We refer for implementation details to Appendix B.Example 2. To illustrate the computation of the valuation function eθ , we return to the problem in Example 1. The domain of discourse is the set of objects on natural images. We have access to a dataset of two objects D = {o1, o2}. The valuation of the formula ϕ = ∀x, y chair(x) ⊗ partOf( y, x) → cushion( y) ⊕ armRest( y) iseθ (μ, ϕ) = A( A(I(T (ηθ (chair)(o1), ηθ (partOf)(o1, o1)), S(ηθ (cushion)(o1), ηθ (armRest)(o1))),I(T (ηθ (chair)(o1), ηθ (partOf)(o2, o1)), S(ηθ (cushion)(o2), ηθ (armRest)(o2)))),A(I(T (ηθ (chair)(o2), ηθ (partOf)(o1, o2)), S(ηθ (cushion)(o1), ηθ (armRest)(o1))),I(T (ηθ (chair)(o2), ηθ (partOf)(o2, o2)), S(ηθ (cushion)(o2), ηθ (armRest)(o2))))).Next, we choose the operators as T = T P , S = S P , A = A T P and I = I RC , such that(cid:13)eθ (μ, ϕ) =1 − ηθ (chair)(x) · ηθ (partOf)( y, x) · (1 − ηθ (cushion)( y))(1 − ηθ (armRest)( y)).x, y∈C= −0.4261If we interpret the predicate functions using the confidence values from Example 1 so that ηθ (P(x)) = p(P(x)), we find that eθ (ϕ) = 0.612. Taking K = {ϕ}, we find using the chain rule that∂LD F L(S, K)∂ηθ (chair)(o2)∂LD F L(S, K)∂ηθ (cushion)(o2)∂LD F L(S, K)∂ηθ (armRest)(o2)∂LD F L(S, K)∂ηθ (partOf)(o2, o2)∂LD F L(S, K)∂ηθ (partOf)(o2, o1)∂LD F L(S, K)∂ηθ (chair)(o1)∂LD F L(S, K)∂ηθ (cushion)(o1)∂LD F L(S, K)∂ηθ (armRest)(o1)∂LD F L(S, K)∂ηθ (partOf)(o1, o1)∂LD F L(S, K)∂ηθ (partOf)(o1, o2)= −0.4031.= −0.2219= −0.4978= −0.1103= −0.0058= 0.4257= 0.7662= 0.0029= 0.0029We can now do a gradient update step to update the confidence values from Example 1, or find what the partial derivative of the parameters θ of some deep learning model pθ should be using Equation (13).One particularly interesting property of Differentiable Fuzzy Logics is that the partial derivatives of the subformulas with respect to the satisfaction of the knowledge base have a somewhat explainable meaning. For example, as hypothesized in Example 1, the computed partial derivatives reflect whether we should increase p(cushion(o2)), as it is indeed the (absolute) largest partial derivative.5. Derivatives of operatorsWe will now show that the choice of operators that are used for the logical connectives actually determines the in-ferences that are done when using DFL. If we used a different set of operators in Example 2, we would have gotten very different derivatives. These could in some cases make more sense, and in some other cases less. Furthermore, it is much easier to find a global minimum of the fuzzy maximum satisfiability problem (Equation (12)) for some operators than for others. This is often because of the smoothness of the operators. In this section, we analyze a wide variety of functions that can be used for logical reasoning and present some of their properties that determine how useful they are in inferences such as those illustrated above.We will not discuss any varieties of fuzzy negations since the strong negation NC (a) = 1 − a is already continuous, intuitive and has simple derivatives.7E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Definition 4. A function f : R → R is said to be vanishing if there are a, b ∈ R, a < b such that for all c ∈ (a, b), f (c) = 0, i.e. there is an interval for which the function is 0. Otherwise, the function is nonvanishing.A function f : Rn → R has a vanishing derivative if for all a1, ..., an ∈ R there is some 1 ≤ i ≤ n such that ∂ f (a1,...,an)vanishing.is ∂aiWhenever the derivative of an operator vanishes, it loses its learning signal. This definition does not include functions that only pass through 0, such as when using the product t-conorm for a ⊕ ¬a, where we find that the derivative of S P (a, 1 − a) is 0 only at 12 . Furthermore, all the partial derivatives of the connectives used in the backward pass from the valuation function to the ground atoms have to be multiplied. If the partial derivatives are less than 1, their product will also approach 0. This can happen for instance with a large sequence of conjunctions using the product t-norm.The drastic product T D and operators derived from it such as the drastic sum S D and the Dubois-Prade and Weber implications (I D P and I W B ) have vanishing derivatives almost everywhere. The output confidence values of deep learning models are the result of transformations on real numbers using functions like the sigmoid or softmax that result in truth values in (0, 1). The operators derived from T D only have nonvanishing derivatives when their inputs are exactly 0 or 1, invalidating their use in this applicationDefinition 5. A function f : Rn → R is said to be single-passing if it has nonzero derivatives on at most one input argument. That is, for all x1, ..., xn ∈ [0, 1] it holds that (cid:16)= 0, i ∈ {1, ..., n}(cid:16)(cid:14)(cid:14)(cid:14) ≤ 1.(cid:14)(cid:14)(cid:14)(cid:15)i(cid:14)(cid:14)(cid:14) ∂ f (x1,...,xn)∂ xiUsing just single-passing Fuzzy Logic operators can be inefficient, since then at most one input will have a nonzero derivative (i.e. a learning signal), yet the complete forward pass still has to be computed to find this input. In particular, this will hold when choosing operators based on the Gödel t-norm.Proposition 1. Any composition of single-passing functions is also single-passing.For the proof, see Appendix C.1.Concluding, for any logical operator to be usable in the learning task, it will need to have a nonvanishing derivative at the majority of the input signals, so it can contribute to the learning signal at all, and ideally not be single-passing so that it can contribute effectively to the learning signal.6. AggregationAfter the global considerations from the previous section, we next analyze in detail aggregation operators for universal and existential quantification separately and outline their benefits and disadvantages in DFL.6.1. Minimum and maximum aggregatorsThe minimum aggregator is given as A T G (x1, ..., xn) = min(x1, ..., xn). The partial derivatives are(cid:2)∂ A T G (x1, ..., xn)∂ xi=10if i = argmin j∈{1,...,n}x jotherwise.(14)It is single-passing with the only nonzero gradient being on the input with the lowest truth value. Many practical formulas have exceptions. An exception to a formula like ∀x Raven(x) → Black(x) would be a raven over which a bucket of red paint is thrown. The minimum aggregator would have a derivative on that exception when ‘red raven’ is correctly predicted. Additionally, it is inefficient, as we still have to compute the forward pass for inputs that do not get a feedback signal.The partial derivatives of the maximum aggregator E S G (x1, ..., xn) = max(x1, ..., xn) are similar, but increase the input with the highest truth value instead. This can be a reasonable aggregator for existential quantification, as it will reinforce the belief that the input we are most confident about is correct will make the existential quantifier true. A downside is that it can only consider one such input, despite the fact that the condition might hold for multiple inputs.6.2. Łukasiewicz aggregatorThe Łukasiewicz aggregator is given as A T LU (x1, ..., xn) = max(cid:2)∂ A T LU (x1, ..., xn)∂ xi=10(cid:4)ni=1 xi > n − 1ifotherwise.8(cid:5)(cid:4)n(cid:6)i=1 xi − (n − 1), 0. The partial derivatives are given by(15)E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602The gradient is nonvanishing only when limn→∞ n−1n= 1, for larger values of n, all inputs have to be high for this to hold.i=1 xi > n − 1, i.e., when the average value of xiis larger than n−1n[57]. As For the next proposition, we refer to the fraction of inputs for which some condition holds. The probability that the condition holds for a point uniformly sampled from [0, 1]n is this fraction.(cid:4)nProposition 2. The fraction of inputs x1, ..., xn ∈ [0, 1] for which the derivative of A T LU is nonvanishing is 1n! .For proof, see Appendix C.2.1. Clearly, for the majority of inputs there is a vanishing gradient, implying that this universal aggregator would not be useful in a DFL learning setting.A similar argument can be made for the existential Łukasiewicz aggregator, the bounded sum E S L K (x1, ..., xn) =(cid:4)ni=1 xi, 1), which will only have nonvanishing derivatives of 1 to all argument when the average value of xi is smaller min(n . Like the Łukasiewicz aggregator, it also has nonvanishing derivatives only on a fraction 1than 1n! of its domain. This is therefore not a useful existential aggregator: The agent will learn nothing unless all inputs are close to 0.6.3. Yager aggregatorThe Yager universal aggregator is given by⎛A T Y (x1, ..., xn) = max⎝1 −(cid:19)n(cid:12)(1 − xi)p(cid:20) 1p⎞⎠ ,, 0p > 0(16)i=1Here, p = 1 corresponds to the Łukasiewicz aggregator, p → ∞ corresponds to the minimum aggregator, and p → 0 corre-sponds to the aggregator formed from the drastic product A T D . The derivative of the Yager aggregator is∂ A T Y (x1, ..., xn)∂ xi=⎧⎪⎨⎪⎩(cid:23)(cid:4)nj=1(1 − x j)p(cid:24)1− 1p · (1 − xi)p−10ifif(cid:23)(cid:4)n(cid:23)(cid:4)nj=1(1 − x j)pj=1(1 − x j)p(cid:24) 1p < 1(cid:24) 1p > 1.(17)This derivative vanishes whenever Therefore, corresponds to the drastic aggregator, and 1 for p = ∞.j=1(1 − x j)p ≥ 1. As 1 − xi ∈ [0, 1], (1 − xi)p is a decreasing function with respect to p. i=1(1 − xi)p < 1 holds for a larger fraction of inputs when p increases, with the fraction being 0 for p = 0 as it (cid:4)n(cid:4)nThe exact fraction of inputs with a nonvanishing derivative is hard to express in the general case.5 However, we can find a closed-form expression for the Euclidean case p = 2.Proposition 3. The fraction of inputs x1, ..., xn ∈ [0, 1] for which the derivative of A T Y with p = 2 is nonvanishing is n2π2 n+ 12n·(cid:10)( 12 ), where (cid:10) is the Gamma function.See Appendix C.2.2 for the proof. We plot the fraction of nonvanishing derivatives for several values of p in Fig. 2. For fairly small p, the vast majority of the inputs will have a vanishing derivative, and similar for high n, showing that this aggregator is also of little use in a learning context.(cid:25)(cid:6) 1(cid:5)(cid:4)ni=1 xpi(cid:26)p , 1are nonvanishing in Similarly, the derivatives of the Yager existential aggregator E S Y (x1, ..., xn) = minthe same fraction of inputs as the Yager universal aggregator.6.4. Generalized Mean and Generalized Mean ErrorIf we are concerned only in maximizing the truth value of A T Y , we can simply remove the max constraint, resulting in an aggregator that has a nonvanishing derivative everywhere. However, then the co-domain of the function is no longer [0, 1]. We can do an affine transformation on this function to ensure this is the case (Appendix D.1), after which we obtain the Generalized Mean Error.5 Assume that x1, ..., xn ∼ U (0, 1) are independently and standard uniformly distributed. Note that zi = 1 − xi is also standard uniformly distributed. zis distributed by the beta distribution Beta(1/p, 1) [27]. Y =i=1 zi is the sum of n such beta-distributed variables. Unfortunately, there is no closed-form expression for the probability density function of sums of independent beta random variables [60]. A suitable approximation would be to use the central limit theorem as z1, ..., zn are identically and independently distributed.(cid:4)npi9E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 2. The fraction of inputs for which the Yager aggregator A T Yderivatives. The values for dotted lines are estimated using Monte Carlo simulation.for several values of p and the nilpotent minimum aggregator A TnM have nonvanishing Definition 6. For any p > 0, the Generalized Mean Error AG M E is defined asAG M E (x1, ..., xn) = 1 −(cid:19)1nn(cid:12)(1 − xi)p(cid:20) 1p.i=1(18)The ‘error’ here is difference between the predicted value xi and the ‘ground truth’ value, a truth value of 1. This function has the following derivative:⎛∂ AG M E (x1, ..., xn)∂ xi= (1 − xi)p−1 1n1pn(cid:12)⎝(1 − x j)pj=1−11p⎞⎠.(19)When p > 1, this derivative is greatest for the inputs that are lowest, which can speed up the optimization by being sensitive to outliers. For p < 1, the opposite is true. A special case is p = 1:n(cid:12)(20)A M A E (x1, ..., xn) = 1 − 1n(1 − xi)i=1having the simple derivative ∂ A M A E (x1,...,xn)associated with the Łukasiewicz t-norm. Another special case is p = 2:= 1∂ xin . This measure is equal to 1 minus the mean absolute error (MAE) and is A R M S E (x1, ..., xn) = 1 −(cid:27)(cid:28)(cid:28)(cid:29) 1nn(cid:12)(1 − xi)2.i=1(21)This function is equal to 1 minus the root-mean-square error (RMSE) which is commonly used for regression tasks and heavily weights outliers. We can do the same for the Yager existential aggregator (Appendix D.1):Definition 7. For any p > 0, the Generalized Mean is defined asE G M (x1, ..., xn) =(cid:19)(cid:20) 1p.1nn(cid:12)i=1xpi(22)p = 1 corresponds to the arithmetic mean and p = 2 to the geometric mean. In contrast to the Generalized Mean Error, (cid:23)(cid:24) 1p−1(cid:4)nj=1 xpjp−1ix1nits derivative 1has greater values for smaller inputs when p < 1, and lower values when p > 1. nSince we want to ensure the derivative is high only for inputs with high truth values to reinforce that those are likely the inputs that confirm the formula, we will want to use p > 1. Note that the arithmetic mean E G M has the same derivative as the mean absolute error A M A E , meaning that with p = 1 universal and existential quantification cannot be distinguished. Furthermore, increasing all inputs equally is not a great idea for the existential quantifier, as there are likely only a few inputs for which the formula holds. Also note that, unlike existential aggregators directly formed from t-conorms, the only maximum of this aggregator is x1, ..., xn = 1. However, it will take long until one can reach this optimum for low inputs.10E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 1036026.5. Product aggregator and probabilistic sumThe product aggregator is given as A T P (x1, ..., xn) =dent events. It has the following partial derivatives:∂ A T P (x1, ..., xn)∂ xi=n(cid:13)x j.j=1,i(cid:16)= j(cid:3)ni=1 xi . This is also the probability of the intersection of n indepen-(23)This derivative vanishes if there are at least two i so that xi = 0. Furthermore, the derivative for xi will be decreased if some other input x j is low. Finally, we cannot compute this aggregator in practice due to numerical underflow when multiplying many small numbers. Noting that argmax f (x) = argmax log( f (x)), we observe that the log-product aggregatorAlog T P (x1, ..., xn) = (log ◦ A T P )(x1, ..., xn) =n(cid:12)i=1log(xi)(24)can be used for formulas in prenex normal form, as then the truth value of the universal quantifiers is not used for another connective. Unlike the other aggregators, its codomain is the non-positive numbers instead of [0, 1]. Furthermore, the log-product aggregator can be seen as the log-likelihood function where we take the correct label to be 1, and thus this is similar to cross-entropy minimization. The partial derivatives are∂ Alog T P (x1, ..., xn)∂ xi= 1xi.(25)In contrast to Equation (23), the values of the other inputs are irrelevant, and derivatives with respect to lower-valued inputs will be far greater as there is a singularity at x = 0 (i.e. the value becomes infinite). We can conclude therefore that the product aggregator is particularly promising as it is nonvanishing and can handle outliers. The log-product aggregator also combines well with the generalized mean aggregator (Equation 7) for formulas of the form ∀x∃ y. The logarithm reduces the outer exponentiation, resulting in the derivative xi(cid:4)p−1.The probabilistic sum aggregator E S P (x1, ..., xn) = 1 −i=1(1 − xi) is trickier. Its derivatives arei xpi(cid:3)n∂ E S P∂ xi=n(cid:13)j=1, j(cid:16)=i(1 − x j).(26)This derivative is quite intuitive: It increases xi if the other inputs x j are low. However, this does not take into account the value of xi itself. If all inputs are low, this will increase all inputs equally. Since the logarithm does not distribute over addition, we cannot use the same trick here as for the product aggregator, so care has to be taken when computing log ◦E S Pto prevent numerical underflow errors.6.6. Nilpotent aggregatorsThe Nilpotent t-norm is given by TnM (a, b) =aggregator A TnM is equal to(cid:2)(cid:2)min(a, b),0,if a + b > 1otherwise.In Appendix D.3 we show that the Nilpotent A TnM (x1, ..., xn) =min(x1, ..., xn),0,if xi + x j > 1; xi and x j are the two lowest values in x1, ..., xnotherwise.(27)The derivative is found as follows:(cid:2)∂ A TnM (x1, ..., xn)∂ xi=if i = argmin j x j and xi + x j > 1 where x j is the second lowest value in x1, ..., xn1,0, otherwise.(28)Like the minimum aggregator it is single-passing, and like the Łukasiewicz aggregator it has a derivative that vanishes for the majority of the input space, namely when the sum of the two smallest values is lower than 1.Proposition 4. The fraction of inputs for which the derivative of A TnM is nonvanishing is 12n−1 .For the proof, see Appendix C.2.3. The fraction of inputs for which there is a nonvanishing derivative is plotted in Fig. 2. Again, this means that for larger numbers of inputs n, this aggregator will vanish on almost every input and is not a useful construction in a learning context.11E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Similarly, the Nilpotent existential aggregator is given as(cid:2)E SnM (x1, ..., xn) =max(x1, ..., xn),1,if xi + x j < 1; xi and x j are the two largest values in x1, ..., xnotherwise.(29)It has a similar derivative that increases the largest input if the two largest inputs together are lower than 1. This is somewhat similar to how the maximum aggregator behaves, but with an additional condition that will stop increasing the largest input if there is another that is also quite high.6.7. SummaryThe minimum aggregator is computationally inefficient and cannot handle exceptions well. Universal aggregation opera-tors that vanish when receiving a large amount of inputs will not scale well, and these include operators based on the Yager family of t-norms and the nilpotent aggregator. Removing the bounds from the Yager aggregators introduces interesting connections to loss functions from the classical machine learning literature. This is also the case for the logarithmic ver-sion of the product aggregator, which corresponds to the cross-entropy loss function. They have natural means for dealing with outliers, and thus are promising for practical use. We have more options for existential quantification, as problems with vanishing gradients are not as important since we only care about ensuring the formula is true for at least one input, instead of all of them.7. Conjunction and disjunctionNext, we analyze the partial derivatives of t-norms and t-conorms, which are used as conjunction and disjunction in Fuzzy Logics. In t-norm Fuzzy Logics, the weak disjunction max(a, b), or the Gödel t-conorm is used instead of the dual t-conorm.Suppose that we have a t-norm T and a t-conorm S. We define the following two quantities, where the choice of taking the partial derivative to a is without loss of generality, since T and S are commutative by definition:dT (a, b) = ∂ T (a, b)∂a,dS (a, b) = ∂ S(a, b)∂a(30)∂a∂1−a= − ∂1−T (1−a,1−b)= ∂ T (1−a,1−b)∂1−aIt should be noted that by Definition 14, ∂ T (a,1)= 1as S(a, 0) = a for any t-conorm S. Furthermore, we note that if S is a t-conorm and the NC -dual of the t-norm T , then ∂1−T (1−a,1−b)∂a= 1 as T (a, 1) = a for any t-norm T , and by Definition 16, ∂ S(a,0)The main difference in analyzing t-norms and t-conorms is that the maximum of T (a, b) (namely 1) is when both arguments a and b are 1. In contrast, in t-conorms, an infinite number of maxima exist. Some of these maxima might be more desirable than others. Referring back to the formula in Example 1, we showed that it is preferable to increase the truth value of cushion( y) and not of armRest( y). Similarly, when a conjunct is negated, or when it appears in the antecedent of an implication (like in the aforementioned formula) we have to choose which of the two conjuncts to decrease. By noting that ∂ T (a,b), we find that the t-norm “chooses” in the same way its dual t-conorm would “choose”. Similarly, if a disjunction is negated, it will minimize both its arguments in the way that its dual t-norm would maximize its arguments.= ∂ S(1−a,1−b)∂1−a∂a∂a.Example 3. We introduce a running example to analyze the behavior of different t-norms. We will optimize (a ⊗b) ⊕(c ⊗¬a)using gradient descent. The truth value of this expression is computed using f (a, b, c) = S(T (a, b), T (1 − a, c)). Using the boundary conditions from Definition 14 and 16, we find the global optima a = 1.0, b = 1.0 and a = 0.0, c = 1.0. The derivative to this function is, using the chain rule,∂ f (a, b, c)∂a= ∂ S(T (a, b), T (1 − a, c))∂ T (a, b)· ∂ T (a, b)∂a+ ∂ S(T (a, b), T (1 − a, c))∂ T (1 − a, c)· ∂ T (1 − a, c)∂a.7.1. Gödel t-normThe Gödel t-norm is T G (a, b) = min(a, b) and the Gödel t-conorm is S G (a, b) = max(a, b). We find(cid:2)(cid:2)∂ T G (a, b)∂a=1,0,if a < bif a > b,∂ S G (a, b)∂a=1,0,if a > bif a < b.(31)(32)Both T G and S G are single-passing, but their derivatives are not defined a = b. A benefit of the magnitude of the deriva-tive nearly always being 1 is that there will not be any exploding or vanishing gradients caused by multiple repeated applications of the chain rule.12E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602a < b1 − a < ca − 1 < c1 − a < ac < ab < 1 − a0-11010-1Fig. 3. Decision tree for the derivative of S G (T G (a, b), T G (1 − a, c)) with respect to a.Example 4. Filling in Equation (31) representing (a ⊗ b) ⊕ (c ⊗ ¬a) with T G and S G gives∂ f (a, b, c)∂a= 1min(a,b)>min(1−a,c) · 1a<b − 1min(1−a,c)>min(a,b) · 11−a<c= 1a>min(1−a,c)∧a<b − 11−a>min(a,b)∧1−a<cwhere 1c is the indicator function. This corresponds to the decision tree in Fig. 3. The value of a can be modified to increase the truth of either one of the conjunctions. In order to choose which of the two should be true, it compares a with 1 − a. If 1 − a < a, it will increase the first conjunct by increasing a. Gradient ascent always finds a global optimum for this formula.A small perturbation in the truth values of the inputs can flip the derivative around. For instance, if a < b and 1 − a < c, then it will increase a if its value is 0.501 and decrease it if it is 0.499. Furthermore, it can cause gradient ascent to get stuck in local optima. For instance, if ϕ = (a ⊕ b) ⊗ (¬a ⊕ c) and a = 0.4, b = 0.2 and c = 0.1, gradient ascent increases auntil a > 0.5, at which point the gradient flips and it decreases a until a < 0.5. Experiments with optimizing this through gradient descent show that we can only find a global optimum in 88.8% of random initializations of a, b and c.7.2. Łukasiewicz t-normThe Łukasiewicz t-norm is T L K (a, b) = max(a + b − 1, 0) and the Łukasiewicz t-conorm is S L K (a, b) = min(a + b, 1). The partial derivatives are:(cid:2)(cid:2)∂ T L K (a, b)∂a=1,0,if a + b > 1if a + b < 1,∂ S L K (a, b)∂a=1,0,if a + b < 1if a + b > 1(33)These derivatives vanish on as much as half of their domain (Proposition 2). However, like the Gödel t-norm, when there is a gradient, it is large and will not cause vanishing or exploding gradients.Example 5. Using the Łukasiewicz t-norm and t-conorm in Equation (31) gives rise to the following computation∂ f (a, b, c)∂a= 1max(a+b−1,0)+max(c−a,0)<1 ·(cid:5)1a+b>1 − 1c−a>0(cid:6).Choosing random values to initialize a, b and c, gradient descent is able to find a (global) optimum in about 83.5% of the initializations.7.3. Yager t-norm(cid:5)ap + b pS Y (a, b) = min((cid:2)(cid:5)∂ T Y (a, b)∂a=The family of Yager t-norms [75] is T Y (a, b) = max(1 −p , 0) and the family of Yager t-conorms is (cid:6) 1p , 1) for p ≥ 0. We plot these for p = 2 in Fig. 4. The derivatives are given by(cid:5)(1 − a)p + (1 − b)p(cid:6) 1(1 − a)p + (1 − b)p0(cid:2)(cid:5)(cid:6) 1p−1 · ap−1∂ S Y (a, b)∂a=ap + b p0(cid:6) 1p−1 · (1 − a)p−1if (1 − a)p + (1 − b)p < 1,if (1 − a)p + (1 − b)p > 1,if ap + b p < 1,if ap + b p > 1(34)(35)We plot these derivatives in Fig. 5, showing for each a vanishing derivative on a non-negligible section of the domain. Using the method described in footnote 5 (Section 6.3), Mathematica finds a closed form expression for the fraction of inputs (cid:23)(cid:24)for which the Yager t-norm is nonvanishing as 1p(cid:24). Observe that when p (cid:16)= 1, the derivative of T Y is undefined at √π 4−1/p (cid:10)(cid:23)p(cid:10)12+ 1pa = b = 1 and the derivative of S Y is undefined at a = b = 0. This requires care in the implementation to prevent numerical issues. For p > 1, the lower of the two truth values has a higher derivative for the t-norm, while for the t-conorm, the 13E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 4. Left: The Yager t-norm. Right: The Yager t-conorm. For both, p = 2.Fig. 5. Left: The derivative of the Yager t-norm. Right: The derivative of the Yager s-norm. For both, p = 2.higher of the two truth values has a higher derivative. As p increases, T Y and S Y will behave more like T G and S G . Note that when p < 1, the t-norm will have higher derivatives for higher inputs as the derivative has a singularity at lima→1 = ∞(b < 1).7.4. Product t-normThe product t-norm and t-conorm, visualized in Fig. 6, are T P (a, b) = a · b and S P (a, b) = a + b − a · b. Their derivatives are∂ T P (a, b)∂a= b,∂ S P (a, b)∂a= 1 − b.(36)The derivative of the t-norm is 0 only when a = b = 0, and similarly when a = b = 1 for the t-conorm. The derivative of the t-norm can be interpreted as follows: ‘If we wish to increase a ⊗ b, a should be increased in proportion to b.’ This is not a sensible learning strategy: If both a and b are small, in which case the conjunction is most certainly not satisfied, the derivative will be low instead of high. The derivative of the t-conorm is more intuitive, as it says ‘If we wish to increase a ⊕ b, a should be increased in proportion to 1 − b’. If b is not yet true, we definitely want at least a to be true.Example 6. By using the product t-norm and t-conorm in Equation (31), we get∂ f (a, b, c)∂a= (1 − (1 − a) · c) · b − (1 − a · b) · cAs explained, increase a in proportion to b if it is not true that c and ¬a are true, and decrease a in proportion to c if it is not true that a and b are true.14E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 6. Left: The product t-norm. Right: The product t-conorm.7.5. SummaryThe Gödel t-norm and t-conorm are simple and effective, having strong derivatives almost everywhere. However, they can be quite brittle by making very binary choices. The Łukasiewicz t-norm and t-conorm also have strong derivatives, but vanish on half of the domain. The Yager family of t-norms and t-conorms also vanish on a significant part of its domain. The derivative of the t-norm is larger for lower values, which is a sensible learning strategy. This is not the case for the product t-norm, where the derivative is dependent on the other input value. However, the product t-conorm is intuitive, and corresponds to the intuition that if one input is not true, the other one should be.8. ImplicationFinally, we consider what functions are suitable for modeling the implication. We will start by discussing the particular challenges associated with the implication operator.8.1. Challenges of the material implicationA significant proportion of background knowledge is written as universally quantified implications. Examples of such statements are ‘all humans are mortal’, ‘laptops consist of a screen, a processor and a keyboard’ and ‘only humans wear clothes’. These formulas are of the form ∀x φ(x) → ψ(x), where we call φ(x) the antecedent and ψ(x) the consequent.The implication is used in two well known rules of inference from classical logic. Modus ponens inference says that if ∀x φ(x) → ψ(x) and we know that φ(x) is true, then ψ(x) should also be true. Modus tollens inference, or contraposition, says that if ∀x φ(x) → ψ(x) and we know that ψ(x) is false, then φ(x) should also be false, as otherwise ψ(x) should also have been.Unlike sequences of conjunctions where each of the formulas should be true, when the agent predicts a scene in which an implication is false, the supervisor has multiple choices. Consider the implication ‘all ravens are black’. There are 4 categories for this formula: black ravens (BR), non-black non-ravens (NBNR), black non-ravens (BNR) and non-black ravens(NBR). Assume our agent observes an NBR, then there are four options to consider.1. Modus Ponens (MP): The antecedent is true, so by modus ponens, the consequent is also true. We trust the agent’s observation of a raven and believe it was a black raven (BR).2. Modus Tollens (MT): The consequent is false, so by modus tollens, the antecedent is also false. We trust the agent’s observation of a non-black object and believe that it was not a raven (NBNR).3. Distrust: We think the agent is wrong in both observations, and conclude it was a black non-raven (BNR).4. Exception: We trust the agent in observing a non-black raven (NBR) and ignore the fact that its observation goes against the background knowledge that ravens are black.6The distrust option seems somewhat useless. The exception option can be correct, but we cannot know when there is an exception from the agent’s observations alone.6 This option is not completely ludicrous as white ravens do in fact exist. However, they are rare.15E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602We can assume there are far more non-black objects which are not ravens, than there are ravens. Thus, from a statistical perspective, it is most likely that the agent observed an NBNR. This shows the imbalance associated with the implication, which was first noted in [42] for the Reichenbach implication. It is quite similar to the class imbalance problem in Ma-chine Learning [37] in the sense that one has far more contrapositive examples than positive examples of the background knowledge.This problem is closely related to the Raven paradox [31,72,42] from the field of confirmation theory which ponders what evidence can confirm a statement like ‘ravens are black’. It is usually stated as follows:1. Premise 1: Observing examples of a statement contributes positive evidence towards that statement.2. Premise 2: Evidence for some statement is also evidence for all logically equivalent statements.3. Conclusion: Observing examples of non-black non-ravens is evidence for ‘all ravens are black’.The conclusion follows since ‘non-black objects are non-ravens’ is logically equivalent to ‘ravens are black’. For DFL a similar thing happens. When we correct the observation of an NBR to a BR, the difference in truth value is equal to when we correct it to NBNR. More precisely, representing ‘ravens are black’ as I(a, b), where, for example, I(1, 1) corresponds to BR:A(x1, ..., I(1, 0), ..., xn) − A(x1, ..., I(1, 1), ..., xn) = A(x1, ..., I(1, 0), ..., xn) − A(x1, ..., I(0, 0), ..., xn)as I(0, 0) = I(1, 1) = 1. When one agent observes a thousand BR’s and a single NBR, and another agent observes a thousand NBNR’s and a single NBR, their truth value for ‘ravens are black’ is equal. The first agent has seen many ravens of which only a single was not black. The second only observed non ravens, and a single raven that was not black. Intuitively, the first agent’s beliefs seem more in line with the background knowledge. We will now proceed to analyze a number of implication operators in light of this discussion.8.2. Analyzing the implication operatorsIn this section, we choose to take the negation of the derivative with respect to the antecedent as it makes it easier to compare them: all fuzzy implications are monotonically decreasing with respect to the antecedent.Definition 8. A fuzzy implication I is contrapositive differentiable symmetric if ∂ I(a,c)∂c= − ∂ I(1−c,1−a)∂1−cfor all a, c ∈ [0, 1].A consequence of contrapositive differentiable symmetry is that if c = 1 − a, then derivatives with respect to the an-. This could be tecedent and consequent are each other’s negation since ∂ I(a,c)seen as the ‘distrust’ option which increases the consequent and negated antecedent equally.= − ∂ I(1−(1−a),c)= − ∂ I(1−c,1−a)= − ∂ I(a,c)∂1−(1−a)∂1−c∂a∂cProposition 5. If a fuzzy implication I is N-contrapositive symmetric (that is, for all a, c ∈ [0, 1], I(a, c) = I(N(c), N(a))), where N is the classical negation, it is also contrapositive differentiable symmetric.By this proposition all S-implications are contrapositive differentiable symmetric. This property says there is no difference in how the implication handles the derivatives with respect to the consequent and antecedent.Proposition 6. If an implication I is left-neutral (that is, for all c ∈ [0, 1], I(1, c) = c), then ∂ I(1,c)contrapositive differentiable symmetric, then − ∂ I(a,0)= 1.∂c∂a= 1. If, in addition, I is The proofs of these two propositions are in Appendix C.3. All S-implications and R-implications are left-neutral, but only S-implications are all also contrapositive differentiable symmetric. The derivatives of R-implications vanish when a ≤ c, that is, on no less than half of the domain. This is not necessarily a bad property, although this depends highly on the sort of application we use DFL for. If, for example, a = 0.499 and c = 0.5 for the implication ‘ravens are black’, this expresses a state of uncertainty, and there is probably more that can be learned! However, this will not be possible since the implication vanishes.8.3. Gödel-based implicationsImplications based on the Gödel t-norm make strong discrete choices and are single-passing. As I K D (a, c) = max(1 − a, c), the derivatives are(cid:2)∂ I K D (a, c)∂c=1,0,if 1 − a < cif 1 − a > c, − ∂ I K D (a, b)∂a=if 1 − a > cif 1 − a < c.(cid:2)1,0,16(37)E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 7. Left: The Kleene Dienes implication. Right: The Gödel implication. Plots in this section are rotated so that the smallest value is in the front to help understand the shape of the functions. In particular, plots of the derivatives of the implications are rotated 180 degrees compared to the implications themselves.Or, simply put, if we are more confident in the truth of the consequent than in the truth of the negated antecedent, increase the truth of the consequent. Otherwise, decrease the truth of the antecedent. This decision can be somewhat arbitrary and does not take into account the imbalance of modus ponens and modus tollens.(cid:2)The Gödel implication is a simple R-implication: I G (a, c) =if a ≤ c1,c, otherwise. Its derivatives are:(cid:2)∂ I G (a, c)∂c=1,if a > c0, otherwise, − ∂ I G (a, b)∂a= 0.(38)These two implications are shown in Fig. 7. The Gödel implication increases the consequent whenever a > c, and the antecedent is never changed. This makes it a poorly performing implication in practice. For example, consider a = 0.1and c = 0. Then the Gödel implication increases the consequent, even if the agent is fairly certain that neither is true. Furthermore, as the derivative with respect to the negated antecedent is always 0, it can never choose the modus tollens correction, which, as we argued, is actually often the best choice.8.4. Łukasiewicz and Yager-based implicationsThe Łukasiewicz implication is both an S- and an R-implication. It is given by I L K (a, c) = min(1 − a + c, 1) and has the simple derivatives∂ I L K (a, c)∂c= − ∂ I L K (a, c)∂a(cid:2)=if a > c1,0, otherwise.(39)Whenever the implication is not satisfied because the antecedent is higher than the consequent, simply increase the negated antecedent and the consequent until it is lower. This could be seen as the ‘distrust’ choice as both observations of the agent are equally corrected, and so does not take into account the imbalance between modus ponens and modus tollens cases. The derivatives of the Gödel implication I G are equal to those of I L K except that I G always has a zero derivative for the negated antecedent.(cid:26)p , 1, p > 0. We plot I Y for p = 2 in Fig. 8. p = 1 is (cid:25)(cid:5)(1 − a)p + c pI L K , p = 0 is I D P , and p = ∞ is I K D . The derivatives are computed asThe Yager S-implication is given as I Y (a, c) = min(cid:6) 1(cid:2)(cid:5)∂ I Y (a, c)∂c=− ∂ I Y (a, c)∂a=(1 − a)p + c p0,(cid:2)(cid:5)(1 − a)p + c p0,(cid:6) 1p(cid:6) 1p−1 · c p−1,−1 · (1 − a)p−1,if (1 − a)p + c p ≤ 1,otherwiseif (1 − a)p + c p ≤ 1,otherwise.We plot these derivatives for p = 2 in Fig. 9. For all p, limc→0∂ I Y (1,c)∂c= 1. Furthermore, for p > 1, lima→117(40)(41)∂ I Y (a,c)∂c(cid:14)(cid:14)(cid:14)c=0= 0E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 8. Left: The Yager S-implication. Right: The Yager R-implication. For both, p = 2.Fig. 9. Plots of the derivatives of the Yager S-implication for p = 2.= ∞. For p > 1, I Y can be understood as an increasingly less smooth version of the and for p < 1, lima→1Kleene-Dienes implication I K D . Lastly, this derivative, like those for T Y and S Y (Section 7.3), is nonvanishing for a fraction ∂ I Y (a,0)∂0(cid:23)(cid:24)(cid:14)(cid:14)(cid:14)c=0√of π 4−1/p (cid:10)(cid:23)p(cid:10)12+ 1p1p(cid:24)of the input space.The Yager R-implication is found (Appendix D.4) as I T Y (a, c) =(cid:2)1,1 −(cid:5)(1 − c)p − (1 − a)p(cid:6) 1if a ≤ cp , otherwise.We plot I T Y for p = 2 in Fig. 8. As expected, p = 1 reduces to I L K , p = 0 reduces to I W B and p = ∞ reduces to I G . It is contrapositive symmetric only for p = 1. The derivatives of this implication are(cid:2)∂ I T Y (a, c)∂c=((1 − c)p − (1 − a)p)0,(cid:2)− ∂ I T Y (a, c)∂a=((1 − c)p − (1 − a)p)0,1p−1 · (1 − c)p−1,if a > cotherwise,1p−1 · (1 − a)p−1,if a > cotherwise.(42)(43)We plot these in Fig. 10. Note that if p > 1, for all c < 1 it holds that lima↓c∂ I T Y (a,c)∂ca approaches c from above, (1 − c)p − (1 − a)p approaches 0, giving a singularity as 0singularities makes the training unstable in practice.1p= lima↓c − ∂ I T Y (a,c)= ∞ as when −1 is undefined. This collection of ∂a18E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 10. Plots of the derivatives of the Yager R-implication for p = 2.Fig. 11. Left: The Reichenbach implication. Right: The Goguen implication.8.5. Product-based implicationsThe product S-implication, also known as the Reichenbach implication, is given by I RC (a, c) = 1 − a + a · c. We plot it in Fig. 11. Its derivatives are given by:= a, − ∂ I RC (a, c)∂ I RC (a, c)∂c∂a= 1 − c.(44)These derivatives closely follow the modus ponens and modus tollens rules. When the antecedent is high, increase the consequent, and when the consequent is low, decrease the antecedent. However, around (1 − a) = c, the derivative is equal and the ‘distrust’ option is chosen. This can result in counter-intuitive behavior. For example, if the agent predicts 0.6 for raven and 0.5 for black and we use gradient descent until we find a maximum, we could end up at 0.3 for raven and 1 for black. We would end up increasing our confidence in black as raven was high. However, because of additional modus tollens reasoning, raven is barely true.Furthermore, if the agent most of the time predicts values around a = 0, c = 0 as a result of the modus tollens case being the most common, then a majority of the gradient decreases the antecedent as − ∂ I RC (a,0)= 1. We identify two methods that counteract this behavior. We introduce the second method in Section 8.5.1. The first method for counteracting the ‘corner’ behavior notes that different aggregators change how the derivatives of the implications behave when their truth value is high. For instance, we find that the derivatives with respect to the negated antecedent when using the log-product aggregator and RMSE aggregator are(cid:14)(cid:14)(cid:14)a=0∂a∂ log ◦ A P (I RC (a1, c1), ..., I RC (an, cn))∂1 − ai=1 − ci1 − ai + ai · ci=¬ca → c,(45)19E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 12. Left: The antecedent derivative of the Reichenbach implication with the log-product aggregator. Right: The antecedent derivative of the Reichenbach implication with the RMSE aggregator.Fig. 13. The derivatives of the Goguen implication. Note that we plot these in log scale.∂ A R M S E (I RC (a1, c1), ..., I RC (an, cn))∂1 − ai= (1 − ci)(ai − ai · ci)j=1(a j − a j · c j)2(cid:30)n(cid:4)n=(cid:30)n¬ci(¬(ai → ci))(cid:4)nj=1(¬(a j → c j))2.(46)We plot these functions in Fig. 12. For the RMSE aggregator we choose n = 2 and a1, c1 so that (a1 − a1 · c1)2 = 0.9. Note that the derivative with respect to the negated antecedent using the RMSE aggregator is 0 in ai = 0, ci = 0 as then ai − ai · ci = 0, and using the log-product aggregator, the derivative is 1. By differentiable contrapositive symmetry, the consequent derivative is 0 when using both aggregators. This shows that when using the RMSE aggregator, the derivatives will vanish at the corners a = 0, c = 0 and a = 1, c = 1, while when using the log-product aggregator, one of a and c will still have a gradient.(cid:2)The R-implication of the product t-norm is the Goguen implication and given by I G G (a, c) =this implication in Fig. 11. The derivatives of I G G are(cid:2)∂ I G G (a, c)∂c=if a ≤ c0,1a , otherwise, − ∂ I G G (a, c)∂a(cid:2)=if a ≤ c0,ca2 , otherwise.if a ≤ c1,ca , otherwise. We plot (47)We plot these in Fig. 13. This derivative is not very useful. First of all, both the modus ponens and modus tollens derivatives increase with ¬a. This is opposite of the modus ponens rule as when the antecedent is low, it increases the consequent most. For example, if raven is 0.1 and black is 0, then the derivative with respect to black is 10, because of the singularity when a approaches 0.20E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 14. The consequent derivatives of the log-Reichenbach and log-Reichenbach-sigmoidal (with s = 9) implications. The figure is plotted in log scale.8.5.1. Sigmoidal implicationsFor the second method for tackling the corner problem, we introduce a new class of fuzzy implications formed by transforming other fuzzy implications using the sigmoid function and translating it so that the boundary conditions still hold. The derivation, along with several proofs of properties, can be found in Appendix D.2.Definition 9. If I is a fuzzy implication, then the I -sigmoidal implication σI is given for s > 0 and b0 ∈ R asσI (a, c) = 1 + e−s(1+b0)e−b0s − e−s(1+b0)(cid:23)(cid:23)·1 + e(cid:24)−b0s· σ (s · (I(a, c) + b0)) − 1(cid:24)(48)where σ (x) = 11+ex denotes the sigmoid function.Here b0 is a parameter that controls the position of the sigmoidal curve and s controls the ‘spread’ of the curve. σI is the function σ (s · (I(a, c) + b0)) linearly transformed so that its codomain is the closed interval [0, 1]. For the common value of b0 = − 12 , a simpler form exists:σI (a, c) = 1(cid:25)(cid:23)·s2 − 1e(cid:25)(cid:25)(cid:24)s21 + e· σs ·(cid:26)(cid:26)(cid:26)− 1.I(a, c) − 12Next, we give the derivative of σI . Substituting d = 1+e−s·(1+b0)−s·(1+b0) and h =−s·b0 −ee(cid:5)1 + e(cid:6)−s·b0, we find∂σI (a, c)∂ I(a, c)= d · h · s · σ (s · (I(a, c) + b0)) · (1 − σ (s · (I(a, c) + b0))).(49)(50)This keeps the properties of the original function but smoothens the gradient for higher values of s. As the derivative of the sigmoid function is positive, this derivative vanishes only when the derivative of I vanishes.We plot the derivatives for the Reichenbach-sigmoidal implication σI RC in Fig. 15. As expected by Proposition 16, it is differentiable contrapositive symmetric. Compared to the derivatives of the Reichenbach implication it has a small gradient in all corners. When using the log-product aggregator, the derivative of the antecedent with respect to the total valuation is divided by the truth of the implication. In Fig. 14 we compare the consequent derivative of the normal Reichenbach implication with the Reichenbach-sigmoidal implication when using the log function. Clearly, for both there is a singularity at a = 1, c = 0, as then the implication is 0 and so the derivative of the log function becomes infinite. A significant difference is that the sigmoidal variant is less ‘flat’ than the normal Reichenbach implication. This can be useful, as this means there is a larger gradient for values of c that make the implication less true. In particular, the gradient at the modus ponens case (a = 1, c = 1) and the modus tollens case (a = 0, c = 0) are far smaller, which could help balancing the effective total gradient by solving the ‘corner’ problem of the Reichenbach implication we brought up in Section 8.5. These derivatives are smaller for higher values of s.In Fig. 16 we plot the Reichenbach-sigmoidal implication for different values of the hyperparameters b0 and s. Comparing 16a and 16b we see that larger values of b0 move the sigmoidal shape so that its center is at lower input values. Note that for s = 0.01 in Fig. 16c, the plotted function is indiscernible from the plot of the Reichenbach implication in Fig. 11 as the interval on which the sigmoid acts is extremely small and the sigmoidal transformation is almost linear. For very high values of s like in 16d we see that the ‘S’ shape is much thinner, and a larger part of the domain has a low derivative.21E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 15. The derivatives of the Reichenbach-sigmoidal implication for s = 9.8.6. SummaryWe analyzed several fuzzy implications from a theoretical perspective, while keeping the challenges caused by the mate-rial implication in mind. As a result of this analysis, we find that popular R-implications, in particular the Gödel implication, the Yager R-implication and the Goguen implication, will not work well in a differentiable setting. The other analyzed implications seem to have more intuitive derivatives, but may have other practical issues like non-smoothness.9. Experimental setupTo get insights in the behavior of these operators in practice, we next perform a series of simple experiments to analyze them. We discuss experiments using the MNIST dataset of handwritten digits [43] to investigate the behavior of different fuzzy operators introduced in this paper. The goal of the experiments is not to show that our method is state of the art for the problem of semi-supervised learning on MNIST, but rather to be able to get insights into how fuzzy operators behave in a differentiable setting.79.1. MeasuresTo investigate the performance of the different configurations of DFL, we first introduce several useful metrics. These give us insight into how different operators behave. In this section, we assume we are dealing with formulas of the form ϕ = ∀x1, ..., xm φ → ψ .Definition 10. The consequent magnitude |cons| and the antecedent magnitude |ant| for a knowledge base K is defined as the sum of the partial derivatives of the consequent and antecedent with respect to the DFL loss:|cons| =(cid:12)(cid:12)ϕ∈Kμ∈Mϕ∂eθ (μ, ϕ)∂eθ (μ, ψ),|ant| =(cid:12)−(cid:12)ϕ∈Kμ∈Mϕ∂eθ (μ, ϕ)∂eθ (μ, φ),(51)where Mϕ is the set of instances of the universally quantified formula ϕ and ψ and φ are evaluated under instantiation μ.The consequent ratio cons% is the sum of consequent magnitudes divided by the sum of consequent and antecedent magnitudes: cons% = |cons||cons|+|ant| .Definition 11. Given a labeling function l that returns the truth value of a formula according to the data for instance μ, the consequent and antecedent correctly updated magnitudes are the sum of partial derivatives for which the consequent or the negated antecedent is true:cucons =(cid:12)(cid:12)ϕ∈Kμ∈Mϕl(ψ, μ) · ∂eθ (μ, ϕ)∂eθ (μ, ψ),cuant =(cid:12)−(cid:12)ϕ∈Kμ∈Mϕl(¬φ, μ) · ∂eθ (μ, ϕ)∂eθ (μ, φ).(52)7 Code is available at https://github .com /HEmile /differentiable -fuzzy-logics.22E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 16. The Reichenbach-sigmoidal implication for different values of b0 and s.That is, if the consequent is true in the data, we measure the magnitude of the derivative with respect to the consequent. To evaluate these quantities, we define ratios similar to a precision metric:Definition 12. The correctly updated ratios for consequent and antecedent are defined ascucons% =(cid:4)(cid:4)ϕ∈K cuconsϕϕ∈K |cons|ϕ,cuant% =(cid:4)(cid:4)ϕ∈K cuantϕϕ∈K |ant|ϕ.(53)These quantify what fraction of the updates are going in the right direction. When these ratios approach 1, DFL will always increase the truth value of the consequent or negated antecedent correctly.8 Otherwise, we are increasing truth values of subformulas that are wrong. Ideally, we want these measures to be high.8 It can still change the truth value of a ground atom wrongly if φ or ψ are not atomic formulas.23E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 1036029.2. FormulasWe use a knowledge base K of universally quantified logic formulas. There is a predicate for each digit, that is zero, one, ..., eight and nine. For example, zero(x) is true whenever x is a handwritten digit labeled with 0. We have two sets of formulas where we learn an additional binary predicate.9.2.1. The same problemThe same problem is a simple problem to test different operators for implication and universal aggregation. We use the binary predicate same that is true whenever both its arguments are the same digit. We next describe the formulas we use.1. ∀x, y zero(x) ⊗ zero( y) → same(x, y), ..., ∀x, y nine(x) ⊗ nine( y) → same(x, y). If both x and y are handwritten zeros, for example, then they represent the same digit.2. ∀x, y zero(x) ⊗ same(x, y) → zero( y), ..., ∀x, y nine(x) ⊗ same(x, y) → nine( y). If x and y represent the same digit and one of them represents zero, then the other one does as well.3. ∀x, y same(x, y) → same( y, x). This formula encodes the symmetry of the same predicate.We find in Appendix F.1 that a set of operators is better than random guessing for the consequent updates if cucons% > 0.1, and that we know with confidence a set of operators to be better than random if cuant% > 0.99.9.2.2. The sum9 problemIn the second problem we use the binary predicate sum9 that is true whenever its arguments sum to 9. We use this problem to test existential quantification, conjunction and disjunction. The formulas are1. ∀x∃ y sum9(x, y). For each digit, there is another such that their sum is 9.92. ∀x, y sum9(x, y) → (zero(x) ⊗ nine( y)) ⊕ (one(x) ⊗ eight( y)) ⊕ · · · ⊕ (nine(x) ⊗ zero( y)): This formula defines the sum9predicate.9.3. Experimental methodologyWe split the MNIST dataset so that 1% of it is labeled and 99% is unlabeled. Given a handwritten digit x labeled with digit y, pθ ( y|x) computes the distribution over the 10 possible labels. We use 2 convolutional layers with max pooling, the first with 10 and the second with 20 filters. Then follows two fully connected hidden layers with 320 and 50 nodes and a softmax output layer. The probability that same(x1, x2) for two handwritten digits x1 and x2 holds is modeled by pθ (same|x1, x2). This takes the 50-dimensional embeddings of x1 and x2 of the fully connected hidden layer ex1 and ex2 . These are used in a network architecture called a Neural Tensor Network [69]:(cid:25)(cid:26)(cid:26)(cid:25)(cid:31)pθ (same|x1, x2) = σ(cid:2)utanh(cid:2)x1 We[1:k]+ Vex2ex1ex2+ b.(54)[1:k] ∈ Rd×d×k is used for the bilinear tensor product, V ∈ Rk×2d is used for the concatenated embeddings and b ∈ Rk is Wused as a bias vector. We use k = 50 for the size of the hidden layer. u ∈ Rk is used to compute the output logit, which goes through the sigmoid function σ to get the confidence value.The loss function we use is split up in three parts, the first over the unlabeled dataset Du , and the two others over the labeled dataset Dl :L(θ ) = w D F L · LD F L((cid:13)Du, η, θ (cid:14), K) −(cid:12)x, y∈Dllog pθ ( y|x) −(cid:12)x1, y1,x2, y2∈Dl×Dllog pθ (same = 1 y1= y2|x1, x2)(55)The first term is the DFL loss which is weighted by the DFL weight w D F L . The second is the supervised cross entropy loss with a batch size of 64. The third is the supervised binary cross entropy loss used to learn to recognize same(x, y).10This loss is log pθ (sum9 = 1 y1+ y2=9|x1, x2) for the sum9 problem. As there are far more negative examples than positive examples, we undersample the negative examples. Note that the two supervised losses can also be seen as a universal aggregation over logical facts using the log-product aggregator: − Alog T P (pθ ( y1|x1), ..., pθ ( y|Dl||x|Dl|)). For optimization, we used ADAM [39] with a learning rate of 0.001.9 We sample minibatches of 64 digits, which means there is a negligible probability that there exists a digit in the minibatch for which there is no match (0.0117, to be precise).10 It is possible to not use this loss term and learn the same predicate using just the formulas, although this is more challenging and only works with a good set of fuzzy operators.24 E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Table 6Results on the same problem for several symmetric configurations with either S-implications or R-implications. For all, w D F L = 1 except for T P , for which w D F L = 10.S-ImplicationsR-ImplicationsAccuracycons%T GT PT L KT Y , p = 1.5T Y , p = 2T Y , p = 20T Nm95.396.594.995.277.795.695.20.320.080.50.200.02cucons%0.310.720.860.510.54cuant%0.830.990.120.750.75Accuracycons%95.094.894.995.295.095.595.210.620.50.620.53cucons%0.110.040.860.610.01cuant%-0.960.120.460.9910. ResultsWe ran experiments for many combinations of operators with the aim of showing that the discussed insights are present in practice. We report the accuracy of recognizing digits in the test set, the consequent ratio cons%, and the consequent and antecedent correctly updated ratios cucons% and cuant%. We train for at most 70.000 iterations (or until convergence). The purely supervised baseline has a test accuracy of 95.18% ± 0.204, and runs for about 35 minutes. Semi-supervised methods should improve upon this baseline to be useful. Our implementation including DFL runs for 1 hour and 52 minutes.10.1. Symmetric configurationsFirst, we consider several symmetric configurations, where the conjunction is a t-norm T , disjunction the dual t-conorm of T , universal aggregation the extended t-norm A T , existential aggregation the extended t-conorm E S and the implication either is the S-implication based on the t-conorm or the R-implication based on the t-norm. For example, for T P we use = log ◦ A T P for aggregation and I RC for implication. Symmetric configurations T P for conjunction, S P for disjunction, Alog T Pwill retain many equivalence relations in fuzzy logic, unlike when one would choose arbitrary configuration of operators.10.1.1. Symmetric configurations on same problemAll configurations are run with w D F L = 1 except for T P which is run using w D F L = 10. The results on the same problem can be found in Table 6. One general observation that can be made is that S-implications seem to work much better than R-implications. The only configuration with R-implications that outperform the supervised baseline is T Y , p = 20, but here the S-implication performs similar to it. We hypothesize this is because the derivatives of R-implications vanish whenever a ≤ c.The Gödel t-norm performs on par with the supervised baseline. This is because the min aggregator is single-passing, like the configuration as a whole. The single instance which receives a derivative might just be an exception as argued in Section 6.1 and evident from the low values of cucons% and cuant%.The Łukasiewicz t-norm performs worse than the supervised baseline. Since A L K either has a derivative of 0 or 1 ev-erywhere, the total gradient is very large when it does not vanish. By the definition of I L K , cons% = 12 as the consequent and negated antecedent derivatives are equal (see Equation (39)). cucons% is very low with only 0.01, which is worse than random guessing. As half of the gradient is MP reasoning, that half is nearly always incorrect. The performance of the Yager t-norm seems highly dependent on the choice of the parameter p. For p = 20 the top performance is quite a bit higher than the baseline. The lower the value of p, the more likely it is that the derivative of the universal aggregator vanishes. However, for p = 2, the results are even worse than the Łukasiewicz t-norm, which corresponds to p = 1, while the derivative with p = 1.5 simply vanishes throughout the whole run.The product t-norm performs best and also has the highest values for cucons% and cuant%. To a large extent this is because the log-product aggregator is very effective, as other symmetric configurations also perform much better with it Appendix F.2. Finally, the Nilpotent t-norm performs exactly like the supervised baseline since the derivative of the universal aggregator vanished during the complete training run.10.1.2. Symmetric configurations on the sum9 problemIn addition to the same problem, we also run the symmetric configurations on the sum9 problem to be able to also take into account how existential quantification and disjunction behave. The results are in Table 7. These closely reflect the results for the same problem. Again, the only configurations that clearly outperform the supervised baseline are the product t-norm and the Yager t-norm with p = 20, with the product t-norm being the most promising candidate. Furthermore, in addition to the Nilpotent t-norm, the derivatives of the Łukasiewicz t-norm and Yager t-norm with p = 2 vanish throughout the whole run.10.2. Individual operatorsWe also perform several experiments where we investigate the contribution of specific fuzzy operators without regard to whether the resulting configurations are sensible in a logical sense. We do this to better understand how each operator 25E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Table 7Results on the sum9 problem for several symmetric configu-rations using the S-implication. w D F L = 1 except for T P with w D F L = 10.Accuracycons%0.310.13cucons%0.440.80cuant%0.780.950.990.820.71T GT PT L KT Y , p = 1.5T Y , p = 2T Y , p = 20T Nm95.296.195.295.295.295.595.2Table 8Left: Results on the same problem, varying the universal aggregator. For all, w D F L = 10. Right: Results on the sum9problem, varying the existential aggregator.AccuracyA T GAlog T PA T L KA T Y , p = 1.5A T Y , p = 2A T Y , p = 20AG M E , p = 1.5A R M S EAG M E , p = 20A T Nm86.696.378.279.583.384.096.196.295.579.8cons%Universal aggregationcucons%0.650.530.940.770.830.810.430.420.380.500.370.140.000.000.000.000.430.460.450.34Existential aggregationcuant%0.450.960.990.980.980.980.760.720.700.58Accuracycons%E S GE S PE S L KE S YE S YE S YE G ME G ME G ME S Nm95.396.195.995.996.396.396.996.796.495.50.380.150.170.210.270.370.290.290.390.31cucons%0.600.680.760.640.590.620.130.140.640.58cuant%0.660.940.870.850.810.700.950.940.700.78Table 9Results on the sum9 problem, varying the t-norm and t-conorm together.Accuracycons%T GT PT L KT Y , p = 1.5T Y , p = 2T Y , p = 20T Nm20.420.397.097.096.894.996.90.470.460.310.290.300.660.31cucons%0.150.160.150.110.110.160.17cuant%0.900.920.930.960.960.860.93contributes to the learning process. Throughout this section, we fix the universal aggregation operator to the log-product aggregator Alog T P , the existential aggregation operator to the generalized mean E G M with p = 1.5, the conjunction and disjunction to T Y and S Y , also with p = 1.5, and the implication to the Reichenbach-sigmoidal implication with s = 9 and b = −0.5. We select these because of their promise in initial experiments.10.2.1. AggregationTable 8 shows the results when varying the universal aggregator in the same problem, and when varying the existential aggregator in the sum9 problem. The log-product operator with w D F L = 10 is the best universal aggregator, with A R M S Etrailing behind it slightly. Other generalized mean errors are also effective. We also see that the single-passing aggregators (minimum and Nilpotent minimum aggregators) and aggregators that vanish on a large part of their domain (Yager-based and Nilpotent minimum) all perform poorly. However, curiously the Yager-based aggregators have very high cucons% and cuant%.The generalized means have the best result for existential aggregation, with p = 1.5 performing best. They manage to properly select the inputs that make the existential quantifier true by softly increasing the largest inputs. Unlike with universal aggregation, the Yager existential aggregator is also a decent choice. The maximum aggregator and Nilpotent maximum aggregator only somewhat outperform the supervised baseline, however, which again is due to them being single-passing.10.2.2. Conjunction and disjunctionIn Table 9, we compare different t-norms together with their corresponding t-conorms. Here, it is the operators that vanish on a large part of their domain that work best, namely Yager t-norms and the Nilpotent minimum. These seem to work much better than when used in aggregation since the amount of inputs is much smaller, reducing the probability that the derivative vanishes. The product t-norm and Gödel t-norm, which corresponds to weak conjunction and disjunction, seem to do perform very poorly. In this table, there is a clear relation where lower cons% seem to perform better. It is likely 26E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Table 10Results on the same problem for several symmetric configurations with either S-implications or R-implications.S-ImplicationsR-ImplicationsAccuracycons%I K DI RCI L KI Y , p = 1.5I Y , p = 2I Y , p = 20I F DσI RC95.796.396.096.196.295.196.196.30.080.090.50.140.130.570.190.14cucons%0.820.730.070.770.820.480.680.53cuant%0.980.980.930.960.970.980.910.96Accuracycons%I GI G GI L KI R YI R YI R YI F D90.593.696.096.195.796.096.110.990.50.140.130.140.19cucons%0.050.000.070.140.640.650.68cuant%0.870.930.660.380.380.91lower in the Yager t-norm since the disjunction in the consequent will very often be 1, which happens when the sum in the Yager t-norm hits the boundary.10.2.3. ImplicationsIn Table 10, we compare different fuzzy implications on the same problem. The Reichenbach implication and Yager S-implication work well, both having an accuracy around 97%. The Kleene Dienes and Yager R-implications surpass the baseline as well. In these experiments, the sigmoidal-Reichenbach implication, which we run with s = 9 and b = − 12 per-forms as well as the normal Reichenbach implication. However, we find in Appendix F.3 that with the SGD algorithm, this implication outperforms the Reichenbach implication, reaching 97.3 accuracy.As argued in Sections 8.3 and 8.5, the Gödel implication and Goguen implication have worse performance than the supervised baseline by making many incorrect modus ponens inferences. While the derivatives of I L K and I G only differ in that I G disables the derivatives with respect to negated antecedent, I L K performs among the better while I G is the worst test implication, suggesting that the derivatives with respect to the negated antecedent are required to successfully applying DFL. Note that S-implications tend to perform better than R-implications, in particular for the Gödel t-norm and the product t-norm. This could be because they inherently balance derivatives with respect to the consequent and negated antecedent by being contrapositive differentiable symmetric.10.2.4. Additional experimentsIn Appendix F.3 we investigate the parameters s and b0 of the sigmoidal-Reichenbach implication. We find here that it is the best performing implication on the same problem when using the vanilla SGD optimizer, reaching 97.3% accuracy. Furthermore, in Appendix F.4 we investigate for the same problem what the influence of each rule is to the learning process.We also ran the sum9 problem on the vanilla SGD optimizer with the fixed configuration from Section 10.2, which reaches 97.7% accuracy. This is significantly higher than with ADAM, confirming our findings for same problem in Sec-tion 10.2.3. Finally, we ran with the same settings using both the formulas from the same problem and the sum9 problem. This has the best accuracy we find in our experiments with 98.0%, and confirms that adding more background knowledge increases the final performance.10.3. AnalysisWe plot the accuracy of the different configurations with respect to cucons and cuant in Figs. 17a and 17b. The blue dots represent runs on the same problem, while the red dots represent runs on the sum9 problem. Fig. 17b shows a positive correlation, suggesting that it is vital to the learning process that updates going into the antecedent are correct. Although there seems to be a slight positive correlation in Fig. 17a for the same problem, it is not as pronounced. Furthermore, it seems that for the sum9, this correlation is negative instead, as the configurations with the highest accuracy have low values of cucons.We plot all experimental values of cons% to the values of cucons% and cuant% in Figs. 17c and 17d. For both, there seems to be a negative correlation. Apparently, a larger consequent ratio decreases the correctness of the updates. In Appendix F.3we find, when experimenting with the value of s, that this could be because for lower values of cons%, a smaller portion of the reasoning happens in the corners around a = 0, c = 0 and a = 1, c = 1, and more for instances that the agent is less certain about. Since all S-implications have strong derivatives at both these corners (Proposition 6), this phenomenon is likely present in other S-implications.This all suggests we need to properly balance the contribution of updates to the antecedent and consequent. Since usually, as reasoned in Section 8.1, derivatives with respect to the antecedent are more common, this balance should be reflected in the experimental ratio between these updates.10.4. ConclusionsWe have run experiments on many configurations of hyperparameters to explore what works and what does not. The only well performing fully symmetric option is the product t-norm with the Reichenbach implication. If we are willing to 27E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 17. We plot several of the analytical measures to find their relations. Blue dots represent runs on the same problem while red dots represent runs on the sum9 problem. (For interpretation of the colors in the figure(s), the reader is referred to the web version of this article.)forego symmetry, we find that the choice of the aggregators is the most important factor for performance. For universal aggregation, we recommend the log-product aggregator, while for existential quantification we recommend the generalized mean with a value of p of somewhere between 1 and 2. We found that it is especially important to choose aggregation operators that do not vanish on a large part of their domain, and that are not single-passing. In our experiments, a well tuned sigmoidal-Reichenbach implication coupled with vanilla SGD proved to be the most effective fuzzy implication. In general, we recommend choosing S-implications above R-implications. For conjunction and disjunction, we recommend tuning the Yager t-norm, although this value can be dependent on the complexity of the formulas to prevent the derivative from vanishing during the whole run.Although Differentiable Fuzzy Logics significantly improves on the supervised baseline and is thus suited for semi-supervised learning, it is not currently competitive with state-of-the-art methods like Ladder Networks [62] which has an accuracy of 98.9% for 100 labeled pictures and 99.2% for 1000.11. Related workDifferentiable Fuzzy Logics falls into the discipline of Statistical Relational Learning [24], which concerns models that can reason under uncertainty and learn relational structures like graphs.11.1. Differentiable Fuzzy LogicsSpecial cases of DFL have been researched in several papers under different names. Logic Tensor Networks (LTN) [2,67]implements function symbols and uses neural model to interpret predicates. LTN is applied to weakly supervised learning on Scene Graph Parsing [19] and transfer learning in Reinforcement Learning [3].Semantic-based regularization (SBR) [17] applies DFL to kernel machines. They use R-implications and the mean aggre-gator. Sen et al. [66] applies SBR to collective classification by predicting using a trained deep learning model, and then optimizes the DFL loss to find new truth values. This ensures predictions are consistent with the formulas during test-time.Marra et al. [50] uses t-norm Fuzzy Logics, where the R-implication is used alongside weak disjunction. By using t-norms based on generator functions, the satisfiability computation can be simplified and generalizations of common loss functions can be found. Marra et al. [48] applies DFL to image generation. It uses the product t-norm, the log-product aggregator and the Goguen implication. By using function symbols that represent generator neural networks, they create constraints that are used to create a semantic description of an image generation problem. Rocktäschel et al. [65] uses the product t-norm and Reichenbach implication for relation extraction by using an efficient matrix embedding of the rules. Guo et al. [26]extends this to link prediction and triple classification by using a margin-based ranking loss for implications.Demeester et al. [16] uses a regularization technique equivalent to the Łukasiewicz implication. Instead of using existing data, it finds a loss function which does not iterate over objects, yet can guarantee that the rules hold. This is very scalable, but can only model simple implications. A promising approach is using adversarial sets [52], which is a set of objects 28E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602from the domain that do not satisfy the knowledge base. These are probably the most informative objects. It uses gradient descent to find objects that minimize the satisfiability. The parameters of the deep learning model are then updated so that it predicts consistent with the knowledge base on this adversarial set. A benefit of this approach is that it does not have to iterate over instances that already satisfy the constraints. Adversarial sets are applied to natural language interpretation in [53]. Both papers use the Łukasiewicz implication and Gödel t-norm and t-conorm. They are not able to infer new labels on existing unlabeled data as they use artificial data, but these methods are not orthogonal and can be used jointly.11.2. Neuro-symbolic methods using fuzzy logic operatorsPosterior regularization [21,32] is a framework for weakly-supervised learning on structured data. It projects the output of a deep learning model to a ‘rule-regularized subspace’ to make it consistent with the knowledge base. This output is used as a label for the deep learning model to imitate. Unlike this paper, it does not compute derivatives over the computation of the satisfaction of the knowledge base. Marra et al. [49] and Daniele and Serafini [13] instead use gradient descent for the projection. Therefore, unlike earlier methods for posterior regularization, derivatives with respect to the operators are used. They learn relative formula weights jointly with the parameters of the deep learning model.Arakelyan et al. [1] uses t-norms, t-conorms and existential quantification to answer queries by finding what entity embedding has the highest truth value of a given query. This search is done using gradient descent. By comparing what entity embedding best fits the optimized entity embedding, the authors can answer complex FOL queries. The authors either use the product or the Gödel t-norms.Another recent work which employs fuzzy logic operators in a neuro-symbolic setting is Logical Neural Networks [63]. This work stands orthogonal to our work, as the foremost distinction is that they employ logics on the low-level (i.e., logical connectives as neurons and neural activation functions) while we employ it on the higher level (i.e., in defining the loss function). They limit their work to the propositional level for simplification purposes, although they argue that extending it to relational level is straightforward.∂ ILP [20] is a differentiable inductive logic programming that uses the product t-norm and t-conorm to do differentiable inference. The Neural Theorem Prover [64] does differentiable proving of queries and combines different proof paths using the Gödel t-norm and t-conorm. Šourek et al. [70] also introduces a method for differentiable query proving, with learnable weights for formulas. They use operators inspired by fuzzy logic and transformed by the sigmoid function.There is a vast literature on Fuzzy Neural Networks [35,36,44] that replace standard neural network neurons with neu-rons based on fuzzy logic. Some neurons use fuzzy logic operators which are differentiated through if the networks are trained using backpropagation.11.3. Differentiable probabilistic logicsSome approaches use probabilistic logics instead of fuzzy logics and interpret predicates probabilistically. As deep learn-ing classifiers can model probability distributions, probabilistic logics could be a more natural choice than fuzzy logics. DeepProbLog [46] is a probabilistic logic programming language with neural predicates that compute the probabilities of ground atoms. It supports automatic differentiation which can be used to back-propagate from the loss at a query predi-cate to the deep learning models that implement the neural predicates, similar to DFL. It also supports probabilistic rules which can handle exceptions to rules. We compare another differentiable probabilistic logic called Semantic Loss [74] in Appendix E and show similarities between it and DFL using operators based on the product t-norm. This similarity suggests that many practical problems that DPFL has are also present in Semantic Loss. They apply Semantic Loss to MNIST semi-supervised learning with a different knowledge base than ours. As inference is exponential in the size of the grounding for probabilistic logics, both approaches use an advanced compilation technique [14] to make inference feasible for larger problems.12. DiscussionThis paper presented theoretical results of Differentiable Fuzzy Logics operators and then evaluated their behavior on semi-supervised learning. We now discuss some problems with deploying solutions using DFL.DFL can be seen as a form of multi-objective optimization [33]. In the DFL loss (Equation (11)) we sum up the valuations of different formulas, each of which is a separate objective. Each of these objectives can be weighted differently, resulting in wildly varying loss landscapes. Having so many objectives requires significant hyperparameter tuning. A method capable of learning relative formula weights jointly like [49,13,70], could solve this problem.A second challenge is related to the class imbalance problem [37,9]. We argued in Section 8.1 that for a significant portion of common-sense background knowledge, the modus tollens case is by far the most common. Our same problem indeed showed that most well-performing implications have a far larger derivative with respect to the negated antecedent than to the consequent. This imbalance will only increase for more complex problems. However, simply removing derivatives with respect to the antecedent does not seem to be the solution. A reason for this could be that those are usually correct, unlike derivatives with respect to the consequent. In fact, we found in Appendix F.4 that the formula in which the digits are 29E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602in the antecedent performs better on its own than the formula in which the digits are in the consequent, even though the model could not learn from any new positive examples.Although we have focused on experimenting with the accuracy of the derivatives of the implication, it should be noted that the derivatives of the disjunction operator make a choice as well. For example, if the agent observes a walking object and the supervisor knows that only humans and animals can walk, how is the supervisor supposed to choose whether it is a human or an animal? Here, similar imbalances exist in the different possible classes: There might be more images of humans than of animals.Further, we pose whether it is more important that we choose operators based on the performance on the task at hand, or based on its logical properties. The best configuration uses operators based on both the product and Yager t-norms. The product t-norm is the only viable symmetric choice in our experiments. The largest benefit of a ‘symmetric’ choice of operators is that the truth value of formulas that are logically equivalent in classical logic will be equal. This makes it easier to analyze how the background knowledge will behave and does not require putting it in a particular form.As a final remark, noteworthy is the interpretation of truth values. As aforementioned, the logic we use is fuzzy logic which was originally aimed to address logical reasoning in the presence of vagueness rather than probabilistic uncertainty. The truth values derived using fuzzy operators, therefore, are not probabilistic (see, for instance, [28, p. 4]).11However, since a considerably large amount of problems addressed by machine learning literature is probabilistic (as it has mathematical origins in statistics), the classification task used in our running example is also of probabilistic origin. With this choice we also aimed to respect the recent literature: Applications of fuzzy operators on a general set of problems which are not necessarily fuzzy are not uncommon in neuro-symbolic AI. Examples include [67], [63], [1], among others cited in Section 11.13. ConclusionWe analyzed Differentiable Fuzzy Logics in order to understand how reasoning using logical formulas behaves in a differentiable setting. We examined how the properties of a large amount of different operators affect DFL. We have found substantial differences between the properties of a large number of such Differentiable Fuzzy Logics operators, and we showed that many of them, including some of the most popular operators, are highly unsuitable for use in a differentiable learning setting. By analyzing aggregation functions, we found that the log-product aggregator and the RMSE aggregator have convenient connections to both fuzzy logic and machine learning and can deal with outliers. Next, we analyzed conjunction and disjunction operators and found several strong candidates. In particular, the Gödel t-norm and t-conorm are a simple choice, and that the Yager t-norm and the product t-conorm have intuitive derivatives.We noted an interesting imbalance between derivatives with respect to the negated antecedent and the consequent of the implication. Because the modus tollens case is much more common, we conclude that a large part of the useful inferences on the MNIST experiments is made by decreasing the antecedent, or by ‘modus tollens reasoning’. Furthermore, we found that derivatives with respect to the consequent often increase the truth value of something that is false as the consequent is false in the majority of times. Therefore, we argue that ‘modus tollens reasoning’ should be embraced in future research. As a possible solution to problems caused by this imbalance, we introduced a smoothed fuzzy implication called the Reichenbach-sigmoidal implication.Experimentally, we found that the product t-norm is the only t-norm that can be used as a base for all choices of operators. The product t-conorm and the Reichenbach implication have intuitive derivatives that correspond to inference rules from classical logic, and the log-product aggregator is the most effective universal aggregation operator.In order to gain the largest improvements over a supervised baseline however, we had to abandon the normal symmetric configurations of norms, where t-norms, t-conorms, implications and the aggregation operators satisfy the usual algebraic relations. Instead, we had to resort to non-symmetric configurations where operators based on different t-norms are com-bined. The Reichenbach-sigmoidal implication performs best in our experiments. Its hyperparameters can be tweaked to decrease the imbalance of the derivatives with respect to the negated antecedent and consequent. For existential quantifica-tion, we found that the general mean error performs best, and for conjunction and disjunction the family of Yager t-norms and the Nilpotent minimum has the highest final accuracy.We believe a proper empirical comparison of different methods that introduce background knowledge through logic could be useful to properly understand the details, performance, possible applications and challenges of each method. Sec-ondly, we believe more work is required in using background knowledge to help deep models train on real-world problems. One research direction would be to develop methods that can properly deal with exceptions. An approach in which formula importance weights can be learned could be used to distinguish between relevant and irrelevant formulas in the background knowledge, and probabilistic instead of fuzzy logics could be a more natural fit. Lastly, additional research on the vast space of fuzzy logic operators might find more properties that are useful in DFL.11 Indeed, when reasoning about belief, using fuzzy logic semantics instead of probabilistic logic semantics straight out-of-the-box, can yield undesirable results: Consider an event a where p(a) (probability of a) is 0.5. Now consider a disjunction, where p(a ∨ a) has the value 0.5. However, in Łukasiewicz logic, S(a, a) would yield 1.30E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Declaration of competing interestThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.AcknowledgementsWe sincerely thank all the anonymous reviewers whose comments substantially improved the content and the quality of this manuscript. This work is partly funded by the MaestroGraph research programme with project number 612.001.552, which is financed by the Dutch Research Council (NWO). Erman Acar is generously funded by the Hybrid Intelligence Project which is financed by the Dutch Ministry of Education, Culture and Science with project number 024.004.022. This work is also supported by the DAS-5 distributed supercomputer [4].Appendix A. Background on fuzzy logic operatorsIn this section, we will introduce the semantics of the fuzzy operators ⊗ (t-norm), ⊕ (t-conorm) and ¬ (negation) that are used to connect truth values of fuzzy predicates, and the semantics of the ∀ quantifier. We follow [38] in this section and refer to it for proofs and additional results.A.1. Fuzzy negationThe functions that are used to compute the negation of a truth value of a formula are called fuzzy negations.Definition 13. A fuzzy negation is a decreasing function N : [0, 1] → [0, 1] so that N(1) = 0 and for all x, N(N(x)) ≥ x [11]. Nis called strict if it is strictly decreasing and continuous, and strong if for all a ∈ [0, 1], N(N(a)) = a.A consequence of these conditions is that N(0) = 1. Throughout the paper we also use N to refer to the classical negation N(a) = 1 − a.A.2. Triangular normsThe functions that are used to compute the conjunction of two truth values are called t-norms. For a rigorous overview, see [40].Definition 14. A t-norm (triangular norm) is a function T : [0, 1]2 → [0, 1] that is commutative and associative, and1. Monotonicity: For all a ∈ [0, 1], T (a, ·) is increasing and2. Neutrality: For all a ∈ [0, 1], T (1, a) = a.The phrase ‘T (a, ·) is increasing’ means that whenever 0 ≤ b1 ≤ b2 ≤ 1, then T (a, b1) ≤ T (a, b2).Definition 15. A t-norm T can have the following properties:a) Continuity: A continuous t-norm is continuous in both arguments.b) Left-continuity: A left-continuous t-norm is left-continuous in both arguments. That is, for all a, b ∈ [0, 1], limx→a− T (x, b) = T (a, b) (the limit of T (x, b) as x increases and approaches a is a).c) Idempotency: An idempotent t-norm has the property that for all a ∈ [0, 1], T (a, a) = a.d) Strict-monotony: A strictly monotone t-norm has the property that for all a ∈ (0, 1], T (a, ·) is strictly increasing.e) Strict: A strict t-norm is continuous and strictly monotone.Table 1 shows the four basic t-norms and two other t-norms of interest alongside their properties.A.3. Triangular conormsThe functions that are used to compute the disjunction of two truth values are called t-conorms or s-norms.Definition 16. A t-conorm (triangular conorm, also known as s-norm) is a function S : [0, 1]2 → [0, 1] that is commutative and associative, and1. Monotonicity: For all a ∈ [0, 1], S(a, ·) is increasing and31E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 1036022. Neutrality: For all a ∈ [0, 1], S(0, a) = a.T-conorms are obtained from t-norms using De Morgan’s laws from classical logic, i.e. p ∨ q = ¬(¬p ∧ ¬q). Therefore, if T is a t-norm and NC the strong negation, T ’s NC -dual S is calculated usingS(a, b) = 1 − T (1 − a, 1 − b)(A.1)Table 2 shows several common t-conorms derived using Equation (A.1) and the t-norms from Table 1, alongside the same optional properties as those for t-norms in Definition 15.A.4. Aggregation operatorsThe functions that are used to compute quantifiers like ∀ and ∃ are aggregation operators [45].Definition 17. An aggregation operator [10] is a function A :argument, and for which A(0, ..., 0) = 0 and A(1, ..., 1) = 1.(cid:7)n∈N[0, 1]n → [0, 1] that is non-decreasing with respect to each Aggregation operators are variadic functions which are functions that are defined for any sequence of arguments. For this i=1 xi := A(x1, ..., xn). Table 3 shows some common aggregation operators that we reason we will often use the notation Anwill talk about. Furthermore, we will only consider symmetric aggregation operators, that are invariant to permutation of the sequence.The ∀ quantifier is interpreted as the conjunction over all arguments x. Therefore, we can extend a t-norm T from 2-dimensional inputs to n-dimensional inputs as they are commutative and associative [40]:A T () = 0A T (x1, x2, ..., xn) = T (x1, A T (x2, ..., xn))(A.2)These operators are a straightforward choice for modeling the ∀ quantifier, as they can be seen as a series of conjunctions. All operators constructed in this way are symmetric aggregation operators, for which the output value is the same for every ordering of its arguments. This generalizes commutativity.We can do the same for a t-conorm S to model the ∃ quantifier:E S () = 0E S (x1, x2, ..., xn) = S(x1, A S (x2, ..., xn))A.5. Fuzzy implications(A.3)The functions that are used to compute the truth value of p → q are called fuzzy implications. p is called the antecedentand q the consequent of the implication. We follow [38] and refer to it for details and proofs.Definition 18. A fuzzy implication is a function I : [0, 1]2 → [0, 1] so that for all a, c ∈ [0, 1], I(·, c) is decreasing, I(a, ·) is increasing and for which I(0, 0) = 1, I(1, 1) = 1 and I(1, 0) = 0.From this definition follows that I(0, 1) = 1.Definition 19. Let N be a fuzzy negation. A fuzzy implication I satisfiesa) left-neutrality (LN) if for all c ∈ [0, 1], I(1, c) = c;b) the exchange principle (EP) if for all a, b, c ∈ [0, 1], I(a, I(b, c)) = I(b, I(a, c));c) the identity principle (IP) if for all a ∈ [0, 1], I(a, a) = 1;d) N-contrapositive symmetry (CP) if for all a, c ∈ [0, 1], I(a, c) = I(N(c), N(a));e) N-left-contrapositive symmetry (L-CP) if for all a, c ∈ [0, 1], I(N(a), c) = I(N(c), a);f) N-right-contrapositive symmetry (R-CP) if for all a, c ∈ [0, 1], I(a, N(c)) = I(c, N(a)).All these statements generalize a law from classical logic. Left neutrality generalizes (1 → p) ≡ p, the exchange principlegeneralizes p → (q → r) ≡ q → (p → r), and the identity principle generalizes that p → p is a tautology. Furthermore, N-contrapositive symmetry generalizes p → q ≡ ¬q → ¬p, N-left-contrapositive symmetry generalizes ¬p → q ≡ ¬q → p and N-right-contrapositive symmetry generalizes p → ¬q ≡ q → ¬p.32E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602A.5.1. S-implicationsIn classical logic, the (material) implication is defined as follows:p → q = ¬p ∨ qUsing this definition, we can use a t-conorm S and a fuzzy negation N to construct a fuzzy implication.Definition 20. Let S be a t-conorm and N a fuzzy negation. The function I S,N : [0, 1]2 → [0, 1] is called an (S, N)-implicationand is defined for all a, c ∈ [0, 1] asI S,N (a, c) = S(N(a), c).(A.4)If N is a strong fuzzy negation, then I S,N is called an S-implication (or strong implication).As we only consider the strong negation NC , we omit the N and use I S to refer to I S,NCAll S-implications I S are fuzzy implications and satisfy LN, EP and R-CP. Additionally, if the negation N is strong, it satisfies CP and if, in addition, it is strict, it also satisfies L-CP. In Table 4 we show several S-implications that use the strong fuzzy negation NC and the common t-conorms (Table 2). Note that S-implications are rotations of the t-conorms.A.5.2. R-implicationsR-implications are another way of constructing implication operators. They are the standard choice in t-norm fuzzy logics.Definition 21. Let T be a t-norm. The function I T : [0, 1]2 → [0, 1] is called an R-implication and defined asI T (a, c) = sup{b ∈ [0, 1]|T (a, b) ≤ c}(A.5)The supremum of a set A, denoted sup{ A}, is the lowest upper bound of A. All R-implications are fuzzy implications, and all satisfy LN, IP and EP. T is a left-continuous t-norm if and only if the supremum can be replaced with the maximum function. Note that if a ≤ c then I T (a, c) = 1. We can see this by looking at Equation (A.5). The largest value for b possible is 1, since then, using the neutrality property of t-norms, T (a, 1) = a ≤ c.Table 5 shows the R-implications created from the common T-norms. Note that I L K and I F D appear in both tables: They are both S-implications and R-implications.Appendix B. Implementation of Differentiable Fuzzy LogicsThe computation of the satisfaction is shown in pseudocode form in Algorithm 1. By first computing the dictionary gthat contains truth values for all ground atoms,12 we can reduce the amount of forward passes through the computations of the truth values of the ground atoms that are required to compute the satisfaction.This algorithm can fairly easily be parallelized for efficient computation on a GPU by noting that the individual terms that are aggregated over in lines 12 and 14 (the different instances of the quantifiers) are not dependent on each other. By noting that formulas are in prenex normal form, we can set up the dictionary g using tensor operations so that the recursion has to be done only once for each formula. This can be done by applying the fuzzy operators elementwise over vectors of truth values instead of a single truth value, where each element of the vector represents a variable assignment.The complexity of this computation then is O (|K| · P · bd), where K is the set of formulas, P is the amount of predicates used in each formula and d is the maximum depth of nesting of universal quantifiers in the formulas in K (known as the quantifier rank). This is exponential in the amount of quantifiers, as every object from the constants C has to be iterated over in lines 12 and 14, although as mentioned earlier this can be mitigated somewhat using efficient parallelization. Still, computing the valuation for transitive rules (such as. ∀x y, z Q(x, z) ⊗ R(z, y) → P(x, y)) will for example be far more demanding than for antisymmetry formulas (such as ∀x, y P(x, y) → ¬P( y, x)).Appendix C. ProofsC.1. Single-passingProposition 7. Any composition of single-passing functions is also single-passing.12 The dictionary g could be seen as a ‘fuzzy Herbrand interpretation’, in that it assigns a truth value to all ground atoms.33E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602else if ϕ = ¬φ thenelse if ϕ = φ ⊗ ψ thenelse if ϕ = φ ⊕ ψ thenelse if ϕ = φ → ψ thenreturn N(e(φ, g, C, μ))if ϕ = P(x1, ..., xm) thenreturn g[P, (μ(x1), ..., μ(xm)]return I(e(φ, g, C, μ), e(ψ, g, C, μ))return S(e(φ, g, C, μ), e(ψ, g, C, μ))return T (e(φ, g, C, μ), e(ψ, g, C, μ))(cid:23) The valuation function computes the Fuzzy truth value of ϕ.(cid:23) Find the truth value of a ground atom using the dictionary g.Algorithm 1 Computation of the Differentiable Fuzzy Logics loss. First it computes the fuzzy Herbrand interpretation ggiven the current embedded interpretation ηθ . This performs a forward pass through the neural networks that are used to interpret the predicates. Then it computes the valuation of each formula ϕ in the knowledge base K, implementing Equations (3)-(8).1: function e(ϕ, g, C, μ) 2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17: end function18:19: procedure DFL(ηθ , P, K, O , N, T , S, I, A, E) C ← o1, ..., ob sampled from O20:g ← dict()21:for P ∈ P do22:23:24:25:26:27:28: end procedureend forreturn Aϕ∈K wϕ · eθ (ϕ, g, C, ∅) (cid:23) Calculate valuation of the formulas ϕ. Start with an empty variable assignment. This implements Equation (11).(cid:23) Computes the Differentiable Fuzzy Logics loss.(cid:23) Sample b constants to use this pass.(cid:23) Collects truth values for ground atoms.return Ao∈C e(φ, g, C, μ ∪ {(x, o)})return Eo∈C e(φ, g, C, μ ∪ {(x, o)})(cid:23) Apply the universal aggregation operator.(cid:23) Each assignment can be seen as an instance of ϕ.(cid:23) Calculate the truth values of the ground atoms.g[P, (o1, ..., oα(P))] ← ηθ (P)(o1, ..., oα(P))for o1, ..., oα(P) ∈ C doelse if ϕ = ∀x φ thenelse if ϕ = ∃x φ thenend forend ifProof. We will prove this by structural induction. Let f : Rn → R be a single-passing function and let x1, ..., xn ∈ R. Then clearly f (x1, ..., xn) is single-passing.Next, assume by induction that g : Rn → R is a composition of single-passing functions that we assume is single-passing. Let y : Rm → R be a single-passing function. Let Z be the set of inputs to y and define xi = y(Z ). We show that the composition g (x1, ..., y(Z ), ..., xn) is also single-passing. For any z ∈ Z holds that∂ g (x1, ..., xn)∂ z= ∂ g (x1, ..., xn)∂ xi∂ y(Z )∂ z.(C.1)As g is single-passing, there is at most 1 number j ∈ 1, ..., n so that ∂ g(x1,...,xn)be no k ∈ 1, ..., m such that ∂ g(x1,...,xn)If j = i, then by the assumption of y(Z ) being single-passing, there is at most 1 k ∈ 1, ..., m so that ∂ y( Z )∂ zEquation (C.1) there is at most 1 input such that ∂ g(x1,...,xn)single-passing. (cid:2)(cid:16)= 0. If there are 0, then there can also = 0. If there is 1, then either j (cid:16)= i, which is the direct input x j . (cid:16)= 0 and by (cid:16)= 0. We conclude that the composition g (x1, ..., y(Z ), ..., xn) is (cid:16)= 0 as ∂ g(x1,...,xn)∂ x j∂ xi∂ x∂ zC.2. Nonvanishing fractionsC.2.1. Łukasiewicz aggregatorProposition 8. The fraction of inputs x1, ..., xn ∈ [0, 1] for which the derivative of A T LU is nonvanishing is 1n! .Proof. Consider standard uniformly distributed random variables x1, ..., xn ∼ U (0, 1). The sum Y =distributed [34,29]. The cumulative density function of this distribution isF Y ( y) = 1n!(cid:27) y(cid:28)(cid:12)(−1)kk=0(cid:26)( y − k)n−1,(cid:25)nk(cid:4)ni=1 xiis Irwin-Hall (C.2)where (cid:27)(cid:28) is the floor function. The derivative of A T LU is nonvanishing when Y > n − 1, or equivalently as the Irwin-Hall distribution is symmetric, when Y < 1. Using F Y gives F Y (1) = 1n!(cid:6)(1 − 0)n + (−1)1(cid:6)1(1 − 1)n(cid:5)(−1)0n! . (cid:2)(cid:5)n1(cid:5)n0= 1(cid:6)This result is the same for the bounded sum aggregator, as for that the condition is that Y < 1.34E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602C.2.2. Yager aggregatorProposition 9. The fraction of inputs x1, ..., xn ∈ [0, 1] for which the derivative of A T Y with p = 2 is nonvanishing is n2π2 n+ 12n·(cid:10)( 12 ), where (cid:10) is the Gamma function.Proof. The points x1, .., xn ∈ R for which volume is found by [5](p.5):(cid:4)ni=1(1 − xi)2 < 1 hold describes the volume of an n-ball13 with radius 1. This V (n) =2π n2 n + 1)(cid:10)( 1.(C.3)We are interested in the part of this volume where x1, ..., xn ∈ [0, 1], that is, those in a single orthant14 of the n-ball. The amount of orthants in which an n-ball lies is 2n.15 Thus, the volume of the part of the n-ball where x1, ..., xn ∈ [0, 1]is V (n). As the total volume of points lying in [0, 1]n is 1, this is also the fraction of points for which the derivative of A T Y with p = 2 is nonvanishing. (cid:2)π2 n+ 12n·(cid:10)( 12 )2n =n2C.2.3. Nilpotent aggregatorProposition 10. The fraction of inputs x1, ..., xn ∈ [0, 1] for which the derivative of A TnM is nonvanishing is 12n−1 .Proof. Consider n standard uniformly distributed random variables x1, ..., xn ∼ U (0, 1). We are interested in the probability that x(1) + x(2) > 1, where x(k) is the k-th smallest sample (known as the k-th order statistic [15]). Weisberg [73] derives the cumulative density function for linear combinations of standard uniform order statistics. Let k0 = 0 < k1 < ... < kS ≤ kn be i=1 di x(i) > v. Let rs = ks − ks−1 for S integers indicating the coefficients di > 0. We aim to calculate the probability that all 1, ..., S and let r S+1 = n − kS . Finally, let c S+1 = 0 and c(s) = c(s+1) + di . m is the largest integer so that v ≤ c(m). Then, Weisberg [73] finds that(cid:4)S(cid:2)S(cid:12)Pdsx(ks) > vs=1!m(cid:12)g=s=1(cid:6)(cid:5)(rs−1)c(s)s(rs − 1)!where g(i)sis the i-th order derivative ofgs(c) =(c − v)nS+1i=1,i(cid:16)=s(c − c(i))ri(cid:3)c(C.4)(C.5)Filling this in for our case, we find that S = 2, where k1 = 1, k2 = 2 as d1 = d2 = 1. Therefore, r1 = r2 = 1 and r3 = n − 2and c(1) = 2, c(2) = 1 and c(3) = 0. The largest integer m so that 1 ≤ c(m) is 2. Filling this in, we find that"Px(1) + x)(2) > 1#= g(1−1)(2)1(1 − 1)!+ g(1−1)(1)2(1 − 1)!=(2 − 1)n2(2 − 1)1(2 − 0)n−2+(1 − 1)n1(1 − 2)(1 − 0)n−2= 12n−1(cid:2)(C.6)(C.7)C.3. ImplicationsProposition 11. If a fuzzy implication I is NC -contrapositive symmetric, where NC is the strong negation, it is also contra-positive differentiable symmetric.Proof. Say we have an implication I that is NC -contrapositive symmetric. Because I is NC -contrapositive symmetric, I(1 −c, 1 − a) = I(a, c). Thus, − ∂ I(1−c,1−a)= ∂ I(a,c). (cid:2)∂1−c= − ∂ I(a,c)∂1−c∂c13 An n-ball is the generalization of the concept of a ball to any dimension and is the region enclosed by a n − 1 hypersphere. For example, the 3-ball (or ball) is surrounded by a sphere (or 2-sphere). Similarly, the 2-ball (or disk) is surrounded by a circle (or 1-sphere). A hypersphere with radius 1 is the set of points which are at a distance of 1 from its center.14 An orthant in n dimensions is a generalization of the quadrant in two dimensions and the octant in three dimensions.15 To help understand this, consider n = 2. The 1-ball is the circle with center (0, 0). The area of this circle is evenly distributed over the four quadrants.35E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Proposition 12. If an implication I is left-neutral, then ∂ I(1,c)then − ∂ I(a,0)= 1.∂c∂a= 1. If, in addition, I is contrapositive differentiable symmetric, Proof. First, assume I is left-neutral. Then for all c ∈ [0, 1], I(1, c) = c. Taking the derivative with respect to c, it is clear that ∂ I(1,c)= 1. As 1 − c ∈ [0, 1], − ∂ I(a,0)= 1. Next, assume I is contrapositive differentiable symmetric. Then, ∂ I(1,c)= − ∂ I(1−c,1−1)= − ∂ I(1−c,0)= 1. (cid:2)∂1−c∂1−c∂c∂c∂aAppendix D. Derivations of used functionsD.1. p-error aggregatorsThe unbounded Yager aggregator isAU Y (x1, ..., xn) = 1 −(cid:19)n(cid:12)(1 − xi)p(cid:20) 1p,p ≥ 0.(D.1)i=1We can do an affine transformation w · AU Y (x1, ..., xn) −h on this function to ensure the boundary conditions in Definition 17hold.w · AU Y (0, ..., 0) − h = 0w · AU Y (1, ..., 1) − h = 1Solving Equation (D.2) and (D.3) for h, we find⎛(cid:19)w ·⎝1 −(cid:20) 1pn(cid:12)(1 − 0)p⎞⎠ − h = 0i=1(cid:23)w ·1 − n1p(cid:24)− h = 0⎛w ·⎝1 −(cid:19)n(cid:12)(1 − 1)p√h = w − w · pn,⎞⎠ − h = 1(cid:20) 1pi=1w · (1 − 0) − h = 1h = w − 1.Equating (D.4) and (D.5) and solving for h, we find√w − w · pn = w − 1w = 1√pn.And so h = 1√pn− 1. Filling in and simplifying we find⎛A p E (x1, ..., xn) = 1√pn·⎝1 −(cid:19)n(cid:12)(1 − xi)pi=1(cid:20) 1p(cid:25)⎞⎠ −(cid:26)1√pn− 1(cid:19)n(cid:12)(1 − xi)p(cid:20) 1pi=1= 1 − 1√pn·(cid:19)1n= 1 −n(cid:12)(1 − xi)pi=1(cid:20) 1p(cid:5)(cid:4)ni=1 xpi(cid:6) 1p , p ≥ 0.36Similarly for the t-conorm AU Y S (x1, ..., xn) =(D.2)(D.3)(D.4)(D.5)(D.6)(D.7)E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602(cid:19)n(cid:12)i=1w ·(cid:20) 1p0p− h = 0w · 0 − h = 0h = 0(cid:20) 1p1p− h = 1(cid:19)n(cid:12)i=1w ·w · n1p − h = 1w = 1√pn(cid:19)A p−M E AN (x1, ..., xn) =1nD.2. Sigmoidal functions(cid:20) 1pn(cid:12)i=1xpi, p ≥ 0.(D.8)(D.9)(D.10)In Machine Learning, the logistic function or sigmoid function σ (x) = 1is a common activation function [25](p.65-66). This inspired [71] to introduce parameterized families of aggregation functions they call Max-Sigmoid activation functions:1+e−x(cid:19)(cid:19)(cid:20)(cid:20)(cid:19)(cid:19)(cid:20)(cid:20)(cid:15)σ +∧(x1, ..., xn) = σAs ·xi − n + 1 + b0,(cid:15)σ +∨(x1, ..., xn) = σAs ·xi + b0(D.11)n(cid:12)i=1n(cid:12)i=1We generalize this transformation for any function f : [0, 1]n → R that is symmetric and increasing:A(cid:15)σ f (x1, ..., xn) = σ (s · ( f (x1, ..., xn) + b0))(D.12)This cannot be an aggregation function according to Definition 17 as σ ∈ (0, 1) and so the boundary conditions (cid:15)(cid:15)σ (1, ..., 1) = 1 and Aσ (0, ..., 0) do not hold. We can solve this by adding two linear parameters w and h, redefining Aσ f asσ f (x1, ..., xn) = w · σ (s · ( f (x1, ..., xn) + b0)) − h(D.13)For this, we need to make sure the lowest value of f on the domain [0, 1]n maps to 0 and the highest to 1. For this, we define inf f = inf{ f (x1, ..., xn)|x1, ..., xn ∈ [0, 1]} and sup f = sup{ f (x1, ..., xn)|x1, ..., xn ∈ [0, 1]}. This gives the following system of equationsAσ (0, ..., 0) = w · σ (s · (inf f + b0)) − h = 0Aσ (1, ..., 1) = w · σ (s · (sup f + b0)) − h = 1First solve both equations for w, starting with Equation (D.14):w · σ (s · (inf f + b0)) − h = 0= hww = h · (1 + e−s·(inf f +b0)1 + e1−s·(inf f +b0))Likewise for Equation (D.15):w · σ (s · (sup f + b0)) − h = 111 + e−s·(sup f +b0)= 1 + hwNow we can solve for h by equating Equations (D.17) and (D.16). Thenw = (1 + h) · (1 + e−s·(sup f +b0))37(D.14)(D.15)(D.16)(D.17)E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602(1 + h) · 1 + e−s·(sup f +b0) = h · 1 + e−s·(inf f +b0)h =1 + e−s·(sup f +b0)1 + e−s·(inf f +b0) − 1 + e−s·(sup f +b0)We thus get the following formula:Aσ (x1, ..., xn) =e−s·(sup f +b0)1 + e−s·(inf f +b0) − e−s·(sup f +b0)(cid:23)(cid:23)·1 + e(cid:24)−s·(inf f +b0)· σ (s · ( f (x1, ..., xn) + b0)) − 1(D.18)(cid:24)If fis a fuzzy logic operator of which the outputs are all in [0, 1], the most straightforward choice of b0 is − 12 . This ] and so it uses a symmetric part of the sigmoid function. For some function f ∈translates the outputs of f to [− 1[0, 1]n → [0, 1], we find the following simplification, noting that the supremum of fis 1 and the infimum is 0:2 , 12σ f (x1, ..., xn) = 1 + ees(0− 12 ) − e−s(1− 12 )·−s(1− 12 )(cid:25)(cid:24)(cid:25)(cid:23)1 + e−s(0− 12 )· σ(cid:25)s ·(cid:25)(cid:23)f (x1, ..., xn) − 12(cid:25)(cid:24)(cid:25)(cid:26)(cid:26)(cid:26)− 1s2· σs ·(cid:25)(cid:24)s2· σs ··1 + e(cid:25)(cid:23)·1 + e(cid:25)(cid:25)f (x1, ..., xn) − 12(cid:25)f (x1, ..., xn) − 12(cid:26)(cid:26)(cid:26)(cid:26)(cid:26)(cid:26)− 1·1 + es2· σs ·f (x1, ..., xn) − 12− 1ss2 − 1· e2 − 1e− s2= 1 + e2 − ees− s2− s2e2 − ess2 − e− s2 )(e(cid:25)(cid:23)=(e= 1es2 − 1s2 − 1)(cid:24)Next, we prove several properties of the sigmoidal implication.Proposition 13. For all a1, c1, a2, c2 ∈ [0, 1],1. if I(a1, c1) < I(a2, c2), then also σI (a1, c1) < σI (a2, c2);2. if I(a1, c1) = I(a2, c2), then also σI (a1, c1) = σI (a2, c2).(D.19)(D.20)(D.21)(D.22)(cid:24)2(cid:26)(cid:26)(cid:26)− 1(cid:23)Proof.1. We note that σI can be written as σI (a, c) = w · σ (s · (I(a, c) + b0)) − h for constants w =−s·(1+b0)−s·(1+b0) . As s > 0, −s · b0 > −s · (1 + b0). Therefore, e−s·b0 − e1 + e1+e−s·b0 −e(cid:23)e1 + e> 0, then also w > 0. As s > 0, s · (I(a1, c1) + b0) <s · (I(a2, c2) + b0) as I(a1, c1) < I(a2, c2). Next, note that the sigmoid function σ is a monotonically increasing function. Using w > 0 we find that σI (a1, c1) = w · σ (s · (I(a1, c1) + b0)) < w · σ (s · (I(a2, c2) + b0)) = σI (a2, c2).e−s·(1+b0) > 0. Furthermore, as e−s·(1+b0) and h =2 > 0 then certainly −s·(1+b0) > 0 and > 0. As both e−s·b0 − e(cid:24)(cid:24)2− s2− s2(cid:23)2−s·(1+b0)1+e−s·b0 −e− s2.σI (a1, c1) = w · σ (s · (I(a1, c1) + b0)) − h = w · σ (s · (I(a2, c2) + b0)) − h = σI (a2, c2) (cid:2)Proposition 14. σI (a, c) is 1 if and only if I(a, c) = 1. Similarly, σI (a, c) is 0 if and only if I(a, c) = 0.Proof. Assume there is some a, c ∈ [0, 1] so that I(a, c) = 1. By construction, σI (a, c) is 1 (see Appendix D.2).Now assume there is some a1, c1 ∈ [0, 1] so that σI (a1, c1) = 1. Now consider some a2, c2 so that I(a2, c2) = 1. By the construction of σI , σI (a2, c2) = 1. For the sake of contradiction assume I(a1, c1) < 1. However, by Proposition 13 as I(a1, c1) < I(a2, c2) then σI (a1, c1) < σI (a2, c2) has to hold. This is in contradiction with σI (a1, c1) = σI (a2, c2) = 1 so the assumption that I(a1, c1) < 1 has to be wrong and I(a1, c1) = 1.The proof for I(a, c) = 0 is analogous. (cid:2)Proposition 15. For all fuzzy implications I , σI is also a fuzzy implication.Proof. By Definition 18 I(·, c) is decreasing and I(a, ·) is increasing. Therefore, by Proposition 13.1, σI (·, c) is also decreasing and σI (a, ·) is also increasing. Furthermore, I(0, 0) = 1, I(1, 1) = 1 and I(1, 0) = 0. We find by Proposition 14 that then also σI (0, 0) = 1, σI (1, 1) = 1 and σI (1, 0) = 0. (cid:2)38E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602I -sigmoidal implications only satisfy left-neutrality if I is left-neutral and s approaches 0.Proposition 16. If a fuzzy implication I is contrapositive symmetric with respect to N, then σI also is.Proof. Assume we have an implication I that is contrapositive symmetric and so for all a, c ∈ [0, 1], I(a, c) = I(N(c), N(a)). By Proposition 13.2, σI (a, c) = σI (N(c), N(a)). Thus, σI is also contrapositive symmetric with respect to N. (cid:2)By this proposition, if I is an S-implication, σIis contrapositive symmetric and thus also contrapositive differentiable symmetric.Proposition 17. If I satisfies the identity principle, then σI also satisfies the identity principle.Proof. Assume we have a fuzzy implication I that satisfies the identity principle. Then I(a, a) = 1 for all a. By Proposition 14it holds that σI (a, a) is also 1. (cid:2)D.3. Nilpotent aggregatorProposition 18. Equation (A.2) is equal for the Nilpotent t-norm to(cid:2)A TnM (x1, ..., xn) =min(x1, ..., xn),0,if xi + x j > 1; xi and x j are the two lowest values in x1, ..., xnotherwise.(D.23)Proof. We will prove this by induction. Base case: Assume n = 2. Then A TnM (x1, x2) = TnM (x1, x2). x1 and x2 are the two lowest values of x1, x2, so the condition in Equation (D.23) would change to x1 + x2 > 1.Inductive step: We assume Equation (D.23) holds for some n ≥ 2. Then by Equation (A.2)A TnM (x1, ..., xn+1) = TnM ( A TnM (x1, ..., xn), xn+1). Note that if A TnM (x1, ..., xn) = 0 then A TnM (x1, ..., xn+1) is also 0 as xn+1 ∈[0, 1] and so 0 + xn+1 > 1 can never hold. We identify three cases:1. If xn+1 is the lowest value in x1, ..., xn+1, then A TnM (x1, ..., xn) is either the second lowest value in x1, ..., xn+1 or 0. If it is 0, the sum of the second and third lowest values is not greater than 1, and so the sum of the two lowest values can neither be. If it is not, then TnM ( A TnM (x1, ..., xn), xn+1) first compares if A TnM (x1, ..., xn) + xn+1 > 1, that is, if the sum of the two lowest values in x1, ..., xn+1 is higher than 1, and returns xn+1 if this holds and 0 otherwise.2. If xn+1 is the second lowest value in x1, ..., xn+1, then A TnM (x1, ..., xn) is either the lowest value in x1, ..., xn+1 or 0. If it is 0, the sum of the first and third lowest values is not greater than 1, and so the sum of the two lowest values can neither be. If it is not, then TnM ( A TnM (x1, ..., xn), xn+1) first compares if A TnM (x1, ..., xn) + xn+1 > 1, that is, if sum of the two lowest values in x1, ..., xn+1 is higher than 1, and returns A TnM (x1, ..., xn) if this holds and 0 otherwise.3. If xn+1 is neither the lowest nor second lowest value in x1, ..., xn+1, then the sum s of the two lowest values in x1, ..., xn is also the sum of the two lowest values in x1, ..., xn+1. If A TnM (x1, ..., xn) is 0, then s can not have been greater than 1 and so A TnM (x1, ..., xn+1) is also 0. If it is not, then s > 1 and A TnM (x1, ..., xn) is the lowest value and surely A TnM (x1, ..., xn) + xn+1 > 1 as xn+1 is at least as large as the second lowest value. (cid:2)By considering E SnM (x1, ..., xn) = 1 − A TnM (1 − x1, ..., 1 − xn), it is easy to see that(cid:2)E SnM (x1, ..., xn) =max(x1, ..., xn),1,if xi + x j < 1; xi and x j are the two largest values in x1, ..., xnotherwise.(D.24)D.4. Yager R-implicationThe Yager t-norm is defined as T Y (a, b) = 1 −(cid:5)(1 − a)p + (1 − b)p(cid:6) 1p . The Yager R-implication then is defined (see Defi-nition 21) asI T Y (a, c) = sup{b ∈ [0, 1]|T Y (a, b) ≤ c}When a ≤ c, I T Y= 1 as T Y (a, 1) = a ≤ c. Assuming a > c, we find by filling inI T Y (a, c) = sup{b ∈ [0, 1]|1 −(cid:5)(1 − a)p + (1 − b)p(cid:6) 1p ≤ c},a > cTo get a closed-form solution of I T Y we have to find the largest b for which 1 −inequality for b, we find39(D.25)(D.26)(cid:5)(1 − a)p + (1 − b)p(cid:6) 1p ≤ c. Solving this E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602(cid:5)c ≥ 1 −(1 − a)p + (1 − b)p(cid:6) 1p(1 − c)p ≤ (1 − a)p + (1 − b)p(cid:5)1 − b ≥(1 − c)p − (1 − a)p(cid:6) 1p(cid:5)(cid:6) 1b ≤ 1 −(1 − c)p − (1 − a)p(D.27)If a > c, then (1 − c)p > (1 − a)p and thus (1 − c)p − (1 − a)p > 0. Furthermore, as a, c ∈ [0, 1], (1 − c)p − (1 − a)p ≤ 1. (cid:6) 1Therefore, it has to be true that 1 −p ∈ [0, 1]. The largest value b ∈ [0, 1] for which the condition holds is then equal to 1 −(cid:6) 1p as it is in [0, 1] and satisfies the inequality.(cid:5)(1 − c)p − (1 − a)p(1 − c)p − (1 − a)p(cid:5)p .Combining this with the earlier observation that when a ≤ c, I T Y(cid:2)I T Y (a, c) =1,1 −(cid:5)(1 − c)p − (1 − a)p(cid:6) 1if a ≤ cp , otherwise.= 1, we find the following R-implication:(D.28)for p = 2 in Fig. 8. As expected, p = 1 reduces to the Łukasiewicz implication. The derivatives of this We plot I T Yimplication are(cid:2)(cid:2)∂ I T Y ((, a)∂a, c) =((1 − c)p − (1 − a)p)0,1p−1 · (1 − c),if a > cotherwise,− ∂ I T Y ((, a)∂(, c) =((1 − c)p − (1 − a)p)0,Appendix E. Differentiable Product Fuzzy Logic1p−1 · (1 − a),if a > cotherwise.(D.29)(D.30)We compare Differentiable Product Fuzzy Logic (DPFL), which uses the product t- and t-conorm T P , S P , the Reichenbach implication I RC and the log-product aggregator Alog T P , and a probabilistic logic method called Semantic Loss [74].Definition 22. Let P be a set of predicates, O the domain of discourse, ηθ an embedded interpretation of L and K a knowledge base of background knowledge. The Semantic Loss is defined as(cid:13)(cid:12)(cid:13)LS (θ; K) = − logηθ (P)(o1, ..., om)w|=Kw|=P(o1,...,om)w|=¬P(o1,...,om)(1 − ηθ (P)(o1, ..., om)) ,(E.1)where w is a world (also known as a Herbrand interpretation) that assigns a binary truth value to every ground atom and where ηθ (P)(o1, ..., om) is the probability of a ground atom.This computes the logarithm of the sum of probabilities of all worlds for which K holds, or the probability of sampling a world that is consistent with K. The probability that a ground atom P(o1, ..., om) is true is ηθ (P)(o1, ..., om). The different ground atoms are assumed to be independent. By marginalizing out the world w , it can be used for injecting background knowledge in unsupervised or semi-supervised learning. Compared to DPFL, Semantic Loss is exponential in the size of the amount of ground atoms as the sum over valid worlds has to be computed. Equivalent formulas have equal Semantic Loss, and a knowledge base consisting of a conjunction of facts is equal to the cross-entropy loss function.DPFL is connected in an interesting way to Semantic Loss. It corresponds to a single iteration of the loopy belief propaga-tion algorithm [55].Proposition 19. Let ϕ be a closed formula so that if P1(o11, ..., o1m) and P2(o21, ..., o2m) are both ground atoms appearing in ϕ, then P1(o11, ..., o1m) = P2(o21, ..., o2m). Then it holds that LS (θ ; ϕ) = −eθ ({}, ϕ) when using T = T P , S = S P , I = I RCand A = Alog T P .As there are no loops when each ground atom appears uniquely in ϕ, the factor graph over which loopy belief propaga-tion is done is a tree. As eθ ({}, ϕ) corresponds to a single iteration of loopy belief propagation, this is equal to regular belief propagation which is an exact method for computing queries on probabilistic models [58]. Clearly, this condition on ϕ is very strong. Although loopy belief propagation is known to often be a good approximation empirically [55], the degree to which DPFL approximates Semantic Loss requires further research as this is not a guarantee. However, if DPFL approximates Semantic Loss well, it can be a strong alternative as it is not an exponential computation. However, it also means that most problems of DPFL will also be present in Semantic Loss. For example, if we just have the formula ∀raven(x) → black(x), the grounding of the knowledge base will not contain repeated ground atoms, and thus Semantic Loss and DPFL are equivalent and share difficulties related to the imbalance of modus ponens and modus tollens.40E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602E.1. ProofIn this section, we prove Proposition 19. Without loss of generality we assume that K = ϕ = ∀ x1, ..., xn φ. Slightly rewriting Equation (E.1), we find that the probability distribution of Semantic Loss isp(ϕ|ηθ ) =p(ϕ|w)p(w|ηθ )(E.2)(cid:12)wwhere we define the valuation probability p(ϕ|w) = I[w |= ϕ] and the world probability(cid:13)(cid:13)p(w|ηθ ) =ηθ (P)(o1, ..., ok)w|=P(o1,...,ok)w|=¬P(o1,...,ok)(1 − ηθ (P)(o1, ..., ok)) .(cid:3)n(cid:3)A Bayesian network is a joint distribution factorized as p(x) =i=1 p(xi|x{pa(i)}) where x{pa(i)} is the set of random vari-ables that are parents of xi . In particular, we are interested in the joint distribution p(ϕ, w|ηθ ). We use the compositional structure of ϕ to expand p(ϕ|w).Let p(φ|ch(φ)) be the probability that φ, a subformula of ϕ, is true according to the binary truth table conditioned on the truth value of the direct subformulas ch(φ) of φ. For example, if φ = α ⊗ β, then p(φ|α, β) = 1 if α and β are 1, and otherwise p(φ|α, β) = 0. For an atomic formula P(o1, ..., ok), we do a lookup in the world w , p(P(o1, ..., ok|w P(o1,...,ok)) =w P(o1,...,ok). Let (cid:14) be the set of all subformulas of ϕ. We express the joint distribution asp((cid:14), w|ηθ ) = p(w|ηθ )p(φ|ch(φ)).(E.3)(cid:13)φ∈(cid:14)(cid:3)φ∈(cid:14) p(φ|ch(φ)) = 1. Note that the distribution p(ϕ|w) =A specific world w uniquely determines a single (cid:14) so that φ∈(cid:14) p(φ|ch(φ)) forms a polytree (or directed tree), as a logical expression is formed as a tree. From this Bayesian net-work, we define the factor graph over which we do the belief propagation. For brevity, we denote a specific ground atom P(o1, ..., ok) as PO .We note that we use m to denote an instantiation instead of μ in this section. μ is used to denote the messages as customary in belief propagation.• There is a variable node w PO for every ground atom PO appearing in the grounding of ϕ. Additionally, there is a factor nodef wP(o1,...,ok ) (w PO ) = ηθ (P)(o1, ..., ok)wPO · (1 − ηθ (P)(o1, ..., ok))1−wPO .• There is a variable node φ and a factor node fφ for every subformula φ ∈ (cid:14).• For every φ = PO , φ ∈ (cid:14), fφ(φ, w PO ) = I[φ = w PO• For every φ = ¬α, φ ∈ (cid:14), fφ(φ, α) = I[φ = 1 − α].• For every φ = α ⊗ β, φ ∈ (cid:14), fφ(φ, α, β) = I[φ = α · β].• Let ϕ = ∀ x1, ..., xn φ be the top node. Denote the set of all instances of ϕ is M. Then fϕ(ϕ, m1, ..., m|M|) = I[ϕ =].(cid:3)m∈M αm] where eμ is the random variable corresponding to the instantiation of m in φ.We ignore the other connectives as they can be formed from ¬ and ⊗, both in classical logic as in DPFL. Next, we com-pute the messages in belief propagation. We start from the world variable nodes w P O and move up through the computation tree to ϕ. The messages for factors to variables are given as [7] μ f s→x(x) =y∈ne( f s)\x μ y→ f s ( y) where ne(x)is the set of neighbors of node x. The messages for variables to factors are given as μx→ f s (x) =X f s(x, X) μ fl→x(x).(cid:4)(cid:3)(cid:3)l∈ne(x)\ f sa. μ f wPOb. μw PO→w PO→ fφ (w PO ) = μ f wPO(w PO ) = ηθ (P)(o1, ..., ok)w PO · (1 − ηθ (P)(o1, ..., ok))1−wPO , factor to variable for ground atom.(cid:3)→w PO(w PO ) (w PO ), ground atom variable to atomic formula factor φ = P(o1, ..., ok). We here assume that the incoming messages μ fψ →w POfrom other atomic formulas using ground atom PO are initialized with 1. We have not yet, and are not able to, compute these as the graph might contain loops.ψ:ψ=PO ,φ(cid:16)=ψ μ fψ →w POc. μ fφ →φ(φ) = I[φ = 1]μw POable for atomic formulas.d. μφ→ fα (α) = μ fα→α(α) for subformula variables to factors of other subformulas α. As φ is only used in two factors, → fφ (0) = ηθ (P)(o1, ..., ok)φ · (1 − ηθ (P)(o1, ..., ok))1−φ , factor to vari-→ fφ (1) + I[φ = 0]μw PO→w PO= μ f wPOthis simply passes the downstream message through.e. μ fφ →φ(φ) = μ fα→α(1)1−φ · μ fα→α(0)φ factor to variable for negated subformulas φ = ¬α.f. μ fφ →φ(φ) =(cid:6)(cid:5)μ fα→α(1) · μ fβ →β (1)(cid:6)(cid:5)(cid:3)→αm (1)tor to variable for conjunctions φ = α ⊗ β.m∈M μ fαm(cid:6)(cid:5)μ fα→α(0) · μ fβ →β (0) + μ fα→α(1) · μ fβ →β (0) + μ fα→α(0) · μ fβ →β (1)(cid:24)→αm (αm)for the factor of the universally quan-tified formula ϕ = ∀x1, ..., xn φ where αm is the subformula corresponding to the instantiation m. The second term is the sum over all cases so that there is a subformula with truth value 0.α1,...,α|M|:∃i:αi =0m∈M μ fαmg. μ fϕ →ϕ(ϕ) =1−φfac-(cid:23)(cid:4)1−ϕϕ ·φ ·(cid:3)41E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602(cid:3)p(φ) =We wish to know what the marginal probability p(ϕ = 1|ηθ ) is. A marginal of a variable φ in a factor graph is found as s∈ne(φ) μ f s→x(φ). The variable node ϕ only has the factor node fϕ as a neighbor, so using (g.) we find16p(ϕ = 1|ηθ ) ≈(cid:13)m∈Mμαm→ fϕ (1).(E.4)Next, we use induction to prove that the computation of μ fαm→αm (1) is equal to Differentiable Product Fuzzy Logic.• Let φ be any subformula of αm for some instantiation m of ϕ. Let eθ be the valuation function (Definition 2) with T = T P and N = NC . We prove that μ fφ →φ(1) = eθ (m, φ) and μ fφ →φ(0) = 1 − eθ (m, φ).• Base case φ = PO . By (c.), μ fφ →φ(1) = ηθ (P)(o1, ..., ok) and μ fφ →φ(0) = 1 − ηθ (P)(o1, ..., ok). By Equation (3),17eθ (m, φ) = ηθ (P)(o1, ..., ok).• Inductive step φ = ¬α. By (e.) and using the inductive hypothesis, μ fφ →φ(1) = μ fα→α(0) = 1 − eθ (α, m) and μ fφ →φ(0) = μ fα→α(1) = eθ (m, α). By Equation (4), eθ (m, φ) = 1 − eθ (m, α).• Inductive step φ = α ⊗ β. By (f.) and using the inductive hypothesis, μ fφ →φ(1) = μ fα→α(1) · μ fβ →β (1) = eθ (m, α) ·eθ (m, β) and μ fφ →φ(0) = μ fα→α(0) · μ fβ →β (0) + μ fα→α(1) · μ fβ →β (0) + μ fα→α(0) · μ fβ →β (1) = (1 − eθ (m, α))(1 −eθ (m, β)) + eθ (m, α)(1 − eθ (m, β)) + (1 − eθ (m, α))eθ (m, β) = 1 − eθ (m, α) · eθ (m, β). By Equation (5) and T P (a, c) = a · c, eθ (m, φ) = eθ (m, α) · eθ (m, β).Using Equation (E.4) we then find that p(ϕ = 1|ηθ ) ≈Logic computation of the universal quantifier in Equation (8).(cid:3)m∈M eθ (m, φm), which is equal to the Differentiable Product Fuzzy Importantly, as the computation of the logic is itself a tree, the only loops are caused through ground atoms appearing in multiple subformulas. Therefore, when each ground atom only appears in a single formula, Differentiable Product Fuzzy Logic computes the same probability as Semantic Loss.E.2. ExampleFor example, a formula P corresponds to a variable node P with two possible values 1 and 0, along with the factor node with factor ηθ (P)() if P is true and 1 − ηθ (P)() otherwise. If we consider the formula γ = P ⊗ ¬(P ⊗ Q) we find the following factor graph:I[Q = w Q]f QQv QI[α = P · Q]fαPv P1I[P1 = w P]f P1w Pv w PI[P2 = w P]f P2v w Q w Qf w Q ηθ (Q)()ηθ (P)()f w Pv P2 PvαP ⊗ QvβI[β = 1 − α]vβ¬(P ⊗ Q)fγI[γ = P · β]vγP ⊗ ¬(P ⊗ Q)Here, box nodes correspond to factor nodes and circle nodes correspond to variable nodes. As γ is the top formula, this is where the messages get passed to. Note that there is a single loop, which is present because the atom P is used twice in → f P2 . The first is incorrect as it does not have access → f P1 and μv wPthe formula. This causes two incorrect messages: μv wPto the incoming message μ f P2→v wPWith Differentiable Product Fuzzy Logic, we find the expression ηθ (P)() · (1 − ηθ (P)() · ηθ (Q)()), while the correct prob-and puts it to 1.ability is where P is 1 and Q is 0, that is ηθ (P)() · (1 − ηθ (Q)()).Appendix F. Additional experimentsIn this Appendix, we report additional experiments on the same problem. Throughout this Appendix we use vanilla stochastic gradient descent with a learning rate of 0.01 and 0.5 momentum instead of ADAM. The reason for this is that the best configurations seem to perform better with this optimizer, while the other configurations seem to perform better with ADAM.16 We use approximation equality for simplification. Note that this is not necessarily true in loopy belief propagation.17 Equation (3) refers to the ungrounded case, but here the full grounding is already done so the lookup function l is not required.42E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Table F.11Configurations using the RMSE aggregator with w D F L = 1 and the log product aggregator with wdf l = 10.AccuracyT GT L KT PT Y , p = 2T Y , p = 20T Nm96.396.696.796.496.095.4Alog T P , w D F L = 10cucons%cons%0.890.330.480.540.510.440.100.50.440.400.290.29cuant%0.970.670.690.740.780.84Accuracy96.296.997.096.695.995.4A R M S E , w D F L = 1cucons%cons%0.890.060.810.870.820.620.100.50.080.120.180.03cuant%0.970.950.980.970.980.99F.1. Comparing different formulas of the same problemWe note what the values of cucons% and cuant% roughly are for each of the used formulas if we were to pick at random.1. ∀x, y zero(x) ⊗ zero( y) → same(x, y), ..., ∀x, y nine(x) ⊗ nine( y) → same(x, y). For this formula, cucons% ≥ 110 as it is the 100 as it is 1 minus the probability that both x and y are zero. The modus 10 cases and the ‘distrust’ option in 100 cases, the modus tollens casein less than 9distribution of same(x, y)18 and cuant% ≤ 99ponens case is true in more than 1more than 9100 cases.2. ∀x, y zero(x) ⊗ same(x, y) → zero( y), ..., ∀x, y nine(x) ⊗ same(x, y) → nine( y). For this formula, cucons% = 1100 . The modus ponens cases are true in more than 1100 cases.probability that a digit represents zero and cuant% ≤ 9910 cases and the ‘distrust’ option in 9modus tollens in 910 as it is the 100 cases, the 3. ∀x, y same(x, y) → same( y, x). As this is a bi-implication, cucons% ≥ 110 and cuant% ≤ 910 . The ‘distrust’ option is not possible in this formula.From this, we can see that a set of operators is better than random guessing for the consequent updates if cucons% > 0.1. It is more difficult to say what the value of cuant% should be as good as random guessing, as the probabilities are upper bounded with the lowest bound at 0.9. We can only say that we know a set of operators to be better than random if cuant% > 0.99.F.2. Varying the aggregatorsIn this section, we analyze symmetric configurations in the same problem, except that we use aggregators other than the one formed by extending the t-norm. In particular, we will consider the RMSE aggregator ( AG M E with p = 2) and the log-product aggregator Alog T P .Table F.11 shows the results when using the RMSE aggregator and a DFL weight of 1 and the log product aggregator and a DFL weight of 10. Nearly all configurations perform significantly better using these aggregators than when using their ‘symmetric’ aggregator. In particular, the Gödel, Łukasiewicz and Yager t-norms all outperform the baseline with both aggregators as they are differentiable everywhere and can handle outliers.The product t-norm seems to do slightly worse with the RMSE aggregator than with the log-product aggregator. Like we discussed in Section 8.5, cons% is higher using this aggregator because the corners ai = 0, ci = 0 and ai = 1, ci = 1 will have no gradient when using the RMSE aggregator. However, the values of cucons% and cuant% are much lower than when using the log-product aggregator. This could have to do with the previously made point: As it no longer has a gradient of 1 at the corners a = 0, c = 0 and a = 1, c = 1, the large gradients are only when the agent is not yet confident about some prediction. This case is inherently ‘riskier’, but also contributes more information. It is not as informative to increase the confidence of a = 0 if a is already very low.The Łukasiewicz t-norm has a particularly high accuracy of 96.9% with the log product and is on the level of performance of the product t-norm. However, it has a very low value for cucons% of 0.06 and a relatively low value for cuant%. Interest-ingly, it is also the only configuration for which cucons% is higher when using the RMSE aggregator than the log-product aggregator.F.3. Reichenbach-sigmoidal implicationThe newly introduced Reichenbach-sigmoidal implication σI RC is a promising candidate for the choice of implication as we have argued in Section 8.5.1. To get a better understanding of this implication, we investigate the effect of its parameters in the same problem. We fix the aggregator to the log-product, the conjunction operator to the Yager t-norm with p = 2, and use a DFL weight of w D F L = 10.18 It is slightly more than 110 because we are using a minibatch of examples. Therefore, the reflexive pairs (i.e., same(x, x)) are common.43E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. F.18. The results using the Reichenbach-sigmoidal implication σI RC , the Alog T P aggregator, T Y with p = 2 and w D F L = 10. Left shows the results for various values of s, keeping b0 fixed to -0.5, and right shows the results for various values of b0, keeping s fixed to 9.Table F.12The results using T Y , p = 2 for the conjunction, Alog T Pand R-implications. These are run using vanilla SGD instead of ADAM.for the aggregator with w 1 = 10 and several S-implications Accuracycons%I K DI L KI RCI Y , p = 2I F D96.197.096.996.696.30.100.50.080.120.07cucons%0.880.030.850.870.65cuant%0.970.970.990.970.96Accuracycons%I GI L KI G GI T YI F DI T Y , p = 0.590.697.094.095.496.396.310.50.860.580.070.18cucons%0.070.030.010.030.650.65cuant%0.970.970.990.960.37Table F.13for the implication with s = 9 and The results using σI RCfor the 2 , T Y , p = 2 for the conjunction and Alog T Pb0 = − 1aggregator with w D F L = 10, leaving some formulas of thesame problem out. The numbers indicated the formulas that are present during training.FormulasAccuracycons%(1) & (2)(2) & (3)(1) & (3)(1)(2)(3)97.195.996.395.695.295.80.050.120.150.050.030.19cucons%0.540.750.520.590.780.64cuant%0.990.950.981.000.990.95On the left plot of Fig. F.18 we find the results when we experiment with the parameter s, keeping b0 fixed to − 12 . Note that when s approaches 0 the Reichenbach-sigmoidal implication is I RC . The value of 9 gives the best results, with 97.3% accuracy. This outperforms the other implications, also when using the vanilla SGD optimizer, as displayed in Table F.12. Interestingly enough, there seem to be clear trends in the values of cons%, cucons% and cuant%. Increasing s seems to increase cons%. This is because the antecedent derivative around the corner a = 0, c = 0 will be low, as argued in Section 8.5.1. When s increases, the corners will be more smoothed out. Furthermore, both cucons% and cuant% decrease when s increases. This could again be because around the corners the derivatives become small. Updates in the corner will likely be correct as the model is already confident about those. For a higher value of s, most of the gradient magnitude is at instances on which the model is less confident. We note that the same happened when using the RMSE aggregator and the product t-norm. Regardless, the best parameter value clearly is not the one for which the values of cucons% and cuant% are highest, namely the Reichenbach implication itself.On the right plot of Fig. F.18 we experiment with the value of b0. Clearly, − 12 works best, having the highest accuracy and cucons%.F.4. Influence of individual formulasFinally, we compare what the influence of the different formulas of the same problem is in Table F.13. Removing the reflexivity formula (3) does not largely impact the performance. The biggest drop in performance is by removing formula (1) that defines the same predicate. Using only formula (1) gets slightly better performance than only using formula (2), despite the fact that no positive labeled examples can be found using formula (1) as the predicates zero to nine are not in its consequent. Since 95% of the derivatives are with respect to the negated antecedent, this formula contributes by finding 44E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602additional counterexamples. Furthermore, improving the accuracy of the same predicate improves the accuracy on digit recognition: Just using the reflexivity formula (3) has the highest accuracy when used individually, even though it does not use the digit predicates.References[1] E. Arakelyan, D. Daza, P. Minervini, M. Cochez, Complex query answering with neural link predictors, in: International Conference on Learning Repre-sentations, 2021.preprint arXiv:1906 .06576, 2019.[2] S. Badreddine, A. d’Avila Garcez, L. Serafini, M. Spranger, Logic tensor networks, arXiv:2012 .13635 [cs], http://arxiv.org /abs /2012 .13635, 2020.[3] S. Badreddine, M. Spranger, Injecting prior knowledge for transfer learning into reinforcement learning algorithms using logic tensor networks, arXiv [4] H. Bal, D. Epema, C. de Laat, R. van Nieuwpoort, J. Romein, F. Seinstra, C. Snoek, H. Wijshoff, A medium-scale distributed system for computer science research: infrastructure for the long term, Computer 49 (2016) 54–63.[5] K. Ball, An elementary introduction to modern convex geometry, in: Flavors of Geometry, vol. 31, 1997, pp. 1–58.[6] T.R. Besold, A.d. Garcez, S. Bader, H. Bowman, P. Domingos, P. Hitzler, K.U. Kuehnberger, L.C. Lamb, D. Lowd, P.M.V. Lima, L. de Penning, G. Pinkas, H. Poon, G. Zaverucha, Neural-symbolic learning and reasoning: a survey and interpretation, arXiv preprint arXiv:1711.03902, http://arxiv.org /abs /1711.03902, 2017.[7] C.M. Bishop, Pattern Recognition and Machine Learning, 2006.[8] A. Brock, J. Donahue, K. Simonyan, Large scale GAN training for high fidelity natural image synthesis, arXiv preprint arXiv:1809 .11096, 2018.[9] M. Buda, A. Maki, M.A. Mazurowski, A systematic study of the class imbalance problem in convolutional neural networks, Neural Netw. 106 (2018) [10] T. Calvo, A. Kolesárová, M. Komorníková, R. Mesiar, Aggregation operators: properties, classes and construction methods, in: T. Calvo, G. Mayor, R. Mesiar (Eds.), Aggregation Operators: New Trends and Applications, Physica-Verlag HD, Heidelberg, 2002, pp. 3–104.[11] R. Cignoli, F. Esteva, L. Godo, F. Montagna, On a class of left-continuous t-norms, Fuzzy Sets Syst. 131 (2002) 283–296, https://doi .org /10 .1016 /S0165 -[12] P. Cintula, P. Hájek, C. Nogura, Handbook of Mathematical Fuzzy Logic, vol. 1, College Publications, 2011.[13] A. Daniele, L. Serafini, Knowledge enhanced neural networks, in: A.C. Nayak, A. Sharma (Eds.), PRICAI 2019: Trends in Artificial Intelligence, Springer International Publishing, Cham, 2019, pp. 542–554.[14] A. Darwiche, SDD: a new canonical representation of propositional knowledge bases, in: IJCAI International Joint Conference on Artificial Intelligence, 249–259.0114(01 )00215 -9.2011, pp. 819–826.[15] H.A. David, H.N. Nagaraja, Order Statistics, third edition, Encyclopedia of Statistical Sciences, 2003.[16] T. Demeester, T. Rocktäschel, S. Riedel, Lifted rule injection for relation embeddings, in: Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, 2016, pp. 1389–1399, http://aclweb .org /anthology /D16 -1146.[17] M. Diligenti, M. Gori, C. Sacca, Semantic-based regularization for learning and inference, Artif. Intell. 244 (2017) 143–165.[18] M. Diligenti, S. Roychowdhury, M. Gori, Integrating prior knowledge into deep learning, in: Machine Learning and Applications (ICMLA), 2017 16th [19] I. Donadello, L. Serafini, A.d. Garcez, Logic tensor networks for semantic image interpretation, in: IJCAI International Joint Conference on Artificial IEEE International Conference on, IEEE, 2017, pp. 920–923.Intelligence, 2017, pp. 1596–1602, http://arxiv.org /abs /1705 .08968.[20] R. Evans, E. Grefenstette, Learning explanatory rules from noisy data, J. Artif. Intell. Res. 61 (2018) 65–170, https://doi .org /10 .1613 /jair.5477.[21] K. Ganchev, J. Gillenwater, Posterior regularization for structured latent variable models, J. Mach. Learn. Res. 11 (2010) 2001–2049, http://dl .acm .org /citation .cfm ?id =1756006 .1859918.[22] A.d. Garcez, K.B. Broda, D.M. Gabbay, Neural-Symbolic Learning Systems: Foundations and Applications, Springer Science & Business Media, 2012.[23] M. Garnelo, K. Arulkumaran, M. Shanahan, Towards deep symbolic reinforcement learning, arXiv preprint arXiv:1609 .05518, 2016.[24] L. Getoor, B. Taskar, Introduction to Statistical Relational Learning, vol. 1, MIT Press, Cambridge, 2007.[25] I. Goodfellow, Y. Bengio, A. Courville, Y. Bengio, Deep Learning, vol. 1, MIT Press, Cambridge, 2016.[26] S. Guo, Q. Wang, L. Wang, B. Wang, L. Guo, Jointly embedding knowledge graphs and logical rules, in: Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, 2016, pp. 192–202.[27] A.K. Gupta, S. Nadarajah, Handbook of Beta Distribution and Its Applications, CRC Press, 2004.[28] P. Hájek, The Metamathematics of Fuzzy Logic, Kluwer, 1998.[29] P. Hall, The distribution of means for samples of size N drawn from a population in which the variate takes values between 0 and 1, all such values being equally probable, Biometrika 19 (1927) 240–245, http://www.jstor.org /stable /2331961.[30] S. Harnad, The symbol grounding problem, Physica D 42 (1990) 335–346.[31] C.G. Hempel, Studies in the Logic of Confirmation (II.), Mind, vol. 54, 1945, pp. 97–121, http://www.jstor.org /stable /2250948.[32] Z. Hu, X. Ma, Z. Liu, E. Hovy, E. Xing, Harnessing deep neural networks with logic rules, in: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Association for Computational Linguistics, 2016, pp. 2410–2420, http://aclweb .org /anthology /P16 -1228.[33] C.L. Hwang, A.S.M. Masud, Multiple Objective Decision Making—Methods and Applications: A State-of-the-Art Survey, vol. 164, Springer Science & Business Media, 2012.[34] J.O. Irwin, On the frequency distribution of the means of samples from a population having any law of frequency with finite moments, with special reference to Pearson’s type II, Biometrika (1927) 225–239.[35] J.S.R. Jang, ANFIS: adaptive-network-based fuzzy inference system, IEEE Trans. Syst. Man Cybern. (1993), https://doi .org /10 .1109 /21.256541.[36] J.S.R. Jang, C.T. Sun, E. Mizutani, Neuro-Fuzzy and Soft Computing: A Computational Approach to Learning and Machine Intelligence, 1997.[37] N. Japkowicz, S. Stephen, The class imbalance problem: a systematic study, Intell. Data Anal. 6 (2002) 429–449.[38] B. Jayaram, M. Baczynski, Fuzzy Implications, vol. 231, Springer, Berlin, Heidelberg, 2008, http://link.springer.com /10 .1007 /978 -3 -540 -69082 -5.[39] D.P. Kingma, J. Ba, Adam: a method for stochastic optimization, arXiv:1412 .6980 [cs], http://arxiv.org /abs /1412 .6980, 2017.[40] E.P. Klement, R. Mesiar, E. Pap, Triangular Norms, vol. 8, Springer Science & Business Media, 2013.[41] G. Klir, B. Yuan, Fuzzy Sets and Fuzzy Logic, vol. 4, Prentice Hall, New Jersey, 1995.[42] E. van Krieken, E. Acar, F. van Harmelen, Semi-supervised learning using differentiable reasoning, IfCoLog J. Log. Appl. 6 (2019) 633–653.[43] Y. LeCun, C. Cortes, MNIST handwritten digit database, http://yann .lecun .com /exdb /mnist/, 2010.[44] C.T. Lin, G.C. Lee, Neural-network-based fuzzy logic control and decision system, IEEE Trans. Comput. (1991), https://doi .org /10 .1109 /12 .106218.[45] Y. Liu, E. Kerre, An overview of fuzzy quantifiers. (I). Interpretations, Fuzzy Sets Syst. 95 (1998) 1–21.[46] R. Manhaeve, S. Dumanˇci ´c, A. Kimmig, T. Demeester, L. De Raedt, DeepProbLog: neural probabilistic logic programming, in: S. Bengio, H.M. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, R. Garnett (Eds.), Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3–8 December 2018, Montréal, Canada, 2018, http://arxiv.org /abs /1805 .10872, http://papers .nips .cc /book /advances -in -neural -information -processing -systems -31 -2018, 2018.45E. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602[47] G. Marcus, Deep learning: a critical appraisal, arXiv preprint arXiv:1801.00631, 2018.[48] G. Marra, F. Giannini, M. Diligenti, M. Gori, Constraint-based visual generation, arXiv preprint arXiv:1807.09202, 2018.[49] G. Marra, F. Giannini, M. Diligenti, M. Gori, Integrating learning and reasoning with deep logic models, arXiv preprint arXiv:1901.04195, pp. 1–17, https://arxiv.org /pdf /1901.04195v1.pdf, 2019.[50] G. Marra, F. Giannini, M. Diligenti, M. Maggini, M. Gori, Learning and T-norms theory, arXiv preprint arXiv:1907.11468, 2019.[51] M. Mayo, Symbol grounding and its implications for artificial intelligence BT, in: Twenty-Sixth Australasian Computer Science Conference (ACSC2003), [52] P. Minervini, T. Demeester, T. Rocktäschel, S. Riedel, Adversarial sets for regularising neural link predictors, in: Uncertainty in Artificial Intelligence-16, 2003, pp. 55–60, http://crpit .com /confpapers /CRPITV16Mayo .pdf.Proceedings of the 33rd Conference, UAI 2017, 2017.on Computational Natural Language Learning, 2018, pp. 65–74.[53] P. Minervini, S. Riedel, Adversarially regularising neural NLI models to integrate logical background knowledge, in: Proceedings of the 22nd Conference [54] S. Muggleton, L. de Raedt, Inductive logic programming: theory and methods, J. Log. Program. 19–20 (1994) 629–679, https://doi .org /10 .1016 /0743 -1066(94 )90035 -3, http://www.sciencedirect .com /science /article /pii /0743106694900353.[55] K.P. Murphy, Y. Weiss, M.I. Jordan, Loopy belief propagation for approximate inference: an empirical study, in: Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence, Morgan Kaufmann Publishers Inc., 2013, pp. 467–475, http://arxiv.org /abs /1301.6725.[56] V. Novák, I. Perfilieva, J. Moˇckoˇr, Mathematical Principles of Fuzzy Logic, Springer, US, 1999, https://doi .org /10 .1007 /978 -1 -4615 -5217 -8.[57] H. Páll Jónsson, Real Logic and Logical Tensor Networks, University of Amsterdam, 2018, MSc thesis, 45.[58] J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, Elsevier, 1988.[59] J. Pearl, Theoretical impediments to machine learning with seven sparks from the causal revolution, in: Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, ACM, 2018, p. 3.[60] T.G. Pham, N. Turkkan, Reliability of a standby system with beta-distributed component lives, IEEE Trans. Reliab. (1994), https://doi .org /10 .1109 /24 .[61] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, Language Models Are Unsupervised Multitask Learners, 2019.[62] A. Rasmus, M. Berglund, M. Honkala, H. Valpola, T. Raiko, Semi-supervised learning with ladder networks, in: Advances in Neural Information Process-285114.ing Systems, 2015, pp. 3546–3554.[63] R. Riegel, A. Gray, F. Luus, N. Khan, N. Makondo, I.Y. Akhalwaya, H. Qian, R. Fagin, F. Barahona, U. Sharma, S. Ikbal, H. Karanam, S. Neelam, A. Likhyani, S. Srivastava, Logical neural networks, arXiv:2006 .13155, 2020.[64] T. Rocktäschel, S. Riedel, End-to-end differentiable proving, https://arxiv.org /pdf /1705 .11040 .pdf, http://arxiv.org /abs /1705 .11040, 2017.[65] T. Rocktäschel, S. Singh, S. Riedel, Injecting logical background knowledge into embeddings for relation extraction, in: Proceedings of the 2015 Con-ference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2015, pp. 1119–1129, https://rockt .github .io /pdf /rocktaschel2015injecting .pdf, http://www.aclweb .org /anthology /N15 -1118, http://aclweb .org /anthology /N15 -1118.[66] P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Galligher, T. Eliassi-Rad, Collective classification in network data, AI Mag. 29 (2008) 93.[67] L. Serafini, A.D. Garcez, Logic tensor networks: deep learning and logical reasoning from data and knowledge, in: CEUR Workshop Proceedings 1768, 2016.05128 .pdf.3 .545.[68] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton, et al., Mastering the game of Go without human knowledge, Nature 550 (2017) 354.[69] R. Socher, D. Chen, C.D. Manning, A.Y. Ng, Reasoning with neural tensor networks for knowledge base completion, in: Proc. of NIPS’13, 2013, pp. 1–10.[70] G. Šourek, V. Aschenbrenner, F. Železný, O. Kuželka, Lifted relational neural networks, in: CEUR Workshop Proceedings, 2015, https://arxiv.org /pdf /1508 .[71] G. šourek, V. Aschenbrenner, F. Železný, S. Schockaert, O. Kuželka, Lifted relational neural networks: efficient learning of latent relational structures, J. Artif. Intell. Res. 62 (2018) 69–100, https://doi .org /10 .1613 /jair.1.11203.[72] P.B. Vranas, Hempel’s raven paradox: a lacuna in the standard Bayesian solution, Br. J. Philos. Sci. 55 (2004) 545–560, https://doi .org /10 .1093 /bjps /55 .[73] H. Weisberg, The distribution of linear combinations of order statistics from the uniform distribution, Ann. Math. Stat. 42 (1971) 704–709, https://doi .org /10 .1214 /aoms /1177693419, https://doi .org /10 .1214 /aoms /1177693419.[74] J. Xu, Z. Zhang, T. Friedman, Y. Liang, G. den Broeck, A semantic loss function for deep learning with symbolic knowledge, in: J. Dy, A. Krause (Eds.), Proceedings of the 35th International Conference on Machine Learning, PMLR, Stockholmsmässan, Stockholm Sweden, 2018, pp. 5502–5511, http://proceedings .mlr.press /v80 /xu18h .html.[75] R.R. Yager, On a general class of fuzzy connectives, Fuzzy Sets Syst. 4 (1980) 235–242.[76] Z.H. Zhou, A brief introduction to weakly supervised learning, Nat. Sci. Rev. 5 (2017) 44–53.46